[{"figure_path": "181llen2gw/tables/tables_7_1.jpg", "caption": "Table 1: Experimental results for zero-shot classification (FACET dataset) tasks. Bold indicates the best result for each baseline, while underline denotes the second-best result.", "description": "This table presents the results of zero-shot multi-class classification experiments conducted on the FACET dataset.  The table compares the performance of several models: a baseline, DeAR, CLIP-clip, Prompt-Debias, and the proposed SFID method.  Performance is evaluated using two metrics: Accuracy and \u0394DP (Demographic Parity). The bold values represent the best accuracy for each model type (CLIP ResNet50, CLIP ViT-B/32, and XVLM), while underlined values indicate the second-best results.  The \u0394DP metric quantifies the fairness of the model's predictions. Lower values indicate better fairness.", "section": "3 Bias Analysis in VLMs"}, {"figure_path": "181llen2gw/tables/tables_8_1.jpg", "caption": "Table 2: Experimental results for text-to-image retrieval (Flickr30K dataset) tasks. Bold indicates the best result for each baseline, while underline denotes the second-best result.", "description": "This table presents the results of text-to-image retrieval experiments using three different vision-language models (CLIP with ResNet-50, CLIP with ViT-B/32, and XVLM).  For each model, it shows the recall at ranks 1, 5, and 10, as well as the gender bias (Skew@100) using the Flickr30K dataset.  The results are shown for a baseline model and four debiasing methods (DeAR, CLIP-clip, Prompt-Debias, and SFID). The bold values indicate the best performance for each model and baseline, while underlined values indicate the second-best performance.", "section": "3.2 Text-to-Image Retrieval"}, {"figure_path": "181llen2gw/tables/tables_8_2.jpg", "caption": "Table 3: Experimental results for image captioning. Bold indicates the best result for each baseline, while underline denotes the second-best result.", "description": "This table presents the experimental results for image captioning task using different models.  Metrics include caption quality (Max METEOR and Max SPICE scores) and misclassification rates (Male-Female, Overall, and Composite).  The table compares the performance of a baseline model against several debiasing methods, highlighting the best-performing method for each metric and model.", "section": "3 Bias Analysis in VLMs"}, {"figure_path": "181llen2gw/tables/tables_8_3.jpg", "caption": "Table 4: Experimental results for text-to-image generation. Bold indicates the best result for each baseline, while underline denotes the second-best result.", "description": "This table presents the performance of different debiasing methods on the text-to-image generation task, using two metrics: mismatch rate and skew. Mismatch rate evaluates the accuracy of gender prediction in generated images, considering both gender-specific and neutral prompts.  Skew measures the fairness of gender distribution in images generated from neutral prompts. The results show the effectiveness of SFID (both LC and HC) in reducing bias without significantly sacrificing overall performance.", "section": "3 Bias Analysis in VLMs"}, {"figure_path": "181llen2gw/tables/tables_9_1.jpg", "caption": "Table 5: Ablation study for low confidence imputation (LCI) and hyperparameter \u03c4 in SFID.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of low-confidence imputation (LCI) and the hyperparameter \u03c4 on the performance of the Selective Feature Imputation for Debiasing (SFID) method.  The study uses the XVLM model and assesses performance across zero-shot classification accuracy (Accuracy), demographic parity (\u0394 DP), and text-to-image retrieval metrics (R@1, R@5, R@10, Skew@100) using the FACET and Flickr30K datasets.  Different variations of SFID are compared, including those with zero filling, Gaussian noise, and LCI with varying values of \u03c4. The results demonstrate the effectiveness of LCI and the optimal value of \u03c4 for achieving a balance between bias mitigation and overall performance.", "section": "5.3 Ablation Study"}, {"figure_path": "181llen2gw/tables/tables_16_1.jpg", "caption": "Table 6: Comparison of Mean Accuracy, Mean DP, and Max DP for different methods", "description": "This table presents a comparison of the performance of different methods in terms of Mean Accuracy, Mean Demographic Parity (DP), and Max DP for multi-class zero-shot classification on the FACET dataset.  It shows the results for three different Vision-Language Models (VLMs) and the improvements achieved by applying the Selective Feature Imputation for Debiasing (SFID) method.", "section": "5.3 Multi-attribute Study"}, {"figure_path": "181llen2gw/tables/tables_17_1.jpg", "caption": "Table 1: Experimental results for zero-shot classification (FACET dataset) tasks. Bold indicates the best result for each baseline, while underline denotes the second-best result.", "description": "This table presents the results of zero-shot multi-class classification experiments using three different vision-language models (CLIP with ResNet-50, CLIP with ViT-B/32, and XVLM) on the FACET dataset.  The table shows the accuracy and average demographic parity (ADP) for each model, comparing the baseline performance to those of several debiasing methods (DeAR, CLIP-clip, Prompt-Debias). Bold values highlight the best performance for each model, and underlined values show the second-best performance.  The table demonstrates the effectiveness of the proposed SFID method in improving model accuracy while simultaneously reducing bias.", "section": "3 Bias Analysis in VLMs"}]