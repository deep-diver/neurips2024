[{"figure_path": "fOQunr2E0T/tables/tables_4_1.jpg", "caption": "Table 1: Active\u2194Logical accuracy. Results are the best performance over five runs. The test sets are divided into IID, and OOD sets 0-shot lexical and structural. Parameter and memory usage is shown for the original DTM with TPRs and our proposed sparse DTM with and without pruning. Our modifications reduce the parameter count by almost two orders of magnitude. *NQG was trained on a seq2seq version without parantheses because it was not able to learn the tree2tree training set.", "description": "This table presents the performance comparison of different models on the Active-Logical task, comparing in-distribution (IID) and out-of-distribution (OOD) generalization abilities.  The models compared are a standard Transformer, a Relative Universal Transformer, NQG (a hybrid neurosymbolic model), the original Differentiable Tree Machine (DTM), and the proposed Sparse Differentiable Tree Machine (sDTM) with and without pruning. The table shows accuracy scores for each model and dataset split (IID, 0-shot lexical, structural), along with the parameter count and memory usage.  It highlights the significant improvement of sDTM in terms of efficiency (parameter count and memory usage) without sacrificing accuracy compared to DTM and other models.", "section": "5.2 Performance Regression (Active Logical)"}, {"figure_path": "fOQunr2E0T/tables/tables_7_1.jpg", "caption": "Table 1: Active\u2194Logical accuracy. Results are the best performance over five runs. The test sets are divided into IID, and OOD sets 0-shot lexical and structural. Parameter and memory usage is shown for the original DTM with TPRs and our proposed sparse DTM with and without pruning. Our modifications reduce the parameter count by almost two orders of magnitude. *NQG was trained on a seq2seq version without parantheses because it was not able to learn the tree2tree training set.", "description": "This table presents the results of an experiment comparing the performance of different models on the Active\u2194Logical task, which involves transforming trees between active and logical forms.  The models compared include a standard Transformer, a Relative Universal Transformer, NQG (a hybrid neurosymbolic system), and two versions of the Differentiable Tree Machine (DTM): the original and a sparse version (sDTM). The table shows accuracy scores on three test sets: IID (in-distribution), 0-shot lexical (out-of-distribution with unseen words), and structural (out-of-distribution with unseen tree structures). It also displays model parameters, memory usage, and relative speed.  The results demonstrate the superior performance of the DTM models, especially the sparse variant, in handling out-of-distribution data.", "section": "5.2 Performance Regression (Active Logical)"}, {"figure_path": "fOQunr2E0T/tables/tables_8_1.jpg", "caption": "Table 2: Accuracies on FOR2LAM and GeoQuery. Results are the best performance over five runs. NQG cannot be evaluated on FOR2LAM because it takes over a week to train. Results taken from Shaw et al. [58]. *We report the results from a replication study of NQG where the result on the Length split differed substantially from the original result [69].", "description": "This table presents the results of four different models (Transformer, RU-Transformer, NQG, and sDTM) on two datasets (FOR2LAM and GeoQuery) with various evaluation splits. FOR2LAM is a tree-to-tree program translation task that measures generalization abilities of the models. GeoQuery is a natural language to SQL dataset focusing on compositional generalization abilities of the models. The various evaluation splits evaluate models ability to perform in different out-of-distribution conditions, such as zero-shot and one-shot lexical samples, structural and length generalization, and template generalization. The results show that sDTM is comparatively more robust against out-of-distribution shifts compared to other models in most cases.", "section": "5 Results"}, {"figure_path": "fOQunr2E0T/tables/tables_9_1.jpg", "caption": "Table 3: SCAN accuracy. Results are the best performance over five runs. MCD scores are calculated as the average of the three MCD splits. Results from Shaw et al. [58]. *Results from Sun et al. [69].", "description": "This table presents the accuracy results of different models on the SCAN dataset across various data splits: IID (in-distribution), 1-shot lexical, 0-shot lexical, Length, Template, and MCD (maximum compound divergence).  The models compared are Transformer, RU-Transformer, NQG (a hybrid neurosymbolic model), sDTM with parse trees, sDTM with LAUD (Left-Aligned Uniform Depth) trees, and DTM (the original Differentiable Tree Machine).  The table highlights the performance of each model in handling different out-of-distribution shifts, showcasing the strengths and weaknesses of each approach in compositional generalization.  The MCD scores represent the average accuracy across three different MCD splits.", "section": "5.5 Seq2Seq (SCAN)"}, {"figure_path": "fOQunr2E0T/tables/tables_16_1.jpg", "caption": "Table 4: Comparing sDTM's accuracy on SCAN 1-shot lexical OOD generalization with and without lexical regularization. We use LAUD to embed the output sequence in a tree.", "description": "This table presents the results of an experiment comparing the performance of the Sparse Differentiable Tree Machine (sDTM) model on the SCAN dataset with and without lexical regularization.  The experiment focuses on one-shot lexical out-of-distribution generalization.  The table shows the accuracy of the sDTM model when trained with and without adding noise to the token embeddings, a form of regularization. The LAUD (Left-Aligned Uniform Depth) method was used to embed the output sequence into a tree structure for processing. The results demonstrate a significant improvement in accuracy when lexical regularization (noise) is used.", "section": "5.2 Performance Regression (Active Logical)"}, {"figure_path": "fOQunr2E0T/tables/tables_17_1.jpg", "caption": "Table 1: Active\u2194Logical accuracy. Results are the best performance over five runs. The test sets are divided into IID, and OOD sets 0-shot lexical and structural. Parameter and memory usage is shown for the original DTM with TPRs and our proposed sparse DTM with and without pruning. Our modifications reduce the parameter count by almost two orders of magnitude. *NQG was trained on a seq2seq version without parantheses because it was not able to learn the tree2tree training set.", "description": "This table presents the results of the Active\u2194Logical experiment, comparing the performance of various models including the original DTM, sDTM (with and without pruning), Transformer, RU-Transformer, and NQG.  The performance is measured across three data splits: IID (in-distribution), 0-shot lexical (out-of-distribution with unseen words), and structural (out-of-distribution with novel syntactic structures).  The table also shows the model parameters, memory usage, and relative speed, highlighting the significant efficiency gains achieved by sDTM compared to the original DTM.", "section": "5.2 Performance Regression (Active Logical)"}, {"figure_path": "fOQunr2E0T/tables/tables_17_2.jpg", "caption": "Table 6: Summary statistics for FOR2LAM and GeoQuery. Mean and standard deviation accuracies are shown.", "description": "This table presents the mean and standard deviation of accuracies achieved by the sDTM model on two tasks: FOR2LAM and GeoQuery. FOR2LAM is a tree-to-tree program translation task and GeoQuery is a natural language to SQL query task. The results are broken down by dataset split (IID, 0-shot lexical, Length, Template, TMCD) to show performance under different generalization settings.", "section": "5 Results"}, {"figure_path": "fOQunr2E0T/tables/tables_18_1.jpg", "caption": "Table 7: Summary statistics for SCAN. Mean and standard deviation accuracies are shown.", "description": "This table presents the performance of three different models (sDTM with parse trees, sDTM with LAUD trees, and DTM with parse trees) on the SCAN dataset across various data splits.  The splits represent different out-of-distribution scenarios (1-shot lexical, 0-shot lexical, length, template, MCD). The mean and standard deviation accuracies are reported for each model and split, showing the variability in performance across different runs.", "section": "5.5 Seq2Seq (SCAN)"}]