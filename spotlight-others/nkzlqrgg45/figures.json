[{"figure_path": "NKzLqRgG45/figures/figures_1_1.jpg", "caption": "Figure 1: Different parameter-resolution designs of image pyramid networks. (a) Plain network which lacks multi-scale features. (b)(c) Inefficient image pyramid networks (shared weights / separate weights with interactions) using equivalently large networks for all scales. (d) Parameter-direct image pyramid network which processes high-resolution images with large models, leading to high computational cost. (e) Our efficient parameter-inverted image pyramid network (PIIP), which pairs models of increasing parameter sizes inversely with images of decreasing resolution. It delivers better performance than those of (b)(c)(d) with much lower computational cost.", "description": "This figure illustrates five different approaches to incorporating image pyramids into a neural network for image processing.  (a) shows a simple network without multi-scale processing. (b) and (c) depict traditional image pyramid approaches that use the same large model at all resolutions, leading to inefficiency.  (d) showcases a parameter-direct approach, where high-resolution images are processed by a large model, also resulting in high computational cost. Finally, (e) presents the proposed Parameter-Inverted Image Pyramid Network (PIIP), which uses smaller models for higher-resolution images and larger models for lower-resolution images, optimizing for computational efficiency without sacrificing performance. The key idea behind PIIP is that features at different resolutions are complementary and can be efficiently fused.", "section": "1 Introduction"}, {"figure_path": "NKzLqRgG45/figures/figures_3_1.jpg", "caption": "Figure 2: Overall architecture of our method. We use multi-resolution branches to process images of different resolutions, where larger images are handled by smaller models. Interaction Units build connections between branches. Branch merging combines the features of all branches to form the final output. Our architecture can leverage pre-trained models with different model sizes to build efficient image pyramids.", "description": "This figure illustrates the architecture of the Parameter-Inverted Image Pyramid Network (PIIP). It shows three branches processing images at different resolutions. Higher-resolution images are processed by smaller models, while lower-resolution images are processed by larger models.  Interaction units connect the branches, allowing features from different scales to be integrated. A final branch merging step combines the features from all branches to produce the final output. This design balances computational efficiency and performance.", "section": "3 Parameter-Inverted Image Pyramid Networks"}, {"figure_path": "NKzLqRgG45/figures/figures_4_1.jpg", "caption": "Figure 3: Structure of an interaction unit.", "description": "This figure shows the detailed architecture of a cross-branch interaction unit used in the Parameter-Inverted Image Pyramid Networks (PIIP).  It details the process of feature fusion between two adjacent branches (Branch 1 and Branch 2) in the PIIP network.  Each unit comprises two deformable cross-attention mechanisms and feed-forward networks (FFN). The first cross-attention takes the output (F\u1d62\u2081) of Branch 1's i-th block as a query, and the output (F\u1d62\u2082) of Branch 2's i-th block as keys and values.  A linear layer (FC) projects the dimensions.  This process is repeated with a second cross-attention, switching the query and key/value roles between the two branches.  Each cross-attention operation is followed by an FFN for channel-wise feature fusion. The resulting features, F\u1d62\u2081 and F\u1d62\u2082, are then fed into the subsequent blocks of their respective branches.", "section": "3.2 Cross-branch Interactions"}, {"figure_path": "NKzLqRgG45/figures/figures_8_1.jpg", "caption": "Figure 2: Overall architecture of our method. We use multi-resolution branches to process images of different resolutions, where larger images are handled by smaller models. Interaction Units build connections between branches. Branch merging combines the features of all branches to form the final output. Our architecture can leverage pre-trained models with different model sizes to build efficient image pyramids.", "description": "This figure illustrates the overall architecture of the Parameter-Inverted Image Pyramid Networks (PIIP). It shows how multi-resolution branches, each processing images of a different resolution, are used. Smaller models are employed for higher resolution images, balancing computational efficiency.  Interaction Units connect the branches, allowing feature fusion between different scales. Finally, a branch merging module integrates the features from all branches into a single output.  The figure highlights the efficiency achieved by using different sized pre-trained models for different resolutions, creating an efficient image pyramid.", "section": "3 Parameter-Inverted Image Pyramid Networks"}, {"figure_path": "NKzLqRgG45/figures/figures_9_1.jpg", "caption": "Figure 6: Performance of different interaction directions.", "description": "This figure shows the performance of different interaction directions in the PIIP network. Five different interaction methods were compared, varying the direction of information flow between branches at different resolutions. The results demonstrate that the bidirectional connections between adjacent branches achieve the best balance between computational cost and performance.", "section": "3.2 Cross-branch Interactions"}]