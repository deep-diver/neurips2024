[{"figure_path": "STrpbhrvt3/figures/figures_1_1.jpg", "caption": "Figure 1: In-domain (ID), out-of-domain (OOD), and average of ID and OOD (Avg) performance on confounded medical image datasets. Our interpretable Knowledge-enhanced Bottlenecks (KnoBo) are more robust to domain shifts (e.g., race, hospital, etc) than fine-tuned vision transformers [17].", "description": "This figure compares the performance of the proposed KnoBo model and a standard vision transformer model (ViT) on in-domain and out-of-domain medical image datasets.  The datasets were confounded by introducing demographic variables (race) and environmental factors (hospital) that are not directly relevant to the medical diagnosis.  The results show that KnoBo significantly outperforms ViT on out-of-domain data, demonstrating improved robustness to domain shifts.", "section": "1 Introduction"}, {"figure_path": "STrpbhrvt3/figures/figures_1_2.jpg", "caption": "Figure 2: Classification performance on natural and medical images through linear probing using features extracted from untrained and frozen models versus pixels features (See Sec 3 for details).", "description": "This figure compares the performance of using different feature extraction methods (random pixel values, features from untrained CNN, ViT models) for image classification tasks across natural images and medical images (X-rays, skin lesions).  Linear probing was used to evaluate the quality of image representations generated by each method, by training a linear classifier on top of the features. The results indicate that while existing visual backbones are effective at extracting features from natural images, they are not as effective for medical images, where raw pixel values sometimes perform better.", "section": "Deep Image Priors for Medical Images"}, {"figure_path": "STrpbhrvt3/figures/figures_3_1.jpg", "caption": "Figure 3: Overview of Knowledge-enhanced Bottlenecks (KnoBo) for medical image classification, comprising three main components: (1) Structure Prior (Sec 4.2) constructs the trustworthy knowledge bottleneck by leveraging medical documents; (2) Bottleneck Predictor (Sec 4.3) grounds the images onto concepts which are used as input for the linear layer and ; (3) Parameter Prior (Sec 4.4) constrains the learning of linear layer with parameters predefined by doctors or LLMs.", "description": "This figure illustrates the architecture of the Knowledge-enhanced Bottlenecks (KnoBo) model.  It shows three main components working together:\n\n1.  **Structure Prior:** Uses medical documents to create a concept bottleneck. This bottleneck helps the model focus on clinically relevant factors. \n2.  **Bottleneck Predictor:** Maps the input medical image to the concept space created in the Structure Prior stage.  It produces a probability of each concept for the input image.\n3. **Parameter Prior:** Constrains the model parameters with information from the medical literature or expert knowledge, making the model less sensitive to biases and spurious correlations in the training data.\nThese components work together to produce a final classification result.", "section": "4 Knowledge-enhanced Bottlenecks"}, {"figure_path": "STrpbhrvt3/figures/figures_8_1.jpg", "caption": "Figure 4: Ablation of bottleneck sizes on X-ray datasets. The x-axis is the number of randomly selected concepts (KnoBo) or visual features (Linear Probe). +prior means adding parameter prior.", "description": "This ablation study analyzes the effect of varying the number of concepts or features used in the model on its performance across different evaluation metrics (in-domain, out-of-domain, average, and unconfounded).  It compares KnoBo (with and without a parameter prior) against a linear probe baseline.  The results show how the choice of bottleneck size impacts the model's robustness and accuracy.", "section": "6 Results"}, {"figure_path": "STrpbhrvt3/figures/figures_19_1.jpg", "caption": "Figure 3: Overview of Knowledge-enhanced Bottlenecks (KnoBo) for medical image classification, comprising three main components: (1) Structure Prior (Sec 4.2) constructs the trustworthy knowledge bottleneck by leveraging medical documents; (2) Bottleneck Predictor (Sec 4.3) grounds the images onto concepts which are used as input for the linear layer and ; (3) Parameter Prior (Sec 4.4) constrains the learning of linear layer with parameters predefined by doctors or LLMs.", "description": "This figure illustrates the architecture of Knowledge-enhanced Bottlenecks (KnoBo), a novel method for medical image classification.  KnoBo uses three main components to improve model performance and robustness to domain shifts.  The Structure Prior utilizes medical documents to construct a reliable bottleneck. The Bottleneck Predictor maps input images onto concepts defined by the prior, which are then used by a linear layer to predict the final label. Finally, the Parameter Prior leverages prior knowledge from medical experts to guide the training process of the linear layer.", "section": "4 Knowledge-enhanced Bottlenecks"}, {"figure_path": "STrpbhrvt3/figures/figures_21_1.jpg", "caption": "Figure 4: Ablation of bottleneck sizes on X-ray datasets. The x-axis is the number of randomly selected concepts (KnoBo) or visual features (Linear Probe). +prior means adding parameter prior.", "description": "This figure shows the results of an ablation study on the number of concepts or features used in the model for chest X-ray image classification.  The x-axis represents the number of concepts (for KnoBo) or features (for the Linear Probe baseline).  The y-axis shows the accuracy achieved on different types of datasets: in-domain (ID), out-of-domain (OOD), the average of both (Avg), and unconfounded test data. Separate lines and shaded areas represent the performance of KnoBo and the linear probe baseline, with and without the addition of a parameter prior.", "section": "6.2 Analysis"}, {"figure_path": "STrpbhrvt3/figures/figures_22_1.jpg", "caption": "Figure 1: In-domain (ID), out-of-domain (OOD), and average of ID and OOD (Avg) performance on confounded medical image datasets. Our interpretable Knowledge-enhanced Bottlenecks (KnoBo) are more robust to domain shifts (e.g., race, hospital, etc) than fine-tuned vision transformers [17].", "description": "This figure compares the performance of the proposed KnoBo model and a baseline model (fine-tuned vision transformers) on medical image datasets. The datasets are designed to have confounding factors such as race or hospital. The results show that KnoBo is more robust to these domain shifts, achieving better in-domain and out-of-domain performance than the baseline model. The figure shows the accuracy of each model on in-domain data, out-of-domain data and an average of both.", "section": "1 Introduction"}, {"figure_path": "STrpbhrvt3/figures/figures_23_1.jpg", "caption": "Figure 1: In-domain (ID), out-of-domain (OOD), and average of ID and OOD (Avg) performance on confounded medical image datasets. Our interpretable Knowledge-enhanced Bottlenecks (KnoBo) are more robust to domain shifts (e.g., race, hospital, etc) than fine-tuned vision transformers [17].", "description": "This figure compares the performance of the proposed KnoBo model and a standard vision transformer (ViT) model on medical image datasets that have been artificially confounded with various factors (race, hospital, etc.).  The ID (in-distribution) performance represents accuracy when the model is trained and tested on data from the same distribution. The OOD (out-of-distribution) performance shows how well the model generalizes to data with a different distribution due to the confounding factors. The Avg represents the average of ID and OOD, showing an overall robustness metric. The figure demonstrates KnoBo's improved robustness against domain shifts.", "section": "1 Introduction"}]