[{"figure_path": "105ZuvpdyW/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure illustrates the architecture of the SegVol model, which is designed for universal and interactive volumetric medical image segmentation. The model takes volumetric medical images as input, along with user-provided prompts (point, bounding box, or text). It utilizes a zoom-out-zoom-in mechanism to first generate a rough prediction mask using a reduced resolution image. This rough prediction is then used to identify a Region of Interest (ROI), which is further processed at a higher resolution to refine the segmentation mask.  The overall workflow involves several encoders (image, spatial, and semantic) and a decoder to produce the final volumetric mask.", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_5_1.jpg", "caption": "Figure 2: Violin plots for quantitative comparison experiment results of SegVol and SAM-like interactive methods[28, 38, 39, 29]. The vertical axis represents the Dice score.", "description": "This figure presents a comparison of the performance of SegVol against other similar interactive segmentation methods across various datasets and anatomical structures.  Violin plots visually represent the distribution of Dice scores for each method on each task, allowing for a comparison of both the central tendency and variability of performance.  The x-axis indicates the different segmentation tasks (e.g., specific organs or lesions), and the y-axis represents the Dice score, a common metric for evaluating the accuracy of segmentation. The plots highlight SegVol's superior performance in the majority of the tasks.", "section": "3 Experiments"}, {"figure_path": "105ZuvpdyW/figures/figures_6_1.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure provides a detailed overview of the SegVol model architecture, highlighting its key components and workflow.  SegVol takes volumetric medical images as input and uses various types of prompts (point, bounding box, text) for interactive segmentation.  The model's core consists of an image encoder, spatial and semantic encoders, and a mask decoder.  A notable feature is the zoom-out-zoom-in mechanism, where a rough prediction is generated initially at a lower resolution (zoom-out) before being refined with high-resolution processing (zoom-in) focused on the region of interest (ROI).", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_8_1.jpg", "caption": "Figure 4: The four cases demonstrate that semantic-prompt can clarify the ambiguity of spatial-prompt and avoid multi-plausible outputs. Each image shows the segmentation result of SegVol using the spatial-prompt, i.e. point or bounding box, and semantic-prompt, i.e. the caption below the image.", "description": "This figure shows four examples where a single spatial prompt (point or bounding box) could correspond to multiple anatomical structures.  The ambiguity is resolved by adding a semantic prompt (text description) which specifies the target structure. SegVol then correctly segments the intended anatomy.", "section": "3.4 Case Studies"}, {"figure_path": "105ZuvpdyW/figures/figures_8_2.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure provides a high-level overview of the SegVol model architecture, which is designed for universal and interactive volumetric medical image segmentation.  It illustrates the model's key components, including the image encoder, spatial and semantic encoders, fusion encoder, and mask decoder. The process starts with a volumetric input image and user prompts (point, bounding box, or text). The zoom-out-zoom-in mechanism is highlighted, showing how the model first generates a rough prediction mask using zoom-out inference and then refines it using zoom-in inference on the region of interest (ROI).", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_15_1.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure illustrates the architecture of the SegVol model, a 3D foundation model for volumetric medical image segmentation.  It shows the model's components, including image, spatial, and semantic encoders, a fusion encoder, and a mask decoder. The figure also highlights the model's interactive capabilities, supporting point, bounding box, and text prompts for user input.  A key feature is the zoom-out-zoom-in mechanism, which allows for efficient and accurate segmentation by first generating a rough prediction mask and then refining it with a zoom-in step on the region of interest (ROI).", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_15_2.jpg", "caption": "Figure 7: The joint dataset encompasses various anatomical structures in major regions of the human body. Several volume examples are demonstrated as 2D slices and 3D shapes in the images respectively.", "description": "This figure shows examples of the various anatomical structures included in the joint dataset used to train the SegVol model.  The images depict different body regions (head and neck, abdomen, thorax, pelvis) and demonstrate the range of anatomical structures included in the dataset, both as 2D slices and 3D renderings.  This visualization helps to illustrate the diversity and comprehensiveness of the dataset, highlighting the complexity of volumetric medical image segmentation.", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_18_1.jpg", "caption": "Figure 8: The demonstration of the training algorithm. Specifically, each case (training sample) consists of an Image x, a Ground Truth(GT) Mask Set Y, and a Pseudo Mask Set Z. The training loss of each sample consists of the ground-truth loss and the pseudo loss. The ground-truth loss is computed by inputting the image, the ground-truth mask (label), and the sampled prompt into the model, while the pseudo loss is computed by inputting the image, the pseudo label, and the fixed prompt into the model. Finally, the model is updated by minimizing the weighted sum of the two losses.", "description": "This figure illustrates the training algorithm of SegVol. Each training sample includes an image, a ground truth mask set, and a pseudo mask set. The training process involves two loops: one for the ground truth masks and one for the pseudo masks.  Different prompt types are used in each loop. The ground truth loss and the pseudo loss are calculated separately and then combined to update the model parameters.", "section": "2.2 Model Architecture"}, {"figure_path": "105ZuvpdyW/figures/figures_18_2.jpg", "caption": "Figure 9: Violin plots for comparing experiment results of SegVol and task-specific methods. The vertical axis is the Dice score.", "description": "The figure shows a comparison of the performance of SegVol against three other task-specific methods (nnU-Net, 3DUX-NET, and SwinUNETR) across ten different organ and lesion segmentation tasks.  Violin plots illustrate the distribution of Dice scores for each method and task, allowing for a visual comparison of performance variability and central tendency. The vertical axis represents the Dice score, a common metric for evaluating segmentation accuracy.", "section": "Additional Experimental Analysis"}, {"figure_path": "105ZuvpdyW/figures/figures_19_1.jpg", "caption": "Figure 10: Visualization results of SegVol and nnU-Net across 3 lesion segmentation tasks.", "description": "This figure visualizes the segmentation results of SegVol and nnU-Net on three lesion segmentation tasks: liver tumor, colon tumor, and lung tumor.  For each task, it presents four image columns: the ground truth, the nnU-Net prediction, and the SegVol prediction.  The visualization is meant to show a qualitative comparison of the segmentation performance of the two methods.  The cyan (light blue) outlines represent the SegVol predictions while the red outlines represent the nnU-Net predictions. The goal is to allow visual inspection of the accuracy and precision of both methods.", "section": "3 Experiments"}, {"figure_path": "105ZuvpdyW/figures/figures_20_1.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure illustrates the architecture of the SegVol model, a 3D foundation model for universal and interactive volumetric medical image segmentation.  It shows the process of taking a volumetric input and using various prompts (points, bounding boxes, text) to produce a precise segmentation mask. The key innovation is a zoom-out-zoom-in mechanism which starts by generating a rough prediction and then refines this prediction at a higher resolution on a region of interest (ROI).", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_21_1.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure provides a detailed overview of the SegVol model architecture. It shows the different components of the model, including the image encoder, spatial encoder, semantic encoder, fusion encoder, and mask decoder.  The figure also illustrates the zoom-out-zoom-in mechanism used for efficient and precise inference on volumetric images.  This mechanism involves initially generating a rough prediction mask using zoom-out inference, then refining this mask using zoom-in inference on a smaller region of interest (ROI) identified from the initial prediction. The various types of user interactions supported by the model, including point, bounding box, and text prompts, are also shown.", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_22_1.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure provides a detailed overview of the SegVol model architecture, illustrating its workflow for universal and interactive volumetric medical image segmentation.  It highlights the key components, including the image encoder, spatial and semantic encoders, fusion encoder, mask decoder, and the zoom-out-zoom-in mechanism.  The zoom-out-zoom-in process is shown to efficiently generate a precise segmentation mask by first creating a rough prediction and then refining it within the region of interest.  The figure showcases how various user prompts (points, bounding boxes, text) are incorporated into the process for flexible interaction.", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_23_1.jpg", "caption": "Figure 14: Visualized aorta and bladder prediction results of MedSAM[29], SAM(bbox)[28], SAM-MED2D[38], SAM-MED3D[39], SAM(points)[28] and SegVol on 4 cases from split test data.", "description": "This figure compares the performance of SegVol against several other state-of-the-art interactive segmentation models, specifically MedSAM, SAM, SAM-MED2D, and SAM-MED3D, on the task of segmenting the aorta and bladder in medical images.  It showcases the ground truth segmentations alongside the results produced by each method, highlighting the differences in accuracy and precision.  The results suggest that SegVol offers superior performance in both aorta and bladder segmentation tasks compared to the other tested methods. The use of a combination of text and bounding box prompts in SegVol is likely a major contributing factor to its improved performance.", "section": "Supplement results for comparative experiments on SAM-like interactive segmentation methods"}, {"figure_path": "105ZuvpdyW/figures/figures_24_1.jpg", "caption": "Figure 15: Visualized gall bladder and left kidney prediction results of MedSAM[29], SAM(bbox)[28], SAM-MED2D[38], SAM-MED3D[39], SAM(points)[28] and SegVol on 4 cases from split test data.", "description": "This figure compares the segmentation results of SegVol with other SAM-like interactive methods on the Gall bladder and Left Kidney.  It shows the ground truth segmentations alongside the results from MedSAM, SAM (using bounding boxes and points), SAM-MED2D, SAM-MED3D, and SegVol (using text and bounding boxes). The figure visually demonstrates the relative performance of each method for segmenting these anatomical structures.", "section": "3.2 Compared with SAM-like Interactive Methods"}, {"figure_path": "105ZuvpdyW/figures/figures_25_1.jpg", "caption": "Figure 1: Overview of SegVol model architecture. SegVol produces precise segmentation of 3D anatomical structures from volumetric inputs with easy user interactions, including point, bounding box, and text prompts. Zoom-out-zoom-in mechanism: SegVol initially produces a rough prediction mask with zoom-out inference, then refines it with zoom-in inference on the identified ROI.", "description": "This figure illustrates the architecture of the SegVol model, which performs 3D medical image segmentation using various types of user prompts (point, bounding box, and text). It highlights the zoom-out-zoom-in mechanism employed for efficient and precise inference. Initially, a rough prediction mask is generated using zoom-out inference, followed by refinement using zoom-in inference on the region of interest (ROI).", "section": "2 Methodology"}, {"figure_path": "105ZuvpdyW/figures/figures_26_1.jpg", "caption": "Figure 2: Violin plots for quantitative comparison experiment results of SegVol and SAM-like interactive methods[28, 38, 39, 29]. The vertical axis represents the Dice score.", "description": "Violin plots showing a comparison of the Dice scores achieved by SegVol and five other SAM-like interactive segmentation methods across various anatomical structures. SegVol demonstrates superior performance in most cases.", "section": "3 Experiments"}, {"figure_path": "105ZuvpdyW/figures/figures_29_1.jpg", "caption": "Figure 18: Visualized liver, spleen, and kidney prediction results of SegVol on 12 cases from MRI set of CHAOS[40, 41, 42]. For unseen MRI modality, SegVol is still able to segment these four organs relatively accurately.", "description": "This figure shows the results of applying the SegVol model to unseen MRI data from the CHAOS dataset.  The model successfully segments liver, spleen, and kidneys, demonstrating its ability to generalize to different imaging modalities.  The comparison between the ground truth segmentations and the SegVol predictions shows the model's accuracy in identifying organ boundaries.", "section": "C Additional Experimental Analysis"}]