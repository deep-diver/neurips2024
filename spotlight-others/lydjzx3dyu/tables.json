[{"figure_path": "lYdjzx3DYu/tables/tables_1_1.jpg", "caption": "Table 1: Prerequisites for each method's working.", "description": "This table summarizes the data and training requirements for various model merging methods.  It indicates whether each method requires training data, validation data, tuning of input labels, or tuning through additional training to achieve its results.  The table highlights the tuning-free nature of the proposed EMR-Merging method.", "section": "1 Introduction"}, {"figure_path": "lYdjzx3DYu/tables/tables_5_1.jpg", "caption": "Table 2: Multi-task performance when merging ViT-B/32 models on eight tasks.", "description": "This table presents the multi-task performance results of various model merging methods on eight image classification tasks.  The methods compared include Individual models (performance of individual models on each task), Traditional MTL (multi-task learning approach), Weight Averaging, Fisher Merging, RegMean, Task Arithmetic, Ties-Merging, AdaMerging, AdaMerging++, and the proposed EMR-MERGING.  The results are shown as average accuracy across the eight tasks (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD).  The table demonstrates the superior performance of EMR-MERGING compared to other existing merging methods.", "section": "4.1 Merging vision models"}, {"figure_path": "lYdjzx3DYu/tables/tables_5_2.jpg", "caption": "Table 2: Multi-task performance when merging ViT-B/32 models on eight tasks.", "description": "This table presents the multi-task performance results achieved by various model merging methods on eight image classification tasks.  The methods compared include traditional MTL (multi-task learning), simple weight averaging, Fisher Merging, RegMean, Task Arithmetic, Ties-Merging, AdaMerging, AdaMerging++, and the proposed EMR-MERGING. The performance of each method is evaluated for each of the eight tasks (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD) and the average accuracy across all eight tasks is reported.  This allows for a direct comparison of the effectiveness of different model merging techniques, showing the advantages and disadvantages of each approach in achieving high accuracy in a multi-task setting.", "section": "4.1 Merging vision models"}, {"figure_path": "lYdjzx3DYu/tables/tables_6_1.jpg", "caption": "Table 4: Task-specific and average performance when merging ViT-B/16 models on 30 tasks.", "description": "This table presents the task-specific and average performance results when merging 30 ViT-B/16 models on various vision tasks.  The table compares the performance of EMR-MERGING against several baseline methods including individual models, weight averaging, RegMean, Task Arithmetic, Ties-Merging, and AdaMerging.  The 30 tasks cover diverse image classification challenges such as MNIST, CIFAR-10, and many more specialized image classification tasks. The results are shown as accuracy percentages for each task and the average accuracy across all 30 tasks. This table helps to evaluate the effectiveness of EMR-MERGING in handling a large number of tasks and models.", "section": "4.1.2 Merging 30 ViTs"}, {"figure_path": "lYdjzx3DYu/tables/tables_7_1.jpg", "caption": "Table 5: Results of merging RoBERTa models on eight datasets from GLUE benchmark.", "description": "This table presents the multi-task performance results of different model merging methods on eight datasets from the GLUE benchmark.  The methods compared include Individual models, Weight Averaging, RegMean [33], Task Arithmetic [30], Ties-Merging [84], and EMR-MERGING (Ours).  The table shows the performance of each method on each of the eight GLUE tasks, providing a comprehensive comparison of the effectiveness of different model merging techniques.", "section": "4.2 Merging language models"}, {"figure_path": "lYdjzx3DYu/tables/tables_7_2.jpg", "caption": "Table 6: Multi-task performance when merging GPT-2 models on seven text classification tasks.", "description": "This table presents the multi-task performance results of several model merging methods, including the proposed EMR-MERGING, when applied to seven text classification tasks using GPT-2 models.  It compares the average accuracy across the seven tasks for each method, showing the performance of EMR-MERGING against baselines such as Weight Averaging, Fisher Merging, RegMean, Task Arithmetic, and Ties-Merging. The \"Individual\" row indicates the average performance of individual, task-specific GPT-2 models, serving as an upper bound for comparison.", "section": "4.2 Merging language models"}, {"figure_path": "lYdjzx3DYu/tables/tables_8_1.jpg", "caption": "Table 7: Results of merging (IA)\u00b3 models on eleven NLP tasks.", "description": "This table presents the results of applying EMR-MERGING and other model merging methods on eleven NLP tasks using (IA)\u00b3 models.  It compares the average accuracy across these tasks for various methods, including individual model performance, traditional multi-task learning (MTL), and other merging techniques.  The table highlights the performance improvement achieved by EMR-MERGING compared to existing methods. The 'Validation' column indicates whether a validation set was used for hyperparameter tuning.", "section": "4.2.3 Merging PEFT models"}, {"figure_path": "lYdjzx3DYu/tables/tables_8_2.jpg", "caption": "Table 8: Results of merging multi-modal BEiT3 models on five vision-language tasks.", "description": "This table presents the results of applying EMR-MERGING and other model merging methods on five vision-language tasks using multi-modal BEiT3 models.  The tasks are COCO-Retrieval, COCO-Captioning, ImageNet-1k Classification, NLVR2, and VQAv2.  Performance is measured using Accuracy, BLEU4, CIDEr, METEOR, and ROUGE-L, depending on the specific task. The table allows comparison of EMR-MERGING against traditional methods like Weight Averaging, Task Arithmetic, and Ties-Merging to demonstrate its effectiveness in multi-modal model merging scenarios.", "section": "4.3 Merging multi-modal models"}, {"figure_path": "lYdjzx3DYu/tables/tables_9_1.jpg", "caption": "Table 2: Multi-task performance when merging ViT-B/32 models on eight tasks.", "description": "This table presents the multi-task performance results achieved by various model merging methods on eight image classification tasks.  The methods compared include Individual models (using a single model per task), Traditional Multi-Task Learning (MTL), Weight Averaging, Fisher Merging, RegMean, Task Arithmetic, Ties-Merging, AdaMerging, AdaMerging++, and the proposed EMR-MERGING. The performance is measured by the average accuracy across the eight tasks.  This demonstrates the comparative performance of different merging techniques, highlighting the effectiveness of EMR-MERGING.", "section": "4.1 Merging vision models"}, {"figure_path": "lYdjzx3DYu/tables/tables_9_2.jpg", "caption": "Table 10: Ablation on the Masking and Rescaling procedures of EMR-MERGING.", "description": "This table presents the ablation study results on the Masking and Rescaling procedures within the EMR-MERGING model.  It shows the average accuracy across eight image classification datasets (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD) when only the Electing procedure is used, when Electing and Masking are combined, when Electing and Rescaling are combined, and when all three procedures (Electing, Masking, and Rescaling) are used together. The improvement in average accuracy is shown in brackets for each combination compared to the baseline using only the Electing procedure. This demonstrates the importance of each component in achieving the high performance of EMR-MERGING.", "section": "4.5 Ablation Study"}, {"figure_path": "lYdjzx3DYu/tables/tables_16_1.jpg", "caption": "Table 2: Multi-task performance when merging ViT-B/32 models on eight tasks.", "description": "This table presents a comparison of the multi-task performance of different model merging methods on eight image classification tasks.  The methods compared include: Individual (using individual models for each task), Traditional MTL (multi-task learning), Weight Averaging, Fisher Merging, RegMean, Task Arithmetic, Ties-Merging, AdaMerging, AdaMerging++, and the proposed EMR-MERGING. The performance is measured by the average accuracy across the eight tasks (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD).  This allows for a quantitative assessment of how well each merging method combines multiple models into a single model that performs well across multiple tasks compared to training a single model on all tasks simultaneously (MTL).", "section": "4.1 Merging vision models"}, {"figure_path": "lYdjzx3DYu/tables/tables_17_1.jpg", "caption": "Table 12: Multi-task performance when merging ViT-B/32 models on 9 vision tasks (ImageNet-1K added).", "description": "This table presents the multi-task performance results of different model merging methods on nine image classification datasets.  The methods compared include Individual models (using a single model per task), Weight Averaging, Task Arithmetic [30], Ties-Merging [84], and the proposed EMR-MERGING method. The datasets used are SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD, and ImageNet-1K. The table shows the accuracy achieved by each method on each dataset, along with the average accuracy across all nine datasets.  The results demonstrate the superior performance of EMR-MERGING in comparison to the existing methods.", "section": "4.1 Merging vision models"}, {"figure_path": "lYdjzx3DYu/tables/tables_19_1.jpg", "caption": "Table 13: Performance of RegMean and Task Arithmetic when pre-processed using DARE [90].", "description": "This table presents the performance of RegMean and Task Arithmetic methods on the GLUE benchmark when their input task vectors are pre-processed using the DARE method.  DARE is a pre-processing technique that randomly drops a percentage of elements in the task vector before merging, aiming to reduce interference. The table shows how the performance of the two methods changes with varying percentages (10%, 30%, 50%, 70%, 90%) of elements dropped by DARE.  The results are compared against the performance of the original RegMean and Task Arithmetic methods without DARE pre-processing and the performance of an individual model for each task (Individual). This table highlights the impact of DARE pre-processing on the performance of these two model merging techniques.", "section": "4.2.1 Merging fully finetuned RoBERTa models"}, {"figure_path": "lYdjzx3DYu/tables/tables_20_1.jpg", "caption": "Table 2: Multi-task performance when merging ViT-B/32 models on eight tasks.", "description": "This table presents the multi-task performance results of various model merging methods on eight image classification tasks using Vision Transformer (ViT)-B/32 models.  The methods compared include individual models, traditional multi-task learning (MTL), weight averaging, Fisher merging, RegMean, Task Arithmetic, Ties-Merging, AdaMerging, AdaMerging++, and the proposed EMR-MERGING. The performance metric is average accuracy across the eight tasks.  The table allows for a comparison of the proposed method against existing techniques and establishes its effectiveness in improving multi-task capabilities without requiring additional tuning or data.", "section": "4.1 Merging vision models"}, {"figure_path": "lYdjzx3DYu/tables/tables_21_1.jpg", "caption": "Table 2: Multi-task performance when merging ViT-B/32 models on eight tasks.", "description": "This table presents the multi-task performance results of various model merging methods on eight image classification tasks.  The methods compared include individual model performance, traditional multi-task learning (MTL), simple averaging of weights, Fisher Merging, RegMean, Task Arithmetic, Ties-Merging, AdaMerging, AdaMerging++, and the proposed EMR-MERGING.  Each method's accuracy is reported for each of the eight tasks (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD), along with an average accuracy across all eight tasks.  This allows for a comparison of the effectiveness of different model merging techniques in achieving multi-task capabilities.", "section": "4.1 Merging vision models"}, {"figure_path": "lYdjzx3DYu/tables/tables_21_2.jpg", "caption": "Table 2: Multi-task performance when merging ViT-B/32 models on eight tasks.", "description": "This table presents the multi-task performance results achieved using various model merging methods on eight image classification tasks.  The methods compared include Individual models (performance of each model individually), Traditional MTL (multi-task learning), Weight Averaging, Fisher Merging, RegMean, Task Arithmetic, Ties-Merging, AdaMerging, AdaMerging++, and EMR-MERGING (the proposed method).  The performance is measured by average accuracy across the eight tasks (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, DTD).  The table demonstrates the relative performance of EMR-MERGING compared to existing state-of-the-art model merging techniques.", "section": "4.1 Merging vision models"}]