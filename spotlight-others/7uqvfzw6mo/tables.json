[{"figure_path": "7uqVfZW6Mo/tables/tables_7_1.jpg", "caption": "Table 1: Experimental results on the semantic correspondence task. The best results are in bold font and the runner-up is underlined.", "description": "This table presents the performance comparison of different methods on the semantic correspondence task, including state-of-the-art (SOTA) methods, baseline methods using conventional activation selection approaches, and the proposed methods.  The results are shown using two metrics: PCK@0.1img\u2191 and PCK@0.1bbox\u2191.  The proposed methods (Ours-v1.5, Ours-XL, Ours-XL-t) consistently outperform the baselines and achieve competitive or superior performance compared to the SOTA methods, highlighting the effectiveness of their proposed feature selection approach.", "section": "6.1 Empirical Results on Semantic Correspondence"}, {"figure_path": "7uqVfZW6Mo/tables/tables_8_1.jpg", "caption": "Table 2: Experimental results on semantic segmentation and its altered version with scarce labeled data, evaluated using mIoU\u2191 metric. The best results are in bold font and the runner-up is underlined.", "description": "This table presents the experimental results for semantic segmentation and its label-scarce version.  It compares the performance of the proposed method (Ours-v1.5, Ours-XL, Ours-XL-t) against several state-of-the-art (SOTA) methods and two baselines (Legacy-v1.5, Legacy-XL) across three different datasets: ADE20K, Cityscapes (standard setting), and Horse-21 (label-scarce setting). The metric used is mean Intersection over Union (mIoU), which measures the average overlap between predicted and ground truth segmentations.  The best performing method for each setting is highlighted in bold.", "section": "6.2 Empirical Results on Semantic Segmentation"}, {"figure_path": "7uqVfZW6Mo/tables/tables_24_1.jpg", "caption": "Table 3: Examination of generalizability across different scenes. Generic Solution refers to our standard feature selection solution for SDXL, while Specific Solution refers to the outcome of considering only a simple scene for the quantitative comparison. The experiment is conducted on the label-scarce segmentation task, where the Horse-21 subset is used for simple scenes and the Bedroom-28 subset is used for complex scenes. We mark the better results as bold font.", "description": "This table compares the performance of two feature selection methods on a label-scarce segmentation task using two different subsets of images (simple and complex scenes).  The Generic Solution uses features selected using a general approach, while the Specific Solution uses features selected based only on the simple scenes subset. The table demonstrates the impact of the feature selection method on the generalizability of the model's performance across different scene complexities. The results show that the Generic Solution generalizes better across both simple and complex scenes compared to the Specific Solution, highlighting the importance of considering diverse image types during the feature selection process.", "section": "D Additional Experimental Results"}, {"figure_path": "7uqVfZW6Mo/tables/tables_25_1.jpg", "caption": "Table 4: Quantitative comparison results of SDXL and Playground v2. This table shows the results from the lowest resolution. Activation ID indicates the location of each activation in the diffusion U-Net. The best results are in bold font and the runner-up is underlined.", "description": "This table presents a quantitative comparison of the discriminative performance of different activations from SDXL and Playground v2 diffusion models. The activations are evaluated at the lowest resolution of the U-Net. Each row represents an activation, identified by its ID, with its performance scores (Simple and Complex scenes). The best and second-best performing activations are highlighted in bold and underlined respectively.", "section": "D.2 Quantitative Comparison Results"}, {"figure_path": "7uqVfZW6Mo/tables/tables_26_1.jpg", "caption": "Table 4: Quantitative comparison results of SDXL and Playground v2. This table shows the results from the lowest resolution. Activation ID indicates the location of each activation in the diffusion U-Net. The best results are in bold font and the runner-up is underlined.", "description": "This table presents a quantitative comparison of different activation features extracted from two diffusion models, SDXL and Playground v2, at their lowest resolution.  Each row represents a different activation feature identified by its ID. The table shows the performance (likely a metric like PCK@0.1img) of each activation on two types of scenes: simple and complex.  The best and second-best performing activations are highlighted.", "section": "D.2 Quantitative Comparison Results"}, {"figure_path": "7uqVfZW6Mo/tables/tables_27_1.jpg", "caption": "Table 1: Experimental results on the semantic correspondence task. The best results are in bold font and the runner-up is underlined.", "description": "This table presents a comparison of different methods for the semantic correspondence task.  It shows the performance of various methods, including state-of-the-art (SOTA) approaches and baseline methods (using only inter-module activations), as well as the proposed method (Ours) applied to two different diffusion models (SDv1.5 and SDXL).  The performance is measured using two metrics: PCK@0.1img and PCK@0.1bbox. The table highlights the superior performance achieved by the proposed method, demonstrating the effectiveness of the proposed feature selection approach.", "section": "6.1 Empirical Results on Semantic Correspondence"}]