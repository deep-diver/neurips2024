{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022", "reason": "This paper introduces the Chain-of-Thought prompting method, which is a foundational technique for improving LLM reasoning and directly related to the proposed Vision-Augmented Prompting (VAP) framework."}, {"fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "publication_date": "2023", "reason": "This paper builds upon Chain-of-Thought prompting by introducing self-consistency, another crucial technique enhancing LLM reasoning capabilities, which VAP also draws inspiration from."}, {"fullname_first_author": "Shunyu Yao", "paper_title": "Tree of thoughts: Deliberate problem solving with large language models", "publication_date": "2023", "reason": "This paper presents the Tree of Thoughts method, an advanced LLM reasoning framework that explores multiple reasoning paths, providing a foundation for VAP's iterative refinement process."}, {"fullname_first_author": "Alan Baddeley", "paper_title": "Working memory", "publication_date": "1992", "reason": "This seminal paper introduces the concept of the visual-spatial sketchpad within the working memory, a core cognitive model that underpins VAP's dual-modality approach."}, {"fullname_first_author": "Mary Hegarty", "paper_title": "Revising the visualizer-verbalizer dimension: Evidence for two types of visualizers", "publication_date": "2002", "reason": "This paper provides critical insights into the interaction between verbal and visual-spatial information processing, the foundational cognitive processes that are analogous to VAP's dual-modality framework."}]}