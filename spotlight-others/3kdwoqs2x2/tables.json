[{"figure_path": "3kDWoqs2X2/tables/tables_2_1.jpg", "caption": "Algorithm 1 EP (\u03b2\u2081=1, ninner=1), power EP (Bi\u22601, ninner=1), and their double-loop variants (ninner>1)", "description": "This algorithm presents a unified view of Expectation Propagation (EP), power EP, and their double-loop variants.  It highlights the iterative process of inner and outer updates to optimize a variational objective. The inner updates involve moment-matching, which can be estimated stochastically (as shown in the caption's note), potentially leading to instability and bias. The algorithm takes as input the exponential family of distributions (F), the natural parameter (\u03b7\u2080), site potentials ({p\u1d62}\u1d62), likelihood terms ({l\u1d62(z)}\u1d62), site parameters ({\u03bb\u1d62}\u1d62), number of inner iterations (ninner), and damping parameter (\u03b1). It then iteratively updates \u03b8 and \u03bb\u1d62 until convergence, finally returning the optimized site parameters.", "section": "Background"}, {"figure_path": "3kDWoqs2X2/tables/tables_5_1.jpg", "caption": "Algorithm 2 EP-\u03b7 and EP-\u03bc (differences with Algorithm 1 are highlighted in green)", "description": "This algorithm presents the steps for the EP-\u03b7 and EP-\u03bc algorithms.  It's a modified version of Algorithm 1, showing the key differences in green. The algorithm iteratively updates site parameters (\u03bbi) until convergence, incorporating either Equation (11) or (13) for EP-\u03b7 or EP-\u03bc respectively.  The core updates are parallel, and nested within an outer update for \u03b8.", "section": "3 Fearlessly stochastic EP algorithms"}]