[{"figure_path": "jM9atrvUii/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates the structure kernel component of the Kermut model.  The model uses an inverse folding model to predict the probability distribution of amino acids at each site in the reference protein, given its structure. The structure kernel then calculates the covariance between pairs of variants based on three factors: 1) The similarity of their local structural environments (assessed using the Hellinger distance between amino acid distributions), 2) the similarity of their mutation probabilities, and 3) the physical proximity of the mutated sites. The figure shows four example variants (x1-x4), each compared against a reference protein (xWT), highlighting how the kernel would compute high or low covariances based on these three factors.", "section": "3.3 Kermut"}, {"figure_path": "jM9atrvUii/figures/figures_7_1.jpg", "caption": "Figure 2: Distribution of predictive variances for datasets with double mutants, grouped by domain. The three first elements correspond to the three split-schemes from ProteinGym. The third and fourth correspond to training on both single and double mutants, and testing on each, respectively. For the last column, we train on single and test on double mutants, corresponding to an extrapolation setting.", "description": "This figure shows the distribution of predictive variances from the model for datasets containing double mutations.  It breaks down the variance based on different training and testing scenarios (domains). The first three represent standard ProteinGym split schemes (random, modulo, contiguous).  The next two show training on both single and double mutants then testing on single mutants and double mutants separately. The final domain shows the challenging extrapolation scenario of training only on single mutants but testing on double mutants.", "section": "Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_9_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates the structure kernel of Kermut. The kernel uses an inverse folding model to compute structure-conditioned amino acid distributions for each site in the reference protein. It then calculates the covariance between two variants based on the similarity of their local environments, the similarity of their mutation probabilities, and their physical distance. The figure shows example covariances between variant x\u2081 and variants x\u2082, x\u2083, x\u2084, illustrating how the kernel captures relationships between mutations based on structural context and mutation similarity.", "section": "3 Methods"}, {"figure_path": "jM9atrvUii/figures/figures_9_2.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates the structure kernel used in the Kermut model.  It shows how the kernel considers three factors when assessing the similarity between two protein variants: (1) The similarity of the local structural environments of the mutated sites, (2) the similarity of the mutation probabilities at those sites (as predicted by an inverse folding model), and (3) the physical distance between the mutated sites.  The examples provided show how the kernel generates higher covariances for variants with similar local environments and mutation probabilities, and that are physically close together.", "section": "3 Methods"}, {"figure_path": "jM9atrvUii/figures/figures_25_1.jpg", "caption": "Figure I.1: Histogram over normalized assay values for 51/69 datasets with multi-mutants. All datasets with more than 7500 variants are ignored. The histograms are colored according to the number of mutations per variant. The assay distribution belong to different modalities depending on the number of mutations present, where double mutations commonly lead to a loss of fitness.", "description": "This figure shows the distribution of normalized assay values for datasets containing multiple mutations.  Data from 51 datasets (out of 69 with multiple mutations, excluding one dataset with excessively many mutations) are shown, with each dataset containing fewer than 7500 variants.  The histograms are separated by the number of mutations in each variant (1 or 2 mutations). The figure illustrates how the distribution of assay values varies depending on the number of mutations, with double mutations tending to correlate with lower fitness.", "section": "Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_27_1.jpg", "caption": "Figure 2: Distribution of predictive variances for datasets with double mutants, grouped by domain. The three first elements correspond to the three split-schemes from ProteinGym. The third and fourth correspond to training on both single and double mutants, and testing on each, respectively. For the last column, we train on single and test on double mutants, corresponding to an extrapolation setting.", "description": "This figure shows the distribution of predictive variances for datasets containing double mutants.  The x-axis represents different domains categorized by the type of mutation testing and training data used: single-mutant training and testing, training on both single and double mutants and testing on both, and extrapolation where training used only single mutants while testing used double mutants. The y-axis shows the predictive variance, a measure of uncertainty in the model's predictions. Each boxplot summarizes the distribution of predictive variances across multiple datasets within each domain, allowing for a visual comparison of uncertainty levels across different prediction scenarios.", "section": "Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_27_2.jpg", "caption": "Figure 2: Distribution of predictive variances for datasets with double mutants, grouped by domain. The three first elements correspond to the three split-schemes from ProteinGym. The third and fourth correspond to training on both single and double mutants, and testing on each, respectively. For the last column, we train on single and test on double mutants, corresponding to an extrapolation setting.", "description": "This figure shows the distribution of predictive variances for datasets that include double mutants, categorized by the type of mutation domain.  The three initial columns show the distributions for the three ProteinGym cross-validation schemes (random, modulo, contiguous).  The fourth and fifth columns compare the distributions when training occurs on both single and double mutants, with testing on only single, and only double mutants respectively. The final column shows the distribution of predictive variances when training only occurs on single mutants while testing is performed on double mutants, representing an extrapolation domain.", "section": "4.2 Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_27_3.jpg", "caption": "Figure 2: Distribution of predictive variances for datasets with double mutants, grouped by domain. The three first elements correspond to the three split-schemes from ProteinGym. The third and fourth correspond to training on both single and double mutants, and testing on each, respectively. For the last column, we train on single and test on double mutants, corresponding to an extrapolation setting.", "description": "This figure shows the distribution of predictive variances for datasets that include double mutants. The x-axis represents the different domains used for training and testing the model, while the y-axis represents the predictive variance. The three first domains correspond to the three split schemes of the ProteinGym benchmark (random, modulo, contiguous), while the other three domains show the predictive variance when training and testing on both single and double mutants, and extrapolating from single mutants to double mutants. This shows that when the training data is closer to the test data, the uncertainties are smaller. This is reflected in the low uncertainty in the first three domains where only single mutants are used.", "section": "Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_28_1.jpg", "caption": "Figure K.1: Predicted means (\u00b12\u03c3) vs. true values. Columns correspond to CV-schemes. Rows correspond to test folds. Perfect prediction corresponds to dashed diagonal line (x = y).", "description": "This figure displays the predicted values plotted against the true values for the BLAT_ECOLX_Stiffler_2015 dataset.  The plot is separated into columns representing different cross-validation schemes (Random, Modulo, Contiguous) and rows showing the results for each test fold (five folds total).  The dashed diagonal line indicates a perfect prediction; points closer to this line show better predictive accuracy. The error bars represent \u00b12 standard deviations, providing a visual representation of model uncertainty. The distribution and spread of points around the diagonal line visually illustrate the calibration of the model's uncertainty estimates for this specific dataset across various splitting schemes. ", "section": "K Predicted vs. true values for calibration datasets"}, {"figure_path": "jM9atrvUii/figures/figures_29_1.jpg", "caption": "Figure 2: Distribution of predictive variances for datasets with double mutants, grouped by domain. The three first elements correspond to the three split-schemes from ProteinGym. The third and fourth correspond to training on both single and double mutants, and testing on each, respectively. For the last column, we train on single and test on double mutants, corresponding to an extrapolation setting.", "description": "This figure shows the distribution of predictive variances for datasets containing double mutants.  It compares the variance across six different scenarios (domains) which vary how the model is trained (single vs. double mutants) and tested (single vs. double mutants). The first three domains represent standard ProteinGym split schemes. The final domain represents an extrapolation setting.", "section": "4.2 Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_30_1.jpg", "caption": "Figure K.1: Predicted means (\u00b12\u03c3) vs. true values. Columns correspond to CV-schemes. Rows correspond to test folds. Perfect prediction corresponds to dashed diagonal line (x = y).", "description": "This figure shows the predicted means with their uncertainty intervals (2\u03c3) plotted against their true values for the BLAT_ECOLX_Stiffler_2015 dataset. It compares the model's predictions across five different cross-validation folds (rows) and three different schemes (columns: random, modulo, and contiguous). The dashed diagonal line represents perfect prediction.  The extent to which the points deviate from this line indicates the accuracy of the model's predictions.", "section": "K Predicted vs. true values for calibration datasets"}, {"figure_path": "jM9atrvUii/figures/figures_31_1.jpg", "caption": "Figure 2: Distribution of predictive variances for datasets with double mutants, grouped by domain. The three first elements correspond to the three split-schemes from ProteinGym. The third and fourth correspond to training on both single and double mutants, and testing on each, respectively. For the last column, we train on single and test on double mutants, corresponding to an extrapolation setting.", "description": "This figure shows the distribution of predictive variances for datasets containing double mutants.  The x-axis represents the predictive variance, and the y-axis shows the different domains. The first three domains represent the three split schemes from the ProteinGym benchmark, which are examples of interpolation. The fourth and fifth domains show the distributions when training on both single and double mutants and testing separately on each. The last domain shows the distribution when training only on single mutants but testing on double mutants (extrapolation). The figure demonstrates how uncertainties vary across different mutation domains and experimental settings.", "section": "Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_32_1.jpg", "caption": "Figure 2: Distribution of predictive variances for datasets with double mutants, grouped by domain. The three first elements correspond to the three split-schemes from ProteinGym. The third and fourth correspond to training on both single and double mutants, and testing on each, respectively. For the last column, we train on single and test on double mutants, corresponding to an extrapolation setting.", "description": "The figure shows the distribution of predictive variances in six different mutation domains. The first three domains are the standard ProteinGym splits (random, modulo, contiguous). The next two domains train on both single and double mutations then test on single or double mutations, respectively. The final domain trains on single mutations only then tests on double mutations.", "section": "Uncertainty quantification per mutation domain"}, {"figure_path": "jM9atrvUii/figures/figures_32_2.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates the structure kernel of Kermut, a Gaussian process regression model for predicting protein variant effects. The kernel leverages signals from pretrained sequence and structure models to capture mutation similarity. The structure kernel uses an inverse folding model to predict amino acid distributions at various sites in the protein, conditioned on the local structural environments. The figure demonstrates that the kernel assigns high covariances between pairs of variants with similar local environments, similar mutation probabilities, and close physical proximity of the mutated sites.  Examples of covariance between a reference variant and three other variants are visually presented.", "section": "3 Methods"}, {"figure_path": "jM9atrvUii/figures/figures_33_1.jpg", "caption": "Figure K.1: Predicted means (\u00b12\u03c3) vs. true values. Columns correspond to CV-schemes. Rows correspond to test folds. Perfect prediction corresponds to dashed diagonal line (x = y).", "description": "This figure displays the predicted versus true values for the BLAT_ECOLX_Stiffler_2015 dataset.  The x-axis represents the true values and the y-axis represents the predicted means, with error bars indicating \u00b12 standard deviations.  The data is broken down by five cross-validation folds (rows) and three schemes (columns: Random, Modulo, Contiguous). The dashed diagonal line shows the ideal prediction where predicted values perfectly match true values. Deviations from this line illustrate the model's predictive accuracy for each fold and scheme.", "section": "K Predicted vs. true values for calibration datasets"}, {"figure_path": "jM9atrvUii/figures/figures_34_1.jpg", "caption": "Figure K.1: Predicted means (\u00b12\u03c3) vs. true values. Columns correspond to CV-schemes. Rows correspond to test folds. Perfect prediction corresponds to dashed diagonal line (x = y).", "description": "This figure displays the predicted means with error bars (\u00b12\u03c3) plotted against the true values for the BLAT_ECOLX_Stiffler_2015 dataset.  It's a visual representation of the model's performance across five different cross-validation folds (rows) and three different splitting schemes: random, modulo, and contiguous (columns). The dashed diagonal line represents perfect prediction; deviations from this line indicate prediction errors. The error bars show the uncertainty associated with each prediction.", "section": "K Predicted vs. true values for calibration datasets"}, {"figure_path": "jM9atrvUii/figures/figures_35_1.jpg", "caption": "Figure K.1: Predicted means (\u00b12\u03c3) vs. true values. Columns correspond to CV-schemes. Rows correspond to test folds. Perfect prediction corresponds to dashed diagonal line (x = y).", "description": "This figure displays the predicted means with their uncertainty intervals (\u00b12\u03c3) plotted against the true values for the BLAT_ECOLX_Stiffler_2015 dataset.  It shows the model's performance across five different test folds and three cross-validation schemes (Random, Modulo, Contiguous). The dashed diagonal line represents perfect prediction, where the predicted and true values would align. Deviations from this line indicate prediction errors. This visualization helps assess the model's calibration (how well the predicted uncertainty reflects the actual error) and overall prediction accuracy for this specific dataset.", "section": "K Predicted vs. true values for calibration datasets"}, {"figure_path": "jM9atrvUii/figures/figures_36_1.jpg", "caption": "Figure K.1: Predicted means (\u00b12\u03c3) vs. true values. Columns correspond to CV-schemes. Rows correspond to test folds. Perfect prediction corresponds to dashed diagonal line (x = y).", "description": "This figure displays the predicted versus true values for the BLAT_ECOLX_Stiffler_2015 dataset.  It shows the results of five-fold cross-validation, with each row representing a different test fold and each column representing a different cross-validation scheme (Random, Modulo, Contiguous). The dashed diagonal line represents perfect prediction. The error bars represent the \u00b12\u03c3 confidence intervals of the predictions.", "section": "K Predicted vs. true values for calibration datasets"}, {"figure_path": "jM9atrvUii/figures/figures_38_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates how Kermut's structure kernel works. The kernel uses an inverse folding model to predict the probability distributions of amino acids at each site in the protein, given the protein's structure.  The model determines the covariance between two protein variants based on three factors: the similarity of their local structural environments, the similarity of their mutation probabilities, and the physical distance between the mutated sites.  The examples in the figure show how these factors combine to produce the covariance.", "section": "3 Methods"}, {"figure_path": "jM9atrvUii/figures/figures_39_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates the structure kernel used in the Kermut model. The kernel leverages information from inverse folding models to capture relationships between the amino acid distributions at different sites in a protein.  High covariances are observed between pairs of mutations where local environments are similar, mutation probabilities are similar, and the sites are physically close together.  The example shown highlights this concept using four variant sites (x1, x2, x3, x4).", "section": "3.3 Kermut"}, {"figure_path": "jM9atrvUii/figures/figures_40_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates how Kermut's structure kernel works. It uses an inverse folding model to predict amino acid distributions at each site in a protein, given the protein's structure.  The kernel then compares these distributions to assess similarity between two protein variants.  The figure shows that the kernel gives high covariance (similarity) between variants when the local environments of the mutated sites are similar, when the probabilities of the mutations are similar, and when the mutated sites are physically close together.  Three example pairs of variants are given to show how covariances are determined.", "section": "3 Methods"}, {"figure_path": "jM9atrvUii/figures/figures_41_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates the structure kernel of Kermut, a Gaussian process regression model.  The kernel leverages signals from pretrained sequence and structure models to model mutation similarity. The illustration shows how the structure kernel computes covariances between different variants by considering the similarity of their local structural environments, mutation probabilities, and physical distances between mutated sites. The examples provided visually depict how the kernel would produce high or low covariances depending on these three factors.", "section": "3 Methods"}, {"figure_path": "jM9atrvUii/figures/figures_42_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x\u2082,\u2083,\u2084 are shown.", "description": "This figure illustrates the structure kernel of Kermut, a Gaussian process regression model for protein variant effect prediction. The structure kernel leverages information from pretrained sequence and structure models to capture the effects of mutations.  It combines signals from three sources: 1) the Hellinger kernel (kh) measures the similarity of amino acid distributions at different sites, conditioned on their local structure; 2) the mutation probability kernel (kp) assesses how likely a specific mutation is at a given site; 3) the Euclidean distance kernel (kd) considers the physical proximity of mutated sites. The figure depicts example covariances showing that the kernel assigns high covariances between variants if their local environments are similar, if the mutation probabilities are similar, and if the mutated sites are physically close.", "section": "3.3 Kermut"}, {"figure_path": "jM9atrvUii/figures/figures_43_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x2,3,4 are shown.", "description": "This figure illustrates the structure kernel of the Kermut model. The structure kernel leverages an inverse folding model to compute structure-conditioned amino acid distributions for all sites in a reference protein.  The kernel calculates high covariances between two variants if their local structural environments are similar, their mutation probabilities are similar, and the mutated sites are physically close. The figure includes schematic examples showing how the kernel evaluates covariances between different variant pairs.", "section": "3 Methods"}, {"figure_path": "jM9atrvUii/figures/figures_44_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x\u2082,\u2083,\u2084 are shown.", "description": "This figure illustrates the structure kernel of Kermut, which models mutation similarity based on the local structural environments of mutated sites.  It uses an inverse folding model to predict amino acid distributions for each site, conditioned on its local environment. The kernel assigns high covariances between two variants if their local environments, mutation probabilities, and the distances between mutated sites are similar. Three example pairs of variants (x\u2081 with x\u2082, x\u2083, x\u2084) are shown to illustrate different levels of covariance (high or low) based on these factors.", "section": "3.3 Kermut"}, {"figure_path": "jM9atrvUii/figures/figures_45_1.jpg", "caption": "Figure 1: Overview of Kermut's structure kernel. Using an inverse folding model, structure-conditioned amino acid distributions are computed for all sites in the reference protein. The structure kernel yields high covariances between two variants if the local environments are similar, if the mutation probabilities are similar, and if the mutates sites are physically close. Constructed examples of expected covariances between variant x\u2081 and x\u2082,\u2083,\u2084 are shown.", "description": "This figure illustrates the structure kernel of the Kermut model, which is a crucial component for capturing mutation similarity based on the local structural environment of residues in a protein.  It uses an inverse folding model to calculate structure-conditioned amino acid distributions for each site. The kernel assigns high covariances between two variants if their local environments are similar, their mutation probabilities are similar, and the mutated sites are physically close. The examples shown depict the expected covariances between a reference variant and three other variants, illustrating how the kernel assesses similarity based on these three factors.", "section": "3.3 Kermut"}]