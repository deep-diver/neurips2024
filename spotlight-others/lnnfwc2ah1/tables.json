[{"figure_path": "LnNfwc2Ah1/tables/tables_1_1.jpg", "caption": "Table 1: Summary of our results for PQ learning and tolerant TDS learning. Except for the first row, all results are for the agnostic noise model.", "description": "This table summarizes the results of the paper on PQ learning and tolerant TDS learning algorithms.  It shows the runtime complexities for several concept classes (halfspaces, intersections of halfspaces, decision trees, and depth-l formulas) under different training distributions (Gaussian and uniform). The first row represents the realizable case, while the rest consider the agnostic noise model, where there is uncertainty in the labels.  The PQ runtime column indicates the efficiency of the proposed PQ learning algorithms, while TDS runtime shows the efficiency of the tolerant TDS learning algorithms.  Dimensionality (d), error rate (\u03b5), size (s) and depth (l) influence the runtime. ", "section": "1.1 Our results"}, {"figure_path": "LnNfwc2Ah1/tables/tables_21_1.jpg", "caption": "Table 1: Summary of our results for PQ learning and tolerant TDS learning. Except for the first row, all results are for the agnostic noise model.", "description": "This table summarizes the runtime and error guarantees achieved by the proposed algorithms for both PQ learning and tolerant TDS learning, under different concept classes (halfspaces, intersections of halfspaces, decision trees, and formulas) and training distributions (Gaussian, uniform).  It shows the computational efficiency in terms of runtime and the tolerance levels to distribution shifts and agnostic noise.", "section": "1.1 Our results"}]