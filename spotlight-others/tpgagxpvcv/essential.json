{"importance": "This paper is important because it introduces **Any2Graph**, a novel framework for end-to-end supervised graph prediction, addressing the challenges of handling graphs of arbitrary size and node ordering.  It presents **a new Optimal Transport-based loss function** that is both permutation-invariant and differentiable. This advances the field by offering a more versatile and efficient approach to graph prediction tasks across various domains. This work opens avenues for future research in developing more efficient and accurate graph prediction models, particularly in areas like drug discovery and computer vision. The synthetic dataset created also offers a valuable benchmark for comparing SGP methods.", "summary": "Any2Graph: a novel deep learning framework using an Optimal Transport loss for accurate and efficient supervised graph prediction.", "takeaways": ["Any2Graph, a new framework for end-to-end supervised graph prediction.", "A novel Optimal Transport loss function (PMFGW) that is permutation-invariant and differentiable.", "Superior performance on various real-world tasks and a challenging synthetic dataset (Coloring)."], "tldr": "Supervised graph prediction (SGP) is challenging due to the complex output space, the absence of suitable loss functions, and the arbitrary size and node ordering of graphs. Existing methods often involve expensive decoding steps or specific assumptions about the input or output data.  Many approaches are not fully end-to-end, employing multiple steps or heuristic solutions. These limitations hinder the efficiency and generalizability of SGP models.\nThis paper introduces Any2Graph, a novel framework addressing these challenges. It employs a novel Optimal Transport loss, the Partially Masked Fused Gromov-Wasserstein (PMFGW), which is permutation-invariant and fully differentiable.  Any2Graph also demonstrates versatility by handling diverse input modalities and outperforming competitors on various datasets, including a novel synthetic dataset (Coloring). The size-agnostic nature of PMFGW further enhances the framework's flexibility and efficiency.", "affiliation": "LTCI & CMAP, T\u00e9l\u00e9com paris, IP Paris", "categories": {"main_category": "Machine Learning", "sub_category": "Deep Learning"}, "podcast_path": "tPgagXpvcV/podcast.wav"}