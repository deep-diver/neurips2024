[{"figure_path": "JvQnJWIj6m/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with prior work. We perform linear evaluation, fine-tuning, COCO detection/segmentation, and ADE20K semantic segmentation on pre-trained ViT-B/16 models. We report linprob, fine-tune, Apbox, Apmask, and mIoU to evaluate the quality of pre-trained representations. The best results are indicated in bold.", "description": "This table compares the performance of C-JEPA with other state-of-the-art self-supervised learning methods on various downstream tasks, including image classification, object detection, instance segmentation, and semantic segmentation.  The results are presented for the ViT-B/16 model architecture, with metrics such as linear probing accuracy, fine-tuning accuracy, average precision for bounding boxes (APbox), average precision for masks (Apmask), and mean Intersection over Union (mIoU) used to evaluate performance.", "section": "4.2 Experimental comparisons"}, {"figure_path": "JvQnJWIj6m/tables/tables_6_2.jpg", "caption": "Table 2: Scaling up to Large Models. We perform linear evaluation, fine-tuning, video object segmentation, and low-level tasks on pre-trained ViT-L/16 models. We report linprob, fine-tune, (J&F)m, Clevr/Count and Clevr/Dist metrics to evaluate the quality of pre-trained representations. The best results are indicated in bold.", "description": "This table presents the results of experiments conducted using larger ViT-L/16 models.  It shows performance metrics for linear probing, fine-tuning, video object segmentation, and low-level tasks (Clevr/Count and Clevr/Dist).  The metrics are used to evaluate the quality of the visual representations learned by the model.  The best performance for each metric is shown in bold.", "section": "4.2 Experimental comparisons"}, {"figure_path": "JvQnJWIj6m/tables/tables_7_1.jpg", "caption": "Table 3: Ablation studies on component analysis for faster convergence. We perform ablation studies on Variance/Covariance and Invariance modules in VICReg using ViT-B/16 model. The best results are indicated in bold.", "description": "This table presents the ablation study results on the effects of Variance/Covariance and Invariance modules from VICReg on the C-JEPA model's performance.  It shows the linear probing, fine-tuning, and J&F metrics (for video object segmentation) for different configurations of these modules, highlighting the impact of each component on the overall performance. The best results for each metric are bolded.", "section": "4.3 Experimental analysis"}, {"figure_path": "JvQnJWIj6m/tables/tables_7_2.jpg", "caption": "Table 4: Ablation studies on component analysis for better convergence. We perform ablation studies on Variance/Covariance and Invariance modules in VICReg using ViT-B/16 model. The best results are indicated in bold.", "description": "This table presents the results of ablation studies conducted to analyze the impact of different components of the VICReg regularization strategy on the convergence and performance of the C-JEPA model.  It shows the effects of including or excluding Variance/Covariance and Invariance terms, with and without using EMA for collapse, on various metrics like linear probing, fine-tuning, and (J&F)_m. The use of all three terms (Variance, Covariance, and Invariance)  yields the best results, suggesting their combined importance for optimal performance.", "section": "4.3 Experimental analysis"}, {"figure_path": "JvQnJWIj6m/tables/tables_16_1.jpg", "caption": "Table 9: ImageNet-1K image classification. We perform a linear evaluation on pre-trained ViT-T/16 and ViT-S/16 models for image classification on ImageNet-1K benchmark. We report the Top-1 accuracies using knn, linprob and fine-tune settings to evaluate the quality of pre-trained representations. The best results are indicated in bold.", "description": "This table presents the results of image classification experiments on the ImageNet-1K dataset using pre-trained Vision Transformer models (ViT-T/16 and ViT-S/16).  The performance is evaluated using three different approaches: k-nearest neighbors (knn), linear probing (linprob), and fine-tuning.  The table shows the top-1 accuracy for each model and approach, highlighting the best performance for each setting.", "section": "4.2 Experimental comparisons"}, {"figure_path": "JvQnJWIj6m/tables/tables_16_2.jpg", "caption": "Table 6: Pretraining setting for ViT-S. All models trained for 100 epochs.", "description": "This table details the hyperparameters used for pre-training the Vision Transformer Small (ViT-S) model.  It specifies the optimizer, number of training epochs, learning rate, weight decay, batch size, learning rate scheduling, warmup epochs, encoder architecture, number of predicted targets, predictor depth, number of predictor attention heads, and predictor embedding dimension.", "section": "4.1 Experimental setup"}, {"figure_path": "JvQnJWIj6m/tables/tables_17_1.jpg", "caption": "Table 7: Pretraining setting for ViT-B. All models trained for 600 epochs.", "description": "This table details the hyperparameters used during the pretraining phase for the ViT-B model.  It lists the optimizer used (AdamW), the number of training epochs, learning rate, weight decay, batch size, the learning rate schedule (cosine decay), the number of warmup epochs, the encoder architecture (ViT-B), the number of predicted targets, the predictor depth, the number of predictor attention heads, and the predictor embedding dimension.  These settings were crucial in achieving optimal performance for the model.", "section": "4.1 Experimental setup"}, {"figure_path": "JvQnJWIj6m/tables/tables_17_2.jpg", "caption": "Table 1: Comparison with prior work. We perform linear evaluation, fine-tuning, COCO detection/segmentation, and ADE20K semantic segmentation on pre-trained ViT-B/16 models. We report linprob, fine-tune, Apbox, Apmask, and mIoU to evaluate the quality of pre-trained representations. The best results are indicated in bold.", "description": "This table compares the performance of the proposed C-JEPA model with several prior state-of-the-art self-supervised learning methods.  The comparison is done using a ViT-B/16 model pre-trained on ImageNet-1K, and the evaluation is performed across multiple downstream tasks: linear evaluation (linprob), fine-tuning (fine-tune), COCO object detection (Apbox, Apmask), and ADE20K semantic segmentation (mIoU).  The best performance for each metric is highlighted in bold.", "section": "4.2 Experimental comparisons"}, {"figure_path": "JvQnJWIj6m/tables/tables_18_1.jpg", "caption": "Table 9: ImageNet-1K image classification. We perform a linear evaluation on pre-trained ViT-T/16 and ViT-S/16 models for image classification on ImageNet-1K benchmark. We report the Top-1 accuracies using knn, linprob and fine-tune settings to evaluate the quality of pre-trained representations. The best results are indicated in bold.", "description": "This table shows the results of image classification experiments on the ImageNet-1K dataset using pre-trained ViT-T/16 and ViT-S/16 models.  The models were evaluated using three methods: k-nearest neighbors (knn), linear probing (linprob), and fine-tuning.  The top-1 accuracy is reported for each method, providing a comparison of the quality of representations learned by the different training methods. The best results for each model and method are highlighted in bold.", "section": "4.2 Experimental comparisons"}, {"figure_path": "JvQnJWIj6m/tables/tables_18_2.jpg", "caption": "Table 10: COCO object detection and instance segmentation. We fine-tuned pre-trained ViT-T/16 and ViT-S/16 models to perform COCO object detection and instance segmentation. The Apbox and Apmask metrics denote the results of COCO detection, and COCO segmentation, respectively. The best results are indicated in bold.", "description": "This table presents the results of fine-tuning pre-trained Vision Transformer models (ViT-T/16 and ViT-S/16) on the MS COCO dataset for object detection and instance segmentation tasks.  The performance is measured using Average Precision (AP) for bounding boxes (Apbox) and Average Precision for instance masks (Apmask) at different Intersection over Union (IoU) thresholds (50 and 75).  The table highlights the superior performance of C-JEPA compared to the baseline I-JEPA.", "section": "4.2 Experimental comparisons"}, {"figure_path": "JvQnJWIj6m/tables/tables_19_1.jpg", "caption": "Table 11: ADE20K semantic segmentation. We fine-tuned pre-trained ViT-T/16 and ViT-S/16 models to perform ADE20K semantic segmentation. The mIoU, aAcc, and mAcc metrics denote the results of ADE20K segmentation. The best results are indicated in bold.", "description": "This table presents the results of ADE20K semantic segmentation using fine-tuned ViT-T/16 and ViT-S/16 models.  The models were pre-trained using the proposed C-JEPA and the baseline I-JEPA methods.  The performance is evaluated using three metrics: mean Intersection over Union (mIoU), average accuracy (aAcc), and mean accuracy (mAcc).  The best results for each metric and model are highlighted in bold, demonstrating the superior performance of C-JEPA.", "section": "4.2 Experimental comparisons"}, {"figure_path": "JvQnJWIj6m/tables/tables_19_2.jpg", "caption": "Table 12: Ablation studies on component analysis for faster convergence. We perform ablation studies on Variance/Covariance and Invariance modules in VICReg using ViT-T/16 model. The best results are indicated in bold.", "description": "This table presents the ablation study results on the impact of Variance/Covariance and Invariance modules of VICReg on the performance of the C-JEPA model using ViT-T/16 architecture.  It shows the effect of including or excluding these components (indicated by checkmarks and crosses) on the knn, linprob, and fine-tune metrics. The best performing configuration for each metric is highlighted in bold.", "section": "4.3 Experimental analysis"}, {"figure_path": "JvQnJWIj6m/tables/tables_20_1.jpg", "caption": "Table 13: Ablation studies on component analysis for better convergence. We perform ablation studies on Variance/Covariance and Invariance modules in VICReg using ViT-T/16 model. The best results are indicated in bold.", "description": "This table presents the ablation study results on the impact of Variance/Covariance and Invariance modules of VICReg on the convergence speed of the ViT-T/16 model.  It compares different combinations of these modules (including no VICReg) against the baseline I-JEPA method, evaluating their performance using knn, linprob, and fine-tune metrics. The best-performing configuration for each metric is highlighted in bold.", "section": "4.3 Experimental analysis"}, {"figure_path": "JvQnJWIj6m/tables/tables_20_2.jpg", "caption": "Table 14: Ablation studies on component analysis for VICReg coefficients. We perform ablation studies on VICReg coefficients (\u00b7) using ViT-T/16 model. The best results are indicated in bold.", "description": "This table presents the results of ablation studies performed to analyze the impact of different VICReg coefficient values on the performance of the C-JEPA model.  The study varies the VICReg coefficient (\u03b2vicreg) while keeping other hyperparameters consistent and measures the performance using three metrics: (J&F)m,Jm,Fm on ViT-T/16 model. The best performance is highlighted in bold.", "section": "4.3 Experimental analysis"}, {"figure_path": "JvQnJWIj6m/tables/tables_21_1.jpg", "caption": "Table 15: Ablation studies on component analysis for invariance coefficients. We perform ablation studies on invariance coefficients (\u00b7) using ViT-T/16 model. The best results are indicated in bold.", "description": "This table presents the ablation study results on the impact of different invariance coefficients used in the VICReg component of the C-JEPA model.  The study varies the invariance coefficient (\u03b2sim) while keeping other parameters consistent and reports the performance metrics (knn, linprob, fine-tune) for ViT-T/16 model. The best results among different coefficient values are highlighted in bold.", "section": "4.3 Experimental analysis"}]