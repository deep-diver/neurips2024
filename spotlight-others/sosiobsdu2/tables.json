[{"figure_path": "SOsiObSdU2/tables/tables_7_1.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction mean squared error (TMSE) achieved by different methods (SINDY, GP, DyNODE, RNN, Transformer, APHYNITY, ZeroShot, ZeroOptim, and HDTwinGen) across six benchmark datasets representing complex real-world systems.  Lower TMSE values indicate better performance. HDTwinGen consistently demonstrates the lowest error, highlighting its effectiveness.  Confidence intervals are provided to indicate the uncertainty in the reported metrics.", "section": "7 Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_7_2.jpg", "caption": "Table 2: Out of distribution shifts. On a variation of the Lung Cancer (with Chemo. & Radio.), HDTwinGen is more robust to OOD shifts in unseen state-action distributions.", "description": "This table compares the performance of several methods (DyNODE, SINDY, RNN, Transformer, ZeroShot, ZeroOptim, and HDTwinGen) on an out-of-distribution (OOD) task.  The IID TMSE (In-Distribution Mean Squared Error) column shows the performance on the original, seen data distribution, and the OOD TMSE shows performance when the model is tested on unseen state-action distributions. The results demonstrate that HDTwinGen is more robust to OOD shifts than other methods, highlighting its ability to generalize better to unseen conditions.", "section": "7.1 Insight Experiments"}, {"figure_path": "SOsiObSdU2/tables/tables_17_1.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction Mean Squared Error (MSE) for different methods on six benchmark datasets. The methods compared include various neural network models (DyNODE, RNN, Transformer), equation discovery methods (SINDy, GP), a hybrid model (APHYNITY), and ablations of the proposed HDTwinGen method (ZeroShot, ZeroOptim).  HDTwinGen consistently achieves the lowest MSE, demonstrating its superior performance.", "section": "Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_20_1.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction mean squared error (TMSE) achieved by different methods on six benchmark datasets.  The methods compared include various neural network models (DyNODE, RNN, Transformer), mechanistic models (SINDy, GP), a hybrid model (APHYNITY), and the proposed HDTwinGen approach. The TMSE values, averaged over ten runs with different random seeds, are shown along with 95% confidence intervals, demonstrating the superior performance of HDTwinGen in accurately modeling the systems.", "section": "7 Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_31_1.jpg", "caption": "Table 4: HDTwinGen Ablation", "description": "This table presents the ablation study results for the HDTwinGen model by removing its memory, only keeping the last hybrid model it generated.  It compares the test prediction MSE (TMSE) for HDTwinGen with and without memory on the Lung Cancer (with Chemo. & Radio.) dataset. The results demonstrate the impact of memory on the model's generalization performance, showing significantly lower error with memory enabled.", "section": "H.5 HDTwinGen Ablation No Memory"}, {"figure_path": "SOsiObSdU2/tables/tables_31_2.jpg", "caption": "Table 5: Ablation of using different LLMs. Test MSE (TMSE) averaged over ten random seeds. HDTwinGen is capable of using other LLM models, however, the best performance results are provided with better-performing LLMs (e.g., GPT-4). The results are presented with \u00b1 indicating 95% confidence intervals.", "description": "This table presents the results of an ablation study where different LLMs were used with the HDTwinGen framework.  It shows the test mean squared error (TMSE) for each LLM, averaged over ten runs. The table demonstrates that HDTwinGen's performance correlates with the capabilities of the underlying LLM, achieving the best performance with a more capable LLM (GPT-4).  The results are reported with 95% confidence intervals to indicate statistical significance.", "section": "H.6 Evaluating Different LLMs"}, {"figure_path": "SOsiObSdU2/tables/tables_32_1.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction mean squared error (TMSE) achieved by different methods on six real-world benchmark datasets.  The TMSE is a measure of how well each method predicts the system's dynamics on unseen data.  The results are averaged over ten independent runs with different random seeds, and 95% confidence intervals are provided to indicate the uncertainty of the estimates. The table highlights that HDTwinGen consistently achieves the lowest TMSE across all datasets, demonstrating its superior performance in modeling complex dynamical systems.", "section": "7 Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_32_2.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction mean squared error (TMSE) achieved by different methods on six real-world datasets.  The methods include several state-of-the-art neural network models (DyNODE, RNN, Transformer), mechanistic models (SINDY, GP), a hybrid model (APHYNITY), and two ablations of the proposed HDTwinGen method (ZeroShot, ZeroOptim).  The results highlight HDTwinGen's superior performance in accurately modeling complex dynamical systems, achieving the lowest TMSE across all datasets.  Error bars represent 95% confidence intervals based on averaging over ten independent runs with different random seeds.", "section": "Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_33_1.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction Mean Squared Error (MSE) achieved by different methods (SINDy, GP, DyNODE, RNN, Transformer, AphyNITY, ZeroShot, ZeroOptim, and HDTwinGen) across six benchmark datasets (Lung Cancer, Lung Cancer (with Chemo.), Lung Cancer (with Chemo. & Radio.), Hare-Lynx, Plankton Microcosm, and COVID-19).  The results highlight the superior performance of HDTwinGen in terms of prediction accuracy.  The values represent averages over ten independent runs, each using different random seeds, with 95% confidence intervals indicating the variability of the results.", "section": "Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_34_1.jpg", "caption": "Table 9: Procedurally Generated Synthetic Model Benchmark. Test MSE (TMSE) averaged over ten random seeds. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all synthetic datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents the results of testing different machine learning models (DyNODE, SINDY, ZeroShot, ZeroOptim, and HDTwinGen) on five procedurally generated synthetic datasets.  Each model's performance is measured by its Test Mean Squared Error (TMSE), averaged over ten independent runs.  The table highlights that HDTwinGen consistently achieves the lowest TMSE across all datasets, demonstrating its superior performance in this benchmark.", "section": "H.9 Procedurally Generated Synthetic Model Benchmark"}, {"figure_path": "SOsiObSdU2/tables/tables_34_2.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents the test prediction mean squared error (TMSE) for six different dynamical systems.  Multiple methods were used to model each system.  The methods include neural network approaches (DyNODE, RNN, Transformer), symbolic regression techniques (SINDy, GP), a hybrid model (APHYNITY), and two variants of the proposed method HDTwinGen (ZeroShot, ZeroOptim).  HDTwinGen consistently achieves the lowest TMSE values across all datasets. The TMSE values represent the average over 10 independent runs with 95% confidence intervals to show the variability in results.", "section": "7 Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_36_1.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction Mean Squared Error (TMSE) achieved by different methods on six benchmark datasets.  The TMSE represents the average error of each method in predicting the system's dynamics on unseen data.  HDTwinGen consistently outperforms other methods across the datasets.", "section": "7 Main Results"}, {"figure_path": "SOsiObSdU2/tables/tables_36_2.jpg", "caption": "Table 1: Benchmark method performance. Reporting the test prediction MSE (TMSE) of the produced system models on held-out test datasets across all benchmark datasets. HDTwinGen achieves the lowest test prediction error. The results are averaged over ten random seeds, with \u00b1 indicating 95% confidence intervals.", "description": "This table presents a comparison of the test prediction Mean Squared Error (MSE) achieved by different methods across six benchmark datasets.  The methods include several neural network-based approaches (DyNODE, RNN, Transformer), mechanistic equation discovery methods (SINDY, GP), a previously published hybrid model (APHYNITY), and two ablations of the proposed HDTwinGen method (ZeroShot, ZeroOptim).  The table highlights that HDTwinGen consistently outperforms other methods in terms of prediction accuracy, achieving the lowest TMSE across all datasets. The reported values are averages across 10 runs with different random seeds, with confidence intervals provided to indicate the reliability of the results.", "section": "7 Main Results"}]