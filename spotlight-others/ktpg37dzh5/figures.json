[{"figure_path": "ktpG37Dzh5/figures/figures_1_1.jpg", "caption": "Figure 1: BMRS uses BMR to perform structured pruning under multiplicative noise by calculating the change in log-evidence of noise variables \u03b8 under a prior which would shrink them to 0.", "description": "This figure illustrates the Bayesian Model Reduction for Structured Pruning (BMRS) method.  The left panel shows a histogram of the expected values of noise variables (E[\u03b8]) from the original model, highlighting the distribution before pruning. The middle panel displays the original and reduced priors for the noise variables.  The reduced prior is designed to shrink the noise variable values toward zero, inducing sparsity.  The difference in log-evidence (\u0394F) between these two priors is then calculated. The right panel displays the histogram of E[\u03b8] after pruning, indicating how the noise variable distribution changes after pruning based on the \u0394F calculation.  BMRS prunes structures based on if \u0394F is greater than zero, indicating a significant improvement in the model's log-evidence by removing the structure.", "section": "4 Bayesian model reduction for structured pruning (BMRS)"}, {"figure_path": "ktpG37Dzh5/figures/figures_5_1.jpg", "caption": "Figure 2: Accuracy vs. compression for post-training pruning on CIFAR10, Fashion-MNIST, and MNIST. The left plot in each subfigure shows the average accuracy across 10 seeds, shading shows the standard deviation. For BMRS, we mark the maximum compression rate based on when \u2206F > 0. The right plot in each subfigure shows a scatter plot and kernel density estimation of accuracy vs. compression of BMRS compared to SNR accuracy. BMRS\u221a and BMRSu-8 consistently stop pruning near the knee point, a preferred trade-off solution.", "description": "This figure compares the performance of different pruning methods (L2, SNR, BMRSN, BMRSu) on three datasets (CIFAR10, Fashion-MNIST, MNIST) using two network architectures (Lenet5, MLP).  The left plots show accuracy versus compression rate curves, highlighting the trade-off between accuracy and model size. The right plots provide a detailed view of BMRS's performance near the 'knee' point of the accuracy-compression curve, demonstrating its effectiveness in finding a good balance between these two factors. Shading represents the standard deviation across multiple runs.  BMRS methods consistently stop at the knee point, indicating a good trade-off between accuracy and compression.", "section": "5 Experiments"}, {"figure_path": "ktpG37Dzh5/figures/figures_7_1.jpg", "caption": "Figure 2: Accuracy vs. compression for post-training pruning on CIFAR10, Fashion-MNIST, and MNIST. The left plot in each subfigure shows the average accuracy across 10 seeds, shading shows the standard deviation. For BMRS, we mark the maximum compression rate based on when \u0394F > 0. The right plot in each subfigure shows a scatter plot and kernel density estimation of accuracy vs. compression of BMRS compared to SNR accuracy. BMRS\u221a and BMRSu-8 consistently stop pruning near the knee point, a preferred trade-off solution.", "description": "This figure displays the results of post-training pruning experiments on three datasets: CIFAR10, Fashion-MNIST, and MNIST, using various pruning methods including L2, SNR, Etheta, BMRSN, and BMRSu. The left plots show accuracy against compression percentage for each method, with error bars representing standard deviation over 10 random seeds.  The BMRS methods' maximum compression is indicated by the point where \u0394F \u2264 0. The right plots provide a more detailed view comparing BMRS's performance to SNR, using scatter plots and kernel density estimations to highlight the accuracy at maximum compression. The results indicate that BMRS methods consistently stop pruning near the optimal trade-off point (knee point of the accuracy vs. compression curve).", "section": "5 Experiments"}, {"figure_path": "ktpG37Dzh5/figures/figures_7_2.jpg", "caption": "Figure 2: Accuracy vs. compression for post-training pruning on CIFAR10, Fashion-MNIST, and MNIST. The left plot in each subfigure shows the average accuracy across 10 seeds, shading shows the standard deviation. For BMRS, we mark the maximum compression rate based on when \u2206F > 0. The right plot in each subfigure shows a scatter plot and kernel density estimation of accuracy vs. compression of BMRS compared to SNR accuracy. BMRS\u221a and BMRSu-8 consistently stop pruning near the knee point, a preferred trade-off solution.", "description": "This figure compares the performance of various pruning methods (L2, SNR, E[\u03b8], BMRSN, BMRSu-8, BMRSu-4) on three datasets (CIFAR10, Fashion-MNIST, MNIST) using a LeNet5 CNN and an MLP.  The left plots show the accuracy vs. compression rate curves for each method across 10 different random seeds.  Shading represents the standard deviation. For the Bayesian methods (BMRS), pruning stops when the change in log-evidence (\u2206F) becomes negative. The right plots provide a closer view, showing a scatter plot and kernel density estimation of the accuracy at maximum compression for BMRS against the SNR method.  The results demonstrate that BMRS methods reliably stop pruning near the optimal point (Pareto front) on the accuracy-compression trade-off curve without needing any threshold tuning, unlike the other methods.", "section": "5 Experiments"}, {"figure_path": "ktpG37Dzh5/figures/figures_17_1.jpg", "caption": "Figure 2: Accuracy vs. compression for post-training pruning on CIFAR10, Fashion-MNIST, and MNIST. The left plot in each subfigure shows the average accuracy across 10 seeds, shading shows the standard deviation. For BMRS, we mark the maximum compression rate based on when \u0394F > 0. The right plot in each subfigure shows a scatter plot and kernel density estimation of accuracy vs. compression of BMRS compared to SNR accuracy. BMRS\u221a and BMRSu-8 consistently stop pruning near the knee point, a preferred trade-off solution.", "description": "This figure compares different pruning methods (L2, Grad, SNR, Etheta, BMRSN, BMRSu-8, BMRSu-4) for three datasets (CIFAR10, Fashion-MNIST, MNIST) with two network architectures (Lenet5, MLP). The left plots show the accuracy versus compression rate for each method.  Shading represents standard deviation across 10 random seeds. BMRS methods are marked at the maximum compression point where \u0394F >0. The right plots show scatter plots and density estimations of accuracy at maximum compression for BMRS and SNR, highlighting that BMRS methods tend to stop near the optimal trade-off point (knee of the curve).", "section": "5 Experiments"}, {"figure_path": "ktpG37Dzh5/figures/figures_17_2.jpg", "caption": "Figure 2: Accuracy vs. compression for post-training pruning on CIFAR10, Fashion-MNIST, and MNIST. The left plot in each subfigure shows the average accuracy across 10 seeds, shading shows the standard deviation. For BMRS, we mark the maximum compression rate based on when \u2206F > 0. The right plot in each subfigure shows a scatter plot and kernel density estimation of accuracy vs. compression of BMRS compared to SNR accuracy. BMRS\u221a and BMRSu-8 consistently stop pruning near the knee point, a preferred trade-off solution.", "description": "This figure presents the results of post-training pruning experiments on three datasets (CIFAR10, Fashion-MNIST, and MNIST) using various methods.  The left-hand plots show accuracy against compression rate for each method (L2, SNR, Etheta, BMRSN, BMRSU-8, and BMRSU-4), illustrating the trade-off between model size and accuracy. The right-hand plots provide a closer look at the performance of BMRS methods, comparing their accuracy and compression rate to SNR.  These plots highlight that BMRS methods tend to stop pruning near the optimal point (the 'knee' of the accuracy-compression curve), which is considered a preferred trade-off between model size and accuracy, demonstrating BMRS's effectiveness in finding a good balance between compression and performance.", "section": "5 Experiments"}, {"figure_path": "ktpG37Dzh5/figures/figures_18_1.jpg", "caption": "Figure 2: Accuracy vs. compression for post-training pruning on CIFAR10, Fashion-MNIST, and MNIST. The left plot in each subfigure shows the average accuracy across 10 seeds, shading shows the standard deviation. For BMRS, we mark the maximum compression rate based on when \u2206F > 0. The right plot in each subfigure shows a scatter plot and kernel density estimation of accuracy vs. compression of BMRS compared to SNR accuracy. BMRS\u221a and BMRSu-8 consistently stop pruning near the knee point, a preferred trade-off solution.", "description": "This figure shows the results of post-training pruning experiments on three datasets: CIFAR10, Fashion-MNIST, and MNIST, using different pruning methods.  The left plots show accuracy vs. compression rate across ten random seeds, highlighting the performance of BMRS methods (BMRSN and BMRSu).  The right plots provide scatter and density plots comparing the accuracy at the maximum compression rate of BMRS methods against the accuracy of SNR pruning at the knee point of the accuracy-compression curve.  The results indicate that BMRS consistently stops pruning near the optimal balance of accuracy and compression, unlike other methods.", "section": "5 Experiments"}]