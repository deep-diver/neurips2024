[{"figure_path": "tUpcRQNvVM/figures/figures_5_1.jpg", "caption": "Figure 1: The structure of a DSPN and the control flow of how a DSPN is trained; parameters are shared between the DSPNs processing E and M sets.", "description": "This figure illustrates the architecture of a Deep Submodular Peripteral Network (DSPN) and its training process.  Two DSPNs, one for set E and one for set M, share the same parameters (w).  Each DSPN consists of five peripteral pillars (input layer), a submodular-preserving permutation-invariant aggregator, and a roof (output layer). The E and M sets are input to their respective DSPNs.  The output from each DSPN, fw(E) and fw(M), is used with the oracle/target function \u0394(E|M) to calculate the peripteral loss. Gradient-based optimization adjusts the shared parameters (w) to minimize this loss. Submodular optimization feedback mechanisms are used for the sampling of E-M pairs, to guide the training process and ensure that information from the oracle/target is effectively transferred to the learner.", "section": "4 Sampling (E,M) Pairs"}, {"figure_path": "tUpcRQNvVM/figures/figures_6_1.jpg", "caption": "Figure 2: Passive Sets. We consider a simple 2D ground set with 5 clusters/classes, as indicated by the colors. The various types of passively sampled sets are depicted (discussed in section 4). Type-I homogeneous sets are randomly sampled from a single class, while Type-I heterogeneous sets are sampled from the full ground set. Meanwhile, Type-II restricts the ground set to a subset of classes and samples \"clumps\" from each of the sampled classes to construct the homogeneous set, and diverse sets from each class to create the heterogeneous sets. Intuitively, using Type-I/II allows the learnt DSPN to model intraclass/interclass respectively.", "description": "This figure illustrates different strategies for passively sampling sets from a 2D dataset with 5 clusters.  Type-I sampling shows homogeneous sets (all points from one cluster) and heterogeneous sets (points from all clusters). Type-II sampling demonstrates the same, but with the ground set restricted to a subset of the clusters. This distinction helps the DSPN learn intra-class and inter-class relationships, respectively.", "section": "4 Sampling (E,M) Pairs"}, {"figure_path": "tUpcRQNvVM/figures/figures_7_1.jpg", "caption": "Figure 4: Transfer. We compare different loss functions in terms of their effectiveness at training a DSPN.", "description": "This figure shows a comparison of four different loss functions used for training Deep Submodular Peripteral Networks (DSPNs).  The radial distance from the center represents the normalized ground-truth (target) summary valuation achieved by performing greedy maximization on the target function.  The angle represents different summary sizes (budgets).  The results indicate that the proposed peripteral loss outperforms other methods (regression, margin, random selection) across various summary sizes and datasets.", "section": "5.1 Transfer from Target to Learner"}, {"figure_path": "tUpcRQNvVM/figures/figures_8_1.jpg", "caption": "Figure 5: Offline Experimental Design. We compare different summarization procedures, and assess them based on the test accuracy that a linear model attains upon being trained on the summary. We find that maximizing the learnt DSPN generates high quality datasets, outperforming existing summarization techniques such as CRAIG and k-centers. In many cases, the DSPN approaches the Target FL even though the latter is aware of the duplicates present in the data. Takeaway: DSPN effectively chooses training samples for labeling from an unlabeled pool.", "description": "This figure compares the performance of different summarization techniques in an offline experimental design setting.  The goal is to select a subset of unlabeled data for labeling to train a linear model.  The x-axis represents the size of the training dataset (the summary), and the y-axis represents the accuracy of the trained linear model. The figure shows that the proposed Deep Submodular Peripteral Network (DSPN) method outperforms existing techniques (k-center, CRAIG, random) in achieving high accuracy, even approaching the performance of the optimal \"Target FL\" method which has access to information not available to the other methods. This demonstrates DSPN's effectiveness in selecting informative training samples.", "section": "5 Experiments"}, {"figure_path": "tUpcRQNvVM/figures/figures_8_2.jpg", "caption": "Figure 6: Online Experimental Design. The performance of a linear probe, trained based on a subset selected by an algorithm that does not use labels, is reported at varying budgets. DSPN-online achieves far higher performance than other streaming algorithms such as reservoir sampling and VeSSAL and is performs comparably to offline algorithms. Takeaway: DSPN can effectively select training samples for labeling from a stream of unlabeled data.", "description": "This figure compares the performance of different summarization methods in an online setting, where data arrives sequentially.  The y-axis shows the accuracy of a linear model trained on the selected subset, and the x-axis shows the size of the training dataset (budget).  The DSPN-online method significantly outperforms baseline methods (Reservoir and VeSSAL) and achieves performance comparable to the offline DSPN approach. This demonstrates that the DSPN is effective at selecting informative samples from a data stream for training.", "section": "5 Experiments"}, {"figure_path": "tUpcRQNvVM/figures/figures_27_1.jpg", "caption": "Figure 7: Peripteral loss of \u03b4 for different values and sign of margin \u0394 and the corresponding gradient.", "description": "This figure shows plots of the peripteral loss function and its gradient with respect to \u03b4 for various values of the margin \u0394 and different values of the hyperparameters \u03b2 and \u03c4. The plots illustrate how the loss changes as a function of \u03b4, demonstrating the impact of the margin and hyperparameters on the loss function's curvature and smoothness. The gradients are also shown, giving insights into the behavior of the loss function's optimization.", "section": "F Analysis and Further Description of Peripteral Loss"}, {"figure_path": "tUpcRQNvVM/figures/figures_28_1.jpg", "caption": "Figure 7: Peripteral loss of \u03b4 for different values and sign of margin \u0394 and the corresponding gradient.", "description": "This figure shows two plots. The left plot shows the peripteral loss for different values of \u03b2 (the smoothing parameter) and for positive and negative margins. The right plot shows the gradient of the peripteral loss with respect to \u03b4 (the difference between the learner and oracle predictions) for the same set of \u03b2 values and margins.  The plots illustrate how the hyperparameter \u03b2 influences the smoothness of the loss function and its gradient, affecting the stability and convergence of the optimization process.", "section": "F Analysis and Further Description of Peripteral Loss"}, {"figure_path": "tUpcRQNvVM/figures/figures_28_2.jpg", "caption": "Figure 7: Peripteral loss of \u03b4 for different values and sign of margin \u0394 and the corresponding gradient.", "description": "This figure shows plots of the peripteral loss function (L\u0394;\u03b2,\u03c4,\u03ba,\u03b5(\u03b4)) and its gradient for various values of the margin (\u0394) and different hyperparameter settings (\u03b2). The plots illustrate how the loss and gradient behave for both positive and negative margins, and how the hyperparameters control the curvature and smoothness of the loss function.  It helps to visualize the behavior of the loss function for different inputs and how the hyperparameters affect the loss landscape during the training process.", "section": "Analysis and Further Description of Peripteral Loss"}, {"figure_path": "tUpcRQNvVM/figures/figures_29_1.jpg", "caption": "Figure 1: The structure of a DSPN and its learning control flow. Please see appendix G for more details.", "description": "This figure illustrates the architecture of a Deep Submodular Peripteral Network (DSPN) and its training process.  Two copies of the DSPN are shown, one for set E and another for set M.  Each DSPN consists of pillars (feature extractors), an aggregation stage (weighted matroid rank function), and a deep submodular function (DSF) roof. The training involves iterative optimization using a novel peripteral loss, leveraging graded pairwise comparisons from an oracle.  The figure visually depicts the flow of information from input data through the DSPN to the final output, emphasizing the interaction between the two DSPN instances and the oracle feedback during training. Appendix G provides additional details.", "section": "4 Sampling (E,M) Pairs"}, {"figure_path": "tUpcRQNvVM/figures/figures_31_1.jpg", "caption": "Figure 11: Imbalanced dataset distributions", "description": "This figure shows the class distributions of four image datasets (Imagenette, Imagewoof, CIFAR-100, and Imagenet100) after adding duplicates to make them heavily class-imbalanced.  The x-axis represents the classes, and the y-axis represents the number of samples per class.  The distributions are shown to illustrate the uneven representation of classes in these datasets, which serves as a more challenging and realistic test for the proposed DSPN model.", "section": "5 Experiments"}, {"figure_path": "tUpcRQNvVM/figures/figures_32_1.jpg", "caption": "Figure 12: Qualitative Assessment of Learnt Features on Imagenet100. For each row, we use a randomly selected feature of either DSPN or CLIP to rank all images in the held out set and visualize the highest and lowest ranked samples. Each DSPN feature corresponds to some count-like property that is correlated to class, evident from the fact that very few distinct classes are present in the highly ranked images.", "description": "This figure qualitatively analyzes the learned features of the DSPN model and compares them to CLIP features.  It shows the top and bottom 10 images ranked by randomly selected features from both DSPN and CLIP.  The DSPN features show a strong correlation to class, indicating that they capture count-like attributes, while CLIP features show weaker correlations.", "section": "I Qualitative Analysis of Learnt Features"}]