[{"figure_path": "AVd7DpiooC/tables/tables_3_1.jpg", "caption": "Table 1: Computational complexity comparison. N is the token number, D is the channel number.", "description": "This table compares the time and space complexity of different self-attention mechanisms: Vanilla Self-Attention (VSA), Spiking Self-Attention (SSA), Spike-Driven Self-Attention (SDSA), Q-K Token Attention (QKTA), and Q-K Channel Attention (QKCA).  The complexity is expressed in Big O notation, showing how it scales with the number of tokens (N) and the number of channels (D).  It highlights the linear complexity of QKTA and QKCA compared to the quadratic complexity of VSA and SSA, indicating their potential for greater efficiency in larger models.", "section": "3 Method"}, {"figure_path": "AVd7DpiooC/tables/tables_5_1.jpg", "caption": "Table 2: Results on ImageNet-1K. Power is calculated as the average theoretical energy consumption when predicting an image from ImageNet test set. The power data for QKFormer and ANNs is evaluated according to Appendix.7.6, and the power data for other works were obtained from related papers. \"A2S\" denotes \"ANN-to-SNN\", \"HST-L-D\" denotes \"Hierarchical Spiking Transformer\" with L encoder blocks and D channels. HST-10-768* and HST-10-768** means HST-10-768 with 2882 and 3842 input size for inference. The top-5 accuracy of QKFormer (HST-10-768**) is 97.74%.", "description": "This table presents the results of various methods (both ANNs and SNNs) on the ImageNet-1K dataset.  It compares their top-1 accuracy, model parameters, power consumption (in mJ), and number of time steps.  It highlights the superior performance of QKFormer, especially when compared to other SNN models, and notes the difference in power consumption between ANNs and SNNs.", "section": "4 Results"}, {"figure_path": "AVd7DpiooC/tables/tables_6_1.jpg", "caption": "Table 3: Comparision on CIFAR10, CIFAR100, DVS128, CIFAR10-DVS. \"Param\" denotes \"Parame-ter (M)\", \"Acc\" denotes \"Top-1 Accuracy (%)\", \"T\" denotes \"Time Step\".", "description": "This table compares the performance of different spiking neural network models on four benchmark datasets: CIFAR10, CIFAR100, DVS128, and CIFAR10-DVS.  The metrics used for comparison are the number of parameters (in millions), the number of time steps used, and the top-1 accuracy achieved.  The table includes both Spiking Neural Network (SNN) models and Artificial Neural Network (ANN) baselines for comparison purposes. Note that the time steps may differ between models, affecting the interpretation of the accuracy.", "section": "4.1 Results on ImageNet-1k Classification"}, {"figure_path": "AVd7DpiooC/tables/tables_8_1.jpg", "caption": "Table 2: Results on ImageNet-1K. Power is calculated as the average theoretical energy consumption when predicting an image from ImageNet test set. The power data for QKFormer and ANNs is evaluated according to Appendix.7.6, and the power data for other works were obtained from related papers. \"A2S\" denotes \"ANN-to-SNN\", \"HST-L-D\" denotes \"Hierarchical Spiking Transformer\" with L encoder blocks and D channels. HST-10-768* and HST-10-768** means HST-10-768 with 2882 and 3842 input size for inference. The top-5 accuracy of QKFormer (HST-10-768**) is 97.74%.", "description": "This table presents a comparison of various methods (both ANNs and SNNs) on ImageNet-1K, including their model type, architecture, input size, number of parameters, power consumption (in mJ), number of time steps, and top-1 accuracy (%).  It highlights the superior performance of QKFormer, especially compared to other SNN models.  Note that the power data is calculated based on theoretical energy consumption and varies depending on the hardware.", "section": "4.1 Results on ImageNet-1k Classification"}, {"figure_path": "AVd7DpiooC/tables/tables_8_2.jpg", "caption": "Table 5: Ablation studies of SPEDS module.", "description": "This table presents the ablation study results focusing on the impact of the Spiking Patch Embedding with Deformed Shortcut (SPEDS) module on the performance of the QKFormer model.  It compares the performance of QKFormer with and without SPEDS, as well as Spikformer with and without SPEDS, on CIFAR100 and CIFAR10-DVS datasets. The results demonstrate the positive contribution of the SPEDS module to improving accuracy.", "section": "4.4 Ablation Study"}, {"figure_path": "AVd7DpiooC/tables/tables_8_3.jpg", "caption": "Table 6: Ablation studies of Q-K Attention.", "description": "This table presents the ablation study results focusing on the impact of different Q-K attention mechanisms on the model's performance.  It shows the top-1 accuracy and the number of parameters (in millions) for various configurations of QKFormer on CIFAR100 and CIFAR10-DVS datasets. The baseline is QKFormer using QKTA + SSA.  The other rows show variations on the attention module, such as using only QKCA or QKTA, or using only SSA. The results demonstrate the impact of the Q-K attention choice on model accuracy and efficiency.", "section": "4.4 Ablation Study"}, {"figure_path": "AVd7DpiooC/tables/tables_9_1.jpg", "caption": "Table 7: Ablation studies of RC, SN, TS.", "description": "This table presents the ablation study results on CIFAR100, comparing the performance of QKFormer under different configurations. Specifically, it investigates the impact of changing the residual connection type (ABA to PA), the spiking neuron model (LIF to IF, LIF to PLIF), and the number of time steps (T). The baseline is QKFormer with ABA residual connection, LIF neuron model, and 4 time steps (T=4).", "section": "4 Experiments"}, {"figure_path": "AVd7DpiooC/tables/tables_16_1.jpg", "caption": "Table 2: Results on ImageNet-1K. Power is calculated as the average theoretical energy consumption when predicting an image from ImageNet test set. The power data for QKFormer and ANNs is evaluated according to Appendix.7.6, and the power data for other works were obtained from related papers. \"A2S\" denotes \"ANN-to-SNN\", \"HST-L-D\" denotes \"Hierarchical Spiking Transformer\" with L encoder blocks and D channels. HST-10-768* and HST-10-768** means HST-10-768 with 2882 and 3842 input size for inference. The top-5 accuracy of QKFormer (HST-10-768**) is 97.74%.", "description": "This table presents the results of various methods (both SNNs and ANNs) on the ImageNet-1K dataset.  It shows the model type (ANN or SNN), architecture, input size, number of parameters, power consumption (in mJ), number of time steps, and top-1 accuracy.  The table highlights QKFormer's superior performance and energy efficiency compared to other SNN and ANN approaches, especially achieving a groundbreaking top-1 accuracy exceeding 85% on ImageNet-1K.", "section": "4.1 Results on ImageNet-1k Classification"}, {"figure_path": "AVd7DpiooC/tables/tables_18_1.jpg", "caption": "Table 2: Results on ImageNet-1K. Power is calculated as the average theoretical energy consumption when predicting an image from ImageNet test set. The power data for QKFormer and ANNs is evaluated according to Appendix.7.6, and the power data for other works were obtained from related papers. \"A2S\" denotes \"ANN-to-SNN\", \"HST-L-D\" denotes \"Hierarchical Spiking Transformer\" with L encoder blocks and D channels. HST-10-768* and HST-10-768** means HST-10-768 with 2882 and 3842 input size for inference. The top-5 accuracy of QKFormer (HST-10-768**) is 97.74%.", "description": "This table presents a comparison of various methods (both ANNs and SNNs) on the ImageNet-1K dataset.  Metrics include top-1 accuracy, number of parameters, power consumption (in millijoules), and the number of time steps. The table highlights the superior performance of QKFormer, particularly when compared to similar-sized Spiking Transformer models.", "section": "4.1 Results on ImageNet-1k Classification"}, {"figure_path": "AVd7DpiooC/tables/tables_18_2.jpg", "caption": "Table 2: Results on ImageNet-1K. Power is calculated as the average theoretical energy consumption when predicting an image from ImageNet test set. The power data for QKFormer and ANNs is evaluated according to Appendix.7.6, and the power data for other works were obtained from related papers. \"A2S\" denotes \"ANN-to-SNN\", \"HST-L-D\" denotes \"Hierarchical Spiking Transformer\" with L encoder blocks and D channels. HST-10-768* and HST-10-768** means HST-10-768 with 2882 and 3842 input size for inference. The top-5 accuracy of QKFormer (HST-10-768**) is 97.74%.", "description": "This table presents a comparison of various models' performance on the ImageNet-1K dataset, including the top-1 accuracy, the number of parameters, power consumption, and the number of time steps. It compares both spiking neural network (SNN) and artificial neural network (ANN) models, highlighting QKFormer's superior performance and efficiency.", "section": "4 Results"}]