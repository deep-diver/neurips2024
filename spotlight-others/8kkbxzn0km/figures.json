[{"figure_path": "8KkBxzn0km/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison of Forgetting-Free Saliency Prediction vs. Catastrophic Forgetting in Classifiers and Activation Maps in Continual Learning Scenarios. (Left figure): The saliency accuracy (measured by the similarity [10] score) of a saliency predictor trained in a continual learning setting improves as more tasks are introduced, while the classification accuracy of a continual classifier degrades over time, indicating that saliency detection remains i.i.d. even with non-i.i.d. data. (Right figure): The top row shows activation maximization maps via GradCAM, which are prone to catastrophic forgetting due to their dependence on the classifier. In contrast, the bottom row shows saliency maps produced by the predictor, which remain stable and consistent over time.", "description": "The figure shows a comparison between the performance of saliency prediction and classification models in continual learning settings.  The left panel shows that saliency prediction remains stable over time, while classification accuracy suffers from catastrophic forgetting. The right panel illustrates this by comparing activation maps (GradCAM, which are classifier-dependent and show forgetting) to saliency maps (which are stable over time).", "section": "1 Introduction"}, {"figure_path": "8KkBxzn0km/figures/figures_2_1.jpg", "caption": "Figure 2: Architecture of the proposed Saliency-driven Experience Replay (SER) strategy.The classification backbone is paired with a saliency prediction network that, given its capability of being forgetting-free, aims at adjusting the learned classification features in order to mitigate overall forgetting.", "description": "The figure shows the architecture of the Saliency-driven Experience Replay (SER) strategy.  It highlights two main branches: a saliency prediction network and a classification backbone. The saliency prediction network, designed to be robust to forgetting, generates saliency maps. These maps modulate the features learned by the classification network, helping to stabilize learning across multiple tasks and reduce catastrophic forgetting.  The attention modulation mechanism is depicted as a Hadamard product between the saliency and classification features.", "section": "Method"}, {"figure_path": "8KkBxzn0km/figures/figures_7_1.jpg", "caption": "Figure 1: Comparison of Forgetting-Free Saliency Prediction vs. Catastrophic Forgetting in Classifiers and Activation Maps in Continual Learning Scenarios. (Left figure): The saliency accuracy (measured by the similarity [10] score) of a saliency predictor trained in a continual learning setting improves as more tasks are introduced, while the classification accuracy of a continual classifier degrades over time, indicating that saliency detection remains i.i.d. even with non-i.i.d. data. (Right figure): The top row shows activation maximization maps via GradCAM, which are prone to catastrophic forgetting due to their dependence on the classifier. In contrast, the bottom row shows saliency maps produced by the predictor, which remain stable and consistent over time.", "description": "This figure compares the performance of saliency prediction and classification models in continual learning settings.  The left graph shows that saliency prediction remains stable or even improves over time, while classification accuracy decreases significantly. The right side shows GradCAM activation maps and predicted saliency maps, visually demonstrating the catastrophic forgetting in the classification model compared to the stability in the saliency prediction model.", "section": "1 Introduction"}, {"figure_path": "8KkBxzn0km/figures/figures_8_1.jpg", "caption": "Figure 1: Comparison of Forgetting-Free Saliency Prediction vs. Catastrophic Forgetting in Classifiers and Activation Maps in Continual Learning Scenarios. (Left figure): The saliency accuracy (measured by the similarity [10] score) of a saliency predictor trained in a continual learning setting improves as more tasks are introduced, while the classification accuracy of a continual classifier degrades over time, indicating that saliency detection remains i.i.d. even with non-i.i.d. data. (Right figure): The top row shows activation maximization maps via GradCAM, which are prone to catastrophic forgetting due to their dependence on the classifier. In contrast, the bottom row shows saliency maps produced by the predictor, which remain stable and consistent over time.", "description": "The figure shows a comparison between the forgetting-free behavior of saliency prediction and the catastrophic forgetting in classifiers during continual learning. The left plot shows that saliency prediction accuracy improves over time as more tasks are introduced, while classifier accuracy degrades. The right part shows Grad-CAM activation maps (top), which are highly affected by catastrophic forgetting, while saliency maps remain stable over time (bottom).", "section": "1 Introduction"}, {"figure_path": "8KkBxzn0km/figures/figures_14_1.jpg", "caption": "Figure 2: Architecture of the proposed Saliency-driven Experience Replay (SER) strategy.The classification backbone is paired with a saliency prediction network that, given its capability of being forgetting-free, aims at adjusting the learned classification features in order to mitigate overall forgetting.", "description": "The figure shows the architecture of the Saliency-driven Experience Replay (SER) method.  It consists of two branches: a classification branch and a saliency prediction branch. The saliency prediction branch, which is designed to be robust to forgetting, generates saliency maps. These saliency maps are then used to modulate the features learned by the classification branch, improving the model's ability to learn new tasks without forgetting previous ones. The modulation happens through an attention mechanism that incorporates the saliency map into the classification feature learning process.", "section": "3 Method"}, {"figure_path": "8KkBxzn0km/figures/figures_17_1.jpg", "caption": "Figure 1: Comparison of Forgetting-Free Saliency Prediction vs. Catastrophic Forgetting in Classifiers and Activation Maps in Continual Learning Scenarios. (Left figure): The saliency accuracy (measured by the similarity [10] score) of a saliency predictor trained in a continual learning setting improves as more tasks are introduced, while the classification accuracy of a continual classifier degrades over time, indicating that saliency detection remains i.i.d. even with non-i.i.d. data. (Right figure): The top row shows activation maximization maps via GradCAM, which are prone to catastrophic forgetting due to their dependence on the classifier. In contrast, the bottom row shows saliency maps produced by the predictor, which remain stable and consistent over time.", "description": "The figure compares the performance of saliency prediction and classification models in continual learning settings.  The left graph shows that saliency prediction remains stable while classification accuracy degrades over time. The right side displays activation maps and demonstrates how saliency maps are more robust to catastrophic forgetting than activation maps.", "section": "1 Introduction"}]