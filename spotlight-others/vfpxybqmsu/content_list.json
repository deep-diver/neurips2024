[{"type": "text", "text": "Slight Corruption in Pre-training Data Makes Better Diffusion Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hao Chen1,\u2217 Yujin Han2, Diganta Misra1,3, Xiang $\\mathrm{Li^{1}}$ , Kai $\\mathrm{Hu^{1}}$ , Difan Zou2, Masashi Sugiyama4,5, Jindong Wang6,\u2020 Bhiksha Raj1,7 ", "page_idx": 0}, {"type": "text", "text": "1Carnegie Mellon University, 2The University of Hong Kong,3Mila - Quebec AI Institute, 4 RIKEN AIP, 5The University of Tokyo, 6William & Mary, 7MBZUAI ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Diffusion models (DMs) have shown remarkable capabilities in generating realistic high-quality images, audios, and videos. They benefti significantly from extensive pre-training on large-scale datasets, including web-crawled data with paired data and conditions, such as image-text and image-class pairs. Despite rigorous flitering, these pre-training datasets often inevitably contain corrupted pairs where conditions do not accurately describe the data. This paper presents the first comprehensive study on the impact of such condition corruption in pre-training data of DMs. We synthetically corrupt ImageNet-1K and CC3M to pre-train and evaluate over 50 conditional DMs. Our empirical findings reveal that various types of slight corruption in pre-training can significantly enhance the quality, diversity, and fidelity of the generated images across different DMs, both during pre-training and downstream adaptation stages. Theoretically, we consider a Gaussian mixture model and prove that slight corruption in the condition leads to higher entropy and a reduced 2-Wasserstein distance to the ground truth of the data distribution generated by the corruptly trained DMs. Inspired by our analysis, we propose a simple method to improve the training of DMs on practical datasets by adding condition embedding perturbations (CEP). CEP significantly improves the performance of various DMs in both pre-training and downstream tasks. We hope that our study provides new insights into understanding the data and pre-training processes of DMs and all models are released at https://huggingface.co/DiffusionNoise. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recently, diffusion models (DMs) have been demonstrating unprecedented capabilities in generating high-quality, realistic, and faithful images [1\u20135], audios [6, 7], and videos [8]. In addition, they exhibit impressive conditional generation results [9\u201311] when trained with classifier-free guidance [12]. The successes of DMs are often attributed to the massive pre-training on large-scale datasets consisting of paired data and conditions [13\u201317], which also empowered and facilitated numerous downstream applications and personalization of pre-trained models, such as subject-driven generation [18, 19], controllable conditional generation [20\u201322], and synthetic data training [23\u201325]. ", "page_idx": 0}, {"type": "text", "text": "The large-scale pre-training datasets of paired data and conditions are usually web-crawled. For example, Stable Diffusion [26] was pre-trained on LAION-2B [17], which contains billion-scale image-text pairs collected from Common Crawl [27]. Despite the heavy flitering mechanisms used in collecting pre-training datasets [17, 28], they still inevitably contain corrupted pairs where conditions do not correctly describe or match the data, such as corrupted labels and texts [29\u201332]. While large-scale datasets are necessary for DMs to perform well, the corruption may lead to unexpected behavior or generalization performance of models [33\u201335] during both pre-training and adaptation stages, especially for safety-critical domains such as healthcare [36] and autonomous driving [37, 38]. ", "page_idx": 0}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/9b19b60b13ab96f0fd5067bfb07aabef037e605756940665ed552ca564964475.jpg", "img_caption": ["Figure 1: Visualization from class and text-conditional DMs pre-trained with clean, slight, and severe condition corruption. Slight corruption in pre-training improves the quality and diversity of images. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Conventional wisdom may suggest that training under corrupted conditions could lead to deterioration in performance. For example, Noisy Label Learning [39\u201342, 29, 43, 44] aims to improve the generalization of models when training with corrupted labels. Label-noise robust conditional generative adversarial nets [45, 46] and DMs [47] have also been studied. However, these works are primarily concerned with supervised learning in downstream scenarios with assumptions of high noise ratios and the same training and testing data distributions. Due to the misalignment with large-scale self-supervised pre-training in practice on filtered datasets with relatively smaller noise ratios, the effects of corruption in pre-training can also differ from those in downstream [48, 49].Understanding the effects of pre-training with such corruption is challenging and still remains largely unexplored. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we provide the first comprehensive and practical study on condition corruption in the pre-training of DMs. Through indepth analysis, we empirically, theoretically, and methodologically verify that slight condition corruption in pre-training makes better DMs. We pre-train over 50 class-conditional and textconditional DMs using classifier-free guidance (CFG) [12] on ImageNet-1K (IN-1K) [50] and CC3M [14] with synthetically corrupted conditions, i.e., classes and texts, of various levels. Our study covers a wide range of DM families, including Latent Diffusion Model (LDM) [9], Diffusion Transformer (DiT) [11], and Latent Consistency Model (LCM) [51, 52]. Due to the known obstacles of evaluating generative mod", "page_idx": 1}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/f3f04f123d16e0df459be3fb89bab76c3b087c972cae3ba7c8cc495bfe6ffc50.jpg", "img_caption": ["Figure 2: (a) FID and (b) IS of DMs pre-trained on IN-1K and CC3M with various corruption. Slight corruption of various types helps DMs achieve better performance, compared to the clean ones. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "els [53\u201355], we conduct both pre-training and downstream evaluation from the perspectives of image quality, fidelity, diversity, complexity, and memorization, to comprehensively understand the effects of pre-training corruption of DMs. More specifically, for pre-training, we directly evaluate the images generated from the pre-trained models, and for downstream adaptation, we evaluate on the images generated using personalized models with ControlNet [20] and T2I-Adapter [21] from the pre-trained ones. In addition, we theoretically investigate how slight corruption in conditional embeddings benefits the training and generative processes of DMs. Our key findings include: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Empirically, slight corruption in pre-training facilitates the DMs to generate images with higher quality and more diversity, both qualitatively (in Fig. 1) and quantitatively (in Fig. 2). \u2022 Theoretically, we employ a Gaussian mixture model to show slight condition corruption improves the diversity and quality of generation by increasing entropy over clean condition generation and reducing the quadratic 2-Wasserstein distance to the true data distribution (in Section 4). ", "page_idx": 1}, {"type": "text", "text": "\u2022 Methodologically, based on our analysis, we propose a simple method to improve the pre-training of DMs by adding conditional embedding perturbations (CEP). We show that CEP can significantly boost the performance of various DMs in both pre-training and downstream tasks (in Section 5). ", "page_idx": 2}, {"type": "text", "text": "Going beyond images, we do see the potential of this study in other modalities. Our efforts may also inspire future investigation on other types of corruption and bias inside pre-training datasets. We hope that our work can shed light on the future research of diffusion models and responsible AI. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Denoising Diffusion Models. DMs are probabilistic models that learn the data distribution $\\mathbb{P}(\\mathbf{x})$ , with $\\mathbf{x}$ denoting the observed data3, over a set of latent variables $\\mathbf{z}_{1},\\dots,\\mathbf{z}_{T}$ with length $T$ [1, 57]. It assumes a forward diffusion process, gradually adding Gaussian noise to the data with a fixed Markov chain: $q(\\mathbf{z}_{t}|\\mathbf{x})=\\mathcal{N}(\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x},\\bar{(1-\\bar{\\alpha}_{t})}\\mathbf{\\bar{I}})$ , which can be re-parameterized as $\\mathbf{z}_{t}=\\sqrt{\\bar{\\alpha}_{t}}\\mathbf{x}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon$ with $\\pmb{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ and $\\bar{\\alpha}_{t}$ as constants produced by a noise scheduler. DMs are trained via the reverse process, inverting the forward process as: $p_{\\theta}(\\mathbf{z}_{t-1}|\\mathbf{z}_{t})=\\mathcal{N}\\left(\\mu_{\\theta}\\left(\\mathbf{z}_{t}\\right),\\Sigma_{\\theta}\\left(\\mathbf{z}_{t}\\right)\\right)$ , with a network that predicts the statistics of $p_{\\theta}$ . Setting $\\pmb{\\Sigma}_{\\theta}\\,(\\mathbf{z}_{t})=(1-\\bar{\\alpha}_{t})\\mathbf{I}$ to untrained constants, the reverse process is simplified as training equally weighted denoising autoencoders $\\boldsymbol{\\epsilon}\\left(\\mathbf{z}_{t},t\\right)$ with uniformly sampled $t$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{DM}}=\\mathbb{E}_{{\\mathbf{x}},{\\mathbf{\\epsilon}}\\sim\\mathcal{N}(0,\\mathbf{I}),t\\sim\\mathcal{U}(1,T)}\\left[\\|\\epsilon-\\epsilon_{\\theta}\\left({\\mathbf{z}}_{t},t\\right)\\|_{2}^{2}\\right].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "After training, new images can be generated by sampling $\\mathbf z_{t-1}\\sim\\mathbf p_{\\theta}\\big(\\mathbf z_{t-1}\\big|\\mathbf z_{t}\\big)$ starting with $\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ . ", "page_idx": 2}, {"type": "text", "text": "Classifier-free Guidance (CFG). Extra condition information $y$ , such as class labels and text prompts, can be injected into DMs with conditional embeddings ${\\bf c}_{\\theta}(y)$ from modality-specific encoders [9] for conditional generation: $\\mathbf{p}_{\\theta}\\big(\\mathbf{z}_{t-1}\\big|\\mathbf{z}_{t},\\mathbf{c}_{\\theta}(y)\\big)$ . CFG [12] jointly learns a unconditional model $\\epsilon_{\\theta}(\\mathbf{z}_{t},t,\\mathbf{c}_{\\theta}(\\theta))$ with an empty condition $y=\\emptyset$ and a conditional model $\\epsilon_{\\theta}(\\mathbf{z}_{t},t,\\mathbf{c}_{\\theta}(y))$ , and combines them linearly to control the trade-off of sample quality and diversity in generation: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\hat{\\epsilon}_{\\theta}(\\mathbf{z}_{t},t,\\mathbf{c}_{\\theta}(y))=\\epsilon_{\\theta}(\\mathbf{z}_{t},t,\\mathbf{c}_{\\theta}(\\emptyset))+s\\left(\\epsilon_{\\theta}(\\mathbf{z}_{t},t,\\mathbf{c}_{\\theta}(y))-\\epsilon_{\\theta}(\\mathbf{z}_{t},t,\\mathbf{c}_{\\theta}(\\emptyset))\\right),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $s>1$ denotes the guidance scale. We adopt CFG by default with the training objective: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}_{\\mathrm{DM}}=\\mathbb{E}_{{\\mathbf{x}},{\\mathbf{y}},\\epsilon\\sim\\mathcal{N}(0,{\\mathbf{I}}),t\\sim\\mathcal{U}(1,T)}\\left[\\|\\epsilon-\\epsilon_{\\theta}\\left({\\mathbf{z}}_{t},t,{\\mathbf{c}}_{\\theta}(y)\\right)\\|_{2}^{2}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Condition Corruption. Ideally, each $y$ should accurately describe and match $\\mathbf{x}$ . However, in practice, due to errors from the collection of web-crawled datasets, conditions $y^{c}$ may un-match $\\mathbf{x}$ We define $(\\mathbf{x},y^{c})$ as pairs with condition corruption, and assume that $\\mathbf{c}_{\\theta}(y^{c})=\\mathbf{c}_{\\theta}(y;\\eta,\\pmb{\\xi})$ , where $\\xi$ denotes certain noise and $\\eta$ denotes corruption ratio that implicitly controls the noise magnitude. ", "page_idx": 2}, {"type": "text", "text": "3 Understanding the Pre-training Corruption in Diffusion Models ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we conduct the first comprehensive and practical study on pre-training DMs with condition corruption. Through holistic exploration with synthetically corrupted datasets, we reveal a surprising observation that slight pre-training corruption can be beneficial for DMs. ", "page_idx": 2}, {"type": "text", "text": "3.1 Pre-training Evaluation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Pre-training Setup. Here, we adopt Latent Diffusion Models (LDMs) [9] with the pre-trained VQ-VAE [58, 56] and a down-sampling factor of 4 for the latent space of observed data $\\mathbf{x}$ , denoted as LDM-4. More specifically, we train class-conditional and text-conditional LDM-4 from scratch on synthetically corrupted IN-1K [50] and CC3M [14], respectively, with a resolution of $256\\times256$ . We use a class embedding layer and a learnable pre-trained BERT [59] to compute the conditional embeddings of the IN-1K class labels and the CC3M text prompts. To introduce synthetic corruption into the conditions, we randomly filp the class label into a random class for IN-1K, and randomly swap the text of two sampled image-text pairs for CC3M, following [48, 49] (other corruption types studied in Section 3.3). We train models with different corruption ratios $\\eta\\in\\{0,2.5,5,7.5,10,15,20\\}\\%$ More details on synthetic corruption and pre-training recipes are shown in Appendix B.1 and B.3. ", "page_idx": 2}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/7fd452d7cb24406d6b1b9aa7fe3df0aabad36b3cd982f0eb11b460b695c64c82.jpg", "img_caption": ["(a) FID - IS, IN-1K (b) Prec. - Recall, IN-1K (c) FID - CS, CC3M (d) Prec. - Recall, CC3M Figure 3: Quantitative evaluation of generated images from class and text-conditional LDMs pre-trained with condition corruption. All metrics are computed over $50K$ generated images and validation images of IN-1K and MS-COCO. We plot FID vs. IS or CS ((a) and (c)) , and Precision vs. Recall ((b) and (d)), where each point indicates the results computed from using a guidance scale. Models pre-trained with slight condition corruption achieve better FID, IS or CS, and PR trade-off. "], "img_footnote": [], "page_idx": 3}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/e6f7d6123a0ae4fdcb8abda848b4eb10bba20d22421d969bbcde7b46ed64894f.jpg", "img_caption": ["Figure 4: Quantitative evaluation of complexity and diversity of class and text-conditional LDMs. We plot the top- $1\\%$ RMD score ((a) and (c)) which measures the complexity and diversity of samples (with $s=2.0$ and $s=3.0$ for IN-1K and CC3M LDMs), and the sample entropy ((b) and (d)) as a proxy measure of diversity, where each point indicates the result of a guidance scale. Models pre-trained with slight condition corruption generate samples of higher complexity and diversity. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Evaluation of Pre-trained Models. We directly use the pre-trained LDMs to generate images to study the effects of condition corruption in the pre-training stage. We use IN-1K class labels for class-conditional LDMs and MS-COCO text prompts [60] for text-conditional LDMs to generate 50K images and compare with the real validation images. The images are generated using a set of guidance scales $s\\in\\{1.5,2.0,\\ldots,10.0\\}$ and DPM [61] scheduler with 50 steps for faster inference speed4. We adopt Fr\u00e9chet Inception Distance (FID) [63], Inception Score (IS) [64], Precision, and Recall [65] to evaluate the quality, fidelity, and coverage of the generated images. For CC3M models, we use the CLIP score (CS) [66] to measure the similarity of the generated images and conditional text prompts. From the perspectives of sample complexity and diversity, we compute the top- $1\\%$ Relative Mahalanobis Distance (RMD) [67, 68], calculated from the estimated class-specific and class-agnostic distributions of generated data, and the sample entropy [69, 70], calculated from the VQ-VAE codebook. We also adopt other metrics, including sFID [71], TopPR F1 [72], average $L_{2}$ distance, and memorization ratio [73]. More details of the metrics used are shown in Appendix B.7. ", "page_idx": 3}, {"type": "text", "text": "Results. We present the main quantitative results of pre-training in Fig. 3 and 4, and the qualitative results in Fig. 5. More results are shown in Appendix C. In summary, we found that slight pretraining corruption5 can facilitate the quality, fidelity, and diversity of generated images: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Class and text-conditional models pre-trained with slight corruption achieve significantly lower FID and higher IS and CLIP score (Fig. 3(a) and 3(c)). They also present comparable and better Precision-Recall curves (Fig. 3(b) and 3(d)), compared to clean pre-trained models. \u2022 Models pre-trained with slight corruption generate images with higher complexity and diversity, with a right-shifted density of RMD (Fig. 4(a) and 4(c)), and larger entropy (Fig. 4(b) and 4(d)). \u2022 Qualitatively, models with slight corruption learn a more diverse distribution. Generated images present better variability in the circular walk around the latent space (Fig. 5(a) and 5(b)). ", "page_idx": 3}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/55e82b5c946edd076f044f61454fd81d7e58659475e115f728dae840d3c8377f.jpg", "img_caption": ["Figure 5: Qualitative evaluation of images generated from circular walk around the learned latent space using (a) class-conditional IN-1K LDMs and (b) text-conditional CC3M LDMs. Models pre-trained with slight condition corruption present more diversity in the learned distribution. ", "\u2022 More corruption in pre-training can potentially lead to quality and diversity degradation. As $\\eta$ increases, almost all metrics first improve and then degrade. However, the degraded measure with more corruption sometimes is still better than the clean ones (e.g. IS and Entropy). "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.2 Downstream Personalization Evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "A common scenario of DMs pre-trained on large-scale datasets is that they can be personalized and customized for more controllable generation [74, 75] after tuning on smaller datasets. Here, we also examine the effects of pre-training condition corruption of DMs at downstream personalization tasks. ", "page_idx": 4}, {"type": "text", "text": "Downstream Personalization Setup. We personalize the pre-trained LDMs with two common methods: ControlNet [20] and T2I-Adapter [21]. Both methods can enable the pre-trained DMs to generate more controllable images according to input spatial conditioning. For fair comparison, we automatically annotate the ImageNet-100 (IN-100) dataset to canny edges using the OpenCV canny detector [76] and segmentation masks using SegmentAnything (SAM) [77], similar to Zhang et al. [20]. For text-conditional LDMs, we additionally use BLIP [78] to generate MS-COCO-style text prompts for IN-100. We then fine-tune the LDMs on the annotated training set of IN-100. More details on the annotation and personalization setup are shown in Appendix B.2 and B.6, respectively. ", "page_idx": 4}, {"type": "text", "text": "Evaluation of Personalized Models. After tuning, we evaluate the personalized LDMs in the annotated validation set of IN-100. We mainly compute FID, IS, Precision, and Recall to compare the models. We similarly use a set of guidance scales to generate images, but only report results of the best guidance scale in this part due to space limit. The complete results are shown in Appendix D. ", "page_idx": 4}, {"type": "text", "text": "Results. Similarly, from the main results in Fig. 6 and Fig. 7, we found that slight pre-training corruption can also benefit the quality of generated images at downstream personalization: ", "page_idx": 4}, {"type": "text", "text": "\u2022 Slight pre-training corruption helps the personalized model generate images with lower FID (Fig. 6(a) and 6(c)) and higher IS score (Fig. 6(b) and 6(d)), whereas more corruption deteriorates. \u2022 Qualitatively, the personalization images from slight corruption pre-trained models also present more diversity, better fidelity with the input spatial controls, and higher quality. ", "page_idx": 4}, {"type": "text", "text": "3.3 Discussion: Other Types of Pre-training Corruption and Diffusion Models ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our previous studies mainly involve LDMs and symmetric random corruption. Here, we additionally study other types of corruption and DMs to verify that the above observations universally hold. ", "page_idx": 4}, {"type": "text", "text": "Condition Corruption. We consider asymmetric (Asym.) label corruption for IN-1K and Large Language Model (LLM) corruption for CC3M. For IN-1K, we introduce corruption only within the overlapped classes with CIFAR-100 [79], while maintaining others as clean. For CC3M, we prompt GPT-4 [80] to corrupt the texts. More details of the corruption are shown in Appendix B.1. ", "page_idx": 4}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/f9f0c28b77642594b5ed7065600501b0660b9ee4dcd4a178bd2018eb02da035b.jpg", "img_caption": ["(a) FID, IN-1K (b) IS, IN-1K (c) FID, CC3M (d) IS, CC3M Figure 6: Quantitative evaluation of ControlNet and T2I-Adapter personalized class and textconditional LDMs. FID ((a) and (c)) and IS ((b) and (d)) are computed using the 5K generated images. Slightly corrupted pre-trained models also present better performance in downstream personalization. "], "img_footnote": [], "page_idx": 5}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/c6c2e5f1d2784c9a70a78d5df423acc77fe34ee9839550fa86976421ae3a63df.jpg", "img_caption": ["Figure 7: Qualitative evaluation of ControlNet and T2I-Adapter (a) IN-1K and (b) CC3M LDMs. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Diffusion Models. LDMs utilize U-Net [81] as backbone and Cross-Attention for adding conditional information [9]. We pre-train class-conditional diffusion transformers on IN-1K for extra assessment, termed DiT-XL/2 [11], with Transformer [82] as backbone and adaptive LayerNorm [83\u201386] for conditional information. We also pre-train the recent text-conditional Latent Consistency Models (LCMs) [52, 51] on CC3M, which distill Stable Diffusion v1.5 [26] models to enable swift inference with minimal steps, noted as LCM-v1.5. Detailed setup is shown in Appendices B.4 and B.5. ", "page_idx": 5}, {"type": "text", "text": "Results. We present the main results in Fig. 2 due to the space limit. Full results are shown in Appendix C. We find that slight condition corruption of various types universally facilitates the performance of different DMs and consistently makes them outperform the clean pre-trained ones. ", "page_idx": 5}, {"type": "text", "text": "4 Theoretical Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we theoretically analyze condition corruption and find that slight corruption prevents the generated distribution from collapsing to the empirical distribution of the training data and encourages coverage of the entire data space, thereby enhancing diversity and alignment with the ground truth. We present a concise overview here and provide a comprehensive analysis in Appendix A. ", "page_idx": 5}, {"type": "text", "text": "Data Distribution. We concentrate on the prototypical problem of sampling from Gaussian mixture models (GMMs). Specifically, we consider the distribution of data $\\mathbf{x}\\in\\dot{\\mathbb{R}}^{d}$ that satisfies: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\mathbf{x}):=\\sum_{y\\in\\mathcal{Y}}w_{y}\\mathcal{N}(\\pmb{\\mu}_{y},\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $y$ denote class labels of a finite set $y\\in\\{1,\\ldots,|\\mathcal{Y}|\\}$ . Given any class, $\\mathbf{x}|y$ follows a Gaussian $\\mathcal{N}(\\mu_{y},\\mathbf{I})$ , and $w_{y}$ represents the weight of the Gaussian components which satisfies $\\textstyle\\sum_{y\\in{\\mathcal{y}}}w_{y}=1$ . ", "page_idx": 5}, {"type": "text", "text": "Denoising Networks and Condition Corruption. Inspired by recent works that also target on GMMs [87, 88] of DMs, we parameterize the denoising network as a piece-wise linear function: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\epsilon_{\\boldsymbol{\\theta}}(\\mathbf{x}_{t},y^{c})=\\sum_{k=1}^{|\\mathcal{V}|}\\mathbb{1}_{y^{c}=k}\\Big(\\mathbf{W}_{t}^{k}\\mathbf{x}_{t}+\\mathbf{V}_{t}^{k}\\mathbf{c}(y^{c})\\Big),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where ${\\bf c}(y^{c})$ is the one-hot encoding of corrupted label $y^{c}$ and $\\{\\mathbf{W}_{t}^{k},\\mathbf{V}_{t}^{k}\\}_{k=1}^{|\\mathcal{D}|}$ Vtk }|kY=|1 are trainable parameters. Specifically, following a line of existing work [89\u201391], we adopt a simpler label-noise model by adding Gaussian perturbation to the label embedding, perturbing the clean condition $\\mathbf{c}(y)$ with standard Gaussian noise $\\xi$ to obtain $\\mathbf{c}(y^{c})=\\mathbf{c}(y)+\\boldsymbol{\\gamma}\\pmb{\\xi}$ . Here, the corruption control parameter $\\gamma$ corresponds to the corruption ratio $\\eta$ for a more direct noise magnitude control. While our theoretical framework focuses on Gaussian noise, it can also be extended to distributions such as uniform. ", "page_idx": 6}, {"type": "text", "text": "4.1 Generation Diversity: Clean vs. Corrupted Conditions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We employ entropy to evaluate the diversity of generated images, following Wu et al. [70]. Higher entropy suggests a wider spread of data, yielding greater diversity in generated images, while lower entropy implies a more concentrated distribution with less diversity. We present Theorem 1, showing the difference in entropy between generations with corrupted and clean conditions: ", "page_idx": 6}, {"type": "text", "text": "Theorem 1. For any class $k\\in\\mathcal{V}$ and sufficiently large length $T$ , assuming the norm of corresponding expectation $\\|\\pmb{\\mu}_{k}\\|_{2}^{2}$ is a constant and the empirical covariance of training data is full rank, let ${\\bf z}_{T}$ and $\\mathbf{z}_{T}^{c}$ be the generation with clean and corrupted conditions respectively, then it holds that ", "page_idx": 6}, {"type": "equation", "text": "$$\nH(\\mathbf{z}_{T}^{c}|y=k)-H(\\mathbf{z}_{T}|y=k)=\\Theta(\\gamma^{2}d),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\gamma$ is the corruption control parameter and $d$ is the data dimension. ", "page_idx": 6}, {"type": "text", "text": "The proof is provided in Appendix A.4.1. Theorem 1 indicates that for any class $k$ , corrupted conditions enhance image diversity by increasing generation entropy. Moreover, with suitable $\\gamma$ values, image diversity can grow with noise, aligning with observations in Fig. 4. ", "page_idx": 6}, {"type": "text", "text": "4.2 Generation Quality: Clean vs. Corrupted Conditions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We then analyze why corrupted conditions benefti the quality of generated images, as also observed in Section 3.1. We employ the 2-Wasserstein distance as a metric to evaluate the sampling error between the true and the generated distributions, with clean and corrupted conditions. A distributed generated closer to the real data distribution indicates better image quality [63]. In Theorem 2, we analyze the difference in the quality of data generated by corrupted DMs and clean ones: ", "page_idx": 6}, {"type": "text", "text": "Theorem 2. For any $k\\in\\mathcal{V}$ and sufficiently large length $T$ , assuming the norm of corresponding expectation $\\|\\pmb{\\mu}_{k}\\|_{2}^{2}$ is constant, let $\\mathbb{P}_{;}$ , $\\mathbb{Q}_{\\mathbf{X}}$ and $\\mathbb{Q}_{\\mathbf{X}}^{c}$ be the ground truth, clean, and corrupted condition distributions over training data $\\mathbf{X}$ . Then $f\\gamma=\\operatorname{\\bar{O}}(1/{\\sqrt{\\operatorname*{max}_{k}n_{k}}})$ , it holds that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{X}}\\Big[\\mathcal{W}_{2}^{2}(\\mathbb{P},\\mathbb{Q}_{\\mathbf{X}})-\\mathcal{W}_{2}^{2}(\\mathbb{P},\\mathbb{Q}_{\\mathbf{X}}^{c})\\vert y=k\\Big]=\\Omega\\Big(\\frac{\\gamma^{2}d}{n_{k}}\\Big),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\mathcal{W}_{2}(\\cdot,\\cdot)$ denotes the 2-Wasserstein distance between two distributions, $n_{k}$ is the sample size of $k$ -labeled dataset, and $d$ is the data dimension. ", "page_idx": 6}, {"type": "text", "text": "Here the expectation is taken over the random sample of the training dataset from the data distribution. Detailed proof is shown in Appendix A.4.2. Theorem 2 reveals that for any class $k$ , small corruption yields generation distributions closer to the true distribution than clean ones. This partially verifies that the generation quality of the uncorrputly trained diffusion model can be improved by adding slight corruption to the training data. This is also well consistent with our empirical observation in Section 3.1, where the noise we used is approximately $0.04\\epsilon$ , close to the theoretical noise level of 0.03\u03f5, showing that the FID of the generated images can be improved with a small corruption. ", "page_idx": 6}, {"type": "text", "text": "5 Improving Diffusion Models with Conditional Embedding Perturbation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1 Method ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Our previous analysis demonstrates that slight condition corruption in the pre-training could potentially benefit both the image quality and diversity of DMs, which inspires us to improve the ", "page_idx": 6}, {"type": "table", "img_path": "VFpXYBqMSU/tmp/f18b5eba61f5cdea858f9496a022ec00c33a372712e000afc8cede5f6b34ca0a.jpg", "table_caption": ["Table 1: Pre-training results of IN-1K and MS-Table 2: ControlNet personalization results of COCO using diffusion models pre-trained with per-IN-100 using LDMs pre-trained with perturbaturbation. CEP achieves the best results (in bold). tion. CEP achieves the best results (in bold). "], "table_footnote": ["pre-training of DMs using this conclusion. In practice, it is usually infeasible to directly corrupt the conditions in the pre-training datasets either due to their large-scale nature or difficulties to select which conditions to corrupt. Instead, we propose to add the perturbation directly to the conditional embeddings of DMs, which is termed conditional embedding perturbation $\\scriptstyle(C E P)$ . Compared to the fixed proportion of condition corruption in datasets we studied before, CEP adds perturbation to every data instance during training on the fly. Specifically, CEP slightly modifies the DM objective: "], "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{DM}}=\\mathbb{E}_{{\\mathbf{x}},{y,\\epsilon}\\sim\\mathcal{N}(0,{\\mathbf{I}}),{t\\sim\\mathcal{U}(1,T)}}\\left[\\|\\epsilon-\\epsilon_{\\theta}\\left({\\mathbf{x}}_{t},t,{\\mathbf{c}}_{\\theta}(y)+\\delta\\right)\\|_{2}^{2}\\right],\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\delta$ denotes the perturbation added to conditional embeddings $\\mathbf{c}_{\\theta}(y)$ . We simply set the perturbation to Uniform, i.e., $\\begin{array}{r}{\\delta\\sim\\mathcal{U}\\left(-\\frac{\\gamma}{\\sqrt{d}}\\mathbf{I},\\frac{\\gamma}{\\sqrt{d}}\\mathbf{I}\\right)}\\end{array}$ , or to Gaussian, i.e., $\\begin{array}{r}{\\delta\\sim\\mathcal{N}\\left(0,\\frac{\\gamma}{\\sqrt{d}}\\mathbf{I}\\right)}\\end{array}$ , where the design of the factor $\\textstyle{\\frac{\\gamma}{\\sqrt{d}}}$ mainly follows previous works [82, 92\u201395], $d$ denotes the dimension of $\\mathbf{c}_{\\theta}(y)$ , and $\\gamma$ controls the perturbation magnitude, mimicing the corruption ratio $\\eta$ . The main purpose of CEP is to learn better DMs with perturbation on relatively clean and heavily flitered datasets, such as CC3M and IN-1K studied in this paper, but it is also applicable to slightly corrupted datasets. Recently, Ning et al. [96] found that adding input perturbations (IP) to latent variables $\\mathbf{z}_{t}$ during the forward process also helps diffusion training by mitigating exposure bias [97]. Compared to IP, CEP does not alter the marginal data distribution, but encourages the learned joint distribution to be more diverse. ", "page_idx": 7}, {"type": "text", "text": "5.2 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Setup. We pre-trained previous class-conditional LDM-4, text-conditional LDM-4, class-conditional DiT-XL/2, and text-conditional LCM-v1.5 with CEP, and compare with IP and clean pre-trained ones. We use both Uniform and Gaussian perturbation, denoted as CEP-U and CEP-G, respectively. We set $\\gamma=1$ for all models, with an ablation study with class-conditional LDM-4 with different $\\gamma\\mathbf{s}$ . ", "page_idx": 7}, {"type": "text", "text": "We evaluated the pre-trained class-conditional models on IN-1K and and text-conditional models on MS-COCO with FID, IS, Precision, and Recall. Additionally, we personalize the pre-trained LDMs with ControlNet on IN-100 to validate the effectiveness of CEP pre-training at downstream. ", "page_idx": 7}, {"type": "text", "text": "Results. We present the pre-training results of CEP in Table 1. CEP significantly and universally improves the performance for different class and text-conditional DMs, e.g., 2.53 and 1.25 FID improvement, and 42.31 and 10.27 IS improvement of LDM-4 and DiT-XL/2. CEP also improves precision and recall of DMs. In contrast, IP only achieves marginal improvement and yields slightly worse precision. Adopting CEP in pre-training also benefits the personalization tasks, especially for text-conditional LDMs, with FID improvement of 6.08 and 7.02 for Canny and SAM spatial control, as shown in Table 2. Qualitatively, as shown in Fig. 9, images generated from DMs with CEP also look more visually appealing and realistic. ", "page_idx": 7}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/b30e6d1dfa7b9d767327e62f67ac0f4b4d87b6d8b77097644e8c33ce0032268d.jpg", "img_caption": ["Figure 8: Ablation with LDM-4 IN-1K. (a) FID and average $L_{2}$ distance of conditional embeddings against clean ones with $\\gamma\\ =$ $\\{0.1,0.5,\\bar{1}.0,\\bar{5.0},10.0\\}$ , indicated by square points (left to right). We compare with fixed synthetic corruption $\\eta=\\{2.5,\\bar{5},10,15\\}\\%$ , shown by circle points. (b) CEP on corrupted IN-1K. ", "", ""], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/00ec2eddaae43324e930d7f982acfe283d7f5cd3ad8c789e21b42297f0db6f89.jpg", "img_caption": ["Figure 9: Comparison of DMs pre-trained with CEP against IP and without perturbation. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "The ablation results of $\\gamma$ are shown in Fig. 8(a). We also compare the average $L_{2}$ distance of CEP and fixed corruption against the clean condition embeddings. Interestingly, one can observe that CEP achieves a lower FID with more corruption in the embedding space (larger $L_{2}$ from the clean ones), demonstrating its effectiveness. CEP is applicable to slightly corrupted datasets that we may often encounter in practice, as shown in Fig. 8(b), where it also facilitates the performance significantly. ", "page_idx": 8}, {"type": "text", "text": "In addition, we also compare the proposed CEP with traditional regularization methods, such as Dropout [98] and Label Smoothing [99], and study the effects of fixed and random perturbation during training in Appendix E.3 and Appendix E.4. The results show that CEP is more effective. ", "page_idx": 8}, {"type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Diffusion Models. Inspired by thermodynamics, DMs were first proposed by Sohl-Dickstein et al. [100]. DMs have soon been developed into image generation with a fixed Gaussian noise diffusion process [1, 101]. Various techniques have then been proposed for more effective and efficient DMs [102, 4, 5]. One of the most well-known is modeling the diffusion process at the latent space of pre-trained image encoders as a strong prior [58, 56], instead of raw pixels spaces [3, 9, 11], which allows for high-quality image generation with affordable inference speed. Numerous foundational DMs that generate photorealistic images have thus been built [103\u2013107, 10, 108, 26, 109]. These powerful models are generally pre-trained on web-crawled billion-scale data with conditions (usually text), which may inevitably contain corruption [31, 110, 111, 32, 35]. Recently, consistency models [51, 112, 52] were also developed from DMs, allowing generation with much fewer inference steps. These foundational DMs also enabled many downstream applications [20, 21, 113\u2013122]. However, the effects of the pre-training corruption on downstream applications remain unknown. ", "page_idx": 8}, {"type": "text", "text": "Learning with Noise. Learning with noise is a long-standing challenge [123\u2013126]. Noisy label learning has been widely studied in classification, from noise correction [127, 40, 128\u2013131, 41, 132, 133, 43, 134, 44, 135] and noise-robust loss functions [39, 136\u2013141, 29, 142]. Learning with noise has also been studied in the context of generative models [143\u2013146]. Robust GANs and DMs [45\u201347] alleviated the quality degradation and condition misalignment of training generative models with label noise. In contrast, we study a more practical scenario, where the models are trained on corrupted pre-training data with a low noise ratio, and then adapted to downstream tasks. ", "page_idx": 8}, {"type": "text", "text": "In fact, more aligned with our work, there are several recent studies on exploring and exploiting the pre-training noise. Chen et al. [48, 49] found that slight label noise in supervised pre-training can be beneficial for in-domain downstream tasks, whereas detrimental for out-of-domain tasks. NoisyTune [147], NEFTune [95], and SymNoise [148] found that introducing noise to the weights and embedding of pre-trained language models can facilitate downstream performance. Ning et al. [96] also found that adding perturbation in the forward diffusion process helps reduce the exposure bias of DMs [97]. Similarly, Naderi et al. [149] introduced noise into the input of image translation networks for better learning with limited data. Synthetic data (potentially with corruption) have also been found to be useful in pre-training [24, 150]. We demonstrate that slight corruption in conditions of the pre-training DMs can also be beneficial at both the pre-training and downstream. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "7 Conclusion and Limitation ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We presented the first comprehensive study on condition corruption in pre-training of DMs. Our empirical and theoretical analysis surprisingly demonstrate that slight condition corruption benefits DMs in both the pre-training and downstream adaptation, based on which we proposed CEP as a simple yet general technique that significantly improves the performance of DMs. We hope our findings could inspire more future work on understanding the pre-training data of foundation models. ", "page_idx": 9}, {"type": "text", "text": "This work has the following limitations. First, due to a lack of computing resources, we cannot study all types of DMs on larger datasets. Second, the theoretical analysis is based on several assumptions that might be further explored in the future. Third, the evaluation of image generation remains an open question, and we used most of the existing criteria for fair comparison. ", "page_idx": 9}, {"type": "text", "text": "Disclaimer ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "While we study DMs for image generation in this paper, it is important to note that all generations have been selected and verified by human experts to ensure that they are responsible. Although we release all the pre-trained models under different corruption settings, it is possible that these models will generate inappropriate content due to the scale of pre-training and without alignment with human preferences. The main purpose of this research is to raise the awareness of the community on data cleaning and corruption in the research of diffusion models. ", "page_idx": 9}, {"type": "text", "text": "Acknowledge ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "MS was supported by the Institute for AI and Beyond, UTokyo. DZ was supported by NSFC 62306252, Guangdong NSF 2024A1515012444, and Hong Kong ECS awards 27309624. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. Advances in neural information processing systems, 33:6840\u20136851, 2020. [2] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In International Conference on Learning Representations, 2021. [3] Arash Vahdat, Karsten Kreis, and Jan Kautz. Score-based generative modeling in latent space. Advances in Neural Information Processing Systems, 34:11287\u201311302, 2021. [4] Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. Advances in neural information processing systems, 34:8780\u20138794, 2021. [5] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. Advances in Neural Information Processing Systems, 35:26565\u201326577, 2022. [6] Haohe Liu, Zehua Chen, Yi Yuan, Xinhao Mei, Xubo Liu, Danilo Mandic, Wenwu Wang, and Mark D Plumbley. AudioLDM: Text-to-audio generation with latent diffusion models. Proceedings of the International Conference on Machine Learning, 2023. [7] Muqiao Yang, Chunlei Zhang, Yong Xu, Zhongweiyang Xu, Heming Wang, Bhiksha Raj, and Dong Yu. usee: Unified speech enhancement and editing with conditional diffusion models. In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 7125\u20137129. IEEE, 2024. [8] Jonathan Ho, Tim Salimans, Alexey Gritsenko, William Chan, Mohammad Norouzi, and David J Fleet. Video diffusion models. Advances in Neural Information Processing Systems, 35:8633\u20138646, 2022. [9] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10684\u201310695, 2022.   \n[10] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton, Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al. Photorealistic text-to-image diffusion models with deep language understanding. Advances in neural information processing systems, 35:36479\u201336494, 2022.   \n[11] William Peebles and Saining Xie. Scalable diffusion models with transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4195\u20134205, 2023.   \n[12] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022.   \n[13] Bart Thomee, David A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64\u201373, 2016.   \n[14] Piyush Sharma, Nan Ding, Sebastian Goodman, and Radu Soricut. Conceptual captions: A cleaned, hypernymed, image alt-text dataset for automatic image captioning. In Proceedings of ACL, 2018.   \n[15] Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut. Conceptual 12M: Pushing web-scale image-text pre-training to recognize long-tail visual concepts. In CVPR, 2021.   \n[16] Christoph Schuhmann, Richard Vencu, Romain Beaumont, Robert Kaczmarczyk, Clayton Mullis, Aarush Katta, Theo Coombes, Jenia Jitsev, and Aran Komatsuzaki. Laion-400m: Open dataset of clip-filtered 400 million image-text pairs. Advances in Neural Information Processing Systems, 2021.   \n[17] Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, et al. Laion5b: An open large-scale dataset for training next generation image-text models. Advances in Neural Information Processing Systems, 35:25278\u201325294, 2022.   \n[18] Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit H Bermano, Gal Chechik, and Daniel Cohen-Or. An image is worth one word: Personalizing text-to-image generation using textual inversion. arXiv preprint arXiv:2208.01618, 2022.   \n[19] Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman. Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22500\u201322510, 2023.   \n[20] Lvmin Zhang, Anyi Rao, and Maneesh Agrawala. Adding conditional control to text-to-image diffusion models. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 3836\u20133847, 2023.   \n[21] Chong Mou, Xintao Wang, Liangbin Xie, Yanze Wu, Jian Zhang, Zhongang Qi, Ying Shan, and Xiaohu Qie. T2i-adapter: Learning adapters to dig out more controllable ability for text-to-image diffusion models. arXiv preprint arXiv:2302.08453, 2023.   \n[22] Shihao Zhao, Dongdong Chen, Yen-Chun Chen, Jianmin Bao, Shaozhe Hao, Lu Yuan, and Kwan-Yee K Wong. Uni-controlnet: All-in-one control to text-to-image diffusion models. Advances in Neural Information Processing Systems, 36, 2024.   \n[23] Ruifei He, Shuyang Sun, Xin Yu, Chuhui Xue, Wenqing Zhang, Philip Torr, Song Bai, and Xiaojuan Qi. Is synthetic data from generative models ready for image recognition? arXiv preprint arXiv:2210.07574, 2022.   \n[24] Lijie Fan, Kaifeng Chen, Dilip Krishnan, Dina Katabi, Phillip Isola, and Yonglong Tian. Scaling laws of synthetic images for model training... for now. arXiv preprint arXiv:2312.04567, 2023.   \n[25] Yonglong Tian, Lijie Fan, Phillip Isola, Huiwen Chang, and Dilip Krishnan. Stablerep: Synthetic images from text-to-image models make strong visual representation learners. Advances in Neural Information Processing Systems, 36, 2024.   \n[26] Stability AI. Stable diffusion. Software available from Stability AI, 2022.   \n[27] Url https://commoncrawl.org/.   \n[28] Samir Yitzhak Gadre, Gabriel Ilharco, Alex Fang, Jonathan Hayase, Georgios Smyrnis, Thao Nguyen, Ryan Marten, Mitchell Wortsman, Dhruba Ghosh, Jieyu Zhang, et al. Datacomp: In search of the next generation of multimodal datasets. Advances in Neural Information Processing Systems, 36, 2024.   \n[29] Curtis G. Northcutt, Lu Jiang, and Isaac L. Chuang. Confident learning: Estimating uncertainty in dataset labels. Journal of Artificial Intelligence Research, 70:1373\u20131411, 2021.   \n[30] Vijay Vasudevan, Benjamin Caine, Raphael Gontijo Lopes, Sara Fridovich-Keil, and Rebecca Roelofs. When does dough become a bagel? analyzing the remaining mistakes on imagenet. Advances in Neural Information Processing Systems, 35:6720\u20136734, 2022.   \n[31] Brian Gordon, Yonatan Bitton, Yonatan Shafir, Roopal Garg, Xi Chen, Dani Lischinski, Daniel Cohen-Or, and Idan Szpektor. Mismatch quest: Visual and textual feedback for image-text misalignment. arXiv preprint arXiv:2312.03766, 2023.   \n[32] Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhilasha Ravichander, Dustin Schwenk, Alane Suhr, Pete Walsh, Dirk Groeneveld, Luca Soldaini, Sameer Singh, et al. What\u2019s in my big data? arXiv preprint arXiv:2310.20707, 2023.   \n[33] Eric Frankel and Edward Vendrow. Fair generation through prior modification. In 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), 2020.   \n[34] Melissa Hall, Laurens van der Maaten, Laura Gustafson, Maxwell Jones, and Aaron Adcock. A systematic study of bias amplification. arXiv preprint arXiv:2201.11706, 2022.   \n[35] Hao Chen, Bhiksha Raj, Xing Xie, and Jindong Wang. On catastrophic inheritance of large foundation models. arXiv preprint arXiv:2402.01909, 2024.   \n[36] Amirhossein Kazerouni, Ehsan Khodapanah Aghdam, Moein Heidari, Reza Azad, Mohsen Fayyaz, Ilker Hacihaliloglu, and Dorit Merhof. Diffusion models in medical imaging: A comprehensive survey. Medical Image Analysis, page 102846, 2023.   \n[37] Xiaofan Li, Yifu Zhang, and Xiaoqing Ye. Drivingdiffusion: Layout-guided multi-view driving scene video generation with latent diffusion model. arXiv preprint arXiv:2310.07771, 2023.   \n[38] Chiyu Jiang, Andre Cornman, Cheolho Park, Benjamin Sapp, Yin Zhou, Dragomir Anguelov, et al. Motiondiffuser: Controllable multi-agent motion prediction using diffusion. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9644\u20139653, 2023.   \n[39] Aritra Ghosh, Himanshu Kumar, and P. Shanti Sastry. Robust loss functions under label noise for deep neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence, 2017.   \n[40] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Wai-Hung Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. Advances in Neural Information Processing Systems, 2018.   \n[41] Junnan Li, Richard Socher, and Steven C.H. Hoi. Dividemix: Learning with noisy labels as semi-supervised learning. In International Conference on Learning Representations, 2020.   \n[42] Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. Provably end-to-end label-noise learning without anchor points. In International Conference on Machine Learning, pages 6403\u20136413. PMLR, 2021.   \n[43] Sheng Liu, Zhihui Zhu, Qing Qu, and Chong You. Robust training under label noise by over-parameterization. In Kamalika Chaudhuri, Stefanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato, editors, Proceedings of the International Conference on Machine Learning, volume 162, pages 14153\u201314172. PMLR, 17\u201323 Jul 2022.   \n[44] Hao Chen, Ankit Shah, Jindong Wang, Ran Tao, Yidong Wang, Xing Xie, Masashi Sugiyama, Rita Singh, and Bhiksha Raj. Imprecise label learning: A unified framework for learning with various imprecise label configurations. arXiv preprint arXiv:2305.12715, 2023.   \n[45] Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh. Robustness of conditional gans to noisy labels. Advances in neural information processing systems, 31, 2018.   \n[46] Takuhiro Kaneko, Yoshitaka Ushiku, and Tatsuya Harada. Label-noise robust generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 2467\u20132476, 2019.   \n[47] Byeonghu Na, Yeongmin Kim, HeeSun Bae, Jung Hyun Lee, Se Jung Kwon, Wanmo Kang, and Il-Chul Moon. Label-noise robust diffusion models. arXiv preprint arXiv:2402.17517, 2024.   \n[48] Hao Chen, Jindong Wang, Ankit Shah, Ran Tao, Hongxin Wei, Xing Xie, Masashi Sugiyama, and Bhiksha Raj. Understanding and mitigating the label noise in pre-training on downstream tasks. In International Conference on Learning Representations (ICLR), 2024.   \n[49] Hao Chen, Jindong Wang, Zihan Wang, Ran Tao, Hongxin Wei, Xing Xie, Masashi Sugiyama, and Bhiksha Raj. Learning with noisy foundation models. arXiv preprint arXiv:2403.06869, 2024.   \n[50] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. Advances in Neural Information Processing Systems, 25, 2012.   \n[51] Yang Song, Prafulla Dhariwal, Mark Chen, and Ilya Sutskever. Consistency models. arXiv preprint arXiv:2303.01469, 2023.   \n[52] Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang Zhao. Latent consistency models: Synthesizing high-resolution images with few-step inference. arXiv preprint arXiv:2310.04378, 2023.   \n[53] Ali Borji. Pros and cons of gan evaluation measures: New developments. Computer Vision and Image Understanding, 215:103329, 2022.   \n[54] Eyal Betzalel, Coby Penso, Aviv Navon, and Ethan Fetaya. A study on the evaluation of generative models. arXiv preprint arXiv:2206.10935, 2022.   \n[55] Tony Lee, Michihiro Yasunaga, Chenlin Meng, Yifan Mai, Joon Sung Park, Agrim Gupta, Yunzhi Zhang, Deepak Narayanan, Hannah Teufel, Marco Bellagente, et al. Holistic evaluation of text-to-image models. Advances in Neural Information Processing Systems, 36, 2024.   \n[56] Patrick Esser, Robin Rombach, and Bjorn Ommer. Taming transformers for high-resolution image synthesis. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 12873\u201312883, 2021.   \n[57] Diederik Kingma and Ruiqi Gao. Understanding diffusion objectives as the elbo with simple data augmentation. Advances in Neural Information Processing Systems, 36, 2024.   \n[58] Aaron Van Den Oord, Oriol Vinyals, et al. Neural discrete representation learning. Advances in Neural Information Processing Systems, 30, 2017.   \n[59] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.   \n[60] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part V 13, pages 740\u2013755. Springer, 2014.   \n[61] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. Dpm-solver: A fast ode solver for diffusion probabilistic model sampling in around 10 steps. Advances in Neural Information Processing Systems, 35:5775\u20135787, 2022.   \n[62] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. arXiv preprint arXiv:2010.02502, 2020.   \n[63] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances in Neural Information Processing Systems, 30, 2017.   \n[64] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. Advances in Neural Information Processing Systems, 29, 2016.   \n[65] Tuomas Kynk\u00e4\u00e4nniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved precision and recall metric for assessing generative models. Advances in neural information processing systems, 32, 2019.   \n[66] Jack Hessel, Ari Holtzman, Maxwell Forbes, Ronan Le Bras, and Yejin Choi. Clipscore: A reference-free evaluation metric for image captioning. arXiv preprint arXiv:2104.08718, 2021.   \n[67] Peng Cui, Dan Zhang, Zhijie Deng, Yinpeng Dong, and Jun Zhu. Learning sample difficulty from pre-trained models for reliable prediction. Advances in Neural Information Processing Systems, 36, 2024.   \n[68] Minhyuk Seo, Diganta Misra, Seongwon Cho, Minjae Lee, and Jonghyun Choi. Just say the name: Online continual learning with category names only via data generation. arXiv preprint arXiv:2403.10853, 2024.   \n[69] Claude Elwood Shannon. A mathematical theory of communication. ACM SIGMOBILE mobile computing and communications review, 5(1):3\u201355, 2001.   \n[70] Yuchen Wu, Minshuo Chen, Zihao Li, Mengdi Wang, and Yuting Wei. Theoretical insights for diffusion guidance: A case study for gaussian mixture models. arXiv preprint arXiv:2403.01639, 2024.   \n[71] Charlie Nash, Jacob Menick, Sander Dieleman, and Peter W Battaglia. Generating images with sparse representations. In International Conference on Machine Learning, 2021.   \n[72] Pum Jun Kim, Yoojin Jang, Jisu Kim, and Jaejun Yoo. Topp&r: Robust support estimation approach for evaluating fidelity and diversity in generative models. Advances in Neural Information Processing Systems, 36, 2024.   \n[73] Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramer, Borja Balle, Daphne Ippolito, and Eric Wallace. Extracting training data from diffusion models. In 32nd USENIX Security Symposium (USENIX Security 23), pages 5253\u20135270, 2023.   \n[74] Pu Cao, Feng Zhou, Qing Song, and Lu Yang. Controllable generation with text-to-image diffusion models: A survey. arXiv preprint arXiv:2403.04279, 2024.   \n[75] Xulu Zhang, Xiao-Yong Wei, Wengyu Zhang, Jinlin Wu, Zhaoxiang Zhang, Zhen Lei, and Qing Li. A survey on personalized content synthesis with diffusion models. arXiv preprint arXiv:2405.05538, 2024.   \n[76] Itseez. Open source computer vision library. https://github.com/itseez/opencv, 2015.   \n[77] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al. Segment anything. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 4015\u20134026, 2023.   \n[78] Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. Blip: Bootstrapping languageimage pre-training for unified vision-language understanding and generation. In International conference on machine learning, pages 12888\u201312900. PMLR, 2022.   \n[79] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[80] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774, 2023.   \n[81] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In Medical image computing and computer-assisted intervention\u2013MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18, pages 234\u2013241. Springer, 2015.   \n[82] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.   \n[83] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.   \n[84] Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reasoning with a general conditioning layer. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018.   \n[85] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018.   \n[86] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4401\u20134410, 2019.   \n[87] Sitan Chen, Vasilis Kontonis, and Kulin Shah. Learning general gaussian mixtures with efficient score matching. arXiv preprint arXiv:2404.18893, 2024.   \n[88] Khashayar Gatmiry, Jonathan Kelner, and Holden Lee. Learning mixtures of gaussians using diffusion models. arXiv preprint arXiv:2404.18869, 2024.   \n[89] Wei Hu, Zhiyuan Li, and Dingli Yu. Simple and effective regularization methods for training on noisily labeled data with generalization guarantee. arXiv preprint arXiv:1905.11368, 2019.   \n[90] Yu-Hang Tang, Yuanran Zhu, and Wibe A de Jong. Detecting label noise via leave-one-out cross-validation. arXiv preprint arXiv:2103.11352, 2021.   \n[91] Jeremy Speth and Emily M Hand. Automated label noise identification for facial attribute recognition. In CVPR Workshops, pages 25\u201328, 2019.   \n[92] Chen Zhu, Yu Cheng, Zhe Gan, Siqi Sun, Tom Goldstein, and Jingjing Liu. Freelb: Enhanced adversarial training for natural language understanding. arXiv preprint arXiv:1909.11764, 2019.   \n[93] Kezhi Kong, Guohao Li, Mucong Ding, Zuxuan Wu, Chen Zhu, Bernard Ghanem, Gavin Taylor, and Tom Goldstein. Robust optimization as data augmentation for large-scale graphs. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 60\u201369, 2022.   \n[94] David Nukrai, Ron Mokady, and Amir Globerson. Text-only training for image captioning using noise-injected clip. arXiv preprint arXiv:2211.00575, 2022.   \n[95] Neel Jain, Ping-yeh Chiang, Yuxin Wen, John Kirchenbauer, Hong-Min Chu, Gowthami Somepalli, Brian R Bartoldson, Bhavya Kailkhura, Avi Schwarzschild, Aniruddha Saha, et al. Neftune: Noisy embeddings improve instruction finetuning. arXiv preprint arXiv:2310.05914, 2023.   \n[96] Mang Ning, Enver Sangineto, Angelo Porrello, Simone Calderara, and Rita Cucchiara. Input perturbation reduces exposure bias in diffusion models. arXiv preprint arXiv:2301.11706, 2023.   \n[97] Mang Ning, Mingxiao Li, Jianlin Su, Albert Ali Salah, and Itir Onal Ertugrul. Elucidating the exposure bias in diffusion models. arXiv preprint arXiv:2308.15321, 2023.   \n[98] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. The journal of machine learning research, 15(1):1929\u20131958, 2014.   \n[99] Rafael M\u00fcller, Simon Kornblith, and Geoffrey E Hinton. When does label smoothing help? Advances in neural information processing systems, 32, 2019.   \n[100] Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In International Conference on Machine Learning, pages 2256\u20132265. PMLR, 2015.   \n[101] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. arXiv preprint arXiv:2011.13456, 2020.   \n[102] Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In International Conference on Machine Learning, pages 8162\u20138171. PMLR, 2021.   \n[103] Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. Glide: Towards photorealistic image generation and editing with text-guided diffusion models. arXiv preprint arXiv:2112.10741, 2021.   \n[104] Ming Ding, Zhuoyi Yang, Wenyi Hong, Wendi Zheng, Chang Zhou, Da Yin, Junyang Lin, Xu Zou, Zhou Shao, Hongxia Yang, et al. Cogview: Mastering text-to-image generation via transformers. Advances in Neural Information Processing Systems, 34:19822\u201319835, 2021.   \n[105] Ming Ding, Wendi Zheng, Wenyi Hong, and Jie Tang. Cogview2: Faster and better text-toimage generation via hierarchical transformers. Advances in Neural Information Processing Systems, 35:16890\u201316902, 2022.   \n[106] Wendi Zheng, Jiayan Teng, Zhuoyi Yang, Weihan Wang, Jidong Chen, Xiaotao Gu, Yuxiao Dong, Ming Ding, and Jie Tang. Cogview3: Finer and faster text-to-image generation via relay diffusion. arXiv preprint arXiv:2403.05121, 2024.   \n[107] Oran Gafni, Adam Polyak, Oron Ashual, Shelly Sheynin, Devi Parikh, and Yaniv Taigman. Make-a-scene: Scene-based text-to-image generation with human priors. In European Conference on Computer Vision, pages 89\u2013106. Springer, 2022.   \n[108] Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, Mark Chen, and Ilya Sutskever. Zero-shot text-to-image generation. In International conference on machine learning, pages 8821\u20138831. Pmlr, 2021.   \n[109] MidJourney Inc. Midjourney. Software available from MidJourney Inc., 2022.   \n[110] Ryan Webster, Julien Rabin, Loic Simon, and Frederic Jurie. On the de-duplication of laion-2b. arXiv preprint arXiv:2303.12733, 2023.   \n[111] Gowthami Somepalli, Vasu Singla, Micah Goldblum, Jonas Geiping, and Tom Goldstein. Understanding and mitigating copying in diffusion models. Advances in Neural Information Processing Systems, 36:47783\u201347803, 2023.   \n[112] Yang Song and Prafulla Dhariwal. Improved techniques for training consistency models. arXiv preprint arXiv:2310.14189, 2023.   \n[113] Chenlin Meng, Yutong He, Yang Song, Jiaming Song, Jiajun Wu, Jun-Yan Zhu, and Stefano Ermon. Sdedit: Guided image synthesis and editing with stochastic differential equations. arXiv preprint arXiv:2108.01073, 2021.   \n[114] Tim Brooks, Aleksander Holynski, and Alexei A Efros. Instructpix2pix: Learning to follow image editing instructions. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 18392\u201318402, 2023.   \n[115] Nisha Huang, Fan Tang, Weiming Dong, Tong-Yee Lee, and Changsheng Xu. Region-aware diffusion for zero-shot text-driven image editing. arXiv preprint arXiv:2302.11797, 2023.   \n[116] Narek Tumanyan, Michal Geyer, Shai Bagon, and Tali Dekel. Plug-and-play diffusion features for text-driven image-to-image translation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1921\u20131930, 2023.   \n[117] Andrey Voynov, Kfir Aberman, and Daniel Cohen-Or. Sketch-guided text-to-image diffusion models. In ACM SIGGRAPH 2023 Conference Proceedings, pages 1\u201311, 2023.   \n[118] Nisha Huang, Yuxin Zhang, Fan Tang, Chongyang Ma, Haibin Huang, Weiming Dong, and Changsheng Xu. Diffstyler: Controllable dual diffusion for text-driven image stylization. IEEE Transactions on Neural Networks and Learning Systems, 2024.   \n[119] Lianghua Huang, Di Chen, Yu Liu, Yujun Shen, Deli Zhao, and Jingren Zhou. Composer: Creative and controllable image synthesis with composable conditions. arXiv preprint arXiv:2302.09778, 2023.   \n[120] Dina Bashkirova, Jos\u00e9 Lezama, Kihyuk Sohn, Kate Saenko, and Irfan Essa. Masksketch: Unpaired structure-guided masked image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1879\u20131889, 2023.   \n[121] Omer Bar-Tal, Lior Yariv, Yaron Lipman, and Tali Dekel. Multidiffusion: Fusing diffusion paths for controlled image generation. 2023.   \n[122] Yuheng Li, Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li, and Yong Jae Lee. Gligen: Open-set grounded text-to-image generation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 22511\u201322521, 2023.   \n[123] Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Ravikumar, and Ambuj Tewari. Learning with noisy labels. Advances in Neural Information Processing Systems, 26, 2013.   \n[124] Bo Han, Quanming Yao, Tongliang Liu, Gang Niu, Ivor W Tsang, James T Kwok, and Masashi Sugiyama. A survey of label-noise representation learning: Past, present and future. arXiv preprint arXiv:2011.04406, 2020.   \n[125] G\u00f6rkem Algan and Ilkay Ulusoy. Image classification with deep learning in the presence of noisy labels: A survey. Knowledge-Based Systems, 215:106771, 2021.   \n[126] Hwanjun Song, Minseok Kim, Dongmin Park, Yooju Shin, and Jae-Gil Lee. Learning from noisy labels with deep neural networks: A survey. IEEE transactions on neural networks and learning systems, 2022.   \n[127] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with extremely noisy labels. Advances in Neural Information Processing Systems, 31, 2018.   \n[128] Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama. How does disagreement help generalization against label corruption? In International Conference on Machine Learning, pages 7164\u20137173. PMLR, 2019.   \n[129] Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi Sugiyama. Are anchor points really indispensable in label-noise learning? Advances in Neural Information Processing Systems, 32, 2019.   \n[130] Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent label noise. Advances in Neural Information Processing Systems, 33:7597\u20137610, 2020.   \n[131] Hongxin Wei, Lei Feng, Xiangyu Chen, and Bo An. Combating noisy labels by agreement: A joint training method with co-regularization. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 13726\u201313735, 2020.   \n[132] Lei Feng, Senlin Shu, Zhuoyi Lin, Fengmao Lv, Li Li, and Bo An. Can cross entropy loss be robust to label noise? In Proceedings of the twenty-ninth international conference on international joint conferences on artificial intelligence, pages 2206\u20132212, 2021.   \n[133] Yivan Zhang, Gang Niu, and Masashi Sugiyama. Learning noise transition matrix from only noisy labels via total variation regularization. In International Conference on Machine Learning, pages 12501\u201312512. PMLR, 2021.   \n[134] Shuo Yang, Erkun Yang, Bo Han, Yang Liu, Min Xu, Gang Niu, and Tongliang Liu. Estimating instance-dependent bayes-label transition matrix using a deep neural network. In International Conference on Machine Learning, pages 25302\u201325312. PMLR, 2022.   \n[135] Hongxin Wei, Huiping Zhuang, Renchunzi Xie, Lei Feng, Gang Niu, Bo An, and Yixuan Li. Mitigating memorization of noisy labels by clipping the model prediction. In International Conference on Machine Learning, pages 36868\u201336886. PMLR, 2023.   \n[136] Zhilu Zhang and Mert Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. Advances in Neural Information Processing Systems, 31, 2018.   \n[137] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetric cross entropy for robust learning with noisy labels. Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 322\u2013330, 2019.   \n[138] Xingjun Ma, Hanxun Huang, Yisen Wang, Simone Romano, Sarah Monazam Erfani, and James Bailey. Normalized loss functions for deep learning with noisy labels. In Proceedings of the International Conference on Machine Learning, 2020.   \n[139] Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy labeled data for image classification. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2691\u20132699, 2015.   \n[140] Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adaptation layer. In International Conference on Learning Representations, 2016.   \n[141] Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Earlylearning regularization prevents memorization of noisy labels. Advances in Neural Information Processing Systems, 33, 2020.   \n[142] X. Li, T. Liu, B. Han, G. Niu, and M. Sugiyama. Provably end-to-end label-noise learning without anchor points. In Proceedings of 38th International Conference on Machine Learning, pages 6403\u20136413, 2021.   \n[143] Kiran Koshy Thekumparampil, Sewoong Oh, and Ashish Khetan. Robust conditional gans under missing or uncertain labels. arXiv preprint arXiv:1906.03579, 2019.   \n[144] Sandhya Tripathi and N Hemachandra. Gans for learning from very high class conditional noisy labels. arXiv preprint arXiv:2010.09577, 2020.   \n[145] Takuhiro Kaneko and Tatsuya Harada. Blur, noise, and compression robust generative adversarial networks. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13579\u201313589, 2021.   \n[146] Lizhen Deng, Chunming He, Guoxia Xu, Hu Zhu, and Hao Wang. Pcgan: A noise robust conditional generative adversarial network for one shot learning. IEEE Transactions on Intelligent Transportation Systems, 23(12):25249\u201325258, 2022.   \n[147] Chuhan Wu, Fangzhao Wu, Tao Qi, Yongfeng Huang, and Xing Xie. Noisytune: A little noise can help you finetune pretrained language models better. arXiv preprint arXiv:2202.12024, 2022.   \n[148] Arjun Singh and Abhay Kumar Yadav. Symnoise: Advancing language model fine-tuning with symmetric noise. arXiv preprint arXiv:2312.01523, 2023.   \n[149] Mohammadreza Naderi, Nader Karimi, Ali Emami, Shahram Shirani, and Shadrokh Samavi. Dynamic-pix2pix: Medical image segmentation by injecting noise to cgan for modeling input and target domain joint distributions with limited training data. Biomedical Signal Processing and Control, 85:104877, 2023.   \n[150] Pavan Kumar Anasosalu Vasu, Hadi Pouransari, Fartash Faghri, and Oncel Tuzel. Clip with quality captions: A strong pretraining for vision tasks. 2024.   \n[151] Hongrui Chen, Holden Lee, and Jianfeng Lu. Improved analysis of score-based generative modeling: User-friendly bounds under minimal smoothness assumptions. In International Conference on Machine Learning, pages 4735\u20134763. PMLR, 2023.   \n[152] Sitan Chen, Sinho Chewi, Jerry Li, Yuanzhi Li, Adil Salim, and Anru R Zhang. Sampling is as easy as learning the score: theory for diffusion models with minimal data assumptions. arXiv preprint arXiv:2209.11215, 2022.   \n[153] Xuefeng Gao, Hoang M Nguyen, and Lingjiong Zhu. Wasserstein convergence guarantees for a general class of score-based generative models. arXiv preprint arXiv:2311.11003, 2023.   \n[154] Christiane Fellbaum. WordNet: An electronic lexical database. MIT press, 1998.   \n[155] Patrick von Platen, Suraj Patil, Anton Lozhkov, Pedro Cuenca, Nathan Lambert, Kashif Rasul, Mishig Davaadorj, Dhruv Nair, Sayak Paul, William Berman, Yiyi Xu, Steven Liu, and Thomas Wolf. Diffusers: State-of-the-art diffusion models. https://github.com/huggingface/ diffusers, 2022.   \n[156] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2818\u20132826, 2016.   \n[157] Alec Radford, Jong Wook Kim, Chris Hallacy, A. Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, 2021.   \n[158] Xiangming Gu, Chao Du, Tianyu Pang, Chongxuan Li, Min Lin, and Ye Wang. On memorization in diffusion models. arXiv preprint arXiv:2310.02664, 2023.   \n[159] TaeHo Yoon, Joo Young Choi, Sehyun Kwon, and Ernest K Ryu. Diffusion probabilistic models generalize when they fail to memorize. In ICML 2023 Workshop on Structured Probabilistic Inference Generative Modeling, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Contents ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "A Derivations and Proofs 22 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "A.1 Preliminaries 22   \nA.2 The Estimation of Conditional Score 23   \nA.3 The Distribution of Generation 26   \nA.4 Diversity and Quality: Clean vs. Corrupted Conditions 30 ", "page_idx": 20}, {"type": "text", "text": "B Details of Condition Corruption, Model Training and Evaluation 33 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "B.1 Synthetic Condition Corruption . . . 33   \nB.2 Automatic ImageNet-100 Annotation 33   \nB.3 LDM Pre-training Setup . . . . . 34   \nB.4 DiT Pre-training Setup . . . . . 34   \nB.5 LCM Pre-training Setup . . 35   \nB.6 ControlNet and T2I-Adapter Personalization Setup . . 35   \nB.7 Evaluation Metrics 35 ", "page_idx": 20}, {"type": "text", "text": "C Full Results of Pre-training Evaluation 36 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "C.1 Quantitative Results 36   \nC.2 Qualitative Results 38 ", "page_idx": 20}, {"type": "text", "text": "D Full Results of Downstream Personalization Evaluation 39 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "D.1 Quantitative Results 39   \nD.2 Qualitative Results 39 ", "page_idx": 20}, {"type": "text", "text": "E Full Results of Conditional Embedding Perturbation 40 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "E.1 Qualitative Results 40   \nE.2 Ablation Study 40   \nE.3 Comparison with Dropout and Label Smoothing . . 40   \nE.4 Comparison with Fixed and Random Corruption . . 40 ", "page_idx": 20}, {"type": "text", "text": "A Derivations and Proofs ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we theoretically investigate the behavior of condition corruption on DMs. Our investigation encompasses the DDIM samplers with continuous-time processes. We focus on how slight conditional embedding corruption can affect the training process of DMs, as well as the consequences on the generative process. As our theoretical analysis indicates, slight conditional embedding corruption will benefit both the generation quality and diversity, which aligns with the experimental conclusions in Section 3. ", "page_idx": 21}, {"type": "text", "text": "A.1 Preliminaries ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We start by giving a concise overview of the problem setup. ", "page_idx": 21}, {"type": "text", "text": "Data Distribution. For precise theoretical characterizations, we concentrate on the prototypical problem of sampling from Gaussian mixture models (GMMs). Specifically, we consider that the distribution of the data $\\mathbf{x}\\in\\mathbb{R}^{d}$ satisfies ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\mathbf{x}):=\\sum_{y\\in\\mathcal{Y}}w_{y}\\mathcal{N}(\\pmb{\\mu}_{y},\\mathbf{I}).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Here, $y$ is denoted as the class labels with a finite set of values $y\\in\\{1,2,\\cdots,|\\mathcal{Y}|\\}$ . Given any class label $y\\in\\mathcal{V}$ , the data distribution $\\mathbf{x}|y$ is a Gaussian with the center and covariance as $(\\pmb{\\mu}_{y},\\mathbf{I})$ . And the positive $w_{y}$ represents the weights of the Gaussian components which satisfies $\\textstyle\\sum_{y\\in{\\mathcal{y}}}w_{y}=1$ . ", "page_idx": 21}, {"type": "text", "text": "The diffusion model is a two processes framework: a forward process that transforms the target distribution into Gaussian noise, and a reverse process that progressively denoises in order to reconstitute the original target distribution. In this paper, we consider the continuous-time processes and define the forward process as an Ornstein\u2013Uhlenbeck (OU) process: ", "page_idx": 21}, {"type": "text", "text": "Forward Process. At time step $t\\in[0,T]$ , the forward process is ", "page_idx": 21}, {"type": "equation", "text": "$$\nd\\mathbf{x}_{t}=-\\mathbf{x}_{t}d_{t}+\\sqrt{2}d\\mathbf{w}_{t},\\quad\\mathbf{x}_{0}=\\mathbf{x}\\sim\\mathbb{P}(\\cdot|y),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where ${\\bf w}_{t}$ is a $d$ -dimensional standard Brownian motion. ", "page_idx": 21}, {"type": "text", "text": "The advantage of considering the forward process as an OU process is that it enables us to directly derive the closed-form expression for the conditional sample distribution at any given time $t$ . ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t}|\\mathbf{x}\\sim\\mathcal{N}(r_{t}\\mathbf{x},\\sigma_{t}^{2}\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $r_{t}=e^{-t}$ and $\\sigma_{t}=\\sqrt{1-e^{-2t}}$ . ", "page_idx": 21}, {"type": "text", "text": "By the reparameterization trick, $\\mathbf{x}_{t}$ can be represented as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbf{x}_{t}=r_{t}\\mathbf{x}+\\sigma_{t}\\pmb{\\epsilon}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We explore the widely adopted sampling method, DDIM, augmented with classifier-free guidance. And the associated reverse process is stated as the following ODE implementation: ", "page_idx": 21}, {"type": "text", "text": "Reverse Process. We write the reverse process in a forward version by switching time direction $t\\rightarrow T-t$ as ", "page_idx": 21}, {"type": "equation", "text": "$$\nd\\mathbf{z}_{t}=\\Big(\\mathbf{z}_{t}+(1+w)\\nabla_{\\mathbf{z}_{t}}\\log\\mathbb{P}(\\mathbf{z}_{t}|y)-w\\nabla_{\\mathbf{z}_{t}}\\log\\mathbb{P}(\\mathbf{z}_{t})\\Big)d t,\\quad\\mathbf{z}_{0}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $w\\geq0$ is a hyperparameter that controls the strength of the classifier guidance. ", "page_idx": 21}, {"type": "text", "text": "Given our primary focus on the impact of corrupted conditional embedding on generation, we simplify the reverse process by setting $w$ to 0 and concentrate solely on the conditional score network, i.e., ", "page_idx": 21}, {"type": "equation", "text": "$$\nd\\mathbf{z}_{t}=\\Big(\\mathbf{z}_{t}+\\nabla_{\\mathbf{z}_{t}}\\log\\mathbb{P}(\\mathbf{z}_{t}|y)\\Big)d t.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The remaining task is to estimate the unknown conditional score function $\\nabla_{\\mathbf{z}_{t}}\\log\\mathbb{P}(\\mathbf{z}_{t}|y)$ and unconditional score function $\\nabla_{\\mathbf{z}_{t}}\\log\\mathbb{P}(\\mathbf{z}_{t}|y)$ via training. In the subsequent analysis, we will indicate that by minimizing Equation (3) and optimizing the denoising network $\\epsilon$ , we can achieve an estimate of the conditional score. ", "page_idx": 21}, {"type": "text", "text": "Denoising Networks. Inspired by recent work that also target on GMMs [87, 88], we parameterize the denoising networks as the following piecewise linear function: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\epsilon_{\\boldsymbol{\\theta}}(\\mathbf{x}_{t},y)=\\sum_{k=1}^{|\\mathcal{V}|}\\mathbf{1}_{y=k}\\Big(\\mathbf{W}_{t}^{k}\\mathbf{x}_{t}+\\mathbf{V}_{t}^{k}\\mathbf{c}(y)\\Big),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\mathbf{c}(y)$ is the one-hot encoding of label $y,\\mathbf{1}_{y}$ is an indicator function and $\\{\\mathbf{W}_{t}^{k},\\mathbf{V}_{t}^{k}\\}_{k=1}^{|\\mathcal{D}|}$ are trainable parameters. ", "page_idx": 22}, {"type": "text", "text": "Conditional Embedding Corruption. We examine the scenario of conditional embedding corruption, wherein the conditional embedding $\\mathbf{c}(y)$ is no longer matched with the data $\\mathbf{x}$ , but instead is perturbed by Gaussian noise. Consequently, the corrupted conditional embedding causes the denoising networks to be as follows: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\epsilon_{\\theta}^{c}(\\mathbf{x}_{t},y)=\\sum_{k=1}^{|\\mathcal{Y}|}\\mathbb{1}_{y=k}\\Big(\\mathbf{W}_{t}^{k}\\mathbf{x}_{t}^{k}+\\mathbf{V}_{t}^{k}(\\mathbf{c}(y)+\\gamma\\pmb{\\xi})\\Big),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the $d$ -dimensional corrupted noise $\\pmb{\\xi}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ and $\\gamma\\geq0$ serves as the corruption control parameter, mirroring the noise ratio $\\eta$ for direct control of noise magnitude. ", "page_idx": 22}, {"type": "text", "text": "Based on the aforementioned setup, our ultimate goal is to obtain the closed form of the final generated data distribution by considering the impact of corrupted noise $\\xi$ on the training and generative processes. By comparing the differences in data distribution before and after the addition of corrupted noise, we aim to accurately characterize the impact of embedding corruption on image generation and explain the phenomena observed in experiments. ", "page_idx": 22}, {"type": "text", "text": "A.2 The Estimation of Conditional Score ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "A.2.1 Clean Conditions ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We first analyze the case of clean conditional embedding. Note that the denoising networks $\\epsilon_{\\theta}$ is a piecewise linear function and the training objective can be represented as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{\\epsilon}[\\|\\epsilon_{\\theta}({\\bf x}_{t,i},y)-\\epsilon\\|_{2}^{2}]=\\sum_{k=1}^{|y|}\\frac{w_{k}}{n_{k}}\\sum_{y_{i}=k}\\mathbb{E}_{\\epsilon}[\\|\\epsilon_{\\theta}({\\bf x}_{t,i},y)-\\epsilon\\|_{2}^{2}],\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the class sample size $n_{k}:=n w_{k}$ . ", "page_idx": 22}, {"type": "text", "text": "We observed that the optimization objective in Equation (17) can be divided into $\\lvert\\mathcal{V}\\rvert$ independent sub-problems based on the label $y$ . This inspires us to analyze the training and generation processes according to different classes. ", "page_idx": 22}, {"type": "text", "text": "Given any class $k\\in\\mathcal{V}$ , we present the following lemma for determining the optimal parameters of the corresponding denoising network and the associated conditional score. ", "page_idx": 22}, {"type": "text", "text": "Lemma 1. (Clean Conditional Embedding). Given any class $k\\in\\mathcal{V}$ , the optimal linear denoising network is ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\epsilon_{\\theta}(\\mathbf{x}_{t},y=k)=\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma_{k}\\Big)^{-1}\\mathbf{x}_{t}-r_{t}\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma_{k}\\Big)^{-1}\\hat{\\mu}_{k}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "And the corresponding optimal linear estimation of conditional score $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|y=k)$ is ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|y=k)=-\\frac{\\epsilon_{\\theta}(\\mathbf{x}_{t},y=k)}{\\sigma_{t}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\begin{array}{r}{\\pmb{\\Sigma}_{k}\\;:=\\;\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\mathbf{x}_{i}^{\\top}\\,-\\,\\frac{1}{n_{k}^{2}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}^{\\top}}\\end{array}$ is the empirical covariance of $k$ -labeled dataset and $\\begin{array}{r}{\\hat{\\pmb{\\mu}}_{k}:=\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}}\\end{array}$ is the empirical mean of $k$ -labeled dataset, $n_{k}$ is the sample size of $k$ -labeled dataset. And $\\boldsymbol{r}_{t}=\\boldsymbol{e}^{-t}$ , $\\sigma_{t}=\\sqrt{1-e^{-2t}}$ . ", "page_idx": 22}, {"type": "text", "text": "Proof. Given any class $k$ , the training objective is ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{w_{k}}{n_{k}}\\sum_{y_{i}=k}\\mathbb{E}_{\\epsilon}[\\|\\epsilon({\\bf x}_{t,i},y)-\\epsilon\\|_{2}^{2}]=\\frac{w_{k}}{n_{k}}\\sum_{y_{i}=k}\\mathbb{E}_{\\epsilon}[\\|{\\bf W}_{t}^{k}r_{t}{\\bf x}_{i}+{\\bf W}_{t}^{k}\\sigma_{t}\\epsilon+{\\bf V}_{t}^{k}{\\bf c}(y)-\\epsilon\\|_{2}^{2}].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since the weights $w_{k}$ is fixed in our analysis, we omit the notation $w_{k}$ without ambiguity in the following contents and for enhanced clarity, we initially omit the subscript/superscript $k$ in $n_{k}$ , $\\mathbf{W}_{t}^{k}$ , $\\mathbf{V}_{t}^{k},\\hat{\\pmb{\\mu}}_{k}\\,,\\pmb{\\mu}_{k}$ and $\\Sigma_{k}$ . Then Equation (20) can restated as as Equation (21) for simplicity. ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{\\epsilon}[\\|\\mathbf{W}_{t}r_{t}\\mathbf{x}_{i}+\\mathbf{W}_{t}\\sigma_{t}\\epsilon+\\mathbf{V}_{t}\\mathbf{c}(y)-\\epsilon\\|_{2}^{2}],\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\mathbf{x}_{i}$ is labeled as $k$ . ", "page_idx": 23}, {"type": "text", "text": "This training loss can be further simplified as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{\\epsilon}[\\|\\mathbf{W}_{t}r_{t}\\mathbf{x}_{i}+\\mathbf{W}_{t}\\sigma_{t}\\epsilon+\\mathbf{V}_{t}\\mathbf{c}(y)-\\epsilon\\|_{2}^{2}]}\\\\ &{\\displaystyle=\\frac{1}{n}\\sum_{i=1}^{n}\\|\\mathbf{W}_{t}r_{t}\\mathbf{x}_{i}+\\mathbf{V}_{t}\\mathbf{c}(y)\\|_{2}^{2}+\\mathbb{E}_{\\epsilon}[\\|(\\mathbf{W}_{t}\\sigma_{t}-\\mathbf{I})\\epsilon\\|_{2}^{2}]}\\\\ &{\\displaystyle=\\frac{r_{t}^{2}}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}^{\\top}\\mathbf{W}_{t}^{\\top}\\mathbf{W}_{t}\\mathbf{x}_{i}+\\frac{2r_{t}}{n}\\mathbf{e}^{\\top}(y)\\mathbf{V}_{t}^{\\top}\\mathbf{W}_{t}\\sum_{i=1}^{n}\\mathbf{x}_{i}+\\mathbf{e}^{\\top}(y)\\mathbf{V}_{t}^{\\top}\\mathbf{V}_{t}\\mathbf{c}(y)+\\mathrm{Tr}\\Big((\\mathbf{W}_{t}\\sigma_{t}-\\mathbf{I})(\\mathbf{W}_{t}^{\\top}\\sigma_{t}-\\mathbf{I})(\\mathbf{W}_{t}^{\\top}\\sigma_{t}-\\mathbf{I})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For simplicity, we denote $\\mathbf{b}_{t}:=\\mathbf{V}_{t}\\mathbf{c}(y)$ and we get ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{\\epsilon}[\\|\\mathbf{W}_{t}r_{t}\\mathbf{x}_{i}+\\mathbf{W}_{t}\\sigma_{t}\\epsilon+\\mathbf{V}_{t}\\mathbf{c}(y)-\\epsilon\\|_{2}^{2}]}\\\\ &{\\displaystyle=\\frac{r_{t}^{2}}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}^{\\top}\\mathbf{W}_{t}^{\\top}\\mathbf{W}_{t}\\mathbf{x}_{i}+\\frac{2r_{t}}{n}\\mathbf{b}_{t}^{\\top}\\mathbf{W}_{t}\\sum_{i=1}^{n}\\mathbf{x}_{i}+\\mathbf{b}_{t}^{\\top}\\mathbf{b}_{t}+\\mathrm{Tr}\\Big((\\mathbf{W}_{t}\\sigma_{t}-\\mathbf{I})(\\mathbf{W}_{t}^{\\top}\\sigma_{t}-\\mathbf{I})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Then, we define the loss function ", "page_idx": 23}, {"type": "equation", "text": "$$\nJ(\\mathbf{W}_{t},\\mathbf{b}_{t})=\\frac{r_{t}^{2}}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}^{\\mathsf{T}}\\mathbf{W}_{t}^{\\mathsf{T}}\\mathbf{W}_{t}\\mathbf{x}_{i}+\\frac{2r_{t}}{n}\\mathbf{b}_{t}^{\\mathsf{T}}\\mathbf{W}_{t}\\sum_{i=1}^{n}\\mathbf{x}_{i}+\\mathbf{b}_{t}^{\\mathsf{T}}\\mathbf{b}_{t}+\\mathrm{Tr}\\Big((\\mathbf{W}_{t}\\boldsymbol{\\sigma}_{t}-\\mathbf{I})\\big(\\mathbf{W}_{t}^{\\mathsf{T}}\\boldsymbol{\\sigma}_{t}-\\mathbf{I}\\big)\\Big).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The optimal $\\mathbf{W}_{t}^{*}$ and $\\mathbf{b}_{t}^{*}$ can be obtained by taking gradient to $J(\\mathbf{W}_{t},\\mathbf{b}_{t})$ such that, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{0}=\\nabla_{\\mathbf{W}_{t}}J(\\mathbf{W}_{t},\\mathbf{b}_{t})=\\frac{2r_{t}^{2}}{n_{k}}\\mathbf{W}_{t}\\displaystyle\\sum_{i=1}^{n}\\mathbf{x}_{i}\\mathbf{x}_{i}^{\\mathsf{T}}+\\frac{2r_{t}}{n}\\mathbf{b}_{t}\\displaystyle\\sum_{i=1}^{n}\\mathbf{x}^{\\mathsf{T}}+2(\\sigma_{t}^{2}\\mathbf{W}_{t}-\\sigma_{t}\\mathbf{I}),}\\\\ &{\\mathbf{0}=\\nabla_{\\mathbf{b}_{t}}J(\\mathbf{W}_{t},\\mathbf{b}_{t})=\\frac{2r_{t}}{n}\\mathbf{W}_{t}\\displaystyle\\sum_{i=1}^{n}\\mathbf{x}_{i}+2\\mathbf{b}_{t}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "And the optimal $\\mathbf{W}_{t}^{*}$ and $\\mathbf{b}_{t}^{*}$ is, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbf{W}_{t}^{*}=\\sigma_{t}\\Bigl(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{Z}\\Bigr)^{-1},\\quad\\mathbf{b}_{t}^{*}=\\mathbf{V}_{t}^{*}\\mathbf{c}(y)=-r_{t}\\sigma_{t}\\Bigl(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{Z}\\Bigr)^{-1}\\hat{\\boldsymbol{\\mu}}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $\\begin{array}{r}{\\pmb{\\Sigma}:=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}\\mathbf{x}_{i}^{\\top}-\\frac{1}{n_{k}^{2}}\\sum_{i=1}^{n}\\mathbf{x}_{i}\\sum_{i=1}^{n}\\mathbf{x}_{i}^{\\top}}\\end{array}$ is the empirical covariance of $k$ -labeled dataset and $\\begin{array}{r}{\\hat{\\pmb{\\mu}}:=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}}\\end{array}$ is the empirical mean of $k$ -labeled dataset. ", "page_idx": 23}, {"type": "text", "text": "Based on above analyze, for class $k$ , we then have the following optimal denoising network as the linear estimator of noise $\\epsilon$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\epsilon_{\\theta}(\\mathbf{x}_{t},y=k)=\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{\\Sigma}\\mathbf{\\Sigma}\\Big)^{-1}\\mathbf{x}_{t}-r_{t}\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{\\Sigma}\\mathbf{\\Sigma}\\Big)^{-1}\\hat{\\mu}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Given any class $k$ , we derive ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|\\mathbf{x},y=k)=-\\frac{\\left(\\mathbf{x}_{t}-r_{t}\\mathbf{x}\\right)}{\\sigma_{t}^{2}}=-\\frac{\\epsilon}{\\sigma_{t}},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where data $\\mathbf{x}$ and $\\mathbf{x}_{t}$ are labeled with $k$ . ", "page_idx": 23}, {"type": "text", "text": "Therefore, the linear estimator of $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|\\mathbf{x},y=k)$ given $k$ -labeled data $\\mathbf{x}_{t}$ is ", "page_idx": 24}, {"type": "equation", "text": "$$\n-\\biggl(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma\\biggr)^{-1}\\mathbf{x}_{t}+r_{t}\\biggl(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma\\biggr)^{-1}\\hat{\\mu}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since the estimation of $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|\\mathbf{x},y=k)$ and $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|y=k)$ are equivalent in optimization, the optimal linear estimator $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|y=k)$ also can be ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{{\\mathbf x}_{t}}\\log\\mathbb{P}({\\mathbf x}_{t}|y=k)=-\\frac{\\epsilon_{\\theta}\\left({\\mathbf x}_{t},y=k\\right)}{\\sigma_{t}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=-\\Bigl(\\sigma_{t}^{2}{\\mathbf I}+r_{t}^{2}\\Sigma\\Bigr)^{-1}{\\mathbf x}_{t}+r_{t}\\Bigl(\\sigma_{t}^{2}{\\mathbf I}+r_{t}^{2}\\Sigma\\Bigr)^{-1}\\hat{\\boldsymbol\\mu}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The proof is completed. ", "page_idx": 24}, {"type": "text", "text": "Note that the ground truth functions of conditional score given the label $k$ is ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|y=k)=-\\mathbf{x}_{t}+r_{t}\\pmb{\\mu}_{k}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We note the similarities in form and coefficients between the optimal linear estimator (19) and ground truth (22); they both are linear combinations of ${\\pmb{\\mu}}_{k}/{\\hat{\\pmb{\\mu}}}_{k}$ and $\\mathbf{x}_{t}$ . Specifically, when the empirical covariance $\\Sigma_{k}$ equals the population covariance I and the empirical mean $\\hat{\\pmb{\\mu}}_{k}$ matches the expected value $\\pmb{\\mu}_{k}$ , the estimated conditional score in Equation (19) coincides with the true conditional score in Equation (22). ", "page_idx": 24}, {"type": "text", "text": "A.2.2 Corrupted Conditions ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The same analytical approach as in Section A.2.1 will be applied to the scenario where the conditional embedding is perturbed. Given the class $k$ , we propose the following Lemma 2 to describe the optimal linear denoising network and the conditional score estimator with the corrupted conditional embedding $({\\bf c}(y)+\\gamma\\pm)$ where $\\xi$ is the standard Gaussian noise. ", "page_idx": 24}, {"type": "text", "text": "Lemma 2. (Corrupted Conditional Embedding). Given any class $k\\in\\mathcal{V}$ , the optimal linear denoising network is ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\epsilon_{\\theta}^{c}(\\mathbf{x}_{t},y=k)=\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{Z}_{k}+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}_{k}\\|_{2}^{2}\\mathbf{I}\\Big)^{-1}\\mathbf{x}_{t}-\\frac{r_{t}}{1+\\gamma^{2}}\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{Z}_{k}+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}_{k}\\|_{2}^{2}\\mathbf{I}\\Big)^{-1}\\hat{\\mu}_{k}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "And the corresponding optimal linear estimation of conditional score $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}^{c}(\\mathbf{x}_{t}|y=k)$ is ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}^{c}(\\mathbf{x}_{t}|y=k)=-\\frac{\\epsilon_{\\theta}^{c}(\\mathbf{x}_{t},y=k)}{\\sigma_{t}}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\begin{array}{r}{\\pmb{\\Sigma}_{k}\\;:=\\;\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\mathbf{x}_{i}^{\\top}\\,-\\,\\frac{1}{n_{k}^{2}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}^{\\top}}\\end{array}$ is the empirical covariance of $k$ -labeled dataset and $\\begin{array}{r}{\\hat{\\pmb{\\mu}}_{k}:=\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}}\\end{array}$ is the empirical mean of $k$ -labeled dataset, $n_{k}$ is the sample size of $k$ -labeled dataset, and $r_{t}=e^{-t}$ , $\\sigma_{t}=\\sqrt{1-e^{-2t}}$ . ", "page_idx": 24}, {"type": "text", "text": "Proof. For enhanced clarity, we initially omit the subscript/superscript $k$ in $n_{k}$ $.,\\mathbf{W}_{t}^{k},\\mathbf{V}_{t}^{k},\\hat{\\mu}_{k}\\;,\\mu_{k}$ and $\\Sigma_{k}$ . ", "page_idx": 24}, {"type": "text", "text": "For any class $k$ and standard Gaussian noise $\\xi$ , we consider the following training loss ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{\\xi}\\mathbb{E}_{\\epsilon}[\\|\\mathbf{W}_{t}r_{t}\\mathbf{x}_{i}+\\mathbf{W}_{t}\\sigma_{t}\\pmb{\\epsilon}+\\mathbf{V}_{t}(\\mathbf{c}(y)+\\gamma\\pmb{\\xi})-\\pmb{\\epsilon}\\|_{2}^{2}].\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "And we further optimize the training loss as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}_{\\xi}[\\|\\mathbf{W}_{t}r_{t}\\mathbf{x}_{i}+\\mathbf{W}_{t}\\sigma_{t}\\boldsymbol{\\epsilon}+\\mathbf{V}_{t}(\\mathbf{c}(y)+\\boldsymbol{\\gamma}\\boldsymbol{\\xi})-\\boldsymbol{\\epsilon}\\|_{2}^{2}]}\\\\ &{\\displaystyle=\\frac{1}{n}\\sum_{i=1}^{n}\\|\\mathbf{W}_{t}r_{t}\\mathbf{x}_{i}+\\mathbf{V}_{t}\\mathbf{c}(y)+\\gamma\\mathbf{V}_{t}\\boldsymbol{\\xi}\\|_{2}^{2}+\\mathbb{E}_{\\boldsymbol{\\epsilon}}[\\|(\\mathbf{W}_{t}\\sigma_{t}-\\mathbf{I})\\boldsymbol{\\epsilon}\\|_{2}^{2}]}\\\\ &{\\displaystyle=\\frac{r_{t}^{2}}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}^{\\top}\\mathbf{W}_{t}^{\\top}\\mathbf{W}_{t}\\mathbf{x}_{i}+\\frac{2r_{t}}{n}\\mathbf{e}^{\\top}(y)\\mathbf{V}_{t}^{\\top}\\mathbf{W}_{t}\\sum_{i=1}^{n}\\mathbf{x}_{i}+\\mathbf{e}^{\\top}(y)\\mathbf{V}_{t}^{\\top}\\mathbf{V}_{t}\\mathbf{c}(y)}\\\\ &{\\displaystyle+\\,\\gamma^{2}\\mathrm{Tr}(\\mathbf{V}_{t}\\mathbf{V}_{t}^{\\top})+\\mathrm{Tr}\\Big((\\mathbf{W}_{t}\\sigma_{t}-\\mathbf{I})(\\mathbf{W}_{t}^{\\top}\\sigma_{t}-\\mathbf{I})\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Similarly, we get the optimal $\\mathbf{W}_{t}^{*}$ and $\\mathbf{b}_{t}^{*}$ is, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{{\\bf W}_{t}^{*}=\\sigma_{t}\\Big(\\sigma_{t}^{2}{\\bf I}+r_{t}^{2}{\\boldsymbol\\Sigma}+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}{\\bf I}\\Big)^{-1}},}}\\\\ {{\\displaystyle{{\\bf b}_{t}^{*}={\\bf V}_{t}^{*}{\\bf c}(y)=-\\frac{r_{t}}{1+\\gamma^{2}}\\sigma_{t}\\Big(\\sigma_{t}^{2}{\\bf I}+r_{t}^{2}{\\boldsymbol\\Sigma}+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}{\\bf I}\\Big)^{-1}\\hat{\\mu}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\begin{array}{r l r}{{\\bf{\\Sigma}}\\!}&{{}:=}&{\\!\\frac{1}{n}\\sum_{i=1}^{n}{\\bf{x}}_{i}{\\bf{x}}_{i}^{\\top}\\;-\\;\\frac{1}{n_{k}^{2}}\\sum_{i=1}^{n}{\\bf{x}}_{i}\\sum_{i=1}^{n}{\\bf{x}}_{i}^{\\top}}\\end{array}$ is the empirical covariance and $\\hat{\\pmb{\\mu}}_{\\mathrm{~\\tiny~:=~}}$ $-{\\textstyle{\\frac{1}{n}}}\\sum_{i=1}^{n}\\mathbf{x}_{i}$ is the empirical mean of $k$ -labeled dataset. ", "page_idx": 25}, {"type": "text", "text": "So for any class $k$ , we get the following optimal denoising network as the linear estimator of noise $\\epsilon$ , ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\epsilon_{\\theta}^{c}(\\mathbf{x}_{t},y=k)=\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{S}_{k}+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}_{k}\\|_{2}^{2}\\mathbf{I}\\Big)^{-1}\\mathbf{x}_{t}-\\frac{r_{t}}{1+\\gamma^{2}}\\sigma_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\mathbf{S}_{k}+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}_{k}\\|_{2}^{2}\\mathbf{I}\\Big)^{-1}\\hat{\\mu}_{k}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The corresponding optimal linear estimator $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}^{c}(\\mathbf{x}_{t}|y=k)$ is ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}^{c}(\\mathbf{x}_{t}|y=k)=-\\frac{\\epsilon_{\\theta}\\left(\\mathbf{x}_{t},y=k\\right)}{\\sigma_{t}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=-\\left(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\lVert\\hat{\\mu}\\rVert_{2}^{2}\\mathbf{I}\\right)^{-1}\\mathbf{x}_{t}+\\frac{r_{t}}{1+\\gamma^{2}}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma+\\frac{r_{t}^{2}\\gamma^{2}}{1+\\gamma^{2}}\\lVert\\hat{\\mu}\\rVert_{2}^{2}\\mathbf{I}\\Big)^{-1}\\hat{\\mu}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "A.3 The Distribution of Generation ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Given the class $k$ , after getting the optimal linear estimator of conditional score $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|y=$ $k$ ), we can accurately characterize the reverse process and derive the closed form of generation distribution. ", "page_idx": 25}, {"type": "text", "text": "A.3.1 Clean Conditions ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "According to Lemma 1, we first replace the conditional score $\\nabla_{\\mathbf{x}_{t}}\\log\\mathbb{P}(\\mathbf{x}_{t}|y=k)$ in Equation (14) with the optimal linear estimator. Given the class $k$ , we get ", "page_idx": 25}, {"type": "equation", "text": "$$\nd\\mathbf{z}_{t}=\\Big(\\mathbf{z}_{t}-\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma_{k}\\Big)^{-1}\\mathbf{z}_{t}+r_{t}\\Big(\\sigma_{t}^{2}\\mathbf{I}+r_{t}^{2}\\Sigma_{k}\\Big)^{-1}\\hat{\\mu}_{k}\\Big)d t.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Assume the empirical covariance $\\Sigma_{k}$ is full rank, since the empirical covariance is diagonalizable and semi-positive, we decompose $\\Sigma_{k}$ as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\Sigma}_{k}=\\mathbf{U}\\pmb{\\Lambda}\\mathbf{U}^{\\top},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\mathbf{U}=[\\mathbf{u}_{1}|\\cdot\\cdot\\cdot|\\mathbf{u}_{d}]$ is an orthogonal matrix whose columns are the real, orthonormal eigenvectors of $\\Sigma_{k}$ and $\\mathbf{A}=\\operatorname{diag}(\\lambda_{1},\\ldots,\\lambda_{d})$ is a diagonal matrix whose entries are the eigenvalues arranged in descending order of $\\Sigma_{k}$ , i.e., $1\\geq\\lambda_{1}\\geq\\cdot\\cdot\\geq\\lambda_{d}>0$ . ", "page_idx": 25}, {"type": "text", "text": "Therefore, problem (26) can be decomposed into $d$ independent sub-problem as ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbf{u}_{i}^{\\mathsf{T}}d\\mathbf{z}_{t}=\\Big(1-\\frac{1}{\\sigma_{t}^{2}+r_{t}^{2}\\lambda_{i}}\\Big)\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{t}d t+\\frac{r_{t}}{\\sigma_{t}^{2}+r_{t}^{2}\\lambda_{i}}\\mathbf{u}_{i}^{\\mathsf{T}}\\hat{\\boldsymbol{\\mu}}_{k}d t,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\mathbf{u}_{i}$ is $i$ -th eigenvector and $\\lambda_{i}$ is its corresponding eigenvalue. ", "page_idx": 25}, {"type": "text", "text": "By analyzing Equation (28), we can obtain the expectation and variance of the final generation distribution separately, thereby inferring the distribution of the ultimately generated data as outlined in the subsequent lemma. ", "page_idx": 25}, {"type": "text", "text": "Lemma 3. (Clean Conditional Embedding). For any class $k$ , the distribution of the generated data ${\\bf z}_{T}$ satisfies ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{T\\rightarrow\\infty}\\mathbf{z}_{T}\\sim{\\mathcal{N}}({\\hat{\\pmb{\\mu}}}_{k},\\pmb{\\Sigma}_{k}),\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\begin{array}{r}{\\pmb{\\Sigma}_{k}\\;:=\\;\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\mathbf{x}_{i}^{\\top}\\,-\\,\\frac{1}{n_{k}^{2}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}^{\\top}}\\end{array}$ is the empirical covariance of $k$ -labeled ataset and $\\begin{array}{r}{\\hat{\\pmb{\\mu}}_{k}:=\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}}\\end{array}$ is the empirical mean of $k$ -labeled dataset, $n_{k}$ is the sample size of $k$ -labeled dataset. ", "page_idx": 25}, {"type": "text", "text": "Proof. For enhanced clarity, we initially remove the subscript $k$ in $\\hat{\\pmb{\\mu}}_{k}$ , $\\pmb{\\mu}_{k}$ and $\\Sigma_{k}$ . In order to obtain the solution to Equation (28) and achieve the closed form of the generation distribution, we first examine the discrete solution of Equation (28). ", "page_idx": 26}, {"type": "text", "text": "Given any class $k$ , we consider the discretization Euler-Maruyama scheme which is widely used in existing work [151\u2013153] and discretize the interval $[0,T]$ into $N$ discretization points, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{(j+1)h}=\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{j h}+\\Big(1-\\frac{1}{\\sigma_{t_{j}}^{2}+r^{2}(t_{j})\\lambda_{i}}\\Big)\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{j}h+\\frac{r(t_{j})}{\\sigma_{t_{j}}^{2}+r^{2}(t_{j})\\lambda_{i}}\\mathbf{u}_{i}^{\\mathsf{T}}\\hat{\\boldsymbol{\\mu}}h,\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\begin{array}{r}{h:=\\frac{T}{N}}\\end{array}$ is the step size and $t_{j}=j h$ . ", "page_idx": 26}, {"type": "text", "text": "According to Equation (30), $\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{(j+1)h}$ can be regarded as a linear transformation of the initial distribution, which is a standard Gaussian distribution. Therefore, $\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{(j+1)h}$ still satisfies a Gaussian distribution. The remaining task is analyze the mean and variance of the $\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{(j+1)h}$ separately. ", "page_idx": 26}, {"type": "text", "text": "Expectation. By Equation (30), we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{(j+1)h})=\\left(1+\\Big(1-\\frac{1}{\\sigma_{t_{j}}^{2}+r^{2}(t_{j})\\lambda_{i}}\\Big)h\\right)\\mathbb{E}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{j h})+\\frac{r(t_{j})}{\\sigma_{t_{j}}^{2}+r^{2}(t_{j})\\lambda_{i}}\\mathbf{u}_{i}^{\\mathsf{T}}\\hat{\\boldsymbol{\\mu}}h.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By telescoping, we get the discretization solution ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{N h})=\\displaystyle\\prod_{k=0}^{N-1}\\Bigg(1+\\Big(1-\\frac{1}{\\sigma_{t_{k}}^{2}+r^{2}(t_{k})\\lambda_{i}}\\Big)h\\Bigg)\\mathbb{E}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{0})}\\\\ &{\\quad\\quad\\quad+\\displaystyle\\sum_{k=0}^{N-1}\\frac{r(t_{k})}{\\sigma_{t_{k}}^{2}+r^{2}(t_{k})\\lambda_{i}}\\mathbf{u}_{i}^{\\mathsf{T}}\\hat{\\mu}h\\prod_{j=k+1}^{N-1}\\Bigg(1+\\Big(1-\\frac{1}{\\sigma_{t_{j}}^{2}+r^{2}(t_{j})\\lambda_{i}}\\Big)h\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Since the initial distribution of reverse process is $\\mathbf{z}_{0}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ , thus $\\mathbb{E}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{0})=0$ . We further have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{N h})=\\sum_{k=0}^{N-1}\\frac{r(t_{k})}{\\sigma_{t_{k}}^{2}+r^{2}(t_{k})\\lambda_{i}}\\mathbf{u}_{i}^{\\mathsf{T}}\\hat{\\mu}h\\prod_{j=k+1}^{N-1}\\Bigg(1+\\Big(1-\\frac{1}{\\sigma_{t_{j}}^{2}+r^{2}(t_{j})\\lambda_{i}}\\Big)h\\Bigg).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By limiting $h\\to0$ , we can use the identity $1+h x\\simeq\\exp(h x)$ . Then we get the continous version of Equation (31) that when $h\\to0$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}(\\mathbf{u}_{i}^{\\top}\\mathbf{z}_{T})=\\int_{0}^{T}\\frac{r_{t}}{\\sigma_{t}^{2}+r_{t}^{2}\\lambda_{i}}\\Bigg(\\exp{\\int_{t}^{T}1}-\\frac{1}{\\sigma_{r}^{2}+r^{2}(r)\\lambda_{i}}d r\\Bigg)\\mathbf{u}_{i}^{\\top}\\hat{\\boldsymbol{\\mu}}d t}\\\\ &{\\ \\ \\ \\ \\ \\ \\ =\\int_{0}^{T}\\frac{e^{t-T}}{1+e^{2(t-T)}(\\lambda_{i}-1)}\\Bigg(\\exp{\\int_{t}^{T}1}-\\frac{1}{1+e^{2(t-T)}(\\lambda_{i}-1)}d r\\Bigg)\\mathbf{u}_{i}^{\\top}\\hat{\\boldsymbol{\\mu}}d t}\\\\ &{\\ \\ \\ \\ \\ \\ \\ =\\int_{0}^{T}\\frac{e^{t-T}\\sqrt{\\lambda_{i}}}{[1+e^{2(t-T)}(\\lambda_{i}-1)]^{\\frac{3}{2}}}\\mathbf{u}_{i}^{\\top}\\hat{\\boldsymbol{\\mu}}d t}\\\\ &{\\ \\ \\ \\ \\ \\ \\ =\\sqrt{\\lambda_{i}}\\frac{e^{t-T}}{\\sqrt{1+e^{2(t-T)}(\\lambda_{i}-1)}}\\Bigg|_{0}^{T}\\mathbf{u}_{i}^{\\top}\\hat{\\boldsymbol{\\mu}}}\\\\ &{\\ \\ \\ \\ \\ \\ \\ =\\left(1-\\frac{\\sqrt{\\lambda_{i}}e^{-T}}{\\sqrt{1+(\\lambda_{i}-1)}e^{-2T}}\\right)\\mathbf{u}_{i}^{\\top}\\hat{\\boldsymbol{\\mu}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Hence, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\mathbf{z}_{T})=\\mathbf{U}\\mathrm{diag}(e_{1},e_{2},\\dots,e_{d})\\mathbf{U}^{T}\\hat{\\boldsymbol{\\mu}},\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\begin{array}{r}{e_{i}=1-\\frac{\\sqrt{\\lambda_{i}}e^{-T}}{\\sqrt{1+(\\lambda_{i}-1)e^{-2T}}}}\\end{array}$ ", "page_idx": 26}, {"type": "text", "text": "When $T\\rightarrow\\infty$ , we get ", "page_idx": 26}, {"type": "equation", "text": "$$\ne_{i}=1-\\frac{\\sqrt{\\lambda_{i}}e^{-T}}{\\sqrt{1+(\\lambda_{i}-1)e^{-2T}}}\\rightarrow1.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "And the expectation of generation distribution is the empirical mean, i.e., ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\mathbf{z}_{T})=\\hat{\\mu}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Variance. Similarly, by Equation (30), we have the variance ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{Var}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{(j+1)h})=\\left(1+\\Bigl(1-\\frac{1}{\\sigma_{t_{j}}^{2}+r^{2}(t_{j})\\lambda_{i}}\\Bigr)h\\right)^{2}\\mathrm{Var}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{j h}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By telescoping, we get the discretization solution ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{Var}(\\mathbf{u}_{i}^{\\top}\\mathbf{z}_{N h})=\\prod_{k=0}^{N-1}\\left(1+\\Big(1-\\frac{1}{\\sigma_{t_{k}}^{2}+r^{2}(t_{k})\\lambda_{i}}\\Big)h\\right)^{2}\\mathrm{Var}(\\mathbf{u}_{i}^{\\top}\\mathbf{z}_{0}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Since $\\mathrm{Var}(\\mathbf{u}_{i}^{\\mathsf{T}}\\mathbf{z}_{0})=\\mathbf{u}_{i}^{\\mathsf{T}}\\mathrm{Var}(\\mathbf{z}_{0})\\mathbf{u}_{i}=1$ , the variance at time $T$ is ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{Var}(\\mathbf{u}_{i}^{\\top}\\mathbf{z}_{N h})=\\prod_{k=0}^{N-1}\\Bigg(1+\\Big(1-\\frac{1}{\\sigma_{t_{k}}^{2}+r^{2}(t_{k})\\lambda_{i}}\\Big)h\\Bigg)^{2}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "When $h\\to0$ and use the identity $(1+h x)^{2}\\simeq\\exp(2h x)$ , we get ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}(\\mathbf u_{i}^{\\top}\\mathbf z_{T})=\\exp\\displaystyle\\int_{0}^{T}2\\Big(1-\\frac{1}{\\sigma_{t}^{2}+r_{t}^{2}\\lambda_{i}}\\Big)d t}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\exp\\displaystyle\\int_{0}^{T}2\\Big(1-\\frac{1}{1+(\\lambda_{i}-1)e^{2(t-T)}}\\Big)d t}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\frac{\\lambda_{i}}{1+(\\lambda_{i}-1)e^{-2T}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Hence, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname{Var}(\\mathbf{z}_{T})=\\mathbf{U}\\mathrm{diag}(v_{1},v_{2},\\ldots,v_{d})\\mathbf{U}^{T}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\begin{array}{r}{v_{i}=\\frac{\\lambda_{i}}{1+(\\lambda_{i}-1)e^{-2T}}}\\end{array}$ ", "page_idx": 27}, {"type": "text", "text": "When $T\\rightarrow\\infty$ , we get ", "page_idx": 27}, {"type": "equation", "text": "$$\nv_{i}=\\frac{\\lambda_{i}}{1+(\\lambda_{i}-1)e^{-2T}}\\rightarrow\\lambda_{i}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "And the expectation of generation distribution is the empirical mean, i.e., ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{Var}({\\mathbf{z}}_{T})=\\Sigma.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We complete the proof. ", "page_idx": 27}, {"type": "text", "text": "A.3.2 Corrupted Conditions ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "We then discuss the distribution of generated data when the conditional embedding is perturbed by noise. Using the same method to derive the data distribution under the corrupted conditional embedding setting, we conclude the following Lemma 4. ", "page_idx": 27}, {"type": "text", "text": "Lemma 4. (Corrupted Conditional Embedding). For any class $k\\in\\mathcal{V}$ , the distribution of generation ${\\bf z}_{T}^{c}$ is ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{T\\to\\infty}\\mathbf{z}_{T}^{c}\\sim\\mathcal{N}(\\frac{\\hat{\\mu}_{k}}{1+\\gamma^{2}},\\Sigma_{k}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}_{k}\\|_{2}^{2}\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\begin{array}{r}{\\pmb{\\Sigma}_{k}\\;:=\\;\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\mathbf{x}_{i}^{\\top}\\,-\\,\\frac{1}{n_{k}^{2}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}^{\\top}}\\end{array}$ is the empirical covariance of $k$ -labeled dataset and \u02c6\u00b5k :=n1k $\\begin{array}{r}{\\hat{\\pmb{\\mu}}_{k}:=\\frac{1}{n_{k}}\\sum_{i=1}^{n_{k}}\\mathbf{x}_{i}}\\end{array}$ is the empirical mean of -labeled dataset, is the sample size of $k$ -labeled dataset. And $\\gamma\\geq0$ is the corruption control parameter. ", "page_idx": 27}, {"type": "text", "text": "Proof. To improve clarity, we initially disregard the subscript $k$ in $\\hat{\\pmb{\\mu}}_{k}\\mathrm{~,~}\\pmb{\\mu}_{k}$ and $\\Sigma_{k}$ . Building upon the proof details presented in Lemma 3 and the optimal conditional score estimation outlined in Lemma 2, we arrive at the subsequent findings: ", "page_idx": 28}, {"type": "text", "text": "Expectation. Similarly, we derive ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}(\\mathbf{u}_{i}^{\\top}\\mathbf{\\bar{z}}_{T}^{c})=\\frac{1}{1+\\gamma^{2}}\\int_{0}^{T}\\frac{r_{t}}{\\sigma_{t}^{2}+r_{t}^{2}(\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}||\\bar{\\boldsymbol{z}})}\\left(\\exp\\int_{t}^{T}1-\\frac{1}{\\sigma_{t}^{2}+r^{2}(\\gamma)(\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}||\\bar{\\boldsymbol{z}})}d r\\right)\\mathbf{u}_{i}^{\\top}\\bar{\\mu}d t}\\\\ &{\\quad\\quad\\quad=\\frac{1}{1+\\gamma^{2}}\\int_{0}^{T}\\frac{e^{t-T}}{1+e^{t(\\gamma-T)}(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}||\\bar{\\boldsymbol{z}})}\\left(\\exp\\int_{t}^{T}1-\\frac{1}{1+e^{2(\\gamma-T)}(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}||\\bar{\\boldsymbol{z}}|))}d r\\right)\\mathbf{u}_{i}^{\\top}\\bar{\\mu}d t}\\\\ &{\\quad\\quad\\quad=\\frac{1}{1+\\gamma^{2}}\\int_{0}^{T}\\frac{e^{t-T}\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}|\\bar{\\boldsymbol{z}}|}}{[1+e^{2(t-T)}(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}||\\bar{\\boldsymbol{z}}|)]^{3}}\\mathbf{u}_{i}^{\\top}\\bar{\\mu}d t}\\\\ &{\\quad\\quad\\quad=\\frac{1}{1+\\gamma^{2}}\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}||\\bar{\\boldsymbol{z}}|}\\frac{e^{t-T}}{\\sqrt{1+e^{2(t-T)}(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}|\\bar{\\mu}||\\bar{\\boldsymbol{z}}|)}}\\bigg|_{0}^{T}\\mathbf{u}_{i}^{\\top}\\bar{\\mu}}\\\\ &\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Hence, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\quad\\quad\\mathbb{E}({\\mathbf z}_{T}^{c})={\\mathbf U}\\mathrm{diag}(e_{1}^{c},e_{2}^{c},\\cdot\\cdot\\cdot,e_{d}^{c}){\\mathbf U}^{T}\\hat{\\boldsymbol\\mu},}\\\\ &{e_{i}^{c}=\\frac{1}{1+\\gamma^{2}}\\Big(1-\\frac{\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\boldsymbol\\mu}\\|_{2}^{2}}e^{-T}}{\\sqrt{1+(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\boldsymbol\\mu}\\|_{2}^{2})e^{-2T}}}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "When $T\\rightarrow\\infty$ , we get ", "page_idx": 28}, {"type": "equation", "text": "$$\ne_{i}^{c}=\\frac{1}{1+\\gamma^{2}}\\Big(1-\\frac{\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}}e^{-T}}{\\sqrt{1+(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2})e^{-2T}}}\\Big)\\to\\frac{1}{1+\\gamma^{2}}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "And the expectation of generation distribution is ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\mathbf{z}_{T}^{c})=\\frac{1}{1+\\gamma^{2}}\\hat{\\mu}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Variance. We get ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}(\\mathbf{u}_{i}^{\\top}\\mathbf{z}_{T}^{c})=\\exp\\int_{0}^{T}2\\Big(1-\\frac{1}{\\sigma_{t}^{2}+r_{t}^{2}(\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2})}\\Big)d t}\\\\ &{\\quad\\quad\\quad\\quad=\\exp\\int_{0}^{T}2\\Big(1-\\frac{1}{1+(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2})e^{2(t-T)}}\\Big)d t}\\\\ &{\\quad\\quad\\quad\\quad=\\frac{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}}{1+(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2})e^{-2T}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Hence, we have ", "page_idx": 28}, {"type": "text", "text": "where $\\begin{array}{r}{v_{i}^{c}=\\frac{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}}{1+(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2})e^{-2T}}}\\end{array}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}(\\mathbf{z}_{T}^{c})=\\mathbf{U}\\mathrm{diag}(v_{1}^{c},v_{2}^{c},\\dots,v_{d}^{c})\\mathbf{U}^{T},}\\\\ &{\\frac{\\gamma^{2}}{\\frac{1+\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}}}\\\\ &{\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2})e^{-2T}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "When $T\\rightarrow\\infty$ , we get ", "page_idx": 28}, {"type": "equation", "text": "$$\nv_{i}^{c}=\\frac{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}}{1+(\\lambda_{i}-1+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2})e^{-2T}}\\rightarrow\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "And the expectation of generation distribution is the empirical mean, i.e., ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\operatorname{Var}(\\mathbf{z}_{T}^{c})=\\Sigma+{\\frac{\\gamma^{2}}{1+\\gamma^{2}}}\\|{\\hat{\\pmb{\\mu}}}\\|_{2}^{2}\\mathbf{I}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "A.4 Diversity and Quality: Clean vs. Corrupted Conditions ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "A.4.1 Generation Diversity ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Given any class $k$ , building on previous work [70], we consider entropy to measure the diversity of generated images. In particular, let $\\mathbb{P}$ and $\\mathbb{P}^{c}$ be the probability densities for the generated data using clean and corrupted conditional embeddings respectively, we have the following for $\\mathbf{z}_{t}$ and $\\mathbf{z}_{t}^{c}$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H(\\mathbf{z}_{T}|y=k):=-\\int\\mathbb{P}(\\mathbf{z}|y=k)\\log\\mathbb{P}(\\mathbf{z}|y=k)d\\mathbf{z},}\\\\ &{H(\\mathbf{z}_{T}^{c}|y=k):=-\\int\\mathbb{P}^{c}(\\mathbf{z}|y=k)\\log\\mathbb{P}^{c}(\\mathbf{z}|y=k)d\\mathbf{z}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We propose the following theorem to describe the difference between these two conditional differential entropy. ", "page_idx": 29}, {"type": "text", "text": "Theorem 3. (Restatement of Theorem 1) For any class $k\\in\\mathcal{V}$ , assuming the norm of corresponding expectation $\\|\\pmb{\\mu}_{k}\\|_{2}^{2}$ is a constant and the empirical covariance of training data is full rank, let ${\\bf z}_{T}$ and ${\\bf z}_{T}^{c}$ be the generation featuring clean and corrupted conditions respectively, then it holds that ", "page_idx": 29}, {"type": "equation", "text": "$$\nH(\\mathbf{z}_{T}^{c}|y=k)-H(\\mathbf{z}_{T}|y=k)=\\Theta(\\gamma^{2}d),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\gamma$ is the corruption control parameter and $d$ is the data dimension. ", "page_idx": 29}, {"type": "text", "text": "Proof. For the sake of clarity, we begin by omitting the subscript $k$ from $\\hat{\\pmb{\\mu}}_{k}\\mathrm{~,~}\\pmb{\\mu}_{k}$ and $\\Sigma_{k}$ . Given any class $k$ , since both the clean generation ${\\bf z}_{T}$ and the corrupted generation ${\\bf z}_{T}^{c}$ follow multivariate Gaussian distributions, we can derive the closed-form expression for the difference in their differential entropy by Lemma 3 and Lemma 4 as follows ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{H(\\mathbf{z}_{T}^{c}|y=k)-H(\\mathbf{z}_{T}|y=k)=\\displaystyle\\frac{1}{2}\\log|\\boldsymbol{\\Sigma}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}||\\hat{\\mu}||_{2}^{2}\\mathbf{I}|-\\frac{1}{2}\\log|\\boldsymbol{\\Sigma}|}\\\\ &{}&{\\quad\\quad\\quad\\quad\\quad=\\displaystyle\\frac{1}{2}\\displaystyle\\sum_{i=1}^{d}\\log\\Big(1+\\frac{\\gamma^{2}}{(1+\\gamma^{2})\\lambda_{i}}||\\hat{\\mu}||_{2}^{2}\\Big),\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $\\begin{array}{r}{\\pmb{\\Sigma}:=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}\\mathbf{x}_{i}^{\\top}-\\frac{1}{n_{k}^{2}}\\sum_{i=1}^{n}\\mathbf{x}_{i}\\sum_{i=1}^{n}\\mathbf{x}_{i}^{\\top}}\\end{array}$ is the empirical covariance of $k$ -labeled dataset and $\\begin{array}{r}{\\hat{\\pmb{\\mu}}:=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x}_{i}}\\end{array}$ is the empirical mean of $k$ -labeled dataset. ", "page_idx": 29}, {"type": "text", "text": "When the noise ratio $\\gamma$ is small and $\\lambda_{i}=\\omega(\\gamma)$ , ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\log\\Big(1+\\frac{\\gamma^{2}}{(1+\\gamma^{2})\\lambda_{i}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}\\Big)=\\frac{\\gamma^{2}}{\\lambda_{i}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}+\\mathcal{O}(\\gamma^{2}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Therefore, ", "page_idx": 29}, {"type": "equation", "text": "$$\nH(\\mathbf{z}_{T}^{c}|y=k)-H(\\mathbf{z}_{T}|y=k)=\\frac{1}{2}\\sum_{i=1}^{d}\\log\\left(1+\\frac{\\gamma^{2}}{(1+\\gamma^{2})\\lambda_{i}}\\|\\hat{\\mu}\\|_{2}^{2}\\right)=\\Theta(\\gamma^{2}d).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "A.4.2 Generation Quality ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Before starting proving that slight noise is beneficial to the quality of generation, we first introduce the lemmas required for the proof. ", "page_idx": 29}, {"type": "text", "text": "Lemma 5. Given $\\mathbf{x}_{1},\\cdots,\\mathbf{x}_{n}$ independent and all distributed as a Gaussian $\\mathcal{N}(\\mu,\\mathbf{I})$ . Then, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\operatorname{Var}(\\mathbf{x}_{i}|\\mathbf{x}_{1}+\\cdot\\cdot\\cdot+\\mathbf{x}_{n}=\\mathbf{z}))={\\frac{n-1}{n}}\\mathbf{I}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. The expectation is ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}({\\mathbf x}_{i}|{\\mathbf x}_{1}+\\cdot\\cdot\\cdot+{\\mathbf x}_{n}={\\mathbf z})}\\\\ &{~=\\mathbb{E}({\\mathbf z}-{\\mathbf x}_{1}-\\cdot\\cdot\\cdot-{\\mathbf x}_{i-1}-{\\mathbf x}_{i+1}-\\cdot\\cdot\\cdot,{\\mathbf x}_{n}|{\\mathbf x}_{1}+\\cdot\\cdot\\cdot+{\\mathbf x}_{n}={\\mathbf z})}\\\\ &{~={\\mathbf z}-(n-1)\\mathbb{E}({\\mathbf x}_{i}|{\\mathbf x}_{1}+\\cdot\\cdot\\cdot+{\\mathbf x}_{n}={\\mathbf z}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Therefore, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}(\\mathbf{x}_{i}|\\mathbf{x}_{1}+\\cdot\\cdot\\cdot+\\mathbf{x}_{n}=\\mathbf{z})={\\frac{\\mathbf{z}}{n}}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By the law of total variance ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}(\\mathrm{Var}(\\mathbf{x}_{i}|\\mathbf{x}_{1}+\\cdots+\\mathbf{x}_{n}=\\mathbf{z}))=\\mathrm{Var}(\\mathbf{x}_{i})-\\mathrm{Var}(\\mathbb{E}(\\mathbf{x}_{i}|\\mathbf{x}_{1}+\\cdots+\\mathbf{x}_{n}=\\mathbf{z}))}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\displaystyle\\frac{n-1}{n}\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We consider the Wasserstein distance to measure the distance between the generation distribution and the true data distribution. A smaller Wasserstein distance implies a closer proximity between the generated data distribution and the true data distribution, thereby indicating better generation quality Given class $k$ , we define 2-Wasserstein distance between the true data distribution $\\mathbf{x}|y\\,=\\,k$ and the clean generation ${\\bf z}_{T}$ as $d:=\\mathcal{W}_{2}\\Big(\\mathcal{N}(\\pmb{\\mu}_{k},\\mathbf{I}),\\mathcal{N}(\\hat{\\pmb{\\mu}}_{k},\\pmb{\\Sigma}_{k})\\Big)$ . Similarly, the Wasserstein distance between the true data distribution $\\mathbf{x}|y=k$ and the corrupted generation $\\mathbf{z}_{t}^{c}$ is denoted as $d_{c}:=$ $\\begin{array}{r l}&{\\mathcal{W}_{2}\\Big(\\mathcal{N}(\\mu_{k},\\mathbf{I}),\\mathcal{N}(\\frac{\\hat{\\mu}_{k}}{1+\\gamma^{2}},\\Sigma_{k}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}||\\hat{\\mu}_{k}||_{2}^{2}\\mathbf{I})\\Big)}\\end{array}$ . ", "page_idx": 30}, {"type": "text", "text": "Theorem 4. (Restatement of Theorem 2) For any class $k\\in\\mathcal{V}$ , assume the norm of corresponding expectation $\\|\\pmb{\\mu}_{k}\\|_{2}^{2}$ is a constant, let $\\mathbb{P}$ , $\\mathbb{Q}_{\\mathbf{X}}$ and $\\mathbb{Q}_{\\mathbf{X}}^{c}$ be the ground truth, clean, and corrupted condition distributions, respectively, where $\\mathbf{X}$ represents the collection of training data points. If $\\gamma=O(1/{\\sqrt{\\operatorname*{max}_{k}n_{k}}})$ , it holds that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{X}}\\Big[\\mathcal{W}_{2}^{2}(\\mathbb{P},\\mathbb{Q}_{\\mathbf{X}})-\\mathcal{W}_{2}^{2}(\\mathbb{P},\\mathbb{Q}_{\\mathbf{X}}^{c})\\vert y=k\\Big]=\\Omega\\Big(\\frac{\\gamma^{2}d}{n_{k}}\\Big),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\mathcal{W}_{2}^{2}(\\cdot,\\cdot)$ denotes the quadratic 2-Wasserstein distance between two distributions, $n_{k}$ is the sample size of $k$ -labeled dataset and $d$ is the data dimension. ", "page_idx": 30}, {"type": "text", "text": "Proof. To express more clearly, we first omit the subscript $k$ of $n_{k}$ $\\mathbf{\\Psi}_{\\cdot},\\hat{\\pmb{\\mu}}_{k}\\,,\\pmb{\\mu}_{k}$ and $\\Sigma_{k}$ . According to Lemma 3 and Lemma 4, we then can directly derive the closed form of Wasserstein distance between two Gaussian as ", "page_idx": 30}, {"type": "text", "text": "\u2022 The squared Wasserstein distance between true data distribution and clean generation distribution ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{d^{2}=\\|\\hat{\\pmb{\\mu}}-\\pmb{\\mu}\\|_{2}^{2}+\\mathrm{Tr}(\\mathbf{I})+\\mathrm{Tr}(\\pmb{\\Sigma})-2\\mathrm{Tr}(\\pmb{\\Sigma}^{\\frac{1}{2}})}}\\\\ {{\\displaystyle=\\|\\hat{\\pmb{\\mu}}-\\pmb{\\mu}\\|_{2}^{2}+d+\\displaystyle\\sum_{i=1}^{d}\\lambda_{i}-2\\displaystyle\\sum_{i=1}^{d}\\sqrt{\\lambda_{i}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "\u2022 The squared Wasserstein distance between true data distribution and corrupted generation distribution ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle d_{c}^{2}=\\Big\\|\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu\\Big\\|_{2}^{2}+\\mathrm{Tr}(\\mathbf{I})+\\mathrm{Tr}\\Big(\\Sigma+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}\\mathbf{I})\\Big)-2\\mathrm{Tr}\\Big((\\Sigma+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}\\mathbf{I})\\Big)^{\\frac{1}{2}}\\Big)}\\\\ {\\displaystyle\\quad=\\Big\\|\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu\\Big\\|_{2}^{2}+d+\\displaystyle\\sum_{i=1}^{d}\\Big(\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}\\Big)-2\\displaystyle\\sum_{i=1}^{d}\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "The difference in squared Wasserstein distance is ", "page_idx": 30}, {"type": "equation", "text": "$$\nd^{2}-d_{c}^{2}=-\\Big\\|\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu\\Big\\|_{2}^{2}+\\|\\hat{\\mu}-\\mu\\|_{2}^{2}-\\sum_{i=1}^{d}\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}+2\\sum_{i=1}^{d}\\Big(\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}}-\\sqrt{\\lambda_{i}}\\Big).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We consider the expectation error to reduce the randomness of $\\hat{\\pmb{\\mu}}$ as ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}[d^{2}-d_{c}^{2}]=-\\mathbb{E}\\left[\\left\\Vert\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu\\right\\Vert_{2}^{2}\\right]+\\mathbb{E}\\left[\\Vert\\hat{\\mu}-\\mu\\Vert_{2}^{2}\\right]+\\sum_{i=1}^{d}\\mathbb{E}\\left[2\\Big(\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}}\\Vert\\hat{\\mu}\\Vert_{2}^{2}-\\sqrt{\\lambda_{i}}\\Big)-\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\Vert\\hat{\\mu}\\Vert_{2}^{2}\\right].\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We notice that the expectation error can be decomposed into two parts. The error of the first part being caused by the difference in means between the generated distribution and the true distribution. Since the distribution of empirical mean is $\\begin{array}{r}{\\hat{\\pmb{\\mu}}\\sim\\mathcal{N}(\\pmb{\\mu},\\frac{1}{n}\\mathbf{I})}\\end{array}$ where $n_{k}$ is the sample size of $k$ -labeled dataset, we get ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\mathbb{E}\\left[\\left\\Vert\\displaystyle\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu\\right\\Vert_{2}^{2}\\right]+\\mathbb{E}\\left[\\|\\hat{\\mu}-\\mu\\|_{2}^{2}\\right]=-\\displaystyle\\frac{d}{n(1+\\gamma^{2})^{2}}-(\\frac{\\gamma^{2}}{1+\\gamma^{2}})^{2}\\|\\mu\\|_{2}^{2}+\\frac{d}{n}}\\\\ &{\\phantom{-\\displaystyle\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu}\\geq-\\displaystyle\\frac{d}{n}+\\frac{2d\\gamma^{2}}{n}-o(\\gamma^{4})+\\frac{d}{n}}\\\\ &{\\phantom{-\\displaystyle\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu}=\\frac{2d\\gamma^{2}}{n}-o(\\gamma^{4}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The second part is attributable to the difference in covariance. ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i=1}^{d}\\mathbb{E}\\left[2\\Big(\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}}-\\sqrt{\\lambda_{i}}\\Big)-\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\mu}\\|_{2}^{2}\\right]}\\\\ &{\\displaystyle\\geq\\sum_{i=1}^{d}\\mathbb{E}\\left[\\gamma^{2}\\frac{\\|\\hat{\\mu}\\|_{2}^{2}}{\\sqrt{\\lambda_{i}}}-\\gamma^{2}\\|\\hat{\\mu}\\|_{2}^{2}-o(\\gamma^{4})\\right]}\\\\ &{\\displaystyle=\\gamma^{2}\\sum_{i=1}^{d}\\mathbb{E}\\Big[(\\frac{1}{\\sqrt{\\lambda_{i}}}-1)\\|\\hat{\\mu}\\|_{2}^{2}\\Big]-o(\\gamma^{4}d).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "By the law of total expectation ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{d}\\mathbb{E}\\Big[(\\frac{1}{\\sqrt{\\lambda_{i}}}-1)\\|\\hat{\\mu}\\|_{2}^{2}\\Big]=\\displaystyle\\sum_{i=1}^{d}\\mathbb{E}\\Big[\\|\\hat{\\mu}\\|_{2}^{2}\\mathbb{E}\\Big(\\frac{1}{\\sqrt{\\lambda_{i}}}|\\hat{\\mu}\\Big)\\Big]-d}&{}\\\\ {\\displaystyle~\\overset{(a)}{\\geq}\\mathbb{E}\\Big[\\displaystyle\\sum_{i=1}^{d}\\frac{\\|\\hat{\\mu}\\|_{2}^{2}}{\\sqrt{\\mathbb{E}(\\lambda_{i}|\\hat{\\mu})}}\\Big]-d}&{}\\\\ {\\displaystyle~\\overset{(b)}{\\geq}\\mathbb{E}\\Bigg[\\frac{\\|\\hat{\\mu}\\|_{2}^{2}}{\\sqrt{\\sum_{i=1}^{d}\\mathbb{E}\\big(\\lambda_{i}|\\hat{\\mu}\\big)}}\\Bigg]-d.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "(a) and (b) achieve by the Jensen\u2019s inequality given $\\frac{1}{\\sqrt{\\lambda_{i}}}$ is a convex function ", "page_idx": 31}, {"type": "text", "text": "By Lemma 5, we derive ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathrm{Tr}\\Big(\\mathbb{E}\\Big[\\mathrm{Var}(\\mathbf{x}|\\hat{\\mu})\\Big]\\Big)=\\mathrm{Tr}\\Big(\\mathbb{E}\\Big[\\Sigma|\\hat{\\mu}\\Big]\\Big)=\\mathrm{Tr}\\Big(\\mathbf{U}\\mathbb{E}\\Big[\\mathbf{A}|\\hat{\\mu}\\Big]\\mathbf{U}^{\\top}\\Big)=\\sum_{i=1}^{d}\\mathbb{E}(\\lambda_{i}|\\hat{\\mu})=\\frac{n-1}{n}d.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Hence, we get ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{d}\\mathbb{E}\\bigg[(\\frac{1}{\\sqrt{\\lambda_{i}}}-1)\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}\\bigg]\\geq\\mathbb{E}\\Big[\\frac{\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}}{\\sqrt{\\sum_{i=1}^{d}\\mathbb{E}(\\lambda_{i}|\\hat{\\pmb{\\mu}})}}\\Big]-d}&{}\\\\ {=\\Big(\\sqrt{\\frac{n}{n-1}}-1\\Big)d\\mathbb{E}[\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}]}&{}\\\\ {=\\Big(\\sqrt{\\frac{n}{n-1}}-1\\Big)\\Big(\\frac{d^{2}}{n}+d\\|\\pmb{\\mu}\\|_{2}^{2}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The second part is ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i=1}^{d}\\mathbb{E}\\left[2\\Big(\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}}-\\sqrt{\\lambda_{i}}\\Big)-\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\|\\hat{\\pmb{\\mu}}\\|_{2}^{2}\\right]}\\\\ &{\\displaystyle\\geq\\gamma^{2}\\Big(\\sqrt{\\frac{n}{n-1}}-1\\Big)(\\frac{d^{2}}{n}+d\\|\\pmb{\\mu}\\|_{2}^{2})-o(\\gamma^{4}d).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Therefore, with small noise ratio $\\gamma$ , we then can conclude that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[d^{2}-d_{c}^{2}]=-\\mathbb{E}\\left[\\left\\Vert\\frac{\\hat{\\mu}}{1+\\gamma^{2}}-\\mu\\right\\Vert_{2}^{2}\\right]+\\mathbb{E}\\left[\\Vert\\hat{\\mu}-\\mu\\Vert_{2}^{2}\\right]+\\displaystyle\\sum_{i=1}^{d}\\mathbb{E}\\left[2\\Big(\\sqrt{\\lambda_{i}+\\frac{\\gamma^{2}}{1+\\gamma^{2}}}\\Vert\\hat{\\mu}\\Vert_{2}^{2}-\\sqrt{\\lambda_{i}}\\Big)-\\frac{\\gamma^{2}}{1+\\gamma^{2}}\\Vert\\hat{\\mu}\\Vert_{2}^{2}\\right]}\\\\ &{\\phantom{2p c}\\geq\\displaystyle\\frac{2d\\gamma^{2}}{n}+\\gamma^{2}\\Big(\\sqrt{\\frac{n}{n-1}}-1\\Big)\\Big(\\frac{d^{2}}{n}+d\\Vert\\mu\\Vert_{2}^{2}\\Big)-o(\\gamma^{4}d).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Noting that $\\sqrt{n/(n-1)}-1=-\\Theta(1/n)$ when $n$ is large, then if the corruption level $\\gamma$ satisfies $\\gamma=O(1/{\\sqrt{n}})$ , for any class $k$ , we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\mathbb{E}[d^{2}-d_{c}^{2}]=\\Omega\\Big(\\frac{\\gamma^{2}d}{n}\\Big).\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "This completes the proof. ", "page_idx": 32}, {"type": "text", "text": "B Details of Condition Corruption, Model Training and Evaluation ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "In this section, we provide detailed training setup of each diffusion models we studied in the main paper, the synthetic corruption for IN-1K and CC3M, the annotation process of IN-100, and the evaluation metrics we adopted. ", "page_idx": 32}, {"type": "text", "text": "B.1 Synthetic Condition Corruption ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We mainly studied four types of condition corruption in this paper, with two datasets. For IN-1K, we used random symmetric and asymmetric condition corruption. For CC3M, we adopted text swapping and LLM re-writing corruption. We used several levels of corruption $\\eta=\\{0,2.5,7.5,10,15,\\bar{20}\\}\\bar{\\%}$ . ", "page_idx": 32}, {"type": "text", "text": "Symmetric Condition Corruption for IN-1K. To introduce symmetric condition corruption in IN-1K according to a corruption ratio $\\eta$ , we randomly sample a $(\\mathbf{x},y)$ pair from the dataset, and filp $y$ to another class according to the class prior in IN-1K to obtain $y^{c}$ , until the ratio of $y^{c}$ satisfies $\\eta$ . ", "page_idx": 32}, {"type": "text", "text": "fTirhset nf, inwd et hrae ncdlaosms loy vsearlmapp lbe fIrNo-m1 tKh ea ndda tCa IsFuAbsRe-t1 0w0h oussien sWatoirsdfiNese taend da sf $\\mathcal{V}_{\\mathrm{IN-1K}}^{\\mathrm{C-100}}$ $(\\mathbf{x},y)$ $y$ $y\\in\\mathcal{Y}_{\\mathrm{IN-1K}}^{\\mathrm{C-100}}$ $y$ the remaining classes of the overlapped set YICN\u2212\u2212110K0/y. ", "page_idx": 32}, {"type": "text", "text": "Text Swapping Condition Corruption for CC3M. For CC3M, where $y$ is text captions for the images, we randomly sample two pairs and swap the text of these two pairs to introduce condition corruptions. This mainly follows Chen et al. [48], where very disruptive corruption is introduced. ", "page_idx": 32}, {"type": "text", "text": "LLM Text Condition Corruption for CC3M. Text swapping corruption may not be common in practice for image-text datasets. Instead, we may encounter captions that have unmatched entities or partially unmatched sentences with the images. To study the text corruption in a more realistic scenarios, we use GPT-4 and prompt it to re-write the captions to introduce corruptions. We pre-define 5 levels of corruption in the prompt, and randomly sample a level as input to GPT-4. ", "page_idx": 32}, {"type": "text", "text": "B.2 Automatic ImageNet-100 Annotation ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Here, we present the details of annotate ImageNet-100 for personalization of LDMs using ControlNet and T2I-Adapters. A few examples of the annotated images and captions are shown in Fig. 10. ", "page_idx": 32}, {"type": "text", "text": "Canny Edge. For canny edge, we directly use the Canny detector from OpenCV to annotate the images. We set the low threshold and high threshold of canny detector to 100 and 200 respectively. ", "page_idx": 32}, {"type": "text", "text": "Segmentation Mask from SAM. We use SAM to annotate segmentation masks from IN-100 images. We directly use the colormap of the segmentation masks as input control to ControlNet and T2I-Adapters. ", "page_idx": 32}, {"type": "text", "text": "Captions from BLIP. We use BLIP captioning model to generate captions for IN-100 for adapting text-conditional LDMs. ", "page_idx": 32}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/eb02b840868ba7e2439e91a7cc59f7e321067bfdd5c87da31c708bc314711897.jpg", "img_caption": ["Figure 10: Annotation examples of IN-100. "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "B.3 LDM Pre-training Setup ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "The pre-training setup of LDM-4 mainly follows Rombach et al. [9], as shown in Table 3. For LDM-4 models, we use a VQ-VAE [56] with a down-sampling factor of 4 and a latent space with shape $64\\times64\\times3$ . It also has a vocabulary size of 8196. ", "page_idx": 33}, {"type": "table", "img_path": "VFpXYBqMSU/tmp/cc225b8139e2be59e3db7a8479776c5abe549268519015bb573e343a6ffa3b0f.jpg", "table_caption": ["Table 3: Hyper-parameters of IN-1K class-conditional and CC3M text-conditional LDMs. "], "table_footnote": [], "page_idx": 33}, {"type": "text", "text": "IN-1K. The hyper-parameters of training IN-1K class-conditional LDMs are summarized as follows. We use a U-Net with channels of 192 and channel multipliers of $1,2,3,5$ as the denoising network backbone. We use class embedding, i.e., embedding layer, for computing the embeddings of class labels. The conditional embedding is injected to the U-Net with cross-attention. We use DDPM with linear schedule of 1000 steps. The batch size is set to 64 per GPU, and the learning rate is set to 1e-4 Training IN-1K LDMs for 178K iterations takes about 2.5 days on 8 NVIDIA A100. ", "page_idx": 33}, {"type": "text", "text": "CC3M. We use a same U-Net as denoising network backbone. We adjust the training iterations to 396K iterations for CC3M, which takes 7.5 days to train on 8 NVIDIA A100. We use a pre-trained BERT model (bert-base-uncased) for the conditional embeddings, and it is fully trainable. ", "page_idx": 33}, {"type": "text", "text": "B.4 DiT Pre-training Setup ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We pre-train DiT-XL/2 on IN-1K follows Peebles et al. [11]. The hyper-parameters are shown in Table 4. We train DiT-XL/2 for 400K training iterations using a per GPU batch size of 32 on 8 NVIDIA A100, which takes around 2.5 days. Compared to LDM-4, DiT-XL/2 used a fine-tuned VQ-VAE with a down-sampling factor of 8, a latent space of shape $32\\times32\\times4$ , and a vocabulary size of 16384. DiT-XL/2 has a denoising network backbone based on Transformer architecture and uses Adaptive LayerNorm, initialized with zeros, for injecting the conditional information. ", "page_idx": 33}, {"type": "table", "img_path": "VFpXYBqMSU/tmp/9bb3a93000f8796ae3afc16df56a3ba6a718f33d9ce8610090f1a270d26f84d6.jpg", "table_caption": ["Table 4: Hyper-parameters of IN-1K class-conditional DiT-XL/2. "], "table_footnote": [], "page_idx": 34}, {"type": "text", "text": "B.5 LCM Pre-training Setup ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "LCM distills the pre-trained Stable Diffusion models to enable faster inference with fewer steps. We choose Stable Diffusion v1.5 as the teacher model and conduct distillation for 35K iterations, which takes 1.5 days on 8 NVIDIA A100 GPUs. We use a learning rate of $1e{-5}$ . ", "page_idx": 34}, {"type": "text", "text": "B.6 ControlNet and T2I-Adapter Personalization Setup ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We use the implementation of ControlNet and T2I-adapter of Diffusers [155] for downstream personalization tasks. Default learning rate and batch size from Diffusers are used for these two methods, and we set the training epochs for IN-100 as 10. On 4 NVIDIA V100 GPUs, training ControlNet and T2I-Adapter with LDM-4 takes about 6 hours. ", "page_idx": 34}, {"type": "text", "text": "B.7 Evaluation Metrics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We introduce the details of metrics we used to evaluate the diffusion models here. Due to the known difficulties of evaluating generative models, we adopt most of the existing criteria to evaluate the models we have trained. ", "page_idx": 34}, {"type": "text", "text": "Fr\u00e9chet Inception Distance (FID) [63]. FID measures the distance between real and generated images in the feature space of an ImageNet-1K pre-trained classifier [156], indicating the similarity and fidelity of the generated images to real images. ", "page_idx": 34}, {"type": "text", "text": "sFID [71]. sFID utilizes the mid-level features of the inception network [156], which are more sensitive to spatial variability. ", "page_idx": 34}, {"type": "text", "text": "Inception Score (IS) [64]. IS also measures the fidelity and diversity of generated images. It consists of two parts: the first part measures whether each image belongs confidently to a single class of an ImageNet-1K pre-trained image classifier [156] and the second part measures how well the generated images capture diverse classes. ", "page_idx": 34}, {"type": "text", "text": "Precision and Recall [65]. The real and generated images are first converted to non-parametric representations of the manifolds using k-nearest neighbors, on which the Precision and Recall can be computed. Precision is the probability that a random generated image from estimated generated data manifolds falls within the support of the manifolds of estimated real data distribution. Recall is the probability that a random real image falls within the support of generated data manifolds. Thus, precision measures the general quality and fidelity of the generated images, and the recall measures the coverage and diversity of the generated images. ", "page_idx": 34}, {"type": "text", "text": "Top- $.1\\%$ Relative Mahalanobis Distance (RMD) Score [67]. RMD score measures the sample complexity and difficulty. It is defined as the difference between the Mahalanobis distances of a sample induced by the class-specific and class-agnostic Gaussian distributed estimated from the generated data. Given the dataset $\\{(\\mathbf{x}_{i},y_{i})\\}_{i\\in[N]}$ , we first compute the features using the CLIP ViTB-16 encoder from the images as $G(\\mathbf{x})$ . The class-specific Gaussian distribution is then estimated: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}(G(\\mathbf{x})\\mid y=k)=\\mathcal{N}\\left(G(\\mathbf{x})\\mid\\mu_{k},\\Sigma\\right)}\\\\ &{\\qquad\\qquad\\quad\\mu_{k}=\\frac{1}{N_{k}}\\displaystyle\\sum_{i:y_{i}=k}G\\left(\\mathbf{x}_{i}\\right)}\\\\ &{\\qquad\\qquad\\quad\\Sigma=\\displaystyle\\frac{1}{N}\\sum_{k}\\sum_{i:y_{i}=k}\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{k}\\right)\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{k}\\right)^{\\top}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The class-agnostic Gaussian distribution is estimated over all data as; ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}(G(\\mathbf{x}))=\\mathcal{N}\\left(G(\\mathbf{x})\\mid\\mu_{\\mathrm{agn}},\\Sigma_{\\mathrm{agn}}\\right),}\\\\ &{\\quad\\quad\\mu_{\\mathrm{agn}}=\\displaystyle\\frac{1}{N}\\sum_{i}^{N}G\\left(\\mathbf{x}_{i}\\right),}\\\\ &{\\quad\\quad\\Sigma_{\\mathrm{agn}}=\\frac{1}{N}\\sum_{i}^{N}\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{\\mathrm{agn}}\\right)\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{\\mathrm{agn}}\\right)^{\\top}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "The RMD is defined as: ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{R M D}\\left(\\mathbf{x}_{i},y_{i}\\right)=\\mathcal{M}\\left(\\mathbf{x}_{i},y_{i}\\right)-\\mathcal{M}_{\\mathrm{agn}}\\left(x_{i}\\right)}\\\\ &{\\quad\\mathcal{M}\\left(\\mathbf{x}_{i},y_{i}\\right)=-\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{y_{i}}\\right)^{\\top}\\Sigma^{-1}\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{y_{i}}\\right)}\\\\ &{\\quad\\mathcal{M}_{\\mathrm{agn}}\\left(\\mathbf{x}_{i}\\right)=-\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{\\mathrm{agn}}\\right)^{\\top}\\Sigma_{\\mathrm{agn}}^{-1}\\left(G\\left(\\mathbf{x}_{i}\\right)-\\mu_{\\mathrm{agn}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "We compute the RMD score for all generated images, and report only the top- $1\\%$ of them. ", "page_idx": 35}, {"type": "text", "text": "Average Top-5 $L_{2}$ Distances. As an additional metric of sample diversity, we compute the $L_{2}$ distance of each generated image with the top-5 nearest neighbor training images. To reduce computation requirement of searching over the raw pixel space, we use the CLIP ViT-B-16 image encoder [157] to transform images into the feature space before calculating the $L_{2}$ distance. This metric measures the distance of generated samples with training images, as a proxy evaluation of diversity and memorization. ", "page_idx": 35}, {"type": "text", "text": "TopPR F1 [72]. TopPR is a set of reliable evaluation metrics with statistically consistent estimates of generated data and real data. We use the F1 score, computed from the TopPR Precision and Recall as an additional metric to evaluate the general quality and diversity of generated images. ", "page_idx": 35}, {"type": "text", "text": "CLIP Score [66]. CLIP score measures the cosine similarity between the CLIP embedding of an image-text pair. It is widely used as a metric to evaluate the fidelity and alignment of the generated images and the conditional text prompts [9]. ", "page_idx": 35}, {"type": "text", "text": "Memorization Ratio [73]. We compute the memorization ratio as the percentage of generated images whose $L_{2}$ distances with their nearest neighbor training images are below a pre-defined threshold. We compute the distances in the feature space of CLIP ViT-B-16 image encoder [157] due to the massive size and resolution of the training images and set the threshold as 0.12. Although there are several studies using the distance comparison between the first and second nearest neighbor as a reflection of memorization [158, 159], we found that this metric is not effective for large-scale datasets. ", "page_idx": 35}, {"type": "text", "text": "Entropy. We compute the entropy metric within the latent space of the pre-trained VQ-VAE [58, 56]. Since LDMs (and DiT) learn the data distribution from the latent space of VQ-VAE, we can compute the sample entropy $\\mathbb{E}[H(\\mathbf{x})]$ using the generated and flatten latent vector $\\mathbf{\\dot{x}}\\in\\mathit{\\mathbb{R}}^{H W\\times D}$ and the codebook $\\mathcal{C}\\in\\mathbb{R}^{\\bar{C}\\times D}$ of VQ-VAE, where $H$ and $W$ are the height and weights of the original latent vectors, $D$ indicates the dimension of the latent space, and $C$ denotes the number of embeddings of the codebook. We compute the probability of each latent vector as Softmax $\\left(\\lVert\\mathbf{x}-\\boldsymbol{\\mathcal{C}}\\rVert_{2}^{2}/\\tau\\right)$ , where $\\tau$ is a temperature parameter controlling the sharpness of the probability. We compute entropy as: ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{E}[H(\\mathbf{x})]=\\frac{1}{N H W}\\sum_{i}^{N}\\sum_{j}^{H W}\\sum_{k}^{C}\\mathrm{Softmax}\\left(\\|\\mathbf{x}_{(i,j)}-\\mathcal{C}\\|_{2}^{2}/\\tau\\right)\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "C Full Results of Pre-training Evaluation ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "In this section, we present all results of our pre-training evaluation, over different diffusion models, including LDM-4, DiT-XL/2, and LCM-v1.5, and various types of condition corruption. ", "page_idx": 35}, {"type": "text", "text": "C.1 Quantitative Results ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "We present the full evaluation results of IN-1K class-conditional LDMs and CC3M textconditional LDMs in Fig. 11 and Fig. 12 respectively. All the results are computed from using a set of guidance scales. For IN-1K LDMs, we use $\\quad s\\quad\\in$ {1.5, 1.75, 2.0, 2.25, 2.5, 3.0, 3.5, 4.0, 4.5, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 9.0, 10.0}. For CC3M LDMs, we use s \u2208 {1.5, 2.0, 2.5, 2.75, 3.0, 3.25, 3.5, 4.0, 5.0, 6.0, 7.0, 7.5, 8.0, 10.0} For all the metrics, including FID, IS, Precision, Recall, sFID, TopPR F1, and CLIP score, we can all observe that slight condition corruption makes LDMs perform better, with improved image quality and diversity. We also observe that, when there is condition corruption in the dataset, the memorization ratio based on $L_{2}$ distances actually decreases, in line with observations as in Gu et al. [158]. ", "page_idx": 35}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/fc88baf980b156c11ed9738864f670f2c0f482a30d3936de3cb2f72211456b51.jpg", "img_caption": ["Figure 11: Qualitative evaluation results of 50K images generated by class-conditional LDMs pretrained on ImageNet-1K with synthetic corruptions. The images are generated with various guidance scales using 1K class conditions and compared with 50K validation images of ImageNet-1K. "], "img_footnote": [], "page_idx": 36}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "By default we use DPM scheduler for generating the images with 50 inference steps. But we also study the generation of DDIM scheduler with 250 inference steps, as adopted in [9]. Due to the computation cost of running DDIM scheduler for 250 steps, we only study it with IN-1K LDM-4. The results are shown in Fig. 13. One can observe the same trends from the metrics using DPM and DDIM, demonstrating our findings are scheduler agnostic. ", "page_idx": 36}, {"type": "text", "text": "We then show the pre-training results of DiT-XL/2 and LCM-v1.5 in Fig. 19, where we primarily compute the FID, IS, Precision, and Recall. For DiT-XL/2, we use $\\begin{array}{r l r}{s}&{{}\\in}&{\\{1.5,1.75,\\dot{2}.0,2.25,2.5,3.0,3.5,4.0,4.5,5.0,5.5\\}.}\\end{array}$ For LCM-v1.5, we use $s\\quad\\in$ {1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 6.0, 6.5, 7.0, 7.5, 8.0, 9.0, 10.0}. Slight condition corruption also facilitates the performance by using the most suitable guidance scale. ", "page_idx": 36}, {"type": "text", "text": "We additionally include the FID and IS trend along training for LDM IN-1K model with no corruption and $2.5\\%$ corruption, using a guidance scale of 2.5, as shown in Table 5. Slight corruption begins to be effective at the very early stage of training. ", "page_idx": 36}, {"type": "text", "text": "Finally, we present the results of LDMs pre-trained on CC3M with LLM corruption and IN-1K with asymmetric corruption, where similar observations still hold. ", "page_idx": 36}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/7b3417d66e83c811abf54cb312ab5b1dd6c3807fffdc2db916828b5c8161ea54.jpg", "img_caption": ["Figure 12: Qualitative evaluation results of 50K images generated by class-conditional LDMs pretrained on CC3M with synthetic corruptions. The images are generated with various guidance scales using 5K text conditions from MS-COCO and compared with validation images of MS-COCO. "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/d28b27cd6f2eb49eef100158bffe4b480e0431e5233db0f729225274888641c4.jpg", "img_caption": ["Figure 13: Qualitative evaluation results of 50K images generated by class-conditional LDMs pretrained on ImageNet-1K with synthetic corruptions. The images are generated with various guidance scales using 1K class conditions and compared with 50K validation images of ImageNet-1K. We use DDIM scheduler with 250 inference steps for these results. "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "C.2 Qualitative Results ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "We present more visualization results of class-conditional LDM-4 in Fig. 18, class-conditional DiTXL/2 in Fig. 19, text-conditional LDM-4 in Fig. 20, and text-conditional LCM-v1.5 in Fig. 21. One can observe that DMs pre-trained with slight condition corruption in general more visually appealing images. ", "page_idx": 37}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/5923947223345b074f431beff38cb396c07ca3c8438aee95b7bb512172ff98e3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Figure 14: Qualitative evaluation results of 50K images generated by class-conditional DiT-XL/2 pre-trained on IN-1K with synthetic corruptions. The images are generated with various guidance scales using 1K class conditions from IN-1K and compared with validation images of IN-1K. ", "page_idx": 38}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/8cf270b047d8eb75de356d4d743ff1aa55a5b16200e3b31f4f0208b3a408ddae.jpg", "img_caption": [], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Figure 15: Qualitative evaluation results of 50K images generated by text-conditional LCM-v1.5 pre-trained on CC3M with synthetic corruptions. The images are generated with various guidance scales using 5K text conditions from MS-COCO and compared with validation images of MS-COCO. ", "page_idx": 38}, {"type": "text", "text": "D Full Results of Downstream Personalization Evaluation ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "We present complete results of downstream personalization here. ", "page_idx": 38}, {"type": "text", "text": "D.1 Quantitative Results ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "We show the results of ControlNet IN-1K LDM-4 in Fig. 22, T2I-Adapter IN-1K LDM4 in Fig. 23, ControlNet CC3M LDM-4 in Fig. 24, and T2I-Adapter CC3M LDM-4 in Fig. 25. For all personalization experiments, we compute the results for both Canny and SAM spatial controls. Guidance scales of $\\{1.25,1.5,\\bar{2.0},2.25,2.5,3.0,4.0,5.0,6.0,7.0\\}$ and {2.0, 3.0, 4.0, 5.0, 6.0, 6.5, 7.0, 7.5, 8.0, 8.5, 9.0, 10.0} are used for IN-1K models and CC3M models, respectively, for all experiments here. ", "page_idx": 38}, {"type": "text", "text": "From the results, one can observe that models pre-trained with slight condition corruption also present the best performance in downstream personalization tasks. ", "page_idx": 38}, {"type": "text", "text": "D.2 Qualitative Results ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "We present the qualitative comparison of ControlNet personalization results here. Since T2I-Adapter personalization results are similar but visually worse (quantitatively worse too), we skip their results. The visualizations of ControlNet IN-1K LDM-4 with Canny and SAM conditions are shown in Fig. 26 and Fig. 27, respectively. The visualizations of ControlNet CC3M LDM-4 with Canny and SAM conditions are shown in Fig. 28 and Fig. 29, respectively. Similarly, models pre-trained with slight condition corruption present the best image quality. ", "page_idx": 38}, {"type": "text", "text": "Table 5: FID and IS along training of LDM IN-1K with guidance scale 2.5. ", "page_idx": 39}, {"type": "table", "img_path": "VFpXYBqMSU/tmp/90a0708ee7f977f8d7c9f77602a7ad02e9b1ede78e549fe07b546ec1a43df3b0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 39}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/f55346914b27a50c29630f7d0a7387953aaa264b46f3a7f4954b904822073433.jpg", "img_caption": [], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "Figure 16: Qualitative evaluation results of 50K images generated by text-conditional LDMs pretrained on CC3M with LLM re-writing corruptions. The images are generated with various guidance scales using 5K text conditions from MS-COCO and compared with validation images of MS-COCO. ", "page_idx": 39}, {"type": "text", "text": "E Full Results of Conditional Embedding Perturbation ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "E.1 Qualitative Results ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "More visualizations of CEP, compared with clean and IP pre-trained are shown here. We present the more results of IN-1K LDM-4 and DiT-XL/2 in Fig. 30(a) and Fig. 30(b), respectively. We also present more results of CC3M LDM-4 and LCM-v1.5 in Fig. 31(a) and Fig. 31(b), respectively. CEP generally helps DMs generate more visually appealing and realistic images. We also show the more personalization visualization in Fig. 32 and Fig. 33. ", "page_idx": 39}, {"type": "text", "text": "E.2 Ablation Study ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "In Fig. 8(a), we compute the $L_{2}$ distance of perturbed condition embeddings and the clean ones, as a measurement for the corruption levels (of CEP). Here, we elaborate how we compute the $L_{2}$ distances. For fixed corruption, we calculate the distances as: ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\frac{1}{N}\\sum_{i=1}^{N}\\|\\mathbf{c}_{\\theta^{*}}(y_{i}^{c})-\\mathbf{c}_{\\theta^{*}}(y_{i})\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where $\\theta^{*}$ is learned from clean data. For CEP, we directly calculate the $L_{2}$ norm of sampled noise: ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{N}\\|\\pmb{\\sigma}_{i}\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "E.3 Comparison with Dropout and Label Smoothing ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Here, we additionally compare CEP with dropout and label smoothing on LDM IN-1K models, which are two alternatives that also introduce perturbations in class embeddings. The results are shown in Table 6. One can observe that, both dropout and label smoothing have similar regularization effects on training diffusion models, whereas CEP-U and CEP-G is more effective. ", "page_idx": 39}, {"type": "text", "text": "E.4 Comparison with Fixed and Random Corruption ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "We further compare with fixed CEP corruption, and random data corruption, to study the effects of fixed and random perturbation to train diffusion models. For fixed CEP-U, we first select the samples ", "page_idx": 39}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/fb4f98137292a7a8a34a43e2a5230edaf080e293ad1ae51549ca681b453f71c8.jpg", "img_caption": [], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "Figure 17: Qualitative evaluation results of 50K images generated by class-conditional LDMs pretrained on IN-1K with asymmetric corruptions. The images are generated with various guidance scales using 1K class conditions from IN-1K and compared with validation images of IN-1K. ", "page_idx": 40}, {"type": "table", "img_path": "VFpXYBqMSU/tmp/0959cf5046a58c715b799620490879f0e3eef7aa189b25794c78f02adeec3a3a.jpg", "table_caption": ["Table 6: Comparison of CEP with dropout and label smoothing on LDM IN-1K. "], "table_footnote": [], "page_idx": 40}, {"type": "text", "text": "to add perturbation, and then fix them during training. For random data corruption, we randomly choose samples during training to make their label noisy by filpping to other classes. From the results in Table 7, we show that CEP works the best among all corruption methods. Also fixed CEP is more effective than adding data corruption (fixed and random). Random data corruption can be viewed as a CEP-variant with embeddings from flipping label instead of adding noise, and thus is also more effective than fixed data corruption. ", "page_idx": 40}, {"type": "table", "img_path": "VFpXYBqMSU/tmp/31a0911c493714840c46af2b7559794b335edb8069ec7c6fbb9e40843807ce76.jpg", "table_caption": ["Table 7: Comparison of fixed and random corruption on LDM IN-1K. "], "table_footnote": [], "page_idx": 40}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/2efa1b516ebef9804648754d3820da28adbe5128c7f0b733fb66f329cb6c9e30.jpg", "img_caption": ["Figure 18: Visualization of LDMs IN-1K pre-training results. "], "img_footnote": [], "page_idx": 41}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/d677fddbe1dc42a02431fb1d3112b9d34cd3819d81bceba028dc74d83809fbb1.jpg", "img_caption": ["Figure 19: Visualization of DiT-XL/2 IN-1K pre-training results. "], "img_footnote": [], "page_idx": 42}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/c9c7eda0fc43615f8fca2678eb489194fc1d2c00f6982944e9ab10cac0f934fb.jpg", "img_caption": ["Figure 20: Visualization of LDMs CC3M pre-training results. ", ""], "img_footnote": [], "page_idx": 43}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 44}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/1699a874357f81af24d2777e2c2ce7f89ac13a7921e60deab104eb66bb6c5a6f.jpg", "img_caption": ["Figure 21: Visualization of LCM CC3M pre-training results. ", ""], "img_footnote": [], "page_idx": 44}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/beb86194ea5e090861a622e0337bd6ac08950d6bce596c5cc33ea7135d53d45f.jpg", "img_caption": ["Figure 22: Qualitative evaluation results of 5K images generated by class-conditional LDMs pretrained on ImageNet-1K and personalized on ImageNet-100 using ControlNet. We personalized the models with different control styles, including canny ((a) - (d)), segmentation mask from SAM ((e) - (h)), and lineart $((\\mathrm{i})-(1))$ . The images are generated using 100 class conditions with various guidance scales, compared with 5K validation images of ImageNet-100. "], "img_footnote": [], "page_idx": 45}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/83c1fc1d5bc036604b7418527627436c569dfd9330d728f2943e4e721e358d12.jpg", "img_caption": ["Figure 23: Qualitative evaluation results of 5K images generated by class-conditional LDMs pretrained on ImageNet-1K and personalized on ImageNet-100 using T2I-Adapter. We personalized the models with different control styles, including canny ((a) - (d)), segmentation mask from SAM ((e) - (h)), and lineart ((i) - (l)). The images are generated using 100 class conditions with various guidance scales, compared with 5K validation images of ImageNet-100. "], "img_footnote": [], "page_idx": 45}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/508f568318d0ba2aeb8971f89315d9ed8b74fdc9d06466dcdfbb1faa1229c045.jpg", "img_caption": ["Figure 24: Qualitative evaluation results of 5K images generated by text-conditional LDMs pretrained on CC3M and personalized on ImageNet-100 using ControlNet. We personalized the models with different control styles, including canny ((a) - (d))and segmentation mask from SAM ((e) - (h)). The images are generated using text captions annotated from BLIP with various guidance scales, compared with 5K validation images of ImageNet-100. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/eace0db514325957c096c822658e3e90e791d196b7c402fe14de2692bfe8d979.jpg", "img_caption": ["Figure 25: Qualitative evaluation results of 5K images generated by text-conditional LDMs pretrained on CC3M and personalized on ImageNet-100 using T2I-Adapter. We personalized the models with different control styles, including canny ((a) - (d)) and segmentation mask from SAM ((e) - (h)). The images are generated using text captions annotated from BLIP with various guidance scales, compared with 5K validation images of ImageNet-100. "], "img_footnote": [], "page_idx": 46}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/5cc1a59021ca31b7ee833fe8377770ad1d761b137d07ce11f251efe57a4a68b0.jpg", "img_caption": ["Figure 26: Visualization of LDMs IN-1K ControlNet Canny personalization results. "], "img_footnote": [], "page_idx": 47}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/4c6e1a1a2981a93e33758d11866da59d75dc2ff243fb6b2f7bfaafff3713ca96.jpg", "img_caption": ["Figure 27: Visualization of LDMs IN-1K ControlNet SAM personalization results "], "img_footnote": [], "page_idx": 47}, {"type": "equation", "text": "$$\n\\eta=2.5\\%\\qquad\\quad\\eta=5\\%\\qquad\\quad\\eta=10\\%\\qquad\\quad\\eta=15\\%\\qquad\\quad\\eta=20\\%\n$$", "text_format": "latex", "page_idx": 48}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/984620ee2b1907653656d5d1c32b4d71ca679a6d888ac7bab0f5f01f81855fb4.jpg", "img_caption": ["Control ", "Figure 28: Visualization of LDMs CC3M ControlNet Canny personalization results. "], "img_footnote": [], "page_idx": 48}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/8081df15a6d8e7cfd32f7713112aade055104bf129056d16cc12ffcba8e5f501.jpg", "img_caption": ["Figure 29: Visualization of LDMs CC3M ControlNet SAM personalization results "], "img_footnote": [], "page_idx": 48}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/5451b36ebec6b28f5d9f87e605327353dd08e529a25bf53ba2d028a0c342f429.jpg", "img_caption": ["Figure 30: Visualization of CEP on IN-1K pre-trained LDM-4 and DiT-XL/2 "], "img_footnote": [], "page_idx": 49}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/281c6dc57ac61c52c91a603a24ff605d1ef393d5c4f9de23838972668baaf082.jpg", "img_caption": ["Figure 31: Visualization of CEP on CC3M pre-trained LDM-4 and LCM-v1.5 "], "img_footnote": [], "page_idx": 50}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/bacd44f53c6b29dea2c89f197005b0b844c498d9d45206a507ef987522f18c02.jpg", "img_caption": ["Figure 32: Visualization of CEP on ControlNet adapted IN-1K pre-trained LDM-4 "], "img_footnote": [], "page_idx": 51}, {"type": "image", "img_path": "VFpXYBqMSU/tmp/5660bbd053a2c68b4038c96f3019dea524f4ef74f5c691c0e79d9c988b0a8909.jpg", "img_caption": ["Figure 33: Visualization of CEP on ControlNet adapted CC3M pre-trained LDM-4 ", "\u201cThere is a large boat that is sailing in the water\u201d "], "img_footnote": [], "page_idx": 51}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 52}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 52}, {"type": "text", "text": "Justification: We claimed contribution in Section 1. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 52}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 52}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Justification: We discussed the limitations in Section 7. ", "page_idx": 52}, {"type": "text", "text": "Guidelines: ", "page_idx": 52}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 52}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 52}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 52}, {"type": "text", "text": "Justification: Full proofs are shown in Appendix A. ", "page_idx": 53}, {"type": "text", "text": "Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 53}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 53}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 53}, {"type": "text", "text": "Justification: All model setups, hyper-parameters, inference details are shown in Appendix. Guidelines: ", "page_idx": 53}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 53}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 53}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 54}, {"type": "text", "text": "Justification: We used public available data and all code will be released. Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 54}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 54}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 54}, {"type": "text", "text": "Justification: All details in main paper and Appendix. Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 54}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 54}, {"type": "text", "text": "Answer: [No] ", "page_idx": 54}, {"type": "text", "text": "Justification: Mainly becuase computational cost. ", "page_idx": 54}, {"type": "text", "text": "Guidelines: ", "page_idx": 54}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 54}, {"type": "text", "text": "", "page_idx": 55}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 55}, {"type": "text", "text": "Justification: All details are shown in Appendix. ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 55}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 55}, {"type": "text", "text": "Justification: All research follows NeurIPS Code of Ethics. Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 55}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 55}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Justification: We discussed at the end of Section 1. ", "page_idx": 55}, {"type": "text", "text": "Guidelines: ", "page_idx": 55}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 55}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 56}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 56}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 56}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 56}, {"type": "text", "text": "Justification: Pre-trained models will be released by reuqest and will be equipped with safety checkers. ", "page_idx": 56}, {"type": "text", "text": "Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 56}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 56}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 56}, {"type": "text", "text": "Justification: All are cited. ", "page_idx": 56}, {"type": "text", "text": "Guidelines: ", "page_idx": 56}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 56}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 57}, {"type": "text", "text": "Answer: [NA] Justification: N/A Guidelines: ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 57}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 57}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 57}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 57}]