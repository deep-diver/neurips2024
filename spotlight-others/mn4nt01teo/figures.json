[{"figure_path": "MN4nt01TeO/figures/figures_1_1.jpg", "caption": "Figure 1: Two-step ARS for L\u221e-bounded attacks. Step M\u2081 adds noise to input X and post-processes the result into a mask w(m1). Step M2 takes masked input w(m1)X and adds noise to get m2. Base classifier g post-processes a weighted average of m1, m2 to output a label. RS reduces to \u03c32 = \u03c3 and w(.) = 1 (no M1).", "description": "This figure illustrates the two-step Adaptive Randomized Smoothing (ARS) process for handling L\u221e-bounded adversarial attacks.  The first step (M\u2081) adds noise to the input (X) and uses a mask model (w) to generate a mask based on the noisy input. This mask focuses on task-relevant information, reducing the input dimension for the next step.  The second step (M\u2082) takes the masked input and adds further noise.  Finally, a base classifier (g) processes a weighted average of the outputs from M\u2081 and M\u2082 to produce the final prediction. The standard Randomized Smoothing (RS) is a special case of this process where there is no masking step (M\u2081).", "section": "2.4 ARS against L\u221e-Bounded Adversaries"}, {"figure_path": "MN4nt01TeO/figures/figures_7_1.jpg", "caption": "Figure 1: Two-step ARS for L\u221e-bounded attacks. Step M\u2081 adds noise to input X and post-processes the result into a mask w(m1). Step M2 takes masked input w(m1)X and adds noise to get m2. Base classifier g post-processes a weighted average of m1, m2 to output a label. RS reduces to \u03c32 = \u03c3 and w(.) = 1 (no M1).", "description": "This figure illustrates the two-step Adaptive Randomized Smoothing (ARS) process for handling L\u221e-bounded adversarial attacks.  The first step (M1) adds noise to the input (X) and uses a mask model (w) to process the noisy input into a mask (w(m1)).  The second step (M2) takes this masked input (w(m1)X) and adds further noise. Finally, a base classifier (g) processes a weighted average of the outputs from steps M1 and M2 to generate the final prediction.  The figure also shows how standard Randomized Smoothing (RS) is a simplified version of ARS.", "section": "3 Two-Step ARS for L\u221e Certification of Image Classification"}, {"figure_path": "MN4nt01TeO/figures/figures_7_2.jpg", "caption": "Figure 3: (left) Original CIFAR-10 images superimposed on backgrounds for different k (except k = 32 which is no background), and (right) their corresponding masks (grayscale) inferred by our mask model w. All masks are for \u03c3 = 0.5. Appendix D.2 shows all the corresponding images across our multi-step architecture.", "description": "This figure shows the input images to the model and the corresponding masks generated by the mask model (M1) in the two-step ARS. The left side shows original CIFAR-10 images superimposed with larger background images of varying sizes (k x k pixels), where k represents the dimension of the input. The right side shows the grayscale masks predicted by the mask model (M1) which highlight the relevant parts of the image that are important for classification. The masks are learned end-to-end during training. Appendix D.2 provides more detail about other stages of the ARS architecture for each image shown in this figure.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_8_1.jpg", "caption": "Figure 2: Certified Test Accuracy on CIFAR-10 (20kBG). (a)-(c) show the effect of dimensionality for (a) no background / k = 32, (b) k = 48, and (c) k = 96 for constant \u03c3 = 0.5. (d)-(f) show the effect of noise for (d) \u03c3 = 0.25, (e) \u03c3 = 0.5 and (f) \u03c3 = 1.0 with dimensionality fixed to k = 64. Each line is the mean and the shaded interval covers +/- one standard deviation across seeds.", "description": "The figure displays the certified test accuracy on CIFAR-10 with distractor backgrounds (20kBG).  It shows how certified accuracy changes with different levels of noise (\u03c3) and input dimensionality (k).  The plots illustrate the impact of both increased dimensionality and noise on the certified accuracy of different methods, including ARS (Adaptive Randomized Smoothing), Cohen et al. (standard randomized smoothing), static mask, UniCR, and S\u00faken\u00edk et al.  ARS shows improved robustness to both higher dimensionality and increased noise levels.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_8_2.jpg", "caption": "Figure 5: ARS masks are localized and input specific.", "description": "This figure shows the test set images for CelebA benchmark and their corresponding masks generated by ARS and static mask. The static mask is almost uniformly 1 across all pixels, while ARS masks are sparse and localized, focusing on the mouth region in each image.", "section": "4.2 CelebA Benchmark: Classification Without Spatial Alignment"}, {"figure_path": "MN4nt01TeO/figures/figures_9_1.jpg", "caption": "Figure 2: Certified Test Accuracy on CIFAR-10 (20kBG). (a)-(c) show the effect of dimensionality for (a) no background / k = 32, (b) k = 48, and (c) k = 96 for constant \u03c3 = 0.5. (d)-(f) show the effect of noise for (d) \u03c3 = 0.25, (e) \u03c3 = 0.5 and (f) \u03c3 = 1.0 with dimensionality fixed to k = 64. Each line is the mean and the shaded interval covers +/- one standard deviation across seeds.", "description": "This figure shows the certified test accuracy of the proposed ARS method on the CIFAR-10 with 20k background dataset.  It illustrates how the certified accuracy changes as a function of the L\u221e radius of adversarial attacks, for different levels of noise (sigma) and input dimensionality (k). The results demonstrate that ARS outperforms other state-of-the-art methods across a range of settings, highlighting its effectiveness in certifying robustness against adversarial examples.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_15_1.jpg", "caption": "Figure 7: UNet structure", "description": "This figure shows the architecture of the Mask model w (M1). It is a UNet architecture which is used to preserve dimensions. It uses a Sigmoid layer at the end of the model to output values between 0 and 1 for mask weights. The hyperparameters of the UNet are: in_channels=3, out_channels=1 (to output a mask), base_channel=32, channel_mult={1,2,4,8}.", "section": "C.1 Mask Architecture"}, {"figure_path": "MN4nt01TeO/figures/figures_17_1.jpg", "caption": "Figure 2: Certified Test Accuracy on CIFAR-10 (20kBG). (a)-(c) show the effect of dimensionality for (a) no background / k = 32, (b) k = 48, and (c) k = 96 for constant \u03c3 = 0.5. (d)-(f) show the effect of noise for (d) \u03c3 = 0.25, (e) \u03c3 = 0.5 and (f) \u03c3 = 1.0 with dimensionality fixed to k = 64. Each line is the mean and the shaded interval covers \u00b1 one standard deviation across seeds.", "description": "This figure displays the certified test accuracy results for the CIFAR-10 dataset with 20k background images (20kBG). It shows how certified accuracy changes with different levels of noise (\u03c3) and input dimensionality (k).  The plots illustrate the impact of increasing dimensionality (by adding background noise) and increasing noise levels on the certified accuracy of different defense methods. Each line represents the mean certified accuracy across multiple runs, with shaded areas indicating the standard deviation.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_18_1.jpg", "caption": "Figure 2: Certified Test Accuracy on CIFAR-10 (20kBG). (a)-(c) show the effect of dimensionality for (a) no background / k = 32, (b) k = 48, and (c) k = 96 for constant \u03c3 = 0.5. (d)-(f) show the effect of noise for (d) \u03c3 = 0.25, (e) \u03c3 = 0.5 and (f) \u03c3 = 1.0 with dimensionality fixed to k = 64. Each line is the mean and the shaded interval covers +/- one standard deviation across seeds.", "description": "This figure displays the certified test accuracy results on the CIFAR-10 dataset with 20k background images, also known as CIFAR-10 (20kBG), for different dimensionality (k) and noise levels (\u03c3). The graphs illustrate how the certified accuracy changes with different levels of L\u221e radius for various methods: ARS, Cohen et al., Static Mask, UniCR, and S\u00faken\u00edk et al. The results show that ARS consistently performs better in most cases.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_18_2.jpg", "caption": "Figure 2: Certified Test Accuracy on CIFAR-10 (20kBG). (a)-(c) show the effect of dimensionality for (a) no background / k = 32, (b) k = 48, and (c) k = 96 for constant \u03c3 = 0.5. (d)-(f) show the effect of noise for (d) \u03c3 = 0.25, (e) \u03c3 = 0.5 and (f) \u03c3 = 1.0 with dimensionality fixed to k = 64. Each line is the mean and the shaded interval covers +/- one standard deviation across seeds.", "description": "This figure shows the certified test accuracy results on the CIFAR-10 dataset with distractor backgrounds (20kBG).  The plots illustrate how certified accuracy changes with different levels of noise (\u03c3) and input dimensionality (k). The experiment evaluates the impact of both higher dimensionality and higher noise levels on the performance of the Adaptive Randomized Smoothing (ARS) method and baseline methods (Cohen et al., Static Mask, UniCR, and Sukenik et al.).", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_19_1.jpg", "caption": "Figure 2: Certified Test Accuracy on CIFAR-10 (20kBG). (a)-(c) show the effect of dimensionality for (a) no background / k = 32, (b) k = 48, and (c) k = 96 for constant \u03c3 = 0.5. (d)-(f) show the effect of noise for (d) \u03c3 = 0.25, (e) \u03c3 = 0.5 and (f) \u03c3 = 1.0 with dimensionality fixed to k = 64. Each line is the mean and the shaded interval covers +/- one standard deviation across seeds.", "description": "This figure displays the certified test accuracy results for the CIFAR-10 dataset with distractor backgrounds (20kBG).  It illustrates how both the dimensionality (k) and noise level (\u03c3) affect the accuracy of different methods: ARS (Adaptive Randomized Smoothing), Cohen et al. (standard Randomized Smoothing), Static Mask (a baseline), S\u00faken\u00edk et al. (a test-time adaptive variance method), and UniCR (a test-time adaptive noise distribution method).  The graphs show that ARS consistently outperforms other methods, particularly as dimensionality increases. This demonstrates the effectiveness of ARS in handling high-dimensional inputs and achieving certified robustness.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_20_1.jpg", "caption": "Figure 1: Two-step ARS for L\u221e-bounded attacks. Step M\u2081 adds noise to input X and post-processes the result into a mask w(m1). Step M2 takes masked input w(m1)X and adds noise to get m2. Base classifier g post-processes a weighted average of m1, m2 to output a label. RS reduces to \u03c32 = \u03c3 and w(.) = 1 (no M1).", "description": "This figure illustrates the two-step adaptive randomized smoothing (ARS) process for handling L\u221e-bounded adversarial attacks.  The first step (M1) adds noise to the input (X) and uses a mask model (w) to process the noisy input into a mask (w(m1)). The second step (M2) takes the masked input (w(m1)X) and adds more noise to produce m2.  Finally, a base classifier (g) processes a weighted average of m1 and m2 to generate the final prediction. The standard randomized smoothing (RS) method is a simplified version where there's only the second step (M2), without the masking step (M1).", "section": "Two-Step ARS for L\u221e Certification of Image Classification"}, {"figure_path": "MN4nt01TeO/figures/figures_20_2.jpg", "caption": "Figure 1: Two-step ARS for L\u221e-bounded attacks. Step M\u2081 adds noise to input X and post-processes the result into a mask w(m1). Step M2 takes masked input w(m1)X and adds noise to get m2. Base classifier g post-processes a weighted average of m1, m2 to output a label. RS reduces to \u03c32 = \u03c3 and w(.) = 1 (no M1).", "description": "This figure illustrates the two-step Adaptive Randomized Smoothing (ARS) process for handling L\u221e-bounded adversarial attacks.  The first step (M1) adds noise to the input (X) and uses a mask model (w) to process the noisy input into a mask (w(m1)). The second step (M2) takes the masked input (w(m1)X) and adds further noise, resulting in m2. Finally, a base classifier (g) processes a weighted average of m1 and m2 to produce the final prediction.  The figure also highlights that standard Randomized Smoothing (RS) is a simplified version of ARS with no M1 step (i.e., w(.) = 1 and only one noise addition).", "section": "Two-Step ARS for L\u221e Certification of Image Classification"}, {"figure_path": "MN4nt01TeO/figures/figures_21_1.jpg", "caption": "Figure 3: (left) Original CIFAR-10 images superimposed on backgrounds for different k (except k = 32 which is no background), and (right) their corresponding masks (grayscale) inferred by our mask model w. All masks are for \u03c3 = 0.5. Appendix D.2 shows all the corresponding images across our multi-step architecture.", "description": "This figure shows example inputs to the model for different values of k (image dimension).  The left side shows the original CIFAR-10 image superimposed on a larger background image, making the classification task more challenging. The right side shows the corresponding masks generated by the mask model (M1) in the ARS architecture. These masks highlight the relevant image regions that the model should focus on during classification, effectively reducing the dimensionality of the input to M2 and improving robustness.  Appendix D.2 provides more detailed visualization of the different steps in the multi-step ARS architecture.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_21_2.jpg", "caption": "Figure 1: Two-step ARS for L\u221e-bounded attacks. Step M\u2081 adds noise to input X and post-processes the result into a mask w(m1). Step M2 takes masked input w(m1)X and adds noise to get m2. Base classifier g post-processes a weighted average of m1, m2 to output a label. RS reduces to \u03c32 = \u03c3 and w(.) = 1 (no M1).", "description": "This figure illustrates the two-step Adaptive Randomized Smoothing (ARS) process for handling L\u221e-bounded adversarial attacks.  The first step (M1) adds noise to the input (X) and uses a mask model to generate a mask (w(m1)) based on the noisy input. This mask focuses the processing on relevant information. The second step (M2) adds noise to the masked input (w(m1)X) and produces m2. Finally, a base classifier (g) combines m1 and m2 to produce the final prediction.  The standard Randomized Smoothing (RS) method is a simplified version of ARS, omitting the first masking step.", "section": "Two-Step ARS for L\u221e Certification of Image Classification"}, {"figure_path": "MN4nt01TeO/figures/figures_22_1.jpg", "caption": "Figure 16: The localized ARS masks produce un-noised mouth regions after averaging.", "description": "This figure shows how the adaptive masking in ARS reduces noise in regions relevant to classification.  The top row shows example input images. The second row shows the images after the first noise injection step (M1). The third row displays the sparse masks (learned by the mask model) which focus on the mouth region. The bottom row shows the images after the second noise injection and averaging step (M2).  The masks effectively reduce noise around the mouth area, improving classification accuracy.", "section": "4.2 CelebA Benchmark: Classification Without Spatial Alignment"}, {"figure_path": "MN4nt01TeO/figures/figures_22_2.jpg", "caption": "Figure 2: Certified Test Accuracy on CIFAR-10 (20kBG). (a)-(c) show the effect of dimensionality for (a) no background / k = 32, (b) k = 48, and (c) k = 96 for constant \u03c3 = 0.5. (d)-(f) show the effect of noise for (d) \u03c3 = 0.25, (e) \u03c3 = 0.5 and (f) \u03c3 = 1.0 with dimensionality fixed to k = 64. Each line is the mean and the shaded interval covers +/- one standard deviation across seeds.", "description": "This figure shows the certified test accuracy results for CIFAR-10 with 20k background images dataset. The x-axis represents the L\u221e radius, and the y-axis represents the certified accuracy. The figure consists of six subfigures, each showing the results for a different combination of dimensionality (k) and noise level (\u03c3). In each subfigure, different methods are compared: ARS, Cohen et al., static mask, S\u00faken\u00edk et al., and UniCR. The shaded area around each line represents the standard deviation of the results across multiple seeds.", "section": "4.1 CIFAR-10 Benchmark: Classification with Distractor Backgrounds"}, {"figure_path": "MN4nt01TeO/figures/figures_23_1.jpg", "caption": "Figure 18: The localized ARS masks produce un-noised object regions after averaging. For \u03c3 = 1.", "description": "This figure shows how the adaptive masking in ARS reduces noise in areas important for classification. The images follow the architecture in Figure 1. The first query noised images are fed to the mask model, which produces sparse masks concentrated around the object. After the weighted averaging of m1 and m2, the second query noised images show reduced noise around the object.", "section": "Additional Results on ImageNet"}, {"figure_path": "MN4nt01TeO/figures/figures_23_2.jpg", "caption": "Figure 18: The localized ARS masks produce un-noised object regions after averaging. For \u03c3 = 1.", "description": "This figure shows the effect of adaptive masking in reducing noise around important areas for classification in ImageNet. The figure presents a sequence of images illustrating different stages in the two-step ARS architecture. The first row shows the original input images. The second row shows the noisy images after the first step (M1) which adds noise. The third row presents the masks generated by the mask model (w), highlighting the important regions. The fourth row displays the noisy images after the second step (M2), where the noise has been reduced in the regions identified by the masks. These images are then combined to obtain the final classification result, showcasing the effectiveness of adaptive masking in improving robustness to adversarial attacks.", "section": "F Additional Results on ImageNet"}, {"figure_path": "MN4nt01TeO/figures/figures_23_3.jpg", "caption": "Figure 1: Two-step ARS for L\u221e-bounded attacks. Step M\u2081 adds noise to input X and post-processes the result into a mask w(m1). Step M2 takes masked input w(m1)X and adds noise to get m2. Base classifier g post-processes a weighted average of m1, m2 to output a label. RS reduces to \u03c32 = \u03c3 and w(.) = 1 (no M1).", "description": "This figure illustrates the two-step Adaptive Randomized Smoothing (ARS) process for handling L\u221e-bounded adversarial attacks.  The first step (M1) adds noise to the input (X) and uses a mask model (w) to process the noisy input to generate a mask (w(m1)). The second step (M2) uses the mask from step 1 to process the input again by applying a weighted average of the noisy input from M1 and M2 before generating the output label using the base classifier (g). The standard randomized smoothing (RS) is a simplified version of ARS with no M1 step (i.e., the mask is always 1 and there is only one noise addition).", "section": "3 Two-Step ARS for L\u221e Certification of Image Classification"}]