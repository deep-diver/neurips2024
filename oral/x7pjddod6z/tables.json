[{"figure_path": "x7pjdDod6Z/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative Results of Single Image to 3D. Evaluated on the 1,030 and 1,038 3D shapes from the GSO [11] and the OmniObject3D [83] datasets, respectively. One-2-3-45++ [31], InstantMesh [85], MeshLRM [79], and our method all take the same multi-view RGB images predicted by Zero123++ [59] as input. CD denotes Chamfer Distance.", "description": "This table presents a quantitative comparison of different single image to 3D methods on two benchmark datasets: GSO and OmniObject3D.  The metrics used include F-Score, Chamfer Distance (CD), PSNR, and LPIPS.  All methods use multi-view RGB images predicted from a single input image using Zero123++ as input, allowing for a fair comparison.", "section": "4.1 Implementation Details and Evaluation Settings"}, {"figure_path": "x7pjdDod6Z/tables/tables_8_1.jpg", "caption": "Table 2: We compare methods using limited training resources. Evaluated on the GSO [11] dataset.", "description": "This table compares the performance of MeshLRM and the proposed MeshFormer model using limited training resources (8x H100 GPUs for 48 hours).  The comparison is based on the GSO dataset and uses F-Score, Chamfer Distance (CD), and PSNR/LPIPS scores for color and normal images to evaluate reconstruction quality. The results show that MeshFormer outperforms MeshLRM even with significantly fewer training resources.", "section": "4.4 Analysis and Ablation Study"}, {"figure_path": "x7pjdDod6Z/tables/tables_9_1.jpg", "caption": "Table 3: Ablation Study on the GSO [11] dataset. -C denotes color renderings, and -N denotes normal renderings. CD stands for Chamfer distance. By default, ground truth multi-view images are used to exclude the influence of errors from 2D diffusion models.", "description": "This ablation study analyzes the impact of different components of MeshFormer on the GSO dataset.  It shows the performance (PSNR-C, LPIPS-C, PSNR-N, LPIPS-N, F-Score, CD) when removing or altering different parts of the model such as normal inputs, SDF supervision, transformer layers, projection-aware cross-attention, geometry enhancement, or using predicted normals instead of ground truth normals. The 'full' row represents the complete MeshFormer model.", "section": "4 Experiments"}, {"figure_path": "x7pjdDod6Z/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative Results of Single Image to 3D. Evaluated on the 1,030 and 1,038 3D shapes from the GSO [11] and the OmniObject3D [83] datasets, respectively. One-2-3-45++ [31], InstantMesh [85], MeshLRM [79], and our method all take the same multi-view RGB images predicted by Zero123++ [59] as input. CD denotes Chamfer Distance.", "description": "This table presents a quantitative comparison of MeshFormer against several state-of-the-art single-view to 3D methods on two benchmark datasets, GSO and OmniObject3D.  The evaluation metrics include F-score, Chamfer distance (CD), PSNR, and LPIPS, assessing both the geometry and texture quality of the generated 3D models.  All methods used multi-view RGB images predicted by Zero123++ as input, ensuring a fair comparison.", "section": "4.2 Comparison with Single/Sparse-View to 3D Methods"}, {"figure_path": "x7pjdDod6Z/tables/tables_18_1.jpg", "caption": "Table 1: Quantitative Results of Single Image to 3D. Evaluated on the 1,030 and 1,038 3D shapes from the GSO [11] and the OmniObject3D [83] datasets, respectively. One-2-3-45++ [31], InstantMesh [85], MeshLRM [79], and our method all take the same multi-view RGB images predicted by Zero123++ [59] as input. CD denotes Chamfer Distance.", "description": "This table presents a quantitative comparison of MeshFormer against several state-of-the-art single/sparse-view to 3D methods on two benchmark datasets: GSO and OmniObject3D.  The comparison uses the F-score, Chamfer Distance (CD), PSNR, and LPIPS metrics to evaluate the quality of the generated 3D shapes. All methods use multi-view RGB images predicted by Zero123++ as input.", "section": "4.1 Implementation Details and Evaluation Settings"}]