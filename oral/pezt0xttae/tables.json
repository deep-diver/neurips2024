[{"figure_path": "Pezt0xttae/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of model accuracy (%) on Digits.", "description": "This table presents a comparison of model accuracy achieved by different federated learning (FL) frameworks on the Digits benchmark dataset.  The frameworks are evaluated on four subsets of the dataset (MNIST, USPS, SVHN, SYN) and the overall global accuracy is also reported.  The 'System Heter.' column indicates whether the framework specifically addresses system heterogeneity.  The results demonstrate that DapperFL outperforms other state-of-the-art methods, particularly when considering system heterogeneity.", "section": "4.2 Performance Comparison"}, {"figure_path": "Pezt0xttae/tables/tables_7_2.jpg", "caption": "Table 2: Comparison of model accuracy (%) on Office Caltech.", "description": "This table presents a comparison of model accuracy achieved by different federated learning (FL) frameworks on the Office Caltech benchmark dataset.  The frameworks are evaluated across four domains within Office Caltech (Caltech, Amazon, Webcam, DSLR), and their overall global accuracy is reported. The 'System Heter.' column indicates whether each framework supports heterogeneous systems, highlighting the performance differences in handling diverse client capabilities.", "section": "4.2 Performance Comparison"}, {"figure_path": "Pezt0xttae/tables/tables_8_1.jpg", "caption": "Table 3: Effect of DapperFL's Key Modules on Digits and Office Caltech", "description": "This table presents the ablation study results, showing the impact of the key modules (MFP and DAR) of DapperFL on model accuracy.  It compares the performance of DapperFL with and without the MFP and DAR modules on two benchmark datasets (Digits and Office Caltech), demonstrating their individual and combined contributions to model accuracy.", "section": "4.3 Ablation Study"}, {"figure_path": "Pezt0xttae/tables/tables_14_1.jpg", "caption": "Table 4: Default hyper-parameters used in our evaluations.", "description": "This table lists the default hyperparameter values used in the experiments for all the compared federated learning frameworks, including DapperFL.  It shows the settings for global and local training parameters, along with framework-specific parameters. These values were kept consistent across all frameworks for fair comparison.", "section": "4.1 Experimental Setup"}, {"figure_path": "Pezt0xttae/tables/tables_16_1.jpg", "caption": "Table 5: Model footprint and accuracy of DapperFL under varying pruning ratios on Digits.", "description": "This table presents the model footprint (number of parameters and FLOPs) and accuracy of the DapperFL model on the Digits benchmark dataset for different pruning ratios (p).  The pruning ratio controls the level of model compression; higher ratios lead to smaller models but may affect accuracy. The table shows the performance across different sub-datasets within Digits (MNIST, USPS, SVHN, SYN) and the overall global accuracy.", "section": "4.3 Ablation Study"}, {"figure_path": "Pezt0xttae/tables/tables_16_2.jpg", "caption": "Table 6: Model footprint and accuracy of DapperFL under varying pruning ratios on Office Caltech.", "description": "This table shows the impact of different pruning ratios on the model size (number of parameters and FLOPs) and accuracy of the DapperFL model when evaluated on the Office Caltech dataset.  It demonstrates how the model's performance changes as different levels of compression are applied.  Note that accuracy decreases as pruning ratio increases, but also the model footprint significantly reduces. ", "section": "4.2 Performance Comparison"}]