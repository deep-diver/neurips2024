{"references": [{"fullname_first_author": "Alekh Agarwal", "paper_title": "Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal", "publication_date": "2020-04-01", "reason": "This paper provides a foundational result on the minimax optimality of model-based reinforcement learning with a generative model, which is a key benchmark for the average-reward MDP setting."}, {"fullname_first_author": "Mohammad Gheshlaghi Azar", "paper_title": "Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model", "publication_date": "2013-06-01", "reason": "This paper establishes foundational minimax sample complexity bounds for reinforcement learning with a generative model for discounted reward MDPs, which are used in the reduction-based approach for average reward MDPs."}, {"fullname_first_author": "Ying Jin", "paper_title": "Feasible Q-Learning for Average Reward Reinforcement Learning", "publication_date": "2024-04-01", "reason": "This paper concurrently develops a minimax optimal algorithm for weakly communicating average-reward MDPs, offering an alternative approach to the reduction-based method discussed in the target paper."}, {"fullname_first_author": "Gen Li", "paper_title": "Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model", "publication_date": "2020-01-01", "reason": "This paper provides an algorithm for discounted MDPs that circumvents the well-known minimax lower bound and achieves a sample complexity that is crucial to the reduction-based approach in the target paper."}, {"fullname_first_author": "Jinghan Wang", "paper_title": "Near Sample-Optimal Reduction-based Policy Learning for Average Reward MDP", "publication_date": "2022-12-01", "reason": "This paper improves upon previous work on the sample complexity of weakly communicating average-reward MDPs by using a refined reduction-based approach, which is also used in the target paper."}]}