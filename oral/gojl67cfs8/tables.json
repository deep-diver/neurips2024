[{"figure_path": "gojL67CfS8/tables/tables_6_1.jpg", "caption": "Table 1: Generative model family comparison on class-conditional ImageNet 256x256. \u201c\u2193\" or \"\u2191\" indicate lower or higher values are better. Metrics include Fr\u00e9chet inception distance (FID), inception score (IS), precision (Pre) and recall (rec). \"#Step\": the number of model runs needed to generate an image. Wall-clock inference time relative to VAR is reported. Models with the suffix \"-re\" used rejection sampling. \u2020: taken from MaskGIT [17].", "description": "This table compares various image generation models on the ImageNet 256x256 benchmark.  It presents key metrics including FID (Fr\u00e9chet Inception Distance), IS (Inception Score), precision, and recall, along with the number of parameters, steps required for generation, and relative inference time compared to the VAR model.  The table helps illustrate the performance and efficiency advantages of the VAR model compared to other state-of-the-art methods.", "section": "5.1 State-of-the-art image generation"}, {"figure_path": "gojL67CfS8/tables/tables_6_2.jpg", "caption": "Table 2: ImageNet 512x512 conditional generation. \u2020: quoted from MaskGIT [17]. \"-s\": a single shared AdaLN layer is used due to resource limitation.", "description": "This table compares the performance of various image generation models on the ImageNet 512x512 dataset.  The metrics used are Fr\u00e9chet Inception Distance (FID), Inception Score (IS), and inference time.  The table highlights the superior performance of the VAR model compared to other methods, including GANs, diffusion models, masked prediction models, and traditional autoregressive (AR) models. The \"-s\" notation indicates a resource-constrained setting for a particular model variant.", "section": "5.1 State-of-the-art image generation"}, {"figure_path": "gojL67CfS8/tables/tables_9_1.jpg", "caption": "Table 3: Ablation study of VAR. The first two rows compare GPT-2-style transformers trained under AR or VAR algorithm without any bells and whistles. Subsequent lines show the influence of VAR enhancements. \"AdaLN\": adaptive layernorm. \"CFG\": classifier-free guidance. \"Attn. Norm.\": normalizing q and k to unit vectors before attention. \"Cost\": inference cost relative to the baseline. \"\u25b3\": FID reduction to the baseline.", "description": "This table presents an ablation study of the VAR model, comparing its performance against a baseline AR model and exploring the effects of various components (AdaLN, Top-k sampling, CFG, Attention Normalization) and scaling up the model size. It quantitatively shows the improvement in FID (Fr\u00e9chet Inception Distance) achieved by each addition or modification and the associated increase in computational cost.", "section": "6 Ablation Study"}]