[{"figure_path": "bg6fVPVs3s/figures/figures_3_1.jpg", "caption": "Figure 1: A fractal-like 2D distribution with two classes indicated with gray and orange regions. Approximately 99% of the probability mass is inside the shown contours. (a) Ground truth samples drawn directly from the orange class distribution. (b) Conditional sampling using a small denoising diffusion model generates outliers. (c) Classifier-free guidance (w = 4) eliminates outliers but reduces diversity by over-emphasizing the class. (d) Naive truncation via lengthening the score vectors. (e) Our method concentrates samples on high-probability regions without reducing diversity.", "description": "This figure demonstrates the effect of different sampling methods on a 2D fractal-like data distribution.  It compares the ground truth distribution to results from unguided sampling, classifier-free guidance (CFG), naive truncation, and the authors' proposed autoguidance method.  The figure highlights how autoguidance effectively concentrates samples in high-probability regions without sacrificing diversity, unlike CFG which overemphasizes the class and reduces variation, or naive truncation which leads to reduced diversity.", "section": "3 Why does CFG improve image quality?"}, {"figure_path": "bg6fVPVs3s/figures/figures_3_2.jpg", "caption": "Figure 2: Closeup of the region highlighted in Figure 1c. (a) The implied learned density p1 (x|c; \u03c3mid) (green) at an intermediate noise level \u03c3mid and its score vectors (log-gradients), plotted at representative sample points. The learned density approximates the underlying ground truth p(x|c; \u03c3mid) (orange) but fails to replicate its sharper details. (b) The weaker unconditional model learns a further spread-out density po(x; \u03c3mid) (red) with a looser fit to the data. (c) Guidance moves the points according to the gradient of the (log) ratio of the two learned densities (blue). As the higher-quality model is more sharply concentrated at the data, this field tends inward towards the data distribution. The corresponding gradient is simply the difference of respective gradients in (a) and (b), illustrated at selected points. (d) Sampling trajectories taken by standard unguided diffusion following the learned score \u2207x log p1(x|c; \u03c3), from noise level \u03c3mid to 0. The contours (orange) represent the ground truth noise-free density. (e) Guidance introduces an additional force shown in (c), causing the points to concentrate at the core of the data density during sampling.", "description": "This figure shows a detailed analysis of a 2D toy example to explain how classifier-free guidance (CFG) improves image quality. It compares the learned density of a conditional model (p1) and an unconditional model (po), highlighting the differences in their sharpness and fit to the data.  It also illustrates how CFG, through the gradient of the ratio p1/po, pulls samples toward higher-probability regions, improving image quality but potentially reducing diversity. The unguided sampling trajectories and CFG-guided trajectories are visually compared, demonstrating the effect on sample distribution.", "section": "Why does CFG improve image quality?"}, {"figure_path": "bg6fVPVs3s/figures/figures_6_1.jpg", "caption": "Figure 3: Sensitivity w.r.t. autoguidance parameters, using EDM2-S on ImageNet-512. The shaded regions indicate the min/max FID over 3 evaluations. (a) Sweep over guidance weight w while keeping all other parameters unchanged. The curves correspond to how much the guiding model was trained relative to the number of images shown to the main model. (b) Sweep over guidance weight for different guiding model capacities. (c) Sweep over the two EMA length parameters for our best configuration, denoted with * in (a) and (b).", "description": "This figure analyzes the sensitivity of the autoguidance method's performance to different hyperparameters using the EDM2-S model on the ImageNet-512 dataset.  It shows three subplots: (a) FID scores varying with guidance weight and the relative training time of the guiding model; (b) FID scores varying with guidance weight and the capacity of the guiding model; (c) FID scores varying with the EMA length parameters (for both main and guiding models). The shaded areas represent the range of FID values across three trials, illustrating the method's robustness.", "section": "Results"}, {"figure_path": "bg6fVPVs3s/figures/figures_7_1.jpg", "caption": "Figure 4: Example results for the Tree frog, Palace, Mushroom, Castle classes of ImageNet-512 using EDM2-S. Guidance weight increases to the right; rows are classifier-free guidance and our method.", "description": "This figure displays example image generation results for four classes from the ImageNet-512 dataset using the EDM2-S model.  It compares the results of using classifier-free guidance (CFG) and the authors' proposed autoguidance method.  Each row represents a different method, with the columns showing how the generated images vary as the guidance weight increases (from w=1 to w=3).  The figure visually demonstrates that autoguidance generates more diverse and stylistically varied images compared to CFG, which tends toward more canonical representations.", "section": "5.2 Qualitative results"}, {"figure_path": "bg6fVPVs3s/figures/figures_8_1.jpg", "caption": "Figure 5: Results for DeepFloyd IF [46] using the prompt \u201cA blue jay standing on a large basket of rainbow macarons\u201d. The rows correspond to guidance weights w \u2208 {1, 2, 3, 4}. The leftmost column shows results for CFG and the rightmost for autoguidance (XL-sized model guided by M-sized one). The middle columns correspond to blending between the two. See Appendix A for more examples.", "description": "This figure shows the results of using different guidance weights (w) on DeepFloyd IF image generation model for a specific prompt.  It compares the results of using Classifier-free Guidance (CFG), Autoguidance (a new method proposed in the paper), and interpolations between the two methods. The figure demonstrates how different methods and varying guidance weights influence the generated image\u2019s style and composition.  It highlights that autoguidance preserves image style better than CFG, while both methods improve image quality with higher guidance weights.", "section": "5.2 Qualitative results"}, {"figure_path": "bg6fVPVs3s/figures/figures_12_1.jpg", "caption": "Figure 6: Additional results for DeepFloyd IF [46]. The rows correspond to guidance weights \u03c9 \u2208 {1, 2, 3, 4}. CFG and our method (XL-sized model guided by M-sized one) on the leftmost and rightmost column, respectively. The middle columns correspond to blending between the two.", "description": "This figure shows additional qualitative results obtained using DeepFloyd IF, a large-scale image generation model.  It demonstrates the effects of classifier-free guidance (CFG) and the authors' proposed method, 'autoguidance', on image generation, showing interpolations between the two techniques.  The rows represent increasing guidance weights (1 to 4), while the columns show the results from pure CFG on the left, pure autoguidance on the right, and interpolations in the middle.", "section": "5.2 Qualitative results"}, {"figure_path": "bg6fVPVs3s/figures/figures_12_2.jpg", "caption": "Figure 4: Example results for the Tree frog, Palace, Mushroom, Castle classes of ImageNet-512 using EDM2-S. Guidance weight increases to the right; rows are classifier-free guidance and our method.", "description": "This figure shows example image generation results using two different methods: classifier-free guidance (CFG) and the authors' proposed autoguidance method.  Four different ImageNet-512 classes (Tree frog, Palace, Mushroom, Castle) are used as image generation prompts. The horizontal axis shows increasing values of the guidance weight (w), and each row demonstrates the results using CFG (top row) versus autoguidance (bottom row). The figure demonstrates that, while both methods improve image quality with increasing guidance weight, autoguidance maintains greater diversity in image generation than CFG.", "section": "5.2 Qualitative results"}, {"figure_path": "bg6fVPVs3s/figures/figures_13_1.jpg", "caption": "Figure 7: Sweep over guidance weight w using EDM2-S on ImageNet-512. The optimal EMA length was searched separately for the three methods and two metrics (FID and FDDINOv2).", "description": "This figure shows the sensitivity analysis of the FID and FDDINOV2 scores with respect to the guidance weight (w) for three different guidance methods: Classifier-free guidance, Guidance interval, and Autoguidance (the proposed method). The EDM2-S model was used on the ImageNet-512 dataset.  For each method, the optimal EMA length was determined independently for FID and FDDINOV2 to ensure fair comparison. The plot reveals the performance of each method across a range of guidance weights, illustrating their relative strengths and weaknesses in balancing image quality and diversity.", "section": "5 Results"}, {"figure_path": "bg6fVPVs3s/figures/figures_13_2.jpg", "caption": "Figure 8: Resulting variation for CFG and our method in Tree frog, Minibus, Mushroom classes of ImageNet-512 using EDM2-S (FDDINOV2-optimized). In this image, we have exaggerated the amount of guidance (w = 4) to make its effect on variation more clearly visible. This causes excessive saturation and other image artifacts, but clearly shows that CFG steers towards canonical templates, while our method preserves much greater variation.", "description": "This figure compares the image variations generated by Classifier-Free Guidance (CFG) and the proposed Autoguidance method.  By increasing the guidance weight (w=4), the differences are highlighted. CFG produces images that are more similar to each other, sticking to what seems to be canonical representations of each class. Conversely, Autoguidance maintains a higher degree of variation, despite the high guidance weight, avoiding overly simplified or stereotypical results. The excessive saturation observed with the high w value is an artifact of this exaggerated testing.", "section": "5.2 Qualitative results"}, {"figure_path": "bg6fVPVs3s/figures/figures_14_1.jpg", "caption": "Figure 9: Progression of implied learned densities during sampling over various \u03c3 in a setup similar to Figure 2. Contours of the corresponding ground truth distributions are also shown. (a) Main model density p1 (x|c; \u03c3). (b) Unconditional guiding model density po(x; \u03c3) in CFG. (c) Conditional guiding model density po(x|c; \u03c3) in autoguidance. (d) With CFG, guidance towards higher ratio p1/po pushes samples towards top right, especially at high \u03c3 (top rows). (e) With autoguidance, this anomalous effect does not occur and samples cover the entire class c.", "description": "Figure 9 compares the evolution of the implied densities during sampling, using the standard CFG and the proposed autoguidance method. The figure shows how the model densities (main and guiding models) and the ratio of conditional to unconditional model densities change over the course of the sampling process. The results indicate that with CFG, samples are pulled towards the high-density regions which cause the reduction in diversity.  In contrast, autoguidance successfully avoids this effect and samples cover the entire class.", "section": "5 Results"}]