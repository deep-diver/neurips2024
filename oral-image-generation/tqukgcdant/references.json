{"references": [{"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces the foundational latent diffusion model, a highly influential architecture that forms the basis of many subsequent advancements in image synthesis."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Imagen video: High definition video generation with diffusion models", "publication_date": "2022-10-00", "reason": "This paper extends diffusion models to video generation, demonstrating the impressive capabilities and scalability of these models for high-quality visual content creation."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with CLIP latents", "publication_date": "2022-04-00", "reason": "This paper pioneers the use of CLIP for text-to-image generation, significantly advancing the field by enabling higher-quality and more semantically meaningful image generation from textual descriptions."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-00-00", "reason": "This paper significantly improves the quality and realism of text-to-image generation using diffusion models, setting a new state-of-the-art and influencing subsequent research."}, {"fullname_first_author": "Yang Song", "paper_title": "Consistency models", "publication_date": "2023-00-00", "reason": "This paper introduces consistency models, a novel approach for training diffusion models that significantly improves their efficiency and sample quality, providing a major advancement in the field."}]}