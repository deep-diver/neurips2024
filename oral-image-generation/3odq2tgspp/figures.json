[{"figure_path": "3Odq2tGSpp/figures/figures_0_1.jpg", "caption": "Figure 1: Adapter Selection. Given a user-provided prompt, our method identifies highly relevant adapters (e.g. Low-Rank Adaptation, LoRA) that are closely aligned with the prompt's context and at least one of the prompt's keywords. Composing relevant adapters into Stable Diffusion improves visual fidelity, image diversity, and textual alignment. Note that these prompts are sampled from MS-COCO [22].", "description": "This figure demonstrates the adapter selection process of the Stylus model.  Given various example prompts (sampled from MS-COCO), Stylus identifies the most relevant adapters (like LoRA) based on keyword and context. Combining these chosen adapters enhances the results of the Stable Diffusion model, leading to higher-fidelity images, increased diversity in generated images, and better alignment between the image and the textual prompt.", "section": "Abstract"}, {"figure_path": "3Odq2tGSpp/figures/figures_1_1.jpg", "caption": "Figure 2: Stylus algorithm. Stylus consists of three stages. The refiner plugs an adapter's model card through a VLM to generate textual descriptions of an adapter's task and then through an encoder to produce the corresponding text embedding. The retriever fetches candidate adapters that are relevant to the entire user prompt. Finally, the composer prunes and jointly categorizes the remaining adapters based on the prompt's tasks, which correspond to a set of keywords.", "description": "This figure illustrates the three-stage Stylus algorithm.  First, the *refiner* processes an adapter's metadata (model card, generated images and prompts) using a Vision-Language Model (VLM) and a text encoder to create concise, descriptive embeddings for each adapter. Second, the *retriever* uses these embeddings to find adapters relevant to the user's prompt based on cosine similarity. Finally, the *composer* segments the prompt into keywords representing different tasks, prunes irrelevant adapters, and assigns the remaining adapters to the appropriate tasks, outputting a composition of adapters optimized for the prompt.", "section": "3 Our Method: Stylus"}, {"figure_path": "3Odq2tGSpp/figures/figures_2_1.jpg", "caption": "Figure 3: Number of Adapters. Civit AI boasts 100K+ adapters for Stable Diffusion, outpacing that of Hugging Face. Low-Rank Adaptation (LoRA) is the dominant approach for finetuning.", "description": "This figure is a bar chart comparing the number of different types of adapters available for Stable Diffusion models on two platforms: Civit AI and Hugging Face.  It shows that Civit AI has significantly more adapters overall (over 100,000) than Hugging Face.  Within each platform's total, the chart breaks down the number of adapters into three categories: LoRA, Textual Inversion, and Hypernetworks.  The chart clearly illustrates that LoRA is the most prevalent type of adapter on both platforms.", "section": "Related Works"}, {"figure_path": "3Odq2tGSpp/figures/figures_3_1.jpg", "caption": "Figure 4: Qualitative comparison between Stylus over realistic (left) and cartoon (right) style Stable Diffusion checkpoints. Stylus produces highly detailed images that correctly depicts keywords in the context of the prompt. For the prompt \"A graffiti of a corgi on the wall\", our method correctly depicts a spray-painted corgi, whereas the checkpoint generates a realistic dog.", "description": "This figure shows a qualitative comparison of images generated by Stylus and Stable Diffusion for both realistic and cartoon styles.  It highlights Stylus's ability to produce images that more accurately reflect the keywords and context of a user prompt, while standard Stable Diffusion may produce less accurate or relevant results. The example prompt \"A graffiti of a corgi on the wall\" demonstrates how Stylus correctly generates a spray-painted corgi, whereas Stable Diffusion creates a more realistic depiction. This visually demonstrates Stylus's improved ability to capture the nuances of the user's intent.", "section": "4 Results"}, {"figure_path": "3Odq2tGSpp/figures/figures_4_1.jpg", "caption": "Figure 5: Human Evaluation. Stylus achieves a higher preference scores (2:1) over different datasets and Stable Diffusion checkpoints.", "description": "This figure presents the results of a human evaluation comparing Stylus's performance against the Stable Diffusion v1.5 model.  The evaluation involved two different datasets (COCO and PartiPrompts) and two distinct Stable Diffusion checkpoints (Realistic Vision-v6 and Counterfeit-v3), resulting in four experimental settings. In each setting, human evaluators were asked to express a preference between an image generated by Stylus and one produced by Stable Diffusion v1.5.  The bar chart displays the percentage of times Stylus was preferred in each of the four experimental setups.  The results show Stylus achieving a preference win rate consistently above 50% in all four scenarios, demonstrating a clear preference for the images generated by Stylus across various datasets and checkpoint models.", "section": "4.2 Human Evaluation"}, {"figure_path": "3Odq2tGSpp/figures/figures_5_1.jpg", "caption": "Figure 6: Automatic Evaluation Metrics. Figure (a) plots the CLIP/FID pareto curve. We observe Stylus shifts the curve down (improved visual fidelity, FID) and to the right (improved textual alignment, CLIP score) over a range of guidance values (CFG): [1, 1.5, 2, 3, 4, 6, 9, 12]. Table (b) evaluates Stylus against different retrieval methods. Stylus outperforms existing retrieval-based methods, attains the best FID score, and achieves similar CLIP score to Stable Diffusion.", "description": "This figure presents the results of an automatic evaluation of the Stylus model using two metrics: CLIP and FID.  The CLIP score measures the alignment between generated images' captions and user prompts, while FID evaluates the diversity and aesthetic quality of image sets. The figure consists of two parts: (a) shows a CLIP/FID Pareto curve, demonstrating that Stylus improves both visual fidelity (lower FID) and textual alignment (higher CLIP) across various guidance scales; (b) provides a tabular comparison of CLIP and FID scores for Stylus and other retrieval methods, highlighting Stylus's superior performance and comparable CLIP scores to Stable Diffusion.", "section": "4 Results"}, {"figure_path": "3Odq2tGSpp/figures/figures_5_2.jpg", "caption": "Figure 6: Automatic Evaluation Metrics. Figure (a) plots the CLIP/FID pareto curve. We observe Stylus shifts the curve down (improved visual fidelity, FID) and to the right (improved textual alignment, CLIP score) over a range of guidance values (CFG): [1, 1.5, 2, 3, 4, 6, 9, 12]. Table (b) evaluates Stylus against different retrieval methods. Stylus outperforms existing retrieval-based methods, attains the best FID score, and achieves similar CLIP score to Stable Diffusion.", "description": "This figure presents the results of an automatic evaluation of Stylus against other methods using two metrics: CLIP score and FID score.  The CLIP score measures the alignment between generated image captions and user prompts, while the FID score evaluates visual fidelity and diversity. The Pareto curve in (a) shows Stylus achieves better FID (visual quality) and CLIP (textual alignment) scores across a range of guidance scales (CFG).  Table (b) further compares Stylus to three alternative retrieval methods (Reranker, Retriever-only, Random) and Stable Diffusion v1.5, demonstrating Stylus' superiority in achieving lower FID scores (better visual quality) and comparable CLIP scores (textual alignment).", "section": "4 Results"}, {"figure_path": "3Odq2tGSpp/figures/figures_5_3.jpg", "caption": "Figure 7: Image Diversity. Given the same prompt, our method (left) generates more diverse and comprehensive sets of images than that of existing Stable Diffusion checkpoints (right). Stylus's diversity comes from its masking scheme and the composer LLM's temperature parameter.", "description": "The figure displays image generation results for the same prompt using Stylus and a standard Stable Diffusion model.  The left side shows Stylus's output, demonstrating a wider variety of images in terms of style, composition, and details. The right side shows the Stable Diffusion output, which exhibits less variation. The caption highlights that Stylus's diversity stems from its ability to select and combine multiple adapters tailored to different aspects of the prompt, along with a temperature parameter that controls the variability of the LLM's output during image generation.", "section": "4.2 Main Experiments"}, {"figure_path": "3Odq2tGSpp/figures/figures_6_1.jpg", "caption": "Figure 8: Figure (a) and (b) evaluate the preference win rate using GPT-4V as a judge. Stylus achieves higher preference scores as judged by GPT-4V for visual quality and image diversity. Figure (c) shows that Stylus achieves higher diversity scores than Stable Diffusion when prompt length increases.", "description": "This figure presents the results of human evaluation using GPT-4V, comparing Stylus and Stable Diffusion.  (a) shows the win rates for visual quality and textual alignment, indicating Stylus's superiority. (b) presents win rates for diversity assessment (using GPT-4V and dFID), again favoring Stylus. (c) demonstrates the effect of prompt length on diversity (dFID), showcasing Stylus's consistent advantage even with longer prompts.", "section": "4.2 Main Experiments"}, {"figure_path": "3Odq2tGSpp/figures/figures_6_2.jpg", "caption": "Figure 9: Different Retrieval Methods. Stylus outperforms all other retrieval methods, which choose adapters than either introduce foreign concepts to the image or override other concepts in the prompt, reducing textual alignment.", "description": "This figure shows a qualitative comparison of image generation results from different adapter retrieval methods: Stylus, Reranker, Retriever, and Random.  Each method was given the same set of prompts to generate images. The figure demonstrates that Stylus produces images that are more faithful to the prompt's description compared to other methods which either introduce irrelevant elements or fail to capture essential aspects of the prompt. This highlights Stylus's superior ability to select and compose relevant adapters for improved image quality and alignment with the user's intent.", "section": "4.3 Ablations"}, {"figure_path": "3Odq2tGSpp/figures/figures_8_1.jpg", "caption": "Figure 11: Comparison of Stylus's inference overheads with Stable Diffusion's inference time by batch size (BS). At BS=1, Stylus accounts for 75% of the image generation time, primarily due to the composer processing long context prompts from adapter descriptions. However, Stylus's overhead decreases when batch size increases.", "description": "This figure compares the inference time of Stylus and Stable Diffusion (SDv1.5) for different batch sizes (BS).  When the batch size is 1, Stylus takes significantly longer than SDv1.5 because the composer needs to process long prompts to make use of the adapter information. However, as the batch size increases, the overhead of Stylus relative to SDv1.5 decreases, demonstrating that Stylus's additional processing time is largely due to its text-based adapter selection which is performed once per batch.", "section": "4.3.3 Breakdown of Stylus's Inference Time"}, {"figure_path": "3Odq2tGSpp/figures/figures_9_1.jpg", "caption": "Figure 12: Stylus over different image-to-image tasks.", "description": "This figure shows the results of applying Stylus to two different image-to-image tasks: image translation and inpainting.  The image translation examples demonstrate Stylus's ability to transform images into different styles (fiery red, voxel style, pencil sketch) while preserving the original content. The inpainting examples illustrate Stylus's capacity to seamlessly fill in missing regions of images, such as replacing a face with a different person's face or adding elements like a bunny to an image.", "section": "4.3.4 Image-Domain Tasks"}, {"figure_path": "3Odq2tGSpp/figures/figures_9_2.jpg", "caption": "Figure 12: Stylus over different image-to-image tasks.", "description": "This figure shows two examples of image-to-image tasks performed using the Stylus model and compares the results to those obtained using the Stable Diffusion v1.5 model.  The left-hand side demonstrates image translation, where a source image (e.g., a motorcycle) is transformed into a variant image with a different style (e.g., a voxel style or pencil sketch) specified in the prompt. The right-hand side shows image inpainting, where Stylus fills in a missing portion of an image (e.g., a masked region of a rabbit) with new characters or concepts (e.g., a glass bunny, a burger, or a robot bunny). In both cases, Stylus produces images that more accurately reflect the prompt's specifications compared to the Stable Diffusion v1.5 model.", "section": "4.3.4 Image-Domain Tasks"}, {"figure_path": "3Odq2tGSpp/figures/figures_14_1.jpg", "caption": "Figure 13: Characterization of Civit Adapter in StylusDocs. (a) Most adapters are categorized as characters or celebrities. (b) Adapter popularity exhibits a power-law distribution, with the top adapters receiving exponentially more downloads than the others.", "description": "This figure presents a characterization of the adapters found within the StylusDocs dataset.  Panel (a) shows a bar chart illustrating the distribution of adapters across various categories, revealing a significant dominance of 'character' and 'celebrity' categories. Panel (b) displays a histogram showing the distribution of the top 500 adapters based on their download counts.  This demonstrates a power-law distribution, where a small number of adapters account for a disproportionately large share of the total downloads, with the most popular adapters having exponentially higher download counts than less popular ones.", "section": "A.3 StylusDocs Characterization"}, {"figure_path": "3Odq2tGSpp/figures/figures_14_2.jpg", "caption": "Figure 13: Characterization of Civit Adapter in StylusDocs. (a) Most adapters are categorized as characters or celebrities. (b) Adapter popularity exhibits a power-law distribution, with the top adapters receiving exponentially more downloads than the others.", "description": "This figure shows the distribution of adapters in StylusDocs dataset across different categories and their popularity based on download counts.  Subfigure (a) is a bar chart showing the proportion of adapters falling into various categories like character, celebrity, style, etc. It highlights that a significant portion of adapters are related to characters and celebrities. Subfigure (b) is a histogram illustrating the distribution of download counts for the top 500 adapters, demonstrating a power-law distribution where a small number of adapters account for a large portion of the downloads.", "section": "A.3 StylusDocs Characterization"}, {"figure_path": "3Odq2tGSpp/figures/figures_15_1.jpg", "caption": "Figure 4: Qualitative comparison between Stylus over realistic (left) and cartoon (right) style Stable Diffusion checkpoints. Stylus produces highly detailed images that correctly depicts keywords in the context of the prompt. For the prompt \"A graffiti of a corgi on the wall\", our method correctly depicts a spray-painted corgi, whereas the checkpoint generates a realistic dog.", "description": "This figure shows a qualitative comparison of images generated by Stylus and Stable Diffusion base models for both realistic and cartoon styles.  Three example prompts are used, demonstrating that Stylus generates images with higher fidelity and more accurately reflects the keywords given in the prompts compared to the base model.", "section": "3.4 Masking"}, {"figure_path": "3Odq2tGSpp/figures/figures_17_1.jpg", "caption": "Figure 14: Categorization of Different Failure Modes.", "description": "This figure shows examples of different failure modes that can occur when using adapters in image generation.  Specifically, it illustrates the problems of image saturation (over-exposure due to high adapter weights), task blocking (where one adapter's effect overrides another), task diversity (lack of variation in generated images for a single task), low-quality adapters (producing poor image quality), and retrieval errors (incorrect adapter selection). Each subfigure (a-e) provides a visual demonstration of one of these failure modes.", "section": "4.3 Ablations"}, {"figure_path": "3Odq2tGSpp/figures/figures_17_2.jpg", "caption": "Figure 4: Qualitative comparison between Stylus over realistic (left) and cartoon (right) style Stable Diffusion checkpoints. Stylus produces highly detailed images that correctly depicts keywords in the context of the prompt. For the prompt \"A graffiti of a corgi on the wall\", our method correctly depicts a spray-painted corgi, whereas the checkpoint generates a realistic dog.", "description": "This figure showcases a qualitative comparison of images generated by Stylus and Stable Diffusion (SD v1.5) using two different checkpoints: Realistic-Vision-v6 and Counterfeit-v3.  The images demonstrate that Stylus produces higher-quality, more detailed images that accurately reflect the keywords in the given prompt, while the Stable Diffusion model sometimes generates images that don't fully match the prompt's intent.  The example \"A graffiti of a corgi on the wall\" illustrates this difference; Stylus shows a spray-painted corgi consistent with graffiti art, while the Stable Diffusion model depicts a realistic dog.", "section": "4 Results"}, {"figure_path": "3Odq2tGSpp/figures/figures_17_3.jpg", "caption": "Figure 7: Image Diversity. Given the same prompt, our method (left) generates more diverse and comprehensive sets of images than that of existing Stable Diffusion checkpoints (right). Stylus's diversity comes from its masking scheme and the composer LLM's temperature parameter.", "description": "This figure demonstrates the improved diversity achieved by Stylus compared to the Stable Diffusion checkpoints.  The same prompt is used for both Stylus and the Stable Diffusion model. Stylus generates a wider variety of images with different compositions, styles, and details, showcasing its ability to produce more comprehensive and diverse outputs. This diversity stems from Stylus's unique masking scheme and the temperature parameter used in its composer LLM. The masking scheme randomly selects a subset of relevant adapters for each task, leading to different combinations of adapters for each image generation. The temperature parameter in the composer LLM controls the randomness of the adapter selection process, further enhancing the diversity of the generated images.", "section": "4.2 Main Experiments"}, {"figure_path": "3Odq2tGSpp/figures/figures_17_4.jpg", "caption": "Figure 4: Qualitative comparison between Stylus over realistic (left) and cartoon (right) style Stable Diffusion checkpoints. Stylus produces highly detailed images that correctly depicts keywords in the context of the prompt. For the prompt \"A graffiti of a corgi on the wall\", our method correctly depicts a spray-painted corgi, whereas the checkpoint generates a realistic dog.", "description": "This figure shows a qualitative comparison of image generation results between Stylus and the Stable Diffusion model v1.5, using both realistic and cartoon-style checkpoints.  The images illustrate Stylus's ability to generate higher-fidelity images that more accurately reflect the keywords in the prompt, compared to the Stable Diffusion v1.5 baseline. The example highlights Stylus's superior ability to incorporate stylistic elements and details specified in the prompt, resulting in more accurate and contextually appropriate outputs.", "section": "Results"}, {"figure_path": "3Odq2tGSpp/figures/figures_20_1.jpg", "caption": "Figure 15: dFID for top 100 keywords in PartiPrompts dataset. Stylus leads to consistently higher diversity when compared to Stable Diffusion checkpoints, especially for words describing concepts and attributes.", "description": "This figure presents a bar chart comparing the diversity (measured by dFID) of images generated by Stylus and Stable Diffusion for the top 100 keywords from the PartiPrompts dataset.  The chart is organized into four sub-charts, each showing a subset of the keywords.  For each keyword, two bars are displayed: one representing the dFID score for Stable Diffusion, and the other for Stylus. Error bars are included to show variability.  The results demonstrate that Stylus consistently achieves higher diversity scores than Stable Diffusion, particularly for keywords representing concepts and attributes rather than simple objects.", "section": "4.2.4 Diversity per Prompt"}]