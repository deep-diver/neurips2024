[{"figure_path": "jXxvSkb9HD/tables/tables_23_1.jpg", "caption": "Table 1: Pairwise comparisons of algorithm performance with the Nemenyi test based on accuracy. Underlined values indicate differences significant at \u03b1 = 0.05 level.", "description": "This table presents the results of pairwise comparisons of seven algorithms (LR, RF, CART, SVM, xGBoost, GLMNet, kNN) using the Nemenyi post-hoc test following a Friedman test.  The p-values indicate the statistical significance of differences in accuracy between algorithm pairs.  Underlined p-values are less than 0.05, indicating a statistically significant difference in accuracy at the 5% significance level. The table shows which algorithms perform significantly better or worse than others in terms of prediction accuracy, based on the OpenML benchmark dataset. Note that this is just the accuracy metric, out of the three used in the OpenML experiment.", "section": "5.1 Experiments on OpenML"}, {"figure_path": "jXxvSkb9HD/tables/tables_24_1.jpg", "caption": "Table 2: Pairwise comparisons of algorithm performance with the Nemenyi test based on computation time on the training data. Underlined values indicate differences significant at a = 0.05 level.", "description": "This table presents pairwise comparisons of seven algorithms' performance using the Nemenyi test, focusing on training computation time.  The p-values indicate the statistical significance of the differences. Underlined p-values (less than 0.05) show statistically significant differences in training time between the algorithm pairs.", "section": "5.1 Experiments on OpenML"}, {"figure_path": "jXxvSkb9HD/tables/tables_24_2.jpg", "caption": "Table 3: Pairwise comparisons of algorithm performance with the Nemenyi test based on computing time on testing data. Underlined values indicate differences significant at a = 0.05 level.", "description": "This table displays the results of pairwise comparisons of seven classifiers using the Nemenyi test for statistical significance.  The test assesses the difference in computation time on test data.  Underlined p-values (less than 0.05) indicate a statistically significant difference in computation time between the two classifiers being compared.", "section": "Experiments on OpenML"}, {"figure_path": "jXxvSkb9HD/tables/tables_24_3.jpg", "caption": "Table 4: Mean results of the classifier comparisons. (Recall that for train/test time: the lower, the better)", "description": "This table presents the mean values of accuracy, training time, and testing time for seven classifiers (LR, RF, CART, SVM, xGBoost, GLMNet, kNN) across multiple datasets.  Lower values for train and test times are better. The table summarizes the average performance of these classifiers based on the metrics used in the OpenML experiments described in the paper.", "section": "5.1 Experiments on OpenML"}, {"figure_path": "jXxvSkb9HD/tables/tables_25_1.jpg", "caption": "Table 5: Post Hoc Nemenyi Test (Accuracy) on PMLB.", "description": "This table presents the results of pairwise post-hoc Nemenyi tests for accuracy on the PMLB benchmark dataset.  The tests are performed after a significant Friedman test result indicates that there are significant differences between algorithms. Each cell shows the p-value from a pairwise comparison between two algorithms. A p-value less than 0.05 suggests that there is a statistically significant difference between the performances of the two algorithms, with the underlined p-values indicating significance at this level. For example, the p-value of 0.00106 indicates a significant difference between the 'ranger' and 'J48' classifiers.", "section": "Experiments on PMLB"}, {"figure_path": "jXxvSkb9HD/tables/tables_25_2.jpg", "caption": "Table 6: Post Hoc Nemenyi Test Summary (Accuracy with Noisy X) on PMLB.", "description": "This table shows pairwise comparisons of algorithm performance with the Nemenyi test based on accuracy with noisy features (X).  Underlined values indicate differences that are statistically significant at the 0.05 level. The table helps to understand the relative performance of different classifiers when considering robustness to noisy features.", "section": "5.2 Experiments on PMLB"}, {"figure_path": "jXxvSkb9HD/tables/tables_25_3.jpg", "caption": "Table 7: Post Hoc Nemenyi Test Summary (Accuracy with Noisy Y) on PMLB.", "description": "This table displays the results of pairwise comparisons of algorithm performance using the Nemenyi test, focusing on the 'Accuracy with Noisy Y' metric from the PMLB benchmark.  Underlined p-values (below 0.05) indicate statistically significant differences at the 0.05 level.  The table shows which classifiers are significantly different from each other in terms of their accuracy when considering noisy y-variables.", "section": "5.2 Experiments on PMLB"}, {"figure_path": "jXxvSkb9HD/tables/tables_26_1.jpg", "caption": "Table 4: Mean results of the classifier comparisons. (Recall that for train/test time: the lower, the better)", "description": "This table presents the mean accuracy, training time and test time for the seven classifiers (LR, RF, CART, SVM, xGBoost, GLMNet, and KNN) evaluated on the OpenML benchmark. Lower values for training and testing time indicate better performance.", "section": "5.1 Experiments on OpenML"}]