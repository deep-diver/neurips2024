{"importance": "This paper is crucial for researchers working on backdoor attacks and defenses.  It challenges the conventional understanding of backdoor safety, highlighting the limitations of current methods and proposing a novel defense mechanism.  **This work significantly advances the field by introducing a new perspective, which opens new avenues for more robust and reliable backdoor defenses.**  The findings directly impact the development of safer and more trustworthy AI systems.", "summary": "Current backdoor defenses, while effective at reducing attack success rates, are vulnerable to rapid re-learning. This work unveils this superficial safety, proposes a novel attack, and introduces a path-aware minimization defense for improved post-purification robustness.", "takeaways": ["Current backdoor purification methods offer only superficial safety; they are vulnerable to rapid backdoor re-learning.", "The proposed Query-based Reactivation Attack (QRA) can effectively reactivate backdoors in purified models using only model queries.", "Path-Aware Minimization (PAM) significantly enhances post-purification robustness by promoting model deviation along backdoor-connected paths."], "tldr": "Backdoor attacks on deep learning models are a significant security concern. Existing defenses often focus on reducing the Attack Success Rate (ASR), but this doesn't guarantee the complete removal of backdoor features.  The paper reveals that current purification methods fail to achieve satisfactory post-purification robustness, meaning backdoors can be easily reactivated even after purification. This superficial safety arises because the purified models don't deviate sufficiently from the original backdoored models along the backdoor-connected path.\nTo address this issue, the authors propose a novel Query-based Reactivation Attack (QRA) that can reactivate the backdoor by merely querying the purified model, and a straightforward defense method, Path-Aware Minimization (PAM), which promotes deviation along backdoor-connected paths.  Extensive experiments show that PAM significantly improves post-purification robustness while maintaining good clean accuracy and low ASR.  This work provides a new perspective on understanding the effectiveness of backdoor safety tuning.", "affiliation": "Hong Kong University of Science and Technology", "categories": {"main_category": "AI Theory", "sub_category": "Safety"}, "podcast_path": "qZFshkbWDo/podcast.wav"}