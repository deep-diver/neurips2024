[{"type": "text", "text": "Optimal Algorithms for Online Convex Optimization with Adversarial Constraints ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Abhishek Sinha, Rahul Vaze School of Technology and Computer Science Tata Institute of Fundamental Research Mumbai 400005, India abhishek.sinha@tifr.res.in, rahul.vaze@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "A well-studied generalization of the standard online convex optimization (OCO) framework is constrained online convex optimization (COCO). In COCO, on every round, a convex cost function and a convex constraint function are revealed to the learner after it chooses the action for that round. The objective is to design an online learning policy that simultaneously achieves a small regret while ensuring a small cumulative constraint violation (CCV) against an adaptive adversary interacting over a horizon of length $T$ . A long-standing o\u221apen question in CO\u221aCO is whether an online policy can simultaneously achieve $O(\\sqrt{T})$ regret and $\\tilde{O}(\\sqrt{T})$ CCV without any restrictive assumptions. For the first time, we answer this in the affirmative and show that a simple first-order policy can simultaneously achieve these bounds. Furthermore, in the case of strongly convex cost and convex constraint functions, the regret guarantee can be improved to ${\\cal O}(\\log{T})$ while keeping the CCV bound the same as above. We establish these results by effectively combining adaptive OCO policies as a blackbox with Lyapunov optimization - a classic tool from control theory. Surprisingly, the analysis is short and elegant. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online convex optimization (OCO) is a standard framework for modelling and analyzing a broad family of online decision problems under uncertainty. In the OCO problem, on every round $t$ , an online policy first selects an action $x_{t}$ from a closed and convex admissible set (a.k.a. decision set) $\\mathcal{X}$ . Then the adversary reveals a convex cost function $f_{t}$ , resulting in a cost of $f_{t}(x_{t})$ . The goal of an online policy is to choose an admissible action sequence $\\{x_{t}\\}_{t=1}^{T}$ so that its cumulative cost is not much larger than that of any fixed admissible action chosen in hindsight. In particular, the objective is to minimize the static regret defined below ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\mathsf{R e g r e t}_{T}\\equiv\\operatorname*{sup}_{\\{f_{t}\\}_{t=1}^{T}}\\operatorname*{sup}_{x^{\\star}\\in\\mathcal{X}}\\mathsf{R e g r e t}_{T}(x^{\\star}),\\mathrm{~where~Regret}_{T}(x^{\\star})\\equiv\\sum_{t=1}^{T}f_{t}(x_{t})-\\sum_{t=1}^{T}f_{t}(x^{\\star}).\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "The term static refers to using a fixed benchmark, specifically only one action $x^{\\star}$ throughout the horizon of length $T$ . ", "page_idx": 0}, {"type": "text", "text": "In this paper, we consider a generalization of the standard OCO framework. In this problem, on every round $t$ , the online policy first chooses an admissible action $x_{t}\\in\\mathcal{X}$ , and then the adversary chooses a convex cost function $f_{t}:\\mathcal{X}\\to\\mathbb{R}$ and $k$ constraints of the form $g_{t,i}(x)\\leq0,\\;i\\in[k]$ , where $g_{t,i}:\\mathcal{X}\\rightarrow\\mathbb{R}$ is a convex function for each $i\\in[k]^{1}$ . Since $g_{t,i}$ \u2019s are revealed after the action $x_{t}$ is chosen, an online policy need not necessarily take feasible actions on each round, and the obvious metric of interest in addition to (1) is the total cumulative constraint violation (CCV) $\\mathbb{V}(T)$ defined as ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbf{CCV}_{T}\\equiv\\mathbb{V}(T)=\\operatorname*{max}_{i=1}^{k}\\mathbb{V}_{i}(T)\\quad\\mathrm{where}\\quad\\mathbb{V}_{i}(T)=\\sum_{t=1}^{T}\\bigl(g_{t,i}(x_{t})\\bigr)^{+}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Let $\\varkappa^{\\star}$ be the feasible set consisting of all admissible actions that satisfy all constraints $g_{t,i}(x)\\leq$ 0, $i\\in[k],t\\in[T]$ . Under the standard assumption that $\\mathcal{X}^{\\star}$ is not empty, the goal is to design an online policy to simultaneously achieve a small regret (1) with respect to any admissible benchmark $x^{\\star}\\in\\mathcal{X}^{\\star}$ and a small CCV (2). We refer to this problem as the constrained OCO (COCO). The assumption $\\mathcal{X}^{\\star}\\neq\\mathcal{O}$ will be relaxed in Section 3 for the Online Constraint Satisfaction (OCS) problem where the cost functions are set to zero, and the objective is to minimize just the CCV. ", "page_idx": 1}, {"type": "text", "text": "COCO arises in many applications, including online portfolio optimization with risk constraints, resource allocation in cloud computing with time-varying demands, pay-per-click online ad markets with budget constraints [Liakopoulos et al., 2019], online recommendation systems, dynamic pricing, revenue management, robotics and path planning problems, and multi-armed bandits with fairness constraints [Sinha, 2024a]. The necessity for revealing the constraints sequentially may also arise, e.g., in communication-limited settings, where it might be infeasible to reveal all constraints defining the feasible set at a time (e.g., combinatorial auctions). See Section 4 for an application of the COCO framework in fraud detection which involves binary classification with a highly-imbalanced dataset. ", "page_idx": 1}, {"type": "text", "text": "1.1 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Unconstrained OCO: In a seminal paper, Zinkevich [2003] showed\u221a that for solving (1), the ubiquitous projected online gradient descent (OGD) policy achieves an $O({\\sqrt{T}})$ regret for convex cost functions with uniformly bounded sub-gradients. A number of follow-up papers proposed adaptive and parameter-free versions of OGD [Hazan et al., 2007, Orabona and P\u00e1l, 2018]. See Orabona [2019], Hazan [2022] for textbook treatments of the OCO framework and associated algorithms. ", "page_idx": 1}, {"type": "text", "text": "Constrained OCO (COCO): (A) Time-invariant constraints: A number of papers considered COCO with time-invariant constraints, i.e., $g_{t,i}=g_{i}$ , $\\forall~t~$ [Yuan and Lamperski, 2018, Jenatton et al., 2016, Mahdavi et al., 2012, Yi et al., 2021]. These works assume that the functions $g_{i}$ \u2019s are known to the policy a priori. However, they allowed the policy to remain infeasible on any round to avoid the costly projection step of the vanilla projected OGD policy. Their main objective was to design an efficient policy (avoiding the explicit projection step) with a small regret and CCV. ", "page_idx": 1}, {"type": "text", "text": "(B) Time-varying constraints: Solving the COCO problem when the constraint functions, i.e., $g_{t,i}$ \u2019s, change arbitrarily with time $t$ is more challenging. In this case, except for Neely and $\\mathrm{Yu}$ [2017] and Liakopoulos et al. [2019], most of the prior works construct some Lagrangian function and then update the primal and dual variables [Yu et al., 2017, Sun et al., 2017, Yi et al., 2023]. However, the performance bounds obtained with this approach remain suboptimal. Both Neely and $\\mathrm{Yu}$ [2017] and Liakopoulos et al. [2019] use the drift-plus-penalty (DPP) framework introduced by Neely [2010] to solve the constrained problem under various assumptions. In particular, Neely and Yu [2017] proposed a DPP-based policy for COCO upon assuming the Slater\u2019s condition, i.e., $g_{t,i}(x^{\\star})<-\\eta$ , for some $\\eta>0\\;\\forall i,t$ . Clearly, this condition precludes the important case of non-negative constraint functions (e.g., constraint functions of the form $\\operatorname*{max}(0,g_{t}(x)))$ . Furthermore, the bounds obtained upon assuming Slater\u2019s condition depend inversely with the Slater\u2019s constant $\\eta$ (usually hidden under the big-Oh notation). Since $\\eta$ could be arbitrarily small, these bounds could be arbitrarily loose. Liakopoulos et al. [2019] extended Neely and $\\mathrm{Yu}$ [2017]\u2019s result by considering a weaker form of the feasibility assumption without assuming Slater\u2019s condition. Furthermore, although these DPP-based results are interesting, they have not been able to provide improved regret or CVV bounds when the cost functions $f_{t}$ \u2019s are strongly convex because of the linearization step inherent in this approach. ", "page_idx": 1}, {"type": "text", "text": "In a recent paper, Guo et al. [2022] considered COCO and obtained the best-known prior results without assuming Slater\u2019s condition. However, in addition to yielding sub-optimal bounds, their policy is quite computationally intensive since it requires solving a convex optimization problem on each round. Compared to this, all policies proposed in this paper take only a single gradient-descent step and perform only one Euclidean projection on each round. Please refer to Table 1 for a brief summary of the results and Section A.5 in the Appendix for a qualitative comparison. The COCO problem has been considered in the dynamic setting as well [Chen and Giannakis, 2018, Cao and Liu, 2018, Vaze, 2022, Liu et al., 2022] where the benchmark $x^{\\star}$ in (1) is replaced by $\\boldsymbol{x}_{t}^{\\star}$ that is also allowed to change its actions over time. However, we focus our attention on achieving the optimal performance bounds for the static version. A special case of COCO is the ONLINE CONSTRAINT SATISFACTION (OCS) problem that does not involve any cost function, i.e., $f_{t}=0$ , $\\forall t$ , and the only object of interest is the CCV. The OCS problem becomes especially interesting in the setting where the feasible set may be empty. ", "page_idx": 1}, {"type": "table", "img_path": "TxffvJMnBy/tmp/981fe5dec8c775eb9584cf0901f6008a71d92c65d7f00468f1e113da9b3e9fd8.jpg", "table_caption": [], "table_footnote": ["Table 1: Summary of the results on COCO. Unless stated otherwise, we assume arbitrary time-varying convex constraints and convex cost functions. In the above table, $0\\leq\\beta\\leq1$ is an adjustable parameter, $\\alpha$ is the strong convexity parameter of the strongly convex cost functions. Conv-OPT refers to solving a constrained convex optimization problem on each round. Projection refers to the Euclidean projection operation on the convex set $\\scriptscriptstyle\\mathcal{X}$ . For typical convex sets (e.g., Euclidean box, probability simplex), projection operations are substantially more efficient than solving a constrained convex optimization problem. "], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "1.2 Our Contributions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this paper, we consider both COCO and OCS problems and make the following contributions. ", "page_idx": 2}, {"type": "text", "text": ". We propose an efficient first-order policy that simultaneously achieves $O({\\sqrt{T}})$ regret and $O({\\sqrt{T}}\\log T)$ CCV for the COCO problem. Our result breaks the long-standing $O(T^{3/4})$ barrier for the CCV and matches the lower bound (derived in Theorem 3, previously missing from the literature) up to a logarithmic term. For strongly convex cost functions, the regret guarantee is improved to $O(\\log T)$ while keeping the CCV bound the same as above. Under an additional assumption that the regret is non-negative, we obtain a further improved logarithmic CCV bound in the strongly convex setting (see Table 1). ", "page_idx": 2}, {"type": "text", "text": "2. We additionally consider a special case of the COCO problem, called Online Constraint Satisfaction (OCS), under relaxed feasibility assumptions and obtain sub-linear CCV bounds. 3. On the algorithmic side, our policy simply runs an adaptive first-order OCO algorithm as a blackbox on a specially constructed convex surrogate cost function sequence. On every round, the policy needs to compute only two gradients and an Euclidean projection. This is way more efficient compared to the policies proposed in the previous works [Guo et al., 2022, Neely and Yu, 2017], which need to solve expensive convex optimization problems on each round while yielding sub-optimal bounds. Furthermore, in the special case of time-invariant constraints, our results yield an efficient first-order OCO policy with competitive regret and CCV bounds [Mahdavi et al., 2012, Jenatton et al., 2016, Yi et al., 2021]. ", "page_idx": 2}, {"type": "text", "text": "4. Our results are obtained by introducing a crisp and elegant potential function-based algorithmic technique for simultaneously controlling the regret and the CCV. In brief, the regret and CCV bounds are derived from a single inequality that arises from plugging in off-the-shelf adaptive regret bounds in a new regret decomposition result (Eqn. (6)). This new analytical technique might also be of independent interest. ", "page_idx": 2}, {"type": "text", "text": "5. Finally, in Section 4, we evaluate the practical performance of our algorithm in the online credit card fraud detection problem with a highly imbalanced dataset. ", "page_idx": 3}, {"type": "text", "text": "2 The Constrained OCO (COCO) Problem ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "2.1 Assumptions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We now state the assumptions considered in this paper. These assumptions are standard in literature on the COCO problem [Guo et al., 2022, Yi et al., 2021, Neely and Yu, 2017]. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1 (Convexity). The cost function $f_{t}:\\mathcal{X}\\mapsto\\mathbb{R}$ and the constraint function $g_{t,i}:\\mathcal{X}\\mapsto\\mathbb{R}$ are convex for all $t\\geq1,i\\in[k]$ . The admissible set (a.k.a. the decision set or the action set) $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ is closed and convex and has a finite Euclidean diameter $D$ . ", "page_idx": 3}, {"type": "text", "text": "Assumption 2 (Lipschitzness). All cost functions $\\{f_{t}\\}_{t\\ge1}$ and the constraint functions $\\{g_{t,i}\\}_{i\\in[k],t\\geq1}{}^{,}s$ are $G$ -Lipschitz. In other words, for any $x,y\\in\\mathcal{X}$ , we have ", "page_idx": 3}, {"type": "equation", "text": "$$\n|f_{t}(x)-f_{t}(y)|\\leq G\\|x-y\\|,\\ |g_{t,i}(x)-g_{t,i}(y)|\\leq G\\|x-y\\|,\\ \\forall t\\geq1,i\\in[k].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Unless specified otherwise, the norm $\\|\\cdot\\|$ will refer to the standard Euclidean norm and $\\nabla f$ will refer to an arbitrary subgradient of a convex function $f$ . Assumption 2 implies that the $\\ell_{2}$ -norm of the (sub)gradients of the cost and constraint functions are uniformly upper-bounded by $G$ over the admissible set $\\mathcal{X}$ . Finally, we make the following feasibility assumption about the constraint functions. ", "page_idx": 3}, {"type": "text", "text": "Assumption 3 (Feasibility). There exists a feasible action $x^{\\star}\\in\\mathcal{X}$ s.t. $g_{t,i}(x^{\\star})\\leq0,\\forall t,i$ . The feasible set $\\varkappa^{\\star}$ is defined to be the set of all feasible actions. The feasibility assumption implies that $\\mathcal{X}^{\\star}\\neq\\mathcal{O}$ . ", "page_idx": 3}, {"type": "text", "text": "The feasibility assumption distinguishes the cost functions from the constraint functions and is commonly assumed in the literature [Guo et al., 2022, Neely and Yu, 2017, Yu and Neely, 2016, Yuan and Lamperski, 2018, Yi et al., 2023, Liakopoulos et al., 2019]. In Section 3, we will consider a constraint-only variant of the problem where the feasibility assumption (Assumption 3) will be relaxed. See Appendix A.1 for a brief discussion on the assumptions. ", "page_idx": 3}, {"type": "text", "text": "Remarks: On each round, multiple constraints of the form $g_{t,i}(x)\\leq0,i\\in[k]$ can be replaced by a single new constraint $g_{t}(x)\\leq0$ where the constraint function $g_{t}$ is defined to be the pointwise maximum of the given constraints, i.e., $g_{t}(x)\\equiv\\operatorname*{max}_{i=1}^{k}g_{t,i}(x),x\\in\\mathcal{X}$ . It is easy to verify that if each of the constraint functions $\\{g_{t,i}\\}_{i=1}^{k}$ satisfies the above assumptions, then the constraint function $g_{t}$ defined above also satisfies the assumptions. Hence, throughout this section and without loss of generality, we will assume that only one constraint function is revealed on each round. That being said, under the relaxed feasibility assumption in Section 3, this trick does not work and there we will need to consider the full set of $k$ constraint functions. ", "page_idx": 3}, {"type": "text", "text": "2.2 Online Policy for COCO ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Recall that compared to the standard OCO problem where the only objective is to minimize the Regret [Hazan, 2022], in COCO, our objective is twofold: to simultaneously control the Regret and the CCV. See Section A.2 in the Appendix for preliminaries on the OCO problem and some standard results which will be useful in our analysis. In the following, we propose a Lyapunov function-based policy that yields the optimal Regret and CCV bounds for the COCO problem. Although for simplicity, we assume that the horizon length $T$ is known, we can use the standard doubling trick for an unknown $T$ . ", "page_idx": 3}, {"type": "text", "text": "2.3 Design and Analysis of the Algorithm ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "To simplify the analysis, we pre-process the cost and constraint functions on each round as follows. ", "page_idx": 3}, {"type": "text", "text": "Pre-processing: On every round, we first clip the negative part of the constraint function to zero by passing it through the standard ReLU unit. Then, we scale both the cost and constraint functions by a positive factor $\\beta$ , which will be determined later. In other words, we work with the pre-processed inputs $\\tilde{f}_{t}\\gets\\beta f_{t},\\tilde{g}_{t}\\gets\\beta(g_{t})^{+}$ . Hence, the pre-processed functions are $\\beta G$ -Lipschitz and $\\tilde{g}_{t}\\geq0,\\forall t$ . ", "page_idx": 3}, {"type": "text", "text": "1: Input: Sequence of convex cost functions $\\{f_{t}\\}_{t=1}^{T}$ and constraint functions $\\{g_{t}\\}_{t=1}^{T}$ , $G\\,=\\,{\\bf a}$ common Lipschitz constant, $T=$ Horizon length, $D=$ Euclidean diameter of the admissible set $\\mathcal{X}$ , $\\mathcal{P}_{\\mathcal{X}}(\\cdot)=\\overline{{\\phantom{\\sum_{i}^{2}\\left(\\frac{1}{\\cdot}\\right)}}}$ Euclidean projection operator on the set $\\mathcal{X}$   \n2: Parameter settings: 1. Convex cost functions: $\\begin{array}{r}{\\beta=(2G D)^{-1},V=1,\\lambda=\\frac{1}{2\\sqrt{T}},\\Phi(x)=\\exp(\\lambda x)-1.}\\end{array}$ 2. $\\alpha$ -strongly convex cost functions: $\\begin{array}{r}{\\beta=1,V=\\frac{8G^{2}\\ln(T e)}{\\alpha},\\Phi(x)=x^{2}}\\end{array}$ .   \n3: Initialization: Set $x_{1}\\in\\mathcal{X}$ arbitrarily, $Q(0)=0$ .   \n4: for each $t=1:T$ do   \n5: Play $x_{t}$ , observe $f_{t},g_{t}$ , incur a cost of $f_{t}(\\boldsymbol{x}_{t})$ and constraint violation of $(g_{t}(x_{t}))^{+}$   \n6: $\\tilde{f}_{t}\\gets\\beta f_{t},\\tilde{g}_{t}\\gets\\beta\\operatorname*{max}(0,g_{t})$ .   \n7: $Q(t)=Q(t-1)+\\tilde{g}_{t}(x_{t})$ .   \n8: Compute (sub)gradient $\\dot{\\nabla}_{t}=\\nabla\\hat{f}_{t}(x_{t})$ , where the surrogate function $\\hat{f}_{t}$ is defined in Eqn. (5)   \n9: $x_{t+1}=\\mathcal{P}_{\\mathcal{X}}\\big(x_{t}-\\eta_{t}\\nabla_{t}\\big)$ , where $\\eta_{t}=\\left\\{\\frac{\\sqrt{2}D}{2\\sqrt{\\sum_{\\tau=1}^{t}\\|\\nabla_{\\tau}\\|_{2}^{2}}},\\right.$ for convex costs (AdaGrad stepsizes) for strongly convex costs ( $H_{s}{=}$ strong convexity parameter of $f_{s},s\\geq1]$ ) ", "page_idx": 4}, {"type": "text", "text": "10: end for each ", "page_idx": 4}, {"type": "text", "text": "2.3.1 Defining the Surrogate Cost Functions ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let $Q(t)$ denote the CCV for the pre-processed constraints up to round $t$ . Clearly, $Q(t)$ satisfies the simple recursion $Q(t)=Q(t-1)+\\bar{g_{t}}(x_{t}),t\\geq1$ , with $\\overset{\\vartriangle}{Q}(0)^{\\bar{\\mathbf{\\alpha}}}=0$ . Recall that one of our objectives is to make $Q(t)$ small. Towards this, let $\\Phi:\\mathbb{R}_{+}\\mapsto\\mathbb{R}_{+}$ be any non-decreasing differentiable convex potential (Lyapunov) function such that $\\Phi(0)=0$ . Using the convexity of $\\Phi(\\cdot)$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{\\Phi(Q(t))}&{\\leq}&{\\Phi(Q(t-1))+\\Phi^{\\prime}(Q(t))(Q(t)-Q(t-1))}\\\\ &{=}&{\\Phi(Q(t-1))+\\Phi^{\\prime}(Q(t))\\tilde{g}_{t}(x_{t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Hence, the change $(d r i f t)$ of the potential function $\\Phi(Q(t))$ on round $t$ can be upper bounded as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Phi(Q(t))-\\Phi(Q(t-1))\\leq\\Phi^{\\prime}(Q(t))\\tilde{g}_{t}(x_{t}).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Recall that, in addition to controlling the CCV, we also want to minimize the cumulative cost $\\textstyle\\sum_{t=1}^{T}f_{t}(x_{t})$ (which is equivalent to the regret minimization). Inspired by the stochastic drift-pluspenalty framework of Neely [2010], we combine these two objectives to a single objective of minimizing a sequence of surrogate cost functions $\\{\\hat{f}_{t}\\}_{t=1}^{T}$ which are obtained by taking a positive linear combination of the drift upper bound (4) and the cost function. More precisely, we define ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{f}_{t}(x):=V\\tilde{f}_{t}(x)+\\Phi^{\\prime}(Q(t))\\tilde{g}_{t}(x),\\;\\;t\\geq1.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In the above, $V$ is a suitably chosen non-negative parameter to be determined later. In brief, the proposed policy for COCO, described in Algorithm 1, simply runs an adaptive OCO policy on the surrogate cost function sequence $\\{\\hat{f}_{t}\\}_{t\\ge1}$ , with a specific choice of the potential function $\\Phi(\\cdot)$ , the parameter $V$ , and step-size sequence $\\{\\eta_{t}\\}_{t\\geq1}$ , as dictated by the following analysis. ", "page_idx": 4}, {"type": "text", "text": "2.3.2 The Regret Decomposition Inequality ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let $x^{\\star}\\in\\mathcal{X}^{\\star}$ be any feasible action guaranteed by Assumption (3). Plugging in the definition of surrogate costs (5) into the drift inequality (4), and using the fact that $g_{\\tau}(\\bar{x}^{\\star})\\leq0,\\forall\\tau\\geq1$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Phi(Q(\\tau))-\\Phi(Q(\\tau-1))+V(\\tilde{f}_{\\tau}(x_{\\tau})-\\tilde{f}_{\\tau}(x^{\\star}))\\leq\\hat{f}_{\\tau}(x_{\\tau})-\\hat{f}_{\\tau}(x^{\\star}),\\ \\forall\\tau\\geq1.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Summing the above inequalities for rounds $1\\leq\\tau\\leq t$ , and using the fact that $\\Phi(0)=0$ , we obtain ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Phi(Q(t))+V\\mathrm{Regret}_{t}(x^{\\star})\\le\\mathrm{Regret}_{t}^{\\prime}(x^{\\star}),\\ \\forall x^{\\star}\\in\\mathcal{X}^{\\star},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where Regrett on the LHS and Regre $\\mathfrak{t}_{t}^{\\prime}$ on the RHS of (6) refer to the regret for learning the preprocessed cost functions $\\{\\widetilde f_{t}\\}_{t\\geq1}$ and the surrogate cost functions $\\{\\hat{f}_{t}\\}_{t\\geq1}$ respectively. We will use ", "page_idx": 4}, {"type": "text", "text": "the following upper bound on the $\\ell_{2}$ -norm of the (sub)gradients $G_{t}$ of the surrogate cost function $\\hat{f}_{t}$ defined in Eqn. (5): ", "page_idx": 5}, {"type": "equation", "text": "$$\nG_{t}\\equiv\\|\\nabla\\hat{f}_{t}(x_{t})\\|\\overset{(a)}{\\leq}V\\|\\nabla\\tilde{f}_{t}(x_{t})\\|+\\Phi^{\\prime}(Q(t))\\|\\nabla\\tilde{g}_{t}(x_{t})\\|\\overset{(b)}{\\leq}\\beta G\\big(V+\\Phi^{\\prime}(Q(t)\\big),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where in $(a)$ , we have used the triangle inequality for $\\ell_{2}$ norms and in $(b)$ , we have used the fact that all pre-processed functions are $\\beta G$ -Lipschitz. ", "page_idx": 5}, {"type": "text", "text": "2.3.3 Convex Cost and Convex Constraint Functions ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We now apply the regret decomposition inequality (6) to the case of convex cost and convex constraint functions. Let us choose the regret-minimizing OCO subroutine for the surrogate cost functions to be the OGD policy with adaptive step sizes (a.k.a. AdaGrad) described in part 1 of Theorem 6 in the Appendix (see Algorithm 1). Plugging in the adaptive regret bound (24) on the RHS of (6), setting $\\beta^{\\doteq}\\,(2G D)^{-1}$ , and using Eqn. (7), we arrive at the following inequality valid for any $t\\geq1$ \u2236 ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Phi(Q(t))+V\\mathrm{Regret}_{t}(x^{\\star})\\leq{\\sqrt{\\sum_{\\tau=1}^{t}\\left(\\Phi^{\\prime}(Q(\\tau))\\right)^{2}}}+V{\\sqrt{t}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In de\u221ariving the above\u221a result, we have utilized simple algebraic inequalities $(x+y)^{2}\\leq2(x^{2}+y^{2})$ and ${\\sqrt{a+b}}\\leq{\\sqrt{a}}+{\\sqrt{b}},a,b\\geq0$ . Now recall that the sequence $\\{Q(t)\\}_{t\\geq1}$ is non-negative and nondecreasing as $\\tilde{g}_{t}\\ge0$ . Furthermore, the derivative $\\Phi^{\\prime}(\\cdot)$ is non-decreasing as the function $\\Phi(\\cdot)$ is assumed to be convex. Hence, bounding all terms in the summation on the RHS of (8) from above by the last term, we arrive at the following inequality for any feasible $x^{\\star}\\in\\mathcal{X}^{\\star}$ \u2236 ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Phi(Q(t))+V\\mathrm{Regret}_{t}(x^{\\star})\\leq\\Phi^{\\prime}\\big(Q(t)\\big)\\sqrt{t}+V\\sqrt{t}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The simplified regret decomposition inequality (9) constitutes the key step for the subsequent analysis. ", "page_idx": 5}, {"type": "text", "text": "\u220ePerformance Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "An exponential Lyapunov function: We now derive the Regret and CCV bounds for the proposed policy (Algorithm 1) by choosing $\\Phi(\\cdot)$ to be the exponential Lyapunov function: $\\Phi(x)\\equiv\\exp(\\lambda x)\\!-\\!1$ , where the parameter $\\lambda\\,\\geq\\,0$ will be fixed later. Clearly, the function $\\Phi(\\cdot)$ satisfies the required conditions for a Lyapunov function - it is a non-decreasing and convex function with $\\Phi(0)=\\bar{0}$ . ", "page_idx": 5}, {"type": "text", "text": "Bounding the Regret: With the above choice for the Lyapunov function $\\Phi(\\cdot)$ , Eqn. (9) implies that for any feasible $x^{\\star}\\in\\mathcal{X}^{\\star}$ and for any $t\\in[T]$ , we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\exp(\\lambda Q(t))-1+V\\mathrm{Regret}_{t}(x^{\\star})\\leq\\lambda\\exp(\\lambda Q(t))\\sqrt{t}+V\\sqrt{t}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Transposing the first term on the above inequality to the RHS and dividing throughout by $V$ , we have: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{t}(x^{\\star})\\leq\\sqrt{t}+\\frac{1}{V}+\\frac{\\exp(\\lambda Q(t))}{V}(\\lambda\\sqrt{t}-1).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Choosing any $\\textstyle\\lambda\\leq{\\frac{1}{\\sqrt{T}}}$ , the last term in the above inequality becomes non-positive for any $t\\in[T]$ Hence, for any $x^{\\star}\\in\\mathcal{X}^{\\star}$ , we have the following regret bound ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{t}(x^{\\star})\\leq\\sqrt{t}+\\frac{1}{V}.\\;\\;\\forall t\\in[T].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Bounding the CCV: Since all pre-processed cost functions are $\\beta G\\ =\\ (2D)^{-1}$ -Lipschitz, we trivially have Regret $\\begin{array}{r}{\\iota_{t}\\bigl(x^{\\star}\\bigr)=\\sum_{s=1}^{t}\\bar{\\bigl(}\\tilde{f}_{s}\\bigl(\\bar{x}_{s}\\bigr)-\\tilde{f}_{s}\\bigl(x^{\\star}\\bigr)\\bigr)\\geq-\\frac{D t}{2D}\\geq-\\frac{t}{2}}\\end{array}$ . Hence, from Eqn. (10), we have that for any $\\textstyle\\lambda<{\\frac{1}{\\sqrt{T}}}$ and any $t\\in[T]$ \u2236 ", "page_idx": 5}, {"type": "equation", "text": "$$\n{\\frac{\\exp(\\lambda Q(t))}{V}}(1-\\lambda{\\sqrt{t}})\\leq2t+{\\frac{1}{V}}\\implies Q(t)\\leq{\\frac{1}{\\lambda}}\\ln{\\frac{1+2V t}{1-\\lambda{\\sqrt{t}}}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Choosing 2\u221a1T ,V = 1, and scaling the bounds back by \u03b2\u22121 \u22612GD, we arrive at our main result. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. For the COCO problem with adversarially chosen $G$ -Lipschitz cost and constraint functions, Algorithm $^{\\,l}$ , with $\\begin{array}{r}{\\dot{\\beta^{}}\\dot{=}\\,(2G D)^{-1},V=1,\\Phi(x)\\stackrel{.}{=}\\exp(\\frac{x}{2\\sqrt{T}})-\\dot{1}}\\end{array}$ , yields the following Regret and CCV bounds for any horizon length $T\\geq1$ \u2236 ", "page_idx": 5}, {"type": "equation", "text": "$$\nR e g r e t_{t}\\leq2G D(\\sqrt{t}+1),\\;\\;\\forall t\\in[T],\\;\\;C C V_{T}\\leq4G D\\ln(2\\bigl(1+2T\\bigr)\\bigr)\\sqrt{T}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In the above, $D$ denotes the Euclidean diameter of the closed and convex admissible set $\\mathcal{X}$ . ", "page_idx": 5}, {"type": "text", "text": "2.3.4 Strongly Convex Cost and Convex Constraint Functions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now consider the setting where each of the cost functions $f_{t},t\\geq1$ , is $\\alpha$ -strongly convex for some $\\alpha>0$ . The constraint functions $g_{t}$ \u2019s are assumed to be convex as before and not necessarily strongly convex. In this case, we choose the regret-minimizing OCO subroutine for the surrogate cost functions to be the OGD algorithm with the step-size sequence as given in part 2 of Theorem 6 in the Appendix (see Algorithm 1). Since the cost functions are known to be $\\alpha$ -strongly convex, each of the surrogate cost functions (5) is $V\\alpha$ -strongly convex. Hence, using the bound from Eqn. (7), choosing the scaling parameter to be $\\beta=1$ , and simplifying the generic regret bound given by Eqn. (25), we obtain the following regret bound for learning the surrogate cost functions $\\{\\bar{\\hat{f}}_{s}\\}_{s\\ge1}$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathsf{R e g r e t}_{t}^{\\prime}(x^{\\star})\\leq\\frac{V G^{2}}{\\alpha}(1+\\ln(t))+\\frac{G^{2}}{\\alpha V}\\sum_{\\tau=1}^{t}\\frac{(\\Phi^{\\prime}(Q(\\tau)))^{2}}{\\tau},\\;x^{\\star}\\in\\mathcal{X}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In the above, we have used the standard bound for the Harmonic sum: $\\begin{array}{r}{\\sum_{\\tau=1}^{t}\\frac{1}{\\tau}\\leq1+\\ln(t)}\\end{array}$ , as well as the fact that $(a+b)^{2}\\,\\le\\,2(a^{2}+b^{2})$ . Substituting the bound (13) into the regret decomposition inequality (6), and using the non-decreasing property of the sequence $\\{Q(\\tau)\\}_{\\tau\\geq1}$ and the derivative $\\bar{\\Phi^{\\prime}(\\bar{\\cdot})}$ , we obtain ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Phi(Q(t))+V\\ R e g r e t_{t}(x^{\\star})\\leq\\frac{V G^{2}}{\\alpha}(1+\\ln(t))+\\frac{G^{2}}{\\alpha V}(1+\\ln(t))\\bigl(\\Phi^{\\prime}(Q(t))\\bigr)^{2},\\ \\forall x^{\\star}\\in\\mathcal{X}^{\\star},\\forall t.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Finally, choosing $\\Phi(\\cdot)$ as the quadratic Lyapunov function, i.e., $\\Phi(x)\\equiv x^{2}$ , we arrive at the following result for strongly convex cost and convex constraint functions. ", "page_idx": 6}, {"type": "text", "text": "Theorem 2. For the COCO problem with adversarially chosen $\\alpha$ -strongly convex, $G$ -Lipschitz cost functions and $G$ -Lipschitz convex constraint functions, Algorithm 1, with $\\beta\\;\\;=\\;\\;1,V\\;\\;=$ 8G2 l\u03b1n(T e),\u03a6(x) = x2, yields the following Regret and CCV bounds for any horizon length T \u22651 \u2236 ", "page_idx": 6}, {"type": "equation", "text": "$$\nR e g r e t_{t}(x^{\\star})\\leq\\frac{G^{2}}{\\alpha}\\bigl(1+\\ln(t)\\bigr),\\,\\,C C V_{t}=O\\bigl(\\sqrt{\\frac{t\\log T}{\\alpha}}\\bigr),\\forall x^{\\star}\\in\\mathcal{X}^{\\star},\\,\\,\\forall t\\in[T].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Furthermore, if the worst-case regret is non-negative in some round $t$ (i.e., $\\operatorname*{sup}_{x^{\\star}\\in\\mathcal{X}^{\\star}}R e g r e t_{t}(x^{\\star})\\geq0)$ , then the CCV can be further improved to $\\begin{array}{r}{C C V_{T}=O(\\frac{\\log T}{\\alpha})}\\end{array}$ while keeping the regret bound the same. ", "page_idx": 6}, {"type": "text", "text": "Please refer to Appendix A.6 for the proof of Theorem 2. ", "page_idx": 6}, {"type": "text", "text": "Remarks: The second part of the theorem is surprising because it says that when the regret is non-negative, a stronger logarithmic CCV bound holds for not necessarily strongly convex constraints. In Appendix A.7, we give example of an interesting class of adversaries, called convex adversary, for which the non-negative regret assumption holds true in the OCO setting. ", "page_idx": 6}, {"type": "text", "text": "2.4 Lower Bounds ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now show that under Assumptions 1, 2, and 3, the regret and the CCV of any online policy for the COCO problem for $T$ rounds are both lower bounded by $\\Omega({\\sqrt{T}})$ provided the problem is high-dimensional. Recall that if the con\u221astraint function $g_{t}=0,\\forall t$ , then the COCO problem reduces to the standard OCO problem, and $\\Omega({\\sqrt{T}})$ is a well-known regret lower bound for OCO [Hazan, 2022, Theorem 10]. In this case, we trivially have ${\\mathrm{CCV}}=0$ . The main challenge in proving a lower bound for COCO is simultaneously bounding both the regret and CCV. Prior work does not give any simultaneous lower bounds since the standard adversarial inputs used to derive the lower bound of Hazan [2022] do not satisfy the feasibility assumption (Assumption 3). We derive the lower bound by constructing a sequence of cost and constraint functions that satisfy Assumption 3 in a $d_{\\cdot}$ -dimensional Euclidean box of unit diameter. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3. Under Assumptions 1, 2, and 3, for any choice of the horizon length $T$ and on\u221aline policy, there exists a problem instance with dimension $d\\geq T$ where $\\operatorname*{min}(R e g r e t_{T},C C V_{T})=\\Omega(\\sqrt{T})$ . ", "page_idx": 6}, {"type": "text", "text": "In high-dimensional problems where $d\\gg T$ , the above lower bound matches with the upper bound given in Theorem 1. The proof of Theorem 3 can be found in Appendix A.4. ", "page_idx": 6}, {"type": "text", "text": "3 The Online Constraint Satisfaction Problem (OCS) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we study a special case of the COCO problem, which involves only constraint functions and no cost functions. The OCS problem arises in many practical settings, including the multi-task learning problem (see Section A.3 in the Appendix for a brief discussion). In Section A.8 in the Appendix, we also establish a connection between the OCS problem and the well-studied Convex Body Chasing problem [Argue et al., 2019]. The setup is similar to the COCO setting \u2013 on every round $t\\geq1$ , an online policy selects an action $x_{t}$ from a closed, bounded, and convex admissible set $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ . After observing the current action $x_{t}$ , the adversary chooses $k$ constraints of the form $g_{t,i}(x)\\leq0,i\\in[k]$ , where each $g_{t,i}:\\mathcal{X}\\mapsto\\mathbb{R}$ is a convex function. Let $\\mathcal{T}$ be any sub-interval of the horizon $[1,T]$ . The cumulative constraint violation $(\\mathbf{CCV})\\;\\mathbb{V}(T)$ for the OCS problem is defined as the maximum signed cumulative constraint violation in any sub-interval: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{V}(T)=\\operatorname*{max}_{i=1}^{k}\\mathbb{V}_{i}(T),\\ \\mathrm{where}\\ \\mathbb{V}_{i}(T)=\\operatorname*{max}_{Z\\subseteq[1,T]}\\sum_{t\\in\\mathbb{Z}}g_{t,i}(x_{t}),\\ 1\\leq i\\leq k.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The objective is to design an online learning policy so that $\\mathbb{V}(T)$ is as small as possible. It is worth noting that in the OCS problem, we consider a soft constraint violation metric maxI $\\textstyle\\sum_{t\\in{\\mathcal{T}}}g_{t,i}(x_{t})$ instead of the hard violation metric $\\textstyle\\sum_{t=1}^{T}(g_{t,i}(x_{t}))^{+}$ as in COCO. This allows for compensating the infeasibility on one round with strict feasibility on other rounds. In contrast with the COCO setting, without Assumption 3, running a no-regret policy on the pointwise maximum of the constraint functions no longer works as the CCV of any fixed benchmark could grow linearly with $T$ . In the OCS problem, we relax the feasibility assumption (Assumption 3), and consider the following two distinct alternatives instead. ", "page_idx": 7}, {"type": "text", "text": "1. $S$ -feasibility: Here, we assume that there is an admissible action $x^{\\star}\\in\\mathcal{X}$ that satisfies the aggregate constraints over any interval of $S$ rounds. However, unlike Liakopoulos et al. [2019], which also considers the same assumption, the value of the parameter $S$ is not necessarily known to the policy $a$ priori. Towards this end, we define the set of all $S$ -feasible actions $\\chi_{S}$ as below: ", "page_idx": 7}, {"type": "equation", "text": "$\\mathcal{X}_{S}=\\{x^{\\star}\\in\\mathcal{X}:\\sum_{\\tau\\in\\mathbb{Z}}g_{\\tau,i}(x^{\\star})\\leq0$ ", "text_format": "latex", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathcal{Z}\\subseteq[1,T],\\;|\\mathcal{Z}|=S,\\forall i\\in[k]\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "We now replace Assumption 3 with the following weaker version: ", "page_idx": 7}, {"type": "text", "text": "Assumption 4 ( $S$ -feasibility). $\\ensuremath{\\boldsymbol{\\chi}}_{S}\\neq\\ensuremath{\\boldsymbol{\\mathcal{O}}}$ for some $1\\le S\\le T$ . ", "page_idx": 7}, {"type": "text", "text": "Clearly, Assumption 4 is weaker than Assumption 3 as $\\mathcal{X}^{\\star}\\subseteq\\mathcal{X}_{S},\\forall S\\geq1$ . Note that even when the individual constraint functions satisfy $S$ -feasibility, their pointwise maximum need not satisfy $S$ -feasibility. Hence, unlike COCO under Assumption 3, this problem cannot be solved by simply running a no-regret policy on the pointwise maximum of the constraints. ", "page_idx": 7}, {"type": "text", "text": "2. $P_{T}$ -constrained adversary In this case, we drop any feasibility assumption altogether. As a consequence, any static admissible benchmark $x^{\\star}\\in\\mathcal{X}$ also incurs a CCV. ", "page_idx": 7}, {"type": "text", "text": "Definition 1. An adversary is called $P_{T}$ -constrained if its minimum static CCV is $P_{T}F$ , i.e., $\\begin{array}{r}{\\frac{1}{F}\\operatorname*{min}_{x^{\\star}\\in\\mathcal{X}}\\operatorname*{max}_{\\mathcal{Z}\\subseteq[T],i}\\sum_{t\\in\\mathcal{Z}}g_{t,i}\\big(x^{\\star}\\big)\\;=\\;P_{T},}\\end{array}$ , where $F$ is a normalizing factor denoting the maximum absolute value of the constraint functions within the compact admissible set $\\mathcal{X}$ . ", "page_idx": 7}, {"type": "text", "text": "As before, the value of $P_{T}$ is not necessarily known to the policy a priori. ", "page_idx": 7}, {"type": "text", "text": "3.1 Designing an OCS Policy with a Quadratic Lyapunov function ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We define a process $\\pmb{Q}(t)=\\big(Q_{i}(t),i\\in[k]\\big),t\\geq1.$ , which tracks the CCV: ", "page_idx": 7}, {"type": "equation", "text": "$$\nQ_{i}(t)=\\big(Q_{i}(t-1)+g_{t,i}(x_{t})\\big)^{+}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Notably, in contrast to COCO, we do not clip the constraint functions in the above recursion. Expanding Eqn. (17), which is also known as the queueing recursion or the Lindley process [Asmussen, 2003, pp. 92], and using the definition in Eqn. (15), we have the following relation for all $i\\in[k]$ \u2236 ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{V}_{i}(T)\\equiv\\operatorname*{max}_{t=1}^{T}\\operatorname*{max}(0,\\operatorname*{max}_{\\tau=0}^{t-1}\\sum_{s=t-\\tau}^{t}g_{s,i}(x_{l}))=\\operatorname*{max}_{t=1}^{T}Q_{i}(t).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Equation (18) indicates that to control the CCV (15), it is sufficient to control the $Q(t)$ process. Similar to the COCO problem, we combine the classic Lyapunov method with adaptive no-regret OCO policies to control the $Q(t)$ process. ", "page_idx": 7}, {"type": "text", "text": "A Quadratic Lyapunov function: We consider the quadratic potential function $\\Phi(Q(t))\\;\\equiv\\;$ $\\textstyle\\sum_{i=1}^{k}Q_{i}^{2}(t),t\\geq1$ . Since $((x)^{+})^{2}=x x^{+}$ , $\\forall x\\in\\mathbb{R}$ , from Eqn. (17), we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{Q_{i}^{2}(t)}&{\\;=\\;\\;\\;\\big(Q_{i}\\big(t-1\\big)+g_{t,i}\\big(x_{t}\\big)\\big)Q_{i}(t)=Q_{i}\\big(t-1\\big)Q_{i}(t)+Q_{i}(t)g_{t,i}(x_{t}),}\\\\ &{\\stackrel{(a)}{\\le}\\;\\;\\frac{1}{2}Q_{i}^{2}(t)+\\displaystyle\\frac{1}{2}Q_{i}^{2}(t-1)+Q_{i}(t)g_{t,i}(x_{t}),\\mathrm{~}\\forall i\\in[k].}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where in $(a)$ , we have used the AM-GM inequality. Rearranging Eqn. (19), the change of the potential function $\\Phi(Q(t))$ on round $t$ can be upper bounded as follows ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\Phi(Q(t))-\\Phi(Q(t-1))=\\sum_{i=1}^{k}\\big(Q_{i}^{2}(t)-Q_{i}^{2}(t-1)\\big)\\leq2\\sum_{i=1}^{k}Q_{i}(t)g_{t,i}(x_{t}).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Similar to (5), we now define a surrogate cost function $\\hat{f}_{t}:\\mathcal{X}\\mapsto\\mathbb{R}$ as a linear combination of the constraint functions with the coefficients given by the vector $Q(t)$ , i.e., ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\hat{f}_{t}(x)\\equiv2\\sum_{i=1}^{k}Q_{i}(t)g_{t,i}(x).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Clearly, the surrogate cost function $\\hat{f}_{t}(\\cdot)$ is convex since the coefficients $Q_{i}(t)$ \u2019s are non-negative and the constraint functions are convex. Our OCS policy, described below, simply runs a regretminimizing adaptive OCO subroutine on the surrogate cost function sequence (21). ", "page_idx": 8}, {"type": "text", "text": "The OCS policy (Algorithm 2): Pass the surrogate cost functions $\\{\\hat{f}_{t}\\}_{t\\geq1}$ to the AdaGrad algorithm which enjoys a data-dependent regret as given in part 1 of Theorem 6 in the Appendix (Eqn. (24)). ", "page_idx": 8}, {"type": "text", "text": "Algorithm 2 Online Policy for OCS ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "1: Input: Sequence of convex constraint functions $\\{g_{t,i}\\}_{i\\in[k],t\\geq1}$ , a closed and convex admissible   \nset $\\mathcal{X}$ with a finite Euclidean diameter $D$ , $\\mathcal{P}_{\\mathcal{X}}(\\cdot)=$ Euclidean projection operator on the set $\\mathcal{X}$   \n2: Output: Sequence of admissible actions $\\{x_{t}\\}_{t\\ge1}$   \n3: Initialization: Set $x_{1}\\in\\mathcal{X}$ arbitrarily, $Q_{i}(0)=0$ , $\\forall i\\in[k]$ .   \n4: for each each round $t\\geq1$ do   \n5: Play $x_{t}$ , observe the constraint functions $\\{g_{t,i}\\}_{i\\in[k]}$ revealed by the adversary.   \n6: [Update $Q(t)]\\;Q_{i}(t)=(Q_{i}(t-1)+g_{t,i}(x_{t}))^{+}$ , $\\overline{{i\\in[k]}}$ .   \n7: [Compute a subgradient] $\\begin{array}{r}{\\nabla_{t}\\equiv\\nabla{\\hat{f}}_{t}{\\left(x_{t}\\right)}=2\\sum_{i=1}^{k}Q_{i}(t)\\nabla g_{t,i}{\\left(x_{t}\\right)}.}\\end{array}$ .   \n8: [AdaGrad step] Compute the next action xt+1 = PX (xt \u2212\u03b7t\u2207t), where \u03b7t =2\u221a\u2211t\u03c4=21 D\u2223\u2223\u2207\u03c4 \u2223\u222322.   \n9: end for each ", "page_idx": 8}, {"type": "text", "text": "3.2 Performance Bounds ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Theorem 4. Under Assumptions \u221a1, 2, and 4, Algorithm 2 achieves the following CCV bound for the OCS problem: $\\mathbb{V}(T)=O(\\operatorname*{max}(\\sqrt{S T},S))$ . ", "page_idx": 8}, {"type": "text", "text": "Theorem 5. Under Assumptions $^{\\,l}$ and 2, Algorithm 2 achieves the following CCV bound for the OCS problem for any $P_{T}$ -constrained adversary as given in Definition 1: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{V}(T)=O(P_{T}^{1/3}T^{2/3})+O(\\sqrt{T}).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Trivially, we have $S\\le T$ and $P_{T}\\,\\leq\\,T$ . In the non-trivial case where either $S$ or $P_{T}$ increases sub-linearly with the horizon length $T$ , the above theorems yield sublinear CCV bounds. ", "page_idx": 8}, {"type": "text", "text": "4 Experiments: Credit Card Fraud Detection ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Classification with a highly imbalanced dataset: We first formulate the credit card fraud detection problem in the COCO framework. Assume that we receive a sequence of $d$ -dimensional feature vectors $\\{z_{t}\\}_{t\\ge1}$ and the corresponding binary labels $\\{y_{t}\\}_{t\\ge1}$ for a sequence of credit card transactions, where each transaction can either be legitimate (label $=0$ ) or fraudulent $({\\tt1a b e l}=1)$ ). The problem is to predict the label $\\hat{y}_{t}$ for each transaction $z_{t}$ before its true label $y_{t}\\in\\{0,1\\}$ is revealed. Typically, legitimate transactions outnumber fraudulent transactions by orders of magnitude. Since the goal is to detect any fraudulent transactions (even at the cost of a few false alarms), maximizing the classification accuracy alone is insufficient due to the significant class imbalance. We propose the following reformulation for this problem within the COCO framework. ", "page_idx": 8}, {"type": "image", "img_path": "TxffvJMnBy/tmp/84968e5c04639977555e358a520903bab7cacdd00d70546ccab78e717f29e2ca.jpg", "img_caption": ["Figure 1: ROC curve obtained by varying $\\lambda$ "], "img_footnote": [], "page_idx": 9}, {"type": "image", "img_path": "TxffvJMnBy/tmp/1ff7de69c6430b877f4f206870e9e1068c4e146247176f9e92c2cdd6f1070fc4.jpg", "img_caption": ["Figure 2: Typical variation of the CCV with time "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Formulation: Let $\\hat{y}_{t}(z_{t},x)$ be the likelihood of class 1 for the feature $z_{t}$ , given by a parameterized model with parameter $x$ . Hence, the log-likelihood $\\mathcal{L}(t)$ of the data on round $t$ can be expressed as: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\mathcal{L}(t)=y_{t}\\log(\\hat{y}_{t}(z_{t},x))+(1-y_{t})\\log(1-\\hat{y}_{t}(z_{t},x)).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "We train the model by maximizing the sum of log-likelihoods for legitimate transactions, subject to the constraint that all fraudulent transactions have a likelihood value close to 1 (i.e., the sum of the log-likelihoods of the fraudulent transactions remains close to zero): ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x}\\sum_{t=1}^{T}(1-y_{t})\\log(1-\\hat{y}_{t}(z_{t},x)),\\;\\;\\mathrm{s.t.}\\;\\;\\sum_{t=1}^{T}y_{t}\\log(\\hat{y}_{t}(z_{t},x))\\geq0.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "The above problem (22) can be immediately recognized to be an instance of COCO with the following cost and constraint functions: ", "page_idx": 9}, {"type": "equation", "text": "$$\nf_{t}(x)\\equiv-(1-y_{t})\\log(1-\\hat{y}_{t}(z_{t},x)),\\;\\;g_{t}(x)\\equiv-y_{t}\\log(\\hat{y}_{t}(z_{t},x)),\\;t\\geq1.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "In our experiments, we consider the common scenario in which the likelihoods are modeled by the output of a feedforward neural network. Note that the feasibility assumption (Assumption 3) is naturally satisfied as the overparameterized neural network models are known to perfectly fti the data [Belkin et al., 2019]. However, in this case, the functions $f_{t}$ and $g_{t}$ are generally non-convex. ", "page_idx": 9}, {"type": "text", "text": "Experiments: We experiment with a publicly available credit card transaction dataset [Dal Pozzolo et al., 2014]. This highly imbalanced dataset contains only 492 frauds $(\\sim0.17\\%)$ out of 284,807 reported transactions. Each data point has $D_{\\mathrm{in}}=30$ features and binary labels. We choose a simple network architecture with a single hidden layer containing $H=10$ hidden nodes and sigmoid nonlinearities. Unlike previous algorithms, our algorithm is especially suitable for training neural network models as it only needs to compute the gradients (via backward pass) and evaluate the functions (via forward pass). Initially, all weights are independently sampled from a standard normal distribution. The network is then trained using Algorithm 1 on a quad-core CPU with 8 GB RAM. The projection operation corresponds to $L_{2}$ -normalization. The code has been publicly released [Sinha, 2024b]. ", "page_idx": 9}, {"type": "text", "text": "Results: Given the severe class imbalance, the area under the ROC curve, which plots the True Positive Rate (TPR) against the False Positive Rate (FPR), is an appropriate metric to evaluate any prediction algorithm for this problem. By varying the hyperparameter $\\lambda$ , we obtain the ROC curve shown in Figure 1. The area under the ROC curve is computed to be $\\approx0.92$ , which is an excellent score (cf. ideal score $=1.0$ ), notwithstanding the fact that, unlike the standard resampling-based techniques, the algorithm learns in an entirely online fashion starting from random initialization. Figure 2 illustrates the expected sublinear variation of CCV during one of the algorithm runs. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we proposed efficient online policies for the COCO problem with optimal performance bounds. We also derived sublinear CCV bounds for the OCS problem under a set of relaxed assumptions. Our analysis is streamlined, leveraging Lyapunov theory and adaptive regret bounds for the standard OCO problem. In the future, exploring dynamic regret bounds and a bandit extension of the COCO problem would be interesting. ", "page_idx": 9}, {"type": "text", "text": "6 Acknowledgement ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was supported by the Department of Atomic Energy, Government of India, under project no. RTI4001 and by a Google India faculty research award. The first author was also partially supported by a US-India NSF-DST collaborative grant coordinated by IDEAS-Technology Innovation Hub (TIH) at the Indian Statistical Institute, Kolkata. The authors gratefully acknowledge comments from the anonymous reviewers, which substantially improved the quality of the presentation. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Nikolaos Liakopoulos, Apostolos Destounis, Georgios Paschos, Thrasyvoulos Spyropoulos, and Panayotis Mertikopoulos. Cautious regret minimization: Online optimization with long-term budget constraints. In International Conference on Machine Learning, pages 3944\u20133952. PMLR, 2019.   \nAbhishek Sinha. BanditQ - Fair Bandits with Guaranteed Rewards. In Uncertainty in Artificial Intelligence. PMLR, 2024a.   \nMartin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In Proceedings of the 20th international conference on machine learning (icml-03), pages 928\u2013936, 2003.   \nElad Hazan, Alexander Rakhlin, and Peter Bartlett. Adaptive online gradient descent. Advances in neural information processing systems, 20, 2007.   \nFrancesco Orabona and D\u00e1vid P\u00e1l. Scale-free online learning. Theoretical Computer Science, 716: 50\u201369, 2018.   \nFrancesco Orabona. A modern introduction to online learning. arXiv preprint arXiv:1912.13213, 2019.   \nElad Hazan. Introduction to online convex optimization. MIT Press, 2022.   \nJianjun Yuan and Andrew Lamperski. Online convex optimization for cumulative constraints. Advances in Neural Information Processing Systems, 31, 2018.   \nRodolphe Jenatton, Jim Huang, and C\u00e9dric Archambeau. Adaptive algorithms for online convex optimization with long-term constraints. In International Conference on Machine Learning, pages 402\u2013411. PMLR, 2016.   \nMehrdad Mahdavi, Rong Jin, and Tianbao Yang. Trading regret for efficiency: online convex optimization with long term constraints. The Journal of Machine Learning Research, 13(1): 2503\u20132528, 2012.   \nXinlei Yi, Xiuxian Li, Tao Yang, Lihua Xie, Tianyou Chai, and Karl Johansson. Regret and cumulative constraint violation analysis for online convex optimization with long term constraints. In International Conference on Machine Learning, pages 11998\u201312008. PMLR, 2021.   \nMichael J Neely and Hao Yu. Online convex optimization with time-varying constraints. arXiv preprint arXiv:1702.04783, 2017.   \nHao Yu, Michael Neely, and Xiaohan Wei. Online convex optimization with stochastic constraints. Advances in Neural Information Processing Systems, 30, 2017.   \nWen Sun, Debadeepta Dey, and Ashish Kapoor. Safety-aware algorithms for adversarial contextual bandit. In International Conference on Machine Learning, pages 3280\u20133288. PMLR, 2017.   \nXinlei Yi, Xiuxian Li, Tao Yang, Lihua Xie, Yiguang Hong, Tianyou Chai, and Karl H Johansson. Distributed online convex optimization with adversarial constraints: Reduced cumulative constraint violation bounds under slater\u2019s condition. arXiv preprint arXiv:2306.00149, 2023.   \nMichael J Neely. Stochastic network optimization with application to communication and queueing systems. Synthesis Lectures on Communication Networks, 3(1):1\u2013211, 2010.   \nHengquan Guo, Xin Liu, Honghao Wei, and Lei Ying. Online convex optimization with hard constraints: Towards the best of two worlds and beyond. Advances in Neural Information Processing Systems, 35:36426\u201336439, 2022.   \nTianyi Chen and Georgios B Giannakis. Bandit convex optimization for scalable and dynamic iot management. IEEE Internet of Things Journal, 6(1):1276\u20131286, 2018.   \nXuanyu Cao and KJ Ray Liu. Online convex optimization with time-varying constraints and bandit feedback. IEEE Transactions on automatic control, 64(7):2665\u20132680, 2018.   \nRahul Vaze. On dynamic regret and constraint violations in constrained online convex optimization. In 2022 20th International Symposium on Modeling and Optimization in Mobile, Ad hoc, and Wireless Networks (WiOpt), pages 9\u201316, 2022. doi: 10.23919/WiOpt56218.2022.9930613.   \nQingsong Liu, Wenfei Wu, Longbo Huang, and Zhixuan Fang. Simultaneously achieving sublinear regret and constraint violations for online convex optimization with time-varying constraints. ACM SIGMETRICS Performance Evaluation Review, 49(3):4\u20135, 2022.   \nHao Yu and Michael J Neely. A low complexity algorithm with $o(\\sqrt{T})$ regret and $o(1)$ constraint violations for online convex optimization with long term constraints. Journal of Machine Learning Research, 21(1):1\u201324, 2020.   \nXinlei Yi, Xiuxian Li, Tao Yang, Lihua Xie, Tianyou Chai, and H Karl. Regret and cumulative constraint violation analysis for distributed online constrained convex optimization. IEEE Transactions on Automatic Control, 2022.   \nHao Yu and Michael J Neely. A low complexity algorithm with $o(\\sqrt{T})$ regret and $o(1)$ constraint violations for online convex optimization with long term constraints. arXiv preprint arXiv:1604.02218, 2016.   \nCJ Argue, S\u00e9bastien Bubeck, Michael B Cohen, Anupam Gupta, and Yin Tat Lee. A nearly-linear bound for chasing nested convex bodies. In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 117\u2013122. SIAM, 2019.   \nS\u00f8ren Asmussen. Applied probability and queues, volume 2. Springer, 2003.   \nMikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine-learning practice and the classical bias\u2013variance trade-off. Proceedings of the National Academy of Sciences, 116(32):15849\u201315854, 2019.   \nAndrea Dal Pozzolo, Olivier Caelen, Yann-Ael Le Borgne, Serge Waterschoot, and Gianluca Bontempi. Learned lessons in credit card fraud detection from a practitioner perspective. Expert systems with applications, 41(10):4915\u20134928, 2014. The dataset is available for download at https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud/.   \nAbhishek Sinha. Source code for \u201cOptimal Algorithms for Online Convex Optimization with Adversarial Constraints\"; A. Sinha, R. Vaze. https://github.com/abhishek-sinha-tifr/ COCO, 2024b.   \nMax Hopkins, Daniel M. Kane, Shachar Lovett, and Gaurav Mahajan. Realizable learning is all you need. In Proceedings of Thirty Fifth Conference on Learning Theory, volume 178 of Proceedings of Machine Learning Research, pages 3015\u20133069. PMLR, 02\u201305 Jul 2022.   \nJohn Duchi, Elad Hazan, and Yoram Singer. Adaptive subgradient methods for online learning and stochastic optimization. Journal of machine learning research, 12(7), 2011.   \nJacob Abernethy, Chansoo Lee, Abhinav Sinha, and Ambuj Tewari. Online linear optimization via smoothing. In Conference on Learning Theory, pages 807\u2013823, 2014.   \nPooria Joulani, Andras Gyorgy, and Csaba Szepesv\u00e1ri. Delay-tolerant online convex optimization: Unified analysis and adaptive-gradient algorithms. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 30, 2016.   \nSebastian Ruder. An overview of multi-task learning in deep neural networks. arXiv preprint arXiv:1706.05098, 2017.   \nOfer Dekel, Philip M Long, and Yoram Singer. Online multitask learning. In International Conference on Computational Learning Theory, pages 453\u2013467. Springer, 2006.   \nKeerthiram Murugesan, Hanxiao Liu, Jaime Carbonell, and Yiming Yang. Adaptive smoothed online multi-task learning. Advances in Neural Information Processing Systems, 29, 2016.   \nNikhil Bansal, Martin B\u00f6hm, Marek Eli\u00e1\u0161, Grigorios Koumoutsos, and Seeun William Umboh. Nested convex bodies are chaseable. In Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1253\u20131260. SIAM, 2018.   \nS\u00e9bastien Bubeck, Bo\u2019az Klartag, Yin Tat Lee, Yuanzhi Li, and Mark Sellke. Chasing nested convex bodies nearly optimally. In Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, pages 1496\u20131508. SIAM, 2020. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Discussion on Assumptions 1, 2 and 3 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Assumptions 1 and 2 are standard in the online learning literature. The feasibility assumption (Assumption 3) is analogous to the realizability assumption in learning theory [Hopkins et al., 2022] and is commonly used in the COCO literature [Neely and Yu, 2017, Yu and Neely, 2016, Yuan and Lamperski, 2018, Yi et al., 2023, Liakopoulos et al., 2019]. Assumption 3 requires the existence of a single admissible action $x^{\\star}\\in\\mathcal{X}$ that satisfies the constraints in every round. Consequently, all constraint functions are required to be non-positive over a non-empty common subset. This assumption is weakened in Section 3, Assumption 4, which only requires the existence of a fixed admissible action $x^{\\star}$ that satisfies the constraints on average. Specifically, Assumption 4 requires that the sum of the constraint functions evaluated at some admissible $x^{\\star}$ over any interval of length $S$ is non-positive. Notably, throughout the paper, we do not assume Slater\u2019s condition as it does not hold in many problems of interest [Yu and Neely, 2016]. As a result, unlike many previous works [Yu et al., 2017], our bounds are independent of Slater\u2019s constant, which can be problem-dependent. Furthermore, we do not restrict the sign of either cost or constraint functions, allowing them to take both positive and negative values. ", "page_idx": 13}, {"type": "text", "text": "A.2 Preliminaries on Online Convex Optimization (OCO) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The standard OCO problem can be described as a repeated game between an online policy and an adversary [Hazan, 2022]. Let $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ be a convex decision set, which we refer to as the admissible set. In each round $t\\geq1$ , an online policy selects an action $x_{t}\\in\\mathcal{X}$ . After the action $x_{t}$ is chosen, the adversary reveals a convex cost function $f_{t}:\\mathcal{X}\\mapsto\\mathbb{R}$ . The goal of the online policy is to choose an admissible action sequence $\\{x_{t}\\}_{t\\ge1}$ so that its total cost over a horizon of length $T$ is not significantly larger than the total cost incurred by any fixed admissible action $x^{\\star}\\in\\mathcal{X}$ . More precisely, the objective is to minimize the static regret, defined as: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname{Regret}_{T}\\equiv\\operatorname*{sup}_{x^{\\star}\\in\\mathcal{X}}\\operatorname{Regret}_{T}(x^{\\star}),{\\mathrm{~where~Regret}}_{T}(x^{\\star})\\equiv\\sum_{t=1}^{T}f_{t}\\big(x_{t}\\big)-\\sum_{t=1}^{T}f_{t}\\big(x^{\\star}\\big).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Algorithm 3 Online Gradient Descent (OGD) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "1: Input: Non-empty closed convex set $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ , sequence of convex cost functions $\\{f_{t}\\}_{t\\geq1}$ , step   \nsizes $\\eta_{1},\\eta_{2},\\dots,\\eta_{T}>0$ , Euclidean projection operator $\\mathcal{P}_{\\mathcal{X}}(\\cdot)$ onto the set $\\mathcal{X}$   \n2: Initialization: Set $x_{1}\\in\\mathcal{X}$ arbitrarily   \n3: for each round $t\\geq1$ do   \n4: Play $x_{t}$ , observe $f_{t}$ , incur a cost of $f_{t}(x_{t})$ .   \n5: Compute a (sub)gradient $\\nabla_{t}\\equiv\\nabla f_{t}{\\big(}x_{t}{\\big)}$ .   \n6: Update $x_{t+1}=\\mathcal{P}_{\\mathcal{X}}\\big(x_{t}-\\eta_{t}\\nabla_{t}\\big)$ .   \n7: end for each ", "page_idx": 13}, {"type": "text", "text": "In a seminal paper, Zinkevich [2003] showed that the online gradient descent policy, outlined in Algorithm 3, run with \u221aan appropriately chosen constant step size sequence, achieves a sublinear regret bound $\\mathrm{Regret}_{T}=O(\\sqrt{T})$ for Lipschitz-continuous convex cost functions. In Theorem 6, we recall two standard results on further refined data-dependent adaptive regret bounds achieved by the OGD policy with appropriately chosen adaptive step size sequences. ", "page_idx": 13}, {"type": "text", "text": "Theorem 6. Consider the generic OGD policy outlined in Algorithm 3. ", "page_idx": 13}, {"type": "text", "text": "1. [Duchi et al., 2011], [Orabona, 2019, Theorem 4.14] Let the cost functions $\\{f_{t}\\}_{t\\geq1}$ be convex and the step size sequence be adaptively chosen as $\\begin{array}{r}{\\eta_{t}\\,=\\,\\frac{\\sqrt{2}D}{2\\sqrt{\\sum_{\\tau=1}^{t}G_{\\tau}^{2}}},t\\,\\geq\\,1}\\end{array}$ , where is the Euclidean diameter of the admissible set and $G_{t}\\,=\\,\\|\\nabla f_{t}(x_{t})\\|_{2},t\\,\\geq\\,1$ . Then Algorithm 3 achieves the following regret bound: ", "page_idx": 13}, {"type": "equation", "text": "$$\nR e g r e t_{T}\\leq\\sqrt{2}D\\sqrt{\\sum_{t=1}^{T}G_{t}^{2}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The OGD policy with the above adaptive step-size sequence is known as (a variant of) the AdaGrad policy in the literature [Duchi et al., 2011]. ", "page_idx": 14}, {"type": "text", "text": "2. [Hazan et al., 2007, Theorem 2.1] Let the cost functions $\\{f_{t}\\}_{t\\geq1}$ be strongly convex and let $H_{t}>0$ be the strong convexity parameter2 for the cost function $f_{t}$ . Let the step size sequence be adaptively chosen as \u03b7t = \u2211ts=11 Hs ,t \u22651. Then Algorithm 3 achieves the following regret bound: ", "page_idx": 14}, {"type": "equation", "text": "$$\nR e g r e t_{T}\\leq\\frac{1}{2}\\sum_{t=1}^{T}\\frac{G_{t}^{2}}{\\sum_{s=1}^{t}H_{s}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Similar adaptive regret bounds are known for various other online learning policies as well. For structured domains, one can use other algorithms such as AdaFTRL [Orabona and P\u00e1l, 2018] which gives better regret bounds for high-dimensional problems. Furthermore, for problems with combinatorial structures, adaptive oracle-efficient algorithms, e.g., Follow-the-Perturbed-Leader (FTPL)-based policies, can be employed [Abernethy et al., 2014, Theorem 11]. Our proposed policies are agnostic to the specific online learning subroutine used for the surrogate OCO problem - what matters is that the subroutine provides adaptive regret bounds similar to (24) and (25). This flexibility allows for an immediate extension of our algorithm to a wide range of settings, such as delayed feedback [Joulani et al., 2016] or combinatorial actions. ", "page_idx": 14}, {"type": "image", "img_path": "TxffvJMnBy/tmp/49dbc3083172572ca53142fe6a1f735274d12215951776a60102165bbeed89e2.jpg", "img_caption": ["A.3 Online Multi-task Learning as an Instance of the OCS Problem ", "Figure 3: A schematic for the online multi-task learning problem "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "Consider the problem of online multi-task learning where a single model is trained to perform a number of related tasks [Ruder, 2017, Dekel et al., 2006, Murugesan et al., 2016]. See Figure 3 for a simplified schematic of the multi-task learning pipeline. In this setup, the action $x_{t}$ naturally corresponds to the shared weight vector that specifies the common model for all tasks. The loss function for the $j^{\\mathrm{th}}$ task on round $t$ is given by the function $g_{t,j}(\\cdot),j\\;\\in\\;[k]$ . A task is assumed to be satisfactorily completed (e.g., correct prediction in the case of classification problems) on any round if the corresponding loss is non-positive. As an example, using linear predictors for the binary classification problem, the requirement for the $j^{\\mathrm{th}}$ task on round $t$ can be taken to be $g_{t,j}\\big(x_{t}\\big)\\,\\equiv\\,\\big\\langle z_{t,j},x_{t}\\big\\rangle\\,\\le\\,0$ , where $z_{t,j}$ is the feature vector for the $j^{\\mathrm{th}}$ task. The goal in multi-task learning is to sequentially update the shared weight vectors $\\{x_{t}\\}_{t=1}^{T}$ so that all tasks are successfully completed. Formally, we require that the maximum cumulative loss of each task over any sub-interval grows sub-linearly. Since the weight vector is shared across the tasks, the above goal would be impossible to achieve had the tasks not been related to each other [Ruder, 2017]. Theorem 4 and Theorem 5 give performance bounds for Algorithm 2 under different task-relatedness assumptions. ", "page_idx": 14}, {"type": "text", "text": "A.4 Proof of Theorem 3 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We prove the Theor\u221aem via constructing an explicit input sequence for which no online policy can have better than $\\Omega({\\sqrt{T}})$ regret and CCV. ", "page_idx": 15}, {"type": "text", "text": "Action space $\\mathcal{X}$ : Let $d=T$ . Let $\\mathcal{X}$ be the $d$ -dimensional cuboid $\\textstyle0\\leq x_{i}\\leq{\\frac{1}{\\sqrt{d}}}$ , $1\\leq i\\leq d$ . Clearly, the Euclidean diameter of $\\mathcal{X}$ is 1. ", "page_idx": 15}, {"type": "text", "text": "Input: For each round we will only consider the case when only one constraint is revealed, i.e., $k\\,=\\,1$ . On round $t\\,=\\,1,\\ldots,d$ , choose the constraint $g_{t}$ to be $\\begin{array}{r}{x_{t}\\;\\dot{\\leq}\\;\\frac{1}{4\\sqrt{d}}}\\end{array}$ or $\\textstyle x_{t}\\,\\geq\\,{\\frac{3}{4{\\sqrt{d}}}}$ with equal probability of $\\frac{1}{2}$ for $\\mathbf{x}=\\left(x_{1},\\ldots,x_{d}\\right)\\in{\\mathcal{X}}$ . Thus, at round $t$ , only the $t^{\\mathrm{th}}$ dimension has an effective constraint. If the chosen gt is xt \u22644\u221a1d then pick $\\textstyle f_{t}=\\left|x-{\\frac{1}{4{\\sqrt{d}}}}\\right|$ , otherwise pick $\\begin{array}{r}{f_{t}=\\left|x-\\frac{3}{4\\sqrt{d}}\\right|}\\end{array}$ . ", "page_idx": 15}, {"type": "text", "text": "For any online policy $\\boldsymbol{\\mathcal{A}}$ , the expected constraint violation at round $t$ is at least $\\textstyle{\\frac{1}{8{\\sqrt{d}}}}$ . Thus, the overall expected constraint violation over rounds $t=1,\\ldots,d$ is at least $\\frac{\\sqrt{d}}{8}$ . Moreover, the expected cost $\\mathbb{E}[f_{t}(x_{t})]$ of $\\boldsymbol{\\mathcal{A}}$ is at least $\\textstyle{\\frac{1}{8{\\sqrt{d}}}}$ for each $t=1,\\ldots,d_{!}$ and the overall cost $\\mathbb{E}\\big[\\sum_{t=1}^{T}f_{t}\\big(x_{t}\\big)\\big]$ is at least $\\frac{\\sqrt{d}}{8}$ . ", "page_idx": 15}, {"type": "text", "text": "Recall that the choice of input has to satisfy Assumption 3, i.e., $\\mathcal{X}^{\\star}\\neq\\mathcal{O}$ . We next demonstrate that for the prescribed input $\\exists\\;\\mathbf{x}^{\\star}\\in\\mathcal{X}^{\\star}$ . ", "page_idx": 15}, {"type": "text", "text": "Choosing a feasible $\\mathbf{x}^{\\star}$ : When $g_{t}$ is such that the constraint is $\\textstyle x_{t}\\,\\leq\\,{\\frac{1}{4{\\sqrt{d}}}}$ choose $\\mathbf{x}^{\\star}\\in\\mathcal{X}$ such that $\\begin{array}{r}{x_{t}^{\\star}~=~\\frac{1}{4\\sqrt{d}}}\\end{array}$ d for t = 1,2,...,d, while if gt is such that xt \u2265 4\u221a3d, then choose $\\begin{array}{r}{x_{t}^{\\star}\\ =\\ \\frac{3}{4\\sqrt{d}}}\\end{array}$ for $t=1,2,\\ldots,d$ . Thus, a single vector $\\mathbf{x}^{\\star}$ satisfies all the revealed constraints. Moreover, with this choice of $\\mathbf{x}^{\\star}$ , the overall cost of $\\mathbf{x}$ , $\\textstyle\\sum_{t}f_{t}(\\mathbf{x}^{\\star})$ , is 0. ", "page_idx": 15}, {"type": "text", "text": "Since $d=T$ , we get that \u221afor any online policy $\\boldsymbol{\\mathcal{A}}$ its regret is at least $\\Omega({\\sqrt{T}})$ and the cumulative constraint violation is $\\Omega({\\sqrt{T}})$ . \u220e ", "page_idx": 15}, {"type": "text", "text": "A.5 Comparison with Previous Works ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.5.1 Neely and Yu [2017], Yu et al. [2017] and Liakopoulos et al. [2019] ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Policies proposed by Yu et al. [2017] and Liakopoulos et al. [2019] are almost identical to Neely and $\\mathrm{Yu}$ [2017]. The policy proposed in Neely and $\\mathrm{Yu}$ [2017], however, is highly customized, does not fully exploit the best guarantees available for the standard OCO problem, and obtains sub-optimal performance bounds that depend inversely on Slater constant, which is assumed to be strictly positive. In a nutshell, Neely and $\\mathrm{Yu}$ [2017] choose the next action $x_{t+1}$ using the algorithm described below. For all rounds $t\\geq1$ , define the following evolution for $Q(t)$ \u2236 ", "page_idx": 15}, {"type": "equation", "text": "$$\nQ(t)=\\left(Q(t-1)+g_{t}(x_{t})+\\nabla^{T}g_{t}(x_{t})(x_{t}-x_{t-1})\\right)^{+},\\;Q(0)=0.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The next action is chosen by solving the following quadratic optimization problem: ", "page_idx": 15}, {"type": "equation", "text": "$$\nx_{t+1}=\\arg\\operatorname*{min}_{x\\in\\mathcal{X}}\\big[\\langle V\\nabla^{T}f_{t}(x_{t})+Q(t)\\nabla g_{t}(x_{t}),x\\rangle+\\alpha\\|x-x_{t-1}\\|^{2}\\big],\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $V$ and $\\alpha$ are suitably chosen parameters. ", "page_idx": 15}, {"type": "text", "text": "In comparison, we have a different and simpler update rule: ", "page_idx": 15}, {"type": "equation", "text": "$$\nQ(t)=Q(t-1)+(2G D)^{-1}(g_{t}(x_{t}))^{+},\\;Q(0)=0.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We then construct a convex surrogate function $\\begin{array}{r}{\\hat{f}_{t}(x)\\equiv f_{t}(x)\\!+\\!\\frac{1}{4G D\\sqrt{T}}e^{\\frac{Q(t)}{2\\sqrt{T}}}(g_{t}(x))^{+}}\\end{array}$ , whose gradient is then passed directly to the AdaGrad subroutine. ", "page_idx": 15}, {"type": "text", "text": "Remarks: We emphasize that Theorem 1, which shows that it is possible to simultaneously achieve $O({\\sqrt{T}})$ regret and $\\dot{\\tilde{O}}(\\sqrt{T})$ CCV in the convex setting without assuming Slater\u2019s condition, is highly surprising and unexpected. In fact, Liakopoulos et al. [2019, Section 4] had previously commented that: ", "page_idx": 15}, {"type": "text", "text": "\"... On the other hand, the point $O({\\sqrt{T}}),O({\\sqrt{T}})$ achieved by Neely and Yu [2017] for $K=1$ is not part of our achievable guarantees; we attribute this gap to the stricter Slater assumption studied by Neely and Yu [2017].\" ", "page_idx": 16}, {"type": "text", "text": "Theorem 1 squarely falsifies the last conjecture. ", "page_idx": 16}, {"type": "text", "text": "A.5.2 Guo et al. [2022] ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The policy in Guo et al. [2022] is a slightly modified form of the policy proposed in [Neely and Yu, 2017]. In particular, it chooses the action $x_{t}$ by solving the following quadratic optimization problem over $\\mathcal{X}$ \u2236 ", "page_idx": 16}, {"type": "equation", "text": "$$\nx_{t}=\\arg\\operatorname*{min}_{x\\in\\mathcal{X}}\\big[\\big\\langle\\nabla f_{t-1}\\big(x_{t-1}\\big),x-x_{t-1}\\big\\rangle+Q\\big(t-1\\big)\\gamma_{t-1}g_{t-1}^{+}\\big(x\\big)+\\alpha_{t-1}\\big\\|x-x_{t-1}\\big\\|^{2}\\big],\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the $Q$ variables are updated as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\nQ(t)=\\operatorname*{max}\\bigl(Q(t-1)+\\gamma_{t-1}g_{t-1}^{+}(x_{t}),\\eta_{t}\\bigr).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here $\\alpha_{t},\\eta_{t},\\gamma_{t}$ are suitably chosen learning rate parameters. Essentially, this policy is trying to find the local optimum of an augmented Lagrangian under the online information model $f_{t}$ and $g_{t}$ are revealed after action $x_{t}$ is chosen). Since their augmented Lagrangian involves the constraint function $g_{t-1}$ , their policy needs to solve a full-fledged constrained convex optimization problem over the set $\\mathcal{X}$ after having full access to the constraint function. In comparison, our policy, rather than using approximations to Lagrangian and adding regularizers, makes full use of the well-developed theory for OCO and uses first-order methods that need to compute only a gradient and perform one Euclidean projection on each round. ", "page_idx": 16}, {"type": "text", "text": "A.5.3 Jenatton et al. [2016] ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The policy proposed by Jenatton et al. [2016] is based on the idea of primal-dual algorithm for optimizing the augmented Lagrangian ", "page_idx": 16}, {"type": "equation", "text": "$$\nL_{t}(\\lambda,x)=f_{t}(x)+\\lambda g_{t}(x)-{\\frac{\\theta_{t}}{2}}\\;\\lambda^{2},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\textstyle{\\frac{\\theta_{t}}{2}}\\lambda^{2}$ is the augmentation term. The primal variable $x_{t}$ and the dual variable $\\lambda_{t}$ are updated by executing projected gradient descent and gradient ascent on the Lagrangian as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\boldsymbol{x}_{t+1}=\\mathcal{P}_{\\mathcal{X}}\\big(\\boldsymbol{x}_{t}-\\eta_{t}\\nabla_{\\boldsymbol{x}}L_{t}(\\boldsymbol{x}_{t},\\lambda_{t})\\big)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\lambda_{t+1}=\\big(\\lambda_{t}+\\mu_{t}\\nabla_{\\lambda}L_{t}\\big(x_{t},\\lambda_{t}\\big)\\big)^{+},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\theta_{t},\\eta_{t}$ , and $\\mu_{t}$ are parameters to be chosen. ", "page_idx": 16}, {"type": "text", "text": "A.6 Proof of Theorem 2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Bounding the CCV: Choosing $\\Phi(x)=x^{2}$ in Eqn. (14), we have for any feasible $x^{\\star}\\in\\mathcal{X}^{\\star}$ \u2236 ", "page_idx": 16}, {"type": "equation", "text": "$$\nQ^{2}(t)+V\\mathbf{Regret}_{t}(x^{\\star})\\leq\\frac{V G^{2}}{\\alpha}(1+\\ln(t))+\\frac{4G^{2}Q^{2}(t)\\ln(T e)}{\\alpha V},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where, on the last term in the RHS, we have used the fact that $t\\leq T$ . Setting $V\\,=\\,\\frac{8G^{2}\\ln(T e)}{\\alpha}$ , and transposing the last term on the RHS to the left, the above inequality yields ", "page_idx": 16}, {"type": "equation", "text": "$$\nQ^{2}(t)+2V\\mathrm{Regret}_{t}(x^{\\star})\\leq\\frac{2V G^{2}}{\\alpha}(1+\\ln(t)).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Since the cost functions are assumed to be $G$ -Lipschitz (Assumption 2), we trivially have Regret $\\begin{array}{r}{\\mathbf{\\Theta}_{t}\\big(x^{\\star}\\big)=\\sum_{t=1}^{T}\\bigl(f_{t}\\bigl(x_{t}\\bigr)-f_{t}\\bigl(x^{\\star}\\bigr)\\bigr)\\geq-G D t}\\end{array}$ . Hence, from Eqn. (29), we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\nQ^{2}(t)\\leq2V G D t+\\frac{2V G^{2}}{\\alpha}(1+\\ln(t))\\implies Q(t)\\stackrel{(a)}{\\leq}4G\\sqrt{\\frac{G D}{\\alpha}}t\\ln(T e)+\\frac{4G^{2}\\ln(T e)}{\\alpha}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "whe\u221are step (a), we have substituted $V\\,=\\,\\frac{8G^{2}\\ln(T e)}{\\alpha}$ . Hence, we have the following bound $\\mathrm{CCV}_{t}=$ $O\\big(\\sqrt{\\frac{t\\log T}{\\alpha}}\\big)$ ", "page_idx": 16}, {"type": "text", "text": "Bounding the regret: Using the above choice for the parameter $V$ and the fact that $Q^{2}(t)\\geq0$ , from Eqn. (29), we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n2V\\mathrm{Regret}_{t}(x^{\\star})\\leq\\frac{2V G^{2}}{\\alpha}(1+\\ln(t)).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This leads to the following logarithmic bound for regret for any feasible $x^{\\star}\\in\\mathcal{X}^{\\star}$ \u2236 ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Regret}_{t}(x^{\\star})\\leq\\frac{G^{2}}{\\alpha}(1+\\ln(t)).~~~\\mathbf{\\!{\\!\\!{s}}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "A sharper CCV bound under the non-negative regret assumption: We now establish an improved CCV bound when the worst-case regret is non-negative on some round $t\\ \\geq\\ 1$ . Let $\\operatorname*{sup}_{x^{\\star}\\in\\mathcal{X}^{\\star}}\\mathrm{Regret}_{t}(x^{\\star})\\geq0$ for some round $t\\geq1$ . Letting V = 8G l\u03b1n(T e)as above, from Eq. (29) we ", "page_idx": 17}, {"type": "equation", "text": "$$\nQ^{2}(t)\\leq{\\frac{2V G^{2}}{\\alpha}}(1+\\ln(t))\\implies Q(t)=O{\\bigl(}{\\frac{\\ln T}{\\alpha}}{\\bigr)},t\\in[T].=\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Comment: From the above proof, it immediately follows that the same conclusion holds even under the weaker assumption of $\\begin{array}{r}{-\\mathrm{Regret}_{T}=O\\big(\\frac{\\log\\dot{T}}{\\alpha}\\big)}\\end{array}$ . ", "page_idx": 17}, {"type": "text", "text": "A.7 Adversaries Ensuring Non-negative Regret ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Convex adversary: An adversary is called convex if for any sequence of action sequence $\\{x_{t}\\}_{t=1}^{T}$ , the adversary chooses the cost function sequence $\\{f_{t}\\}_{t=1}^{T}$ such that for any $T\\geq1$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}f_{t}(x_{t})\\geq\\sum_{t=1}^{T}f_{t}(\\bar{x}_{T}),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\begin{array}{r}{\\bar{x}_{T}\\equiv\\frac{1}{T}\\sum_{t=1}^{T}x_{t}}\\end{array}$ . Hence, by definition, a convex adversary guarantees a non-negative regret with respect to the average action $\\bar{x}_{T}$ for all rounds. In the following, we give two examples of convex adversaries. ", "page_idx": 17}, {"type": "text", "text": "1. Fixed adversary: An adversary which always selects a fixed convex function $f$ on all rounds is a convex adversary. In this case, Eqn. (30) holds due to the Jensen\u2019s inequality. ", "page_idx": 17}, {"type": "text", "text": "2. Minimax adversary: Let $\\mathcal{F}$ denote an arbitrary non-empty set of convex functions defined on the admissible set $\\mathcal{X}$ . Consider an adversary $\\mathcal{M}$ , which, upon seeing the selected action $x_{t}$ , chooses the worst cost function $f_{t}$ from the set $\\mathcal{F}$ on round $t$ \u2236 ", "page_idx": 17}, {"type": "equation", "text": "$$\nf_{t}\\in\\arg\\operatorname*{max}_{f\\in\\mathcal{F}}f(x_{t}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We now show that $\\mathcal{M}$ is a convex adversary. By definition, for any round $\\tau\\in[T]$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nf_{\\tau}(x_{\\tau})\\geq f_{t}(x_{\\tau})\\implies f_{\\tau}(x_{\\tau})\\geq\\frac{1}{T}\\sum_{t=1}^{T}f_{t}(x_{\\tau}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Summing up the above inequalities for each $\\tau\\in[T]$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{\\tau=1}^{T}f_{\\tau}(x_{\\tau})\\geq\\sum_{t=1}^{T}\\frac{1}{T}\\sum_{\\tau=1}^{T}f_{t}(x_{\\tau})\\overset{(\\mathrm{a})}{\\geq}\\sum_{t=1}^{T}f_{t}(\\bar{x}_{T}),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where inequality (a) follows upon applying Jensen\u2019s inequality to each cost function. Eqn. (31) shows that $\\mathcal{M}$ is a convex adversary. ", "page_idx": 17}, {"type": "text", "text": "P.S. It can be easily seen that Fixed adversary is a special case of Minimax adversary where $\\mathcal{F}=\\{f\\}$ . ", "page_idx": 17}, {"type": "text", "text": "A.8 Connection Between OCS and the Convex Body Chasing Problem ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "A well-studied problem related to the OCS problem is the nested convex body chasing (NCBC) problem [Bansal et al., 2018, Argue et al., 2019, Bubeck et al., 2020], where at each round $t$ , a convex set $\\chi_{t}\\subseteq\\chi$ is revealed such that $\\chi_{t}\\subseteq\\chi_{t-1}$ , where $\\chi_{0}\\,=\\,\\chi\\,\\subseteq\\,\\mathbb{R}^{d}$ is a convex, compact, and bounded set. The objective is to choose $x_{t}\\in\\chi_{t}$ so as to minimize the total movement cost across rounds $\\begin{array}{r}{C=\\sum_{t=1}^{T}\\|x_{t}-x_{t-1}\\|_{2}}\\end{array}$ , where $x_{0}\\in\\chi$ is some fixed action. In NCBC, action $x_{t}$ is chosen after the set $\\chi_{t}$ is revealed. This is in contrast to the OCS problem, where $x_{t}$ must be chosen before the constraints $g_{t,i}$ \u2019s are revealed at round $t$ . Moreover, note that the nested condition $\\chi_{t}\\subseteq\\chi_{t-1}$ is stricter than Assumption 3, which is applicable to the OCS problem. However, as we show next, a feasible algorithm for NCBC also provides an upper bound on the CCV of the OCS problem under Assumption 3. ", "page_idx": 18}, {"type": "text", "text": "In this reduction, we define $\\chi_{t}$ as the intersection of the first $k t$ convex constraints $g_{\\tau,i}\\,\\leq\\,0,1\\,\\leq$ $\\tau\\leq t,i\\in[k]$ , revealed up to round $t$ for the OCS problem. It is easy to see that $\\chi_{t}$ is convex and $\\chi_{t}\\subseteq\\chi_{t-1}$ , $\\forall t$ . Let $x_{t}$ be the action chosen by an algorithm $\\boldsymbol{\\mathcal{A}}$ for the NCBC problem after the set $\\chi_{t}$ is revealed. Note that $\\chi_{t}\\neq\\emptyset$ , thanks to Assumption 3. We now choose $y_{t}:=x_{t-1}$ as the action for the OCS problem on round $t$ , ensuring that action $y_{t}$ is chosen before the set $\\chi_{t}$ is revealed. The resulting $i^{t h}$ constraint violation for the OCS problem at round $t$ is given by ", "page_idx": 18}, {"type": "equation", "text": "$$\ng_{t,i}\\bigl(y_{t}\\bigr)\\stackrel{(a)}{\\leq}g_{t,i}\\bigl(y_{t}\\bigr)-g_{t,i}\\bigl(y_{t+1}\\bigr)\\leq G\\bigl|\\bigl|y_{t}-y_{t+1}\\bigr|\\bigr|,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $(a)$ follows from the feasibility of $\\boldsymbol{\\mathcal{A}}$ for NCBC, $y_{t+1}\\,=\\,x_{t}\\,\\in\\,\\chi_{t}$ and hence $g_{t,i}(y_{t+1})\\,\\leq\\,0$ . Summing across rounds $t=1,\\dots,T$ , and taking the max over all the $k$ constraints, we get that the CCV using $\\boldsymbol{\\mathcal{A}}$ for the OCS is upper bounded by $\\begin{array}{r}{\\sum_{t=2}^{T}G\\|y_{t}-y_{t+1}\\|\\leq\\sum_{t=2}^{T}G\\|x_{t-1}-x_{t}\\|\\leq G\\cdot C_{A}}\\end{array}$ , where $C_{A}$ is the movement cost of $\\boldsymbol{\\mathcal{A}}$ for the NCBC problem. ", "page_idx": 18}, {"type": "text", "text": "From prior work Bansal et al. [2018], Argue et al. [2019], Bubeck et al. [2020], it is known that for NC\u221aBC, a Steiner point-based algorithm that chooses $x_{t}$ as the Steiner point of $\\chi_{t}$ can achieve $C_{\\cal A}=$ $O({\\sqrt{d\\log d}})$ , where $\\chi\\subset\\mathbb{R}^{d}$ . Thus, the Steiner point-based algorithm (even though computationally intensive) provides an $O({\\sqrt{d\\log d}})$ constraint violation for the OCS as well. However, this result is effective for problems where ${\\sqrt{d\\log d}}=o(T)$ . Our result efficiently overcomes this hurdle and provides a bound under weaker feasibility assumptions even beyond ${\\sqrt{d\\log d}}=o(T)-{\\mathrm{a}}$ setting that is better motivated in practice for modern deep learning applications which are characteristically high-dimensional. ", "page_idx": 18}, {"type": "text", "text": "A.9 Proof of Theorem 4 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Generalized regret decomposition: Fix any $S$ -feasible benchmark $x^{\\star}\\in\\mathcal{X}_{S}$ , as given by Eqn. (16). Then, from Eqn. (20), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l l l}{\\Phi(\\tau)-\\Phi(\\tau-1)}&{\\le}&{2\\displaystyle\\sum_{i=1}^{k}Q_{i}(\\tau)g_{\\tau,i}(x_{\\tau})}\\\\ &{=}&{2\\displaystyle\\sum_{i=1}^{k}Q_{i}(\\tau)\\big(g_{\\tau,i}(x_{\\tau})-g_{\\tau,i}(x^{\\star})\\big)+2\\displaystyle\\sum_{i=1}^{k}Q_{i}(\\tau)g_{\\tau,i}(x^{\\star})}\\\\ &{=}&{\\displaystyle\\hat{f}_{\\tau}(x_{\\tau})-\\hat{f}_{\\tau}(x^{\\star})+2\\displaystyle\\sum_{i=1}^{k}Q_{i}(\\tau)g_{\\tau,i}(x^{\\star}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Summing up the above inequalities from $\\tau=1$ to $\\tau=t$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}Q_{i}^{2}(t)=\\Phi(t)\\leq\\mathrm{Regret}_{t}^{\\prime}(x^{\\star})+2\\sum_{i=1}^{k}\\sum_{\\tau=1}^{t}Q_{i}(\\tau)g_{\\tau,i}(x^{\\star}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where Regret $\\left(\\cdot\\right)$ refers to the regret of the surrogate costs as before. We now bound the last term by imntaekrivnagl $[1,t]$ fi tnthoe $S$ -sfjeoiansit bailnidt yc oofn stehce uaticvtieo sn $x^{\\star}$ inatse rgvivalesn $\\{\\mathcal{T}_{j}\\}_{j=1}^{\\lceil t/S\\rceil}$ (, 1e6a)c. hL oeft  luesn ngtohw $S$ i(veixdcee tpht et heen ltiarset interval which could be of a smaller length). Let $Q_{i}^{\\star}(j)$ be the value of the variable beginning of the $j^{\\mathrm{th}}$ interval. We have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{\\tau=1}^{t}Q_{i}(\\tau)g_{\\tau,i}(x^{\\star})=\\sum_{j=1}^{\\lceil t/S\\rceil}\\sum_{\\tau\\in\\mathbb{Z}_{j}}\\big(Q_{i}(\\tau)-Q_{i}^{\\star}(j)\\big)g_{\\tau,i}(x^{\\star})+\\sum_{j=1}^{\\lceil t/S\\rceil}Q_{i}^{\\star}(j)\\sum_{\\tau\\in\\mathbb{Z}_{j}}g_{\\tau,i}(x^{\\star}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Using the boundedness assumption, let $g_{t,i}(x)\\leq F,\\forall x\\in\\mathcal{X},t,i$ . Using the Lipschitzness property of the queueing dynamics (17) with respect to time, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\tau\\in\\mathcal{Z}_{j}}\\bigl|Q_{i}(\\tau)-Q_{i}^{\\star}(j)\\bigr|\\leq F\\bigl(S-1\\bigr).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Substituting the above bound into Eqn. (33), we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{\\tau=1}^{t}Q_{i}(\\tau)g_{\\tau,i}(x^{\\star})\\leq\\big(1+\\frac{t}{S}\\big)F^{2}S(S-1)+F(S-1)\\big(Q_{i}(t)+F(S-1)\\big),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where in the last term, we have used the $S$ -feasibility of the action $x^{\\star}$ in all intervals, except possibly the last interval. Substituting the bound (34) into Eqn. (32), we arrive at the following extended regret decomposition inequality: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\displaystyle\\sum_{i=1}^{k}Q_{i}^{2}(t)}&{\\le}&{\\mathrm{Regret}_{t}^{\\prime}(x^{\\star})+2k F^{2}S t+2F S\\displaystyle\\sum_{i=1}^{k}Q_{i}(t)+4F^{2}S^{2}k.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Eqn. (35) leads to the following bound on the cumulative constraint violation. ", "page_idx": 19}, {"type": "text", "text": "A.9.1 CCV Bound ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We now apply the generalized regret decomposition bound given in (35) to the case of convex constraint functions. Substituting the regret bound (24) of the AdaGrad policy into Eqn. (35), we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}Q_{i}^{2}(t)\\leq c_{1}\\sqrt{\\sum_{\\tau=1}^{t}\\Big(\\sum_{i=1}^{k}Q_{i}^{2}(\\tau)\\Big)}+c_{2}S t+c_{3}S\\sum_{i=1}^{k}Q_{i}(t)+c_{4}S^{2}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the constants $:c_{1}\\equiv O(G D\\sqrt{k}),c_{2}=O(k F^{2}),c_{3}=O(F),c_{4}=O(k F^{2})$ are problem-specific parameters that depend on the bounds on the gradients and the maximum value of the constraint functions, the number of constraints, and the diameter of the admissible set. Defining $Q^{2}(t)\\,\\equiv\\,$ $\\sum_{i}Q_{i}^{2}(t)$ , we obtain: ", "page_idx": 19}, {"type": "equation", "text": "$$\nQ^{2}(t)\\leq c_{1}\\sqrt{\\sum_{\\tau=1}^{t}Q^{2}(\\tau)}+c_{2}S t+c_{3}S\\sum_{i=1}^{k}Q_{i}(t)+c_{4}S^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since $Q_{i}(t)\\leq F t,\\forall i$ , the above inequality can be simplified to ", "page_idx": 19}, {"type": "equation", "text": "$$\nQ^{2}(t)\\leq c_{1}\\sqrt{\\sum_{\\tau=1}^{t}Q^{2}(\\tau)}+c_{2}^{\\prime}S t+c_{4}S^{2},~\\forall t\\geq1,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where we have defined $c_{2}^{\\prime}\\equiv c_{3}k F+c_{2}$ . To solve the above system of inequalities, note that for each $1\\leq\\tau\\leq t$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nQ^{2}(\\tau)\\leq c_{1}\\sqrt{\\sum_{\\tau=1}^{t}Q^{2}(\\tau)}+c_{2}^{\\prime}S t+c_{4}S^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Summing up the above inequalities for $1\\leq\\tau\\leq t$ and defining $Z_{t}\\equiv\\sqrt{\\sum_{\\tau=1}^{t}Q^{2}(\\tau)}$ , we obtain ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{Z_{t}^{2}}&{\\le}&{c_{1}t Z_{t}+c_{2}^{\\prime}S t^{2}+c_{4}S^{2}t}\\\\ {i.e.,\\,Z_{t}^{2}}&{\\le}&{3\\operatorname*{max}\\bigl(c_{1}t Z_{t},c_{2}^{\\prime}S t^{2},c_{4}S^{2}t\\bigr)}\\\\ {i.e.,\\,Z_{t}}&{=}&{O\\bigl(\\operatorname*{max}\\bigl(t,t\\sqrt{S},S\\sqrt{t}\\bigr)\\bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Substituting the above bound for $Z(t)$ in Eqn. (36), we have for any $t\\geq1$ : ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{Q^{2}(t)}&{=}&{O(\\operatorname*{max}(Z_{t},S t,S^{2}))}\\\\ {i.e.,\\,Q(t)}&{=}&{O(\\operatorname*{max}(\\sqrt{Z_{t}},\\sqrt{S t},S))}\\\\ {\\mathrm{Hence},\\,\\,Q_{i}(t)\\leq Q(t)}&{=}&{O(\\operatorname*{max}(\\sqrt{t},\\sqrt{t}S^{1/4},\\sqrt{S}t^{1/4},\\sqrt{S t},S))}\\\\ &{=}&{O(\\operatorname*{max}(\\sqrt{S t},S)),\\,\\,\\forall i\\in[k].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The final result follows upon appealing to Eqn. (18). ", "page_idx": 19}, {"type": "text", "text": "A.10 Proof of Theorem 5 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "We will use a similar line of arguments used in the analysis of an $S$ -constrained adversary for a suitable value of $S$ to be determined later. We start from Eqn. (33), which holds for any value of the sub-interval length $S\\geq1$ and any arbitrary adversary. Furthermore, from the definition of a $P_{T}$ -constrained adversary, we know that there exists a benchmark $x^{\\star}\\in\\mathcal{X}$ such that for any interval $\\mathcal{T}_{j}$ and any $i\\in[k]$ , we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{\\tau\\in\\mathcal{T}_{j}}g_{\\tau,i}\\big(x^{\\star}\\big)\\leq P_{T}F,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $F$ is the maximum absolute value of the constraint functions as given in Definition 1. Hence, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{\\displaystyle\\sum_{j=1}^{[t/S]}Q_{i}^{\\star}(j)\\sum_{\\tau\\in\\cal Z_{j}}g_{\\tau,i}(x^{\\star})}&{\\le}&{\\displaystyle P_{T}F\\sum_{j=1}^{[t/S]}Q_{i}^{\\star}(j)}\\\\ &{\\le}&{\\displaystyle\\frac{P_{T}F}{S}\\sum_{j=1}^{[t/S]}\\sum_{\\tau\\in\\cal Z_{j}}\\left(Q_{i}^{\\star}(j)-Q_{i}(\\tau)\\right)+\\frac{P_{T}F}{S}\\sum_{\\tau=1}^{t}Q_{i}(\\tau).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Hence, from Eqn. (33), we have that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{\\displaystyle\\sum_{\\tau=1}^{t}Q_{i}(\\tau)g_{\\tau,i}(x^{\\star})}&{\\displaystyle\\leq}&{\\displaystyle\\big(1+\\frac{t}{S}\\big)F^{2}S(S-1)+\\big(1+\\frac{t}{S}\\big)P_{T}F^{2}\\big(S-1\\big)+\\frac{P_{T}F}{S}\\displaystyle\\sum_{\\tau=1}^{t}Q_{i}(\\tau)}\\\\ &{\\displaystyle\\leq}&{F^{2}\\big(S+P_{T}\\big)\\big(S+t\\big)+\\frac{P_{T}F}{S}\\displaystyle\\sum_{\\tau=1}^{t}Q_{i}(\\tau).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Substituting the above bound into Eqn. (32), we have that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}Q_{i}^{2}(t)\\leq\\mathrm{Regret}_{t}^{\\prime}(x^{\\star})+2k F^{2}(S+P_{T})(S+t)+\\frac{2P_{T}F}{S}\\sum_{\\tau=1}^{t}\\sum_{i=1}^{k}Q_{i}(\\tau).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Plugging in the regret bound of the AdaGrad policy for the surrogate cost functions, the above equation yields ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}Q_{i}^{2}(t)\\leq G D\\sqrt{2k}\\sqrt{\\sum_{\\tau=1}^{t}\\Big(\\sum_{i=1}^{k}Q_{i}^{2}(\\tau)\\Big)}+2k F^{2}\\big(S+P_{T}\\big)\\big(S+t\\big)+\\frac{2P_{T}F}{S}\\sum_{\\tau=1}^{t}\\sum_{i=1}^{k}Q_{i}\\big(\\tau\\big).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Using Cauchy-Schwarz inequality, the last term of the above inequality can be upper bounded by ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{2P_{T}F\\sqrt{k t}}{S}\\sqrt{\\sum_{\\tau=1}^{t}\\big(\\sum_{i=1}^{k}Q_{i}^{2}(\\tau)\\big)}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Hence, we have the following inequality which holds for any $1\\leq S\\leq t$ and $1\\leq\\tau\\leq t$ \u2236 ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}Q_{i}^{2}(\\tau)\\leq\\left(G D\\sqrt{2k}+\\frac{2P_{T}F\\sqrt{k t}}{S}\\right)\\sqrt{\\sum_{\\tau=1}^{t}\\left(\\sum_{i=1}^{k}Q_{i}^{2}(\\tau)\\right)}+2k F^{2}(S+P_{T})(S+t).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Summing up the above inequalities for $1\\leq\\tau\\leq t$ and defining $\\begin{array}{r}{Z_{t}^{2}\\equiv\\sum_{\\tau=1}^{t}\\sum_{i=1}^{k}Q_{i}^{2}(\\tau)}\\end{array}$ , we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{Z_{t}^{2}}&{\\leq}&{\\Bigg(G D\\sqrt{2k}+\\displaystyle\\frac{2P_{T}F\\sqrt{k t}}{S}\\Bigg)t Z_{t}+2k F^{2}t\\big(S+P_{T}\\big)\\big(S+t\\big)}\\\\ &{\\leq}&{2\\operatorname*{max}\\Bigg(\\big(G D\\sqrt{2k}+\\displaystyle\\frac{2P_{T}F\\sqrt{k t}}{S}\\big)t Z_{t},2k F^{2}t\\big(S+P_{T}\\big)\\big(S+t\\big)\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The above inequality implies that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{Z_{t}}&{\\le}&{2\\operatorname*{max}\\Bigg(\\big(G D\\sqrt{2k}+\\displaystyle\\frac{2P_{T}F\\sqrt{k t}}{S}\\big)t,F\\sqrt{k t\\big(S+P_{T}\\big)\\big(S+t\\big)}\\Bigg)}\\\\ &{\\le}&{2\\operatorname*{max}\\Bigg(\\big(G D\\sqrt{2k}+\\displaystyle\\frac{2P_{T}F\\sqrt{k T}}{S}\\big)T,F T\\sqrt{2k\\big(S+P_{T}\\big)}\\Bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where in the last step, we have used the fact that $t\\leq T$ and $S\\le T$ . Now, let us choose $S\\equiv P_{T}^{2/3}T^{1/3}$ . With the above choice of $S$ , from the above inequality, we have the following bound for $Z_{t}$ \u2236 ", "page_idx": 21}, {"type": "equation", "text": "$$\nZ_{t}\\le2\\operatorname*{max}\\left(\\big(G D\\sqrt{2k}+2F\\sqrt{k}P_{T}^{1/3}T^{1/6}\\big)T,2F\\sqrt{k}P_{T}^{1/3}T^{7/6}\\right)=O\\big(P_{T}^{1/3}T^{7/6}\\big)+O(T),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where we have used the fact that $P_{T}\\leq T$ . Substituting the above bound in (38), we have for any $1\\leq i\\leq k$ and any $t\\leq T$ \u2236 ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}Q_{i}^{2}(t)\\stackrel{(a)}{=}O(P_{T}^{2/3}T^{4/3})+O(T)+O(P_{T}^{2/3}T^{4/3})=O(P_{T}^{2/3}T^{4/3})+O(T),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where in (a), we have used the fact that $T\\geq S\\geq P_{T}$ in bounding the last term. Hence, we have the following upper bound on the queue lengths for any $1\\leq t\\leq T$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\|Q(t)\\|_{\\infty}\\leq\\|Q(t)\\|_{2}=O(P_{T}^{1/3}T^{2/3})+O(\\sqrt{T}).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The final result follows upon appealing to the relation (18). ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We give complete proofs of all claims made in the paper (either in the main paper or in the Appendix). ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We clearly state the assumptions under which our results hold. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We clearly state the assumptions in the main paper and give complete proofs of all claims (either in the main paper or in the Appendix) ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We have publicly released the code so that it can be used to reproduce the main experimental results reported in this paper. Link to the codebase, which includes detailed instructions on how to run the code, has been included in the paper. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We have publicly released the code with clear instructions on how to replicate the experimental results. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Sufficient details have been provided in the paper. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [No] ", "page_idx": 24}, {"type": "text", "text": "Justification: Since the paper deals with worst-case guarantees against adversarial inputs, statistical guarantees are superfluous. Choice of random seeds used in the experiments have been clearly specified in the code. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 24}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Compute details have been mentioned in the paper. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: This work conforms with the NeurIPS Code of Ethics in every respect. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is a foundational work on online learning and does not have a direct societal impact. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 25}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This theoretical paper does not pose any such risks. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The public dataset used in the experiments has been appropriately cited. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The code we have released is well documented. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}]