[{"figure_path": "N12B6wvA55/figures/figures_8_1.jpg", "caption": "Figure 1: (Left) Value of W along the flow for two difference interaction Bregman potentials, (Middle and Right) Trajectories of particles to minimize W.", "description": "This figure presents the results of minimizing the Wasserstein distance between two probability distributions using mirror descent with different interaction Bregman potentials. The left panel shows the value of the Wasserstein distance (W) over time (number of iterations) for two different potentials.  The middle and right panels display the trajectories of particles during the optimization process for the two potentials, visualizing how the particles move to minimize W.  The results highlight the different dynamics of the optimization depending on the choice of potential.", "section": "Applications and Experiments"}, {"figure_path": "N12B6wvA55/figures/figures_9_1.jpg", "caption": "Figure 3: Preconditioned GD vs. (vanilla) GD to predict the responses of cell populations to cancer treatment on 4i (Upper row) and scRNAseq (Lower row) datasets. For each treatment, starting from the untreated cells \u03bc\u2081, we minimize F(\u03bc) = D(\u03bc, vi) with vi the treated cells. The plot is organized as pairs of columns, each corresponding to optimizing a specific metric, with two scatter plots displaying points zi = (xi, Yi) where (First column) yi is the attained minima F(\u00fb) = D(\u03bc, \u03bd\u2081) with preconditioning and xi that without preconditioning, and (Second column) yi is the number of iterations to reach convergence with preconditioning and xi that without preconditioning. A point below the diagonal y = x then refers to an experiment in which preconditioning provides (First column) a better minima or (Second column) faster convergence. We assign a color to each treatment and plot three runs, obtained with three different initializations, along with their mean (brighter point).", "description": "This figure compares the performance of preconditioned gradient descent (PrecGD) and vanilla gradient descent (GD) in predicting cellular responses to cancer treatments using two different datasets (4i and scRNAseq).  For each treatment, the algorithms minimize a distance function (D) between the untreated (\u03bc\u2081) and treated (vi) cell populations. The figure presents scatter plots showing the minimum attained by each method (y-axis) against the number of iterations to convergence (x-axis). The plots are separated by datasets and metrics.  Points below the diagonal indicate superior performance of PrecGD, showcasing its improvement in finding better minima and converging faster.", "section": "Applications and Experiments"}, {"figure_path": "N12B6wvA55/figures/figures_39_1.jpg", "caption": "Figure 1: (Left) Value of W along the flow for two difference interaction Bregman potentials, (Middle and Right) Trajectories of particles to minimize W.", "description": "This figure shows the results of minimizing the Wasserstein distance between two probability distributions using mirror descent with two different interaction Bregman potentials. The left panel shows the evolution of the Wasserstein distance (W) over time for the two potentials. The middle and right panels show the trajectories of particles during the optimization process for each potential. The trajectories illustrate how the particles move to minimize the Wasserstein distance between the two distributions.  The different potentials lead to different optimization paths and convergence rates.", "section": "Applications and Experiments"}, {"figure_path": "N12B6wvA55/figures/figures_39_2.jpg", "caption": "Figure 2: Convergence towards Gaussians N(0, UDUT) averaged over 20 covariances, with U ~ Unif(O10(R)) and D fixed.", "description": "This figure shows the convergence of different optimization methods towards a Gaussian distribution.  The x-axis represents time (in iterations), and the y-axis shows the Kullback-Leibler (KL) divergence between the current distribution and the target Gaussian distribution.  Multiple methods (NEM, PFB, FB, PKLM, KLM) are compared, illustrating their relative convergence speeds. The target Gaussian distributions are generated with varying covariances to test the robustness of the methods.", "section": "Applications and Experiments"}, {"figure_path": "N12B6wvA55/figures/figures_40_1.jpg", "caption": "Figure 1: (Left) Value of W along the flow for two difference interaction Bregman potentials, (Middle and Right) Trajectories of particles to minimize W.", "description": "This figure shows the results of minimizing the Wasserstein distance between two probability distributions using different interaction Bregman potentials. The left panel displays the value of the Wasserstein distance (W) over time, demonstrating the convergence of the optimization process. The middle and right panels visualize the trajectories of particles during the optimization, illustrating how the particles move to minimize the Wasserstein distance.  Different colors represent different Bregman potentials, showing the impact of the choice of potential on the optimization process.", "section": "5 Applications and Experiments"}, {"figure_path": "N12B6wvA55/figures/figures_41_1.jpg", "caption": "Figure 7: Preconditioned GD and (vanilla) GD vs. the entropic map Te [101] to predict the responses of cell populations to cancer treatments on 4i and scRNAseq datasets, providing respectively 34 and 9 treatment responses. For each profiling technology and each treatment, we have a pair (\u00b5i, vi) of source (untreated) cells and target (treated) cells. For each pair (\u00b5i, vi), with both preconditioned GD and vanilla GD, we minimize the functional F(\u03bc) = D(\u03bc, \u03bdi) with D a metric to recover the effect of the perturbation. In both cases, the prediction is obtained by \u03bc^i = min\u03bc F(\u03bc). We then fit an entropic map Te and predict Te\u03bci. We then compare the objective function values F(\u03bc^i) and F(Te\u03bci). A point below the diagonal y = x then refers to an experiment in which (preconditioned) WGD provides a better estimate of the perturbed population.", "description": "This figure compares the performance of preconditioned gradient descent (PrecGD) and vanilla gradient descent (GD) against the entropic map (Te) in predicting cell population responses to cancer treatments. Two datasets, 4i and scRNAseq, are used, each with multiple treatments. For each treatment, the methods aim to minimize a distance function D(\u03bc, \u03bd) between the untreated (\u03bci) and treated (\u03bdi) cell distributions. Lower values indicate better predictions. PrecGD consistently outperforms GD and Te across both datasets and different distance metrics. This highlights the effectiveness of PrecGD in this biological application.", "section": "Applications and Experiments"}, {"figure_path": "N12B6wvA55/figures/figures_43_1.jpg", "caption": "Figure 8: (Left) Samples from a Dirichlet posterior distribution for Mirror Descent (MD) and Mirror Langevin (MLD). (Right) Evolution of the objective averaged over 20 different initialisations.", "description": "This figure shows the results of sampling from a Dirichlet distribution using two different methods: Mirror Descent (MD) and Mirror Langevin (MLD).  The left panel displays the initial particle distribution (blue), the final particle distribution after MD (red), and the final particle distribution after MLD (red). The right panel shows the evolution of the objective function (KL divergence) over 200 iterations for both methods. MLD shows better convergence towards the true distribution than MD.", "section": "G.5 Mirror descent on the simplex"}]