[{"figure_path": "p43ObIwJFW/tables/tables_6_1.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of the proposed VCM model against various state-of-the-art methods and traditional solvers on benchmark instances (B2500) and very large instances (P3000-P7000). The comparison is based on two key metrics: the optimality gap (GAP) and the average running time (ART).  The table allows readers to easily assess VCM's efficiency and solution quality compared to existing techniques. The results show that VCM outperforms its competitors in terms of both solution quality and computational speed, achieving near-optimal results in milliseconds even for very large problem instances.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_17_1.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of the proposed Value Classification Model (VCM) against various state-of-the-art algorithms on benchmark instances (B2500) and well-known instances (P3000, P4000, P5000, P6000, P7000). The comparison is based on two key metrics: the optimality gap (GAP) and the average running time (ART). The results showcase VCM's superior performance in terms of both solution quality and computational efficiency across different instance sizes.  It highlights VCM's remarkable generalization ability, achieving near-optimal solutions within milliseconds even on very large instances.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_18_1.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of different algorithms on benchmark datasets (B) and well-known instances (P).  The algorithms include various heuristic methods, learning-based sequential decision models, and the proposed VCM model. For each algorithm, the table reports the average optimality gap (percentage difference from the optimal solution) and average runtime (in milliseconds). The results show that the VCM model significantly outperforms other methods in terms of both solution quality and computational efficiency. Notably, the VCM model trained on smaller instances exhibits remarkable generalization ability when applied to larger instances.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_18_2.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of various algorithms, including the proposed VCM and several baselines (e.g., Gurobi, DRLH, PI-GNN) on benchmark datasets (B) and large-scale instances (P). It shows the optimality gap (%) and average running time (ms) achieved by each method, highlighting the superior performance of the VCM in terms of both solution quality and computational efficiency.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_21_1.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of various algorithms (DIAG, SR, VCM variants, BGF, DRLH-B, S2V-DQN-B, ECO-DQN-B, PI-GNN variants, Gurobi with 1-second and 1-hour time limits, VCM-BGF-HB) on benchmark datasets (B2500(10)) and well-known instances (P3000(5), P4000(5), P5000(5), P6000(3), P7000(3)).  The comparison metrics are the optimality gap (%) and the average running time in milliseconds (ms). It showcases the superior performance of the proposed VCM in terms of both solution quality and computational efficiency.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_21_2.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of various algorithms (DIAG, SR, VCM variations, BGF, DRLH-B, S2V-DQN-B, ECO-DQN-B, PI-GNN variations, Gurobi) on benchmark datasets (B2500(10)) and large-scale, well-known instances (P sets).  The comparison is done using the OFV gap (%) (difference from the optimal OFV) and average running time (ART in milliseconds).  The results demonstrate the superior performance of the proposed VCM in terms of both solution quality and efficiency.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_22_1.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the results of the proposed Value Classification Model (VCM) and other methods on benchmark and well-known instances.  For each dataset, it shows the average optimality gap (GAP) and the average running time (ART). It allows to compare VCM against a range of baselines including exact methods (Gurobi), heuristic methods (Diag, SR, BGF), learning-based sequential decision methods (DRLH-B, S2V-DQN-B, ECO-DQN-B), and a physics-inspired neural solver (PI-GNN).  The results highlight VCM's superior performance in terms of both solution quality and speed.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_22_2.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of various algorithms on benchmark instances (B) and well-known instances (P) of different sizes.  The algorithms are compared based on the average optimality gap (percentage deviation from the optimal solution) and the average running time (in milliseconds).  The table shows the performance of various heuristic methods, learning-based methods (including the proposed VCM and its variants), and an exact solver (Gurobi). The results highlight the VCM's superior performance in terms of both solution quality and computational efficiency, especially for larger instances.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_22_3.jpg", "caption": "Table 9: Results of DVN depths on benchmarks B2500(10).", "description": "This table presents the results of the DVN depth experiment. It shows the average gap and average running time (ART) on benchmarks B2500(10) for various testing depths (10, 20, 30, 40, 50, 100, 200, and 300) and training depths (10, 20, 30, 40, 50, and 100). The results demonstrate the impact of increasing testing and training depths on the model's performance.", "section": "J Results of DVN depths"}, {"figure_path": "p43ObIwJFW/tables/tables_23_1.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of various algorithms (including the proposed VCM and its variants, baseline methods, and state-of-the-art learning-based approaches) on benchmark and well-known QUBO instances.  The metrics used for evaluation are the optimality gap (percentage deviation from the optimal solution) and the average running time (in milliseconds). The table showcases the superior performance of the VCM in terms of both solution quality and computational efficiency across different problem sizes.", "section": "4.2 Experimental Results"}, {"figure_path": "p43ObIwJFW/tables/tables_24_1.jpg", "caption": "Table 1: Results on benchmarks and large well-known instances.", "description": "This table presents the performance comparison of different algorithms on benchmark datasets (B) and well-known instances (P). The results are compared in terms of the optimality gap (percentage difference from the optimal solution) and the average running time (in milliseconds).  The algorithms compared include various heuristic methods, learning-based sequential decision models and the proposed VCM at different training depths.  The optimal solution values are provided as a baseline for comparison.", "section": "4.2 Experimental Results"}]