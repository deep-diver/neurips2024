{"references": [{"fullname_first_author": "Kenneth Arrow", "paper_title": "Social Choice and Individual Values", "publication_date": "1951-01-01", "reason": "This foundational work in social choice theory provides the axiomatic framework used to evaluate AI reward function aggregation methods in the paper."}, {"fullname_first_author": "Felix Brandt", "paper_title": "Handbook of Computational Social Choice", "publication_date": "2016-01-01", "reason": "This handbook provides a comprehensive overview of social choice theory, serving as a key resource for the theoretical underpinnings of the paper's axiomatic analysis."}, {"fullname_first_author": "Ralph Allan Bradley", "paper_title": "Rank analysis of incomplete block designs: I. the method of paired comparisons", "publication_date": "1952-01-01", "reason": "This paper introduces the Bradley-Terry-Luce model, a central method for reward function learning in RLHF, which the paper analyzes and critiques."}, {"fullname_first_author": "Paul F Christiano", "paper_title": "Deep reinforcement learning from human preferences", "publication_date": "2017-01-01", "reason": "This influential paper introduces a key RLHF technique that the current paper builds upon and improves through the lens of social choice theory."}, {"fullname_first_author": "Long Ouyang", "paper_title": "Training language models to follow instructions with human feedback", "publication_date": "2022-01-01", "reason": "This paper highlights a recent and significant application of RLHF to large language models, providing context for the paper's focus on improving RLHF methods."}]}