[{"figure_path": "3LKuC8rbyV/tables/tables_25_1.jpg", "caption": "Table 1: The constants for the loss function and other calculation on MNIST and CIFAR-10.", "description": "This table lists the values of hyperparameters used in the experiments, including the smoothness constant (L), strongly convex constant (m), Lipschitz constant (M), RDP constant (\u03b4), and the lower bound of the LSI constant (CLSI).  These constants are calculated for the MNIST, CIFAR10-binary, and CIFAR10-multi-class datasets.", "section": "4 Experiments"}, {"figure_path": "3LKuC8rbyV/tables/tables_26_1.jpg", "caption": "Table 1: The constants for the loss function and other calculation on MNIST and CIFAR-10.", "description": "This table lists the values of hyperparameters and constants used in the experiments for MNIST and CIFAR-10 datasets.  It includes the smoothness constant (L), strong convexity constant (m), Lipschitz constant (M), RDP constant (\u03b4), and Log-Sobolev Inequality (LSI) constant (CLSI).  These values are essential for the theoretical analysis and practical implementation of the Langevin Unlearning algorithm, and are dataset-specific.", "section": "4 Experiments"}, {"figure_path": "3LKuC8rbyV/tables/tables_26_2.jpg", "caption": "Table 1: The constants for the loss function and other calculation on MNIST and CIFAR-10.", "description": "This table presents the values of hyperparameters and constants used in the experiments.  These include the smoothness constant (L), strong convexity constant (m), Lipschitz constant (M), RDP constant (\u03b4), and log-Sobolev inequality constant (CLSI) for both the MNIST and CIFAR-10 datasets.  The gradient clipping values (M) are also shown. This information is crucial for understanding and reproducing the experimental results.", "section": "4 Experiments"}, {"figure_path": "3LKuC8rbyV/tables/tables_27_1.jpg", "caption": "Table 1: The constants for the loss function and other calculation on MNIST and CIFAR-10.", "description": "This table presents the values of hyperparameters and constants used in the experiments.  These values are crucial for configuring and understanding the results of the logistic regression models on the MNIST and CIFAR-10 datasets.  The table includes smoothness constant (L), strong convexity constant (m), Lipschitz constant (M), RDP constant (\u03b4), and log-Sobolev inequality constant (CLSI).", "section": "Experiments"}, {"figure_path": "3LKuC8rbyV/tables/tables_27_2.jpg", "caption": "Table 2: Baseline \u03c3 details in Fig. 3a", "description": "This table shows the noise standard deviation (\u03c3) values used for the Delete-to-Descent (D2D) baseline method in Figure 3a of the paper.  Different values of \u03c3 were used for different datasets (CIFAR-10-binary, CIFAR-10-multi-class, MNIST) and different numbers of unlearning iterations (1, 2, 5). The values are presented to show how the noise parameter was adjusted for varying levels of privacy requirements.  These parameters are crucial in understanding the privacy-utility trade-offs in the experiments.", "section": "M.4 Implementation Details for Fig. 3a"}, {"figure_path": "3LKuC8rbyV/tables/tables_28_1.jpg", "caption": "Table 3: The \u03c3 found with different target \u00ea", "description": "This table presents the optimal noise standard deviation (\u03c3) values determined through a binary search for various target privacy loss parameters (\u00ea). Different values of \u00ea are tested and the corresponding \u03c3 is calculated for three datasets: CIFAR-10-binary, CIFAR-10-multi-class, and MNIST. Each dataset has a different set of \u03c3 values depending on the target \u00ea.", "section": "M.4 Implementation Details for Fig. 3a"}, {"figure_path": "3LKuC8rbyV/tables/tables_29_1.jpg", "caption": "Table 1: The constants for the loss function and other calculation on MNIST and CIFAR-10.", "description": "This table presents the values of hyperparameters and constants used in the experiments. These values are calculated based on the specific properties of the datasets used (MNIST and CIFAR-10) and the loss function used in the experiments. The table includes the smoothness constant (L), strong convexity constant (m), Lipschitz constant (M), RDP constant (\u03b4), and CLSI (logarithmic Sobolev inequality constant). These constants are crucial for the theoretical analysis and privacy guarantees provided in the paper.  The gradient clip value (M) is used to control the norm of the gradients during the training process, and the RDP constant is a parameter that determines the level of privacy provided by the algorithm.  The CLSI constant is a measure of how well the probability distribution over model parameters satisfies the log-Sobolev inequality, a crucial property for the convergence analysis.", "section": "Experiments"}]