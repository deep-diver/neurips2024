[{"figure_path": "Vxijl0IOId/tables/tables_6_1.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model (DSM) and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error (the difference between the model's approximation and the true GVF, relative to the maximum of the two), and the percentage of constraints satisfied for both training and testing sets. The results are broken down by different GVF instance families (KG and Euclidean) and sizes, highlighting the scalability and accuracy of the methods.  It demonstrates that the unsupervised DSM approach performs comparably or better than the supervised DenseNet approach in approximating the GVF, despite not requiring labeled data.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_6_2.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error (the difference between the model and the actual GVF), and the percentage of constraints satisfied (a measure of how well the model approximates the GVF) for different model sizes and instance types. The table also provides data labelling times for the DenseNet for comparison. This allows assessment of the relative computational costs involved.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_7_1.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error (a measure of approximation accuracy), and the percentage of constraints satisfied during training and testing for both models across different problem instances (KG and Euclidean). The table also includes the time taken to generate labels (data labeling time) for the supervised learning models.  This illustrates the scalability of the DSM approach and its comparison against alternative methods.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_8_1.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error, and percentage of constraints satisfied for both models on various instances of the uncapacitated facility location problem. The table also provides data labeling times for the supervised methods (DenseNet and Random Forest). The results indicate that the Dual-Stack Model can perform comparably to or better than the supervised methods, even without labeled data, demonstrating its efficiency in learning the GVF.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_9_1.jpg", "caption": "Table 2: DSM Heuristic Solver on UFL Instances.", "description": "This table compares the performance of the proposed DSM heuristic against a state-of-the-art MILP solver (SCIP) and a Benders decomposition heuristic on Uncapacitated Facility Location (UFL) instances.  For each instance size (250, 500, 750 for KG instances; 100, 200, 300 for Euclidean instances), it reports the solve time, provable gap (%), gap to MILP (%), and gap to Benders for the DSM heuristic, as well as LP relaxation solve time, MILP solve time, and solve time for the full model and Benders heuristic, respectively.  Negative values in \"Gap to MILP (%) \" indicate the DSM heuristic outperformed SCIP within the time limit.", "section": "7.2 Heuristic for Two-Stage Problems"}, {"figure_path": "Vxijl0IOId/tables/tables_19_1.jpg", "caption": "Table 3: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model and DenseNet in learning the Generalized Linear Programming Value Function (GVF). It shows the training time, true relative error, training lower bound, test lower bound, and data labeling time for both models on a specific SCFL instance (16 customers, 50 facilities).  The true relative error indicates the accuracy of the learned GVF approximation. The lower bounds reflect the percentage of constraints satisfied during training and testing.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_19_2.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model (DSM) and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error (a measure of approximation accuracy), and the percentage of constraints satisfied during training and testing for various instances of the uncapacitated facility location (UFL) problem.  The results indicate how well each model approximates the GVF, considering both training efficiency and approximation quality.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_20_1.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error (the percentage difference between the model's prediction and the true GVF), and the percentage of constraints satisfied during training for both models across different sizes of instances (KG and Euclidean). The results indicate the Dual-Stack Model's competitiveness in approximating the GVF, particularly considering that it does not use supervised training.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_20_2.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error (a measure of approximation accuracy), and the percentage of constraints satisfied for both models across different instances of the uncapacitated facility location problem (UFL). The results demonstrate the Dual-Stack Model's effectiveness and competitiveness with a supervised learning method, while highlighting its scalability.", "section": "7 Computational Results"}, {"figure_path": "Vxijl0IOId/tables/tables_20_3.jpg", "caption": "Table 1: Comparison between Dual-Stack Model and DenseNet in Learning GVF.", "description": "This table compares the performance of the Dual-Stack Model (DSM) and DenseNet in learning the Generalized Linear Programming Value Function (GVF).  It shows the training time, true relative error (a measure of approximation accuracy), and the percentage of constraints satisfied during training and testing for both models. The data is broken down by the class of GVF (KG and Euclidean) and the size of the problem instance.", "section": "7 Computational Results"}]