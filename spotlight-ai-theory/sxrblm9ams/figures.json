[{"figure_path": "SxRblm9aMs/figures/figures_1_1.jpg", "caption": "Figure 1: Schematic representation of OptGNN. During training, OptGNN produces node embeddings v using message passing updates on the graph G. These embeddings are used to compute the penalized objective Lp(v; G). OptGNN is trained by minimizing the average loss over the training set. At inference time, the fractional solutions (embeddings) v for an input graph G produced by OptGNN are rounded using randomized rounding.", "description": "This figure illustrates the OptGNN architecture.  The training phase shows message-passing updates on the graph to produce node embeddings which are then used to minimize a penalized loss function.  The inference phase shows that these embeddings are then rounded via a randomized method to yield a final solution.", "section": "1 Introduction"}, {"figure_path": "SxRblm9aMs/figures/figures_8_1.jpg", "caption": "Figure 2: Results for Max-Cut and Minimum Vertex Cover.", "description": "Figure 2(a) shows the comparison on GSET Max-Cut instances against state-of-the-art neural baselines. The numbers reported are the mean (over the graphs in the test set) deviations from the best-known Max-Cut values, reported in Benlic & Hao (2013). Figure 2(b) shows the average approximation ratio and standard deviation over the test set for vertex covers on forced RB instances. A ratio of 1.000 represents finding the minimum vertex cover.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/figures/figures_8_2.jpg", "caption": "Figure 2: Results for Max-Cut and Minimum Vertex Cover.", "description": "This figure presents a comparison of the performance of OptGNN against other state-of-the-art methods for Max-Cut and Minimum Vertex Cover problems.  Subfigure (a) shows results on Max-Cut problems using the GSET benchmark instances, comparing OptGNN against several neural network baselines as well as classical methods like Goemans-Williamson and a greedy heuristic. Subfigure (b) displays the approximation ratio achieved by OptGNN and other baselines on Minimum Vertex Cover problems, focusing on two specific distributions of forced RB instances (RB200 and RB500).  The approximation ratio indicates how close the obtained solutions are to the optimal solutions, with values closer to 1 representing better performance.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/figures/figures_9_1.jpg", "caption": "Figure 3: Experimental comparison of SDP versus OptGNN Dual Certificates on random graphs of 100 nodes for the Max-Cut problem. Our OptGNN certificates track closely with the SDP certificates while taking considerably less time to generate.", "description": "This figure compares the SDP certificates and OptGNN dual certificates on random graphs with 100 nodes for the Max-Cut problem.  The plot shows that the OptGNN certificates closely track the SDP certificates, indicating good agreement in terms of solution quality.  The key advantage of the OptGNN certificates is that they require significantly less computation time.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/figures/figures_29_1.jpg", "caption": "Figure 3: Experimental comparison of SDP versus OptGNN Dual Certificates on random graphs of 100 nodes for the Max-Cut problem. Our OptGNN certificates track closely with the SDP certificates while taking considerably less time to generate.", "description": "This figure compares the quality of SDP certificates versus OptGNN certificates for the Max-Cut problem on random graphs with 100 nodes.  The x-axis represents the value obtained by the OptGNN method. The y-axis represents the value of the corresponding dual certificates. Both SDP and OptGNN dual certificates are plotted for comparison.  The plot shows that OptGNN certificates closely track SDP certificates, indicating their high quality. The key takeaway is that OptGNN certificates achieve comparable accuracy to SDP certificates but with significantly faster computation times, which is a major advantage.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/figures/figures_35_1.jpg", "caption": "Figure 2: Results for Max-Cut and Minimum Vertex Cover.", "description": "This figure shows the results of experiments comparing OptGNN's performance against other methods for Max-Cut and Minimum Vertex Cover problems.  Subfigure (a) displays the average approximation ratio for Max-Cut on GSET instances, comparing OptGNN against state-of-the-art neural baselines. Lower values indicate better performance. Subfigure (b) illustrates the average approximation ratio for Minimum Vertex Cover on forced RB instances, comparing OptGNN to classical and neural baselines.  A ratio closer to 1 indicates better performance.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/figures/figures_36_1.jpg", "caption": "Figure 2: Results for Max-Cut and Minimum Vertex Cover.", "description": "This figure contains two subfigures. Figure 2(a) shows the comparison of OptGNN against other state-of-the-art neural baselines and classical algorithms on Max-Cut instances from the GSET benchmark. Figure 2(b) shows the comparison of OptGNN against other neural and classical baselines on Minimum Vertex Cover instances from forced RB instances. Both subfigures show that OptGNN achieves competitive performance, often outperforming other approaches.", "section": "Experiments"}]