[{"figure_path": "SxRblm9aMs/tables/tables_7_1.jpg", "caption": "Table 1: Performance of OptGNN, Greedy, and Gurobi 0.1s, 1s, and 8s on Maximum Cut. For each approach and dataset, we report the average cut size measured on the test slice. Here, higher score is better. In parentheses, we include the average runtime in milliseconds for OptGNN.", "description": "This table compares the performance of three different algorithms (OptGNN, Greedy, and Gurobi) on the Maximum Cut problem across various datasets.  OptGNN's runtime is also provided in milliseconds. Higher scores indicate better performance.", "section": "4 Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_7_2.jpg", "caption": "Table 2: Average number of unsatisfied clauses for Max-3-SAT on random instances with N = 100 variables and clause ratios r 4.00, 4.15, 4.30. Standard deviation of the ratio over the test set is reported in superscript. In parentheses, we report the average time per instance on the test set in seconds.", "description": "This table shows the average number of unsatisfied clauses for the Max-3-SAT problem, using different algorithms and different clause ratios. The standard deviation and average runtime for each method are also given.  The results are presented for random instances with 100 variables and three different clause ratios. The algorithms compared include ErdosGNN, Walksat (with 1 and 100 restarts), Survey Propagation, OptGNN, Autograd SDP, and Low-Rank SDP. OptGNN outperforms most of the other methods, especially when compared to the Autograd SDP and Low-Rank SDP methods.", "section": "4 Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_31_1.jpg", "caption": "Table 5: Performance of various model architectures for selected datasets on Maximum Cut. Here, higher is better. GAT is the Graph Attention network (Veli\u010dkovi\u0107 et al., 2018), GIN is the Graph Isomorphism Network (Xu et al., 2019), GCNN is the Graph Convolutional Neural Network (Morris et al., 2019), and GatedGCNN is the gated version (Li et al., 2015).", "description": "This table compares the performance of several Graph Neural Network (GNN) architectures against OptGNN, on Maximum Cut problem.  It shows that OptGNN outperforms other GNN architectures for this problem, although some other models achieve similar performance in several cases.", "section": "4 Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_32_1.jpg", "caption": "Table 1: Performance of OptGNN, Greedy, and Gurobi 0.1s, 1s, and 8s on Maximum Cut. For each approach and dataset, we report the average cut size measured on the test slice. Here, higher score is better. In parentheses, we include the average runtime in milliseconds for OptGNN.", "description": "This table presents a comparison of the performance of three algorithms (OptGNN, Greedy, and Gurobi) on the Maximum Cut problem across various datasets.  OptGNN's runtime is also provided in milliseconds.  Higher scores indicate better performance. The table allows for a comparison of OptGNN's speed and accuracy relative to the established Greedy and Gurobi methods.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_33_1.jpg", "caption": "Table 4: Performance of OptGNN, Greedy, and Gurobi 0.1s, 1s, and 8s on Maximum Cut. For each approach and dataset, we report the average cut size measured on the test slice. Here, higher score is better. In parentheses, we include the average runtime in milliseconds for OptGNN.", "description": "This table presents the performance comparison of three different algorithms (OptGNN, Greedy, and Gurobi) on Maximum Cut problem using several datasets.  The average cut size is reported for each algorithm and dataset on the test set.  OptGNN's average runtime in milliseconds is also provided in parentheses. A higher cut size indicates better performance.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_33_2.jpg", "caption": "Table 6: Performance of OptGNN on Max-Cut compared to Gurobi running under an 8 second time limit, expressed as a ratio. For each dataset, we take the ratio of the integral values achieved by OptGNN and Gurobi 8s on each of the graphs in the test slice. We present the average and standard deviation of these ratios. Here, higher is better. This table demonstrates that OptGNN achieves nearly the same performance, missing on average 1.1% of the cut value in the worst measured case.", "description": "This table presents the performance of the OptGNN model on the Max-Cut problem, comparing its results to those obtained using the Gurobi solver with an 8-second time limit.  The performance is expressed as a ratio, showing how close OptGNN gets to the optimal solution found by Gurobi.  The average ratio and standard deviation are reported for each dataset, indicating both the typical performance and the variability of the results.  The caption highlights that OptGNN achieves results very close to Gurobi's, with a maximum difference of only 1.1%.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_33_3.jpg", "caption": "Table 6: Performance of OptGNN on Max-Cut compared to Gurobi running under an 8 second time limit, expressed as a ratio. For each dataset, we take the ratio of the integral values achieved by OptGNN and Gurobi 8s on each of the graphs in the test slice. We present the average and standard deviation of these ratios. Here, higher is better. This table demonstrates that OptGNN achieves nearly the same performance, missing on average 1.1% of the cut value in the worst measured case.", "description": "This table shows the performance of OptGNN on Max-Cut compared to Gurobi (with an 8-second time limit).  The performance is expressed as a ratio of OptGNN's result to Gurobi's result for each graph in the test set.  The average and standard deviation of these ratios are given.  OptGNN performs very well, on average achieving 98.9% of Gurobi's performance.", "section": "Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_34_1.jpg", "caption": "Table 7: Models for Min-Vertex-Cover trained on \"dataset\" were tested on a selection of the TU datasets (ENZYMES, PROTEINS, MUTAG, IMDB-BINARY, and COLLAB). We observe that the performance of the models generalizes well even when they are taken out of their training context.", "description": "This table shows the generalization performance of OptGNN trained on different datasets when tested on other TU datasets.  Each row represents a model trained on a specific dataset (shown in the first column), and the columns show its performance on different test datasets. The results show that the model generalizes well to datasets it has not been trained on, suggesting that OptGNN captures generalizable aspects of the problem rather than merely overfitting the training data.", "section": "D.6 Out of distribution testing"}, {"figure_path": "SxRblm9aMs/tables/tables_34_2.jpg", "caption": "Table 4: Performance of OptGNN, Greedy, and Gurobi 0.1s, 1s, and 8s on Maximum Cut. For each approach and dataset, we report the average cut size measured on the test slice. Here, higher score is better. In parentheses, we include the average runtime in milliseconds for OptGNN.", "description": "This table presents a comparison of the performance of OptGNN, a greedy algorithm, and Gurobi on various Max-Cut datasets. The average cut size achieved by each method on the test set is reported, with higher scores indicating better performance.  For OptGNN, average runtime in milliseconds is also provided in parentheses.  The table allows for an evaluation of OptGNN against classical and more sophisticated solvers.", "section": "4 Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_34_3.jpg", "caption": "Table 5: Performance of various model architectures for selected datasets on Maximum Cut. Here, higher is better. GAT is the Graph Attention network (Veli\u010dkovi\u0107 et al., 2018), GIN is the Graph Isomorphism Network (Xu et al., 2019), GCNN is the Graph Convolutional Neural Network (Morris et al., 2019), and GatedGCNN is the gated version (Li et al., 2015).", "description": "This table compares the performance of OptGNN against other state-of-the-art Graph Neural Network architectures on the Max-Cut problem.  It shows the average cut size achieved by each model on several datasets, demonstrating that OptGNN generally achieves competitive or better results.", "section": "4 Experiments"}, {"figure_path": "SxRblm9aMs/tables/tables_37_1.jpg", "caption": "Table 7: Models for Min-Vertex-Cover trained on \"dataset\" were tested on a selection of the TU datasets (ENZYMES, PROTEINS, MUTAG, IMDB-BINARY, and COLLAB). We observe that the performance of the models generalizes well even when they are taken out of their training context.", "description": "This table shows the generalization performance of OptGNN models trained on different datasets when tested on a subset of the TU datasets. The results indicate that the model generalizes well to different datasets, suggesting that it captures a general process instead of overfitting to the training data.", "section": "D.6 Out of distribution testing"}]