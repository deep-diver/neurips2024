[{"figure_path": "AB6XpMzvqH/tables/tables_21_1.jpg", "caption": "Figure A.1: Context Length for best-performing and the maximum number of shots tested for each task. The horizontal dashed line shows the context length of GPT-3 (2048 tokens), which is representative of typical few-shot prompts tested in the LLM literature. For several tasks, we observed the best-performing shots correspond to the maximum number of shots we tested, which was often limited by the number of available examples for in-context learning. On some tasks (e.g., code verifier, planning), we did observe slight performance deterioration beyond a certain number of shots.", "description": "This figure compares the best-performing number of shots and the maximum number of shots tested in many-shot in-context learning (ICL) experiments across various tasks.  It highlights the context length limitations of previous few-shot ICL approaches (using GPT-3's 2048-token limit as a reference) and shows how many-shot ICL allows for significantly larger numbers of shots, which greatly impact performance.  In some cases, performance even plateaus or slightly decreases after an optimal number of shots is reached.", "section": "A.1 Context Length for Many-shot ICL"}]