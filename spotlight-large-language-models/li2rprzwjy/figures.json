[{"figure_path": "Li2rpRZWjy/figures/figures_1_1.jpg", "caption": "Figure 1: Rule extrapolation summary for all models and languages (Tab. 1): The Transformer is the best on context-free and context-sensitive languages, whereas the LSTM and Mamba excel on regular languages. We also plot chance-level performance as gray rectangles. Mean accuracies and standard deviations (averaged over 5 seeds)", "description": "This figure summarizes the performance of different language models (Transformer, LSTM, Linear, Mamba, XLSTM) on various formal languages (regular, context-free, and context-sensitive) in terms of rule extrapolation.  The x-axis represents the languages, and the y-axis represents the accuracy of the models in completing the prompts.  The Transformer generally outperforms other models on context-free and context-sensitive languages, while LSTM and Mamba show better performance on regular languages. Chance-level accuracies are also displayed for comparison.", "section": "4 Results"}, {"figure_path": "Li2rpRZWjy/figures/figures_7_1.jpg", "caption": "Figure 2: Graphical model representing our approach for OOD prompt completion. Although Bob's LM Pdata assigns zero probability to the OOD prompt, it defines a conditional probability distribution for its completions. Our probabilistic model assumes that Bob's LM completes the ID and OOD prompt independently, according to the same procedure (e.g. the same LM architecture and parameters are used for generating the completions). This is the same as assuming that the Markov factors marked in blue are the same, i.e. p(completion|prompt, Pdata) = p(completion|OOD prompt, Pdata), and the conditional independence OOD completion | ID prompt | OOD prompt.", "description": "This figure is a graphical model showing how the proposed method for out-of-distribution (OOD) prompt completion works.  The model assumes that the language model (LM) generates both in-distribution (ID) and OOD completions independently, following the same procedure. The blue connections in the graph represent this shared process.  Despite the LM assigning zero probability to the OOD prompt, a conditional probability distribution for the OOD completions is defined, allowing the model to predict a completion even in this low-probability scenario.", "section": "5 Normative theory of OOD prompt completion"}, {"figure_path": "Li2rpRZWjy/figures/figures_9_1.jpg", "caption": "Figure 3: Training dynamics of rule learning for a Transformer trained on the a<sup>n</sup>b<sup>n</sup> language: we color-code the log probability of all sequences of length 8 consisting of a's and b's and ending with EOS at initialization (left left), during (left middle) and after training (left right). The sequences are separated according to which rule they obey. While at initialization, the probabilities are distributed roughly evenly, during training the model starts to assign higher probabilities to sequences satisfying (R2). After training the most likely sequences are the ones in (R1) \u2229 (R2), the others are negligible. The same trend can be seen on the right, where the normalized sum of the probabilities of the four categories (satisfying (R1) and (R2), only (R1), only (R2) and neither) is plotted during training.", "description": "This figure visualizes the training dynamics of a transformer model on the a<sup>n</sup>b<sup>n</sup> formal language.  The heatmaps show the log probabilities of sequences of length 8, categorized by whether they satisfy rule R1, R2, both, or neither.  The line graph shows the normalized sum of probabilities for each category over training epochs. The visualization demonstrates that the model initially assigns probabilities relatively evenly across categories but learns to favor sequences satisfying R2 first and eventually those satisfying both R1 and R2.", "section": "Towards explaining training dynamics and rule extrapolation"}, {"figure_path": "Li2rpRZWjy/figures/figures_14_1.jpg", "caption": "Figure 3: Training dynamics of rule learning for a Transformer trained on the anbn language: we color-code the log probability of all sequences of length 8 consisting of a's and b's and ending with EOS at initialization (left left), during (left middle) and after training (left right). The sequences are separated according to which rule they obey. While at initialization, the probabilities are distributed roughly evenly, during training the model starts to assign higher probabilities to sequences satisfying (R2). After training the most likely sequences are the ones in (R1) \u2229 (R2), the others are negligible. The same trend can be seen on the right, where the normalized sum of the probabilities of the four categories (satisfying (R1) and (R2), only (R1), only (R2) and neither) is plotted during training.", "description": "This figure visualizes the training dynamics of a Transformer model on the a<sup>n</sup>b<sup>n</sup> language.  The left panels show heatmaps of log probabilities for sequences of length 8, categorized by which rules (R1 and R2) they satisfy. The right panel shows the evolution of the normalized probabilities of these four categories over training epochs.  The results illustrate how the model learns the rules sequentially, initially prioritizing rule R2 (a's before b's), then converging to correctly generate sequences obeying both R1 (#a=#b) and R2.", "section": "Towards explaining training dynamics and rule extrapolation"}, {"figure_path": "Li2rpRZWjy/figures/figures_14_2.jpg", "caption": "Figure 3: Training dynamics of rule learning for a Transformer trained on the anbn language: we color-code the log probability of all sequences of length 8 consisting of a's and b's and ending with EOS at initialization (left left), during (left middle) and after training (left right). The sequences are separated according to which rule they obey. While at initialization, the probabilities are distributed roughly evenly, during training the model starts to assign higher probabilities to sequences satisfying (R2). After training the most likely sequences are the ones in (R1) \u2229 (R2), the others are negligible. The same trend can be seen on the right, where the normalized sum of the probabilities of the four categories (satisfying (R1) and (R2), only (R1), only (R2) and neither) is plotted during training.", "description": "This figure shows the training dynamics of a transformer model learning the formal language a<sup>n</sup>b<sup>n</sup>.  The left panels show heatmaps of log probabilities for sequences of length 8, categorized by whether they satisfy rules R1 and R2, or only one of them, or neither.  The right panel shows the evolution of the sum of probabilities for each category over training epochs.  The visualization demonstrates a bias towards learning rule R2 first, then subsequently learning the intersection of both rules (R1 \u2229 R2).", "section": "Towards explaining training dynamics and rule extrapolation"}, {"figure_path": "Li2rpRZWjy/figures/figures_17_1.jpg", "caption": "Figure 6: Rule extrapolation summary for all models but the xLSTM and languages L1 - L5 (Tab. 1) with greedy (Fig. 6a) and sampling (Fig. 6b) next-token decoding", "description": "This figure compares the performance of different language models (Transformer, LSTM, Linear, Mamba) on rule extrapolation tasks using two different decoding methods: greedy decoding and sampling decoding.  The models are evaluated on several formal languages (L1-L5) with varying complexity. The figure visually presents the accuracy of each model in completing sequences according to rule 1 (R1) and the completion of rule 2 (R2), which is only partially satisfied, highlighting the strengths and weaknesses of each model under different decoding strategies and across different language complexities. The chance-level performance is also included as a baseline.", "section": "Additional experimental results"}, {"figure_path": "Li2rpRZWjy/figures/figures_17_2.jpg", "caption": "Figure 1: Rule extrapolation summary for all models and languages (Tab. 1): The Transformer is the best on context-free and context-sensitive languages, whereas the LSTM and Mamba excel on regular languages. We also plot chance-level performance as gray rectangles. Mean accuracies and standard deviations (averaged over 5 seeds)", "description": "This figure summarizes the rule extrapolation performance of different models (Transformer, LSTM, Linear, Mamba) across six formal languages of varying complexity (regular, context-free, context-sensitive).  The bar chart displays the accuracy of each model in completing OOD prompts that violate at least one rule of the language, showing how well the models extrapolate the remaining rules.  The gray rectangles indicate the chance level accuracy for each language, representing the performance expected from a random guess. The Transformer achieves the highest accuracy for the context-free and context-sensitive languages, while the LSTM and Mamba perform best on the regular languages.", "section": "4 Results"}, {"figure_path": "Li2rpRZWjy/figures/figures_18_1.jpg", "caption": "Figure 1: Rule extrapolation summary for all models and languages (Tab. 1): The Transformer is the best on context-free and context-sensitive languages, whereas the LSTM and Mamba excel on regular languages. We also plot chance-level performance as gray rectangles. Mean accuracies and standard deviations (averaged over 5 seeds)", "description": "This figure summarizes the performance of various language models (Transformer, LSTM, Linear, Mamba) on rule extrapolation tasks across six formal languages with different complexities (regular, context-free, context-sensitive).  The bar chart displays the accuracy of each model in completing sequences while adhering to at least one of the two rules defining each language, even when another rule is violated. The gray rectangles represent the chance-level accuracy for each task.  The results indicate that the Transformer generally outperforms others on more complex languages, while LSTM and Mamba are better suited for regular languages.", "section": "4 Results"}]