[{"figure_path": "xabStWAUtr/tables/tables_4_1.jpg", "caption": "Table 1: Evaluating generalization of the knowledge learned from the synthetic corpora. Results are 5-shot accuracies. The model finetuned on the Referencing text generalizes well in all reasoning tasks, while the model finetuned on the Narrative text does not.", "description": "This table presents the results of evaluating the generalization of knowledge learned by language models finetuned on synthetic corpora.  The models were tested on various question-answering and reasoning tasks, including simple question answering (QA), multiple-choice questions, reverse QA, indirect reasoning, and 2-hop reasoning.  The results show that models trained on text with implicit factual associations (Referencing) generalize significantly better to complex reasoning tasks compared to those trained on text with explicit co-occurrence statistics (Narrative).  The 5-shot accuracy reflects performance after only five examples for the models to learn the new knowledge.", "section": "3.2 Generalization of co-occurrence vs. factual association"}, {"figure_path": "xabStWAUtr/tables/tables_6_1.jpg", "caption": "Table 2: Evaluating generalization of the knowledge learned from the MQuAKE-T dataset (5-shot). (*) denotes standard deviation calculated from 3 runs with different random seeds.", "description": "This table presents the results of evaluating the generalization of knowledge learned from the MQuAKE-T dataset using different training methods.  It compares the performance of the models on single-hop and multi-hop question answering tasks. The \"Original\" training data uses the narrative text provided in the original dataset, while the \"Referencing\" data uses a modified version that introduces implicit associations between entities. The results demonstrate the impact of implicit textual associations on the model's ability to generalize knowledge to more complex reasoning scenarios.  The numbers represent 5-shot accuracies, and the numbers in parentheses are standard deviations across three separate runs with different random seeds.", "section": "4.1 Learning factual associations from implicit association"}, {"figure_path": "xabStWAUtr/tables/tables_8_1.jpg", "caption": "Table 1: Evaluating generalization of the knowledge learned from the synthetic corpora. Results are 5-shot accuracies. The model finetuned on the Referencing text generalizes well in all reasoning tasks, while the model finetuned on the Narrative text does not.", "description": "This table presents the results of evaluating the generalization of knowledge learned by language models finetuned on two different types of synthetic corpora: Narrative and Referencing.  It shows the 5-shot accuracy of several reasoning tasks (QA, Multiple Choice, Reverse QA, Indirect Reasoning, 2-hop Reasoning) for different language models (LLaMA 3 8B, LLaMA 3 70B, Gemma 7B). The results demonstrate that models trained on the Referencing corpus (implicit factual associations) generalize significantly better to complex reasoning tasks than those trained on the Narrative corpus (explicit co-occurrence statistics).", "section": "3.2 Generalization of co-occurrence vs. factual association"}]