[{"figure_path": "232VcN8tSx/figures/figures_5_1.jpg", "caption": "Figure 1: (a) We show the correlation between the ground-truth model validation loss change in one gradient update iteration U(t)(S;z(val)) := l(wt,z(val))\u2212l(wt+1(S),z(val)) and the first-order Taylor approximation \u2211z\u2208S\u03b7tg(z)\u22c5g(z(val)). (b) We show the correlation between U(t)(S;z(val)) and the first-order approximation corrected by the Hessian interaction \u2211z\u2208S\u03b7tg(z)\u22c5g(z(val))\u2212\u2211z,z\u2032\u2208S\u03b7tg(z)H(z(val))g(z\u2032).", "description": "This figure shows the correlation between the actual and predicted validation loss changes.  Panel (a) uses only the first-order Taylor expansion, while panel (b) includes both the first-order and Hessian interaction terms. The higher correlation in (b) demonstrates the improved accuracy of the approximation when considering the Hessian interaction.", "section": "4.2 An Efficient Greedy Algorithm for Utility Optimization without Utility Evaluation"}, {"figure_path": "232VcN8tSx/figures/figures_8_1.jpg", "caption": "Figure 3: Comparison of the validation and test perplexity dynamics during training for different online batch selection methods under different settings. SBERT and RHOLoss are omitted from comparison due to computational cost and time constraints.", "description": "This figure displays the validation and test perplexity curves for several online batch selection methods across various settings. The x-axis represents training steps, and the y-axis represents perplexity.  Each subplot shows results for a different model, task, or validation data size.  The figure highlights the faster convergence and better generalization performance of GREATS (the proposed method) compared to other methods, particularly for smaller validation set sizes.  The exclusion of SBERT and RHOLoss is noted due to high computational cost.", "section": "5.2 Performance Evaluation"}, {"figure_path": "232VcN8tSx/figures/figures_8_2.jpg", "caption": "Figure 4: (a)-(b): Impact of the number of validation data points on the performance of GREATS. (c)-(d): Comparison of the validation and test perplexity dynamics during GPT2 pretraining for different online batch selection methods.", "description": "This figure shows the effect of the number of validation data points on GREATS' performance in both fine-tuning and pre-training settings.  Subfigures (a) and (b) demonstrate that even with a small number of validation points (2 or 3), GREATS still significantly improves the validation and test perplexity compared to regular training during the fine-tuning process. Subfigures (c) and (d) illustrate GREATS' effectiveness in pre-training a GPT-2 model, showing that even in this setting, it offers better performance than regular training.", "section": "5.2 Performance Evaluation"}, {"figure_path": "232VcN8tSx/figures/figures_17_1.jpg", "caption": "Figure 2: Comparison of the validation and test perplexity dynamics during training for different online batch selection methods on MMLU. We select sociology and US foreign policy subjects.", "description": "This figure displays the validation and test perplexity over training steps for different online batch selection methods applied to the MMLU benchmark.  Two specific subjects within MMLU are examined: sociology and US foreign policy.  The purpose is to demonstrate how GREATS compares to alternative online batch selection methods (Regular, GradNorm, MaxLoss, SBERT, RHOLoss) in terms of convergence speed and generalization performance. The results show that GREATS converges more quickly and achieves lower perplexity than other methods.", "section": "5.2 Performance Evaluation"}, {"figure_path": "232VcN8tSx/figures/figures_17_2.jpg", "caption": "Figure 3: Comparison of the validation and test perplexity dynamics during training for different online batch selection methods under different settings. SBERT and RHOLoss are omitted from comparison due to computational cost and time constraints.", "description": "The figure shows the performance of different online batch selection methods (GREATS, Regular, GradNorm, MaxLoss) on various tasks (MMLU, TYDIQA, SAMSUM). It compares the validation and test perplexity over training steps, highlighting GREATS's faster convergence and improved generalization.", "section": "5.2 Performance Evaluation"}]