[{"figure_path": "ANO1i9JPtb/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between single-query [8, 11], multi-query [14, 17], and (c) our BoT methods.", "description": "This figure compares three different approaches to reasoning with large language models (LLMs): single-query, multi-query, and the proposed Buffer of Thoughts (BoT) method.  Single-query methods rely on a single LLM query with a carefully crafted prompt to elicit a correct response, but this often requires significant task-specific engineering and struggles with complex problems.  Multi-query methods break down complex tasks into multiple sub-problems solved with iterative LLM queries, potentially improving accuracy but at the cost of increased computational expense.  The BoT method leverages a \"meta-buffer\" storing reusable high-level \"thought-templates\" distilled from previously solved tasks, allowing efficient and accurate reasoning even for complex problems by retrieving relevant templates and instantiating them with task-specific details.  The figure visually represents the flow of information and processing steps in each method, highlighting the key differences in approach and their respective strengths and weaknesses in terms of accuracy and efficiency.", "section": "1 Introduction"}, {"figure_path": "ANO1i9JPtb/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of different reasoning process. Buffer of Thoughts enables large language models to tackle complex reasoning tasks through our thought-augmented reasoning process. Thought template is marked in orange and instantiated thought is marked in blue.", "description": "This figure illustrates the Buffer of Thoughts (BoT) reasoning process, comparing it to traditional Chain-of-Thought and Plan-and-Solve methods.  It highlights the key steps: problem distillation (extracting relevant information), thought retrieval (selecting an appropriate thought template from the meta-buffer), and instantiated reasoning (adapting the template to solve the specific problem). The use of a meta-buffer to store reusable high-level thought-templates is emphasized, showcasing how BoT improves efficiency and accuracy by leveraging previously learned problem-solving strategies.  The figure uses color-coding (orange for thought templates, blue for instantiated thoughts) to visually distinguish the different stages of the process.  An example problem is shown to demonstrate the workflow.", "section": "3 Buffer of Thoughts"}, {"figure_path": "ANO1i9JPtb/figures/figures_7_1.jpg", "caption": "Figure 3: Comparison of logarithmic inference time between our Buffer of Thoughts and GPT4 [3], GPT4+CoT [8], Expert-prompting [9], PAL [10], ToT [14] across different benchmarks.", "description": "This figure compares the inference time of different prompting methods across three benchmark tasks: Game of 24, MGSM, and Checkmate-in-One. The methods compared are: Buffer of Thoughts (Ours), GPT-4, GPT-4+CoT, Expert Prompting, PAL, and ToT. The y-axis represents the logarithmic inference time in seconds, and the x-axis represents the benchmark task. The figure shows that Buffer of Thoughts has comparable inference times to single-query methods (Expert Prompting and PAL) and significantly faster times than multi-query methods (ToT).", "section": "4 Experiments"}, {"figure_path": "ANO1i9JPtb/figures/figures_7_2.jpg", "caption": "Figure 4: Comparison of reasoning robustness between our Buffer of Thoughts and GPT4 [3], GPT4+CoT [8], Expert-prompting [9], PAL [10], ToT [14] across different benchmarks.", "description": "This figure compares the robustness of different prompting methods, including the proposed Buffer of Thoughts (BoT), across various reasoning benchmarks. Robustness is measured as the average success rate over multiple runs.  The BoT demonstrates superior robustness, consistently outperforming other methods across all benchmarks. This highlights the method's ability to handle variations and uncertainties in problem solving.", "section": "4 Experiments"}, {"figure_path": "ANO1i9JPtb/figures/figures_8_1.jpg", "caption": "Figure 2: Illustration of different reasoning process. Buffer of Thoughts enables large language models to tackle complex reasoning tasks through our thought-augmented reasoning process. Thought template is marked in orange and instantiated thought is marked in blue.", "description": "This figure illustrates how the Buffer of Thoughts (BoT) method works.  It shows a comparison of different reasoning processes, highlighting how BoT leverages a \"thought-augmented reasoning\" approach.  The process begins with an input problem, which is distilled to extract key information.  A relevant \"thought-template\" (highlighted in orange) is then retrieved from the meta-buffer, a library of high-level thoughts.  This template is instantiated with task-specific reasoning structures (blue), leading to a solution.  The figure emphasizes the key components of BoT: the problem distiller, thought retrieval, instantiated reasoning, and the meta-buffer itself, showing how they work together to solve complex reasoning problems.", "section": "3 Buffer of Thoughts"}, {"figure_path": "ANO1i9JPtb/figures/figures_8_2.jpg", "caption": "Figure 6: We evaluate the trade-off between model size and performance with Llama3-8B and Llama3-70B models on three challenging benchmarks.", "description": "This figure shows the accuracy of Llama-3-8B and Llama-3-70B language models, both with and without the Buffer of Thoughts (BoT) method, on three challenging reasoning tasks: Game of 24, Word list sorting, and Checkmate-in-One.  The results demonstrate that BoT significantly improves the accuracy of the smaller Llama-3-8B model, even surpassing the performance of the larger Llama-3-70B model in some cases.  This highlights BoT's ability to improve the efficiency of language models by leveraging shared knowledge across tasks, thus reducing the need for extremely large models.", "section": "4 Experiments"}, {"figure_path": "ANO1i9JPtb/figures/figures_9_1.jpg", "caption": "Figure 7: We conduct ablation study on buffer-manager regarding reasoning accuracy across four tasks, employing Llama3-70B and GPT-4 as the base models.", "description": "This figure shows the results of an ablation study on the impact of the buffer-manager component of the Buffer of Thoughts (BoT) model.  The study compares the accuracy of the BoT model with and without the buffer-manager across four different reasoning tasks, using two large language models (LLMs), Llama3-70B and GPT-4, as base models. The x-axis represents the four rounds of the experiment, and the y-axis represents the accuracy achieved in each round. The lines represent the accuracy of BoT+GPT4 with the buffer-manager and BoT+GPT4 without the buffer-manager. The results demonstrate that the buffer-manager significantly improves the accuracy of the BoT model, especially in later rounds.", "section": "6 Discussion"}, {"figure_path": "ANO1i9JPtb/figures/figures_13_1.jpg", "caption": "Figure 8: We conduct ablation study on problem-distiller across four benchmarks, employing Llama3-70B and GPT-4 as the base models.", "description": "This figure shows the results of an ablation study where the problem-distiller component of the Buffer of Thoughts (BoT) model was removed.  The experiment was conducted on four benchmark tasks (Game of 24, Word list sorting, Checkmate-in-One, and MGSM) using two different base language models: Llama3-70B and GPT-4. The bar chart displays the accuracy achieved by the BoT model with and without the problem-distiller for each benchmark and language model. The results demonstrate the impact of the problem-distiller on model performance, particularly for more complex reasoning tasks.", "section": "A More Ablation Studies"}, {"figure_path": "ANO1i9JPtb/figures/figures_13_2.jpg", "caption": "Figure 9: We conduct ablation study on meta-buffer across four benchmarks, employing Llama3-70B and GPT-4 as the base models.", "description": "This ablation study investigates the impact of removing the meta-buffer component from the Buffer of Thoughts (BoT) model.  The figure displays accuracy results across four different benchmarks (Game of 24, Word list sorting, Checkmate-in-One, MGSM) using two different base LLMs (Llama3-70B and GPT-4). The results demonstrate the significant improvement in accuracy provided by the meta-buffer across all benchmarks and both LLMs.  The differences in accuracy between models with and without the meta-buffer highlight its crucial role in the BoT's overall performance.  The larger difference between the models in the Checkmate-in-One benchmark is especially noteworthy, indicating the meta-buffer's increased importance for more complex reasoning tasks.", "section": "A More Ablation Studies"}, {"figure_path": "ANO1i9JPtb/figures/figures_14_1.jpg", "caption": "Figure 3: Comparison of logarithmic inference time between our Buffer of Thoughts and GPT4 [3], GPT4+CoT [8], Expert-prompting [9], PAL [10], ToT [14] across different benchmarks.", "description": "This figure compares the inference time of the Buffer of Thoughts method with several other baseline methods across various benchmarks.  It shows that Buffer of Thoughts achieves a comparable inference time to single-query methods while significantly outperforming multi-query methods.  The logarithmic scale is used to better visualize the differences in time across the different methods.  The benchmarks listed allow for a cross-comparison of the model performance.", "section": "4 Experiments"}, {"figure_path": "ANO1i9JPtb/figures/figures_17_1.jpg", "caption": "Figure 2: Illustration of different reasoning process. Buffer of Thoughts enables large language models to tackle complex reasoning tasks through our thought-augmented reasoning process. Thought template is marked in orange and instantiated thought is marked in blue.", "description": "This figure illustrates the thought-augmented reasoning process of Buffer of Thoughts. It compares three different reasoning methods: Chain-of-Thought, Plan-and-Solve, and Buffer of Thoughts. The figure shows how Buffer of Thoughts uses a meta-buffer to store high-level thoughts and retrieves a relevant thought-template for each problem. The thought-template is then instantiated with specific reasoning structures to conduct efficient reasoning. The figure highlights that Buffer of Thoughts enables large language models to tackle complex reasoning tasks more effectively by leveraging informative historical reasoning structures and eliminating the need to build reasoning structures from scratch. ", "section": "3 Buffer of Thoughts"}, {"figure_path": "ANO1i9JPtb/figures/figures_18_1.jpg", "caption": "Figure 1: Comparison between single-query [8, 11], multi-query [14, 17], and (c) our BoT methods.", "description": "This figure compares three different reasoning methods used with large language models (LLMs): single-query, multi-query, and the authors' proposed Buffer of Thoughts (BoT) method.  Single-query methods rely on a single prompt to obtain an answer, while multi-query methods iteratively refine the answer through multiple prompts. The BoT method uses a meta-buffer to store high-level thoughts derived from previous problem-solving, allowing for more efficient and accurate reasoning on new problems.", "section": "1 Introduction"}]