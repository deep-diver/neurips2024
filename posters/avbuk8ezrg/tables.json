[{"figure_path": "AvBuK8Ezrg/tables/tables_6_1.jpg", "caption": "Table 1: Performance comparison on HCPA and UKB datasets. Colored numbers indicate ranking in the first, second, and third place.", "description": "This table presents a comparison of the performance of different machine learning models, including NeuroPath, on two datasets (HCPA and UKB) for neural activity classification.  The performance is measured by accuracy and F1 score, with results shown for different combinations of static/dynamic data and BOLD/CORR features. Colored numbers highlight the top three performing models for each metric and data setting.", "section": "4 Experimental Results"}, {"figure_path": "AvBuK8Ezrg/tables/tables_6_2.jpg", "caption": "Table 2: Performance comparison on ADNI and OASIS datasets. Colored numbers indicate ranking in the first, second, and third place.", "description": "This table presents the performance comparison of different models on two datasets: ADNI and OASIS.  The models are evaluated based on accuracy and F1 score using different data settings (static/dynamic BOLD and CORR). The colored numbers highlight the top three performing models for each setting.", "section": "4 Experimental Results"}, {"figure_path": "AvBuK8Ezrg/tables/tables_6_3.jpg", "caption": "Table 3: Conclusion of performance: Average rank of methods on different scenarios and evaluation metrics. \u2018Bold\u2019 and \u2018underline\u2019 denote the first and the second place, respectively.", "description": "This table summarizes the average ranks of different machine learning models (MLP, GCN, BrainGNN, BNT, BolT, Graphormer, NAGphormer, and NeuroPath) across various datasets (HCPA, UKB, ADNI, OASIS) and evaluation metrics (Accuracy and F1 score).  Different experimental scenarios (BOLD/CORR, static/dynamic) are considered.  The ranking helps to understand the relative performance of each model under different conditions.  Bold and underlined numbers highlight the top two performing models for each scenario.", "section": "4 Experimental Results"}, {"figure_path": "AvBuK8Ezrg/tables/tables_7_1.jpg", "caption": "Table 4: Zero-shot learning between four datasets using BOLD as node attributes under different data settings, where resting/tasking state classification is tested for HCPA and UKB datasets, F1 scores are listed, and 'bold' and 'underline' denote the first and the second rank, respectively.", "description": "This table presents the results of zero-shot learning experiments.  The model was trained on one dataset (either HCPA, UKB, ADNI, or OASIS) and tested on a different one. F1 scores are reported for both static and dynamic data, with BOLD as the node attribute. The top performing model in each setting is highlighted.", "section": "4.3 Zero-shot Learning"}, {"figure_path": "AvBuK8Ezrg/tables/tables_8_1.jpg", "caption": "Table 5: Ablation of none branch (a vanilla Transformer), single branch, and twin branch of NeuroPath on four datasets with static BOLD as node attributes, where \u2018bold\u2019 and \u2018underline\u2019 denote the first and the second rank, respectively.", "description": "This table presents the results of an ablation study on the NeuroPath model.  It shows the performance (Accuracy and F1 score) of four different model variations on four different datasets (ADNI, OASIS, HCPA, UKB). The variations are: using no additional transformer branches, using only the topological detour multi-head self-attention (TD-MHSA) branch, using only the functional connectivity filtered multi-head self-attention (FC-MHSA) branch, and using both branches.  The best-performing model variation for each dataset and metric is highlighted.", "section": "4.5 Ablation of Model Architecture"}, {"figure_path": "AvBuK8Ezrg/tables/tables_8_2.jpg", "caption": "Table 1: Performance comparison on HCPA and UKB datasets. Colored numbers indicate ranking in the first, second, and third place.", "description": "This table presents a comparison of the performance of different machine learning models, including NeuroPath, on two datasets (HCPA and UKB) for neural activity classification.  The performance is measured using accuracy and F1 score, with results broken down by dataset and data type (BOLD dynamic, BOLD static, CORR dynamic, CORR static).  Colored numbers highlight the top three performing models for each metric and data setting.", "section": "4 Experimental Results"}, {"figure_path": "AvBuK8Ezrg/tables/tables_9_1.jpg", "caption": "Table 1: Performance comparison on HCPA and UKB datasets. Colored numbers indicate ranking in the first, second, and third place.", "description": "This table presents the performance comparison of different machine learning models, including NeuroPath, on two datasets (HCPA and UKB) for neural activity classification. The performance is measured by accuracy and F1 score under various settings (BOLD/CORR and dynamic/static). The colored numbers highlight the top three performing models for each setting.", "section": "4 Experimental Results"}, {"figure_path": "AvBuK8Ezrg/tables/tables_9_2.jpg", "caption": "Table 8: Computational complexity in our experiments, where computing time is the average on UKB dataset with unit the millisecond per graph data.", "description": "This table shows the computational cost of different models used in the paper's experiments.  It compares the number of parameters, preprocessing time, training time, and testing time for each model.  The time units are milliseconds per graph data point, averaged on the UKB dataset.  It shows that while some models (Graphormer and NAGphormer) have fewer parameters, they require significantly more time in pre-processing, training, and testing.  NeuroPath demonstrates efficiency in this regard.", "section": "4 Experimental Results"}, {"figure_path": "AvBuK8Ezrg/tables/tables_15_1.jpg", "caption": "Table 9: Data profiles, where |G| denotes the number of graphs, |C| denotes the number of classes, and avg(D) denotes the average degree of brain networks.", "description": "This table presents the characteristics of four different datasets used in the paper's experiments: HCPA, UKB, ADNI, and OASIS.  For each dataset, it shows the number of graphs (|G|), the number of classes (|C|) for the classification task, and the average degree (avg(D)) of the brain networks. The table is further divided into static and dynamic versions of each dataset, reflecting the different processing methods used.  The average degree reflects the average number of connections per node in the brain network graph, providing information about network density.", "section": "A.3 Data Profiles"}]