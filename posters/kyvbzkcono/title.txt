Injecting Undetectable Backdoors in Obfuscated Neural Networks and Language Models