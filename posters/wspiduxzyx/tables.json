[{"figure_path": "wSpIdUXZYX/tables/tables_8_1.jpg", "caption": "Table 1. Test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets with viscosity Re = 400 and Re = 4000 for different numbers of few-shot training samples.", "description": "This table presents the test L2 loss for fluid dynamics and fluid-structure interaction datasets.  It shows the performance of different models (GINO, DeepO, GNN, ViT, U-Net, and the proposed CoDA-NO) with varying numbers of few-shot training samples (5, 25, 100) and two Reynolds numbers (Re = 400 and Re = 4000).  The results are split by evaluation dataset (NS and NS+EW) and whether or not CoDA-NO was pre-trained on either NS or NS+EW datasets.  This allows for comparison of the performance of the models when using data from different scenarios (fluid only or fluid-structure interaction) and with varying amounts of training data. ", "section": "Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_9_1.jpg", "caption": "Table 2. Test L2 error for Rayleigh-B\u00e9nard convection system with coupled Navier-Stokes and energy (heat) equation with Rayleigh number Ra = 12 \u00d7 103 and Ra = 20 \u00d7 103 for different few shot examples.", "description": "This table presents the test L2 error results for the Rayleigh-B\u00e9nard convection system, comparing the performance of Unet, FNO, and the proposed CoDA-NO model across different Rayleigh numbers (Ra = 12 \u00d7 10^3 and Ra = 20 \u00d7 10^3) and varying numbers of few-shot training samples (5, 10, 25).  It highlights the performance improvement of CoDA-NO, especially when limited training data is available.", "section": "4 Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_17_1.jpg", "caption": "Table 3. Evaluating L2 loss across different models using various pre-training datasets and varying numbers of few-shot training samples. \"*\" indicates configurations that did not converge due to excessive training error.", "description": "This table presents the results of an ablation study on the CoDA-NO model.  It shows the impact of removing or changing different components of the model (codomain attention, VSPE, normalization) on its performance.  Different pre-training datasets (NS, NS+EW) and varying numbers of few-shot training samples (5, 25, 100) are used.  The '*' indicates that the model did not converge during training for those configurations.", "section": "F.1 Ablation of Proposed components"}, {"figure_path": "wSpIdUXZYX/tables/tables_17_2.jpg", "caption": "Table 4. Zero Shot Super Resolution Performance on Fluid-Solid (NS-EW) Interaction Problem", "description": "This table compares the zero-shot super-resolution performance of different models on the fluid-solid interaction problem.  The models are tested on unseen fluid viscosities (\u03bc = 5, \u03bc = 1, \u03bc = 10) after being pretrained on different datasets (NS-ES and NS). The results show the L2 error for each model and viscosity, highlighting the superior performance of CoDA-NO in this zero-shot setting.", "section": "F.2 Zero-Shot Super Resolution Test"}, {"figure_path": "wSpIdUXZYX/tables/tables_18_1.jpg", "caption": "Table 5. Comparison of Inference Time, Training Time (in sec.) per sample, and Number of Parameters for different models.", "description": "This table compares the performance of different models (GNN, GINO, DeepO, ViT, Unet, and CoDA-NO) in terms of inference time, training time per sample, and the number of parameters.  The data allows for a comparison of efficiency and computational resource requirements across these models.", "section": "F.3 Parameter Count and Computational Cost"}, {"figure_path": "wSpIdUXZYX/tables/tables_18_2.jpg", "caption": "Table 1. Test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets with viscosity Re = 400 and Re = 4000 for different numbers of few-shot training samples.", "description": "This table presents the L2 loss (a measure of error) for two different datasets: fluid dynamics (NS) and fluid-structure interaction (NS+EW).  The experiments were conducted with two different Reynolds numbers (Re=400 and Re=4000) representing different fluid viscosities and varying numbers of few-shot training samples (5, 25, and 100).  The table compares the performance of different models in handling these datasets with limited data.", "section": "Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_19_1.jpg", "caption": "Table 1. Test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets with viscosity Re = 400 and Re = 4000 for different numbers of few-shot training samples.", "description": "This table presents the test L2 loss for fluid dynamics and fluid-solid interaction datasets using different numbers of few-shot training samples. The results are broken down by model (GINO, DeepO, GNN, ViT, U-Net, Ours), pretraining dataset (NS, NS+EW), and the number of few-shot training samples (5, 25, 100).  It allows for comparison of different models' performance on different datasets under varying data scarcity conditions.", "section": "4 Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_20_1.jpg", "caption": "Table 1. Test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets with viscosity Re = 400 and Re = 4000 for different numbers of few-shot training samples.", "description": "This table shows the test L2 loss for two datasets, fluid dynamics (NS) and fluid-solid interaction (NS+EW),  with two different Reynolds numbers (400 and 4000). The table compares the performance of several models (GINO, DeepO, GNN, ViT, U-Net, and Ours) under different numbers of few-shot training samples (5, 25, 100).  The \"Ours\" model refers to the CoDA-NO model proposed in the paper. The results show how well each model generalizes to unseen data with limited training examples.", "section": "4 Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_20_2.jpg", "caption": "Table 1. Test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets with viscosity Re = 400 and Re = 4000 for different numbers of few-shot training samples.", "description": "This table presents the test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets.  The results are shown for two Reynolds numbers (Re = 400 and Re = 4000) and different numbers of few-shot training samples (5, 25, 100).  It allows comparison of the performance of various models (GINO, DeepONet, GNN, ViT, U-Net, and the proposed CoDA-NO) under different data regimes.", "section": "Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_20_3.jpg", "caption": "Table 1. Test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets with viscosity Re = 400 and Re = 4000 for different numbers of few-shot training samples.", "description": "This table presents the test L2 loss for two datasets, fluid dynamics (NS) and fluid-solid interaction (NS+EW), across different models and varying numbers of few-shot training samples.  The results are shown for two Reynolds numbers (Re = 400 and Re = 4000) to demonstrate the model's performance under different flow conditions.  The models tested include several baselines (GINO, DeepO, GNN, ViT, U-Net) and the proposed CoDA-NO model with and without pretraining on different datasets. The table allows comparison of model performance given limited data for both single-physics and multi-physics scenarios.", "section": "Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_21_1.jpg", "caption": "Table 1. Test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets with viscosity \u03bc = 400 and \u03bc = 4000 for different numbers of few-shot training samples.", "description": "The table presents the test L2 loss for fluid dynamics (NS) and fluid-solid interaction (NS+EW) datasets.  The results are shown for two different viscosities (\u03bc = 400 and \u03bc = 4000) and varying numbers of few-shot training samples (5, 25, 100).  It compares the performance of the proposed CoDA-NO model against several baseline methods (GINO, DeepO, GNN, ViT, U-Net). The table helps to evaluate the generalization ability and sample efficiency of the CoDA-NO model in handling multiphysics problems with limited data.", "section": "Experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_21_2.jpg", "caption": "Table 12. Test errors (L2 error) for CoDA-NO vs FNO on 2D datasets from PDEBench. SWE indicates shallow water equations data. \u201812DATA\u2019 represents the 12PDE PDE datasets DPOT is pretrained on. The \"-200\" and \"-500\" suffixes denote fine-tuning on each subset for 200 and 500 epochs, respectively, which is directly taken from the DPOT paper. All of this was fine-tuned on SWE data.", "description": "This table compares the performance of CoDA-NO and FNO on three single-physics PDE datasets from PDEBench: Shallow Water Equations (SWE), Diffusion Equations (DIFF), and a combined dataset of Navier-Stokes, Diffusion, and Shallow Water Equations (NS+DIFF+SWE).  It shows the prediction error and reconstruction error for each model and dataset.", "section": "G. PDEBench experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_22_1.jpg", "caption": "Table 13. Comparison of model parameter sizes for CoDA-NO, FNO, and DPOT. DPOT-FT stands for the Finetuning model used, whereas -T stands for tiny, -S stands for small, -M stands for medium, and -L stands for Large. The pretrained model sizes are present in the original paper but are around the same parameter sizes as the fine-tuned models.", "description": "This table compares the number of parameters of the CoDA-NO model with several baselines: FNO and DPOT.  The table shows that CoDA-NO has significantly fewer parameters than FNO, and is comparable to the smaller versions of DPOT.", "section": "G PDEBench experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_22_2.jpg", "caption": "Table 12. Test errors(L2 error) for CODA-NO vs FNO on 2D datasets from PDEBench. SWE indicates shallow water equations data. \u201812DATA\u2019 represents the 12PDE PDE datasets DPOT is pretrained on. The \"-200\" and \"-500\" suffixes denote fine-tuning on each subset for 200 and 500 epochs, respectively, which is directly taken from the DPOT paper. All of this was fine-tuned on SWE data.", "description": "This table compares the performance of CoDA-NO and FNO on three single-physics PDE datasets from PDEBench.  It shows the prediction error for each model when pretrained on the SWE dataset and a dataset comprised of 12 different PDEs, with different finetuning epochs.  The results highlight CoDA-NO's superior generalization abilities, particularly when pretrained on a broader dataset.", "section": "G PDEBench experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_23_1.jpg", "caption": "Table 12. Test errors(L2 error) for CODA-NO vs FNO on 2D datasets from PDEBench. SWE indicates shallow water equations data. \u201812DATA\u2019 represents the 12PDE PDE datasets DPOT is pretrained on. The \"-200\" and \"-500\" suffixes denote fine-tuning on each subset for 200 and 500 epochs, respectively, which is directly taken from the DPOT paper. All of this was fine-tuned on SWE data.", "description": "This table compares the performance of CoDA-NO and FNO on three single-physics datasets from the PDEBench dataset.  It shows the test error (L2 error) for both models on the Shallow Water Equation (SWE) and Diffusion Equation (DIFF) datasets. Additionally, it includes results where both models were pre-trained on a combined dataset of 12 PDEs (12DATA) and then fine-tuned on the SWE and DIFF datasets separately for 200 and 500 epochs.", "section": "G PDEBench experiments"}, {"figure_path": "wSpIdUXZYX/tables/tables_23_2.jpg", "caption": "Table 16. Test errors (L2 norm) for models in both the Shallow Water Equation and Diffusion-Reaction experiments. The number of parameters is reported alongside the L2 errors for both tasks.", "description": "This table compares the performance of CoDA-NO and FNO models with varying numbers of parameters on two different PDE datasets: Shallow Water Equation (SWE) and Diffusion-Reaction (DIFF).  It shows the L2 error for each model on both datasets.  The table highlights the relationship between model size (# parameters) and prediction accuracy (L2 error).", "section": "G PDEBench experiments"}]