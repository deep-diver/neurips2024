[{"figure_path": "ZMmJ1z8vee/figures/figures_0_1.jpg", "caption": "Figure 1: Given a few-shot target dataset of a specific domain such as sketches painted by an artist (a), it is usually difficult to directly generate images of this domain using pretrained text-to-image models (b). By using DomainGallery we propose in this work, we can achieve domain-driven generation in intra-category (c); cross-category (d); extra attribute (e); and personalization (f) scenarios.", "description": "This figure illustrates the four scenarios where DomainGallery excels: intra-category, cross-category, extra attribute, and personalization.  It showcases how DomainGallery, given a few examples (few-shot learning), can generate images that match a particular artistic style (sketches), going beyond what standard text-to-image models can achieve.  Sub-figures (a) through (f) demonstrate DomainGallery's capability in these scenarios.", "section": "Introduction"}, {"figure_path": "ZMmJ1z8vee/figures/figures_4_1.jpg", "caption": "Figure 2: An overview of DomainGallery. (a) Before finetuning, we erase the prior attributes of the identifier [V] by matching the predicted noises when using source/target text conditions via Lerase. (b) During fintuning, besides training ordinarily on target datasets (top-left), we additionally impose domain-category attribute disentanglement loss Ldisen (bottom-left) and transfer-based similarity consistency loss Lsim (right). (c) When generating cross-category images, we enhance the domain attributes referred by [V] in a CFG-like manner. Dashed arrows indicate gradient stopping.", "description": "This figure illustrates the pipeline of DomainGallery, which consists of three main steps: prior attribute erasure, finetuning, and inference. In the prior attribute erasure step, the model is trained to remove prior attributes associated with the identifier [V] before finetuning. The finetuning step involves training the model on the target dataset while incorporating additional losses such as domain-category attribute disentanglement and transfer-based similarity consistency loss. Finally, during inference, the model generates images by enhancing the domain attributes of [V] using a classifier-free guidance (CFG) approach. The dashed arrows in the figure denote gradient stopping.", "section": "4 DomainGallery"}, {"figure_path": "ZMmJ1z8vee/figures/figures_7_1.jpg", "caption": "Figure 3: The 10-shot CUFS sketches dataset (left) and the intra-category samples generated by the baselines and DomainGallery with prompt \"a [V] face\" (right).", "description": "This figure shows the results of intra-category image generation on the CUFS sketches dataset.  The left panel displays the 10-shot dataset used for fine-tuning. The right panel presents images generated by different methods: DreamBooth, DreamBooth+LoRA, DomainStudio, and the proposed DomainGallery. All methods used the prompt \"a [V] face\" to generate images in the style of the dataset. This allows for a visual comparison of the methods' ability to reproduce the artistic style and features of the original sketches.", "section": "5.2 Experimental Result"}, {"figure_path": "ZMmJ1z8vee/figures/figures_8_1.jpg", "caption": "Figure 1: Given a few-shot target dataset of a specific domain such as sketches painted by an artist (a), it is usually difficult to directly generate images of this domain using pretrained text-to-image models (b). By using DomainGallery we propose in this work, we can achieve domain-driven generation in intra-category (c); cross-category (d); extra attribute (e); and personalization (f) scenarios.", "description": "This figure illustrates the capabilities of DomainGallery for few-shot domain-driven image generation. It demonstrates the model's ability to generate images within a specific style or domain, even when limited training data is available.  The image showcases several scenarios (intra-category, cross-category, extra attribute, personalization) to highlight the model's flexibility and versatility. (a) shows a few-shot target dataset, (b) depicts failure of a pre-trained model, and (c) to (f) show successful results of DomainGallery.", "section": "1 Introduction"}, {"figure_path": "ZMmJ1z8vee/figures/figures_8_2.jpg", "caption": "Figure 5: Intra-category (top row) and cross-category (middle row) samples with extra attributes given by texts generated by DomainGallery, on CUFS sketches. The bottom row additionally show the case where the text contains conflicting attributes.", "description": "This figure demonstrates the capabilities of DomainGallery in generating images with extra attributes. The top row showcases intra-category generation, where the generated images belong to the same category as the input dataset (CUFS sketches). The middle row shows cross-category generation, where the generated images are of different categories than the input dataset but still maintain the domain-specific style.  The bottom row illustrates a scenario where conflicting attributes are present in the text prompt, resulting in images that blend both attributes.", "section": "5.2 Experimental Result"}, {"figure_path": "ZMmJ1z8vee/figures/figures_9_1.jpg", "caption": "Figure 6: Few-shot subject datasets (left, partially shown) and the personalized samples generated by DomainGallery on CUFS sketches, Van Gogh houses and watercolor dogs.", "description": "This figure demonstrates the personalization capability of DomainGallery.  It shows two examples: one using a dataset of Corgi dogs and another using a dataset of vases. For each example, the leftmost images show the few-shot subject dataset used for finetuning. The subsequent images show the results of generating images with different prompts, demonstrating the ability to generate images that combine both domain-specific style and subject-specific characteristics. This highlights the method's ability to personalize generated images within the given domain.", "section": "5 Experiment"}, {"figure_path": "ZMmJ1z8vee/figures/figures_14_1.jpg", "caption": "Figure 7: The cross-category samples generated by DomainGallery without prior attribute erasure (top), DomainGallery without attribute disentanglement (middle), and the full DomainGallery (bottom) on CUFS sketches.", "description": "This figure shows the results of cross-category image generation experiments using three different versions of the DomainGallery model. The top row shows results from a model without prior attribute erasure, where unintended attributes appear in the generated images. The middle row displays results from a model without attribute disentanglement, showing a leakage of attributes between the identifier [V] and category [N]. The bottom row illustrates results from the complete DomainGallery model, demonstrating improved performance and successful separation of attributes.", "section": "B.1 Ablation Study"}, {"figure_path": "ZMmJ1z8vee/figures/figures_14_2.jpg", "caption": "Figure 2: An overview of DomainGallery. (a) Before finetuning, we erase the prior attributes of the identifier [V] by matching the predicted noises when using source/target text conditions via Lerase. (b) During fintuning, besides training ordinarily on target datasets (top-left), we additionally impose domain-category attribute disentanglement loss Ldisen (bottom-left) and transfer-based similarity consistency loss Lsim (right). (c) When generating cross-category images, we enhance the domain attributes referred by [V] in a CFG-like manner. Dashed arrows indicate gradient stopping.", "description": "This figure provides a visual overview of the DomainGallery pipeline, which consists of three main steps: (a) Prior Attribute Erasure, where prior attributes associated with the identifier [V] are removed; (b) Finetuning, which involves training on target datasets and applying additional loss functions (Ldisen and Lsim) to improve the model's performance; and (c) Attribute Enhancement, which enhances domain attributes during inference for cross-category image generation.  The diagram uses different colors and shapes to represent various UNet components, LoRA parameters, and loss functions, highlighting the interplay between these elements.", "section": "4 DomainGallery"}, {"figure_path": "ZMmJ1z8vee/figures/figures_15_1.jpg", "caption": "Figure 9: The cross-category samples generated by the three baselines with attribute enhancement (top three rows), by DomainGallery without attribute enhancement (fourth row), and by DomainGallery with attribute enhancement of either VN-N or V-uncond mode (last two rows) on CUFS sketches.", "description": "This figure compares the cross-category image generation results of different methods. The top three rows show the results of three baselines (DreamBooth, DreamBooth+LoRA, and DomainStudio) with attribute enhancement. The fourth row shows the results of DomainGallery without attribute enhancement. The last two rows show the results of DomainGallery with two different attribute enhancement modes (VN-N and V-uncond). All results are generated using CUFS sketches dataset.", "section": "4 DomainGallery"}, {"figure_path": "ZMmJ1z8vee/figures/figures_17_1.jpg", "caption": "Figure 10: The 10-shot datasets (left) and the intra-category samples generated by the baselines and DomainGallery (right), respectively on FFHQ sunglasses (\"a [V] face\"), Van Gogh houses (\"a [V] house\"), watercolor dogs (\"a [V] dog\") and wrecked cars (\"a [V] car\") (from top to bottom).", "description": "This figure shows a comparison of image generation results between the proposed DomainGallery method and baseline methods (DreamBooth, DreamBooth+LoRA, and DomainStudio) on four different datasets.  Each dataset contains 10 images representing a specific domain (FFHQ sunglasses, Van Gogh houses, watercolor dogs, and wrecked cars).  The left side displays the original 10 images from each dataset, while the right displays images generated using different methods, all prompted with the text corresponding to the domain (e.g., \"a [V] face\" for the sunglasses dataset). The comparison aims to demonstrate DomainGallery's superior ability to generate images that accurately reflect the style and characteristics of each specific domain.", "section": "5.2 Experimental Result"}, {"figure_path": "ZMmJ1z8vee/figures/figures_18_1.jpg", "caption": "Figure 1: Given a few-shot target dataset of a specific domain such as sketches painted by an artist (a), it is usually difficult to directly generate images of this domain using pretrained text-to-image models (b). By using DomainGallery we propose in this work, we can achieve domain-driven generation in intra-category (c); cross-category (d); extra attribute (e); and personalization (f) scenarios.", "description": "This figure shows examples of domain-driven image generation using the proposed DomainGallery method. It demonstrates the ability of DomainGallery to generate images in various scenarios, including intra-category generation, cross-category generation, extra attribute addition, and personalization, starting from a few-shot target dataset of a specific domain (e.g., sketches). The figure highlights the challenges in directly generating images of a specific domain using pretrained text-to-image models and how DomainGallery addresses these challenges.", "section": "Introduction"}]