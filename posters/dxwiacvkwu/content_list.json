[{"type": "text", "text": "Divide-and-Conquer Predictive Coding: a Structured Bayesian Inference Algorithm ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Eli Sennesh1, Hao $\\mathbf{W}\\mathbf{u}^{2}$ , Tommaso Salvatori2,3 ", "page_idx": 0}, {"type": "text", "text": "1Department of Psychology, Vanderbilt University, Nashville, TN, USA 2VERSES AI Research Lab, Los Angeles, USA 3Vienna University of Technology, Vienna, Austria eli.sennesh@vanderbilt.edu, wuhaomxhy@gmail.com, tommaso.salvatori@verses.ai ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Unexpected stimuli induce \u201cerror\u201d or \u201csurprise\u201d signals in the brain. The theory of predictive coding promises to explain these observations in terms of Bayesian inference by suggesting that the cortex implements variational inference in a probabilistic graphical model. However, when applied to machine learning tasks, this family of algorithms has yet to perform on par with other variational approaches in high-dimensional, structured inference problems. To address this, we introduce a novel predictive coding algorithm for structured generative models, that we call divide-and-conquer predictive coding (DCPC); it differs from other formulations of predictive coding, as it respects the correlation structure of the generative model and provably performs maximum-likelihood updates of model parameters, all without sacrificing biological plausibility. Empirically, DCPC achieves better numerical performance than competing algorithms and provides accurate inference in a number of problems not previously addressed with predictive coding. We provide an open implementation of DCPC in Pyro on Github. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In recent decades, the fields of cognitive science, machine learning, and theoretical neuroscience have borne witness to a flowering of successes in modeling intelligent behavior via statistical learning. Each of these fields has taken a different approach: cognitive science has studied probabilistic inverse inference [Chater et al., 2006, Pouget et al., 2013, Lake et al., 2017] in models of each task and environment, machine learning has employed the backpropagation of errors [Rumelhart et al., 1986, Lecun et al., 2015, Schmidhuber, 2015], and neuroscience has hypothesized that predictive coding (PC) [Srinivasan et al., 1982, Rao and Ballard, 1999, Friston, 2005, Bastos et al., 2012, Spratling, 2017, Hutchinson and Barrett, 2019, Millidge et al., 2021] may explain neural activity in perceptual tasks. These approaches share in common a commitment to \u201cdeep\u201d models, in which task processing emerges from the composition of elementary units. ", "page_idx": 0}, {"type": "text", "text": "In machine learning, PC-based algorithms have recently gained popularity for their theoretical potential to provide a more biologically plausible alternative to backpropagation for training neural networks [Salvatori et al., 2023, Song et al., 2024]. However, PC does not perform comparably in these tasks to backpropagation due to limitations in current formulations. First, predictive coding for gradient calculation typically models every node in the computation graph with a Gaussian, and hence fails to express many common generative models. Recent work on PC has addressed this by allowing approximating non-Gaussian energy functions with samples [Pinchetti et al., 2022]. Second, the Laplace approximation to the posterior infers only a maximum-a-posteriori (MAP) estimate and Gaussian covariance for each latent variable, keeping PC from capturing multimodal or correlated distributions. Third, this loose approximation to the posterior distribution results in inaccurate, high-variance updates to the parameters of the generative model. ", "page_idx": 0}, {"type": "image", "img_path": "dxwIaCVkWU/tmp/f835bd44fc45a90da4f976ae4ba462777cc3983dff9eb9f10f594481e19f62e1.jpg", "img_caption": ["Figure 1: Left: Classical PC learns a mean-field approximate posterior with prediction error layers. Right: Divide-and-conquer PC approximates the joint posterior with bottom-up and recurrent errors. Where classical predictive coding has layers communicate through shared error units, divide-andconquer predictive coding separates recurrent from \u201cbottom-up\u201d error pathways to target complete conditional distributions rather than posterior marginal distributions. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "In this work we propose a new algorithm, divide-and-conquer predictive coding (DCPC), for approximating structured target distributions with populations of Monte Carlo samples. DCPC goes beyond Gaussian assumptions, and decomposes the problem of sampling from structured targets into local coordinate updates to individual random variables. These local updates are informed by unadjusted Langevin proposals parameterized in terms of biologically plausible prediction errors. Nesting the local updates within divide-and-conquer Sequential Monte Carlo [Lindsten et al., 2017, Kuntz et al., 2024] ensures that DCPC can target any statically structured graphical model, while Theorem 2 provides a locally factorized way to learn model parameters by maximum marginal likelihood. ", "page_idx": 1}, {"type": "text", "text": "DCPC also provides a computational perspective on the canonical cortical microcircuit [Bastos et al., 2012, 2020, Campagnola et al., 2022] hypothesis in neuroscience. Experiments have suggested that deep laminar layers in the cortical microcircuit represent sensory imagery, while superficial laminar represent raw stimulus information [Bergmann et al., 2024]; experiments in a predictive coding paradigm specifically suggested that the deep layers represent \u201cpredictions\u201d while the shallow layers represent \u201cprediction errors\u201d. This circuitry could provide the brain with its fast, scalable, generic Bayesian inference capabilities. Figure 1 compares the computational structure of DCPC with that of previous PC models. The following sections detail the contributions of this work: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Section 3 defines the divide-and-conquer predictive coding algorithm and shows how to use it as a variational inference algorithm;   \n\u2022 Section 4 examines under what assumptions the cortex could plausibly implement DCPC, proving two theorems that contribute to biological plausibility;   \n\u2022 Section 5 demonstrates DCPC experimentally in head-to-head comparisons against recent generative models and inference algorithms from the predictive coding literature. ", "page_idx": 1}, {"type": "text", "text": "Section 2 will review the background for Section 3\u2019s algorithm: the problem predictive coding aims to solve and a line of recent work adressing that problem from which this paper draws. ", "page_idx": 1}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "This section reviews the background necessary to construct the divide-and-conquer predictive coding algorithm in Section 3. Let us assume we have a directed, acyclic graphical model with a joint density split into observations $x\\in\\mathbf{x}$ and latents $z\\in\\mathbf{z}$ , parameterized by some $\\theta$ at each conditional density ", "page_idx": 1}, {"type": "equation", "text": "$$\np_{\\theta}(\\mathbf{x},\\mathbf{z}):=\\prod_{x\\in\\mathbf{x}}p_{\\theta}(x\\mid\\mathrm{Pa}(x))\\prod_{z\\in\\mathbf{z}}p_{\\theta}(z\\mid\\mathrm{Pa}(z)),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\operatorname{Pa}(z)$ denotes the parents of the random variable $z\\in\\mathbf{z}$ and $\\operatorname{Ch}(z)$ denotes its children. ", "page_idx": 1}, {"type": "text", "text": "Empirical Bayes Empirical Bayes consists of jointly estimating, in light of the data, both the parameters $\\theta^{*}$ and the Bayesian posterior over the latent variables $\\mathbf{z}$ , that is: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\theta^{*}=\\arg\\operatorname*{max}_{\\theta}p_{\\theta}(\\mathbf{x})=\\arg\\operatorname*{max}_{\\theta}\\int_{z\\in{\\mathcal{Z}}}\\ p_{\\theta}(\\mathbf{x},\\mathbf{z})\\,d\\mathbf{z},\\qquad\\quad p_{\\theta^{*}}(\\mathbf{z}\\mid\\mathbf{x}):={\\frac{p_{\\theta^{*}}(\\mathbf{x},\\mathbf{z})}{p_{\\theta^{*}}(\\mathbf{x})}}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Typically the marginal and posterior densities have no closed form, so learning and inference algorithms treat the joint distribution as a closed-form unnormalized density over the latent variables; its integral then gives the normalizing constant for approximation ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\gamma_{\\theta}(\\mathbf{z}):=p_{\\theta}(\\mathbf{x,z}),\\qquad\\quad Z_{\\theta}:=\\int_{\\mathbf{z}\\in\\mathcal{Z}}\\ \\gamma_{\\theta}(\\mathbf{z})\\ d\\mathbf{z}=p_{\\theta}(\\mathbf{x}),\\qquad\\quad\\pi_{\\theta}(\\mathbf{z}):=\\frac{\\gamma_{\\theta}(\\mathbf{z})}{Z_{\\theta}}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Neal and Hinton [1998] reduced empirical Bayes to minimization of the variational free energy: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{F}(\\theta,q):=\\mathbb{E}_{\\mathbf{z}\\sim q(\\mathbf{z})}\\left[-\\log\\frac{\\gamma_{\\theta}(\\mathbf{z})}{q(\\mathbf{z})}\\right]\\geq-\\log Z(\\theta).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The ratio of densities in Equation 2 is an example of a weight used to approximate a distribution known only up to its normalizing constant. The proposal distribution $q(\\mathbf{z})$ admits tractable sampling, while the unnormalized target density $\\gamma_{\\theta}(\\mathbf{z})$ admits tractable, pointwise density evaluation. ", "page_idx": 2}, {"type": "text", "text": "Predictive Coding Computational neuroscientists now often hypothesize that predictive coding (PC) can optimize the above family of objective functionals in a local, neuronally plausible way [Millidge et al., 2021, 2023]. More in detail, it is possible to define this class of algorithms as follows: ", "page_idx": 2}, {"type": "text", "text": "Definition 1 (Predictive Coding Algorithm). Consider approximate inference in a model $p_{\\theta}(\\mathbf{x},\\mathbf{z})$ using an algorithm $\\mathcal{A}$ . Salvatori et al. [2023] calls $\\mathcal{A}\\,a$ predictive coding algorithm if and only if: ", "page_idx": 2}, {"type": "text", "text": "Particle Algorithms In contrast to predictive coding, particle algorithms approach empirical Bayes problems by setting the proposal to a collection of weighted particles $(w^{k},\\mathbf z^{k})$ drawn from a sampling algorithm meeting certain conditions (see Definition 4 in Appendix B). Any proposal meeting these conditions (see Proposition 1 in Appendix B and Naesseth et al. [2015], Stites et al. [2021]) defines a free energy functional, analogous to Equation 2 in upper-bounding the model surprisal: ", "page_idx": 2}, {"type": "equation", "text": "$$\n{\\mathcal{F}}(\\theta,q):=\\mathbb{E}_{w,\\mathbf{z}\\sim q(w,\\mathbf{z})}\\left[-\\log w\\right]\\implies{\\mathcal{F}}(\\theta,q)\\geq-\\log Z(\\theta).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "This paper builds on the particle gradient descent (PGD) algorithm of Kuntz et al. [2023], that works   \ntahs ef toallrogewts l: ogA-td eeancsiht yit ewriatthi oan $t$ e, arPnGinDg  driaftfeu sa nthd ei npdaertpieclned eclnot uGd $\\begin{array}{r}{q_{K}(\\mathbf{z})\\,=\\,\\frac{1}{K}\\sum_{k=1}^{K}\\delta_{\\mathbf{z}^{k}}(\\mathbf{z})}\\end{array}$ taecsr tohses $\\eta$   \nparameters $\\theta$ by ascending the gradient of the log-likelihood, estimated by averaging over the particles.   \nThe update rules are then the following: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{z}^{t+1,k}:=\\mathbf{z}^{t,k}+\\eta\\nabla_{\\mathbf{z}}\\log\\gamma_{\\theta^{t}}(\\mathbf{z}^{t,k})+\\sqrt{2\\eta}\\xi^{k},}\\\\ &{\\theta^{t+1}:=\\theta^{t}+\\eta\\left(\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\nabla_{\\theta}\\log\\gamma_{\\theta^{t}}(\\mathbf{z}^{t+1,k})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The above equations target the joint density of an entire graphical model1. When the prior $p_{\\theta}(\\mathbf{z})$ factorizes into many separate conditional densities, achieving high inference performance often requires factorizing the inference network or algorithm into conditionals as well [Webb et al., 2018]. Estimating the gradient of the entire log-joint, as in PGD and amortized inference [Dasgupta et al., 2020, Peters et al., 2024], also requires nonlocal backpropagation. To provide a generic inference algorithm for high-dimensional, structured models using only local computations, Section 3 will apply Equation 3 to sample individual random variables in a joint density, combine the coordinate updates via sequential Monte Carlo, and locally estimate gradients for model parameters via Equation 4. ", "page_idx": 2}, {"type": "text", "text": "3 Divide-and-Conquer Predictive Coding ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The previous section provided a mathematical toolbox for constructing Monte Carlo algorithms based on gradient updates and a working definition of predictive coding. This section will combine those ", "page_idx": 2}, {"type": "table", "img_path": "dxwIaCVkWU/tmp/67c753a9567082c3b832cef167f529256d02f48554aab3b9b83eb9063ac91b93.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "Table 1: Comparison of divide-and-conquer predictive coding (DCPC) against other predictive coding algorithms. DCPC provides the greatest flexibility: arbitrary differentiable generative models, an empirical approximation to the posterior, and sampling according to the target\u2019s conditional structure. tools to generalize the above notion of predictive coding, yielding the novel divide-and-conquer predictive coding (DCPC) algorithm. Given a causal graphical model, DCPC will approximate the posterior with a population $q(\\mathbf{z})$ of $K$ samples, while also learning $\\theta$ explaining the data. This will require deriving local coordinate updates and then parameterizing them in terms of prediction errors. Let us assume we again have a causal graphical model $p_{\\theta}(\\mathbf{x},\\mathbf{z})$ locally parameterized by $\\theta$ and factorized (as in Equation 1) into conditional densities for each $x\\in\\mathbf{x}$ and $z\\in\\mathbf{z}$ . DCPC then requires two hyperparameters: a learning rate $\\eta\\in\\mathbb{R}^{+}$ , and particle count $K\\in\\mathbb{N}^{+}$ , and is initialized (at $t=0$ ) via a population of predictions by ancestor sampling defined as $\\begin{array}{r}{\\mathbf{z}^{0}\\sim\\prod_{z\\in\\mathbf{z}}p_{\\theta}(z^{0}\\mid\\operatorname{Pa}(z^{0}))}\\end{array}$ . DCPC aims to minimize the variational free energy (Equation 2). The optimal proposal $q_{*}$ for each random variable would equal, if it had closed form, the complete conditional density for that variable, containing all information from other random variables ", "page_idx": 3}, {"type": "equation", "text": "$$\nq_{*}(\\mathbf{z}^{t}\\mid\\mathbf{z}^{t-1})\\propto\\gamma_{\\theta}(z;\\mathbf{z}_{\\backslash z})=p_{\\theta}(z\\mid\\mathrm{Pa}(z))\\prod_{v\\in\\mathrm{Ch}(z)}p_{\\theta}(v\\mid\\mathrm{Pa}(v)).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We observe that the prediction errors $\\varepsilon_{z}$ in classical predictive coding, usually defined as the precision weighted difference between predicted and actual value of a variable, can be seen as the score function of a Gaussian, where the score is the gradient with respect to the parameter $z$ of the log-likelihood: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\varepsilon_{z}:=\\nabla_{z}\\log\\mathcal{N}(z,\\tau)=\\tau\\left(x-z\\right);\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "When given the ground-truth parameter $z$ , the expected score function $\\mathbb{E}_{x\\sim p(x|z)}\\left[\\nabla_{z}\\log p(x\\mid z)\\right]$ under the likelihood becomes zero, making score functions a good candidate for implementing predictive coding. We therefore define $\\varepsilon_{z}$ in DCPC as the complete conditional\u2019s score function ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\varepsilon_{z}:=\\nabla_{z}\\log\\gamma_{\\theta}(z;\\mathbf{z}_{\\mid z})=\\nabla_{z}\\log p_{\\theta}(z\\mid\\mathrm{Pa}(z))+\\sum_{v\\in\\mathrm{Ch}(z)}\\nabla_{z}\\log p_{\\theta}(v\\mid\\mathrm{Pa}(v)).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This gradient consists of a sum of local prediction-error terms: one for the local \u201cprior\u201d on $z$ and one for each local \u201clikelihood\u201d of a child variable. By defining the prediction error as a sum of local score functions, we write Equation 3 in terms of $\\varepsilon_{z}$ (Equation 6) and the preconditioner of Definition 3: ", "page_idx": 3}, {"type": "equation", "text": "$$\nq_{\\eta}(z^{t}\\mid\\varepsilon_{z}^{t},z^{t-1}):=\\mathcal{N}\\left(z^{t-1}+\\eta\\hat{\\Sigma}_{\\mathcal{Z}}\\varepsilon_{z}^{t},2\\eta\\hat{\\Sigma}_{\\mathcal{Z}}\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The resulting proposal now targets the complete conditional density (Equation 5), simultaneously meeting the informal requirement of Definition 1 for purely local proposal computations while also \u201cdividing and conquering\u201d the sampling problem into lower-dimensional coordinate updates. ", "page_idx": 3}, {"type": "text", "text": "Since the proposal from which we can sample by predictive coding is not the optimal coordinate update, we importance weight for the true complete conditional distribution that is optimal ", "page_idx": 3}, {"type": "equation", "text": "$$\nz^{t}\\sim q_{\\eta}(z^{t}\\mid z^{t-1},\\varepsilon_{z}^{t})\\qquad\\qquad\\qquad u_{z}^{t}={\\frac{\\gamma_{\\theta^{t-1}}(z^{t};\\mathbf{z}_{\\backslash z})}{q_{\\eta}(z^{t}\\mid z^{t-1},\\varepsilon_{z}^{t})}};\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "resampling with respect to these weights corrects for discretization error, yields particles distributed according to the true complete conditional, and estimates the complete conditional\u2019s normalizer ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{RESAMPLE}\\left(z^{t},u_{z}^{t}\\right)\\sim\\pi_{\\theta^{t-1}}(z^{t}\\mid\\mathbf{z}_{\\backslash z}),\\quad\\quad\\quad\\quad\\hat{Z}_{\\theta^{t-1}}(\\mathbf{z}_{\\backslash z})^{t}:=\\frac{1}{K}\\sum_{k=1}^{K}u_{z}^{t,k}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The recursive step of \u201cDivide and Conquer\u201d Sequential Monte Carlo [Lindsten et al., 2017, Kuntz et al., 2024] exploits the estimates $\\hat{Z}_{\\theta^{t-1}}(\\mathbf{z}_{\\setminus z})^{t}$ to weigh the samples for the complete target density ", "page_idx": 3}, {"type": "equation", "text": "$$\nw_{\\theta^{t-1}}^{t}=\\frac{p_{\\theta^{t-1}}(\\mathbf{x},\\mathbf{z}^{t})}{\\prod_{z\\in\\mathbf{z}}\\gamma_{\\theta}(z^{t};\\mathbf{z}_{\\backslash z})}\\prod_{z\\in\\mathbf{z}}\\hat{Z}_{\\theta^{t-1}}(\\mathbf{z}_{\\backslash z})^{t}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Algorithm 1 Divide-and-Conquer Predictive Coding for empirical Bayes ", "page_idx": 4}, {"type": "text", "text": "Require: learning rate $\\eta\\in\\mathbb{R}^{+}$ , particle count $K\\in\\mathbb N$ , number of sweeps $S\\in\\mathbb{N}$   \nRequire: initial particle vector $\\bar{\\mathbf{z}^{0}}$ , initial parameters $\\theta^{0}$ , observations $\\mathbf{x}\\in\\mathcal{X}$   \n1: for $t\\in[1\\ldots T]$ do $\\triangleright$ Loop through predictive coding steps   \n2: for $\\bar{s}\\in[1\\ldots S]$ do \u25b7Loop through Gibbs sweeps over graphical model   \n3: for $z\\in\\mathbf{z}$ do \u25b7Loop through latent variables in graphical model   \n4: $\\varepsilon_{z}\\gets\\nabla_{\\mathbf{z}}\\log p_{\\theta^{t-1}}(z\\mid\\mathrm{Pa}(z))$ $\\triangleright$ Local prediction error   \n5: \u03b5z \u2190\u03b5z +  v\u2208Ch(z) \u2207z log p\u03b8t\u22121(v | Pa(v)) \u25b7Children\u2019s prediction errors   \n6: \u03a3\u02c6I \u2190 d1 TI\u02c6r[KI\u02c6(K\u03b51z(:\u03b5K1z:)K\u2212)1\u22121] \u25b7Estimate precision of prediction errors   \n7: zt \u223cq\u03b7(zt | \u03b5z, zt\u22121) \u25b7Sample coordinate update   \n8: ut \u2190 \u03b3\u03b8t\u22121(zt;z\\z) q\u03b7(zt|\u03b5z,zt\u22121) $\\triangleright$ Correct coordinate update by weighing   \n9: zt \u2190RESAMPLE (zt, utz) \u25b7Resample from true coordinate update   \n10: Z\u02c6\u03b8t\u22121(z\\z)t \u2190K1 kK=1 utz,k \u25b7Estimate coordinate update\u2019s normalizer   \n11: Ft \u2190\u2212K1  kK=1 log  z\u2208pz \u03b8\u03b3t\u03b8\u2212t1\u2212(1x(,zzt,k;)zt\\,zk ) z\u2208z Z\u02c6\u03b8t\u22121(z\\z)t \u25b7Update free energy   \n12: \u03b8t \u2190\u03b8t\u22121 + \u03b7 K1  kK=1 \u2207\u03b8t\u22121 log p\u03b8t\u22121(x, zt,k) \u25b7Update parameters   \n13: return zT , \u03b8T , FT \u25b7Output: updated particles, parameters, free energy ", "page_idx": 4}, {"type": "text", "text": "By Proposition 1, log-transforming these weights estimates the free energy (Equation 2): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}^{t}({\\mathbf{z}}^{t-1},\\theta^{t-1}):=\\mathbb{E}_{q\\ast({\\mathbf{z}}^{t}\\mid{\\mathbf{z}}^{t-1})}\\left[-\\log\\frac{p_{\\theta^{t-1}}\\left({\\mathbf{x}},{\\mathbf{z}}^{t}\\right)}{q_{\\ast}\\left({\\mathbf{z}}^{t}\\mid{\\mathbf{z}}^{t-1}\\right)}\\right]\\approx\\mathbb{E}_{q}\\left[-\\log w_{\\theta^{t-1}}^{t}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Theorem 3 in Appendix B shows that the gradient $\\nabla_{\\theta^{t-1}}\\mathcal{F}^{t}=\\mathbb{E}_{q}\\left[-\\nabla_{\\theta^{t-1}}\\log p_{\\theta^{t-1}}(\\mathbf{x},\\mathbf{z}^{t})\\right]$ of the above estimator equals the expected gradient of the log-joint distribution. Descending this gradient $\\theta^{t}:=\\theta^{t-1}-\\eta\\nabla_{\\theta^{t-1}}\\bar{\\mathcal{F}}^{t}$ enables DCPC to learn model parameters $\\theta$ . ", "page_idx": 4}, {"type": "text", "text": "The above steps describe a single pass of divide-and-conquer predictive coding over a causal graphical model. Algorithm 1 shows the complete algorithm, consisting of nested iterations over latent variables $z\\in\\mathbf{z}$ (inner loop) and iterations $t\\in T$ (outer loop). DCPC satisfies criteria (1) and (2) of Definition 1, and relaxes criterion (3) to allow gradient-based proposals beyond the Laplace assumption. As with Pinchetti et al. [2022] and Oliviers et al. [2024], relaxing the Laplace assumption enables much greater flexibility in approximating the model\u2019s true posterior distribution. ", "page_idx": 4}, {"type": "text", "text": "4 Biological plausibility ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Different works in the literature consider different criteria for biological plausibility. This paper follows the non-spiking predictive coding literature and considers an algorithm biologically plausible if it performs only spatially local computations in a probabilistic graphical model [Whittington and Bogacz, 2017], without requiring a global control of computation. However, while in the standard literature locality is either directly defined in the objective function [Rao and Ballard, 1999], or derived from a mean-field approximation to the joint density [Friston, 2005], showing that the updates of the parameters of DCPC require only local information is not as trivial. To this end, in this section we first formally show that DCPC achieves decentralized inference of latent variables $\\mathbf{z}$ (Theorem 1), and then that also the parameters $\\theta$ are updated via local information (Theorem 2). ", "page_idx": 4}, {"type": "text", "text": "Gibbs sampling provides the most widely-used algorithm for sampling from a high-dimensional probability distribution by local signaling. It consists of successively sampling coordinate updates to individual nodes in the graphical model by targeting their complete conditional densities $\\bar{\\pi}_{\\theta}(z\\mid$ $\\mathbf{x},\\mathbf{z}_{\\setminus z})$ . Theorem 1 demonstrates that DCPC\u2019s coordinate updates approximate Gibbs sampling. ", "page_idx": 4}, {"type": "text", "text": "Theorem 1 (DCPC coordinate updates sample from the true complete conditionals). Each DCPC coordinate update (Equation 7) for a latent $z\\ \\in\\textbf{z}$ samples from $z$ \u2019s complete conditional (the normalization of Equation 5). Formally, for every measurable $h:{\\mathcal{Z}}\\to\\mathbb{R},$ , resampled expectations with respect to the DCPC coordinate update equal those with respect to the complete conditional ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim q\\eta(z\\mid z^{t-1},\\varepsilon_{z}^{t})}\\left[\\mathbb{E}_{u\\sim\\delta(u),z^{\\prime}\\sim\\mathrm{RESAMPLE}(z,u_{z})}\\left[h(z)\\right]\\right]=\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\pi_{\\theta}(z\\mid\\mathbf{z}_{\\backslash z})\\,d z.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We follow the canonical cortical microcircuit hypothesis of predictive coding [Bastos et al., 2012, Gillon et al., 2023] or predictive routing [Bastos et al., 2020]. Consider a cortical column representing $z\\in\\textbf{z}$ ; the $\\theta$ , $\\alpha/\\beta$ , and $\\gamma$ frequency bands of neuronal oscillations [Buzs\u00e1ki and Draguhn, 2004] could synchronize parallelizations (known to exist for simple Gibbs sampling in a causal graphical model [Gonzalez et al., 2011]) of the loops in Algorithm 1. From the innermost to the outermost and following the neurophysiological findings of Bastos et al. [2015], Fries [2015], $\\gamma$ -band oscillations could synchronize the bottom-up conveyance of prediction errors (lines 4-6) from L2/3 of lower cortical columns to L4 of higher columns, $\\beta$ -band oscillations could synchronize the top-down conveyance of fresh predictions (implied in passing from $s$ to $s+1$ in the loop of lines 2-9) from $L5/6$ of higher columns to ${\\mathrm{L}}1{+}{\\mathrm{L}}6$ of lower columns, and $\\theta$ -band oscillations could synchronize complete attention-directed sampling of stimulus representations (lines 1-11). Figure 5 in Appendix A visualizes these hypotheses for how neuronal areas and connections could implement DCPC. ", "page_idx": 5}, {"type": "text", "text": "Biological neurons often spike to represent changes in their membrane voltage [Mainen and Sejnowski, 1995, Lundstrom et al., 2008, Forkosh, 2022], and some have even been tested and found to signal the temporal derivative of the logarithm of an underlying signal [Adler and Alon, 2018, Borba et al., 2021]. Theorists have also proposed models [Chavlis and Poirazi, 2021, Moldwin et al., 2021] under which single neurons could calculate gradients internally. In short, if neurons can represent probability densities, as many theoretical proposals and experiments suggest they can, then they can likely also calculate the prediction errors used in DCPC. Theorem 2 will demonstrate that given the \u201cfactorization\u201d above, DCPC\u2019s model learning requires only local prediction errors. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2 (DCPC parameter learning requires only local gradients in a factorized generative model). Consider a graphical model factorized according to Equation $^{\\,l}$ , with the additional assumption that the model parameters $\\begin{array}{r}{\\partial\\stackrel{\\cdot}{\\in}\\Theta=\\prod_{x\\in{\\bf x}}\\Theta_{x}\\times\\overline{{\\prod_{z\\in{\\bf z}}}}\\overline{{\\Theta_{z}}}}\\end{array}$ factorize disjointly. Then the gradient $\\nabla_{\\theta}\\mathcal{F}(\\theta,q)$ of DCPC\u2019s free energy similarly factorizes into a sum of local particle averages ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}\\mathcal{F}=\\mathbb{E}_{q}\\left[-\\nabla_{\\theta}\\log p_{\\theta}(\\mathbf{x},\\mathbf{z})\\right]\\approx-\\sum_{v\\in(\\mathbf{x},\\mathbf{z})}\\frac{1}{K}\\sum_{k=1}^{K}\\nabla_{\\theta_{v}}\\log p_{\\theta_{v}}(v^{k}\\mid\\mathrm{Pa}(v)^{k}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Proof. See Proposition 5 in Appendix B. ", "page_idx": 5}, {"type": "text", "text": "Our practical implementation of DCPC, evaluated in the experiments above, takes advantage of Theorem 2 to save memory by detaching samples from the automatic differentiation graph in the forward ancestor-sampling pass through the generative model. ", "page_idx": 5}, {"type": "text", "text": "Finally, DCPC passes from local coordinate updates to the joint target density via an importance resampling operation, requiring that implementations synchronously transmit numerical densities or log-densities for the freshly proposed particle population. While phase-locking to a cortical oscillation may make this biologically feasible, resampling then requires normalizing the weights. Thankfully, divisive normalization appears ubiquitously throughout the brain [Carandini and Heeger, 2012], as well as just the type of \u201cwinner-take-all\u201d circuit that implements a softmax function (e.g. for normalizing and resampling importance weights) being ubiquitous in crosstalk between superficial and deep layers of the cortical column [Liu, 1999, Douglas and Martin, 2004]. ", "page_idx": 5}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Divide-and-conquer predictive coding is not the first predictive coding algorithm to incorporate sampling into the inference process, and certainly not the first variational inference algorithm for structured graphical models. This section therefore evaluates DCPC\u2019s performance against both models from the predictive coding literature and against a standard deep generative model. Each experiment holds the generative model, dataset, and hyperparameters constant except where noted. ", "page_idx": 5}, {"type": "text", "text": "We have implemented DCPC as a variational proposal or \u201cguide\u201d program in the deep probabilistic programming language Pyro [Bingham et al., 2019]; doing so enables us to compute free energy and prediction errors efficiently in graphical models involving neural networks. Since the experiments below involve minibatched subsampling of observations $\\textbf{x}\\sim\\ B$ from a dataset $\\mathcal{D}\\,\\sim\\,p(\\mathcal{D})$ of unknown distribution, we replace Equation 9 with a subsampled form (see Welling and Teh [2011] for derivation) of the variational Sequential Monte Carlo gradient estimator [Naesseth et al., 2018] ", "page_idx": 5}, {"type": "table", "img_path": "dxwIaCVkWU/tmp/3f5e5fe9e099e1290a63faa355d1a5bc9cca18c98fb47e48633d4e38cf06970e.jpg", "table_caption": [], "table_footnote": ["Table 2: Negative log-likelihood and mean squared error for MCPC against DCPC on held-out images from the MNISTs. Means and standard deviations are taken across five random seeds. "], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}\\mathcal{F}\\approx|\\mathcal{D}|\\mathbb{E}_{\\mathcal{B}\\sim p(\\mathcal{D})}\\left[\\frac{1}{|\\mathcal{B}|}\\sum_{\\mathbf{x}^{b}\\in\\mathcal{B}}\\mathbb{E}_{(\\mathbf{z},w)^{1:K}\\sim q}\\left[\\log\\left(\\frac{1}{K}\\sum_{k=1}^{K}w^{k}\\right)\\mid\\mathbf{x}^{b}\\right]\\right].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "We optimized the free energy in all experiments using Adam [Kingma and Ba, 2014], making sure to call detach() after every Pyro sample() operation to implement the purely local gradient calculations of Theorem 2 and Equation 10. The first experiment below considers a hierarchical Gaussian model on three simple datasets. The model consists of two latent codes above an observation. ", "page_idx": 6}, {"type": "text", "text": "Deep latent Gaussian models with predictive coding Oliviers et al. [2024] brought together predictive coding with neural sampling hypotheses in a single model: Monte Carlo predictive coding (MCPC). Their inference algorithm functionally backpropagated the score function of a log-likelihood, applying Langevin proposals to sample latent variables from the posterior joint density along the way. They evaluated MCPC\u2019s performance on MNIST with a deep latent Gaussian model [Rezende et al., 2014] (DLGM). Their model\u2019s conditional densities consisted of nonlinearities followed by linear transformations to parameterize the mean of each Gaussian conditional, with learned covariances. Figure 2 shows that the DLGM structure already requires DCPC to respect hierarchical dependencies. ", "page_idx": 6}, {"type": "text", "text": "We tested DCPC\u2019s performance on elementary reconstruction and generation tasks by using it to train this exact generative model, changing only the likelihood from a discrete Bernoulli to a continuous Bernoulli [Loaiza-Ganem and Cunningham, 2019]. After training we evaluated with a discrete Bernoulli likelihood. Table 2 shows that in terms of both surprise (negative log evidence, with the discrete Bernoulli likelihood) and mean squared reconstruction error, DCPC enjoys better average performance with a lower standard deviation of performance, the latter by an order of magnitude. All experiments used a learning rate $\\eta=0.1$ and $K=4$ particles. ", "page_idx": 6}, {"type": "image", "img_path": "dxwIaCVkWU/tmp/45953143886f7e61c449836de310eb603d36b9815eb403118a68e46ee772ecb4.jpg", "img_caption": ["Figure 2: Hierarchical graphical model for DLGM\u2019s. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 3 shows an extension of this experiment to EMNIST [Cohen et al., 2017] and Fashion MNIST [Xiao et al., 2017] as well as the original MNIST, with ground-truth images in the top row and their reconstructions from DCPCinferred latent codes below. The ground-truth images come from a $10\\%$ validation split of each data-set, on which DCPC only infers particles $q_{K=4}(\\mathbf{z})$ . ", "page_idx": 6}, {"type": "text", "text": "The above datasets do not typically challenge a new inference algorithm. The next experiment will thus attempt to learn representations of color images, as in the widely-used variational autoencoder [Kingma and Welling, 2013] framework, without an encoder network or amortized inference. ", "page_idx": 6}, {"type": "text", "text": "Image generation with representation learning Zahid et al. [2024] have also recently designed and evaluated Langevin predictive coding (LPC), with differences from both MCPC and DCPC. ", "page_idx": 6}, {"type": "image", "img_path": "dxwIaCVkWU/tmp/053d5baa9e5d50bf79c6057795ae25b1089a53961a8a8ee12e8b7142a7c7daf5.jpg", "img_caption": [], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Figure 3: Top: images from validation sets of MNIST (left), EMNIST (middle), and Fashion MNIST (right). Bottom: reconstructions by deep latent Gaussian models trained with DCPC for MNIST (left), EMNIST (middle), and Fashion MNIST (right), averaging over $K\\,=\\,4$ particles. DCPC achieves quality reconstructions by inference over $\\mathbf{z}$ without training an inference network. ", "page_idx": 6}, {"type": "table", "img_path": "dxwIaCVkWU/tmp/18f8b4887783288f9eb7c7763041673d5667333cd2a7a8694f2eff2df22c1f5b.jpg", "table_caption": ["Algorithm Likelihood Resolution \u2191 S\u00d7 Epochs \u2193 FID \u2193 "], "table_footnote": ["Table 3: FID score comparisons on the CelebA dataset [Liu et al., 2015]. The score for LPC comes from Figure 2 in Zahid et al. [2024], where they ablated warm-starts and initialized from the prior. "], "page_idx": 7}, {"type": "image", "img_path": "dxwIaCVkWU/tmp/0552fcd17d8d7a565b7eeb46b9f0e3481453ecb69e0ec028cc455069709b92b5.jpg", "img_caption": ["(a) Reconstructions of the CelebA validation set(b) Samples drawn de novo from the posterior preby a generator network trained with DCPC. dictive distribution of the trained network. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 4: Left: reconstructions from the CelebA validation set. Right: samples from the generative model. DCPC achieves quality reconstructions by inference over $\\mathbf{z}$ with $K=16$ particles and no inference network, while the learned generative model captures variation in the data. ", "page_idx": 7}, {"type": "text", "text": "While MCPC sends prediction errors up through a hierarchical model, LPC computed as its prediction error the log-joint gradient for all latent variables in the generative model. This meant that biological plausibility, and their goal of amortizing predictive coding inference, restricted them to single-level decoder adapted from Higgins et al. [2017]. We evaluated with their discretized Gaussian likelihood, taken from Cheng et al. [2020], Ho et al. [2020], learning the variance as in Rybkin et al. [2021]. ", "page_idx": 7}, {"type": "text", "text": "We compare DCPC to LPC using the Frechet Inception Distance (FID) [Seitzer, 2020] featured in Zahid et al. [2024], holding constant the prior, neural network architecture, learning rate on $\\theta$ , and number of gradient evaluations used to train the parameters $\\theta$ and latents $\\mathbf{z}$ . Zahid et al. [2024] evaluated a variety of scenarios and reported that their training could converge quickly when counted in epochs, but they accumulated gradients of $\\theta$ over inference steps. We compare to the results they report after 15 epochs with 300 inference steps applied to latents initialized from the prior, equivalent to $15\\times300=4500$ gradient steps on $\\theta$ per batch, replicating their batch size of 64. Since Algorithm 1 updates $\\theta$ only in its outer loop, we set $S=30$ and ran DCPC for 150 epochs, with $\\eta=0.001$ and $K=16$ . Table 3 shows that DCPC outperforms LPC in apples-to-apples generative quality, though not to the point of matching other model architectures2by inference quality alone. ", "page_idx": 7}, {"type": "text", "text": "Figure 4 shows reconstructed images from the validation set (left) and samples from the posterior predictive generative model (right). There is blurriness in the reconstructions, as often occurs with variational autoencoders, but DCPC training allows the network to capture background color, hair color, direction in which a face is looking, and other visual properties. Figure 4a shows reconstructions over the validation set, while Figure 4b shows samples from the predictive distribution. ", "page_idx": 7}, {"type": "text", "text": "Kuntz et al. [2023] also reported an experiment on CelebA in terms of FID score, at the lower $32\\times32$ resolution. Since they provided both source code and an exact mathematical description, we were able to run an exact, head-to-head comparison with PGD. The line in Table 3 evaluating DCPC with PGD\u2019s example neural architecture at the $32\\times32$ resolution (with similar particle count and learning rate) demonstrates a significant improvement in FID for DCPC, alongside reduced FID variance. ", "page_idx": 7}, {"type": "text", "text": "Necessary Compute Resources The initial DLGM experiments on the MNIST-alike datasets were performed on a desktop workstation with 128GB of RAM and an NVIDIA Quadro P4000 with 8GB of VRAM. Experiments on CelebA were conducted on an NVIDIA DGX equipped with eight (8) NVIDIA A100\u2019s, each with 80GB of VRAM. The latter compute infrastructure was also used for unpublished experiments, on several different datasets, in structured time-series modeling. ", "page_idx": 8}, {"type": "text", "text": "6 Related Work ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Pinchetti et al. [2022] expanded predictive coding beyond Gaussian generative models for the first time, applying the resulting algorithm to train variational autoencoders by variational inference and transformer architectures by maximum likelihood. DCPC, in turn, broadens predictive coding to target arbitrary probabilistic graphical models, following the broadening in Salvatori et al. [2022] to arbitrary deterministic computation graphs. DCPC follows on incremental predictive coding [Salvatori et al., 2024] in quickly alternating between updates to random variables and model parameters, giving an incremental EM algorithm [Neal and Hinton, 1998]. Finally, Zahid et al. [2024] and Oliviers et al. [2024] also recognized the analogy between predictive coding\u2019s prediction errors and the score functions used in Langevin dynamics for continuous random variables. ", "page_idx": 8}, {"type": "text", "text": "There exists a large body of work on how neurobiologically plausible circuits could implement probabilistic inference. Classic work by Shi and Griffiths [2009] provided a biologically plausible implementation of hierarchical inference via importance sampling; DCPC proceeds from importance sampling as a foundation, while parameterizing the proposal distribution via prediction errors. Recent work by Fang et al. [2022] studied neurally plausible algorithms for sampling-based inference with Langevin dynamics, though only for a Gaussian generative model of sparse coding. Golkar et al. [2022] imposed a whitening constraint on a Gaussian generative model for biological plausibility. Finally, Dong and Wu [2023] and Zahid et al. [2024] both suggest mechanisms for employing momentum to reduce gradient noise in a biologically plausible sampling algorithm; the former intriguingly analogize their momentum term to neuronal adaptation. To conclude, other works have already implemented predictive coding models for image generation tasks, a notable example being the neural generative coding framework Ororbia and Kifer [2022], Ororbia and Mali [2022]. ", "page_idx": 8}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "This paper proposed divide-and-conquer predictive coding (DCPC), an algorithm that efficiently and scalably approximates Gibbs samplers by importance sampling; DCPC parameterizes efficient proposals for a model\u2019s complete conditional densities using local prediction errors. Section 4 showed how Monte Carlo sampling can implement a form of \u201cprospective configuration\u201d [Song et al., 2024], first inferring a sample from the joint posterior density (Theorem 1) and then updating the generative model without a global backpropagation pass ( Theorem 2). Experiments in Section 5 showed that DCPC outperforms the state of the art Monte Carlo Predictive Coding from computational neuroscience, head-to-head, on the simple generative models typically considered in theoretical neuroscience; DCPC also outperforms the particle gradient descent algorithm of Kuntz et al. [2023] while under the constraint of purely local computation. DCPC\u2019s Langevin proposals admit the same extension to constrained sample spaces as applied in Hamiltonian Monte Carlo [Brubaker et al., 2012]; our Pyro implementation includes this extension via Pyro\u2019s preexisting support for HMC. ", "page_idx": 8}, {"type": "text", "text": "DCPC offers a number of ways forward. Particularly, this paper employed naive Langevin proposals, while Dong and Wu [2023], Zahid et al. [2024] applied momentum-based preconditioning to take advantage of the target\u2019s geometry. Yin and Ao [2006] demonstrated that gradient flows of this general kind can also provide more efficient samplers by breaking the detailed-balance condition necessary for the Metropolis-Hastings algorithm, motivating the choice of SMC over MCMC to correct proposal bias. Appendix C derives a mathematical background for an extension of DCPC to discrete random variables. Future work could follow Marino et al. [2018], Taniguchi et al. [2022] in using a neural network to iteratively map from particles and prediction errors to proposal parameters. ", "page_idx": 8}, {"type": "text", "text": "7.1 Limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "DCPC\u2019s main limitations are its longer training time, and greater sensitivity to learning rates, than state-of-the-art amortized variational inference trained end-to-end. Such limitations occur frequently in the literature on neuroscience-inspired learning algorithms, as well as in the literature on particlebased algorithms with no parametric form. This work has no singular ethical concerns specific only to DCPC, rather than the broader implications and responsibilities accompanying advancements in biologically plausible learning and Bayesian inference. ", "page_idx": 8}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "E.S. was supported by Vanderbilt Brain Institute Faculty Funds, as well as the Vanderbilt Data Science Institute, through PI Andre Bastos. Hamed Nejat produced the laminar circuitry figure in the supplementary material in conjunction with E.S. H.W. and T.S. were supported through VERSES.AI. E.S. would also like to thank Jan-Willem van de Meent, Karen Quigley, and Lisa Feldman Barrett for the training in approximate inference and predictive processing out of which this paper developed. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Miri Adler and Uri Alon. Fold-change detection in biological systems. Current Opinion in Systems Biology, 8:81\u201389, April 2018. ISSN 2452-3100. doi: 10.1016/j.coisb.2017.12.005. ", "page_idx": 9}, {"type": "text", "text": "Andre M Bastos, Julien Vezoli, and Pascal Fries. Communication through coherence with interareal delays. Current Opinion in Neurobiology, 31:173\u2013180, April 2015. ISSN 09594388. doi: 10.1016/j.conb.2014.11.001. ", "page_idx": 9}, {"type": "text", "text": "Andr\u00e9 M. Bastos, W Martin Usrey, Rick A Adams, George R Mangun, Pascal Fries, and Karl J Friston. Canonical microcircuits for predictive coding. Neuron, 76(4):695\u2013711, 2012. ", "page_idx": 9}, {"type": "text", "text": "Andr\u00e9 M. Bastos, Mikael Lundqvist, Ayan S. Waite, Nancy Kopell, and Earl K. Miller. Layer and rhythm specificity for predictive routing. Proceedings of the National Academy of Sciences, 117 (49):31459\u201331469, December 2020. ISSN 0027-8424, 1091-6490. doi: 10.1073/pnas.2014868117. ", "page_idx": 9}, {"type": "text", "text": "Johanna Bergmann, Lucy S Petro, Clement Abbatecola, Min S Li, A Tyler Morgan, and Lars Muckli. Cortical depth profiles in primary visual cortex for illusory and imaginary experiences. Nature Communications, 15(1):1002, 2024. ", "page_idx": 9}, {"type": "text", "text": "Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, Neeraj Pradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul Horsfall, and Noah D. Goodman. Pyro: Deep universal probabilistic programming. Journal of Machine Learning Research, 20(28):1\u20136, 2019. URL http://jmlr.org/papers/v20/18-403.html. ", "page_idx": 9}, {"type": "text", "text": "Cezar Borba, Matthew J Kourakis, Shea Schwennicke, Lorena Brasnic, and William C Smith. Fold change detection in visual processing. Frontiers in Neural Circuits, 15:705161, 2021. ", "page_idx": 9}, {"type": "text", "text": "Marcus Brubaker, Mathieu Salzmann, and Raquel Urtasun. A family of mcmc methods on implicitly defined manifolds. In Artificial intelligence and statistics, pages 161\u2013172. PMLR, 2012. ", "page_idx": 9}, {"type": "text", "text": "Gy\u00f6rgy Buzs\u00e1ki and Andreas Draguhn. Neuronal oscillations in cortical networks. Science, 304 (5679):1926\u20131929, June 2004. ISSN 0036-8075, 1095-9203. doi: 10.1126/science.1099745. ", "page_idx": 9}, {"type": "text", "text": "Luke Campagnola, Stephanie C. Seeman, Thomas Chartrand, Lisa Kim, Alex Hoggarth, Clare Gamlin, Shinya Ito, Jessica Trinh, Pasha Davoudian, Cristina Radaelli, Mean-Hwan Kim, Travis Hage, Thomas Braun, Lauren Alfiler, Julia Andrade, Phillip Bohn, Rachel Dalley, Alex Henry, Sara Kebede, Alice Mukora, David Sandman, Grace Williams, Rachael Larsen, Corinne Teeter, Tanya L. Daigle, Kyla Berry, Nadia Dotson, Rachel Enstrom, Melissa Gorham, Madie Hupp, Samuel Dingman Lee, Kiet Ngo, Philip R. Nicovich, Lydia Potekhina, Shea Ransford, Amanda Gary, Jeff Goldy, Delissa McMillen, Trangthanh Pham, Michael Tieu, La\u2019Akea Siverts, Miranda Walker, Colin Farrell, Martin Schroedter, Cliff Slaughterbeck, Charles Cobb, Richard Ellenbogen, Ryder P. Gwinn, C. Dirk Keene, Andrew L. Ko, Jeffrey G. Ojemann, Daniel L. Silbergeld, Daniel Carey, Tamara Casper, Kirsten Crichton, Michael Clark, Nick Dee, Lauren Ellingwood, Jessica Gloe, Matthew Kroll, Josef Sulc, Herman Tung, Katherine Wadhwani, Krissy Brouner, Tom Egdorf, Michelle Maxwell, Medea McGraw, Christina Alice Pom, Augustin Ruiz, Jasmine Bomben, David Feng, Nika Hejazinia, Shu Shi, Aaron Szafer, Wayne Wakeman, John Phillips, Amy Bernard, Luke Esposito, Florence D. D\u2019Orazi, Susan Sunkin, Kimberly Smith, Bosiljka Tasic, Anton Arkhipov, Staci Sorensen, Ed Lein, Christof Koch, Gabe Murphy, Hongkui Zeng, and Tim Jarsky. Local connectivity and synaptic dynamics in mouse and human neocortex. Science, 375(6585):eabj5861, 2022. doi: 10.1126/science.abj5861. URL https://www.science.org/doi/abs/10.1126/ science.abj5861. ", "page_idx": 9}, {"type": "text", "text": "Matteo Carandini and David J Heeger. Normalization as a canonical neural computation. Nature reviews neuroscience, 13(1):51\u201362, 2012.   \nNick Chater, Joshua B Tenenbaum, and Alan Yuille. Probabilistic models of cognition: Conceptual foundations. Trends in cognitive sciences, 10(7):287\u2013291, 2006.   \nSpyridon Chavlis and Panayiota Poirazi. Drawing inspiration from biological dendrites to empower artificial neural networks. Current Opinion in Neurobiology, 70:1\u201310, October 2021. ISSN 0959-4388. doi: 10.1016/j.conb.2021.04.007.   \nZhengxue Cheng, Heming Sun, Masaru Takeuchi, and Jiro Katto. Learned image compression with discretized gaussian mixture likelihoods and attention modules. In Proceedings of the 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2020.   \nGregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik. Emnist: Extending mnist to handwritten letters. In 2017 international joint conference on neural networks (IJCNN), pages 2921\u20132926. IEEE, 2017.   \nIshita Dasgupta, Eric Schulz, Joshua B Tenenbaum, and Samuel J Gershman. A theory of learning to infer. Psychological review, 127(3):412, 2020.   \nXingsi Dong and Si Wu. Neural Sampling in Hierarchical Exponential-family Energy-based Models. In Advances in Neural Information Processing Systems, New Orleans, LA, 2023. Curran Associates Inc.   \nRodney J Douglas and Kevan AC Martin. Neuronal circuits of the neocortex. Annu. Rev. Neurosci., 27(1):419\u2013451, 2004.   \nMichael Y-S Fang, Mayur Mudigonda, Ryan Zarcone, Amir Khosrowshahi, and Bruno A Olshausen. Learning and inference in sparse coding models with langevin dynamics. Neural Computation, 34 (8):1676\u20131700, 2022.   \nOren Forkosh. Memoryless optimality: Neurons do not need adaptation to optimally encode stimuli with arbitrarily complex statistics. Neural Computation, 34(12):2374\u20132387, November 2022. ISSN 0899-7667, 1530-888X. doi: 10.1162/neco_a_01543.   \nPascal Fries. Rhythms for cognition: Communication through coherence. Neuron, 88(1):220\u2013235, October 2015. ISSN 0896-6273. doi: 10.1016/j.neuron.2015.09.034.   \nKarl Friston. A theory of cortical responses. Philosophical transactions of the Royal Society B: Biological sciences, 360(1456):815\u2013836, 2005.   \nColleen J. Gillon, Jason E. Pina, J\u00e9r\u00f4me A. Lecoq, Ruweida Ahmed, Yazan N. Billeh, Shiella Caldejon, Peter Groblewski, Timothy M. Henley, India Kato, Eric Lee, Jennifer Luviano, Kyla Mace, Chelsea Nayan, Thuyanh V. Nguyen, Kat North, Jed Perkins, Sam Seid, Matthew T. Valley, Ali Williford, Yoshua Bengio, Timothy P. Lillicrap, Blake A. Richards, and Joel Zylberberg. Learning from unexpected events in the neocortical microcircuit. bioRxiv, 2023. doi: 10.1101/ 2021.01.15.426915. URL https://www.biorxiv.org/content/early/2023/04/06/2021. 01.15.426915.   \nSiavash Golkar, Tiberiu Tesileanu, Yanis Bahroun, Anirvan Sengupta, and Dmitri Chklovskii. Constrained predictive coding as a biologically plausible model of the cortical hierarchy. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 14155\u201314169. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/ 5b5de8526aac159e37ff9547713677ed-Paper-Conference.pdf.   \nJoseph Gonzalez, Yucheng Low, Arthur Gretton, and Carlos Guestrin. Parallel gibbs sampling: From colored fields to thin junction trees. In Geoffrey Gordon, David Dunson, and Miroslav Dud\u00edk, editors, Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, volume 15 of Proceedings of Machine Learning Research, pages 324\u2013332, Fort Lauderdale, FL, USA, 11\u201313 Apr 2011. PMLR. URL https://proceedings.mlr.press/ v15/gonzalez11a.html.   \nIrina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. beta-VAE: Learning basic visual concepts with a constrained variational framework. In International Conference on Learning Representations, 2017. URL https://openreview.net/forum?id $=$ Sy2fzU9gl.   \nJonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Advances in Neural Information Processing Systems, volume 33, page 6840\u20136851. Curran Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper/2020/hash/ 4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html.   \nJ. Benjamin Hutchinson and Lisa Feldman Barrett. The Power of Predictions: An Emerging Paradigm for Psychological Research. Current Directions in Psychological Science, 2019. ISSN 14678721. doi: 10.1177/0963721419831992.   \nDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.   \nDiederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114, 2013.   \nJuan Kuntz, Jen Ning Lim, and Adam M Johansen. Particle algorithms for maximum likelihood training of latent variable models. In Proceedings of the 26th International Conference on Artificial Intelligence and Statistics, volume 206, Valencia, Spain, April 2023. Proceedings of Machine Learning Research.   \nJuan Kuntz, Francesca R. Crucinio, and Adam M. Johansen. The divide-and-conquer sequential Monte Carlo algorithm: Theoretical properties and limit theorems. The Annals of Applied Probability, 34(1B):1469 \u2013 1523, 2024. doi: 10.1214/23-AAP1996. URL https://doi.org/10.1214/ 23-AAP1996.   \nBrenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, and Samuel J. Gershman. Building machines that learn and think like people. Behavioral and Brain Sciences, 40:e253, 2017. doi: 10.1017/S0140525X16001837.   \nYann Lecun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436\u2013444, 2015. ISSN 14764687. doi: 10.1038/nature14539. Citation Key: Lecun2015.   \nF. Lindsten, A. M. Johansen, C. A. Naesseth, B. Kirkpatrick, T. B. Sch\u00f6n, J. A.D. Aston, and A. Bouchard-C\u00f4t\u00e9. Divide-and-conquer with sequential monte carlo. Journal of Computational and Graphical Statistics, 26(2):445\u2013458, 2017. ISSN 15372715. doi: 10.1080/10618600.2016.1237363. arXiv: 1406.4993 Citation Key: Lindsten2017.   \nShih-Chii Liu. A winner-take-all circuit with controllable soft max property. In S. Solla, T. Leen, and K. M\u00fcller, editors, Advances in Neural Information Processing Systems, volume 12. MIT Press, 1999. URL https://proceedings.neurips.cc/paper_files/paper/1999/file/ 3e7e0224018ab3cf51abb96464d518cd-Paper.pdf.   \nZiwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In Proceedings of International Conference on Computer Vision (ICCV), December 2015.   \nGabriel Loaiza-Ganem and John P Cunningham. The continuous bernoulli: fixing a pervasive error in variational autoencoders. In Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019. URL https://proceedings.neurips.cc/paper/2019/hash/ f82798ec8909d23e55679ee26bb26437-Abstract.html.   \nBrian N. Lundstrom, Matthew H. Higgs, William J. Spain, and Adrienne L. Fairhall. Fractional differentiation by neocortical pyramidal neurons. Nature Neuroscience, 11(11):1335\u20131342, November 2008. ISSN 1546-1726. doi: 10.1038/nn.2212.   \nZachary F Mainen and Terrence J Sejnowski. Reliability of spike timing in neocortical neurons. Science, 268(5216):1503\u20131506, 1995.   \nJoseph Marino, Yisong Yue, and Stephan Mandt. Iterative amortized inference. In 35th International Conference on Machine Learning, ICML 2018, volume 8, page 5444\u20135462, 2018. ISBN 978-1- 5108-6796-3. arXiv: 1807.09356 Citation Key: Marino2018a.   \nBeren Millidge, Anil Seth, and Christopher L Buckley. Predictive coding: a theoretical and experimental review. arXiv preprint arXiv:2107.12979, 2021.   \nBeren Millidge, Yuhang Song, Tommaso Salvatori, Thomas Lukasiewicz, and Rafal Bogacz. A theoretical framework for inference and learning in predictive coding networks. In The Eleventh International Conference on Learning Representations, 2023. URL https://openreview.net/ forum?id $\\equiv$ ZCTvSF_uVM4.   \nToviah Moldwin, Menachem Kalmenson, and Idan Segev. The gradient clusteron: A model neuron that learns to solve classification tasks via dendritic nonlinearities, structural plasticity, and gradient descent. PLOS Computational Biology, 17(5):e1009015, May 2021. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1009015.   \nChristian Naesseth, Fredrik Lindsten, and Thomas Schon. Nested sequential monte carlo methods. In Francis Bach and David Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1292\u2013 1301, Lille, France, 07\u201309 Jul 2015. PMLR. URL https://proceedings.mlr.press/v37/ naesseth15.html.   \nChristian Naesseth, Scott Linderman, Rajesh Ranganath, and David Blei. Variational sequential monte carlo. In Amos Storkey and Fernando Perez-Cruz, editors, Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84 of Proceedings of Machine Learning Research, pages 968\u2013977. PMLR, 09\u201311 Apr 2018. URL https://proceedings.mlr.press/v84/naesseth18a.html.   \nRadford M. Neal and Geoffrey E. Hinton. A View of the EM Algorithm that Justifies Incremental, Sparse, and other Variants, page 355\u2013368. NATO ASI Series. Springer Netherlands, Dordrecht, 1998. ISBN 978-94-011-5014-9. doi: 10.1007/978-94-011-5014-9_12. URL https://doi.org/ 10.1007/978-94-011-5014-9_12.   \nGaspard Oliviers, Rafal Bogacz, and Alexander Meulemans. Learning probability distributions of sensory inputs with monte carlo predictive coding. bioRxiv, 2024.   \nAlexander Ororbia and Daniel Kifer. The neural coding framework for learning generative models. Nature communications, 13(1):2064, 2022.   \nAlexander Ororbia and Ankur Mali. Convolutional neural generative coding: Scaling predictive coding to natural images. arXiv preprint arXiv:2211.12047, 2022.   \nBenjamin Peters, James J DiCarlo, Todd Gureckis, Ralf Haefner, Leyla Isik, Joshua Tenenbaum, Talia Konkle, Thomas Naselaris, Kimberly Stachenfeld, Zenna Tavares, et al. How does the primate brain combine generative and discriminative computations in vision? ArXiv, 2024.   \nLuca Pinchetti, Tommaso Salvatori, Yordan Yordanov, Beren Millidge, Yuhang Song, and Thomas Lukasiewicz. Predictive coding beyond gaussian distributions. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 1280\u20131293. Curran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/file/ 08f9de0232c0b485110237f6e6cf88f1-Paper-Conference.pdf.   \nAlexandre Pouget, Jeffrey M Beck, Wei Ji Ma, and Peter E Latham. Probabilistic brains: knowns and unknowns. Nature neuroscience, 16(9):1170\u20131178, 2013.   \nRajesh P N Rao and Dana H Ballard. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature neuroscience, 2(1):79\u201387, 1999. ISSN 1097-6256. doi: 10.1038/4580. URL 10.1038/4580%5Cnhttp://www.nature.com/neuro/ journal/v2/n1/abs/nn0199_79.html.   \nDanilo Jimenez Rezende, Shakir Mohamed, and Daan Wierstra. Stochastic backpropagation and approximate inference in deep generative models. In Proceedings of the 31st International Conference on Machine Learning, volume 4, page 3057\u20133070, Beijing, China, 2014. arXiv: 1401.4082 Citation Key: Rezende2014 ISBN: 9781634393973.   \nDavid E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. Nature, 323(6088):533\u2013536, 1986.   \nOleh Rybkin, Kostas Daniilidis, and Sergey Levine. Simple and effective vae training with calibrated decoders. In International conference on machine learning, pages 9179\u20139189. PMLR, 2021.   \nTommaso Salvatori, Luca Pinchetti, Beren Millidge, Yuhang Song, Tianyi Bao, Rafal Bogacz, and Thomas Lukasiewicz. Learning on arbitrary graph topologies via predictive coding. Advances in neural information processing systems, 35:38232\u201338244, 2022.   \nTommaso Salvatori, Ankur Mali, Christopher L Buckley, Thomas Lukasiewicz, Rajesh PN Rao, Karl Friston, and Alexander Ororbia. Brain-inspired computational intelligence via predictive coding. arXiv preprint arXiv:2308.07870, 2023.   \nTommaso Salvatori, Yuhang Song, Yordan Yordanov, Beren Millidge, Cornelius Emde, Zhenghua Xu, Lei Sha, Rafal Bogacz, and Thomas Lukasiewicz. A stable, fast, and fully automatic learning algorithm for predictive coding networks. In International Conference on Learning Representations, 2024.   \nJ\u00fcrgen Schmidhuber. Deep learning in neural networks: An overview. Neural Networks, 61:85\u2013117, 2015. ISSN 18792782. doi: 10.1016/j.neunet.2014.09.003. Citation Key: Schmidhuber2015.   \nMaximilian Seitzer. pytorch-fid: FID Score for PyTorch. https://github.com/mseitzer/ pytorch-fid, August 2020. Version 0.3.0.   \nLei Shi and Thomas L. Griffiths. Neural implementation of hierarchical bayesian inference by importance sampling. In Advances in Neural Information Processing Systems, page 1669\u20131677, 2009. ISBN 978-1-61567-911-9. Citation Key: Shi2009.   \nYuhang Song, Beren Millidge, Tommaso Salvatori, Thomas Lukasiewicz, Zhenghua Xu, and Rafal Bogacz. Inferring neural activity before plasticity as a foundation for learning beyond backpropagation. Nature Neuroscience, page 1\u201311, January 2024. ISSN 1546-1726. doi: 10.1038/s41593-023-01514-1.   \nM. W. Spratling. A review of predictive coding algorithms. Brain and Cognition, 112:92\u201397, 2017. ISSN 10902147. doi: 10.1016/j.bandc.2015.11.003.   \nM. V. Srinivasan, S. B. Laughlin, and A. Dubs. Predictive coding: A fresh view of inhibition in the retina. Proceedings of the Royal Society of London - Biological Sciences, 216(1205):427\u2013459, 1982. ISSN 09628452. doi: 10.1098/rspb.1982.0085.   \nSam Stites, Heiko Zimmermann, Hao Wu, Eli Sennesh, and Jan-Willem Van de Meent. Learning proposals for probabilistic programs with inference combinators. 37th Conference on Uncertainty in Artificial Intelligence (UAI 2021), 2021.   \nShohei Taniguchi, Yusuke Iwasawa, Wataru Kumagai, and Yutaka Matsuo. Langevin autoencoders for learning deep latent variable models. Advances in Neural Information Processing Systems, 35: 13277\u201313289, 2022. URL https://proceedings.neurips.cc/paper_files/paper/2022/ hash/565f995643da6329cec701f26f8579f5-Abstract-Conference.html.   \nStefan Webb, Adam Golinski, Rob Zinkov, Siddharth N, Tom Rainforth, Yee Whye Teh, and Frank Wood. Faithful inversion of generative models for effective amortized inference. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018. URL https://proceedings.neurips.cc/paper_files/paper/2018/file/ 894b77f805bd94d292574c38c5d628d5-Paper.pdf.   \nMax Welling and Yee Whye Teh. Bayesian learning via stochastic gradient langevin dynamics. In Proceedings of the 28th International Conference on Machine Learning, ICML 2011, Bellevue, WA, USA, 2011. Proceedings of Machine Learning Research.   \nJames CR Whittington and Rafal Bogacz. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural computation, 29(5): 1229\u20131262, 2017.   \nHan Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. arXiv preprint arXiv:1708.07747, 2017.   \nL. Yin and P. Ao. Existence and construction of dynamical potential in nonequilibrium processes without detailed balance. Journal of Physics A: Mathematical and General, 39(27):8593, June 2006. ISSN 0305-4470. doi: 10.1088/0305-4470/39/27/003. URL https://dx.doi.org/10. 1088/0305-4470/39/27/003.   \nUmais Zahid, Qinghai Guo, and Zafeirios Fountas. Sample as you infer: Predictive coding with langevin dynamics. In Proceedings of the 41st International Conference on Machine Learning, volume 235, Vienna, Austria, 2024. Proceedings of Machine Learning Research. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "image", "img_path": "dxwIaCVkWU/tmp/8428eed8673a55fbc4202caf3816bab509da0911b9f761724c1e4d2958e53be4.jpg", "img_caption": [], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Figure 5: Divide-and-conquer predictive coding provides an algorithmic interpretation for some of the connections mapped in the canonical neocortical microcircuit [Bastos et al., 2012, 2020, Campagnola et al., 2022]: prediction errors (red) arrive through ascending pathways into the central laminar layer 4, which transmits them up to layers 2/3 (green). These layers combine the incoming errors with a present posterior estimate (green $L5{\\rightarrow}\\,\\mathrm{L}2/3$ connection) to generate prediction errors for the next cortical area. Eventually the updated predictions flow back down the cortical hierarchy (blue). ", "page_idx": 15}, {"type": "text", "text": "A Further experiments and results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Alternate image generation/ representation learning As indicated in Section 2, this paper builds upon the particle gradient descent (PGD) algorithm; Kuntz et al. [2023] demonstrated the algorithm\u2019s performance by training a generator network on CelebA. Their network employed a Gaussian likelihood with a fixed standard deviation of 0.01, and evaluated a log-joint objective over 100 epochs on exactly 10,000 subsampled data points. The paper then evaluated mean squared error on an inpainting task and the Frechet Inception Distance over data images. ", "page_idx": 15}, {"type": "text", "text": "When applied to the resulting target density, DCPC amounts to PGD with a resampling step. Table 4 shows the results of training and evaluating the same model described above with DCPC. Since PGD trained for 100 epochs with a batch size of 128, albeit on a 10,000-image subsample of CelebA, we trained with the entire dataset for 100 epochs with batch-size 128. ", "page_idx": 15}, {"type": "table", "img_path": "dxwIaCVkWU/tmp/41da79e1996fb93c17f9a3a8d436c0092d37fe1346786cf040eb20c853c29246.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Table 4: Log-joint probabilities and FID metrics show how DCPC performs against the original PGD. ", "page_idx": 15}, {"type": "text", "text": "We suspect that the supplied code for log-joint calculation averages over either particles or batch items differently from how we have evaluated DCPC (e.g. we call mean() without dividing by any further shape dimensions), accounting for the apparent order-of-magnitude difference between log-joints. ", "page_idx": 15}, {"type": "text", "text": "At the request of reviewers, we have substituted a simplified Figure 1 in the main text for Figure 5 showing how to map DCPC onto laminar microcircuit structure. ", "page_idx": 15}, {"type": "text", "text": "B Importance sampling and gradient estimation proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Titsias [2023] introduced optimal estimators for preconditioning Langevin dynamics to adapt with the Fisher information of the target density. Definition 2 gives the most basic estimator for that Fisher information, defined in terms of the score functions we use as prediction errors. ", "page_idx": 15}, {"type": "text", "text": "Definition 2 (Bayesian Fisher estimator [Titsias, 2023]). Denoting by $\\varepsilon_{z}$ the score function (from Equation $6$ ) and letting $\\lambda>0$ be a fixed hyperparameter, the Bayesian Fisher estimator ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\tilde{\\mathcal{Z}}_{K}:=\\mathbb{E}_{\\boldsymbol{\\varepsilon}_{z}^{1:K}\\sim\\pi_{\\theta}(\\boldsymbol{z}|\\mathbf{z}\\backslash\\boldsymbol{z})}\\left[\\left(\\varepsilon_{z}\\varepsilon_{z}^{\\top}\\right)^{k}\\right]+\\frac{\\lambda}{K}I\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "is an empirical estimator of a Bayesian target density\u2019s Fisher information (the target density from which the prediction errors were derived) based on a cloud of $K$ particles. When the particles are not yet distributed around a mode of the target (e.g. the score function does not have an average of zero), substituting the empirical covariance for the expected outer product reduces the estimator\u2019s bias ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{Z}}_{K}(\\varepsilon_{z}^{1:K}):=\\mathrm{Cov}\\left(\\varepsilon_{z}^{1:K}\\right)+\\frac{\\lambda}{K}I.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The above matrix does not describe the preconditioner that Titsias [2023] actually recommended applying in a Langevin proposal. Definition 3 provides the fully normalized preconditioner. ", "page_idx": 16}, {"type": "text", "text": "Definition 3 (Predictive coding Fisher preconditioner [Titsias, 2023]). Using Definition 2 to parameterize a preconditioner for the Langevin dynamics proposal, the predictive coding Fisher preconditioner is the inverse of Equation $^{12}$ , normalized to have an average eigenvalue of $^{\\,I}$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\hat{\\Sigma}_{\\mathcal{Z}}(\\varepsilon_{z}^{1:K}):=\\frac{\\hat{\\mathcal{Z}}_{K}(\\varepsilon_{z}^{1:K})^{-1}}{\\frac{1}{d}\\mathrm{Tr}[\\hat{\\mathcal{Z}}_{K}(\\varepsilon_{z}^{1:K})^{-1}]}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Definition 4 generalizes the definition of importance sampling, suitable for recursively constructing sequential Monte Carlo algorithms with changing target densities. ", "page_idx": 16}, {"type": "text", "text": "Definition 4 (Strict proper weighting for a density). Given an unnormalized density $\\gamma_{\\theta}(\\mathbf{z})$ with corresponding normalizing constant $Z(\\theta)$ and normalized density $\\pi_{\\theta}(\\mathbf{z})$ ", "page_idx": 16}, {"type": "equation", "text": "$$\nZ(\\theta):=\\int_{\\mathbf{z}\\in\\mathcal{Z}}\\,\\gamma_{\\theta}(\\mathbf{z})\\,d\\mathbf{z}\\qquad\\qquad\\qquad\\quad\\pi_{\\theta}(\\mathbf{z}):=\\frac{\\gamma_{\\theta}(\\mathbf{z})}{Z(\\theta)},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "the random variables $w,\\mathbf{z}\\sim q(w,\\mathbf{z})$ are strictly properly weighted [Naesseth et al., 2015] with respect to $\\gamma_{\\theta}(\\mathbf{z})$ if and only if for any measurable test function $h:{\\mathcal{Z}}\\to\\mathbb{R},$ , the weighted expectation over the proposal $q(w,\\mathbf{z})$ equals the expectation under the target $\\gamma_{\\theta}(\\mathbf{z})$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{w,\\mathbf{z}\\sim q(w,\\mathbf{z})}\\left[w h(\\mathbf{z})\\right]=\\int_{\\mathbf{z}\\in\\mathcal{Z}}\\,h(\\mathbf{z})\\,\\gamma_{\\theta}(\\mathbf{z})\\,d\\mathbf{z}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The following two propositions come from the previous work by Wu et al. [2020], Stites et al. [2021] and Zimmermann et al. [2021]. The reader looking for foundations can see Naesseth et al. [2015] or Chopin and Papaspiliopoulos [2020]. ", "page_idx": 16}, {"type": "text", "text": "Proposition 1 (The free energy upper-bounds the surprisal). Given a proposal $q_{\\phi}(w,\\mathbf{z})$ strictly properly weighted (Definition 4) for the target $\\gamma_{\\theta}(\\mathbf{z})$ , the variational free energy provides an upper bound to the target\u2019s surprisal ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}(\\theta,q)\\geq-\\log Z(\\theta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. I begin by writing out the free energy (Equation 2) as an expectation of a negative logarithm ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{F}(\\theta,q)=\\mathbb{E}_{z,w\\sim q(z,w)}\\left[-\\log w\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Jensen\u2019s Inequality allows moving the expectation into the negative logarithm by relaxing the definition of the variational free energy from an equality to an upper bound ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{F}(\\theta,q)\\geq-\\log\\mathbb{E}_{z,w\\sim q(z,w)}\\left[w\\right].\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Setting $h(z)=1$ , strict proper weighting for an unnormalized density (Definition 4) says the expected weight will be the normalizing constant ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z,w\\sim q(z,w)}\\left[w\\right]=Z(\\theta)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which I substitute back in to obtain the desired inequality ${\\mathcal{F}}(\\theta,q)\\geq-\\log Z(\\theta)$ . ", "page_idx": 16}, {"type": "text", "text": "Proposition 2 (Weighted expectations approximate the normalized target up to a constant). Given a proposal $q_{\\phi}(w,\\mathbf{z})$ strictly properly weighted (Definition 4) for the target $\\gamma_{\\theta}(\\mathbf{z})$ and a measurable test function $h:\\mathcal{Z}\\to\\mathbb{R}$ , weighted expectations under the proposal equal the target\u2019s normalizing constant times the test function\u2019s expectation under the normalized target ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{(w,\\mathbf{z})\\sim q_{\\phi}(w,\\mathbf{z})}\\left[w h(\\mathbf{z})\\right]=Z(\\theta)\\mathbb{E}_{\\mathbf{z}\\sim\\pi_{\\theta}(\\cdot)}\\left[h(\\mathbf{z})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Strict proper weighting (Equation 14) states that weighted expectations under the proposal equal integrals over the unnormalized target, and by definition the normalized target equals the unnormalized density over its normalizing constant ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{w,\\mathbf{z}\\sim q(w,\\mathbf{z})}\\left[w h(\\mathbf{z})\\right]=\\int_{\\mathbf{z}\\in\\mathcal{Z}}\\,h(\\mathbf{z})\\,\\gamma_{\\theta}(\\mathbf{z})\\,d\\mathbf{z},\\qquad\\qquad\\pi_{\\theta}(\\mathbf{z}):=\\frac{\\gamma_{\\theta}(\\mathbf{z})}{Z(\\theta)}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The second equation expresses the unnormalized target in terms of the normalized one ", "page_idx": 17}, {"type": "equation", "text": "$$\nZ(\\theta)\\pi_{\\theta}(\\mathbf{z})=\\gamma_{\\theta}(\\mathbf{z}),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and substituting this expression into the definition of strict proper weighting leads to the desired result ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\int_{\\mathbf{z}\\in\\mathcal{Z}}\\ h(\\mathbf{z})\\ \\gamma_{\\theta}(\\mathbf{z})\\ d\\mathbf{z}=\\int_{\\mathbf{z}\\in\\mathcal{Z}}\\ h(\\mathbf{z})\\ Z(\\theta)\\pi_{\\theta}(\\mathbf{z})\\ d\\mathbf{z},}\\\\ {\\displaystyle\\qquad\\qquad\\qquad=Z(\\theta)\\int_{\\mathbf{z}\\in\\mathcal{Z}}\\ h(\\mathbf{z})\\ \\pi_{\\theta}(\\mathbf{z})\\ d\\mathbf{z}}\\\\ {\\mathbb{E}_{w,\\mathbf{z}\\sim q(w,\\mathbf{z})}\\left[w h(\\mathbf{z})\\right]=Z(\\theta)\\mathbb{E}_{\\pi_{\\theta}(\\mathbf{z})}\\left[h(\\mathbf{z})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proposition 3 (DCPC\u2019s free energy has a pathwise derivative). The free energy $\\mathcal{F}^{t+1}\\;\\;=\\;\\;$ $\\mathbb{E}_{q}\\left[-\\log w_{\\theta^{t}}^{t+1}\\right]$ constructed by the population predictive coding algorithm (Algorithm $^{\\,l}$ ) has $a$ pathwise derivative as the expectation of the negative gradient of the log-joint density ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\nabla_{\\theta^{t}}\\mathcal{F}^{t+1}=\\mathbb{E}_{q}\\left[-\\nabla_{\\theta^{t}}\\log p_{\\theta^{t}}(\\mathbf{x},\\mathbf{z}^{t+1})\\right].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. The free energy has an expression in terms of Equation 8 ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\quad}&{\\mathcal{F}^{t+1}=\\mathbb{E}_{q}\\left[-\\log w_{\\theta^{t}}^{t+1}\\right]\\ \\ \\ \\ \\ }&&{w_{\\theta^{t}}^{t+1}=\\frac{p_{\\theta^{t}}\\left(\\mathbf{x},\\mathbf{z}\\right)}{\\prod_{z\\in\\mathbf{z}}\\gamma_{\\theta}\\left(z_{b}^{t+1};\\mathbf{z}_{\\setminus\\tau}\\right)}\\prod_{z\\in\\mathbf{z}}\\hat{z}_{\\theta^{t}}(\\mathbf{z}_{\\setminus z})^{t+1},}\\\\ &{\\hat{Z}_{\\theta^{t}}(\\mathbf{z}_{\\lfloor z\\rfloor^{\\tau}})^{t+1}=\\frac{1}{K}\\sum_{k=1}^{K}u_{b}^{t+1,k}\\ \\ \\ \\ \\ \\ }&&{u_{z}^{t+1}=\\frac{\\gamma_{\\theta}\\left(z^{t+1};\\mathbf{z}_{\\lfloor z\\rfloor^{\\tau}}\\right)}{q\\left(z^{t+1}\\mid\\varepsilon_{z}\\left(z^{t}\\right)\\right)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and writing out the free energy itself in full shows that many terms cancel ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{q(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t})=\\displaystyle\\prod_{z_{b}^{t+1}\\in\\mathbf{z}^{t+1}}q(z^{t+1}\\mid z^{t}),}\\\\ &{\\qquad=\\mathbb{E}_{q(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t})}\\left[-\\log\\frac{p_{\\theta^{t}}(\\mathbf{x},\\mathbf{z})}{\\prod_{z\\in\\mathbf{z}^{\\prime}\\cup\\theta}(z_{b}^{t+1};\\mathbf{z}_{\\mid z})}\\prod_{z\\in\\mathbf{z}^{t}}\\frac{\\mathcal{N}}{\\mathcal{N}_{k}^{W}}\\!\\!\\!\\sum_{q(z^{t+1}\\mid\\mathbf{z}_{z}\\mid z^{t})}^{\\gamma_{e}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\gamma_{\\theta}(z_{b}^{t+1};\\mathbf{z}_{\\mid z})\\right]}\\\\ &{\\qquad=\\mathbb{E}_{q(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t})}\\left[-\\log\\frac{p_{\\theta^{t}}(\\mathbf{x},\\mathbf{z})}{\\prod_{z\\in\\mathbf{z}^{\\prime}\\cup\\theta}(z_{b}^{t+1};\\mathbf{\\theta}_{\\mid z})}\\frac{\\prod_{z\\in\\mathbf{z}^{\\prime}\\cup\\theta}(z_{b}^{t+1};\\mathbf{z}_{\\mid z})}{\\prod_{z\\in\\mathbf{z}^{\\prime}}q(z^{t+1}\\mid\\mathbf{z}_{z}(z^{t}))}\\right]}\\\\ &{\\qquad=\\mathbb{E}_{q(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t})}\\left[-\\log\\frac{p_{\\theta^{t}}(\\mathbf{x},\\mathbf{z})}{q(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t})}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The proposal distribution $q$ is a function of the random variable values themselves through the prediction errors, not of the parameters $\\theta$ . The above expression therefore admits a pathwise ", "page_idx": 17}, {"type": "text", "text": "derivative [Schulman et al., 2015], moving the gradient operator into the expectation ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\theta^{t}}\\mathcal{F}^{t+1}=\\nabla_{\\theta^{t}}\\mathbb{E}_{q\\left(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t}\\right)}\\left[-\\log\\frac{p_{\\theta^{t}}\\left(\\mathbf{x},\\mathbf{z}^{t+1}\\right)}{q\\left(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t}\\right)}\\right]}\\\\ &{\\qquad\\quad=\\mathbb{E}_{q\\left(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t}\\right)}\\left[\\nabla_{\\theta^{t}}-\\log\\frac{p_{\\theta^{t}}\\left(\\mathbf{x},\\mathbf{z}^{t+1}\\right)}{q\\left(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t}\\right)}\\right]}\\\\ &{\\qquad\\quad=\\mathbb{E}_{q\\left(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t}\\right)}\\left[\\nabla_{\\theta^{t}}-\\left[\\log p_{\\theta^{t}}(\\mathbf{x},\\mathbf{z}^{t+1})-\\log q(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t})\\right]\\right]}\\\\ &{\\qquad\\quad=\\mathbb{E}_{q\\left(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t}\\right)}\\left[-\\left[\\nabla_{\\theta^{t}}\\log p_{\\theta^{t}}(\\mathbf{x},\\mathbf{z}^{t+1})-\\nabla_{\\theta^{t}}\\log q(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t})\\right]\\right]}\\\\ &{\\qquad\\quad\\forall_{\\theta^{t}}\\mathcal{F}^{t+1}=\\mathbb{E}_{q\\left(\\mathbf{z}^{t+1}\\mid\\mathbf{z}^{t}\\right)}\\left[-\\nabla_{\\theta^{t}}\\log p_{\\theta^{t}}(\\mathbf{x},\\mathbf{z}^{t+1})\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proposition 4 (DCPC coordinate updates are strictly properly weighted for the complete conditionals). Each DCPC coordinate update (Equation 7) for a latent variable $z\\in\\mathbf{z}$ is strictly properly weighted (Definition 4) for $z$ \u2019s unnormalized complete conditional. For every measurable $h:\\mathcal{Z}\\to\\mathbb{R}$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim q\\eta\\left(z^{t}\\mid z^{t-1},\\varepsilon_{z}^{t}\\right)}\\left[\\mathbb{E}_{u\\sim\\delta\\left(u\\right),z^{\\prime},\\hat{Z}\\sim\\mathsf{R E S A M P L E}\\left(z,u_{z}\\right)}\\left[h(z)\\right]\\right]=\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\gamma_{\\theta}(z;\\mathbf{z}_{\\vee,z})\\,d z.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. Expanding the outer expectation into an integral and replacing the Dirac delta with the expression for the local weights transforms Equation 16 into ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle\\int_{z\\in\\mathcal{Z}}\\,\\frac{\\gamma\\theta(z;\\mathbf{z}_{|z})}{g_{\\!\\scriptscriptstyle{p}}(z\\!+\\!\\!z^{\\!-\\!\\!1};\\mathcal{E}_{z}^{t})}\\mathbb{E}_{z^{\\prime}\\sim\\mathsf{R E S A M P L E}(z,u_{z})}\\left[h(z^{\\prime})\\right]\\,g_{\\!\\scriptscriptstyle{p}}(z\\!+\\!\\!z^{t\\!-\\!\\!1}\\overline{{\\varepsilon}}_{z}^{t\\!-\\!\\!1})\\,d z=\\hfill}\\\\ {\\displaystyle\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\gamma\\theta(z;\\mathbf{z}_{|z})\\,d z;}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "importance resampling also preserves strict proper weighting (see Naesseth et al. [2015], Stites et al. [2021] and Chopin and Papaspiliopoulos [2020] for proofs), and so this yields ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\int_{z\\in\\mathcal{Z}}\\mathbb{E}_{z^{\\prime}\\sim\\textsc R\\mathrm{ESAMPLE}(z,u_{z})}\\left[h(z^{\\prime})\\right]\\,\\gamma_{\\theta}(z;\\mathbf{z}_{\\backslash z})\\,d z=\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\gamma_{\\theta}(z;\\mathbf{z}_{\\backslash z})\\,d z}\\\\ {\\displaystyle\\int_{z^{\\prime}\\in\\mathcal{Z}}\\,h(z^{\\prime})\\,\\gamma_{\\theta}(z^{\\prime};\\mathbf{z}_{\\backslash z})\\,d z^{\\prime}=\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\gamma_{\\theta}(z;\\mathbf{z}_{\\backslash z})\\,d z.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Corollary 4.1 (DCPC coordinate updates sample from the true complete conditionals). Each DCPC coordinate update (Equation 7) for a latent $z\\ \\in\\textbf{z}$ samples from $z$ \u2019s complete conditional (the normalization of Equation 5). Formally, for every measurable $h:{\\mathcal{Z}}\\to\\mathbb{R}_{}$ , resampled expectations with respect to the DCPC coordinate update equal those with respect to the complete conditional ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim q\\eta\\left(z\\mid z^{t-1},\\varepsilon_{z}^{t}\\right)}\\left[\\mathbb{E}_{u\\sim\\delta\\left(u\\right),z^{\\prime}\\sim\\mathrm{RESAMPLE}\\left(z,u_{z}\\right)}\\left[h(z^{\\prime})\\right]\\right]=\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\pi_{\\theta}(z\\mid\\mathbf{z}_{\\vee})\\,d z.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. Proposition 4 in Appendix B provides a lemma ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim q\\eta\\left(z^{t}\\mid z^{t-1},\\varepsilon_{z}^{t}\\right)}\\left[\\mathbb{E}_{u\\sim\\delta\\left(u\\right),z^{\\prime},\\hat{Z}\\sim\\mathrm{RESAMPLE}\\left(z,u_{z}\\right)}\\left[h(z^{\\prime})\\right]\\right]=\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\gamma_{\\theta}(z;\\mathbf{z}_{\\vee})\\,d z,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which we can apply by observing that resampling sums over self-normalized weights ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{z\\sim q_{\\eta}(z|z^{t-1},\\varepsilon_{z}^{t})}\\left[\\mathbb{E}_{u\\sim\\delta(u),z^{\\prime}\\sim\\mathrm{RESAMPLE}(z,u_{z})}\\left[h(z)\\right]\\right]=}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathbb{E}_{z\\sim q_{\\eta}(z|z^{t-1},\\varepsilon_{z}^{t})}\\left[\\mathbb{E}_{u\\sim\\delta(u)}\\left[\\mathbb{E}_{z^{\\prime}\\sim\\frac{u\\delta_{z}(\\cdot)}{\\sum w^{\\prime}}}\\left[h(z^{\\prime})\\right]\\right]\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which is just a weighted sum that by Definition 4 is itself properly weighted ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}_{z\\sim q_{\\eta}(z\\mid z^{t-1},\\varepsilon_{z}^{t})}\\left[\\mathbb{E}_{u\\sim\\delta(u)}\\left[\\mathbb{E}_{z^{\\prime}\\sim\\frac{u\\delta_{z}(\\cdot)}{\\Sigma\\,u^{\\prime}}}\\left[h(z^{\\prime})\\right]\\right]\\right]=\\mathbb{E}_{z\\sim q_{\\eta}(z\\mid z^{t-1},\\varepsilon_{z}^{t})}\\left[\\mathbb{E}_{u\\sim\\delta(u)}\\left[\\frac{u}{\\sum u}h(z)\\right]\\right]\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\mathbb{E}_{z\\sim q\\eta\\left(z\\mid z^{t-1},\\varepsilon_{z}^{t}\\right)}\\left[\\mathbb{E}_{u\\sim\\delta\\left(u\\right)}\\left[\\frac{1}{\\sum u}\\int_{z\\in\\mathcal{Z}}h(z)\\,\\gamma_{\\theta}(z;\\mathbf{x},\\mathbf{z}_{\\backslash})\\,d z\\right]\\right]}\\\\ &{=\\mathbb{E}_{z\\sim q\\eta\\left(z\\mid z^{t-1},\\varepsilon_{z}^{t}\\right)}\\left[\\mathbb{E}_{u\\sim\\delta\\left(u\\right)}\\left[\\frac{1}{\\widehat{Z}_{\\theta}\\left(\\mathbf{x},\\mathbf{z}_{\\backslash}\\right)}Z_{\\theta}(\\mathbf{x},\\mathbf{z}_{\\backslash})\\right\\rangle_{z\\in\\mathcal{Z}}\\,h(z)\\,\\pi_{\\theta}(z\\mid\\mathbf{x},\\mathbf{z}_{\\backslash})\\,d z\\right]\\right]}\\\\ &{=\\displaystyle\\int_{z\\in\\mathcal{Z}}\\,h(z)\\,\\pi_{\\theta}(z\\mid\\mathbf{x},\\mathbf{z}_{\\backslash})\\,d z.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proposition 5 (DCPC parameter learning requires only local gradients in a factorized generative model). Consider a graphical model factorized according to Equation $^{\\,l}$ , with the additional assumption that the model parameters $\\begin{array}{r}{\\theta\\in\\stackrel{\\cdot}{\\Theta}=\\prod_{x\\in{\\bf x}}\\Theta_{x}\\times\\bar{\\prod}_{z\\in{\\bf z}}\\bar{\\Theta}_{z}}\\end{array}$ share that factorization. Then the gradient $\\nabla_{\\theta}\\mathcal{F}(\\theta,q)$ of DCPC\u2019s free energy similarly factorizes into a sum of local particle averages ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nabla_{\\theta}\\mathcal{F}=\\mathbb{E}_{q}\\left[-\\nabla_{\\theta}\\log p_{\\theta}(\\mathbf{x},\\mathbf{z})\\right]}\\\\ &{\\quad\\quad=\\displaystyle\\sum_{v\\in(\\mathbf{x},\\mathbf{z})}\\mathbb{E}_{q(v,\\mathrm{Pa}(v)\\mid\\varepsilon_{v},\\varepsilon_{\\mathrm{Pa}(v)})}\\left[-\\nabla_{\\theta_{v}}\\log p_{\\theta_{v}}(v\\mid\\mathrm{Pa}(v))\\right]}\\\\ &{\\quad\\quad=-\\displaystyle\\sum_{v\\in(\\mathbf{x},\\mathbf{z})}\\frac{1}{K}\\displaystyle\\sum_{k=1}^{K}\\nabla_{\\theta_{v}}\\log p_{\\theta_{v}}(v^{k}\\mid\\mathrm{Pa}(v)^{k}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Proposition 3 provides the lemma that $\\nabla_{\\theta}\\mathcal{F}\\,=\\,\\mathbb{E}_{q}\\left[-\\nabla_{\\theta}\\log p_{\\theta}(\\mathbf{x},\\mathbf{z})\\right]$ , and applying the factorization of the generative model demonstrates that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}\\mathcal{F}=\\mathbb{E}_{q}\\left[-\\nabla_{\\theta}\\sum_{v\\in(\\mathbf{x},\\mathbf{z})}\\log p_{\\theta}(v\\mid\\operatorname{Pa}(v))\\right].\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since the proposal $q$ does not depend on any $\\theta$ and consists of a particle cloud, we can rewrite it as a mixture over the particles (after sampling is performed) ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\nabla_{\\theta}\\mathcal{F}\\approx\\frac{1}{K}\\sum_{k=1}^{K}-\\nabla_{\\theta}\\sum_{v\\in(\\mathbf{x},\\mathbf{z})}\\log p_{\\theta}(v^{k}\\mid\\mathrm{Pa}(v)^{k}),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and then finally apply the assumption of this theorem that $\\begin{array}{r}{\\theta\\in\\Theta=\\prod_{x\\in\\mathbf{x}}\\Theta_{x}\\times\\prod_{z\\in\\mathbf{z}}\\Theta_{z}}\\end{array}$ , moving the gradient operation into the sum over individual random variables ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\approx\\frac{1}{K}\\sum_{k=1}^{K}\\sum_{v\\in(\\mathbf{x},\\mathbf{z})}-\\nabla_{\\theta^{v}}\\log p_{\\theta^{v}}(v^{k}\\mid\\operatorname{Pa}(v)^{k}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "C Extension to discrete sample spaces ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Contemporaneously to the work of Kuntz et al. [2023] on particle gradient descent, Sun et al. [2023] derived a novel Wasserstein gradient flow and corresponding descent algorithm for discrete distributions. In their setting, each Wasserstein gradient step constructs a $D$ -dimensional, finitely supported distribution over the $C$ -Hamming ball of the starting sample, such that the distribution has $D C$ possible states in total. Let $z^{t+h}\\in\\overline{{N_{C}(z^{t})}}$ denote the resulting discrete random variable in the $C$ -neighborhood around $z^{t}$ with respect to the Hamming distance. The update rule relies on simulating the gradient flow for time $h$ , sampling from a Markov jump process at time $t+h$ ", "page_idx": 19}, {"type": "equation", "text": "$$\nz^{t+h}\\sim\\prod_{d\\in[1\\ldots D]}q(z_{d}^{t+h}\\mid z_{d}^{t}).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "A rate matrix $Q_{d}(z^{t})$ defined by the entire discrete variable $z^{t}$ parameterizes the proposal distribution ", "page_idx": 19}, {"type": "equation", "text": "$$\nq_{h}(z_{d}^{t+h}\\mid z^{t})=\\exp\\big(Q_{d}(z^{t})h\\big).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "the rate matrix will have nondiagonal entries at indices $i\\neq j\\in[1\\ldots C]$ in the neighborhood $N_{C}(z^{t})$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\nQ_{d}(z^{t})_{i,j}=w_{i,j}g\\left(\\frac{\\pi_{\\theta}(z_{\\backslash d}^{t},z_{d,j}^{\\prime})}{\\pi_{\\theta}(z_{\\backslash d}^{t},z_{d,i}^{\\prime})}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The above equation requires that $\\forall i,j\\in[1\\ldots C],w_{i,j}=w_{j,i}\\in\\mathbb{R}$ and $\\begin{array}{r}{g(a)=a g\\left(\\frac{1}{a}\\right)}\\end{array}$ . The ratio of normalized target densities $\\pi$ will equal the ratio of unnormalized densities $\\gamma$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\frac{\\pi_{\\theta}(z_{\\setminus d}^{t},z_{d,j}^{\\prime})}{\\pi_{\\theta}(z_{\\setminus d}^{t},z_{d,i}^{\\prime})}=\\frac{\\gamma_{\\theta}(z_{d,j}^{\\prime};z_{\\setminus d}^{t})Z_{z_{\\neq}}(z_{\\setminus d}^{t},\\theta)}{Z_{z_{d}}(z_{\\setminus d}^{t})\\gamma_{\\theta}(z_{d,i}^{\\prime};z_{\\setminus d}^{t})}}\\\\ &{}&{g\\left(\\frac{\\pi_{\\theta}(z_{\\setminus d}^{t},z_{d,j}^{\\prime})}{\\pi_{\\theta}(z_{\\setminus d}^{t},z_{d,i}^{\\prime})}\\right)=g\\left(\\frac{\\gamma_{\\theta}(z_{d,j}^{\\prime};z_{\\setminus d}^{t})}{\\gamma_{\\theta}(z_{d,i}^{\\prime};z_{\\setminus d}^{t})}\\right).\\quad\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Based on the experimental recommendations of Sun et al. [2023], let $w_{i,j}=w_{j,i}=1$ and $g(a)={\\sqrt{a}}$ . The rate matrix then simplifies to nondiagonal and diagonal terms ", "page_idx": 20}, {"type": "equation", "text": "$$\nQ_{d}(z^{t})_{i,j}=\\sqrt{\\frac{\\gamma_{\\theta}(z_{d,j}^{\\prime};z_{\\{d\\}}^{t})}{\\gamma_{\\theta}(z_{d,i}^{\\prime};z_{\\{d\\}}^{t})}},~~~~~~~~~~~~~Q_{d}(z^{t})_{i,i}=-\\sum_{j\\ne i}Q_{d}(z^{t})_{i,j}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Equations 17 and 18 give a distribution descending the Wasserstein gradient of the free energy with respect to a particle cloud in a discrete sample space. Applying Equation 18 to $\\gamma_{\\theta}(z;\\mathbf{z}_{\\setminus z})$ yields a factorization in log space ", "page_idx": 20}, {"type": "equation", "text": "$$\nQ(z^{t})_{i,j}=\\sqrt{\\frac{\\gamma_{\\theta}(z^{t}+i;\\mathbf{z}_{\\lfloor z\\rfloor}^{t})}{\\gamma_{\\theta}(z^{t}+j;\\mathbf{z}_{\\lfloor z\\rfloor}^{t})}}\\quad\\log Q(z^{t})_{i,j}=\\frac{1}{2}\\left(\\log\\gamma_{\\theta}(z^{t}+i;\\mathbf{z}_{\\lfloor z\\rfloor}^{t})-\\log\\gamma_{\\theta}(z^{t}+j;\\mathbf{z}_{\\lfloor z\\rfloor}^{t})\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This difference can be written as a difference of differences ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\gamma_{\\theta}(z^{t}+i;\\mathbf{z}_{\\langle z}^{t})-\\log\\gamma_{\\theta}(z^{t}+j;\\mathbf{z}_{\\langle z}^{t})=}\\\\ &{\\qquad\\ \\left(\\log\\gamma_{\\theta}(z^{t}+i;\\mathbf{z}_{\\langle z}^{t})-\\log\\gamma_{\\theta}(z^{t};\\mathbf{z}_{\\langle z}^{t})\\right)-\\left(\\log\\gamma_{\\theta}(z^{t}+j;\\mathbf{z}_{\\langle z}^{t})-\\log\\gamma_{\\theta}(z^{t};\\mathbf{z}_{\\langle z}^{t})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Recent work on efficient sampling for discrete distributions has focused on approximating density ratios, such as the one in Equation 18, with series expansions parameterized by error vectors. When the underlying discrete densities consist of exponentiating a differentiable energy function, as in Grathwohl et al. [2021], these error vectors have taken the form of gradients and the finite-series expansions have been Taylor series. When they do not, Xiang et al. [2023] showed how they take the form of finite differences and Newton\u2019s series ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\log\\gamma(z^{\\prime})-\\log\\gamma(z)\\approx\\Delta_{1}\\left(\\log\\gamma(z)\\right)^{\\top}\\cdot(z^{\\prime}-z).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Discrete DCPC would therefore use finite differences as discrete prediction errors, breaking each discrete $z\\in\\mathbf{z}$ into dimensions and incrementing each dimension separately to construct a vector ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Delta_{1}f(z):=\\big(f(z_{1}+1,z_{2:D}),\\ldots,f(z_{1:i},z_{i}+1,z_{i+1:D}),\\ldots,f(z_{1:D-1},z_{D}+1)\\big)\\ominus f(z),\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\circleddash$ subtracts the scalar $f(z)$ from the vector elements and $f:\\mathbb{Z}^{D}\\to\\mathbb{R}$ is the target function. This would lead to defining the discrete prediction error as the finite difference ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\varepsilon_{z}:=\\Delta_{1}\\log\\gamma_{\\theta}\\big(z^{t};{\\mathbf{z}}_{\\setminus z}^{t}\\big).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Applying Equation 20 to the two terms of Equation 19, we obtain the approximations ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\gamma_{\\theta}(z^{t}+i;\\mathbf{z}_{\\lfloor z\\rfloor}^{t})-\\log\\gamma_{\\theta}(z^{t};\\mathbf{z}_{\\lfloor z\\rfloor}^{t})\\approx\\Delta_{1}\\left(\\log\\gamma_{\\theta}(z^{t};\\mathbf{z}_{\\lfloor z\\rfloor}^{t})\\right)^{\\top}\\cdot((z^{t}+i)-z^{t})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\approx\\varepsilon_{z}(z^{t})^{\\top}\\cdot i}\\\\ &{\\log\\gamma_{\\theta}(z^{t}+j;\\mathbf{z}_{\\lfloor z\\rfloor}^{t})-\\log\\gamma_{\\theta}(z^{t};\\mathbf{z}_{\\lfloor z\\rfloor}^{t})\\approx\\Delta_{1}\\left(\\log\\gamma_{\\theta}(z^{t};\\mathbf{z}_{\\lfloor z\\rfloor}^{t})\\right)^{\\top}\\cdot((z^{t}+j)-z^{t})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\approx\\varepsilon_{z}(z^{t})^{\\top}\\cdot j,}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\log Q(z^{t})_{i,j}\\approx\\frac{1}{2}\\varepsilon_{z}(z^{t})^{\\top}\\left(i-j\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Discrete DCPC would thus parameterize its discrete proposal (Equation 17) in terms of $\\varepsilon_{z}$ (Equation 22), so that Equation 18 comes out to the (matrix) exponential of the (elementwise) exponential ", "page_idx": 20}, {"type": "equation", "text": "$$\nq_{h}(z^{t+h}\\mid\\varepsilon_{z})=\\exp\\left(Q(\\varepsilon_{z})h\\right)\\qquad\\qquad Q_{d}(\\varepsilon_{z})_{i,j}=\\exp\\left(\\frac{(\\varepsilon_{z})_{d}^{\\top}(i_{d}-j_{d})}{2}\\right).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Supplementary References ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Nicolas Chopin and Omiros Papaspiliopoulos. An Introduction to Sequential Monte Carlo. Springer, 2020. ISBN 978-3-030-47844-5. doi: 10.1007/978-3-030-47845-2. Citation Key: Chopin2020 ISSN: 2197-568X. ", "page_idx": 21}, {"type": "text", "text": "Will Grathwohl, Kevin Swersky, Milad Hashemi, David Duvenaud, and Chris Maddison. Oops I took a gradient: Scalable sampling for discrete distributions. In Proceedings of the 38th International Conference on Machine Learning, page 3831\u20133841. PMLR, July 2021. URL https://proceedings.mlr.press/v139/grathwohl21a.html.   \nJohn Schulman, Nicolas Heess, Theophane Weber, and Pieter Abbeel. Gradient estimation using stochastic computation graphs. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 28. Curran Associates, Inc., 2015. URL https://proceedings.neurips.cc/paper_files/paper/2015/ file/de03beffeed9da5f3639a621bcab5dd4-Paper.pdf.   \nHaoran Sun, Hanjun Dai, Bo Dai, Haomin Zhou, and Dale Schuurmans. Discrete Langevin Samplers via Wasserstein Gradient Flow. In Proceedings of the 26th International Conference on Artificial Intelligence and Statistics, Valencia, Spain, April 2023. Proceedings of Machine Learning Research.   \nMichalis Titsias. Optimal preconditioning and fisher adaptive langevin sampling. In Advances in Neural Information Processing Systems, volume 37. Curran Associates, Inc., 2023. URL https://proceedings.neurips.cc/paper_files/paper/2023/hash/ 5da6d5818a156791090c875abeca3cf8-Abstract-Conference.html.   \nHao Wu, Heiko Zimmermann, Eli Sennesh, Tuan Anh Le, and Jan Willem van de Meent. Amortized population Gibbs samplers with neural sufficient statistics. In Proceedings of the 37th International Conference on Machine Learning, 2020.   \nYue Xiang, Dongyao Zhu, Bowen Lei, Dongkuan Xu, and Ruqi Zhang. Efficient Informed Proposals for Discrete Distributions via Newton\u2019s Series Approximation. In Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, pages 7288\u20137310. PMLR, April 2023. URL https://proceedings.mlr.press/v206/xiang23a.html. ISSN: 2640-3498.   \nHeiko Zimmermann, Hao Wu, Babak Esmaeili, and Jan-Willem van de Meent. Nested variational inference. In M. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan, editors, Advances in Neural Information Processing Systems, volume 34, pages 20423\u201320435. Curran Associates, Inc., 2021. URL https://proceedings.neurips.cc/paper_files/paper/ 2021/file/ab49b208848abe14418090d95df0d590-Paper.pdf. ", "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 22}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 22}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] . ", "page_idx": 22}, {"type": "text", "text": "\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available. \u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 22}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 22}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Section 7.1 discusses limitations specifically. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper. ", "page_idx": 22}, {"type": "text", "text": "\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: Proofs can be found in Appendix B. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper includes the learning rates and particle counts, the necessary hyperparameters, for the original experiments, as well as releasing code to run them. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: The paper provides a link to the code in the abstract and introduction. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper notes the hyperparameters and datasets used, gives additional details in the appendices, and releases the code. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Results are given in terms of sample averages and standard deviations, with the standard deviations serving as error bars. The paper notes the number of replicates over which averages are taken. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The experiments section now includes a paragraph at the end documenting the specific compute resources used in our experiments. Many of our experiments can be trained with less compute than we used, albeit more slowly. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. ", "page_idx": 25}, {"type": "text", "text": "\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The paper does not rely on human subjects, nor release any new dataset. Approximate Bayesian inference is a well-understood problem whose downstream ethical impacts do not differ significantly from those of other machine-learning methods. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: We propose a novel neuroscience-inspired learning algorithm, which does not have immediate societal impacts, positive or negative. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: We do not use data that is not already available online, nor do we release any models for a task more complex than non-customizable image generation. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [No] ", "page_idx": 27}, {"type": "text", "text": "Justification: The code is not well-documented by the standards of industry, being research code. We do not release any new datasets or foundation models to document. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: [NA] Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}]