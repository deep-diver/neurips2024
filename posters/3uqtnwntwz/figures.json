[{"figure_path": "3uQtNWNTwz/figures/figures_0_1.jpg", "caption": "Figure 1: Novel views generated from a single source image (far left column) at a specific target view angle (with different seeds), compared between Zero123-XL [27] and our Zero-to-Hero method. Operating during inference, our method achieves significantly higher fidelity and maintains authenticity to the original image, all while ensuring realistic variation in the results (e.g., variations in chair backs in the top row). The ground-truth target view is displayed in the far right column.", "description": "This figure compares the novel view synthesis results of Zero123-XL and the proposed Zero-to-Hero method.  Multiple novel views are generated from a single source image at different angles using both methods.  The figure highlights that Zero-to-Hero produces more realistic and faithful results compared to Zero123-XL, while also maintaining variability in the generated outputs.", "section": "Introduction"}, {"figure_path": "3uQtNWNTwz/figures/figures_4_1.jpg", "caption": "Figure 2: Zero-to-Hero main modules. (Left) Two denoising steps of the generation process of both the source (top) and target views (bottom). Each denoising step is iterated R times (\u201cresampling\u201d). (Right-top) Attention map filtering: Robustifying attention maps via an aggregation of same step and previous steps attention maps. (Right-bottom) Mutual self-attention: Guiding target shape through the keys and values of the source generation branch.", "description": "This figure illustrates the main modules of the Zero-to-Hero method. The left panel shows the overall architecture, highlighting the two denoising steps for source and target views, each involving R resampling iterations.  The right panel zooms into the two key components: attention map filtering (top right) which enhances robustness by aggregating attention maps across steps, and early-stage mutual self-attention (bottom right) which ensures consistency by incorporating information from the source view into the target view generation. ", "section": "4 Method"}, {"figure_path": "3uQtNWNTwz/figures/figures_5_1.jpg", "caption": "Figure 3: Through the injection of ground-truth attention maps extracted from the target view, we demonstrate that Self-attention maps are key to robust view synthesis.", "description": "This figure shows the impact of using ground-truth attention maps in the view synthesis process.  By replacing the computed self-attention maps with the ground truth maps, the results show a significant improvement, demonstrating the importance of accurate self-attention maps for robust view generation.", "section": "4.1 Analyzing the Role of Cross- and Self-Attention Layers in Novel View Generation"}, {"figure_path": "3uQtNWNTwz/figures/figures_6_1.jpg", "caption": "Figure 4: From SGD to Diffusion Models: An illustration of our conceptual analogy.", "description": "This figure illustrates the conceptual analogy drawn between the weight update process in stochastic gradient descent (SGD) optimization and the attention map update process during the denoising steps in diffusion models.  The left side shows a typical SGD step where network parameters (\u03b8) are updated based on the gradient of a loss function.  The right side shows the analogous process in diffusion models where attention maps (Mt) are updated based on the denoising process (DS). The analogy highlights that both processes iteratively refine parameters (weights or attention maps) to approach a desirable solution (minimum of loss function or a realistic image).", "section": "4 Method"}, {"figure_path": "3uQtNWNTwz/figures/figures_6_2.jpg", "caption": "Figure 5: Attention map filtering in action. We compare the attention scores of zero123-XL (top) and Zero-to-Hero (bottom) wrt the region marked with a purple circle at different denoising steps. Both methods are initialized with the same seed. We observe that the strong correlation values in the upper right corner lead to exaggerated content creation (note the unrealistically elongated neck). Conversely, through filtering, Zero-to-Hero mitigates these artifacts, leading to robust view synthesis.", "description": "This figure compares attention maps of Zero123-XL and Zero-to-Hero models at different denoising steps.  The focus is on a specific region (purple circle) where strong correlations in Zero123-XL's attention maps lead to unrealistic details (elongated neck). Zero-to-Hero's attention map filtering mitigates these artifacts and produces more realistic results.", "section": "4.3 Robust View Generation via Attention Map Filtering"}, {"figure_path": "3uQtNWNTwz/figures/figures_9_1.jpg", "caption": "Figure 6: Qualitative results for pose-conditioned ControlNet. Qualitative results for pre-trained pose-conditioned ControlNet, without and with AMF. Both methods are initialized with the same seed. AMF leads to results that are more plausible and better align with the conditions.", "description": "This figure shows a comparison of image generation results using a pre-trained ControlNet model versus ControlNet enhanced with the proposed Attention Map Filtering (AMF) method.  The experiment uses three different prompts:  'Superman flying above the ocean,' 'A witch riding her broomstick,' and 'A swimmer dives around sharks, wearing a red swimsuit.' Each prompt is paired with a pose provided as input to the model. The figure demonstrates that the AMF method enhances the quality and realism of the generated images and improves their alignment with the input prompts and pose.", "section": "5.3 Attention Map Filtering Beyond Novel View Synthesis"}, {"figure_path": "3uQtNWNTwz/figures/figures_9_2.jpg", "caption": "Figure 1: Novel views generated from a single source image (far left column) at a specific target view angle (with different seeds), compared between Zero123-XL [27] and our Zero-to-Hero method. Operating during inference, our method achieves significantly higher fidelity and maintains authenticity to the original image, all while ensuring realistic variation in the results (e.g., variations in chair backs in the top row). The ground-truth target view is displayed in the far right column.", "description": "This figure compares the novel view synthesis results of Zero123-XL and the proposed Zero-to-Hero method.  The leftmost column shows the single source image used as input.  The subsequent columns display several novel views generated by each method at the same target angle, using different random seeds. The far right column shows the ground truth target view. The comparison demonstrates that Zero-to-Hero produces more realistic and faithful novel views while maintaining the authenticity of the original image.", "section": "Introduction"}, {"figure_path": "3uQtNWNTwz/figures/figures_14_1.jpg", "caption": "Figure 7: Cross-Attention in Zero-1-to-3. (Left) The cross-attention map before applying softmax. (Right) The degenerated all-ones attention map, produced by applying softmax on the left map.", "description": "This figure demonstrates the issue of degenerated cross-attention in the Zero-1-to-3 model.  The left panel shows the cross-attention map *before* the softmax function is applied.  The right panel shows the map *after* softmax; it has become a uniform all-ones matrix, losing all spatial information that would normally be encoded in the attention weights. This highlights the key limitation the authors address: the inability of the cross-attention layer to effectively inject spatial information based on pose, preventing accurate control over the shape of the generated image.", "section": "8.1 Cross-Attention in Zero-1-to-3"}, {"figure_path": "3uQtNWNTwz/figures/figures_15_1.jpg", "caption": "Figure 3: Through the injection of ground-truth attention maps extracted from the target view, we demonstrate that Self-attention maps are key to robust view synthesis.", "description": "This figure shows the results of an experiment where ground-truth attention maps from the target view were injected into the Zero123-XL model during the generation process. The results demonstrate that self-attention maps are crucial for robust view synthesis, as using the ground truth maps leads to significant improvement in image quality. This supports the paper's claim that manipulating attention maps can significantly enhance the quality of view synthesis.", "section": "4.1 Analyzing the Role of Cross- and Self-Attention Layers in Novel View Generation"}, {"figure_path": "3uQtNWNTwz/figures/figures_16_1.jpg", "caption": "Figure 1: Novel views generated from a single source image (far left column) at a specific target view angle (with different seeds), compared between Zero123-XL [27] and our Zero-to-Hero method. Operating during inference, our method achieves significantly higher fidelity and maintains authenticity to the original image, all while ensuring realistic variation in the results (e.g. variations in chair backs in the top row). The ground-truth target view is displayed in the far right column.", "description": "This figure shows a comparison of novel view synthesis results between the Zero123-XL model and the proposed Zero-to-Hero method.  Multiple generated views from a single source image are shown for each method.  Zero-to-Hero demonstrates improved fidelity, authenticity, and realistic variations compared to Zero123-XL. The rightmost column shows the ground truth target views.", "section": "1 Introduction"}, {"figure_path": "3uQtNWNTwz/figures/figures_20_1.jpg", "caption": "Figure 1: Novel views generated from a single source image (far left column) at a specific target view angle (with different seeds), compared between Zero123-XL [27] and our Zero-to-Hero method. Operating during inference, our method achieves significantly higher fidelity and maintains authenticity to the original image, all while ensuring realistic variation in the results (e.g. variations in chair backs in the top row). The ground-truth target view is displayed in the far right column.", "description": "This figure compares novel view synthesis results from the Zero123-XL model and the proposed Zero-to-Hero method.  Given a single source image, both methods generate multiple novel views from a specific target angle using different random seeds.  The Zero-to-Hero method shows significantly improved fidelity to the source image while maintaining realistic variations and avoiding artifacts present in the Zero123-XL results. The ground truth target view is included for comparison.", "section": "Introduction"}, {"figure_path": "3uQtNWNTwz/figures/figures_21_1.jpg", "caption": "Figure 11: Generation diversity wrt filtering iterations. We select an extreme change in viewpoint, and show how different choices of R, the number of filtering iterations, affect the diversity of generated outputs. As filtering iterations increase, the results become less diverse and more realistic.", "description": "This figure shows the impact of the number of resampling iterations (R) on the diversity of generated images using the Zero-to-Hero method.  As R increases, the model becomes more focused, resulting in less diverse but more realistic outputs. This demonstrates a trade-off between diversity and realism controlled by the parameter R, a key aspect of the attention map filtering technique. The experiment uses a challenging viewpoint change to highlight this effect.", "section": "4.3 Robust View Generation via Attention Map Filtering"}, {"figure_path": "3uQtNWNTwz/figures/figures_21_2.jpg", "caption": "Figure 1: Novel views generated from a single source image (far left column) at a specific target view angle (with different seeds), compared between Zero123-XL [27] and our Zero-to-Hero method. Operating during inference, our method achieves significantly higher fidelity and maintains authenticity to the original image, all while ensuring realistic variation in the results (e.g., variations in chair backs in the top row). The ground-truth target view is displayed in the far right column.", "description": "This figure shows the comparison of novel view generation results between the Zero123-XL baseline method and the proposed Zero-to-Hero method.  Multiple samples are shown for each target angle, demonstrating the improved fidelity, authenticity, and consistency of Zero-to-Hero. The leftmost column shows the input source image, and the rightmost column shows the ground truth target view for comparison. The superior realism and attention to detail in the Zero-to-Hero results are highlighted.", "section": "Introduction"}, {"figure_path": "3uQtNWNTwz/figures/figures_22_1.jpg", "caption": "Figure 3: Through the injection of ground-truth attention maps extracted from the target view, we demonstrate that Self-attention maps are key to robust view synthesis.", "description": "This figure shows a comparison of novel view synthesis results using Zero123-XL, with and without ground-truth (GT) attention maps.  The leftmost column displays the source view. The middle column shows Zero123-XL's results using its own calculated attention maps, while the rightmost column shows the results when the model uses GT attention maps from the target view. The results demonstrate that the self-attention maps play a crucial role in the robustness and quality of view synthesis, as using the GT maps leads to significantly more accurate and realistic results.", "section": "Analyzing the Role of Cross- and Self-Attention Layers in Novel View Generation"}, {"figure_path": "3uQtNWNTwz/figures/figures_23_1.jpg", "caption": "Figure 1: Novel views generated from a single source image (far left column) at a specific target view angle (with different seeds), compared between Zero123-XL [27] and our Zero-to-Hero method. Operating during inference, our method achieves significantly higher fidelity and maintains authenticity to the original image, all while ensuring realistic variation in the results (e.g., variations in chair backs in the top row). The ground-truth target view is displayed in the far right column.", "description": "This figure compares the novel view synthesis results of the Zero123-XL model and the proposed Zero-to-Hero method.  The input source image is shown in the far left column.  Multiple synthesized images for each of three different random seeds are presented for both models, demonstrating the variance in their outputs. The ground truth target view is given in the far right column.  Zero-to-Hero demonstrates improved fidelity and realism compared to Zero123-XL.", "section": "Introduction"}]