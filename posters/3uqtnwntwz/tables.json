[{"figure_path": "3uQtNWNTwz/tables/tables_5_1.jpg", "caption": "Table 1: Quantitative evaluation on a challenging GSO subset. Zero-to-Hero consistently improves performance upon baselines, taking a significant step towards oracle map performance (bottom rows).", "description": "This table presents a quantitative evaluation of the Zero-to-Hero model on a subset of the Google Scanned Objects (GSO) dataset.  The models compared are Zero-1-to-3, Zero123-XL, and the Zero-to-Hero model applied to both.  For each model, results are shown for 25, 50, and 100 denoising steps.  The metrics used are PSNR, SSIM, LPIPS, and IoU.  The bottom rows show oracle results achieved by using ground-truth attention maps.", "section": "5.1 Evaluations"}, {"figure_path": "3uQtNWNTwz/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative evaluation on a challenging GSO subset. Zero-to-Hero consistently improves performance upon baselines, taking a significant step towards oracle map performance (bottom rows).", "description": "This table presents a quantitative comparison of different novel view synthesis methods on a challenging subset of the Google Scanned Objects (GSO) dataset.  The methods compared include Zero-1-to-3, Zero123-XL, and the proposed Zero-to-Hero method,  each tested with varying numbers of denoising steps (25, 50, 100). The results are evaluated using four metrics: PSNR, SSIM, LPIPS, and IoU. The bottom rows of the table show the performance using ground truth (GT) attention maps as an upper bound for comparison. The table highlights Zero-to-Hero's improvement in performance compared to the baseline methods, particularly its advancement towards the performance level achieved with the oracle GT maps.", "section": "5.1 Evaluations"}, {"figure_path": "3uQtNWNTwz/tables/tables_8_2.jpg", "caption": "Table 2: Ablation Study. We demonstrate the importance of each of Zero-to-Hero modules, applied to the base method Zero123-XL: Sample scheduling (Hourglass), Resampling (Resample), Attention map filtering (AMF), and Early-Stage Mutual Self-Attention (MSA). Consistent conclusions are reached with the base model Zero-1-to-3 and are shown in Sec. 8.6 of the appendix.", "description": "This table presents the ablation study of the Zero-to-Hero model. It shows the impact of each component (Hourglass, Resample, AMF, MSA) on the overall performance when applied to the Zero123-XL model.  The results are presented in terms of PSNR, SSIM, LPIPS, and IoU metrics.  The study demonstrates that all components contribute to improved performance.", "section": "5 Experiments"}, {"figure_path": "3uQtNWNTwz/tables/tables_15_1.jpg", "caption": "Table 3: Quantitative evaluation on RTMV dataset. Zero-to-Hero consistently improves performance upon baselines.", "description": "This table presents a quantitative comparison of the performance of Zero-to-Hero against baseline methods (Zero-1-to-3 and Zero123-XL) on the RTMV dataset.  The evaluation metrics include PSNR, SSIM, LPIPS, and IoU, calculated for various numbers of denoising steps (T) and function evaluations (NFE). The results demonstrate that Zero-to-Hero consistently outperforms the baseline methods across all metrics.", "section": "5.1 Evaluations"}, {"figure_path": "3uQtNWNTwz/tables/tables_17_1.jpg", "caption": "Table 4: Runtime analysis of the computational overhead of Zero-to-Hero.", "description": "This table shows a runtime analysis comparing the computational overhead introduced by the Zero-to-Hero method against the base model Zero-1-to-3.  It demonstrates how the inference time scales with the number of generated samples, showing that the increase in runtime is relatively modest compared to the improvement in image quality.", "section": "8.5 Implementation Details"}, {"figure_path": "3uQtNWNTwz/tables/tables_18_1.jpg", "caption": "Table 1: Quantitative evaluation on a challenging GSO subset. Zero-to-Hero consistently improves performance upon baselines, taking a significant step towards oracle map performance (bottom rows).", "description": "This table presents a quantitative evaluation of the Zero-to-Hero model on a challenging subset of the Google Scanned Objects (GSO) dataset.  It compares the performance of Zero-to-Hero against two baseline models (Zero-1-to-3 and Zero123-XL) across four metrics: PSNR, SSIM, LPIPS, and IoU.  The table shows the number of sampled timesteps (T) and the total number of network function evaluations (NFE) for each model.  The results demonstrate that Zero-to-Hero consistently outperforms the baselines, achieving a substantial improvement in all metrics, and making significant progress towards the performance of a hypothetical model with access to ground-truth attention maps.", "section": "5.1 Evaluations"}, {"figure_path": "3uQtNWNTwz/tables/tables_18_2.jpg", "caption": "Table 6: Ablation study: Hourglass scheduling \u2014 Zero123-XL. We demonstrate the superiority of our Hourglass scheduling over uniform DDIM sampling with different number of denoising steps. The experiments are based on Zero123-XL.", "description": "This table presents an ablation study comparing the performance of different sampling schedules within the Zero123-XL model. It contrasts uniform DDIM sampling with varying numbers of steps (25, 50, and 100) against the proposed Hourglass scheduling (26 steps).  The Hourglass method is shown to improve or match the performance of uniform sampling using fewer steps, highlighting its efficiency in novel view synthesis.", "section": "5.2 Ablation Study"}, {"figure_path": "3uQtNWNTwz/tables/tables_19_1.jpg", "caption": "Table 2: Ablation Study. We demonstrate the importance of each of Zero-to-Hero modules, applied to the base method Zero123-XL: Sample scheduling (Hourglass), Resampling (Resample), Attention map filtering (AMF), and Early-Stage Mutual Self-Attention (MSA). Consistent conclusions are reached with the base model Zero-1-to-3 and are shown in Sec. 8.6 of the appendix.", "description": "This table presents the ablation study of the proposed Zero-to-Hero method.  It systematically evaluates the impact of each of its components\u2014Hourglass scheduling, resampling, attention map filtering (AMF), and early-stage mutual self-attention (MSA)\u2014on the performance of the Zero123-XL model.  The results show the contribution of each module to the final performance improvement.  The study also notes that consistent conclusions were obtained when applying the same analysis to the Zero-1-to-3 model.", "section": "5 Experiments"}, {"figure_path": "3uQtNWNTwz/tables/tables_19_2.jpg", "caption": "Table 6: Ablation study: Hourglass scheduling - Zero123-XL. We demonstrate the superiority of our Hourglass scheduling over uniform DDIM sampling with different number of denoising steps. The experiments are based on Zero123-XL.", "description": "This table presents an ablation study comparing different sampling strategies (uniform vs. Hourglass) used in the Zero123-XL model. It shows the impact of the proposed Hourglass scheduling scheme on the performance of the model, measured by PSNR, SSIM, LPIPS, and IoU metrics.  The results demonstrate the effectiveness of the Hourglass scheduler in improving the efficiency and overall performance of the model compared to uniform sampling. The number of sampled timesteps and network function evaluations (NFE) are also reported for each sampling method.", "section": "5.2 Ablation Study"}, {"figure_path": "3uQtNWNTwz/tables/tables_19_3.jpg", "caption": "Table 5: Ablation study - Zero-1-to-3. We demonstrate the importance of each of Zero-to-Hero modules, applied to the base method Zero-1-to-3: Sample scheduling (Hourglass), Resampling (Resample), Attention map filtering (AMF), and Early stage Mutual Self-Attention (MSA).", "description": "This ablation study systematically evaluates the contribution of each component of the Zero-to-Hero method when applied to the Zero-1-to-3 model.  It shows the impact of each module individually and in combination, measuring performance improvements using PSNR, SSIM, LPIPS, and IoU metrics.  The results highlight the relative importance of each component in enhancing the overall quality of novel view synthesis. ", "section": "5.2 Ablation Study"}, {"figure_path": "3uQtNWNTwz/tables/tables_19_4.jpg", "caption": "Table 10: Ablation study: Attention map filtering \u2014 Zero-1-to-3. We demonstrate the importance of Attention Map Filtering over only applying Resampling (Resample). The experiments are based on Zero-1-to-3.", "description": "This table presents the ablation study of applying the Attention Map Filtering (AMF) module of the Zero-to-Hero method to the baseline Zero-1-to-3 model. The study compares the Intersection over Union (IOU) metric for four different settings: without AMF, with only resampling, with AMF and with both AMF and resampling.  The results demonstrate the importance of including both the resampling and the AMF modules for improved performance. The timesteps where mutual self-attention (MSA) is applied are indicated for each method. This shows the effectiveness of AMF alone and in tandem with resampling in improving the results.", "section": "5.2 Ablation Study"}]