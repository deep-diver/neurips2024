[{"figure_path": "IfpNsorodK/tables/tables_16_1.jpg", "caption": "Table 1: The used datasets, codes, and their licenses.", "description": "This table lists the datasets and code used in the paper, along with their respective licenses.  It provides the URLs for easy access to the resources. The information is crucial for reproducibility and ensures proper attribution to the creators and owners of the assets.", "section": "D.1 License"}, {"figure_path": "IfpNsorodK/tables/tables_17_1.jpg", "caption": "Table 2: Sample quality measured by FID\u2193 on the CIFAR10 [42], CelebA 64x64 [43], LSUN-bedroom 256x256 [44], and LSUN-church 256x256 [44] using unconditional discrete-time DPMs, varying the number of function evaluations (NFE). Evaluated on 50k samples. PFDiff uses DDIM [20] and Analytic-DDIM [23] as baselines and introduces DDPM [2] and Analytic-DDPM [23] with \u03b7 = 1.0 from Eq. (6) for comparison.", "description": "This table presents the FID scores for various methods on four datasets (CIFAR10, CelebA 64x64, LSUN-bedroom 256x256, LSUN-church 256x256) using unconditional discrete-time DPMs.  The number of function evaluations (NFE) is varied to show the impact on FID.  DDIM and Analytic-DDIM are used as baselines, with comparisons also made against DDPM and Analytic-DDPM (using \u03b7 =1.0). The PFDiff method is evaluated across all conditions.", "section": "4.1 Unconditional sampling"}, {"figure_path": "IfpNsorodK/tables/tables_18_1.jpg", "caption": "Table 3: Sample quality measured by FID\u2193 on the CIFAR10 [42] and CelebA 64x64 [43] using unconditional discrete-time DPMs with and without our method (PFDiff), varying the number of function evaluations (NFE) and \u03b7 from Eq. (6). Evaluated on 50k samples.", "description": "This table presents the Fr\u00e9chet Inception Distance (FID) scores for different configurations of the experiment. It shows FID scores for DDPM and DDIM with different noise levels (controlled by \u03b7) and with and without PFDiff. The number of function evaluations (NFE) is varied from 4 to 20.  Lower FID scores indicate better sample quality.", "section": "4.1 Unconditional sampling"}, {"figure_path": "IfpNsorodK/tables/tables_18_2.jpg", "caption": "Table 3: Sample quality measured by FID\u2193 on the CIFAR10 [42] and CelebA 64x64 [43] using unconditional discrete-time DPMs with and without our method (PFDiff), varying the number of function evaluations (NFE) and \u03b7 from Eq. (6). Evaluated on 50k samples.", "description": "This table presents the FID scores achieved by different methods on CIFAR10 and CelebA datasets for unconditional discrete-time DPMs.  It compares the performance of DDPM, Analytic-DDPM, Analytic-DDIM, and DDIM with and without the proposed PFDiff method. The FID scores are shown for varying numbers of function evaluations (NFE) and different noise scales (\u03b7).  Lower FID scores indicate better image generation quality.", "section": "4.1 Unconditional sampling"}, {"figure_path": "IfpNsorodK/tables/tables_19_1.jpg", "caption": "Table 5: Sample quality measured by FID\u2193 on the ImageNet 64x64 [32] and ImageNet 256x256 [32], using ADM-G [5] model with guidance scales of 1.0 and 2.0, varying the number of function evaluations (NFE). Evaluated: ImageNet 64x64 with 50k, ImageNet 256x256 with 10k samples. *We directly borrowed the results reported by AutoDiffusion [26], and AutoDiffusion requires additional search costs. *We directly borrowed the results reported by AutoDiffusion [26], and AutoDiffusion requires additional search costs. \u201c\" represents missing data in the original paper.", "description": "This table presents the Fr\u00e9chet Inception Distance (FID) scores for the ImageNet 64x64 and 256x256 datasets, using the ADM-G model with guidance scales of 1.0 and 2.0.  The FID scores are shown for varying numbers of function evaluations (NFE).  The table compares the performance of DDIM, various DPM-Solver methods, AutoDiffusion, and the proposed DDIM+PFDiff method.  Note that AutoDiffusion results were taken directly from the original paper and require additional search costs.", "section": "4.2 Conditional sampling"}, {"figure_path": "IfpNsorodK/tables/tables_20_1.jpg", "caption": "Table 6: Sample quality measured by FID\u2193 on the validation set of MS-COCO2014 [31] using Stable-Diffusion model [9] with guidance scales of 7.5 and 1.5, varying the number of function evaluations (NFE). Evaluated on 10k samples. We borrow the results reported in DPM-Solver-v3 [27] directly.", "description": "This table shows the FID scores for different sampling methods on the MS-COCO2014 dataset using the Stable Diffusion model.  Two guidance scales (7.5 and 1.5) are used, and the number of function evaluations (NFE) varies.  It compares the performance of DDIM, various DPM-Solver methods, UniPC, and DPM-Solver-v3(2M), along with the proposed PFDiff method. Results from DPM-Solver-v3 are directly taken from that paper.", "section": "4.2 Conditional sampling"}, {"figure_path": "IfpNsorodK/tables/tables_21_1.jpg", "caption": "Table 7: Ablation of the impact of k and l on PFDiff in CIFAR10 [42], ImageNet 64x64 and MS-COCO2014 using DDPM [2], ScoreSDE [4], ADM-G [5] and Stable-Diffusion [9] models. We report the FID\u2193, varying the number of function evaluations (NFE). Evaluated: MS-COCO2014 with 10k, others with 50k samples.", "description": "This table presents the results of an ablation study on the hyperparameters k and l of the PFDiff algorithm.  It shows the FID scores (Fr\u00e9chet Inception Distance, a lower score is better) for different configurations of the PFDiff algorithm (PFDiff-1, PFDiff-2_1, PFDiff-2_2, PFDiff-3_1, PFDiff-3_2, PFDiff-3_3) across various datasets (CIFAR10, ImageNet 64x64, and MS-COCO2014) and varying numbers of function evaluations (NFEs). The purpose is to determine the impact of changing k and l on the model's performance.", "section": "4.3 Ablation study"}, {"figure_path": "IfpNsorodK/tables/tables_22_1.jpg", "caption": "Table 3: Sample quality measured by FID\u2193 on the CIFAR10 [42] and CelebA 64x64 [43] using unconditional discrete-time DPMs with and without our method (PFDiff), varying the number of function evaluations (NFE) and \u03b7 from Eq. (6). Evaluated on 50k samples.", "description": "This table presents FID scores for CIFAR10 and CelebA datasets using different methods and varying the number of function evaluations (NFE).  The impact of different noise levels (controlled by \u03b7) on the performance of DDPM, Analytic-DDIM, and DDIM with and without PFDiff is shown. The results highlight the effectiveness of PFDiff in improving sampling quality across different NFE settings and noise levels.", "section": "4.1 Unconditional sampling"}, {"figure_path": "IfpNsorodK/tables/tables_23_1.jpg", "caption": "Table 3: Sample quality measured by FID\u2193 on the CIFAR10 [42] and CelebA 64x64 [43] using unconditional discrete-time DPMs with and without our method (PFDiff), varying the number of function evaluations (NFE) and \u03b7 from Eq. (6). Evaluated on 50k samples.", "description": "This table presents the FID scores for CIFAR10 and CelebA 64x64 datasets using unconditional discrete-time DPMs with different numbers of function evaluations (NFE) and different noise levels (controlled by \u03b7). It compares the performance of DDPM, Analytic-DDPM, Analytic-DDIM, and DDIM with and without the proposed PFDiff method.  The table shows how PFDiff improves the FID scores across various NFE values and noise levels, demonstrating its effectiveness in enhancing the sampling process of unconditional discrete-time DPMs.", "section": "4.1 Unconditional sampling"}]