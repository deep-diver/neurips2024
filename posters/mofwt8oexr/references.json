{"references": [{"fullname_first_author": "Volodymyr Mnih", "paper_title": "Human-level control through deep reinforcement learning", "publication_date": "2015-MM-DD", "reason": "This paper is foundational to the field of deep reinforcement learning, introducing the DQN algorithm that achieved human-level performance in many Atari games."}, {"fullname_first_author": "David Silver", "paper_title": "Mastering the game of Go with deep neural networks and tree search", "publication_date": "2016-MM-DD", "reason": "This paper demonstrates the power of combining deep learning with traditional search algorithms, achieving a breakthrough result in the game of Go."}, {"fullname_first_author": "David Silver", "paper_title": "A general reinforcement learning algorithm that masters chess, shogi, and go through self-play", "publication_date": "2018-MM-DD", "reason": "This work showcases the AlphaZero algorithm's ability to master multiple complex games solely through self-play, highlighting the potential of general-purpose reinforcement learning algorithms."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-MM-DD", "reason": "This paper introduces denoising diffusion probabilistic models, a powerful generative modeling technique that underlies many of the recent advancements in image generation and other fields."}, {"fullname_first_author": "Yang Song", "paper_title": "Consistency models", "publication_date": "2023-MM-DD", "reason": "This paper introduces consistency models, an efficient alternative to traditional diffusion models, which are particularly relevant to the current work on visual reinforcement learning."}]}