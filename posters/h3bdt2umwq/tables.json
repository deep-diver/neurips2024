[{"figure_path": "h3BdT2UMWQ/tables/tables_6_1.jpg", "caption": "Table 1: Detailed descriptions and statistics of datasets. 'Avg. length' represents the average length of item sequences, while 'Avg. num' indicates the average number of words in item text.", "description": "This table presents the key statistics of three datasets used in the paper's experiments: Scientific, Office, and Online Retail.  For each dataset, it shows the number of users, items, and interactions, as well as the average length of the item sequences and the average number of words in the item descriptions. These statistics are crucial for understanding the characteristics of the datasets and interpreting the experimental results.  The average sequence length provides insight into user behavior patterns, indicating how frequently users interact with items, while the average number of words in item descriptions reveals the richness of textual information associated with each item. ", "section": "5.1 Experiment Settings"}, {"figure_path": "h3BdT2UMWQ/tables/tables_7_1.jpg", "caption": "Table 2: Performance of different models. Bold (underline) is used to denote the best (second-best) metric, and '*' indicates significant improvements relative to the best baseline (t-test P<.05). 'R@K' ('N@K') is short for 'Recall@K' ('NDCG@K'). The features of items have been listed, whether ID, text (T), or both (ID+T).", "description": "This table presents the performance comparison of different sequential recommendation models on three datasets (Scientific, Office, Online Retail).  The models are evaluated using Recall@K and NDCG@K metrics (K=10,50).  The table highlights the best and second-best performing models for each metric and dataset, and also notes statistically significant improvements compared to the best baseline model.", "section": "5.2 Overall Performance"}, {"figure_path": "h3BdT2UMWQ/tables/tables_8_1.jpg", "caption": "Table 2: Performance of different models. Bold (underline) is used to denote the best (second-best) metric, and '*' indicates significant improvements relative to the best baseline (t-test P<.05). 'R@K' ('N@K') is short for 'Recall@K' ('NDCG@K'). The features of items have been listed, whether ID, text (T), or both (ID+T).", "description": "This table presents the performance comparison of different sequential recommendation models on three datasets (Scientific, Office, Online Retail).  The models are evaluated using Recall@K and NDCG@K metrics (K=10, 50), and the best and second-best results are highlighted.  The table also indicates whether item features used are IDs, text descriptions (T), or both (ID+T), providing a comprehensive performance analysis across various settings and item feature combinations.", "section": "5.2 Overall Performance"}, {"figure_path": "h3BdT2UMWQ/tables/tables_15_1.jpg", "caption": "Table 2: Performance of different models. Bold (underline) is used to denote the best (second-best) metric, and '*' indicates significant improvements relative to the best baseline (t-test P<.05). 'R@K' ('N@K') is short for 'Recall@K' ('NDCG@K'). The features of items have been listed, whether ID, text (T), or both (ID+T).", "description": "This table presents the performance comparison of different sequential recommendation models on three datasets (Scientific, Office, Online Retail).  The models are evaluated using Recall@K and NDCG@K metrics (K=10, 50).  The table highlights the best and second-best performing models for each metric and dataset, indicating statistically significant improvements where applicable.  It also shows whether item features used by each model included only IDs, text descriptions, or both.", "section": "5.2 Overall Performance"}, {"figure_path": "h3BdT2UMWQ/tables/tables_15_2.jpg", "caption": "Table 5: Comparison of Actual Operational Costs.", "description": "This table compares the GPU memory usage, training time per epoch, and evaluation time per epoch for three different models (UniSRec, DiffuRec, and DDSR) across three datasets (Scientific, Office, and Online Retail).  It provides a quantitative assessment of the computational efficiency and resource demands associated with each model on datasets with varying sizes and characteristics.", "section": "5.2 Overall Performance"}]