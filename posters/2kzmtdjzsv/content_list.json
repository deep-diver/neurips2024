[{"type": "text", "text": "Beyond Task Diversity: Provable Representation Transfer for Sequential Multi-Task Linear Bandits ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Thang Duong University of Arizona thangduong@arizona.edu ", "page_idx": 0}, {"type": "text", "text": "Zhi Wang University of Wisconsin\u2013Madison zhi.wang@wisc.edu ", "page_idx": 0}, {"type": "text", "text": "Chicheng Zhang University of Arizona chichengz@cs.arizona.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study lifelong learning in linear bandits, where a learner interacts with a sequence of linear bandit tasks whose parameters lie in an $m$ -dimensional subspace of $\\mathbf{\\dot{R}}^{d}$ , thereby sharing a low-rank representation. Current literature typically assumes that the tasks are diverse, i.e., their parameters uniformly span the $m$ - dimensional subspace. This assumption allows the low-rank representation to be learned before all tasks are revealed, which can be unrealistic in real-world applications. In this work, we present the first nontrivial result for sequential multitask linear bandits without the task diversity assumption. We develop an algorithm that efficiently learns and transfers low-rank representations. When facing $N$ tasks, each played over $\\tau$ rounds, our algorithm achieves a regret guarantee of $\\tilde{O}\\left(N m\\sqrt{\\tau}+\\bar{N}^{\\frac{2}{3}}\\tau^{\\frac{2}{3}}d m^{\\frac{1}{3}}+N d^{2}\\!+\\!\\tau m d\\right)$ under the ellipsoid action set assumption. This result can significantly improve upon the baseline of $\\tilde{O}\\left(N d\\sqrt{\\tau}\\right)$ that does not leverage the low-rank structure when the number of tasks $N$ is sufficiently large and $m\\ll d$ . We also demonstrate empirically on synthetic data that our algorithm outperforms baseline algorithms, which rely on the task diversity assumption. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recommendation systems that interact with customers to promote the best items for each user have been widely adopted around the world. These interactions are often sequential and can be modelled as linear bandit problems [Abe and Long, 1999, Dani et al., 2008, Rusmevichientong and Tsitsiklis, 2010, Abbasi-Yadkori et al., 2011], where the characteristics of items can be represented as context vectors, and a user\u2019s preference for an item (i.e., reward) can be modelled using a linear combination of the context of the item. Even though the problem is typically high-dimensional, different users may exhibit similar preferences, leading to a low-dimensional underlying reward structure. ", "page_idx": 0}, {"type": "text", "text": "Motivated by this observation, there has been growing interest in representation learning within the context of linear bandits. For instance, in the item recommendation example, each session of interaction with a user can be seen as a linear bandit task, and similarity across tasks can be captured by the existence of a global feature extractor that applies to all problem instances. ", "page_idx": 0}, {"type": "text", "text": "Formally, we consider a problem where the learner sequentially faces $N$ $d$ -dimensional linear bandit tasks, each with horizon $\\tau$ , with a key assumption that the reward predictors of the $N$ tasks, $\\theta_{1},\\dots,\\theta_{N}$ , lie in an $m$ -dimensional linear subspace of $\\mathbb{R}^{d}$ . The goal of the learner is to minimize their meta (pseudo-)regret, which is the sum of regret across all tasks (see Equation (1) below), by exploiting the shared subspace structure. ", "page_idx": 0}, {"type": "text", "text": "One naive approach is to solve each task independently using a base algorithm (such as LinUCB [Abbasi-Yadkori et al., 2011] or PEGE [Rusmevichientong and Tsitsiklis, 2010]); this approach, which we will henceforth refer to as the individual single-task baseline), would yield an upper bound on the meta-regret of $\\tilde{O}(N d\\sqrt{\\tau})$ . On the other hand, had the shared $m$ -dimensional subspace been known beforehand, one would only need to estimate each reward predictor\u2019s projection onto the subspace; this leads to a meta-regret of $\\tilde{O}(N m\\sqrt{\\tau})$ . In this work, we focus on the setting where $N$ and $\\tau$ are large and $m\\ll d$ , the regime in which representation transfer learning would be beneficial. ", "page_idx": 1}, {"type": "text", "text": "Despite rich results for multi-task linear bandits in the parallel setting [e.g. Yang et al., 2020, Hu et al., 2021, Yang et al., 2022, Cella et al., 2023], progresses on multi-task bandits in the sequential setting have been relatively sparse. This can be attributed to the additional challenge of meta-exploration: in addition to exploration in each bandit learning task, one also needs to determine when (in which tasks) to acquire more information on the shared $m$ -dimensional subspace representation. This is in contrast to the parallel setting, where algorithms that treat all tasks equally can achieve a near-optimal regret through a reduction to low-rank linear bandits [Hu et al., 2021, Jang et al., 2021a]. ", "page_idx": 1}, {"type": "text", "text": "Under the assumption that the action sets are well-conditioned ellipsoids, Qin et al. [2022] design an efficient algorithm with a meta-regret of $\\tilde{O}\\left(N m\\sqrt{\\tau}+d m\\sqrt{\\tau N}\\right)$ . However, it relies on an additional key assumption that the tasks are \u201cdiverse\u201d in the $m$ -dimensional subspace: more formally, for any subsequence of tasks $S$ , the $m$ -th eigenvalue of the task parameters\u2019 covariance matrix $\\begin{array}{r}{\\frac{1}{|S|}\\sum_{n\\in S}^{\\bullet}\\theta_{n}\\theta_{n}^{\\dagger}}\\end{array}$ is bounded away from zero (see Tripuraneni et al. [2021] for a related assumption in the supervised regression setting). However, this task diversity assumption is hard to verify and may not even hold in practice. Therefore, we raise the question: ", "page_idx": 1}, {"type": "text", "text": "Can we design sequential multi-task bandit algorithms with provable low meta-regret without strong assumptions on task parameters, especially on task diversity? ", "page_idx": 1}, {"type": "text", "text": "In this paper, we answer this question positively. Under mild assumptions that the action sets are wellconditioned ellipsoids and all task parameters have norms upper and lower bounded by constants, we design an algorithm with a meta-regret of $\\tilde{O}\\left(N m\\sqrt{\\tau}+N^{\\frac{2}{3}}\\tau^{\\frac{2}{3}}d m^{\\frac{1}{3}}+N d^{2}+\\tau m d\\right)^{1}$ , providing the first nontrivial result for sequential multi-task linear bandit without the task diversity assumption. To the best of our knowledge, p\u221arior to our work, no regret bounds better than that of the individual single-task baseline (i.e., $\\bar{o(N d\\sqrt{\\tau})})$ were known for this setting. ", "page_idx": 1}, {"type": "text", "text": "Our algorithm, BOSS, is based on a reduction to a bandit online subspace selection problem. Specifically, for each new task $n$ , our algorithm chooses a subspace, represented by its canonical orthonormal basis $\\hat{B}_{n}$ , to approximate the ground-truth subspace $B$ and guide exploration. To address the challenge of meta-exploration, as choosing different $\\hat{B}_{n}$ \u2019s leads to learning the projections of $\\theta_{n}$ onto different subspaces/directions, our algorithm is designed to randomly meta-explore in some tasks and use them to learn $B$ . Empirically, we demonstrate the effectiveness of our algorithm in a simulated adversarial environment where the task diversity assumption does not hold. ", "page_idx": 1}, {"type": "text", "text": "1.1 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Parallel representation transfer for multi-task linear bandit. The parallel setting where the learner interacts with $N$ tasks simultaneously in each round was initially studied by Yang et al. [2020]. For the finite action setting, under some distributional assumptions on the action set in each round, they provide a total regret lower bound of $\\Omega\\left(N{\\sqrt{m\\tau}}+{\\sqrt{m d\\tau N}}\\right)$ and an algorithm that matches this up to logarithmic factors. For the infinite action setting, they provide a lower bound for the problem of $\\Omega\\left(N m\\sqrt{\\tau}+d\\sqrt{m\\tau N}\\right)$ , which holds even under the task diversity assumption. Under the same task diversity assumption and in the infinite action set setting2, Yang et al. [2022] present an algorithm with a regret guarantee of $\\tilde{O}\\left(N m\\sqrt{\\tau}+d\\sqrt{m\\tau N}\\right)$ . ", "page_idx": 1}, {"type": "table", "img_path": "2kZMtdjzSV/tmp/4b478f2ca9265f474d29c3adef0307a0f8cc984eb4712eb9600af085c4f84d08.jpg", "table_caption": [], "table_footnote": ["Table 1: Comparisons of the settings, assumptions, and regret guarantees in this paper and previous works. A more comprehensive comparison is available in Table 2 of Appendix A. "], "page_idx": 2}, {"type": "text", "text": "For general action spaces, Hu et al. [2021] provide a regret guarantee of $\\tilde{O}\\left(N\\sqrt{m d\\tau}+d\\sqrt{\\tau N m}\\right)$ albeit using a computationally inefficient algorithm. They also provide an extension for multi-task linear reinforcement learning under the assumption of low inherent Bellman error. ", "page_idx": 2}, {"type": "text", "text": "Unlike previous approaches, Cella et al. [2023] relaxes the requirement to know the subspace rank $m$ and the need for the task diversity assumption. Assuming that the action sets are finite and drawn from a specific distribution, by using trace-norm regularization for estimating task parameters and taking actions in a greedy fashion, they provide a regret upper bound of $\\tilde{O}\\left(N\\sqrt{m\\tau}+\\sqrt{d m\\tau N}\\right)$ that matches the lower bound from Yang et al. [2020] up to logarithmic factors. ", "page_idx": 2}, {"type": "text", "text": "Sequential representation transfer for multi-task linear bandit. Compared with the parallel setting, the sequential setting is more challenging, where the learner only interacts with one task at a time; hence, even after many tasks, the reward predictors of the seen tasks may not span the underlying $m$ -dimensional subspace. Qin et al. [2022] avoid this challenge by assuming a task diversity assumption, i.e., any large enough subset of tasks span the underlying $m$ -dimensional subspace in a well-conditioned manner. With this, they provide a meta-regret guarantee $\\bar{O}\\left(N m\\sqrt{\\tau}+d\\bar{m}\\sqrt{\\tau N}\\right)$ which nearly matches a lower bound of $\\Omega\\left(N m\\sqrt{\\tau}+d\\sqrt{m\\tau N}\\right)$ . They also extend their analysis to a nonstationary representation setting where the global feature extractor can change over segments of tasks. Yang et al. [2022] study the sequential setting with an additional assumption that ${\\bar{\\|}}\\theta_{n}\\|=1$ for all tasks; however, it appears that there may be a non-trivial oversight in the analysis.3 ", "page_idx": 2}, {"type": "text", "text": "Bilaj et al. [2024] study a related setting where the task parameters are i.i.d. sampled from a distribution with high variances from a $m$ -dimensional subspace and with low variances in the orthogonal directions. They provide a meta-regret guarantee of at least O\u02dc N \u03c4(d \u2212m) log 1 +\u03bbA (md\u2212m)  , where $\\lambda_{m i n}^{A}$ is the smallest eigenvalue of the empirical covariance matrix of the actions taken. Since a linear bandit algorithm is expected to converge to pull the optimal arm at the end; $\\lambda_{m i n}^{A}$ may be constant when the action space is fixed. Thus, this bound can be as large as $\\tilde{O}(N d\\sqrt{\\tau})$ . For a quick reference, see Table 1 for a comparison between our work and most related works. See also Appendix A for further discussions on related work. ", "page_idx": 2}, {"type": "text", "text": "2 Problem setup ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We consider a sequence of linear bandit tasks of the same length $\\tau$ , described by the task parameters $\\theta_{1},\\cdot\\cdot\\cdot\\,,\\theta_{N}\\in\\mathbb{R}^{d}$ chosen by an environment such that they satisfy Assumption 1. The learner solves $N$ tasks sequentially. In task $n$ , for each time step $t=1,\\dots,\\tau$ , the learner chooses an action $A_{n,t}$ from the action set $\\boldsymbol{\\mathcal{A}}$ that satisfies Assumption 2 and receives a reward $r_{n,t}=A_{n,t}^{\\top}\\theta_{n}+\\eta_{n,t}$ , where $\\eta_{n,t}$ is independent, mean-zero 1-sub-Gaussian noise. The learner then moves on to task $n+1$ and repeats the same learning process. ", "page_idx": 2}, {"type": "text", "text": "1: Input: Task index $n$ , exploration length $\\tau_{1}$ (a multiple of $d$ )   \n2: for $i\\in[d]$ do   \n3: Let $A_{n,t}=\\lambda_{0}e_{i}$ for $t=u(i-1)+1,\\cdots,u i$ , where $\\begin{array}{r}{u=\\frac{\\tau_{1}}{d}}\\end{array}$   \n4: end for   \n5: for time step $t\\gets1,\\cdots\\,,\\tau_{1}$ do   \n6: Take action $A_{n,t}$ and receive the reward $\\boldsymbol{r}_{\\!\\;\\!n,t}$   \n7: end for   \n8: Compute $\\begin{array}{r}{\\widehat{\\theta}_{n}:=\\operatorname*{argmin}_{\\theta\\in\\mathbb{R}^{d}}\\frac{1}{\\tau_{1}}\\sum_{t=1}^{\\tau_{1}}\\left(\\langle A_{n,t},\\theta\\rangle-r_{n,t}\\right)^{2}}\\end{array}$   \n9: for time step $t\\gets\\tau_{1}+1,\\cdot\\cdot\\cdot\\,,\\bar{\\tau}\\,\\mathbf{d}$ o   \n10: Take action $A_{n,t}\\leftarrow\\arg\\operatorname*{max}_{a\\in\\mathcal{A}}\\left\\langle a,\\hat{\\theta}_{n}\\right\\rangle$   \n11: end for ", "page_idx": 3}, {"type": "text", "text": "Assumption 1 (Low-rank representation). Let $m<d.$ . For task parameters $\\theta_{1},\\cdot\\cdot\\cdot,\\theta_{N}$ , there exist $(i)$ a global feature extractor $\\dot{B}\\in\\mathbb{R}^{d\\times m}$ with orthogonal columns and $(i i)$ vectors $w_{1},\\dots,w_{N}\\in\\mathbb{R}^{m}$ , such that $\\theta_{i}=B w_{i}$ for all $i\\in[N]$ . ", "page_idx": 3}, {"type": "text", "text": "Given a semi-orthonormal matrix $U\\,\\in\\,\\mathbb{R}^{d\\times m}$ (i.e., $U^{\\top}U\\,=\\,I_{m})$ ), denote by $U_{\\perp}\\,\\in\\,\\mathbb{R}^{d\\times(d-m)}$ a matrix whose columns constitute an orthonormal basis of the orthogonal complement of $\\operatorname{span}(U)$ , where we break ties in dictionary order4. We also denote the $i$ -th column vector of $U$ by $U(i)$ . ", "page_idx": 3}, {"type": "text", "text": "Following Rusmevichientong and Tsitsiklis [2010] and [Qin et al., 2022], we also assume that the action set $\\boldsymbol{\\mathcal{A}}$ is an ellipsoid and the task parameters have bounded $\\ell_{2}$ norms: ", "page_idx": 3}, {"type": "text", "text": "Assumption 2 (Linear bandits with ellipsoid action sets). The action set ${\\mathcal{A}}\\quad:=$ $\\left\\{x\\in\\bar{\\mathbb{R}^{d}}:\\ x^{\\top}M^{-1}x\\leq1\\right\\}$ is an ellipsoid, where $M$ is a symmetric, positive definite matrix. $I n$ addition, there exist constants $\\theta_{\\mathrm{min}}$ and $\\theta_{\\mathrm{max}}$ such that for all tasks $n\\in[N].$ , $\\theta_{\\mathrm{min}}\\leq\\|\\theta_{n}\\|_{2}\\leq\\theta_{\\mathrm{max}}$ . ", "page_idx": 3}, {"type": "text", "text": "We define the expected pseudo-regret for task $n$ as $\\begin{array}{r}{R_{\\tau}^{n}:=\\operatorname*{max}_{a\\in\\mathcal{A}}\\mathbb{E}\\left[\\sum_{t=1}^{\\tau}a^{\\top}\\theta_{n}-\\sum_{t=1}^{\\tau}A_{n,t}^{\\top}\\theta_{n}\\right]\\!,}\\end{array}$ , and the meta-regret for all $N$ tasks as ", "page_idx": 3}, {"type": "equation", "text": "$$\nR_{\\tau}:=\\sum_{n=1}^{N}R_{\\tau}^{n}=\\sum_{n=1}^{N}\\operatorname*{max}_{a\\in\\mathcal{A}}\\mathbb{E}\\left[\\sum_{t=1}^{\\tau}a^{\\top}\\theta_{n}-\\sum_{t=1}^{\\tau}A_{n,t}^{\\top}\\theta_{n}\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The learner\u2019s goal is to sequentially interact with each task in a way that minimizes its meta-regret. ", "page_idx": 3}, {"type": "text", "text": "3 Algorithm ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Unlike in the parallel setting or the sequential setting with a task diversity assumption, here, the learner cannot directly learn the global feature extractor $B$ . Instead, it needs to reason with the uncertainty about $B$ learned from the seen tasks. ", "page_idx": 3}, {"type": "text", "text": "High-level idea of our approach. To simultaneously learn $B$ online and utilize our (imperfect) knowledge of it, we solve the sequential multi-task bandit problem using a bi-level approach: ", "page_idx": 3}, {"type": "text", "text": "\u2022 At the lower level, for each task $n$ , the learner has the option of invoking two base algorithms: one performs naive exploration that does not incorporate our knowledge on $B$ , using a variant of fulldimensional linear bandit algorithm (PEGE [Rusmevichientong and Tsitsiklis, 2010], Algorithm 1); the other tries to incorporate a learned subspace $\\hat{B}$ as prior knowledge to get reduced regret (Algorithm 2). Algorithm 1 and 2 can be viewed as performing meta-exploration and meta-exploitation respectively: Algorithm 1, while ignoring the low-dimension property of the tasks, produces unbiased estimators of $\\theta_{n}$ that helps learn the task subspace $B$ ; Algorithm 2 allows the learner to achieve a much lower regret when the subspace B\u02c6 approximately contains $\\theta_{n}$ ; however, using it may slow down the learning of $B$ . ", "page_idx": 3}, {"type": "text", "text": "1: Input: Task index $n$ , exploration length $\\tau_{2}$ (a multiple of $m$ ), and the subspace orthonormal   \nbasis $\\hat{B}_{n}\\in\\mathbb{R}^{d\\times m}$   \n2: for $i\\in[m]$ do   \n3: Let $A_{n,t}=\\lambda_{0}\\hat{B}_{n}(i)$ for $t=u(i-1)+1,\\cdots,u i$ , where $\\textstyle u={\\frac{\\tau_{2}}{m}}$   \n4: end for   \n5: for time step $t\\gets1,\\cdots\\,,\\tau_{2}$ do   \n6: Take action $A_{n,t}$ and receive the reward $\\boldsymbol{r}_{\\!\\;\\!n,t}$   \n7: end for   \n8: Compute $\\begin{array}{r}{\\hat{w}_{n}:=\\operatorname*{argmin}_{w\\in\\mathbb{R}^{m}}\\frac{1}{\\tau_{2}}\\sum_{t=1}^{\\tau_{2}}\\left(\\left\\langle A_{n,t},\\hat{B}_{n}w\\right\\rangle-r_{n,t}\\right)^{2}}\\end{array}$   \n9: Let $\\hat{\\theta}_{n}:=\\hat{B}_{n}\\hat{w}_{n}$   \n10: for time step $t\\gets\\tau_{2}+1,\\cdot\\cdot\\cdot\\,,\\tau\\,\\mathbf{d}$ o   \n11: Take action $A_{n,t}\\leftarrow\\arg\\operatorname*{max}_{a\\in\\mathcal{A}}\\left\\langle a,\\hat{\\theta}_{n}\\right\\rangle$   \n12: end for ", "page_idx": 4}, {"type": "text", "text": "\u2022 At the upper level, the learner has two decisions to make for each task $n$ : (1) choosing between meta-exploration and meta-exploitation; (2) choosing a subspace $\\hat{B}_{n}$ to use if performing metaexploitation. To this end, we propose Algorithm 3, which aims at making these decisions in a feedback-driven way to ensure low meta-regret. ", "page_idx": 4}, {"type": "text", "text": "We now elaborate on each level in more detail. ", "page_idx": 4}, {"type": "text", "text": "The lower level. As mentioned above, Algorithm 1 is for meta-exploration. When invoked in task $n$ , it can achieve two goals simultaneously: obtaining an unbiased estimate of $\\theta_{n}$ , while maintaining a reasonable regret guarantee for task $n$ . For the first $\\tau_{1}$ steps (line 3 to 6), the learner takes actions {\u03bb0ei}i=1 that span the action space $\\boldsymbol{\\mathcal{A}}$ , where $e_{i}$ is the $i$ -th canonical vector of $\\mathbb{R}^{d}$ and $\\lambda_{0}=\\sqrt{\\lambda_{\\operatorname*{min}}(M)}$ is a constant factor that ensures $\\lambda_{0}e_{i}\\in A$ (recall Assumption 2). ", "page_idx": 4}, {"type": "text", "text": "Then, the learner estimates task parameter $\\hat{\\theta}_{n}$ in line 8 and acts greedily for the rest of the task (line 10). We summarize its guarantee (originally due to Rusmevichientong and Tsitsiklis [2010]) as follows: ", "page_idx": 4}, {"type": "text", "text": "Lemma 3. Fix $\\tau_{1}$ to be a multiple of d. Suppose Algorithm 1 is run on task $n$ with the exploration length $\\tau_{1}$ . Then, there exists some constant $c_{1},c_{2}>0$ (that depends on $\\lambda_{0},\\theta_{\\mathrm{max}}$ , $\\theta_{\\mathrm{min}}$ , and $M$ ) such that: ", "page_idx": 4}, {"type": "text", "text": "1. The regret on task n is bounded as $\\begin{array}{r}{R_{\\tau}^{n}\\leq c_{1}\\cdot\\left(\\boldsymbol{\\tau}_{1}+\\boldsymbol{\\tau}\\cdot\\frac{d^{2}}{\\tau_{1}}\\right)=:C_{i n f o},}\\end{array}$   \n2. With probability $1-\\delta$ , it returns $\\widehat{\\theta}_{n}$ such that $\\begin{array}{r}{\\|\\widehat{\\theta}_{n}-\\theta_{n}\\|\\leq c_{2}\\cdot\\left(d\\sqrt{\\frac{\\ln\\frac{d}{\\delta}}{\\tau_{1}}}\\right)=:\\alpha.}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "We defer the proof of this lemma to Appendix E. Lemma 3 reveals a tradeoff between meta-exploration and regret minimization for task $n$ : if $\\tau_{1}$ is larger (say, closer to $\\tau$ ), $\\hat{\\theta}_{n}$ estimates $\\theta_{n}$ more accurately; however, this may yield a worse bound on $R_{\\tau}^{n}$ . ", "page_idx": 4}, {"type": "text", "text": "On the other hand, Algorithm 2 is for meta-exploitation. It takes a subspace (represented by its orthonormal basis $\\hat{B}$ ) as input, and when invoked in task $n$ , it can achieve a lower regret guarantee than Algorithm 1 when the subspace contains vectors that closely approximate $\\theta_{n}$ . Instead of exploring $\\mathbb{R}^{d}$ , the learner only explores the subspace induced by $\\hat{B}_{n}$ (lines 3 and 6). Then, the learner estimates the low-dimensional task parameter $\\hat{w}_{n}$ in line 9 and acts greedily for the rest of the task (line 11). We summarize its guarantee (originally due to Yang et al. [2020]) as follows: ", "page_idx": 4}, {"type": "text", "text": "Lemma 4. Fixed $\\tau_{2}$ to be a multiple of $m$ . Suppose Algorithm 2 is run on task n with input subspace $\\hat{B}_{n}$ and the exploration length $\\tau_{2}$ . Then, there exists some constant $c>0$ (that depends on $\\lambda_{0},\\theta_{\\mathrm{max}},\\theta_{\\mathrm{min}}$ , and $M$ ), such that the regret on task n is bounded as: ", "page_idx": 4}, {"type": "equation", "text": "$$\nR_{\\tau}^{n}\\leq c\\cdot\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|_{2}^{2}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Algorithm 3 BOSS: Bandit Online Subspace Selection for Sequential Multitask Linear Bandits. The full algorithm 4 is in Appendix A. ", "page_idx": 5}, {"type": "text", "text": "1: Input: Task length $\\tau$ , number of task $N$ , task dimension $d$ , subspace dimension $m$ , and explo  \nration rate $p$ .   \n2: Initialize: An uniform distribution $D_{0}$ over the set of experts $\\mathcal{E}^{\\varepsilon}$ in Definition 5   \n3: for $n\\in[N]$ : do   \n4: Randomly draw $\\hat{B}_{n}$ from $D_{n}$   \n5: With probability $p$ : $Z_{n}=1$ , otherwise $Z_{n}=0$   \n6: if $Z_{n}=1$ then   \n7: Exploration procedure in Algorithm 1   \n8: Update the distribution $D_{n+1}$ with the EWA algorithm   \n9: else   \n10: Exploitation procedure in Algorithm 2 with $\\hat{B}_{n}$   \n11: end if   \n12: end for ", "page_idx": 5}, {"type": "text", "text": "Lemma 4 reveals the opportunistic nature of Algorithm 2: if $\\theta_{n}$ is perfectly contained in the subspace spanned by $\\hat{B}$ , $\\|\\hat{B}_{\\perp}^{\\top}\\theta_{n}\\|=0$ and the regret bound is $\\begin{array}{r}{R_{\\tau}^{n}\\le O\\left(\\tau_{2}+\\tau\\cdot\\frac{m^{2}}{\\tau_{2}}\\right)}\\end{array}$ , which can be as low as $O(m{\\sqrt{\\tau}})$ ; on the other extreme, $\\|\\hat{B}_{\\perp}^{\\top}\\theta_{n}\\|$ can be as large as $\\lVert\\theta_{n}\\rVert$ in the worst case, which yields a trivial linear regret bound. Thus, its regret guarantee hinges on good choices of subspace $\\hat{B}$ as input. ", "page_idx": 5}, {"type": "text", "text": "The upper level. For the upper level, we propose Algorithm 3 that decides (1) when to perform meta-exploration and (2) the subspace to use if performing meta-exploitation. ", "page_idx": 5}, {"type": "text", "text": "For (1), for each task, the learner chooses to explore the subspace with probability $p$ (line 6) or exploit with the online subspace estimate $\\hat{B}_{n}$ (line 12). ", "page_idx": 5}, {"type": "text", "text": "For (2), we propose to choose B\u02c6n nN=1 t hat can optimize the following cost function online5: ", "page_idx": 5}, {"type": "equation", "text": "$$\nC_{n}(B):=\\left\\{\\!\\!\\begin{array}{l l}{\\mathbf{C}_{\\mathrm{hit}}:=\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\alpha^{2}\\right)}&{\\|B_{\\bot}^{\\top}\\theta_{n}\\|_{2}\\leq2\\alpha}\\\\ {\\mathbf{C}_{\\mathrm{miss}}:=\\tau}&{\\mathrm{otherwise}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The motivation behind this definition of $C_{n}$ is as follows: according to Lemma 4, $C_{n}(\\hat{B}_{n})$ is (up to constant) an upper bound of the regret of the learner at task $n$ , were the learner to invoke Algorithm 2 using $\\hat{B}_{n}$ for this task. Therefore, if we can guarantee $\\textstyle\\sum_{n=1}^{N}C_{n}({\\hat{B}}_{n})$ to be small, then using Algorithm 2 for all tasks yields a small meta-regret. ", "page_idx": 5}, {"type": "text", "text": "An immediate challenge in directly optimizing $C_{n}$ defined in Eq. (2) is its dependence on unobserved quantity $\\theta_{n}$ . This challenge is further complicated by the following: (i) at best, we observe $\\hat{\\theta}_{n}$ \u2019s that are $\\alpha$ -approximations of $\\theta_{n}$ (e.g. in those meta-exploration tasks, see Lemma 3); (ii) in metaexploitation tasks, we do not have guarantees on how close $\\widehat{\\theta}_{n}$ is to $\\theta_{n}$ . ", "page_idx": 5}, {"type": "text", "text": "To address the challenge (i), we propose to optimize the following surrogate cost function for $C_{n}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{C}_{n}(B):=\\left\\{\\begin{array}{l l}{\\mathbf{C}_{\\mathrm{hit}}}&{\\|B_{\\perp}^{\\top}\\hat{\\boldsymbol{\\theta}}_{n}\\|\\leq\\alpha}\\\\ {\\mathbf{C}_{\\mathrm{miss}}}&{\\mathrm{otherwise}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In Lemma 11, we show that, with high probability, ${\\tilde{C}}_{n}$ is an upper bound of $C_{n}$ . ", "page_idx": 5}, {"type": "text", "text": "With this modification of the optimization objective, challenge (ii) persists: ${\\tilde{C}}_{n}$ is not a valid upper bound of $C_{n}$ for all rounds $n$ ; to ensure this upper bound property, we propose to optimize the cost: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\bar{C}_{n}(B):=\\tilde{C}_{n}(B)\\cdot\\frac{Z_{n}}{p},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where we introduce the importance weighting multiplier $\\frac{Z_{n}}{p}$ . Our key observation is that, although $\\bar{C}_{n}(B)$ is no longer an upper bound of $C_{n}(B)$ , the upper bound property holds $i n$ -expectation; to see this, observe that for any fixed $B$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}_{Z_{n}}\\left[\\bar{C}_{n}(B)\\right]=\\mathbb{E}_{Z_{n}}\\left[\\tilde{C}_{n}(B)\\cdot\\frac{Z_{n}}{p}\\right]\\gtrsim\\mathbb{E}_{Z_{n}}\\left[C_{n}(B)\\cdot\\frac{Z_{n}}{p}\\right]=C_{n}(B),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "here, the first equality is from the definition of $\\bar{C}_{n}(B)$ ; the inequality (here, $\\gtrsim$ indicates greater than up to a negligible constant) uses the property that when $Z_{n}=1$ , with high probability, $\\tilde{C}_{n}(B)\\geq C_{n}(B)$ ; the second equality is from the fact that $Z_{n}\\sim\\operatorname{Ber}(p)$ . ", "page_idx": 6}, {"type": "text", "text": "Following the online learning literature, we propose to use the Exponential Weight Algorithm (EWA) Freund and Schapire [1997] to optimize $\\left\\{\\bar{C}_{n}(B)\\right\\}$ online. Ideally, we would like to run EWA with the $\\mathcal{B}=\\left\\{B:B\\in\\mathbb{R}^{d\\times m}\\;\\mathrm{s.t.}\\;B^{\\top}B=I_{m}\\right\\}$ , the set of all $m$ -dimensional subspaces; however, this is impossible because $|\\beta|$ is infinite. So instead, we propose to run EWA with the expert set defined as an $\\varepsilon$ -cover of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ : ", "page_idx": 6}, {"type": "text", "text": "Definition 5. $\\mathcal{E}^{\\varepsilon}$ is said to be a $\\varepsilon$ -cover over the set of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ in the principal angle sense , if: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\forall\\;B\\in\\mathcal{B},\\;\\exists B^{\\prime}\\in\\mathcal{E}^{\\varepsilon}\\;s u c h\\;t h a t\\;\\|B_{\\perp}^{\\top}B^{\\prime}\\|_{F}\\leq\\varepsilon\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Definition 5 is motivated by the well-known fact that $\\|\\boldsymbol{B}_{\\perp}^{\\top}\\boldsymbol{B}^{\\prime}\\|_{F}$ is the Frobenius norm of the sine of the principal angle matrix between subspaces spanned by $B$ and $B^{\\prime}$ . In Appendix C we show that there is a construction of $\\mathcal{E}^{\\varepsilon}$ of size $O\\left(\\overline{{(\\sqrt{d m}/\\varepsilon)^{d m}}}\\right)$ . In subsequent discussions, we will assume that BOSS uses such a $\\mathcal{E}^{\\varepsilon}$ . ", "page_idx": 6}, {"type": "text", "text": "Define a constant shift and scaling of $\\bar{C}_{n}$ $\\begin{array}{r}{\\mathbf{\\Lambda}_{\\mathfrak{z}},\\,\\ell_{n}(B)\\,:=\\,\\frac{p}{\\mathbf{C}_{\\mathrm{miss}}}\\left[\\bar{C}_{n}(B)-\\mathbf{C}_{\\mathrm{hit}}\\frac{Z_{n}}{p}\\right]}\\end{array}$ ; we note that any regret guarantee over sequence $\\{\\ell_{n}\\}$ immediately translates to a regret guarantee over sequence $\\left\\{{\\bar{C}}_{n}\\right\\}$ . By the construction of the expert set $\\mathcal{E}^{\\varepsilon}$ , sequence $\\{\\ell_{n}\\}$ is realizable with high probability: there exists some $B_{\\varepsilon}\\in\\mathcal{E}^{\\varepsilon}$ such that $\\begin{array}{r}{\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})=0}\\end{array}$ ; this allows EWA to achieve a constant regret guarantee, summarized as follows: ", "page_idx": 6}, {"type": "text", "text": "Lemma 6. Let $\\begin{array}{r}{\\varepsilon=\\alpha=c_{2}d\\sqrt{\\frac{\\ln\\frac{d}{\\delta}}{\\tau_{1}}}}\\end{array}$ ln\u03c4 1\u03b4d (with c2 defined in Lemma 3) and \u03b4 \u2208[0, 1] be a constant such that $\\begin{array}{r}{\\frac{N^{2}}{c d m}\\delta+\\frac{1}{2}\\ln\\ln\\frac{d}{\\delta}\\leq\\ln m\\sqrt{\\tau_{1}}}\\end{array}$ , where $c$ is a constant in Lemma 13. ", "page_idx": 6}, {"type": "text", "text": "Then, Algorithm 3 chooses a sequence of subspaces $\\left\\{{\\hat{B}}_{n}\\right\\}$ over the expert set $\\mathcal{E}^{\\varepsilon}$ , defined in Definition 5, such that: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\sum_{n=1}^{N}\\mathbb{E}\\left[C_{n}(\\hat{B}_{n})\\right]\\leq O\\left(N C_{h i t}+\\frac{C_{m i s s}\\log|\\mathcal{E}^{\\varepsilon}|}{p}\\right)=\\tilde{O}\\left(N\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\alpha^{2}\\right)\\right)+\\frac{\\tau d m}{p}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Note that the cumulative cost bound of $\\left\\{{\\hat{B}}_{n}\\right\\}$ has two terms: the benchmark term $N\\mathbf{C_{\\mathrm{{hit}}}}$ and the regret bound term Cmis slog p|E\u03b5|. The benchmark term represents the best-case regret bound one can achieve if, for all task $n$ , the chosen subspace $\\hat{B}_{n}$ can well approximate $\\theta_{n}$ (i.e. $\\|(\\hat{B}_{n})_{\\perp}^{\\top}\\hat{\\theta}_{n}\\|\\leq\\alpha)$ On the other hand, the regret-bound term depends on a few important factors: first, the cost decreases when the meta-exploration probability $p$ increases \u2013 this matches our intuition that a larger $p$ gives more frequent feedback to learn about $\\theta_{n}$ , allowing the learned $\\hat{B}_{n}$ to adapt faster to $\\theta_{n}$ ; second, the cost depends logarithmically on the size of the expert set $\\ln|\\mathcal{E}^{\\varepsilon}|$ , which is standard in the online learning from expert advice literature; third, the cumulative cost depends on the range of the instantaneous costs $\\mathbf{C}_{\\mathrm{miss}}$ . ", "page_idx": 6}, {"type": "text", "text": "Remark 1. The subspace selection game in the upper level resembles the partial monitoring problem [see Lattimore and Szepesv\u00e1ri, 2020, Chapter 37], where the learner does not directly observe the loss for its actions but receives signals from an environment according to an observation matrix. Here, in our subspace selection problem, the learner does not directly observe the chosen subspace\u2019s cost for most tasks, except when they choose to explore the subspace $B$ . Unlike the traditional partial monitoring problem, here, the observation would be $\\hat{\\theta}_{n}$ , and the cost $C_{n}(B)$ depends on the chosen subspace $B$ and $\\theta_{n}$ . This means that the cost matrix has an infinite number of columns (one for each $B$ ) and the observation depends on the actions of the learner and the environment in a stochastic fashion, unlike a deterministic dependence in the original partial monitoring setting. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4 Performance Guarantees ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We bound the meta-regret of Algorithm 3 in Theorem 7: ", "page_idx": 7}, {"type": "text", "text": "Theorem 7. With exploration probability $\\begin{array}{r}{p\\ =\\ \\operatorname*{min}\\left(\\left(\\frac{2m\\sqrt{\\tau}}{N}\\right)^{\\frac{2}{3}},1\\right)}\\end{array}$ by choosing $\\varepsilon\\ =\\ \\alpha\\ =$ $c_{2}d\\sqrt{\\frac{\\ln\\frac{d}{\\delta}}{\\tau_{1}}}$ (with $c_{2}$ defined in Lemma $3$ ) , where $\\begin{array}{r}{\\delta\\,=\\,\\frac{\\ln|\\mathcal{E}^{\\varepsilon}|}{N^{2}}}\\end{array}$ , and $\\begin{array}{r}{\\tau_{1}\\,=\\,d\\cdot\\,\\left\\lfloor\\operatorname*{min}\\left(d\\sqrt{\\frac{\\tau}{p}},\\tau\\right)/d\\right\\rfloor}\\end{array}$ , $\\tau_{2}=m\\cdot\\lfloor\\sqrt{\\tau}\\rfloor$ , the meta-regret of the BOSS algorithm is bounded by: ", "page_idx": 7}, {"type": "equation", "text": "$$\nR_{\\tau}\\leq\\tilde{O}\\left(N m\\sqrt{\\tau}+N^{\\frac{2}{3}}\\tau^{\\frac{2}{3}}d m^{\\frac{1}{3}}+N d^{2}+\\tau m d\\right).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "In the meta-regret bound (5), we vi\u221aew the first two terms as the main terms and the last two as \u201cburn-in\u201d terms. The first term, $N m\\sqrt{\\tau}$ is the cumulative regret bound of the oracle baseli\u221ane, i.e. the idealized algorithm that takes advantage of the extra knowledge of $B$ to achieve a $O(m{\\sqrt{\\tau}})$ regret for every task. The second term, $N^{\\frac{2}{3}}\\tau^{\\frac{2}{3}}d m^{\\frac{1}{3}}$ is the main overhead for learning the representation $B$ ; it grows sublinearly in $N$ , and as a consequence, is dominated by the first term when the number of tasks $N$ is very large (specifically, $\\begin{array}{r}{N\\gg\\frac{\\bar{d}^{3}\\sqrt{\\tau}}{m^{2}}.}\\end{array}$ dm2\u03c4 ). Compared with multi-task regret bounds in the parallel setting [Yang et al., 2020, Hu et al., 2021], our dependence on $N$ is admittedly weaker; nevertheless, to our knowledge, Theorem 7 is the first nontrivial result in the sequential setting without task diversity assumptions, which has not been studied before in [e.g., Qin et al., 2022]. ", "page_idx": 7}, {"type": "text", "text": "For the burn-in terms, the $N d^{2}$ term can be interpreted as a constant $d^{2}$ regret overhead per task; the \u03c4md term can be interpreted as the learner sacrificing a constant number of tasks (md tasks) to learn a good representation $B$ . Observe that, in the less favourable situation where $N<m d$ or $\\tau<d^{2}$ , the burn-in terms would lead to regret bounds worse than the trivial $N\\tau$ . ", "page_idx": 7}, {"type": "text", "text": "Comparison with the indiv\u221aidual single task baseline. Recall that the individual single-task baseline has a meta-reg\u221aret of $O(N d\\sqrt{\\tau})$ ; our meta-regret guarantee improves over this baseline when $\\tau\\gg d^{2}$ and $N\\gg m\\bar{\\sqrt{\\tau}}$ . We leave broadening the parameter regimes when our guarantee outperforms the individual single-task baseline as an important open problem. ", "page_idx": 7}, {"type": "text", "text": "Comparison with lower bounds. Qin et al. [2022] showed a lower bound for the problem: $\\Omega\\left(N m\\sqrt{\\tau}+d\\sqrt{m\\tau N}\\right)$ . We can see that there still exists a gap between our upper bound in Theorem 7 with this, and the gap is bigger than other solutions with task diversity assumption such as Qin et al. [2022]; we speculate that this is a price we pay due to not making any assumptions on task diversity. ", "page_idx": 7}, {"type": "text", "text": "We now sketch the proof of Theorem 7 below. ", "page_idx": 7}, {"type": "text", "text": "Proof sketch. Denote the pseudo-regret for task $n$ as $\\begin{array}{r}{\\hat{R}_{\\tau}^{n}:=\\tau\\operatorname*{max}_{a\\in\\mathcal{A}}\\big\\langle\\theta_{n},a\\big\\rangle-\\sum_{t=1}^{\\tau}\\big\\langle\\theta_{n},A_{n,t}\\big\\rangle.}\\end{array}$ . ", "page_idx": 7}, {"type": "text", "text": "We decompose $R_{\\tau}$ as follows: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle R_{\\tau}=\\sum_{n=1}^{N}\\mathbb{E}\\left[\\hat{R}_{\\tau}^{n}\\right]=\\sum_{n=1}^{N}\\mathbb{E}\\left[\\hat{R}_{\\tau}^{n}Z_{n}+\\hat{R}_{\\tau}^{n}(1-Z_{n})\\right]}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{\\quad=\\sum_{n=1}^{N}\\mathbb{E}\\left[\\hat{R}_{\\tau}^{n}\\mid Z_{n}=1\\right]\\cdot p+\\sum_{n=1}^{N}\\mathbb{E}\\left[\\hat{R}_{\\tau}^{n}\\mid Z_{n}=0\\right]\\cdot(1-p)}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{\\le\\mathbf{C}_{\\mathrm{inte}}\\cdot N p+\\sum_{n=1}^{N}\\mathbb{E}\\left[C_{n}(\\hat{B}_{n})\\right]}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\\\ {{=\\bar{O}\\left(\\left(\\tau_{1}+\\tau\\cdot\\frac{d^{2}}{\\tau_{1}}\\right)N p+N\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\frac{d^{2}}{\\tau_{1}}\\right)\\right)+\\frac{\\tau d m}{p}\\right)}}\\\\ {{\\displaystyle}}\\\\ {{\\displaystyle}}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where the first two equalities are by the definition of $R_{\\tau}$ and algebra; the third equality uses the law of total expectation; the inequality uses Lemmas 3 and 4 to bound the first and second terms, respectively; the fourth equality is due to the definition of $\\mathbf{C}_{\\mathrm{info}}$ and Lemma 6; the last equality is by algebra. ", "page_idx": 8}, {"type": "text", "text": "The meta-regret of Algorithm 3 follows from the choices of $\\tau_{1},\\tau_{2}$ , and $p$ \u2013 specifically, $\\tau_{2}$ balances the last two terms, whereas $\\tau_{1}$ and $p$ aims at balancing the first three terms subject to the constraint that $\\tau_{1}\\leq\\tau$ and $p\\leq1-\\mathrm{see}$ Appendix H for the remaining details. \u53e3 ", "page_idx": 8}, {"type": "text", "text": "Adaptivity to problem parameters. Algorithm 3 requires the knowledge of $N$ and $m$ , the total number of tasks and the dimensionality of the subspace underlying the task parameters. Below, we show that knowledge of $N$ can be relaxed. ", "page_idx": 8}, {"type": "text", "text": "We can relax the need to know $N$ by using the doubling trick on BOSS. Specifically, in phase $i$ , we can run our algorithm with the assumption that there are $2^{i}$ total tasks in this phase. The modified algorithm has a meta-regret guarantee that is within a constant of the algorithm that knows $N$ . This implicitly gives an adaptive setting of meta-exploration probability $p$ that is decaying over time. ", "page_idx": 8}, {"type": "text", "text": "For $m$ , the requirement can be relaxed to knowing an upper bound of $m$ . Removing this knowledge requires a change of approach, such as low-rank matrix optimization, as in Cella et al. [2023] or additional assumption, as in Bilaj et al. [2024]. Cella et al. [2023] is in the parall\u221ael setting, which is not applicable here, and Bilaj et al. [2024]\u2019s guarantee can be as large as $\\bar{O(N d\\sqrt{\\tau})}$ as discussed in section 1.1. ", "page_idx": 8}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section6, we compare the performance of our BOSS algorithm with the baselines on synthetic environments. The algorithms we evaluate include: ", "page_idx": 8}, {"type": "text", "text": "\u2022 PEGE: independently solves each task using the PEGE algorithm [Rusmevichientong and Tsitsiklis, 2010]   \n\u2022 PEGE-oracle: The \u201coracle baseline\u201d that only uses PEGE on the true subspace $B$ , for all tasks   \n\u2022 SeqRepL: our implementation of [Qin et al., 2022], in which $\\hat{B}_{n}$ is estimated with SVD and the tasks for meta-exploration are chosen deterministically at round $\\begin{array}{r}{n=\\frac{i(i+1)}{2}}\\end{array}$ i(i2+1) for i = 1, 2, \u00b7 \u00b7 \u00b7 .   \n\u2022 BOSS-no-oracle: Algorithm 3 with $\\mathcal{E}^{\\varepsilon}$ set of 100,000 experts drawn uniformly at random from $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ .   \n\u2022 BOSS: Algorithm 3 with $\\mathcal{E}^{\\varepsilon}$ set as 100,000 experts drawn uniformly at random from $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , plus the ground truth expert $B$ . This algorithm is a better approximation of the original BOSS (Algorithm 3) since there exists $B_{\\varepsilon}\\in\\mathcal{E}^{\\varepsilon}$ such that $\\|(B_{\\varepsilon})_{\\perp}^{\\top}B\\|_{F}\\stackrel{\\textstyle\\cdot}{\\leq}\\varepsilon$ . ", "page_idx": 8}, {"type": "text", "text": "The setting is $(N,\\tau,d,m)=(4000,500,10,3)$ . The environment reveals a new subspace dimension at tasks 1, 2501, and 3501. In this experiment, we assume $\\boldsymbol{\\mathcal{A}}$ is a unit sphere, i.e., $M=I_{d}$ . At each task $n$ , denote by $B_{n}\\in\\mathbb{R}^{d\\times m_{n}}$ the subspace basis that the environment used to generate $\\theta_{n}$ , where $m_{n}$ is incremented when $n=1,2501,3501.\\;\\theta$ $\\theta_{n}$ is chosen in the following way: $\\theta_{n}=\\lambda_{1}B_{n}w_{n}$ for some $w_{n}\\sim\\mathrm{Unif}(\\mathbb{S}^{m_{n}-1})$ and $\\lambda_{1}\\sim\\mathrm{Unif}([0.8,1])$ is a random scaling factor to ensures Assumption 2, where $\\theta_{\\mathrm{min}}=0.8,\\theta_{\\mathrm{max}}=1$ . ", "page_idx": 9}, {"type": "text", "text": "The hyper-parameters $p,\\tau_{1},\\tau_{2}$ , and $\\alpha$ of all algorithms, where it applies, are tuned. The error bands in the figures indicate $\\pm1$ standard deviation computed over 5 independent runs. ", "page_idx": 9}, {"type": "text", "text": "Figure 3a clearly shows the linear dependency of the cumulative regret on $N$ . Observe that BOSS and its variants outperform both the independent PEGE and the SeqRepL baselines. It is also clear that the gap between BOSS-no-oracle and BOSS exists because the expert set $B^{\\varepsilon}$ used in this experiment does not cover the true $B$ , since even with $\\begin{array}{r}{\\varepsilon=\\frac{d}{\\sqrt{\\tau_{1}}}\\approx0.5}\\end{array}$ , the theoretical size of the expert set is $|{\\mathcal{E}}^{\\varepsilon}|=({\\sqrt{d m}}/\\varepsilon)^{d m}\\approx11^{30}$ in this experiment setting which is much larger than the expert set size used in BOSS-no-oracle. ", "page_idx": 9}, {"type": "text", "text": "In Figure 3b, we plot $\\|\\hat{B}_{n,\\perp}^{\\top}B_{n}\\|_{F}$ , which measures the closeness of ${\\hat{B}}_{n,\\perp}$ to $B_{n}$ . When the environment reveals a new subspace dimension at tasks 1, 2501, and 3501, all algorithms\u2019 estimation $\\hat{B}_{n}$ require updates and converge after a while. Even though BOSS-no-oracle has a worse estimation of $\\hat{B}_{n}$ compared to SeqRepL, it achieves a better regret due to having a better estimation of $\\widehat{\\theta}_{n}$ as shown in Figure 3c. ", "page_idx": 9}, {"type": "image", "img_path": "2kZMtdjzSV/tmp/2ced4f5461de6ba5362ce908da678553964cf347fef3f6bcae8dd19be7c45970.jpg", "img_caption": ["Figure 1: Comparing the cumulative regret of BOSS and other baselines. The setting is $(N,\\tau,d,m)=$ $(4000,500,10,3)$ and $\\|\\theta_{n}\\|_{2}\\in[0.8,1]\\;\\forall n\\in[N]$ chosen uniformly at random from this interval. The environment only reveals a new subspace dimension at tasks 1, 2501, and 3501, so there\u2019s no task diversity assumption. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Discussion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We study the problem of sequential representation transfer in multi-task linear bandit, where the task parameters are allowed to be chosen adversarially online. Our BOSS algorithm achieves the regret guarantee of $\\tilde{O}\\left(N m\\sqrt{\\tau}+N^{\\frac{2}{3}}\\tau^{\\frac{2}{3}}d m^{\\frac{1}{3}}+N d^{2}+\\tau m d\\right)$ without using the task diversity assumption as in previous works. ", "page_idx": 9}, {"type": "text", "text": "In this work, we present the first nontrivial result for sequential multi-task representation transfer in linear bandits without the task diversity assumption. This paper opens up many promising avenues for future work. Statistically, it would be good to design an algorithm that performs no worse than the individual single-task baseline\u2019s performance in all parameter regimes. In addition, BOSS utilizes the special structure of fixed, ellipsoid-shaped action spaces to obtain useful information for metaexploration, extending the algorithm and guarantees to general and time-varying action spaces is an important direction. Practically, it would also be nice to design parameter-free variants of BOSS that do not require knowing $m$ ahead of time. Furthermore, BOSS requires maintaining an exponentially large number of experts in $B^{\\varepsilon}$ ; in the future, we would like to develop more computationally efficient algorithms. Lastly, it would be interesting to study relaxations of Assumption 1 (all task parameters lie exactly in a $m$ -dimensional linear subspace), similar to Bilaj et al. [2024] or the changing subspace setting of Qin et al. [2022]. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. Advances in neural information processing systems, 24, 2011.   \nNaoki Abe and Philip M Long. Associative reinforcement learning using linear probabilistic concepts. In ICML, pages 3\u201311. Citeseer, 1999.   \nJavad Azizi, Thang Duong, Yasin Abbasi-Yadkori, Andr\u00e1s Gy\u00f6rgy, Claire Vernade, and Mohammad Ghavamzadeh. Non-stationary bandits and meta-learning with a small set of optimal arms. Reinforcement Learning Journal, 5:2461\u20132491, 2024.   \nMaria-Florina Balcan, Keegan Harris, Mikhail Khodak, and Zhiwei Steven Wu. Meta-learning adversarial bandits. arXiv preprint arXiv:2205.14128, 2022.   \nSteven Bilaj, Sofien Dhouib, and Setareh Maghsudi. Meta learning in bandits within shared affine subspaces, 2024.   \nLeonardo Cella, Karim Lounici, Gr\u00e9goire Pacreau, and Massimiliano Pontil. Multi-task representation learning with stochastic linear bandits. In International Conference on Artificial Intelligence and Statistics, pages 4822\u20134847. PMLR, 2023.   \nVarsha Dani, Thomas P Hayes, and Sham M Kakade. Stochastic linear optimization under bandit feedback. In COLT, volume 2, page 3, 2008.   \nMurat A Erdogdu and Mert Vural. Csc 2532 winter 2024: Statistical learning theory, lecture 5. https://erdogdu.github.io/csc2532/lectures/lecture05.pdf, 2024.   \nYoav Freund and Robert E Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1):119\u2013139, 1997.   \nJohn C Gower and Garmt B Dijksterhuis. Procrustes problems, volume 30. OUP Oxford, 2004.   \nJiachen Hu, Xiaoyu Chen, Chi Jin, Lihong Li, and Liwei Wang. Near-optimal representation learning for linear bandits and linear rl. In International Conference on Machine Learning, pages 4349\u20134358. PMLR, 2021.   \nKyoungseok Jang, Kwang-Sung Jun, Se-Young Yun, and Wanmo Kang. Improved regret bounds of bilinear bandits using action space analysis. In International Conference on Machine Learning, pages 4744\u20134754. PMLR, 2021a.   \nKyoungseok Jang, Kwang-Sung Jun, Se-Young Yun, and Wanmo Kang. Improved regret bounds of bilinear bandits using action space analysis. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 4744\u20134754. PMLR, 18\u201324 Jul 2021b. URL https://proceedings. mlr.press/v139/jang21a.html.   \nTor Lattimore and Csaba Szepesv\u00e1ri. Bandit algorithms. Cambridge University Press, 2020.   \nYuzhen Qin, Tommaso Menara, Samet Oymak, ShiNung Ching, and Fabio Pasqualetti. Non-stationary representation learning in sequential linear bandits. IEEE Open Journal of Control Systems, 1: 41\u201356, 2022.   \nPaat Rusmevichientong and John N Tsitsiklis. Linearly parameterized bandits. Mathematics of Operations Research, 35(2):395\u2013411, 2010.   \nNilesh Tripuraneni, Chi Jin, and Michael Jordan. Provable meta-learning of linear representations. In International Conference on Machine Learning, pages 10434\u201310443. PMLR, 2021.   \nTrung Vu. Matrix perturbation and davis-kahan theorem. https://trungvietvu.github.io/ notes/2020/DavisKahan, 2020.   \nJiaqi Yang, Wei Hu, Jason D Lee, and Simon Shaolei Du. Impact of representation learning in linear bandits. In International Conference on Learning Representations, 2020.   \nJiaqi Yang, Qi Lei, Jason D Lee, and Simon S Du. Nearly minimax algorithms for linear bandits with shared representation. arXiv preprint arXiv:2203.15664, 2022. ", "page_idx": 10}, {"type": "text", "text": "Meta learning bandit problems. Balcan et al. [2022] analyzed a harder problem in the Sequential setting by dealing with tasks generated by an adversary, and each task is an adversarial linear bandit problem. By using an online mirror decent base algorithm, they provided a guarantee of $\\begin{array}{r}{\\tilde{O}\\left(\\operatorname*{min}_{\\frac{1}{\\tau}\\leq\\epsilon\\leq\\frac{1}{\\sqrt{\\tau}}}N\\left(d\\hat{V}_{\\epsilon}\\sqrt{\\tau}+\\epsilon\\tau\\right)+N^{\\frac{3}{4}}\\tau^{2}d\\right)}\\end{array}$ , where $\\hat{V}_{\\epsilon}$ measures the proximity of the optimal parameters of all $N$ tasks. Balcan et al. [2022]\u2019s results also applies to the sequential meta-learning with adversarial $K$ -arms bandit, which is further investigated by Azizi et al. [2024]. Their bandit meta-learning with a small set of optimal arms setting is analogous to the sequential multi-task representation transfer in linear bandit. The task diversity assumption is equivalent to the Azizi et al. [2024]\u2019s Efficient Identification assumption; both require a gap to separate the noise from the problem\u2019s parameters. Our BOSS algorithm also has some high-level similarities with their E-BASS algorithm. ", "page_idx": 11}, {"type": "text", "text": "Bilinear bandits. The bilinear bandit problem described by Jang et al. [2021b] studies a setting where the learner has (potentially time-varying) sets of left actions and right actions available. It can take a left action $x_{L}$ and a right action $x_{R}$ and receive reward $r=x_{L}^{\\top}\\mathbf{\\bar{\\Theta}}\\mathbf{}\\cdot\\mathbf{{\\Theta}}_{P R}+\\eta$ . This reduces to our setting when the action set of the left action is the task descriptor $\\{e_{i}\\}_{i=1,\\cdots,N}$ and the task\u2019s parameters have a low-rank structure. When applying their approach to our setting, their guarantee is $\\tilde{O}\\left(N d\\sqrt{\\tau}+N^{\\frac{3}{2}}\\sqrt{d\\tau}\\right)$ , which is worse than independently using a classical algorithm, such as PEGE, for each task. This is due to the fact that Jang et al. [2021b]\u2019s solution does not exploit the low-rank and the left action structures. ", "page_idx": 11}, {"type": "text", "text": "In Table 2, we comprehensively compare the settings and assumptions of the previous works for the multi-task bandit representation transfer problem. ", "page_idx": 11}, {"type": "table", "img_path": "2kZMtdjzSV/tmp/854aa533bd939236806ae2e3b2797d0d0a2238f96d6a259f24e39f0e495d25c7.jpg", "table_caption": [], "table_footnote": ["Table 2: A comparison of the settings, assumptions, and regret guarantees our result versus previous works. "], "page_idx": 11}, {"type": "text", "text": "Algorithm 4 BOSS: Bandit Online Subspace Selection for Sequential Multitask Linear Bandits ", "page_idx": 12}, {"type": "text", "text": "1: Input: Task length $\\tau$ , number of task $N$ , task dimension $d$ , subspace dimension $m$ , learning rate   \n$\\eta$ , and exploration rate $p$ .   \n2: Initialize: An uniform distribution $D_{1}$ over the set of experts $\\mathcal{E}^{\\varepsilon}$ in Definition 5   \n3: for $n\\in[N]$ : do   \n4: Randomly draw $\\hat{B}_{n}$ from $D_{n}$   \n5: With probability $p$ : $Z_{n}=1$ , otherwise $Z_{n}=0$   \n6: if $Z_{n}=1$ then   \n7: Exploration procedure in Algorithm 1   \n8: Update the distribution $D_{n+1}$ with the EWA algorithm   \n9: For all $B\\,\\in\\,\\mathcal{E}^{\\varepsilon}$ , observe the cost $\\tilde{C}_{n}(B)\\,=\\,\\bar{\\mathbb{I}}(\\|B_{\\perp}^{\\top}\\hat{\\theta}_{n}\\|_{2}\\,\\le\\,\\alpha){\\bf C}_{\\mathrm{hit}}+\\mathbb{I}(\\|B_{\\perp}^{\\top}\\hat{\\theta}_{n}\\|_{2}\\,>$   \n$\\alpha)\\mathbf{C}_{\\tt m i s s}$   \n10: The shifted and scaled loss:   \n$\\ell_{n}(B)=\\frac{p}{\\mathbf{C}_{\\mathrm{miss}}}\\left[\\Tilde{C}_{n}(B)\\frac{Z_{n}}{p}-\\mathbf{C}_{\\mathrm{hit}}\\frac{Z_{n}}{p}\\right]=\\frac{1}{\\mathbf{C}_{\\mathrm{miss}}}\\left[\\Tilde{C}_{n}(B)-\\mathbf{C}_{\\mathrm{hit}}\\right]$   \n11: Update: Dn+1(B) = B\u2032\u2208En\u03b5 Dn(B\u2032) exp(n\u2212\u03b7\u2113n(B\u2032))   \n12: else   \n13: Exploitation procedure in Algorithm 2 with $\\hat{B}_{n}$   \n14: Update: $D_{n+1}=D_{n}$   \n15: end if   \n16: end for ", "page_idx": 12}, {"type": "text", "text": "C Additional details about Section 3 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In this section, we provide more details about the construction of the expert set used in Section 3. ", "page_idx": 12}, {"type": "text", "text": "Since it is difficult to directly construct $\\mathcal{E}^{\\varepsilon}$ , an $\\varepsilon$ -cover in the principal angle sense (Definition 5) , we define the surrogate set $\\mathcal{E}_{F}^{\\varepsilon}$ : an $\\varepsilon$ -cover in the Frobenius norm sense over the set $B_{S}\\supseteq B$ in Definition 8. We will then show that $\\mathcal{E}_{F}^{\\varepsilon}$ is also an $\\varepsilon$ -cover of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ in the principal angle sense. Specifically, Lemma 13 shows that for any $B\\in B$ , there exists $A\\in\\mathcal{E}_{F}^{\\varepsilon}$ such that $\\|A_{\\bot}^{\\top}B\\|_{F}\\leq\\varepsilon$ . ", "page_idx": 12}, {"type": "text", "text": "Definition 8. $\\mathcal{E}_{F}^{\\varepsilon}$ is said to be an $\\varepsilon$ -cover over the set of $\\beta_{S}=\\{B:\\|B\\|_{F}={\\sqrt{m}}\\}$ in the Frobenius norm sense, $i f$ : ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\forall\\;B\\in\\mathcal{B}_{S},\\;\\exists A\\in\\mathcal{E}_{F}^{\\varepsilon}\\;s u c h\\;t h a t\\;\\|v e c(A)-v e c(B)\\|_{2}\\leq\\varepsilon\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "After defining the expert set, to use the EWA algorithm, we need to use a surrogate expert\u2019s cost ${\\tilde{C}}_{n}$ defined in Equation (3), which is a high probability upper-bound of the true cost $C_{n}(B)$ following Lemma 11. To construct ${\\tilde{C}}_{n}$ , we need to introduce the definition of $\\alpha$ -covering in Definition 9. ", "page_idx": 12}, {"type": "text", "text": "Definition 9. $A$ subspace (represented by its orthonormal basis) $\\textit{B}\\in\\ \\mathbb{R}^{d\\times m}$ is said to $\\alpha$ - approximately cover vector $\\phi\\in\\mathbb{R}^{d}$ , $i f\\|B_{\\perp}^{\\top}\\dot{\\phi}\\|_{2}\\leq\\alpha$ . ", "page_idx": 12}, {"type": "text", "text": "Note: the specific choice of $B_{\\bot}$ does not affect the validity of this definition \u2013 e.g., $\\|B_{\\perp}\\phi\\|_{2}$ are always the same regardless of the specific choice of $B_{\\bot}$ , as long as its columns form a orthonormal basis of span $(B_{\\bot})$ : for any two choices of $B_{\\bot}$ (denoted by $B_{\\perp,1},B_{\\perp,2}$ , respectively) there exists orthonormal $V\\in\\mathbb{R}^{(d-m)\\times(d-m)}$ such that $B_{\\perp,1}=B_{\\perp,2}V$ . Therefore, ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\|B_{\\bot,1}^{\\top}\\theta_{n}\\|_{2}=\\|V^{\\top}B_{\\bot,2}^{\\top}\\theta_{n}\\|_{2}=\\|B_{\\bot,2}^{\\top}\\theta_{n}\\|_{2}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "The following lemma justifies that all valid choices of $B_{\\bot}$ are equivalent up to a $(d-m)\\times(d-m)$ orthogonal transformation: ", "page_idx": 12}, {"type": "text", "text": "Lemma 10. Let $W$ be a $k$ -dimensional subspace of $\\mathbb{R}^{d}$ . Let $\\boldsymbol{B},\\hat{\\boldsymbol{B}}\\,\\in\\,\\mathbb{R}^{d\\times k}$ be matrices whose columns form an orthonormal basis of $W$ . Then, there exists an orthogonal matrix $V\\in\\mathbb{R}^{k\\times k}$ such that ${\\hat{B}}=B V$ . ", "page_idx": 12}, {"type": "text", "text": "Proof. Since $B$ is a basis of $W$ , there exists some $V$ such that ${\\hat{B}}\\ =\\ B V$ . Since $V^{\\top}V\\;=$ $V^{\\top}(B^{\\top}B)V=(B V)^{\\top}(B V)=\\hat{B}^{\\top}\\hat{B}=I,V$ is an orthogonal matrix. \u53e3 ", "page_idx": 13}, {"type": "text", "text": "Next, we justify the use of ${\\tilde{C}}_{n}$ as a surrogate cost for the true cost $C_{n}$ in Lemma 11, which requires Remark 2. ", "page_idx": 13}, {"type": "text", "text": "Remark 2. By the observation that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\|B_{\\bot}^{\\top}\\phi\\|_{2}=\\|B_{\\bot}B_{\\bot}^{\\top}\\phi\\|_{2}=\\|\\phi-B B^{\\top}\\phi\\|_{2}=\\operatorname*{min}_{\\theta\\in\\mathrm{span}(B)}\\|\\phi-\\theta\\|,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "$B\\;\\alpha\\cdot$ -approximately cover $\\phi$ if and only if there exists some $\\theta$ in span $(B)$ that is $\\alpha$ -close to $\\phi$ . As a result: ", "page_idx": 13}, {"type": "text", "text": "\u2022 If $\\theta_{n}\\in\\operatorname{span}(B)$ and $\\|{\\boldsymbol{\\theta}}_{n}-{\\hat{\\boldsymbol{\\theta}}}_{n}\\|\\leq\\alpha$ , $B$ also $\\alpha$ -covers $\\widehat{\\theta}_{n}$ ;   \n\u2022 If $B\\ \\alpha$ -covers $\\hat{\\theta}_{n}$ and $\\lVert{\\boldsymbol{\\theta}}_{n}-{\\hat{\\boldsymbol{\\theta}}}_{n}\\rVert\\leq\\alpha$ , $B$ also $2\\alpha$ -covers $\\theta_{n}$ . ", "page_idx": 13}, {"type": "text", "text": "Lemma 11. With high probability, ${\\tilde{C}}_{n}$ is an upper bound of $C_{n}$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. We have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{C_{n}(B)=\\mathbb{I}(\\|B_{\\bot}^{\\top}\\theta_{n}\\|_{2}\\le2\\alpha)\\mathbf{C}_{\\mathrm{hit}}+\\mathbb{I}(\\|B_{\\bot}^{\\top}\\theta_{n}\\|_{2}>2\\alpha)\\mathbf{C}_{\\mathrm{niss}}}\\\\ &{\\qquad\\quad\\lesssim\\mathbb{I}(\\|B_{\\bot}^{\\top}\\hat{\\theta}_{n}\\|_{2}\\le\\alpha)\\mathbf{C}_{\\mathrm{hit}}+\\mathbb{I}(\\|B_{\\bot}^{\\top}\\hat{\\theta}_{n}\\|_{2}>\\alpha)\\mathbf{C}_{\\mathrm{niss}}}&&{\\quad{\\mathrm{(With~high~probability)}}}\\\\ &{\\qquad=\\tilde{C}_{n}(B).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Here, the first equality comes from Equation (2). Since, for all meta-exploration rounds $n$ (where $Z_{n}=1)$ ), $\\lVert{\\widehat{\\theta}}_{n}-\\theta_{n}\\rVert\\leq\\alpha$ with high probability, the inequality is true following Remark 2 ", "page_idx": 13}, {"type": "text", "text": "To ensure that there exists some $B\\in\\mathcal{E}^{\\varepsilon}$ that can $\\alpha$ -cover all $\\widehat{\\theta}_{n}$ , we need to choose $\\varepsilon$ by following Lemma 12. ", "page_idx": 13}, {"type": "text", "text": "Lemma 12. By choosing $\\varepsilon\\leq\\alpha,$ , there exists some $B_{\\varepsilon}\\in\\mathcal{E}^{\\varepsilon}$ such that, for all $n$ , $B_{\\varepsilon}$ $\\alpha$ -approximately covers $\\theta_{n}$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. For any $n\\in[N]$ , $\\theta_{n}\\in\\operatorname{span}(B)$ . Hence, $\\theta_{n}=P_{B}\\theta_{n}$ . ", "page_idx": 13}, {"type": "text", "text": "Thus: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{U\\in\\mathcal{E}^{\\varepsilon}}{\\operatorname*{min}}\\,\\|\\theta_{n}-U U^{\\top}\\theta_{n}\\|_{2}=\\underset{U\\in\\mathcal{E}^{\\varepsilon}}{\\operatorname*{min}}\\,\\|U_{\\bot}U_{\\bot}^{\\top}\\theta_{n}\\|_{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=\\underset{U\\in\\mathcal{E}^{\\varepsilon}}{\\operatorname*{min}}\\,\\|U_{\\bot}U_{\\bot}^{\\top}B B^{\\top}\\theta_{n}\\|_{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\leq\\underset{U\\in\\mathcal{E}^{\\varepsilon}}{\\operatorname*{min}}\\,\\|U_{\\bot}\\|_{o p}\\|U_{\\bot}^{\\top}B\\|_{F}\\|B^{\\top}\\|_{o p}^{2}\\|\\theta_{n}\\|_{2}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\leq\\underset{U\\in\\mathcal{E}^{\\varepsilon}}{\\operatorname*{min}}\\,\\|U_{\\bot}^{\\top}B\\|_{F}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\leq\\varepsilon}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Hence, by setting $\\varepsilon\\leq\\alpha$ , we ensure that $\\begin{array}{r}{\\operatorname*{min}_{U\\in{\\mathcal{E}}^{\\varepsilon}}\\|\\phi-U U^{\\top}\\phi\\|_{2}\\leq\\alpha}\\end{array}$ . ", "page_idx": 13}, {"type": "text", "text": "D The expert set size $|\\mathcal{E}^{\\varepsilon}|$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Lemma 13. ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "\u2022 For any $B\\in\\mathcal{B}$ , there exists $A\\in\\mathcal{E}_{F}^{\\varepsilon}$ such that $\\|A_{\\bot}^{\\top}B\\|_{F}\\leq\\varepsilon$ ", "page_idx": 13}, {"type": "text", "text": "\u2022 The size of the set $\\mathcal{E}^{\\varepsilon}$ defined in Definition $^{5}$ is $|{\\mathcal{E}}^{\\varepsilon}|\\leq|{\\mathcal{E}}_{F}^{\\varepsilon}|\\leq c\\cdot\\left(\\left({\\frac{d m}{\\varepsilon}}\\right)^{d m}\\right)$ ", "page_idx": 13}, {"type": "text", "text": "Following Vu [2020] , we relate $\\|A_{\\perp}^{\\top}B\\|_{F}$ to the Orthogonal Procrustes problem in Gower and Dijksterhuis [2004]: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{R\\in\\mathbb{R}^{m\\times m}:R^{\\top}R=I_{m}}\\|A R-B\\|_{F}^{2}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "With the solution $R^{*}=A^{\\top}B\\left(B^{\\top}A A^{\\top}B\\right)^{-{\\frac{1}{2}}}$ , at the optimum: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\|A_{\\cdot}^{\\top}B\\|_{F}^{2}=\\displaystyle\\sum_{i=1}^{m}\\sin^{2}(\\theta_{i})}\\\\ {\\displaystyle=m-\\displaystyle\\sum_{i=1}^{m}\\cos^{2}(\\theta_{i})}\\\\ {\\displaystyle\\le m-\\displaystyle\\sum_{i=1}^{m}(2\\cos(\\theta_{i})-1)}\\\\ {\\displaystyle=2m-2\\displaystyle\\sum_{i=1}^{m}\\cos(\\theta_{i})}\\\\ {\\displaystyle=\\|A^{\\top}-B\\|_{F}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "equation", "text": "$$\n(\\cos(\\theta_{i})^{2}\\geq2\\cos(\\theta_{i})-1)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We have $\\|A_{\\bot}^{\\top}B\\|_{F}^{2}\\leq\\|A R^{*}-B\\|_{F}^{2}\\leq\\|A-B\\|_{F}^{2}$ . Thus, $\\forall A,B\\in[-1,1]^{d\\times m}$ , if $\\|A-B\\|_{F}\\leq\\varepsilon$ , then $\\|A_{\\bot}^{\\top}B\\|_{F}\\leq\\varepsilon$ . ", "page_idx": 14}, {"type": "text", "text": "Since $\\|B\\|_{F}=\\|v e c(B)\\|_{2}=\\sqrt{m}$ , by vectorizing $B$ , we can further describe $B\\subset B_{S}$ as the surface of the sphere in $\\mathbb{R}^{d m}$ with radius $\\sqrt{m}$ . ", "page_idx": 14}, {"type": "text", "text": "Since $B\\subset B_{S}$ and the inequality above, by Definition 8: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\forall\\;B\\in\\mathcal{B},\\;\\exists A\\in\\mathcal{E}_{F}^{\\varepsilon}\\mathrm{~such~that~}\\|A_{\\bot}^{\\top}B\\|_{F}\\leq\\|v e c(A)-v e c(B)\\|_{2}\\leq\\varepsilon\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since this is the same as the Definition 5, we can conclude that $\\mathcal{E}_{F}^{\\varepsilon}$ is a \"denser\" net than $\\mathcal{E}^{\\varepsilon}$ over $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ . In other word, since $\\mathcal{E}_{F}^{\\varepsilon}$ $\\varepsilon$ -cover $B_{S}$ , then it also $\\varepsilon$ -cover $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ ", "page_idx": 14}, {"type": "text", "text": "Then, following Erdogdu and Vural [2024], if we discretize the hyper-cube that contains this sphere (not just the surface), then $\\begin{array}{r}{|\\mathcal{E}^{\\varepsilon}|\\leq|\\mathcal{E}_{F}^{\\varepsilon}|\\leq\\Big(\\frac{2m\\sqrt{d}}{\\varepsilon}\\Big)^{d m}=c\\cdot\\Big(\\big(\\frac{d m}{\\varepsilon}\\big)^{d m}\\Big).}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "E Proof of Lemma 3: Regret of the Exploration task ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We first restate Lemma 3. ", "page_idx": 14}, {"type": "text", "text": "Lemma 3. Fix $\\tau_{1}$ to be a multiple of $d$ . Suppose Algorithm $^{\\,l}$ is run on task $n$ with the exploration length $\\tau_{1}$ . Then, there exists some constant $c_{1},c_{2}>0$ (that depends on $\\lambda_{0},\\theta_{\\mathrm{max}},\\theta_{\\mathrm{min}}$ , and $M$ ) such that: ", "page_idx": 14}, {"type": "text", "text": "1. The regret on task n is bounded as $\\begin{array}{r}{R_{\\tau}^{n}\\le c_{1}\\cdot\\left(\\tau_{1}+\\tau\\cdot\\frac{d^{2}}{\\tau_{1}}\\right)=:C_{i n f o};}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "2. With probability $1-\\delta$ , it returns $\\widehat{\\theta}_{n}$ such that $\\begin{array}{r}{\\|\\widehat{\\theta}_{n}-\\theta_{n}\\|\\leq c_{2}\\cdot\\left(d\\sqrt{\\frac{\\ln\\frac{d}{\\delta}}{\\tau_{1}}}\\right)=:\\alpha.}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "Proof. For the first item, following Rusmevichientong and Tsitsiklis [2010]\u2019s Lemma 3.4, we have: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\Vert\\hat{\\theta}-\\theta\\Vert^{2}\\right]\\leq c_{0}\\frac{d^{2}}{\\tau_{1}},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $c_{0}$ is a constant that depends on $\\lambda_{0}$ and $M$ . From Yang et al. [2020]\u2019s Lemma 17, we have: $\\begin{array}{r}{\\operatorname*{max}_{a\\in\\mathcal{A}}\\left\\langle a-A_{n,t},\\theta_{n}\\right\\rangle\\leq J\\|\\theta_{n}-\\hat{\\theta}_{n}\\|^{2}/\\|\\theta_{n}\\|}\\end{array}$ , where $A_{n,t}\\;=\\;\\mathrm{argmax}_{a\\in\\mathcal{A}}\\left\\langle a,\\hat{\\theta}_{n}\\right\\rangle$ , $J\\,=$ \u221a\u03bbmax(M) = \u03bbmax(M). Thus: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[R_{\\tau}^{n}\\right]=\\mathbb{E}\\left[\\tau\\operatorname*{max}_{a\\in\\mathcal{A}}\\left\\langle\\theta_{n},a\\right\\rangle-\\sum_{t=1}^{\\tau}\\left\\langle\\theta_{n},A_{n,t}\\right\\rangle\\right]}\\\\ &{\\quad\\quad=\\mathbb{E}\\left[\\tau_{1}\\operatorname*{max}_{a\\in\\mathcal{A}}\\left\\langle\\theta_{n},a\\right\\rangle-\\sum_{t=1}^{\\tau_{1}}\\left\\langle\\theta_{n},A_{n,t}\\right\\rangle+\\left(\\tau-\\tau_{1}\\right)\\operatorname*{max}_{a\\in\\mathcal{A}}\\left\\langle\\theta_{n},a\\right\\rangle-\\sum_{t=\\tau_{1}+1}^{\\tau}\\left\\langle\\theta_{n},A_{n,t}\\right\\rangle\\right]}\\\\ &{\\quad\\quad\\leq\\lambda_{0}\\theta_{\\operatorname*{max}}\\tau_{1}+(\\tau-\\tau_{1})J\\frac{\\mathbb{E}\\left\\lVert\\hat{\\theta}_{n}-\\theta_{n}\\right\\rVert^{2}}{\\theta_{\\operatorname*{min}}}}\\\\ &{\\quad\\quad\\leq\\lambda_{0}\\theta_{\\operatorname*{max}}\\tau_{1}+\\frac{J}{\\theta_{m i n}}\\cdot\\tau c_{0}\\frac{d^{2}}{\\tau_{1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The proof of the first item is concluded by taking c1 = max(\u03bb0\u03b8max, \u03b8Jmci0n ) ", "page_idx": 15}, {"type": "text", "text": "For the second item, recall that $\\begin{array}{r}{u=\\frac{\\tau_{1}}{d}}\\end{array}$ , and $A_{n,1},\\dotsc,A_{n,\\tau_{1}}$ are constructed as follows: for each $i\\in[d]$ and $t\\in\\{u(i-1)+1,\\cdots\\,,u i\\}^{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!$ , $A_{n,t}=\\lambda_{0}e_{i}$ . ", "page_idx": 15}, {"type": "text", "text": "Since $\\begin{array}{r}{\\widehat{\\theta}_{n}\\,:=\\,\\operatorname*{argmin}_{\\theta}\\frac{1}{\\tau_{1}}\\sum_{t=1}^{\\tau_{1}}\\big(\\langle A_{n,t},\\theta\\rangle-r_{n,t}\\big)^{2},}\\end{array}$ , by the closed-form solution of ordinary least squares, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\theta}_{n}=(A_{n}^{\\top}A_{n})^{-1}A_{n}^{\\top}r_{n},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where ", "page_idx": 15}, {"type": "equation", "text": "$$\nA_{n}:={\\binom{A_{n,1}^{\\top}}{\\cdots\\cdot\\cdot}}\\in\\mathbb{R}^{\\tau_{1}\\times d},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and $r_{n}:=(r_{n,1},\\cdot\\cdot\\cdot\\,,r_{n,\\tau_{1}})$ . Observe that ", "page_idx": 15}, {"type": "equation", "text": "$$\nA_{n}^{\\top}A_{n}=u\\lambda_{0}^{2}\\sum_{i=1}^{d}e_{i}e_{i}^{\\top}=u\\lambda_{0}^{2}I_{d}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let $\\eta_{n}:=(\\eta_{n,1},\\dotsc,\\eta_{n,\\tau_{1}})$ . We have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\theta}_{n}=(A_{n}^{\\top}A_{n})^{-1}A_{n}^{\\top}r_{n}}\\\\ &{\\quad\\stackrel{\\mathrm{(a)}}{=}\\frac{1}{u\\lambda_{0}^{2}}A_{n}^{\\top}r_{n}}\\\\ &{\\quad=\\frac{1}{u\\lambda_{0}^{2}}A_{n}^{\\top}(A_{n}\\theta_{n}+\\eta_{n})}\\\\ &{\\stackrel{\\mathrm{(b)}}{=}\\theta_{n}+\\frac{1}{u\\lambda_{0}^{2}}A_{n}^{\\top}\\eta_{n},}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where both (a) and (b) follow from Eq. (6). ", "page_idx": 15}, {"type": "text", "text": "It now suffices to show that $\\begin{array}{r}{\\left\\|\\hat{\\theta}_{n}-\\theta_{n}\\right\\|_{2}=\\left\\|\\frac{1}{u\\lambda_{0}^{2}}A_{n}^{\\top}\\eta_{n}\\right\\|_{2}\\leq O\\left(d\\sqrt{\\frac{\\log\\left(d/\\delta\\right)}{\\tau_{1}}}\\right)}\\end{array}$ with probability at least $1-\\delta$ . To this end, observe that by the construction of $A_{n}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\nA_{n}^{\\top}\\eta_{n}=\\left(\\begin{array}{c}{{\\lambda_{0}\\sum_{t=1}^{u}\\eta_{n,t}}}\\\\ {{\\dots\\cdot\\cdot}}\\\\ {{\\lambda_{0}\\sum_{t=\\tau_{1}-u+1}^{\\tau_{1}}\\eta_{n,t}}}\\end{array}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since for each $n$ and $t,\\eta_{n,t}$ is zero-mean and 1-sub-Gaussian, by [Lattimore and Szepesv\u00e1ri, 2020, Corollary 5.5], for any $i\\in[d]$ , we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left(\\left|\\sum_{t=u(i-1)+1}^{u i}\\eta_{n,t}\\right|\\geq\\sqrt{2u\\log(2/\\delta^{\\prime})}\\right)\\leq\\delta^{\\prime}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let $\\delta=d\\delta^{\\prime}$ and ", "page_idx": 15}, {"type": "equation", "text": "$$\nG:=\\left\\{\\forall i\\in[d],\\quad\\left|(A_{n}^{\\top}\\eta_{n})_{i}\\right|\\leq\\lambda_{0}\\sqrt{2u\\log(2d/\\delta)}\\right\\}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then, by the union bound, $G$ happens with probability at least $1-\\delta$ . Since under the event $G$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\|\\hat{\\theta}_{n}-\\theta_{n}\\|_{2}=\\bigg\\|\\frac{1}{u\\lambda_{0}^{2}}A_{n}^{\\top}\\eta_{n}\\bigg\\|_{2}}}\\\\ &{}&{=\\frac{1}{u\\lambda_{0}^{2}}\\sqrt{\\displaystyle\\sum_{i=1}^{d}(A_{n}^{\\top}\\eta_{n})_{i}^{2}}}\\\\ &{}&{\\le\\frac{1}{u\\lambda_{0}}\\sqrt{d\\cdot2u\\log(2d/\\delta)}}\\\\ &{}&{\\le O\\left(d\\sqrt{\\frac{\\log(d/\\delta)}{\\tau_{1}}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "the proof of the second item is complete. ", "page_idx": 16}, {"type": "text", "text": "F Proof of Lemma 4: Regret of the Exploitation task ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We first restate Lemma 4. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Lemma 4. Fixed $\\tau_{2}$ to be a multiple of $m$ . Suppose Algorithm 2 is run on task n with input subspace $\\hat{B}_{n}$ and the exploration length $\\tau_{2}$ . Then, there exists some constant $c>0$ (that depends on $\\lambda_{0},\\theta_{\\mathrm{max}},\\theta_{\\mathrm{min}}$ , and $M$ ), such that the regret on task $n$ is bounded as: ", "page_idx": 16}, {"type": "equation", "text": "$$\nR_{\\tau}^{n}\\leq c\\cdot\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|_{2}^{2}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Specifically, $i f\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|_{2}\\leq2\\alpha_{1}$ , then $\\begin{array}{r}{R_{\\tau}^{n}\\leq c\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\alpha^{2}\\right)\\right)}\\end{array}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. Similar to Rusmevichientong and Tsitsiklis [2010], define $\\begin{array}{r}{J=\\frac{\\lambda_{m a x}(M)}{\\sqrt{\\lambda_{m i n}(M)}}=\\frac{\\lambda_{m a x}(M)}{\\lambda_{0}}}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "From Yang et al. [2020]\u2019s Lemma 17, we have: $\\begin{array}{r}{\\operatorname*{max}_{a\\in\\mathcal{A}}\\left\\langle a-A_{n,t},\\theta_{n}\\right\\rangle\\,\\le\\,J\\|\\theta_{n}-\\hat{\\theta}_{n}\\|^{2}/\\|\\theta_{n}\\|}\\end{array}$ , where $A_{n,t}=\\operatorname{argmax}_{a\\in A}\\left\\langle a,{\\hat{\\theta}}_{n}\\right\\rangle$ . ", "page_idx": 16}, {"type": "text", "text": "Thus: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[R_{\\tau}^{n}\\right]=\\mathbb{E}\\left[\\tau\\operatorname*{max}_{a\\in\\mathcal{A}}\\big\\langle\\theta_{n},a\\big\\rangle-\\displaystyle\\sum_{t=1}^{\\tau}\\langle\\theta_{n},A_{n,t}\\rangle\\right]}\\\\ &{\\quad\\quad=\\mathbb{E}\\left[\\tau_{2\\operatorname*{max}}\\langle\\theta_{n},a\\rangle-\\displaystyle\\sum_{t=1}^{\\tau_{2}}\\langle\\theta_{n},A_{n,t}\\rangle+\\big(\\tau-\\tau_{2}\\big)\\operatorname*{max}_{a\\in\\mathcal{A}}\\big\\langle\\theta_{n},a\\big\\rangle-\\displaystyle\\sum_{t=\\tau_{2}+1}^{\\tau}\\langle\\theta_{n},A_{n,t}\\rangle\\right]}\\\\ &{\\quad\\quad\\leq\\lambda_{0}\\theta_{\\operatorname*{max}}\\tau_{2}+(\\tau-\\tau_{2})J\\frac{\\mathbb{E}\\|\\theta_{n}-\\hat{B}_{n}\\hat{w}_{n}\\|^{2}}{\\theta_{m i n}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "For the second term, by the Subspace informed estimation Theorem 14, we have: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left\\|\\hat{B}_{n}\\hat{w}_{n}-\\theta_{n}\\right\\|^{2}\\leq\\frac{m^{2}}{\\lambda_{0}^{2}\\tau_{2}}+\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|^{2}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Thus: ", "page_idx": 16}, {"type": "equation", "text": "$$\nR_{\\tau}^{n}\\leq c\\cdot\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|_{2}^{2}\\right)\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "When $\\lVert\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\rVert_{2}\\leq2\\alpha$ , then: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[R_{\\tau}^{n}\\right]\\leq\\lambda_{0}\\theta_{\\operatorname*{max}}\\tau_{2}+(\\tau-\\tau_{2})\\frac{J}{\\theta_{m i n}}\\left(\\frac{m^{2}}{\\lambda_{0}^{2}\\tau_{2}}+4\\alpha^{2}\\right)\\leq c\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\alpha^{2}\\right)\\right),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\begin{array}{r}{c=\\operatorname*{max}\\left\\{\\lambda_{0}\\theta_{\\mathrm{max}},\\frac{J}{\\lambda_{0}^{2}\\theta_{\\mathrm{min}}},\\frac{4J}{\\theta_{\\mathrm{min}}}\\right\\}}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "In the proof above, we use the Subspace informed estimation theorem. Similar to Qin et al. [2022]\u2019s lemma 2 and Yang et al. [2020]\u2019s lemma 18, we have: ", "page_idx": 17}, {"type": "text", "text": "Theorem 14 (Subspace informed estimation). Suppose Algorithm 2 is run on task n with the exploration length $\\tau_{2}$ , then: $\\begin{array}{r}{\\mathbb{E}\\|\\hat{\\theta}_{n}-\\theta_{n}\\|^{2}\\leq\\frac{m^{2}}{\\lambda_{0}^{2}\\tau_{2}}+\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|^{2}}\\end{array}$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. Since $A_{n,t}~=~\\lambda_{0}\\hat{B}_{n}(i)$ , $i\\ \\in\\ [m]$ , and each action repeats $\\lfloor\\tau_{2}/m\\rfloor$ times, we have $\\begin{array}{r}{\\sum_{t=1}^{\\tau_{2}}A_{n,t}A_{n,t}^{\\top}=\\frac{\\tau_{2}\\lambda_{0}^{2}}{m}\\hat{B}_{n}\\hat{B}_{n}^{\\top}}\\end{array}$ . Thus: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t=1}^{\\tau_{2}}\\hat{B}_{n}^{\\top}A_{n,t}A_{n,t}^{\\top}\\hat{B}_{n}=\\frac{\\tau_{2}\\lambda_{0}^{2}}{m}\\hat{B}_{n}^{\\top}\\hat{B}_{n}\\hat{B}_{n}^{\\top}\\hat{B}_{n}}}\\\\ &{}\\\\ &{=\\frac{\\tau_{2}\\lambda_{0}^{2}}{m}I_{m}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, the OLS estimator is given by: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\hat{w}_{n}=\\left(\\sum_{i=1}^{n_{E}}\\hat{B}_{n}^{\\top}A_{n,i}A_{n,i}^{\\top}\\hat{B}_{n}\\right)^{-1}\\sum_{t=1}^{D}\\hat{B}_{n}^{\\top}A_{n,t}r_{n,t}}\\\\ {\\displaystyle}\\\\ {\\displaystyle}&{\\phantom{\\frac{1}{\\sum_{t=1}^{D}}}\\left(\\sum_{i=1}^{n_{E}}\\hat{B}_{n}^{\\top}A_{n,i}A_{n,t}^{\\top}\\hat{B}_{n}\\right)^{-1}\\sum_{t=1}^{D}\\hat{B}_{n}^{\\top}A_{n,t}\\left(A_{n,t}^{\\top}B(w_{n}+\\eta_{n,t})\\right.}\\\\ {\\displaystyle}\\\\ &{\\left.\\phantom{\\frac{1}{\\sum_{t=1}^{D}}}=\\frac{m}{\\eta_{2}\\hat{X}_{n}^{\\top}}\\sum_{i=1}^{D}\\hat{B}_{n}^{\\top}A_{n,t}\\left(A_{n,t}^{\\top}B(w_{n}+\\eta_{n,t})\\right.\\right.}\\\\ {\\displaystyle}&{\\left.\\left.-\\frac{m}{\\eta_{2}\\hat{X}_{n}^{\\top}}\\sum_{i=1}^{D}\\hat{B}_{n}^{\\top}A_{n,i}A_{n,t}^{\\top}\\left(\\hat{B}_{n,i}\\hat{B}_{n}^{\\top}+\\hat{B}_{n,i}\\hat{B}_{n,i}^{\\top}\\right)B(w_{n}+\\frac{m}{\\eta_{2}\\hat{X}_{n}^{\\top}}\\sum_{i=1}^{D}\\hat{B}_{n}^{\\top}A_{n,i}\\eta_{n,t}}\\\\ {\\displaystyle}&{\\left.\\phantom{\\frac{1}{\\sum_{t=1}^{D}}}\\left(\\hat{B}_{n}^{\\top}A_{n,t}+\\frac{m}{\\eta_{2}\\hat{X}_{n}^{\\top}}\\sum_{i=1}^{D}\\hat{B}_{n}^{\\top}A_{n,i}A_{n,t}^{\\top}\\hat{B}_{n,i}\\hat{B}_{n,i}^{\\top}\\right.\\right.+\\displaystyle\\left.\\left.\\frac{m}{\\eta_{2}\\hat{X}_{n}^{\\top}}\\sum_{i=1}^{D}\\hat{B}_{n}^{\\top}A_{n,i}B_{n,t}^{\\top}\\right.\\right.}\\\\\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first equality is the closed-form solution of OLS; the second equality is by the definition of ${\\boldsymbol{r}}_{n,t}$ . The other equalities are algebraic manipulations. ", "page_idx": 17}, {"type": "text", "text": "Now, we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\theta}_{n}-\\theta_{n}=\\hat{B}_{n}\\hat{w}_{n}-B w_{n}}\\\\ &{\\qquad\\quad=\\hat{B}_{n}\\left(\\hat{B}_{n}^{\\top}B w_{n}+\\frac{m}{\\tau_{2}\\lambda_{0}^{2}}\\displaystyle\\sum_{t=1}^{\\tau_{2}}\\hat{B}_{n}^{\\top}A_{n,t}\\eta_{n,t}\\right)-B w_{n}}\\\\ &{\\qquad\\quad=\\underbrace{\\left(\\hat{B}\\hat{B}_{n}^{\\top}B w_{n}-B w\\right)}_{=:s_{1}}+\\underbrace{\\frac{m}{\\tau_{2}\\lambda_{0}^{2}}\\displaystyle\\sum_{t=1}^{\\tau_{2}}\\hat{B}_{n}\\hat{B}_{n}^{\\top}A_{n,t}\\eta_{n,t}}_{=:s_{2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "For $s_{1}$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|s_{1}\\|^{2}=\\|\\hat{B}_{n}\\hat{B}_{n}^{\\top}B w_{n}-B w_{n}\\|^{2}}\\\\ &{\\qquad=\\|(I-\\hat{B}_{n,\\perp}\\hat{B}_{n,\\perp}^{\\top})B w_{n}-B w_{n}\\|^{2}}\\\\ &{\\qquad=\\|\\hat{B}_{n,\\perp}\\hat{B}_{n,\\perp}^{\\top}B w_{n}\\|^{2}}\\\\ &{\\qquad\\leq\\|\\hat{B}_{n,\\perp}\\|_{o p}^{2}\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|^{2}}\\\\ &{\\qquad\\leq\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For s2: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{E}\\|x_{j}\\|^{2}=\\mathbb{E}\\bigg\\|\\frac{m^{2}}{\\gamma\\lambda_{j}\\zeta_{j}}\\frac{\\hat{\\mathcal{E}}_{\\lambda}}{\\hat{\\mathcal{E}}_{\\lambda}}\\hat{d}_{x}\\hat{d}_{x,\\mu_{1}}\\bigg\\|^{2}}&{}&\\\\ &{\\quad=\\frac{m^{2}}{\\gamma^{2}\\lambda_{j}^{2}}\\mathbb{E}\\bigg[\\frac{\\hat{\\mathcal{E}}_{\\lambda}}{\\hat{w}_{1}}\\Big(\\hat{h}_{x}\\hat{\\mathcal{E}}_{\\lambda}(A_{x},\\eta_{x_{1}})\\Big)^{\\top}\\bar{\\mathcal{E}}_{\\bar{\\mathcal{N}}}\\bar{\\hat{N}}_{x}^{\\top}\\bar{A}_{x,\\eta_{1}}\\eta_{x_{2}}\\bigg]}&\\\\ &{\\quad=\\frac{m^{2}}{\\gamma\\lambda_{j}^{2}}\\mathbb{E}\\|h_{x,\\eta}\\|^{2}\\sum_{k=1}^{\\bar{\\lambda}}\\hat{L}_{\\mathcal{N}}\\hat{d}_{x,\\mu}\\hat{N}_{x}^{\\top}\\bar{A}_{x,\\mu}}&\\\\ &{\\quad=\\frac{m^{2}}{\\gamma\\lambda_{j}^{2}}\\mathbb{E}\\|h_{x,\\eta}\\|_{\\mathcal{E}_{\\lambda}^{2}}^{2}\\lambda_{j}^{2},\\quad\\quad}&\\\\ &{\\quad=\\frac{m^{2}}{\\gamma^{2}\\lambda_{j}^{2}}\\mathbb{E}\\|h_{x,\\eta}\\|_{\\mathcal{E}_{\\lambda}^{2}}^{2}\\lambda_{i}^{-1},\\quad\\hat{L}_{\\mathcal{N}}\\big(\\bar{L}_{\\lambda}-\\bar{B}_{x,\\eta_{1}}\\hat{B}_{x,\\epsilon}^{\\top}\\big)\\,\\mathcal{A}_{u,\\mu}}&{\\quad\\hat{(d_{\\mathcal{N}}\\bar{B}_{x}^{\\top}+\\bar{B}_{y,\\epsilon}\\hat{B}_{x,\\epsilon}^{\\top}-\\bar{L}_{\\mathcal{N}})}\\\\ &{\\quad=\\frac{m^{2}}{\\gamma^{2}\\lambda_{j}^{2}}\\mathbb{E}\\|h_{x,\\eta}\\|_{\\mathcal{E}_{\\lambda}^{2}}^{2}\\sum_{k=1}^{\\bar{\\lambda}}\\hat{L}_{\\mathcal{N},\\epsilon}}&\\\\ &{\\quad=\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Hence: ", "page_idx": 18}, {"type": "text", "text": "(Triangle inequality) ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\|\\hat{\\theta}_{n}-\\theta_{n}\\|^{2}\\leq\\mathbb{E}\\|s_{1}\\|^{2}+\\mathbb{E}\\|s_{2}\\|^{2}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\frac{m^{2}}{\\tau_{2}\\lambda_{0}^{2}}+\\|\\hat{B}_{n,\\perp}^{\\top}\\theta_{n}\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "G Proof of lemma 6: Regret of the subspace selection game ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Lemma 6. Let $\\begin{array}{r}{\\varepsilon=\\alpha=c_{2}d\\sqrt{\\frac{\\ln\\frac{d}{\\delta}}{\\tau_{1}}}}\\end{array}$ ln\u03c4 \u03b4 (with c2 defined in Lemma 3) and \u03b4 \u2208[0, 1] be a constant such that $\\begin{array}{r}{\\frac{N^{2}}{c d m}\\delta+\\frac{1}{2}\\ln\\ln\\frac{d}{\\delta}\\leq\\ln m\\sqrt{\\tau_{1}}}\\end{array}$ , where $c$ is a constant in Lemma 13.   \nThen, Algorithm $3$ chooses a sequence of subspaces $\\left\\{{\\hat{B}}_{n}\\right\\}$ over the expert set $\\mathcal{E}^{\\varepsilon}$ , defined in Definition 5, such that:   \nn=1 $\\sum_{n=1}^{N}\\mathbb{E}\\left[C_{n}(\\hat{B}_{n})\\right]\\leq O\\left(N C_{h i t}+\\frac{C_{m i s s}\\log|\\mathcal{E}^{\\varepsilon}|}{p}\\right)=\\tilde{O}\\left(N\\left(\\tau_{2}+\\tau\\cdot\\left(\\frac{m^{2}}{\\tau_{2}}+\\alpha^{2}\\right)\\right)+\\frac{\\tau d m}{p}\\right).$ ", "page_idx": 18}, {"type": "text", "text": "hParvoeo . want to show that, by choosing $\\delta$ such that $\\begin{array}{r}{\\frac{N^{2}}{c d m}\\delta+\\frac{1}{2}\\ln\\ln\\frac{d}{\\delta}\\leq\\ln m\\sqrt{\\tau_{1}}}\\end{array}$ , we would $\\begin{array}{r}{\\delta\\leq\\frac{\\ln|\\mathcal{E}^{\\varepsilon}|}{N^{2}}}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "We have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}{{\\hat{u}}\\leq{\\frac{\\ln(Y)}{\\ln(Y)}}}&{\\leq\\ln({\\frac{\\ln(\\ln(\\ln(X)))}{Z}})}\\\\ &{\\leq c{\\frac{\\bigl((\\ln(\\ln(B+\\ln))-\\ln(Z))\\bigr)}{Z}}}\\\\ &{=c{\\big(}{\\frac{\\ln(\\ln(B+\\ln)-\\ln(Z))}{Z}}{\\big)}}\\\\ &{=c{\\bigg(}{\\frac{\\ln(\\ln(B+\\ln)-\\ln(Z){\\big|}{\\frac{\\ln(Z)}{Z}})}{Z}}{\\bigg)}}\\\\ &{=c{\\bigg(}{\\frac{\\ln(\\ln(B+\\ln)-\\ln(Z){\\big|}{\\frac{\\ln(Z)}{Z}}+\\ln(Z))}{Z{\\big|}}}{\\bigg)}}\\\\ &{=c{\\bigg(}{\\frac{\\ln(\\ln(B+\\ln)+\\ln(\\ln(X)))}{Z{\\big|}}}{\\bigg)}}\\\\ &{\\qquad-c{\\bigg(}{\\frac{\\ln(\\ln(B+\\ln)-\\ln(Z-\\ln(\\ln(Z))))}{Z{\\big|}}}{\\bigg)}}\\\\ &{{\\xrightarrow{{\\mathrm{NO}}^{\\prime}}}i{\\frac{1}{2}}\\ln i{\\frac{\\tilde{\\partial}}{\\tilde{\\partial}{\\tilde{\\partial}{\\tilde{\\partial}{Z}}}}}\\sinh i{\\frac{\\sqrt{\\tilde{\\partial}-h}(\\ln(Z)-\\ln(\\ln(Z)))}{Z}}{\\bigg)}}\\\\ &{\\qquad-\\ln{\\frac{\\ln({\\frac{\\tilde{\\partial}}{\\tilde{\\partial}{Z}}})}{Z{\\tilde{\\partial}}}}}\\end{array}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Hence, by choosing $\\delta$ such that $\\begin{array}{r}{\\frac{N^{2}}{c d m}\\delta+\\frac{1}{2}\\ln\\ln\\frac{d}{\\delta}\\leq\\ln m\\sqrt{\\tau_{1}}}\\end{array}$ , we would have $\\begin{array}{r}{\\delta\\leq\\frac{\\ln|\\mathcal{E}^{\\varepsilon}|}{N^{2}}}\\end{array}$ ", "page_idx": 19}, {"type": "text", "text": "Next, recall the guarantee of Hedge from Freund and Schapire [1997]: ", "page_idx": 19}, {"type": "text", "text": "Theorem 15 (Freund and Schapire [1997]). For any sequence of loss vectors $\\ell_{1},\\cdot\\cdot\\cdot,\\ell_{T}$ and the initial weights of the experts are $w_{1}^{i}=1/n$ for all $i\\,\\in\\,[n]$ and $\\gamma\\,\\in\\,(0,1)$ , the Hedge algorithm generates $\\left\\{p_{t}\\right\\}_{t=1}^{T}$ such that its expected loss is bounded by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{T}\\left<\\ell_{t},p_{t}\\right>\\leq\\frac{-\\log(1-\\gamma)}{\\gamma}\\ell_{t}(i)+\\frac{\\ln n}{\\gamma},\\quad\\forall i=1,\\ldots,n\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "specifically, if at each round we choose $i_{t}\\sim p_{t}$ , ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{t=1}^{T}\\ell_{t}(i_{t})\\right]\\leq-\\frac{\\ln(1-\\gamma)}{\\gamma}\\cdot\\mathbb{E}\\left[\\sum_{t=1}^{T}\\ell_{t}(i)\\right]+\\frac{\\ln n}{\\gamma},\\quad\\forall i=1,\\ldots,n\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Applying Theorem 15 with $T=N$ , expert set $\\mathcal{E}^{\\varepsilon}$ , $i_{t}=\\hat{B}_{n}$ , and the baseline expert $i=B_{\\varepsilon}$ , we get: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{n=1}^{N}\\ell_{n}(\\hat{B}_{n})\\right]\\leq-\\frac{\\ln(1-\\gamma)}{\\gamma}\\cdot\\mathbb{E}\\left[\\sum_{n=1}^{N}\\ell_{t}(B_{\\varepsilon})\\right]+\\frac{\\ln|{\\mathcal E}^{\\varepsilon}|}{\\gamma}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By using Taylor expansion, we have: $\\begin{array}{r}{\\ln(1-x)=-x-{\\frac{x^{2}}{2}}+\\cdot\\cdot\\cdot}\\end{array}$ , then: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{-\\gamma-\\frac{\\gamma^{2}}{2}\\leq\\ln(1-\\gamma)}\\\\ {\\implies1+\\frac{\\gamma}{2}\\geq\\frac{\\ln(1-\\gamma)}{-\\gamma}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Hence: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sum_{n=1}^{N}\\ell_{n}(\\hat{B}_{n})\\right]\\leq(1+\\gamma/2)\\mathbb{E}\\left[\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})\\right]+\\frac{\\log|\\mathcal{E}^{\\varepsilon}|}{\\gamma}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Define $E_{n}$ as the event where $\\lVert{\\widehat{\\theta}}_{n}-\\theta_{n}\\rVert\\leq\\alpha$ and $E=\\cap_{n=1}^{N}E_{n}$ . Then, when all of our estimations $\\hat{\\theta}_{n}$ are accurate, we have: $\\begin{array}{r}{\\mathbb{I}\\left(E\\right)\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})\\,=\\,0}\\end{array}$ for $\\begin{array}{r}{\\dot{\\ell_{n}(B)}\\,=\\,\\frac{p}{\\mathbf{C}_{\\mathrm{miss}}}\\left[\\bar{C}_{n}(B)-\\mathbf{C}_{\\mathrm{hit}}\\frac{Z_{n}}{p}\\right]}\\end{array}$ and $B_{\\varepsilon}\\in\\mathcal{E}^{\\varepsilon}$ . ", "page_idx": 20}, {"type": "text", "text": "Since $P(E_{n}^{c})=\\delta$ , we have: $\\begin{array}{r}{P(E)\\geq1-\\sum_{n=1}^{N}P(E_{n}^{c})=1-N\\delta}\\end{array}$ . Thus. the event $E$ happens with high probability $1-N\\delta$ . Hence: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[\\displaystyle\\sum_{n=1}^{N}\\ell_{n}(\\hat{B_{n}})-\\displaystyle\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})\\right]\\leq\\mathbb{E}\\left[\\displaystyle\\gamma\\displaystyle\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})+\\frac{\\log|\\mathcal{E}^{\\varepsilon}|}{\\gamma}\\right]}&{}\\\\ {=\\mathbb{E}\\left[\\mathbb{I}(E)\\gamma\\displaystyle\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})+\\mathbb{I}(E^{\\varepsilon})\\gamma\\displaystyle\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})+\\frac{\\log|\\mathcal{E}^{\\varepsilon}|}{\\gamma}\\right]}&{}\\\\ {=\\mathbb{E}\\left[0+\\mathbb{I}(E^{\\varepsilon})\\gamma\\displaystyle\\sum_{n=1}^{N}\\ell_{n}(B_{\\varepsilon})+\\frac{\\log|\\mathcal{E}^{\\varepsilon}|}{\\gamma}\\right]}&{}\\\\ {\\leq\\mathbb{E}\\left[\\mathbb{I}(E^{\\varepsilon})\\gamma N+\\frac{\\log|\\mathcal{E}^{\\varepsilon}|}{\\gamma}\\right]}&{}\\\\ {\\leq N^{2}\\gamma\\delta+\\frac{\\log|\\mathcal{E}^{\\varepsilon}|}{\\gamma}}&{}\\\\ {\\leq O\\left(\\log|\\mathcal{E}^{\\varepsilon}|\\right).}&{\\qquad(\\delta\\leq\\frac{\\log|\\mathcal{E}^{\\varepsilon}|}{\\gamma}\\mathrm{~and~chose~}\\gamma=1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since $\\gamma=1-\\exp(-\\eta)$ , the learning rate $\\eta$ of the algorithm is $\\eta=-\\log(0.5)=0.301$ . ", "page_idx": 20}, {"type": "text", "text": "Then, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathbb{E}\\left[\\sum_{i=1}^{N}\\ell_{*}(B_{i})-\\sum_{n=1}^{N}\\ell_{*}(B_{i})\\right]\\le O(\\log|\\ell^{\\tau}|)}\\\\ {\\displaystyle\\rightarrow\\mathbb{E}\\left[\\sum_{i=1}^{N}\\ell_{*}(B_{i})\\right]-\\mathbb{E}\\left[(\\sum_{l=1}^{N}\\sum_{i=1}^{r}\\ell_{*}(B_{l})+1(E))\\sum_{n=1}^{r}\\ell_{*}(B_{i})\\right]\\le O(\\log|\\ell^{\\tau}|)}\\\\ {\\displaystyle\\rightarrow\\mathbb{E}\\left[\\sum_{i=1}^{N}\\ell_{*}(B_{i})\\right]-\\mathbb{E}\\left[\\big[\\{E\\>\\sum_{i=1}^{N}\\ell_{*}(B_{i})\\big\\}\\leq O(\\log|\\ell^{\\tau}|)\\right.}\\\\ {\\displaystyle\\rightarrow\\left.\\mathbb{E}\\left[\\sum_{i=1}^{N}\\sum_{i=1}^{r}\\ell_{*}(B_{i})\\right]\\leq O(\\log|\\ell^{\\tau}|)+{\\cal N}^{2}\\delta^{2}\\right.}\\\\ {\\displaystyle\\rightarrow\\sum_{i=1}^{N}\\mathbb{E}_{\\sum\\ell_{*}(B_{i})}\\left[\\ell_{*}(B_{i})-\\mathbb{C}_{\\ln}\\frac{Z_{\\ell}}{P}\\right]\\le O(\\log|\\ell^{\\tau}|)}\\\\ {\\displaystyle\\rightarrow\\sum_{i=1}^{N}\\mathbb{E}\\left[\\sum_{i=1}^{N}\\mathbb{E}_{\\sum\\ell_{*}(B_{i})}\\right]<O\\left(\\frac{\\mathbb{C}_{\\ln|\\ell^{\\tau}|}}{P}\\right)}\\\\ {\\displaystyle\\rightarrow\\sum_{i=1}^{N}\\mathbb{E}\\left[\\ell_{*}(B_{i})\\right]<O\\left(\\log|\\ell_{*}|\\right)\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\bar{C}_{n}(\\hat{B}_{n})\\right]=\\mathbb{E}\\left[\\tilde{C}_{n}(\\hat{B}_{n})\\cdot\\frac{Z_{n}}{p}\\right]}\\\\ &{\\phantom{\\mathbb{E}\\bigg[}\\tilde{C}_{n}(\\hat{B}_{n})\\cdot\\mathbb{I}(E_{n})\\cdot\\frac{Z_{n}}{p}\\bigg]}\\\\ &{\\phantom{\\mathbb{E}\\bigg[}C_{n}(\\hat{B}_{n})\\cdot(1-\\mathbb{I}(E_{n}^{C}))\\cdot\\frac{Z_{n}}{p}\\bigg]\\qquad\\qquad\\qquad(\\tilde{C}_{n}(B)\\mathbb{I}(E_{n})\\geq C_{n}(B)\\mathbb{I}(E_{n}))}\\\\ &{\\phantom{\\mathbb{E}\\bigg[}=C_{n}(\\hat{B}_{n})-\\mathbb{E}\\left[C_{n}(\\hat{B}_{n})\\cdot\\mathbb{I}(E_{n}^{C})\\cdot\\mathbb{E}\\left[\\frac{Z_{n}}{p}\\mid\\hat{B}_{n}\\right]\\right]}\\\\ &{\\phantom{\\mathbb{E}\\bigg[}\\geq C_{n}(\\hat{B}_{n})-\\mathbf{C}_{n^{\\perp}\\mathbf{s}\\mathbf{s}}\\beta}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Hence, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{n=1}^{N}\\mathbb{E}\\left[\\bar{C}_{n}(\\hat{B}_{n})\\right]\\leq O\\left(N\\mathbf{C}_{\\mathrm{hit}}+\\frac{\\mathbf{C}_{\\mathrm{niss}}\\log|\\mathcal{E}^{\\varepsilon}|}{p}\\right)}\\\\ &{\\Longrightarrow\\displaystyle\\sum_{n=1}^{N}\\mathbb{E}\\left[C_{n}(\\hat{B}_{n})\\right]\\leq O\\left(N\\mathbf{C}_{\\mathrm{hit}}+\\frac{\\mathbf{C}_{\\mathrm{niss}}\\log|\\mathcal{E}^{\\varepsilon}|}{p}+N\\delta\\mathbf{C}_{\\mathrm{niss}}\\right)}\\\\ &{\\displaystyle=O\\left(N\\mathbf{C}_{\\mathrm{hit}}+\\frac{\\mathbf{C}_{\\mathrm{niss}}\\log|\\mathcal{E}^{\\varepsilon}|}{p}\\right)\\quad~~(N^{2}\\delta=\\log|\\mathcal{E}^{\\varepsilon}|\\mathrm{~and~}\\frac{1}{N}\\leq1\\leq\\frac{1}{p})}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Substituting $\\mathbf{C_{\\mathrm{hit}}}$ and $\\mathbf{C}_{\\mathrm{miss}}$ in Equation (2) to complete the proof. ", "page_idx": 21}, {"type": "text", "text": "H Theorem 7: meta-regret guarantee ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Theorem 7. With exploration probability $\\begin{array}{r}{p\\ =\\ \\operatorname*{min}\\Bigg(\\Big(\\frac{2m\\sqrt{\\tau}}{N}\\Big)^{\\frac{2}{3}}\\,,1\\Bigg).}\\end{array}$ by choosing $\\varepsilon\\ =\\ \\alpha\\ =$ $c_{2}d\\sqrt{\\frac{\\ln\\frac{d}{\\delta}}{\\tau_{1}}}$ (with $c_{2}$ defined in Lemma 3) , where $\\delta\\,=\\,{\\frac{\\ln|{\\mathcal{E}}^{\\varepsilon}|}{N^{2}}}$ , and $\\begin{array}{r}{\\tau_{1}\\,=\\,d\\cdot\\,\\Big\\lfloor\\operatorname*{min}\\left(d\\sqrt{\\frac{\\tau}{p}},\\tau\\right)/d\\Big\\rfloor;}\\end{array}$ , $\\tau_{2}=m\\cdot\\lfloor\\sqrt{\\tau}\\rfloor$ , the meta-regret of the BOSS algorithm is bounded by: ", "page_idx": 21}, {"type": "equation", "text": "$$\nR_{\\tau}\\leq\\tilde{O}\\left(N m\\sqrt{\\tau}+N^{\\frac{2}{3}}\\tau^{\\frac{2}{3}}d m^{\\frac{1}{3}}+N d^{2}+\\tau m d\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Remainder of the Proof of Theorem 7. Recall that in the proof sketch of Theorem 7 (Section 4), we have proved that ", "page_idx": 21}, {"type": "equation", "text": "$$\nR_{\\tau}\\leq\\tilde{O}\\left(N p\\tau_{1}+N\\tau\\frac{d^{2}}{\\tau_{1}}+\\frac{\\tau d m}{p}+N\\tau_{2}+N\\tau\\frac{m^{2}}{\\tau_{2}}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now, by the choice of $\\tau_{2}=m\\cdot\\lfloor\\sqrt{\\tau}\\rfloor$ , ", "page_idx": 21}, {"type": "equation", "text": "$$\nR_{\\tau}\\leq\\tilde{O}\\left(N m\\sqrt{\\tau}+N\\tau\\frac{d^{2}}{\\tau_{1}}+N p\\tau_{1}+\\frac{\\tau d m}{p}\\right)\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We want to tune the parameters $p,\\tau_{1}$ to minimize the meta-regret subjected to the constraint: $p\\in[0,1]$ and $\\tau_{1}\\in[0,\\tau]$ . ", "page_idx": 21}, {"type": "text", "text": "The meta-regret is: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{R_{\\tau}\\leq\\tilde{O}\\left(N m\\sqrt{\\tau}+N\\tau\\frac{d^{2}}{\\tau_{1}}+N p\\tau_{1}+\\frac{\\tau d m}{p}\\right)}\\\\ &{\\quad=\\tilde{O}\\left(N m\\sqrt{\\tau}+N d\\sqrt{\\tau p}+\\frac{\\tau d m}{p}+N d^{2}\\right)}&&{(\\mathrm{Choose}\\ \\tau_{1}=d\\cdot\\left\\lfloor\\operatorname*{min}\\left(d\\sqrt{\\frac{\\tau}{p}},\\tau\\right)/d\\right\\rfloor)}\\\\ &{\\quad=\\tilde{O}\\left(N m\\sqrt{\\tau}+N^{\\frac{2}{3}}\\tau^{\\frac{2}{3}}d m^{\\frac{1}{3}}+N d^{2}+\\tau m d\\right)}&&{(\\mathrm{Choose}\\ p p=\\operatorname*{min}\\left(\\left(\\frac{2m\\sqrt{\\tau}}{N}\\right)^{\\frac{2}{3}},1\\right))}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "I Additional experiment result ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "I.1 Adversarial environment for SeqRepL\u2019s deterministic exploration schedule ", "page_idx": 22}, {"type": "image", "img_path": "2kZMtdjzSV/tmp/acb850e0dc12460160fa18f65a893763e50ea15c55ea8f7a859d3507a73b28d3.jpg", "img_caption": [], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "Figure 2: Comparing the cumulative regret of BOSS and other baselines. The setting is $(N,\\tau,d,m)=$ (6000, 2000, 10, 3) and $\\lVert\\theta_{n}\\rVert_{2}\\in[0.8,\\bar{1}]\\;\\forall n\\in[N]$ chosen uniformly at random from this interval. SeqRepL, BOSS, and BOSS-no-oracle uses the same hyperparameters $\\tau_{1}\\,=\\,400,\\tau_{2}\\,=\\,50$ . The environment only reveals a new subspace dimension at tasks 1, 501, and 1001, and only reveals the same dimension at Qin et al. [2022]\u2019s deterministic exploration schedule. ", "page_idx": 22}, {"type": "text", "text": "I.2 When the Task Diversity assumption is satisfied ", "text_level": 1, "page_idx": 22}, {"type": "image", "img_path": "2kZMtdjzSV/tmp/47f8e1c5e7fb00dd3a4a198443e58ab516511331a1052033f89be34324bbf776.jpg", "img_caption": ["Figure 3: Comparing the cumulative regret of BOSS and other baselines. The setting is $(N,\\tau,d,m)=$ (6000, 2000, 10, 3) and $\\|\\theta_{n}\\|_{2}\\in[0.8,\\bar{1}]\\,\\forall n\\in[N]$ . SeqRepL, BOSS, and BOSS-no-oracle uses the same hyperparameters $\\tau_{1}=1000$ , $\\tau_{2}=300$ . The task diversity assumption is satisfied: each $\\theta_{n}$ is generated by a linear combinations of the columns in $B_{n}$ \u2013 the subspace spanning $\\theta_{1},\\cdot\\cdot\\cdot,\\theta_{n-1}$ . The performance of SeqRepL and BOSS is almost identical in Fig 3a. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: See the abstract, the end of Section 1 (and Section 4 and 5 for elaboration) on a summary of the contributions. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 23}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: The limitations are discussed in Section 4 and Section 6 ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 23}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: All the necessary assumptions and proof are shown in the main paper and Appendix. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 24}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We will publish the code in the future, including all the hyper-parameters to reproduce the results in the paper. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The code for our paper can be found at https://github.com/ duongnhatthang/BOSS. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 25}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The experiment information is provided in Section 5 and the code with all the parameters can be found at https://github.com/duongnhatthang/BOSS. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 25}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is shown in Section 5, where we provide a standard deviation error over five randomized experiments. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 25}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [No] ", "page_idx": 26}, {"type": "text", "text": "Justification: The experiment is relatively small and simple, and the paper\u2019s main focus is the theoretical analysis. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 26}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] Justification: We have read the NeurIPS Code of Ethics and found no violation. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 26}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: Our work focus on the theoretical analysis and poses no significant societal impacts. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 26}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: The paper poses no such risks. Our dataset is synthetic. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 27}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: All authors and citations are mentioned, to the best of our knowledge. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: We don\u2019t provide any new assets. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 28}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: Our work does not involve human subjects ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 28}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: Our work does not require IRB Approvals or Equivalent for Research with Human Subjects. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}]