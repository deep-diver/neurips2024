[{"figure_path": "8CguPoe3TP/figures/figures_4_1.jpg", "caption": "Figure 1: Graphical display of smooth ambiguity aversion at work. Although \u03b8\u2081 and \u03b8\u2082 yield the same loss R* in Q-expectation, the ambiguity averse criterion favors the less variable decision \u03b8\u2081. Graphically, this is because the orange line connecting \u03c6(Rp\u2081(\u03b8\u2081)) to \u03c6(Rp\u2082(\u03b8\u2081)) lies (point-wise) below the line connecting \u03c6(Rp\u2081(\u03b8\u2082)) to \u03c6(Rp\u2082(\u03b8\u2082)).", "description": "This figure illustrates the concept of smooth ambiguity aversion. Two decisions, \u03b8\u2081 and \u03b8\u2082, have the same expected risk (R*) under a distribution Q, but \u03b8\u2081 has less variability in its risk across different possible models (p\u2081 and p\u2082).  A convex function \u03c6 applied to the expected risks highlights that the ambiguity-averse criterion prefers \u03b8\u2081 due to its lower risk variability.", "section": "Decision Theory and Bayesian Statistics"}, {"figure_path": "8CguPoe3TP/figures/figures_21_1.jpg", "caption": "Figure 2: Simulation results for the high-dimensional sparse linear regression experiment. Bars report the mean and standard deviation (across 200 sample simulations) of the test RMSE, L2 distance of estimated coefficient vector \u03b8 from the data-generating one, and the L2 norm of \u03b8. Results are shown for the ambiguity-averse, ambiguity-neutral, and OLS procedures. Note: The left (blue) axis refers to mean values, the right (orange) axis to standard deviation values.", "description": "This figure displays the results of a high-dimensional sparse linear regression simulation study.  Three different methods are compared: an ambiguity-averse approach (the proposed method), an ambiguity-neutral approach (regularized regression), and ordinary least squares (OLS). The performance is evaluated across four different values of the concentration parameter (a = 1, 2, 5, 10) using three metrics: test RMSE (root mean squared error), L2 distance of the estimated coefficient vector from the true vector, and the L2 norm of the estimated coefficient vector.  The bars represent the mean and standard deviation of each metric across 200 simulations.  The results show that the ambiguity-averse method generally outperforms the others in terms of both average performance and stability (lower standard deviation).", "section": "Simulation Studies"}, {"figure_path": "8CguPoe3TP/figures/figures_22_1.jpg", "caption": "Figure 3: Simulation results from the experiment on Gaussian mean estimation with outliers. Bars report the mean and standard deviation (across 100 sample simulations) of the test mean negative log-likelihood and the absolute value distance of the estimated parameter from 0 (the data-generating value). Results are shown for the ambiguity-averse, ambiguity-neutral, and MLE procedures. Note: The left (blue) axis refers to mean values, the right (orange) axis to standard deviation values.", "description": "The figure shows the results of a simulation study comparing three different methods for estimating the mean of a Gaussian distribution in the presence of outliers. The methods are: ambiguity-averse, ambiguity-neutral, and maximum likelihood estimation (MLE). For each method, the figure displays the mean and standard deviation of the test mean negative log-likelihood and the absolute distance of the estimated parameter from the true value (0) across 100 simulations.  The results demonstrate that the ambiguity-averse method outperforms the other two in terms of both average performance and variability.", "section": "Experiment on Gaussian Location Estimation With Outliers"}, {"figure_path": "8CguPoe3TP/figures/figures_23_1.jpg", "caption": "Figure 4: Simulation results for the high-dimensional sparse logistic regression experiment. Bars report the mean and standard deviation (across 200 sample simulations) of the test average loss, L2 distance of estimated coefficient vector \u03b8 from the data-generating one, and the L2 norm of \u03b8. Results are shown for the ambiguity-averse, L2-regularized, and un-regularized procedures. Note: The left (blue) axis refers to mean values, the right (orange) axis to standard deviation values.", "description": "This figure displays the performance comparison among three different methods in a high-dimensional sparse logistic regression task.  The methods are the proposed ambiguity-averse method, L2-regularized logistic regression, and unregularized logistic regression. The results across 200 simulations are shown for three metrics: test average loss, L2 distance from the true coefficient vector, and the L2 norm of the estimated coefficient vector. Each bar represents the mean and standard deviation of the metric across the simulations for a given method and regularization parameter (\u03b1). The figure demonstrates that the ambiguity-averse method shows improvement in terms of average performance and reduced variability, particularly for smaller \u03b1 values.", "section": "Experiments"}]