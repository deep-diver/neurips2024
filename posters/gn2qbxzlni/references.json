{"references": [{"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-05-14", "reason": "This paper is foundational in establishing the capabilities of LLMs to perform few-shot learning, a key concept in the current LLM paradigm."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2021-05-03", "reason": "The MMLU benchmark introduced in this paper is a widely used and significant dataset for evaluating the capabilities of LLMs across numerous tasks, directly relevant to the current study."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-26", "reason": "This paper presents the GSM8K benchmark, which is directly used and referenced as a core benchmark for mathematical reasoning by the current study."}, {"fullname_first_author": "Aarohi Srivastava", "paper_title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models", "publication_date": "2022-06-08", "reason": "This paper introduces the BIG-bench benchmark, which is extensively used and referenced by the current study for its comprehensive evaluation of LLM capabilities."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-11-28", "reason": "This paper introduces the chain-of-thought prompting technique, a crucial methodology employed and extensively analyzed by the current study"}]}