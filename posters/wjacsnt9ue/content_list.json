[{"type": "text", "text": "Sharpness-diversity tradeoff: improving flat ensembles with SharpBalance ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Haiquan $\\mathbf{L}\\mathbf{u}^{1}$ ,\u2217 Xiaotian Liu2,\u2217 Yefan Zhou2,\u2217 Qunli Li3,\u2217 Kurt Keutzer4, Michael W. Mahoney4,5,6, Yujun Yan2, Huanrui $\\mathbf{Yang^{4}}$ , Yaoqing Yang2 ", "page_idx": 0}, {"type": "text", "text": "1 Nankai University   \n2 Dartmouth College   \n3 University of California San Diego   \n4 University of California at Berkeley   \n5 International Computer Science Institute   \n6 Lawrence Berkeley National Laboratory ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recent studies on deep ensembles have identified the sharpness of the local minima of individual learners and the diversity of the ensemble members as key factors in improving test-time performance. Building on this, our study investigates the interplay between sharpness and diversity within deep ensembles, illustrating their crucial role in robust generalization to both in-distribution (ID) and out-of-distribution (OOD) data. We discover a trade-off between sharpness and diversity: minimizing the sharpness in the loss landscape tends to diminish the diversity of individual members within the ensemble, adversely affecting the ensemble\u2019s improvement. The trade-off is justified through our theoretical analysis and verified empirically through extensive experiments. To address the issue of reduced diversity, we introduce SharpBalance, a novel training approach that balances sharpness and diversity within ensembles. Theoretically, we show that our training strategy achieves a better sharpness-diversity trade-off. Empirically, we conducted comprehensive evaluations in various data sets (CIFAR-10, CIFAR-100, TinyImageNet) and showed that SharpBalance not only effectively improves the sharpness-diversity trade-off, but also significantly improves ensemble performance in ID and OOD scenarios. Our code has been made open-source.\u2020 ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "There has been interest in understanding the properties of neural networks (NNs) and their implications for robust generalization to both in-distribution (ID) and out-of-distribution (OOD) data [Hendrycks and Dietterich, 2019a]. Two properties of particular importance, sharpness (or flatness) [Granziol, 2020, Andriushchenko et al., 2023, Yang et al., 2021, Dinh et al., 2017, Yao et al., 2020] and diversity [Laviolette et al., 2017, Fort et al., 2019, Yao et al., 2020, Dietterich, 2000, Ortega et al., 2022, Theisen et al., 2023], have been shown to have a significant influence on performance. In the context of deep ensembles [Ovadia et al., 2019, Lakshminarayanan et al., 2017, Fort et al., 2019, Mehrtash et al., 2020, Ganaie et al., 2022], diversity (which measures the variance in output between independently-trained models) is shown to be critical in enhancing ensemble accuracy. Sharpness, on the other hand, quantifies the curvature of local minima and is believed to be empirically correlated with an individual model\u2019s generalization ability. ", "page_idx": 0}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/e5ec002972617448b65822082a7ac728dbc46e1284e11ac270f851c5d1181e77.jpg", "img_caption": [], "img_footnote": [], "page_idx": 1}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/7d82838657c391e290644cc40f4b82b86bccd078a91d5ff913bdf290c58af5f9.jpg", "img_caption": ["Figure 1: (Sharpness-diversity trade-off and SharpBalance). (a) Caricature illustrating the sharpness-diversity trade-off that emerges in an ensemble\u2019s loss landscape induced by the Sharpnessaware Minimization (SAM) optimizer. We propose SharpBalance to address this trade-off. Each black circle represents an individual NN in a three-member ensemble. The distance between circles represents the diversity between NNs and the ruggedness of the basin represents the sharpness of each NN. (b) Theoretically proving the existence of the sharpness-diversity trade-off and improvement from SharpBalance, plotting the analytic representation of sharpness and diversity from Theorem 1 and Theorem 2 by changing the perturbation radius $\\rho$ of SAM. SharpBalance achieves a larger diversity for the same level of sharpness. (c) Empirical results of verifying sharpness-diversity trade-off improvement from SharpBalance. Each marker represents a three-member ResNet18 ensemble trained on CIFAR-10. Diversity is measured by the variance of individual models\u2019 predictions, and sharpness is measured by the adaptive worst-case sharpness, both defined in Section 2. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Recent research on loss landscapes [Yang et al., 2021] highlights that a single structural property of the loss landscape is insufficient to fully capture a model\u2019s generalizability, and it underscores the importance of a joint analysis of sharpness and diversity. Despite significant efforts in studying sharpness and diversity individually, a gap persists in understanding their relationship, particularly in the context of ensemble learning. Our work seeks to bridge this gap by investigating ensemble learning through the lens of loss landscapes, with a specific focus on the interplay between sharpness and diversity. ", "page_idx": 1}, {"type": "text", "text": "Sharpness-diversity trade-off. Our examination of loss landscape structure for ensembling revealed a \u201ctrade-off\u201d between the diversity of individual NNs and the sharpness of the local minima to which they converge. This trade-off introduces a potential limitation to the achievable performance of the deep ensemble: the test accuracy of individual NN can be improved as the sharpness is reduced, but it simultaneously reduces diversity, thereby compromising the ensembling improvement (evidence in Section 4.2 and 4.4). This trade-off is visually summarized in the lower transition branch in Figure 1a. We also developed theories (in Section 3) to verify the trade-off. The theoretical results characterizing this phenomenon are visualized in Figure 1b, and the experimental observation is presented in Figure 1c. In Section 4.2, we also verified the existence of the trade-off by varying the experimental setting to include different datasets and different levels of overparameterization (e.g., changing model width). ", "page_idx": 1}, {"type": "text", "text": "SharpBalance mitigates the trade-off and improves ensembling performance. To address the challenge presented by the sharpness-diversity tradeoff, we propose a novel ensemble training method called SharpBalance. This method aims to simultaneously reduce the sharpness of individual NNs and prevent diversity reduction among them, as demonstrated in the upper transition branch of Figure 1a. This method is designed based on our theoretical results, which suggest that training different ensemble members using a loss function that aims to reduce sharpness on different subsets of the training data can improve the trade-off between sharpness and diversity. Our theoretical results are summarized in Figure 1b. Aligned with theoretical insights, our SharpBalance method lets each ensemble member minimize the sharpness objective exclusively on a subset of training data, termed the sharpness-aware set. The sharpness-aware set of each ensemble member is diversified by an adaptive strategy based on data-dependent sharpness measures. As shown in Figure 1c, we verify that SharpBalance improves the sharpness-diversity tradeoff in training the ResNet18 ensemble on CIFAR10. We conducted experiments on three classification datasets to show that SharpBalance boosts ensembling performance in ID and OOD data. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Our contributions are summarized as follows: ", "page_idx": 2}, {"type": "text", "text": "\u2022 Comprehensive identification of the sharpness-diversity trade-off: This work provides a thorough examination of the phenomenon sharpness-diversity trade-off where reducing the sharpness of individual models can decrease diversity between models within an ensemble. We demonstrate this effect through extensive experiments across various settings,using different sharpness and diversity measures, as well as different model capacities. Our findings show that this trade-off can negatively affect the ensemble improvements. ", "page_idx": 2}, {"type": "text", "text": "\u2022 Novel theory: We prove the existence of the trade-off under a novel theoretical framework based on rigorous analysis of sharpness-aware training objectives [Foret et al., 2021, Behdin and Mazumder, 2023]. Our analysis borrows tools from analyzing Wishart moments [Bishop et al., 2018], and characterizes the exact dynamics of training, bias-variance tradeoff, and the upper and lower bounds of sharpness. Notably, our novel theoretical analysis generalizes existing analysis to ensemble members trained with different data, which is the key to analyzing our own training method SharpBalance. ", "page_idx": 2}, {"type": "text", "text": "\u2022 Effective approach: To mitigate the sharpness-diversity trade-off, we introduce SharpBalance, an ensemble training approach. Our theoretical framework demonstrates that SharpBalance provably achieves improvements on the sharpness-diversity trade-off by reducing sharpness while mitigating the decrease in diversity. Empirically, we confirm this improvement and demonstrate that SharpBalance enhances overall ensemble performance, outperforming baseline methods in CIFAR-10, CIFAR-100 [Krizhevsky, 2009], TinyImageNet [Le and Yang, 2015], and their corrupted versions to assess OOD performance. ", "page_idx": 2}, {"type": "text", "text": "We provide a more detailed discussion on related work in Appendix B. ", "page_idx": 2}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Preliminaries. We use a NN denoted as $f_{\\theta}:\\mathbb{R}^{d_{\\mathrm{in}}}\\rightarrow\\mathbb{R}^{d_{\\mathrm{out}}}$ , where $\\pmb\\theta\\in\\mathbb{R}^{p}$ denotes the trainable parameters. The training dataset comprises $n$ data-label pairs $\\mathcal{D}=\\left\\{(\\pmb{x}_{1},\\pmb{y}_{1})\\,,\\dots,(\\pmb{x}_{n},\\pmb{y}_{n})\\right\\}$ . The training loss of NN $f_{\\theta}$ over a dataset $\\mathcal{D}$ can be defined as $\\begin{array}{r}{\\mathcal{L}_{\\mathcal{D}}(\\pmb{\\theta})=\\frac{1}{n}\\sum_{i=1}^{n}\\ell\\left(f_{\\pmb{\\theta}}\\left(\\pmb{x}_{i}\\right),\\pmb{y}_{i}\\right)}\\end{array}$ . Here $\\ell(\\cdot)$ is a loss function, which, for instance, can be the cross entropy loss or $\\ell_{2}$ loss. We construct a deep ensemble consisting of $m$ distinct NNs $f_{\\pmb{\\theta}_{1}},\\dots,f_{\\pmb{\\theta}_{m}}$ . For classification tasks, the ensemble\u2019s output is derived by averaging the predicted logits of these individual networks. We use flat ensemble to mean the deep ensemble in which each ensemble member is trained using a sharpness-aware optimization method [Foret et al., 2021], differentiating it from other ensemble approaches. ", "page_idx": 2}, {"type": "text", "text": "Diversity metrics. Distinct measures of diversity have been proposed in the literature [Laviolette et al., 2017, Fort et al., 2019, Dietterich, 2000, Baek et al., 2022, Ortega et al., 2022, Theisen et al., 2023], and they are primarily calculated using the predictions made by individual models. Ortega et al. [2022] define diversity $\\mathbb{D}(\\pmb\\theta)$ to be the variance of model outputs averaged over the data-generating distribution, which we adopt in the theoretical analysis: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{D}(\\pmb\\theta)=\\mathbb{E}_{\\mathcal{D}}[\\mathrm{Var}(f_{\\pmb\\theta}(\\mathcal{D}))].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In our experiments, diversity is measured using variance defined above, as well as two other widely used metrics in ensemble learning, namely Disagreement Error Ratio (DER) [Theisen et al., 2023] defined in equation (2), and KL divergence [Kullback and Leibler, 1951] defined in equation (11) in the appendices. We show in Section 4.2 that our main claim generalizes to these three metrics in characterizing the diversity between members within an ensemble. Specifically, denote $\\mathcal{P}$ as the distribution of model weights $\\pmb{\\theta}$ after training. Then, the DER is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{DER}=\\frac{E_{\\pmb{\\theta},\\pmb{\\theta}^{\\prime}\\sim\\mathcal{P}}[\\mathrm{Dis}(f_{\\pmb{\\theta}},f_{\\pmb{\\theta}^{\\prime}})]}{E_{\\pmb{\\theta}\\sim\\mathcal{P}}[\\mathcal{E}(f_{\\pmb{\\theta}})]},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\operatorname{Dis}(f_{\\theta},f_{\\theta^{\\prime}})$ is the prediction disagreement [Masegosa, 2020, Mukhoti et al., 2021, Jiang et al., 2022] between two classifier $f_{\\theta},f_{\\theta^{'}}$ , and $\\mathcal{E}(f_{\\theta})$ is the prediction error. ", "page_idx": 2}, {"type": "text", "text": "Sharpness Metric. In accordance with the definition proposed by Foret et al. [2021], we characterize the first-order sharpness of a model as the worst-case perturbation within a radius of $\\rho_{0}$ . Mathematically, the sharpness $\\kappa$ of a model $\\pmb{\\theta}$ is expressed as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\kappa(\\pmb\\theta;\\rho_{0})=\\operatorname*{max}_{\\|\\pmb\\varepsilon\\|_{2}\\leq\\rho_{0}}\\mathcal L_{\\mathcal D}(\\pmb\\theta+\\pmb\\varepsilon)-\\mathcal L_{\\mathcal D}(\\pmb\\theta).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Empirically, we measure the sharpness of the NN via the adaptive worst-case sharpness [Kwon et al., 2021, Andriushchenko et al., 2023]. The adaptive worst-case sharpness captures how much the loss can increase within the perturbation radius $\\rho_{0}$ of $\\pmb{\\theta}$ : ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\|T_{\\theta}^{-1}\\boldsymbol{\\varepsilon}\\|_{2}\\leq\\rho_{0}}\\!\\mathcal{L}_{\\mathcal{D}}(\\theta+\\boldsymbol{\\varepsilon})-\\mathcal{L}_{\\mathcal{D}}(\\theta),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\pmb\\theta=[\\theta_{1},\\ldots,\\theta_{l}]$ , and $T_{\\theta}=\\mathrm{diag}\\,(|\\theta_{1}|\\,,\\dots,|\\theta_{l}|).~?$ $T_{\\theta}^{-1}$ is a normalization operator to make sharpness \u201cscale-free\u201d, that is, such that scaling operations on $\\pmb{\\theta}$ that do not alter NN predictions will not impact the sharpness measure. ", "page_idx": 3}, {"type": "text", "text": "Ensembling. We characterize the effectiveness of ensembling by the metric called ensemble improvement rate (EIR) [Theisen et al., 2023], which is defined as the ensembling improvement over the average performance of single models. Let $\\mathcal{E}_{\\mathrm{ens}}$ denote the test error of an ensemble; the EIR is then defined as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{EIR}=\\frac{E_{\\pmb{\\theta}\\sim\\mathcal{P}}[\\mathcal{E}(f_{\\pmb{\\theta}})]-\\mathcal{E}_{\\mathrm{ens}}}{E_{\\pmb{\\theta}\\sim\\mathcal{P}}[\\mathcal{E}(f_{\\pmb{\\theta}})]}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Sharpness Aware Minimization (SAM). SAM [Foret et al., 2021] has been shown to be an effective method for improving the generalization of NNs by reducing the sharpness of local minima. It essentially functions by penalizing the maximum loss within a specified radius $\\rho$ of the current parameter $\\theta$ . The training objective of SAM is to minimize the following loss function: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal L_{\\mathcal D}^{\\mathrm{SAM}}(\\pmb\\theta):=\\operatorname*{max}_{\\|\\pmb\\varepsilon\\|_{2}\\leq\\rho}\\mathcal L_{\\mathcal D}(\\pmb\\theta+\\pmb\\varepsilon)+\\lambda\\|\\pmb\\theta\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\lambda$ is the hyperparameter of a standard $\\ell_{2}$ regularization term. ", "page_idx": 3}, {"type": "text", "text": "3 Theoretical Analysis of Sharpness-diversity Trade-off ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "This section theoretically analyzes the sharpness-diversity trade-off. The diversity among individual models is quantified using equation (1). The first theorem establishes the existence of a trade-off between sharpness and diversity. The second theorem demonstrates that training models with only a subset of data samples leads to a more favorable trade-off between these two metrics. ", "page_idx": 3}, {"type": "text", "text": "Sharpness and Diversity of SAM. Assume the training data matrix $\\mathbf{A}\\in\\mathbb{R}^{n_{\\mathrm{tr}}\\times d_{\\mathrm{in}}}$ and test data matrix $\\mathbf{T}\\in\\dot{\\mathbb{R}}^{n_{\\mathrm{tc}}\\times d_{\\mathrm{in}}}$ are random with entries drawn from Gaussian $\\begin{array}{r}{\\mathcal{N}(0,\\frac{1}{d_{\\mathrm{in}}}\\mathbf{I})}\\end{array}$ . Suppose the model weight at the 0-th time step, $\\pmb{\\theta}_{0}$ , is initialized randomly such that $\\mathbb{E}[\\pmb{\\theta}_{0}]=\\mathbf{0}$ and $\\mathbb{E}[\\pmb{\\theta}_{0}\\pmb{\\theta}_{0}^{T}]=\\sigma^{2}\\mathbf{I}$ and updated with a quadratic optimization objective through SAM. The learned weight matrix after $k$ time steps is denoted as $\\theta_{k}$ . Let $\\pmb{\\theta}^{*}$ be the teacher model (i.e., ground-truth model) such that $\\mathbf{A}\\theta^{*}=\\mathbf{y}^{(\\mathbf{A})}$ and $\\mathbf{T}\\pmb{\\theta}^{*}=\\mathbf{y}^{(\\mathbf{T})}$ , where $\\mathbf{y}^{(\\mathbf{D})}$ is the label vector for data matrix $\\mathbf{D}$ . Given a perturbation radius $\\rho_{0}$ , the sharpness of a model after $k$ iteration under the random matrix assumption is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\kappa(\\pmb{\\theta}_{k};\\rho_{0})=\\mathbb{E}_{\\mathbf{A}}[\\operatorname*{max}_{\\|\\pmb{\\varepsilon}\\|_{2}\\leq\\rho_{0}}f\\left(\\mathbb{E}_{\\pmb{\\theta}_{0}}\\left[\\pmb{\\theta}_{k}\\right]+\\pmb{\\varepsilon};\\mathbf{A}\\right)-f\\left(\\mathbb{E}_{\\pmb{\\theta}_{0}}\\left[\\pmb{\\theta}_{k}\\right];\\mathbf{A}\\right)],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is the expected fluctuation of the model output after perturbation over the data distribution. For simplicity, we denote $\\kappa(\\pmb{\\theta}_{k}^{S A M};\\rho_{0})\\,=\\,\\kappa_{k}^{S A M}$ for the rest of the paper. We derive an explicit formulation of diversity and upper and lower bounds of sharpness for models optimized with SAM in Theorem 1. Detailed proof can be found in Appendix C.1. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1 (Diversity and Sharpness of SAM). Let $\\theta_{0}$ be initialized randomly such that $\\mathbb{E}[\\pmb{\\theta}_{0}]=\\mathbf{0}$ and $\\mathbb{E}[\\pmb{\\theta}_{0}\\pmb{\\theta}_{0}^{T}]=\\sigma^{2}\\mathbf{I}.$ . Suppose $\\pmb{\\theta}_{k}^{S A M}$ is the model weight after $k$ iterations of training with SAM on $\\mathbf{A}\\in\\mathbb{R}^{n_{\\mathrm{tr}}\\times d_{\\mathrm{in}}}$ and evaluated on $\\mathbf{T}\\in\\mathbb{R}^{n_{\\mathrm{tc}}\\times d_{\\mathrm{in}}}$ . Let $\\eta$ be the step size, $\\rho$ be the perturbation radius in SAM and $\\rho_{0}$ be the radius for measuring sharpness kSAM. Then ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{D}(\\pmb{\\theta}_{k}^{S A M})=\\phi(2k,0)\\sigma^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "equation", "text": "$$\n\\frac{\\gamma_{0}^{2}}{2}\\left(\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}-1\\right)^{2}+\\rho_{0}\\sqrt{\\phi(2k,2)}\\|\\theta^{*}\\|_{2}-G\\leq\\kappa_{k}^{S A M}\\leq\\frac{\\rho_{0}^{2}}{2}\\left(\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}+1\\right)^{2}+\\rho_{0}\\sqrt{\\phi(2k,2)}\\|\\theta^{*}\\|_{2},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where ", "page_idx": 4}, {"type": "equation", "text": "$$\nb(i,j):=\\mathbb{1}_{j=0}+\\sum_{k_{1}+k_{2}+k_{3}=i}\\frac{i!}{k_{1}!k_{2}!k_{3}!}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}\\left(\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}\\right)^{m}\\sum_{l=1}^{m}\\left(\\frac{d_{\\mathrm{in}}}{n_{\\mathrm{tr}}}\\right)^{m-l}\\mathcal{O}(1+1/d_{\\mathrm{in}})N_{m,l},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To provide a clearer understanding of the relationship between sharpness and diversity, Figure 2 presents a trade-off curve between these two metrics. The estimated sharpness and diversity are displayed on the $x$ and $y$ axes, respectively. Each point in the plot corresponds to a model trained using SAM with a different $\\rho$ value, showcasing the outcome of varying perturbation radius. In these experiments, we evaluated the sharpness and diversity of the models empirically and compared them to the estimates obtained using Theorem 1. The soundness of Theorem 1 and tightness of the derived bounds are further supported by empirical evidence, as depicted in Figure 2. Further verification results supporting our theoretical analysis are provided in Appendix C.3 ", "page_idx": 4}, {"type": "text", "text": "Training with Data Subsets. Assume A is partitioned into $S$ horizontal submatrices, such that $\\mathbf{A}\\:=\\:[\\mathbf{A}_{1}^{T},\\mathbf{A}_{2}^{T},\\ldots,\\mathbf{A}_{S}^{T}]^{T}$ . We show in Theorem 2 a similar analysis of the sharpness and diversity of ensembles for which each model is trained with a submatrix. Under this setting, we first selected a subset of data $\\mathbf{A}_{s}$ uniformly at random and then train the model with the selected subset with SAM. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2 (Diversity and Sharpness when Models are Trained on Subsets). Suppose the training data matrix A is partitioned into $S$ horizontal submatrices. Let $\\pmb{\\theta}_{0}$ be initialized randomly such that $\\mathbb{E}[\\pmb{\\theta}_{0}]=\\mathbf{0}$ and $\\mathbb{E}[\\pmb{\\theta}_{0}\\pmb{\\theta}_{0}^{T}]\\,=\\,\\sigma^{2}\\mathbf{I}.$ . Let $\\theta_{k}^{\\bar{S}h a r p B a l}$ be the model weight trained with SAM for $k$ iterations on the submatrix $\\mathbf{A}_{s}\\in\\mathbb{R}^{\\frac{n_{\\mathrm{tr}}}{S}\\times d_{\\mathrm{in}}}$ , selected uniformly at random, and evaluated on test data $\\mathbf{T}\\in\\dot{\\mathbb{R}}^{n_{\\mathrm{tc}}\\times\\dot{d}_{\\mathrm{in}}}$ . Let $\\eta$ be the step size, $\\rho$ be the perturbation radius in SAM, $\\rho_{0}$ be the radius for measuring sharpness \u03bakS $\\kappa_{k}^{S A M}$ , and $\\begin{array}{r}{r=\\frac{n_{\\mathrm{tr}}}{S d_{\\mathrm{in}}}}\\end{array}$ . Then ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{D}(\\pmb{\\theta}_{k}^{S h a r p B a l})=\\!\\phi^{\\prime}(2k,0)\\sigma^{2}}&{{}}\\\\ {+\\frac{S-1}{d_{\\mathrm{in}}S}\\left(\\phi^{\\prime}(2k,0)-\\phi^{\\prime}(k,0)^{2}\\right)\\|\\pmb{\\theta}^{*}\\|_{2}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and ", "page_idx": 4}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/44d3535aa7ebef5bb2d63782233120b2875585e49760a77176e63f42a74dd3f1.jpg", "img_caption": ["Figure 2: (Theoretical vs. Simulated sharpness-diversity trade-off). This figure illustrates the relationship between sharpness (upper and lower bounds) and diversity as predicted by Thereom 1 and as observed in simulations. Note that the upper and lower bounds correspond to the sharpness values plotted along the $\\mathbf{X}$ -axis, with the upper bound positioned to the right and the lower bound to the left. Also, note that the bounds provided are for the expected sharpness, which means that random fluctuations can cause the simulation results to move beyond these bounds. "], "img_footnote": [], "page_idx": 4}, {"type": "equation", "text": "$$\n\\kappa_{k}^{S h a r p B a l}(\\rho_{0})\\leq\\frac{\\rho_{0}^{2}}{2}\\left(\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}+1\\right)^{2}\\!\\!+\\!\\frac{\\rho_{0}}{S}\\sqrt{C}\\|\\pmb{\\theta}^{*}\\|_{2},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{C=S\\phi^{\\prime}(2k,2)+2r S(S-1)\\phi^{\\prime}(2k,1)+2S(S-1)\\phi^{\\prime}(k,2)\\phi^{\\prime}(k,0)}\\\\ &{\\qquad+\\,r(1+r)S(S-1)\\phi^{\\prime}(2k,0)+2S(S-1)\\phi^{\\prime}(k,1)\\phi^{\\prime}(k,1)}\\\\ &{\\qquad+\\,\\frac{3}{2}r(1+r)S(S-1)(S-2)\\phi^{\\prime}(k,0)^{2}+\\frac{3}{2}r^{2}S(S-1)(S-2)\\phi^{\\prime}(2k,0)}\\\\ &{\\qquad+\\,3r S(S-1)(S-2)\\phi^{\\prime}(k,0)\\phi^{\\prime}(k,1)+r^{2}S(S-1)(S-2)(S-3)\\phi^{\\prime}(k,0)^{2},}\\\\ &{\\qquad+\\,1_{j=0}+\\displaystyle\\sum_{k_{1}+k_{2}+k_{3}=i}\\frac{i!}{k_{1}!k_{2}!k_{3}!}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}\\left(\\frac{n_{\\mathrm{tr}}}{S d_{\\mathrm{in}}}\\right)^{m}\\displaystyle\\sum_{l=1}^{m}\\left(\\frac{S d_{\\mathrm{in}}}{n_{\\mathrm{tr}}}\\right)^{m-l}\\mathcal{O}(1+\\frac{1}{d_{\\mathrm{in}}})N_{m,l},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $m=k_{2}+2k_{3}+j$ . $\\begin{array}{r}{N_{m,l}=\\frac{1}{l}\\binom{m-1}{l-1}\\binom{m}{l-1}}\\end{array}$ is the Narayana number. ", "page_idx": 4}, {"type": "text", "text": "The proof of Theorem 2 is provided in Appendix C.2. Similar experimental validations are conducted to verify Theorem 2, with results also presented in Appendix C. The main insight from Theorem 2 is that training models on a randomly selected data subset offers a better trade-off between sharpness and diversity compared to training on the complete dataset. This idea is further illustrated in Figure 1b, where we compare the sharpness upper bound and diversity of models trained on the full dataset (labeled as SAM) and those trained on subsets (labeled as SharpBalance). The results demonstrate that SharpBalance achieves a more favorable trade-off. For a given level of sharpness, deep ensembles with models trained on subsets of the data exhibit higher diversity compared to those trained on the entire dataset. This indicates that minimizing sharpness on randomly sampled data subsets for each model within the ensemble promotes the diversity among the models, thereby enhancing the sharpness-diversity trade-off. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we describe our experiments. In particular, following Section 4.1 where we describe our experimental setup, in Section 4.2, we provide an empirical evaluation across various datasets to explore the trade-off between sharpness and diversity. We also examine how this trade-off changes with different levels of overparameterization. Then, in Section 4.3 and 4.4, we elaborate the SharpBalance algorithm and compare its performance with baseline methods. ", "page_idx": 5}, {"type": "text", "text": "4.1 Experimental setup ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Here, we describe the experiment setup for Section 4.2. Each ensemble member is trained individually using SAM with a consistent perturbation radius $\\rho$ , as defined in equation (5). We adjust $\\rho$ across different ensembles to achieve varying levels of minimized sharpness. Sharpness for each NN was measured using the adaptive worst-case sharpness metric, defined in equation (3). The sharpness measurement was done on the training set, using 100 batches of size 5. The diversity between NNs is measured using DER defined in equation (2). The diversity between ensemble members is tested on OOD data. We evaluated this trade-off using a variety of image classification datasets, including CIFAR-10, CIFAR-100 [Krizhevsky, 2009], TinyImageNet [Le and Yang, 2015], and their corrupted versions [Hendrycks and Dietterich, 2019b]. For the setup of Section 4.4, we used the same datasets and architecture. The hyperparameters of the baseline methods has been carefully tuned. The hyperparameters for conducting the experiments are detailed in Appendix D. ", "page_idx": 5}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/fc1b092337ba4a028d7f6841c5e4fd73dc9122a8d877f7ac0afa0368d319d7c3.jpg", "img_caption": ["(a) Measuring diversity via Variance (b) Measuring diversity via DER (c) Measuring diversity via KL "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 3: (Varying diversity measure in empirical study). Three different metrics are employed to measure the diversity of individual models within an ensemble, i.e., Variance in equation (1), DER in equation (2), and KL divergence in equation (11). The results of the three metrics show consistent trends, demonstrating the sharpness-diversity trade-off: lower sharpness is correlated with lower diversity. The experiment is conducted by training a three-member ResNet18 ensemble on CIFAR10. ", "page_idx": 5}, {"type": "text", "text": "4.2 Empirical validation of Sharpness-diversity trade-off ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We provide empirical observation to validate and explore the sharpness-diversity trade-off. Figure 3 presents the validation of observing the trade-off phenomenon on training ResNet18 ensembles on CIFAR10 applying three different metrics to measure the diversity. The results demonstrate that this trade-off phenomenon generalizes to the three diversity metrics defined in Section 2. Figure 4 presents the validation on three different datasets. In the following empirical study, DER will be the primary metric for measuring diversity of models. ", "page_idx": 5}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/7c9f5585fb37beffa056946bba46a86bd9bcecf57d5e663a240c1b8ac462cb32.jpg", "img_caption": ["Figure 4: (Empirical observations of sharpness-diversity trade-off). The identified trade-off shows that while reducing sharpness enhances individual model performance, it concurrently lowers diversity and thus diminishes the ensemble improvement rate. First row: the color encoding represents the ensemble improvement rate (EIR) defined in equation (4), from red to blue means ensembling improvement decreases. Second row: the color encoding represents the individual ensemble member\u2019s OOD accuracy, from blue to red means individual performance becomes better. Each marker represents a three-member ResNet18 ensemble trained with SAM with a different perturbation radius. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Experimental results obtained with the other two metrics are available in Appendix E. The three sets of results first verify that minimizing individual member\u2019s sharpness indeed reduces diversity. This is confirmed by the consistent trends of markers moving from upper right to lower left. Second, the first row of Figure 4 shows that an ensemble with decreased diversity (lower in $y$ -axis) shows a lower ensemble improvement rate (from red to blue), highlighting the negative impact of this trade-off. Lastly, the second row shows when the sharpness of the individual model is reduced (lower in $x$ -axis), the individual model\u2019s OOD accuracy is improved (from blue to red), demonstrating the benefits of minimizing sharpness. We verify the robustness of the phenomenon by measuring the sharpness and diversity using different metrics in Appendix E. ", "page_idx": 6}, {"type": "text", "text": "Figure 5 illustrates the trade-off curves as the overparameterization level of the model is adjusted by changing width or sparsity (introduced using model pruning). This visualization confirms that the trade-off is a consistent phenomenon across models of different sizes, and the ensemble provides less improvement (blue color) at the lower left end of each trade-off curve. It also highlights that models with smaller or sparser configurations show a more significant trade-off effect, as evidenced by the steeper slopes and higher coefficient values of the linear fitting curves. As sparse ensembles are now being used to demonstrate the benefits of ensembling for efficient models [Liu et al., 2022, Diffenderfer et al., 2021, Whitaker and Whitley, 2022, Kobayashi et al., 2022, Zimmer et al., 2024], addressing the conflict between sharpness and diversity becomes particularly crucial. ", "page_idx": 6}, {"type": "text", "text": "4.3 Our SharpBalance method ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Here, we describe the design and implementation of our main method, SharpBalance. Figure 6 provides an overview. Our approach is motivated by the theoretical analysis in Section 3, which suggests that having each ensemble member minimize sharpness on diverse subsets of the data can lead to a better trade-off between sharpness and diversity. SharpBalance aims to achieve the optimal balance by applying SAM to a carefully selected subset of the data, while performing standard optimization on the remaining samples. More specifically, for each ensemble member NN $f_{\\pmb{\\theta}_{i}}$ , our method divides the entire training dataset $\\mathcal{D}$ into two distinct subsets: sharpness-aware set $\\mathcal{D}_{\\mathrm{SAM}}^{i}$ and normal set $\\mathcal{D}_{\\mathrm{Normal}}^{i}$ . The model is trained to optimize the sharpness reduction objective on $\\mathcal{D}_{\\mathrm{SAM}}^{i}$ , ", "page_idx": 6}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/e9fa0464f2555bed290cf719b9e6cfbf8e48a2a94ac8ab1353a253ebb803bd16.jpg", "img_caption": ["(a) Varying model width "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/3f2ee67cf5afeb1f86bdcc10d636c2d3d1cef7eb15c7a798b20c2391b0f6eaa9.jpg", "img_caption": ["(b) Varying model sparsity "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 5: (Sharpness-diversity trade-off in models varying overparameterization levels). Different types of markers represent models with varying degrees of overparameterization, determined by changing the model width (a) or sparsity (b). Each marker represents a three-member ensemble trained with SAM with a different perturbation radius. The $\\beta$ reflects the rate of decline in the trade-off curve, calculated via applying linear fitting over the ensembles at each level of overparameterization. A higher $\\beta$ points to a steeper decline in the trade-off. Ensembles with narrower widths or increased sparsity display more pronounced trade-off effects. The model used in ResNet18 and the dataset is CIFAR-10. ", "page_idx": 7}, {"type": "text", "text": "while it optimizes the normal training objective on $\\mathcal{D}_{\\mathrm{Normal}}^{i}$ . These training objectives are denoted as ${\\mathcal L}_{\\mathcal D_{\\mathrm{SAM}}^{i}}^{\\mathrm{SAM}}(\\pmb\\theta_{i})$ and ${\\mathcal L}_{{\\mathcal D}_{\\mathrm{Normal}}^{i}}(\\pmb\\theta_{i})$ , respectively. The $\\mathcal{D}_{\\mathrm{SAM}}^{i}$ is selected by an adaptive strategy from the whole dataset $\\mathcal{D}$ : it is composed of the union of samples that are deemed \u201csharp\u201d by all other members of the ensemble except the $i$ -th. Specifically, for each model, we pick the subset of data samples with the top- $k\\%$ highest \u201cper-data-sample sharpness.\u201d Then, we take the union of all such subsets expect the $i$ -th for creating the subset $\\bar{D_{\\mathrm{SAM}}^{i^{-}}}$ . This partition of data samples can be efficiently computed in parallel as there is no sequential dependency on the training of the ensemble members. However, SharpBalance can be easily adapted for sequential training if memory constraints permit training only one model at a time. ", "page_idx": 7}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/1427fd3899af0062957e92aa0d7c83908ecf43fd0e9cd928aa1a82857faae3dc.jpg", "img_caption": ["Figure 6: (System diagram of SharpBalance). Each ensemble member $f_{\\pmb{\\theta}_{i}}$ optimizes the sharpness reduction objective on subset $\\mathcal{D}_{\\mathrm{SAM}}^{i}$ and the normal training objective on $\\mathcal{D}_{\\mathrm{Normal}}^{i}$ . DiSAM is formed by selecting data samples from $\\mathcal{D}$ that significantly affect the loss landscape sharpness of other ensemble members. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Per-data-sample sharpness. This metric is designed to efficiently assess the sharpness of a model for individual data samples. For each data point $(x_{j},y_{j})$ , sharpness is quantified using the Fisher Information Matrix (FIM), which is expressed as $\\bar{\\nabla_{\\pmb{\\theta}}}\\ell(\\bar{f}_{\\pmb{\\theta}}(\\pmb{x}_{j}),\\pmb{y}_{j})\\nabla_{\\pmb{\\theta}}\\ell(f_{\\pmb{\\theta}}(\\pmb{x}_{j}),\\pmb{y}_{j})^{T}$ . Following a well-established approach [Bottou et al., 2018], we approximate the trace of the FIM by computing the squared $\\ell_{2}$ norm of the gradient: $\\|\\nabla_{\\pmb{\\theta}}\\ell(f_{\\pmb{\\theta}}(\\pmb{x}_{j}),\\pmb{y}_{j}^{\\top})\\|_{2}^{2}$ . Other common sharpness metrics, such as worst-case sharpness, trace of the Hessian, or Hessian eigenvalues, are computationally slightly more expensive to approximate [Yao et al., 2020, 2021], but are expected to lead to similar results. ", "page_idx": 7}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/0eb1639c3d829c7b1dd6028ec9494bb9d431854a77e19864187505e4ab94b02b.jpg", "img_caption": ["Figure 7: (Main results: SharpBalance improves the overall ensembling performance and mitigates the reduced ensembling improvement caused by sharpness-diversity trade-off). The three-member ResNet18 ensemble is trained with different methods on three datasets. The first row reports the OOD accuracy and the second row reports the ID accuracy. The lower part of each bar with the diagonal lines represents the individual model performance. The upper part of each bar represents the ensembling improvement. The results are reported by averaging three ensembles, and each ensemble is comprised of three models. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "We evaluate SharpBalance by benchmarking it against both a standard Deep Ensemble, trained using SGD, and a Deep Ensemble enhanced with SAM. The results are presented in Figure 7 for CIFAR-10, CIFAR-100, and TinyImageNet. The comparison between the middle and left bars shows that SAM enhances individual model performance by reducing sharpness. However, this reduction in sharpness also diminishes the overall ensemble effectiveness by lowering diversity, exemplifying the sharpness-diversity trade-off discussed in Section 4.2. Further comparison between the right and middle bars shows that SharpBalance maintains or improves individual performance while improving ensemble effectiveness. ", "page_idx": 8}, {"type": "text", "text": "We also evaluate SharpBalance on different ensemble sizes. As shown in Figure 8, SharpBalance demonstrates more pronounced empirical improvements as the number of ensemble models increases. The accuracy difference between SharpBalance and the baseline methods becomes more significant, especially on corrupted data. Specifically, SharpBalance outperforms the baselines by up to $1.30\\%$ when ensembling 5 models on CIFAR100-C dataset. ", "page_idx": 8}, {"type": "text", "text": "To further evaluate SharpBalance, we provide corroborating results in Appendix F, which includes: ", "page_idx": 8}, {"type": "text", "text": "\u2022 We evaluate SharpBalance on different severity of the corruption on CIFAR10-C, CIFAR100-C and Tiny-ImageNet-C. SharpBalance increasingly outperforms the baselines as the severity of the corruption increases. We also evaluate the proposed method using uncertainty metrics such as negative log-likelihood and expected calibration error.   \n\u2022 We further evaluate SharpBalance on other model architectures and tasks, such as WideResNet, ViT, and ALBERT [Lan et al., 2020] on language tasks.   \n\u2022 We compare our method of measuring sharpness with another method of measuring the curvature of the loss around a data point [Garg and Roy, 2023] and show the strong correlation between these two methods.   \n\u2022 We further compare SharpBalance with ensemble baseline EoA [Arpit et al., 2022], an improved version of SAM (for which individual models in an ensemble are trained with different $\\rho$ values) and GSAM [Zhuang et al., 2022]. Results show that SharpBalance can significantly outperform the baselines. ", "page_idx": 8}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/ed04eecfc36890e3d1acd7617afee9427c5b02cffd78064b62462d7c340b056b.jpg", "img_caption": ["Figure 8: SharpBalance achieves more pronounced improvement when increasing the number of ensembling models. \"EIR\" represents the ensemble inprovement rate, which is defined in Section 2, the larger the better. $x$ -axis represents the number of individual models in one ensemble. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "\u2022 We demonstrate that, compared to training a deep ensemble with SAM, our method adds only minimal computational cost. The extra time complexity is dominated by the computation of Fisher trace for evaluating per-sample sharpness, which empirically increases the training time by $1\\%$ . ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our theoretical and empirical analyses demonstrate the existence of a sharpness-diversity trade-off when sharpness-minimization training methods are applied to deep ensembles. This leads to two main insights that are relevant for improving model performance. First, reducing the sharpness in individual models proves to be beneficial in enhancing the performance of the ensemble as a whole. Second, the accompanying reduction in diversity suggests that popular ensembling methods have limitations, and also highlights the potential for more sophisticated designs that promote diversity among models with lower sharpness. These results are particularly timely, given recent theoretical work on characterizing ensemble improvement [Theisen et al., 2023]. In response to these findings, we have proposed SharpBalance, which \u201cdiagnoses\u201d the training data by evaluating the sharpness of each sample and then fine-tunes the training of individual models to focus on a diverse subset of the sharpest training data samples. This targeted approach helps maintain diversity among models while also reducing their individual sharpness. Extensive evaluations indicate that SharpBalance not only improves the sharpness-diversity trade-off but also delivers superior OOD performance for both dense and sparse models across various datasets and architectures when compared to other ensembling approaches. ", "page_idx": 9}, {"type": "text", "text": "Limitations. One limitation of the study is that our theoretical analysis in Section 3 relies on the assumption that the data matrices A, T follow a Gaussian distribution and assumed the optimization objective to be quadratic, which may not always hold in practice. Despite the potentially strong assumptions, our empirical findings in Section 4 show that the conclusions remain robust in real-world datasets with various model architectures. This suggests the insights discovered in our study are applicable to a wider range of real-world scenarios, beyond just those strictly adhering to the Gaussian assumption. Nevertheless, future research could explore how such assumptions can be relaxed and extend the theoretical analysis to a weaker condition. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements. Michael W. Mahoney would like to acknowledge the UC Berkeley CLTC, ARO, IARPA (contract W911NF20C0035), NSF, and ONR for providing partial support of this work. Kurt Keutzer would like to acknowledge support from Berkeley Deep Drive. Yaoqing Yang would like to acknowledge support from DOE under Award Number DE-SC0025584, DARPA under Agreement number HR00112490441, and Dartmouth College. Our conclusions do not necessarily reflect the position or the policy of our sponsors, and no official endorsement should be inferred. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Maksym Andriushchenko, Francesco Croce, Maximilian Mueller, Matthias Hein, and Nicolas Flammarion. A modern look at the relationship between sharpness and generalization. In International Conference on Machine Learning, 2023.   \nDevansh Arpit, Huan Wang, Yingbo Zhou, and Caiming Xiong. Ensemble of averages: Improving model selection and boosting performance in domain generalization. Advances in Neural Information Processing Systems, 2022.   \nChristina Baek, Yiding Jiang, Aditi Raghunathan, and J Zico Kolter. Agreement-on-the-line: Predicting the performance of neural networks under distribution shift. Advances in Neural Information Processing Systems, 35:19274\u201319289, 2022.   \nKayhan Behdin and Rahul Mazumder. On statistical properties of sharpness-aware minimization: Provable guarantees. arXiv preprint arXiv:2302.11836, 2023.   \nAdrian N Bishop, Pierre Del Moral, Ang\u00e8le Niclas, et al. An introduction to wishart matrix moments. Foundations and Trends\u00ae in Machine Learning, 11(2):97\u2013218, 2018.   \nL\u00e9on Bottou, Frank E Curtis, and Jorge Nocedal. Optimization methods for large-scale machine learning. SIAM review, 60(2):223\u2013311, 2018.   \nLeo Breiman. Random forests. Machine learning, 45(1):5\u201332, 2001.   \nAnh Bui, Vy Vo, Tung Pham, Dinh Phung, and Trung Le. Diversity-aware agnostic ensemble of sharpness minimizers. arXiv preprint arXiv:2403.13204, 2024.   \nJunbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, and Sungrae Park. Swad: Domain generalization by seeking flat minima. Advances in Neural Information Processing Systems, 34:22405\u201322418, 2021.   \nTianqi Chen and Carlos Guestrin. Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785\u2013794, 2016.   \nThomas G Dietterich. Ensemble methods in machine learning. In International workshop on multiple classifier systems, pages 1\u201315. Springer, 2000.   \nJames Diffenderfer, Brian Bartoldson, Shreya Chaganti, Jize Zhang, and Bhavya Kailkhura. A winning hand: Compressing deep networks can improve out-of-distribution robustness. Advances in neural information processing systems, 34:664\u2013676, 2021.   \nLaurent Dinh, Razvan Pascanu, Samy Bengio, and Yoshua Bengio. Sharp minima can generalize for deep nets. In International Conference on Machine Learning, pages 1019\u20131028. PMLR, 2017.   \nJiawei Du, Hanshu Yan, Jiashi Feng, Joey Tianyi Zhou, Liangli Zhen, Rick Siow Mong Goh, and Vincent Tan. Efficient sharpness-aware minimization for improved training of neural networks. In International Conference on Learning Representations, 2024.   \nPierre Foret, Ariel Kleiner, Hossein Mobahi, and Behnam Neyshabur. Sharpness-aware minimization for efficiently improving generalization. In International Conference on Learning Representations, 2021.   \nStanislav Fort, Huiyi Hu, and Balaji Lakshminarayanan. Deep ensembles: A loss landscape perspective. arXiv preprint arXiv:1912.02757, 2019.   \nYoav Freund. Boosting a weak learning algorithm by majority. Information and computation, 121(2): 256\u2013285, 1995.   \nYoav Freund and Robert E Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. Journal of computer and system sciences, 55(1):119\u2013139, 1997.   \nMudasir A Ganaie, Minghui Hu, AK Malik, M Tanveer, and PN Suganthan. Ensemble deep learning: A review. Engineering Applications of Artificial Intelligence, 115:105151, 2022.   \nXiang Gao, Meera Sitharam, and Adrian E. Roitberg. Bounds on the jensen gap, and implications for mean-concentrated distributions. The Australian Journal of Mathematical Analysis and Applications, 2019.   \nIsha Garg and Kaushik Roy. Samples with low loss curvature improve data efficiency. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 20290\u201320300, 2023.   \nKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \nDan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2019a.   \nDan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. In International Conference on Learning Representations, 2019b.   \nGeoffrey E. Hinton and Drew van Camp. Keeping the neural networks simple by minimizing the description length of the weights. In Proceedings of the Sixth Annual Conference on Computational Learning Theory, 1993.   \nSepp Hochreiter and J\u00fcrgen Schmidhuber. Flat Minima. Neural Computation, 9(1):1\u201342, 1997.   \nPavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gordon Wilson. Averaging weights leads to wider optima and better generalization. In 34th Conference on Uncertainty in Artificial Intelligence 2018, UAI 2018, pages 876\u2013885. Association For Uncertainty in Artificial Intelligence (AUAI), 2018.   \nWeisen Jiang, Hansi Yang, Yu Zhang, and James Kwok. An adaptive policy to employ sharpnessaware minimization. In International Conference on Learning Representations, 2023.   \nYiding Jiang, Vaishnavh Nagarajan, Christina Baek, and J Zico Kolter. Assessing generalization of SGD via disagreement. In International Conference on Learning Representations, 2022.   \nJean Kaddour, Linqing Liu, Ricardo Silva, and Matt J Kusner. When do flat minima optimizers work? Advances in Neural Information Processing Systems, 35:16577\u201316595, 2022.   \nNitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. In International Conference on Learning Representations, 2016.   \nSosuke Kobayashi, Shun Kiyono, Jun Suzuki, and Kentaro Inui. Diverse lottery tickets boost ensemble from a single pretrained model. In Proceedings of BigScience Episode #5 \u2013 Workshop on Challenges & Perspectives in Creating Large Language Models, 2022.   \nAlex Krizhevsky. Learning multiple layers of features from tiny images. 2009.   \nS. Kullback and R. A. Leibler. On Information and Sufficiency. The Annals of Mathematical Statistics, 22(1):79 \u2013 86, 1951. doi: 10.1214/aoms/1177729694.   \nJungmin Kwon, Jeongseop Kim, Hyunseo Park, and In Kwon Choi. Asam: Adaptive sharpness-aware minimization for scale-invariant learning of deep neural networks. In International Conference on Machine Learning, pages 5905\u20135914. PMLR, 2021.   \nBalaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. Advances in neural information processing systems, 30, 2017.   \nZhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. Albert: A lite bert for self-supervised learning of language representations. In International Conference on Learning Representations, 2020. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Fran\u00e7ois Laviolette, Emilie Morvant, Liva Ralaivola, and Jean-Francis Roy. Risk upper bounds for general ensemble methods with an application to multiclass classification. Neurocomputing, 219: 15\u201325, 2017. ", "page_idx": 13}, {"type": "text", "text": "Ya Le and Xuan S. Yang. Tiny imagenet visual recognition challenge. 2015. ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Yoonho Lee, Huaxiu Yao, and Chelsea Finn. Diversify and disambiguate: Learning from underspecified data. In ICML 2022: Workshop on Spurious Correlations, Invariance and Stability, 2022.   \nShiwei Liu, Tianlong Chen, Zahra Atashgahi, Xiaohan Chen, Ghada Sokar, Elena Mocanu, Mykola Pechenizkiy, Zhangyang Wang, and Decebal Constantin Mocanu. Deep ensembling with no overhead for either training or testing: The all-round blessings of dynamic sparsity. In International Conference on Learning Representations, 2022.   \nAndres Masegosa. Learning under model misspecification: Applications to variational and ensemble methods. Advances in Neural Information Processing Systems, 33:5479\u20135491, 2020.   \nAlireza Mehrtash, Purang Abolmaesumi, Polina Golland, Tina Kapur, Demian Wassermann, and William Wells. Pep: Parameter ensembling by perturbation. Advances in neural information processing systems, 33:8895\u20138906, 2020.   \nJishnu Mukhoti, Andreas Kirsch, Joost van Amersfoort, Philip HS Torr, and Yarin Gal. Deterministic neural networks with appropriate inductive biases capture epistemic and aleatoric uncertainty. arXiv preprint arXiv:2102.11582, 2021.   \nBehnam Neyshabur, Srinadh Bhojanapalli, and Nathan Srebro. A PAC-bayesian approach to spectrally-normalized margin bounds for neural networks. In International Conference on Learning Representations, 2018.   \nLuis A Ortega, Rafael Caba\u00f1as, and Andres Masegosa. Diversity and generalization in neural network ensembles. In International Conference on Artificial Intelligence and Statistics, pages 11720\u201311743. PMLR, 2022.   \nYaniv Ovadia, Emily Fertig, Jie Ren, Zachary Nado, David Sculley, Sebastian Nowozin, Joshua Dillon, Balaji Lakshminarayanan, and Jasper Snoek. Can you trust your model\u2019s uncertainty? evaluating predictive uncertainty under dataset shift. Advances in neural information processing systems, 32, 2019.   \nTianyu Pang, Kun Xu, Chao Du, Ning Chen, and Jun Zhu. Improving adversarial robustness via promoting ensemble diversity. In International Conference on Machine Learning, pages 4970\u20134979. PMLR, 2019.   \nJack Parker-Holder, Luke Metz, Cinjon Resnick, Hengyuan Hu, Adam Lerer, Alistair Letcher, Alexander Peysakhovich, Aldo Pacchiano, and Jakob Foerster. Ridge rider: Finding diverse solutions by following eigenvectors of the hessian. Advances in Neural Information Processing Systems, 33:753\u2013765, 2020.   \nAlexandre Rame, Matthieu Kirchmeyer, Thibaud Rahier, Alain Rakotomamonjy, Patrick Gallinari, and Matthieu Cord. Diverse weight averaging for out-of-distribution generalization. Advances in Neural Information Processing Systems, 35:10821\u201310836, 2022.   \nRyan Theisen, Hyunsuk Kim, Yaoqing Yang, Liam Hodgkinson, and Michael W Mahoney. When are ensembles really effective? Advances in neural information processing systems, 2023.   \nGiorgio Valentini and Thomas G Dietterich. Low bias bagged support vector machines. In Proceedings of the 20th International Conference on Machine Learning (ICML-03), pages 752\u2013759, 2003.   \nRoman Vershynin. High-Dimensional Probability: An Introduction with Applications in Data Science. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, 2018.   \nTim Whitaker and Darrell Whitley. Prune and tune ensembles: low-cost ensemble learning with sparse independent subnetworks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 8638\u20138646, 2022.   \nYaoqing Yang, Liam Hodgkinson, Ryan Theisen, Joe Zou, Joseph E Gonzalez, Kannan Ramchandran, and Michael W Mahoney. Taxonomizing local versus global structure in neural network loss landscapes. Advances in Neural Information Processing Systems, 34:18722\u201318733, 2021.   \nZhewei Yao, Amir Gholami, Qi Lei, Kurt Keutzer, and Michael W Mahoney. Hessian-based analysis of large batch training and robustness to adversaries. Advances in Neural Information Processing Systems, 31, 2018.   \nZhewei Yao, Amir Gholami, Kurt Keutzer, and Michael W Mahoney. Pyhessian: Neural networks through the lens of the hessian. In 2020 IEEE international conference on big data (Big data), pages 581\u2013590. IEEE, 2020.   \nZhewei Yao, Amir Gholami, Sheng Shen, Mustafa Mustafa, Kurt Keutzer, and Michael Mahoney. Adahessian: An adaptive second order optimizer for machine learning. In proceedings of the AAAI conference on artificial intelligence, volume 35, pages 10665\u201310673, 2021.   \nJuntang Zhuang, Boqing Gong, Liangzhe Yuan, Yin Cui, Hartwig Adam, Nicha C Dvornek, James s Duncan, Ting Liu, et al. Surrogate gap minimization improves sharpness-aware training. In International Conference on Learning Representations, 2022.   \nMax Zimmer, Christoph Spiegel, and Sebastian Pokutta. Sparse model soups: A recipe for improved pruning via model averaging. In International Conference on Learning Representations, 2024. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A Impact Statement ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "This paper uncovers a trade-off between sharpness and diversity in deep ensembles and introduces a novel training strategy to achieve an optimal balance between these two crucial metrics. While the proposed method could potentially be misused for malicious purposes, we believe that the study itself does not pose any direct negative societal impact. More importantly, this research advances the field of ensemble learning and contribute to the development of more reliable deep ensemble models. These advancements consequently result in enhanced robustness when dealing with OOD data and enable the quantification of uncertainty, thereby strengthening the reliability and applicability of deep learning systems in real-world scenarios. ", "page_idx": 15}, {"type": "text", "text": "B Related work ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Ensembling. Diversity is one of the major factors that contribute to the success of the ensembling method. Popular ensemble techniques have been developed for tree-type individual learners, which are known to have a high variance. This is evident such as in [Breiman, 2001, Chen and Guestrin, 2016, Freund, 1995, Freund and Schapire, 1997]. In contrast, more stable algorithms, such as support vector machines (SVM) type learners, are less commonly used for ensembles, unless they are tuned to a low-bias, high-variance regime, as explored in [Valentini and Dietterich, 2003]. When it comes to diversity and ensembling, NNs are known to exhibit properties different than traditional models, e.g., as described in recent theoretical and empirical work on loss landscapes and emsemble improvement [Theisen et al., 2023, Yang et al., 2021]. Therefore, ensembling techniques that work well for traditional models (e.g., tree-type models) often underperform the simple yet efficient deep ensembles method [Fort et al., 2019, Ortega et al., 2022] that uses the independent initialization and optimization. Previous literature has explored various new methods to learn diverse NNs [Lee et al., 2022, Rame et al., 2022, Pang et al., 2019, Parker-Holder et al., 2020]. Our work is different from previous work in that we study flat ensembles obtained from sharpness-aware training methods, especially focusing on diversifying flat ensembles by reducing the overlap between sharpness-aware data subsets. While our work demonstrates significant improvements in OOD generalization, it is known that (in some cases, see also Theisen et al. [2023]) deep ensembling is a simple, yet effective method to improve OOD performance [Diffenderfer et al., 2021]. Therefore, we compare the OOD performance of SharpBalance to deep ensembles. ", "page_idx": 15}, {"type": "text", "text": "Sharpness and generalization. A large body of work has studied the relationship between the sharpness (or flatness) of minima and the generalizability of models [Hochreiter and Schmidhuber, 1997, Hinton and van Camp, 1993, Keskar et al., 2016, Neyshabur et al., 2018, Yang et al., 2021, Kaddour et al., 2022, Yao et al., 2021, 2020]. Works such as those by [Hochreiter and Schmidhuber, 1997] and [Hinton and van Camp, 1993] use Bayesian learning and minimum description length to explain why we should train models to flat minima. [Keskar et al., 2016] introduces a sharpness-based metric, demonstrating how large-batch training can skew NNs towards sharp local minima, adversely affecting generalization. In addition, [Neyshabur et al., 2018] uses a PAC-Bayesian framework to prove bounds on generalization, which can be interpreted as the relationship between sharpness and test accuracy. Furthermore, [Cha et al., 2021] presents a theoretical exploration of the link between the sharpness of minima and OOD generalization. ", "page_idx": 15}, {"type": "text", "text": "Motivated by the good generalization property of flat minima, variants of sharpness-guided optimization techniques have been proposed [Yao et al., 2018, 2021, Du et al., 2024, Jiang et al., 2023], including sharpness-aware minimization [Foret et al., 2021]. The DiWA method [Rame et al., 2022] observed that SAM can decrease the diversity of models in the context of weight averaging (WA) [Izmailov et al., 2018]. However, WA imposes constraints on different models, requiring them to share the same initialization and stay close to each other in the parameter space. In contrast, our work focuses on deep ensembles that do not pose additional constraints on the training trajectories of individual ensemble members. Previous work by [Behdin and Mazumder, 2023] provided a theoretical characterization of important statistical properties for kernel regression models and single-layer ReLU networks, optimized using SAM on noisy datasets. Our theoretical analysis borrows ideas from [Behdin and Mazumder, 2023] and extends the analysis using random matrix theory. DASH was proposed in [Bui et al., 2024] to minimize the generalization loss by adding KL divergence constraint on the output logits of ensemble members. The authors believe that the decrease in diversity is a result of models being initialized closely and updated with the same direction. In contrast, SharpBalance observed that the sharpness-diversity trade-off is ubiquitous across various settings and provides a rigorous theoretical quantification that characterizes the interplay of the two metrics. Compare to DASH, SharpBalance provably achieves improved performance and is simple, effective, and computationally cheap to implement. ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "C Proof of Theorems in Section 3 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Recall that SAM updates the model weights, ignoring the normalization constant and regularization, through the following recursive rule ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\pmb{\\theta}_{k+1}^{S A M}=\\pmb{\\theta}_{k}^{S A M}-\\eta\\nabla f\\left(\\pmb{\\theta}_{k}^{S A M}+\\rho\\nabla f(\\pmb{\\theta}_{k}^{S A M})\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We first show an unrolling of the iterative optimization on a quadratic objective. ", "page_idx": 16}, {"type": "text", "text": "Theorem 3 (Unrolling SAM). Let $\\theta^{*}$ be the teacher model. Let $\\theta_{0}$ be randomly initialized and updated with SAM to solve a quadratic objective $\\begin{array}{r}{\\mathcal{L}_{\\mathbf{A}}(\\pmb{\\theta})=\\frac{1}{2}(\\pmb{\\theta}-\\pmb{\\theta}^{*})^{T}\\mathbf{A}^{T}\\mathbf{A}(\\pmb{\\theta}-\\mathbf{\\dot{\\theta}}^{*})}\\end{array}$ . Then, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\pmb{\\theta}_{k+1}^{S A M}=\\eta\\sum_{i=0}^{k}\\mathbf{B}^{i}\\left(\\mathbf{A}^{T}\\mathbf{A}+\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2}\\right)\\pmb{\\theta}^{*}+\\mathbf{B}^{k+1}\\pmb{\\theta}_{0},}\\\\ &{\\mathbf{A}-\\eta\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathbf{B}=\\mathbf{I}-\\eta\\mathbf{A}^{T}\\mathbf{A}-\\eta\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2}$ ", "page_idx": 16}, {"type": "text", "text": "Proof. The gradient of the objective $f$ is given by $\\nabla f(\\pmb\\theta)=\\mathbf{A}^{T}\\mathbf{A}(\\pmb\\theta-\\pmb\\theta^{*})$ . Therefore, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\pmb{\\theta}_{k}^{S A M}+\\rho\\nabla f(\\pmb{\\theta}_{k}^{S A M})=(\\mathbf{I}+\\rho\\mathbf{A}^{T}\\mathbf{A})\\pmb{\\theta}_{k}^{S A M}-\\rho\\mathbf{A}^{T}\\mathbf{A}\\pmb{\\theta}^{*}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "With SAM update, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\theta_{k+1}^{S A M}=\\theta_{k}^{S A M}-\\eta\\nabla f\\left(\\theta_{k}^{S A M}+\\rho\\nabla f(\\theta_{k}^{S A M})\\right)}\\\\ &{\\quad\\quad=\\theta_{k}^{S A M}-\\eta\\mathbf{A}^{T}\\mathbf{A}\\left(\\theta_{k}^{S A M}+\\rho\\nabla f(\\theta_{k}^{S A M})-\\theta^{*}\\right)}\\\\ &{\\quad\\quad=\\theta_{k}^{S A M}-\\eta\\mathbf{A}^{T}\\mathbf{A}\\left((\\mathbf{I}+\\rho\\mathbf{A}^{T}\\mathbf{A})\\theta_{k}^{S A M}-\\rho\\mathbf{A}^{T}\\mathbf{A}\\theta^{*}-\\theta^{*}\\right)}\\\\ &{\\quad\\quad=\\left(\\mathbf{I}-\\eta\\mathbf{A}^{T}\\mathbf{A}-\\eta\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2}\\right)\\theta_{k}^{S A M}+\\eta\\left(\\mathbf{A}^{T}\\mathbf{A}+\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2}\\right)\\theta^{*}}\\\\ &{\\quad\\quad=\\eta\\displaystyle\\sum_{i=0}^{k}\\mathbf{B}^{i}\\left(\\mathbf{A}^{T}\\mathbf{A}+\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2}\\right)\\theta^{*}+\\mathbf{B}^{k+1}\\theta_{0},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last equation is obtained by recursively unrolling the weight by previous updates. ", "page_idx": 16}, {"type": "text", "text": "Theorem 3 offers a valuable tool to analyze the statistical behavior of the models optimized by SAM. However, one more ingredient is required to arrive at the interesting conclusions claimed in Section 3, the random matrix theory. Recall that the data matrix $\\mathbf{A}\\in\\mathbb{R}^{n_{\\mathrm{tr}}\\times\\breve{d}_{\\mathrm{in}}}$ is random with entries drawn from Gaussian $\\mathcal{N}(0,\\mathbf{I}/d_{\\mathrm{in}})$ . As a result, entries in $\\mathbf{A}^{T}\\mathbf{A}$ follows the Wishart distribution and according to Corollary 3.3 in Bishop et al. [2018], for $k\\geq1$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[(\\mathbf{A}^{T}\\mathbf{A})^{k}]=\\left(\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}\\right)^{k}\\sum_{i=1}^{k}\\left(\\frac{d_{\\mathrm{in}}}{n_{\\mathrm{tr}}}\\right)^{k-i}\\mathcal{O}\\left(1+1/d_{\\mathrm{in}}\\right)N_{k,i}\\mathbf{I},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\begin{array}{r}{N_{k,i}=\\frac{1}{i}\\binom{k-1}{i-1}\\binom{k}{i-1}}\\end{array}$ is the Narayana number. With the help of this Corollary, we now prove a proposition on the expectation of $\\mathbf{B}^{k}$ . ", "page_idx": 16}, {"type": "text", "text": "Proposition 1 (Expectation of Wishart Moments). Let $i,j$ be non-negative integers, then ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{A}}[\\mathbf{B}^{i}(\\mathbf{A}^{T}\\mathbf{A})^{j}]=\\phi(i,j)\\mathbf{I},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where ", "page_idx": 16}, {"type": "equation", "text": "$$\nb(i,j):=\\!\\!1_{j=0}+\\sum_{k_{1}+k_{2}+k_{3}=i}\\frac{i!}{k_{1}!k_{2}!k_{3}!}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}\\left(\\frac{n_{t r}}{d_{i n}}\\right)^{m}\\sum_{l=1}^{m}\\left(\\frac{d_{i n}}{n_{t r}}\\right)^{m-l}\\mathcal{O}(1+1/d_{i n})N_{m,l},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and $m=k_{2}+2k_{3}+j$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. By Multinomial Theorem, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\mathbf B}^{i}({\\mathbf A}^{T}{\\mathbf A})^{j}=\\left(\\underset{k_{1}+k_{2}+k_{3}=i}{\\sum}\\frac{i!}{k_{1}!k_{2}!k_{3}!}{\\mathbf I}^{k_{1}}(-\\eta{\\mathbf A}^{T}{\\mathbf A})^{k_{2}}(-\\eta\\rho({\\mathbf A}^{T}{\\mathbf A})^{2})^{k_{3}}\\right)({\\mathbf A}^{T}{\\mathbf A})^{j}}\\\\ &{\\qquad\\qquad=\\underset{k_{1}+k_{2}+k_{3}=i}{\\sum}\\frac{i!}{k_{1}!k_{2}!k_{3}!}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}({\\mathbf A}^{T}{\\mathbf A})^{k_{2}+2k_{3}+j}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $m=k_{2}+2k_{3}+j$ and taking the expectation with equation (6) gives ", "page_idx": 17}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}{{\\boldsymbol{\\mathbb{\\Sigma}}}_{\\mathbf{A}}[{\\boldsymbol{\\mathbf{B}}}^{i}({\\mathbf{A}}^{T}\\mathbf{A})^{j}]=\\!\\!\\!\\sum_{k_{1}+k_{2}+k_{3}=i}{\\frac{i!}{k_{1}!k_{2}!k_{3}!}}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}{\\mathbb{E}}_{\\mathbf{A}}[({\\mathbf{A}}^{T}\\mathbf{A})^{k_{2}+2k_{3}+j}]}\\\\ {=\\!\\!\\!\\!\\displaystyle\\sum_{k_{1}+k_{2}+k_{3}=i}{\\frac{i!}{k_{1}!k_{2}!k_{3}!}}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}\\left({\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}\\right)^{m}\\sum_{l=1}^{m}\\left({\\frac{d_{\\mathrm{in}}}{n_{\\mathrm{tr}}}}\\right)^{m-l}{\\mathcal{O}}(1+1/d_{\\mathrm{in}})N_{m,l}\\mathbf{I}.}\\end{array}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "If $j=0$ , then there is a case when $k_{2}=k_{3}=0$ , and the expectation of $(\\mathbf{A}^{T}\\mathbf{A})^{0}$ simply becomes I. Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{\\bar{z}}_{\\mathbf{A}}[\\mathbf{B}^{i}(\\mathbf{A}^{T}\\mathbf{A})^{j}]=\\mathbb{1}_{j=0}\\mathbf{I}+\\displaystyle\\sum_{k_{1}+k_{2}+k_{3}=i}\\frac{i!}{k_{1}!k_{2}!k_{3}!}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}\\left(\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}\\right)^{m}\\sum_{l=1}^{m}\\left(\\frac{d_{\\mathrm{in}}}{n_{\\mathrm{tr}}}\\right)^{m-l}\\mathcal{O}(1+1/d_{\\mathrm{spar}})}\\\\ &{\\qquad\\qquad=\\phi(i,j)\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "C.1 Proof of Theorem 1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this subsection, we show a proof for Theorem 1. ", "page_idx": 17}, {"type": "text", "text": "Proof. Apply Singular Value Decomposition (SVD) to obtain ${\\bf A}={\\bf V}\\boldsymbol{\\Sigma}{\\bf U}^{T}$ and $\\mathbf{A}^{T}\\mathbf{A}=\\mathbf{U}\\boldsymbol{\\Sigma}^{2}\\mathbf{U}^{T}$ Let $\\mathbf{\\dot{D}}=\\mathbf{\\bar{\\Sigma}}^{2}$ . By Theorem 3, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta_{k}^{\\operatorname*{suf}}=\\frac{\\theta_{k}^{-1}}{\\tau_{k}^{\\operatorname*{suf}}}\\mathbf{B}^{\\prime}(\\mathbf{A}^{T}\\mathbf{A}+\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2})^{\\#}+\\mathbf{B}^{\\#}\\theta_{0}}\\\\ &{\\quad=\\eta\\sum_{i=0}^{K}\\left(\\mathbf{1}-\\eta\\mathbf{A}^{T}\\mathbf{A}-\\eta(\\theta(\\mathbf{A}^{T})\\mathbf{A})^{2}\\right)^{i}\\left(\\mathbf{A}^{T}\\mathbf{A}+\\rho(\\mathbf{A}^{T}\\mathbf{A})^{2}\\right)^{\\#}+\\mathbf{B}^{\\#}\\theta_{0}}\\\\ &{\\quad=\\frac{\\theta_{k}^{-1}}{\\tau_{k}^{\\operatorname*{suf}}}\\mathbf{(1-}\\eta\\mathbf{D}-\\eta\\theta(\\mathbf{D}^{T})\\nabla^{2}\\Pi^{\\mathrm{\\#}}\\nabla(\\mathbf{D}+\\rho)^{2}\\nabla^{T}\\theta^{\\star}+\\mathbf{B}^{\\#}\\theta_{0}}\\\\ &{\\quad=\\frac{\\eta\\sum_{i=0}^{K}\\mathbf{A}}{\\tau_{k}^{\\operatorname*{suf}}}\\left(-\\frac{\\Gamma(\\mathbf{1}-\\eta)\\mathbf{D}-\\eta(\\theta_{i})^{2}}{\\Gamma_{\\infty}^{2}(1-\\eta\\theta_{i})}-\\eta(\\rho_{k}^{2})^{4}\\right)_{j=1}^{\\theta_{0}}\\right)\\nabla^{T}\\theta^{\\star}+\\mathbf{B}^{\\#}\\theta_{0}}\\\\ &{\\quad=\\eta\\nabla\\cdot\\operatorname*{dim}_{\\theta}\\left(\\left\\{\\sum_{i=0}^{K}\\left(1-\\eta\\hat{d}_{i}-\\eta\\rho_{j}^{2}\\right)^{\\theta_{k}}\\left(\\mu_{j}+\\rho\\mu_{j}^{2}\\right)\\right\\}_{j=1}^{\\theta_{0}}\\right)\\nabla^{T}\\theta^{\\star}+\\mathbf{B}^{\\theta}\\theta_{0}}\\\\ &{\\quad=\\eta\\nabla\\cdot\\operatorname*{dim}_{\\theta}\\left(\\left\\{\\frac{1-(1-\\eta)\\hat{d}_{j}-\\eta\\rho_{j}^{2}\\}{\\eta\\hat{d}_{j}+\\eta\\rho_{j}^{2}}\\right\\}_{j=1}^{\\theta_{0}}\\right)\\Theta^{T}\\theta^{\\star}+\\frac{\\eta\\mathbf{A}}{\\\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "As a result, ${\\mathbb E}_{\\theta_{0}}[\\theta_{k}^{S A M}]=\\theta^{*}-\\left({\\bf I}-\\eta{\\bf A}^{T}{\\bf A}-\\eta\\rho({\\bf A}^{T}{\\bf A})^{2}\\right)^{k}\\theta^{*}=\\theta^{*}-{\\bf B}^{k}\\theta^{*}$ . By definition, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{m_{\\mathrm{p}}\\mathrm{Rin}^{2}\\big(\\theta_{k}^{\\mathrm{SAM}}\\big)=\\mathbb{E}_{\\boldsymbol{\\mathbf{A}},\\boldsymbol{\\mathbf{T}}}\\Bigg[\\sum_{i=1}^{N}\\big(\\mathbb{E}_{\\boldsymbol{\\mathbf{A}}}\\big)\\big[f\\big(\\theta_{k}^{\\mathrm{SAM}};\\boldsymbol{\\mathbf{T}}_{\\boldsymbol{\\mathbf{A}}}\\big)\\big]-y_{\\boldsymbol{\\mathbf{A}}}^{\\top}\\big)^{2}\\Bigg]}\\\\ &{=\\mathbb{E}_{\\boldsymbol{\\mathbf{A}},\\boldsymbol{\\mathbf{T}}}\\big[\\big(\\mathbb{E}_{\\boldsymbol{\\mathbf{A}}}\\big)\\big(\\delta_{\\boldsymbol{\\mathbf{A}}}^{\\mathrm{TAM}}\\big)-\\theta^{\\mathrm{op}}\\big]^{\\mathrm{T}}\\mathbf{T}^{\\mathrm{T}}\\mathbf{T}\\mathbf{T}\\big[\\mathbb{E}_{\\theta_{k}}\\big(\\theta_{k}^{\\mathrm{SAM}}\\big)-\\theta^{\\mathrm{op}}\\big]}\\\\ &{=\\mathbb{E}_{\\boldsymbol{\\mathbf{A}}}\\big[\\big(\\mathbb{E}_{\\boldsymbol{\\mathbf{A}}}\\big)\\big(\\delta_{\\boldsymbol{\\mathbf{A}}}^{\\mathrm{TAM}}\\big)-\\theta^{\\mathrm{op}}\\big]^{\\mathrm{T}}\\mathbf{E}_{\\boldsymbol{\\mathbf{T}}}\\big[\\mathbb{T}^{\\mathrm{T}}\\big]\\big(\\mathbb{E}_{\\theta_{k}}\\big(\\theta_{k}^{\\mathrm{SAM}}\\big)-\\theta^{\\mathrm{op}}\\big]}\\\\ &{=\\frac{m_{\\mathrm{p}}}{\\mu_{\\mathrm{d}}}\\mathbb{E}_{\\boldsymbol{\\mathbf{A}}}\\big[(\\theta^{\\mathrm{T}})^{\\mathrm{T}}\\mathbf{B}^{\\lambda}\\theta^{\\mathrm{r}}\\big]}\\\\ &{=\\frac{m_{\\mathrm{d}}}{\\mu_{\\mathrm{d}}}\\phi(2\\delta_{\\boldsymbol{\\mathbf{A}}})\\big\\|\\theta^{\\mathrm{T}}\\big\\|_{2}^{2},}\\\\ {m_{\\mathrm{p}}\\mathrm{Reror}(\\theta_{k}^{\\mathrm{SAM}})=\\mathbb{E}_{\\boldsymbol{\\mathbf{A}},\\boldsymbol{\\mathbf{T}}_{\\boldsymbol{\\mathbf{A}}}}\\Bigg[\\sum_{i=1}^{N}\\big(\\theta_{k}^{\\mathrm{SAM}};\\mathbb{T}\\big)^{2}\\big]}\\\\ &{=\\mathbb{E}_{\\boldsymbol{\\mathbf{A}},\\boldsymbol{\\mathbf{T}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since $\\begin{array}{r}{\\mathbb{E}_{\\mathbf{T}}[\\mathbf{T}^{T}\\mathbf{T}]={\\frac{n_{\\mathrm{tc}}}{d_{\\mathrm{in}}}}\\mathbf{I}}\\end{array}$ and $\\mathbb{E}[\\pmb{\\theta}_{0}\\pmb{\\theta}_{0}^{T}]=\\sigma^{2}\\mathbf{I}$ . Hence, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{D}(\\pmb{\\theta}_{k}^{S A M})=\\operatorname{Var}\\left(f(\\pmb{\\theta}_{k}^{S A M};\\mathbf{T})\\right)=\\frac{1}{n_{\\mathrm{te}}}\\left(n_{\\mathrm{te}}\\mathrm{Error}(\\pmb{\\theta}_{k}^{S A M})-n_{\\mathrm{te}}\\mathrm{Bias}^{2}(\\pmb{\\theta}_{k}^{S A M})\\right)=\\phi(2k,0)\\sigma^{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Recall that given a perturbation radius $\\rho_{0}$ , the sharpness is defined as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\kappa(\\pmb{\\theta}_{k})=\\mathbb{E}_{A}[\\operatorname*{max}_{\\|\\pmb{\\epsilon}\\|_{2}\\leq\\rho_{0}}f\\left(\\mathbb{E}_{\\pmb{\\theta}_{0}}\\left[\\pmb{\\theta}_{k}\\right]+\\pmb{\\varepsilon}\\right)-f\\left(\\mathbb{E}_{\\pmb{\\theta}_{0}}\\left[\\pmb{\\theta}_{k}\\right]\\right)].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We first compute ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f\\left(\\mathbb{E}_{\\theta_{0}}\\left[\\theta_{k}^{S A M}\\right]+\\varepsilon;\\mathbf{A}\\right)=\\frac{1}{2}(\\mathbb{E}_{\\theta_{0}}\\left[\\theta_{k}^{S A M}\\right]+\\varepsilon-\\theta^{*})^{T}A^{T}A(\\mathbb{E}_{\\theta_{0}}\\left[\\theta_{k}^{S A M}\\right]+\\varepsilon-\\theta^{*})}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\frac{1}{2}(\\varepsilon-\\mathbf{B}^{k}\\theta^{*})^{T}\\mathbf{A}^{T}\\mathbf{A}(\\varepsilon-\\mathbf{B}^{k}\\theta^{*})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{1}{2}\\varepsilon^{T}\\mathbf{A}^{T}\\mathbf{A}\\varepsilon-\\varepsilon^{T}\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\theta^{*}+\\frac{1}{2}(\\theta^{*})^{T}\\mathbf{B}^{2k}\\mathbf{A}^{T}\\mathbf{A}\\theta^{*}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Similarly, ", "page_idx": 18}, {"type": "equation", "text": "$$\nf\\left(\\mathbb{E}_{\\pmb{\\theta}_{0}}\\left[\\pmb{\\theta}_{k}^{S A M}\\right];\\mathbf{A}\\right)=\\frac{1}{2}(\\pmb{\\theta}^{*})^{T}\\mathbf{B}^{2k}\\mathbf{A}^{T}\\mathbf{A}\\pmb{\\theta}^{*}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $\\lambda_{m i n}$ be the least eigenvalue of $\\mathbf{A}^{T}\\mathbf{A}$ . By subtracting equation (7) with equation (8), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\kappa_{k}^{S A M}=\\mathbb{E}_{\\mathbf{A}}\\big[\\underset{\\|\\epsilon\\|_{2}\\leq\\rho_{0}}{\\operatorname*{max}}\\frac{1}{2}\\boldsymbol{\\varepsilon}^{T}\\mathbf{A}^{T}\\mathbf{A}\\boldsymbol{\\varepsilon}-\\boldsymbol{\\varepsilon}^{T}\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\boldsymbol{\\theta}^{*}\\big]}\\\\ &{\\quad\\quad\\geq\\mathbb{E}_{\\mathbf{A}}\\big[\\underset{\\|\\epsilon\\|_{2}\\leq\\rho_{0}}{\\operatorname*{max}}\\frac{1}{2}\\lambda_{m i n}\\|\\mathbf{U}^{T}\\boldsymbol{\\varepsilon}\\|_{2}^{2}-\\boldsymbol{\\varepsilon}^{T}\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\boldsymbol{\\theta}^{*}\\big]}\\\\ &{\\quad\\quad\\geq\\mathbb{E}_{\\mathbf{A}}\\big[\\underset{\\|\\epsilon\\|_{2}\\leq\\rho_{0}}{\\operatorname*{max}}\\frac{1}{2}\\lambda_{m i n}\\|\\mathbf{U}^{T}\\boldsymbol{\\varepsilon}\\|_{2}^{2}-\\boldsymbol{\\varepsilon}^{T}\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\boldsymbol{\\theta}^{*}\\big]}\\\\ &{\\quad\\quad\\quad\\quad\\in\\mathbb{E}_{\\mathbf{A}}}\\\\ &{\\quad\\quad=\\mathbb{E}_{\\mathbf{A}}\\big[\\underset{\\|\\epsilon\\|_{2}\\leq\\rho_{0}}{\\operatorname*{max}}\\frac{1}{2}\\lambda_{m i n}\\|\\mathbf{v}\\|_{2}^{2}-\\underset{\\|\\epsilon\\|_{2}\\leq\\rho_{0}}{\\operatorname*{min}}\\varepsilon^{T}\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\boldsymbol{\\theta}^{*}\\big]}\\\\ &{\\quad\\quad=\\mathbb{E}_{\\mathbf{A}}\\big[\\frac{1}{2}\\lambda_{m i n}\\rho_{0}^{2}+\\rho_{0}\\|\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\boldsymbol{\\theta}^{*}\\|_{2}\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The smallest singular value $\\lambda_{m i n}$ of a random $n\\times d_{\\mathrm{in}}$ matrix $\\mathbf{A}$ can be bounded by the following inequality on the smallest singular value $\\sigma_{m i n}(A)$ by Vershynin [2018], assuming $n_{\\mathrm{tr}}\\geq d_{\\mathrm{in}}$ , then almost surely ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{A}}[\\sigma_{m i n}(\\mathbf{A})]\\geq\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}-1.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, $\\begin{array}{r l r}{\\mathbb{E}_{A}[\\lambda_{m i n}]}&{\\ge}&{\\mathbb{E}_{A}[\\sigma_{m i n}(A)]^{2}\\;\\ge\\;\\left(\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}-1\\right)^{2}}\\end{array}$ . Now we show a lower bound on $\\mathbb{E}_{\\mathbf{A}}[\\rho_{0}\\,\\lVert\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\theta^{*}\\rVert_{2}]$ . By Gao et al. [2019], the Jensen gap $(\\mathbb{E}[Z])^{1/2}-\\mathbb{E}[(Z)^{1/2}]$ is upper bounded by $\\frac{\\mathrm{Var}(Z)}{2}$ when $Z$ is non-negative and $\\mathbb{E}[Z]=1$ . Notice that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{A}}[\\rho_{0}\\|\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\pmb{\\theta}^{*}\\|_{2}]=\\rho_{0}\\mathbb{E}_{\\mathbf{A}}[\\left((\\pmb{\\theta}^{*})^{T}\\mathbf{B}^{2k}(\\mathbf{A}^{T}\\mathbf{A})^{2}\\pmb{\\theta}^{*}\\right)^{1/2}],\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and we let $Z=(\\pmb{\\theta}^{*})^{T}\\mathbf{B}^{2k}(\\mathbf{A}^{T}\\mathbf{A})^{2}\\pmb{\\theta}^{*}$ . Then $\\mathbb{E}_{\\mathbf{A}}[Z]=\\phi(2k,2)\\lVert\\pmb{\\theta}^{*}\\rVert_{2}^{2}$ and ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{Var}[Z]=\\left(\\phi(4k,4)-\\phi(2k,2)^{2}\\right)\\|\\theta^{*}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By normalizing $Z$ and applying the Jensen gap upperbound, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{A}}[\\rho_{0}\\|\\mathbf{B}^{k}\\mathbf{A}^{T}\\mathbf{A}\\pmb{\\theta}^{*}\\|_{2}]\\ge\\rho_{0}\\sqrt{\\phi(2k,2)}\\|\\pmb{\\theta}^{*}\\|_{2}^{2}-\\frac{\\phi(4k,4)-\\phi(2k,2)^{2}}{2\\phi(2k,2)^{3/2}\\|\\pmb{\\theta}^{*}\\|_{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "As a result, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\kappa_{k}^{S A M}\\geq\\frac{\\rho_{0}^{2}}{2}\\left(\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}-1\\right)^{2}+\\rho_{0}\\sqrt{\\phi(2k,2)}\\|\\theta^{*}\\|_{2}-\\frac{\\phi(4k,4)-\\phi(2k,2)^{2}}{2\\phi(2k,2)^{3/2}\\|\\theta^{*}\\|_{2}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The derivation of the upper bound follows from a similar proof, ignoring the Jensen gap. ", "page_idx": 19}, {"type": "text", "text": "C.2 Proof of Theorem 2 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Below we show a proof of Theorem 2. ", "page_idx": 19}, {"type": "text", "text": "Proof. We apply SVD to $\\mathbf{A}_{s}$ to obtain ${\\bf A}_{s}={\\bf V}_{s}\\Sigma_{s}{\\bf U}_{s}^{T}$ and $\\mathbf{A}_{s}^{T}\\mathbf{A}=\\mathbf{U}_{s}\\Sigma_{s}^{2}\\mathbf{U}_{s}^{T}$ . Let $\\mathbf{D}_{s}=\\Sigma_{s}^{2}$ and $\\mathbf{B}_{s}=\\mathbf{I}-\\eta\\hat{\\mathbf{A}}_{s}^{\\mathcal{{T}}}\\mathbf{\\dot{A}}_{s}-\\eta\\rho(\\mathbf{A}_{s}^{T}\\mathbf{A}_{s})^{2}$ . By Theorem 3 and a similar derivation in the proof of Theorem 1, ", "page_idx": 19}, {"type": "text", "text": "As a result, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\theta_{k}^{S h a r p B a l}=\\eta\\sum_{j=0}^{k-1}\\mathbf{B}_{s}^{j}\\left(\\mathbf{A}_{s}^{T}\\mathbf{A}_{s}+\\rho(\\mathbf{A}_{s}^{T}\\mathbf{A}_{s})^{2}\\right)\\theta^{*}+\\mathbf{B}_{s}^{k}\\theta_{0}}\\\\ {\\displaystyle=\\theta^{*}+\\left(\\mathbf{I}-\\eta\\mathbf{A}_{s}^{T}\\mathbf{A}_{s}-\\eta\\rho(\\mathbf{A}_{s}^{T}\\mathbf{A}_{s})^{2}\\right)^{k}(\\theta_{0}-\\theta^{*}).}\\\\ {\\displaystyle_{),s}[\\theta_{k}^{S h a r p b a l}]=\\mathbb{E}_{s}[\\theta^{*}-\\mathbf{B}_{s}^{k}\\theta^{*}]=\\theta^{*}-\\frac{1}{S}\\sum_{s=1}^{S}\\mathbf{B}_{s}^{k}\\theta^{*}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Applying Proposition 1, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{A}}[\\mathbf{B}_{s}^{i}(\\mathbf{A}_{s}^{T}\\mathbf{A}_{s})^{j}]=\\phi^{\\prime}(i,j),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\phi^{\\prime}(i,j)=\\mathbb{1}_{j=0}+\\sum_{k_{1}+k_{2}+k_{3}=i}{\\frac{i!}{k_{1}!k_{2}!k_{3}!}}(-\\eta)^{k_{2}+k_{3}}\\rho^{k_{3}}\\left({\\frac{n_{\\mathrm{tr}}}{S d_{\\mathrm{in}}}}\\right)^{m}\\sum_{l=1}^{m}\\left({\\frac{S d_{\\mathrm{in}}}{n_{\\mathrm{tr}}}}\\right)^{m-l}N_{m,l}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{n_{\\mathrm{te}}\\mathrm{Bias}^{2}(\\theta_{k}^{S A M})=\\mathbb{E}_{\\mathbf{A},\\mathbf{T}}\\big[\\Big(\\mathbb{E}_{\\theta_{0},s}[\\theta_{k}^{S h a r p b a l}]-\\theta^{*}\\Big)^{T}\\mathbf{T}^{T}\\mathbf{T}\\big(\\mathbb{E}_{\\theta_{0},s}[\\theta_{k}^{S h a r p b a l}]-\\theta^{*}\\big)\\big]}\\\\ &{\\quad\\quad\\quad\\quad\\quad=\\frac{n_{\\mathrm{te}}}{d_{\\mathrm{in}}}\\mathbb{E}_{\\mathbf{A}}[(-\\displaystyle\\frac{1}{S}\\displaystyle\\sum_{s=1}^{S}\\mathbf{B}_{s}^{k}\\theta^{*})^{T}(-\\displaystyle\\frac{1}{S}\\displaystyle\\sum_{s^{\\prime}=1}^{S}\\mathbf{B}_{s^{\\prime}}^{k}\\theta^{*})]}\\\\ &{\\quad\\quad\\quad\\quad=\\frac{n_{\\mathrm{te}}}{d_{\\mathrm{in}}S^{2}}\\mathbb{E}_{\\mathbf{A}}[\\displaystyle\\sum_{s=1}^{S}\\mathbf{B}_{s}^{k}\\theta^{*}\\sum_{s^{\\prime}=1}^{S}\\mathbf{B}_{s^{\\prime}}^{k}]\\|\\theta^{*}\\|_{2}^{2}}\\\\ &{\\quad\\quad\\quad=\\frac{n_{\\mathrm{te}}}{d_{\\mathrm{in}}S}\\left(\\phi^{\\prime}(2k,0)+(s-1)\\phi^{\\prime}(k,0)^{2}\\right)\\|\\theta^{*}\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The last equality is the result of applying $\\mathbb{E}_{\\mathbf{A}}[B_{s}^{i}]=\\phi^{\\prime}(i,0)$ with different combinations of $\\mathbf{B}_{s},\\mathbf{B}_{s^{\\prime}}$ , counting multiplicity. Similarly, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{n_{\\mathrm{te}}\\mathrm{Error}(\\theta_{k}^{S h a r p b a l})=\\mathbb{E}_{\\mathbf{A},\\mathbf{T},\\theta_{0},s}[(\\theta^{*})^{T}\\mathbf{B}_{s}^{k}\\mathbf{T}^{T}\\mathbf{T}\\mathbf{B}_{s}^{k}\\theta^{*}]+\\mathbb{E}_{\\mathbf{A},\\mathbf{T},\\theta_{0},s}[\\theta_{0}^{T}\\mathbf{B}_{s}^{k}\\mathbf{T}^{T}\\mathbf{T}\\mathbf{B}_{s}^{k}\\theta_{0}]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{n_{\\mathrm{te}}}{d_{\\mathrm{in}}}\\phi^{\\prime}(2k,0)\\|\\theta^{*}\\|_{2}^{2}+n_{\\mathrm{te}}\\phi^{\\prime}(2k,0)\\sigma^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathrm{Var}\\left(f(\\theta_{k}^{S h a r p B a l};\\mathbf{T})\\right)=\\!\\frac{1}{n_{\\mathrm{te}}}\\left(n_{\\mathrm{te}}\\mathrm{Error}(\\theta_{k}^{S h a r p B a l})-n_{\\mathrm{te}}\\mathrm{Bias}^{2}(\\theta_{k}^{S h a r p B a l})\\right)}\\\\ &{}&{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\!\\phi^{\\prime}(2k,0)\\sigma^{2}+\\displaystyle\\frac{S-1}{d_{\\mathrm{in}}S}\\left(\\phi^{\\prime}(2k,0)-\\phi^{\\prime}(k,0)^{2}\\right)\\|\\theta^{*}\\|_{2}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "When the model is trained on the submatrix, the sharpness of model $\\theta_{k}^{S h a r p B a l}$ is defined as ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\kappa_{k}^{S h a r p B a l}=\\mathbb{E}_{\\mathbf{A}}\\big[\\operatorname*{max}_{\\|\\varepsilon\\|_{2}\\leq\\rho_{0}}f\\left(\\mathbb{E}_{\\theta_{0},s}\\left[\\theta_{k}^{S h a r p B a l}\\right]+\\varepsilon;\\mathbf{A}\\right)-f\\left(\\mathbb{E}_{\\theta_{0},s}\\left[\\theta_{k}^{S h a r p B a l}\\right];\\mathbf{A}\\right)\\big].\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "From a similar analysis of the proof for Theorem 1, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\kappa_{k}^{S h a r p B a l}\\leq\\frac{\\rho_{0}^{2}}{2}\\left(\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}+1\\right)^{2}+\\frac{\\rho_{0}}{S}\\mathbb{E}_{\\mathbf{A}}[\\|\\sum_{s=1}^{S}\\mathbf{B}_{s}^{k}\\mathbf{A}^{T}\\mathbf{A}\\theta^{*}\\|_{2}],\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and with $\\begin{array}{r}{r=\\frac{n_{\\mathrm{tr}}}{S d_{\\mathrm{in}}}}\\end{array}$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{k}\\Big[\\displaystyle\\prod_{s=1}^{S}\\mathbf{B}_{s}^{k}\\mathbf{A}^{T}\\mathbf{A}\\theta^{*}\\Big\\Vert_{2}\\Big]=\\mathbb{E}_{k}\\Big[\\big(\\theta^{*}\\big)^{T}\\mathbf{A}^{T}\\mathbf{A}\\sum_{s=1}^{S}\\mathbf{B}_{s}^{k}\\sum_{s=1}^{S}\\mathbf{B}_{s}^{k}\\mathbf{A}^{T}\\mathbf{A}\\theta^{*}\\big)^{1/2}\\Big]}\\\\ &{\\qquad\\qquad\\leq\\Bigg((\\theta^{*})^{T}\\mathbb{E}_{k}\\Big\\vert\\sum_{j=1}^{S}\\mathbf{A}_{j}^{T}\\mathbf{A}_{s}\\Big)\\sum_{s=1}^{S}\\mathbf{B}_{s}^{k}\\sum_{i=1}^{S}\\mathbf{B}_{i}^{k}\\sum_{l=1}^{S}\\mathbf{A}_{l}^{l}\\mathbf{A}_{l}\\Big\\vert\\theta^{*}\\Bigg)^{1/2}}\\\\ &{\\qquad=(S\\theta^{*}(2k,2)+2r S(S-1)\\phi^{\\prime}(2k,1)+2S(S-1)\\phi^{\\prime}(k,2))\\delta^{\\prime}(k,0)}\\\\ &{\\qquad+r(1+r)S(S-1)\\phi^{\\prime}(2k,0)+2S(S-1)\\phi^{\\prime}(k,1)\\phi^{\\prime}(k,1)}\\\\ &{\\qquad+\\frac{3}{2}r(1+r)S(S-1)(S-2)\\phi^{\\prime}(k,0)^{2}}\\\\ &{\\qquad+\\frac{3}{2}r^{2}S(S-1)(S-2)\\phi^{\\prime}(2k,0)}\\\\ &{\\qquad+3r S(S-1)(S-2)\\phi^{\\prime}(k,1)\\phi^{\\prime}(k,0)}\\\\ &{\\qquad+r^{2}S(S-1)(S-2)(S-3)\\phi^{\\prime}(k,0)^{2}\\vert\\phi^{*}\\vert\\vert_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The last equality is the result of applying $\\mathbb{E}_{\\mathbf{A}}[B_{s}^{i}(\\mathbf{A}_{s}^{T}\\mathbf{A}_{s})^{j}]=\\phi^{\\prime}(i,j)$ with different combinations of $\\mathbf{B}_{s},\\mathbf{B}_{s^{\\prime}},\\bar{\\mathbf{A}}_{j}^{T}\\bar{\\mathbf{A}_{j}}$ , and ${\\bf A}_{l}^{T}{\\bf A}_{l}$ , counting multiplicity and the fact that $\\mathbb{E}_{\\mathbf{A}}[(\\mathbf{A}_{s}^{T}\\mathbf{A}_{s})^{2}]=r(1+r)\\mathbf{I}$ . In conclusion, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\kappa_{k}^{S h a r p B a l}\\leq\\frac{\\rho_{0}^{2}}{2}\\left(\\sqrt{\\frac{n_{\\mathrm{tr}}}{d_{\\mathrm{in}}}}+1\\right)^{2}+\\frac{\\rho_{0}}{S}\\sqrt{C}\\|\\pmb{\\theta}^{*}\\|_{2},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{C=S\\phi^{\\prime}(2k,2)+2r S(S-1)\\phi^{\\prime}(2k,1)+2S(S-1)\\phi^{\\prime}(k,2)\\phi^{\\prime}(k,0)}}\\\\ {{\\qquad+r(1+r)S(S-1)\\phi^{\\prime}(2k,0)+2S(S-1)\\phi^{\\prime}(k,1)\\phi^{\\prime}(k,1)}}\\\\ {{\\qquad+\\,\\frac{3}{2}r(1+r)S(S-1)(S-2)\\phi^{\\prime}(k,0)^{2}+\\frac{3}{2}r^{2}S(S-1)(S-2)\\phi^{\\prime}(2k,0)}}\\\\ {{\\qquad+\\,3r S(S-1)(S-2)\\phi^{\\prime}(k,0)\\phi^{\\prime}(k,1)+r^{2}S(S-1)(S-2)(S-3)\\phi^{\\prime}(k,0)^{2}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "The claims in Theorem 2 is further supported by the experimental validations with results presented in Figure 9. ", "page_idx": 20}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/63610c009ea3a5cf9edf981b7277c89990bf71e16f1e534f0ddfec7ac472a2eb.jpg", "img_caption": ["Figure 9: (Theoretical vs. Simulated sharpness-diversity trade-off in SharpBalance) This figure illustrates the relationship between sharpness(upper bound) and diversity as predicted by Theorem 2 and as observed in simulations under different configurations. (a) validates our theoretical results by varying the perturbation radius $\\rho$ from 1.0 to 0.4. (b) validates the derivation by varying number of iterations $k$ from 1 to 15. These results demonstrate the soundness of our derivation across a range of parameters. ", "(a) Varying perturbation radius $\\rho$ "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/6478bde51173b0c916dad33780725a0c00c25368b1eab48a11f0360dc67534a0.jpg", "img_caption": ["(b) Varying number of training iterations $k$ "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "C.3 Empirical Verification of Theorem 1 and 2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "To demonstrate the robustness and tightness of the bounds presented in Theorem 1, we provide verification results across a range of parameter configurations. Interestingly, the observed model behaviors closely align with the upper bound derived in Theorem 1, highlighting the effectiveness of our theoretical analysis in capturing the underlying dynamics of the ensemble. Figure 10 illustrates these results, with each sub-figure corresponding to a specific combination of $k$ and $\\eta$ with $\\rho$ from range 0.5 to 0.3. In these experiment, we generated 50 random data matrices A of size $3000\\times150$ and test data $\\mathbf{T}$ of size $1000\\times150$ . For each random dataset, we initialized 50 random model weights $\\pmb{\\theta}_{0}$ and collected the expected statistics of interest after training. To measure the sharpness \u03baSAM, we employed projected gradient ascent to find the optimal perturbation, using a step size of 0.01 and a maximum of 50 steps. Similar experiments are performed to verify the derivations in Theorem 2 with results presented in Figure 11, with the number of partitions $S=10$ . ", "page_idx": 21}, {"type": "text", "text": "D Hyperparamter setting ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "D.1 Datasets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We first evaluate on image classification datasets CIFAR-10 and CIFAR-100. The corresponding OOD robustness is evaluated on CIFAR-10C and CIFAR-100C [Hendrycks and Dietterich, 2019b]. The experiments are carried out on ResNet18 [He et al., 2016]. We use a batch size of 128, a momentum of 0.9, and a weight decay of 0.0005 for model training. TinyImageNet is an image classification dataset consisting of 100K images for training and 10K images for in-distribution testing. We evaluate ensemble\u2019s OOD robustness on TinyImageNetC [Hendrycks and Dietterich, 2019b]. ", "page_idx": 21}, {"type": "text", "text": "D.2 Hyperparamter setting for empirical sharpness-diversity trade-off ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Here, we provide the hyperparameter for the experiments in Section 4.2. When using adaptive worst-case sharpness for sharpness measurement, the size of neighborhood $\\gamma$ defined in equation (3) needed to be specified, we use a $\\gamma$ of 0.5 for all the results in Figure 1 and Figure 5. Additionally, when training NNs in the ensemble, we change the perturbation radius $\\rho$ of SAM so that we can study the trade-off. The range of $\\rho$ for the results in Figure 1 is $\\{0.01,0.02,0.03,0.04,0.05,0.1,0.2,0.3\\},$ , the range of $\\rho$ for the results in Figure 5 is $\\{0.01,0.015,0.02,0.025,0.03,0.05,0.1,0.2,0.3,0.4\\}.$ ", "page_idx": 21}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/9c32e44f6ea32ff25827385c7fd53322fb7538e60f6dea77bc5a7cb3e4621fd2.jpg", "img_caption": ["Figure 10: (Theoretical vs. Simulated sharpness-diversity trade-off in SAM). This figure compares the sharpness and diversity as predicted by Theorem 1 and as observed in simulations under various parameter configurations. Results demonstrates the robustness of our theoretical analysis and tightness of the derived sharpness upper bound. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "D.3 Hyperparamter setting for SharpBalance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Hyperparameter setting on CIFAR10/100. For experiments on CIFAR10/100, we train an NN from scratch with basic data augmentations, including random cropping, padding by four pixels, and random horizontal flipping. We use a batch size of 128, a momentum of 0.9, and a weight decay of 0.0005. For deep ensemble, we train each model for 200 epochs. ", "page_idx": 22}, {"type": "text", "text": "In addition, we use $10\\%$ of the training set as the validation set for selecting $\\rho$ and $k$ based on the ensemble\u2019s performance. We make a grid search for $\\rho$ over $\\left\\{0.01,0.02,0.05,0.1,0.2,0.5\\right\\}$ . For SharpBalance, we use the same $\\rho$ as SAM and search $k$ over $\\{0.2,0.3,0.4,0.5,0.6\\}$ . $T_{d}$ is another hyperparameter introduced by SharpBalance, we use a $T_{d}$ of 10 for all experiments on CIFAR10, a $T_{d}$ of 100 and 150 respectively when training dense and sparse models on CIFAR100. See Table 1 for the optimal $\\rho$ and $k$ after grid search. ", "page_idx": 22}, {"type": "text", "text": "Hyperparameter setting on TinyImageNet. For experiments on TinyImageNet, we adopt basic data augmentations, including random cropping, padding by four pixels, and random horizontal flipping. We train each model for 200 epochs. We use a batch size of 128, a momentum of 0.9, a weight decay of 5e-4, a $T_{d}$ of 100, an initial learning rate of 0.1, and decay it with a factor of 10 at Epoch 100 and 150. We search $\\rho$ and $k$ in the same range as what we do on CIFAR10/100. See Table 1 for the optimal $\\rho$ and $k$ after grid search. ", "page_idx": 22}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/aa9d54028168eb275298e06a406da9bba4954188a607a9e87e49a6a3730322fa.jpg", "img_caption": ["Figure 11: (Theoretical vs. Simulated sharpness-diversity trade-off in SharpBalance). This figure compares the sharpness and diversity as predicted by Theorem 2 and as observed in simulations under various parameter configurations. The observed model behaviors align closely with our derived upper bounds. "], "img_footnote": [], "page_idx": 23}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/ff61888ccf3d6656b0b2a077de388c623705001102dbf9990c3b02b8b3c9628e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 1: Hyperparamter setting for results in Section 4.4, we report the optimal $\\rho$ and $k$ after grid search. Each result in Figure 7 is averaged over three ensembles, which corresponds to 9 random seeds, the random seeds we use are $\\{13,\\bar{17},27,113,117,127,43,59,223\\}$ . ", "page_idx": 23}, {"type": "text", "text": "E Ablation studies on loss landscape metrics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section, we show that the sharpness-diversity trade-off generalizes to different measurements of sharpness and diversity. The results are presented in Figure 12. ", "page_idx": 23}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/f56ee40562d7bda0b92bb657c28f207d97f6f4d609788fb0717d092a7b7859f4.jpg", "img_caption": ["Figure 12: (Ablation study of varying sharpness and diversity metrics to corroborate existence of sharpness-diversity trade-off). (a)(d) Varying sharpness metric by using the adaptive $\\ell_{\\infty}$ worstcase sharpness. (b)(e) Varying sharpness metric by using the adaptive $\\ell_{2}$ average case sharpness. (c)(f) Varying diversity metric by using the KL divergence. The sharpness-diversity trade-off is still observed in all the settings. The $x$ -axis and $y$ -axis are in log scale. The notation $\\beta$ stands for the slope of the linear regression function fitted on all the ensembles trained by SAM. ", "(d) Diff sharpness (TIN) ", "(e) Diff sharpness (TIN) ", "(f) Diff diversity (TIN) "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Sharpness metric. In the main paper, we use adaptive worst-case sharpness defined in equation (3), the parameter neighborhood is bounded by $\\ell_{2}$ norm. In this section, we consider two more sharpness metrics [Kwon et al., 2021, Andriushchenko et al., 2023]: adaptive worst-case sharpness with the parameter neighborhood bounded by $\\ell_{\\infty}$ norm (referred to as adaptive $\\ell_{\\infty}$ worst-case sharpness); and adaptive average case sharpness bounded by $\\ell_{2}$ norm (termed average case sharpness). The adaptive $\\ell_{\\infty}$ worst-case sharpness is defined as: ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\|T_{\\theta}^{-1}\\pmb{\\varepsilon}\\|_{\\infty}\\leq\\rho_{0}}\\!\\mathcal{L}_{\\mathcal{D}}(\\pmb{\\theta}+\\pmb{\\varepsilon})-\\mathcal{L}_{\\mathcal{D}}(\\pmb{\\theta}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The average case sharpness is defined as: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{\\varepsilon\\sim\\mathcal{N}\\left(0,\\rho_{0}^{2}\\,\\mathrm{diag}(T_{\\theta}^{2})\\right)}}&{{}\\mathcal{L}_{\\mathcal{D}}(\\pmb{\\theta}+\\pmb{\\varepsilon})-\\mathcal{L}_{\\mathcal{D}}(\\pmb{\\theta}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\rho_{0}$ is the neighborhood size of current parameter $\\pmb{\\theta}$ . $T_{\\theta}$ is a normalization operator that ensures the sharpness measure is invariant with respect to the re-scaling operation of the parameter. The results, illustrated in Figures 12, corroborate our observation of a trade-off between sharpness and diversity. ", "page_idx": 24}, {"type": "text", "text": "Diversity metric. We consider Kullback\u2013Leibler (KL) Divergence [Kullback and Leibler, 1951] as an alternative diversity metric, which is also widely used in previous literature to gauge the diversity of two ensemble members [Fort et al., 2019, Liu et al., 2022]. Specifically, the KL-divergence between the outputs of two ensemble members given a data sample $\\left({\\pmb x},{\\pmb y}\\right)$ is defined as: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathrm{KL}\\left(f_{\\theta_{1}}(x),f_{\\theta_{2}}(x)\\right)=\\mathbb{E}_{f_{\\theta_{1}}(x)}\\left[\\log f_{\\theta_{1}}(x)-\\log f_{\\theta_{2}}(x)\\right].\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We measure the KL divergence on each data sample in the test data and then average the measured KL divergence. The results for KL-divergence are shown in Figure 12, which demonstrate the trade-off remains consistent for different diversity metrics. ", "page_idx": 24}, {"type": "text", "text": "F More results ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "F.1 Evaluation on different corruption severity ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "SharpBalance \u2019s main advantage lies in OOD scenarios. As shown in Table 2-4, SharpBalance consistently outperforms the baselines on different levels of corruption. ", "page_idx": 25}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/15e062e27d7ccafc621325be8428568cb728a3e95ab581ef3759772bdd0e8b2e.jpg", "table_caption": ["Table 2: Results of different severity levels on CIFAR10-C. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/e678a36b65af6903f9c63ff090a40d3e46891238aa08a0efe40810e9becf9dac.jpg", "table_caption": ["Table 3: Results of different severity levels on CIFAR100-C. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/7c958e1ea5d02696b7aba270f5f75579734b1099c662953b3fa9ddf2f76c515b.jpg", "table_caption": ["Table 4: Results of different severity levels on Tiny-ImageNet-C. "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "F.2 Evaluation on different model architectures ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We extend the evaluations on more architectures such as WideResNet (WRN), ViT, and ALBERT. Here we describe the experimental setup. For vision tasks with WRN, we trained the ensemble members from scratch on CIFAR-10 and CIFAR-100. For vision tasks with transformers, we constructed the three-member ensemble by fine-tuning the pre-trained ViT-T/16 model on the CIFAR100 dataset, evaluated on in-distribution and CIFAR100-C test sets. For language tasks, we constructed the three-member ensemble by fine-tuning the pre-trained ALBERT-Base model on Microsoft Research Paraphrase Corpus (MRPC) dataset and evaluated the performance on its validation set. The hyperparameter search and setup are the same as in Appendix D.3. ", "page_idx": 25}, {"type": "text", "text": "These results in Figure 13 and Table 5 confirm that SharpBalance consistently boosts both ID and OOD performance across the models and datasets studied. ", "page_idx": 25}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/30db69847be92a4ffd75267cfbc4f21ef051ddd547bd668a6d95f2909b5223b1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "Table 5: (Additional experiments on Transformer-architecture). The ensemble test accuracy is reported and each ensemble comprises three members. The observation is consistent with the residual network results in the main paper: SAM improves the Deep Ensemble, and SharpBalance outperforms both two baselines. ", "page_idx": 25}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/d75d4dcb7b56e1801da4241f91308d3ef22d506a7231536d70082a6fcbb4272d.jpg", "img_caption": ["Figure 13: The three-member WRN-40-2 ensemble is trained with different methods on two datasets. The first row reports the OOD accuracy and the second row reports the ID accuracy. The lower part of each bar with the diagonal lines represents the individual model performance. The upper part of each bar represents the ensembling improvement. The results are reported by averaging three ensembles, and each ensemble is comprised of three models. "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "F.3 Sharpness-aware set: hard vs easy examples ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "SharpBalance aims to achieve the optimal balance by applying SAM to a carefully selected subset of the data while performing standard optimization on the remaining samples. In our work, sharpness is determined by the curvature of the loss around the model\u2019s weights, whereas [Garg and Roy, 2023] determines it based on the curvature of the loss around a data point. In Figure 14, we rank 1000 samples using both metrics and found a strong correlation between these two. ", "page_idx": 26}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/5f6e8b4a834f0f40f0476d4cab146c4d5280553a6c02bdef222501ddbb071b77.jpg", "img_caption": ["Figure 14: Rank correlation between fisher trace and loss curvature around input data "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "F.4 Comparison with more baselines ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "We compare SharpBalance with stronger ensemble method EoA [Arpit et al., 2022] and stronger SAM methods. We carefully tuned the hyperparameters for EoA. EoA fine-tuned a pre-trained model; and in our paper, all models are trained from scratch. We compare SharpBalance with another SAM baseline: ${\\tt S A M}+$ , where three individual models are trained with different $\\rho$ values, e.g., 0.05, 0.1, and 0.2, respectively. From Table 6, SharpBalance outperforms these two baselines both in-distribution and OOD generalization. ", "page_idx": 27}, {"type": "text", "text": "In Table 7, we combine GSAM [Zhuang et al., 2022] with Deep Ensemble as a new baseline method \u201cDeep Ensemble $+\\,\\mathrm{GSAM^{\\ast}}$ , and incorporate the GSAM into our method SharpBalance. The results show that the new baseline with GSAM outperforms the original baseline in ID and OOD performance but still underperforms SharpBalance (w/ SAM). Furthermore, we enhance SharpBalance by replacing the SAM with GSAM, which leads to better ID performance. ", "page_idx": 27}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/a4cbda593f805d4564283ebbb2de26e9138b06ecee42218241981356858ee0a6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/f1a9703fe25003257127b73d0bb5a1b00b49d065926cf5f3b51279b9f474c069.jpg", "table_caption": ["Table 6: SharpBalance outperforms EoA and SAM $^+$ both in-distribution and OOD generalization on CIFAR10 and CIFAR100. "], "table_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/f811e7d8cd39e3be0842cf582c05f0d1c2deae8801747465b5056e804c114387.jpg", "img_caption": ["Table 7: (Comparing our method SharpBalance with stronger SAM baseline). The ensemble test accuracy is reported and each ensemble comprises three members. GSAM improves the original baseline method with SAM and SharpBalance. The model is ResNet18. ", "(a) Expected Calibration Error (ECE) "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "wJaCsnT9UE/tmp/3505995efcfc5c59b65f8177737169e49206235407a295be28fda9a39e7fc36b.jpg", "img_caption": ["(b) Negative Log Likelihood (NLL) "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "Figure 15: (Uncertainty metrics on CIFAR100-C). \u201cECE\u201d represents expected calibration error, and \u201cNLL\u201d represents negative log-likelihood. Both metrics are lower the better. The model architecture is ResNet-18. The uncertainty metrics demonstrate the superior performance of SharpBalance. $x$ -axis represents the number of individual models in one ensemble. ", "page_idx": 27}, {"type": "text", "text": "F.5 Evaluation on uncertainty metrics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In Figure 15, we present the results of uncertainty metrics, i.e., negative log-likelihood and expected calibration error. These uncertainty metrics exhibit trends similar to the accuracy metrics: \"Deep Ensemble $+\\,S\\mathrm{AM\"}$ outperforms \"Deep Ensemble\", and our method outperforms both baselines. The experiments were conducted using ResNet-18 on CIFAR100, with metrics reported on corrupted datasets. Additionally, we observe that both metrics improve as the number of ensemble members increases for all three methods. ", "page_idx": 28}, {"type": "text", "text": "G Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "All codes are implemented in PyTorch, and the experiments are conducted on 3 Nvidia Quadro RTX 6000 GPUs for training an ensemble of 3 models. Compared to SAM, our method adds a minimal computational cost. The extra time comes from using Fisher trace to compute the per-sample sharpness. Therefore, computing the per-sample sharpness requires one single forward pass and one backward pass. We report the additional training cost in Table 8. SharpBalance only increases the training time by $1\\%$ : 0.83 $(84.48-0.83)\\times100\\%\\approx1\\%$ . ", "page_idx": 28}, {"type": "table", "img_path": "wJaCsnT9UE/tmp/0700e9d33ebeafd21b3d7576a85d220ef35fe3bfcb910a9f19f377d13be52520.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table 8: Additional training cost introduced by SharpBalance. We train a ResNet18 on CIFAR10 for 200 epochs. ", "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Main claims made in the abstract and introduction accurately reflect the scope and contribution of the paper, supported by our theoretical and experimental results. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: The limitations of the work are discussed in Section 5. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Proofs of all theoretical results are provided in Appendix C and the assumptions are clearly stated in the theorems. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper fully discloses all relevant information including detailed description of the algorithms, datasets, experimental set up in Section 4 and hyperparameters in Appendix D to reproduce the main experimental results claimed in the paper. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The implementation can be found through the anonymous github repository and the zip file uploaded as the supplementary materials. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: The experimental settings with hyperparameters are provided in both Section 4 and Appendix D. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The results are accompanied by error bars, for the experiments in Section 4.4 that support the main claims of the paper. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 31}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The information on the computer resources for experiments can be found in Appendix G. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] Justification: The impact statement of the study can be found in Appendix A. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. ", "page_idx": 32}, {"type": "text", "text": "\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 33}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper poses no such risks. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The original papers that produced the code or dataset are appropriately cited in this work. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 34}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}]