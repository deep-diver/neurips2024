[{"figure_path": "lckAdnVzsT/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative evaluation of 3D scene reconstruction on SUN RGB-D [62] (left) and 3D shape reconstruction on Pix3D [64] (right). Our 3D scene diffusion approach outperforms all baseline methods on both tasks on common 3D scene reconstruction metrics.", "description": "This table presents a quantitative comparison of the proposed 3D scene diffusion approach against state-of-the-art methods on two benchmark datasets: SUN RGB-D and Pix3D.  For SUN RGB-D, it shows the Intersection over Union (IoU) for 3D bounding boxes, Average Precision (AP) at 15% IoU threshold, and a surface alignment loss (Lalign). For Pix3D, it displays the Chamfer distance (CD) and F-Score.  The results demonstrate that the proposed method significantly outperforms the baselines across all metrics on both datasets.", "section": "4 Experiments"}, {"figure_path": "lckAdnVzsT/tables/tables_7_2.jpg", "caption": "Table 2: Ablations. We ablate the effect of our contributions and design decisions. We observe significant gains by introducing our proposed scene prior and intra-scene attention module, using denoising diffusion compared to regression, and jointly training shape and pose together.", "description": "This table presents ablation study results, showing the impact of different design choices on the model's performance.  It demonstrates the individual and combined contributions of using a diffusion model, incorporating intra-scene attention (ISA), and jointly training pose and shape.  The results quantify the improvements achieved by each component, highlighting the effectiveness of the overall approach.", "section": "3 Method"}, {"figure_path": "lckAdnVzsT/tables/tables_16_1.jpg", "caption": "Table 3: Additional 3D room layout estimation on SUN RGB-D [62]. We evaluate the 3D IoU of the orientied room bounding box. Our diffusion-based pose estimation lead to an improvement of +1.7% in Room Layout IoU.", "description": "This table compares the performance of three different methods for 3D room layout estimation on the SUN RGB-D dataset.  The methods are Total3D [48], Im3D [77], and the authors' proposed method.  The metric used is the 3D Intersection over Union (IoU) of the oriented room bounding box. The authors' method achieves a +1.7% improvement in Layout IoU compared to Im3D.", "section": "3.3 Object Pose Parameterization"}, {"figure_path": "lckAdnVzsT/tables/tables_16_2.jpg", "caption": "Table 1: Quantitative evaluation of 3D scene reconstruction on SUN RGB-D [62] (left) and 3D shape reconstruction on Pix3D [64]. Our 3D scene diffusion approach outperforms all baseline methods on both tasks on common 3D scene reconstruction metrics.", "description": "This table presents a quantitative comparison of the proposed 3D scene diffusion model against several state-of-the-art baselines on two benchmark datasets: SUN RGB-D and Pix3D.  The left side shows results for 3D scene reconstruction on SUN RGB-D, evaluating Average Precision (AP) at an Intersection over Union (IoU) threshold of 15% and a novel surface alignment loss (Lalign). The right side shows results for 3D shape reconstruction on Pix3D, using Chamfer Distance (CD) and F-Score as evaluation metrics. The table demonstrates the superior performance of the proposed method on both datasets across these commonly used metrics.", "section": "4 Experiments"}, {"figure_path": "lckAdnVzsT/tables/tables_16_3.jpg", "caption": "Table 5: Quantitative comparison with ROCA [17] on the ScanNet dataset [11]. While ROCA estimated each object's pose individually, our generative scene prior can reason about object relationships, leading to a +3.1% improvement in class-wise alignment accuracy.", "description": "This table compares the performance of the proposed method against ROCA [17] on the ScanNet dataset [11] in terms of class-wise alignment accuracy.  The key finding is that the proposed method, by leveraging a generative scene prior that captures inter-object relationships, achieves a 3.1% improvement over ROCA, which estimates object poses individually.  The table presents the quantitative results for each object category.", "section": "4.4 Comparison to State of the Art"}, {"figure_path": "lckAdnVzsT/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative evaluation of 3D scene reconstruction on SUN RGB-D [62] (left) and 3D shape reconstruction on Pix3D [64]. Our 3D scene diffusion approach outperforms all baseline methods on both tasks on common 3D scene reconstruction metrics.", "description": "This table presents a quantitative comparison of the proposed 3D scene diffusion method against several state-of-the-art baselines on two benchmark datasets: SUN RGB-D and Pix3D.  For SUN RGB-D, the metrics used are Average Precision (AP) at an Intersection over Union (IoU) threshold of 15% and a surface alignment loss (Lalign). For Pix3D, the metrics are Chamfer Distance (CD), and F-Score. The results demonstrate that the proposed method significantly outperforms the baselines on all metrics, highlighting its effectiveness in both 3D scene and shape reconstruction.", "section": "4 Experiments"}, {"figure_path": "lckAdnVzsT/tables/tables_18_1.jpg", "caption": "Table 7: Per-class comparisons of shape reconstruction on Pix3D [64]. We report F-Score using the non-overlapping 3D model split from [37]. We observe noticeable improvements or comparable results on all categories.", "description": "This table presents a quantitative comparison of the proposed 3D scene diffusion approach's shape reconstruction performance against three state-of-the-art baselines (Total3D, Im3D, and InstPIFu) on the Pix3D dataset.  The comparison is made using the F-Score metric, a common evaluation measure for 3D shape reconstruction tasks. The table breaks down the F-Score for each of the object categories in the Pix3D dataset, offering a detailed view of the method's performance across different object types.  The non-overlapping 3D model split from a previous work [37] ensures the results are not influenced by model overlap during training.", "section": "4.4 Comparison to State of the Art"}, {"figure_path": "lckAdnVzsT/tables/tables_21_1.jpg", "caption": "Table 1: Quantitative evaluation of 3D scene reconstruction on SUN RGB-D [62] (left) and 3D shape reconstruction on Pix3D [64]. Our 3D scene diffusion approach outperforms all baseline methods on both tasks on common 3D scene reconstruction metrics.", "description": "This table presents a quantitative comparison of the proposed 3D scene diffusion method against several state-of-the-art baselines on two benchmark datasets: SUN RGB-D and Pix3D.  The metrics used for evaluation include Average Precision (AP), Intersection over Union (IoU), Chamfer Distance (CD), and F-Score. The results demonstrate significant improvements achieved by the proposed approach over existing methods in both 3D scene and shape reconstruction tasks.", "section": "4 Experiments"}, {"figure_path": "lckAdnVzsT/tables/tables_21_2.jpg", "caption": "Table 7: Per-class comparisons of shape reconstruction on Pix3D [64]. We report F-Score using the non-overlapping 3D model split from [37]. We observe noticeable improvements or comparable results on all categories.", "description": "This table presents a quantitative comparison of the proposed method against state-of-the-art methods for 3D shape reconstruction on the Pix3D dataset.  It shows the F-score achieved for each object category (bed, bookcase, chair, desk, miscellaneous objects, sofa, table, tool, wardrobe) using a non-overlapping split of the dataset.  The results demonstrate the effectiveness of the proposed method, showing either improvements or comparable performance compared to existing approaches.", "section": "4.4 Comparison to State of the Art"}]