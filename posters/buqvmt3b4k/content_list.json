[{"type": "text", "text": "Self-Labeling the Job Shop Scheduling Problem ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Andrea Corsini Angelo Porrello Simone Calderara Mauro Dell\u2019Amico ", "page_idx": 0}, {"type": "text", "text": "University of Modena and Reggio Emilia, Italy {name.surname}@unimore.it ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "This work proposes a self-supervised training strategy designed for combinatorial problems. An obstacle in applying supervised paradigms to such problems is the need for costly target solutions often produced with exact solvers. Inspired by semi- and self-supervised learning, we show that generative models can be trained by sampling multiple solutions and using the best one according to the problem objective as a pseudo-label. In this way, we iteratively improve the model generation capability by relying only on its self-supervision, eliminating the need for optimality information. We validate this Self-Labeling Improvement Method (SLIM) on the Job Shop Scheduling (JSP), a complex combinatorial problem that is receiving much attention from the neural combinatorial community. We propose a generative model based on the well-known Pointer Network and train it with SLIM. Experiments on popular benchmarks demonstrate the potential of this approach as the resulting models outperform constructive heuristics and state-of-the-art learning proposals for the JSP. Lastly, we prove the robustness of SLIM to various parameters and its generality by applying it to the Traveling Salesman Problem. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The Job Shop Problem (JSP) is a classic optimization problem with many practical applications in industry and academia [56]. At its core, the JSP entails scheduling a set of jobs across multiple machines, where each job has to be processed on the machines following a specific order. The goal of this problem is generally to minimize the makespan: the time required to complete all jobs [40]. ", "page_idx": 0}, {"type": "text", "text": "Over the years, various approaches have been developed to tackle the JSP. A common one is adopting exact methods such as Mixed Integer Programming solvers (MIP). However, these methods often struggle to provide optimal or high-quality solutions on medium and large instances in a reasonable timeframe [29]. As a remedy, metaheuristics have been extensively investigated [36, 13, 24] and constitute an alternative to exact methods. Although state-of-the-art metaheuristics like [37] can rapidly provide quality solutions, typically within minutes, they are rather complex to implement and their results can be difficult to reproduce [6]. Therefore, due to their lower complexity, Priority Dispatching Rules (PDR) [40] are frequently preferred in practical applications with tighter time constraints. The main issue of PDRs is their tendency to perform well in some cases and poorly in others, primarily due to their rigid, hand-crafted prioritization schema based on hardcoded rules [21]. ", "page_idx": 0}, {"type": "text", "text": "Recent works have increasingly investigated Machine Learning (ML) to enhance or replace some of these approaches, primarily focusing on PDRs. ML-based approaches, specifically Reinforcement Learning (RL) ones, proved to deliver higher-quality solutions than classic PDRs at the cost of a small increase in execution time [33]. Despite the potential of RL [54, 25], training RL agents is a complex task [45, 34], is sensitive to hyper-parameters [43], and has reproducibility issues [22]. ", "page_idx": 0}, {"type": "text", "text": "Contrary, supervised learning is less affected by these issues but heavily relies on expensive annotations [32]. This is particularly problematic in combinatorial problems, where annotations in the form of (near-) optimal information are generally produced with expensive exact solvers. To contrast labeling cost and improve generalization, semi-supervised [48] and self-supervised [32] are gaining popularity in many fields due to their ability to learn from unlabeled data. Despite this premise, little to no application of these paradigms can be found in the JSP and the combinatorial literature [5, 9]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Motivated by these observations, we introduce a novel self-supervised training strategy that is simpler than most RL algorithms, does not require the formulation of the Markov Decision Process [45], and relies only on model-generated information, thus removing the need for expensive annotations. Our proposal is based on two weak assumptions: i) we suppose to be able to generate multiple solutions for a problem, a common characteristic of generative models [38]; and ii) we suppose it is possible to discriminate solutions based on the problem objective. When these assumptions are met, we train a model by generating multiple solutions and using the best one according to the problem objective as a pseudo-label [31]. This procedure draws on the concept of pseudo-labeling from semi-supervised learning, but it does not require any external and expansive annotation as in self-supervised learning. Hence, we refer to it as a SLIM: Self-Labeling Improvement Method. ", "page_idx": 1}, {"type": "text", "text": "We prove the effectiveness of SLIM primarily within the context of Job Shop, a challenging scheduling problem with many baseline algorithms [1, 36] and established benchmarks [44, 46, 16]. As recognized in other works [54, 39, 25], focusing on the JSP is crucial because its study helps address related variants, such as Dynamic JSP [51] and Flow Shop [42], while also establishing a concrete base for tackling more complicated scheduling problems like Flexible JSP [53]. ", "page_idx": 1}, {"type": "text", "text": "Similar to PDRs, we cast the generation of solutions as a sequence of decisions, where at each decision one job operation is scheduled in the solution under construction. This is achieved with a generative model inspired by the Pointer Network [50], a well-known architecture for dealing with sequences of decisions in combinatorial problems [5]. We train our model on random instances of different sizes by generating multiple parallel solutions and using the one with the minimum makespan to update the model. This training strategy produces models outperforming state-of-the-art learning proposals and other conventional JSP algorithms on popular benchmark sets. Furthermore, our methodology demonstrates robustness and effectiveness across various training regimes, including a brief analysis on the Traveling Salesman Problem to emphasize the broader applicability of SLIM beyond scheduling. In summary, the contributions of this work are: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Our key contribution is the introduction of SLIM, a novel self-labeling improvement method for training generative models. Thanks to its minimal assumptions, SLIM can be easily applied as-is to other combinatorial problems. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Additionally, we present a generative encoder-decoder architecture capable of generating highquality solutions for JSP instances in a matter of seconds. ", "page_idx": 1}, {"type": "text", "text": "The remainder of this work is organized as follows: Sec. 2 reviews related ML works; Sec. 3 formalizes the JSP; Sec. 4 introduces our generative model and SLIM; Sec. 5 compares our approach with others; Sec. 6 studies additional aspects of our proposal; and Secs. 7 and 8 close with general considerations, some limitations, and potential future directions. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "ML approaches have been recently investigated to address issues of traditional JSP methodologies. ", "page_idx": 1}, {"type": "text", "text": "Motivated by the success of supervised learning, various studies have employed exact methods to generate optimality information for synthetic JSP instances, enabling the learning of valuable scheduling patterns. For example, [26] used imitation learning [5] to derive superior dispatching rules from optimal solutions, highlighting the limitations of learning solely from optimal solutions. [28] proposed a joint utilization of optimal solutions and Lagrangian terms during training to better capture JSP constraints. Whereas, in [14], the authors trained a Recurrent Neural Network (RNN) to predict the quality of machine permutations \u2013 generated during training with an MIP \u2013 for guiding a metaheuristic. Despite their quality, these proposals are limited by their dependence on costly optimality information. ", "page_idx": 1}, {"type": "text", "text": "To avoid the need for optimality, other works have turned to reinforcement learning. The advantage of RL lies in its independence from costly optimal information, requiring only the effective formulation of the Markov Decision Process [45]. Several works focused on creating better neural PDRs, showcasing the effectiveness of policy-based methods [54, 39, 25, 11]. All these methods adopted a ", "page_idx": 1}, {"type": "text", "text": "Proximal Policy Optimization algorithm [43] and proposed different architectures or training variations. For instance, [54, 39] adopted Graph Neural Networks (GNN), [11] proposed a rather complex Transformer [49], while [25] used RNNs and curriculum learning [58]. Differently, [20] presented a Double Deep Q-Network approach, proving the applicability of value-based methods. ", "page_idx": 2}, {"type": "text", "text": "Other works employed RL to enhance other algorithmic approaches. In [12], an iterative RL-based approach was proposed to rewrite regions of JSP solutions selected by a learned policy. Whereas [17] utilized a Deep Q-learning approach to control three points of interventions within metaheuristics, and [55] recently presented an RL-guided improvement heuristic. Differently, [47] presented a hybrid imitation learning and policy gradient approach coupled with Constraint Programming (CP) for outperforming PDRs and a CP solver. ", "page_idx": 2}, {"type": "text", "text": "3 Job Shop Scheduling ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In the Job Shop Problem, we are given a set of jobs $J\\,=\\,\\{J_{1},\\dots,J_{n}\\}$ , a set of machines $M\\,=$ $\\{M_{1},\\ldots,M_{m}\\}$ , and a set of operations $O=\\{1,\\dots,o\\}$ . Each job $j\\in J$ comprises a sequence of $m_{j}$ consecutive operations $O_{j}=(l_{j},\\,.\\,.\\,.\\,,l_{j}+m_{j}-1)\\subset O$ indicating the order in which the job must be performed on machines, where $\\begin{array}{r}{l_{j}=1+\\sum_{i=1}^{j-1}m_{i}}\\end{array}$ is the index of its first operation (e.g., for and for in Fig. 1). An operation $i\\in O$ has to be performed on machine $\\mu_{i}\\,\\in\\,M$ for an uninterrupted amount of time $\\tau_{i}\\,\\in\\,\\mathbb{R}_{\\geq0}$ . Additionally, machines can handle one operation at a time. The objective of the JSP is to provide an order to operations on each machine, such that the precedences within operations are respected and the time required to complete all jobs (makespan) is minimized. Formally, we indicate with $\\pi$ a JSP solution comprising a permutation of operations for each machine and use $C_{i}(\\pi)$ to identify the completion time of operation $i\\in O$ in $\\pi$ . ", "page_idx": 2}, {"type": "text", "text": "A JSP instance can be represented with a disjunctive graph $G=(V,A,E)$ [3], where: $V$ contains one vertex for each operation $i\\in O$ ; $A$ is the set of directed arcs connecting consecutive operations of jobs reflecting the order in which operations must be performed; $E$ is the set of disjunctive (undirected) edges connecting operations to perform on the same machines. When the JSP is represented as a disjunctive graph $G$ , finding a solution means providing a direction to all the edges in $E$ , such that the resulting graph is directed and acyclic (all precedences are respected). As in related works [54, 39], we augment the disjunctive graph by associating to each vertex a set of 15 features $\\boldsymbol{x}_{i}\\in\\mathbb{R}^{15}$ describing information about operation $i\\in O$ . For lack of space, we present these features in App. A. ", "page_idx": 2}, {"type": "text", "text": "3.1 Constructing Feasible Job Shop Solutions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Feasible JSP solutions can be constructed step-by-step as a sequence of decisions, a common approach adopted by PDRs [40] and RL algorithms [54, 25]. The construction of solutions can be visualized using a branchdecision tree, shown at the bottom of Fig. 1. Each path from the root node $(R)$ to a leaf node presents a particular sequence of $o=|O|$ decisions and leads to a valid JSP solution, such as the one highlighted in gray. At every node in the tree, one uncompleted job needs to be selected, and its ready operation is scheduled in the solution being constructed. Due to the precedence constraints and the partial solution $\\pi_{<t}$ constructed up to decision $t$ , there is at most one operation $o(t,\\,j)\\in\\bar{O}_{j}$ that is ready to be scheduled for any job $j\\in J$ . Thus, by selecting a job $j$ , we uniquely identify an operation $o(t,\\,j)$ that will be scheduled by appending it to the partial permutation of its machine. Notice that once a job is completed, it cannot be selected again, and such a situation is identified with a cross in Fig. 1. ", "page_idx": 2}, {"type": "image", "img_path": "buqvMT3B4k/tmp/21fb293213e3cfda66fa23f020de36faeee32678b01e01ed804141b86b10858d.jpg", "img_caption": ["Figure 1: The sequences of decisions for constructing solutions in a JSP instance with two jobs $J_{1}$ and $J_{2}$ ) and two machines (identified in green and red). Best viewed in colors. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "We emphasize that diverse paths can lead to the same solution, indicating certain solutions are more frequent than others. In some instances, near-optimal solutions may lie at the end of unlikely and hardly discernible paths, making their construction more challenging. This could explain why PDRs, which rely on rigid, predefined rules, sometimes struggle to generate quality solutions, whereas neural algorithms \u2013 able to leverage instance- and solution-wide features \u2013 may perform better. ", "page_idx": 2}, {"type": "table", "img_path": "buqvMT3B4k/tmp/e178a8fc9b994622c0e6c30068584e2e167d87d6e3faa2983ab8d5ca505a39bc.jpg", "table_caption": ["Table 1: The features of a context vector $c_{j}\\in\\mathbb{R}^{11}$ that describes the status of a job $j$ within a partial solution $\\pi{_{<t}}$ . Recall that $o(t,j)$ is the ready operation of job $j$ at step $t$ , $\\mu_{o(t,\\,j)}$ its machine, and $o(t,j)-1$ its predecessor. "], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "4 Methodology: Generative Model & Self-Labeling ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "As described in Sec. 3.1, we tackle the JSP as a sequence of decisions. Thus, we propose a generative model inspired by the Pointer Network [50] (a well-known encoder-decoder architecture to generate sequences of decisions) whose goal is to select the right job at each decision step $t$ . Formally, our model learns a function $f_{\\theta}(\\cdot)$ , parametrized by $\\theta$ , that estimates the probability $\\bar{p}_{\\theta}\\bar{(\\pi}|G)$ of a solution $\\pi$ being of high-quality, expressed as a product of probabilities: ", "page_idx": 3}, {"type": "equation", "text": "$$\np_{\\theta}(\\pi|G)=\\prod_{t=1}^{|O|}f_{\\theta}(y_{t}\\,|\\,\\pi_{<t},G),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $f_{\\theta}(y_{t}\\,|\\pi_{<t},G)$ gives the probability of selecting job $y_{t}\\in J$ for creating $\\pi$ , conditioned on the instance $G$ and the partial solution $\\pi{_{<t}}$ constructed up to step $t$ . By accurately learning $f_{\\theta}(\\cdot)$ , the model can construct high-quality solutions autoregressively. The following sections present the proposed encoder-decoder architecture and the self-labeling strategy to train this generative model. ", "page_idx": 3}, {"type": "text", "text": "4.1 The Generative Encoder-Decoder Architecture ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Overview. Our model processes JSP instances represented as a disjunctive graph $G$ and produces single deterministic or multiple randomized solutions depending on the adopted construction strategy. The encoder operates at the instance level, creating embedded representations for all the operations in $O$ with a single forward computation of $G$ (hence, no autoregression). Whereas the decoder operates at the solution level (job and machine level), using the embeddings of ready operations and the partial solution $\\pi_{<t}$ to produce a probability of selecting each job at step $t$ . Recall that after selecting a job $j$ , its ready operation $o(t,\\,j)$ is scheduled in $\\pi_{<t}$ to produce the partial solution for step $t+1$ . ", "page_idx": 3}, {"type": "text", "text": "Encoder. It captures instance-wide relationships into the embeddings of operations, providing the decoder with a high-level view of the instance characteristics. The encoder can be embodied by any architecture, like a Feedforward Neural Network (FNN), that transforms raw operation features $\\boldsymbol{x}_{i}\\in\\mathbb{R}^{15}$ (see App. A for the features) into embeddings $\\boldsymbol{e}_{i}\\in\\mathbb{R}^{h}$ . As in related works [54, 39], we also encode the relationships among operations present in the disjunctive graph. We thus equip the encoder with Graph Neural Networks [52], allowing the embeddings to incorporate topological information of $G$ . In our encoder, we stack two Graph Attention Network (GAT) layers [8] as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\ne_{i}=[x_{i}\\mid\\mid\\sigma({\\mathrm{GAT}}_{2}(\\,[x_{i}\\mid\\mid\\sigma({\\mathrm{GAT}}_{1}(x_{i},\\,G))],\\,G)],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\sigma$ is the ReLU non-linearity and $||$ stands for the concatenation operation. ", "page_idx": 3}, {"type": "text", "text": "Decoder. It produces at any step $t$ the probability of selecting each job from the embeddings $e_{i}$ and solution-related features. The encoder is logically divided into two distinct components: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Memory Network: generates a state $s_{j}\\in\\mathbb{R}^{d}$ for each job $j\\in J$ from the partial solution $\\pi_{<t}$ . This is achieved by first extracting from $\\pi_{<t}$ a context vector $c_{j}$ (similarly to [27]), which contains ", "page_idx": 3}, {"type": "text", "text": "eleven hand-crafted features providing useful cues about the status of job $j$ . We refer to Tab. 1 for the definition and meaning of these features. Then, these vectors are fed into a Multi-Head Attention layer (MHA) [49] followed by a non-linear projection to produce jobs\u2019 states: ", "page_idx": 4}, {"type": "equation", "text": "$$\ns_{j}=\\mathrm{ReLU}(\\left[c_{j}\\,W_{1}+{\\bf M}{\\bf H}{\\bf A}(c_{b}\\,W_{1})\\right]W_{2}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $W_{1}$ and $W_{2}$ are projection matrices. Note that we use the MHA to consider the context of all jobs when producing the state for a specific one, similarly to [11]. ", "page_idx": 4}, {"type": "text", "text": "\u2022 Classifier Network: outputs the probability $p_{j}$ of selecting a job $j$ by combining the embedding $e_{o(t,j)}$ of its ready operation and the state $s_{j}$ produced by the memory network. To achieve this, we first concatenate the embeddings $e_{o(t,j)}$ with the states $s_{j}$ and apply an FNN: ", "page_idx": 4}, {"type": "equation", "text": "$$\nz_{j}=\\mathrm{FNN}([e_{o(t,\\,j)}\\,\\,||\\,s_{j}]).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Then, these scores $z_{j}\\in\\mathbb{R}$ are transformed into softmax probabilities: $\\begin{array}{r}{p_{j}=e^{z_{j}}\\left/\\begin{array}{r l r}\\end{array}\\right.\\sum_{b\\in J}e^{z_{b}}}\\end{array}$ . The final decision on which job to select at $t$ is made using a sampling strategy, as ex plained next. ", "page_idx": 4}, {"type": "text", "text": "Sampling solutions. To generate solutions, we employ a probabilistic approach for deciding the job selected at any step. Specifically, we randomly sample a job $j$ with a probability $p_{j}$ , produced at step $t$ by our decoder. We also prevent the selection of completed jobs by setting their scores $z_{j}=-\\infty$ to force $p_{j}=0$ before sampling. Note how this probabilistic selection is autoregressive, meaning that sampling a job depends on $p_{j}$ which is a function of $e_{o(t,j)}$ and $s_{j}$ resulting from earlier decisions (see Eqs. 3 and 4). Various strategies exist for sampling from autoregressive models, including top- $\\cdot\\mathbf{k}$ [23], nucleus [23], and random sampling [4]. Preliminary experiments revealed that these strategies perform similarly, with average optimality gap variations within $0.2\\%$ on benchmark instances. However, top- $\\cdot\\mathbf{k}$ and nucleus sampling introduce brittle hyperparameters that can hinder training convergence if not managed carefully. Therefore, we adopt the simplest strategy for training and testing, which is random sampling: sampling a job $j$ with probability $p_{j}$ at random. Note however that the sampling strategy remains a flexible design choice, not inherently tied to our methodology. ", "page_idx": 4}, {"type": "text", "text": "4.2 SLIM: Self-Labeling Improvement Method ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We propose a self-supervised training strategy that uses the model\u2019s output as a teaching signal, eliminating the need for optimality information or the formulation of Markov Decision Processes. Our strategy exploits two aspects: the capacity of generative models to construct multiple (parallel) solutions and the ability to discriminate solutions of combinatorial problems based on their objective values, such as the makespan in the JSP. With these two ingredients, we design a procedure that at each iteration generates multiple solutions and uses the best one as a pseudo-label [31]. ", "page_idx": 4}, {"type": "text", "text": "More in detail, for each training instance $G$ , we randomly sample a set of $\\beta$ solutions from the generative model $f_{\\theta}(\\cdot)$ . We do that by keeping $\\beta$ partial solutions in parallel and independently sample for each one the next job from the probabilities generated by the model. Once the solutions have been completely generated, we take the one with the minimum makespan $\\overline{{\\pi}}$ and use it to compute the Self-Labeling loss $(\\mathcal{L}_{\\mathrm{SL}})$ . This loss minimizes the cross-entropy across all the steps as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}_{\\mathrm{SL}}(\\overline{{\\pi}})=-\\frac{1}{|O|}\\sum_{t=1}^{|O|}\\log f_{\\theta}(y_{t}\\,|\\,\\overline{{\\pi}}_{<t},G),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $y_{t}\\in J$ is the index of the job selected at the decision step $t$ while constructing the solution $\\overline{{\\pi}}$ . ", "page_idx": 4}, {"type": "text", "text": "The rationale behind this training schema is to collect knowledge about sequences of decisions leading to high-quality solutions and distill it in the parameters $\\theta$ of the model. This is achieved by treating the best-generated solution $\\overline{{\\pi}}$ for an instance $G$ as a pseudo-label and maximizing its likelihood using Eq. 5. Similar to supervised learning, repeated exposure to various training instances enables the model to progressively refine its ability to solve combinatorial problems such as the JSP. Hence, we named this training strategy Self-Labeling Improvement Method (SLIM). ", "page_idx": 4}, {"type": "text", "text": "Relations with Existing Works ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Although our strategy was developed independently, attentive readers may find a resemblance with the Cross-Entropy Method (CEM), a stochastic and derivative-free optimization method [15]. Typically applied to optimize parametric models such as Bernoulli and Gaussian mixtures models [57], the ", "page_idx": 4}, {"type": "text", "text": "CEM relies on a maximum likelihood approach to either estimate a random variable or optimize the objective function of a problem [7]. According to Algorithm 2.2 in [7], the CEM independently samples $N=\\beta$ solutions, selects a subset based on the problem\u2019s objective $(\\hat{\\gamma}=S_{(N)}$ in our case), and updates the parameters of the model. ", "page_idx": 5}, {"type": "text", "text": "While the CEM independently tackles instances by optimizing a separate model for each, SLIM trains a single model on multiple instances to globally learn how to solve a combinatorial problem. Moreover, we adopt a more complex parametric model instead of mixture models, always select a single solution to update the model, and resort to the gradient descent for updating parameters $\\theta$ Notably, our strategy also differs from CEM applications to model-based RL, e.g., [57], as we do not rely on rewards in Eq. 5. In summary, our strategy shares the idea of sampling and selecting with the CEM but globally operates as a supervised learning paradigm once the target solution is identified. ", "page_idx": 5}, {"type": "text", "text": "Other self-labeling approaches can be found, e.g., in [10, 2], where the former uses K-Means to generate pseudo-labels, and the latter assigns labels to equally partition data with an optimal transportation problem. As highlighted in [2], these approaches may incur in degenerate solutions that trivially minimize Eq. 5, such as producing the same solution despite the input instance in our case. We remark that SLIM avoids such degenerate solutions by jointly using a probabilistic generation process and the objective value (makespan) of solutions to select the best pseudo-label $\\overline{{\\pi}}$ . ", "page_idx": 5}, {"type": "text", "text": "5 Results ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "This section outlines the implementation details, introduces the selected competitors, and presents the key results. All the experiments were performed on an Ubuntu 22.04 machine equipped with an Intel Core i9-11900K and an NVIDIA GeForce RTX 3090 GPU having $24\\,\\mathrm{GB}$ of memory.1 ", "page_idx": 5}, {"type": "text", "text": "5.1 Experimental Setup ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Dataset & Benchmarks. To train our model, we created a dataset of 30 000 instances as in [46] by randomly generating 5000 instances per shape $(n\\times m)$ in the set: $\\{10\\times10$ , $15\\times10$ , $15\\times15$ , $20~\\times$ 10, $20\\times15$ , $20\\times20\\}$ . While our training strategy does not strictly require a fixed dataset, we prefer using it to enhance reproducibility. For testing purposes, we adopted two challenging and popular benchmark sets to evaluate our model and favor cross-comparison. The first set is from Taillard [46], containing 80 instances of medium-large shapes (10 instances per shape). The second set is the Demirkol\u2019s one [16], containing 80 instances (10 per shape) which proved particularly challenging in related works [54, 25]. We additionally consider the smaller and easier Lawrence\u2019s benchmark [44] and extremely larger instances in Apps. C and E, respectively. ", "page_idx": 5}, {"type": "text", "text": "Metric. We assess performance on each benchmark instance using the Percentage Gap: $\\mathrm{PG}=$ $100\\cdot(C_{a l g},/,C_{u b}-1)$ , where $C_{a l g}$ is the makespan produced by an algorithm and $C_{u b}$ is either the optimal or best-known makespan for the instance. Lower PG values indicate better results, as they reflect solutions with an objective value closer to the optimal or best-known makespan. ", "page_idx": 5}, {"type": "text", "text": "Architecture. In all our experiments, we configure the model of Sec. 4.1 in the same way. Our encoder consists of two GAT layers [8], both with 3 attention heads and leaky slope at 0.15. In $\\mathrm{GAT_{1}}$ , we set the size of each head to 64 and concatenate their outputs; while in $\\mathrm{GAT}_{2}$ , we increase the head\u2019s size to 128 and average their output to produce $e_{i}\\in\\bar{\\mathbb{R}}^{143}$ $(h=15+128)$ ). Inside the decoder\u2019s memory network, the MHA layer follows [49] but it concatenates the output of 3 heads with 64 neurons each, while $W_{1}\\in\\mathbb{R}^{11\\times192}$ and $W_{2}\\in\\bar{\\mathbb{R}}^{192\\times128}$ use 192 and 128 neurons, respectively. Thus, the job states $s_{j}\\in\\mathbb{R}^{d}$ have size $d=128$ . Finally, the classifier FNN features a dense layer with 128 neurons activated through the Leaky-ReLU ( ${\\mathrm{slope}}=0.15)$ and a final linear with 1 neuron. ", "page_idx": 5}, {"type": "text", "text": "Training. We train this generative model with SLIM (see Sec. 4.2) on our dataset for 20 epochs, utilizing the Adam optimizer [19] with a constant learning rate of 0.0002. In each training step, we accumulate gradients over a batch of size 16, meaning that we update the model parameters $\\theta$ after processing 16 instances. During training and validation, we fix the number of sampled solutions $\\beta$ to 256 and save the parameters producing the lower average makespan on a hold-out set comprising 100 random instances per shape included in our dataset. Training in this way takes approximately 120 hours, with each epoch lasting around 6 hours. ", "page_idx": 5}, {"type": "table", "img_path": "buqvMT3B4k/tmp/90e9bc2e63dc9e606acad5d6fb3ecc95ebe45a2107991274ff38d1bce749b4d2.jpg", "table_caption": ["Table 2: The average PG of the algorithms on the benchmarks. In each row, we highlight in blue (bold) the best constructive (non-constructive) gap. Shapes marked with \\* are larger than those seen in training by our GM. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "Competitors. We compare the effectiveness of our methodology against various types of conventional algorithms and ML competitors reviewed in Sec. 2. We divide competitors as follows: ", "page_idx": 6}, {"type": "text", "text": "\u2022 Greedy Constructives generate a single solution for any input instance. We consider two cornerstone ML works for the JSP: the actor-critic (L2D) of [54] and the recent curriculum approach (CL) of [25]. We also coded the INSertion Algorithm (INSA) of [36] and three standard dispatching rules that prioritize jobs based on the Shortest Processing Time (SPT); Most Work Remaining (MWR); and Most Operation Remaining (MOR). ", "page_idx": 6}, {"type": "text", "text": "\u2022 Multiple (Randomized) Constructives generate multiple solutions for an instance by introducing a controlled randomization in the selection process, a simple technique for enhancing constructive algorithms [50, 25]. We consider randomized results of CL and L2D. As only greedy results were disclosed for L2D, we used the open-source code to sample randomized solutions as described in Sec. 4.1. We also consider the three dispatching rules above, randomized by arbitrarily scheduling an operation among the three with higher priority, and the Shifting Bottleneck Heuristic (SBH) [1] that creates multiple solutions while optimizing. All these approaches were seeded with 12345, generate $\\beta=128$ solutions, and return the one with minimum makespan. ", "page_idx": 6}, {"type": "text", "text": "\u2022 Non-constructive Approaches do not rely on a pure constructive strategy for creating JSP solutions. We include two RL-enhanced metaheuristics: the $\\mathrm{NLS}_{A}$ in [18] (200 iterations) and the recent L2S proposal of [55] visiting 500 $(\\mathrm{L}2\\mathrm{S}_{500})$ and 5000 $(\\mathrm{L}2\\mathrm{S}_{5k})$ ) solutions. We also consider two state-of-the-art solvers for the JSP: Gurobi 9.5 (MIP) solving the disjunctive formulation of [29] and the CP-Sat (CP) of Google OR tools 9.8, both executing with a time limit of 3600 seconds. ", "page_idx": 6}, {"type": "text", "text": "For lack of space, we compare our methodology against other learning proposals in App. B. ", "page_idx": 6}, {"type": "text", "text": "5.2 Performance on Benchmarks ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This section evaluates the performance of our generative Graph Model (GM), configured and trained with SLIM as explained in Sec. 5.1. When contrasted with greedy approaches, our GM generates a single solution by picking the job with the highest probability. In the other comparisons, we randomly sample 128 $\\mathrm{(GM_{128})}$ and 512 $\\operatorname{(GM_{512})}$ solutions as explained in Sec. 4.1. Note that we coded our GM, PDRs, INSA, SBH, MIP, and CP; while we reported results from original papers of all the ML competitors but L2D, for which we used the open-source code to generate randomized solutions. ", "page_idx": 6}, {"type": "text", "text": "Tab. 2 presents the comparison of algorithms on Taillard\u2019s and Demirkol\u2019s benchmarks, each arranged in a distinct horizontal section. The table is vertically divided into Greedy Constructive, Multiple (Randomized) Constructive, and Non-constructive Approaches; with the results of algorithms categorized accordingly. Each row reports the average PG (the lower the better) on a specific instance shape while the last row (Avg) reports the average gap across all instances, regardless of their shapes. ", "page_idx": 6}, {"type": "text", "text": "This table shows that our GM and CL produce lower gaps than PDRs, INSA, and SBH in both the greedy and randomized cases, proving the superiority of neural constructive approaches. Surprisingly, ", "page_idx": 6}, {"type": "table", "img_path": "buqvMT3B4k/tmp/cfa725a99f8b1f5c377dd1da88a1be3706b2ff742d032cd80bee96b58536991e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Table 3: The average gaps when sampling 128 solutions from architectures trained without and with self-labeling. CLUCL is the model obtained in [25] by training with reward-to-go on random instance shapes (no curriculum learning) and CL is similarly obtained by applying curriculum learning. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "image", "img_path": "buqvMT3B4k/tmp/e2b956d48fe0b1b7a60b7e86685269f2876e1aa764a91760f3040f7202001aa1.jpg", "img_caption": ["Figure 2: GM validation curves when trained with PPO and our SLIM in the same training setting of [54]. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "INSA and PDRs outperform L2D. This is likely related to how PDRs were coded in [54], where ours align with those in [25]. Focusing on our GM, we observe that it consistently archives lower gaps than all the greedy approaches and, when applied in a randomized manner $\\mathrm{(GM_{128})}$ , it outperforms all the randomized constructives. Notably, the GM generalizes well to instance shapes larger than training ones (marked with \\* in Tab. 2), as its gaps do not progressively increase on such shapes. ", "page_idx": 7}, {"type": "text", "text": "Our GM is also competitive when compared with non-constructive approaches. The $\\mathrm{GM_{512}}$ largely outperforms the $\\mathrm{NLS}_{A}$ and ${\\mathrm{L}}2{\\mathrm{S}}_{500}$ metaheuristics, and roughly align with ${\\mathrm{L}}2{\\mathrm{S}}_{5k}$ visiting 5000 solutions. On shapes larger than $20\\times20$ , the $\\mathrm{GM_{512}}$ remarkably achieves lower gaps with just a few seconds of computations than a MIP executing for 3600 sec. Therefore, we conclude that our methodology, encompassing the proposed GM and SLIM, is effective in solving the JSP. ", "page_idx": 7}, {"type": "text", "text": "As already observed in [25, 55], our GM and other neural constructive approaches are generally outperformed by CP and state-of-the-art metaheuristics, e.g., [36]. Although the performance gap is steadily narrowing, the higher complexity of CP solvers renders them more powerful, albeit at the cost of longer execution time (often dozens of minutes). Therefore, neural constructive approaches may be preferable whenever a quality solution must be provided in a few minutes. ", "page_idx": 7}, {"type": "text", "text": "We refer the reader to Apps. D and E for statistical considerations and a comparison between our GM and CP on extremely large instances, respectively. ", "page_idx": 7}, {"type": "text", "text": "6 A Closer Look at SLIM ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "This section studies additional aspects of our proposed methodology. For these evaluations, we adopt the same setting described in Sec. 5.1 and explicitly indicate the varied aspects and parameters. ", "page_idx": 7}, {"type": "text", "text": "6.1 Self-Labeling other Architectures ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "To demonstrate the generality of our self-labeling improvement method beyond the proposed Graph Model (GM), we use it to train other architectures as described in Sec. 5.1. Specifically, we train the model proposed in [25] $(\\mathrm{CL}_{\\mathrm{SL}})$ and a variation of our GM (named $\\mathrm{{FNN}_{S L}}$ ), where we replaced the Graph Attention and Multi-Head Attention layers with linear projections (ReLU activated) by maintaining the same hidden dimensionalities. Tab. 3 reports the average gap of $\\mathrm{CL}_{\\mathrm{SL}}$ , $\\mathrm{FNN_{SL}}$ , and GM on each benchmark. As baselines for comparison, we also include the average gap of CL and CLUCL reported in [25], the latter being trained without curriculum learning similarly to our setting. ", "page_idx": 7}, {"type": "text", "text": "Tab. 3 shows that $\\mathrm{CL}_{\\mathrm{SL}}$ nearly matches the performance of CL even without curriculum learning. Note that we intentionally avoided applying curriculum learning to eliminate potential biases when demonstrating the contribution of our self-labeling strategy. Furthermore, we observe that both $\\mathrm{FNN}_{\\mathrm{SL}}$ and GM outperform CL, with GM achieving the best overall performance. Therefore, we conclude that SLIM can successfully train well-designed architectures for the JSP. ", "page_idx": 7}, {"type": "text", "text": "6.2 Comparison with Proximal Policy Optimization ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The previous Sec. 6.1 proved the quality of our GM when trained with SLIM. As Proximal Policy Optimization (PPO) is extensively used to train neural algorithms for scheduling problems (see Sec. 2), we contrast the GM\u2019s performance when trained with PPO and our self-labeling strategy (SLIM- $\\cdot\\beta$ with $\\beta\\in\\{32,64,128\\bar{\\})$ . For this evaluation, we adopt the same hyper-parameters of [54] for both ", "page_idx": 7}, {"type": "image", "img_path": "buqvMT3B4k/tmp/18fad6fac4823e641b0c8240ed66a30b334e36590ede9852fd3ea4c33054071a.jpg", "img_caption": ["Figure 3: The GM performance when trained by sam-Figure 4: The GM performance (trained as in Sec. 5.1) pling varying number of solutions $\\beta$ . For each shape,for varying numbers of sampled solutions $\\beta$ at test time. we report the average PG on instances of both bench-For each shape, we report the average PG on instances marks by sampling 512 solutions during testing. of both benchmarks. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "PPO and SLIM by training on 40 000 random instances of shape $30\\times20$ (same training of L2D [54]). We only double the batch size to 8 to reduce training noise. Fig. 2 reports the validation curves obtained by testing the GM on Taillard\u2019s benchmark every 100 training steps. We test by sampling 128 solutions and we also include the randomized results of L2D (dashed line) as a baseline for comparisons. From Fig. 2, we observe that training with our self-labeling improvement method results in faster convergence and produces better final models. ", "page_idx": 8}, {"type": "text", "text": "We justify this by hypothesizing that the reward received from partial solutions (makespan increments) may not always provide reliable guidance on how to construct the best final solution. While constructing a solution, the critical path may change with implications on past rewards. Our self-labeling strategy does not rely on partial rewards and may avoid such a source of additional \u201cnoise\". Note that this is only an intuition, proving it would require a deeper analysis, which we refer to in future works. Finally, we stress that we do not claim SLIM is superior to PPO. Instead, we believe it offers an alternative that provides a fresh perspective and potential for integration with existing RL algorithms to advance the neural combinatorial optimization field. ", "page_idx": 8}, {"type": "text", "text": "6.3 The Effect of $\\beta$ on Training ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "As our self-labeling improvement method is based on sampling, we assess the impact of sampling a different number of solutions $\\beta$ while training. We retrain a new GM as described in Sec. 5.1 with a number of solutions $\\beta\\in\\{32,64,128,256\\}$ , where we stop at 256 as the memory usage with larger values becomes impractical. We test the resulting models by sampling 512 solutions on all the instances of both benchmarks for a broader assessment. Fig. 3 reports the average PG (the lower the better) of the trained GM (colored markers) on each shape. To ease comparisons, we also include the results of CL (dashed line) \u2013 the second-best ML proposal in Tab. 2 \u2013 and the MIP (dotted line). ", "page_idx": 8}, {"type": "text", "text": "Overall, we see that training by sampling more solutions slightly improves the model\u2019s performance, as outlined by lower PGs for increasing $\\beta$ . We also observe that such improvement is less marked on shapes seen in training, such as in $15\\times15,20\\times15$ , and $20\\times20$ shapes, and more marked on others. This suggests that training by sampling more solutions results in better generalization, although it is more memory-demanding. However, the GM\u2019s trends observed in Tab. 2 remain consistent with smaller $\\beta$ , proving the robustness of SLIM to variations in the number of sampled solutions $\\beta$ . ", "page_idx": 8}, {"type": "text", "text": "6.4 The Effect of $\\beta$ on Testing ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We also assess how the number of sampled solutions $\\beta$ impacts the GM performance at test time. To evaluate such an impact, we plot in Fig. 4 the average PG on different shapes for varying $\\beta\\in\\{32,64,128,256,512\\}$ . For this analysis, we use the GM trained by sampling 256 solutions, the one of Tab. 2. As in Sec. 6.3, we also report the results of CL and MIP to ease the comparison. ", "page_idx": 8}, {"type": "text", "text": "Despite the reduced number of solutions, the GM remains a better alternative than CL \u2013 the best RL proposal \u2013 and still outperforms the MIP on medium and large instances. Not surprisingly, by sampling more solutions the GM performance keeps improving at the cost of increased execution times. Although we verified that sampling more than 512 solutions further improves results (see bottom of App. F), we decided to stop at $\\beta=512$ as a good trade-off between performance and time. We refer the reader to App. F for other timing considerations. ", "page_idx": 8}, {"type": "text", "text": "Finally, we provide a brief analysis to demonstrate the broader applicability of our selflabeling improvement method to other combinatorial problems. Thus, we evaluate SLIM on the Traveling Salesman Problem (TSP), a cornerstone in neural combinatorial optimization research [5, 50, 35], by using it to train the wellknown Attention Model [27] on TSP instances with 20 nodes. To assess SLIM\u2019s performance, we compare it against the established Policy Optimization with Multiple Optima (POMO) approach [30]. We train the Attention Model with both SLIM and POMO, using the same hyperparameters and sampling strategy outlined in [30]. Training is carried out over 100,000 steps (equivalent to 1 epoch in [30]) by generating batches of 32 instances at each step. ", "page_idx": 9}, {"type": "image", "img_path": "buqvMT3B4k/tmp/d0a95986ae959ecb0b972dd089f1cab401cbb66f807a07bb68542b80c4f85d0d.jpg", "img_caption": ["Figure 5: Validation curves obtained by training with SLIM and POMO on random TSP instances with 20 nodes. POMO20 is the best model produced in [30], trained on instances with 20 nodes. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Fig. 5 presents the validation curves of SLIM and POMO obtained by testing the model every 100 steps on small instances (with up to 100 nodes) from the TSPLIB [41]. The results are reported in terms of the average optimality gap and, as a baseline for comparison, we include the performance of the best model in [30] (POMO20) trained for hundreds of epochs. As shown, SLIM achieves faster convergence than POMO and produces a model comparable to POMO20 after just one epoch, thereby demonstrating that SLIM can be effective in other combinatorial problems. ", "page_idx": 9}, {"type": "text", "text": "7 Limitations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Despite the proven effectiveness of SLIM, it is important to note that only one of the sampled solutions per training instance is used to update the model. This approach may be sub-optimal from an efficiency standpoint. Therefore, we see significant potential in hybridizing our self-labeling strategy with existing (RL) methods to mitigate this inefficiency. Moreover, sampling multiple solutions during training requires substantial memory, which can limit batch sizes. Although we have shown that SLIM remains effective with a small number of sampled solutions (see Sec. 6.3), increasing their number accelerates training convergence and improves the resulting model. Consequently, developing new strategies that can sample higher-quality solutions without generating numerous random ones is a promising future direction. Such advancements could reduce memory usage and further enhance our methodology as well as others in the literature. ", "page_idx": 9}, {"type": "text", "text": "8 Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The key contribution of this work is the introduction of SLIM, a novel Self-Labeling Improvement Method to train generative models for the JSP and other combinatorial problems. Additionally, an efficient encoder-decoder architecture is presented to rapidly generate parallel solutions for the JSP. Despite its simplicity, our methodology significantly outperformed many constructive and learning algorithms for the JSP, even surpassing a powerful MIP solver. However, as a constructive approach, it still lags behind state-of-the-art approaches like constraint programming solvers, which nevertheless require more time. We also proved the robustness of SLIM across various parameters and architectures, and its generality by applying it successfully to the Traveling Salesman Problem. ", "page_idx": 9}, {"type": "text", "text": "More broadly, self-labeling might be a valuable training strategy as it eliminates the need for optimality information or the precise formulation of a Markov Decision Process. For instance, given a designed generative model (i.e., a constructive algorithm whose decisions are taken by a neural network), this strategy can be applied as-is to combinatorial problems with unconventional objectives or a combination of objective functions. In contrast, RL approaches require the careful definition of a meaningful reward function, which is often a complex and challenging task. ", "page_idx": 9}, {"type": "text", "text": "In future, we intend to apply our methodology to other shop scheduling and combinatorial problems as well as explore combinations of our self-supervised strategy with other existing learning approaches. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Joseph Adams, Egon Balas, and Daniel Zawack. The Shifting Bottleneck Procedure for Job Shop Scheduling. Management Science, 34, 1988.   \n[2] Yuki M. Asano, Christian Rupprecht, and Andrea Vedaldi. Self-labelling via simultaneous clustering and representation learning. In International Conference on Learning Representations, 2020.   \n[3] Egon Balas. Machine sequencing via disjunctive graphs: an implicit enumeration algorithm. Operations Research, 17, 1969. [4] Irwan Bello, Hieu Pham, Quoc V Le, Mohammad Norouzi, and Samy Bengio. Neural combinatorial optimization with reinforcement learning. International Conference on Learning Representations, 2017. [5] Yoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial optimization: A methodological tour d\u2019horizon. European Journal of Operational Research, 290, 2021. [6] Christian Blum and Andrea Roli. Metaheuristics in combinatorial optimization: Overview and conceptual comparison. ACM computing surveys (CSUR), 35, 2003.   \n[7] Zdravko I. Botev, Dirk P. Kroese, Reuven Y. Rubinstein, and Pierre L\u2019Ecuyer. The Cross-Entropy Method for Optimization. In Handbook of Statistics, volume 31. Elsevier, 2013. [8] Shaked Brody, Uri Alon, and Eran Yahav. How Attentive are Graph Attention Networks? In International Conference on Learning Representations, 2022. [9] Quentin Cappart, Didier Ch\u00e9telat, Elias B. Khalil, Andrea Lodi, Christopher Morris, and Petar Veli\u02c7ckovi\u00b4c. Combinatorial Optimization and Reasoning with Graph Neural Networks. In Proceedings of the International Joint Conference on Artificial Intelligence, 2021.   \n[10] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. Deep clustering for unsupervised learning of visual features. In Proceedings of the European Conference on Computer Vision, 2018.   \n[11] Ruiqi Chen, Wenxin Li, and Hongbing Yang. A Deep Reinforcement Learning Framework Based on an Attention Mechanism and Disjunctive Graph Embedding for the Job-Shop Scheduling Problem. IEEE Transactions on Industrial Informatics, 19, 2023.   \n[12] Xinyun Chen and Yuandong Tian. Learning to Perform Local Rewriting for Combinatorial Optimization. Advances in Neural Information Processing Systems, 32, 2019.   \n[13] Runwei Cheng, Mitsuo Gen, and Yasuhiro Tsujimura. A tutorial survey of job-shop scheduling problems using genetic algorithms, part II: hybrid genetic search strategies. Computers & Industrial Engineering, 36, 1999.   \n[14] Andrea Corsini, Simone Calderara, and Mauro Dell\u2019Amico. Learning the Quality of Machine Permutations in Job Shop Scheduling. IEEE Access, 10, 2022.   \n[15] Pieter-Tjerk De Boer, Dirk P Kroese, Shie Mannor, and Reuven Y Rubinstein. A tutorial on the cross-entropy method. Annals of operations research, 134, 2005.   \n[16] Ebru Demirkol, Sanjay Mehta, and Reha Uzsoy. Benchmarks for shop scheduling problems. European Journal of Operational Research, 109, 1998.   \n[17] Jonas K Falkner, Daniela Thyssens, Ahmad Bdeir, and Lars Schmidt-Thieme. Learning to Control Local Search for Combinatorial Optimization. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer, 2022.   \n[18] Jonas K. Falkner, Daniela Thyssens, Ahmad Bdeir, and Lars Schmidt-Thieme. Learning to control local search for combinatorial optimization. In Machine Learning and Knowledge Discovery in Databases, 2023. ", "page_idx": 10}, {"type": "text", "text": "[19] Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. MIT Press, 2016. ", "page_idx": 11}, {"type": "text", "text": "[20] Bao-An Han and Jian-Jun Yang. Research on Adaptive Job Shop Scheduling Problems Based on Dueling Double DQN. IEEE Access, 8, 2020.   \n[21] Reinhard Haupt. A survey of priority rule-based scheduling. Operations Research Spektrum, 11, 1989.   \n[22] Peter Henderson, Riashat Islam, Philip Bachman, Joelle Pineau, Doina Precup, and David Meger. Deep Reinforcement Learning That Matters. Proceedings of the AAAI Conference on Artificial Intelligence, 32, 2018.   \n[23] Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The Curious Case of Neural Text Degeneration. In International Conference on Learning Representations, 2020.   \n[24] Kuo-Ling Huang and Ching-Jong Liao. Ant colony optimization combined with taboo search for the job shop scheduling problem. Computers & Operations Research, 35, 2008.   \n[25] Zangir Iklassov, Dmitrii Medvedev, Ruben Solozabal Ochoa de Retana, and Martin Takac. On the Study of Curriculum Learning for Inferring Dispatching Policies on the Job Shop Scheduling. In Proceedings of the International Joint Conference on Artificial Intelligence, 2023.   \n[26] Helga Ingimundardottir and Thomas Philip Runarsson. Discovering Dispatching Rules from Data Using Imitation Learning: A Case Study for the Job-Shop Problem. Journal of Scheduling, 21, 2018.   \n[27] Wouter Kool, Herke Van Hoof, and Max Welling. Attention, learn to solve routing problems! In International Conference on Learning Representations, 2018.   \n[28] James Kotary, Ferdinando Fioretto, and Pascal Van Hentenryck. Fast approximations for job shop scheduling: A lagrangian dual deep learning method. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, 2022.   \n[29] Wen-Yang Ku and J. Christopher Beck. Mixed Integer Programming models for job shop scheduling: A computational analysis. Computers & Operations Research, 73, 2016.   \n[30] Yeong-Dae Kwon, Jinho Choo, Byoungjip Kim, Iljoo Yoon, Youngjune Gwon, and Seungjai Min. Pomo: Policy optimization with multiple optima for reinforcement learning. Advances in Neural Information Processing Systems, 33, 2020.   \n[31] Dong-Hyun Lee et al. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3, 2013.   \n[32] Xiao Liu, Fanjin Zhang, Zhenyu Hou, Li Mian, Zhaoyu Wang, Jing Zhang, and Jie Tang. Self-Supervised Learning: Generative or Contrastive. IEEE Transactions on Knowledge and Data Engineering, 35, 2023.   \n[33] Nina Mazyavkina, Sergey Sviridov, Sergei Ivanov, and Evgeny Burnaev. Reinforcement learning for combinatorial optimization: A survey. Computers & Operations Research, 134, 2021.   \n[34] Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy Lillicrap, Tim Harley, David Silver, and Koray Kavukcuoglu. Asynchronous methods for deep reinforcement learning. In International Conference on Machine Learning, 2016.   \n[35] Mohammadreza Nazari, Afshin Oroojlooy, Lawrence Snyder, and Martin Tak\u00e1c. Reinforcement learning for solving the vehicle routing problem. Advances in Neural Information Processing Systems, 31, 2018.   \n[36] Eugeniusz Nowicki and Czeslaw Smutnicki. A Fast Taboo Search Algorithm for the Job Shop Problem. Management Science, 42, 1996.   \n[37] Eugeniusz Nowicki and Czeslaw Smutnicki. An Advanced Tabu Search Algorithm for the Job Shop Problem. Journal of Scheduling, 8, 2005.   \n[38] Achraf Oussidi and Azeddine Elhassouny. Deep generative models: Survey. In International Conference on Intelligent Systems and Computer Vision, 2018.   \n[39] Junyoung Park, Jaehyeong Chun, Sang Kim, Youngkook Kim, and Jinkyoo Park. Learning to schedule job-shop problems: representation and policy learning using graph neural network and reinforcement learning. International Journal of Production Research, 59, 2021.   \n[40] M.L. Pinedo. Scheduling: Theory, Algorithms, and Systems. SpringerLink : B\u00fccher. Springer New York, 2012.   \n[41] Gerhard Reinelt. TSPLIB\u2014A traveling salesman problem library. ORSA journal on computing, 3, 1991.   \n[42] Daniel Alejandro Rossit, Fernando Tohm\u00e9, and Mariano Frutos. The Non-Permutation FlowShop scheduling problem: A literature review. Omega, 77, 2018.   \n[43] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.   \n[44] Lawrence Stephen. Resource constrained project scheduling: an experimental investigation of heuristic scheduling techniques (Supplement). Graduate School of Industrial Administrationa, 1984.   \n[45] Richard S Sutton and Andrew G Barto. Reinforcement learning: An introduction. MIT press, 2018.   \n[46] Eric Taillard. Benchmarks for basic scheduling problems. European Journal of Operational Research, 64, 1993.   \n[47] Pierre Tassel, Martin Gebser, and Konstantin Schekotihin. An End-to-End Reinforcement Learning Approach for Job-Shop Scheduling Problems Based on Constraint Programming. Proceedings of the International Conference on Automated Planning and Scheduling, 33, 2023.   \n[48] Jesper E Van Engelen and Holger H Hoos. A survey on semi-supervised learning. Machine learning, 109, 2020.   \n[49] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in Neural Information Processing Systems, 30, 2017.   \n[50] Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. Advances in Neural Information Processing Systems, 28, 2015.   \n[51] Libing Wang, Xin Hu, Yin Wang, Sujie Xu, Shijun Ma, Kexin Yang, Zhijun Liu, and Weidong Wang. Dynamic job-shop scheduling in smart manufacturing using deep reinforcement learning. Computer Networks, 190, 2021.   \n[52] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S. Yu. A Comprehensive Survey on Graph Neural Networks. IEEE Transactions on Neural Networks and Learning Systems, 32, 2021.   \n[53] Jin Xie, Liang Gao, Kunkun Peng, Xinyu Li, and Haoran Li. Review on flexible job shop scheduling. IET collaborative intelligent manufacturing, 1, 2019.   \n[54] Cong Zhang, Wen Song, Zhiguang Cao, Jie Zhang, Puay Siew Tan, and Xu Chi. Learning to dispatch for job shop scheduling via deep reinforcement learning. Advances in Neural Information Processing Systems, 33, 2020.   \n[55] Cong Zhang, Zhiguang Cao, Wen Song, Yaoxin Wu, and Jie Zhang. Deep Reinforcement Learning Guided Improvement Heuristic for Job Shop Scheduling. In International Conference on Learning Representations, 2024.   \n[56] Jian Zhang, Guofu Ding, Yisheng Zou, Shengfeng Qin, and Jianlin Fu. Review of job shop scheduling research and its new perspectives under Industry 4.0. Journal of Intelligent Manufacturing, 30, 2019.   \n[57] Zichen Zhang, Jun Jin, Martin Jagersand, Jun Luo, and Dale Schuurmans. A Simple Decentralized Cross-Entropy Method. Advances in Neural Information Processing Systems, 35, 2022.   \n[58] Runlong Zhou, Yuandong Tian, Yi Wu, and Simon Shaolei Du. Understanding Curriculum Learning in Policy Optimization for Online Combinatorial Optimization. In NeurIPS Workshop: Optimization for Machine Learning, 2022. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "table", "img_path": "buqvMT3B4k/tmp/0ca8ad095790dce087ee14d8f6a0bd1d245d96a4638187764502bb1879c48f96.jpg", "table_caption": ["Table 4: The features $x_{i}~\\in~\\mathbb{R}^{15}$ associated with a vertex $i\\in V$ of the disjunctive graph $G$ that provide information about operation $i$ in the instance. Recall that $\\tau_{i}$ represents the processing time of operation $i$ , and $\\mu_{i}$ denotes the machine on which the operation is performed. "], "table_footnote": [], "page_idx": 14}, {"type": "table", "img_path": "buqvMT3B4k/tmp/e803ff8879bdb2f4aa2a2e7e1eabda2db7f89343c6c90c534535733a42dca1db.jpg", "table_caption": ["Table 5: The average PG of greedy constructive approaches on the same two Taillard\u2019s instances of the ten available for each shape, as utilized in [20, 11]. We highlight in bold the best PG on each instance shape. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "A Disjunctive Graph Features ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Following ML works reviewed in Sec. 2, we augment the standard disjunctive graph representation of a JSP instance by incorporating additional features for each vertex $i\\in V$ . Tab. 4 details these features. Some features, such as features 1-3, have been adapted from previous works [54, 39], while others have been introduced by us to better model JSP concepts like machines and jobs. For instance, features 4-6 take the same value for operations of the same job, emphasizing which operations belong to different jobs, while features 7-9 do the same for operations to be performed on the same machine. ", "page_idx": 14}, {"type": "text", "text": "Note that these features as well as those outlined in Tab. 1 can also be used for other shop scheduling problems, including Flow Shop, Flexible Flow Shop, and Flexible Job Shop. ", "page_idx": 14}, {"type": "text", "text": "B Additional Comparisons with Neural Algorithms ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We additionally consider learning proposals reviewed in Sec. 2, which were tested only on a few benchmark instances or which could not be included in Tab. 2 due to how results are disclosed. ", "page_idx": 14}, {"type": "text", "text": "Regarding proposals not included in Tab. 2, we highlight that our GM outperforms the Graph Neural Network in [39] that exhibits a significantly higher average gap of $19.5\\%$ on Taillard\u2019s benchmark. Note that only qualitative results are disclosed in [39], we did our best to report them. Similarly, we remark that the GM performance is superior to the proposal in [47] (hCP), mixing RL and constraint programming. hCP achieves an average makespan of 2670 and 5701 on Taillard and Demirkol benchmarks respectively, while our greedy GM yet obtains an average of 2642 and 5581. ", "page_idx": 14}, {"type": "text", "text": "As some other learning proposals like [11, 20] were tested only on certain benchmark instances, we provide an additional evaluation on such instances for a fair comparison. We include in Tab. 5 the average PGs of greedy constructive approaches on the two Taillard\u2019s instances of each shape used in the Transformer (TRL) proposal of [11] and the Deep Q-Network (DQN) of [20]. On this subset of instances, we see that TRL is the worst-performing approach and that DQN roughly aligns with CL. As our GM is always the best or second best algorithm on each shape, it achieves the lowest overall average gap (Avg). ", "page_idx": 14}, {"type": "table", "img_path": "buqvMT3B4k/tmp/96e5807410150dee4b132841c6702f5ebf9cc78e8f3a1b511594842fb883e90e.jpg", "table_caption": ["Table 6: The average PGs of the algorithms on Lawrence\u2019s benchmark. For each row, we highlight in blue and bold the lowest (best) constructive and non-constructive gap, respectively. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "buqvMT3B4k/tmp/c9d77f379b7dd452e39e5ceeb2f9941069d2787162b2a5eda35b5982c148b4d3.jpg", "table_caption": ["Table 7: The average PG and its standard deviation $(a v g\\ \\pm\\ s t d)$ of the best four multiple (randomized) constructive and non-constructive algorithms on Taillard\u2019s benchmark. We highlight in blue (bold) the best constructive (non-constructive) gap. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "C Performance on Lawrence\u2019s Benchmark ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Lawrence\u2019s benchmark has been extensively used in the JSP literature to develop various resolution approaches, e.g. [1, 36, 55]. This benchmark includes 40 instances of 8 different shapes and features smaller (and easier) instances compared to the Taillard\u2019s and Demirkol\u2019s ones. To complement the evaluation of Sec. 5.2 on small instances, we provide in Tab. 6 a comparison of approaches included in Tab. 2 on Lawrence\u2019s benchmark. Note that we could not include CL and $\\mathrm{NLS}_{A}$ as they were not tested on these instances. ", "page_idx": 15}, {"type": "text", "text": "Tab. 6 shows that our GM remains the best constructive approach for small instances. However, we observe that ${\\mathrm{L}}2{\\mathrm{S}}_{5k}$ achieves slightly better results than $\\mathrm{GM_{512}}$ at the cost of significantly longer execution times. Specifically, $\\mathrm{L2S_{5k}}$ always requires more than 70 sec on such instance shapes (as reported in [55]), whereas our $\\mathrm{GM_{512}}$ always completes in less than 0.5 sec (see also App. F for timing considerations). Finally, we highlight that on small instances like those in Lawrence\u2019s benchmark, exact methods such as MIP and CP can effectively solve them to optimality. ", "page_idx": 15}, {"type": "text", "text": "D Statistical Analysis ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Due to space constraints, we evaluate algorithms in Tab. 2 solely in terms of average gaps. This approach is justified as the average trends are consistent with other statistical measures. For example, Tab. 7 reports the average and standard deviation of the best four multiple (randomized) constructive and non-constructive approaches on Taillard\u2019s benchmark. We omit Demirkol\u2019s instances since not all algorithms report results for them. Each row in Tab. 7 presents the average gap and standard deviation for instances of a specific shape, but the last row, which reports the average and standard deviation on all instances, regardless of their shapes. This table confirms that the observations made for Tab. 2 remain valid when considering standard deviations. Specifically, $\\mathrm{GM_{512}}$ remains the best constructive approach, aligning closely with the RL-enhanced metaheuristic $\\mathrm{L2S_{5k}}$ . The MIP still has worse overall performance than $\\mathrm{GM_{512}}$ while CP produces the best average gaps and standard deviations. ", "page_idx": 15}, {"type": "table", "img_path": "buqvMT3B4k/tmp/481b270cdee86913eb5864ddf80602e1e503968ed18c3b3c63cd388f93011e41.jpg", "table_caption": ["Table 8: Average makespan $(a v g\\,\\pm\\,s t d)$ and execution time of CP-Sat and our GM (when sampling $\\beta=512$ solutions) on very large instances. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "E Extremely Large Instances ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "As shown in Tab. 2, constructive approaches are generally inferior to state-of-the-art metaheuristics [36] (see also [55]), Mixed Integer Programming (MIP) [29], and Constraint Programming (CP) solvers. These resolution methods employ more complex frameworks, making them more effective for solving combinatorial problems. However, neural constructive approaches are continuously closing the gap as remarked by the GM\u2019s performance matching that of MIP solvers. Herein, we also prove that our GM generally produces better results than CP solvers on very large instances. ", "page_idx": 16}, {"type": "text", "text": "To this end, we randomly generated 20 JSP instances with shapes $\\{200\\,\\times\\,20,200\\,\\times\\,40,500\\,\\times$ $20,500\\times40\\}$ and solved them with the CP-Sat solver of Google OR-tools 9.8, executing for 1 hour, and our GM (trained as described in Sec. 5.1), sampling $\\beta=512$ solutions. Tab. 8 reports the average execution time $(t i m e)$ , the average makespan and its standard deviation $\\left(C_{m a x}\\right)$ of CP-Sat and our $\\mathrm{GM_{512}}$ on each shape. The last row (Gap sum from CP-Sat) offers a relative comparison by summing up the gaps of the $\\mathrm{GM_{512}}$ computed from the solutions produced by CP-Sat. A negative value means that the GM produced better solutions. ", "page_idx": 16}, {"type": "text", "text": "As one can see, the $\\mathrm{GM_{512}}$ produces better average results than CP-Sat with just a fraction of time. On these 80 instances, we observed only 7 cases in which the solutions of CP-Sat are slightly better than those of the GM. This remarks once more the quality of our proposal, making it a valid alternative to CP solvers for extremely large instances. ", "page_idx": 16}, {"type": "text", "text": "Lastly, we remark that on these large instances, the execution times of our GM can be further reduced by employing speed-up techniques such as model quantization (i.e., converting floats to lower precision numbers) and the new compile functionality available in PyTorch $\\geq2.0$ . Our model did not undergo any of the above (herein and in any other evaluation) and has been coded by keeping the implementation as simple as possible. ", "page_idx": 16}, {"type": "text", "text": "F Execution Times ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We additionally assess the timing factor, an important aspect in some scheduling scenarios. To this end, we plot in the left of Fig. 6 the execution time trends of dispatching rules (PDR), INSA, L2D (we omit CL as it has slightly higher execution times than L2D), and GM on typical benchmark shapes, all applied in a greedy constructive manner. We also include the execution time of our GM when sampling 512 solutions $(\\mathrm{GM}_{\\mathrm{512}})$ to prove that sampling multiple parallel solutions does not dramatically increase times. Note that all these algorithms were executed on the machine described at the beginning of Sec. 5. We omit other RL proposals as they do not publicly release the code, do not disclose execution times, or is unclear whether they used GPUs. ", "page_idx": 16}, {"type": "text", "text": "When sampling 512 solutions, the $\\mathrm{GM_{512}}$ takes less than a second on medium shapes, less than 3 sec on large ones, and around 10 sec on the big $100\\times20$ . As these trends align with L2D, which only constructs a single solution, our GM is a much faster neural alternative, despite being also better in terms of quality. We also underline that the GM and any ML-based approach are likely to be slower than PDRs and constructive heuristics, either applied in a greedy or randomized way. One can see that such approaches work faster: PDRs take 0.2 sec and INSA 1.61 sec on $100\\times20$ instances. However, this increase in execution time is not dramatic and is largely justified by better performance, especially in the case of our GM. ", "page_idx": 16}, {"type": "image", "img_path": "buqvMT3B4k/tmp/013e54118516dbabb503a2e5344c8178fb8cbe335ce0e7f7619d072b21d3cbe3.jpg", "img_caption": ["Figure 6: The average execution time in seconds of the coded algorithms on different instance shapes considered in Tab. 2. The times of PDRs, INSA, L2D, and CL refer to the construct of a single solution. Whereas we report the times of the GM for varying numbers of sampled solution $\\beta\\in\\{1,32,64,128,256,512\\}$ . "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "We finally provide in the right table of Fig. 6 the precise GM timing for varying numbers of sampled solutions $\\beta$ during testing. Each row reports the average execution time on a benchmark shape and the last row (Tot Sum) sums up all the times for an overall comparison. We observe that sampling 32 and 64 solutions from the GM takes the same except in large instances $50\\times15$ , $50\\times20$ , and $100\\times20$ shapes), where variations are small. Therefore, sampling less than 32 solutions is pointless, as the reduction in the execution times is negligible while the quality is further reduced. Additionally, sampling more than 512 solutions further improves the GM\u2019s results at the cost of a consistent increment in the execution time. As an example, by sampling 1024 solutions, the overall average gap (Avg row in Tab. 2) is reduced by $0.4\\%$ in both benchmarks with respect to the $\\beta=512$ case, but the execution time is roughly 1.9 times larger. Instead of blindly sampling many random solutions with long executions, it should be possible to achieve better results in less time with ad-hoc strategies, such as Beam-Search or other strategies, that sample differently based on the generated probabilities or other information. We leave this study on testing strategies to future work. ", "page_idx": 17}, {"type": "text", "text": "G Extended Results ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The extended results of the coded algorithms (PDRs, INSA, SBH, L2D, MIP, CP, and the GM\u2019s configurations) are available at 2. For computing the percentage gap (PG), we used the optimal or best-known makespan of an instance $\\left(C_{u b}\\right)$ , available at: https://optimizizer.com/ jobshop.php. The extended results highlight that models trained using our Self-Labeling strategy with $\\beta<256$ exhibit competitive performance and, in some instances, even surpass the model trained with $\\beta=256$ . This indicates the efficacy of our strategy even with a reduced number of sampled solutions. However, as remarked in the paper, sampling a larger number of training solutions yields improved overall performance, as evidenced by the lower total sums observed for larger values of $\\beta$ . ", "page_idx": 17}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 18}, {"type": "text", "text": "Justification: The abstract and introduction in Sec. 1 present the intuitions that guided our work and the assumptions behind it. All these statements are used throughout the paper and backed up by the main results and additional studies provided respectively in Secs. 5 and 6. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: We discussed limitations in Sec. 7 and used them to point out potential future improvements. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 18}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 19}, {"type": "text", "text": "Justification: The paper does not provide theoretical results. Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We provided necessary information to reproduce experiments in Secs. 4.1, 5.1, 5.2 and 6. We also included our code and dataset to maximize reproducibility and cross-comparisons. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 19}, {"type": "text", "text": "Justification: We included a link to the GitHub repository containing the code, trained models, and the created dataset. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 20}, {"type": "text", "text": "Justification: We described the adopted experimental details in Sec. 5.1 and at the beginning of Sec. 5.2. Any modifications to this setup, as in the studies presented in Sec. 6, are explicitly described where they occur. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 20}, {"type": "text", "text": "Justification: We provided statistical considerations in App. D. In addition, we exposed our methodologies to various training regimes and models in the additional studies of Sec. 6, demonstrating the significance of our contribution in different setups. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 21}, {"type": "text", "text": "Justification: We provided information about the employed computational resources at the beginning of Sec. 5. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 21}, {"type": "text", "text": "Justification: We did all our best to adhere to the NeurIPS Code of Ethics. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 21}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 21}, {"type": "text", "text": "Justification: We briefly motivated at the beginning of Sec. 1 why tackling the Job Shop Scheduling problem is of concern for the community. Additionally, we provided an analysis in Appendix E on potential practical applications and pointed out extensions to other combinatorial problems in Sec. 8. Note however that discussing the societal impacts is outside the scope or our work and is largely addressed by surveys papers on such problems. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 21}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 22}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We properly referenced throughout the paper the creators of original code and assets, like in Secs. 5.1 and 6.1. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We provided the necessary details of assets (like models and dataset) produced by our research in the body of the paper (e.g., Sec. 5.1), and we included additional documentation in the released code. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}]