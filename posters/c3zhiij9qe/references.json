{"references": [{"fullname_first_author": "Ajay Mandlekar", "paper_title": "Learning to generalize across long-horizon tasks from human demonstrations", "publication_date": "2020-03-00", "reason": "This paper is foundational to the field of long-horizon visual imitation learning, introducing a key challenge addressed by VLMimic."}, {"fullname_first_author": "Tete Xiao", "paper_title": "Masked visual pre-training for motor control", "publication_date": "2022-03-00", "reason": "This paper introduces a novel visual representation learning method using masking, a technique that is relevant to VLMimic's approach to visual grounding."}, {"fullname_first_author": "Suraj Nair", "paper_title": "R3M: A universal visual representation for robot manipulation", "publication_date": "2022-03-00", "reason": "R3M is a strong baseline for visual imitation learning, and its performance is compared directly to VLMimic's in the paper."}, {"fullname_first_author": "Cheng Chi", "paper_title": "Diffusion policy: Visuomotor policy learning via action diffusion", "publication_date": "2023-03-00", "reason": "This paper presents a state-of-the-art diffusion-based policy learning method, which is compared to VLMimic as a strong baseline."}, {"fullname_first_author": "Jacky Liang", "paper_title": "Code as policies: Language model programs for embodied control", "publication_date": "2023-00-00", "reason": "This paper explores using language models to generate robot control policies, an idea that is conceptually related to VLMimic's use of VLMs for skill learning."}]}