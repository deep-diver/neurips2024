[{"figure_path": "1M67AdMBbg/tables/tables_5_1.jpg", "caption": "Table 1: Comparison with other latest SOTA methods on 3 downstream tasks. We report F1 score (%) for PolypDiag, Dice (%) for CVC-12k, and F1 score (%) for KUMC, respectively.", "description": "This table compares the performance of the proposed M\u00b2CRL method against other state-of-the-art (SOTA) self-supervised learning methods on three endoscopic video downstream tasks: Polyp classification (PolypDiag dataset), polyp segmentation (CVC-12k dataset), and polyp detection (KUMC dataset).  The results are presented as F1 scores (percentage) for classification and detection tasks, and Dice scores (percentage) for the segmentation task.  The table highlights the improvements achieved by M\u00b2CRL over existing methods.", "section": "4.2 Comparison with Prior Work"}, {"figure_path": "1M67AdMBbg/tables/tables_8_1.jpg", "caption": "Table 2: Multi-view mask. We compare multiple different masking strategies on different views. FAGTM = Frame-aggregated Attention Guided Tube Mask. RTM = Random Tube Mask.", "description": "This table presents ablation study results comparing different masking strategies applied to global and local views within a multi-view masked contrastive representation learning framework.  It shows the performance (classification, segmentation, and detection F1 scores) achieved using various combinations of masking methods (random, RTM, FAGTM) applied independently to the global and local views, highlighting the effectiveness of the proposed multi-view masking strategy.", "section": "4.2 Comparison with Prior Work"}, {"figure_path": "1M67AdMBbg/tables/tables_8_2.jpg", "caption": "Table 3: Hyper-parameters of the FAGTM.", "description": "This ablation study investigates the effect of different hyperparameter values (\u03b3) of the Frame-aggregated Attention Guided Tube Mask (FAGTM) on the model's performance across three downstream tasks: classification, segmentation, and detection.  The results show that a \u03b3 value of 0.6 yields the best overall performance.", "section": "4.3 Ablation Studies"}, {"figure_path": "1M67AdMBbg/tables/tables_8_3.jpg", "caption": "Table 1: Comparison with other latest SOTA methods on 3 downstream tasks. We report F1 score (%) for PolypDiag, Dice (%) for CVC-12k, and F1 score (%) for KUMC, respectively.", "description": "This table compares the performance of the proposed M\u00b2CRL method against other state-of-the-art (SOTA) self-supervised learning methods on three downstream tasks: Polyp classification (PolypDiag dataset), polyp segmentation (CVC-12k dataset), and polyp detection (KUMC dataset).  The table shows the F1 score for classification and detection tasks, and the Dice score for the segmentation task.  It highlights the improvements achieved by M\u00b2CRL compared to other methods.", "section": "4.2 Comparison with Prior Work"}, {"figure_path": "1M67AdMBbg/tables/tables_9_1.jpg", "caption": "Table 1: Comparison with other latest SOTA methods on 3 downstream tasks. We report F1 score (%) for PolypDiag, Dice (%) for CVC-12k, and F1 score (%) for KUMC, respectively.", "description": "This table compares the performance of the proposed M\u00b2CRL model with other state-of-the-art (SOTA) self-supervised learning methods on three endoscopic video analysis tasks: Polyp classification (PolypDiag dataset), polyp segmentation (CVC-12k dataset), and polyp detection (KUMC dataset).  The results are presented in terms of F1 score (for classification and detection) and Dice score (for segmentation), showing the improvement achieved by M\u00b2CRL over existing methods.", "section": "4.2 Comparison with Prior Work"}, {"figure_path": "1M67AdMBbg/tables/tables_9_2.jpg", "caption": "Table 6: Components analysis. Our proposed M\u00b2CRL combines masked video modeling with contrastive learning and has the best performance.", "description": "This table presents an ablation study comparing the performance of the proposed M\u00b2CRL method against models using only contrastive learning or only masked video modeling.  The results, shown for classification, segmentation, and detection tasks, demonstrate that combining both techniques yields superior performance compared to using either method alone.  The scores indicate F1-score for classification and detection tasks and Dice score for segmentation.", "section": "4.3 Ablation Studies"}, {"figure_path": "1M67AdMBbg/tables/tables_17_1.jpg", "caption": "Table 1: Comparison with other latest SOTA methods on 3 downstream tasks. We report F1 score (%) for PolypDiag, Dice (%) for CVC-12k, and F1 score (%) for KUMC, respectively.", "description": "This table compares the performance of the proposed M\u00b2CRL method with other state-of-the-art (SOTA) self-supervised learning methods on three downstream tasks: Polyp classification (PolypDiag dataset), polyp segmentation (CVC-12k dataset), and polyp detection (KUMC dataset).  The results are presented as F1 scores for classification and detection, and Dice scores for segmentation.  The table highlights the improvements achieved by M\u00b2CRL in comparison to other methods.", "section": "4.2 Comparison with Prior Work"}, {"figure_path": "1M67AdMBbg/tables/tables_18_1.jpg", "caption": "Table 8: Prediction target. The effect of pixel regression is better.", "description": "This table presents the ablation study on different prediction targets used in the M\u00b2CRL model. The results are shown for three downstream tasks: classification, segmentation and detection. Pixel regression as the prediction target outperforms feature distillation, indicating the advantage of using pixel-level reconstruction for improving the performance of downstream tasks.", "section": "Additional Ablations"}, {"figure_path": "1M67AdMBbg/tables/tables_18_2.jpg", "caption": "Table 9: Ablations on loss.", "description": "This table presents the ablation study results on different loss functions used in the masked modeling component of the proposed M2CRL model.  The table shows that different loss functions have minimal impact on the final results across classification, segmentation, and detection tasks, indicating robustness of the model to the choice of loss function.", "section": "Additional Ablations"}, {"figure_path": "1M67AdMBbg/tables/tables_18_3.jpg", "caption": "Table 10: Ablation on different architectures.", "description": "This table presents the results of ablation studies conducted on different Vision Transformer (ViT) architectures to evaluate their impact on the performance of the proposed M\u00b2CRL framework across three downstream tasks: classification, segmentation, and detection.  The results show that larger models (ViT-L/16) generally perform better, but the improvement diminishes as the model size increases, potentially due to overfitting.  The ViT-B/16 architecture shows a good balance between performance and computational cost.", "section": "4.2 Comparison with Prior Work"}, {"figure_path": "1M67AdMBbg/tables/tables_18_4.jpg", "caption": "Table 1: Comparison with other latest SOTA methods on 3 downstream tasks. We report F1 score (%) for PolypDiag, Dice (%) for CVC-12k, and F1 score (%) for KUMC, respectively.", "description": "The table compares the performance of the proposed M\u00b2CRL method with other state-of-the-art (SOTA) self-supervised learning methods on three downstream tasks: Polyp classification (PolypDiag dataset), polyp segmentation (CVC-12k dataset), and polyp detection (KUMC dataset).  For each method, it reports the training time (in hours), and the F1 score (for classification and detection) and Dice score (for segmentation).  The results show that M\u00b2CRL outperforms other methods by a significant margin.", "section": "4.2 Comparison with Prior Work"}, {"figure_path": "1M67AdMBbg/tables/tables_19_1.jpg", "caption": "Table 1: Comparison with other latest SOTA methods on 3 downstream tasks. We report F1 score (%) for PolypDiag, Dice (%) for CVC-12k, and F1 score (%) for KUMC, respectively.", "description": "This table compares the performance of the proposed M\u00b2CRL method against other state-of-the-art (SOTA) self-supervised learning methods on three downstream tasks: classification (PolypDiag dataset), segmentation (CVC-12k dataset), and detection (KUMC dataset).  It shows the F1 score for classification and detection, and Dice score for segmentation, highlighting the improvement achieved by M\u00b2CRL.", "section": "4.2 Comparison with Prior Work"}]