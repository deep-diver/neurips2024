[{"figure_path": "a4cPpx1xYg/figures/figures_2_1.jpg", "caption": "Figure 1: Directed acyclic graph of diversified block sparse hierarchical structure. Except for Measurements (blue nodes), which are known, all other nodes are parameters to estimate.", "description": "This figure is a directed acyclic graph showing the hierarchical Bayesian model used in the DivSBL algorithm.  The nodes represent variables in the model. The blue nodes represent the measurements (y), which are known inputs. The green nodes represent the sparse vector to be recovered (x), which are unknown variables. The red nodes represent the covariance hyperparameters (G, B), which control the prior distribution of the sparse vector. The gray node represents the noise level (\u03b2).  The yellow dashed boxes represent pre-defined blocks, while the pink dashed boxes represent the true blocks, which the model aims to estimate adaptively. The arrows indicate the dependencies between variables. The model uses a hierarchical Bayesian approach, learning the hyperparameters from the data to estimate the underlying block-sparse structure of the signal.", "section": "2 Diversified block sparse Bayesian model"}, {"figure_path": "a4cPpx1xYg/figures/figures_2_2.jpg", "caption": "Figure 1: Directed acyclic graph of diversified block sparse hierarchical structure. Except for Measurements (blue nodes), which are known, all other nodes are parameters to estimate.", "description": "This figure is a directed acyclic graph (DAG) that illustrates the hierarchical Bayesian model used in the proposed DivSBL algorithm.  The nodes represent the variables in the model.  The blue nodes represent the measurements, which are the observed data. The other nodes represent the parameters to be estimated. The arrows indicate the dependencies between the variables. The figure shows how the different components of the model are related and how they are used to estimate the block sparse signal.", "section": "2 Diversified block sparse Bayesian model"}, {"figure_path": "a4cPpx1xYg/figures/figures_2_3.jpg", "caption": "Figure 1: Directed acyclic graph of diversified block sparse hierarchical structure. Except for Measurements (blue nodes), which are known, all other nodes are parameters to estimate.", "description": "This figure shows a graphical representation of the hierarchical Bayesian model used in the proposed DivSBL algorithm.  It illustrates the relationships between different parameters: measurements (y), the sparse vector to be recovered (x), and various hyperparameters (including the diversified variance matrices (Gi), diversified correlation matrices (Bi), and noise level (\u03b2)). The arrows indicate the dependencies between the variables.  Understanding this graph helps to visualize how the algorithm infers the unknown parameters from the observed measurements.", "section": "2 Diversified block sparse Bayesian model"}, {"figure_path": "a4cPpx1xYg/figures/figures_5_1.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure presents the results of multiple experiments to demonstrate the robustness and reliability of the proposed DivSBL algorithm.  It shows box plots illustrating the distribution of NMSE (Normalized Mean Squared Error) and correlation values obtained across numerous runs of the experiments, both for homoscedastic and heteroscedastic data. This visual representation helps to quantify the consistency and stability of the DivSBL method compared to other algorithms in recovering the original signals from noisy measurements.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_6_1.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "The figure shows box plots of the results of multiple experiments to demonstrate the statistical consistency of the proposed algorithm, DivSBL, compared to other methods (BSBL, PC-SBL, SBL, Glasso, GBPDN, StructOMP) under both homoscedastic and heteroscedastic noise conditions.  The plots visualize the distribution of NMSE (Normalized Mean Squared Error) and correlation values, providing a clear comparison of performance across different experimental runs.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_7_1.jpg", "caption": "Figure 4: NMSE variation with changing preset block sizes.", "description": "The figure demonstrates the robustness of DivSBL to preset block sizes.  It shows that DivSBL consistently achieves lower NMSE (Normalized Mean Squared Error) across a range of preset block sizes, even when those sizes significantly differ from the true block sizes in the signal. In contrast, other block-based algorithms (BSBL, Group Lasso, Group BPDN) show a greater sensitivity to the choice of block size, with performance degrading as the preset block size moves further away from the optimal size. This highlights DivSBL's superior adaptability in handling block-sparse signals with unknown or variable block structures.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_8_1.jpg", "caption": "Figure 5: Variance learning", "description": "This figure visualizes the posterior variance learning on the signal to demonstrate DivSBL's ability to adaptively identify the true blocks. The algorithms are tested with preset block sizes of 20 (small), 50 (medium), and 125 (large), respectively, to show how each algorithm learns the blocks when block structure is misspecified. As expected in Section 2.1 and Figure 2, DivSBL is able to adaptively find the true block through diversification learning and remains robust to the preset block size. Exhibits enhanced recovery capability in challenging scenarios. The optimal block size for DivSBL is around 20\u201350, which is more consistent with the true block sizes. This indicates that when true block sizes are large and varied, DivSBL can effectively capture richer information within each block by setting larger block sizes, thereby significantly improving the recovery performance. In contrast, other algorithms do not perform as well as DivSBL, even at their optimal block sizes.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_9_1.jpg", "caption": "Figure 6: Phase transition diagram under different SNR and measurements.", "description": "This figure shows the phase transition diagram of DivSBL under various signal-to-noise ratios (SNR) and sampling rates (M/N). It illustrates the algorithm's performance across different SNR and M/N conditions, showing its robustness and effectiveness in signal recovery. The color intensity represents the NMSE (Normalized Mean Squared Error).", "section": "5.3 1D audioSet"}, {"figure_path": "a4cPpx1xYg/figures/figures_9_2.jpg", "caption": "Figure 7: Reconstruction results for Parrot, Monarch and House images.", "description": "This figure displays the reconstruction results of three images (Parrot, Monarch, and House) using different sparse learning algorithms.  The goal is to show the visual quality of the reconstruction. DivSBL is highlighted as offering the best visual reconstruction compared to other methods, preserving finer features and showing minimal artifacts like noise patterns and stripes.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_13_1.jpg", "caption": "Figure 8: NMSE with iteration number.", "description": "This figure compares the performance of different algorithms in terms of NMSE (Normalized Mean Squared Error) over the number of iterations.  It shows the convergence behavior of BSBL (Block Sparse Bayesian Learning), Diff-BSBL (a variation of BSBL), DivSBL (Diversified Block Sparse Bayesian Learning) without diversified correlation, and the proposed DivSBL algorithm.  The plot helps to visualize how each algorithm converges to a solution, highlighting the impact of diversified correlation on the speed and accuracy of convergence.", "section": "A Experimental result of diversifying correlation matrices"}, {"figure_path": "a4cPpx1xYg/figures/figures_16_1.jpg", "caption": "Figure 9: Comparison of Computation Time", "description": "This figure compares the computation time of three algorithms: DivSBL, DivSBL (with complete dual ascent), and BSBL.  The x-axis represents the CPU time (in seconds), and the y-axis represents the NMSE.  It demonstrates that DivSBL achieves faster NMSE reduction compared to both BSBL and the fully iterative DivSBL.", "section": "3.2 Diversified correlation matrices by dual ascent"}, {"figure_path": "a4cPpx1xYg/figures/figures_19_1.jpg", "caption": "Figure 1: Directed acyclic graph of diversified block sparse hierarchical structure. Except for Measurements (blue nodes), which are known, all other nodes are parameters to estimate.", "description": "This figure shows the hierarchical Bayesian model used in the Diversified Block Sparse Bayesian Learning (DivSBL) method.  It illustrates the relationships between different parameters in the model. The blue nodes represent the observed measurements (y), which are known. The other nodes represent the parameters that need to be estimated: the sparse vector to be recovered (x), the intra-block variance (G), the inter-block correlation (B), and the noise level (\u03b2). The arrows indicate the dependencies between the parameters. The figure visually represents the hierarchical structure of the model.", "section": "2 Diversified block sparse Bayesian model"}, {"figure_path": "a4cPpx1xYg/figures/figures_19_2.jpg", "caption": "Figure 1: Directed acyclic graph of diversified block sparse hierarchical structure. Except for Measurements (blue nodes), which are known, all other nodes are parameters to estimate.", "description": "This figure shows a directed acyclic graph (DAG) illustrating the hierarchical Bayesian model used in the Diversified Block Sparse Bayesian Learning (DivSBL) method.  The DAG depicts the relationships between various parameters in the model, including the observed measurements (y), the sparse signal (x) to be recovered, and hyperparameters representing the diversified variance (G), diversified correlation (B), and noise level (\u03b2). The nodes represent the variables, and the arrows indicate the dependencies between them.", "section": "2 Diversified block sparse Bayesian model"}, {"figure_path": "a4cPpx1xYg/figures/figures_19_3.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure demonstrates the reliability of the experimental results by showing box plots for multiple experimental runs under both homoscedastic and heteroscedastic noise conditions.  The plots visualize the distribution of NMSE and Correlation values across various trials, showcasing the algorithm's consistent performance and highlighting the statistical significance of the findings.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_20_1.jpg", "caption": "Figure 13: Confidence intervals for each Bayesian approach.", "description": "The figure displays the posterior mean and credible intervals for each of the six algorithms considered in the paper: DivSBL, BSBL, PC-SBL, SBL, Horseshoe, and Normal-Gamma.  The credible intervals visualize the uncertainty associated with the point estimates. It helps to understand the stability and accuracy of the posterior estimates for different methods.", "section": "I.2 Reconstructed by Bayesian methods with credible intervals for point estimation"}, {"figure_path": "a4cPpx1xYg/figures/figures_20_2.jpg", "caption": "Figure 14: The original signal and its sparse representation.", "description": "The figure shows the original audio signal and its sparse representation after applying Discrete Cosine Transform (DCT).  The original signal (a) is a continuous waveform. After DCT transformation, it exhibits a block-sparse structure, meaning that non-zero elements in the transformed signal appear in clusters (b). This illustrates the block sparsity phenomenon used as a basis for the DivSBL algorithm, which is designed to handle this specific structure for enhanced signal recovery.", "section": "5.3 1D audioSet"}, {"figure_path": "a4cPpx1xYg/figures/figures_20_3.jpg", "caption": "Figure 1: Directed acyclic graph of diversified block sparse hierarchical structure. Except for Measurements (blue nodes), which are known, all other nodes are parameters to estimate.", "description": "This figure shows a graphical representation of the hierarchical Bayesian model used in the Diversified Block Sparse Bayesian Learning (DivSBL) method.  It illustrates the dependencies between different model parameters, including the measurements, the sparse vector to be recovered, the diversified variance and correlation matrices, and the noise level.  The nodes represent the parameters, and the arrows indicate the dependencies between them, showing how each parameter is used to estimate other parameters in a hierarchical fashion.  This visualization aids understanding the complex relationship between the different components of the DivSBL model.", "section": "2 Diversified block sparse Bayesian model"}, {"figure_path": "a4cPpx1xYg/figures/figures_20_4.jpg", "caption": "Figure 16: NMSE vs. sample rates.", "description": "This figure shows the NMSE (Normalized Mean Squared Error) performance of DivSBL and other algorithms across different sampling rates (M/N). The x-axis represents the sampling rate, and the y-axis represents the NMSE in dB.  DivSBL consistently outperforms other methods across all sampling rates, demonstrating its robustness and efficiency in recovering signals with varying levels of sampling.", "section": "5.3 1D audioSet"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_1.jpg", "caption": "Figure 17: Parrot and House image data (the first five columns) transformed in discrete wavelet domain.", "description": "This figure displays the first five columns of the sparse representation of Parrot and House images in the discrete wavelet domain.  The plots visualize the wavelet coefficients after the image data has undergone a discrete wavelet transform, revealing a block-sparse structure where non-zero coefficients are clustered together.", "section": "5.4 2D image reconstruction"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_2.jpg", "caption": "Figure 17: Parrot and House image data (the first five columns) transformed in discrete wavelet domain.", "description": "This figure shows the sparse representation of Parrot and House images in the discrete wavelet domain. The first five columns of the transformed data are displayed.  This visualization helps to illustrate the block sparsity structure present in the images, which is a key characteristic exploited by the DivSBL algorithm for improved reconstruction.", "section": "5.4 2D image reconstruction"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_3.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure demonstrates the consistency and reproducibility of the experimental results by showing box plots of NMSE and correlation for multiple experiments.  The plots are separated into homoscedastic and heteroscedastic signal cases, providing a clear visual representation of the performance variability across different runs. The consistency of the results across various trials strengthens the conclusions made by the authors regarding the superior performance of their proposed approach.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_4.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure demonstrates the consistency and reliability of the DivSBL algorithm's performance across multiple experimental runs.  The results are presented in box plots for both homoscedastic and heteroscedastic synthetic signals. Each box plot shows the distribution of NMSE and correlation values obtained across the various runs.  The consistency of the results across multiple runs and the different types of signals (homoscedastic and heteroscedastic) validates the algorithm's robustness and effectiveness.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_5.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure demonstrates the robustness and consistency of the proposed DivSBL algorithm across multiple experimental runs.  It displays box plots visualizing the distribution of NMSE (Normalized Mean Squared Error) and Correlation values obtained for both homoscedastic and heteroscedastic synthetic signal data.  The consistent performance across multiple runs highlights the reliability and stability of DivSBL in different scenarios.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_6.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure demonstrates the consistent performance of the DivSBL algorithm across multiple experimental runs.  It shows box plots illustrating the distribution of NMSE (Normalized Mean Squared Error) and correlation values obtained for both homoscedastic (consistent variance) and heteroscedastic (varying variance) synthetic signals.  The results demonstrate that DivSBL consistently outperforms other algorithms in terms of both reconstruction accuracy (lower NMSE) and correlation with the true signal.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_7.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure displays box plots visualizing the consistency of the results obtained from multiple experiments.  The left panel shows results for homoscedastic signals, and the right panel shows results for heteroscedastic signals. Each panel presents two subplots: (a) and (c) show the Normalized Mean Squared Error (NMSE), while (b) and (d) show the correlation. The box plots summarize the NMSE and correlation values from multiple experimental runs, providing a visual representation of the distribution and variability of the results across different runs, for both homoscedastic and heteroscedastic data.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_8.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "The figure shows box plots for the results of multiple experiments performed on both homoscedastic and heteroscedastic signals to confirm the reliability of the results. The NMSE (Normalized Mean Squared Error) and Correlation are used as evaluation metrics. The plots display the distribution of NMSE and Correlation values for each algorithm across multiple experimental runs, illustrating the consistency and statistical significance of the findings.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_21_9.jpg", "caption": "Figure 3: The consistency of multiple experiments with homoscedastic signals for (a) NMSE (b) Correlation, and with heteroscedastic signals for (c) NMSE and (d) Correlation.", "description": "This figure presents the results of multiple experiments conducted to evaluate the performance of the proposed DivSBL algorithm and other competing algorithms.  The experiments were carried out using both homoscedastic (consistent variance) and heteroscedastic (variable variance) synthetic signals.  The figure displays box plots showing the distribution of NMSE (Normalized Mean Squared Error) and Correlation values obtained across these multiple runs.  This visualization demonstrates the robustness and consistency of DivSBL's performance compared to the other methods under different signal characteristics.", "section": "5 Experiments"}, {"figure_path": "a4cPpx1xYg/figures/figures_22_1.jpg", "caption": "Figure 26: The sensitivity to initialization for DivSBL.", "description": "This figure displays the sensitivity analysis of the DivSBL algorithm to the initialization of variance parameters (\u03b3). Two initialization methods are used: (a) \u03b3 = \u03b7 * ones(gL, 1) and (b) \u03b3 = \u03b7 * rand(gL, 1), where \u03b7 is a scaling factor that varies across different values (0.1, 0.5, 1, 10, 50, 100, 1000, 10000). The NMSE (Normalized Mean Squared Error) is plotted against the iteration number for each \u03b7 value. The results show that although different initializations of \u03b3 affect the convergence speed to some extent, the algorithm converges to a similar NMSE value in all cases, indicating its robustness to initialization choices.", "section": "L The sensitivity to initialization"}]