[{"figure_path": "YkSKZEhIYt/tables/tables_3_1.jpg", "caption": "Table 1: Performance (mean\u00b1std) on SBM and Planar datasets.", "description": "This table presents the quantitative results of the proposed DISCO model and several other state-of-the-art graph generation models on two benchmark datasets: SBM and Planar.  The metrics used to evaluate model performance are Degree (Deg.), Clustering (Clus.), Orbit counts (Orb.), Uniqueness, Novelty, and Validity. Lower values for Deg., Clus., and Orb. are better, while higher values for Uniqueness, Novelty, and Validity are preferred.  The results show the mean and standard deviation of each metric across multiple runs.", "section": "4.1 Plain Graph Generation"}, {"figure_path": "YkSKZEhIYt/tables/tables_7_1.jpg", "caption": "Table 1: Performance (mean\u00b1std) on SBM and Planar datasets.", "description": "This table presents the performance comparison of various graph generation models on two benchmark datasets: SBM and Planar.  For each model and dataset, the table shows the mean and standard deviation of several metrics: Deg. (degree distribution relative squared MMD), Clus. (clustering coefficient distribution relative squared MMD), Orb. (orbit counts distribution relative squared MMD), Unique (percentage of unique graphs generated), Novel (percentage of novel graphs generated), and Valid (percentage of valid graphs generated). Lower values for Deg., Clus., and Orb. are better, while higher values for Unique, Novel, and Valid are preferred.  The results show that DISCO-MPNN and DISCO-GT generally outperform the other models, especially in terms of generating unique and valid graphs. ", "section": "4.1 Plain Graph Generation"}, {"figure_path": "YkSKZEhIYt/tables/tables_7_2.jpg", "caption": "Table 2: Performance (mean\u00b1std%) on QM9 dataset. V., U., and N. mean Valid, Unique, and Novel.", "description": "This table presents the performance of various graph generative models on the QM9 dataset.  The models are evaluated based on three key metrics: Validity (V.), Uniqueness (U.), and Novelty (N.).  Validity refers to the percentage of generated molecules that are chemically valid. Uniqueness indicates the proportion of unique molecules generated. Novelty represents the fraction of generated molecules that are novel compared to the training data.  The table shows the mean and standard deviation of these metrics for each model.", "section": "4.2 Molecule Graph Generation"}, {"figure_path": "YkSKZEhIYt/tables/tables_8_1.jpg", "caption": "Table 3: Performance on MOSES. VAE, JT-VAE, and GraphINVENT have hard-coded rules to ensure high validity.", "description": "This table presents the performance comparison of different molecular graph generative models on the MOSES dataset.  The metrics used to evaluate the models include: Validity (percentage of generated molecules with valid SMILES strings), Uniqueness (percentage of unique molecules), Novelty (percentage of molecules not present in the training set), Filters (number of filters used in the model), FCD (Fr\u00e9chet ChemNet Distance), SNN (similarity to nearest neighbor), and Scaf (scaffold similarity).  Note that VAE, JT-VAE, and GraphINVENT employ hard-coded rules to guarantee high validity, indicating that their performance in this metric might not be directly comparable to the other models that do not use such rules.", "section": "4.2 Molecule Graph Generation"}, {"figure_path": "YkSKZEhIYt/tables/tables_8_2.jpg", "caption": "Table 4: Performance on GuacaMol. LSTM, NAGVAE, and MCTS are tailored for molecule datasets; ConGress, DiGress, and DISCO are general graph generation models.", "description": "This table presents the performance of various graph generation models on the GuacaMol dataset.  It compares the performance of models specifically designed for molecular datasets (LSTM, NAGVAE, MCTS) against general-purpose graph generation models (ConGress, DiGress, DISCO). The metrics used to evaluate the models are Validity, Uniqueness, Novelty, KL Divergence, and FCD.", "section": "4.2 Molecule Graph Generation"}, {"figure_path": "YkSKZEhIYt/tables/tables_8_3.jpg", "caption": "Table 5: Efficiency comparison in terms of number of parameters, forward and backpropagation time (second/iteration).", "description": "This table compares the computational efficiency of the Graph Transformer (GT) and Message Passing Neural Network (MPNN) architectures used in the DISCO model.  It shows the number of parameters, forward pass time, and backpropagation time for each architecture. This is important for understanding the trade-offs between model complexity and computational cost.", "section": "4.3 Efficiency Study"}, {"figure_path": "YkSKZEhIYt/tables/tables_9_1.jpg", "caption": "Table 6: Ablation study (mean\u00b1std%) with GT backbone. V., U., and N. mean Valid, Unique, and Novel.", "description": "This ablation study investigates the impact of different reference distributions (marginal vs. uniform) and varying numbers of sampling steps (1 to 500) on the performance of the DISCO-GT model. The results are presented in terms of Validity, Uniqueness, and Novelty metrics, offering insights into the model's robustness and sensitivity to these hyperparameters.", "section": "4.4 Ablation Study"}, {"figure_path": "YkSKZEhIYt/tables/tables_26_1.jpg", "caption": "Table 7: Dataset statistics.", "description": "This table presents the statistics of six graph datasets used in the paper's experiments. For each dataset, it lists the number of graphs, the split into training, validation, and testing sets, the number of edge types (a), the number of node types (b), the average number of edges (Avg. |E|), the maximum number of edges (Max |E|), the average number of nodes (Avg. |F|), and the maximum number of nodes (Max |F|).  The datasets include both plain graph datasets (SBM, Planar, Community) and molecular graph datasets (QM9, MOSES, GuacaMol).  This information is crucial for understanding the scale and characteristics of the data used in evaluating the proposed model.", "section": "4.1 Plain Graph Generation"}, {"figure_path": "YkSKZEhIYt/tables/tables_27_1.jpg", "caption": "Table 8: Generation performance (mean\u00b1std) on the Community dataset.", "description": "This table presents the performance of various graph generation models on the Community dataset.  The models are evaluated using three metrics: Deg. (degree distribution), Clus. (clustering coefficient distribution), and Orb. (orbit counts distribution). Lower values indicate better performance for these metrics.  The table includes results for several state-of-the-art models (GraphRNN, GRAN, EDP-GNN, etc.) and the proposed DISCO model with both MPNN and GT backbones.  The table allows for comparison of the proposed method against existing approaches on a standard benchmark dataset.", "section": "4.1 Plain Graph Generation"}, {"figure_path": "YkSKZEhIYt/tables/tables_28_1.jpg", "caption": "Table 9: Ablation study (mean\u00b1std%) with MPNN backbone. V., U., and N. mean Valid, Unique, and Novel.", "description": "This ablation study investigates the effect of different reference distributions (marginal vs. uniform) and varying numbers of sampling steps on the performance of the DISCO model with an MPNN backbone.  The results are evaluated using the metrics Valid, Unique, and Novel, showing the impact of these hyperparameters on model performance.", "section": "4.4 Ablation Study"}]