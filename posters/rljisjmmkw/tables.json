[{"figure_path": "rLJisJmMKw/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative comparisons. We compare our method with novel view generative models [36, 17] and warping-and-inpainting approach consisting of Stable Diffusion Inpainting [35, 7, 31], on in-domain setting (training dataset [52]), and out-of-domain setting (external dataset [8]). \u2020 We additionally provide results of Stable Diffusion Inpainting fine-tuned on the multi-view dataset [52].", "description": "This table presents a quantitative comparison of the proposed GenWarp model against several baseline methods for novel view synthesis.  The comparison is conducted on both in-domain (RealEstate10K) and out-of-domain (ScanNet) datasets.  Metrics used include FID (Fr\u00e9chet Inception Distance) and PSNR (Peak Signal-to-Noise Ratio) for both mid-range and long-range viewpoint changes. The results demonstrate the superiority of GenWarp in terms of FID and PSNR, especially in the out-of-domain setting.  A fine-tuned version of one of the baseline methods (SD-Inpainting) is also included for a more comprehensive comparison.", "section": "4.3 Quantitative results"}, {"figure_path": "rLJisJmMKw/tables/tables_8_2.jpg", "caption": "Table 2: Ablation on embeddings.", "description": "This table presents the results of an ablation study on the effectiveness of different types of embeddings used to guide the geometric warping process within the GenWarp model.  The study compares the use of warped coordinates, warped depth maps, warped images, and camera embeddings (using Pl\u00fccker coordinates).  The FID (Fr\u00e9chet Inception Distance) score is used to evaluate the quality of the generated novel views, with lower scores indicating better quality. The results demonstrate that using warped coordinates as the embedding condition yields the best performance in terms of FID, indicating superior generation quality compared to other embedding strategies.", "section": "4.4 Ablation study"}, {"figure_path": "rLJisJmMKw/tables/tables_17_1.jpg", "caption": "Table 3: Matching distance of models over training steps.", "description": "This table presents the average distance between the flow map obtained from depth information and the flow map extracted from the cross-attention layer at different training steps (2000, 6000, 10000) and after the model converged. It also includes a comparison with a model where the warped coordinate embedding is replaced with the Pl\u00fccker camera embedding.", "section": "4.4 Ablation study"}, {"figure_path": "rLJisJmMKw/tables/tables_17_2.jpg", "caption": "Table 4: Attention distribution in visible/invisible regions.", "description": "This table shows the distribution of attention weights between cross-attention and self-attention mechanisms for visible and invisible regions in the generated novel view.  It highlights how the model leverages cross-attention more heavily for visible regions (where warping is more reliable) and self-attention for invisible regions (requiring more generative capacity).", "section": "4.4 Ablation study"}]