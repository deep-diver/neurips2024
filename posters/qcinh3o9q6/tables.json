[{"figure_path": "QCINh3O9q6/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with SoTA methods of supervised person ReID. * means the result with the input size as 384 \u00d7 128. \u2020 represents fine-tuning with MGN.", "description": "This table compares the proposed CION method with other state-of-the-art (SoTA) methods on supervised person re-identification (ReID) tasks.  It shows the mAP and Rank-1 accuracy on Market1501 and MSMT17 datasets. The methods are categorized by their backbone initialization approach (ImageNet pre-training or self-supervised large-scale person image pre-training). The table highlights that CION outperforms other methods, especially those using the same ResNet50-IBN backbone, achieving higher accuracy even with fewer training samples.  The asterisk (*) indicates results with a different input image size, and the dagger (\u2020) indicates fine-tuning with the MGN method.", "section": "4.2 Comparison with state-of-the-art methods"}, {"figure_path": "QCINh3O9q6/tables/tables_7_1.jpg", "caption": "Table 1: Comparison with SoTA methods of supervised person ReID. * means the result with the input size as 384 \u00d7 128. \u2020 represents fine-tuning with MGN.", "description": "This table compares the performance of the proposed CION method with other state-of-the-art (SoTA) methods on supervised person re-identification tasks.  It is divided into methods using ImageNet pre-training and those using self-supervised large-scale person image pre-training. The results are presented in terms of mean Average Precision (mAP) and Rank-1 accuracy on two benchmark datasets, Market1501 and MSMT17.  The table highlights CION's superior performance, especially when using fewer training samples, showcasing its efficiency and effectiveness.", "section": "4.2 Comparison with state-of-the-art methods"}, {"figure_path": "QCINh3O9q6/tables/tables_7_2.jpg", "caption": "Table 1: Comparison with SoTA methods of supervised person ReID. * means the result with the input size as 384 \u00d7 128. \u2020 represents fine-tuning with MGN.", "description": "This table compares the proposed CION model's performance with other state-of-the-art (SOTA) methods on supervised person re-identification (ReID) tasks using two benchmark datasets, Market1501 and MSMT17.  The models are categorized by their initialization method: using supervised ImageNet pre-training or self-supervised large-scale person image pre-training. The table shows the mAP (mean Average Precision) and Rank-1 accuracy for each method on each dataset.  The asterisk (*) indicates results obtained with an input image size of 384x128, and the dagger (\u2020) indicates that the results were obtained after fine-tuning with the MGN model. This comparison highlights CION's superior performance, especially when using fewer training samples.", "section": "4.2 Comparison with state-of-the-art methods"}, {"figure_path": "QCINh3O9q6/tables/tables_8_1.jpg", "caption": "Table 4: Our identity-level method achieves significant leading performance compared with two identity-ignored pre-training methods [10, 1].", "description": "This table compares the performance of the proposed CION method against two other pre-training methods: LUP+MGN and DINO+MGN.  All models were fine-tuned using MGN on the Market1501 and MSMT17 datasets.  The results show that CION achieves significantly better mAP and Rank-1 accuracy, demonstrating the superiority of the identity-level correlating approach.", "section": "4.4 Ablation studies and analyses"}, {"figure_path": "QCINh3O9q6/tables/tables_14_1.jpg", "caption": "Table 1: Comparison with SoTA methods of supervised person ReID. * means the result with the input size as 384 \u00d7 128. \u2020 represents fine-tuning with MGN.", "description": "This table compares the proposed CION method with other state-of-the-art (SoTA) methods on supervised person re-identification.  It breaks down the results by different model backbones (e.g., ResNet50, ViT-B) and pre-training methods (ImageNet 1K/21K, large-scale person images).  The table highlights the superior performance of CION, particularly when using fewer training samples, as indicated by the mAP and Rank-1 metrics on the Market1501 and MSMT17 datasets.", "section": "4.2 Comparison with state-of-the-art methods"}, {"figure_path": "QCINh3O9q6/tables/tables_15_1.jpg", "caption": "Table 1: Comparison with SoTA methods of supervised person ReID. * means the result with the input size as 384 \u00d7 128. \u2020 represents fine-tuning with MGN.", "description": "This table compares the proposed CION method with state-of-the-art (SoTA) methods on supervised person re-identification. It shows the mean average precision (mAP) and Rank-1 accuracy on Market1501 and MSMT17 datasets. The methods are categorized by their backbone initialization: ImageNet pre-training and self-supervised large-scale person images pre-training.  The table highlights that CION achieves superior performance, especially when using fewer training samples, demonstrating the effectiveness of cross-video identity-correlating pre-training.", "section": "4.2 Comparison with state-of-the-art methods"}]