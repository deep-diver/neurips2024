[{"figure_path": "oe7MfqFK1M/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the performance of the proposed 'Recover and Resample' method with various other baseline methods for skeleton-based action recognition across multiple datasets (PKU-MMD, NTU-RGBD, and ETRI-Activity3D).  The methods are evaluated on their ability to generalize to unseen datasets, using metrics such as average accuracy across different cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P). The table highlights the significant improvement achieved by the proposed method compared to other state-of-the-art techniques.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_6_2.jpg", "caption": "Table 2: Comparison with other methods in NTU \u2192 PKU setting with 51 actions.", "description": "This table compares the performance of the proposed method with other state-of-the-art methods on the NTU \u2192 PKU cross-dataset setting, which involves 51 action classes.  It shows the accuracy achieved by each method, highlighting the superior performance of the proposed approach.", "section": "4 Experiments"}, {"figure_path": "oe7MfqFK1M/tables/tables_6_3.jpg", "caption": "Table 2: Comparison with other methods in NTU \u2192 PKU setting with 51 actions.", "description": "This table compares the proposed method's performance with other state-of-the-art methods on the NTU \u2192 PKU cross-dataset setting, using 51 action classes.  It shows the accuracy achieved by different methods, highlighting the improved performance of the proposed approach compared to baselines in a challenging cross-dataset scenario.", "section": "4 Experiments"}, {"figure_path": "oe7MfqFK1M/tables/tables_7_1.jpg", "caption": "Table 4: Effect of each component and the effect of using different prior datasets for our method. All ablation experiments in this table have the resampling step.", "description": "This table presents the ablation study of different components of the proposed Recover and Resample framework.  It shows the impact of using only the nonlinear function (FN), only the linear transform (FL), and combinations of these, using either the training dataset (Self) or a separate dataset (P) to obtain boundary poses and linear transforms. The results highlight the contribution of each module and the effectiveness of using a complete action prior from the P dataset.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_8_1.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the performance of the proposed 'Recover and Resample' method against various baselines on three cross-dataset settings for skeleton-based action recognition.  The settings involve training on a single dataset and testing on the other two. The table shows the average accuracy across different datasets, highlighting the superior performance of the proposed method.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_8_2.jpg", "caption": "Table 4: Effect of each component and the effect of using different prior datasets for our method. All ablation experiments in this table have the resampling step.", "description": "This table presents the ablation study results of the proposed method. It shows the effects of each component (nonlinear transform, linear transform) and using different prior datasets on the performance (average accuracy across four cross-dataset settings). The resampling step is used in all experiments.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_8_3.jpg", "caption": "Table 7: Comparison with other learning variants in our method.", "description": "This table compares the performance of three different learning approaches for action completion against the proposed method.  The three methods are extrapolating a motion sequence (FNN, extrap), infilling missing frames in a motion sequence (FNN, infill), and the proposed recover-and-resample method.  The results are evaluated across four cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P), and the average accuracy is reported for each method.  This shows the effectiveness of combining the boundary-conditioned extrapolation and linear transform in the proposed approach.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_8_4.jpg", "caption": "Table 8: Per-class accuracy improvement of our proposed method compared to ERM.", "description": "This table presents the per-class accuracy improvement achieved by the proposed method compared to the baseline method (ERM) across four different cross-dataset settings.  The improvements are shown as percentage increases, providing a detailed view of the method's effectiveness on specific actions.  Actions with larger improvements are likely those that benefit most from the method's approach to recovering complete action sequences.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_9_1.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the performance of the proposed method with several other baseline methods across four different cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P).  The average accuracy across all four settings is shown, highlighting the superior performance of the proposed 'Recover and Resample' augmentation framework compared to various baselines, such as ERM, ADA, ST-Cubism, and others. The best result for each setting is shown in bold, and the second-best is underlined. ", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_9_2.jpg", "caption": "Table 9: Performance of our method on different backbones.", "description": "This table shows the average accuracy of the proposed method on different backbones (ST-GCN and CTR-GCN) across four cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P).  It compares the performance of the base backbones against the backbones when combined with the proposed augmentation method.  The results highlight the improvement in accuracy achieved by incorporating the proposed method regardless of the backbone used.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_13_1.jpg", "caption": "Table 10: Action labels used in our cross-dataset settings.", "description": "This table lists the 18 action labels that are commonly shared among the three large-scale datasets (NTU60-RGBD, PKU-MMD, and ETRI-Activity3D) used in the cross-dataset experiments of the paper.  These actions were selected for their presence across the datasets and suitability for evaluating the proposed method in a cross-domain scenario. The actions are categorized to help in understanding.", "section": "4.1 Datasets and Settings"}, {"figure_path": "oe7MfqFK1M/tables/tables_13_2.jpg", "caption": "Table 11: Number of training and test samples for each dataset split.", "description": "This table presents the number of samples used for training and testing in each of the five datasets used in the cross-dataset experiments. The datasets are denoted by their first letter: N for NTU60-RGBD, EA for ETRI-Activity3D (adult split), P for PKU-MMD, and E for ETRI-Activity3D.  The adult split of ETRI was used to balance the training set size across different domains.", "section": "4.1 Datasets and Settings"}, {"figure_path": "oe7MfqFK1M/tables/tables_15_1.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the performance of the proposed method with other baseline methods across four different cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P).  The best and second-best results for each setting are highlighted in bold and underlined, respectively. The average accuracy across all four settings is also provided. The methods include ERM (Empirical Risk Minimization), several domain generalization and self-supervised learning approaches, along with various augmentation methods.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_15_2.jpg", "caption": "Table 8: Per-class accuracy improvement of our proposed method compared to ERM.", "description": "This table presents a per-class breakdown of the accuracy improvements achieved by the proposed method over the baseline ERM (Empirical Risk Minimization) across four different cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P).  Each row represents a specific action, showing the improvement in accuracy for that action across the four settings and an average improvement across all settings.  The values indicate the improvement in percentage points.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_16_1.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the performance of the proposed method against various baselines on three cross-dataset settings. The settings evaluate the model's ability to generalize to unseen datasets by training on one dataset and testing on the other two. The table shows that the proposed augmentation method significantly improves performance, outperforming the other methods by a considerable margin.  The best performing method for each setting is bolded, and the second best is underlined.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_16_2.jpg", "caption": "Table 15: Comparison between different clustering algorithms.", "description": "This table compares the performance of the proposed method using two different clustering algorithms: k-means and agglomerative.  The results are presented as the average accuracy across four different cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P).  This allows for an evaluation of how sensitive the method is to the choice of clustering algorithm.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_16_3.jpg", "caption": "Table 16: Comparison between different resizing strategies and segment lengths in the resampling stage. r denotes the range of length for sampled segments.", "description": "This table presents the result of an ablation study on the resampling stage of the proposed method. Four different resampling strategies were compared: linear resizing with ranges [0.3, 1.0], [0.5, 1.0], [0.7, 1.0], and random resizing with a range of [0.7, 1.0]. The average accuracy across four cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P) was calculated for each strategy. The results show that linear resizing with a range of [0.7, 1.0] yields the best performance, indicating that sampling longer and more complete segments is crucial for effective data augmentation.", "section": "4 Experiments"}, {"figure_path": "oe7MfqFK1M/tables/tables_16_4.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the performance of the proposed method against various baseline methods across three different cross-dataset settings for skeleton-based action recognition.  The table shows the average accuracy achieved by each method on unseen datasets. The best and second best performances in each setting are highlighted.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_17_1.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the performance of the proposed 'Recover and Resample' method against several baselines on a cross-dataset action recognition task.  The task involves training a model on one dataset (source domain) and testing it on two other unseen datasets (target domains). The table shows the average accuracy across four different cross-dataset settings. The baselines include ERM (Empirical Risk Minimization), several domain generalization methods (CCSA, ADA, ST-Cubism, Skeleton-MAE, HICLR), and several augmentation methods (uniform sampling, Mixup, CropPad, CropResize, TSN, multiple-crop testing, OTAM+KNN). The results demonstrate that the proposed method significantly outperforms all baselines.", "section": "4.3 Results"}, {"figure_path": "oe7MfqFK1M/tables/tables_17_2.jpg", "caption": "Table 1: Comparison with other methods in our cross-dataset settings. The best result is in bold and the second best is with underlines.", "description": "This table compares the proposed method with various other baseline methods across four different cross-dataset settings (N\u2192E, N\u2192P, EA\u2192N, EA\u2192P). The average accuracy across all settings is reported for each method. The best performing method is highlighted in bold, and the second best is underlined.  The table shows the relative performance improvements of the proposed method compared to existing approaches in addressing cross-dataset generalization problems in skeleton-based action recognition.", "section": "4.3 Results"}]