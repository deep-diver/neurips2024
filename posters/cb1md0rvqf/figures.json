[{"figure_path": "Cb1Md0RvqF/figures/figures_0_1.jpg", "caption": "Figure 8: ABO shapes textured by UV3-TeD with and without the proposed farthest-sampled attention layer.", "description": "This figure compares texture generation results on the Amazon Berkeley Objects (ABO) dataset using UV3-TeD with and without the farthest-sampled attention layer.  The comparison highlights the impact of the attention layer on texture quality and consistency, particularly across different object parts.", "section": "Ablation Studies Detailed Discussion"}, {"figure_path": "Cb1Md0RvqF/figures/figures_2_1.jpg", "caption": "Figure 19: Failure cases of random samples generated by our UV3-TeD trained on ShapeNet chairs (top) and ABO (bottom). Most failures exhibit issues in correctly recognizing the different object parts, long-range inconsistencies, uniform yet unreasonable colours, or blotchy patterns.", "description": "This figure showcases examples where the UV3-TeD model failed to generate high-quality textures. The failures are categorized into four main issues: incorrect recognition of object parts, inconsistencies in texture appearance across the object's surface, use of unrealistic and uniform colors, and the presence of blotchy patterns.", "section": "Additional Experiments"}, {"figure_path": "Cb1Md0RvqF/figures/figures_4_1.jpg", "caption": "Figure 3: Framework of UV3-TeD. Given a mesh M = {V, F} we precompute the proposed mixed Laplacian (Lmix) and its eigendecomposition (A and \u03a6). During the online sampling we compute a coloured point-cloud {P, X} alongside its spectral quantities and other information used by our network (Fig. 9). In particular, eigenvalues A, sampled eigenvectors Pp, and approximate mass Mp are used to compute the heat diffusion operations (Eq. (1)); the farthest point samples fps (P) are used in the proposed diffused farthest-sampled attention layers (Fig. 4), and the scale invariant heat kernel signatures sihks and slope-adjusted eigenvalues A' are used as shape conditioning. UV3-TeD leverages these information to generate coloured point-clouds (X0) from noise (XT).", "description": "This figure illustrates the framework of the UV3-TeD model.  It shows the pre-computation stage involving the mixed Laplacian and its eigendecomposition, followed by the online sampling stage where point cloud data and spectral quantities are calculated.  These are then fed into the UV3-TeD network, which uses this information to generate textured point clouds from noise.", "section": "4 UV-free Texture Diffusion (UV3-TeD)"}, {"figure_path": "Cb1Md0RvqF/figures/figures_5_1.jpg", "caption": "Figure 4: Attention-enhanced Heat Diffusion block. Three consecutive Diffusion blocks (bottom) inspired by [48] and conditioned with a denoising time embedding are combined with a diffused farthest-sampled attention layer (top). The proposed attention, conditioned with local and global shape embeddings (sihkse and A'), first spreads information to all the points on the surface, before computing a multi-headed self-attention on the features of the farthest samples (red points), and finally spreads them back to all the points with another heat diffusion.", "description": "This figure shows the architecture of an Attention-enhanced Heat Diffusion Block.  It consists of three Diffusion Blocks (inspired by DiffusionNet [48]) concatenated and combined with a diffused farthest-sampled attention layer.  The attention layer uses a heat diffusion process to spread information across the surface and then performs a multi-headed self-attention operation on the farthest points (shown in red). Finally, it applies another heat diffusion to spread the attention results back to all points.  The blocks are conditioned with local and global shape embeddings (sihkse and A') and a time embedding, helping to integrate shape information and diffusion timestep into the feature processing. The three diffusion blocks include heat diffusion, spatial gradient features, and a multi-layer perceptron (MLP) for per-vertex processing.", "section": "4.1 Attention-enhanced Heat Diffusion Blocks"}, {"figure_path": "Cb1Md0RvqF/figures/figures_6_1.jpg", "caption": "Figure 5: Heat diffusion on Ted sliced on the belly and on a topologically disconnected birdhouse. Using the mesh LBO prevents heat from spreading to disconnected regions, this is particularly visible on Ted as heat does not spread over the nose, mouth, and legs. Similarly, on the birdhouse heat spreads only on the right-hand side of the roof. Using our mixed LBO formulation heat can spread over the entire shape even in the presence of topological errors and disconnected components.", "description": "This figure demonstrates the effectiveness of the proposed mixed Laplacian operator (Lmix) in handling meshes with topological errors and disconnected components. Heat diffusion is performed on two models: a teddy bear and a birdhouse. The mesh Laplacian (L) fails to diffuse heat across disconnected parts, while the mixed Laplacian successfully diffuses heat across all parts, even the disconnected parts, ensuring that the entire model is consistently textured. This showcases the robustness of the mixed Laplacian in handling complex mesh structures.", "section": "4 UV-free Texture Diffusion (UV3-TeD)"}, {"figure_path": "Cb1Md0RvqF/figures/figures_7_1.jpg", "caption": "Figure 6: Rendering a point-cloud textured cow [16]. When a ray intersects the mesh, we interpolate the colours of the three nearest texture points.", "description": "The figure shows a 3D model of a cow with a point cloud texture applied to its surface.  A magnified inset highlights how the rendering process works: when a ray from the camera intersects the mesh, the three closest points in the point cloud texture are found, and their colors are interpolated to determine the color of the intersected point on the surface. This method avoids traditional UV mapping techniques, thus mitigating seam and distortion issues.", "section": "4.4 Rendering Point-Cloud Textures"}, {"figure_path": "Cb1Md0RvqF/figures/figures_8_1.jpg", "caption": "Figure 15: Additional random samples generated by our UV3-TeD (top), and Point-UV Diffusion (bottom) trained on chairs from ShapeNet. The point-clouds generated by Point-UV Diffusion were rendered with our method for a more fair comparison with no projection artefacts. Our method generates more diverse textures and better distinguishes the different parts.", "description": "This figure compares texture generation results of UV3-TeD and Point-UV Diffusion on ShapeNet chair models.  UV3-TeD produces more diverse and detailed textures that better represent the different parts of the chairs.", "section": "Experiments"}, {"figure_path": "Cb1Md0RvqF/figures/figures_9_1.jpg", "caption": "Figure 1: Random textures generated by our method, Uv3-TeD, on the surface of general objects from the Amazon Berkeley Object dataset and of chairs from ShapeNet (miniatures on the shelves).", "description": "This figure showcases examples of random textures generated using the proposed method, UV3-TeD.  The textures are applied directly onto the surfaces of various 3D objects, demonstrating the method's ability to handle different object shapes and complexities. The objects include general items from the Amazon Berkeley Object dataset and chairs from the ShapeNet dataset, with some smaller chair models displayed on shelves to further illustrate the versatility of the method.", "section": "Abstract"}, {"figure_path": "Cb1Md0RvqF/figures/figures_14_1.jpg", "caption": "Figure 9: Architecture of the proposed UV3-TeD. The noised input colours (Xt) go through a U-Net-shaped network with multiple Attention-enhanced Heat Diffusion Blocks (detailed in Fig. 4). Blue arrows depict how the blocks are connected in a U-Net fashion. Each Diffusion block is conditioned on a time embedding obtained by embedding the timestep and processing it with an MLP and multiple block-specific linear layers. The attention part of the attention-enhanced blocks is conditioned on the signal obtained by processing A' and sihs with two separate MLPs. All the conditioning is depicted in pink arrows.", "description": "This figure shows the architecture of the proposed model UV3-TeD.  The model uses a U-Net architecture with several attention-enhanced heat diffusion blocks. Each block is conditioned on time embeddings (from a timestep), and global and local shape information.  The flow of data through the network is shown, indicating how the different components interact.", "section": "4 UV-free Texture Diffusion (UV3-TeD)"}, {"figure_path": "Cb1Md0RvqF/figures/figures_15_1.jpg", "caption": "Figure 3: Framework of UV3-TeD. Given a mesh M = {V, F} we precompute the proposed mixed Laplacian (Lmix) and its eigendecomposition (A and \u03a6). During the online sampling we compute a coloured point-cloud {P, X} alongside its spectral quantities and other information used by our network (Fig. 9). In particular, eigenvalues A, sampled eigenvectors Pp, and approximate mass Mp are used to compute the heat diffusion operations (Eq. (1)); the farthest point samples fps (P) are used in the proposed diffused farthest-sampled attention layers (Fig. 4), and the scale invariant heat kernel signatures sihks and slope-adjusted eigenvalues A' are used as shape conditioning. UV3-TeD leverages these information to generate coloured point-clouds (X0) from noise (XT).", "description": "This figure illustrates the framework of the UV3-TeD model. It shows how a mesh is pre-processed to compute the mixed Laplacian and its eigendecomposition. Then, during online sampling, a colored point cloud is generated along with its spectral properties.  These properties are fed into the UV3-TeD network, which utilizes heat diffusion operations and farthest point sampling to generate the final colored point cloud from noise.  Shape conditioning is provided by scale-invariant heat kernel signatures and slope-adjusted eigenvalues.", "section": "4 UV-free Texture Diffusion (UV3-TeD)"}, {"figure_path": "Cb1Md0RvqF/figures/figures_16_1.jpg", "caption": "Figure 11: Top: heat diffusion on a chair whose legs are disconnected from the rest of the structure. Diffusing heat with the mesh LBO, heat cannot spread beyond the leg where heat was applied. With the point-cloud LBO heat diffuses also across the rest of the structure, but it quickly travels also horizontally across the vertical bars. With our mixed LBO formulation heat correctly spread over the rest of the structure and it appears to better follow geodesic paths. Bottom: Heat diffusion on an object with thin structures using different LBO formulations. Using the proposed mixed LBO heat diffuses geodesically, closely mimicking the behaviour of heat diffusion with the mesh LBO. On the contrary, with the point-cloud LBO heat would be immediately transferred from the back of the hanger to its front because of the Euclidean proximity of the two parts. This is an undesirable behaviour not shown by our method.", "description": "This figure shows the heat diffusion results on two different 3D models using three different Laplacian operators: mesh LBO, mixed LBO, and point-cloud LBO. The top row shows a chair with disconnected legs, while the bottom row shows a coat hanger with thin structures. The results demonstrate that the mixed LBO provides a better balance between preserving the topology and diffusing the heat geodesically, as compared to the other two methods.", "section": "A.2 Additional Experiments"}, {"figure_path": "Cb1Md0RvqF/figures/figures_17_1.jpg", "caption": "Figure 12: Comparison between the eigenvectors of the same shape with two different sampling densities. The eigenvectors of the original mesh are represented as colours on the surface of the mesh, while the eigenvectors of a mesh obtained subdividing the faces of the original mesh are reported on a point-cloud. The point colours match those of the underlying mesh, suggesting that sampling the eigenvectors of the mesh at the point locations would produce the same result.", "description": "This figure compares the eigenvectors of a mesh with two different sampling densities.  The original mesh's eigenvectors are color-coded on its surface. A denser point cloud is created by subdividing the original mesh's faces. The point cloud is then color-coded with the corresponding eigenvector values from the original mesh.  The close match in colors demonstrates that sampling the eigenvector values directly from the point cloud locations would yield virtually identical results to interpolating them from the original mesh's vertices.", "section": "4.3 Online Sampling of Points, Colours, and Spectral Operators"}, {"figure_path": "Cb1Md0RvqF/figures/figures_17_2.jpg", "caption": "Figure 13: Heat diffusion computed on the vertices of a mesh and with our online sampling on a point-cloud. The heat depicted on the surface of the mesh is computed with the traditional method using Eq. (1) and our Mixed LBO (Sec. 4.2). The heat depicted on the point-cloud was computed using the online sampled operators like described in Sec. 4.3. Heat diffuses in the same way with both techniques proving the correctness of our sampling strategy.", "description": "This figure compares heat diffusion on a mesh and on an online-sampled point cloud to demonstrate the effectiveness of the proposed online sampling strategy.  Heat diffusion is calculated using both traditional methods and the new online sampling approach, showing that both methods produce similar results, confirming the accuracy of the new strategy.", "section": "4 UV-free Texture Diffusion (UV3-TeD)"}, {"figure_path": "Cb1Md0RvqF/figures/figures_18_1.jpg", "caption": "Figure 14: Additional random samples generated by our UV3-TeD trained on ABO.", "description": "This figure shows a set of 3D models of furniture and home goods that were textured using the UV3-TeD method described in the paper. The textures are diverse, showing different materials and styles.  The objects are from the Amazon Berkeley Objects (ABO) dataset, and the UV3-TeD method was trained on this dataset.", "section": "Additional Experiments"}, {"figure_path": "Cb1Md0RvqF/figures/figures_19_1.jpg", "caption": "Figure 15: Additional random samples generated by our UV3-TeD (top), and Point-UV Diffusion (bottom) trained on chairs from ShapeNet. The point-clouds generated by Point-UV Diffusion were rendered with our method for a more fair comparison with no projection artefacts. Our method generates more diverse textures and better distinguishes the different parts.", "description": "This figure compares the texture generation results of UV3-TeD and Point-UV Diffusion on chairs from ShapeNet.  UV3-TeD produces more diverse and detailed textures that better differentiate different chair parts.", "section": "Experiments"}, {"figure_path": "Cb1Md0RvqF/figures/figures_20_1.jpg", "caption": "Figure 1: Random textures generated by our method, Uv3-TeD, on the surface of general objects from the Amazon Berkeley Object dataset and of chairs from ShapeNet (miniatures on the shelves).", "description": "This figure showcases the results of the proposed UV3-TeD method for generating textures directly on 3D object surfaces, without using UV-mapping.  It displays diverse textures generated on various objects from two datasets: Amazon Berkeley Objects and ShapeNet. Notably, some smaller objects from ShapeNet are shown arranged on shelves, highlighting the versatility of the method across different object types and scales.", "section": "Abstract"}, {"figure_path": "Cb1Md0RvqF/figures/figures_20_2.jpg", "caption": "Figure 17: Plane perturbed by a ripple effect and textured with point-cloud textures generated by UV3-TeD trained on CelebA for only 50 epochs.", "description": "This figure shows textures generated by the UV3-TeD model trained on the CelebA dataset.  The textures are applied to a plane that has been deformed by a ripple effect, demonstrating the model's ability to generate textures on non-planar surfaces.  The training was done for only 50 epochs, indicating the model's relatively quick convergence.", "section": "Experiments"}, {"figure_path": "Cb1Md0RvqF/figures/figures_20_3.jpg", "caption": "Figure 18: ABO shapes textured by UV3-TeD with and without the proposed farthest-sampled attention layer.", "description": "This figure shows a comparison of textures generated on ABO shapes using UV3-TeD with and without the farthest-sampled attention layer.  The results demonstrate the positive impact of the attention layer on the quality and consistency of the generated textures.", "section": "Ablation Studies Detailed Discussion"}, {"figure_path": "Cb1Md0RvqF/figures/figures_21_1.jpg", "caption": "Figure 1: Random textures generated by our method, Uv3-TeD, on the surface of general objects from the Amazon Berkeley Object dataset and of chairs from ShapeNet (miniatures on the shelves).", "description": "This figure showcases examples of textures generated by the proposed method, UV3-TeD, applied to various 3D objects. The textures demonstrate the method's ability to generate high-quality, diverse textures on the surfaces of different object shapes, without relying on UV mapping.", "section": "Abstract"}, {"figure_path": "Cb1Md0RvqF/figures/figures_21_2.jpg", "caption": "Figure 2: Qualitative comparison between point-cloud-textures (top-right halves) and automatically wrapped UV-textures (bottom-left halves). All textures were generated by Point-UV Diffusion in order to showcase some of the most common issues of UV-mapping. Although the method generated good quality textures as point-clouds, projecting them in UV-space introduces significant artefacts.", "description": "The figure compares textures generated using point clouds and UV mapping.  The top-right shows textures generated directly as point clouds, while the bottom-left demonstrates those generated using standard UV mapping, which introduces various artifacts such as seams and distortions. This highlights the advantages of the proposed UV-free method.", "section": "1 Introduction"}]