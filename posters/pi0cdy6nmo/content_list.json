[{"type": "text", "text": "Towards Efficient and Optimal Covariance-Adaptive Algorithms for Combinatorial Semi-Bandits ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Julien Zhou ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Pierre Gaillard ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Thibaud Rahier ", "page_idx": 0}, {"type": "text", "text": "Criteo AI Lab Paris, France ", "page_idx": 0}, {"type": "text", "text": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France ", "page_idx": 0}, {"type": "text", "text": "julien.zhou@inria.fr ", "page_idx": 0}, {"type": "text", "text": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France ", "page_idx": 0}, {"type": "text", "text": "Criteo AI Lab, Paris, France ", "page_idx": 0}, {"type": "text", "text": "Houssam Zenati ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Julyan Arbel ", "page_idx": 0}, {"type": "text", "text": "Universite Paris-Saclay, Inria, Palaiseau, France ", "page_idx": 0}, {"type": "text", "text": "Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, 38000 Grenoble, France ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We address the problem of stochastic combinatorial semi-bandits, where a player selects among $P$ actions from the power set of a set containing $d$ base items. Adaptivity to the problem's structure is essential in order to obtain optimal regret upper bounds. As estimating the coefficients of a covariance matrix can be manageable in practice, leveraging them should improve the regret. We design \u201coptimistic' covariance-adaptive algorithms relying on online estimations of the covariance structure, called OLS-UCB-C and $\\tt C O S-V$ (only the variances for the latter). They both yield improved gap-free regret. Although Cos-V can be slightly suboptimal, it improves on computational complexity by taking inspiration from Thompson Sampling approaches. It is the first sampling-based algorithm satisfying a $O({\\sqrt{T}})$ gap-free regret (up to poly-logs). We also show that in some cases, our approach efficiently leverages the semi-bandit feedback and outperforms bandit feedback approaches, not only in exponential regimes where $P\\gg d$ but also when $P\\leq d$ which is not covered by existing analyses. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In sequential decision-making, the bandit framework has been extensively studied and was instrumental to several applications, e.g. A/B testing (Guo et al., 2020), online advertising and recommendation services (Zeng et al., 2016), network routing (Tabei et al., 2023), demand-side management (Br\u00e9gere et al., 2019), etc. Its popularity stems from its relative simplicity, allowing it to model and analyze a wide range of challenging real-world settings. Reference books like Bubeck and Cesa-Bianchi (2012) or Lattimore and Szepesvari (2020) offer a wide perspective on the subject. ", "page_idx": 0}, {"type": "text", "text": "In this framework, a decision-maker or player must make choices and receives associated rewards, but it lacks prior knowledge of its environment. This naturally leads to an exploration-exploitation trade-off: the player must explore different actions to determine the best one, but an inefficient exploration strategy may harm the cumulative rewards. Efficient algorithms rely on exploiting the environment's structure, such as estimating the parameters of a reward function instead of exploring everyaction. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "This paper focuses on the stochastic combinatorial semi-bandit framework. At each round, the player chooses a subset of base items and receives a feedback for each item chosen. The action set is included in the base items' power set, and can therefore be exponentially big and dificult to explore. The main challenge in this framework is to effectively combine the information collected through different actions (that may share common base items). ", "page_idx": 1}, {"type": "text", "text": "Problem formulation.We consider a set of $d\\in\\mathbb{N}^{*}$ base items, each item $i\\in[d]=\\{1,\\ldots,d\\}$ yielding stochastic rewards. A player accesses these rewards through a set $A\\subseteq\\{0,1\\}^{d}$ of $P\\in\\mathbb{N}^{*}$ actions, each corresponding to a subset of at most $m\\geq5$ items(@). We refer to actions $a\\in A$ using their components vector $a\\stackrel{=}{=}(a_{i})_{i\\in[d]}\\in\\{0,1\\}^{d}$ where for all $j\\in[d]$ \uff0c $a_{j}=1$ if and only if action $a$ contains base item $j$ ", "page_idx": 1}, {"type": "text", "text": "The player interacts with an environment over a sequence of $T\\in\\mathbb{N}^{*}$ rounds. At each round $t\\in[T]$ the player chooses an action $A_{t}\\in\\mathcal A$ , the environment samples a reward vector $Y_{t}\\in\\mathbb{R}^{d}$ ,the player observes the realization for every item contained in $A_{t}$ , and receives their sum. The interactions between the player and the environment are summarized in Framework 1. ", "page_idx": 1}, {"type": "table", "img_path": "PI0CDY6nmo/tmp/9002239b38f22823a28f740ecad72a64516c293fb8320813c0c6c9dc3cd3a691.jpg", "table_caption": [], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "Assumptions. We make the following assumptions. For all $t\\in[T]$ \uff0c $Y_{t}$ is independent of the past rewards and the player's decision $\\sigma(A_{1},Y_{1},\\ldots,A_{t-1},Y_{t-1},A_{t})$ . There exists a mean reward vector $\\mathbb{E}[Y_{t}]=\\mu\\in\\mathbb{R}^{d}$ and a second order moment matrix $\\mathbf{S}=\\mathbb{E}[Y_{t}Y_{t}^{\\top}]\\,\\in\\,M_{d}(\\mathbb{R})$ . The positive semidefinite covariance matrix is denoted $\\Sigma\\in M_{d}(\\mathbb{R})$ , with $\\Sigma=\\mathbf{S}-\\mu\\mu^{\\top}$ .There exists a known vector $B\\in\\mathbb{R}_{+}^{d}$ such that for all $t\\in[T]$ and $i\\in[d]$ $|Y_{t,i}|\\leq B_{i}/2$ almost surely (and $\\vert Y_{t,i}-\\mu_{i}\\vert\\le B_{i})$ ", "page_idx": 1}, {"type": "text", "text": "The objective of the decision-maker is to minimize the expected cumulative pseudo-regret defined as: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[R_{T}]=\\mathbb{E}\\left[\\sum_{t=1}^{T}\\langle a^{*}-A_{t},\\mu\\rangle\\right]=\\sum_{t=1}^{T}\\Delta_{A_{t}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\langle\\cdot,\\cdot\\rangle$ denotes the usual inner product in $\\mathbb{R}^{d}$ $a^{*}\\in\\arg\\operatorname*{max}_{a\\in\\mathcal{A}}\\langle a,\\mu\\rangle$ is an optimal action, and $\\Delta_{a}=\\langle a^{*}-a,\\mu\\rangle$ is the sub-optimality gap for action $a\\in A$ ", "page_idx": 1}, {"type": "text", "text": "1.1 Existing work and limitations ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Combinatorial semi-bandit problems have been extensively studied by the bandit community since their introduction by Chen et al. (2013). Here, we only highlight key earlier works related to this paper. For a comprehensive introduction to this literature, we refer the interested reader to the monograph by Lattimore and Szepesvari (2020). ", "page_idx": 1}, {"type": "text", "text": "A first line of works considers deterministic algorithms based on the optimistic principle and upper confidence bounds (UCBs). Chen et al. (2013) first designed cUCB, computing UCBs for the items' average rewards, converting these into UCBs for the actions\u2019 rewards, and choosing the action with the highest one. It was later analyzed by Kveton et al. (2015), who proved a regret upper bound uniform over all possible covariance matrices $\\Sigma$ (hence, paying the worst-case). Combes et al. (2015) highlighted the importance of designing $\\Sigma$ -adaptive algorithms by showing that the regret could be improved by a factor of $m$ when the items\u2019 average rewards are independent. Subsequently, Degenne and Perchet (2016) developed 0Ls-UCB, an algorithm intended to leverage the covariance structure. However, OLs-UCB requires prior knowledge of a positive semi-definite covariance-proxy matrix $\\mathbf{T}$ , such that for all $t\\geq1$ and for all $u\\in\\mathbb{R}^{\\check{d}}$ $\\begin{array}{r}{\\mathbb{E}[\\exp(\\langle u,Y_{t}-\\mu\\rangle)]\\leq\\exp(\\frac{1}{2}\\|u\\|_{\\Gamma}^{2})}\\end{array}$ . Estimating $\\mathbf{T}$ in practice is challenging and leads to regret bounds depending on it instead of the \u201ctrue\u201d covariance matrix $\\Sigma$ , potentially resulting in significantly looser bounds. This issue was addressed by Perrault et al. (2020b), who proposed a covariance-adaptive algorithm, ESCB-C, with asymptotically optimal gap-dependent regret upper bounds. Yet, it suffers from an additive constant of order $\\Delta_{\\operatorname*{min}}^{-\\bar{2}}$ min ,which prevents its conversion into an $\\tilde{O}(\\sqrt{T})^{(\\mathrm{b)}}$ gap-free bound. Thus, none of the above works proposes a $\\tilde{O}(\\sqrt{T})$ gap-free and covariance-adaptive regret bound, which is one of the key contributions of this paper. A common drawback of these works is also their potentially prohibitive computational complexity, due to the need to solve a maximization step over a large action set $A\\subseteq\\{\\dot{0},1\\}^{d}$ that can be exponentially large. Some works, such as Cuvelier et al. (2021) or Liu et al. (2022), propose solutions to achieve polynomial time complexity, for example by applying UCB at the item level only rather than the action level. However, these approaches only work for independent rewards or under specific assumptions on their distribution, making the analysis for generic and unknown distributions extremely challenging. Another approach to tackle the computational burden in combinatorial semi-bandits is to resort to sampling algorithms, which we detail below. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "A second line of works for stochastic combinatorial semi-bandits considers randomized algorithms inspired by Thompson Sampling (Ts) for multi-armed bandits (Thompson, 1933). These algorithms involve sampling a random vector $\\tilde{\\mu}_{t}\\,\\in\\,\\mathbb{R}^{d}$ at each round $t+1\\,\\\\in\\,[T-1]$ from a distribution representing a \u201cbelief\u201d over the parameter $\\mu$ , taking a decision ${A_{t+1}}^{\\cdot}\\in\\,\\arg\\operatorname*{max}_{a\\in\\mathcal{A}}\\langle a,\\tilde{\\mu}_{t}\\rangle$ : and updating the belief distribution using the observations. The main appeal of these approaches lies in their computational complexity, especially when solving a linear maximization problem in particular action spaces (such as matroids). Recent works have designed and analyzed such algorithms. Notably, Wang and Chen (2018) consider independent item's rewards. Perrault et al. (2020a) refine it and assume a known variance-proxy $\\mathbf{T}$ and therefore suffers from the same drawbacks as Degenne and Perchet (2016). Their technical analysis also yields a gap-dependent regret bound with an undesirable $\\Delta_{\\mathrm{min}}^{-m}$ term, preventing a $\\tilde{O}(\\sqrt{T})$ gap-freeratcntacnrutnurpaperistcmban of the computational efficiency for sampling algorithms with the covariance-adaptivity $\\tilde{O}(\\sqrt{T})$ gap-free from our UCB approach. ", "page_idx": 2}, {"type": "text", "text": "Besides, the literature concerning our setting has historically mostly focused on cases where the action set is exponentially large, namely $P\\gg d$ , and the way to get quasi-optimal regret rates in these instances. However, outside of these regimes, the commonly derived regret bounds are too rough and fail to show the benefit of the semi-bandit feedback. While the conventional stochastic combinatorial semi-bandit regret upper bound grows as $\\tilde{O}(\\sqrt{m d T})$ (Kveton et al., 2015), a $\\tilde{O}(\\sqrt{m P T})$ could be achieved using bandit feedback only (Auer et al., 2002b). Intriguingly, the latter appears to outperform the semi-bandit rate as soon as $P<d$ , making the extra information obtained through a richer feedback seemingly useless. Fine-grained analyses, clearly taking the structure into account, are therefore needed. ", "page_idx": 2}, {"type": "text", "text": "1.2 Contributions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A new deterministic optimism-based algorithm (Section 2). We present OLS-UCB-C (Online Least Squares Upper Confidence Bound with Covariance estimation), relying on the optimism principle. The analysis of OLS-UCB-C sketched in Section 5.2 shows the following properties: ", "page_idx": 2}, {"type": "text", "text": "\u00b7 First optimal gap-free regret upper bound. OLS-UCB-C yields a similar gap-dependent regret bound as ESCB-C from Perrault et al. (2020b) up to logarithmic factors, and the first optimal covariance-adaptative gap-free $\\tilde{O}(\\sqrt{T})$ regret bound (Theorem 1). \u00b7Improved performance over UCB in all regimes of $P/d$ . Under some conditions on the covariance matrix $\\Sigma$ , we prove that OLS-UCB has a uniformly better regret than UCB, showing that properly leveraging semi-bandit feedback indeed consistently offers an advantage on (simple) bandit algorithms, which is not straightforward from existing analyses. \u00b7 Improved complexity over concurrent algorithms. OLs-UCB-C circumvents the convex optimization problem that EsCB-C requires to solve at each round and is therefore more efficient, despite suffering in the very large $P$ regime as many other deterministic algorithms. ", "page_idx": 2}, {"type": "text", "text": "The first stochastic optimism-based algorithm (Section 3). We introduce COs-V (Combinatorial Optimistic Sampling with Variance estimation), a TS-inspired algorithm exploiting the \u201cfrequentist' confidence regions derived in Section 4. It satisfies the following: ", "page_idx": 2}, {"type": "text", "text": "\u00b7 Improved complexity for $P\\gg1$ compared to other deterministic semi-bandit algorithms. COS- $\\boldsymbol{\\cdot}$ can be efficient in the very large $P$ regime, which is the main blind spot of OLS-UCB-C. \u00b7 First gap-free $\\tilde{O}(\\sqrt{T})$ regret upper bound for a sampling algorithm. The analysis we provide in Section 5.3 exploits the common structure of the OLS-UCB-C and COS- $\\mathtt{V}$ algorithms. It enables the derivation of a gap-dependent bound for Cos-V that does not involve the $\\Delta^{-m}$ term we typically find in the analysis for other TS algorithms (Wang and Chen, 2018; Perrault et al., 2020a), consequently leading to a new $\\tilde{O}(\\sqrt{T})$ variance-adaptive gap-free regret upper bound for a sampling algorithm. ", "page_idx": 3}, {"type": "text", "text": "A novel gap-free lower bound (Section 2.2).  We show a gap-free lower bound on the regret for stochastic combinatorial semi-bandits, explicitly involving the structure of the problem (the items forming each action) and the covariance matrix $\\Sigma$ . This lower bound highlights the optimality of the gap-free upper bound we establish for OLS-UCB-C. ", "page_idx": 3}, {"type": "text", "text": "Technical details are deferred to Section 4, Section 5, and the Appendix ", "page_idx": 3}, {"type": "table", "img_path": "PI0CDY6nmo/tmp/f93b7d4719452db3fba7122cc3a1819a402facc3cf5cb3d35ae09b35cd7e3c80.jpg", "table_caption": ["Table 1: Asymptotic $\\tilde{O}(\\cdot)$ regret bounds and per-round time complexities up to poly-logarithmic terms in $d$ for the following deterministic algorithms: UCB (Auer et al., 2002a), UCBV (Audibert et al., 2009), CUCB (Kveton et al., 2015), 0LS-UCB-C (Degenne and Perchet, 2016), ESCB-C (Perrault et al., 2020b), and 0LS-UCB-C (ours); as well as the two stochastic algorithms: CTS-Gaussian (Perrault et al., 2020a) and c0s-V (ours). Notations: $\\footnote{T w o t y p i c a l a p p l i c a t i o n s c e n a r i o s f o r t h e p r o p o s e d s y s t e m a r e h e a l t h c a r e,a n d l o g i s t i c s a n d w a r e h o u s i n g,i n w h i c h m u l t i p l e I o T d e v i c e s a r e d e p l o y e d c l o s e t o t h e r e c e i v e r a n d t h e t i m e d e l a y b e t w e e n t h e d i r e c t l i n k a n d b a c k s c a t t e r l i n k i s t h u s n e g l i g i b l e.}$ refers to actions; $i$ and $j$ refer to items; $m$ denotes the maximum number of items per action; $B$ is a vector of bounds on the items' rewards; $\\mathbf{T}$ is a covariance-proxy matrix; $\\gamma$ is the maximum of \u201ccorrelationsproxy'\"; we abbreviate $\\operatorname*{max}\\{x,0\\}$ 0 $(x)_{+}$ for any $x\\in\\mathbb{R}\\,;\\bar{C}_{1/T}^{\\mathrm{opt}}$ refers to the complexity of the optimisation step needed in ESCB-C. "], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "2  Covariance-adaptative deterministic algorithm: OLS-UCB-C ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we design a new algorithm that efficiently leverages the semi-bandit feedback. It approximates the coefficients of the covariance matrix $\\Sigma$ online. The approximation is symmetric by construction and yields a coefficient-wise upper bound of $\\Sigma$ , but it is not necessarily positive semi-definite, a constraint that can be challenging to impose in practice. ", "page_idx": 3}, {"type": "text", "text": "2.1  Algorithm: OLS-UCB-C ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We present OLS-UCB-C described in Alg. 2 and detail below the successive steps it performs. ", "page_idx": 3}, {"type": "text", "text": "Initial exploration.  The algorithm first explores by choosing every base item $i\\in[d]$ and every \u201c\"reachable\u201d couple $(i,j)\\in[d]^{2}$ at least once. ", "page_idx": 3}, {"type": "text", "text": "Rewards means estimation.  At each round $t+$ $1\\in[T-1]$ , the algorithm uses an empirical mean $\\hat{\\mu}_{t}$ for $\\mu$ defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mu}_{t}=\\mathbf{N}_{t}^{-1}\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}Y_{s},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{d}_{a}\\ =\\ \\mathrm{diag}(a)\\ \\in\\ M_{d}(\\mathbb{R})$ is the diagonal matrix of the elements in $a\\,\\in\\,\\mathcal{A};\\,n_{t,(i,j)}$ is the number of times items $i$ and $j$ (with possibly $i\\;=\\;j)$ have been chosen together; $\\mathbf{N}_{t}\\,\\,=\\,\\,$ $\\mathrm{diag}((n_{t,(i,i)})_{i\\in[d]})\\in M_{d}(\\mathbb{R})$ is the diagonal matrix of item counts. ", "page_idx": 4}, {"type": "text", "text": "Rewards covariances estimation.  The covariances are estimated by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{\\chi}_{t,(i,j)}=\\hat{\\bf S}_{t,(i,j)}-\\hat{\\mu}_{t,i}\\hat{\\mu}_{t,j}\\;,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where St,(i,i) = $\\begin{array}{r}{\\hat{\\bf S}_{t,(i,j)}\\;=\\;{\\frac{1}{n_{t,(i,j)}}}\\sum_{s=1}^{t}A_{s,i}A_{s,j}Y_{s,i}Y_{s,j}.}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "Algorithm 2 OLS-UCB-C ", "page_idx": 4}, {"type": "text", "text": "Input $\\delta>0$ $B\\in\\mathbb{R}_{+}^{d}$   \nfor $t=1,\\dots,T$ do if $\\left\\{a\\;\\in\\;{\\cal A}\\vert\\operatorname*{min}_{(i,j)\\in a}n_{t,(i,j)}\\;<\\;1\\right\\}\\;\\neq\\;\\emptyset$ then Choose any $A_{t}$ in the above set. else Compute $\\hat{\\mu}_{t-1}$ from (2). Compute $\\hat{\\Sigma}_{t-1}$ from (3) and (4). Compute $\\hat{\\mathbf{Z}}_{t-1}$ from (5). Choose $A_{t}\\in\\mathcal A$ from (6). Environment samples ${Y_{t}}\\in\\mathbb{R}^{d}$ Receive reward $\\begin{array}{r}{\\langle A_{t},Y_{t}\\rangle=\\sum_{i}A_{t,i}Y_{t,i}}\\end{array}$ end if   \nend for ", "page_idx": 4}, {"type": "text", "text": "", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The algorithm uses $\\hat{\\Sigma}_{t}$ , a coefficient-wise upper-confidence bound of $\\Sigma$ whose coefficients are defined for a fixed $\\delta>0$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\hat{\\bf\\Delta}_{t,(i,j)}=\\hat{\\chi}_{t,(i,j)}+\\frac{B_{i}B_{j}}{4}\\biggl(\\frac{5h_{t,\\delta}}{\\sqrt{n_{t,(i,j)}}}+\\frac{h_{t,\\delta}^{2}}{n_{t,(i,j)}}+\\frac{1}{n_{t,(i,j)}^{2}}\\biggr)\\,,}\\\\ &{}&{\\mathrm{~:~}h_{t,\\delta}=\\Bigl(1+2\\log(1/\\delta)+2\\log\\left(t\\log(t)^{2}d(d+1)\\right)+\\log(1+t)\\Bigr)^{1/2}.\\quad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Optimistic action choice. Following the \u2018optimistic\u2019 principle of UcB-like algorithms, the estimated rewards $(\\langle\\hat{\\mu}_{t},a\\rangle)_{a\\in\\mathcal{A}}$ are inflated by bonuses, yielding corresponding upper confidence bounds. The bonuses involve the history through a regularized empirical design matrix (with empirical covariances): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{\\mathbf{Z}}_{t}=\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}\\hat{\\Sigma}_{t}\\mathbf{d}_{A_{s}}+\\mathbf{d}_{\\hat{\\Sigma}_{t}}\\mathbf{N}_{t}+\\|B\\|^{2}\\mathbf{I}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\mathbf{d}_{\\hat{\\Sigma}_{t}}=\\mathrm{diag}(\\hat{\\Sigma}_{t})\\in M_{d}(\\mathbb{R}),$ I is the identity matrix and $\\hat{\\Sigma_{t}}$ is the coefficient-wise upper bound for the covariance matrix defined in (4). Formally, OLS-UCB-C chooses ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{A_{t+1}\\in\\arg\\operatorname*{max}\\left\\{\\left.\\left\\langle a,\\hat{\\mu}_{t}\\right\\rangle+f_{t,\\delta}\\left\\|\\mathbf{N}_{t}^{-1}a\\right\\|_{\\hat{\\mathbf{Z}}_{t}}\\right\\},}}\\\\ {{:f_{t,\\delta}=6\\log(1/\\delta)+6\\Big(\\log(t)+(d+2)\\log(\\log(t))\\Big)+3d\\Big(2\\log(2)+\\log(1+e)\\Big).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Efficiency improvement. While Perrault et al. (2020b) use an axis-realignment technique to derive their confidence regions, our approach builds ellipsoidal confidence regions. This simplifies the computation of an upper confidence bound for each action as we have a closed-form expression. In comparison, Perrault et al. (2020b) need to solve linear programs in convex sets at each iteration. ", "page_idx": 4}, {"type": "text", "text": "2.2  Regret upper bounds ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Theorem 1. Let $T\\in\\mathbb{N}^{*}$ and $\\delta>0$ ", "page_idx": 4}, {"type": "text", "text": "Then, OLS-UCB-C (Alg. 2) satisfies the gap-dependent regret upper bound ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]=\\tilde{O}\\bigg(\\log(m)^{2}\\sum_{i=1}^{d}\\operatorname*{max}_{a\\in\\mathcal{A}/i\\in a,\\Delta_{a}>0}\\frac{\\sigma_{a,i}^{2}}{\\Delta_{a}}\\bigg)\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\begin{array}{r}{\\sigma_{a,i}^{2}=\\sum_{j\\in a}\\operatorname*{max}\\{\\Sigma_{i,j},0\\},}\\end{array}$ and the gap-free regret upperboud ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[R_{T}]=\\tilde{O}\\bigg(\\log(m)\\sqrt{T}\\sqrt{\\sum_{i=1}^{d}\\underset{a\\in\\mathcal{A}/i\\in a}{\\operatorname*{max}}\\sigma_{a,i}^{2}}\\bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The proof is outlined in Section 5 and the specific details are presented in Appendix E. ", "page_idx": 4}, {"type": "text", "text": "Optimal gap-free bound. This result shows that OLS-UCB-C yields the same gap-dependent regret upper bound as ESCB-C (Perrault et al., 2020b) (up to poly-logarithmic factors) and more importantly yields a novel covariance-adaptive and optimal $\\dot{O}(\\sqrt{T})$ gap-free bound, as shown by the following lower-bound proven in Appendix A. Unfortunately, only the positive coeffcients of $\\Sigma$ areconsidered in our bound but the inclusion of negative correlations could be advantageous to reduce the rate at which the regret increases. However, it could complicate the analysis greatly and is thus deferred to future research. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. Let $d,m\\in\\mathbb{N}^{*}$ such that $d/m\\ge2$ is an integer $T\\in\\mathbb{N}^{*}$ ,and $\\Sigma\\succeq0$ a covariance matrix.Then,there exists a stochastic combinatorial semi-bandit with $d$ baseitems,andareward distributionwithcovariancematrix $\\Sigma$ on which for any policy $\\pi$ thepseudoregret satisfies ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]\\geq\\frac{1}{8}\\bigg(T\\sum_{i\\in[d]}\\operatorname*{max}_{a\\in\\mathcal{A},i\\in a}\\sum_{j\\in a}\\Sigma_{i,j}\\bigg)^{1/2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Improvement over CUCB. Our gap-free and gap-dependent bounds outperform those of CUCB (Kveton et al., 2015) no mater the covariance structure, as $(T m d)^{1/2}\\|B\\|_{\\infty}\\gtrsim(\\mathrm{Tr}(\\Sigma)T)^{1/2}$ Besides, in the particular case of a diagonal $\\Sigma$ , our gap-free upper bound gains a factor at least $\\sqrt{m}$ over the nofCUCBInthis senario. $\\sigma_{a,i}^{2}=\\Sigma_{i,i}$ for all $a\\in A$ and $i\\in a$ . Our gap-dependent and gap-free upper bounds are then roughly bounded as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{d}\\frac{\\Sigma_{i,i}}{\\operatorname*{min}_{a\\in A/i\\in a}\\Delta_{a}}\\mathrm{~and~}\\sqrt{\\mathrm{Tr}(\\Sigma)T}\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "respectively. ", "page_idx": 5}, {"type": "text", "text": "Improvement over UCBV.  Assuming that $\\Sigma_{i,j}\\geq0$ for all $i,j$ our upper-bound uniformly improves the one of UCBVof order $\\left(T\\sum_{a}a^{\\top}\\dot{\\Sigma_{a}}\\right)^{1/2}$ since in thiscase $\\begin{array}{r}{\\sum_{i=1}^{d}\\operatorname*{max}_{a\\in\\mathcal{A}\\backslash i\\in\\mathcal{A}}\\sigma_{a,i}^{2}\\leq\\sum_{a}^{\\phantom{.}}\\|a\\|_{\\Sigma}}\\end{array}$ Existing semi-bandit analyses could only leverage semi-bandit feedback in the regime $P\\gg d$ which is natural in combinatorial bandits but not systematic in real-world applications. ", "page_idx": 5}, {"type": "text", "text": "3   New sampling algorithm for combinatorial semi-bandits: Cos-V ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we introduce a randomized algorithm inspired from TS, enabling to get potentially computational complexity at the cost of not leveraging off-diagonal covariances. ", "page_idx": 5}, {"type": "text", "text": "The difficulty in designing and analysing TS algorithms generally stems from controlling the random exploration. To that end, we parametrize the exploration distribution using the same estimators as OLS-UCB-C. ", "page_idx": 5}, {"type": "text", "text": "We propose a sampling strategy using \u201cfrequentist\" estimators, cos- $\\mathtt{V}$ , described in Algorithm 3. ", "page_idx": 5}, {"type": "text", "text": "The algorithm begins with the same exploration phase as OLS-UCB-C. Thereafter at each round $\\bar{t}+1\\in[T-1]$ we sample parameters $(\\tilde{\\mu}_{i,t})_{i\\in[d]}$ using 1-dimensional normal distributions biased toward the positive orthant. Formally, for all $i\\in[d]$ ", "page_idx": 5}, {"type": "text", "text": "3.1 Algorithm: COS-V ", "text_level": 1, "page_idx": 5}, {"type": "table", "img_path": "PI0CDY6nmo/tmp/74603866587ad705380b6cdb23b63b17dc98c61a5020dc42a2aadfc6e8e63ee3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": ", we sample ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{\\mu}_{t,i}\\sim\\mathcal{N}\\bigg(\\hat{\\mu}_{t,i}+(1+g_{t,\\delta})f_{t,\\delta}\\frac{\\hat{\\mathbf{z}}_{t,(i,i)}^{1/2}}{n_{t,(i,i)}},\\,\\,f_{t,\\delta}^{2}\\frac{\\hat{\\mathbf{z}}_{t,(i,i)}}{n_{t,(i,i)}^{2}}\\bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $g_{t,\\delta}=\\left(1+2\\log\\left(2d t\\log(t)^{2}/\\delta\\right)\\right)^{1/2}$ and $f_{t,\\delta}$ is the same as for OLS-UCB-C. ", "page_idx": 5}, {"type": "text", "text": "(c)We denote $\\gtrsim$ for $\\geq$ up to a constant factor. ", "page_idx": 5}, {"type": "text", "text": "3.2  Regret upper bound ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Theorem 3. Let $T\\in\\mathbb{N}^{*}$ ,and $\\delta>0$ ", "page_idx": 6}, {"type": "text", "text": "Then, COs-V (Alg. 3) satisfies the gap-dependent regret upper bound ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]=\\tilde{O}\\bigg(\\log(m)^{2}\\sum_{i=1}^{d}\\frac{m\\pmb{\\Sigma}_{i,i}}{\\Delta_{i,\\operatorname*{min}}}\\bigg)\\,,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\Delta_{i,\\operatorname*{min}}=\\operatorname*{min}\\{\\Delta_{a},\\;a\\in{\\cal A}$ such that $i\\in a\\}$ , and the gap-free regret upper bound ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[R_{T}]=\\tilde{O}\\bigg(\\log(m)\\sqrt{T}\\sqrt{m\\sum_{i=1}^{d}\\Sigma_{i,i}}\\bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The proof is outlined in Section 5 and the specific details can be found in Appendix F. ", "page_idx": 6}, {"type": "text", "text": "Novel variance-dependent bound.  Theorem 3 presents the first variance-dependent bound for a sampling-based semi-bandit algorithm. Unfortunately, integrating the covariances $\\Sigma_{i,j}$ in the leading term is still an open problem. Possible leads include exploring other biasing strategies for sampling, or using oversampling approaches like Abeille and Lazaric (2017) which inflate the confidence regions in the linear bandits setting. ", "page_idx": 6}, {"type": "text", "text": "Novel gap-free regret bound. An important novelty of our gap-dependent bound Eq. (16) is the absenceof $\\Delta_{\\mathrm{min}}^{-m}$ termspresent in the peviousalysesofCTs (Wang andChn,2018s Perralt tal, 2020a). In particular, this improvement yields the first $\\tilde{O}(\\sqrt{T})$ gap-fre regret upper bound for a sampling strategy. ", "page_idx": 6}, {"type": "text", "text": "4   Mean and covariance estimation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we present concentration results for $\\hat{\\mu}_{t}$ (rewards means) and $\\hat{\\Sigma}_{t}$ (rewards covariances, estimated with $\\hat{\\chi}_{t}$ ) used in OLS-UCB-C and COS-V, which are central to prove Theorem 1 and Theorem 3 (sketched in Section 5). ", "page_idx": 6}, {"type": "text", "text": "4.1   Covariance-aware confidence region for the average reward ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Average reward estimation.  Let $a\\in{\\mathcal{A}}$ $t\\geq d(d+1)/2$ , as introduced in Section 2.1, the least square estimator for the mean reward vector $\\mu$ using all the data gathered after round $t$ is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mu}_{t}=\\mathbf{N}_{t}^{-1}\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}Y_{s}=\\mu+\\mathbf{N}_{t}^{-1}\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}\\eta_{s}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the $\\eta_{s}$ denote the deviations $Y_{s}-\\mu$ ", "page_idx": 6}, {"type": "text", "text": "Confidence region design. We design confidence regions inspired from LinUCB literature (Rusmevichientong and Tsitsiklis, 2010; Filippi et al., 2010; Abbasi-Yadkori et al., 2011) and the work of Degenne and Perchet (2016). Major differences with those works include using Bernstein's style concentration inequalities involving the covariance matrix $\\Sigma$ , assuming a multidimensional noise term, and combining them with a covering argument to relax dependence in $d$ (peeling trick from Degenne and Perchet, 2016). We introduce the regularized design matrix defined by ", "page_idx": 6}, {"type": "equation", "text": "$$\n{\\bf Z}_{t}={\\bf V}_{t}+{\\bf N}_{t}{\\bf d}_{\\Sigma}+\\|B\\|^{2}{\\bf I}\\,,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\begin{array}{r}{{\\bf V}_{t}\\,=\\,\\sum_{s=1}^{t}{\\bf d}_{A_{s}}\\{{\\bf\\Sigma}{\\bf d}_{A_{s}}}\\end{array}$ is the design matrix (of which the OLs-UCB-C and COS- $\\boldsymbol{\\cdot}$ use an empirical version). Let $S_{t}=\\mathbf{N}_{t}(\\hat{\\mu}_{t}-\\mu)$ , the deviations of $\\left\\langle a,\\hat{\\mu}_{t}\\right\\rangle$ are bounded as ", "page_idx": 6}, {"type": "equation", "text": "$$\n|\\langle a,\\hat{\\mu}_{t}-\\mu\\rangle|\\leq\\|\\mathbf{N}_{t}^{-1}a\\|\\mathbf{z}_{t}\\,\\,\\|S_{t}\\|_{\\mathbf{Z}_{t}^{-1}}\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Designing a confidence region for $\\|S_{t}\\|_{\\mathbf{Z}_{t}^{-1}}$ therefore allows to control the deviations $|\\langle a,\\hat{\\mu}_{t}-\\mu\\rangle|$ uniformly on $\\boldsymbol{\\mathcal{A}}$ .Let $\\delta>0$ ,we define the event ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\mathcal{G}_{t}=\\left\\{\\left.\\|S_{t}\\|_{\\mathbf{Z}_{t}^{-1}}\\leq f_{t,\\delta}\\right\\},}\\\\ {\\displaystyle f_{t,\\delta}=6\\log(1/\\delta)+6[\\log(t)+(d+2)\\log(\\log(t))]+3d[2\\log(2)+\\log(1+e)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This event can also be written $\\mathcal{G}_{t}=\\left\\{\\ \\|\\hat{\\mu}_{t}-\\mu\\|_{\\mathbf{N}_{t}\\mathbf{Z}_{t}^{-1}\\mathbf{N}_{t}}\\leq f_{t,\\delta}\\right\\}$ and is therefore equivalent to $\\hat{\\mu}_{t}$ belonging to an ellipsoid around the true reward mean vector $\\mu$ ", "page_idx": 6}, {"type": "text", "text": "Confidence region probability. The following result proven in Appendix B presents an upper bound for $\\mathbb{P}(\\mathcal{G}_{t}^{c})$ ", "page_idx": 7}, {"type": "text", "text": "Proposition 1. Let $t\\geq d(d+1)/2$ and $\\delta>0$ Then, $\\mathbb{P}(\\mathcal{G}_{t}^{c})\\leq\\delta/(t\\log(t)^{2})$ ", "page_idx": 7}, {"type": "text", "text": "Proving this result relies on an argument adapted from Faury et al. (2020) and a covering trick from Degenne and Perchet (2016). ", "page_idx": 7}, {"type": "text", "text": "4.2  Confidence interval for covariances estimator ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Rewards covariances estimator. Let $t\\geq d(d+1)/2$ and a \u201creachable\u201d couple $(i,j)\\in[d]^{2}$ . The coefficients of $\\Sigma$ can be estimated online by $\\hat{\\chi}_{t}$ as introduced in Section 2.1 ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\hat{\\chi}_{t,(i,j)}=\\hat{\\bf S}_{t,(i,j)}-\\hat{\\mu}_{t,i}\\hat{\\mu}_{t,j}\\;.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Rewards covariances upper confidence bound. Let $\\delta>0$ . We use the following coefficient-wise upper estimates of $\\Sigma$ in our algorithms ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\hat{\\bf\\Delta}_{t,(i,j)}=\\hat{\\chi}_{t,(i,j)}+\\frac{B_{i}B_{j}}{4}\\biggl(\\frac{5h_{t,\\delta}}{\\sqrt{n_{t,(i,j)}}}+\\frac{h_{t,\\delta}^{2}}{n_{t,(i,j)}}+\\frac{1}{n_{t,(i,j)}^{2}}\\biggr)\\,,}\\\\ &{}&{h_{t,\\delta}=\\biggl(1+2\\log(1/\\delta)+2\\log\\left(t\\log(t)^{2}d(d+1)\\right)+\\log(1+t)\\biggr)^{1/2}.\\qquad\\qquad}\\end{array}\n$$with ", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Favorable event design. We define $\\ensuremath{\\mathcal{C}}_{t}$ as the event where all the coefficients of $\\hat{\\Sigma}_{t}$ are indeed upper bounding those of $\\Sigma$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathcal{C}_{t}=\\left\\{\\forall(i,j)\\in[d]^{2}\\ ^{*}\\mathrm{reachable}^{,},\\ \\hat{\\Sigma}_{t,(i,j)}\\geq\\Sigma_{i,j}\\right\\}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Favorable event probability.  The following result proven in Appendix $\\mathrm{C}$ presents an upper bound for $\\mathbb{P}(\\mathcal{C}_{t}^{c})$ ", "page_idx": 7}, {"type": "text", "text": "Proposition 2. Let $t\\geq d(d+1)/2$ and $\\delta>0$ Then, $\\mathbb{P}(\\mathcal{C}_{t}^{c})\\leq\\delta/(t\\log(t)^{2})$ ", "page_idx": 7}, {"type": "text", "text": "5   Regret upper bounds ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we provide a sketch of the proof for Theorem 1 and Theorem 3. For both OLS-UCB-C andcos- $\\cdot\\nabla$ the idea to bound the regret is to find a sequence of favorable events $(\\mathcal{E}_{t})_{t\\geq d(d+1)/2}$ that are true with high probability, and under which the regret grows logarithmically with time. ", "page_idx": 7}, {"type": "text", "text": "5.1 Template bound ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Let $(\\mathcal{E}_{t})_{t\\in[T]}$ be a sequence of events, then for both OLS-UCB-C and COS-V standard derivations yield ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[R_{T}]\\leq\\Delta_{\\operatorname*{max}}\\Big(d(d+1)/2+\\sum_{t=d(d+1)/2}^{T-1}\\mathbb{P}(\\mathcal{E}_{t}^{c})\\Big)+\\mathbb{E}\\Big[\\sum_{t=d(d+1)/2}^{T-1}\\mathbb{1}\\{\\mathcal{E}_{t}\\}\\Delta_{A_{t+1}}\\Big]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Assuming that the sequence of events $(\\mathcal{E}_{t})_{t\\geq d(d+1)/2}$ happens with high enough probability, it is sufficient to control what happens conditionally to it. In particular, Proposition 6 in Appendix D states that if we can bound $\\Delta_{A_{t+1}}^{2}$ withaliearcombiationof tems evolving as $n_{t,(i,j)}^{-k}$ forevery couple $(i,j)\\in A_{t+1}$ and different $k\\geq1$ , then we can infer a worst-case behaviour, which yields Theorem 1 and Theorem 3. ", "page_idx": 7}, {"type": "text", "text": "In the following we willrefe to the termZ-dld tad+1)P() asthe unfavorable event probabilty and to the term $\\begin{array}{r}{\\mathbb{\\operatorname{\\mathbb{E}}}\\left[\\sum_{t=d(d+1)/2}^{T}\\mathbb{1}\\{\\mathcal{E}_{t}\\}\\Delta_{A_{t+1}}\\right]}\\end{array}$ as the high-probaility regret. ", "page_idx": 7}, {"type": "text", "text": "5.2  Regret of OLS-UCB-C ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "For OLS-UCB-C we consider the sequence of events $\\mathcal{E}_{t}~=~\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}$ for all $t\\ \\geq\\ d(d+1)/2$ corresponding the confidence regions of $(\\hat{\\mu}_{t})_{t\\geq d(d+1)/2}$ and of $(\\Sigma_{t,(i,j)})_{t\\geq d(d+1)/2}$ $(i,j)\\!\\in\\![d]^{2}$ defined in Section 4. Under these events, we can upper-bound the high-probability regret from Eq. (13) with the following proposition (proven in Appendix E.1). ", "page_idx": 7}, {"type": "text", "text": "Proposition 3. Let $\\delta>0$ . Then, OLS-UCB-C yields ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Bigg[\\sum_{t=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\right\\}\\Bigg]=O\\left(\\log(T)^{2}\\log(m)^{2}\\sum_{i=1}^{d}\\operatorname*{max}_{a\\in A/i\\in a}\\frac{\\sigma_{a,i}^{2}}{\\Delta_{a}}\\right),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "as $T\\rightarrow\\infty$ where $\\begin{array}{r}{\\sigma_{a,i}^{2}=\\sum_{j\\in a}(\\Sigma_{i,j})_{+}}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "Conclusion of the proof. Injecting results from Proposition 3 (high-probability regret) as well as Proposition 1 and Proposition 2 (unfavorable event probability) into the template bound (13), we get ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]=O\\left(\\log(T)^{2}\\log(m)^{2}\\sum_{i\\in[d]}\\operatorname*{max}_{a\\in A/i\\in a}\\frac{\\sigma_{a,i}^{2}}{\\Delta_{a}}\\right),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "for OLS-UCB-C as $T\\rightarrow\\infty$ . This provides the gap-dependent bound of Theorem 1. The gap-free bound is detailed in Appendix E.4. It is enabled by the fact that our gap-dependent bound does not incur any term in $\\Delta_{\\operatorname*{min}}^{-2^{-}}$ , unlike Perrault et al. (2020b); Degenne and Perchet (2016). ", "page_idx": 8}, {"type": "text", "text": "5.3 Regret of COS-V ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "For the analysis of our stochastic algorithm COS- $\\boldsymbol{\\cdot}$ we need to consider events related to the sampling distributions in addition to the events $\\mathcal{G}_{t}^{\\prime}$ and $\\ensuremath{\\mathcal{C}}_{t}$ introduced in the precedent section. For this purpose, we denote the event $\\mathcal{H}_{t}$ defined as ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{H}_{t}=\\left\\{\\forall i\\in[d],\\,\\left|\\left(\\hat{\\mu}_{t,i}+(1+g_{t,\\delta})f_{t,\\delta}\\frac{(\\hat{\\bf Z}_{t,i})^{1/2}}{n_{t,i}}\\right)-\\tilde{\\mu}_{t,i}\\right|\\leq g_{t,\\delta}f_{t}\\frac{(\\hat{\\bf Z}_{t,i})^{1/2}}{n_{t,i}}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "The high-level idea of the event $\\mathcal{H}_{t}$ is to ensure that the sampled rewards $\\tilde{\\mu}_{t,i}$ upper-bound the true mean $\\mu_{i}$ while not being too far for all the items $i\\in a^{*}$ . Showing that the event $\\mathcal{H}_{t}$ indeed occurs with high-probability (Lemma 7 in Appendix F) and setting the events $\\mathcal{E}_{t}=\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\mathcal{H}_{t}\\}$ ,we can upper-bound the high-probability regret in the following proposition (proof is in Appendix F.2). ", "page_idx": 8}, {"type": "text", "text": "Proposition 4. Let $\\delta>0$ Then COS- $\\boldsymbol{\\cdot}$ yields ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Bigg[\\sum_{t=d(d+1)}^{T-1}\\Delta_{A_{t+1}}\\mathbb{1}\\big\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\mathcal{H}_{t}\\big\\}\\Bigg]=O\\Bigg(\\log(T)^{3}\\log(m)^{2}\\Big(\\sum_{i=1}^{d}\\frac{m\\Sigma_{i,i}}{\\Delta_{i,\\operatorname*{min}}}\\Big)\\Bigg)\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Conclusion of the proof. Injecting results from Proposition 4 (high-probability regret) as well as Lemma 7, Proposition 1 and Proposition 2 (unfavorable event probability) into the template bound (13) yields ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]=O\\left(\\log(T)^{3}\\log(m)^{2}\\sum_{i\\in[d]}\\frac{m\\Sigma_{i,i}}{\\Delta_{i,\\operatorname*{min}}}\\right),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "as $T\\rightarrow\\infty$ . This provides the gap-dependent bound of Theorem 3. As it does not incur any term in $\\Delta_{\\mathrm{min}}^{-m}$ as in Wang and Chen (2018); Perrault et al. (2020a),this result can be used to derive a $\\tilde{O}(\\sqrt{T})$ gap-free bound for a sampling-based combinatorial semi-bandit algorithm. ", "page_idx": 8}, {"type": "text", "text": "6 Concluding remarks ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We propose and analyze two algorithms for combinatorial semi-bandits. OLS -UCB-C is a deterministic, covariance-adaptive algorithm. Compared to other existing approaches, our algorithm is typically less computationally demanding and yields the first $\\tilde{O}(\\sqrt{T})$ gap-free regret rate that explicitly depends on the covariance of the base item rewards and the structure. COs- $\\mathtt{V}$ is a variance-adaptive, Ts-like algorithm. Its complexity is significantly lower under certain types of constraints, but its regret is suboptimal as it assumes worst-case correlations. However, leveraging the analysis of OLS-UCB-C, it also yields the first $\\tilde{O}(\\sqrt{T})$ gap-free regret upper bound among sampling-based approaches. ", "page_idx": 8}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Abbasi- Yadkori, Y., Pal, D., and Szepesvari, C. (2011). Improved algorithms for linear stochastic bandits. Advances in Neural Information Processing Systems.   \nAbeille, M. and Lazaric, A. (2017). Linear thompson sampling revisited. In Artificial Intelligence and Statistics, pages 176-184. PMLR.   \nAudibert, J.-Y., Munos, R., and Szepesvari, C. (2009). Exploration-exploitation tradeoff using variance estimates in multi-armed bandits. Theoretical Computer Science, 410(19):1876-1902.   \nAuer, P., Cesa-Bianchi, N., and Fischer, P. (2002a). Finite-time analysis of the multiarmed bandit problem. Machine Learning, 47:235-256.   \nAuer, P., Cesa-Bianchi, N., Freund, Y., and Schapire, R. E. (2002b). The nonstochastic multiarmed bandit problem. SIAM Journal on Computing, 32(1):48-77.   \nBr\u00e9gere, M., Gaillard, P., Goude, Y., and Stoltz, G. (2019). Target tracking for contextual bandits: Application to demand side management. In International Conference on Machine Learning.   \nBubeck, S. and Cesa-Bianchi, N. (2012). Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122.   \nChen, W., Wang, Y., and Yuan, Y. (2013). Combinatorial multi-armed bandit: General framework and applications. In International Conference on Machine Learning.   \nCombes, R., Talebi Mazraeh Shahi, M. S., Proutiere, A., et al. (2015). Combinatorial bandits revisited. Advances in Neural Information Processing Systems.   \nCuvelier, T., Combes, R., and Gourdin, E. (2021). Statistically efficient, polynomial-time algorithms for combinatorial semi-bandits. Proceedings of the ACM on Measurement and Analysis of Computing Systems, 5(1):1-31.   \nDegenne, R. and Perchet, V. (2016). Combinatorial semi-bandit with known covariance. Advances in Neural Information Processing Systems.   \nFaury, L., Abeille, M., Calauzenes, C., and Fercoq, O. (2020). Improved optimistic algorithms for logistic bandits. In International Conference on Machine Learning, pages 3052-3060. PMLR.   \nFilippi, S., Cappe, O., Garivier, A., and Szepesvari, C. (2010). Parametric bandits: The generalized linear case. Advances in Neural Information Processing Systems.   \nGuo, D., Ktena, S. I., Myana, P. K., Huszar, F., Shi, W., Tejani, A., Kneier, M., and Das, S. (2020). Deep Bayesian bandits: Exploring in online personalized recommendations. In Conference on Recommender Systems.   \nKveton, B., Wen, Z., Ashkan, A., and Szepesvari, C. (2015). Tight regret bounds for stochastic combinatorial semi-bandits. In International Conference on Artificial Intelligence and Statistics.   \nLattimore, T. and Szepesvari, C. (2020). Bandit algorithms. Cambridge University Press.   \nLiu, X., Zuo, J., Wang, S., Joe-Wong, C., Lui, J., and Chen, W. (2022). Batch-size independent regret bounds for combinatorial semi-bandits with probabilisticallytriggered arms or independent arms. Advances in Neural Information Processing Systems.   \nPerrault, P., Boursier, E., Valko, M., and Perchet, V. (2020a). Statistical efficiency of thompson sampling for combinatorial semi-bandits. Advances in Neural Information Processing Systems, 33:5429-5440.   \nPerrault, P, Valko, M, and Perchet, V. (2020b). Covariance-adapting algorithm for semi-bandits with application to sparse outcomes. In Conference on Learning Theory.   \nRusmevichientong, P. and Tsitsiklis, J. N. (2010). Linearly parameterized bandits. Mathematics of Operations Research, 35(2):395-411.   \nTabei, G., Ito, Y., Kimura, T., and Hirata, K. (2023). Design of multi-armed bandit-based routing for in-network caching. IEEE Access.   \nThompson, W. R. (1933). On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3-4):285-294.   \nWang, S. and Chen, W. (2018). Thompson sampling for combinatorial semi-bandits. In International Conference on Machine Learning.   \nZeng, C., Wang, Q., Mokhtari, S., and Li, T. (2016). Online context-aware recommendation with time varying multi-armed bandit. In International Conference on Knowledge Discovery and Data Mining. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "The Supplementary is organized as follows: ", "page_idx": 11}, {"type": "text", "text": "-Appendix A proves the lower bound from Theorem 2,   \n-Appendix B outlines proofs concerning the concentration of the average estimator (Propositions1)   \nAppendix C presents those for the covariance estimator (Proposition 2),   \n-Appendix D establishes general propositions used to upper-bound the number of times each item is chosen,   \n- Appendix E and Appendix F detail proofs for OLS-UCB-C and COS-V,   \n-Appendix G presents some experimental results. ", "page_idx": 11}, {"type": "text", "text": "A Proof of the lower bound (Theorem 2) ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "Theorem 2. Let $d,m\\in\\mathbb{N}^{*}$ such that $d/m\\ge2$ is an integer, $T\\in\\mathbb{N}^{*}$ ,and $\\Sigma\\succeq0$ a covariance matrix.Then,there exists a stochastic combinatorial semi-bandit with $d$ baseitems,andareward distributionwithcovariancematrix $\\Sigma$ on which for any policy $\\pi$ ,thepseudoregretsatisfies ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]\\geq\\frac{1}{8}\\bigg(T\\sum_{i\\in[d]}\\operatorname*{max}_{a\\in\\mathcal{A},i\\in a}\\sum_{j\\in a}\\Sigma_{i,j}\\bigg)^{1/2}.\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Proof. We follow the methodology of Auer et al. (2002b), modifying it to account for the different variances among actions. ", "page_idx": 11}, {"type": "text", "text": "Let $d,m\\in\\mathbb{N}^{*}$ such that $d/m\\ge2$ is an integer, $T\\in\\mathbb{N}^{*}$ , and a covariancematrix $\\Sigma\\succeq0$ . We consider the structure where $\\mathcal{A}=\\{a_{1},\\dots,a_{d/m}\\}\\,\\subset\\,\\{0,1\\}^{d}$ contains $d/m$ disjoint actions each having $m$ base elements. We consider that for all $p\\in[d/m]$ \uff0c $(a_{p})_{i\\in[d]}=\\left(\\mathbb{1}\\left\\{(p-1)m<i\\leq p m\\right\\}\\right)_{i\\in[d]}$ . Let $\\pi$ be a policy. As all the actions are disjoints, we can reduce ourselves to a multi-armed bandit with $d/m$ actions, where for all $p\\in[d/m]$ the variance of the $p$ -th action is $\\langle a_{p},\\Sigma_{p}\\rangle$ ", "page_idx": 11}, {"type": "text", "text": "Let $\\Sigma^{\\prime}\\in M_{d/m}(\\mathbb{R})$ be the diagonal matrix where for all $p\\in[d/m]$ \uff0c $\\Sigma_{p,p}^{\\prime}=a_{p}^{\\top}\\Sigma a_{p}$ . Let $c>0$ and ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\Delta=2c\\sqrt{\\Sigma_{\\mathrm{min}}^{\\prime}\\frac{\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}}{T}}\\,,\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "where Em $\\begin{array}{r}{\\Sigma_{\\mathrm{min}}^{\\prime}=\\operatorname*{min}_{p\\in[d/m]}\\Sigma_{p,p}^{\\prime}}\\end{array}$ ", "page_idx": 11}, {"type": "text", "text": "We denote $G_{0}\\sim\\mathcal{N}(0,\\Sigma^{\\prime})$ a $(d/m)$ -dimensional centered Gaussian distribution with covariance matrix $\\Sigma^{\\prime}$ . Let $p\\in[d/m]$ , we consider the mean vector $\\mu^{(p)}\\in\\mathbb{R}^{d/m}$ having coordinate O everywhere and $\\Delta$ at coordinate $p$ for all $i\\in[d/m]$ \uff0c \u03bc(P) =1{ = p}. We introduce the Gaussian reward distributions $G_{p}\\sim\\mathcal{N}(\\boldsymbol{\\mu}^{(p)},\\boldsymbol{\\Sigma}^{\\prime})$ and denote $\\begin{array}{r}{T_{p}\\,=\\,\\sum_{t=1}^{T}\\mathbb{1}\\{A_{t}\\,=\\,p\\}}\\end{array}$ Then, using policy $\\pi$ and considering the reward distributions $G_{p}$ and $\\bar{G}_{0}$ , the average number of times action $p$ has been chosen satisfies ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\Big|\\mathbb{E}_{\\pi,G_{p}}[T_{p}]-\\mathbb{E}_{\\pi,G_{0}}[T_{p}]\\Big|\\le T\\,\\mathrm{TV}\\Big((\\pi,G_{0}),(\\pi,G_{p})\\Big)\\le T\\sqrt{\\frac12\\mathrm{KL}\\Big((\\pi,G_{0}),(\\pi,G_{p})\\Big)}\\,,\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "where TV denotes the total variation distance, KL denotes the Kullback-Leibler divergence and the last inequality uses Pinsker's inequality. Then, using the divergence decomposition between multi-armed bandits (Lemma 15.1 in Lattimore and Szepesvari, 2020), ", "page_idx": 11}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{KL}\\big((\\pi,G_{0}),(\\pi,G_{p})\\big)=\\displaystyle\\sum_{k=1}^{d/m}\\mathbb{E}_{\\pi,G_{0}}\\big[T_{k}\\big]\\;\\mathrm{KL}\\big(\\mathcal{N}(0,\\Sigma^{\\prime}),\\mathcal{N}(\\mu^{(p)},\\Sigma^{\\prime})\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{k=1}^{d/m}\\mathbb{E}_{\\pi,G_{0}}\\big[T_{k}\\big]\\;\\frac{\\big(\\mu_{k}^{(p)}\\big)^{2}}{2\\Sigma_{k,k}^{\\prime}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 11}, {"type": "text", "text": "Reinjecting this expression into Eq. (18), we get ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{\\pi,G_{p}}[T_{p}]\\le\\mathbb{E}_{\\pi,G_{0}}[T_{p}]+\\frac{T}{2}\\sqrt{\\displaystyle{\\sum_{k=1}^{d/m}\\frac{\\big(\\mu_{k}^{(p)}\\big)^{2}}{\\mathbb{E}_{k,k}^{\\prime}}\\mathbb{E}_{\\pi,G_{0}}[T_{k}]}}}&{}\\\\ {=\\mathbb{E}_{\\pi,G_{0}}[T_{p}]+\\frac{T}{2}\\sqrt{\\displaystyle{\\frac{1}{\\sum_{p,p}^{\\prime}\\Delta^{2}}\\mathbb{E}_{\\pi,G_{0}}[T_{p}]}}}&{}\\\\ {=\\mathbb{E}_{\\pi,G_{0}}[T_{p}]+c\\sqrt{T\\mathbb{E}_{\\pi,G_{0}}[T_{p}]\\displaystyle{\\sum_{\\sum_{p,p}^{\\prime},k=1}^{\\sum_{p}^{\\prime}\\frac{d/m}{\\sum_{k=1}^{d}}\\mathbb{E}_{k,k}^{\\prime}}}}}&{~~~+\\mathrm{erinjec}}\\\\ {\\le\\mathbb{E}_{\\pi,G_{0}}[T_{p}]+c\\sqrt{T\\mathbb{E}_{\\pi,G_{0}}[T_{p}]\\displaystyle{\\sum_{k=1}^{d/m}\\mathbb{E}_{k,k}^{\\prime}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Now, summing over the actions $p$ ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{p=1}^{d/m}\\mathbb{E}_{\\pi,G_{p}}[T_{p}]\\leq\\sum_{p=1}^{d/m}\\mathbb{E}_{\\pi,G_{0}}[T_{p}]+c\\sqrt{T\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}\\displaystyle\\sum_{p=1}^{d/m}\\sqrt{\\mathbb{E}_{\\pi,G_{0}}[T_{p}]}}}\\\\ &{}&{\\leq T+c\\sqrt{T\\displaystyle\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}}\\sqrt{\\displaystyle\\frac{d}{m}}\\sqrt{\\displaystyle\\sum_{p=1}^{d/m}\\mathbb{E}_{\\pi,G_{0}}[T_{p}]}\\qquad\\gets\\mathrm{Cauchy\u2013Schwarz}}\\\\ &{}&{\\leq T+c T\\sqrt{\\displaystyle\\frac{d}{m}\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Wedenote $R_{T}^{\\left(p\\right)}$ the average cumulative regret inurred with the reward distribution $G_{p}$ ,then ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{p=1}^{d/m}R_{P}^{(p)}=\\Delta\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Taking C = $\\begin{array}{r}{c=\\frac{1}{2}\\frac{1}{\\sqrt{\\Sigma_{\\operatorname*{min}}^{\\prime}}}(1-\\frac{m}{d})}\\end{array}$ ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{p=1}^{d/m}R_{T}^{(p)}\\ge\\frac{d}{m}\\sqrt{T\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}\\,\\frac{1}{2}\\biggl(1-\\frac{m}{d}\\biggr)^{2}}}}\\\\ &{}&{\\ge\\frac{1}{8}\\frac{d}{m}\\sqrt{T\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}}\\leftarrow\\mathrm{as}\\;m/d\\le1/2\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Therefore, there exists at least one instance $p^{*}\\in[d/m]$ such that ", "page_idx": 13}, {"type": "equation", "text": "$$\nR_{T}^{(p^{*})}\\geq\\frac{1}{8}\\sqrt{T\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}}\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Now, decomposing ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{d/m}\\Sigma_{k,k}^{\\prime}=\\sum_{k=1}^{d/m}\\Big(\\sum_{i\\in a_{k}}\\sum_{j\\in a_{k}}\\Sigma_{i,j}\\Big)=\\sum_{i\\in[d]}\\operatorname*{max}_{a\\in\\mathcal{A},i\\in a}\\sum_{j\\in a}\\Sigma_{i,j}\\,,\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "we get ", "page_idx": 13}, {"type": "equation", "text": "$$\nR_{T}^{(p^{*})}\\geq\\frac18\\sqrt{T\\sum_{i\\in[d]}\\operatorname*{max}_{a\\in\\mathcal{A},i\\in a}\\sum_{j\\in a}\\Sigma_{i,j}}\\;.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "B  Concentration of the average rewards estimations (Proposition 1) ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proposition 1. Let $t\\geq d(d+1)/2$ and $\\delta>0$ Then, $\\mathbb{P}(\\mathcal{G}_{t}^{c})\\leq\\delta/(t\\log(t)^{2})$ ", "page_idx": 13}, {"type": "text", "text": "Proof. Let $t\\geq d(d+1)/2$ and $\\delta>0$ ", "page_idx": 13}, {"type": "text", "text": "We have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f_{t,\\delta}=6\\log(1/\\delta)+6\\Big(\\log(t)+(d+2)\\log(\\log(t))\\Big)+3d\\Big(2\\log(2)+\\log(1+e)\\Big)}\\\\ &{\\quad\\quad=6\\log\\left(\\frac{t\\log(t)^{2}}{\\delta}\\bigg(\\frac{\\log(t)}{\\log(1+(e-1))}\\bigg)^{d}+\\Big(6d\\log(2)+3d\\log(2+(e-1))\\Big)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Covering argument (Peeling trick).   The peeling trick consists in separating the space of trajectories uptoround $t$ into an exponentially large number of parts, each having an exponentially small probability. ", "page_idx": 13}, {"type": "text", "text": "Formally, let $0<\\epsilon<1$ . For each $p\\in\\mathbb{N}^{d}$ we associate the set ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{D}_{p}=\\left\\{x\\in\\mathbb R^{d}\\mathrm{~s.t.~}\\forall i\\in[d],\\;(1+\\epsilon)^{p_{i}}\\leq x_{i}<(1+\\epsilon)^{p_{i}+1}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "As an abuse ofnotation, we denoteby $\\left(t\\in\\mathcal{D}_{p}\\right)$ the event $\\left(\\left(n_{t,(i,i)}+1\\right)_{i\\in[d]}\\in\\mathcal{D}_{p}\\right)$ ", "page_idx": 13}, {"type": "text", "text": "Setting $\\begin{array}{r}{P_{t,\\epsilon}=\\left\\lfloor\\frac{\\log(t)}{\\log(1+\\epsilon)}\\right\\rfloor}\\end{array}$ , we define for each $p\\in[P_{t,\\epsilon}]^{d}$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\mathbf{N}}_{p}=\\mathrm{diag}\\Big(\\big((1+\\epsilon)^{p_{i}}\\big)_{i\\in[d]}\\Big)\\in M_{d}(\\mathbb{R})\\,,}\\\\ &{\\mathbf{Z}_{t,p}=\\mathbf{V}_{t}+\\tilde{\\mathbf{N}}_{p}\\mathbf{d}_{\\Sigma}+\\|B\\|^{2}\\mathbf{I}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "In particular, under the event $\\left(t\\in\\mathcal{D}_{p}\\right)$ $\\mathbf{N}_{t}\\preceq(1+\\epsilon)\\tilde{\\mathbf{N}}_{p}$ ", "page_idx": 13}, {"type": "text", "text": "Using this covering, we decompose ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}(\\mathcal{G}_{t}^{c})=\\mathbb{P}\\Bigg(\\Bigg\\|\\displaystyle\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}\\eta_{s}\\Bigg\\|_{\\mathbf{z}_{t}^{-1}}>f_{t,\\delta}\\Bigg)}\\\\ &{\\qquad=\\displaystyle\\sum_{p\\in[P_{t,\\epsilon}]^{d}}\\mathbb{P}\\Bigg(\\Big(\\|S_{t}\\|_{\\mathbf{z}_{t}^{-1}}>f_{t,\\delta}\\Big)\\cap(t\\in\\mathcal{D}_{p})\\Bigg)}\\\\ &{\\qquad\\le\\displaystyle\\sum_{p\\in[P_{t,\\epsilon}]^{d}}\\mathbb{P}\\Bigg(\\Big(\\|S_{t}\\|_{\\mathbf{z}_{t,p}^{-1}}>f_{t,\\delta}\\Big)\\cap(t\\in\\mathcal{D}_{p})\\Bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We now apply the following Lemmas. ", "page_idx": 13}, {"type": "text", "text": "Lemma 1. Let $t\\geq d(d+1)/2$ \uff0c $0<\\epsilon<1$ $p\\in[P_{t,\\epsilon}]^{d}$ ,and $\\delta>0$ Then, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\|S_{t}\\|_{{\\mathbf Z}_{t,p}^{-1}}>6\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\Big)+6\\log(1/\\delta)\\Bigg)\\leq\\delta\\,,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Norm}_{p}=\\int_{\\lambda\\in\\mathbb R^{d}}\\mathbb{1}\\left\\{\\|\\mathbf{Z}_{0,p}^{1/2}\\lambda\\|\\leq\\displaystyle\\frac{1}{2}\\right\\}\\exp\\{-\\|\\lambda\\|_{\\mathbf{Z}_{0,p}}^{2}\\}d\\lambda\\,,}\\\\ {\\mathrm{Norm}_{t,p}=\\int_{\\lambda\\in\\mathbb R^{d}}\\mathbb{1}\\left\\{\\|\\mathbf{Z}_{t,p}^{1/2}\\lambda\\|\\leq\\displaystyle\\frac{1}{2}\\right\\}\\exp\\{-\\|\\lambda\\|_{\\mathbf{Z}_{t,p}}^{2}\\}d\\lambda\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Lemma 2. Let $t\\geq d(d+1)/2$ \uff0c $0<\\epsilon<1$ and $p\\in[P_{t,\\epsilon}]^{d}$ . Then, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\log\\left(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{p,t}}\\right)\\leq d\\log(2)+\\frac{1}{2}\\log\\left(\\frac{\\operatorname*{det}({\\mathbf Z}_{t,p})}{\\operatorname*{det}({\\mathbf Z}_{0,p})}\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Moreover, under event $(t\\in\\mathcal{D}_{p}$ ) ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{p,t}}\\Big)\\leq d\\log(2)+\\frac{1}{2}d\\log(2+\\epsilon)\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "In our case, setting $\\epsilon=e-1$ , they yield ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathcal{O}_{i}^{\\varepsilon}\\sum_{p\\in\\mathbb{N}_{s},\\eta\\in\\mathbb{N}}\\mathbb{P}\\bigg(\\bigg\\{\\|S\\|_{\\mathcal{X}_{\\varepsilon}^{\\varepsilon}}>\\theta\\log\\bigg(\\frac{\\mathrm{I}(\\log(\\hat{t})^{2})}{\\delta}\\log(t)^{2}\\bigg)+\\bigg(\\6\\log(2)+3\\log_{\\theta}\\bigg)\\bigg.}}\\\\ &{\\leq\\sum_{p\\in\\mathbb{N}_{s},\\eta\\in\\mathbb{N}_{s}}\\mathbb{P}\\bigg(\\bigg\\{\\|S\\|_{\\mathcal{X}_{\\varepsilon}^{\\varepsilon}}>\\mathrm{etor}\\bigg(\\frac{\\mathrm{I}(\\log(t)^{2})}{\\delta}\\log(t)^{2}\\bigg)+6\\log\\bigg(\\frac{\\mathrm{Norm}_{p}}{3\\log(t)}\\bigg)\\bigg\\}}}\\\\ &{\\leq\\sum_{p\\in\\mathbb{N}_{s},\\eta\\in\\mathbb{N}_{s}}\\mathbb{P}\\bigg(\\bigg\\{\\|S\\|_{\\mathcal{X}_{\\varepsilon}^{\\varepsilon}}>\\mathrm{etor}\\bigg(\\frac{\\mathrm{I}(\\log(t)^{2})}{\\delta}\\log(t)^{2}\\bigg)+6\\log\\bigg(\\frac{\\mathrm{Norm}_{p}}{3\\log(t)}\\bigg)\\bigg\\}}}\\\\ &{\\leq\\sum_{p\\in\\mathbb{N}_{s},\\eta\\in\\mathbb{N}_{s}}\\mathbb{P}\\bigg(\\bigg\\{\\|S\\|_{\\mathcal{X}_{\\varepsilon}^{\\varepsilon}}>\\mathrm{etor}\\bigg(\\frac{\\mathrm{I}(\\log(t)^{2})}{\\delta}\\log(t)^{2}\\bigg)+6\\log\\bigg(\\frac{\\mathrm{Norm}_{p}}{3\\log(t)}\\bigg)\\bigg\\}}}\\\\ &{\\leq\\sum_{p\\in\\mathbb{N}_{s},\\eta\\in\\mathbb{N}_{s}}\\frac{\\delta}{p\\log(t)^{2}\\log(t)^{2}}+16\\pi m}\\\\ &{=\\delta\\frac{1}{p\\log(t)^{2}}\\frac{1}{p\\log(t)^{2}}\\log(t^{2}}\\\\ &{=\\frac{\\delta}{p\\log(t)^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "B.1 Proof of Lemma 1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lemma 1. Let $t\\geq d(d+1)/2$ \uff0c $0<\\epsilon<1$ $p\\in[P_{t,\\epsilon}]^{d}$ ,and $\\delta>0$ Then, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\|S_{t}\\|_{{\\mathbf Z}_{t,p}^{-1}}>6\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\Big)+6\\log(1/\\delta)\\Bigg)\\leq\\delta\\,,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Norm}_{p}=\\int_{\\lambda\\in\\mathbb R^{d}}\\mathbb{1}\\left\\{\\|\\mathbf{Z}_{0,p}^{1/2}\\lambda\\|\\leq\\displaystyle\\frac{1}{2}\\right\\}\\exp\\{-\\|\\lambda\\|_{\\mathbf{Z}_{0,p}}^{2}\\}d\\lambda\\,,}\\\\ {\\mathrm{Norm}_{t,p}=\\int_{\\lambda\\in\\mathbb R^{d}}\\mathbb{1}\\left\\{\\|\\mathbf{Z}_{t,p}^{1/2}\\lambda\\|\\leq\\displaystyle\\frac{1}{2}\\right\\}\\exp\\{-\\|\\lambda\\|_{\\mathbf{Z}_{t,p}}^{2}\\}d\\lambda\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. We adapt the proofs from Faury et al. (2020), which adapts Abbasi- Yadkori et al. (2011) itself. Let $\\dot{t}\\geq d(d+\\mathbf{\\bar{1}})/2$ $0<\\epsilon<1$ $p\\in[\\dot{P}_{t,\\epsilon}]^{d}$ ,and $\\delta>0$ ", "page_idx": 15}, {"type": "text", "text": "Let $\\lambda\\in\\mathbb{R}^{d}$ such that $\\begin{array}{r}{\\|\\lambda\\|\\leq\\frac{1}{2\\|B\\|}}\\end{array}$ and $s\\in[t]$ .We denote $\\mathcal{F}_{t-1}^{\\prime}=\\sigma(A_{1},Y_{1},\\ldots,A_{t-1},Y_{t-1},A_{t}).$ Then, $\\|\\boldsymbol{\\lambda}^{\\top}\\mathbf{d}_{A_{s}}\\eta_{s}\\|\\leq1/2$ and ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}\\bigg[\\exp\\Big(\\lambda^{\\top}\\mathbf{d}_{A_{s}}\\eta_{s}-\\lambda^{\\top}\\mathbf{d}_{A_{s}}\\Sigma\\mathbf{d}_{A_{s}}\\lambda\\Big)\\bigg|\\mathcal{F}_{s-1}^{\\prime}\\bigg]\\leq1\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which yilds that $\\Big(M_{k}(\\lambda)\\Big)_{k\\in\\mathbb{N}^{*}}=\\Big(\\exp\\big(\\lambda^{\\top}S_{k}-\\|\\lambda\\|_{V_{k}}^{2}\\big)\\Big)_{k\\in\\mathbb{N}^{*}}$ is a $\\mathcal{F}_{k}^{\\prime}$ -supermartingale. ", "page_idx": 15}, {"type": "text", "text": "Let $p\\in[P_{t,\\epsilon}]^{d}$ , we consider the density $g_{p}$ of a $d$ -dimensional Gaussian with covariance matrix $\\begin{array}{r}{\\frac{1}{2}\\big(\\tilde{\\mathbf{N}}_{p}\\mathbf{d}_{\\Sigma}+\\|B\\|^{2}\\mathbf{I}\\big)^{-1}=\\frac{1}{2}\\mathbf{Z}_{0,p}^{-1}}\\end{array}$ truncated inthe elisoid $\\{x\\in\\mathbb{R}^{d}$ \uff0c $\\|\\mathbf{Z}_{0,p}^{1/2}x\\|\\leq\\frac{1}{2}\\}$ \uff0c ", "page_idx": 15}, {"type": "equation", "text": "$$\ng_{p}(x)=\\frac{\\mathbb{1}\\!\\left\\{x\\in\\mathbb{R}^{d},\\;\\|\\mathbf{Z}_{0,p}^{1/2}x\\|\\leq\\frac{1}{2}\\right\\}}{\\mathrm{Norm}_{p}}\\exp\\Big(-\\|x\\|_{\\mathbf{Z}_{0,p}}^{2}\\Big)\\,,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\mathrm{Norm}_{p}$ is the normalisation constant. ", "page_idx": 15}, {"type": "text", "text": "W ntegrate $\\Big(M_{k}(\\lambda)\\Big)_{k\\in\\mathbb{N}^{*}}$ for $\\lambda\\sim g_{p}$ , and define $(\\bar{M}_{p,k})_{k\\in\\mathbb{N}^{*}}$ as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\bar{M}_{p,k}=\\int_{\\lambda\\in\\mathbb{R}^{d}}M_{k}(\\lambda)d\\lambda=\\int_{\\lambda\\in\\mathbb{R}^{d}}\\frac{\\mathbb{1}\\{\\|\\mathbf{Z}_{0,p}^{1/2}\\lambda\\|\\leq\\frac{1}{2}\\}}{\\mathrm{Norm}_{p}}\\exp{\\left(\\lambda^{\\top}S_{k}-\\|\\lambda\\|_{\\mathbf{Z}_{k,p}}^{2}\\right)}d\\lambda\\,,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which is still a supermartingale. ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\widehat{u}_{p,k}=\\frac{\\exp(\\lambda_{q}^{*}\\gamma_{S}-\\|\\lambda_{q}^{*}\\|_{\\mathcal{Z}_{k}}^{2})}{\\operatorname{Norm}_{p}}\\int_{\\|\\mathbb{Z}_{q}^{1/2}\\|_{\\mathcal{Z}_{k}}^{2},1\\|\\boldsymbol{\\mathcal{Z}}_{k}^{*}\\|}\\exp\\left((\\lambda-\\lambda_{q}^{*})^{\\top}S_{l}-\\|\\lambda\\|_{\\mathcal{Z}_{k},p}^{2}+\\|\\lambda_{q,p}^{*}\\|_{\\mathcal{Z}_{k},p}^{2}\\right)d\\lambda}\\\\ {=\\frac{\\exp(\\lambda_{q}^{*}\\gamma_{S}-\\|\\lambda_{q}^{*}\\|_{\\mathcal{Z}_{k}}^{2})}{\\operatorname{Norm}_{p}}\\int_{\\|\\mathbb{Z}_{q}^{1/2}\\|_{\\mathcal{Z}_{k}}^{2}+\\|\\mathbb{Z}_{q,p}^{1/2}\\|_{\\mathcal{Z}_{k},p}\\|_{\\mathcal{Z}_{k}}^{2}}\\exp\\left(\\lambda^{\\top}S_{k}-\\|\\lambda\\|_{\\mathcal{Z}_{k},p}^{2}-2\\lambda^{\\top}\\mathbb{Z}_{k,p}\\lambda_{q,p}^{*}\\right)d\\lambda}\\\\ {\\geq\\frac{\\exp(\\lambda_{q}^{*}\\gamma_{S}-\\|\\lambda_{q}^{*}\\|_{\\mathcal{Z}_{k}}^{2})}{\\operatorname{Norm}_{p}}\\int_{\\|\\mathbb{Z}_{q}^{1/2}\\|_{\\mathcal{Z}_{k},p}^{2}}\\exp\\left(\\lambda^{\\top}S_{k}-\\|\\lambda\\|_{\\mathcal{Z}_{k},p}^{2}-2\\lambda^{\\top}\\mathbb{Z}_{k,p}\\lambda_{p}^{*}\\right)d\\lambda}\\\\ {=\\frac{\\exp(\\lambda_{q}^{*}\\gamma_{S}-\\|\\lambda_{q}^{*}\\|_{\\mathcal{Z}_{k}}^{2})}{\\operatorname{Norm}_{p}}\\int_{\\|\\mathbb{Z}_{q}^{1/2}\\|_{\\mathcal{Z}_{k},p}^{2}}\\exp\\left(\\lambda^{\\top}\\left(S_{k}-2\\mathbb{Z}_{k,p}\\lambda_{p,p}^{*}\\right)-\\|\\lambda\\|_{\\mathcal{Z}_{k},p}^{2}\\right)d\\lambda}\\\\ {=\\frac{\\exp(\\lambda\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where we can recognize $g_{k,p}$ the dnsity of a $d$ mensilGassawivran $\\scriptstyle{\\frac{1}{2}}\\mathbf{Z}_{k,p}^{-1}$ \uff0c truncated in the ellipsoid $\\left\\{x\\in\\mathbb{R}^{d},\\ \\lVert\\mathbf{Z}_{0,p}^{1/2}x\\rVert\\leq\\frac{1}{4}\\right\\}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\ng_{k,p}(x)=\\frac{\\P\\{\\|\\mathbf Z_{0,p}^{1/2}x\\|\\leq\\frac{1}{4}\\}}{\\mathrm{Norm}_{k,p}}\\exp\\Big(-\\|x\\|_{\\mathbf Z_{k,p}}^{2}\\Big)\\,,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with $\\mathrm{Norm}_{k,p}$ the normalisation constant. ", "page_idx": 15}, {"type": "text", "text": "Besides, Jensen's inequality yields ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\int_{\\lambda\\in\\mathbb{R}^{d}}\\frac{\\mathbb{I}\\left\\{\\|\\mathbf{Z}_{0,p}^{1/2}\\lambda\\|\\leq\\frac{1}{4}\\right\\}}{\\mathrm{Norm}_{k,p}}\\exp\\left(\\lambda^{\\top}\\left(S_{k}-2\\mathbf{Z}_{k,p}\\lambda_{t,p}^{*}\\right)-\\|\\lambda\\|_{\\mathrm{Z}_{k,p}}^{2}\\right)d\\lambda}\\\\ &{\\ \\ \\ =\\displaystyle\\int_{\\mathbb{R}^{d}}g_{k,p}(\\lambda)\\exp\\left(\\lambda^{\\top}\\Big(S_{k}-2\\mathbf{Z}_{k,p}\\lambda_{t,p}^{*}\\Big)\\right)d\\lambda}\\\\ &{\\ \\ \\ \\ \\geq\\exp\\left(\\displaystyle\\int_{\\mathbb{R}^{d}}g_{t,p}(\\lambda)\\lambda^{\\top}\\Big(S_{k}-2\\mathbf{Z}_{k,p}\\lambda_{t,p}^{*}\\Big)d\\lambda\\right)}\\\\ &{\\ \\ \\ =\\exp\\left(\\left(S_{k}-2\\mathbf{Z}_{k,p}\\lambda_{t,p}^{*}\\right)^{\\top}\\displaystyle\\int_{\\mathbb{R}^{d}}g_{t,p}(\\lambda)\\lambda d\\lambda\\right)}\\\\ &{\\ \\ \\ =1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Therefore, for all $k\\in\\mathbb{N}^{*}$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n1\\geq\\bar{M}_{p,k}\\geq\\frac{\\mathrm{Norm}_{k,p}}{\\mathrm{Norm}_{p}}\\exp(\\lambda_{t,p}^{*}S_{k}-\\|\\lambda_{t,p}^{*}\\|_{\\mathbf{Z}_{k,p}}^{2})\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Markov's inequality yields ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta\\geq\\mathbb{P}\\bigg(\\bar{M}_{p,k}\\geq\\frac{1}{\\delta}\\bigg)}\\\\ &{\\phantom{\\delta\\geq}\\mathbb{P}\\bigg(\\frac{\\mathrm{Norm}_{k,p}}{\\mathrm{Norm}_{p}}\\exp(\\lambda_{t,p}^{*\\top}S_{k}-\\|\\lambda_{t,p}^{*}\\|_{\\mathbf{Z}_{k,p}}^{2})\\geq\\frac{1}{\\delta}\\bigg)}\\\\ &{\\phantom{\\leq}=\\mathbb{P}\\bigg(\\lambda_{t,p}^{*\\top}S_{k}-\\|\\lambda_{t,p}^{*}\\|_{\\mathbf{Z}_{k,p}}^{2}\\geq\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{k,p}}\\Big)+\\log(1/\\delta)\\bigg)\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Taking $k=t$ in particular gives ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\delta\\geq\\mathbb{P}\\left(\\operatorname*{max}_{\\|\\mathbf{Z}_{0,p}^{1\\slash2}\\lambda\\|\\leq\\frac{1}{4}}\\lambda^{\\top}S_{t}-\\|\\lambda\\|_{\\mathbf{Z}_{t,p}}^{2}\\geq\\log\\left(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\right)+\\log(1/\\delta)\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The constraint on $\\lambda$ in the inner expression prevent to use the usual optimal value for subgaussian r.v. Wwhich could give a bound for $\\|S_{t}\\|_{Z_{t,p}^{-1}}^{2}$ Instead,we introduce ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\lambda_{t,p}=\\frac{1}{4}\\frac{Z_{t,p}^{-1}S_{t}}{||S_{t}||_{Z_{t,p}^{-1}}}\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for which ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\mathbf{Z}_{0,p}^{1/2}\\lambda_{t,p}\\|\\leq\\displaystyle\\frac{1}{4}\\|\\mathbf{Z}_{0,p}^{1/2}\\mathbf{Z}_{t,p}^{-1/2}\\|\\frac{\\|S_{t}\\|_{\\mathbf{Z}_{t,p}^{-1}}}{\\|S_{t}\\|_{\\mathbf{Z}_{t,p}^{-1}}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{1}{4}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Then ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\delta\\geq\\mathbb{P}\\bigg(\\frac{1}{4}\\|S_{t}\\|_{\\mathbf Z_{t,p}^{-1}}-\\frac{1}{16}\\|S_{t}\\|_{\\mathbf Z_{t,p}^{-1}}\\geq\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\Big)+\\log(1/\\delta)\\bigg)}\\\\ &{\\quad=\\mathbb{P}\\bigg(\\|S_{t}\\|_{\\mathbf Z_{t,p}^{-1}}\\geq\\frac{16}{3}\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\Big)+\\frac{16}{3}\\log(1/\\delta)\\bigg)}\\\\ &{\\quad\\geq\\mathbb{P}\\bigg(\\|S_{t}\\|_{\\mathbf Z_{t,p}^{-1}}\\geq6\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\Big)+6\\log(1/\\delta)\\bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "B.2Proof of Lemma 2 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Lemma 2. Let $t\\geq d(d+1)/2$ \uff0c $0<\\epsilon<1$ and $p\\in[P_{t,\\epsilon}]^{d}$ . Then, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\log\\left(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{p,t}}\\right)\\leq d\\log(2)+\\frac{1}{2}\\log\\left(\\frac{\\operatorname*{det}({\\mathbf Z}_{t,p})}{\\operatorname*{det}({\\mathbf Z}_{0,p})}\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Moreover, under event $\\left(t\\in\\mathcal{D}_{p}\\right)$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\log\\Big(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{p,t}}\\Big)\\leq d\\log(2)+\\frac{1}{2}d\\log(2+\\epsilon)\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Let $t\\geq d(d+1)/2$ $0\\,<\\,\\epsilon\\,<\\,1$ and $p\\,\\in\\,[P_{t,\\epsilon}]^{d}$ . Then, following steps from Faury et al. (2020) yields ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Norm}_{p}=\\displaystyle\\int_{\\lambda\\in\\mathbb{R}^{d}}1\\!\\left\\{\\|\\mathbf{Z}_{0,p}^{1/2}\\lambda\\|\\leq\\frac{1}{2}\\right\\}\\exp\\{-\\|\\lambda\\|_{\\mathbf{Z}_{0,p}}^{2}\\}d\\lambda}\\\\ &{\\quad\\quad\\quad=\\displaystyle\\frac{1}{\\sqrt{\\operatorname*{det}(\\mathbf{Z}_{0,p})}}\\int_{\\lambda\\in\\mathbb{R}^{d}}1\\!\\left\\{\\|\\lambda\\|\\leq\\frac{1}{2}\\right\\}\\exp\\{-\\|\\lambda\\|^{2}\\}d\\lambda\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Norm}_{t,p}=\\displaystyle\\int_{\\lambda\\in\\mathbb{R}^{d}}1\\!\\left\\{\\|\\mathbf{Z}_{0,p}^{1/2}\\lambda\\|\\leq\\frac{1}{4}\\right\\}\\exp\\{-\\|\\lambda\\|_{\\mathbf{Z}_{t,p}}^{2}\\}d\\lambda}\\\\ &{\\qquad\\qquad=\\frac{1}{\\sqrt{\\operatorname*{det}(\\mathbf{Z}_{t,p})}}\\displaystyle\\int_{\\lambda\\in\\mathbb{R}^{d}}1\\!\\left\\{\\|\\mathbf{Z}_{0,p}^{1/2}\\mathbf{Z}_{t,p}^{-1/2}\\lambda\\|\\leq\\frac{1}{4}\\right\\}\\exp\\{-\\|\\lambda\\|^{2}\\}d\\lambda\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Noting that $\\|\\mathbf{Z}_{0,p}^{1/2}\\mathbf{Z}_{t,p}^{-1/2}\\|\\leq1$ , we deduce ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Norm}_{t,p}\\geq\\frac{1}{\\sqrt{\\operatorname*{det}(\\mathbf{Z}_{t,p})}}\\int_{\\mathbb{R}^{d}}\\mathbb{1}\\Big\\{\\|\\boldsymbol{\\lambda}\\|\\leq\\frac{1}{4}\\Big\\}\\exp\\{-\\|\\boldsymbol{\\lambda}\\|^{2}\\}d\\boldsymbol{\\lambda}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\leq\\sqrt{\\frac{\\operatorname*{det}(\\mathbf{Z}_{t,p})}{\\operatorname*{det}(\\mathbf{Z}_{0,p})}}\\frac{\\int_{\\mathbb{R}^{d}}\\mathbb{1}\\left\\{\\|\\lambda\\|\\leq\\frac{1}{2}\\right\\}\\exp\\{-\\|\\lambda\\|^{2}\\}d\\lambda}{\\int_{\\mathbb{R}^{d}}\\mathbb{1}\\left\\{\\|\\lambda\\|\\leq\\frac{1}{4}\\right\\}\\exp\\{-\\|\\lambda\\|^{2}\\}d\\lambda}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We treat the integrals as ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\int_{\\mathbb{R}^{d}}{\\mathbf1}\\left\\{\\|\\lambda\\|\\leq\\frac{1}{2}\\right\\}\\exp\\left\\{-\\|\\lambda\\|^{2}\\right\\}d\\lambda}{\\int_{\\mathbb{R}^{d}}{\\mathbf1}\\left\\{\\|\\lambda\\|\\leq\\frac{1}{4}\\right\\}\\exp\\left\\{-\\|\\lambda\\|^{2}\\right\\}d\\lambda}=\\frac{\\int_{\\mathbb{R}^{d}}\\left({\\mathbf1}\\left\\{\\|\\lambda\\|\\leq\\frac{1}{4}\\right\\}+{\\mathbf1}\\left\\{\\frac{1}{4}<\\|\\lambda\\|\\leq\\frac{1}{2}\\right\\}\\right)\\exp\\left\\{-\\|\\lambda\\|^{2}\\right\\}d\\lambda}{\\int_{\\mathbb{R}^{d}}{\\mathbf1}\\left\\{\\lambda\\|\\leq\\frac{1}{4}\\right\\}\\exp\\left\\{-\\|\\lambda\\|^{2}\\right\\}d\\lambda}}\\\\ &{=1+\\frac{\\int_{\\mathbb{R}^{d}}{\\mathbf1}\\left\\{\\frac{1}{4}<\\|\\lambda\\|\\leq\\frac{1}{2}\\right\\}\\exp\\left\\{-\\|\\lambda\\|^{2}\\right\\}d\\lambda}{\\int_{\\mathbb{R}^{d}}{\\mathbf1}\\left\\{\\|\\lambda\\|\\leq\\frac{1}{4}\\right\\}\\exp\\left\\{-\\|\\lambda\\|^{2}\\right\\}d\\lambda}}\\\\ &{\\leq1+\\frac{\\exp\\left(-1/16\\right)}{\\exp\\left(-1/16\\right)}\\frac{\\int_{\\mathbb{R}^{d}}{\\mathbf1}\\left\\{\\frac{1}{4}<\\|\\lambda\\|\\leq\\frac{1}{2}\\right\\}d\\lambda}{\\int_{\\mathbb{R}^{d}}{\\mathbf1}\\left\\{\\|\\lambda\\|\\leq\\frac{1}{4}\\right\\}d\\lambda}}\\\\ &{=2^{d}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\log\\left(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\right)\\leq d\\log(2)+\\frac{1}{2}\\log\\left(\\frac{\\operatorname*{det}\\left(\\mathbf{Z}_{t,p}\\right)}{\\operatorname*{det}\\left(\\mathbf{Z}_{0,p}\\right)}\\right)}&{}\\\\ {=d\\log(2)+\\frac{1}{2}\\log\\left(\\operatorname*{det}\\left(\\mathbf{I}+\\mathbf{Z}_{0,p}^{-1/2}{\\mathbf{V}_{t}}\\mathbf{Z}_{0,p}^{-1/2}\\right)\\right)}&{}\\\\ {\\leq d\\log(2)+\\frac{1}{2}\\log\\left(\\prod_{i\\in[d]}\\left(1+\\frac{n_{t,(i,i)}\\Sigma_{i,i}}{(1+\\epsilon)^{p_{i}}\\Sigma_{i,i}+\\|B\\|}\\right)\\right)}&{}\\\\ &{\\leq d\\log(2)+\\frac{1}{2}\\log\\left(\\prod_{i\\in[d]}\\left(1+\\frac{n_{t,(i,i)}}{(1+\\epsilon)^{p_{i}}}\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "In particular under event $\\left(t\\in\\mathcal{D}_{p}\\right)$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\log\\left(\\frac{\\mathrm{Norm}_{p}}{\\mathrm{Norm}_{t,p}}\\right)\\leq d\\log(2)+\\frac{d}{2}\\log(2+\\epsilon)\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "C  Concentration of the covariances estimations (Proposition 2) ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proposition 2. Let $t\\geq d(d+1)/2$ and $\\delta>0$ Then, $\\mathbb{P}(\\mathcal{C}_{t}^{c})\\leq\\delta/(t\\log(t)^{2})$ ", "page_idx": 18}, {"type": "text", "text": "It is a direct application of the following proposition: ", "page_idx": 18}, {"type": "text", "text": "Proposition 5. Let $\\delta\\in(0,1)$ . Then with probability $1-\\delta_{i}$ for all $t\\geq d(d+1)/2$ and $(i,j)\\in[d]^{2}$ \"reachable'\", ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\vert\\hat{\\chi}_{t,(i,j)}-\\Sigma_{i,j}\\vert\\leq\\frac{B_{i}B_{j}}{4}\\biggl(\\frac{5h_{t,\\delta}}{\\sqrt{n_{t,(i,j)}}}+\\frac{h_{t,\\delta}^{2}}{n_{t,(i,j)}}+\\frac{1}{n_{t,(i,j)}^{2}}\\biggr)\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\nh_{t,\\delta}=(1+2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1+t))^{1/2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. Let $\\delta>0,t\\geq d(d+A)/2$ We remind ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal{C}_{t}=\\left\\{\\forall(i,j)\\in[d]^{2}\\ ^{*}\\mathrm{reachable}^{*},\\ \\hat{\\Sigma}_{t,(i,j)}\\geq\\Sigma_{i,j}\\right\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Let $(i,j)\\in[d]^{2}$ \u201creachable\". Then", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\chi}_{t,(i,j)}=\\hat{\\bf S}_{t,(i,j)}-\\hat{\\mu}_{t,i}\\hat{\\mu}_{t,j}}\\\\ &{\\qquad\\quad=\\displaystyle\\frac{1}{n_{t,(i,j)}}\\sum_{s=1}^{t}A_{s,i}A_{s,j}Y_{s,i}Y_{s,j}-\\Big(\\frac{1}{n_{t,i}}\\sum_{s=1}^{t}A_{s,i}Y_{s,i}\\Big)\\Big(\\frac{1}{n_{t,i}}\\sum_{s=1}^{t}A_{s,j}Y_{s,j}\\Big)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "And, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{i,(i,j)}-\\sum_{i,j}=\\frac{1}{n_{t,(i,j)}}\\sum_{s=1}^{t}A_{s,i}A_{s,j}Y_{s,i}Y_{s,j}-\\mathbf{S}_{i,j}-\\left[\\left(\\frac{1}{n_{t,i}}\\sum_{s=1}^{t}A_{s,i}Y_{s,i}\\right)\\left(\\frac{1}{n_{t,j}}\\sum_{s=1}^{t}A_{s,j}Y_{s,j}\\right)-\\mu_{s,i}\\right]}}\\\\ &{}&{=\\frac{1}{n_{t,(i,j)}}\\sum_{s=1}^{t}A_{s,i}A_{s,j}\\Big[Y_{s,i}Y_{s,j}-\\mathbf{S}_{i,j}\\Big]-\\left[\\left(\\frac{1}{n_{t,i}}\\sum_{s=1}^{t}A_{s,i}\\Big[Y_{s,i}-\\mu_{i}\\Big]\\right)\\left(\\frac{1}{n_{t,j}}\\sum_{s=1}^{t}A_{s,j}Y_{s,j}\\right)\\right]}\\\\ &{}&{+\\left.\\mu_{j}\\left(\\frac{1}{n_{t,i}}\\sum_{s=1}^{t}A_{s,i}\\Big[Y_{s,i}-\\mu_{i}\\Big]\\right)+\\mu_{i}\\left(\\frac{1}{n_{t,j}}\\sum_{s=1}^{t}A_{s,j}\\Big[Y_{s,j}-\\mu_{j}\\Big]\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "A triangle inequality yields ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\ \\Sigma_{i,j}|\\leq\\left|\\frac{1}{n_{t,(i,j)}}\\displaystyle\\sum_{s=1}^{t}A_{s,i}A_{s,j}\\Big[Y_{s,i}Y_{s,j}-\\mathbf{S}_{i,j}\\Big]\\right|+\\left|\\frac{1}{n_{t,i}}\\displaystyle\\sum_{s=1}^{t}A_{s,i}\\Big[Y_{s,i}-\\mu_{i}\\Big]\\right|\\left|\\frac{1}{n_{t,j}}\\displaystyle\\sum_{s=1}^{t}A_{s,j}\\Big[Y_{s,j}-\\mu_{i}\\Big]\\right|}\\\\ &{\\phantom{\\quad\\quad\\quad\\quad\\quad}+\\ \\displaystyle\\frac{B_{j}}{2}\\left|\\frac{1}{n_{t,i}}\\displaystyle\\sum_{s=1}^{t}A_{s,i}\\Big[Y_{s,i}-\\mu_{i}\\Big]\\right|+\\displaystyle\\frac{B_{i}}{2}\\left|\\frac{1}{n_{t,j}}\\displaystyle\\sum_{s=1}^{t}A_{s,j}\\Big[Y_{s,j}-\\mu_{j}\\Big]\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We make repeated use of the following Lemma ", "page_idx": 19}, {"type": "text", "text": "Lemma 3. Let $(\\mathcal{H}_{t})_{t\\in\\mathbb{N}^{*}}$ be a filtration, $(U_{t})_{t\\in\\mathbb{N}^{*}}$ be an $\\mathcal{H}_{t}$ adapted martingales bounded by $C\\in\\mathbb{R}_{+}^{*}$ with $\\mathbb{E}[U_{1}]=0$ and $(\\mathbb{1}\\{V_{t}\\})_{t\\in\\mathbb{N}^{*}}$ be a predictable process and $\\delta>0$ ", "page_idx": 19}, {"type": "text", "text": "Then with probability at least $1-\\delta$ forall $t$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\frac{\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}U_{s}}{1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}}>\\frac{C}{\\sqrt{1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}}}\\sqrt{2\\log(1/\\delta)+\\log(1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\})}\\Bigg)\\leq\\delta\\,.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, with probability at least $1-\\delta/2$ , for all $(i,j)$ and $t$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\frac{1}{n_{t,(i,j)}}\\sum_{s=1}^{t}A_{s,i}A_{s,j}\\Big[Y_{s,i}Y_{s,j}-\\mathbf{S}_{i,j}\\Big]\\Bigg|\\leq\\left|\\frac{1}{n_{t,(i,j)}+1}\\sum_{s=1}^{t}A_{s,i}A_{s,j}\\Big[Y_{s,i}Y_{s,j}-\\mathbf{S}_{i,j}\\Big]\\right|+\\displaystyle\\frac{B_{i}B_{j}}{4\\big(n_{t,(i,j)}+1\\big)}}&{}\\\\ {\\leq\\displaystyle\\frac{B_{i}B_{j}}{4}\\frac{1}{\\sqrt{n_{t,(i,j)}+1}}\\sqrt{2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1/\\delta)}}&{}\\\\ {+\\displaystyle\\frac{B_{i}B_{j}}{4n_{t,(i,j)}}}&{}\\\\ {\\leq\\displaystyle\\frac{B_{i}B_{j}}{4\\sqrt{n_{t,(i,j)}}}\\sqrt{2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1/\\delta)}}&{}\\\\ {+\\displaystyle\\frac{B_{i}B_{j}}{4n_{t,(i,j)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "With probability at least $1-\\delta/2$ , for all $i$ and $t$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\bigg|\\frac{1}{n_{t,i}}\\sum_{s=1}^{t}A_{s,i}\\bigg[Y_{s,i}-\\mu_{i}\\bigg]\\bigg|\\leq\\bigg|\\frac{1}{n_{t,i}+1}\\sum_{s=1}^{t}A_{s,i}\\bigg[Y_{s,i}-\\mu_{i}\\bigg]\\bigg|+\\frac{B_{i}}{2n_{t,(i,i)}}}}\\\\ &{}&{\\leq\\frac{B_{i}}{2\\sqrt{n_{t,(i,i)}}}\\sqrt{2\\log(1/\\delta)+2\\log(2d)+\\log(1+t)}+\\frac{B_{i}}{2n_{t,(i,i)}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, reinjecting those expressions yields that with probability at least $1-\\delta$ for all $(i,j)$ and $t$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\widehat{\\mathbf{t}}_{\\ell,(\\ell,i)}-\\mathbf{\\lambda}_{\\ell,i}|\\leq\\frac{B_{\\ell}B_{\\ell}}{4\\sqrt{\\eta_{\\ell+1,i}}\\omega_{\\ell}}\\sqrt{2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1+t)}+\\frac{B_{\\ell}B_{\\ell}}{4\\pi_{\\ell+1,i}}}&{}\\\\ {+\\frac{B_{\\ell}B_{\\ell}\\left(2\\log(1/\\delta)+2\\log(2d)+\\log(1(t+t))\\right)}{4\\sqrt{\\eta_{\\ell+1,i}}\\eta_{\\ell+1,j}\\eta_{\\ell,i}}+\\frac{B_{\\ell}B_{\\ell}}{4\\pi_{\\ell,i}(\\omega_{\\ell})n_{\\ell,i}(\\omega_{\\ell})}}&{}\\\\ {+\\frac{B_{\\ell}B_{\\ell}}{4}\\Big(\\frac{1}{\\sqrt{\\eta_{\\ell+1,i}}\\sqrt{\\eta_{\\ell+1,i}}}+\\frac{1}{\\eta_{\\ell+1,i}\\sqrt{\\eta_{\\ell,i}}(\\omega_{\\ell})}\\Big)\\sqrt{2\\log(1/\\delta)+2\\log(2d)+\\log}}&{}\\\\ {+\\frac{B_{\\ell}B_{\\ell}}{4}\\Big(\\frac{1}{\\sqrt{\\eta_{\\ell+1,i}}(\\omega_{\\ell})}+\\frac{1}{\\sqrt{\\eta_{\\ell+1,i}}(\\omega_{\\ell})}\\Big)\\sqrt{2\\log(1/\\delta)+2\\log(2d)+\\log(1+t)}}&{}\\\\ {\\leq\\frac{B_{\\ell}B_{\\ell}}{4\\sqrt{\\eta_{\\ell+1,i}}\\sqrt{\\eta_{\\ell+1,i}}}\\sqrt{2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1+t)}+\\frac{B_{\\ell}B_{\\ell}}{4\\pi_{\\ell+1,i}(\\omega_{\\ell})}}&{}\\\\ {+\\frac{B_{\\ell}B_{\\ell}\\left(2\\log(1/\\delta)+2\\log(2d)+\\log(1+t)\\right)}{4\\sqrt{\\eta_{\\ell+1,i}\\eta_{\\ell+1,j}}\\eta_{\\ell+1,j}}+\\frac{B_{\\ell}B_{\\ell}}{4\\pi_{\\ell,i}(\\omega_{\\ell})}}&{}\\\\ {+\\frac{B_{\\ell}B_{\\ell}}{2}\\Big(\\frac{1}{\\sqrt{\\eta_{\\ell+1,i}}(\\omega_{\\ell\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "To simplify this expression, using $n_{t,(i,j)}\\,\\leq\\,\\operatorname*{min}\\{n_{t,(i,i)},n_{t,(j,j)}\\}$ and $n_{t,(i,j)}\\,\\leq\\,\\sqrt{n_{t,(i,i)}n_{t,(j,j)}}$ yields ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\hat{\\chi}_{t,(i,j)}-\\Sigma_{i,j}|\\leq5\\frac{B_{i}B_{j}}{4}\\frac{1}{\\sqrt{n_{t,(i,j)}}}\\sqrt{2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1+t)}}\\\\ &{\\phantom{\\frac{1}{\\sqrt{n_{t,(i,j)}}}-\\frac{1}{4}\\chi_{t,(i,j)}}+\\frac{B_{i}B_{j}}{4}\\frac{1}{n_{t,(i,j)}}\\Big(1+2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1+t)\\Big)}\\\\ &{\\phantom{\\frac{1}{\\sqrt{n_{t,(i,j)}}}-\\frac{1}{4}\\chi_{t,(i,j)}}+\\frac{B_{i}B_{j}}{4}\\frac{1}{n_{t,(i,j)}^{2}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Denoting $h_{t,\\delta}\\:=\\:\\Big(1+2\\log(1/\\delta)+2\\log\\big(t\\log(t)^{2}d(d+1)\\big)+\\log(1+t)\\Big)^{1/2}$ , we have with probabilitya least - a(d+1)lg(t) ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\bigl|\\hat{\\chi}_{t,(i,j)}-\\Sigma_{i,j}\\bigr|\\leq\\frac{B_{i}B_{j}}{4}\\Bigl(\\frac{5h_{t,\\delta}}{\\sqrt{n_{t,(i,j)}}}+\\frac{h_{t,\\delta}^{2}}{n_{t,(i,j)}}+\\frac{1}{n_{t,(i,j)}^{2}}\\Bigr)\\,.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "A union bound yields the desired results. ", "page_idx": 20}, {"type": "text", "text": "C.1 Proof for Lemma 3 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Lemma 3. Let $(\\mathcal{H}_{t})_{t\\in\\mathbb{N}^{*}}$ be a filtration, $(U_{t})_{t\\in\\mathbb{N}^{*}}$ be an $\\mathcal{H}_{t}$ adapted martingales bounded by $C\\in\\mathbb{R}_{+}^{*}$ with $\\mathbb{E}[U_{1}]=0$ and $(\\mathbb{1}\\{V_{t}\\})_{t\\in\\mathbb{N}^{*}}$ be a predictable process and $\\delta>0$ ", "page_idx": 20}, {"type": "text", "text": "Then with probability at least $1-\\delta$ for all $t$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\frac{\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}U_{s}}{1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}}>\\frac{C}{\\sqrt{1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}}}\\sqrt{2\\log(1/\\delta)+\\log(1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\})}\\Bigg)\\leq\\delta\\,.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. Let $t\\geq2$ . Then $U_{t}$ is $C$ sub-Gaussian and for all $\\lambda\\in$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\exp\\left(\\lambda\\mathbb{1}\\{V_{t}\\}U_{t}-\\frac{\\lambda^{2}C^{2}}{2}\\mathbb{1}\\{V_{t}\\}\\right)\\middle|\\mathcal{H}_{t-1}\\right]\\leq1\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Then $\\begin{array}{r}{(W_{t}(\\lambda))_{t\\in\\mathbb{N}^{*}}\\;=\\;\\left(\\exp(\\lambda\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}U_{s}-\\,\\frac{\\lambda^{2}C^{2}}{2}\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\})\\right)_{t\\in\\mathbb{N}^{*}}}\\end{array}$ is a supermatringale. We use the Method of Mixtures by integrating for a $\\lambda\\sim\\mathcal{N}(0,{1}/{C^{2}})$ . This yield ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\int_{\\lambda\\in\\mathbb{R}}\\frac{C}{\\sqrt{2\\pi}}\\exp\\Big(-\\frac{\\lambda^{2}C^{2}}{2}\\Big)W_{t}(\\lambda)d\\lambda}\\\\ &{=\\frac{C}{\\sqrt{2\\pi}}\\int_{\\lambda\\in\\mathbb{R}}\\exp\\Big(\\lambda\\sum_{s=1}^{t}\\{\\{V_{s}\\}U_{s}-\\frac{\\lambda^{2}C^{2}}{2}(1+\\displaystyle\\sum_{s=1}^{t}1\\{V_{s}\\})\\Big)d\\lambda}\\\\ &{=\\frac{C}{\\sqrt{2\\pi}}\\int_{\\lambda\\in\\mathbb{R}}\\exp\\bigg(\\frac{\\big(\\sum_{s=1}^{t}1\\{V_{s}\\}U_{s}\\big)^{2}}{2C^{2}(1+\\sum_{s=1}^{t}1\\{V_{s}\\})}\\bigg)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad-\\frac{1}{2}\\big(\\lambda-\\frac{\\sum_{s=1}^{t}1\\{V_{s}\\}U_{s}}{C^{2}(1+\\sum_{s=1}^{t}1\\{V_{s}\\})}\\big)^{2}C^{2}(1+\\displaystyle\\sum_{s=1}^{t}1\\{V_{s}\\})\\bigg)d\\lambda}\\\\ &{=\\exp\\bigg(\\frac{\\big(\\sum_{s=1}^{t}1\\{V_{s}\\}U_{s}\\big)^{2}}{2C^{2}(1+\\sum_{s=1}^{t}1\\{V_{s}\\})}\\bigg)\\frac{1}{\\sqrt{1+\\sum_{s=1}^{t}1\\{V_{s}\\}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Therefore, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\frac{\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}U_{s}}{1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}}>\\frac{C}{\\sqrt{1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\}}}\\sqrt{2\\log(1/\\delta)+\\log(1+\\sum_{s=1}^{t}\\mathbb{1}\\{V_{s}\\})}\\Bigg)\\leq\\delta\\,.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Using the stopping time construction from Abbasi- Yadkori et al. (2011) yields the property for all $t$ \u53e3 ", "page_idx": 21}, {"type": "text", "text": "D  Behaviour in the high-probability events (Section 5) ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The following proposition states that under some assumptions on the sequence of events $\\left(\\mathcal{E}_{t}\\right)$ ,the regret can be bounded by problem-dependent quantities (including $\\Sigma,T$ Or $d$ ).They are not all explicitly stated in Proposition 6 to make it adaptive to both algorithms but are hidden in the constants. ", "page_idx": 21}, {"type": "text", "text": "Proposition 6. Let $r\\in\\mathbb{N}$ $e\\in(1,+\\infty)^{r}$ . Let $(\\mathcal{E}_{t})_{t\\geq d(d+1)/2}$ be a sequence of events such that for all $t\\geq d(d+1)/2$ under $\\mathcal{E}_{t}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\frac{\\Delta_{A_{t+1}}^{2}}{C}\\leq\\sum_{i\\in A_{t+1}}\\frac{C_{A_{t+1},i}}{n_{t,(i,j)}}+\\sum_{s\\in[r]}\\left[\\sum_{(i,j)\\in A_{t+1}}\\frac{C_{s}}{n_{t,(i,j)}^{e_{s}}}\\right]\\!,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $C$ and $(C_{s})_{s\\in[r]}$ are problem-dependent positive constants. $C_{A_{t+1},i}$ is a positive constant depending on $A_{t+1}$ and $i$ so that, for all $a\\in{\\mathcal{A}}$ $C_{a,i}\\leq2m\\pmb{\\Sigma}_{i,i}$ . Let $c\\in\\mathbb{R}_{+}^{*}$ and $(c_{s})_{s\\in[r]}\\in(\\mathbb{R}_{+}^{*})^{r}$ be positive constants such that $\\textstyle1/c+\\sum_{s\\in[r]}1/c_{s}=1$ ", "page_idx": 21}, {"type": "text", "text": "Then, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t={d(d+1)}/{2}}^{T-1}\\Delta_{A_{t+1}}\\mathbf{1}\\{\\xi_{t}\\}}}\\\\ &{\\in\\R e_{1}C\\log(m)^{2}\\sum_{i\\in[d]}\\left(\\underset{a\\in A/i\\in a}{\\operatorname*{max}}\\frac{C_{a,i}}{\\Delta_{a}}\\right)}\\\\ &{\\quad\\ +\\underset{s=1}{\\overset{r}{\\sum}}\\Bigg[\\mathbf{1}\\Big\\{e_{s}=2\\Big\\}346\\Big(c_{s}C c_{s}\\log(m)\\Big)^{1/2}m d^{2}\\bigg(1+\\log\\Big(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\Big)\\bigg)}\\\\ &{\\qquad+\\ \\mathbf{1}\\Big\\{1<e_{s}<2\\Big\\}60.30^{1/\\varepsilon_{s}}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/\\varepsilon_{s}}d^{2}m^{2/\\varepsilon_{s}}\\Delta_{\\operatorname*{min}}^{1-2/\\varepsilon_{s}}}\\\\ &{\\qquad+\\ \\mathbf{1}\\Big\\{2<e_{s}\\Big\\}60.30^{1/\\varepsilon_{s}}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/\\varepsilon_{s}}\\frac{e_{s}}{e_{s}-2}d^{2}m^{2/\\varepsilon_{s}}\\Delta_{\\operatorname*{max}}^{1-2/\\varepsilon_{s}}\\Bigg]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $(\\alpha_{k})_{k\\in\\mathbb{N}^{*}}$ \uff0c $(\\beta_{k})_{k\\in\\mathbb{N}^{*}}$ and $k_{0}\\in\\mathbb{N}^{*}$ are defined in Appendix $D.I$ ", "page_idx": 21}, {"type": "text", "text": "Proof. The proof is classical and involves a decomposition of the events $\\mathcal{E}_{t}$ (see Kveton et al. (2015); Degenne and Perchet (2016); Perrault et al. (2020b). By considering each of the $r$ sub-sum in Eq. (25) and designing sets of event that can happen only a finite number of times. ", "page_idx": 21}, {"type": "text", "text": "We introduce twosequences $(\\alpha_{k})_{k\\in\\mathbb{N}^{*}}$ and $(\\beta_{k})_{k\\in\\mathbb{N}^{*}}$ , both begin at 1 and strictly decrease to 0 (see Appendix D.1 for their definitions). These sequences are introduced to be able to consider the different terms of Eq. (25) separately. ", "page_idx": 21}, {"type": "text", "text": "Let $t\\geq d(d+1)/2$ $k\\in\\mathbb{N}^{*}$ . We define the set ", "page_idx": 21}, {"type": "equation", "text": "$$\nS_{t,k}=\\left\\{i\\in A_{t+1},\\quad n_{t,(i,i)}\\leq c_{1}m\\alpha_{k}\\;\\frac{C}{\\Delta_{A_{t+1}}^{2}}\\;\\frac{C_{A_{t+1},i}^{2}}{\\Sigma_{i,i}^{*}}\\right\\},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and the event ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{A}_{t,k}=\\left\\{\\sum_{i\\in S_{t,k}}\\frac{\\Sigma_{i,i}^{*}}{C_{A_{t+1},i}}\\ge\\beta_{k}m;\\quad\\forall l<k,\\sum_{i\\in S_{t,l}^{1}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}<\\beta_{l}m\\right\\}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "A notable difference from previous approaches is the use of $\\Sigma_{i,i}^{*}/C_{a,i}$ .1 $\\mathbb{A}_{t,k}^{1}$ instead of set cardinals. This enables the explicit appearance of the $C_{a,i}$ coefficients, which will involve the $\\sigma_{a,i}^{2}$ for the application of this proposition to our algorithms. ", "page_idx": 21}, {"type": "text", "text": "For $s\\in[r]$ , we define ", "page_idx": 22}, {"type": "equation", "text": "$$\nS_{t,k}^{s}=\\left\\{(i,j)\\in A_{t+1},\\quad n_{t,(i,j)}^{e_{s}}\\leq c_{s}m^{2}\\alpha_{k}\\,\\frac{C}{\\Delta_{A_{t+1}}^{2}}\\,C_{s}\\right\\}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and the events ", "page_idx": 22}, {"type": "equation", "text": "$$\n{\\mathbb A}_{t,k}^{s}=\\left\\{|S_{t,k}^{s}|\\ge\\beta_{k}m^{2};\\quad\\forall l<k,|S_{t,l}^{s}|<\\beta_{l}m^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The following Lemma, proven in Appendix D.2, decomposes $(\\mathcal{E}_{t})_{t\\geq d(d+1)/2}$ using these events. ", "page_idx": 22}, {"type": "text", "text": "Lemma 4. Let's consider the assumptions of Proposition 6. Let $\\mathbb{A}_{t,k}$ and $(\\mathbb{A}_{t,k}^{s})_{s\\in[r]}$ be the events defined in Eq. (28)and Eq. (30). Let $k_{0}\\in\\mathbb{N}^{*}$ such that $\\begin{array}{r}{0<m\\beta_{k_{0}}<\\frac{1}{2m}}\\end{array}$ and $t\\geq d(d+1)/2$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{1}\\{\\mathcal{E}_{t}\\}\\le\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}\\}+\\sum_{s=1}^{r}\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}^{s}\\}\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Using it, we decompose ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\mathcal{E}_{t}\\right\\}\\leq\\displaystyle\\sum_{t=d(d+1)/2}^{T-1}\\left[\\sum_{k=1}^{k_{0}}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\hat{\\mathbb{A}}_{t,k}\\right\\}+\\sum_{s=1}^{r}\\sum_{k=1}^{k_{0}}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\hat{\\mathbb{A}}_{t,k}^{s}\\right\\}\\right]}\\\\ &{=\\displaystyle\\sum_{t=d(d+1)/2}^{T-1}\\left[\\Delta_{A_{t+1}}\\sum_{k=1}^{k_{0}}\\mathbb{I}\\left\\{\\hat{\\mathbb{A}}_{t,k}\\right\\}\\right]+\\sum_{s=1}^{r}\\sum_{t=d(d+1)/2}^{T-1}\\left[\\Delta_{A_{t+1}}\\sum_{k=1}^{k_{0}}\\mathbb{I}\\left\\{\\hat{\\mathbb{A}}_{t,k}^{s}\\right\\}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We begin with the first term of Eq. (31). Let $t\\geq d(d+1)/2$ , and $k\\in[k_{0}]$ . Then, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{\\hat{a}}_{t,k}=\\left\\{\\sum_{i\\in S_{t,k}^{1}}\\frac{\\sum_{i,i}}{C_{A_{t+1},i}}\\ge\\beta_{k}m;\\quad\\forall l<k,\\,\\sum_{i\\in S_{t,l}^{1}}\\frac{\\sum_{i,i}}{C_{A_{t+1},i}}<\\beta_{l}\\right\\}\\subseteq\\left\\{\\frac{1}{\\beta_{k}m}\\sum_{i\\in S_{t,k}^{1}}\\frac{\\sum_{i,i}}{C_{A_{t+1},i}}\\ge1\\right\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{1}\\{\\mathbb{A}_{t,k}\\}\\leq\\frac{1}{\\beta_{k}m}\\sum_{i\\in[d]}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}\\mathbb{1}\\!\\left\\{\\mathbb{A}_{t,k}\\cap\\{i\\in S_{t,k}\\}\\right\\}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Summing over $t$ and $k$ , and including the gaps yields ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{c l r}{\\displaystyle\\sum_{a=d(d+1)/2}^{T-1}{\\Delta}_{A_{t+1}\\sum_{k=1}^{k_{0}}\\mathbf{1}\\left\\{\\mathbb{A}_{t,k}^{1}\\right\\}}}&{\\quad}&{\\displaystyle(33)}\\\\ &{\\displaystyle\\leq\\sum_{t=d(d+1)/2}^{T}{\\Delta}_{A_{t+1}\\sum_{k=1}^{k_{0}}\\frac{1}{\\beta_{k}m}\\sum_{i\\in[d]}\\frac{\\sum_{i,i}}{C_{A_{t+1,i}}}\\mathbb{I}\\left\\{\\mathbb{A}_{t,k}^{1}\\cap\\{i\\in S_{t,k}\\}\\right\\}}\\leftarrow\\mathrm{by~Eq.~(32)}}\\\\ &{\\displaystyle\\leq\\sum_{i\\in[d]}\\sum_{t=d(d+1)/2}^{T}{\\sum_{k=1}^{k_{0}}\\frac{1}{\\beta_{k}m}\\frac{\\Delta_{A_{t+1}}}{C_{A_{t+1,i}}}\\mathbb{I}\\left\\{i\\in S_{t,k}\\right\\}}}&\\\\ &{\\displaystyle=\\sum_{i\\in[d]}\\sum_{k=1}^{k_{0}}\\sum_{\\vec{b},k}\\displaystyle\\sum_{t=d(d+1)/2}^{T}{\\sum_{C_{A_{t+1,i}}}\\frac{\\Delta_{A_{t+1}}}{C_{A_{t+1,i}}}\\Bigg\\{n_{t,(i,i)}\\leq c_{1}m\\alpha_{k}\\frac{C}{\\left(\\frac{\\Delta_{A_{t+1}}}{C_{A_{t+1,i}}}\\right)^{2}\\Sigma_{i,i}}\\Bigg\\}}\\cdot\\mathrm{e~by~Eq}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let $i\\,\\in\\,[d]$ , we consider all the actions associated to it. Let $q_{i}\\;\\in\\;\\mathbb{N}^{*}$ be the number of actions   \nassociated to item $i$ . Let $l\\in[q_{i}]$ ,we denote $e_{i}^{l}\\in A$ the $l_{\\cdot}$ -th action associated to item $i$ , sorted by >e C = O by convention. Then   \ndecreasing Cet,'? ,with   \n$\\begin{array}{r l}&{\\begin{array}{r l}&{\\frac{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i+1,i+1}}{\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i+1,i+1}}\\Biggl\\{u_{i,0,0}\\le\\mathrm{van}\\frac{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}}{(\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i+1})^{2}\\Sigma_{0,i}}\\Biggr\\}}\\\\ &{\\times\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i+1}\\Biggl\\{u_{i,0,0}\\le\\mathrm{van}\\frac{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}}{(\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i})^{2}},~~A_{1}=i-i\\Biggr\\}^{N}}\\\\ &{=\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i+1}\\Biggl\\{u_{i,0,0}\\frac{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}}{(\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i})^{2}},~~A_{1}=i-i\\Biggr\\}^{N}}\\\\ &{=\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i+1}\\Biggl\\{u_{i,0,0}\\frac{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}}{(\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i})^{2}},~~A_{1}=i-i\\Biggr\\}^{N}}\\\\ &{\\overset{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i+1,i}\\Biggl\\{\\frac{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}}{\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i}}\\Biggr\\}\\times\\mathrm{van}\\frac{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i}}{(\\sum_{j=1}^{N}\\widetilde{\\lambda}_{i})^{2}}\\succcurlyeq\\frac{1}{(\\sum_{j=1}^{N}\\widetilde{\\lambda}_{j})},~~A_{1}=i-i\\Biggr\\}+\\cdots}\\end{array}}\\\\ &{\\begin{array}{r l}&{\\sum_{i=1}^{N}\\widetilde{\\lambda}_{i+1}\\sum_{j=1$ oosing the event   \n$\\begin{array}{r l}&{\\quad_{\\mathbb{P}}\\underset{=}^{T-1}+\\frac{1}{\\gamma-\\varepsilon_{1}}\\sum_{i=1}^{\\infty}\\frac{\\Delta t_{i}}{\\varepsilon_{2}+\\varepsilon_{3}}\\bigg\\{\\frac{1}{(\\frac{\\Delta t_{i}-\\varepsilon_{1}}{\\varepsilon_{2}+\\varepsilon_{1}})}<\\alpha_{\\varepsilon_{1},i0}\\frac{\\Delta_{t_{i}}}{\\varepsilon_{1}(\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{\\varepsilon_{2}+\\varepsilon_{2}})},\\quad+\\frac{\\alpha_{\\varepsilon_{1}}}{(\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{\\varepsilon_{2}+\\varepsilon_{3}})}-\\varepsilon_{4,i1}^{2}\\bigg\\}+\\alpha_{\\varepsilon_{1}}}\\\\ &{\\quad=\\frac{\\sqrt{3}}{\\gamma-\\varepsilon_{1}}\\frac{\\Delta t_{i}}{\\varepsilon_{2}+\\varepsilon_{3}}\\frac{\\sqrt{3}}{\\varepsilon_{1}+\\varepsilon_{2}+\\varepsilon_{3}}\\bigg\\{\\frac{1}{(\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{\\varepsilon_{2}+\\varepsilon_{1}})}<\\alpha_{\\varepsilon_{1},i0}\\frac{\\Delta_{t_{i}}}{\\varepsilon_{2}+\\varepsilon_{3}},\\quad+\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{(\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{\\varepsilon_{2}+\\varepsilon_{3}})},\\quad\\mathscr{A}_{\\varepsilon_{1}+\\varepsilon_{1}}-\\varepsilon_{4,i1}^{2}\\bigg\\}}\\\\ &{\\quad\\leq\\frac{\\sqrt{3}}{\\gamma-\\varepsilon_{1}}\\frac{\\Delta_{t_{i}}}{\\varepsilon_{2}+\\varepsilon_{3}}\\frac{\\sqrt{3}}{\\varepsilon_{1}+\\varepsilon_{2}+\\varepsilon_{3}}\\bigg\\{\\frac{1}{(\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{\\varepsilon_{2}+\\varepsilon_{2}})}<\\alpha_{\\varepsilon_{1},i0}\\frac{\\Delta_{t_{i}}}{\\varepsilon_{1}(\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{\\varepsilon_{2}+\\varepsilon_{3}})},\\quad+\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{(\\frac{\\Delta_{t_{i}-\\varepsilon_{1}}}{\\varepsilon_{2}+\\varepsilon_{3}$ Cer,;i extend the sum over l   \n$\\begin{array}{r l}&{\\varphi\\left[\\sigma\\left(\\tau_{G},\\tau_{G}\\right)\\right]=\\frac{1}{N}\\left(\\sigma\\left(\\tau_{G}^{\\dagger}\\right)\\right)^{2}}\\\\ &{=\\frac{5}{N}\\frac{\\lambda_{d}}{\\rho}\\sum_{i,j=1\\atop i\\neq j}^{N}\\frac{1}{N}\\left\\{\\frac{1}{\\left(N\\beta_{i j}-1\\right)^{2}}\\sum_{s,t,s,t,s^{\\prime}}\\frac{1}{\\tau_{G}\\left(\\tau_{G}^{\\dagger}\\right)}\\frac{\\lambda_{d}}{N}\\right\\}}\\\\ &{\\varphi\\left[\\sigma\\left(\\tau_{G}^{\\dagger}\\right)\\right]=\\frac{5}{N}\\frac{\\lambda_{d}}{\\rho}\\frac{\\lambda_{d}}{N}\\frac{\\lambda_{d}}{\\rho}\\exp\\left\\{-\\frac{4\\lambda_{d}}{N}\\sum_{s,t,s^{\\prime}}\\frac{1}{\\tau_{G}\\left(\\tau_{G}^{\\dagger}\\right)}\\frac{\\lambda_{d}}{N}\\right\\}+\\kappa\\alpha\\left(\\kappa+\\tau_{G}^{\\dagger}\\right)\\sin\\left\\{n+\\tau_{G}^{\\dagger}\\right\\}}\\\\ &{\\xi\\frac{\\sqrt{N}}{\\rho}\\frac{\\lambda_{d}}{N}\\Bigg[\\left(\\frac{\\lambda_{d}}{N\\xi_{d}}\\right)^{2}\\cos_{t}^{2}\\left(\\tau_{G}^{\\dagger}\\right)\\left(\\frac{\\lambda_{d}}{N}\\right)^{2}\\cos_{t}^{2}\\left(\\tau_{G}^{\\dagger}\\right)\\Bigg]+\\kappa\\alpha\\left(\\kappa\\tau_{G}^{\\dagger}\\right)\\sin\\left\\{n+\\tau_{G}^{\\dagger}\\right\\}}\\\\ &{=\\left(\\left\\{\\left(\\frac{\\lambda_{d}}{N\\xi_{d}}\\right)^{2}\\sin^{2}\\left(\\tau_{G}^{\\dagger}\\right)\\frac{\\lambda_{d}}{N}\\right\\}\\frac{\\lambda_{d}}{\\rho\\left(\\tau_{G}^{\\dagger}\\right)}+\\frac{\\sqrt{1}}{N}\\right)\\left(\\left(\\frac{\\lambda_{d}}{\\Delta\\xi_{d}}\\right)^{2}\\cos_{t}^{2}\\left(\\tau_{G}^{\\dagger}\\right)-\\frac{\\lambda_{d}}{\\sqrt{\\pi}}\\right)+\\kappa\\left(\\kappa+\\tau_{G}^{\\dagger}\\right)\\sin\\left\\{n+\\tau_{G}^{\\dagger}\\right\\}}\\\\ &{\\varphi\\left[\\sigma\\left(\\tau_{G}^{\\dagger}\\right)\\right]=\\frac{5}{N}\\frac{\\lambda_{d}} $ y the inner sum open a given nbr. of times ummation by parts ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "Reinjecting Eq. (35) into Eq. (34) yields ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\sum_{k=1}^{k_{0}}\\mathbb{I}\\big\\{\\mathbb{A}_{t,k}^{1}\\big\\}\\leq\\displaystyle\\sum_{i\\in[d]}\\Sigma_{i,i}\\displaystyle\\sum_{k=1}^{k_{0}}\\frac{1}{\\beta_{k}m}\\frac{2c_{1}m C\\alpha_{k}}{\\Sigma_{i,i}}\\Big(\\operatorname*{max}_{a\\in A/i\\in a}\\frac{C_{a,i}}{\\Delta_{a}}\\Big)}\\\\ {\\displaystyle}&{=2c_{1}C\\Big(\\sum_{k=1}^{k_{0}}\\frac{\\alpha_{k}}{\\beta_{k}}\\Big)\\displaystyle\\sum_{i\\in[d]}\\Big(\\operatorname*{max}_{a\\in A/i\\in a}\\frac{C_{a,i}}{\\Delta_{a}}\\Big)}\\\\ {\\displaystyle}&{=96c_{1}C\\log(m)^{2}\\sum_{i\\in[d]}\\Big(\\operatorname*{max}_{a\\in A/i\\in a}\\frac{C_{a,i}}{\\Delta_{a}}\\Big)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We treat the $r$ other terms in a similar way. Let $s\\in[r],t\\geq d(d+1)/2$ , and $k\\in[k_{0}]$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{A}_{t,k}^{s}=\\left\\{|S_{t,k}^{s}|\\geq\\beta_{k}m^{2};\\quad\\forall l<k,|S_{t,l}^{s}|<\\beta_{l}m^{2}\\right\\}\\subseteq\\left\\{\\frac{1}{\\beta_{k}m^{2}}|S_{t,k}^{2}|\\geq1\\right\\}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{1}\\{\\mathbb{A}_{t,k}^{s}\\}\\le\\frac{1}{\\beta_{k}m^{2}}\\sum_{(i,j)\\in[d]^{2}}\\mathbb{1}\\!\\left\\{\\mathbb{A}_{t,k}^{s}\\cap\\{(i,j)\\in S_{t,k}^{s}\\}\\right\\}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Summing over $t$ and $k$ yields ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i=0}^{T-1}\\sum_{\\substack{\\Delta}\\atop\\l=i(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\sum_{\\substack{k=1}}^{k_{0}}\\mathbf{1}\\{\\hat{\\mathbf{A}}_{t,k}^{s}\\}}}\\\\ &{\\leq\\underset{t=d(d+1)/2}{\\sum_{\\substack{\\Gamma=\\ d(d+1)/2}}}^{T-1}\\Delta_{A_{t+1}}\\underset{k=1}{\\overset{k_{0}}{\\sum}}\\frac{1}{\\hat{\\beta}_{k}m^{2}}\\underset{(i,j)\\in\\{d\\}^{2}}{\\sum}\\mathbb{1}\\Big\\{\\hat{\\mathbf{A}}_{t,k}^{s}\\cap\\{(i,j)\\in S_{t,k}^{s}\\}\\Big\\}\\leftarrow\\textrm{b y E q},(37)}\\\\ &{\\leq\\underset{(i,j)\\in[d]^{2}}{\\sum}\\underset{t=d(d+1)/2}{\\sum^{T-1}}\\underset{k=1}{\\overset{k_{0}}{\\sum}}\\frac{1}{\\hat{\\beta}_{k}m^{2}}\\Delta_{A_{t+1}}\\mathbf{1}\\{(i,j)\\in S_{t,k}^{s}\\}}\\\\ &{=\\underset{(i,j)\\in[d]^{2}}{\\sum}\\underset{k=1}{\\overset{k_{0}}{\\sum}}\\frac{1}{\\hat{\\beta}_{k}m^{2}}\\underset{t=d(d+1)/2}{\\sum^{T-1}}\\Delta_{A_{t+1}}\\mathbf{1}\\left\\{n_{t,(i,j)}\\leq m^{2/e_{s}}(c_{s}\\alpha_{k}C C_{s})^{1/e_{s}}\\frac{1}{\\Delta_{A_{t+1}}^{2/e_{s}}}\\right\\}\\leftarrow}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Let $(i,j)\\in[d]^{2}$ , we consider all the actions which are associated to it. Let $q_{(i,j)}\\in\\mathbb{N}^{*}$ be the number of actions asciatd to the tle $(i,j)$ . Let $l\\in\\big[q_{(i,j)}\\big]$ this time, we denote $e_{(i,j)}^{l}\\in\\mathcal{A}$ the $l_{\\cdot}$ th action associated to tuple $(i,j)$ , sorted by decreasing $\\Delta_{e_{(i,j)}^{l}}$ , with $\\frac{1}{\\Delta_{e_{(i,j)}^{0}}}=0$ by convention. Then, ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\Gamma-1}{2}\\sum_{A_{1}+1}^{A}\\mathbf{1}\\Bigg\\{n_{t,(i,j)}\\leq m^{2/e}(c_{0}\\alpha_{t}C C{C_{s}})^{1/e}\\cdot\\frac{1}{\\Delta_{A_{1}+1}^{2}}\\Bigg\\}}\\\\ &{\\overset{r\\cong(i+1)/2}{\\leq}\\sum_{i=0}^{1-1}\\Delta_{\\alpha_{i,j}^{(i)}}\\Bigg\\{n_{t,(i,j)}\\leq m^{2/e}(c_{0}\\alpha_{t}C C{C_{s}})^{1/e}\\cdot\\frac{1}{\\Delta_{A_{1}+1}^{2/e}},\\quad A_{t+1}=e_{(i,j)}^{1}\\Bigg\\}}\\\\ &{\\overset{r\\cong(i)}{=}\\frac{\\Gamma^{1/e}(\\Delta_{\\alpha_{i}})}{t\\cong0}\\Delta_{\\alpha_{i,j}^{(i)}}\\Bigg\\{n_{t,(i,j)}\\leq m^{2/e}(c_{0}\\alpha_{t}C C{C_{s}})^{-1/e}\\cdot\\frac{1}{\\Delta_{A_{1}+1}^{2/e}},\\quad A_{t+1}=e_{(i,j)}^{1}\\Bigg\\}}\\\\ &{\\overset{r\\cong(i)}{=}\\frac{\\Gamma^{1/e}(\\Delta_{\\alpha_{i}})}{t\\cong0}\\Delta_{\\alpha_{i,j}^{(i)}}\\Bigg\\{n_{t,(i,j)}m^{-2/e}(c_{0}\\alpha_{t}C{C_{s}})^{-1/e}\\cdot\\leq\\frac{1}{\\Delta_{e_{(i,j)}^{(i,j)}}},\\quad A_{t+1}=e_{(i,j)}^{1}\\Bigg\\}}\\\\ &{\\overset{T\\cong(i)}{=}\\sum_{i=0}^{1-1}\\Delta_{\\alpha_{i,j}^{(i)}}\\sum_{r=1}^{1}\\Bigg\\{\\frac{1}{\\Delta_{\\alpha_{i}^{(j)}}^{2/e}\\cdot\\leq}n_{t,(i,j)}m^{-2/e}(c_{s}\\alpha_{k}C{C_{s}})^{-1/e}\\cdot\\leq\\frac{1}{\\Delta_{\\alpha_{i,j}^{(i)}}},\\quad A_{t+1}=e_{(i,j)}^{l}\\Bigg\\}}\\\\ &{\\overset{r\\cong(i)}{\\leq}\\frac{\\Gamma^{1/e}(\\Delta_{\\alpha_{i}} \n$$", "text_format": "latex", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\le\\displaystyle\\sum_{p=1}^{q(\\pm1)}\\Delta_{\\sigma_{i,p}^{p}}\\sum_{t=0}^{T-1}\\mathbf{i}\\left\\{\\frac{1}{\\Delta_{\\sigma_{i,p}^{p}}(\\pmb\\mathscr{T}_{\\sigma_{i,p}})}-\\alpha_{t,(i,j)}m^{-2/\\epsilon_{*}}(c_{*}\\alpha_{t}C C{C_{p}})^{-1/\\epsilon_{*}}\\leq\\frac{1}{\\Delta_{\\sigma_{i,q}^{p}}^{2/\\epsilon_{*}}},\\quad i\\in A_{t+1}\\right\\}}\\\\ &{\\leq\\displaystyle\\sum_{p=1}^{q(\\pm1)}\\Delta_{\\sigma_{i,p}^{p}}\\left(\\left|\\frac{m^{2/\\epsilon_{*}}(c_{*}\\alpha_{t}C{C_{p}})^{1/\\epsilon_{*}}}{\\Delta_{\\sigma_{i,p}^{p}}^{2/\\epsilon_{*}}}\\right|-\\left|\\frac{m^{2/\\epsilon_{*}}(c_{*}\\alpha_{t}C{C_{p}})^{1/\\epsilon_{*}}}{\\Delta_{\\sigma_{i,p}^{p}}^{2/\\epsilon_{*}}}\\right|\\right)}\\\\ &{=\\displaystyle\\left\\{\\frac{m^{2/\\epsilon_{*}}(c_{*}\\alpha_{t}C C{C_{p}})^{1/\\epsilon_{*}}}{\\Delta_{\\sigma_{i,p}^{p}}^{2/\\epsilon_{*}}}\\left|\\Delta_{\\sigma_{i,p}^{q}}\\right.+\\underbrace{q_{\\mathrm{t+1}}^{q_{*}/\\epsilon_{*}}}_{p=1}\\left\\{\\frac{m^{2/\\epsilon_{*}}(c_{*}\\alpha_{t}C{C_{p}})^{1/\\epsilon_{*}}}{\\Delta_{\\sigma_{i,p}^{p}}^{2/\\epsilon_{*}}}\\right\\}\\left(\\Delta_{\\sigma_{i,p}^{p}}-\\Delta_{\\sigma_{i,p}^{p+1}}\\right)}\\\\ &{\\leq m^{2/\\epsilon_{*}}(c_{*}\\alpha_{t}C{C_{p}})^{1/\\epsilon_{*}}\\left(\\Delta_{\\sigma_{i,p}^{q}}\\right)^{1/2/\\epsilon_{*}}+\\displaystyle\\sum_{p=1}^{q(\\pm1)}\\left(\\Delta_{\\sigma_{i,p}^{p}}\\right)^{-2/\\epsilon_{*}}\\left(\\Delta_{\\sigma_{i,p}^{p \n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "If $e_{s}=2$ then ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{t=d(d+1)/2}{\\overset{T-1}{\\sum}}\\Delta_{A_{t+1}}1\\Biggl\\{n_{t,(i,j)}\\leq m^{2/e_{s}}(c_{s}\\alpha_{k}C C_{s})^{1/e_{s}}\\frac{1}{\\Delta_{A_{t+1}}^{2/e_{s}}}\\Biggr\\}}\\\\ &{\\leq m(c_{s}\\alpha_{k}C C_{s})^{1/2}\\Biggl(1+\\int_{\\Delta_{e_{(i,j)}^{q_{(i,j)}}}}^{\\Delta_{e_{(i,j)}^{1}}}x^{-1}d x\\Biggr)}\\\\ &{\\leq m(c_{s}\\alpha_{k}C C_{s})^{1/2}\\Biggl(1+\\log\\left(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\right)\\Biggr)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Reinjecting this expression into yields Eq. (38), for $e_{s}=2$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}^{s}\\}\\leq\\sum_{(i,j)\\in[d]^{2}}\\sum_{k\\in[k_{0}]}\\frac{1}{\\beta_{k}m^{2}}m(c_{s}\\alpha_{k}C C_{s})^{1/2}\\Bigg(1+\\log\\Big(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\Big)\\Bigg)}}\\\\ &{=(c_{s}C C_{s})^{1/2}\\frac{d^{2}}{m}\\Bigg(1+\\log\\Big(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\Big)\\Bigg)\\sum_{k\\in[k_{0}]}\\frac{\\alpha_{k}^{1/2}}{\\beta_{k}}}\\\\ &{\\leq346\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/2}m d^{2}\\Bigg(1+\\log\\Big(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\Big)\\Bigg)\\,.\\qquad\\qquad\\Omega}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Else, for $1<e_{s}<2$ , then ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{t=d(d+1)/2}{\\overset{T-1}{\\sum}}\\Delta_{A_{t+1}}\\mathbf{1}\\Bigg\\{n_{t_{i}(i,j)}\\leq m^{2/e_{s}}(c_{\\alpha}\\alpha_{k}C C C_{s})^{1/e_{s}}\\frac{1}{\\Delta_{A_{t+1}}^{2/e_{s}}}\\Bigg\\}}\\\\ &{\\leq m^{2/e_{s}}(c_{\\alpha}\\alpha_{k}C C_{s})^{1/e_{s}}\\Bigg(\\Big(\\Delta_{e_{(i,j)}^{\\sigma}}\\Big)^{1-2/e_{s}}+\\int_{\\Delta_{e_{(i,j)}^{\\sigma}}}^{\\Delta_{e_{(i,j)}^{\\sigma}}}x^{-2/e_{e}}d x\\Bigg)}\\\\ &{=m^{2/e_{s}}(c_{\\alpha}\\alpha_{k}C C_{s})^{1/e_{s}}\\Bigg(\\Big(\\Delta_{e_{(i,j)}^{\\sigma}}\\Big)^{1-2/e_{s}}+\\frac{e_{s}}{e_{s}-2}\\Bigg(\\Delta_{e_{(i,j)}^{\\sigma}}^{1-2/e_{s}}-\\Delta_{e_{(i,j)}^{\\sigma}}^{1-2/e_{s}}\\Bigg)\\Bigg)}\\\\ &{\\leq m^{2/e_{s}}(c_{\\alpha}\\alpha_{k}C C_{s})^{1/e_{s}}\\Bigg(\\Bigg(\\Delta_{e_{(i,j)}^{\\sigma}}\\Big)^{1-2/e_{s}}-e_{s}\\Bigg(\\Delta_{e_{(i,j)}^{\\sigma}}^{1-2/e_{s}}-\\Delta_{e_{(i,j)}^{\\sigma}}^{1-2/e_{s}}\\Bigg)\\Bigg)}\\\\ &{\\leq3m^{2/e_{s}}(c_{\\alpha}\\alpha_{k}C C_{s})^{1/e_{s}}\\Delta_{m^{2}}^{1/e_{s}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "This yield ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{t=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}^{s}\\}\\leq\\sum_{(i,j)\\in[d]^{2}}\\sum_{k\\in[k_{0}]}\\frac{1}{\\beta_{k}m^{2}}3m^{2/e_{s}}(c_{s}\\alpha_{k}C C_{s})^{1/e_{s}}\\Delta_{\\operatorname*{min}}^{1-2/e_{s}}}}\\\\ &{}&{=3(c_{s}C C_{s})^{1/e_{s}}d^{2}m^{2/e_{s}-2}\\Delta_{\\operatorname*{min}}^{1-2/e_{s}}\\sum_{k\\in[k_{0}]}\\frac{\\alpha_{k}^{1/e_{s}}}{\\beta_{k}}}\\\\ &{}&{\\leq189.30^{1/e_{s}}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/e_{s}}d^{2}m^{2/e_{s}}\\Delta_{\\operatorname*{min}}^{1-2/e_{s}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Finally, for $e_{s}>2$ \uff0c ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{T-1}{t=d(d+1)/2}\\Delta_{A_{t+1}}\\mathbf{1}\\Bigg\\{n_{t,(i,j)}\\leq m^{2/e_{s}}(c_{s}\\alpha_{k}C C\\sigma_{s})^{1/e_{s}}\\frac{1}{\\Delta_{A_{t+1}}^{2/e_{s}}}\\Bigg\\}}\\\\ &{\\leq m^{2/e_{s}}(c_{s}\\alpha_{k}C C\\sigma_{s})^{1/e_{s}}\\Bigg(\\Big(\\Delta_{e_{(i,j)}^{\\eta}}\\Big)^{1-2/e_{s}}+\\int_{\\Delta_{e_{(i,j)}^{\\eta}}}^{\\Delta_{e_{(i,j)}}^{1}}x^{-2/e_{s}}d x\\Bigg)}\\\\ &{=m^{2/e_{s}}(c_{s}\\alpha_{k}C C\\sigma_{s})^{1/e_{s}}\\Bigg(\\Big(\\Delta_{e_{(i,j)}^{\\eta}}\\Big)^{1-2/e_{s}}+\\frac{e_{s}}{e_{s}-2}\\Bigg(\\Delta_{e_{(i,j)}^{\\eta}}^{1-2/e_{s}}-\\Delta_{e_{(i,j)}^{\\eta}}^{1-2/e_{s}}\\Bigg)\\Bigg)}\\\\ &{\\leq m^{2/e_{s}}(c_{s}\\alpha_{k}C C\\sigma_{s})^{1/e_{s}}\\frac{e_{s}}{e_{s}-2}\\Big(\\Delta_{\\operatorname*{max}}\\Big)^{1-2/e_{s}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{a=(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}^{s}\\}\\le\\displaystyle\\sum_{(i,j)\\in[d]^{2}}\\sum_{k\\in[k_{0}]}\\frac{1}{\\beta_{k}m^{2}}m^{2/e_{s}}(c_{s}\\alpha_{k}C C_{s})^{1/e_{s}}\\frac{e_{s}}{e_{s}-2}\\Big(\\Delta_{\\operatorname*{max}}\\Big)^{1-2/e_{s}}}&{}\\\\ {\\displaystyle=\\big(c_{s}C C_{s})^{1/e_{s}}\\frac{e_{s}}{e_{s}-2}d^{2}m^{2/e_{s}-2}\\Delta_{\\operatorname*{max}}^{1-2/e_{s}}\\sum_{k\\in[k_{0}]}\\frac{\\alpha_{k}^{1/e_{s}}}{\\beta_{k}}}&{}\\\\ {\\displaystyle\\le63.30^{1/e_{s}}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/e_{s}}\\frac{e_{s}}{e_{s}-2}d^{2}m^{2/e_{s}}\\Delta_{\\operatorname*{max}}^{1-2/e_{s}}.}&{\\quad(41)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "All in all, we reinject Eq. (36), Eq. (39), Eq. (40) and Eq. (41) into Eq. (31), yielding ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{i=0}^{T-1}}}&{\\Delta_{A_{i+1}}\\mathbb{I}\\left\\{\\boldsymbol{\\varepsilon}_{i}\\right\\}}\\\\ &{\\leq\\underset{t=0}{\\overset{T-1}{\\sum}}\\left[\\boldsymbol{\\Delta}_{A_{i+1}}\\sum_{k=1}^{\\infty}\\mathbb{I}\\left\\{\\boldsymbol{\\Lambda}_{i,k}\\right\\}\\right]+\\underset{s=1}{\\overset{T-1}{\\sum}}\\underset{t=0}{\\overset{T-1}{\\sum}}\\left[\\boldsymbol{\\Delta}_{A_{i+1}}\\sum_{k=1}^{\\infty}\\mathbb{I}\\left\\{\\boldsymbol{\\Lambda}_{i,k}^{s}\\right\\}\\right]}\\\\ &{\\leq96\\boldsymbol{\\epsilon}_{i}(\\boldsymbol{a}_{i})\\lvert\\boldsymbol{\\cdot}\\rvert}\\\\ &{\\leq96\\boldsymbol{\\epsilon}_{i}(\\boldsymbol{\\hat{h}})^{2}\\sum_{i\\in\\mathcal{I}_{i}}^{\\infty}\\left(\\underset{s\\in\\mathcal{I}_{i}}{\\operatorname*{max}}\\ \\frac{C_{\\boldsymbol{a}_{i}}}{\\Delta_{i}}\\right)}\\\\ &{\\quad+\\sum_{s=1}^{T}\\left[\\mathbf{1}\\left\\{e_{s}=2\\right\\}34\\boldsymbol{\\epsilon}\\big(c_{s}C_{s}\\log(m)\\big)^{1/2}m_{d}^{2}\\right.\\Bigg.\\Bigg(1+\\log\\left(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{max}}}\\right)\\Bigg)}\\\\ &{\\quad\\left.+\\mathbf{1}\\left\\{1<\\epsilon_{s}<2\\right\\}63.0317e_{s}\\left(c_{s}C_{s}\\log(m)\\right)^{1/6}e^{\\int_{0}m/2\\epsilon_{s}}\\Delta_{\\operatorname*{max}}^{1=2/6}\\mathrm{,~}}\\\\ &{\\quad+\\mathbf{1}\\left\\{2<\\epsilon_{s}\\right\\}63.310^{1/6}\\left(c_{s}C_{s}\\log(m)\\right)^{1/6}\\underset{s=1}{\\overset{e_{s}}{\\sum}}\\hat{a}^{2}m^{2/6}\\pi^{3}\\Lambda_{\\operatorname*{max}}^{1=2/6}\\mathrm{,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "D.1 Definition of the sequences $\\left(\\alpha_{k}\\right)$ and $(\\beta_{k})$ ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Let $\\beta=1/5$ $x>0$ .We define $\\beta_{0}=\\alpha_{0}=1$ . For $k\\geq1$ , we define ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\beta_{k}=\\beta^{k},\\qquad\\qquad\\alpha_{k}=x\\beta^{k}\\,.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Let's first look fo an adequate $k_{0}$ for Lemma 4, taking $\\begin{array}{r}{1\\leq k_{0}=\\lceil\\frac{2\\log(\\sqrt{2}m)}{\\log(1/\\beta)}+1\\rceil\\leq(2\\log(m)+3)}\\end{array}$ is suficient to have $\\begin{array}{r}{0<m\\beta_{k_{0}}<\\frac{1}{2m}}\\end{array}$ . This choice particularly yields ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\left(\\sum_{k=1}^{k_{0}-1}\\frac{\\beta_{k-1}-\\beta_{k}}{\\alpha_{k}}+\\frac{\\beta_{k_{0}-1}}{\\alpha_{k_{0}}}\\right)=\\left(\\sum_{k=1}^{k_{0}-1}\\frac{1-\\beta}{\\beta}+\\frac{1}{\\beta}\\right)\\frac{1}{x}}&{}\\\\ {\\displaystyle=\\left((k_{0}-1)\\frac{1-\\beta}{\\beta}+\\frac{1}{\\beta}\\right)\\frac{1}{x}}&{}\\\\ {\\displaystyle=\\left(4k_{0}+1\\right)\\frac{1}{x}}&{}\\\\ {\\displaystyle<1\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "for $x=4k_{0}+2$ ", "page_idx": 27}, {"type": "text", "text": "Besides, ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{k_{0}}\\frac{\\alpha_{k}}{\\beta_{k}}=(4k_{0}+2)k_{0}\\le16\\log(m)^{2}+52\\log(m)+42\\le48\\log(m)^{2}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "as $m\\geq5$ . Let $c\\in\\mathbb{R},c>1$ . Then ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\frac{\\mathrm{d}s}{2}\\frac{\\partial w_{j}^{2}}{\\partial s_{k}}-(4s_{k}+2)^{1/s_{k}}\\frac{\\sqrt{s}}{\\Delta{t}}(s^{1/s-1})^{k}}&{}\\\\ &{\\qquad\\qquad\\leq(8\\log(m)+1)^{1/s}\\frac{\\sqrt{s}}{k-1}(5^{2}\\log(\\sqrt{2n})+2)^{s}}\\\\ &{\\qquad\\qquad\\leq30^{1/s_{k}}\\biggl(10^{1/s}\\ln(10^{1/s})^{1/s}\\biggr)^{k}}\\\\ &{\\qquad\\qquad\\leq30^{1/s}\\log(m)^{1/s}\\frac{\\sqrt{s}}{5}\\,,}\\\\ &{\\qquad=30^{1/s}\\log(m)^{1/s}\\frac{\\sqrt{s}}{5}\\,,}\\\\ &{\\qquad=30^{1/s}\\log(m)^{1/s}\\frac{\\sqrt{s}}{4}(8^{s_{k}}-1)}\\\\ &{\\qquad=30^{1/s}\\log(m)^{1/s}\\frac{\\sqrt{s}}{4}\\biggl(\\exp\\left(\\frac{2\\log(\\sqrt{2n})}{16\\log(5)}+2\\right)\\biggr)-1\\biggr)}\\\\ &{\\qquad=30^{1/s}\\log(m)^{1/s}\\frac{\\sqrt{s}}{4}\\biggl(5\\log^{2}(m)-1\\biggr)}\\\\ &{\\qquad\\qquad\\leq68m^{2}(30^{s_{k}}\\log(m)^{1/s})}\\\\ &{\\qquad\\leq683m^{2}(10^{s_{k}}\\log(m)^{1/s})}\\\\ &{\\qquad\\leq630^{1/s_{k}}\\log(m)^{1/s},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "D.2 Proof of Lemma 4 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Lemma 4. Let's consider the assumptions of Proposition 6. Let $\\mathbb{A}_{t,k}$ and $(\\mathbb{A}_{t,k}^{s})_{s\\in[r]}$ be the events defined in Eq. (28) and Eq. (30). Let $k_{0}\\in\\mathbb{N}^{*}$ such that $\\begin{array}{r}{0<m\\beta_{k_{0}}<\\frac{1}{2m}}\\end{array}$ and $t\\geq d(d+1)/2$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{1}\\{\\mathcal{E}_{t}\\}\\le\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}\\}+\\sum_{s=1}^{r}\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}^{s}\\}\\,.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof Let's consider the assumptions of 6, $\\mathbb{A}_{t,k}$ and $(\\mathbb{A}_{t,k}^{s})_{s\\in[r]}$ be the events defined in Eq. (28) and Eq. (30) Let $k_{0}\\in\\mathbb{N}^{*}$ such that $\\begin{array}{r}{0<m\\beta_{k_{0}}<\\frac{1}{2m}}\\end{array}$ and $t\\geq d(d+1)/2$ ", "page_idx": 28}, {"type": "text", "text": "We first prove that the events for $k\\geq k_{0}$ cannot happen. Let $k\\geq k_{0}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{A}_{t,k}=\\left\\{\\sum_{i\\in S_{t,k}^{1}}\\frac{\\Sigma_{i,i}^{*}}{C_{A_{t+1},i}}\\ge\\beta_{k}m;\\quad\\forall l<k,\\sum_{i\\in S_{t,l}^{1}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}<\\beta_{l}m\\right\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "As $\\begin{array}{l l l l l l l}{\\beta_{k}m}&{<}&{\\beta_{k_{0}}m}&{<}&{\\frac{1}{2m}}&{\\leq}&{\\operatorname*{min}_{i,a}\\frac{\\Sigma_{i,i}}{C_{a,i}}}\\end{array}$ and $(S_{t,l}^{1})_{l}$ is a decreasing sequence of sets, $\\begin{array}{r}{\\sum_{i\\in S_{t,k_{0}}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}\\;<\\;\\beta_{k_{0}}m}\\end{array}$ <Bm imply St,ko =and iest, at $\\begin{array}{r}{\\sum_{i\\in S_{t,k}}\\frac{\\mathbf{\\nabla}\\sum_{i,i}^{*}}{C_{A_{t+1}}}\\,=\\,0\\,<\\,\\beta_{k}m}\\end{array}$ .Therefore, $\\mathbb{A}_{t,k}$ cannothappenandwedenote ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{\\hat{a}}_{t}=\\bigcup_{k\\ge1}\\mathbb{A}_{t,k}=\\bigcup_{k\\in[k_{0}]}\\mathbb{\\hat{a}}_{t,k}=\\bigcup_{k\\in[k_{0}]}\\left\\{\\sum_{i\\in S_{t,k}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}\\ge\\beta_{k}m;\\quad\\forall l<k,\\sum_{i\\in S_{t,l}^{1}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}<\\beta_{l}m\\right\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Likewise, for $k>k_{0}$ and $s\\in[r]$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n{\\mathbb A}_{t,k}^{s}=\\left\\{|S_{t,k}^{s}|\\ge\\beta_{k}m^{2};\\quad\\forall l<k,|S_{t,k}^{s}|<\\beta_{l}m^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "As $\\beta_{k_{0}}m^{2}\\,<\\,1/2\\,<\\,1$ and $(S_{t,l}^{s})_{l}$ is adecreasing sequence of sets, thn $|S_{t,k_{0}}^{s}|\\,<\\,\\beta_{k_{0}}m^{2}$ imply $S_{t,k_{0}}^{s}=\\emptyset$ and $|S_{t,k}^{s}|=0<\\beta_{k}{m}^{2}$ . Therefore, $\\mathbb{A}_{t,k}^{s}$ cannot happen and we denote ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{A}_{t}^{s}=\\bigcup_{k\\geq1}\\mathbb{A}_{t,k}^{s}=\\bigcup_{k\\in[k_{0}]}\\mathbb{A}_{t,k}^{s}=\\bigcup_{k\\in[k_{0}]}\\left\\{|S_{t,k}^{s}|\\geq\\beta_{k}m^{2};\\quad\\forall l<k,|S_{t,k}^{s}|<\\beta_{l}m^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The idea is now to prove that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left(\\mathbb{A}_{t}\\cup\\bigcup_{s=1}^{r}\\mathbb{A}_{t}^{s}\\right)^{c}=\\mathbb{A}_{t}^{c}\\cap\\cap\\cap_{s=1}^{r}\\left(\\mathbb{A}_{t}^{s}\\right)^{c}\\subseteq{\\mathcal{E}}_{t}^{c}\\,.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We begin by considering $(\\mathbb{A}_{t}^{1})^{c}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(\\mathbb{A}_{t}\\right)^{c}=\\cap_{k=1}^{k_{0}}\\!\\left(\\mathbb{A}_{t,k}\\right)^{c}}\\\\ &{\\qquad=\\bigcap_{k=1}^{k_{0}}\\!\\left(\\left\\{\\displaystyle\\sum_{i\\in S_{t,k}}\\frac{\\sum_{i,i}}{C_{A_{t+1},i}}<\\beta_{k}m\\right\\}\\displaystyle\\bigcup_{l=1}^{k-1}\\left\\{\\displaystyle\\sum_{i\\in S_{t,l}^{1}}\\frac{\\sum_{i,i}}{C_{A_{t+1},i}}\\geq\\beta_{l}m\\right\\}\\right)}\\\\ &{\\qquad=\\bigcap_{k=1}^{k_{0}}\\!\\left\\{\\displaystyle\\sum_{i\\in S_{t,k}^{1}}\\frac{\\sum_{i,i}}{C_{A_{t+1},i}}<\\beta_{k}m\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Then, under $(\\mathbb{A}_{t})^{c}$ , denoting $S_{t,0}=A_{t+1}$ , as $S_{t,k_{0}}=\\emptyset$ and the sets $S_{t,k}$ are decreasing with respect to $k$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{C_{A_{t+1},i}}{n_{t,(i,i)}}=\\displaystyle\\sum_{k=1}^{k_{0}}\\sum_{i<s_{t,k-1}^{1}\\backslash S_{t,k}^{1}}\\frac{C_{A_{t+1},i}}{n_{t,(i,i)}}}\\\\ {\\displaystyle}&{\\le\\displaystyle\\sum_{k=1}^{k_{0}}\\sum_{i<s_{t,k-1}^{1}\\backslash S_{t,k}^{1}}C_{A_{t+1},i}\\frac{1}{3m\\alpha_{k}}\\frac{\\Delta_{A_{t+1}}^{2}}{C}\\frac{\\Sigma_{i,i}^{*}}{C_{A_{t+1},i}^{2}}\\leftarrow\\mathrm{by}\\operatorname{Eq}.}\\\\ &{=\\displaystyle\\frac{\\Delta_{A_{t+1}}^{2}}{c_{1}m C}\\sum_{k=1}^{k_{0}}\\frac{1}{\\alpha_{k}}\\sum_{i<s_{t,k-1}^{1}\\backslash S_{t,k}^{1}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}}\\\\ &{=\\displaystyle\\frac{\\Delta_{A_{t+1}}^{2}}{c_{1}m C}\\sum_{k=1}^{k_{0}}\\frac{1}{\\alpha_{k}}\\Biggl(\\sum_{i\\in S_{t,k-1}^{1}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}-\\sum_{i\\in S_{t,k}^{1}}\\frac{\\Sigma_{i,i}}{C_{A_{t+1},i}}\\Biggr)}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\frac{\\Delta_{4,4+1}^{2}}{c_{1}m\\Omega}\\displaystyle\\sum_{k=0}^{k-1}\\frac{1}{\\alpha_{k+1}}\\bigg(\\sum_{i\\in S_{k,k}^{0}}\\frac{\\sum_{i,i}}{C_{A_{k+1,i}}}-\\sum_{i\\in S_{k,k+1}^{1}}\\frac{\\sum_{i,i}}{C_{A_{k+1,i}}}\\bigg)}\\\\ &{=\\frac{\\Delta_{4,4+1}^{2}}{c_{1}m C}\\bigg(\\frac{1}{\\alpha_{1}}\\sum_{i\\in S_{k,i}^{0}}\\frac{\\sum_{i,i}}{C_{A_{k+1,i}}}+\\sum_{k=1}^{k-1}\\bigg(\\frac{1}{\\alpha_{k+1}}-\\frac{1}{\\alpha_{k}}\\bigg)\\sum_{i\\in S_{k,k}^{1}}\\frac{\\sum_{i,i}}{C_{A_{k+1,i}}}\\bigg)}\\\\ &{\\leqslant\\frac{\\Delta_{4,4+1}^{2}}{c_{1}m C}\\bigg(\\frac{m}{\\alpha_{1}}+\\sum_{k=1}^{k-1}m\\beta_{k}\\bigg(\\frac{1}{\\alpha_{k+1}}-\\frac{1}{\\alpha_{k}}\\bigg)\\bigg)\\leftarrow S_{t,0}=A_{t+1}\\mathrm{~and~Eq.}}\\\\ &{=\\frac{\\Delta_{4,4+1}^{2}}{c_{1}C}\\bigg(\\sum_{k=1}^{k-1}\\frac{\\beta_{k-1}-\\beta_{k}}{\\alpha_{k}}+\\frac{\\beta_{k}_{0-1}}{\\alpha_{k_{0}}}\\bigg)}\\\\ &{\\subseteq\\frac{1}{c}\\frac{\\Delta_{4,4+1}^{2}}{c_{1}}\\cdot\\mathrm{~(-~b\\y~Eq.~(44))}}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Likewise for $s\\in[r]$ \uff0c", "page_idx": 29}, {"type": "equation", "text": "$$\n(\\mathbb{A}_{t}^{s})^{c}=\\cap_{k=1}^{k_{0}}\\left\\{|S_{t,k}^{s}|<\\beta_{k}m^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Denoting $S_{t,0}^{s}=A_{t+1}\\times A_{t+1}$ ,as $S_{t,k_{0}}^{s}=\\emptyset$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{s_{i}=0}{\\sum}\\frac{C_{s_{i}}}{\\nu_{i k}\\omega_{i}}-\\frac{\\nu_{k}}{\\nu_{i k}\\omega_{i}}\\sum_{s_{i-1}=1}^{\\infty}\\frac{C_{s_{i}}}{\\nu_{i k}\\omega_{i}}}&{,}\\\\ {~}&{\\leq\\frac{C_{s_{i}}}{\\nu_{i k}\\omega_{i}}\\sum_{s_{i-1}=1}^{\\infty}C_{s_{i}}\\frac{C_{s_{i}}}{\\nu_{i k}\\omega_{i}}\\overline{{s}}_{i}-\\frac{1}{C_{s_{i}}}+\\nu_{i k}\\Re_{i k}(\\Im_{i k})}\\\\ &{~~-\\frac{A_{s_{i}}}{\\nu_{i k}\\omega_{i}}D_{s_{i-1}}^{s_{i}}\\frac{C_{s_{i}}}{\\nu_{i k}\\omega_{i}}\\bigg(\\frac{\\nu_{i k}}{\\nu_{i k}}-1\\left|-\\frac{\\nu_{i k}}{\\nu_{i k}}\\right|\\bigg)}\\\\ &{=\\frac{\\Delta_{s_{i}}\\Delta_{s_{i-1}}}{\\nu_{i k}\\omega_{i}}\\sum_{s_{i-1}=1}^{\\infty}\\frac{1}{\\nu_{i k}\\omega_{i}}\\Big(\\delta_{i,s_{i-1}}\\left|-\\frac{\\nu_{i k}}{\\nu_{i k}}+\\right|\\Big)}\\\\ &{-\\frac{\\Delta_{s_{i}}\\Delta_{s_{i-1}}}{\\nu_{i k}\\omega_{i}}\\left(\\frac{|\\alpha_{s_{i}}|}{\\nu_{i k}}+\\frac{|\\alpha_{s_{i}}|}{\\nu_{i k}}\\left(\\alpha_{i+1}-\\frac{1}{\\alpha_{i}}\\right)\\right)}\\\\ &{\\leq\\frac{\\Delta_{s_{i}}\\Delta_{s_{i-1}}}{\\nu_{i k}\\omega_{i}}\\left(\\frac{1}{\\nu_{i k}}\\omega^{2}+\\frac{1}{\\nu_{i k}}\\delta_{i}\\alpha^{2}\\left(\\frac{1}{\\omega_{i+1}}-\\frac{1}{\\alpha_{i}}\\right)\\right)+\\nu_{i k}\\Re_{i k}}\\\\ &{~~-\\frac{\\Delta_{s_{i}}\\Delta_{s_{i-1}}}{\\nu_{i k}\\omega_{i}}\\left(\\frac{|\\alpha_{s_{i}}|}{\\nu_{i k}}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Therefore, under $\\mathbb{A}_{t}^{c}\\cap\\cap_{s=1}^{r}\\!\\left(\\mathbb{A}_{t}^{s}\\right)^{c}$ , summing Eq. (47) and Eq. (49) ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{C_{A_{t+1},i}}{n_{t,(i,j)}}+\\sum_{s\\in[r]}\\left[\\sum_{(i,j)\\in A_{t+1}}\\frac{C_{s}}{n_{t,(i,j)}^{e_{s}}}\\right]<\\left(\\frac{1}{c}+\\displaystyle\\sum_{s\\in[r]}\\frac{1}{c_{s}}\\right)\\frac{\\Delta_{A_{t+1}}^{2}}{C}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{\\Delta_{A_{t+1}}^{2}}{C}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "which contradict Eq. (25) and thus imply $\\mathcal{E}_{t}^{c}$ . By contraposition, we have proved that $\\mathcal{E}_{t}$ imply $\\begin{array}{r}{\\mathbb{A}_{t}\\cap\\bigcup_{s=1}^{r}\\left(\\mathbb{A}_{t}^{s}\\right)}\\end{array}$ . Therefore, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{1}\\{\\mathcal{E}_{t}\\}\\le\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}\\}+\\sum_{s=1}^{r}\\sum_{k=1}^{k_{0}}\\mathbb{1}\\{\\mathbb{A}_{t,k}^{s}\\}\\,.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "EDetails for OLS-UCB-C (Section 5.2) ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "E.1  Proof of Proposition 3 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Proposition 3. Let $\\delta>0$ . Then, OLS-UCB-C yields ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Bigg[\\sum_{t=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\right\\}\\Bigg]=O\\left(\\log(T)^{2}\\log(m)^{2}\\sum_{i=1}^{d}\\operatorname*{max}_{a\\in A/i\\in a}\\frac{\\sigma_{a,i}^{2}}{\\Delta_{a}}\\right),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "as $T\\rightarrow\\infty$ where $\\begin{array}{r}{\\sigma_{a,i}^{2}=\\sum_{j\\in a}(\\Sigma_{i,j})_{+}}\\end{array}$ ", "page_idx": 30}, {"type": "text", "text": "Proof. The objective is to use Proposition 6. ", "page_idx": 30}, {"type": "text", "text": "Proposition 6. Let $r\\in\\mathbb{N}$ $e\\in(1,+\\infty)^{r}$ . Let $(\\mathcal{E}_{t})_{t\\geq d(d+1)/2}$ be a sequence of events such that for all $t\\geq d(d+1)/2$ under $\\mathcal{E}_{t}$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{\\Delta_{A_{t+1}}^{2}}{C}\\leq\\sum_{i\\in A_{t+1}}\\frac{C_{A_{t+1},i}}{n_{t,(i,j)}}+\\sum_{s\\in[r]}\\left[\\sum_{(i,j)\\in A_{t+1}}\\frac{C_{s}}{n_{t,(i,j)}^{e_{s}}}\\right]\\!,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $C$ and $(C_{s})_{s\\in[r]}$ are problem-dependent positive constants. $C_{A_{t+1},i}$ is a positive constant depending on $A_{t+1}$ and $i$ so that, for all $a\\in A$ $C_{a,i}\\leq2m\\pmb{\\Sigma}_{i,i}$ Let $c\\in\\mathbb{R}_{+}^{*}$ and $(c_{s})_{s\\in[r]}\\in(\\mathbb{R}_{+}^{*})^{r}$ be positive constants such that $\\begin{array}{r}{1/c+\\sum_{s\\in[r]}1/c_{s}=1}\\end{array}$ ", "page_idx": 30}, {"type": "text", "text": "Then, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{t=d(d+1)/2}{\\overset{T-1}{\\sum}}}&{\\Delta_{A_{t+1}}\\mathbf{1}\\{\\xi_{t}\\}}\\\\ &{\\overset{}{\\leq}96c_{1}C\\log(m)^{2}\\underset{i\\in[d]}{\\overset{}{\\sum}}\\Big(\\underset{a\\in\\mathcal{A}/\\mathfrak{t}_{d}}{\\operatorname*{max}}\\ \\frac{C_{a,i}}{\\Delta_{a}}\\Big)}\\\\ &{\\qquad+\\underset{s=1}{\\overset{T}{\\sum}}\\Bigg[\\mathbf{1}\\Big\\{e_{s}=2\\Big\\}346\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/2}m d^{2}\\Big(1+\\log\\Big(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\Big)\\Big)}\\\\ &{\\qquad+\\,1\\Big\\{1<e_{s}<2\\Big\\}60.30^{1/\\varepsilon}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/\\varepsilon}\\mathscr{A}^{2}m^{2/\\varepsilon}\\mathscr{S}\\frac{1-2/\\varepsilon}{\\operatorname*{min}}}\\\\ &{\\qquad+\\,1\\Big\\{2<e_{s}\\Big\\}60.30^{1/\\varepsilon}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/\\varepsilon}\\frac{e_{s}}{e_{s}-2}d^{2}m^{2/\\varepsilon}\\mathscr{S}_{\\operatorname*{max}}^{1-2/\\varepsilon}\\mathscr{E}\\Bigg]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $(\\alpha_{k})_{k\\in\\mathbb{N}^{*}},\\,(\\beta_{k})_{k\\in\\mathbb{N}^{*}}$ and $k_{0}\\in\\mathbb{N}^{*}$ are defined in Appendix $D.I$ ", "page_idx": 30}, {"type": "text", "text": "We need to check that its hypotheses are satisfied. Let $t\\geq d(d+1)/2$ and $\\delta>0$ , then we have the Lemma. ", "page_idx": 30}, {"type": "text", "text": "Lemma 5. Let $\\delta>0$ and $t\\geq d(d+1)/2$ . Then under $\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}$ , OLS-UCB-C satisfies ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{\\Delta_{A_{t+1}}^{2}}{f_{T,\\delta}^{2}}\\sum_{i\\in A_{t+1}}\\frac{4\\bar{\\sigma}_{A_{t+1},i}^{2}}{n_{t,(i,i)}}+\\sum_{(i,j)\\in A_{t+1}}\\frac{(4d+h_{t,\\delta}^{2})\\|B\\|_{\\infty}^{2}}{n_{t,(i,j)}^{2}}+\\sum_{(i,j)\\in A_{t+1}}\\frac{5h_{t,\\delta}\\|B\\|_{\\infty}^{2}}{n_{t,(i,j)}^{3/2}}+\\sum_{(i,j)\\in A_{t+1}}\\frac{\\|B\\|_{\\infty}^{2}}{n_{t,(i,j)}^{3}}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\begin{array}{r}{\\bar{\\sigma}_{A_{t+1},i}^{2}=2\\sum_{j\\in A_{t+1}/\\Sigma_{j,j}\\leq\\Sigma_{i,i}}(\\Sigma_{i,j})_{+}\\leq2\\sigma_{A_{t+1},i}^{2}.}\\end{array}$ ", "page_idx": 30}, {"type": "text", "text": "Therefore, we can choose $r=3$ $\\boldsymbol{e}=(2,\\,3/2,\\,3)$ and $(\\mathcal{E}_{t})=(\\mathcal{G}_{t}\\cap\\mathcal{C}_{t})$ . Taking $c=(4,4,4,4)$ and identifying the rest of the coefficients yields that OLS-UCB-C satisfies ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{c l r}{{\\displaystyle\\sum_{t=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\mathbb{1}\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}}}\\\\ {{\\displaystyle}}&{{\\displaystyle}}&{{\\le384f_{T,\\delta}^{2}\\log(m)^{2}\\sum_{i\\in[d]}\\left(\\operatorname*{max}_{\\alpha\\in A/i\\in a}\\frac{\\bar{\\mathcal{D}}_{\\alpha,i}^{2}}{\\Delta_{\\alpha}}\\right)}}\\\\ {{\\displaystyle}}&{{\\displaystyle}}&{{\\displaystyle+\\,692\\|B\\|_{\\infty}f_{T,\\delta}(4d+h_{t,\\delta}^{2})^{1/2}\\log(m)^{1/2}\\left(1+\\log\\left(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\right)\\right.}}\\\\ {{\\displaystyle}}&{{\\displaystyle}}&{{\\displaystyle\\left.+1460\\|B\\|_{\\infty}^{4/3}f_{T,\\delta}^{2/3}\\ln_{t,\\delta}^{2/3}\\log(m)^{2/3}d^{2}\\alpha^{2/3}\\Delta_{\\operatorname*{min}}^{-1/3}\\right.}}\\\\ {{\\displaystyle}}&{{\\displaystyle}}&{{\\displaystyle+\\left.296\\|B\\|_{\\infty}^{2/3}f_{T,\\delta}^{2/3}\\log(m)^{1/3}d^{2}m^{2/3}\\Delta_{\\operatorname*{max}}^{1/3}\\right.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "As ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f_{t,\\delta}=6\\log(1/\\delta)+6\\Bigl(\\log(t)+(d+2)\\log(\\log(t))\\Bigr)+3d\\Bigl(2\\log(2)+\\log(1+e)\\Bigr),}\\\\ &{h_{t,\\delta}=\\Bigl(1+2\\log(1/\\delta)+2\\log\\bigl(t\\log(t)^{2}d(d+1)\\bigr)+\\log(1+t)\\Bigr)^{1/2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "we deduce ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{t=d(d+1)/2}^{T-1}\\Delta_{A_{t+1}}\\mathbb{1}\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}=O\\left(\\log(T)^{2}\\log(m)^{2}\\sum_{i\\in[d]}\\left(\\operatorname*{max}_{a\\in A/i\\in a}\\frac{\\bar{\\sigma}_{a,i}^{2}}{\\Delta_{a}}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "E.2Proof of Lemma 5 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Lemma 5. Let $\\delta>0$ and $t\\geq d(d+1)/2$ .Then under $\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}$ , OLS-UCB-C satisfies ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\frac{\\Delta_{A_{t+1}}^{2}}{f_{T,\\delta}^{2}}\\sum_{i\\in A_{t+1}}\\frac{4\\bar{\\sigma}_{A_{t+1},i}^{2}}{n_{t,(i,i)}}+\\sum_{(i,j)\\in A_{t+1}}\\frac{(4d+h_{t,\\delta}^{2})\\|B\\|_{\\infty}^{2}}{n_{t,(i,j)}^{2}}+\\sum_{(i,j)\\in A_{t+1}}\\frac{5h_{t,\\delta}\\|B\\|_{\\infty}^{2}}{n_{t,(i,j)}^{3/2}}+\\sum_{(i,j)\\in A_{t+1}}\\frac{\\|B\\|_{\\infty}^{2}}{n_{t,(i,j)}^{3}}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\begin{array}{r}{\\bar{\\sigma}_{A_{t+1},i}^{2}=2\\sum_{j\\in A_{t+1}/\\Sigma_{j,j}\\leq\\Sigma_{i,i}}(\\Sigma_{i,j})_{+}\\leq2\\sigma_{A_{t+1},i}^{2}.}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "Proof. Let $t\\geq d(d+1)/2$ and $\\delta>0$ . OLS-UCB-C statisfies the following Lemma. ", "page_idx": 31}, {"type": "text", "text": "Lemma 6. Let $t\\geq d(d+1)/2$ and $\\delta>0$ . Then for OLS-UCB- $C,$ under the event $\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\Delta_{A_{t+1}}\\leq f_{t,\\delta}\\big(\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\mathbf{z}_{t}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\hat{\\mathbf{z}}_{t}}\\big)\\,.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Therefore, under $\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}$ , and ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{0\\leq\\Delta_{A_{t+1}}\\leq f_{t,\\delta}\\big(\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\mathbf{z}_{t}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\hat{\\mathbf{z}}_{t}\\big)}\\\\ &{\\qquad\\Delta_{A_{t+1}}^{2}\\leq f_{t,\\delta}^{2}\\big(\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\mathbf{z}_{t}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\hat{\\mathbf{z}}_{t}\\big)^{2}}\\\\ &{\\qquad\\qquad\\leq2f_{t,\\delta}^{2}\\big(\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{z}_{t}}^{2}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\hat{\\mathbf{z}}_{t}}^{2}\\big)}\\\\ &{\\qquad\\qquad\\frac{\\Delta_{A_{t+1}}^{2}}{2f_{t\\delta}^{2}}\\leq\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{z}_{t}}^{2}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\hat{\\mathbf{z}}_{t}}^{2}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "From, here, we develop the right-hand side, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}=A_{t+1}^{\\top}\\mathbf{N}_{t}^{-1}\\mathbf{Z}_{t}\\mathbf{N}_{t}^{-1}A_{t+1}}}\\\\ &{}&{=\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{(\\mathbf{Z}_{t})_{i,j}}{n_{t,(i,i)}n_{t,(j,j)}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "As $\\begin{array}{r}{{\\bf{Z}}_{t}=\\sum_{s=1}^{t}{\\bf{d}}_{A_{s}}{\\bf{\\Sigma}}^{*}{\\bf{d}}_{A_{s}}+{\\bf{d}}_{{\\Sigma}^{*}}{\\bf{N}}_{t}+\\|B\\|^{2}{\\bf{I}}}\\end{array}$ we get ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}=\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{n_{t,(i,j)}\\Sigma_{i,j}}{n_{t,(i,i)}n_{t,(j,j)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{n_{t(i,i)}\\Sigma_{i,i}}{n_{t,(i,i)}^{2}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\|B\\|^{2}}{n_{t,(i,i)}^{2}}}\\\\ {\\le\\displaystyle\\sum_{i\\in A_{t+1}}\\left(2\\displaystyle\\sum_{j\\in A_{t+1}/\\Sigma_{j,j}\\leq\\Sigma_{i,i}}\\frac{n_{t,(i,j)}\\Sigma_{i,j}}{n_{t,(i,i)}n_{t,(j,j)}}\\right)+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\|B\\|^{2}}{n_{t,(i,i)}^{2}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "by rearranging terms. ", "page_idx": 32}, {"type": "text", "text": "Now as for all $(i,j)\\in[d]^{2},n_{t,(i,j)}\\leq\\operatorname*{min}\\{n_{t,(i,i)},n_{t,(j,j)}\\}$ then ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}\\le\\sum_{i\\in A_{t+1}}\\frac{1}{n_{t,(i,i)}}\\bigg(2\\sum_{j\\in A_{t+1}/\\Sigma_{j,j}\\le\\Sigma_{i,i}}\\Sigma_{i,j}\\bigg)+\\sum_{i\\in A_{t+1}}\\frac{\\|B\\|^{2}}{n_{t,(i,i)}^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Denoting $\\begin{array}{r}{\\bar{\\sigma}_{A_{t+1},i}^{2}=2\\sum_{j\\in A_{t+1}/\\Sigma_{j,j}\\leq\\Sigma_{i,i}}(\\Sigma_{i,j})_{+}}\\end{array}$ yields ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}\\le\\sum_{i\\in A_{t+1}}\\frac{\\bar{\\sigma}_{A_{t+1},i}^{2}}{n_{t,(i,i)}}+\\sum_{i\\in A_{t+1}}\\frac{\\|B\\|^{2}}{n_{t,(i,i)}^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "The second term from the right-hand side of Eq. (51) is developed in the same manner but involves more terms. ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\mathbf{N}_{t}^{-1}A_{t+1}\\right\\rVert_{\\hat{\\mathbf{Z}}_{t}}^{2}=A_{t+1}^{\\top}\\mathbf{N}_{t}^{-1}\\hat{\\mathbf{Z}}_{t}\\mathbf{N}_{t}^{-1}A_{t+1}}\\\\ {=\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{(\\hat{\\mathbf{Z}}_{t})_{i,j}}{n_{t,(i,i)}n_{t,(j,j)}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "We remind that $\\begin{array}{r}{\\hat{\\mathbf{Z}}_{t}=\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}\\hat{\\Sigma}_{t}\\mathbf{d}_{A_{s}}+\\mathbf{d}_{\\hat{\\Sigma}_{t}}\\mathbf{N}_{t}+\\|B\\|^{2}\\mathbf{I}}\\end{array}$ where for all $(i,j)\\in[d]^{2}$ \uff0c ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\hat{\\Sigma}_{t,(i,j)}=\\hat{\\chi}_{t,(i,j)}+\\frac{B_{i}B_{j}}{4}\\biggl(\\frac{5h_{t,\\delta}}{\\sqrt{n_{t,(i,j)}}}+\\frac{h_{t,\\delta}^{2}}{n_{t,(i,j)}}+\\frac{1}{n_{t,(i,j)}^{2}}\\biggr)\\,.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Being under the event $\\mathcal{C}$ Proposition 2 yields $\\begin{array}{r}{\\hat{\\Sigma}_{t,(i,j)}\\leq\\Sigma_{i,j}+\\frac{B_{i}B_{j}}{4}\\bigg(\\frac{5h_{t,\\delta}}{\\sqrt{n_{t,(i,j)}}}+\\frac{h_{t,\\delta}^{2}}{n_{t,(i,j)}}+\\frac{1}{n_{t,(i,j)}^{2}}\\bigg).}\\end{array}$ Then, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\|\\mathbf{N}_{t}^{-1}A_{41}\\|_{2,5}^{2}\\leq\\sum_{i,j\\leq k_{1}+1\\atop i\\leq j}\\frac{\\overline{{n}}_{i,k_{2}}(i_{1})\\overline{{\\mathbf{z}}}_{k_{3},j}}{(\\pi_{i,j+k_{1}}^{0}+\\pi_{i,j+k_{1}}^{1})(\\overline{{n}}_{i,k_{2}}^{1}\\mu_{k_{1}}^{2})}}\\quad}&{}\\\\ &{+\\sum_{i,j\\leq k_{1}+1\\atop i\\leq j,k_{2}+1\\atop i\\neq k_{1}+1\\atop i\\neq j,k_{2}+1\\atop i\\neq k_{2}+1\\atop i\\neq k_{1}+1\\atop i\\neq j,k_{3}}\\frac{\\overline{{n}}_{i,k_{3}}(\\overline{{\\nabla}}_{\\cdot}\\tilde{\\mathbf{z}}_{i,k_{3}}^{2}+\\frac{\\overline{{n}}_{i,k_{4}}^{2}}{n_{i,j+k_{3}}^{2}}+\\frac{1}{n_{i,(i_{2})}^{3}})}{4\\pi_{i,k_{4}}^{2}}}\\\\ &{+\\sum_{i\\geq k_{1}}\\frac{\\overline{{n}}_{i,k_{4}}^{2}(\\overline{{n}}_{i,k_{4}}^{1})}{(\\pi_{i,j+k_{1}}^{0}+\\pi_{i,k_{4}}^{1})(\\overline{{n}}_{i,k_{2}}^{1}+\\frac{\\overline{{n}}_{i,k_{1}}^{2}}{n_{i,k_{4}}^{2}})}+\\frac{\\overline{{n}}_{i,k_{2}}^{2}}{4\\pi_{i,k_{3}}^{2}}\\bigg(\\frac{5\\overline{{n}}_{i,k_{4}}}{\\pi_{i,j+k_{3}}^{0}}+\\frac{\\overline{{n}}_{i,k_{3}}^{2}}{n_{i,k_{4}}(\\pi_{i,k_{3}}^{2}+\\pi_{i,k_{4}}^{1})}\\bigg)}\\\\ &{+\\sum_{i,k_{1}}\\frac{\\overline{{n}}_{i,k_{2}}^{1}}{\\pi_{i,k_{1}}^{0}+\\pi_{i,k_{2} \n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Reinjecting Eq. (52) and Eq. (53) into Eq. (51) yields ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\Delta_{A_{t+1}}^{2}}{2f_{t,\\delta}^{2}}\\leq\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\hat{\\mathbf{Z}}_{t}}^{2}}\\\\ &{\\qquad\\leq\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{2\\bar{\\sigma}_{A_{t+1},i}^{2}}{n_{t,(i,i)}}+\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{(2d+h_{t,\\delta}^{2}/2)\\|B\\|_{\\infty}^{2}}{n_{t,(i,j)}^{2}}}\\\\ &{\\qquad\\qquad+\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{5h_{t,\\delta}\\|B\\|_{\\infty}^{2}/2}{n_{t,(i,j)}^{3/2}}+\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{\\|B\\|_{\\infty}^{2}/2}{n_{t,(i,j)}^{3}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The desired inequality just comes from $f_{T,\\delta}\\geq f_{t,\\delta}$ ", "page_idx": 33}, {"type": "text", "text": "E.3Proof of Lemma 6 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Lemma 6. Let $t\\geq d(d+1)/2$ and $\\delta>0$ .Then for OLS-UCB-C, under the event $\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\}$ ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\Delta_{A_{t+1}}\\leq f_{t,\\delta}\\big(\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\mathbf{z}_{t}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\hat{\\mathbf{z}}_{t}}\\big)\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. Let $t\\geq d(d+1)/2$ and $\\delta>0$ . The error in estimating the mean reward for action $a$ with $\\left\\langle a,\\hat{\\mu}_{t}\\right\\rangle$ is bounded as ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|a^{\\top}(\\hat{\\mu}_{t}-\\mu)\\right|\\leq\\left\\|\\mathbf{N}_{t}^{-1}a\\right\\|\\mathbf{z}_{t}\\,\\left\\|\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}\\eta_{s}\\right\\|_{\\mathbf{Z}_{t}^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "The definition of $\\begin{array}{r}{\\mathcal{G}_{t}=\\left\\{\\ \\left\\Vert\\sum_{s=1}^{t}\\mathbf{d}_{A_{s}}\\eta_{s}\\right\\Vert_{\\mathbf{Z}_{t}^{-1}}\\leq f_{t,\\delta}\\right\\}}\\end{array}$ yields that in this event, ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle A_{t+1},\\hat{\\mu}_{t}\\rangle\\leq\\langle A_{t+1},\\mu\\rangle+f_{t,\\delta}\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\mathbf{z}_{t}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "and ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\langle a^{*},\\mu\\rangle-f_{t,\\delta}\\|\\mathbf{N}_{t}^{-1}a^{*}\\|\\mathbf{z}_{t}\\leq\\langle a^{*},\\hat{\\mu}_{t}\\rangle\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "By the definition of $A_{t+1}$ for OLS-UCB-C in (6); ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\langle a^{*},\\hat{\\mu}_{t}\\rangle+f_{t,\\delta}\\|\\mathbf{N}_{t}^{-1}a^{*}\\|_{\\hat{\\mathbf{Z}}_{t}}\\leq\\langle A_{t+1},\\hat{\\mu}_{t}\\rangle+f_{t,\\delta}\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\hat{\\mathbf{Z}}_{t}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Combining the expressions gives ", "page_idx": 34}, {"type": "equation", "text": "$$\na^{*},\\mu)+f_{t,\\delta}(\\|\\mathbf{N}_{t}^{-1}a^{*}\\|_{\\tilde{\\mathbf{Z}}_{t}}-\\|\\mathbf{N}_{t}^{-1}a^{*}\\|\\mathbf{z}_{t})\\leq\\left<A_{t+1},\\mu\\right>+f_{t,\\delta}(\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|\\mathbf{z}_{t}+\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\tilde{\\mathbf{Z}}_{t}})\\,.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Now, we use the fact that under $\\boldsymbol{\\mathcal{C}}_{t},\\hat{\\mathbf{Z}}_{t}$ uses coefcient-wise upper bounds of $\\Sigma$ which yields that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\|\\mathbf{N}_{t}^{-1}a^{*}\\|_{\\mathbf{Z}_{t}}^{2}\\leq\\|\\mathbf{N}_{t}^{-1}a^{*}\\|_{\\hat{\\mathbf{Z}}_{t}}^{2}\\,.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Rearranging terms the desired result. ", "page_idx": 34}, {"type": "text", "text": "E.4  Proof of the gap-free bound ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Theorem 1. Let $T\\in\\mathbb{N}^{*}$ and $\\delta>0$ ", "page_idx": 34}, {"type": "text", "text": "Then, OLS-UCB-C (Alg. 2) satisfies the gap-dependent regret upper bound ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]=\\tilde{O}\\bigg(\\log(m)^{2}\\sum_{i=1}^{d}\\operatorname*{max}_{a\\in\\mathcal{A}/i\\in a,\\Delta_{a}>0}\\frac{\\sigma_{a,i}^{2}}{\\Delta_{a}}\\bigg)\\,,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $\\begin{array}{r}{\\sigma_{a,i}^{2}=\\sum_{j\\in a}\\operatorname*{max}\\{\\Sigma_{i,j},0\\}}\\end{array}$ and the gap-free regret upper bound ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[R_{T}]=\\tilde{O}\\bigg(\\log(m)\\sqrt{T}\\sqrt{\\sum_{i=1}^{d}\\underset{a\\in\\mathcal{A}/i\\in a}{\\operatorname*{max}}\\sigma_{a,i}^{2}}\\bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Proof. Let $\\Delta>0$ then ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=d(d+1)}^{T-1}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\right\\}=\\displaystyle\\sum_{t=d(d+1)}^{T-1}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\left(\\Delta_{A_{t+1}}\\leq\\Delta\\right)\\right\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\displaystyle+\\sum_{t=d(d+1)}^{T-1}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\left(\\Delta_{A_{t+1}}>\\Delta\\right)\\right\\}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\le T\\Delta+\\displaystyle\\sum_{t=d(d+1)}^{T-1}\\Delta_{A_{t+1}}\\mathbb{I}\\left\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\left(\\Delta_{A_{t+1}}>\\Delta\\right)\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Adapting Proposition 6 to account for $\\Delta_{A_{t+1}}>\\Delta$ yields ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sum_{t=0}^{T-1}\\Delta_{A_{t+1}}\\mathbb{1}\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap(\\Delta_{A_{t+1}}>\\Delta)\\}\\lesssim\\frac{1}{\\Delta}\\log(T)^{2}\\log(m)^{2}\\sum_{i\\in[d]}\\left(\\operatorname*{max}_{a\\in A/i\\in a}\\sigma_{a,i}^{2}\\right).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $\\lesssim$ is an inequality up to constant factors (when $T$ varies). ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\mathbb{E}[R_{T}]=O\\left(\\log(m)\\log(T)\\sqrt{T}\\sqrt{\\sum_{i\\in[d]}\\operatorname*{max}_{a\\in\\mathcal{A}/i\\in a}\\sigma_{a,i}^{2}}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "FDetails for COs-V (Section 5.3) ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "F.1Proof for Lemma 7 ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Lemma 7. Let $\\delta>0$ . Then Cos-V satisfies ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\sum_{s=d(d+A)/2}^{T}\\mathbb{P}(\\mathcal{H}_{t}^{c})\\leq\\delta\\sum_{t=1}^{T}\\frac{1}{t\\log(t)^{2}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Proof. Let $\\delta>0,t\\geq d(d+1)/2$ . We remind ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{H}_{t}=\\left\\{\\forall i\\in[d],\\;\\left|\\left(\\hat{\\mu}_{t,i}+(1+g_{t,\\delta})f_{t,\\delta}\\frac{(\\hat{\\bf Z}_{t,i})^{1/2}}{n_{t,i}}\\right)-\\tilde{\\mu}_{t,i}\\right|\\leq g_{t,\\delta}f_{t}\\frac{(\\hat{\\bf Z}_{t,i})^{1/2}}{n_{t,i}}\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $g_{t,\\delta}=\\Big(2\\log\\big(2d t\\log(t)^{2}\\big)+\\log(1/\\delta)\\Big)^{1/2}.$ ", "page_idx": 35}, {"type": "text", "text": "Conditionally to $\\mathcal{F}_{t}=\\sigma(A_{1},Y_{1},\\ldots,A_{t},Y_{t})$ , for all $i\\in[d]$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\tilde{\\mu}_{t,i}\\sim\\mathcal{N}\\bigg(\\hat{\\mu}_{t,i}+(1+g_{t,\\delta})f_{t,\\delta}\\frac{\\hat{\\mathbf{z}}_{t,(i,i)}^{1/2}}{n_{t,(i,i)}},\\,\\,f_{t,\\delta}^{2}\\frac{\\hat{\\mathbf{z}}_{t,(i,i)}}{n_{t,(i,i)}^{2}}\\bigg)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Let $i\\in a^{*}$ . Then Gaussian concentration yields ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\scriptstyle^{3}\\mathcal{F}_{t}\\left(\\left|\\left(\\hat{\\mu}_{t,i}+(1+g_{t,\\delta})f_{t,\\delta}\\frac{\\hat{\\mathbf{Z}}_{t,(i,i)}^{1/2}}{n_{t,(i,i)}}\\right)-\\tilde{\\mu}_{t,i}\\right|>\\sqrt{2\\log(2d t\\log(t)^{2}/\\delta)}f_{t,\\delta}\\frac{\\hat{\\mathbf{Z}}_{t,(i,i)}^{1/2}}{n_{t,(i,i)}}\\right)\\le\\frac{\\delta}{d t\\log(t)^{2}}\\,,\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "and ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\Bigg|\\Big(\\hat{\\mu}_{t,i}+(1+g_{t,\\delta})f_{t,\\delta}\\frac{\\hat{\\mathbf{Z}}_{t,(i,i)}^{1/2}}{n_{t,(i,i)}}\\Big)-\\tilde{\\mu}_{t,i}\\Bigg|>\\sqrt{2\\log(2d t\\log(t)^{2}/\\delta)}f_{t,\\delta}\\frac{\\hat{\\mathbf{Z}}_{t,(i,i)}^{1/2}}{n_{t,(i,i)}}\\Bigg)\\leq\\frac{\\delta}{d t\\log(t)^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "by integration. ", "page_idx": 35}, {"type": "text", "text": "A union bound on $i\\in[d]$ and $t\\geq d(d+1)/2$ yields the result ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{t=d(d+1)/2}^{T}\\mathbb{P}(\\mathcal{H}_{t}^{c})\\leq\\sum_{t\\in[T]}\\frac{\\delta}{t(\\log(t)^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "F.2 Proof for Proposition 4 ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Proposition 4. Let $\\delta>0$ Then COS- $\\boldsymbol{\\cdot}$ yields ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Bigg[\\sum_{t=d(d+1)}^{T-1}\\Delta_{A_{t+1}}\\mathbb{1}\\big\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\mathcal{H}_{t}\\big\\}\\Bigg]=O\\Bigg(\\log(T)^{3}\\log(m)^{2}\\Big(\\sum_{i=1}^{d}\\frac{m\\Sigma_{i,i}}{\\Delta_{i,\\operatorname*{min}}}\\Big)\\Bigg)\\,.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof.Let $\\delta>0$ . We first make use of the following Lemma. ", "page_idx": 35}, {"type": "text", "text": "Lemma 8. Let $t\\geq d(d+1)/2,\\,\\delta>0$ .Then for COS- $\\mathtt{V}_{\\mathrm{i}}$ under $\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\mathcal{H}_{t}\\}$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\Delta_{A_{t+1}}}{f_{T,\\delta}^{2}g_{T,\\delta}^{2}}\\le\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{40m\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{29m d h_{t,\\delta}^{2}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{2}}\\qquad}\\\\ {+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{45m h_{t,\\delta}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{3/2}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{9m\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{3}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "This enables to use a \u201cmodified\u2019\" version of Proposition 6, which do not consider covariances. ", "page_idx": 35}, {"type": "text", "text": "Proposition 7. Let $r\\in\\mathbb{N}$ $e\\in(1,+\\infty)^{r}$ . Let $(\\mathcal{E}_{t})_{t\\geq d(d+1)/2}$ be a sequence of events such that for all $t\\geq d(d+1)/2$ under $\\mathcal{E}_{t}$ ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\frac{\\Delta_{A_{t+1}}^{2}}{C}\\leq\\sum_{i\\in A_{t+1}}\\frac{C_{i}}{n_{t,(i,j)}}+\\sum_{s\\in[r]}\\left[\\sum_{i\\in A_{t+1}}\\frac{C_{s}}{n_{t,(i,j)}^{e_{s}}}\\right]\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $C$ and $(C_{s})_{s\\in[r]}$ are problem-dependent positive constants. $C_{i}$ is a positive constant depending on i so that, $C_{i}\\,\\leq\\,2m\\pmb{\\Sigma}_{i,i}$ Let $c\\in\\mathbb{R}_{+}^{*}$ and $(c_{s})_{s\\in[r]}\\;\\in\\;(\\mathbb{R}_{+}^{*})^{r}$ be positive constants such that $\\textstyle1/c+\\sum_{s\\in[r]}1/c_{s}=1$ ", "page_idx": 35}, {"type": "text", "text": "Then, ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t=i d(i+1)/2}^{T-1}\\Delta_{A_{t+1}}\\mathbf{1}\\{\\xi_{t}\\}}}\\\\ &{\\leq96c_{1}C\\log(m)^{2}\\sum_{i\\in[d]}\\left(\\frac{C_{i}}{\\Delta_{i,\\operatorname*{min}}}\\right)}\\\\ &{\\qquad+\\sum_{s=1}^{r}\\Bigg[\\mathbf{1}\\Big\\{e_{s}=2\\Big\\}346\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/2}m^{3/2}d\\Big(1+\\log\\Big(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\Big)\\Big)}\\\\ &{\\qquad+\\,\\mathbf{1}\\Big\\{1<e_{s}<2\\Big\\}60.30^{1/\\varepsilon}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/\\varepsilon}d m^{1+1/\\varepsilon}\\Delta_{\\operatorname*{min}}^{1-2/\\varepsilon,s}}\\\\ &{\\qquad+\\,\\mathbf{1}\\Big\\{2<e_{s}\\Big\\}60.30^{1/\\varepsilon}\\Big(c_{s}C C_{s}\\log(m)\\Big)^{1/\\varepsilon}\\frac{e_{s}}{e_{s}-2}d m^{1+1/\\varepsilon}\\Delta_{\\operatorname*{max}}^{1-2/\\varepsilon,s}\\Bigg]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $(\\alpha_{k})_{k\\in\\mathbb{N}^{*}}$ \uff0c $(\\beta_{k})_{k\\in\\mathbb{N}^{*}}$ and $k_{0}\\in\\mathbb{N}^{*}$ are defined in Appendix $D.I$ ", "page_idx": 36}, {"type": "text", "text": "Applied to COS- $\\mathtt{V}$ , this yields ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{t=d(d+1)/2}{\\overset{T-1}{\\sum}}\\Delta_{A_{t+1}}\\mathbf{1}\\big\\{\\mathcal{G}_{t}\\cap\\mathcal{C}\\cap\\mathcal{H}\\big\\}}\\\\ &{\\quad\\quad\\quad\\leq15360f_{T,\\delta}^{2}g_{T,\\delta}^{2}\\log(m)^{2}\\underset{i\\in[d]}{\\overset{}{\\sum}}\\left(\\frac{m\\Sigma_{i,i}}{\\Delta_{i,\\operatorname*{min}}}\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\overset{}{\\quad+3727f_{T,\\delta}g_{T,\\delta}h_{T,\\delta}(\\log(m))^{1/2}\\|B\\|_{\\infty}m^{2}d^{2}\\left(1+\\log\\left(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\right)\\right)}}\\\\ &{\\quad\\quad\\quad+7329(f_{T,\\delta}g_{T,\\delta})^{4/3}h_{T,\\delta}^{2/3}\\log(m)^{2/3}\\|B\\|_{\\infty}^{4/3}m^{5/3}d\\Delta_{\\operatorname*{min}}^{-1/3}}\\\\ &{\\quad\\quad\\quad\\quad+3745(f_{T,\\delta}g_{T,\\delta})^{2/3}\\log(m)^{1/3}\\|B\\|_{\\infty}^{2/3}m^{4/3}d\\Delta_{\\operatorname*{min}}^{1/3},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f_{t,\\delta}=6\\log(1/\\delta)+6\\Bigl(\\log(t)+(d+2)\\log(\\log(t))\\Bigr)+3d\\Bigl(2\\log(2)+\\log(1+e)\\Bigr),}\\\\ &{h_{t,\\delta}=(1+2\\log(1/\\delta)+2\\log(d(d+1))+\\log(1+t))^{1/2},}\\\\ &{g_{t,\\delta}=(1+\\log(2d t\\log(t)^{2})+\\log(1/\\delta))^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "We deduce ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Bigg[\\sum_{t=d(d+1)}^{T-1}\\Delta_{A_{t+1}}\\mathbb{1}\\big\\{\\mathcal{G}_{t}\\cap\\mathcal{C}\\cap\\mathcal{H}\\big\\}\\Bigg]=O\\Bigg(\\log(T)^{3}\\log(m)^{2}\\Big(\\sum_{i=1}^{d}\\frac{m\\Sigma_{i,i}}{\\Delta_{i,\\operatorname*{min}}}\\Big)\\Bigg)\\,.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "F.3Proof for Lemma 8 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Lemma 8. Let $t\\geq d(d+1)/2,\\,\\,\\,$ $\\delta>0$ Then for COs- $\\mathtt{V}_{\\mathrm{i}}$ under $\\{\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}\\cap\\mathcal{H}_{t}\\}$ ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\Delta_{A_{t+1}}}{f_{T,\\delta}^{2}g_{T,\\delta}^{2}}\\le\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{40m\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{29m d h_{t,\\delta}^{2}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{2}}\\qquad}\\\\ {+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{45m h_{t,\\delta}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{3/2}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{9m\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{3}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Proof. Let $t\\geq d(d+1)/2$ and $\\delta>0$ . Then ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta_{A_{t+1}}=\\langle a^{*}-A_{t+1},\\mu\\rangle}\\\\ &{\\quad\\quad=\\langle a^{*},\\mu-\\tilde{\\mu}_{t}\\rangle+\\langle a^{*}-A_{t+1},\\tilde{\\mu}_{t}\\rangle+\\langle A_{t+1},\\tilde{\\mu}_{t}-\\mu\\rangle}\\\\ &{\\quad\\quad\\leq\\langle a^{*},\\mu-\\tilde{\\mu}_{t}\\rangle+\\langle A_{t+1},\\tilde{\\mu}_{t}-\\mu\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "by definition of $A_{t+1}$ ", "page_idx": 37}, {"type": "text", "text": "Besides, ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\langle a^{*},\\mu-\\tilde{\\mu}_{t}\\rangle=\\sum_{i\\in a^{*}}\\mu_{i}-\\tilde{\\mu}_{t,i}}\\quad}&{{}}\\\\ &{{=\\displaystyle\\sum_{i\\in a^{*}}\\left(\\mu_{i}-\\hat{\\mu}_{t,i}+\\hat{\\mu}_{t,i}-\\tilde{\\mu}_{t,i}\\right).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Under $\\mathcal{G}_{t}\\cap\\mathcal{C}_{t}$ , for all $i\\in a^{*}$ \uff0c", "page_idx": 37}, {"type": "equation", "text": "$$\n\\mu_{i}-\\hat{\\mu}_{t,i}\\leq f_{t,\\delta}\\frac{\\mathbf{Z}_{t,i}^{1/2}}{n_{t,(i,i)}}.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Under $\\mathcal{H}_{t}$ , for all $i\\in a^{*}$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mu}_{t,i}+(1+g_{t,\\delta})f_{t,\\delta}\\frac{\\hat{\\mathbf{Z}}_{t,i}^{1/2}}{n_{t,(i,i)}}-\\tilde{\\mu}_{t,i}\\leq g_{t,\\delta}f_{t,\\delta}\\frac{\\hat{\\mathbf{Z}}_{t,i}^{1/2}}{n_{t,(i,i)}}}\\\\ {\\hat{\\mu}_{t,i}-\\tilde{\\mu}_{t,i}\\leq-f_{t,\\delta}\\frac{\\hat{\\mathbf{Z}}_{t,i}^{1/2}}{n_{t,(i,i)}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Therefore, under $\\{\\mathcal{G}_{t}\\cap\\mathcal{H}_{t}\\cap\\mathcal{C}_{t}\\}$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n0\\leq\\Delta_{A_{t+1}}\\leq\\left<A_{t+1},\\tilde{\\mu}_{t}-\\mu\\right>.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "We now develop the expression ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Delta_{A+1}^{2}\\leq\\Big(\\big(A_{t+1},\\hat{\\mu}_{t}-\\mu\\big)\\Big)^{2}}\\\\ &{\\leq2\\Big(\\big(A_{t+1},\\hat{\\mu}_{t}-\\hat{\\mu}_{t}\\big)\\Big)^{2}+2\\Big(\\big(A_{t+1},\\hat{\\mu}_{t}-\\mu\\big)\\Big)^{2}}\\\\ &{\\leq2\\Big(\\displaystyle\\sum_{i\\in A_{t+1}}\\hat{\\mu}_{t,i}-\\hat{\\mu}_{t,i}\\Big)^{2}+2f_{t,0}^{2}\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}}\\\\ &{\\leq2m\\displaystyle\\sum_{i\\in A_{t+1}}\\Big(\\hat{\\mu}_{t,i}-\\hat{\\mu}_{t,i}\\Big)^{2}+2f_{t,0}^{2}\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}}\\\\ &{\\leq2m(1+2g_{t,0})^{2}f_{t,0}^{2}\\displaystyle\\sum_{i\\in A_{t+1}}\\displaystyle\\sum_{n_{t}^{\\prime}(i,i)}\\displaystyle\\sum_{i_{t}^{\\prime}(i,i_{t})}\\,+2f_{t,\\delta}^{2}\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}}\\\\ &{\\leq18m g_{t,0}^{2}f_{t,0}^{2}\\displaystyle\\sum_{i_{t}}^{2}\\Big\\[\\hat{\\mu}_{t,i_{t}}^{\\mathrm{\\tiny{t}}}+2f_{t,0}^{2}\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "As ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i\\in A_{t+1}}\\overline{{\\pi}}_{t,(i,i)}^{t}=2\\sum_{i\\in A_{t+1}}\\frac{\\dot{\\Sigma}_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{d\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}}}&{}\\\\ {\\le2\\displaystyle\\sum_{i\\in A_{t+1}}\\displaystyle\\sum_{n_{t,(i,i)}}\\frac{\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{d\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{2}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\frac{5}{2}h_{t,(i)}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{3}}}&{}\\\\ {+\\displaystyle\\sum_{i\\in A_{t+1}}\\displaystyle\\sum_{n_{t,(i,i)}}^{H_{t,(i)}}\\lVert\\overline{{\\boldsymbol B}}\\|_{\\infty}^{2}/2+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\|B\\|_{\\infty}^{2}/2}{n_{t,(i,i)}^{3}}}&{}\\\\ {=\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{2\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{(d+h_{t,i}^{2}/2)\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}}}&{}\\\\ {+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\dot{\\Sigma}_{i}h_{t,(i)}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\|B\\|_{\\infty}^{2}/2}{n_{t,(i,i)}},}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "and ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\mathbf{N}_{t}^{-1}A_{t+1}\\|_{\\mathbf{Z}_{t}}^{2}=\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{n_{t,(i,j)}\\Sigma_{i,j}}{n_{t,(i,j)}n_{t,(j,j)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{n_{t(i,i)}\\Sigma_{i,i}}{n_{t,(i,i)}^{2}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\|B\\|^{2}}{n_{t,(i,i)}^{2}}}\\\\ &{\\leq\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{n_{t,(i,j)}\\sqrt{\\Sigma_{i,i}}\\sqrt{\\Sigma_{j,j}}}{n_{t,(i,i)}n_{t,(j,j)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{d\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{2}}}\\\\ &{\\leq\\displaystyle\\sum_{(i,j)\\in A_{t+1}}\\frac{n_{t,(i,j)}(\\Sigma_{i,i}+\\Sigma_{j,j})/2}{n_{t,(i,i)}n_{t,(j,j)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{d\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{2}}}\\\\ &{\\leq\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{(m+1)\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{d\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Therefore, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\Delta_{3+1}^{2}\\leq\\displaystyle\\sum_{i\\neq\\bar{i}+1}^{3}\\frac{360\\beta_{i}^{2}H_{3}^{2}H_{4}^{3}}{n_{i}(\\Delta_{i})}+\\sum_{i\\neq\\bar{i}+1}^{5}\\frac{909n\\beta_{i}^{2}H_{2}^{2}(\\Delta_{i}^{2}H_{3}^{2})[H_{3}^{2}]}{n_{i}^{2}(\\Delta_{i})}}\\\\ &{\\phantom{m m m m m m m m m}+\\displaystyle\\sum_{i\\neq\\bar{i}+1}^{6}\\frac{4952\\beta_{i}^{3}H_{3}^{4}H_{2}^{3}}{n_{i}^{3}(\\Delta_{i})}+\\sum_{i\\neq1}^{5}\\frac{909n\\beta_{i}^{2}H_{3}^{2}H_{4}^{3}}{n_{i}(\\Delta_{i})}}\\\\ &{\\phantom{m m m m m m m m m}+\\displaystyle\\sum_{i\\neq1}^{6}\\frac{1092\\beta_{i}^{4}H_{2}^{3}}{n_{i}(\\Delta_{i})}+\\sum_{i\\neq1}^{2}\\frac{24\\beta_{i}^{4}H_{3}^{2}}{n_{i}^{3}(\\Delta_{i})}}\\\\ &{\\phantom{m m m m m m m m m}+\\displaystyle\\sum_{i\\neq1}^{6}\\frac{492\\beta_{i}^{5}\\Delta_{i}^{4}}{n_{i}(\\Delta_{i})}}\\\\ {\\leq\\displaystyle\\sum_{i\\neq\\bar{i}+1}^{5}\\frac{409n\\beta_{i}^{2}H_{3}^{2}(\\Delta_{i}^{2}\\left(\\beta_{i}^{2}\\right))+1}{n_{i}(\\Delta_{i})}+\\sum_{i\\neq\\bar{i}+1}^{7}\\frac{f_{2}\\left|\\beta_{i}\\right|H_{3}^{2}\\left(\\left(2\\eta\\Delta_{i}^{2}H_{3}^{2}\\right)H_{4}^{2}+2i\\right)}{n_{i}^{3}(\\Delta_{i})}}\\\\ &{\\phantom{m m m m m m m m}+\\displaystyle\\sum_{i\\in\\bar{i}+1}^{4}\\frac{492\\beta_{i}^{2}H_{3}^{4}H_{4}^{3}\\left(\\left|\\beta_{i}^{3}\\right|\\right)^{2}}{n_{i}^\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "This finally yields ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\Delta_{A_{t+1}}}{f_{T,\\delta}^{2}g_{T,\\delta}^{2}}\\leq\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{40m\\Sigma_{i,i}}{n_{t,(i,i)}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{29m d h_{t,\\delta}^{2}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{2}}\\qquad}\\\\ {+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{45m h_{t,\\delta}\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{3/2}}+\\displaystyle\\sum_{i\\in A_{t+1}}\\frac{9m\\|B\\|_{\\infty}^{2}}{n_{t,(i,i)}^{3}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "G Experimental results ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "This section outlines some experimental results. ", "page_idx": 39}, {"type": "text", "text": "G.1  Theoretical regret upper bound ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "In this experiment, the objective is to show the effect of the smallest suboptimality gap $\\Delta_{\\mathrm{min}}$ over theoretical gap-dependent regret upper bounds for ESCB-C and OLS-UCB-C. To that end, we sampled 100 environments with different $\\Delta_{\\mathrm{min}}$ , with a constant number of items $d=20$ ahorizon of $T=10^{5}$ rounds, and randomly sampled structures. We represent theoretical upper bounds with respect to $1/\\Delta_{\\mathrm{min}}$ in Fig. 1. ", "page_idx": 39}, {"type": "text", "text": "For readability reasoning, we have rescaled and reweighted the different components of the sums so that the leading term in the upper-bounds $(1/\\Delta_{\\operatorname*{min}})^{\\frac{1}{}}$ Or $1/\\Delta_{\\mathrm{min}}^{2}$ for ESCB-C or OLS-UCB-C) is greater/smaller than the rest, in a significant number of cases. In particular, all the theoretical upper boundshavetheform ", "page_idx": 39}, {"type": "equation", "text": "$$\nR_{T}\\leq\\frac{C}{\\Delta_{\\mathrm{min}}}+\\frac{C^{\\prime}}{\\Delta_{\\mathrm{min}}^{2}}+C_{r}\\mathrm{Rest}\\,,\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where $C,\\,C^{\\prime}$ and $C_{r}$ are the tuned constants. ", "page_idx": 39}, {"type": "text", "text": "For OLS-UCB-C, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Rest}=\\Delta_{\\mathrm{max}}(d(d+1)/2)}\\\\ &{\\qquad\\qquad\\qquad+\\,\\|B\\|_{\\infty}f_{T,\\delta}(4d+h_{t,\\delta}^{2})^{1/2}\\log(m)^{1/2}\\biggl(1+\\log\\Big(\\frac{\\Delta_{\\operatorname*{max}}}{\\Delta_{\\operatorname*{min}}}\\Big)\\biggr)}\\\\ &{\\qquad\\qquad\\qquad+\\,\\|B\\|_{\\infty}^{4/3}f_{T,\\delta}^{4/3}h_{t,\\delta}^{2/3}\\log(m)^{2/3}d^{2}m^{2/3}\\Delta_{\\operatorname*{min}}^{-1/3}}\\\\ &{\\qquad\\qquad\\qquad+\\,\\|B\\|_{\\infty}^{2/3}f_{T,\\delta}^{2/3}\\log(m)^{1/3}d^{2}m^{2/3}\\Delta_{\\operatorname*{max}}^{1/3}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "For ESCB-C, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathrm{Rest}=\\Delta_{\\mathrm{max}}(d(d+1)/2)}\\\\ {\\displaystyle\\qquad\\qquad\\qquad+\\log(T)\\log(m)^{2}\\sum_{i\\in[d]}\\frac{\\operatorname*{max}_{a\\in A/i\\in a}\\bar{\\sigma}_{a,i}^{2}}{\\Delta_{i_{\\mathrm{min}}}}+\\log(T)\\log(m)\\sum_{i,j}\\log\\Big(\\frac{\\Delta_{(i,j),\\operatorname*{max}}}{\\Delta_{(i,j),\\operatorname*{min}}}\\Big)}\\\\ {\\displaystyle\\qquad\\qquad+\\log(T)\\log(m)\\sum_{i}\\log\\Big(\\frac{\\Delta_{i,\\operatorname*{max}}}{\\Delta_{i,\\operatorname*{min}}}\\Big)+\\log(T)\\log(m)\\sum_{i,j}\\Delta_{(i,j),\\operatorname*{min}}^{-1/3}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "When the minimal gap is too small (right part of Fig. 1), both upper-bounds are of the magnitude of either $1/\\Delta_{\\mathrm{min}}^{2}$ $1/\\Delta_{\\mathrm{min}}$ (depending on the algorithm). In this case, the theoretical regret bound of OLS-UCB-C outperforms the one of ESCB-C (green dots vs. blue dots). On the other side, when the gap is big enough, the remaining terms have more impact. In this case, ESCB-C has a better theoretical guarantee (orange dots vs. red dots). ", "page_idx": 39}, {"type": "image", "img_path": "PI0CDY6nmo/tmp/51540ec5c317fae9f0188c35f0f8a87b31c86f124760c44c79f69017e772e587.jpg", "img_caption": ["", "Figure 1: Evolution of regret upper bounds "], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "G.2  Comparison between ESCB-C and OLS-UCB-C ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "We evaluate ESCB-C (approximated as proposed in Perrault et al., 2020b) and OLS-UCB-C on $d=5$ items, $P=10$ actions, $\\dot{T}=10^{5}$ rounds and randomly sampled structures. ", "page_idx": 40}, {"type": "text", "text": "We represent the pseudo-regret evolutions in Fig. 2. The evolutions remain the same until $10^{3}$ rounds. After that, ESCB-C seemingly performs better than OLS-UCB-C which has a supplementary $\\log(t)$ factor and is more conservative. However, just before $10^{5}$ rounds, we can observe a slight regime change for ESCB-C while the pseudo-regret of OLS-UCB-C continues to increase smoothly. The average regret of EsCB-C seems to have an inflexion point upward to meet the $\\mathrm{q}75$ curve. ", "page_idx": 40}, {"type": "image", "img_path": "PI0CDY6nmo/tmp/66cdcd34e4a4764df7438716a9f08de464344351fb79e30b43b74d7694469fb5.jpg", "img_caption": ["Figure 2: Pseudo-regret for ESCB-C and OLS-UCB-C for randomly sampled environments (with $\\mathrm{q}25$ and $\\mathrm{q}75$ confidence intervals). "], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "When observing the final regret with respect to $1/\\Delta_{\\mathrm{min}}$ in Fig. 3, overall ESCB-C seems to outperform OLS-UCB-C except on some corner cases. Those cases skew the distribution for ESCB-C. Especially, for the case with the smallest suboptimality gap (the rightmost part of the figure), OLS-UCB-C outperforms EScB-c. ", "page_idx": 41}, {"type": "image", "img_path": "PI0CDY6nmo/tmp/d59fb95d5161e85a39e166ddfa6e33e64603e721f0054e5a86e3e9e54aabd674.jpg", "img_caption": ["Figure 3: Pseudo-Regret with respect to $1/\\Delta_{\\mathrm{min}}$ "], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "The evolution of the pseudo-regret in this case with the smallest suboptimality gap is presented in Fig. 4. While ESCB-C seems to fare better in the beginning, we actually see a sharp increase in its pseudo-regretbefore $10^{5}$ rounds. It could have been caused by the computational approximation of ESCB-C (described in Perrault et al. (2020b), and/or it could be the impact of the $1\\bar{/}\\bar{\\Delta}_{\\mathrm{min}}^{2}$ term. ", "page_idx": 41}, {"type": "image", "img_path": "PI0CDY6nmo/tmp/69de86ac0f46d7b83a7522f23c954fa442241a1b4dbfd6956bb553195b45b323.jpg", "img_caption": ["Figure 4: Pseudo-Regret in the \u201cworst\" environment. "], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 42}, {"type": "text", "text": "Justification: The main claims of the paper are stated in Theorems and Propositions which for which the technical proofs are in the Appendix. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 42}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Justification: The results and theorems are discussed with comments made especially about some limitations. In particular, computational complexity is addressed. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should refect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 42}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 42}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: The Theorems and proofs are numbered and cross-referenced. The proofs for the main results are outlined in the paper and formally written in the Appendix. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 43}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: The paper is mainly states theoretical results and include no experiments. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPs does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 43}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: The paper does not include experiments requiring code. Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 44}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: The answer NA means that the paper does not include experiments. Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 44}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: The paper does not include experiments ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 44}, {"type": "text", "text": "", "page_idx": 45}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 45}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We have reviewed the NeurIPS Code of Ethics. The paper does not involve human subjects or participants, and the data-related concerns are not applicable. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 45}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 45}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 45}, {"type": "text", "text": "Justification: The paper is mainly theoretical and is not directly tied to an application. Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 45}, {"type": "text", "text": "", "page_idx": 46}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 46}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 46}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 47}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 47}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 47}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 47}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 47}]