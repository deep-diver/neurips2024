[{"figure_path": "Qe2BKeCEBC/figures/figures_1_1.jpg", "caption": "Figure 1: Illustrations of (a) existing cross Mamba, (b) our support recapped Mamba (SRM); and (c) our query intercepted Mamba (QIM). In (a), the support features are firstly scanned and selectively compressed into the hidden state, which is expected to be fused into query FG. Nevertheless, (1) with the scan on query, the compressed support FG is gradually reduced, and (2) query FG is essentially more similar to itself rather than support FG. Thus, the support FG cannot well enhance the query FG features. In (b) and (c), we design (1) a SRM to periodically re-scan the support FG, so the hidden state always contain sufficient support features, and (2) a QIM to intercept the mutual interactions among query pixels, thus, they are forcibly fused with support features.", "description": "This figure illustrates three different approaches to fusing support and query features in few-shot segmentation. (a) shows the existing cross-Mamba method, which suffers from support forgetting and intra-class gap issues. (b) and (c) present the proposed support recapped Mamba (SRM) and query intercepted Mamba (QIM), respectively, which address these issues by periodically re-scanning support features and preventing mutual interactions among query pixels.", "section": "1 Introduction"}, {"figure_path": "Qe2BKeCEBC/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of HMNet. Mamba blocks consist of alternatively appeared self Mamba blocks (SMB) and hybrid Mamba blocks (HMB). Self Mamba aims at capturing the intra-sequence correlations, while hybrid Mamba attempts to capture the support-query intra-sequence dependencies. Hybrid Mamba further includes a support recapped Mamba (SRM) and a query intercepted Mamba (QIM) to address the support forgetting and intra-class gap issues.", "description": "This figure illustrates the architecture of the Hybrid Mamba Network (HMNet). It shows how the query image and support image are processed through a shared backbone. The network utilizes alternating self Mamba blocks (SMB) and hybrid Mamba blocks (HMB) to capture intra- and inter-sequence dependencies. The hybrid Mamba block incorporates support recapped Mamba (SRM) and query intercepted Mamba (QIM) to mitigate the issues of support forgetting and intra-class gap.", "section": "4.2 Hybrid Mamba Network (HMNet)"}, {"figure_path": "Qe2BKeCEBC/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of HMB. (1) Based on different scanning directions [25], SRM arranges support and query features into 4 sequences in the form of alternatively appeared support and query patches, which are sequentially scanned with 4 sets of parameters \u0398. (2) After scanning support features for the first time in SRM, 4 hidden states are averaged into Hs. In QIM, Hs is used to scan query features in parallel. Note that QIM's parameter is shared with the first SRM.", "description": "This figure illustrates the Hybrid Mamba Block (HMB), a key component of the proposed HMNet architecture.  The HMB consists of two main parts: the Support Recapped Mamba (SRM) and the Query Intercepted Mamba (QIM).  The SRM addresses the 'support forgetting' issue by periodically rescanning support features while scanning query features. This ensures that the support information is consistently available during the query processing. The SRM splits query features into patches, downsamples support features, and arranges them alternately. Query features are scanned in parallel (Query Intercepted Mamba, QIM), preventing mutual interaction between query pixels. This forces the query pixels to effectively incorporate support features and mitigates the 'intra-class gap' issue.", "section": "4.2.1 Hybrid Mamba Block (HMB)"}, {"figure_path": "Qe2BKeCEBC/figures/figures_7_1.jpg", "caption": "Figure 4: Qualitative comparisons with HDMNet [31] on PASCAL-5\u00b2 and COCO-20\u00b2.", "description": "This figure shows a qualitative comparison of the proposed HMNet method against the HDMNet baseline on the PASCAL-5i and COCO-20i datasets.  For each dataset, it presents several example images: the support image (providing context for the segmentation), the query image (to be segmented), the segmentation result from HDMNet, and the segmentation result from the proposed HMNet. The visual comparison highlights the superior performance of HMNet in terms of more accurately segmenting foreground objects, especially in complex scenes with clutter.", "section": "5.2 Comparisons with State-of-the-Arts"}, {"figure_path": "Qe2BKeCEBC/figures/figures_8_1.jpg", "caption": "Figure 3: Illustration of HMB. (1) Based on different scanning directions [25], SRM arranges support and query features into 4 sequences in the form of alternatively appeared support and query patches, which are sequentially scanned with 4 sets of parameters \u0398. (2) After scanning support features for the first time in SRM, 4 hidden states are averaged into Hs. In QIM, Hs is used to scan query features in parallel. Note that QIM's parameter is shared with the first SRM.", "description": "This figure illustrates the Hybrid Mamba Block (HMB) which consists of two components: the Support Recapped Mamba (SRM) and the Query Intercepted Mamba (QIM).  SRM addresses the support forgetting issue by periodically rescanning support features during the query scan, ensuring sufficient support information. QIM addresses the intra-class gap issue by preventing interactions between query pixels and forcing them to integrate support features, leading to better support information utilization. The figure visually depicts the process of feature arrangement, sequential scanning within SRM and parallel processing within QIM.", "section": "4.2.1 Hybrid Mamba Block (HMB)"}, {"figure_path": "Qe2BKeCEBC/figures/figures_17_1.jpg", "caption": "Figure 6: Details of (a) self Mamba block (SMB), devised from an attention block, (b) self Mamba, and (c) self selective selective state model (SSM), taken from VMamba [25].", "description": "This figure details the architecture of the Self Mamba Block (SMB) used in the Hybrid Mamba Network (HMNet).  Panel (a) shows the overall structure of the SMB, which is based on an attention block and includes layer normalization (LN), a self-Mamba module, a feedforward network (FFN), and skip connections. Panel (b) illustrates the self-Mamba module itself, showing how it processes input features using layer normalization, a SILU activation function, and depthwise convolutions. Finally, panel (c) breaks down the self-selective state space model (SSM), showing how it processes the input features using separate SSMs for four different scanning directions to capture long-range dependencies.", "section": "4.2.1 Hybrid Mamba Block (HMB)"}, {"figure_path": "Qe2BKeCEBC/figures/figures_17_2.jpg", "caption": "Figure 7: Visualization of QIM module.", "description": "This figure visualizes the impact of the Query Intercepted Mamba (QIM) module. The top part shows a standard Mamba approach where support features (Fs) and query features (Fq) are concatenated and scanned sequentially. The resulting enhanced query features (Fw/o QIM) achieve a cosine similarity of 46.0%. The bottom part illustrates QIM, where the support features are first processed to obtain a hidden state (Hs). This hidden state is then used to process each query feature individually in parallel, preventing interactions between query pixels. This parallel processing leads to enhanced query features (Fw/ QIM) with a higher cosine similarity of 59.0%, demonstrating the effectiveness of QIM in fusing support information.", "section": "D.2 Visualization of Query Intercepted Mamba"}, {"figure_path": "Qe2BKeCEBC/figures/figures_18_1.jpg", "caption": "Figure 4: Qualitative comparisons with HDMNet [31] on PASCAL-5\u00b2 and COCO-20\u00b2.", "description": "This figure presents a qualitative comparison of the proposed HMNet model's performance against the HDMNet model on the PASCAL-5i and COCO-20i datasets.  For each dataset, several example images are shown, with the support image, query image, HDMNet segmentation result, and HMNet segmentation result displayed in separate rows. The visual comparison highlights the superior ability of the proposed HMNet model to correctly segment foreground (FG) objects and distinguish between FG and background (BG) objects compared to the HDMNet model.  The examples reveal that HMNet generally produces more accurate and complete segmentations, especially in challenging scenarios with complex backgrounds or subtle object boundaries.", "section": "5.2 Comparisons with State-of-the-Arts"}, {"figure_path": "Qe2BKeCEBC/figures/figures_18_2.jpg", "caption": "Figure 10: More qualitative results on COCO-20\u00b2. ", "description": "This figure provides more qualitative comparison results between the proposed HMNet and HDMNet on the COCO-20 dataset.  It shows example support and query images alongside the segmentation results of each model. The images illustrate various scenarios and object categories, allowing for visual evaluation of the methods' performance.", "section": "D.3 More Qualitative Results"}, {"figure_path": "Qe2BKeCEBC/figures/figures_19_1.jpg", "caption": "Figure 10: More qualitative results on COCO-20\".", "description": "This figure shows qualitative comparison results of HDMNet and the proposed HMNet on COCO-20 dataset.  For each example, it displays the support images, query images, segmentation masks produced by HDMNet, and segmentation masks from the proposed HMNet. The results visually demonstrate that the proposed HMNet achieves better segmentation results than HDMNet, especially for complex scenes.", "section": "D.3 More Qualitative Results"}]