[{"figure_path": "oPFjhl6DpR/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of sampling steps with primal-based methods (The lower, the better). M denotes one million.", "description": "This table compares the number of sampling steps required by ESPO and two other primal-based safe RL algorithms (CRPO and PCRPO) across three different tasks from the Safety-MuJoCo benchmark.  ESPO demonstrates superior sample efficiency, requiring fewer samples to achieve comparable or better performance.", "section": "5.1 Experiments of Comparison with Primal-Based Methods"}, {"figure_path": "oPFjhl6DpR/tables/tables_7_1.jpg", "caption": "Table 2: Comparison of sampling steps with primal-dual based methods (The lower, the better). M denotes one million samples.", "description": "This table compares the number of samples required by ESPO and three primal-dual safe RL baselines (PCPO, CUP, PPOLag) to achieve a certain level of performance on two tasks from the Omnisafe benchmark (SafetyHopperVelocity-v1 and SafetyAntVelocity-v1).  A lower number indicates better sample efficiency.  The results show that ESPO requires significantly fewer samples than the baselines.", "section": "Experiments of Comparison with Primal-Dual-Based Methods"}, {"figure_path": "oPFjhl6DpR/tables/tables_28_1.jpg", "caption": "Table 3: Update style analysis. The Reward update represents the number of times the algorithm updates its policy primarily focusing on maximizing rewards, the Cost update refers to the number of cost updates where the safety violation happens and the primary focus is on minimizing costs, the Reward & Cost update corresponds to the number of times the optimization of reward and cost updates are executed simultaneously.", "description": "This table presents a comparison of the update styles between ESPO and CRPO algorithms for the SafetyHumanoidStandup-v4 task.  It shows the number of times each algorithm focused solely on reward maximization, solely on cost minimization (due to safety violations), and simultaneously on both reward and cost.  The results highlight the differences in optimization strategies employed by the two algorithms, which is further discussed in the paper.", "section": "Ablation Experiments"}, {"figure_path": "oPFjhl6DpR/tables/tables_30_1.jpg", "caption": "Table 4: Key parameters used in Safety-MuJoCo benchmarks. In ESPO, the sample size of each epoch is determined by Algorithm 1, with Equations (7) and (6), in which the X is 16000.", "description": "This table lists the key hyperparameters used for the experiments conducted on the Safety-MuJoCo benchmark.  It includes parameters such as gamma, regularization strength (l2-reg), damping factor, epoch number, gradient clipping coefficient (grad-c), hidden layer dimensions in the neural network, acceptance ratio, energy weight, and forward reward weight.  It also notes that the sample size in ESPO is determined dynamically by Algorithm 1 using Equations (7) and (6), where the base sample size (X) is set to 16000.", "section": "5.1 Experiments of Comparison with Primal-Based Methods"}, {"figure_path": "oPFjhl6DpR/tables/tables_30_2.jpg", "caption": "Table 5: Sample parameters used in Omnisafe and Safety-MuJoCo experiments. The results of SafetyHopperVelocity-v1 and SafetyAntVelocity-v1 are shown in Figure 3, the results of SafetyHumanoidStandup-v4 and SafetyWalker2d-v4 are shown in Figure 2, the results of SafetyWalker2d-v4-a are shown in Figures 4 (a), (b) and (c), the results of SafetyWalker2d-v4-a and SafetyWalker2d-v4-b are shown in Figures 4 (d), (e) and (f); the results of SafetyReacher-v4 experiments are shown in Figure 2.", "description": "This table lists the sample parameters (\u03b6\u207a, \u03b6\u207b) used in the Omnisafe and Safety-MuJoCo experiments.  These parameters influence the soft constraint region used in the three-mode optimization of the ESPO algorithm. The caption also cross-references the figures in the paper showing the results for each of the tasks listed.", "section": "5.1 Experiments of Comparison with Primal-Based Methods"}, {"figure_path": "oPFjhl6DpR/tables/tables_30_3.jpg", "caption": "Table 6: Cost limit and slack parameters used in Omnisafe and Safety-MuJoCo experiments. The results of SafetyHopperVelocity-v1 and SafetyAntVelocity-v1 are shown in Figure 3, the results of SafetyHumanoidStandup-v4 and SafetyWalker2d-v4 are shown in Figure 2, the results of SafetyWalker2d-v4-a are shown in Figures 4 (a), (b) and (c), the results of SafetyWalker2d-v4-a and SafetyWalker2d-v4-b are shown in Figures 4 (d), (e) and (f); the results of SafetyReacher-v4 experiments are shown in Figure 2.", "description": "This table lists the cost limit (b), positive slack (h+), and negative slack (h-) parameters used in the Safety-MuJoCo and Omnisafe benchmark experiments.  It also cross-references the figures in the paper that display the results for each task.", "section": "Experiments of Comparison with Primal-Based Methods"}, {"figure_path": "oPFjhl6DpR/tables/tables_31_1.jpg", "caption": "Table 7: Key hyparameters used in Omnisafe experiments. In ESPO, the steps of each epoch is determined by Algorithm 1, with Equations (7) and (6), in which the X is 20000. The parameters for the baselines are consistent with those of Omnisafe, and their performance is meticulously fine-tuned in Omnisafe [32].", "description": "This table presents the hyperparameters used for the experiments conducted on the Omnisafe benchmark.  It details the settings for ESPO and three other algorithms (CUP, PCPO, PPOLag).  The table includes device, parallelisation specifics, epoch and step settings, hyperparameters related to the optimization process (target KL, entropy coefficient, gradient normalization, learning rates, etc.), and the method for advantage estimation.  Importantly, it clarifies that ESPO's sample size per epoch is dynamically adjusted using Equations (7) and (6) from Algorithm 1, and that baseline algorithms' settings were consistent with the original Omnisafe benchmark and their performance was finely tuned for optimal results within the context of the benchmark.", "section": "D Detailed Experiments"}]