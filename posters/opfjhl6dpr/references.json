{"references": [{"fullname_first_author": "Joshua Achiam", "paper_title": "Constrained policy optimization", "publication_date": "2017-00-00", "reason": "This paper introduces a foundational constrained optimization method in safe reinforcement learning, which is directly referenced and extended in the target paper's approach."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-00-00", "reason": "As a comprehensive textbook on reinforcement learning, this work provides fundamental concepts and algorithms crucial to understanding the target paper's context and methodology."}, {"fullname_first_author": "Alekh Agarwal", "paper_title": "Optimality and approximation with policy gradient methods in Markov decision processes", "publication_date": "2019-00-00", "reason": "This paper offers theoretical guarantees for policy gradient methods, providing a basis for analyzing the convergence properties of safe reinforcement learning algorithms."}, {"fullname_first_author": "Richard H Byrd", "paper_title": "Sample size selection in optimization methods for machine learning", "publication_date": "2012-00-00", "reason": "This work explores the crucial role of sample size in optimization, which directly inspires the target paper's dynamic sample size adaptation strategy."}, {"fullname_first_author": "Shangding Gu", "paper_title": "Balance reward and safety optimization for safe reinforcement learning: A perspective of gradient manipulation", "publication_date": "2024-00-00", "reason": "This paper, also authored by members of the target paper's research team, provides crucial groundwork and context for the proposed sample manipulation techniques."}]}