{"references": [{"fullname_first_author": "Arjevani", "paper_title": "Lower bounds for non-convex stochastic optimization", "publication_date": "2022-MM-DD", "reason": "This paper provides lower bounds for non-convex stochastic optimization, which are crucial for establishing the optimality of the proposed Fragile SGD and Amelie SGD algorithms."}, {"fullname_first_author": "Bornstein", "paper_title": "SWIFT: Rapid decentralized federated learning via wait-free model communication", "publication_date": "2023-MM-DD", "reason": "This paper introduces a novel decentralized federated learning method called SWIFT, which the current paper improves upon in terms of time complexity."}, {"fullname_first_author": "Even", "paper_title": "Asynchronous SGD on graphs: A unified framework for asynchronous decentralized and federated optimization", "publication_date": "2024-MM-DD", "reason": "This paper provides a unified framework for analyzing asynchronous SGD on graphs, which the current paper builds upon and improves upon by providing tighter complexity bounds."}, {"fullname_first_author": "Ghadimi", "paper_title": "Stochastic first-and zeroth-order methods for nonconvex stochastic programming", "publication_date": "2013-MM-DD", "reason": "This paper establishes the optimal oracle complexity for non-convex stochastic optimization problems, which is fundamental to the analysis of the proposed algorithms' efficiency."}, {"fullname_first_author": "Khaled", "paper_title": "Better theory for SGD in the nonconvex world", "publication_date": "2022-MM-DD", "reason": "This paper offers improved theoretical analysis for SGD in non-convex settings, which is essential for understanding the convergence properties of the algorithms."}]}