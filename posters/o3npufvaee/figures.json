[{"figure_path": "O3nPufVaee/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of basic idea of our approach.", "description": "This figure illustrates the core idea behind the proposed Directional Self-Attention (DSA) mechanism.  Panel (a) shows standard self-attention (SA), where the attention window encompasses all pixels. In contrast, panel (b) depicts the DSA mechanism. Here, the attention window is restricted to a half-plane, preventing the current token from attending to itself, thus creating a \u2018blind spot\u2019  This blind spot is crucial for self-supervised learning, as it prevents the network from trivially learning the identity mapping.  The figure showcases several attention windows to emphasize how the half-plane grid is dynamically applied to each token.", "section": "Main idea of our approach"}, {"figure_path": "O3nPufVaee/figures/figures_5_1.jpg", "caption": "Figure 3: Architecture of the proposed SelfFormer.", "description": "The figure shows the architecture of the proposed SelfFormer, which consists of two sub-networks: SelfFormer-D and SelfFormer-F. SelfFormer-D has four branches, each using directional self-attention (DSA) with a half-plane grid, creating a blind-spot structure. SelfFormer-F uses full-grid self-attention (SA) with a single branch.  Both sub-networks share weights, except for the last 1x1 convolution.  The figure also details the components of each attention block, including channel attention (CA or BSCA), feed-forward networks (FFN), and DSA/grid SA modules.  The overall loss function combines self-reconstruction and mutual learning losses to improve performance.", "section": "3.2 Architecture of SelfFormer"}, {"figure_path": "O3nPufVaee/figures/figures_8_1.jpg", "caption": "Figure 4: Visual inspection of the results of some samples from SIDD-Benchmark and DND.", "description": "This figure shows a visual comparison of denoising results from several methods on samples from SIDD-Benchmark and DND datasets.  The top two rows show results for images with relatively flat regions, while the bottom two rows show results for images with more textured regions.  Each column represents a different denoising method: Laine et al. [23], AP-BSN [27], LG-BPN [28], PUCA [30], and SelfFormer (Ours). The green boxes highlight specific regions for closer examination and comparison of the results.", "section": "4.2 Performance Evaluation on Real-world Denoising"}, {"figure_path": "O3nPufVaee/figures/figures_8_2.jpg", "caption": "Figure A3: More qualitative comparison on samples from SIDD-Benchmark.", "description": "This figure shows a visual comparison of denoising results from different methods on samples from the SIDD-Benchmark dataset.  It specifically highlights the performance on images with richly textured regions, allowing for a detailed comparison of the preservation of fine details and the handling of noise by each algorithm.", "section": "A.2 Additional Results"}, {"figure_path": "O3nPufVaee/figures/figures_16_1.jpg", "caption": "Figure 4: Visual inspection of the results of some samples from SIDD-Benchmark and DND.", "description": "This figure shows a qualitative comparison of denoising results from several methods on samples from the SIDD-Benchmark and DND datasets.  Each row represents a different image, and each column shows the results obtained using a different denoising method, including Laine et al. [23], AP-BSN [27], LG-BPN [28], PUCA [30], and the proposed SelfFormer. The green boxes highlight specific regions of interest where differences between the methods are most apparent.  The figure is intended to show the visual differences and improvement provided by the proposed SelfFormer.", "section": "4.2 Performance Evaluation on Real-world Denoising"}, {"figure_path": "O3nPufVaee/figures/figures_16_2.jpg", "caption": "Figure A3: More qualitative comparison on samples from SIDD-Benchmark.", "description": "This figure provides a visual comparison of the denoising results from several methods on samples from the SIDD-Benchmark dataset.  It shows the noisy input images, the ground truth clean images, and the denoised outputs produced by different methods, including Laine et al., AP-BSN, LG-BPN, PUCA and the proposed SelfFormer. This allows for a direct visual comparison of the performance of each method in handling complex real-world noise.", "section": "A.2 Additional Results"}, {"figure_path": "O3nPufVaee/figures/figures_17_1.jpg", "caption": "Figure 4: Visual inspection of the results of some samples from SIDD-Benchmark and DND.", "description": "This figure shows a visual comparison of denoising results from several methods on samples from the SIDD-Benchmark and DND datasets.  The top row shows denoising results from Laine et al. [23], AP-BSN [27], LG-BPN [28], PUCA [30], and SelfFormer (Ours) on a sample from SIDD-Benchmark. The middle row shows the same comparison on a sample from the DND dataset. The bottom row is another SIDD-Benchmark sample.  Each method's performance is visually assessed by comparing its output to the original, noisy image.", "section": "4.2 Performance Evaluation on Real-world Denoising"}]