[{"figure_path": "DoewNm2uT3/figures/figures_4_1.jpg", "caption": "Figure 1: An instance of RTSP with interval uncertainty. (a) Interval support set. (b) Worst case scenario wc(x) corresponding to route x. (c) Optimal TSP solution under scenario wc(x).", "description": "This figure illustrates an example of the Robust Traveling Salesman Problem (RTSP) with interval uncertainty.  Panel (a) shows the graph with the interval travel times for each edge.  Panel (b) highlights a sample solution (green edges) and its corresponding worst-case scenario (where uncertainty maximizes regret; shown by edge values). Panel (c) shows the optimal TSP solution under the worst-case scenario.", "section": "3.2 Robust TSP"}, {"figure_path": "DoewNm2uT3/figures/figures_4_2.jpg", "caption": "Figure 2: The complete solution framework of our method. Variable a represents the action of selecting the next node according to the probability distribution. The reward r is a sparse variable that takes its max-regret value only in the complete sequence, while being set to zero for all other time steps.", "description": "This figure illustrates the complete solution framework of the proposed neural combinatorial optimization method for solving the robust routing problem.  The framework uses an encoder-decoder structure. The encoder takes the input data (Up_Matrix and Low_Matrix) representing the upper and lower bounds of travel times between nodes and extracts problem features using a MatNet model.  The decoder uses masked multi-head cross-attention and a single attention and scaling mechanism to generate a probability distribution over the next node to visit in the route. A pre-trained TSP model calculates the reward (r) based on the max-regret value of the completed route, which is used to train the policy network. The reward is zero until a complete route is generated, making it a sparse reward.", "section": "4.1 Solution Framework"}, {"figure_path": "DoewNm2uT3/figures/figures_8_1.jpg", "caption": "Figure 3: Performance on varying-scale problems. Gap is relative to the test results of the models trained on the consistent scales.", "description": "This figure shows the generalization ability of the model trained on different sizes of the RTSP problem (N = 20, 30, 40, and 50).  The x-axis represents the size of test instances (N), while the y-axis displays the average optimality gap percentage across 20 instances.  The bars illustrate the performance of models trained on various sizes of training datasets. The results show that models trained on larger datasets achieve better generalization, specifically with the model trained on 50 nodes demonstrating competitive results even when tested on smaller datasets. ", "section": "5.2 Results and Discussions"}, {"figure_path": "DoewNm2uT3/figures/figures_14_1.jpg", "caption": "Figure 1: An instance of RTSP with interval uncertainty. (a) Interval support set. (b) Worst case scenario wc(x) corresponding to route x. (c) Optimal TSP solution under scenario wc(x).", "description": "This figure illustrates an example of the Robust Traveling Salesman Problem (RTSP) with interval uncertainty.  Part (a) shows the graph with edges having travel times defined by intervals. Part (b) shows a specific solution ('1 \u2192 2 \u2192 3 \u2192 4 \u2192 1') and its corresponding worst-case scenario, where the travel times on the selected edges reach their upper bounds, while others are at their lower bounds. Part (c) shows the optimal solution for this worst-case scenario.", "section": "3.2 Robust TSP"}, {"figure_path": "DoewNm2uT3/figures/figures_17_1.jpg", "caption": "Figure 5: Different encoding methods for the uncertainty set. (a) ours. (b) blended. (c) fusion.", "description": "This figure illustrates three different methods for encoding the uncertainty set in the robust routing problem.  Method (a) uses a dual-weighted graph approach where the upper and lower bound matrices are processed separately before being combined.  Method (b) creates a blended matrix by weighting the upper and lower bound matrices before processing.  Method (c) uses a fusion approach where the matrices and attention scores are combined using a multi-layer perceptron (MLP) before being fed into the encoder.", "section": "4.2 Model Architecture"}, {"figure_path": "DoewNm2uT3/figures/figures_18_1.jpg", "caption": "Figure 6: The training loss and score curves for R-50-100 instances. The horizontal axis represents epochs, while the vertical axis represents the values of loss or score (i.e., the objective value). (a) Training loss. (b) Training score.", "description": "This figure shows the training curves of the proposed neural combinatorial optimization model for solving the Robust Traveling Salesman Problem (RTSP) with 50 nodes and interval uncertainty.  The left subplot (a) displays the training loss over 2000 epochs, indicating a decrease in loss as the model learns. The right subplot (b) shows the training score (objective value), also over 2000 epochs, reflecting improvement in solution quality as the training progresses.", "section": "4.3 Training"}, {"figure_path": "DoewNm2uT3/figures/figures_19_1.jpg", "caption": "Figure 5: Different encoding methods for the uncertainty set. (a) ours. (b) blended. (c) fusion.", "description": "This figure illustrates three different methods for encoding the uncertainty set in the robust routing problem.  Method (a) uses two separate matrices (one for upper bounds and one for lower bounds) and then combines their embeddings. Method (b) blends the two matrices into a single matrix before encoding. Method (c) fuses the matrices and attention scores using a multi-layer perceptron before encoding.  These different approaches are compared to determine which is most effective for handling uncertainty in the model.", "section": "4.2 Model Architecture"}]