[{"figure_path": "yDjojeIWO9/tables/tables_6_1.jpg", "caption": "Table 1: Comparison results of transfer-based adversarial attacks on different models. The surrogate model is the open-sourced SAM.", "description": "This table compares the performance of different transfer-based adversarial attacks on various downstream models fine-tuned from the Segment Anything Model (SAM).  The attacks leverage only information from the open-sourced SAM, without access to the downstream task datasets.  Metrics such as mDSC, mHD, BER, Sa, and MAE are used to evaluate the effectiveness of each attack on different models and datasets (Medical SAM, Shadow-SAM, Camouflaged-SAM). The table showcases the significant impact of the proposed UMI-GRAT attack in comparison to existing methods.", "section": "6 Experimental Results"}, {"figure_path": "yDjojeIWO9/tables/tables_7_1.jpg", "caption": "Table 1: Comparison results of transfer-based adversarial attacks on different models. The surrogate model is the open-sourced SAM.", "description": "This table presents a comparison of different transfer-based adversarial attacks on various downstream models fine-tuned from the Segment Anything Model (SAM).  The attacks utilize only information from the open-sourced SAM, without access to downstream task datasets.  The table shows the performance of several attacks (MI-FGSM, DMI-FGSM, PGN, BSR, ILPD, and the proposed UMI-GRAT) across three different downstream tasks and datasets: medical image segmentation, shadow segmentation, and camouflaged object segmentation.  Metrics include mean Dice Similarity Coefficient (mDSC), mean Hausdorff Distance (mHD), Bit Error Rate (BER), and Structural Similarity (Sa) along with Mean Absolute Error (MAE). The results show the effectiveness of the proposed UMI-GRAT attack in misleading the downstream models compared to existing transfer-based attacks.", "section": "6 Experimental Results"}, {"figure_path": "yDjojeIWO9/tables/tables_9_1.jpg", "caption": "Table 1: Comparison results of transfer-based adversarial attacks on different models. The surrogate model is the open-sourced SAM.", "description": "This table presents a comparison of different transfer-based adversarial attack methods on various downstream models fine-tuned from the Segment Anything Model (SAM).  The attacks use the open-sourced SAM as a surrogate model, meaning they don't have access to the specific training data or task of the downstream models. The table shows the effectiveness of different attack methods (MI-FGSM, DMI-FGSM, PGN, BSR, ILPD, and the proposed UMI-GRAT, and combinations thereof) on three types of downstream models: Medical SAM, Shadow-SAM, and Camouflaged-SAM. Metrics used for evaluation include mean Dice Similarity Coefficient (mDSC), mean Hausdorff Distance (mHD), Bit Error Rate (BER), Structural Similarity (Sa), and Mean Absolute Error (MAE), depending on the task of the downstream model. The results highlight the transferability and effectiveness of the proposed UMI-GRAT attack method in misleading these models.", "section": "6 Experimental Results"}, {"figure_path": "yDjojeIWO9/tables/tables_14_1.jpg", "caption": "Table 1: Comparison results of transfer-based adversarial attacks on different models. The surrogate model is the open-sourced SAM.", "description": "This table presents a comparison of different transfer-based adversarial attack methods on various downstream models fine-tuned from the Segment Anything Model (SAM).  The attacks are evaluated using metrics relevant to each model's task (mDSC, mHD for medical segmentation; Sa, MAE for camouflaged object segmentation; BER for shadow segmentation). The key point is that all attacks use the open-sourced SAM as a surrogate model, simulating a real-world scenario where an attacker does not have access to the downstream model or dataset.", "section": "6 Experimental Results"}, {"figure_path": "yDjojeIWO9/tables/tables_14_2.jpg", "caption": "Table 1: Comparison results of transfer-based adversarial attacks on different models. The surrogate model is the open-sourced SAM.", "description": "This table presents a comparison of different transfer-based adversarial attack methods on three downstream models (Medical SAM, Shadow-SAM, and Camouflaged-SAM) fine-tuned from the Segment Anything Model (SAM).  The attacks are evaluated using various metrics depending on the downstream task (mDSC and mHD for medical segmentation, Sa and MAE for camouflaged object segmentation, and BER for shadow segmentation). The table shows the effectiveness of each attack method, with the proposed MUI-GRAT consistently outperforming other methods across all three downstream models. The results highlight the transferability and effectiveness of the proposed MUI-GRAT.", "section": "6 Experimental Results"}, {"figure_path": "yDjojeIWO9/tables/tables_15_1.jpg", "caption": "Table 1: Comparison results of transfer-based adversarial attacks on different models. The surrogate model is the open-sourced SAM.", "description": "This table compares the performance of different transfer-based adversarial attack methods on various downstream models fine-tuned from the Segment Anything Model (SAM).  The attacks are evaluated using metrics relevant to each downstream task (e.g., mDSC and mHD for medical image segmentation, Sa and MAE for camouflaged object segmentation). The \"Without attacks\" row provides the baseline performance of each model. The results show that the proposed method (MUI-GRAT) consistently achieves better performance than other methods across various downstream tasks and datasets.", "section": "6 Experimental Results"}]