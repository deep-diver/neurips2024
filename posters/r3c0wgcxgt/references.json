{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces a foundational vision-language model that significantly advanced the field and is frequently used as a base for other models."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the core denoising diffusion probabilistic models (DDPMs) which form the foundation of many modern image generation models."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-20", "reason": "This paper extends DDPMs to generate higher resolution images, which is a key improvement over previous models."}, {"fullname_first_author": "Chitwan Saharia", "paper_title": "Photorealistic text-to-image diffusion models with deep language understanding", "publication_date": "2022-12-01", "reason": "This paper significantly improved the quality of text-to-image generation using diffusion models."}, {"fullname_first_author": "Lvmin Zhang", "paper_title": "Adding conditional control to text-to-image diffusion models", "publication_date": "2023-10-26", "reason": "This paper introduces ControlNet, a framework that is widely used for controlling the generation process of diffusion models, which is essential for high-quality text generation."}]}