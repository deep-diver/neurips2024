{"references": [{"fullname_first_author": "Edward J. Hu", "paper_title": "Lora: Low-rank adaptation of large language models", "publication_date": "2022-04-01", "reason": "This paper introduces the Low-Rank Adaptation (LoRA) technique, a crucial method that SNELL builds upon to achieve its parameter efficiency."}, {"fullname_first_author": "Menglin Jia", "paper_title": "Visual prompt tuning", "publication_date": "2022-00-00", "reason": "This paper introduces the concept of visual prompt tuning, a related parameter-efficient fine-tuning method that SNELL improves upon with its novel approach."}, {"fullname_first_author": "Haoyu He", "paper_title": "Sensitivity-aware visual parameter-efficient fine-tuning", "publication_date": "2023-00-00", "reason": "This paper introduces the concept of sensitivity-aware visual parameter-efficient fine-tuning, improving upon previous methods and directly influencing SNELL's design."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-00-00", "reason": "This paper introduces the Masked Autoencoders (MAE) technique, which is used as a pre-training method for the vision transformers in SNELL's experiments, directly impacting the performance results."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-05-01", "reason": "This paper introduces Vision Transformers (ViT), a key backbone architecture used in SNELL's experiments; its introduction is fundamental to the context and comparison of results."}]}