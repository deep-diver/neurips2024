[{"figure_path": "65UoJ0z7Kp/tables/tables_4_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free results of the proposed SeTAR model and compares its performance with zero-shot baselines (Vanilla MCM and Vanilla GL-MCM) on two benchmark datasets (ImageNet1K and Pascal VOC).  The results are evaluated using two metrics: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic Curve (AUROC). Lower FPR95 and higher AUROC values indicate better performance.  The table highlights SeTAR's superior performance, achieving lower FPR95 and higher AUROC compared to the baselines across various OOD datasets, demonstrating the effectiveness of the proposed method for training-free OOD detection.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_5_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free results of the proposed SeTAR method and compares its performance with existing zero-shot baselines (Vanilla MCM and Vanilla GL-MCM) on two benchmark datasets (ImageNet1k and Pascal VOC).  The metrics used are FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve). Lower FPR95 and higher AUROC indicate better performance. The results are shown separately for MCM and GL-MCM scoring functions and for various OOD datasets.  The table highlights SeTAR's superior performance in reducing the false positive rate compared to the baselines, indicating its effectiveness in identifying out-of-distribution samples without the need for training.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_6_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u22c4 represents the absence of reporting in the paper. * denotes the result of our re-run. \u2212 denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of SeTAR and baselines on various OOD detection tasks using the CLIP-base model.  It compares the False Positive Rate at 95% True Positive Rate (FPR95) and the Area Under the Receiver Operating Characteristic curve (AUROC) across different OOD datasets. The results demonstrate SeTAR's improved performance compared to existing zero-shot methods.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_6_2.jpg", "caption": "Table 3: Ablation study on modality. ", "description": "This table presents the results of an ablation study conducted to evaluate the impact of different modalities (vision, text, and vision+text) on the performance of the SeTAR model for out-of-distribution (OOD) detection.  The study uses two benchmark datasets, ImageNet1K and Pascal-VOC, and two scoring functions (MCM and GL-MCM) to measure performance using FPR and AUROC metrics.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/tables/tables_6_3.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of SeTAR and compares it against existing zero-shot baselines (Vanilla MCM, Vanilla GL-MCM) on the ImageNet1k and Pascal-VOC datasets.  The results are shown in terms of False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the ROC Curve (AUROC). The table highlights SeTAR's superior performance in reducing the false positive rate compared to the baselines without requiring any training.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_7_1.jpg", "caption": "Table 5: Results for different search algorithms. Here LES, MIS and SeTAR-S stand for layer-exhaustive search, modality-interleave greedy search, and the search algorithm of SeTAR.", "description": "This table compares three different search algorithms used in the SeTAR model for OOD detection.  The algorithms differ in how they traverse the layers of the image and text encoders in CLIP: LES (Layer-Exhaustive Search) checks all layers exhaustively, MIS (Modality-Interleaved Search) alternates between image and text layers, and SeTAR-S (the SeTAR search algorithm) searches the layers sequentially from top to bottom, image then text.  The table shows the FPR (False Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve) for each algorithm on ImageNet1k and Pascal-VOC datasets using both MCM and GL-MCM scores. SeTAR-S achieves the best overall performance.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/tables/tables_7_2.jpg", "caption": "Table 6: Results for different pruning strategies. We use CLIP-B/16 as a backbone.", "description": "This table presents a comparison of SeTAR's performance against two alternative pruning strategies: principal component pruning and random pruning.  It shows the False Positive Rate (FPR) at 95% True Positive Rate (TPR) and the Area Under the Receiver Operating Characteristic Curve (AUROC) for both the MCM and GL-MCM scoring functions, on ImageNet1K and Pascal-VOC datasets. The results demonstrate that SeTAR's strategy of selectively pruning minor singular components significantly outperforms both principal component pruning and random pruning.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/tables/tables_8_1.jpg", "caption": "Table 7: Image classification results with different methods. We use ImageNet1K (IN1K) as ID dataset. * denotes the results of our re-run. The results are averaged over 3 runs.", "description": "This table presents the image classification results obtained using different methods.  The ImageNet1K dataset is used as the in-distribution (ID) dataset. The results from running the Vanilla CLIP model, as well as the LoCoOp and LoRA finetuning-based approaches are compared against the proposed SeTAR and SeTAR+FT methods.  The average accuracy across multiple OOD datasets (SUN, Places, and Texture) is reported for each method.  The results show that SeTAR+FT outperforms all baseline models. The '*' indicates that the results are from re-running the experiments.", "section": "4.5 Analyses"}, {"figure_path": "65UoJ0z7Kp/tables/tables_8_2.jpg", "caption": "Table 8: Results for different ViT backbones.", "description": "This table presents the training-free results of False Positive Rate at 95% true positive rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC) for out-of-distribution (OOD) detection on ImageNet1K and Pascal-VOC datasets using different Vision Transformer (ViT) backbones (CLIP-base, CLIP-large, and Swin-base) and various scoring functions (NegLabel, MCM, GL-MCM, MSP, and Energy).  It compares the performance of the vanilla methods (without SeTAR) to the SeTAR method. Lower FPR95 and higher AUROC values indicate better performance.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/tables/tables_8_3.jpg", "caption": "Table 10: Near-OOD results on CLIP-base.", "description": "This table presents the results of near-out-of-distribution (near-OOD) detection experiments using the CLIP-base model.  It compares the performance of SeTAR and SeTAR+FT against several baseline methods on the task of identifying near-OOD samples, specifically using ImageNet1K as the in-distribution (ID) dataset and SSB-Hard as the near-OOD dataset.  The metrics used are False Positive Rate (FPR) at a True Positive Rate (TPR) of 95% and Area Under the Receiver Operating Characteristic curve (AUROC).  Lower FPR and higher AUROC values indicate better performance.", "section": "4. Experiments"}, {"figure_path": "65UoJ0z7Kp/tables/tables_8_4.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents a comparison of the training-free out-of-distribution (OOD) detection performance of SeTAR against existing zero-shot baselines (Vanilla MCM, Vanilla GL-MCM) on two benchmark datasets (ImageNet1K and Pascal VOC).  The results are evaluated using two metrics: False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC).  Lower FPR95 and higher AUROC indicate better performance. The table highlights SeTAR's superior performance in reducing the false positive rate compared to the baselines, demonstrating its effectiveness as a training-free OOD detection method.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_15_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR model and compares it against several zero-shot baselines (Vanilla MCM, Vanilla GL-MCM) on two common OOD detection benchmarks (ImageNet1K and Pascal-VOC).  The results are shown in terms of FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve).  Lower FPR95 and higher AUROC values are better. The table highlights the superior performance of SeTAR in reducing the false positive rate, particularly on the GL-MCM scoring metric, indicating its effectiveness in improving OOD detection without requiring any training.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_16_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR model and compares it with several zero-shot baselines on two benchmark datasets, ImageNet1K and Pascal-VOC. The results are evaluated using two metrics: FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic Curve). Lower FPR95 and higher AUROC values indicate better performance. The table shows that SeTAR consistently outperforms the baseline methods across various OOD datasets.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_16_2.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free results of the proposed SeTAR method for out-of-distribution (OOD) detection.  It compares SeTAR's performance (measured by FPR95 and AUROC) against two zero-shot baselines (Vanilla MCM and Vanilla GL-MCM) on six different OOD datasets using the CLIP-base model.  The table shows that SeTAR significantly outperforms the baselines, particularly in reducing the false positive rate (FPR95). The asterisk (*) indicates results obtained by rerunning the baselines, and the symbol \u25c7 denotes the absence of results reported in the cited paper. Note that standard deviations aren't reported because the methods are training-free.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_17_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents a comparison of the training-free performance of different OOD detection methods on two benchmark datasets (ImageNet1K and Pascal VOC). It compares the proposed SeTAR method against several zero-shot baselines (Vanilla MCM, Vanilla GL-MCM) across six OOD datasets.  The results are shown in terms of FPR95 (false positive rate at 95% true positive rate) and AUROC (area under the receiver operating characteristic curve).  The table highlights SeTAR's superior performance in reducing false positives compared to existing methods. Note that standard deviations are not reported due to the training-free nature of the methods.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_18_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents a comparison of the training-free performance of SeTAR against existing zero-shot baselines for out-of-distribution (OOD) detection using the CLIP model.  The table shows the False Positive Rate at 95% True Positive Rate (FPR95) and the Area Under the Receiver Operating Characteristic curve (AUROC) for several OOD datasets and two different scoring functions (MCM and GL-MCM).  The results demonstrate SeTAR's superior performance in reducing false positives compared to the baseline methods.  The absence of standard deviation is due to the training-free nature of the method.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_18_2.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents a comparison of the training-free performance of SeTAR against existing zero-shot baselines (Vanilla MCM and Vanilla GL-MCM) on two common OOD detection benchmarks using the CLIP-ViT-B/16 model.  The results are shown for both MCM and GL-MCM scoring functions and across various OOD datasets (iNaturalist, SUN, Places, Texture, ImageNet22K, and COCO).  The metrics used are FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve). Bold values indicate the best performance for each metric and dataset.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_19_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of SeTAR and several zero-shot baselines on two benchmark datasets (ImageNet1K and Pascal-VOC). The table compares the False Positive Rate at 95% True Positive Rate (FPR95) and the Area Under the Receiver Operating Characteristic curve (AUROC) for various Out-of-Distribution (OOD) datasets against different methods.  Lower FPR95 and higher AUROC values indicate better performance.  The results demonstrate SeTAR's superior performance compared to the zero-shot baselines, particularly in reducing the false positive rate.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_19_2.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR method and compares it to several zero-shot baselines on two benchmark datasets (ImageNet1K and Pascal-VOC).  The metrics used are False Positive Rate at 95% True Positive Rate (FPR95) and Area Under the Receiver Operating Characteristic curve (AUROC).  Lower FPR95 values and higher AUROC values indicate better performance. The table shows that SeTAR consistently outperforms the zero-shot baselines across various OOD datasets for both MCM and GL-MCM scoring functions. The asterisk (*) indicates re-run results and the dagger (\u2020) indicates results cited from Miyai et al (2023b).", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_20_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of SeTAR and compares it against several zero-shot baselines on the CLIP-base model for out-of-distribution (OOD) detection.  The results are shown for various metrics (FPR95 and AUROC) and across different OOD datasets (iNaturalist, SUN, Places, Texture, ImageNet22K, COCO). The table highlights SeTAR's superior performance in reducing the false positive rate and improving the overall accuracy compared to existing zero-shot methods.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_20_2.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR model on out-of-distribution (OOD) detection tasks, compared to existing zero-shot baselines. The results are shown for different OOD datasets (iNaturalist, SUN, Places, Texture, ImageNet22K, COCO) and using two metrics: FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve). Lower FPR95 and higher AUROC values indicate better performance.  The table highlights that SeTAR consistently achieves superior results, reducing the false positive rate significantly compared to existing methods. The absence of standard deviation is due to the method being training free.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_20_3.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of SeTAR and several baseline methods on the ImageNet1K and Pascal-VOC datasets.  The metrics used are FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic curve). Lower FPR95 values and higher AUROC values indicate better performance.  The table compares SeTAR's performance to two zero-shot baselines (MCM and GL-MCM) and their variations with and without the use of a star (*) denoting re-run results to ensure consistency.   The results are categorized by the OOD datasets used for evaluation and the scoring function used (MCM or GL-MCM), providing a comprehensive view of SeTAR's effectiveness across different tasks and scenarios. The symbol \u25c7 indicates when results were not available in the original paper. The absence of standard deviations is explicitly noted because the methods used are training-free.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_21_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR model compared to existing zero-shot baselines (MCM and GL-MCM) on two benchmark datasets (ImageNet1K and Pascal-VOC).  The results are reported in terms of FPR95 (false positive rate at 95% true positive rate) and AUROC (area under the receiver operating characteristic curve), which are common metrics for evaluating the performance of OOD detection methods. The table highlights the improvement achieved by SeTAR over the baselines, showcasing its effectiveness in reducing false positives without the need for any training.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_21_2.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR model and several zero-shot baselines on the ImageNet1K and Pascal-VOC datasets. The metrics used are FPR95 (False Positive Rate at 95% True Positive Rate) and AUROC (Area Under the Receiver Operating Characteristic Curve).  Lower FPR95 and higher AUROC values indicate better performance. The table compares SeTAR's performance to vanilla MCM and GL-MCM methods, showing improvements in both metrics.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_21_3.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR method on the ImageNet1K and Pascal-VOC datasets for OOD detection. It compares SeTAR's performance against several zero-shot baselines (Vanilla MCM, Vanilla GL-MCM) using different scoring functions (MCM and GL-MCM). The table shows the False Positive Rate at 95% True Positive Rate (FPR95) and the Area Under the Receiver Operating Characteristic curve (AUROC) for various OOD datasets (iNaturalist, SUN, Places, Texture, ImageNet22K, COCO). Bold values indicate the best performance achieved by SeTAR.", "section": "4.2 Training-free Results"}, {"figure_path": "65UoJ0z7Kp/tables/tables_25_1.jpg", "caption": "Table 1: Training-free results of FPR95(FPR) and AUROC(AUC) compared to zero-shot baselines on CLIP-base. Bold values represent the highest performance. \u2020 is cited from Miyai et al. (2023b), where \u25c7 represents the absence of reporting in the paper. * denotes the result of our re-run. denotes the OOD dataset has overlapping categories with the ID dataset. We do not report standard deviations since no training is involved.", "description": "This table presents the training-free performance of the proposed SeTAR model and several zero-shot baselines on CLIP-based OOD detection tasks.  The results are compared using two metrics: FPR95 (false positive rate at 95% true positive rate) and AUROC (area under the receiver operating characteristic curve). Lower FPR95 and higher AUROC values indicate better performance. The table shows that SeTAR outperforms the zero-shot baselines on both ImageNet1K and Pascal-VOC datasets across multiple OOD datasets. Results are shown without standard deviation because no training is involved.", "section": "4.2 Training-free Results"}]