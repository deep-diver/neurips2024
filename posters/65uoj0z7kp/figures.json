[{"figure_path": "65UoJ0z7Kp/figures/figures_2_1.jpg", "caption": "Figure 1: The overview of SeTAR. (a) The structure of the CLIP image and text encoder. (b) The details of the feed-forward sublayer. (c) For each encoder layer, we replace the Wup weight matrix with its low-rank approximation Wup. (d) The illustration of \u03a3 before and after low-rank approximation.", "description": "This figure provides a visual overview of the SeTAR method. It shows the architecture of the CLIP image and text encoder, highlighting the feed-forward sublayer where the low-rank approximation is applied.  Panel (c) illustrates the singular value decomposition (SVD) and how selective low-rank approximation modifies the weight matrix Wup. Finally, (d) visually demonstrates the effect of the low-rank approximation on the singular value matrix \u03a3.", "section": "3 Method"}, {"figure_path": "65UoJ0z7Kp/figures/figures_22_1.jpg", "caption": "Figure 2: Average AUROC/FPR95 of different weight types on ImageNet1K benchmark. We use CLIP-B/16 as a backbone.", "description": "This figure shows the performance comparison of SeTAR when using different weight matrices (Wup, Wdown, Wq, Wk, Wv, Wout) in the CLIP model for out-of-distribution (OOD) detection on the ImageNet1K benchmark.  The x-axis represents the number of encoder layers visited during the greedy search algorithm used by SeTAR.  The y-axis shows the average AUROC (Area Under the Receiver Operating Characteristic curve) and average FPR95 (False Positive Rate at 95% True Positive Rate) across multiple OOD datasets.  A higher AUROC indicates better performance, while a lower FPR95 also indicates better performance. The figure helps to determine which weight matrices are most effective for improving OOD detection performance using SeTAR, indicating the effectiveness of targeting the \u2018Wup\u2019 matrix.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/figures/figures_22_2.jpg", "caption": "Figure 2: Average AUROC/FPR95 of different weight types on ImageNet1K benchmark. We use CLIP-B/16 as a backbone.", "description": "This figure shows the ablation study on different weight matrices in CLIP\u2019s image and text encoders. It compares the performance of SeTAR when using different weight matrices (Wup, Wdown, Wq, Wk, Wv, and Wout) for low-rank approximation against a baseline without any modification. The results are presented in terms of average AUROC and average FPR95, indicating SeTAR\u2019s performance using different weight matrices on the ImageNet1K benchmark. CLIP-B/16 is used as the backbone model.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/figures/figures_22_3.jpg", "caption": "Figure 2: Average AUROC/FPR95 of different weight types on ImageNet1K benchmark. We use CLIP-B/16 as a backbone.", "description": "This figure shows the results of an ablation study comparing the performance of SeTAR when different weight matrices (Wup, Wdown, Wq, Wk, Wv, Wo, and Wout) are modified using low-rank approximation.  The x-axis represents the number of layers visited by the greedy search algorithm used in SeTAR, and the y-axis shows the average AUROC and FPR95 across different OOD datasets.  The figure helps to illustrate which weight matrix is most effective for improving OOD detection performance when using SeTAR.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/figures/figures_23_1.jpg", "caption": "Figure 4: Ablation studies on \u03bb on different ID datasets. We use CLIP-B/16 as a backbone.", "description": "This figure presents the ablation study on the hyperparameter \u03bb (lambda) across different datasets.  The top two panels show the average AUROC (Area Under the Receiver Operating Characteristic curve) and average FPR95 (False Positive Rate at 95% True Positive Rate) on ImageNet1K, while the bottom two panels show the same metrics for Pascal VOC.  The x-axis represents the value of \u03bb, and the y-axis represents the AUROC and FPR95, respectively. Each line represents the performance with different combinations of SeTAR+MCM (SeTAR with the Maximum Class Mean scoring function) and SeTAR+GL-MCM (SeTAR with the Generalized Maximum Class Mean scoring function). The purpose of this ablation is to determine the optimal value of \u03bb for various datasets and scoring functions by analyzing the trade-off between AUROC and FPR95.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/figures/figures_23_2.jpg", "caption": "Figure 5: Ablation studies on top-K on different ID datasets. We use CLIP-B/16 as a backbone.", "description": "This figure presents the results of ablation studies conducted to evaluate the impact of the hyperparameter top-K on the performance of the SeTAR model across different in-distribution (ID) datasets (ImageNet1K and Pascal VOC).  The plots show the average AUROC (Area Under the Receiver Operating Characteristic Curve) and average FPR95 (False Positive Rate at 95% True Positive Rate) for various values of top-K using both MCM and GL-MCM scoring functions. The x-axis represents the value of top-K, and the y-axis represents the performance metrics (AUROC and FPR95). The goal of this analysis is to determine the optimal top-K value that balances model performance and robustness.", "section": "4.4 Ablation Study"}, {"figure_path": "65UoJ0z7Kp/figures/figures_24_1.jpg", "caption": "Figure 6: Loss plots of SeTAR+FT v.s. LoRA on ImageNet1K. We use CLIP-B/16 as a backbone. SeTAR+FT demonstrates faster convergence across all losses, especially in the OOD loss. For reference, with MCM score, SeTAR+FT achieves an average FPR of 38.77 at epoch 5. While LORA achieves an average FPR of 42.88, 39.92 and 42.23 at epoch 1, 5 and 15, respectively.", "description": "This figure compares the training loss curves of SeTAR+FT and LoRA on the ImageNet1K dataset using the CLIP-B/16 backbone.  Three loss curves are shown: the total loss (LoCoOp Loss), the in-distribution (ID) loss, and the out-of-distribution (OOD) loss.  SeTAR+FT demonstrates faster convergence than LoRA, achieving lower losses in fewer epochs, especially for the OOD loss.  This indicates that SeTAR+FT is more efficient in adapting the pre-trained model for OOD detection than LoRA.  The FPR (False Positive Rate) at epoch 5 for SeTAR+FT is also provided as a point of reference, showing its superior performance over LORA's results at epochs 1, 5, and 15.", "section": "3.2 OOD Detection with SeTAR-enhanced Low-rank Adaptation"}, {"figure_path": "65UoJ0z7Kp/figures/figures_24_2.jpg", "caption": "Figure 7: Visualization of SeTAR rank reduction ratio distribution on different ID datasets with different backbones. IN1K, VOC stand for ImageNet1K and Pascal-VOC. And V, T stand for visual modality and text modality of the CLIP model.", "description": "This figure visualizes the rank reduction ratios obtained by SeTAR for different layers in the CLIP image and text encoders, using ImageNet1K and Pascal VOC as the ID datasets.  Different backbones (CLIP-base, CLIP-large, and Swin-base) are shown. The heatmap shows that SeTAR adaptively adjusts the rank reduction ratio depending on the layer and backbone architecture, highlighting the method's adaptability and efficiency.  The visual and text modalities are represented as 'V' and 'T', respectively.", "section": "4.4 Ablation Study"}]