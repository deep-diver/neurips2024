[{"figure_path": "Y5DPSJzpra/tables/tables_5_1.jpg", "caption": "Table 1: Optimizing for orthogonality appropriately allows low-dimensional projectors to match the performance (on CIFAR-10) of much higher-dimensional projectors.", "description": "This table presents the results of experiments comparing the performance of Barlow Twins and VICReg models with different projector dimensionalities (pdim).  It shows that using a properly tuned orthogonality constraint (beta), low-dimensional projectors can achieve similar performance to much larger, higher-dimensional ones, indicating that high-dimensionality is not always necessary for good representation learning with these methods.", "section": "4.1 Low-dimensional projectors can yield good representations"}, {"figure_path": "Y5DPSJzpra/tables/tables_7_1.jpg", "caption": "Table 2: Using multiple augmentations yields faster convergence, with reduced time to reach baseline performance on CIFAR-10, i.e. performance of feature encoder pretrained with an 8192-dim projector and 2 augmentations.", "description": "This table shows the time taken (in minutes) for BarlowTwins and VICReg to reach baseline performance on CIFAR-10. The baseline performance is defined as the performance achieved using an 8192-dimensional projector and only two augmentations.  The table compares the time taken to reach this baseline performance under different conditions: using 2 augmentations with an 8192-dimensional projector, 2 augmentations with a 256-dimensional projector, 4 augmentations with a 256-dimensional projector, and 4 augmentations with a 256-dimensional projector. The results highlight that increasing the number of augmentations reduces the training time required to achieve baseline performance.", "section": "4.2 Multiple Augmentations Improve Performance and Convergence"}, {"figure_path": "Y5DPSJzpra/tables/tables_7_2.jpg", "caption": "Table 3: Time required to pass 80% accuracy on CIFAR-10 when pretraining on fraction of the dataset, while using multiple augmentations. See Figure 5 for further discussion.", "description": "This table shows the time it takes to reach 80% accuracy on the CIFAR-10 dataset using different numbers of augmentations and different fractions of the dataset for pretraining. It highlights the time efficiency gains achievable by using more augmentations even with smaller datasets.", "section": "4.3 Sample Efficient Multi-augmentation Learning"}, {"figure_path": "Y5DPSJzpra/tables/tables_25_1.jpg", "caption": "Table 1: Optimizing for orthogonality appropriately allows low-dimensional projectors to match the performance (on CIFAR-10) of much higher-dimensional projectors.", "description": "This table presents the results of an experiment comparing the performance of Barlow Twins and VICReg models with different projector dimensions.  It shows that using a stronger orthogonality constraint with lower-dimensional projectors can achieve similar or better accuracy compared to models with higher-dimensional projectors.  This supports the paper's claim that low-dimensional projectors can be efficient for self-supervised learning.", "section": "4.1 Low-dimensional projectors can yield good representations"}, {"figure_path": "Y5DPSJzpra/tables/tables_30_1.jpg", "caption": "Table 1: Optimizing for orthogonality appropriately allows low-dimensional projectors to match the performance (on CIFAR-10) of much higher-dimensional projectors.", "description": "This table presents the results of experiments comparing the performance of BarlowTwins and VICReg with different projector dimensionalities (pdim) on the CIFAR-10 dataset.  It demonstrates that using a stronger orthogonality constraint (optimal beta) allows for achieving similar performance with low-dimensional projectors (e.g., 64) as with much higher-dimensional projectors (e.g., 8192), thereby reducing the computational cost without significant performance loss. The table highlights the importance of optimizing the orthogonality constraint for different projector sizes to achieve optimal performance.", "section": "4.1 Low-dimensional projectors can yield good representations"}, {"figure_path": "Y5DPSJzpra/tables/tables_31_1.jpg", "caption": "Table 1: Optimizing for orthogonality appropriately allows low-dimensional projectors to match the performance (on CIFAR-10) of much higher-dimensional projectors.", "description": "This table shows that using the proposed method with a strong orthogonalization constraint, even low-dimensional projectors can achieve similar performance as high-dimensional projectors on the CIFAR-10 dataset.  It compares the performance of Barlow Twins and VICReg with different projector dimensions (64, 256, 1024, 8192) using both a fixed beta and an optimized beta. The optimized beta is chosen specifically for each dimension to maximize performance, showing that the proposed approach can achieve high performance even with fewer parameters. ", "section": "4.1 Low-dimensional projectors can yield good representations"}]