{"references": [{"fullname_first_author": "Ajay, A.", "paper_title": "Opal: Offline primitive discovery for accelerating offline reinforcement learning", "publication_date": "2020-10-13", "reason": "This paper introduces a novel approach to accelerate offline reinforcement learning by discovering and reusing temporal abstractions, a key concept in the target paper."}, {"fullname_first_author": "Araujo, E. G.", "paper_title": "Learning control composition in a complex environment", "publication_date": "1996-01-01", "reason": "This paper is foundational for hierarchical reinforcement learning, a central theme in the target paper, demonstrating how learning can be decomposed into simpler subtasks."}, {"fullname_first_author": "Bacon, P.-L.", "paper_title": "The option-critic architecture", "publication_date": "2017-01-01", "reason": "This paper proposes the option-critic architecture, a key component of hierarchical reinforcement learning which is extended in the target paper."}, {"fullname_first_author": "Bertsekas, D.", "paper_title": "Neuro-dynamic programming", "publication_date": "1996-01-01", "reason": "This book is a foundational text in reinforcement learning that provides the theoretical background for many of the algorithms used in the target paper."}, {"fullname_first_author": "Dayan, P.", "paper_title": "Feudal reinforcement learning", "publication_date": "1993-01-01", "reason": "This paper introduces feudal reinforcement learning, an early approach to hierarchical reinforcement learning which is relevant to the methods proposed in the target paper."}]}