{"references": [{"fullname_first_author": "Grosse, R.", "paper_title": "A Kronecker-factored approximate Fisher matrix for convolution layers", "publication_date": "2016-00-00", "reason": "This paper introduces the Kronecker-factored approximate Fisher matrix, a crucial concept for efficient second-order optimization methods in convolutional neural networks, directly impacting the core methodology of the current work."}, {"fullname_first_author": "Martens, J.", "paper_title": "Optimizing neural networks with Kronecker-factored approximate curvature", "publication_date": "2015-00-00", "reason": "This foundational paper lays the groundwork for Kronecker-factored approximate curvature methods (KFAC), which is a central focus of the advancements and analysis presented in the current paper."}, {"fullname_first_author": "Hayashi, K.", "paper_title": "Exploring unexplored tensor network decompositions for convolutional neural networks", "publication_date": "2019-00-00", "reason": "This paper provides the tensor network formulation of convolution that the current work builds upon, providing a crucial theoretical foundation for the presented tensor network approach to analyzing and optimizing convolutions."}, {"fullname_first_author": "Eschenhagen, R.", "paper_title": "Kronecker-factored approximate curvature for modern neural network architectures", "publication_date": "2023-00-00", "reason": "This recent work significantly advances KFAC methods, particularly by introducing KFAC-reduce, a computationally efficient variant that's directly compared and improved upon using the tensor network approach."}, {"fullname_first_author": "LeCun, Y.", "paper_title": "Backpropagation applied to handwritten zip code recognition", "publication_date": "1989-00-00", "reason": "This highly influential paper is foundational to convolutional neural networks, marking a milestone in the development of deep learning architectures and providing historical context to the advancements in understanding and optimizing convolutions discussed in the current work."}]}