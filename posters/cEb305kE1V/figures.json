[{"figure_path": "cEb305kE1V/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of our framework. (a) A neural network extracts multi-scale features from the input images. (b)These features are used to optimize warp fields using a multi-scale differentiable optimization solver. (c) The optimized transform is used to warp the moving image and labels. (d) The warped image/label are compared with the fixed image/label using a similarity metric.", "description": "This figure shows the architecture of the proposed framework, DIO. (a) shows a neural network that extracts multi-scale features from input images. (b) shows a multi-scale differentiable optimization solver that uses these features to optimize warp fields. (c) shows the process of warping the moving image and labels using the optimized transform. (d) shows the calculation of the loss based on the similarity between the warped image/labels and the fixed image/labels.", "section": "3 Methods"}, {"figure_path": "cEb305kE1V/figures/figures_4_1.jpg", "caption": "Figure 1: Overview of our framework. (a) A neural network extracts multi-scale features from the input images. (b)These features are used to optimize warp fields using a multi-scale differentiable optimization solver. (c) The optimized transform is used to warp the moving image and labels. (d) The warped image/label are compared with the fixed image/label using a similarity metric.", "description": "This figure shows the overall framework of the proposed method, DIO.  It consists of four main stages:\n(a) A neural network extracts multi-scale features from input images (fixed and moving).\n(b) These features are used by a multi-scale differentiable optimization solver to optimize the warp fields.\n(c) The resulting optimized transformation is applied to warp the moving image and labels.\n(d) Finally, the warped image and labels are compared to their fixed counterparts using a similarity metric to calculate the loss.", "section": "3 Methods"}, {"figure_path": "cEb305kE1V/figures/figures_6_1.jpg", "caption": "Figure 1: Overview of our framework. (a) A neural network extracts multi-scale features from the input images. (b)These features are used to optimize warp fields using a multi-scale differentiable optimization solver. (c) The optimized transform is used to warp the moving image and labels. (d) The warped image/label are compared with the fixed image/label using a similarity metric.", "description": "This figure shows the DIO framework's components: a feature extractor network, multi-scale differentiable optimization solver, a resampling step, and image and label loss calculation. The feature network extracts multi-scale features. The optimizer finds optimal warp fields using these features.  The moving image and labels are warped using the transform. Finally, the warped data is compared to the fixed data, computing the image and label alignment error.", "section": "3 Methods"}, {"figure_path": "cEb305kE1V/figures/figures_7_1.jpg", "caption": "Figure 1: Overview of our framework. (a) A neural network extracts multi-scale features from the input images. (b)These features are used to optimize warp fields using a multi-scale differentiable optimization solver. (c) The optimized transform is used to warp the moving image and labels. (d) The warped image/label are compared with the fixed image/label using a similarity metric.", "description": "This figure shows the DIO framework's architecture. (a) shows the feature extraction from fixed and moving images, using a neural network. (b) shows the optimization solver receiving multi-scale features to generate the warp field. (c) uses the warp field to transform the moving image and labels. (d) evaluates the similarity between the transformed moving image/label and the fixed image/label, computing losses.", "section": "3 Methods"}, {"figure_path": "cEb305kE1V/figures/figures_16_1.jpg", "caption": "Figure 2: Dense feature learning leads to flatter loss landscapes. Top row shows the intensity image with the corresponding multi-scale features predicted by the deep network, where the Lth level denotes a feature of size H/2k\u00d7W/2k\u00d7Ck. Bottom row shows the loss landscape as a function of the relative translation between the squares in the fixed and moving image. Note the flat maxima which occurs when there is no overlap between the fixed and moving image, making optimization impossible if there is no overlap of the squares. On the contrary, the loss landscape for learned features is smooth, even at the finest scale, leading to much faster convergence even when there is no overlap between the intensity images.", "description": "This figure shows how the learned features lead to flatter loss landscapes compared to using intensity images directly for registration. The top row displays the intensity images and their corresponding multi-scale features extracted by the network.  The bottom row illustrates the loss landscapes as a function of relative translation between two squares, one in the fixed image and one in the moving image. For intensity images (left), the loss landscape shows flat maxima when squares do not overlap, making optimization challenging. In contrast, the loss landscape for learned features is smooth even with no overlap, resulting in faster convergence during optimization.", "section": "3 Methods"}, {"figure_path": "cEb305kE1V/figures/figures_19_1.jpg", "caption": "Figure 1: Overview of our framework. (a) A neural network extracts multi-scale features from the input images. (b)These features are used to optimize warp fields using a multi-scale differentiable optimization solver. (c) The optimized transform is used to warp the moving image and labels. (d) The warped image/label are compared with the fixed image/label using a similarity metric.", "description": "This figure provides a visual overview of the proposed framework, DIO, illustrating the four main steps involved. First, a neural network extracts multi-scale features from both the fixed and moving images (a). These features are then used as input for a multi-scale differentiable optimization solver to optimize the warp fields (b). Subsequently, the optimized transformation is applied to warp the moving image and labels (c). Finally, a similarity metric compares the warped image/labels with the fixed image/labels (d), completing the end-to-end process.", "section": "3 Methods"}, {"figure_path": "cEb305kE1V/figures/figures_20_1.jpg", "caption": "Figure 8: Loss curves for toy dataset. Plot shows three curves - the Dice score for (a) all validation image pairs, (b) image pairs that have non-zero overlap in the image space (therefore a gradient-based affine solver will recover a transform from intensity images), and (c) image pairs that have zero overlap in the image space (therefore any gradient-based solver using intensity images will fail). Our feature network recovers dense multi-scale features (see Fig. 2) which allows all subsets to be registered with >0.99 Dice score.", "description": "This figure shows the loss curves for three different sets of image pairs in a toy dataset experiment: all pairs, overlapping pairs, and non-overlapping pairs.  The results demonstrate that the proposed method is able to recover accurate transformations even for image pairs without overlap, which is difficult for gradient-based methods. This success is attributed to the learned dense, multi-scale features.", "section": "4 Experiments"}, {"figure_path": "cEb305kE1V/figures/figures_22_1.jpg", "caption": "Figure 1: Overview of our framework. (a) A neural network extracts multi-scale features from the input images. (b)These features are used to optimize warp fields using a multi-scale differentiable optimization solver. (c) The optimized transform is used to warp the moving image and labels. (d) The warped image/label are compared with the fixed image/label using a similarity metric.", "description": "This figure illustrates the proposed framework's workflow. It starts with a neural network extracting multi-scale features from input images (a).  These features are then fed into a multi-scale differentiable optimization solver to produce optimal warp fields (b). The moving image and labels are warped using this optimized transform (c). Finally, a similarity metric compares the warped results with the fixed image and labels (d).", "section": "3 Methods"}]