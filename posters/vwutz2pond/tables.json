[{"figure_path": "VwUTz2pOnD/tables/tables_3_1.jpg", "caption": "Table 1: Summary of the existing regret bounds in the infinite horizon average reward setting under various cases with respect to MDP structure (tabular, linear, kernel based) and assumptions.", "description": "This table summarizes the regret bounds of existing algorithms for infinite horizon average reward reinforcement learning under various assumptions about the Markov Decision Process (MDP) and its structure. The algorithms are categorized by MDP structure (tabular, linear, kernel-based) and assumptions (weakly communicating MDP, Bellman optimality equation, uniform mixing). For each algorithm, the table shows its regret bound, MDP assumption, and structure.", "section": "1.2 Related Work"}]