[{"figure_path": "nRdST1qifJ/tables/tables_3_1.jpg", "caption": "Table 1: The performances of PAT on the Advbench dataset. The best and the second best results obtained by defenses are in bold and underline, respectively. PAT achieves the lowest average ASR compared to baseline defenses.", "description": "This table presents a comparison of the attack success rate (ASR) achieved by various defense methods, including PAT, against different attack strategies on the Advbench dataset for two LLMs: Vicuna-7B and Llama-2-7B.  It also includes the performance of each model on two benchmarks: MT-bench and MMLU, demonstrating the effect of each defense on maintaining the model's utility.  PAT consistently shows the lowest average ASR while maintaining comparable performance on benign tasks.", "section": "4 Experiments"}, {"figure_path": "nRdST1qifJ/tables/tables_5_1.jpg", "caption": "Table 1: The performances of PAT on the Advbench dataset. The best and the second best results obtained by defenses are in bold and underline, respectively. PAT achieves the lowest average ASR compared to baseline defenses.", "description": "This table presents the attack success rate (ASR) and model utility scores for various defense methods against different jailbreak attacks on two large language models (Vicuna-7B and Llama-2-7B).  The results showcase that the proposed Prompt Adversarial Tuning (PAT) method significantly reduces ASR while maintaining comparable or higher utility scores compared to existing methods.  The table highlights PAT's effectiveness in both grey-box and black-box attack settings.", "section": "4 Experiments"}, {"figure_path": "nRdST1qifJ/tables/tables_6_1.jpg", "caption": "Table 1: The performances of PAT on the Advbench dataset. The best and the second best results obtained by defenses are in bold and underline, respectively. PAT achieves the lowest average ASR compared to baseline defenses.", "description": "This table presents a comparison of the attack success rate (ASR) and the performance on two benchmark datasets (MT-bench and MMLU) for various defense methods against several jailbreak attacks on two large language models (Vicuna-7B and Llama-2-7B).  The results show that the proposed Prompt Adversarial Tuning (PAT) method achieves significantly lower ASR compared to other state-of-the-art defense methods while maintaining high utility scores on benign tasks.  The best and second-best results for each metric are highlighted.", "section": "4 Experiments"}, {"figure_path": "nRdST1qifJ/tables/tables_8_1.jpg", "caption": "Table 3: Performances of PAT on defending human-crafted jailbreak attacks on closed-source models. The lowest ASR achieved by defense methods are in bold.", "description": "This table compares the attack success rate (ASR) of several defense methods against human-crafted jailbreaking attacks on GPT-3.5 and GPT-4.  The attacks are categorized into competing objectives (CO) and mismatched generalizations (MG), with specific attack types listed for each category (e.g., AIM, PI, RS for CO, and Base64, BN for MG). The table shows that PAT consistently achieves the lowest ASR across various attacks and models, demonstrating its effectiveness in defending against human-crafted attacks while maintaining reasonable model utility. ", "section": "4.5 Defense against Human-crafted Attacks"}, {"figure_path": "nRdST1qifJ/tables/tables_9_1.jpg", "caption": "Table 4: ASR of adaptive attack against the unprotected and protected models.", "description": "This table presents the Attack Success Rate (ASR) for four different attacks (GCG, AutoDAN, PAIR, and TAP) against two large language models (Vicuna-7B and Llama-2-7B).  It shows the ASR both before (unprotected) and after (protected) applying the proposed Prompt Adversarial Tuning (PAT) defense method.  The significant reduction in ASR after applying PAT demonstrates the effectiveness of the defense against adaptive attacks, where the attacker has knowledge of the defense mechanism.", "section": "4.7 Adaptive Attack"}, {"figure_path": "nRdST1qifJ/tables/tables_15_1.jpg", "caption": "Table 5: Hyperparameter setting for baseline attacks", "description": "This table lists the hyperparameters used in the baseline attacks (GCG, AutoDAN, ICA, PAIR, and TAP) against the LLMs.  For each attack, several hyperparameters are specified, including the number of prompts, length of control strings, epoch numbers, token set size, batch size, weight parameters for the loss function, temperature, number of demonstrations, and the models used for the attack and judging.  These settings were used to conduct the experiments comparing the performance of the proposed PAT method against existing techniques.", "section": "4.2 Performances of PAT under the Grey-box Setting"}, {"figure_path": "nRdST1qifJ/tables/tables_15_2.jpg", "caption": "Table 1: The performances of PAT on the Advbench dataset. The best and the second best results obtained by defenses are in bold and underline, respectively. PAT achieves the lowest average ASR compared to baseline defenses.", "description": "This table presents a comparison of the attack success rate (ASR) achieved by the proposed Prompt Adversarial Tuning (PAT) method and six other state-of-the-art defense methods against five different jailbreaking attacks on two large language models (LLMs): Vicuna-7B and Llama-2-7B.  The table highlights PAT's superior performance in achieving a significantly lower average ASR while maintaining a high level of model utility (measured by MT-bench and MMLU scores).  It demonstrates the effectiveness of PAT across various attacks and LLMs.", "section": "4 Experiments"}, {"figure_path": "nRdST1qifJ/tables/tables_16_1.jpg", "caption": "Table 1: The performances of PAT on the Advbench dataset. The best and the second best results obtained by defenses are in bold and underline, respectively. PAT achieves the lowest average ASR compared to baseline defenses.", "description": "This table presents the performance comparison of the proposed Prompt Adversarial Tuning (PAT) method against several existing defense methods on the Advbench dataset.  The results are evaluated in terms of Attack Success Rate (ASR) and the utility of the model (measured by MT-bench and MMLU scores).  It shows that PAT achieves the lowest ASR across various attack types while maintaining reasonable model utility compared to other defense techniques.", "section": "4 Experiments"}, {"figure_path": "nRdST1qifJ/tables/tables_17_1.jpg", "caption": "Table 1: The performances of PAT on the Advbench dataset. The best and the second best results obtained by defenses are in bold and underline, respectively. PAT achieves the lowest average ASR compared to baseline defenses.", "description": "This table presents a comparison of the attack success rate (ASR) achieved by Prompt Adversarial Tuning (PAT) and other baseline defense methods against several jailbreak attacks on two large language models (LLMs), Vicuna-7B and Llama-2-7B.  The ASR is a key metric for evaluating the effectiveness of defense mechanisms against jailbreaking attacks. Lower ASR indicates better performance. The table also includes the average Multi-turn Benchmark (MT-bench) and Massive Multitask Language Understanding (MMLU) scores for each method. These scores represent the model's performance on benign tasks.", "section": "4 Experiments"}]