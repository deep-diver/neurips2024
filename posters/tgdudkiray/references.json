{"references": [{"fullname_first_author": "Joshua Achiam", "paper_title": "Constrained policy optimization", "publication_date": "2017-00-00", "reason": "This paper introduces a foundational constrained optimization method for reinforcement learning, which is highly relevant to the problem of safe reinforcement learning addressed in the target paper."}, {"fullname_first_author": "Felix Berkenkamp", "paper_title": "Safe model-based reinforcement learning with stability guarantees", "publication_date": "2017-00-00", "reason": "This paper presents a seminal work on safe reinforcement learning, focusing on model-based methods and providing theoretical stability guarantees, which is directly relevant to the techniques used in the target paper."}, {"fullname_first_author": "Krishnamurthy Dvijotham", "paper_title": "A dual approach to scalable verification of deep networks", "publication_date": "2018-00-00", "reason": "This paper introduces a scalable method for verifying deep neural networks, a crucial component for ensuring the safety of the neural network controllers proposed in the target paper."}, {"fullname_first_author": "Shiqi Wang", "paper_title": "Beta-CROWN: Efficient bound propagation with per-neuron split constraints for complete and incomplete neural network verification", "publication_date": "2021-00-00", "reason": "This paper introduces an improved technique for neural network verification (Beta-CROWN), which is directly used in the target paper for verifying the safety of its learned controllers."}, {"fullname_first_author": "Junlin Wu", "paper_title": "Robust deep reinforcement learning through bootstrapped opportunistic curriculum", "publication_date": "2022-00-00", "reason": "This paper introduces a curriculum learning approach for reinforcement learning, a technique that is leveraged in the target paper to improve the efficiency and scalability of learning verified safe controllers."}]}