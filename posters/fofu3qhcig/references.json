{"references": [{"fullname_first_author": "Noah Hollmann", "paper_title": "TabPFN: A transformer that solves small tabular classification problems in a second", "publication_date": "2023-00-00", "reason": "This paper introduces TabPFN, a prior-data fitted network that serves as the foundation model for TuneTables, demonstrating strong performance on small datasets and laying the groundwork for the improvements in TuneTables."}, {"fullname_first_author": "Samuel M\u00fcller", "paper_title": "Transformers can do Bayesian inference", "publication_date": "2022-00-00", "reason": "This paper establishes the theoretical framework of prior-data fitted networks (PFNs), including the Bayesian inference concept that underpins TuneTables' methodology."}, {"fullname_first_author": "Tianqi Chen", "paper_title": "XGBoost: A scalable tree boosting system", "publication_date": "2016-00-00", "reason": "This paper introduces XGBoost, a gradient boosting decision tree algorithm frequently used as a baseline and strong competitor against TuneTables, highlighting its significance in the field of tabular data classification."}, {"fullname_first_author": "Cynthia Dwork", "paper_title": "Fairness through awareness", "publication_date": "2012-00-00", "reason": "This paper is a seminal work on fairness in machine learning, providing a theoretical foundation for bias mitigation methods, a key extension explored in TuneTables to address societal impacts."}, {"fullname_first_author": "Vadim Borisov", "paper_title": "Deep neural networks and tabular data: A survey", "publication_date": "2021-00-00", "reason": "This survey paper provides a comprehensive overview of the existing landscape of deep learning for tabular data, contextualizing the novelty and significance of TuneTables in addressing the limitations of previous approaches."}]}