{"references": [{"fullname_first_author": "Micah Goldblum", "paper_title": "Dataset security for machine learning: Data poisoning, backdoor attacks, and defenses", "publication_date": "2022-00-00", "reason": "This paper provides a comprehensive overview of data poisoning and backdoor attacks in machine learning, forming a foundational basis for the current research on diffusion models."}, {"fullname_first_author": "Tianyu Gu", "paper_title": "Badnets: Identifying vulnerabilities in the machine learning model supply chain", "publication_date": "2017-00-00", "reason": "This paper introduces the BadNets attack, a seminal work that inspires the BadNets-like data poisoning method used in this paper to evaluate diffusion model vulnerability."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-00-00", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), a fundamental concept underlying the diffusion models studied in this paper."}, {"fullname_first_author": "Sheng-Yen Chou", "paper_title": "How to backdoor diffusion models?", "publication_date": "2023-00-00", "reason": "This paper is among the first to investigate backdoor attacks on diffusion models, providing a crucial context for this paper's research on data poisoning attacks."}, {"fullname_first_author": "Weixin Chen", "paper_title": "Trojdiff: Trojan attacks on diffusion models with diverse targets", "publication_date": "2023-00-00", "reason": "This paper explores another type of attack on diffusion models (Trojan attacks), providing further context and comparison for the data poisoning attacks investigated in this paper."}]}