[{"figure_path": "GtEmIzLZmR/tables/tables_8_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table summarizes the performance of several fairness-aware machine learning models across various datasets.  It shows the proportion of times each model's performance fell into three categories: 'Unlikely' (achieving very low fairness violations), 'Permissible' (achieving moderate fairness violations), and 'Sub-optimal' (achieving high fairness violations).  The table also provides an estimate of the training time for each model.  The results are based on Bernstein's Confidence Intervals and reflect performance across different datasets and fairness metrics.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_21_1.jpg", "caption": "Table 2: Results for the Adult dataset and EO fairness violation with and without sensitivity analysis: Proportion of empirical trade-offs for each baseline which lie in the three trade-off regions (using Bootstrap CIs).", "description": "This table shows the proportion of empirical trade-offs that fall into three categories (Unlikely, Permissible, Suboptimal) for different fairness baselines on the Adult dataset.  It compares results with and without sensitivity analysis (using different numbers of additional models: |M| = 0, 2, and 5). The results are based on Bootstrap Confidence Intervals (CIs). The purpose is to demonstrate how the sensitivity analysis impacts the confidence intervals, helping to identify truly suboptimal trade-offs versus those seemingly suboptimal due to sampling variability.", "section": "Experimental results"}, {"figure_path": "GtEmIzLZmR/tables/tables_21_2.jpg", "caption": "Table 3: Results for the Adult dataset and DP fairness violation with and without sensitivity analysis: Proportion of empirical trade-offs for each baseline which lie in the three trade-off regions (using Bootstrap CIs).", "description": "This table presents the results of experiments conducted on the Adult dataset using the Demographic Parity (DP) fairness metric. It shows the proportions of empirical trade-offs for various baselines that fall into three categories: 'Sub-optimal', 'Permissible', and 'Unlikely', based on the confidence intervals constructed using the Bootstrap method. The table compares the results with and without sensitivity analysis to evaluate the impact of this analysis on the accuracy of the results.", "section": "5.1 Results"}, {"figure_path": "GtEmIzLZmR/tables/tables_21_3.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table presents the proportion of empirical accuracy-fairness trade-offs achieved by different fairness methods that fall into three categories: unlikely, permissible, and suboptimal.  These categories are defined by the confidence intervals calculated using Bernstein's method in the paper.  The table summarizes results across multiple datasets and fairness metrics, providing a comparison of the methods' performance. Training time is also provided, illustrating the computational efficiency of the proposed YOTO method.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_27_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table presents the proportion of empirical trade-offs for different fairness methods across four datasets (Adult, COMPAS, CelebA, Jigsaw) and three fairness metrics (Demographic Parity, Equalized Opportunity, Equalized Odds).  It categorizes the results into three regions based on the constructed confidence intervals: 'Unlikely' (suboptimal), 'Permissible' (achievable), and 'Sub-optimal'.  The table highlights the relative performance and computational cost of various fairness methods and supports claims about the data-dependent nature of accuracy-fairness trade-offs.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_31_1.jpg", "caption": "Table 6: Approximate training times per model for different baselines across various datasets.", "description": "This table presents the approximate training times required for different fairness-achieving baselines across four datasets: Adult, COMPAS, CelebA, and Jigsaw.  The baselines include various regularization approaches, the reductions method, KDE-fair, the YOTO method (the authors' proposed method), and an adversarial approach.  Training times are given per model, and for the RTO (Randomized Threshold Optimizer) method, separate timings are provided for the base classifier training and subsequent post-hoc optimizations. The table offers a comparison of the computational costs associated with these different methods.", "section": "F.3 Baselines"}, {"figure_path": "GtEmIzLZmR/tables/tables_32_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table summarizes the performance of various fairness methods across different datasets and fairness metrics. It shows the proportion of times each method resulted in trade-offs falling into three categories: unlikely to achieve (suboptimal), permissible, and suboptimal.  The last column indicates the approximate training time for each method.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_33_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table shows the performance of various fairness methods across different datasets.  It categorizes the empirical accuracy-fairness trade-offs into three regions: unlikely, permissible, and suboptimal, based on the confidence intervals generated by the proposed method. The table also provides an estimate of the training time required for each method.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_34_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table presents the proportion of empirical trade-offs for various fairness baselines that fall into three categories: unlikely, permissible, and suboptimal.  These categories correspond to visual regions in Figure 1, representing the range of achievable accuracy-fairness tradeoffs. The table also provides an estimate of the training time required for each baseline.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_35_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table shows the performance of various fairness methods across different datasets. The proportion of empirical trade-offs that fall into the 'Unlikely', 'Permissible', and 'Sub-optimal' regions are presented.  The 'Unlikely', 'Permissible', and 'Sub-optimal' regions refer to the classifications of achievable accuracy-fairness trade-offs from Figure 1 in the paper. The table also provides a rough estimate of the training time required for each method.", "section": "Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_36_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table shows the proportion of times different baseline models' accuracy-fairness trade-offs fall into three categories: unlikely to be achieved, permissible, and suboptimal.  It's aggregated across all datasets and fairness metrics used in the paper. The categories are based on the confidence intervals calculated and visualized in Figure 1.  The final column gives a relative comparison of the training time required for each model.", "section": "Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_36_2.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table presents the proportion of empirical accuracy-fairness trade-offs for several fairness methods that fall into three categories: unlikely to be achievable, permissible, and suboptimal.  The categories are defined by the confidence intervals calculated in the paper.  The table also shows the approximate training time required for each method.  This data helps quantify the effectiveness and efficiency of the different methods, considering both performance and computational cost.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_37_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table summarizes the performance of various fairness methods across different datasets and fairness metrics. For each method, it shows the proportion of times the accuracy-fairness trade-off falls into three categories: 'Unlikely' (below the lower bound of the confidence interval), 'Permissible' (within the confidence interval), and 'Sub-optimal' (above the upper bound). It also shows the approximate training time for each method.", "section": "Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_37_2.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table summarizes the performance of various fairness methods across different datasets, categorized into three regions based on the accuracy-fairness trade-off: unlikely, permissible, and suboptimal.  The proportions of each method falling into each region are shown, along with approximate training times. This helps evaluate the effectiveness and efficiency of different approaches to achieving fairness in machine learning models.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_38_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table shows the proportion of empirical trade-offs for different fairness baselines that fall into three categories: unlikely, permissible, and suboptimal.  The categories are based on the confidence intervals calculated in the paper and visualized in Figure 1.  The table summarizes results across several datasets and fairness metrics, indicating the likelihood of baselines being suboptimal (falling outside the permissible range). It also provides a comparison of the training time required for each baseline.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_38_2.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table presents the proportion of empirical accuracy-fairness trade-offs that fall into three categories: 'Unlikely', 'Permissible', and 'Sub-optimal'.  These categories correspond to regions defined visually in Figure 1, representing trade-offs that are unlikely to be achievable, permissible, or suboptimal. The table shows these proportions for various fairness baselines across several datasets and fairness metrics, using Bernstein's confidence intervals.  The final column indicates the approximate training time for each baseline.", "section": "Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_38_3.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein\u2019s CIs). \u2018Unlikely\u2019, \u2018Permissible\u2019 and \u2018Sub-optimal\u2019 correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table shows the proportion of empirical trade-offs for different fairness methods that fall into three categories: unlikely to be achievable, permissible, and suboptimal.  The categorization is based on confidence intervals calculated using Bernstein's method, and visualized in Figure 1 as colored regions.  The table covers several datasets and fairness metrics (Demographic Parity, Equalized Odds, Equalized Opportunity), providing a comprehensive comparison across various in-processing and post-processing methods. The final column shows the approximate training time for each method.", "section": "5 Experiments"}, {"figure_path": "GtEmIzLZmR/tables/tables_39_1.jpg", "caption": "Table 1: Proportion of empirical trade-offs for each baseline in the three trade-off regions, aggregated across all datasets and fairness metrics (using Bernstein's CIs). 'Unlikely', 'Permissible' and 'Sub-optimal' correspond to the blue, green and pink regions in Figure 1 respectively. The last column shows the rough average training time per model across experiments \u00d7 no. of models per experiment.", "description": "This table presents the proportion of empirical trade-offs that fall into three different regions (Unlikely, Permissible, and Sub-optimal) for various baselines, aggregated across multiple datasets and fairness metrics.  The regions correspond to the visual depiction in Figure 1.  The table also offers an estimate of the training time for each model, factoring in the number of models trained per experiment.", "section": "5 Experiments"}]