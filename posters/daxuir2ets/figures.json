[{"figure_path": "dAXuir2ets/figures/figures_2_1.jpg", "caption": "Figure 1: Illustration of SpaFL framework that performs model pruning through thresholds. Only the thresholds are communicated between the server and clients.", "description": "The figure illustrates the SpaFL framework, showing how trainable thresholds are used for structured pruning in a federated learning setting. Each client has a structured sparse model with individual thresholds for each filter/neuron.  Only these thresholds, not the model parameters themselves, are communicated between the clients and the central server. The server aggregates the thresholds to produce global thresholds, which are then sent back to the clients for the next round of training. This process allows for efficient communication and personalized model pruning.", "section": "3 SpaFL Algorithm"}, {"figure_path": "dAXuir2ets/figures/figures_8_1.jpg", "caption": "Figure 2: Learning curves on FMNIST, CIFAR-10, and CIFAR-100", "description": "This figure shows the learning curves of SpaFL and several baseline algorithms on three image classification datasets: FMNIST, CIFAR-10, and CIFAR-100.  The x-axis represents the number of communication rounds, and the y-axis represents the accuracy achieved.  The plot visually compares the training performance and convergence speed of SpaFL against other approaches, illustrating its effectiveness in achieving high accuracy with fewer communication rounds.", "section": "5 Main Results"}, {"figure_path": "dAXuir2ets/figures/figures_9_1.jpg", "caption": "Figure 3: Sparsity pattern of conv1 layer on CIFAR-10", "description": "This figure visualizes the sparsity patterns of the first convolutional layer (conv1) in a model trained on the CIFAR-10 dataset across different training rounds (40, 150, and 500). Each subfigure represents a specific training round, showing a heatmap where black represents active filters/neurons and white represents pruned ones. The x-axis shows the different clients, and the y-axis represents the filters. This visualization demonstrates how SpaFL, the proposed algorithm, learns to optimize sparse model structures by evolving the sparsity patterns over the training process, indicating that initially many filters are pruned and then some are recovered as training progresses.", "section": "3 SpaFL Algorithm"}, {"figure_path": "dAXuir2ets/figures/figures_20_1.jpg", "caption": "Figure 3: Sparsity pattern of conv1 layer on CIFAR-10", "description": "This figure visualizes the sparsity patterns of the first convolutional layer (conv1) across different training rounds (40, 150, and 500) on the CIFAR-10 dataset.  Each subplot represents a specific training round and shows the sparsity pattern for each client.  Black pixels indicate active filters/neurons, while white pixels represent pruned (inactive) ones. The figure demonstrates how the sparsity patterns evolve as training progresses, showing that clients gradually learn common sparse model structures by optimizing shared thresholds across training rounds. Note that some filters initially pruned may be reactivated during the training process.", "section": "3 SpaFL Algorithm"}, {"figure_path": "dAXuir2ets/figures/figures_20_2.jpg", "caption": "Figure 3: Sparsity pattern of conv1 layer on CIFAR-10", "description": "This figure visualizes the sparsity patterns of the first convolutional layer (conv1) across different training rounds (40, 150, and 500) on the CIFAR-10 dataset.  Each subfigure shows a heatmap where each row represents a client and each column represents a filter in the layer. Black indicates a filter that is active (not pruned) while white represents a pruned filter. The figure demonstrates how the sparsity pattern evolves during training. It shows how the sparsity patterns differ across clients, indicating personalization, and also how the overall sparsity changes over time.", "section": "3 SpaFL Algorithm"}, {"figure_path": "dAXuir2ets/figures/figures_20_3.jpg", "caption": "Figure 3: Sparsity pattern of conv1 layer on CIFAR-10", "description": "This figure shows the sparsity patterns of the first convolutional layer (conv1) with 64 filters and three input channels on the CIFAR-10 dataset at different communication rounds (40, 150, and 500).  Active filters are shown in black, while pruned filters are shown in white.  The figure illustrates how SpaFL enables clients to learn common, optimized sparse model structures across training rounds by optimizing thresholds.  Initially (round 40), there is high sparsity.  As training progresses, pruned filters may be recovered and sparsity is gradually enforced.  This demonstrates the dynamic and adaptive nature of the sparsity patterns learned by the SpaFL algorithm.", "section": "3 SpaFL Algorithm"}]