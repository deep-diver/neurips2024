[{"figure_path": "0sJBW05a2W/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between our method and existing methods in multi-instance point cloud registration. Our method decomposes the multi-instance point cloud registration into multiple pair-wise point cloud registration.", "description": "The figure compares existing multi-instance point cloud registration methods with the proposed method. Existing methods directly find correspondences between the model point cloud and the scene point cloud, which is challenging in cluttered scenes. The proposed method first localizes the object centers, generates object proposals, and then performs multiple pair-wise point cloud registrations for improved accuracy.", "section": "1 Introduction"}, {"figure_path": "0sJBW05a2W/figures/figures_2_1.jpg", "caption": "Figure 2: The framework of our 3D focusing-and-matching network for multi-instance pint cloud registration. Given the scene point cloud and the CAD model, we first present the 3D multi-object focusing module to localize the centers of the potential objects in the scene. Then, we design the 3D dual-masking instance matching module to learn pair-wise point cloud registration from the localized object proposals.", "description": "This figure illustrates the overall pipeline of the proposed 3D focusing-and-matching network for multi-instance point cloud registration. It's a two-stage process. The first stage, 3D multi-object focusing module, localizes potential object centers in the scene point cloud by learning correlations between the scene and model point clouds. The second stage, 3D dual-masking instance matching module, performs pair-wise registration between the model point cloud and object proposals generated from the localized object centers.  Self-attention and cross-attention mechanisms are used to associate the model point cloud with structurally similar objects, improving object center prediction accuracy.  Instance and overlap masks refine the pair-wise registration, addressing the challenges of incomplete objects and background noise. ", "section": "3 Method"}, {"figure_path": "0sJBW05a2W/figures/figures_8_1.jpg", "caption": "Figure 3: Registration results on the test set of the Sacn2CAD dataset. We visualize the successfully registered instances of MIRETR [46] in (b) and ours in (c). \"# Inst\" means the number of registered instances. Note that for a better view, we draw the green boxes for the ground truth and the red boxes for the predict correspondences.", "description": "This figure compares the performance of the proposed 3DFMNet method against the state-of-the-art MIRETR method on the Scan2CAD dataset for multi-instance point cloud registration. It shows three sets of point cloud registration results: ground truth, MIRETR results, and 3DFMNet results. Each set contains three examples with different numbers of instances. Red boxes highlight the instances predicted by each method, green boxes are ground truth instances, and the number of instances is indicated for each case. The figure visually demonstrates 3DFMNet's improved accuracy in identifying and registering multiple instances compared to MIRETR.", "section": "4.3 Results"}, {"figure_path": "0sJBW05a2W/figures/figures_9_1.jpg", "caption": "Figure 3: Registration results on the test set of the Sacn2CAD dataset. We visualize the successfully registered instances of MIRETR [46] in (b) and ours in (c). \"# Inst\" means the number of registered instances. Note that for a better view, we draw the green boxes for the ground truth and the red boxes for the predict correspondences.", "description": "This figure compares the performance of the proposed 3DFMNet method against the state-of-the-art MIRETR method on the Scan2CAD dataset.  It shows the successfully registered instances for both methods, side-by-side with the ground truth. Each subfigure shows a scene with multiple instances of chairs, with the number of successfully registered instances indicated. The 3DFMNet method showcases improved accuracy in registering the instances compared to the MIRETR method.", "section": "4.3 Results"}, {"figure_path": "0sJBW05a2W/figures/figures_9_2.jpg", "caption": "Figure 5: Visualization results of pair-wise correspondences on the test set of Scan2CAD dataset.", "description": "This figure visualizes the pair-wise correspondences obtained by the proposed method on the Scan2CAD dataset.  It showcases the successful matching of points between the model point cloud and the corresponding instances within the scene point cloud.  The visualization helps to illustrate the accuracy and effectiveness of the 3D dual-masking instance matching module in establishing accurate correspondences, especially in challenging scenarios with cluttered or occluded objects.", "section": "4.3 Results"}]