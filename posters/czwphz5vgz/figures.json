[{"figure_path": "CZwphz5vgz/figures/figures_0_1.jpg", "caption": "Figure 1: Reconstructing humans from monocular videos frequently fails under occlusion. In this paper, we introduce OccFusion, a method that combines 3D Gaussian splatting with 2D diffusion priors for modeling occluded humans. Our method outperforms the state-of-the-art in rendering quality and efficiency, resulting in clean and complete renderings free of artifacts.", "description": "This figure demonstrates the problem of reconstructing humans from monocular videos in the presence of occlusions, where existing methods often fail to produce clean and complete renderings. It introduces OccFusion, a novel method that uses a combination of 3D Gaussian splatting and 2D diffusion priors to improve the quality and efficiency of human rendering, achieving state-of-the-art results in handling occlusions.", "section": "Introduction"}, {"figure_path": "CZwphz5vgz/figures/figures_4_1.jpg", "caption": "Figure 2: OccFusion achieves occluded human rendering via three sequential stages. In the Initialization Stage, we recover complete binary human masks {M} from occluded partial observations {I} with the help of segmentation priors {M} and pose priors {P}. {M} will be further used to help optimize the 3D Gaussians \u03a0 in subsequent stages. In the Optimization Stage, we apply {P} conditioned SDS on both posed human and canonical human to enforce the human occupancy to remain complete. In the Refinement Stage, we use the coarse human renderings {\u00ce} from the Optimization Stage to help generate missing RGB values in {I} through our proposed in-context inpainting. Through this process, both the appearance and geometry of the human are fine-tuned to be in high fidelity. Training of all three stages takes only 10 minutes on a single Titan RTX GPU.", "description": "This figure shows the OccFusion pipeline, which consists of three stages: Initialization, Optimization, and Refinement.  The Initialization stage uses a diffusion model to inpaint missing parts of the human mask from partially visible input images. The Optimization stage uses 3D Gaussian splatting and Score Distillation Sampling (SDS) to optimize the 3D Gaussian representation of the human, enforcing completeness. Finally, the Refinement stage employs in-context inpainting to enhance the rendering quality, particularly in less observed regions.", "section": "4 OccFusion"}, {"figure_path": "CZwphz5vgz/figures/figures_4_2.jpg", "caption": "Figure 3: Stable Diffusion 1.5 generations [48] conditioned on a challenging pose P. While conditioning on the original pose results in multiple limbs and other abnormalities, our method of simplifying pose by removing self-occluded joints results in more feasible generations.", "description": "This figure shows the results of using Stable Diffusion 1.5 to generate images conditioned on challenging poses. The leftmost column shows an example of an occluded human image. The middle column shows that directly using the original pose as input leads to unstable generations with multiple limbs and abnormalities. The rightmost column illustrates that simplifying the pose by removing self-occluded joints before inputting into the Stable Diffusion model yields more realistic and feasible generations.", "section": "4.1 Initialization Stage: Recovering Human Geometry from Partial Observations"}, {"figure_path": "CZwphz5vgz/figures/figures_5_1.jpg", "caption": "Figure 4: While generative models provide inconsistent inpainting results, the binary masks that can be extracted from these generated images are much more consistent.", "description": "This figure illustrates the inpainting process used in the Initialization Stage of the OccFusion method. It demonstrates that using a generative model to directly inpaint occluded human regions in an RGB image is unreliable, resulting in inconsistent results. However, inpainting the corresponding binary human mask produces much more consistent results. This is due to the fact that minor variations in human silhouette are less critical than variations in color and texture. The consistent binary masks obtained after this process are then used to provide reliable supervision in the subsequent stages of the OccFusion pipeline.", "section": "4.1 Initialization Stage: Recovering Human Geometry from Partial Observations"}, {"figure_path": "CZwphz5vgz/figures/figures_7_1.jpg", "caption": "Figure 5: Qualitative comparisons on simulated occlusions in the ZJU-MoCap dataset [44] (left column) and real-world occlusions in the OcMotion dataset [16]. ON denotes OccNeRF [64] and OGH denotes OccGauHuman.", "description": "This figure presents a qualitative comparison of the OccFusion model against other state-of-the-art methods on the ZJU-MoCap and OcMotion datasets.  The left side shows simulated occlusions from ZJU-MoCap, while the right shows real-world occlusions from OcMotion. Each column represents a different method: input (occluded view), OccNeRF (ON), OccGauHuman (OGH), OccFusion (Ours), and the reference (ground truth).  The results demonstrate that OccFusion produces more realistic and complete renderings of humans compared to other methods, especially in the presence of occlusions.", "section": "5 Experiments"}, {"figure_path": "CZwphz5vgz/figures/figures_8_1.jpg", "caption": "Figure 6: Qualitative ablation studies. Please see Table 2 for corresponding experiments. Major differences are highlighted by red arrows.", "description": "This figure shows a qualitative comparison of the ablation experiments presented in Table 2.  The left panel illustrates the results of experiments A-E on a person from the ZJU-MoCap dataset [44] in a relatively simple side pose. The right panel shows results from experiments B-D on a person from the OcMotion dataset [15] in a more challenging, spread-leg pose. Red arrows highlight the key differences between the results of each experiment, showing how each component contributes to improving the final reconstruction of the human. This figure visually demonstrates the importance of each stage in the OccFusion pipeline, highlighting the impact of the initialization, optimization and refinement stages in recovering complete human geometry from occluded observations.", "section": "5.3 Ablation Studies"}, {"figure_path": "CZwphz5vgz/figures/figures_9_1.jpg", "caption": "Figure 5: Qualitative comparisons on simulated occlusions in the ZJU-MoCap dataset [44] (left column) and real-world occlusions in the OcMotion dataset [16]. ON denotes OccNeRF [64] and OGH denotes OccGauHuman.", "description": "This figure presents a qualitative comparison of human rendering results on simulated and real-world occlusions using different methods.  The left side shows results from the ZJU-MoCap dataset with simulated occlusions, while the right side shows results from the OcMotion dataset with real-world occlusions.  Each column represents: Input (occluded human), GauHuman (GH), OccGauHuman (OGH), OccFusion (Ours), and Reference (Ref).  The figure visually demonstrates the superior performance of OccFusion in handling occlusions and generating high-quality renderings.", "section": "5.1 Datasets and Evaluation"}, {"figure_path": "CZwphz5vgz/figures/figures_16_1.jpg", "caption": "Figure 8: Comparison of the inpainted human in the Refinement Stage with and without using the proposed in-context inpainting technique. Major differences are highlighted with red arrows.", "description": "This figure compares the results of the Refinement Stage with and without using in-context inpainting. It showcases that the in-context inpainting method significantly improves the quality of the rendered human, especially in occluded areas.  The red arrows highlight the key differences between the two approaches, demonstrating how in-context inpainting effectively fills in missing details and creates a more realistic representation.", "section": "Additional Studies"}, {"figure_path": "CZwphz5vgz/figures/figures_16_2.jpg", "caption": "Figure 10: Training with complete vs. occluded masks vs. with in-painted masks in the Optim. stage. Although inpainted masks are slightly more inconsistent compared to the complete masks, our training pipeline converges to the same level of rendering quality.", "description": "This figure compares the results of training the OccFusion model with complete, occluded, and in-painted human masks. The results show that although using in-painted masks introduces some inconsistency compared to using complete masks, the final rendering quality remains largely unaffected. This demonstrates the robustness of the OccFusion method to variations in input data.", "section": "4.3 Refinement Stage: Refining Human Appearance via In-context Inpainting"}, {"figure_path": "CZwphz5vgz/figures/figures_17_1.jpg", "caption": "Figure 11: Novel view synthesis results from InstantMesh [65] conditioned on the least occluded frame. Discrepancies are circled in red.", "description": "This figure shows the results of novel view synthesis using InstantMesh, a method that conditions on the least occluded frame from a video sequence to reconstruct a complete 3D human model. The results highlight the discrepancies that still exist in the generated views, even after attempting to recover the missing parts from the least occluded frame.  The red circles highlight areas where the reconstruction is incomplete or inaccurate compared to the reference image.", "section": "5 Experiments"}, {"figure_path": "CZwphz5vgz/figures/figures_17_2.jpg", "caption": "Figure 11: Novel view synthesis results from InstantMesh [65] conditioned on the least occluded frame. Discrepancies are circled in red.", "description": "This figure shows the results of novel view synthesis using InstantMesh, a method that conditions on a single image.  The input image shows a person with significant occlusions. The results demonstrate that while InstantMesh can generate novel views, it struggles with the occluded regions, leading to inconsistencies such as missing or incomplete limbs. The red circles highlight areas where the model produces inaccurate or missing details.", "section": "5 Experiments"}]