{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023", "reason": "This paper is foundational to the work as it introduces GPT-4, a large language model that serves as inspiration and a point of comparison for the graph foundation model GFT."}, {"fullname_first_author": "Rishi Bommasani", "paper_title": "On the opportunities and risks of foundation models", "publication_date": "2021", "reason": "This paper provides a comprehensive overview of foundation models, which are central to the context and motivation of this research."}, {"fullname_first_author": "Yoshua Bengio", "paper_title": "Deep learning of representations for unsupervised and transfer learning", "publication_date": "2012", "reason": "This work is highly influential, providing foundational concepts of transfer learning, which is crucial to this paper's focus on creating transferable patterns in graph foundation models."}, {"fullname_first_author": "Thomas N. Kipf", "paper_title": "Semi-supervised classification with graph convolutional networks", "publication_date": "2017", "reason": "This paper is a seminal work in graph neural networks (GNNs), which are directly relevant to the development of the GFT model."}, {"fullname_first_author": "Franco Scarselli", "paper_title": "The vapnik-chervonenkis dimension of graph and recursive neural networks", "publication_date": "2018", "reason": "This paper delves into the theoretical aspects of graph neural networks, which is essential for understanding the generalization capabilities of the proposed GFT model."}]}