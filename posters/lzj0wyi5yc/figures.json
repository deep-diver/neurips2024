[{"figure_path": "lZJ0WYI5YC/figures/figures_2_1.jpg", "caption": "Figure 1: Correlation between Dice Score and Mutual Information. Classical registration methods like ANTs show a strong correlation between the Dice Score of registered pairs, and the mutual information between the corresponding image and label across 4 brain datasets.", "description": "This figure shows the strong correlation between the Dice Score (a measure of registration accuracy) and the mutual information (MI) between the image intensity and label maps for four different brain datasets. The Dice Score measures how well the automatically aligned labels match the ground truth labels, while the mutual information quantifies the amount of shared information between the image intensity and the labels. A higher mutual information indicates that the image intensity provides more information about the labels, leading to better registration accuracy. The strong correlation suggests that the performance of classical registration methods, which primarily rely on image intensity, is strongly linked to the amount of information the image provides about the labels. This suggests that simply improving the architecture of learning-based methods may not significantly improve the performance of such methods, as these architectures are unlikely to impact the underlying relationship between image intensities and labels.", "section": "2.2 Deep Learning for Image Registration"}, {"figure_path": "lZJ0WYI5YC/figures/figures_3_1.jpg", "caption": "Figure 2: Performance of classical and unsupervised DLIR methods on OASIS data. Boxplots (top) show that classical methods on average are ranked higher than DLIR methods, both on the trainval and val splits. Interestingly, the performance of unsupervised DLIR methods does not improve on the trainval split compared to val split - showing that deep learning does not have an intrinsic advantage in label alignment. Tables (bottom) of p-values show the results of a pairwise two-sided t-test between the performance of classical and DLIR methods on the trainval and val splits. denotes a cell where the classical method is significantly better than the DLIR method (p < 0.01), a denotes the opposite, denotes no significant difference. Most of the cells are indicating that classical methods are significantly better than DLIR methods.", "description": "This figure compares the performance of classical and unsupervised deep learning-based image registration (DLIR) methods on the OASIS dataset. The top part shows boxplots illustrating the Dice scores achieved by each method on both the train/validation split and the validation split. The bottom part presents a table of p-values obtained from pairwise two-sided t-tests comparing the performance of classical and DLIR methods.  The results indicate that classical methods generally outperform unsupervised DLIR methods, and the performance of unsupervised DLIR methods does not noticeably improve with more training data.", "section": "Contributions"}, {"figure_path": "lZJ0WYI5YC/figures/figures_7_1.jpg", "caption": "Figure 2: Performance of classical and unsupervised DLIR methods on OASIS data. Boxplots (top) show that classical methods on average are ranked higher than DLIR methods, both on the trainval and val splits. Interestingly, the performance of unsupervised DLIR methods does not improve on the trainval split compared to val split - showing that deep learning does not have an intrinsic advantage in label alignment. Tables (bottom) of p-values show the results of a pairwise two-sided t-test between the performance of classical and DLIR methods on the trainval and val splits. denotes a cell where the classical method is significantly better than the DLIR method (p < 0.01), a denotes the opposite, denotes no significant difference. Most of the cells are indicating that classical methods are significantly better than DLIR methods.", "description": "This figure compares the performance of classical and unsupervised deep learning-based image registration (DLIR) methods on the OASIS dataset. The top part shows box plots illustrating the Dice scores for different methods on both trainval (training and validation) and validation sets.  It highlights that classical methods generally outperform unsupervised DLIR methods.  The lack of improvement in unsupervised DLIR methods on the trainval set compared to the validation set suggests that deep learning doesn't inherently offer an advantage in label alignment in this unsupervised setting. The bottom part presents tables of p-values from pairwise two-sided t-tests comparing the performance of each classical method against each DLIR method on both datasets. The color-coding emphasizes which method performed significantly better in each comparison (classical or DLIR).  Most comparisons show classical methods significantly outperform DLIR methods.", "section": "4 Unsupervised DLIR does not improve label matching performance"}, {"figure_path": "lZJ0WYI5YC/figures/figures_8_1.jpg", "caption": "Figure 5: Classical methods retain robustness across different datasets. Boxplots show the performance of classical and DLIR methods trained on the OASIS dataset, on four T1-brain datasets. For DLIR methods, we plot the performance of the supervised and unsupervised models. Across all datasets, FireANTs and ANTs consistently outperform DLIR methods, showing robustness to domain shift. Among DLIR methods, SynthMorph and TransMorph show robust performance, and training with label matching objective does not lead to significant improvement.", "description": "This figure compares the performance of classical and deep learning-based image registration methods across four different brain datasets.  The methods were initially trained on the OASIS dataset.  The boxplots show the distribution of Dice scores, a measure of registration accuracy, for each method across datasets.  The results highlight the robustness of classical methods (FireANTS and ANTs) to domain shift, consistently outperforming deep learning methods even when the latter are trained with label supervision.", "section": "6 DLIR methods do not generalize across datasets"}]