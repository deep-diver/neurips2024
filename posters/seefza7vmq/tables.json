[{"figure_path": "SeefZa7Vmq/tables/tables_1_1.jpg", "caption": "Table 1: Main results: The average test accuracy (%) results with standard deviations from three runs (random seeds are set to 23, 1023, and 2023) of classification models trained on the UMT datasets", "description": "This table presents the average test accuracy results of 16 different classification models trained on point cloud datasets transformed using the proposed UMT (multi-class-wise transformation) method.  It shows the performance comparison between clean datasets and datasets with various levels of transformation (k=1, k=2, k=3, and k=4).  The results are presented for four different benchmark datasets (ModelNet40, ModelNet10, ShapeNetPart, and KITTI), highlighting the impact of the UMT method on model accuracy across diverse model architectures and datasets.  Standard deviations are included to indicate the reliability of the results.", "section": "4 Experiments"}, {"figure_path": "SeefZa7Vmq/tables/tables_6_1.jpg", "caption": "Table 1: Main results: The average test accuracy (%) results with standard deviations from three runs (random seeds are set to 23, 1023, and 2023) of classification models trained on the UMT datasets", "description": "This table presents the average test accuracy and standard deviation for 16 different 3D point cloud classification models trained on datasets protected by the proposed UMT (Unlearnable Multi-Transformation) framework. The table compares the performance of these models on four different datasets (ModelNet40, ModelNet10, ShapeNetPart, and KITTI), with results broken down by the number of transformations used (k=1, k=2, k=3, k=4).  The results showcase the impact of the UMT framework on model performance, demonstrating the effectiveness of the proposed method in hindering unauthorized training.", "section": "4 Experiments"}, {"figure_path": "SeefZa7Vmq/tables/tables_6_2.jpg", "caption": "Table 2: Robustness results: The test accuracy (%) results on UMT-ModelNet40 against pre-process schemes", "description": "This table presents the robustness of the proposed UMT (Unlearnable Multi-Transformation) framework against various pre-processing techniques.  It shows the test accuracy of the PointNet, PointNet++, DGCNN, PointCNN, CurveNet, SimpleView, RIConv++, 3DGCN, PointNN, and PointMLP models trained on the UMT-ModelNet40 dataset when different data augmentation or pre-processing methods (SOR, SRS, random rotation, random scaling, random jitter, and random rotation & scaling) are applied. The results demonstrate the effectiveness of the UMT framework in maintaining its unlearnable properties even after pre-processing.", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_7_1.jpg", "caption": "Table 3: Semantic segmentation: Evaluation of UMT on semantic segmentation task using S3DIS dataset", "description": "This table presents the results of applying the proposed Unlearnable Multi-Transformation (UMT) framework to the semantic segmentation task using the Stanford 3D Indoor Spaces dataset (S3DIS). It compares the performance of different segmentation models (PointNet++, Point Transformer v3, and SegNN) on clean data versus data transformed using the UMT method.  The evaluation metrics used are evaluation accuracy and mean Intersection over Union (mIoU), which measure the correctness and completeness of the segmentation results.  The table aims to show the effectiveness of UMT in protecting point cloud data by significantly reducing the performance of trained models on the transformed data. ", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_7_2.jpg", "caption": "Table 1: Main results: The average test accuracy (%) results with standard deviations from three runs (random seeds are set to 23, 1023, and 2023) of classification models trained on the UMT datasets", "description": "This table presents the average test accuracy results achieved by various classification models trained on the UMT (Unlearnable Multi-Transformation) datasets. The results are categorized by dataset (ModelNet40 and ModelNet10), transformation level (k=1, k=2, k=3, k=4), and model.  Standard deviations are included to reflect the variability in the results across three independent runs.  The table shows the performance drop when using UMT-processed data compared to clean data, demonstrating the effectiveness of the UMT approach.", "section": "4 Experiments"}, {"figure_path": "SeefZa7Vmq/tables/tables_16_1.jpg", "caption": "Table 5: The test accuracy (%) results on diverse types of transformations on ModelNet10 training set using PointNet classifier", "description": "This table presents the test accuracy achieved using a PointNet classifier trained on ModelNet10 datasets with different transformation methods. It compares the performance of three transformation patterns: sample-wise, dataset-wise, and class-wise, along with a baseline without any transformations. The results show that the class-wise transformation significantly reduces the test accuracy, indicating that it makes the data unlearnable.", "section": "Supplementary Experimental Settings"}, {"figure_path": "SeefZa7Vmq/tables/tables_16_2.jpg", "caption": "Table 6: Accuracy results obtained with different test sets when training the PointNet classifier using class-wise transformed training sets", "description": "This table shows the test accuracy results obtained from training a PointNet classifier using class-wise transformed training data and testing on three different test sets: a class-wise test set (using consistent transformation parameters with the training set), a permuted class-wise test set (transformation parameters permuted), and a clean test set (no transformations).  It demonstrates that the model learns the mapping between transformations and labels resulting in high accuracy on the consistent test set. However, accuracy drops significantly when the test set's transformations are permuted or when testing on a clean test set.", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_18_1.jpg", "caption": "Table 7: The test accuracy (%) results obtained from training the point cloud classifiers PointNet, PointNet++, DGCNN, PointCNN, PCT using a ModelNet10 dataset generated with diverse combinations of transformations under a class-wise setting, where R, S, H, and W correspond to rotation, scaling, shear, and twisting respectively", "description": "This table presents the test accuracy results achieved using five different point cloud classifiers (PointNet, PointNet++, DGCNN, PointCNN, PCT) trained on a ModelNet10 dataset.  The dataset was generated using various combinations of class-wise transformations (rotation, scaling, shear, and twisting). Each row represents a unique combination of transformations, showing the average accuracy across the five classifiers for that specific combination.  This illustrates the impact of different class-wise transformation combinations on model performance.", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_18_2.jpg", "caption": "Table 8: The test accuracy (%) results with standard deviations from three runs (random seeds are set to 23, 1023, and 2023) obtained from training the point cloud classifiers PointNet, PointNet++, DGCNN, and PointCNN using a ModelNet10 dataset generated with diverse two class-wise transformations", "description": "This table presents the test accuracy results obtained from training four different point cloud classifiers (PointNet, PointNet++, DGCNN, and PointCNN) on a ModelNet10 dataset. The dataset was generated using diverse combinations of two class-wise transformations. The results are averages from three runs with different random seeds (23, 1023, and 2023), and standard deviations are also reported.", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_19_1.jpg", "caption": "Table 9: The accuracy (%) results on clean and UMT ModelNet10 training set and test set using four point cloud classifiers. Higher accuracy values correspond to lower cross-entropy loss values.", "description": "This table presents the test accuracy results obtained using four different point cloud classifiers (PointNet, PointNet++, DGCNN, PointCNN).  The accuracy is measured under four different scenarios: (1) training and testing on clean data, (2) training on clean data and testing on UMT (unlearnable) data, (3) training on UMT data and testing on clean data, and (4) training and testing on UMT data.  Higher accuracy indicates a lower cross-entropy loss, suggesting better model performance. The results highlight the effectiveness of the UMT method in making the data unlearnable for unauthorized users.", "section": "4.4 Insightful Analysis Into UMT"}, {"figure_path": "SeefZa7Vmq/tables/tables_19_2.jpg", "caption": "Table 10: Test accuracy (%) results using UMT training data and UMT data employing random augmentations", "description": "This table presents the test accuracy results obtained using UMT training data and UMT data with random augmentations. It shows the effectiveness of UMT against adaptive attacks by comparing the accuracy of different models (PointNet, PointNet++, DGCNN, PointCNN) on clean baseline data, UMT data (k=4), and UMT data (k=4) with random RSHW augmentations. The results indicate that the UMT scheme is robust against adaptive attacks.", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_20_1.jpg", "caption": "Table 3: Semantic segmentation: Evaluation of UMT on semantic segmentation task using S3DIS dataset", "description": "This table presents the results of the proposed Unlearnable Multi-Transformation (UMT) method on a semantic segmentation task using the S3DIS dataset.  It compares the performance of different segmentation models (PointNet++, Point Transformer V2, and SegNN) on both a clean baseline and data processed by the UMT method (k=2, RS). The evaluation metrics used are Eval Accuracy and mIoU, which are common metrics used in evaluating semantic segmentation performance. The data shows the significant reduction in segmentation accuracy after applying the UMT data protection scheme.", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_20_2.jpg", "caption": "Table 12: Test accuracy (%) results using UMT training data to train the SE(3)-Transformer", "description": "This table presents the test accuracy results obtained when using data protected by the UMT scheme to train the SE(3)-Transformer model.  It compares the performance of the model trained on clean data against the performance achieved when training on data that has undergone various UMT transformations (using different combinations of transformations). The results highlight the effectiveness of the UMT framework in reducing the accuracy of unauthorized models.", "section": "4 Experiments"}, {"figure_path": "SeefZa7Vmq/tables/tables_21_1.jpg", "caption": "Table 13: The test accuracy (%) results on ModelNet10 dataset with a boarder range of hype-parameters rs, rp, b\u2081, bu", "description": "This table presents the test accuracy results obtained from experiments on the ModelNet10 dataset using PointNet, DGCNN, and PointCNN classifiers.  The experiments were conducted with a broader range of hyperparameters (rs, rp, b\u2081, bu) than those used in the main experiments, to analyze the sensitivity of the unlearnable scheme to these hyperparameters. Each row represents a different combination of these parameters.  The table aims to demonstrate the robustness of the unlearnable method across a range of parameter settings.", "section": "4.3 Ablation Study and Hyper-Parameter Sensitivity Analysis"}, {"figure_path": "SeefZa7Vmq/tables/tables_22_1.jpg", "caption": "Table 15: Mixture results: The test accuracy (%) results achieved by training on the mixture data consisting of class-wise UMT samples and sample-wise UMT samples", "description": "This table presents the test accuracy results obtained from training on mixture data that combines class-wise UMT samples and sample-wise UMT samples.  The varying proportions of class-wise to sample-wise data (from 20% to 100%) are tested, and the accuracy results across four point cloud models (PointNet, PointNet++, DGCNN, PointCNN) are shown. The results demonstrate how the proportion of class-wise samples affects the test accuracy.", "section": "4.2 Evaluation of Proposed Unlearnable Schemes"}, {"figure_path": "SeefZa7Vmq/tables/tables_26_1.jpg", "caption": "Table 16: Different \u03b2\u2081 values and corresponding g(t) with t = 0.3 and t = 0.4. The bold values represent cases where p\u2081 < \u00bd is satisfied.", "description": "This table shows the results of evaluating the function g(t) with different values of \u03b2\u2081 and t (0.3 and 0.4). The function g(t) is part of the proof for Lemma 5, which bounds the accuracy of the unlearnable decision boundary.  The bold values highlight cases where the inequality p\u2081 < \u00bd holds true, a crucial element in establishing the unlearnable nature of the proposed method.", "section": "D.3 Proof for Lemma 5"}, {"figure_path": "SeefZa7Vmq/tables/tables_26_2.jpg", "caption": "Table 17: Different \u03b22 values and corresponding h(t) with t = 0.3 and t = 0.4. The bold values represent cases where p2 < 1/2 is satisfied.", "description": "This table presents the results of calculating the function h(t) with different values of \u03b22 and t (0.3 and 0.4). The function h(t) is used in the proof of Lemma 5, which provides an upper bound on the accuracy of the unlearnable decision boundary. The bold values highlight cases where the condition p2 < 1/2, a crucial component of Theorem 6 is met, indicating the unlearnable effect.", "section": "D Proofs for Theories"}]