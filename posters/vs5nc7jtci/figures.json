[{"figure_path": "vS5NC7jtCI/figures/figures_1_1.jpg", "caption": "Figure 1: Qualitative and quantitative analyses of semantic misalignment between OOD labels and negative proxies using ImageNet (ID) and SUN (OOD) datasets. (a) Visualization of ID labels, OOD labels, negative labels from NegLabel, and adaptive negative proxies (AdaNeg). (b) Quantitative analysis based on ID-Similarity to OOD Ratio (ISOR in short, see Appendix A.1). Lower ISOR indicates a higher similarity to OOD labels and reduced similarity to ID labels. AdaNeg consistently achieves lower ISOR, demonstrating enhanced alignment with OOD characteristics. Visualizations include the top 1,000 discriminative proxies from both NegLabel and AdaNeg.", "description": "This figure demonstrates the misalignment issue between existing negative proxies (NegLabel) and actual OOD data, and how the proposed AdaNeg method addresses this issue.  The t-SNE visualization (a) shows that AdaNeg proxies are closer to the actual OOD samples than NegLabel proxies. The histogram (b), showing the ID-Similarity to OOD Ratio (ISOR), quantitatively supports this finding; AdaNeg consistently achieves lower ISOR values, indicating better alignment with OOD characteristics.", "section": "1 Introduction"}, {"figure_path": "vS5NC7jtCI/figures/figures_3_1.jpg", "caption": "Figure 2: The overall framework of AdaNeg, where we selectively cache test images and generate adaptive proxies with an external feature memory bank. The final score combines textual and visual knowledge from static negative labels and our adaptive proxies, integrating multi-modal information.", "description": "This figure illustrates the AdaNeg framework. It starts with a test image, which is processed by an image encoder to get image features. These features, along with features from a text encoder processing ID and negative labels, are used to generate a multi-modal score for OOD detection. A key component is the feature memory bank, which selectively caches discriminative features from test images to dynamically generate adaptive negative proxies, improving OOD detection accuracy.  The memory bank updates without requiring further optimization during testing. ", "section": "3 Methodology"}, {"figure_path": "vS5NC7jtCI/figures/figures_8_1.jpg", "caption": "Figure 3: Analyses on the hyper-parameters of (a) threshold \u03b3 in Eq. 8, (b) gap value g in Eq. 8, and (c) memory length L on the ImageNet dataset under OpenOOD setting.", "description": "The figure shows the impact of three hyperparameters (threshold \u03b3, gap value g, and memory length L) on the performance of the AdaNeg model for out-of-distribution (OOD) detection on the ImageNet dataset.  Each subfigure displays the AUROC (Area Under the Receiver Operating Characteristic curve) for both near-OOD and far-OOD datasets as a function of the hyperparameter.  This helps to determine optimal values for these hyperparameters that balance performance across near and far OOD scenarios.", "section": "4 Experiments"}, {"figure_path": "vS5NC7jtCI/figures/figures_16_1.jpg", "caption": "Figure 3: Analyses on the hyper-parameters of (a) threshold \u03b3 in Eq. 8, (b) gap value g in Eq. 8, and (c) memory length L on the ImageNet dataset under OpenOOD setting.", "description": "This figure analyzes the impact of three hyperparameters (threshold \u03b3, gap value g, and memory length L) on the performance of the AdaNeg method for out-of-distribution (OOD) detection using the ImageNet dataset.  Each subplot shows how AUROC and FPR95 vary as the corresponding hyperparameter changes, providing insights into their optimal settings for different OOD scenarios.  The results suggest that moderate values of \u03b3, appropriately tuned gap values based on OOD difficulty (near vs. far), and a sufficient memory length are important for achieving optimal performance.", "section": "4 Experiments"}]