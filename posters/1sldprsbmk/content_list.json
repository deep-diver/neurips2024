[{"type": "text", "text": "Can Models Learn Skill Composition from Examples? ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Haoyu Zhao1,2 Simran Kaur1,2 Dingli $\\mathbf{Y_{u}}^{1,2}$ Anirudh Goyal3 Sanjeev Arora1,2 ", "page_idx": 0}, {"type": "text", "text": "1 Department of Computer Science, Princeton University 2 Princeton Language and Intelligence (PLI), Princeton University 3 Meta {haoyu,arora}@cs.princeton.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As large language models (LLMs) become increasingly advanced, their ability to exhibit compositional generalization\u2014the capacity to combine learned skills in novel ways not encountered during training\u2014has garnered significant attention. This type of generalization, particularly in scenarios beyond training data, is also of great interest in the study of AI safety and alignment. ", "page_idx": 0}, {"type": "text", "text": "A recent study introduced the SKILL-MIX [33] evaluation, where models are tasked with composing a short paragraph demonstrating the use of a specified $k$ -tuple of language skills. While small models struggled with composing even with $k=3$ , larger models like GPT-4 performed reasonably well with $k=5$ and 6. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we employ a setup akin to SKILL-MIX to evaluate the capacity of smaller models to learn compositional generalization from examples. Utilizing a diverse set of language skills\u2014including rhetorical, literary, reasoning, theory of mind, and common sense\u2014\u2013GPT-4 was used to generate text samples that exhibit random subsets of $k$ skills. Subsequent fine-tuning of 7B and 13B parameter models on these combined skill texts, for increasing values of $k$ , revealed the following findings: ", "page_idx": 0}, {"type": "text", "text": "\u2022 Training on combinations of $k=2$ and 3 skills results in noticeable improvements in the ability to compose texts with $k=4$ and 5 skills, despite models never having seen such examples during training. \u2022 When skill categories are split into training and held-out groups, models significantly improve at composing texts with held-out skills during testing despite having only seen training skills during fine-tuning, illustrating the efficacy of the training approach even with previously unseen skills. ", "page_idx": 0}, {"type": "text", "text": "This study also suggests that incorporating skill-rich (potentially synthetic) text into training can substantially enhance the compositional capabilities of models. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Today\u2019s large language models (LLMs) exhibit many impressive skills but remain imperfect in key areas. Arguably, one significant limitation stems from their difficulty in combining or composing the skills they have already learned. For example, solving a math problem on a specific topic may require a certain set of skills, while solving a more challenging question may require applying broader combinations of more skills as compared to a simple question. Understanding how well models can learn to compose skills with limited training examples is therefore a crucial area of investigation. ", "page_idx": 0}, {"type": "text", "text": "Let us note why this is a nontrivial challenge. If a model has learned $N$ base skills, and we want it to be able to compose any subset of $k$ skills, there are $\\binom{N}{k}$ possible combinations of interest. Since $\\binom{N}{k}$ scales roughly with the $k$ -th power of $N$ , even reasonable-sized training datasets will likely omit examples of many skill combinations. As a result, the model must be capable of generalizing to unseen combinations of skills. ", "page_idx": 0}, {"type": "image", "img_path": "1sLdprsbmk/tmp/8c08c2eb09ec7c3c65f7e8f0c033306f9f386cf3dad9b7c15d5fd60067e2062a.jpg", "img_caption": ["Figure 1: Pipeline for evaluating the generalization capability to combine skills. We split the language skill set $\\boldsymbol{S}$ from [33] into training skills $S_{\\mathrm{train}}$ and held-out skills $S_{\\mathrm{held-out}}$ , and the topic set $\\tau$ into training topics $\\tau_{\\mathrm{rain}}$ and held-out topics $\\mathcal{T}_{\\mathrm{held-out}}$ . The pipeline consists of three steps: (1) generate data by prompting GPT-4. The training texts contain only training skills $S_{\\mathrm{train}}$ and training topics $\\tau_{\\mathrm{rain}}$ , and each text exhibits at most 3 skills; (2) fine-tune LLaMA-2-13B-Chat and Mistral-7B-Instruct- $\\cdot\\mathrm{v}0.2$ using the generated data; (3) evaluate the fine-tuned models on held-out skills $S_{\\mathrm{held-out}}$ and held-out topics $\\mathcal{T}_{\\mathrm{held-out}}$ with the number of requested skills being as large as 5. See our detailed setups in Section 3. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "This issue was highlighted in [1], which introduced a simple mathematical framework to demonstrate that current LLM scaling laws [13] suggest scaling up models can enhance their ability to combine $k$ skills\u2014though the ability increases only gradually with model size. This prediction was validated through the SKILL-MIX evaluation [33], which directly tested models\u2019 capability to combine $k$ language skills that were listed in the model\u2019s prompt (see Section 2 for details). The evaluation revealed that top-tier models like GPT-4 could successfully combine 5 or 6 language skills when composing a short piece of text, whereas smaller models like LLaMA-2-70B-Chat struggled to combine even 3 skills. ", "page_idx": 1}, {"type": "text", "text": "This finding of SKILL-MIX evaluation raises an interesting question: even if pre-training does not fully endow models with the ability to combine skills, can the capability be induced through fine-tuning on suitable data? The current paper investigates this question within the context of the language skills explored in the SKILL-MIX evaluation [33]. ", "page_idx": 1}, {"type": "text", "text": "1.1 Our contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We address the question posed above by fine-tuning smaller models, including LLaMA-2-13B-Chat and Mistral-7B-Instruct-v0.2, using a small yet high-quality dataset generated by GPT-4. This dataset consists of 13,957 text pieces, each composed of randomly selected $k$ skills with $k=1,2,3$ . We evaluate the capability of the fine-tuned models to combine an another set of held-out skills with potentially higher $k$ . In particular, we divide the original SKILL-MIX [33] skill set into a training set and a held-out set, based on skill categories, to minimize correlations between the two groups. This ensures a clearer evaluation of the models\u2019 ability to generalize to unseen skills. Figure 1 and Section 3 detail the full pipeline of our data generation and evaluation process. Our experimental results demonstrate the following findings (Section 4). ", "page_idx": 1}, {"type": "text", "text": "Finding 1: Fine-tuning on texts that compose training skills improves capabilities of composing held-out skills. Figure 2 shows the success rate of various models of combining $k$ held-out skills. Before fine-tuning, LLaMA-2-13B-Chat and Mistral-7B-Instruct- $\\cdot\\mathrm{v}0.2$ perform significantly worse than GPT-4, especially when $k>2$ . Both models improve remarkably after fine-tuning on our small dataset. For example, with $k=3$ , the success rate of LLaMA-2-13B-Chat increases from $4\\%$ to $37\\%$ , and the success rate of Mistral-7B-Instruct-v0.2 increases from $8\\%$ to $49\\%$ . Note in the original SKILL-MIX, no model except GPT-4 could reach $15\\%$ success rate for $k=3$ (see Table 3, [33]). ", "page_idx": 1}, {"type": "image", "img_path": "1sLdprsbmk/tmp/fb048d780dba3b309d9ccfdd8735c8b8087d446510d961f85d90cc356e80e2b3.jpg", "img_caption": ["Figure 2: The success rate of different models to compose $k$ held-out skills in a short paragraph. (See the detailed definition of \u201cRatio of Full Marks\u201d in Section 3.3.) The strongest model like GPT-4 can compose 5 skills in a short paragraph reasonably well, while smaller models struggle to compose even 3 skills. After fine-tuning, the models\u2019 ability to compose skills improves significantly. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "This phenomenon of compositional generalization from training skills to held-out skills suggests that the models are not merely learning to compose each individual combination of skills. Instead, they are acquiring a higher-order meta-skill that allows them to generalize and apply to combine unseen skills. ", "page_idx": 2}, {"type": "text", "text": "Finding 2: Fine-tuning on texts that compose a smaller number of skills leads to improvement of composing a larger number of skills. Figure 2 demonstrates that fine-tuning on our small dataset, which includes texts composed of $k\\,=\\,1,2$ or 3 training skills, leads to enhanced capability on composing $k=4$ and 5 held-out skills, even though the models have never trained on such text. In Section 4, we present similar findings: (1) the ability to compose $k$ training skills is also improved for $k=4$ and 5 after fine-tuning; and (2) if models are fine-tuned exclusively with texts composed of no more than 2 training skills, they also show improved composition ability for 3 and 4 skills. ", "page_idx": 2}, {"type": "text", "text": "Note Finding 1 and Finding 2 are beyond the scope of the theory presented in Arora and Goyal [1], which studies the composition ability for skills that appear in the training data. ", "page_idx": 2}, {"type": "text", "text": "Finding 3: Fine-tuning on texts that compose more skills (i.e., with a larger $k$ ) is more data-efficient for learning skill compositions. We design control experiments in Section 4.3 that fine-tune LLaMA2-13B-Chat on two datasets: (a) one dataset contains around 10,000 text pieces with only 1 or 2 skills; and (b) another dataset contains 8,000 text pieces, consisting of a random subset of the first dataset and around 2,000 text pieces that compose 3 skills. Table 4 shows that LLaMA-2 fine-tuned on the dataset with richer skill composition performs significantly better than the other for all $k=2,3,4,5$ . ", "page_idx": 2}, {"type": "text", "text": "We discuss our main findings thoroughly in Section 4. In Section 5.1, we solidify our findings using Claude 3 Opus (instead of GPT-4) as the Grader in evaluation. This eliminates the possibility that the ability to compose skills comes from GPT-4\u2019s bias towards the models fine-tuned on GPT-4\u2019s outputs ", "page_idx": 2}, {"type": "text", "text": "We also discuss the implications of our findings for going beyond \u201cstochastic parrots\u201d behavior [2], which refers to the perception that LLMs might not generate novel pieces of text but rather mimic data from the pretraining corpus (Section 5.2). ", "page_idx": 2}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Compositional generalization Compositional generalization has grabbed lots of attention in AI. [29, 27] studied compositional generalization in the realm of mathematical reasoning, and [3, 22] investigated for logical inference. In computer vision, compositional generalization was studied on disentangled representation learning to generate images from novel combinations of concepts [12, 10, 31]. Besides, several works have explored composing visual relations [20], as well as benchmarks for text-to-visual generation[14, 19]. Other works have explored using compositional models for image generation [7] , as well as to create plans for unseen tasks at inference time [6]. ", "page_idx": 2}, {"type": "text", "text": "Compositional generalization for language and LLMs There is also a long history of study of compositional generalization in language [11, 18, 4, 15, 17, 21]. However, the test bed for compositional generalization mostly relies on rule-based languages, like SQL or synthetic-generated ones, and thus deviates a little bit from natural language. Recent works have observed compositional capabilities in LLMs emerge multiplicatively on natural languages [30, 1, 23, 33]. These observations have fueled a growing interest in exploring and evaluating compositional generalization in LLMs as a means to more appropriately evaluate LLM capabilities [9, 32, 24, 26, 33]. Some examples include imposing constraints and/or requirements on text generation [9, 32, 5], as well as providing multi-hop questions whose answers require composing multiple facts that were individually observed during pretraining [26]. Dziri et al. [8] tests whether the LLMs can learn compositional generalization by studying integer multiplication and a specific form of dynamic programming. Skill-Mix [33] presents an approach to evaluating compositional generalization on language skills, which we discuss in more detail in the next paragraph. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Skill-Mix $\\mathrm{Yu}$ et al. [33] introduce a new evaluation named SKILL-MIX that tests for models to produce novel pieces of text from random combinations of $k$ skills, and the evaluation can be made more difficult by increasing the value of $k$ . The procedure is roughly as follows: (1) from a set of $N$ language skills and $T$ topics, pick a random subset of $k$ skills and one topic; then, (2) query the Student model to produce a short piece of text (at most $k-1$ sentences) that illustrates the $k$ skills in the context of the provided topic. Note that for $k=1$ , the maximum sentence limit is 1 sentence. A Grader model is used to evaluate the text piece based on the following criteria: correctly illustrating all $k$ skills and the topic, meeting the maximum length requirement, and general coherence. Thus, each piece of text can award up to a maximum of $k+3$ points (see the original paper for various metrics extracted from points earned). Note that each of the $N$ language skills has a Wikipedia entry, so it is reasonable to expect an LLM to encounter the skills multiple times in isolation in the pretraining corpus, but not in all possible combinations. In this paper, we choose to study the compositional generalization of LLMs in the context of SKILL-MIX because SKILL-MIX is close to general language capability and is more flexible for modifying the language skill set. ", "page_idx": 3}, {"type": "text", "text": "3 Pipeline ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our pipeline consists of three stages: generating data by selecting GPT-4 responses on SKILL-MIX (Section 3.1), fine-tuning on the generated data (Section 3.2), and evaluating our fine-tuned model on SKILL-MIX evaluation [33] (Section 3.3). The pipeline overview is shown in Figure 1. ", "page_idx": 3}, {"type": "text", "text": "3.1 Data generation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We adapt the procedure presented in SKILL-MIX evaluation [33] to produce finetuning data. Only the generations with full marks (i.e., illustrating all skills and topics, meeting the length requirement, and general coherence) are selected. To enhance the likelihood of obtaining full marks, we prompt GPT-4, the best Student model reported in Yu et al. [33], to create the generations. ", "page_idx": 3}, {"type": "text", "text": "Skills and topics for data generation. Since our goal is to measure the generalization capability strictly, we minimize the overlap between the skills/topics used during data generation and the skills/topics used to evaluate the fine-tuned models. Specifically, we partition the original set of 101 skills introduced in $\\mathrm{Yu}$ et al. [33], $\\boldsymbol{S}$ , into a set of 53 train skills, $\\ensuremath{S_{\\mathrm{train}}}$ , and 48 held-out skills, $S_{\\mathrm{held-out}}$ , based on the skill category. $\\ensuremath{S_{\\mathrm{train}}}$ includes only literary and rhetorical categories, while $S_{\\mathrm{held-out}}$ comprises the rest of the categories, including reasoning, logic, theory of mind, pragmatics, common sense, and physical knowledge. Similarly, we partition the original set of topics, $\\tau$ , into random sets of 50 training topics, $\\tau_{\\mathrm{rain}}$ , and 50 held-out topics, $\\mathcal{T}_{\\mathrm{held-out}}$ . It is important to note that partitioning skills randomly can lead to correlations between the train and held-out skills, as skills from the same category can be highly related. However, partitioning topics randomly does not present this issue, as the topics are generally unrelated. (Please refer to Appendix A for the detailed list of skills and topics.) ", "page_idx": 3}, {"type": "text", "text": "Data generation with $k=1,2,3$ . We produce fine-tuning data with $k=1,2$ and 3 using GPT-4 as both the Student and Grader model. For $k=1$ , we use the original set of skills $\\boldsymbol{S}$ and training topics $\\tau_{\\mathrm{rain}}$ to produce approximately 5,000 generations, and we only keep generations that receive full marks. We refer to the resulting dataset as $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ . $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ contains only texts with individual skills, thus serving the role of separating the improvement from better utilizing an individual skill and the improvement from better composing multiple skills in later experiments. ", "page_idx": 3}, {"type": "text", "text": "We follow an analogous procedure for $k\\,=\\,2$ and $k\\,=\\,3$ , but using our 53 training skills $S_{\\mathrm{train}}$ and 50 training topics $\\tau_{\\mathrm{rain}}$ . We produce 10,000 generations for each $k$ before filtering. We refer to the resulting datasets as $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(2)$ and $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(3)$ , respectively. For convenience, we use $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2)$ to denote the dataset that combines $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ and $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(2)$ , i.e., $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2)=\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)\\cup\\mathcal{D}_{\\mathrm{SKILL-MIX}}(2).$ . Similarly, we use $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ to denote the dataset that combines $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ , $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(2)$ , and $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(3)$ together. We summarize our notations in Table 1. ", "page_idx": 3}, {"type": "table", "img_path": "1sLdprsbmk/tmp/63bc73171520bee0797c7fc73569c244fa650aa9c6322cfa3451a73ee8d43d6a.jpg", "table_caption": ["Table 1: Notation used in data generation (Section 3.1) "], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "3.2 Fine-tuning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We fine-tune LLaMA-2-13B-Chat [28] and Mistral-7B-Instruct-v0.2 [16] on the data generated in Section 3.1 for 4000 steps with a batch size of 64. Each data generated from SKILL-MIX consists of 4 parts: PROMPT1, ANSWER1, PROMPT2, ANSWER2. Here, PROMPT1 denotes the prompt asking the student to generate answers, ANSWER1 stands for student\u2019s first round answer, PROMPT2 is the prompt that asks the student to correct or refine its answer, and ANSWER2 is the student\u2019s second round answer. During fine-tuning, we feed the concatenation of PROMPT1, ANSWER1, PROMPT2, ANSWER2 into the model as a single text, but only compute the cross-entropy loss for tokens belonging to ANSWER1 and ANSWER2. We use Adam as the optimizer and linear warmup for the first 64 steps, followed by a constant learning rate of 2e-5 for the remaining training steps. The maximum token length is set as 1024. All fine-tuning experiments are conducted on 4 Nvidia H100/A100 GPUs. Similarly to the loss design of RLHF [25], we mix pre-training data2 during fine-tuning to prevent degradation of general abilities. ", "page_idx": 4}, {"type": "text", "text": "3.3 Evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We evaluate the SKILL- $\\mathrm{{MIX}}(k)$ performance $\\langle k=2,3,4,5\\rangle$ ) for all the models fine-tuned on data generated in Section 3.1, i.e., $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ , $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(2)$ , and $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(3)$ . ", "page_idx": 4}, {"type": "text", "text": "Settings As mentioned earlier, SKILL-MIX evaluation requires a skill set and a topic set. We consider the following 3 settings (where Setting $\\mathrm{II}$ is our main setting used in Figure 1): ", "page_idx": 4}, {"type": "text", "text": "I. SKILL-MIX evaluation on training skills and topics. Since the model observes the same skills and topics during fine-tuning, this setting serves as an in-domain evaluation for $k=2,3$ . For $k=4,5$ , it tests the models\u2019 ability to combine more skills, which is already out-ofdomain, since the model has never seen such data during fine-tuning. We use the notation SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(k)$ to denote the SKILL-MIX $(k)$ evaluation on training skills and topics. ", "page_idx": 4}, {"type": "text", "text": "Table 2: Performance of fine-tuned LLaMA-2-13B-Chat on SKILL-MIX $(k)$ graded by GPT-4 in various settings. Ratio of Full Marks/Skills Fraction are reported for each model at different $k=$ $2,3,4,5$ . $\\bar{D_{\\mathrm{SKILL-MIX}}(k)}$ denote the data generated with full SKILL-MIX $(k)$ score. (see Section 3.1) ", "page_idx": 5}, {"type": "table", "img_path": "1sLdprsbmk/tmp/4ec35fac3e447eac864b2a41468ddad22ffba1383c3e5fc0e081cd13c16822c2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "II. SKILL-MIX on held-out skills and topics. This setting tests the models\u2019 ability to combine skills that are never present in fine-tuning.3 This setting serves as another perspective to show the stronger out-of-domain generalization for composing skills compared to Setting I. We use the notation $\\mathsf{S K I L L-M I X_{h e l d-o u t}}(k)$ to denote the SKILL- $\\mathrm{MIX}(k)$ evaluation on held-out skills and topics. ", "page_idx": 5}, {"type": "text", "text": "III. SKILL-MIX on all skills and topics. Evaluating SKILL-MIX on only half of the skills split by category might make the evaluation easier, since combining 2 rhetorical or logical skills might be easier than combining 1 rhetorical and 1 logical skill. Thus, we also evaluate SKILL-MIX on all skills and topics available, which serves as a direct comparison with the results in Yu et al. [33]. We use the notation SKILL- $\\mathrm{MIX_{all}}(k)$ to denote the SKILL-MIX $(k)$ evaluation on all skills and topics. ", "page_idx": 5}, {"type": "text", "text": "Evaluation Metrics We follow the evaluation rubric of SKILL-MIX. Each generated text can receive up to $k+3$ points: 1 point for each correctly illustrated skill, 1 point for sticking to the topic, 1 point for text coherence / making sense, and 1 point for meeting the length requirement. ", "page_idx": 5}, {"type": "text", "text": "Following Yu et al. [33], we grade each generated piece of text three times. For each of the $k+3$ criteria, we collect the majority vote among the three grading rounds, and map the points earned to the following two metrics of interest 4: (Ratio of Full Marks) count as 1 if all $k\\!+\\!3$ points are earned, and 0 otherwise; and (Skills Fraction) the fraction of points awarded for the $k$ skills if all 3 points are awarded for the remaining criteria, and 0 otherwise. For a given ( $k$ skill, 1 topic) combination, we take the maximum value of the metric among the 3 generations. We average the maximum value across all the combinations. Note that we use one of the harder variants of SKILL-MIX [33], where we do not award any points for a particular skill if the skill name is explicitly mentioned in the generated text piece. ", "page_idx": 5}, {"type": "text", "text": "4 Skill Composition Can Be Learned From Examples ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We present experiment results using the pipeline (Section 3) to evaluate compositional generalization. Table 2 and Table 3 summarizes the SKILL-MIX $(k)$ performances of LLaMA-2-13B-Chat and Mistral-7B-Instruct-v0.2 fine-tuned on various datasets under three evaluation settings. We discuss our findings on compositional generalization for in-domain evaluations (Section 4.1), compositional generalization for out-of-domain evaluations (Section 4.2), and the data efficiency to induce compositional generalization (Section 4.3). ", "page_idx": 5}, {"type": "text", "text": "Table 3: Performance of fine-tuned Mistral-7B-Instruct-v0.2 on SKILL-MIX $(k)$ graded by GPT-4 in various settings. Ratio of Full Marks/Skills Fraction are reported for each model at different $k=$ $2,3,4,5$ . $\\bar{D_{\\mathrm{SKILL-MIX}}(k)}$ denote the data generated with full SKILL-MIX $(k)$ score. (see Section 3.1) ", "page_idx": 6}, {"type": "table", "img_path": "1sLdprsbmk/tmp/37ab8c012ac2c590ec9e41d3b9ed78ba374f2a8a8d664fa93d48ad74ec49d695.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "4.1 Compositional generalization for in-domain evaluations ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We first observe that, after fine-tuning LLaMA-2-13B-Chat on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2)$ , the SKILL- $\\mathrm{MIX}_{\\mathrm{train}}$ (2) performance significantly improves. Similarly, after fine-tuning LLaMA-2-13B-Chat on $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ , the SKILL- $\\mathrm{MIX}_{\\mathrm{train}}(3)$ performance also improves. For example, the Ratio of Full Marks for SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(3)$ improves from $2\\%$ for LLaMA-2-13B-Chat to $24\\%$ after fine-tuned on $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ (Table 2). ", "page_idx": 6}, {"type": "text", "text": "One confounding factor in the above evaluation is that the original LLaMA-2-13B-Chat may not utilize all the individual skills perfectly, and the SKILL-MIX performance improvement might just be attributed to the model\u2019s knowledge of the individual skills after fine-tuning, not the model\u2019s ability to better compose different skills together. Thus, we also evaluate the SKILL-MIX performance on LLaMA-2-13B-Chat fine-tuned only on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ , which consists of purely SKILL-MIX $k=1$ data and serves as another baseline besides the original LLaMA-2-13B-Chat. After fine-tuning on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ , the model indeed knows the individual skills much better, since the Ratio of Full Marks of SKILL-MIX $k=1$ improves from $52\\%$ to $87\\%$ . However, better knowledge of individual skills does not lead to a better ability to compose skills together, since the SKILL- $\\mathrm{MIX}_{\\mathrm{train}}(2)$ or SKILL- $\\mathrm{MIX}_{\\mathrm{train}}(3)$ performance of LLaMA-2-13B-Chat fine-tuned on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ keeps nearly the same as the pre-trained ones, under both Ratio of Full Marks and Skills Fraction metrics. Thus, mainly all the improvement on SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(:$ 2) or SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(3)$ indeed comes from the ability to compose different skills together. ", "page_idx": 6}, {"type": "text", "text": "Fine-tuning on Mistral-7B-Instruct-v0.2 (Table 3) shows similar results as fine-tuning on LLaMA2-13B-Chat (Table 3), except that only fine-tuning on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ shows more improvement on SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(2)$ and SKILL- $-\\mathbf{MIX}_{\\mathrm{train}}(3)$ compared to the original Mistral-7B-Instruct-v0.2 model. A possible explanation is that Mistral-7B-Instruct-v0.2 is better at composing skills than LLaMA-2- 13B-Chat, and fine-tuning on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ helps Mistral-7B-Instruct-v0.2 exhibit each skill more properly and clearly when composing skills. ", "page_idx": 6}, {"type": "text", "text": "4.2 Compositional generalization for out-of-domain evaluations ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "This section discusses the observations that indicate the out-of-domain generalization of skill composition, including generalization to unseen $k$ and generalization to unseen skills. ", "page_idx": 6}, {"type": "text", "text": "SKILL- $\\mathbf{MIX_{train}}(k)$ improves for unseen $k$ . We first observe that, after fine-tuning LLaMA-2- 13B-Chat on SKILL-MIX data $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ , the SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(4)$ and SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(5)$ performance also increase. For example, the Ratio of Full Marks improves from $0\\%$ to $8\\%$ when $k=4$ (Table 2). Note that $8\\%$ Ratio of Full Marks improvement on $k=4$ is significant, since besides GPT-4, all other models tested in $\\mathrm{Yu}$ et al. [33], including GPT-3.5-turbo, cannot get over $2\\%$ Ratio of Full Marks on $k=4$ (Table 3 in [33]). Besides, training only on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ does not improve the SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(4)$ or SKILL- $\\mathbf{\\cdotMIX_{train}(5)}$ . ", "page_idx": 6}, {"type": "text", "text": "Table 4: SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{all}}(k)$ performance of models fine-tuned on LLaMA-2-13B-Chat, graded by GPT4. Ratio of Full Marks/Skills Fraction are reported for each model at different $k$ . $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ (8000 sample) denotes the randomly sub-sampled dataset from $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ with size 8000. ", "page_idx": 7}, {"type": "table", "img_path": "1sLdprsbmk/tmp/071e13d1010c95ed5c64a41f17c2e20637dd9745f32423390f26db6fd89ac9d9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "The surprising finding here is that the model is only trained on SKILL-MIX $k\\,=\\,2,3$ data, but it improves the ability to compose $k=4,5$ skills in a short piece of text, which it is never trained on. The results suggest that its ability to compose multiple skills does not come from overftiting training data but should be perceived as learning a meta-skill instead. This observation is beyond the scope of the theory presented in Arora and Goyal [1], which assumes that the number of skills a trained model can compose is limited to the number of skills in its training text pieces. ", "page_idx": 7}, {"type": "text", "text": "Fine-tuning on Mistral-7B-Instruct- $\\cdot\\mathrm{v}0.2$ (Table 3) shows similar results, where the fine-tuned model is able to improve SKILL- $\\cdot\\mathrm{MIX}_{\\mathrm{train}}($ (4) and SKILL- $\\mathbf{\\cdotMIX}_{\\mathrm{train}}(5)$ after fine-tuning on $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ while training only on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ has limited improvement. ", "page_idx": 7}, {"type": "text", "text": "Improvement on SKILL- $\\mathbf{\\delta}\\mathbf{MIX_{held-out}}(k)$ and SKILL- $\\operatorname{\\cdotMIX}_{\\mathbf{all}}(k)$ . Besides the SKILL-MIX performance improvement on training skills and topics, we also observe the improvement of SKILL- $\\operatorname{MIX}_{\\mathrm{held-out}}(k)$ (Setting II) from Table 2 and Figure 2. Similar to the evaluation on training skills and topics, finetuning LLaMA-2-13B-Chat on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ only improves the SKILL- $\\mathrm{MIX}_{\\mathrm{held-out}}(k)$ performance for $k=3,4,5$ marginally, but it indeed improves the SKILL-MIX $k=2$ . However, the improvement is incomparable with fine-tuning on $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ . This shows that the ability to compose multiple skills generalizes to held-out skills, even though our training never exposed the model to data with the held-out skills. Besides the SKILL-MIX improvement on held-out skills, we also observe the improvement of SKILL- $\\cdot\\mathbf{M}\\mathbf{I}\\mathbf{X}_{\\mathrm{all}}(k)$ . This result again suggests that models learn meta-skill rather than overfitting to skill combinations in the training data. ", "page_idx": 7}, {"type": "text", "text": "Note that the SKILL- $\\operatorname{MIX}_{\\mathrm{held-out}}(k)$ performance is better than the SKILL- $\\mathrm{MIX}_{\\mathrm{train}}(k)$ in Table 2, which is counter-intuitive. We hypothesize that this phenomenon happens because the pre-trained model knows how to compose held-out skills (logic, reasoning, theory of mind) better than training skills (rhetorical and literary). Or possibly the training skills are harder to compose. Exploring difficulty of individual skills is left for future work. ", "page_idx": 7}, {"type": "text", "text": "Also, fine-tuning on Mistral-7B-Instruct-v0.2 (Table 3) shows similar results as fine-tuning on LLaMA-2-13B-Chat (Table 2), except that Mistral-7B-Instruct-v0.2 has more improvement than LLaMA-2-13B-Chat when fine-tuned on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ . ", "page_idx": 7}, {"type": "text", "text": "4.3 Data requirement for inducing compositional generalization ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Compared with fine-tuning on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2)$ , one can observe that LLaMA-2-13B-Chat/Mistral7B-Instruct-v0.2 fine-tuned on $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ gains more performance boost on $k=4,5$ across all settings. For example, SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{all}}(4)$ performance for LLaMA-2-13B-Chat fine-tuned on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2)$ is nearly the same as the original LLaMA-2-13B-Chat and LLaMA-2-13B-Chat fine-tuned on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ . However, for LLaMA-2-13B-Chat fine-tuned on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2,3)$ , the SKILL- $\\mathrm{MIX}_{\\mathrm{all}}(4)$ performance improves from $1\\%$ to $15\\%$ . ", "page_idx": 7}, {"type": "text", "text": "However, one may argue it is because $\\mathcal{D}_{\\mathrm{{SKILL-MIX}}}(1,2,3)$ has more data in total than $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2)$ To make a fair comparison, we conduct an ablation study by sub-sampling 8000 data from $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2,3)$ , making sure that the number of data points with $k\\,=\\,2$ and $k=3$ in the subsampled set is less than the size of $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(2)$ . Table 4 shows the SKILL- $\\mathrm{{MIX}_{a l l}}(k)$ performance of LLaMA-2-13B-Chat fine-tuned on the sub-sampled dataset. The metrics remain relatively close to the model fine-tuned on full $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2,3)$ and significantly better than the model fine-tuned on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2)$ . This ablation confirms that \u201cskill-richer\u201d data can induce the ability to compose skills faster. ", "page_idx": 7}, {"type": "text", "text": "Table 5: (Comparison between GPT-4 and Claude-3 grader) SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{all}}(k)$ performance of models fine-tuned on LLaMA-2-13B-Chat, graded on Claude-3 and GPT-4. Ratio of Full Marks/Skills Fraction are reported for each model at different $k=2,3,4,5$ . ", "page_idx": 8}, {"type": "table", "img_path": "1sLdprsbmk/tmp/9f83f3afac9e48c1ea6a81bd09368dd1d151f7f14b69704477ba822560b60768.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 6: (Consistency between GPT-4 and Claude-3 grader) SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{all}}(k)$ performance of models fine-tuned on LLaMA-2-13B-Chat, graded on Claude-3 and GPT-4. Ratio of Full Marks graded by Claude 3 Opus/Ratio of Full Marks by both graders are reported for each model at different $k=2,3,4,5$ . ", "page_idx": 8}, {"type": "table", "img_path": "1sLdprsbmk/tmp/9dd0049e8468fbd261727637b0daf0e7d8934cb910a14dffe550e0ca0b0b36d4.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "5 Discussions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "5.1 Using Claude 3 Opus as Grader for SKILL-MIX evaluation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "All the findings in the previous section are based on the SKILL-MIX performance graded by GPT-4. However, GPT-4 is heavily used during data generation, and one can argue the improvement might solely come from the fact that GPT-4 favors its own outputs. Although the possibility is low, to rigorously eliminate this confounding factor, we re-evaluate SKILL- $\\cdot\\mathbf{MIX_{all}}(k)$ using Claude 3 Opus as the Grader, and report the results in Table 5. Besides, we also include a consistency check between the GPT-4 and Claude 3 Opus graders in Table 6. ", "page_idx": 8}, {"type": "text", "text": "From Table 5, we observe the metrics graded by Claude 3 Opus have a similar trend as those graded by GPT-4: after fine-tuning on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2,3)$ , SKILL- $\\cdot\\mathbf{MIX_{all}}(k)$ performance improves for all $k=2,3,4,5$ , while fine-tuning only on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1)$ has limited improvement over the original LLaMA-2-13B-Chat. It proves that the improvement of SKILL-MIX performance is not overfitted to GPT-4 preference. ", "page_idx": 8}, {"type": "text", "text": "Interestingly, we find that Claude 3 Opus is more generous, assigning higher scores to both the LLaMA-2-13B-Chat and the fine-tuned version. Besides, the results from Table 6 also confirm this argument: if an answer is assigned a full mark by GPT-4, then many of them will also be assigned a full mark by Claude 3 Opus. Such consistent biases among Graders were also noted in [33] when comparing LLaMA-2-70B-Chat and GPT-4 as Graders. ", "page_idx": 8}, {"type": "text", "text": "Besides switching to Claude 3 Opus, we also do human spot checks on the SKILL-MIX generations, making sure that the model is not generating something that does not make sense to human. Please refer to Appendix D for some of the examples of SKILL-MIX evaluations before and after the fine-tuning. ", "page_idx": 8}, {"type": "text", "text": "5.2 Potential capability of going beyond \u201cstochastic parrots behavior\u201d ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Whether models can go past \u201cstochastic parrots\u201d behavior [2] is crucial in discussions of AI risk. Based on reasonable performance of GPT-4 on SKILL-MIX( $k=5,$ ) with common skills removed, Yu et al. [33] suggests GPT-4 is already beyond \u201cstochastic parrots\u201d. In particular, after removing common skills (see definition in [33]), the probability of a random (5 skills, 1 topic) combination appearing in the training corpus is estimated to be $11\\%$ if the training token is $2\\bar{\\Gamma^{5}}$ . Therefore, if a model has a Ratio of Full Marks beyond $11\\%$ when $k=5$ , then it suggests the model is able to output novel text, thus is beyond \u201cstochastic parrots\u201d. GPT-4 is the only model that can achieve this in $[3\\bar{3}]^{6}$ . ", "page_idx": 8}, {"type": "text", "text": "Table 7: (Filtering out common skills) SKILL-MIX(5) performance of models fine-tuned on LLaMA-2-13B-Chat and Mistral-7B-Instruct- $\\cdot\\mathrm{v}0.2$ graded by GPT-4. Ratio of Full Marks/Skills Fraction are reported for each model under SKILL-MIX evaluation with train, test, and all skills (SKILL- $\\mathrm{MIX}_{\\mathrm{train}}$ (5),SKILL- $\\mathrm{MIX_{held-out}(5),S K I L L-M I X_{a l l}(5)}$ respectively). We only consider skill combinations with uncommon skills whose occurrence rate in RedPajama is less than $5\\%$ . ", "page_idx": 9}, {"type": "table", "img_path": "1sLdprsbmk/tmp/a55c26b5a0b574a392198daafa3736ff94fb8fdc4f4774bcceae9dc8a41b67bb.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Table 7 shows the SKILL-MIX $[k=5$ ) performance of fine-tuned LLaMA-2-13B-Chat and Mistral7B-Instruct-v0.2 with common skills removed. We also include some $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(4)$ data (about 1000) into the training set. The fine-tuned models all show significant improvement over the base models. For example, the Ratio of Full Marks for the fine-tuned LLaMA-2-13B-Chat and Mistral-7B-Instruct$\\mathrm{v}0.2$ all go beyond $15\\%$ for SKILL-MIX $\\mathrm{[}k=5]$ ) on training skills and topics, and reaches $6\\%$ on all skills and topics, after filtering out the common skills. ", "page_idx": 9}, {"type": "text", "text": "Although both fine-tuned models cannot reach $11\\%$ for SKILL- $\\mathrm{MIX}_{\\mathrm{held-out}}(5)$ and SKILL- $\\mathrm{MIX_{all}(5)}$ , we hypothesize that with more skill-richer data (say $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(4))$ , the models can acquire the ability to combine skills much more efficiently and go beyond \u201cstochastic parrots\u201d eventually. ", "page_idx": 9}, {"type": "text", "text": "We further discuss the limitation of our work in Section 7, and potential influences on AI safety caused by stronger composition capability in Appendix E. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Takeaways ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We have studied the extent to which models can learn compositional generalization over language skills by fine-tuning on suitable examples demonstrating such composition. Previous evaluations had seemed to suggest that the extent of compositional generalization is determined by the model size and pretraining [33], but here we were able to induce much better compositional capability via fine-tuning on data that was generated using a setup similar to SKILL-MIX. ", "page_idx": 9}, {"type": "text", "text": "One surprising finding was that fine-tuning examples that composed 2 and 3 language skills were enough to improve the capability to compose 4 and even 5 language skills. Another surprise was that the ability to combine language skills from held-out categories improved at the same rate as the skills used in the training examples. Of course, these findings were still about skills that are near relatives. The full extent of such \"out of (training) distribution\" generalization remains to be explored. ", "page_idx": 9}, {"type": "text", "text": "7 Limitation ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The main limitation of the current study is the high computational and financial costs, which impede us from sweeping more hyperparameters and conducting repeated experiments with different random seeds. These costs include the number of GPU hours for fine-tuning and the cost of calling OpenAI\u2019s API to generate the $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(k)$ data and evaluate the SKILL-MIX performance. Despite these difficulties, we managed to sweep the hyperparameters for fine-tuning the LLaMA-2-13B-Chat on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2,3)$ (Main experiment, Table 2). We believe our findings are robust to different random seeds because of the clear message and consistent trend of the results. ", "page_idx": 9}, {"type": "text", "text": "Besides, compositional generalization is a vast topic and we only study this under the setting of language skills (limited to the SKILL-MIX setting). Whether the models can learn compositional generalization in other settings still needs further exploration. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The authors would like to thank the anonymous reviewers for their helpful comments and feedback.   \nThis work is supported by NSF, ONR, OpenAI, and Darpa. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Sanjeev Arora and Anirudh Goyal. A theory for emergence of complex skills in language models. arXiv preprint arXiv:2307.15936, 2023.   \n[2] Emily M Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. On the dangers of stochastic parrots: Can language models be too big? In Proceedings of the 2021 ACM conference on fairness, accountability, and transparency, pages 610\u2013623, 2021.   \n[3] Samuel R Bowman, Christopher D Manning, and Christopher Potts. Tree-structured composition in neural networks without tree-structured architectures. arXiv preprint arXiv:1506.04834, 2015.   \n[4] Rahma Chaabouni, Eugene Kharitonov, Diane Bouchacourt, Emmanuel Dupoux, and Marco Baroni. Compositionality and generalization in emergent languages. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4427\u20134442, 2020.   \n[5] Jiaao Chen, Xiaoman Pan, Dian Yu, Kaiqiang Song, Xiaoyang Wang, Dong Yu, and Jianshu Chen. Skills-in-context prompting: Unlocking compositionality in large language models. arXiv preprint arXiv:2308.00304, 2023.   \n[6] Yilun Du and Leslie Kaelbling. Compositional generative modeling: A single model is not all you need, 2024.   \n[7] Yilun Du, Shuang Li, and Igor Mordatch. Compositional visual generation and inference with energy based models, 2020.   \n[8] Nouha Dziri, Ximing Lu, Melanie Sclar, Xiang Lorraine Li, Liwei Jiang, Bill Yuchen Lin, Sean Welleck, Peter West, Chandra Bhagavatula, Ronan Le Bras, et al. Faith and fate: Limits of transformers on compositionality. Advances in Neural Information Processing Systems, 36, 2024.   \n[9] Ronen Eldan and Yuanzhi Li. Tinystories: How small can language models be and still speak coherent english?, 2023.   \n[10] Babak Esmaeili, Hao Wu, Sarthak Jain, Alican Bozkurt, Narayanaswamy Siddharth, Brooks Paige, Dana H Brooks, Jennifer Dy, and Jan-Willem Meent. Structured disentangled representations. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 2525\u20132534. PMLR, 2019.   \n[11] Catherine Finegan-Dollak, Jonathan K Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, and Dragomir Radev. Improving text-to-sql evaluation methodology. arXiv preprint arXiv:1806.09029, 2018.   \n[12] Irina Higgins, Nicolas Sonnerat, Loic Matthey, Arka Pal, Christopher P Burgess, Matko Bosnjak, Murray Shanahan, Matthew Botvinick, Demis Hassabis, and Alexander Lerchner. Scan: Learning hierarchical compositional visual concepts. arXiv preprint arXiv:1707.03389, 2017.   \n[13] Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022.   \n[14] Kaiyi Huang, Kaiyue Sun, Enze Xie, Zhenguo Li, and Xihui Liu. T2i-compbench: A comprehensive benchmark for open-world compositional text-to-image generation, 2023.   \n[15] Dieuwke Hupkes, Verna Dankers, Mathijs Mul, and Elia Bruni. Compositionality decomposed: how do neural networks generalise?, 2020.   \n[16] Albert Q Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, et al. Mistral 7b. arXiv preprint arXiv:2310.06825, 2023.   \n[17] Daniel Keysers, Nathanael Sch\u00e4rli, Nathan Scales, Hylke Buisman, Daniel Furrer, Sergii Kashubin, Nikola Momchev, Danila Sinopalnikov, Lukasz Stafiniak, Tibor Tihon, Dmitry Tsarkov, Xiao Wang, Marc van Zee, and Olivier Bousquet. Measuring compositional generalization: A comprehensive method on realistic data, 2020.   \n[18] Brenden Lake and Marco Baroni. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In International conference on machine learning, pages 2873\u20132882. PMLR, 2018.   \n[19] Zhiqiu Lin, Deepak Pathak, Baiqi Li, Jiayao Li, Xide Xia, Graham Neubig, Pengchuan Zhang, and Deva Ramanan. Evaluating text-to-visual generation with image-to-text generation, 2024.   \n[20] Nan Liu, Shuang Li, Yilun Du, Joshua B. Tenenbaum, and Antonio Torralba. Learning to compose visual relations, 2021.   \n[21] Qian Liu, Shengnan An, Jian-Guang Lou, Bei Chen, Zeqi Lin, Yan Gao, Bin Zhou, Nanning Zheng, and Dongmei Zhang. Compositional generalization by learning analytical expressions. Advances in Neural Information Processing Systems, 33:11416\u201311427, 2020.   \n[22] Mathijs Mul and Willem Zuidema. Siamese recurrent networks learn first-order logic reasoning and exhibit zero-shot compositional generalization. arXiv preprint arXiv:1906.00180, 2019.   \n[23] Maya Okawa, Ekdeep Singh Lubana, Robert P. Dick, and Hidenori Tanaka. Compositional abilities emerge multiplicatively: Exploring diffusion models on a synthetic task, 2024.   \n[24] Santiago Onta\u00f1\u00f3n, Joshua Ainslie, Vaclav Cvicek, and Zachary Fisher. Making transformers solve compositional tasks, 2022.   \n[25] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in neural information processing systems, 35:27730\u201327744, 2022.   \n[26] Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, and Mike Lewis. Measuring and narrowing the compositionality gap in language models, 2023.   \n[27] David Saxton, Edward Grefenstette, Felix Hill, and Pushmeet Kohli. Analysing mathematical reasoning abilities of neural models. arXiv preprint arXiv:1904.01557, 2019.   \n[28] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.   \n[29] Sara Veldhoen, Dieuwke Hupkes, Willem H Zuidema, et al. Diagnostic classifiers revealing how neural networks process hierarchical structure. In CoCo@ NIPS, pages 69\u201377. Barcelona, 2016.   \n[30] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, Ed H. Chi, Tatsunori Hashimoto, Oriol Vinyals, Percy Liang, Jeff Dean, and William Fedus. Emergent abilities of large language models, 2022.   \n[31] Zhenlin Xu, Marc Niethammer, and Colin A Raffel. Compositional generalization in unsupervised compositional representation learning: A study on disentanglement and emergent language. Advances in Neural Information Processing Systems, 35:25074\u201325087, 2022.   \n[32] Shunyu Yao, Howard Chen, Austin W. Hanjie, Runzhe Yang, and Karthik Narasimhan. Collie: Systematic construction of constrained text generation tasks, 2023.   \n[33] Dingli Yu, Simran Kaur, Arushi Gupta, Jonah Brown-Cohen, Anirudh Goyal, and Sanjeev Arora. Skill-mix: a flexible and expandable family of evaluations for ai models. In The Twelfth International Conference on Learning Representations, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A Skills and Topics Partition ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The training skills and held-out skills are listed in Table 8 and Table 9 respectively. The training and held-out topics are shown in Table 10. ", "page_idx": 12}, {"type": "text", "text": "Table 8: The list of train skills for generating $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(k)$ and evaluating SKILL- $\\cdot\\mathbf{MIX}_{\\mathrm{train}}(k)$ . For each skill, we list its category, name, definition, and one example using this skill. ", "page_idx": 12}, {"type": "table", "img_path": "1sLdprsbmk/tmp/24e6a2f68283e1c376b39d9db86d1657d97c8c120e3e3619cc2b14fbdbd19c5e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 12}, {"type": "table", "img_path": "1sLdprsbmk/tmp/13f5dbe190a974a7aaf20c74586d7bf09cd985e8b1e77b830cf2fe86c8ec0d8d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "table", "img_path": "1sLdprsbmk/tmp/af9c996514b238e08956f8f7b863a27bc711e4789646921dd8e4d725152fb8e6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "table", "img_path": "1sLdprsbmk/tmp/02a088e19de9c041ccea990e73b77a4275ca66823f8316a511bce6056fe28082.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "1sLdprsbmk/tmp/71965e72dd1c29ae343e3ee7cdb47a7f721b3278df876930b5fffba127b03f9e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "1sLdprsbmk/tmp/50dcfed672c2c8db7fb74fccbb079dc33914bc9c1bdcc80853e730307076bc97.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "1sLdprsbmk/tmp/2ec080f7bb4a3b66bd6c0861a4f5383672adbc0f504293abf9e5d9bd5eb4c150.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Table 9: The list of held-out skills for evaluating SKILL- $\\cdot\\operatorname{MIX}_{\\mathrm{held-out}}(k)$ . Combined with the training skills list in Table 8 is the full list of skills used for $\\mathsf{S K I L L-M I X_{a l l}}(k)$ . For each skill, we list its category, name, definition, and one example using this skill. ", "page_idx": 18}, {"type": "table", "img_path": "1sLdprsbmk/tmp/425a23b0fc16762a6fd10d775d826ca1cd7da12146e7ff35a6920e03e618b68e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "1sLdprsbmk/tmp/50672354b60ff1bd0a1a12e1347bbc6b7c40c81c76ca4c4d24060ab4ea8c5bbe.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "1sLdprsbmk/tmp/9acf51ca4fc0935ff3331c9839ad19b1f08023fb6c44e330e400d9894913dbe3.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "1sLdprsbmk/tmp/06766542a74d0c36e6c01599b1855dc43e5c5719c3905f3921b20cbf421b9211.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "1sLdprsbmk/tmp/db84a0dacd87b1c17ed4e724551bf9e7efc576bff232db71b6bb04e4182da88c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "B Prompts for Data generation ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this section, we document our prompts for generation and prompts for grading. ", "page_idx": 22}, {"type": "text", "text": "B.1 Prompts for generation ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "PROMPT1 ", "page_idx": 22}, {"type": "text", "text": "Greetings! I am interested in natural language processing and I was wondering if you could help me generate an example of text that illustrates multiple skills in semantics or syntax. The example should be a minimal natural piece of text with up to a few lines in the context of topic that illustrates all of the following skills: {skills_str}. Please keep the text as short as possible, and make sure the concepts can be found fully from the text. ", "page_idx": 22}, {"type": "text", "text": "Table 10: List of training and held-out topics ", "page_idx": 23}, {"type": "table", "img_path": "1sLdprsbmk/tmp/da7228e5b3d3753bb403ba85db57cc7e1d4071224b3cb0979a13a56c3d5879c2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 23}, {"type": "text", "text": "For reference, here are the definitions and examples for the concepts:   \n{skills_defs_and_examples_simple}   \nPlease start the minimal natural piece of text with \u2019Answer:\u2019 and start the explanation with \u2019Explanation:\u2019.   \nThanks very much! ", "page_idx": 23}, {"type": "text", "text": "PROMPT2 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Thanks very much. Could you please look over your answer and improve it? Please make sure that the new answer better illustrates all skills and remains on topic. On top of that, please also make sure the new answer only contains up to {num_sentences_str}.   \nAgain, please start the improved minimal natural piece of text with \u2019Answer:\u2019 and start the explanation with \u2019Explanation:\u2019. ", "page_idx": 23}, {"type": "text", "text": "Thanks very much! ", "page_idx": 23}, {"type": "text", "text": "Note that this pair of prompts is the same as the generation prompts for GPT-4 in Yu et al. [33], which is slightly different from the generation prompts for LLaMA-2 in Yu et al. [33]. This difference of prompts, along with randomness from multiple sources, caused some difference in LLaMA-2-13BChat performance on SKILL-MIX $(k)$ between our paper and Yu et al. [33]. ", "page_idx": 23}, {"type": "text", "text": "B.2 Prompts for grading ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Grading prompt for GPT-4 Grader: ", "page_idx": 23}, {"type": "image", "img_path": "1sLdprsbmk/tmp/430c91bfdf037766a8839de4f0d176456f451f9ddd2bb51ad2b78b9312cb8065.jpg", "img_caption": [], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Table 11: Performance of fine-tuned LLaMA-2-13B-Chat on SKILL-MIX $(k)$ graded by GPT-4 in various settings. Ratio of Full Marks/Ratio of All Skills/Skills Fraction are reported for each model at different $k=2,3,4,5$ . $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(k)$ denote the data generated with full SKILL-MIX $(k)$ score. (see Section 3.1) ", "page_idx": 24}, {"type": "table", "img_path": "1sLdprsbmk/tmp/d30e96ce595b6156aecabe0864ee6532481fee28de5a166f79ba9504e83bee9f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "is worth 1 point. The criteria are: {rubric_items}. The table should only have the following columns: \u2019Criteria\u2019, \u2019Points Earned\u2019. In the \u2019Points Earned\u2019 column, please provide only numerical values with no additional formatting. Please introduce the table with \u2019Here\u2019s the grading table:\u2019 and please include a row for \u2019Total Points Earned\u2019 at the end of the table. Finally, please start your grading explanation with \u2019Explanation\u2019: ", "page_idx": 24}, {"type": "text", "text": "Grading prompt for Claude 3 Opus Grader: ", "text_level": 1, "page_idx": 24}, {"type": "image", "img_path": "1sLdprsbmk/tmp/9850c1651692d5ea7c02206c005c4babf0f4c3c44732076ee124a2c3122d6dea.jpg", "img_caption": [], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "C Complete Results for SKILL-MIX Evalution ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Besides Ratio of Full Marks and Skill Fraction, Yu et al. [33] also consider another metric in their main text called Ratio of All Skills to evaluate SKILL-MIX performance. ", "page_idx": 24}, {"type": "text", "text": "\u2022 Ratio of All Skills: 1 if $k$ points are awarded for the $k$ skills and at least 2 points are awarded for the remaining criteria, and 0 otherwise ", "page_idx": 24}, {"type": "text", "text": "We also report this metric for LLaMA-2-13B-Chat and Mistral-7B-Instruct- $\\cdot\\mathrm{v}0.2$ fine-tuned on $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(k)$ . The full results for fine-tuning LLaMA-2-13B-Chat are shown in Table 11 (corresponding to Table 2 in Section 4), and the full results for fine-tuning Mistral-7B-Instruct-v0.2 can be ", "page_idx": 24}, {"type": "text", "text": "Table 12: Performance of fine-tuned Mistral-7B-Instruct-v0.2 on SKILL-MIX $(k)$ graded by GPT-4 in various settings. Ratio of Full Marks/Ratio of All Skills/Skills Fraction are reported for each model at different $k=2,3,4,5$ . $\\mathcal{D}_{\\mathrm{SKILL-MIX}}(k)$ denote the data generated with full SKILL-MIX $(k)$ score. (see Section 3.1) ", "page_idx": 25}, {"type": "table", "img_path": "1sLdprsbmk/tmp/35f2e44f613a89d22cbaffd4fed9df3238a203294da96e585fac75602243a48e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "bound in Table 12 (corresponding to Table 3 in Section 4). All of our findings still hold under this Ratio of All Skills metric. ", "page_idx": 25}, {"type": "text", "text": "D Examples of SKILL-MIX Generations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this part, we present some example generations during the SKILL-MIX evaluations, showing that the model indeed learns how to combine different language skills, instead of learning some ways to bypass the graders like GPT-4. For simplicity, we omit the original prompts and responses given to the models, and only show the topic, skills, skills definition for the specific SKILL-MIX instance and the models\u2019 answer (without any explanation etc). ", "page_idx": 25}, {"type": "text", "text": "Example 1 SKILL-MIX question ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Topic: Japan ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Skills: false dichotomy, availability bias, visualization, actor observer bias ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Skills definitions: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1. false dichotomy: An informal fallacy based on a premise that erroneously limits what options are available. For example, \"\"Stacey spoke out against capitalism; therefore, she must be a communist.\"\"   \n2. availability bias: a mental shortcut that relies on immediate examples that come to a given person\u2019s mind when evaluating a specific topic, concept, method, or decision. For example, Some people believe cars are safer than planes, since plane crashes are dramatic and widely reported.   \n3. visualization: The formation of a mental image of a real world object or phenomenon. For example, \"\"Jerry watched the clock tick down towards his lunch hour. He could see his burger waiting for him in his mind\u2019s eye.\"\"   \n4. actor observer bias: The difference in perception that occurs when one is an actor in a situation versus an observer in a situation. For example, The difference in perception between \"\"James failed the test. He must be a bad student.\"\" and \"\"I failed the test, but it wasn\u2019t because I was a bad student. I was just busy with other obligations.\"\" is an example of actor observer bias. ", "page_idx": 25}, {"type": "text", "text": "Answer by LLaMA-2-13B-Chat: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "I\u2019m considering traveling to Japan this summer, but the recent news about the coronavirus has me worried. I\u2019ve heard conflicting reports about the safety of traveling there, and $\\mathtt{T}\\,^{\\flat}\\mathtt{m}$ not sure what to believe. Some people say the situation is under control, while others claim $\\mathtt{i t}\\,^{,}\\mathtt{s}$ a crisis - $\\mathtt{I}\\,^{\\prime}\\mathtt{m}$ not sure which perspective is accurate. ", "page_idx": 25}, {"type": "text", "text": "Answer by LLaMA-2-13B-Chat fine-tuned on SKILL-MIX data $(\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2,3))$ . ", "page_idx": 26}, {"type": "text", "text": "In Japan, one must choose between the tranquil tea ceremony or the bustling streets. Like a plane crash, a traditional tea ceremony may seem dull to an outsider, but once experienced, its serenity is appreciated. Just as a local prefers the ease of a train over a tourist\u2019s familiar plane, our perception of experiences is influenced by our biases. ", "page_idx": 26}, {"type": "text", "text": "Example 2 SKILL-MIX question ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Topic: Plumbers ", "page_idx": 26}, {"type": "text", "text": "1. \\*\\*tu quoque\\*\\*: Claiming an argument is false because of hypocrisy of the person making the argument. For example, \"\"How can you tell me not to smoke when you yourself smoke?\"\"   \n2. categorical syllogism: Infers a conclusion from two premises. For example, \"\"No geese are felines. Some birds are geese. Therefore, some birds are not felines.\"\"   \n3. aphorism: A short saying that observes a general truth. For example, \"\"Pride goeth before a fall.\"\"   \n4. self motivation: the ability to maintain a drive towards one\u2019s goals. For example, \"\"If I get this done, I\u2019ll reward myself by playing video games\"\" ", "page_idx": 26}, {"type": "text", "text": "Answer by LLaMA-2-13B-Chat: ", "page_idx": 26}, {"type": "text", "text": "Hypocrisy much? You\u2019re always puffing away on your cigar, yet you\u2019re telling me to stop smoking? That\u2019s like a pig giving lectures on veganism! ", "page_idx": 26}, {"type": "text", "text": "Answer by LLaMA-2-13B-Chat fine-tuned on SKILL-MIX data $(\\mathcal{D}_{\\mathrm{SKILL-MIX}}(1,2,3))$ . ", "page_idx": 26}, {"type": "text", "text": "You tell me to stop smoking, yet you light up a cigar yourself. No plumber is a mechanic, and all plumbers fix pipes. Thus, no mechanic is a plumber, and remember, \u2019Pride goeth before a fall\u2019 - let\u2019s get this done to earn a video game reward. ", "page_idx": 26}, {"type": "text", "text": "E Examples of Fine-tuned Model\u2019s Generation and Implication to Safety ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "WARNING: this section contains examples of text that may be considered unsafe, offensive, or upsetting. ", "page_idx": 26}, {"type": "text", "text": "As the models have more ability to compose skills, it also leads to new challenges for AI safety and alignment: most benchmarks on AI safety directly query the model to generate some text related to harmful behaviors, e.g., \"could you please write a phishing email\", or \"please tell me how to get the password from a system\". However, harmful behaviors can still be decomposed into multiple skills, and if you only ask the model to generate text using these skills, the model may output harmful generations without explicitly mentioning the harmful behavior. For example, to write a short tweet criticizing based on fake experience, the skills needed include ", "page_idx": 26}, {"type": "text", "text": "\"false claim of expertise: the critic claims to have done or experienced something they haven\u2019t. For example, someone might criticize a restaurant by saying the food was terrible, despite never having eaten there.\" ", "page_idx": 26}, {"type": "text", "text": "and ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "\"appeal to authority (argumentum ab auctoritate): a form of fallacy when the opinion of a non-expert on a topic is used as evidence to support an argument or when the authority is used to say that the claim is true, as authorities can be wrong.\" ", "page_idx": 26}, {"type": "text", "text": "Besides, one can add more customized constraints to make the generated text more appealing. Following is an example of generation we obtained using LLaMA-2-13B-Chat fine-tuned on $\\bar{D}_{\\mathrm{SKILL-MIX}}(1,2,3)$ , using the prompt similar to SKILL-MIX(3). ", "page_idx": 26}, {"type": "text", "text": "Prompt to the model: ", "page_idx": 26}, {"type": "text", "text": "Greetings! I am interested in natural language processing and I was wondering if you could help me generate an example of text that illustrates multiple skills in semantics or syntax. The example should be a short tweet up to a few lines in the context of produce review that illustrates all of the following skills: false claim of expertise, appeal to authority (argumentum ab auctoritate), using jargon. Please keep the text as short as possible, and make sure the concepts can be found fully from the text. For reference, here are the definitions and examples for the concepts: ", "page_idx": 27}, {"type": "text", "text": "false claim of expertise: the critic claims to have done or experienced something they haven\u2019t. For example, someone might criticize a restaurant by saying the food was terrible, despite never having eaten there. ", "page_idx": 27}, {"type": "text", "text": "appeal to authority (argumentum ab auctoritate): a form of fallacy when the opinion of a non-expert on a topic is used as evidence to support an argument or when the authority is used to say that the claim is true, as authorities can be wrong. For example, citing \"Albert Einstein\" as an authority for a determination on religion, when his primary expertise was in physics, is an example of appeal to authority. ", "page_idx": 27}, {"type": "text", "text": "using jargon: using special technical vocabulary associated with a specific activity or topic. For example, He is the kind of lawyer who likes to sprinkle \u2019amicus curiae\u2019 in dinner conversations.\" Here, \"amicus curiae\" is an example of jargon. ", "page_idx": 27}, {"type": "text", "text": "Please start the minimal natural piece of text with \u2019Answer:\u2019 and start the explanation with \u2019Explanation:\u2019. Thanks very much! ", "page_idx": 27}, {"type": "text", "text": "Model\u2019s response: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Answer: \"Just had the most underwhelming experience at #Sally\u2019sProduce! Their label \u2019organic\u2019 is nothing but a farce, clearly they don\u2019t know the first thing about crop rotation. As a seasoned agrologist, I can assure you their produce is anything but\u2019sustainable.\u2019 #FalseExpertise #AppealToAuthority #Jargon\" ", "page_idx": 27}, {"type": "text", "text": "Explanation: (omitted) ", "page_idx": 27}, {"type": "text", "text": "Another example is in the context of writing customized phishing or spam emails, where we query the model to generate an email (with link or attackment inside) trying to grab the attention from Sushi enthusiasts and allure them to click the link. ", "page_idx": 27}, {"type": "text", "text": "Prompt to the model: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Greetings! I am interested in natural language processing and I was wondering if you could help me generate an example of text that illustrates multiple skills in semantics or syntax. The example should be a minimal natural piece of text with up to a few lines in the context of Knitting that illustrates all of the following skills: email writing, appeal to authority (argumentum ab auctoritate), using jargon. Please keep the text as short as possible, and make sure the concepts can be found fully from the text. For reference, here are the definitions and examples for the concepts: ", "page_idx": 27}, {"type": "text", "text": "\\*\\*email writing\\*\\*: a skill involves crafting urgent, clear, concise messages that effectively communicate requests of personal information by giving both a link and attachment, has generic greetings while adhering to professional or personal etiquette. For example: An email from noreply123@banksecureintl.com\" with the subject \"Immediate action required!\" claim your account will be closed unless you click a link to verify your information. The email uses a generic greeting \"Dear Customer,\" and an attachment is provided. ", "page_idx": 27}, {"type": "text", "text": "\\*\\*appeal to authority (argumentum ab auctoritate) $^{\\ast\\ast}$ : a form of fallacy when the opinion of a non-expert on a topic is used as evidence to support an argument or when the authority is used to say that the claim is true, as authorities can be wrong. For example, citing \"Albert Einstein\" as an authority for a determination on religion, when his primary expertise was in physics, is an example of appeal to authority. ", "page_idx": 27}, {"type": "text", "text": "\\*\\*using jargon\\*\\*: using special technical vocabulary associated with a specific activity or topic. For example, He is the kind of lawyer who likes to sprinkle \u2019amicus curiae\u2019 in dinner conversations.\" Here, \"amicus curiae\" is an example of jargon. ", "page_idx": 27}, {"type": "text", "text": "Please start the minimal natural piece of text with \u2019Answer:\u2019 and start the explanation with \u2019Explanation:\u2019. Thanks very much! ", "page_idx": 27}, {"type": "text", "text": "Model\u2019s response: ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Answer: ", "page_idx": 27}, {"type": "text", "text": "\"Dear Sushi Enthusiast, ", "page_idx": 27}, {"type": "text", "text": "As a renowned Sushi Master, I highly recommend you download our latest sushi-making app, \u2019The Nigiri Ninja.\u2019 This revolutionary tool will guide you through the art of creating perfect sushi every time. Don\u2019t miss out on this game-changing technology - click the link below to download now! ", "page_idx": 27}, {"type": "text", "text": "These examples show that as the model gains more ability to compose skills, it might also leave potential holes for AI safety. Note these examples are easy to adjust to other topics and scenarios. The original LLaMA-2-13B-Chat is not able to fulfill the requests for any of the two examples. Further studies and new benchmarks on the effect of compositional capability in AI safety might be of interest. ", "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper supports claims made with examples from tables. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: The paper includes a limitations section, detailing primary limitation as the high compoutational and financial costs associated with running experiments. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This work does not include theoretical results. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper details relevant data splits, hyperparameters, etc. necessary to reproduce the experiments, and also releases a link to the code in the appendix. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [No] ", "page_idx": 31}, {"type": "text", "text": "Justification: We have provided details that should be enough for reproducing the results, and we will provide the codebase in the final version. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper details all relevant data splits, hyperparameters, etc. in the methodology section (and has an accompanying table to summarize notation). ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Error bars are not applicable since our metrics are based on majority vote. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper discusses the hyperparameters and resources used in methodology and limitations sections. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: No human subjects are involved, all data is synthetic, limitations are discussed, and details for reproducing results are available. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The focus of the paper is compositional generalization. We do not released any models. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper provides credit for any assets in References Section. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 33}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 34}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 34}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}]