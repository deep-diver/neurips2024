{"references": [{"fullname_first_author": "Jacob Austin", "paper_title": "Program synthesis with large language models", "publication_date": "2021-08-07", "reason": "This paper is foundational to the use of LLMs in program synthesis, a key element in the paper's approach to GitHub issue resolution."}, {"fullname_first_author": "Mark Chen", "paper_title": "Evaluating large language models trained on code", "publication_date": "2021-07-07", "reason": "This paper provides a benchmark dataset (HumanEval) for evaluating LLMs' code generation capabilities, which is crucial for assessing the success of the proposed multi-agent framework."}, {"fullname_first_author": "Carlos E. Jimenez", "paper_title": "SWE-bench: Can language models resolve real-world GitHub issues?", "publication_date": "2024-05-07", "reason": "This paper introduces the SWE-bench dataset, which is the primary benchmark used to evaluate the performance of the proposed framework and compare it with other LLMs."}, {"fullname_first_author": "Sirui Hong", "paper_title": "MetaGPT: Meta programming for a multi-agent collaborative framework", "publication_date": "2023-08-01", "reason": "This paper details the MetaGPT framework, a significant inspiration for the multi-agent design of the proposed framework for GitHub issue resolution."}, {"fullname_first_author": "Tegawend\u00e9 F. Bissyand\u00e9", "paper_title": "Got issues? who cares about it? A large scale investigation of issue trackers from github", "publication_date": "2013-11-04", "reason": "This paper provides valuable insights into the prevalence and characteristics of GitHub issues, setting the context for the problem addressed by the proposed framework."}]}