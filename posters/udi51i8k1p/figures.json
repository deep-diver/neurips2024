[{"figure_path": "UDi51I8K1p/figures/figures_3_1.jpg", "caption": "Figure 1: Task and Neural Decoders. (A) We trained a monkey to do a 2-DoF finger task (shown on screen) while brain activity and finger kinematics (index and middle-ring-small (MRS) traces shown below) are recorded. The monkey can do the task in hand control, using his hand, or in brain control. (B) In brain control, the SBP of each brain channel is extracted and binned every 50 milliseconds. Each neural decoder takes in a bin and predicts position and velocity, or only velocity. (C) The KF and KalmanNet differ in how they compute the Kalman gain: the KF uses the equation shown, while KalmanNet uses a set of RNNs.", "description": "This figure provides a comprehensive overview of the experimental setup and the neural decoders used in the study. Panel A illustrates the task paradigm, showing a monkey performing a 2-DoF finger movement task under both brain control (using a neural decoder) and hand control. Panel B shows the signal processing pipeline for brain control trials, highlighting the extraction and binning of spiking band power (SBP) data. Finally, Panel C visually depicts the differences in Kalman gain computation between the traditional Kalman filter (KF) and KalmanNet, emphasizing KalmanNet's use of recurrent neural networks.", "section": "3 Methods"}, {"figure_path": "UDi51I8K1p/figures/figures_6_1.jpg", "caption": "Figure 2: Offline Performance. (A) Traces of ground truth index position and velocity (in blue) versus the predictions from each neural decoder. Note that tcFNN only predicts finger velocity. (B) Velocity (left) and position (right) performance in terms of correlation and MSE for each neural decoder. Square markers and error bars denote the mean and the standard error of the mean, respectively. Tested across n = 13 days from both monkeys.", "description": "This figure displays the offline performance comparison of four neural decoders (KF, tcFNN, KalmanNet, and LSTM) in predicting finger kinematics from brain data. Panel (A) shows example traces of ground truth and predicted finger positions and velocities, highlighting the performance differences between the decoders. Panel (B) provides a quantitative comparison using correlation coefficients and mean squared errors (MSE) for both velocity and position predictions, calculated over 13 days of data from two monkeys.  Error bars represent the standard error of the mean.", "section": "4 Results"}, {"figure_path": "UDi51I8K1p/figures/figures_6_2.jpg", "caption": "Figure 3: Online Performance. (A) Traces of the positions of the index (blue) and middle-ring-small (yellow) fingers during online control, across neural decoders. Blue-filled boxes represent index targets in the flexion-extension range, while yellow-filled boxes represent MRS targets. Green-outlined boxes represent successful trials, while red-outlined boxes show failed trials. (B) Online metrics of performance. Throughput, trial times, and path efficiencies are normalized to the corresponding KalmanNet value for each day. Tested on monkey N across T = 601 (KF), 576 (tcFNN), 2801 (KNet), 393 (LSTM) trials in a total of five days.", "description": "This figure shows a comparison of the online performance of four different neural decoders (KF, tcFNN, KalmanNet, and LSTM) for controlling finger movements in a monkey.  Panel A displays time series data showing the index and middle-ring-small finger positions for successful and failed trials for each decoder. Panel B presents a bar graph summarizing the performance metrics (success rate, throughput, trial times, and path efficiency) for each decoder, normalized to KalmanNet's performance for easier comparison.  The results show that KalmanNet outperforms other decoders in most metrics.", "section": "4 Results"}, {"figure_path": "UDi51I8K1p/figures/figures_7_1.jpg", "caption": "Figure 4: KalmanNet as a Non-linear Trust System. (A) Offline trace showing the norm of the Kalman gain for KalmanNet (in green) and for the KF (in orange), together with the predicted velocity for KalmanNet (black). The inset shows the first five seconds of trials, during which KF\u2019s Kalman gain converges to a fixed value [35, Ch. 4]. (B) Average correlations between Kalman gain and velocity for KalmanNet, HKF, and KF, for offline (n = 13 days, across both monkeys) and online (n = 5 days, only Monkey N) trials. (C) Online trace of the norm of the Kalman gain for KalmanNet (green), together with the predicted velocity (black). (D) Offline velocity prediction performance comparison between KF, HKF, and KalmanNet, in terms of correlation coefficient (left) and MSE (right). Arrows represent the addition of a heteroscedastic process noise to transform the KF into HKF. Tested across n = 13 days and both monkeys.", "description": "This figure demonstrates KalmanNet's ability to modulate its trust between the dynamics model and neural observations, acting as a non-linear trust system. Panel A shows an offline trace comparing KalmanNet's Kalman gain (a measure of trust) with the KF's Kalman gain and predicted velocity.  Panel B presents the average correlation between Kalman gain and velocity for KalmanNet, HKF (heteroscedastic Kalman filter), and KF, across both offline and online trials. Panel C displays an online trace mirroring panel A's analysis. Finally, panel D offers a comparison of offline velocity prediction performance (correlation and MSE) between KF, HKF, and KalmanNet, highlighting the performance boost achieved by modulating trust using a recurrent neural network.", "section": "4.2 Modulating Trust between Dynamics and Observations"}, {"figure_path": "UDi51I8K1p/figures/figures_8_1.jpg", "caption": "Figure 5: Robustness to Injected Noise. (A) Offline traces across neural decoders as compared to the ground truth index velocity (black). Grey columns represent noise injections of 5 times the standard deviation of the training dataset distribution, for a duration of one time bin. (B) Change in normalized velocity MSE as the noise magnitude changes, for a fixed noise duration of 3 time bins. (C) Change in normalized velocity MSE as the noise duration changes, for a fixed noise magnitude of 1x the training dataset distribution\u2019s standard deviation. Tested on 13 days for Monkeys N and W.", "description": "This figure demonstrates how different neural decoders respond to injected noise in offline settings.  Panel A shows example velocity traces for each decoder with a noise injection. Panels B and C illustrate how mean squared error (MSE) changes as a function of noise magnitude (B) and duration (C). The results reveal that KalmanNet is most sensitive to the injected noise, while LSTM is most robust.", "section": "4.3 Robustness to Noise and Change in Task Context"}, {"figure_path": "UDi51I8K1p/figures/figures_8_2.jpg", "caption": "Figure 6: Generalization Across Task Contexts. (A) Illustration of how off-context and on-context decoders are trained. Monkeys performed a variation of the task that included a change in wrist angle and a spring that resisted flexion. Off-context decoders were trained on a normal set of trials from the same day and then tested on the last 20% of the trials of the spring+wrist context. On-context decoders were trained and tested on the same spring+wrist context. (B) Change in velocity MSE between on and off-context decoders for each decoder. Tested across n = 6 days of Monkey N.", "description": "This figure demonstrates the generalization ability of different decoders across varying task contexts.  Panel A illustrates the training and testing procedures for both off-context (trained on normal tasks, tested on a spring-restrained task) and on-context (trained and tested on the spring-restrained task) decoders.  Panel B presents the results, showing the increase in mean squared error (MSE) for velocity predictions when decoders are tested in an unfamiliar task context (off-context).  The Kalman filter demonstrates superior generalization compared to the deep-learning models (KalmanNet, tcFNN, and LSTM).", "section": "4 Results"}, {"figure_path": "UDi51I8K1p/figures/figures_15_1.jpg", "caption": "Figure 7: KalmanNet architecture. Diagram of the components of the KalmanNet network. It consists of three GRUs plus seven linear + ReLU layers that try to model the normal way of computing the Kalman gain [25]. F1 through F4 correspond to the input features from equations 9 through 12.", "description": "This figure shows the architecture of the KalmanNet model.  KalmanNet uses a recurrent neural network (RNN) to calculate the Kalman gain, which determines the balance between dynamical predictions and observations. The inputs to the network are four feature vectors (F1, F2, F3, F4) representing differences between current and past Kalman filter states and observations. These features are processed through three gated recurrent units (GRUs) and several linear layers with ReLU activation functions. The output of the network is the Kalman gain, which is used to update the state estimate.", "section": "3.1 Neural Decoders"}, {"figure_path": "UDi51I8K1p/figures/figures_15_2.jpg", "caption": "Figure 8: Sensitivity analysis of sequence length during training. Offline velocity correlation (left) and MSE (right) for KalmanNet, under different sequence lengths employed during training. The horizontal axis represents the number of 50ms bins; the one used throughout corresponds to 60, or equivalently, three seconds. Computed across all n = 13 days for both monkeys.", "description": "This figure displays the results of a sensitivity analysis performed to determine the optimal sequence length used for training the KalmanNet model.  The analysis compares the model's performance across different sequence lengths in terms of velocity correlation and mean squared error (MSE). The results are shown as error bars, indicating the variability across 13 days of testing with two monkeys.  The optimal sequence length was found to be 60 bins (3 seconds).", "section": "A.2 KalmanNet"}, {"figure_path": "UDi51I8K1p/figures/figures_17_1.jpg", "caption": "Figure 9: Resistance to noise injection. (A) Offline velocity MSE for KalmanNet (green) and LSTM (brown) across n=13 days for both monkeys, with noise values closer to those present in the training data. A noise of zero magnitude is equivalent to not adding noise (i.e., baseline shown in Figure 2). (B) Full product of normalized velocity MSE across models for all values of noise magnitude and duration. The logarithmic color bar on the right represents the MSE value for each combination of noise magnitude and duration, normalized to each model\u2019s baseline performance (without noise).", "description": "Figure 9 shows the results of evaluating the robustness of KalmanNet and other models to noise in real-world scenarios.  (A) shows a comparison of the mean squared error (MSE) for KalmanNet and LSTM at varying noise magnitudes, showing that LSTM is more resistant to out-of-distribution noise. (B) presents a heatmap summarizing the MSE across all models tested for combinations of noise magnitude and duration, highlighting the sensitivity of each model to these types of noise.", "section": "4.3 Robustness to Noise and Change in Task Context"}]