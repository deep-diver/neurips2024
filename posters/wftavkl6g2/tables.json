[{"figure_path": "WftaVkL6G2/tables/tables_1_1.jpg", "caption": "Table 1: Communication and computation complexity of various methods to find an e-stationary point for L-smooth, non-convex objectives. N: number of clients, \u03ba: data heterogeneity sup ||\u2207fi(x) - \u2207f(x)|| \u2264 \u03ba. S: number of participating clients per round, K: number of groups for cyclic participation. See Section 3.2 for a description of each participation pattern. We say that an algorithm exhibits reduced communication if its dependence in terms of e is strictly smaller than O(\u03b5\u22124). Derivation of complexities for Amplified FedAvg can be found in Appendix C.", "description": "This table compares the communication and computation complexities of different federated learning algorithms in achieving an \u03f5-stationary point for non-convex objectives.  It considers three scenarios for client participation: i.i.d. (independent and identically distributed), regularized (clients participate almost surely within a fixed window), and cyclic (clients participate in rounds). The table shows the complexity in terms of the number of clients (N), data heterogeneity (\u03ba), number of participating clients per round (S), and number of groups in cyclic participation (K).  The 'Reduced Communication' column indicates whether the algorithm's complexity improves over the naive O(\u03f5\u207b\u2074) bound. The 'Unaffected by Heterogeneity' column indicates whether the algorithm's complexity is independent of the data heterogeneity.", "section": "Related Work"}, {"figure_path": "WftaVkL6G2/tables/tables_49_1.jpg", "caption": "Table 1: Communication and computation complexity of various methods to find an e-stationary point for L-smooth, non-convex objectives. N: number of clients, \u03ba: data heterogeneity sup ||\u2207fi(x) - f(x)|| \u2264 \u03ba. S: number of participating clients per round, K: number of groups for cyclic participation. See Section 3.2 for a description of each participation pattern. We say that an algorithm exhibits reduced communication if its dependence in terms of e is strictly smaller than O(\u03b5-4). Derivation of complexities for Amplified FedAvg can be found in Appendix C.", "description": "This table compares the communication and computation complexity of different federated learning algorithms in achieving an \u03f5-stationary point for non-convex objectives.  It considers various client participation patterns (i.i.d., regularized, and cyclic) and highlights the impact of data heterogeneity (\u03ba) and the number of participating clients (S) on the complexity.  The table indicates whether an algorithm exhibits reduced communication (dependence on \u03f5 is less than O(\u03b5\u207b\u2074)).", "section": "Related Work"}]