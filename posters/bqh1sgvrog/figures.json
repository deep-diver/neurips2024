[{"figure_path": "BQh1SGvROG/figures/figures_1_1.jpg", "caption": "Figure 1: The accuracy under adversarial attacks (APGD-DLR [9]) versus corruption error on out-of-distribution input (ImageNet-C [28]) of various ViT models [16, 23, 38, 42]. AdaNCA improves the robustness of different ViTs against both adversarial attacks and OOD input. *: the same model architecture but with more layers.", "description": "This figure shows a comparison of the performance of several Vision Transformer (ViT) models under adversarial attacks and out-of-distribution (OOD) inputs.  The x-axis represents the corruption error on the ImageNet-C dataset, a measure of the model's robustness to image corruptions.  The y-axis represents the accuracy under adversarial attacks using the APGD-DLR method.  The figure demonstrates that adding AdaNCA (Adaptor Neural Cellular Automata) consistently improves the robustness of various ViT architectures against both adversarial attacks and OOD inputs.  The asterisk (*) indicates that some models use a deeper architecture (more layers) than their counterparts without the asterisk.", "section": "Abstract"}, {"figure_path": "BQh1SGvROG/figures/figures_2_1.jpg", "caption": "Figure 2: Method overview. (a) To improve model performance and robustness, Neural Cellular Automata (NCA) can be inserted into Vision Transformers (ViTs) as Adaptors, hence termed AdaNCA. The details of AdaNCA are presented in Section 3.2. The improvement is maximized when AdaNCA is inserted between two layer sets that each consists of similar layers. (b) The robustness improvement brought by AdaNCA is highly correlated with the corresponding network redundancy quantification of the insert position introduced in Section 3.3. This supports the idea that AdaNCA should be placed between two sets of redundant layers.", "description": "This figure shows the method overview of AdaNCA.  The left panel (a) illustrates how AdaNCA, which uses Neural Cellular Automata (NCA) as adaptors, can be inserted into the Vision Transformer (ViT) architecture to improve performance and robustness.  It highlights the optimal placement of AdaNCA between layers with similar characteristics.  The right panel (b) shows the strong correlation between the robustness improvement achieved by AdaNCA and network redundancy at the insertion point, which suggests that AdaNCA should be inserted into redundant layers.", "section": "3 Method"}, {"figure_path": "BQh1SGvROG/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of AdaNCA architecture. Instead of concatenating the interaction results generated by the depth-wise convolutions, our Dynamic Interaction conducts a point-wise weighted sum on them to improve the efficiency and enhance the performance. The weights are obtained based on the token states so that each token can dynamically adjust, according to the inputs, the interaction strategy. The Multi-scale Dynamic Interaction aggregates the results from Dynamic Interaction, where the convolutions have different dilation rates. Then, to finish one step of evolution, the output is fed into the Update stage.", "description": "This figure shows the architecture of AdaNCA, which uses a dynamic interaction mechanism instead of concatenation for improved efficiency.  It also incorporates multi-scale dynamic interaction to aggregate results from convolutions with varying dilation rates.  Finally, it shows the update stage which completes a single evolutionary step.", "section": "3.2 AdaNCA architecture"}, {"figure_path": "BQh1SGvROG/figures/figures_7_1.jpg", "caption": "Figure 4: Pair-wise layer similarities. Layer sets are marked in red boxes. Swin-B-AdanCA has a clearer stage partition, which might be attributed to AdaNCA acting as an information transmitter between different layer sets.", "description": "This figure shows a comparison of pairwise layer similarities between the Swin-B model and the Swin-B model with AdaNCA.  The red boxes highlight sets of layers with high internal similarity.  The AdaNCA model shows more distinct groupings of layers, suggesting that AdaNCA acts as an intermediary, facilitating information exchange between those sets. This increased modularity in the AdaNCA enhanced model may contribute to improved robustness.", "section": "4.2 Layer similarity structure"}, {"figure_path": "BQh1SGvROG/figures/figures_9_1.jpg", "caption": "Figure 6: Classification accuracy of humans and ViTs on noisy images. The images are perturbed by Gaussian noise with different standard deviations (Magnitude of Noise) and are filtered with different spatial-frequency bands (Frequency of Noise). AdaNCA improves the accuracy on images with certain types of noise (dotted black boxes), indicating that it makes ViTs less sensitive to them. Quantitative results are presented in Appendix C.16.", "description": "This figure shows the results of a noise sensitivity examination.  The leftmost heatmap displays human classification accuracy across different magnitudes and frequencies of Gaussian noise added to images. The remaining heatmaps show the classification accuracy of four different vision transformer models (Swin-Base, Swin-B-AdaNCA, ConViT-Base, and ConViT-B-AdaNCA) under the same noisy image conditions.  The dotted boxes highlight regions where AdaNCA improves model accuracy, suggesting it makes Vision Transformers less sensitive to specific types of noise, similar to human performance.  Appendix C.16 provides quantitative data.", "section": "4.4 Noise sensitivity examination"}, {"figure_path": "BQh1SGvROG/figures/figures_18_1.jpg", "caption": "Figure 7: Top: Visualization of layer redundancy (K(i) = \u043a(1,i+1)+\u043a(\u0456+2, L)) and corresponding robustness improvement \u03b3. Bottom: Visualization of pair-wise layer similarity of the 3 ViTs.", "description": "This figure displays the relationship between layer redundancy and robustness improvement achieved by inserting AdaNCA at various positions within three different ViT models (Swin-tiny, FAN-small-hybrid, and RVT-small-plus). The top row shows the layer redundancy (K(i)), calculated as the sum of the cohesion indices for layer sets before and after position i, plotted against the layer indices. The middle row shows the corresponding robustness improvement (\u03b3), indicating the relative increase in attack failure rate. The bottom row visualizes the pairwise layer similarity using heatmaps, representing the similarity between output feature maps of different layers within each ViT model. This analysis aims to demonstrate that placing AdaNCA at positions with high layer redundancy leads to significant robustness improvement.", "section": "3.3 Insert positions of AdaNCA"}, {"figure_path": "BQh1SGvROG/figures/figures_18_2.jpg", "caption": "Figure 8. The relationship between the layer redundancy \u03ba and robustness improvement \u03b3 by inserting AdaNCA in the corresponding position. \u03b3norm and \u03banorm are obtained by normalizing \u03b3 and \u03ba within the results of each model. Note that the coordinate (1.0, 1.0) has two overlapping points (Swin-tiny and FAN-small-hybrid). Quantitatively, \u03b3norm is significantly correlated with \u03banorm (r = 0.6938, p < 0.001). The linear fit is shown in orange.", "description": "This figure shows the strong correlation between the improvement in model robustness (\u03b3) achieved by inserting AdaNCA at different positions in the network and the layer redundancy (\u03ba) at those positions.  The normalization of both \u03b3 and \u03ba allows for comparison across different ViT models (Swin-tiny, FAN-small-hybrid, and RVT-small-plus). The strong positive correlation (r = 0.6938, p < 0.001) supports the hypothesis that placing AdaNCA in more redundant parts of the network leads to greater robustness improvements.", "section": "3.3 Insert positions of AdaNCA"}, {"figure_path": "BQh1SGvROG/figures/figures_24_1.jpg", "caption": "Figure 9: Visualization of attention maps of Swin-Base [38] and Swin-B-AdaNCA using GradCAM++ [6] on clean images and images with adversarial noise. AdaNCA helps ViTs focus more on the object when facing noise.", "description": "This figure shows a comparison of attention maps generated using GradCAM++ for Swin-Base and Swin-B-AdaNCA models.  The images used include clean images and images with adversarial noise added. The attention maps illustrate how the models focus their attention on different parts of the image.  The aim is to demonstrate that AdaNCA improves the focus of the model on the object of interest, especially when the image includes noise that could distract a standard model.", "section": "C.10 Visualization of attention maps"}, {"figure_path": "BQh1SGvROG/figures/figures_26_1.jpg", "caption": "Figure 10: Layer similarity structures of different ViTs. Layer set marked in red boxes. AdaNCA is inserted between each pair of stages. Kmean is the mean of K of all stages marked out.", "description": "This figure visualizes the layer similarity structures of four different ViT models (Swin-B, RVT-B, FAN-B, and ConViT-B) before and after the insertion of AdaNCA.  Pairwise layer similarity is represented using heatmaps, with red boxes highlighting sets of similar layers.  The caption indicates that AdaNCA is strategically placed between these sets to improve robustness. The metric 'Kmean' quantifies the average layer similarity within each set.", "section": "4.2 Layer similarity structure"}, {"figure_path": "BQh1SGvROG/figures/figures_26_2.jpg", "caption": "Figure 6: Classification accuracy of humans and ViTs on noisy images. The images are perturbed by Gaussian noise with different standard deviations (Magnitude of Noise) and are filtered with different spatial-frequency bands (Frequency of Noise). AdaNCA improves the accuracy on images with certain types of noise (dotted black boxes), indicating that it makes ViTs less sensitive to them. Quantitative results are presented in Appendix C.16.", "description": "This figure presents a comparison of the noise sensitivity of AdaNCA-enhanced ViTs and baseline ViTs, along with human performance.  The images used were perturbed with Gaussian noise across varying magnitudes and frequencies, and then the classification accuracy was evaluated for each model.  The results show AdaNCA improves performance in specific frequency bands, exhibiting more human-like robustness to noise.", "section": "4.4 Results on Image Classification"}, {"figure_path": "BQh1SGvROG/figures/figures_29_1.jpg", "caption": "Figure 12: Visualization of the developing token maps of AdaNCA using PCA. Without Dynamic Interaction, AdaNCA cannot recover from the noisy adversarial inputs. Equipped with it, the model can stick to the evolution path similar to the clean inputs.", "description": "The figure shows the evolution of token maps over time for a clean image and an adversarial example.  The top row illustrates the token evolution without using dynamic interaction in AdaNCA, while the bottom row shows the evolution with dynamic interaction.  The visualization highlights how the dynamic interaction helps the model maintain its evolution path in the presence of adversarial noise, whereas without it, the model is disrupted. This demonstrates that the dynamic interaction significantly improves the robustness of the model against adversarial attacks.", "section": "4.3 Ablation studies"}]