{"references": [{"fullname_first_author": "Sepp Hochreiter", "paper_title": "Long short-term memory", "publication_date": "1997-00-00", "reason": "This paper introduces LSTM, a fundamental recurrent neural network architecture widely used in time series forecasting and other sequence modeling tasks."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-00-00", "reason": "This paper introduces the Transformer architecture, which has significantly impacted various sequence modeling tasks, including long-term time series forecasting."}, {"fullname_first_author": "Boris N Oreshkin", "paper_title": "N-BEATS: Neural basis expansion analysis for interpretable time series forecasting", "publication_date": "2019-00-00", "reason": "This paper proposes N-BEATS, a novel neural network architecture that uses basis functions for time series forecasting, offering interpretability and improved performance."}, {"fullname_first_author": "Haoyi Zhou", "paper_title": "Informer: Beyond efficient transformer for long sequence time-series forecasting", "publication_date": "2021-00-00", "reason": "This paper introduces Informer, a transformer-based model designed to efficiently handle long sequences in time series forecasting, addressing scalability challenges."}, {"fullname_first_author": "Tian Zhou", "paper_title": "Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting", "publication_date": "2022-00-00", "reason": "This paper presents Fedformer, which combines frequency-domain decomposition and transformer architecture for enhanced long-term time series forecasting."}]}