[{"figure_path": "qPpVDzPhSL/figures/figures_1_1.jpg", "caption": "Figure 1: The ProRec Framework for human-oriented binary reverse engineering. The figure shows a simple example of lifting a cumsum function from binary to human readable summarization. The probed contexts synthesized by the cross-modal knowledge prober, while not identical to the oracle source code of the query binary, exhibit informativeness in terms of symbol names and correct loop structure. These contexts help the black-box LLMs to successfully recover the high-level functionality of binary function in the summary that is consistent with the source code summary, moving beyond merely describing its low-level operations.", "description": "This figure illustrates the ProRec framework, which is a novel probe-and-recover framework for human-oriented binary reverse engineering (HOBRE).  It shows how the framework uses a binary-source encoder-decoder model and black-box LLMs to bridge the semantic gap between binary code and source code.  The framework synthesizes source code fragments (probed contexts) that are similar to the original source code, but not identical.  These contexts help the LLMs recover high-level information and functionality from the binary, resulting in more accurate and human-readable summarizations, rather than simply low-level operation descriptions. The example shown focuses on lifting a cumsum function.", "section": "2 ProRec: Reverse Binary by Probing Source Code Foundation Models"}, {"figure_path": "qPpVDzPhSL/figures/figures_3_1.jpg", "caption": "Figure 2: The prober architecture and compute-efficient alignment with limited trainable parameters.", "description": "This figure shows the architecture of the cross-modal knowledge prober used in the ProRec framework.  The prober takes as input a disassembled binary function and its dependency graph. It uses a structure-aware binary function encoder (CODEART) to extract features from the binary code. These features are then projected into the embedding space of a pre-trained source code foundation model (SCFM, like CodeLlama).  A key aspect highlighted is the compute-efficient alignment strategy; only a small part of the model (the projection layer and the last block of the binary encoder) is trainable, while the SCFM remains frozen to leverage its pre-trained knowledge efficiently. The resulting embeddings are then used to synthesize relevant source code fragments.", "section": "2 ProRec: Reverse Binary by Probing Source Code Foundation Models"}, {"figure_path": "qPpVDzPhSL/figures/figures_3_2.jpg", "caption": "Figure 3: Negative log-likelihoods of source functions estimated by base SCLM and those conditioned on its binary counterpart estimated by the aligned prober.", "description": "This figure shows a scatter plot comparing the negative log-likelihood (NLL) estimations of source code functions.  One estimation is from a base Source Code Foundation Model (SCFM) and the other is from the aligned prober (a model that conditions the SCFM on binary code). The strong positive correlation and the trendline suggest that the aligned prober effectively leverages the pre-trained knowledge in the base SCFM while incorporating information from binary code.", "section": "2 ProRec: Reverse Binary by Probing Source Code Foundation Models"}, {"figure_path": "qPpVDzPhSL/figures/figures_7_1.jpg", "caption": "Figure 4: Scores from our proposed GPT4 evaluator for summaries generated basd on GPT3.5-turbo. The x-axes denote context relevance (left) and functionality (right), respectively. Larger scores are better. Bars denote the number of summaries with the corresponding score, and dashed lines denote the number of summaries with at least the corresponding score.", "description": "This figure presents the results from a GPT4-based evaluator assessing the quality of summaries generated using three different methods: directly from decompiled code only, using retrieval-augmented approach, and using the proposed ProRec framework.  The x-axis represents the scores (1-5, with 5 being the best) given by the evaluator for two criteria: context relevance and functionality. The y-axis shows the number of summaries that received each score (bars) and the cumulative number of summaries that received at least that score (dashed lines). The bars and lines are color-coded for each method to compare their performance across different scores and criteria.  The results show that ProRec generally outperforms the other two methods in both context relevance and functionality.", "section": "4.1 Binary Summarization Results"}, {"figure_path": "qPpVDzPhSL/figures/figures_8_1.jpg", "caption": "Figure 5: Binary function name recovery results with and without LLM's internal analysis by using top-k additional contexts on 100 examples.", "description": "This figure shows the results of binary function name recovery experiments with and without using the internal analysis feature of LLMs.  The experiments used different numbers of additional contexts (Top-k) and compared three approaches: direct prompting (Dec-only), retrieval-augmented approach (+Ret), and the proposed ProRec framework. The left panel shows results when LLM's internal analysis is used, while the right panel displays results without it. The shaded areas represent confidence intervals, illustrating the variability in performance. The results show that the use of LLM's internal analysis generally leads to more consistent performance, especially when a larger number of additional contexts is provided.  The Token-level F1 score is shown on the y-axis.", "section": "Analysis"}, {"figure_path": "qPpVDzPhSL/figures/figures_19_1.jpg", "caption": "Figure 1: The ProRec Framework for human-oriented binary reverse engineering. The figure shows a simple example of lifting a cumsum function from binary to human readable summarization. The probed contexts synthesized by the cross-modal knowledge prober, while not identical to the oracle source code of the query binary, exhibit informativeness in terms of symbol names and correct loop structure. These contexts help the black-box LLMs to successfully recover the high-level functionality of binary function in the summary that is consistent with the source code summary, moving beyond merely describing its low-level operations.", "description": "The figure illustrates the ProRec framework, a novel approach to human-oriented binary reverse engineering (HOBRE).  It shows how a cross-modal knowledge prober uses a binary-source encoder-decoder model and a black-box LLM to synthesize relevant source code fragments as context for the LLM. This context helps the LLM to generate human-readable summaries of binary functions that accurately capture high-level functionality, rather than just low-level operations.  An example of lifting a cumulative sum function from binary to a human-readable summary is provided.", "section": "2 ProRec: Reverse Binary by Probing Source Code Foundation Models"}, {"figure_path": "qPpVDzPhSL/figures/figures_20_1.jpg", "caption": "Figure 1: The ProRec Framework for human-oriented binary reverse engineering. The figure shows a simple example of lifting a cumsum function from binary to human readable summarization. The probed contexts synthesized by the cross-modal knowledge prober, while not identical to the oracle source code of the query binary, exhibit informativeness in terms of symbol names and correct loop structure. These contexts help the black-box LLMs to successfully recover the high-level functionality of binary function in the summary that is consistent with the source code summary, moving beyond merely describing its low-level operations.", "description": "This figure illustrates the ProRec framework, which is a novel probe-and-recover framework for human-oriented binary reverse engineering (HOBRE).  It shows how the framework uses a binary-source encoder-decoder model and black-box LLMs to lift a binary function's cumsum function to human-readable summarization.  The key is using a cross-modal knowledge prober to synthesize relevant source code fragments as context, enhancing the accuracy of the black-box LLM's recovery of high-level functionality.", "section": "2 ProRec: Reverse Binary by Probing Source Code Foundation Models"}, {"figure_path": "qPpVDzPhSL/figures/figures_22_1.jpg", "caption": "Figure 1: The ProRec Framework for human-oriented binary reverse engineering. The figure shows a simple example of lifting a cumsum function from binary to human-readable summarization. The probed contexts synthesized by the cross-modal knowledge prober, while not identical to the oracle source code of the query binary, exhibit informativeness in terms of symbol names and correct loop structure. These contexts help the black-box LLMs to successfully recover the high-level functionality of binary function in the summary that is consistent with the source code summary, moving beyond merely describing its low-level operations.", "description": "This figure illustrates the ProRec framework, a novel approach to human-oriented binary reverse engineering (HOBRE). It demonstrates how the framework uses a cross-modal knowledge prober and a black-box LLM to convert binary code into a human-readable summary. The prober synthesizes source code fragments, which, despite not being identical to the original, provide valuable context for the LLM to generate an accurate and high-level summary of the binary function's functionality.", "section": "2 ProRec: Reverse Binary by Probing Source Code Foundation Models"}, {"figure_path": "qPpVDzPhSL/figures/figures_23_1.jpg", "caption": "Figure 1: The ProRec Framework for human-oriented binary reverse engineering. The figure shows a simple example of lifting a cumsum function from binary to human readable summarization. The probed contexts synthesized by the cross-modal knowledge prober, while not identical to the oracle source code of the query binary, exhibit informativeness in terms of symbol names and correct loop structure. These contexts help the black-box LLMs to successfully recover the high-level functionality of binary function in the summary that is consistent with the source code summary, moving beyond merely describing its low-level operations.", "description": "This figure illustrates the ProRec framework, a novel approach to human-oriented binary reverse engineering.  It shows how a binary cumsum function is processed. First, a cross-modal knowledge prober, using a binary-source encoder-decoder model and a pre-trained source code foundation model (SCFM), synthesizes relevant source code fragments as context.  These fragments, even if not identical to the original source code, provide valuable information, such as symbol names and loop structures. Then, a black-box large language model (LLM) acts as a recoverer, using the binary function and the synthesized context to generate a human-readable summarization of the function's high-level functionality, bridging the semantic gap between binary and source code.", "section": "2 ProRec: Reverse Binary by Probing Source Code Foundation Models"}, {"figure_path": "qPpVDzPhSL/figures/figures_24_1.jpg", "caption": "Figure 1: The ProRec Framework for human-oriented binary reverse engineering. The figure shows a simple example of lifting a cumsum function from binary to human readable summarization. The probed contexts synthesized by the cross-modal knowledge prober, while not identical to the oracle source code of the query binary, exhibit informativeness in terms of symbol names and correct loop structure. These contexts help the black-box LLMs to successfully recover the high-level functionality of binary function in the summary that is consistent with the source code summary, moving beyond merely describing its low-level operations.", "description": "This figure illustrates the ProRec framework, which bridges the semantic gap between binary and source code for human-oriented binary reverse engineering.  It shows how a binary function (a cumsum function in this example) is processed through a cross-modal knowledge prober and a black-box LLM to generate a human-readable summarization. The prober synthesizes relevant source code fragments, which, even if not identical to the original source code, provide valuable symbolic information and structural context. This enhanced context allows the LLM to generate a summary that accurately reflects the high-level functionality of the binary function, surpassing summaries based solely on low-level decompiled code.", "section": "ProRec: Reverse Binary by Probing Source Code Foundation Models"}]