[{"type": "text", "text": "Lookback Prophet Inequalities ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ziyad Benomar   \nENSAE, Ecole Polytechnique, FairPlay joint team   \nziyad.benomar@ensae.fr ", "page_idx": 0}, {"type": "text", "text": "Dorian Baudry Department of Statistics, University of Oxford dorian.baudry@ox.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Vianney Perchet CREST, ENSAE, Criteo AI LAB Fairplay joint team vianney.perchet@normalesup.org ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Prophet inequalities are fundamental optimal stopping problems, where a decisionmaker observes sequentially items with values sampled independently from known distributions, and must decide at each new observation to either stop and gain the current value or reject it irrevocably and move to the next step. This model is often too pessimistic and does not adequately represent real-world online selection processes. Potentially, rejected items can be revisited and a fraction of their value can be recovered. To analyze this problem, we consider general decay functions $D_{1},D_{2},\\ldots$ , quantifying the value to be recovered from a rejected item, depending on how far it has been observed in the past. We analyze how lookback improves, or not, the competitive ratio in prophet inequalities in different order models. We show that, under mild monotonicity assumptions on the decay functions, the problem can be reduced to the case where all the decay functions are equal to the same function $x\\mapsto\\gamma x$ , where $\\gamma=\\operatorname*{inf}_{x>0}\\operatorname*{inf}_{j\\geq1}D_{j}(x)/x$ . Consequently, we focus on this setting and refine the analyses of the competitive ratios, with upper and lower bounds expressed as increasing functions of $\\gamma$ . ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Optimal stopping problems constitute a classical paradigm of decision-making under uncertainty [Dynkin, 1963] Typically, in online algorithms, these problems are formalized as variations of the secretary problem [Lindley, 1961] or the prophet inequality [Krengel and Sucheston, 1977]. In the context of the prophet inequality, the decision-maker observes a finite sequence of items, each having a value drawn independently from a known probability distribution. Upon encountering a new item, the decision-maker faces the choice of either accepting it and concluding the selection process or irreversibly rejecting it, with the objective of maximizing the value of the selected item. However, while the prophet inequality problem is already used in scenarios such as posted-price mechanism design [Hajiaghayi et al., 2007] or online auctions [Syrgkanis, 2017], it might present a pessimistic model of real-world online selection problems. Indeed, it is in general possible in practice to revisit previously rejected items and potentially recover them or at least recover a fraction of their value. ", "page_idx": 0}, {"type": "text", "text": "Consider for instance an individual navigating a city in search of a restaurant. When encountering one, they have the choice to stop and dine at this place, continue their search, or revisit a previously passed option, incurring a utility cost that is proportional to the distance of backtracking. In another example drawn from the real estate market, homeowners receive offers from potential buyers. The decision to accept or reject an offer can be revisited later, although buyer interest may have changed, resulting in a potentially lower offer or even a lack of interest. Lastly, in the financial domain, an agent may choose to sell an asset at its current price or opt for a lookback put option, allowing them to sell at the asset\u2019s highest price over a specified future period. To make a meaningful comparison between the two, one must account for factors such as discounting (time value of money) and the cost of the option. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "1.1 Formal problem and notation ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "To encompass diverse scenarios, we propose a general way to quantify the cost incurred by the decision-maker for retrieving a previously rejected value. ", "page_idx": 1}, {"type": "text", "text": "Definition 1.1 (Decay functions). Let $\\mathcal{D}=(D_{1},D_{2},\\ldots)$ be a sequence of non-negative functions defined on $[0,\\infty)$ . $I t$ is a sequence of decay functions $i f$ ", "page_idx": 1}, {"type": "text", "text": "(i) $D_{1}(x)\\leq x$ for all $x\\geq0$ , (ii) the sequence $(D_{j}(x))_{j\\geq1}$ is non-increasing for all $x\\geq0$ , (iii) the function $D_{j}$ is non-decreasing for all $j\\geq1$ . ", "page_idx": 1}, {"type": "text", "text": "In the context of decay functions $\\mathcal{D}$ , if a value $x$ is rejected, the algorithm can recover $D_{j}(x)$ after $j$ subsequent steps. The three conditions defining decay functions serve as fundamental prerequisites for the problem. The first and second conditions ensure that the recoverable value of a rejected item can only diminish over time, while the final condition implies that an increase in the observed value $x$ corresponds to an increase in the potential recovered value. Although the non-negativity of the decay functions is non-essential, we retain it for convenience, as we can easily revert to this assumption by considering that the algorithm has a reward of zero by not selecting any item. ", "page_idx": 1}, {"type": "text", "text": "The motivating examples that we introduced can be modeled respectively with decay functions of the form $D_{j}(x)=x-c_{j}$ where $(c_{j})_{j\\geq1}$ is a non-decreasing positive sequence, $\\dot{D_{j}}(x)=\\xi_{j}x$ with $\\xi_{j}\\sim\\beta(p_{j})$ and $(p_{j})_{j\\geq1}$ a non-increasing sequence of probabilities, and $D_{j}(x)=\\lambda^{j}x$ with $\\lambda\\in[0,1]$ . In one of these examples (housing market), the natural model is to use random decay functions: the buyer makes the same offer if they are still interested, and offers 0 otherwise. Definition 1.1 can be easily extended to consider this case. However, to enhance the clarity of the presentation, we only discuss the deterministic case in the rest of the paper. In Appendix $\\mathrm{D}$ , we explain how all the proofs and theorems can be generalized to that case. ", "page_idx": 1}, {"type": "text", "text": "The $\\mathcal{D}$ -prophet inequality. For any decay functions $\\mathcal{D}$ , we define the $\\mathcal{D}$ -prophet inequality problem, where the decision maker, knowing $\\mathcal{D}$ , observes sequentially the values $X_{1},\\ldots,X_{n}$ , with $X_{i}$ drawn from a known distribution $F_{i}$ for all $i\\in[n]$ . If they decide to stop at some step $\\tau$ , then instead of gaining $X_{\\tau}$ as in the classical prophet inequality, they can choose to select the current item $X_{\\tau}$ and have its full value, or select any item $X_{i}$ with $i<\\tau$ among the rejected ones but only recover a fraction $D_{\\tau-i}(X_{i})\\leq X_{i}$ of its value. Therefore, if an algorithm ALG stops at step $\\tau$ its reward is ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{A L G}^{\\mathcal{D}}(X_{1},\\ldots,X_{n})=\\operatorname*{max}\\{X_{\\tau},D_{1}(X_{\\tau-1}),D_{2}(X_{\\tau-2}),\\ldots,D_{\\tau-1}(X_{1})\\}}\\\\ {=\\displaystyle\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{D_{i}(X_{\\tau-i})\\}\\;,\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "with the convention $D_{0}(x)=x$ . If the algorithm does not stop at any step before $n$ , then its reward is ${\\sf A L G}^{\\mathcal{D}}(X_{1},\\ldots,X_{n})=\\operatorname*{max}_{1\\leq i\\leq n}\\{D_{i}(X_{\\pi(n-i+1)})\\}$ , which corresponds to $\\tau=n+1$ . ", "page_idx": 1}, {"type": "text", "text": "Remark 1.1. As in the standard prophet inequality, an algorithm is defined by its stopping time, i.e., the rule set to decide whether to stop or not. Hence, $i f D$ and $\\mathcal{D}^{\\prime}$ are two different sequences of decay functions, any algorithm for the $\\mathcal{D}$ -prophet inequality, although its stopping time might depend on the particular sequence of functions $\\mathcal{D}$ , is also an algorithm for the $\\mathcal{D}^{\\prime}$ -prophet inequality. Consider for example an algorithm $A L G$ with stopping time $\\tau(\\mathcal{D})$ that depends on $\\mathcal{D}$ . Its reward in the $\\mathcal{D}^{\\prime}$ -prophet inequality is $\\begin{array}{r}{A L G^{\\mathcal{D}^{\\prime}}(X_{1},\\ldots,X_{n})=\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{D_{i}^{\\prime}(X_{\\tau(\\mathcal{D})-i})\\}.}\\end{array}$ ", "page_idx": 1}, {"type": "text", "text": "Observation order. Several variants of the prophet inequality problem have been studied, depending on the order of observations. The standard model is the adversarial (or fixed) order: The instance of the distributions $F_{1},\\ldots,F_{n}$ is chosen by an adversary, and the algorithm observes the samples $X_{1}\\sim F_{1},\\ldots,X_{n}\\sim F_{n}$ in this order [Krengel and Sucheston, 1977, 1978]. In the random order model, the adversary can again choose the distributions, but the algorithm observes the samples in a uniformly random order. Another setting in which the observation order is no longer important is the IID model [Hill and Kertz, 1982, Correa et al., 2021b], where all the values are sampled independently from the same distribution $F$ . The $\\mathcal{D}$ -prophet inequality is well-defined in each of these different order models: if the items are observed in the order $X_{\\pi(1)},\\ldots,X_{\\pi(n)}$ with $\\pi$ a permutation of $[n]$ , then the reward of the algorithm is $\\mathsf{A L G}^{\\mathcal{D}}(X_{1},\\ldots,X_{n})=\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{D_{i}(X_{\\pi(\\tau-i)})\\}$ . In this paper, we study the $\\mathcal{D}$ -prophet inequality in the three models we presented, providing lower and upper bounds in each of them. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Competitive ratio. In the $\\mathcal{D}$ -prophet inequality, an input instance $I$ is a finite sequence of probability distributions $(F_{1},\\ldots,F_{n})$ . Thus, for any instance $I$ , we denote by $\\mathbb{E}[\\mathsf{A L G}^{\\mathcal{D}}(I)]$ the expected reward of $\\mathsf{A L G}$ given $I$ as input, and we denote by $\\mathbb{E}[{\\sf O P T}(I)]$ the expected maximum of independent random variables $(X_{i})_{i\\in[n]}$ , where $X_{i}\\sim F_{i}$ . With these notations, we define the competitive ratio, which will be used to measure the quality of the algorithms. ", "page_idx": 2}, {"type": "text", "text": "Definition 1.2 (Competitive ratio). Let $\\mathcal{D}$ be a sequence of decay functions and $A L G$ an algorithm. We define the competitive ratio of ALG by ", "page_idx": 2}, {"type": "equation", "text": "$$\nC R^{\\cal D}(A L G)=\\operatorname*{inf}_{I}\\frac{\\mathbb{E}[A L G^{\\cal D}(I)]}{\\mathbb{E}[O P T(I)]}\\;,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with the infimum taken over the tuples of all sizes of non-negative distributions with finite expectation. ", "page_idx": 2}, {"type": "text", "text": "An algorithm is said to be $\\alpha$ -competitive if its competitive ratio is at least $\\alpha$ , which means that for any possible instance $I$ , the algorithm guarantees a reward of at least $\\alpha\\mathbb{E}[{\\mathsf{O P T}}(I)]$ . The notion of competitive ratio is used more broadly in competitive analysis as a metric to evaluate online algorithms [Borodin and El-Yaniv, 2005]. ", "page_idx": 2}, {"type": "text", "text": "1.2 Contributions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "It is trivial that non-zero decay functions $\\mathcal{D}$ guarantee a better reward compared to the classical prophet inequality. However, in general, this is not sufficient to conclude that the standard upper bounds or the competitive ratio of a given algorithm can be improved. Hence, a first key question is: what condition on $\\mathcal{D}$ is necessary to surpass the conventional upper bounds of the classical prophet inequality? Surprisingly, the answer hinges solely on the constant $\\gamma_{\\mathscr{D}}$ , defined as follows, ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\gamma_{\\cal D}=\\operatorname*{inf}_{x>0}\\operatorname*{inf}_{j\\geq1}\\left\\{\\frac{D_{j}(x)}{x}\\right\\}\\;.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In the adversarial order model, we demonstrate that the optimal competitive ratio achievable in the $\\mathcal{D}$ -prophet inequality is determined by the parameter $\\gamma_{\\mathscr{D}}$ alone. Additionally, in both the random order and IID models, we demonstrate the essential requirement of $\\gamma_{\\mathscr D}>0$ for breaking the upper bounds of the classical prophet inequality. In particular, this implies that no improvement can be made with decay functions of the form $\\bar{D_{j}}\\bar{(}x\\bar{)}=\\bar{x}-c_{j}$ with $c_{j}>0$ , or $D_{j}(x)=\\bar{\\lambda^{j}}x$ with $\\lambda\\in[0,1)$ . Subsequently, we develop algorithms and provide upper bounds in the $\\mathcal{D}$ -prophet inequality, uniquely dependent on the parameter $\\gamma_{\\mathscr{D}}$ . We illustrate them in Figure 1, comparing them with the identity function $\\gamma\\mapsto\\gamma$ , which is a trivial lower bound. ", "page_idx": 2}, {"type": "text", "text": "1.3 Related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Prophet inequalities. The first prophet inequality was proven by Krengel and Sucheston [Krengel and Sucheston, 1977, 1978] in the setting where the items are observed in a fixed order, demonstrating that the dynamic programming algorithm has a competitive ratio of $1/2$ , which is the best possible. It was shown later that the same guarantee can be obtained with simpler algorithms [Samuel-Cahn, 1984, Kleinberg and Weinberg, 2012], accepting the first value above a carefully chosen threshold. For a more comprehensive and historical overview, we refer the interested reader to surveys on the problem such as [Lucier, 2017, Correa et al., 2019]. Prophet inequalities have immediate applications in mechanism design [Hajiaghayi et al., 2007, Deng et al., 2022, Psomas et al., 2022, Makur et al., 2024], auctions [Syrgkanis, 2017, D\u00fctting et al., 2020], resource management [Sinclair et al., 2023], and online matching [Cohen et al., 2019, Ezra et al., 2020, Jiang et al., 2021, Papadimitriou et al., 2021, Brubach et al., 2021]. Many variants and related problems have been studied, including, for example, the matroid prophet inequality [Kleinberg and Weinberg, 2012, Feldman et al., 2016], prophet inequality with advice [Diakonikolas et al., 2021], and variants with fairness considerations [Correa et al., 2021a, Arsenis and Kleinberg, 2022]. ", "page_idx": 2}, {"type": "image", "img_path": "cg1vwt5Xou/tmp/2cd26b49b475087a794c83b9a2c00b113da324839e70ed43cdb7c284eee98b3a.jpg", "img_caption": ["Figure 1: Lower and upper bounds on the competitive ratio in the $\\mathcal{D}$ -prophet inequality depending on $\\gamma_{\\mathscr{D}}$ , in the adversarial order $\\mathrm{Thm}\\,4.3\\rangle$ ), random order $\\mathrm{Thm}\\,4.4)$ and IID $(\\mathrm{Thm}\\,4.6)$ models "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Random order and IID models. Esfandiari et al. [2017] introduced the prophet secretary problem, where items are observed in a uniformly random order, and they proved a $\\left(1\\,-\\,\\frac{1}{e}\\right)$ -competitive algorithm. Correa et al. [2021c] showed later a competitive ratio of 0.669, and Harb [2024] enhanced it to 0.6724, which c\u221aurrently stands as the best-known solution for the problem. They also proved an upper bound of $\\sqrt{3}-1\\approx0.732$ , which was improved to 0.7254 in [Bubna and Chiplunkar, 2023] then 0.723 in [Giambartolomei et al., 2023]. Addressing the gap between the lower and upper bound remains an engaging and actively pursued open question. On the other hand, the study of prophet inequalities with IID random variables dates back to papers such as [Hill and Kertz, 1982, Kertz, 1986], demonstrating guarantees on the dynamic programming algorithm. The problem was completely solved in [Correa et al., 2021b], where the authors show that the competitive ratio of the dynamic programming algorithm is 0.745, thus it constitutes an upper bound on the competitive ratio of any algorithm, and they give a simpler adaptive threshold algorithm matching it. Another setting that we do not study in this paper, is the order selection model, where the decision-maker can choose the order in which the items are observed, knowing their distributions [Chawla et al., 2010, Beyhaghi et al., 2021, Peng and Tang, 2022]. ", "page_idx": 3}, {"type": "text", "text": "Beyond the worst-case. In recent years, there has been increasing interest in exploring ways to exceed the worst-case upper bounds of online algorithms by providing the decision-maker with additional capabilities. A notable research avenue is learning-augmented algorithms [Lykouris and Vassilvtiskii, 2018], which equip the decision-maker with predictions or hints about unknown variables of the problem. Multiple problems have been studied in this framework, such as scheduling [Purohit et al., 2018, Lassota et al., 2023, Benomar and Perchet, 2024b], matching [Antoniadis et al., 2020, Dinitz et al., 2021, Chen et al., 2022], caching [Antoniadis et al., 2023, Chlkedowski et al., 2021, Christianson et al., 2023], the design of data structures [Kraska et al., 2018, Lin et al., 2022, Benomar and Coester, 2024], and in particular, online selection problems [D\u00fctting et al., 2021, Sun et al., 2021, Benomar et al., 2023, Benomar and Perchet, 2024a, Diakonikolas et al., 2021]. More related to our setting, the ability to revisit items in online selection has been studied in problems such as the multiple-choice prophet inequality, where the algorithm can select up to $k$ items and its reward is the maximum selected value [Assaf and Samuel-Cahn, 2000]. This allows for revisiting up to $k$ items, chosen during the execution, for final acceptance or rejection decisions. Similarly, in Pandora\u2019s box problem [Weitzman, 1978, Kleinberg et al., 2016] and its variants [Esfandiari et al., 2019, Gergatsouli and Tzamos, 2022, Atsidakou et al., 2024, Gergatsouli and Tzamos, 2024, Berger et al., 2024], the decision maker decides the observation order of the items, but a cost $c_{i}$ is paid for observing each value $X_{i}$ , with the gain being the maximum observed value minus the total opening costs. A very recent work investigates a scenario closely related to the lookback prophet inequality [Ekbatani et al., 2024] where, upon selecting a candidate $X_{i}$ , the decision-maker has the option to discard it and choose a new value $X_{j}$ at any later step $j$ , at a buyback cost of $f X_{i}$ , where $f>0$ . The authors present an optimal algorithm for the case when $f\\geq1$ , although the problem remains open for $f\\in(0,1)$ . Other problems were studied in similar settings, such as online matching [Ekbatani et al., 2022] and online resource allocation [Ekbatani et al., 2023]. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "2 From $\\mathcal{D}$ -prophet to the $D_{\\infty}$ -prophet inequality ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Let us consider a sequence $\\mathcal{D}$ of decay functions. By Definition 1.1, for any $x\\in[0,\\infty]$ the sequence $(D_{j}(x))_{j\\geq1}$ converges, since it is non-increasing and non-negative. Hence, there exists a mapping $D_{\\infty}$ such that for any $x\\geq0$ , $\\begin{array}{r}{\\operatorname*{lim}_{j\\to\\infty}D_{j}(x)=\\bar{D}_{\\infty}(x)}\\end{array}$ . Furthermore, we can easily verify that $D_{\\infty}$ is non-decreasing and satisfies $\\bar{D_{\\infty}}(x)\\in[0,x]$ for all $x\\geq0$ . ", "page_idx": 4}, {"type": "text", "text": "Thanks to these properties, we obtain that $(D_{\\infty})_{j\\geq1}$ also satisfies Definition 1.1, and is hence a valid sequence of decay functions. We thus refer to the corresponding problem as the $D_{\\infty}$ -prophet inequality. Since $D_{j}\\geq D_{\\infty}$ for any $j\\geq1$ , it is straightforward that the stopping problem with the decay functions $D_{\\infty}$ would be less favorable to the decision-maker. More precisely, for any random variables $X_{1},\\ldots,X_{n}$ , observation order $\\pi$ , and algorithm ALG with stopping time $\\tau$ , it holds that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathsf{A L G}^{D}(X_{1},\\hdots,X_{n}):=\\operatorname*{max}\\{X_{\\pi(\\tau)},\\operatorname*{max}_{i<\\tau}D_{\\tau-i}(X_{\\pi(i)})\\}\\geq\\operatorname*{max}\\{X_{\\pi(\\tau)},\\operatorname*{max}_{i<\\tau}D_{\\infty}(X_{\\pi(i)})\\}\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "which corresponds to the output of ALG (with the same decision rule) when all the decay functions are equal to $D_{\\infty}$ . Therefore, any guarantees established for algorithms in the $D_{\\infty}$ -prophet inequality naturally extend to the $\\mathcal{D}$ -prophet inequality. However, it remains uncertain whether the $\\mathcal{D}$ -prophet inequality can yield improved competitive ratios compared to the $D_{\\infty}$ -prophet inequality. In the following, we prove that this is not the case, for all the order models presented in Section 1. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2.1. Let $D_{\\infty}$ be the pointwise limit of the sequence of decay functions $\\mathcal D=(D_{j})_{j\\geq1}$ . Then for any instance $I=\\left(F_{1},\\ldots,F_{n}\\right)$ of non-negative distributions, it holds in the adversarial and the random order models that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\forall A L G:C R^{D}(A L G)\\leq\\operatorname*{sup}_{A}\\frac{\\mathbb{E}[A^{D_{\\infty}}(I)]}{\\mathbb{E}[O P T(I)]}\\ ,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the supremum is taken over all the online algorithms $A.$ . In the IID model, the same inequality holds with an additional $O(n^{-1/3})$ term, which depends only on the size n of the instance. ", "page_idx": 4}, {"type": "text", "text": "The main implication of Theorem 2.1 is the following corollary. ", "page_idx": 4}, {"type": "text", "text": "Corollary 2.1.1. In the adversarial order and the random order models, $i f\\mathbf{\\overline{{{A}}}}_{\\infty}$ is an optimal algorithm for the $D_{\\infty}$ -prophet inequality, i.e. with maximal competitive ratio, then $\\bar{A}_{\\infty}$ is also optimal for the $\\mathcal{D}$ -prophet inequality. Moreover, it holds that ", "page_idx": 4}, {"type": "equation", "text": "$$\nC R^{\\scriptscriptstyle D}(\\bar{A}_{\\infty})=C R^{\\scriptscriptstyle D\\infty}(\\bar{A}_{\\infty})\\;.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "A direct consequence of this result is that, in the adversarial and the random order models, the asymptotic decay $D_{\\infty}$ entirely determines the competitive ratio that is achievable and the upper bounds for the $\\mathcal{D}$ -prophet inequality. Therefore, we can restrict our analysis to algorithms designed for the problem with identical decay function. In the IID model, the same conclusion holds if the worst-case instances are arbitrarily large, making the additional $O(n^{-1/3})$ term vanish. This is the case in particular in the classical IID prophet inequality [Hill and Kertz, 1982]. ", "page_idx": 4}, {"type": "text", "text": "2.1 Sketch of the proof of Theorem 2.1 ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "While we use different techniques for each order model considered, all the proofs share the same underlying idea. Given any instance $I$ of non-negative distributions, we build an alternative instance $J$ such that the reward of any algorithm on $I$ with decay functions $\\mathcal{D}=(D_{j})_{j}$ is at most its reward on $J$ with decay functions all equal to $D_{\\infty}$ . To do this, we essentially introduce an arbitrarily large number of zero values between two successive observations drawn from distributions belonging to $I$ . Hence, under $J$ , the algorithm cannot recover much more than a fraction $D_{\\infty}(X)$ for any past observation $X$ collected from a distribution $F\\in I$ . ", "page_idx": 4}, {"type": "text", "text": "In the adversarial case, implementing this idea is straightforward, since nature can build $J$ by directly inserting $m$ zeros between each pair of consecutive values, and the result is obtained by making $m$ arbitrarily large. For the random order model, we use the same instance $J$ , but extra steps are needed to prove that the number of steps between two non-zero values is very large with high probability. ", "page_idx": 5}, {"type": "text", "text": "Moving to the IID model, an instance $I$ is defined by a pair $(F,n)$ , where $F$ is a non-negative distribution, and $n$ is the size of the instance. In this scenario, we consider an instance consisting of $m>n$ IID random variables $(Y_{i})_{i\\in[m]}$ , each sampled from $F$ with probability $n/m$ , and equal to zero with the remaining probability. We again achieve the desired result by letting $m$ be arbitrarily large compared to $n$ . However, the number of variables sampled from $F$ is not fixed; it follows a Binomial distribution with parameters $(m,n/m)$ . We control this variability by using concentration inequalities, which causes the additional term $O(n^{-1/3})$ . ", "page_idx": 5}, {"type": "text", "text": "3 From $D_{\\infty}$ -prophet to the $\\gamma_{D}$ -prophet inequality ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As discussed in Section 2, Theorem 2.1 implies that, for either establishing upper bounds or guarantees on the competitive ratios of algorithms, it is sufficient to study the $D_{\\infty}$ -prophet inequality, where all the decay functions are equal to $D_{\\infty}$ . The remaining question is then to determine which functions $D_{\\infty}$ allow to improve upon the upper bounds of the classical prophet inequality. Before tackling this question, let us make some observations regarding algorithms in the $D_{\\infty}$ -prophet inequality. ", "page_idx": 5}, {"type": "text", "text": "In the $D_{\\infty}$ -prophet inequality, it is always possible to have a reward of $D_{\\infty}(\\operatorname*{max}_{i\\in[n]}X_{i})$ by rejecting all the items and then selecting the maximum by the end. Thus, it is suboptimal to stop at a step $i$ where $X_{i}\\le D_{\\infty}(\\operatorname*{max}_{j<i}X_{j})$ . An algorithm respecting this decision rule is called rational. ", "page_idx": 5}, {"type": "text", "text": "Lemma 3.1. For any rational algorithm $A L G$ in the $D_{\\infty}$ -prophet inequality, if we denote by $\\tau$ its stopping time, then for any instance $I=(F_{1},\\ldots,F_{n})$ and $X_{i}\\sim F_{i}$ for all $i\\in[n]$ we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n{\\cal A}{\\cal L}G^{D_{\\infty}}(X_{1},\\ldots,X_{n})={\\cal A}{\\cal L}G^{0}(X_{1},\\ldots,X_{n})+D_{\\infty}\\big(\\operatorname*{max}_{i\\in[n]}X_{i}\\big)\\mathbb{1}_{\\tau=n+1}\\;,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $A L G^{0}$ denotes the reward of the algorithm in the standard prophet inequality. Moreover, the optimal dynamic programming algorithm in the $D_{\\infty}$ -prophet inequality is rational. ", "page_idx": 5}, {"type": "text", "text": "The best competitive ratio in the $D_{\\infty}$ -prophet inequality is achieved, possibly among others, by the optimal dynamic programming algorithm, which is a rational algorithm by the previous Lemma. Hence, it suffices to prove upper bounds on rational algorithms. We use this observation to prove the next propositions. ", "page_idx": 5}, {"type": "text", "text": "Pmroodpelo, stihtiaotn 3.2. In the $D_{\\infty}$ -prophet inequality, $\\begin{array}{r}{i f\\operatorname*{inf}_{x>0}\\frac{D_{\\infty}(x)}{x}=0,}\\end{array}$ D\u221ex(x) = 0, then it holds, in any order ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\forall A L G:C R^{D_{\\infty}}(A L G)\\leq\\operatorname*{sup}_{A}C R^{0}(A)\\ ,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the supremum is taken over all the online algorithms $A,$ , and CR denotes the competitive ratio in the standard prophet inequality. ", "page_idx": 5}, {"type": "text", "text": "Proposition 3.2 implies that if $\\begin{array}{r}{\\operatorname*{inf}_{x>0}\\frac{D_{\\infty}(x)}{x}=0}\\end{array}$ D\u221ex(x) = 0, then, in any order model, any upper bound on the competitive ratios of all algorithms in the classical prophet inequality is also an upper bound on the competitive ratios of all algorithm in the $D_{\\infty}$ -prophet inequality. Consequently, for surpassing the upper bounds of the classical prophet inequality, it is necessary to have, for some $\\gamma>0$ , that $D_{\\infty}(\\bar{x})\\geq\\gamma x$ for all $x\\geq0$ . Furthermore, the next Proposition allows giving upper bounds in the $D_{\\infty}$ -prophet inequality that depend only on $\\operatorname*{inf}_{x>0}{\\frac{D_{\\infty}(x)}{x}}$ . ", "page_idx": 5}, {"type": "text", "text": "Proposition 3.3. Let $\\gamma=\\operatorname*{inf}_{x>0}D_{\\infty}(x)/x$ , and $0<a<b$ . Consider an instance $I$ of distributions with support in $\\{0,a,b\\}$ , then in any order model and for any algorithm $A L G$ we have that ", "page_idx": 5}, {"type": "equation", "text": "$$\nC R^{D_{\\infty}}(A L G)\\leq\\operatorname*{sup}_{A}\\frac{\\mathbb{E}[A^{\\gamma}(I)]}{\\mathbb{E}[O P T(I)]}\\ ,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathbb{E}[A^{\\gamma}(I)]$ is the reward of $A$ if all the decay functions were equal to $x\\mapsto\\gamma x$ ", "page_idx": 5}, {"type": "text", "text": "The core idea for proving this proposition is that rescaling an instance, i.e. considering $(r X_{i})_{i\\in[n]}$ instead of $(X_{i})_{i\\in[n]}$ , has no impact in the classical prophet inequality. However, in the $D_{\\infty}$ -prophet inequality, rescaling can be exploited to adjust the ratio $\\frac{D_{\\infty}(r x)}{r x}$ . By considering instances with random variables taking values in $\\{0,a,b\\}$ almost surely, where $a<b$ , a reasonable algorithm facing such an instance would never reject the value $b$ . Consequently, the value it recovers from rejected items is either $D_{\\infty}(0)=0$ or $\\bar{D_{\\infty}}(a)$ . Rescaling this instance by a factor $r=s/a$ and taking the ratio to the expected maximum, the term D\u221es(s)appears, with s a free parameter that can be chosen to satisfy D\u221e(s) $\\begin{array}{r}{\\frac{D_{\\infty}(s)}{s}\\to\\operatorname*{inf}_{x>0}\\frac{D_{\\infty}(x)}{x}=\\gamma_{\\mathcal{D}}}\\end{array}$ ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "As a consequence, if $\\begin{array}{r}{\\operatorname*{inf}_{x>0}\\frac{D_{\\infty}(x)}{x}=\\gamma}\\end{array}$ , then any upper bound obtained in the $\\gamma$ -prophet inequality (when the decay functions are all equal to $x\\mapsto\\gamma x)$ ) using instances of random variables $(X_{1},\\bot...,X_{n})$ satisfying $X_{i}\\in\\{0,a,b\\}$ a.s. for all $i$ , is also an upper bound in the $D_{\\infty}$ -prophet inequality. ", "page_idx": 6}, {"type": "text", "text": "Implication Consider any sequence $\\mathcal{D}$ of decay functions, and define ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\gamma_{\\mathscr{D}}:=\\operatorname*{inf}_{x>0}\\left\\{\\frac{D_{\\infty}(x)}{x}\\right\\}=\\operatorname*{inf}_{x>0}\\operatorname*{inf}_{j\\geq1}\\left\\{\\frac{D_{j}(x)}{x}\\right\\}\\;.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "For any $x>0$ and $j\\geq1$ it holds that $D_{j}(x)\\geq\\gamma_{\\cal D}x$ , therefore, any guarantees on the competitive ratio of an algorithm in the $\\gamma_{\\mathscr{D}}$ -prophet inequality are valid in the $\\mathcal{D}$ -prophet inequality, under any order model. Furthermore, combining Theorem 2.1 and Proposition 3.3, we obtain that for any instance $I$ of random variables taking values in a set $\\{0,a,b\\}$ it holds that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\forall\\mathsf{A L G}:\\mathsf{C R}^{\\scriptscriptstyle D}(\\mathsf{A L G})\\leq\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{\\gamma_{D}}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\;,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with an additional term of order $O(n^{-1/3})$ in the IID model. In the particular case where $\\gamma_{\\mathscr D}=0$ , Proposition 3.3 with Theorem 2.1 give a stronger result, showing that no algorithm can surpass the upper bounds of the classical prophet inequality. This is true also for the IID model since the instances used to prove the tight upper bound of $\\approx0.745$ are of arbitrarily large size [Hill and Kertz, 1982]. ", "page_idx": 6}, {"type": "text", "text": "Therefore, by studying the $\\gamma$ -prophet inequality for $\\gamma\\in[0,1]$ , we can prove upper bounds and lower bounds on the $\\mathcal{D}$ -prophet inequality for any sequence $\\mathcal{D}$ of decay functions. ", "page_idx": 6}, {"type": "text", "text": "4 The $\\gamma$ -prophet inequality ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We study in this section the $\\gamma$ -prophet inequality, where all the decay functions are equal to $x\\mapsto\\gamma x$ , for some $\\gamma\\in[0,1]$ . For any algorithm ALG with stopping time $\\tau$ and random variables $X_{1},\\ldots,X_{n}$ , if the observation order is $\\pi$ , we use the notation ", "page_idx": 6}, {"type": "equation", "text": "$$\n{\\sf A L G}^{\\gamma}(X_{1},\\ldots,X_{n})=\\operatorname*{max}\\{X_{\\pi(\\tau)},\\gamma X_{\\pi(\\tau-1)},\\ldots,\\gamma X_{\\pi(1)}\\}\\ .\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "and we denote by $\\mathsf{C R}^{\\gamma}(\\mathsf{A L G})$ the competitive ratio of ALG in this setting. In the following, we provide theoretical guarantees for the $\\gamma$ -prophet inequality. ", "page_idx": 6}, {"type": "text", "text": "For each observation order, we first derive upper bounds on the competitive ratio of any algorithm, depending on $\\gamma$ , using only hard instances satisfying the condition of Proposition 3.3. This would guarantee that the upper bounds extend to the $\\mathcal{D}$ -prophet inequality if $\\gamma_{\\mathscr D}=\\gamma$ . Then, we design single-threshold algorithms with well-chosen thresholds depending on $\\gamma$ and the distributions, with competitive ratios improving with $\\gamma$ . A crucial property of single-threshold algorithms, which we use to estimate their competitive ratios, is that their reward satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\n{\\mathsf{A L G}}^{\\gamma}(X_{1},\\ldots,X_{n})={\\mathsf{A L G}}^{0}(X_{1},\\ldots,X_{n})+\\gamma(\\operatorname*{max}_{i}X_{i})\\mathbb{1}_{(\\operatorname*{max}_{i}X_{i}<\\theta)}\\ .\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The additional term appearing due to $\\gamma$ depends only on $\\operatorname*{max}_{i\\in[n]}X_{i}$ , which is the reward of the prophet against whom we compete. This property is not satisfied by more general class of algorithms such as multiple-threshold algorithms, where each observation $X_{\\pi(i)}$ is compared with a threshold $\\theta_{i}$ . ", "page_idx": 6}, {"type": "text", "text": "Remark 4.1. We only consider instances with continuous distributions in the proofs of lower bounds. The thresholds $\\theta$ considered are such that $\\operatorname*{Pr}(\\operatorname*{max}_{i\\in[n]}X_{i}\\geq\\theta)=g(\\gamma,n,\\pi)$ , with $g$ depending on $\\gamma,$ , the order model $\\pi$ and the size of the instance $n$ . Such a threshold is always guaranteed to exist when the distributions are continuous. However, as in the prophet inequality, the algorithms can be easily adapted to non-continuous distributions by allowing stochastic tie-breaking. A detailed strategy for doing this can be found for example in [Correa et al., 2021c]. ", "page_idx": 6}, {"type": "text", "text": "Before delving into the study of the different models, we provide generic lower and upper bounds, which depend solely on the bounds of the classical prophet inequality and $\\gamma$ . ", "page_idx": 7}, {"type": "text", "text": "Proposition 4.2. In any order model, if \u03b1 is a lower bound in the classical prophet inequality, and $\\beta$ an upper bound, then, in the $\\gamma$ -prophet inequality ", "page_idx": 7}, {"type": "text", "text": "(i) there exists a trivial algorithm with a competitive ratio of at least $\\operatorname*{max}\\{\\gamma,\\alpha\\}$ , (ii) the competitive ratio of any algorithm is at most $(1-\\gamma)\\beta+\\gamma$ . ", "page_idx": 7}, {"type": "text", "text": "4.1 Adversarial order ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We first consider the adversarial order model, and prove the upper bound of $\\frac{1}{2-\\gamma}$ . Then, we provide a single-threshold algorithm with a competitive ratio matching this upper bound, hence fully solving the $\\gamma$ -prophet inequality in this adversarial order model. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.3. In the adversarial order model, the competitive ratio of any algorithm is at most $\\frac{1}{2-\\gamma}$ . Furthermore, there exists a single threshold algorithm with a competitive ratio $\\frac{1}{2-\\gamma}$ : given any instance $(F_{1},\\ldots,F_{n})$ , this is achieved with the threshold $\\theta$ satisfying ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{Pr}_{X_{1}\\sim F_{1},\\dots,X_{n}\\sim F_{n}}(\\operatorname*{max}_{i\\in[n]}X_{i}\\leq\\theta)=\\frac{1}{2-\\gamma}~.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The upper bound in the previous theorem is proved using instances satisfying the condition of Proposition 3.3. Hence it extends to the $D_{\\infty}$ - then to the $\\mathcal{D}$ -prophet inequality, with $\\gamma=\\gamma_{\\mathscr D}$ , by Proposition 3.3 and Theorem 2.1. ", "page_idx": 7}, {"type": "text", "text": "4.2 Random order ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Consider now that the items are observed in a uniformly random order $X_{\\pi(1)},\\ldots,X_{\\pi(n)}$ , and $X^{*}=\\operatorname*{max}_{i\\in[n]}X_{i}$ . As for the adversarial model, we first prove an upper bound on the competitive ratio as a function of $\\gamma$ , and then prove a lower bound for a single-threshold algorithm. However, for this model, there is a gap between the two bounds, as illustrated in Figure 1. ", "page_idx": 7}, {"type": "text", "text": "We first prove an upper bound that depends on $\\gamma$ , matching the upper bound $\\sqrt{3}-1$ of Correa et al. [2021c] when $\\gamma=0$ and equal to 1 when $\\gamma=1$ . Our single-threshold algorithm has a competitive ratio of at least $\\left(1-{\\frac{1}{e}}\\right)$ when $\\gamma=0$ , which is the best competitive ratio of a single threshold algorithm in the prophet inequality [Esfandiari et al., 2017, Correa et al., 2021c], and equal to 1 for $\\gamma=1$ . ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.4. The competitive ratio of any algorithm $A L G$ in the $\\gamma$ -prophet inequality with random order satisfies ", "page_idx": 7}, {"type": "equation", "text": "$$\nC R^{\\gamma}(A L G)\\leq(1-\\gamma)^{3/2}(\\sqrt{3-\\gamma}-\\sqrt{1-\\gamma})+\\gamma\\;.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Furthermore, denoting by p\u03b3 is the unique solution to the equation 1 \u2212(1 \u2212\u03b3)p = \u22121l\u2212ogp p, the single-threshold algorithm $A L G_{\\theta}$ with $\\begin{array}{r}{\\operatorname*{Pr}_{X_{1}\\sim F_{1},\\dots,X_{n}\\sim F_{n}}(\\operatorname*{max}_{i\\in[n]}X_{i}\\leq\\theta)=p_{\\gamma}}\\end{array}$ satisfies ", "page_idx": 7}, {"type": "equation", "text": "$$\nC R^{\\gamma}(A L G)\\geq1-(1-\\gamma)p_{\\gamma}\\ .\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Similarly to the adversarial order model, we used instances satisfying the condition of Proposition 3.3 to prove the upper bound, thus it extends to the $\\mathcal{D}$ -prophet inequality with $\\gamma=\\gamma_{\\mathscr D}$ . ", "page_idx": 7}, {"type": "text", "text": "While the equation defining $p_{\\gamma}$ cannot be solved analytically, the solution can easily be computed numerically for any $\\gamma\\in[0,1]$ . Before moving to the IID case, we propose in the following a more explicit lower bound derived from Theorem 4.4. ", "page_idx": 7}, {"type": "text", "text": "Corollary 4.4.1. In the random order model, the single threshold algorithm with a threshold $\\theta$ satisfying Pr(maxi\u2208[n] Xi \u2265\u03b8) =1\u2212(11\u2212/1e/e) \u03b3 has a competitive ratio of at least 1 \u22121\u2212((11\u2212\u2212\u03b31)//ee)\u03b3 . ", "page_idx": 7}, {"type": "text", "text": "4.3 IID Random Variables ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In the classical IID prophet inequality, [Hill and Kertz, 1982] showed that the competitive ratio of any algorithm is at mos $\\approx0.745$ . The proof of this upper bound is hard to generalize for the IID $\\gamma$ -prophet inequality. As an alternative, we prove a weaker upper bound, which equals $\\approx0.778$ for $\\gamma=0$ and 1 for $\\gamma=1$ , and the proof relies on instances of arbitrarily large size satisfying the condition of Proposition 3.3, hence the upper bound can be extended to the $\\mathcal{D}$ -prophet inequality. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Subsequently, we present a single-threshold algorithm with the same competitive ratio as the random order algorithm. However, the proof is different, leveraging the fact that the variables are identically distributed. More precisely, we introduce a single-threshold algorithm with guarantees that depend on the size $n$ of the instance, then we show that its competitive ratio is at least that of the algorithm presented in Theorem 4.4, with equality when $n$ approaches infinity. ", "page_idx": 8}, {"type": "text", "text": "Although it might look surprising that the obtained competitive ratio in the IID model is not better than that of the random-order model, the same behavior occurs in the classical prophet inequality. Indeed, Li et al. [2022] established that no single-threshold algorithm can achieve a competitive ratio better than $1-1/e$ in the standard prophet inequality with IID random variables, which is also the best possible with a single-threshold algorithm in the random order. However, considering larger classes of algorithms, the competitive ratios achieved in the IID model are better than those of the random order model. ", "page_idx": 8}, {"type": "text", "text": "We describe the algorithm and give a first lower bound on its reward depending on the size of the instance in the following lemma. ", "page_idx": 8}, {"type": "text", "text": "Lemma 4.5. Let $a_{n,\\gamma}$ be the unique solution of the equation (1\u2212a1/n)n \u22121  a1 \u22121 = \u03b3, then for any $I I D$ instance $X_{1},\\ldots,X_{n}$ , the algorithm with threshold $\\theta$ satisfying $\\textstyle\\operatorname*{Pr}(X_{1}>\\theta)={\\frac{a_{n,\\gamma}}{n}}$ has $a$ reward of at least ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\frac{1}{a_{n,\\gamma}}\\left(1-\\left(1-\\frac{a_{n,\\gamma}}{n}\\right)^{n}\\right)\\mathbb{E}[\\operatorname*{max}_{i\\in[n]}X_{i}]\\ .\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "We can prove that the reward presented in the Lemma above is strictly better than that of the random order model. However, both are asymptotically equal as we show in the following theorem. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.6. The competitive ratio of any algorithm in the IID $\\gamma$ -prophet inequality is at most ", "page_idx": 8}, {"type": "equation", "text": "$$\nU(\\gamma)=1-(1-\\gamma)\\frac{e^{2}\\log(3-\\gamma)-(2-\\gamma)}{2(2e^{2}-1)-(3e^{2}-1)\\gamma}\\;.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "In particular, $U$ is increasing, $\\begin{array}{r}{U(0)=\\frac{4-\\log3}{2(2-\\frac{1}{e}^{2})}\\approx0.778}\\end{array}$ and $U(1)=1$ . Furthermore, there exists a single-threshold algorithm $A L G_{\\theta}$ satisfying ", "page_idx": 8}, {"type": "equation", "text": "$$\nC R^{\\gamma}(A L G_{\\theta})\\geq1-(1-\\gamma)p_{\\gamma}~,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $p_{\\gamma}$ is defined in Theorem 4.4. ", "page_idx": 8}, {"type": "text", "text": "To prove the upper bound, we used instances satisfying the condition of Proposition 3.3, guaranteeing that it remains true in the $D_{\\infty}$ -prophet inequality with $\\gamma=\\gamma_{\\mathscr D}$ . On the other hand, Theorem 2.1 ensures that the upper bound extends to the $\\mathcal{D}$ -prophet inequality, but with an additional $O(1/n^{1/3})$ term. The latter does change the result, as we considered instances of arbitrarily large size $n\\to\\infty$ . ", "page_idx": 8}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we addressed the $\\mathcal{D}$ -prophet inequality problem, which models a very broad spectrum of online selection scenarios, accommodating various observation order models and allowing to revisit rejected candidates at a cost. The problem extends the classic prophet inequality, corresponding to the special case where all decay functions are zero. The main result of the paper is a reduction from the general $\\mathcal{D}$ -prophet inequality to the $\\gamma$ -prophet inequality, where all the decay functions equal to $x\\mapsto\\gamma x$ for some constant $\\gamma\\in[0,1]$ . Subsequently, we provide algorithms and upper bounds for the $\\gamma$ -prophet inequality, which remain valid, by the previous reduction, in the $\\mathcal{D}$ -prophet inequality. Notably, the proved upper and lower bounds match each other for the adversarial order model, hence completely solving the problem. Our analysis paves the way for more practical applications of prophet inequalities, and advances efforts towards closing the gap between theory and practice in online selection problems. ", "page_idx": 8}, {"type": "text", "text": "Limitations and future work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Better upper bounds in the $D_{\\infty}$ -prophet inequality. Proposition 3.3 establishes that upper bounds proved in the $\\gamma$ -prophet inequality using instances of random variables with support in some set $\\{0,a,b\\}$ remain true in the $D_{\\infty}$ -prophet inequality, hence in the $\\mathcal{D}$ -prophet inequality by Theorem 2.1. This is enough to establish a tight upper bound in the adversarial order model, but not in the random order and IID models. An interesting question to explore is if more general upper bounds can be extended, or not, from the $\\gamma.$ - to the $\\mathcal{D}$ -prophet inequality. ", "page_idx": 9}, {"type": "text", "text": "Algorithms for the $\\gamma$ -prophet inequality. As explained in Section 4, our analysis of the competitive ratio of single-threshold algorithms relies on the identity (4), which is not satisfied for instance by multiple-threshold algorithms. In the adversarial order model, we proved that the optimal competitive ratio $1/(2-\\gamma)$ can be achieved with a single-threshold algorithm. However, this is not the case in the random order or IID models. An interesting research avenue is to study other classes of algorithms in the $\\gamma$ -prophet inequality. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research was supported in part by the French National Research Agency (ANR) in the framework of the PEPR IA FOUNDRY project (ANR-23-PEIA-0003) and through the grant DOOM ANR23-CE23-0002. It was also funded by the European Union (ERC, Ocean, 101071601). Views and opinions expressed are however those of the author(s) only and do not necessarily reflect those of the European Union or the European Research Council Executive Agency. Neither the European Union nor the granting authority can be held responsible for them. ", "page_idx": 9}, {"type": "text", "text": "Dorian Baudry thanks the support of the French National Research Agency: ANR-19-CHIA-02 SCAI, ANR-22-SRSE-0009 Ocean, and ANR-23-CE23-0002 Doom; and of the European Research Council (GTIR project) ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Antonios Antoniadis, Themis Gouleakis, Pieter Kleer, and Pavel Kolev. Secretary and online matching problems with machine learned advice. Advances in Neural Information Processing Systems, 33: 7933\u20137944, 2020. ", "page_idx": 9}, {"type": "text", "text": "Antonios Antoniadis, Joan Boyar, Marek Eli\u00e1s, Lene Monrad Favrholdt, Ruben Hoeksma, Kim S Larsen, Adam Polak, and Bertrand Simon. Paging with succinct predictions. In International Conference on Machine Learning, pages 952\u2013968. PMLR, 2023.   \nMakis Arsenis and Robert Kleinberg. Individual fairness in prophet inequalities. In Proceedings of the 23rd ACM Conference on Economics and Computation, pages 245\u2013245, 2022.   \nDavid Assaf and Ester Samuel-Cahn. Simple ratio prophet inequalities for a mortal with multiple choices. Journal of applied probability, 37(4):1084\u20131091, 2000.   \nAlexia Atsidakou, Constantine Caramanis, Evangelia Gergatsouli, Orestis Papadigenopoulos, and Christos Tzamos. Contextual pandora\u2019s box. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 10944\u201310952, 2024.   \nZiyad Benomar and Christian Coester. Learning-augmented priority queues. arXiv preprint arXiv:2406.04793, 2024.   \nZiyad Benomar and Vianney Perchet. Advice querying under budget constraint for online algorithms. Advances in Neural Information Processing Systems, 36, 2024a.   \nZiyad Benomar and Vianney Perchet. Non-clairvoyant scheduling with partial predictions. In Forty-first International Conference on Machine Learning, 2024b.   \nZiyad Benomar, Evgenii Chzhen, Nicolas Schreuder, and Vianney Perchet. Addressing bias in online selection with limited budget of comparisons. arXiv preprint arXiv:2303.09205, 2023.   \nBen Berger, Tomer Ezra, Michal Feldman, and Federico Fusco. Pandora\u2019s problem with deadlines. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 20337\u201320343, 2024.   \nHedyeh Beyhaghi, Negin Golrezaei, Renato Paes Leme, Martin P\u00e1l, and Balasubramanian Sivan. Improved revenue bounds for posted-price and second-price mechanisms. Operations Research, 69(6):1805\u20131822, 2021.   \nAllan Borodin and Ran El-Yaniv. Online computation and competitive analysis. cambridge university press, 2005.   \nBrian Brubach, Nathaniel Grammel, Will Ma, and Aravind Srinivasan. Improved guarantees for offline stochastic matching via new ordered contention resolution schemes. Advances in Neural Information Processing Systems, 34:27184\u201327195, 2021.   \nArchit Bubna and Ashish Chiplunkar. Prophet inequality: Order selection beats random order. In Proceedings of the 24th ACM Conference on Economics and Computation, pages 302\u2013336, 2023.   \nShuchi Chawla, Jason D Hartline, David L Malec, and Balasubramanian Sivan. Multi-parameter mechanism design and sequential posted pricing. In Proceedings of the forty-second ACM symposium on Theory of computing, pages 311\u2013320, 2010.   \nJustin Chen, Sandeep Silwal, Ali Vakilian, and Fred Zhang. Faster fundamental graph algorithms via learned predictions. In International Conference on Machine Learning, pages 3583\u20133602. PMLR, 2022.   \nJakub Chlkedowski, Adam Polak, Bartosz Szabucki, and Konrad Tomasz .Zolna. Robust learningaugmented caching: An experimental study. In International Conference on Machine Learning, pages 1920\u20131930. PMLR, 2021.   \nNicolas Christianson, Junxuan Shen, and Adam Wierman. Optimal robustness-consistency tradeoffs for learning-augmented metrical task systems. In International Conference on Artificial Intelligence and Statistics, pages 9377\u20139399. PMLR, 2023.   \nAlon Cohen, Avinatan Hassidim, Haim Kaplan, Yishay Mansour, and Shay Moran. Learning to screen. Advances in Neural Information Processing Systems, 32, 2019.   \nJose Correa, Patricio Foncea, Ruben Hoeksma, Tim Oosterwijk, and Tjark Vredeveld. Recent developments in prophet inequalities. ACM SIGecom Exchanges, 17(1):61\u201370, 2019.   \nJose Correa, Andres Cristi, Paul Duetting, and Ashkan Norouzi-Fard. Fairness and bias in online selection. In International conference on machine learning, pages 2112\u20132121. PMLR, 2021a.   \nJos\u00e9 Correa, Patricio Foncea, Ruben Hoeksma, Tim Oosterwijk, and Tjark Vredeveld. Posted price mechanisms and optimal threshold strategies for random arrivals. Mathematics of operations research, 46(4):1452\u20131478, 2021b.   \nJose Correa, Raimundo Saona, and Bruno Ziliotto. Prophet secretary through blind strategies. Mathematical Programming, 190(1-2):483\u2013521, 2021c.   \nYuan Deng, Vahab Mirrokni, and Hanrui Zhang. Posted pricing and dynamic prior-independent mechanisms with value maximizers. Advances in Neural Information Processing Systems, 35: 24158\u201324169, 2022.   \nIlias Diakonikolas, Vasilis Kontonis, Christos Tzamos, Ali Vakilian, and Nikos Zarifis. Learning online algorithms with distributional advice. In International Conference on Machine Learning, pages 2687\u20132696. PMLR, 2021.   \nMichael Dinitz, Sungjin Im, Thomas Lavastida, Benjamin Moseley, and Sergei Vassilvitskii. Faster matchings via learned duals. Advances in neural information processing systems, 34:10393\u201310406, 2021.   \nPaul D\u00fctting, Thomas Kesselheim, and Brendan Lucier. An o (log log m) prophet inequality for subadditive combinatorial auctions. ACM SIGecom Exchanges, 18(2):32\u201337, 2020.   \nPaul D\u00fctting, Silvio Lattanzi, Renato Paes Leme, and Sergei Vassilvitskii. Secretaries with advice. In Proceedings of the 22nd ACM Conference on Economics and Computation, pages 409\u2013429, 2021.   \nEvgenii Borisovich Dynkin. The optimum choice of the instant for stopping a markov process. Soviet Mathematics, 4:627\u2013629, 1963.   \nFarbod Ekbatani, Yiding Feng, and Rad Niazadeh. Online matching with cancellation costs. arXiv preprint arXiv:2210.11570, 2022.   \nFarbod Ekbatani, Yiding Feng, and Rad Niazadeh. Online resource allocation with buyback: Optimal algorithms via primal-dual. In Proceedings of the 24th ACM Conference on Economics and Computation, pages 583\u2013583, 2023.   \nFarbod Ekbatani, Rad Niazadeh, Pranav Nuti, and Jan Vondr\u00e1k. Prophet inequalities with cancellation costs. In Proceedings of the 56th Annual ACM Symposium on Theory of Computing, pages 1247\u2013 1258, 2024.   \nHossein Esfandiari, MohammadTaghi Hajiaghayi, Vahid Liaghat, and Morteza Monemizadeh. Prophet secretary. SIAM Journal on Discrete Mathematics, 31(3):1685\u20131701, 2017.   \nHossein Esfandiari, MohammadTaghi HajiAghayi, Brendan Lucier, and Michael Mitzenmacher. Online pandora\u2019s boxes and bandits. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 1885\u20131892, 2019.   \nTomer Ezra, Michal Feldman, Nick Gravin, and Zhihao Gavin Tang. Online stochastic max-weight matching: prophet inequality for vertex and edge arrival models. In Proceedings of the 21st ACM Conference on Economics and Computation, pages 769\u2013787, 2020.   \nMoran Feldman, Ola Svensson, and Rico Zenklusen. Online contention resolution schemes. In Proceedings of the twenty-seventh annual ACM-SIAM symposium on Discrete algorithms, pages 1014\u20131033. SIAM, 2016.   \nEvangelia Gergatsouli and Christos Tzamos. Online learning for min sum set cover and pandora\u2019s box. In International Conference on Machine Learning, pages 7382\u20137403. PMLR, 2022.   \nEvangelia Gergatsouli and Christos Tzamos. Weitzman\u2019s rule for pandora\u2019s box with correlations. Advances in Neural Information Processing Systems, 36, 2024.   \nGiordano Giambartolomei, Frederik Mallmann-Trenn, and Raimundo Saona. Prophet inequalities: Separating random order from order selection. arXiv preprint arXiv:2304.04024, 2023.   \nMohammad Taghi Hajiaghayi, Robert Kleinberg, and Tuomas Sandholm. Automated online mechanism design and prophet inequalities. In AAAI, volume 7, pages 58\u201365, 2007.   \nElfarouk Harb. New prophet inequalities via poissonization and sharding, 2024.   \nTheodore P Hill and Robert P Kertz. Comparisons of stop rule and supremum expectations of iid random variables. The Annals of Probability, pages 336\u2013345, 1982.   \nZhihao Jiang, Pinyan Lu, Zhihao Gavin Tang, and Yuhao Zhang. Online selection problems against constrained adversary. In International Conference on Machine Learning, pages 5002\u20135012. PMLR, 2021.   \nRobert P Kertz. Stop rule and supremum expectations of iid random variables: a complete comparison by conjugate duality. Journal of multivariate analysis, 19(1):88\u2013112, 1986.   \nRobert Kleinberg and Seth Matthew Weinberg. Matroid prophet inequalities. In Proceedings of the forty-fourth annual ACM symposium on Theory of computing, pages 123\u2013136, 2012.   \nRobert Kleinberg, Bo Waggoner, and E Glen Weyl. Descending price optimally coordinates search. arXiv preprint arXiv:1603.07682, 2016.   \nTim Kraska, Alex Beutel, Ed H Chi, Jeffrey Dean, and Neoklis Polyzotis. The case for learned index structures. In Proceedings of the 2018 international conference on management of data, pages 489\u2013504, 2018. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Ulrich Krengel and Louis Sucheston. Semiamarts and finite values. 1977. ", "page_idx": 12}, {"type": "text", "text": "Ulrich Krengel and Louis Sucheston. On semiamarts, amarts, and processes with finite value. Probability on Banach spaces, 4:197\u2013266, 1978.   \nAlexandra Anna Lassota, Alexander Lindermayr, Nicole Megow, and Jens Schl\u00f6ter. Minimalistic predictions to schedule jobs with online precedence constraints. In International Conference on Machine Learning, pages 18563\u201318583. PMLR, 2023.   \nBo Li, Xiaowei Wu, and Yutong Wu. Query efficient prophet inequality with unknown iid distributions. arXiv preprint arXiv:2205.05519, 2022.   \nHonghao Lin, Tian Luo, and David Woodruff. Learning augmented binary search trees. In International Conference on Machine Learning, pages 13431\u201313440. PMLR, 2022.   \nDenis V Lindley. Dynamic programming and decision theory. Journal of the Royal Statistical Society: Series C (Applied Statistics), 10(1):39\u201351, 1961.   \nBrendan Lucier. An economic view of prophet inequalities. ACM SIGecom Exchanges, 16(1):24\u201347, 2017.   \nThodoris Lykouris and Sergei Vassilvtiskii. Competitive caching with machine learned advice. In International Conference on Machine Learning, pages 3296\u20133305. PMLR, 2018.   \nAnuran Makur, Marios Mertzanidis, Alexandros Psomas, and Athina Terzoglou. On the robustness of mechanism design under total variation distance. Advances in Neural Information Processing Systems, 36, 2024.   \nChristos Papadimitriou, Tristan Pollner, Amin Saberi, and David Wajc. Online stochastic max-weight bipartite matching: Beyond prophet inequalities. In Proceedings of the 22nd ACM Conference on Economics and Computation, pages 763\u2013764, 2021.   \nBo Peng and Zhihao Gavin Tang. Order selection prophet inequality: From threshold optimization to arrival time design. In 2022 IEEE 63rd Annual Symposium on Foundations of Computer Science (FOCS), pages 171\u2013178. IEEE, 2022.   \nAlexandros Psomas, Ariel Schvartzman Cohenca, and S Weinberg. On infinite separations between simple and optimal mechanisms. Advances in Neural Information Processing Systems, 35:4818\u2013 4829, 2022.   \nManish Purohit, Zoya Svitkina, and Ravi Kumar. Improving online algorithms via ml predictions. Advances in Neural Information Processing Systems, 31, 2018.   \nEster Samuel-Cahn. Comparison of threshold stop rules and maximum for independent nonnegative random variables. the Annals of Probability, pages 1213\u20131216, 1984.   \nSean R Sinclair, Felipe Vieira Frujeri, Ching-An Cheng, Luke Marshall, Hugo De Oliveira Barbalho, Jingling Li, Jennifer Neville, Ishai Menache, and Adith Swaminathan. Hindsight learning for mdps with exogenous inputs. In International Conference on Machine Learning, pages 31877\u201331914. PMLR, 2023.   \nBo Sun, Russell Lee, Mohammad Hajiesmaili, Adam Wierman, and Danny Tsang. Pareto-optimal learning-augmented algorithms for online conversion problems. Advances in Neural Information Processing Systems, 34:10339\u201310350, 2021.   \nVasilis Syrgkanis. A sample complexity measure with applications to learning optimal auctions. Advances in Neural Information Processing Systems, 30, 2017.   \nMartin Weitzman. Optimal search for the best alternative, volume 78. Department of Energy, 1978. ", "page_idx": 12}, {"type": "text", "text": "A From $\\mathcal{D}$ -prophet to the $D_{\\infty}$ -prophet inequality ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we prove the reduction from the $\\mathcal{D}$ -prophet to the $D_{\\infty}$ -prophet inequality problem in the adversarial and random order models, and the reduction up to an additional $O(n^{-1/3})$ term in the IID model. First, we prove Corollary 2.1.1, which is the principal implication of Theorem 2.1. ", "page_idx": 13}, {"type": "text", "text": "A.1 Proof of Corollary 2.1.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. Let us denote $\\mathsf{A}_{*,\\infty}$ the algorithm taking optimal decisions for any instance in the $D_{\\infty}$ -prophet inequality (obtained via dynamic programming). Then, by Theorem 2.1 we obtain for the adversarial and random order models that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\mathbb{A},\\mathbb{G}}\\mathbb{C}\\mathsf{R}^{\\mathcal{D}}(\\mathbb{A}\\mathbb{L}\\mathbb{G})\\leq\\operatorname*{inf}_{I}\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}=\\operatorname*{inf}_{I}\\frac{\\mathbb{E}[\\mathsf{A}_{*,\\infty}^{D_{\\infty}}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}=\\mathsf{C}\\mathsf{R}^{D_{\\infty}}(\\mathsf{A}_{*,\\infty})=\\operatorname*{sup}_{\\mathsf{A}}\\mathsf{C}\\mathsf{R}^{D_{\\infty}}(\\mathsf{A})\\ .\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Since $\\mathsf{C R}^{\\mathcal{D}}(\\mathsf{A L G})\\,\\ge\\,\\mathsf{C R}^{\\cal D_{\\infty}}(\\mathsf{A L G})$ for any algorithm, we deduce that (5) is an equality. If we consider now any algorithm $\\bar{\\mathsf{A}}_{\\infty}$ that is optimal for the $D_{\\infty}$ -prophet inequality, not necessarily $\\mathsf{A}_{*,\\infty}$ , then Equation (5) provides ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{\\mathcal{D}}(\\bar{\\mathsf{A}}_{\\infty})\\geq\\mathsf{C R}^{D_{\\infty}}(\\bar{\\mathsf{A}}_{\\infty})=\\operatorname*{sup}_{\\mathsf{A L G}}\\mathsf{C R}^{\\mathcal{D}}(\\mathsf{A L G})\\;.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The previous inequality is again an equality, and it implies that $\\bar{\\mathsf{A}}_{\\infty}$ is also optimal, in the sense of the competitive ratio, for the $\\mathcal{D}$ -prophet inequality, and ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{\\scriptscriptstyle D}(\\bar{\\mathsf{A}}_{\\infty})=\\mathsf{C R}^{\\scriptscriptstyle D_{\\infty}}(\\bar{\\mathsf{A}}_{\\infty})\\;.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "A.2 Auxilary Lemma ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The efficiency of the proof scheme introduced in Section 2.1 relies on the following key argument: if $(D_{j})_{j\\geq1}$ converges pointwise to $D_{\\infty}$ , then for any algorithm A and any instance $I$ , the output of $\\mathsf{A}$ when all the decay functions are equal to $D_{m}$ converges to its output when all the decay functions are equal to $D_{\\infty}$ . If $X_{1},\\ldots,X_{n}$ are the realizations of $I$ observed by $\\mathsf{A}$ and if $\\sigma$ is the order in which they are observed, then denoting $\\tau$ the stopping time of $\\mathsf{A}$ we can write that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A}^{D_{m}}(I)]-\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(I)]}\\\\ &{\\qquad\\quad=\\mathbb{E}[\\operatorname*{max}\\{X_{\\sigma(\\tau)},D_{m}(\\operatorname*{max}_{i<\\tau}X_{\\sigma(i)})\\}]-\\mathbb{E}[\\operatorname*{max}\\{X_{\\sigma(\\tau)},D_{\\infty}(\\operatorname*{max}_{i<\\tau}X_{\\sigma(i)})\\}]}\\\\ &{\\qquad\\quad\\leq\\operatorname*{max}_{\\pi\\in S_{n}}\\left\\{\\mathbb{E}[\\operatorname*{max}\\{X_{\\pi(q)},D_{m}(\\operatorname*{max}_{i<q}X_{\\pi(i)})\\}]-\\mathbb{E}[\\operatorname*{max}\\{X_{\\pi(q)},D_{\\infty}(\\operatorname*{max}_{i<q}X_{\\pi(i)})\\}]\\right\\}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\ensuremath{\\boldsymbol{S}}_{n}$ is the set of all permutations of $[n]$ . The latter upper bound is independent of $\\sigma$ and A. We show in the following lemma that it converges to 0 when $m\\rightarrow\\infty$ . ", "page_idx": 13}, {"type": "text", "text": "Lemma A.1. Let ${\\mathcal{S}}_{n}$ be the set of all permutations of $[n]$ . For any fixed instance $I=(F_{1},\\ldots,F_{n}),$ , considering $X_{i}\\sim F_{i}$ for all $i\\in[n]$ , define for all $m\\geq1$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\epsilon_{m}(I)=\\operatorname*{max}_{\\pi\\in S_{n}}\\left\\{\\mathbb{E}[\\operatorname*{max}\\{X_{\\pi(q)},D_{m}(\\operatorname*{max}_{i<q}X_{\\pi(i)})\\}]-\\mathbb{E}[\\operatorname*{max}\\{X_{\\pi(q)},D_{\\infty}(\\operatorname*{max}_{i<q}X_{\\pi(i)})\\}]\\right\\}\\,.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. Let us denote $f_{1},\\ldots,f_{n}$ the respective probability density functions of $X_{1},\\ldots,X_{q}$ . For any $q~\\in~[n]$ and $\\pi\\,\\in\\,S_{n}$ , let us define for all $m\\,\\geq\\,0$ the function $\\varphi_{m}^{\\pi,q}\\,:\\,[0,\\infty)^{q}\\,\\rightarrow\\,[0,\\dot{\\infty})$ by $\\begin{array}{r}{\\varphi_{m}^{\\pi,q}(x_{1},\\dot{\\dots},x_{q})=\\operatorname*{max}\\{x_{\\pi(q)},D_{m}(\\operatorname*{max}_{i<q}x_{\\pi(i)})\\}-\\operatorname*{max}\\{x_{\\pi(q)},D_{\\infty}^{\\infty}(\\operatorname*{mix}_{i<q}x_{\\pi(i)})\\}}\\end{array}$ . $\\varphi_{m}^{\\pi,q}$ is positive because $D_{m}\\geq D_{\\infty}$ . The sequence $(\\varphi_{m}^{\\pi,q})_{m}$ is non-increasing, converges to 0 pointwise, and is dominated by $(x_{1},\\dotsc...,x_{q})\\mapsto\\operatorname*{max}_{i\\in[q]}x_{i}$ , which is integrable with respect to the probability measure $(x_{1},\\dots,x_{q})\\mapsto\\textstyle\\prod_{i=1}^{q}f(x_{i})$ . Therefore, using the dominated convergence theorem, we deduce that $\\begin{array}{r}{\\operatorname*{lim}_{m\\rightarrow\\infty}\\mathbb{E}[\\varphi_{m}^{\\pi,q}(\\bar{X_{1}},\\ldots,X_{q})]=0}\\end{array}$ . It follows that ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{m\\to\\infty}\\epsilon_{m}(I)=\\operatorname*{lim}_{m\\to\\infty}\\Big(\\operatorname*{max}_{\\pi\\in S_{n}\\atop q\\in[n]}\\mathbb{E}[\\varphi_{m}^{\\pi,q}(X_{1},\\ldots,X_{q})]\\Big)=0\\;.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "A.3 Proof of Theorem 2.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof of Theorem 2.1. We provide a separate proof for each of the adversarial order, random order and IID models. ", "page_idx": 14}, {"type": "text", "text": "Adversarial order Let $I=\\left(F_{1},\\ldots,F_{n}\\right)$ be any instance and $X_{i}\\sim F_{i}$ for all $i\\in[n]$ . Consider the instance $I_{m}\\;=\\;(Y_{1},\\ldots,Y_{m n})$ , where $Y_{k m}\\,\\sim\\,F_{k}$ for any $k\\;\\in\\;[n]$ and $Y_{i}~=~0$ a.s. for all $i\\not\\in\\{m,2m,\\ldots,m n\\}$ . It is clear that no reasonable algorithm would stop at a zero value: if the current observation is 0 it is preferable to wait for a non-null value, or it would have been preferable to stop at the previous non-null value. Hence, $\\tau$ is a multiple of $m$ : $\\tau=\\rho m$ for some $\\rho\\in\\mathbb{N}^{\\star}$ . Given that $D_{j}(0)=0$ for all $j$ and the sequence $(D_{j})_{j}$ is non-increasing, we have that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\mathsf{A L G}^{D}(I_{m})]=\\mathbb{E}[\\operatorname*{max}_{i\\le r}D_{\\tau-i}(Y_{i})]}&{}\\\\ {=\\mathbb{E}[\\operatorname*{max}_{k\\le\\rho}D_{\\tau-k m}(Y_{k m})]}&{}\\\\ {=\\mathbb{E}[\\operatorname*{max}_{k\\le\\rho}D_{\\rho m-k m}(X_{k})]}&{}\\\\ {=\\mathbb{E}[\\operatorname*{max}\\{X_{\\rho,\\operatorname*{max}}D_{(\\rho-k)m}(X_{k})\\}]}&{}\\\\ {\\le\\mathbb{E}[\\operatorname*{max}\\{X_{\\rho,\\operatorname*{max}}D_{m}(X_{k})\\}]}&{}\\\\ {\\le\\mathbb{E}[\\operatorname*{max}\\{X_{\\rho,\\operatorname*{max}}D_{m}(X_{k})\\}]}&{}\\\\ {\\le\\mathbb{E}[\\operatorname*{max}\\{X_{\\rho,\\operatorname*{max}}D_{\\infty}(X_{k})\\}]+\\epsilon_{m}(I)\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\epsilon_{m}(I)$ is defined in Lemma A.1. We can then use that the first right-hand term is the output of some other algorithm that would choose a stopping time $\\rho$ when facing $I$ in the context of the $D_{\\infty}$ -prophet inequality. More precisely, consider the algorithm $\\mathsf{A}_{m}$ which, given any instance $\\boldsymbol{I}\\,=\\,(F_{1},\\dots,F_{n})$ , simulates the behavior of ALG facing the sequence $I_{m}$ , where at each step $i\\in[m n]$ ", "page_idx": 14}, {"type": "text", "text": "$\\mathsf{A}_{m}(X_{1},\\ldots,X_{n})$ stops at the same value as $\\mathsf{A L G}(Y_{1},\\ldots,Y_{m})$ , their reward in the $D_{\\infty}$ -prophet inequality is the same, and since $\\begin{array}{r}{\\operatorname*{max}_{i\\in[n]}X_{i}=\\operatorname*{max}_{i\\in[m n]}Y_{i}}\\end{array}$ this yields to ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{\\mathcal{D}}(\\mathsf{A L G})\\leq\\frac{\\mathbb{E}[\\mathsf{A L G}^{\\mathcal{D}}(I_{m})]}{\\mathbb{E}[\\mathsf{O P T}(I_{m})]}\\leq\\frac{\\mathbb{E}[\\mathsf{A}_{m}^{D_{\\infty}}(I)]+\\epsilon_{m}(I)}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\leq\\operatorname*{sup}_{\\mathsf{A:\\,a g o}}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}+\\frac{\\epsilon_{m}(I)}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\,,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and taking the limit when $m\\rightarrow\\infty$ gives the result, by making the second term vanish. ", "page_idx": 14}, {"type": "text", "text": "Random order Let $\\boldsymbol{I}\\,=\\,(F_{1},\\ldots,F_{n})$ be an instance of distributions and $X_{i}\\sim F_{i}$ for $i\\,\\in\\,[n]$ . Using the notation $\\delta_{0}$ for the Dirac distribution in 0, we consider $\\begin{array}{r}{I_{m}\\,=\\,\\left(F_{1},\\dots,F_{n},\\delta_{0},\\dots,\\bar{\\delta}_{0}\\right)}\\end{array}$ containing $m$ copies of $\\delta_{0}$ so that the observations from this instance always contain at least $m$ null values. Let $Y_{1},\\ldots,Y_{m}$ be a realization of this instance. For simplicity, say that $Y_{i}=X_{i}$ for $i\\in[n]$ , and $Y_{i}=0$ for $i>n$ . ", "page_idx": 14}, {"type": "text", "text": "We first show that when $m\\ \\rightarrow\\ \\infty$ , since the observation order is drawn uniformly at random, the algorithm observes a large number of zeros between every two random variables drawn from $(F_{1},\\ldots,F_{n})$ . Let us denote by $\\pi$ the uniformly random order in which the observations are received, i.e. the algorithms observes $Y_{\\pi(1)},Y_{\\pi(2)},\\ldots,$ , and let $\\ell\\geq1$ be some positive integer, and $t_{1},\\ldots,t_{n}$ be the increasing indices in which the variables $Y_{1},\\ldots,Y_{n}$ are observed, i.e. $t_{1}<...<t_{n}$ and $\\{t_{1},\\dots t_{n}\\}=\\{\\bar{\\pi}^{-1}(1),\\dots,\\pi^{-1}(n)\\}$ . Therefore, any observation outside $\\{Y_{\\pi(t_{1})},\\ldots,Y_{\\pi(t_{1})}\\}$ is zero. Using the notation $\\begin{array}{r}{L=\\operatorname*{min}_{i\\in[n-1]}\\left|t_{i+1}-t_{i}\\right|}\\end{array}$ , we obtain that ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(L\\leq\\ell)=\\operatorname*{Pr}(\\lfloor\\upsilon_{i=1}^{n-1}\\{t_{i+1}-t_{i}\\le\\ell\\})}\\\\ &{\\qquad\\qquad=\\operatorname*{Pr}\\left(\\lfloor\\upsilon_{i=1}^{n-1}\\cup_{j=1}^{k-1}\\left\\{\\vert\\pi^{-1}(k)-\\pi^{-1}(j)\\vert\\le\\ell\\right\\}\\right)}\\\\ &{\\qquad\\qquad\\leq\\frac{n(n-1)}{2}\\operatorname*{Pr}(\\vert\\pi^{-1}(1)-\\pi^{-1}(2)\\vert\\leq\\ell)}\\\\ &{\\qquad\\qquad=\\frac{n(n-1)}{2}\\operatorname*{Pr}(\\{\\cup_{k=1}^{n+m}\\left(\\pi^{-1}(1)=k,\\pi^{-1}(2)\\in\\left\\{k-\\ell,\\ldots,k+\\ell\\right\\}\\setminus\\{k\\}\\right)}\\\\ &{\\qquad\\qquad\\leq\\frac{n(n-1)}{2}\\times(n+m)\\times\\frac{1}{n+m}\\times\\frac{2\\ell}{n+m-1}}\\\\ &{\\qquad\\qquad\\leq\\frac{n^{2}\\ell}{m}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Taking $\\ell=\\sqrt{m}$ , we find that $\\operatorname*{Pr}(L\\leq\\ell)\\leq n^{2}/{\\sqrt{m}}$ . Therefore, for any algorithm ALG, observing that the reward of $\\mathsf{A L G}^{D}$ is at most $\\operatorname*{max}_{i\\in[n]}X_{i}$ a.s., and by independence of $\\operatorname*{max}_{i\\in[n]}X_{i}$ and $L$ we deduce that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[{\\mathsf{A L G}}^{\\mathcal{D}}(I_{m})]=\\mathbb{E}[{\\mathsf{A L G}}^{\\mathcal{D}}(I_{m})\\mathbb{1}_{L>\\ell}]+\\mathbb{E}[{\\mathsf{A L G}}^{\\mathcal{D}}(I_{m})\\mathbb{1}_{L\\leq\\ell}]}\\\\ &{\\leq\\mathbb{E}[{\\mathsf{A L G}}^{\\mathcal{D}}(I_{m})\\mid L>\\ell]+\\mathbb{E}[(\\underset{i\\in[n]}{\\operatorname*{max}}X_{i})\\mathbb{1}_{L\\leq\\ell}]}\\\\ &{\\leq\\mathbb{E}[{\\mathsf{A L G}}^{\\mathcal{D}}(I_{m})\\mid L>\\ell]+\\mathbb{E}[\\underset{i\\in[n]}{\\operatorname*{max}}X_{i}]\\frac{n^{2}}{\\sqrt{m}}\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Let us denote $\\tau$ the stopping time of ALG and $t_{\\rho}=\\operatorname*{max}_{j\\in[n]}\\{t_{j}:t_{j}\\,\\leq\\,\\tau\\}$ the last time when a variable $(X_{j})_{j\\in[n]}$ was observed by ALG. The sequence of functions $(D_{j})_{j\\geq1}$ is non-increasing, hence ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{D}(I_{m})\\mid L>\\ell]=\\mathbb{E}[\\underset{i\\in[\\tau]}{\\operatorname*{max}}D_{\\tau-i}(Y_{\\pi(i)})\\mid L>\\ell]}\\\\ &{\\quad\\quad\\quad\\quad=\\mathbb{E}[\\underset{j\\leq i}{\\operatorname*{max}}D_{\\tau-t_{j}}(Y_{\\pi(t_{j})})\\mid L>\\ell]}\\\\ &{\\quad\\quad\\quad\\leq\\mathbb{E}[\\underset{j\\leq i}{\\operatorname*{max}}D_{t_{\\rho}-t_{j}}(Y_{\\pi(t_{j})})\\mid L>\\ell]}\\\\ &{\\quad\\quad\\quad=\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{\\pi(t_{\\rho})},\\underset{j<\\rho}{\\operatorname*{max}}D_{t_{\\rho}-t_{j}}(Y_{\\pi(t_{j})})\\right\\}\\mid L>\\ell]}\\\\ &{\\quad\\quad\\quad\\leq\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{\\pi(t_{\\rho})},\\underset{j\\leq\\rho}{\\operatorname*{max}}D_{\\ell}(Y_{\\pi(t_{j})})\\right\\}]\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Equation (7) holds because the only non-zero values up to step $\\tau$ are $(Y_{\\pi(t_{j})})_{j\\in[\\rho]}$ . Inequality (8) uses that the sequence $(D_{j})_{j\\geq1}$ is non-increasing, and (9) uses, in addition to that, the independence of $L$ and $(Y_{\\pi(t_{j})})_{j\\in[n]}$ . We now argue that the term $\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{\\pi(t_{\\rho})},\\operatorname*{max}_{j<\\rho}D_{\\ell}(Y_{\\pi(t_{j})})\\right\\}]$ is the expected reward of an algorithm in the $D_{\\ell}$ -inequality. Given that $\\pi$ is a uniform random permutation of $[n+m]$ and by definition of $t_{1},\\ldots,t_{n}$ , the application $\\sigma:k\\in[n]\\mapsto\\pi(t_{k})$ is a random permutation of $[n]$ . Therefore we consider the algorithm $\\mathsf{A}_{m}$ that receives as input the instance $\\boldsymbol{I}=\\left(F_{1},\\ldots,F_{n}\\right)$ , then considers the array $u=(1,\\dotsc,1,0,\\dotsc,0)$ composed of $n$ values equal to 1 and $m$ zero values, and a uniformly random permutation $\\pi$ of $[n+m]$ , then simulates $\\mathsf{A L G}^{D}(I_{m})$ as follows: at each step $j\\in[n+\\dot{m}]$ ", "page_idx": 15}, {"type": "text", "text": "\u2022 if $u_{\\pi(j)}=0$ , then ALG observes the value $Y_{\\pi(j)}=0$ , \u2022 if $u_{\\pi(j)}=1$ , then $\\mathsf{A}_{m}$ observes the next value $X_{\\sigma(k)}$ , and ALG observes $Y_{\\pi(j)}=X_{\\sigma(k)}$ , \u2022 when ALG decides to stop, $\\mathsf{A}_{m}$ also stops, and its reward is the current value $X_{\\sigma(k)}$ . ", "page_idx": 15}, {"type": "text", "text": "With this construction, $(Y_{j})_{j\\in[n+m]}$ is indeed a realization of the instance $I_{m}$ , and $\\mathsf{A}_{m}$ stops on the last value sampled from $F_{1},\\bar{\\dots},\\bar{F_{n}}$ observed by ALG. Therefore, denoting $\\rho$ the stopping time of $\\mathsf{A}_{m}$ , and $\\epsilon_{\\ell}(I)$ as defined in Lemma A.1, we have ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{D}(I_{m})\\mid L>\\ell]\\le\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{\\pi(t_{\\rho})},\\operatorname*{max}D_{\\ell}(Y_{\\pi(t_{j})})\\right\\}]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}[\\operatorname*{max}\\left\\{X_{\\sigma(\\rho)},\\operatorname*{max}D_{\\ell}(X_{\\sigma(t_{j})})\\right\\}]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}[\\mathsf{A}_{m}^{D_{\\ell}}(I)]}\\\\ &{\\qquad\\qquad\\quad\\le\\mathbb{E}[\\mathsf{A}_{m}^{D_{\\infty}}(I)]+\\epsilon_{\\ell}(I)}\\\\ &{\\qquad\\le\\operatorname*{sup}\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(I)]+\\epsilon_{\\ell}(I)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Taking $\\ell=\\sqrt{m}$ and substituting into Equation (6), then observing that $\\mathbb{E}[\\mathsf{O P T}(I)]=\\mathbb{E}[\\mathsf{O P T}(I_{m})]$ , gives that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{\\mathcal{D}}(\\mathsf{A L G})\\leq\\frac{\\mathbb{E}[\\mathsf{A L G}^{\\mathcal{D}}(I_{m})]}{\\mathbb{E}[\\mathsf{O P T}(I_{m})]}\\leq\\operatorname*{sup}_{\\mathsf{A}:\\mathrm{algo}}\\frac{\\mathbb{E}[\\mathsf{A}^{\\mathcal{D}_{\\infty}}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}+\\frac{\\epsilon_{\\sqrt{m}}(I)}{\\mathbb{E}[\\mathsf{O P T}(I)]}+\\frac{n^{2}}{\\sqrt{m}}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Finally, taking $m\\rightarrow\\infty$ and using Lemma A.1, we deduce that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{\\cal D}(\\mathsf{A L G})\\leq\\operatorname*{sup}_{\\mathsf{A\\Pi:a l g o}}\\frac{\\mathbb{E}[\\mathsf{A}^{\\cal D_{\\infty}}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\;,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which completes the proof for the random order. ", "page_idx": 16}, {"type": "text", "text": "IID random variables For any probability distribution $F$ on $[0,\\infty)$ and for any $n\\geq1$ we denote $\\mathbb{E}[{\\sf O P T}(F,n)]$ the expected maximum of $n$ independent random variables drawn from $F$ , and for any algorithm ALG we denote $\\mathbb{E}[{\\sf A L G}^{\\mathcal{D}}(F,n)]$ its expected output when given $n$ IID variable sampled from $F$ as input. The proof of Theorem 2.1 for this last model is much more technical than for previous models, so we first prove several auxiliary results that we will later use to provide a concise proof of the last part of the theorem. ", "page_idx": 16}, {"type": "text", "text": "Lemma A.2. For any probability distribution $F$ and $n\\geq1,\\Delta\\geq0$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[O P T(F,n+\\Delta)]\\leq\\left(1+{\\frac{\\Delta}{n}}\\right)\\mathbb{E}[O P T(F,n)]\\;.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. We first write ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(\\mathsf{O P T}(F,n+\\Delta)>x)=1-F(x)^{n+\\Delta}}\\\\ &{\\phantom{=}\\quad\\quad\\quad\\quad\\quad=\\left(1+F(x)^{n}\\frac{1-F(x)^{\\Delta}}{1-F(x)^{n}}\\right)(1-F(x)^{n})}\\\\ &{\\phantom{=}\\quad\\quad\\quad\\quad\\quad=\\left(1+F(x)^{n}\\frac{1-F(x)^{\\Delta}}{1-F(x)^{n}}\\right)\\operatorname*{Pr}(\\mathsf{O P T}(F,n)>x)\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and then use that ", "page_idx": 16}, {"type": "equation", "text": "$$\nF(x)^{\\Delta}=e^{\\Delta\\log(F(x))}\\geq1+\\Delta\\log(F(x))=1-\\frac{\\Delta}{n}\\log(1/F(x)^{n})\\geq1-\\frac{\\Delta}{n}\\left(\\frac{1-F(x)^{n}}{F(x)^{n}}\\right)~,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "so we directly obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\nF(x)^{n}\\frac{1-F(x)^{\\Delta}}{1-F(x)^{n}}\\leq\\frac{\\Delta}{n}\\;,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "which gives that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}({\\mathsf{O P T}}(F,n+\\Delta)>x)\\leq\\left(1+{\\frac{\\Delta}{n}}\\right)\\operatorname*{Pr}({\\mathsf{O P T}}(F,n)>x)\\;.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "As we consider non-negative random variables, it follows directly that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[{\\mathsf{O P T}}(F,n+\\Delta)]\\leq\\left(1+{\\frac{\\Delta}{n}}\\right)\\mathbb{E}[{\\mathsf{O P T}}(F,n)]\\;.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Lemma A.3. Let $N\\sim B(m,\\varepsilon)$ and let $n:=\\mathbb{E}[N]=\\varepsilon m$ , then we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[O P T(F,N)\\mathbb{1}_{N\\geq n+n^{2/3}}]\\leq\\frac{6}{n^{1/3}}\\mathbb{E}[O P T(F,n+n^{2/3})]\\ ,}\\\\ &{\\qquad\\qquad\\mathbb{E}[O P T(F,N)]\\leq\\left(1+\\frac{3}{n^{1/3}}\\right)\\mathbb{E}[O P T(F,n+n^{2/3})]\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Let $\\Delta,s>0$ such that $\\Delta\\leq s$ . For any $k\\geq1$ let $W_{k}=[s+(k-1)\\Delta,s+k\\Delta).$ . $(W_{k})_{k\\geq1}$ is a partition of $[s,\\infty)$ , thus we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbf{1}_{N\\geq s}]=\\displaystyle\\sum_{k=1}^{\\infty}\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbf{1}_{N\\in W_{k}}]}&{}\\\\ {\\leq\\displaystyle\\sum_{k=1}^{\\infty}\\mathbb{E}[\\mathsf{O P T}(F,s+k\\Delta)\\mathbf{1}_{N\\in W_{k}}]}&{}\\\\ {=\\displaystyle\\sum_{k=1}^{\\infty}\\mathbb{E}[\\mathsf{O P T}(F,s+k\\Delta)]\\,\\mathbb{P}\\mathbf{r}(N\\in W_{k})}&{}\\\\ {\\leq\\displaystyle\\sum_{k=1}^{\\infty}\\left(1+\\frac{k\\Delta}{s}\\right)\\mathbb{E}[\\mathsf{O P T}(F,s)]\\,\\mathbb{P}\\mathbf{r}(N\\in W_{k})}&{}\\\\ {=\\left(\\mathbb{P}\\mathbf{r}(N\\geq s)+\\frac{\\Delta}{s}\\sum_{k=1}^{\\infty}k\\,\\mathrm{Pr}(N\\in W_{k})\\right)\\mathbb{E}[\\mathsf{O P T}(F,s)]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where we used Lemma A.2 in the penultimate inequality. Furthermore, observing that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{\\infty}k\\operatorname*{Pr}(N\\in W_{k})=\\sum_{k=1}^{\\infty}\\sum_{\\ell=0}^{k-1}\\operatorname*{Pr}(N\\in W_{k})=\\sum_{\\ell=0}^{\\infty}\\sum_{k=\\ell+1}^{\\infty}\\operatorname*{Pr}(N\\in W_{k})=\\sum_{\\ell=0}^{\\infty}\\operatorname*{Pr}(N\\geq s+\\ell\\Delta)~,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "we obtain, given $\\Delta\\leq s$ , that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[{\\sf O P T}(F,N)\\mathbb{1}_{N\\geq s}]\\leq\\left(\\operatorname*{Pr}(N\\geq s)+\\displaystyle\\frac{\\Delta}{s}\\sum_{k=0}^{\\infty}\\operatorname*{Pr}(N\\geq s+k\\Delta)\\right)\\mathbb{E}[{\\sf O P T}(F,s)]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(2\\displaystyle\\sum_{k=0}^{\\infty}\\operatorname*{Pr}(N\\geq s+k\\Delta)\\right)~.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "$N$ is a Binomial random variable with expectation $n$ . Therefore, Chernoff\u2019s inequality gives for any $\\delta\\geq0$ that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(N\\geq(1+\\delta)n)\\leq\\exp\\left(-\\frac{\\delta^{2}n}{2+\\delta}\\right)\\leq\\exp\\left(-\\frac{\\operatorname*{min}(\\delta,\\delta^{2})n}{3}\\right)~,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the second inequality can be derived by treating separately $\\delta<1$ and $\\delta\\geq1$ . In particular, for any k \u22651, taking \u03b4 = kn\u2206 such that $\\Delta\\leq n$ yields ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\Upsilon_{\\mathsf{T}}(N\\ge n\\!+\\!k\\Delta)\\le\\exp\\left(-\\frac{\\operatorname*{min}(k\\Delta,k^{2}\\Delta^{2}/n)}{3}\\right)\\le\\exp\\left(-\\frac{k\\operatorname*{min}(\\Delta,\\Delta^{2}/n)}{3}\\right)=\\exp\\left(-\\frac{k\\Delta^{2}}{3n}\\right)\\ .\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Substituting this Inequality into (11) with $s=n+\\Delta$ , we obtain ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{N\\geq n+\\Delta}]\\leq\\left(2\\displaystyle\\sum_{k=1}^{\\infty}\\mathrm{Pr}(N\\geq n+k\\Delta)\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(2\\displaystyle\\sum_{k=1}^{\\infty}\\exp\\left(-\\frac{k\\Delta^{2}}{3n}\\right)\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}\\\\ &{\\qquad\\qquad=\\displaystyle\\frac{2}{\\exp\\left(\\frac{\\Delta^{2}}{3n}\\right)-1}\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}\\\\ &{\\qquad\\qquad\\leq\\frac{6n}{\\Delta^{2}}\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and taking $\\Delta=n^{2/3}$ proves the first inequality of the lemma. ", "page_idx": 18}, {"type": "text", "text": "Let us move now to the second inequality. We have ", "page_idx": 18}, {"type": "text", "text": "$\\begin{array}{r}{\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{N<s}]\\le\\mathbb{E}[\\mathsf{O P T}(F,s)\\mathbb{1}_{N<s}]=\\mathbb{E}[\\mathsf{O P T}(F,s)]\\operatorname*{Pr}(N<s)\\;,}\\end{array}$ and thus, using Inequality (10), again with $s=n+\\Delta$ and $\\Delta=n^{2/3}$ , it follows that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{O P T}(F,N)]=\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{N<s}]+\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{N\\geq s}]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(1+\\displaystyle\\frac{\\Delta}{s}\\displaystyle\\sum_{k=0}^{\\infty}\\mathrm{Pr}(N\\geq s+k\\Delta)\\right)\\mathbb{E}[\\mathsf{O P T}(F,s)]}\\\\ &{\\qquad\\qquad\\leq\\left(1+\\displaystyle\\sum_{k=1}^{\\infty}\\mathrm{Pr}(N\\geq n+k\\Delta)\\right)\\mathbb{E}[\\mathsf{O P T}(F,s)]}\\\\ &{\\qquad\\qquad\\leq\\left(1+\\displaystyle\\frac{3}{n^{1/3}}\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Lemma A.4. Let $\\delta_{1},\\ldots,\\delta_{m}\\overset{i i d}{\\sim}\\mathcal{B}(\\varepsilon),$ , and $\\textstyle N=\\sum_{i=1}^{m}\\delta_{i}$ . Denoting by $n=\\mathbb{E}[N]=\\varepsilon m$ , if $n\\geq4$ then ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}[N^{2}O P T(F,N)]\\le\\left(1+\\frac{8}{n^{3}}\\right)n^{2}\\mathbb{E}[O P T(F,n+n^{2/3})]\\;.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. For all $k\\in[m]$ , denote by $\\begin{array}{r}{N_{k}=\\sum_{i=k}^{m}\\delta_{i}}\\end{array}$ . We have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle N^{2}{\\sf O P T}(F,N)=\\left(\\displaystyle\\sum_{i=1}^{m}\\delta_{i}\\right)^{2}{\\sf O P T}(F,N)}}\\\\ {{\\displaystyle~~}}\\\\ {{\\displaystyle~~~~~~~~~~~~=\\left(\\displaystyle\\sum_{i=1}^{m}\\delta_{i}^{2}+2\\sum_{i<j}\\delta_{i}\\delta_{j}\\right){\\sf O P T}(F,N)~,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and observing that $\\delta_{i}^{2}=\\delta_{i}$ for all $i$ , we obtain in expectation ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[N^{2}{\\sf O P T}(F,N)]=m\\mathbb{E}[\\delta_{1}{\\sf O P T}(F,\\delta_{1}+N_{2})]+m(m-1)\\mathbb{E}[\\delta_{1}\\delta_{2}{\\sf O P T}(\\delta_{1}+\\delta_{2}+N_{3})]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\leq m\\mathbb{E}[\\delta_{1}{\\sf O P T}(F,1+N_{2})]+m(m-1)\\mathbb{E}[\\delta_{1}\\delta_{2}{\\sf O P T}(2+N_{3})]}\\\\ &{\\quad\\quad\\quad\\quad\\quad=m\\varepsilon\\mathbb{E}[{\\sf O P T}(F,1+N_{2})]+m(m-1)\\varepsilon^{2}\\mathbb{E}[{\\sf O P T}({\\sf2}+N_{3})]}\\\\ &{\\quad\\quad\\quad\\quad\\quad=m\\varepsilon\\mathbb{E}[{\\sf O P T}(F,1+N_{2})]+m^{2}\\varepsilon^{2}\\mathbb{E}[{\\sf O P T}({\\sf2}+N_{3})]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "For $j\\ \\in\\ \\{1,2\\}$ , the proof of Lemma A.3 can be easily adjusted to prove an upper bound on $\\mathbb{E}[{\\sf O P T}(F,j+N_{j+1})$ , by first bounding $\\mathbb{E}[{\\sf O P T}(F,j+N_{j+1})\\mathbb{1}_{N_{j+1}\\geq s}]$ then $\\mathbb{E}[{\\sf O P T}(F,j+$ $N_{j+1})\\mathbb{1}_{N_{j+1}<s}]$ . The concentration arguments remain the same, replacing $m$ by $m\\mathrm{~-~}j$ . The expectation of $N_{j+1}$ is $\\varepsilon(m-j)=n-\\varepsilon j$ , hence we obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\mathsf{O P T}(F,j+N_{j+1})]\\leq\\left(1+\\displaystyle\\frac{3}{(n-\\varepsilon j)^{1/3}}\\right)\\mathbb{E}[\\mathsf{O P T}(F,j+(n-\\varepsilon j)+(n-\\varepsilon j)^{2/3})]}&{}\\\\ {=\\left(1+\\displaystyle\\frac{3}{(n-\\varepsilon j)^{1/3}}\\right)\\mathbb{E}[\\mathsf{O P T}(F,j+n+n^{2/3})]}&{}\\\\ {\\leq\\left(1+\\displaystyle\\frac{3}{(n-2)^{1/3}}\\right)\\mathbb{E}[\\mathsf{O P T}(F,2+n+n^{2/3})]}&{}\\\\ {\\leq\\left(1+\\displaystyle\\frac{4}{n^{1/3}}\\right)\\mathbb{E}[\\mathsf{O P T}(F,2+n+n^{2/3})]\\:,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where we used respectively in the last inequalities that $j\\leq2$ and $n\\geq4$ . Furthermore, Lemma A.2 gives that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[{\\mathsf{O P T}}(F,j+N_{j+1})]\\leq\\left(1+\\frac{4}{n^{1/3}}\\right)\\left(1+\\frac{2}{n+n^{2/3}}\\right)\\mathbb{E}[{\\mathsf{O P T}}(F,n+n^{2/3})]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(1+\\frac{6}{n^{1/3}}\\right)\\mathbb{E}[{\\mathsf{O P T}}(F,n+n^{2/3})]\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the last inequality is true for $n\\geq4$ . Finally, substituting into 12 yields ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[N^{2}{\\sf O P T}(F,N)]\\leq(m^{2}\\varepsilon^{2}+m\\varepsilon)\\left(1+\\frac{6}{n^{1/3}}\\right)\\mathbb{E}[{\\sf O P T}(F,n+n^{2/3})]}\\\\ &{\\qquad\\qquad\\qquad=(n^{2}+n)\\left(1+\\frac{6}{n^{1/3}}\\right)\\mathbb{E}[{\\sf O P T}(F,n+n^{2/3})]}\\\\ &{\\qquad\\qquad\\qquad=\\left(1+\\frac{1}{n}\\right)\\left(1+\\frac{6}{n^{1/3}}\\right)n^{2}\\mathbb{E}[{\\sf O P T}(F,n+n^{2/3})]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(1+\\frac{8}{n^{1/3}}\\right)n^{2}\\mathbb{E}[{\\sf O P T}(F,n+n^{2/3})]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma A.5. Let $\\delta_{1},\\ldots,\\delta_{m}\\stackrel{i i d}{\\sim}\\mathcal{B}(\\varepsilon),$ , $\\textstyle N=\\sum_{i=1}^{m}\\delta_{i}$ , $n=\\mathbb{E}[N]=\\varepsilon m$ and $\\begin{array}{r}{L=\\operatorname*{min}_{i\\neq j}\\{|i-j|:}\\end{array}$ $\\delta_{i}=1,\\delta_{j}=1\\}$ , then for any $\\ell\\geq0$ we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}[O P T(F,N)\\mathbb{1}_{L\\le\\ell}]\\le7m\\ell\\varepsilon^{2}\\mathbb{E}[O P T(F,n+n^{2/3})]\\;.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. The random variables $N$ and $L$ are not independent, thus we need to adequately compute the distribution of $L$ conditional to $N$ . For any $\\ell\\geq0$ and $k\\geq2$ we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(L\\leq\\ell,N=s)=\\operatorname*{Pr}\\Big(L\\leq\\ell,\\displaystyle\\sum_{i=1}^{m}\\delta_{k}=s\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\operatorname*{Pr}\\bigg(\\bigcup_{i=1}^{m}\\bigcup_{j=\\operatorname*{max}(1,i-\\ell)}^{i-1}\\big(\\delta_{i}=\\delta_{j}=1,\\displaystyle\\sum_{i=1}^{m}\\delta_{k}=s\\big)\\bigg)}\\\\ &{\\qquad\\qquad\\qquad\\leq m\\ell\\operatorname*{Pr}\\big(\\delta_{1}=\\delta_{2}=1,\\displaystyle\\sum_{i=3}^{m}\\delta_{k}=s-2\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=m\\ell\\binom{m-2}{s-2}\\varepsilon^{s}(1-\\varepsilon)^{m-s+2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "therefore ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(L\\leq\\ell\\mid N=s)=\\frac{\\operatorname*{Pr}(L\\leq\\ell,N=s)}{\\operatorname*{Pr}(N=s)}}\\\\ &{\\qquad\\qquad\\leq\\frac{m\\ell\\binom{m-2}{s-2}\\varepsilon^{s}(1-\\varepsilon)^{m-s+2}}{\\binom{m}{s}\\varepsilon^{s}(1-\\varepsilon)^{m-s}}}\\\\ &{\\qquad\\leq m\\ell\\frac{\\binom{m-2}{s-2}}{\\binom{m}{s}}}\\\\ &{\\qquad=m\\ell\\frac{s(s-1)}{m(m-1)}}\\\\ &{\\qquad\\leq\\frac{\\ell s^{2}}{m}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Using this inequality and Lemma A.4, we deduce that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{L\\leq\\ell}]=\\mathbb{E}[\\mathsf{O P T}(F,N)\\operatorname*{Pr}(L\\leq\\ell\\mid N,0\\mathsf{P T}(F,N))]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}[\\mathsf{O P T}(F,N)\\operatorname*{Pr}(L\\leq\\ell\\mid N)]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{\\ell}{m}\\mathbb{E}[N^{2}\\mathsf{O P T}(F,N)]}\\\\ &{\\qquad\\qquad\\leq\\left(1+\\frac{8}{n^{1/3}}\\right)\\frac{\\ell n^{2}}{m}\\mathbb{E}[\\mathsf{O P T}(F,n+n^{2/3})]}\\\\ &{\\qquad\\qquad=\\left(1+\\frac{8}{n^{1/3}}\\right)m\\ell\\varepsilon^{2}\\mathbb{E}[\\mathsf{O P T}(F,n+n^{2/3})]}\\\\ &{\\qquad\\qquad=7m\\ell\\varepsilon^{2}\\mathbb{E}[\\mathsf{O P T}(F,n+n^{2/3})]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Using the previous lemmas, we can now prove the theorem. Let $m>n\\geq1$ , $\\Delta=n^{2/3}$ , $\\varepsilon=n/m$ and let $Q$ be the probability distribution of a random variable that is equal to 0 with probability $1-\\varepsilon$ , and drawn from $F$ with probability $\\varepsilon$ . ", "page_idx": 20}, {"type": "text", "text": "Let us consider $m$ i.i.d. variables $Y_{1},\\ldots,Y_{m}\\,\\sim\\,Q$ , and for each $i\\,\\in\\,[m]$ we denote by $\\delta_{i}$ the indicator that $Y_{i}$ is drawn from $F$ . Define $\\begin{array}{r}{N=\\sum_{i=1}^{m}\\delta_{i}\\sim\\mathcal{B}(m,\\varepsilon)}\\end{array}$ the number of random variables $Y_{i}$ drawn from the distribution $F$ . In the following, we upper bound the competitive ratio of any algorithm by analyzing its ratio on this particular instance. For this, we first provide a lower bound on $\\mathbb{E}[{\\sf O P T}(Q,m)]$ using Lemma A.2, and obtain ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}[{\\sf O P T}(F,n-\\Delta)]\\ge\\frac{1}{1+\\frac{2\\Delta}{n}}\\mathbb{E}[{\\sf O P T}(F,n+\\Delta)]\\ge\\left(1-\\frac{2\\Delta}{n}\\right)\\mathbb{E}[{\\sf O P T}(F,n+\\Delta)]\\;,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "thus we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\mathsf{O P T}(Q,m)]=\\mathbb{E}[\\mathsf{O P T}(F,N)]}&{}\\\\ {\\leq\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbf{1}_{N\\geq n-\\Delta}]}\\\\ {\\geq\\mathbb{E}[\\mathsf{O P T}(F,n-\\Delta)\\mathbf{1}_{N\\geq n-\\Delta}]}\\\\ {=\\mathbb{E}[\\mathsf{O P T}(F,n-\\Delta)]\\operatorname{Pr}(N\\geq n-\\Delta)}\\\\ {\\geq\\left(1-\\frac{2\\Delta}{n}\\right)\\operatorname{Pr}(N\\geq n-\\Delta)\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}\\\\ {\\geq\\left(1-\\frac{2\\Delta}{n}-\\operatorname*{Pr}(N<n-\\Delta)\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}\\\\ {\\geq\\left(1-2n^{-1/3}-\\exp(-n^{1/3}/2)\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}\\\\ {\\geq\\left(1-4n^{-1/3}\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]\\mid,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where, for the last three inequalities, we used respectively Bernoulli\u2019s inequality, Chernoff bound, then $e^{-y}\\leq1/y$ . ", "page_idx": 20}, {"type": "text", "text": "Then, we upper bound the reward of any algorithm given the instance $(Q,m)$ as input. Let $L=$ $\\begin{array}{r}{\\operatorname*{min}_{i\\neq j}\\{|i-j|:\\delta_{i}=1,\\delta_{j}=1\\}}\\end{array}$ the smallest gap between two successive variables $Y_{i}$ drawn from $F$ , and let $t_{1}<\\ldots<t_{N}$ the indices for which $\\delta_{i}=1$ . We have for any algorithm ALG and positive integer $\\ell$ that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[{\\mathsf{A L G}}^{D}(Q,m)]=\\mathbb{E}[{\\mathsf{A L G}}^{D}(Q,m){\\mathbb{1}}_{N\\geq n+\\Delta\\,\\mathrm{or}\\,L\\leq\\ell}]+\\mathbb{E}[{\\mathsf{A L G}}^{D}(Q,m){\\mathbb{1}}_{N<n+\\Delta,L>\\ell}]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Using Lemma A.3 and Lemma A.5, the first term can be bounded as follows ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{D}(Q,m)\\mathbb{1}_{N\\geq n+\\Delta\\mathsf{\\sigma r}\\,L\\leq\\ell}]\\leq\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{N\\geq n+\\Delta\\mathsf{\\sigma r}\\,L\\leq\\ell}]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{N\\geq n+\\Delta}]+\\mathbb{E}[\\mathsf{O P T}(F,N)\\mathbb{1}_{L\\leq\\ell}]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(\\frac{6}{n^{1/3}}+7m\\ell\\varepsilon^{2}\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+n^{2/3})]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Recalling that $\\varepsilon=m/n$ and taking $\\ell=\\sqrt{m}$ , we obtain ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{A L G}^{\\mathcal{D}}(Q,m)\\mathbb{1}_{N\\ge n+\\Delta\\;\\mathrm{or}\\;L\\le\\ell}]\\le\\left(\\frac{6}{n^{1/3}}+\\frac{7n^{2}}{\\sqrt{m}}\\right)\\mathbb{E}[\\mathsf{O P T}(F,n+n^{2/3})]\\;.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Regarding the second term in Equation (14), let $\\tau$ be the stopping time of ALG and $t_{\\rho}=\\operatorname*{max}\\{j\\leq$ $\\bar{\\tau}:\\bar{\\delta}_{j}=\\bar{1}\\}$ the last value sampled from $F$ and observed by ALG before it stops. We have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\mathsf{A L G}^{D}(Q,m)\\mathbb{1}_{N<n+\\Delta,L>\\ell}]\\le\\mathbb{E}[\\mathsf{A L G}^{D}(Q,m)\\mid N<n+\\Delta,L>\\ell]}&{}\\\\ {=\\mathbb{E}[\\operatorname*{max}_{i\\in[\\tau]}D_{\\tau-i}(Y_{i})\\mid N<n+\\Delta,L>\\ell]}\\\\ {=\\mathbb{E}[\\operatorname*{max}_{j\\in[\\rho]}D_{\\tau-t_{j}}(Y_{i})\\mid N<n+\\Delta,L>\\ell]}\\\\ {\\le\\mathbb{E}[\\operatorname*{max}_{j\\in[\\rho]}D_{t_{\\rho}-t_{j}}(Y_{i})\\mid N<n+\\Delta,L>\\ell]}\\\\ {=\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{t_{\\rho}},\\operatorname*{max}D_{t_{\\rho}-t_{j}}(Y_{t_{j}})\\right\\}\\mid N<n+\\Delta,L>\\ell]}\\\\ {\\le\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{t_{\\rho}},\\operatorname*{max}D_{\\ell}(Y_{t_{j}})\\right\\}\\mid N<n+\\Delta,L>\\ell]}\\\\ {\\le\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{t_{\\rho}},\\operatorname*{max}D_{\\ell}(Y_{t_{j}})\\right\\}\\mid N<n+\\Delta]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We then prove that the last term is the reward of an algorithm $\\mathsf{A}_{m}$ in the $D_{\\ell}$ -prophet inequality. Let us $\\mathsf{A}_{m}$ be the algorithm that takes as input an instance $X_{1},\\ldots,X_{n+\\Delta-1}$ of $n+\\Delta$ IID random variables, then simulates $\\mathsf{A L G}^{\\mathcal{D}}(Q,m)\\mid N<n+\\Delta$ as follows: let $\\delta_{1},\\ldots,\\delta_{m}\\stackrel{\\mathrm{iid}}{\\sim}\\mathcal{B}(n/m)$ set $N_{\\mathsf{A}}=0$ and for each $i\\in[m]$ ", "page_idx": 21}, {"type": "text", "text": "\u2022 if $\\delta_{i}=0$ : ALG observes the value $Y_{i}=0$ ,   \n\u2022 if $\\delta_{i}=1$ : increment $N$ , then $\\mathsf{A}_{m}$ observes the next value $X_{k}$ , and ALG observes $Y_{i}=X_{k}$ , \u2022 if $N_{\\mathsf{A}}=n+\\Delta-1$ or ALG stops, then $\\mathsf{A}_{m}$ also stops. ", "page_idx": 21}, {"type": "text", "text": "When ALG decides to stop, the current value observed by $\\mathsf{A}_{m}$ is $X_{\\rho}$ : the last value $Y_{t_{\\rho}}$ observed by ALG such that $\\delta_{t_{\\rho}}=0$ . Observe that stopping when $N_{\\mathsf{A}}=n+\\Delta+1$ , is equivalent to letting $\\mathsf{A L G}$ observe zero values until the end, and stopping when ALG stops. Hence, the variables $Y_{1},\\ldots,Y_{m}$ have the same distribution as $m$ IID samples from $Q$ conditional to $N<n+\\Delta$ . Denoting $\\rho$ the stopping time of $\\mathsf{A}_{m}$ and $\\epsilon_{\\ell}(F,n+\\Delta)$ as defined in Lemma A.1, we deduce that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{D}(Q,m)\\mid N<n+\\Delta,L>\\ell]\\le\\mathbb{E}[\\operatorname*{max}\\left\\{Y_{t_{\\rho}},\\underset{j<\\rho}{\\operatorname*{max}}D_{\\ell}(Y_{t_{j}})\\right\\}\\mid N<n+\\Delta]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}[\\operatorname*{max}\\left\\{X_{\\rho},\\underset{j<\\rho}{\\operatorname*{max}}D_{\\ell}(X_{j})\\right\\}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}[\\mathsf{A}_{m}^{D_{\\ell}}(F,n+\\Delta)]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\mathbb{E}[\\mathsf{A}_{m}^{D_{\\infty}}(F,n+\\Delta)]+\\epsilon_{\\ell}(F,n+\\Delta)\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Substituting (15) and (16) in (14), with $\\ell=\\sqrt{m}$ , yields ", "page_idx": 21}, {"type": "equation", "text": "$$\n{\\mathfrak{z}}[{\\mathsf{A L G}}^{D}(Q,m)]\\leq\\left({\\frac{6}{n^{1/3}}}+{\\frac{7n^{2}}{\\sqrt{m}}}\\right){\\mathbb{E}}[{\\mathsf{O P T}}(F,n+\\Delta)]+{\\mathbb{E}}[{\\mathsf{A}}_{m}^{D_{\\infty}}(F,n+\\Delta)]+\\epsilon_{\\sqrt{m}}(F,n+\\Delta)\\;,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "and using Inequality 13, it follows that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{C}\\mathsf{R}^{\\mathcal{D}}(\\mathsf{A L G})\\le\\frac{\\mathbb{E}[\\mathsf{A L G}^{D}(Q,m)]}{\\mathbb{E}[\\mathsf{O P T}(Q,m)]}}\\\\ &{\\qquad\\qquad\\le\\frac{\\frac{6}{n^{1/3}}+\\frac{7n^{2}}{\\sqrt{m}}}{1-\\frac{4}{n^{1/3}}}+\\frac{\\mathbb{E}[\\mathsf{A}_{m}^{D_{\\infty}}(F,n+\\Delta)]+\\epsilon_{\\sqrt{m}}(F,n+\\Delta)}{(1-\\frac{4}{n^{1/3}})\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}}\\\\ &{\\qquad\\le\\frac{\\frac{6}{n^{1/3}}+\\frac{7n^{2}}{\\sqrt{m}}}{1-\\frac{4}{n^{1/3}}}+\\frac{1}{1-\\frac{4}{n^{1/3}}}\\left(\\frac{\\epsilon_{\\sqrt{m}}(F,n+\\Delta)}{\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}+\\operatorname*{sup}_{\\mathbb{A}\\ge\\log}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(F,n+\\Delta)]}{\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]}\\right)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "taking the limit $m\\rightarrow\\infty$ and using Lemma A.1 gives ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{{\\mathsf{C R}}^{{\\mathbb{D}}}(\\mathsf{A L G})\\leq\\frac{\\frac{6}{n^{1/3}}}{1-\\frac{4}{n^{1/3}}}+\\frac{1}{1-\\frac{4}{n^{1/3}}}\\left(\\operatorname*{sup}_{\\mathsf{A\\cdot a l g o}}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(F,n+\\Delta)]}{\\mathbb{E}[{\\mathsf{O P T}}(F,n+\\Delta)]}\\right)}\\\\ &{\\qquad\\qquad=\\frac{6}{n^{1/3}-4}+\\left(1+\\frac{4}{n^{1/3}-4}\\right)\\left(\\operatorname*{sup}_{\\mathsf{A\\cdot a l g o}}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(F,n+\\Delta)]}{\\mathbb{E}[{\\mathsf{O P T}}(F,n+\\Delta)]}\\right)}\\\\ &{\\qquad\\qquad\\leq\\frac{10}{n^{1/3}-4}+\\operatorname*{sup}_{\\mathsf{A\\cdot a l g o}}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(F,n+n^{2/3})]}{\\mathbb{E}[{\\mathsf{O P T}}(F,n+n^{2/3})]}\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the last inequality holds because $\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(F,n+\\Delta)]\\le\\mathbb{E}[\\mathsf{O P T}(F,n+\\Delta)]$ for any algorithm A. From here, the statement of the theorem can be deduced by observing that, for $\\dot{k}=n+n^{2/3}$ , we have $n\\geq(n+n^{2/3})/2=k/2$ , thus $n^{1/3}\\geq k^{1/3}/2$ , and we obtain ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathsf{C R}^{\\mathcal{D}}(\\mathsf{A L G})\\le\\displaystyle\\frac{20}{k^{1/3}-8}+\\operatorname*{sup}_{\\mathsf{A}:\\mathrm{algo}}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(F,k)]}{\\mathbb{E}[\\mathsf{O P T}(F,k)]}}\\\\ &{}&{=\\displaystyle\\operatorname*{sup}_{\\mathsf{A}:\\mathrm{algo}}\\frac{\\mathbb{E}[\\mathsf{A}^{D_{\\infty}}(F,k)]}{\\mathbb{E}[\\mathsf{O P T}(F,k)]}+O\\left(\\frac{1}{k^{1/3}}\\right)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "B From $D_{\\infty}$ -prophet to the $\\gamma_{D}$ -prophet inequality ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "B.1 Proof of Lemma 3.1 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proof. Let ALG be any rational algorithm in the $D_{\\infty}$ -prophet inequality. If ALG stops at some step $\\tau\\in[n]$ , then by definition we have that $X_{\\tau}>D_{\\infty}(\\operatorname*{max}_{j<\\tau}X_{j})$ , and thus $\\mathsf{A L G}^{D_{\\infty}}(X_{1},\\ldots,X_{n})=$ ${\\sf A L G}^{0}(X_{1},\\ldots,X_{n})$ . Otherwise, if it stops at $\\tau=n+1$ , then its reward is $\\begin{array}{r l}{\\operatorname*{max}_{i\\in[n]}D_{\\infty}(X_{i})=}&{{}}\\end{array}$ $D_{\\infty}(\\operatorname*{max}_{i\\in[n]}X_{i})$ , because $D_{\\infty}$ -is non increasing. ", "page_idx": 22}, {"type": "text", "text": "On the other hand, let $\\mathsf{A}_{*}$ be the optimal dynamic programming algorithm for the $D_{\\infty}$ -prophet inequality. At any step $i$ , if $X_{i}<D_{\\infty}(\\operatorname*{max}_{j<i}X_{j})$ , then stopping at $i$ gives a reward of $D_{\\infty}(\\operatorname*{max}_{j<i}X_{j})$ , while by rejecting $X_{i}$ , the final reward is guaranteed to be at least $D_{\\infty}(\\operatorname*{max}_{j<i}X_{j})$ . Thus rejecting $X_{i}$ can only increase the reward, it is therefore the optimal decision. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "B.2 Proof of Proposition 3.2 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proof. Let us place ourselves in any order model, or in the IID model. Assume that $\\begin{array}{r}{\\operatorname*{inf}_{x>0}\\frac{D_{\\infty}(x)}{x}=}\\end{array}$ 0, then there exist a sequence $\\left(s_{k}\\right)_{k\\geq1}$ such that $\\begin{array}{r}{\\operatorname*{lim}_{k\\to\\infty}\\frac{D_{\\infty}(s_{k})}{s_{k}}=0.}\\end{array}$ ", "page_idx": 22}, {"type": "text", "text": "Let $\\boldsymbol{I}\\,=\\,(F_{1},\\dots,F_{n})$ an instance of non-negative random variables with finite expectation, and $X_{i}\\sim F_{i}$ for all $i\\in[n]$ . Let ALG be a rational algorithm for the $D_{\\infty}$ -prophet inequality and let us denote $\\tau$ its stopping time. Denoting $X^{*}:=\\operatorname*{max}_{i\\in[n]}X_{i}$ and using Lemma 3.1, we have for any constant $C>0$ that that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{D_{\\infty}}(I)]=\\mathbb{E}[\\mathsf{A L G}^{0}(I)\\mathbb{1}_{\\tau\\leq n}]+\\mathbb{E}[D_{\\infty}(X^{\\ast})\\mathbb{1}_{\\tau=n+1}]}\\\\ &{\\phantom{\\leq}\\mathbb{E}[\\mathsf{A L G}^{0}(I)]+\\mathbb{E}[D_{\\infty}(C)]+\\mathbb{E}[D_{\\infty}(X^{\\ast})\\mathbb{1}_{X^{\\ast}>C}]}\\\\ &{\\phantom{\\leq}\\operatorname*{sup}_{\\mathsf{A}}\\mathbb{E}[\\mathsf{A}^{0}(I)]+\\mathbb{E}[D_{\\infty}(C)]+\\mathbb{E}[X^{\\ast}\\mathbb{1}_{X^{\\ast}>C}]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let $k\\ \\geq\\ 1$ a positive integer, $M$ a positive constant, and consider the instance $I^{k}$ of random variables $(X_{1}^{k},\\cdot\\cdot\\cdot,X_{n}^{k})$ with $\\begin{array}{r}{X_{i}^{k}\\sim\\frac{\\mathbf{\\dot{s}}_{k}}{M}X_{i}}\\end{array}$ for all $i\\,\\in\\,[n]$ . We have that $\\mathsf{O P T}(I^{k})\\,=\\,\\frac{s_{k}}{M}\\mathsf{O P T}(I)$ and $\\begin{array}{r}{\\operatorname*{sup}_{\\mathsf{A}}\\mathbb{E}[\\mathsf{A}^{0}(I^{k})]=\\frac{s_{k}}{M}\\operatorname*{sup}_{\\mathsf{A}}\\mathbb{E}[\\mathsf{A}^{0}(I)]}\\end{array}$ . Therefore, using Inequality (17) with $I^{k}$ instead of $I$ and ", "page_idx": 22}, {"type": "text", "text": "$\\begin{array}{r}{C=\\frac{s_{k}}{M}}\\end{array}$ , then dividing by ${\\mathsf{O P T}}(I^{k})$ gives that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{X}^{D_{\\infty}}(\\mathsf{A L G})\\leq\\frac{\\mathbb{E}[\\mathsf{A L G}^{D_{\\infty}}(I^{k})]}{\\mathbb{E}[\\mathsf{O P T}(I^{k})]}\\leq\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{0}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}+\\frac{D_{\\infty}(s_{k})}{\\frac{s_{k}}{M}\\mathbb{E}[\\mathsf{O P T}(I)]}+\\frac{\\mathbb{E}[\\frac{s_{k}}{M}X^{*}\\mathbb{1}_{X^{*}>M}]}{\\frac{s_{k}}{M}\\mathbb{E}[\\mathsf{O P T}(I)]}}\\\\ {=\\displaystyle\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{0}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}+\\left(\\frac{M}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\right)\\frac{D_{\\infty}(s_{k})}{s_{k}}+\\frac{\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>M}]}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and taking the limit $k\\rightarrow\\infty$ , we obtain ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{D_{\\infty}}(\\mathsf{A L G})\\leq\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{0}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}+\\frac{\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>M}]}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\;,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and since $X^{*}$ has finite expectation, taking the limit $M\\to\\infty$ gives ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{D\\infty}(\\mathsf{A L G})\\leq\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{0}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\mathrm{~.~}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Finally, taking the infimum over all instances, we obtain that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{D\\infty}(\\mathsf{A L G})\\leq\\operatorname*{sup}_{\\mathsf{A}}\\mathsf{C R}^{0}(\\mathsf{A})\\;.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "As in the proof of Corollary 2.1.1, permuting $\\operatorname{inf}_{I}$ and $\\mathrm{sup}_{\\mathsf{A}}$ is possible because there is an algorithm (dynamic programming) achieving the supremum for any instance. By Lemma 3.1, the inequality above holds for in particular for the optimal dynamic programming algorithm, which has a maximal competitive ratio. Therefore, the inequality remains true for any other algorithm A, not necessarily rational. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "B.3 Proof of Proposition 3.3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Proof. Let us place ourselves in any order model or in the IID model. Since $\\gamma=\\operatorname*{inf}_{x>0}\\frac{D_{\\infty}(x)}{x}$ there exists a sequence $\\left(s_{k}\\right)_{k\\geq1}$ of positive numbers such that $\\begin{array}{r}{\\operatorname*{lim}_{k\\to\\infty}\\frac{D_{\\infty}(s_{k})}{s_{k}}=\\gamma.}\\end{array}$ . ", "page_idx": 23}, {"type": "text", "text": "For the random variables $X_{1},\\ldots,X_{n}$ taking values in $\\{0,a,b\\}$ a.s., in any order model, it is clear that the optimal decision when observing a zero value is to reject it, and when observing the value $b$ is to accept it. Let ALG be an algorithm satisfying this property and let $\\tau$ be its stopping time. If $\\tau=n+1$ then necessarily $\\operatorname*{max}_{i\\in[n]}X_{i}\\neq b$ , and the reward of ALG in that case is $D_{\\infty}(a)$ if $\\operatorname*{max}_{i\\in[n]}X_{i}$ and 0 otherwise. In particular, ALG is rational in the $D_{\\infty}$ -prophet inequality and we have by Lemma 3.1 that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{D_{\\infty}}(I)]=\\mathbb{E}[\\mathsf{A L G}^{0}(I)]+\\mathbb{E}[D_{\\infty}(\\operatorname*{max}_{i\\in[n]}X_{i})\\mathbb{1}_{\\tau=n+1}]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}[\\mathsf{A L G}^{0}(I)]+D_{\\infty}(a)\\operatorname*{Pr}(\\tau=n+1,\\operatorname*{max}_{i\\in[n]}X_{i}=a)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Consider now the instance $I^{k}$ of random variables $(X_{1}^{k},\\cdot\\cdot\\cdot,X_{n}^{k})$ where $\\begin{array}{r}{X_{i}^{k}=\\frac{s_{k}}{a}X_{i}}\\end{array}$ for all $i\\in[n]$ . $I^{k}$ satisfies the same assumptions as $I$ with $a^{k}=s_{k}$ and $\\textstyle b^{k}\\,=\\,{\\frac{s_{k}b}{a}}$ , and we have $\\mathbb{E}[{\\sf O P T}(I^{k})]=$ $\\begin{array}{r}{\\frac{s_{k}}{a}\\mathbb{E}[{\\sf O P T}(I)],\\mathbb{E}[{\\sf A L G}^{0}(I^{k})]\\leq\\frac{s_{k}}{a}\\operatorname*{sup}_{\\mathsf{A}}\\mathbb{E}[{\\sf A}^{0}(I)]}\\end{array}$ and $\\begin{array}{r}{(\\operatorname*{max}_{i\\in[n]}X_{i}^{k}=a^{k})\\iff(\\operatorname*{max}_{i\\in[n]}X_{i}=}\\end{array}$ $a)$ . It follows that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\mathbb{E}[\\mathsf{A}\\mathsf{L}\\mathsf{G}^{D_{\\infty}}(I^{k})]}{\\mathbb{E}[\\mathsf{O}\\mathsf{P}\\mathsf{T}(I^{k})]}\\leq\\frac{\\operatorname*{sup}_{\\mathsf{A}}\\mathbb{E}[\\mathsf{A}^{0}(I)]}{\\mathbb{E}[\\mathsf{O}\\mathsf{P}\\mathsf{T}(I)]}+\\frac{D_{\\infty}(s_{k})}{\\frac{s_{k}}{a}\\mathbb{E}[\\mathsf{O}\\mathsf{P}\\mathsf{T}(I)]}\\operatorname*{Pr}(\\tau=n+1,\\underset{i\\in[n]}{\\operatorname*{max}}X_{i}=a)}\\\\ &{\\,\\quad\\,\\quad\\,\\quad\\,\\quad\\,\\quad\\,\\,=\\frac{\\operatorname*{sup}_{\\mathsf{A}}\\mathbb{E}[\\mathsf{A}^{0}(I)]}{\\mathbb{E}[\\mathsf{O}\\mathsf{P}\\mathsf{T}(I)]}+\\left(\\frac{D_{\\infty}(s_{k})}{s_{k}}\\right)\\frac{a}{\\mathbb{E}[\\mathsf{O}\\mathsf{P}\\mathsf{T}(I)]}\\operatorname*{Pr}(\\tau=n+1,\\underset{i\\in[n]}{\\operatorname*{max}}X_{i}=a)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Taking the limit $k\\rightarrow\\infty$ gives ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathsf{C R}^{D_{\\infty}}(\\mathsf{A L G})\\leq\\frac{\\operatorname*{sup}_{\\mathsf{A}}\\mathbb{E}[\\mathsf{A}^{0}(I)]+\\gamma a\\operatorname*{Pr}(\\tau=n+1,\\operatorname*{max}_{i\\in[n]}X_{i}=a)}{\\mathbb{E}[\\mathsf{O P T}(I)]}}\\\\ {=\\frac{\\operatorname*{sup}_{\\mathsf{A}}(\\mathbb{E}[\\mathsf{A}^{0}(I)]+\\mathbb{E}[\\gamma(\\operatorname*{max}_{i\\in[n]}X_{i})\\mathbb{1}_{\\tau=n+1}])}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\;.\\quad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "ALG is also rational in the $\\gamma$ -prophet inequality. Therefore, using Lemma 3.1, we deduce that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{D_{\\infty}}(\\mathsf{A L G})\\leq\\frac{\\mathbb{E}[\\mathsf{A L G}^{\\gamma}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}\\leq\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{\\gamma}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This upper bound is true for the optimal dynamic programming algorithm, since it rejects all zeros and accepts $b$ , therefore the upper bound also holds for any other algorithm. \u53e3 ", "page_idx": 24}, {"type": "text", "text": "C The $\\gamma_{D}$ -prophet inequality ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "C.1 Proof of Proposition 4.2 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Proof. For the lower bound, it suffices to consider the following trivial algorithm: if $\\alpha>\\gamma$ then run $\\mathsf{A}_{\\alpha}$ , and if $\\gamma>\\alpha$ then observe all the items then select the one with maximum value. ", "page_idx": 24}, {"type": "text", "text": "For the upper bound, let $\\boldsymbol{I}\\,=\\,(F_{1},\\dots,F_{n})$ be an instance of the problem and $X_{i}\\sim\\;F_{i}$ for all $i$ , and let $\\begin{array}{r}{\\beta_{I}:=\\operatorname*{sup}_{\\mathsf{A}}\\frac{\\mathbb{E}[\\mathsf{A}^{0}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}}\\end{array}$ . Let $\\mathsf{A}$ be any algorithm, $\\tau$ its stopping time, and $Y_{\\tau}=\\operatorname*{max}_{i<\\tau}X_{\\pi(i)},$ where $\\pi$ is the observation order. With the previous notations, we can write that $\\mathbb{E}[\\mathsf{A}^{\\gamma}(I)]\\;=$ $\\mathbb{E}[\\operatorname*{max}(X_{\\pi(\\tau)},\\gamma Y_{\\tau})]$ . For any $x,y\\geq0$ , the application $\\gamma\\mapsto\\operatorname*{max}(x,\\gamma y)$ is convex on $[0,1]$ , hence it can be upper bounded by $(1-\\gamma)x+\\gamma\\operatorname*{max}(x,y)$ . Therefore ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A}^{\\gamma}(I)]\\leq(1-\\gamma)\\mathbb{E}[X_{\\pi(\\tau)}]+\\gamma\\mathbb{E}[\\operatorname*{max}(X_{\\pi(\\tau)},Y_{\\tau})]}\\\\ &{\\qquad\\qquad\\leq(1-\\gamma)\\mathbb{E}[\\mathsf{A}^{0}(I)]+\\gamma\\mathbb{E}[\\mathsf{O P T}(I)]}\\\\ &{\\qquad\\qquad\\leq\\big((1-\\gamma)\\beta_{I}+\\gamma\\big)\\mathbb{E}[\\mathsf{O P T}(I)]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, $\\mathsf{C R}^{\\gamma}(\\mathsf{A L G})\\leq((1-\\gamma)\\beta_{I}+\\gamma)$ . Taking the infimum over all the instances $I$ gives the result. Indeed, if we denote $\\mathsf{A}_{*}$ the optimal dynamic programming algorithm for the standard prophet inequality, then ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{I}\\beta_{I}=\\operatorname*{inf}_{I}\\frac{\\mathbb{E}[\\mathsf{A}_{*}^{0}(I)]}{\\mathbb{E}[\\mathsf{O P T}(I)]}={\\mathsf{C R}}^{0}(\\mathsf{A}_{*})\\leq\\beta\\;.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "C.2 Proofs for the adversarial order model ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Proof. We first prove the upper bound, and then analyze the single threshold algorithm proposed in the theorem. ", "page_idx": 24}, {"type": "text", "text": "Upper bound Let $\\varepsilon\\in(0,1-\\gamma)$ , and let $\\begin{array}{r}{a=\\frac{1}{1-(1-\\varepsilon)\\gamma}}\\end{array}$ (such that $1+(1-\\varepsilon)\\gamma a=a)$ . Let $X_{1},X_{2}$ the two random variables defined by $X_{1}=a$ almost surely and ", "page_idx": 24}, {"type": "equation", "text": "$$\nX_{2}=\\left\\{\\begin{array}{l l}{{\\frac1\\varepsilon}}&{{\\mathrm{w.p.~}\\varepsilon}}\\\\ {{0}}&{{\\mathrm{w.p.~}1-\\varepsilon}}\\end{array}\\right.\\ .\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Stopping at the first step gives a reward of $a$ , while stopping at the second step gives ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\operatorname*{max}(\\gamma a,X_{2})]=\\varepsilon\\times\\frac{1}{\\varepsilon}+(1-\\varepsilon)\\times\\gamma a=1+(1-\\varepsilon)\\gamma a=a\\;,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "hence the expected output of any algorithm is exactly equal to $a$ . On the other hand ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\operatorname*{max}(X_{1},X_{2})]=1+(1-\\varepsilon)a~,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and we deduce that, for any algorithm ALG for the $\\gamma$ -prophet inequality, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathsf{C R}(\\mathsf{A L G})\\leq\\frac{\\mathbb{E}[\\mathsf{A L G}(X_{1},X_{2})]}{\\mathbb{E}[\\operatorname*{max}(X_{1},X_{2})]}=\\frac{a}{1+(1-\\varepsilon)a}\\;,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and this is true for any $\\varepsilon\\in(0,1-\\gamma)$ , thus taking $\\varepsilon\\rightarrow0$ gives ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathsf{C R}(\\mathsf{A L G})\\leq\\frac{\\frac{1}{1-\\gamma}}{1+\\frac{1}{1-\\gamma}}=\\frac{1}{2-\\gamma}\\;.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Lower bound Consider an algorithm with an acceptance threshold $\\theta$ , i.e. that accepts the first value larger than $\\theta$ . Let $\\bar{I}=(F_{1},\\bar{\\dots},F_{n})$ be any instance, such that $X_{i}\\sim F_{i}$ for all $i$ , and let us define $X^{*}=\\operatorname*{max}_{i\\in[n]}X_{i}$ and $p=\\operatorname*{Pr}(X^{*}\\leq\\theta)$ . In the classical prophet inequality, if no value is larger than $\\theta$ then the reward of the algorithm is zero, and we have the classical lower bound ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{A L G}^{0}(I)]\\ge(1-p)\\theta+p\\mathbb{E}[(X^{\\ast}-\\theta)_{+}],\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "For the $\\gamma$ -prophet, if no value is larger than $\\theta$ (i.e $X^{*}\\leq\\theta_{,}$ ), then the algorithm gains $\\gamma X^{*}$ instead of 0. Therefore, it holds that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{\\gamma}(I)]=\\mathbb{E}[\\mathsf{A L G}^{0}(I)]+\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}\\leq\\theta}]}\\\\ &{\\phantom{=}\\ge(1-p)\\theta+p\\mathbb{E}[(X^{*}-\\theta)_{+}]+\\gamma\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}\\leq\\theta}]}\\\\ &{\\phantom{=}=(1-p)\\theta+p\\mathbb{E}[(X^{*}-\\theta)\\mathbb{1}_{X^{*}>\\theta}]+\\gamma\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}\\leq\\theta}]}\\\\ &{\\phantom{=}=(1-p)\\theta+p(\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>\\theta}]-(1-p)\\theta)+\\gamma\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}\\leq\\theta}]}\\\\ &{\\phantom{=}=(1-p)^{2}\\theta+p\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>\\theta}]+\\gamma\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}\\leq\\theta}]\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and observing that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\theta=\\frac{\\mathbb{E}[\\theta\\mathbb{1}_{X^{\\ast}\\leq\\theta}]}{p}\\geq\\frac{\\mathbb{E}[X^{\\ast}\\mathbb{1}_{X^{\\ast}\\leq\\theta}]}{p}~,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "we deduce the lower bound ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[{\\sf A L G}^{\\gamma}(I)]\\ge p\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>\\theta}]+\\left(\\gamma+\\displaystyle\\frac{(1-p)^{2}}{p}\\right)\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}\\le\\theta}]}\\\\ &{\\qquad\\qquad\\ge\\operatorname*{min}\\left\\{p,\\gamma+\\displaystyle\\frac{(1-p)^{2}}{p}\\right\\}\\mathbb{E}[X^{*}]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The right term is maximized for $p$ satisfying $\\begin{array}{r}{p=\\gamma+\\frac{(1-p)^{2}}{p}}\\end{array}$ , that leads to ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{p=\\gamma+\\displaystyle\\frac{(1-p)^{2}}{p}\\,\\,\\Longleftrightarrow\\,\\,p^{2}=\\gamma p+1-2p+p^{2}}}\\\\ {{\\nonumber}}\\\\ {{\\Longleftrightarrow\\,\\,p=\\displaystyle\\frac{1}{2-\\gamma}\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Hence, by choosing a threshold \u03b8 satisfying Pr(X\u2217\u2264\u03b8) =2\u22121\u03b3 we obtain a competitive ratio of at least $\\textstyle{\\frac{1}{2-\\gamma}}$ . \u53e3 ", "page_idx": 25}, {"type": "text", "text": "C.3 Proofs for the random order model ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We prove here the upper and lower bounds stated in Theorem 4.4. ", "page_idx": 25}, {"type": "text", "text": "C.3.1 Proof of Theorem 4.4 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Proof. We first prove the upper bound, and then derive the analysis for single threshold algorithms. ", "page_idx": 25}, {"type": "text", "text": "Upper bound Let $a~>~0$ , and let $X_{1},\\ldots,X_{n+1}$ be independent random variables such that $X_{n+1}=a$ a.s. and for $1\\leq i\\leq n$ ", "page_idx": 25}, {"type": "equation", "text": "$$\nX_{i}\\sim\\left\\{\\begin{array}{l l}{{n}}&{{\\mathrm{w.p.~}\\frac{1}{n^{2}}}}\\\\ {{0}}&{{\\mathrm{w.p.~}1-\\frac{1}{n^{2}}}}\\end{array}\\right.~.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Any reasonable algorithm skips zero values and stops when observing the value $n$ . The only strategic decision to make is thus to stop or not when observing $X_{n+1}\\,=\\,a$ . By analyzing the dynamic programming solution $\\mathsf{A L G}_{\\star}$ we obtain that the optimal decision rule is to skip $a$ if it is observed before a certain step $j$ , and select it otherwise. The step $j$ corresponds to the time when the expectation of the future reward is less than $a$ . Let $\\pi$ be the random order in which the variables are observed. Then, if $\\pi^{-1}(n+1)<j$ , i.e. if the value $a$ is observed before time $j$ , $X_{n=1}$ is not selected. The output of this algorithm is hence $n$ if at least one random variable equals $n$ , and $\\gamma a$ otherwise. This leads to ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathsf{A L G}_{\\star}^{\\gamma}(X)\\mid\\pi^{-1}(n+1)<j]=n\\left(1-\\left(1-\\displaystyle\\frac{1}{n^{2}}\\right)^{n}\\right)+\\gamma a\\left(1-\\displaystyle\\frac{1}{n^{2}}\\right)^{n}}\\\\ {\\leq1+\\gamma a\\;,\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where we used the inequality $\\left(1-{\\frac{1}{n^{2}}}\\right)^{n}\\,\\geq\\,1\\,-\\,{\\frac{1}{n}}$ . On the other hand, if $\\pi^{-1}(n)\\geq j$ , then $a$ is selected if the value $n$ has not been observed before it, hence for any $i\\geq j$ we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\mathbb{E}[{\\sf A L G}_{\\star}^{\\gamma}(X)\\mid\\pi^{-1}(n+1)=i]=n\\left(1-\\left(1-\\displaystyle\\frac{1}{n^{2}}\\right)^{i-1}\\right)+a\\left(1-\\displaystyle\\frac{1}{n^{2}}\\right)^{i-1}}\\\\ {\\leq\\displaystyle\\frac{i-1}{n}+a\\:,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "we deduce that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}_{\\star}^{\\gamma}(X)]\\leq(1+\\gamma a)\\operatorname*{Pr}(\\pi^{-1}(n)\\leq j-1)+\\displaystyle\\sum_{i=j}^{n+1}\\left(\\frac{i-1}{n}+a\\right)\\operatorname*{Pr}(\\pi^{-1}(n)=i)}\\\\ &{\\qquad\\qquad=\\frac{j-1}{n+1}(1+\\gamma a)+\\displaystyle\\frac{1}{n+1}\\sum_{i=j}^{n+1}\\left(\\frac{i-1}{n}+a\\right)}\\\\ &{\\qquad=(1-(1-\\gamma)a)\\frac{j}{n}-\\displaystyle\\frac{1}{2}\\left(\\frac{j}{n}\\right)^{2}+\\displaystyle\\frac{1}{2}+a+o(1)}\\\\ &{\\qquad\\leq1+2\\gamma a+(1-\\gamma)^{2}a^{2}+o(1)\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the last inequality is obtained by maximizing over $j/n$ . Finally, we directly obtain that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}[\\operatorname*{max}_{i}X_{i}]=n\\left(1-\\left(1-\\frac{1}{n^{2}}\\right)^{n}\\right)+a\\left(1-\\frac{1}{n^{2}}\\right)^{n}}\\\\ {\\displaystyle=1+a+o(1)\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "so for any algorithm ALG we obtain that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{\\gamma}(\\mathsf{A L G})\\leq\\mathsf{C R}^{\\gamma}(\\mathsf{A L G}_{\\star})\\leq\\frac{1+2\\gamma a+(1-\\gamma)^{2}a^{2}}{1+a}\\ .\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "The function above is minimized for $\\begin{array}{r}{a=\\sqrt{\\frac{3-\\gamma}{1-\\gamma}}-1}\\end{array}$ , which translates to ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathsf{C R}^{\\gamma}(\\mathsf{A L G})\\leq(1-\\gamma)^{3/2}(\\sqrt{3-\\gamma}-\\sqrt{1-\\gamma})+\\gamma\\;.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lower bound We still denote by $I=\\left(F_{1},\\ldots,F_{n}\\right)$ the input instance and $X_{i}\\sim F_{i}$ for all $i\\in[n]$ . Let ALG be the algorithm with single threshold $\\theta$ , then it is direct that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathsf{A L G}^{\\gamma}(I)=\\mathsf{A L G}^{0}(I)+\\gamma X^{*}\\mathbb{1}_{X^{*}<\\theta}\\;.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "We start by giving a lower bound on $\\mathbb{E}[\\mathsf{A L G}^{0}]$ . We use from Correa et al. [2021c] (Theorem 2.1) that for any $x<\\theta$ it holds that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathrm{Pr}(\\mathsf{A L G}^{0}(I)\\geq x)=\\mathrm{Pr}(\\mathsf{A L G}^{0}(I)\\geq\\theta)=\\mathrm{Pr}(X^{*}\\geq\\theta)=1-p\\;,\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "and for $x\\geq\\theta$ it holds that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(\\mathsf{A L G}^{0}(I)\\geq x)\\geq\\frac{1-p}{-\\log p}\\operatorname*{Pr}(X^{*}\\geq x)~,\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "from which we deduce that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}[\\mathsf{A L G}^{0}(I)]=\\int_{0}^{\\infty}\\operatorname*{Pr}(\\mathsf{A L G}^{0}(I)\\geq x)d x}\\\\ {\\displaystyle\\geq(1-p)\\theta+\\frac{1-p}{-\\log p}\\int_{\\theta}^{\\infty}\\operatorname*{Pr}(X^{*}\\geq x)d x\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "On the other hand, we obtain that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}<\\theta}]=\\displaystyle\\int_{0}^{\\infty}\\operatorname*{Pr}(X^{*}\\mathbb{1}_{X^{*}<\\theta}\\ge x)d x=\\displaystyle\\int_{0}^{\\infty}\\operatorname*{Pr}(x\\le X^{*}<\\theta)d x}\\\\ &{\\qquad\\qquad=\\displaystyle\\int_{0}^{\\theta}(\\operatorname*{Pr}(X^{*}>x)-\\operatorname*{Pr}(X^{*}\\ge\\theta))d x}\\\\ &{\\qquad\\qquad=\\displaystyle\\int_{0}^{\\theta}\\operatorname*{Pr}(X^{*}>x)d x-(1-p)\\theta\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Using (19), (20) and (21) we deduce that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb E[\\mathsf{A L G}^{\\dagger}(I)]\\geq(1-p)\\theta+\\displaystyle\\frac{1-p}{\\log p}\\int_{\\theta}^{\\infty}\\operatorname*{Pr}(X^{*}\\geq x)d x+\\displaystyle\\gamma\\int_{0}^{\\theta}\\operatorname*{Pr}(X^{*}\\geq x)d x-\\gamma(1-p)\\theta}\\\\ &{=(1-\\gamma)(1-p)\\theta+\\gamma\\int_{0}^{\\theta}\\operatorname*{Pr}(X^{*}\\geq x)d x+\\displaystyle\\frac{1-p}{-\\log p}\\int_{\\theta}^{\\infty}\\operatorname*{Pr}(X^{*}\\geq x)d x}\\\\ &{\\ge((1-\\gamma)(1-p)+\\gamma)\\int_{0}^{\\theta}\\operatorname*{Pr}(X^{*}\\geq x)d x+\\displaystyle\\frac{1-p}{-\\log p}\\int_{\\theta}^{\\infty}\\operatorname*{Pr}(X^{*}\\geq x)d x}\\\\ &{\\ge\\operatorname*{min}\\left\\{(1-\\gamma)(1-p)+\\gamma,\\,\\displaystyle\\frac{1-p}{-\\log p}\\right\\}\\left(\\int_{0}^{\\theta}\\operatorname*{Pr}(X^{*}\\geq x)d x+\\displaystyle\\int_{\\theta}^{\\infty}\\operatorname*{Pr}(X^{*}\\geq x)d x\\right)}\\\\ &{=\\operatorname*{min}\\left\\{1-(1-\\gamma)p,\\,\\displaystyle\\frac{1-p}{-\\log p}\\right\\}\\mathbb E[X^{*}]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Finally, choosing $p=p_{\\gamma}$ gives the result. ", "page_idx": 27}, {"type": "text", "text": "C.3.2 Proof of Corollary 4.4.1 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Proof. For $\\begin{array}{r}{p=\\frac{1/e}{1-(1-1/e)\\gamma}}\\end{array}$ , we have immediately that ", "page_idx": 27}, {"type": "equation", "text": "$$\n1-(1-\\gamma)p=1-\\frac{(1-\\gamma)/e}{1-(1-1/e)\\gamma}\\;,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "and $p\\in[1/e,1]$ for any $\\gamma\\in[0,1]$ . Since the function $x\\mapsto(1-x)/\\log(1/x)$ is concave, we can lower bound it on $[1/e,1]$ by $\\begin{array}{r}{x\\mapsto1-1/e+\\frac{x-1/e}{e-1}}\\end{array}$ , which is the line intersecting it in $1/e$ and 1. Therefore we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n{\\frac{1-p}{-\\log p}}\\geq1-1/e+{\\frac{p-1/e}{e-1}}=1-{\\frac{(1-\\gamma)/e}{1-(1-1/e)\\gamma}}\\;.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Finally, using the previous theorem, this choice of $p$ guarantees a competitive ratio of at least ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname*{min}\\left\\{1-(1-\\gamma)p\\,,\\,\\frac{1-p}{-\\log p}\\right\\}=1-\\frac{(1-\\gamma)/e}{1-(1-1/e)\\gamma}\\;.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "C.4 Proofs for the IID model ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Proof of Lemma 4.5 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Proof of Lemma 4.5. Let $F$ be the cumulative distribution function of $X_{1}$ , $a~>~0$ and ALG the algorithm with single threshold $\\theta$ such that $\\textstyle1-F(\\theta)={\\frac{a}{n}}$ . We denote $X^{*}=\\operatorname*{max}_{i\\in[n]}X_{i}$ . As in the previous proofs, we will begin by lower bounding $\\mathsf{A L G}^{0}(F,n)$ . For any $i\\in[n]$ , ALG stops at step $i$ if and only if $X_{i}>\\theta$ and all the previous items were rejected, i.e. $X_{j}\\leq\\theta$ for all $j<i$ . Thus we can write ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{0}(F,n)]=\\mathbb{E}\\Big[\\displaystyle\\sum_{i=1}^{n}(X_{i}\\mathbb{1}_{X_{i}>\\theta})\\mathbb{1}_{\\forall j<i:X_{j}\\le\\theta}\\Big]}\\\\ &{\\phantom{=}\\displaystyle\\sum_{i=1}^{n}F(\\theta)^{i-1}\\mathbb{E}[X_{i}\\mathbb{1}_{X_{i}>\\theta}]}\\\\ &{\\phantom{=\\displaystyle\\sum_{i=1}^{n}F(\\theta)^{n}}=\\frac{1-F(\\theta)^{n}}{1-F(\\theta)}\\mathbb{E}[X_{1}\\mathbb{1}_{X_{1}>\\theta}]}\\\\ &{\\phantom{=\\displaystyle\\sum_{i=1}^{n}\\frac{\\hat{F}[\\theta]^{n}}{1-F(\\theta)}\\times n\\mathbb{E}[X_{1}\\mathbb{1}_{X_{1}>\\theta}]\\;,}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the second equality is true by the independence of the random variables $(X_{i})_{i}$ . On the other hand, we can upper bound $\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>\\theta}]$ as follows ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>\\theta}]\\leq\\operatorname*{Pr}(X^{*}>\\theta)\\theta+\\mathbb{E}[(X^{*}-\\theta)_{+}]}\\\\ &{\\qquad\\qquad\\leq\\operatorname*{Pr}(X^{*}>\\theta)\\theta+\\mathbb{E}\\Big[\\displaystyle\\sum_{i=1}^{n}(X_{i}-\\theta)_{+}\\Big]}\\\\ &{\\qquad\\qquad=\\operatorname*{Pr}(X^{*}>\\theta)\\theta+n\\big(\\mathbb{E}[X_{1}\\mathbb{1}_{X_{1}>\\theta}]-\\operatorname*{Pr}(X_{1}>\\theta)\\theta\\big)}\\\\ &{\\qquad\\qquad=(1-F(\\theta)^{n}-a)\\theta+n\\mathbb{E}[X_{1}\\mathbb{1}_{X_{1}>\\theta}]\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Using the definition of $\\theta$ , the independence of $(X_{i})_{i}$ then Bernoulli\u2019s inequality we have that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(X^{*}>\\theta)=1-F(\\theta)^{n}=1-\\left(1-{\\frac{a}{n}}\\right)^{n}\\leq1-(1-n\\times{\\frac{a}{n}})=a\\;,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and observing that $\\begin{array}{r}{\\theta=\\frac{\\mathbb{E}[\\theta\\mathbb{1}_{X^{\\ast}\\leq\\theta}]}{F(\\theta)^{n}}\\geq\\frac{\\mathbb{E}[X^{\\ast}\\mathbb{1}_{X^{\\ast}\\leq\\theta}]}{F(\\theta)^{n}}}\\end{array}$ , we deduce that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}>\\theta}]\\leq-\\left(1-\\frac{1-a}{F(\\theta)^{n}}\\right)\\mathbb{E}[X^{*}\\mathbb{1}_{X^{*}\\leq\\theta}]+n\\mathbb{E}[X_{1}\\mathbb{1}_{X_{1}>\\theta}]\\;.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "by substituting into (22), we obtain ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{A L G}^{0}(F,n)]\\ge\\frac{1-F(\\theta)^{n}}{a}\\left(\\mathbb{E}[X^{\\ast}\\mathbb{1}_{X^{\\ast}>\\theta}]+\\left(1-\\frac{1-a}{F(\\theta)^{n}}\\right)\\mathbb{E}[X^{\\ast}\\mathbb{1}_{X^{\\ast}\\le\\theta}]\\right)~.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Finally, the reward in the $\\gamma$ -prophet inequality is ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[{\\mathbb{A}}{\\mathbb{L}}\\mathbb{G}^{\\gamma}(F,n)]=\\mathbb{E}[{\\mathbb{A}}{\\mathbb{L}}\\mathbb{G}^{0}(F,n)]+\\gamma\\mathbb{E}[X^{*}{\\mathbb{1}}_{X^{*}<\\theta}]}\\\\ &{\\phantom{\\mathbb{E}}\\ge\\frac{1-F(\\theta)^{n}}{a}\\mathbb{E}[X^{*}{\\mathbb{1}}_{X^{*}>\\theta}]+\\left(\\frac{1-F(\\theta)^{n}}{a}\\left(1-\\frac{1-a}{F(\\theta)^{n}}\\right)+\\gamma\\right)\\mathbb{E}[X^{*}{\\mathbb{1}}_{X^{*}<\\theta}]}\\\\ &{\\phantom{\\mathbb{E}}\\ge\\operatorname*{min}\\left\\{\\frac{1-F(\\theta)^{n}}{a},\\frac{1-F(\\theta)^{n}}{a}\\left(1-\\frac{1-a}{F(\\theta)^{n}}\\right)+\\gamma\\right\\}\\mathbb{E}[X^{*}]\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The equation $\\begin{array}{r}{\\frac{1-F(\\theta)^{n}}{a}=\\frac{1-F(\\theta)^{n}}{a}\\left(1-\\frac{1-a}{F(\\theta)^{n}}\\right)+\\gamma.}\\end{array}$ , is equivalent to ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left(\\frac{1}{(1-a/n)^{n}}-1\\right)\\left(\\frac{1}{a}-1\\right)=\\gamma\\ ,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "and for any $n\\geq2$ the function $\\begin{array}{r}{a\\mapsto\\left(\\frac{1}{(1-a/n)^{n}}-1\\right)\\left(\\frac{1}{a}-1\\right)}\\end{array}$ is decreasing on $(0,1]$ and goes from 1 to 0, thus Equation (23) admits a unique solution $a_{n,\\gamma}$ , and taking $a=a_{n,\\gamma}$ guarantees a reward of $\\begin{array}{r}{\\frac{1-F(\\theta)^{n}}{a_{n,\\gamma}}\\mathbb{E}[X^{*}]=\\frac{1-(1-\\frac{a_{n,\\gamma}}{n})^{n}}{a_{n,\\gamma}}\\mathbb{E}[X^{*}].}\\end{array}$ . \u53e3 ", "page_idx": 28}, {"type": "text", "text": "Proof of Theorem 4.6 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proof. We first prove the upper bound, and then we give the single-threshold algorithm satisfying the lower bound. ", "page_idx": 28}, {"type": "text", "text": "Upper bound We consider an instance similar to the one used in the proof of Theorem 4.4. Let $a,x>0$ , and let $X_{1},\\ldots,X_{n}$ be IID random variables with the following the distribution $F$ defined by ", "page_idx": 28}, {"type": "equation", "text": "$$\nX_{1}\\sim\\left\\{\\begin{array}{l l}{{n}}&{{\\mathrm{w.p.~}\\frac{1}{n^{2}}}}\\\\ {{a}}&{{\\mathrm{w.p.~}\\frac{x}{n}}}\\\\ {{0}}&{{\\mathrm{w.p.~}1-\\frac{x}{n}-\\frac{1}{n^{2}}}}\\end{array}\\right.~.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "A reasonable algorithm would always reject the value 0 and accept the value $n$ . However, if the algorithm faces an item with value $a$ , it must decide to either accept it, or reject it with a guarantee of recovering $\\gamma a$ at the end. By analyzing the dynamic programming algorithm $\\mathsf{A L G}_{\\star}$ , we find that the optimal decision is to reject $a$ if observed before a certain step $j$ , and accept it otherwise. Let us denote $\\tau$ the stopping time of $\\mathsf{A L G}_{\\star}$ . By convention, we write $\\tau=n+1$ to say that no value was selected by the algorithm, in which case the reward is $\\gamma\\operatorname*{max}_{i\\in[n]}X_{i}$ . ", "page_idx": 28}, {"type": "text", "text": "If $\\tau\\le j-1$ then necessarily $X_{\\tau}=n$ , because $\\mathsf{A L G}_{\\star}$ rejects the value $a$ if it is met before step $j$ , and if $\\tau=n+1$ then $\\operatorname*{max}_{i\\in[n]}X_{i}\\in\\{0,a\\}$ , because otherwise the algorithm would have selected the value $n$ and stopped earlier. It follows that the expected output of $\\mathsf{A L G}_{\\star}$ on this instance is ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}[\\mathsf{A L G}_{\\star}^{\\gamma}(F,n)]=\\!n\\operatorname*{Pr}(\\tau<j)+\\sum_{i=j}^{n}\\mathbb{E}[X_{i}\\mid\\tau=i]\\operatorname*{Pr}(\\tau=i)}}\\\\ &{\\quad\\quad\\quad\\quad\\quad+\\,\\gamma a\\operatorname*{Pr}(\\tau=n+1,\\displaystyle\\operatorname*{max}_{i\\in[n]}X_{i}=a)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Let us now compute the terms above one by one. ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}(\\tau<j)=\\operatorname*{Pr}(\\exists i\\in[j-1]:X_{i}=n)=1-\\left(1-{\\frac{1}{n^{2}}}\\right)^{j-1}\\leq{\\frac{j}{n^{2}}}\\;,\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where we used Bernoulli\u2019s inequality $\\begin{array}{r}{(1-1/n^{2})^{j-1}\\geq1-\\frac{j-1}{n^{2}}>1-\\frac{j}{n^{2}}}\\end{array}$ . For $i\\,\\in\\,\\{j,\\dots,n\\}$ , $\\mathsf{A L G}_{\\star}$ stops at $i$ if $X_{i}\\in\\{a,n\\}$ and if it has not stopped before, i.e. $X_{k}\\in\\dot{\\{0,a\\}}$ for all $k<j$ and $X_{k}=0$ for all $k\\in\\{j,\\ldots,i-1\\}$ , hence ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(\\tau=i)=\\operatorname*{Pr}(\\forall k<j:X_{k}\\neq n\\mathrm{~and~}\\forall j\\leq k\\leq i-1:X_{k}:}\\\\ &{\\quad\\quad\\quad=\\left(1-\\displaystyle\\frac{1}{n^{2}}\\right)^{j-1}\\left(1-\\displaystyle\\frac{x}{n}-\\displaystyle\\frac{1}{n^{2}}\\right)^{i-j}\\operatorname*{Pr}(X_{i}\\neq0)}\\\\ &{\\quad\\quad\\quad\\leq\\left(1-\\displaystyle\\frac{x}{n}\\right)^{i-j}\\operatorname*{Pr}(X_{i}\\neq0)~,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "the second equality is true by independence, and the last inequality holds because $\\textstyle1-{\\frac{1}{n^{2}}}\\leq1$ and $\\textstyle1-{\\frac{x}{n}}-{\\frac{1}{n^{2}}}\\leq1-{\\frac{x}{n}}$ . By independence of the variables $(X_{k})_{k}$ , we also have that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{E}[X_{i}\\mid\\tau=i]=\\mathbb{E}[X_{i}\\mid X_{i}\\neq0]={\\frac{\\mathbb{E}[X_{i}]}{\\operatorname*{Pr}(X_{i}\\neq0)}}={\\frac{1+a x}{n\\operatorname*{Pr}(X_{i}\\neq0)}}\\ .\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Finally, the event $(\\tau=n+1,\\operatorname*{max}_{i\\in[n]}X_{i}=a)$ is equivalent $(\\operatorname*{max}_{i\\in[j-1]}X_{i}=a,\\forall k\\geq j:X_{k}=$ 0). In fact, the algorithm does not stop before $n+1$ if and only if $X_{k}\\neq n$ for all $k<j$ and $X_{k}=0$ for all $j\\le k\\le n$ , and under these conditions, it holds that $\\begin{array}{r}{\\operatorname*{max}_{i\\in[n]}X_{i}=\\operatorname*{max}_{i\\in[j-1]}X_{i}.}\\end{array}$ . Therefore ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}(\\tau=n+1,\\underset{i\\in[n]}{\\operatorname*{max}}X_{i}=a)=\\operatorname*{Pr}(\\underset{i\\in[j-1]}{\\operatorname*{max}}X_{i}=a,\\forall k\\geq j:X_{k}=0)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\operatorname*{Pr}(\\underset{i\\in[j-1]}{\\operatorname*{max}}X_{i}\\neq0)\\operatorname*{Pr}(\\forall k\\geq j:X_{k}=0)}\\\\ &{\\qquad\\qquad\\qquad=\\left(1-\\left(1-\\cfrac{x}{n}-\\cfrac{1}{n^{2}}\\right)^{j-1}\\right)\\left(1-\\cfrac{x}{n}-\\cfrac{1}{n^{2}}\\right)^{n-j}}\\\\ &{\\qquad\\qquad\\qquad=\\left(1-e^{-\\frac{x j}{n}}+o(1)\\right)\\left(e^{-x+\\frac{x j}{n}}+o(1)\\right)}\\\\ &{\\qquad\\qquad\\qquad=\\left(e^{\\frac{x j}{n}}-1\\right)e^{-x}+o(1)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "All in all, we obtain by substituting into 24 that ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\mathbb{A}\\mathbb{G}_{*}^{\\top}(F,n)]\\leq\\frac{j}{n}+\\left(\\frac{1+\\alpha x}{n}\\right)\\displaystyle\\sum_{i=j}^{n}\\left(1-\\frac{x}{n}\\right)^{i-j}+\\gamma a e^{-x}\\big(e^{\\frac{x i}{n}}-1\\big)+\\sigma(1)}\\\\ {=\\frac{j}{n}+\\left(\\frac{1+\\alpha x}{n}\\right)\\displaystyle\\frac{1-(1-x/n)^{n-j+1}}{x/n}+\\gamma a e^{-x}\\big(e^{\\frac{x i}{n}}-1\\big)+\\sigma(1)}\\\\ {=\\frac{j}{n}+\\left(\\frac{1}{x}+a\\right)\\left(1-e^{-x+\\frac{n i}{n}}+o(1)\\right)+\\gamma a e^{-x}\\big(e^{\\frac{x i}{n}}-1\\big)+\\sigma(1)}\\\\ {=\\frac{j}{n}-\\left[\\big(\\frac{1}{x}+(1-\\gamma)a\\big)\\right]e^{\\frac{x i}{n}}+\\frac{1}{x}+a-\\gamma a e^{-x}+o(1)}\\\\ {\\leq\\operatorname*{max}\\bigg\\{s-\\left[(\\frac{1}{x}+(1-\\gamma)a)\\right]e^{\\frac{x i}{n}}\\bigg\\}+\\frac{1}{x}+(1-\\gamma e^{-x})a+o(1)}\\\\ {=-\\frac{1}{x}\\big(\\log(1+(1-\\gamma)a x)+1-x\\big)+\\frac{1}{x}+(1-\\gamma e^{-x})a+o(1)}\\\\ {=-\\frac{1}{x}\\log(1+(1-\\gamma)a x)+1+(1-\\gamma e^{-x})a+o(1)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "On the other hand, we have that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{i\\in[n]}X_{i}=n)=1-\\left(1-\\frac{1}{n^{2}}\\right)^{n}=\\frac{1}{n}+o(1/n)\\;,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{i\\in[n]}X_{i}=0)=\\left(1-\\frac{x}{n}-\\frac{1}{n^{2}}\\right)=e^{-x}+o(1)\\;,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}_{i\\in[n]}X_{i}=a)=1-\\operatorname*{Pr}_{i\\in[n]}X_{i}=0)-\\operatorname*{Pr}_{i\\in[n]}X_{i}=n)=1-e^{-x}+o(1)\\;,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "therefore, the expected maximum value is ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\underset{i\\in[n]}{\\operatorname*{max}}\\,X_{i}]=n\\operatorname*{Pr}(\\underset{i\\in[n]}{\\operatorname*{max}}\\,X_{i}=n)+a\\operatorname*{Pr}(\\underset{i\\in[n]}{\\operatorname*{max}}\\,X_{i}=a)}\\\\ &{\\qquad\\qquad\\qquad=1+\\big(1-e^{-x}\\big)a+o(1)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We deduce that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\frac{\\mathbb{E}[\\mathsf{A L G}_{\\star}^{\\gamma}(F,n)]}{\\mathbb{E}[\\operatorname*{max}_{i\\in[n]}X_{i}]}\\leq\\frac{-\\frac{1}{x}\\log(1+(1-\\gamma)a x)+1+(1-\\gamma e^{-x})a}{1+\\big(1-e^{-x}\\big)a}+o(1)}\\\\ {=1-\\frac{\\frac{1}{x}\\log(1+(1-\\gamma)a x)-(1-\\gamma)a e^{-x}}{1+\\big(1-e^{-x}\\big)a}+o(1)\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Consequently, for any $a,x>0$ and for any algorithm ALG we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathsf{C R}(\\mathsf{A L G})\\le\\mathsf{C R}(\\mathsf{A L G}_{\\star})}}\\\\ &{\\qquad\\le\\operatorname*{lim}_{n\\to\\infty}\\frac{\\mathbb{E}[\\mathsf{A L G}_{\\star}^{\\gamma}(F,n)]}{\\mathbb{E}[\\operatorname*{max}_{i\\in[n]}X_{i}]}}\\\\ &{\\le1-\\frac{\\log(1+(1-\\gamma)a x)-(1-\\gamma)a x e^{-x}}{x+(1-e^{-x})a x}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "In particular, for $x=2$ and $\\begin{array}{r}{a=\\frac{1-\\gamma/2}{1-\\gamma}}\\end{array}$ we find that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\textsf{C R}(\\mathsf{A L G})\\leq1-\\frac{\\log(3-\\gamma)-\\left(2-\\gamma\\right)e^{-2}}{2+\\frac{2-\\gamma}{1-\\gamma}(1-e^{-2})}}\\\\ {=1-(1-\\gamma)\\frac{e^{2}\\log(3-\\gamma)-\\left(2-\\gamma\\right)}{2\\left(2e^{2}-1\\right)-\\gamma(3e^{2}-1)}}\\\\ {=U(\\gamma)\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "This proves the upper bound stated in the theorem, and we can verify that it is increasing, and satisfies $\\begin{array}{r}{U(0)\\ =\\frac{4-\\log3}{4-2/e^{2}}\\,\\bar{U}(1)=1}\\end{array}$ ", "page_idx": 30}, {"type": "text", "text": "Lower bound on the competitive ratio We will prove that the algorithm presented in Lemma 4.5 has a competitive ratio of at least $(1-(1-\\gamma)p_{\\gamma})$ , where $p_{\\gamma}$ , first introduced in Theorem 4.4, is the unique solution of the equation (1\u2212(1\u2212\u03b3)p) =\u22121l\u2212ogp p , which is equivalent to $\\begin{array}{r l}{\\left(\\frac{1}{p}\\!-\\!1\\right)\\left(\\frac{1}{\\log\\left(1/p\\right)}\\!-\\!1\\right)=}&{{}}\\end{array}$ $\\gamma$ . ", "page_idx": 30}, {"type": "text", "text": "Let $a_{\\gamma}=-\\log(p_{\\gamma})$ . It follows from the definition of $p_{\\gamma}$ that $a_{\\gamma}$ is the unique solution of the equation $\\begin{array}{r}{(e^{a}-1)(\\frac{1}{a}-1)=\\gamma}\\end{array}$ . For any $n\\geq2$ and $x\\geq0$ we have that $(1-x/n)^{n}\\leq e^{-x}$ , hence, by definition of $a_{n,\\gamma}$ and $a_{\\gamma}$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\left(\\frac{1}{e^{-a_{n,\\gamma}}}-1\\right)\\left(\\frac{1}{a_{n,\\gamma}}-1\\right)\\le\\left(\\frac{1}{(1-\\frac{a_{n,\\gamma}}{n})^{n}}-1\\right)\\left(\\frac{1}{a_{n,\\gamma}}-1\\right)}}\\\\ &{}&{=\\gamma}\\\\ &{}&{=\\left(\\frac{1}{e^{-a_{\\gamma}}}-1\\right)\\left(\\frac{1}{a_{\\gamma}}-1\\right)\\ .}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Moreover, the function $x\\mapsto(e^{x}-1)(1/x-1)$ is decreasing on $(0,1)$ . In fact its derivative at any point $x\\in(0,1)$ is ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d}{d x}\\left[\\left(\\frac{1}{e^{-x}}-1\\right)\\left(\\frac{1}{x}-1\\right)\\right]=\\left(\\frac{1}{x}-1\\right)e^{x}-\\frac{e^{x}-1}{x^{2}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\frac{1}{x^{2}}\\left(1-x^{2}-(1-x)e^{x}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\frac{1-x}{x^{2}}(1+x-e^{x})<0\\;.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Idte fdoullcoe wths aftrom (25) that $a_{\\gamma}\\leq a_{n,\\gamma}$ . Finally, given that $x\\mapsto{\\frac{1-e^{-x}}{x}}$ is non-increasing on $(0,1]$ , we ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\frac{1-(1-\\frac{a_{n,\\gamma}}{n})^{n}}{a_{n,\\gamma}}\\geq\\frac{1-e^{-a_{n,\\gamma}}}{a_{n,\\gamma}}\\geq\\frac{1-e^{-a_{\\gamma}}}{a_{\\gamma}}\\;.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We deduce that the competitive ratio of the algorithm described in Theorem 4.6 is at least $\\begin{array}{r}{\\frac{1-e^{-a_{\\gamma}}}{a_{\\gamma}}=}\\end{array}$ $\\begin{array}{r}{\\frac{1-p_{\\gamma}}{\\log(1/p_{\\gamma})}=1-(1-\\gamma)p_{\\gamma}.}\\end{array}$ ", "page_idx": 31}, {"type": "text", "text": "D Random decay functions ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "While we only studied deterministic decay functions in the paper, it is also possible to have scenarios with random decay functions. Consider for example that rejected items remain available after $j$ steps with a probability $p_{j}$ , this is modeled by $D_{j}(x)=\\xi_{j}x$ with $\\xi_{j}$ a Bernoulli random variable with parameter $p_{j}$ . We explain in this section how the definitions and our results extend to this case. ", "page_idx": 31}, {"type": "text", "text": "Definition D.1 (Random process). Let $\\mathcal{X}$ is a non-empty set. $A$ random process o $\\mathcal{X}$ is a collection of random variables $\\{Z_{x}\\}_{x\\in\\mathcal{X}}$ . Two random processes $\\mathcal{Z}=\\{Z_{x}\\}_{x\\in\\mathcal{X}}$ and $\\mathcal{Z}^{\\prime}=\\{Z_{x}^{\\prime}\\}_{x\\in\\mathcal{X}^{\\prime}}$ are independent if any finite sub-process of $\\mathcal{Z}$ is independent of any sub-process of ${\\mathcal{Z}}^{\\prime}$ . For simplicity, let us say that the random processes {Zx1}x\u2208X 1, . . . , $\\{Z_{x}^{\\mathrm{i}}\\}_{x\\in\\mathcal{X}^{1}},\\dots,\\{Z_{x}^{m}\\}_{x\\in\\mathcal{X}^{m}}$ are mutually independent if, for any $x_{1}\\in\\mathcal{X}_{1},\\ldots,x_{m}\\in\\mathcal{X}_{m},$ , the random variables $Z_{x_{1}}^{1},\\ldots,Z_{x_{m}}^{m}$ are mutually independent. ", "page_idx": 31}, {"type": "text", "text": "Definition D.2 (Random decay functions). Let $\\cal{D}\\;=\\;(D_{1},D_{2},..\\;.)$ be a sequence of mutually independent random processes. We say that $\\mathcal{D}$ is a sequence of random decay functions $i f$ ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathrm{Pr}(D_{j}(x)\\notin[0,x])=0\\,f o r\\,a n y\\,x\\geq0\\,a n d\\,j\\geq1,\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The second condition asserts that the random variable $D_{j-1}(x)$ has first-order stochastic dominance over $D_{j}(x)$ . Along with the first condition, reflect that the distributions of the rejected values become progressively smaller. The last condition indicates that for any integer $j\\geq1$ and non-negative real numbers $x<y$ , $D_{j}(y)$ has a first-order stochastic dominance over $D_{j}(x)$ , which means that, as the value of $x$ increases, so does the potential recovered value after $j$ steps. ", "page_idx": 31}, {"type": "text", "text": "The decision-maker In the $\\mathcal{D}$ -prophet inequality with deterministic decay functions, we assumed that the decision-maker has full knowledge of the functions $D_{1},D_{2}\\ldots$ In the randomized setting, we assume instead that the decision-maker knows the distributions of the decay functions, i.e. knows the distribution of the random variables $D_{j}(x)$ for all $x\\,\\geq\\,0$ and $j\\geq1$ . However, they do not observe their values until they decide to stop. The online selection process is therefore as follows: the algorithm knows beforehand the distributions of the decay functions, then at each step, it observes a new item with value $X_{i}$ , and decides to stop or continue. Once they decide to stop at some time $\\tau$ , they observe the values $D_{1}(X_{\\tau-1}),\\ldots,D_{\\tau}(X_{1})$ and then they choose the maximal one. As a consequence, the stopping time $\\tau$ is independent of the randomness induced by the decay functions. As in the deterministic case, the expected reward of any algorithm ALG can be written as ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\mathsf{A L G}^{\\mathbb{D}}(X_{1},\\ldots,X_{n})]=\\mathbb{E}[\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{D_{i}(X_{\\tau-i})\\}]\\;.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "The limit decay A key result in our paper is the reduction of the problem to the case where all the decay functions are identical, and we prove this reduction by considering the pointwise limit of the decay functions. In the case of random decay functions, instead of the pointwise convergence, it holds for all $x\\geq0$ that the random variables $(D_{j}(x))_{j}$ converge in distribution to some random variable $D_{\\infty}(x)$ . In fact, for any $x\\ge0$ and $a\\geq0$ , the sequence $(\\operatorname*{Pr}(D_{j}(x)\\geq a))_{j\\geq1}$ is non-increasing and non-negative, thus it converges to some constant $G(x,a)$ . Given that $x\\leftrightarrow\\operatorname*{Pr}(D_{j}(x)\\geq a)$ is non-decreasing for any $j$ , we obtain by taking the limit $j\\rightarrow\\infty$ that $x\\mapsto G(x,a)$ is non-increasing, and with similar argument we obtain, for any $x\\geq0$ , that $G(x,a)=1$ for all $a\\leq0$ and $G(x,a)=0$ for all $a>x$ . Therefore, $a\\mapsto1-G(x,a)$ defined the cumulative distribution of a random variable $D_{\\infty}$ such that ", "page_idx": 32}, {"type": "text", "text": "Therefore, for all $x~\\ge~0$ , $D_{\\infty}(x)$ is the limit in distribution of $(D_{j}(x))_{j}$ , hence a sequence ${\\cal D}^{\\prime}\\,=\\,({\\cal D}_{1}^{\\prime},{\\cal D}_{2}^{\\prime},\\ldots)$ of mutually independent random processes such that $\\tilde{D}_{j}^{\\prime}(x)\\,\\sim\\,D_{\\infty}(\\bar{x})$ for any $j~\\geq~1$ and $x~\\ge~0$ defines a sequence of decay functions. We say in this case that all the decay functions are identically distributed as $D_{\\infty}$ . Moreover, it holds for all $x~\\ge~0$ that $\\begin{array}{r}{\\mathbb{E}[D_{\\infty}(\\bar{x_{}})]=\\operatorname*{lim}_{j\\rightarrow\\infty}\\mathbb{E}[D_{j}(x)]=\\operatorname*{inf}_{j\\geq1}\\mathbb{E}[D_{j}(x)]}\\end{array}$ ", "page_idx": 32}, {"type": "text", "text": "From there, all the proofs of Section 2 can be easily generalized to the case of random decay functions, and it follows that we can restrict ourselves to studying identically distributed decay functions. Moreover, Proposition 3.2 can be generalized to the case of random decay functions, and the necessary condition for surpassing $1/2$ becomes 0E[D\u221ex(x)]> 0. Similarly, using that the stopping time $\\tau$ of the algorithm is independent of randomness induced by $D_{\\infty}$ , Proposition 3.3 remains true with $\\gamma=\\operatorname*{inf}_{x>0}\\frac{\\mathbb{E}[D_{\\infty}(x)]}{x}$ . ", "page_idx": 32}, {"type": "text", "text": "Lower bounds For establishing lower bounds, observe that, for any random decay functions $\\mathcal{D}$ , if we denote $H_{j}(x)=\\mathbb{E}[D_{j}(x)]$ for all $x$ , then $\\mathcal{H}=(H_{1},H_{2},\\ldots)$ defines a sequence of deterministic decay functions. Furthermore, for any instance $X_{1},\\ldots,X_{n}$ and any algorithm ALG, it holds that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\mathsf{A L G}^{D}(X_{1},\\ldots,X_{n})]=\\mathbb{E}[\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{D_{i}(X_{\\tau-i})\\}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}\\Big[\\mathbb{E}[\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{D_{i}(X_{\\tau-i})\\}\\mid\\tau,X_{1},\\ldots,X_{n}]\\Big]}\\\\ &{\\qquad\\quad\\ge\\mathbb{E}\\Big[\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{\\mathbb{E}[D_{i}(X_{\\tau-i})\\mid\\tau,X_{1},\\ldots,X_{n}]\\}\\Big]}\\\\ &{\\qquad\\quad=\\mathbb{E}\\Big[\\operatorname*{max}_{0\\leq i\\leq\\tau-1}\\{H_{i}(X_{\\tau-i})\\}\\Big]}\\\\ &{\\qquad\\quad=\\mathbb{E}[\\mathsf{A L G}^{\\mathcal{H}}(X_{1},\\ldots,X_{n})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "It follows that lower bounds established for deterministic decay functions can be extended to random decay functions by considering their expectations. ", "page_idx": 32}, {"type": "text", "text": "Implications With the previous observations, both the lower and upper bounds, depending on $\\gamma_{\\mathscr{D}}$ that we proved in the deterministic $\\mathcal{D}$ -prophet inequality can be generalized to the random $\\mathcal{D}$ -prophet inequality, by taking ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\gamma_{\\mathscr{D}}=\\operatorname*{inf}_{x>0}\\operatorname*{inf}_{j\\geq1}\\frac{\\mathbb{E}[D_{j}(x)]}{x}~.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: In the introduction, present the problem, and state the main contributions of the paper. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 33}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: The limitations are discussed in the conclusion. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 33}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: All the assumptions are clearly stated, and full proofs are in the appendix. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 34}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: No experimental results. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 34}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: No experimental results. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 35}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: No experiments. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 35}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: No experiments. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 36}, {"type": "text", "text": "Answer:[NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: No experiments. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 36}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: We have reviewed the Code of Ethics, and the paper conforms to it. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 36}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The contribution of the paper is theoretical. We do not feel there is major societal impact that needs to be discussed. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: The contribution of the paper is mainly theoretical. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 37}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: We do not use any assets. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 37}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 38}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not provide any new assets. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 38}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: No such experiments are included in the paper. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 38}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: No such studies are included in the paper. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 38}]