[{"figure_path": "xL7Ve14AHA/tables/tables_5_1.jpg", "caption": "Table 1: Weighted group sparsity and validation accuracy of different subproblem stopping criteria.", "description": "This table presents the weighted group sparsity and validation accuracy achieved by different algorithms (ProxGen and RAMDA) using two different subproblem stopping criteria: no early stopping and early stopping. The results are shown for two different models (VGG19 and ResNet50) and two different datasets (CIFAR10 and CIFAR100).  The table demonstrates the impact of the subproblem solver's stopping criterion on the final model's performance in terms of accuracy and sparsity.", "section": "6 Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_7_1.jpg", "caption": "Table 1: Weighted group sparsity and validation accuracy of different subproblem stopping criteria.", "description": "This table presents the weighted group sparsity and validation accuracy achieved by ProxGen and RAMDA on CIFAR10 and CIFAR100 datasets under two different subproblem stopping criteria: no early stopping and early stopping.  The results show the impact of the early stopping criterion on both the model's performance and sparsity level.", "section": "Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_8_1.jpg", "caption": "Table 2: Weighted group sparsity, validation accuracy and time/epoch of ProxSSI and ProxGen for CIFAR10/CIFAR100. We report the average time/epoch using one NVIDIA V100 GPU.", "description": "This table compares the performance of ProxSSI and ProxGen on CIFAR10 and CIFAR100 datasets in terms of weighted group sparsity, validation accuracy, and training time per epoch.  It highlights the significant difference in training time between the two algorithms, with ProxGen being substantially faster.", "section": "Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_8_2.jpg", "caption": "Table 3: Weighted group sparsity and validation accuracy on ImageNet/ResNet50.", "description": "This table presents the results of experiments conducted on the ImageNet dataset using the ResNet50 model.  It compares the performance of several algorithms, including MSGD, ProxSGD, ProxGen, RMDA, and RAMDA, in terms of both weighted group sparsity (a measure of the model's structure) and validation accuracy. RAMDA achieves the highest validation accuracy and the highest weighted group sparsity among all algorithms compared.", "section": "6 Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_8_3.jpg", "caption": "Table 4: Weighted group sparsity and validation perplexity on Transformer-XL with WikiText-103.", "description": "This table presents the results of training a Transformer-XL language model on the WikiText-103 dataset using different optimization algorithms.  The algorithms are compared based on their validation perplexity (a measure of how well the model predicts the next word in a sequence), the level of weighted group sparsity achieved (a measure of the model's structure), and the training time per epoch.  The table shows that RAMDA achieves the lowest perplexity and highest sparsity, suggesting that it is a more efficient and effective method for training structured neural networks for language modeling.", "section": "6 Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_9_1.jpg", "caption": "Table 5: Weighted group sparsity and validation loss on Tacotron2 with LJSpeech.", "description": "This table presents the results of training the Tacotron2 model for speech synthesis on the LJSpeech dataset using different optimization algorithms.  The algorithms compared include AdamW (a baseline without structured sparsity), ProxSGD, ProxGen, RMDA, and RAMDA.  The table shows the validation loss achieved by each algorithm, along with the weighted group sparsity level and the training time per epoch.  The key metric is validation loss, with lower values indicating better performance.  The sparsity metric indicates the degree of structured sparsity achieved in the trained model.", "section": "6 Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_13_1.jpg", "caption": "Table 6: Algorithms used in the experiments.", "description": "This table summarizes the algorithms used in the paper's experiments, comparing them based on their unregularized counterpart and the method used to solve their subproblems.  It shows that RAMDA leverages MADGRAD for its unregularized counterpart and uses a proximal gradient (PG) method for its subproblem.  Other methods such as RMDA, ProxSGD, ProxGen, and ProxSSI are also presented with their respective unregularized counterparts and subproblem solvers.", "section": "A.2 Details of the Algorithms Compared"}, {"figure_path": "xL7Ve14AHA/tables/tables_20_1.jpg", "caption": "Table 7: Group sparsity and validation accuracy of different methods on image classification with smaller datasets.", "description": "This table presents the results of comparing various algorithms (ProxSGD, ProxSSI, ProxGen, RMDA, and RAMDA) on image classification tasks using smaller datasets (MNIST, CIFAR10, CIFAR100).  The algorithms are evaluated based on their validation accuracy and the level of group sparsity achieved.  This allows for a comparison of the algorithms' performance on both prediction accuracy and the ability to induce a desired structure in the model.", "section": "Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_24_1.jpg", "caption": "Table 8: Low-rank level and validation accuracy of different methods on training a six-layer fully-connected neural network with the FashionMNIST dataset for image classification.", "description": "This table presents the results of an experiment comparing several algorithms on a six-layer fully connected neural network trained on the FashionMNIST dataset. The algorithms compared are MSGD, ProxSGD, ProxGen, RMDA, and RAMDA.  The table shows the validation accuracy and low-rank level achieved by each algorithm. The low-rank level is a measure of the extent to which each algorithm produces a low-rank model, which is a type of structured sparsity.", "section": "6 Experiments"}, {"figure_path": "xL7Ve14AHA/tables/tables_24_2.jpg", "caption": "Table 9: Low-rank level and validation loss of different methods on pretraining a modified vision transformer model using the CIFAR10 dataset for masked image modeling.", "description": "This table presents the results of experiments comparing different optimization algorithms on a masked image modeling task using a modified vision transformer and the CIFAR10 dataset.  The algorithms compared include AdamW (a baseline without regularization), ProxSGD, ProxGen, RMDA, and the proposed RAMDA. The table shows the validation loss and the achieved low-rank level for each algorithm, demonstrating the effectiveness of RAMDA in achieving a low-rank structure while maintaining competitive prediction performance.", "section": "6 Experiments"}]