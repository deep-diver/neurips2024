{"references": [{"fullname_first_author": "Pieter Abbeel", "paper_title": "Apprenticeship learning via inverse reinforcement learning", "publication_date": "2004-01-01", "reason": "This paper is foundational to the field of adversarial imitation learning (AIL), introducing the concept of learning from expert demonstrations to infer optimal policies."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Generative adversarial imitation learning", "publication_date": "2016-01-01", "reason": "This paper introduced Generative Adversarial Imitation Learning (GAIL), a highly influential and widely used method in AIL that leverages adversarial training to improve policy learning."}, {"fullname_first_author": "Divyansh Garg", "paper_title": "IQ-Learn: Inverse soft-q learning for imitation", "publication_date": "2021-01-01", "reason": "This paper proposed Inverse Soft-Q Learning (IQL), a state-of-the-art deep AIL method that demonstrates competitive empirical performance on various challenging tasks."}, {"fullname_first_author": "Zhihan Liu", "paper_title": "Provably efficient generative adversarial imitation learning for online and offline setting with linear function approximation", "publication_date": "2021-01-01", "reason": "This paper provides theoretical guarantees for AIL with linear function approximation, bridging the gap between theoretical analysis and practical applications of AIL."}, {"fullname_first_author": "Tian Xu", "paper_title": "Provably efficient adversarial imitation learning with unknown transitions", "publication_date": "2023-01-01", "reason": "This paper presents a provably efficient AIL algorithm for general function approximation in online settings, addressing a significant limitation in prior theoretical studies of AIL."}]}