[{"figure_path": "Yhd0yzC8yD/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison between Knowledge Distillation (KD) (left) and our method (right). KD requires N times of training with the teacher model on data to produce N different scale models for N clients. In contrast, our method requires only a single training to decompose the teacher model into different learngenes that can be economically and flexibly recomposed into models with diverse layers to meet different client needs.", "description": "This figure compares the knowledge distillation (KD) approach with the proposed method for creating diverse-scale models. KD requires multiple training sessions with a teacher model to produce different-sized models for various clients.  The new method only requires single training session to decompose a teacher model into learngenes (basic components). These learngenes can be recombined flexibly to generate models with different numbers of layers, accommodating various computational resource limitations.", "section": "1 Introduction"}, {"figure_path": "Yhd0yzC8yD/figures/figures_1_2.jpg", "caption": "Figure 2: After using PCA to reduce the dimension of the parameters of a well-trained ViT, we find that the parameters of the most layers have an approximately linear correlation with their layer position. More details are given in the supplementary material.", "description": "This figure shows the results of applying Principal Component Analysis (PCA) to reduce the dimensionality of the parameters in each layer of a well-trained Vision Transformer (ViT) model.  The resulting plot demonstrates that there's an approximately linear relationship between the parameters' values and the layer's position within the network's architecture.  This observation is discussed further in the supplementary materials of the paper, providing more context and detail regarding the PCA process and its implications for the proposed decomposition and recomposition strategy of the ViT model.", "section": "1 Introduction"}, {"figure_path": "Yhd0yzC8yD/figures/figures_4_1.jpg", "caption": "Figure 3: Decomposition and Recomposition. The upper part illustrates the decomposition process, where a ViT model is gradually recomposed into several learngenes. At each stage, only the newly added learngenes are trained, while the previously trained learngenes remain frozen. The lower part shows the recomposition process with two examples. The first initializes a 2-layer ViT with three learngenes trained by \u201cwithout constraints\u201d, while the second initializes a 3-layer ViT with four learngenes trained by \u201cwith constraints\u201d. Note that the flame icons indicate that the parameters of the layer are trained, while the snowflake icons indicates that the parameters are frozen.", "description": "This figure illustrates the two-stage process of linearly decomposing a Vision Transformer (ViT) into learngenes and then recomposing them into ViTs with different depths. The decomposition process is shown in the upper part, while the recomposition process is shown in the lower part. Different training strategies are used for the recomposed ViTs, either with or without constraints on the learngene parameters.", "section": "3 Method"}, {"figure_path": "Yhd0yzC8yD/figures/figures_7_1.jpg", "caption": "Figure 4: The accuracy of our method is compared with that of DeiT-B and SN-Net on ImageNet-1K. composed of these learngenes not only improves, but", "description": "This figure compares the performance of the proposed method (ICT) with DeiT-Base and SN-Net on ImageNet-1K.  The left subplot shows that the accuracy of the proposed method increases with the number of learngenes used, surpassing that of SCT (simultaneous training) and eventually reaching a performance comparable to DeiT-Base. The right subplot compares the accuracy and the number of parameters with SN-Net, demonstrating that the proposed method achieves comparable or better accuracy with fewer parameters. This highlights the efficiency and effectiveness of the proposed decomposition strategy.", "section": "4.2 Results and Analyses"}, {"figure_path": "Yhd0yzC8yD/figures/figures_8_1.jpg", "caption": "Figure 3: Decomposition and Recomposition. The upper part illustrates the decomposition process, where a ViT model is gradually recomposed into several learngenes. At each stage, only the newly added learngenes are trained, while the previously trained learngenes remain frozen. The lower part shows the recomposition process with two examples. The first initializes a 2-layer ViT with three learngenes trained by \u201cwithout constraints\u201d, while the second initializes a 3-layer ViT with four learngenes trained by \u201cwith constraints\u201d. Note that the flame icons indicate that the parameters of the layer are trained, while the snowflake icons indicates that the parameters are frozen.", "description": "This figure illustrates the process of linearly decomposing a Vision Transformer (ViT) model into its basic components called learngenes, and then recomposing these learngenes to create ViT models with varying depths (number of layers). The decomposition happens iteratively, with one learngene added and trained at each step, while the previously trained learngenes remain fixed.  The recomposition process demonstrates the flexibility to construct ViT models of different scales (number of layers) based on the availability of computational resources.  Two example recomposition scenarios are shown: one without training constraints and the other with.", "section": "3 Method"}, {"figure_path": "Yhd0yzC8yD/figures/figures_8_2.jpg", "caption": "Figure 6: Comparative results. The ViTs are initialized with two different recomposition cases and trained by corresponding methods, i.e., one is trained with constraint and the other is trained without constraint, and then compared with the performance of differently scaled pre-trained models and models obtained by model compression methods.", "description": "This figure compares the performance of Vision Transformers (ViTs) initialized using the proposed decomposition-recomposition method with pre-trained models and models generated by compression methods.  Two variants of the proposed method are shown: one trained with constraints and one without. The results demonstrate the comparable or superior performance of the proposed method across various model sizes on different datasets.", "section": "4.2 Results and Analyses"}, {"figure_path": "Yhd0yzC8yD/figures/figures_13_1.jpg", "caption": "Figure 7: The parameters of each layer of the pre-trained model and their corresponding layer position relationships.", "description": "This figure displays four graphs, one for each of the four pre-trained models (MOCO, DINO, MAE-B, and BEITv2-B). Each graph shows the relationship between the layer position (x-axis) and the weight value (y-axis) obtained after applying dimensionality reduction to the parameters of each layer in each model. The graphs show that the parameters in most layers display an approximately linear correlation with layer position in well-trained ViTs.", "section": "A.1 Dimensionality Reduction and Inter-Layer Parameter Relationships in ViTs"}, {"figure_path": "Yhd0yzC8yD/figures/figures_14_1.jpg", "caption": "Figure 8: Qualitative visualization of decomposed learngenes", "description": "This figure visualizes the qualitative characteristics of the decomposed learngenes of the Vision Transformer (ViT) model. Grad-CAM [44] is used to show which parts of the image each learngene focuses on.  The top row shows visualizations when each of the first six learngenes is used to initialize a ViT separately. The bottom row shows how the visualizations change as more learngenes are incrementally added. Early learngenes focus on basic shapes and contours.  Later learngenes focus on finer details and unique features, demonstrating how the model's attention to detail improves as more learngenes are incorporated.", "section": "A.2.2 Recomposition"}, {"figure_path": "Yhd0yzC8yD/figures/figures_14_2.jpg", "caption": "Figure 8: Qualitative visualization of decomposed learngenes", "description": "This figure visualizes the characteristics of decomposed learngenes using Grad-CAM.  Part (a) shows each learngene initialized separately, highlighting different focuses (shapes, textures, colors, spatial features, contrast, background/foreground). Part (b) shows the incremental addition of learngenes, illustrating the shift from general to detailed features as more are included.  This demonstrates how individual learngenes capture distinct aspects of the image leading to improved accuracy in image classification as more are used.", "section": "A.2.2 Recomposition"}, {"figure_path": "Yhd0yzC8yD/figures/figures_15_1.jpg", "caption": "Figure 3: Decomposition and Recomposition. The upper part illustrates the decomposition process, where a ViT model is gradually recomposed into several learngenes. At each stage, only the newly added learngenes are trained, while the previously trained learngenes remain frozen. The lower part shows the recomposition process with two examples. The first initializes a 2-layer ViT with three learngenes trained by \"without constraints\", while the second initializes a 3-layer ViT with four learngenes trained by \u201cwith constraints\u201d. Note that the flame icons indicate that the parameters of the layer are trained, while the snowflake icons indicates that the parameters are frozen.", "description": "This figure illustrates the two-stage process of linearly decomposing a Vision Transformer (ViT) into learngenes and then recomposing them into ViTs with varying depths. The top half shows the decomposition where, in iterative steps, the ViT's parameters are separated into multiple learngenes.  Each stage only trains new learngenes while keeping previously trained ones frozen. The bottom half demonstrates recomposition, showing how to initialize ViTs of varying depths using these trained learngenes. Two cases are illustrated, one where training happens without layer parameter constraints, and the other where such constraints are in effect.", "section": "3 Method"}, {"figure_path": "Yhd0yzC8yD/figures/figures_15_2.jpg", "caption": "Figure 3: Decomposition and Recomposition. The upper part illustrates the decomposition process, where a ViT model is gradually recomposed into several learngenes. At each stage, only the newly added learngenes are trained, while the previously trained learngenes remain frozen. The lower part shows the recomposition process with two examples. The first initializes a 2-layer ViT with three learngenes trained by \"without constraints\", while the second initializes a 3-layer ViT with four learngenes trained by \u201cwith constraints\u201d. Note that the flame icons indicate that the parameters of the layer are trained, while the snowflake icons indicates that the parameters are frozen.", "description": "This figure illustrates the decomposition and recomposition process of the Vision Transformer (ViT) model. The top half shows how the ViT is incrementally decomposed into learngenes, training only the newly added ones at each stage while keeping the previously trained ones fixed.  The bottom half presents two recomposition examples: one creating a 2-layer ViT from three learngenes (unconstrained), and another creating a 3-layer ViT from four learngenes (constrained).  Flame icons represent trained parameters, while snowflake icons indicate frozen parameters.", "section": "3 Method"}, {"figure_path": "Yhd0yzC8yD/figures/figures_15_3.jpg", "caption": "Figure 5: Performance of ViTs with different layers initialized with different learngenes on downstream datasets.", "description": "This figure visualizes the performance of Vision Transformers (ViTs) with varying numbers of layers and learngenes on various downstream datasets.  It showcases the impact of the number of learngenes and the depth of the network on model accuracy. Each subfigure represents a different dataset, illustrating the trade-off between model complexity (number of layers and learngenes) and performance. The heatmaps show the performance for various combinations of learngenes and depths. The color intensity represents the accuracy, with darker shades indicating higher accuracy.", "section": "4.2 Results and Analyses"}]