[{"figure_path": "Yhd0yzC8yD/tables/tables_6_1.jpg", "caption": "Table 1: Results of ViTs with different decomposition coefficients.", "description": "This table presents the accuracy results of Vision Transformers (ViTs) when different polynomial decomposition coefficients (Taylor, Chebyshev, Fourier, Legendre) are used.  The table demonstrates the impact of the coefficient choice on the final performance of the model, showing that the Chebyshev polynomial achieves the best accuracy.", "section": "4.2.1 Choosing Suitable Polynomial Coefficients"}, {"figure_path": "Yhd0yzC8yD/tables/tables_16_1.jpg", "caption": "Table 2: Comparative experiments. Two cases of initializing models with learngenes and their corresponding training approaches, compared with the pre-training fine-tuning and model compression methods.", "description": "This table presents a comparison of the performance of different methods for training vision transformer models.  It compares models trained using pre-training and fine-tuning, model compression techniques, and the proposed method (using different numbers of learngenes and training strategies). The comparison is done across various datasets and model sizes, evaluating the accuracy of each method. The table highlights the trade-off between model size (parameters), computational efficiency, and accuracy.", "section": "4.2 Results and Analyses"}, {"figure_path": "Yhd0yzC8yD/tables/tables_16_2.jpg", "caption": "Table 3: Overview of Classification Datasets", "description": "This table lists the nine datasets used for the downstream tasks in the paper.  For each dataset, it shows the number of categories, the number of training samples, and the number of test samples.  These datasets represent diverse image classification challenges, including general object recognition, fine-grained recognition (cars, flowers, pets), and texture classification.", "section": "A.3.2 Datasets and Pre-processing"}]