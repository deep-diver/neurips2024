{"references": [{"fullname_first_author": "Michael N. Katehakis and Arthur F. Veinott", "paper_title": "The multi-armed bandit problem: Decomposition and computation", "publication_date": "1987-00-00", "reason": "This paper provides the foundational theory behind the Monte Carlo Tree Search algorithm, a key component of the proposed GIF-MCTS method."}, {"fullname_first_author": "Levente Kocsis and Csaba Szepesv\u00e1ri", "paper_title": "Bandit based monte-carlo planning", "publication_date": "2006-00-00", "reason": "This foundational work introduces the Upper Confidence Bound for Trees (UCT) algorithm, a crucial element in the Monte Carlo Tree Search implementation of the GIF-MCTS method."}, {"fullname_first_author": "Richard S. Sutton", "paper_title": "Dyna, an integrated architecture for learning, planning, and reacting", "publication_date": "1991-07-01", "reason": "This highly influential paper introduces the concept of Dyna-Q, a model-based reinforcement learning algorithm which inspired the approach of using code-based world models in this paper."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This paper demonstrates the remarkable few-shot learning capabilities of large language models, which are leveraged by the GIF-MCTS method for code generation."}, {"fullname_first_author": "Sergey Levine", "paper_title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems", "publication_date": "2020-00-00", "reason": "This paper provides a comprehensive overview of offline reinforcement learning, which is the setting used to evaluate the proposed Code World Models Benchmark."}]}