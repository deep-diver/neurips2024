{"references": [{"fullname_first_author": "Andy Zou", "paper_title": "Universal and transferable adversarial attacks on aligned large language models", "publication_date": "2023-07-15", "reason": "This paper introduces the Greedy Coordinate Gradient (GCG) attack, a foundational technique that the current paper builds upon and improves."}, {"fullname_first_author": "Nicholas Carlini", "paper_title": "Towards evaluating the robustness of neural networks", "publication_date": "2017-05-22", "reason": "This paper is highly influential in the field of adversarial machine learning, introducing key concepts and techniques used in subsequent research, including this paper."}, {"fullname_first_author": "Battista Biggio", "paper_title": "Evasion attacks against machine learning at test time", "publication_date": "2013-01-01", "reason": "This seminal work established the foundational understanding of evasion attacks, which are central to the current paper's investigation of adversarial prompts."}, {"fullname_first_author": "Ian J Goodfellow", "paper_title": "Explaining and harnessing adversarial examples", "publication_date": "2015-01-01", "reason": "This paper is foundational to the field of adversarial machine learning, introducing the concept of adversarial examples and their properties, highly relevant to the current paper's topic."}, {"fullname_first_author": "Christian Szegedy", "paper_title": "Intriguing properties of neural networks", "publication_date": "2014-01-01", "reason": "This foundational work detailed the properties of neural networks which are relevant to the current paper's approach to adversarial examples."}]}