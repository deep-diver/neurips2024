{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a foundational multimodal model that significantly impacts the field and is extensively analyzed in the current work."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces Stable Diffusion, another highly influential multimodal model, whose performance is also investigated in this research."}, {"fullname_first_author": "Christoph Schuhmann", "paper_title": "LAION-400M: Open dataset of CLIP-filtered 400 million image-text pairs", "publication_date": "2021-11-01", "reason": "This paper introduces a large-scale dataset crucial for pretraining many of the models studied in this paper."}, {"fullname_first_author": "Alex Fang", "paper_title": "Data determines distributional robustness in contrastive language image pre-training (CLIP)", "publication_date": "2022-07-01", "reason": "This paper provides valuable insights into the influence of pretraining data on the robustness of CLIP models, a key aspect explored in the present work."}, {"fullname_first_author": "Prasanna Mayilvahanan", "paper_title": "Does CLIP's generalization performance mainly stem from high train-test similarity?", "publication_date": "2024-04-01", "reason": "This paper investigates a potential confounding factor (train-test similarity) in CLIP's performance, which is carefully controlled for in the current study."}]}