{"importance": "This paper is crucial because **it addresses the critical data security concerns** surrounding large vision-language models (VLLMs). By introducing the first MIA benchmark tailored for VLLMs and a novel MIA pipeline, it significantly advances the understanding and methodology of membership inference attacks in this emerging field.  The research directly contributes to the development of more secure and privacy-preserving VLLMs, which is vital in today's data-driven world.  Moreover, the **new MaxR\u00e9nyi-K% metric** offers a versatile tool for evaluating MIAs across various modalities, opening new avenues for future research and enhancing the robustness of privacy-preserving techniques.", "summary": "First benchmark for detecting training data in large vision-language models (VLLMs) improves data security.", "takeaways": ["First MIA benchmark for VLLMs is introduced to facilitate training data detection.", "A novel MIA pipeline, specifically designed for token-level image detection, is proposed.", "A new metric, MaxR\u00e9nyi-K%, is presented for evaluating MIAs on both text and image data."], "tldr": "Large vision-language models (VLLMs) are powerful but raise significant data security concerns due to potential inclusion of sensitive information during training.  Current methods for detecting misuse of data in VLLMs are inadequate due to the lack of standardized datasets and methodologies.  This has resulted in a critical and unresolved issue in securing sensitive data used to train these models. \nThis paper introduces the first membership inference attack (MIA) benchmark designed for VLLMs, along with a novel MIA pipeline for token-level image detection.  A new metric, MaxR\u00e9nyi-K%, is proposed to evaluate MIAs across various VLLMs and modalities (text and image).  **The results demonstrate the effectiveness of the proposed MIA pipeline and metric**, contributing to a deeper understanding of MIAs in the context of VLLMs and offering valuable tools for enhancing data security and privacy in this emerging field.", "affiliation": "LIONS, EPFL", "categories": {"main_category": "Multimodal Learning", "sub_category": "Vision-Language Models"}, "podcast_path": "nv2Qt5cj1a/podcast.wav"}