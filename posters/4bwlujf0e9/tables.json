[{"figure_path": "4BWlUJF0E9/tables/tables_5_1.jpg", "caption": "Table 1: Graph classification results on small-scale benchmarks (measured by accuracy: %)", "description": "This table presents the results of graph classification experiments on six small-scale benchmark datasets.  The table shows the accuracy (%) achieved by various graph neural network (GNN) models, including several baselines and the proposed N\u00b2.  Each row represents a different GNN model, and each column represents a different benchmark dataset.  The results demonstrate the performance of N\u00b2 in comparison to existing models on these relatively smaller-scale graph classification problems.", "section": "5 Experiment"}, {"figure_path": "4BWlUJF0E9/tables/tables_6_1.jpg", "caption": "Table 3: Node classification results on small-scale homophilic graphs (measured by ROC-AUC: %).", "description": "This table presents the results of node classification experiments conducted on six small-scale homophilic graph datasets.  The results are measured using the ROC-AUC metric and compare the performance of various methods, including GCN, GAT, GPRGNN, APPNP, GIN, H2GCN, FAGCN, GloGNN, GT, Graphormer, GraphGPS, and Exphormer, with the proposed N\u00b2 method.  The table shows average precision (%) and the number of parameters (in thousands) for each method. The datasets used span a variety of domains and sizes.", "section": "5.2 Node Classification"}, {"figure_path": "4BWlUJF0E9/tables/tables_6_2.jpg", "caption": "Table 3: Node classification results on small-scale homophilic graphs (measured by ROC-AUC: %).", "description": "This table presents the results of node classification experiments conducted on six small-scale homophilic graph datasets.  The results are measured using the ROC-AUC (Receiver Operating Characteristic - Area Under the Curve) metric, a common evaluation measure for node classification problems.  The table compares the performance of the proposed N\u00b2 model against several other state-of-the-art graph neural network (GNN) models.  The datasets used are AmazonPhoto, AmazonComputers, CoauthorCS, CoauthorPhysics, Questions, and Amazon-ratings.  The table provides a detailed comparison of the ROC-AUC scores achieved by each model on each dataset.  This allows for a quantitative assessment of the relative performance of the different GNN models in a homophilic graph setting.", "section": "5.2 Node Classification"}, {"figure_path": "4BWlUJF0E9/tables/tables_6_3.jpg", "caption": "Table 4: Node classification results on small-scale heterophilic graphs (measured by ROC-AUC except accuracy for amazon-ratings: %). \u2020 denotes our reproduced results.", "description": "This table presents the results of node classification experiments conducted on six small-scale heterophilic graph datasets.  The table compares the performance (measured by ROC-AUC, except for Amazon-ratings where accuracy is used) of the proposed N\u00b2 model against several baseline methods, including SGC, GCN, GAT, GPRGNN, H2GCN, FAGCN, GLOGNN, GT, Graphormer, GraphGPS, and Exphormer.  The results highlight the performance of N\u00b2 in comparison to these baseline models on heterophilic graph datasets.", "section": "5.2 Node Classification"}, {"figure_path": "4BWlUJF0E9/tables/tables_7_1.jpg", "caption": "Table 5: Node classification results on large-scale benchmarks (measured by ROC-AUC/accuracy: %). \u2020 denotes our reproduced results.", "description": "This table presents the results of node classification experiments conducted on four large-scale benchmark datasets: GENIUS, ARXIV-YEAR, OGB-ARXIV, and OGB-PROTEINS.  The metrics used for evaluation are ROC-AUC (for GENIUS, ARXIV-YEAR, and OGB-PROTEINS) and accuracy (for ARXIV-YEAR). The table compares the performance of the proposed N\u00b2 model against several state-of-the-art baseline methods. Note that some baseline models resulted in out-of-memory (OOM) errors, highlighting the scalability challenges associated with large graph datasets.  The results demonstrate N\u00b2's ability to achieve superior or comparable performance on these challenging benchmarks.", "section": "5.2 Node Classification"}, {"figure_path": "4BWlUJF0E9/tables/tables_8_1.jpg", "caption": "Table 7: Ablation on the modules of N2 (measured by accuracy: %). PA., L., and G. denote pseudo-node adaptation, local message passing, and global message passing. Att. and Prx. denote the attention and proximity measurement.", "description": "This table presents the ablation study results on the different modules of the N2 model. The accuracy is measured on three datasets: Amz-ratings, Amz-Photo, and RPO-TEINS. The modules being ablated include pseudo-node adaptation (PA.), local message passing (L.), and global message passing (G.).  Two variations are tested for the \"Full\" model, one using attention (Att.) and the other using proximity (Prx.) measurements.", "section": "5.3.4 Ablation Study"}, {"figure_path": "4BWlUJF0E9/tables/tables_17_1.jpg", "caption": "Table S6: Hyper-parameter setups for N2.", "description": "This table shows the hyperparameter settings used for the N2 model across various graph classification and node classification benchmarks.  The hyperparameters include the number of recursive steps (L), hidden dimension, state space dimension, number of units (k), number of pseudo-nodes (np), and dropout rate.  Different benchmarks have different optimal hyperparameter values, reflecting the varying characteristics of the datasets.", "section": "C.2 Experimental Setups"}, {"figure_path": "4BWlUJF0E9/tables/tables_18_1.jpg", "caption": "Table S7: Effectiveness study on peptides-struct (measured by mean absolute error).", "description": "This table presents the results of an effectiveness study conducted on the peptides-struct benchmark dataset.  The study compares the performance of various graph neural network (GNN) models, including GCNII, GCN, GINE, GATEDGCN, SAN, PATHNN, DREW-GCN, EXPHORMER, and the proposed model N\u00b2, in terms of their mean absolute error.  The goal is to evaluate the effectiveness of these models in handling the challenges of graph regression tasks, such as over-squashing.  The table showcases the mean absolute error achieved by each model on the peptides-struct dataset.", "section": "5.3.2 Effectiveness of N\u00b2"}, {"figure_path": "4BWlUJF0E9/tables/tables_22_1.jpg", "caption": "Table 8: Ablation studies on messages.", "description": "This table presents the ablation study results on the impact of using messages in the dynamic message-passing mechanism of the proposed N2 model. It compares the performance (measured by accuracy) on eight benchmark datasets: Questions, Amazon-Ratings, Tolokers, Minesweeper, CoauthorCS, CoauthorPhysics, AmazonPhoto, and AmazonComputers when using messages (W. MESSAGES) versus when not using messages (W/O. MESSAGES). The last column (W/O.-W.) shows the difference in accuracy between these two scenarios.  The results indicate the relative importance of message passing for model performance on different datasets.", "section": "5.3.4 Ablation Study"}, {"figure_path": "4BWlUJF0E9/tables/tables_22_2.jpg", "caption": "Table 1: Graph classification results on small-scale benchmarks (measured by accuracy: %)", "description": "This table presents the graph classification accuracy results (%) for various graph neural network (GNN) models on several small-scale benchmark datasets.  The table shows the performance of different GNN models including GCN, GraphSAGE, GIN, and the proposed model N\u00b2. The benchmarks used cover different domains such as proteins, chemical compounds, and movie collaborations.  Each dataset is characterized by its size in terms of the number of graphs, nodes, edges, and node features.  This allows for a comparative assessment of the different GNN architectures and their efficacy on different graph characteristics.", "section": "5 Experiment"}]