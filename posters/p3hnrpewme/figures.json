[{"figure_path": "p3hNrpeWMe/figures/figures_5_1.jpg", "caption": "Figure 1: Empirical comparison of the corrected cosine similarity scores between $\n\\phi^{(+)}\\text{ (on top)}\\text{ and }\\phi^{(-)}\\text{ (on bottom) for varying n and p shown in heatmap. The dimension, i.e., d = 2^n is varied from 2 to 1024 (n \u2208 {1,2,\u2026\u2026\u2026,10}) and the number of vector pairs bundled is varied from 1 to 50. This shows that we can accurately identify when a vector $x_i$ has been bound to a VSA or not when we keep track of how many pairs of terms p are included.", "description": "This figure shows the results of an empirical study that compares the corrected cosine similarity scores ($\n\\phi^{(+)}\\text{ and }\\phi^{(-)}$) for different numbers of vector pairs (p) and dimensions (d=2^n). The heatmaps show that the corrected cosine similarity for positive cases ($\n\\phi^{(+)}$) is close to 1, and for negative cases ($\n\\phi^{(-)}$) is close to 0.  This indicates the effectiveness of the proposed method in accurately identifying whether a vector has been bound to a VSA or not when the number of bundled vector pairs is known.", "section": "4 Empirical Results"}, {"figure_path": "p3hNrpeWMe/figures/figures_6_1.jpg", "caption": "Figure 2: The area under the accuracy curve due to the change of no. of bundled pairs p for dimensions d. All the dimensions are chosen to be perfect squares due to the constraint of VTB.", "description": "This figure shows the area under the curve (AUC) of the accuracy versus the number of bundled pairs for different vector dimensions (d).  It compares the performance of four different Vector Symbolic Architectures (VSAs): HRR, VTB, MAP, and the proposed HLB.  The dimensions are chosen as perfect squares to accommodate the requirements of the VTB method. The AUC provides a summary measure of each VSA's performance across various numbers of bundled vector pairs.", "section": "4 Empirical Results"}, {"figure_path": "p3hNrpeWMe/figures/figures_6_2.jpg", "caption": "Figure 3: When repeatedly binding different random (left) or a single vector (right), HLB consistently returns the ideal similarity score of 1 for a present item (top row) and has a constant magnitude (bottom row), avoiding exploding/vanishing values.", "description": "This figure shows the results of an experiment where different VSAs (HRR, VTB, MAP, and HLB) were repeatedly used to bind either a different random vector or a single vector in each round. The top row shows the similarity score between the original vector and the retrieved vector. The bottom row shows the magnitude of the retrieved vector. The figure demonstrates that HLB consistently maintains a similarity score close to 1 and a constant magnitude, even with a large number of repeated bindings. This contrasts with the other VSAs, which show a decline in similarity and/or instability in magnitude as the number of bindings increases. This indicates that HLB is more robust and reliable for tasks involving repeated binding operations.", "section": "4 Empirical Results"}, {"figure_path": "p3hNrpeWMe/figures/figures_14_1.jpg", "caption": "Figure 4: Heatmap of the empirical comparison of the noise components \u03b7 and \u03b7 for varying n and p shown in natural logarithm scale. The dimension, i.e., d = 2n is varied from 2 to 1024 (n \u2208 {1,2,\u2026\u2026,10}) and the number of vector pairs bundled is varied from 2 to 50.", "description": "This figure shows the heatmap visualization of the noise for both \u03b7 and \u03b7 in natural log scale. The amount of noise accumulated without any projection to the inputs is much higher compared to the noise accumulation with the projection. For varying n and p, the maximum amount of noise accumulated when projection is applied is 7.18 and without any projection, the maximum amount of noise is 19.38. Also, most of the heatmap of \u03b7 remains in the blue region whereas as n and p increase, the heatmap of \u03b7 moves towards the red region. Therefore, it is evident that the projection to the inputs diminishes the amount of accumulated noise with the retrieved output.", "section": "3 Methodology"}, {"figure_path": "p3hNrpeWMe/figures/figures_15_1.jpg", "caption": "Figure 5: Comparison between the theoretical and experimental relationship of Theorem B.1. The norm of the composite representation of the bound vectors is computed for no. of bundled vectors from 1 to 200 of dimension d = 1024. The figure shows how the experimental value of the norm closely follows the theoretical relation between ||Xp||2 and p.", "description": "This figure empirically validates Theorem B.1, which states that the norm of the composite representation (||Xp||2) is proportional to the square root of the number of bundled vector pairs (\u221ap).  The graph plots the theoretical norm (red line) against the experimentally obtained norm (purple dots) for 200 bundled pairs of vectors in a 1024-dimensional space. The close agreement between the theoretical prediction and experimental results supports the theorem, showing that the approximation holds well even for a substantial number of bound vectors.  Slight deviations are observed, particularly at higher values of p, likely due to the approximation made in the theorem's derivation (discarding noise terms).", "section": "B Norm Relation"}, {"figure_path": "p3hNrpeWMe/figures/figures_16_1.jpg", "caption": "Figure 6: Comparison between the theoretical and experimental \u03c6 \u2013 p relationship. Vectors of dimension d = 512 are combined and retrieved with a varied number of vectors from 1 to 50. The zoom portion shows how closely experimental results match with the theoretical conclusion.", "description": "This figure compares the theoretical and experimental results of the relationship between cosine similarity (\u03c6) and the number of bundled pairs (p).  The theoretical relationship, derived from Theorem 3.2, predicts that cosine similarity decreases proportionally to the inverse square root of the number of bundled pairs. The experimental results, obtained through simulations, closely follow the theoretical prediction, with the shaded region showing the standard deviation. The zoomed inset highlights the close agreement between theoretical and experimental values.", "section": "4.1 Classical VSA Tasks"}]