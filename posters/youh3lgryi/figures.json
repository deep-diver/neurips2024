[{"figure_path": "YOUh3lgRYI/figures/figures_1_1.jpg", "caption": "Figure 1: Demonstration of SI2T and ST2I tasks.", "description": "This figure illustrates the complementary nature of the SI2T and ST2I tasks.  It shows that SI2T (spatial image-to-text) involves a relatively difficult 3D scene construction process from a 2D image, followed by an easier process of generating a textual description of that 3D scene. Conversely, ST2I (spatial text-to-image) has an easier process of constructing a 3D scene from the textual input, but faces the difficulty of generating the actual 2D image from the 3D scene. The figure highlights the concept of 'intermediate processing sharing' where the easier process of each task aids in the harder process of the other, and '3D scene feature sharing' where the common 3D scene representation benefits both tasks. The example illustrates how a family scene would be processed, indicating the information flow between input (image/text), intermediate 3D scene representation, and output (text/image).", "section": "1 Introduction"}, {"figure_path": "YOUh3lgRYI/figures/figures_1_2.jpg", "caption": "Figure 1: Demonstration of SI2T and ST2I tasks.", "description": "This figure illustrates the complementary nature of the SI2T (Spatial Image-to-Text) and ST2I (Spatial Text-to-Image) tasks.  It shows how the input and output of each task are reversed, highlighting their dual nature.  It also visually represents the concept of 'intermediate processing sharing,' where easier sub-tasks within each main task (e.g., 3D scene generation from text in ST2I) can aid more difficult ones (e.g., 3D scene reasoning from an image in SI2T), and '3D scene feature sharing,' emphasizing that both tasks fundamentally rely on constructing a 3D understanding of the scene.", "section": "1 Introduction"}, {"figure_path": "YOUh3lgRYI/figures/figures_4_1.jpg", "caption": "Figure 2: Overall Framework of the S\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "This figure illustrates the Synergistic Dual Discrete Diffusion (SD\u00b3) framework proposed in the paper.  It shows how the model handles both spatial image-to-text (SI2T) and spatial text-to-image (ST2I) tasks simultaneously. The framework consists of three main components: 1) a shared graph diffusion model to generate a 3D Scene Graph (3DSG) representation from either image or text input. This 3DSG is then used to guide 2) an image diffusion model for ST2I and 3) a text diffusion model for SI2T. Importantly, the easier 3D-to-image/text processes aid the more difficult image/text-to-3D processes, resulting in synergistic improvement in both tasks.  The diagram clearly depicts the information flow and the different processes involved.", "section": "4 Methodology"}, {"figure_path": "YOUh3lgRYI/figures/figures_6_1.jpg", "caption": "Figure 2: Overall Framework of the SD\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "The figure illustrates the overall framework of the proposed Spatial Dual Discrete Diffusion (SD\u00b3), which consists of three separate discrete diffusion models: a shared 3DSG diffusion model, an ST2I diffusion model, and an SI2T diffusion model.  The 3DSG diffusion model converts initial TSG (for ST2I) and VSG (for SI2T) to a 3DSG representation. The ST2I and SI2T models then generate images and texts, respectively, using the 3DSG as a condition.  Intermediate features from the easy parts of the processes are used to guide the harder parts, facilitating mutual benefit between the two dual tasks. ", "section": "4 Methodology"}, {"figure_path": "YOUh3lgRYI/figures/figures_8_1.jpg", "caption": "Figure 2: Overall Framework of the SD\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "This figure illustrates the overall framework of the proposed synergistic dual framework for spatial image-to-text (SI2T) and spatial text-to-image (ST2I) generation.  It highlights the dual processes involved and the shared 3D scene graph (3DSG) that benefits both tasks. The framework uses three separate discrete diffusion models: one for 3DSG generation from visual or textual inputs, one for image generation from the 3DSG (ST2I), and one for text generation from the 3DSG (SI2T). The figure emphasizes the intermediate processing sharing and the 3D scene feature sharing that enhances the performance of each task.", "section": "4 Methodology"}, {"figure_path": "YOUh3lgRYI/figures/figures_8_2.jpg", "caption": "Figure 2: Overall Framework of the SD\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "This figure illustrates the Synergistic Dual Spatial-aware Generation framework for both spatial image-to-text (SI2T) and spatial text-to-image (ST2I) tasks.  It highlights the dual nature of the processes, showing how easier sub-tasks (3D\u2192Text and 3D\u2192Image) assist harder ones (Text\u21923D and Image\u21923D), and how a shared 3D Scene Graph (3DSG) representation benefits both tasks. Three main diffusion processes are shown: one for generating the 3DSG from input image or text, and separate ones for generating the image and text outputs respectively.", "section": "4 Methodology"}, {"figure_path": "YOUh3lgRYI/figures/figures_9_1.jpg", "caption": "Figure 2: Overall Framework of the SD\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "This figure illustrates the overall framework of the proposed Synergistic Dual Spatial-aware Generation of Image-to-Text and Text-to-Image model. It shows the three main components and their interactions: 1) a shared graph diffusion model for generating 3D scene graph (3DSG) representations from input images (VSG) or texts (TSG); 2) an image diffusion model for generating images from 3DSG (ST2I); and 3) a text diffusion model for generating text from 3DSG (SI2T).  The figure highlights the dual learning process, where the intermediate features from the easier 3D\u2192X (Image or Text) process are used to guide the harder X\u21923D process, thereby improving the performance of both tasks. This synergistic approach emphasizes the sharing of 3D scene features and intermediate processing results between the SI2T and ST2I tasks.", "section": "4 Methodology"}, {"figure_path": "YOUh3lgRYI/figures/figures_21_1.jpg", "caption": "Figure 8: The evaluation of structure matching on the gold 3DSSG dataset with noise.", "description": "This figure shows the impact of noisy 3DSG training data on the performance of the model.  The x-axis represents the percentage of noise added to the gold standard 3DSG dataset.  The y-axis shows the percentage of successful matches (Noisy/No Noise).  Three lines represent the performance of SI2T, ST2I, and 3DSG generation tasks.  As the noise rate increases, the performance of all three tasks degrades significantly, demonstrating the sensitivity of the model to the quality of the 3DSG training data.", "section": "C.4 How the quality of 3DSG dataset influences the performance"}, {"figure_path": "YOUh3lgRYI/figures/figures_21_2.jpg", "caption": "Figure 2: Overall Framework of the SD\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "This figure illustrates the synergistic dual framework for spatial image-to-text (SI2T) and spatial text-to-image (ST2I) generation.  It shows three main components: 1) A shared graph diffusion model to generate a 3D scene graph (3DSG) from either an image or text input. The 3DSG serves as a common representation for both tasks; 2) A discrete diffusion model for ST2I, which uses the 3DSG to generate images; 3) A discrete diffusion model for SI2T, which leverages the 3DSG to generate text.  The design incorporates intermediate processing sharing, allowing easier tasks (3D\u2192Text and 3D\u2192Image) to aid harder ones (Text\u21923D and Image\u21923D), improving the overall performance of both SI2T and ST2I.", "section": "4 Methodology"}, {"figure_path": "YOUh3lgRYI/figures/figures_22_1.jpg", "caption": "Figure 4: Qualitative results by different models, where the samples are selected from VSDv2.", "description": "This figure showcases qualitative results from different models on the VSDv2 dataset.  For each row, it displays the ground truth image, the ground truth text caption, and then outputs from four different models: VQ-Diffusion, Frido, 3DVSD, and SD\u00b3.  The outputs include both generated images (for text-to-image) and generated text captions (for image-to-text). The figure visually demonstrates the comparative performance of the different models in terms of accurately generating images from text descriptions and generating spatial descriptions from images.  The focus is on the spatial relationships depicted. Note that SD\u00b3 is the authors' proposed model.", "section": "5.3 Qualitative Results"}, {"figure_path": "YOUh3lgRYI/figures/figures_22_2.jpg", "caption": "Figure 2: Overall Framework of the SD\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "This figure illustrates the overall framework of the proposed Spatial Dual Discrete Diffusion (SD\u00b3) model for synergistic dual spatial-aware generation of Image-to-Text (SI2T) and Text-to-Image (ST2I).  It shows three main components: a shared graph diffusion model that generates a 3D Scene Graph (3DSG) from either an image or text input, an image diffusion model for generating images from the 3DSG (ST2I), and a text diffusion model for generating text from the 3DSG (SI2T).  The model uses an intermediate processing sharing strategy, where the easier 3D\u2192X processes (3D to image or text) guide the harder X\u21923D processes (image or text to 3D). The 3DSG is a key component that allows for shared information between the two tasks.", "section": "4 Methodology"}, {"figure_path": "YOUh3lgRYI/figures/figures_22_3.jpg", "caption": "Figure 10: More cases of ST2I generated by SD\u00b3.", "description": "This figure shows additional examples of images generated by the proposed Spatial Dual Discrete Diffusion (SD\u00b3) model for the spatial text-to-image (ST2I) task. Each row presents a text prompt and several images generated by the model, illustrating the model's ability to generate images that accurately reflect the spatial relationships described in the text.", "section": "5.3 Qualitative Results"}, {"figure_path": "YOUh3lgRYI/figures/figures_23_1.jpg", "caption": "Figure 2: Overall Framework of the SD\u00b3. The figure presents the dual processes of ST2I and SI2T. The RED block represents the hard X\u21923D processes, and the GREEN block represents the 3D\u2192X processes. There are three diffusion processes in total, i.e., a shared graph diffusion model for VSG/TSG\u21923DSG generation, and the image diffusion model and text diffusion model.", "description": "This figure illustrates the Synergistic Dual Discrete Diffusion (SD\u00b3) framework, which uses three discrete diffusion models for image-to-text (SI2T) and text-to-image (ST2I) generation.  It highlights the dual processes (X\u21923D and 3D\u2192X) and shows how a shared graph diffusion model generates a 3D scene graph (3DSG) that benefits both SI2T and ST2I tasks. The intermediate features from the easier 3D\u2192X processes help guide the harder X\u21923D processes.", "section": "4 Methodology"}]