[{"type": "text", "text": "Teach Better or Show Smarter? On Instructions and Exemplars in Automatic Prompt Optimization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Xingchen Wan, Ruoxi Sun, Hootan Nakhost, Sercan \u00d6. Ar\u0131k Google Cloud AI Research {xingchenw, ruoxis, hootan, soarik}@google.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Large language models have demonstrated remarkable capabilities but their performance is heavily reliant on effective prompt engineering. Automatic prompt optimization (APO) methods are designed to automate this and can be broadly categorized into those targeting instructions (instruction optimization, IO) vs. those targeting exemplars (exemplar optimization, EO). Despite their shared objective, these have evolved rather independently, with IO receiving more research attention recently. This paper seeks to bridge this gap by comprehensively comparing the performance of representative IO and EO techniques both isolation and combination on a diverse set of challenging tasks. Our findings reveal that intelligently reusing model-generated input-output pairs obtained from evaluating prompts on the validation set as exemplars, consistently improves performance on top of IO methods but is currently under-investigated. We also find that despite the recent focus on IO, how we select exemplars can outweigh how we optimize instructions, with EO strategies as simple as random search outperforming state-of-the-art IO methods with seed instructions without any optimization. Moreover, we observe a synergy between EO and IO, with optimal combinations surpassing the individual contributions. We conclude that studying exemplar optimization both as a standalone method and its optimal combination with instruction optimization remain a crucial aspect of APO and deserve greater consideration in future research, even in the era of highly capable instruction-following models. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Significant advancements in large language models (LLMs) have revolutionized various natural language processing tasks [9, 4, 1, 15]. One notable aspect of LLMs, however, is their sensitivity to the input \"prompts,\" which has given rise to the burgeoning field of prompt engineering [26, 38]. On black-box LLMs where we can neither modify or access internal parameters, prompt engineering involves crafting input prompts that effectively guide LLMs to generate desired outputs. Starting from manual processes requiring human expertise, the complexity and volume of prompts have necessitated the development of automatic prompt optimization (APO) methods aiming to streamline and automate prompt generation, thereby alleviating the burden of manual intervention. Broadly, since prompts consist of instructions and exemplars, we may roughly categorize APO into instruction optimization (IO) and exemplar optimization (EO) approaches. IO focuses ", "page_idx": 0}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/0ababc0d2d9fd317337002af3e5539832577b8592b373480ab03a9d9af04fab7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Figure 1: Average performance over ${>}20$ tasks on PaLM 2 \u2013 We compare and combine APO targeting exemplars and instructions, and find that how we optimize exemplars (orange) can eclipse how we optimize instructions despite current research favoring the latter (blue and purple), whereas optimizing both is the best (cyan) within similar budget. ", "page_idx": 0}, {"type": "text", "text": "on refining the textual instructions provided to LLMs that contain task-specific information (i.e., to teach), whereas EO emphasizes the selection of relevant examples to guide model behavior (i.e., to show). Partially driven by the improved instruction-following ability of LLMs, the research attention has increasingly shifted towards IO, especially using LLMs themselves as optimizers [66, 35, 48]. ", "page_idx": 1}, {"type": "text", "text": "While EO and IO approaches address the similar overarching problem, they have evolved somewhat independently, with a few exceptions [14, 47]. Indeed, as we elaborate in $\\S2$ , EO approaches are often based on simple, handcrafted templates without explicit instruction optimization [21, 45], while IO methods seldom optimize exemplars and often rely on random validation set samples [35], require additional fixed exemplars on top of the validation set [66, 16], or consider the \u201czero-shot\u201d setup with no exemplars at all [48]. Whereas the lack of IO in EO methods is somewhat understandable as many EO approaches predate instruction finetuning [49] and, subsequently, instruction-following models that are sensitive to instructions, the inverse is much less so: concretely, almost all existing IO approaches already require a labeled dataset as the validation set, and are therefore, by definition, not \u201czero-shot\u201d. With the inputs, labels, and, if applicable, model-generated intermediate outputs (e.g., reasoning steps) on the subset of the validation set that the model has answered correctly, we already have a set of exemplars as a free side-product whenever we perform IO, independent from and on top to any additionally provided, human-annotated exemplars. A common argument for not focusing on EO, such as mentioned in Pryzant et al. [35], is the goal to focus on one objective at a time1. However, given the common practical goal of and the interplay between EO and IO [30], we argue they should not be treated separately \u2013 it is instead critical to understand their relative importance and combined impact, and, where necessary, optimize them jointly for the best performance-cost balance. ", "page_idx": 1}, {"type": "text", "text": "This is, to our knowledge, where there is a gap in the literature that we aim to bridge. To do so, on a diverse suite of challenging BIG-Bench and MMLU tasks, we compare the performance gain brought by various representative, state-of-the-art (SoTA) IO and EO methods on the fairground with PaLM 2, Gemini (1.0/1.5) and GPT models to foster better scientific understanding of different APO techniques. While IO comfortably improves the baseline prompts before any instruction or exemplar optimization, this, at best, portrays an incomplete picture. Under the same setup, with simple yet effective EO methods on the model-generated exemplars on the validation set, we show: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Intelligently incorporating exemplars generated by the target model itself on the validation set significantly and consistently improves performance on top of recently proposed IO methods;   \n\u2022 The performance gains realized by choosing appropriate exemplars via methods as simple as random search can eclipse the improvements brought by SoTA instruction optimization. As a concrete example, as shown in Fig. 1, with a simple optimization routine on exemplars, seed instructions before any optimization outperform optimized instructions obtained with complex IO but with random exemplars most commonly used.   \n\u2022 There exists a synergy between EO and IO, and optimally mixing-and-matching IO and EO is greater than the sum of its parts under a comparable computational budget.   \n\u2022 SoTA IO might be itself implicitly generating exemplars, and these exemplars, while somewhat unintentional, contribute more to the performance than the rest of the instruction that IO methods are meant to optimize.   \n\u2022 While arguably receiving less research attention recently, exemplar optimization remains a crucial design consideration in APO. Even in an era of highly capable instruction-following LLMs, the significance of exemplar optimization should not be relegated to an afterthought, and better exemplar optimization both as a standalone tool and as a combinable component with IO is crucial for APO. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Prompts are natural language inputs to LLMs. Denoting an input task query as $x$ , a few-shot prompt $P(x)$ may be represented as $P(\\bar{x})=[I,e_{1},...,e_{k},x]$ where $I$ denotes an instruction and $\\bar{\\{e_{1},...,e_{k}\\}}$ denote $k$ exemplars (or interchangeably, demonstrations), each of which is a concatenation of other queries and their outputs (including both the final answer and any possible intermediate outputs) which resemble the current query $x$ or may otherwise guide the LLM to better handle the current task, and we show a common prompt template organizing these components in Fig. $2-$ note that not all components are required: e.g., zero-shot prompts feature no exemplars. ", "page_idx": 1}, {"type": "text", "text": "Automatic prompt optimization (APO) aims to automatically design $P(x)$ via optimization. We broadly consider black-box API-only $\\mathrm{LLMs}^{2}$ . The proposed framework assumes a validation dataset $D_{\\mathrm{val}}:=\\{(x_{i},y_{i})\\}_{i=1}^{n_{\\mathrm{val}}}$ , where $x_{i}$ and $y_{i}$ represent validation inputs and targets, a performance metric (e.g., accuracy) $g(\\cdot,\\cdot)$ , and aims to find the optimal prompt $P^{*}(x)$ to be used at test time, which is empirically the maximizer on $\\mathcal{D}_{\\mathrm{val}}$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\nP^{*}(x)=\\arg\\operatorname*{max}_{P(\\cdot)\\sim\\mathcal{P}}\\mathbb{E}_{(x,y)\\sim\\mathcal{D}_{\\mathrm{val}}}\\Big[g\\Big(f_{\\mathrm{LLM}}\\big(P(x)\\big),y\\Big)\\Big],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $f_{\\mathrm{LLM}}(\\cdot)$ denotes a textual LLM output given input and $\\mathcal{P}$ denotes the search space, whose definition allows a broad categorization of APO methods into instruction optimization methods targeting instructions in Fig. 2, exemplar optimization methods targeting exemplars in Fig. 2 and approaches that tackle both. ", "page_idx": 2}, {"type": "text", "text": "Exemplar optimization (EO). Efforts to optimize exemplars started soon after the discovery of in-context learning (ICL) [6] via retrieval-based approaches to identify the closest labeled examples [28, 61, 51, 64], influences and sensitivity [31, 8], and learning-based approaches [58, 55]. Toolkits like DSPy [21] adopt EO as the main APO paradigm. Works [45, 46, 60, 22, 41, 59] have also extended EO to model-generated exemplars in LLMs and multimodal models. Lastly, by framing EO from an active learning angle, Margatina et al. [29] provide a comprehensive understanding and comparative analyses. These works, however, principally analyze different EO strategies only, nor do they analyze from the angle of APO. Many of these works also primarily focus on and draw findings from earlier and simpler tasks that are arguably less challenging to SoTA LLMs. ", "page_idx": 2}, {"type": "text", "text": "Solve the following math problems by following the steps:   \n1. When multiplying or dividing two negative numbers, the result will be positive.   \n2. When multiplying or dividing a positive and a negative number, the result will be negative.   \n3. When adding or subtracting a   \nnegative number, it is the same as adding or subtracting its positive counterpart.   \n((6 - 0 \\* 5 + -3) \\* (6 - -7 + -2 - -7)) =   \n(6 - 0 + -3) \\* (6 - -7 + -2 - -7)   \n3 \\* (13 + -2 + 7)   \n3 \\* 18 ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "<answer>54</answer> ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "$((8^{\\star}\\,9^{\\star}\\,0\\,-\\,-1)\\,-\\,(-9\\,-\\,-7\\,+\\,-4\\,-8))=$   \n$1.8\\times9\\times0--1=0+1=1$   \n$2.-9--7+-4-8=-9+7-4-8=-14$   \n3 $3.7-(-14)=1+14=15$   \n<answer>15</answer> ", "page_idx": 2}, {"type": "text", "text": "Figure 2: An example prompt: instruction $I$ describes the task; exemplars $(e_{1},...,e_{k}$ , $k\\ =\\ 1$ in the figure) provide demonstrations and enable ICL; both are prepended to the query $x$ before receiving the LLM responses. ", "page_idx": 2}, {"type": "text", "text": "Instruction optimization (IO). On black-box LLMs, the origin of IO may be traced to discrete prompt search [12, 40, 53, 62, 34] which prepend optimized tokens, which can be viewed as a form of \u201cinstructions\u201d, to inputs. However, these approaches do not necessarily yield interpretable prompts and most of them require output signals (such as logits) beyond strictly black-box access. Thus, recent advances have shifted towards utilizing an LLM itself to generate natural language instructions for iterative optimization on $\\mathcal{D}_{\\mathrm{val}}$ in Eq. 1. The seminal works is APE [66], which employs the LLM to iteratively cull top-performing instructions on $\\mathcal{D}_{\\mathrm{val}}$ and paraphrase them until convergence. Similar evolutionary frameworks are widely used in follow-up works [16, 19, 63] and alternative formulations like Bayesian optimization (BO) [7] and neural bandits [25] were also used. Another line of works [35, 48, 56, 42] employ reflection, directing an LLM to articulate reasons for errors to iteratively improve instructions. Other approaches like OPRO and its variants [54, 27], treat the LLM as a black-box optimizer, tasking it with generating new instructions based on the trajectory of previously evaluated instructions and their performances without explicit meta-instructions. ", "page_idx": 2}, {"type": "text", "text": "Combining EO and IO. As discussed in $\\S1$ , there is a relative dearth of work combining EO and IO despite their shared objective. Specifically, even when the labeled dataset $\\mathcal{D}_{\\mathrm{val}}$ is a prerequisite of virtually all IO methods, it is primarily used to estimate the expectation in Eq. 1 only rather than to construct exemplars in a principled way: For instance, ProTeGi [35] randomly samples exemplars from $\\mathcal{D}_{\\mathrm{val}}$ , while OPRO [54] uses them only for instruction induction [18]. Other works [16, 66, 48] either use no exemplars or fix exemplars and only optimize the instructions \u2013 for challenging reasoning tasks, these methods require human-annotated chain-of-thought (CoT) exemplars [50] in addition to $\\mathcal{D}_{\\mathrm{val}}$ , which arguably runs counter to the goal of automatically designing prompts without human intervention in APO. A few exceptions exist: PromptBreeder [14] employs \u201ccontext shuffling\u201d to co-evolve exemplars and instructions, while Mixture-of-Prompts (MoP) [47] aligns exemplars with multiple prompting \u201cexperts\" for joint optimization. However, these works still focus their optimization effort on instructions: PromptBreeder emphasizes complex mutation operators for IO while providing only basic EO frameworks, whereas MoP chiefly focuses on IO with the bulk of its contribution being assigning optimized instructions to different exemplar groups, rather than optimizing the exemplars themselves. Other works [13, 57] also include both exemplars and instructions in the search space, but they require information beyond strictly black-box outputs to some extent. Lastly, several works have analyzed the interplay between ICL and instructions [30] or prompt templates [39], but they mainly characterize the performance variation as an issue deserving attention. We, however, consider the APO setup specifically, and argue that such an interdependence presents an opportunity through holistically considering instructions and exemplars. Concurrent to our work, Agarwal et al. [2] and Opsahl-Ong et al. [32] also study the joint optimization of instructions and exemplars, and in many cases reached conclusions corroborating our findings, demonstrating the community\u2019s growing awareness on the importance of the subject of focal interest to this paper. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3 Understanding Instruction Optimization and Exemplar Optimization ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "While studying IO and EO independently has academic value, the practical goal ultimately for both is to optimize the performance of LLMs. Hence, IO and EO, as two dominant genres of APO methods, present practitioners with the challenge of selecting or combining them to maximize cost-performance benefits. We aim to meet this by evaluating EO and IO in the context of APO by answering the following: 1) What is the relative importance and performance impact of EO and IO, both in isolation and when combined together? 2) How do we make the optimal use of the limited data and computational budget under the current APO framework? ", "page_idx": 3}, {"type": "text", "text": "3.1 Experimental Setup ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We perform thorough experiments employing various EO and IO methods individually and in combination. We use the PaLM 2 text-bison-002 [4] and Gemini 1.0 Pro/1.5 Flash [15, 36] as the target models, but we will also validate key findings on GPT-3.5. Modern IO methods often employ another, usually more potent optimizer model for to generate and/or critique instructions; we use PaLM 2 text-unicorn-001 (for text-bison target model), Gemini 1.0 Ultra (for Gemini 1.0 Pro target model) or Gemini 1.5 Pro (for Gemini 1.5 Flash target model). We evaluate on tasks selected from BIG-Bench Hard (BBH) [43], a collection of diverse tasks considered to be challenging to LLMs \u2013 the suite itself and datasets of similar task types are frequently used in many recent APO works [48, 54, 19, 14, inter alia]: the tasks include numerical reasoning, commonsense problemsolving, logical deduction, linguistic manipulation, machine translation, and tabular reasoning, among others. For all tasks, we use $20\\%$ of data as validation set and the remaining $80\\%$ for testing, the latter of which is held-out and unavailable to the LLM at search time (see App. A for implementation details). We also test some of our key findings on the MMLU benchmark [17], a set of 57 tasks frequently used to gauge the general problem-solving abilities of LLMs \u2013 we use the official val and test splits for validation and testing, respectively. We consider the following IO strategies: ", "page_idx": 3}, {"type": "text", "text": "1. No IO: we use the seed instruction $I_{0}$ \u201cLet\u2019s think step by step.\u201d [23] without any optimization. 2. APE [66] is the seminal work for LLM-as-an-instruction-optimizer and uses an evolutionary algorithm design: at each iteration, we evaluate a population of instructions on the validation set and the optimizer is asked to generate a new population by paraphrasing the top-performing instructions. This process iterates until convergence. ", "page_idx": 3}, {"type": "text", "text": "3. ProTeGi [35] collects samples that the target LLM answers incorrectly on $\\mathcal{D}_{\\mathrm{val}}$ under the current instruction and directs the optimizer LLM to reflect and critique it. The optimizer model is then asked to update the instruction by summarizing and abstracting the feedback. Additionally, at each iteration, ProTeGi also paraphrases instructions similar to APE (referred to as \u201cMonte Carlo sampling\u201d) and uses beam search to identify the most promising instructions. ", "page_idx": 3}, {"type": "text", "text": "4. PromptAgent [48] is similar to ProTeGi but it features a more advanced planning agent using Monte Carlo tree search [10]. ", "page_idx": 3}, {"type": "text", "text": "5. OPRO [54] implicitly optimizes instructions. Starting from the seed instruction, at each iteration, OPRO provides the optimizer model a concatenation of previously evaluated instructions and their validation scores. Instead of explicitly requesting paraphrasing or reflection, OPRO treats the optimizer LLM as a black-box optimizer and simply asks the optimizer model to \u201ccome up with a better instruction\u201d given these information. ", "page_idx": 3}, {"type": "text", "text": "The above methods are selected as each of them represents the state of the art of a genre of approaches as outlined in $\\S2$ and collectively represents IO techniques as a whole. We initialize each method at the seed instruction and ensure they consume the same amount of compute measured by the number of prompt evaluations on $\\ensuremath{\\mathcal{D}_{\\mathrm{val}}}\\;m$ (we cap $m=32$ except for \u201cNo IO\u201d which requires no iteration). We also compare against PromptBreeder [14] in a later section, as it features a much more expansive search space and requires significantly more than 32 iterations before convergence. After obtaining the optimized instruction $I^{*}$ (or $I_{0}$ if no IO is performed), we perform EO. At this point, we emphasize that our setup should not be confused with the \u201cfew-shot\u201d setup considered by some prior works [66, 16] which require additional human-annotated exemplars with reasoning traces to elicit CoT behavior. We perform EO only from the exemplars self-generated by the target model (also referred to as \u201cbootstrapped few-shot\u201d in DSPy [21] and \u201creinforced ICL\u201d in concurrent works like Agarwal et al. [3]) and do not assume exemplars are given at the start of APO (i.e., we do not assume the presence of initial $\\{e_{1},...,e_{k}\\}$ in $P(x),$ ). We consider the following EO strategies: ", "page_idx": 3}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/342129dbd1dcd8f9fbab443cf06accbdfde4b6270cd730cb3124ef44e9c046d7.jpg", "img_caption": ["Figure 3: Appropriate $E O$ improves over any or no $I O$ : Task-specific BBH performance with no instruction optimization (left) and with SoTA $I O$ : APE (middle) and ProTeGi (right) before and after applying exemplars found via Mutation (\u00a73.1) on PaLM 2. Dashed and solid lines denote the average performance before and after exemplars, respectively. Task index is determined by the ascending order of test accuracy under seed instruction. Refer to additional visualization in App. B.3. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "1. No EO: no exemplars are used; this is typically referred to as \u201czero-shot\u201d in the APO literature. 2. Random: we randomly sample $k$ input-output pairs from $\\begin{array}{r}{\\mathcal{D}_{c}(I^{*})\\;\\subseteq\\;\\mathcal{D}_{\\mathrm{val}}}\\end{array}$ , the subset to the validation set that the target LLM predicted correctly under $I^{*}$ and the output in this case includes any intermediate output the LLM generates before the final answer. ", "page_idx": 4}, {"type": "text", "text": "3. Nearest: We use the same $\\mathcal{D}_{c}(I^{*})$ as above, but instead of sampling randomly, we retrieve top- $k$ input-output pairs whose inputs are most similar to the current test input based on text embedding cosine similarity. We use the Gecko embedding [24]. 4. Diversity: We use $\\mathcal{D}_{c}(I^{*})$ but select the $k$ input-output pairs closest to the centroids via $k$ -means clustering, similar to the approach in Zhang et al. [60] to promote diversity in exemplars. 5. All exemplars (Gemini 1.5 target models only): With the advent of long-context models like Gemini 1.5, we may also fit the entire set of $\\mathcal{D}_{c}$ into the context and perform no selection at all. ", "page_idx": 4}, {"type": "text", "text": "The above heuristic-based EO strategies do not use $\\mathcal{D}_{\\mathrm{val}}$ , whereas optimization-based EO can utilize it similarly to IO. Instead of generating instructions, we select the exemplar combinations with the highest validation accuracy for testing [33, 20, 21]. Unlike IO, which creates new instructions via an optimizer model, EO selects from pre-generated outputs and does not require an optimizer model. Formally, we focus on optimizing exemplars conditional on $I^{*}$ from IO (or $I_{0}$ if no IO is involved)3: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{E^{*}=\\{e_{j}^{*}\\}_{j=1}^{k}=\\arg\\operatorname*{max}_{e_{1},\\dots,e_{k}\\in\\mathcal{E}}\\mathbb{E}_{(x_{i},y_{i})\\sim\\mathcal{D}_{\\mathrm{val}}}\\Big[g\\big(f_{\\mathrm{LLM}}\\big(I^{*},\\{e_{j}\\}_{j=1}^{k},x_{i}\\big),y_{i}\\big)\\Big]}\\\\ &{\\quad\\mathrm{s.t.}\\ I^{*}=\\arg\\underset{I\\in\\mathcal{L}}{\\operatorname*{max}}\\mathbb{E}_{(x_{i},y_{i})\\sim\\mathcal{D}_{\\mathrm{val}}}\\Big[g\\big(f_{\\mathrm{LLM}}\\big(I,x_{i}\\big),y_{i}\\big)\\Big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We include the following optimization-based EO methods that differ in search strategy: ", "page_idx": 4}, {"type": "text", "text": "6. Random search: Following the EO procedure in DSPy [21], we randomly sample $m$ combinations of $k$ exemplars: $\\{E_{1},...,\\bar{E}_{m}\\}$ where each $E_{\\ell}\\,=\\,\\bigl\\{\\bar{e}_{j}^{\\ell}\\bigr\\}_{j=1}^{k}\\,\\forall\\,\\ell\\,\\in\\,\\bigl\\{1,...,m\\bigr\\}$ . We evaluate each combination on the validation set and use the best for testing. ", "page_idx": 4}, {"type": "text", "text": "7. Mutation: We also implement a mutation-based baseline, initiating with a population of $Q$ combinations for $T=\\bar{m}/Q$ generations, where $Q=8$ . Each generation starts with a randomly ", "page_idx": 4}, {"type": "text", "text": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No $I O$ and/or No $E O$ baseline of the respective row/column. The background shades indicate cost in terms of $\\#$ prompt evaluations on $\\mathcal{D}_{\\mathrm{val}}$ by the target model: gray cells requires no evaluation on $\\mathcal{D}_{\\mathrm{val}}$ $(m\\,=\\,0)$ ) ; blue cells perform $m\\:=\\:32$ evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars $m$ times on top of optimized instructions. ", "page_idx": 5}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/179af4cde949a735a211c989313517d3b465077c01b8c6d668a1354e8f847e40.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Table 2: Average BBH accuracy of seed instruction $(N o\\,I O)$ Table 3: Average MMLU accuracy and ProTeGi (best IO strategy from Table 1) with different of No IO and ProTeGi with different EO strategies using Gemini $\\bf{\\bar{1.0}\\,P r o}$ target model and Gem- EO strategies with text-bison target ini 1.0 Ultra optimizer model. Refer to Table 1 for further model and text-unicorn optimizer explanations. model. See App B.2 for Gemini results. ", "page_idx": 5}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/01b4f20b5e9dda7311585bca775a3b34c1c5ce1875ce15eb6b6080a3a2897d5f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Table 4: Average BBH accuracy of seed instruction $(N o\\,I O)$ , APE and ProTeGi (top 2 IO strategies from Table 1) with different EO strategies using Gemini 1.5 Flash target model and Gemini 1.5 Pro optimizer model. Refer to Table 1 for further explanations. ", "page_idx": 5}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/00b77a3a0f0db21d5e3344b35088325c4d6a20995eee2cd1a96c1c48281d8300.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "initialized first generation, similar to random search. For subsequent generations, we populate with $Q$ mutations of the best-performing combination from the previous generation, $E_{\\leq t}^{*}$ . Each mutation involves swapping one exemplar for another input-output pair from $\\mathcal{D}_{c}$ . ", "page_idx": 5}, {"type": "text", "text": "For all EO methods except for \u201cAll exemplars\u201d, we use $m=32,k=3$ for all main experiments, but we also test with $k=\\{1,3,5,10,20\\}$ in App. B.4. Given the IO and EO strategies, we experiment on each of the IO-EO combinations. ", "page_idx": 5}, {"type": "text", "text": "3.2 Results and Analyses ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "On BBH, we aggregate the results in Table 1 for PaLM 2 models. We also experiment on Gemini models with no $I O$ and with ProTeGi (best overall IO technique from the PaLM 2 results) in Table 2 (Gemini 1.0) and Table 4 (Gemini 1.5). We also validate key findings in representative datasets on GPT-3.5 (Table 13, App B). On MMLU, we present results in Table 3 (PaLM 2) and App. B.1 (Gemini). Below, we highlight and discuss the key insights. ", "page_idx": 5}, {"type": "text", "text": "Insight 1: We should almost always perform EO whenever we perform APO. ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "One of the immediate findings from the tables is that comparing the first column against others, any EO consistently improves test performance, with any or no instruction optimization. In Fig. 3, we further show that the EO not only benefits at an aggregated level but also leads to significant and almost unanimous improvements across diverse tasks. ", "page_idx": 5}, {"type": "text", "text": "While exemplars improving performance may not seem surprising, it is worth noting that as mentioned, in this case they are side-products of evaluating instructions on $\\mathcal{D}_{\\mathrm{val}}$ with no additional data costs. Thus, we argue that for practical purposes under the framework of Eq. 1, barring unusual constraints like extreme restrictions in context length, which This might restrict applicability of IO methods too as many SoTA IO methods also generate long prompts, and/or extreme long-context tasks where it is not possible to fit exemplars in the context window, there is little incentive to consider the \u201czero-shot\u201d setup without exemplars and little incentive not to perform EO, given that current APO setup requires $\\mathcal{D}_{\\mathrm{val}}$ anyway, regardless of whether we use them as exemplars. Thus, it is by definition, not \u201czero-shot\u201d and is not directly comparable to true zero-shot methods requiring no labeled data. Furthermore, there is also the risk that \u201czero-shot\u201d results neither reflect nor accurately predict the full potential of the LLM, as what performs well under zero-shot does not necessarily performs well when a better EO strategy (e.g., PromptAgent in Table 1 and ProTeGi in Table 3) is used. Lastly, since obtaining labeled data can be costly, intelligently reusing them as exemplars also represents a more judicious use of scarce resources compared to only using them to evaluate a metric for optimization. ", "page_idx": 5}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/9f03fd9ce1e5321f65350e74d926ab24f4ad4bd60c2a6b2d8c5799722e407134.jpg", "img_caption": ["Figure 4: Optimized exemplars generalize better than optimized instructions. Comparison of validation accuracy and test accuracy over different model-task combinations. The generalization gap, which is the difference between validation and test accuracy, is marked on each figure. The better generalization of EO is exemplified by the smaller generalization gaps in all cases studied. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Insight 2: How we select exemplars may outweigh how we optimize instructions, and selecting exemplars via iterative optimization consistently outperforms alternative strategies. ", "page_idx": 6}, {"type": "text", "text": "Exemplar optimization outweighs instruction optimization. Despite the recent focus the community places on IO, we find that how we select exemplars outweighs how we optimize instructions in the model-task combinations we investigate. With reference to Tables 1 \u2013 4 (and task-specific breakdown in Fig. 5), we find that if we optimize instructions or exemplars (i.e., the blue cells) under a roughly compute-matched budget, prompts without instruction optimization but with optimized exemplars (e.g., the \u201cNo IO $^+$ Mutation\u201d combination) outperform prompts with SoTA instruction optimization but without optimized exemplars (e.g., the \u201cProTeGi $^+$ Random\u201d combinations) in an overwhelming majority of cases. In fact, on a separate set of experiments performed on the PaLM 2 models, we find this to be true even after halving the evaluation budget of $E O$ (see App. B.6), and optimization on exemplars as na\u00efve as random search can outperform IO methods that are significantly more complicated and expensive. Further substantiating this argument are that: ", "page_idx": 6}, {"type": "text", "text": "1) In isolation, EO boosts performance more effectively than IO: for example, with reference to Table 2, compared to the seed prompt, using the best EO strategy (Mutation, first row) alone increases the average performance by ${>}11\\%$ , compared to approximately $8\\%$ using the best IO strategy (ProTeGi, first column); ", "page_idx": 6}, {"type": "text", "text": "2) When combined, beneftis of EO and IO stack up but are largely attributable to EO: under \u201cMutation\u201d (last column), the best EO strategy, the performance gap between the best and worst IO strategies shrinks to less than $4\\%$ , suggesting that instructions might be less critical if the LLM is provided with good exemplars after all. ", "page_idx": 6}, {"type": "text", "text": "We observe similar conclusions for different models and task combinations. In fact, on MMLU (Table 3) featuring much smaller validation splits, we observe that judicious exemplar optimization completely eliminates the performance gap caused by IO under zero-shot, with No IO even surpassing SoTA IO. Interestingly, as we show in Fig. 4 where we further consider the difference between validation accuracy, which is the empirical objective function in Eq. 1, and the test accuracy, which is the reported metric that represents the generalization power of the optimized prompt, optimized exemplars generalize better than optimized instructions under all model-task combinations considered. On MMLU tasks (two rightmost plots in Fig. 4), IO even improves validation performance comparable to or better than EO, but the validation improvement does not generalize to the test set. These imply that the superior test performance of EO cannot be solely attributed to a more effective search space $\\mathcal{P}$ or optimization strategy in Eq. 1, and the performance gap might not be completely closed by advancing optimization only. ", "page_idx": 6}, {"type": "text", "text": "Optimization-based EO outperforms heuristics. Between the different EO strategies, we find that optimization-based EO vastly outperform the alternatives: e.g. in all tables, ProTeGi with optimized ", "page_idx": 6}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/03d5f131f434d1bd1940f03ccac91f45125de0fc58961d5e7179ec2055ec7b48.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 5: Task-specific BBH performance of selected IO-EO combinations with PaLM 2 (first 12 tasks; refer to App. B.3 for all other tasks/models). Note that 1) Proper EO almost uniformly improves performance and 2) With appropriate exemplars, seed instructions with no optimization (third bar from the right) can often perform on par or better than SoTA IO but with standard random exemplars or no exemplars commonly used in the literature (first six bars in each figure). ", "page_idx": 7}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/b317c8ccb9cdfa9324c0d3bdd7643bb2cc996fc509f5eeca21c7b3212c2f5f14.jpg", "img_caption": [], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 6: \u201cWinning\u201d exemplars that led to exceedingly high performance: (a, b) LLM improves by almost $50\\%$ from imitating and chaining the patterns in the optimal exemplars. (c) When CoT hurts performance, optimal exemplars encourage LLMs to override instructions and answer directly. Refer to App. B.9 for examples of LLM responses when these exemplars are applied. ", "page_idx": 7}, {"type": "text", "text": "exemplars outperforms random exemplars, which is the default design in Pryzant et al. [35], by more than $6\\%$ in both Table 1 and 2 and more than $2\\%$ in Table 4. Interestingly, as shown by the \u201cAll\u201d column in Table 4 for Gemini 1.5 and App. B.4 for Gemini 1.0, na\u00efvely scaling the number of exemplars may not be the most effective \u2013 the fact using the entire $\\mathcal{D}_{c}$ underperforms 3 optimized exemplars, which are a subset of $\\mathcal{D}_{c}$ , highlights the relevance of EO even for modern LLMs capable of handling long context windows. On the other hand, heuristic-based selection like Diversity and Nearest do not consistently outperform simple random baseline, echoing previous findings [33]. ", "page_idx": 7}, {"type": "text", "text": "Imitation of task-dependent winning patterns outweighs elaborate descriptions. We further present representative prompts in Fig 6 and how LLM responds to them in App. B.9: Generally, we find that even detailed and task-specific instructions do not regulate the LLM\u2019s behavior as effectively as exemplars, which enable imitation. For example, for challenging tasks like tracking_shuffled_objects and web_of_lies, optimization-based EO discover \u201cwinning\u201d templates that, when followed, improve performance massively. Even when SoTA IO methods may often state the answer steps equivalently in words, we find LLMs to simply respond better to exemplars from which they can copy behaviors. On the other hand, for tasks where CoT-style answering are known to be unhelpful (e.g., snarks) [43], the optimized exemplars are invariably those giving direct answers; when prepended to the test queries, LLMs tend to prioritize exemplar imitation over instruction following to answer directly despite triggers like \u201cWe should move forward in stages\u201d. These highly task-dependent \u201cwinning\u201d patterns that vary from elaborate step-to-step reasoning to direct answering may also explain why heuristic-based EO fares worse to data-driven approaches, since there might not be a single heuristic universally useful for all tasks. ", "page_idx": 7}, {"type": "text", "text": "Concluding remarks. We argue that the findings are highly significant for the future of APO. First, they point to a need of re-balancing: without disparaging the value of IO, we argue that EO is at least equally crucial and should not be relegated to an afterthought. Second, we note that the EO strategies studied are in no way exhaustive. In fact, in contrast to the sophisticated search and instruction generation approaches adopted by IO methods, they can even be considered elementary. Yet, they deliver comparable or more significant improvements. Thus, we anticipate advanced methods that more effectively optimize exemplars would yield even greater enhancements: some techniques in IO may be adapted to EO with little-to-no modifications. For example, many recent advances in IO adopt an evolutionary search framework \u2013 while our \u201cMutation\u201d baseline can be seen as an elementary version of it in EO, it should be also straightforward to use more advanced search strategies and operators or use techniques like LLM-generated paraphrasing on top of selected exemplars. Other search techniques, such as sample-efficient combinatorial BO [5, 44, 11, 65], can be uniquely suitable for the EO setup, which is itself a combinatorial optimization problem4. Furthermore, while we used a fixed set of exemplars (i.e., task-wise selection), it might also be fruitful to further explore in the direction of instance-wise selection [51, 37]. Lastly, as discussed, the presence of (often large) generalization gap also suggests the importance to consider generalization alongside optimization, which seems to be the chief focus thus far; it might be promising to investigate analogies of well-tested in classical machine learning like regularization and cross-validation in APO. ", "page_idx": 7}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/bcd81b1cfa24f8e4d48a468b89df1c06cfcf337628b092434a1c05685463636f.jpg", "img_caption": ["Figure 7: Mixing-and-matching EO and IO outperforms either alone under a similar budget. Top figure: Validation accuracy vs. # evaluations on $\\mathcal{D}_{\\mathrm{val}}$ with PaLM 2 in selected tasks if we optimize instructions only (via APE), exemplars only (Mutation), or both (first 8 evals for IO (purple shade) $^+$ remaining 24 for EO). Gray dashed lines denote the performance of $I_{0}$ . Bottom table: Test accuracy averaged across all tasks for different IO/EO budget allocations for PaLM 2 and Gemini 1.5. \u2020Used best APE results without EO that incur additional evaluations. Refer to App. B.7 for all per-task results and additional results on Gemini $1.0\\,\\mathrm{Pro}$ and other instruction optimizers. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Insight 3: Optimizing both instructions and exemplars is greater than the sum of its parts, even under a comparable computational budget. ", "page_idx": 8}, {"type": "text", "text": "For most of the results obtained, we note that iteratively optimizing both instructions and exemplars led to the best performance. This naturally leads us to answer the second research question: whereas experiments in Tables 1 and 2 expend additional cost by optimizing exemplars on top of the optimized instructions, we show that 1) such a combinable benefti does not simply root from the additional compute and 2) optimally mixing-and-matching IO and EO leads to significant performance improvement with negligible additional overhead. ", "page_idx": 8}, {"type": "text", "text": "Concretely, we budget a total $\\textit{m}=\\textit{32}$ prompt evaluations on $\\mathcal{D}_{\\mathrm{val}}$ where we use first $m_{\\mathrm{IO}}{=}\\{0,\\!8,\\!16,\\!24,\\!32\\}$ iterations optimizing instructions and the remaining $m_{\\mathrm{EO}}$ optimizing exemplars. We summarize the results in Fig. 7, where we find that 1) any mix-and-match outperforms IO or EO only (i.e., $\\scriptstyle m_{\\mathrm{IO}}=0$ or 32), and 2) the best allocation bridges the gap or almost bridges the gap compared to the combination that uses twice as many prompt evaluations (last column) \u2013 interestingly, in this case the optimal allocation also roughly reflects the relative contribution of IO and EO to the overall performance improvement in Table 1. We show in App. B.7 that the above findings hold for other target models and instruction optimizers, and we also give detailed examples and explanations of the mechanism leading to this synergy. Additionally, in App. B.10, we compare this simple routine against PromptBreeder [14], which is one of the few existing IO methods that supports EO via an optional \u201ccontext shuffling\u201d routine. It, however, mutates the exemplars purely stochastically rather than optimizing from the validation metric. We show that despite the simplicity, our algorithm converges to comparable or better solutions while incurring a fraction of the PromptBreeder cost, which often requires hundreds of evaluations before convergence. Finally, we note that the presented way to combine optimization-based IO and EO is a proof of concept and room for future improvement can be vast and we experiment several other alternative ways to combine them in App. B.8, but we defer thorough investigations to a future work. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Insight 4: SoTA IO methods may be inadvertently relying on exemplars already. ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Beyond inspecting performance metrics only, we also examine the actual instructions and exemplars discovered. While detailed prompts are available in App. C, we highlight a key observation that adds a new dimension to our discussion: SoTA IO strategies may inadvertently utilize exemplars already. Despite IO methods not typically explicitly focusing on exemplars, we find them to frequently generate texts resembling exemplars within instructions through feedback and reflection processes. For instance, PromptBreeder employs \u201cLamarckian mutation\u201d to reconstruct instructions from inputoutput pairs, while ProTeGi prompts the optimizer model to analyze target model errors. These operators, though varied, all involve taking actual validation exemplars as inputs to optimizer models. As exemplified by Fig. 8, while the original intention may have been to abstract task-level instructions, the model occasionally incorporates these exemplars verbatim in the instructions. Whereas these \u201cquasi-exemplars\u201d may seem unintentional, we observe that they are surprisingly common in highperforming instructions and often contribute more to the performance than the actual instructions themselves. Full prompt: $84.5\\%$ ", "page_idx": 9}, {"type": "text", "text": "We argue that the findings here provide further evidence corroborating our insights obtained so far and our suggestions advocating explicit EO. Indeed, in contrast to explicit optimization of the exemplars, the aforementioned mechanism of exemplar discovery via IO is entirely opportunistic and, depending on interpretation, an unintentional artifact. For example, the quasi-exemplars in Fig. 8 almost certainly originate from the optimizer model in ProTeGi taking a convenient shortcut by incorporating a critique into the instruction verbatim (note the presence of traces like \u201cLabel: a Prediction: b\u201d which suggests a previous mistake by the target model), which should not happen if the optimizer model perfectly executes the intended task of abstracting these critiques. Thus, we argue that instead of relying on the opportunistic exemplar generation via IO, explicitly optimizing for exemplars can be more preferable, as shown throughout this study. ", "page_idx": 9}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/a4f63ad855621fc4a67fbd195369d182bdc2488332be40ce56bf511c99525e7e.jpg", "img_caption": ["Figure 8: The best instructions might actually be exemplars: Best instruction discovered by ProTeGi on hyperbaton where spontaneously discovered \u201cquasi-exemplars\u201d are highlighted. We also edit the instructions to either remove or retain the higlighted parts and find these quasi-exemplars, rather than the rest of the instruction, drive the performance. See App. B.11 for more examples. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "4 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We present comprehensive evaluations on the SoTA IO and EO methods, both individually and combined. We demonstrate that EO can be a potentially more crucial element in APO, revealing a beneficial synergy through joint optimization with IO. We also find that the high performance of SoTA IO methods can themselves be driven by implicit yet spontaneous exemplar discovery. Overall, we advocate for further research into EO, both as an independent approach and in conjunction with IO, even for highly-capable instruction-following modern models. One limitation is that although the tasks we consider are fairly diverse and findings on it are already of value given the widespread interest just on these tasks only, they are not exhaustive, omitting tasks like open-ended longer-form generation and metrics like safety & harmfulness which are important for responsible use of LLMs. As is the case for any inductive study deriving insights from experiments, there is also a possibility that the findings may not fully generalize to other tasks and/or models. Expanding to include these aspects would be important for future work. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We thank all colleagues from Google Cloud AI Research for their feedback. We would also like to thank the anonymous NeurIPS reviewers and area chairs, whose valuable comments have helped to improve our paper. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Achiam, J., Adler, S., Agarwal, S., Ahmad, L., Akkaya, I., Aleman, F. L., Almeida, D., Altenschmidt, J., Altman, S., Anadkat, S., et al. GPT-4 technical report. arXiv preprint arXiv:2303.08774, 2023.   \n[2] Agarwal, E., Dani, V., Ganu, T., and Nambi, A. Promptwizard: Task-aware agent-driven prompt optimization framework. arXiv preprint arXiv:2405.18369, 2024.   \n[3] Agarwal, R., Singh, A., Zhang, L. M., Bohnet, B., Chan, S., Anand, A., Abbas, Z., Nova, A., Co-Reyes, J. D., Chu, E., et al. Many-shot in-context learning. arXiv preprint arXiv:2404.11018, 2024.   \n[4] Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri, S., Taropa, E., Bailey, P., Chen, Z., et al. Palm 2 technical report. arXiv preprint arXiv:2305.10403, 2023.   \n[5] Baptista, R. and Poloczek, M. Bayesian optimization of combinatorial structures. In International Conference on Machine Learning, pp. 462\u2013471. PMLR, 2018. [6] Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language models are few-shot learners. Advances in neural information processing systems, 33:1877\u20131901, 2020.   \n[7] Chen, L., Chen, J., Goldstein, T., Huang, H., and Zhou, T. Instructzero: Efficient instruction optimization for black-box large language models. arXiv preprint arXiv:2306.03082, 2023.   \n[8] Chen, Y., Zhao, C., Yu, Z., McKeown, K., and He, H. On the relation between sensitivity and accuracy in in-context learning. arXiv preprint arXiv:2209.07661, 2022.   \n[9] Chowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. Journal of Machine Learning Research, 24(240):1\u2013113, 2023.   \n[10] Coulom, R. Efficient selectivity and backup operators in monte-carlo tree search. In International conference on computers and games, pp. 72\u201383. Springer, 2006.   \n[11] Daulton, S., Wan, X., Eriksson, D., Balandat, M., Osborne, M. A., and Bakshy, E. Bayesian optimization over discrete and mixed spaces via probabilistic reparameterization. Advances in Neural Information Processing Systems, 35:12760\u201312774, 2022.   \n[12] Deng, M., Wang, J., Hsieh, C.-P., Wang, Y., Guo, H., Shu, T., Song, M., Xing, E., and Hu, Z. RLPrompt: Optimizing discrete text prompts with reinforcement learning. In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 3369\u20133391, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.222. URL https://aclanthology.org/2022.emnlp-main.222.   \n[13] Do, X. L., Zhao, Y., Brown, H., Xie, Y., Zhao, J. X., Chen, N. F., Kawaguchi, K., Xie, M. Q., and He, J. Prompt optimization via adversarial in-context learning. arXiv preprint arXiv:2312.02614, 2023.   \n[14] Fernando, C., Banarse, D., Michalewski, H., Osindero, S., and Rockt\u00e4schel, T. Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint arXiv:2309.16797, 2023.   \n[15] Gemini team, Anil, R., Borgeaud, S., Wu, Y., Alayrac, J.-B., Yu, J., Soricut, R., Schalkwyk, J., Dai, A. M., Hauth, A., et al. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805, 2023.   \n[16] Guo, Q., Wang, R., Guo, J., Li, B., Song, K., Tan, X., Liu, G., Bian, J., and Yang, Y. Connecting large language models with evolutionary algorithms yields powerful prompt optimizers. International Conference on Learning Representations, 2024.   \n[17] Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.   \n[18] Honovich, O., Shaham, U., Bowman, S. R., and Levy, O. Instruction induction: From few examples to natural language task descriptions. In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1935\u20131952, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.108. URL https://aclanthology.org/2023.acl-long.108.   \n[19] Hsieh, C.-J., Si, S., Yu, F. X., and Dhillon, I. S. Automatic engineering of long prompts. arXiv preprint arXiv:2311.10117, 2023.   \n[20] Khattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. Demonstrate-search-predict: Composing retrieval and language models for knowledge-intensive nlp. arXiv preprint arXiv:2212.14024, 2022.   \n[21] Khattab, O., Singhvi, A., Maheshwari, P., Zhang, Z., Santhanam, K., Vardhamanan, S., Haq, S., Sharma, A., Joshi, T. T., Moazam, H., et al. DSPy: Compiling declarative language model calls into self-improving pipelines. International Conference on Learning Representations, 2024.   \n[22] Kim, H. J., Cho, H., Kim, J., Kim, T., Yoo, K. M., and Lee, S.-g. Self-generated in-context learning: Leveraging auto-regressive language models as a demonstration generator. arXiv preprint arXiv:2206.08082, 2022.   \n[23] Kojima, T., Gu, S. S., Reid, M., Matsuo, Y., and Iwasawa, Y. Large language models are zero-shot reasoners. Advances in neural information processing systems, 35:22199\u201322213, 2022.   \n[24] Lee, J., Dai, Z., Ren, X., Chen, B., Cer, D., Cole, J. R., Hui, K., Boratko, M., Kapadia, R., Ding, W., et al. Gecko: Versatile text embeddings distilled from large language models. arXiv preprint arXiv:2403.20327, 2024.   \n[25] Lin, X., Wu, Z., Dai, Z., Hu, W., Shu, Y., Ng, S.-K., Jaillet, P., and Low, B. K. H. Use your instinct: Instruction optimization using neural bandits coupled with transformers. arXiv preprint arXiv:2310.02905, 2023.   \n[26] Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., and Neubig, G. Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9):1\u201335, 2023.   \n[27] Liu, S., Chen, C., Qu, X., Tang, K., and Ong, Y.-S. Large language models as evolutionary optimizers. arXiv preprint arXiv:2310.19046, 2023.   \n[28] Lu, Y., Bartolo, M., Moore, A., Riedel, S., and Stenetorp, P. Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 8086\u20138098, 2022.   \n[29] Margatina, K., Schick, T., Aletras, N., and Dwivedi-Yu, J. Active learning principles for in-context learning with large language models. In Bouamor, H., Pino, J., and Bali, K. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2023, pp. 5011\u20135034, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023. findings-emnlp.334. URL https://aclanthology.org/2023.findings-emnlp.334.   \n[30] Mizrahi, M., Kaplan, G., Malkin, D., Dror, R., Shahaf, D., and Stanovsky, G. State of what art? a call for multi-prompt llm evaluation. arXiv preprint arXiv:2401.00595, 2024.   \n[31] Nguyen, T. and Wong, E. In-context example selection with influences. arXiv preprint arXiv:2302.11042, 2023.   \n[32] Opsahl-Ong, K., Ryan, M. J., Purtell, J., Broman, D., Potts, C., Zaharia, M., and Khattab, O. Optimizing instructions and demonstrations for multi-stage language model programs. arXiv preprint arXiv:2406.11695, 2024.   \n[33] Perez, E., Kiela, D., and Cho, K. True few-shot learning with language models. Advances in neural information processing systems, 34:11054\u201311070, 2021.   \n[34] Prasad, A., Hase, P., Zhou, X., and Bansal, M. GrIPS: Gradient-free, edit-based instruction search for prompting large language models. In Vlachos, A. and Augenstein, I. (eds.), Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pp. 3845\u20133864, Dubrovnik, Croatia, May 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.eacl-main.277. URL https://aclanthology.org/2023. eacl-main.277.   \n[35] Pryzant, R., Iter, D., Li, J., Lee, Y., Zhu, C., and Zeng, M. Automatic prompt optimization with \u201cgradient descent\u201d and beam search. In Bouamor, H., Pino, J., and Bali, K. (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 7957\u20137968, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023. emnlp-main.494. URL https://aclanthology.org/2023.emnlp-main.494.   \n[36] Reid, M., Savinov, N., Teplyashin, D., Lepikhin, D., Lillicrap, T., Alayrac, J.-b., Soricut, R., Lazaridou, A., Firat, O., Schrittwieser, J., et al. Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024.   \n[37] Rubin, O., Herzig, J., and Berant, J. Learning to retrieve prompts for in-context learning. In Carpuat, M., de Marneffe, M.-C., and Meza Ruiz, I. V. (eds.), Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 2655\u20132671, Seattle, United States, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.naacl-main.191. URL https:// aclanthology.org/2022.naacl-main.191.   \n[38] Sahoo, P., Singh, A. K., Saha, S., Jain, V., Mondal, S., and Chadha, A. A systematic survey of prompt engineering in large language models: Techniques and applications. arXiv preprint arXiv:2402.07927, 2024.   \n[39] Sclar, M., Choi, Y., Tsvetkov, Y., and Suhr, A. Quantifying language models\u2019 sensitivity to spurious features in prompt design or: How i learned to start worrying about prompt formatting. arXiv preprint arXiv:2310.11324, 2023.   \n[40] Shin, T., Razeghi, Y., Logan IV, R. L., Wallace, E., and Singh, S. Autoprompt: Eliciting knowledge from language models with automatically generated prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 4222\u20134235, 2020.   \n[41] Stani\u00b4c, A., Caelles, S., and Tschannen, M. Towards truly zero-shot compositional visual reasoning with llms as programmers. arXiv preprint arXiv:2401.01974, 2024.   \n[42] Sun, H., Li, X., Xu, Y., Homma, Y., Cao, Q., Wu, M., Jiao, J., and Charles, D. Autohint: Automatic prompt optimization with hint generation. arXiv preprint arXiv:2307.07415, 2023.   \n[43] Suzgun, M., Scales, N., Sch\u00e4rli, N., Gehrmann, S., Tay, Y., Chung, H. W., Chowdhery, A., Le, Q. V., Chi, E. H., Zhou, D., et al. Challenging big-bench tasks and whether chain-of-thought can solve them. arXiv preprint arXiv:2210.09261, 2022.   \n[44] Wan, X., Nguyen, V., Ha, H., Ru, B., Lu, C., and Osborne, M. A. Think global and act local: Bayesian optimisation over high-dimensional categorical and mixed search spaces. In International Conference on Machine Learning, pp. 10663\u201310674. PMLR, 2021.   \n[45] Wan, X., Sun, R., Dai, H., Arik, S., and Pfister, T. Better zero-shot reasoning with selfadaptive prompting. In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.), Findings of the Association for Computational Linguistics: ACL 2023, pp. 3493\u20133514, Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.findings-acl.216. URL https://aclanthology.org/2023.findings-acl.216.   \n[46] Wan, X., Sun, R., Nakhost, H., Dai, H., Eisenschlos, J., Arik, S., and Pfister, T. Universal self-adaptive prompting. In Bouamor, H., Pino, J., and Bali, K. (eds.), Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, pp. 7437\u20137462, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023. emnlp-main.461. URL https://aclanthology.org/2023.emnlp-main.461.   \n[47] Wang, R., An, S., Cheng, M., Zhou, T., Hwang, S. J., and Hsieh, C.-J. Mixture-of-experts in prompt optimization. International Conference on Machine Learning, 2024.   \n[48] Wang, X., Li, C., Wang, Z., Bai, F., Luo, H., Zhang, J., Jojic, N., Xing, E. P., and Hu, Z. Promptagent: Strategic planning with language models enables expert-level prompt optimization. International Conference on Learning Representations, 2024.   \n[49] Wei, J., Bosma, M., Zhao, V., Guu, K., Yu, A. W., Lester, B., Du, N., Dai, A. M., and Le, Q. V. Finetuned language models are zero-shot learners. In International Conference on Learning Representations, 2022. URL https://openreview.net/forum?id=gEZrGCozdqR.   \n[50] Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou, D., et al. Chain-of-thought prompting elicits reasoning in large language models. Advances in neural information processing systems, 35:24824\u201324837, 2022.   \n[51] Wu, Z., Wang, Y., Ye, J., and Kong, L. Self-adaptive in-context learning: An information compression perspective for in-context example selection and ordering. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1423\u20131436, 2023.   \n[52] Wu, Z., Lin, X., Dai, Z., Hu, W., Shu, Y., Ng, S.-K., Jaillet, P., and Low, B. K. H. Prompt optimization with ease? efficient ordering-aware automated selection of exemplars. arXiv preprint arXiv:2405.16122, 2024.   \n[53] Xu, H., Chen, Y., Du, Y., Shao, N., Wang, Y., Li, H., and Yang, Z. Gps: Genetic prompt search for efficient few-shot learning. arXiv preprint arXiv:2210.17041, 2022.   \n[54] Yang, C., Wang, X., Lu, Y., Liu, H., Le, Q. V., Zhou, D., and Chen, X. Large language models as optimizers. In International Conference on Learning Representations, 2024.   \n[55] Ye, J., Wu, Z., Feng, J., Yu, T., and Kong, L. Compositional exemplars for in-context learning. In International Conference on Machine Learning, pp. 39818\u201339833. PMLR, 2023.   \n[56] Ye, Q., Axmed, M., Pryzant, R., and Khani, F. Prompt engineering a prompt engineer. arXiv preprint arXiv:2311.05661, 2023.   \n[57] Zhang, T., Wang, X., Zhou, D., Schuurmans, D., and Gonzalez, J. E. Tempera: Test-time prompting via reinforcement learning. International Conference on Learning Representations, 2023.   \n[58] Zhang, Y., Feng, S., and Tan, C. Active example selection for in-context learning. In Goldberg, Y., Kozareva, Z., and Zhang, Y. (eds.), Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 9134\u20139148, Abu Dhabi, United Arab Emirates, December 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.622. URL https://aclanthology.org/2022.emnlp-main.622.   \n[59] Zhang, Y., Zhou, K., and Liu, Z. What makes good examples for visual in-context learning? Advances in Neural Information Processing Systems, 36, 2024.   \n[60] Zhang, Z., Zhang, A., Li, M., and Smola, A. Automatic chain of thought prompting in large language models. International Conference on Learning Representations, 2023.   \n[61] Zhao, Z., Wallace, E., Feng, S., Klein, D., and Singh, S. Calibrate before use: Improving few-shot performance of language models. In International conference on machine learning, pp. 12697\u201312706. PMLR, 2021.   \n[62] Zhou, H., Wan, X., Vulic\u00b4, I., and Korhonen, A. Survival of the most influential prompts: Efficient black-box prompt search via clustering and pruning. In Bouamor, H., Pino, J., and Bali, K. (eds.), Findings of the Association for Computational Linguistics: EMNLP 2023, pp. 13064\u201313077, Singapore, December 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023. findings-emnlp.870. URL https://aclanthology.org/2023.findings-emnlp.870.   \n[63] Zhou, H., Wan, X., Liu, Y., Collier, N., Vuli\u00b4c, I., and Korhonen, A. Fairer preferences elicit improved human-aligned large language model judgments. arXiv preprint arXiv:2406.11370, 2024.   \n[64] Zhou, H., Wan, X., Proleev, L., Mincu, D., Chen, J., Heller, K., and Roy, S. Batch calibration: Rethinking calibration for in-context learning and prompt engineering. International Conference on Learning Representations (ICLR), 2024.   \n[65] Zhou, H., Wan, X., Vuli\u00b4c, I., and Korhonen, A. Autopeft: Automatic configuration search for parameter-efficient fine-tuning. Transactions of the Association for Computational Linguistics, 12:525\u2013542, 2024.   \n[66] Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., and Ba, J. Large language models are human-level prompt engineers. In The Eleventh International Conference on Learning Representations, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: The abstract and instroduction accurately reflect our contributions and scope. Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 15}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Justification: We clearly discuss our limitations in the Conclusion. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 15}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 15}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 15}, {"type": "text", "text": "Justification: The paper does not include theoretical results. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 16}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: We fully disclose the datasets (all datasets are publicly accessible) and the models used (all models have public API). We include all discussions about the implementation details in Appendix. A. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 16}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 17}, {"type": "text", "text": "Answer: [No] ", "page_idx": 17}, {"type": "text", "text": "Justification: While we aim to open-source our experimental code in the future, we cannot open source the codebase at the time of submission. However, many of our experiments derive from existing methods, which can be reproduced by running the respective, opensourced codebase which we outline in Appendix A. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 17}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: We fully disclose the datasets (all datasets are publicly accessible) and the models used (all models have public API). We include all discussions about the implementation details in Appendix. A. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 17}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 17}, {"type": "text", "text": "Answer: [No] ", "page_idx": 17}, {"type": "text", "text": "Justification: While we do not repeat each experiments more than once due to the computational constraints, we perform experiments on a large set of tasks, and insights are largely drawn from the aggregated results averaged over $^{70+}$ different tasks to improve the reliability of our results. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 17}, {"type": "text", "text": "\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 18}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We include all necessary details in Appendix. A. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 18}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We have reviewed and agreed to the NeurIPS code of ethics. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 18}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We include such discussion in the Conclusion. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 19}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: This paper does not release new generative models or scraped datasets but rather derive from existing models and datasets. Therefore, we do not anticipate such risks. Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 19}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We list the license and terms of use in Appendix A. Original creators/owners of all assets used in the paper are properly credited with citations. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: The paper does not release new assets. We entirely use assets that have already been made available. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 20}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 20}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 20}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 21}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "A Implementation Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Input prompt templates. In this section, we outline the input prompt templates we used for all experiments for reproducibility. For seed instruction (i.e., No $I O$ ), APE and OPRO, we adopt the following template for all datasets. ", "page_idx": 22}, {"type": "text", "text": "Q: {{ QUERY_TEXT }} {{ ANSWER_INSTRUCTION }} A: {{ INSTRUCTION }} {{ llm() }} ", "page_idx": 22}, {"type": "text", "text": "In the template above, QUERY_TEXT denotes the input text; INSTRUCTION denotes the instruction to be added, which is the principal optimizable component of IO methods; llm() denotes the location where LLM is prompted to generate an output. ANSWER_INSTRUCTION is a special, taskspecific sentence to ensure the LLM generates the final answer in a format that can be easily parsed. Specifically, for all multiple-choice questions-style tasks, it has the following content: ", "page_idx": 22}, {"type": "text", "text": "Show your final answer option bracketed between <answer $>$ and <\\answer >. ", "page_idx": 22}, {"type": "text", "text": "For all other tasks, the content is:   \nShow your final answer {{ TASK_SPECIFIC_CONSTRAINT }} bracketed between <ans $>$ and <\\ answer >. ", "page_idx": 22}, {"type": "text", "text": "where the content of TASK_SPECIFIC_CONSTRAINT depends on the task: ", "page_idx": 22}, {"type": "text", "text": "\u2022 boolean_expressions: (True or False only)   \n\u2022 formal_fallacies: (valid or invalid only)   \n\u2022 navigate, sports_understanding, causal_judgement, web_of_lies: (yes or no only) \u2022 word_sorting: (sorted words separated by spaces only)   \n\u2022 all other tasks: None (empty string). ", "page_idx": 22}, {"type": "text", "text": "At test time, the final answer is extracted with the capturing pattern <answer>...<\\answer>. When exemplars are added, we use the following template: ", "page_idx": 22}, {"type": "text", "text": "Q: {{ DEMO_1_QUERY_TEXT }} {{ ANSWER_INSTRUCTION }} A: {{ INSTRUCTION }} {{ DEMO_1_OUTPUT }}   \n${4\\:\\:\\mathrm{~}}==$ Q: {{ DEMO_2_QUERY_TEXT }} {{ ANSWER_INSTRUCTION }} A: {{ INSTRUCTION }} {{ DEMO_2_OUTPUT }}   \n$\\begin{array}{r l}{9}&{{}==}\\end{array}$ Q: {{ QUERY_TEXT }} {{ ANSWER_INSTRUCTION }} A: {{ INSTRUCTION }} {{ llm() }} ", "page_idx": 22}, {"type": "text", "text": "where DEMO_{i}_OUTPUT contains the entire response from the LLM to the corresponding input (not the final answer only). For ProTeGi and PromptAgent, we follow the templates used in the respective original papers with the format that puts the instruction and answer instruction in front of the test query: ", "page_idx": 22}, {"type": "text", "text": "{{ INSTRUCTION }} {{ ANSWER_INSTRUCTION }}", "page_idx": 22}, {"type": "text", "text": "{{ QUERY_TEXT }} {{ llm () }} ", "page_idx": 22}, {"type": "text", "text": "Accordingly, we modify the template with exemplars to: ", "page_idx": 22}, {"type": "text", "text": "{{ INSTRUCTION }} {{ DEMO_1_QUERY_TEXT }} {{ ANSWER_INSTRUCTION }} {{ DEMO_1_OUTPUT }}   \n${4\\:\\:\\mathrm{~}}==$ {{ DEMO_2_QUERY_TEXT }} {{ ANSWER_INSTRUCTION }} {{ DEMO_2_OUTPUT }}   \n$8\\:\\:=\\:=$ {{ QUERY_TEXT }} {{ ANSWER_INSTRUCTION }} {{ llm () }} ", "page_idx": 22}, {"type": "text", "text": "Noting that instruction is stated once at the beginning only rather than repeated at each exemplar, in consistency to the original styles adopted by these papers. ", "page_idx": 23}, {"type": "text", "text": "Implementation details of IO methods. In this section, we describe the implementation details of the IO and EO methods adopted. For all methods, we use greedy decoding (temperature $=0$ ) for the PaLM 2 (text-bison-002) or Gemini target models. Whenever an optimizer model is used, we use temperature $=1.0$ , $\\mathtt{t o p\\_k}=40$ and $\\mathtt{t o p\\_p}=0.8$ . For both PaLM 2 and Gemini models, we use the Google Cloud Vertex AI API available at https://cloud.google.com/vertex-ai. ", "page_idx": 23}, {"type": "text", "text": "\u2022 APE: We adapt the official implementation available at https://github.com/keirp/ automatic_prompt_engineer. Instead of using \u201cinstruction induction\u201d [18] from exemplars which is the primary initialization method introduced in the original paper in $\\S3.1$ , Forward Mode Generation or Reverse Mode Generation, we opt for the third option, Customized Prompts where we initialize APE at the seed prompt \u201cLet\u2019s think step by step\u201d because 1) this ensures fairness in comparison with other methods and 2) we find initializing at the seed prompt actually leads to much better performance because it is well-known to induce step-by-step, CoT-style reasoning from the LLM. On the other hand, while the LLM induced initial instructions may describe the task better, the model often tends to utter the final answer without intermediate steps which we observe lead to much worse performance: on the BBH tasks selected for experimentation in this work, instruction induction using the meta-prompt provided by the APE paper only led to an average test accuracy of $56.7\\%$ on PaLM 2 (text-bison-002), which is even worse than using the seed prompt with no additional optimization. For APE, we use a population size of 8 and allow for 4 generations. ", "page_idx": 23}, {"type": "text", "text": "\u2022 OPRO: we adapt the official implementation available at https://github.com/ google-deepmind/opro. At each optimization step, we follow the authors by asking the optimizer model to generate 8 candidate prompts and we budget for 4 steps. \u2022 ProTeGi: We use the official implementation available at https://github.com/microsoft/ LMOps. We set the initial prompt to the seed prompt, and we always use the entire validation set to generate the \u201cgradients\u201d (i.e., we use no mini-batching). We set the number of newly proposed instructions per optimization step to 8, where half of them come from \u201cgradients\u201d (i.e., new instructions generated by using the optimizer model to critique past mistakes made by the target model) and the other half come from \u201cMonte Carlo samples\u201d which are paraphrased/rewritten variants of the past prompts by the optimizer model. We again allow for 4 generations of mutations. \u2022 PromptAgent: We use the official implementation at https://github.com/XinyuanWangCS/ PromptAgent. We set the initial prompt to the seed prompt and use the default Monte Carlo Tree Search algorithm and set the number of maximum iterations to 32 to be consistent with the other methods described above. ", "page_idx": 23}, {"type": "text", "text": "Computational Resources. All experiments conducted in this work are accessible via public APIs where the underlying LLMs are hosted from the server side. There is no computational resource requirement on the client machine except that one can access Google Colab and run Python 3.10. ", "page_idx": 23}, {"type": "text", "text": "Datasets. As discussed briefly in $\\S3.1$ , we rely on existing assets to perform experiments. Both the BIG-Bench Hard (BBH) dataset and the MMLU dataset we used are licensed under the MIT License (BBH: https://github.com/suzgunmirac/BIG-Bench-Hard/blob/main/LICENSE; MMLU: https://github.com/hendrycks/test/blob/master/LICENSE). ", "page_idx": 23}, {"type": "text", "text": "B Additional Experimental Results ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "B.1 Detailed Results on BBH ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In Tables 5 to 10, we show the per-task performance breakdown using the PaLM 2 (text-bison-002) target model whose aggregated results are presented in Table 1. In Table 11 and Table 12, we show the results using the Gemini 1.0 Pro and Gemini 1.5 Flash target models whose aggregated results are presented in Table 2 and Table 4, respectively. The aggregated and task-specific breakdown results on the GPT-3.5 (gpt-3.5-turbo-0125) model are shown in Tables 13 and 14, respectively. ", "page_idx": 23}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/023769705751d09191239faaadd9dad5bd3dfe41e397b45c42ceb7fa547525fc.jpg", "table_caption": ["Table 5: Per-task test accuracy $(\\%)$ of the PaLM-2 (text-bison-002) target model without exemplar optimization (No EO). "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/139890abc37afdee3fe1c09ef5ee7d002f0ea3e3f99b8859beace06e98678980.jpg", "table_caption": ["Table 6: Per-task test accuracy $(\\%)$ of the PaLM-2 (text-bison-002) target model with random exemplar optimization (Random). "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/9441656afafbb2fcdb4bc6483a01c1fdc2368b2da2d0cfe5ff5be982bcd7d006.jpg", "table_caption": ["Table 7: Per-task test accuracy $(\\%)$ of the PaLM-2 (text-bison-002) target model with nearest exemplar optimization (Nearest). "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/e10b05c95935e1b2a8b57d6231eb1047e44a99d3c0ad70fae53c073eba9766bf.jpg", "table_caption": ["Table 8: Per-task test accuracy $(\\%)$ of the PaLM-2 (text-bison-002) target model with diversity exemplar optimization (Diversity). "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/0b74075feb1ad5bb73cc70e608caa2a5d092de2a70e3ac99ea521b0383e9ed4c.jpg", "table_caption": ["Table 9: Per-task test accuracy $(\\%)$ of the PaLM-2 (text-bison-002) target model with random search exemplar optimization (Random search) with search budget $m=32$ . "], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/cb9a671990a425b9782c94a12ab3112f1fe0656445ae71febb6533d8f17753a3.jpg", "table_caption": ["Table 10: Per-task test accuracy $(\\%)$ of the PaLM-2 (text-bison-002) target model with mutation exemplar optimization (Mutation) with search budget $m=32$ . "], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/c0f29242836785a6b201401cb0eb0bd6df7900029c46740184e484b13a05680d.jpg", "table_caption": ["Table 11: Per-task test accuracy $(\\%)$ of the Gemini 1.0 Pro target model. "], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/4c52a030afb674a9939fb6c281012dabac6108ed4387cd61316a9500c8176194.jpg", "table_caption": ["Table 12: Per-task test accuracy $(\\%)$ of the Gemini 1.5 Flash target model. "], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/879aa44231d93613f5ff6b9007aa311249c18ef969db6dd5c4d3de30eca8c0fe.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "B.2 Detailed Per-task Results on MMLU ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In Table 15, we show the per-task performance breakdown using the PaLM 2 (text-bison-002) target model whose aggregated results are presented in Table 3. In Table 16, we show the MMLU results using the Gemini 1.0 Pro target model. ", "page_idx": 27}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/cc598982ecce421685aec81ded82f75e7873c02b4ece391d1b04784b899486e6.jpg", "table_caption": ["Table 15: Per-task test accuracy $(\\%)$ of the PaLMTable 16: Per-task test accuracy $(\\%)$ of the Gemini 2 target model on MMLU. 1.0 Pro target model on MMLU. "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "B.3 Additional Visualization of Comparison Across IO and EO ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Complementary to Fig. 3 in the main text, in PaLM 2 model, we show the per-task change of test accuracy before and after applying EO for APE and OPRO in Fig. 9 (comparison between optimized exemplars vs. no exemplars) and Fig. 10 (comparison between optimized exemplars vs random exemplars). We also include a visualization on the effect of IO (comparing optimized instructions and initial instructions) in Fig. 11. We also visualize the Gemini 1.0 Pro results in Fig. 12. ", "page_idx": 28}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/0c79b06cf71afe5cdc62cb5ae23e0fa530b162c05763efee66a51dd4c3157d6b.jpg", "img_caption": ["Figure 9: Optimized exemplars vs. no exemplars in PaLM 2 model: Comparison of performance of OPRO and PromptAgent (left to right) before (no exemplars) and after applying exemplars found via Mutation. Dashed and solid lines denote the average performance before and after exemplars, respectively. The results using APE, ProTeGi and no IO are shown in Fig. 3. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/dd53410f2135e74f57df7e9eb526856fae80125a87eb6eb605734c62c78d12eb.jpg", "img_caption": ["Figure 10: Influence of using optimized exemplars compared to random exemplars in PaLM 2 model: Comparison of performance of No IO, APE, OPRO, ProTeGi and PromptAgent (left to right and top to bottom) using random exemplars and optimized exemplars found via Mutation. Dashed and solid lines denote the average performance before and after exemplars, respectively. . "], "img_footnote": [], "page_idx": 29}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/6e576d6822c1c7252391b0c80ef4dab97870fa0ac70045bb3180f416d3fe5bae.jpg", "img_caption": ["Figure 11: Influence of using optimized instructions compared to initial instructions in PaLM 2 model: Comparison of performance before and after using optimized instructions found via APE, OPRO (Top row), ProTeGi and PromptAgent (Bottom row). All results are without exemplars (i.e., \u201czero-shot\u201d setup). Dashed and solid lines denote the average performance before and after examplers, respectively. "], "img_footnote": [], "page_idx": 30}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/3091f059705ddc6225937b45dc0537d844ae451ef0c8f0f9e8c57826cd99bd60.jpg", "img_caption": ["Figure 12: Influence of using optimized exemplars compared to no exemplars and random exemplars in Gemini 1.0 Pro model: Comparison of performance of No IO (top row) and ProTeGi (bottom row) using no/random exemplars vs optimized exemplars found via Mutation. Dashed and solid lines denote the average performance before and after exemplars, respectively. "], "img_footnote": [], "page_idx": 31}, {"type": "text", "text": "Complementary to Fig. 5 in the main text, we visualize the additional BBH tasks on PaLM 2 in Fig. 13(a), Gemini 1.0 Pro in Fig. 13(b) and Gemini 1.5 Flash in Fig. 13. We also test key findings on a representative subset of 11 tasks in GPT-3.5 (Fig. 14. We visualize the MMLU results in Fig. 15. ", "page_idx": 31}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/0ce4a15a9979939583f2c35219debd6c435e5c1f7306506c3fbca3785128cedb.jpg", "img_caption": ["Figure 13: Visualization of per-task performance comparison on (first panel) PaLM 2 (except the first 12 tasks, which are shown in Fig. 5), (middle panel) Gemini 1.0 Pro and (bottom panel) Gemini 1.5 Flash. "], "img_footnote": [], "page_idx": 32}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/c498097579c4a67150c475fc07f38e994f61de72f107b73a16f4d0415e0d7f1e.jpg", "img_caption": ["Figure 14: Visualization of per-task performance comparison on GPT-3.5. "], "img_footnote": [], "page_idx": 33}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/d838801e2a7fc55251d1d036ff2d15a38b5218d115aef5fba932a253b1ba5ea9.jpg", "img_caption": ["Figure 15: Visualization of MMLU per-task performance comparison on PaLM 2. "], "img_footnote": [], "page_idx": 33}, {"type": "text", "text": "B.4 Varying Number of Shots ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "With the advent of LLMs that support longer context windows, an alternative approach to performing exemplar optimization is to scale the number of exemplars. Taking into the context of our setup, instead of selecting $k$ exemplars from $\\mathcal{D}_{c}$ where $k$ is a small value, we can scale $k$ to a larger value or even use the entire $\\mathcal{D}_{c}$ as exemplars. In this section, we perform experiments on the relative merits of the two approaches. ", "page_idx": 34}, {"type": "text", "text": "We show the aggregated results in Table 17 and task-specific results for both models in Fig. 16 and Fig. 17. While we find increasing the number of exemplars generally leads to improved test performance up to $k\\,=\\,10$ , further increase leads to performance deterioration. The increase in performance, however, does not diminish the importance of exemplar optimization as we show that using optimized exemplars outperform many more random exemplars, both at an aggregated level and on a task-specific level (the instances where optimized exemplars outperform random exemplars of any $k$ , which are marked by magenta lines in Figs. 16 & 17, are more than $50\\%$ in both target models) \u2013 we argue that this suggests that exemplar optimization remains relevant even in modern LLMs with long contexts. In fact, we believe that novel exemplar search strategy in such many-shot setup can be an important next step, given that the number of possible combinations and permutations of exemplars explodes exponentially for a higher $k$ , necessitating more advanced search strategies that would navigate this optimization landscape more effectively and efficiently. We defer a thorough investigation of this direction to a future work. ", "page_idx": 34}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/746ad5c1ca75356dba87bd9bcb39187f78a1faa30a5561a4580e02c8b416680b.jpg", "table_caption": ["Table 17: 3 optimized exemplars outperform 20 random exemplars: average performance across BBH tasks comparing different number of random exemplars per sample vs. optimized exemplars as presented in the paper. "], "table_footnote": [], "page_idx": 34}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/d6ec35ecd99b5b8e205bd20b88497d5d29f9793bc435e1adcbf0f220f76330e5.jpg", "img_caption": ["Figure 16: Per-task results on BBH tasks where we vary $k=\\{0,1,3,5,10,20\\}$ for PaLM 2. The green curves denote the performance of \u201cNo $^{\\mathrm{{IO}}+}$ random exemplars\u201d combination under different $k$ values; the dashed and solid lines correspond to the \u201cNo IO $^+$ Mutation\u201d and \u201cProTeGi $^+$ Mutation\u201d combinations under $k=3$ , respectively, and these lines are colored magenta when they outperform random exemplars of any $k$ . $k=0$ and $k=3$ values are taken from Table 1 and 2 for PaLM 2 and Gemini models, respectively. "], "img_footnote": [], "page_idx": 35}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/8c927d2a9c00bac79710416b7d5cb8a6ee40b95d9068e66a3d7995ceb8efce7c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 36}, {"type": "text", "text": "Figure 17: Per-task results on BBH tasks where we vary $k=\\{0,1,3,5,10,20\\}$ for Gemini $1.0\\,\\mathrm{Pro}$ .   \nRefer to Fig. 16 for additional explanations. ", "page_idx": 36}, {"type": "text", "text": "B.5 Varying Validation Dataset Sizes ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "In the main experiments, we used $20\\%{-}80\\%$ validation-test split for all BBH tasks. In this section, we investigate the sensitivity of the various methods to changing validation data sizes, especially under very data-constrained setups such as very small validation data sizes. To do so, we vary the validation split to be $\\{2,\\,4,\\,10,\\,20\\}\\%$ and we investigate on the combination of ProTeGi and Mutation, the bestperforming IO and EO methods, respectively. We summarize the average test accuracy against the size of validation data split (as a fraction of the total data available) in Fig. 18. ", "page_idx": 36}, {"type": "text", "text": "We find that optimization-based EO is remarkably robust towards the size of the validation size, with the smallest performance drop even with an extremely small validation set (i.e., $2\\%$ or $4\\%$ , which correspond to 5 or 10 validation samples). On the other hand, ", "page_idx": 36}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/cde7f8105630184be9f39c4536b457298097bc98447a3fcf6fd240e275eb5862.jpg", "img_caption": ["Figure 18: Average test accuracy with different validation split sizes with different IO-EO Combinations. "], "img_footnote": [], "page_idx": 36}, {"type": "text", "text": "ProTeGi dropped to a performance no better than un-optimized seed instruction under such an extremely data-constrained setup, and even the performance of ProTeGi $^+$ Mutation, which performs the best overall in the main text dropped significantly with a small validation data size. ", "page_idx": 36}, {"type": "text", "text": "B.6 EO with a Reduced Budget ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "In this section, we show the results of EO with search budget approximately halved (from $m=32$ to $m=16$ ) in Table 18 on top of the seed instructions without instruction optimization. We find that even after halving the budget (i.e., the EO strategies are now half as expensive), seed instruction and ", "page_idx": 36}, {"type": "text", "text": "optimized exemplars still outperform optimized instruction and random exemplars both in terms of average test accuracy and average rank. ", "page_idx": 37}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/5c55829e2a7a287c9d277f9a9f658dcbeb48158da7d079c711e187e50d01f30c.jpg", "table_caption": ["Table 18: Per-task test accuracy $(\\%)$ of the PaLM-2 (text-bison-002) target model using EO of halved budget $m=16)$ . The last column (marked by $\\dagger$ ) is the result obtained by running ProTeGi (the best overall IO method from Table 1 with $m=32$ with random exemplar optimization, as used originally in Pryzant et al. [35]. "], "table_footnote": [], "page_idx": 37}, {"type": "text", "text": "B.7 Additional Results by Mixing-and-Matching IO and EO ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Other choices of instruction optimizers and/or target models. We show results from mixingand-matching IO and EO in a similar manner to Fig. 7 but use ProTeGi (instead of APE in Fig. 7) on both PaLM 2 (text-bison-002) and Gemini 1.0 Pro target models in Table 19, where we see that two key findings (that any mix-and-match outperforms IO and EO only and that optimal allocation completely bridges the gap compared to a more expensive routine) we made still hold, except on Gemini model, the optimal allocation occurs at 16/16 instead of 8/24. This confirms that the phenomenon we see in Fig. 7 in the main text is not specific to the choice of the target models and/or instruction optimizers but is instead generally applicable. ", "page_idx": 37}, {"type": "text", "text": "Table 19: Mixing-and-matching IO and EO leads to performance beneftis under different $I O$ strategies and/or target models. Results on BBH tasks using two-stage IO-EO described in Insight 3, $\\S3.2$ but we instead use ProTeGi as the instruction optimizer on both PaLM 2 / Gemini 1.0 Pro target models. The color of the cells denotes the computational costs in terms of target model traversals on $\\mathcal{D}_{\\mathrm{val}}$ consistent to Table 1. ", "page_idx": 37}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/9e3f6b85bc9bd4d811a3bce4f7ee36189bde2738adbd5e7641a49c8d29977ff9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/2322ce3ccb8a66dacc55c251b70f5a19ee33ef1cf3694e74be0c00917980dfa1.jpg", "img_caption": ["Figure 19: An example of how IO and EO may synergize on multistep_arithmetic_two dataset using PaLM 2 target model. "], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Mechanism of synergy between IO and EO. In this section, we give an example of why combined IO and EO outperform its constituting building blocks in Fig. 19: performing IO only (Fig. 19a) generates step-by-step text instructions, but without exemplars, the model is prone to making arithmetic errors. Performing EO only (Fig. 19b), on the other hand, subjects the model to the shortcomings of the un-optimized seed prompt, which, in this case, generates arithmetic operations-only outputs without textual reasoning. Combined IO and EO (Fig. 19c) addresses both issues, leading to vastly improved performance from both textual reasoning and exemplars. ", "page_idx": 38}, {"type": "text", "text": "B.8 Alternative Ways of Combining IO and EO ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "As discussed in $\\S3.2$ , we conducted EO after IO in the main text: in our setup, the exemplars are bootstrapped from the model\u2019s own predictions, which in turn depend on the instructions given. As such, we performed instruction optimization first on the zero-shot setup and search for the optimal exemplar(s) amongst the predictions induced by the optimal instruction. While we believe this order is the most natural, it is also important to ensure that any findings derived in this paper are not biased by the particular order we chose. Thus, in this section, we also experiment with two alternatives: ", "page_idx": 38}, {"type": "text", "text": "1. Inverted order. We first optimize the exemplars based on the seed instruction (\u201cLet\u2019s think step by step.\u201d for most cases), and then freeze the exemplars and optimize the instruction on both Gemini 1.0 Pro and Gemini 1.5 Flash models. We used APE to optimize the instructions and random search to optimize exemplars wiht a total budget of $m=32$ , which is identical to the setup presented in Fig. 7 in the main text.   \n2. Interleaved. Instead of framing the exemplar and instruction optimization as a two-staged approach, a better approach in principle is to optimize them jointly. Here, we propose an interleaved approach with the intention of conditioning instructions to the best exemplars discovered so far and vice versa given their inter-dependence. The pseudocode representation of the algorithm in shown in Algorithm 1.   \n1: Inputs: $\\mathcal{D}_{\\mathrm{val}}$ , target LLM, optimizer LLM, # generations $T$ , instruction pop size $|{\\mathcal{T}}|$ , exemplar pop size $\\vert\\mathcal{E}\\vert$ , number of exemplar shots: $k$ .   \n2: Initialize instructions $\\mathcal{T}_{0}$ with seed instruction or LLM-sampled instructions; initialize exemplars $\\mathcal{E}_{0}\\gets\\emptyset$ , best instruction $\\&$ exemplar so far $I_{\\leq0}^{\\ast},E_{\\leq0}^{\\ast}\\gets\\mathtt{N o n e}$   \n3: for all generation $t\\in\\{1,...,T\\}$ do   \n4: # Optimize instructions conditional on best exemplars   \n5: Evaluate prompt metrics on $\\mathcal{D}_{\\mathrm{val}}$ : $\\widetilde{s}\\gets\\mathbb{E}_{(x,y)\\sim\\mathcal{D}_{\\mathrm{val}}}\\big[g\\big(f_{\\mathrm{LLM}}\\big(x,I_{t}^{(i)},E_{\\le t}^{*},\\big),y\\big)\\big]\\forall I_{t}^{(i)}\\in\\mathcal{Z}_{t}.$   \n6: Retain $\\hat{\\mathcal{T}}_{t}$ , the top instructions in $\\mathcal{Z}_{t}$ in terms of $\\widetilde{s}$ and use the optimizer LLM to rewrite without changing the semantic meaning $\\mathcal{T}_{t+1}\\leftarrow\\mathrm{resample}(\\hat{\\mathcal{T}}_{t})$ .   \n7: Update $I_{\\leq t}^{*}\\gets\\arg\\operatorname*{max}_{I_{t}\\in\\mathcal{Z}_{t}}\\widetilde{s}(I_{t}|E_{\\leq t}^{*})$   \n8: # Optimize exemplars conditi o nal on best instructions   \n9: if $\\mathcal{E}_{t}=\\emptyset$ then   \n10: Fill $\\mathcal{E}_{t+1}$ with input-output (inc. intermediate outputs) pairs randomly sampled from $\\mathcal{D}_{c}(I_{\\leq t}^{*})$ , the subset of $\\mathcal{D}_{\\mathrm{val}}$ where the target model answered correctly under the best instruction seen so far: $\\forall\\,E_{j}\\in\\mathcal{E}_{t+1},E_{j}\\gets\\{e_{j}^{(m)}\\}_{m=1}^{k},e_{j}\\sim\\mathcal{D}_{c}(I_{\\leq t}^{*})$   \n11: else   \n12: Fill $\\mathcal{E}_{t+1}$ with $|\\mathcal{E}|$ mutated copies of $E_{\\le t}^{*}$ : randomly replace an input-output pair in $E_{\\le t}^{*}$ with another pair from $\\mathcal{D}_{c}(I_{\\leq t}^{*})$ .   \n13: end if   \n14: Evaluate prompt metrics on $\\mathcal{D}_{\\mathrm{val}}$ $\\widetilde{\\underline{{s}}}\\gets\\mathbb{E}_{(x,y)\\sim\\mathcal{D}_{\\mathrm{val}}}\\big[g\\big(f_{\\mathrm{LLM}}\\big(x,I_{\\leq t}^{*},E_{t}^{(j)},\\big),y\\big)\\big]\\forall E_{t}^{(j)}\\in\\mathcal{E}_{t}$   \n15: Update $E_{\\le t}^{*}\\gets\\arg\\operatorname*{max}_{E_{t}\\in\\mathcal{E}_{t}}\\widetilde{s}(E_{t}|I_{\\le t}^{*})$   \n16: end for ", "page_idx": 38}, {"type": "text", "text": "", "page_idx": 39}, {"type": "text", "text": "", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "17: Return instruction-exemplar combination with the highest score. ", "page_idx": 39}, {"type": "text", "text": "We present the comparison between the original and inverted orders in Table 20, where we found that the findings (in particular, Insights 2 and 3) are not affected by the optimization order. For the interleaved approach, we find it to achieve a test accuracy of $74.6\\%$ on 26 BBH tasks on PaLM 2, which is broadly on par with the two-staged approach with $m_{\\mathrm{IO}}\\,=\\,16,m_{\\mathrm{EO}}\\,=\\,16\\mathrm{~-~}\\mathrm{we}$ thus primarily focused on the two-staged approach for its simplicity, and defer a detailed exploration on better ways to exploit the interdependence of exemplars and instructions to future work. ", "page_idx": 39}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/cc372ae270b8f7ba8cd573830ad9d76bd69c8cc457ffe9db760b97e0436e4296.jpg", "table_caption": ["Table 20: Effect of ordering between IO and EO on selected BBH tasks of (left) Gemini $1.0\\;\\mathrm{Pro}$ and (right) Gemini 1.5 Flash. Original refers to the IO before EO order used in the main text and Inverted refers to the IO-after-EO optimization order. "], "table_footnote": [], "page_idx": 39}, {"type": "text", "text": "B.9 Case Study on How LLMs Respond to Exemplars and Instructions ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Complementary to Insight 2 and Fig. 8, in this section, we give some examples on the LLM response when prompted with the optimized instructions and/or exemplars in representative tasks. ", "page_idx": 39}, {"type": "text", "text": "Table 21: Case study on tracking_shuffled_objects (7): Top table: the discovered prompts by various methods (only one exemplar is shown under \u201cBest EO\u201d for conciseness). Bottom table: response of LLM to two representative questions in the test set when conditioned on each of the discovered prompt \u2013 note that instructions in this case do not fully specify the model behavior. Even when the LLM is indeed following instructions generate reasoning steps, the effectiveness of reasoning templates vary and LLMs are error-prone and often track unnecessary items. With carefully selected exemplars, however, the LLM can perform behavior imitation via adapting and chaining the pattern \u201c[A] and [B] [do something]. [A] had [X] and [B] had [Y]. So now, [A] has [Y] and [B] has [X]\u201d to achieve an extraordinary accuracy. Some texts are truncated with ... for better presentation. ", "page_idx": 40}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/c3bfdd7d639e26ada9f557052e6e6eeaf170ff97fb24da206d65fc0c4284de89.jpg", "table_caption": [], "table_footnote": [], "page_idx": 40}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/8ca164a6185431c7dfe4c62498bd36abd7434070303c1ee4fa2e7c1b2d311d3f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 40}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/cad8d0a1dbc0760c3ea01def528f73cd92b3511a303ceadd9f313895c20eafe0.jpg", "table_caption": ["Table 22: Case study on web_of_lies: Top table: discovered prompts. Bottom table: response of LLM to two representative questions in the test set when conditioned on each of the discovered prompt. The winning pattern that the LLM copy behavior from is \u201c[A] says [B] [lies/tells the truth]. So [A] [lies/tells the truth]\u201d to achieve a near-perfect accuracy. "], "table_footnote": [], "page_idx": 41}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/8dd2ef23c7a9f1797f95322e3f726ce0bdcad0bb476232f9a6726d85bf70dc0b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 41}, {"type": "text", "text": "B.10 Comparison Against PromptBreeder ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "In this section, we compare the two-stage EO-IO combined search mentioned in $\\S3.2$ against PromptBreeder [14], the SoTA method that has the option of optimizing both instructions and exemplars. In contrast to our method which is a simple combination of APE (for instruction optimization) and mutation (for exemplar optimization), PromptBreeder features a much expansive search space introduced by its different mutation operators on the instruction and the meta-prompts (referred to as hyper-mutation in Fernando et al. [14]). As such, the algorithm requires many more iterations before convergence \u2013 for our experiment, we use a population size of 40 and allow for 10 generations. Since PromptBreeder uses binary tournament evolution for each generation which will result in half of its population being replaced with new prompts requiring evaluations $\\mathcal{D}_{\\mathrm{val}}$ , there are total $40+10\\times(40/2)=240$ traversals on the validation set $\\mathcal{D}_{\\mathrm{val}}$ , which is approximately an order-of-magnitude larger than the budget used in this paper and the discovered prompts can be deemed as an approximation of the performance \u201cupper bound\u201d when a SoTA optimizing agent is left to freely explore an expansive search space with ample search budget. As a comparison, we run our two-staged EO and IO algorithm for 100 iterations, with first 25 iterations used for IO and the remaining 75 for EO. Due to the much larger computational costs, we run the comparison on four selected tasks: movie_recommendation, multistep_arithmetic_two, object_counting and ruin_names. ", "page_idx": 41}, {"type": "text", "text": "", "page_idx": 42}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/00777a28cfbf1a39e5a2072633d370e4415c453db5033fb26d5db89cfec93134.jpg", "table_caption": ["Table 23: Comparison of the simple two-stage IO-EO algorithm introduced in $\\S3.2$ (with a budget of 100 validation set evaluations) and PromptBreeder (with a budget of 240 validation set evaluations) on 4 representative tasks using PaLM 2 (text-bison-002) model. "], "table_footnote": [], "page_idx": 42}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/0b395e0eb8794718f1a37df69a36ca3265831a54af5ff3c44be92a897d08b938.jpg", "img_caption": ["Figure 20: Comparison of validation accuracy vs. number of evaluations on the validation set between our two-stage IO-EO search and PromptBreeder. Scattered points denote the performance of each evaluated instruction and the line denotes the best instruction up to that point. Note that PromptBreeder uses $2.5\\times$ more search budget. "], "img_footnote": [], "page_idx": 42}, {"type": "text", "text": "We summarize the results in Table 23 and Fig. 20. It is worth noting that our simple two-stage search performs on par or better than PromptBreeder in 3/4 tasks in terms of both validation and test metrics while using less than half of the budget and using a much simpler instruction optimization heuristic. Given that the chief difference between our algorithm and PromptBreeder is the explicit iterative optimization for exemplars (noting that the \u201ccontext shuffilng\u201d routine used in PromptBreeder, which permutes the exemplars in the prompt, relies purely on stochasticity), this again suggests that the importance of exemplar optimization may actually outweigh complicated instruction optimization as we highlighted in Insight 2 in $\\S3.2$ \u2013 in fact, even the the PromptBreeder authors themselves remarked in App. J that \u201c... We find that in the few-shot evolution case, the contexts dominate, and often the task-prompts drift into nonsense. They are less critically determining of fitness than the evolved contexts.\u201d. ", "page_idx": 42}, {"type": "text", "text": "B.11 Additional Examples of How SoTA IO Uses Exemplars ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Complementary to Insight 4 in $\\S3.2$ of the main text, in this section, we show additional examples illustrating how SoTA IO techniques may spontaneously and opportunistically use quasi-exemplars. For selected examples, we also perform ablation experiments similar to the experiment in Fig. 8 where we either retain or remove the identified quasi-exemplars to study the effect of their presence on the final performance and we show the results in Table $24-$ it is further worth noting that in multiple cases, the instruction optimizers discovered instructions that consist of quasi-exemplars only (e.g., multi_arithmetic_two and movie_recommendation in Table 24), which further corroborates our point made in Insight 4. ", "page_idx": 42}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/6bdc2723251a0bd286bf5c5436dede61bbcc44c693bdf436374e7d3dbdc7c2bd.jpg", "table_caption": ["Table 24: Additional examples where SoTA instruction optimizers generate quasi-exemplars (highlighted in yellow) discussed in Insight 4 in $\\S3.2$ in the main text. Where possible, we perform similar ablation experiment as in Fig. 8 to either retain the quasi-exemplars or remove the quasi-exemplars and re-run evaluation on the test set. It is worth noting that in several cases, the instruction optimizer generates instructions consisting of quasi-exemplars only (marked by asterisks in the table below) where it is not possible to perform the ablation experiments. "], "table_footnote": [], "page_idx": 43}, {"type": "text", "text": "C Best Prompts Discovered ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "In this section, we present the best optimized prompts discovered by any method on each of the BBH tasks studied. ", "page_idx": 44}, {"type": "text", "text": "Q: ( not ( False ) or False ) is   \nShow your final answer (True or False only) bracketed between <answer $>$ and </answer >. A: Let \u2019s use a stepwise approach. ( not ( False ) or False ) is   \nShow your final answer (True or False only) bracketed between <answer > and </answer >. A: Let \u2019s use a stepwise approach.   \n1. not ( False ) $=$ True   \n2. True or False $=$ True   \n<answer >True </answer >   \n$==$   \nQ: ( True and not True and True ) is   \nShow your final answer (True or False only) bracketed between <answer $>$ and </answer >. A: Let \u2019s use a stepwise approach. ( True and not True and True ) is   \nShow your final answer (True or False only) bracketed between <answer $>$ and </answer >. A: Let \u2019s use a stepwise approach.   \n1. not True is False.   \n2. True and False is False.   \n3. False and True is False.   \n<answer >False </ answer >   \n$==$   \nQ: True and False or ( not False ) is   \nShow your final answer (True or False only) bracketed between <answer $>$ and </answer >. A: Let \u2019s use a stepwise approach. True and False or ( not False ) is   \nShow your final answer (True or False only) bracketed between <answer > and </answer >. A: Let \u2019s use a stepwise approach.   \n1. ( not False ) is True.   \n2. True or True is True.   \n<answer >True </answer >   \n$==$ ", "page_idx": 44}, {"type": "text", "text": "Listing 1: boolean_expressions: OPRO + Mutation. Test accuracy = 95.0% ", "text_level": 1, "page_idx": 44}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/b314852e31d27d9ebea27fe1e5f0d8686388a20dd820b495faa0a3087d505352.jpg", "table_caption": [], "table_footnote": [], "page_idx": 44}, {"type": "text", "text": "to answer incoming phone calls , the company issued the following official policy: Suzy is the only one permitted to log into the central computer in the mornings , whereas Billy is the only one permitted to log into the central computer in the afternoons. Billy is not permitted to log into the central computer in the morning. Today at 9 am , Billy and Suzy both log into the central computer at the same time. Immediately , some work emails containing important customer information are deleted from the central computer. Did Suzy cause the central computer to delete some work emails containing important customer information ? Options: - Yes - No Show your final answer (Yes or No only) bracketed between <answer > and </answer >. A: Let \u2019s think step by step. <answer >No </ answer > $==$ ", "page_idx": 45}, {"type": "text", "text": "Listing 2: causal_judgement: No IO + Random Search. Test accuracy $=68.7\\%$ ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Q: Jane thinks today is 6/18/2019 , but John thinks today is 6/19/2019. John is correct. What is the date 10 days ago in MM/DD/YYYY?   \nOptions:   \n(A) 06/08/2019   \n(B) 08/09/2018   \n(C) 06/09/2019   \n(D) 05/19/2019   \n(E) 06/09/2044   \n(F) 06/15/2019   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Let \u2019s think step by step. Today is 6/19/2019. 10 days ago would be 6/19/2019 - 10 = 6/9/2019.   \n<answer $>$ (C) </answer >   \n$==$   \nQ: Jane was born on the last day of Feburary in 2001. Today is her 16-year -old birthday. What is the date a month ago in MM/DD/YYYY?   \nOptions:   \n(A) 11/12/2016   \n(B) 01/21/2017   \n(C) 01/14/2017   \n(D) 01/28/2017   \n(E) 02/03/2017   \nShow your final answer option bracketed between <answer > and </answer > at the end. A: Let \u2019s think step by step. Jane was born on the last day of February in 2001 , which is February 28, 2001. Today is her 16th birthday , which means it is February 28, 2017. A month ago from today would be January 28, 2017.   \n<answer $>$ (D) </answer >   \n$==$   \nQ: The concert was scheduled to be on 06/01/1943 , but was delayed by one day to today. What is the date tomorrow in MM/DD/YYYY?   \nOptions:   \n(A) 06/03/1943   \n(B) 03/15/1943   \n(C) 08/03/1942   \n(D) 06/02/1943   \n(E) 07/04/1943   \n(F) 05/06/1943   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Let \u2019s think step by step. The concert was scheduled to be on 06/01/1943 , but was delayed by one day to today. So today is 06/02/1943. Tomorrow will be 06/03/1943. <answer $>$ (A) </answer >   \n$==$ ", "page_idx": 45}, {"type": "text", "text": "Listing 3: date_understanding: No IO + Mutation. Test accuracy = 81.0% ", "page_idx": 45}, {"type": "text", "text": "Q: In the following sentences , explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.   \nSentence: The writer tried to fool the salesperson and told him a fake story. Options:   \n(A) Told the writer a fake story   \n(B) Told the salesperson a fake story   \n(C) Ambiguous   \nShow your final answer option bracketed between <answer > and </answer > at the end. A: Let \u2019s think step by step. The pronoun \"him\" refers to \"the salesperson \".   \n$<$ answer $>$ (B) ${<}/$ answer >   \n$==$   \nQ: In the following sentences , explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous. Sentence: The chief encouraged the writer because she wrote a good book.   \nOptions:   \n(A) The chief wrote a good book   \n(B) The writer wrote a good book   \n(C) Ambiguous   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Let \u2019s think step by step. The pronoun \"she\" refers to the writer.   \nThe antecedent of the pronoun \"she\" is \"the writer \".   \n<answer $>$ (B) </answer >   \n$==$   \nQ: In the following sentences , explain the antecedent of the pronoun (which thing the pronoun refers to), or state that it is ambiguous.   \nSentence: The reporter and the chef discuss their favorite dishes.   \nOptions:   \n(A) They discuss the reporter \u2019s favorite dishes   \n(B) They discuss the chef \u2019s favorite dishes   \n(C) Ambiguous   \nShow your final answer option bracketed between <answer > and </answer > at the end. A: Let \u2019s think step by step. The pronoun \"their\" refers to both the reporter and the chef The final answer is: <answer $>$ (C) Ambiguous </ answer >   \n$==$ ", "page_idx": 45}, {"type": "text", "text": "", "page_idx": 46}, {"type": "text", "text": "Listing 4: disambiguation_qa: No IO + Mutation. Test accuracy = 71.5% ", "text_level": 1, "page_idx": 46}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/0a1cee24de05ef9b6c09bfb401b51bb7a7ad89346b43b4bc3f72c1f106ad284a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 46}, {"type": "text", "text": "\"Here comes a perfectly valid argument: First premise: Whatever is ingredient of Concealer is at least one of these: an ingredient of HEART SHAPED BALM , an ingredient of Goth Fairy or an ingredient of Love Me Like A Wimp. Second premise: Being an ingredient of Clarifying Mask is necessary for being an ingredient of Goth Fairy. Third premise: Being an ingredient of HEART SHAPED BALM is sufficient for being an ingredient of Clarifying Mask. Fourth premise: Every ingredient of Love Me Like A Wimp is an ingredient of Clarifying Mask. So , necessarily , being an ingredient of Concealer is sufficient for being an ingredient of Clarifying Mask .\"   \nIs the argument , given the explicitly stated premises , deductively valid or invalid?   \nOptions:   \n- valid   \n- invalid   \nShow your final answer (valid or invalid only) bracketed between <answer > and </answer >. <answer >valid </ answer >   \n$==$ ", "page_idx": 47}, {"type": "text", "text": "$^+$ ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Listing 5: formal_fallacies: ProTeGi Random Search. Test accuracy = 63.0% Q: This SVG path element <path d=\"M 25.00 ,38.00 L 89.00 ,58.00\"/ > draws a Options: (A) circle (B) heptagon (C) hexagon (D) kite (E) line (F) octagon (G) pentagon (H) rectangle (I) sector (J) triangle Show your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: We should proceed in a sequential manner. A: We should proceed in a sequential manner. The path element starts at point (25, 38) and draws a line to point (89, 58). So , it is a line. <answer $>$ (E) </answer > $==$ Q: This SVG path element <path $\\mathtt{d}=\"\\mathtt{M}$ 21.22 ,43.76 L 13.59 ,7.93 L 49.15 ,35.84 M 49.15 ,35.84 L 21.22 ,43.76\"/ > draws a Options: (A) circle (B) heptagon (C) hexagon (D) kite (E) line (F) octagon (G) pentagon (H) rectangle (I) sector (J) triangle Show your final answer option bracketed between <answer $>$ and </answer > at the end. A: We should proceed in a sequential manner. A: We should proceed in a sequential manner. The first part of the path element , \"M 21.22 ,43.76 L 13.59 ,7.93\" , draws a line from the point (21.22 , 43.76) to the point (13.59 , 7.93). The second part of the path element , \"L 49.15 ,35.84\" , draws a line from the point (13.59 , 7.93) to the point (49.15 , 35.84). The third part of the path element , \"M 49.15 ,35.84 L 21.22 ,43.76\" , draws a line from the point (49.15 , 35.84) back to the point (21.22 , 43.76). This path element draws a triangle. <answer $>$ (J) </answer > $==$ Q: This SVG path element <path d=\"M 53.07 ,5.04 L 61.70 ,11.14 L 62.83 ,22.38 L 66.68 ,29.10 L 63.41 ,40.33 L 49.09 ,37.83 L 38.28 ,25.14 L 52.62 ,23.25 L 53.07 ,5.04\"/ > draws a Options: (A) circle (B) heptagon (C) hexagon (D) kite (E) line (F) octagon (G) pentagon (H) rectangle (I) sector (J) triangle ", "page_idx": 47}, {"type": "text", "text": "Show your final answer option bracketed between <answer > and </answer > at the end.   \nA: We should proceed in a sequential manner. The path starts at point (53.07 , 5.04) and then goes to point (61.70 , 11.14). This is a line segment.   \nNext , it goes to point (62.83 , 22.38). This is another line segment.   \nIt continues to point (66.68 , 29.10). This is a third line segment.   \nThen , it goes to point (63.41 , 40.33). This is a fourth line segment.   \nNext , it goes to point (49.09 , 37.83). This is a fifth line segment.   \nIt continues to point (38.28 , 25.14). This is a sixth line segment.   \nThen , it goes to point (52.62 , 23.25). This is a seventh line segment.   \nFinally , it returns to the starting point (53.07 , 5.04). This is an eighth line segment.   \nSo , the path consists of eight line segments that connect nine points. This forms a polygon. To determine the type of polygon , we need to count the number of sides. Since there are eight sides , the polygon is an octagon.   \n<answer $>$ (F) </answer >   \n== ", "page_idx": 48}, {"type": "text", "text": "Listing 6: geometric_shapes: APE $^+$ Random Search. Test accuracy = 88.5% ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Let \u2019s think step by step.   \nThe correct order of adjectives is:   \n1. Opinion   \n2. Size   \n3. Shape   \n4. Color   \n5. Origin   \n6. Material   \n7. Purpose   \nNow , let \u2019s look at the options:   \n(A) little black driving ship   \n(B) driving little black ship   \nThe correct answer is (A) because it follows the correct order of adjectives . <answer $>$ (A) </answer >   \nWhich sentence has the correct adjective order:   \nOptions:   \n(A) large archaic red Indonesian sock   \n(B) large red Indonesian archaic sock   \nShow your final answer option bracketed between <answer > and </answer > at the end. The correct order of adjectives is:   \n1. Size   \n2. Shape   \n3. Color   \n4. Origin   \n5. Material   \n6. Purpose   \nNow , let \u2019s look at the options:   \n(A) large archaic red Indonesian sock   \n(B) large red Indonesian archaic sock   \nThe correct answer is (A) because it follows the correct order of adjectives . <answer $>$ (A) </answer >   \n$==$   \nWhich sentence has the correct adjective order:   \nOptions:   \n(A) German gray lovely ship   \n(B) lovely gray German ship   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. The correct order of adjectives is:   \n1. Opinion   \n2. Size   \n3. Shape   \n4. Color   \n5. Origin   \n6. Material   \n7. Purpose   \nNow , let \u2019s look at the options:   \n(A) German gray lovely ship   \n(B) lovely gray German ship ", "page_idx": 48}, {"type": "text", "text": "The correct answer is (B) because it follows the correct order of adjectives . ", "page_idx": 49}, {"type": "text", "text": "<answer >(B) </answer > $==$ ", "page_idx": 49}, {"type": "text", "text": "Listing 7: hyperbaton: PromptAgent $^+$ Random Search. Test accuracy $=90.5\\%$ Q: The following paragraphs each describe a set of five objects arranged in a fixed order . The statements are logically consistent within each paragraph. In a golf tournament , there were five golfers: Mel , Dan , Amy , Joe , and Eve. Amy finished below Dan. Mel finished first. Joe finished above Dan. Eve finished last. Options: (A) Mel finished second (B) Dan finished second (C) Amy finished second (D) Joe finished second (E) Eve finished second Show your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Here \u2019s the thought process I used to solve the problem. \\*\\* Thought process :\\*\\* 1. Mel finished first. 2. Eve finished last. 3. Amy finished below Dan. 4. Joe finished above Dan. Based on these statements , we can conclude that: Mel finished first. - Eve finished fifth. - Dan finished third. - Amy finished fourth. - Joe finished second. $^{\\ast\\ast}$ Answer :\\*\\* <answer $>$ (D) ${<}/$ answer > $==$ Q: The following paragraphs each describe a set of five objects arranged in a fixed order . The statements are logically consistent within each paragraph. On a shelf , there are five books: a green book , an orange book , a gray book , a yellow book , and a purple book. The green book is the rightmost. The gray book is to the right of the orange book. The purple book is to the left of the yellow book. The purple book is to the right of the gray book. Options: (A) The green book is the leftmost (B) The orange book is the leftmost (C) The gray book is the leftmost (D) The yellow book is the leftmost (E) The purple book is the leftmost Show your final answer option bracketed between <answer $>$ and </answer > at the end. A: Here \u2019s the thought process I used to solve the problem. The green book is the rightmost. The gray book is to the right of the orange book. The purple book is to the left of the yellow book. The purple book is to the right of the gray book. From the first statement , we know that the green book is on the rightmost side. From the second statement , we know that the gray book is to the right of the orange book. This means that the orange book must be to the left of the gray book. From the third statement , we know that the purple book is to the left of the yellow book. From the fourth statement , we know that the purple book is to the right of the gray book. This means that the gray book must be between the purple book and the orange book. Therefore , the order of the books from left to right is: orange , gray , purple , yellow , green. <answer $>$ (B) </answer > $==$ Q: The following paragraphs each describe a set of five objects arranged in a fixed order The statements are logically consistent within each paragraph. In a golf tournament , there were five golfers: Amy , Mel , Rob , Joe , and Ada. Joe finished second. Joe finished below Amy. Mel finished second -to -last. Ada finished last. Options: (A) Amy finished first (B) Mel finished first (C) Rob finished first (D) Joe finished first (E) Ada finished first Show your final answer option bracketed between <answer > and </answer > at the end. ", "page_idx": 49}, {"type": "text", "text": "A: Here \u2019s the thought process I used to solve the problem. \\*\\* Step 1: Understand the information given in each paragraph . $^{\\ast\\ast}$ ", "page_idx": 50}, {"type": "text", "text": "The first paragraph describes a golf tournament with five golfers: Amy , Mel , Rob , Joe , and Ada. ", "page_idx": 50}, {"type": "text", "text": "\\*\\* Step 2: Identify the key information related to the order of finish .\\*\\* ", "page_idx": 50}, {"type": "text", "text": "- Joe finished second. - Joe finished below Amy. - Mel finished second -to -last - Ada finished last. ", "page_idx": 50}, {"type": "text", "text": "\\*\\* Step 3: Use the given information to deduce the order of finish .\\*\\* ", "page_idx": 50}, {"type": "text", "text": "Based on the information provided , we can conclude the following: ", "page_idx": 50}, {"type": "text", "text": "- Ada finished last.   \n- Mel finished second -to -last.   \nJoe finished second.   \n- Amy finished above Joe. ", "page_idx": 50}, {"type": "text", "text": "Since Amy finished above Joe , who finished second , and no other information is given about the golfers who finished ahead of Joe , we can conclude that Amy finished first ", "page_idx": 50}, {"type": "text", "text": "Listing 8: logical_deduction_five_objects: OPRO Listing 8: 1ogica1_deduction_1ive_objects: OPRO + Random Search. Test accuracy = 62.5% $^+$ Random Search. Test accuracy $=62.5\\%$ ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Q: The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. A fruit stand sells seven fruits: plums , kiwis , cantaloupes , pears , watermelons , apples , and loquats. The watermelons are more expensive than the cantaloupes . The apples are less expensive than the cantaloupes . The watermelons are the second -most expensive. The loquats are less expensive than the kiwis. The apples are more expensive than the loquats. The loquats are the third -cheapest. The plums are the cheapest.   \nOptions:   \n(A) The plums are the cheapest   \n(B) The kiwis are the cheapest   \n(C) The cantaloupes are the cheapest   \n(D) The pears are the cheapest   \n(E) The watermelons are the cheapest   \n(F) The apples are the cheapest   \n(G) The loquats are the cheapest   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nA: I need to think step -by -step. Step 1: Identify the most expensive fruit.   \nThe watermelons are the second -most expensive. So the most expensive fruit must be either the cantaloupes or the kiwis.   \nStep 2: Identify the cheapest fruit.   \nThe plums are the cheapest.   \nStep 3: Determine the order of the fruits from most expensive to least expensive.   \nThe most expensive fruit is either the cantaloupes or the kiwis. The watermelons are the second -most expensive. The apples are less expensive than the cantaloupes . The loquats are less expensive than the kiwis. The apples are more expensive than the loquats. The loquats are the third -cheapest.   \nStep 4: Identify the cheapest fruit.   \nThe plums are the cheapest.   \n<answer >A</ answer >   \n==   \nQ: The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a shelf , there are seven books: a purple book , a brown book , a red book , a blue book , a gray book , a black book , and a green book. The brown book is to the left of the green book. The gray book is the second from the left. The black book is to the left of the gray book. The blue book is to the left of the red book. The blue book is the second from the right. The green book is to the left of the purple book.   \nOptions:   \n(A) The purple book is the second from the right   \n(B) The brown book is the second from the right   \n(C) The red book is the second from the right   \n(D) The blue book is the second from the right   \n(E) The gray book is the second from the right   \n(F) The black book is the second from the right   \n(G) The green book is the second from the right   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nA: I need to think step -by -step. Step 1: Identify the position of the gray book.   \nThe gray book is the second from the left.   \nStep 2: Identify the books to the left of the gray book.   \nThe black book is to the left of the gray book.   \nStep 3: Identify the books to the right of the gray book.   \nThe brown book is to the left of the green book.   \nThe green book is to the left of the purple book.   \nTherefore , the books to the right of the gray book are the green book , the purple book , the red book , and the blue book.   \nStep 4: Identify the position of the blue book.   \nThe blue book is the second from the right.   \nStep 5: Determine which book is the second from the right.   \nThe blue book is the second from the right.   \n<answer >D</ answer >   \n$==$   \nQ: The following paragraphs each describe a set of seven objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament , there were seven golfers: Joe , Mel , Mya , Eve , Rob , Ada , and Dan. Rob finished first. Eve finished last. Dan finished above Ada. Mel finished above Mya. Joe finished second -to -last. Mya finished third.   \nOptions:   \n(A) Joe finished second -to -last   \n(B) Mel finished second -to -last   \n(C) Mya finished second -to -last   \n(D) Eve finished second -to -last   \n(E) Rob finished second -to -last   \n(F) Ada finished second -to -last   \n(G) Dan finished second -to -last   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nA: I need to think step -by -step. \\*\\* Step 1:\\*\\* Identify the finishing positions of the golfers mentioned in the paragraph. Rob finished first. Eve finished last. Dan finished above Ada. Mel finished above Mya. Joe finished second -to -last.   \n- Mya finished third.   \n\\*\\* Step $2:**$ Determine the remaining finishing positions.   \n- Since Rob finished first and Mya finished third , the remaining golfers must finish in positions 2, 4, 5, 6, and 7. Dan finished above Ada , so Dan must be in position 4 or 5 and Ada must be in position 5 or 6. Mel finished above Mya , so Mel must be in position 2 or 3.   \n\\*\\* Step 3:\\*\\* Identify the golfer who finished second -to -last.   \n- Joe finished second -to -last , so the answer is (A).   \n\\*\\* Final Answer :\\*\\* <answer $>$ (A) </answer >   \n$==$ ", "page_idx": 50}, {"type": "text", "text": "", "page_idx": 51}, {"type": "text", "text": "Listing 9: logical_deduction_seven_objects: OPRO + Mutation. Test accuracy $=62.5\\%$ ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Q: The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch , there are three birds: a blue jay , a cardinal , and a quail. The cardinal is to the right of the quail. The quail is to the right of the blue jay.   \nOptions:   \n(A) The blue jay is the rightmost   \n(B) The cardinal is the rightmost   \n(C) The quail is the rightmost   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nA: Let \u2019s think step by step. The quail is to the right of the blue jay. The cardinal is to the right of the quail. So the order is: blue jay , quail , cardinal.   \n<answer $>$ (B) </answer >   \nQ: The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. In a golf tournament , there were three golfers: Ana , Mel , and Ada. Ada finished above Ana. Mel finished below Ana.   \nOptions:   \n(A) Ana finished first   \n(B) Mel finished first   \n(C) Ada finished first   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end.   \nA: Let \u2019s think step by step. Ada finished above Ana.   \nMel finished below Ana.   \nSo , the order is Ada , Ana , Mel.   \n<answer $>$ (C) </answer >   \n$==$   \nQ: The following paragraphs each describe a set of three objects arranged in a fixed order. The statements are logically consistent within each paragraph. On a branch , there are three birds: a crow , a falcon , and a raven. The crow is to the left of the raven. The falcon is to the right of the raven.   \nOptions:   \n(A) The crow is the rightmost   \n(B) The falcon is the rightmost   \n(C) The raven is the rightmost   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end.   \nA: Let \u2019s think step by step. A: Let \u2019s think step by step.   \nThe crow is to the left of the raven.   \nThe falcon is to the right of the raven.   \nSo the order is: crow , raven , falcon.   \nThe falcon is the rightmost.   \n$<$ answer $>$ (B) </answer >   \n$==$ ", "page_idx": 51}, {"type": "text", "text": "", "page_idx": 52}, {"type": "text", "text": "Listing 10: logical_deduction_three_objects: No IO $^+$ Random Search. Test accuracy $=$ $84.5\\%$ ", "page_idx": 52}, {"type": "text", "text": "Let \u2019s think step by step. First , let \u2019s identify the common themes or genres of the given movies ", "page_idx": 52}, {"type": "text", "text": "Then , let \u2019s look at the options and choose the one that best fits the common themes or genres. ", "page_idx": 52}, {"type": "text", "text": "If none of the options fit the common themes or genres perfectly , let \u2019s choose the option that is most similar to the given movies in terms of its popularity and well - knownness. ", "page_idx": 52}, {"type": "text", "text": "Finally , let \u2019s bracket the final answer option between <answer > and </answer >. ", "page_idx": 52}, {"type": "text", "text": "Find a movie similar to Schindler \u2019s List , Pulp Fiction , Braveheart , The Usual Suspects: Options:   \n(A) 12 Angry Men   \n(B) Mo \u2019 Better Blues   \n(C) Mindhunters   \n(D) The Shawshank Redemption   \nShow your final answer option bracketed between <answer > and </answer > at the end. ", "page_idx": 52}, {"type": "text", "text": "The common theme among the given movies is that they are all critically acclaimed and highly regarded in the film industry. They also cover various genres , including historical drama (Schindler \u2019s List), crime (Pulp Fiction), historical epic ( Braveheart), and crime thriller (The Usual Suspects). ", "page_idx": 52}, {"type": "text", "text": "Find a movie similar to American History X, Requiem for a Dream , Raiders of the Lost Ark , The Sixth Sense: ", "page_idx": 52}, {"type": "text", "text": "Options:   \n(A) Miss Meadows   \n(B) Little Man   \n(C) Goodfellas   \n(D) You Can \u2019t Take It with You   \nShow your final answer option bracketed between <answer > and </answer > at the end. ", "page_idx": 52}, {"type": "text", "text": "The common theme among the given movies is that they are all critically acclaimed and well -known films. ", "page_idx": 52}, {"type": "text", "text": "While the genres of the movies vary , they are all considered to be classic films that have stood the test of time.   \nOut of the options provided , the movie that is most similar to the given movies in terms of its popularity and well -knownness is Goodfellas .   \n<answer $>$ (C) Goodfellas </ answer >   \n$==$   \nFind a movie similar to Batman , The Usual Suspects , The Silence of the Lambs , Jurassic Park:   \nOptions:   \n(A) The End of the Tour   \n(B) Forrest Gump   \n(C) Lust   \n(D) Caution   \n(E) Shelter   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nThe common theme among the given movies is that they are all critically acclaimed and popular films from the 1990s.   \nOut of the options , the movie that is most similar to the given movies in terms of its popularity and well -knownness is Forrest Gump.   \n<answer $>$ (B) Forrest Gump </ answer >   \n$==$ ", "page_idx": 53}, {"type": "text", "text": "Listing 11: movie_recommendation: PromptAgent $^+$ Mutation. Test accuracy $=95.0\\%$ ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Solve the following math problems by following the steps in the order of operations :   \n1. When multiplying or dividing two negative numbers , the result will be positive.   \n2. When multiplying or dividing a positive and a negative number , the result will be negative.   \n3. When adding or subtracting a negative number , it is the same as adding or subtracting its positive counterpart .   \n$((6-0\\div5+-3)\\ast(6--7+-2\\cdots7))=$   \nShow your final answer bracketed between <answer > and </answer >. $((6-0\\ast5+-3)\\ast(6--7+-2---7))=$   \n(6 - 0 + -3) \\* (6 - -7 + -2 - -7)   \n(6 + -3) \\* (6 - -7 + -2 - -7)   \n3 \\* (6 - -7 + -2 - -7)   \n3 \\* (6 + 7 + -2 + 7)   \n3 \\* (13 + -2 + 7)   \n3 \\* (11 + 7)   \n3 \\* 18   \n<answer >54 </ answer >   \n$==$   \n1. When multiplying or dividing two negative numbers , the result will be positive.   \n2. When multiplying or dividing a positive and a negative number , the result will be negative.   \n3. When adding or subtracting a negative number , it is the same as adding or subtracting its positive counterpart .   \n$\\begin{array}{r l r l r l r l}{(\\textbf{(8}*\\textbf{9}*\\textbf{0}-\\textbf{-1})}&{{}-\\textbf{(-9}}&{{}-\\textbf{7}+\\textbf{-4}-\\textbf{8})}&{{}=}&{}&{{}}\\end{array}$   \nShow your final answer bracketed between <answer > and </answer >.   \n$\\begin{array}{r l r l r l r l}{(\\textbf{(8}\\div\\textbf{9}\\ast\\textbf{0}\\cdots\\textbf{1})}&{{}-\\textbf{(-9}\\cdots\\textbf{7}+\\textbf{-4}\\cdots\\textbf{8}))}&{{}=}&{}&{{}}\\end{array}$   \n$1\\ .\\quad8\\ \\ *\\ \\ 9\\ \\ *\\ \\ 0\\ \\ \\ -\\ \\ \\ -\\ 1\\ \\ =\\ \\ 0\\ \\ +\\ \\ 1\\ \\ =\\ \\ 1$   \n$2\\cdot\\mathrm{~\\texttt~{~-~}~}\\cdot\\texttt{~-~}\\texttt{-}\\texttt{-}\\texttt{+}\\texttt{-}\\texttt{8}=\\texttt{-9}+\\texttt{7}\\texttt{-4}\\texttt{-8}=\\texttt{-14}$   \n3 $\\begin{array}{l l l l l l l l l l}{\\cdot}&{1}&{-}&{(\\mathit{\\Pi}-14\\mathit{\\Psi})}&{=}&{1}&{+}&{14}&{=}&{15}\\end{array}$   \n<answer $>\\!15\\!<\\!/$ answer >   \n$==$   \n1. When multiplying or dividing two negative numbers , the result will be positive.   \n2. When multiplying or dividing a positive and a negative number , the result will be negative.   \n3. When adding or subtracting a negative number , it is the same as adding or subtracting its positive counterpart .   \n$\\begin{array}{r l r l r l r l}{\\textnormal{((1}}&{*}&{0}&{-\\;-5}&{-\\;-\\;3\\,)}&{+}&{\\textnormal{(9}}&{*}&{6}&{+\\;\\;-4\\;\\;-\\;\\;0\\,)\\,\\textnormal{)}}&{=}&{}&{\\end{array}$   \nShow your final answer bracketed between <answer > and </answer >. $\\begin{array}{r l r l r l r l}{(\\texttt{(1}\\dot{*}\\texttt{0}\\texttt{--}5\\texttt{--}3)\\texttt{+}(\\mathfrak{g}\\texttt{*}\\texttt{6}\\texttt{+}\\texttt{-4}\\texttt{-}0)\\texttt{)}=}&{{}}&{}\\end{array}$ $\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!2\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!=\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\{\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!3\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!(\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!-\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!3\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!)\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!$   \n2. $\\begin{array}{r c c c c c c c c c c c}{(9}&{*}&{6}&{+}&{-4}&{-}&{0}\\end{array})}&{=}&{(\\,54\\,\\mathrm{\\boldmath~\\ell~}+\\,\\mathrm{\\boldmath~-~}4\\,\\mathrm{\\boldmath~\\ell~}-\\,\\mathrm{\\boldmath~0~})}&{=}&{50}&{\\,}&{\\,}\\end{array}$   \n3. $2+50=52$   \n<answer >52 </ answer >   \n$==$   \nGiven a set of instructions , determine whether following those instructions will take you back to the exact same spot you started from. Keep in mind any movements , including turns and the direction of any steps. For example , if you take 2 steps forward and then 2 steps backward , you will end up in the same spot. Determine your answer by saying \"yes\" or \"no\".   \nIf you follow these instructions , do you return to the starting point? Take 2 steps. Take 10 steps. Take 8 steps.   \nOptions:   \n- Yes   \n- No   \nShow your final answer (Yes or No only) bracketed between <answer > and </answer >. <answer >No </ answer >   \n$==$   \nIf you follow these instructions , do you return to the starting point? Always face forward. Take 6 steps forward. Take 7 steps backward. Take 7 steps backward. Take 8 steps forward.   \nOptions:   \n- Yes   \n- No   \nShow your final answer (Yes or No only) bracketed between <answer > and </answer >.   \n<answer $>$ Yes </answer >   \n==   \nIf you follow these instructions , do you return to the starting point? Take 6 steps. Turn around. Take 8 steps. Take 2 steps.   \nOptions:   \n- Yes   \n- No   \nShow your final answer (Yes or No only) bracketed between <answer > and </answer >. <answer >No </ answer >   \n$==$ ", "page_idx": 53}, {"type": "text", "text": "", "page_idx": 54}, {"type": "text", "text": "Listing 13: navigate: ProTeGi + Random Search. Test accuracy $=68.5\\%$ ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Q: I have a yam , a stalk of celery , a potato , a cabbage , two cauliflowers , an onion , a lettuce head , a head of broccoli , a carrot , and a garlic. How many vegetables do I have? Show your final answer bracketed between <answer > and </answer >. A: Let \u2019s break down the problem into smaller steps and solve each one. A: Let \u2019s break down the problem into smaller steps and solve each one.   \n1. Identify the vegetables: - Yam - Celery - Potato - Cabbage - Cauliflower (2) - Onion - Lettuce - Broccoli - Carrot - Garlic   \n2. Count the number of vegetables: - Yam: 1 Celery: 1 - Potato: 1 - Cabbage: 1 - Cauliflower : 2 - Onion: 1 - Lettuce: 1 - Broccoli: 1 - Carrot: 1 - Garlic: 1   \n3. Add up the counts: $\\texttt{l+1+1+1+2+1+1+1+1+1+1+1+1+1+1+1}=\\texttt{11}$ Therefore , the final answer is <answer >11 </ answer >. $==$ Q: I have a cauliflower , a cabbage , a garlic , a lettuce head , an onion , a head of broccoli , a potato , and a carrot. How many vegetables do I have?   \nShow your final answer bracketed between <answer > and </answer >.   \nA: Let \u2019s break down the problem into smaller steps and solve each one. A: Let \u2019s break down the problem into smaller steps and solve each one.   \n1. Identify the vegetables: - Cauliflower - Cabbage - Garlic - Lettuce head - Onion - Broccoli - Potato - Carrot   \n2. Count the number of vegetables: - There are 8 items in the list.   \nTherefore , the answer is <answer $>\\!8\\!<\\!/$ answer >.   \n$==$   \nQ: I have an accordion , a clarinet , and three drums. How many musical instruments do I have?   \nShow your final answer bracketed between <answer > and </answer >.   \nA: Let \u2019s break down the problem into smaller steps and solve each one. A: Let \u2019s break down the problem into smaller steps and solve each one.   \n1. We have one accordion.   \n2. We have one clarinet.   \n3. We have three drums.   \nAdding these up , we get:   \n${\\begin{array}{l l l l l l l}{1}&{+}&{1}&{+}&{3}&{=}&{5}&{}\\end{array}}$   \nTherefore , we have <answer $>5<.$ / answer $>$ musical instruments .   \n$==$ ", "page_idx": 54}, {"type": "text", "text": "", "page_idx": 55}, {"type": "text", "text": "Listing 14: object_counting: OPRO $^+$ Random Search. Test accuracy $=99.0\\%$ ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Q: Here is a table where the first line is a header and each subsequent line is a penguin : name , age , height (cm), weight (kg) Louis , 7, 50, 11 Bernard , 5, 80, 13 Vincent , 9, 60, 11 Gwen , 8, 70, 15 For example: the age of Louis is 7, the weight of Gwen is 15 kg , the height of Bernard is 80 cm. Which is the second heaviest penguin?   \nOptions:   \n(A) Louis   \n(B) Bernard   \n(C) Vincent   \n(D) Gwen   \n(E) James   \nShow your final answer option bracketed between <answer $>$ and </answer > at the end.   \nA: Let \u2019s proceed in a sequential manner. The heaviest penguin is Gwen , who weighs 15 kg. The second heaviest penguin must be either Louis , Bernard , or Vincent , as they all weigh less than Gwen.   \nLouis weighs $11\\;\\mathrm{\\textbf{kg}}$ , Bernard weighs $13\\;\\mathrm{~\\textmu~}\\mathrm{kg}$ , and Vincent weighs 11 kg. Therefore , Bernard is the second heaviest penguin.   \n<answer $>$ (B) </answer >   \n$==$   \nQ: Here is a table where the first line is a header and each subsequent line is a penguin : name , age , height (cm), weight (kg) Louis , 7, 50, 11 Bernard , 5, 80, 13 Vincent , 9, 60, 11 Gwen , 8, 70, 15 For example: the age of Louis is 7, the weight of Gwen is 15 kg , the height of Bernard is 80 cm. We then delete the penguin named Bernard from the table.   \nHow many penguins are more than 8 years old?   \nOptions:   \n(A) 1   \n(B) 2   \n(C) 3   \n(D) 4   \n(E) 5   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end.   \nA: Let \u2019s proceed in a sequential manner. The question asks the number of penguins that are more than 8 years old.   \nThe table has 4 penguins: Louis , Bernard , Vincent , and Gwen. Louis is 7 years old , Vincent is 9 years old , and Gwen is 8 years old.   \nTherefore , there is only 1 penguin that is more than 8 years old.   \n<answer $>$ (A) </answer >   \n$==$   \nQ: Here is a table where the first line is a header and each subsequent line is a penguin : name , age , height (cm), weight (kg) Louis , 7, 50, 11 Bernard , 5, 80, 13 Vincent , 9, 60, 11 Gwen , 8, 70, 15 For example: the age of Louis is 7, the weight of Gwen is 15 kg , the height of Bernard is 80 cm. How many penguins are less than 8 years old ?   \nOptions:   \n(A) 1   \n(B) 2   \n(C) 3   \n(D) 4   \n(E) 5   \nShow your final answer option bracketed between <answer > and </answer > at the end. A: Let \u2019s proceed in a sequential manner. Louis is 7 years old.   \nBernard is 5 years old.   \nVincent is 9 years old.   \nGwen is 8 years old.   \nThere are two penguins less than 8 years old.   \n<answer $>$ (B) </answer >   \n$==$ ", "page_idx": 55}, {"type": "text", "text": "", "page_idx": 56}, {"type": "text", "text": "Listing 15: penguins_in_a_table: APE $^+$ Random Search. Test accuracy $=89.7\\%$ ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Q: On the table , I see three black stress balls , one orange stress ball , two purple keychains , one black dog leash , one orange keychain , three orange cat toys , one black keychain , and one purple stress ball. If I remove all the cat toys from the table , how many orange items remain on it?   \nOptions:   \n(A) zero   \n(B) one   \n(C) two   \n(D) three   \n(E) four   \n(F) five   \n(G) six   \n(H) seven   \n(I) eight   \n(J) nine   \n(K) ten   \n(L) eleven   \n(M) twelve   \n(N) thirteen   \n(O) fourteen   \n(P) fifteen   \n(Q) sixteen   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Let \u2019s take a methodical approach. A: Let \u2019s take a methodical approach.   \nThere are three black stress balls , one orange stress ball , two purple keychains , one black dog leash , one orange keychain , three orange cat toys , one black keychain , and one purple stress ball.   \nIf we remove all the cat toys from the table , we are left with:   \nThree black stress balls   \nOne orange stress ball   \nTwo purple keychains   \nOne black dog leash   \nOne orange keychain   \nOne black keychain   \nOne purple stress ball   \nCounting the orange items , we have:   \nOne orange stress ball   \nOne orange keychain   \nSo , there are two orange items remaining on the table.   \n<answer >C</ answer >   \n$==$ Q: On the floor , you see a bunch of things arranged in a row: a turquoise paperclip , an orange bracelet , a green keychain , and a silver pen. What is the color of the thing directly to the left of the silver thing?   \nOptions:   \n(A) red   \n(B) orange   \n(C) yellow   \n(D) green   \n(E) blue   \n(F) brown   \n(G) magenta   \n(H) fuchsia   \n(I) mauve   \n(J) teal   \n(K) turquoise   \n(L) burgundy   \n(M) silver   \n(N) gold   \n(O) black   \n(P) grey   \n(Q) purple   \n(R) pink   \nShow your final answer option bracketed between <answer > and </answer > at the end. A: Let \u2019s take a methodical approach. A: Let \u2019s take a methodical approach. The question asks for the color of the thing directly to the left of the silver thing. The given items are:   \n- turquoise paperclip   \norange bracelet   \n- green keychain   \nsilver pen   \nReading from left to right , the silver pen is the last item. The item directly to its left is the green keychain. Therefore , the color of the thing directly to the left of the silver thing is green.   \n<answer >D</ answer >   \n$==$   \nQ: On the floor , there is a green pencil , a yellow mug , a fuchsia booklet , and a pink pen . Is the booklet fuchsia?   \nOptions:   \n(A) yes   \n(B) no   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Let \u2019s take a methodical approach. <answer $>\\tt A\\textless/$ answer >   \n$==$ ", "page_idx": 56}, {"type": "text", "text": "", "page_idx": 57}, {"type": "text", "text": "Listing 16: reasoning_about_colored_objects: APE $^+$ Diversity. Test accuracy $=80.5\\%$ ", "page_idx": 57}, {"type": "text", "text": "Q: Which of the following is a humorous edit of this artist or movie name: \u2019spice girls \u2019? Options:   \n(A) spihe girls   \n(B) spic girls   \n(C) spice tgirls   \n(D) spite girls   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Determine which answer choice represents the most plausible humorous edit. The humorous edit that stands out is:   \n<answer $>$ (D) spite girls </answer >   \nThis edit plays on the idea of spite , which is a feeling of resentment or ill will , adding a humorous twist to the original name \"Spice Girls .\"   \n==   \nQ: Which of the following is a humorous edit of this artist or movie name: \u2019the men who stare at goats \u2019?   \nOptions:   \n(A) the men who stare at boats   \n(B) uhe men who stare at goats   \n(C) the men who stare vt goats   \n(D) the omen who stare at goats   \nShow your final answer option bracketed between <answer > and </answer > at the end. A: Determine which answer choice represents the most plausible humorous edit. The humorous edit that stands out is:   \n(A) the men who stare at boats   \nThis edit introduces a comical twist by replacing \"goats\" with \"boats ,\" creating an amusing mental image of men intently staring at boats instead of goats. The other ", "page_idx": 57}, {"type": "text", "text": "options either contain typos or do not significantly alter the original name in a humorous way. ", "page_idx": 58}, {"type": "text", "text": "<answer $>$ (A) </answer > $==$ ", "page_idx": 58}, {"type": "text", "text": "Q: Which of the following is a humorous edit of this artist or movie name: \u2019gone with the wind \u2019?   \nOptions:   \n(A) gowne with the wind   \n(B) gone with the wand   \n(C) gone with the wing   \n(D) gone witth the wind   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: Determine which answer choice represents the most plausible humorous edit. <answer >(B) gone with the wand </ answer >   \n== ", "page_idx": 58}, {"type": "text", "text": "Listing 17: ruin_names: OPRO $^+$ Mutation. Test accuracy = 91.0% ", "text_level": 1, "page_idx": 58}, {"type": "table", "img_path": "IdtoJVWVnX/tmp/694b1f01071ead1c884c70b84d940f79e770731954c970ebba33e68257756cd0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 58}, {"type": "text", "text": "Therefore , the error pertains to (E) Dropped Content. ", "page_idx": 59}, {"type": "text", "text": "Final answer: <E> == ", "page_idx": 59}, {"type": "text", "text": "Q: The following translations from German to English contain a particular error. That error will be one of the following types: Named Entities: An entity (names , places , locations , etc .) is changed to a different entity. Numerical Values: Numerical values (ordinals or cardinals), dates , and/or units are changed. Modifiers or Adjectives: The modifiers and adjectives pertaining to a noun are changed. Negation or Antonyms: Introduce or remove a negation or change comparatives to their antonyms . Facts: Trivial factual errors not pertaining to the above classes are introduced in the translations . Dropped Content: A significant clause in the translation is removed. Please identify that error. Source: Karte mit allen Koordinaten : OSM | WikiMap   \nTranslation : Map with no coordinates : OSM | WikiMap   \nThe translation contains an error pertaining to   \nOptions:   \n(A) Modifiers or Adjectives   \n(B) Numerical Values   \n(C) Negation or Antonyms   \n(D) Named Entities   \n(E) Dropped Content   \n(F) Facts   \nShow your final answer option bracketed between <answer $>$ and </answer > at the end.   \nA: Let \u2019s think step by step. The original German sentence is \"Karte mit allen Koordinaten : OSM | WikiMap \". The English translation is \"Map with no coordinates : OSM | WikiMap \". The error in the translation is that the word \"allen\" (all) has been translated as \"no\". This is an error of Negation or Antonyms.   \n<answer $>$ (C) </answer >   \n$==$ ", "page_idx": 59}, {"type": "text", "text": "Listing 18: salient_translation_error_detection: APE $^+$ Random Search. Test accuracy $=$ $62.5\\%$ ", "page_idx": 59}, {"type": "text", "text": "Q: Which statement is sarcastic?   \nOptions:   \n(A) You can still achieve the American Dream after working at Walmart   \n(B) You can still achieve the American Dream of working at Walmart   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: We should move forward in stages. <answer $>$ (B) ${<}/$ answer >   \n$==$   \nQ: Which statement is sarcastic?   \nOptions:   \n(A) Anyone can be successful without having inherited all their money first (B) Nobody can be successful without having inherited all their money first Show your final answer option bracketed between <answer $>$ and </answer $>$ at the end. A: We should move forward in stages. <answer $>$ (B) ${<}/$ answer >   \n$==$   \nQ: Which statement is sarcastic?   \nOptions:   \n(A) We should start a petition to ban breathing   \n(B) We should start a petition to ban vaping   \nShow your final answer option bracketed between <answer $>$ and </answer > at the end. A: We should move forward in stages. <answer $>$ (A) </answer >   \n$==$ ", "page_idx": 59}, {"type": "text", "text": "Listing 19: snarks: APE $^+$ Random Search. Test accuracy $=87.4\\%$ ", "page_idx": 59}, {"type": "text", "text": "To address this question , we will divide it into smaller steps and use the provided knowledge about sports.   \nProvided knowledge:   \nDejounte Murray plays in the NBA.   \nGoal tending is a basketball rule.   \nToni Kroos is a professional football player.   \nFA Cup is a football competition .   \nTravis Konecny is a hockey player.   \nBryce Harper is a baseball player.   \nTuukka Rask is a hockey player. Giorgio Chiellini is a football player.   \nMaradona is a move in football. Back shoulder fade is a move in football.   \nPowerplay is a term in hockey.   \nHandball is an illegal move in football , where a player touches the ball with their hand during a match. Side -step three is a move in basketball .   \nStuds up is a term in football.   \nBlocking foul is a penalty in football. ", "page_idx": 59}, {"type": "text", "text": "", "page_idx": 60}, {"type": "text", "text": "Initially , we will define what it means for a sentence to be plausible in the context of sports. It is logical and consistent with the facts about sports when a sentence is plausible. ", "page_idx": 60}, {"type": "text", "text": "Now , we will look into the given four examples. For example 1, \"Travis Konecny did a maradona on the defender ,\" we can infer that this sentence is not plausible since maradona is a move in football , not hockey. Similarly , for example 2, \"Bryce Harper hit the back shoulder fade ,\" we can also infer that this sentence is not plausible because back shoulder fade is a move in football , not baseball. For example 3, \" Tuukka Rask killed the powerplay ,\" we can conclude that this sentence is plausible because powerplay is a term in hockey. Likewise , for example 4, \"Giorgio Chiellini committed a handball in the FA Cup ,\" we can also conclude that this sentence is plausible because handball is a penalty in football and the FA Cup is a football competition . ", "page_idx": 60}, {"type": "text", "text": "Based on the above analysis , the correct answers are:   \nExample 1: no   \nExample 2: no   \nExample 3: yes   \nExample 4: yes ", "page_idx": 60}, {"type": "text", "text": "Now , we will examine the two new examples. For example 1, \"Dejounte Murray took a side - step three ,\" we can conclude that this sentence is plausible since side -step three is a move in basketball. Similarly , for example 2, \"Luka Modric went in studs up in the FA Cup ,\" we can also conclude that this sentence is plausible because studs up is a term in football and the FA Cup is a football competition . ", "page_idx": 60}, {"type": "text", "text": "Therefore , the correct answers for the new examples are:   \nExample 1: yes   \nExample 2: yes   \nIs the following sentence plausible? \"Neymar did a maradona on the defender in the Champions Leage Semifinal .\" ", "page_idx": 60}, {"type": "text", "text": "Show your final answer (yes or no only) bracketed between <answer > and </answer >. <answer >yes </answer > ", "page_idx": 60}, {"type": "text", "text": "Provided knowledge: Dejounte Murray plays in the NBA. Goal tending is a basketball rule. Toni Kroos is a professional football player.   \nFA Cup is a football competition . Travis Konecny is a hockey player. Bryce Harper is a baseball player. Tuukka Rask is a hockey player. Giorgio Chiellini is a football player. Maradona is a move in football. Back shoulder fade is a move in football.   \nPowerplay is a term in hockey. ", "page_idx": 60}, {"type": "text", "text": "Initially , we will define what it means for a sentence to be plausible in the context of sports. It is logical and consistent with the facts about sports when a sentence is plausible. ", "page_idx": 60}, {"type": "text", "text": "Now , we will look into the given four examples. For example 1, \"Travis Konecny did a maradona on the defender ,\" we can infer that this sentence is not plausible since maradona is a move in football , not hockey. Similarly , for example 2, \"Bryce Harper hit the back shoulder fade ,\" we can also infer that this sentence is not plausible because back shoulder fade is a move in football , not baseball. For example 3, \" Tuukka Rask killed the powerplay ,\" we can conclude that this sentence is plausible because powerplay is a term in hockey. Likewise , for example 4, \"Giorgio Chiellini committed a handball in the FA Cup ,\" we can also conclude that this sentence is plausible because handball is a penalty in football and the FA Cup is a football competition . ", "page_idx": 60}, {"type": "text", "text": "Based on the above analysis , the correct answers are:   \nExample 1: no   \nExample 2: no   \nExample 3: yes   \nExample 4: yes   \nNow , we will examine the two new examples. For example 1, \"Dejounte Murray took a side - step three ,\" we can conclude that this sentence is plausible since side -step three is a move in basketball. Similarly , for example 2, \"Luka Modric went in studs up in the FA Cup ,\" we can also conclude that this sentence is plausible because studs up is a term in football and the FA Cup is a football competition .   \nTherefore , the correct answers for the new examples are:   \nExample 1: yes   \nExample 2: yes   \nIs the following sentence plausible? \"Collin Sexton hit the buzzer beater .\"   \nShow your final answer (yes or no only) bracketed between <answer > and </answer >. <answer >yes </answer >   \n$==$   \nProvided knowledge:   \nDejounte Murray plays in the NBA. Goal tending is a basketball rule. Toni Kroos is a professional football player. FA Cup is a football competition . Travis Konecny is a hockey player. Bryce Harper is a baseball player. Tuukka Rask is a hockey player. Giorgio Chiellini is a football player. Maradona is a move in football. Back shoulder fade is a move in football. Powerplay is a term in hockey. Handball is an illegal move in football , where a player touches the ball with their hand during a match. Side -step three is a move in basketball . Studs up is a term in football. Blocking foul is a penalty in football.   \nInitially , we will define what it means for a sentence to be plausible in the context of sports. It is logical and consistent with the facts about sports when a sentence is plausible.   \nNow , we will look into the given four examples. For example 1, \"Travis Konecny did a maradona on the defender ,\" we can infer that this sentence is not plausible since maradona is a move in football , not hockey. Similarly , for example 2, \"Bryce Harper hit the back shoulder fade ,\" we can also infer that this sentence is not plausible because back shoulder fade is a move in football , not baseball. For example 3, \" Tuukka Rask killed the powerplay ,\" we can conclude that this sentence is plausible because powerplay is a term in hockey. Likewise , for example 4, \"Giorgio Chiellini committed a handball in the FA Cup ,\" we can also conclude that this sentence is plausible because handball is a penalty in football and the FA Cup is a football competition .   \nBased on the above analysis , the correct answers are:   \nExample 1: no   \nExample 2: no   \nExample 3: yes   \nExample 4: yes   \nNow , we will examine the two new examples. For example 1, \"Dejounte Murray took a side - step three ,\" we can conclude that this sentence is plausible since side -step three is a move in basketball. Similarly , for example 2, \"Luka Modric went in studs up in the FA Cup ,\" we can also conclude that this sentence is plausible because studs up is a term in football and the FA Cup is a football competition .   \nTherefore , the correct answers for the new examples are:   \nExample 1: yes   \nExample 2: yes   \nIs the following sentence plausible? \"Stefon Diggs hit the slant pass .\"   \nShow your final answer (yes or no only) bracketed between <answer > and </answer >. <answer >yes </answer >   \n$==$ ", "page_idx": 60}, {"type": "text", "text": "", "page_idx": 61}, {"type": "text", "text": "Listing 20: sports_understanding: ProTeGi + Mutation. Test accuracy $=90.0\\%$ ", "page_idx": 61}, {"type": "text", "text": "To solve this problem , we can break it down into smaller steps. The first step is to find the time when the person woke up. Once we have that information , we can then proceed to the next step , which is to identify the earliest time slot that has not been accounted for.   \nToday , James went to the swimming pool. Between what times could they have gone?   \nWe know that:   \nJames woke up at 5am.   \nAshley saw James sitting on a rooftop from 7am to 9am.   \nHannah saw James taking photos near the Eiffel Tower from 9am to 7pm.   \nWilliam saw James buying cookies at a bakery from 7pm to 8pm.   \nLinda saw James waiting at the train station from 8pm to $10\\,\\mathrm{pm}$ .   \nThe swimming pool was closed after $10\\,\\mathrm{pm}$ .   \nBetween what times could James have gone to the swimming pool?   \nOptions:   \n(A) 7pm to 8pm   \n(B) 8pm to 10pm   \n(C) 5am to 7am   \n(D) 7am to 9am   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nThe person woke up at 5am. Ashley saw James sitting on a rooftop from 7am to 9am. This means that James could not have gone to the swimming pool during this time. Hannah saw James taking photos near the Eiffel Tower from 9am to 7pm. This means that James could not have gone to the swimming pool during this time either. William saw James buying cookies at a bakery from 7pm to 8pm. This means that James could not have gone to the swimming pool during this time either. Linda saw James waiting at the train station from 8pm to $10\\,\\mathrm{pm}$ . This means that James could not have gone to the swimming pool during this time either. Therefore , the only time slot that is left is from 5am to 7am.   \n<answer $>$ (C) </answer >   \n$==$   \nToday , James went to the beach. Between what times could they have gone?   \nWe know that:   \nJames woke up at 5am.   \nSean saw James walking towards the Statue of Liberty from 5am to 6am.   \nMichael saw James driving to the water park from 6am to 7am.   \nAnthony saw James reading at the library from 7am to 3pm.   \nWilliam saw James getting a coffee at the cafe from 4pm to 9pm.   \nThe beach was closed after 9pm.   \nBetween what times could James have gone to the beach?   \nOptions:   \n(A) 7am to 3pm   \n(B) 5am to 6am   \n(C) 4pm to 9pm   \n(D) 3pm to 4pm   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nJames woke up at 5am.   \nSean saw James walking towards the Statue of Liberty from 5am to 6am.   \nMichael saw James driving to the water park from 6am to 7am.   \nAnthony saw James reading at the library from 7am to 3pm.   \nWilliam saw James getting a coffee at the cafe from 4pm to 9pm.   \nThe beach was closed after 9pm.   \nFrom the information given , we know that James was at the Statue of Liberty from 5am to 6 am , at the water park from 6am to 7am , and at the library from 7am to 3pm. This means that he could not have gone to the beach during those times. He was also at the cafe from 4pm to 9pm , so he could not have gone to the beach then either.   \nTherefore , the only time slot that is not accounted for is from 3pm to 4pm.   \n<answer $>$ (D) </answer >   \n$==$   \nToday , Elizabeth went to the park. Between what times could they have gone?   \nWe know that:   \nElizabeth woke up at 10am.   \nEmily saw Elizabeth buying a bike at the bike shop from 10am to 11am.   \nLeslie saw Elizabeth buying lunch at the deli from 11am to 2pm.   \nSarah saw Elizabeth playing tennis at the tennis court from 4pm to 8pm.   \nThe park was closed after 8pm.   \nBetween what times could Elizabeth have gone to the park?   \nOptions:   \n(A) 10am to 11am   \n(B) 11am to 2pm   \n(C) 4pm to 8pm   \n(D) 2pm to 4pm   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nElizabeth woke up at 10am. She was seen at the bike shop from 10am to 11am , at the deli from 11am to 2pm , and at the tennis court from 4pm to 8pm. The park was closed after 8pm. Therefore , the earliest time slot that has not been accounted for is from 2pm to 4pm.   \n<answer $>$ (D) </answer >   \n$==$ ", "page_idx": 61}, {"type": "text", "text": "", "page_idx": 62}, {"type": "text", "text": "Listing 21: temporal_sequences: ProTeGi + Mutation. Test accuracy = 100.0% ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Let \u2019s approach this task in a systematic manner. First , let \u2019s identify all the different objects that are being swapped in the context. Then , let \u2019s trace the swaps and keep track of the objects as they change hands. Finally , let \u2019s use our understanding of the swaps and the initial positions of the objects to answer the question. We also need to make sure that all the information necessary to answer the question is ", "page_idx": 62}, {"type": "text", "text": "contained in the context and check that the number of players is the same as the number of objects. ", "page_idx": 63}, {"type": "text", "text": "Alice , Bob , Claire , Dave , and Eve are holding a white elephant gift exchange. At the start of the event , they are each holding a present of a different color: Alice has a purple present , Bob has a blue present , Claire has a brown present , Dave has a yellow present , and Eve has a black ball. ", "page_idx": 63}, {"type": "text", "text": "As the event progresses , pairs of people swap gifts. First , Alice and Bob swap their gifts. Then , Bob and Dave swap their gifts. Then , Claire and Bob swap their gifts. Then , Dave and Alice swap their gifts. Finally , Dave and Eve swap their gifts. At the end of the event , Dave has the ", "page_idx": 63}, {"type": "text", "text": "Options:   \n(A) purple present   \n(B) blue present   \n(C) brown present   \n(D) yellow present   \n(E) black ball   \nShow your final answer option bracketed between <answer $>$ and </answer > at the end. Iets ", "page_idx": 63}, {"type": "text", "text": "1. Alice and Bob swap their gifts: Alice gives her purple present to Bob , and Bob gives his blue present to Alice. So now Alice has the blue present , and Bob has the purple present. ", "page_idx": 63}, {"type": "text", "text": "2. Bob and Dave swap their gifts: Bob gives his purple present to Dave , and Dave gives his yellow present to Bob. So now Bob has the yellow present , and Dave has the purple present. ", "page_idx": 63}, {"type": "text", "text": "3. Claire and Bob swap their gifts: Claire gives her brown present to Bob , and Bob gives his yellow present to Claire. So now Bob has the brown present , and Claire has the yellow present. ", "page_idx": 63}, {"type": "text", "text": "4. Dave and Alice swap their gifts: Dave gives his purple present to Alice , and Alice gives her blue present to Dave. So now Alice has the purple present again , and Dave has the blue present again. ", "page_idx": 63}, {"type": "text", "text": "5. Dave and Eve swap their gifts: Dave gives his blue present to Eve , and Eve gives her black ball to Dave. So now Dave has the black ball , and Eve has the blue present. ", "page_idx": 63}, {"type": "text", "text": "At the end of the swaps , Dave has the black ball ", "page_idx": 63}, {"type": "text", "text": "Therefore , the answer is: <answer $>$ (E) ${<}/$ answer > ", "page_idx": 63}, {"type": "text", "text": "Alice , Bob , Claire , Dave , and Eve are dancers at a square dance. At the start of a song , they each have a partner: Alice is dancing with Rodrigo , Bob is dancing with Sam , Claire is dancing with Izzi , Dave is dancing with Jamie , and Eve is dancing with Ophelia. ", "page_idx": 63}, {"type": "text", "text": "Throughout the song , the dancers often trade partners. First , Bob and Eve switch partners . Then , Alice and Bob switch partners. Then , Eve and Bob switch partners. Then , Dave and Alice switch partners. Finally , Eve and Claire switch partners. At the end of the dance , Alice is dancing with ", "page_idx": 63}, {"type": "text", "text": "Options:   \n(A) Rodrigo   \n(B) Sam   \n(C) Izzi   \n(D) Jamie   \n(E) Ophelia   \nShow your final answer option bracketed between <answer > and </answer > at the end. ", "page_idx": 63}, {"type": "text", "text": "Let \u2019s identify the dancers and their initial partners: ", "page_idx": 63}, {"type": "text", "text": "Eve and Bob switch partners: Eve is now dancing with Rodrigo , and Bob is dancing with Sam again. ", "page_idx": 63}, {"type": "text", "text": "Dave and Alice switch partners: Dave is now dancing with Alice , and Alice is dancing with Jamie. ", "page_idx": 63}, {"type": "text", "text": "Eve and Claire switch partners: Eve is now dancing with Izzi , and Claire is dancing with Rodrigo. ", "page_idx": 63}, {"type": "text", "text": "At the end of the dance , Alice is dancing with Jamie ", "page_idx": 63}, {"type": "text", "text": "$==$   \nAlice , Bob , Claire , Dave , and Eve are dancers at a square dance. At the start of a song , they each have a partner: Alice is dancing with Lola , Bob is dancing with Melissa , Claire is dancing with Jamie , Dave is dancing with Rodrigo , and Eve is dancing with Helga.   \nThroughout the song , the dancers often trade partners. First , Bob and Eve switch partners . Then , Alice and Dave switch partners. Then , Eve and Bob switch partners. Then , Eve and Claire switch partners. Finally , Dave and Bob switch partners. At the end of the dance , Eve is dancing with   \nOptions:   \n(A) Lola   \n(B) Melissa   \n(C) Jamie   \n(D) Rodrigo   \n(E) Helga   \nShow your final answer option bracketed between <answer > and </answer > at the end. Let \u2019s identify the dancers and their initial partners:   \n- Alice: Lola   \n- Bob: Melissa   \n- Claire: Jamie   \n- Dave: Rodrigo   \n- Eve: Helga   \nNow , let \u2019s trace the swaps:   \n1. Bob and Eve switch partners: Bob is now dancing with Helga , and Eve is dancing with Melissa.   \n2. Alice and Dave switch partners: Alice is now dancing with Rodrigo , and Dave is dancing with Lola.   \n3. Eve and Bob switch partners: Eve is now dancing with Bob , and Bob is dancing with Melissa again.   \n4. Eve and Claire switch partners: Eve is now dancing with Claire , and Claire is dancing with Bob.   \n5. Dave and Bob switch partners: Dave is now dancing with Melissa , and Bob is dancing with Rodrigo.   \nAt the end of the dance , Eve is dancing with Claire. <answer $>$ (C) </answer >   \n== ", "page_idx": 64}, {"type": "text", "text": "Listing 22: tracking_shuffled_objects_five_objects: ProTeGi $^+$ Random Search. Test accuracy $=70.0\\%$ ", "page_idx": 64}, {"type": "text", "text": "Q: Alice , Bob , Claire , Dave , Eve , Fred , and Gertrude are dancers at a square dance. At the start of a song , they each have a partner: Alice is dancing with Lola , Bob is dancing with Ophelia , Claire is dancing with Sam , Dave is dancing with Helga , Eve is dancing with Patrick , Fred is dancing with Jamie , and Gertrude is dancing with Rodrigo.   \nThroughout the song , the dancers often trade partners. First , Fred and Bob switch partners. Then , Eve and Alice switch partners. Then , Fred and Eve switch partners. Then , Claire and Fred switch partners. Then , Gertrude and Alice switch partners. ", "page_idx": 64}, {"type": "text", "text": "Then , Alice and Bob switch partners. Finally , Dave and Fred switch partners. At the end of the dance , Dave is dancing with ", "page_idx": 64}, {"type": "text", "text": "Options:   \n(A) Lola   \n(B) Ophelia   \n(C) Sam   \n(D) Helga   \n(E) Patrick   \n(F) Jamie   \n(G) Rodrigo   \nShow your final answer option bracketed between <answer > and </answer > at the end. ", "page_idx": 64}, {"type": "text", "text": "At the start of the dance , the dancers are paired as follows: ", "page_idx": 64}, {"type": "text", "text": "Alice - Lola Bob - Ophelia Claire - Sam Dave - Helga Eve - Patrick Fred - Jamie Gertrude - Rodrigo ", "page_idx": 64}, {"type": "text", "text": "Step 1: Fred and Bob switch partners. ", "page_idx": 64}, {"type": "text", "text": "Alice - Lola ", "page_idx": 64}, {"type": "text", "text": "Step 2: Eve and Alice switch partners. ", "page_idx": 65}, {"type": "text", "text": "Alice - Patrick   \nBob - Jamie   \nClaire - Sam   \nDave - Helga   \nEve - Lola   \nFred - Ophelia   \nGertrude - Rodrigo ", "page_idx": 65}, {"type": "text", "text": "Step 3: Fred and Eve switch partners. ", "page_idx": 65}, {"type": "text", "text": "Alice - Patrick   \nBob - Jamie   \nClaire - Sam   \nDave - Helga   \nEve - Ophelia   \nFred - Lola   \nGertrude - Rodrigo ", "page_idx": 65}, {"type": "text", "text": "Step 4: Claire and Fred switch partners. ", "page_idx": 65}, {"type": "text", "text": "Alice - Patrick   \nBob - Jamie   \nClaire - Lola   \nDave - Helga   \nEve - Ophelia   \nFred - Sam   \nGertrude - Rodrigo ", "page_idx": 65}, {"type": "text", "text": "Step 5: Gertrude and Alice switch partners. ", "page_idx": 65}, {"type": "text", "text": "Alice - Rodrigo   \nBob - Jamie   \nClaire - Lola   \nDave - Helga   \nEve - Ophelia   \nFred - Sam   \nGertrude - Patrick ", "page_idx": 65}, {"type": "text", "text": "Step 6: Alice and Bob switch partners. ", "page_idx": 65}, {"type": "text", "text": "Alice - Jamie Bob - Rodrigo Claire - Lola Dave - Helga Eve - Ophelia Fred - Sam Gertrude - Patrick ", "page_idx": 65}, {"type": "text", "text": "Step 7: Dave and Fred switch partners. ", "page_idx": 65}, {"type": "text", "text": "Alice - Jamie Bob - Rodrigo Claire - Lola Dave - Sam Eve - Ophelia Fred - Helga Gertrude - Patrick ", "page_idx": 65}, {"type": "text", "text": "At the end of the dance , Dave is dancing with Sam. ", "page_idx": 65}, {"type": "text", "text": "The final answer is <answer $>$ (C) ${<}/$ answer $>$ . ", "page_idx": 65}, {"type": "text", "text": "swap books. Finally , Dave and Bob swap books. At the end of the semester , Claire has Options: (A) Lolita (B) Moby Dick (C) Hound of the Baskervilles (D) Catch -22 (E) The Fellowship of the Ring (F) The Pearl (G) Frankenstein Show your final answer option bracketed between <answer $>$ and </answer $>$ at the end. ", "page_idx": 66}, {"type": "text", "text": "A: Let \u2019s follow a step -by -step process. Let \u2019s follow a step -by -step process.   \nAt the start of the semester , Alice has Lolita.   \nAfter the first swap , Dave has Lolita and Bob has Catch -22.   \nAfter the second swap , Alice has The Fellowship of the Ring and Eve has Lolita.   \nAfter the third swap , Bob has Lolita and Fred has Catch -22.   \nAfter the fourth swap , Gertrude has Lolita and Claire has Frankenstein .   \nAfter the fifth swap , Fred has Lolita and Dave has Catch -22.   \nAfter the sixth swap , Alice has Lolita and Fred has The Fellowship of the Ring.   \nAfter the seventh swap , Dave has Lolita and Bob has The Fellowship of the Ring.   \nAt the end of the semester , Claire has Frankenstein .   \n<answer $>$ (G) </answer >   \n$==$   \nQ: Alice , Bob , Claire , Dave , Eve , Fred , and Gertrude are dancers at a square dance. At the start of a song , they each have a partner: Alice is dancing with Ophelia , Bob is dancing with Melissa , Claire is dancing with Jamie , Dave is dancing with Sam , Eve is dancing with Patrick , Fred is dancing with Rodrigo , and Gertrude is dancing with Karl.   \nThroughout the song , the dancers often trade partners. First , Dave and Claire switch partners. Then , Alice and Eve switch partners. Then , Eve and Bob switch partners. Then , Claire and Bob switch partners. Then , Fred and Eve switch partners. Then , Gertrude and Dave switch partners. Finally , Dave and Alice switch partners. At the end of the dance , Fred is dancing with   \nOptions:   \n(A) Ophelia   \n(B) Melissa   \n(C) Jamie   \n(D) Sam   \n(E) Patrick   \n(F) Rodrigo   \n(G) Karl   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end.   \nA: Let \u2019s follow a step -by -step process. Let \u2019s follow the steps one by one:   \n1. Dave and Claire switch partners.   \nDave was dancing with Sam , and Claire was dancing with Jamie. So now , Dave is dancing with Jamie , and Claire is dancing with Sam.   \n2. Alice and Eve switch partners.   \nAlice was dancing with Ophelia , and Eve was dancing with Patrick. So now , Alice is dancing with Patrick , and Eve is dancing with Ophelia.   \n3. Eve and Bob switch partners.   \nEve was dancing with Patrick , and Bob was dancing with Melissa. So now , Eve is dancing with Melissa , and Bob is dancing with Patrick.   \n4. Claire and Bob switch partners.   \nClaire was dancing with Sam , and Bob was dancing with Patrick. So now , Claire is dancing with Patrick , and Bob is dancing with Sam.   \n5. Fred and Eve switch partners.   \nFred was dancing with Rodrigo , and Eve was dancing with Melissa. So now , Fred is dancing with Melissa , and Eve is dancing with Rodrigo.   \n6. Gertrude and Dave switch partners.   \nGertrude was dancing with Karl , and Dave was dancing with Jamie. So now , Gertrude is dancing with Jamie , and Dave is dancing with Karl.   \n7. Dave and Alice switch partners. ", "page_idx": 66}, {"type": "text", "text": "", "page_idx": 66}, {"type": "text", "text": "Dave was dancing with Karl , and Alice was dancing with Patrick. So now , Dave is dancing with Patrick , and Alice is dancing with Karl. ", "page_idx": 67}, {"type": "text", "text": "At the end of the dance , Fred is dancing with Melissa. ", "page_idx": 67}, {"type": "text", "text": "<answer $>$ (B) </answer > == ", "page_idx": 67}, {"type": "text", "text": "Listing 23: tracking_shuffled_objects_seven_objects: APE $^+$ Mutation. Test accuracy $=$ $86.0\\%$ ", "page_idx": 67}, {"type": "text", "text": "We will methodically address this by breaking it down into manageable portions. We will monitor the final status of every entity (e.g., Alice , Bob , and Claire) after the transactions noted in the problem. We will also monitor the flow of the transactions   \nAlice , Bob , and Claire are dancers at a square dance. At the start of a song , they each have a partner: Alice is dancing with Helga , Bob is dancing with Patrick , and Claire is dancing with Sam.   \nThroughout the song , the dancers often trade partners. First , Claire and Alice switch partners. Then , Claire and Bob switch partners. Finally , Alice and Bob switch partners. At the end of the dance , Bob is dancing with   \nOptions:   \n(A) Helga   \n(B) Patrick   \n(C) Sam   \nShow your final answer option bracketed between <answer > and </answer > at the end.   \nLet \u2019s track the partners of Alice , Bob , and Claire throughout the dance:   \n- Initially , Alice is dancing with Helga , Bob is dancing with Patrick , and Claire is dancing with Sam.   \n- After the first switch , Claire and Alice switch partners , so Alice is now dancing with Sam , and Claire is dancing with Helga.   \n- After the second switch , Claire and Bob switch partners , so Claire is now dancing with Bob , and Bob is dancing with Helga. After the third switch , Alice and Bob switch partners , so Alice is now dancing with Bob , and Bob is dancing with Sam.   \nTherefore , at the end of the dance , Bob is dancing with Sam.   \n<answer $>$ (C) </answer >   \n$==$   \nAlice , Bob , and Claire are dancers at a square dance. At the start of a song , they each have a partner: Alice is dancing with Lola , Bob is dancing with Patrick , and Claire is dancing with Melissa.   \nThroughout the song , the dancers often trade partners. First , Alice and Claire switch partners. Then , Bob and Claire switch partners. Finally , Claire and Alice switch partners. At the end of the dance , Alice is dancing with   \nOptions:   \n(A) Lola   \n(B) Patrick   \n(C) Melissa   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end.   \nLet \u2019s track the partners of Alice , Bob , and Claire throughout the dance:   \n- Initially , Alice is dancing with Lola , Bob is dancing with Patrick , and Claire is dancing with Melissa.   \n- After the first switch , Alice and Claire switch partners , so Alice is now dancing with Melissa , and Claire is dancing with Lola.   \n- After the second switch , Bob and Claire switch partners , so Bob is now dancing with Melissa , and Claire is dancing with Patrick.   \n- After the third switch , Claire and Alice switch partners again , so Claire is now dancing with Melissa , and Alice is dancing with Patrick. ", "page_idx": 67}, {"type": "text", "text": "Therefore , the answer is: <answer $>$ (B) </answer > $==$ ", "page_idx": 67}, {"type": "text", "text": "Alice , Bob , and Claire are friends and avid readers who occasionally trade books. At the start of the semester , they each buy one new book: Alice gets Catch -22, Bob gets Moby Dick , and Claire gets The Fellowship of the Ring.   \nAs the semester proceeds , they start trading around the new books. First , Claire and Alice swap books. Then , Bob and Alice swap books. Finally , Claire and Bob swap books . At the end of the semester , Claire has   \nOptions:   \n(A) Catch -22   \n(B) Moby Dick   \n(C) The Fellowship of the Ring   \nShow your final answer option bracketed between <answer $>$ and </answer $>$ at the end.   \n$^{\\ast\\ast}$ Initial Status :\\*\\*   \n- Alice: Catch -22   \n- Bob: Moby Dick   \n- Claire: The Fellowship of the Ring   \n\\*\\* First Trade (Claire and Alice swap books):\\*\\* Alice: The Fellowship of the Ring Bob: Moby Dick   \n- Claire: Catch -22   \n\\*\\* Second Trade (Bob and Alice swap books):\\*\\* Alice: Moby Dick Bob: The Fellowship of the Ring Claire: Catch -22   \n\\*\\* Third Trade (Claire and Bob swap books):\\*\\* Alice: Moby Dick Bob: Catch -22   \nClaire: The Fellowship of the Ring   \n\\*\\* Final Status :\\*\\* Alice: Moby Dick Bob: Catch -22   \n- Claire: The Fellowship of the Ring   \nTherefore , at the end of the semester , Claire has \\*\\* The Fellowship of the Ring \\*\\*.   \n<answer $>$ (C) </answer >   \n$==$ ", "page_idx": 68}, {"type": "text", "text": "Listing 24: tracking_shuffled_objects_three_objects: ProTeGi $^+$ Random Search. Test accuracy $=74.0\\%$ ", "page_idx": 68}, {"type": "text", "text": "Q: Question: Jim lies. Crista says Jim lies. Vernell says Crista tells the truth. Bernita says Vernell tells the truth. Millicent says Bernita tells the truth. Does Millicent tell the truth?   \nShow your final answer (Yes or No only) bracketed between <answer > and </answer >.   \nA: Let \u2019s follow a step -by -step approach. Let \u2019s follow a step -by -step approach.   \n1. Jim lies. So , Jim is a liar.   \n2. Crista says Jim lies. If Crista is telling the truth , then Jim is a liar. But we already know that Jim is a liar. So , Crista is telling the truth.   \n3. Vernell says Crista tells the truth. If Vernell is telling the truth , then Crista is telling the truth. We already know that Crista is telling the truth. So , Vernell is telling the truth.   \n4. Bernita says Vernell tells the truth. If Bernita is telling the truth , then Vernell is telling the truth. We already know that Vernell is telling the truth. So , Bernita is telling the truth.   \n5. Millicent says Bernita tells the truth. If Millicent is telling the truth , then Bernita is telling the truth. We already know that Bernita is telling the truth. So , Millicent is telling the truth.   \nTherefore , the answer is <answer $>$ Yes </ answer >.   \n==   \nQ: Question: Conception tells the truth. Elanor says Conception tells the truth. Alexis says Elanor tells the truth. Fidel says Alexis tells the truth. Delbert says Fidel lies. Does Delbert tell the truth? $<$ Show your final answer (Yes or No only) bracketed between answer > and </answer >.   \nA: Let \u2019s follow a step -by -step approach. Let \u2019s follow a step -by -step approach. 1. Conception tells the truth.   \n2. Elanor says Conception tells the truth. (Hence , Elanor also tells the truth .) 3. Alexis says Elanor tells the truth. (Hence , Alexis also tells the truth .)   \n4. Fidel says Alexis tells the truth. (Hence , Fidel also tells the truth .)   \n5. Delbert says Fidel lies.   \nIf Delbert tells the truth , then Fidel lies. But if Fidel lies , then Delbert must be lying. Therefore , Delbert cannot be telling the truth.   \n<answer $>$ No </ answer >   \n$==$   \nQ: Question: Helene tells the truth. Leda says Helene lies. Antwan says Leda tells the truth. Andree says Antwan lies. Shaunda says Andree lies. Does Shaunda tell the truth?   \nShow your final answer (Yes or No only) bracketed between <answer > and </answer >. A: Let \u2019s follow a step -by -step approach. Let \u2019s follow a step -by -step approach.   \n1. Helene tells the truth.   \n2. Leda says Helene lies. (This contradicts statement 1, so Leda is lying .)   \n3. Antwan says Leda tells the truth. (This contradicts statement 2, so Antwan is lying .) 4. Andree says Antwan lies. (This is true because Antwan is indeed lying .)   \n5. Shaunda says Andree lies. (This contradicts statement 4, so Shaunda is lying .) ", "page_idx": 68}, {"type": "text", "text": "", "page_idx": 68}, {"type": "text", "text": "", "page_idx": 69}, {"type": "text", "text": "Therefore , the final answer is <answer $>$ No </ answer >. ", "page_idx": 69}, {"type": "text", "text": "Listing 25: web_of_lies: APE $^+$ Random Search. Test accuracy $=99.5\\%$ ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "Q: Sort the following words alphabetically : List: roadster earl metaphoric hollandaise supranational psyche pedro gloss granola quarantine inauspicious penis baccarat arenaceous mackenzie blare bowman   \nShow your final answer bracketed between <answer $>$ and </answer >.   \nA: Let \u2019s think step by step. The words sorted alphabetically are:   \n<answer >arenaceous , baccarat , blare , bowman , earl , gloss , granola , hollandaise , inauspicious , mackenzie , metaphoric , pedro , penis , psyche , quarantine , roadster , supranational ${<}/$ answer $>$   \nQ: Sort the following words alphabetically : List: almost delphic semitic unbeknownst astute deadlock libertarian antic levitate execution sanction scathe storehouse dandelion affable sweeney fortunate leverage horntail apache   \nShow your final answer bracketed between <answer > and </answer >.   \nA: Let \u2019s think step by step. \\*\\* Step 1:\\*\\* List the words alphabetically .   \n- affable   \n- almost   \n- antic   \n- apache astute   \n- dandelion   \n- deadlock   \n- delphic execution   \n- fortunate   \n- horntail   \n- leverage   \n- levitate libertarian sanction   \n- scathe   \n- semitic   \n- storehouse   \n- sweeney unbeknownst ", "page_idx": 69}, {"type": "text", "text": "", "page_idx": 69}, {"type": "text", "text": "", "page_idx": 69}, {"type": "text", "text": "$**8$ tep 2:\\*\\* Place the words between <answer > and </answer >. ", "page_idx": 69}, {"type": "text", "text": "<answer $>$ affable   \nalmost   \nantic   \napache   \nastute   \ndandelion   \ndeadlock   \ndelphic   \nexecution   \nfortunate ", "page_idx": 69}, {"type": "image", "img_path": "IdtoJVWVnX/tmp/03817461b3231cb388de282f33cb0e25e4043118ab0e53047f6c554a6988500d.jpg", "img_caption": ["Listing 26: word_sorting: No IO $^+$ Mutation. Test accuracy $=81.5\\%$ "], "img_footnote": [], "page_idx": 70}]