[{"figure_path": "IdtoJVWVnX/tables/tables_5_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy scores achieved by combining various instruction optimization (IO) and exemplar optimization (EO) methods.  It shows the performance of using no IO/EO, various IO methods (APE, ProTeGi, PromptAgent, OPRO), and various EO methods (Random, Nearest, Diversity, Random Search, Mutation). The table highlights the maximum improvement in accuracy obtained with each EO method compared to the baseline (No EO) and the maximum improvement when combining IO and EO, relative to the baseline (No IO/EO). The color-coding indicates the computational cost (number of prompt evaluations on the validation set) for each experiment.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_5_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance of different combinations of instruction optimization (IO) and exemplar optimization (EO) methods on the BIG-Bench Hard (BBH) benchmark using PaLM 2.  It shows the impact of various IO and EO strategies, both individually and in combination, on the model's accuracy. The table highlights the computational cost associated with each method by color-coding the cells, indicating the number of prompt evaluations on the validation set. The last row and column show the maximum accuracy improvement achieved by EO and IO respectively.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_5_3.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance across BIG-Bench Hard (BBH) tasks for various combinations of instruction optimization (IO) and exemplar optimization (EO) methods.  The rows represent different IO methods (No IO, APE, ProTeGi, PromptAgent, OPRO), while the columns show different EO methods (No EO, Random, Nearest, Diversity, Random Search, Mutation).  The numbers in the cells show the average BBH accuracy for each IO-EO combination. The last row and column highlight the maximum improvement achieved over baselines (No IO and No EO).  Color-coding indicates the computational cost: gray is zero cost, blue is a cost of 32 prompt evaluations, and orange is a cost of more than 32 prompt evaluations due to iterative optimization.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_24_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy results for various combinations of instruction optimization (IO) and exemplar optimization (EO) methods using PaLM 2.  It shows the impact of using different EO strategies (No EO, Random, Nearest, Diversity, Random Search, and Mutation) in conjunction with different IO strategies (No IO, APE, ProTeGi, PromptAgent, and OPRO). The table highlights the maximum accuracy improvement achieved by using EO and/or IO compared to the baseline (No EO and No IO). The color-coding helps visualize the computational cost (number of prompt evaluations) for each combination.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_24_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance across various combinations of instruction optimization (IO) methods and exemplar optimization (EO) methods on the BIG-Bench Hard (BBH) benchmark using PaLM 2.  The table shows the average BBH accuracy for each combination of IO and EO techniques.  The last row and column highlight the maximum accuracy improvement achieved by using either EO or IO compared to the baseline (no IO or EO). The color-coding of the cells represents the computational cost (number of prompt evaluations) involved in each optimization strategy.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_25_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance across 30 different combinations of instruction optimization (IO) methods and exemplar optimization (EO) methods on the BIG-Bench Hard (BBH) dataset using PaLM 2.  The table shows the impact of using different IO and EO strategies, both individually and in combination. The color-coding indicates the computational cost of each method, with gray representing no additional cost, blue representing a cost of 32 prompt evaluations, and orange representing a cost of 32 prompt evaluations for IO and an additional m evaluations for EO.  The last row and column show the maximum improvement achieved by each optimization strategy compared to the baseline (no IO and/or no EO).", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_25_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy across 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods using the PaLM 2 language model.  The table shows the impact of different EO strategies (No EO, Random, Nearest, Diversity, Random Search, and Mutation) when combined with different IO strategies (No IO, APE, ProTeGi, PromptAgent, and OPRO). The color-coding of the cells represents the computational cost (number of prompt evaluations).  Gray indicates no cost, blue indicates 32 evaluations, and orange represents iterative optimization of exemplars on top of already optimized instructions.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_26_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average BIG-Bench Hard (BBH) accuracy across 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods.  The rows represent different IO methods (No IO, APE, ProTeGi, PromptAgent, OPRO), while the columns show different EO methods (No EO, Random, Nearest, Diversity, Random Search, Mutation).  The last row and column highlight the maximum accuracy improvement achieved by using either EO or IO, respectively, compared to the baseline (No IO and No EO). The shading of cells indicates the computational cost, with gray representing no cost, blue representing 32 prompt evaluations for iterative optimization, and orange representing iterative exemplar optimization on top of instruction optimization.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_26_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance across all BIG-Bench Hard (BBH) tasks for 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods.  It shows the performance gains from using different EO methods (random, nearest neighbor, diversity, random search, and mutation) in combination with different IO methods (no IO, APE, ProTeGi, PromptAgent, and OPRO).  The color-coding indicates the computational cost of each combination, with gray representing no cost, blue representing a cost of 32 prompt evaluations, and orange representing a cost of 32 prompt evaluations for IO plus an additional m evaluations for EO. The last row and column show the maximum improvement achieved for each method over the baselines (no IO and/or no EO).", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_27_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance across all BIG-Bench Hard (BBH) tasks for 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods using the PaLM 2 language model.  It shows how different exemplar selection and instruction optimization techniques impact the model's performance, both individually and in combination.  The color-coding indicates the computational cost for each combination, with gray representing no extra evaluations, blue indicating 32 evaluations for either IO or EO, and orange indicating 32 additional evaluations for EO on top of an already optimized instruction.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_27_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance across various BIG-Bench Hard (BBH) tasks for different combinations of instruction optimization (IO) and exemplar optimization (EO) methods using the PaLM 2 model.  The table shows the impact of each method individually and in combination. The color-coding of cells indicates the computational cost (number of prompt evaluations), ranging from zero (gray) for methods without iterative optimization to 32 (blue) for those with iterative optimization of either instructions or exemplars, and finally to 32 (orange) for those that iterate on both.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_27_3.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance of various combinations of instruction optimization (IO) and exemplar optimization (EO) methods on the BIG-Bench Hard (BBH) benchmark using PaLM 2.  It shows the impact of using different EO strategies (No EO, Random, Nearest, Diversity, Random Search, and Mutation) in conjunction with different IO strategies (No IO, APE, ProTeGi, PromptAgent, and OPRO). The table highlights the maximum performance gain achieved by each EO strategy and by combining IO and EO, indicating the cost (number of prompt evaluations) for each approach. The color-coding of the cells provides a visual representation of the computational cost.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_28_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average BIG-Bench Hard (BBH) accuracy scores achieved by combining various instruction optimization (IO) and exemplar optimization (EO) methods.  It shows the performance gains from using each method alone and in combination. The color-coding highlights the computational cost (number of prompt evaluations on the validation set). Gray indicates no cost, blue indicates 32 evaluations, and orange indicates iterative optimization of exemplars (32 evaluations per iteration). The last row and column show the maximum accuracy improvement compared to baselines (No IO/No EO).", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_34_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy across 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods.  The table shows the impact of various EO strategies (No EO, Random, Nearest, Diversity, Random Search, Mutation) combined with various IO strategies (No IO, APE, ProTeGi, PromptAgent, OPRO) on the model's performance. The color-coding highlights the computational cost of each combination, with gray representing no additional evaluations, blue representing 32 evaluations for iterative optimization, and orange representing iterative exemplar optimization on top of optimized instructions. The last row and column show the maximum accuracy improvement compared to baselines (No IO/No EO).", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_37_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy across 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods.  It compares using no IO/EO,  various state-of-the-art IO methods (APE, ProTeGi, PromptAgent, OPRO), and multiple EO methods (Random, Nearest, Diversity, Random Search, Mutation).  The color-coding of cells represents the computational cost: gray (no cost), blue (32 evaluations), orange (more than 32 evaluations).  The last row and column show the maximum accuracy gain compared to the baseline of no IO and no EO, respectively.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_37_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average BIG-Bench Hard (BBH) accuracy results across various combinations of instruction optimization (IO) and exemplar optimization (EO) methods using the PaLM 2 language model.  It shows the impact of different EO strategies (No EO, Random, Nearest, Diversity, Random Search, Mutation) when combined with different IO strategies (No IO, APE, ProTeGi, PromptAgent, OPRO). The table highlights the maximum accuracy gain achieved by using EO and/or IO compared to a baseline with no optimization.  The color-coding of the cells indicates the computational cost (number of prompt evaluations on the validation set) for each approach.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_39_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy across 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods using the PaLM 2 language model.  It shows the impact of using different EO methods (No EO, Random, Nearest, Diversity, Random Search, Mutation) in conjunction with various IO methods (No IO, APE, ProTeGi, PromptAgent, OPRO).  The table highlights the maximal accuracy gains achieved by both EO and IO alone and in combination, indicating the computational cost (number of prompt evaluations) associated with each method.  The color-coding of the cells visually represents the computational cost for each combination.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_40_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average BIG-Bench Hard (BBH) accuracy results across various combinations of instruction optimization (IO) and exemplar optimization (EO) methods using PaLM 2.  It shows the impact of using different EO strategies (No EO, Random, Nearest, Diversity, Random Search, and Mutation) in combination with different IO strategies (No IO, APE, ProTeGi, PromptAgent, and OPRO).  The color-coding helps visualize the computational cost (number of prompt evaluations) for each combination.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_40_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy results across various combinations of instruction optimization (IO) and exemplar optimization (EO) methods using PaLM 2.  It shows the impact of different EO strategies (No EO, Random, Nearest, Diversity, Random Search, Mutation) combined with different IO methods (No IO, APE, ProTeGi, PromptAgent, OPRO). The table highlights the maximum accuracy gains achieved by using either EO or IO alone, and also the synergy obtained by combining both, considering the computational cost (number of prompt evaluations).", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_41_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average performance across BIG-Bench Hard (BBH) tasks for various combinations of instruction optimization (IO) and exemplar optimization (EO) methods using PaLM 2.  It shows the impact of different EO strategies (No EO, Random, Nearest, Diversity, Random Search, Mutation) combined with different IO strategies (No IO, APE, ProTeGi, PromptAgent, OPRO). The table highlights the maximum performance gains achieved by using EO and/or IO compared to the baseline (No IO and No EO). The background colors help visualize the computational cost associated with each method, with gray indicating no cost, blue indicating moderate cost, and orange indicating high cost.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_41_2.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy results for 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods using the PaLM 2 language model.  It shows the impact of various EO strategies (No EO, Random, Nearest, Diversity, Random Search, and Mutation) when combined with various IO strategies (No IO, APE, ProTeGi, PromptAgent, OPRO). The table highlights the maximal accuracy gains achieved by using EO and/or IO compared to the baseline (No IO, No EO), and uses color-coding to represent the computational cost (number of prompt evaluations) for each combination.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_42_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy for various combinations of instruction optimization (IO) and exemplar optimization (EO) methods using PaLM 2.  It shows the maximum accuracy gains achieved by using either EO or IO alone, and by combining them. The color-coding highlights the computational cost (number of prompt evaluations) for each method.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_43_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy scores achieved by combining various instruction optimization (IO) and exemplar optimization (EO) methods.  It shows the impact of each method individually and in combination.  The table highlights the computational cost (number of prompt evaluations) for each combination, categorized into no cost (gray), moderate cost (blue), and high cost (orange). The last row and column indicate the maximum accuracy improvement achieved by using EO and/or IO, respectively. ", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_44_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy scores for various combinations of instruction optimization (IO) and exemplar optimization (EO) methods using PaLM 2.  It shows the impact of combining different IO and EO techniques on model performance. The color-coding of the cells indicates the computational cost (number of prompt evaluations) associated with each combination, facilitating a cost-benefit analysis of different APO strategies.", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_46_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy for 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods using PaLM 2.  It shows the maximum accuracy gain achieved by using EO and/or IO compared to the baseline (no IO, no EO). The color-coding of the cells represents the computational cost (number of prompt evaluations): gray (no cost), blue (32 evaluations), orange (iterative optimization of exemplars on top of optimized instructions).", "section": "3.1 Experimental Setup"}, {"figure_path": "IdtoJVWVnX/tables/tables_58_1.jpg", "caption": "Table 1: Average BBH accuracy of all 30 EO-IO combinations with PaLM 2 (text-bison-002) target model and PaLM 2 (text-unicorn-001) optimizer model. The last row/column show the max improvement over the No IO and/or No EO baseline of the respective row/column. The background shades indicate cost in terms of # prompt evaluations on Dval by the target model: gray cells requires no evaluation on Dval (m = 0); blue cells perform m = 32 evaluations to iteratively optimize instructions or exemplars; orange cells iteratively optimize exemplars m times on top of optimized instructions.", "description": "This table presents the average Big-Bench Hard (BBH) accuracy for 30 different combinations of instruction optimization (IO) and exemplar optimization (EO) methods using the PaLM 2 language model.  It shows the impact of using various EO methods (No EO, Random, Nearest, Diversity, Random Search, Mutation) in combination with various IO methods (No IO, APE, ProTeGi, PromptAgent, OPRO). The maximum improvement achieved by applying EO and IO methods is also presented. The background color-coding helps in understanding the computational cost (number of prompt evaluations) associated with each combination.", "section": "3.1 Experimental Setup"}]