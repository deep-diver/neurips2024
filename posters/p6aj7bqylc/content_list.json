[{"type": "text", "text": "GACL: Exemplar-Free Generalized Analytic Continual Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Huiping Zhuang1\u2217 Yizhu Chen1\u2217 Di Fang1 Run He1 Kai Tong1 Hongxin Wei2 Ziqian Zeng1\u2020 Cen Chen1,3,4\u2020 ", "page_idx": 0}, {"type": "text", "text": "1South China University of Technology, China Southern University of Science and Technology, China 3Shenzhen Institute, Hunan University, China 4Pazhou Lab, China ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Class incremental learning (CIL) trains a network on sequential tasks with separated categories in each task but suffers from catastrophic forgetting, where models quickly lose previously learned knowledge when acquiring new tasks. The generalized CIL (GCIL) aims to address the CIL problem in a more real-world scenario, where incoming data have mixed data categories and unknown sample size distribution. Existing attempts for the GCIL either have poor performance or invade data privacy by saving exemplars. In this paper, we propose a new exemplarfree GCIL technique named generalized analytic continual learning (GACL). The GACL adopts analytic learning (a gradient-free training technique) and delivers an analytical (i.e., closed-form) solution to the GCIL scenario. This solution is derived via decomposing the incoming data into exposed and unexposed classes, thereby attaining a weight-invariant property, a rare yet valuable property supporting an equivalence between incremental learning and its joint training. Such an equivalence is crucial in GCIL settings as data distributions among different tasks no longer pose challenges to adopting our GACL. Theoretically, this equivalence property is validated through matrix analysis tools. Empirically, we conduct extensive experiments where, compared with existing GCIL methods, our GACL exhibits a consistently leading performance across various datasets and GCIL settings. Source code is available at https://github.com/CHEN-YIZHU/GACL. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Class incremental learning (CIL) [1], an important form of continual learning, aims to effectively tune an off-the-shelf network on incoming new datasets, with data excluding various categories from its previous states. The CIL has gained significant traction due to its ability to refine learned models for new and unfamiliar data classes, eliminating the need to start the training process from scratch. This elimination of retraining saves valuable computational resources, which is especially important in the era of pre-trained models that have absorbed a massive amount of data. ", "page_idx": 0}, {"type": "text", "text": "One significant challenge in CIL is catastrophic forgetting [2, 3], which causes trained models to lose existing knowledge when gaining new information quickly. This can be attributed to the fundamental property of gradient-based iterative algorithms that impose a task-recency bias, i.e., predictions favor recently updated categories [4]. To the authors\u2019 knowledge, no solutions exist for these gradient-trained CIL models to fully tackle catastrophic forgetting. ", "page_idx": 0}, {"type": "text", "text": "On the other hand, traditional CIL assumes that the number of samples in each task is fixed and that new tasks are entirely disjoint from previous ones. This paradigm does not align with real-world scenarios, where training data may include both new and previously encountered categories, and the number of data points often exhibits arbitrariness in each task. This extended CIL setting is referred to as generalized CIL (GCIL) [5, 6]. Such an uneven task-wise distribution of training samples and data categories further complicates the forgetting issue. For instance, GCIL may lead to the neglect of minority samples within a batch, thereby undermining representation during the training process. ", "page_idx": 1}, {"type": "text", "text": "To mitigate catastrophic forgetting, a simple but effective approach is to replay historical samples. Replay-based CIL [1, 4] mitigates forgetting by storing a small number of samples from historical categories for the model to review while learning new information. However, this replay mechanism poses risks to data privacy. Thus, the exemplar-free CIL (EFCIL) without saving old exemplars gains prominence due to the increasing concern for privacy. However, many EFCIL methods perform poorly due to the task-recency bias caused by the nature of gradient-based algorithms [4]. Recently, this dilemma has been alleviated by the analytic continual learning (ACL) [7, 8], an emerging EFCIL branch that first achieves comparable or even more competitive performance over the replay-based CIL. This improvement occurs because, for the first time, ACL achieves a near \u201ccomplete nonforgetting\u201d by allowing an equivalence between the incremental learning and its joint training (i.e., the weight-invariant property). ", "page_idx": 1}, {"type": "text", "text": "The ACL provides a powerful toolbox for traditional EFCIL scenarios where data categories among training tasks are mutually exclusive. However, an apparent gap exists between the existing ACL techniques and the more desired and real-world GCIL scenario. Exploring the possibility of incorporating the weight-invariant property into the GCIL framework is both a significant and natural motivation, as it has the potential to enhance overall performance. To achieve this, we propose a generalized analytic continual learning (GACL), a new and compensated ACL member, offering a weight-invariant property solution to the GCIL. The key contributions are summarized as follows. ", "page_idx": 1}, {"type": "text", "text": "\u2022 We present the GACL, an exemplar-free technique that achieves the equivalence between the GCIL (with split incoming data) and its joint training (with data centralized in a single task).   \n\u2022 We theoretically establish the GACL\u2019s weight-invariant property. It is achieved and proved by separating the incoming data into exposed and unexposed components and aligning them structurally with matrix decomposition techniques.   \n\u2022 We isolate the distinctive component of the GACL, namely the exposed class label gain (ECLG), from the existing ACL. This module explains the feasibility of achieving GCIL\u2019s analytic learning, offering a high interpretability in the GCIL realm.   \n\u2022 Experiments on various benchmark datasets are presented, showing that the GACL outperforms the existing EFCIL by a large margin. It also exceeds most state-of-the-art replay-based methods. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "This section reviews existing methods for CIL and its more real-world counterpart, i.e., GCIL. ", "page_idx": 1}, {"type": "text", "text": "2.1 CIL Techniques ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Existing CIL methods can be roughly divided into three categories: replay-based methods, regularization-based methods, and prototype-based methods. ", "page_idx": 1}, {"type": "text", "text": "The replay-based CIL methods such as iCaRL [1], LUCIR [4], PODNet [9], AANets [10], FOSTER [11], and OHO [12], retain past training samples as exemplars and utilize them during the learning of new ones. However, storing original training samples presents a significant challenge, particularly in scenarios with strict data privacy requirements. ", "page_idx": 1}, {"type": "text", "text": "The regularization-based CIL aims to design a loss function that prevents the change of activations or important weights. Methods such as the Less-forgetting learning [13] and the LwF [14] introduce knowledge distillation [15] into their loss function to prevent the forgetting caused by activation drift. EWC [16], $\\mathrm{EWC++}$ , RWalk [17], and Rotate your Networks [18], introduce regularization that slows down learning on the weights important for old tasks by calculating the Fisher information matrix. ", "page_idx": 1}, {"type": "text", "text": "The prototype-based CIL maintains distinct prototypes for each category, which prevents overlapping representations of new and old categories. For example, the PASS [19] distinguishes prior categories by augmenting feature prototypes. The SSRE technique [20] enhances the dissimilarity between old and new categories via selecting prototypes to incorporate with new samples into a distillation process. The FeTrIL [21] uses new representations to generate pseudo-features of old categories. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2.2 Analytic Continual Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The ACL is a recently developed EFCIL branch inspired by the analytic learning [22, 23, 24] where the training of neural networks yields a closed-form solution using least squares. The ACIL [7] first converts a continual learning problem to a batch recursive least-squares problem, eliminating the need to store samples by preserving the correlation matrix, and the RanPAC [25] applies this trick to pre-trained models. The GKEAL [8] focuses on the few-shot CIL scenarios by leveraging a Gaussian kernel projection. The DS-AL [26] introduces an additional linear classifier to learn the residue of the ACIL to enhance the plasticity, while the REAL [27] introduces the representation enhancing distillation to improve the backbone\u2019s generalization capabilities. The AFL [28] extends the ACL to federated learning, transitioning from temporal increment to spatial increment, and similar techniques are applied to the reinforcement learning [29]. The ACL is an emerging competitive CIL branch with a closed-form solution that leads to a valuable weight-invariant property, securing the equivalence between CIL and its joint learning. However, existing ACL methods are designed for the CIL scenario in which the categories of samples in each task must be entirely distinct. This restricts their applicability in real-world scenarios. ", "page_idx": 2}, {"type": "text", "text": "2.3 The Generalized Class Incremental Learning ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The GCIL simulates real-world incremental learning, as distributions of data category and size could be unknown in one task. The GCIL arouses problems such as intra- and inter-task forgettings and the class imbalance problem [30]. The key GCIL properties can be summarized as follows: (i) the number of classes across different tasks is not fixed; (ii) classes shown in prior tasks could reappear in later tasks; (iii) training samples are imbalanced across different classes in each task [6] (See Appendix B). ", "page_idx": 2}, {"type": "text", "text": "There are several GCIL settings. In the BlurryM setting [5], $a\\%$ of the classes are disjoint between tasks, while the remaining classes appear in every task. The i-Blurry-N-M [31] setting has blurry task boundaries and requires the model to perform anytime inference. However, the i-Blurry scenario has a fixed number of classes in each task with the same proportion of new and old classes. The Si-Blurry [30] is the most complex and realistic GCIL setting satisfying all three GCIL properties since it has an ever-changing number of classes and is capable of effectively simulating newly emerging or disappearing data, highlighting the problem of uneven distribution in real-world scenarios. ", "page_idx": 2}, {"type": "text", "text": "To address the issue of the GCIL, gradient-based sample selection methods such as the GSS-IQP and the GSS-Greedy are proposed by [5]. The RM [32] proposes a memory management strategy based on per-sample classification uncertainty and data augmentation, while the management in the CLIB [31] eliminates samples based on a per-sample importance score. The DualPrompt [33], as an EFCIL method, introduces the prompt-based learning to the CIL problem, and the MVP [30] proposes an instance-wise logit masking and contrastive visual prompt tuning loss. ", "page_idx": 2}, {"type": "text", "text": "3 The Proposed Method ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we deliver details of the proposed GACL. We first define the learning problem. Then, we derive the GACL by employing matrix decomposition techniques. A corresponding theoretical analysis follows to indicate the interpretability of our work. An overview is depicted in Figure 1. ", "page_idx": 2}, {"type": "text", "text": "3.1 Problem Definition ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We denote the complete set of available data as $\\mathcal{D}$ . When $\\mathcal{D}$ is partitioned into a sequence of GCIL tTahsek st,r awien iansgs udmatea stheta $\\mathcal{D}_{k}^{\\mathrm{train}}\\sim\\{X_{k}^{\\mathrm{train}},Y_{k}^{\\mathrm{train}}\\}$ issa tmhep lseest,  owf htrearien r eresepnrte sien nttass $k$ $\\mathcal{D}_{k}^{\\mathrm{train}}$ $X_{k}^{\\mathrm{train}}\\in\\mathbb{R}^{N_{k}\\times c\\times w\\times h}$ $N_{k}$ input image samples with a shape of $c\\times w\\times h$ . $Y_{k}^{\\mathrm{train}}\\in\\mathbb{R}^{N_{k}\\times\\dot{d}_{y_{k}}}$ represents $N_{k}$ -stacked one-hot encoded label tensors with $d_{y_{k}}$ classes that have been kseen from task $1$ to task $k$ $.\\;\\mathcal{D}_{k}^{\\mathrm{test}}\\sim\\{X_{k}^{\\mathrm{test}},Y_{k}^{\\mathrm{test}}\\}$ ", "page_idx": 2}, {"type": "image", "img_path": "P6aJ7BqYlc/tmp/649d0cd80ac5a2adad881bbd81de287a38dbd02abafbad060608d48cb89b8511.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 1: An overview of our proposed GACL. (a) Labels of the exposed class and the unexposed class are extracted in each GCIL task (see definition in Section 3.2), respectively. (b) A frozen pre-trained ViT and a buffer layer are utilized to extract features from the inputs. (c) The key to the recursively updated formulation of the GACL contains two components. The W\u02c6 u(nke)xp osed takes in the contribution of unexposed class data (see (11)). The other is contributed by the ECLG module $\\hat{W}_{\\mathrm{ECLG}}^{(k)}$ (e.g., see (12)), which reflects the gain of exposed class data on the seen categories. The recursive formulation flows aided by the autocorrelation memory matrix $\\boldsymbol{R}$ throughout the GCIL. ", "page_idx": 3}, {"type": "text", "text": "tish etihre  pteersft odramtaasnecte  ion nt atshke $k$ e. stT dhaet agsoeatl . CHILe rien, $k$ iesn toot etsr atihne  njoeitnwt odraktsa suesti nsgp $\\mathcal{D}_{k}^{\\mathrm{train}}$ g atnads kesv a1l tuoa $\\mathcal{D}_{1:k}^{\\mathrm{test}}$ $\\mathcal{D}_{1:k}$ $k$ ", "page_idx": 3}, {"type": "text", "text": "3.2 Exposed-unexposed Class Split ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In each GCIL task, classes may not appear exclusively. Hence, in any GCIL task $k$ , we refer to classes that have appeared in previous tasks 1 to $k-1$ as the exposed classes of task $k$ , while classes making their initial appearance are the unexposed classes of task $k$ as shown in Figure 1 (a). This distinction helps to characterize the evolving nature of class occurrences throughout different GCIL tasks. ", "page_idx": 3}, {"type": "text", "text": "In a task-wise GCIL scenario, we can involve all class labels in a set $\\boldsymbol{S}$ . In task $k$ , the set of the exposed class labels is denoted as $S_{\\mathrm{exposed,\\,k}}\\subseteq S$ , while the set of unexposed class labels is marked by $S_{\\mathrm{unexposed,\\,k}}\\subseteq S$ , where $S_{\\mathrm{{exposed},\\,k}}\\cap\\dot{S}_{\\mathrm{{unexposed},\\,k}}=\\emptyset$ . Note that $S_{\\mathrm{exposed,\\,k}}$ and $S_{\\mathrm{unexposed,\\,k}}$ may evolve from task $k-1$ to task $k$ , that is ", "page_idx": 3}, {"type": "equation", "text": "$$\nS_{\\mathrm{exposed,k}}=S_{\\mathrm{unexposed,k-1}}\\cup S_{\\mathrm{exposed,k-1}}=S_{\\mathrm{unexposed,k-1}}\\cup S_{\\mathrm{unexposed,k-2}}\\ldots\\cup S_{\\mathrm{unexposed,1}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "From the scope of exposed-unexposed classes, the $d_{y_{k}}$ can be represented as $d_{y_{k}}\\,=\\,|S_{\\mathrm{exposed,\\,k}}|\\,+$ $|S_{\\mathrm{unexposed,\\,k}}|\\stackrel{\\cdot}{=}d_{y_{k-1}}\\stackrel{\\cdot}{+}|S_{\\mathrm{unexposed,\\,k}}|$ , where $\\left|\\cdot\\right|$ denotes the cardinality of a set. ", "page_idx": 3}, {"type": "text", "text": "In task $k$ , given training dataset $\\mathcal{D}_{k}^{\\mathrm{train}}\\sim\\{X_{k}^{\\mathrm{train}},Y_{k}^{\\mathrm{train}}\\}$ , class labels $Y_{k}^{\\mathrm{train}}$ can be partitioned due to the exposed-unexposed split as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nY_{k}^{\\mathrm{train}}=\\left[\\bar{Y}_{k}^{\\mathrm{train}}\\right.\\left.\\ \\tilde{Y}_{k}^{\\mathrm{train}}\\right],\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\bar{Y}_{k}^{\\mathrm{train}}\\in\\mathbb{R}^{N_{k}\\times d_{y_{k-1}}}$ is the exposed class label matrix and $\\tilde{Y}_{k}^{\\mathrm{train}}\\in\\mathbb{R}^{N_{k}\\times(d_{y_{k}}-d_{y_{k-1}})}$ is the unexposed class label matrix. They correspond to segments displaying the appearance of exposed classes and unexposed classes. ", "page_idx": 3}, {"type": "text", "text": "3.3 Buffered Embedding Extraction ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The power of pre-trained models allows the GACL to adopt a frozen backbone from structures such as ViT [34] to extract the features of images shown in Figure 1 (b). Let ", "page_idx": 3}, {"type": "equation", "text": "$$\nX^{\\mathrm{(E)}}=f_{\\mathrm{backbone}}(X,\\Theta_{\\mathrm{backbone}})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "be the features extracted by the backbone, where $\\Theta_{\\mathrm{backbone}}$ indicates the backbone weight. Then, we use a buffer layer to project features, i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\nX_{i}^{\\mathrm{(B)}}=f_{\\mathrm{buffer}}(X^{\\mathrm{(E)}}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $f_{\\mathrm{buffer}}$ indicates the operation of the buffer layer. Several options for the buffer layer exist, including a randomly initialized linear mapping in the ACIL [7] or a kernel embedding projection in the GKEAL [8]. The selection of the buffer layer is not our focus. For convenience, we follow the ACIL, taking the random linear projection followed by a non-linear activation function as the buffer layer, i.e. $f_{\\mathrm{buffer}}^{'}(X^{(\\mathrm{E})})=\\mathrm{ReLU}(\\bar{X}^{(\\mathrm{E})}W_{\\mathrm{B}})$ , where the elements of the buffer layer weight $W_{\\mathrm{{B}}}$ are randomly sampled from a normal distribution. ", "page_idx": 4}, {"type": "text", "text": "3.4 Generalized Analytic Class Incremental Learning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Here, we derive the GACL by partitioning training samples into unexposed and exposed categories, aws hsihcho wcan ni nb eF iegxutreen 1d e(dc )f. roLemt $\\mathbf{\\bar{\\calX}}_{1:k}^{\\mathrm{total}}$ caunmd $\\bar{Y_{1:k}^{\\mathrm{total}}}$ bme atthriec aecs e da nfde di nl atbaeslk eass i fno tlalsokw $k$ $X_{1:k-1}^{\\mathrm{total}}$ $Y_{1:k-1}^{\\mathrm{total}}$ $k-1$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{X_{1:k}^{\\mathrm{total}}=\\left[\\!\\!\\begin{array}{c}{X_{1:k-1}^{\\mathrm{total}}}\\\\ {X_{k}^{(\\mathrm{B})}}\\end{array}\\!\\!\\right],\\quad Y_{1:k}^{\\mathrm{total}}=\\left[\\!\\!\\begin{array}{c c}{Y_{1:k-1}^{\\mathrm{total}}}&{\\mathbf{0}}\\\\ {\\Bar{Y}_{k}^{\\mathrm{train}}}&{\\Bar{Y}_{k}^{\\mathrm{train}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Subsequently, one could formulate the learning problem in task $k$ by a fully connected network (FCN) as the classifier ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\underset{W_{\\mathrm{FCN}}^{(k)}}{\\arg\\operatorname*{min}}\\ \\left\\|\\boldsymbol{Y}_{1:k}^{\\mathrm{total}}-\\boldsymbol{X}_{1:k}^{\\mathrm{total}}\\boldsymbol{W}_{\\mathrm{FCN}}^{(k)}\\right\\|_{\\mathrm{F}}^{2}+\\gamma\\left\\|\\boldsymbol{W}_{\\mathrm{FCN}}^{(k)}\\right\\|_{\\mathrm{F}}^{2},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\lVert\\cdot\\rVert_{\\mathrm{F}}$ is Frobenius-norm, $\\gamma\\geq0$ is the regularization term and $W_{\\mathrm{FCN}}^{(k)}$ indicates the FCN layer weight. The optimal solution to (4) is ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{W}_{\\mathrm{FCN}}^{(k)}=(X_{1:k}^{\\mathrm{total}\\top}X_{1:k}^{\\mathrm{total}}+\\gamma I)^{-1}X_{1:k}^{\\mathrm{total}\\top}Y_{1:k}^{\\mathrm{total}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The goal of the GACL is then to obtain W\u02c6 F(Ck)N recursively from W\u02c6 F(CkN\u22121)w ithout directly involving historical samples (e.g., $X_{1:k-1}^{\\mathrm{total}}$ and Y 1t:okta\u2212l1). That is to solve ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\operatorname*{argmin}_{W_{\\mathrm{FCN}}^{(k)}}\\;\\left\\|\\left[\\!\\!\\begin{array}{c c}{Y_{1:k-1}^{\\mathrm{total}}}&{\\mathbf{0}}\\\\ {\\bar{Y}_{k}^{\\mathrm{train}}}&{\\tilde{Y}_{k}^{\\mathrm{train}}}\\end{array}\\!\\!\\right]-\\left[\\!\\!\\begin{array}{c}{X_{1:k-1}^{\\mathrm{total}}}\\\\ {X_{k}^{(\\mathrm{B})}}\\end{array}\\!\\!\\right]W_{\\mathrm{FCN}}^{(k)}\\!\\!\\right\\|_{\\mathrm{F}}^{2}+\\gamma\\left\\|\\!\\!\\begin{array}{c}{W_{\\mathrm{FCN}}^{(k)}}\\\\ {\\mathbf{F}}\\end{array}\\!\\!\\right\\|_{\\mathrm{F}}^{2}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "bmye rmeocruyr simvaetlryi xu pads aftoilnlgo twhse. previous-task weight $\\hat{W}_{\\mathrm{FCN}}^{(k)}$ . To achieve this, we define an autocorrelation ", "page_idx": 4}, {"type": "equation", "text": "$$\nR_{k}=(X_{1:k}^{\\mathrm{total}\\top}X_{1:k}^{\\mathrm{total}}+\\gamma I)^{-1}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Accordingly, we summarize the recursive formulation of the proposed GACL in Theorem 3.1. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.1. Let $\\hat{W}_{\\mathrm{FCN}}^{(k)}$ be the optimal estimation of (6) with all the training data from task 1 to task $k$ . Then $\\hat{W}_{\\mathrm{FCN}}^{(k)}$ is equivalent to its recursive form ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{W}_{\\mathrm{FCN}}^{(k)}=\\left[\\hat{W}_{\\mathrm{FCN}}^{(k-1)}-R_{k}X_{k}^{(\\mathrm{B})\\top}X_{k}^{(\\mathrm{B})}\\hat{W}_{\\mathrm{FCN}}^{(k-1)}+R_{k}X_{k}^{(\\mathrm{B})\\top}\\bar{Y}_{k}^{\\mathrm{train}}\\quad R_{k}X_{k}^{(\\mathrm{B})\\top}\\tilde{Y}_{k}^{\\mathrm{train}}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where ", "page_idx": 4}, {"type": "equation", "text": "$$\nR_{k}=R_{k-1}-R_{k-1}X_{k}^{\\mathrm{(B)\\top}}(I+X_{k}^{\\mathrm{(B)}}R_{k-1}X_{k}^{\\mathrm{(B)\\top}})^{-1}X_{k}^{\\mathrm{(B)}}R_{k-1}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Proof. See Appendix A. ", "page_idx": 4}, {"type": "text", "text": "As indicated in Theorem 3.1, the weight $\\hat{W}_{\\mathrm{FCN}}^{(k)}$ in task $k$ recursively obtained using the previous-task weight $\\hat{W}_{\\mathrm{FCN}}^{(k-1)}$ is identical to its joint-learning counterpart formulated in (6). That is, the GACL maintains the same weight-invariant property in the GCIL scenario as other ACL methods. ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 The pseudo-code of GACL. ", "page_idx": 5}, {"type": "text", "text": "Input: GCIL tasks Dt1rain, $\\mathcal{D}_{1}^{\\mathrm{train}},\\dots,\\mathcal{D}_{K}^{\\mathrm{train}}$ with $\\mathcal{D}_{k}^{\\mathrm{train}}\\sim\\{X_{k}^{\\mathrm{train}},Y_{k}^{\\mathrm{train}}\\}$ , the pre-trained backbone with   \nfrozen weight \u0398backbone   \nInitialization: $R_{0}\\leftarrow\\gamma I$ , $W_{\\mathrm{FCN}}^{(0)}\\leftarrow\\mathbf{0}$   \nfor task to $K$ do $X_{k}^{\\mathrm{(E)}}\\gets f_{\\mathrm{backbone}}(X_{k}^{\\mathrm{train}},\\Theta_{\\mathrm{backbone}})$ (2) $X_{k}^{\\mathrm{(B)}}\\gets f_{\\mathrm{buffer}}(X_{k}^{\\mathrm{(E)}})$ (3)   \nRDke co\u2190mpRoks\u2212e $Y_{k}^{\\mathrm{train}}$ ki\u2212nt1o Xe(xBp)o\u22a4s(eId  +a ndX (uB n)eRxkpo\u2212s1eXd (cBl)a\u22a4ss) \u2212c1oXmpkoRnke\u2212nt1s $\\bar{Y}_{k}^{\\operatorname{train}}$ and $\\tilde{Y}_{k}^{\\mathrm{train}}$ $\\begin{array}{r l}&{R_{k}\\leftarrow\\bar{R}_{k-1}\\stackrel{\\sim}{-}R_{k-1}X_{k}^{(\\bar{\\mathrm{B}})^{\\top}}(I+X_{k}^{(\\mathrm{B})}\\bar{R_{k-1}}X_{k}^{(\\mathrm{B})^{\\top}})^{-1}\\bar{X_{k}}R_{k-1}\\stackrel{\\sim}{-}(9)}\\\\ &{W_{\\mathrm{uncenosed}}^{(k)}\\leftarrow\\left[W_{\\mathrm{FCN}}^{(k-1)}-R_{k}X_{k}^{(\\mathrm{B})^{\\top}}X_{k}^{(\\mathrm{B})}\\hat{W}_{\\mathrm{FCN}}^{(k-1)}\\quad R_{k}X_{k}^{(\\mathrm{B})^{\\top}}\\tilde{Y}_{k}^{\\mathrm{train}}\\right]}\\\\ &{W_{\\mathrm{ECLG}}^{(k)}\\leftarrow\\left[R_{k}X_{k}^{(\\mathrm{B})^{\\top}}\\bar{Y}_{k}^{\\mathrm{train}}\\quad0\\right]\\quad(12)}\\\\ &{W_{\\mathrm{rCN}}^{(k)}\\leftarrow W_{\\mathrm{uncenosed}}^{(k)}+W_{\\mathrm{ECLG}}^{(k)}}\\end{array}$ (11)   \nend for ", "page_idx": 5}, {"type": "text", "text": "The pseudo-code of the GACL is listed in Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "Exemplar-free. The recursive formulation is aided by $\\scriptstyle R_{k}$ as indicated in (9). Note that this autocorrelation memory matrix records the inverse of inner products among the historical embedding matrices as shown in (7). Hence, the embeddings (e.g., $X_{k}^{\\mathrm{(B)}},$ are not reversible. Saving $\\scriptstyle R_{k}$ instead of used samples is a safe alternative to preserve past knowledge. That is, our GACL is an exemplar-free technique without the need to keep any historical samples. ", "page_idx": 5}, {"type": "text", "text": "To more properly explain our GACL, as indicated in Figure 1 (c), the recursive solution in (8) can be rewritten as the sum of the unexposed-class contributed weight $\\hat{W}_{\\mathrm{unexposed}}^{(k)}$ unexposed and the ECLG weight $\\hat{W}_{\\mathrm{ECLG}}^{(k)}$ , i.e., ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{W}_{\\mathrm{FCN}}^{(k)}=\\hat{W}_{\\mathrm{unexposed}}^{(k)}+\\hat{W}_{\\mathrm{ECLG}}^{(k)},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{W}_{\\mathrm{unexposed}}^{(k)}=\\left[\\hat{W}_{\\mathrm{FCN}}^{(k-1)}-R_{k}X_{k}^{\\mathrm{(B)T}}X_{k}^{\\mathrm{(B)}}\\hat{W}_{\\mathrm{FCN}}^{(k-1)}\\quad R_{k}X_{k}^{\\mathrm{(B)T}}\\tilde{Y}_{k}^{\\mathrm{train}}\\right],}\\\\ &{\\hat{W}_{\\mathrm{ECLG}}^{(k)}=\\left[R_{k}X_{k}^{\\mathrm{(B)T}}\\bar{Y}_{k}^{\\mathrm{train}}\\quad\\mathbf{0}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Unexposed-class Contributed Weight. The unexposed-class contributed weight W\u02c6 u(nke)xp osed is recursively updated by the data of the unexposed class only. Note that the unexposed class label $\\tilde{Y}_{k}^{\\mathrm{train}}$ is applied on the concatenated weight along with new data $X_{k}^{(\\mathrm{B})^{\\top}}$ , which is reasonable as historical information should not intervene with the weight update of unseen classes. On the other hand, new data X(kB)\u22a4c ould also affect historical knowledge. This is marked by the gain of $-R_{k}X_{k}^{(\\mathrm{B})\\top}X_{k}^{(\\mathrm{B})}\\hat{W}_{\\mathrm{FCN}}^{(k-1)}$ to the original weight $\\hat{W}_{\\mathrm{FCN}}^{(k-1)}$ as indicated in (11). ", "page_idx": 5}, {"type": "text", "text": "Exposed-class Label Gain Weight. The ECLG module indicated in (12) captures knowledge from exposed-class labels. The supervision of this weight component marked by $\\mathbf{\\bar{\\alpha}}\\mathbf{R}_{k}X_{k}^{\\mathrm{(B)\\top}}\\bar{\\mathbf{Y}}_{k}^{\\mathrm{train}}$ is mainly contributed by the exposed-class labels (i.e., $\\bar{Y}_{k}^{\\mathrm{train}}$ ). It is important to note that when $\\bar{Y}_{k}^{\\mathrm{train}}$ is empty (i.e., no classes reappear in task k), this component does not contribute to the update of W\u02c6 F(Ck)N. This module is also isolated to distinguish GACL\u2019s difference from the existing ACL methods in a mathematical analysis manner (indicated as follows). ", "page_idx": 5}, {"type": "text", "text": "Difference from Existing ACL Methods. Overall, the GACL can be treated as a nontrivial generalization of ACIL [7], GKEAL [8], and various other ACL methods. For instance, in conventional CIL where no classes reappear in new tasks (i.e., $\\forall k,\\bar{Y}_{k}^{\\mathrm{train}}\\in\\mathbb{R}^{*\\times0})$ , the classifier of the GACL $\\hat{W}_{\\mathrm{FCN}}^{(k)}=\\hat{W}_{\\mathrm{unexposed}}^{(k)}$ ,  pwrohpicohs eids  eGqAuiCvLal. eTnth te o mthajeo rr edciufrfseirveen ccel alsiseisf iienr  tohfe  thEeC LAGC ILm.o Tduhlaet,  ics,o rtrhees pAoCnIdLi nigs to the exposed-class gain. This pattern makes sense as there must be compensation on top of ACIL updates (specifically designed for traditional CIL) when exposed data (out of setting) participate. ", "page_idx": 5}, {"type": "text", "text": "Table 1: Comparison of $A_{\\mathrm{AUC}}$ , $\\mathcal{A}_{\\mathrm{Avg}}$ , and $\\boldsymbol{A}_{\\mathrm{Last}}$ among the GACL and other methods under the Si-Blurry setting. Data in bold represent the best EFCIL results, and data underlined are the best among all settings. We run all experiments 5 times and show \u201cmean $\\pm$ standard error\u201d. ", "page_idx": 6}, {"type": "table", "img_path": "P6aJ7BqYlc/tmp/1dc4587edf7640500d2f307f3723177dd70afed928c324652d52e95cca1ca517.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In the section, we conduct experiments on various benchmark datasets and compare the GACL with both EFCIL and replay-based state-of-the-art methods, including LwF [14], L2P [36], DualPrompt [33], ER [35], $\\mathrm{EWC++}$ [16], SLDA [37], RM [32], MVP [30], and MVP-R (MVP with exemplars).3 ", "page_idx": 6}, {"type": "text", "text": "Datasets. We conduct experiments on three datasets: CIFAR-100 [38], ImageNet-R [39], and Tiny-ImageNet [40]. We evaluate each method under the Si-Blurry setting [30] (the most complex GCIL setting) with 5 independent seeds. For the Si-Blurry setting, we set the disjoint class ratio $\\scriptstyle{r_{\\mathrm{D}}}$ to $50\\%$ and the blurry sample ratio $r_{\\mathrm{B}}$ to $10\\%$ . More details about Si-Blurry are listed in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "Implementation Details. We utilize the DeiT-S/16 [41] as our backbone. Following [42, 43], we pre-train the backbone on 611 ImageNet classes after excluding 389 classes that overlap with CIFAR and Tiny-ImageNet to prevent data leakage. To ensure a fair comparison, all methods utilize a frozen backbone. All methods under comparison are implemented as specified in [30]. The memory sizes of compared relay-based methods are set to 500 and 2000. ", "page_idx": 6}, {"type": "text", "text": "There are two hyperparameters in the GACL, the regularization term $\\gamma$ and the size of the buffer layer. Here, we adopt $\\gamma=100$ , which is determined by the grid search of $\\{0,10,100,500,1000,10000\\}$ on CIFAR-100 (by a $90\\%$ - $.10\\%$ train-val split). As the regularization term $\\gamma$ is not sensitive in a proper range [7], we adopt this value for all datasets for convenience. We relocate its analysis to Appendix E. The size for the buffer layer $W_{\\mathrm{{B}}}$ is set to 5000 for both the GACL and ACIL for convenience. ", "page_idx": 6}, {"type": "text", "text": "Evaluation Protocol. Three metrics are adopted to evaluate GCIL tasks. The real-time performance is evaluated by the area under the curve of accuracy $A_{\\mathrm{AUC}}$ [31], i.e., $\\begin{array}{r}{\\mathcal{A}_{\\mathrm{AUC}}=\\sum_{i=1}^{k}f(i\\cdot\\triangle n)\\cdot\\triangle n,}\\end{array}$ where is the number of samples observed between evaluation and $f(\\cdot)$ is th e curve in the accuracyto-{number of training samples} plot, measuring anytime inference performance during training. A higher $A_{\\mathrm{AUC}}$ corresponds to a method consistently maintaining high accuracy throughout the training. The overall performance is evaluated by the average incremental accuracy (or average accuracy) $\\begin{array}{r}{\\mathcal{A}_{\\mathrm{Avg}}=\\frac{1}{K+1}\\!\\sum_{k=1}^{K}\\!\\mathcal{A}_{k}}\\end{array}$ , where the task-wise accuracy $\\mathcal{A}_{k}$ indicates the average test accuracy in task $k$ by testing the network on $\\mathcal{D}_{1:k}^{\\mathrm{test}}$ . A higher $\\mathcal{A}_{\\mathrm{Avg}}$ score is preferred when evaluating algorithms. The last evaluation metric is the last-task accuracy $\\bar{\\mathcal{A}}_{\\mathrm{Last}}$ evaluating the network\u2019s last-task performance after completing all tasks. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4.2 Comparison with State-of-the-arts ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "As shown in Figure 2, we comprehensively compare the GACL with both EFCIL and replay-based methods. ", "page_idx": 7}, {"type": "image", "img_path": "P6aJ7BqYlc/tmp/6b23fb495b816de31258ce848e2f490de418500366157b4eac5f1dc4d6fe8104.jpg", "img_caption": ["Figure 2: The task-wise accuracy $\\mathcal{A}_{k}$ of the GACL with EFCIL methods (top) and replay-based methods (bottom) on benchmark datasets with the $K=5$ . "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "Compare with EFCIL Methods. EFCIL methods address privacy concerns and mitigate catastrophic forgetting without exemplars. Among EFCIL methods, our GACL consistently exhibits superior performance across all three datasets, as illustrated in the lower panel of Table 1. ", "page_idx": 7}, {"type": "text", "text": "For instance, on CIFAR-100, our method surpasses the second-best method SLDA, by $\\mathbf{4.99\\%}$ , $\\mathbf{6.15\\%}$ , and $\\mathbf{8.52\\%}$ for $A_{\\mathrm{AUC}}$ , $\\mathcal{A}_{\\mathrm{Avg}}$ , and $\\boldsymbol{A}_{\\mathrm{Last}}$ , respectively. On Tiny-ImageNet, the GACL achieves impressive results with $A_{\\mathrm{AUC}},A_{\\mathrm{Avg}}$ , and $\\boldsymbol{A}_{\\mathrm{Last}}$ reaching $63.14\\%$ , $69.32\\%$ , and $62.68\\%$ , respectively, surpassing the previous best EFCIL by $\\mathbf{13.97\\%}$ , $21.39\\%$ , and $\\mathbf{9.55\\%}$ . Similar patterns are evident in the results of ImageNet-R, further confirming that the GACL is an exceptional tool for GCIL. ", "page_idx": 7}, {"type": "text", "text": "Owing to the weight-invariant property, the GACL exhibits more accurate and stable evolutions as $k$ increases as observed in Figure 2 (a). All compared EFCIL methods exhibit sharp declines in accuracy, while the GACL delivers nearly non-declining curves. In particular, on CIFAR-100, the GACL shows an unnatural improvement of task-wise accuracy throughout the learning tasks, with the GACL initially lagging behind other EFCIL methods. This is because the Si-Blurry samples more than $70\\%$ of the CIFAR-100 categories in the first two tasks (see Appendix F), constructing a scenario where gradient-based algorithms could largely avoid the forgetting issue. Moreover, our method produces more stable predictions across diverse scenarios, as indicated by much smaller standard errors (colored shades in Figure 2 (a)). In summary, the experimental results demonstrate that our proposed GACL is exceedingly accurate and robust, exhibiting exceptional generalization ability. ", "page_idx": 7}, {"type": "text", "text": "Compare with Replay-based Methods. Replay-based methods are considerably competitive as they leverage historical samples. The memory size is a key adjustment, as increasing it typically leads to performance improvements by allowing more historical knowledge to be reviewed. For instance, the MVP-R achieves $4.42\\%$ , $3.97\\%$ , and $8.95\\%$ gains for $A_{\\mathrm{AUC}},\\,A_{\\mathrm{Avg}}$ , and $\\boldsymbol{A}_{\\mathrm{Last}}$ (see Table 1) on CIFAR-100 when increasing the memory size from 500 to 2000. ", "page_idx": 7}, {"type": "text", "text": "As an exemplar-free technique, our GACL avoids re-using the historical samples. However, as indicated in Table 1, the GACL still outperforms most existing replay-based results. For instance, the GACL achieves the best $\\boldsymbol{A}_{\\mathrm{Last}}$ results among all settings. The GACL\u2019s $A_{\\mathrm{AUC}}$ and $\\mathcal{A}_{\\mathrm{Avg}}$ results are also mostly superior, except that our performance is slightly weaker than that of MVP-R with a memory size of 2000 on CIFAR-100 and ImageNet-R. Although increasing the number of exemplars can further improve the results of replay-based methods, this approach could lead to higher training and memory costs and, more importantly, more severe privacy invasion. ", "page_idx": 8}, {"type": "text", "text": "As indicated in Figure 2 (b), replay-based methods experience accuracy declines similar to those observed in the EFCIL case. This decline is due to an inherent limitation of gradient-based iterative algorithms, which tend to favor recently trained categories and thus lead to catastrophic forgetting. The GACL is iterative-free and then not constrained by this forgetting issue, thereby achieving nearly no performance reduction as $K$ increases. ", "page_idx": 8}, {"type": "text", "text": "Why the GACL Gives Leading Performance. The above comparisons show that the proposed GACL is a powerful GCIL technique. Its competitive performance can be explained as follows. (i) Weight-invariant property. As shown in Theorem 3.1, the weight obtained recursively is equal to its joint-learning counterpart, indicating that the GACL is a \u201ccompletely non-forgetting\u201d technique (under the condition of a frozen backbone). (ii) Analytical solution. Existing GCIL techniques are gradient-based iterative algorithms prone to catastrophic forgetting by nature. The GACL is a new member of the ACL and inherits its non-iterative gradient-free essence with an analytical solution, thereby avoiding the task-recency bias to address forgetting. ", "page_idx": 8}, {"type": "text", "text": "4.3 Ablation Study on the ECLG Module ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The ECLG module is a core component that allows the GACL to obtain the weight-invariant property in the GCIL scenario. Here, we conduct an ablation study to justify the ECLG\u2019s contributions under various blurry sample ratios $r_{B}$ with $r_{\\mathrm{D}}=50\\%$ . Larger $r_{\\mathrm{B}}$ indicates more complex data distributions in the Si-Blurry setting. As shown in Table 2, the GACL without ECLG exhibits poor performance with a visible gap for $A_{\\mathrm{AUC}}$ , $\\mathcal{A}_{\\mathrm{Avg}}$ , and $\\boldsymbol{A}_{\\mathrm{Last}}$ . For instance, on CIFAR-100 with $r_{B}=10\\%$ , the ECLG contributes a $23.01\\%$ $\\boldsymbol{A}_{\\mathrm{Last}}$ gain to the GACL. ", "page_idx": 8}, {"type": "table", "img_path": "P6aJ7BqYlc/tmp/5b3a8a2d7864beba1d3824f8dd56f7156cd625c138189328b58333d1935e8840.jpg", "table_caption": ["Table 2: Ablation study on the ECLG module of our GACL. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "As claimed in Theorem 3.1, the classifier without the ECLG module fails to absorb knowledge from joint classes in each task (i.e., classes that reappear), leading to substantial information loss under the GCIL setting. The GACL, equipped with the ECLG module, demonstrates competence in handling overlapping classes in realistic scenarios. ", "page_idx": 8}, {"type": "text", "text": "4.4 Robustness Analysis in Si-Blurry Setting ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Here, we conduct a robust analysis by varying the disjoint class ratio $r_{\\mathrm{D}}$ and the blurry sample ratio $r_{\\mathrm{{B}}}$ . The comparison happens among the GACL, the second-best EFCIL method SLDA, and the top-performing replay-based method MVP-R with a memory size of 500. ", "page_idx": 8}, {"type": "text", "text": "We evaluate our method under various $r_{\\mathrm{D}}$ , including extreme cases where each task shares classes $r_{\\mathrm{D}}=0\\%$ ) and traditional CIL scenarios $\\mathbf{\\Delta}r_{\\mathrm{D}}=100\\bar{\\%}$ ). Table 3 illustrates that our GACL consistently outperforms the compared methods (e.g., leads the SLDA by $2\\%{-}10\\%$ ) and produces near-identical $A_{\\mathrm{Last}}$ values with varying $r_{\\mathrm{D}}$ . This shows the accurate and robust traits of the GACL. ", "page_idx": 9}, {"type": "text", "text": "We also evaluate our method using various $r_{\\mathrm{B}}$ values, as shown in Table 4. Similar patterns observed here align with those in Table 3, further demonstrating the robustness of the proposed GACL, which delivers exceptional performance across different GCIL settings. ", "page_idx": 9}, {"type": "table", "img_path": "P6aJ7BqYlc/tmp/c1442f20ac315e2ec6dd200dfd6a31b8a5c47c730a00ab2c6b2af9ea8592b964.jpg", "table_caption": ["Table 3: The performance at different $r_{\\mathrm{D}}$ with $r_{\\mathrm{B}}=10\\%$ on CIFAR-100. ", "Table 4: The performance at different $r_{\\mathrm{{B}}}$ with $r_{\\mathrm{D}}=50\\%$ on CIFAR-100. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "4.5 Limitation and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Overall, the GACL exhibits various good characteristics as an exemplar-free GCIL technique. The major limitation here is the need for a well-trained backbone because the GACL does not update backbone weights. This could motivate the exploration of adjustable backbones to continuously improve their feature extraction abilities, thereby further enhancing GACL\u2019s performance. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we introduce the exemplar-free generalized analytic class incremental learning (GACL) approach to address the GCIL problem. Building upon analytic learning, the GACL delivers closedform solutions to GCIL through the decomposition of GCIL data into exposed and unexposed classes. The GACL achieves the weight-invariant property that provides identical solutions for GCIL to its joint learning counterpart. We theoretically validate this property and provide high interpretability through the matrix analysis tool. Various experiments are conducted under the Si-Blurry setting, demonstrating that our proposed GACL achieves remarkable performance with high robustness compared to state-of-the-art EFCIL and replay-based methods. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research was supported by the National Natural Science Foundation of China (62306117), the Guangzhou Basic and Applied Basic Research Foundation (2024A04J3681, 2023A04J1687), the South China University of Technology-TCL Technology Innovation Fund, the Fundamental Research Funds for the Central Universities (2023ZYGXZR023, 2024ZYGXZR074), the Guangdong Basic and Applied Basic Research Foundation (2024A1515010220), the CAAIMindSpore Open Fund developed on Openl Community, the Shenzhen Fundamental Research Program (JCYJ20230807091809020), and Shenzhen Science and Technology Plan (Grant No. JCYJ20210324123802006). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Sylvestre-Alvise Rebuff,i Alexander Kolesnikov, Georg Sperl, and Christoph H. Lampert. iCaRL: Incremental classifier and representation learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017. [2] Michael McCloskey and Neal J. Cohen. Catastrophic interference in connectionist networks: The sequential learning problem. In Gordon H. Bower, editor, Psychology of Learning and Motivation, volume 24, pages 109\u2013165. Academic Press, 1989.   \n[3] Ian J. Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. An empirical investigation of catastrophic forgetting in gradient-based neural networks, 2013.   \n[4] Saihui Hou, Xinyu Pan, Chen Change Loy, Zilei Wang, and Dahua Lin. Learning a unified classifier incrementally via rebalancing. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), June 2019.   \n[5] Rahaf Aljundi, Min Lin, Baptiste Goujaud, and Yoshua Bengio. Gradient based sample selection for online continual learning. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.   \n[6] Fei Mi, Lingjing Kong, Tao Lin, Kaicheng Yu, and Boi Faltings. Generalized class incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, June 2020.   \n[7] Huiping Zhuang, Zhenyu Weng, Hongxin Wei, RENCHUNZI XIE, Kar-Ann Toh, and Zhiping Lin. ACIL: Analytic class-incremental learning with absolute memorization and privacy protection. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems, volume 35, pages 11602\u201311614. Curran Associates, Inc., 2022.   \n[8] Huiping Zhuang, Zhenyu Weng, Run He, Zhiping Lin, and Ziqian Zeng. GKEAL: Gaussian kernel embedded analytic learning for few-shot class incremental task. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 7746\u20137755, June 2023.   \n[9] Arthur Douillard, Matthieu Cord, Charles Ollion, Thomas Robert, and Eduardo Valle. PODNet: Pooled outputs distillation for small-tasks incremental learning. In Andrea Vedaldi, Horst Bischof, Thomas Brox, and Jan-Michael Frahm, editors, Computer Vision \u2013 ECCV 2020, pages 86\u2013102, Cham, 2020. Springer International Publishing.   \n[10] Yaoyao Liu, Bernt Schiele, and Qianru Sun. Adaptive aggregation networks for classincremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 2544\u20132553, June 2021.   \n[11] Fu-Yun Wang, Da-Wei Zhou, Han-Jia Ye, and De-Chuan Zhan. FOSTER: Feature boosting and compression for class-incremental learning. In Shai Avidan, Gabriel Brostow, Moustapha Ciss\u00e9, Giovanni Maria Farinella, and Tal Hassner, editors, Computer Vision \u2013 ECCV 2022, pages 398\u2013414, Cham, 2022. Springer Nature Switzerland.   \n[12] Yaoyao Liu, Yingying Li, Bernt Schiele, and Qianru Sun. Online hyperparameter optimization for class-incremental learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7):8906\u20138913, Jun. 2023.   \n[13] Heechul Jung, Jeongwoo Ju, Minju Jung, and Junmo Kim. Less-forgetting learning in deep neural networks, 2016.   \n[14] Zhizhong Li and Derek Hoiem. Learning without forgetting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(12):2935\u20132947, 2018.   \n[15] Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network, 2015.   \n[16] James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei A. Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, Demis Hassabis, Claudia Clopath, Dharshan Kumaran, and Raia Hadsell. Overcoming catastrophic forgetting in neural networks. Proceedings of the National Academy of Sciences, 114(13):3521\u20133526, 2017.   \n[17] Arslan Chaudhry, Puneet K. Dokania, Thalaiyasingam Ajanthan, and Philip H. S. Torr. Riemannian walk for incremental learning: Understanding forgetting and intransigence. In Proceedings of the European Conference on Computer Vision (ECCV), September 2018.   \n[18] Xialei Liu, Marc Masana, Luis Herranz, Joost Van de Weijer, Antonio M. L\u00f3pez, and Andrew D. Bagdanov. Rotate your networks: Better weight consolidation and less catastrophic forgetting. In 2018 24th International Conference on Pattern Recognition (ICPR), pages 2262\u20132268, 2018.   \n[19] Fei Zhu, Xu-Yao Zhang, Chuang Wang, Fei Yin, and Cheng-Lin Liu. Prototype augmentation and self-supervision for incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5871\u20135880, June 2021.   \n[20] Kai Zhu, Wei Zhai, Yang Cao, Jiebo Luo, and Zheng-Jun Zha. Self-sustaining representation expansion for non-exemplar class-incremental learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 9296\u20139305, June 2022.   \n[21] Gr\u00e9goire Petit, Adrian Popescu, Hugo Schindler, David Picard, and Bertrand Delezoide. FeTrIL: Feature translation for exemplar-free class-incremental learning. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), pages 3911\u20133920, January 2023.   \n[22] Ping Guo and Michael R. Lyu. A pseudoinverse learning algorithm for feedforward neural networks with stacked generalization applications to software reliability growth data. Neurocomputing, 56:101\u2013121, 2004.   \n[23] Huiping Zhuang, Zhiping Lin, and Kar-Ann Toh. Blockwise recursive moore\u2013penrose inverse for network learning. IEEE Transactions on Systems, Man, and Cybernetics: Systems, 52(5):3237\u2013 3250, 2022.   \n[24] Huiping Zhuang, Zhiping Lin, Yimin Yang, and Kar-Ann Toh. Analytic learning of convolutional neural network for pattern recognition, 2022.   \n[25] Mark D. McDonnell, Dong Gong, Amin Parvaneh, Ehsan Abbasnejad, and Anton van den Hengel. RanPAC: Random projections and pre-trained models for continual learning. In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information Processing Systems, volume 36, pages 12022\u201312053. Curran Associates, Inc., 2023.   \n[26] Huiping Zhuang, Run He, Kai Tong, Ziqian Zeng, Cen Chen, and Zhiping Lin. DS-AL: A dual-stream analytic learning for exemplar-free class-incremental learning. Proceedings of the AAAI Conference on Artificial Intelligence, 38(15):17237\u201317244, Mar. 2024.   \n[27] Run He, Huiping Zhuang, Di Fang, Yizhu Chen, Kai Tong, and Cen Chen. REAL: Representation enhanced analytic learning for exemplar-free class-incremental learning, 2024.   \n[28] Huiping Zhuang, Run He, Kai Tong, Di Fang, Han Sun, Haoran Li, Tianyi Chen, and Ziqian Zeng. Analytic federated learning, 2024.   \n[29] Zichen Liu, Chao Du, Wee Sun Lee, and Min Lin. Locality sensitive sparse encoding for learning world models online. In The Twelfth International Conference on Learning Representations, 2024.   \n[30] Jun-Yeong Moon, Keon-Hee Park, Jung Uk Kim, and Gyeong-Moon Park. Online class incremental learning on stochastic blurry task boundary via mask and visual prompt tuning. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 11731\u201311741, October 2023.   \n[31] Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, and Jonghyun Choi. Online continual learning on class incremental blurry task configuration with anytime inference. In International Conference on Learning Representations, 2022.   \n[32] Jihwan Bang, Heesu Kim, YoungJoon Yoo, Jung-Woo Ha, and Jonghyun Choi. Rainbow memory: Continual learning with a memory of diverse samples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 8218\u20138227, June 2021.   \n[33] Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister. DualPrompt: Complementary prompting for rehearsal-free continual learning. In Shai Avidan, Gabriel Brostow, Moustapha Ciss\u00e9, Giovanni Maria Farinella, and Tal Hassner, editors, Computer Vision \u2013 ECCV 2022, pages 631\u2013648, Cham, 2022. Springer Nature Switzerland.   \n[34] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021.   \n[35] David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, and Gregory Wayne. Experience replay for continual learning. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch\u00e9-Buc, E. Fox, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc., 2019.   \n[36] Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister. Learning to prompt for continual learning. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 139\u2013149, June 2022.   \n[37] Tyler L. Hayes and Christopher Kanan. Lifelong machine learning with deep streaming linear discriminant analysis. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, June 2020.   \n[38] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Learning multiple layers of features from tiny images. Technical report, Toronto, ON, Canada, 2009.   \n[39] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, Dawn Song, Jacob Steinhardt, and Justin Gilmer. The many faces of robustness: A critical analysis of out-of-distribution generalization. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 8340\u20138349, October 2021.   \n[40] Ya Le and Xuan Yang. Tiny imagenet visual recognition challenge. CS 231N, 7(7):3, 2015.   \n[41] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herve Jegou. Training data-efficient image transformers & distillation through attention. In Marina Meila and Tong Zhang, editors, Proceedings of the 38th International Conference on Machine Learning, volume 139 of Proceedings of Machine Learning Research, pages 10347\u201310357. PMLR, 18\u201324 Jul 2021.   \n[42] Gyuhak Kim, Changnan Xiao, Tatsuya Konishi, and Bing Liu. Learnability and algorithm for continual learning. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 16877\u201316896. PMLR, 23\u201329 Jul 2023.   \n[43] Gyuhak Kim, Bing Liu, and Zixuan Ke. A multi-head model for continual learning via out-ofdistribution replay. In Sarath Chandar, Razvan Pascanu, and Doina Precup, editors, Proceedings of The 1st Conference on Lifelong Learning Agents, volume 199 of Proceedings of Machine Learning Research, pages 548\u2013563. PMLR, 22\u201324 Aug 2022.   \n[44] Huiping Zhuang, Zhiping Lin, and Kar-Ann Toh. Correlation projection for analytic learning of a classification network. Neural Processing Letters, 53(6):3893\u20133914, dec 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. in task $k-1$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\hat{V}_{\\mathrm{FCN}}^{(k-1)}=(X_{1:k-2}^{\\mathrm{toal}\\top}X_{1:k-2}^{\\mathrm{toal}}+X_{k-1}^{\\mathrm{(B)\\top}}X_{1:k-1}^{\\mathrm{(B)}}+\\gamma I)^{-1}\\left[X_{1:k-2}^{\\mathrm{toal}\\top}Y_{1:k-2}^{\\mathrm{toal}}+X_{k-1}^{\\mathrm{(B)\\top}}\\bar{Y}_{k-1}^{\\mathrm{train}}\\right.}&{{}X_{k-1}^{\\mathrm{(B)\\top}}\\bar{Y}_{k}^{\\mathrm{train}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Hence, in task $k$ , we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\hat{W}_{\\mathrm{FCN}}^{(k)}=(X_{1:k-1}^{\\mathrm{toal}\\top}X_{1:k-1}^{\\mathrm{toal}}+X_{k}^{(\\mathrm{B})\\top}X_{k}^{(\\mathrm{B})}+\\gamma I)^{-1}\\left[X_{1:k-1}^{\\mathrm{toal}\\top}Y_{1:k-1}^{\\mathrm{total}}+X_{k}^{(\\mathrm{B})\\top}\\bar{Y}_{k}^{\\mathrm{train}}\\quad X_{k}^{(\\mathrm{B})\\top}\\tilde{Y}_{k}^{\\mathrm{train}}\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We have defined the autocorrelation memory matrix $R_{k-1}$ in the paper via ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\pmb{R}_{k-1}=(\\pmb{X}_{1:k-2}^{\\mathrm{total}\\top}\\pmb{X}_{1:k-2}^{\\mathrm{total}}+\\pmb{X}_{k-1}^{\\mathrm{(B)}\\top}\\pmb{X}_{k-1}^{\\mathrm{(B)}}+\\gamma\\pmb{I})^{-1}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "To facilitate subsequent calculations, here we also define a cross-correlation matrix $Q_{k-1}$ , i.e., ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{k-1}=\\left[X_{1:k-2}^{\\mathrm{total}\\top}Y_{1:k-2}^{\\mathrm{total}}+X_{k-1}^{\\mathrm{(B)\\top}}\\bar{Y}_{k-1}^{\\mathrm{train}}\\quad X_{k-1}^{\\mathrm{(B)\\top}}\\tilde{Y}_{k}^{\\mathrm{train}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Thus we can rewrite (13) as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{W}_{\\mathrm{FCN}}^{(k-1)}=R_{k-1}Q_{k-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, in task $k$ we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\hat{W}_{\\mathrm{FCN}}^{(k)}=R_{k}Q_{k}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "From (15), we can recursively calculate $\\scriptstyle R_{k}$ from $R_{k-1}$ , i.e., ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\pmb{R}_{k}=\\left(\\pmb{R}_{k-1}^{-1}+\\pmb{X}_{k}^{(\\mathrm{B})\\top}\\pmb{X}_{k}^{(\\mathrm{B})}\\right)^{-1}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "According to the Woodbury matrix identity, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n(A+U C V)^{-1}=A^{-1}-A^{-1}U(C^{-1}+V A^{-1}U)^{-1}V A^{-1}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Let $A=R_{k-1}^{-1},U=X_{k}^{(\\mathrm{B})^{\\top}},C=I$ , and $V=X_{k}^{\\mathrm{(B)}}$ in (19), we have ", "page_idx": 13}, {"type": "equation", "text": "$$\nR_{k}=R_{k-1}-R_{k-1}X_{k}^{\\mathrm{(B)\\top}}(I+X_{k}^{\\mathrm{(B)}}R_{k-1}X_{k}^{\\mathrm{(B)\\top}})^{-1}X_{k}^{\\mathrm{(B)}}R_{k-1}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Hence, $\\scriptstyle R_{k}$ can be recursively updated using its last-task counterpart $R_{k-1}$ and data from the current task (i.e., $X_{k}^{\\mathrm{(B)}}$ ). This proves the recursive calculation of the autocorrelation memory matrix. ", "page_idx": 13}, {"type": "text", "text": "Next, we derive the recursive formulation of $\\hat{W}_{\\mathrm{FCN}}^{(k)}$ . To this end, we also recurse the cross-correlation matrix $Q_{k}$ in task $k$ , i.e., ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{k}=\\left[X_{1:k-1}^{\\mathrm{(oul)}}Y_{1:k-1}^{\\mathrm{(oul)}}+X_{k}^{\\mathrm{(B)^{\\top}}}\\bar{Y}_{k}^{\\mathrm{ruin}}\\quad X_{k}^{\\mathrm{(B)^{\\top}}}\\bar{Y}_{k}^{\\mathrm{ruin}}\\right]=Q_{k-1}^{\\prime}+\\left[X_{k}^{\\mathrm{(B)^{\\top}}}\\bar{Y}_{k}^{\\mathrm{ruin}}\\quad X_{k}^{\\mathrm{(B)^{\\top}}}\\tilde{Y}_{k}^{\\mathrm{ruin}}\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{k-1}^{\\prime}=\\left\\{\\left[Q_{k-1}\\right.\\quad\\mathbf{0}_{d_{(\\mathrm{B})}\\times(d_{y_{k}}-d_{y_{k-1}})}\\right],\\quad d_{y_{k}}>d_{y_{k-1}}}\\\\ {Q_{k-1},\\quad\\qquad\\qquad\\qquad\\quad d_{y_{k}}=d_{y_{k-1}}}\\end{array}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "cNlaostes etsh (ath ethnec ec omnocraet ecnoaltuiomnn si)n  t(h2a2n) t. oI tt hise  paossssuimblpet itohna tt thhaet $Y_{1:k}^{\\mathrm{train}}$ nion  tnaeswk $k$ acsosnetsa ianpsp emaro rien  tdaastak $Y_{1:k-1}^{\\mathrm{train}}$   \n$k$ , then $\\tilde{Y}_{k}^{\\mathrm{train}}$ should be 0. ", "page_idx": 13}, {"type": "text", "text": "Similar to what (22) does, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{W}_{\\mathrm{FCN}}^{(k-1)\\prime}=\\left\\{\\overset{\\displaystyle\\left[\\hat{W}_{\\mathrm{FCN}}^{(k-1)}\\right.}{\\hat{W}_{\\mathrm{FCN}}^{(k-1)}}\\right.\\quad\\mathbf{0}_{d_{\\mathrm{(B)}}\\times(d_{y_{k}}-d_{y_{k-1}})}\\right],\\quad d_{y_{k}}>d_{y_{k-1}}}\\\\ {\\hat{W}_{\\mathrm{FCN}}^{(k-1)},\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad d_{y_{k}}=d_{y_{k-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "We have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\hat{W}_{\\mathrm{FCN}}^{(k-1)\\prime}=R_{k-1}Q_{k-1}^{\\prime}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, W\u02c6 (k) can be rewritten as ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{W}_{\\mathrm{FCN}}^{(k)}=R_{k}Q_{k}}\\\\ &{\\qquad\\quad=R_{k}(Q_{k-1}^{\\prime}+\\bigl[X_{k}^{\\mathrm{(B)^{\\top}}}\\bar{Y}_{k}^{\\mathrm{train}}\\quad X_{k}^{\\mathrm{(B)^{\\top}}}\\tilde{Y}_{k}^{\\mathrm{train}}\\bigr])}\\\\ &{\\qquad\\quad=R_{k}Q_{k-1}^{\\prime}+R_{k}X_{k}^{\\mathrm{(B)^{\\top}}}\\left[\\bar{Y}_{k}^{\\mathrm{train}}\\quad\\tilde{Y}_{k}^{\\mathrm{train}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "By substituting (20) into $R_{k}Q_{k-1}^{\\prime}$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{k}Q_{k-1}^{\\prime}=R_{k-1}Q_{k-1}^{\\prime}-R_{k-1}X_{k}^{\\mathrm{(B)^{T}}}(I+X_{k}^{\\mathrm{(B)}}R_{k-1}X_{k}^{\\mathrm{(B)^{T}}})^{-1}X_{k}^{\\mathrm{(B)}}R_{k-1}Q_{k-1}^{\\prime}}\\\\ &{\\qquad\\qquad=\\hat{W}_{\\mathrm{FCN}}^{(k-1)\\prime}-R_{k-1}X_{k}^{\\mathrm{(B)^{T}}}(I+X_{k}^{\\mathrm{(B)}}R_{k-1}X_{k}^{\\mathrm{(B)^{T}}})^{-1}X_{k}^{\\mathrm{(B)}}\\hat{W}_{\\mathrm{FCN}}^{(k-1)\\prime}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To simplify this equation, let $K_{k}=(\\pmb{I}+\\pmb{X}_{k}^{\\mathrm{(B)}}\\pmb{R}_{k-1}\\pmb{X}_{k}^{\\mathrm{(B)}\\top})^{-1}$ . Since ", "page_idx": 14}, {"type": "equation", "text": "$$\nI=K_{k}K_{k}^{-1}=K_{k}(I+X_{k}^{(\\mathrm{B})}R_{k-1}X_{k}^{(\\mathrm{B})\\top}),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "we have $K_{k}=I-K_{k}X_{k}^{\\mathrm{(B)}}R_{k-1}X_{k}^{\\mathrm{(B)}\\top}$ . Therefore, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{k-1}X_{k}^{\\mathrm{(B)^{T}}}(I+X_{k}^{\\mathrm{(B)}}R_{k-1}X_{k}^{\\mathrm{(B)^{T}}})^{-1}}\\\\ &{=R_{k-1}X_{k}^{\\mathrm{(B)^{T}}}K_{k}}\\\\ &{=R_{k-1}X_{k}^{\\mathrm{(B)^{T}}}(I-K_{k}X_{k}^{\\mathrm{(B)}}R_{k-1}X_{k}^{\\mathrm{(B)^{T}}})}\\\\ &{=(R_{k-1}-R_{k-1}X_{k}^{\\mathrm{(B)^{T}}}K_{k}X_{k}^{\\mathrm{(B)}}R_{k-1})X_{k}^{\\mathrm{(B)^{T}}}}\\\\ &{=R_{k}X_{k}^{\\mathrm{(B)^{T}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Substituting (27) into (26), $R_{k}Q_{k-1}^{\\prime}$ can be written as ", "page_idx": 14}, {"type": "equation", "text": "$$\nR_{k}Q_{k-1}^{\\prime}={\\hat{W}}_{\\mathrm{FCN}}^{(k-1)\\prime}-R_{k}X_{k}^{\\mathrm{(B)\\top}}X_{k}^{\\mathrm{(B)}}{\\hat{W}}_{\\mathrm{FCN}}^{(k-1)\\prime}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Substituting (28) into (25) implies that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{W}_{\\mathrm{FCN}}^{(k)}=\\hat{W}_{\\mathrm{FCN}}^{(k-1)\\prime}-R_{k}X_{k}^{\\mathrm{(B)^{\\top}}}X_{k}^{\\mathrm{(B)}}\\hat{W}_{\\mathrm{FCN}}^{(k-1)\\prime}+R_{k}X_{k}^{\\mathrm{(B)^{\\top}}}\\left[\\bar{Y}_{k}^{\\mathrm{train}}\\quad\\tilde{Y}_{k}^{\\mathrm{train}}\\right]}\\\\ &{\\qquad\\quad=\\left[\\hat{W}_{\\mathrm{FCN}}^{(k-1)}-R_{k}X_{k}^{\\mathrm{(B)^{\\top}}}X_{k}^{\\mathrm{(B)}}\\hat{W}_{\\mathrm{FCN}}^{(k-1)}+R_{k}X_{k}^{\\mathrm{(B)^{\\top}}}\\bar{Y}_{k}^{\\mathrm{train}}\\quad R_{k}X_{k}^{\\mathrm{(B)^{\\top}}}\\tilde{Y}_{k}^{\\mathrm{train}}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which completes the proof. ", "page_idx": 14}, {"type": "text", "text": "B GCIL Properties ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The GCIL scenario [6] is a recent CIL focus. Given task-wise learning tasks, we can involve all class labels in a set $\\boldsymbol{S}$ with the number of classes $N$ . The sample sizes, such as the numbers of input images of different classes appearing in task $k$ , are modeled as a random vector $c_{k}\\in\\mathbb{R}^{N}$ . Each entry $c_{k,i}$ is a random variable denoting the sample size of class $i$ in task $k$ . In the generalized form, $c_{k}$ is sampled from a task-dependent distribution. The GCIL scenario can be summarized as the following three key properties. ", "page_idx": 15}, {"type": "text", "text": "Property B.1. The number of classes in a task is not fixed. Suppose $m_{k}$ is the number of classes in task $k$ , we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\nM_{k}=|\\{i\\in\\mathcal{S}:c_{k,i}>0\\}|\\sim\\mathcal{M}_{k},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\mathcal{M}_{k}$ is a task-dependent distribution. ", "page_idx": 15}, {"type": "text", "text": "Property B.2. Classes appearing in different tasks could overlap. For two tasks $k$ and $k^{\\prime}$ , $k\\neq k^{\\prime}$ , we have: ", "page_idx": 15}, {"type": "equation", "text": "$$\nP(c_{k}\\odot c_{k^{\\prime}}\\neq0)>0,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\odot$ denotes element-wise multiplication of two vectors and $P(\\cdot)$ is the probability. ", "page_idx": 15}, {"type": "text", "text": "Property B.3. Sample sizes of different classes at the same task could be different. That is, for task $k$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\ni,j\\in S,i\\neq j,P(c_{k,i}\\neq c_{k,j}\\mid c_{k,i}\\neq0,c_{k,j}\\neq0)>0.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In short, the number of classes and samples could vary throughout the continual learning. ", "page_idx": 15}, {"type": "text", "text": "C Si-Blurry Setting", "text_level": 1, "page_idx": 15}, {"type": "image", "img_path": "P6aJ7BqYlc/tmp/2de1c94c0c6e2844a17cd5a4a76348a299b6b79be02dae3ac45d065a9393abfb.jpg", "img_caption": ["Figure 3: A configuration example of Si-Blurry setting. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "The Si-Blurry setting [30] satisfies all the three properties of GCIL mentioned in Appendix B and can be treated as its good realization. As shown in Figure 3, for a $K$ -task learning, the Si-Blurry first randomly partitions all classes into two groups: disjoint classes that cannot overlap between tasks and blurry classes that might reappear. The ratio of partition is controlled by the disjoint class ratio $r_{\\mathrm{D}}$ , which is defined as the ratio of the number of disjoint classes to the number of all classes. Then disjoint classes and blurry classes are randomly assigned to disjoint tasks $(T^{\\mathrm{D}})$ and blurry tasks $(T^{\\mathtt{B}})$ respectively. Next, each blurry task further conducts the blurry sample division by randomly extracting part of samples to assign to other blurry tasks based on blurry sample ratio $r_{\\mathrm{{B}}}$ , which is defined as the ratio of the extracted sample within samples in all blurry tasks. Finally, each Si-Blurry task $T^{\\mathrm{B+D}}$ with a stochastic blurry task boundary consists of a disjoint and blurry task. We adopt Si-Blurry with different combinations of $r_{\\mathrm{D}}$ and $r_{\\mathrm{B}}$ for reliable empirical validations. ", "page_idx": 15}, {"type": "text", "text": "D Compute Resources ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "GPU Usage. We conduct experiments in PyTorch on one Nvidia Geforce RTX 4090 GPU with a batch size of 64 for training and 128 for inference. Figure 4 shows that the GACL uses minimal GPU memory. Our GACL significantly reduces GPU memory usage since it requires no back-propagation, thereby detaching gradients from tensors during calculations. This characteristic allows our approach to be applied with a larger batch size without memory leaks. ", "page_idx": 16}, {"type": "image", "img_path": "P6aJ7BqYlc/tmp/192755f69f0c9275076eedc044a0a28611dbdb10a3e53af1e4a3ca399a6fe7f3.jpg", "img_caption": ["Figure 4: GPU memory consumption in GB with a batch size of 64 where replay-based methods are with 2000 memory size. "], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "Training Time. Table 5 further illustrates the GACL\u2019s training time compared to others on one Nvidia Geforce RTX 4090 GPU, highlighting its efficiency. The GACL is faster than any other baselines except SLDA on three datasets because only the classifier and autocorrelation memory matrix $\\boldsymbol{R}$ are updated, leading to small numbers of trainable parameters compared to those baselines in a back-propagation manner. ", "page_idx": 16}, {"type": "table", "img_path": "P6aJ7BqYlc/tmp/aae94eeed1974c6e280958df229a450727f6a8b91f11162c8091a0e058773a61.jpg", "table_caption": ["Table 5: Average Training time of 5 independent seeds in seconds (s) where replay-based methods are with 2000 memory size. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "E Hyperparameter Analysis for Regularization Term ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Table 6: $A_{\\mathrm{AUC}}$ , $\\mathcal{A}_{\\mathrm{Avg}}$ , and $\\boldsymbol{A}_{\\mathrm{Last}}$ of the GACL on all benchmark datasets with various values of the regularization term . ", "page_idx": 16}, {"type": "table", "img_path": "P6aJ7BqYlc/tmp/2a327ad161ab44cc352965851e7206868f7585ec777d26cc31e0803c4d2007e2.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "The regularization term $\\gamma$ plays a crucial role and demonstrates robust behavior throughout our experiments. We assess the impact of the regularization term $\\gamma$ in Table 6 and visualize the real-time accuracy of the GACL as it learns from training samples in Figure 5. Table 6 reveals the GACL\u2019s consistent performance across a broad range of $\\gamma$ values, spanning from 10 to 10000. This highlights the versatility and robustness of our proposed GACL. However, as indicated in Figure 5, $\\gamma$ of 10000 leads to slightly poorer performance because the ACL is prone to underfitting due to simple linear regression [44]. ", "page_idx": 17}, {"type": "image", "img_path": "P6aJ7BqYlc/tmp/a25db63e942fd16fb84db1ef7c0a92206c69484ee5648674494ef3c56b55bbc8.jpg", "img_caption": ["Figure 5: Real-time accuracy of the GACL on all benchmark datasets with various values of the regularization term $\\gamma$ . "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "Notably, both Table 6 and Figure 5 demonstrate that the absence of regularization results in a significant decline in performance. This underscores the crucial importance of incorporating $\\gamma$ in the model. As indicated in (7), if we eliminate regularization by setting $\\gamma$ to 0, the initial autocorrelation memory matrix $R_{0}$ becomes zero. Subsequently, the computation of the autocorrelation memory matrix in task 1, denoted as $R_{1}$ , is expressed as: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{R_{1}=(X_{1}^{\\mathrm{total}\\top}X_{1}^{\\mathrm{total}})^{-1}=(X_{1}^{\\mathrm{(B)^{\\top}}}X_{1}^{\\mathrm{(B)}})^{-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "However, it\u2019s crucial to emphasize that $X_{1}^{\\mathrm{(B)^{\\top}}}X_{1}^{\\mathrm{(B)}}$ might result in a singular matrix, rendering it non-invertible. This potential singularity introduces an error in calculating $R_{1}$ , leading to a decrease in accuracy. ", "page_idx": 17}, {"type": "text", "text": "F Analysis of task-wise Accuracy Trends of the GACL ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "As depicted in Figure 2 (a), the task-wise accuracy of the GACL on CIFAR-100 demonstrates an increase. Notably, in the initial two tasks, the accuracy is lower compared to other EFCIL methods. However, on the other datasets, the GACL remains relatively stable. Upon a more detailed examination of the dataset split, we infer that the observed variations in trends are attributed to the specific dataset settings. ", "page_idx": 17}, {"type": "text", "text": "For a dataset with $N$ classes, the class number ratio $r_{c}$ after training on $i$ -th samples is defined as $r_{c}=d_{i}/N$ , where $d_{i}$ is the number of classes that have been seen observed at that point. As Figure 6 indicates, by examining the real-time accuracy and the class number ratio $r_{c}$ across the three sets of figures, a notable observation is made: when the sample size is small, the class number ratio $r_{c}$ on CIFAR-100 always surpasses that of the other two datasets on 5 seeds. This suggests that tasks on CIFAR-100 are notably more complex and intricate, resembling a few-shot learning scenario. ", "page_idx": 17}, {"type": "text", "text": "Consequently, the GACL exhibits lower task-wise accuracy compared to other gradient-based EFCIL methods, particularly in the initial stages. However, as more training samples are acquired, its accuracy progressively improves. ", "page_idx": 17}, {"type": "image", "img_path": "P6aJ7BqYlc/tmp/86d4f7ea1f856d1b568a17bd51c35509f1dc94b2426eed0506bb5d9fbbac598e.jpg", "img_caption": ["Figure 6: Real-time accuracy and class number ratio $r_{c}$ on 5 independent random seeds. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: All the claims are clearly clarified, including the contributions made in the paper and important assumptions and limitations. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 18}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: In Section 4.5, a discussion of the limitations and the future work of the GACL is conducted. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper. \u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. ", "page_idx": 18}, {"type": "text", "text": "\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: The proof of the Theorem 3.1 is listed in Appendix A Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 19}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: Our paper comprehensively outlines both the experimental implementation and algorithmic details, ensuring transparency in our method. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example   \n(a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: All datasets are publicly accessible, and we have provided the source code. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 20}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: We have reported all the necessary details of our experiment. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.   \n\u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 20}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes]   \nJustification: Results in this paper are reported by the average of 5 different seeds with standard error.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The information on the computer resources for our GACL is listed in Appendix D. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 21}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: The paper fully complies with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 21}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 21}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: The models and benchmark datasets mentioned in the paper are all openly accessible with no personally identifiable information or offensive content. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 22}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We have verified that this paper cites all the datasets and models we used.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 22}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: We have made our source code publicly available at https://github.com/ CHEN-YIZHU/GACL. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 23}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 23}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 23}]