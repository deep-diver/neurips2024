[{"figure_path": "HC6iqpPt3L/tables/tables_17_1.jpg", "caption": "Table 1: Avg. MSE Summary in Tabular Env: Compares the average MSE across multiple GVFs in different experimental settings in Tabular environment. We compare baselines with GVFExplorer at same 2 \u00d7 10<sup>6</sup> steps of learning. We show the % improvement in GVFExplorer w.r.t. to best baseline RoundRobin. Note: Smaller MSE indicates better performance.", "description": "This table compares the average Mean Squared Error (MSE) across multiple General Value Functions (GVFs) for different experimental settings using a tabular environment.  It compares the performance of the proposed GVFExplorer algorithm against several baseline methods (BPS, SR, UniformPol, RoundRobin, MixPol) after 2 million learning steps.  The table highlights the percentage improvement achieved by GVFExplorer compared to the best-performing baseline.  Lower MSE values indicate better performance.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/tables/tables_17_2.jpg", "caption": "Table 2: Optimized Hyperparameters: We show the optimized hyperparameters for different Experimental Settings. \u03b1Q is learning rate for value function. \u03b1M is learning rate for variance function.", "description": "This table presents the optimal hyperparameter settings for various experimental setups used in the paper.  It lists the learning rates (\u03b1Q for the Q-value network and \u03b1M for the variance network) that yielded the best performance (lowest MSE) for each experimental condition. The conditions include using identical or distinct cumulants, and the number of GVFs evaluated. The learning rates were optimized for different scenarios, demonstrating the adaptive nature of the algorithm.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/tables/tables_22_1.jpg", "caption": "Table 3: Avg. MSE Summary for Continuous Env.: Averaged MSE across two GVFs for different algorithms in the continuous environment. GVFExplorer performance measured against others using standard and prioritized experience replay after 1 \u00d7 106 learning steps. Note: Smaller MSE indicates better performance.", "description": "This table presents the average Mean Squared Error (MSE) for two General Value Functions (GVFs) across different algorithms in a continuous environment.  The algorithms are compared using both standard experience replay and prioritized experience replay, after 1 million learning steps.  The table shows that GVFExplorer consistently outperforms other methods, achieving lower MSE across both replay buffer types. The percent improvement of GVFExplorer over the best-performing baseline is also provided.", "section": "7.2 Continuous State Environment with Non-Linear Function Approximation"}]