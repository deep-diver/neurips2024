[{"figure_path": "HC6iqpPt3L/figures/figures_5_1.jpg", "caption": "Figure 1: MSE Performance: Averaged MSE over 25 runs with standard error in different experimental settings. GVFExplorer demonstrate notably lower MSE compared to the baselines.", "description": "This figure displays the averaged Mean Squared Error (MSE) over 25 runs for different algorithms across three distinct experimental settings.  The x-axis represents the number of samples and the y-axis shows the MSE. Each subplot corresponds to a different experimental setup: (a) Two Distinct Policies & Identical Cumulants, (b) Non-Stationary Cumulant in FourRooms, and (c) Large Scale Evaluation with 40 Distinct GVFs.  The results clearly indicate that the GVFExplorer algorithm consistently outperforms all baseline methods in terms of achieving significantly lower MSE values across all three experiments.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_7_1.jpg", "caption": "Figure 1: MSE Performance: Averaged MSE over 25 runs with standard error in different experimental settings. GVFExplorer demonstrate notably lower MSE compared to the baselines.", "description": "This figure compares the Mean Squared Error (MSE) performance of the proposed GVFExplorer algorithm against several baseline methods across three different experimental scenarios.  The x-axis represents the number of samples used, and the y-axis shows the average MSE across all GVFs (General Value Functions). The three subfigures showcase different experimental settings: (a) Two Distinct Policies & Identical Cumulants, (b) Non-Stationary Cumulant in FourRooms, and (c) Large Scale Evaluation with 40 Distinct GVFs. In all cases, GVFExplorer consistently outperforms the baselines, demonstrating its effectiveness in learning multiple GVFs efficiently and accurately.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_7_2.jpg", "caption": "Figure 2: Two Distinct Policies & Distinct Cumulants: Evaluate averaged MSE over 25 runs with two distinct distractor GVFs (\u03c0\u2081, c\u2081), (\u03c0\u2082, c\u2082) in gridworld . Green dots at top show two GVF goals. (a) Averaged MSE, (b) averaged absolute error in GVFs value predictions for baseline RoundRobin and (c) GVFExplorer. The color bar uses log scale & vibrant colors indicate higher values.", "description": "This figure compares the performance of GVFExplorer against a baseline method (RoundRobin) for estimating two General Value Functions (GVFs) with distinct target policies and distinct cumulants in a gridworld environment.  The averaged Mean Squared Error (MSE) is shown, along with heatmaps visualizing the absolute error in GVF value predictions for both methods.  The heatmaps reveal that GVFExplorer achieves significantly lower errors, particularly in areas where the RoundRobin baseline exhibits higher uncertainty.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_8_1.jpg", "caption": "Figure 3: Non-Linear Function Approximation: (a) Averaged MSE over 50 runs with standard error using Experience Replay Buffer (solid lines) and PER (dotted lines). GVFExplorer show lower MSE with both buffers. PER generally reduces MSE across all algorithms except SR. Log-scale absolute value error for RoundRobin (b) and GVFExplorer (c); GVFExplorer achieves smaller errors (vibrant colors represent higher values).", "description": "This figure compares the performance of GVFExplorer against several baselines in a continuous state environment with non-linear function approximation using both standard experience replay and prioritized experience replay (PER).  The results show that GVFExplorer achieves the lowest mean squared error (MSE) in both cases, highlighting the effectiveness of the algorithm even with complex function approximation.  The use of PER further improves the performance of all methods.", "section": "7.2 Continuous State Environment with Non-Linear Function Approximation"}, {"figure_path": "HC6iqpPt3L/figures/figures_9_1.jpg", "caption": "Figure 4: MSE in Mujoco: Averaged MSE over 5 runs with standard error in Mujoco environment with continuous state-actions for (a)Walker and (b)Cheetah domains for GVFExplorer, UniformPolicy and RoundRobin. GVFExplorer consistently lowers averaged MSE as compared to the baselines.", "description": "This figure compares the performance of GVFExplorer against two baselines (UniformPolicy and RoundRobin) across two MuJoCo environments (Walker and Cheetah) in terms of averaged Mean Squared Error (MSE).  The results show that GVFExplorer consistently achieves lower MSE than the baselines, highlighting its effectiveness in efficiently learning multiple General Value Functions (GVFs) in complex continuous control environments.", "section": "7.3 Mujoco Environments with Continuous State-Action Tasks"}, {"figure_path": "HC6iqpPt3L/figures/figures_17_1.jpg", "caption": "Figure 5: Visual representation of cumulants.", "description": "This figure shows three different types of cumulants used in the paper's experiments: constant, distractor, and drifter.  The constant cumulant has a fixed value. The distractor cumulant is a stationary signal with a fixed mean and variance, following a normal distribution. The drifter cumulant is a non-stationary signal, modeled as a zero-mean random walk with low variance. The figure visually represents how each type of cumulant varies over time.", "section": "B.2 Types of Cumulants"}, {"figure_path": "HC6iqpPt3L/figures/figures_18_1.jpg", "caption": "Figure 6: Impact of Learning Rate on Averaged MSE in Two Distinct Policies & Identical Cumulants scenario: Demonstrate the effect of changing minimum value of learning rate on the averaged MSE (performance averaged over 10 runs) across GVFs. The optimal hyperparameter is selected based on the least MSE in these plots. LR_Q: value learning rate, LR_M: variance learning rate.", "description": "This figure shows the sensitivity analysis of varying learning rates for value functions (all baselines) and variance functions (GVFExplorer) with the averaged MSE performance in Two Distinct Policies & Identical Cumulants. The learning rate resulting in the lowest MSE was selected as optimal. For each algorithm, the averaged MSE across multiple GVFs is shown.  The optimal hyperparameters for each algorithm are obtained from these plots by selecting the combination of learning rates that resulted in the lowest MSE.", "section": "B.3.1 Two Distinct Policies & Identical Cumulants"}, {"figure_path": "HC6iqpPt3L/figures/figures_18_2.jpg", "caption": "Figure 7: Two Distinct Policies & Identical Cumulants in 20x20 Grid: Averaged MSE over 25 runs for two GVFs (\u03c0\u2081, C), (\u03c0\u2082, c) with same cumulant. We show individual MSE\u2081, MSE\u2082. GVFExplorer shows lower MSE compared to other baselines.", "description": "This figure shows the mean squared error (MSE) for two different general value functions (GVFs) over 25 independent runs in a 20x20 gridworld environment.  The two GVFs use distinct target policies but share the same cumulant (a distractor cumulant). The figure compares the performance of GVFExplorer to several baseline methods (RoundRobin, SR, etc.).  The results demonstrate that GVFExplorer achieves a lower MSE than the baselines, indicating improved performance in estimating the value functions.", "section": "B.3.1 Two Distinct Policies & Identical Cumulants"}, {"figure_path": "HC6iqpPt3L/figures/figures_19_1.jpg", "caption": "Figure 8: Two Distinct Policies & Distinct Cumulants in Grid env: Evaluate two distinct GVFs (\u03c0\u2081, C\u2081) and (\u03c0\u2082, C\u2082) averaged over 25 runs. Compared baselines \u2013 RoundRobin, MixturePolicy, UniformPolicy, SR, BPS with GVFExplorer. Green dots show GVF goals. (a) Individual MSE\u2081 for GVF (\u03c0\u2081, C\u2081), and MSE\u2082 for GVF (\u03c0\u2082, C\u2082). (b,c) Estimated variance M\u2081, M\u2082 in GVFExplorer. Variance plots show log-scale empirical values; most areas appear black, due to their relatively small magnitude compared to high variance regions. The color bar uses log scale & vibrant colors indicate higher values.", "description": "This figure shows the results of an experiment comparing GVFExplorer to several baseline methods for estimating two distinct general value functions (GVFs) in a grid environment.  The GVFs have different target policies and distinct distractor cumulants. The figure shows (a) the individual mean squared error (MSE) for each GVF over 25 runs.  Panels (b) and (c) show the estimated variance of the returns for each GVF, illustrating the higher variance areas that GVFExplorer prioritizes. The results demonstrate GVFExplorer's superior performance in minimizing MSE compared to the baselines.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_19_2.jpg", "caption": "Figure 1: MSE Performance: Averaged MSE over 25 runs with standard error in different experimental settings. GVFExplorer demonstrate notably lower MSE compared to the baselines.", "description": "This figure compares the performance of GVFExplorer against several baseline methods in terms of Mean Squared Error (MSE) across multiple General Value Functions (GVFs).  The results are shown for three different experimental settings: 1) Two distinct policies with identical cumulants, 2) Non-stationary cumulants in a FourRooms environment, and 3) a large-scale evaluation involving 40 distinct GVFs. In all three scenarios, GVFExplorer demonstrates significantly lower MSE compared to baselines, indicating its superior performance in accurately estimating multiple GVFs with improved data efficiency.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_20_1.jpg", "caption": "Figure 10: Impact of Feature Approximation on MSE: Averaged MSE over 10 runs with standard error in tabular environment. Increasing GroupingFactor indicates coarser feature mapping (more states mapped to the same feature). As expected, overall MSE increases with coarser mapping. GVFExplorer outperforms baselines given a reasonable feature approximator.", "description": "This figure shows how the performance of different algorithms changes when the resolution of the state space representation is reduced.  As expected, performance degrades for all algorithms with lower resolution due to loss of information. However, GVFExplorer consistently outperforms the other methods even at lower resolutions. This highlights the algorithm's robustness to less precise state representations.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_20_2.jpg", "caption": "Figure 11: Non-Stationary Cumulant in FourRooms: We placed a stationary distractor cumulant in the top-left room and a non-stationary drifter cumulant in the top-right room. (a & b) show the change in estimated variance M over time, highlighting the effectiveness of GVFExplorer in tracking the non-stationary cumulant placed in top-right corner, later in learning process over stationary cumulant (top-left). (c) shows the average MSE for GVFExplorer with different levels of driftness (\u03c3) in the cumulant value; higher driftness leads to higher MSE.", "description": "This figure demonstrates the performance of GVFExplorer in a FourRooms environment with non-stationary rewards.  Panels (a) and (b) show heatmaps of the estimated variance (M) at different stages of training, illustrating how GVFExplorer adapts to track the changing reward. Panel (c) shows how the average MSE changes as the variability (\u03c3) of the non-stationary reward is increased, revealing GVFExplorer's robustness to this variation.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_21_1.jpg", "caption": "Figure 12: 10 different cumulants for Large Scale Evaluation with 40 Distinct GVFs in 20 \u00d7 20 grid. The color depict the cumulant empirical value.", "description": "This figure shows the 10 different cumulants used in the large-scale evaluation experiment with 40 distinct GVFs. Each cumulant is assigned to a specific region (goal) in the 20x20 gridworld environment. The color intensity of each grid cell represents the empirical value of the cumulant in that region. The figure helps to visualize the distribution of cumulants across the gridworld and aids in understanding how different cumulants contribute to the overall GVF evaluation task.", "section": "7.1 Tabular Experiments"}, {"figure_path": "HC6iqpPt3L/figures/figures_21_2.jpg", "caption": "Figure 13: IS vs Expected Sarsa update in FR env: We show the averaged MSE (over 25 runs) in Fourrooms by doing off-policy IS corrections in TD updates and off-policy Expected Sarsa in GVFExplorer algorithm. Expected Sarsa leads to smaller MSE and faster convergence.", "description": "The figure compares the performance of using Importance Sampling (IS) and Expected Sarsa for updating the value function in the FourRooms environment.  It shows that Expected Sarsa achieves a lower mean squared error (MSE) and converges faster than IS. This indicates that Expected Sarsa is a more effective method for off-policy learning in this environment.", "section": "B.3.6 Ablation: IS ratios vs Expected Sarsa Update"}, {"figure_path": "HC6iqpPt3L/figures/figures_22_1.jpg", "caption": "Figure 3: Non-Linear Function Approximation: (a) Averaged MSE over 50 runs with standard error using Experience Replay Buffer (solid lines) and PER (dotted lines). GVFExplorer show lower MSE with both buffers. PER generally reduces MSE across all algorithms except SR. Log-scale absolute value error for RoundRobin (b) and GVFExplorer (c); GVFExplorer achieves smaller errors (vibrant colors represent higher values).", "description": "This figure compares the performance of different algorithms with and without prioritized experience replay (PER) for estimating general value functions in a continuous state environment with non-linear function approximation.  It shows that GVFExplorer consistently achieves lower mean squared error (MSE) than the other baselines, both with and without PER.  The use of PER further improves the performance of most algorithms, especially GVFExplorer. The plots visualize the average MSE and the absolute error in GVF value estimations to provide a more detailed view of performance.", "section": "7.2 Continuous State Environment with Non-Linear Function Approximation"}, {"figure_path": "HC6iqpPt3L/figures/figures_23_1.jpg", "caption": "Figure 15: Value Prediction Errors in Continuous Env: Compares log-scale absolute errors between actual and predicted values for two GVFs. Top row: RoundRobin baseline errors; Bottom row: GVFExplorer results at equivalent steps. (Col 1): Mean error, (Col 2): Error in GVF 1, (Col 3): Error in GVF 2. GVFExplorer specially achieves smaller errors in areas where RoundRobin has higher MSE, due to the focus on reducing overall MSE (indicated by lighter colors).", "description": "This figure compares the prediction errors of two different algorithms, RoundRobin and GVFExplorer, for estimating the values of two general value functions (GVFs) in a continuous environment. The top row displays the errors from the RoundRobin algorithm, while the bottom row shows the errors from the GVFExplorer algorithm.  Each column shows a different metric:  the average error across both GVFs, the error for the first GVF, and the error for the second GVF.  The results indicate that GVFExplorer achieves lower errors, particularly in areas where RoundRobin has higher errors, demonstrating its effectiveness in minimizing overall error.", "section": "7.2 Continuous State Environment with Non-Linear Function Approximation"}, {"figure_path": "HC6iqpPt3L/figures/figures_23_2.jpg", "caption": "Figure 16: Estimated Variance in Continuous Env: The two GVF goals are depicted in Green. We show the estimated variance M (log values) over states from GVFExplorer method highlighting the motivation for behavior policy to visit high variance areas. (a) Mean variance, (b) Variance for left goal GVF, (c) variance for right goal GVF. These variance plots show log scale empirical values; most areas appear black due to their relatively small magnitude compared to high variance regions.", "description": "This figure shows the estimated variance of returns across states for two different GVFs (left and right goal). The color intensity reflects the magnitude of the variance, with brighter colors indicating higher variance. This visualization helps explain why GVFExplorer focuses on high-variance areas to improve the efficiency of data collection, thereby reducing the mean squared error in the GVF estimations.", "section": "7.2 Continuous State Environment with Non-Linear Function Approximation"}, {"figure_path": "HC6iqpPt3L/figures/figures_23_3.jpg", "caption": "Figure 17: Sampled trajectories in Continuous Env: GVFExplorer generates trajectories which reduces the overall variance, thus minimizing the total MSE. Contrary, RoundRobin collects data according to given target policies. Green dots show GVF goals and red depicts the start state.", "description": "This figure compares the trajectories generated by GVFExplorer and RoundRobin in a continuous environment.  GVFExplorer's trajectories are more focused, aiming to minimize the overall variance and MSE. In contrast, RoundRobin's trajectories follow the given target policies more directly, potentially leading to less efficient exploration and higher MSE.", "section": "7.2 Continuous State Environment with Non-Linear Function Approximation"}]