[{"figure_path": "bqGAheAeQY/figures/figures_1_1.jpg", "caption": "Figure 1: We present TRACKSTO4D, a method for mapping a set of 2D point tracks extracted from casual dynamic videos into their corresponding 3D locations and camera motion. At inference time, our network predicts the dynamic structure and camera motion in a single feed-forward pass. Our network takes as input a set of 2D point tracks (left) and uses several multi-head attention layers while alternating between the time dimension and the track dimension (middle). The network predicts cameras, per-frame 3D points, and per-world point movement value (right). The 3D point internal colors illustrate the predicted 3D movement level values, such that points with high/low 3D motion are presented in red/purple colors respectively. These outputs are used to reproject the predicted points into the frames for calculating the reprojection error losses. See details in the text. The reader is encouraged to watch the supplementary video visualizations.", "description": "This figure illustrates the TRACKSTO4D architecture, which takes 2D point tracks from casual dynamic videos as input and predicts 3D locations, camera motion, and per-point movement levels in a single feed-forward pass. The architecture uses multi-head attention layers to process the 2D point tracks, alternating between time and track dimensions. The output includes camera poses, per-frame 3D point clouds, and per-point movement values, which are used to calculate reprojection error losses.  The color-coding of the 3D points visually represents their predicted motion levels.", "section": "Method"}, {"figure_path": "bqGAheAeQY/figures/figures_3_1.jpg", "caption": "Figure 2: The symmetry structure of our problem. Frames (vertical) have time translation symmetry while points (horizontal) have set permutation symmetry.", "description": "This figure illustrates the symmetries present in the input data (point track tensors) for the TRACKSTO4D model.  The vertical axis represents frames in a video sequence, exhibiting temporal or time translation symmetry.  The horizontal axis represents points being tracked across the frames, exhibiting permutation symmetry, meaning the order of points does not affect the underlying relationships. These symmetries are central to the design of the TRACKSTO4D architecture, which is designed to process these inputs in an equivariant way, preserving these symmetries in the processing and improving generalization capabilities.", "section": "2.1 Equivariant layers for point track tensors"}, {"figure_path": "bqGAheAeQY/figures/figures_8_1.jpg", "caption": "Figure 1: We present TRACKSTO4D, a method for mapping a set of 2D point tracks extracted from casual dynamic videos into their corresponding 3D locations and camera motion. At inference time, our network predicts the dynamic structure and camera motion in a single feed-forward pass. Our network takes as input a set of 2D point tracks (left) and uses several multi-head attention layers while alternating between the time dimension and the track dimension (middle). The network predicts cameras, per-frame 3D points, and per-world point movement value (right). The 3D point internal colors illustrate the predicted 3D movement level values, such that points with high/low 3D motion are presented in red/purple colors respectively. These outputs are used to reproject the predicted points into the frames for calculating the reprojection error losses. See details in the text. The reader is encouraged to watch the supplementary video visualizations.", "description": "This figure illustrates the TRACKSTO4D architecture and workflow.  The input is a set of 2D point tracks from a video.  The network uses multi-head attention to process these tracks and predict 3D point cloud locations and camera poses in a single feedforward pass.  The output is visualized with the 3D points color-coded according to their predicted movement levels (red for high motion, purple for low motion).  The reprojection error is calculated by comparing the projected 3D points back onto the 2D frames with the original 2D tracks.", "section": "1 Introduction"}, {"figure_path": "bqGAheAeQY/figures/figures_8_2.jpg", "caption": "Figure 1: We present TRACKSTO4D, a method for mapping a set of 2D point tracks extracted from casual dynamic videos into their corresponding 3D locations and camera motion. At inference time, our network predicts the dynamic structure and camera motion in a single feed-forward pass. Our network takes as input a set of 2D point tracks (left) and uses several multi-head attention layers while alternating between the time dimension and the track dimension (middle). The network predicts cameras, per-frame 3D points, and per-world point movement value (right). The 3D point internal colors illustrate the predicted 3D movement level values, such that points with high/low 3D motion are presented in red/purple colors respectively. These outputs are used to reproject the predicted points into the frames for calculating the reprojection error losses. See details in the text. The reader is encouraged to watch the supplementary video visualizations.", "description": "This figure illustrates the TRACKSTO4D architecture and its workflow.  The input is a set of 2D point tracks extracted from a video. The architecture uses multi-head attention to process the tracks, alternating between time and track dimensions. The output is the reconstructed 3D point cloud, camera poses, and per-point movement levels. The colors of the 3D points represent their motion levels (red for high motion, purple for low). The reprojection error is calculated to evaluate the accuracy of the reconstruction.", "section": "2 Method"}]