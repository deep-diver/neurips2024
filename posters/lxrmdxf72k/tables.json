[{"figure_path": "LxRmdXf72k/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of causal and non-causal attentions for image classification on ImageNet-1K.", "description": "This table compares the top-1 accuracy on ImageNet-1K for various image classification models.  It contrasts causal models (indicated by a checkmark in the \"Causal\" column) against non-causal models.  The table includes details on model size (Size), number of parameters (#Param), and the achieved top-1 accuracy.  The results show a performance comparison between different model architectures, highlighting the performance of the proposed De-focus Attention Networks.", "section": "5 Experiments"}, {"figure_path": "LxRmdXf72k/tables/tables_7_1.jpg", "caption": "Table 2: Results of object detection on the COCO [36] dataset with DINO [72] detector.", "description": "This table presents the results of object detection experiments conducted on the COCO dataset using the DINO detector.  Different models, including ResNet-50, DeiT-Base, and De-focus Mamba-Base, are evaluated. The table shows the performance metrics (APbox, AP50, AP75) for each model trained for 12 and 36 epochs. The results demonstrate the superior performance of De-focus Mamba-Base compared to other models.", "section": "5.2 Main Results"}, {"figure_path": "LxRmdXf72k/tables/tables_7_2.jpg", "caption": "Table 3: Results on zero-shot image classification of CLIP pre-trained models.", "description": "This table presents the results of zero-shot image classification on the ImageNet dataset using various CLIP pre-trained models.  It compares the top-1 accuracy achieved by OpenAI CLIP, OpenCLIP, and the proposed De-focus Mamba model. The table highlights the performance of the De-focus Mamba model in comparison to existing state-of-the-art models, showcasing its competitive performance in zero-shot image classification.", "section": "5.2 Main Results"}, {"figure_path": "LxRmdXf72k/tables/tables_7_3.jpg", "caption": "Table 4: Results on image-text retrieval on the COCO [36] dataset of CLIP pre-trained models.", "description": "This table presents the results of image-text retrieval on the COCO dataset using CLIP pre-trained models.  It compares the performance of OpenAI CLIP-Base/32, OpenCLIP-Base/32, and the De-focus Mamba-Base/32 model across various recall metrics (@1, @5, @10) for both image retrieval and text retrieval.  The table shows that the De-focus model shows comparable performance to state-of-the-art non-causal models.", "section": "5.2 Main Results"}, {"figure_path": "LxRmdXf72k/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of causal and non-causal attentions for image classification on ImageNet-1K.", "description": "This table compares the top-1 accuracy of various causal and non-causal attention models on the ImageNet-1K dataset.  It shows the model size (#Param), the image resolution used (Size), and the resulting Top-1 accuracy.  The table includes both small and base versions of DeiT, Mamba, and Vision RWKV, along with the De-focus attention network proposed in the paper.  The results demonstrate the De-focus network's ability to achieve comparable or superior performance to 2D non-causal models.", "section": "5 Experiments"}, {"figure_path": "LxRmdXf72k/tables/tables_14_1.jpg", "caption": "Table 1: Comparison of causal and non-causal attentions for image classification on ImageNet-1K.", "description": "This table compares the top-1 accuracy of various causal and non-causal models on the ImageNet-1K dataset for image classification.  It shows the model name, whether it uses causal attention, the model size, the number of parameters, and the achieved top-1 accuracy.  The comparison highlights the performance of the proposed De-focus Attention Networks against existing causal and non-causal methods.", "section": "5 Experiments"}, {"figure_path": "LxRmdXf72k/tables/tables_17_1.jpg", "caption": "Table 1: Comparison of causal and non-causal attentions for image classification on ImageNet-1K.", "description": "This table compares the top-1 accuracy of various causal and non-causal models on the ImageNet-1K dataset.  It shows the impact of using causal attention mechanisms (with and without the proposed De-focus Attention Network) on model performance across different model sizes (small, base, large).  The results highlight the effectiveness of the proposed method in bridging the performance gap between 1D causal and 2D non-causal vision models.", "section": "5 Experiments"}, {"figure_path": "LxRmdXf72k/tables/tables_18_1.jpg", "caption": "Table 2: Results of object detection on the COCO [36] dataset with DINO [72] detector.", "description": "This table presents the results of object detection experiments conducted on the MS COCO dataset using the DINO detector.  Different models are compared based on their performance across various metrics (APbox, AP50, AP75, and AP) and with two different training durations (12 and 36 epochs). The models include ResNet-50, DeiT-Base, De-focus ViT-Base, and De-focus Mamba-Base.  The data shows how the De-focus models compare to standard models in object detection.", "section": "5.2 Main Results"}, {"figure_path": "LxRmdXf72k/tables/tables_18_2.jpg", "caption": "Table 1: Comparison of causal and non-causal attentions for image classification on ImageNet-1K.", "description": "This table compares the top-1 accuracy of various causal and non-causal attention models on the ImageNet-1K image classification benchmark.  It shows the model name, whether it uses causal attention, the model size, the number of parameters, and the achieved top-1 accuracy.  The results demonstrate the performance of the proposed De-focus Attention Networks in comparison to existing causal and non-causal models.", "section": "5 Experiments"}, {"figure_path": "LxRmdXf72k/tables/tables_18_3.jpg", "caption": "Table 1: Comparison of causal and non-causal attentions for image classification on ImageNet-1K.", "description": "This table compares the top-1 accuracy of various causal and non-causal vision models on the ImageNet-1K image classification benchmark.  It showcases the performance of different model sizes (small, base, large) including DeiT, Mamba, Vision Mamba, Vision RWKV and the proposed De-focus Attention Networks (applied to ViT, RetNet, and Mamba). The table highlights the impact of the proposed De-focus attention mechanism on improving the accuracy of 1D causal models, demonstrating their competitiveness against traditional 2D non-causal approaches.", "section": "5 Experiments"}, {"figure_path": "LxRmdXf72k/tables/tables_18_4.jpg", "caption": "Table 1: Comparison of causal and non-causal attentions for image classification on ImageNet-1K.", "description": "This table compares the top-1 accuracy of various causal and non-causal attention models on the ImageNet-1K dataset.  It shows the model size, number of parameters, and top-1 accuracy for each model.  The table highlights the performance of De-focus attention networks in comparison to other causal and non-causal models, demonstrating their improved accuracy.", "section": "5 Experiments"}]