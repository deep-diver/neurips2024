[{"type": "text", "text": "$\\mathbf{S}\\mathbf{T}_{k}$ : A Scalable Module for Solving Top-k Problems ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hanchen $\\mathbf{Xia^{\\dagger,*}}$ , Weidong Liu\u2020,\u2021, Xiaojun Mao\u2020,\u00a7 ", "page_idx": 0}, {"type": "text", "text": "{\u2020School of Mathematical Sciences, \u2021Ministry of Education Key Lab of Artificial Intelligence, \u00a7Ministry of Education Key Laboratory of Scientific and Engineering Computing} Shanghai Jiao Tong University, Shanghai, China \u2663RoyalFlush AI Research Institute, Hangzhou, China {x_hc_2000, weidongl, maoxj}@sjtu.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The cost of ranking becomes significant in the new stage of deep learning. We propose $S\\mathrm{T}_{k}$ , a fully differentiable module with a single trainable parameter, designed to solve the Top- $\\cdot\\mathbf{k}$ problem without requiring additional time or GPU memory. Due to its fully differentiable nature, $S\\mathrm{T}_{k}$ can be embedded end-to-end into neural networks and optimize the Top- $\\cdot\\mathbf{k}$ problems within a unified computational graph. We apply ${\\mathrm{ST}}_{k}$ to the Average Top- $\\cdot\\mathbf{k}$ Loss $(\\mathrm{AT}_{k})$ , which inherently faces a Top-k problem. The proposed $S\\mathrm{T}_{k}$ Loss outperforms $\\mathrm{AT}_{k}$ Loss and achieves the best average performance on multiple benchmarks, with the lowest standard deviation. With the assistance of $\\mathrm{ST}_{k}$ Loss, we surpass the state-of-the-art (SOTA) on both CIFAR-100-LT and Places-LT leaderboards. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The ranking problem is quite common in the field of AI. For imbalanced datasets, the Average Top- $\\cdot\\mathbf{k}$ $\\left(\\mathbf{A}\\mathbf{T}_{k}\\right)$ Loss is more suitable than the conventional Average Loss [Lyu et al., 2020]. In the context of ambiguous classification tasks, Top-k Learning allows the ground truth to fall within the largest $k$ probabilities, enhancing the model\u2019s generalizability [Lapin et al., 2017, Berrada et al., 2018, Petersen et al., 2022]. For language models, the Top-k sampling method helps the models select the top $k$ most probable words during text generation, producing more fluent and coherent sentences. Distributed learning systems employ Top- $\\cdot\\mathbf{k}$ sparsification with error compensation (Top-k SGD) to reduce communication traffic without noticeably impacting model accuracy [Chen et al., 2018, Lin et al., 2018, Shi et al., 2019]. However, as deep learning models continue to grow in size, the cost of the ranking process becomes increasingly significant. For example, on a single NVIDIA H800 GPU, tuning a Llama-8B model using the LoRA [Hu et al., 2022] method with a batch size of 4096 and 1000 iterations takes 990.14 seconds. In particular, performing QuickSort on the individual losses consumes 86.33 seconds. ", "page_idx": 0}, {"type": "text", "text": "In this work, we propose $\\mathrm{ST}_{k}$ (Smoothed Top- $\\cdot\\mathbf{k}$ ), a scalable module for Top- $\\cdot\\mathbf{k}$ problems. By adding only a single trainable parameter, $S\\mathrm{T}_{k}$ is able to solve the Top- $\\cdot\\mathbf{k}$ problem in $O(n+k)$ steps. Due to the fully differentiable nature of $\\mathrm{ST}_{k}$ , it can be embedded end-to-end as a layer. Experiments show that we can even add $\\lambda$ to the computational graph for unified optimization using Stochastic Gradient Descent (SGD), which means that we do not need to consider the time cost of solving the Top- $\\cdot\\mathbf{k}$ problems within the computational graph. However, we can still enjoy the performance improvements that Top- $\\cdot\\mathbf{k}$ optimization provides. The contributions of this work are summarized as follows: ", "page_idx": 0}, {"type": "text", "text": "\u2022 We propose a uniformly convergent approximation of the ReLU function.   \n\u2022 We propose an efficient and robust Smoothed Top- $\\cdot\\mathbf{k}$ module, ${\\mathrm{ST}}_{k}$ .   \n\u2022 We apply $S\\mathrm{T}_{k}$ Module to smooth $\\mathrm{AT}_{k}$ Loss, resulting in performance improvement and refreshing the state-of-the-art methods on two long-tailed learning leaderboards.   \n\u2022 We design an imbalanced classification dataset with a theoretical decision boundary. ", "page_idx": 1}, {"type": "text", "text": "For experiments, by applying the $\\mathrm{ST}_{k}$ Module, we smooth the $\\mathrm{AT}_{k}$ Loss into $\\mathrm{ST}_{k}$ Loss. The computation time of ${\\mathrm{ST}}_{k}$ Loss is almost identical to that of the average aggregating method, significantly faster than the sorting-required $\\mathrm{AT}_{k}$ Loss, and it exhibits the best performance. Experiments on synthetic datasets demonstrate that models trained with ${\\mathrm{ST}}_{k}$ Loss most closely approximate the theoretical decision boundary. On benchmarks of imbalanced binary classification, models trained by ${\\mathrm{ST}}_{k}$ Loss exhibit the lowest average misclassification rate and the lowest standard deviation. On regression datasets, models trained with ${\\mathrm{ST}}_{k}$ Loss exhibit the lowest (RMSE). Experiments on large real-world datasets demonstrate that ${\\mathrm{ST}}_{k}$ Loss, as an aggregating trick for individual losses, is a scalable technique that improves accuracy on long-tailed benchmarks. With the help of $S\\mathrm{T}_{k}$ Loss, we surpass the state-of-the-art (SOTA) on both the CIFAR-100-LT and Places-LT leaderboards. ", "page_idx": 1}, {"type": "text", "text": "1.1 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In current research, although there are many studies on individual loss, the general characteristics of aggregate loss are often overlooked. In the existing machine learning literature, a related line of work is the data subset selection problem [Wei et al., 2015], which aims to select a subset from a large training dataset for model training while minimizing average loss. Curriculum learning [Bengio et al., 2009] and self-paced [Kumar et al., 2010] learning are two recent learning schemes. They organized the training process into several iterative stages, gradually including training data from easy to difficult to learn, where the difficulty level is measured by individual loss. Therefore, each training session in these methods corresponds to the average aggregate loss in the selected subset. The difficulties encountered by the Average Loss when dealing with imbalanced data, as discussed in [Shalev-Shwartz and Wexler, 2016, Huang et al., 2020], prompted the exploration of more robust aggregate losses. Among these, Lyu et al. [2020] introduced the $\\mathrm{AT}_{k}$ loss, which averages the $k$ largest individual losses, and exhibits advanced performance on imbalanced datasets. ", "page_idx": 1}, {"type": "text", "text": "Many classification tasks in the real world have inherent label confusion, as mentioned in Berrada et al. [2018]. This confusion may arise from various factors, such as incorrect labels, incomplete annotations, or some fundamental ambiguities that even confuse the true labels for human experts. Therefore, some works proposed the concept of Top-k Learning in the field of image classification to address the issues of multiple semantics and semantic confusion in images [Lapin et al., 2017]. ", "page_idx": 1}, {"type": "text", "text": "Berrada et al. [2018] proposed a method to partially smooth the Top- $\\cdot\\mathbf{k}$ Learning loss function, but did nofo $C_{n}^{k}$ . mPpelteetresleyn s eotl vael.  t[h2e0 s2o2r]t ipnrgo pprooseblde am  Sipnl itth eS elloescst ifounn cNtieotnw aornkd  (iSntSroNd) ubcaesde da  soonr tsionrgti ncog mneptuwtaotrikosn, which made the Top- process differentiable and achieved the state of the art on ImageNet-1K at that time. However, the computation required by this method is cumbersome and multilayered. Sorting networks are similar to algorithms like QuickSort with time complexities of $\\mathcal{O}(n\\log\\bar{n})$ . ", "page_idx": 1}, {"type": "text", "text": "1.2 Notational Conventions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Let $\\mathbb{N}^{n}$ denotes the set $\\{1,...,n\\}$ and $\\mathbb{I}_{\\{a\\}}$ denotes the indicator function (which is 1 when the proposition $a$ is true and 0 otherwise). Thus, the sign function can be defined as: $s i g n(x)\\;=\\;$ $\\mathbb{I}_{\\{x>0\\}}-\\mathbb{I}_{\\{x<0\\}}$ . The Hinge function can be defined as: $[x]_{+}=\\operatorname*{max}\\left\\{0,x\\right\\}$ . We use $\\|\\boldsymbol{x}\\|_{1},\\|\\boldsymbol{x}\\|_{2}$ , and $\\|x\\|_{\\infty}$ to represent the $\\ell_{1},\\,\\ell_{2}$ , and $\\ell_{\\infty}$ norms of $x$ , respectively. For the set $L=\\ell_{1},\\ell_{2},...,\\ell_{n}$ , $\\ell_{[k]}$ denotes the $k$ -th largest element, so we have $\\ell_{[1]}\\,\\geq\\,\\ell_{[2]}\\,\\geq\\,\\ldots\\,\\geq\\,\\ell_{[n]}$ . In supervised learning problems, our training set typically contains an input set and a target set, the input set coming from the input domain $\\mathcal{X}$ , and the target set from the target domain $\\boldsymbol{\\wp}$ , and we use their joint domain $\\mathcal{Z}=\\mathcal{X}\\times\\mathcal{Y}$ to represent the range of the dataset. The training set $S\\,=\\,z_{1},z_{2},...,z_{n}$ is a subset of $\\mathcal{Z}$ , where $z_{i}=(x_{i},y_{i})$ . Our task is to find a predictor $f:\\mathcal{X}\\to\\mathcal{Y}$ from the function family $\\mathcal{H}$ that can predict the corresponding target $y$ based on the new input $x$ . To evaluate the effect of the predictor, we need to introduce an individual loss function $\\ell:\\mathcal{Y}\\times\\mathcal{Y}\\rightarrow\\mathbb{R}^{+}$ , where $\\ell=\\ell(f(x),y)$ usually reflects some distance between the prediction ${\\hat{y}}=f(x)$ and the true value $y$ . The training process of the predictor can be described as using the gradient descent algorithm to optimize an objective function (usually minimizing the loss function). The objective function can generally be written as $\\mathcal{L}(f,S)+\\Omega(f)$ , where $\\mathcal{L}(f,S)$ is the aggregated individual loss function, and $\\Omega(f)$ is a regularization term ( $\\ell_{1}$ or $\\ell_{2}$ regularization term). The loss function ${\\mathcal{L}}(f,S)$ is usually Average Loss, that is, $\\begin{array}{r}{\\mathcal{L}_{a v g}(f,S)=\\frac{1}{n}\\sum_{i=1}^{n}\\bar{\\ell}(f(x_{i}),y_{i})}\\end{array}$ . However, recent works, have shown some drawbacks of the average loss in adapting to imbalanced data distributions [Shalev-Shwartz and Wexler, 2016], and explored choices other than the average loss for the aggregate loss formed from individual losses, e.g., the maximum (aggregate) loss, $\\begin{array}{r}{\\bar{\\mathcal{L}_{m a x}}(f,S)=\\operatorname*{max}_{i\\in\\mathbb{N}_{n}}\\ell(f(x_{i}),y_{i})}\\end{array}$ . ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2 $\\mathbf{S}\\mathbf{T}_{k}$ Architecture ", "text_level": 1, "page_idx": 2}, {"type": "image", "img_path": "OdJKB9jSa5/tmp/f7d1f699a257c0ac634f0e86e920650da25e569dba845d046c349272952d3b19.jpg", "img_caption": [], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Figure 1: $S\\mathrm{T}_{k}$ Architecture. For any layer of neurons in a neural network, to solve the Top- $\\cdot\\mathbf{k}$ problem for its weights, insert an $S\\mathrm{T}_{k}$ Module. The trainable parameter $\\lambda$ will gradually approximate the $k$ -th largest element during the optimization process. And this $\\lambda$ can be used to filter neurons. ", "page_idx": 2}, {"type": "text", "text": "Suppose we have a set of elements $\\{e_{i}\\}_{i=1}^{n}$ , then the Top- $\\cdot\\mathbf{k}$ problem can be describe as: ", "page_idx": 2}, {"type": "text", "text": "1. find the $k$ -th largest element $\\boldsymbol{e}_{[k]}$ ; ", "page_idx": 2}, {"type": "text", "text": "2. find the sum of top- $\\cdot\\mathbf{k}$ largest elements $\\textstyle\\sum_{i=1}^{k}e_{[k]}$ . ", "page_idx": 2}, {"type": "text", "text": "This process can certainly be achieved through conventional sorting and summation. However, in the worst-case scenario, the cost of solving the Top- $\\cdot\\mathbf{k}$ problem can reach $O(n^{2})$ . Ogryczak and Tamir [2003] proposed an equivalent optimization form to solve the Top- $\\cdot\\mathbf{k}$ problem and proved its linear convergence. ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}e_{[k]}=\\operatorname*{min}_{\\lambda\\geq0}\\left\\{\\sum_{i=1}^{n}\\left[e_{i}-\\lambda\\right]_{+}+k\\lambda\\right\\},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "However, this surrogate objective function suffers from a non-differentiable point at $e_{i}=\\lambda$ , which makes it challenging to optimize. The key to solving this problem lies in designing a function approximating $[\\cdot{\\bar{\\ }}_{+}$ , which can be regarded as a rectified linear unit (ReLU) function. Here, we introduce the Smoothed ReLU (SReLU). ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{SReLU(x)}=\\frac{1}{2}\\left[x+\\delta\\left(\\sqrt{\\frac{x^{2}}{\\delta^{2}}+1}-1\\right)\\right],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\delta$ is a hyperparameter (usually we set $\\delta=0.01$ ). It can be observed from Figure 2 that as $\\delta$ decreases, SReLU increasingly approximates the ReLU function. In fact, SReLU converges uniformly to ReLU as $\\delta\\rightarrow0^{+}$ ; a detailed proof of this uniform convergence is provided in Proposition 1 of Appendix A.1. With the help of SReLU, the objective function (1) can be smoothed as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{k}e_{[k]}\\approx\\operatorname*{min}_{\\lambda\\geq0}\\Biggl\\{\\frac{1}{2}\\sum_{i=1}^{n}\\left[(e_{i}-\\lambda)+\\delta\\left(\\sqrt{\\frac{(e_{i}-\\lambda)^{2}}{\\delta^{2}}+1}-1\\right)\\right]+k\\lambda\\Biggr\\},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "the optimal $\\lambda^{*}=e_{[k]}$ which is the $k$ -th largest element. In the following section, we will introduce an application scenario for $S\\mathrm{T}_{k}$ . ", "page_idx": 2}, {"type": "image", "img_path": "OdJKB9jSa5/tmp/76238dfaac909b66d6a6399514aa7644cc5b2a4a7ec6c4502090bb2d790a13bc.jpg", "img_caption": ["Figure 2: ReLU and SReLU with various smoothing coefficients $\\delta$ . "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "3 From $\\mathbf{A}\\mathbf{T}_{k}$ Loss to $\\mathbf{S}\\mathbf{T}_{k}$ Loss ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In the training process of a neural network, we first choose a form of individual loss (e.g., logistic loss, hinge loss, mean square loss, or cross-entropy loss). Then, we aggregate all individual losses to calculate their average, which is the most common aggregate loss function: Average Loss. The Average Loss is widely used in a myriad of deep learning tasks. This widespread application stems from the robust theoretical foundations [Bartlett et al., 2006, De Vito et al., 2005]. However, Average Loss tends to overfti the training data, especially on imbalanced datasets [Shalev-Shwartz and Wexler, 2016, Huang et al., 2020]. This has inspired the motivation to find other forms of aggregate loss, such as the maximum value among individual losses (referred to as Maximum Loss). The Average Top- $\\cdot\\mathbf{k}$ $(\\mathrm{AT}_{k})$ ) Loss was introduced by Lyu et al. [2020]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{a t-k}=\\frac{1}{k}\\sum_{i=1}^{k}\\ell_{[k]},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which represents the average of the largest $k$ individual losses. According to the derivation in [Ogryczak and Tamir, 2003], this ranking loss can be written in the following equivalent form: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{m a t-k}=\\frac{1}{n}\\sum_{i=1}^{n}\\left[\\ell_{i}-\\lambda\\right]_{+}+\\frac{k}{n}\\lambda.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "With the help of the $S\\mathrm{T}_{k}$ Module, $\\mathcal{L}_{m a t-k}(f,S)$ can be reconstructed as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{s t-k}=\\frac{1}{2n}\\sum_{i=1}^{n}\\left[(\\ell_{i}-\\lambda)+\\delta\\left(\\sqrt{\\frac{(\\ell_{i}-\\lambda)^{2}}{\\delta^{2}}+1}-1\\right)\\right]+\\frac{k}{n}\\lambda,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\ell_{i}\\,=\\,\\ell(f_{w_{\\mathrm{model}}}(x_{i}),y_{i})$ is the individual loss of sample $i$ , and $w_{\\mathrm{model}}$ represents the set of parameters of the predictor $f$ . It is easy to verify that $\\begin{array}{r}{\\operatorname*{lim}_{\\delta\\rightarrow0^{+}}\\mathcal{L}_{s t-k}=\\mathcal{L}_{m a t-k}}\\end{array}$ , given Proposition ", "page_idx": 3}, {"type": "text", "text": "1 in Appendix A.1. ", "page_idx": 4}, {"type": "image", "img_path": "OdJKB9jSa5/tmp/71c9913492cba5cbc023cfdfbdffcca1a56af100585641c83540f1e9c037179d.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "The approximation error between the smoothed loss function and the original loss function can be uniformly bounded by $\\delta/2,\\forall\\ell$ . ", "page_idx": 4}, {"type": "text", "text": "When $\\ell$ is convex, Equation (6) exhibits joint convexity with respect to the parameters $\\left(w_{\\mathrm{model}},\\lambda\\right)$ , making the problem a special case of the non-linear multiple choice knapsack problem [Zemel, 1984], which has at most $q=2$ roots. These roots can be found in constant time, allowing the problem to be solved in $\\mathcal{O}(n\\cdot\\ln q)=\\mathcal{O}(n)$ time when $q$ is fixed [Megiddo, 1984]. Therefore, it can be iteratively updated using relatively simple algorithms. For example, in the case of batch learning, the block coordinate descent (BCD) method [Nocedal and Wright, 1999] can be employed, where $w_{\\mathrm{model}}$ and $\\lambda$ are updated alternately after initialization. ", "page_idx": 4}, {"type": "text", "text": "BCD- $S\\mathrm{T}_{k}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\lambda^{(t+1)}\\gets\\underset{\\lambda}{\\mathrm{argmin}}\\,\\mathcal{L}_{s t-k};}\\\\ {w^{(t+1)}\\gets\\underset{w}{\\mathrm{argmin}}\\,\\mathcal{L}_{s t-k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The convergence of the above coordinate descent algorithms can be found in Luo and Tseng [1992], Saha and Tewari [2013], Tseng [2001]. ", "page_idx": 4}, {"type": "text", "text": "Furthermore, empirical evidence suggests that we do not need to spend extra time optimizing $\\lambda$ separately, incorporating $\\lambda$ into the computational graph of $w_{\\mathrm{model}}$ for unified optimization using Stochastic Gradient Descent (SGD) [Bottou and Bousquet, 2008, Shamir, 2011, Srebro and Tewari, 2010], performance improvements can still be achieved. ", "page_idx": 4}, {"type": "text", "text": "$\\mathrm{SGD-ST}_{k}$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\lambda^{(t+1)}\\leftarrow\\lambda^{(t)}-\\eta\\cdot\\partial_{\\lambda}\\mathcal{L}_{s t-k};}\\\\ &{w^{(t+1)}\\leftarrow w^{(t)}-\\eta\\cdot\\nabla_{w}\\mathcal{L}_{s t-k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\eta_{t}$ is the size of the update step, and when $\\begin{array}{r}{\\eta_{t}\\sim\\frac{1}{\\sqrt{t^{\\prime}}}}\\end{array}$ \u221a1t\u2032 , the stochastic gradient descent method can ensure convergence to a local minimum of Equation (6) [Shamir, 2011, Srebro and Tewari, 2010]. By eliminating points where the gradients are discontinuous, the training process becomes more stable, and converges faster, as experimentally demonstrated by the standard deviations reported in Tables 3, 4, and 9, and the time cost reported in Table 2. ", "page_idx": 4}, {"type": "text", "text": "4 Synthetic Experiments ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "4.1 Time Cost ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We first perform experiments to compare the time costs of two standard sorting algorithms, $\\mathrm{AT}_{k}$ , and ${\\mathrm{ST}}_{k}$ , in calculating the ranking average. The experimental setup involves finding the Top- $\\cdot\\mathbf{k}$ $(\\mathrm{k}{=}5)$ sum from 10,000 standard normally distributed samples. For both $\\mathrm{AT}_{k}$ and $S\\mathrm{T}_{k}$ , we iterate until the error is less than $10^{-2}$ . For each algorithm, we run 50 experiments and record the average time taken. ", "page_idx": 4}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/4e7053e8eed2f05494a93fc1fdd602568b8737f3071dda82a033b74a0bdf25c5.jpg", "table_caption": ["Table 1: Performance comparison of different sorting algorithms and our method. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "As shown in Table 1, ${\\mathrm{ST}}_{k}$ indeed demonstrates linear time complexity while also exhibiting a stable optimization process. ", "page_idx": 5}, {"type": "text", "text": "4.2 Gaussian Distributed Dataset ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To illustrate the capability of $S\\mathrm{T}_{k}$ Loss in approximating the ideal decision boundary, we design a Gaussian-distributed dataset. The dataset is generated by a pre-set covariance matrix $\\dot{\\Sigma}\\in\\mathbb{R}^{d\\times d}$ , and mean vectors $\\pmb{\\mu}_{1},\\pmb{\\mu}_{2}\\in\\mathbb{R}^{d}$ corresponding to two categories. We set $d=200$ , $\\Sigma_{j k}=0.25^{0.5+|j-k|}$ , $\\pmb{\\mu}_{1}=\\mathbf{0}_{d}$ and $\\pmb{\\mu}_{2}=(1,1,...,1,0,0,...,0)^{\\top}$ , which has 10 ones. For the predictor, we use a Logistic Regression (LR) model $f(\\pmb{x})=\\mathrm{sigmoid}(\\pmb{\\omega}^{\\top}\\pmb{x}+b)$ . The detailed derivation process of the decision boundary can be found in the Appendix A.2. Here, we present the conclusion directly. For two normal populations with a given covariance matrix $\\Sigma$ , and means $\\pmb{\\mu}_{1}$ and $\\pmb{\\mu}_{2}$ , the LR model has a theoretical decision boundary: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\omega^{*}=(\\mu_{1}-\\mu_{0})^{\\top}\\Sigma^{-1};\\ \\ b^{*}=\\frac{1}{2}\\Biggl[\\mu_{0}^{\\top}\\Sigma^{-1}\\mu_{0}+\\mu_{1}^{\\top}\\Sigma^{-1}\\mu_{1}\\Biggr]+\\ln\\left[\\frac{\\mathrm{Pr}(Y=1)}{\\mathrm{Pr}(Y=0)}\\right].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Figure 3 provide an example on 2D plane, we set $\\pmb{\\Sigma}_{(j,k)}=0.8^{|j-k|},\\pmb{\\mu}_{1}=[0,0]^{\\top},\\pmb{\\mu}_{2}=[2,2]^{\\top}$ , thus according to our derivation above, $\\pmb{\\omega}^{*}=[1.111,1.111]^{\\top},b^{*}=-0.836$ , where the black dashed line is the theoretical boundary. ", "page_idx": 5}, {"type": "text", "text": "We use $\\mathrm{ParaF_{1}}$ [Tian and Gu, 2017] to measure the overlap of estimated supports and true supports: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathrm{ParaF_{1}}=2\\cdot{\\frac{\\mathrm{precision\\cdotrecall}}{\\mathrm{precision}+\\mathrm{recall}}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\begin{array}{r}{\\mathrm{recall}\\,=\\,\\frac{|\\mathrm{support}(\\hat{\\omega})\\cap\\mathrm{support}(\\omega^{*})|}{|\\mathrm{support}(\\omega^{*})|}}\\end{array}$ , where $\\hat{\\omega}$ is the estimated value of the parameters obtained by the predictor, and $\\omega^{*}$ is the theoretical value of the parameters mentioned above. The operator $|\\cdot|$ is used to find the cardinality of the set, which is the number of elements, and support(\u00b7) is the support set of the vector, which refers to the set of indices of its non-zero elements. ", "page_idx": 5}, {"type": "text", "text": "Other basic settings are as follows. The loss function we use is the binary cross-entropy loss. To obtain a sparse solution, we add an $\\ell_{1}$ regularization term. The number of samples is 10,000 for the training set and 2,500 each for the validation set and the test set. We implement early stopping of the iteration based on the accuracy ", "page_idx": 5}, {"type": "image", "img_path": "OdJKB9jSa5/tmp/7f9396a7ed942f779269aa58d9286b8e9b9c8bd5f2d74c88331ce2c55a5d370b.jpg", "img_caption": ["Figure 3: A Synthetic Example on 2D-Plain. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "curve in the validation set; that is, we break when the increase in validation accuracy within 200 steps is less than $10^{-4}$ . For each meta-experiment, we repeat it 50 times and take the average. Now we conduct two groups of experiments as follows. ", "page_idx": 5}, {"type": "text", "text": "Aggregate Losses and ReLU Varients. In these experiments, we set the ratio of positive to negative samples at 8:2 for the training set, while the validation set and the test set remain 1:1. We also compare SReLU with other variants of ReLU. The smoothing coefficient for SReLU is set to 0.01, and the settings for the other ReLU variants remain at their defaults. We use Adam as our optimizer, setting the batch size to 512, while keeping the other hyperparameters as default. According to Equation (8), we could compute the theoretical value of $\\omega^{*}$ , which is a vector with only the first 10 elements non-zero. Sensitive Analysis. In these experiments, we only adjust the positive-negative ratio and retain the rest of the settings from the previous experiment. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/8d68f4f3bbe95386c200969dd58ba04034b5b76e435bb2b4c8b97db24288b7ff.jpg", "table_caption": ["Table 2: Accuracy and ParaF $^1$ -Score on the synthetic dataset. "], "table_footnote": [], "page_idx": 6}, {"type": "image", "img_path": "OdJKB9jSa5/tmp/71c4680ba5381e91fef6fecdad05f9041c07b4f4a64e43b469a45702de93294e.jpg", "img_caption": ["Figure 4: Accuracy and ParaF $^1$ -Score vs Negative Sample Ratio. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "Table 2 presents the Accuracy and $\\mathrm{ParaF_{1}}$ score achieved when different aggregate loss functions are combined with the LR model and the cross-entropy loss, trained to convergence. With the help of SReLU, $\\mathrm{ST}_{k}$ Loss achieves performance that surpasses that of all other aggregate losses. Due to its property of being a real uniformly convergent approximation (not just similar in shape), SReLU outperforms other ReLU variants in this scenario. Figure 4 shows the relationship between accuracy, ParaF $^1$ -score, and negative sample ratio (negative ratio). $\\mathrm{ST}_{k}$ is less sensitive to the imbalance ratio, ", "page_idx": 6}, {"type": "text", "text": "5 Real World Applications ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1 Binary Classification ", "text_level": 1, "page_idx": 6}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/6e5734562dbdc92243faa9950761eec5b02569df4ca8813e2216263c87c57e24.jpg", "table_caption": ["We select binary classification datasets from the KEEL2 and $\\mathrm{UCI}^{3}$ databases; see Table 9. "], "table_footnote": ["Table 3: Misclassification Rate $\\%)$ and Standard Derivation of Various Aggregate Losses Combined with Individual Logistic Loss. "], "page_idx": 6}, {"type": "text", "text": "Next, we tested the performance of different forms of aggregate loss on binary classification benchmarks. The individual loss function can generally be chosen as Logistic or Hinge, which are defined ", "page_idx": 6}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/f675c7a3694d0d3968876b0ebe62618f7262fab82b7e793a9b1864b2fa3d3393.jpg", "table_caption": [], "table_footnote": ["Table 4: Misclassification Rate $\\%)$ ) and Standard Derivation of Various Aggregate Losses Combined with Individual Hinge Loss. "], "page_idx": 7}, {"type": "text", "text": "as follows: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Logistic:~}\\ell(f(x),y)=\\log(1+\\exp(-y f(x)));}\\\\ &{\\mathrm{Hinge:~}\\ell(f(x),y)=[1-y f(x)]_{+}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The prediction model is a two-layer MLP with 10 nodes in the hidden layer, activated by the ReLU function between the two fully connected layers. To increase the stability of the training process, we added an $\\ell_{2}$ regularization term to the loss function $\\begin{array}{r}{\\Omega(w)=\\frac{1}{2C}\\lVert w\\rVert_{2}^{2}}\\end{array}$ . We divided the datasets into training, validation, and test sets in a $0.5:0.25:0.25$ ratio. Nowadays, SGD is generally replaced by the mini-batch method instead of stochastic gradient descent with a single sample point, which is faster and more robust. To accommodate datasets of varying sizes in the article, we set the batch size to 16. ", "page_idx": 7}, {"type": "text", "text": "The hyperparameters in the experiment include $k$ in $\\mathbf{MAT}_{k}$ and $\\mathrm{AT}_{k}$ , the coefficient of the regularization term $C$ , the initial learning rate $\\eta$ , and the smoothing coefficient $\\delta$ . These hyperparameters will be selected based on their convergence accuracy performance on the validation set (for each combination of hyperparameters, we repeat the experiment fifty times and take the average of their prediction accuracy on the validation set as the basis for parameter selection). The search spaces for several hyperparameters are as follows: $k\\in\\{1\\}\\cup[0.1:\\bar{0}.1:1]$ ; $C\\in\\{10^{0},10^{1},10^{2},10^{3},\\dot{10}^{4},10^{5}\\}$ ; $\\eta\\in\\{0.1,\\bar{0}.0\\bar{5},0,01,0.005,0.001\\}$ ; $\\delta\\in\\{0.1,0.01,0.001,0.0001\\}$ . ", "page_idx": 7}, {"type": "text", "text": "Since traditional gradient descent is too sensitive to the choice of step size, which is not conducive to our pure comparison of the convergence speed and accuracy of the loss function, we use the AdaGrad algorithm to iteratively update the learning rate. During the learning process, to avoid overfitting the model, we record the accuracy of the MLP predictor on the validation set after each iteration, and perform an early stop when the accuracy does not increase (the increase in the accuracy of the predictor on the validation set is less than $1\\dot{0}^{-6}$ after 50 steps) and roll back the model to the checkpoint with the highest accuracy on the validation set during the entire training process; otherwise, we continue training until convergence. Tables 3 and 4, respectively, show the average probability of misclassification $(\\%)$ of the models trained to convergence in 50 experiments in the test set under individual Logistic and Hinge loss (the standard deviation of the 50 experiments is listed in parentheses). ", "page_idx": 7}, {"type": "text", "text": "In the results shown in Tables 3 and 4. Almost all the lowest misclassification rates appear in the $S\\mathrm{T}_{k}$ trained models. Furthermore, models trained with ${\\mathrm{ST}}_{k}$ Loss exhibit the lowest standard deviation, which to some extent demonstrates the robustness of the training process. ", "page_idx": 7}, {"type": "text", "text": "5.2 Long-Tailed Classification ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The interest in long-tailed classification tasks has increased with the advent of large vision-language models such as contrastive language-image pre-training (CLIP) Radford et al. [2021]. Long-tailed versions of recognized datasets were built by the community. Using the Pareto distribution $(\\alpha=6)$ ), the ImageNet-1K and Places datasets can be sampled to create ImageNet-LT and Places-LT datasets, as described in [Liu et al., 2019]. Consider two types of imbalance [Cui et al., 2019, Buda et al., 2018], Cao et al. [2019] built CIFAR-10-LT ( $\\rho=10)$ ) and CIFAR-100-LT $\\zeta=100)$ , where $\\rho=$ $\\operatorname*{max}_{i}\\{n_{i}\\}/\\operatorname*{min}_{i}\\{n_{i}\\}$ represents the imbalance ratio, defined as the ratio between the sample sizes of the most frequent and least frequent class. Due to varying word frequencies, machine translation, or more generally, text generating, can inherently be considered as long-tailed classification tasks. We choose the WMT $2017^{4}$ and IWSLT $2014^{5}$ datasets for the experiments. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "image", "img_path": "OdJKB9jSa5/tmp/9ce98671617f3355279d89800295ae5ae24e48a44264936366b317455e8c7523.jpg", "img_caption": ["Figure 5: ImageNet-LT. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Settings For visual classification tasks, we use Parameter-Efficient Long-Tailed (PEL) Recognition [Shi et al., 2023], which primarily leverages information from a text encoder to adjust classification probabilities. The text encoder in PEL is derived from the pre-trained CLIP model, and the backbone is a Vision Transformer (ViT-Base) [Dosovitskiy et al., 2021] pre-trained in ImageNet-21K. We freeze the backbone and train the branch model of Parameter Efficient Fine-Tuning (PEFT) [Jia et al., 2022, Hu et al., 2022, Houlsby et al., 2019]. We simply replaced the Average aggregation of individual losses in the Logit Adjust (LA) [Menon et al., 2021] loss with $\\mathrm{AT}_{k}$ or ${\\mathrm{ST}}_{k}$ . For $k$ , we set it at $0.9\\;\\times$ batch size, and $\\delta=0.01$ . Then we report the accuracy of the balanced test sets. Visual classification experiments can be implemented on a single L20 GPU, with varying durations ranging from 20 to 200 minutes. ", "page_idx": 8}, {"type": "text", "text": "For translation tasks, we use the training workflows provided by OpenNMT6 [Klein et al., 2018] and FAIR-Seq7 [Ott et al., 2019], which are very easy to reproduce. Models are essentially different sizes of Transformers (see the footnotes). In the training process of language models, the actual batch size, calculated as the sequence length multiplied by the number of sequences, is often dynamic. Consequently, we set $k/$ batch size $=0.96$ . We simply replaced the Average aggregation of individual losses in the Cross Entropy (CE) loss with $\\mathrm{AT}_{k}$ or $\\mathrm{ST}_{k}$ . We calculate the bilingual evaluation understudy (BLEU) scores for the models. The BLEU for IWSLT2014-trained models are derived from their test set, while for the WMT2017-trained models, we evaluate their BLEU on the Newstest2016 test set. Training these Transformer-based models would take about 10 hours on a single RTX 4090. ", "page_idx": 8}, {"type": "text", "text": "Overall Results ${\\mathrm{ST}}_{k}$ Loss, as an aggregating trick for individual losses, is a scalable technique that improves accuracy on long-tailed benchmarks. The models trained by ${\\mathrm{ST}}_{k}$ Loss surpass SOTA on the CIFAR-100-LT and Places-LT leaderboards. ", "page_idx": 8}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/f62b89435b5dd7c35e202dd24739099ce8a5f4357d8293b141781cb2241eb964.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Table 5: Results on large long-tailed datasets are presented, where the first three columns indicate accuracy, and the last two columns show the BLEU scores. Values marked with an \u201c\\*\u201d represent the state-of-the-art (SOTA) on the leaderboard. ", "page_idx": 9}, {"type": "text", "text": "5.3 Regression Tasks ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "For descriptions of the four regression datasets, see Table 9. In regression tasks, the individual loss is generally the distance ( $\\ell_{1}$ or $\\ell_{2}$ distance) between the predicted value and the ground truth. Next, we present the specific settings of the experiment. For the Housing, Abalone, and Cpusmall datasets, we normalize the output to between $[0,1]$ ; for the Sinc dataset, we first randomly sample 1000 points $(x_{i},y_{i})$ from the function, where $x_{i}\\in[-10,10]$ , then we use the Radial Basis Function (RBF) kernel to map $x_{i}$ into the kernel space. We select 10 RBF kernels, resulting in a 10-dimensional input $\\boldsymbol{x}=[\\bar{k}(x,c_{1}),...,k(x,c_{10})]$ , where $k(x,c_{j})=\\exp(-(x-c_{j})^{2})$ . Furthermore, we add Gaussian noise $\\mathcal{N}(0,0.2^{2})$ to the target output $y$ . ", "page_idx": 9}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/eec4e80f0126566ad5ddb8e70e580e0c5d568621b106189492d7429695962b59.jpg", "table_caption": [], "table_footnote": ["Table 6: Comparison of Average RMSE and Standard Deviation for Different Aggregate Losses Combined with Square and Absolute Loss. "], "page_idx": 9}, {"type": "text", "text": "For individual losses, we choose the absolute value loss $(\\ell_{1})$ and the squared loss $(\\ell_{2})$ . The prediction model is the same as above, a two-layer MLP with 10 nodes in the hidden layer, activated by the ReLU function between the two fully connected layers. As in binary classification experiments, we randomly divide the dataset into training, validation, and test sets, with hyperparameters chosen based on the performance in the validation set, repeated 50 times, and statistics on the test set are reported. ", "page_idx": 9}, {"type": "text", "text": "Tables 6 show the average RMSE and standard deviation of 50 experiments in regression datasets with different aggregate losses combined with absolute individual loss and squared individual loss (given the experience of the previous experiment, we no longer compare with Maximum Loss here), and $S\\mathrm{T}_{k}$ shows further performance improvement after smoothing. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Limitation ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The proposed ${\\mathrm{ST}}_{k}$ Module can effectively solve the Top- $\\cdot\\mathbf{k}$ problem within neural networks, with no additional GPU memory or ranking time. Due to its fully differentiable nature, the training process are stable. By applying $S\\mathrm{T}_{k}$ Module to the Average Top-k Loss, we achieve significant improvements across numerous benchmarks. ", "page_idx": 9}, {"type": "text", "text": "The limitation of this study is that we have not yet evaluated the ${\\mathrm{ST}}_{k}$ Module for additional application scenarios. The effectiveness of the ${\\mathrm{ST}}_{k}$ Module is only demonstrated in smoothing $\\mathrm{AT}_{k}$ loss. We hope that future research will further explore the potential utility of the ${\\mathrm{ST}}_{k}$ Module. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Siwei Lyu, Yanbo Fan, Yiming Ying, and Bao-Gang Hu. Average top- $\\cdot\\mathbf{k}$ aggregate loss for supervised learning. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(1):76\u201386, 2020. ", "page_idx": 9}, {"type": "text", "text": "Maksim Lapin, Matthias Hein, and Bernt Schiele. Analysis and optimization of loss functions for multiclass, top-k, and multilabel classification. IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(7):1533\u20131554, 2017.   \nLeonard Berrada, Andrew Zisserman, and M. Pawan Kumar. Smooth loss functions for deep top- $\\cdot\\mathbf{k}$ classification. In International Conference on Learning Representations, 2018.   \nFelix Petersen, Hilde Kuehne, Christian Borgelt, and Oliver Deussen. Differentiable top-k classification learning. In International Conference on Machine Learning, pages 17656\u201317668. PMLR, 2022.   \nChia-Yu Chen, Jungwook Choi, Daniel Brand, Ankur Agrawal, Wei Zhang, and Kailash Gopalakrishnan. Adacomp: Adaptive residual gradient compression for data-parallel distributed training. In Proceedings of the AAAI conference on artificial intelligence, volume 32, 2018.   \nYujun Lin, Song Han, Huizi Mao, Yu Wang, and Bill Dally. Deep gradient compression: Reducing the communication bandwidth for distributed training. In International Conference on Learning Representations, 2018.   \nShaohuai Shi, Xiaowen Chu, Ka Chun Cheung, and Simon See. Understanding top-k sparsification in distributed deep learning. arXiv preprint arXiv:1911.08772, 2019.   \nEdward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. In International Conference on Learning Representations, 2022.   \nKai Wei, Rishabh Iyer, and Jeff Bilmes. Submodularity in data subset selection and active learning. In International Conference on Machine Learning, pages 1954\u20131963. PMLR, 2015.   \nYoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Jason Weston. Curriculum learning. In Proceedings of the 26th annual International Conference on Machine Learning, pages 41\u201348, 2009.   \nM Kumar, Benjamin Packer, and Daphne Koller. Self-paced learning for latent variable models. Advances in Neural Information Processing Systems, 23, 2010.   \nShai Shalev-Shwartz and Yonatan Wexler. Minimizing the maximal loss: How and why. In International Conference on Machine Learning, pages 793\u2013801. PMLR, 2016.   \nLang Huang, Chao Zhang, and Hongyang Zhang. Self-adaptive training: beyond empirical risk minimization. Advances in Neural Information Processing Systems, 33:19365\u201319376, 2020.   \nWlodzimierz Ogryczak and Arie Tamir. Minimizing the sum of the k largest functions in linear time. Information Processing Letters, 85(3):117\u2013122, 2003.   \nPeter L Bartlett, Michael I Jordan, and Jon D McAuliffe. Convexity, classification, and risk bounds. Journal of the American Statistical Association, 101(473):138\u2013156, 2006.   \nErnesto De Vito, Andrea Caponnetto, and Lorenzo Rosasco. Model selection for regularized leastsquares algorithm in learning theory. Foundations of Computational Mathematics, 5:59\u201385, 2005.   \nEitan Zemel. An o (n) algorithm for the linear multiple choice knapsack problem and related problems. Information Processing Letters, 18(3):123\u2013128, 1984.   \nNimrod Megiddo. Linear programming in linear time when the dimension is fixed. Journal of the ACM (JACM), 31(1):114\u2013127, 1984.   \nJorge Nocedal and Stephen J Wright. Numerical optimization. Springer, 1999.   \nZhi-Quan Luo and Paul Tseng. On the convergence of the coordinate descent method for convex differentiable minimization. Journal of Optimization Theory and Applications, 72(1):7\u201335, 1992.   \nAnkan Saha and Ambuj Tewari. On the nonasymptotic convergence of cyclic coordinate descent methods. SIAM Journal on Optimization, 23(1):576\u2013601, 2013.   \nPaul Tseng. Convergence of a block coordinate descent method for nondifferentiable minimization. Journal of Optimization Theory and Applications, 109(3):475, 2001.   \nL Bottou and O Bousquet. The tradeoffs of large scale learning, advances in neural information processing systems, 20, 2008.   \nOhad Shamir. Making gradient descent optimal for strongly convex stochastic optimization. CoRR, abs/1109.5647, 2011.   \nNathan Srebro and Ambuj Tewari. Stochastic optimization for machine learning. ICML Tutorial, 2010.   \nLu Tian and Quanquan Gu. Communication-efficient distributed sparse linear discriminant analysis. In Artificial Intelligence and Statistics, pages 1178\u20131187. PMLR, 2017.   \nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International Conference on Machine Learning, pages 8748\u20138763. PMLR, 2021.   \nZiwei Liu, Zhongqi Miao, Xiaohang Zhan, Jiayun Wang, Boqing Gong, and Stella X Yu. Largescale long-tailed recognition in an open world. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 2537\u20132546, 2019.   \nYin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. Class-balanced loss based on effective number of samples. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9268\u20139277, 2019.   \nMateusz Buda, Atsuto Maki, and Maciej A Mazurowski. A systematic study of the class imbalance problem in convolutional neural networks. Neural networks, 106:249\u2013259, 2018.   \nKaidi Cao, Colin Wei, Adrien Gaidon, Nikos Arechiga, and Tengyu Ma. Learning imbalanced datasets with label-distribution-aware margin loss. Advances in Neural Information Processing Systems, 32, 2019.   \nJiang-Xin Shi, Tong Wei, Zhi Zhou, Xin-Yan Han, Jie-Jing Shao, and Yu-Feng Li. Parameter-efficient long-tailed recognition. arXiv preprint arXiv:2309.10019, 2023.   \nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In International Conference on Learning Representations, 2021.   \nMenglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie, Bharath Hariharan, and Ser-Nam Lim. Visual prompt tuning. In European Conference on Computer Vision, pages 709\u2013727. Springer, 2022.   \nNeil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient transfer learning for nlp. In International Conference on Machine Learning, pages 2790\u20132799. PMLR, 2019.   \nAditya Krishna Menon, Sadeep Jayasumana, Ankit Singh Rawat, Himanshu Jain, Andreas Veit, and Sanjiv Kumar. Long-tail learning via logit adjustment. In International Conference on Learning Representations, 2021.   \nGuillaume Klein, Yoon Kim, Yuntian Deng, Vincent Nguyen, Jean Senellart, and Alexander M. Rush. Opennmt: Neural machine translation toolkit, 2018.   \nMyle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, and Michael Auli. fairseq: A fast, extensible toolkit for sequence modeling. In Proceedings of NAACL-HLT 2019: Demonstrations, 2019.   \nKaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, and Ross Girshick. Masked autoencoders are scalable vision learners. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 16000\u201316009, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Appendix: Proposition Proof ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A.1 Uniform Convergence ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "[[[PPPrrrooopppooosssiiitttiiiooonnn   111]]] We have that SReLU uniformly converges to ReLU as $\\delta\\;\\;\\rightarrow\\;\\;0^{+}$ , that is, $\\begin{array}{r}{\\operatorname*{lim}_{\\delta\\rightarrow0^{+}}\\operatorname*{sup}_{x}|\\mathrm{SReLU}_{\\delta}(x)-[x]_{+}|=0}\\end{array}$ . ", "page_idx": 12}, {"type": "text", "text": "PPPrrroooooofff... ", "text_level": 1, "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathrm{ReLU}(x)=[x]_{+}=\\frac{1}{2}(x+|x|);}\\\\ {\\displaystyle\\mathrm{SReLU}(\\mathrm{x})=\\frac{1}{2}\\left[x+\\delta\\left(\\sqrt{\\frac{x^{2}}{\\delta^{2}}+1}-1\\right)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Note that $\\operatorname{D}(x)=2{\\bigl(}\\operatorname{ReLU}(x)-\\operatorname{SReLU}(x){\\bigr)}=|x|-\\delta{\\Biggl(}{\\sqrt{\\frac{x^{2}}{\\delta^{2}}+1}}-1{\\Biggl)}$ , we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{D}(x)=\\sqrt{x^{2}}-\\sqrt{x^{2}+\\delta^{2}}+\\delta}\\\\ &{\\qquad=\\delta-\\frac{\\delta^{2}}{\\sqrt{x^{2}}+\\sqrt{x^{2}+\\delta^{2}}}}\\\\ &{\\qquad=\\delta\\Bigg(1-\\frac{1}{\\sqrt{\\frac{x^{2}}{\\delta^{2}}}+\\sqrt{\\frac{x^{2}}{\\delta^{2}}+1}}\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "For any $x$ and $\\delta$ , the form $\\begin{array}{r}{0<1-\\frac{1}{\\sqrt{\\frac{x^{2}}{\\delta^{2}}}+\\sqrt{\\frac{x^{2}}{\\delta^{2}}+1}}<1}\\end{array}$ , therefore, for any $\\epsilon>0$ , if $\\delta<\\epsilon$ , then $\\forall x$ we shall have $\\mathrm{D}(x)<\\epsilon$ . ", "page_idx": 12}, {"type": "text", "text": "A.2 Decision Boundary ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "[[[PPPrrrooopppooosssiiitttiiiooonnn   222]]] For two normal populations with known (denote as $\\Sigma$ ) and equal covariance matrices, and means $\\pmb{\\mu}_{1}$ and $\\pmb{\\mu}_{2}$ , the LR model $f(\\pmb{x})=\\mathrm{sigmoid}(\\pmb{\\omega}^{\\top}\\pmb{x}+b)$ has a theoretical decision boundary: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\omega^{*}=(\\mu_{1}-\\mu_{0})^{\\top}\\Sigma^{-1};}\\\\ &{b^{*}=\\frac{1}{2}\\Bigg[\\mu_{0}^{\\top}\\Sigma^{-1}\\mu_{0}+\\mu_{1}^{\\top}\\Sigma^{-1}\\mu_{1}\\Bigg]+\\ln\\Bigg[\\frac{\\mathrm{Pr}(Y=1)}{\\mathrm{Pr}(Y=0)}\\Bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "PPPrrroooooofff... Usually, we estimate the parameters $\\omega$ and $b$ by maximizing the likelihood function ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\ln[\\operatorname*{Pr}(y_{i}|x_{i})].\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "This is to estimate parameters in the \u201cmost data-fitting manner\u201d when the distribution is unknown. Now we know that two classes are normally distributed, we even know their mean and covariance matrix. ", "page_idx": 12}, {"type": "text", "text": "In Logistic Regression ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\operatorname*{Pr}(Y=1|x)=\\cfrac{1}{1+e^{-(\\omega^{\\top}x+b)}};}\\\\ {\\operatorname*{Pr}(Y=0|x)=\\cfrac{e^{-\\omega^{\\top}x+b}}{1+e^{-(\\omega^{\\top}x+b)}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "So we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\ln\\left[{\\frac{\\operatorname*{Pr}(Y=1|x)}{\\operatorname*{Pr}(Y=0|x)}}\\right]={\\boldsymbol{\\omega}}^{\\top}{\\boldsymbol{x}}+{\\boldsymbol{b}}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "And by Bayes\u2019 theorem, we can derive ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\ln\\left[{\\frac{\\operatorname*{Pr}(Y=1|x)}{\\operatorname*{Pr}(Y=0|x)}}\\right]=\\ln\\left[{\\frac{\\operatorname*{Pr}(x|Y=1)\\operatorname*{Pr}(Y=1)}{\\operatorname*{Pr}(x|Y=0)\\operatorname*{Pr}(Y=0)}}\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Here, since we inherently know the data is normally distributed, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\ln\\left[{\\frac{\\operatorname*{Pr}(Y=1|x)}{\\operatorname*{Pr}(Y=0|x)}}\\right]=(\\mu_{1}-\\mu_{0})^{\\top}\\Sigma^{-1}x+{\\frac{1}{2}}\\left[\\mu_{0}^{\\top}\\Sigma^{-1}\\mu_{0}+\\mu_{1}^{\\top}\\Sigma^{-1}\\mu_{1}\\right]+\\ln\\left[{\\frac{\\operatorname*{Pr}(Y=1)}{\\operatorname*{Pr}(Y=0)}}\\right].\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Then, comparing Equation (10) with Equation (9), we\u2019ll have the answer. ", "page_idx": 13}, {"type": "text", "text": "A.3 More Experiments ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We conduct an ablation study on \"how $S\\mathrm{T}_{k}$ complements other long-tailed learning algorithms.\" The backbone here is a Vision Transformer (ViT) pre-trained by MAE / CLIP [He et al., 2022, Radford et al., 2021]. \"CS\" represents cost-sensitive learning, and \u201cPEL\u201d refers to the method provided by [Shi et al., 2023]. The batch size was set to 2048 and the models were trained in 30,000 steps. ", "page_idx": 13}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/baa61c968ec2d242424c33a10ae2d026c21b320d6f281f004e46004cf38a651b.jpg", "table_caption": [], "table_footnote": ["Table 7: Ablation Study on Long-Tailed Learning Algorithms. "], "page_idx": 13}, {"type": "text", "text": "The smoothing coefficient $\\delta$ , 0.01, is a grid search determined value for all datasets in Section 5.1 (see page 7) and was adopted in all other experiments. We conducted an ablation study on the five real-world datasets with all other settings remaining unchanged, except for $\\delta$ . ", "page_idx": 13}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/a00223a61b376c1331683d775a00efe56deb0b33a4a6d49684d878af52304c52.jpg", "table_caption": ["Table 8: Sensitive Analysis of the Smoothing Coefficient \u03b4. "], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "A.4 Benchmarks Detailed Information ", "text_level": 1, "page_idx": 13}, {"type": "table", "img_path": "OdJKB9jSa5/tmp/26a7f9ef6ea70604159587e3144c6489e0f324d0d98c9b16f4d949ec6a1ef77a.jpg", "table_caption": ["Table 9: Statistics of Benchmarks. "], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "In Table 9, we provide the statistical information for two benchmark sets discussed in Section 5, where c, n, d are the number of classes, samples and features, respectively. The left part provides the information of four regression datasets in Section 5.3. The \u201cSinc\u201d dataset is a synthetic dataset, sampled from the sinc function $y=\\sin(x)/x$ . The right part provides the information of seven binary classification datasets in Section 5.1. ", "page_idx": 13}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "Justification: The abstract and/or introduction clearly state the claims made. ", "page_idx": 14}, {"type": "text", "text": "Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 14}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Justification: The limitations can be found in Section 6. ", "page_idx": 14}, {"type": "text", "text": "Guidelines: ", "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 14}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 14}, {"type": "text", "text": "Justification: The proof can be found in Appendix. Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 15}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Justification: Every experiment can be easily reproduced, and the code will be available soon. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 15}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: Main results can be reproduced by supplementary material. Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 16}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: The paper has specified all the training and test details. Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 16}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: We provide the Std of the results, where the proposed method exhibits the lowest Std and surpasses other methods in terms of mean performance. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: The computational resource requirements of experiments on large real-world datasets can be found in 5.2, while the remaining experiments can be produced on CPU. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 17}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Justification: Sure about that. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 17}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 18}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We ensure that the creators or original owners of assets used in the paper are properly credited, and the license and terms of use are explicitly mentioned and properly respected. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 19}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 19}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 19}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] Justification: ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 19}]