[{"figure_path": "QAEnr5j172/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparisons on Face Synthetics and SynFashion datasets.", "description": "This table presents a quantitative comparison of different image-to-image translation methods on two datasets: Face Synthetics and SynFashion.  The metrics used for comparison are: KID (Kernel Inception Distance), LPIPS (Learned Perceptual Image Patch Similarity), and SSIM (Structural Similarity Index). Lower KID values indicate better realism, lower LPIPS values indicate higher perceptual similarity to the ground truth, and higher SSIM values indicate better structural similarity. The table allows for a comparison of the performance of various methods in terms of realism, image quality, and texture preservation.", "section": "4 Results"}, {"figure_path": "QAEnr5j172/tables/tables_7_2.jpg", "caption": "Table 2: User studies on overall realism, image quality and consistency. The table shows the percentage of votes that existing methods are preferred to ours.", "description": "This table presents the results of a user study comparing the proposed method to existing methods in terms of overall realism, image quality and consistency.  For each criterion, the percentage of participants who preferred the existing methods over the proposed method is shown. Lower percentages indicate that the proposed method is preferred. The study was conducted on two datasets, Face Synthetics and SynFashion, using 100 image pairs per dataset and about 2000 votes in total.", "section": "4.3 Results"}, {"figure_path": "QAEnr5j172/tables/tables_8_1.jpg", "caption": "Table 3: Ablation study in a drop-on-out manner.", "description": "This table presents the quantitative results of an ablation study performed on the Face Synthetics and SynFashion datasets. The study investigates the impact of removing one component at a time from the proposed method: source domain knowledge injection (DKI), target domain knowledge injection (DKI), and texture-preserving attention control (TAC).  The results are measured using KID (Kernel Inception Distance), LPIPS (Learned Perceptual Image Patch Similarity), and SSIM (Structural Similarity Index). Lower KID values indicate better realism, lower LPIPS values indicate higher perceptual similarity to real images, and higher SSIM values indicate better structural similarity.  The table allows one to assess the contribution of each component to the overall performance of the method.", "section": "4.4 Ablation Study and Further Analysis"}, {"figure_path": "QAEnr5j172/tables/tables_9_1.jpg", "caption": "Table 4: Comparison of memory required and testing time across different methods.", "description": "This table compares the memory required (in GB) and testing time (in seconds) for five different methods: CUT, SANTA, VCT, UNSB, and the authors' proposed method.  The comparison highlights the computational efficiency of different approaches for rendered-to-real image translation. Note that the testing time for VCT is significantly longer than the others.", "section": "4 Experiments"}, {"figure_path": "QAEnr5j172/tables/tables_16_1.jpg", "caption": "Table 5: Number of images in different categories of SynFashion.", "description": "This table shows the number of images available in the SynFashion dataset for each of the 20 clothing categories.  The categories are broken down into three rows for better readability.", "section": "4.1 Datasets"}]