{"references": [{"fullname_first_author": "C. Blundell", "paper_title": "Weight uncertainty in neural networks", "publication_date": "2015-00-00", "reason": "This paper is foundational for Bayesian deep learning, introducing the concept of weight uncertainty in neural networks which is fundamental to the proposed approach in this paper."}, {"fullname_first_author": "C. M. Bishop", "paper_title": "Pattern recognition and machine learning", "publication_date": "2006-00-00", "reason": "This is a highly influential textbook on pattern recognition and machine learning, providing background on Bayesian methods which is the basis for the proposed approach."}, {"fullname_first_author": "Y. Gal", "paper_title": "Dropout as a Bayesian approximation: Representing model uncertainty in deep learning", "publication_date": "2016-00-00", "reason": "This paper established dropout as a Bayesian approximation technique, which is a key element in many Bayesian neural network methods, including the one proposed in this paper."}, {"fullname_first_author": "E. J. Hu", "paper_title": "LoRA: Low-rank adaptation of large language models", "publication_date": "2022-00-00", "reason": "This paper introduced LoRA (Low-Rank Adaptation), a parameter-efficient fine-tuning method that is central to the proposed approach in this paper."}, {"fullname_first_author": "D. Hendrycks", "paper_title": "Measuring massive multitask language understanding", "publication_date": "2021-00-00", "reason": "This paper introduced the MMLU benchmark, providing a comprehensive evaluation dataset for large language models which is used in the experimental evaluation of this paper."}]}