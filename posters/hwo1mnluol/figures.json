[{"figure_path": "HwO1mNluoL/figures/figures_1_1.jpg", "caption": "Figure 1: Summary of our setup. A frozen pretrained encoder is used as a feature extractor for a downstream task. An adapter is attached on top of the encoder that learns the bias in the downstream dataset. Finally, the bias is mitigated with the help of an adaptive margin loss, leading to unbiased predictions. No knowledge of the bias attribute is assumed apriori.", "description": "The figure illustrates the proposed method for mitigating bias in a downstream classification task using a frozen pretrained encoder.  The process involves three stages: 1) Using a pretrained encoder (frozen weights) to extract features from input images. 2) Adding a trainable adapter module on top of the encoder to learn and amplify the bias present in the downstream dataset. 3) Applying a novel adaptive margin loss technique to mitigate the learned bias, resulting in unbiased predictions for the downstream task.  Crucially, the method does not require prior knowledge of the bias attribute.", "section": "3 Problem Statement and Methodology"}, {"figure_path": "HwO1mNluoL/figures/figures_4_1.jpg", "caption": "Figure 3: Overview of our method. There are 3 steps: a) Bias-amplified training of the model through Cross-Entropy Loss with high weight decay, b) Clustering the biased features f, c) Mitigating the biases by using the resultant clusters to calculate the margins and the corresponding loss, leading to decent performance on the bias-conflicting data points.", "description": "This figure shows the three stages of the proposed bias mitigation method. Stage 1 involves bias amplification by training the model with a cross-entropy loss and high weight decay.  In stage 2, the resulting biased features are clustered to identify groups based on bias. Finally, in stage 3, an adaptive margin loss uses cluster information to mitigate bias, leading to improved performance on the bias-conflicting data samples.", "section": "3.4 Our approach"}, {"figure_path": "HwO1mNluoL/figures/figures_7_1.jpg", "caption": "Figure 3: Overview of our method. There are 3 steps: a) Bias-amplified training of the model through Cross-Entropy Loss with high weight decay, b) Clustering the biased features f, c) Mitigating the biases by using the resultant clusters to calculate the margins and the corresponding loss, leading to decent performance on the bias-conflicting data points.", "description": "This figure illustrates the three-stage process of the proposed bias mitigation method. Stage 1 involves bias amplification training using cross-entropy loss with high weight decay. In Stage 2, the biased features are clustered. Finally, Stage 3 uses the clusters to calculate adaptive margins for a margin loss, mitigating biases and improving performance on bias-conflicting data.", "section": "3 Problem Statement and Methodology"}, {"figure_path": "HwO1mNluoL/figures/figures_17_1.jpg", "caption": "Figure 3: Overview of our method. There are 3 steps: a) Bias-amplified training of the model through Cross-Entropy Loss with high weight decay, b) Clustering the biased features f, c) Mitigating the biases by using the resultant clusters to calculate the margins and the corresponding loss, leading to decent performance on the bias-conflicting data points.", "description": "This figure illustrates the three-stage process of the proposed bias mitigation method.  Stage 1 involves bias amplification training using cross-entropy loss with a high weight decay, resulting in a model that overemphasizes the biases in the data. Stage 2 uses clustering to group similar biased features. Finally, Stage 3 applies an adaptive margin loss that leverages the cluster information to mitigate the bias and improve performance, especially for bias-conflicting data points. The diagram shows the flow of data through the pretrained encoder, adapter, and classifier layers, highlighting which components are frozen and which are trainable.", "section": "3 Problem Statement and Methodology"}, {"figure_path": "HwO1mNluoL/figures/figures_17_2.jpg", "caption": "Figure 3: Overview of our method. There are 3 steps: a) Bias-amplified training of the model through Cross-Entropy Loss with high weight decay, b) Clustering the biased features f, c) Mitigating the biases by using the resultant clusters to calculate the margins and the corresponding loss, leading to decent performance on the bias-conflicting data points.", "description": "This figure shows the three stages of the proposed bias mitigation method.  First, bias is amplified in the model using cross-entropy loss with a high weight decay. Then, the learned features are clustered to identify groups of samples with similar characteristics. Finally, a margin loss is used to mitigate biases, with the margin values determined by the cluster assignments to obtain unbiased predictions, especially for samples that were not well learned in the first stage of training.", "section": "3.4 Our approach"}]