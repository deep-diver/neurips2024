[{"figure_path": "PyTkA6HkzX/figures/figures_3_1.jpg", "caption": "Figure 1: Our structural causal model M. Circles represent endogenous random variables and boxes represent exogenous random variables. The value of each endogenous variable is given by a function of the values of its ancestors, as defined by Eq. 3. The value of each exogenous variable is sampled independently from a given distribution.", "description": "This figure presents a structural causal model (SCM) illustrating how a decision support system based on prediction sets affects human expert predictions.  The model depicts the relationships between exogenous variables (V, U, \u039b representing data generation, expert characteristics, and threshold), endogenous variables (X, Y, C\u03bb(X), \u0176 representing features, ground truth, prediction set, and expert prediction), and the causal flows between them. It serves as the foundation for the paper's analysis of counterfactual harm.", "section": "Counterfactual harm of decision support systems"}, {"figure_path": "PyTkA6HkzX/figures/figures_7_1.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  The x-axis represents the average counterfactual harm, and the y-axis represents the average accuracy. Each point represents a different threshold (\u03bb) used to generate prediction sets. The color intensity indicates how often that threshold resulted in a harm value below the specified \u03b1 (0.01 in (a) and 0.05 in (b)).  Different rows represent different pre-trained classifiers.  The results suggest that improved accuracy often comes at the cost of increased counterfactual harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_8_1.jpg", "caption": "Figure 3: Average accuracy estimated using predictions by human participants (Real) and using the mixture of MNLs (Predicted) against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which the \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. The decision support systems C\u03bb use the pre-trained classifier VGG19. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure compares the average accuracy of human participants' predictions (Real) and predictions made by the mixture of multinomial logit models (MNLs, Predicted) against the average counterfactual harm caused by the decision support system C\u03bb using the pre-trained classifier VGG19 for \u03b1 = 0.01 and \u03b1 = 0.05. The figure shows the trade-off between accuracy and counterfactual harm, illustrating that higher accuracy may come at the cost of increased harm. The coloring of the points reflects the frequency with which each \u03bb value is within the harm-controlling set \u039b(\u03b1) for each \u03b1, indicating which \u03bb values are suitable for controlling harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_21_1.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  The x-axis represents the average counterfactual harm, and the y-axis represents the average accuracy. Each point represents a different threshold value (\u03bb) used to generate prediction sets. The color intensity indicates the frequency with which a given \u03bb value was identified as harm-controlling (i.e., part of the set \u039b(\u03b1)).  Different rows represent results for systems using different pre-trained classifiers (VGG19, DenseNet161, GoogleNet, ResNet152, AlexNet).", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_22_1.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  The x-axis represents the average counterfactual harm, and the y-axis represents the average accuracy achieved by human experts using the system. Each point represents a different threshold (\u03bb) value used to create the prediction sets. The color intensity indicates how often that threshold value resulted in a harm level below the specified bound (\u03b1) across multiple random samplings.  Different rows represent different pre-trained classifiers used, showcasing consistent trends across different models. The results demonstrate that higher accuracy can come at the cost of increased counterfactual harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_23_1.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  The x-axis represents the average counterfactual harm, and the y-axis represents the average accuracy. Each point represents a different threshold (\u03bb) used to create the prediction sets. The color intensity indicates how often that threshold was selected as harm-controlling across multiple random samplings of the data. Different rows correspond to different pre-trained classifiers used to generate the prediction sets.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_23_2.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  It displays the average accuracy (estimated using a mixture of multinomial logit models) plotted against the average counterfactual harm for different threshold values (\u03bb) in a system using prediction sets. Each line represents a different pre-trained classifier, and the color intensity represents the frequency with which a given threshold is considered harm-controlling.  The results highlight that higher accuracy often comes at the cost of increased harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_23_3.jpg", "caption": "Figure 7: Average set size and empirical coverage against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.025.", "description": "This figure shows the relationship between the average prediction set size and empirical coverage with the average counterfactual harm for different decision support systems using various pre-trained classifiers.  It demonstrates that systems with higher coverage tend to generate larger prediction sets, and they also tend to cause less counterfactual harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_23_4.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  Each point represents a different threshold (\u03bb) used to create prediction sets. The color intensity indicates how often that threshold resulted in harm below the user-specified threshold (\u03b1), averaged over multiple random samplings of the data.  Different rows correspond to different pre-trained classifiers.  The overall trend demonstrates that higher accuracy often comes at the cost of increased counterfactual harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_25_1.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure displays the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  The x-axis represents average counterfactual harm, and the y-axis represents average accuracy. Each point shows a different threshold (\u03bb) used to create prediction sets, with the color indicating how frequently that \u03bb resulted in harm below the specified threshold (\u03b1) across different random samples.  Different rows represent results obtained with different pre-trained classifiers (VGG19, DenseNet161, GoogleNet, ResNet152, AlexNet). The study demonstrates that higher accuracy often correlates with greater counterfactual harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_25_2.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  The x-axis represents the average counterfactual harm, and the y-axis represents the average accuracy. Each point represents a different threshold (\u03bb) used to generate prediction sets. The color intensity indicates how often a given threshold results in an average counterfactual harm below the specified bound (\u03b1).  Different rows represent different pre-trained classifiers. The study demonstrates that higher accuracy often comes at the cost of increased counterfactual harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_26_1.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  It plots the average accuracy (estimated using a mixture of multinomial logit models) against the average counterfactual harm for different threshold values (\u03bb). Each line represents a different pre-trained classifier, demonstrating how the relationship between accuracy and harm varies depending on the model used.  The color intensity indicates the frequency with which a given threshold value is part of the harm-controlling set (\u039b(\u03b1)).", "section": "5 Controlling counterfactual harm using conformal risk control"}, {"figure_path": "PyTkA6HkzX/figures/figures_26_2.jpg", "caption": "Figure 2: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  Each point represents a different threshold (\u03bb) used to create prediction sets. The color intensity shows how often that threshold resulted in harm below the specified level (\u03b1) across different random samplings of the data. Each row uses a different pre-trained classifier, demonstrating the impact of classifier choice on this trade-off. The results show that higher accuracy often comes at the cost of increased harm, highlighting a key challenge in designing these systems.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_26_3.jpg", "caption": "Figure 7: Average set size and empirical coverage against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies as in Figure 6 above. The average accuracy achieved by the simulated human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.025.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  It displays two subfigures: one showing the average prediction set size versus average counterfactual harm, and another showing the empirical coverage (the fraction of test samples where the prediction set contains the ground truth label) versus average counterfactual harm.  The results are based on experiments using different pre-trained classifiers and averaged across multiple random samplings of the data.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_28_1.jpg", "caption": "Figure 12: Empirical success probability per prediction set size averaged across (a) all experts for images with ground truth label bottle, (b) all experts for images with ground truth label oven, (c) experts with low level of competence for images with ground truth label bottle, and (d) experts with high level of competence for images with ground truth label bottle with high, medium to high and medium to low difficulty. In all panels, we have only considered prediction sets that included the ground truth label and thus have omitted showing the empirical success probability for singletons, as it is always 1. Error bars denote standard error.", "description": "This figure shows the average accuracy achieved by human experts when predicting labels from prediction sets of different sizes.  The data is stratified by image difficulty (high, medium-high, medium-low, low) and expert competence (high, low).  Each panel shows results for a specific combination of label (bottle or oven) and expert competence level.  The results visually demonstrate the relationship between prediction set size and prediction accuracy.", "section": "F Average accuracy vs. prediction set size"}, {"figure_path": "PyTkA6HkzX/figures/figures_29_1.jpg", "caption": "Figure 13: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm upper bound for images with w = 80. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b\u2032(\u03b1) across random samplings of the calibration set for a fixed \u03b1\u2032. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifiers as in Figure 4. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals have width always below 0.02 and are represented using shaded areas.", "description": "This figure displays the trade-off between accuracy and counterfactual harm for different decision support systems (different pre-trained classifiers) on images with a specific noise level (w=80).  The x-axis represents the average counterfactual harm bound, while the y-axis shows the average accuracy.  Each point represents a threshold (\u03bb) value, and the color intensity indicates how frequently that threshold was found to be harm-controlling across multiple random samplings. The shaded areas show the 95% confidence intervals for the average accuracy.", "section": "G Experiments under the interventional monotonicity assumption"}, {"figure_path": "PyTkA6HkzX/figures/figures_30_1.jpg", "caption": "Figure 3: Average accuracy estimated using predictions by human participants (Real) and using the mixture of MNLs (Predicted) against the average counterfactual harm for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which the \u03bb value is in \u039b(\u03b1) across random samplings of the calibration set. The decision support systems C\u03bb use the pre-trained classifier VGG19. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals are represented using shaded areas and always have width below 0.02.", "description": "This figure shows the trade-off between accuracy and counterfactual harm in decision support systems based on prediction sets.  It compares the accuracy of human predictions (real) versus model-predicted accuracy (using a Mixture of Multinomial Logits, MNL) against the average counterfactual harm.  The color intensity shows the frequency with which a specific threshold (\u03bb) results in harm less than a user-specified value (\u03b1). The results show that even with the best threshold, some counterfactual harm is present, and that there is a trade-off between achieving high accuracy and minimizing harm.", "section": "Experiments"}, {"figure_path": "PyTkA6HkzX/figures/figures_30_2.jpg", "caption": "Figure 15: Average accuracy estimated by the mixture of MNLs against the average counterfactual harm upper bound for images with w = 110. Each point corresponds to a \u03bb value from 0 to 1 with step 0.001 and the coloring indicates the relative frequency with which each \u03bb value is in \u039b\u2032(\u03b1) across random samplings of the calibration set for a fixed \u03b1\u2032. Each row corresponds to decision support systems C\u03bb with a different pre-trained classifier with average accuracies 0.846 (VGG19), 0.830 (DenseNet), 0.722 (GoogleNet), 0.727 (ResNet152), and 0.691 (AlexNet). The average accuracy achieved by human experts on their own is 0.771. The results are averaged across 50 random samplings of the test and calibration set. In both panels, 95% confidence intervals have width always below 0.02 and are represented using shaded areas.", "description": "This figure displays the trade-off between accuracy and counterfactual harm in decision support systems using prediction sets.  Different pre-trained classifiers are used, and the effect of varying the threshold (\u03bb) on accuracy and the upper bound of counterfactual harm is shown.  The color intensity shows the frequency at which each threshold is within a harm-controlling set.  The results are averaged across multiple random samplings to account for variability.", "section": "Experiments under the interventional monotonicity assumption"}]