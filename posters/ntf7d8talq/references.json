{"references": [{"fullname_first_author": "Arnab Auddy", "paper_title": "Approximate leave-one-out cross validation for regression with l1 regularizers", "publication_date": "2024", "reason": "This paper proposes a novel method for estimating the cross-validation error of regression models with l1 regularization, addressing the limitations of traditional methods in high-dimensional settings."}, {"fullname_first_author": "Pierre C Bellec", "paper_title": "Out-of-sample error estimate for robust m-estimators with convex penalty", "publication_date": "2023-10", "reason": "This paper provides a novel approach for estimating the out-of-sample prediction error for robust M-estimators with convex penalties, which is crucial for high-dimensional robust regression."}, {"fullname_first_author": "Pierre C Bellec", "paper_title": "Derivatives and residual distribution of regularized m-estimators with application to adaptive tuning", "publication_date": "2022", "reason": "This paper offers valuable insights into the properties of regularized M-estimators and provides tools for adaptive tuning, which is essential for efficient and accurate estimation in robust regression."}, {"fullname_first_author": "Stephen Boyd", "paper_title": "Distributed optimization and statistical learning via the alternating direction method of multipliers", "publication_date": "2011", "reason": "This paper introduces the Alternating Direction Method of Multipliers (ADMM), a powerful algorithm for solving large-scale optimization problems, which is relevant to the robust regression methods discussed."}, {"fullname_first_author": "Jianqing Fan", "paper_title": "Variable selection via nonconcave penalized likelihood and its oracle properties", "publication_date": "2001", "reason": "This paper introduces the SCAD and MCP penalties, which are non-convex penalties used for variable selection in high-dimensional regression, and are relevant to the penalized robust regression setting discussed in this paper."}]}