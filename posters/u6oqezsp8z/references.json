{"references": [{"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-XX-XX", "reason": "This paper introduces a visual instruction tuning method, which is highly relevant to the proposed approach of leveraging an image captioner for audio captioning."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-XX-XX", "reason": "This foundational paper introduces CLIP, a vision-language model that is crucial to the work presented, as the authors leverage its image captioning capabilities."}, {"fullname_first_author": "Benjamin Elizalde", "paper_title": "CLAP: Learning audio concepts from natural language supervision", "publication_date": "2023-XX-XX", "reason": "CLAP is a key model in the field of audio captioning, and is directly compared against in the paper's results."}, {"fullname_first_author": "Victor Weixin Liang", "paper_title": "Mind the gap: Understanding the modality gap in multi-modal contrastive representation learning", "publication_date": "2022-XX-XX", "reason": "This paper discusses the modality gap problem which is a central challenge addressed by the proposed distribution alignment method."}, {"fullname_first_author": "Jort F Gemmeke", "paper_title": "Audio set: An ontology and human-labeled dataset for audio events", "publication_date": "2017-XX-XX", "reason": "AudioSet is the primary dataset used in this work, thus its description and characteristics are fundamental to understanding the experimental setup and results."}]}