[{"figure_path": "cuWsR25bbI/tables/tables_2_1.jpg", "caption": "Table 1: Multitask sparse parity dataset and skill basis functions. The control bits are ns-dimensional one-hot vectors encoding specific parity tasks, indexed in the first column. The frequency of the distinct parity tasks follows a rank-frequency distribution with an inverse power law relation (Eq. (1)). The skill bits are binary strings with m = 3 relevant sparse bits (highlighted in colors) with their locations varying by skill. The y column shows the target scale S multiplied by the parity computed from the relevant bit set M(i, x). The last columns show the values of the skill basis functions gk (i, x), defined in Eq. (2).", "description": "This table shows the dataset used for the multitask sparse parity problem.  It displays the control bits (one-hot encoding of the task), skill bits (binary string with m=3 relevant bits), the target value (y), a vector representation (M) of the relevant bits used to compute the parity, and the values of the skill basis functions (gk) for each example.  The frequencies of the different parity tasks follow an inverse power law distribution, a key element of the multitask problem. The skill basis functions are orthogonal and form a basis set to represent skills.", "section": "2 Setup"}, {"figure_path": "cuWsR25bbI/tables/tables_5_1.jpg", "caption": "Table 2: Summary of the scaling laws for the multilinear model. The leftmost column indicates the bottleneck resource while the next two columns are the conditions for the 'large resources' - large enough to be treated as infinity. The fourth column is the bottleneck resource's scaling law exponent for the loss. The last two columns show the statement for the prefactor constant and the scaling law (with the assumptions and explicit error terms) in Appendix J.", "description": "This table summarizes the scaling laws derived for the multilinear model presented in the paper. It shows how the loss (MSE) scales with respect to time (T), data size (D), number of parameters (N), and optimal compute (C).  Each row represents a different bottleneck resource (the most limited resource), and it specifies the conditions under which the scaling law holds (for the other resources being sufficiently large). The exponents and prefactors for the scaling laws are given, along with references to the theorems and corollaries in Appendix J where the rigorous derivations are presented.", "section": "Scaling laws"}, {"figure_path": "cuWsR25bbI/tables/tables_15_1.jpg", "caption": "Table 1: Multitask sparse parity dataset and skill basis functions. The control bits are ns-dimensional one-hot vectors encoding specific parity tasks, indexed in the first column. The frequency of the distinct parity tasks follows a rank-frequency distribution with an inverse power law relation (Eq. (1)). The skill bits are binary strings with m = 3 relevant sparse bits (highlighted in colors) with their locations varying by skill. The y column shows the target scale S multiplied by the parity computed from the relevant bit set M(i, x). The last columns show the values of the skill basis functions gk (i, x), defined in Eq. (2).", "description": "This table presents the data for the multitask sparse parity problem used in the paper.  It shows how the control bits (one-hot vectors) encode the specific parity tasks, with frequencies following an inverse power law.  The skill bits are binary strings where colored bits are relevant, and the y-column is the target value calculated from those bits. The last columns provide the values of the skill basis functions.", "section": "2 Setup"}, {"figure_path": "cuWsR25bbI/tables/tables_21_1.jpg", "caption": "Table 2: Summary of the scaling laws for the multilinear model. The leftmost column indicates the bottleneck resource while the next two columns are the conditions for the 'large resources' - large enough to be treated as infinity. The fourth column is the bottleneck resource's scaling law exponent for the loss. The last two columns show the statement for the prefactor constant and the scaling law (with the assumptions and explicit error terms) in Appendix J.", "description": "This table summarizes the scaling laws derived for the multilinear model presented in the paper.  It shows how the loss (L) scales with different resources (time (T), data size (D), number of parameters (N), and compute (C)).  The table presents scaling exponents, and prefactor constants for these scaling laws. Note that the conditions listed describe the circumstances under which the scaling laws are valid, highlighting the need for sufficiently large resource values to treat them as infinite in the derivation.", "section": "4 Scaling laws"}, {"figure_path": "cuWsR25bbI/tables/tables_34_1.jpg", "caption": "Table 2: Summary of the scaling laws for the multilinear model. The leftmost column indicates the bottleneck resource while the next two columns are the conditions for the 'large resources' - large enough to be treated as infinity. The fourth column is the bottleneck resource's scaling law exponent for the loss. The last two columns show the statement for the prefactor constant and the scaling law (with the assumptions and explicit error terms) in Appendix J.", "description": "This table summarizes the scaling laws derived for the multilinear model presented in the paper.  It shows how the loss (L) scales with respect to time (T), data size (D), number of parameters (N), and compute (C). The table specifies the conditions under which each scaling law applies, indicating the 'bottleneck resource' and the conditions when other resources are sufficiently large ('large resources'). Finally, it indicates where to find a rigorous proof for each scaling law including prefactor constants.", "section": "Scaling laws"}, {"figure_path": "cuWsR25bbI/tables/tables_52_1.jpg", "caption": "Table 1: Multitask sparse parity dataset and skill basis functions. The control bits are ns-dimensional one-hot vectors encoding specific parity tasks, indexed in the first column. The frequency of the distinct parity tasks follows a rank-frequency distribution with an inverse power law relation (Eq. (1)). The skill bits are binary strings with m = 3 relevant sparse bits (highlighted in colors) with their locations varying by skill. The y column shows the target scale S multiplied by the parity computed from the relevant bit set M(i, x). The last columns show the values of the skill basis functions gk (i, x), defined in Eq. (2).", "description": "This table presents data for the multitask sparse parity problem used in the paper. It shows how each skill (parity task) is encoded in the control bits, the corresponding skill bits, and the relevant skill basis functions.  The frequencies of the different parity tasks follow a power-law distribution, making this a challenging learning problem designed to study emergence and scaling laws in neural networks.", "section": "2 Setup"}]