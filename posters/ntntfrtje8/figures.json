[{"figure_path": "NtNTfRTjE8/figures/figures_3_1.jpg", "caption": "Figure 1: Generator artifacts: noise residuals power spectrum of images from 9 generative models and 1 real dataset. Top row: 5 Diffusion Models. Bottom row: 2 GANs, cycleGAN and starGAN, 2 CNN-based generators, Deepfake and CRN, and 1 real dataset, LAION.", "description": "This figure visualizes the noise residuals power spectrum of images generated by various generative models and a real dataset (LAION). It aims to highlight the differences in artifacts produced by different generative architectures (Diffusion Models and GANs) and CNN-based generators. The spectral patterns are unique for each generator, showcasing distinct artifacts that could be exploited for detection.  The figure shows how different generative models create images with various artifacts.  These artifacts are visible in the frequency spectrum and differ significantly between GANs, Diffusion Models, and CNN-based generators.  The figure's purpose is to show the uniqueness of artifacts for different generators and to lay the groundwork for a proposed method.", "section": "3 Methodology"}, {"figure_path": "NtNTfRTjE8/figures/figures_3_2.jpg", "caption": "Figure 2: Semantic artifacts: noise residuals power spectrum of images from different scenes. Top row: 5 real datasets. Bottom row: 5 generative models in corresponding scenes, deepfake, SITD, and 3 variants of Latent Diffusion on CelebA, FFHQ, and LAION.", "description": "This figure visualizes the noise residuals power spectrum of images from both real and synthetic datasets. The top row shows the power spectrum of 5 different real-world datasets, demonstrating the unique spectral characteristics associated with each dataset's content and image processing.  The bottom row displays the corresponding power spectrum for synthetic images generated by different models trained on the same datasets. This comparison highlights how generative models inherit and reflect the unique artifacts present in their training data, which are referred to as \"semantic artifacts.\"  The existence of \"semantic artifacts\" in both real and generated images is a key finding of the paper and a significant challenge to creating generalized AI-generated image detectors.", "section": "3 Methodology"}, {"figure_path": "NtNTfRTjE8/figures/figures_4_1.jpg", "caption": "Figure 3: The visualization of CAM extracted from different detectors on Bedroom or Church images. Warmer color indicates a higher probability.", "description": "This figure visualizes Class Activation Maps (CAMs) from different AI-generated image detection models applied to images of bedrooms and churches.  The models tested are: a baseline ResNet-50 trained on bedroom images; a baseline ResNet-50 trained on church images; a ResNet-50 trained on bedroom images that uses a patch shuffling technique; a ResNet-50 trained on church images that uses a patch shuffling technique; and the authors' proposed approach.  The warmer colors in the CAMs indicate areas the model deemed more important for its classification decision. The purpose of the figure is to demonstrate how the models utilize different features when classifying images (e.g., the authors' model focuses on local rather than global features).", "section": "3.2 Analysis of the Impact of Semantic Artifacts"}, {"figure_path": "NtNTfRTjE8/figures/figures_5_1.jpg", "caption": "Figure 4: Pipeline of our approach. First, for pre-processing, we divide the input image into patches and shuffle these patches to obtain a randomized sequence. Then, we train a patch-based convolutional network for feature extraction. Finally, we flatten these features into a one-dimensional vector and then apply a linear classifier for classification.", "description": "This figure illustrates the three main steps of the proposed approach for generalized AI-generated image detection. First, the input image is divided into patches, and these patches are randomly shuffled to mitigate the impact of global semantic artifacts. Second, a patch-based convolutional neural network is used to extract local features from each patch. Finally, the extracted features are concatenated into a vector, and a linear classifier is applied to determine whether the input image is real or fake. This approach aims to break the global semantics while preserving the local generator-specific artifacts, which are more robust to cross-scene generalization.", "section": "3.3 Approach"}, {"figure_path": "NtNTfRTjE8/figures/figures_16_1.jpg", "caption": "Figure 5: Additional noise residuals power spectrum of images from 4 real datasets (Faceforensics++, Raw Camera, CelebA, LAION) and 4 generative models (Deepfake, SITD, LDM-CelebA, LDM-LAION). As suggested by the reviewer, we consider 3 preprocessing operations from rows 2 to 4.", "description": "This figure visualizes the noise residuals power spectrum for images from four real datasets (FaceForensics++, Raw Camera, CelebA, LAION) and four generative models (Deepfake, SITD, LDM-CelebA, LDM-LAION). The figure shows the original images, images after resizing, images after shuffling (Patch Shuffle), and segmented patches of the images. It demonstrates the effectiveness of Patch Shuffle in breaking down global semantic artifacts by comparing the spectral characteristics of the processed images with the original images.", "section": "3.1 Artifacts Analysis"}, {"figure_path": "NtNTfRTjE8/figures/figures_16_2.jpg", "caption": "Figure 3: The visualization of CAM extracted from different detectors on Bedroom or Church images. Warmer color indicates a higher probability.", "description": "This figure visualizes Class Activation Maps (CAMs) to show which parts of the input image the different detectors focus on for classification.  The top row shows results for bedroom images, while the bottom row shows results for church images.  Columns (b) and (c) show the CAMs from ResNet-50 models trained only on bedroom and church images, respectively, demonstrating overfitting to the specific scene. Columns (d) and (e) show results after applying the Patch Shuffle pre-processing method, indicating some improvement. Finally, column (f) shows the CAMs from the proposed \"Our approach\", demonstrating that the approach effectively focuses on local features instead of overall semantic content.", "section": "3.2 Analysis of the Impact of Semantic Artifacts"}, {"figure_path": "NtNTfRTjE8/figures/figures_18_1.jpg", "caption": "Figure 1: Generator artifacts: noise residuals power spectrum of images from 9 generative models and 1 real dataset. Top row: 5 Diffusion Models. Bottom row: 2 GANs, cycleGAN and starGAN, 2 CNN-based generators, Deepfake and CRN, and 1 real dataset, LAION.", "description": "This figure visualizes the noise residuals power spectrum of images generated by nine different generative models and one real dataset (LAION). The top row shows five diffusion models, while the bottom row displays two GANs (cycleGAN and starGAN), two CNN-based generators (Deepfake and CRN), and the LAION real dataset.  Each image shows a distinct spectral pattern, highlighting the unique artifacts produced by different generative architectures.", "section": "3.1 Artifacts Analysis"}]