{"references": [{"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces the foundational CLIP model, which is a key component of many large vision language models (LVLMs) and is directly referenced in the current paper's introduction."}, {"fullname_first_author": "Liu", "paper_title": "LLaVA: Large language-and-vision assistant", "publication_date": "2024-00-00", "reason": "The LLaVA model is used as the primary base LVLM for the experiments in the current paper, demonstrating its significance as a foundational model for the research."}, {"fullname_first_author": "Rafailov", "paper_title": "Direct preference optimization: Your language model is secretly a reward model", "publication_date": "2023-00-00", "reason": "This paper introduces the Direct Preference Optimization (DPO) method, which is used as the core method for the self-training approach in STIC, which is the core method of the current paper."}, {"fullname_first_author": "Chen", "paper_title": "InternVL: Scaling up vision foundation models and aligning for generic visual-linguistic tasks", "publication_date": "2023-12-14", "reason": "The InternVL model is a relevant large vision language model that is frequently compared against in other recent LVLMs research, making it an important reference for context and comparison."}, {"fullname_first_author": "Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-18", "reason": "This paper introduces the Llama 2 model family, highlighting the advancements in LLMs that serve as the language backbone for many LVLMs, therefore providing important context for the development of LVLMs."}]}