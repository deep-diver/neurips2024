[{"figure_path": "4lGPSbGe11/tables/tables_5_1.jpg", "caption": "Table 1: Asymptotic bias and coverage for each approach, where \u2713 and X denote valid and invalid coverages. o(\u00b7), \u03a9(\u00b7) and \u03c9(\u00b7) follow the standard big O notation.", "description": "This table summarizes the asymptotic bias and coverage validity of three methods (plug-in, k-fold CV, LOOCV) for estimating out-of-sample model performance.  It shows the bias (how much the estimate differs from the true value) and the coverage validity (whether the confidence interval correctly contains the true value) for general models and specific models (Linear ERM, kNN, Random Forest).  The results are categorized based on the model's convergence rate (\u03b3), distinguishing between fast and slow convergence scenarios.  A checkmark indicates valid asymptotic coverage, while an 'X' indicates invalid coverage. The big O notation describes the rate at which the bias approaches zero as the sample size increases.", "section": "Main Results"}, {"figure_path": "4lGPSbGe11/tables/tables_8_1.jpg", "caption": "Table 1: Asymptotic bias and coverage for each approach, where \u2713 and X denote valid and invalid coverages. o(\u00b7), \u03a9(\u00b7) and \u03c9(\u00b7) follow the standard big O notation.", "description": "This table summarizes the theoretical findings of the paper regarding the asymptotic bias and coverage validity of three different model evaluation methods (plug-in, K-fold CV, and LOOCV) across various model specifications (parametric and nonparametric) and convergence rates. It provides a concise overview of the performance of each method under different scenarios, indicating whether the resulting interval estimates provide valid coverage guarantees (\u2713) or not (X) for the true out-of-sample performance. The asymptotic bias is also shown in terms of the order of convergence.  This information is crucial for practitioners to choose the appropriate model evaluation method based on the model and context.", "section": "Main Results"}, {"figure_path": "4lGPSbGe11/tables/tables_29_1.jpg", "caption": "Table 1: Asymptotic bias and coverage for each approach, where \u2713 and X denote valid and invalid coverages. o(\u00b7), \u03a9(\u00b7) and \u03c9(\u00b7) follow the standard big O notation.", "description": "This table summarizes the theoretical findings of the paper regarding the asymptotic bias and coverage validity of three different methods (plug-in, K-fold CV, and LOOCV) for estimating out-of-sample model performance.  It shows under what conditions each method provides valid coverage and the asymptotic bias of each method for both parametric and nonparametric models, categorized by convergence rate (\u03b3).  The table also shows specific examples demonstrating the theoretical results.", "section": "Main Results"}, {"figure_path": "4lGPSbGe11/tables/tables_29_2.jpg", "caption": "Table 1: Asymptotic bias and coverage for each approach, where \u2713 and X denote valid and invalid coverages. o(\u00b7), \u03a9(\u00b7) and \u03c9(\u00b7) follow the standard big O notation.", "description": "This table summarizes the asymptotic bias and coverage validity of three model evaluation methods (plug-in, K-fold CV, and LOOCV) across different model types (specific parametric, general parametric, and nonparametric).  It shows whether the methods produce valid coverage intervals (\u2713) or not (X) for the out-of-sample model performance, considering both fast and slow model convergence rates. The bias values are expressed using Big O notation to illustrate their asymptotic behavior relative to the sample size.", "section": "Main Results"}, {"figure_path": "4lGPSbGe11/tables/tables_30_1.jpg", "caption": "Table 1: Asymptotic bias and coverage for each approach, where \u2713 and X denote valid and invalid coverages. o(\u00b7), \u03a9(\u00b7) and \u03c9(\u00b7) follow the standard big O notation.", "description": "This table summarizes the asymptotic bias and coverage validity of three model evaluation methods (plug-in, K-fold CV, LOOCV) across different model types (specific parametric models, general parametric models, and nonparametric models).  The bias and coverage are assessed based on the convergence rate of the model (\u03b3). The table shows conditions under which each method provides valid (\u2713) or invalid (X) coverage of the out-of-sample model performance.", "section": "Main Results"}, {"figure_path": "4lGPSbGe11/tables/tables_30_2.jpg", "caption": "Table 6: Coverage Results of the method kNN in the dataset puma32H, where boldfaced values mean valid coverage for c(2) (i.e., within [0.85, 0.95]).", "description": "This table presents the coverage probabilities for the mean-squared error of a k-Nearest Neighbors model on the puma32H dataset, using different sample sizes and evaluation methods. The methods include plug-in, 2-fold cross-validation, and 5-fold cross-validation.  A valid coverage is considered to be within the range [0.85, 0.95]. The results show that plug-in provides valid coverage across all sample sizes, while cross-validation methods perform less well, especially at larger sample sizes.", "section": "F.3 Regression Study in the Additional Real-World Dataset"}, {"figure_path": "4lGPSbGe11/tables/tables_31_1.jpg", "caption": "Table 2: Evaluation performance of different methods, where boldfaced values mean valid coverage for c(2) (i.e., within [0.85, 0.95]) and boldfaced values in parantheses mean valid coverage for c(z*). IW and biases for kNN and Forest in the regression problem are presented in unit \u00d7103. Results on other sample sizes and numerical reports on standard errors can be found in Tables 3 and 4 in Appendix F.", "description": "This table summarizes the asymptotic bias and coverage probability for three methods (plug-in, 5-fold CV, LOOCV) across various model settings.  It shows the bias and interval width for each method, indicating the accuracy of the out-of-sample performance estimation.  Bold values highlight when the 90% confidence interval successfully covers the true out-of-sample performance.  The table also notes that additional results with different sample sizes and standard errors are provided in supplementary tables.", "section": "Main Results"}, {"figure_path": "4lGPSbGe11/tables/tables_32_1.jpg", "caption": "Table 2: Evaluation performance of different methods, where boldfaced values mean valid coverage for c(2) (i.e., within [0.85, 0.95]) and boldfaced values in parantheses mean valid coverage for c(z*). IW and biases for kNN and Forest in the regression problem are presented in unit \u00d7103. Results on other sample sizes and numerical reports on standard errors can be found in Tables 3 and 4 in Appendix F.", "description": "This table presents the results of evaluating the performance of plug-in, 5-fold cross-validation, and leave-one-out cross-validation for different models and sample sizes.  The metrics reported are coverage probability (at 90% nominal level), interval width, and bias.  The results show how the bias and coverage vary depending on the model and the sample size, supporting the paper's claims on when plug-in is a good alternative to cross-validation.  Additional details and standard errors are provided in supplementary tables.", "section": "5 Numerical Experiments"}]