{"references": [{"fullname_first_author": "Christoph Molnar", "paper_title": "Interpretable machine learning", "publication_date": "2022-00-00", "reason": "This paper provides a comprehensive overview of interpretable machine learning techniques, which is foundational to the current research on explaining audio classifiers."}, {"fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "publication_date": "2019-00-00", "reason": "This paper introduces the concept of language models as unsupervised multitask learners which is a core concept behind zero-shot learning models such as CLAP which is used extensively in this paper."}, {"fullname_first_author": "Benjamin Elizalde", "paper_title": "Learning audio concepts from natural language supervision", "publication_date": "2023-00-00", "reason": "This paper introduces CLAP, the Contrastive Language-Audio Pretraining model, which is the primary model used in the experiments and is crucial to the methods and results of the current paper."}, {"fullname_first_author": "Jayneel Parekh", "paper_title": "Listen to interpret: Post-hoc interpretability for audio networks with NMF", "publication_date": "2022-00-00", "reason": "This paper introduces a method for post-hoc explanation of audio classifiers, which is directly relevant to the current paper's focus on explaining zero-shot classifiers."}, {"fullname_first_author": "Francesco Paissan", "paper_title": "Listenable Maps for Audio Classifiers", "publication_date": "2024-00-00", "reason": "This paper introduces L-MAC, a previous work by the same authors that is directly related to the proposed method LMAC-ZS."}]}