[{"figure_path": "UmW9BYj761/tables/tables_4_1.jpg", "caption": "Table 1: Filtering training data to English image-text pairs negatively impacts cultural diversity but improves performance on standard benchmarks. Asterisk (*) denotes statistical significance at the 95% confidence level. No statistically significant differences are observed for XM3600 retrieval.", "description": "This table presents a comparison of the performance of contrastive vision-language models (VLMs) trained on different datasets.  The 'en' column shows results for models trained solely on English image-text pairs, while 'globe' represents models trained on unfiltered global data, and 'globe-tl' represents models trained on globally diverse data with English translations.  The table evaluates performance across various metrics categorized into three groups: culturally diverse zero-shot evaluations (Dollar Street, GLDv2, GeoDE, MaRVL), Crossmodal-3600 retrieval recall (with both English and translated captions), and prevalent Western-oriented benchmarks (ImageNet zero-shot, COCO image-text retrieval).  The 'en vs. globe-tl' column highlights the performance differences between the English-only trained model and the globally diverse model with translations. Statistical significance is indicated with an asterisk.", "section": "3.1 No filter for improved cultural diversity"}, {"figure_path": "UmW9BYj761/tables/tables_5_1.jpg", "caption": "Table 1: Filtering training data to English image-text pairs negatively impacts cultural diversity but improves performance on standard benchmarks. Asterisk (*) denotes statistical significance at the 95% confidence level. No statistically significant differences are observed for XM3600 retrieval.", "description": "This table presents a comparison of the performance of contrastive vision-language models (VLMs) trained on different datasets across various evaluation metrics.  It shows how filtering training data to only English image-text pairs negatively affects cultural diversity benchmarks while improving performance on standard Western-centric benchmarks like ImageNet and COCO. The table highlights the trade-off between performance on standard benchmarks and performance on culturally diverse datasets.", "section": "3.1 No filter for improved cultural diversity"}, {"figure_path": "UmW9BYj761/tables/tables_8_1.jpg", "caption": "Table 1: Filtering training data to English image-text pairs negatively impacts cultural diversity but improves performance on standard benchmarks. Asterisk (*) denotes statistical significance at the 95% confidence level. No statistically significant differences are observed for XM3600 retrieval.", "description": "This table compares the performance of three SigLIP models trained on different datasets: English-only (en), global multilingual (globe), and global multilingual with English translation (globe-tl).  It evaluates zero-shot classification accuracy on culturally diverse datasets (Dollar Street, GLDv2, GeoDE, MaRVL) and standard benchmarks (ImageNet, COCO). The results show that while the English-only model performs best on standard benchmarks, the global models significantly outperform it on culturally diverse datasets. The globe-tl model, which uses machine translation to convert non-English text to English, provides a balance between these two performance metrics.", "section": "3.1 No filter for improved cultural diversity"}, {"figure_path": "UmW9BYj761/tables/tables_16_1.jpg", "caption": "Table 1: Filtering training data to English image-text pairs negatively impacts cultural diversity but improves performance on standard benchmarks. Asterisk (*) denotes statistical significance at the 95% confidence level. No statistically significant differences are observed for XM3600 retrieval.", "description": "This table presents a comparison of the performance of vision-language models (VLMs) trained on different datasets on various benchmark tasks.  The datasets include culturally diverse datasets and standard Western-centric benchmarks like ImageNet and COCO. The table shows that filtering training data to only English image-text pairs improves performance on Western benchmarks but negatively impacts cultural diversity evaluations.  The results are presented for three model variants: one trained on English-only data, one trained on global unfiltered data, and another pretrained on global data then fine-tuned on English data.  Statistical significance is indicated where applicable.", "section": "3.1 No filter for improved cultural diversity"}]