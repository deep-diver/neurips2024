[{"figure_path": "FTpKGuxEfy/tables/tables_6_1.jpg", "caption": "Table 1: Category-level object pose estimation results on 5 novel categories of Wild6D.", "description": "This table presents the results of category-level object pose estimation on 5 unseen object categories from the Wild6D dataset.  It compares the proposed VFM-6D method with several existing methods (SPD, SGPA, DualPoseNet, GPV-Pose, PoseContrast, and ZSP), showing the average precision (AP) for different pose error thresholds (2cm, 5cm).  The 'Unseen' column indicates whether the method was specifically trained on these categories or not.", "section": "4.3 Main Results"}, {"figure_path": "FTpKGuxEfy/tables/tables_7_1.jpg", "caption": "Table 2: Category-level object pose estimation results on 20 unseen categories of CO3D dataset. We report Acc.15\u00b0 / Acc.30\u00b0 averaged across all 20 categories. We also report results for an illustrative subset of categories. Please refer to the appendix for full per-category results.", "description": "This table presents a comparison of category-level object pose estimation results on 20 unseen categories from the CO3D dataset.  The methods compared include LOFTR, LightGlue, GeDi, ZSP, and the proposed VFM-6D method.  The results are presented as the average accuracy for rotation thresholds of 15 and 30 degrees across all categories, with results for a subset of illustrative categories also provided.  A more complete breakdown of per-category results is available in the appendix.", "section": "4.3 Main Results"}, {"figure_path": "FTpKGuxEfy/tables/tables_7_2.jpg", "caption": "Table 3: Instance-level object pose estimation results measured by ADD-0.1d on LINEMOD dataset. We report average score over all instances and per-instance score for an illustrative subset of instances. Please refer to the appendix for full per-instance results.", "description": "This table presents the results of instance-level object pose estimation using the ADD-0.1d metric on the LINEMOD dataset.  The ADD-0.1d metric measures the average distance between the estimated and ground truth object poses, with a threshold of 0.1 times the object diameter.  The table shows the average performance across all object instances in the dataset and also provides individual results for a selection of instances to illustrate the performance variability.", "section": "4.3 Main Results"}, {"figure_path": "FTpKGuxEfy/tables/tables_8_1.jpg", "caption": "Table 4: Ablation study of individual modules of VFM-6D. The average accuracy over 'motorcycle', 'bicycle', 'chair', 'toyplane', and \u2018toytrain' are reported.", "description": "This table presents the ablation study results of individual modules within the VFM-6D framework.  It shows the impact of removing either the feature lifting module, the shape module, or both on the overall accuracy (measured by Acc.15\u00b0 and Acc.30\u00b0) for object pose estimation. The results demonstrate the significant contribution of both modules to the model's performance.", "section": "4.4 Ablation Studies"}, {"figure_path": "FTpKGuxEfy/tables/tables_18_1.jpg", "caption": "Table 2: Category-level object pose estimation results on 20 unseen categories of CO3D dataset. We report Acc.15\u00b0/Acc.30\u00b0 averaged across all 20 categories. We also report results for an illustrative subset of categories. Please refer to the appendix for full per-category results.", "description": "This table presents a comparison of category-level object pose estimation results on 20 unseen object categories from the CO3D dataset using different methods.  The accuracy is measured using two metrics (Acc.15\u00b0 and Acc.30\u00b0), representing the percentage of poses estimated within 15 and 30 degrees of the ground truth, respectively.  Results are shown for the average across all 20 categories and also a subset of illustrative categories.  More detailed per-category results can be found in the appendix.", "section": "4.3 Main Results"}, {"figure_path": "FTpKGuxEfy/tables/tables_19_1.jpg", "caption": "Table 3: Instance-level object pose estimation results measured by ADD-0.1d on LINEMOD dataset. We report average score over all instances and per-instance score for an illustrative subset of instances. Please refer to the appendix for full per-instance results.", "description": "This table presents the results of instance-level object pose estimation using the ADD-0.1d metric on the LINEMOD dataset.  It compares the proposed VFM-6D method against three other methods: LatentFusion, OSOP, and FS6D. The table shows the average ADD-0.1d score across all instances, as well as scores for a selection of individual instances.  A more complete set of results is available in the appendix.", "section": "4.3 Main Results"}, {"figure_path": "FTpKGuxEfy/tables/tables_20_1.jpg", "caption": "Table 7: Object pose estimation results on LINEMOD and LINEMOD-Occlusion datasets.", "description": "This table presents the results of object pose estimation experiments conducted on the LINEMOD and LINEMOD-Occlusion datasets.  It shows the performance of the method (ADD-0.1d) under varying levels of occlusion: no occlusion, less than 30% occlusion, 30-60% occlusion, and greater than 60% occlusion.  The table quantifies the impact of occlusion on the accuracy of the object pose estimation.", "section": "4.3 Main Results"}, {"figure_path": "FTpKGuxEfy/tables/tables_20_2.jpg", "caption": "Table 8: Object pose estimation results on 5 representative object categories of the CO3D dataset.", "description": "This table presents the results of object pose estimation on five categories from the CO3D dataset under different levels of occlusion.  The results are presented as Accuracy (Acc.15\u00b0/Acc.30\u00b0), which represents the percentage of poses estimated with less than 15\u00b0 and 30\u00b0 angular error, respectively. Each category shows the results for 'No occlusion', '<30%', '30%-60%', and '>60%' occlusion, indicating how the performance changes with increasing occlusion levels. This provides insights into the robustness of the proposed method under varying occlusion conditions.", "section": "4.3 Main Results"}, {"figure_path": "FTpKGuxEfy/tables/tables_20_3.jpg", "caption": "Table 1: Category-level object pose estimation results on 5 novel categories of Wild6D.", "description": "This table presents the results of category-level object pose estimation on five unseen categories from the Wild6D dataset.  It compares the proposed VFM-6D method against several other methods (SPD, SGPA, DualPoseNet, GPV-Pose, PoseContrast, ZSP), showing the accuracy of pose estimation (measured in degrees and centimeters) at different levels of accuracy thresholds (5\u00b0 and 10\u00b0 for rotation error, 2cm and 5cm for translation error). The results demonstrate VFM-6D's superior performance on unseen categories.", "section": "4.3 Main Results"}]