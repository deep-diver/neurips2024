[{"figure_path": "wiK6bwuxjE/tables/tables_5_1.jpg", "caption": "Table 1: Benchmarking on the KITTI 3D test set. All experiments adopt AP<sub>R40</sub> metric with an IoU threshold of 0.7. Best in bold, second underlined.", "description": "This table presents a comparison of the proposed MonoMAE method against several state-of-the-art monocular 3D object detection methods on the KITTI 3D test set.  The performance is evaluated using the Average Precision (AP) at Recall 40 (R40) metric with an Intersection over Union (IoU) threshold of 0.7.  The results are shown separately for easy, moderate, and hard difficulty levels, and for both 3D and Bird's Eye View (BEV) object detection. The best performing method for each metric is highlighted in bold, and the second-best is underlined.", "section": "4 Experiments"}, {"figure_path": "wiK6bwuxjE/tables/tables_6_1.jpg", "caption": "Table 2: Ablation study of technical designs in MonoMAE on the KITTI 3D val set. \u2018NOQG\u2019, \u2018DAM\u2019, and \u2018CN\u2019 denote Non-Occluded Query Grouping, Depth-Aware Masking, and Completion Network, respectively. The symbol * indicates the baseline. The best results are highlighted in bold.", "description": "This table presents the ablation study results on the KITTI 3D validation set to analyze the impact of different components of MonoMAE.  It shows the performance (AP3D and APBEV) under various configurations of the model, including with and without the Non-Occluded Query Grouping (NOQG), Depth-Aware Masking (DAM), and Completion Network (CN). The baseline model (*) includes only NOQG. The results help to understand the contribution of each component to the overall performance.", "section": "4.3 Ablation Study"}, {"figure_path": "wiK6bwuxjE/tables/tables_7_1.jpg", "caption": "Table 3: Ablation study of masking strategies on the KITTI 3D val set. The best results are in bold.", "description": "This table presents the results of an ablation study that examines the effectiveness of different masking strategies used in the MonoMAE model.  Three masking strategies are compared: Image Masking, Query Masking (without Depth-Aware), and Query Masking (with Depth-Aware). The table shows the Average Precision (AP) for different levels of object occlusion (Easy, Moderate, Hard) in both 3D and Bird's Eye View (BEV) perspectives. The results demonstrate that Depth-Aware Query Masking significantly improves the performance of the model compared to the other methods.", "section": "4.3 Ablation Study"}, {"figure_path": "wiK6bwuxjE/tables/tables_7_2.jpg", "caption": "Table 4: Ablation study of the loss functions on the KITTI 3D val set.  L<sub>occ</sub> and L<sub>com</sub> refer to the occlusion classification loss and the completion loss, respectively. The best results are in bold.", "description": "This table shows the ablation study results on the KITTI 3D validation set by varying the loss functions used in MonoMAE.  It compares the performance (AP3D and APBEV) with different combinations of the occlusion classification loss (L<sub>occ</sub>) and the completion loss (L<sub>com</sub>). Row 3 shows the best overall performance, indicating that using both loss functions is crucial for optimal results.", "section": "4.3 Ablation Study"}, {"figure_path": "wiK6bwuxjE/tables/tables_8_1.jpg", "caption": "Table 5: Comparison on inference speed of several monocular 3D detection methods. Ours* denotes the proposed MonoMAE without including the Completion Network.", "description": "This table compares the inference time in milliseconds (ms) of five different monocular 3D object detection methods: GUPNet [37], MonoDTR [19], MonoDETR [66], MonoMAE without the Completion Network (Ours*), and MonoMAE with the Completion Network (Ours).  The results show that MonoMAE (with or without the completion network) generally has a faster inference speed than the other methods.", "section": "4 Experiments"}, {"figure_path": "wiK6bwuxjE/tables/tables_8_2.jpg", "caption": "Table 6: Cross-dataset evaluations that perform training on the KITTI train set, and testing on the KITTI val and nuScenes val sets. We adopt the evaluation metric mean absolute error of the depth (\u2193). Best is highlighted in bold, and second underlined.", "description": "This table presents the results of cross-dataset evaluations, where the model is trained on the KITTI dataset and tested on both KITTI validation and nuScenes frontal validation sets.  The evaluation metric used is the mean absolute depth error, with lower values indicating better performance.  The table compares the performance of MonoMAE against several other state-of-the-art monocular 3D object detection methods, categorized by depth range (0-20m, 20-40m, 40-\u221em) and overall performance across all depth ranges.", "section": "4.4 Discussions"}]