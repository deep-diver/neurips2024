[{"figure_path": "njvPjG0BfK/figures/figures_1_1.jpg", "caption": "Figure 1: Our method (HardCore) achieves the best trade-off of inference cost and SAT-problem hardness.", "description": "This figure compares different SAT problem generation methods in terms of their computational cost and the hardness of the generated problems. The x-axis represents the relative hardness of the generated problems compared to original problems, while the y-axis represents the time it takes to generate each problem.  The plot shows that HardCore achieves the best balance between generating hard problems and computational efficiency. While HardSATGEN produces very hard problems, it has a significantly higher computational cost. In contrast, G2MILP and W2SAT are much faster but fail to generate sufficiently hard problems.", "section": "1 Introduction"}, {"figure_path": "njvPjG0BfK/figures/figures_3_1.jpg", "caption": "Figure 2: Core Refinement. The core refinement process comes in two steps: (1) Core Prediction, in which we use a GNN-based architecture to identify the core of the generated instance; and (2) De-Coring, in which we add a non-conflicted literal to a clause in the core, rendering the core satisfiable and giving rise to a new, harder minimal unsatisfiable subset (core). As steps (1) and (2) are repeated, the easiest core of the problem is gradually refined, raising the hardness of the generated instances.", "description": "This figure illustrates the core refinement process, a two-step iterative process used to generate harder instances. First, a GNN predicts the core of a generated instance.  Then, in the 'De-coring' step, a non-conflicting literal is added to a clause within the core. This makes the core satisfiable, leading to a new, smaller unsatisfiable subset (a harder core). The process repeats until the core is deemed sufficiently hard.", "section": "5.1 Generating Hard Instances"}, {"figure_path": "njvPjG0BfK/figures/figures_4_1.jpg", "caption": "Figure 3: Core Prediction GNN Architecture. We construct our GNN using three parallel message passing neural networks (MPNN) whose calculated node embeddings are aggregated at each layer to form the layer's node embeddings. Readout is done by taking the sigmoid of a fully-connected layer on clause node embeddings and thresholding. Training is supervised by taking a binary classification loss between the true core labels and the clause nodes' core prediction probabilities.", "description": "This figure illustrates the architecture of the Graph Neural Network (GNN) used for core prediction.  The GNN consists of three parallel message-passing neural networks (MPNNs), each processing a different type of edge in the literal-clause graph (LCG). These MPNNs process literal-literal edges, literal-to-clause edges, and clause-to-literal edges. The outputs of these MPNNs are aggregated at each layer, and the final layer's node embeddings are passed through a fully-connected layer with a sigmoid activation function to produce a core membership probability for each clause node. A binary classification loss (comparing predicted probabilities to true core labels) is used during training.", "section": "5.2 Core Prediction"}, {"figure_path": "njvPjG0BfK/figures/figures_7_1.jpg", "caption": "Figure 1: Our method (HardCore) achieves the best trade-off of inference cost and SAT-problem hardness.", "description": "This figure shows a comparison of different SAT problem generation methods in terms of their inference cost (time taken to generate a problem) and the hardness of the generated problems.  The x-axis represents the hardness of the generated problem instances as a percentage of the hardness of the original instances (100% represents the original hardness).  The y-axis represents the inference cost per instance, measured in seconds, minutes, or hours. The figure demonstrates that the HardCore method achieves a superior balance between cost and problem hardness, generating problems that are significantly harder than those produced by other methods, at a significantly lower cost.", "section": "1 Introduction"}, {"figure_path": "njvPjG0BfK/figures/figures_7_2.jpg", "caption": "Figure 1: Our method (HardCore) achieves the best trade-off of inference cost and SAT-problem hardness.", "description": "This figure shows a comparison of different SAT problem generation methods in terms of their computational cost (inference cost) and the hardness of the generated problems. The x-axis represents the instance hardness as a percentage of the original problem's hardness, while the y-axis represents the time cost per instance.  The plot shows that the HardCore method achieves the best balance between generating hard problems and maintaining a low computational cost. Other methods like HardSATGEN produce harder problems but at a significantly higher cost, while methods like G2MILP and W2SAT produce significantly easier problems.", "section": "1 Introduction"}, {"figure_path": "njvPjG0BfK/figures/figures_13_1.jpg", "caption": "Figure 1: Our method (HardCore) achieves the best trade-off of inference cost and SAT-problem hardness.", "description": "The figure shows a comparison of different methods for generating hard SAT problems, plotting instance hardness against the time cost per instance.  HardCore is shown to achieve the best balance between generating hard problems and having a reasonable inference cost.  Other methods either generate relatively easy problems or are computationally very expensive, highlighting the efficiency of the HardCore approach.", "section": "1 Introduction"}, {"figure_path": "njvPjG0BfK/figures/figures_14_1.jpg", "caption": "Figure 7: Mean MAE on Runtime Prediction. Boxplot-view of results presented in Table 2 for LEC data.", "description": "This figure shows box plots of Mean Absolute Error (MAE) for runtime prediction across different sizes of training datasets.  It compares the performance of using the HardCore method for data augmentation against other methods (Original, HardSATGEN-50, HardSATGEN-Strict, W2SAT). The x-axis represents the size of the original training dataset used, and the y-axis represents the MAE.  The box plots show the median, quartiles, and range of the MAE values for each method and dataset size, allowing for a visual comparison of the effectiveness of different data augmentation techniques in improving runtime prediction accuracy.", "section": "6.2.4 Question 4: Can we successfully augment training data with the method's generated data for machine learning?"}]