{"references": [{"fullname_first_author": "Martin Abadi", "paper_title": "Deep Learning with Differential Privacy", "publication_date": "2016-00-00", "reason": "This paper is foundational for privacy-preserving machine learning, providing a theoretical basis for many subsequent works on mitigating privacy risks in LLMs."}, {"fullname_first_author": "Nicholas Carlini", "paper_title": "Membership Inference Attacks From First Principles", "publication_date": "2022-00-00", "reason": "This paper provides a foundational theoretical framework for membership inference attacks, which is central to the paper's methodology."}, {"fullname_first_author": "Nicholas Carlini", "paper_title": "Quantifying Memorization Across Neural Language Models", "publication_date": "2022-00-00", "reason": "This paper is highly relevant due to its focus on the memorization capabilities of LLMs, a crucial aspect of the proposed SPV-MIA attack."}, {"fullname_first_author": "Fatemehsadat Mireshghallah", "paper_title": "An empirical analysis of memorization in fine-tuned autoregressive language models", "publication_date": "2022-00-00", "reason": "This paper directly addresses the memorization phenomenon in LLMs, which is central to the theoretical foundation of SPV-MIA."}, {"fullname_first_author": "Justus Mattern", "paper_title": "Membership Inference Attacks against Language Models via Neighbourhood Comparison", "publication_date": "2023-00-00", "reason": "This paper presents a related MIA approach against LLMs, providing a comparative context for the novel SPV-MIA method."}]}