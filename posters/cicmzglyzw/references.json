{"references": [{"fullname_first_author": "Aitor Lewkowycz", "paper_title": "Solving quantitative reasoning problems with language models", "publication_date": "2022-12-31", "reason": "This paper is foundational to the current work as it explores the capabilities of LLMs in solving quantitative reasoning problems, providing context for the study's focus on enhancing these capabilities."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-14", "reason": "This paper introduces the GSM8K dataset, which serves as a primary benchmark for evaluating mathematical reasoning abilities in LLMs and is used in the current study."}, {"fullname_first_author": "Dan Hendrycks", "paper_title": "Measuring mathematical problem solving with the math dataset", "publication_date": "2021-12-31", "reason": "This paper introduces the MATH dataset, another key benchmark in the field of mathematical reasoning for LLMs, and is used for comparison in the current study."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-09", "reason": "This paper introduces LLaMA-2, one of the LLMs used in this study's experiments, highlighting its relevance to the research on large language model capabilities."}, {"fullname_first_author": "Albert Q. Jiang", "paper_title": "Mistral 7b", "publication_date": "2023-10-06", "reason": "This paper introduces Mistral-7B, another LLM used in the study's experiments, providing a comparison point for evaluating the proposed approach."}]}