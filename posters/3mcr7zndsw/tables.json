[{"figure_path": "3mCr7ZNdSw/tables/tables_7_1.jpg", "caption": "Table 1: We compare synthetic tabular data generated by our Algorithm 1 with baselines, all under the same privacy budget \u20ac = 5.1. We demonstrate them on the US Census data derived from the American Community Survey (ACS) with various evaluation metrics. These metrics range from 0 to 1, with higher scores indicating better performance. Since Employment has only one numerical column and CorrSim requires at least two numerical columns, we skip its values. The highest scores are highlighted in bold. If two methods have the same average score, only the one with lower standard deviation is highlighted. We remark that KSComp and CorrSim are less significant since they are designed for numerical columns. However, the benchmark datasets contain a limited number of numerical columns, with the majority being categorical (see Table 2).", "description": "The table compares the performance of different differentially private (DP) mechanisms for generating synthetic tabular data using the US Census data.  Algorithm 1 is compared against SliceWass, DP-SGD, PATE, and MERF across five different tasks (Income, Coverage, Mobility, Employment, TravelTime), using various evaluation metrics. The results indicate the relative quality of synthetic data produced by different methods.", "section": "Numerical Experiments"}, {"figure_path": "3mCr7ZNdSw/tables/tables_19_1.jpg", "caption": "Table 2: Dataset details. In addition to the described columns, each dataset has a binary outcome column, which is used by the evaluation metric LogitRegression.", "description": "This table presents details of the five datasets used in the paper's experiments.  Each dataset includes a target column used for the LogitRegression evaluation metric. The table shows the number of records, the total number of columns, and the breakdown of columns into categorical and numerical features for each dataset.", "section": "4.1 Synthetic Tabular Data"}, {"figure_path": "3mCr7ZNdSw/tables/tables_20_1.jpg", "caption": "Table 1: We compare synthetic tabular data generated by our Algorithm 1 with baselines, all under the same privacy budget \u20ac = 5.1. We demonstrate them on the US Census data derived from the American Community Survey (ACS) with various evaluation metrics. These metrics range from 0 to 1, with higher scores indicating better performance. Since Employment has only one numerical column and CorrSim requires at least two numerical columns, we skip its values. The highest scores are highlighted in bold. If two methods have the same average score, only the one with lower standard deviation is highlighted. We remark that KSComp and CorrSim are less significant since they are designed for numerical columns. However, the benchmark datasets contain a limited number of numerical columns, with the majority being categorical (see Table 2).", "description": "This table compares the performance of the proposed algorithm (Algorithm 1) against four baseline methods (SliceWass, DP-SGD, PATE, and MERF) for generating synthetic tabular data under a privacy budget of 5.1.  The comparison uses five datasets from the US Census American Community Survey and several evaluation metrics assessing the similarity between the synthetic and real data distributions.", "section": "Numerical Experiments"}]