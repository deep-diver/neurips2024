[{"figure_path": "09RKw0vXjR/figures/figures_4_1.jpg", "caption": "Figure 1: (a)-(e): Comparisons of log processing times for each dataset and k. (f): Comparison of number of gradient computations on gisette. (g): Comparisons of log processing times for gisette with a large step size. Some results of AccIHT are omitted since they could not converge.", "description": "This figure compares the performance of the proposed FastIHT method against three other methods (IHT, RegIHT, and AccIHT) across five datasets and various values of k (sparsity level).  Subfigures (a) through (e) show the log processing times for each dataset. Subfigure (f) shows the number of gradient computations for the gisette dataset, highlighting the significant reduction achieved by FastIHT. Subfigure (g) demonstrates the performance of FastIHT with a larger step size on the gisette dataset.", "section": "5.1 Processing Time"}, {"figure_path": "09RKw0vXjR/figures/figures_4_2.jpg", "caption": "Figure 1: (a)-(e): Comparisons of log processing times for each dataset and k. (f): Comparison of number of gradient computations on gisette. (g): Comparisons of log processing times for gisette with a large step size. Some results of AccIHT are omitted since they could not converge.", "description": "This figure compares the performance of the proposed FastIHT method against several baselines (IHT, RegIHT, and AccIHT) across five datasets (gisette, robert, ledgar, real-sim, and epsilon) and various values of k (sparsity level).  Subfigures (a) through (e) show log processing times for each dataset, demonstrating that FastIHT is significantly faster. Subfigure (f) specifically illustrates the substantial reduction in the number of gradient computations achieved by FastIHT on the gisette dataset. Finally, subfigure (g) shows the consistent speed advantage of FastIHT even when using a larger step size.  Note that some results for AccIHT are missing due to failure to converge in those instances.", "section": "5.1 Processing Time"}, {"figure_path": "09RKw0vXjR/figures/figures_8_1.jpg", "caption": "Figure 1: (a)-(e): Comparisons of log processing times for each dataset and k. (f): Comparison of number of gradient computations on gisette. (g): Comparisons of log processing times for gisette with a large step size. Some results of AccIHT are omitted since they could not converge.", "description": "This figure compares the performance of different algorithms for feature selection tasks. Subfigures (a) through (e) show the log processing time of five datasets (gisette, robert, ledgar, real-sim, and epsilon) for different values of k (the number of selected features). Subfigure (f) shows the number of gradient computations required by the proposed method (FastIHT) and plain IHT for the gisette dataset. Subfigure (g) shows log processing times for the gisette dataset when the step size is increased. The results show that the proposed method is significantly faster than existing methods for all datasets and k values, and its performance is robust even with a larger step size.", "section": "5.1 Processing Time"}]