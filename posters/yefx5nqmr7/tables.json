[{"figure_path": "yeFx5NQmr7/tables/tables_6_1.jpg", "caption": "Table 1: We report the mean and standard deviations of the square errors as indicated in Equation 8. We exhibit the impacts of our dissipation unit \u03a6d and contrastive loss Lcon. Both of the components enable EUNet to obtain lower errors and smaller standard deviations, leading to higher accuracy and generalization ability.", "description": "This table presents the quantitative results of the EUNet model's performance. It shows the mean and standard deviation of square errors calculated using Equation 8, comparing the full EUNet model with versions that exclude the dissipation unit (\u03a6d) and the contrastive loss (Lcon).  The results are broken down by material type (Silk, Leather, Denim, Cotton) and overall performance. Lower values indicate better performance.", "section": "4.1 Learning Constitutive Laws"}, {"figure_path": "yeFx5NQmr7/tables/tables_7_1.jpg", "caption": "Table 2: Euclidean error (mm) on sampled Cloth3D [2] with sequence length of 80 frames. The garment-to-human collision rates are displayed under Collision. We use the garment-wise learning pipeline to train MGN [24] and LayersNet [28]. We further train a simulator based on MGN constrained by Saint Venant Kirchhoff (StVK) elastic model and the bending model as mentioned in [26], which is denoted by MGN-S+PHYS. In addition, based on the disentangled scheme, we combine our EUNet with energy optimization scheme and train models denoted by MGN-S+EUNet and MGN-H+EUNet, where MGN-H is the hierarchical graph neural network adopted in HOOD[10]. Simulators constrained by our EUNet achieve superior performance without access to the ground truth garments.", "description": "This table compares the performance of different garment animation methods on the Cloth3D dataset.  The methods include those using garment-wise supervised learning (MGN and LayersNet), a physics-based model (MGN-S+PHYS), and the proposed disentangled approach using EUNet (MGN-S+EUNet and MGN-H+EUNet). The metrics reported are Euclidean error (in mm) and collision rate (%). The results show that the methods using EUNet achieve better performance, especially in terms of collision rate, suggesting that the disentangled approach leads to more physically plausible garment animations.", "section": "4.2 Animating Garments"}, {"figure_path": "yeFx5NQmr7/tables/tables_13_1.jpg", "caption": "Table 2: Euclidean error (mm) on sampled Cloth3D [2] with sequence length of 80 frames. The garment-to-human collision rates are displayed under Collision. We use the garment-wise learning pipeline to train MGN [24] and LayersNet [28]. We further train a simulator based on MGN constrained by Saint Venant Kirchhoff (StVK) elastic model and the bending model as mentioned in [26], which is denoted by MGN-S+PHYS. In addition, based on the disentangled scheme, we combine our EUNet with energy optimization scheme and train models denoted by MGN-S+EUNet and MGN-H+EUNet, where MGN-H is the hierarchical graph neural network adopted in HOOD[10]. Simulators constrained by our EUNet achieve superior performance without access to the ground truth garments.", "description": "This table compares the performance of different garment animation methods on the Cloth3D dataset.  It shows Euclidean error and collision rates for various methods, including those using garment-wise learning and the proposed disentangled approach with EUNet. The results demonstrate that models using the EUNet-based disentangled scheme achieve superior performance compared to other methods, especially when considering long-term predictions and physical plausibility.", "section": "4.2 Animating Garments"}, {"figure_path": "yeFx5NQmr7/tables/tables_14_1.jpg", "caption": "Table 2: Euclidean error (mm) on sampled Cloth3D [2] with sequence length of 80 frames. The garment-to-human collision rates are displayed under Collision. We use the garment-wise learning pipeline to train MGN [24] and LayersNet [28]. We further train a simulator based on MGN constrained by Saint Venant Kirchhoff (StVK) elastic model and the bending model as mentioned in [26], which is denoted by MGN-S+PHYS. In addition, based on the disentangled scheme, we combine our EUNet with energy optimization scheme and train models denoted by MGN-S+EUNet and MGN-H+EUNet, where MGN-H is the hierarchical graph neural network adopted in HOOD[10]. Simulators constrained by our EUNet achieve superior performance without access to the ground truth garments.", "description": "This table presents a comparison of Euclidean error and collision rates for different garment animation methods on the Cloth3D dataset.  The methods include those using garment-wise supervised learning (MGN and LayersNet), physics-based simulations (MGN-S+PHYS), and the proposed disentangled approach combining EUNet with energy optimization (MGN-S+EUNet and MGN-H+EUNet). The results show the superior performance of the proposed method in terms of lower errors and collision rates, even without access to ground truth garment data.", "section": "4.2 Animating Garments"}, {"figure_path": "yeFx5NQmr7/tables/tables_14_2.jpg", "caption": "Table 1: We report the mean and standard deviations of the square errors as indicated in Equation 8. We exhibit the impacts of our dissipation unit \u03a6d and contrastive loss Lcon. Both of the components enable EUNet to obtain lower errors and smaller standard deviations, leading to higher accuracy and generalization ability.", "description": "This table presents the quantitative results of the EUNet model's performance. It compares the mean and standard deviation of square errors obtained under different configurations of the model: with and without the dissipation unit and contrastive loss. The results demonstrate the impact of these components on the model's accuracy and generalization ability.", "section": "4.1 Learning Constitutive Laws"}]