[{"figure_path": "6ArNmbMpKF/figures/figures_8_1.jpg", "caption": "Figure 1: 7-person, 14-day rosters under various \u025b. Algorithms parameters: potential function is negative entropy parameterized by b = 1; K = 1.1\u016b/(yb), \u03b4 = .01, T = 104. Other settings follow Theorem 3.10. Results reported are averages of 50 runs. Strong duality holds due to linearity.", "description": "This figure shows the workforce scheduling results under different privacy levels (\u025b). Each cell in the heatmap represents the probability of assigning a worker to a specific day. The rightmost heatmap shows the optimal non-private solution, while others illustrate how the solution changes with different privacy parameters. The algorithm parameters include the potential function (negative entropy), hyperparameters (b, K, \u03b4, T), and the number of runs.", "section": "5.1 Workforce scheduling"}, {"figure_path": "6ArNmbMpKF/figures/figures_8_2.jpg", "caption": "Figure 3: K_constant v.s. optimality & constraint violations. Settings are the same as in Figure 1 except K_constant. Shadow areas and error bars indicate 95% confidence interval.", "description": "This figure shows the impact of the hyperparameter K_constant on the performance of three different algorithms for solving the resource allocation problem under Joint Differential Privacy (JDP).  The x-axis represents the privacy parameter epsilon (\u03b5), while the y-axis on the left shows the optimality gap (the difference between the optimal objective value and the algorithm's objective value), and the y-axis on the right shows the total constraint violations. Two different values for K_constant are shown (1.1 and 2.0). The results suggest a trade-off between optimality and constraint violation: smaller K_constant leads to lower optimality gap but higher constraint violation.  Larger values of K_constant are more conservative, leading to higher optimality gaps but fewer constraint violations. The performance of the proposed algorithms (MD_12 and MD_neg.entr) is compared to the baseline algorithm (Hsu et al. 2016).", "section": "5.1 Workforce scheduling"}, {"figure_path": "6ArNmbMpKF/figures/figures_24_1.jpg", "caption": "Figure 3: K_constant v.s. optimality & constraint violations. Settings are the same as in Figure 1 except K_constant. Shadow areas and error bars indicate 95% confidence interval.", "description": "This figure shows the impact of the hyperparameter K_constant on the performance of three different algorithms for solving the resource allocation problem under joint differential privacy. The x-axis represents different values of K_constant, while the y-axis shows both the optimality gap and the total constraint violations.  The figure shows that a smaller K_constant leads to a smaller optimality gap but more constraint violations, and vice versa.  The trade-off between optimality and constraint violation is clearly illustrated across different values of the privacy parameter epsilon (\u03b5).", "section": "5.1 Workforce scheduling"}, {"figure_path": "6ArNmbMpKF/figures/figures_25_1.jpg", "caption": "Figure 4: (prefix averaging) dual variables converge.", "description": "The figure shows the convergence of dual variables in the Noisy Dual Mirror Descent algorithm for different privacy parameters (\u03b5). The y-axis represents the L2 norm of the difference between the current dual variables and the optimal dual variables, normalized by the L2 norm of the optimal dual variables. The x-axis represents the training progress. The shaded areas represent the standard deviations of the dual variables over multiple runs. The figure indicates that the convergence speed increases with larger privacy parameters (\u03b5).", "section": "5.2 Assignment problem"}]