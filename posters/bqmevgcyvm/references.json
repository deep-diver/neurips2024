{"references": [{"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment Anything", "publication_date": "2023-00-00", "reason": "This paper introduces the Segment Anything Model (SAM), a foundation model for image segmentation that is crucial to VideoLISA's architecture."}, {"fullname_first_author": "Xin Lai", "paper_title": "LISA: Reasoning Segmentation via Large Language Model", "publication_date": "2023-00-00", "reason": "This paper introduces LISA, an image reasoning segmentation method that serves as the basis for VideoLISA's image segmentation module."}, {"fullname_first_author": "Anna Khoreva", "paper_title": "Video object segmentation with language referring expressions", "publication_date": "2019-12-06", "reason": "This paper is foundational to the field of referring video object segmentation, a key task that VideoLISA addresses."}, {"fullname_first_author": "Kirill Gavrilyuk", "paper_title": "Actor and action video segmentation from a sentence", "publication_date": "2018-00-00", "reason": "This paper introduces the referring video object segmentation task and benchmark, providing a critical context for VideoLISA's evaluation."}, {"fullname_first_author": "Henghui Ding", "paper_title": "MeViS: A large-scale benchmark for video segmentation with motion expressions", "publication_date": "2023-00-00", "reason": "This paper introduces MeViS, a benchmark dataset specifically designed for evaluating video segmentation models that incorporate motion understanding, directly relevant to VideoLISA's capabilities."}]}