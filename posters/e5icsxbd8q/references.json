{"references": [{"fullname_first_author": "Lucas Bourtoule", "paper_title": "Machine unlearning", "publication_date": "2021-00-00", "reason": "This paper provides a foundational overview of machine unlearning, which is the core problem that this paper aims to address in the context of LLMs."}, {"fullname_first_author": "Pratyush Maini", "paper_title": "TOFU: A task of fictitious unlearning for LLMs", "publication_date": "2024-00-00", "reason": "This paper introduces a new benchmark dataset and task for evaluating LLM unlearning, providing a crucial resource for evaluating the proposed method's effectiveness."}, {"fullname_first_author": "Nathaniel Li", "paper_title": "The WMDP benchmark: Measuring and reducing malicious use with unlearning", "publication_date": "2024-00-00", "reason": "This paper introduces a benchmark dataset and task for evaluating LLM unlearning focused on hazardous knowledge, which is directly compared against in the experimental results."}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This foundational paper highlights the few-shot learning capabilities of LLMs, which is a key characteristic exploited in the proposed ECO framework."}, {"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-00-00", "reason": "This technical report details the architecture and capabilities of GPT-4, a large language model the proposed method is evaluated on, providing essential background on the target model."}]}