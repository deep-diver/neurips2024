<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Large Language Model Unlearning via Embedding-Corrupted Prompts &#183; NeurIPS 2024</title>
<meta name=title content="Large Language Model Unlearning via Embedding-Corrupted Prompts &#183; NeurIPS 2024"><meta name=description content="ECO prompts enable efficient LLM unlearning by corrupting prompts flagged for forgetting, achieving promising results across various LLMs and tasks with minimal side effects."><meta name=keywords content="Natural Language Processing,Large Language Models,üè¢ UC Santa Cruz,"><link rel=canonical href=https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/><link type=text/css rel=stylesheet href=/neurips2024/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/neurips2024/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/neurips2024/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/neurips2024/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/neurips2024/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/neurips2024/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/neurips2024/favicon-16x16.png><link rel=manifest href=/neurips2024/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/"><meta property="og:site_name" content="NeurIPS 2024"><meta property="og:title" content="Large Language Model Unlearning via Embedding-Corrupted Prompts"><meta property="og:description" content="ECO prompts enable efficient LLM unlearning by corrupting prompts flagged for forgetting, achieving promising results across various LLMs and tasks with minimal side effects."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posters"><meta property="article:published_time" content="2024-09-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-26T00:00:00+00:00"><meta property="article:tag" content="Natural Language Processing"><meta property="article:tag" content="Large Language Models"><meta property="article:tag" content="üè¢ UC Santa Cruz"><meta property="og:image" content="https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/cover.png"><meta name=twitter:title content="Large Language Model Unlearning via Embedding-Corrupted Prompts"><meta name=twitter:description content="ECO prompts enable efficient LLM unlearning by corrupting prompts flagged for forgetting, achieving promising results across various LLMs and tasks with minimal side effects."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posters","name":"Large Language Model Unlearning via Embedding-Corrupted Prompts","headline":"Large Language Model Unlearning via Embedding-Corrupted Prompts","abstract":"ECO prompts enable efficient LLM unlearning by corrupting prompts flagged for forgetting, achieving promising results across various LLMs and tasks with minimal side effects.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/neurips2024\/posters\/e5icsxbd8q\/","author":{"@type":"Person","name":"AI Paper Reviewer"},"copyrightYear":"2024","dateCreated":"2024-09-26T00:00:00\u002b00:00","datePublished":"2024-09-26T00:00:00\u002b00:00","dateModified":"2024-09-26T00:00:00\u002b00:00","keywords":["Natural Language Processing","Large Language Models","üè¢ UC Santa Cruz"],"mainEntityOfPage":"true","wordCount":"7618"}]</script><meta name=author content="AI Paper Reviewer"><link href=https://neurips.cc/ rel=me><link href=https://x.com/NeurIPSConf rel=me><link href rel=me><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://x.com/algo_diver/ rel=me><script src=/neurips2024/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/neurips2024/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/neurips2024/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/neurips2024/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/neurips2024/ class="text-base font-medium text-gray-500 hover:text-gray-900">NeurIPS 2024</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/neurips2024/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Oral
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/neurips2024/oral-ai-applications/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) AI Applications</p></a><a href=/neurips2024/oral-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) AI Theory</p></a><a href=/neurips2024/oral-image-generation/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Image Generation</p></a><a href=/neurips2024/oral-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Large Language Models</p></a><a href=/neurips2024/oral-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Others</p></a><a href=/neurips2024/oral-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Reinforcement Learning</p></a></div></div></div></div><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Spotlight
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/neurips2024/spotlight-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) AI Theory</p></a><a href=/neurips2024/spotlight-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Large Language Models</p></a><a href=/neurips2024/spotlight-optimization/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Optimization</p></a><a href=/neurips2024/spotlight-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Others</p></a><a href=/neurips2024/spotlight-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Reinforcement Learning</p></a></div></div></div></div><a href=/neurips2024/posters/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Posters</p></a><a href=/neurips2024/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/neurips2024/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Oral</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/neurips2024/oral-ai-applications/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) AI Applications</p></a></li><li class=mt-1><a href=/neurips2024/oral-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) AI Theory</p></a></li><li class=mt-1><a href=/neurips2024/oral-image-generation/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Image Generation</p></a></li><li class=mt-1><a href=/neurips2024/oral-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Large Language Models</p></a></li><li class=mt-1><a href=/neurips2024/oral-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Others</p></a></li><li class=mt-1><a href=/neurips2024/oral-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Reinforcement Learning</p></a></li><li class=mb-2></li><li class=mt-1><a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Spotlight</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/neurips2024/spotlight-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) AI Theory</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Large Language Models</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-optimization/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Optimization</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Others</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Reinforcement Learning</p></a></li><li class=mb-2></li><li class=mt-1><a href=/neurips2024/posters/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Posters</p></a></li><li class=mt-1><a href=/neurips2024/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/neurips2024/posters/e5icsxbd8q/cover_hu8699031557834385817.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/>NeurIPS 2024</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/posters/>Posters</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/posters/e5icsxbd8q/>Large Language Model Unlearning via Embedding-Corrupted Prompts</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Large Language Model Unlearning via Embedding-Corrupted Prompts</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time><span class="px-2 text-primary-500">&#183;</span><span>7618 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">36 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_posters/e5icsXBD8Q/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_posters/e5icsXBD8Q/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/natural-language-processing/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Natural Language Processing
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/large-language-models/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Large Language Models
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/-uc-santa-cruz/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ UC Santa Cruz</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviewer" src=/neurips2024/img/avatar_hu1344562329374673026.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviewer</div><div class="text-sm text-neutral-700 dark:text-neutral-400">As an AI, I specialize in crafting insightful blog content about cutting-edge research in the field of artificial intelligence</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://neurips.cc/ target=_blank aria-label=Homepage rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg fill="currentcolor" height="800" width="800" id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 491.398 491.398"><g><g id="Icons_19_"><path d="M481.765 220.422 276.474 15.123c-16.967-16.918-44.557-16.942-61.559.023L9.626 220.422c-12.835 12.833-12.835 33.65.0 46.483 12.843 12.842 33.646 12.842 46.487.0l27.828-27.832v214.872c0 19.343 15.682 35.024 35.027 35.024h74.826v-97.62c0-7.584 6.146-13.741 13.743-13.741h76.352c7.59.0 13.739 6.157 13.739 13.741v97.621h74.813c19.346.0 35.027-15.681 35.027-35.024V239.091l27.812 27.815c6.425 6.421 14.833 9.63 23.243 9.63 8.408.0 16.819-3.209 23.242-9.63 12.844-12.834 12.844-33.65.0-46.484z"/></g></g></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/NeurIPSConf target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href target=_blank aria-label=Line rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 14.707 14.707"><g><rect x="6.275" y="0" style="fill:currentColor" width="2.158" height="14.707"/></g></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/algo_diver/ target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#eco-prompt-method>ECO Prompt Method</a></li><li><a href=#unlearning-threat-model>Unlearning Threat Model</a></li><li><a href=#zeroth-order-opt>Zeroth-Order Opt.</a></li><li><a href=#llm-unlearning-tasks>LLM Unlearning Tasks</a></li><li><a href=#eco-limitations>ECO Limitations</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#eco-prompt-method>ECO Prompt Method</a></li><li><a href=#unlearning-threat-model>Unlearning Threat Model</a></li><li><a href=#zeroth-order-opt>Zeroth-Order Opt.</a></li><li><a href=#llm-unlearning-tasks>LLM Unlearning Tasks</a></li><li><a href=#eco-limitations>ECO Limitations</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>e5icsXBD8Q</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Chris Yuhao Liu et el.</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href="https://openreview.net/forum?id=e5icsXBD8Q" target=_blank role=button>‚Üó OpenReview
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://neurips.cc/virtual/2024/poster/94295 target=_blank role=button>‚Üó NeurIPS Homepage
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://huggingface.co/papers/2406.07933 target=_blank role=button>‚Üó Hugging Face
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href="https://huggingface.co/spaces/huggingface/paper-central?tab=tab-chat-with-paper&amp;paper_id=e5icsXBD8Q&amp;paper_from=neurips" target=_blank role=button>‚Üó Chat</a></p><audio controls><source src=https://ai-paper-reviewer.com/e5icsXBD8Q/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Large Language Models (LLMs) are powerful but can memorize sensitive information, raising concerns about privacy and safety. Unlearning, the process of removing unwanted knowledge from an LLM, is challenging due to the large model size and the potential for damaging unintended knowledge removal. Current methods often involve computationally expensive retraining or fine-tuning, which hinders their application on state-of-the-art models.</p><p>This paper introduces Embedding-Corrupted (ECO) Prompts, a novel unlearning framework. Instead of directly modifying the LLM, ECO prompts use a classifier to identify prompts containing unwanted information. These flagged prompts are then &lsquo;corrupted&rsquo; via modifications to their embeddings, learned offline via optimization. This approach achieves effective unlearning at nearly zero side effects across numerous LLMs, ranging from 0.5B to 236B parameters, without increasing computational costs. The superior efficiency and scalability of ECO offers a promising solution to the unlearning challenge for real-world LLM applications.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-fd4ed622bc54ba649643fd1aff1fa51b></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-fd4ed622bc54ba649643fd1aff1fa51b",{strings:[" ECO prompts offer a lightweight and efficient unlearning method for LLMs, outperforming existing gradient-based techniques. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-bc7512deca5a1f65d0f23897fb36fc92></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-bc7512deca5a1f65d0f23897fb36fc92",{strings:[" The method effectively mitigates knowledge entanglement and achieves promising unlearning results with virtually zero side effects. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-ec8b4266d842cf67511309bc4b85f12a></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-ec8b4266d842cf67511309bc4b85f12a",{strings:[" ECO prompts scale efficiently to LLMs with a vast number of parameters without additional computational costs. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial for researchers working on <strong>LLM safety and responsible AI</strong>, offering a novel, efficient, and scalable solution to the challenging problem of unlearning. Its focus on prompt manipulation rather than model retraining opens exciting avenues for future research in this critical area.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/figures_1_1.jpg alt></figure></p><blockquote><p>This figure illustrates the ECO (Embedding-Corrupted) Prompts framework for large language model unlearning. It shows a two-step process: First, a prompt classifier determines if an incoming prompt is within the scope of knowledge to be forgotten. Second, if the classifier flags the prompt for unlearning, the prompt embedding is corrupted using a learned corruption function (parameterized by œÉk) before being fed into the model. This corruption is learned offline via zeroth-order optimization. The figure highlights that this process does not involve updating the original LLM weights; instead, it modifies the input at inference time to achieve the unlearning effect. The difference between the original output and the unlearned output is displayed to emphasize the result of applying the corrupted prompt.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_7_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) on two benchmark datasets: WMDP (for unlearning) and MMLU (for retaining knowledge). The table compares the performance of several unlearning methods: original model, prompting, RMU, and the proposed ECO method. For each model, it shows the accuracy on four sub-tasks of WMDP and the overall accuracy on the MMLU dataset. The results demonstrate ECO&rsquo;s effectiveness in achieving near random-guessing accuracy on the WMDP (unlearning) task while maintaining performance on the MMLU (retaining knowledge) task, outperforming other baseline methods which often suffer from either low unlearning effectiveness or a significant drop in MMLU performance.</p></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">ECO Prompt Method<div id=eco-prompt-method class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#eco-prompt-method aria-label=Anchor>#</a></span></h4><p>The ECO Prompt method is a novel approach to large language model (LLM) unlearning that focuses on manipulating prompts during inference rather than modifying model weights. <strong>This lightweight method avoids the computational cost and potential risks associated with retraining or fine-tuning large models.</strong> It functions by first employing a prompt classifier to identify whether incoming prompts fall under the scope of the data intended for unlearning. If flagged, these prompts are selectively corrupted in their embedding space using a learned corruption function, preventing unwanted outputs. The use of a classifier enhances the system&rsquo;s efficiency and reduces the risk of unintended side effects, particularly in managing knowledge entanglement. This approach significantly reduces collateral damage and offers a practical solution for efficient and effective unlearning in LLMs, demonstrated by its scalability across various model sizes without additional cost. <strong>The offline learning of corruption parameters improves both efficiency and precision.</strong> This technique holds immense promise for promoting responsible and safe usage of LLMs by offering a robust yet minimally invasive unlearning approach.</p><h4 class="relative group">Unlearning Threat Model<div id=unlearning-threat-model class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#unlearning-threat-model aria-label=Anchor>#</a></span></h4><p>A robust unlearning threat model for large language models (LLMs) must consider various attack vectors. <strong>Adversarial attacks</strong>, aiming to manipulate the model into revealing sensitive information, are crucial. These could involve carefully crafted prompts designed to elicit specific responses or exploit vulnerabilities in the unlearning process itself. <strong>Data poisoning</strong>, where malicious data is injected into the training or unlearning datasets to compromise the model&rsquo;s integrity, presents another significant risk. Furthermore, the model&rsquo;s <strong>architecture</strong> itself could be a source of weakness, susceptible to attacks targeting specific parameters or layers to circumvent the unlearning mechanism. <strong>Implementation weaknesses</strong> in the unlearning algorithm can be exploited, leading to incomplete removal of sensitive data or unintentional side effects. A comprehensive threat model needs to evaluate these risks across different model architectures and unlearning strategies to enhance the safety and reliability of LLMs.</p><h4 class="relative group">Zeroth-Order Opt.<div id=zeroth-order-opt class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#zeroth-order-opt aria-label=Anchor>#</a></span></h4><p>Zeroth-order optimization, in the context of embedding-corrupted prompts for large language model (LLM) unlearning, offers a <strong>computationally efficient alternative</strong> to traditional gradient-based methods. Instead of directly calculating gradients, which are expensive for large LLMs, it estimates the impact of small changes to the prompt embeddings on the model&rsquo;s output. This is particularly useful for unlearning because it avoids the need for computationally demanding backpropagation. The <strong>offline learning phase</strong> of this approach is crucial; here, the optimal corruption parameter is determined before interacting with the model, eliminating any additional cost during inference. The strategy offers a compelling way to induce forgetting without directly modifying the model&rsquo;s weights, thus <strong>reducing the risk of catastrophic interference</strong> and enabling scalability to massive LLMs. However, this approach has inherent limitations such as the accuracy of the zeroth-order approximation and its dependence on a well-trained prompt classifier.</p><h4 class="relative group">LLM Unlearning Tasks<div id=llm-unlearning-tasks class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#llm-unlearning-tasks aria-label=Anchor>#</a></span></h4><p>LLM unlearning tasks present a significant challenge in aligning AI with human values and safety. <strong>Effective unlearning necessitates the ability to selectively remove knowledge from large language models (LLMs) without causing unintended side effects or degrading overall performance.</strong> These tasks can be categorized into various types, each requiring different strategies to address their unique challenges. For instance, <strong>entity unlearning</strong> aims to remove sensitive information about specific individuals, <strong>hazardous knowledge unlearning</strong> focuses on eliminating harmful or misleading information, while <strong>copyrighted content unlearning</strong> tackles the removal of data subject to intellectual property rights. Each task demands precise control and rigorous evaluation methods to ensure that the intended knowledge is successfully removed without compromising the utility of the LLM for other purposes. The development of robust and reliable unlearning techniques is crucial for establishing trust and promoting the responsible deployment of LLMs.</p><h4 class="relative group">ECO Limitations<div id=eco-limitations class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#eco-limitations aria-label=Anchor>#</a></span></h4><p>The ECO method, while promising for LLM unlearning, has limitations. <strong>It only works with models accessible via APIs</strong>, relying on a classifier and a corruption function, making it vulnerable to adversaries with direct model access. <strong>The prompt classifier&rsquo;s accuracy is critical</strong>, and a compromised classifier could lead to ineffective unlearning or unintended information removal. The method&rsquo;s reliance on a limited context window in the prompt classifier might allow attackers to bypass the system using carefully crafted prompts. <strong>The need for a task-specific surrogate metric (√ªr) limits generalizability</strong>, necessitating a task-agnostic method. Finally, <strong>the method&rsquo;s reliance on prompt corruption rather than direct weight modification raises concerns about its efficacy for certain tasks</strong> and the potential for unintended collateral damage to the model&rsquo;s general functionality.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/figures_6_1.jpg alt></figure></p><blockquote><p>This figure shows the trade-off between model utility and forget quality for two different LLMs (Phi-1.5 and Llama-2-7B-Chat) after unlearning different percentages (1%, 5%, and 10%) of the TOFU dataset. It compares the performance of the ECO method to several baseline unlearning methods (GA, GD, KL, PO, Prompting, NPO, NPO-KL, NPO-RT). The plot demonstrates that ECO achieves high forget quality with no loss in model utility, unlike most baseline methods which either fail to forget sufficiently or suffer significant utility loss.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/figures_21_1.jpg alt></figure></p><blockquote><p>This figure illustrates the ECO framework for large language model unlearning. It shows how a prompt classifier first identifies whether a given prompt should be forgotten (i.e., falls within the scope of the unlearning target). If it should be forgotten, the framework selectively corrupts dimensions within the tokens&rsquo; embeddings using a corruption function learned offline (through zeroth-order optimization). This corruption results in an output resembling the model&rsquo;s response had it never been trained on the data to be forgotten. Crucially, this method does not require updating the LLM&rsquo;s weights, just manipulating inputs during the inference stage.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/figures_29_1.jpg alt></figure></p><blockquote><p>This figure illustrates the ECO prompt unlearning framework. It shows how a classifier determines if a prompt should be unlearned, and if so, how corruption is applied to the prompt embedding before input to the LLM. This corruption prevents the model from recalling information without requiring any changes to its internal weights.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/figures_40_1.jpg alt></figure></p><blockquote><p>This figure shows the relationship between the number of parameters in a language model and its performance on two benchmarks (WMDP and MMLU) after applying an unlearning technique. The x-axis represents the number of parameters, and the y-axis shows the average accuracy. It visualizes data from Tables 21 and 22, demonstrating how the unlearning method&rsquo;s effectiveness changes as model size increases.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/figures_40_2.jpg alt></figure></p><blockquote><p>This figure shows the results of probing experiments using linear probes trained on the logits of three different LLMs: Zephyr-7B, Yi-34B-Chat, and Mixtral-8x7B-Instruct. The goal was to assess the model&rsquo;s ability to prevent knowledge recovery after applying ECO (Embedding-Corrupted Prompts) unlearning. The x-axis represents the three sub-categories of the WMDP (Winning at Machine Deception Prediction) benchmark dataset (Bio, Chem, Cyber). The y-axis represents the accuracy of the linear probe. The dashed line indicates random chance. The figure demonstrates that before unlearning (Original), the probes achieve relatively high accuracy. After unlearning with ECO (Unlearned), however, the accuracy drops to near random chance, indicating that ECO successfully prevents the extraction of sensitive information directly from the model&rsquo;s logits.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/figures_55_1.jpg alt></figure></p><blockquote><p>This figure illustrates the ECO (Embedding-Corrupted) prompts method for unlearning in LLMs. It shows a two-step process: first, a classifier determines if an incoming prompt is related to the target knowledge to be forgotten; second, if it is, the prompt&rsquo;s embedding is corrupted using a learned corruption function before being fed to the LLM. This corruption is learned offline and doesn&rsquo;t require any changes to the LLM&rsquo;s weights, creating an &lsquo;unlearned state&rsquo; during inference. The figure visually depicts the flow of the prompt through the classifier, the corruption function, and finally into the LLM to generate an unlearned output.</p></blockquote></details><details><summary>More on tables</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_7_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for the Zephyr-7B model on three MMLU subsets (economics, law, physics) and their corresponding retain sets (econometrics, jurisprudence, math) after applying different unlearning methods: original model, prompting baseline, RMU, and ECO. The results show the effectiveness of ECO in achieving near-perfect forgetting (accuracy close to random guessing) on the forget subsets while maintaining the original performance on the retain subsets. In contrast, the prompting baseline negatively impacts accuracy on forget subsets, and RMU achieves good forgetting but with a significant decrease in accuracy on retain subsets.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_8_1.jpg alt></figure></p><blockquote><p>This table compares the performance of the proposed ECO method against various baseline methods on two copyrighted content unlearning tasks: BBC News and Harry Potter. The comparison is done using metrics focusing on similarity to a model that hasn&rsquo;t seen the forgotten data (average similarity gap, ASG), generation quality (perplexity, PPL, unique tokens), and utility (performance on general tasks). The results demonstrate ECO&rsquo;s ability to maintain high similarity to the retained model while achieving good unlearning performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_24_1.jpg alt></figure></p><blockquote><p>This table presents the sizes of the training and testing sets used for training the prompt classifiers. It breaks down the data into the forget set (D<sub>f</sub>), retain set (D<sub>r</sub>), and general set (D<sub>g</sub>) for each of the tasks (TOFU, WMDP, MMLU, HP Book, and BBC News). The sizes of the forget sets vary for the TOFU dataset (1%, 5%, 10% of the data). For the other datasets, the forget and retain sets are clearly defined. The general set (D<sub>g</sub>) is used to test the classifier&rsquo;s generalization ability on unseen data.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_24_2.jpg alt></figure></p><blockquote><p>This table presents the performance of prompt classifiers in identifying prompts belonging to the unlearning target (forget set) and unrelated prompts (retain set), with and without a threshold. It evaluates the false negative rate (FNR), the rate at which the classifier fails to correctly identify prompts from the forget set, and the false positive rate (FPR), the rate at which the classifier incorrectly identifies prompts from the retain set. Results are shown for training data, test data from the forget and retain sets, and out-of-distribution (OOD) data from eleven other NLP benchmarks.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_24_3.jpg alt></figure></p><blockquote><p>This table shows the performance of prompt classifiers in identifying whether a prompt belongs to the forget set (false negative rate) or the retain set (false positive rate), both before and after applying a threshold. The false negative rate represents the classifier&rsquo;s failure to identify prompts that should be forgotten, while the false positive rate reflects incorrect identification of prompts that should be retained. The table shows results on various datasets with and without a thresholding process.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_25_1.jpg alt></figure></p><blockquote><p>This table presents the false negative rate (FNR) and false positive rate (FPR) for a prompt classifier used in the ECO method. The FNR shows the proportion of prompts intended for forgetting that were incorrectly classified as belonging to the retained set. The FPR indicates the proportion of retained prompts that were misclassified as forget prompts. Results are shown for various datasets with different amounts of data for training (Train) and testing (Test). The &lsquo;Dg&rsquo; column shows the FPR on an out-of-distribution dataset (eleven NLP benchmarks from Table 9) which tests for the impact on generalizability.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_25_2.jpg alt></figure></p><blockquote><p>This table presents the results of evaluating the performance of MMLU classifiers on highly related subjects. It breaks down the false positive and false negative rates for each sub-category within the three main categories (Economics, Law, Physics). The false positive rate represents how often the classifier incorrectly identifies a prompt from the retain set as belonging to the forget set. Conversely, the false negative rate shows how often the classifier fails to correctly identify a prompt from the forget set.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_27_1.jpg alt></figure></p><blockquote><p>This table lists eleven benchmark datasets commonly used for evaluating large language models. These datasets cover a range of tasks and domains, and are used in the paper to assess the general capabilities of LLMs after the unlearning process. The use of this out-of-distribution (OOD) data helps determine if the unlearning process has negatively impacted the model&rsquo;s performance on unrelated tasks.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_28_1.jpg alt></figure></p><blockquote><p>This table presents the results of evaluating the robustness of the original TOFU prompt classifier against various types of out-of-distribution (o.o.d.) prompts. The different perturbation types represent various ways an attacker might try to circumvent the classifier, such as rephrasing the prompt, using adversarial examples, adding irrelevant context, or employing jailbreak-like prefixes/suffixes. The false positive rate indicates how often the classifier incorrectly identifies a non-target prompt as a target prompt, while the false negative rate shows how frequently the classifier fails to correctly identify a target prompt. The results demonstrate that the classifier is fairly robust against most perturbation types, although the presence of jailbreak-like prefixes/suffixes substantially increases the false negative rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_28_2.jpg alt></figure></p><blockquote><p>This table shows the performance of the original TOFU prompt classifier when it encounters various types of out-of-distribution (o.o.d.) prompts. The different prompt perturbation types include rephrased prompts, adversarial prompts, prompts with irrelevant context, prompts with jailbreak-like prefixes or suffixes, and prompts that only contain keywords or short phrases. The table reports the false positive and false negative rates for each perturbation type, indicating the classifier&rsquo;s robustness to different kinds of unexpected or manipulated inputs.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_32_1.jpg alt></figure></p><blockquote><p>This table presents the ablation study on the corruption functions used in the paper. It shows the forget quality of different corruption methods (flip sign, random noise, zero out) applied to two different models (Phi-1.5 and Llama-2-7B-Chat) for three different forget set sizes (1%, 5%, and 10%). The goal is to determine how sensitive the unlearning performance is to the choice of corruption function and how it impacts different model sizes.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_33_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results of five different LLMs on two benchmarks: WMDP (forgetting) and MMLU (retaining). It compares the performance of the original models, a prompting baseline, and the proposed ECO method for each LLM. The results demonstrate ECO&rsquo;s effectiveness in achieving near-random accuracy on the forgetting task (WMDP) while maintaining the original performance on the retaining task (MMLU), showcasing its superiority over other baselines.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_33_2.jpg alt></figure></p><blockquote><p>This table presents the ablation study on the corruption function for the BBC News unlearning task using the OLMo-7B model. It compares different corruption methods (Flip Sign First N, Flip Sign Top-k, Rand Noise Rand N, Rand Noise Top-k, Reverse Order, Shuffle, Zero Out First N, and Zero Out Top-k) against the original and retained models, evaluating metrics like ASG, PPL, Unique Token Ratio, BERTScore, METROR, ROUGE, and SacreBLEU. The goal is to determine which corruption method performs best while maintaining a balance between retaining and forgetting.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_34_1.jpg alt></figure></p><blockquote><p>This table compares the results of using a task-dependent method (where the surrogate metric value is chosen specifically for each task) versus a task-agnostic method (where a single surrogate metric value is used for all tasks). The table shows that the task-agnostic approach works almost as well as the task-dependent approach for the TOFU and WMDP tasks, and identical for the BBC News task. This suggests that choosing a single surrogate metric value for all tasks is a viable alternative.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_34_2.jpg alt></figure></p><blockquote><p>This table presents the per-example time delay (in milliseconds) added by the prompt content detection step. It compares the time taken without the classifier and with the classifier, showing the absolute increase and the percentage increase in time for various tasks and datasets. The results indicate that the additional time overhead of prompt classification is relatively small (generally less than 21ms) for most tasks except for TOFU (Forget10) which has a higher increase likely because of additional computation by a BERT-based token classifier.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_35_1.jpg alt></figure></p><blockquote><p>This table presents a comprehensive evaluation of Llama-2-7B-Chat&rsquo;s performance on the TOFU dataset after unlearning. It shows the results for different metrics (Retain Prob, Forget Prob, Authors Prob, Facts Prob, Retain TR, Forget TR, Authors TR, Facts TR, Retain ROUGE, Forget ROUGE, Authors ROUGE, Facts ROUGE, Utility, and Forget Quality) for various forget set sizes (1%, 5%, and 10%). The results are shown for the original model, a retained model (trained without the forget data), several baseline unlearning methods (Grad Ascent, Grad Diff, KL Min, Pref Opt, Prompting, NPO, NPO-KL, NPO-RT), and the proposed ECO method (with three variants: Rand Noise, Zero-Out, and Sign-Flip). This allows a detailed comparison of the effectiveness of different techniques in terms of both retaining useful knowledge and forgetting unwanted knowledge.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_36_1.jpg alt></figure></p><blockquote><p>This table presents a comprehensive evaluation of Llama-2-7B-Chat&rsquo;s performance on the TOFU dataset under various unlearning methods. It shows detailed results for different metrics (retain probability, forget probability, author probability, facts probability, retain truth ratio (TR), forget TR, author TR, facts TR, retain ROUGE, forget ROUGE, author ROUGE, facts ROUGE, utility, and forget quality) across three different forget set sizes (1%, 5%, and 10%). The table allows for a detailed comparison of the effectiveness of different unlearning techniques, including the proposed ECO method, against several baseline methods.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_38_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) on two benchmark datasets: the WMDP benchmark (for evaluating forgetting) and the full MMLU (for evaluating retention). The models are tested before and after unlearning using the ECO method and several other baselines. ECO achieves near-random guessing accuracy on the WMDP benchmark&rsquo;s forget subsets (indicating successful forgetting), while maintaining original accuracy on the MMLU&rsquo;s retain set. The baselines either fail to achieve satisfactory forgetting or show a substantial decrease in MMLU accuracy, highlighting the effectiveness of ECO.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_39_1.jpg alt></figure></p><blockquote><p>This table presents the results of unlearning experiments on 22 specialized LLMs (in biology, chemistry, or coding). The LLMs were initially trained on relevant data for their specialization. The experiment evaluates three methods: using the original model, a prompting baseline, and the proposed ECO method. The results show that ECO consistently reduces the performance across all three specializations to a level close to random guessing, unlike the other two methods which showed varied levels of success.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_43_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two distinct tasks: WMDP (forgetting) and MMLU (retaining). It showcases the performance of various unlearning methods, including the proposed ECO method, comparing their ability to both forget unwanted knowledge and retain useful information. The results highlight ECO&rsquo;s effectiveness in achieving near-random accuracy on the forgetting task while maintaining original performance on the retaining task, in contrast to other methods.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_43_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) across two benchmark tasks: WMDP (forgetting) and MMLU (retaining). The WMDP task evaluates the models&rsquo; ability to forget specific knowledge, while the MMLU task assesses their ability to retain general knowledge. The table compares the performance of the original models, models fine-tuned using a prompting baseline, and models using the ECO method. ECO is shown to achieve near random-guess accuracy on the WMDP forget task while maintaining original accuracy on the MMLU retain task, outperforming the other baselines.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_43_3.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) across two distinct benchmarks: WMDP (for evaluating unlearning) and MMLU (for evaluating knowledge retention). The WMDP benchmark focuses on assessing the ability of the LLMs to forget specific information related to a target set (forget), while the MMLU benchmark assesses the LLM&rsquo;s overall knowledge retention and utility after the unlearning process. The results show how different unlearning methods (including the proposed ECO method) impact the accuracy of the LLMs on these benchmarks. ECO is highlighted as being particularly effective at achieving near-random-guessing accuracy on the forget sets, while maintaining original performance on the retain sets.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_44_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) on two distinct benchmarks: WMDP (for evaluating unlearning) and MMLU (for assessing retention). The WMDP benchmark focuses on the ability of the models to forget specific information, while the MMLU benchmark evaluates the models&rsquo; overall knowledge retention after unlearning. The table shows the performance of the original, unlearned model, and the models after applying several different unlearning methods, including ECO (Embedding-Corrupted Prompts). The results reveal that ECO successfully unlearns the target information in the WMDP benchmark (achieving accuracies close to random guessing), while maintaining similar performance in MMLU, unlike many of the other baselines.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_44_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results of five different Large Language Models (LLMs) on two tasks: WMDP (forgetting) and MMLU (retaining). The WMDP task evaluates the ability of the models to &lsquo;forget&rsquo; specific knowledge, while the MMLU task assesses their ability to retain general knowledge. The results show that the Embedding-Corrupted (ECO) Prompts method achieves near-random accuracy on the WMDP task (indicating successful forgetting), while maintaining performance on the MMLU task. Other baseline methods either struggle to forget the targeted knowledge or show significant performance loss in the retention task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_44_3.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs (Large Language Models) on two benchmarks: WMDP (for unlearning) and MMLU (for retaining general knowledge). The table compares the original model&rsquo;s accuracy, a prompting baseline, and the performance of several unlearning methods (RMU, SCRUB, SSD, ECO). The results show that ECO consistently achieves an accuracy close to random guessing on the WMDP benchmark (indicating successful unlearning), while maintaining similar or even slightly improved accuracy on MMLU (indicating that general knowledge is retained). Other methods either struggle to achieve adequate unlearning or show a significant drop in performance on the MMLU benchmark.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_44_4.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two tasks: WMDP (forgetting) and MMLU (retaining). The models were tested before and after an unlearning process using the ECO method and several baseline methods. The results show that ECO effectively achieves near random-guess accuracy on the forgetting task (WMDP) while maintaining performance on the retaining task (MMLU), unlike the baselines which either fail to effectively forget or experience significant drops in retaining accuracy.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_45_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two tasks: WMDP (forgetting) and MMLU (retaining). The WMDP task evaluates the models&rsquo; ability to forget specific knowledge, while the MMLU task assesses their ability to retain general knowledge. The table compares the performance of the original models, models using a prompting baseline, and models utilizing the ECO method. Notably, the ECO method achieves near random-guess accuracy on the WMDP forget sets (indicating successful forgetting) while maintaining original accuracy on the MMLU retain sets (showing knowledge preservation). In contrast, other baselines struggle to balance forgetting and retention.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_45_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) on two benchmarks: WMDP (forgetting) and MMLU (retaining). The models were tested after undergoing an unlearning process using different methods, including ECO (Embedding-Corrupted Prompts). The table shows that the ECO method achieves near random guessing accuracy on the WMDP forgetting task, which is the desired outcome, without causing a decrease in accuracy on the MMLU retaining task. In contrast, other methods either failed to effectively forget the unwanted information or caused significant performance reduction on the retaining task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_45_3.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two tasks: WMDP (forgetting) and MMLU (retaining). The results demonstrate the effectiveness of the ECO method for unlearning, showing that ECO achieves near random guessing accuracy on the WMDP benchmark while maintaining the original accuracy on the MMLU task. In contrast, other methods either fail to effectively forget or suffer significant accuracy losses on the MMLU task. The table highlights the superiority of the ECO method in achieving a balance between forgetting unwanted knowledge and retaining useful information.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_45_4.jpg alt></figure></p><blockquote><p>This table compares the performance of the proposed ECO method against several baseline methods in two copyrighted content unlearning tasks. It focuses on the similarity of the unlearned model&rsquo;s output to that of a model never trained on the forgotten data (retained model). The metrics used include Average Similarity Gap (ASG), which measures the similarity of the text generated by different methods to the original text; Perplexity (PPL), indicating the fluency of the generated text; Unique Token %, which reflects the diversity of the generated text; and Utility, representing the overall performance of the model on various tasks.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_46_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results of five different Large Language Models (LLMs) on two benchmark datasets: WMDP (for unlearning) and MMLU (for retaining knowledge). The models were subjected to an unlearning process where a subset of the knowledge (WMDP) was to be removed. ECO is an unlearning method described in the paper, while other methods are baselines (LLMU, SCRUB, SSD, Prompting). The table shows that the ECO method effectively unlearns the targeted information in WMDP (achieving close to random-guess accuracy), while maintaining the original performance on the MMLU dataset. Other unlearning methods in the comparison either perform poorly on the unlearning task, or show a significant drop in performance on the knowledge retention task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_46_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results of five different Large Language Models (LLMs) on two benchmark datasets: WMDP (for unlearning) and MMLU (for retaining knowledge after unlearning). The results are shown for the original model, a prompting baseline, and three unlearning methods (SCRUB, SSD, RMU, and ECO). The WMDP results assess the ability to &lsquo;forget&rsquo; specific information, while MMLU assesses the ability to retain general knowledge. The table highlights ECO&rsquo;s success in achieving near-random accuracy on WMDP (successful forgetting) without sacrificing accuracy on MMLU.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_46_3.jpg alt></figure></p><blockquote><p>This table compares the performance of several large language models (LLMs) on two tasks: unlearning knowledge from the WMDP benchmark and retaining knowledge from the full MMLU benchmark. The models are evaluated on multiple-choice accuracy. The results show that the Embedding-Corrupted (ECO) Prompts method achieves near random-guess accuracy on the WMDP &lsquo;forget&rsquo; task (indicating successful unlearning), while maintaining original accuracy on the MMLU &lsquo;retain&rsquo; task. Other methods either struggle to successfully unlearn or experience a significant drop in accuracy on the retain task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_46_4.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) on two tasks: WMDP (forgetting) and MMLU (retaining). It compares the performance of the original models, prompting baselines, RMU (Representation misdirection for unlearning), and ECO (Embedding-Corrupted Prompts). The results show that ECO achieves near random-guess accuracy on WMDP subsets, indicating successful unlearning, while maintaining the original accuracy on MMLU. Other methods struggle to balance forgetting and retaining knowledge.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_47_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across two tasks: WMDP (forgetting) and MMLU (retaining). It compares the performance of the original models, a prompting baseline, and several unlearning methods including ECO (Embedding-Corrupted Prompts), RMU, SCRUB, and SSD. The results show that ECO effectively achieves the goal of near-random accuracy on the forgetting tasks while maintaining the original accuracy on the retaining task. Other methods struggle to achieve both retention and forgetting without substantial performance loss.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_47_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two distinct benchmarks: WMDP (forgetting) and MMLU (retaining). The models&rsquo; performances are evaluated before and after applying the ECO unlearning method. The results show that ECO effectively achieves near random guessing accuracy on WMDP&rsquo;s subsets, while maintaining the original accuracy on MMLU. In contrast, other baseline unlearning methods either struggle to forget the intended knowledge or experience substantial accuracy drops on MMLU.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_47_3.jpg alt></figure></p><blockquote><p>This table compares the performance of several LLMs (Large Language Models) on two tasks: WMDP (forgetting specific knowledge) and MMLU (retaining general knowledge) before and after applying an unlearning technique. The goal is to see how well the models can forget unwanted information while retaining useful information. The table shows the multiple-choice accuracy for different LLMs on various sub-tasks within the benchmarks, demonstrating the effectiveness (or lack thereof) of various methods. ECO (Embedding-Corrupted Prompts) consistently achieves near-random accuracy on the WMDP &lsquo;forget&rsquo; tasks while maintaining high accuracy on the MMLU &lsquo;retain&rsquo; tasks, indicating successful unlearning without significant negative side effects.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_47_4.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) across two benchmarks: WMDP (for unlearning) and MMLU (for retaining knowledge). The WMDP benchmark tests the ability of the models to &lsquo;forget&rsquo; specific knowledge, while the MMLU benchmark measures the overall knowledge retention after the unlearning process. The table compares the performance of the original models, a prompting baseline, RMU (Representation Misdirection for Unlearning), and the authors&rsquo; proposed ECO method. The results show that ECO effectively unlearns target knowledge in the WMDP benchmark while causing no loss of accuracy on the MMLU benchmark, outperforming other methods that either struggle to forget the target knowledge or negatively impact overall performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_48_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) across the WMDP benchmark (forgetting task) and the full MMLU (retaining task) after applying the ECO unlearning method. It compares the performance of ECO to several other baseline unlearning methods. The key observation is that ECO achieves accuracy near random guessing (the desired outcome) on the WMDP forget task, while simultaneously showing no decrease in accuracy on the MMLU retain task. Other methods demonstrate difficulty in balancing the forgetting and retaining objectives.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_48_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across two tasks: WMDP (forgetting) and MMLU (retaining). The results are presented for different unlearning methods, including the proposed ECO method, prompting baselines, and other state-of-the-art methods. ECO effectively achieves near-random accuracy on the WMDP forgetting task, indicating successful unlearning, while maintaining the original accuracy on the MMLU retaining task. The table highlights the effectiveness of ECO compared to other methods that either struggle to forget the targeted knowledge or suffer from a significant decrease in performance on the retain task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_48_3.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two tasks: WMDP (forgetting) and MMLU (retaining). The &lsquo;Original&rsquo; row shows the baseline accuracy before unlearning. The &lsquo;Prompting&rsquo;, &lsquo;RMU&rsquo;, and &lsquo;SCRUB&rsquo; rows represent the performance of existing unlearning methods. The &lsquo;ECO (Ours)&rsquo; row shows the results achieved by the proposed Embedding-Corrupted (ECO) Prompts method. The results show that ECO effectively achieves near random guessing accuracy on the WMDP task (successful forgetting) while maintaining the original accuracy on the MMLU task (successful retention). Other methods either struggle to forget the target information or result in significant accuracy drops on the retain task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_48_4.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs on two benchmarks: WMDP (forgetting) and MMLU (retaining). It compares the performance of the original model, a prompting baseline, a retention-based method (RMU), and the proposed ECO method for unlearning. The results demonstrate ECO&rsquo;s ability to achieve near-random-guessing accuracy on the forgetting tasks while maintaining original accuracy on the retaining tasks, showcasing its superior performance compared to other baselines.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_49_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) across two distinct benchmarks: WMDP (for evaluating unlearning) and MMLU (for evaluating knowledge retention). The WMDP benchmark focuses on the ability of LLMs to forget specific knowledge, while the MMLU assesses overall knowledge retention after the unlearning process. The table compares the performance of the original LLMs, LLMs trained with a simple prompting method, LLMs that use a gradient-based retraining approach (RMU), and LLMs that utilize the proposed Embedding-Corrupted (ECO) prompts method. The results highlight ECO&rsquo;s effectiveness in achieving near-random accuracy (successful forgetting) on WMDP subsets without sacrificing accuracy on the MMLU benchmark, unlike other unlearning methods.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_49_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two tasks: WMDP (forgetting) and MMLU (retaining). The models were evaluated on their ability to unlearn information from a specific subset of their training data (WMDP), while maintaining accuracy on other tasks (MMLU). The results show that the ECO method achieves near-random guessing accuracy on the WMDP task (meaning effective forgetting), while maintaining the original accuracy on the MMLU task. Other unlearning baselines either showed poor forgetting performance or significant reductions in MMLU accuracy.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_49_3.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across the WMDP (forgetting) and MMLU (retaining) benchmarks after applying different unlearning methods. The focus is on the effectiveness of ECO (Embedding-Corrupted Prompts) compared to other methods (Prompting, LLMU, SCRUB, RMU). The results show that ECO consistently achieves near-random accuracy on the WMDP benchmark, indicating effective forgetting, while maintaining the original accuracy on the MMLU benchmark. Other methods either fail to effectively forget or show a significant decrease in MMLU performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_49_4.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across two benchmarks: WMDP (forgetting) and MMLU (retaining). The table compares the performance of the original models, prompting baseline, RMU, and ECO across different model sizes. It demonstrates the effectiveness of ECO in achieving near-random accuracy on the WMDP benchmark while maintaining original performance on the MMLU benchmark, showcasing the method&rsquo;s ability to unlearn unwanted knowledge with minimal collateral damage to overall model functionality.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_50_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) on two benchmark datasets: WMDP (for evaluating unlearning performance) and MMLU (for assessing model utility after unlearning). The results are shown for the original models, models that have undergone a prompting baseline (a simple instruction-based approach) and models that have used the ECO method. The WMDP results demonstrate that ECO achieves an accuracy close to random guessing, indicating effective forgetting of the target knowledge. Meanwhile, ECO shows no decrease in MMLU accuracy, highlighting its ability to effectively unlearn without significant impact on general knowledge.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_50_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two benchmark datasets: WMDP (for evaluating unlearning) and MMLU (for evaluating knowledge retention). The models were subjected to an unlearning process, and the table shows their performance on both datasets before and after unlearning. The ECO method is highlighted, demonstrating its ability to achieve near-random guessing accuracy on the WMDP (forgetting task) while maintaining the original accuracy on the MMLU (retention task). Other unlearning methods are presented for comparison, and their varying levels of success in both forgetting and retaining are shown.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_50_3.jpg alt></figure></p><blockquote><p>This table compares the performance of the proposed ECO method with various baseline methods on two copyrighted content unlearning tasks. It evaluates the methods based on their similarity to a retained model (model never trained on copyrighted data), using metrics such as Average Similarity Gap (ASG), Perplexity (PPL), Unique Token ratio, and several other text similarity scores. The results show that ECO maintains high similarity to the retained model while also achieving high diversity and maintaining utility, unlike many baselines that fail to achieve similar performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_50_4.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) across two benchmark datasets: WMDP (for forget) and MMLU (for retain). The goal is to evaluate the models&rsquo; ability to both forget unwanted knowledge and retain useful knowledge after an unlearning process. The table shows the original accuracy, the accuracy after using a prompting baseline, and the accuracy after using the ECO method (Embedding-Corrupted Prompts). ECO demonstrates near-perfect forgetting on the WMDP benchmark while maintaining original MMLU performance, whereas other baselines either fail to forget or suffer significant loss of utility on the MMLU benchmark.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_51_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across two tasks: WMDP (forgetting) and MMLU (retaining). The performance of each LLM is evaluated using four methods: Original, Prompting, RMU, and ECO. ECO shows promising results, nearly achieving random accuracy for the WMDP task while maintaining the original MMLU accuracy. Other baselines either struggle to achieve forgetting or lose accuracy in the MMLU task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_51_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two benchmarks: WMDP (forgetting) and MMLU (retaining). The models were evaluated before and after an unlearning process using the ECO method and several baseline methods. The results show that ECO effectively unlearns knowledge in the WMDP benchmark while maintaining performance on the MMLU benchmark, unlike the baseline methods which either show poor unlearning or significant performance degradation.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_51_3.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two tasks: WMDP (forgetting) and MMLU (retaining). The models were subjected to an unlearning process using various methods including the authors&rsquo; proposed method (ECO) and several baselines. The table shows that the ECO method achieved near random-guessing accuracy on the WMDP task (indicating successful unlearning) with no decrease in accuracy on the MMLU task (indicating maintained utility). In contrast, baseline methods either struggled to forget information or experienced a significant drop in accuracy on the MMLU task.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_51_4.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) on two benchmarks: WMDP (for evaluating unlearning) and MMLU (for measuring the general capabilities of the models). The WMDP benchmark involves assessing the models&rsquo; ability to &lsquo;forget&rsquo; specific knowledge, while MMLU assesses their performance on a wide range of tasks after unlearning. The table shows the performance of the original models, and then after applying three unlearning methods: Prompting, RMU, and ECO. ECO consistently achieves near random-guessing accuracy on the WMDP benchmark, showing effective unlearning, and also maintains the original accuracy on the MMLU benchmark, showcasing that the general capabilities of the model were preserved. Other methods struggle to achieve this balance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_52_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) across two benchmark datasets: WMDP (for evaluating unlearning) and MMLU (for evaluating knowledge retention). The models&rsquo; performance is compared under different unlearning methods, including the proposed ECO method. The results demonstrate the effectiveness of ECO in achieving near random-guessing accuracy (successful unlearning) on the forget set of WMDP, with minimal impact on the model&rsquo;s overall MMLU performance (indicating successful knowledge retention). In contrast, other unlearning methods struggle to balance forgetting and retention, often showing significant accuracy reduction on the MMLU benchmark.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_52_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across two benchmarks: WMDP (for unlearning) and MMLU (for retention). It compares the performance of several unlearning methods: the original model, a prompting baseline, and three other methods. The focus is on how well each method balances forgetting (low accuracy on WMDP) with retaining knowledge (maintaining accuracy on MMLU). The ECO method stands out by achieving near random-guess accuracy on WMDP, indicating successful unlearning, while also maintaining the original performance on MMLU.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_52_3.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results of five different large language models (LLMs) on two benchmark datasets: WMDP (for unlearning) and MMLU (for knowledge retention). The WMDP benchmark tests the ability of the models to &lsquo;forget&rsquo; specific knowledge, while the MMLU benchmark assesses their overall knowledge retention. The table compares the performance of the original model, a baseline using prompting, and three other unlearning methods (RMU, SCRUB, SSD) against the proposed ECO method. The results show that ECO achieves near-random guessing accuracy on the WMDP benchmark (successfully forgetting the targeted knowledge) while maintaining high accuracy on the MMLU benchmark (retaining general knowledge). Other methods demonstrate difficulty in balancing forgetting and retention, either failing to forget or suffering a substantial performance decrease on the MMLU benchmark.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_56_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results of five different LLMs (Large Language Models) on two benchmarks: WMDP (Wild Misinformation Dataset Protocol) and MMLU (Massive Multitask Language Understanding). The WMDP benchmark tests the ability of the models to <em>forget</em> specific information, while the MMLU benchmark measures the models&rsquo; ability to <em>retain</em> general knowledge. The table compares the performance of the original, unmodified LLMs against several unlearning methods, including a prompting baseline, and the proposed ECO (Embedding-Corrupted Prompts) method. ECO aims to maintain unlearned state during inference by selectively corrupting dimensions of prompt embeddings. The results show that ECO effectively unlearns the targeted information in WMDP while maintaining performance on MMLU, unlike other methods, which either fail to completely unlearn the unwanted information or suffer a significant drop in overall knowledge.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_56_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across two datasets: WMDP (forgetting) and MMLU (retaining). The table compares the performance of the original model, a prompting baseline, and the proposed ECO method, along with other unlearning baselines. The results demonstrate the effectiveness of the ECO method in achieving near-random guessing accuracy on the WMDP dataset (indicating successful forgetting) without significant performance degradation on the MMLU dataset (indicating successful retention). In contrast, other baselines struggle to balance forgetting and retaining, often exhibiting substantial drops in MMLU accuracy.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_57_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across the WMDP (forgetting) and MMLU (retaining) benchmarks after performing unlearning. It compares the performance of the ECO method against several baseline methods. The results demonstrate that ECO effectively achieves near-random-guessing accuracy on the WMDP benchmark (which is the desired outcome), while maintaining the original accuracy on the MMLU benchmark, showcasing its ability to forget targeted knowledge without negatively impacting general knowledge.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_58_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different large language models (LLMs) on two benchmark datasets: WMDP (for unlearning) and MMLU (for retention). The models are tested under different unlearning methods, including the proposed ECO method and several baselines. The results show that ECO effectively unlearns knowledge from the WMDP dataset, achieving accuracy close to random guessing without impacting the performance on the MMLU dataset. In contrast, other methods either fail to effectively unlearn or experience a significant performance drop on the MMLU dataset.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_59_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs on two benchmarks: WMDP (forgetting) and MMLU (retaining). It compares the performance of the original models, prompting-based unlearning, RMU, and the proposed ECO method. The results show that ECO effectively achieves near-random-guess accuracy on the WMDP forgetting task while maintaining the original accuracy on the MMLU retaining task. Other methods struggle to balance these two objectives.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_59_2.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs (Zephyr-7B, Yi-34B-Chat, Mixtral-8x7B-Instruct, Mixtral-8x22B-Instruct, and DeepSeek-V2-Chat) across two tasks: WMDP (forgetting) and MMLU (retaining). It compares the performance of ECO against various baselines in unlearning specific knowledge from these models. The goal is to achieve near random guessing accuracy (around 25%) on the WMDP &lsquo;forget&rsquo; task while maintaining performance on the MMLU &lsquo;retain&rsquo; task. The table shows that ECO successfully achieves this, unlike the other methods, which struggle to achieve the target accuracy or suffer a decrease in overall performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_60_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs on two tasks: WMDP (forgetting) and MMLU (retaining). The results demonstrate the performance of the ECO method compared to several baselines (Prompting, LLMU, SCRUB, SSD, RMU). ECO consistently achieves near random guessing accuracy on the WMDP subset, indicating successful forgetting while maintaining high accuracy on the MMLU subset, showing no detrimental side effects on retained knowledge. Other methods show either poor forgetting or significant performance drops on the MMLU subset.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_61_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different LLMs across two datasets: WMDP (forgetting) and MMLU (retaining). The performance of several unlearning methods (including ECO) is compared against the original model and a prompting baseline. ECO demonstrates its ability to achieve near-random guessing accuracy on the WMDP dataset, while maintaining the original accuracy on the MMLU dataset. In contrast, other baselines show difficulty in achieving both forgetting and retaining objectives, often exhibiting reduced accuracy on the retaining tasks.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/e5icsXBD8Q/tables_62_1.jpg alt></figure></p><blockquote><p>This table presents the multiple-choice accuracy results for five different Large Language Models (LLMs) across two distinct benchmarks: WMDP (for evaluating the ability to forget specific knowledge) and MMLU (for measuring the retention of general knowledge). The models are evaluated under various unlearning methods, including the proposed ECO method. The results demonstrate that ECO effectively unlearns information from the WMDP dataset without significantly impacting general knowledge retention, whereas other baselines struggle to achieve effective unlearning.</p></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-d636a7b4652d467c64ac8691ba2b562a class=gallery><img src=https://ai-paper-reviewer.com/e5icsXBD8Q/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/e5icsXBD8Q/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/&amp;title=Large%20Language%20Model%20Unlearning%20via%20Embedding-Corrupted%20Prompts" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/&amp;text=Large%20Language%20Model%20Unlearning%20via%20Embedding-Corrupted%20Prompts" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/neurips2024/posters/e5icsxbd8q/&amp;subject=Large%20Language%20Model%20Unlearning%20via%20Embedding-Corrupted%20Prompts" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_posters/e5icsXBD8Q/index.md",oid_likes="likes_posters/e5icsXBD8Q/index.md"</script><script type=text/javascript src=/neurips2024/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/neurips2024/posters/jd3nypeq3r/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Large language model validity via enhanced conformal prediction methods</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/neurips2024/posters/8dy42thone/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Large Language Model Unlearning</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
AI Paper Reviewer</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/neurips2024/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/neurips2024/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>