[{"figure_path": "RkOT8rAmRR/figures/figures_0_1.jpg", "caption": "Figure 1: OSDCap is an optimal-state dynamics estimation (cyan) based on two streams of input: motion, a kinematics-based pose estimation from videos (top-left), and a physics-based simulation by a meta-PD controller (bottom-left). The predicted motion is physically-plausible, contains reduced high-frequency noise, while retaining highly accurate global position.", "description": "This figure illustrates the OSDCap system, which combines video-based pose estimation and physics simulation to achieve more realistic human motion capture.  The top-left shows noisy kinematic pose estimation from a video. The bottom-left depicts a physics simulation driven by a meta-PD controller.  The cyan section in the middle shows how the system optimally combines these two inputs to generate a physically plausible motion sequence that is smoother and more accurate than either input alone. The resulting motion is shown in the center, demonstrating reduced high-frequency noise while maintaining high accuracy in the overall position.", "section": "1 Introduction"}, {"figure_path": "RkOT8rAmRR/figures/figures_3_1.jpg", "caption": "Figure 2: The main pipeline of OSDCap. Our approach consists of one neural network model, OSDNet (orange), and three processing components. OSDNet takes the current system state, estimates a Kalman gain matrix, PD gains, external force and an inertia-bias matrix. The optimal pose estimation performs contains a Kalman filter for the current system state and the input kinematics. Yellow refers to the algorithm's state vectors and cyan denotes processing operations. The physics priors block (gray) computes the inertia matrix and non-linear forces using the Composite rigid-body algorithm and Inverse dynamics [5]. Using the PD algorithm and forward dynamics (Eq. 1), the physics simulation block (green) updates the velocity based on the computed optimal pose and physics priors.", "description": "This figure illustrates the overall pipeline of the proposed method, OSDCap. It comprises three main stages: optimal pose estimation using a Kalman filter, physics priors calculation, and physics simulation based on the computed optimal pose and physics priors. The core component is the OSDNet which estimates the Kalman gain matrix, PD gains, external forces and inertia bias matrix, facilitating the fusion of kinematic and dynamic inputs.", "section": "3 Method"}, {"figure_path": "RkOT8rAmRR/figures/figures_8_1.jpg", "caption": "Figure 3: Qualitative results of OSDCap (cyan) compared to the kinematics input [40] (purple), with corresponding ground truth pose (red). Left: Filtering results of OSDCap on a sample from SportsPose [14], where the kinematics estimation is very inaccurate along the camera's depth dimension. The Kalman gain at the y-axis (optical axis) is greatly decreased due to the incorrect translation of the kinematics input. Therefore, the simulated state is preferred. Right: Example from Fit3D [7], with an unnaturally leaning pose caused by depth ambiguities. Unlike Fig. 3a, the three poses are manually separated apart for better visualization. OSDCap recovers the physically plausible upright pose.", "description": "This figure shows a qualitative comparison of the proposed OSDCap method against a kinematics-only approach and ground truth data. Two examples are presented: one where the kinematics estimation has large errors in depth, and another where the pose is unnatural due to ambiguities. OSDCap is able to correct these issues and produce physically plausible poses by integrating physics-based simulation and Kalman filtering.", "section": "4 Experiments"}, {"figure_path": "RkOT8rAmRR/figures/figures_13_1.jpg", "caption": "Figure 4: Architecture of the proposed OSDNet. The network consists of 3 hidden layer of size 512 to generate system state's embedding. Based on the state embedding, the inertia-bias matrix Mbaset, PD gains KP, KD, Jacobian matrix Jt, contact probability p and external force At are estimated. The proposed GRU unit with size 128 takes the dynamics features (mentioned in Sec. 3.2) as input, the Kalman gain matrix Kt is estimated from the concatenation of GRU and the state embedding. The hidden state hgru is continuously updated at each time step. For a better estimation of foot-ground contacts and reaction forces, we also feed the feet position and linear velocity as additional inputs.", "description": "The figure shows the architecture of the neural network OSDNet.  It consists of a GRU (Gated Recurrent Unit) processing dynamic features and the system state to produce estimates for Kalman gains, PD controller gains, inertia bias, and external forces. The GRU\u2019s hidden state is updated at each time step.  Additional inputs of feet position and velocity improve the estimation of foot-ground contact and reaction forces.  The outputs are used in later processing stages.", "section": "A Network details"}, {"figure_path": "RkOT8rAmRR/figures/figures_14_1.jpg", "caption": "Figure 2: The main pipeline of OSDCap. Our approach consists of one neural network model, OSDNet (orange), and three processing components. OSDNet takes the current system state, estimates a Kalman gain matrix, PD gains, external force and an inertia-bias matrix. The optimal pose estimation performs contains a Kalman filter for the current system state and the input kinematics. Yellow refers to the algorithm's state vectors and cyan denotes processing operations. The physics priors block (gray) computes the inertia matrix and non-linear forces using the Composite rigid-body algorithm and Inverse dynamics [5]. Using the PD algorithm and forward dynamics (Eq. 1), the physics simulation block (green) updates the velocity based on the computed optimal pose and physics priors.", "description": "This figure illustrates the overall pipeline of the OSDCap method, which is comprised of a neural network (OSDNet) and three processing components: optimal pose estimation, physics priors calculation, and physics simulation.  OSDNet estimates key parameters like Kalman gain matrices, PD gains, external forces, and inertia bias.  The optimal pose estimation utilizes a Kalman filter to combine kinematic data with physics-based simulation results. Physics priors use a rigid body dynamics model to calculate inertia and forces, while the simulation updates velocity based on the optimal pose and physics priors. The diagram clearly shows the flow of data and processing steps within the OSDCap framework.", "section": "3 Method"}, {"figure_path": "RkOT8rAmRR/figures/figures_15_1.jpg", "caption": "Figure 6: Example results on SportsPose [14] test data. Here we show four out of five action classes of SportsPose [14] that have foot-ground contacts. Qualitatively OSDCap matches the provided ground truth much better than the kinematics input TRACE.", "description": "This figure shows a qualitative comparison of human motion capture results between the proposed method (OSDCap) and a baseline method (TRACE). Four different sports actions (tennis, baseball, football, and volleyball) are displayed, each with three columns: the input kinematics from TRACE, the estimated pose from OSDCap, and the ground truth pose.  The results demonstrate that OSDCap is able to produce significantly more accurate and plausible human motion than TRACE, especially when the input kinematics are noisy or inaccurate.", "section": "4 Experiments"}, {"figure_path": "RkOT8rAmRR/figures/figures_16_1.jpg", "caption": "Figure 1: OSDCap is an optimal-state dynamics estimation (cyan) based on two streams of input: motion, a kinematics-based pose estimation from videos (top-left), and a physics-based simulation by a meta-PD controller (bottom-left). The predicted motion is physically-plausible, contains reduced high-frequency noise, while retaining highly accurate global position.", "description": "This figure illustrates the OSDCap system, which combines kinematic pose estimation from videos and physics-based simulation using a meta-PD controller to estimate human motion. The cyan part represents the optimal-state dynamics estimation, which integrates the two input streams to produce a physically plausible and noise-reduced motion while maintaining high accuracy in global position.", "section": "Introduction"}]