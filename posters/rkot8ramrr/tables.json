[{"figure_path": "RkOT8rAmRR/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparison on the Human3.6M dataset [15]. Related methods are separated into two main categories: kinematics (top) and physics-based (bottom). In addition only [37, 38, 46, 50] retains the online prediction ability of the video-based kinematics estimations. Bold numbers denote the best evaluation score on each metric. Our approach achieves state-of-the-art in MPJPE and PCK among online approaches, and competitive results on GRP and Accel. Note that *DnD [21] does not follow standard evaluation protocols by using additional training data.", "description": "This table compares the performance of OSDCap with other state-of-the-art methods for 3D human motion capture on the Human3.6M dataset.  It shows various metrics, including different versions of MPJPE (Mean Per Joint Position Error), PCK (Percentage of Correct Keypoints), CPS (Correct Pose Score), and GRP (Global Root Position).  The table highlights OSDCap's superior performance, especially compared to online methods.", "section": "4.4 Comparison with State of the Art"}, {"figure_path": "RkOT8rAmRR/tables/tables_7_2.jpg", "caption": "Table 2: Evaluation results on Fit3D [7] and SportsPose [14]. OSDCap improves the kinematics baseline TRACE by a large margin across all metrics. We fine-tune OSDCap (pretrained on Human3.6M) on SportsPose's ground truth keypoints for additional 15 epochs. Even with very noisy inputs from SportsPose, OSDCap still manage to retain the robust estimation thanks to the Kalman filtering process, especially on global translation metrics (MPJPE-G and GRP).", "description": "This table presents a quantitative comparison of the proposed OSDCap method against the TRACE baseline on two different datasets: Fit3D and SportsPose.  The metrics used are MPJPE (with its variations MPJPE-G and MPJPE-PA), PCK, CPS, GRP, and Accel, which assess aspects like joint position error, keypoint accuracy, pose correctness, global position error, and motion smoothness.  The results show that OSDCap significantly outperforms TRACE on both datasets, highlighting its robustness to noisy inputs and ability to maintain accurate global motion estimates.", "section": "4 Experiments"}, {"figure_path": "RkOT8rAmRR/tables/tables_8_1.jpg", "caption": "Table 3: Ablation study on the impact of OSDNet on a subset of Human 3.6M [15]. Naive methods such as median or Gaussian smoothing cannot help with the plausibility of the pose. Without our Kalman filtering process, the PD controller cannot train and estimate the correct dynamics. We also study the effects of the inertia-bias M\u00ba and some performance gains has been recorded.", "description": "This table presents the results of an ablation study on the impact of OSDNet, a neural network model, on human pose estimation using a subset of the Human3.6M dataset.  It compares the performance of OSDCap with and without the inertia bias, and with several baseline methods such as median and Gaussian smoothing applied to the input kinematics from TRACE.  The results show that OSDNet significantly improves the accuracy and physical plausibility of the estimated poses, highlighting the importance of the Kalman filtering and inertia bias components.", "section": "4 Experiments"}, {"figure_path": "RkOT8rAmRR/tables/tables_9_1.jpg", "caption": "Table 1: Quantitative comparison on the Human3.6M dataset [15]. Related methods are separated into two main categories: kinematics (top) and physics-based (bottom). In addition only [37, 38, 46, 50] retains the online prediction ability of the video-based kinematics estimations. Bold numbers denote the best evaluation score on each metric. Our approach achieves state-of-the-art in MPJPE and PCK among online approaches, and competitive results on GRP and Accel. Note that *DnD [21] does not follow standard evaluation protocols by using additional training data.", "description": "This table compares the performance of OSDCap with other state-of-the-art methods on the Human3.6M dataset for human motion capture.  It shows various metrics including MPJPE (with and without pose alignment), PCK, CPS, GRP, and Accel, which assess the accuracy and smoothness of the generated 3D poses. The table highlights OSDCap's superior performance among online methods, particularly in terms of accuracy (MPJPE and PCK).  It also notes that one comparable method, DnD, uses additional training data, thus affecting the comparison.", "section": "4 Experiments"}, {"figure_path": "RkOT8rAmRR/tables/tables_9_2.jpg", "caption": "Table 5: Additional physics-based measurements for kinematics input TRACE and OSDCap. Because the ground penetration (GP) metric does not correctly reflect the foot-ground contact quality, i.e. floating above the ground is ignored and produces no error, we propose using an additional ground-distance (GD) metric. For foot-skating, we followed DiffPhy to compute the percentage of frames that contain skating artifacts over the whole sequence.", "description": "This table presents a comparison of several physics-based metrics between the baseline kinematics method (TRACE) and the proposed method (OSDCap).  The metrics quantify aspects of physical plausibility such as ground penetration, ground distance, friction, velocity consistency, and foot-skating artifacts.  The results demonstrate that OSDCap leads to improvements in physical realism compared to the baseline.", "section": "4.5.3 Additional physics-based metrics"}]