[{"figure_path": "a6em980M9x/tables/tables_5_1.jpg", "caption": "Table 1: Overview of benchmarks including their spatial dimensions d, spatial resolution M, temporal resolution Nt, and training data Ntrain and test data Ntest.", "description": "This table presents an overview of the six benchmark datasets used in the paper to evaluate the performance of the proposed AM-FNO model and its comparison with baseline models.  For each dataset, it lists the partial differential equation (PDE) being modeled, the geometry of the problem domain, the spatial dimensions (d), the spatial resolution (M), the temporal resolution (Nt), the number of training samples (Ntrain), and the number of test samples (Ntest). These details are crucial for understanding the experimental setup and reproducing the results.", "section": "5.1 Experimental Setup"}, {"figure_path": "a6em980M9x/tables/tables_6_1.jpg", "caption": "Table 2: Comparison of the primary findings across six benchmark tests with six baseline methods. Lower scores signify superior performance, with the best outcome highlighted in bold and the second-best outcome underlined. The presence of a \"-\" indicates that the corresponding baseline is incapable of addressing the benchmark.", "description": "This table compares the performance of the proposed AM-FNO model (with KAN and MLP implementations) against six baseline neural operator methods across six different PDE benchmarks.  The benchmarks vary in geometry, dimensionality, and the nature of the PDEs involved, allowing for a comprehensive evaluation of the model's performance.  Lower values indicate better performance. The best result for each benchmark is shown in bold, while the second-best is underlined.  The '-' symbol indicates that a particular baseline method was not applicable to that benchmark.", "section": "5.2 Main Results"}, {"figure_path": "a6em980M9x/tables/tables_7_1.jpg", "caption": "Table 3: Comparison of the error in different frequency regions on CFD-2D benchmarks. Each complex-valued parameter is considered as 2 in the parameter count (Param). Train error (Train Err.) and test error (Test Err.) are evaluated using the l2 relative error at each time step. fL2 signifies the l2 relative error in Fourier space (fRMSE) pertaining to the low, middle, and high-frequency regions. FNO+ refers to FNO without frequency truncation.", "description": "This table compares the performance of different neural operator models on the CFD-2D benchmark across different frequency ranges.  It shows the training and test errors, as well as the error specifically in low, middle, and high-frequency components of the Fourier transform of the solution.  FNO+ represents a version of the FNO model without frequency truncation for comparison.", "section": "5.3 Frequency-Based Error Analysis"}, {"figure_path": "a6em980M9x/tables/tables_7_2.jpg", "caption": "Table 4: Comparison of the l2 relative error for different components of AM-FNO (MLP) on Darcy, Airfoil, and Pipe benchmarks. Chebyshev basis functions are substituted with triangular basis functions (TBF) and non-orthogonal polynomial basis functions (PBF). A version of the model without orthogonal embedding (Non) is included for comparison. The training time and memory requirements are derived from the Airfoil benchmark.", "description": "This table presents an ablation study comparing the performance of AM-FNO (MLP) using different orthogonal basis functions (Chebyshev, triangular, and non-orthogonal polynomials). It shows the l2 relative error for each configuration on three benchmarks (Darcy, Airfoil, and Pipe), along with training time and memory usage (based on Airfoil). The results highlight the importance of using orthogonal embedding functions for optimal performance.", "section": "5.4 Ablation Experiments"}, {"figure_path": "a6em980M9x/tables/tables_8_1.jpg", "caption": "Table 5: Comparison of l2 relative error across different resolutions on NS-2D benchmark, with all models trained with 32 \u00d7 32 resolution.", "description": "This table presents the results of a zero-shot super-resolution experiment on the NS-2D benchmark.  Models were trained on lower-resolution data (32x32) and then evaluated on both the training resolution and a higher resolution (64x64). The table shows the l2 relative error for each model at each resolution. This demonstrates the models' ability to generalize to unseen resolutions.", "section": "5.5 Zero-Shot Super-Resolution"}, {"figure_path": "a6em980M9x/tables/tables_12_1.jpg", "caption": "Table 6: Comparison of GPU memory, training time per epoch, and parameter counts on Darcy benchmark.", "description": "This table compares the GPU memory usage, training time per epoch, and the number of parameters for different neural operator models on the Darcy benchmark. The models compared include AM-FNO(MLP), AM-FNO(KAN), FNO, U-FNO, OFormer, LSM, F-FNO, and AFNO.  The results show the computational resource requirements of each model.", "section": "5.2 Main Results"}, {"figure_path": "a6em980M9x/tables/tables_12_2.jpg", "caption": "Table 7: Comparison of the l2 relative error on NS-2D and CFD-2D benchmark.", "description": "This table presents a comparison of the L2 relative error achieved by AM-FNO(MLP) and AM-FNO(KAN) on two benchmark problems: NS-2D (Navier-Stokes 2D) and CFD-2D (compressible fluid dynamics 2D).  The results show the mean error and standard deviation, indicating the performance variability across multiple runs (although the paper mentions only one run was performed due to computational constraints). Lower values indicate better performance.", "section": "5.2 Main Results"}, {"figure_path": "a6em980M9x/tables/tables_12_3.jpg", "caption": "Table 4: Comparison of the \u21132 relative error for different components of AM-FNO (MLP) on Darcy, Airfoil, and Pipe benchmarks. Chebyshev basis functions are substituted with triangular basis functions (TBF) and non-orthogonal polynomial basis functions (PBF). A version of the model without orthogonal embedding (Non) is included for comparison. The training time and memory requirements are derived from the Airfoil benchmark.", "description": "This table presents an ablation study comparing different components of the AM-FNO (MLP) model on three benchmarks: Darcy, Airfoil, and Pipe. It investigates the impact of using different basis functions (Chebyshev, Triangular, and Non-orthogonal Polynomial) and the necessity of orthogonal embedding. The table shows the relative \u21132 error, model parameters, memory usage, and training time per epoch for each configuration.", "section": "5.4 Ablation Experiments"}, {"figure_path": "a6em980M9x/tables/tables_13_1.jpg", "caption": "Table 9: Comparison of the l2 relative error on Darcy benchmark.", "description": "This table compares the l2 relative error achieved by AM-FNO (MLP), AM-FNO (KAN), and other baseline methods (Geo-FNO, U-FNO, OFormer, LSM, and F-FNO) on the Darcy benchmark.  Lower scores indicate better performance.", "section": "5.3 Frequency-Based Error Analysis"}]