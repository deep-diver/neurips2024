[{"figure_path": "XrK4JK2jBr/figures/figures_4_1.jpg", "caption": "Figure 2: Here, we provide an overview of the steps to produce a collaborative AI teammate with an interpretable policy and the proposed policy modification scheme evaluated in our user study.", "description": "This figure shows a flow chart that outlines the steps in the methodology of the study. It starts with training a collaborative AI agent in a simulation environment.  Then, the trained AI policy is pruned to reduce its complexity and improve interpretability using the contextual pruning algorithm. This interpretable AI policy is then used in an interactive human-machine teaming (HMT) setting, allowing for human modification of the AI policy.  The process of interaction and modification leads to team development, shown as Tuckman's stages of team development.", "section": "4 Methodology"}, {"figure_path": "XrK4JK2jBr/figures/figures_5_1.jpg", "caption": "Figure 3: Users have several capabilities in creating an effective teammate, including modifying the tree structure by adding or removing decision nodes, changing state features the tree is conditioned on, and modifying actions and/or their respective probabilities at leaf nodes.", "description": "This figure shows the different ways a human user can modify the AI teammate's policy tree representation.  Three types of modifications are presented: tree deepening (adding nodes to increase complexity), decision variable modification (changing the conditions used for decision-making), and leaf node modification (altering actions and their probabilities).", "section": "4.2 Modifying an Interpretable Policy"}, {"figure_path": "XrK4JK2jBr/figures/figures_7_1.jpg", "caption": "Figure 4: User gameplay scores across teaming iterations with per-iteration means connected by the red dotted line and the per-iteration standard deviation shaded in red.", "description": "This figure shows the results of a user study comparing different AI teaming strategies across two game scenarios: Forced Coordination and Optional Collaboration.  Each panel represents a different AI strategy: Human-Led Policy Modification, AI-Led Policy Modification, Static (Interpretable), Static (Black-Box), and Fictitious Co-Play. The y-axis shows the cumulative team reward, and the x-axis shows the iteration number (repeated teaming interactions). The red dotted line represents the average reward for each iteration, and the shaded area shows the standard deviation.  The figure demonstrates how different strategies lead to varying team performance over repeated interactions, highlighting the impact of interpretability and interactivity on teamwork effectiveness.", "section": "5.1 Results"}, {"figure_path": "XrK4JK2jBr/figures/figures_7_2.jpg", "caption": "Figure 4: User gameplay scores across teaming iterations with per-iteration means connected by the red dotted line and the per-iteration standard deviation shaded in red.", "description": "This figure displays the results of the user study across the two domains (Forced Coordination and Optional Collaboration). The x-axis represents the iteration number (1-4), and the y-axis represents the team reward. Each point represents a single user's score in a particular iteration, and the red dotted line connects the average scores across iterations. The shaded area represents the standard deviation of the scores. The figure shows that the performance varies across different conditions in both domains.", "section": "5.1 Results"}, {"figure_path": "XrK4JK2jBr/figures/figures_8_1.jpg", "caption": "Figure 4: User gameplay scores across teaming iterations with per-iteration means connected by the red dotted line and the per-iteration standard deviation shaded in red.", "description": "This figure shows the results of the user study, comparing the performance of different teaming methods across two game domains (Forced Coordination and Optional Collaboration) over four iterations.  The lines represent the average team reward per iteration, and the shaded areas show the standard deviation.  The goal is to see how different teaming methods affect team performance over time and if there are differences between the two game types.", "section": "5.1 Results"}, {"figure_path": "XrK4JK2jBr/figures/figures_15_1.jpg", "caption": "Figure 6: Tree Policy Generation for Conditions IV1-C1-C4", "description": "This figure shows the pipeline for generating the AI teammate policies used in the study.  It starts with training an IDCT (Interpretable Discrete Control Tree) agent in each domain (Forced Coordination and Optional Collaboration). Then, contextual pruning is applied to simplify the tree structure while maintaining performance. The resulting pruned IDCT policies (with 3 leaves for Forced Coordination and 2 for Optional Collaboration) are used in the pre-experiment stage of the user study.", "section": "4 Methodology"}, {"figure_path": "XrK4JK2jBr/figures/figures_16_1.jpg", "caption": "Figure 7: Trained Interpretable Discrete Control Tree in the Forced Coordination Domain.", "description": "This figure shows a visualization of a trained interpretable discrete control tree (IDCT) used in the Forced Coordination domain of the Overcooked-AI experiment. The tree's structure displays decision nodes (blue boxes) and action nodes (orange boxes). Each node shows probabilities for different actions, and the tree's structure is designed to be interpretable by humans for easier understanding and potential modification. The caption is short and does not provide enough information about the figure itself.", "section": "C.5 Visualization of IDCT Policies in Each Domain"}, {"figure_path": "XrK4JK2jBr/figures/figures_16_2.jpg", "caption": "Figure 7: Trained Interpretable Discrete Control Tree in the Forced Coordination Domain.", "description": "This figure shows the trained interpretable discrete control tree used in the Forced Coordination domain. The tree consists of a root decision node that checks if there is soup on the shared counter, leading to different action nodes based on whether the condition is true or false.  If true, the agent has a high probability of getting soup from the counter. If false, there's a distribution across actions including getting soup and tomatoes from the counter, getting a dish, or waiting.", "section": "C.5 Visualization of IDCT Policies in Each Domain"}, {"figure_path": "XrK4JK2jBr/figures/figures_18_1.jpg", "caption": "Figure 9: This figure displays an experiment flow diagram for each condition.", "description": "This figure shows the experiment procedure for each of the five conditions (IV1-C1 to IV1-C5).  Each condition involves a slightly different approach to human-AI interaction, ranging from human-led modification of the AI's policy to AI-led modifications based on gameplay and static (interpretable or black box) policies. The flowcharts outline the sequence of events, including surveys, tutorials, AI interaction phases, policy visualizations, and concluding questionnaires.", "section": "Additional User Study Information"}, {"figure_path": "XrK4JK2jBr/figures/figures_18_2.jpg", "caption": "Figure 9: This figure displays an experiment flow diagram for each condition.", "description": "This figure shows the experiment flow diagram for each of the five conditions tested in the study.  It outlines the steps involved in each condition, from the initial introduction and surveys through the repeated teaming episodes, policy modifications (where applicable), and finally the post-experiment surveys. The diagram is broken down to visualize the differences in procedure for each of the five conditions.", "section": "Additional User Study Information"}, {"figure_path": "XrK4JK2jBr/figures/figures_18_3.jpg", "caption": "Figure 9: This figure displays an experiment flow diagram for each condition.", "description": "This figure shows the detailed flowcharts for the five different conditions (IV1-C1 to IV1-C5) in the user study. Each flowchart illustrates the sequence of events, including initial surveys, the tutorial, repeated human-AI teaming episodes, policy modifications (if applicable), workload surveys, and finally post-experiment surveys.  It visually represents the differences in procedures across conditions, highlighting variations in user interaction with the AI's policy and the degree of policy control afforded to the human user. The different steps for different conditions help to understand the design of the study and how it manipulates different independent variables.", "section": "5 Human-Subjects Study"}, {"figure_path": "XrK4JK2jBr/figures/figures_18_4.jpg", "caption": "Figure 9: This figure displays an experiment flow diagram for each condition.", "description": "This figure shows the experiment procedure for the five different conditions in the user study.  Each condition is represented by a separate flowchart that details the steps from the introduction phase with demographic and gaming experience surveys, followed by a tutorial, to the main experimentation phase which includes repeated teaming episodes and workload surveys, concluding with end-of-experiment surveys assessing various aspects such as collaboration fluency and trust.", "section": "5 Human-Subjects Study"}]