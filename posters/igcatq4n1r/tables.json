[{"figure_path": "IGCaTQ4n1R/tables/tables_6_1.jpg", "caption": "Table 1: Zero-shot classification results on ModelNet40 [46], ScanObjectNN [47] and OmniObject3D [48]. The best-performing results are presented in bold, while the second-best results are underlined. Our models are highlighted in blue.", "description": "This table presents a comparison of the zero-shot classification performance of OpenDlign against several state-of-the-art models on three benchmark datasets: ModelNet40, ScanObjectNN, and OmniObject3D.  The results show Top-1, Top-3, and Top-5 accuracy for each method, highlighting OpenDlign's superior performance, especially in the OmniObject3D dataset.", "section": "4 Experiments"}, {"figure_path": "IGCaTQ4n1R/tables/tables_6_2.jpg", "caption": "Table 2: Few-shot classification results on ModelNet40 [46], ScanObjectNN [47] and OmniObject3D [48]. Our results are averaged over 10 random seeds.", "description": "This table presents the few-shot classification results obtained by OpenDlign and other state-of-the-art models on three benchmark datasets: ModelNet40, ScanObjectNN, and OmniObject3D.  The results are averaged over 10 different random seeds to provide a more robust statistical measure of performance. The table shows the accuracy achieved using different numbers of training shots (1-shot, 2-shot, 4-shot, 8-shot, 16-shot). This allows for a comparison of the models' ability to generalize to unseen data when provided with limited training examples.", "section": "4.2 Few-Shot 3D Classification"}, {"figure_path": "IGCaTQ4n1R/tables/tables_7_1.jpg", "caption": "Table 3: Zero-shot 3D object detection results on ScanNet V2 [51].", "description": "This table presents the results of a zero-shot 3D object detection experiment conducted using the ScanNet V2 dataset.  The experiment compared three different methods: PointCLIP [14], PointCLIP V2 [13], and the proposed OpenDlign method.  The results are reported as mean Average Precision (mAP) at Intersection over Union (IoU) thresholds of 0.25 and 0.5.  The table shows the mAP for each of the 18 object categories in the ScanNet dataset, as well as the overall mean AP across all categories.  OpenDlign demonstrates a significant improvement in performance compared to the other two methods.", "section": "4.3 Zero-Shot 3D Object Detection"}, {"figure_path": "IGCaTQ4n1R/tables/tables_8_1.jpg", "caption": "Table 4: Ablation study for OpenDlign on ModelNet40 [46] and ScanObjectNN [47]. Accuracy improvements over the baseline (first-row) are highlighted in green.", "description": "This ablation study analyzes the contribution of each component in the OpenDlign model.  It shows the impact of using contour-aware projection, multimodal alignment with depth-aligned images, depth-specific texts, and logits aggregation on the classification accuracy for ModelNet40 and ScanObjectNN datasets.  The results are presented as Top1, Top3, and Top5 accuracy, with improvements over the baseline indicated in green.", "section": "4.5 Ablation Study"}, {"figure_path": "IGCaTQ4n1R/tables/tables_8_2.jpg", "caption": "Table 4: Ablation study for OpenDlign on ModelNet40 [46] and ScanObjectNN [47]. Accuracy improvements over the baseline (first-row) are highlighted in green.", "description": "This ablation study analyzes the impact of different components of the OpenDlign model on its performance in zero-shot classification.  It compares several variations, altering contour-aware projection, the strategy used for multimodal alignment (depth-aligned images versus CAD-rendered images and different text prompt strategies), and the method of logits aggregation.  The results show the contribution of each element to the final accuracy and highlight the benefits of using depth-aligned images for robust multimodal alignment. Improvements over a baseline configuration are highlighted in green.", "section": "4.5 Ablation Study"}, {"figure_path": "IGCaTQ4n1R/tables/tables_13_1.jpg", "caption": "Table 1: Zero-shot classification results on ModelNet40 [46], ScanObjectNN [47] and OmniObject3D [48]. The best-performing results are presented in bold, while the second-best results are underlined. Our models are highlighted in blue.", "description": "This table presents a comparison of the zero-shot classification performance of OpenDlign against other state-of-the-art models on three benchmark datasets: ModelNet40, ScanObjectNN, and OmniObject3D.  The results are categorized by the 3D model used and include Top1, Top3, and Top5 accuracy scores.  OpenDlign's performance is highlighted, showing its superior accuracy compared to existing methods.", "section": "4 Experiments"}, {"figure_path": "IGCaTQ4n1R/tables/tables_14_1.jpg", "caption": "Table 7: Zero-shot classification results on Objaverse-LVIS [23]. The best-performing results are presented in bold, while the second-best results are underlined. Our models are highlighted in blue.", "description": "This table presents the zero-shot classification results on the Objaverse-LVIS dataset, a challenging long-tailed dataset containing 1,156 categories of 3D objects.  The table compares the performance of OpenDlign against several existing state-of-the-art open-world 3D models. The results are categorized by the training source (2D inferences or ShapeNet) and CLIP variants used.  OpenDlign consistently outperforms the other methods across various CLIP variants, highlighting its superior performance on this challenging dataset.", "section": "4.1 Zero-Shot 3D Classification"}, {"figure_path": "IGCaTQ4n1R/tables/tables_15_1.jpg", "caption": "Table 8: Few-shot classification results on Objaverse-LVIS [23].", "description": "This table presents the few-shot classification results of OpenDlign and other state-of-the-art models on the Objaverse-LVIS dataset.  The results are shown for different numbers of training examples per class (1-shot, 2-shot, 4-shot, 8-shot, and 16-shot). OpenDlign consistently outperforms the baselines across all scenarios.", "section": "4.2 Few-Shot 3D Classification"}, {"figure_path": "IGCaTQ4n1R/tables/tables_15_2.jpg", "caption": "Table 3: Zero-shot 3D object detection results on ScanNet V2 [51].", "description": "This table presents the results of a zero-shot 3D object detection experiment conducted on the ScanNet V2 dataset.  The experiment evaluates the performance of the OpenDlign model and compares it against two other methods (PointCLIP and PointCLIP V2). The table shows the mean Average Precision (mAP) at Intersection over Union (IoU) thresholds of 0.25 and 0.5 for each of the 18 object categories in the ScanNet dataset.  Higher mAP values indicate better performance. ", "section": "4.3 Zero-Shot 3D Object Detection"}, {"figure_path": "IGCaTQ4n1R/tables/tables_15_3.jpg", "caption": "Table 4: Ablation study for OpenDlign on ModelNet40 [46] and ScanObjectNN [47]. Accuracy improvements over the baseline (first-row) are highlighted in green.", "description": "This ablation study analyzes the contribution of each component in OpenDlign towards improving the accuracy of zero-shot classification on ModelNet40 and ScanObjectNN datasets.  It systematically removes or modifies different parts of the OpenDlign pipeline (contour-aware projection, multimodal alignment with depth-aligned images, depth-specific texts, and logits aggregation) to assess their individual impact on the overall performance. The results quantify the improvement brought by each component compared to a baseline configuration and are presented as percentage increases in Top1, Top3, and Top5 accuracy.", "section": "4.5 Ablation Study"}, {"figure_path": "IGCaTQ4n1R/tables/tables_16_1.jpg", "caption": "Table 11: Effect of the number of viewpoints for 16-shot classification.", "description": "This table shows the effect of varying the number of viewpoints used in OpenDlign's few-shot (16-shot) classification experiments.  It presents the Top-1 accuracy results on three benchmark datasets: ModelNet40, ScanObjectNN, and OmniObject3D, for different numbers of viewpoints ranging from 1 to 10.  The results demonstrate the impact of using multiple views on the performance of the model.", "section": "4.2 Few-Shot 3D Classification"}]