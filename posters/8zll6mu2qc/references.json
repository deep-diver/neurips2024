{"references": [{"fullname_first_author": "A. T. Suresh", "paper_title": "Distributed Mean Estimation With Limited Communication", "publication_date": "2017-00-00", "reason": "This paper is foundational for many of the distributed and federated learning concepts discussed, introducing a key problem and the technique of quantization."}, {"fullname_first_author": "J. Kone\u010dn\u00fd", "paper_title": "Randomized Distributed Mean Estimation: Accuracy vs. Communication", "publication_date": "2018-00-00", "reason": "This paper directly addresses the trade-offs between accuracy and communication efficiency in distributed mean estimation, a central theme in the target paper."}, {"fullname_first_author": "S. Caldas", "paper_title": "Expanding the Reach of Federated Learning by Reducing Client Resource Requirements", "publication_date": "2018-00-00", "reason": "This work highlights the practical challenges of federated learning, particularly concerning client resource constraints, directly motivating the need for efficient quantization techniques like those explored in the target paper."}, {"fullname_first_author": "S. Vargaftik", "paper_title": "EDEN: Communication-Efficient and Robust Distributed Mean Estimation for Federated Learning", "publication_date": "2022-00-00", "reason": "This paper is highly relevant due to its focus on communication-efficient distributed mean estimation, which is directly related to the ASQ problem and the proposed QUIVER algorithm."}, {"fullname_first_author": "D. Alistarh", "paper_title": "QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding", "publication_date": "2017-00-00", "reason": "This work is highly influential, proposing the communication-efficient QSGD algorithm that employs gradient quantization, a technique that is closely related to and builds upon the ideas presented in the target paper."}]}