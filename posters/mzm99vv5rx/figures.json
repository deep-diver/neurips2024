[{"figure_path": "MzM99vV5Rx/figures/figures_1_1.jpg", "caption": "Figure 1: An example of human-model interactive question answering (IQA) and our automatic evaluation (IQA-EVAL). The two interactions occur with two types of personas in humans (or LLM-based evaluation agents): Expert and Clarity-seeker, and are evaluated by humans or agents with corresponding personas. The IQA model only responds to the immediately preceding prompt without further contexts like the question itself (leftmost in the Figure).", "description": "This figure illustrates an example of human-model interactive question answering (IQA) and the automatic evaluation framework IQA-EVAL. It shows two interaction scenarios, one with an \"Expert\" persona and another with a \"Clarity-seeker\" persona.  Each interaction involves a human (or LLM-based Evaluation Agent) asking questions to an IQA model.  The model responds, and then the interaction is evaluated by a human (or agent) with a matching persona. The key point highlighted is that the IQA model only processes the immediately preceding prompt, without considering earlier parts of the conversation.", "section": "1 Introduction"}, {"figure_path": "MzM99vV5Rx/figures/figures_3_1.jpg", "caption": "Figure 1: An example of human-model interactive question answering (IQA) and our automatic evaluation (IQA-EVAL). The two interactions occur with two types of personas in humans (or LLM-based evaluation agents): Expert and Clarity-seeker, and are evaluated by humans or agents with corresponding personas. The IQA model only responds to the immediately preceding prompt without further contexts like the question itself (leftmost in the Figure).", "description": "This figure shows an example of human-model interactive question answering (IQA) and how the IQA-EVAL framework automatically evaluates these interactions.  Two interaction scenarios are depicted, one with an \"Expert\" persona and another with a \"Clarity-seeker\" persona. Each interaction is evaluated based on criteria such as fluency and helpfulness, either by human evaluators or by LLM-based agents simulating those human evaluators.  Importantly, the IQA model's responses are only based on the immediately preceding prompt in the conversation, without broader context.", "section": "1 Introduction"}, {"figure_path": "MzM99vV5Rx/figures/figures_5_1.jpg", "caption": "Figure 1: An example of human-model interactive question answering (IQA) and our automatic evaluation (IQA-EVAL). The two interactions occur with two types of personas in humans (or LLM-based evaluation agents): Expert and Clarity-seeker, and are evaluated by humans or agents with corresponding personas. The IQA model only responds to the immediately preceding prompt without further contexts like the question itself (leftmost in the Figure).", "description": "This figure illustrates an example of human-model interactive question answering (IQA) and the proposed automatic evaluation method, IQA-EVAL. It showcases two interaction scenarios with different personas (Expert and Clarity-seeker), highlighting how the automatic evaluation agent simulates human behavior and assesses the IQA model's responses based on established evaluation criteria. The figure emphasizes the dynamic nature of human-AI interactions and the limitations of traditional single-turn evaluation methods.", "section": "1 Introduction"}]