{"references": [{"fullname_first_author": "T. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational for the field of large language models (LLMs), introducing the concept that LLMs can be effective few-shot learners, which is directly relevant to the current paper's focus on efficient online adaptation of LLMs."}, {"fullname_first_author": "N. Hu", "paper_title": "Meta-learning online adaptation of language models", "publication_date": "2023-12-01", "reason": "This paper directly addresses the problem of online adaptation of LLMs and proposes a gradient-based meta-learning approach, providing a key baseline that the current paper builds upon and improves upon."}, {"fullname_first_author": "J. Ball\u00e9", "paper_title": "Variational image compression with a scale hyperprior", "publication_date": "2018-12-01", "reason": "This paper introduces an efficient method for compressing images, providing a relevant foundation for the current paper\u2019s memory-efficient techniques which also compresses large volumes of document data."}, {"fullname_first_author": "M. Garnelo", "paper_title": "Conditional neural processes", "publication_date": "2018-12-01", "reason": "This paper introduces conditional neural processes, a type of meta-learning model, which is closely related to the current paper\u2019s use of amortization-based meta-learning for efficient online adaptation."}, {"fullname_first_author": "K. Guu", "paper_title": "Retrieval augmented language model pre-training", "publication_date": "2020-12-01", "reason": "This paper introduces retrieval augmented generation (RAG), providing a critical technique for enhancing LLM performance by incorporating external knowledge, which the current paper utilizes and improves upon."}]}