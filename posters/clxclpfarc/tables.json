[{"figure_path": "CLxcLPfARc/tables/tables_8_1.jpg", "caption": "Table 1: C-ASR of embedding space attacks (using either 1, 5, or 20 suffix tokens for the attack) and the two baselines HPA and PDA for the LlamaHP model on the Harry Potter Q&A.", "description": "This table presents the cumulative attack success rate (C-ASR) achieved by different embedding space attack methods on the LlamaHP model for the Harry Potter Q&A task.  It compares the performance of attacks using varying numbers of suffix tokens (1, 5, or 20) with two baseline methods, Head Projection Attack (HPA) and Probability Delta Attack (PDA).  The C-ASR metric indicates the percentage of queries for which the correct answer appears at least once across multiple attack attempts.  Higher C-ASR values indicate more successful attacks.", "section": "6 Attacking Unlearned Models"}, {"figure_path": "CLxcLPfARc/tables/tables_9_1.jpg", "caption": "Table 6: Cumulative ROUGE-1 score of universal embedding space attacks against an unlearned Llama2 model on the TOFU 1% forget dataset using train test splits. Multi-layer attacks are not used.", "description": "This table shows the results of universal embedding space attacks on the TOFU unlearning benchmark's 1% forget dataset, comparing different numbers of attacked tokens and training/testing data splits.  The ROUGE-1 score, a metric for evaluating the quality of text summarization, is used to assess the model's ability to generate responses for unseen data.  The table illustrates the impact of different attack strategies (individual vs. universal attacks) and parameters (number of attacked tokens) on the model's performance after unlearning.", "section": "K Universal Attacks on the TOFU dataset"}, {"figure_path": "CLxcLPfARc/tables/tables_15_1.jpg", "caption": "Table 3: Summary of models used in this work.", "description": "This table lists the seven different open-source LLMs used in the paper's experiments.  It includes the model name, the reference where the model is described, and a URL to access the model on Hugging Face.", "section": "4.1 Models"}, {"figure_path": "CLxcLPfARc/tables/tables_17_1.jpg", "caption": "Table 4: Examples of responses to the questions in the Harry Potter Q&A dataset for the LlamaHP model with and without attack. Answers were shortened for readability if no relevant information was within the remaining tokens. The optimization target of the attack is highlighted with blue color. Unicode emojis are replaced with (emoji).", "description": "This table presents example questions from the Harry Potter Q&A dataset and compares the model's responses with and without embedding space attacks.  It showcases the model's ability to retrieve previously unlearned information when subjected to these attacks, highlighting the effectiveness of the method in uncovering residual knowledge.", "section": "G Harry Potter Unlearning"}, {"figure_path": "CLxcLPfARc/tables/tables_19_1.jpg", "caption": "Table 5: Cumulative Success rate of embedding space attacks against the LlamaHP model on the Harry Potter Q&A dataset using train test splits.", "description": "This table presents the cumulative success rate of embedding space attacks against the LlamaHP model on the Harry Potter Q&A dataset.  It shows the results for both universal attacks (using all layers) and attacks using only the last layer. The success rates are broken down for different train/test splits (50/50 and 25/75) and varying numbers of attacked tokens (1, 5, and 20).  The table quantifies the model's vulnerability to these attacks under different data conditions and attack parameters.  Higher percentages represent a greater likelihood of the attack successfully retrieving the targeted information.", "section": "J Universal Attacks on the Harry Potter Q&A"}, {"figure_path": "CLxcLPfARc/tables/tables_19_2.jpg", "caption": "Table 6: Cumulative ROUGE-1 score of universal embedding space attacks against an unlearned Llama2 model on the TOFU 1% forget dataset using train test splits. Multi-layer attacks are not used.", "description": "This table shows the results of universal embedding space attacks on an unlearned Llama2 model using the TOFU benchmark's 1% forget dataset.  It presents the cumulative ROUGE-1 scores achieved by these attacks under different train/test splits (50/50 and 25/75) and varying numbers of attacked tokens (1, 5, and 20). The results illustrate the performance of the attacks in generalizing to unseen data and highlight the impact of the number of tokens targeted during the attack.", "section": "K Universal Attacks on the TOFU dataset"}]