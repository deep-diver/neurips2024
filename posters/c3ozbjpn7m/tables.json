[{"figure_path": "c3OZBJpN7M/tables/tables_8_1.jpg", "caption": "Table 1: Results on data partitions generated from Dirichlet distribution with the concentration parameter \u03b2 = 0.5. The number of clients is 10, 20, and 50; the clients utilize 10%, 20%, and 50% of the datasets. A single client's averaged wall-clock time per round is measured across 2 A100 GPUs in a parallel manner. The reported local and global accuracies are the averages of the last 5 rounds.", "description": "This table presents the experimental results of various federated learning methods on three benchmark datasets (SVHN, CIFAR-10, CIFAR-100) with varying numbers of clients and data heterogeneity levels.  The results are shown in terms of local and global accuracies, along with average training time per client.  The table allows for comparison of FedGMKD with other state-of-the-art methods under different Non-IID data settings.", "section": "4.5 Results"}, {"figure_path": "c3OZBJpN7M/tables/tables_16_1.jpg", "caption": "Table 2: Performance of different schemes on CIFAR-10 and SVHN datasets under various data heterogeneity settings controlled by Dirichlet distribution parameter \u03b2.", "description": "This table presents the results of various federated learning methods on CIFAR-10 and SVHN datasets under different levels of data heterogeneity, controlled by the Dirichlet distribution parameter \u03b2.  A smaller \u03b2 indicates higher heterogeneity (data imbalance and non-overlapping feature spaces), while a larger \u03b2 implies more homogeneity. The table shows the local and global accuracy achieved by each method under both high (\u03b2 = 0.2) and low (\u03b2 = 5) heterogeneity conditions.  It demonstrates how each algorithm performs across varying levels of data heterogeneity.", "section": "4.5 Results"}, {"figure_path": "c3OZBJpN7M/tables/tables_16_2.jpg", "caption": "Table 2: Performance of different schemes on CIFAR-10 and SVHN datasets under various data heterogeneity settings controlled by Dirichlet distribution parameter \u03b2.", "description": "This table compares the performance of various federated learning schemes (FedAvg, FedProx, FedMD, FedGen, MOON, FedProto, FPL, FjORD, and FedGMKD) on CIFAR-10 and SVHN datasets under different levels of data heterogeneity.  The heterogeneity is controlled by the Dirichlet distribution parameter \u03b2, where a smaller \u03b2 indicates higher heterogeneity. The table reports the local and global accuracy for each scheme under two different \u03b2 values (0.2 and 5) for both datasets.  This allows for a comparison of the algorithms' robustness to varying degrees of data heterogeneity across different client data distributions.", "section": "4.5 Results"}, {"figure_path": "c3OZBJpN7M/tables/tables_17_1.jpg", "caption": "Table 4: Comparison of performance for various schemes on CIFAR-10 using ResNet-18 and ResNet-50 architectures.", "description": "This table compares the performance of different federated learning schemes (FedAvg, FedProx, FedMD, FedGen, FedProto, Moon, FPL, and FedGMKD) on the CIFAR-10 dataset using two different model architectures: ResNet-18 and ResNet-50.  For each scheme and architecture, the table shows the local and global accuracy achieved.  This allows for a comparison of performance across different methods and model complexities.", "section": "4.4.3 Impact of Model Complexity"}, {"figure_path": "c3OZBJpN7M/tables/tables_18_1.jpg", "caption": "Table 5: FedGMKD performance with varying \u03bb and \u03b3 values on CIFAR-10 dataset (10 clients, 50 epochs).", "description": "This table presents the results of an ablation study on the CIFAR-10 dataset using FedGMKD with varying regularization coefficients \u03bb and \u03b3.  It shows the impact of different \u03bb and \u03b3 values on both local and global accuracy.  Baseline results for FedAvg, FedProto, and FPL are also included for comparison, allowing an assessment of FedGMKD's performance relative to other state-of-the-art methods in this specific setting.", "section": "4.4 Hyperparameter Exploration in FedGMKD"}, {"figure_path": "c3OZBJpN7M/tables/tables_19_1.jpg", "caption": "Table 6: Comparison of Hyper-Knowledge Averaging with DAT and FedGMKD on CIFAR-10, SVHN, and CIFAR-100 datasets with \u03b2 = 0.5.", "description": "This table compares the performance of FedGMKD against a baseline method that uses hyper-knowledge averaging with DAT.  The comparison is performed across three datasets (CIFAR-10, SVHN, CIFAR-100) with varying numbers of clients.  The results show local and global accuracy for each method, highlighting FedGMKD's superior performance in achieving higher accuracies across all datasets and client configurations.", "section": "A.4.5 Comparison Between Hyper-Knowledge Averaging with DAT and FedGMKD"}, {"figure_path": "c3OZBJpN7M/tables/tables_19_2.jpg", "caption": "Table 7: Performance of different schemes on IMDB dataset using BERT model (10 clients, 50 epochs).", "description": "This table presents the results of an experiment evaluating various federated learning schemes on the IMDB dataset using a BERT model. The experiment was conducted with 10 clients over 50 training epochs. The table compares the local and global accuracy, as well as the average computation time per client, for each of the evaluated schemes: FedAvg, FedProx, FedMD, FedGen, FedProto, FPL, and FedGMKD. This table shows how well each model performs on the sentiment analysis task of the IMDB dataset in the context of federated learning.", "section": "A.4.6 Evaluation on IMDB Dataset"}]