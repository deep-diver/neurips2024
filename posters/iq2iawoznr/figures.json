[{"figure_path": "Iq2IAWozNr/figures/figures_2_1.jpg", "caption": "Figure 1: Causal Model for generic partially annotated scientific experiment: T treatment, W experimental settings, X high-dimensional observation, Y outcome, S annotation flag.", "description": "This figure shows a causal graph representing a generic partially annotated scientific experiment.  The variables are: T (treatment), W (experimental settings), X (high-dimensional observation), Y (outcome), and S (annotation flag). The arrows indicate causal relationships. For instance, the treatment (T) influences the high-dimensional observation (X), and the observation (X) influences the outcome (Y).  The annotation flag (S) is influenced by the experimental settings (W). This model is used to represent the process of estimating the average treatment effect (ATE) in a scenario where annotating the outcome Y for all data points is expensive, so only a subset of data is annotated.", "section": "2 Setting"}, {"figure_path": "Iq2IAWozNr/figures/figures_2_2.jpg", "caption": "Figure 2: Examples of high-dimensional observations X with corresponding annotated social behaviour Y from ISTAnt (ours).", "description": "This figure shows two example images from the ISTAnt dataset.  The images are high-dimensional observations (X) of ants exhibiting social behavior.  The figure visually represents the complexity of the data involved in the study, highlighting the need for sophisticated methods to extract meaningful information for causal inference. (a) depicts ants engaging in grooming behavior (blue ant to focal ant), indicating a positive outcome (Y). (b) depicts ants not engaging in grooming behavior, indicating a negative or null outcome (Y). These images showcase the type of visual data used for the causal inference tasks detailed in the paper.", "section": "1 Introduction"}, {"figure_path": "Iq2IAWozNr/figures/figures_4_1.jpg", "caption": "Figure 3: Monte-Carlo simulation of the discretization bias' convergence result.", "description": "This figure shows the results of a Monte Carlo simulation to illustrate the impact of discretization bias on the estimation of the associational difference.  It demonstrates that while a non-discretized model converges to the true associational difference (AD), a discretized version converges to a different, biased value. The degree of bias depends on the randomness in the outcome variable. The figure is used to visually support Theorem 3.1. which shows that discretizing model predictions introduces bias in downstream causal tasks.", "section": "3 Biases in downstream ATE estimation from ML pipelines"}, {"figure_path": "Iq2IAWozNr/figures/figures_7_1.jpg", "caption": "Figure 4: Violin plots comparing the Treatment Effect Relative Bias (TERB) per annotation criteria in few and many annotations regime. Biased annotations lead to biased ATE estimation (i.e., TERB\u22600) and random annotation should be preferred.", "description": "This figure showcases the impact of different annotation criteria (random, experiment-based, position-based) on the Treatment Effect Relative Bias (TERB) when estimating the average treatment effect (ATE).  It compares the results for both few-shot and many-shot learning settings. The key takeaway is that biased annotation methods (experiment and position) lead to a significantly biased ATE estimation, while the random annotation method produces a TERB closer to zero, indicating more accurate results.", "section": "6 Results"}, {"figure_path": "Iq2IAWozNr/figures/figures_7_2.jpg", "caption": "Figure 4: Violin plots comparing the Treatment Effect Relative Bias (TERB) per annotation criteria in few and many annotations regime. Biased annotations lead to biased ATE estimation (i.e., TERB\u22600) and random annotation should be preferred.", "description": "This figure shows violin plots illustrating the Treatment Effect Relative Bias (TERB) for different annotation criteria in both few-shot and many-shot learning settings.  The x-axis represents the annotation criteria (Random, Experiment, Position), while the y-axis shows the TERB.  Separate plots are provided for 'many annotations' and 'few annotations' scenarios, highlighting how the choice of annotation strategy impacts the bias in estimating the average treatment effect. The plots show that the random annotation method leads to less bias compared to the other methods (Experiment, Position), particularly in the few-shot setting.  This result supports the paper's claim that using a biased annotation strategy introduces a bias in the estimation of the causal effect, while random sampling produces more accurate results.", "section": "6 Results"}, {"figure_path": "Iq2IAWozNr/figures/figures_7_3.jpg", "caption": "Figure 5: Scatter plot comparing the TERB and balanced accuracy in prediction among the 20 best models per 6 established encoders. Despite different downstream prediction performances, all the encoders (with excepts of MAE) lead to similar TERB (up to \u00b1 50%).", "description": "This figure shows a scatter plot illustrating the relationship between the Treatment Effect Relative Bias (TERB) and the balanced accuracy achieved by the top 20 models for each of six different encoders.  The x-axis represents balanced accuracy, while the y-axis represents TERB.  Each point in the plot represents a model, and the color of each point represents the specific encoder used.  The plot demonstrates that even with high balanced accuracy (above 0.95), there's substantial variation in TERB, ranging from approximately -0.5 to +0.5.  This suggests that high predictive accuracy doesn't necessarily translate to accurate causal effect estimation.", "section": "6 Results"}, {"figure_path": "Iq2IAWozNr/figures/figures_8_1.jpg", "caption": "Figure 6: Spearman rank-order correlation matrix comparing different metrics for model selection on validation (subscript val) and over the full dataset (subscript D). We considered all the 1620 fine-tuned models to predict \u2018Blue to Focal\u2019 or \u2018Orange to Focal\u2019 grooming in few-annotations regime (i.e., |Ds| << Du). Standard prediction metrics on validation correlate, but they are almost independent of the |TEB|val. Similarly, they correlate with the prediction metrics on the full dataset but poorly predict the |TEB|D. On the other hand, |TEB|val is the most correlated metric with |TEB|D, unlike even the prediction metrics on the full dataset.", "description": "This figure shows the Spearman rank-order correlation between different metrics for model selection. The metrics considered are BCE loss, accuracy, balanced accuracy, and treatment effect bias (TEB) on both validation and full datasets. The results indicate that standard prediction metrics on the validation set have low correlation with the TEB on the full dataset, while the TEB on the validation set shows high correlation with the TEB on the full dataset.", "section": "6 Results"}, {"figure_path": "Iq2IAWozNr/figures/figures_16_1.jpg", "caption": "Figure 1: Causal Model for generic partially annotated scientific experiment: T treatment, W experimental settings, X high-dimensional observation, Y outcome, S annotation flag.", "description": "This figure presents a causal model illustrating the relationships between different variables in a generic partially annotated scientific experiment.  T represents the treatment, W denotes the experimental settings or conditions, X signifies high-dimensional observations or data, Y is the outcome variable, and S indicates the annotation flag (whether an observation is annotated or not). The arrows in the diagram showcase the causal relationships between these variables.", "section": "2 Setting"}, {"figure_path": "Iq2IAWozNr/figures/figures_18_1.jpg", "caption": "Figure 8: Random samples from CausalMNIST dataset.", "description": "This figure shows six example images from the CausalMNIST dataset.  The dataset is a synthetic dataset created by manipulating the MNIST dataset to control for the causal model.  The images illustrate how the background color (green or red) and the digit color (white or black) are varied to create different causal effects on the outcome variable Y, representing whether the digit is greater than a threshold value (d).  This variation allows researchers to study the impact of different experimental design choices on downstream causal inference tasks.", "section": "E CausalMNIST"}, {"figure_path": "Iq2IAWozNr/figures/figures_20_1.jpg", "caption": "Figure 4: Violin plots comparing the Treatment Effect Relative Bias (TERB) per annotation criteria in few and many annotations regime. Biased annotations lead to biased ATE estimation (i.e., TERB\u22600) and random annotation should be preferred.", "description": "This figure shows violin plots visualizing the Treatment Effect Relative Bias (TERB) for different annotation criteria (random, experiment, position) in both few-shot and many-shot learning scenarios.  The plots reveal that biased annotation methods (experiment and position) result in a significantly biased TERB, while random annotation methods yield a TERB closer to zero, indicating unbiased ATE estimation.  The results highlight the importance of unbiased sampling techniques in causal inference tasks.", "section": "6 Results"}, {"figure_path": "Iq2IAWozNr/figures/figures_21_1.jpg", "caption": "Figure 10: Violin plots of the TERB of the model (discretized or not) for both random and biased annotation sampling, varying number of annotations (few/many) and seeds.", "description": "This figure shows violin plots comparing the Treatment Effect Relative Bias (TERB) for models with and without discretization, under both random and biased annotation sampling schemes.  The plots are separated into 'many annotations' and 'few annotations' scenarios to show how the sampling strategy affects bias.  The horizontal dashed line represents a TERB of zero (no bias). The plots illustrate that biased annotation generally leads to higher bias than random annotation, and discretization adds extra bias.", "section": "Results"}, {"figure_path": "Iq2IAWozNr/figures/figures_22_1.jpg", "caption": "Figure 11: Spearman rank-order correlation matrix comparing different metrics for model selection on validation (subscript val) and over the full dataset (subscript D). We considered all the 200 models trained with random sampling, varying the number of annotations (few and many) and seeds. Standard prediction metrics on validation strongly correlate, but they are less associated with |TEB|val. Similarly, they correlate with the prediction metrics on the full dataset but poorly predict the |TEB|D. On the other hand, |TEB|val is the most correlated metric with |TEB|D, unlike even the prediction metrics on the full dataset.", "description": "This figure shows the Spearman rank-order correlation matrix between different metrics for model selection.  It compares results from validation and the full dataset using 200 models trained with random sampling and varying annotation numbers (few and many).  It highlights that while standard prediction metrics correlate well within each dataset, they are less predictive of the treatment effect bias (TEB) on the full dataset. Notably, the TEB from validation is the strongest predictor of TEB on the full dataset.", "section": "Results"}, {"figure_path": "Iq2IAWozNr/figures/figures_23_1.jpg", "caption": "Figure 5: Scatter plot comparing the TERB and balanced accuracy in prediction among the 20 best models per 6 established encoders. Despite different downstream prediction performances, all the encoders (with excepts of MAE) lead to similar TERB (up to \u00b1 50%).", "description": "This figure shows a scatter plot illustrating the relationship between the Treatment Effect Relative Bias (TERB) and balanced accuracy for prediction. The data points represent the top 20 models from six different encoder architectures (ViT-B, ViT-L, CLIP-ViT-B, CLIP-ViT-L, MAE, and DINOv2).  It demonstrates that even with high balanced accuracy (above 0.95), the TERB can vary significantly (up to \u00b150%), indicating that high prediction accuracy doesn't guarantee accurate causal effect estimation. The exception is MAE, which underperforms other encoders possibly due to focusing on background instead of the ants.", "section": "6 Results"}]