{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, a foundational vision-language model that the TransAgent framework builds upon and improves."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked autoencoders are scalable vision learners", "publication_date": "2022-06-01", "reason": "MAE is a key vision agent integrated into TransAgent, providing detailed image modeling capabilities crucial for the framework's performance."}, {"fullname_first_author": "Matthieu Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-10-01", "reason": "DINO, another important vision agent, is leveraged in TransAgent for its visual knowledge, complementing CLIP and enhancing overall performance."}, {"fullname_first_author": "Bowen Cheng", "paper_title": "Segment Anything", "publication_date": "2023-10-01", "reason": "SAM is a crucial vision agent that contributes instance-level prediction capabilities, improving TransAgent's versatility in handling various visual tasks."}, {"fullname_first_author": "Junnan Li", "paper_title": "BLIP-2: Bootstrapping language-image pre-training with frozen image encoders and large language models", "publication_date": "2023-07-23", "reason": "BLIP-2 serves as a key multi-modal agent in TransAgent, facilitating improved alignment between visual and textual prompts and enhancing the model's multi-modal understanding."}]}