[{"figure_path": "FjssnGuHih/tables/tables_4_1.jpg", "caption": "Table 1: List of all public datasets used to train our model. '# Image' denotes the number of unique images in the entire dataset. Note that for annotation 'scanpath', there are multiple scanpaths recorded from a group of users associated with one image, so '# Training Sample' is much larger than '# Image'. During training, we randomly sample from all training datasets with an equal sampling rate.", "description": "This table lists eleven publicly available datasets used to train the UniAR model.  Each dataset is characterized by its domain (e.g., natural images, webpages), the type of annotation provided (attention heatmap, scanpath, subjective rating), the viewing style used for data collection (free-viewing or object-searching), the number of unique images, the image resolution, and the number of training samples.  Note that the number of training samples for scanpath datasets is significantly higher than the number of images because multiple scanpaths are recorded per image.", "section": "4 Experiment"}, {"figure_path": "FjssnGuHih/tables/tables_6_1.jpg", "caption": "Table 2: Subjective rating prediction results on Natural image image dataset KonIQ-10k and webpage dataset Web Aesthetics.", "description": "This table presents the results of subjective rating prediction on two datasets: KonIQ-10k (natural images) and Web Aesthetics (webpages).  It compares the performance of UniAR against several state-of-the-art (SOTA) methods using SRCC and PLCC metrics, which measure the rank correlation and Pearson linear correlation between predicted and ground truth ratings, respectively. The table shows that UniAR achieves competitive or superior performance to the existing SOTA models on these two datasets.", "section": "4.3 Experiment Results"}, {"figure_path": "FjssnGuHih/tables/tables_7_1.jpg", "caption": "Table 3: Heatmap prediction results on 7 public datasets across natural images, art, cartoons, mobile UIs, and webpages (Please refer to Table 6 in Appendix C for complete baselines & metrics). For Imp1k we predict the importance heatmap, while for the remaining datasets, we predict the attention/saliency heatmap. For each dataset and metric, the best result is in bold, second best is in blue, and our method is highlighted in green. For our model, the relative performance change compared to the best result is noted. Note that the metric values for baseline models are obtained from existing references as described in the \"Benchmarks\" paragraph. \"-\" means the metrics are not reported in references. Also note that there are two versions of Salicon data, Salicon 2015 and Salicon 2017. The results in this table are on Salicon 2017.", "description": "This table presents the performance of the UniAR model and other state-of-the-art models on heatmap prediction tasks across seven different datasets.  The datasets cover various image types (natural images, art, cartoons, mobile UIs, webpages) and tasks (saliency and importance heatmaps).  The table shows the results for multiple evaluation metrics, highlighting UniAR's performance relative to the best-performing models for each dataset and metric.", "section": "4.3 Experiment Results"}, {"figure_path": "FjssnGuHih/tables/tables_8_1.jpg", "caption": "Table 4: Scanpath (sequence) prediction results on natural image and digital design datasets, with object-searching and free-viewing tasks.", "description": "This table presents the performance of UniAR and other methods on scanpath prediction tasks using two datasets: COCO-Search18 (object searching in natural images) and WS-Scanpath (free viewing of webpages).  It compares the models' performance across several metrics designed to evaluate the accuracy of predicted scanpaths, including their shape, direction, length, position, and an overall multi-match score.", "section": "4.3 Experiment Results"}, {"figure_path": "FjssnGuHih/tables/tables_8_2.jpg", "caption": "Table 5: Experiments on transferring knowledge from other domain/task combinations to WS-Scanpath dataset for scanpath predictions. CC = COCO-FreeView dataset.", "description": "This table presents the results of experiments designed to evaluate the model's ability to transfer knowledge learned from one task/domain combination to another unseen task/domain combination.  Specifically, it investigates the model's performance on the WS-Scanpath dataset (webpage scanpath prediction) after being trained on different combinations of data from the WS-Scanpath dataset itself, COCO-FreeView (natural image scanpath and saliency), and WS-Saliency (webpage saliency). The results show the Sequence Score and MultiMatch metrics, which evaluate the accuracy of the predicted scanpaths.", "section": "4.3 Experiment Results"}, {"figure_path": "FjssnGuHih/tables/tables_16_1.jpg", "caption": "Table 3: Heatmap prediction results on 7 public datasets across natural images, art, cartoons, mobile UIs, and webpages (Please refer to Table 6 in Appendix C for complete baselines & metrics). For Imp1k we predict the importance heatmap, while for the remaining datasets, we predict the attention/saliency heatmap. For each dataset and metric, the best result is in bold, second best is in blue, and our method is highlighted in green. For our model, the relative performance change compared to the best result is noted. Note that the metric values for baseline models are obtained from existing references as described in the \"Benchmarks\" paragraph. \"-\" means the metrics are not reported in references. Also note that there are two versions of Salicon data, Salicon 2015 and Salicon 2017. The results in this table are on Salicon 2017.", "description": "This table presents the performance of UniAR and several baseline methods on seven different public datasets for heatmap prediction.  The datasets encompass various visual content types (natural images, art, cartoons, mobile UIs, and webpages), and the task is either predicting saliency heatmaps or importance heatmaps.  The table shows several metrics to compare the performance, including Correlation Coefficient (CC), Kullback-Leibler Divergence (KLD), AUC-Judd, shuffled AUC (SAUC), Similarity (SIM), Normalized Scanpath Saliency (NSS), Root Mean Square Error (RMSE), and R-squared (R2).  The best performing model for each metric and dataset is highlighted.  UniAR's performance is compared to the previous state-of-the-art (SOTA) models. Note that some datasets have different types of heatmaps (saliency vs. importance).", "section": "4.3 Experiment Results"}, {"figure_path": "FjssnGuHih/tables/tables_17_1.jpg", "caption": "Table 4: Scanpath (sequence) prediction results on natural image and digital design datasets, with object-searching and free-viewing tasks.", "description": "This table presents the performance of UniAR and other methods on scanpath prediction.  It compares the results across two different datasets: COCO-Search18 (object searching in natural images) and WS-Scanpath (free viewing of webpages).  The metrics used to evaluate the performance include SemSS, SemFED, Sequence Score, Shape, Direction, Length, Position, and MultiMatch.  Each metric quantifies different aspects of the predicted scanpath's similarity to the ground truth.", "section": "4.3 Experiment Results"}]