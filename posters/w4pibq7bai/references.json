{"references": [{"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-MM-DD", "reason": "This paper introduces a foundational large language model (LLM) architecture that underpins many of the models evaluated in the MEDIQ benchmark."}, {"fullname_first_author": "Di Jin", "paper_title": "What disease does this patient have? A large-scale open domain question answering dataset from medical exams", "publication_date": "2021-MM-DD", "reason": "This paper introduces MEDQA, a key dataset that was adapted to create a significant portion of the MEDIQ benchmark."}, {"fullname_first_author": "Shreya Johri", "paper_title": "Testing the limits of language models: A conversational framework for medical AI assessment", "publication_date": "2023-MM-DD", "reason": "This paper introduces CRAFT-MD, another key dataset that was adapted to create a portion of the MEDIQ benchmark."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-MM-DD", "reason": "This paper introduces Llama-2, one of the state-of-the-art LLMs used in the MEDIQ benchmark."}, {"fullname_first_author": "Melanie Sclar", "paper_title": "Quantifying language models' sensitivity to spurious features in prompt design or: How I learned to start worrying about prompt formatting", "publication_date": "2023-MM-DD", "reason": "This paper highlights the sensitivity of LLMs to prompt variations, which is relevant to the MEDIQ benchmark's focus on interaction design."}]}