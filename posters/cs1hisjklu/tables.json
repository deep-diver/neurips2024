[{"figure_path": "cs1HISJkLU/tables/tables_7_1.jpg", "caption": "Table 2: Quantitative comparison between our AVDIT with MoNL and MM-Diffusion (MMD).", "description": "This table presents a quantitative comparison of the proposed AVDIT model trained with the Mixture of Noise Levels (MoNL) against the MM-Diffusion baseline.  The comparison uses Fr\u00e9chet metrics (FAD and FVD) to evaluate the quality of audio and video generation across several tasks: joint audio-video generation, audio-to-video generation, video-to-audio generation, and two interpolation tasks (inpainting and continuation). The results demonstrate the superior performance of AVDIT with MoNL across most tasks and metrics.", "section": "6.2 Evaluation Settings"}, {"figure_path": "cs1HISJkLU/tables/tables_15_1.jpg", "caption": "Table 1: Comparison of AVDiT trained with mixture of noise levels (MoNL) on the Monologues dataset for unconditional joint generation (Joint), cross-modal (A2V, V2A) and multimodal interpolation (AV-inpaint, AV-continue) tasks. FAD = 2.7 and FVD = 3.3 for groundtruth autoencoder reconstructions of the inputs.", "description": "This table presents a quantitative comparison of the proposed Audiovisual Diffusion Transformer (AVDIT) model trained with the Mixture of Noise Levels (MoNL) approach against various baseline methods.  The evaluation metrics (Fr\u00e9chet Audio Distance (FAD) and Fr\u00e9chet Video Distance (FVD)) assess the quality of generated audio and video, respectively, across different tasks: unconditional joint generation, audio-to-video (A2V), video-to-audio (V2A), and two types of multimodal interpolation (AV-inpaint and AV-continue). The ground truth autoencoder reconstruction FAD and FVD values are also provided for reference.", "section": "6. Experiments"}, {"figure_path": "cs1HISJkLU/tables/tables_15_2.jpg", "caption": "Table 1: Comparison of AVDiT trained with mixture of noise levels (MoNL) on the Monologues dataset for unconditional joint generation (Joint), cross-modal (A2V, V2A) and multimodal interpolation (AV-inpaint, AV-continue) tasks. FAD = 2.7 and FVD = 3.3 for groundtruth autoencoder reconstructions of the inputs. Fr\u00e9chet metrics estimated with N=25k.", "description": "This table compares the performance of the proposed Audiovisual Diffusion Transformer (AVDIT) model trained with the Mixture of Noise Levels (MoNL) approach against various baselines across different audiovisual generation tasks.  The tasks include unconditional joint generation, cross-modal generation (audio-to-video and video-to-audio), and multimodal interpolation (inpainting and continuation).  The Fr\u00e9chet audio distance (FAD) and Fr\u00e9chet video distance (FVD) metrics are used to evaluate the quality of the generated audio and video, respectively.  Lower FAD and FVD scores indicate better generation quality.  The table also provides ablation results comparing the MoNL approach to other variable noise level strategies and a vanilla baseline.", "section": "6 Experiments"}, {"figure_path": "cs1HISJkLU/tables/tables_15_3.jpg", "caption": "Table 1: Comparison of AVDiT trained with mixture of noise levels (MoNL) on the Monologues dataset for unconditional joint generation (Joint), cross-modal (A2V, V2A) and multimodal interpolation (AV-inpaint, AV-continue) tasks. FAD = 2.7 and FVD = 3.3 for groundtruth autoencoder reconstructions of the inputs. Fr\u00e9chet metrics estimated with N=25k.", "description": "This table presents a quantitative comparison of the proposed Audiovisual Diffusion Transformer (AVDIT) model trained using the Mixture of Noise Levels (MoNL) approach against several baseline methods across various audiovisual generation tasks.  The tasks include unconditional joint generation, cross-modal generation (audio-to-video and vice-versa), and multimodal interpolation. The performance is measured using Fr\u00e9chet Inception Distance (FID) for video (FVD) and Fr\u00e9chet Audio Distance (FAD) for audio. The ground truth autoencoder reconstructions provide a baseline for comparison.  The results show the performance gains achieved by MoNL across various tasks.", "section": "6 Experiments"}, {"figure_path": "cs1HISJkLU/tables/tables_19_1.jpg", "caption": "Table 7: Comparison of AVDiT trained with mixture of noise levels (MoNL) on the Monologues dataset for AV-continue-2s) to fill out 2 seconds of AV given the first video frame and corresponding 0.125s of audio AV-continue-1.5s) to fill out 1.5 seconds of AV given the first 5 video frames and corresponding 0.625s of audio. FAD = 2.7 and FVD = 3.3 for ground truth autoencoder reconstructions of the inputs. Fr\u00e9chet metrics estimated with N=25k.", "description": "This table compares the performance of different training methods (conditional, per modality, vanilla, MONL, etc.) on two audiovisual continuation tasks.  The tasks differ in the amount of conditioning information provided (1 frame vs. 5 frames of video, and corresponding audio).  The Fr\u00e9chet audio distance (FAD) and Fr\u00e9chet video distance (FVD) metrics are reported, evaluating the quality of the generated audio and video, respectively.  Lower FAD and FVD values indicate better performance.", "section": "6 Experiments"}]