{"references": [{"fullname_first_author": "Antoine Bordes", "paper_title": "Translating embeddings for modeling multi-relational data", "publication_date": "2013-01-01", "reason": "This paper introduces TransE, a foundational model for knowledge graph embedding that is heavily used in many entity alignment methods, including those cited in the target paper."}, {"fullname_first_author": "Liyi Chen", "paper_title": "MMEA: Entity alignment for multi-modal knowledge graph", "publication_date": "2020-01-01", "reason": "This paper is among the earliest works on multi-modal entity alignment and introduces many concepts that are expanded upon in the target paper."}, {"fullname_first_author": "Ye Liu", "paper_title": "MMKG: multi-modal knowledge graphs", "publication_date": "2019-01-01", "reason": "This paper introduces the concept of Multi-Modal Knowledge Graphs (MMKGs), the core object of study in the target paper."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019-01-01", "reason": "BERT is a foundational model for natural language processing that is used in the target paper for attribute alignment."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-01-01", "reason": "Vision Transformer (ViT) is used in the target paper for visual knowledge encoding; this paper introduces ViT."}]}