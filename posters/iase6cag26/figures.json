[{"figure_path": "IAse6CAG26/figures/figures_1_1.jpg", "caption": "Figure 1: A toy example to illustrate the uncertain correspondences in multi-modal entity alignment, where entities are highlighted with a yellow background.", "description": "This figure shows a simplified example of multi-modal entity alignment, highlighting the challenges posed by uncertain correspondences between entities across different knowledge graphs.  It demonstrates how entities with weak semantic associations across modalities, inconsistent descriptions of the same attribute, and missing modality information can make accurate alignment difficult.  The example features two knowledge graphs (MMKG1 and MMKG2) which contain relational, attribute, and visual information about the movie \"Twilight\" and its actors.", "section": "1 Introduction"}, {"figure_path": "IAse6CAG26/figures/figures_3_1.jpg", "caption": "Figure 2: The framework overview of TMEA.", "description": "This figure presents a detailed overview of the TMEA framework, which is a method for Multi-modal Entity Alignment. It shows three main modules: Multi-modal Knowledge Encoder (MKE), Missing Modality Imputation (MMI), and Multi-modal Commonality Enhancement (MCE). The MKE module encodes relational, attribute, and visual knowledge into their preliminary feature representations. The MMI module addresses missing modality by unifying features into a shared latent subspace and generating pseudo features. The MCE module enhances semantic associations between modalities using cross-attention with orthogonal constraints. The figure also illustrates the overall model optimization strategy, integrating multi-modal contrastive learning and bi-directional iteration.", "section": "4 Methodology"}, {"figure_path": "IAse6CAG26/figures/figures_8_1.jpg", "caption": "Figure 3: The performance of TMEA and the strongest baseline, MSNEA, when varying ratios of entities have visual or attribute modalities on FB15K-DB15K.", "description": "This figure displays the performance of TMEA and MSNEA (the strongest baseline) under different ratios of entities with visual and attribute modalities on the FB15K-DB15K dataset.  It illustrates how the models' performance changes (measured by MRR and Hits@1) when the amount of visual and attribute information is varied. The purpose is to demonstrate the robustness of TMEA in scenarios with missing or incomplete modalities.", "section": "5.3 Ablation Study"}, {"figure_path": "IAse6CAG26/figures/figures_9_1.jpg", "caption": "Figure 4: Comparison results with different ratios of alignment labels.", "description": "This figure compares the performance of various multi-modal entity alignment methods using different percentages of aligned entity pairs for training (20%, 50%, and 80%).  It demonstrates that TMEA consistently outperforms other methods across all evaluation metrics (H@1, H@10, MRR) and shows robustness to reductions in training data.  Other methods show a more significant decline in performance as training data decreases.", "section": "5.2 Performance Comparison"}, {"figure_path": "IAse6CAG26/figures/figures_14_1.jpg", "caption": "Figure 2: The framework overview of TMEA.", "description": "This figure presents a detailed architecture of the TMEA model, illustrating its three core modules: Multi-modal Knowledge Encoder (MKE), Missing Modality Imputation (MMI), and Multi-modal Commonality Enhancement (MCE).  The MKE module encodes relational, attribute, and visual knowledge. The MMI module addresses modality absence by unifying features into a shared latent subspace and generating pseudo features.  The MCE module enhances semantic associations using cross-attention with orthogonal constraints.  The figure also shows the data flow and connections between these modules, including the use of various techniques like TransE, BERT, Vision Transformer, and VAEs.  The overall objective function is shown at the bottom, incorporating losses for different components.", "section": "4 Methodology"}, {"figure_path": "IAse6CAG26/figures/figures_17_1.jpg", "caption": "Figure 5: The parameter sensitivity on FB15K-DB15K.", "description": "This figure shows the performance change of TMEA with varying coefficients (\u03bb1 and \u03bb2) for the two constraint losses in the overall objective function. The x-axis represents the values of \u03bb1 and \u03bb2, while the y-axis represents the MRR and H@1 scores. The optimal values for \u03bb1 and \u03bb2 are 1e-2. When the values are greater than 1e-2, the performance declines. This is because excessive emphasis on constraint behavior can lead to a deviation in the optimization direction.", "section": "C.5 Parameter Sensitivity"}]