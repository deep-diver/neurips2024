[{"figure_path": "SDWeIGPAh9/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of the motivation. We observe that directly aligning the predictions of atypical samples to the target label is not appropriate, causing overconfidence (horse with 95% confidence). Instead, the confidence should be aligned with the human perception. During training, the cross-entropy loss increases the magnitude ||f|| and adjusts their direction towards the target (represented by the angle \u03b1). Consider this example where an image of a human body with a horse head is presented, the loss may optimize towards f2 in the blue box, which is not the ideal outcome direction. Instead, it would be better to optimize towards f1, rather than being biased towards either one, ensuring a more balanced and unbiased representation and allowing for a more accurate estimation of confidence.", "description": "The figure illustrates the problem of overconfidence in deep neural networks (DNNs) when dealing with atypical samples.  A cross-entropy loss function attempts to align model predictions with labels by increasing the magnitude of the logit vector or adjusting its direction. In the case of atypical images (e.g., a picture of a human body with a horse's head), this approach can lead to overconfidence because the label may not reflect the image content accurately. The figure shows how the ideal prediction should align with human perception (f1) rather than being biased towards either the true label or a false label (f2), leading to more accurate confidence estimation.", "section": "Key observation & Motivation"}, {"figure_path": "SDWeIGPAh9/figures/figures_3_1.jpg", "caption": "Figure 2: The differences between closely related tasks. The blue curve represents the decision boundary, and the shaded area in the figure indicates incorrect predictions. (a) illustrates the objective of OoD-D tasks to reject predictions with semantic shifts and accept in-distribution predictions, without concern for predictions with covariate shifts. (b) shows the old setting of FD tasks, accepting correct in-distribution predictions and rejecting incorrect out-of-distribution predictions. (c) displays the new setting of FD tasks, accepting correct in-distribution predictions and correct predictions with covariate shifts, while rejecting incorrect in-distribution predictions, incorrect predictions with covariate shifts, and predictions with semantic shifts. (d) illustrates examples of OoD-D, Old FD, and New FD tasks. A classifier trained on CIFAR10 [20] is evaluated on 6 images under a whole range of relevant distribution shifts: For instance, the 3rd and the 4th images in grayscale depict an airplane and a horse which encounter covariate shifts from that in the original CIFAR10. The 5th and the 6th images depict samples belonging to unseen categories with semantic shifts.", "description": "This figure compares three different approaches to failure detection: Out-of-Distribution detection (OoD-D), traditional failure detection (Old FD), and the proposed new failure detection method (New FD).  It illustrates their differences in how they handle correct and incorrect predictions under various scenarios: in-distribution data, covariate shifts, and semantic shifts.  The figure highlights that New FD considers both in-distribution data and covariate shift predictions as \"success\" cases, rejecting only incorrect predictions regardless of their origin.  In contrast, OoD-D only considers semantic shifts, and Old FD only addresses covariate shifts.", "section": "2 Background and Preliminary"}, {"figure_path": "SDWeIGPAh9/figures/figures_4_1.jpg", "caption": "Figure 3: The framework of TAL. During training, statistical information (mean \u00b5\u2081 and variance \u03c3j) of features from correct predictions updates the Historical Features Queue (HFQ) at time-step t. The typicalness measure \u03c4 is calculated by comparing these statistics between the current batch and the HFQ. This \u03c4 influences the overall loss calculation, guiding the model to differentiate between atypical and typical samples. In the inference phase, TAL operates similarly to a model trained with conventional cross-entropy. Confidence is derived from the cosine similarity of the predicted logit direction, emphasizing our approach of using direction as a more reliable confidence metric. The framework distinguishes between typical (high \u03c4) and atypical (low \u03c4) samples, influencing the optimization process accordingly.", "description": "This figure illustrates the framework of the Typicalness-Aware Learning (TAL) method proposed in the paper.  It shows how TAL dynamically adjusts logit magnitudes based on a sample's typicalness, which is calculated by comparing the sample's features to a historical queue of typical features.  The figure details the training and inference processes, emphasizing the use of cosine similarity for confidence estimation in the inference phase.", "section": "3 Method"}, {"figure_path": "SDWeIGPAh9/figures/figures_8_1.jpg", "caption": "Figure 4: (a) and (b) is the ablation study of Tmin, Tmax. And (c) is the ablation study on the length of the Historical Feature Queue.", "description": "This figure presents the results of ablation studies conducted to evaluate the impact of different hyperparameters and architectural choices on the proposed TAL model.  Specifically, subfigures (a) and (b) show the effect of varying Tmin and Tmax (lower and upper bounds for the dynamic magnitude T(\u03c4)) on the EAURC metric for CIFAR10 and CIFAR100 datasets respectively.  The 3D surface plots visualize the EAURC scores across a range of Tmin and Tmax values. Subfigure (c) illustrates the effect of varying the length of the Historical Feature Queue (HFQ) on EAURC for CIFAR100. The line plot shows that the performance is stable for queue lengths between 10,000 and 50,000 but decreases when the length exceeds 50,000.", "section": "4.3 Ablation Study"}, {"figure_path": "SDWeIGPAh9/figures/figures_9_1.jpg", "caption": "Figure 5: (a) Comparison of the Mean of Features between ID and OOD; (b) Comparison of different methods for measuring typicality; (c) The Risk-Coverage curves on old and new setting FD tasks; (d) Examples of typical and atypical examples.", "description": "This figure shows four subfigures that illustrate different aspects of the Typicalness-Aware Learning (TAL) method. (a) compares the mean of features between in-distribution (ID) and out-of-distribution (OOD) samples. (b) compares different methods for measuring typicality, including GMM, mean & variance, and KNN. (c) shows the risk-coverage curves for both old and new failure detection tasks, illustrating the performance improvement achieved by TAL. (d) shows examples of typical and atypical samples, further clarifying the concept of typicalness used in the TAL method.", "section": "4.3 Ablation Study"}, {"figure_path": "SDWeIGPAh9/figures/figures_15_1.jpg", "caption": "Figure 6: OOD-D methods lead to worse confidence separation between correct and wrong samples.", "description": "This figure displays kernel density estimations for confidence scores produced by three different out-of-distribution (OOD) detection methods: MSP, Energy, and LogitNorm. Each plot shows the distributions for correctly classified in-distribution (ID) samples, incorrectly classified ID samples, and OOD samples.  The overlap ratios between these distributions are quantified, illustrating that OOD methods result in greater overlap between correctly and incorrectly classified samples compared to what is desired, hindering their effectiveness for failure detection.", "section": "A. The Reasons Why OoD method Performs Poor in FD"}]