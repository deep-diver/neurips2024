[{"figure_path": "AH1mFs3c7o/figures/figures_1_1.jpg", "caption": "Figure 1: InterControl is able to generate interactions of a group of people given joint-joint contact or separation pairs as spatial condition, and it is only trained on single-person data. Our generated interactions are realistic and similar to real interactions in internet images in (a) daily life and (b) fighting. (c) shows our generated group motions (red dots) could serve as reference motions for physics animation.", "description": "This figure demonstrates the ability of the InterControl model to generate realistic multi-person interactions from a single-person motion dataset.  The model takes joint-joint contact and separation information as input and synthesizes motions accordingly. The top row shows various daily life scenarios (a), while the middle row demonstrates fighting scenarios (b).  These interactions are diverse and naturally-looking. The bottom row (c) presents an example of using the generated group motions as input to a physics simulator, showcasing the potential for applying the generated motions to realistic simulations.", "section": "1 Introduction"}, {"figure_path": "AH1mFs3c7o/figures/figures_4_1.jpg", "caption": "Figure 2: Overview. Our model could precisely control human joints in the global space via the Motion ControlNet and IK guidance module. By leveraging LLM to adapt interaction descriptions to joint contact pairs, it could generate multi-person interactions via a single-person motion generation model in a zero-shot manner.", "description": "This figure illustrates the overall architecture of the InterControl model.  It shows how the model uses an LLM to generate interaction descriptions (e.g., two people fighting), which are then converted into joint-joint contact pairs. These pairs serve as spatial controls for a motion diffusion model. The controls are processed by a Motion ControlNet and refined further with inverse kinematics guidance, enabling precise control of character joints in the global space. The final output are realistic multi-person interactions.", "section": "3 InterControl"}, {"figure_path": "AH1mFs3c7o/figures/figures_8_1.jpg", "caption": "Figure 1: InterControl is able to generate interactions of a group of people given joint-joint contact or separation pairs as spatial condition, and it is only trained on single-person data. Our generated interactions are realistic and similar to real interactions in internet images in (a) daily life and (b) fighting. (c) shows our generated group motions (red dots) could serve as reference motions for physics animation.", "description": "This figure demonstrates the capabilities of the InterControl model.  It showcases the generation of realistic multi-person interactions from simple joint-pair constraints (contact or separation distances). The model is trained only on single-person data, achieving zero-shot generalization to multiple people.  Subfigures (a) and (b) show examples from daily life and fighting scenarios, respectively. These examples highlight the model's ability to produce interactions resembling real-world examples found in internet images.  Subfigure (c) further illustrates how the generated group motions can be used as input for physics-based animation simulations.", "section": "1 Introduction"}, {"figure_path": "AH1mFs3c7o/figures/figures_15_1.jpg", "caption": "Figure 2: Overview. Our model could precisely control human joints in the global space via the Motion ControlNet and IK guidance module. By leveraging LLM to adapt interaction descriptions to joint contact pairs, it could generate multi-person interactions via a single-person motion generation model in a zero-shot manner.", "description": "This figure illustrates the overall architecture of the InterControl model.  It shows how the model uses a large language model (LLM) to convert interaction descriptions into joint contact pairs, which are then used as spatial controls. These spatial controls are processed by two modules: Motion ControlNet, a fine-tuned copy of a pre-trained motion diffusion model, and IK Guidance, an inverse kinematics module.  These modules work together to precisely control human joints in the global space, allowing the generation of realistic and diverse multi-person interactions from a single-person motion model.", "section": "3 InterControl"}, {"figure_path": "AH1mFs3c7o/figures/figures_17_1.jpg", "caption": "Figure 3: Comparison with PriorMDM [51] in user-study of zero-shot human interaction generation.", "description": "The figure shows a qualitative comparison between the proposed InterControl method and the PriorMDM method in a user study on zero-shot human interaction generation.  It provides two example sequences of two-person interactions generated by each method alongside a text description of the intended interaction.  The visual comparison highlights the differences in the realism and accuracy of the generated interactions, particularly regarding torso collision and alignment with the given textual description.  InterControl's results demonstrate a significant improvement in both aspects.", "section": "4.2 Zero-Shot Multi-Person Interaction Generation"}]