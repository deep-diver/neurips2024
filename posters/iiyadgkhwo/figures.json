[{"figure_path": "iiYadgKHwo/figures/figures_1_1.jpg", "caption": "Figure 1: VDD distills a diffusion policy into an MoE. LfD is challenging due to the multimodality of human behaviour. For example, tele-operated demonstrations of an avoiding task often contain multiple solutions [13]. Lower: A diffusion policy can predict high quality actions but relies on an iterative sampling process from noise to data, shown as the red arrows. Upper: VDD uses the score function to distill a diffusion policy into an MoE, unifying the advantages of both approaches.", "description": "This figure illustrates the core idea of Variational Diffusion Distillation (VDD).  The top panel shows how VDD distills a diffusion policy (which generates high-quality actions but is slow due to iterative sampling) into a Mixture of Experts (MoE) model using the score function. The bottom panel highlights the contrast between the iterative sampling process of a diffusion policy (red arrows) and the efficient single-step sampling of the MoE model produced by VDD.  The figure uses the example of learning from human demonstrations (LfD) for robot control, where the inherent multimodality of human behavior makes it a challenging task.", "section": "1 Introduction"}, {"figure_path": "iiYadgKHwo/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of training VDD using the score function for a fixed state in a 2D toy task. (a) The probability density of the distribution is depicted by the color map. The score function is shown by the gradient field, visualized as white arrows. From (b) to (f), we initialize and train VDD until convergence. We initialize 8 components, each represented by an orange circle. These components are driven by the score function to match the data distribution and avoid overlapping modes by utilizing the learning objective in Eq. (11). Eventually, they align with all data modes.", "description": "This figure demonstrates the VDD training process on a simple 2D example.  Panel (a) shows the target probability distribution and its score function (gradients). Panels (b) through (f) show the iterative training process of the mixture of experts model (MoE), where each expert is represented by an orange circle. The training process gradually aligns the MoE components with the modes of the target distribution, avoiding overlaps.", "section": "4 Variational Distillation of Denoising Diffusion Policies"}, {"figure_path": "iiYadgKHwo/figures/figures_8_1.jpg", "caption": "Figure 3: Ablation studies for key design choices used in VDD. (a) Using only one expert leads to a higher success rate but is unable to solve the task in diverse manners. Sufficiently more experts can trade off task success and action diversities. (b)Learning the gating distribution improves the success rates in three D3IL tasks. (c) A Uniform gating leads to higher task entropy in two out of three tasks. (d) Sampling the score from multiple noise levels leads to a better distillation performance", "description": "This figure presents ablation studies on several key design choices within the Variational Diffusion Distillation (VDD) method.  Panel (a) shows how the number of experts impacts both task success rate and diversity, demonstrating a trade-off between these two metrics. Panels (b) and (c) compare the impact of training a gating distribution versus using a uniform distribution on task success and entropy, highlighting that training the gating distribution improves performance but reduces diversity.  Finally, panel (d) examines the effect of sampling from multiple noise levels on the overall performance of VDD.", "section": "5.5 Ablation Studies"}, {"figure_path": "iiYadgKHwo/figures/figures_9_1.jpg", "caption": "Figure 4: Trajectory visualization for VDD with different number of components Z \u2208 {1,2, 4, 8} on the Avoiding task (left). Different colors indicate components with highest likelihood according to the learned gating network q(z|s) at a state s. For each step we select the action by first sampling an expert from the categorical gating distribution and then take the mean of the expert prediction. We decompose the case Z = 8 and visualize the individual experts zi (bottom row). Diverse behavior emerges as multiple actions are likely given the same state. For example, moving to the bottom right (21) and top right (22). An extreme case of losing diversity is seen with Z = 1, where the policy is unable to capture the diverse behavior of the diffusion teacher, leading to deterministic trajectories.", "description": "This figure visualizes the behavior of the VDD model on the \"Avoiding\" task from the D3IL dataset for different numbers of experts (Z).  The left panel shows the task environment. The main part of the figure shows trajectories generated by VDD with different numbers of experts. Different colors represent different experts, and their intensity reflects the probability of that expert being selected. The bottom row shows the individual experts' behaviors. As the number of experts increases, the diversity of trajectories increases, showing VDD's ability to capture multi-modal behaviors. With only one expert (Z=1), the behavior is deterministic, lacking the diversity seen in the teacher model.", "section": "5.6 Visualization of the per-Expert Behavior"}, {"figure_path": "iiYadgKHwo/figures/figures_14_1.jpg", "caption": "Figure 1: VDD distills a diffusion policy into an MoE. LfD is challenging due to the multimodality of human behaviour. For example, tele-operated demonstrations of an avoiding task often contain multiple solutions [13]. Lower: A diffusion policy can predict high quality actions but relies on an iterative sampling process from noise to data, shown as the red arrows. Upper: VDD uses the score function to distill a diffusion policy into an MoE, unifying the advantages of both approaches.", "description": "This figure illustrates the core idea of Variational Diffusion Distillation (VDD).  The lower part shows how a diffusion policy generates actions through iterative sampling, which is slow. The upper part shows how VDD uses the score function of the diffusion model to distill the policy into a Mixture of Experts (MoE), resulting in a faster and more efficient model, especially beneficial for real-time applications like robot control.", "section": "1 Introduction"}, {"figure_path": "iiYadgKHwo/figures/figures_14_2.jpg", "caption": "Figure 1: VDD distills a diffusion policy into an MoE. LfD is challenging due to the multimodality of human behaviour. For example, tele-operated demonstrations of an avoiding task often contain multiple solutions [13]. Lower: A diffusion policy can predict high quality actions but relies on an iterative sampling process from noise to data, shown as the red arrows. Upper: VDD uses the score function to distill a diffusion policy into an MoE, unifying the advantages of both approaches.", "description": "This figure illustrates the core idea of Variational Diffusion Distillation (VDD).  The top part shows VDD transforming a complex diffusion policy (represented by the iterative sampling process from noise to data) into a simpler, faster Mixture of Experts (MoE) model. The bottom part highlights the challenge of learning from human demonstrations (LfD) due to the inherent multi-modality of human behavior, which diffusion models are well-suited to handle, but their iterative sampling makes real-time applications difficult. VDD addresses this by distilling the diffusion model's knowledge into an MoE, combining the accuracy of diffusion models with the speed and tractability of MoEs.", "section": "1 Introduction"}, {"figure_path": "iiYadgKHwo/figures/figures_17_1.jpg", "caption": "Figure 1: VDD distills a diffusion policy into an MoE. LfD is challenging due to the multimodality of human behaviour. For example, tele-operated demonstrations of an avoiding task often contain multiple solutions [13]. Lower: A diffusion policy can predict high quality actions but relies on an iterative sampling process from noise to data, shown as the red arrows. Upper: VDD uses the score function to distill a diffusion policy into an MoE, unifying the advantages of both approaches.", "description": "This figure illustrates the core concept of Variational Diffusion Distillation (VDD).  The lower part shows how a diffusion policy generates actions through an iterative sampling process, which is computationally expensive. In contrast, the upper part illustrates how VDD distills the diffusion policy into a more efficient Mixture of Experts (MoE) model using the score function. This allows for faster action prediction and addresses the multimodality often found in human behavior data (LfD).", "section": "1 Introduction"}]