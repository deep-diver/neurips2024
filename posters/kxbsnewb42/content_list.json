[{"type": "text", "text": "Acceleration Exists! Optimization Problems When Oracle Can Only Compare Objective Function Values ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Aleksandr Lobanov Alexander Gasnikov Andrei Krasnov MIPT, Skoltech, ISP RAS Innopolis, MIPT, MI RAS MIPT, Innopolis lobbsasha@mail.ru gasnikov@yandex.ru krasnov.an@phystech.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Frequently, the burgeoning field of black-box optimization encounters challenges due to a limited understanding of the mechanisms of the objective function. To address such problems, in this work we focus on the deterministic concept of Order Oracle, which only utilizes order access between function values (possibly with some bounded noise), but without assuming access to their values. As theoretical results, we propose a new approach to create non-accelerated optimization algorithms (obtained by integrating Order Oracle into existing optimization \u201ctools\u201d) in non-convex, convex, and strongly convex settings that are as good as both SOTA coordinate algorithms with first-order oracle and SOTA algorithms with Order Oracle up to logarithm factor. Moreover, using the proposed approach, we provide the first accelerated optimization algorithm using the Order Oracle. And also, using an already different approach we provide the asymptotic convergence of the first algorithm with the stochastic Order Oracle concept. Finally, our theoretical results demonstrate effectiveness of proposed algorithms through numerical experiments. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The black box problem has garnered extensive attention in diverse scientific and engineering domains, reflecting the challenge of optimizing systems with complex and opaque objective functions, prompting the exploration of innovative solutions Conn et al. (2009); Kimiaei and Neumaier (2022). ", "page_idx": 0}, {"type": "text", "text": "This paper focuses on solving a standard general optimization problem in the following form: ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{x\\in\\mathbb{R}^{d}}\\left\\{f(x):=\\mathbb{E}_{\\xi\\sim\\mathcal{D}}f_{\\xi}(x)\\right\\},\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "where $f:\\ensuremath{\\mathbb{R}^{d}}\\to\\ensuremath{\\mathbb{R}}$ is a possibly non-convex, possibly stochastic function. This problem configuration encompasses a broad range of applications in ML scenarios, e.g. empirical risk minimization,where $\\mathcal{D}$ denotes distribution across training data points, and $f_{\\xi}(x)$ represents loss of model $x$ on data point $\\xi$ . ", "page_idx": 0}, {"type": "text", "text": "When the objective function $f(x)$ has exclusive access to a zero-order oracle Rosenbrock (1960), problem (1) falls under the classification of a black-box optimization problem. This class of problems is actively studied in various application settings, e.g., deep learning Chen et al. (2017); Gao et al. (2018), federated learning Dai et al. (2020); Alashqar et al. (2023); Patel et al. (2022), reinforcement learning Choromanski et al. (2018); Mania et al. (2018), overparameterized models Lobanov and Gasnikov (2023), online optimization (Agarwal et al., 2010; Bach and Perchet, 2016; Akhavan et al., 2022), multi-armed bandits Shamir (2017); Lattimore and Gyorgy (2021), hyperparameter settings Bergstra and Bengio (2012); Hern\u00e1ndez-Lobato et al. (2014); Nguyen and Balasubramanian (2022), and control system performance optimization Bansal et al. (2017); Xu et al. (2022). It is important to highlight that the zero-order oracle presupposes awareness of the objective function\u2019s value $f(\\boldsymbol{x}_{k})$ at a specific point $x_{k}$ (which may be inexact), enabling the development of effective gradient-free algorithms tailored to various problem scenarios Gasnikov et al. (2022a). ", "page_idx": 0}, {"type": "table", "img_path": "kxBsNEWB42/tmp/dade8d704c45d882e8a369ea70a46a43486f0ef25d1096507502902fac838e1d.jpg", "table_caption": ["Table 1: Comparison of oracle complexity for the methods proposed in this work with SOTA methods both in the coordinate descent class and in the Order Oracle concept (2). Notation: $F_{0}=f(x_{0})-f(x^{*})$ ; $R=\\|x_{0}-x^{*}\\|$ ; $\\begin{array}{r}{R_{[1-\\alpha]}=R_{1-\\alpha}(x_{0})=\\operatorname*{sup}_{x\\in\\mathbb{R}^{d}:f(x)\\leq f(x_{0})}\\|x-x^{*}\\|_{[1-\\alpha]^{d}}}\\end{array}$ ; $\\varepsilon=$ desired accuracy of problem solving. "], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "In this paper, we consider concept of zero-order oracle, termed Order Oracle, to address problem (1): ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\phi(x,y)=\\mathrm{sign}\\left[f(x)-f(y)+\\delta(x,y)\\right],\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\begin{array}{r l r}{|\\delta(x,y)|}&{{}\\le}&{\\Delta}\\end{array}$ is some bounded noise. The Order Oracle has the capability to compare two functions; however, in contrast to the zero-order oracle, it lacks the ability to calculate or utilize the actual value of the objective function. This concept closely mirrors the challenges encountered in real-world black-box optimization problems. ", "page_idx": 1}, {"type": "text", "text": "The motivation for the proposed oracle concept becomes more evident when considering the ongoing developments in generative models. Companies like Valio and SberAI have already embraced the active involvement of AI in dessert creation. Notably, Valio, as illustrated in Figure $1^{\\ast}$ , employed AI to determine the optimal concentration of milk for chocolate bars based on available data. However, envision a scenario where AI creates customized chocolate for an individual by adjusting the concentration of ingredients. In such a case, a flavor comparison procedure, depicted in one iteration, would involve determining the preference order. Given that Figure 1: Valio\u2019s chocolate tastes can be closely aligned, introducing bounded noise in oracle (2) mitigates the potential for errors. ", "page_idx": 1}, {"type": "image", "img_path": "kxBsNEWB42/tmp/b2673c2d0e5af7519e3b113738d15de6dee966d34827d8306cf1c488f48ebbfc.jpg", "img_caption": [], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "To address the initial deterministic problem (1) with the Order Oracle (2), we propose a novel approach to algorithm design that uses class of coordinate descent methods (CD) Bubeck et al. (2015) as an optimization \u201ctool\u201d to integrate our oracle into multidimensional optimization. This approach is good in that we use linear search (where the Order Oracle is directly used) to determine not only the iteration step size, but also the gradient coordinate of the objective function. Thus demonstrating that the proposed algorithms are also adaptive. And for solving the initial stochastic problem (1) with the Order Oracle, we propose an approach based on normalized SGD, providing asymptotic convergence. ", "page_idx": 1}, {"type": "text", "text": "1.1 Our contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "More specifically, our contributions are the following: ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "\u2022 We provide a novel approach to design algorithms for solving deterministic optimization problems (1) with Order Oracle (2) that achieves SOTA convergence results up to logarithm factor in the non-convex, convex, and strongly convex settings (see Table 1 and Algorithm 1). \u2022 By using the approach proposed in this paper to create algorithms for solving deterministic optimization problem (1) with the Order Oracle (2), we have shown, on an example of strongly convex functions, that acceleration in such an oracle concept exists (see Algorithm 2 and Theorem 4.1). Moreover, we have shown how the convergence results of the accelerated algorithm can be improved when the problem is low-dimensional (the algorithm described in Appendix G shows convergence that even the Ellipsoid method cannot). \u2022 We provide the first algorithm for solving a problem (1) with the stochastic Order Oracle concept, where the order between two functions on the same realization is determined. \u2022 Through numerical experiments (see Section 7), we validate our theoretical results by comparing with first-order algorithms, as well as providing practical recommendations for implementing the first accelerated algorithm with the Order Oracle (2) (see Algorithm 2). ", "page_idx": 1}, {"type": "text", "text": "1.2 Main assumptions and notations ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Before discussing related works, we present the notation and main assumptions we use in our work. ", "page_idx": 2}, {"type": "text", "text": "Notation. We use $\\textstyle\\langle x,y\\rangle\\;:=\\;\\sum_{i=1}^{d}x_{i}y_{i}$ to denote standard inner product of $x,y\\;\\in\\;\\mathbb{R}^{d}$ . We denote Euclidean norm in $\\mathbb{R}^{d}$ as $\\|\\boldsymbol{x}\\|:=\\sqrt{\\textstyle\\sum_{i=1}^{d}x_{i}^{2}}$ . In particular, this norm $\\|x\\|:={\\sqrt{\\langle x,x\\rangle}}$ is related to the inner product. We use $\\mathbf{e}_{i}\\in\\mathbb{R}^{d}$ to denote the $i^{\\th}$ -th unit vector. We define the norms $\\begin{array}{r}{\\|\\boldsymbol{x}\\|_{[\\alpha]}:=\\sqrt{\\sum_{i=1}^{d}L_{i}^{\\alpha}x_{i}^{2}}}\\end{array}$ and $\\begin{array}{r}{\\|x\\|_{[\\alpha]}^{*}:=\\sqrt{\\sum_{i=1}^{d}\\frac{1}{L_{i}^{\\alpha}}x_{i}^{2}}}\\end{array}$ . We denote by $\\nabla f(x)$ the full gradient of function $f$ at point $x\\in\\mathbb{R}^{d}$ , and by $\\nabla_{i}f(x)$ the $i$ -th coordinate gradient. The sum of constant $L_{i}$ denotes as $\\begin{array}{r}{S_{\\alpha}:=\\sum_{i}^{d}L_{i}^{\\alpha}}\\end{array}$ . We use $S^{d}(r):=\\left\\{x\\in\\mathbb{R}^{d}:\\|x\\|=r\\right\\}$ to denote Euclidean sphere. We use $\\tilde{O}(\\cdot)$ to hide the logarithmic coefficients. We denote $f^{*}:=f(x^{*})$ as the solution to initial problem. For all our theoretical results, we assume that $f(x)$ is $L_{i}$ -smooth with respect to its $i$ -th coordinate: ", "page_idx": 2}, {"type": "text", "text": "Assumption 1.1 (Smoothness). A function $f\\;\\;:\\;\\;\\mathbb{R}^{d}\\;\\;\\rightarrow\\;\\;\\mathbb{R}$ is $L$ -coordinate-Lipschitz for $L_{1},L_{2},...,L_{d}>0$ if for any $i\\in[d],x\\in\\mathbb{R}^{d}$ and $h\\in\\mathbb{R}$ the following inequality holds: ", "page_idx": 2}, {"type": "equation", "text": "$$\n|\\nabla_{i}f(x+h\\mathbf{e}_{i})-\\nabla_{i}f(x)|\\leq L_{i}|h|.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "The smoothness assumption of the function is widely used in the optimization literature (e.g. Boyd and Vandenberghe, 2004; Nesterov et al., 2018). However, Assumption 1.1 is specific and frequently utilized in the context of optimization via the CD method Lin et al. (2014); Zhang and Xiao (2017); Mangold et al. (2023). This assumption means that for every input point $x$ , if we alter its $i$ -th coordinate by at most $h$ , then the corresponding gradient $\\nabla_{i}f(x+h\\mathbf{e}_{i})$ differs from $\\nabla_{i}f(x)$ by at most $L_{i}$ times $|h|$ . Throughout this paper we assume that function $f(x)$ can be (strongly) convex w.r.t. the norm $\\|\\cdot\\|_{[1-\\alpha]}$ : Assumption 1.2. A function $f:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ is $\\mu_{1-\\alpha}\\geq0$ strongly convex w.r.t. the norm $\\|\\cdot\\|_{[1-\\alpha]}$ if for any $x,y\\in\\mathbb{R}^{d}$ the following inequality holds: ", "page_idx": 2}, {"type": "equation", "text": "$$\nf(y)\\geq f(x)+\\left\\langle\\nabla f(x),y-x\\right\\rangle+\\frac{\\mu_{1-\\alpha}}{2}\\left\\Vert y-x\\right\\Vert_{[1-\\alpha]}^{2}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Many works in convex optimization rely on the (strong) convexity assumption, as evidenced by references such as Duchi (2016); Shi et al. (2019); Asi et al. (2021). Since our work employs norms $\\|\\cdot\\|_{[1-\\alpha]}$ to derive theoretical estimates, Assumption 1.2 deviates slightly from the standard. However, this assumption of $\\mu_{1-\\alpha}$ (strong) convexity is extensively used in the following literature: Nesterov (2012); Lee and Sidford (2013); Allen-Zhu et al. (2016). Assumption 1.2 can conform to standard form of $\\mu$ (strong) convexity via Euclidean norm if $\\alpha=1$ . This assumption is convex provided $\\mu_{1-\\alpha}=0$ . ", "page_idx": 2}, {"type": "text", "text": "1.3 Paper organization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Further, this paper has the following structure. In Section 2, we provide a related work discussion. We present and analyze the non-accelerated algorithm in Section 3. Then in Section 4, we discuss the feasibility of accelerating the proposed algorithm in the concept of Order Oracle and provide theoretical guarantees. We provide the first algorithm that utilizes the stochastic concept of the Order Oracle in Section 5. In Section 6, we discuss the current results of this work. Through numerical experiments in Section 7, we validate the theoretical results. While Section 8 concludes the paper. ", "page_idx": 2}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The literature in the field of optimization is already extensive and continuously expanding, encompassing various problem formulations and assumptions. In this section, we provide an overview of the most relevant contributions to our work. Namely both CD methods and algorithms with Order Oracle. ", "page_idx": 2}, {"type": "text", "text": "Algorithms with Order Oracle. In the field of black-box optimization problem, special attention has been paid to algorithms that use only the Order Oracle. For example, Stochastic Three Points Method was proposed in Bergou et al. (2020), which uses an oracle that compares three function values at once and achieves the following oracle complexity in the strongly convex case $\\mathcal{O}\\left(d L/\\mu\\log1/\\varepsilon\\right)$ . A little later, the authors of Gorbunov et al. (2019) modified the Stochastic Three Points Method to the case of importance sampling, improving the oracle complexity estimate in the strongly convex case $\\mathcal{O}\\left(S_{\\alpha}/\\mu\\log1/\\varepsilon\\right)$ . Already in 2021, Saha et al. (2021) provided another algorithm in which the oracle compares two function values only once per iteration. The analysis of this algorithm is based on the Sign SGD and achieves oracle complexity in the strongly convex case $\\mathcal{O}\\left(d L/\\mu\\log1/\\varepsilon\\right)$ . The work of Tang et al. (2023) showed that the Order Oracle is also extensively used in Reinforcement Learning with Human Feedback, providing only in the non-convex case an estimate on oracle complexity ${\\mathcal{O}}\\left(d/\\varepsilon^{2}\\right)$ . In this paper, we propose an alternative approach for creating optimization algorithms (via line search method), which achieves SOTA convergence results with logarithm accuracy in a class of non-accelerated algorithms, and provide the first accelerated algorithm with the Order Oracle. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Coordinate descent (CD) methods. In addition to full-gradient algorithms for smooth first-order optimization, coordinate descent algorithms are categorized into accelerated and non-accelerated algorithms. Non-accelerated algorithms typically converge at rates $1/\\varepsilon$ and $1/\\mu$ in convex $(\\mu=0)$ ) and strongly convex $(\\mu>0)$ ) cases, respectively, while accelerated algorithms achieve rates $1/\\sqrt\\varepsilon$ and $1/\\sqrt{\\mu}$ in convex and strongly convex cases, respectively. This classification dates back to 1983 when Nesterov introduced the optimal convergence rates for first-order algorithms Nesterov (1983). However, the fundamental difference between coordinate descent and full-gradient descent lies in the step taken along the $i^{\\th}$ -th coordinate of the gradient (directional derivative). Monograph Bubeck et al. (2015) has demonstrated that if the direction is chosen uniformly, coordinate descent may require up to $d$ times more iterations than full-gradient descent. However, authors in Nesterov (2012) have shown that considering smoothness along the direction $L_{i}$ can improve the number of iterations ${\\mathcal O}\\left(S_{\\alpha}R_{[1-\\alpha]}^{2}/\\varepsilon\\right)$ and $\\scriptstyle{\\mathcal{O}}\\left(S_{\\alpha}/\\mu_{1-\\alpha}\\log{\\frac{1}{\\varepsilon}}\\right)$ in convex and strongly convex cases, respectively, where $\\begin{array}{r}{R_{[1-\\alpha]}\\,=\\,\\operatorname*{sup}_{x\\in\\mathbb{R}^{d}:f(x)\\le f(x_{0})}\\|x-x^{*}\\|_{[1-\\alpha]}}\\end{array}$ for $\\alpha\\,\\in\\,[0,1]$ . In the same paper Nesterov (2012), the authors demonstrated the potential for acceleration in coordinate descent through the scheme proposed in Nesterov (1983). Subsequently, in Lee and Sidford (2013), they analyzed and presented an accelerated version of coordinate descent (ACDM), along with the corresponding number of required $\\mathcal{O}\\left(\\sqrt{d S_{\\alpha}R_{[1-\\alpha]}^{2}/\\varepsilon}\\right)$ and $\\mathcal{O}\\left(\\sqrt{d S_{\\alpha}/\\mu_{1-\\alpha}}\\log\\frac{1}{\\varepsilon}\\right)$ iterations in convex and strongly convex cases, respectively. It is noteworthy that, at that time, this iteration complexity was deemed unimprovable. However, a few years later, both Nesterov and Stich (2017) and Allen-Zhu et al. (2016) independently provided same results, demonstrating that it is indeed possible to enhance the iteration complexity for accelerated coordinate descent methods by modifying the probability of choosing the $i$ -th coordinate: $L_{i}^{\\alpha/2}/S_{\\alpha/2}$ . In this paper, we propose a coordinate descent algorithm with an Order Oracle (2), demonstrating that it achieves the same iteration complexity as first-order algorithms. Furthermore, based on accelerated coordinate descent Nesterov and Stich (2017), we establish on the strongly convex case that even with an Order Oracle, acceleration can be attained, resulting in the most favorable estimates on iteration complexity known to date. ", "page_idx": 3}, {"type": "text", "text": "3 Non-Accelerated Methods ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we begin to present our main results, by introducing algorithms tailored to address the initial problem (1) utilizing the Order Oracle (2). Given the demand for this oracle concept, we furnish convergence guarantees and conduct comparisons with algorithms employing alternative oracles. ", "page_idx": 3}, {"type": "text", "text": "Our approach for developing a new algorithm involves incorporating the Order Oracle into an existing optimization method using linear search. We opt for linear search as the integration tool due to its compatibility with the Order Oracle concept. However, the choice of optimization method to which this linear search can be applied poses a crucial question. After careful consideration, we determined that the coordinate descent method (CDM) is the most suitable candidate. In each iteration, the CDM, given a step size $\\zeta_{k}>0$ and starting point $\\boldsymbol{x}_{0}\\in\\mathbb{R}^{d}$ , proceeds as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nx_{k+1}=x_{k}-\\underbrace{\\zeta_{k}\\nabla_{i_{k}}f(x_{k})}_{\\eta_{k}}\\mathbf{e}_{i_{k}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $i_{k}$ is the coordinate index drawn from $[d]$ . Note that the coordinate descent method step (3) requires both a step size $\\zeta_{k}$ and a gradient coordinate value $\\nabla_{i_{k}}f(x_{k})$ , which are scalars. Thus, by employing linear search $\\begin{array}{r}{\\eta_{k}=\\arg\\operatorname*{min}_{\\eta}\\{f(x_{k}+\\eta\\mathbf{e}_{i_{k}})\\}}\\end{array}$ at each iteration, we can optimally determine both the direction of steepest descent and the step size to traverse along this direction, resulting in a fully adaptive algorithm. The next consideration is the strategy for coordinate selection at each iteration. Following the trend initiated by Nesterov (2012), we use a more general sampling distribution than the uniform one, obtaining already random coordinate descent (RCD). Specifically, for $\\alpha>0$ , we assume that a random generator $\\mathcal{R}_{\\alpha}(L)$ independently selects $i_{k}$ from the following distribution: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\np_{\\alpha}(i)=L_{i}^{\\alpha}/S_{\\alpha},\\quad i\\in[d].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We are now ready to introduce a method designed to solve problem (1) utilizing the oracle concept (2). ", "page_idx": 4}, {"type": "text", "text": "This algorithm falls under the category of coordinate methods and is named random coordinate descent with order oracle (OrderRCD), see Algorithm 1. It should be noted that the inherent \"stochasticity\" of problem (1) is artificially induced by randomized procedure used to select the $i^{\\th}$ -th coordinate (4). Here, $\\xi$ denotes the $i$ -th coordinate, and $\\mathcal{D}$ represents distribution $p_{\\alpha}(i)$ from (4). The golden ratio method (GRM) serves ", "page_idx": 4}, {"type": "table", "img_path": "kxBsNEWB42/tmp/4b4491bfa6cf482f2dc8c3e51a914f25e626b78fb336b2a0cdcf0c725c9b9dcb.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "text", "text": "as the linear search algorithm, which is where the Order Oracle is used. It is known that GRM (which is described in Appendix C.2) requires $N=\\mathcal{O}\\left(\\log1/\\epsilon\\right)$ iterations to achieve the desired accuracy $\\epsilon$ (in terms of function) of the solution to the linear search problem (namely, $\\eta_{k}=\\operatorname{argmin}_{\\eta}\\{f(x_{k}\\!+\\!\\eta\\mathbf{e}_{i_{k}})\\})$ ", "page_idx": 4}, {"type": "text", "text": "Next, we present our theoretical results, demonstrating through convergence analyses that random coordinate descent with order oracle (OrderRCD) exhibits competitive iteration complexity compared to first-order algorithms when applied to non-convex, convex, or strongly convex functions. ", "page_idx": 4}, {"type": "text", "text": "3.1 Non-convex setting ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Theorem 3.1 (non-convex). Let function $f\\!\\!\\left(x\\right)$ satisfies Assumption 1.1, $N$ is the number of iterations, $F_{0}=f(x_{0})-f(x^{*})$ , then Algorithm $^{\\,l}$ (OrderRCD) with oracle (2) guarantees an error: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac1N\\sum_{k=0}^{N-1}\\left(\\left\\|\\nabla f(x_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2}\\leq\\mathcal{O}\\left(\\frac{S_{\\alpha}F_{0}}{N}+S_{\\alpha}\\epsilon+S_{\\alpha}\\Phi\\Delta\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\epsilon$ is the accuracy of solving linear search problem by function and $\\begin{array}{r}{\\Phi=\\frac{1+\\sqrt{5}}{2}}\\end{array}$ is golden ratio. ", "page_idx": 4}, {"type": "text", "text": "The convergence results of Theorem 3.1 imply the existence of a point $\\textit{k}\\in\\mathsf{\\Gamma}[N]$ where $\\begin{array}{r}{(\\|\\nabla f(x_{k})\\|_{[1-\\alpha]}^{*})^{2}\\,\\leq\\,\\mathcal{O}\\left(\\frac{S_{\\alpha}F_{0}}{N}\\right)}\\end{array}$ holds true. Additionally, Theorem 3.1 indicate that, to achieve the desired accuracy $\\varepsilon$ (according to the gradient norm), Algorithm 1 requires $N={\\mathcal{O}}\\left(S_{\\alpha}F_{0}/\\varepsilon^{2}\\right)$ iterations and $T\\,=\\,\\tilde{\\mathcal{O}}\\left(S_{\\alpha}F_{0}/\\varepsilon^{2}\\right)$ calls to the oracle (2). The maximum admissible noise level ensuring the desired accuracy should not exceed $\\sim\\varepsilon^{2}$ . Notably, the convergence rate of random coordinate descent with the order oracle (OrderRCD), assuming minimal noise $(\\Delta\\leq\\varepsilon^{2})$ , is equal to first-order method: random coordinate descent (RCD). It is also characteristic (within the coordinate methods class) to be inferior to gradient descent (Ghadimi and Lan, 2013, under $L$ smoothness assumption). For instance, in the case when $\\alpha=1$ , the convergence rates $\\mathcal{O}\\left(L F_{0}/N\\right)$ is better because $\\textstyle L\\leq\\sum_{i=1}^{d}L_{i}$ . Not surprisingly, in terms of oracle complexity, Algorithm (1) is logarithmically inferior to first-order algorithms. This discrepancy reflects the \"cost\" associated with employing GRM, where the $\\tilde{O}(\\cdot)$ to hide the logarithmic coefficient representing the number of oracle calls in the GRM, contingent upon its accuracy $\\epsilon$ . A detailed proof of Theorem 3.1 is given in Appendix D.1. ", "page_idx": 4}, {"type": "text", "text": "3.2 Convex setting ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now prove an analogous theorem on the convergence of the algorithm when the function is convex, i.e., additionally assuming that Assumption 1.2 is satisfied with $\\mu_{1-\\alpha}=0$ . ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.2 (convex). Let function $f(x)$ satisfies Assumption 1.1 ( $L$ -Smoothness) and Assumption 1.2 (convexity, $\\mu_{1-\\alpha}=0.$ ), then Algorithm $^{\\,I}$ (OrderRCD) with oracle (2) guarantees an error: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\mathcal{O}\\left(\\frac{S_{\\alpha}R_{[1-\\alpha]}^{2}}{N}+\\frac{2S_{\\alpha}R_{[1-\\alpha]}^{2}\\left(\\epsilon+\\Phi\\Delta\\right)}{F_{N-1}}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\epsilon$ is an inner problem accuracy, $\\begin{array}{r}{R_{[1-\\alpha]}=\\operatorname*{sup}_{x\\in\\mathbb{R}^{d}:f(x)\\leq f(x_{0})}\\|x-x^{*}\\|_{[1-\\alpha]},}\\end{array}$ , and $\\begin{array}{r}{\\Phi=\\frac{1+\\sqrt{5}}{2}}\\end{array}$ ", "page_idx": 4}, {"type": "text", "text": "In comparison to Theorem 3.1 (non-convex setting), the convergence results of Algorithm 1 demonstrate improvement under the assumption of function convexity (Assumption 1.2 with $\\mu_{1-\\alpha}=0)$ ). Specifically, according to Theorem 3.2, random coordinate descent with order oracle (OrderRCD) requires $N=\\mathcal{O}(S_{\\alpha}R_{[1-\\alpha]}^{2}/\\varepsilon)$ iterations and $T=\\tilde{\\mathcal{O}}(S_{\\alpha}R_{[1-\\alpha]}^{2}/\\varepsilon)$ oracle calls to achieve the desired accuracy $\\varepsilon$ (where $\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\varepsilon)$ . However, in cases where $\\Delta\\,>\\,0$ , the condition for maximum noise remains unchanged compared to the non-convex setting. Furthermore, the iteration complexity $N$ aligns with that of the first-order algorithm, (random coordinate descent (RCD) Nesterov, 2012). Similarly, akin to Theorem 3.2, the convergence rate of gradient descent (Nesterov et al., 2018, under assuming $L$ smoothness and convexity) outperforms that of Algorithm 1. Moreover, when $\\alpha=0$ (corresponding to a uniform distribution with probability $p_{\\alpha}(i)=\\mathbf{\\bar{1}}/d)$ , OrderRCD (like all coordinate methods) necessitates $d$ times more iterations than gradient descent. Concerning oracle complexity $T$ , a logarithmic coefficient is evident, correlating with the number of oracle calls per iteration of Algorithm 1, line 2. For a comprehensive proof of Theorem 3.2, refer to Appendix D.2. ", "page_idx": 5}, {"type": "text", "text": "3.3 Strongly convex setting ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section we consider case when function is strongly convex (see Assumption 1.2, $\\mu_{1-\\alpha}>0)$ ). Theorem 3.3 (strongly convex). Let function $f(x)$ satisfies Assumption 1.1 ( $L$ -Smoothness) and Assumption 1.2 (convexity, $\\mu_{1-\\alpha}>0,$ ), then Algorithm $^{\\,l}$ with oracle (2) has a linear convergence rate: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\left(1-\\frac{\\mu_{1-\\alpha}}{S_{\\alpha}}\\right)^{N}F_{0}+\\frac{2S_{\\alpha}\\epsilon}{\\mu_{1-\\alpha}}+\\frac{2c S_{\\alpha}\\Phi\\Delta}{\\mu_{1-\\alpha}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where c is some constant, $\\epsilon$ is the GRM accuracy (by function) and $\\textstyle\\Phi={\\frac{1+{\\sqrt{5}}}{2}}$ is golden ratio. ", "page_idx": 5}, {"type": "text", "text": "As depicted in Theorem 3.3 Algorithm 1 exhibits a linear convergence rate, achieving the desired accuracy $\\varepsilon$ in $\\begin{array}{r}{N=\\mathcal{O}_{\\left({S_{\\alpha}}/{\\mu_{1-\\alpha}}\\log\\frac{1}{\\varepsilon}\\right)}}\\end{array}$ iterations and $\\begin{array}{r}{T=\\tilde{\\mathcal{O}}\\left(\\bar{S_{\\alpha}}/\\mu_{1-\\alpha}\\log\\frac{1}{\\varepsilon}\\right)}\\end{array}$ oracle calls. Furthermore, there\u2019s an enhancement in the maximum noise level $\\Delta$ , reaching $\\sim\\mu_{1-\\alpha}\\varepsilon$ . It\u2019s notable that a weaker strong convexity condition was employed in the proof of Theorem 3.3 (see Appendix D.3): ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|\\nabla f(x)\\|_{[1-\\alpha]}^{2}\\geq2\\mu_{1-\\alpha}(f(x)-f(x^{*})),\\forall x\\in\\mathbb{R}^{d}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "This condition (in the case $\\alpha=1$ ), also known as the Polyak\u2013Lojasiewicz or Gradient-dominated functions condition Polyak (1963); Lojasiewicz (1963); Karimi et al. (2016); Belkin (2021), encompasses a broad class of functions: convex functions, strongly convex functions, sum of squares (e.g. where considering a system of non-linear equations), invex and non-convex functions, as well as over-parameterized systems. Also it is shown in Yue et al. (2023) that non-accelerated algorithms (like Algorithm 1) are optimal for $L$ -smooth problems under the Polyak\u2013Lojasiewicz condition (5). ", "page_idx": 5}, {"type": "text", "text": "High probability deviations bounds. Given that OrderRCD method in strongly convex setting demonstrates a linear convergence rate and employs a randomization in coordinate selection, we can derive exact estimates of high deviation probabilities using Markov\u2019s inequality Anikin et al. (2015): ", "page_idx": 5}, {"type": "image", "img_path": "kxBsNEWB42/tmp/8f739cd80984ee36a6970d4c509894308d9116cf6a8bbec8015ad504ab56d736.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{P}\\left(f(x_{N(\\varepsilon\\sigma)})-f^{*}\\geq\\varepsilon\\right)\\leq\\sigma\\frac{\\mathbb{E}\\left[f\\big(x_{N(\\varepsilon\\sigma)}\\big]-f^{*}}{\\varepsilon\\sigma}\\leq\\sigma.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "4 Accelerated Method ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Random coordinate descent with order oracle (OrderRCD) demonstrates efficiency in the class of coordinate methods. The number of iterations $N$ required to achieve the desired accuracy $\\varepsilon$ is fully identical to random coordinate descent (RCD), which is the best among the non-accelerated methods in this class, and are also not inferior to existing competitors with Order Oracle. This fact confirms that our proposed approach to developing a novel optimization algorithm is successful. However, Algorithm 1 is still not optimal because it belongs to non-accelerated algorithms. Nevertheless, Section 3 gives hope for the possibility of acceleration among algorithms using the oracle concept (2). ", "page_idx": 5}, {"type": "text", "text": "In this section, we demonstrate on the example of the strongly convex (Assumption 1.2 is satisfied with constant $\\mu_{1-\\alpha}>0)$ ) problem (1) that acceleration in the class of optimization algorithms using the Order Oracle (2) exists! For simplicity, we consider the case when $\\Delta=0$ . ", "page_idx": 5}, {"type": "text", "text": "Our approach to creating an accelerated algorithm closely mirrors the one proposed in Section 3, which involves adapting an existing optimization method (from the class of coordinate algorithms) to the Order Oracle using linear search method (namely, golden ratio method, GRM). Among the accelerated algorithms in the class of coordinate descent, two stand out: (accelerated coordinate descent method (ACDM), Nesterov and Stich, 2017) and (accelerated coordinate descent method with non-uniform sampling (NU-ACDM), Allen-Zhu et al., 2016). These algorithms boast the same convergence rate and are considered among the best available today. Therefore, we select one of them (specifically, ACDM) as the base algorithm to adapt to our oracle concept (2). At each iteration, the ACDM, given parameters such as $\\alpha_{k}$ , $\\beta_{k}$ , $a_{k+1}$ , $A_{k+1}$ , $B_{k+1}$ , Lipschitz coordinate constant $L_{i}$ , strong convexity $\\mu_{1-\\alpha}$ , distribution $p_{\\beta}(i)$ , and a starting point $x_{0}=z_{0}$ , proceeds as follows: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{y_{k}=(1-\\alpha_{k})x_{k}+\\alpha_{k}w_{k},}\\\\ &{x_{k+1}=y_{k}-(1/L_{i_{k}})\\nabla_{i_{k}}f(y_{k})\\mathbf{e}_{i_{k}},}\\\\ &{z_{k+1}=w_{k}-\\frac{a_{k+1}}{L_{i_{k}}^{1-\\alpha}B_{k+1}p_{\\beta}(i)}\\nabla_{i_{k}}f(y_{k})\\mathbf{e}_{i_{k}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $w_{k}\\,=\\,(1\\,-\\,\\beta_{k})z_{k}\\,+\\,\\beta_{k}y_{k}$ . Looking at the $x_{k+1}$ update (6), it seems that it should not be difficult to determine the step size $1/L_{i_{k}}$ and the value of the gradient coordinate $\\nabla_{i_{k}}f(y_{k})$ using a linear search, as demonstrated in Algorithm 1. However, substituting the same $\\eta_{k}$ instead of $(1/L_{i_{k}})\\nabla_{i_{k}}f(y_{k})$ into the $z_{k+1}$ update (7) isn\u2019t straightforward. The step with linear search is larger than the original step of $(1/L_{i_{k}})\\nabla_{i_{k}}f(y_{k})$ , potentially leading to a paradoxical situation where the step worsens with linear search. This ", "page_idx": 6}, {"type": "text", "text": "is because there is no guarantee that the function $f$ is monotonically decreasing along the sequences $\\{z_{k}\\}_{k=0}^{\\infty}$ and $\\{x_{k}\\}_{k=0}^{\\infty}$ Nesterov (1983). Nevertheless, we have successfully addressed this challenge and we are ready to present the first accelerated algorithm utilizing only the Order Oracle: the accelerated coordinate descent method with order oracle. ", "page_idx": 6}, {"type": "text", "text": "It is evident from Algorithm 2 that the challenge was addressed by incorporating a secondary linear search, ensuring that the update step in $z_{k+1}$ with linear search is at least as effective as (7). However, unlike Algorithm 1, OrderACDM cannot be deemed fully adaptive as it necessitates knowledge of the strong convexity constant $\\mu_{1-\\alpha}$ and the Smoothness constant $L_{i}$ (which disappears in the case where $\\alpha=0$ ). Despite this, we are ready to present the main advantage ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 Accelerated Coordinate Descent Method with Order Oracle (OrderACDM) ", "page_idx": 6}, {"type": "text", "text": "Input: $\\begin{array}{r}{x_{0}=z_{0}\\in\\mathbb{R}^{d},\\mathcal{R}_{\\alpha}(L),A_{0}=0,B_{0}=1,\\beta=\\frac{\\alpha}{2}}\\end{array}$   \nfor $k=0$ to $N-1$ do   \n1. choose active coordinate $i_{k}=\\mathcal{R}_{\\beta}(L)$   \n2. find parameter $a_{k+1}$ from $a_{k+1}^{2}S_{\\beta}^{2}=A_{k+1}B_{k+1}$ , where $A_{k+1}=A_{k}+a_{k+1}$ and $B_{k+1}=B_{k}+\\mu_{1-\\alpha}a_{k+1}$ $\\begin{array}{r}{\\alpha_{k}\\leftarrow\\frac{a_{k+1}}{A_{k+1}}}\\end{array}$   \n4. $\\begin{array}{r}{\\beta_{k}\\gets\\frac{\\mu_{1-\\alpha}a_{k+1}}{B_{k+1}}}\\end{array}$   \n5. yk \u2190(1\u2212\u03b1k)xk+\u03b1k(1\u2212\u03b2k)zk   \n6. compute $\\eta_{k}=\\mathrm{argmin}_{\\eta}\\{f(y_{k}+\\eta\\mathbf{e}_{i_{k}})\\}$ via (GRM)   \n7. xk+1 \u2190yk + \u03b7keik   \n8. wk \u2190(1 \u2212\u03b2k)zk + \u03b2kyk +Bkk++11p\u03b2i(ki)\u03b7keik   \n9. compute $\\zeta_{k}=\\mathrm{argmin}_{\\zeta}\\{f(w_{k}+\\zeta{\\bf e}_{i_{k}})\\}$ via (GRM)   \n10. $z_{k+1}\\leftarrow w_{k}+\\zeta_{k}\\mathbf{e}_{i_{k}}$ ", "page_idx": 6}, {"type": "text", "text": "end for ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Return: xN ", "page_idx": 6}, {"type": "text", "text": "of Algorithm: Faster convergence rate of Accelerated Coordinate Descent Method with Order Oracle. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.1. Let function $f(x)$ is strongly convex (Assumption 1.2), $L$ -Smoothness (Assumption 1.1) and $L_{[1-\\alpha]}$ -Smoothness\u2020, then Algorithm 2 (OrderACDM) with oracle (2) guarantees an error ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\left(1-\\frac{\\sqrt{\\mu_{1-\\alpha}}}{S_{\\alpha/2}}\\right)^{N}F_{0},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\begin{array}{r}{F_{0}=f(x_{0})-f(x^{*}),\\,S_{\\alpha/2}=\\sum_{i=1}^{d}L_{i}^{\\alpha/2}.}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "Compared to the results of Section 3, the convergence rate demonstrated in Theorem 4.1 is superior, confirming the potential for acceleration in algorithms utilizing the Order Oracle. To achieve the desired accuracy $\\varepsilon$ , Algorithm 2 (OrderACDM) requires $\\begin{array}{r}{N=^{\\bullet}\\!\\mathcal{O}\\left(S_{\\alpha/2}/\\!\\sqrt{\\mu_{1-\\alpha}}\\log\\frac{1}{\\varepsilon}\\right)}\\end{array}$ iterations and $\\begin{array}{r}{T=\\tilde{\\mathcal{O}}\\left(S_{\\alpha/2}/\\sqrt{\\mu_{1-\\alpha}}\\log\\frac{1}{\\varepsilon}\\right)}\\end{array}$ oracle calls, significantly outperforming existing competitors that utilize the Order Oracle (see Table 1). One notable difference from Algorithm 1 is selection of the active coordinate $i=\\mathscr{R}_{\\beta}(L)$ , where $\\beta=\\alpha/2$ . This choice aims to eliminate dimensionality $d$ from the iteration and oracle complexities derived in Lee and Sidford (2013), since $S_{\\alpha/2}\\leq\\sqrt{d S_{\\alpha}}$ . A detailed proof of Theorem 4.1 is given in Appendix $\\boldsymbol{\\mathrm E}$ . ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5 Stochastic Order Oracle Concept ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "This section is devoted to an equally important concept of the Order Oracle (2), namely its modification to the stochastic case, where the values of two functions on one realization $\\xi$ are compared: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\phi(x,y,\\xi)=\\mathrm{sign}\\left[f(x,\\xi)-f(y,\\xi)\\right].\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "For simplicity, we assume that the oracle (8) is not subject to adversarial noise. This oracle concept can also be motivated by the creation of an ideal chocolate only for a group of people on average. That is, in this concept the $\\xi$ -th realization of the function can be understood as the $\\xi$ -th individual of group. ", "page_idx": 7}, {"type": "text", "text": "To address the stochastic black-box optimization problem (1) when only the Order Oracle (8) is available, we provide the first optimization algorithm that uses exactly the stochastic oracle concept (8): ", "page_idx": 7}, {"type": "equation", "text": "$$\n{\\bf\\mu}_{x+1}=x_{k}-\\eta_{k}\\phi(x_{k}+\\gamma_{k}{\\bf e}_{k},x_{k}-\\gamma_{k}{\\bf e}_{k},\\xi_{k}){\\bf e}_{k},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\gamma_{k}>0$ is a smoothing parameter, ${\\mathbf e}_{k}\\in S^{d}(1)$ is a vector uniformly distributed on the Euclidean sphere. In order to proceed to convergence guarantees of this method (9), we use the auxiliary results. ", "page_idx": 7}, {"type": "text", "text": "Lemma 5.1. Let function $f$ be $L$ -smooth\u2021, $\\begin{array}{r}{\\gamma_{k}=\\frac{\\|\\nabla f(x_{k},\\xi_{k})\\|}{\\sqrt{d}L}}\\end{array}$ , ${\\mathbf e}_{k}\\in S^{d}(1)$ , then the following holds: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\phi(x_{k}+\\gamma_{k}\\mathbf{e}_{k},x_{k}-\\gamma_{k}\\mathbf{e}_{k},\\xi_{k})\\mathbf{e}_{k}=\\mathrm{sign}\\left[\\langle\\nabla f(x_{k},\\xi_{k}),\\mathbf{e}_{k}\\rangle\\right]\\mathbf{e}_{k}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Now using Lemma 5.1 we show how our algorithm (9) with oracle (8) is related to normalized SGD. Lemma 5.2. Let vector $\\nabla f(x,\\xi)\\in\\mathbb{R}^{d}$ and vector $\\mathbf{e}\\in S^{d}(1)$ , then with some constant c we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\mathbf{e}}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}\\right]=\\frac{c}{\\sqrt{d}}\\cdot\\frac{\\nabla f(x,\\xi)}{\\|\\nabla f(x,\\xi)\\|}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "As Lemma 5.2 shows, the direction in which a step is taken in Algorithm (9) is the direction of normalized stochastic gradient descent. Given this fact and based on the work of Polyak and Tsypkin (1980) we can provide asymptotic convergence for the first algorithm using the oracle concept (8). ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.3 (Asymptotic convergence). Let the function\u221a $f$ be a $L$ -smooth and ${\\mathbf e}_{k}\\in S^{d}(1)$ , then f\u221aor the algorithm (9) with step size $\\eta_{k}=\\eta/k$ the value $\\sqrt{N}\\left(x_{k}-x^{*}\\right)$ is asymptotically normal: ${\\sqrt{N}}\\left(x_{k}-x^{*}\\right)\\sim{\\mathcal{N}}\\left(0,V\\right)\\!,$ , where the matrix $V$ is as follows: ", "page_idx": 7}, {"type": "equation", "text": "$$\nV={\\frac{\\eta^{2}}{d}}\\left(2\\eta(1-1/d){\\frac{c}{\\sqrt{d}}}\\alpha\\nabla^{2}f(x^{*})-I\\right)^{-1},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "$\\begin{array}{r}{\\alpha=\\int\\left\\lVert z\\right\\rVert^{-1}d P(z)<\\infty,2\\eta(1-1/d)\\frac{c}{\\sqrt{d}}\\alpha\\nabla^{2}f(x^{*})>I\\left(w h e r e\\;I\\;i s\\right)\\times\\pi.}\\end{array}$ unit matrix).", "page_idx": 7}, {"type": "text", "text": "For a detailed proof of Theorem 5.3, including a consideration of auxiliary Lemmas, see Appendix F. ", "page_idx": 7}, {"type": "text", "text": "6 Discussion ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In Section 3, we showed that such a multidimensional optimization problem (1) can be solved using Algorithm 1, which utilizes only comparative information. The fact that such an algorithm exists is not surprising, but the fact that it is as good as other methods with this oracle or first-order algorithms (in the class of coordinate algorithms) is positive news that allows us to think about the optimality of the algorithm. In the Subsection 3.3, we showed that when the Polyak-Lojasiewicz condition is satisfied, we can perhaps consider that OrderRCD has optimal iteration complexity (see, Yue et al., 2023). However, when the other conditions are satisfied, this is not the case, since Algorithm 1 belongs to non-accelerated algorithms. Therefore, we believe that Section 4 provides a vector for the development of the question of optimality by showing an OrderACDM, which can perhaps be considered optimal in terms of iteration complexity. However, in the case of a low-dimensional problem, we can take a \"Private communication\" approach proposed Yurii Nesterov (for a more detailed description, see Appendix G) to create a more efficient algorithm using only oracle (2). ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Before move to the numerical experiments, it\u2019s important to note that accelerated Algorithm 2 employs the golden ratio method (GRM) twice per iteration. This might raise concerns about its computational efficiency. However, in practice, we found that OrderACDM converges efficiently, comparable to the first-order algorithm, even when utilizing the golden ratio method only once. For a detailed analysis of the numerical experiments, refer to next Section 7 and Appendix B. ", "page_idx": 8}, {"type": "text", "text": "7 Numerical Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we investigate the performance of the proposed algorithms in the corresponding Sections 3 and 4 on a numerical experiment. We compare OrderRCD (see Algorithm 1) and OrderACDM (see Algorithm 2), which utilize deterministic oracle concept (2) with existing firstorder state-of-the-art algorithms. The goal is to highlight our theoretical results. ", "page_idx": 8}, {"type": "text", "text": "The optimization problem (1) has a standard quadratic form: $\\begin{array}{r}{\\operatorname*{min}_{x\\in\\mathbb{R}^{d}}f(x):=\\frac{1}{2}\\left\\langle x,A x\\right\\rangle-\\left\\langle b,x\\right\\rangle\\!+c,}\\end{array}$ where $A\\in\\mathbb{R}^{d\\times d}$ , $b\\in\\ensuremath{\\mathbb{R}}^{d}$ , and $c\\in\\mathbb R$ . We use a uniform distribution $(\\alpha=0$ ) to choose the active coordinate, then the distribution (4) has the following form: $p_{0}(i)=1/d$ . For such a problem, the assumptions of $L$ -Coordinate-Lipschitz smoothness (Assumption 1.1) and $\\mu_{1-\\alpha}$ -strong convexity (Assumption 1.2) are satisfied, where $L_{i}\\,=\\,A_{i i}$ . In all experiments, we employ the golden ratio method (GRM) to solve the linear search problem with a precision of $\\epsilon=10^{-8}$ . ", "page_idx": 8}, {"type": "text", "text": "In Figure 2, we compare the convergence random coordinate descent with order oracle (OrderRCD) and accelerated coordinate descent method with order oracle (OrderACDM) with the SOTA non-accelerated algorithms: random coordinate descent (RCD) from Nesterov (2012), as well as gradient descent (GD). Non-accelerated coordinate algorithms, both for first-order oracle (RCD) and for our oracle concept (OrderRCD), are observed to lag behind gradient descent, confirming our theoretical derivations in Section 3. Interestingly, the random coordinate descent with order oracle even outperforms its first-order counterpart, despite the limitations associated with oracle usage (only Order Oracle (2) available). This ", "page_idx": 8}, {"type": "image", "img_path": "kxBsNEWB42/tmp/1186b4068578aa1dd64e22bb6206494a66f0e80a3ad078cbac0925d7537f7a96.jpg", "img_caption": ["Figure 2: Comparison of algorithms proposed with nonaccelerated first-order algorithms. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "observation can be attributed to the adaptiveness of Algorithm 1, as OrderRCD employs an exact step in the steepest descent direction obtained using the golden ratio method (GRM) at each iteration. Additionally, we can observe perhaps the most significant result demonstrated in Figure 2: acceleration in our oracle concept (2) exists! We see that accelerated coordinate descent method with order oracle outpaces the convergence speed of all non-accelerated algorithms, including first-order coordinate (RCD) and full-gradient (GD) methods. In this experiment, OrderACDM was implemented using the method described in Algorithm 2 with $\\zeta_{k}=0$ (i.e., with one golden ratio method); RCD and GD used a constant step size, specifically $1/L_{i}$ and $1/L$ . ", "page_idx": 8}, {"type": "text", "text": "8 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We proposed a new approach to design optimization algorithms using only the deterministic concept of Order Oracle (2) by providing theoretical guarantees (showing SOTA results up to logarithm factor) for non-accelerated algorithms in non-convex, convex and strongly convex settings. We also discussed under which condition the Algorithm 1 is optimal (under the Polyak-Lojasiewicz condition). Using the proposed approach, we have shown that acceleration in the deterministic concept of the Order Oracle exists, thereby opening up a whole range of potential research. Furthermore, we have shown how the evaluation of the accelerated algorithm (so still convex tuning) can be improved by considering lowdimensional problems. Moreover, we provided first-of-its-kind theoretical guarantees for an algorithm utilizing the stochastic concept of Order Oracle (8). Finally, we demonstrated the effectiveness of the proposed algorithms (OrderRCD and OrderACDM) on numerical experiments, thereby validating the theoretical results. We provided practical recommendations for implementation of these algorithms. ", "page_idx": 8}, {"type": "text", "text": "9 Authors\u2019 Affiliation Clarification ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "MIPT = Moscow Institute of Physics and Technology, Dolgoprudny, Russia;   \nSkoltech $=$ Skolkovo Institute of Science and Technology, Moscow, Russia;   \nISP RAS $=$ Ivannikov Institute for System Programming of the Russian Academy of Sciences, Moscow, Russia;   \nInnopolis $=$ Research Center for Artificial Intelligence, Innopolis University, Innopolis, Russia;   \nMI RAS $=$ Steklov Mathematical Institute of Russian Academy of Sciences, Moscow, Russia. ", "page_idx": 9}, {"type": "text", "text": "10 Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research has been financially supported by The Analytical Center for the Government of the Russian Federation (Agreement No. 70-2021-00143 01.11.2021, IGK 000000D730324P540002). The authors are grateful to Eduard Gorbunov, Andrey Neznamov, Alexander Vedyakhin. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Artem Agafonov, Dmitry Kamzolov, Pavel Dvurechensky, Alexander Gasnikov, and Martin Tak\u00e1\u02c7c. Inexact tensor methods and their application to stochastic convex optimization. Optimization Methods and Software, pages 1\u201342, 2023.   \nAlekh Agarwal, Ofer Dekel, and Lin Xiao. Optimal algorithms for online convex optimization with multi-point bandit feedback. In Colt, pages 28\u201340. Citeseer, 2010.   \nAhmad Ajalloeian and Sebastian U Stich. On the convergence of sgd with biased gradients. arXiv preprint arXiv:2008.00051, 2020.   \nArya Akhavan, Massimiliano Pontil, and Alexandre Tsybakov. Distributed zero-order optimization under adversarial noise. Advances in Neural Information Processing Systems, 34:10209\u201310220, 2021.   \nArya Akhavan, Evgenii Chzhen, Massimiliano Pontil, and Alexandre Tsybakov. A gradient estimator via l1-randomization for online zero-order optimization with two point feedback. Advances in Neural Information Processing Systems, 35:7685\u20137696, 2022.   \nBA Alashqar, AV Gasnikov, DM Dvinskikh, and AV Lobanov. Gradient-free federated learning methods with $l_{1}$ and $l_{2}$ -randomization for non-smooth convex stochastic optimization problems. Computational Mathematics and Mathematical Physics, 63(9):1600\u20131653, 2023.   \nZeyuan Allen-Zhu, Zheng Qu, Peter Richt\u00e1rik, and Yang Yuan. Even faster accelerated coordinate descent using non-uniform sampling. In International Conference on Machine Learning, pages 1110\u20131119. PMLR, 2016.   \nA Anikin, P Dvurechensky, A Gasnikov, A Golov, A Gornov, Yu Maximov, M Mendel, and V Spokoiny. Modern efficient numerical approaches to regularized regression problems in application to traffic demands matrix calculation from link loads. In Proceedings of International conference ITAS-2015, 2015.   \nHilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in l1 geometry. In International Conference on Machine Learning, pages 393\u2013403. PMLR, 2021.   \nFrancis Bach and Vianney Perchet. Highly-smooth zero-th order online optimization. In Conference on Learning Theory, pages 257\u2013283. PMLR, 2016.   \nSomil Bansal, Roberto Calandra, Ted Xiao, Sergey Levine, and Claire J Tomlin. Goal-driven dynamics learning via bayesian optimization. In 2017 IEEE 56th Annual Conference on Decision and Control (CDC), pages 5168\u20135173. IEEE, 2017.   \nMikhail Belkin. Fit without fear: remarkable mathematical phenomena of deep learning through the prism of interpolation. Acta Numerica, 30:203\u2013248, 2021.   \nEl Houcine Bergou, Eduard Gorbunov, and Peter Richt\u00e1rik. Stochastic three points method for unconstrained smooth minimization. SIAM Journal on Optimization, 30(4):2726\u20132749, 2020.   \nJames Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of machine learning research, 13(2), 2012.   \nStephen P Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.   \nS\u00e9bastien Bubeck et al. Convex optimization: Algorithms and complexity. Foundations and Trends\u00ae in Machine Learning, 8(3-4):231\u2013357, 2015.   \nPin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. Zoo: Zeroth order optimization based black-box attacks to deep neural networks without training substitute models. In Proceedings of the 10th ACM workshop on artificial intelligence and security, pages 15\u201326, 2017.   \nKrzysztof Choromanski, Mark Rowland, Vikas Sindhwani, Richard Turner, and Adrian Weller. Structured evolution with compact architectures for scalable policy optimization. In International Conference on Machine Learning, pages 970\u2013978. PMLR, 2018.   \nAndrew R Conn, Katya Scheinberg, and Luis N Vicente. Introduction to derivative-free optimization. SIAM, 2009.   \nZhongxiang Dai, Bryan Kian Hsiang Low, and Patrick Jaillet. Federated bayesian optimization via thompson sampling. Advances in Neural Information Processing Systems, 33:9687\u20139699, 2020.   \nJohn Duchi. Lecture notes for statistics 311/electrical engineering 377. URL: https://stanford. edu/class/stats311/Lectures/full notes. pdf. Last visited on, 2:23, 2016.   \nJi Gao, Jack Lanchantin, Mary Lou Soffa, and Yanjun Qi. Black-box generation of adversarial text sequences to evade deep learning classifiers. In 2018 IEEE Security and Privacy Workshops (SPW), pages 50\u201356. IEEE, 2018.   \nAlexander Gasnikov, Darina Dvinskikh, Pavel Dvurechensky, Eduard Gorbunov, Aleksander Beznosikov, and Alexander Lobanov. Randomized gradient-free methods in convex optimization. arXiv preprint arXiv:2211.13566, 2022a.   \nAlexander Gasnikov, Anton Novitskii, Vasilii Novitskii, Farshed Abdukhakimov, Dmitry Kamzolov, Aleksandr Beznosikov, Martin Takac, Pavel Dvurechensky, and Bin Gu. The power of first-order smooth optimization for black-box non-smooth problems. In International Conference on Machine Learning, pages 7241\u20137265. PMLR, 2022b.   \nSaeed Ghadimi and Guanghui Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic programming. SIAM Journal on Optimization, 23(4):2341\u20132368, 2013.   \nMargalit R Glasgow, Honglin Yuan, and Tengyu Ma. Sharp bounds for federated averaging (local sgd) and continuous perspective. In International Conference on Artificial Intelligence and Statistics, pages 9050\u20139090. PMLR, 2022.   \nEduard Gorbunov, Adel Bibi, Ozan Sener, El Houcine Bergou, and Peter Richtarik. A stochastic derivative free optimization method with momentum. In International Conference on Learning Representations, 2019.   \nEduard Gorbunov, Marina Danilova, and Alexander Gasnikov. Stochastic optimization with heavy-tailed noise via accelerated gradient clipping. Advances in Neural Information Processing Systems, 33:15042\u201315053, 2020.   \nMert Gurbuzbalaban, Umut Simsekli, and Lingjiong Zhu. The heavy-tail phenomenon in sgd. In International Conference on Machine Learning, pages 3964\u20133975. PMLR, 2021.   \nJos\u00e9 Miguel Hern\u00e1ndez-Lobato, Matthew W Hoffman, and Zoubin Ghahramani. Predictive entropy search for efficient global optimization of black-box functions. Advances in neural information processing systems, 27, 2014.   \nFeihu Huang, Shangqian Gao, Jian Pei, and Heng Huang. Accelerated zeroth-order and first-order momentum methods from mini to minimax optimization. The Journal of Machine Learning Research, 23(1):1616\u20131685, 2022.   \nBo Jiang, Haoyue Wang, and Shuzhong Zhang. An optimal high-order tensor method for convex optimization. In Conference on Learning Theory, pages 1799\u20131801. PMLR, 2019.   \nHamed Karimi, Julie Nutini, and Mark Schmidt. Linear convergence of gradient and proximal-gradient methods under the polyak-\u0142ojasiewicz condition. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2016, Riva del Garda, Italy, September 19-23, 2016, Proceedings, Part I 16, pages 795\u2013811. Springer, 2016.   \nMorteza Kimiaei and Arnold Neumaier. Efficient unconstrained black box optimization. Mathematical Programming Computation, 14(2):365\u2013414, 2022.   \nNikita Kornilov, Ohad Shamir, Aleksandr Lobanov, Darina Dvinskikh, Alexander Gasnikov, Innokentiy Andreevich Shibaev, Eduard Gorbunov, and Samuel Horv\u00e1th. Accelerated zeroth-order method for non-smooth stochastic convex optimization problem with infinite variance. In Thirty-seventh Conference on Neural Information Processing Systems, 2023.   \nHeinz D Kurz. Hermann heinrich gossen (1810\u20131858). In Handbook on the History of Economic Analysis Volume I. Edward Elgar Publishing, 2016.   \nTor Lattimore and Andras Gyorgy. Improved regret for zeroth-order stochastic convex bandits. In Conference on Learning Theory, pages 2938\u20132964. PMLR, 2021.   \nYin Tat Lee and Aaron Sidford. Efficient accelerated coordinate descent methods and faster algorithms for solving linear systems. In 2013 ieee 54th annual symposium on foundations of computer science, pages 147\u2013156. IEEE, 2013.   \nQihang Lin, Zhaosong Lu, and Lin Xiao. An accelerated proximal coordinate gradient method. Advances in Neural Information Processing Systems, 27, 2014.   \nAleksandr Lobanov and Alexander Gasnikov. Accelerated zero-order sgd method for solving the black box optimization problem under \u201coverparametrization\u201d condition. In International Conference on Optimization and Applications, pages 72\u201383. Springer, 2023.   \nStanislaw Lojasiewicz. Une propri\u00e9t\u00e9 topologique des sous-ensembles analytiques r\u00e9els. Les \u00e9quations aux d\u00e9riv\u00e9es partielles, 117:87\u201389, 1963.   \nPaul Mangold, Aur\u00e9lien Bellet, Joseph Salmon, and Marc Tommasi. High-dimensional private empirical risk minimization by greedy coordinate descent. In International Conference on Artificial Intelligence and Statistics, pages 4894\u20134916. PMLR, 2023.   \nHoria Mania, Aurelia Guy, and Benjamin Recht. Simple random search of static linear policies is competitive for reinforcement learning. Advances in Neural Information Processing Systems, 31, 2018.   \nYu Nesterov. Efficiency of coordinate descent methods on huge-scale optimization problems. SIAM Journal on Optimization, 22(2):341\u2013362, 2012.   \nYurii Nesterov. Implementable tensor methods in unconstrained convex optimization. Mathematical Programming, 186:157\u2013183, 2021.   \nYurii Nesterov and Sebastian U Stich. Efficiency of the accelerated coordinate descent method on structured optimization problems. SIAM Journal on Optimization, 27(1):110\u2013123, 2017.   \nYurii Nesterov et al. Lectures on convex optimization, volume 137. Springer, 2018.   \nYurii Evgen\u2019evich Nesterov. A method of solving a convex programming problem with convergence rate o\\bigl(k\u02c62\\bigr). In Doklady Akademii Nauk, volume 269, pages 543\u2013547. Russian Academy of Sciences, 1983.   \nAnthony Nguyen and Krishnakumar Balasubramanian. Stochastic zeroth-order functional constrained optimization: Oracle complexity and applications. INFORMS Journal on Optimization, 2022.   \nKumar Kshitij Patel, Aadirupa Saha, Lingxiao Wang, and Nathan Srebro. Distributed online and bandit convex optimization. In OPT 2022: Optimization for Machine Learning (NeurIPS 2022 Workshop), 2022.   \nBoris T Polyak. Gradient methods for the minimisation of functionals. USSR Computational Mathematics and Mathematical Physics, 3(4):864\u2013878, 1963.   \nBoris Teodorovich Polyak and Yakov Zalmanovich Tsypkin. Optimal pseudogradient adaptation algorithms. Avtomatika i Telemekhanika, (8):74\u201384, 1980.   \nHoHo Rosenbrock. An automatic method for finding the greatest or least value of a function. The computer journal, 3(3):175\u2013184, 1960.   \nAadirupa Saha, Tomer Koren, and Yishay Mansour. Dueling convex optimization. In International Conference on Machine Learning, pages 9245\u20139254. PMLR, 2021.   \nOhad Shamir. An optimal algorithm for bandit and zero-order convex optimization with two-point feedback. The Journal of Machine Learning Research, 18(1):1703\u20131713, 2017.   \nBin Shi, Simon S Du, Weijie Su, and Michael I Jordan. Acceleration via symplectic discretization of highresolution differential equations. Advances in Neural Information Processing Systems, 32, 2019.   \nSebastian U Stich and Sai Praneeth Karimireddy. The error-feedback framework: Better rates for sgd with delayed gradients and compressed updates. The Journal of Machine Learning Research, 21(1):9613\u20139648, 2020.   \nZhiwei Tang, Dmitry Rybin, and Tsung-Hui Chang. Zeroth-order optimization meets human feedback: Provable learning via ranking oracles. In ICML 2023 Workshop The Many Facets of Preference-Based Learning, 2023.   \nWenjie Xu, Colin N Jones, Bratislav Svetozarevic, Christopher R Laughman, and Ankush Chakrabarty. Vabo: Violation-aware bayesian optimization for closed-loop control performance optimization with unmodeled constraints. In 2022 American Control Conference (ACC), pages 5288\u20135293. IEEE, 2022.   \nPengyun Yue, Cong Fang, and Zhouchen Lin. On the lower bound of minimizing polyak-\u0142ojasiewicz functions. In The Thirty Sixth Annual Conference on Learning Theory, pages 2948\u20132968. PMLR, 2023.   \nYuchen Zhang and Lin Xiao. Stochastic primal-dual coordinate method for regularized empirical risk minimization. Journal of Machine Learning Research, 18(84):1\u201342, 2017. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "APPENDIX Acceleration Exists! Optimization Problems When Oracle Can Only Compare Objective Function Values ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A A Few More Words on the Motivation Behind the Order Oracle Concept ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this Section, we would like to emphasize the motivation behind the problem statement discussed in this paper. In particular, we would like to demonstrate the applicability of this work. ", "page_idx": 13}, {"type": "text", "text": "A.1 Perfect coffee for everyone ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "As already demonstrated in Section 1 (Introduction) with the example of chocolate, the deterministic concept of the Order Oracle has many potential applications. However, this research was initiated due to a challenge one of the co-authors faced during the realization of a startup: the creation of an ideal coffee machine that can make the perfect drink for each customer. This startup has just started its life cycle. At the moment we have designed a coffee machine that is functioning at the testing stage (see the photo of the machine in Figure 3 and the 3D model in Figure 4). ", "page_idx": 13}, {"type": "image", "img_path": "kxBsNEWB42/tmp/9d0e7a37ad2b86372638a14153da9306153faf962e75c4a5e057d071ce891e0e.jpg", "img_caption": ["Figure 3: Smart coffee machine. "], "img_footnote": [], "page_idx": 13}, {"type": "image", "img_path": "kxBsNEWB42/tmp/dd7f28cc385fe30ad297defd3fe6a084a009f855c1a9d3cdc251983e3916fdd2.jpg", "img_caption": ["Figure 4: 3D model of a smart coffee machine. "], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "Brief description of the coffee machine. A coffee machine that can make the perfect coffee. By varying the proportions of strong Robusta beans, which give a bitter \"Starbucks flavor\", and mild Arabica beans, we can find the perfect level of bitterness and coffee strength. By varying the amount of milk and cream we can find the right level of milkiness and fat content. We can also adjust the amount of other ingredients such as sugar, ice, lemon juice, chocolate, different syrups to make sure that the customer will definitely like this coffee. ", "page_idx": 13}, {"type": "text", "text": "A.2 Order Oracle: a zero-order oracle close to reality ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this Subsection, we would like to show that the oracle concept considered in this paper is perhaps the closest to reality. ", "page_idx": 13}, {"type": "text", "text": "One of the key criteria for evaluating optimization algorithms is oracle complexity. Oracles are commonly used in theoretical estimates, where they offer insights into the function\u2019s behavior. For instance, the first-order oracle is prevalent in machine learning literature: the authors of Gorbunov et al. (2020); Gurbuzbalaban et al. (2021); Huang et al. (2022) use the oracle to obtain the gradient value $\\nabla f(x_{k})$ of a function at a given point $x_{k}$ . And in Stich and Karimireddy (2020); Ajalloeian and Stich (2020); Glasgow et al. (2022), the authors assume some adversarial environment where the oracle is inaccurate, i.e., the oracle produces the gradient of the function at a given point with some adversarial noise (adversarial refers to the noise that accumulates over iterations). The authors of Nesterov (2012); Lee and Sidford (2013); Mangold et al. (2023) also refer their oracles that produce only the gradient coordinate of the function $\\nabla_{i}f(x_{k})$ at a given point $x_{k}$ to a first-order oracle. However, this oracle formally can also be referred to the so-called gradient-free oracle Gasnikov et al. (2022a), since the algorithm does not use the whole gradient, but only the directional derivative. The following works Jiang et al. (2019); Nesterov (2021); Agafonov et al. (2023) use a higher-order oracle to obtain information, for example, about the Hesse matrix of a function at a given point. But there are oracle concepts closer to reality, for example in Bach and Perchet (2016); Shamir (2017); Akhavan et al. (2021); Gasnikov et al. (2022b); Kornilov et al. (2023) the authors develop algorithms that use only information about the function value $f(x)$ , possibly with some adversarial noise. Such a concept is very common in the field of black-box optimization. In this paper we consider a concept of zero-order oracle: the Order Oracle (2), which is even closer to reality, where even the function value is not available to us, but only the order between two functions (the possibility to compare). Moreover, we take into account the presence of noise (which seems to be natural in applied realities) in such an oracle. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "A.3 Why is a convex/concave function being considered? ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this Subsection, we would like to emphasize the organicity of considering the convexity/concave assumption of the objective function of the original problem (1). ", "page_idx": 14}, {"type": "text", "text": "\"In terms of the law of diminishing utility, the utility function is a concave function in ordinary coordinates:\" In economic science there is a concept of \"utility\". Usually this term is used when describing a consumer who makes a set of several goods (like a basket in a supermarket). Each such set has some utility for the consumer, and he tries to maximize it. We do not consider a consumer who makes a set of goods, but a consumer who makes the goods themselves from a set of their characteristics. We believe that here the consumer is already maximizing a \"preference function\" to emphasize the difference with the \"utility function\". For convenience, we consider all characteristics to be useful (the larger the diagonal of the TV set, the more the consumer likes it). \"Harmful\" characteristics, such as price, we simply replace with the inverse, because the inverse price $1/\\mathfrak{p}$ will already be useful (among goods with the same characteristics, it is logical to assume that the consumer will choose the cheaper one). Gossen\u2019s first law sounds as follows: \"The magnitude [intensity] of pleasure decreases continuously if we continue to satisfy one and the same enjoyment without interruption until satiety is ultimately reached\" Kurz (2016). It is more commonly referred to as the law of diminishing marginal utility of goods. The decreasing marginal utility of a good actually means that the derivative or gradient of the utility function decreases as the quantity of the \"useful attribute\" increases. This leads us to the concavity of the utility function. It is therefore natural to assume that the \"preference function\" will also be concave. ", "page_idx": 14}, {"type": "text", "text": "B Additional Numerical Experiments ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this Section, we provide additional experiments that solve the problem discussed in Section 7. We also give practical recommendations for implementing the accelerated Algorithm 2 in practice. ", "page_idx": 14}, {"type": "text", "text": "In Figure 5, we investigate effect of adversarial noise $\\delta(x,y)$ from deterministic oracle concept (2) on a random coordinate descent with order oracle (OrderRCD). We used $(\\delta(x,y)=\\Delta\\cdot\\cos x\\cdot\\sin y)$ as the adversarial deterministic noise, where $\\Delta$ (s.t. $|\\delta(x,y)|\\leq\\Delta)$ is the maximum noise level. In Figure 5, we see that the adversarial noise justifies its name as it accumulates over iterations. In addition, we observe that the convergence of the non-accelerated coordinate method depends directly on the maximum noise level $\\Delta$ , namely, the lower the noise level, the more accurately the algorithm converges. And finally we see that our theoretical results from Section 3 are confirmed, which indicate that the asymptote to which the algorithm converges can be controlled by the maximum noise level $\\Delta$ , for example, in this case, when $\\alpha=0$ , the condition for achieving the desired accuracy $\\varepsilon$ looks as follows: $\\Delta\\leq\\mu_{1-\\alpha}\\varepsilon/d$ . Or we can rephrase this condition: the OrderRCD has a linear convergence rate to the asymptote depending on level noise $\\Delta$ . ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "image", "img_path": "kxBsNEWB42/tmp/69c7d9c0d599dd9c142f59d037fcc9b40c93eac8e94674699e7cdb505bc4302b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 15}, {"type": "image", "img_path": "kxBsNEWB42/tmp/7818eaf7c14a258575a6b2ff7eca644d8a76fdccc88e8c4bdff6ce7b2af6032b.jpg", "img_caption": ["Figure 5: Effects of adversarial noise from the Order Figure 6: Effect of the second of golden ratio method Oracle (2) on the convergence of random coordinate on the convergence of accelerated coordinate descent descent (OrderRCD). Here we optimize $f(x)$ with with order oracle. Here we optimize $f(x)$ with the pathe parameters: $d=100$ (dimensional of problem), rameters: $d=100$ (dimensional of problem), $\\Delta=0$ $\\Delta=\\{0.5,0.1,0.0001\\}$ (maximum noise level). (maximum noise level in the Order Oracle). "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "In Figure 6, we illustrate the advantage of employing Algorithm 2 with one method of line search $\\zeta_{k}=0)$ ). We can observe that the method proposed in Section 4, the accelerated coordinate descent with order oracle (OrderACDM with two GRM), indeed qualifies as accelerated (thus affirming the theoretical findings of Section 4) as it outperforms gradient descent (GD), which can be considered a boundary between non-accelerated and accelerated coordinate methods. However, this algorithm significantly lags behind the accelerated coordinate descent method (ACDM, Nesterov and Stich, 2017). The reason may be the delayed momentum effect caused by using the golden ratio method (GRM) a second time (see line 10 of Algorithm 2). Addressing this may involve utilizing the golden section method only once per iteration in Algorithm 2 (that is, substitute $\\zeta_{k}~=~0$ into line 10). Indeed, we observe that when using the golden section method once per iteration in Algorithm 2, the OrderACDM enhances convergence rate and does not fall behind its first-order counterpart (ACDM) which confirms our theoretical results. That is why we recommend to utilize in practice accelerated coordinate descent method with order oracle (OrderACDM, see Algorithm 2) with only one the golden ratio method (GRM) per iteration. ", "page_idx": 15}, {"type": "text", "text": "Technical Information. All experiments were performed on an INTEL CORE i5 $2.10\\:\\mathrm{GHz}$ processor. The performance of each Figure depended on the particular algorithm, for example, gradient descent (GD) performed 40000 iterations in 0.1 second, while random coordinate descent (RCD) and accelerated coordinate descent method (ACDM) performed 40000 iterations in 0.2 seconds and 0.4 seconds respectively. But Algorithms 1 and 2 proposed in this paper, by virtue of using linear search at each iteration performed 40000 iterations in 02:02 minutes and 02:13 minutes respectively. ", "page_idx": 15}, {"type": "text", "text": "C Auxiliary Results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section we provide auxiliary materials that are used in the proof of Theorems. ", "page_idx": 15}, {"type": "text", "text": "C.1 Basic inequalities and assumptions ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Basic inequalities. For all $a,b\\in\\mathbb{R}^{d}$ $d\\geq1$ ) the following equality holds: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\|a\\|^{2}+\\|b\\|^{2}=2\\left<a,b\\right>+\\|a-b\\|^{2},}\\\\ {\\langle a,b\\rangle\\leq\\|a\\|\\cdot\\|b\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Coordinate-Lipschitz-smoothness. Throughout this paper, we assume that the smoothness condition (Assumption 1.1) is satisfied. This inequality can be represented in the equivalent form: ", "page_idx": 15}, {"type": "equation", "text": "$$\nf(x+h\\mathbf{e}_{i})\\leq f(x)+h\\nabla_{i}f(x)+\\frac{L_{i}h^{2}}{2},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $L_{1},L_{2},...,L_{d}>0$ for any $i\\in[d],x\\in\\mathbb{R}^{d}$ and $h\\in\\mathbb{R}$ . ", "page_idx": 15}, {"type": "text", "text": "Lipschitz-smoothness. To prove Theorem 4.1, we additionally assume $L_{[1-\\alpha]}$ -smoothness w.r.t. the norm \u2225\u00b7\u2225[1\u2212\u03b1]: ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(y)\\leq f(x)+\\langle\\nabla f(x),y-x\\rangle+\\frac{L_{[1-\\alpha]}}{2}\\left\\Vert y-x\\right\\Vert_{[1-\\alpha]}^{2},\\quad\\forall x,y\\in\\mathbb{R}^{d}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "C.2 The Golden Ratio Method (GRM) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Algorithms 1 and 2, presented in Section 3 and 4, respectively, use the Golden Ratio Method (GRM) at least once per iteration. This method utilizes the oracle concept (2) considered in this paper and has the following form (See Algorithm 3). ", "page_idx": 16}, {"type": "text", "text": "Algorithm 3 Golden Ratio Method (GRM) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1: Input: Interval $[a,b]$   \n2: Initialization: Choose constants $\\epsilon>0$ (desired accuracy), put the constant $\\textstyle\\rho={\\frac{1}{\\Phi}}={\\frac{{\\sqrt{5}}-1}{2}}$   \n3: $y\\leftarrow a+(1-\\rho)(b-a)$   \n4: $z\\leftarrow a+\\rho(b-a)$   \n5: while $b-a>\\epsilon\\,\\mathbf{do}$   \n6: if $\\phi(y,z)=-1$ then   \n7: $b\\gets z$   \n8: $\\begin{array}{l}{z\\leftarrow y}\\\\ {y\\leftarrow a+(1-\\rho)(b-a)}\\end{array}$   \n9:   \n10: else   \n11: $\\begin{array}{l}{a\\leftarrow y}\\\\ {y\\leftarrow z}\\\\ {z\\leftarrow a+\\rho(b-a)}\\end{array}$   \n12:   \n13:   \n14: end if   \n15: end while   \n16: Return: ${\\frac{a+b}{2}}\\,$ ", "page_idx": 16}, {"type": "text", "text": "We utilize the Golden Ratio Method to find a solution to the following one-dimensional problem: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\eta_{k}=\\operatorname*{arg\\,min}_{\\eta\\in\\mathbb{R}}f(x_{k}+\\eta\\mathbf{e}_{i_{k}}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Using the well-known fact about the golden ratio method that GRM is required to do $N=\\mathcal{O}\\left(\\log\\frac{1}{\\epsilon}\\right)$ (where $\\epsilon$ is the accuracy of the solution to the linear search problem (by function)), we derive the following corollaries from the solution of this problem: ", "page_idx": 16}, {"type": "text", "text": "\u2022 In Section 4 (Accelerated Algorithms), for simplicity, we consider the scenario when the Order Oracle (2) is not subject to an adversarial noise $\\left.\\Delta=0\\right]$ ) and the golden ratio method solves the inner problem exactly $\\epsilon\\simeq0$ ). Then we can observe the following: ", "page_idx": 16}, {"type": "equation", "text": "$$\nf(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}})\\leq f(x_{k}+\\eta\\mathbf{e}_{i_{k}}),\\qquad\\qquad\\forall\\eta\\in\\mathbb{R}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "\u2022 In Section 3 (\"Non-Accelerated Algorithms\"), we consider the scenario when the Order Oracle (2) is subjected to an adversarial noise $(\\Delta>0)$ ). Then from the convergence results ( by function) of the golden ratio method (GRM) we can observe the following: ", "page_idx": 16}, {"type": "equation", "text": "$$\nf\\big(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\big)\\leq f\\big(x_{k}+\\eta\\mathbf{e}_{i_{k}}\\big)+\\epsilon+c\\Phi\\Delta,\\qquad\\quad\\forall\\eta\\in\\mathbb{R},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $c$ is some constant, $\\epsilon$ is the GRM accuracy (by function) and $\\textstyle\\Phi={\\frac{1+{\\sqrt{5}}}{2}}$ is golden ratio. ", "page_idx": 16}, {"type": "text", "text": "It is worth noting that we consider convergence of the golden ratio in terms of function, because we assume that our Order Oracle may be subject to adversarial noise. If we talk about convergence by argument, there may be no convergence at all with a noisy concept of the Order Oracle. Thus, in the final corollary (15), we consider the scenario where adversarial noise accumulates over iterations, resulting in the following observation: the golden ratio method converges towards the $\\mathcal{O}\\left(\\Delta\\right)$ asymptote. ", "page_idx": 16}, {"type": "text", "text": "D Proof of Convergence for Non-Accelerated Algorithm 1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we furnish the omitted proofs for the theorems presented in Section 3. ", "page_idx": 17}, {"type": "text", "text": "D.1 Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "From Assumption 1.1 we obtain: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)-f(x_{k})\\overset{(15)}{\\leq}f\\left(x_{k}-\\cfrac{1}{L_{i_{k}}}\\nabla_{i_{k}}f(x_{k})\\mathbf{e}_{i_{k}}\\right)-f(x_{k})+\\epsilon+c\\Phi\\Delta}\\\\ &{\\overset{(12)}{\\leq}-\\cfrac{1}{L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\cfrac{1}{2L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\epsilon+c\\Phi\\Delta}\\\\ &{=-\\cfrac{1}{2L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\epsilon+c\\Phi\\Delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\eta_{k}=\\arg\\operatorname*{min}_{\\eta\\in\\mathbb{R}}f(x_{k}+\\eta\\mathbf{e}_{i_{k}})$ . We use this as follows: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left[f(x_{k+1})\\right]-f(x_{k})=\\mathbb{E}\\left[f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)\\right]-f(x_{k})}\\\\ {\\displaystyle\\overset{(4)}{=}\\sum_{i=1}^{d}p_{\\alpha}(i)\\left(f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)-f(x_{k})\\right)}\\\\ {\\displaystyle\\overset{(16)}{\\leq}-\\sum_{i=1}^{d}p_{\\alpha}(i)\\frac{1}{2L_{i}}(\\nabla_{i}f(x_{k}))^{2}+\\sum_{i=1}^{d}p_{\\alpha}(i)\\left(\\epsilon+c\\Phi\\Delta\\right)}\\\\ {\\displaystyle=-\\frac{1}{2S_{\\alpha}}\\left(\\left\\|\\nabla f(x_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2}+\\epsilon+c\\Phi\\Delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Rearranging the terms and summing over all $k$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k=0}^{N-1}\\displaystyle\\frac{1}{2S_{\\alpha}}\\left(\\left\\|\\nabla f(x_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2}\\leq\\displaystyle\\sum_{k=0}^{N-1}\\left(F_{k}-F_{k+1}\\right)+\\displaystyle\\sum_{k=0}^{N-1}\\epsilon+\\displaystyle\\sum_{k=0}^{N-1}c\\Phi\\Delta}\\\\ &{\\leq F_{0}+F_{N}+N\\epsilon+N c\\Phi\\Delta}\\\\ &{\\leq F_{0}+N\\epsilon+N c\\Phi\\Delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $F_{k}=\\mathbb{E}\\left[f(x_{k})\\right]-f(x^{*})$ . ", "page_idx": 17}, {"type": "text", "text": "Dividing both sides by number of iterations $N$ , we obtain the convergence rate for the non-convex case: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\frac{1}{N}\\sum_{k=0}^{N-1}\\left(\\left\\|\\nabla f(x_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2}\\leq\\frac{2S_{\\alpha}}{N}F_{0}+2S_{\\alpha}\\epsilon+2S_{\\alpha}c\\Phi\\Delta.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This convergence results imply the existence of a point $k\\in[N]$ where holds true: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\left(\\left\\|\\nabla f(x_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2}\\leq\\mathcal{O}\\left(\\frac{S_{\\alpha}F_{0}}{N}+S_{\\alpha}\\epsilon+S_{\\alpha}\\Phi\\Delta\\right).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Then, achieving the desired accuracy $\\varepsilon$ , where $\\|\\nabla f(x_{k})\\|_{[1-\\alpha]}^{*}\\leq\\varepsilon$ , requires ", "page_idx": 17}, {"type": "equation", "text": "$$\nN=\\mathcal{O}\\left(\\frac{S_{\\alpha}F_{0}}{\\varepsilon^{2}}\\right),\\qquad\\quad T=\\tilde{\\mathcal{O}}\\left(\\frac{S_{\\alpha}F_{0}}{\\varepsilon^{2}}\\right)\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "iterations and oracle calls respectively, provided the maximum noise does not exceed $\\Delta\\lesssim\\varepsilon^{2}/S_{\\alpha}$ . ", "page_idx": 17}, {"type": "text", "text": "D.2 Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "From Assumption 1.1 we obtain: ", "page_idx": 17}, {"type": "equation", "text": "$$\nf\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)-f(x_{k})\\overset{(15)}{\\leq}f\\left(x_{k}-\\frac{1}{L_{i_{k}}}\\nabla_{i_{k}}f(x_{k})\\mathbf{e}_{i_{k}}\\right)-f(x_{k})+\\epsilon+c\\Phi\\Delta\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle{\\overset{(12)}{\\leq}-\\frac{1}{L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\frac{1}{2L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\epsilon+c\\Phi\\Delta}}\\\\ {\\displaystyle{=-\\frac{1}{2L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\epsilon+c\\Phi\\Delta,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $\\eta_{k}=\\arg\\operatorname*{min}_{\\eta\\in\\mathbb{R}}f(x_{k}+\\eta\\mathbf{e}_{i k})$ . We use this as follows: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left[f(x_{k+1})\\right]-f(x_{k})=\\mathbb{E}\\left[f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)\\right]-f(x_{k})}\\\\ {\\displaystyle\\overset{(4)}{=}\\sum_{i=1}^{d}p_{\\alpha}(i)\\left(f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)-f(x_{k})\\right)}\\\\ {\\displaystyle\\overset{(17)}{\\leq}-\\sum_{i=1}^{d}p_{\\alpha}(i)\\frac{1}{2L_{i}}(\\nabla_{i}f(x_{k}))^{2}+\\sum_{i=1}^{d}p_{\\alpha}(i)\\left(\\epsilon+c\\Phi\\Delta\\right)}\\\\ {\\displaystyle=-\\frac{1}{2S_{\\alpha}}\\left(\\left\\|\\nabla f(x_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2}+\\epsilon+c\\Phi\\Delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Denote $F_{k}\\ =\\ \\mathbb{E}\\left[f(x_{k})\\right]\\;-\\;f(x^{*})$ . Note that the above calculation can be used to show $f(x_{k+1})\\leq f(x_{k})$ , then we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{F_{k}\\overset{\\mathtt{()}}{\\leq}\\langle\\nabla f(x_{k}),x_{k}-x^{*}\\rangle}\\\\ &{\\quad\\overset{\\mathtt{(11)}}{\\leq}\\|x_{k}-x^{*}\\|_{[1-\\alpha]}\\,\\|\\nabla f(x_{k})\\|_{[1-\\alpha]}^{*}}\\\\ &{\\quad\\leq R_{[1-\\alpha]}\\,\\|\\nabla f(x_{k})\\|_{[1-\\alpha]}^{*}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where in $\\textcircled{1}$ we used Assumption 1.2 with $\\mu_{1-\\alpha}=0$ , and a new notation for convenience, which looks as follows $\\begin{array}{r}{R_{[1-\\alpha]}=\\operatorname*{sup}_{x\\in\\mathbb{R}^{d}:f(x)\\leq f(x_{0})}\\|x-x^{*}\\|_{[1-\\alpha]}.}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "Then substituting (19) into (18) we obtain: ", "page_idx": 18}, {"type": "equation", "text": "$$\nF_{k+1}\\leq F_{k}-\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}F_{k}^{2}+\\epsilon+c\\Phi\\Delta.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Rewriting this inequality, we obtain: ", "page_idx": 18}, {"type": "equation", "text": "$$\n{\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}}F_{k}^{2}\\le F_{k}-F_{k+1}+\\epsilon+c\\Phi\\Delta.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Next, we divide both sides by $F_{k+1}F_{k}$ : ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}\\cdot\\frac{F_{k}}{F_{k+1}}\\le\\frac{1}{F_{k+1}}-\\frac{1}{F_{k}}+\\frac{\\epsilon+c\\Phi\\Delta}{F_{k+1}F_{k}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Using the fact that $\\begin{array}{r}{\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}\\le\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}\\frac{F_{k}}{F_{k+1}}}\\end{array}$ Fk we obtain the following: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}\\leq\\frac{1}{F_{k+1}}-\\frac{1}{F_{k}}+\\frac{\\epsilon+c\\Phi\\Delta}{F_{k+1}F_{k}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "When summing over all $k$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{k=0}^{N-1}\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}\\le\\sum_{k=0}^{N-1}\\left(\\frac{1}{F_{k+1}}-\\frac{1}{F_{k}}\\right)+\\sum_{k=0}^{N-1}\\frac{\\epsilon+c\\Phi\\Delta}{F_{k+1}F_{k}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "we get: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{N\\frac{1}{2S_{\\alpha}R_{[1-\\alpha]}^{2}}\\le\\frac{1}{F_{N}}-\\frac{1}{F_{0}}+\\frac{N\\left(\\epsilon+c\\Phi\\Delta\\right)}{F_{N}F_{N-1}}}}\\\\ &{}&{\\le\\frac{1}{F_{N}}+\\frac{N\\left(\\epsilon+c\\Phi\\Delta\\right)}{F_{N}F_{N-1}}.\\ \\ \\ \\ }\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Taking into account the fact that $F_{N-1}=\\mathbb{E}\\left[f(x_{N-1})\\right]-f(x^{*})\\geq\\varepsilon$ and rewriting the expression we obtain the convergence rate for the convex case: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\frac{2S_{\\alpha}R_{[1-\\alpha]}^{2}}{N}+\\frac{2S_{\\alpha}R_{[1-\\alpha]}^{2}}{\\varepsilon}\\left(\\epsilon+c\\Phi\\Delta\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then, achieving the desired accuracy $\\varepsilon$ , where $\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\varepsilon$ , requires ", "page_idx": 19}, {"type": "equation", "text": "$$\nN=\\mathcal{O}\\left(\\frac{S_{\\alpha}R_{[1-\\alpha]}^{2}}{\\varepsilon}\\right),\\qquad\\;\\;T=\\tilde{\\mathcal{O}}\\left(\\frac{S_{\\alpha}R_{[1-\\alpha]}^{2}}{\\varepsilon}\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "iterations and oracle calls respectively, provided the maximum noise does not exceed the following value \u2206\u2272\u03b52/(S\u03b1R[21\u2212\u03b1]). ", "page_idx": 19}, {"type": "text", "text": "D.3 Proof of Theorem 3.3 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "From Assumption 1.1 we obtain: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)-f(x_{k})\\overset{(15)}{\\leq}f\\left(x_{k}-\\cfrac{1}{L_{i_{k}}}\\nabla_{i_{k}}f(x_{k})\\mathbf{e}_{i_{k}}\\right)-f(x_{k})+\\epsilon+c\\Phi\\Delta}\\\\ &{\\overset{(12)}{\\leq}-\\cfrac{1}{L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\cfrac{1}{2L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\epsilon+c\\Phi\\Delta}\\\\ &{=-\\cfrac{1}{2L_{i_{k}}}(\\nabla_{i_{k}}f(x_{k}))^{2}+\\epsilon+c\\Phi\\Delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\eta_{k}=\\arg\\operatorname*{min}_{\\eta\\in\\mathbb{R}}f(x_{k}+\\eta\\mathbf{e}_{i_{k}})$ . We use this as follows: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}\\left[f(x_{k+1})\\right]-f(x_{k})=\\mathbb{E}\\left[f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)\\right]-f(x_{k})}\\\\ {\\displaystyle\\overset{(4)}{=}\\sum_{i=1}^{d}p_{\\alpha}(i)\\left(f\\left(x_{k}+\\eta_{k}\\mathbf{e}_{i_{k}}\\right)-f(x_{k})\\right)}\\\\ {\\displaystyle\\overset{(20)}{\\leq}-\\sum_{i=1}^{d}p_{\\alpha}(i)\\frac{1}{2L_{i}}(\\nabla_{i}f(x_{k}))^{2}+\\sum_{i=1}^{d}p_{\\alpha}(i)\\left(\\epsilon+c\\Phi\\Delta\\right)}\\\\ {\\displaystyle=-\\frac{1}{2S_{\\alpha}}\\left(\\left\\|\\nabla f(x_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2}+\\epsilon+c\\Phi\\Delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By strong convexity, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{f({\\boldsymbol x}_{k})-f({\\boldsymbol x}^{*})\\stackrel{\\scriptscriptstyle()}{\\le}\\left\\langle\\nabla f({\\boldsymbol x}_{k}),{\\boldsymbol x}_{k}-{\\boldsymbol x}^{*}\\right\\rangle-\\frac{\\mu_{1-\\alpha}}{2}\\left\\|{\\boldsymbol x}_{k}-{\\boldsymbol x}^{*}\\right\\|_{[1-\\alpha]}}}\\\\ &{\\stackrel{\\scriptscriptstyle(11)}{\\le}\\left\\|\\nabla f({\\boldsymbol x}_{k})\\right\\|_{[1-\\alpha]}^{*}\\cdot\\left\\|{\\boldsymbol x}_{k}-{\\boldsymbol x}^{*}\\right\\|_{[1-\\alpha]}-\\frac{\\mu_{1-\\alpha}}{2}\\left\\|{\\boldsymbol x}_{k}-{\\boldsymbol x}^{*}\\right\\|_{[1-\\alpha]}}\\\\ &{\\leq\\frac{1}{\\mu_{1-\\alpha}}\\left(\\left\\|\\nabla f({\\boldsymbol x}_{k})\\right\\|_{[1-\\alpha]}^{*}\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where in $\\textcircled{1}$ we used Assumption 1.2 with $\\mu_{1-\\alpha}>0$ . Then, using this inequality in (21) we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[f(x_{k+1})\\right]-f(x^{*})\\leq\\left(1-\\frac{\\mu_{1-\\alpha}}{2S_{\\alpha}}\\right)(f(x_{k})-f(x^{*}))+\\epsilon+c\\Phi\\Delta.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Applying recursion we obtain a linear convergence rate: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\left(1-\\frac{\\mu_{1-\\alpha}}{2S_{\\alpha}}\\right)^{N}\\left(f(x_{0})-f(x^{*})\\right)+\\frac{2S_{\\alpha}\\epsilon}{\\mu_{1-\\alpha}}+\\frac{2c S_{\\alpha}\\Phi\\Delta}{\\mu_{1-\\alpha}}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Then, achieving the desired accuracy $\\varepsilon$ , where $\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\varepsilon$ , requires ", "page_idx": 19}, {"type": "equation", "text": "$$\nN=\\mathcal{O}\\left(\\frac{S_{\\alpha}}{\\mu_{1-\\alpha}}\\log\\frac{1}{\\varepsilon}\\right),\\qquad\\quad T=\\tilde{\\mathcal{O}}\\left(\\frac{S_{\\alpha}}{\\mu_{1-\\alpha}}\\log\\frac{1}{\\varepsilon}\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "iterations and oracle calls respectively, provided the maximum noise does not exceed the following value $\\Delta\\lesssim\\mu_{1-\\alpha}\\varepsilon/S_{\\alpha}$ . ", "page_idx": 19}, {"type": "text", "text": "E Proof of Convergence for Accelerated Algorithm 2 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Denote $\\omega_{k}=(1-\\beta_{k})z_{k}+\\beta_{k}y_{k}$ . Then ", "page_idx": 20}, {"type": "equation", "text": "$$\ny_{k}={\\frac{(1-\\alpha_{k})x_{k}}{1-\\alpha_{k}\\beta_{k}}}+{\\frac{\\alpha_{k}(1-\\beta_{k})}{1-\\alpha_{k}\\beta_{k}}}\\cdot{\\frac{\\omega_{k}-\\beta_{k}y_{k}}{1-\\beta_{k}}}={\\frac{(1-\\alpha_{k})x_{k}+\\alpha_{k}\\omega_{k}}{1-\\alpha_{k}\\beta_{k}}}-{\\frac{\\alpha_{k}\\beta_{k}y_{k}}{1-\\alpha_{k}\\beta_{k}}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Thus, in method we have the following representation: ", "page_idx": 20}, {"type": "equation", "text": "$$\ny_{k}=(1-\\alpha_{k})x_{k}+\\alpha_{k}\\omega_{k}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Let the solution of initial problem denote $\\begin{array}{r}{x^{*}=x_{*}=\\arg\\operatorname*{min}_{x\\in\\mathbb{R}^{d}}f(x)}\\end{array}$ , then from Assumption 1.1 we obtain: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{\\sqrt{a_{k}}}\\frac{\\langle n_{k}\\rangle}{\\sqrt{a_{k}}}\\bigg[\\left(\\frac{\\Gamma(n_{k}+1)\\Gamma}{\\Gamma(n_{k})}-f(\\ln\\omega_{k})\\right)^{2}-f(\\ln\\omega_{k})^{2}\\bigg]\\bigg(f\\left(n_{k}-\\frac{1}{L_{k}}\\right)\\Gamma(n_{k})\\bigg)-f(\\ln\\omega_{k})\\bigg)}\\\\ &{\\overset{(a)}{\\leq}-\\frac{\\epsilon^{-1}}{\\sqrt{a_{k}}}\\frac{\\langle n_{k}\\rangle}{\\sqrt{a_{k}}}f(\\Gamma(n_{k}))^{2}+\\|n_{k}\\rangle\\,-\\frac{1}{\\sqrt{a_{k}}}f(\\ln\\omega_{k})^{2}}\\\\ &{=-\\frac{\\Gamma(n_{k})^{2}}{\\sqrt{a_{k}}}\\bigg[\\langle n_{k}\\rangle^{2}-f(\\ln\\omega_{k})^{2}\\bigg]+\\bigg(\\frac{\\Gamma(n_{k}+1)}{\\sqrt{a_{k}}}f(\\ln\\omega_{k})\\bigg)^{2}\\bigg]-\\sum_{k=1}^{L_{k}\\to\\sqrt{a_{k}}(\\mu_{k})}-\\delta(\\gamma-1)^{k}}\\\\ &{\\quad+\\ln\\omega_{k}-\\delta(\\gamma-1)^{2}}\\\\ &{\\overset{(a)}{=}-\\frac{\\epsilon^{-1}}{\\sqrt{a_{k}}}\\bigg[\\left(\\delta^{a_{k}}-\\delta^{a_{k}}\\right)^{2}-\\frac{\\delta(\\gamma-1)}{\\sqrt{a_{k}}-\\delta(\\gamma-1)\\Gamma(n_{k})}\\bigg]\\bigg(\\gamma_{k}\\bigg)^{2}+\\frac{2a_{k+1}}{\\sqrt{a_{k}}}\\bigg[\\langle n_{k}\\rangle^{2}-\\delta^{a_{k}}\\bigg]\\bigg(\\nabla_{a}f(\\ln\\omega_{k})\\bigg)^{2}}\\\\ &{\\quad-\\sum_{k=1}^{L_{k}\\to\\sqrt{a_{k}}(\\mu_{k})}-\\delta(\\gamma_{k})^{2}+\\|n_{k}\\rangle\\,-\\delta\\bigg[\\int_{n_{k}+1}^{L_{k}}\\gamma_{k}(\\mu_{k})\\bigg]\\bigg(\\gamma_{k}\\bigg)^{2}}\\\\ &{=-\\left[-\\frac{\\epsilon^{-1}}{\\sqrt{a_{k}}}-\\delta^{a_{k}}\\right]\\bigg(\\gamma_{k \n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\begin{array}{r l}&{-\\frac{4}{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta\\beta}}\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}{L}\\Biggr[\\phantom{2}\\nabla_{\\beta}\\phi_{\\alpha\\beta}^{(1)}}\\\\ &{=-\\Biggl[\\Phi_{\\alpha}(\\frac{\\ensuremath{\\mathcal{E}}_{\\beta}(\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha}(\\frac{\\cdot}{\\ensuremath{\\mathcal{T}}_{\\beta})}}{L})+\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}{L})\\nabla_{\\beta}\\phi_{\\alpha}(\\frac{\\ensuremath{\\mathcal{E}}_{\\beta}(\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha}(\\frac{\\cdot}{\\ensuremath{\\mathcal{T}}_{\\beta})}}{L})+\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}{L})+\\frac{1}{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}-\\mathrm{c.c.}\\Biggr]_{\\beta\\alpha}^{0},}\\\\ &{-\\frac{2}{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta\\beta}}\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}{L}\\Biggr[\\phantom{2}\\nabla_{\\beta}f_{\\alpha\\beta}(\\frac{\\ensuremath{\\mathcal{E}}_{\\beta}(\\frac{\\cdot}{\\mathcal{T}_{\\beta})}}{L})-\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}{L}\\Biggr]_{\\beta\\alpha}^{0}+\\frac{2}{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}\\Biggr[(f_{\\alpha\\beta})_{\\alpha\\beta}(\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha}(\\frac{\\cdot}{\\mathcal{T}_{\\beta})}}{L})}\\\\ &{\\overset{\\mathrm{()}}{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}\\Biggr]_{\\beta\\alpha}^{+}\\Biggl[\\phantom{2}\\biggl.+\\Biggl.\\frac{\\mu_{\\alpha}(\\frac{\\mathcal{E}_{\\beta}(\\frac{\\cdot}{\\mathcal{T}_{\\beta})}}{L})}{L}\\Biggr[\\phantom{2}\\nabla_{\\beta}f_{\\alpha\\beta}(\\frac{\\ensuremath{\\mathcal{E}}_{\\beta}(\\frac{\\cdot}{\\mathcal{T}_{\\beta})}}{L})-\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}{L}\\Biggr]_{\\beta\\alpha}^{+}+\\mathrm{b.c.}}\\\\ &{-\\frac{2}{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta\\beta}}\\frac{\\ensuremath{\\mathcal{E}}_{\\alpha\\beta}}{L}\\Biggr[\\phantom{2}\\nabla\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where in $\\textcircled{1}$ we used Assumption 1.2 with $\\mu_{1-\\alpha}>0$ . ", "page_idx": 21}, {"type": "text", "text": "Denote $r_{k}^{2}\\,=\\,\\|z_{k}-x_{*}\\|_{[1-\\alpha]}^{2}$ and $\\omega_{k}\\,=\\,(1\\,-\\,\\beta_{k})z_{k}\\,+\\,\\beta_{k}y_{k}$ , then due to convexity of the norm function it follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\omega_{k}-x_{*}\\right\\|_{[1-\\alpha]}^{2}\\leq\\left(1-\\beta_{k}\\right)\\left\\|z_{k}-x_{*}\\right\\|_{[1-\\alpha]}^{2}+\\beta_{k}\\left\\|y_{k}-x_{*}\\right\\|_{[1-\\alpha]}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Substituting (24) into (23) we obtain ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathfrak{I}_{k+1}r_{k+1}^{2}\\overset{(24)}{\\leq}(1-\\beta_{k})B_{k+1}r_{k}^{2}+\\beta_{k}B_{k+1}\\left\\|y_{k}-x_{*}\\right\\|_{[1-\\alpha]}^{2}}\\\\ &{\\quad\\quad\\quad\\quad-\\frac{2a_{k+1}}{p_{\\beta}(i_{k})}\\left\\langle\\nabla_{i_{k}}f(y_{k})\\mathbf{e}_{i_{k}},\\boldsymbol{\\omega}_{k}^{i_{k}}-\\boldsymbol{x}_{*}^{i_{k}}\\right\\rangle+\\frac{2L_{k+1}^{2}}{B_{k+1}p_{\\beta}^{2}(i_{k})}\\left(f(y_{k})-f(x_{k+1})\\right)}\\\\ &{\\quad\\quad\\quad\\overset{(2)}{\\leq}B_{k}r_{k}^{2}+\\beta_{k}B_{k+1}\\left\\|y_{k}-x_{*}\\right\\|_{[1-\\alpha]}^{2}-\\frac{2a_{k+1}}{p_{\\beta}(i_{k})}\\left\\langle\\nabla_{i_{k}}f(y_{k})\\mathbf{e}_{i_{k}},\\boldsymbol{\\omega}_{k}^{i_{k}}-\\boldsymbol{x}_{*}^{i_{k}}\\right\\rangle+\\frac{2L_{i_{k}}^{\\alpha}a_{k+1}^{2}}{B_{k+1}p_{\\beta}^{2}(i_{k})}\\left(f(y_{k})-\\left[\\begin{array}{l}{\\hat{y}_{k}}\\\\ {\\hat{y}_{k}}\\end{array}\\right]\\right)}\\\\ &{\\overset{(4)}{\\leq}B_{k}r_{k}^{2}+\\beta_{k}B_{k+1}\\left\\|y_{k}-x_{*}\\right\\|_{[1-\\alpha]}^{2}-\\frac{2a_{k+1}}{p_{\\beta}(i_{k})}\\left\\langle\\nabla_{i_{k}}f(y_{k})\\mathbf{e}_{i_{k}},\\boldsymbol{\\omega}_{k}^{i_{k}}-\\boldsymbol{x}_{*}^{i_{k}}\\right\\rangle+\\frac{2L_{i_{k}}^{\\alpha}a_{k+1}^{2}S_{\\beta}^{2}}{B_{k+1}L_{i_{k}}^{2\\beta}}\\left(f(y_{k})-\\left[\\begin{array}{l}{\\hat{y}_{k}}\\\\ {\\hat{y}_{k}}\\end{array}\\right]\\right)}\\\\ \n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where in $\\textcircled{1}$ we use that $(1-\\beta_{k})B_{k+1}=B_{k+1}-\\sigma_{1-\\alpha}a_{k+1}=B_{k}$ , and in $\\circledcirc$ we use that $\\alpha=2\\beta$ ", "page_idx": 21}, {"type": "text", "text": "Note that $\\begin{array}{r}{\\mathbb{E}\\left[f(x_{k+1})\\right]=\\sum_{i=1}^{d}p_{\\beta}(i)f(x_{k+1})}\\end{array}$ . Therefore, taking expectation we obtain: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathbb{E}\\left[B_{k+1}r_{k+1}^{2}\\right]\\leq B_{k}r_{k}^{2}+\\beta_{k}B_{k+1}\\left\\|y_{k}-x_{*}\\right\\|_{[-\\alpha]}^{2}-\\mathbb{E}\\left[\\frac{2a_{k+1}}{p_{\\beta}(i_{k})}\\left\\langle\\nabla_{i_{k}}f(y_{k})\\mathbf{e}_{i_{k}},\\omega_{k}^{i_{k}}-x_{*}^{i_{k}}\\right\\rangle\\right]}}\\\\ &{\\quad+\\frac{2a_{k+1}^{2}S_{\\beta}^{2}}{B_{k+1}}\\left(f(y_{k})-\\mathbb{E}\\left[f(x_{k+1})\\right]\\right)}\\\\ &{\\leq B_{k}r_{k}^{2}+\\beta_{k}B_{k+1}\\left\\|y_{k}-x_{*}\\right\\|_{[-1-\\alpha]}^{2}-\\displaystyle\\sum_{i=1}^{d}p_{\\beta}(i)\\frac{2a_{k+1}}{p_{\\beta}(i)}\\left\\langle\\nabla_{i}f(y_{k})\\mathbf{e}_{i},\\omega_{k}^{i}-x_{*}^{i_{k}}\\right\\rangle}\\\\ &{\\quad\\quad+\\frac{2a_{k+1}^{2}S_{\\beta}^{2}}{B_{k+1}}\\left(f(y_{k})-\\mathbb{E}\\left[f(x_{k+1})\\right]\\right)}\\\\ &{=B_{k}r_{k}^{2}+\\beta_{k}B_{k+1}\\left\\|y_{k}-x_{*}\\right\\|_{[-\\alpha]}^{2}+2a_{k+1}\\left\\langle\\nabla f(y_{k}),x_{*}-\\omega_{k}\\right\\rangle+\\frac{2a_{k+1}^{2}S_{\\beta}^{2}}{B_{k+1}}\\left(f(y_{k})-\\nu_{*}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since $\\begin{array}{r}{\\omega_{k}\\overset{(22)}{=}y_{k}+\\frac{1-\\alpha_{k}}{\\alpha_{k}}(y_{k}-x_{k})}\\end{array}$ , we obtain ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{2a_{k+1}\\left\\langle\\nabla f(y_{k}),x_{*}-\\omega_{k}\\right\\rangle=2a_{k+1}\\left\\langle\\nabla f(y_{k}),x_{*}-y_{k}+\\displaystyle\\frac{1-\\alpha_{k}}{\\alpha_{k}}(x_{k}-y_{k})\\right\\rangle}\\\\ {\\overset{\\oplus}{\\leq}2a_{k+1}\\left(f(x_{*})-f(y_{k})\\right)-a_{k+1}\\sigma_{1-\\alpha}\\left\\Vert x_{*}-y_{k}\\right\\Vert_{[1-\\alpha]}^{2}}\\\\ {\\quad\\quad+\\displaystyle2a_{k+1}\\frac{1-\\alpha_{k}}{\\alpha_{k}}\\left(f(x_{k})-f(y_{k})\\right)}\\\\ {\\overset{\\oplus}{=}2a_{k+1}f(x_{*})-2A_{k+1}f(y_{k})+2A_{k}f(x_{k})-a_{k+1}\\sigma_{1-\\alpha}\\left\\Vert x_{*}-y_{k}\\right\\Vert_{[1-\\alpha]}^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where in $\\textcircled{1}$ we use Assumption 1.2 with $\\mu_{1-\\alpha}~>~0$ and in $\\circledcirc$ we use that $\\begin{array}{r l}{a_{k+1}\\frac{1-\\alpha_{k}}{\\alpha_{k}}}&{{}=}\\end{array}$ $\\begin{array}{r}{a_{k+1}\\frac{1-\\frac{a_{k+1}}{A_{k+1}}}{\\frac{a_{k+1}}{A_{k+1}}}=A_{k+1}-a_{k+1}=A_{k}.}\\end{array}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\natural\\left[B_{k+1}r_{k+1}^{2}\\right]\\leq B_{k}r_{k}^{2}+\\beta_{k}B_{k+1}\\left\\Vert y_{k}-x_{*}\\right\\Vert_{[1-\\alpha]}^{2}+2a_{k+1}\\left\\langle\\nabla f(y_{k}),x_{*}-\\omega_{k}\\right\\rangle+\\frac{2a_{k+1}^{2}S_{\\beta}^{2}}{B_{k+1}}\\left(f(y_{k})-f(y_{k+1})\\right)\\leq\\frac{2a_{k+1}^{2}S_{\\beta}^{2}}{B_{k}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\partial}{\\partial}\\,B_{k}r_{k}^{2}+a_{k+1}\\sigma_{1-\\alpha}\\,\\|y_{k}-x_{*}\\|_{[1-\\alpha]}^{2}+2a_{k+1}\\left\\langle\\nabla f(y_{k}),x_{*}-\\omega_{k}\\right\\rangle+\\frac{2a_{k+1}^{2}S_{\\beta}^{2}}{B_{k+1}}\\left(f(y_{k})-\\mathbb{E}\\left[f(x_{k+1})-f(y_{k+1})\\right]\\right)}\\\\ {\\displaystyle\\frac{(25)}{\\le}B_{k}r_{k}^{2}+2a_{k+1}f(x_{*})-2A_{k+1}f(y_{k})+2A_{k}f(x_{k})\\pm2A_{k}f(x_{*})+\\frac{2a_{k+1}^{2}S_{\\beta}^{2}}{B_{k+1}}\\left(f(y_{k})-\\mathbb{E}\\left[f(x_{k+1})-f(y_{k+1})\\right]\\right)}\\\\ {\\displaystyle\\frac{\\partial}{=}B_{k}r_{k}^{2}+2a_{k+1}f(x_{*})-2A_{k+1}f(y_{k})+2A_{k}f(x_{k})\\pm2A_{k}f(x_{*})+2A_{k+1}\\left(f(y_{k})-\\mathbb{E}\\left[f(x_{k+1})-f(x_{k+1})\\right]\\right)}\\\\ {\\displaystyle=B_{k}r_{k}^{2}-2A_{k+1}\\left(\\mathbb{E}\\left[f(x_{k+1})\\right]-f(x_{*})\\right)+2A_{k}\\left(f(x_{k})-f(x_{*})\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where in $\\textcircled{1}$ we use that $\\begin{array}{r}{\\beta_{k}=\\frac{\\sigma_{1-\\alpha}a_{k+1}}{B_{l+1}}}\\end{array}$ , and in $\\circledcirc$ we use that $a_{k+1}^{2}S_{\\beta}^{2}=A_{k+1}B_{k+1}$ ", "page_idx": 22}, {"type": "text", "text": "By summing over $k$ we obtain: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{k=0}^{N-1}A_{k+1}\\left(\\mathbb{E}\\left[f(x_{k+1})\\right]-f(x_{*})\\right)\\leq2\\sum_{k=0}^{N-1}A_{k}\\left(f(x_{k})-f(x_{*})\\right)+\\sum_{k=0}^{N-1}B_{k}r_{k}^{2}-\\sum_{k=0}^{N-1}\\mathbb{E}\\left[B_{k+1}r_{k+1}^{2}\\right]\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n2A_{N}\\left(\\mathbb{E}\\left[f(x_{N})\\right]-f(x_{*})\\right)\\leq2A_{0}\\left(f(x_{0})-f(x_{*})\\right)+B_{0}r_{0}^{2}-\\mathbb{E}\\left[B_{N}r_{N}^{2}\\right].\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Using the known facts from Nesterov and Stich (2017) we can estimate the parameters $A_{N}$ and $B_{N}$ : ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{A_{N}\\geq\\displaystyle\\frac{1}{4\\mu_{1-\\alpha}}\\left[(1+\\gamma)^{N}-(1-\\gamma)^{N}\\right]^{2}}}\\\\ {{\\mathrm{}}}\\\\ {{\\displaystyle\\geq\\frac{1}{4\\mu_{1-\\alpha}}\\left[(1+\\gamma)^{N}-1\\right]^{2}\\geq\\displaystyle\\frac{1}{8\\mu_{1-\\alpha}}(1+\\gamma)^{2N}\\geq\\displaystyle\\frac{1}{8\\mu_{1-\\alpha}}(1+\\gamma)^{N},}}\\\\ {{B_{N}\\geq\\displaystyle\\frac{1}{4}\\left[(1+\\gamma)^{N}+(1-\\gamma)^{N}\\right]^{2},}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\begin{array}{r}{\\gamma=\\frac{\\sqrt{\\mu_{1-\\alpha}}}{2S_{\\alpha/2}}}\\end{array}$ 2S\u00b51\u2212\u03b1. Then using A0 = 0 and B0 = 1 we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{A_{N}\\left(\\mathbb{E}\\left[f(x_{N})\\right]-f(x_{*})\\right)\\leq2A_{0}\\left(f(x_{0})-f(x_{*})\\right)+B_{0}r_{0}^{2}-B_{N}\\mathbb{E}\\left[r_{N}^{2}\\right].}\\\\ &{\\overset{\\textcircled{\\ast}}{\\leq}\\frac{1}{\\mu_{1-\\alpha}}\\left(f(x_{0})-f(x_{*})-\\langle\\nabla f(x_{*}),x_{0}-x_{*}\\rangle\\right)}\\\\ &{=\\frac{1}{\\mu_{1-\\alpha}}\\left(f(x_{0})-f(x_{*})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Let\u2019s divide both parts by $A_{N}$ , then we have the convergence rate for accelerated method ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\left[f(x_{N})\\right]-f(x_{*})\\le\\displaystyle\\frac{1}{\\mu_{1-\\alpha}A_{N}}\\left(f(x_{0})-f(x_{*})\\right)}&{}\\\\ {\\le8(1+\\gamma)^{-N}\\left(f(x_{0})-f(x_{*})\\right)}&{}\\\\ {\\le8(1-\\gamma)^{N}\\left(f(x_{0})-f(x_{*})\\right)}&{}\\\\ {=8\\left(1-\\frac{\\sqrt{\\mu_{1-\\alpha}}}{2S_{\\alpha/2}}\\right)^{N}\\left(f(x_{0})-f(x_{*})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, achieving the desired accuracy $\\varepsilon$ , where $\\mathbb{E}\\left[f(x_{N})\\right]-f(x^{*})\\leq\\varepsilon$ , requires ", "page_idx": 22}, {"type": "equation", "text": "$$\nN=\\mathcal{O}\\left(\\frac{S_{\\alpha/2}}{\\sqrt{\\mu_{1-\\alpha}}}\\log\\frac{1}{\\varepsilon}\\right),\\qquad\\;\\;T=\\tilde{\\mathcal{O}}\\left(\\frac{S_{\\alpha/2}}{\\sqrt{\\mu_{1-\\alpha}}}\\log\\frac{1}{\\varepsilon}\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "iterations and oracle calls respectively. ", "page_idx": 22}, {"type": "text", "text": "F Scheme of the Proof of Asymptotic Convergence of the Algorithm with the Stochastic Order Oracle Concept ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this Section, we give a proof of Theorem 5.3, which is based on the work of Polyak and Tsypkin (1980). In order to take advantage of the above work, we need to show that our method (9) is a normalized stochastic gradient descent. Therefore, we will first prove two auxiliary Lemmas 5.1 and 5.2 showing that our algorithm is still a normalized stochastic gradient descent, and then proceed to the statement of the Theorem 5.3. Our reasoning in the Proofs of auxiliary Lemmas is similar to the work of Saha et al. (2021). ", "page_idx": 22}, {"type": "text", "text": "Lemma F.1. Let the function $f$ be $L$ -smooth (for all $\\begin{array}{r l r l}{x,y}&{{}\\in}&{{}\\mathbb{R}^{d}}\\end{array}$ it holds: $\\begin{array}{r}{f(y,\\xi)\\leq f(x,\\xi)+\\langle\\nabla f(x,\\xi),y-x\\rangle+\\frac{L}{2}\\left\\|y-x\\right\\|^{2}),~~\\gamma~=~~\\frac{\\left\\|\\nabla f(x,\\xi)\\right\\|}{\\sqrt{d}L}~~a n d\\textbf{e}\\in~S^{c}}\\end{array}$ , then the following holds: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi(x+\\gamma\\mathbf{e},x-\\gamma\\mathbf{e},\\xi)\\mathbf{e}=\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. From the Assumption of $L$ -smoothness of the function $f$ we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\langle\\nabla f(x,\\xi),\\gamma\\mathbf{e}\\rangle-\\displaystyle\\frac{L\\gamma^{2}}{2}\\le f(x+\\gamma\\mathbf{e},\\xi)-f(x,\\xi)\\le\\langle\\nabla f(x,\\xi),\\gamma\\mathbf{e}\\rangle+\\displaystyle\\frac{L\\gamma^{2}}{2};\\ \\ }\\\\ &{}&{-\\left\\langle\\nabla f(x,\\xi),\\gamma\\mathbf{e}\\right\\rangle-\\displaystyle\\frac{L\\gamma^{2}}{2}\\le f(x-\\gamma\\mathbf{e},\\xi)-f(x,\\xi)\\le-\\left\\langle\\nabla f(x,\\xi),\\gamma\\mathbf{e}\\right\\rangle+\\displaystyle\\frac{L\\gamma^{2}}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Subtracting the inequalities, we obtain ", "page_idx": 23}, {"type": "equation", "text": "$$\n|f(x+\\gamma\\mathbf{e},\\xi)-f(x-\\gamma\\mathbf{e},\\xi)-2\\gamma\\left<\\nabla f(x,\\xi),\\mathbf{e}\\right>|\\leq L\\gamma^{2}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Consequently, if $L\\gamma^{2}\\leq\\gamma|\\left\\langle\\nabla f(x,\\xi),\\mathbf{e}\\right\\rangle|$ , we have that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi(x+\\gamma\\mathbf{e},x-\\gamma\\mathbf{e},\\xi)\\mathbf{e}=\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let\u2018s analyse $\\mathcal{P}_{\\mathbf{e}}\\left(L\\gamma\\leq|\\left\\langle\\nabla f(x,\\xi),\\mathbf{e}\\right\\rangle|\\right)$ . It is known that for $\\begin{array}{r}{\\mathbf{u}\\sim\\mathcal{N}\\left(0,I\\right),\\mathbf{e}:=\\frac{\\mathbf{u}}{\\|\\mathbf{u}\\|}}\\end{array}$ is a vector uniformly distributed on the unit Euclidean sphere. Then the following is true: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{\\mathcal{P}_{e}}\\left(|\\left\\langle\\nabla f(x,\\xi),\\mathbf{e}\\right\\rangle|\\ge L\\gamma\\right)=\\mathcal{P}_{\\mathbf{u}}\\left(|\\left\\langle\\nabla f(x,\\xi),\\mathbf{u}\\right\\rangle|\\ge L\\gamma\\|\\mathbf{u}\\|\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\le\\mathcal{P}_{\\mathbf{u}}\\left(|\\left\\langle\\nabla f(x,\\xi),\\mathbf{u}\\right\\rangle|\\ge2L\\gamma\\sqrt{d\\log1/\\Tilde{\\beta}}\\right)+\\mathcal{P}_{\\mathbf{u}}\\left(\\|\\mathbf{u}\\|\\ge2\\sqrt{d\\log1/\\Tilde{\\beta}}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\le\\mathcal{P}_{\\mathbf{u}}\\left(|\\left\\langle\\nabla f(x,\\xi),\\mathbf{u}\\right\\rangle|\\ge2L\\gamma\\sqrt{d\\log1/\\Tilde{\\beta}}\\right)+\\Tilde{\\beta},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we used the well-known fact that $\\forall\\widetilde{\\beta}$ $\\tilde{\\beta}\\colon\\mathcal{P}_{\\mathbf{u}}\\left(\\left\\|\\mathbf{u}\\right\\|\\leq2\\sqrt{d\\log1/\\tilde{\\beta}}\\right)\\geq1-\\tilde{\\beta}$ . On the other hand, since $\\left\\langle\\nabla f(x,\\xi),\\mathbf{u}\\right\\rangle\\sim\\mathcal{N}\\left(0,\\|\\nabla f(x,\\xi)\\|^{2}\\right)$ , then for all $\\gamma>0$ we obtain ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathcal{P}\\left(\\left|\\left\\langle\\nabla f(x,\\xi),\\mathbf{u}\\right\\rangle\\right|\\leq\\gamma\\right)\\leq\\frac{2\\gamma}{\\left\\Vert\\nabla f(x,\\xi)\\right\\Vert\\sqrt{2\\pi}}\\leq\\frac{\\gamma}{\\left\\Vert\\nabla f(x,\\xi)\\right\\Vert}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Combining the inequalities, we have that $\\phi(x+\\gamma\\mathbf{e},x-\\gamma\\mathbf{e},\\xi)\\mathbf{e}=\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}$ except with probability at most ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\tilde{\\beta}>0}\\left\\{\\tilde{\\beta}+\\frac{2L\\gamma\\sqrt{d\\log1/\\tilde{\\beta}}}{\\|\\nabla f(x,\\xi)\\|}\\right\\}\\leq\\frac{3L\\gamma}{\\|\\nabla f(x,\\xi)\\|}\\sqrt{d\\log\\frac{\\|\\nabla f(x,\\xi)\\|}{\\sqrt{d}L\\gamma}}\\overset{\\^\\perp}{=}0=\\beta,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where in $\\textcircled{1}$ we take $\\begin{array}{r}{\\gamma\\,=\\,\\frac{||\\nabla f(x,\\xi)||}{\\sqrt{d}L}}\\end{array}$ . Thus, given the condition on the smoothing parameter, the statement of the Lemma is satisfied with probability 1. ", "page_idx": 23}, {"type": "text", "text": "Lemma F.2. Let vector $\\nabla f(x,\\xi)\\in\\mathbb{R}^{d}$ and vector $\\mathbf{e}\\in S^{d}(1)$ , then we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}\\right]=\\frac{c}{\\sqrt{d}}\\cdot\\frac{\\nabla f(x,\\xi)}{\\|\\nabla f(x,\\xi)\\|},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $c\\in[\\frac{1}{20},1]$ is some universal constant. ", "page_idx": 23}, {"type": "text", "text": "Proof. Without loss of generality, we can assume $\\|\\nabla f(x,\\xi)\\|=1$ , as normalizing $\\|\\nabla f(x,\\xi)\\|$ does not impact the left-hand side. First, let\u2019s demonstrate that $\\mathbb{E}$ [sign $[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle]\\,\\mathbf{e}]=\\zeta\\dot{\\nabla}f(x,\\xi)$ for some $\\zeta\\in\\mathbb{R}$ . Consider the reflection matrix along $\\nabla f(x,\\xi)$ given by: ", "page_idx": 23}, {"type": "equation", "text": "$$\nP=2\\nabla f(x,\\xi)\\nabla f(x,\\xi)^{\\mathrm{T}}-I,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "and examine the random vector $\\tilde{\\mathbf{e}}=P\\mathbf{e}$ . As you can see that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathfrak{m}\\left[\\left\\langle\\nabla f(x,\\xi),\\tilde{\\mathbf{e}}\\right\\rangle\\right]=\\mathrm{sign}\\left[2\\left\\Vert\\nabla f(x,\\xi)\\right\\Vert^{2}\\left\\langle\\nabla f(x,\\xi),\\mathbf{e}\\right\\rangle-\\left\\langle\\nabla f(x,\\xi),\\mathbf{e}\\right\\rangle\\right]=\\mathrm{sign}\\left[\\left\\langle\\nabla f(x,\\xi),\\mathbf{e}\\right\\rangle\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since $\\tilde{\\mathbf{e}}$ is also a random vector on the unit sphere, we then have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\mathbf{e}}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}\\right]=\\frac{1}{2}\\mathbb{E}_{\\mathbf{e}}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}\\right]+\\frac{1}{2}\\mathbb{E}_{\\mathbf{e}}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\tilde{\\mathbf{e}}\\rangle\\right]\\tilde{\\mathbf{e}}\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=\\frac{1}{2}\\mathbb{E}_{\\mathbf{e}}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad+\\frac{1}{2}\\mathbb{E}_{\\mathbf{e}}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\left(2\\nabla f(x,\\xi)\\nabla f(x,\\xi)^{\\mathrm{T}}-I\\right)\\mathbf{e}\\right]}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad=\\mathbb{E}_{\\mathbf{e}}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\,\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\right]\\nabla f(x,\\xi).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, $\\mathbb{E}_{\\mathbf{e}}\\left[\\operatorname{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}\\right]=\\zeta\\nabla f(x)$ , where $\\zeta=\\mathbb{E}_{\\mathbf{e}}\\left[|\\left\\langle\\nabla f(x,\\xi),\\mathbf{e}\\right\\rangle|\\right]$ . It remains to restrict $\\zeta$ , which by virtue of rotation invariance is equal to $\\zeta=\\mathbb{E}\\left[e_{1}\\right]$ . For an upper bound, observe that by symmetry $\\begin{array}{r}{\\mathbb{E}\\left[e_{1}^{2}\\right]=\\frac{1}{d}\\mathbb{E}\\left[\\sum_{i=1}^{d}e_{i}^{2}\\right]=\\frac{1}{d}}\\end{array}$ and consequently: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left|e_{1}\\right|\\right]\\leq{\\sqrt{\\mathbb{E}\\left[e_{1}^{2}\\right]}}={\\frac{1}{\\sqrt{d}}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Let us prove a lower bound on $\\zeta$ . If e were a Gaussian random vector with i.i.d. entries $\\begin{array}{r}{e_{i}\\sim\\mathcal{N}\\left(0,\\frac{1}{d}\\right)}\\end{array}$ , then from the standard properties of the (truncated) Gaussian distribution we would obtain that $\\mathbb{E}\\left[\\vert e_{1}\\vert\\right]=\\sqrt{\\frac{2}{\\pi d}}$ . For e uniformly distributed on the unit sphere, $e_{i}$ is distributed like $\\frac{u_{1}}{\\|\\mathbf{u}\\|}$ , where $\\mathbf{u}$ is Gaussian with i.i.d. entries $\\textstyle N\\left(0,{\\frac{1}{d}}\\right)$ . We then can write: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{P}\\left(|e_{1}|\\geq\\frac{v}{\\sqrt{d}}\\right)=\\mathcal{P}\\left(\\frac{|u_{1}|}{\\|\\mathbf{u}\\|}\\geq\\frac{v}{\\sqrt{d}}\\right)\\geq\\mathcal{P}\\left(|u_{1}|\\geq\\frac{1}{\\sqrt{d}}\\mathrm{and}\\,\\|\\mathbf{u}\\|\\leq\\frac{1}{v}\\right)}\\\\ &{\\qquad\\qquad\\qquad\\geq1-\\mathcal{P}\\left(|u_{1}|\\geq\\frac{1}{\\sqrt{d}}\\right)-\\mathcal{P}\\left(\\|\\mathbf{u}\\|>\\frac{1}{v}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since $u_{1}\\sqrt{d}$ is a standard Normal, we obtain ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{P}\\left(|u_{1}|\\geq\\frac{1}{\\sqrt{d}}\\right)=\\mathcal{P}\\left(-1<u_{1}\\sqrt{d}<1\\right)\\leq0.7,\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and since $\\mathbb{E}\\left[\\left\\Vert\\mathbf{u}\\right\\Vert^{2}\\right]=1$ , the application of Markov inequality gives: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{P}\\left(\\lvert\\lvert\\mathbf{u}\\rvert\\rvert>\\frac{1}{v}\\right)=\\mathcal{P}\\left(\\lvert\\lvert\\mathbf{u}\\rvert\\rvert^{2}>\\frac{1}{v^{2}}\\right)\\leq v^{2}\\mathbb{E}\\left[\\lvert\\lvert\\mathbf{u}\\rvert\\rvert^{2}\\right]=v^{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "For $v=0.25$ , this means that $\\mathcal{P}\\left(|e_{1}|\\geq0.25\\sqrt{d}\\right)\\geq0.2$ , whence $\\begin{array}{r}{\\zeta=\\mathbb{E}\\left[\\left|e_{1}\\right|\\right]\\geq\\frac{1}{20}\\sqrt{d}.}\\end{array}$ . ", "page_idx": 24}, {"type": "text", "text": "Now that we have shown that our method (9) is a normalized stochastic gradient descent, then by applying Theorem 2 of Polyak and Tsypkin (1980), and refining Theorem 2 to the case of normalized SGD, where in our case ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{R(x)=\\mathbb{E}\\left[\\phi(x+\\gamma\\mathbf{e},x-\\gamma\\mathbf{e},\\xi)\\mathbf{e}\\right]=\\mathbb{E}\\left[\\mathrm{sign}\\left[\\langle\\nabla f(x,\\xi),\\mathbf{e}\\rangle\\right]\\mathbf{e}\\right]\\overset{\\odot}{=}\\frac{c}{\\sqrt{d}}\\mathbb{E}_{\\xi}\\left[\\frac{\\nabla f(x,\\xi)}{\\|\\nabla f(x,\\xi)\\|}\\right]}}\\ ~}\\\\ {{\\displaystyle{\\overset{\\circleddash}{=}\\frac{c}{\\sqrt{d}}\\int\\varphi(\\nabla f(x)+z)d P(z)=\\frac{c}{\\sqrt{d}}\\psi(\\nabla f(x)),}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where in $\\textcircled{1}$ we used the Lemma 5.2, and in $\\circledcirc$ we defined a function $\\varphi(z)\\,=\\,{\\frac{z}{\\|z\\|}}$ and used that $\\nabla f(x,\\xi)=\\nabla f(x)+\\xi$ . Thus, using the following ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\tau^{*})=\\frac{c}{\\sqrt{d}}\\psi^{\\prime}(0)\\nabla^{2}f(x^{*})=\\frac{c}{\\sqrt{d}}\\int\\nabla\\varphi(z)d P(z)\\nabla^{2}f(x^{*})=\\left(1-\\frac{1}{d}\\right)\\frac{c}{\\sqrt{d}}\\underbrace{\\int\\Vert z\\Vert^{-1}\\,d P(z)}_{\\alpha}\\nabla^{2}f(x^{*}).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "and $\\begin{array}{r}{\\eta_{k}=\\frac{\\eta}{k}}\\end{array}$ , we obtain the sought statement of Theorem 5.3, which guarantees asymptotic convergence. ", "page_idx": 24}, {"type": "text", "text": "G Description of the \"Private Communication\" Approach ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section, we describe an approach privately communicated to us by Yurii Nesterov to create a more efficient algorithm for low-dimensional problems, compared to the gradient-based methods proposed in this paper, using only the Order Oracle (2). ", "page_idx": 25}, {"type": "text", "text": "Consider the following method for solving the problem of minimiz  \ning a convex Lipschitz function (with Lipschitz constant $L$ ) on a   \nsquare in $\\mathbb{R}^{2}$ with side $R$ . A horizontal line (blue line) is drawn   \nthrough the center of the square. On the interval carved from the   \nsquare of this line, with accuracy $\\sim\\varepsilon/\\log(L R/\\varepsilon)$ (by function) we   \nsolve the one-dimensional optimization (line search) problem. At   \nthe found point (blue point), the direction of the function gradient   \n(which is determined via the Order Oracle) is calculated and it is   \ndetermined in which of the two rectangles it \u201clooks\"; this rectangle   \nis \u201cdiscarded\". A vertical line (red line) is drawn through the center   \nof the remaining rectangle, and on the segment carved by this line   \nin the rectangle, also with accuracy $\\sim\\varepsilon/\\log(L R/\\varepsilon)$ (by function)   \nsolves the problem of one-dimensional optimization (line search)   \nproblem. At the found point (red point), the direction of the function   \ngradient (which is determined via the Order Oracle) is calculated Figure 7: Schematic of algorithm ", "page_idx": 25}, {"type": "text", "text": "and it is determined in which of the two rectangles it \u201clooks\"; this rectangle is \u201cdiscarded\". As a result of this procedure, the linear size of the original square is halved (green square). The schematic of the performance of the algorithm is shown in Figure 7. ", "page_idx": 25}, {"type": "image", "img_path": "kxBsNEWB42/tmp/fdaeef63984f37fcf5af8435506a83bdc155ef8ab603b44ffc1cec924ec3242e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "Corollary G.1. It is not difficult to show that after $\\log(L R/\\varepsilon)$ repetitions of such a procedure we can find with \u03b5 accuracy (by function) the solution of the original problem. ", "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: For convenience, we have also added a Subsection \u201cOur contributions\u201d to Section 1 (Introduction). ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: See Section 1 (Introduction) where we formulate the problem statement. See also the statement of Theorems, where we provide conditions under which the theoretical results are guaranteed, and the discussion of them. In addition, we discuss in Section 6 (Discussion) how the algorithm would behave if we move away from the assumptions under consideration, e.g., the gradient dominance assumption (Polyak\u2013Lojasiewicz condition). ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: The main assumptions and notations can be found in Section 1 (Introduction). Each theoretical statement contains conditions (assumptions) under which a particular result is guaranteed. And also after each theoretical result (discussion) there is a link to the Appendix section with a detailed proof. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Section 7 (Experiments) presents a particular problem formulation (1), which demonstrates the performance of the proposed algorithms with its counterparts in a numerical experiment. Also, both in the main Section 7 and in the additional Numerical Experiments Section (Appendix B), detailed information on the hyperparameters used and other information necessary to reproduce the experiments is provided. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 27}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [No] ", "page_idx": 28}, {"type": "text", "text": "Justification: We believe that the presented experiments contain well-described information that allows us to implement the code on ourselves without difficulty. However, if the Reviewers or Area Chair feel that the information provided is not sufficient for reproducibility of the experiments, we will certainly add a link to an anonymous repository with the code. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: In both the main Section 7 and the supplementary Section (Appendix B), we have provided experiments with detailed information including, for example, parameter values, adversarial noise function, etc. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [No] ", "page_idx": 28}, {"type": "text", "text": "Justification: Unfortunately running experiments several times to calculate statistics and error bars would be too computationally expensive ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Detailed information is provided in the section with additional experiments (see Appendix B, Technical Information) ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Research conforms with NeurIPS Code of Ethics ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: This work does not have a negative social impact ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: Presented research doesn\u2019t need safeguards ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: All the used assets are cited ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. ", "page_idx": 30}, {"type": "text", "text": "\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: This work provides as new assets unique theoretical results that are verified by numerical experiment. If necessary, we will provide a code license after acceptance of the paper ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 32}]