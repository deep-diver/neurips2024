[{"figure_path": "om2Aa0gUha/figures/figures_8_1.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size nk is equal to its lower bound in sec. 4, with the choice ck := y2h(k+1) (note the dependence on h) and in solid lines, the step size nk is set using an identical stepsize schedule across all values of h with ck := y2(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "This figure shows the suboptimality gap of the h-PMD algorithm in both exact and inexact settings. The x-axis represents iterations for the exact case and both iterations and runtime for the inexact case. The y-axis represents the suboptimality gap. The figure shows that h-PMD converges faster with larger h, even considering runtime. The different line styles represent different step size strategies, either adaptive or fixed. ", "section": "7 Simulations"}, {"figure_path": "om2Aa0gUha/figures/figures_27_1.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size nk is equal to its lower bound in sec. 4, with the choice ck := y2h(k+1) (note the dependence on h) and in solid lines, the step size nk is set using an identical stepsize schedule across all values of h with ck := y2(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "This figure compares the performance of the h-PMD algorithm in both exact and inexact settings across different values of h (lookahead depth). The left panel shows the suboptimality gap against iterations for the exact setting. The middle and right panels display the same metrics for the inexact setting, with the right panel also showing runtime. The results indicate that higher values of h lead to faster convergence, even considering runtime.", "section": "Simulations"}, {"figure_path": "om2Aa0gUha/figures/figures_28_1.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size \u03b7k is equal to its lower bound in sec. 4, with the choice ck := \u03b32h(k+1) (note the dependence on h) and in solid lines, \u03b7k identical stepsize schedule across all values of h with ck := \u03b32(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "This figure shows the suboptimality gap for h-PMD in both exact and inexact settings. The left plot shows the exact setting, with the suboptimality plotted against iterations. The middle and right plots show the inexact setting, with suboptimality plotted against both iterations and runtime.  The results show that h-PMD converges faster with larger lookahead depths (h), even considering the increased computational cost per iteration. Different step-size strategies were used, with the results highlighting the benefits of lookahead regardless of the step-size approach.", "section": "Simulations"}, {"figure_path": "om2Aa0gUha/figures/figures_28_2.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size nk is equal to its lower bound in sec. 4, with the choice ck := y2h(k+1) (note the dependence on h) and in solid lines, the step size nk is set using an identical stepsize schedule across all values of h with ck := y2(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "This figure shows the convergence performance of the h-PMD algorithm in both exact and inexact settings.  The left panel displays the suboptimality gap versus iterations for the exact setting, illustrating that higher lookahead depth (h) leads to faster convergence. The middle and right panels show the same metrics for the inexact setting, with the right panel additionally showing runtime.  Different step-size schedules are compared (dotted and solid lines). The results consistently demonstrate the benefits of lookahead, showing faster convergence with increasing h, even when considering runtime.", "section": "7 Simulations"}, {"figure_path": "om2Aa0gUha/figures/figures_29_1.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size nk is equal to its lower bound in sec. 4, with the choice ck := y2h(k+1) (note the dependence on h) and in solid lines, the step size nk is set using an identical stepsize schedule across all values of h with ck := y2(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "This figure compares the performance of the h-PMD algorithm in both exact and inexact settings. The left plot shows the suboptimality gap against iterations for the exact h-PMD (where the value function can be computed exactly), demonstrating faster convergence with increasing lookahead depth (h). The middle and right plots show the same for the inexact h-PMD (where the value function is estimated using Monte Carlo sampling), with the right plot showing the runtime instead of iterations.  The results show h-PMD converges faster with higher h, even when considering runtime.", "section": "Simulations"}, {"figure_path": "om2Aa0gUha/figures/figures_29_2.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size nk is equal to its lower bound in sec. 4, with the choice ck := y2h(k+1) (note the dependence on h) and in solid lines, the step size nk is set using an identical stepsize schedule across all values of h with ck := y2(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "This figure displays the suboptimality gap (difference between optimal value function and the value function at each iteration) for h-PMD in both exact (where h-step lookahead values are computed precisely) and inexact (where h-step lookahead values are estimated using Monte Carlo sampling) settings. The left panel shows iterations vs. suboptimality gap in the exact setting, while the middle and right panels show iterations and runtime vs. suboptimality gap in the inexact setting.  The figure shows that h-PMD with higher values of lookahead parameter h converges faster, even when considering runtime (right panel).  Two different step size strategies are also compared.", "section": "Simulations"}, {"figure_path": "om2Aa0gUha/figures/figures_30_1.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size nk is equal to its lower bound in sec. 4, with the choice ck := y2h(k+1) (note the dependence on h) and in solid lines, the step size nk is set using an identical stepsize schedule across all values of h with ck := y2(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "This figure shows the convergence rate of the h-PMD algorithm (in both exact and inexact settings) for different lookahead depths (h). The left plot shows the suboptimality gap against the number of iterations for the exact setting, while the middle and right plots show this gap against the number of iterations and the runtime respectively for the inexact setting.  The plots demonstrate that increasing the lookahead depth (h) leads to faster convergence, even when considering the increased computational cost per iteration.", "section": "Simulations"}, {"figure_path": "om2Aa0gUha/figures/figures_30_2.jpg", "caption": "Figure 8: Performance of h-PMD in two of OpenAI's gym [8] environments, CartPole-v1 (left) and Acrobot-v1 (right). In both figures the reward is plotted against the total number of environment steps evaluated, which can be understood as the number of samples used. Note that higher values of h do lead to better performance for the CartPole-v1 environment, but not necessarily for the Acrobot-v1 environment.", "description": "This figure shows the performance of h-PMD on two continuous control environments from OpenAI Gym: CartPole-v1 and Acrobot-v1.  The x-axis represents the total number of steps (and therefore samples) taken by the algorithm, while the y-axis shows the accumulated reward. Different line colors represent different lookahead depths (h).  The shaded areas represent confidence intervals.  The results demonstrate that increasing the lookahead depth (h) can improve performance in the CartPole environment, but the effect is less pronounced and potentially non-monotonic in the Acrobot environment, highlighting task-dependent behavior of the lookahead mechanism.", "section": "D.7 Continuous Control Experiments"}, {"figure_path": "om2Aa0gUha/figures/figures_31_1.jpg", "caption": "Figure 1: Suboptimality value function gap for h-PMD in the exact (left) and inexact (middle/right) settings, plotted against iterations in the exact case (left) and against both iterations (middle) and runtime (right) in the inexact case. 16 runs performed for each h, mean in solid line and standard deviation as shaded area. In dotted lines (left), the step size \u03b7k is equal to its lower bound in sec. 4, with the choice ck := \u03b32h(k+1) (note the dependence on h) and in solid lines, \u03b7k identical stepsize schedule across all values of h with ck := \u03b32(k+1) to isolate the effect of the lookahead. Notice that higher values of h still perform better even in terms of runtime.", "description": "The figure shows the convergence performance of the h-PMD algorithm in both exact and inexact settings. The left panel displays the suboptimality gap against the number of iterations for the exact case, while the middle and right panels show the same metric against iterations and runtime respectively for the inexact case.  The results indicate that increasing the lookahead depth h leads to faster convergence, even considering the increased computational cost in the inexact setting.", "section": "7 Simulations"}]