[{"figure_path": "0LfgE6kvKZ/tables/tables_6_1.jpg", "caption": "Table 1: Label shift test accuracy after R = 1 and R = 3 communication rounds. We primarily compared two categories of methods: conventional FL methods and state-of-the-art local weight averaging-based fine-tuning methods that enhance domain generalization.", "description": "This table presents the results of label shift experiments on FMNIST and CIFAR-10 datasets.  It compares the performance of various federated learning (FL) methods, including both conventional methods and more advanced techniques focused on local weight averaging and fine-tuning to improve domain generalization.  The accuracy is measured after 1 and 3 communication rounds, showing how different methods perform with limited communication.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_6_2.jpg", "caption": "Table 2: Feature shift test accuracy after R = 1 and R = 3 communication rounds. LSS consistently outperforms other methods on both datasets across under feature shift settings.", "description": "This table presents the results of experiments conducted to evaluate the performance of Local Superior Soups (LSS) and other federated learning methods under feature shift conditions.  The accuracy of different algorithms is compared on two datasets (Digit-5 and DomainNet) after 1 and 3 communication rounds.  The results show that LSS consistently achieves higher accuracy than other methods, highlighting its effectiveness in handling feature shift in federated learning.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_13_1.jpg", "caption": "Table 1: Label shift test accuracy after R = 1 and R = 3 communication rounds. We primarily compared two categories of methods: conventional FL methods and state-of-the-art local weight averaging-based fine-tuning methods that enhance domain generalization.", "description": "This table presents the test accuracy results for various federated learning methods under label shift conditions.  The accuracy is measured after 1 and 3 communication rounds.  The methods are categorized into conventional FL methods and advanced methods using local weight averaging and fine-tuning for improved domain generalization.  The results show how different methods perform under limited communication rounds in a challenging non-IID data scenario.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_19_1.jpg", "caption": "Table 4: FedAvg with different local steps: Label shift test accuracy after R = 1 communication rounds (CIFAR-10 with 5 Clients).", "description": "This table presents the results of experiments using the FedAvg algorithm with varying numbers of local training steps (\u03c4) on the CIFAR-10 dataset under a label shift scenario. The test accuracy is reported after a single round of communication (R=1) for five clients. The results show how changing the number of local training steps affects the model's performance in this setting.  It demonstrates that arbitrarily increasing local steps may not always lead to improved performance.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_19_2.jpg", "caption": "Table 5: Computational and memory costs of different types of method (ResNet-18).", "description": "This table compares the computational overhead (in Giga MACs) and memory usage for different federated learning methods, including FedAvg, SWA, Soups, and LSS.  It shows that while LSS has higher computational costs per epoch and round than FedAvg and SWA, its training time per round is significantly less than Soups due to its more efficient model selection and training process. The memory usage is also shown.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_19_3.jpg", "caption": "Table 6: Smoothness of the trained model. Evaluated trained model performance drop on a testset with added l\u221e norm random noise. CIFAR-10 dataset Dirichlet distribution a = 1.0 and a = 0.1: Label shift test accuracy after R = 1", "description": "This table presents the results of an experiment designed to evaluate the robustness of the trained models to noise perturbation.  It shows the performance degradation (drop in accuracy) of models trained using FedAvg and the proposed LSS method when different levels of noise are added to the test set. Lower values indicate better robustness.  The experiment uses the CIFAR-10 dataset with two different Dirichlet distributions (\u03b1=1.0 and \u03b1=0.1) to simulate different levels of label shift.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_20_1.jpg", "caption": "Table 7: Loss landscape flatness quantification with Hessian eigenvalue.", "description": "This table presents the Hessian eigenvalue, a metric used to quantify the flatness of the loss landscape, for different methods. Lower values indicate flatter minima, generally associated with better generalization. The table compares FedAvg to Local Superior Soups (LSS) with varying numbers of averaged models (M).", "section": "4.3 Ablation Studies"}, {"figure_path": "0LfgE6kvKZ/tables/tables_20_2.jpg", "caption": "Table 8: Different client numbers (5 Clients and 50 Clients): Label shift test accuracy after R = 1 and R = 3 communication rounds.", "description": "This table presents the results of experiments conducted to evaluate the performance of the proposed LSS method and the baseline FedAvg method under different numbers of clients (5 and 50) in a label shift scenario. The accuracy of both methods is measured after 1 and 3 communication rounds. The results demonstrate that LSS consistently outperforms FedAvg across different client numbers and communication rounds, highlighting its efficiency and effectiveness in handling the complexities of federated learning with a larger number of clients.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_20_3.jpg", "caption": "Table 2: Feature shift test accuracy after R = 1 and R = 3 communication rounds. LSS consistently outperforms other methods on both datasets across under feature shift settings.", "description": "This table presents the results of experiments conducted to evaluate the performance of Local Superior Soups (LSS) and other baseline methods under feature shift conditions.  The accuracy of models is compared after 1 and 3 communication rounds on two datasets, Digit-5 and DomainNet.  The results demonstrate that LSS consistently outperforms all other methods across both datasets and communication round settings, highlighting its effectiveness in handling feature shift in federated learning.", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_21_1.jpg", "caption": "Table 10: Different Non-IID level (Dirichlet distribution \u03b1 = 1.0 and \u03b1 = 0.1): Label shift test accuracy after R = 1 and R = 3 communication rounds.", "description": "This table presents the results of experiments conducted to evaluate the performance of FedAvg and the proposed LSS method under different levels of data heterogeneity. The experiments were performed on the CIFAR-10 dataset with two different Dirichlet distribution parameters (\u03b1 = 1.0 and \u03b1 = 0.1), representing different levels of Non-IID data. The table shows the test accuracy achieved by each method after 1 and 3 communication rounds.  The results demonstrate the effectiveness of LSS in achieving higher accuracy compared to FedAvg, especially in scenarios with higher data heterogeneity (\u03b1 = 0.1).", "section": "4.2 Performance Comparison"}, {"figure_path": "0LfgE6kvKZ/tables/tables_21_2.jpg", "caption": "Table 11: Different model initialization (Pre-trained v.s. Random): Label shift test accuracy after R = 1 and R = 3 communication rounds. Result: It shows that our method still maintains a significant advantage with random initialization, but it does not achieve the near-optimal performance seen with pre-trained initialization.", "description": "This table compares the performance of FedAvg and LSS on CIFAR-10 dataset under label shift with two different model initializations: pre-trained and random. The results show that LSS outperforms FedAvg in both cases, achieving higher accuracy after 1 and 3 communication rounds.  However, the performance gap is more significant when using pre-trained initialization.", "section": "4.2 Performance Comparison"}]