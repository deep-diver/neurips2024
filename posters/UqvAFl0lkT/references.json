{"references": [{"fullname_first_author": "A. P. Badia", "paper_title": "Never give up: Learning directed exploration strategies", "publication_date": "2019", "reason": "This paper proposes Never Give Up, a state-of-the-art exploration algorithm used as a baseline in the current paper's experiments for comparison."}, {"fullname_first_author": "M. Bellemare", "paper_title": "Unifying count-based exploration and intrinsic motivation", "publication_date": "2016", "reason": "This paper introduces a count-based exploration method which is used as a starting point for developing a language-guided exploration method in the current paper."}, {"fullname_first_author": "Y. Burda", "paper_title": "Large-Scale Study of Curiosity-Driven Learning", "publication_date": "2018", "reason": "This paper presents a large-scale study on curiosity-driven learning, which is related to the intrinsic motivation approach used in the current paper."}, {"fullname_first_author": "M. Jaderberg", "paper_title": "Reinforcement learning with unsupervised auxiliary tasks", "publication_date": "2016", "reason": "This paper introduces the UNREAL architecture used in the current paper for combining reinforcement learning with unsupervised auxiliary tasks."}, {"fullname_first_author": "S. Kapturowski", "paper_title": "Recurrent experience replay in distributed reinforcement learning", "publication_date": "2018", "reason": "This paper introduces the R2D2 algorithm, which is used in the current paper's experiments for training RL agents."}]}