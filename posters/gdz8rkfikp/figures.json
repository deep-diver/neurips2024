[{"figure_path": "GDz8rkfikp/figures/figures_2_1.jpg", "caption": "Figure 1: Analysis of the impact of erasing the target concept on the model's capability. The impact is measured by the difference of CLIP score d(c) between the original model and the corresponding sanitized model. 1a: Impact of erasing \"nudity\" or \"garbage truck\" to other concepts. 1b: Comparing the impact of erasing the same \"garbage truck\" to other concepts with different preserving strategies, including preserving a fixed concept such as \"\", \"lexus\", or \"road\", and adaptively preserving the most sensitive concept found by our method.", "description": "This figure analyzes how erasing a target concept from a diffusion model affects the generation of other concepts.  The impact is quantified using the CLIP score difference between the original and sanitized models. Subfigure (a) shows the impact of erasing \"nudity\" and \"garbage truck\", separately. Subfigure (b) compares the effects of erasing \"garbage truck\" while preserving different concepts: a neutral concept (\"\"), a related concept (\"lexus\", \"road\"), and the most sensitive concept (as determined by the proposed method). This illustrates the impact of different preservation strategies on overall model performance.", "section": "3 Problem Statement"}, {"figure_path": "GDz8rkfikp/figures/figures_3_1.jpg", "caption": "Figure 2: Sensitivity spectrum of concepts to the target concept \"nudity\". The histogram shows the distribution of the similarity score between outputs of the original model \u03b8 and the corresponding sanitized model \u03b8' for each concept c from the CLIP tokenizer vocabulary.", "description": "This figure shows a histogram representing the distribution of similarity scores between the outputs of an original diffusion model and a sanitized version of the model after removing the concept of \"nudity\". The x-axis displays the similarity score, and the y-axis represents the frequency of concepts with that similarity score. The histogram illustrates how different concepts are affected differently by the removal of the target concept. The vertical dashed lines highlight the similarity scores for specific concepts (e.g., \"naked\", \"women\", \"men\", \"person\", \"a photo\", \" \"). The figure demonstrates that closely related concepts to the target concept are more significantly impacted by the removal, while less related concepts show a higher similarity score to the original model's output.", "section": "3.2 Impact of Concept Removal on the Model Performance"}, {"figure_path": "GDz8rkfikp/figures/figures_4_1.jpg", "caption": "Figure 1: Analysis of the impact of erasing the target concept on the model's capability. The impact is measured by the difference of CLIP score d(c) between the original model and the corresponding sanitized model. 1a: Impact of erasing \"nudity\" or \"garbage truck\" to other concepts. 1b: Comparing the impact of erasing the same \"garbage truck\" to other concepts with different preserving strategies, including preserving a fixed concept such as \"\", \"lexus\", or \"road\", and adaptively preserving the most sensitive concept found by our method.", "description": "This figure analyzes how erasing a target concept impacts other concepts in a diffusion model.  Part (a) shows the impact of removing either \"nudity\" or \"garbage truck,\" while part (b) compares the effects of removing \"garbage truck\" while preserving different concepts (a neutral concept, specific related concepts, or the most sensitive concept as determined by the proposed method). The impact is quantified using the difference in CLIP scores between the original and modified models for each concept.", "section": "3 Problem Statement"}, {"figure_path": "GDz8rkfikp/figures/figures_5_1.jpg", "caption": "Figure 4: Images generated from the most sensitive concepts found by our method over the fine-tuning process. Top: Continous search with PGD. Bottom: Discrete search with Gumbel-Softmax.  Ca represents for the keyword.", "description": "This figure visualizes the results of the proposed method's adversarial concept search process during fine-tuning.  The top row shows a continuous search using Projected Gradient Descent (PGD), while the bottom row demonstrates a discrete search using Gumbel-Softmax.  Each image represents a concept identified as highly sensitive to changes during the concept erasure process. The keyword, Ca, indicates the concept being represented in the image.", "section": "4 Proposed Method: Adversarial Concept Preservation"}, {"figure_path": "GDz8rkfikp/figures/figures_6_1.jpg", "caption": "Figure 1: Analysis of the impact of erasing the target concept on the model's capability. The impact is measured by the difference of CLIP score d(c) between the original model and the corresponding sanitized model. 1a: Impact of erasing \"nudity\" or \"garbage truck\" to other concepts. 1b: Comparing the impact of erasing the same \"garbage truck\" to other concepts with different preserving strategies, including preserving a fixed concept such as \"\", \"lexus\", or \"road\", and adaptively preserving the most sensitive concept found by our method.", "description": "This figure analyzes how erasing a target concept impacts other concepts in a diffusion model.  Part (a) shows the impact of erasing either \"nudity\" or \"garbage truck,\" illustrating varying effects on related and unrelated concepts. Part (b) compares the impact of erasing \"garbage truck\" while employing different preservation strategies (e.g., preserving a neutral concept or the most affected concept). This highlights the importance of choosing the right concepts to preserve during erasure.", "section": "3 Problem Statement"}, {"figure_path": "GDz8rkfikp/figures/figures_8_1.jpg", "caption": "Figure 5: Comparison of the erasing performance on the I2P dataset. 5a: Number of exposed body parts counted in all generated images with threshold 0.5. 5b: Ratio of images with any exposed body parts detected by the detector Praneet (2019).", "description": "This figure shows a comparison of the erasing performance of different methods on NSFW content using the I2P dataset and the Praneet (2019) nudity detector.  Figure 5a is a stacked bar chart showing the number of different exposed body parts detected in images generated by each method at a threshold of 0.5. Figure 5b is a bar chart showing the percentage of images containing any exposed nudity detected by Praneet (2019) across various threshold levels (0.3-0.8).  The results demonstrate the effectiveness of the proposed method in erasing NSFW content while maintaining the quality of other aspects of generated images.", "section": "5.2 Mitigating Unethical Content"}, {"figure_path": "GDz8rkfikp/figures/figures_19_1.jpg", "caption": "Figure 6: Intermediate results of the search process. Row-1,3,5,7,9: images generated from the most sensitive concepts ca found by our method. Row-2,4,6,8,10: images generated from the corresponding to-be-erased concepts. Each column represents different fine-tuning steps in increasing order.", "description": "This figure visualizes the intermediate results of the adversarial concept search process during the model fine-tuning. The odd rows display images generated using the most sensitive concepts identified by the proposed method, while the even rows show images generated from the concepts targeted for erasure. Each column represents a stage in the fine-tuning process, illustrating how the generated images evolve as the model learns to remove the unwanted concepts.  The figure demonstrates the gradual removal of the target concepts in the even rows and the adaptation of the adversarial concepts in the odd rows.", "section": "B.4 Further Analysis on Searching for Adversarial Concepts"}, {"figure_path": "GDz8rkfikp/figures/figures_20_1.jpg", "caption": "Figure 7: The figure shows the correlation between the drop of the CLIP scores (measured between generated images and their prompts) between the base/original model, and the sanitized model (i.e., removing the target concept \\\"nudity\\\") and the similarity score between the target concept \\\"nudity\\\" and other concepts in the textual embedding space. The radius of the circle indicates the variance of the CLIP scores measured in 200 samples, i.e., the larger circle indicates the larger variance of the CLIP scores.", "description": "This figure displays the correlation between the change in CLIP scores (measuring alignment between generated images and prompts) after removing the \"nudity\" concept and the similarity of other concepts to \"nudity\" in the textual embedding space.  Each point represents a concept, with the top circle showing the original model's CLIP score and the bottom circle showing the score after removing \"nudity\".  The radius of each circle indicates score variance, and the vertical lines connect the original and sanitized scores for each concept. This helps visualize which concepts are most affected (sensitive) by removing \"nudity\".", "section": "B.5 Difficulties in Searching for Adversarial Concepts"}, {"figure_path": "GDz8rkfikp/figures/figures_22_1.jpg", "caption": "Figure 8: Generated images from the original model. Five first rows are to-be-erased objects (marked by red text) and the rest are to-be-preserved objects. Each column represents different random seeds.", "description": "This figure shows images generated from the original Stable Diffusion model before any concept erasure.  The top five rows represent the object classes that will be targeted for removal in later experiments, while the remaining rows display classes that should remain unaffected by the erasure process. Each column uses a different random seed to illustrate the model's variability in generating images for the same prompts.", "section": "5.1 Erasing Concepts Related to Physical Objects"}, {"figure_path": "GDz8rkfikp/figures/figures_23_1.jpg", "caption": "Figure 8: Generated images from the original model. Five first rows are to-be-erased objects (marked by red text) and the rest are to-be-preserved objects. Each column represents different random seeds.", "description": "This figure shows images generated from the original Stable Diffusion model before any concept erasure.  The top five rows display examples of the 'to-be-erased' object categories (marked in red), while the remaining rows show examples of the 'to-be-preserved' object categories. Each column shows the results obtained using different random seeds, illustrating the model's ability to generate a variety of images within each category before any modifications are made.", "section": "Qualitative Results"}, {"figure_path": "GDz8rkfikp/figures/figures_24_1.jpg", "caption": "Figure 1: Analysis of the impact of erasing the target concept on the model's capability. The impact is measured by the difference of CLIP score d(c) between the original model and the corresponding sanitized model. 1a: Impact of erasing \"nudity\" or \"garbage truck\" to other concepts. 1b: Comparing the impact of erasing the same \"garbage truck\" to other concepts with different preserving strategies, including preserving a fixed concept such as \"\", \"lexus\", or \"road\", and adaptively preserving the most sensitive concept found by our method.", "description": "This figure analyzes how erasing a target concept from a diffusion model affects the generation of other concepts.  The left subfigure (1a) shows the impact of removing either the concept of \"nudity\" or \"garbage truck\" on various other concepts, measured by the change in CLIP scores. The right subfigure (1b) compares different preservation strategies when erasing \"garbage truck\".  Strategies include using a neutral concept (\"\"), a related concept (\"lexus\", \"road\"), or an adaptively chosen most sensitive concept as determined by the proposed method.", "section": "3 Problem Statement"}, {"figure_path": "GDz8rkfikp/figures/figures_25_1.jpg", "caption": "Figure 8: Generated images from the original model. Five first rows are to-be-erased objects (marked by red text) and the rest are to-be-preserved objects. Each column represents different random seeds.", "description": "This figure shows the image generation results from the original Stable Diffusion model before any concept erasure. The top five rows represent the \"to-be-erased\" concepts, and the remaining rows show the \"to-be-preserved\" concepts. Each column displays results for different random seeds, showcasing the model's ability to generate diverse images across various concepts.", "section": "5.1 Erasing Concepts Related to Physical Objects"}, {"figure_path": "GDz8rkfikp/figures/figures_26_1.jpg", "caption": "Figure 12: Erasing artistic style concepts. Each column represents the erasure of a specific artist, except the first column which represents the generated images from the original SD model. Each row represents the generated images from the same prompt but with different artists. The ideal erasure should result in a change in the diagonal pictures (marked by a red box) compared to the first column, while the off-diagonal pictures should remain the same. row-1: Portrait of a woman with floral crown by Kelly McKernan; row-2: Ajin: Demi Human character portrait; row-3: Neon-lit cyberpunk cityscape by Kilian Eng; row-4: A Thomas Kinkade-inspired painting of a peaceful countryside; row-5: Tyler Edlin-inspired artwork of a mystical forest;", "description": "The figure shows the results of erasing artistic style concepts using four different methods: the authors' proposed method, ESD, UCE, and CA. Each column represents a different artist whose style is to be removed, while each row shows the same prompt used to generate images. In the ideal scenario, only the diagonal images (marked by red boxes) would change significantly, indicating that only the targeted artist's style has been removed, while others remain consistent.", "section": "C Qualitative Results"}, {"figure_path": "GDz8rkfikp/figures/figures_27_1.jpg", "caption": "Figure 12: Erasing artistic style concepts. Each column represents the erasure of a specific artist, except the first column which represents the generated images from the original SD model. Each row represents the generated images from the same prompt but with different artists. The ideal erasure should result in a change in the diagonal pictures (marked by a red box) compared to the first column, while the off-diagonal pictures should remain the same. row-1: Portrait of a woman with floral crown by Kelly McKernan; row-2: Ajin: Demi Human character portrait; row-3: Neon-lit cyberpunk cityscape by Kilian Eng; row-4: A Thomas Kinkade-inspired painting of a peaceful countryside; row-5: Tyler Edlin-inspired artwork of a mystical forest;", "description": "This figure shows the qualitative results of erasing artistic style concepts from the Stable Diffusion model using four different methods: the proposed method, ESD, UCE, and CA. Each column represents a different artist whose style is to be erased. Each row represents the same prompt but with different artists. The diagonal images (in red boxes) are expected to change significantly due to the erasure of the artist's style, while the non-diagonal images should remain similar to the original SD model's output. This visualization helps to evaluate the effectiveness of each method in removing the specified styles while preserving other aspects of the generated images.", "section": "Qualitative Results"}, {"figure_path": "GDz8rkfikp/figures/figures_28_1.jpg", "caption": "Figure 12: Erasing artistic style concepts. Each column represents the erasure of a specific artist, except the first column which represents the generated images from the original SD model. Each row represents the generated images from the same prompt but with different artists. The ideal erasure should result in a change in the diagonal pictures (marked by a red box) compared to the first column, while the off-diagonal pictures should remain the same. row-1: Portrait of a woman with floral crown by Kelly McKernan; row-2: Ajin: Demi Human character portrait; row-3: Neon-lit cyberpunk cityscape by Kilian Eng; row-4: A Thomas Kinkade-inspired painting of a peaceful countryside; row-5: Tyler Edlin-inspired artwork of a mystical forest;", "description": "This figure shows a qualitative comparison of the proposed method against three baselines for erasing artistic style concepts. Each column represents a different artist whose style is being removed. The first column shows the original model's output, while the subsequent columns demonstrate the results of the proposed method and the baselines.  The diagonal elements (red boxes) highlight the expected changes where the target artist's style should be removed. The off-diagonal elements showcase how well other artistic styles are preserved.", "section": "Qualitative Results"}]