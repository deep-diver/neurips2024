[{"figure_path": "wkwGedn19x/tables/tables_6_1.jpg", "caption": "Table 1: Top-1 accuracy of CRATE-a on ImageNet-1K with different model scales when pre-trained on ImageNet-21K and then fine-tuned on ImageNet-1K. For comparison, we also list the results from the paper [46] which demonstrate the diminished return from CRATE base to large, trained only on ImageNet-1K. \"IN-21K\" refers to ImageNet-21K.  ($Results from [46].) ", "description": "This table presents the top-1 accuracy of the CRATE-a model on the ImageNet-1K dataset for various model sizes (Base and Large).  The models were pre-trained on ImageNet-21K before fine-tuning on ImageNet-1K.  The table also includes results from the original CRATE paper [46] for comparison, highlighting the improved scalability of CRATE-a.", "section": "4.2 Training and Fine-tuning Procedures"}, {"figure_path": "wkwGedn19x/tables/tables_8_1.jpg", "caption": "Table 2: The performance comparison between CRATE and CRATE-a across various datasets.", "description": "This table compares the performance of the original CRATE model and the improved CRATE-\u03b1 model on four different datasets: CIFAR-10, CIFAR-100, Oxford Flowers-102, and Oxford-IIIT-Pets.  It shows the top-1 accuracy achieved by each model variant (different model sizes and patch sizes) on each dataset, highlighting the performance improvement of CRATE-\u03b1 over the original CRATE model.", "section": "Downstream Applications"}, {"figure_path": "wkwGedn19x/tables/tables_8_2.jpg", "caption": "Table 3: Performance comparison of CRATE models with different configurations.", "description": "This table compares the performance of different CRATE models on a segmentation task.  The models vary in their configurations, and the table shows the mean Intersection over Union (mIoU), mean Accuracy (mAcc), and average Accuracy (aAcc) achieved by each model.  It highlights the impact of model configuration on performance.", "section": "Downstream Applications"}, {"figure_path": "wkwGedn19x/tables/tables_8_3.jpg", "caption": "Table 4: The comparison between CRATE and CRATE-a on the NLP task using the OpenWebText dataset.", "description": "This table compares the performance of GPT-2-base, CRATE-base, CRATE-a-small, and CRATE-a-base models on the NLP task using the OpenWebText dataset.  The comparison is based on the cross-entropy validation loss, which is a measure of how well the model predicts the next word in a sequence.  Lower cross-entropy loss indicates better performance.", "section": "4.2 Training and Fine-tuning Procedures"}, {"figure_path": "wkwGedn19x/tables/tables_8_4.jpg", "caption": "Table 1: Top-1 accuracy of CRATE-a on ImageNet-1K with different model scales when pre-trained on ImageNet-21K and then fine-tuned on ImageNet-1K. For comparison, we also list the results from the paper [46] which demonstrate the diminished return from CRATE base to large, trained only on ImageNet-1K. \"IN-21K\" refers to ImageNet-21K. (*Results from [46].) ", "description": "This table presents a comparison of the Top-1 accuracy achieved by different sized CRATE-a models on the ImageNet-1K dataset.  The models were pre-trained on ImageNet-21K and then fine-tuned on ImageNet-1K.  Results from the original CRATE paper are also included for comparison, highlighting the improved scalability of the CRATE-a architecture.", "section": "4.2 Training and Fine-tuning Procedures"}, {"figure_path": "wkwGedn19x/tables/tables_9_1.jpg", "caption": "Table 6: Object detection and fine-grained segmentation via MaskCut on COCO val2017 [20]. We evaluate models of various scales and assess their average precision using COCO's official evaluation metric. Compared with existing models such as CRATE and ViT, CRATE-a model achieves a notable performance gain. In addition, when scaling CRATE-a from base to large, it also exhibits the benefit of scalability.", "description": "This table presents the results of object detection and fine-grained segmentation using MaskCut on the COCO val2017 dataset.  It compares the performance of CRATE-a models of different sizes (base and large) against CRATE and ViT models, showcasing CRATE-a's superior performance and scalability in both detection and segmentation tasks. The metrics used are average precision (AP) at different IoU thresholds (AP50 and AP75) and overall AP.", "section": "4.3 Results and Analysis"}, {"figure_path": "wkwGedn19x/tables/tables_14_1.jpg", "caption": "Table 7: Model configurations for different sizes of CRATE-a, parameter counts, and comparisons to CRATE models. L is depth, d is the hidden size, and K is the number of heads.", "description": "This table details the configurations of CRATE-a models of varying sizes (Tiny, Small, Base, Large, Huge).  For each model size, it lists the depth (L), hidden size (d), number of heads (K), the number of parameters in the CRATE-\u03b1 model, and the number of parameters in the original CRATE model for comparison.  This allows for a direct comparison of the model complexity between the improved CRATE-\u03b1 architecture and the original CRATE architecture across different scales.", "section": "A.1 Model configuration"}, {"figure_path": "wkwGedn19x/tables/tables_14_2.jpg", "caption": "Table 8: The comparison between CRATE-a and ViT. FLOPs and throughput are calculated based on an input size of 224x224 on an NVIDIA RTX A6000 graphics card.", "description": "This table compares the performance of CRATE-a and ViT models with different sizes.  It shows the FLOPs (floating point operations), the number of parameters, and the throughput (images processed per second) for each model. The comparison helps to illustrate the computational efficiency and speed of CRATE-a relative to ViT.", "section": "A.2 Comparison of model structure with ViT"}, {"figure_path": "wkwGedn19x/tables/tables_15_1.jpg", "caption": "Table 1: Top-1 accuracy of CRATE-a on ImageNet-1K with different model scales when pre-trained on ImageNet-21K and then fine-tuned on ImageNet-1K. For comparison, we also list the results from the paper [46] which demonstrate the diminished return from CRATE base to large, trained only on ImageNet-1K. \"IN-21K\" refers to ImageNet-21K.  ($Results from [46].) ", "description": "This table presents the ImageNet-1K Top-1 accuracy for various CRATE-a models with different sizes (Base and Large), trained using two different training strategies: pre-training on ImageNet-21K then fine-tuning on ImageNet-1K, and only training on ImageNet-1K (results from a previous study [46]). It demonstrates that CRATE-a models trained with ImageNet-21K pre-training significantly outperform those trained solely on ImageNet-1K, highlighting the improved scalability and performance of the CRATE-a architecture.", "section": "4.1 Dataset and Evaluation"}]