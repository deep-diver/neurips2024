[{"figure_path": "AWFryOJaGi/figures/figures_1_1.jpg", "caption": "Figure 1: Examples of dangling entities.", "description": "This figure illustrates the concept of dangling entities in entity alignment.  Two knowledge graphs (KGs) are shown, represented by circles. Red nodes represent entities in the source KG, and blue nodes represent entities in the target KG.  The overlapping area shows entities that have matches in both KGs (matchable entities).  The nodes outside of the overlapping area are entities that only appear in one KG, which are the dangling entities. The arrows show connections (relationships) between entities within each KG.  Dangling entities present a challenge for entity alignment because they lack corresponding entities in the other KG.", "section": "1 Introduction"}, {"figure_path": "AWFryOJaGi/figures/figures_1_2.jpg", "caption": "Figure 2: The illustration of our framework.", "description": "This figure illustrates the LAMBDA framework for entity alignment with unlabeled dangling cases.  It shows the two main phases: dangling detection and entity alignment. Both phases utilize a GNN-based encoder (KEESA) with spectral contrastive learning. The dangling detection phase incorporates an iterative positive-unlabeled learning algorithm (iPULE) to estimate the proportion of matchable entities and identify them.  The framework uses a gating mechanism to integrate intra-graph and cross-graph representations for entity alignment.  If the proportion of matchable entities is too low, the alignment phase is skipped.", "section": "3 Selective Aggregation with Spectral Contrastive Learning"}, {"figure_path": "AWFryOJaGi/figures/figures_2_1.jpg", "caption": "Figure 2: The illustration of our framework.", "description": "This figure illustrates the LAMBDA framework for entity alignment with unlabeled dangling cases. It shows the two main phases: dangling detection and entity alignment. Both phases share a GNN-based encoder (KEESA) with a spectral contrastive learning loss. The dangling detection module uses an iterative positive-unlabeled learning algorithm (iPULE) to estimate the proportion of matchable entities and identify them.  The entity alignment module uses the KEESA encoder and spectral contrastive learning loss to align matchable entities. The framework also includes modules for adaptive dangling indication, relation projection attention, and selective aggregation to handle dangling entities effectively.", "section": "2 Preliminaries and Related Work"}, {"figure_path": "AWFryOJaGi/figures/figures_7_1.jpg", "caption": "Figure 3: Prior estimation GA-DBP15K and DBP2.0. (loss convergence in appendix F).", "description": "This figure shows the results of prior estimation and convergence for the GA-DBP15K and DBP2.0 datasets.  The top row displays the prior estimation for the GA-DBP15K dataset with different pre-aligned percentages (10%, 15%, 20%, 25%), showing the estimated class prior gradually approaching the true value. The bottom row displays the same for the DBP2.0 dataset, illustrating how the estimated class prior converges to the true value.  The plots demonstrate the effectiveness of the iterative positive-unlabeled (PU) learning algorithm in estimating the class prior and achieving convergence.", "section": "5.1 Experiments of iPULE Convergence and Class Prior Estimation"}, {"figure_path": "AWFryOJaGi/figures/figures_8_1.jpg", "caption": "Figure 4: Visualization of entity representations learned by our method on GA16K dataset.", "description": "This figure visualizes the entity representations learned by the proposed method, LAMBDA, on the GA16K dataset.  It shows the embedding space for the entities, differentiating between matchable entities (red and green) and dangling entities (blue). The visualization helps illustrate how LAMBDA effectively separates matchable and dangling entities in the embedding space, which is crucial for accurate entity alignment.", "section": "5 Experiments"}, {"figure_path": "AWFryOJaGi/figures/figures_9_1.jpg", "caption": "Figure 5: The ablation study of entity alignment performance in the consolidated setting on DBP2.0.", "description": "This figure presents the results of ablation studies conducted on the DBP2.0 dataset to evaluate the impact of the adaptive dangling indicator and relation projection attention mechanisms on the entity alignment performance. The ablation studies involved removing the adaptive dangling indicator (w/o re;), replacing the relation embedding (w/o hrk), and using the complete model (Ours).  The results are shown separately for Hits@1, Precision, Recall, and F1-score across different language pairs (ZH-EN, EN-ZH, JA-EN, EN-JA, FR-EN, EN-FR). This allows for a detailed analysis of the contribution of each component in improving the overall alignment performance in scenarios with unlabeled dangling entities. The consolidated setting means the evaluation was performed considering both matchable and dangling entities.", "section": "5.4 Ablation Studies and Varying Anchor Nodes"}, {"figure_path": "AWFryOJaGi/figures/figures_9_2.jpg", "caption": "Figure 6: The entity alignment performance on varying pre-aligned anchor nodes ratios on DBP2.0.", "description": "This figure shows how the entity alignment performance on the DBP2.0 dataset changes with varying pre-aligned anchor node ratios.  The x-axis represents the anchor ratio (proportion of pre-aligned nodes), while the y-axis displays the performance metrics Hits@1, Precision, Recall, and F1-score. Different lines represent the performance for different language pairs (ZH-EN, EN-ZH, JA-EN, EN-JA, FR-EN, EN-FR). The results show that as the anchor ratio increases, the alignment performance generally improves for all language pairs, indicating the importance of having sufficient pre-aligned entities for effective alignment.", "section": "5.4 Ablation Studies and Varying Anchor Nodes"}, {"figure_path": "AWFryOJaGi/figures/figures_22_1.jpg", "caption": "Figure 7: Visualization of loss convergence on DBP2.0 and GA-DBP15K.", "description": "This figure visualizes the loss convergence during the training process of the proposed iPULE algorithm on the DBP2.0 and GA-DBP15K datasets.  The plots show the mean and variance of the loss across multiple runs, with different colors representing different language pairs. The x-axis represents the training epoch, and the y-axis represents the loss value.  The figure helps demonstrate the stability and convergence behavior of the iPULE algorithm for different datasets and language pairs.  The histograms show the distribution of loss differences for each language pair, providing insight into the speed of convergence and the consistency of the algorithm's performance.", "section": "5.1 Experiments of iPULE Convergence and Class Prior Estimation"}]