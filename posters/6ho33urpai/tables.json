[{"figure_path": "6HO33urpaI/tables/tables_4_1.jpg", "caption": "Table 1: The summary of our results on each task category in CLRS. The best-performing results in each row are highlighted in bold. To save space, we use the column \"Prior Best\" to denote the best results among four existing approaches: Memnet [26], PGN [26], MPNN [26], and NPQ [12], and the column \"Ours\" to denote the best results achieved by applying the open-book framework to the three existing architectures.", "description": "This table summarizes the performance of the proposed open-book framework on the CLRS benchmark.  It compares the best results obtained by three existing architectures (after incorporating the open-book framework) against the previous state-of-the-art results from four other methods (Memnet, PGN, MPNN, and NPQ). The results are grouped by task category within the benchmark and show significant improvements using the open-book method.", "section": "4 Experiments"}, {"figure_path": "6HO33urpaI/tables/tables_6_1.jpg", "caption": "Table 1: The summary of our results on each task category in CLRS. The best-performing results in each row are highlighted in bold. To save space, we use the column \"Prior Best\" to denote the best results among four existing approaches: Memnet [26], PGN [26], MPNN [26], and NPQ [12], and the column \"Ours\" to denote the best results achieved by applying the open-book framework to the three existing architectures.", "description": "This table summarizes the performance of the proposed open-book framework on the CLRS benchmark across different task categories. It compares the best results achieved by three existing architectures (with the open-book framework applied) against the best results from four previous state-of-the-art methods (Memnet, PGN, MPNN, and NPQ).  The \"Prior Best\" column shows the best previously reported results, while the \"Ours\" column shows the best results obtained using the open-book method.", "section": "4 Experiments"}, {"figure_path": "6HO33urpaI/tables/tables_8_1.jpg", "caption": "Table 2: For each target (task), we show the task with the highest attention weight among other tasks in column \u201cAuxiliary\u201d. We use bold text to indicate when the paired tasks belong to the same algorithmic category.", "description": "This table presents the results of a multi-task interpretation experiment. For each algorithmic task in the CLRS benchmark, the table shows the task from other categories that had the highest attention weight when solving the target task using the open-book framework.  This highlights which other tasks were most influential in the open-book processor when solving each specific task. The use of bold text indicates when the most influential task belonged to the same category as the target task.", "section": "4.4 Multi-Task Interpretation"}, {"figure_path": "6HO33urpaI/tables/tables_8_2.jpg", "caption": "Table 1: The summary of our results on each task category in CLRS. The best-performing results in each row are highlighted in bold. To save space, we use the column \"Prior Best\" to denote the best results among four existing approaches: Memnet [26], PGN [26], MPNN [26], and NPQ [12], and the column \"Ours\" to denote the best results achieved by applying the open-book framework to the three existing architectures.", "description": "This table summarizes the performance of the open-book framework on the CLRS benchmark, comparing it to prior state-of-the-art methods. It shows the best performance achieved by each of the three architectures used in the paper (Triplet-GMPNN, PGN, and MPNN) after incorporating the open-book framework, categorized by task type (Graphs, Geometry, Strings, Dynamic Programming, Divide and Conquer, Greedy, Search, Sorting). The results highlight the effectiveness of the open-book approach across diverse algorithmic tasks.", "section": "4.2 Single-Task Augmenting"}]