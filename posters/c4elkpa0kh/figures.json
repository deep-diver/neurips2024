[{"figure_path": "c4ElkpA0kh/figures/figures_2_1.jpg", "caption": "Figure 1: An example of a tree-form decision problem. Decision points are black squares with white text labels; observation points are white squares. Edges are labeled with action names, which are numbers. Pure strategies in this decision problem are identified with vectors x = (x1, x2, x3, x4, x5) \u2208 {0,1}5 satisfying \u22115i=1 xi = 1.", "description": "This figure shows a simple example of a tree-form decision problem.  Decision nodes, where the player chooses an action, are represented by black squares, while observation nodes, where the environment makes a choice, are white squares. Each edge is labeled with the action that leads to the next node. The leaves of the tree represent the terminal nodes of the decision process. The pure strategies for the player are represented by binary vectors where each element corresponds to a terminal node and indicates whether the path leading to that node is chosen by the player (1) or not (0). In this example, a player must choose exactly one terminal node.  This constraint is expressed mathematically as the sum of the vector elements equals 1.", "section": "2.1 Tree-form decision problems"}, {"figure_path": "c4ElkpA0kh/figures/figures_20_1.jpg", "caption": "Figure 2: A representation of the deviation (x) = (x1 + x3, x2x4, x2x5, x2, 0) (discussed in Appendix C.2) in the decision problem X in Figure 1, as a strategy in X X & X, i.e., with k = 2 mediators. (For an example of a one-mediator deviation, see Zhang et al. [2024, Figure 1].) Again, black squares are decision nodes and white squares are observation nodes. Nodes are labeled with their state representations: the state in X first (in blue), and the two mediator states after (in red). Similarly, blue edge labels indicate interactions with the decision problem (i.e., playing actions and receiving observations in X), and red edge labels indicate interactions with the mediators (i.e., querying and receiving action recommendations from the mediators). Redundant edges (such as those in which the decision problem in X has terminated) are omitted. The deviation is shown in thick black lines. For example, $2(x) = x2x4 because the only state in which the deviator plays action 2 is when the mediator state is (2,4). $1(x) = x1 + x3 because the deviator plays action 1 at mediator states (1,1) and (3,0), which would give the formula $1(x) = x + x3x0 (where x0 := 1 \u2013 x1), but one can easily check that x + x3x0 = x1 + x3 for all x \u2208 X.", "description": "This figure illustrates a depth-2 decision tree deviation with two mediators.  The deviation is represented as a strategy in the combined decision problem X\u2297X\u2297X. Nodes are colored and labeled to show the state in the original problem X (blue) and the two mediators' states (red). Edges show actions and observations. Thick lines highlight the deviation's path.", "section": "E.1 Interleaving decision problems"}]