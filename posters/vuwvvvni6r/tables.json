[{"figure_path": "VUWvVvNi6r/tables/tables_6_1.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the performance comparison between RPC-SymViT and SymViT models on ImageNet-1K dataset and its corrupted versions for image classification. It shows the top-1 and top-5 accuracy, mean corruption error, and AUPR. The RPC-SymViT model applies the Principal Attention Pursuit (PAP) algorithm with varying numbers of iterations (niter) either only to the first layer or all layers of the model.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_7_1.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the performance comparison between RPC-SymViT and SymViT models on ImageNet-1K dataset and its corruptions (ImageNet-C, ImageNet-A, ImageNet-O, ImageNet-R).  It shows Top-1 and Top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR).  Different versions of RPC-SymViT are evaluated, varying the number of PAP iterations applied to either only the first layer or all layers. SymViT serves as the baseline model.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_7_2.jpg", "caption": "Table 2: Top-1/5 accuracy (%) on attacked ImageNet-1K data. RPC-SymViT (niter/layer1) applies n PAP iterations at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the top-1 and top-5 accuracy results of different models on the ImageNet-1K dataset after being attacked by various methods.  It compares the baseline SymViT model against several variations of the RPC-SymViT model, which incorporates the proposed robust principal component analysis (RPC) based attention mechanism. The variations differ in the number of PAP (Principal Attention Pursuit) iterations applied (either to only the first layer or all layers) and the number of iterations. The attacks used include PGD, FGSM, SPSA, SLD, CW, noise, and AutoAttack, representing diverse attack strategies.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_8_1.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents a comparison of the performance of RPC-SymViT and SymViT models on the ImageNet-1K dataset and several standard robustness benchmarks.  The metrics used are Top-1 and Top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR).  Different configurations of RPC-SymViT are tested, varying the number of PAP iterations applied either to only the first layer or all layers. The baseline model is SymViT.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_21_1.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents a comparison of the performance of RPC-SymViT and SymViT models on ImageNet-1K dataset and its variations (ImageNet-C, ImageNet-R, ImageNet-A, and ImageNet-O) used for evaluating robustness of models against corruptions and distribution shifts.  It shows top-1 and top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR).  Different versions of RPC-SymViT are tested, applying the proposed robust principal component analysis (RPC)-based attention mechanism to either only the first layer or all layers of the model.  The baseline model is SymViT, a standard Vision Transformer model without RPC-Attention.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_23_1.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents a comparison of the performance of RPC-SymViT and SymViT models on the ImageNet-1K dataset and several standard robustness benchmarks for image classification.  The models are evaluated on their top-1 and top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR).  The table also shows the effect of applying different numbers of PAP iterations to either only the first layer or all layers of the RPC-SymViT model.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_23_2.jpg", "caption": "Table 5: Top-1 and Top-5 accuracy (%) of RPC-SymViT(6iter/layer1) and baseline SymViT on square attacked ImageNet-1K validation data. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer.", "description": "This table presents the results of square attack on ImageNet-1K validation set. The top-1 and top-5 accuracy are reported for both baseline SymViT and RPC-SymViT model with 6 PAP iterations applied only to the first layer.  The table shows that RPC-SymViT outperforms the baseline SymViT demonstrating its improved robustness against this adversarial attack.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_24_1.jpg", "caption": "Table 6: Mean accuracy (%) and mean Intersection-Over-Union (IOU) of RPC-SymViT and SymViT on clean ADE20K and corrupted ADE20K dataset. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the performance of the RPC-SymViT model and the baseline SymViT model on the ADE20K image segmentation task.  It shows the mean accuracy and mean Intersection over Union (IOU) for both clean and corrupted data. Different configurations of RPC-SymViT (varying the number of PAP iterations and the layers they are applied to) are compared.", "section": "4.2 Language Tasks: WikiText-103 Language Modeling"}, {"figure_path": "VUWvVvNi6r/tables/tables_24_2.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the performance of RPC-SymViT and SymViT models on ImageNet-1K dataset and its corrupted versions (ImageNet-C, ImageNet-A, ImageNet-O, ImageNet-R).  The metrics used are Top-1 accuracy, Top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR).  Different configurations of RPC-SymViT are tested, varying the number of PAP iterations applied (either only to the first layer or all layers).  The results show the impact of applying the robust principal component analysis (RPC) method on the robustness of the models against various corruptions and perturbations.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_24_3.jpg", "caption": "Table 8: Top-1 and top-5 accuracy (%) of RPC-SymViT-base and SymViT-base on PGD and FGSM attacked ImageNet-1K validation data with the highest perturbation budget. RPC-SymViT-base (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the top-1 and top-5 accuracy of two models, RPC-SymViT-base and SymViT-base, when evaluated on the ImageNet-1K dataset under PGD and FGSM attacks.  The attacks use the highest perturbation budget.  RPC-SymViT-base incorporates the proposed Robust Principal Component Attention (RPC-Attention) method, and SymViT-base serves as a baseline without this method.  The results highlight the improved robustness of RPC-SymViT-base against these adversarial attacks.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_25_1.jpg", "caption": "Table 9: Top-1, top-5 accuracy (%) of RPC-FAN-tiny and FAN-tiny on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-FAN-tiny (niter/layer1) applies n PAP iterations only at the first layer.", "description": "This table presents the performance comparison between RPC-FAN-tiny and FAN-tiny models on ImageNet-1K dataset and its variations (IN-R, IN-A). RPC-FAN-tiny is the proposed model in the paper that uses Robust Principal Component Analysis (RPCA) to improve the robustness of self-attention. The table shows that RPC-FAN-tiny outperforms FAN-tiny in terms of Top-1 and Top-5 accuracy on all datasets. This demonstrates the effectiveness of RPC-Attention in enhancing the model robustness.", "section": "4 Experimental Results"}, {"figure_path": "VUWvVvNi6r/tables/tables_25_2.jpg", "caption": "Table 10: Top-1 and top-5 accuracy (%) of RPC-FAN-tiny and FAN-tiny on PGD and FGSM attacked ImageNet-1K validation data with the highest perturbation budget. RPC-FAN-ViT (niter/layer1) applies n PAP iterations only at the first layer.", "description": "This table presents the top-1 and top-5 accuracy of two models, FAN-tiny (baseline) and RPC-FAN-tiny (4iter/layer1), evaluated on the ImageNet-1K dataset under PGD and FGSM attacks.  The highest perturbation budget was used for the attacks. The RPC-FAN-tiny model incorporates the Robust Principal Component Attention (RPC-Attention) method, applying the Principal Attention Pursuit (PAP) algorithm 4 times in the first layer. The results show how the RPC-Attention method improves the model's robustness against adversarial attacks.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_25_3.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the performance comparison between RPC-SymViT and SymViT models on ImageNet-1K dataset and its corruptions (ImageNet-C, ImageNet-A, ImageNet-O, ImageNet-R).  The metrics used are Top-1 accuracy, Top-5 accuracy, mean corruption error, and area under the precision-recall curve.  Different configurations of RPC-SymViT are evaluated, varying the number of PAP iterations and whether they are applied to only the first layer or all layers.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_25_4.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the performance comparison between RPC-SymViT and SymViT models on ImageNet-1K dataset and its corrupted versions (ImageNet-C, ImageNet-A, ImageNet-O, and ImageNet-R).  The metrics used are Top-1 and Top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR).  RPC-SymViT is a variant of SymViT that incorporates the Robust Principal Component Pursuit (RPC) algorithm. Two variations are presented, applying the RPC algorithm either to only the first layer or to all layers of the model. The results show that RPC-SymViT generally outperforms SymViT, especially on the corrupted datasets, indicating its improved robustness.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_26_1.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents the performance comparison between RPC-SymViT and SymViT models on ImageNet-1K dataset and its various corrupted versions.  It shows the top-1 and top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR) for both models under different settings (number of PAP iterations applied to either only the first layer or all layers). The results are categorized by the type of corruption (brightness, contrast, etc.) and presented to demonstrate the robustness of the RPC-SymViT model compared to the baseline SymViT.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}, {"figure_path": "VUWvVvNi6r/tables/tables_26_2.jpg", "caption": "Table 1: Top-1, Top-5 accuracy (%), mean corruption error (mCE), and area under the precision-recall curve (AUPR) of RPC-SymViT and SymViT on clean ImageNet-1K data and popular standard robustness benchmarks for image classification. RPC-SymViT (niter/layer1) applies n PAP iterations only at the first layer. RPC-SymViT (niter/all-layer) applies n PAP iterations at all layers.", "description": "This table presents a comparison of the performance of RPC-SymViT and SymViT models on the ImageNet-1K dataset and several standard robustness benchmarks for image classification.  It shows Top-1 and Top-5 accuracy, mean corruption error (mCE), and area under the precision-recall curve (AUPR) for both models under various conditions.  The RPC-SymViT model is a variant of the SymViT model that incorporates the proposed robust principal component attention mechanism.  The results indicate the performance gain from incorporating this method, particularly on the more challenging robustness benchmarks.", "section": "4.1 Vision Tasks: ImageNet-1K Object Classification"}]