[{"type": "text", "text": "Discrete Dictionary-based Decomposition Layer for Structured Representation Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Taewon Park1 Hyun-Chul Kim1 Minho Lee1,2 ", "page_idx": 0}, {"type": "text", "text": "1Kyungpook National University, South Korea 2ALI Co., Ltd., South Korea ptw7998@gmail.com, hyunchul_kim@knu.ac.kr, mholee@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Neuro-symbolic neural networks have been extensively studied to integrate symbolic operations with neural networks, thereby improving systematic generalization. Specifically, Tensor Product Representation (TPR) framework enables neural networks to perform differentiable symbolic operations by encoding the symbolic structure of data within vector spaces. However, TPR-based neural networks often struggle to decompose unseen data into structured TPR representations, undermining their symbolic operations. To address this decomposition problem, we propose a Discrete Dictionary-based Decomposition (D3) layer designed to enhance the decomposition capabilities of TPR-based models. D3 employs discrete, learnable key-value dictionaries trained to capture symbolic features essential for decomposition operations. It leverages the prior knowledge acquired during training to generate structured TPR representations by mapping input data to pre-learned discrete features within these dictionaries. D3 is a straightforward drop-in layer that can be seamlessly integrated into any TPR-based model without modifications. Our experimental results demonstrate that D3 significantly improves the systematic generalization of various TPR-based models while requiring fewer additional parameters. Notably, D3 outperforms baseline models on the synthetic task that demands the systematic decomposition of unseen combinatorial data.1 ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Compositional generalization, aiming at understanding unseen data by combining known concepts, is essential for neural networks to handle complex tasks [2, 13, 12, 16, 8, 6]. Tensor Product Representation (TPR) framework [33] facilitates this by embedding the symbolic structure of data within vector spaces, providing neural networks with compositional capabilities. Within this framework, individual objects are decomposed at the representation level into distinct symbolic components called role-fliler pairs2. The TPR framework encodes each object by taking a tensor product of its role vector and filler vector, represented as $T=f i l l e r\\otimes r o l e$ , and then superimposes them to represent multiple objects within a single representation. During decoding, the TPR framework retrieves specific flilers\u2014essential for solving tasks\u2014from the superimposed representation through matrix multiplication using an unbinding operator correlated to a particular role, $f i l l e r=T\\cdot u n b i n d.$ . This retrieved filler is then utilized in downstream tasks. Based on this property, TPR-based neural networks have demonstrated significant generalization and applicability in fields such as associative reasoning [28, 30], mathematical problem-solving [29], and natural language processing [9, 32, 21, 34]. ", "page_idx": 0}, {"type": "image", "img_path": "NJUClFbosX/tmp/f0fbc0c07dc1324c9d3c90f506c757f88aea97403baa2358b9737f6aae4f634b.jpg", "img_caption": ["Figure 1: Overview of D3. D3 generates structured TPR representations by mapping input data to the nearest pre-learned symbolic features stored within discrete, learnable dictionaries. Each dictionary is linked explicitly to specific TPR components, such as roles, fliler, and unbinding operators. Notably, D3 uses a shared dictionary configuration between the roles and unbinding operators. This figure illustrates, for example, that $r o l e_{1}$ and unbind1 share one dictionary, while $r o l e_{2}$ and unbind2 share another. $T$ denotes a superimposed representation that represents multiple objects. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Despite their successes, the TPR-based approaches pose a significant challenge known as a decomposition problem [33, 23], which refers to the difficulty of decomposing input data into TPR components, such as roles, flilers, and unbinding operators. Without accurate decomposition, TPR-based models fail to represent the symbolic structure of data, causing a decline in the performance of the TPR operations. Recently, inspired by an object-centric learning method [18], Park et al. [23] proposes an attention-based iterative decomposition (AID) module to address this issue. AID uses competitive attention to iteratively refine structured representations, thereby enhancing the systematic generalization of TPR-based models. However, it still struggles to generalize all possible combinations of known symbols in simple synthetic tasks. This failure is likely attributable to its insufficient mechanism for explicitly mapping input data to known symbolic features observed during training. Therefore, the decomposition module may need an additional mechanism to store observed symbolic features during training and utilize it to effectively decompose unseen combinatorial data of known symbols. ", "page_idx": 1}, {"type": "text", "text": "In another line of work, discrete representation learning has been explored to improve the efficiency, interpretability, and generalization capabilities of neural networks [39, 14, 17, 37, 7]. This approach involves mapping continuous input data into discrete representations by finding the nearest features in a predefined codebook. The features within the codebook are learnable parameters, specifically trained to capture the latent features of data during training phase [39]. Some researchers have applied discrete representation techniques to extract specific types of representations from unstructured data [11, 43, 44]. Other researchers have integrated discrete symbolic embeddings within the TPR framework to improve its interpretability [21, 9]. However, these methods are designed for specific applications, such as question-answering and summarization tasks, making them difficult to integrate into other TPR-based models. ", "page_idx": 1}, {"type": "text", "text": "In this work, we propose a Discrete Dictionary-based Decomposition (D3) layer for structured representation learning within the TPR framework. D3 employs the discrete representations techniques to utilize prior knowledge acquired during training for decomposition operations. Inspired by prior discrete key-value architectures [14, 38], D3 consists of multiple dictionaries, each comprising discrete, learnable key-value pairs. Unlike prior work, each dictionary of D3 is linked explicitly to individual TPR components, such as role, filler, and unbinding operator. This design allows each dictionary to capture and store the discrete features of its corresponding TPR components during training. D3 acts as a drop-in layer that maps input data into pre-learned discrete features for the decomposition of TPR components through a three-step process, as illustrated in Fig. 1. First, it generates multiple queries from the input data, with each query utilized for different TPR components. Next, it identifies the nearest codebook keys within each dictionary based on these queries. Finally, D3 generates structured TPR representations by aggregating the codebook values corresponding to these keys. Moreover, D3 can be seamlessly integrated into any TPR-based model by replacing the TPR component generation layer without requiring further modifications. ", "page_idx": 1}, {"type": "text", "text": "Our main contributions are as follows. ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "\u2022 We propose a novel D3 layer to tackle the decomposition problem inherent in the TPR-based approaches. D3 leverages discrete, learnable dictionaries to enhance the decomposition capabilities of TPR-based models. By mapping input data to pre-learned discrete features stored within the dictionaries, D3 effectively generates structured TPR representations.   \n\u2022 We conduct extensive experiments across various systematic generalization tasks, including synthetic associative recall and text/visual question-answering tasks. Our experimental results show that D3 significantly enhances the generalization performance of TPR-based models, demonstrating its effectiveness on systematic generalization tasks.   \n\u2022 Our analyses show that D3 generates well-bound structured representations that are satisfactory for the requirements of the TPR framework, utilizing the discrete, learnable dictionaries. ", "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Decomposition Problem. Compositional generalization in neural networks, which allows for generalizing beyond training data, has been extensively studied [2, 13, 12, 16, 8, 6, 41]. One important capability for achieving this is a segregation, as discussed in Greff et al. [6], which enables the formation of meaningful representations from structured and unstructured data [3, 18]. TPR-based neural networks also rely on this capability to generate structured representations for TPR components such as roles, flilers, and unbinding operators. In the TPR framework, these structured representations must satisfy specific conditions to ensure accurate encoding and decoding. First, roles need to be linearly independent to avoid filler overlap. Second, the unbinding operator must correlate with the corresponding roles to accurately retrieve associated fillers. Recent work [23] has shown that existing TPR-based models often fail to generate structured representations that meet these conditions, undermining their symbolic operations. To address this, an attention-based decomposition module [23] has been introduced, but it still shows limited performance on synthetic tasks involving the decomposition of unseen combinatorial data. In this work, we address the decomposition problem within the TPR framework using a discrete dictionary-based method, advancing the research further. ", "page_idx": 2}, {"type": "text", "text": "Discrete Representation Learning. Discrete neural representation learning has introduced a codebook of discrete, learnable representations into neural networks [39]. During training, each discrete representation captures underlying latent features by mapping continuous input data to the nearest features within the codebook, which are then used for downstream tasks. Recent work on object-centric learning has utilized discrete representations to extract specific types of features from unstructured data, leveraging latent features learned during training [11, 43]. Some researchers have proposed a separate key-value codebook for learning discrete representations, demonstrating its effectiveness in systematic generalization [17] and robustness against distributional shifts [38]. Inspired by these findings, we develop a separate key-value-based discrete dictionary method to enhance the decomposition capabilities of TPR-based models. Other researchers have introduced a discrete symbolic embedding layer to improve the interpretability of TPR-based models, showing the feasibility of discrete representations in the TPR framework [21, 9]. However, their methods focus on encoding processes and specific tasks such as question-answering [21] and abstractive summarization [9]. In contrast, our work addresses the decomposition problem in TPR-based approaches, and our D3 method is a drop-in solution that can be easily adapted to any TPR-based model. ", "page_idx": 2}, {"type": "text", "text": "Memory Network. Research on memory networks has focused on enhancing neural network capacity by integrating external memory [36, 4, 5, 24, 27, 41]. Memory-augmented neural networks store variable lengths of sequential data in this external memory and retrieve necessary information using various addressing methods [36, 5]. These writing and reading mechanisms share many similarities with our D3 approach. However, while memory networks store input features sequentially in their memory states as a continuous stream, D3 updates symbolic feature information through gradient descent into codebook parameters within dictionaries. This distinctive characteristic allows D3 to leverage the learned discrete features to decompose unseen data after training. In another work, Lample et al. [14] introduces a learnable key-value memory layer to improve the efficiency of the Transformer by replacing the feed-forward layer. Unlike their memory layer, D3 employs key-value pairs in dictionaries explicitly linked to individual TPR components, making it well-suited for the TPR framework. ", "page_idx": 2}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we explain how the D3 module generates structured representations of the TPR components using discrete, learnable dictionaries. We then introduce configurations of D3 and how it can be applied to our baseline models. ", "page_idx": 3}, {"type": "text", "text": "3.1 Discrete Dictionary-based Decomposition module ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "D3 is a discrete dictionary-based drop-in layer designed to enhance the decomposition capabilities of TPR-based approaches. At every time step, D3 decomposes input data into TPR components, such as roles, fillers, and unbinding operators, by mapping input data to pre-learned symbolic pTaPirRs ,c doemnpotoende nats, $\\{\\mathcal{D}^{j}\\}_{j=1}^{N\\mathrm{co}}$ mitp otnoe nlteaasr ns hthoew sny imn bEoqli. c1 f. eEataucrhe sd ircetqiouinraerdy $\\mathcal{D}^{j}$ gise neexrpaltiicnitgl yt hlei nskpeedc itfoi ca $j$ P-tRh component. This design also enables the generation of structured representations for different TPR components individually and in parallel. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{D}^{j}:=\\{(\\mathsf{k}_{i}^{j},\\mathsf{v}_{i}^{j})\\mid\\mathsf{k}_{i}^{j}\\in\\mathbb{R}^{D_{\\mathrm{qucr}}},\\mathsf{v}_{i}^{j}\\in\\mathbb{R}^{D_{\\mathrm{cod}}}\\}_{i=1}^{N_{\\mathrm{cod}}}\\quad\\mathrm{~where~}\\;j=1,...,N_{\\mathrm{component}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathcal{D}^{j}$ denotes the discrete, learnable dictionary for the $j$ -th TPR component, $\\mathsf{k}$ denotes a learnable codebook key, and $\\mathsf{v}$ denotes a learnable codebook value. In the next paragraph, we describe how D3 generates TPR components using these dictionaries in three steps. ", "page_idx": 3}, {"type": "text", "text": "Step 1: Query Generation. At each time step $t$ , D3 takes input data, denoted as $\\mathrm{input}_{t}\\in\\mathbb{R}^{D\\mathrm{input}}$ , and generates the query, denoted as quer $\\mathbf{\\Delta}_{\\sf t e s}_{t}\\in\\mathbb{R}^{N\\mathrm{component}\\times D_{\\mathrm{input}}}$ , for each $j$ -th TPR component using a query network, $f_{\\mathsf{q u e r y}}^{j}:\\mathsf{i n p u t}_{t}\\mapsto\\mathsf{q u e r y}_{t}^{j}\\in\\mathbb{R}^{D\\mathrm{query}}$ . The query network can be any neural network; in this study, we use a feed-forward network with a single layer. Additionally, we apply a layer normalization [1] and a dropout of $p_{\\mathrm{dropout}}$ [35] to quer $\\cdot\\mathbf{y}_{t}^{j}$ . ", "page_idx": 3}, {"type": "text", "text": "Step 2: Sparse Key Access. D3 searches for the nearest keys from each dictionary, $\\mathcal{D}^{j}$ , based on the generated quer $\\cdot\\mathbf{y}_{t}^{j}$ . We measure the similarity using the inner product between quer $\\mathbb{y}_{t}^{j}$ and $\\{\\mathsf{k}_{i}^{j}\\}_{i=1}^{N_{\\mathrm{code}}}$ . Then, D3 selects top- $k$ codebook keys in order of largest similarity, as follows. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{Z}^{j}=\\mathcal{T}_{k}(\\mathsf{q u e r y}_{t}^{j}\\,^{\\top}\\hat{\\mathsf{k}}_{i}^{j})\\quad\\mathrm{~where~}\\,\\hat{\\mathsf{k}}_{i}^{j}=\\mathsf{k}_{i}^{j}/||\\mathsf{k}_{i}^{j}||_{2}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathcal{T}_{k}$ denotes the top- $k$ operator that finds the indices of $k$ largest values, and $\\mathcal{T}^{j}$ denotes the indices of the $k$ most similar keys within $\\mathcal{D}^{j}$ . We found that applying $L2$ normalization to keys before the inner product mitigates the codebook collapse problem. ", "page_idx": 3}, {"type": "text", "text": "Step 3: Aggregation of Code Values. D3 computes the normalized score for selected codebook keys, denoted as $w_{t}^{j}$ , and aggregates codebook values corresponding to selected codebook keys with $w_{t}^{j}$ , as follows. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathsf{c o d e}_{t}^{j}=\\Sigma_{i\\in\\mathbb{Z}}w_{t,i}^{j}\\mathsf{v}_{i}^{j}\\quad\\mathrm{~where~}\\;w_{t}^{j}=\\mathsf{S o f t m a x}(\\mathsf{q u e r y}_{t}^{j}\\bar{\\mathsf{k}}_{i}^{j}))_{i\\in\\mathbb{Z}^{j}}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Then, D3 maps quer $\\boldsymbol{\\mathrm{y}}_{t}^{j}$ to a dimension of $D_{\\mathrm{code}}$ and adds this projected vector to ${\\mathsf{c o d e}}_{t}^{j}$ . The summed vectors are mapped to a dimension of $D_{\\mathrm{component}}$ to generate structured representations of TPR components, as follows. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{component}_{t}^{j}=\\mathsf{c o d e}_{t}^{j}+\\mathrm{layer}_{\\mathrm{residual}}(\\mathsf{q u e r y}_{t}^{j})\\in\\mathbb{R}^{D_{\\mathrm{code}}}}\\\\ {\\mathbf{\\overline{{component}}}_{t}^{j}=\\mathrm{layer}_{\\mathrm{final}}(\\mathsf{c o m p o n e n t}_{t}^{j})\\in\\mathbb{R}^{D_{\\mathrm{component}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathrm{\\layer{}_{\\mathrm{residual}}}$ and $\\mathrm{{layer}_{\\mathrm{{final}}}}$ denote a feed-forward network with a single layer. Those component $\\mathbf{s}_{t}$ are then utilized for TPR operations to solve the downstream tasks. ", "page_idx": 3}, {"type": "text", "text": "3.2 Module Configurations ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we describe the configurations of D3 when applied to TPR-based models. ", "page_idx": 3}, {"type": "text", "text": "Shared Dictionary between Role and Unbinding Operator. As discussed in Section 2, roles and unbinding operators should have correlated features for accurate TPR operations. Considering this characteristic of the TPR framework, we share the dictionaries of roles and unbinding operators. This shared dictionary also reduces the number of learnable parameters. ", "page_idx": 4}, {"type": "text", "text": "D3 Applied to Filler. While the TPR framework requires specific conditions for roles and unbinding operators for accurate TPR operations, there are no such requirements for fillers. Therefore, we explore two configurations in this study: applying D3 to generate flilers $(w/F)$ and not applying D3 to generate fillers $(w/o\\;F)$ . In the w/o $F$ configuration, we follow the baseline models to generate the filler representations. ", "page_idx": 4}, {"type": "text", "text": "3.3 Integration of D3 into Existing TPR-based Models ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we introduce our baseline models and explain how D3 is applied to them, considering the configurations of D3. We use three TPR-based models as our baselines: FWM [30], TPR-RNN [28], and Linear Transformer [10]. Notably, integrating D3 into these baseline models requires only substituting their TPR component generation layer with D3 without further modifications. ", "page_idx": 4}, {"type": "text", "text": "Fast Weight Memory. Fast Weight Memory (FWM) [30] is a TPR-based memory network designed for understanding long sequential contexts. It proposes a single word-level TPR operation related to the perceptron learning rule [25]. It has shown significant associative reasoning capability in reinforcement learning and natural language processing tasks. FWM requires two types of roles $(r o l e_{1}$ and $r o l e_{2}$ ) and one filler for encoding, as well as two types of unbinding operators (unbind1 and unbind2) for decoding. When D3 is integrated into FWM, it employs three dictionaries for the shared dictionary configuration: one for the $r o l e_{1}$ and unbind1, another for the $r o l e_{2}$ and unbind2, and the other for filler, as shown in Fig. 1. ", "page_idx": 4}, {"type": "text", "text": "TPR-RNN. TPR-RNN [28] is a sentence-level TPR-based memory network designed for basic text question-answering tasks [42]. It incorporates various encoding operations such as writing, moving, and backlink to process sequential data at the sentence level. These operations necessitate different encoding components with varying dimensions, making direct connections to the decoding components challenging. As a result, we do not apply the shared dictionary configuration to TPR-RNN; instead, we use a shared query network without layer normalization. Furthermore, due to the differing dimensions of the TPR components in TPR-RNN, we employ distinct layer $\\mathrm{fnal}$ layers for each TPR component. ", "page_idx": 4}, {"type": "text", "text": "Linear Transformer. Linear Transformer [10] linearizes the attention mechanism to improve the computational efficiency of the Transformer [40]. Recently, Schlag et al. [31] demonstrated the equivalence between TPR and the linear attention mechanism, indicating that the key, value, and query in linear attention correspond to the role, fliler, and unbinding operator, respectively. Building on this work, we apply D3 to generate the query, key, and value in the Linear Transformer. Unlike TPR-RNN and FWM, the Linear Transformer utilizes multi-head operations. Therefore, we use distinct dictionaries for each head, with the key and query of each head sharing the same dictionary. ", "page_idx": 4}, {"type": "text", "text": "4 Experiment ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we evaluate the effectiveness of D3 across various tasks, including a synthetic task, text/visual question-answering tasks, and a language modeling task. To assess the decomposition capabilities, we follow the experimental settings of the AID [23], a prior work addressing the decomposition problem in the TPR framework, and closely compare our D3 model to baseline models and AID. ", "page_idx": 4}, {"type": "text", "text": "4.1 Task ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Systematic Associative Recall (SAR) task. This task evaluates systematic generalization in memorizing and recalling combinatorial data [23]. It consists of a discovery phase and an inference phase. During the discovery phase, the model receives the combinatorial sequential items, each combining two symbols, $x\\in X$ and $y\\in Y$ where $X=X_{1}\\cup X_{2}\\cup X_{3}$ and $Y=Y_{1}\\cup Y_{2}$ . The model is then required to predict an associated $y$ when a specific $x$ is presented. The SAR task uses different combination settings between training and evaluation to target systematic generalization specifically. During training, the model learns the following combination settings: (1) $X_{1}$ and $Y_{1}$ , (2) $X_{2}$ and $Y_{2}$ , and (3) $X_{3}$ and $Y$ . At the evaluation, on the other hand, the model should generalize unseen combination settings, specifically $X_{1}$ and $Y_{2}$ . Additionally, the task includes a hyper-parameter $\\begin{array}{r}{p=\\frac{|X_{3}|}{|X_{2}|+|X_{3}|}}\\end{array}$ where $|X_{i}|$ denotes the cardinality of set $X_{i}$ . By adjusting $p$ , this task tests the systematic generalization of models under varying levels of exposure to different symbol combinations during training. In our study, we focus solely on the most challenging setting of the SAR task $\\it{p}=0.0)$ ), where the subset $X_{3}$ is excluded. In the SAR task, the TPR framework regards $x$ as the role and the unbinding operator, and $y$ as the filler. Therefore, TPR-based models should systematically decompose the combinatorial data into structured representations by mapping $x$ to the role and $y$ to the filler during the discovery phase, and mapping $x$ to the unbinding operator during the inference phase to solve this task. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Systematic bAbI (sys-bAbI) task. This task is a variant of the bAbI task [42] designed to evaluate systematic generalization in text understanding and reasoning [23]. It consists of 20 distinct sub-tasks, each comprising stories, relevant queries, and corresponding answers. The sys-bAbI task requires the models to remember the stories and predict corresponding answers to the queries. Unlike the original bAbI task, the sys-bAbI task evaluates the models with two aspects: (a) in-distribution (w/o sys diff) and (b) with the systematic difference $(w/s y s\\;d i f)$ where each sub-task includes unseen words during training. Therefore, the models should learn task-independent text understanding to solve the sys-bAbI task. ", "page_idx": 5}, {"type": "text", "text": "Sort-of-CLEVR task. This task [26] evaluates compositional generalization in visual relational reasoning. It consists of scene images, queries, and corresponding answers. This task requires the models to understand the properties of individual objects (Unary) or the relationships between multiple objects (Binary or Ternary) within visual scene images, and predict the correct answers to the queries [20]. Therefore, the model should capture relationships within each object and between objects to solve this task. ", "page_idx": 5}, {"type": "text", "text": "WikiText-103 task. This task [19] is a language modeling dataset consisting of lengthy corpora from Wikipedia. Although the WikiText-103 task does not directly measure the systematic generalization of the models, it is used to evaluate the effectiveness and applicability of D3 on a large-scale task beyond relatively simple tasks. ", "page_idx": 5}, {"type": "text", "text": "4.2 Experimental Results ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we present the experimental results of the SAR task, sys-bAbI task, sort-of-CLEVR task, and WikiText-103 task. In our experiments, we set $D_{\\mathrm{query}}$ as $D_{\\mathrm{code}}/2$ . ", "page_idx": 5}, {"type": "text", "text": "4.2.1 TPR-based Memory Networks ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "First, we evaluate FWM with D3 on the SAR task, which requires understanding the composition of two types of symbols, $x$ and $y$ . TPRbased models are expected to solve this task perfectly by mapping each symbol to a specific TPR component during decomposition. However, as shown in Fig. 2, FWM and AID fail to generalize unseen combinations of known symbols. In contrast, our D3 module significantly outperforms other baseline models, achieving nearly $100\\%$ accuracy. This result demonstrates that D3 effectively decomposes unseen combinatorial data into TPR components using discrete dictionaries. ", "page_idx": 5}, {"type": "image", "img_path": "NJUClFbosX/tmp/e3ce7d8885e687d432f115a2fa984a5d23c266293d6cff204076e63a68664927.jpg", "img_caption": ["Figure 2: Test accuracy curve $[\\%]$ on the SAR task for 10 seeds, with shadowed area indicating SD. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Next, we test TPR-RNN and FWM with D3 on the sys-bAbI task. This task involves compositional information in each story sentence, such as the relation between objects and their locations. It makes a sentence-level model more suitable for capturing the structural information of data than a word-level model. However, as shown in Table 1, TPR-RNN shows a larger performance gap between the $w/o$ sys diff and $w/$ sys diff cases than FWM. Notably, D3 enhances the systematic generalization of both TPR-RNN and FWM with fewer additional parameters, significantly reducing the performance gap for TPR-RNN. These results highlight the efficacy of D3 in text understanding tasks. ", "page_idx": 5}, {"type": "table", "img_path": "NJUClFbosX/tmp/d2d111078de4089e6b8c5494c3fcae2c3c248a33493d24e11d7ce0ecb17fe82e.jpg", "table_caption": ["Table 1: The mean word error rate $[\\%]$ on the sys-bAbI task for 10 seeds, with $\\pm$ indicating SD. "], "table_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "NJUClFbosX/tmp/5ab9a763a8535f6af671e6c4b2ca603224d353ff395f315b81b05ff680aeb9fb.jpg", "table_caption": ["Table 2: The mean accuracy $[\\%]$ on the sort-of-CLEVR task for 10 seeds, with $\\pm$ indicating SD. "], "table_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "NJUClFbosX/tmp/2b17d75c236030ffc2dd264d5e2b1d8e5c7b3e658077079452b4c418b9149b14.jpg", "table_caption": ["Table 3: Perplexity on the WikiText-103 task. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "4.2.2 Linear Transformer ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We also evaluate the Linear Transformer with D3 on the sort-of-CLEVR task and WikiText-103 task. Following the AID [23], we use a 4-layered Linear Transformer with shared parameters for the sortof-CLEVR task and apply D3 to a 16-layered Linear Transformer at intervals of 4 out of the 16 layers for the WikiText-103 task. As shown in Tables 2 and 3, D3 improves the performance of the Linear Transformer, with these improvements increasing as the capacity of the dictionaries grows. These results demonstrate the effectiveness of D3 on visual relational reasoning and language modeling tasks, as well as its applicability to the Linear Transformer. In addition, D3 shows comparable performance to the attention-based decomposition method, even with fewer parameters. ", "page_idx": 6}, {"type": "text", "text": "4.3 Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we conduct a qualitative analysis of the structured TPR representations generated by D3 and an ablation study of D3. For these analyses, we experiment with D3 $(w/o\\,F)$ on the SAR task. ", "page_idx": 6}, {"type": "text", "text": "4.3.1 Qualitative Analysis ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "TPR framework requires its structured representations to satisfy the following conditions for accurate TPR operations: $(i)$ linearly independence between distinct roles, and $(i i)$ high correlation between role and unbinding operator for the same symbol $x$ . We analyze the orthogonality of generated representations to investigate whether they satisfy these TPR conditions. Specifically, we consider the case of varying $x$ while keeping $y$ fixed for simplicity. ", "page_idx": 6}, {"type": "image", "img_path": "NJUClFbosX/tmp/91ec0672d905aa1897c9d4a4793a476137567e244a166776b433465466d12acc.jpg", "img_caption": ["Figure 3: The heatmap displays the cosine similarity between the generated representations during the discovery phase for the SAR task. We explore the similarity across different types of representations: (a) queries of roles, (b) codes of roles, and (c) the roles themselves. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "NJUClFbosX/tmp/a1c7a57e51cd022ca84efbaef5e1ed8b6b5d3fe635338df9e506efc463aa86bb.jpg", "img_caption": ["Figure 4: The heatmap displays the cosine similarity between the generated representations during the discovery phase (represented on the x-axis) and the inference phase (represented on the $\\mathbf{y}$ -axis) for the SAR task. We explore the similarity across different types of representations: (a) queries of roles and unbinding operators, (b) codes of roles and unbinding operators, and (c) the roles and unbinding operators themselves. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "NJUClFbosX/tmp/0e03b50a3074e41e6ef4062b8175086465448d136ef0b3aa8372c4b4ae109733.jpg", "img_caption": ["Figure 5: The heatmap visualizes the cosine similarity of the learned codebook features for the as $\\{\\mathsf{k}_{i}\\}_{i=1}^{N\\mathrm{code}}$ , and (b) the similarity among codebook values, denoted as $\\{\\boldsymbol{\\ v}_{i}\\}_{i=1}^{N\\mathrm{code}}$ . For better "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Fig. 3(c) shows the cosine similarity between the roles during the discovery phase, and Fig. 4(c) shows the cosine similarity between the roles during the discovery phase and the unbinding operator during the inference phase. Both results demonstrate that the generated representations by D3 satisfy the TPR conditions, resulting in an accuracy of nearly $100\\%$ . We also conduct the same analysis for intermediate features, particularly query and code. Figs. 3 and 4 show that each intermediate representation complements the others to satisfy the TPR condition, indicating the effectiveness of D3. ", "page_idx": 7}, {"type": "image", "img_path": "NJUClFbosX/tmp/243fd35c495966d82620ab67477fec9817477f8c13a09d921a135f8a97accde4.jpg", "img_caption": ["Figure 6: The mean accuracy on the SAR task for 10 seeds in the ablation study, with error bar indicating SD. The default setting uses $D_{\\mathrm{code}}$ of 64, $N_{\\mathrm{code}}$ of 64, and top- $k$ of 8. Each figure shows the experimental results for the following settings: (a) Varying $D_{\\mathrm{code}}$ . (b) Varying $N_{\\mathrm{code}}$ with top- $k$ constant. (c) Varying top- $k$ with $N_{\\mathrm{code}}$ constant. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Furthermore, we analyze the similarity patterns of codebook keys and codebook values. Fig. 5 shows that the codebook features learn orthogonal patterns despite being learned without constraints. This result implies that the learnable parameters of dictionaries implicitly capture TPR conditions to ensure accurate TPR operations. ", "page_idx": 8}, {"type": "text", "text": "4.3.2 Ablation Study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We investigate the effect of hyper-parameters of D3, specifically $N_{\\mathrm{code}}$ , $D_{\\mathrm{code}}$ , and top- $k$ , on performance on the SAR task. Fig. 6(a) shows the effect of $D_{\\mathrm{code}}$ . We observe that the value of $D_{\\mathrm{code}}$ significantly affects the performance of D3. Notably, D3 fails to solve the SAR task when $D_{\\mathrm{code}}$ is set to 8, indicating a need for adequate capacity of $D_{\\mathrm{code}}$ . Fig. 6(b) shows the effect of varying top- $k$ while holding $N_{\\mathrm{code}}$ constant, indicating that D3 achieves optimal performance when top- $k$ is set to 2. This result demonstrates the efficacy of the sparse mechanism employed by D3. Fig. 6(c) examines the effect of varying $N_{\\mathrm{code}}$ while holding top- $k$ constant, showing that D3 generally performs better with larger values of $N_{\\mathrm{code}}$ . ", "page_idx": 8}, {"type": "text", "text": "5 Discussion and Limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Motivation. From the perspective of systematic generalization, the decomposition operations in the TPR framework can be viewed as mapping unseen data to TPR components observed during training. Motivated by this, we design a decomposition module based on discrete representations, which maps input data to discrete, learned features facilitating systematic generalization in the decomposition operations of TPR. This design choice differentiates our contribution from AID\u2019s competitive attention-based decomposition module. Additionally, each dictionary in D3 is explicitly linked to a specific TPR component, ensuring that each dictionary is responsible solely for generating its corresponding component. The generated components are then utilized in predefined TPR operations of the TPR-based models. This design ensures that each dictionary is trained to specialize in a specific TPR component. ", "page_idx": 8}, {"type": "text", "text": "Interpretability. The TPR framework decomposes data at the representation level into distinct symbols, such as role-fliler pairs for encoding and unbinding operators for decoding. This characteristic enhances the interpretability of models because the relationships between roles and unbinding operators explain which parts of the input the model focuses on to predict the output. However, this interpretability is reliable only when the generated structured representations satisfy the TPR conditions. In this context, D3 enhances the interpretability of models by providing structured representations that more effectively satisfy the TPR conditions than baseline models like FWM and AID. Figs. 9 and 10 demonstrate that the representations generated by D3 better conform to the TPR conditions than those from other baseline models, supporting our claim that D3 contributes to increased interpretability. ", "page_idx": 8}, {"type": "text", "text": "D3 Applied to Filler (w/o F and w/ F). In the TPR framework, roles and unbinding operators must meet specific conditions, such as linear independence among roles and high correlation between roles and unbinding operators, to ensure accurate TPR operations. However, there are no such requirements for fillers, which are features related to downstream tasks. This characteristic affects the performance of D3 depending on whether it is applied to generate the fillers $(w/F)$ or not $(w/o$ $F$ ). In our experiments, the $w/F$ configuration performs well on the sys-bAbI and sort-of-CLEVR tasks with relatively few labels $({\\sim}200)$ . In contrast, the w/o $F$ configuration excels on the SAR and WikiText-103 tasks, which have a larger number of labels $(500\\mathrm{\\sim})$ . These findings suggest that the w/o $F$ configuration may be more effective for large-scale practical tasks. Nevertheless, beyond these experimental results, we do not fully understand the conditions under which each configuration performs better. Consequently, one limitation of D3 is the additional burden of determining the suitable configuration for various tasks when applying it to other domains. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Sparse Key Selection. D3 integrates seamlessly with existing TPR-based models, significantly enhancing their generalization performance across various tasks. However, this integration introduces additional computational overhead to the baseline models. Specifically, the sparse key selection mechanism of D3 has a computational complexity of $\\mathcal{O}(N_{\\mathrm{code}}\\,\\times\\,(D_{\\mathrm{query}}+\\mathrm{log}k))$ ) for each TPR component. Therefore, this complexity can become a drawback as the capacity of the dictionaries increases. One potential solution to address this capacity issue is to incorporate product keys into the sparse key selection mechanism of D3, a technique studied in prior discrete key-value architectures [14]. We leave this enhancement for future work. ", "page_idx": 9}, {"type": "text", "text": "Scalability. The scalability of D3 is inherently linked to TPR operations of baseline models since the number of dictionaries in the D3 layer aligns with the number of TPR components required for their operations. As TPR operations require increasing components to handle large datasets, our method also requires a proportional increase in dictionaries, resulting in significant computational and memory overhead. As explored in prior work, one potential solution to mitigate this issue is distributing shared dictionaries across multiple heads or layers [14]. However, this approach requires further investigation and experimentation, which we plan to research in future work. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we tackle the decomposition problem inherent in the TPR framework, which poses a significant challenge for TPR-based models. To address this, we introduce a discrete dictionary-based layer, D3, designed to enhance the decomposition capabilities of TPR-based models. D3 employs the discrete dictionaries to map input data to pre-learned symbolic features within each dictionary, thereby generating structured TPR representations. Our comprehensive experiments demonstrate that D3 significantly enhances the systematic generalization of the TPR-based models with fewer additional parameters. Furthermore, our qualitative analysis verifies that D3 effectively generates structured representations that are satisfactory for the requirements of the TPR framework. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. 2021R1A2C3011169 & No. 2022R1A5A7026673 & No. RS-2022-00166735 & No. RS-2023-00218987). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] J. L. Ba, J. R. Kiros, and G. E. Hinton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016.   \n[2] J. A. Fodor and Z. W. Pylyshyn. Connectionism and cognitive architecture: A critical analysis. Cognition, 28(1-2):3\u201371, 1988.   \n[3] A. Goyal, A. Lamb, J. Hoffmann, S. Sodhani, S. Levine, Y. Bengio, and B. Sch\u00f6lkopf. Recurrent independent mechanisms. arXiv preprint arXiv:1909.10893, 2019.   \n[4] A. Graves, G. Wayne, and I. Danihelka. Neural turing machines. arXiv preprint arXiv:1410.5401, 2014.   \n[5] A. Graves, G. Wayne, M. Reynolds, T. Harley, I. Danihelka, A. Grabska-Barwi\u00b4nska, S. G. Colmenarejo, E. Grefenstette, T. Ramalho, J. Agapiou, et al. Hybrid computing using a neural network with dynamic external memory. Nature, 538(7626):471\u2013476, 2016.   \n[6] K. Greff, S. Van Steenkiste, and J. Schmidhuber. On the binding problem in artificial neural networks. arXiv preprint arXiv:2012.05208, 2020.   \n[7] K. Hsu, W. Dorrell, J. Whittington, J. Wu, and C. Finn. Disentanglement via latent quantization. Advances in Neural Information Processing Systems, 36, 2024.   \n[8] D. Hupkes, V. Dankers, M. Mul, and E. Bruni. Compositionality decomposed: How do neural networks generalise? Journal of Artificial Intelligence Research, 67:757\u2013795, 2020.   \n[9] Y. Jiang, A. Celikyilmaz, P. Smolensky, P. Soulos, S. Rao, H. Palangi, R. Fernandez, C. Smith, M. Bansal, and J. Gao. Enriching transformers with structured tensor-product representations for abstractive summarization. arXiv preprint arXiv:2106.01317, 2021.   \n[10] A. Katharopoulos, A. Vyas, N. Pappas, and F. Fleuret. Transformers are rnns: Fast autoregressive transformers with linear attention. In International conference on machine learning, pages 5156\u20135165. PMLR, 2020.   \n[11] A. Kori, F. Locatello, F. D. S. Ribeiro, F. Toni, and B. Glocker. Grounded object-centric learning. In The Twelfth International Conference on Learning Representations, 2023.   \n[12] B. Lake and M. Baroni. Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. In International conference on machine learning, pages 2873\u20132882. PMLR, 2018.   \n[13] B. M. Lake, T. D. Ullman, J. B. Tenenbaum, and S. J. Gershman. Building machines that learn and think like people. Behavioral and brain sciences, 40:e253, 2017.   \n[14] G. Lample, A. Sablayrolles, M. Ranzato, L. Denoyer, and H. J\u00e9gou. Large memory layers with product keys. Advances in Neural Information Processing Systems, 32, 2019.   \n[15] H. Le, T. Tran, and S. Venkatesh. Self-attentive associative memory. In International Conference on Machine Learning, pages 5682\u20135691. PMLR, 2020.   \n[16] A. Li\u0161ka, G. Kruszewski, and M. Baroni. Memorize or generalize? searching for a compositional rnn in a haystack. arXiv preprint arXiv:1802.06467, 2018.   \n[17] D. Liu, A. M. Lamb, K. Kawaguchi, A. G. ALIAS PARTH GOYAL, C. Sun, M. C. Mozer, and Y. Bengio. Discrete-valued neural communication. Advances in Neural Information Processing Systems, 34:2109\u20132121, 2021.   \n[18] F. Locatello, D. Weissenborn, T. Unterthiner, A. Mahendran, G. Heigold, J. Uszkoreit, A. Dosovitskiy, and T. Kipf. Object-centric learning with slot attention. Advances in Neural Information Processing Systems, 33:11525\u201311538, 2020.   \n[19] S. Merity, C. Xiong, J. Bradbury, and R. Socher. Pointer sentinel mixture models. arXiv preprint arXiv:1609.07843, 2016.   \n[20] S. Mittal, S. C. Raparthy, I. Rish, Y. Bengio, and G. Lajoie. Compositional attention: Disentangling search and retrieval. arXiv preprint arXiv:2110.09419, 2021.   \n[21] H. Palangi, P. Smolensky, X. He, and L. Deng. Question-answering with grammaticallyinterpretable representations. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 32, 2018.   \n[22] T. Park, I. Choi, and M. Lee. Distributed associative memory network with memory refreshing loss. Neural Networks, 144:33\u201348, 2021.   \n[23] T. Park, I. Choi, and M. Lee. Attention-based iterative decomposition for tensor product representation. In The Twelfth International Conference on Learning Representations, 2023.   \n[24] J. Rae, J. J. Hunt, I. Danihelka, T. Harley, A. W. Senior, G. Wayne, A. Graves, and T. Lillicrap. Scaling memory-augmented neural networks with sparse reads and writes. In Advances in Neural Information Processing Systems, pages 3621\u20133629, 2016.   \n[25] F. Rosenblatt. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review, 65(6):386, 1958.   \n[26] A. Santoro, D. Raposo, D. G. Barrett, M. Malinowski, R. Pascanu, P. Battaglia, and T. Lillicrap. A simple neural network module for relational reasoning. Advances in neural information processing systems, 30, 2017.   \n[27] A. Santoro, R. Faulkner, D. Raposo, J. Rae, M. Chrzanowski, T. Weber, D. Wierstra, O. Vinyals, R. Pascanu, and T. Lillicrap. Relational recurrent neural networks. Advances in neural information processing systems, 31, 2018.   \n[28] I. Schlag and J. Schmidhuber. Learning to reason with third order tensor products. Advances in neural information processing systems, 31, 2018.   \n[29] I. Schlag, P. Smolensky, R. Fernandez, N. Jojic, J. Schmidhuber, and J. Gao. Enhancing the transformer with explicit relational encoding for math problem solving. arXiv preprint arXiv:1910.06611, 2019.   \n[30] I. Schlag, T. Munkhdalai, and J. Schmidhuber. Learning associative inference using fast weight memory. arXiv preprint arXiv:2011.07831, 2020.   \n[31] I. Schlag, K. Irie, and J. Schmidhuber. Linear transformers are secretly fast weight programmers. In International Conference on Machine Learning, pages 9355\u20139366. PMLR, 2021.   \n[32] Z. Shi, Q. Zhang, and A. Lipani. Stepgame: A new benchmark for robust multi-hop spatial reasoning in texts. In Proceedings of the AAAI conference on artificial intelligence, volume 36, pages 11321\u201311329, 2022.   \n[33] P. Smolensky. Tensor product variable binding and the representation of symbolic structures in connectionist systems. Artificial intelligence, 46(1-2):159\u2013216, 1990.   \n[34] P. Soulos, E. J. Hu, K. McCurdy, Y. Chen, R. Fernandez, P. Smolensky, and J. Gao. Differentiable tree operations promote compositional generalization. In International Conference on Machine Learning, pages 32499\u201332520. PMLR, 2023.   \n[35] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: a simple way to prevent neural networks from overftiting. The journal of machine learning research, 15 (1):1929\u20131958, 2014.   \n[36] S. Sukhbaatar, J. Weston, R. Fergus, et al. End-to-end memory networks. In Advances in neural information processing systems, pages 2440\u20132448, 2015.   \n[37] A. Tamkin, M. Taufeeque, and N. D. Goodman. Codebook features: Sparse and discrete interpretability for neural networks. arXiv preprint arXiv:2310.17230, 2023.   \n[38] F. Tr\u00e4uble, A. Goyal, N. Rahaman, M. C. Mozer, K. Kawaguchi, Y. Bengio, and B. Sch\u00f6lkopf. Discrete key-value bottleneck. In International Conference on Machine Learning, pages 34431\u201334455. PMLR, 2023.   \n[39] A. Van Den Oord, O. Vinyals, et al. Neural discrete representation learning. Advances in neural information processing systems, 30, 2017.   \n[40] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, \u0141. Kaiser, and I. Polosukhin. Attention is all you need. Advances in neural information processing systems, 30, 2017.   \n[41] T. W. Webb, I. Sinha, and J. D. Cohen. Emergent symbols through binding in external memory. arXiv preprint arXiv:2012.14601, 2020.   \n[42] J. Weston, A. Bordes, S. Chopra, A. M. Rush, B. Van Merri\u00ebnboer, A. Joulin, and T. Mikolov. Towards ai-complete question answering: A set of prerequisite toy tasks. arXiv preprint arXiv:1502.05698, 2015.   \n[43] Y.-F. Wu, M. Lee, and S. Ahn. Structured world modeling via semantic vector quantization. arXiv preprint arXiv:2402.01203, 2024.   \n[44] X. Zhuang, Q. Zhang, K. Ding, Y. Bian, X. Wang, J. Lv, H. Chen, and H. Chen. Learning invariant molecular representation in latent discrete space. Advances in Neural Information Processing Systems, 36, 2024. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A Experiment Details ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "This section provides a detailed description of our experiments on the SAR task, sys-bAbI task, sort-of-CLEVR task, and WikiText-103 task. We followed the experimental settings outlined by AID [23] to assess the decomposition capabilities of D3. To ensure stability and reproducibility, we ran all experiments, except for the WikiText-103 task, using 10 different random seeds3. For the WikiText-103 task, we experimented with a single seed of 1111. Each experiment was conducted on a single 48GB NVIDIA RTX A6000 GPU and an AMD EPYC 7513 32-Core Processor. ", "page_idx": 13}, {"type": "text", "text": "A.1 Systematic Associative Recall task ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The SAR task [23] evaluates systematic generalization in memorizing and recalling combinatorial data. It consists of a discovery phase and an inference phase. During the discovery phase, the model receives the combinatorial sequential items, each combining two symbols, $x\\in X$ and $y\\in Y$ where $X=X_{1}\\cup X_{2}\\cup X_{3}$ and $Y=Y_{1}\\cup Y_{2}$ . The model is then required to predict an associated $y$ when a specific $x$ is presented. The SAR task uses different combination settings between training and evaluation to target systematic generalization specifically. During the training, the model learns the following combination settings: (1) $X_{1}$ and $Y_{1}$ , (2) $X_{2}$ and $Y_{2}$ , and (3) $X_{3}$ and $Y$ . At evaluation, however, the model should generalize unseen combination settings, specifically $X_{1}$ and $Y_{2}$ . In our study, unlike the AID paper [23], we only consider the most challenging setting of the SAR task by excluding the subset $X_{3}$ . ", "page_idx": 13}, {"type": "text", "text": "Each combinatorial item is constructed as follows. First, symbols $x$ and $y$ are sampled from their respective sets $X$ and $Y$ , where $|X_{1}|\\,=\\,|X_{2}|\\,=\\,|Y_{1}|\\,=\\,|Y_{2}|\\,=\\,250$ . The sampled symbols are mapped into a 50-dimensional space using a word embedding method. These embedding vectors are then concatenated to construct the combinatorial item. For training, 100 randomly generated combinatorial items are sequentially provided to the model during the discovery phase. During the inference phase, the model receives only the $x$ symbols sequentially, with the embedding vector of $y$ set to zero. This task also provides binary flags to indicate the start of each phase. At evaluation, all possible combinations that can be formed in $X_{1}$ and $Y_{2}$ are tested. ", "page_idx": 13}, {"type": "text", "text": "To build the experimental environment for the SAR task, we utilize the open-source implementation4 from the AID [23]. We train the model using the Adam optimizer with a batch size of 64 and a learning rate of $1e^{-3}$ , $\\beta_{1}$ of 0.9, and $\\beta_{2}$ of 0.98 for training iterations of $30K$ . Each experiment took approximately 3 hours per each seed. ", "page_idx": 13}, {"type": "text", "text": "A.2 Systematic bAbI task ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The sys-bAbI task [23] is a variant of the bAbI task [42] designed to evaluate systematic generalization in text understanding and reasoning. It consists of 20 distinct sub-tasks, each comprising stories, relevant queries, and corresponding answers. The sys-bAbI task requires the models to remember the stories and predict corresponding answers to the queries. Unlike the original bAbI task, the sys-bAbI task evaluates the models with two aspects: (a) in-distribution (w/o sys diff) and (b) with the systematic difference $(w/s y s\\,d i f\\!\\!\\!/)$ where each sub-task includes unseen words during training. Therefore, the models should learn task-independent text understanding to solve the sys-bAbI task. ", "page_idx": 13}, {"type": "text", "text": "The bAbI dataset includes various versions, such as $\\mathtt{e n-10k}$ and en-valid- $10\\mathtt{k}$ . The sys-bAbI task uses the en-valid- $10\\mathtt{k}$ version, which is already divided into training, validation, and test datasets. To create the experimental environment for the sys-bAbI task, we use the open-source implementation5 provided by the AID. ", "page_idx": 13}, {"type": "text", "text": "We use the open-source implementation of the baseline models, TPR-RNN6 [28] and $\\mathrm{FWM}^{7}$ [30]. Following the experimental settings of baseline models, we use different configurations for each model. We train the TPR-RNN with D3 using an embedding size of 179 and the Adam optimizer with a batch size of 128 and a learning rate of $\\bar{1}e^{-3}$ , $\\beta_{1}$ of 0.9, and $\\beta_{2}$ of 0.99 for 100 training epochs. For FWM with D3, we use an embedding size of 256 and the Adam optimizer with a batch size of 64 and a learning rate of $1e^{-3}$ , $\\beta_{1}$ of 0.9, and $\\beta_{2}$ of 0.98 for training iterations of $60K$ . Furthermore, following the AID, we use the reconstruction loss for the bAbI task, introduced in Park et al. [22], in our experiments on the sys-bAbI task. Each experiment took approximately 7 hours per seed for the TPR-RNN with D3 and 8 hours per seed for the FWM with D3. ", "page_idx": 14}, {"type": "text", "text": "A.3 Sort-of-CLEVR task ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The sort-of-CLEVR task [26] evaluates compositional generalization in visual relational reasoning. It consists of scene images, queries, and corresponding answers. This task requires the models to understand the properties of individual objects (Unary) or the relationships between multiple objects (Binary or Ternary) within visual scene images and predict the correct answers to the queries. Therefore, the model should capture relationships within each object and between objects to solve this task. ", "page_idx": 14}, {"type": "text", "text": "Each scene image, with a size of $75\\!\\times\\!75$ pixels, includes 6 distinct objects in 6 different colors (red, blue, green, orange, yellow, or gray) and 2 different shapes (square or circle). This scene image is encoded by a visual encoder. The encoded visual feature is then concatenated with the embedding vector of the query. These concatenated features are provided to the model. Following the experimental settings of the AID [23], we use a single CNN layer with a kernel size of 15 and a stride of 15 for the visual encoder, and an embedding size of 128 for the word embedding method. Also, we use a 4-layered Transformer, where each layer shares its parameters with others, as our baseline model. ", "page_idx": 14}, {"type": "text", "text": "To build the experimental environment for the sort of CLEVR task, we utilize the open-source implementation8 from Mittal et al. [20]. We train the model using the Adam optimizer with a batch size of 64 and a learning rate of $1e^{-4}$ for 100 training epochs. Each experiment took approximately 2.5 hours per each seed. ", "page_idx": 14}, {"type": "text", "text": "A.4 WikiText-103 task ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The WikiText-103 task [19] is a language modeling dataset consisting of lengthy corpora from Wikipedia. Although the WikiText-103 task does not directly measure the systematic generalization of the models, it is used to evaluate the effectiveness and applicability of D3 on a large-scale task beyond relatively simple tasks. ", "page_idx": 14}, {"type": "text", "text": "The WikiText-103 task comprises 28,475 articles for training, 60 for validation, and 60 for testing. Following the experimental settings of Schlag et al. [31], we partition the articles into segments of $L$ words. During training, the gradient is back-propagated only within spans of $L$ words. The performance of the model is evaluated using the measure of perplexity. During evaluation, the model processes an input sequence of $L$ words by sliding a segment over the article with a stride size of 1. Perplexity is then computed based on the last position of each segment, except for the first segment, where every position is taken into account. ", "page_idx": 14}, {"type": "text", "text": "To build the experimental environment for the WikiText-103 task, we utilize the open-source implementation9 from [31]. Following the AID [23], we apply D3 to a 16-layered Linear Transformer at intervals of 4 out of the 16 layers. We train the model using the Adam optimizer with a batch size of 96, an initial learning rate of $\\stackrel{\\cdot}{2.5e^{-4}}$ , and a learning rate warmup step of 2,000 for 120 epochs. Each experiment took approximately ${\\sim}3$ days. ", "page_idx": 14}, {"type": "text", "text": "B Hyper-parameter Settings ", "text_level": 1, "page_idx": 15}, {"type": "table", "img_path": "NJUClFbosX/tmp/9d490f9f17acd976039b0edf616b55441d1fa54153168d895bd494fd51759de0.jpg", "table_caption": ["Table 4: Hyper-parameter settings of the D3. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "NJUClFbosX/tmp/12ba63ba3181bc3ee87000b66971df407b16440e8260420b9e702feab8c04cd6.jpg", "table_caption": ["Table 5: Hyper-parameters of TPR-RNN. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "NJUClFbosX/tmp/368440ed4e41bc7ac191c2f72c1777fb738156e63fc3984a34a215318a1bf65e.jpg", "table_caption": ["Table 6: Hyper-parameters of FWM. "], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "NJUClFbosX/tmp/bfb3a07611c88180fa0dd9b78220b6c1cd020dd546888011b0422816ddff7fcd.jpg", "table_caption": ["Table 7: Hyper-parameters of Linear Transformer. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "C Additional Experiments ", "text_level": 1, "page_idx": 16}, {"type": "table", "img_path": "NJUClFbosX/tmp/9c3bba3fcecfcbf55069e3d6b5af9f6951c6e530ff564c72e4af0eb6da8533b9.jpg", "table_caption": ["Table 8: The mean word error rate $[\\%]$ on additional experiments of the sys-bAbI task for 10 seeds. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "D Additional Comparisons ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we expand our comparisons to include a broader range of state-of-the-art methods, as detailed below. ", "page_idx": 16}, {"type": "text", "text": "sys-bAbI task. We compare D3 to state-of-the-art methods (DAM [22] and STM [15]) on the original bAbI task. Table 9 shows that existing memory networks struggle with the sys-bAbI task, highlighting the efficacy of D3 compared to these state-of-the-art memory networks. ", "page_idx": 16}, {"type": "table", "img_path": "NJUClFbosX/tmp/75680a613f3c90ab05fd74249ef5823cb49ce0ec813913450ff1d32fd50f3a5b.jpg", "table_caption": ["Table 9: The mean word error rate $[\\%]$ on additional comparison of the sys-bAbI task for 10 seeds. "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "Sort-of-CLEVR task. We compare D3 to vanilla Transformer [40] and Compositional Transformer [20], designed to enhance the systematic generalization capabilities of multi-head self-attention methods. Table 10 shows that the Linear Transformer significantly degrades systematic generalization performance compared to the vanilla Transformer and the Compositional Transformer. While D3 improves the performance of the Linear Transformer from a TPR perspective, it still shows limited performance in reasoning the relationships between multiple objects (Binary and Ternary) compared to the vanilla Transformer and Compositional Transformer. ", "page_idx": 16}, {"type": "text", "text": "WikiText-103 task. We compared D3 to the Delta Network [31], which introduced a delta updating rule instead of the additive outer product-based updating rule in the Linear Transformer. Table 11 indicates that although D3 improves the performance of the Linear Transformer in language modeling tasks, the choice of updating rules has a more substantial impact on performance for tasks involving the comprehension of lengthy corpora than the decomposition operation. ", "page_idx": 16}, {"type": "table", "img_path": "NJUClFbosX/tmp/5b6f7472de2be0f2a44674201a30a93c31b7e48832d7b897ea2a3d2f1d6e27a7.jpg", "table_caption": ["Table 10: The mean accuracy $[\\%]$ on additional comparison of the sort-of-CLEVR task for 10 seeds. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "table", "img_path": "NJUClFbosX/tmp/f1a137b79661e00fdb814aad1915be1a73f39210b47d7e291d6551cb0e9d795f.jpg", "table_caption": ["Table 11: Perplexity on additional comparison of the WikiText-103 task. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "E Additional Ablation Study ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we extend our ablation studies to investigate the effects of varying the number of keys in the codebook and the impact of removing either the residual connection or the codebook from the D3 layer. ", "page_idx": 17}, {"type": "text", "text": "The Effect of Varying the Number of Codebook Keys. Fig. 7 shows that even with a significantly reduced number of keys, the model with D3 maintains high accuracy on the SAR task. This observation prompts the question of how consistent performance is achieved despite the reduction in codebook size. To explore this further, we examine the impact of removing the codebook or the residual connection within the D3 layer on the SAR and sys-bAbI tasks. Specifically, removing the codebook means that the components are generated solely by the shared feed-forward networks (layerresidual and layer $\\mathrm{\\dot{\\final}}.$ ) while removing the residual connection implies that the components are derived solely from the codebook values. ", "page_idx": 17}, {"type": "image", "img_path": "NJUClFbosX/tmp/0708fb6a61c5942e3151ade6e2acc0d74c25b0e6a74a1f75c519203df45a40c2.jpg", "img_caption": ["Figure 7: The mean accuracy on the SAR task for 10 seeds in the ablation study for the effect of varying $N_{\\mathrm{code}}$ from 2 to 128 with top- ${\\cdot k}$ constant. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "The Effect of Residual Connection. Fig. 8 shows that without the residual connection, the generalization performance of D3 dramatically degrades. This result indicates that the residual connection is crucial for effectively training the D3 layer. ", "page_idx": 18}, {"type": "image", "img_path": "NJUClFbosX/tmp/6a3b93b9680204186c25d1166d1c30503c9fa0f3cef8ff4a3d2d7f9ff6d23e48.jpg", "img_caption": ["Figure 8: Ablation study for the effect of the residual connection on (a) the SAR task and (b) the sys-bAbI task for 10 seeds. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "The Effect of Codebook. Table 12 shows that even without the codebook (\"w/o codebook\"), the D3 layer improves the generalization performance of the baseline model on the SAR task. This result indicates that the shared feed-forward networks significantly contribute to performance enhancement, which may explain why the model maintains robust performance even with fewer keys. ", "page_idx": 18}, {"type": "text", "text": "However, it is important to note that without the codebook, the D3 layer does not achieve near-perfect accuracy on the SAR task (as shown in Table 12) and fails to significantly enhance the systematic generalization of the baseline model on the sys-bAbI task (as shown in Table 13). These results demonstrate that the codebook plays a crucial role in enhancing the model\u2019s overall performance and generalization capabilities, especially in tasks requiring systematic generalization. ", "page_idx": 18}, {"type": "text", "text": "Furthermore, we experiment with $N_{\\mathrm{code}}\\,=\\,1$ on the SAR task, where the codebook may act as a bias term. The results in Table 12) show that using a single codebook element leads to degraded generalization performance compared to the \"w/o codebook\" configuration, indicating that multiple codebook elements are essential for achieving optimal results. ", "page_idx": 18}, {"type": "table", "img_path": "NJUClFbosX/tmp/b17cc13c72f23b77b65b409190c440c25dff6c0c28047f34d69c5e4ed53eb8d3.jpg", "table_caption": ["Table 12: Ablation study for the effect of the codebook on the SAR task for 10 seeds. "], "table_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "NJUClFbosX/tmp/93910c4bb79938c0f106af2d1759266ed23509cc87f17a68dc825c465333bb6e.jpg", "table_caption": ["Table 13: Ablation study for the effect of the codebook on the sys-bAbI task for 10 seeds. "], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Discussion. Our ablation study on the codebook in the SAR task (Table 12) indicates that the shared residual networks within the D3 layer significantly enhance generalization performance. However, the results from the sys-bAbI task (Table 13) suggest that while these networks improve performance, they alone struggle to generalize more structured data. ", "page_idx": 18}, {"type": "text", "text": "The ablation studies in Tables 12 and 13 demonstrate that incorporating the codebook mechanism leads to nearly $100\\%$ accuracy on the SAR task and significantly improves the systematic generalization of models on the sys-bAbI task. However, as shown in the ablation study on the residual connection (Fig. 8), the codebook alone does not achieve the same level of generalization and exhibits instability within the D3 layer. ", "page_idx": 19}, {"type": "text", "text": "In conclusion, our experimental results indicate that the combination of the codebook and the shared residual networks within the D3 layer is crucial for enhancing systematic generalization performance and stability. By integrating these two components, our D3 layer significantly improves the systematic generalization capabilities of TPR-based models. ", "page_idx": 19}, {"type": "text", "text": "F Additional Qualitative Analysis ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "F.1 Comparison to Baselines ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We conduct an orthogonal analysis for the baseline models (FWM and AID) similar to the analysis presented in Section 4.3.1. Figs. 9 and 10 indicate that the D3 model generates more structured and orthogonal representations than the baseline models, FWM and AID, demonstrating its effectiveness. ", "page_idx": 19}, {"type": "image", "img_path": "NJUClFbosX/tmp/c24644c02f7b5656c40fade4f8966f60717c5716f1285fe26134a0a840c22581.jpg", "img_caption": ["Figure 9: The heatmap displays the cosine similarity between the roles during the discovery phase for the SAR task. "], "img_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "NJUClFbosX/tmp/76e885cdce432d64e4efbc1cbefb48c08e864ae0c48ab7c773b66bcc9595516c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Figure 10: The heatmap displays the cosine similarity between the roles (x-axis) during the discovery phase and the unbinding operators (y-axis) during the inference phase for the SAR task. ", "page_idx": 19}, {"type": "text", "text": "F.2 Qualitative Analysis for Different Seeds ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Additionally, we present the results of the qualitative analysis for different seeds in the SAR task. ", "page_idx": 20}, {"type": "text", "text": "F.2.1 Ncode: 64, $D_{\\mathbf{code}}$ : 32, top-k: 8, seed: 3333 ", "text_level": 1, "page_idx": 20}, {"type": "image", "img_path": "NJUClFbosX/tmp/48a44aef963c8e2ffa96590e390f7ff8eb966b23d151f7d234cffb34a942d39e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 11: The heatmap displays the cosine similarity between the generated representations during the discovery phase for the SAR task. We explore the similarity across different types of representations: (a) queries of roles, (b) codes of roles, and (c) the roles themselves. ", "page_idx": 20}, {"type": "image", "img_path": "NJUClFbosX/tmp/1dfe4a8eef882414b99347264e4c1665bb4490977b8def5447e63b422880af5b.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 12: The heatmap displays the cosine similarity between the generated representations during the discovery phase (represented on the $\\mathbf{X}$ -axis) and the inference phase (represented on the y-axis) for the SAR task. We explore the similarity across different types of representations: (a) queries of roles and unbinding operators, (b) codes of roles and unbinding operators, and (c) the roles and unbinding operators themselves. ", "page_idx": 20}, {"type": "image", "img_path": "NJUClFbosX/tmp/b85ee4212554ed87b300a437bdffe7bd9897cd4fddee035647f293b749b91f7a.jpg", "img_caption": ["Figure 13: The heatmap visualizes the cosine similarity of the learned codebook features fkoery tsh, ed SenAoRt etda saks. $\\{\\mathsf{k}_{i}\\}_{i=1}^{N\\mathrm{code}}$ ,t wano dp (arbt)s  ttho ee saicmh ihlaeraittym aapm: o(an)g t hceo dsiembioloarki tvy aalumeos,n gd ecnoodteebdo oaks $\\{\\boldsymbol{\\ v}_{i}\\}_{i=1}^{N\\mathrm{code}}$ . For better visualization, the heatmap values are reordered to reflect the cluster of similar codebook keys. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "NJUClFbosX/tmp/24452eb2e02f02a2320e4baf9f0bbeaf65672c7e3959c25ea1d2c233b3f4085f.jpg", "img_caption": [], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Figure 14: The heatmap displays the cosine similarity between the generated representations during the discovery phase for the SAR task. We explore the similarity across different types of representations: (a) queries of roles, (b) codes of roles, and (c) the roles themselves. ", "page_idx": 21}, {"type": "image", "img_path": "NJUClFbosX/tmp/27fded8a17bc81aeb47bdf3f4cc29be67357896157ea4e60241176b49707eeda.jpg", "img_caption": [], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "Figure 15: The heatmap displays the cosine similarity between the generated representations during the discovery phase (represented on the $\\mathbf{X}$ -axis) and the inference phase (represented on the y-axis) for the SAR task. We explore the similarity across different types of representations: (a) queries of roles and unbinding operators, (b) codes of roles and unbinding operators, and (c) the roles and unbinding operators themselves. ", "page_idx": 21}, {"type": "image", "img_path": "NJUClFbosX/tmp/a1f15bb50a4ea2f98419fd37e6e53b395b1a97cf635b4452e2198e6577c42217.jpg", "img_caption": ["Figure 16: The heatmap visualizes the cosine similarity of the learned codebook features fkoery tsh, ed SenAoRt etda saks. $\\{\\mathsf{k}_{i}\\}_{i=1}^{N\\mathrm{code}}$ ,t wano dp (arbt)s  ttho ee saicmh ihlaeraittym aapm: o(an)g t hceo dsiembioloarki tvy aalumeos,n gd ecnoodteebdo oaks $\\{\\boldsymbol{\\ v}_{i}\\}_{i=1}^{N\\mathrm{code}}$ . For better visualization, the heatmap values are reordered to reflect the cluster of similar codebook keys. "], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: This paper includes the paper\u2019s contributions and scope in the abstract and introduction, as follows. This paper tackles the decomposition problem inherent in the TPR-based approaches. To address this, this paper proposes a discrete dictionary-based decomposition (D3) layer designed to enhance the decomposition capabilities of the TPRbased models. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 22}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: This paper discusses the limitations of the work performed by the authors in Section 5, as follows. The model introduced in this paper requires additional computational overhead and configuration search when the proposed model is integrated into the existing baseline models. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 22}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: This paper does not include theoretical results. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 23}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: This paper discloses all the information needed to reproduce the experimental results. This paper explains the mechanism of the proposed model and how it is applied to existing baseline models in Section 3 and presents the experiment details and hyperparameter settings in Appendices A and B. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 23}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 24}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: This paper provides supplementary materials to reproduce all experimental results of the proposed method, including source codes about our model implementation, data processing, scripts for execution, etc. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 24}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: This paper presents our experiment details and hyper-parameter settings in Appendices A and B. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 24}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: This paper reports the mean and standard deviation values in the experimental results conducted using fixed 10 different random seeds. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 25}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: This paper provides the computer resources used in our experiments and the time it took to learn each task in Appendix A. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 25}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The research conducted in this paper conforms to the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 25}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: The authors do not foresee a negative societal impact on the work presented in this paper beyond the general effects of ML advancements. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 26}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not have a high risk for misuse. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 26}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper cites the original paper that produced the code package or dataset, and includes URLs in Appendix A. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. ", "page_idx": 26}, {"type": "text", "text": "\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 27}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper provides supplementary materials with source code, license, and README.md files. The README.md files cite the code packages utilized in this paper and provide all the instructions to reproduce the experimental results. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 27}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 27}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 27}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 28}]