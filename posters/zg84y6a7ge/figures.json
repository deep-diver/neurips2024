[{"figure_path": "ZG84y6a7ge/figures/figures_1_1.jpg", "caption": "Figure 1: A simple overall diagram of the proposed alternate slimming process.", "description": "This figure illustrates the alternate slimming framework used in SlimSAM.  It shows the original heavyweight image encoder of SAM being progressively compressed in two stages. First, embedding pruning removes redundant parameters from the embedding dimensions, followed by bottleneck aligning which minimizes divergence from the original model using a loss function that considers the bottleneck dimensions. Next, bottleneck pruning reduces parameters in the bottleneck dimensions, and embedding aligning refines the model using a loss function focused on the embedding dimensions. The final result is a lightweight image encoder.", "section": "3 Methods"}, {"figure_path": "ZG84y6a7ge/figures/figures_4_1.jpg", "caption": "Figure 2: The provided figure depicts our alternate slimming process with a 50% pruning ratio on SAM-B. We utilize structural pruning at the channel-wise group level to compress SAM's image encoder, coupled with knowledge distillation from intermediate layers to restore the pruned encoder. The red numbers highlight the pruned dimensions at each pruning step.", "description": "This figure illustrates the proposed alternate slimming framework for compressing the SAM-B model. It shows a step-by-step process of alternately pruning and distilling distinct, decoupled sub-structures (embedding and bottleneck dimensions) within the image encoder.  The pruning is done at the channel-wise group level, and knowledge distillation from intermediate layers helps restore performance after pruning. Red numbers indicate the pruned dimensions at each step.", "section": "3.2 Alternate Slimming"}, {"figure_path": "ZG84y6a7ge/figures/figures_7_1.jpg", "caption": "Figure 3: Training results on SA-1B with the common one-step method and our alternate slimming framework. Left and right are results with disturbed Taylor importance and random importance.", "description": "This figure compares the training performance (measured by mean IoU) of the proposed alternate slimming framework against the conventional one-step method.  Two sub-figures are shown, one for each importance estimation method used: disturbed Taylor importance and random importance. The x-axis represents the number of training epochs, and the y-axis represents the mean IoU.  The alternate slimming framework consistently shows better performance than the one-step approach, demonstrating the effectiveness of the proposed method in enhancing knowledge retention and achieving superior performance under limited data.", "section": "4 Experiments"}, {"figure_path": "ZG84y6a7ge/figures/figures_7_2.jpg", "caption": "Figure 4: The intermediate dimensions of QVK Attention (top row) and MLP (bottom row) within each ViT after pruning. We present the outcomes of local pruning and global pruning under five distinct normalization methods.", "description": "This figure shows the intermediate dimensions of QKV Attention and MLP within each ViT of the image encoder after applying different pruning methods (local and global).  Five different normalization methods (mean, max, sum, Gaussian, and standardization) were used for global pruning, and their effects on the resulting dimensions are displayed for comparison.", "section": "4 Experiments"}, {"figure_path": "ZG84y6a7ge/figures/figures_9_1.jpg", "caption": "Figure 5: Comparison of segmentation results using segment everything prompts", "description": "This figure compares the segmentation results of different methods on various images using \"segment everything\" prompts.  It shows the original SAM-H results alongside results from SlimSAM-50, SlimSAM-77, EdgeSAM, EfficientSAM, MobileSAM, and FastSAM. The comparison highlights the differences in segmentation accuracy and detail between the different methods.  SlimSAM models show promising results compared to the other methods and the original SAM-H model.", "section": "4.2 Comparision and Analysis"}, {"figure_path": "ZG84y6a7ge/figures/figures_9_2.jpg", "caption": "Figure 11: Comparison of segmentation results using point prompts", "description": "This figure compares the segmentation results obtained from several different models (SAM-H, SlimSAM-50, SlimSAM-77, EdgeSAM, EfficientSAM, MobileSAM, and FastSAM) when using point prompts.  The goal is to show a qualitative comparison of the models' performance on a variety of images and scenarios.", "section": "4.2 Comparision and Analysis"}, {"figure_path": "ZG84y6a7ge/figures/figures_15_1.jpg", "caption": "Figure 4: The intermediate dimensions of QVK Attention (top row) and MLP (bottom row) within each ViT after pruning. We present the outcomes of local pruning and global pruning under five distinct normalization methods.", "description": "This figure visualizes the intermediate dimensions (QKV Attention and MLP) of each Vision Transformer (ViT) block within the image encoder after applying different pruning strategies.  It compares local pruning with global pruning performed using five different normalization techniques (mean, max, sum, Gaussian, and standardization) to illustrate how the choice of pruning method and normalization impacts the resulting dimension distribution across the ViT blocks.", "section": "4 Experiments"}, {"figure_path": "ZG84y6a7ge/figures/figures_15_2.jpg", "caption": "Figure 8: Training results on SA-1B with common one-step strategy and our alternate slimming strategy.", "description": "This figure compares the training performance (measured by MIoU) of the proposed alternate slimming method against a standard one-step pruning and distillation approach. The alternate slimming method shows significantly better performance in terms of MIoU across training epochs, highlighting its effectiveness in improving knowledge retention and model performance during the compression process.", "section": "4 Experiments"}, {"figure_path": "ZG84y6a7ge/figures/figures_18_1.jpg", "caption": "Figure 9: Comparison of segmentation results using segment everything prompts", "description": "This figure compares the segmentation results of different models on various images using the \"segment everything\" prompt.  The models compared include SAM-H (the original, heavy model), SlimSAM-50 (SlimSAM with 50% pruning ratio), SlimSAM-77 (SlimSAM with 77% pruning ratio), EdgeSAM, EfficientSAM, MobileSAM, and FastSAM. The images show that SlimSAM achieves comparable performance to the original SAM-H while requiring significantly less data and computation. ", "section": "4.2 Comparision and Analysis"}, {"figure_path": "ZG84y6a7ge/figures/figures_19_1.jpg", "caption": "Figure 10: Comparison of segmentation results using box prompts", "description": "This figure compares the segmentation results of different methods, including SlimSAM, using box prompts.  The results show the segmentation masks generated by each method for a set of images, allowing for a visual comparison of their performance. Red boxes indicate the box prompts used for the segmentation.", "section": "4.2 Comparision and Analysis"}, {"figure_path": "ZG84y6a7ge/figures/figures_20_1.jpg", "caption": "Figure 11: Comparison of segmentation results using point prompts", "description": "This figure compares the segmentation results of different models (SAM-H, SlimSAM-50, SlimSAM-77, EdgeSAM, EfficientSAM, MobileSAM, and FastSAM) on various images using point prompts.  It visually demonstrates the performance of SlimSAM compared to other state-of-the-art models on different image types and scenarios.", "section": "4.2 Comparision and Analysis"}]