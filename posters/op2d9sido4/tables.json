[{"figure_path": "OP2D9sIdo4/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of function-level VD of  and  on . P: Precision(%); R: Recall(%); F1: F1-score(%)", "description": "This table presents the results of function-level vulnerability detection experiments using various methods, including Cppcheck, Flawfinder, and more advanced deep learning approaches like VulCNN and KF-GVD.  The performance metrics (Precision, Recall, and F1-score) are compared across different modules (Fs, Drivers, Net, Include) for two target tasks (Tm119 and Tsub) using the S119 source task dataset. The table allows assessing the relative effectiveness of various vulnerability detection methods and their ability to generalize performance across diverse code modules and subtypes.", "section": "4.2 Function-level Vulnerability Detection Performance"}, {"figure_path": "OP2D9sIdo4/tables/tables_6_2.jpg", "caption": "Table 2: Comparison of function-level VD of Tm416 on S416. P: Precision(%); R: Recall(%); F1: F1-score(%)", "description": "This table presents the results of function-level vulnerability detection experiments on the target task Tm416 (CWE-416 vulnerabilities in various modules of the Linux kernel) using the source task dataset S416 (CWE-416 vulnerabilities). It compares the performance of KF-GVD with several baseline methods (Cppcheck, Flawfinder, Sysver, VulCNN, Codebert, CodeLlama, Wizardcoder, Devign, ReGVD, IVDetect, GVD-ft) across different modules (Fs, Net, Drivers, Kernel, Block, Include).  The evaluation metrics used are Precision (P), Recall (R), and F1-score (F1), all expressed as percentages.", "section": "4.2 Function-level Vulnerability Detection Performance"}, {"figure_path": "OP2D9sIdo4/tables/tables_7_1.jpg", "caption": "Table 3: Comparison of statement-level VD of Tm119 and Tsub on S119. P: Precision(%); R:Recall(%); F1: F1-score(%)", "description": "This table presents the results of statement-level vulnerability detection (VD) experiments. It compares the performance of several methods (IVDetect, LineVD, LineVul, GVD-ft, and KF-GVD) on two target tasks (Tm119 and Tsub) using the S119 dataset as a source task. The table shows precision (P), recall (R), and F1-score (F) for each method on different modules (Fs, Drivers, Net, Include) and CWE subtypes (CWE-125 and CWE-787).  The metrics assess the effectiveness of the methods at locating vulnerabilities at the statement level within the code.", "section": "4.3 Statement-level Vulnerability Detection Performance"}, {"figure_path": "OP2D9sIdo4/tables/tables_7_2.jpg", "caption": "Table 2: Comparison of function-level VD of Tm416 on S416. P: Precision(%); R: Recall(%); F1: F1-score(%)", "description": "This table presents the results of function-level vulnerability detection (VD) experiments for the target task Tm416 (detecting CWE-416 vulnerabilities in various Linux kernel modules) using the source task dataset S416.  It compares the performance of KF-GVD against several baseline methods, including Cppcheck, Flawfinder, Sysver, VulCNN, Codebert, CodeLlama, Wizardcoder, Devign, ReGVD, IVDetect, and GVD-ft. The metrics used are Precision (P), Recall (R), and F1-score (F1), all expressed as percentages.  The table provides a breakdown of results for each of the Linux kernel modules: Net, Fs, Drivers, Kernel, Block, and Include.", "section": "4.2 Function-level Vulnerability Detection Performance"}, {"figure_path": "OP2D9sIdo4/tables/tables_8_1.jpg", "caption": "Table 5: Undisclosed vulnerabilities detected by KF-GVD in different C++ open-source objects.", "description": "This table lists 9 undisclosed vulnerabilities discovered by the KF-GVD model in various open-source C++ projects.  Each row represents a unique vulnerability, providing its CNNVD ID, the project it was found in, the specific file and line number where the vulnerability resides. This demonstrates the model's ability to find previously unknown vulnerabilities.", "section": "4.4 Case Study"}, {"figure_path": "OP2D9sIdo4/tables/tables_14_1.jpg", "caption": "Table 6: Dataset statistics", "description": "This table presents the statistics of four different datasets used in the paper's experiments.  The datasets are categorized as source tasks (S<sub>119</sub> and S<sub>416</sub>) and target tasks (T<sub>m</sub> and T<sub>sub</sub>). For each dataset, the table shows the number of code files, the ratio of vulnerable to non-vulnerable code samples (Vul: Non-Vul), and the label granularity used (Function or Function, statement, indicating whether the vulnerability labels are assigned at the function level or also at the statement level).", "section": "4.1 Experiment Settings"}, {"figure_path": "OP2D9sIdo4/tables/tables_15_1.jpg", "caption": "Table 7: Parameter settings", "description": "This table shows the hyperparameters used for the Word2Vec model and the Graph Neural Networks (GNNs) in the KF-GVD framework.  It specifies settings for parameters like minimum count, size, window, embedding dimension, hidden dimension, activation function, learning rate, optimizer, and the train/validation/test data split ratio.", "section": "4.1 Experiment Settings"}, {"figure_path": "OP2D9sIdo4/tables/tables_16_1.jpg", "caption": "Table 8: Results of applying the models trained on Tm119 and Tsub to S119.", "description": "This table presents the results of applying models trained on specific target tasks (Tm119 and Tsub) to their corresponding source task (S119).  It demonstrates the model's generalization capabilities and shows the performance differences between models trained for specific subtasks versus the general model.  The final row, 'AD', indicates the average differences in precision (P), recall (R), and F1-score (F) between the models trained on the target tasks and the models initially trained only on the source task.", "section": "4.3 Statement-level Vulnerability Detection Performance"}, {"figure_path": "OP2D9sIdo4/tables/tables_16_2.jpg", "caption": "Table 2: Comparison of function-level VD of Tm416 on S416. P: Precision(%); R: Recall(%); F1: F1-score(%)", "description": "This table presents the results of function-level vulnerability detection (VD) for target task Tm416 (detecting CWE-416 vulnerabilities in various modules of the Linux kernel) using the source task dataset S416.  It compares the performance of KF-GVD against several baseline methods (Cppcheck, Flawfinder, Sysver, VulCNN, Codebert, CodeLlama, Wizardcoder, Devign, ReGVD, IVDetect, and GVD-ft). The metrics used for comparison are Precision (P), Recall (R), and F1-score (F1).  The table shows the performance across different modules of the Linux kernel: Fs, Net, Drivers, Kernel, Block, and Includes.", "section": "4.2 Function-level Vulnerability Detection Performance"}, {"figure_path": "OP2D9sIdo4/tables/tables_17_1.jpg", "caption": "Table 9: F1-score (%) comparison of VD through the fusion of different vulnerability knowledge on the target tasks corresponding to S119.", "description": "This table presents the results of function-level vulnerability detection (VD) experiments on the target tasks (Tm119 and Tsub) corresponding to the source task S119. It compares the performance of the general-purpose VD model (GVD) with different combinations of vulnerability knowledge (K1 and K2) integrated into the model.  K1 represents knowledge about vulnerable program operations and sensitive functions relevant to the vulnerability type. K2 represents customized knowledge for specific tasks related to the target functional scenarios. The table shows the F1-scores for each target task and module (Fs, Drivers, Net, Include), as well as for specific CWE subtypes (CWE-125 and CWE-787).  The results demonstrate the impact of integrating specific vulnerability knowledge on the model's performance.", "section": "4.3 Statement-level Vulnerability Detection Performance"}, {"figure_path": "OP2D9sIdo4/tables/tables_17_2.jpg", "caption": "Table 10: F1-score (%) comparison of VD using different graph representations on S119 and its corresponding target tasks.", "description": "This table presents the F1-scores achieved by the vulnerability detection (VD) method using different graph representations (CFG, PDG, CPG) on the source task S119 and its corresponding target tasks (Tm119 and Tsub).  It demonstrates the impact of the choice of graph representation on the performance of the VD method across various modules (Fs, Drivers, Net, Include) and CWE subtypes (CWE-125, CWE-787). The CPG representation consistently outperforms CFG and PDG, highlighting its effectiveness in capturing comprehensive vulnerability information for improved VD performance.", "section": "D.2 Feature Representation Sensitivity Analysis"}, {"figure_path": "OP2D9sIdo4/tables/tables_17_3.jpg", "caption": "Table 11: F1-score (%) comparison of VD using different embedding models on S<sub>119</sub> and its corresponding target tasks.", "description": "This table presents the results of vulnerability detection (VD) experiments using different embedding models: Code2Vec, Code2Seq, and Word2Vec.  The F1-score, a metric combining precision and recall, is reported for the source task (S<sub>119</sub>) and several target tasks (T<sub>m119</sub> and T<sub>sub</sub>). The target tasks represent different subsets of the Linux kernel (Fs, Drivers, Net, Include) and specific vulnerability subtypes (CWE-125, CWE-787). The table helps to assess the impact of different embedding models on the effectiveness of the KF-GVD approach in various scenarios.", "section": "D.2 Feature Representation Sensitivity Analysis"}, {"figure_path": "OP2D9sIdo4/tables/tables_18_1.jpg", "caption": "Table 12: F1-score (%) comparison of VD on cross-domain tasks.", "description": "This table presents the results of cross-domain vulnerability detection experiments. Six different cross-domain tasks (L->F, L->O, F->L, F->O, O->L, O->F) were performed using seven different vulnerability detection methods. The F1-score, a metric that balances precision and recall, is used to evaluate the performance of each method on each task. The results show the relative effectiveness of the different methods across various domains.", "section": "4.2 Function-level Vulnerability Detection Performance"}]