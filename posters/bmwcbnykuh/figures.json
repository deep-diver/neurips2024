[{"figure_path": "BmwcbNYkuH/figures/figures_3_1.jpg", "caption": "Figure 1: We pass the input image (or, with 0.5 probability, input image multiplied with its nuclear segmentation mask) and its nuclear segmentation mask through the network and minimise the Binary Cross-Entropy (BCE) loss for both the input image and its mask. Additionally, we minimise the l2-distance between the input image\u2019s embedding vector and the mask\u2019s embedding vector just before the Global Average Pooling (GAP) layer. The embedding vector is ResNet-50\u2019s penultimate layer\u2019s feature map, i.e., stage 4\u2019s last feature map.", "description": "The figure illustrates the proposed method's architecture.  An input image is passed through a ResNet-50 model (without GAP and classification layers), along with its corresponding nuclear segmentation mask. The model calculates the BCE loss for both the image and mask.  Additionally, it calculates the Euclidean distance between the image's embedding vector and mask's embedding vector. The total loss is the sum of these two losses.", "section": "3 Proposed Method"}, {"figure_path": "BmwcbNYkuH/figures/figures_7_1.jpg", "caption": "Figure 1: We pass the input image (or, with 0.5 probability, input image multiplied with its nuclear segmentation mask) and its nuclear segmentation mask through the network and minimise the Binary Cross-Entropy (BCE) loss for both the input image and its mask. Additionally, we minimise the l2-distance between the input image\u2019s embedding vector and the mask\u2019s embedding vector just before the Global Average Pooling (GAP) layer. The embedding vector is ResNet-50\u2019s penultimate layer\u2019s feature map, i.e., stage 4\u2019s last feature map.", "description": "This figure illustrates the proposed method's architecture.  The input is either an H&E stained image or that same image multiplied by its nuclear segmentation mask (with 50% probability). Both the image and the mask are passed through a ResNet-50 network (without GAP and classification layers). The network produces embedding vectors for both the image and the mask. The method minimizes the Binary Cross-Entropy (BCE) loss for both inputs and the Euclidean distance between their embedding vectors. This encourages the network to learn features that are shared by the original image and the mask, prioritizing the nuclei.", "section": "3 Proposed Method"}, {"figure_path": "BmwcbNYkuH/figures/figures_8_1.jpg", "caption": "Figure 1: We pass the input image (or, with 0.5 probability, input image multiplied with its nuclear segmentation mask) and its nuclear segmentation mask through the network and minimise the Binary Cross-Entropy (BCE) loss for both the input image and its mask. Additionally, we minimise the l2-distance between the input image's embedding vector and the mask's embedding vector just before the Global Average Pooling (GAP) layer. The embedding vector is ResNet-50's penultimate layer's feature map, i.e., stage 4's last feature map.", "description": "The figure illustrates the proposed method's architecture.  An input image (with a 50% chance of being multiplied by its corresponding nuclear segmentation mask) and the mask itself are fed into a ResNet-50 network. The network outputs embedding vectors for both the image and the mask. The method minimizes both the Binary Cross-Entropy (BCE) loss for image and mask classification and the L2 distance between the embedding vectors, encouraging alignment between image and mask representations.", "section": "3 Proposed Method"}, {"figure_path": "BmwcbNYkuH/figures/figures_9_1.jpg", "caption": "Figure 1: We pass the input image (or, with 0.5 probability, input image multiplied with its nuclear segmentation mask) and its nuclear segmentation mask through the network and minimise the Binary Cross-Entropy (BCE) loss for both the input image and its mask. Additionally, we minimise the l2-distance between the input image's embedding vector and the mask's embedding vector just before the Global Average Pooling (GAP) layer. The embedding vector is ResNet-50's penultimate layer's feature map, i.e., stage 4's last feature map.", "description": "This figure illustrates the proposed method's architecture.  The input is either the original image or the original image multiplied by its nuclear segmentation mask (with 50% probability for each). Both the image and the mask are passed through a ResNet-50 network. The network outputs embedding vectors for both. The loss function minimizes both the binary cross-entropy between the network's predictions and ground truth for both the image and the mask, and also the Euclidean distance between the two embedding vectors.  This approach encourages the network to learn features that align between the original image and its mask, prioritizing nuclear morphology.", "section": "3 Proposed Method"}, {"figure_path": "BmwcbNYkuH/figures/figures_24_1.jpg", "caption": "Figure 1: We pass the input image (or, with 0.5 probability, input image multiplied with its nuclear segmentation mask) and its nuclear segmentation mask through the network and minimise the Binary Cross-Entropy (BCE) loss for both the input image and its mask. Additionally, we minimise the l2-distance between the input image's embedding vector and the mask's embedding vector just before the Global Average Pooling (GAP) layer. The embedding vector is ResNet-50's penultimate layer's feature map, i.e., stage 4's last feature map.", "description": "The figure illustrates the proposed method's architecture.  An input image (or the image multiplied by its nuclear segmentation mask with 50% probability) and its corresponding mask are fed into a ResNet-50 network. The network generates embedding vectors for both the image and mask. The method minimizes the Binary Cross-Entropy (BCE) loss for both the image and the mask, and also minimizes the L2 distance between the embedding vectors. This encourages the network to learn features from both the image and mask that are related to the nuclei and helps to improve out-of-domain generalization.", "section": "3 Proposed Method"}, {"figure_path": "BmwcbNYkuH/figures/figures_25_1.jpg", "caption": "Figure 1: We pass the input image (or, with 0.5 probability, input image multiplied with its nuclear segmentation mask) and its nuclear segmentation mask through the network and minimise the Binary Cross-Entropy (BCE) loss for both the input image and its mask. Additionally, we minimise the l2-distance between the input image's embedding vector and the mask's embedding vector just before the Global Average Pooling (GAP) layer. The embedding vector is ResNet-50's penultimate layer's feature map, i.e., stage 4's last feature map.", "description": "The figure illustrates the proposed method's architecture.  The input image (or, with 50% probability, the image multiplied by its nuclear segmentation mask) and its corresponding mask are fed into a ResNet-50 network. The network outputs embedding vectors for both the image and the mask, and the method minimizes the Binary Cross-Entropy loss for both, as well as the L2 distance between the two embedding vectors. This encourages the network to focus on the features present in the nuclear masks, improving out-of-domain generalization.", "section": "3 Proposed Method"}, {"figure_path": "BmwcbNYkuH/figures/figures_26_1.jpg", "caption": "Figure 1: We pass the input image (or, with 0.5 probability, input image multiplied with its nuclear segmentation mask) and its nuclear segmentation mask through the network and minimise the Binary Cross-Entropy (BCE) loss for both the input image and its mask. Additionally, we minimise the l2-distance between the input image's embedding vector and the mask's embedding vector just before the Global Average Pooling (GAP) layer. The embedding vector is ResNet-50's penultimate layer's feature map, i.e., stage 4's last feature map.", "description": "The figure illustrates the proposed method's architecture.  An input image, optionally multiplied by its nuclear segmentation mask, and the corresponding mask are fed into a ResNet-50 network. The network generates embeddings for both the image and mask.  The model minimizes the Binary Cross-Entropy loss for both inputs and also minimizes the L2 distance between the image and mask embeddings. This encourages the network to focus on nuclear morphology and organization.", "section": "3 Proposed Method"}]