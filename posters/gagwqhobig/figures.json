[{"figure_path": "gAgwqHOBIg/figures/figures_0_1.jpg", "caption": "Figure 1: Diffusion-based processes. (a) Probabilistic diffusion process [1], where q(\u00b7) is noise sampling and pe (\u00b7) is denoising. (b) Diffusion process in the 2D coordinate space [2, 3, 4]. (c) A purely visual diffusion-based data prediction approach reconstructs the subsequent video frame. (d) Our proposed data interpolation approach DINTR interpolates between two consecutive video frames, indexed by timestamp t, allowing a seamless temporal transition for visual content understanding, temporal modeling, and instance extracting for the object tracking task across various indications (e).", "description": "This figure illustrates different diffusion-based processes used in object tracking. (a) shows a standard probabilistic diffusion process. (b) demonstrates a diffusion process operating in 2D coordinate space, commonly used in existing tracking methods. (c) depicts a visual diffusion approach for video frame prediction. (d) introduces the authors' proposed DINTR method, which performs interpolation between consecutive frames for improved temporal understanding and object tracking. (e) shows various object representations (points, bounding boxes, segments, and text) that DINTR can handle for object tracking.", "section": "Introduction"}, {"figure_path": "gAgwqHOBIg/figures/figures_5_1.jpg", "caption": "Figure 2: Illustration of the reconstruction and interpolation processes, where the purple dashed arrow is q(z|z\u2080) and the purple solid arrow is p\u03b8(z\u209c\u208a\u2081|z\u209c), while the blue arrow illustrates p\u03d5(z\u209c\u208a\u2081|z\u2080).", "description": "This figure illustrates the two core processes of the DINTR model: reconstruction and interpolation.  The reconstruction process (purple arrows) involves a standard diffusion process where noise is added to the latent representation (z\u2080) and then gradually removed through denoising steps to reconstruct a clean image. The interpolation process (blue arrow) utilizes a novel mechanism that directly interpolates between two consecutive latent representations (z\u2080 and z\u2080\u209c\u208a\u2081) to predict the next frame's latent representation.  This interpolation is designed to be more efficient and stable than traditional diffusion-based approaches.", "section": "4.3 DINTR for Tracking via Diffusion-based Interpolation"}, {"figure_path": "gAgwqHOBIg/figures/figures_20_1.jpg", "caption": "Figure B.3: The conditional LDMs utilizes U-Net [104] blocks. First, a clean image Ik is converted to a noisy latent zk via the noise sampling process Q(\u00b7) (top branch). Then, well-structured regions are reconstructed from that extremely noisy input via the denoising/reconstruction process P\u025b (\u00b7) (bottom branch). Additionally, conditions can be added as indicators of the regions of interest. While the figure style is adapted from LDMs [13], we made a distinct change reflecting the injected sampling process, following Prompt-to-Prompt [141].", "description": "This figure illustrates the architecture of the conditional latent diffusion model (LDM) used in the paper. It shows how a clean image is converted into a noisy latent representation, then how this noisy representation is denoised and reconstructed into a clean image with well-structured regions, guided by conditional indicators.  This process is detailed, showing the different blocks and branches involved. The figure highlights the key components of the LDM, such as the U-Net, the noise sampling and denoising processes, and the injection of conditions.", "section": "Overall Framework"}, {"figure_path": "gAgwqHOBIg/figures/figures_20_2.jpg", "caption": "Figure B.4: Our proposed autoregressive framework constructed via the diffusion mechanics for temporal modeling. The current frame is input to the encoder E(It) to produce an initial latent z0. The sampling process Q(\u00b7) adds noises into the latent in a sequence of T steps. Next, reconstruction process P\u025b(\u00b7) is manipulated through KL divergence optimization w.r.t. zt+1. This shapes the reconstructed image \u00cet+1 to be more similar to the future frame It+1. Finally, the location of the targets can be extracted by spatial correspondences, exhibited by the attention maps \u0100s and \u0100x.", "description": "This figure illustrates the autoregressive framework of DINTR for temporal modeling. It shows how the current frame's features are encoded into a latent representation, noise is added iteratively, and the reconstruction process is guided to approximate the next frame.  Finally, object locations are extracted using attention maps.", "section": "B Overall Framework"}, {"figure_path": "gAgwqHOBIg/figures/figures_25_1.jpg", "caption": "Figure 1: Diffusion-based processes. (a) Probabilistic diffusion process [1], where q(\u00b7) is noise sampling and pe (\u00b7) is denoising. (b) Diffusion process in the 2D coordinate space [2, 3, 4]. (c) A purely visual diffusion-based data prediction approach reconstructs the subsequent video frame. (d) Our proposed data interpolation approach DINTR interpolates between two consecutive video frames, indexed by timestamp t, allowing a seamless temporal transition for visual content understanding, temporal modeling, and instance extracting for the object tracking task across various indications (e).", "description": "This figure illustrates different diffusion-based processes used for object tracking. (a) Shows a general probabilistic diffusion process. (b) Shows a diffusion process operating on 2D coordinates. (c) Illustrates a visual diffusion approach that predicts the next frame. (d) Shows the proposed DINTR approach which interpolates between consecutive frames, enabling smooth temporal transitions and facilitating object tracking across diverse indications, shown in (e).", "section": "1 Introduction"}, {"figure_path": "gAgwqHOBIg/figures/figures_26_1.jpg", "caption": "Figure 1: Diffusion-based processes. (a) Probabilistic diffusion process [1], where q(\u00b7) is noise sampling and pe (\u00b7) is denoising. (b) Diffusion process in the 2D coordinate space [2, 3, 4]. (c) A purely visual diffusion-based data prediction approach reconstructs the subsequent video frame. (d) Our proposed data interpolation approach DINTR interpolates between two consecutive video frames, indexed by timestamp t, allowing a seamless temporal transition for visual content understanding, temporal modeling, and instance extracting for the object tracking task across various indications (e).", "description": "This figure illustrates different diffusion-based processes.  (a) Shows a standard probabilistic diffusion process with noise sampling and denoising. (b) Shows a diffusion process operating in 2D coordinate space, commonly used for object tracking. (c) Demonstrates a visual diffusion method to predict the next frame in a video sequence. Finally, (d) introduces the authors' proposed DINTR approach which interpolates between consecutive video frames to enable object tracking across various representations (e).", "section": "1 Introduction"}]