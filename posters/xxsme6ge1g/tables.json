[{"figure_path": "XxSME6GE1G/tables/tables_2_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted to evaluate the performance of TAIA across various large language models (LLMs), training datasets, and fine-tuning methods. It shows the accuracy achieved on seven downstream tasks (MATH, BBH, CQA, LogiQA, SVAMP, MMB, MMLU) by different models trained using two distinct corpora (Alpaca-GPT4 and CoT-Collection) and two fine-tuning techniques (LoRA and MoLoRA). For each setting, three inference approaches were evaluated: Vanilla (full fine-tuning), TAIA (training all parameters but inferring only with attention), and the baseline model. The table highlights the optimal and suboptimal results for each subgroup and shows that TAIA generally achieves the best results across various settings.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_5_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted on various LLMs using two different training datasets (Alpaca-GPT4 and CoT-Collection).  Four different LLMs were used, and each was fine-tuned using two different methods (LoRA and MoLoRA) with two different inference modes (Vanilla and TAIA). The performance is evaluated across seven different downstream tasks assessing reasoning and knowledge capabilities. The table highlights the optimal performance achieved by TAIA in most scenarios.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_6_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted on seven downstream tasks using four different base language models (LLMs) and two fine-tuning techniques (LoRA and MoLoRA). The experiments are performed using two different training corpora (Alpaca-GPT4 and CoT-Collection). The table shows the performance of the baseline model (no fine-tuning), vanilla fine-tuning, and TAIA across various evaluation metrics. The bold values highlight the optimal performance for each subgroup of models, datasets, and fine-tuning methods. The underlined values show suboptimal results, while TAIA generally shows superior results across a wide range of tasks and models.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_7_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted on seven different downstream tasks (MATH, BBH, CQA, LogiQA, SVAMP, MMB, and MMLU) using four different base LLMs (Qwen1.5-1.8B, Qwen1.5-7B, LLaMA2-7B, and LLaMA3-8B).  Two different training datasets (Alpaca-GPT4 and CoT-Collection) and two different fine-tuning methods (LoRA and MoLoRA) were used. The table compares the performance of the vanilla fine-tuning method with TAIA. Bold values indicate the best performing method for each subgroup, while underlined values indicate the second-best performing method.  The results show TAIA generally achieves better fine-tuning results.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_8_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted using two different training corpora (Alpaca and CoT-Collection) and four different base LLMs (Qwen1.5-1.8B, Qwen1.5-7B, LLaMA2-7B, and LLaMA3-8B).  It shows the performance of various fine-tuning methods (vanilla fine-tuning, LoRA, and MoLoRA) and TAIA on seven downstream tasks across different categories (Reasoning, Knowledge, and Math). The table helps to demonstrate the effectiveness and robustness of TAIA across various model sizes and fine-tuning techniques, particularly when dealing with limited or mismatched data.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_8_2.jpg", "caption": "Table 5: Comparison of TAIA with vanilla fine-tuning on red-teaming resistance. When jailbreaking LLMs on harmful datasets, TAIA harvests lower attack success rates than vanilla fine-tuning on both harmful and benign datasets, showing its strong generalization in distilling out harmful features.", "description": "This table presents the results of a red-teaming experiment comparing TAIA and vanilla fine-tuning methods. The experiment aimed to evaluate the robustness of the methods against adversarial attacks. The results show that TAIA, in comparison to vanilla fine-tuning, resulted in lower attack success rates across different types of attacks. This indicates that TAIA is more effective in filtering out harmful features and improving the safety and helpfulness of the language model.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_17_1.jpg", "caption": "Table 6: Experiments on two tasks whose knowledge is not fully acquired by base LLMs. TAIA lags behind vanilla fine-tuning methods by a small margin for Qwen1.5-1.8B. However, for the base model with sufficient knowledge like Qwen1.5-7B, TAIA surpasses the vanilla fine-tuning methods.", "description": "This table compares the performance of vanilla fine-tuning and TAIA on two tasks (SQUAD v2.0 and XSum) where the base LLMs may not have sufficient knowledge.  It shows that while TAIA sometimes slightly underperforms vanilla fine-tuning on smaller models, it significantly outperforms vanilla fine-tuning on larger models where the base models already have a good understanding of the tasks. This highlights TAIA's effectiveness when the base model already possesses relevant knowledge.", "section": "Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_20_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments comparing different fine-tuning methods (Vanilla, LoRA, MoLoRA, and TAIA) on seven downstream tasks using four different base LLMs (Qwen1.5-1.8B, Qwen1.5-7B, LLaMA2-7B, LLaMA3-8B) and two training datasets (Alpaca-GPT4, CoT-Collection). The table shows the performance (accuracy) of each method on each task, highlighting the best-performing method (in bold) for each LLM and dataset combination.  The results demonstrate that TAIA often outperforms other methods, particularly when fine-tuning on data that is not perfectly aligned with the test set.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_21_1.jpg", "caption": "Table 8: Data mixture ablation on the OOD data ratio. We compare vanilla LoRA tuning with TAIA on two mixture strategies: uniform mixture and linear annealing mixture. TAIA achieves best performance under both settings.", "description": "This table presents an ablation study on the impact of different out-of-distribution (OOD) data mixing strategies on the performance of vanilla LoRA tuning and the proposed TAIA method.  Two data mixing schedules are compared: uniform mixing and linear annealing.  For each schedule, the table shows the performance of both methods across four different ratios of OOD data (20K, 40K, 60K, 80K).  The results demonstrate that TAIA consistently outperforms vanilla LoRA under both mixing strategies and across all OOD data ratios. ", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_21_2.jpg", "caption": "Table 8: Data mixture ablation on the OOD data ratio. We compare vanilla LoRA tuning with TAIA on two mixture strategies: uniform mixture and linear annealing mixture. TAIA achieves best performance under both settings.", "description": "This table presents an ablation study on the impact of different out-of-distribution (OOD) data mixing strategies on the performance of TAIA and vanilla LoRA tuning. Two data mixing strategies are compared: uniform and linear annealing.  The results show the performance of each method across various OOD data ratios (20k, 40k, 60k, 80k).", "section": "F.4 More Discussion on ID/OOD Data"}, {"figure_path": "XxSME6GE1G/tables/tables_22_1.jpg", "caption": "Table 8: Data mixture ablation on the OOD data ratio. We compare vanilla LoRA tuning with TAIA on two mixture strategies: uniform mixture and linear annealing mixture. TAIA achieves best performance under both settings.", "description": "This table presents the results of an ablation study comparing the performance of TAIA and vanilla LoRA tuning under different out-of-distribution (OOD) data mixing strategies.  Two strategies were used: uniform mixing and linear annealing. The results show that TAIA consistently outperforms vanilla LoRA tuning across various OOD data ratios, regardless of the mixing strategy.", "section": "Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_22_2.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted using two different training corpora (Alpaca-GPT4 and CoT-Collection) and four different base LLMs (Qwen1.5-1.8B, Qwen1.5-7B, LLaMA2-7B, LLaMA3-8B).  The experiments evaluated performance across seven downstream tasks, comparing vanilla fine-tuning (Vanilla), LoRA, and MoLoRA against TAIA.  Results are shown in terms of average accuracy across the seven tasks, with bold indicating the best performing method in each subgroup and underlined indicating suboptimal performance.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_22_3.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted on seven different downstream tasks using four distinct LLMs (Qwen1.5-1.8B, Qwen1.5-7B, LLaMA2-7B, LLaMA3-8B).  Two different fine-tuning methods (LoRA and MoLoRA) and two training corpora (Alpaca and CoT Collection) were employed. The table displays the average accuracy across these tasks for each model, fine-tuning method, and training corpus, comparing the performance of vanilla fine-tuning with the proposed TAIA method. Bold values indicate the best performance within each subgroup, and underlined values show the second-best. The table highlights the consistent superiority of TAIA across various settings.", "section": "Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_23_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments on seven downstream tasks using two training datasets (Alpaca-GPT4 and CoT-Collection) and four different base LLMs (Qwen1.5-1.8B, Qwen1.5-7B, LLaMA2-7B, and LLaMA3-8B).  It compares the performance of three fine-tuning methods: LoRA, MoLoRA, and TAIA.  For each model and method, the table shows accuracy scores for each task. The bold values indicate the best-performing method for each group of experiments.  The table demonstrates that TAIA generally outperforms other fine-tuning methods across different models and datasets.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_23_2.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted to assess the performance of the TAIA method across different models, fine-tuning methods, and datasets.  The experiments used four different base LLMs and two fine-tuning techniques (LoRA and MoLoRA) and evaluated the performance on seven downstream tasks. The table highlights which methods achieved optimal and suboptimal results. Note that the TAIA approach frequently yields the best performance.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_23_3.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted to assess the performance of the TAIA method. Four different base LLMs were fine-tuned using two different training corpora and two fine-tuning methods (LoRA and MoLoRA).  The performance of each model is evaluated across seven downstream tasks: MATH, BBH, CQA, LogiQA, SVAMP, MMB, and MMLU.  The table highlights the best and second-best performing methods for each model-corpus-method combination.  The results show that the TAIA method generally achieves optimal or near-optimal performance.", "section": "4 Experiments"}, {"figure_path": "XxSME6GE1G/tables/tables_28_1.jpg", "caption": "Table 1: Validation experiments using two training corpus and four seed backbones across seven test sets. \"CQA.\" refers to CommonsenseQA and \"MMB.\" refers to the English subset of MMedbench benchmark. \"FT Method\" denotes the fine-tuning method, which is either LoRA or MOLORA. Bold indicates the optimal result in each subgroup and underline indicates the suboptimal result. The TAIA setting achieves optimal fine-tuning results in most cases.", "description": "This table presents the results of validation experiments conducted using two training corpora (Alpaca-GPT4 and CoT-Collection) and four different base LLMs (Qwen1.5-1.8B, Qwen1.5-7B, LLaMA2-7B, and LLaMA3-8B).  The experiments evaluate the performance of three fine-tuning methods (Vanilla, LoRA, and MoLoRA) along with TAIA across seven downstream tasks (MATH, BBH, CQA, LogiQA, SVAMP, MMB, and MMLU).  The table highlights the best and second-best performing methods for each model and task, demonstrating TAIA's superiority in achieving optimal fine-tuning results.", "section": "4 Experiments"}]