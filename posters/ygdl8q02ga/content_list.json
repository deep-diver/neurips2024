[{"type": "text", "text": "Optimal Algorithms for Learning Partitions with Faulty Oracles ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Adela Frances DePavia Olga Medrano Mart\u00edn del Campo Erasmo Tani University of Chicago University of Chicago University of Chicago adepavia@uchicago.edu omedranomdelc@uchicago.edu etani@uchicago.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We consider a clustering problem where a learner seeks to partition a finite set by querying a faulty oracle. This models applications where learners crowdsource information from non-expert human workers or conduct noisy experiments to determine group structure. The learner aims to exactly recover a partition by submitting queries of the form \u201care $u$ and $v$ in the same group?\u201d for any pair of elements $u$ and $v$ in the set. Moreover, because the learner only has access to faulty sources of information, they require an error-tolerant algorithm for this task: i.e. they must fully recover the correct partition, even if up to $\\ell$ answers are incorrect, for some error-tolerance parameter $\\ell$ . We study the question: for any given error-tolerance $\\ell$ , what is the minimum number of queries needed to learn a finite set partition of $n$ elements into $k$ groups? We design algorithms for this task and prove that they achieve optimal query complexity. To analyze our algorithms, we first highlight a connection between this task and correlation clustering. We then use this connection to build a R\u00e9nyi-Ulam style analytical framework for this problem, which yields matching lower bounds. Our analysis also reveals an inherent asymmetry between the query complexity necessary to be robust against false negative errors as opposed to false positive errors. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Learning cluster structure from data is a fundamental task in machine learning. While the statistical setting is typically concerned with using batch data to approximately recover cluster structure with high probability, some applications allow for the learner to make explicit queries, and some require exact recovery guarantees. ", "page_idx": 0}, {"type": "text", "text": "We highlight two key settings. In several scientific domains, particularly bioinformatics, researchers conduct physical experiments to learn whether two objects are part of the same class [9, 11, 20, 35]. Another major application is learning cluster structure by collecting information from human workers via crowdsourcing services [15, 30, 37]. While some traditional methods focus on querying workers for class labels, alternative approaches use simpler same-cluster queries. For example, Vinayak and Hassibi [37] point out that, given images of birds, it may be easier for non-experts to correctly answer the question \u201cDo these two birds belong to the same species?\u201d as opposed to \u201cWhat species does this bird belong to?\u201d In both of these application domains, the learner typically seeks to minimize the number of queries made, as queries require carrying out potentially expensive measurements or time-consuming experiments. ", "page_idx": 0}, {"type": "text", "text": "We consider a very general setting and develop algorithms that make no assumptions about the specific type of data involved, but rather rely solely on the same-cluster queries to infer structure. In particular, we model this task by assuming that the algorithm only interfaces with the data via a same-cluster oracle. In this setting, the learner obtains information about a hidden partition $\\mathcal{C}$ of a finite set $V$ by repeatedly choosing two elements $u,v\\in V$ and asking questions of the form \u201cAre $u$ and $v$ part of the same cluster?\u201d, i.e. given $\\mathcal{C}$ and $V$ , a same-cluster oracle is an oracle $\\alpha_{C}$ that takes as input $u$ and $v$ in $V$ , and returns 1 if $u$ and $v$ belong to the same cluster in $\\mathcal{C}$ , and $-1$ otherwise. The power and limitations of same-cluster oracles have been studied in a variety of settings, including the clustering problem described above [8, 26, 33, 34]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "However, previous work on this model makes the arguably unrealistic assumption that all queries return the correct answer. In the motivating applications, queries are often at risk of failure that results from relying on non-expert workers or suffering from experimental noise. The learner\u2019s goal is to recover the partition in spite of these errors. Such errors are also often not persistent: in the presence of noise, repeating an experiment multiple times may yield different answers, and querying different human workers may result in conflicting responses. Nonetheless, practitioners may need to achieve exact recovery of the underlying partition. However, existing theory either focuses on the error-free regime [26, 33], assumes that errors are persistent [16, 32], or focuses on probabilistic guarantees rather than exact recovery [15]. ", "page_idx": 1}, {"type": "text", "text": "To address this literature gap, we study algorithms for partition learning via same-cluster oracles that are robust to non-persistent errors. A typical way to incorporate uncertainty and noise is to assume that errors occur independently at random with some small probability on every query. However, it is not possible to guarantee exact recovery of the underlying clusters in this model. Instead, we focus on a model in which the learner sets an error-tolerance parameter $\\ell$ , and they require guaranteed full recovery of the hidden partition as long as the error incurred is within this tolerance. In particular, we say a same-cluster oracle $\\alpha_{\\mathcal{C}}$ is $\\ell$ -faulty if it may return an incorrect answer up to $\\ell$ times. We do not assume that errors are persistent: if a single pair of elements is queried repeatedly, an $\\ell\\cdot$ -faulty oracle may return inconsistent responses. We define the $\\ell$ -bounded error partition learning (\u2113-PL) problem, as the problem of exactly recovering a hidden partition via access to an $\\ell_{}$ -faulty same-cluster oracle. ", "page_idx": 1}, {"type": "text", "text": "We design algorithms for the $\\ell$ -PL problem and related variants, and analyze their query complexity. We introduce a two-player game based on correlation clustering, and we show that the minimax value of this game is closely linked to the query complexity of the $\\ell$ -PL problem. We then use this game as a framework to give tight lower bounds for the query complexity of this task, proving the proposed algorithms are optimal. ", "page_idx": 1}, {"type": "text", "text": "We find that the $\\ell$ -PL problem occupies a unique position at the intersection of different research streams. In fact, the study of this problem complements work on clustering with same-cluster query advice, and the techniques used for its analysis draw from the theory of graph learning with oracle queries and the study of R\u00e9nyi-Ulam liar games1. We are hopeful that the impact of these connections will go beyond the results presented in this paper. ", "page_idx": 1}, {"type": "text", "text": "1.1 Background and related results ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Clustering with same-cluster oracles In the error-free regime, Liu and Mukherjee [26] studied the query complexity of recovering partitions of a finite set in different oracle models. They prove tight lower bounds on the query complexity of learning partitions with error-free same-cluster oracles, and point out that an algorithm proposed by Reyzin and Srivastava [33] exactly achieves this query complexity. ", "page_idx": 1}, {"type": "text", "text": "In many motivating applications of this model queries may return the wrong answer, such as when labels result from non-expert human input or noisy scientific experiments. Vinayak and Hassibi [37] consider multiple query models for collecting information from human workers, pointing out that same-cluster queries can accomplish similar end goals as label queries while potentially being easier questions for non-experts to answer correctly. They also provide an algorithm that works for the setting in which triangle queries\u2013which ask the worker to provide all pairwise relationships between three data points\u2013are made. Mazumdar and Saha [30] initiate the formal study of clustering with same-cluster oracles in the presence of persistent i.i.d. errors. They point out that under these assumptions, learning a partition has a strong relationship to recovering community structure in the stochastic block model (SBM). This work inspired a productive line of research on the i.i.d. noise model, which also leverages connections to the SBM to study related problems. In fact, this problem has been studied in the setting when $k=2$ [22], when the underlying clusters are nearly-balanced [32], and in the semi-random noise model, in which errors occur with some i.i.d. probability, but when they do occur the (erroneous) answer may be chosen adversarially [16]. Models for non-persistent error have also been considered. Chen et al. [15] study same-cluster queries in the presence of i.i.d. error, allowing for repeated querying of pairs. They give an efficient algorithm with recovery guarantees that does not require a-priori knowledge of the probability of query failure. Similar results were also subsequently established in a recent paper by Gupta et al. [23]. Our work complements this line of research by considering a setting in which exact recovery is possible in spite of errors and providing a full characterization of the query complexity of the problem in this setting. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "R\u00e9nyi-Ulam games In his autobiography, Stanis\u0142aw Ulam, introduced the following two-player game [36]. One player (the responder) thinks of a number in $x\\in[N]$ for some $N\\in\\mathbb{N}$ , and the other player (the questioner), given $N$ , tries to guess $x$ by asking only yes/no questions. The main twist to this setup is that the responder is allowed to lie up to $\\ell$ times. The term \u201cR\u00e9nyi-Ulam games\u201d has since been used to identify a wide range of problems involving asking questions to an oracle who is allowed some limited amount of lying (see e.g. [31]). The question of finding the worst-case query complexity of the $\\ell\\cdot$ -PL problem can be naturally formulated as a R\u00e9nyi-Ulam game, in which the learning algorithm takes the role of the questioner, and the oracle plays the part of the responder. ", "page_idx": 2}, {"type": "text", "text": "Correlation clustering Bansal et al. [10] introduced correlation clustering. In this problem, one is given a signed graph $G=(V,E,\\sigma)$ , where $\\sigma:E\\rightarrow\\{\\pm1\\}$ is a function representing one\u2019s prior belief about which pairs of vertices belong to the same cluster. The goal of the problem is to return a partition of the vertices of $G$ into clusters that minimizes the amount of disagreement with the edge signs given by $\\sigma$ . The problem is known to be NP-Hard. Many variations of problem have been proposed, including versions with weighted edges [2, 17], a version where the number of clusters is constrained to some fixed $k$ [19], and an agreement maximization setting. Different assumptions have also been studied, such as instance stability and noisy partial information [27\u201329]. ", "page_idx": 2}, {"type": "text", "text": "1.2 Discussion of the Model ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In the previous sections, we introduce a problem in which a learner has to exactly recover a hidden partition by making same-cluster queries that could be subject to up to $\\ell$ errors. Other plausible models for learning partitions with errors could be considered. In this section, we discuss some of the key design features of the model and provide justification and examples. ", "page_idx": 2}, {"type": "text", "text": "In general, even in the regime in which $k$ the number of clusters is known to the learner, it is not possible to recover the partition exactly unless one is able to resolve all but at most 2 of the pairwise same-cluster relationship between the elements. This follows from a result of Reyzin and Srivastava (this is a key idea leveraged in the proof of Proposition 3 in [33]). In particular, simple extensions of these core arguments imply that in the setting in which the answers to the queries are persistent, it is impossible to solve the problem even for small constant values of of $\\ell$ [18, 33]. Furthermore, this implies that even in the non-persistent error-model, one cannot solve the problem for a value of $\\ell$ that grows linearly with $n$ . Below, we give two general motivating examples, in the technology and scientific domains respectively, illustrating the role of $\\ell$ in partition learning tasks. ", "page_idx": 2}, {"type": "text", "text": "Example 1: Robustness to Misinformation Consider a setting where a user is trying to cluster a dataset by crowdsourcing information in the form of same-cluster questions. However, the user suspects that an ill-intentioned competitor organization is attempting to corrupt the learning process by entering a number of bad actors in the crowd to strategically mislabel queries. If the user selects a new person every time they submit a query, then the number of adversarial answers they encounter is finite and does not grow with the number of queries submitted. In this scenario, $\\ell$ plays the role of a security parameter, and the algorithm is guaranteed to be robust to up to $\\ell_{}$ -many poisoned responses. The user can set $\\ell$ based on, e.g., their prior belief about the resources of the competitor organization. Our results can be interpreted as quantifying the cost (in queries / crowd size) of implementing a fixed security parameter $\\ell$ . ", "page_idx": 2}, {"type": "text", "text": "Example 2: Trustworthy Science Consider a setting in which a scientist is attempting to group items into classes by running experiments that reveal whether two items are in the same class, such as the example of clustering compatible molecules described in Gupta et al. [23]. The scientist has limited resources (e.g. limited materials or time) and can only conduct a finite number of experiments. Our results allow the scientist to derive the maximum number of errors to which their learning procedure can be tolerant, given their fixed query budget. They can use this maximum value as ", "page_idx": 2}, {"type": "table", "img_path": "ygDl8q02gA/tmp/d5698be3c4edb2a3cfe087ed5a30fa23e3bcb84d96ca931a3108bcf53d829432.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "Table 1: The query complexity of the different variants of the $\\ell_{}$ -PL problem, for both the $k$ -known ad the $k$ -unknown setting. We obtain matching upper and lower bounds for all the variants with the exception of the weighted \u2113-PL problem in $k$ -unknown setting, for which the upper bound does not match the lower bound (given for the $k$ -unknown case) exactly. The results are given in terms of the complexity $R S^{k}(n,k)$ and $R S^{u}(n,k)$ (defined in Equations 1 and 2) of solving the problem without errors. ", "page_idx": 3}, {"type": "text", "text": "the setting for $\\ell$ , and then use our algorithms to guide their choice of experiments. Our analysis would then allow them to measure the significance of their findings by quantifying the number of experiments that would need to have failed for the finding to be incorrect. ", "page_idx": 3}, {"type": "text", "text": "2 Technical preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Basic definitions Given a positive integer $n$ we denote with $[n]$ the set $\\{1,...,n\\}$ . Given any finite set $V$ we denote with $\\binom{V}{2}$ the set $\\{\\{i,j\\}\\subseteq V\\mid i\\neq j\\}$ . A graph $G=(V,E)$ is a pair containing a finite vertex set $V$ and a subset $E\\subseteq{\\binom{V}{2}}$ . Given a finite set $V$ a $k$ -partition of $V$ is a collection of $k$ pairwise disjoint non-empty subsets $\\mathcal{C}=\\{C_{1},...,C_{k}\\}$ of $V$ such that $\\textstyle\\bigcup_{a=1}^{k}C_{a}=V$ . We will denote by $n$ the cardinality $|V|$ of $V$ and we may assume without loss of  generality that $V=[n]$ . Given two elements $u$ and $v$ of $V$ , we write $u\\sim_{\\mathcal{C}}v$ (resp. $u\\not\\sim v$ ) for the statement $\\exists C\\in\\mathcal{C},\\{\\dot{u},\\dot{v}\\}\\subseteq C$ (resp. $\\nexists$ $C\\in{\\mathcal{C}}$ , $\\{u,v\\}\\subseteq C)$ . We denote by $[u]_{\\mathcal{C}}$ the equivalence class of $u$ with respect to $\\mathcal{C}$ , i.e. $[u]_{\\mathcal{C}}$ is the unique $C\\in{\\mathcal{C}}$ containing $u$ . Given two partitions $\\mathcal{C}_{1}$ and $\\mathcal{C}_{2}$ we say $\\mathcal{C}_{2}$ is a refinement of $\\mathcal{C}_{1}$ if for every $C\\in\\mathcal{C}_{2}$ there is a $C^{\\prime}\\in\\mathcal{C}_{1}$ such that $C\\subseteq C^{\\prime}$ . ", "page_idx": 3}, {"type": "text", "text": "3 A hierarchy of problems ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In the introduction we consider learning a partition $\\mathcal{C}$ of a finite set $V$ by asking questions of the form \u201cAre $u$ and $v$ part of the same cluster in $\\mathcal{C P}^{\\bullet}$ , where up to $\\ell$ of the answers may be incorrect. We refer to this as the $\\ell$ -PL problem. We characterize the hardness of the $\\ell$ -PL problem by considering a family of related tasks. In particular, we introduce a hierarchy of problems with different degrees of difficulty (see Figure 1) and establish matching upper lower bounds in nearly all of these tasks. We summarize our results in Table 1. ", "page_idx": 3}, {"type": "text", "text": "At the bottom of the hierarchy, we have the problem first studied by Reyzin and Srivastava [33] of learning partitions with same-cluster queries, where the answer to every query is guaranteed to be correct. They give an algorithm that can learn the underlying partition with: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\nR S^{k}(n,k)\\ {\\stackrel{\\mathrm{def}}{=}}\\ n(k-1)-{\\binom{k}{2}}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "many queries when the number $k$ of clusters is known to learner and: ", "page_idx": 4}, {"type": "equation", "text": "$$\nR S^{u}(n,k)\\ {\\stackrel{\\mathrm{def}}{=}}\\ n k-{\\binom{k+1}{2}}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "when $k$ is unknown to the learner. Recently, Liu and Mukherjee [26] showed that no algorithm can guarantee full recovery of the underlying partition in fewer that $R S^{k}(n,k)$ (resp. $R S^{u}(n,{\\bar{k}}))$ queries when $k$ is known (resp. unknown) to the learner, showing that the algorithms of Reyzin and Srivastava are optimal down to the exact constants. Since this is the \u201ceasiest\u201d version of the problem we will be considering, the lower bounds of Liu and Mukherjee immediately imply the same lower bounds for all the other problems in the family. ", "page_idx": 4}, {"type": "text", "text": "We then consider two variants of this problem, each only admitting one-sided error. In the first variant, which we refer to as the $\\ell$ -bounded error partition learning with false positives $(\\ell{\\mathrm{-}}\\mathrm{PL}^{\\mathrm{FP}})$ problem, the oracle might return the answer $+1$ even when two elements are not part of the same cluster. We refer to this kind of fault as a false positive answer. Here, we restrict the oracle to return at most $\\ell$ many false positive answers, for some fixed positive integer $\\ell$ , and to always return $-1$ when the two elements being queried are not part of the same cluster. ", "page_idx": 4}, {"type": "text", "text": "In the second variant, which we refer to as the $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ problem, the oracle behaves the opposite way, and it may return $-1$ even if the two elements being queried are part of the same cluster in the hidden partition (a false negative answer), but it cannot return a false positive answer. Similarly to the previous variant, we restrict the number of false negative answers to be at most some fixed $\\ell$ . We give precise definitions of the $\\ell{-}\\mathrm{PL}^{\\mathrm{FP}}$ and $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ problems below. ", "page_idx": 4}, {"type": "text", "text": "The $\\ell$ -PL problem is then a generalization of all of the three variants described above (false positives, false negatives and no error), and hence, it inherits hardness results from all three of these problems. Instead of directly designing an algorithm for the $\\ell$ -PL problem, we consider a yet more general version of the problem, and use results from that generalized version to obtain algorithms for all of the other problems in the class. This final variant is a more fine-grained problem, which allows false positive answers and false negative answers to incur different penalties. In particular we consider a weighted version of $\\ell$ -PL, which is formalized in the following definition: ", "page_idx": 4}, {"type": "text", "text": "Definition 1 ( $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -Faulty Oracle and Weighted $\\ell$ -PL Problem). Let $V$ be a finite set, and $\\mathcal{C}$ be a partition of $V$ . A $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -faulty oracle for $\\mathcal{C}$ is an algorithm $\\alpha_{\\mathcal{C}}$ which, given as input a pair of elements $u v$ , returns a value $r=\\in\\{\\pm1\\}$ so that for any sequence of queries $\\{u_{t}v_{t}\\}_{t\\in[T]}$ the sequence of responses $\\{r_{t}=\\alpha_{\\mathcal{C}}\\big(u_{t}v_{t}\\big)\\big\\}_{t\\in[T]}$ satisfies: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{\\left|\\left\\{t:u_{t}\\ \\gamma\\llcorner\\ v_{t}\\wedge r_{t}=+1\\right\\}\\right|}{\\ell_{\\mathtt{y e s}}}+\\frac{\\left|\\left\\{t:u_{t}\\sim\\!c\\ v_{t}\\wedge r_{t}=-1\\right\\}\\right|}{\\ell_{\\mathtt{n o}}}\\leq1.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that we assume the oracle can maintain an internal state, so its answers may depend on the query history. The weighted $\\ell$ -PL problem asks one to recover an unknown $k$ -partition of $V$ given access to an $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -faulty oracle for $\\mathcal{C}$ . ", "page_idx": 4}, {"type": "text", "text": "Observe that by setting $\\ell_{\\tt y e s}<1$ (resp. $\\ell_{\\mathfrak{n}\\circ}<1\\rangle$ ) one would require the oracle to not return any false positive (resp. false negative) answer. As a convention, we will write $\\ell_{\\mathtt{y e s}}=0$ or $\\ell_{\\mathbf{n}\\circ}=0$ to indicate any setting that ensures the oracle may not return any false positive or false negative answers respectively. We note that, up to rescaling $\\ell_{\\mathrm{yes}}$ and $\\ell_{\\mathbf{n}\\circ}$ by a factor of 2, this problem is equivalent to a version of the problem in which the oracle has separate constraints for the number of false positive answers and false negative answers, a simple fact which we prove in Appendix B. ", "page_idx": 4}, {"type": "text", "text": "Given this definition, the (unweighted) $\\ell_{}$ -PL can be cast as a homogeneous version of the above, one in which $\\ell_{\\tt y e s}=\\ell_{\\tt n o}$ , as follows: ", "page_idx": 4}, {"type": "text", "text": "Definition 2 $\\ell_{\\mathrm{i}}$ -Faulty Oracle and $\\ell$ -PL Problem). An $\\ell$ -faulty oracle is an $(\\ell,\\ell)$ -faulty oracle. The $\\ell_{}$ -PL problem is the problem of learning a partition with access to an $\\ell$ -faulty oracle. ", "page_idx": 4}, {"type": "text", "text": "The $\\ell{-}\\mathrm{PL}^{\\mathrm{FP}}$ and $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ problems discussed above can now be formally described as special instances of the weighted $\\ell_{}$ -PL problem. ", "page_idx": 4}, {"type": "image", "img_path": "ygDl8q02gA/tmp/60f8d77ce9ce8645754854e132d46ca11eb525ab3d9812ef5ea1f6d58d4dd467.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 1: The lattice of problems considered in this paper. Algorithmic results propagate from left to right while lower bound results propagate right to left. ", "page_idx": 5}, {"type": "text", "text": "Definition 3 $\\scriptstyle\\mathcal{\\ell}-\\,\\mathsf{P L}^{\\mathtt{F P}}$ Problem and $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ Problem). The $\\ell{-}\\mathrm{PL}^{\\mathrm{FP}}$ problem is the problem of learning a partition with access to an $(\\ell,0)$ -faulty oracle. Intuitively, this corresponds to the problem of learning partitions subject to at most $\\ell$ false-positive responses and no false negatives. The $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ problem is the problem of learning a partition with access to an $(0,\\ell)$ -faulty oracle. This corresponds to learning partitions subject to at most $\\ell$ false-negatives responses and no false positives. ", "page_idx": 5}, {"type": "text", "text": "In the rest of the paper, we will always assume that the set $V$ , its cardinality $n$ , and the parameters $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ are known to the learner. We will consider both the $k$ -known setting, in which the number $k$ of clusters is known to learner, and the $k$ -unknown setting, in which it is not. It is easy to see that the query complexity of every problem in the $k$ -unknown setting is no smaller than that of the same problem in the $k$ -known setting, since any learning algorithm could simply ignore the value of $k$ . We design separate algorithms for the $k$ -known and the $k$ -unknown setting, while the lower bounds, which we only prove for the $k$ -known setting, apply directly to the $k$ -unknown setting. ", "page_idx": 5}, {"type": "text", "text": "In the next section we describe a number of algorithmic results to solve variants of the $\\ell$ -PL problem. In particular, Theorem 1 describes the performance of an algorithm for the weighted $\\ell$ -PL problem in the $k$ -known setting. We briefly comment that it is actually not necessary for the number of false negatives $\\ell_{\\mathbf{n}\\circ}$ to be bounded or known in advance in order to run this algorithm and achieve optimal query complexity. Rather the value of $\\ell_{\\mathbf{n}\\circ}$ that appears in the query complexity analysis will be the true number of false-negative responses that occur during the execution of the algorithm. In particular, this implies that in the version of the problem in which no false positives can occur, one does not need to set any upper bound on the error at all. In contrast in the $k$ -unknown setting, in order to achieve the bound described in Theorem 3 our proposed algorithm does require a user-chosen value for $\\ell_{\\mathbf{n}\\circ}$ . Here, a simple argument shows that it is impossible to guarantee one has found the correct answer unless they can upper bound both $\\ell_{\\tt y e s}$ and $\\ell_{\\mathbf{n}\\circ}$ . ", "page_idx": 5}, {"type": "text", "text": "4 Algorithmic results ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our first result is an algorithm for the weighted $\\ell$ -PL problem in the $k$ -known setting. ", "page_idx": 5}, {"type": "text", "text": "Theorem 1. There exists an algorithm for the weighted \u2113-PL problem which recovers the full partition $\\mathcal{C}$ in the $k$ -known setting with query complexity bounded by ", "page_idx": 5}, {"type": "equation", "text": "$$\nO(R S^{k}(n,k)+(n-k)\\ell_{y e s}+k^{2}\\ell_{n o}).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We observe an asymmetry in the dependence on $\\ell_{\\tt y e s}$ and $\\ell_{\\mathbf{n}\\circ}$ respectively, indicating that falsenegative and false-positive errors cause the algorithm to incur different costs. In Section 5 we prove lower bounds showing that this is not a mere artifact of the algorithm or its analysis, but rather a fundamental aspect of the problem. ", "page_idx": 5}, {"type": "text", "text": "We describe the algorithm and prove Theorem 1 in Section 6. Throughout the paper, when considering the $k$ -known setting, we shall assume that $k\\not\\in\\{1,n\\}$ , for otherwise the problem is trivially solved without the need to query the oracle. Because the weighted $\\ell_{}$ -PL problem generalizes the $\\ell$ -PL problem, this yields an algorithm for the $\\ell$ -PL problem as well: ", "page_idx": 5}, {"type": "text", "text": "Corollary 2. There exists an algorithm for the \u2113-PL problem which learns the correct partition in the $k$ -known setting with query complexity bounded by ", "page_idx": 6}, {"type": "equation", "text": "$$\nO(R S^{k}(n,k)+(n-k)\\ell+k^{2}\\ell).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "As our final algorithmic result, in Section $\\mathrm{D}$ we show that the algorithm can be adapted to obtain optimal asymptotic performance for the $\\ell$ -PL problem in the $k$ -unknown setting. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3. There exists an algorithm for the weighted \u2113-PL problem which recovers the full partition $\\mathcal{C}$ in the $k$ -unknown setting with query complexity bounded by ", "page_idx": 6}, {"type": "equation", "text": "$$\nO\\left(R S^{u}(n,k)+(n-k)\\operatorname*{max}\\{\\ell_{y e s},\\ell_{n o}\\}+k^{2}\\ell_{n o}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "An immediate corollary bounds the query complexity of the $\\ell$ -PL problem in the $k$ -unknown setting. ", "page_idx": 6}, {"type": "text", "text": "Corollary 4. There exists an algorithm for the $\\ell_{}$ -PL problem which learns the correct partition in the $k$ -unknown setting with query complexity bounded by ", "page_idx": 6}, {"type": "equation", "text": "$$\nO\\left(R S^{u}(n,k)+\\ell(n-k)+k^{2}\\ell\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In the following section we show that all the bounds discussed in this section are asymptotically optimal. While the results are stated only asymptotically, we note that the upper bounds we obtain are only a small constant factor away from the lower bounds, and we give the exact upper bounds in Section D, where we prove Theorem 3. ", "page_idx": 6}, {"type": "text", "text": "5 Lower bound techniques: correlation clustering and the chip-liar game ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Underlying our lower bound analysis is a connection between partition learning problems, R\u00e9nyiUlam and Chip-Liar games, and correlation clustering. The R\u00e9nyi-Ulam game, as defined in the background is equivalent to the following Chip-Liar game (see e.g. Chapter 15, in the book of Alon and Spencer [5]). In the game, $N$ chips, numbered 1 to $N$ are placed on a game board that has $\\ell+1$ positions, labeled $0,\\ldots,\\ell$ . At the start of the game, all of the chips begin at position 0 on the board. The game takes place in rounds. On each round the questioner player $Q$ selects a subset $S$ of the chips, and the responder player $R$ decides on one of the following moves: they can either increase the position of every chip in $S$ by 1, or increase the position of every chip in $\\overline{S}$ by 1. If a chip at position $\\ell$ is in a group whose position is advanced, the chip is said to have fallen off the board. After this point such chips will no longer advance. The rules of the game constrain $R$ \u2019s responses; $R$ must ensure that on every round, at least one chip remains on the board at position $i\\leq\\ell$ . The game terminates when there is a unique chip remaining on the board. ", "page_idx": 6}, {"type": "text", "text": "Note that one can think of the $\\ell$ -PL problem as a constrained version of this Chip-Liar game. In the $k$ -known setting2, the chips are equivalent to $k$ -partitions of the finite set $V$ , so that the number $N$ of chips is the Stirling Number of the second kind $N\\,=\\,\\left\\{{n\\atop k}\\right\\}$ . Moreover, unlike the general Chip-Liar game, in our setup the questioner may only select specific subsets $S$ : for any pair of elements $u,v\\in V$ , the questioner can select $S$ to be the set of all partitions in which $u$ and $v$ are part of the same cluster. When the questioner submits a query (\"Are $u$ and $v$ in the same group?\"), all chips whose partitions are inconsistent with the response advance by one position on the board. ", "page_idx": 6}, {"type": "text", "text": "This allows one to adopt the following perspective. One may think of the queries $\\{u_{t}v_{t}\\}_{t\\in[T]}$ made by the questioner together with the signs given by the responses to the queries as making up an instance of the correlation clustering problem. The position of a chip on the board will then be equal the cost of the corresponding partition as a solution of the correlation clustering instance constructed. In Appendix E.1 and Appendix E.2, we formalize this intuition by defining R\u00e9nyi-Ulam Correlation Clustering (RUCC) games, which are the key tools we use to lower bound query complexity. ", "page_idx": 6}, {"type": "text", "text": "Leveraging the above techniques, we lower bound the query complexity of the $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ and $\\ell_{}$ -PLFP problems. Combining these lower bounds with results in the error-free regime yield the following lower bounds on the $\\ell$ -PL problem. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5. Every algorithm for the $\\ell$ -PL problem requires at least: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\Omega(\\operatorname*{max}\\{R S(n,k),\\ell(n-k),\\ell k^{2}\\})\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "queries both in the $k$ -known and in the $k$ -unknown setting. Moreover every algorithm for the weighted $\\ell$ -PL problem requires at least: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\Omega(\\operatorname*{max}\\{R S(n,k),\\ell_{y e s}(n-k),\\ell_{n o}k^{2}\\})\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "queries both in the $k$ -known and in the $k$ -unknown setting. Here $R S(n,k)$ represents $R S^{k}(n,k)$ in the $k$ -known setting, and $R S^{u}(n,k)$ in the $k$ -unknown setting. ", "page_idx": 7}, {"type": "text", "text": "This theorem is a corollary of Theorems 19 and 21, which we prove in Appendix F.1 and Appendix F.2. ", "page_idx": 7}, {"type": "text", "text": "Intuitively, the difference in complexity we observe between the case of false negative errors and the case of false positive errors is due to the following. On one hand, certifying the existence of $k$ -clusters using positive answers requires building a spanning forest, which has $(n-k)$ edges. On the other hand, accomplishing the same task using negative answers requires constructing a clique on $k$ vertices which requires $\\bar{O(k^{2})}$ edges. This intuition is made precise in Section E in the proofs of Theorem 19 and 21 respectively. ", "page_idx": 7}, {"type": "text", "text": "6 Algorithm for weighted $\\ell$ -PL with $k$ -known ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section we give an algorithm that solves the weighted $\\ell_{}$ -PL problem in the $k$ -known setting with asymptotically optimal query complexity. We later adapt this algorithm to the $k$ -unknown setting in Appendix D. ", "page_idx": 7}, {"type": "text", "text": "We begin by briefly providing intuition for the algorithm. The algorithm maintains $\\mathcal{C^{\\prime}}$ a refinement of the correct hidden partition $\\mathcal{C}$ . At the start of the algorithm $\\mathcal{C}^{\\prime}$ is the set of all singleton elements in $V$ . The algorithm repeatedly makes sequences of queries that guarantee progress towards either (a) learning $\\mathcal{C}$ , in the form of establishing that a pair of vertices $u$ and $v$ must be part of the same cluster, or (b) certifying that an error has occurred in the oracle\u2019s responses. ", "page_idx": 7}, {"type": "text", "text": "In particular, the algorithm repeatedly attempts to construct $(k+1)$ -cliques of $-1$ responses. If at any point the oracle responses form such a clique, then a false-negative response must have occurred, as vertices in $V$ belong to at most $k$ distinct clusters (note that $k$ is assumed to be known to the algorithm). In this case, the algorithm has certified a false-negative response. On the other hand, the only way that this process may be interrupted is if the algorithm receives a $(+1)$ response to some query uv. However, if such a positive response is received, repeatedly querying the pair ${u v}$ will either quickly determine that $u$ and $v$ must be part of the same cluster or it will reveal that an error has occurred. In the first case, the algorithm makes progress towards learning $\\mathcal{C}$ , and in the second case it has certified the occurrence of an error. ", "page_idx": 7}, {"type": "text", "text": "We provide the pseudocode for the algorithm and describe in prose the main functions of each subroutine. The algorithm is comprised of subroutines Learn, Get_New, Insert and Compare: ", "page_idx": 7}, {"type": "text", "text": "Learn This is the core component of the algorithm. It maintains a partition $\\mathcal{C}^{\\prime}$ for $V$ . Throughout the algorithm, $\\mathcal{C}^{\\prime}$ is guaranteed to be a refinement of the true hidden partition $\\mathcal{C}$ . $\\mathcal{C^{\\prime}}$ is initialized as the set of singletons for every element in $V$ . The algorithm then repeatedly tries to construct a clique of negative answers, supported on some set $S\\subseteq V$ until $\\left|S\\right|=k+1$ . It does so by inserting new vertices $v$ into $S$ by calling the subroutine Insert. Insert may then either make progress towards constructing the clique (by increasing the size of $S$ ) or towards learning the hidden partition by decreasing the size of $\\mathcal{C^{\\prime}}$ (merging two clusters together). ", "page_idx": 7}, {"type": "text", "text": "Get_New Given $S\\subseteq V$ and $\\mathcal{C}^{\\prime}$ a partition of $V$ , Get_New returns an element $v\\in V\\backslash S$ representing a cluster in $\\mathcal{C}^{\\prime}$ that\u2019s not yet represented in $S$ , i.e. $v\\not\\in[u]c^{\\prime}$ for any $u\\in S$ . ", "page_idx": 7}, {"type": "text", "text": "Insert Given an element $v$ and a subset $S\\subseteq V$ , Insert compares $v$ against every element in $S$ by passing $u$ and $v$ to the function Compare. Compare returns result $\\in\\bar{\\{}\\pm1\\}$ . If Compare returns a negative result for each $u\\in S$ , then Insert adds $v$ to the subset $S$ . On the other hand, if Compare returns a positive result for $v$ and some element $u\\in S$ , then Insert updates the partition $\\mathcal{C}^{\\prime}$ to reflect that $u$ and $v$ must be in the same cluster. The latter is done by merging $[u]_{\\mathcal{C}^{\\prime}}$ with $[v]_{\\mathcal{C}^{\\prime}}$ . ", "page_idx": 7}, {"type": "text", "text": "Compare Given two vertices $u$ and $v$ , Compare repeatedly submits query uv to the oracle. Compare maintains count to record information about the number of positive and negative responses received for this query. If at any point Compare has received strictly more negative responses than positive responses, it returns result $=-1$ . ", "page_idx": 8}, {"type": "text", "text": "$\\mathbf{\\overline{{Algorithm\\1\\!:\\,Learn(}}}(V,\\alpha,k,\\ell_{\\mathtt{y e s}})$ ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Input: A finite set $V$ , an $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -faulty oracle $\\alpha_{\\mathcal{C}}$ , a target number of clusters $k$ , and error parameters $\\ell_{\\mathrm{yes}}$ . Output: A partition $\\mathcal{C^{\\prime}}$ of $V$ . 1 $S\\gets\\{\\}$ , ${\\mathcal{C}}^{\\prime}\\,\\overleftarrow{\\leftarrow}\\,\\{\\{v\\}\\mid v\\in V\\}$ 2 while $|{\\mathcal{C}}^{\\prime}|>k$ do 3 $v\\leftarrow\\tt G e t\\tt_{-}\\tt N e w(S,\\mathcal{C}^{\\prime})$ 4 $\\mathcal{C}^{\\prime},S\\gets\\mathtt{I n s e r t}(V,\\alpha,S,\\mathcal{C}^{\\prime},\\ell_{\\mathtt{y e s}})$ 5 if $|S|=k+1$ then 6 $S\\gets\\{\\}$ 7 end 8 end 9 return $\\mathcal{C}^{\\prime}$ ", "page_idx": 8}, {"type": "text", "text": "Algorithm 2: Get_New(S, C\u2032) ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Input: A partition $\\mathcal{C^{\\prime}}$ of some finite set $V$ , and a subset $S\\subset V$ such that $|S|\\leq|{\\mathcal{C}}^{\\prime}|$ Output: An element $v\\in V$ representing a set in $\\mathcal{C^{\\prime}}$ which is currently not represented by any element of $S$ . for $v\\in V$ do if $[v]_{\\mathcal{C}^{\\prime}}\\cap S=\\emptyset$ then return $v$ end 5 end 6 return \u22a5 ", "page_idx": 8}, {"type": "text", "text": "Algorithm 3: Insert(v, \u03b1, C\u2032, S, \u2113yes) ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Input: A finite set $V$ ,a same-cluster oracle $\\alpha$ for $V$ , a partial clique $S$ , a candidate partition $\\mathcal{C}^{\\prime}$ of $V$ , and error parameter $\\ell_{\\mathrm{yes}}$ . Output: A new candidate cluster $\\mathcal{C}^{\\prime}$ , partial clique $S$ . 1 for $u\\in S$ do 2 // Returns either $\\mathtt{r e s u l t}=-1$ or $+1$ 3 $\\mathbf{result}\\gets\\mathbf{Compare}(u,v,\\alpha,\\ell_{\\mathbf{yes}})$ 4 // If $+1$ : it is guaranteed that $u$ and $v$ are part of the same cluster and $\\mathcal{C}^{\\prime}$ is edited to reflect this 5 if $r e s u l\\,t=+1$ then 6 $\\mathsf{n e w\\_s e t}\\gets\\lceil v\\rceil_{\\mathcal{C}^{\\prime}}\\cup\\lceil u\\rceil_{\\mathcal{C}^{\\prime}}$ $\\mathcal{C}^{\\prime}\\gets(\\mathcal{C}^{\\prime}\\setminus\\{[v]_{\\mathcal{C}}^{\\prime},[u]_{\\mathcal{C}^{\\prime}}\\})\\cup\\mathsf{n e w\\mathrm{_{-}s e t}}$ 8 return C\u2032, S 9 end ", "page_idx": 8}, {"type": "text", "text": "10 end   \n11 $//$ If $S$ is empty or if result $=-1$ for every $u\\in S$ then a new item is inserted into $S$   \n12 $S\\leftarrow S\\cup\\{v\\}$   \n13 return ${\\mathcal{C}}^{\\prime},S$ ", "page_idx": 8}, {"type": "text", "text": "We briefly remark that for the $k$ -unknown setting, Algorithm 9 proposed in the appendix, works in an analogous fashion. The key difference between the two settings is that rather than building cliques of size $k+1$ , Algorithm 9 builds the largest clique possible. We then give a charging argument that shows that this strategy does not lead to a significantly higher query complexity. The algorithm and analysis are presented in Section D. ", "page_idx": 8}, {"type": "text", "text": "Input: A pair of vertices $u$ and $v$ from some finite set $V$ , a same-cluster oracle $\\alpha$ for $V$ , and error parameter $\\ell_{\\tt v e s}$ . Output: result $\\in\\{\\pm1\\}$ . 1 // Initialize count to track \u201chow many more times have we observed $r=+1$ compared to $r=-1^{,}$ 2 count $\\gets0$ 3 while coun $t\\ge0$ do 4 $r\\leftarrow\\alpha(u,v)$ 5 if $r=-1$ and coun $t\\!>0$ then 6 count \u2190count\u22121 7 else if $r=-1$ and $\\scriptstyle{c o u n t=0}$ then 8 $/*$ If the number of $-1$ responses exceeds the number of $+1$ responses seen so far, we return $-1^{*}\\!/$ 9 return $-1$ 10 else 11 $\\big|\\quad\\mathrm{count}\\gets\\mathrm{count}{+}1$ 12 end 13 // If count $/\\ell_{\\tt y e s}>1$ then we have verified that $u\\sim_{\\mathcal{C}\\ast}v$ so return result $=+1$ 14 if coun $t/\\ell_{y e s}>1$ then 15 return 1 16 end 17 end ", "page_idx": 9}, {"type": "text", "text": "7 Conclusions, Limitations, and Future Directions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper we initiated the study of learning partitions from same-cluster queries subject to bounded adversarial errors. We completely characterize the query complexity of the core problem as well as some of its relevant variants. To do so, we introduce a novel R\u00e9nyi-Ulam style game based on correlation clustering. ", "page_idx": 9}, {"type": "text", "text": "The aim of this paper is to resolve the query complexity of exact recovery with a fixed error tolerance. In particular, the results in this paper do not apply to any setting in which the error may exceed the tolerance $\\ell$ , e.g. when errors occur probabilistically and independently on every query. This limitation is analogous to those encountered when considering the Hamming (worst-case, bounded) model of error in the theory of error-correcting codes (see e.g. [24]). Thus, like the theory for bounded-error codes, results in this paper should be assumed to hold verbatim in stochastic error settings. ", "page_idx": 9}, {"type": "text", "text": "The results in this paper open up several avenues for future research. First, while we settle the complexity of all the variants of the problem in the $k$ -known setting, the exact complexity of weighted $\\ell$ -PL problem in the setting of $k$ -unknown remains to be determined. Specifically, the lower bounds of $\\Omega(k^{2}\\ell_{\\mathsf{n}\\circ})$ and $\\Omega((n^{\\mathsf{\\bar{\\alpha}}}-k)\\ell_{\\mathtt{y e s}})$ that we prove for $k$ -known directly extend to the $k$ -unknown setting. However, the analysis of Algorithm 9 can be used to establish upper bounds with terms $O(k^{2}\\ell_{\\mathrm{no}}^{-}+(n-k)\\operatorname*{max}\\{\\ell_{\\mathrm{yes}},\\ell_{\\mathrm{no}}\\})$ . The question of whether the upper bounds can be tightened to $O(k^{2}\\ell_{\\mathrm{no}}+(n-k)\\ell_{\\mathrm{ves}})$ , or whether the corresponding lower bound can be strengthened to e.g. $\\Omega((n-k)\\operatorname*{max}\\{\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}}\\})$ in the $k$ -unknown setting, remains open. Another interesting open question is whether there exist algorithms that can achieve exact recovery in the setting of $k$ -known when the number of false-positives, $\\ell_{\\tt y e s}$ , is not known to the algorithm a priori. In this work we established that such algorithms exist without knowing $\\ell_{\\mathbf{n}\\circ}$ in advance, but it is unclear whether $\\ell_{\\mathrm{yes}}$ has analogous properties. ", "page_idx": 9}, {"type": "text", "text": "We focus on same-cluster queries due to their popularity and simplicity, but there are other practical query models that may interest the community. One such example includes the triangle queries introduced by Vinayak and Hassibi [37] in which a worker is asked to input all pairwise same-cluster responses for three data points at a time. It would be interesting to explore whether the analysis techniques introduced in this work can determine the query complexity of learning partitions under other query models. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements. The authors wish to thank Daniel Di Benedetto for providing helpful advice early on in the project; Yibo Jiang for suggesting related work; Mark Olson, Angela Wang, and Nathan Waniorek for useful discussions. AD is supported by NSF DGE 2140001. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] H. Abasi and B. Nader. On learning graphs with edge-detecting queries. In Algorithmic Learning Theory, pages 3\u201330. PMLR, 2019.   \n[2] N. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information: ranking and clustering. Journal of the ACM (JACM), 55(5):1\u201327, 2008.   \n[3] N. Ailon, A. Bhattacharya, and R. Jaiswal. Approximate correlation clustering using samecluster queries. In LATIN 2018: Theoretical Informatics: 13th Latin American Symposium, Buenos Aires, Argentina, April 16-19, 2018, Proceedings, pages 14\u201327. Springer, 2018.   \n[4] N. Alon and V. Asodi. Learning a hidden subgraph. SIAM Journal on Discrete Mathematics, 18 (4):697\u2013712, 2005.   \n[5] N. Alon and J. H. Spencer. The probabilistic method. John Wiley & Sons, 2016.   \n[6] N. Alon, R. Beigel, S. Kasif, S. Rudich, and B. Sudakov. Learning a hidden matching. SIAM Journal on Computing, 33(2):487\u2013501, 2004.   \n[7] D. Angluin and J. Chen. Learning a hidden graph using o (logn) queries per edge. Journal of Computer and System Sciences, 74(4):546\u2013556, 2008.   \n[8] H. Ashtiani, S. Kushagra, and S. Ben-David. Clustering with same-cluster queries. Advances in neural information processing systems, 29, 2016.   \n[9] D. Balding, W. Bruno, D. Torney, and E. Knill. A comparative survey of non-adaptive pooling designs. In Genetic mapping and DNA sequencing, pages 133\u2013154. Springer, 1996.   \n[10] N. Bansal, A. Blum, and S. Chawla. Correlation clustering. In The 43rd Annual IEEE Symposium on Foundations of Computer Science, 2002. Proceedings., pages 238\u2013247. IEEE, 2002.   \n[11] M. Bouvel, V. Grebinski, and G. Kucherov. Combinatorial search on graphs motivated by bioinformatics applications: A brief survey. In Graph-Theoretic Concepts in Computer Science: 31st International Workshop, WG 2005, Metz, France, June 23-25, 2005, Revised Selected Papers 31, pages 16\u201327. Springer, 2005.   \n[12] M. Bressan, N. Cesa-Bianchi, S. Lattanzi, and A. Paudice. Exact recovery of mangled clusters with same-cluster queries. Advances in Neural Information Processing Systems, 33:9324\u20139334, 2020.   \n[13] M. Bressan, N. Cesa-Bianchi, S. Lattanzi, and A. Paudice. On margin-based cluster recovery with oracle queries. Advances in Neural Information Processing Systems, 34:25231\u201325243, 2021.   \n[14] H. Chang, H.-L. Fu, and C.-H. Shih. Learning a hidden graph. Optimization Letters, 8: 2341\u20132348, 2014.   \n[15] Y. Chen, R. K. Vinayak, and B. Hassibi. Crowdsourced clustering via active querying: Practical algorithm with theoretical guarantees. In Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, volume 11, pages 27\u201337, 2023.   \n[16] A. Del Pia, M. Ma, and C. Tzamos. Clustering with queries under semi-random noise. In Conference on Learning Theory, pages 5278\u20135313. PMLR, 2022.   \n[17] E. D. Demaine, D. Emanuel, A. Fiat, and N. Immorlica. Correlation clustering in general weighted graphs. Theoretical Computer Science, 361(2-3):172\u2013187, 2006.   \n[18] A. F. DePavia, O. M. M. del Campo, and E. Tani. Error-tolerant exact query learning of finite set partitions with same-cluster oracle. arXiv preprint arXiv:2305.13402, 2023.   \n[19] I. Giotis and V. Guruswami. Correlation clustering with a fixed number of clusters. Theory OF Computing, 2:249\u2013266, 2006.   \n[20] V. Grebinski and G. Kucherov. Reconstructing a hamiltonian cycle by querying the graph: Application to dna physical mapping. Discrete Applied Mathematics, 88(1-3):147\u2013165, 1998.   \n[21] V. Grebinski and G. Kucherov. Optimal reconstruction of graphs under the additive model. Algorithmica, 28:104\u2013124, 2000.   \n[22] K. Green Larsen, M. Mitzenmacher, and C. Tsourakakis. Clustering with a faulty oracle. In Proceedings of The Web Conference 2020, pages 2831\u20132834, 2020.   \n[23] S. Gupta, P. W. Staar, and C. de Sainte Marie. Clustering items from adaptively collected inconsistent feedback. In International Conference on Artificial Intelligence and Statistics, pages 604\u2013612. PMLR, 2024.   \n[24] V. Guruswami, A. Atri Rudra, and M. Sudan. Essential coding theory, Oct 2023. URL https://cse.buffalo.edu/faculty/atri/courses/coding-theory/book/.   \n[25] Z. Kadelburg, D. Dukic, M. Lukic, and I. Matic. Inequalities of karamata, schur and muirhead, and some applications. The Teaching of Mathematics, 8(1):31\u201345, 2005.   \n[26] X. Liu and S. Mukherjee. Tight query complexity bounds for learning graph partitions. In Conference on Learning Theory, pages 167\u2013181. PMLR, 2022.   \n[27] K. Makarychev, Y. Makarychev, and A. Vijayaraghavan. Bilu\u2013linial stable instances of max cut and minimum multiway cut. In Proceedings of the twenty-ffith annual ACM-SIAM symposium on Discrete algorithms, pages 890\u2013906. SIAM, 2014.   \n[28] K. Makarychev, Y. Makarychev, and A. Vijayaraghavan. Correlation clustering with noisy partial information. In Conference on Learning Theory, pages 1321\u20131342. PMLR, 2015.   \n[29] C. Mathieu and W. Schudy. Correlation clustering with noisy input. In Proceedings of the twenty-first annual ACM-SIAM symposium on Discrete Algorithms, pages 712\u2013728. SIAM, 2010.   \n[30] A. Mazumdar and B. Saha. Clustering with noisy queries. Advances in Neural Information Processing Systems, 30, 2017.   \n[31] A. Pelc. Searching games with errors\u2014fifty years of coping with liars. Theoretical Computer Science, 270(1-2):71\u2013109, 2002.   \n[32] P. Peng and J. Zhang. Towards a query-optimal and time-efficient algorithm for clustering with a faulty oracle. In Conference on Learning Theory, pages 3662\u20133680. PMLR, 2021.   \n[33] L. Reyzin and N. Srivastava. Learning and verifying graphs using queries with a focus on edge counting. International Conference on Algorithmic Learning Theory, page 285\u2013297, 2007.   \n[34] B. Saha and S. Subramanian. Correlation clustering with same-cluster queries bounded by optimal cost. arXiv preprint arXiv:1908.04976, 2019.   \n[35] A. Sorokin, A. Lapidus, V. Capuano, N. Galleron, P. Pujic, and S. D. Ehrlich. A new approach using multiplex long accurate pcr and yeast artificial chromosomes for bacterial chromosome mapping and sequencing. Genome research, 6(5):448\u2013453, 1996.   \n[36] S. M. Ulam. Adventures of a Mathematician. Univ of California Press, 1991.   \n[37] R. K. Vinayak and B. Hassibi. Crowdsourced clustering: Querying edges vs triangles. Advances in Neural Information Processing Systems, 29, 2016.   \n[38] F. Xia, K. Sun, S. Yu, A. Aziz, L. Wan, S. Pan, and H. Liu. Graph learning: A survey. IEEE Transactions on Artificial Intelligence, 2(2):109\u2013127, apr 2021. doi: 10.1109/tai.2021.3076021. URL https://doi.org/10.1109%2Ftai.2021.3076021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Additional relevant background ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Comparison of random and adversarial error Most of the prior work on clustering with faulty same-cluster queries focuses on the random-error model. Different models of random error have been considered. The most similar works to this paper are the papers of Gupta et al. [23] and Chen et al. [15]. These papers consider non-persistent random error. In this setting, the best known upper bounds on the query complexity of partition learning are ", "page_idx": 12}, {"type": "equation", "text": "$$\n{\\tilde{O}}\\left({\\frac{n k}{f(p)}}\\right)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $p$ is the probability of error and $f$ is some function that tends to 0 as $p\\rightarrow1/2$ [15, 23]. It is difficult to compare the scaling of query complexity under random error as a function of probability of error versus the scaling of query complexity under adversarial error as a function of parameter $\\ell$ However one interesting qualitative distinction is that in this work the tight upper and lower bounds on query complexity under adversarial error never pay for a term as large as $n\\cdot k\\cdot\\ell$ . Instead in the setting of adversarial error, query complexity bounds scale with $(n+k^{\\bar{2}})\\cdot\\ell$ . ", "page_idx": 12}, {"type": "text", "text": "Comparison of persistent and non-persistent error Prior literature has also studied the persistent random error version of this problem. The seminal work of Mazumdar and Saha [30] inspired a series of followup works in this setting [16, 22]. For this problem, upper and lower bounds which match up to log factors are known: Mazumdar and Saha [30] establish a lower bound stating that any algorithm achieving probability of recovery at least $3/4$ must make at least ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\Omega\\left(\\frac{n k}{(1-2p)^{2}}\\right)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "queries. They further give a (time-inefficient) algorithm which recovers the maximum-likelihood clustering estimate with high probability when $p<1/2$ , using ", "page_idx": 12}, {"type": "equation", "text": "$$\nO\\left(\\frac{n k\\log(n)}{(1-2p)^{2}}\\right)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "queries [30]. In particular, while a piori the persistent-error versions of the problem can be no easier than the non-persistent-error ones, we are not aware of any result that shows a gap in query complexity between these two different settings. ", "page_idx": 12}, {"type": "text", "text": "We note that a model imposing persistent adversarial error does not allow for any non-trivial algorithmic results. ", "page_idx": 12}, {"type": "text", "text": "Active learning of graphs with oracles The field of graph learning focuses on learning graph structure with oracle access to the graph in question.3 Numerous settings have been considered in the literature, including instances where the target graphs are matchings [6], stars or cliques [4], or Hamiltonian cycles [35]. Further research examines Las Vegas algorithms [1] and the role that adaptivity plays in the query complexity of these problems [14, 21]. In a related paper, Reyzin and Srivastava [33] give an algorithm that learns the partitions of a graph with $n$ vertices using $O(n k)$ shortest path queries, as well as an algorithm that learns such partitions using $O(n\\log n)$ edge counting queries. Angluin and Chen [7] give an algorithm that can learn a graph with $n$ vertices using $O(\\log n)$ edge detection queries per edge. Following this line of inquiry, Liu and Mukherjee [26] find that the exact worst-case number of queries needed to learn a partition of $[n]$ into $k$ clusters in the same-cluster query model is exactly $n(k-1)-{\\binom{k}{2}}$ if $k$ is known by the learner a priori, and $n k-\\binom{k+1}{2}$ otherwise. ", "page_idx": 12}, {"type": "text", "text": "Geometric clustering with oracle advice Ashtiani et al. [8] introduce the problem of clustering data when the learner can make limited same-cluster queries, and they show that this leads to a polynomial-time algorithm for $\\mathbf{k}$ -means clustering under certain geometric assumptions. In recent years, the model of Ashtiani et al. has inspired a variety of other related works which aim to understand the beneftis of accessing a same-cluster oracle (e.g. [12, 13, 16]). Ailon et al. [3] show that making a small number of queries to a same-cluster oracle allows one to improve exponentially the dependency on the approximation parameter $\\varepsilon$ and on the number $k$ of clusters for polynomial time approximation schemes for some versions of correlation clustering. Saha and Subramanian [34] also consider the problem of using same-cluster queries to aid the solution of a correlation clustering instance, and they give algorithms with performance guarantees that are functions of the optimal value of the input instance. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "B Equivalence between weighted problem and doubly constrained one ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this section, we argue that, up to changing the parameters by a factor of at most 2, the weighted $\\ell_{}$ -PL problem is equivalent to one in which the oracle may return up to $\\ell_{\\tt y e s}$ many false positive answers and $\\ell_{\\mathbf{n}\\circ}$ many false negative ones. We refer to this problem as the asymmetric $\\ell$ -PL problem. ", "page_idx": 13}, {"type": "text", "text": "Definition 4 (Asymmetric $\\ell$ -PL Problem). Given a finite set $V$ , and a partition $\\mathcal{C}$ of $V$ , an $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ - asymmetric oracle for $\\mathcal{C}$ is an algorithm $\\alpha_{\\mathscr{C}}$ which, given as input a pair of elements $u v$ , returns a value $r=\\in\\{\\pm1\\}$ so that for any sequence of queries $\\{(u_{t},v_{t})\\}_{t\\in[T]}$ the sequence of responses $\\{r_{t}=\\alpha_{\\mathcal{C}}\\big(u_{t}v_{t}\\big)\\}_{t\\in[T]}$ satisfies:: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\left\\{t\\mid r_{t}=1\\wedge u_{t}\\;\\rlap/\\infty\\;v_{t}\\right\\}\\right|\\leq\\ell_{\\mathtt{y e s}}\\ \\ \\ \\ \\ \\mathrm{and}\\ \\ \\ \\ \\ \\left|\\left\\{t\\mid r_{t}=-1\\wedge u_{t}\\sim c\\;v_{t}\\right\\}\\right|\\leq\\ell_{\\mathtt{n o}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The asymmetric $\\ell$ -PL problem is the problem of recovering $\\mathcal{C}$ by making queries to an $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ - asymmetric oracle. ", "page_idx": 13}, {"type": "text", "text": "It is easy to see that any $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -faulty oracle is also an $(\\ell_{\\tt y e s},\\ell_{\\tt n o})$ -asymmetric oracle and hence the query complexity of the asymmetric $\\ell_{}$ -PL problem is no larger than that of the weighted $\\ell$ -PL problem for the same choice of parameters. Conversely, we have the following: ", "page_idx": 13}, {"type": "text", "text": "Proposition 6. For any algorithm which solves the weighted \u2113-PL problem by making at most $q(n,k,\\ell_{y e s},\\ell_{n o})$ queries, there exists an algorithm which solves the asymmetric \u2113-PL problem by making at most $q(n,k,2\\ell_{y e s},2\\ell_{n o})$ queries. ", "page_idx": 13}, {"type": "text", "text": "Proof. This simply follows from the fact that any $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -asymmetric oracle is also an $(\\ell_{\\mathrm{yes}}/2,\\ell_{\\mathrm{n}o}/2)$ -faulty oracle. \u53e3 ", "page_idx": 13}, {"type": "text", "text": "C Deferred proofs from Section 6 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Query Accounting For the sake of analysis, we will assume that the algorithm maintains a global history of all the queries made to the oracle and the responses received. We will also let the algorithm assign labels to query-response pairs. This is done in order to charge the queries made to some measure of progress towards either learning the partitions or certifying that errors have occurred. The lines of pseudocode assigning labels to the query history, written in blue, are not necessary for the algorithm to work correctly but rather are included only to facilitate the analysis. ", "page_idx": 13}, {"type": "text", "text": "Lemma 7. Throughout the execution of Algorithm 5, $\\mathcal{C}^{\\prime}$ is always a refinement of the true partition. ", "page_idx": 13}, {"type": "text", "text": "Proof of Lemma 7. $\\mathcal{C^{\\prime}}$ is essentially a global variable. We begin by noting that $\\mathcal{C}^{\\prime}$ is trivially a refinement of the correct partition at the beginning of the algorithm. The only point in the algorithm at which $\\mathcal{C}^{\\prime}$ is modified is on Lines 7 and 8 of Insert. In that step, the algorithm modifies $\\mathcal{C}^{\\prime}$ by merging the cluster containing $v$ with the cluster containing $u$ . This lines are executed only if the value of the variable result, output by Compare, is $+1$ . This happens only if count $/\\ell_{\\tt y e s}>1$ on Line 16 of Compare, in which case the latest call to Compare has obtained more than $\\ell_{\\mathrm{yes}}$ many uv queries returning $+1$ . ", "page_idx": 13}, {"type": "text", "text": "We now argue that if that happens, $u$ and $v$ must have been part of the same cluster in the ground-truth partition $\\mathcal{C}$ . If $u$ and $v$ were not part of the same of the same cluster in $\\mathcal{C}$ , we derive a contradiction, as this would imply: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathrm{FP}\\geq\\mathsf{c o u n t}>\\ell_{\\mathsf{y e s}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "and hence F $\\mathrm{P}\\,/\\ell_{\\mathrm{yes}}>1$ . Hence, if $\\mathcal{C}^{\\prime}$ was a refinement of $\\mathcal{C}$ before merging the clusters containing $u$ and $v$ , then it is still a refinement of $\\mathcal{C}$ after merging the two clusters. This invariant is then maintained throughout the algorithm, and the lemma holds. \u53e3 ", "page_idx": 13}, {"type": "text", "text": "$\\mathbf{Algorithm}\\,5\\!\\colon\\!\\mathbf{Learn}(V,\\alpha,k,\\ell_{\\mathtt{y e s}})$ ", "page_idx": 14}, {"type": "text", "text": "Input: A finite set $V$ , an $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -faulty oracle $\\alpha_{\\mathscr{C}}$ , a target number of clusters $k$ , and error parameters $\\ell_{\\mathrm{yes}}$ . Output: A partition $\\mathcal{C^{\\prime}}$ of $V$ . 1 $S\\gets\\{\\}$ , ${\\mathcal{C}}^{\\prime}\\,\\overleftarrow{\\leftarrow}\\,\\{\\{v\\}\\mid v\\in V\\}$ 2 while $|{\\mathcal{C}}^{\\prime}|>k$ do 3 $v\\leftarrow\\tt G e t\\tt_{-}\\tt N e w(S,\\mathcal{C}^{\\prime})$ 4 $\\mathcal{C}^{\\prime},S\\gets\\mathrm{Insert}(V,\\alpha,S,\\mathcal{C}^{\\prime},\\ell_{\\mathrm{yes}},\\ell_{\\mathrm{no}})$ 5 if $|S|=k+1$ then 6 \u2014 $S\\gets\\{\\}$ 7 end 8 end 9 return $\\mathcal{C}^{\\prime}$ ", "page_idx": 14}, {"type": "text", "text": "Algorithm ${\\bf6}{\\bf:}\\cot_{-}\\mathtt{N e w}(S,\\mathcal{C}^{\\prime})$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Input: A partition $\\mathcal{C^{\\prime}}$ of some finite set $V$ , and a subset $S\\subset V$ such that $|S|\\leq|{\\mathcal{C}}^{\\prime}|$ Output: An element $v\\in V$ representing a set in $\\mathcal{C^{\\prime}}$ which is currently not represented by any element of $S$ . 1 for $v\\in V$ do 2 if $[v]c\\prime\\cap S=\\emptyset$ then 3 return $v$ 4 end 5 end 6 return \u22a5 ", "page_idx": 14}, {"type": "text", "text": "$\\mathbf{Algorithm\\7:\\Insert}(v,\\alpha,\\mathcal{C}^{\\prime},S,\\ell_{\\mathrm{yes}})$ ", "page_idx": 14}, {"type": "text", "text": "Input: A finite set $V$ ,a same-cluster oracle $\\alpha$ for $V$ , a partial clique $S$ , a candidate partition $\\mathcal{C}^{\\prime}$ of $V$ , and error parameters $\\ell_{\\tt y e s}$ . Output: A new candidate cluster $\\mathcal{C}^{\\prime}$ , partial clique $S$ .   \n1 for $u\\in S$ do   \n2 // Returns either $\\mathtt{r e s u l t}=-1$ or $+1$   \n3 $\\mathbf{result}\\gets\\mathbf{Compare}(u,v,\\alpha,\\ell_{\\mathbf{yes}},\\ell_{\\mathbf{no}})$   \n4 // If $+1$ : it is guaranteed that $u$ and $v$ are part of the same cluster and $\\mathcal{C}^{\\prime}$ is edited to reflect this   \n5 if $r e s u l\\,t=+1$ then   \n6 Re-label all $^{\\bullet}{\\tt c1}$ ique\u2019 queries made during this execution of Insert (and all calls to Compare therein) as \u2018merge-\u2019   \n7 new_s $\\mathtt{s t}\\gets[v]c^{\\prime}\\cup[u]c^{\\prime}$   \n8 $\\mathcal{C}^{\\prime}\\gets(\\mathcal{C}^{\\prime}\\setminus\\{[v]_{\\mathcal{C}}^{\\prime},[u]_{\\mathcal{C}^{\\prime}}\\})\\cup\\mathsf{n e w\\mathrm{_{-}s e t}}$   \n9 return C\u2032, S   \n10 end   \n11 end   \n12 $//$ If $S$ is empty or if $\\mathtt{r e s u l t}=-1$ for every $u\\in S$ then a new item is inserted into $S$ $S\\leftarrow S\\cup\\{v\\}$ ", "page_idx": 14}, {"type": "text", "text": "13   \n14 return ${\\mathcal{C}}^{\\prime},S$   \nInput: A pair of vertices $u$ and $v$ from some finite set $V$ , a same-cluster oracle $\\alpha$ for $V$ , and error   \nparameters $\\ell_{\\mathrm{ves}}$ .   \nOutput: result $\\in\\{\\pm1\\}$ .   \n1 // Initialize count to track \u201chow many more times have we observed $r=+1$ compared to   \n$r=-1^{,}$   \n2 count $\\gets0$   \n3 while coun $t\\ge0$ do   \n4 $r\\leftarrow\\alpha(u,v)$   \n5 if $r=-1$ and coun $t\\!>0$ then   \n6 count \u2190count\u22121   \n7 else if $r=-1$ and $\\scriptstyle{c o u n t=0}$ then   \n8 $/*$ If the number of $-1$ responses exceeds the number of $+1$ responses seen so far, we   \nreturn $-1^{*}\\!/$   \n9 Label the last query as \u2018clique\u2019   \n10 Label all other queries created on this execution of Compare as \u2018spurious\u2019   \n11 return $-1$   \n12 else   \n13 $\\mid\\mathrm{\\boldmath~{\\count}~}\\{\\mathrm{-count}\\mathrm{+}1$   \n14 end   \n15 // If count $/\\ell_{\\tt y e s}>1$ then we have verified that $u\\sim_{\\mathcal{C}\\ast}v$ so return result $=+1$   \n16 if count $:/\\ell_{y e s}>1$ then   \n17 Label the last count-many queries which received positive responses as \u2018merge+\u2019   \n18 Label all other queries made during this execution of Compare as \u2018spurious\u2019   \n19 return 1   \n20 end   \n21 end ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Lemma 8. At the end of the algorithm, the history of queries contains at most $(\\ell_{y e s}+1)(n-k)$ queries labelled \u2018merge $^+$ \u2019and at most $k(n-k)$ queries labelled \u2018merge-\u2019. ", "page_idx": 15}, {"type": "text", "text": "Proof of Lemma 8. Consider a point in the algorithm in which Compare returns $+1$ . When that happens, the if block starting on Line 5 of Insert is executed; we refer to this as a merge event. ", "page_idx": 15}, {"type": "text", "text": "We begin by arguing that at most $n-k$ merge events can occur during an execution of Algorithm 5. At the start of the algorithm $|{\\mathcal{C}}^{\\prime}|\\,=\\,n$ . At each merge event two clusters in $\\mathcal{C}^{\\prime}$ are merged and the cardinality of $\\mathcal{C^{\\prime}}$ decreases by 1. Since $\\mathcal{C}^{\\prime}$ is always a refinement of the hidden $k$ -partition $\\mathcal{C}$ (by Lemma 7), this implies that at most $n-k$ merge events can occur during the execution of the algorithm. ", "page_idx": 15}, {"type": "text", "text": "Both \u2018merge-\u2019 and \u2018merge+\u2019 queries are only created in correspondence with a merge event. We now show that on any merge event, at most $k$ \u2018merge-\u2019 queries and at most $\\ell_{\\tt y e s}+1$ \u2018merge+\u2019 queries are created. By the above argument these results imply the statement of the lemma. ", "page_idx": 15}, {"type": "text", "text": "We now show that at most $k$ \u2018merge-\u2019 queries are created during each merge event. \u2018merge-\u2019 queries are created when some \u2018clique\u2019 queries are re-labelled as \u2018merge-\u2019. Specifically, all the \u2018clique\u2019 queries created during every execution of Compare within the current execution of Insert are relabelled as \u2018merge-\u2019. On any execution of Insert, at most one \u2018clique\u2019 query is created for every element in the current set $S$ . During any iteration of the for loop at Insert Line 1, the set $S$ is of size at most $k$ , implying that at most $k$ \u2018clique\u2019 queries are created during one execution of Insert. As a result at most $k$ \u2018merge-\u2019 queries are created at every merge event. ", "page_idx": 15}, {"type": "text", "text": "Similarly, \u2018merge+\u2019 queries are only created in correspondence with a merge event. Specifically, merge events occur when Compare returns result $=+1$ . When this happens, \u2018merge+\u2019 queries are created at Compare Line 17. When Line 17 is executed, the number of queries labelled \u2018merge+\u2019 is equal to the current value of count, which is at most at most $\\ell_{\\tt y e s}+1$ . Therefore, at most $\\ell_{\\tt y e s}+1$ \u2018merge+\u2019queries are created in correspondence with each merge event, concluding the proof. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "Lemma 9. At the end of the algorithm, the history of queries contains at most $2\\operatorname*{max}\\{\\ell_{y e s},\\ell_{n o}\\}$ queries labelled \u2018spurious\u2019. ", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma 9. Each query uv labelled \u2018spurious\u2019 can be paired uniquely with another query uv labelled spurious which returned the opposite answer. Hence, the number of erroneous answers returned by the oracle is at least the number of spurious queries divided by two. This number is upper bounded by $\\operatorname*{max}\\{\\ell_{\\mathrm{yes}},\\ell_{\\mathrm{no}}\\}$ and the result follows. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "Lemma 10. At the end of the algorithm, the history of queries contains at most $(\\ell_{n o}+1)\\binom{k+1}{2}$ queries labelled $'c l i q u e'$ . ", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma 10. The algorithm only labels queries as \u2018clique\u2019 in Line 9 of Compare. Thus every \u2018clique\u2019 query is made between two elements $u$ and $v$ such that both $u$ and $v$ were inserted into some construction of a clique, supported on the set $S$ . ", "page_idx": 16}, {"type": "text", "text": "If $S$ reaches cardinality $k+1$ , the if block on Line 5 of Insert is executed. We refer to this occurrence as a clique event. When a clique event occurs, queries have made up new a clique of $-1$ responses of size $k+1$ . In order for all of these responses to have been correct, the ground-truth partition would need to have been size at least $k+1$ , hence every time a clique event happens, a false negative error must have occurred. Since every clique event can be charged to a false negative error, at most $\\ell_{\\mathbf{n}\\circ}$ clique events can occur. ", "page_idx": 16}, {"type": "text", "text": "We will charge every \u2018clique\u2019 query made before a clique event to the first clique event following the query\u2019s creation. These queries represent a distinct edge $u v$ of a clique built on $S$ which eventually reaches size k + 1, and hence exactly k2+1 many of these \u2018clique\u2019 queries will occur per clique event. Finally, all \u2018clique\u2019 queries occurring after the last clique event make up the edges of a clique supported on the set $S$ , which never reaches size $k+1$ , and hence there are less than $\\textstyle{\\binom{k+1}{2}}$ such queries. ", "page_idx": 16}, {"type": "text", "text": "The result then follows. ", "page_idx": 16}, {"type": "text", "text": "Lemma 11. If Algorithm 5 makes a finite number of queries, then it must terminate. ", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma 11. We show that if Algorithm 5 makes a finite number of queries, then Line 4 of Algorithm 5 is executed a finite number of times. This implies termination of Algorithm 5. ", "page_idx": 16}, {"type": "text", "text": "When Line 4 of Algorithm 5 executes, Algorithm 5 calls Algorithm 7, Insert. If $S$ is nonempty on the execution of Line 4, then Insert calls Compare on some pair of elements. On every call to Compare, Line 4 of Compare executes at least once, and hence the algorithm makes at least one query. If $S$ is empty on the execution of Line 4, then Insert increases the size of $S$ by 1. This implies that on the next execution of Line 4, $S$ will be nonempty. Thus in order for Algorithm 5 to execute Line 4 infinitely many times, the algorithm must make infinitely many queries, yielding the result. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "We now analyze the number of queries made by the algorithm. We begin by noting that when the algorithm terminates, every query made will hold exactly one of the following labels: \u2018merge-\u2019, $\\scriptstyle{\\mathrm{~merge}}+{^{\\prime}}$ , \u2018clique\u2019, \u2018spurious\u2019. The analysis proceeds by showing how labels of each category contribute to either (a) correctly identifying the true partition, or (b) correctly certifying the occurrence of errors. ", "page_idx": 16}, {"type": "text", "text": "Equipped with these lemmata, we now prove Theorem 1. ", "page_idx": 16}, {"type": "text", "text": "Proof of Theorem 1. Let $|{\\mathfrak{m e r g e^{-}}}^{\\prime}|,|{\\mathfrak{m e r g e^{+}}}^{\\prime}|,|{\\mathfrak{s p u r i o u s}}^{\\prime}|,|{\\mathfrak{c}}{\\mathtt{l i q u e}}^{\\prime}|$ be the number of \u2018merge-\u2019, \u2018merge+\u2019, \u2018spurious\u2019 and \u2018clique\u2019 queries made by the algorithm respectively. By Lemmata 8, 9, and 10, the algorithm makes at most ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\mathbf{\\eta}|\\mathbf{merge}^{-\\prime}|+|\\mathbf{\\eta}|\\mathbf{merge}^{+\\prime}|+|\\mathbf{\\eta}|^{*}\\mathbf{spurious}^{\\prime}|+|\\mathbf{\\eta}|^{*}\\mathbf{clique}^{\\prime}|}\\\\ &{\\qquad\\qquad\\leq n k-k^{2}+(\\ell_{\\mathtt{y e s}}+1)(n-k)+2\\operatorname*{max}\\{\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}}\\}+(\\ell_{\\mathtt{n o}}+1)\\binom{k+1}{2}}\\\\ &{\\qquad\\qquad=O\\left(R S^{k}(n,k)\\right.\\left.+(n-k)\\ell_{\\mathtt{y e s}}+k^{2}\\ell_{\\mathtt{n o}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "many queries. By Lemma 11 this implies that the algorithm must terminate. ", "page_idx": 17}, {"type": "text", "text": "When the algorithm terminates, the condition in the while loop of Learn is not met, and hence $|{\\mathcal{C}}^{\\prime}|\\leq k$ . But since, by Lemma $7\\,\\mathcal{C}^{\\prime}$ is a refinement of $\\mathcal{C}$ , it must hold that upon termination $\\left|{\\mathcal{C}}^{\\prime}\\right|=k$ and hence ${\\mathcal{C}}^{\\prime}={\\mathcal{C}}$ . The algorithm then returns the correct hidden partition $\\mathcal{C}$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "D The algorithm for $k$ -unknown ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section we describe an algorithm for the weighted $\\ell$ -PL problem in the $k$ -unknown setting, and further prove that it achieves optimal asymptotic performance for the unweighted version of the problem. A complete description of the algorithm is given in the pseudocode below. Note that the algorithm makes use of subroutines defined in Section D. The main challenge in adapting Algorithm 5 in Section 6 is that the algorithm crucially relies on knowing the value of $k$ to build a lower bound to the number of observed errors, by counting the number of $\\left(k+1\\right)$ -cliques of $-1$ answers observed. ", "page_idx": 17}, {"type": "text", "text": "To overcome this problem, the new algorithm will instead simply aim to build the largest possible clique of $-1$ answers. We show that, remarkably, when false positive and false negative errors are equivalent $(\\ell_{\\mathtt{y e s}}=\\ell_{\\mathtt{n o}}=\\ell)$ , this suffices to match the optimal guarantees of Algorithm 5, up to small constant factors. ", "page_idx": 17}, {"type": "image", "img_path": "ygDl8q02gA/tmp/53677d53ba03d24469530a40579bd70d60a8017ebbb2eac58e5c93a0258a1312.jpg", "img_caption": [], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "The intuition behind the success of Algorithm 9 is that, for the algorithm to construct large cliques (significantly larger than the cardinality $k$ of the hidden partition), the oracle must return many incorrect answers. We formalize this intuition in Lemma 12. ", "page_idx": 17}, {"type": "text", "text": "Consider the execution of Algorithm 9. The algorithm will repeatedly construct cliques of $-1$ queries supported on vertex sets $S_{i}$ , adding elements to $S_{i}$ until all elements of $V$ belong to an equivalence class $[u]_{\\mathcal{C}^{\\prime}}$ for some $u\\in S_{i}$ . Once this condition is met, the algorithm increments $i$ and initializes $S_{i+1}$ as the empty set. The following lemma shows that the maximum size of any such set $S_{i}$ constructed by the algorithm is bounded as a function of the true unknown partition size $k$ and the error parameter $\\ell_{\\mathbf{n}\\circ}$ . ", "page_idx": 17}, {"type": "text", "text": "Consider the set $S_{i}$ constructed by Algorithm 9 while $\\mathtt{i d x}=i$ . We will denote by $n_{i}$ the maximum cardinality attained by this set $S_{i}$ . For convention we will also set $n_{0}=n$ . Moreover, we let $\\ell_{i}$ denote the number of false negative responses returned while $\\mathtt{i d x}=i$ . ", "page_idx": 17}, {"type": "text", "text": "Lemma 12. For any $i\\geq1$ , we have: ", "page_idx": 17}, {"type": "equation", "text": "$$\nn_{i}\\leq k+\\sqrt{2k\\ell_{i}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Note that, if the hidden partition has cardinality $k$ , and the algorithm obtains a clique of $-1$ responses on $n_{i}$ vertices, then the number of false negative errors contained in the clique responses is at least the minimum number of within-cluster edges of any $k$ -partition of the complete graph $K_{n_{i}}$ . ", "page_idx": 17}, {"type": "text", "text": "I.e. a lower bound to the number of false negative errors that must have occurred is given by: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\ell_{i}\\geq\\operatorname*{min}\\left\\{\\displaystyle\\sum_{j=1}^{k}\\binom{c_{j}}{2}\\bigg|c_{1},...,c_{k}\\in\\mathbb{N},\\displaystyle\\sum_{j=1}^{k}c_{j}=n_{i}\\right\\}}\\\\ {\\geq\\operatorname*{min}\\left\\{\\displaystyle\\sum_{j=1}^{k}\\frac{c_{j}(c_{j}-1)}{2}\\bigg|c_{1},...,c_{k}\\in\\mathbb{R}_{>0},\\displaystyle\\sum_{j=1}^{k}c_{j}=n_{i}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that the function $\\begin{array}{r}{f(x)=\\frac{x(x-1)}{2}}\\end{array}$ is convex, and hence by Karamata\u2019s Inequality (Theorem 1 from [25]) the right-hand side above is lower bounded by: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\ell_{i}\\geq\\sum_{j=1}^{k}{\\frac{{\\frac{n_{i}}{k}}\\left({\\frac{n_{i}}{k}}-1\\right)}{2}}={\\frac{1}{2}}n_{i}\\left({\\frac{n_{i}}{k}}-1\\right).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Re-arranging, we find that $n_{i}^{2}-k n_{i}\\leq2\\ell_{i}k$ . Completing the square we obtain: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left(n_{i}-{\\frac{1}{2}}k\\right)^{2}\\leq2\\ell_{i}k+{\\frac{1}{4}}k^{2}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "giving: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{n_{i}-\\displaystyle\\frac{1}{2}k\\le\\sqrt{2\\ell_{i}k+\\displaystyle\\frac{1}{4}k^{2}}\\le\\sqrt{2\\ell_{i}k}+\\displaystyle\\frac{1}{2}k,}}\\\\ {{n_{i}\\le\\sqrt{2\\ell_{i}k}+k,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and hence: ", "page_idx": 18}, {"type": "text", "text": "as needed. ", "page_idx": 18}, {"type": "text", "text": "Crucially, we note that as with Algorithm 5, the partition $\\mathcal{C}^{\\prime}$ maintained by Algorithm 9 is always a refinement of the ground-truth. ", "page_idx": 18}, {"type": "text", "text": "Lemma 13. Throughout the execution of Algorithm 9, $\\mathcal{C}^{\\prime}$ is always a refinement of the true partition.   \nThe proof of this lemma is identical to the proof of Lemma 7. ", "page_idx": 18}, {"type": "text", "text": "Lemma 14. Algorithm 9 terminates. ", "page_idx": 18}, {"type": "text", "text": "Proof. We show that Lines 6 and 10 in Algorithm 9 execute finitely many times. This implies termination of the algorithm. ", "page_idx": 18}, {"type": "text", "text": "Every time Line 6 executes, the value of idx is incremented by 1. Once the value of idx exceeds $\\ell_{\\mathfrak{n}\\circ}+1$ , the while loop in Algorithm 9 exits, and thus Line 6 can only execute finitely many times. ", "page_idx": 18}, {"type": "text", "text": "To show that Line 10 executes finitely many times, we show that every time Line 10 executes, either $\\mathcal{C}^{\\prime}$ decreases in cardinality or $S_{\\mathrm{idx}}$ increases in cardinality. This follows from considering Algorithm 7, Insert. On each call to Insert, either result $=+1$ for some $u\\in S$ , in which case the cardinality of $\\mathcal{C}^{\\prime}$ is reduced in Line 8, or result $=-1$ for every $u\\,\\in\\,S$ . In the latter case, the size of $S$ is increased in Line 13. ", "page_idx": 18}, {"type": "text", "text": "By Lemma 13, $\\mathcal{C}^{\\prime}$ is always a refinement of $\\mathcal{C}$ and thus its cardinality cannot decrease more than $(n-k)$ times. Similarly, for each value ${\\dot{\\mathtt{i d x}}}=i$ , $|S_{i}|\\leq n$ so $S_{i}$ can increase in size finitely many times for each value of $\\mathtt{i d x}\\in[1,\\ell_{\\mathtt{n o}}+1]$ . This implies that Line 10 can only execute finitely many times, completing the proof. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Lemma 15. When Algorithm 9 terminates $\\mathcal{C^{\\prime}}$ is equal to the ground-truth partition $\\mathcal{C}$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. By Lemma $13\\,{\\mathcal{C}}^{\\prime}$ is always a refinement of $\\mathcal{C}$ . Therefore to show that the partition $\\mathcal{C^{\\prime}}$ returned is equal to $\\mathcal{C}$ , it remains to show that the cardinality of $\\mathcal{C}^{\\prime}$ upon termination is the true unknown value $k$ . ", "page_idx": 18}, {"type": "text", "text": "Assume for the sake of contradiction that this does not hold. Once initialized, the only place where $\\mathcal{C}^{\\prime}$ is modified during the execution of Algorithm 9 is in Lines 7 and 8 of Insert. There, the algorithm modifies $\\mathcal{C^{\\prime}}$ by merging two previously disjoint equivalence classes. This reduces the number of disjoint equivalence classes in $\\mathcal{C^{\\prime}}$ , and so in particular the cardinality of $\\mathcal{C^{\\prime}}$ montonically decreases during the execution of Algorithm 9. Thus if upon termination the cardinality of $\\mathcal{C^{\\prime}}$ is strictly greater than $k$ , then this was true at all points during the algorithm\u2019s execution. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "Recall that $n_{i}$ is defined to be the maximum cardinality attained by set $S_{i}$ . In particular, $S_{i}$ attains maximum size when Line 6 of Algorithm 9 is executed. When this happens, $S_{i}$ contains exactly one representative from every cluster in $\\mathcal{C}^{\\prime}$ at the time of execution. If the size of $\\mathcal{C^{\\prime}}$ is strictly greater than $k$ at all points during the execution of Algorithm 9 then $n_{i}>k\\;\\forall i\\in[0,\\ell_{\\mathtt{n o}}+1]$ . ", "page_idx": 19}, {"type": "text", "text": "In particular for every value $i\\in[1,\\ell_{\\mathrm{n}0}+1]$ , for every distinct $u$ , $v\\in S_{i}$ Algorithm 9 receives at least one response $-1$ for query $(u,v)$ . This response is consistent with the scenario in which $u$ and $v$ belong to disjoint sets in the ground truth partition $\\mathcal{C}$ . If $n_{i}>|{\\mathcal{C}}|$ then at least one of these responses must have been a false negative error. As this holds for every value $i\\in[1,\\ell_{\\mathtt{n}0}+1]$ , this implies least $\\ell_{\\mathfrak{n}\\circ}+1$ false negative responses occur during the execution of Algorithm 9. In particular this violates the assumption that $\\alpha$ is an $(\\ell_{\\mathtt{y e s}},\\ell_{\\mathtt{n o}})$ -faulty oracle, and we thus conclude that the size of $\\mathcal{C}^{\\prime}$ cannot be greater than $k$ upon termination, implying that the partition returned by the algorithm satisfies ${\\mathcal{C}}^{\\prime}={\\mathcal{C}}$ . \u53e3 ", "page_idx": 19}, {"type": "text", "text": "As with the analysis of Algorithm 5, bounding the query complexity of Algorithm 9 reduces to bounding the number of queries with labels \u2018merge-\u2019, \u2018merge+\u2019, \u2018clique\u2019, \u2018spurious\u2019 upon termination of the algorithm. ", "page_idx": 19}, {"type": "text", "text": "Lemma 16. When Algorithm 9 terminates the history of queries contains at most $\\left(1+\\sqrt{2}\\right)\\left(\\ell_{n o}+\\right.$ $1)k^{2}$ queries labelled \u2018clique\u2019. ", "page_idx": 19}, {"type": "text", "text": "Proof. All queries labeled \u2018clique\u2019 upon termination must have been created during the construction of some set $S_{i}$ while ${\\dot{\\tt I d x}}{=}\\;i$ . Given $n_{i}$ the maximum cardinality attained by set $S_{i}$ , the number of \u2018clique\u2019 queries present upon termination that were constructed while $\\mathtt{i d x}{=}\\ i$ is exactly ", "page_idx": 19}, {"type": "equation", "text": "$$\n{\\binom{n_{i}}{2}}={\\frac{1}{2}}(n_{i}^{2}-n_{i})\\leq k^{2}+2k{\\sqrt{2k\\ell_{i}}}+2k\\ell_{i}-n_{i}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the upperbound follows from Lemma 12 and $\\ell_{i}$ denotes the number of false negative responses returned by the oracle while $\\mathtt{i d x}{=}\\ i$ . Summing the total number of such queries over all iterates $\\mathtt{i d x=1,\\ldots,\\ell_{n0}+1}$ , we obtain: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{i=1}^{\\ell_{\\infty}+1}\\binom{n_{i}}{2}\\leq\\frac{1}{2}\\sum_{i=1}^{\\ell_{\\infty}+1}k^{2}+2k\\sqrt{2k\\ell_{i}}+2k\\ell_{i}-n_{i}}\\\\ {\\displaystyle=\\frac{1}{2}(\\ell_{\\infty}+1)k^{2}+\\sqrt{2}\\sum_{i=1}^{\\ell_{\\infty}+1}k\\sqrt{k\\ell_{i}}+k\\sum_{i=1}^{\\ell_{\\infty}+1}\\ell_{i}-\\frac{1}{2}\\sum_{i=1}^{\\ell_{\\infty}+1}n_{i}}\\\\ {\\displaystyle\\leq\\frac{1}{2}(\\ell_{\\infty}+1)k^{2}+\\sqrt{2}k\\sum_{i=1}^{\\ell_{\\infty}+1}\\frac{\\ell_{i}+k}{2}+k\\sum_{i=1}^{\\ell_{\\infty}+1}\\ell_{i}-\\frac{1}{2}\\sum_{i=1}^{\\ell_{\\infty}+1}n_{i}}\\\\ {\\displaystyle=\\frac{1}{2}(\\ell_{\\infty}+1)k^{2}+\\frac{k\\ell_{\\infty}}{\\sqrt{2}}+\\frac{(\\ell_{\\infty}+1)k^{2}}{\\sqrt{2}}+k\\ell_{\\infty}-\\frac{1}{2}k(\\ell_{\\infty}+1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The last line follows by observing that by definition of $\\ell_{i}$ , $\\textstyle\\sum_{i=1}^{\\ell+1}\\ell_{i}\\leq\\ell_{\\mathtt{n o}}$ . ", "page_idx": 19}, {"type": "text", "text": "We can simplify the above expression using the fact that for integer $k$ it holds that $k\\leq k^{2}$ , to obtain the bound: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\frac12(\\ell_{\\mathrm{no}}+1)k^{2}+\\frac{k\\ell_{\\mathrm{no}}}{\\sqrt{2}}+\\frac{(\\ell_{\\mathrm{no}}+1)k^{2}}{\\sqrt{2}}+k\\ell-\\frac{1}{2}k(\\ell_{\\mathrm{no}}+1)=\\left(\\frac12+\\frac{1}{\\sqrt{2}}\\right)\\big((\\ell_{\\mathrm{no}}+1)k^{2}+k\\ell_{\\mathrm{no}}\\big)}\\\\ {\\leq\\left(1+\\sqrt{2}\\right)(\\ell_{\\mathrm{no}}+1)k^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Lemma 17. Upon termination of Algorithm 9, the history of queries contains at most $2\\operatorname*{max}\\{\\ell_{y e s},\\ell_{n o}\\}$ queries labelled \u2018spurious\u2019. ", "page_idx": 19}, {"type": "text", "text": "The proof follows analogously to that of Lemma 9. ", "page_idx": 20}, {"type": "text", "text": "Lemma 18. Upon termination of Algorithm 9, the history of queries contains at most $(\\ell_{y e s}\\!+\\!1)(n\\!-\\!k)$ queries labelled \u2018merge+\u2019, and at most ", "page_idx": 20}, {"type": "equation", "text": "$$\n(n-k)\\operatorname*{max}\\left\\{(1+\\sqrt{2})k,k+\\ell_{n o}\\sqrt{2}\\right\\}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "queries labelled \u2018merge-\u2019. ", "page_idx": 20}, {"type": "text", "text": "Proof. Similarly to the analysis of Algorithm 5, we analyze the numbers of $\\mathbf{\\dot{m}e r g e}^{+}$ and \u2018merge-\u2019 queries, by considering merge events. A merge event is defined as the execution of Line 5 in Insert. ", "page_idx": 20}, {"type": "text", "text": "Recall that $n_{i}$ is define to be the maximum cardinality attained by set $S_{i}$ . In particular, $S_{i}$ attains maximum size when Line 6 of Algorithm 9 is executed. When this happens, $S_{i}$ contains exactly one representative from every cluster in $\\mathcal{C}^{\\prime}$ at the time of execution. Thus $n_{i}-n_{i+1}$ is equal to the number of clusters merged while $\\mathtt{i d x}=(i+1)$ , i.e. the number of merge events that occurred while $\\mathtt{i d x}=(i+1)$ . Moreover the size of $\\mathcal{C^{\\prime}}$ upon termination of Algorithm 9 is equal to $n_{\\ell_{\\tt n o}+1}$ , and hence by Lemma $15\\;n_{\\ell_{\\tt n o}+1}=k$ . This implies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{i=0}^{\\ell_{\\mathrm{no}}}n_{i}-n_{i+1}=n_{0}-n_{\\ell_{\\mathrm{no}}+1}=n-k.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "As with the proof of Lemma 8, we note that each \u2018merge+\u2019 query can be charged to a unique merge event in such a way that exactly $\\ell_{\\mathrm{yes}}+1~\\mathrm{^{\\bullet}m e r g e+^{\\circ}}$ queries are charged to each merge event. As a result, the number $|{\\mathsf{'m e r g e}}{\\mathsf{+}}^{\\prime}|$ of \u2018merge+\u2019 queries satisfies: ", "page_idx": 20}, {"type": "equation", "text": "$$\n|{\\mathsf{m e r g e}}^{\\prime}|=\\sum_{i=0}^{\\ell_{\\mathsf{n o}}}(\\ell_{\\mathsf{y e s}}+1){\\big(}n_{i}-n_{i+1}{\\big)}=(\\ell+1)(n-k)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Similarly, \u2018merge-\u2019 queries are only created in correspondence with a merge event. Specifically, \u2018merge-\u2019 are created when \u2018clique\u2019 queries are re-labelled as \u2018merge-\u2019. When $\\mathtt{i d x}=(i+1)$ on any single execution of Insert, at most one \u2018clique\u2019 query is created for every element in the current set $S_{(i+1)}$ . Hence at most $n_{i+1}$ \u2018merge-\u2019 queries correspond to each merge event that occurs while $\\mathtt{i d x}=(i+1)$ . Summing over all values attained by idx, this implies the total number of queries labeled \u2018merge-\u2019 is bounded by ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{^\\langle\\mathbf{\\underline{{\\tau}}}_{\\mathrm{merge}^{-\\prime}}|\\leq\\sum_{i=0}^{\\ell_{\\mathrm{m}}}n_{i+1}(n_{i}-n_{i+1})}}\\\\ &{\\leq\\displaystyle\\sum_{i=0}^{\\ell_{\\mathrm{m}}}(k+\\sqrt{2k\\ell_{i+1}})(n_{i}-n_{i+1})}\\\\ &{=k\\sum_{i=0}^{\\ell_{\\mathrm{m}}}(n_{i}-n_{i+1})+\\sqrt{2k}\\sum_{i=0}^{\\ell_{\\mathrm{m}}}(n_{i}-n_{i+1})\\sqrt{\\ell_{i+1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second inequality follows from the bound in Lemma 12. Invoking the fact that $\\textstyle\\sum_{i=0}^{\\ell_{\\mathrm{no}}}n_{i}-$ $n_{i+1}=n-k$ , we can bound the above and obtain: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\mathrm{\\lceil{\\Psi}\\rfloor}\\cdot\\operatorname{merge}\\cdot}}&{|\\le k\\cdot(n-k)+\\sqrt{2k}\\cdot\\operatorname*{max}_{i}\\sqrt{\\ell_{i+1}}\\cdot\\sum_{i=0}^{\\ell_{\\mathrm{no}}}(n_{i}-n_{i+1})}\\\\ &{\\le\\left(k+\\sqrt{2k\\ell_{\\mathrm{no}}}\\right)(n-k)}\\\\ &{\\le(n-k)\\cdot\\operatorname*{max}\\left\\{(1+\\sqrt{2})k,k+\\ell_{\\mathrm{no}}\\sqrt{2}\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "yielding the result. ", "page_idx": 20}, {"type": "text", "text": "Equipped with the above lemmata, we proceed to prove Theorem 3. ", "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 3. By Lemmata 14 and 15, Algorithm 9 terminates and returns the correct hidden partition. It thus remains to bound the number of queries made during execution. ", "page_idx": 21}, {"type": "text", "text": "Let $|{\\mathsf{{\\cdot m e r g e}^{-}}}|,|{\\mathsf{{m e r g e}^{+}}}|,|{\\mathsf{{\\cdot s p u r i o u s}^{\\prime}}}|,|{\\mathsf{{\\cdot c l i q u e}^{\\prime}}}|$ be the number of \u2018merge-\u2019, \u2018merge+\u2019, \u2018spurious\u2019 and $^\\cdot{\\tt c1}$ ique\u2019 queries made by the algorithm respectively. By Lemmata 16, 17, and 18, the algorithm makes at most ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\mathsf{m e r g e}^{-}|\\!+\\!|\\mathsf{m e r g e}^{+}|+|\\!*\\mathsf{s p u r i o u s}^{\\prime}|+|\\!*\\mathsf{c l i q u e}^{\\prime}|}\\\\ &{\\qquad\\qquad\\leq(n-k)\\operatorname*{max}\\Big\\{(1+\\sqrt{2})k,k+\\ell_{\\mathrm{no}}\\sqrt{2}\\Big\\}+(\\ell_{\\mathsf{y e s}}+1)(n-k)}\\\\ &{\\qquad\\qquad\\qquad+\\,2\\operatorname*{max}\\{\\ell_{\\mathsf{y e s}},\\ell_{\\mathsf{n o}}\\}+(1+\\sqrt{2})(\\ell_{\\mathsf{n o}}+1)k^{2}}\\\\ &{\\qquad\\qquad=O\\left(R S^{u}(n,k)+(n-k)\\operatorname*{max}\\{\\ell_{\\mathsf{y e s}},\\ell_{\\mathsf{n o}}\\}+k^{2}\\ell_{\\mathsf{n o}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "many queries. ", "page_idx": 21}, {"type": "text", "text": "E Lower bound results ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "E.1 Lower bounds for the easy problem: $\\ell$ -false negatives ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We prove the following lower bound on the query complexity of the $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ problem. ", "page_idx": 21}, {"type": "text", "text": "Theorem 19. Every algorithm for the $\\ell{-}P L^{F N}$ problem which guarantees full recovery of the correct partitions requires $\\stackrel{\\cdot}{R S^{\\check{k}}}(n,k)+\\Omega(k^{2}\\ell)$ queries in the worst case. ", "page_idx": 21}, {"type": "text", "text": "Because the $\\ell{-}\\mathrm{PL}^{\\mathrm{FN}}$ problem is no harder than the $\\ell_{}$ -PL problem, this immediately implies the same lower bound on the query complexity of the $\\ell$ -PL problem. ", "page_idx": 21}, {"type": "text", "text": "To establish this result, we introduce and analyze a game between a Quetionner and a Responder, representing the algorithm and the oracle respectively. ", "page_idx": 21}, {"type": "text", "text": "Definition of the $\\mathbf{RUCC^{\\mathrm{FN}}}$ game. We define the following game, which we call the $\\mathrm{RUCC}^{\\mathrm{FN}}$ game. The game is played by two players, the questioner $(Q)$ and the responder $(R)$ and it is parametrized by a finite set $V$ of cardinality $n$ , a positive integer $k\\in\\{2,...,n-1\\}$ , and a non-negative integer $\\ell$ . The goal of the questioner is to infer a $k$ -partition of $V$ given input from the responder. At the start of the game, we are given a complete undirected graph $G_{0}$ on vertex set $V$ . $G_{0}\\bar{=}\\left(V,E,w_{0}^{+},w_{0}^{-}\\right)$ has two associated edge weight functions $w_{0}^{+}:E\\to\\mathbb{R}$ and $w_{0}^{-}:E\\to\\mathbb{R}$ , both of which are set to zero at the beginning of the game. ", "page_idx": 21}, {"type": "text", "text": "At each iteration $t$ , the questioner $Q$ submits a query $u v$ for distinct $u$ and $v$ in $V$ . The responder $R$ then issues a response $r_{t}\\in\\{\\pm1\\}$ . If $r_{t}=+1$ , then $w^{+}$ is updated by setting $w_{t}^{+}(u v)=w_{t-1}^{+}(u v){+}1$ . Otherwise, if $r_{t}\\,=\\,-1$ , then $w^{-}$ is updated by setting $w_{t}^{-}(u v)\\,=\\,w_{t-1}^{-}(u v)+1$ . We then set $G_{t}=(V,E,w_{t}^{+},w_{t}^{-})$ . ", "page_idx": 21}, {"type": "text", "text": "For any partition $\\mathcal{C}$ of $V$ , we define the cost: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\cos\\!\\mathrm{t}_{G_{t}}^{\\mathrm{FN}}(\\mathcal{C})\\stackrel{\\mathrm{def}}{=}\\sum_{\\stackrel{u v\\in E}{u\\sim c\\,v}}w_{t}^{-}(u v)+\\mathbb{I}\\left(\\sum_{\\stackrel{u v\\in E}{u\\sim c\\,v}}w_{t}^{+}(u v)=0\\right),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\mathbb{I}$ is the convex indicator function. Intuitively, the value of $\\mathrm{cost}_{G_{t}}^{\\mathbb{F N}}(\\mathcal{C})$ is the number of incorrect negative $(-1)$ answers that the responder would have to have given if $\\mathcal{C}$ was the correct partition, or infinity if the responder would have had to given any incorrect positive $(+1)$ answer. ", "page_idx": 21}, {"type": "text", "text": "We require that the responder must, at each iteration $t$ , reply in a way that guarantees that there exists some $k$ -partition $\\mathcal{C}$ of $V$ such that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathrm{cost}_{G_{t}}^{\\mathtt{F N}}(\\mathcal{C})\\leq\\ell.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "The game terminates when $\\mathrm{cost}_{G_{t}}^{\\mathbb{F N}}(\\mathcal{C})$ is strictly more than $\\ell$ for all but one $k$ -partition $\\mathcal{C}$ of $V$ , indicating that the responder is left with a single feasible partition and hence they have learned the ground truth. If the game terminates at iteration $T$ , then the payoff to the responder player is $T$ , and the payoff to the questioner is $-T$ . ", "page_idx": 21}, {"type": "text", "text": "Given a questioner strategy $Q$ and a responder strategy $R$ , we let Game $^{\\mathrm{FN}}(Q,R)$ be the number of iterations the game lasts when questioner $Q$ plays against responder $R$ , as a function of the parameters $n$ , $k$ and $\\ell$ . The query complexity of the $\\ell{-}\\bar{\\mathbf{P}}\\mathbf{L}^{\\mathrm{FN}}$ problem is the value: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{Q\\in{\\mathcal{Q}}}\\operatorname*{max}_{R\\in{\\mathcal{R}}}\\mathrm{Game}^{\\mathtt{F N}}(Q,R),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\mathcal{Q}$ is the set of all possible questioner strategies and $\\mathcal{R}$ is the set of all possible responder strategies. A simple argument then shows: ", "page_idx": 22}, {"type": "text", "text": "Lemma 20. Let $f$ be a non-negative real valued function. If there exists a responder strategy $R^{*}$ such that: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\forall n,k,\\ell\\in\\mathbb{N}_{0}:\\qquad\\operatorname*{min}_{Q\\in{\\mathcal{Q}}}\\mathrm{Game}^{F n}(Q,R^{*})\\geq f(n,k,\\ell),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "then the query complexity of the $\\ell{-}P L^{F N}$ problem is at least $f(n,k,\\ell)$ . ", "page_idx": 22}, {"type": "text", "text": "Proof. This follows from: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{Q\\in\\mathcal{Q}}\\operatorname*{max}_{R\\in\\mathcal{R}}\\operatorname{Game}^{\\mathtt{F N}}(Q,R)\\ge\\operatorname*{min}_{Q\\in\\mathcal{Q}}\\operatorname{Game}^{\\mathtt{F N}}(Q,R^{*})\\ge f(n,k,\\ell).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "In Theorem 23 in Appendix F.1 we show that there exists a responder strategy $R^{*}$ satisfying ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{Q\\in\\mathcal{Q}}\\operatorname{Game}^{\\mathrm{FN}}(Q,R^{*})\\geq(\\ell+1)\\left(\\binom{k+1}{2}-1\\right)=\\Omega(\\ell k^{2})\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "queries. Lemma 20 and Theorem 23, together with the lower bound of Liu and Mukherjee for the problem without errors [26] immediately imply Theorem 19. ", "page_idx": 22}, {"type": "text", "text": "E.2 Lower bounds for the easy problem: $\\ell$ -false positives ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We prove the following lower bound on the query complexity of the $\\ell{-}\\mathrm{PL}^{\\mathrm{FP}}$ problem: ", "page_idx": 22}, {"type": "text", "text": "Theorem 21. Every algorithm for the $\\ell{-}P L^{F P}$ problem which guarantees exact recovery of the correct partition requires $R S^{k}(n,k)+\\Omega(\\ell(n-k))$ queries in the worst case. ", "page_idx": 22}, {"type": "text", "text": "As in Section E.1, this result immediately implies the same lowerbound for the $\\ell$ -PL problem. In order to analyze the query complexity of learning partitions with $\\ell$ false positives, we consider a very similar game to that defined above in Appendix E.1. ", "page_idx": 22}, {"type": "text", "text": "Definition of the RUCCFP game. The $\\mathrm{RUCC}^{\\mathrm{FP}}$ game is defined with the same setup as the $\\mathrm{RUCC}^{\\mathrm{FN}}$ game. The questioner $\\mathrm{^Q}$ , responder $\\mathbf{R}$ , finite set $V$ , and gameplay graph $\\begin{array}{r l}{G_{t}}&{{}=}\\end{array}$ $(V,E,w_{t}^{+},\\stackrel{\\_}{w_{t}^{-}})$ are all defined as in Appendix E.1. The core distinction between the RUCCFP game and the $\\mathrm{RUCC^{FN}}$ game is the notion of cost employed. For the $\\mathrm{RUCC}^{\\mathrm{FP}}$ game, for any partition $\\mathcal{C}$ of $V$ we define the cost ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\cos\\!\\mathrm{t}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C})\\stackrel{\\mathrm{def}}{=}\\sum_{u v\\in E\\atop u\\not\\sim c\\,v}w_{t}^{+}(u v)+\\mathbb{I}\\left(\\sum_{u v\\in E\\atop u\\sim c\\,v}w_{t}^{-}(u v)\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Intuitively, the value of $\\cos\\mathbf{t}^{\\mathrm{FP}}(\\mathcal{C})$ is either the number of incorrect positive answers $(+1)$ that the responder would have to have given if $\\mathcal{C}$ were the correct partition, or the value is infinity if the responder would have given any incorrect negative $(-1)$ answer. ", "page_idx": 22}, {"type": "text", "text": "The rules of the game require that at each iteration $t$ , the responder must reply in such a way that guarantees the existence of some $k$ -partition $\\mathcal{C}^{*}$ of $V$ such that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}^{*})\\leq\\ell.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The game terminates when there exists a unique $k$ -partition $\\mathcal{C}^{*}$ such that $\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}^{*})\\le\\ell$ . ", "page_idx": 22}, {"type": "text", "text": "The query complexity of the $\\ell{-}\\mathrm{PL}^{\\mathrm{FP}}$ problem can be characterized as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{Q\\in{\\mathcal{Q}}}\\operatorname*{max}_{R\\in{\\mathcal{R}}}\\mathrm{Game}^{\\mathtt{F P}}(Q,R),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where Game ${}^{\\mathrm{FP}}(Q,R)$ indicates the number of iterations in the $\\mathrm{RUCC}^{\\mathrm{FP}}$ game when questioner strategy $Q$ plays against responder $R$ . As in Appendix E.1, this characterization allows us to lower bound the query complexity of the problem by analyzing the $\\mathrm{RUCC}^{\\mathrm{FP}}$ game: ", "page_idx": 23}, {"type": "text", "text": "Lemma 22. Let $f$ be a non-negative real valued function. If there exists a responder strategy $R^{*}$ such that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\forall n,k,\\ell\\in\\mathbb{N}_{0}:\\quad\\,\\,\\operatorname*{min}_{Q\\in\\mathcal{Q}}\\mathrm{Game}^{F P}(Q,R^{*})\\geq f(n,k,\\ell)\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "then the query complexity of learning partitions with $\\ell$ false positives is at least $f(n,k,\\ell)$ . ", "page_idx": 23}, {"type": "text", "text": "The proof is entirely analogous to that of Lemma 20. ", "page_idx": 23}, {"type": "text", "text": "In Theorem 25 from Appendix F.2 we show that there exists a responder strategy $R^{*}$ which satisfies: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{Q\\in\\mathcal{Q}}\\operatorname{Game}^{\\mathrm{FP}}(Q,R^{*})\\geq\\frac{(\\ell+1)(n-k+1))}{2}=\\Omega(\\ell(n-k)).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This, together with Lemma 22 immediately implies Theorem 21. ", "page_idx": 23}, {"type": "text", "text": "F One-sided error lower bounds strategies ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "F.1 A responder strategy for the RUCCFN game ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section we show that there exists a responder strategy for the $\\mathrm{RUCC}^{\\mathrm{FN}}$ game that guarantees the game lasts at least $\\Omega(\\ell k^{2})$ iterations. We consider a responder strategy which we call the $(k+1)$ -groups responder strategy, denoted $R_{(k+1)}$ . In this strategy, the responder fixes an arbitrary $(k+1)$ -partition of $V$ , denoted $\\mathcal{C}^{*}\\,=\\,\\{C_{i}^{*}\\}_{i=1}^{k+1}$ . We define $R_{(k+1)}$ as the responder strategy in which the responder replies consistently with $\\mathcal{C}^{*}$ whenever the rules of the $\\mathrm{RUCC^{FN}}$ game allow, i.e. whenever this does not cause the cost of every $k$ -partition to exceed $\\ell$ . We lower bound the number of iterations needed for any questioner strategy to terminate the $\\mathrm{RUCC}^{\\mathrm{FN}}$ game when playing against R(k+1): ", "page_idx": 23}, {"type": "text", "text": "Theorem 23. The $(k+1)$ -groups responder strategy $R_{(k+1)}$ satisfies ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{Q\\in\\mathcal{Q}}\\operatorname{Game}^{F^{H}}(Q,R_{(k+1)})\\ge(\\ell+1)\\left(\\binom{k+1}{2}-1\\right)=\\Omega(\\ell k^{2})\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "queries. ", "page_idx": 23}, {"type": "text", "text": "Proof. For $i,j\\in[k+1]$ , consider the $k$ -partitions $\\mathcal{C}_{i j}$ obtained by starting with $\\mathcal{C}^{*}$ and merging $C_{i}^{*}$ and $C_{j}^{*}$ i.e.: ", "page_idx": 23}, {"type": "equation", "text": "$$\n{\\mathcal C}_{i j}=\\{C_{a}^{*}\\}_{a\\in[k+1]\\backslash\\{i,j\\}}\\cup\\{C_{i}^{*}\\cup C_{j}^{*}\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We show that the questioner cannot increase the cost of more than one of these partitions $\\mathcal{C}_{i j}$ on any single iteration (a claim which we prove afterwards): ", "page_idx": 23}, {"type": "text", "text": "Claim 24. Suppose that $\\mathrm{cost}_{G_{t}}^{F N}({\\mathcal{C}}_{i j})\\leq\\ell.$ . Then on iteration $t+1$ the cost of $\\mathcal{C}_{i j}$ increases only if the questionner submits a query utv for $u\\in C_{i}^{*}$ and $v\\in C_{j}^{*}$ . ", "page_idx": 23}, {"type": "text", "text": "We now prove Theorem 23 using Claim 24. Consider the potential function: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi^{(t)}:=\\sum_{\\stackrel{i,j\\in[k+1]}{i\\not=j}}\\operatorname*{min}\\{\\mathrm{cost}_{G_{t}}^{\\mathrm{FN}}(\\mathcal{C}_{i j}),\\ell+1\\}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Note that, $\\phi^{(0)}=0$ and, by Claim 24, at every step $t$ of the game we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi^{(t+1)}\\leq\\phi^{(t)}+1.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Suppose that the game terminates at iteration $T$ . Then by the rule of the $\\mathrm{RUCC}^{\\mathrm{FN}}$ game, for all but one $k$ -partitions $\\mathcal{C}$ , it must be the case that $\\mathrm{cost}_{G_{T}}^{\\mathtt{F N}}(\\mathcal{C})>\\ell$ . In particular, all but at most one of the partitions $\\mathcal{C}_{i j}$ must have cost at least $\\ell+1$ , implying: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi^{(T)}\\geq(\\ell+1)\\left(\\binom{k+1}{2}-1\\right),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "image", "img_path": "ygDl8q02gA/tmp/17de5a0298085510bc342820f7d3d6d077db10d1bbef1eed2404095d4ce1c855.jpg", "img_caption": ["Figure 2: The partition $\\mathcal{C}^{*}$ used in the $(k-1)$ responder strategy. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "and hence: ", "page_idx": 24}, {"type": "equation", "text": "$$\nT\\geq(\\ell+1)\\left(\\binom{k+1}{2}-1\\right)=\\Omega(\\ell k^{2}),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "as needed. ", "page_idx": 24}, {"type": "text", "text": "We conclude this section by proving Claim 24. ", "page_idx": 24}, {"type": "text", "text": "Proof of Claim 24. Consider $G_{t}$ such that $\\mathrm{cost}_{G_{t}}^{\\mathtt{F N}}(\\mathcal{C}_{i j})\\leq\\ell$ and such that the $\\mathrm{RUCC}^{\\mathrm{FN}}$ Game has not yet terminated. Assume the query submitted by the questioner is not of the form $u v$ for any $u\\in C_{i}^{*}$ , $v\\in C_{j}^{*}$ . For any such $u v$ , by the definition of $\\mathcal{C}_{i j}$ the pair $u,v$ is in the same cluster with respect to partition $\\mathcal{C}_{i j}$ if and only if the pair is in the same cluster with respect to partition $\\mathcal{C}^{*}$ . Thus if the responder is able to return an answer consistent with $\\mathcal{C}^{*}$ , this response will also be consistent with $\\mathcal{C}_{i j}$ , and as a result ${\\mathrm{cost}}_{G_{t}}^{\\mathtt{F N}}(\\mathcal{C}_{i j})={\\mathrm{cost}}_{G_{t+1}}^{\\mathtt{F N}}(\\mathcal{C}_{i j})$ . ", "page_idx": 24}, {"type": "text", "text": "It remains to show that the responder is able to reply consistently with $\\mathcal{C}^{*}$ on such a query. By assumption $\\mathrm{cost}_{G_{t}}^{\\mathtt{F N}}(\\mathcal{C}_{i j})\\,\\le\\,\\ell$ , and as shown above responding consistently to the query $u v$ in a manner consistent with $\\mathcal{C}^{*}$ will ensure ${\\mathrm{cost}}_{G_{t}}^{\\mathtt{F N}}({\\mathcal{C}}_{i j})\\,=\\,{\\mathrm{cost}}_{G_{t+1}}^{\\mathtt{F N}}({\\mathcal{C}}_{i j})\\,\\le\\,\\ell$ . Thus if the responder replies to query $u v$ consistently with $\\mathcal{C}^{*}$ , there will still exist a $k$ -partition\u2013namely, $\\mathcal{C}_{i j}$ \u2013such that $\\mathrm{cost}_{G_{t+1}}^{\\mathtt{F N}}(\\mathcal{C}_{i j})\\le\\ell.$ Thus the rules of the $\\mathrm{RUCC}^{\\mathrm{FN}}$ game allow the responder to reply to query $u v$ consistently with $\\mathcal{C}^{*}$ , and by definition of strategy $R_{(k+1)}$ the responder will do so. Thus the cost of $\\mathcal{C}_{i j}$ at iteration $(t+1)$ does not increase when the questioner plays such a pair $u v$ . \u53e3 ", "page_idx": 24}, {"type": "text", "text": "F.2 A responder strategy for the RUCCFP ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we show that there exists a responder strategy for the $\\mathrm{RUCC}^{\\mathrm{FP}}$ game that guarantees that the game lasts at least $\\Omega(\\ell(n-k))$ iterations. In particular, we consider a responder strategy which we call the $(k-1)$ -groups responder strategy, denoted $R_{(k-1)}$ . This strategy fixes $k-2$ arbitrary elements $v_{1}^{*},...,v_{k-2}^{*}$ and then fixes the following $(k-1)$ -partition: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathcal{C}^{*}:=\\{V\\setminus\\{v_{1}^{*},...,v_{k-2}^{*}\\},\\{v_{1}^{*}\\},...,\\{v_{k-2}^{*}\\}\\}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "(See Figure Figure 2). Note that when $k\\,=\\,2$ , the set of $\\{v_{i}^{*}\\}$ is just empty and the partition $\\mathcal{C}^{*}$ consists of a single set equal to $V$ . We define the $(k-1)$ -groups strategy, as the responder strategy in which the responder replies consistently with $\\mathcal{C}^{*}$ whenever the rules of the $\\mathrm{RUCC}^{\\mathrm{FP}}$ game allow them to. ", "page_idx": 24}, {"type": "text", "text": "Theorem 25. The $(k-1)$ -groups responder strategy $R_{(k-1)}$ satisfies: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{Q\\in\\mathcal{Q}}\\operatorname{Game}^{F P}(Q,R_{(k-1)})\\geq\\frac{(\\ell+1)(n-k+1))}{2}=\\Omega(\\ell(n-k)).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. We will prove the theorem by considering a subset of the partitions which are hard for the questioner to differentiate among when playing against this responder strategy. Let $S^{\\ast}:=$ $V\\setminus\\bar{\\{}v_{1}^{*},...,v_{k-2}^{*}\\}$ , and for any $v\\in S^{*}$ let $\\mathcal{C}_{v}$ be the partition: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{C}_{v}:=\\{\\{v\\},S^{*}\\setminus\\{v\\},\\{v_{1}^{*}\\},...,\\{v_{k-2}^{*}\\}\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By definition of the $\\mathrm{RUCC}^{\\mathrm{FP}}$ game, at the end of the final iteration $T$ , we must have $\\mathrm{cost}_{G_{T}}^{\\mathtt{F P}}(\\mathcal{C}_{v})>\\ell$ for all but one of the partitions $\\{\\mathcal{C}_{v}\\}_{v\\in S^{*}}$ . In particular, consider the potential function: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\phi^{(t)}\\ \\stackrel{\\mathrm{def}}{=}\\displaystyle\\sum_{v\\in S^{*}}\\operatorname*{min}\\{\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(C_{v}),\\ell+1\\}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then, if the game ends at iteration $T$ , we must have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\phi^{(T)}\\geq(\\ell+1)(|S^{*}|-1)=(\\ell+1)(n-k+1).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "On the other hand, we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\phi^{(0)}=0.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We show that this potential $\\phi^{(t)}$ changes by a small amount on any given iteration of the RUCCFP game: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\phi^{(t)}<(n-k+1)(\\ell+1),\\,t h e n\\;\\phi^{(t+1)}\\leq\\phi^{(t)}+2.\\nonumber\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "An immediate consequence of Claim 26 and Equations (7) and (8) is that the number of iterations required for the game to terminate is at least $T\\stackrel{\\cdot}{\\geq}(n-k+1)(\\ell+1)/2$ , yielding the statement of Theorem 25. \u53e3 ", "page_idx": 25}, {"type": "text", "text": "We conclude by proving Claim 26. ", "page_idx": 25}, {"type": "text", "text": "Proof of Claim 26. Let uv be the query submitted by the questioner on iteration $t+1$ . We will split the proof of the theorem into cases. ", "page_idx": 25}, {"type": "text", "text": "Case 1 Suppose $\\{u,v\\}\\subseteq S^{*}$ . Then, if the responder answers in a way that\u2019s consistent with $\\mathcal{C}^{*}$ , their answer will also be consistent with $\\mathcal{C}_{w}$ for every $w\\,\\in\\,S^{*}$ . By consequence of the assumption that $\\phi^{(t)}<(n-k+1)(\\ell+1)$ , a simple counting argument implies that there exists an element $w_{t}\\in S^{*}$ such that: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}_{w_{t}})\\le\\ell.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Since $w_{t}$ as defined above satisfies $\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}_{w_{t}})\\le\\ell$ , this implies that the responder can answer in a way consistent with $\\mathcal{C}^{*}$ without violating the rules of the game. By the definition of the strategy, the responder then will answer in a way consistent with $\\mathcal{C}^{*}$ (and with all partitions ${\\mathcal{C}}_{w}$ ) and hence, for all $w\\,\\in\\,S^{*}$ : ${\\mathrm{cost}}_{G_{t+1}}^{\\mathtt{F P}}({\\mathcal{C}}_{w})={\\mathrm{cost}}_{G_{t}}^{\\mathtt{F P}}({\\mathcal{C}}_{w})$ , giving $\\phi^{(t+1)}=$ $\\phi^{(t)}$ . ", "page_idx": 25}, {"type": "text", "text": "Case 2.a Suppose that $\\{u,v\\}\\subseteq S^{*}$ , and that the responder replies in a way that\u2019s consistent with $\\mathcal{C}^{*}$ . In this scenario, for any $w\\in S^{*}\\setminus\\{u,v\\}$ we have $\\mathrm{\\mathop{cost}}_{G_{t+1}}^{\\mathtt{F P}}(\\mathcal{C}_{w})=\\mathrm{\\mathop{cost}}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}_{w})$ , while ${\\mathrm{cost}}_{G_{t+1}}^{\\mathtt{F P}}({\\mathcal{C}}_{u})\\leq{\\mathrm{cost}}_{G_{t}}^{\\mathtt{F P}}({\\mathcal{C}}_{u})+1$ and ${\\mathrm{cost}}_{G_{t+1}}^{\\mathtt{F P}}(\\mathcal{C}_{v})\\leq{\\mathrm{cost}}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}_{v})+1.$ . This immediately implies $\\phi^{(t+1)}\\leq\\phi^{(t)}+2$ . ", "page_idx": 25}, {"type": "text", "text": "Case 2.b Suppose that $\\{u,v\\}\\subseteq S^{*}$ , and that the responder replies in a way that is not consistent with $\\mathcal{C}^{*}$ , i.e. the responder replies to the query ${u v}$ with $-1$ . Then by the definition of the rreulsepso onfd tehr es tgraatmeeg, yi,. ei.t  itm uwsot ublde  tchaeu scea esve etrhya $k$ -apnasrtwiteiroinn $\\mathcal{C}$ $+1$ $V$ t toh he aqvue $\\dot{\\mathrm{cost}}_{G_{t+1}}^{\\mathtt{F P}}({\\mathcal{C}})\\geq\\ell+1$ But, for every $w\\in S^{*}\\setminus\\{u,v\\}$ , the cost of the partition $\\mathcal{C}_{w}$ does not increase if the response to the query $\\{u,v\\}$ is $+1$ . Hence, it must be the case that $\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}_{w})\\geq\\ell+1$ for all such $w$ . Hence, for any $w\\in S^{*}\\setminus\\{u,v\\}$ : ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "equation", "text": "$$\n\\operatorname*{min}\\{\\ell+1,\\smash{\\cos^{\\mathrm{tp}}}_{G_{t+1}}(\\mathcal{C}_{w})\\}=\\ell+1=\\operatorname*{min}\\{\\ell+1,\\smash{\\cos^{\\mathrm{tp}}}_{G_{t}}(\\mathcal{C}_{w})\\}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "On the other hand, since the responder is replying to the query ${u v}$ with $-1$ , their answer is simultaneously consistent with both $\\mathcal{C}_{u}$ and $\\mathcal{C}_{v}$ . We then have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathrm{cost}_{G_{t+1}}^{\\mathtt{F P}}(\\mathcal{C}_{u})=\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}_{u})\\;\\mathrm{and}\\;\\,\\mathrm{cost}_{G_{t+1}}^{\\mathtt{F P}}(\\mathcal{C}_{v})=\\mathrm{cost}_{G_{t}}^{\\mathtt{F P}}(\\mathcal{C}_{v}).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "In particular, Equations (9) and (10) directly imply $\\phi^{(t+1)}=\\phi^{(t)}$ . ", "page_idx": 26}, {"type": "text", "text": "This concludes the proof of Claim 26 (and in turn the proof of Theorem 25). ", "page_idx": 26}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The authors ensured that the content of the abstract accurately reflects that of the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 27}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: A brief discussion of limitations of the results appears in Section 7 ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 27}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We include thorough proofs of all our theoretical results in the supplementary material. Additionally, the full set of assumptions required for the theorems to hold are clearly stated both in the introduction and in Section 4 where the results are formally stated. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 28}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper does not contain experiments. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 28}, {"type": "text", "text": "5. Open access to data and code ", "page_idx": 28}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not contain any experiments. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 29}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 29}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 30}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: The authors have carefully reviewed the ethics guidelines, and ensured that the papers complies with them fully. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 30}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The work carried out in this paper is of entirely foundational nature and has no direct path to any negative applications. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 31}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: The paper does not use existing assets. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 31}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 32}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 32}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 32}, {"type": "text", "text": "Answer:[NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: While crowdsourcing of information is a motivating application for the theory developed in this paper, this work does not include any crowdsourcing experiments nor any research with human subjects. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 32}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 32}, {"type": "text", "text": "Answer:[NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: While crowdsourcing of information is a motivating application for the theory developed in this paper, this work does not include any crowdsourcing experiments nor any research with human subjects. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. ", "page_idx": 32}, {"type": "text", "text": "\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 33}]