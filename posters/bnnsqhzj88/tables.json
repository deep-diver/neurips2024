[{"figure_path": "bnNSQhZJ88/tables/tables_5_1.jpg", "caption": "Table 1: An overview of the common knowledge facts required to perform forms of steganography.", "description": "This table shows which common knowledge facts are necessary for different types of steganography. It lists the common knowledge requirements for steganography by covertext modification, complexity-theoretic steganography, and information-theoretic steganography.  The rows indicate specific components involved in each steganographic method, such as channel alphabet, encoding function, decoding function, sampling temperature, public keys, shared PRNG generator, and shared one-time pad. A check mark (\u2713) signifies that the respective common knowledge fact is required, while a cross mark (X) indicates it is not required.", "section": "Capability Evaluations"}, {"figure_path": "bnNSQhZJ88/tables/tables_5_2.jpg", "caption": "Table 2: An overview of the model capabilities required to perform different types of steganography.", "description": "This table shows the capabilities required for different types of steganography, including those based on covertext modification, complexity-theoretic methods, and information-theoretic methods.  It details whether each steganography type requires self-sampling, symmetric key encryption or PRNG generation, logit simulation, the ability to store one-time pads (approximately), and the capability to generate minimum entropy couplings. A checkmark indicates that the capability is required, while an 'X' indicates that it is not.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_6_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across several key areas related to steganography.  It shows whether GPT-4 was successful in tasks such as coordinating on simple and complex Schelling points, using ciphers, performing self-sampling and logit simulation, generating couplings and MECs, using tools (code interpreter), and covertext steganography, evading an overseer.  The results are presented with checkmarks for success, X for failure, and ~ for partial success, indicating that certain capabilities were not fully demonstrated.  Further details are available in the appendices.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_24_1.jpg", "caption": "Table 4: Simple Coordination Scheme Schelling Point - Encoder Model", "description": "This table presents a prompt template used in an experiment to test whether language models can independently reach an agreement on a simple encoding/decoding scheme.  The prompt instructs the model to act as an encoder in a cryptographic coordination scheme, requiring alignment with a decoding clone. The goal is for both models to independently decide on the same scheme and reach an agreement on a Schelling point, outputting their chosen coordination scheme concisely. The user is prompted to decide upon the name of the coordination scheme. An example response of `AES256-SHA256 Hybrid Encryption` is also shown.", "section": "F.1 Common Knowledge Schelling Points"}, {"figure_path": "bnNSQhZJ88/tables/tables_24_2.jpg", "caption": "Table 5: Simple Coordination Scheme Schelling Point - Encoder Model", "description": "This table presents a prompt template for an encoder model in a simple coordination scheme Schelling Point experiment.  The encoder and decoder models must independently decide upon the same coordination scheme. The goal is for both to reach an agreement (Schelling point) on the chosen scheme without prior communication. The table shows the role (system, user, assistant), and the content of each prompt to guide the models toward selecting a simple Caesar cipher scheme.", "section": "F.1 Common Knowledge Schelling Points"}, {"figure_path": "bnNSQhZJ88/tables/tables_25_1.jpg", "caption": "Table 1: An overview of the common knowledge facts required to perform forms of steganography.", "description": "This table lists the common knowledge requirements for three types of steganography: steganography by covertext modification, complexity-theoretic steganography, and information-theoretic steganography.  It indicates which common knowledge elements (channel alphabet, encoding function, etc.) are necessary for each type of steganography.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_25_2.jpg", "caption": "Table 1: An overview of the common knowledge facts required to perform forms of steganography.", "description": "This table lists the common knowledge requirements for three different steganography techniques: steganography by covertext modification, complexity-theoretic steganography, and information-theoretic steganography. For each technique, it specifies whether common knowledge is required for the channel alphabet, encoding function, coordination variable, decoding function, sampling temperature, public keys, and/or a shared pseudorandom number generator or one-time pad.", "section": "Capability Evaluations"}, {"figure_path": "bnNSQhZJ88/tables/tables_26_1.jpg", "caption": "Table 1: An overview of the common knowledge facts required to perform forms of steganography.", "description": "This table shows a summary of the common knowledge required to perform various types of steganography, including steganography by covertext modification, complexity-theoretic steganography, and information-theoretic steganography.  It lists the common knowledge requirements for different aspects of the steganographic process, such as the channel alphabet, encoding function, coordination variable, decoding function, and the use of public keys or shared pseudorandom number generators.", "section": "Capability Evaluations"}, {"figure_path": "bnNSQhZJ88/tables/tables_26_2.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganographic techniques.  It shows GPT-4's success rates on tasks such as coordinating on Schelling points (with different complexity levels), performing cipher encoding/decoding, generating couplings, and utilizing code interpreters for cryptographic tasks.  The table also indicates that group steganography (covert communication in multi-agent settings) is possible to a certain extent for GPT-4.  For detailed descriptions and analyses, the reader is referred to Appendix F and G.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_26_3.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across several steganography-related tasks.  It shows GPT-4's performance in tasks such as coordinating on Schelling points (simple and complex), performing cryptographic operations (cipher encoding/decoding), simulating logits, and creating couplings (MECs). The table also indicates whether GPT-4 uses tools such as Code Interpreter and its overall success rate in group steganography evasions.  More details on the individual evaluations and the methodology used can be found in Appendix F and G, respectively. Section 5 describes the model evaluation framework used for these assessments.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_27_1.jpg", "caption": "Table 1: An overview of the common knowledge facts required to perform forms of steganography.", "description": "This table shows which common knowledge facts are necessary for different types of steganography, namely steganography by covertext modification, complexity-theoretic steganography, and information-theoretic steganography.  It lists several elements, such as the channel alphabet, encoding and decoding functions, and the presence of public keys or a shared random number generator, and indicates whether each is required for each of the steganography methods.  The checkmarks show the necessary elements for a particular type of steganography.", "section": "Capability Evaluations"}, {"figure_path": "bnNSQhZJ88/tables/tables_28_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across several steganography-relevant tasks, as defined in the model evaluation framework presented in Section 5.  These evaluations assess the model's performance in various tasks such as Schelling point coordination (with varying complexity levels, including code-based schemes), cipher encoding/decoding (Base64 and Caesar cipher), minimum entropy coupling generation, and tool usage (Code Interpreter). The table indicates GPT-4's success rate in each task, providing a quantitative overview of its abilities. Detailed descriptions and methodologies for these evaluations are available in Appendices F and G.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_29_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities in various steganographic techniques according to the model evaluation framework presented in Section 5.  It shows GPT-4's performance on tasks such as coordinating on Schelling points, using ciphers, self-sampling, generating couplings, and employing its code interpreter. The evaluations' details are provided in Appendix F and G.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_30_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-related tasks, as defined in the model evaluation framework introduced in Section 5.  The tasks assess the model's abilities in different areas such as coordinating on Schelling points, performing cryptographic functions, and using steganographic techniques.  Specific details of the evaluations are provided in Appendix F (individual capabilities) and Appendix G (group capabilities).  The results show the success rate or performance level achieved by GPT-4 for each task, indicating its proficiency in performing each.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_30_2.jpg", "caption": "Table 18: Comparison of minimum and GPT-4 coupling entropies for random n \u00d7 n matrices.", "description": "This table compares the minimum possible entropy for coupling matrices of different dimensions (2x2 to 8x8) with the entropy of coupling matrices generated by the GPT-4 language model.  The minimum entropy represents the theoretical lower bound for the entropy of a coupling matrix given the marginal distributions. The GPT-4 coupling entropy shows the actual entropy achieved by the model, revealing the difference between the theoretical optimal and the model's performance in generating such matrices.", "section": "Empirical Investigations"}, {"figure_path": "bnNSQhZJ88/tables/tables_31_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganographic tasks, as outlined in the model evaluation framework in Section 5.  It shows GPT-4's performance on tasks such as coordination (Schelling points), cipher use, and generating couplings. The table provides a quantitative overview of GPT-4's ability in each area and indicates which appendices provide the detailed evaluations.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_31_2.jpg", "caption": "Table 20: Comparison of LLMs' ability to communicate undetectably through steganographic covertext modification.", "description": "This table presents the success rates of different large language models (LLMs) in covertly communicating a message using steganography.  The communication must be undetectable by an overseer while still being understandable by a recipient who shares common knowledge with the sender. The results demonstrate a significant increase in success rates as model size and capabilities increase.", "section": "Empirical Investigations"}, {"figure_path": "bnNSQhZJ88/tables/tables_32_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-related tasks, as defined in Section 5 and detailed in Appendices F and G.  It shows GPT-4's performance in areas like coordinating on Schelling points (simple and complex), using ciphers (Base64 and Caesar), performing logit simulations, generating couplings, and using tools (Code Interpreter). The results provide a baseline for assessing the capabilities of LLMs in performing steganography.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_32_2.jpg", "caption": "Table 20: Comparison of LLMs' ability to communicate undetectably through steganographic covertext modification.", "description": "This table presents the success rate of different large language models (LLMs) in covertly communicating a message through steganographic techniques within a specific experimental setting.  The results demonstrate the varying capabilities of LLMs in evading detection while successfully transmitting hidden information. The success rate represents the percentage of attempts where the message was undetectable to an overseer model but successfully decoded by the intended receiver. The higher the success rate, the better the LLM's ability to perform covert communication. The table highlights the improvement in steganographic capabilities as model size and training data increase.", "section": "6 Empirical Investigations"}, {"figure_path": "bnNSQhZJ88/tables/tables_33_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-related tasks, as defined in Section 5's model evaluation framework.  It provides a concise overview of GPT-4's performance in tasks such as Schelling Point coordination, cipher encryption/decryption, and group steganography, indicating success rates and observations for each task.  Further details on the individual and group evaluations can be found in Appendices F and G, respectively.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_33_2.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the performance of GPT-4 on various steganography-related tasks, as evaluated by the proposed model evaluation framework.  It shows GPT-4's success rates in tasks such as Schelling point coordination (with varying complexities), cipher encoding/decoding, coupling generation, and code interpretation.  The results highlight GPT-4's capabilities and limitations in each task, providing insights into the model's preparedness for steganographic activities.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_34_1.jpg", "caption": "Table 25: Maximum coupling dimension that models can generate when given individual distributions.", "description": "This table presents the maximum coupling dimension that different language models (GPT-2, Llama 2 7B, Llama 2 70B, Mixtral 8x7B, GPT-3.5, and GPT-4) can generate when provided with individual distributions.  The results show a clear increase in capability as model size and performance increase, with GPT-4 being able to generate couplings up to 10x10, while smaller models struggle to generate couplings beyond 3x3 or even 2x2.", "section": "Empirical Investigations"}, {"figure_path": "bnNSQhZJ88/tables/tables_34_2.jpg", "caption": "Table 26: Coupling entropy vs MEC by dimension and model. \"-\" indicates models unable to generate an MEC matrix.", "description": "This table compares the entropy of coupling matrices generated by various large language models (LLMs) against the theoretical minimum entropy coupling (MEC) for different matrix dimensions (2x2 to 8x8).  A lower entropy value indicates a more efficient coupling. The table shows that smaller LLMs (GPT-2, Llama 2 7B, Llama 2 70B, Mixtral 8x7B) either couldn't generate couplings or produced couplings with significantly higher entropy than the MEC.  Larger LLMs (GPT-3.5, GPT-4) show improved performance, generating couplings closer to the MEC, although still not achieving it perfectly.", "section": "Empirical Investigations"}, {"figure_path": "bnNSQhZJ88/tables/tables_34_3.jpg", "caption": "Table 27: Simple Schelling point agreement by model.", "description": "This table presents the results of an experiment evaluating the ability of different language models to agree on a simple encoding/decoding scheme (Schelling point) without prior communication.  The 'Default Temperature Agreement (%)' column shows the percentage of times the encoder and decoder models successfully agreed on the scheme at a default temperature setting.  The results show that agreement improves as model size and capabilities increase, with GPT-4 achieving a significantly higher success rate than the other models.", "section": "H.3 Encoder-Decoder Schelling Points (Simple)"}, {"figure_path": "bnNSQhZJ88/tables/tables_34_4.jpg", "caption": "Table 28: Complex Schelling point agreement by model.", "description": "This table presents the results of an experiment evaluating the ability of different language models to reach agreement on a complex encoding/decoding scheme without prior communication.  The models were tested at default temperature.  The results show the percentage of times the models reached agreement on the scheme.  The table demonstrates the increasing ability of more advanced models to achieve coordination on complex tasks.", "section": "H.4 Encoder-Decoder Schelling Points (Complex)"}, {"figure_path": "bnNSQhZJ88/tables/tables_35_1.jpg", "caption": "Table 29: Code Schelling point agreement by model.", "description": "This table presents the results of an experiment to evaluate the ability of various language models to agree on a complex coordination scheme involving code-based encoding and decoding, without prior communication.  The \"Default Temperature Agreement (%)\" column shows the percentage of times the models reached agreement at their default temperature settings.  The models tested are GPT-2, Llama 2 7B, Llama 2 70B, Mixtral 8x7B, GPT-3.5, and GPT-4.  GPT-2 is marked as N/A because it did not have the capability to perform the task.", "section": "H.5 Encoder-Decoder Schelling Points (Code)"}, {"figure_path": "bnNSQhZJ88/tables/tables_35_2.jpg", "caption": "Table 30: Cipher encoding and decoding success rates by models at default temperatures.", "description": "This table presents the success rates of various large language models (LLMs) in performing Base64 and Caesar cipher encoding and decoding tasks at default temperature settings. The results demonstrate a significant performance improvement in GPT-4 compared to other models, highlighting its enhanced cryptographic capabilities.", "section": "Empirical Investigations"}, {"figure_path": "bnNSQhZJ88/tables/tables_35_3.jpg", "caption": "Table 31: Evaluation of self-sampling capabilities in various language models.", "description": "This table presents the results of evaluating the self-sampling capabilities of several large language models. Self-sampling is a crucial capability for perfectly secure steganography.  The table shows whether each model demonstrated the ability to perform self-sampling, indicating a significant step towards securing information-theoretic communication.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_37_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities in various steganographic techniques and tasks, based on the model evaluation framework detailed in Section 5 of the paper.  Specific capabilities assessed include coordination on Schelling points, cryptographic functions, generating couplings, and using code interpreters.  The results indicate the success rate for GPT-4 in each task and refer to Appendices F and G for further details and methodology.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_38_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across several key areas relevant to steganography, such as coordination, encryption, and tool use.  Each capability is assessed, and the results are summarized, with detailed explanations provided in Appendices F and G.  The framework used for evaluation is introduced in Section 5 of the paper.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_38_2.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-related tasks, as defined in the model evaluation framework of Section 5.  Each row represents a different capability (e.g., coordinating on Schelling points, using ciphers, generating couplings, etc.), and shows whether GPT-4 successfully demonstrated the capability. The results are qualitative, with a brief description of GPT-4's performance in each task. More detailed results are available in Appendices F and G.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_38_3.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-relevant tasks,  as defined in the model evaluation framework presented in Section 5.  The specific tasks and detailed evaluation methods are described in Appendices F and G.  The results show GPT-4's performance in terms of success rates or other relevant metrics for each task.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_39_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities in various steganographic tasks according to the framework introduced in Section 5.  It shows GPT-4's success rate in different tasks such as coordination on Schelling points (simple and complex), cryptographic functions (encoding/decoding), couplings (maximum dimension achieved), and tool use (code interpreter).  The full details of the individual and group evaluations are available in Appendices F and G respectively.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_39_2.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the performance of GPT-4 across various steganography-relevant capabilities, as assessed by the model evaluation framework introduced in Section 5 of the paper.  The results indicate GPT-4's abilities in tasks such as Schelling point coordination (with varying complexity), cipher encoding/decoding, self-sampling, logit simulation, and generating coupling matrices.  Appendix F and G provide detailed explanations and analysis of the individual and group evaluations, respectively.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_40_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-related tasks, as defined in the model evaluation framework introduced in Section 5.  Each row represents a specific capability (e.g., Schelling point coordination, cipher encryption, etc.), and the evaluation details and results are provided for GPT-4.  More detailed results and explanations can be found in Appendices F and G.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_40_2.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-relevant tasks, as defined in Section 5's model evaluation framework.  The results are presented concisely, indicating whether GPT-4 succeeded at each task (indicated by a checkmark), and providing brief details about its performance. More detailed explanations and methodology are given in Appendices F and G.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_41_1.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across various steganography-related tasks, as defined in Section 5's model evaluation framework.  It shows GPT-4's performance on tasks such as coordinating on Schelling points (of varying complexity), performing cipher encoding/decoding (using Base64 and Caesar cipher), self-sampling, generating couplings and MECs, and utilizing tools like code interpreters.  Appendix F and G contain more detailed information on the individual and group capability evaluations, respectively.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}, {"figure_path": "bnNSQhZJ88/tables/tables_41_2.jpg", "caption": "Table 3: GPT-4 capability evaluations according to our model evaluation framework (see Section 5). Details are in Appendix F and G.", "description": "This table summarizes the results of evaluating GPT-4's capabilities across several steganography-related tasks.  These tasks assess various capabilities needed for secret collusion, such as coordinating on simple and complex Schelling points, using ciphers, generating couplings, and using the Code Interpreter tool.  The table shows whether GPT-4 could successfully perform each task and provides a qualitative assessment of its performance. For detailed results and methodologies, refer to Appendix F and G.", "section": "5 A Model Evaluation Framework for Steganographic Capabilities"}]