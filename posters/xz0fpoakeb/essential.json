{"importance": "This paper challenges the fundamental assumption of train-test model validation in AI, particularly in complex social systems where data is passively collected.  It shows that **existing validation methods are likely invalid** and proposes alternative approaches like participatory data curation and open science for more reliable model evaluation. This is crucial for advancing AI research and ensuring positive social impact.", "summary": "Passive data collection in complex social systems invalidates standard AI model validation;  new methods are needed.", "takeaways": ["Standard train-test validation is often invalid for AI models trained on passively collected data from complex social systems.", "The paper formally proves the invalidity of commonly used validation methods under realistic data collection processes.", "The research proposes remedies like participatory data curation and open science to improve the reliability and validity of model evaluation."], "tldr": "Modern AI heavily relies on train-test model validation to assess performance. However, this paradigm often fails when applied to AI systems interacting with complex social systems where data is collected passively. Passive data collection means the data used for training and testing is generated by an inherent social process, such as popularity bias or network effects, which are themselves not independent and identically distributed (i.i.d.).  This violates the assumptions ensuring test validity, leading to unreliable conclusions about the model's true performance. The current model evaluation practices lack a justification and are invalid in these systems, raising major concerns for the responsible development and deployment of AI.\nThis paper formally demonstrates the invalidity of such validation techniques. Using formal results from complex systems and learning theory, it shows that, for a large number of practical applications, the train-test paradigm cannot guarantee valid model validation. The paper illustrates this problem with the widely used MovieLens benchmark for recommender systems and proposes a solution to address this fundamental issue: the need for participatory data curation and open science. It argues that current model validation methods are inadequate, and advocates for new approaches to create more reliable and socially beneficial AI systems.", "affiliation": "Meta AI", "categories": {"main_category": "AI Theory", "sub_category": "Generalization"}, "podcast_path": "XZ0fpoAKEB/podcast.wav"}