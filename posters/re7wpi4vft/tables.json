[{"figure_path": "RE7wPI4vfT/tables/tables_6_1.jpg", "caption": "Table 2: Evaluating FID score (lower is better) of parallel DDPM sampler on real-world datasets using 5,000 samples. For reported FID scores, we run three sets of random seeds and reported the average with uncertainty.", "description": "This table shows the FID scores (Frechet Inception Distance) for different models trained on various real-world image datasets, using the parallel DDPM sampler.  Lower FID scores indicate better image generation quality.  The results are averaged over three runs with different random seeds to account for variability.", "section": "5.1 Parallel Sampling"}, {"figure_path": "RE7wPI4vfT/tables/tables_7_1.jpg", "caption": "Table 3: Evaluating sequential deterministic EDM samplers generation quality. For reported FID scores, we run three sets of random seeds and reported the average with uncertainty.", "description": "This table presents the FID scores (Frechet Inception Distance, a metric for evaluating the quality of generated images) for sequential deterministic EDM (Energy-based Diffusion Model) samplers.  The results are broken down by dataset (CIFAR-10, AFHQv2, FFHQ) and conditioning type (unconditional, conditional).  Two models are compared: VP and VE, representing two variations of the EDM architecture, and their CDL-regularized counterparts (CDL-VP, CDL-VE). Lower FID scores indicate better image generation quality. The number of function evaluations (NFEs) required for sampling is also included.  The reported FID scores are averages across three runs with different random seeds, along with uncertainty.", "section": "5.2 Sequential Sampling"}, {"figure_path": "RE7wPI4vfT/tables/tables_15_1.jpg", "caption": "Table 4: Evaluating FID score for both parallel and sequential DDPM samplers. FID scores are calculated using 5,000 samples.", "description": "This table presents FID (Frechet Inception Distance) scores, a metric for evaluating the quality of generated images, for both parallel and sequential DDPM (Denoising Diffusion Probabilistic Models) samplers.  Two models are compared: one trained with the standard DDPM loss and another trained with the proposed Contrastive Diffusion Loss (CDL).  Lower FID scores indicate better image quality.  The table shows that CDL improves the quality of generated images for both parallel and sequential samplers.", "section": "5.1 Parallel Sampling"}, {"figure_path": "RE7wPI4vfT/tables/tables_16_1.jpg", "caption": "Table 5: Fine-tuning configurations for different datasets", "description": "This table lists the hyperparameters used for fine-tuning different pre-trained models on various datasets.  The hyperparameters shown include the training duration, batch size, learning rate, channel resampling parameters (cres), dropout rate, and data augmentation parameters (augment).  Different datasets (CIFAR-10, AFHQ-64, and FFHQ-64) required different hyperparameter settings for optimal performance.", "section": "5.1 Parallel Sampling"}, {"figure_path": "RE7wPI4vfT/tables/tables_16_2.jpg", "caption": "Table 6: Evaluating FID score (lower is better) of parallel DDPM sampler on real-world datasets using 5, 000 samples. \"NA\" stands for \"Not Applicable\". For reported FID scores, we run three sets of random seeds and reported the average with uncertainty.", "description": "This table presents the Frechet Inception Distance (FID) scores for various models trained on three real-world datasets: CIFAR-10, AFHQv2, and FFHQ.  Lower FID scores indicate better image quality.  The table compares the performance of standard models (DDPM, VP, VE) against models trained with the Contrastive Diffusion Loss (CDL-DDPM, CDL-VP, CDL-VE).  The results show that CDL-trained models generally achieve lower FID scores, suggesting improved image quality.  The \"NA\" values indicate that the corresponding metrics were not applicable for those models and datasets.", "section": "5.1 Parallel Sampling"}, {"figure_path": "RE7wPI4vfT/tables/tables_17_1.jpg", "caption": "Table 2: Evaluating FID score (lower is better) of parallel DDPM sampler on real-world datasets using 5, 0000 samples. For reported FID scores, we run three sets of random seeds and reported the average with uncertainty.", "description": "This table shows the FID scores achieved by different models on various real-world image datasets, using the parallel DDPM sampler.  Lower FID scores indicate better sample quality. The results compare the standard DDPM and CDL-regularized models for both unconditional and conditional generation on CIFAR-10, AFHQv2, and FFHQ datasets. The average FID scores across three random seeds are reported, along with uncertainty estimates.", "section": "5.1 Parallel Sampling"}, {"figure_path": "RE7wPI4vfT/tables/tables_17_2.jpg", "caption": "Table 2: Evaluating FID score (lower is better) of parallel DDPM sampler on real-world datasets using 5, 0000 samples. For reported FID scores, we run three sets of random seeds and reported the average with uncertainty.", "description": "This table presents the Fr\u00e9chet Inception Distance (FID) scores for various models trained on different datasets (CIFAR-10, AFHQv2, and FFHQ) using a parallel DDPM sampler.  Lower FID scores indicate better sample quality. The results show that models trained using Contrastive Diffusion Loss (CDL) consistently achieve lower FID scores than their baselines, demonstrating improved generation quality. Three random seeds were used for each model, and the average FID with uncertainty is reported.", "section": "5.1 Parallel Sampling"}]