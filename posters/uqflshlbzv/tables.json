[{"figure_path": "UQflshLbZv/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparison for irrelevant attributes preservation. IDS [13] denotes identity similarity, PSNR, and SSIM are calculated at the intersected non-hair regions before and after editing.", "description": "This table presents a quantitative comparison of different hair editing methods in terms of their ability to preserve irrelevant facial attributes.  It uses three metrics: Identity Similarity (IDS), Peak Signal-to-Noise Ratio (PSNR), and Structural Similarity Index (SSIM).  Higher scores indicate better preservation of identity and image quality in the non-hair regions of the face after hair editing. The comparison helps to demonstrate the effectiveness of the proposed method (Ours) in maintaining facial features while altering the hair.", "section": "4.1 Quantitative and Qualitative Comparison"}, {"figure_path": "UQflshLbZv/tables/tables_7_2.jpg", "caption": "Table 2: User study on text-driven image manipulation, color transfer, and cross-modal hair editing methods. Accuracy denotes the manipulation accuracy for given conditional inputs, Preservation indicates the ability to preserve irrelevant regions and Naturalness denotes the visual realism of the manipulated image. The numbers represent the percentage of votes. Bold and underline denote the best and the second best result, respectively.", "description": "This table presents the results of a user study comparing different hair editing methods across three categories: text-driven editing, color transfer, and cross-modal editing.  The metrics evaluated are Accuracy (how well the method achieved the desired edit), Preservation (how well the method preserved irrelevant facial features), and Naturalness (how realistic the resulting image appears).  Each cell shows the percentage of user votes for each method in each category, with bold and underlined entries indicating the top two performers.", "section": "4.1 Quantitative and Qualitative Comparison"}, {"figure_path": "UQflshLbZv/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative comparison of different variants of warping module with various conditions removed. We achieve the best performance by leveraging the remaining techniques.", "description": "This table presents a quantitative analysis of the ablation study conducted on the warping module within the HairDiffusion model. By systematically removing components (warping module, patch match, and bilateral filtering), the impact on model performance is evaluated using FID, FIDclip, and SSIM metrics.  The results demonstrate that the combination of all three components achieves the best performance. The table helps readers understand the contribution of each component to the overall performance of HairDiffusion.", "section": "4.2 Ablation Study"}, {"figure_path": "UQflshLbZv/tables/tables_18_1.jpg", "caption": "Table 4: Quantitative comparison of single color transfer and self-transfer reconstruction metrics. Bold and underline denote the best and the second best result, respectively.", "description": "This table presents a quantitative comparison of different methods for single color transfer and self-transfer reconstruction tasks.  The metrics used are FID (Frechet Inception Distance), FID_CLIP (FID calculated using CLIP features), LPIPS (Learned Perceptual Image Patch Similarity), PSNR (Peak Signal-to-Noise Ratio), and for reconstruction tasks FID and FID_CLIP.  Lower FID and FID_CLIP scores indicate better image quality, while lower LPIPS indicates better perceptual similarity. Higher PSNR indicates better fidelity to the original image. The best performing method in each category is highlighted in bold and underlined.", "section": "4.1 Quantitative and Qualitative Comparison"}]