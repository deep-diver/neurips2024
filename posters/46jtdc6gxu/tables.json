[{"figure_path": "46jtDC6gXu/tables/tables_6_1.jpg", "caption": "Table 1: Quantitative evaluations of AsyncDiff on three text-to-image diffusion models, showcasing various configurations. 'N' indicates the number of components into which the model is divided, and 'S' represents the denoising stride. MACs quantifies the computational load per device for generating a single image throughout the denoising process.", "description": "This table presents a quantitative analysis of AsyncDiff's performance on three different text-to-image diffusion models (SD 2.1, SD 1.5, and SDXL). It shows how different configurations of the method, specified by the number of components (N) and the denoising stride (S), affect several key metrics: MACs (Multiply-Accumulate operations), latency, speedup, CLIP score, FID (Fr\u00e9chet Inception Distance), and LPIPS (Learned Perceptual Image Patch Similarity).  The results demonstrate the trade-off between speedup and the slight degradation in image quality (as measured by CLIP, FID, and LPIPS).", "section": "4.2 Experimental Results on Image Diffusion Models"}, {"figure_path": "46jtDC6gXu/tables/tables_6_2.jpg", "caption": "Table 2: Quantitative evaluations of the effect of increasing warm-up steps. More warm-up steps can achieve pixel-level consistency with the original output while slightly reducing processing speed.", "description": "This table presents a quantitative analysis of how increasing the number of warm-up steps in the AsyncDiff model affects its speed and the pixel-level consistency of its generated images compared to the original sequential model.  It shows that increasing warm-up steps improves pixel-level consistency (as measured by LPIPS) but slightly reduces the speedup achieved.", "section": "4.2 Experimental Results on Image Diffusion Models"}, {"figure_path": "46jtDC6gXu/tables/tables_7_1.jpg", "caption": "Table 3: Quantitative comparison with other parallel acceleration methods. To ensure a fair comparison with Distrifusion, we increased the warm-up steps in our method to match the speedup ratio of Distrifusion, allowing us to fairly compare generation quality and resource costs.", "description": "This table compares AsyncDiff with two other parallel acceleration methods, Faster Diffusion and Distrifusion, across three different speedup ratios (1.6x, 2.3x, and 2.7x).  It shows the number of devices used, the MACs (multiply-accumulate operations), memory consumption, CLIP Score, FID (Fr\u00e9chet Inception Distance), and LPIPS (Learned Perceptual Image Patch Similarity) scores for each method at each speedup ratio. The comparison highlights AsyncDiff's superior performance and resource efficiency.", "section": "4.2 Experimental Results on Image Diffusion Models"}, {"figure_path": "46jtDC6gXu/tables/tables_8_1.jpg", "caption": "Table 4: Quantitative evaluations of AsyncDiff on text-to-video and image-to-video diffusion models. We present the results with various configurations.", "description": "This table presents the quantitative results of applying AsyncDiff to two video diffusion models: AnimateDiff (text-to-video) and Stable Video Diffusion (image-to-video).  It shows the original model's performance, and then compares it to AsyncDiff's performance with different configurations (number of devices and stride). The metrics reported are MACs (Multiply-Accumulate operations), latency (inference time), speedup (relative to the original model), and CLIP score (a measure of image quality).  The results demonstrate AsyncDiff's ability to significantly reduce inference time while maintaining reasonable image quality.", "section": "4.3 Experimental Results on Video Diffusion Models"}, {"figure_path": "46jtDC6gXu/tables/tables_8_2.jpg", "caption": "Table 5: Effect of stride denoising on SD 2.1. Stride denoising significantly lowers overall latency and the communication cost while only slightly compromising the generative quality", "description": "This table presents a quantitative evaluation of the impact of stride denoising on the Stable Diffusion 2.1 model. It compares the performance of AsyncDiff with and without stride denoising, showing metrics such as MACs (Million Arithmetic Calculations), latency, speedup, communication number, communication latency, and CLIP score.  The results demonstrate that stride denoising substantially reduces both latency and communication overhead with minimal impact on generative quality.", "section": "4.4 Effect of Stride Denoising"}, {"figure_path": "46jtDC6gXu/tables/tables_9_1.jpg", "caption": "Table 6: Quantitative evaluations of AsyncDiff using DPM-Solver sampler on SD 2.1", "description": "This table presents a quantitative comparison of the performance of AsyncDiff and the DPM-Solver method on the Stable Diffusion 2.1 model using the DPM-Solver sampler.  It shows the speedup achieved, the number of Multiply-Accumulate operations (MACs), the CLIP score, and the Fr\u00e9chet Inception Distance (FID). The comparison is made for different numbers of steps used in the denoising process, showcasing the effect of AsyncDiff on different speedup levels.", "section": "4.2 Experimental Results on Image Diffusion Models"}, {"figure_path": "46jtDC6gXu/tables/tables_9_2.jpg", "caption": "Table 7: Quantitative evaluations of AsyncDiff using DDIM sampler on SD 2.1", "description": "This table presents a quantitative comparison of the performance of AsyncDiff using the DDIM sampler with different speedup ratios on the Stable Diffusion 2.1 model.  It shows the speedup achieved, the resulting MACs (Million Multiply-Accumulates), CLIP Score, and FID (Fr\u00e9chet Inception Distance) for different numbers of denoising steps (and configurations of AsyncDiff).  The comparison is made against the standard DDIM method with the same number of steps, to highlight the tradeoffs between speed and image quality.", "section": "4.5 Compatibility with Various Samplers"}, {"figure_path": "46jtDC6gXu/tables/tables_9_3.jpg", "caption": "Table 8: Acceleration Ratio and Latency on Different GPUs", "description": "This table compares the acceleration ratios and inference latency achieved by AsyncDiff on three different GPUs: NVIDIA RTX A5000, NVIDIA RTX 3090, and NVIDIA RTX 2080Ti.  The original latency and speedup factors (relative to the original) are presented for AsyncDiff configurations with different numbers of components (N) and strides (S).  It demonstrates the effectiveness of AsyncDiff across a range of GPU hardware.", "section": "4 Experiments"}, {"figure_path": "46jtDC6gXu/tables/tables_16_1.jpg", "caption": "Table 9: Time cost comparisons on SD 2.1. 'Ratio' in this table represents the proportion of communication cost to overall latency. All measurements were conducted on NVIDIA A5000 GPUs equipped with NVLINK Bridge", "description": "This table presents a quantitative analysis of the time costs associated with model execution and inter-device communication when using AsyncDiff on the Stable Diffusion 2.1 model.  It breaks down the overall time into running time and communication time, and calculates the ratio of communication time to overall time for different configurations. The configurations vary in terms of the number of components the model is split into (N) and the stride of denoising (S). The results show that communication overhead is a relatively small part of the overall process, making AsyncDiff efficient for distributed computing, although it does slightly increase as the number of devices and the stride increases.", "section": "More Analysis"}, {"figure_path": "46jtDC6gXu/tables/tables_16_2.jpg", "caption": "Table 10: Acceleration ratio on SD 2.1 under different num of denoising steps", "description": "This table shows how the speedup achieved by AsyncDiff on the Stable Diffusion 2.1 model changes depending on the number of denoising steps used (25, 50, and 100).  Different AsyncDiff configurations (N= number of components, S = stride) are compared against the original sequential method. The numbers in parentheses represent the time taken for inference in seconds.", "section": "4.2 Experimental Results on Image Diffusion Models"}, {"figure_path": "46jtDC6gXu/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative evaluations of AsyncDiff on three text-to-image diffusion models, showcasing various configurations. 'N' indicates the number of components into which the model is divided, and 'S' represents the denoising stride. MACs quantifies the computational load per device for generating a single image throughout the denoising process.", "description": "This table presents a quantitative analysis of the AsyncDiff model's performance on three different text-to-image diffusion models (SD 2.1, SD 1.5, and SDXL).  It shows how different model configurations (number of components 'N' and denoising stride 'S') affect the model's latency, speedup, CLIP score, FID, and LPIPS metrics across varying numbers of devices.  MACs (Multiply-Accumulate operations) provides a measure of computational cost per device.", "section": "4.2 Experimental Results on Image Diffusion Models"}]