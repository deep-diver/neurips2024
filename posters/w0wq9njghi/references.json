{"references": [{"fullname_first_author": "Ryan Lowe", "paper_title": "Multi-agent actor-critic for mixed cooperative-competitive environments", "publication_date": "2017-00-00", "reason": "This paper introduces the MADDPG algorithm, a foundational multi-agent reinforcement learning algorithm used as a baseline and a comparison point in the current paper."}, {"fullname_first_author": "Jakob Foerster", "paper_title": "Learning to communicate with deep multi-agent reinforcement learning", "publication_date": "2016-00-00", "reason": "This paper introduces the concept of centralized training with decentralized execution (CTDE), a crucial paradigm in multi-agent reinforcement learning that the current paper builds upon."}, {"fullname_first_author": "Tabish Rashid", "paper_title": "Monotonic value function factorization for deep multi-agent reinforcement learning", "publication_date": "2020-00-00", "reason": "This paper introduces the QMIX algorithm, a value-based multi-agent reinforcement learning algorithm, used extensively as a comparison algorithm in experiments within this paper."}, {"fullname_first_author": "Johannes Ackermann", "paper_title": "Reducing overestimation bias in multi-agent domains using double centralized critics", "publication_date": "2019-00-00", "reason": "This paper introduces the MATD3 algorithm, an actor-critic multi-agent reinforcement learning algorithm, that this paper extends and improves upon."}, {"fullname_first_author": "Benjamin Ellis", "paper_title": "SMACv2: An improved benchmark for cooperative multi-agent reinforcement learning", "publication_date": "2024-00-00", "reason": "This paper introduces the SMACv2 environment, a challenging benchmark used for evaluating multi-agent reinforcement learning algorithms in the current paper."}]}