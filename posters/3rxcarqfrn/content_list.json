[{"type": "text", "text": "Generative Adversarial Model-Based Optimization via Source Critic Regularization ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Michael S. Yao\u2217 ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hamsa Bastani ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Bioengineering Perelman School of Medicine University of Pennsylvania ", "page_idx": 0}, {"type": "text", "text": "Yimeng Zeng Department of Computer and Information Science University of Pennsylvania ", "page_idx": 0}, {"type": "text", "text": "The Wharton School University of Pennsylvania ", "page_idx": 0}, {"type": "text", "text": "James C. Gee Department of Radiology University of Pennsylvania ", "page_idx": 0}, {"type": "text", "text": "Jacob Gardner Department of Computer and Information Science University of Pennsylvania ", "page_idx": 0}, {"type": "text", "text": "Osbert Bastani\u2217 Department of Computer and Information Science University of Pennsylvania ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Offline model-based optimization seeks to optimize against a learned surrogate model without querying the true oracle objective function during optimization. Such tasks are commonly encountered in protein design, robotics, and clinical medicine where evaluating the oracle function is prohibitively expensive. However, inaccurate surrogate model predictions are frequently encountered along offline optimization trajectories. To address this limitation, we propose generative adversarial model-based optimization using adaptive source critic regularization (aSCR)\u2014a task- and optimizer- agnostic framework for constraining the optimization trajectory to regions of the design space where the surrogate function is reliable. We propose a computationally tractable algorithm to dynamically adjust the strength of this constraint, and show how leveraging aSCR with standard Bayesian optimization outperforms existing methods on a suite of offilne generative design tasks. Our code is available at https://github.com/michael-s-yao/gabo. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In many real-world tasks, we often seek to optimize the value of an objective function over some search space of inputs. Such optimization problems span across a wide variety of domains, including molecule and protein design (Guimaraes et al., 2017; Brown et al., 2019; Maus et al., 2022), patient treatment effect estimation (Kim & Bastani, 2021; Berrevoets et al., 2022; Xu & Bastani, 2023), and resource allocation in public policy (Bastani et al., 2021; Ramchandani et al., 2021). A number of algorithms have been explored for online optimization in these domains, including first-order methods, quasi-Newton methods, and Bayesian optimization (Sun et al., 2020). ", "page_idx": 0}, {"type": "text", "text": "However, in many situations it may prove difficult or costly to estimate the objective function for any arbitrary input configuration. Evaluating newly proposed molecules requires expensive experimental laboratory setups, and testing multiple drug doses for a single patient can potentially be dangerous. In these scenarios, the allowable budget for objective function queries is prohibitive, thereby limiting the utility of out-of-the-box online policy optimization methods. ", "page_idx": 0}, {"type": "text", "text": "To overcome this limitation, recent work has investigated the utility of optimization methods in the offline setting, where we are unable to query the objective function during the optimization process and instead only have access to a set of prior observations of inputs and associated objective values; this problem can often be referred to as offilne model-based optimization (MBO) (Trabucco et al., 2021; Mashkaria et al., 2023). While one may na\u00efvely attempt to learn a surrogate black-box model from the prior observations that approximates the true oracle objective function, such models can suffer from overestimation errors, yielding falsely promising objective estimates for inputs not contained in the offilne dataset. As a result, offilne optimization against the surrogate objective may yield low-scoring candidate designs according to the true oracle objective function\u2014a key limitation of traditional policy optimization techniques in the offline setting (Fig. 1). ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this work, we propose a novel offline MBO algorithm that leverages source critic models to optimize a surrogate objective while simultaneously remaining in-distribution when compared against a reference offline dataset. In this setting, an optimizer is rewarded for proposing optima that are \u201csimilar\u201d to reference data points, thereby minimizing overestimation error and allowing for more robust oracle function optimization in the offline setting. Inspired by recent work on generative adversarial networks (Goodfellow et al., 2014), we quantify design similarity by proposing a novel method that regularizes a surrogate objective model using a source critic actor, which we call adaptive source critic regularization (aSCR). We show how our algorithm can be readily leveraged with optimization methods such as Bayesian optimization (BO) and first-order methods. ", "page_idx": 1}, {"type": "text", "text": "Contributions: Our contributions are as follows: (1) We propose a novel approach for MBO that formulates the task as a constrained primal optimization problem, and we show how this framework can be used to solve for the optimal ", "page_idx": 1}, {"type": "image", "img_path": "3RxcarQFRn/tmp/3611dfa1396cb5ed398c7399760357a0b31daf93af9824e8c31777dac25bdc6a.jpg", "img_caption": ["Figure 1: Na\u00efve offline model-based optimization (MBO) (Trabucco et al., 2021), which optimizes against a learned surrogate model $f_{\\theta}$ trained on a fixed dataset $D_{n}~=~\\{(\\mathbf{x}_{i},y_{i})\\}_{i=1}^{n}$ (shaded region) without access to the true oracle $f$ , often yields candidate designs $\\mathbf{x}^{*}$ (i.e., diamond) that score poorly using the true oracle (i.e., cross). Our method (aSCR) constrains optimization trajectories to avoid these extrapolated points, instead proposing \u2018in-distribution\u2019 designs (i.e., star). "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "tradeoff between na\u00efvely optimizing against the surrogate model and staying in-distribution relative to the offilne dataset. (2) We introduce a computationally tractable method\u2014which we call adaptive source critic regularization (aSCR)\u2014to implement this framework with two popular optimization methods: Bayesian optimization and gradient ascent. (3) We show that compared to prior methods, our proposed algorithm with Bayesian optimization empirically achieves the highest rank of 3.8 (second best is 5.5) on top-1 design evaluation, and highest rank of 3.0 (second best is 4.6) on top-128 design evaluation across a variety of tasks spanning multiple scientific domains. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Leveraging source critic model feedback for adversarial training of neural networks was popularized by works such as Goodfellow et al. (2014), where a generator and adversarial discriminator \u201cplay\u201d a zero-sum minimax game to train a generative model. However, such discriminators often suffer from mode collapse and training instability in practice. To overcome these limitations, Arjovsky et al. (2017) introduced the Wasserstein generative adversarial net (WGAN), which instead utilizes a source critic that learns to approximate the 1-Wasserstein distance between the generated and training distributions. However, WGANs and similar networks primarily aim to generate samples that look in-distribution from a latent space prior, rather than optimize against an objective function. In our work, we adapt WGAN-inspired source critic models for Wasserstein distance estimation. ", "page_idx": 1}, {"type": "text", "text": "Separately in the field of optimization, Brookes et al. (2019) introduced a method for conditioning by adaptive sampling (CbAS) that learns a density model of the input space that is gradually adapted towards the optimal solution. However, such prior works have focused on solving low-dimensional, online optimization tasks (Hansen & Ostermeier, 1996; Brookes et al., 2019). More recently, Trabucco et al. (2021) introduced conservative objective models (COM) specifically for offline optimization tasks; however, their method requires directly modifying the parameters of the surrogate function during optimization, which is not always feasible for any general task. Mashkaria et al. (2023) proposed Black-box Optimization Networks (BONET) to learn the dynamics of optimization trajectories using a causally masked transformer model, and Krishnamoorthy et al. (2023) introduced Denoising Diffusion Optimization Models (DDOM) to learn the generative process via a diffusion model. Furthermore, Yu et al. (2021) and Chen et al. (2022) describe Robust Model Adaptation (RoMA) and Bidirectional learning via infinite-width networks (BDI), respectively. RoMA regularizes the gradient of surrogate objective models by enforcing a local smoothness prior at the observed inputs, and BDI learns bidirectional mappings between low- and high- scoring candidates. Finally, Nguyen et al. (2023) introduce Experiment Pretrained Transformers $(\\mathbf{E}\\mathbf{x}\\mathbf{P}\\mathbf{T})$ to learn a general model for optimization using unsupervised methods. While these recent works and others propose promising algorithms for offline optimization tasks, they are often evaluated using expensive oracle query budgets that are often not achievable in practice\u2014especially for potentially dangerous tasks such as patient care and other high-stakes applications. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "3 Background ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Offline Model-Based Optimization ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In many real-world domains, we often seek to optimize an oracle objective function $f(\\mathbf{x})$ over a space of design candidates $\\mathcal{X}$ to solve for $\\mathbf{x}^{*}=\\operatorname{argmax}_{\\mathbf{x}\\in\\mathcal{X}}f(\\mathbf{x})$ . Examples of such problems include optimizing certain desirable properties of molecules in molecular design (Guimaraes et al., 2017; Brown et al., 2019; Maus et al., 2022), and estimating the optimal therapeutic intervention for patient care in clinical medicine (Kim & Bastani, 2021; Berrevoets et al., 2022; Xu & Bastani, 2023). In practice, however, the true objective function $f$ may be costly to compute or even entirely unknown, making it difficult to query in optimizing $f(\\mathbf{x})$ . Instead, it is often more feasible to obtain access to a reference labeled dataset of observations from nature $\\mathcal{D}_{n}\\,=\\,\\bigl\\{(\\mathbf{x}_{1},y_{1}),\\dots,(\\mathbf{x}_{n},y_{n})\\bigr\\}$ where $y_{i}=f(\\mathbf{x}_{i})$ . Optimization methods may use a variety of different strategies to leverage $\\mathcal{D}_{n}$ in the offilne setting (Mashkaria et al., 2023; Krishnamoorthy et al., 2023; Chen et al., 2022); one common approach used by Trabucco et al. (2021) and others is to learn a regressor model $f_{\\theta}$ parametrized by ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\theta^{*}=\\operatorname{argmin}_{\\theta}\\ \\mathbb{E}_{(\\mathbf{x}_{i},y_{i})\\sim\\mathcal{D}_{n}}||f_{\\theta}(\\mathbf{x}_{i})-y_{i}||^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "as a surrogate model for the true oracle objective $f(\\mathbf{x})$ . Rather than querying the oracle $f$ as in the online setting, we can instead solve the related optimization problem ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{x}^{*}=\\operatorname{argmax}_{\\mathbf{x}\\in\\mathcal{X}}f_{\\theta}(\\mathbf{x})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "with the hope that optimizing $f_{\\theta}$ will also lead to desirable oracle values of $f$ as well. Solving (2) is one instantiation of offline model-based optimization (MBO) for which a number of techniques have been developed, such as gradient ascent and Bayesian optimization (BO) (Sun et al., 2020). ", "page_idx": 2}, {"type": "text", "text": "Of note, it is difficult to guarantee the reliability of the model\u2019s predictions for $\\mathbf{x}\\notin\\mathcal{D}_{n}$ that are almost certainly encountered in the optimization trajectory. Thus, na\u00efvely optimizing the surrogate objective $f_{\\theta}$ can result in \u201coptima\u201d that are low-scoring according to the oracle objective $f$ . ", "page_idx": 2}, {"type": "text", "text": "3.2 Optimization Over Latent Spaces ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In certain cases, the search space $\\mathcal{X}$ for an optimization task may be discretized over a finite set of structured inputs, such as amino acids for protein sequences or atomic building blocks for molecules. However, many historical optimization algorithms do not generalize well to these settings for a number of different reasons, such as the lack of gradients with respect to the input designs to guide the optimization trajectory. Instead of directly optimizing over $\\mathcal{X}$ , recent work leverages deep variational autoencoders (VAEs) to first map the input space into a continuous, (often) lower dimensional latent space $\\mathcal{Z}$ and then performing optimization over $\\mathcal{Z}$ instead (Tripp et al., 2020; Deshwal & Doppa, 2021; Maus et al., 2022). A VAE is composed of a two components: (1) an encoder with parameters $\\phi$ that learns an approximated posterior distribution $q_{\\phi}(z|\\mathbf{x})$ for $\\mathbf{x}\\in\\mathcal{X},z\\in\\mathcal{Z}$ ; and (2) a decoder with parameters $\\varphi$ that learns the conditional likelihood distribution $p_{\\varphi}(\\mathbf{x}|z)$ (Kingma & Welling, 2013). The encoder and decoder are co-trained to maximize the evidence lower bound (ELBO) ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{ELBO}=\\mathbb{E}_{z\\sim q_{\\phi}}\\left[\\log p_{\\varphi}(\\mathbf{x}|z)\\right]-D_{\\mathrm{KL}}\\left[q_{\\phi}(z|\\mathbf{x})\\ ||\\ p_{\\mathrm{VaE}}(z)\\right]\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $D_{\\mathrm{KL}}$ is the Kullback-Leibler (KL) divergence and $p_{\\mathrm{VAE}}(z)$ is the prior distribution. A common choice is to set $p_{\\mathrm{VAE}}=\\mathcal{N}(0,I)$ (i.e., the standard normal distribution). Optimization can then be performed over the continuous latent space $\\mathcal{Z}$ of the VAE to propose \u2018latent space designs\u2019 that can be readily decoded using the decoder $\\varphi$ back into the original input space. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "One such optimization method over VAE latent spaces is Bayesian optimization (BO), a sampleefficient framework for solving expensive black-box optimization problems (Mockus, 1982; Osborne et al., 2009; Snoek et al., 2012). While the utility of BO has primarily been explored for expensiveto-evaluate black-box functions in prior literature, recent work has shown that BO also outperforms baseline optimization methods in offline tasks involving models that are relatively inexpensive to evaluate, such as the neural network surrogates used in model-based optimization (MBO). Multiple prior works have shown that BO and related methods consistently outperform both first-order gradientbased and stochastic evolutionary methods (Eriksson et al., 2019b; Maus et al., 2022; Hvarfner et al., 2024; Eriksson & Jankowiak, 2021; Astudillo & Frazier, 2019). ", "page_idx": 3}, {"type": "text", "text": "3.3 Wasserstein Metric Between Probability Distributions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The Wasserstein distance is a distance metric between any two probability distributions, and is closely related to problems in optimal transport. We define the $p\\,=\\,1$ Wasserstein distance between a reference distribution $P$ and a generated distribution $Q$ using distance metric $d(\\cdot,\\cdot)$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\nW_{1}(P,Q)=\\operatorname*{inf}_{\\gamma\\in\\Gamma(P,Q)}\\mathbb{E}_{(z^{\\prime},z)\\sim\\gamma}d(z^{\\prime},z)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\Gamma$ is the set of all couplings between $P$ and $Q$ . For empirical distributions where ${{p}_{n}}\\left({{q}_{n}}\\right)$ is based on $n$ observations $\\{z_{j}^{\\prime}\\}_{j=1}^{n}\\,(\\{z_{i}\\}_{i=1}^{n})$ , (4) can be simplified to ", "page_idx": 3}, {"type": "equation", "text": "$$\nW_{1}(p_{n},q_{n})=\\operatorname*{inf}_{\\sigma}\\frac{1}{n}\\sum_{i=1}^{n}||z_{\\sigma(i)}^{\\prime}-z_{i}||\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the infimum is over all permutations $\\sigma$ of $n$ elements. Leveraging the Kantorovich-Rubinstein duality theorem (Kantorovich $\\&$ Rubinstein, 1958), (5) can be equivalently written as ", "page_idx": 3}, {"type": "equation", "text": "$$\nW_{1}(p_{n},q_{n})=\\frac{1}{K}\\operatorname*{sup}_{||c||_{L}\\leq K}\\left[\\mathbb{E}_{z^{\\prime}\\sim P}[c(z^{\\prime})]-\\mathbb{E}_{z\\sim Q}[c(z)]\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $c(z)$ is a source critic and $\\vert\\vert c\\vert\\vert_{L}$ is the Lipschitz norm of $c(z)$ . In the Wasserstein GAN (WGAN) model proposed by Arjovsky et al. (2017), a generative network and source critic are cotrained in a minimax game where the generator (critic) seeks to minimize (maximize) the Wasserstein distance $W_{1}$ between the training and generated distributions. Such an optimization schema enables the generator policy to learn the distribution of training samples from nature. ", "page_idx": 3}, {"type": "text", "text": "4 A Framework for Generative Adversarial Optimization ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section we describe our proposed framework for generative adversarial model-based optimization using adaptive source critic regularization (aSCR). Our method uses a $K$ -Lipschitz source critic model to dynamically regularize the optimization objective to avoid extrapolation against the proxy surrogate model $f_{\\theta}$ in offline MBO. ", "page_idx": 3}, {"type": "text", "text": "4.1 Constrained Optimization Formulation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In offilne generative optimization, we aim to optimize against a surrogate objective function $f_{\\theta}$ . In order to ensure that we are achieving reliable estimates of the true, unknown oracle objective, we can add a regularization penalty to keep generated samples \u201csimilar\u201d to those from the training dataset of $f_{\\theta}$ according to an adversarial source critic trained to discriminate between generated and offline samples. That is, in contrast to (2), aSCR instead considers a closely related constrained problem ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\operatornamewithlimits{m i n i m i z e}_{z\\in\\mathcal{Z}}}&{{}-f_{\\theta}(z)}\\\\ {\\mathrm{subject~to}}&{{}\\mathbb{E}_{z^{\\prime}\\in P}[c^{*}(z^{\\prime})]-c^{*}(z)\\leq0}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "over some configuration space $\\mathcal{Z}\\subseteq\\mathbb{R}^{d}$ , and where we define $c^{*}$ as a source critic model that maximizes $\\mathbb{E}_{z^{\\prime}\\in P}[c^{*}(z^{\\prime})]-\\mathbb{E}_{z\\in Q}[c^{*}(z)]$ over all $K$ -Lipschitz functions as in (6). We can think of $\\mathbb{E}_{z^{\\prime}\\in P}[c^{*}(z^{\\prime})]-c^{*}(z)$ as the contribution of a particular generated datum $z$ to the overall $p\\,=\\,1$ ", "page_idx": 3}, {"type": "text", "text": "Wasserstein distance between the generated candidate $(Q)$ and reference $(P)$ distributions of designs as in (6). In practice, we model $c^{*}$ as a fully connected neural net. Intuitively, the imposed constraint restricts the feasible search space to designs that score at least as in-distribution as the average sample in the offline dataset according to the source critic. Therefore, $c^{*}$ acts as an adversarial model to regularize the optimization policy. Of note, this additional constraint in (7) may be highly non-convex for general $c^{*}$ , and so it is often impractical to directly apply (7) to any arbitrary MBO policy. ", "page_idx": 4}, {"type": "text", "text": "4.2 Dual Formulation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To solve this implementation problem, we instead look to reformulate (7) in its dual space by first considering the Lagrangian $\\mathcal{L}$ of our constrained problem: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}\\left(z;\\lambda\\right)=-f_{\\theta}(z)+\\lambda\\left[\\mathbb{E}_{z^{\\prime}\\in P}[c^{*}(z^{\\prime})]-c^{*}(z)\\right]\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\lambda\\geq0$ is the Lagrange multiplier associated with the constraint in (7). We can equivalently think of $\\lambda$ as a hyperparameter that controls the relative strength of the source critic-penalty term: $\\lambda=0$ equates to na\u00efvely optimizing the surrogate objective, while $\\lambda\\gg1$ asymptotically approaches a WGAN-like optimization policy. Minimizing $\\mathcal{L}$ thus minimizes a relative sum of $-f_{\\theta}$ and the Wasserstein distance contribution from any particular generated datum $z$ with relative weighting dictated by the hyperparameter $\\lambda$ . From duality, minimizing $\\mathcal{L}$ over $z$ and simultaneously maximizing over $\\lambda\\in\\mathbb{R}_{+}$ is equivalent to the original constrained problem in (7). ", "page_idx": 4}, {"type": "text", "text": "The challenge now is in determining this optimal value of $\\lambda$ : if $\\lambda$ is too small, then the objective estimates may be unreliable; if $\\lambda$ is too large, then the optimization trajectory may be unable to adequately explore the input space. Prior work by Trabucco et al. (2021) has previously explored the idea of formulating offilne optimization problems as a similarly regularized Lagrangian (albeit with a separate regularization constraint), although their method tunes a static hyperparameter by hand. In contrast, aSCR treats $\\lambda$ as a dynamic parameter that adapts to the optimization trajectory in real time. ", "page_idx": 4}, {"type": "text", "text": "4.3 Computing the Lagrange Multiplier $\\lambda$ ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Continuing with our dual formulation of (7), the Lagrange dual function $g(\\lambda)$ is defined as $g(\\lambda)=$ $\\operatorname*{inf}_{z\\in\\mathbb{R}^{n}}\\mathcal{L}\\left(z;\\lambda\\right)$ . The $z\\,=\\,{\\hat{z}}$ that minimizes the Lagrangian in the definition of $g$ is evidently a function of $\\lambda$ . To show this, we use the first-order condition that $\\nabla_{z}\\mathcal{L}=0$ at $z=\\hat{z}$ . Per (8), we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\nabla_{z}\\mathcal{L}(\\hat{z};\\lambda)=-\\nabla_{z}f_{\\theta}(\\hat{z})-\\lambda\\nabla_{z}c^{*}(\\hat{z})=0\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In general, solving (9) for $\\hat{z}$ is computationally intractable\u2014especially in high-dimensional problems. Instead, we can approximate $\\hat{z}$ by relaxing the condition in (9) according to ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{z}(\\lambda)=\\operatorname*{argmin}_{z\\in\\mathbb{R}^{n}}\\frac{1}{2}\\left||-\\nabla_{z}f_{\\theta}(z)-\\lambda\\nabla_{z}c^{*}(z)|\\right|^{2}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Our key insight is that although minimizing the loss term in (10) is not practical when the feasible set is na\u00efvely uniform over $\\mathbb{R}^{n}$ , we can instead choose to focus our attention on latent space coordinates with high associated probability according to the VAE prior distribution $p_{\\mathrm{VAE}}(z)$ . This is because in optimization problems acting over the latent space of any variational autoencoder, the majority of the encoded information content is embedded according to $p_{\\mathrm{VAE}}(z)$ due to the Kullback-Leibler (KL) divergence contribution to VAE training. Put simply, the encoder distribution $q_{\\phi}(z|\\mathbf{x})$ is trained so that $D_{\\mathrm{KL}}\\bar{[q_{\\phi}(z|\\mathbf{x})||p_{\\mathrm{VAE}}(z))]}$ is optimized as a regularization term in (3). We argue that it is thus sufficient enough to approximate $\\hat{z}(\\lambda)$ using a Monte Carlo sampling schema with random samples $\\mathcal{Z}_{N}=(z_{1},z_{2},\\ldots,z_{N})\\sim p_{\\mathrm{VAE}}(z)$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\hat{z}(\\lambda)\\approx\\operatorname*{argmin}_{\\mathcal{Z}_{N}\\sim p_{\\mathrm{var}}(z)}\\frac{1}{2}\\left||-\\nabla_{z}f_{\\theta}(z)-\\lambda\\nabla_{z}c^{*}(z)|\\right|^{2}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We can now concretely write an approximation of the Lagrange dual problem of (7): ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathrm{maximize}}{\\mathrm{maximize}}}&{g(\\lambda)=-f_{\\theta}(\\hat{z})+\\lambda\\left[\\mathbb{E}_{z^{\\prime}\\in P}[c^{*}(z^{\\prime})]-c^{*}(\\hat{z})\\right]}\\\\ {\\mathrm{subject\\to}}&{\\lambda\\geq0}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\hat{z}$ is as in (11). Defining the surrogate variable $\\alpha$ such that $\\textstyle\\lambda={\\frac{\\alpha}{1-\\alpha}}$ , we can rewrite (12) as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{\\mathrm{maximize}}{\\mathrm{maximize}}}&{{}-(1-\\alpha)f_{\\theta}(\\hat{z})+\\alpha\\left[\\mathbb{E}_{z^{\\prime}\\in P}[c^{*}(z^{\\prime})]-c^{*}(\\hat{z})\\right]}\\\\ {\\mathrm{subject~to}}&{{}0\\le\\alpha<1}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "In practice, we discretize the search space for $\\alpha$ to 200 evenly spaced points between 0 and 1 inclusive. From weak duality, finding the optimal solution to (12) provides a lower bound on the optimal solution to the primal problem in (7). Algorithm 1 can now be used to choose the optimal $\\alpha$ (and hence $\\lambda$ ) adaptively during offline optimization: we refer to our method as Adaptive SCR (aSCR). ", "page_idx": 5}, {"type": "text", "text": "4.4 Overall Algorithm ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Using Adaptive SCR, we now have a proposed method for dynamically computing $\\alpha$ (and hence the Lagrange multiplier $\\lambda$ ) of the constrained optimization problem in (7). Importantly, aSCR can be integrated with any standard function optimization method by optimizing the Lagrangian objective in (8) over the candidate design space as opposed to the original unconstrained objective $f_{\\theta}$ . We refer to this algorithm as Generative Adversarial Model-Based Optimization (GAMBO). To evaluate aSCR empirically, we instantiate two flavors of GAMBO: (1) Generative Adversarial Bayesian Optimization (GABO, Algorithm 2); and (2) Generative Adversarial Gradient Ascent (GAGA).2 ", "page_idx": 5}, {"type": "text", "text": "We implement GABO using a quasi-expected improvement (qEI) acquisition function, iterative sampling budget of $T=32$ , sampling batch size of $b=64$ , and GAGA using a step size of $\\eta=0.05$ , $T=128$ , and $b=16$ . Of note, the optimization objective using aSCR is time-varying and causally linked to past observations made during the optimization process via intermittent training of the source critic $c$ . Prior works from Nyikosa et al. (2018) and Aglietti et al. (2022) have examined optimization against dynamic objective functions, although have either entirely disregarded causal relationships between variables or only examined causality between inputs as opposed to inputs and the objective. We leave such methods for future work given that aSCR works well in practice. ", "page_idx": 5}, {"type": "text", "text": "5 Experimental Evaluation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "5.1 Datasets and Tasks ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To evaluate our proposed algorithm, we focus on a set of eight tasks spanning multiple domains with publicly available datasets in the field of offilne model-based optimization. (1) The Branin function is a well-known synthetic benchmark function where the task is to maximize the two-dimensional Branin function $\\dot{f}_{b r}\\,:\\,[-5,10]\\,\\times\\,[0,15]\\,\\rightarrow\\,\\mathbb{R}$ . (2) The LogP task is a well-studied optimization problem (Zhou et al., 2019; Chen et al., 2021; Flam-Shepherd et al., 2022) where we search over candidate molecules to maximize the penalized water-octanol partition coefficient (logP) score, which is an approximate measure of a molecule\u2019s hydrophobicity (Ertl & Schuffenhauer, 2009) that also rewards structures that can be synthesized easily and feature minimal ring structures. We use the publicly available Guacamol benchmarking dataset from Brown et al. (2019) to implement this task. ", "page_idx": 5}, {"type": "text", "text": "Tasks (3) - (7) are derived from Design-Bench, a publicly available set of MBO benchmarking tasks (Trabucco et al., 2022): (3) TF-Bind-8 aims to maximize the transcription factor binding efficiency of an 8-base-pair DNA sequence (Barrera et al., 2016); (4) GFP the green fluorescence of a 237-amino-acid protein sequence (Brookes et al., 2019; Rao et al., 2019); (5) UTR the gene expression from a 50-base-pair 5\u2019UTR DNA sequence (Sample et al., 2019; Angermueller et al., 2020); (6) ChEMBL the mean corpuscular hemoglobin concentration (MCHC) biological response of a molecule using an offilne dataset collected from the ChEMBL assay CHEMBL3885882 (Gaulton et al., 2012); and (7) D\u2019Kitty the morphological structure of the D\u2019Kitty robot (Ahn et al., 2020). ", "page_idx": 5}, {"type": "text", "text": "Finally, (8) the Warfarin task uses the dataset of patients on warfarin medication from Consortium (2009) to estimate the optimal dose of warfarin given clinical and pharmacogenetic patient data. Of note, in contrast to tasks (1) - (7) and other traditional MBO tasks in prior literature (Trabucco et al., 2022), the Warfarin task is novel in that only a subset of the input design dimensions may be optimized over (i.e., warfarin dose) while the others remain fixed as conditioning variables (i.e., patient covariates). Such a task can therefore be thought of as conditional model-based optimization. ", "page_idx": 5}, {"type": "text", "text": "5.2 Policy Optimization and Evaluation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For all experiments, the surrogate objective model $f_{\\theta}$ is a fully connected net with two hidden layers of size 2048 and LeakyReLU activations. $f_{\\theta}$ takes as input a VAE-encoded latent space datum and returns the predicted objective function value as output. The VAE encoder and decoder backbone architectures vary by MBO task and are detailed in Supplementary Table A1. Following G\u00f3mezBombarelli et al. (2018) and Maus et al. (2022), we co-train the VAE and surrogate objective models together using an Adam optimizer with a learning rate of $3\\times10^{-4}$ for all tasks. For the optimization tasks over continuous design spaces (i.e., Branin, Warfarin, and D\u2019Kitty), we fix the VAE encoder and decoders as the identity functions, such that the latent and input spaces are equivalent. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "The source critic agent $c$ in (7) is implemented as a fully connected net with two hidden layers with sizes equal to four (one) times the number of input dimensions for the first (second) layer. To constrain the Lipschitz norm of $c$ as in (6), we clamp the weights of the model between [-0.01, 0.01] after each optimization step as done by Arjovsky et al. (2017). The model is trained using gradient descent with a learning rate of 0.001 to maximize the Wasserstein distance between the dataset and generated candidates in the VAE latent space. ", "page_idx": 6}, {"type": "text", "text": "During optimization, both GABO and GAGA alternate between sampling new designs and training the source critic actor $c(z)$ until there is no improvement to the Wasserstein distance $W_{1}$ according to $c$ after 100 consecutive weight updates. We find that training $c$ every $n_{\\mathrm{generator}}=4$ sampling steps is a good choice across all tasks assessed, similar to prior work Arjovsky et al. (2017). ", "page_idx": 6}, {"type": "text", "text": "All MBO methods were evaluated using a fixed surrogate query budget of 2048. We focus on two evaluation metrics: 100th percentile (1) top $k=1$ ; and (2) top $k=128$ oracle score. The top $k=128$ evaluation metric is commonly reported in prior offilne MBO literature (Mashkaria et al., 2023; Trabucco et al., 2021; Yu et al., 2021); the top $k=1$ metric better accounts for the limited oracle query budget of the real-world tasks in which offline MBO would be of use. In both settings, an optimizer selects the top $k$ design that minimize the Lagrangian function value in (8) from the 2048 assessed designs to evaluate using the true oracle function, and the maximum score of those $k$ designs is reported across 10 random seeds. ", "page_idx": 6}, {"type": "text", "text": "We evaluate both GABO and GAGA against a number of pre-existing baseline algorithms on one internal cluster with 8 NVIDIA RTX A6000 GPUs. We include vanilla Bayesian Optimization (BO-qEI) and gradient ascent (Grad.) in our evaluation to assess the utility of our proposed aSCR algorithm. Furthermore, we evaluate limited-memory BFGS (L-BFGS) Liu & Nocedal (1989), CMA-ES Hansen & Ostermeier (1996), and ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1 Adaptive Source Critic Regularization (SCR) Input: differentiable surrogate objective $f_{\\theta}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ , differentiable source critic $c:\\mathbb{R}^{d}\\stackrel{}{\\rightarrow}\\mathbb{R}$ , reference dataset $\\mathcal{D}_{n}=\\{z_{j}^{\\prime}\\}_{j=1}^{n}$ , $\\alpha$ step size $\\Delta\\alpha$ , search budget $\\boldsymbol{\\mathbf{\\rho}}_{\\perp}$ , norm threshold $\\tau$ Sample candidates $\\mathcal{Z}_{B}\\gets\\{z_{i}\\}_{i=1}^{B}\\sim\\mathcal{N}(0,I_{d})$ Initialize $\\alpha^{*}\\gets$ None and $g^{*}\\gets-\\infty$ for $\\alpha$ in range(start $=0$ , end $=1$ , stepsize $=\\Delta\\alpha$ ) do $z^{*}\\leftarrow\\mathrm{argmin}_{z_{i}\\in\\mathcal{Z}_{n}}||(1-\\alpha)\\nabla f_{\\theta}(\\bar{z}_{i})+\\alpha\\nabla c(\\bar{z}_{i})||_{2}$ if $||(1-\\alpha)\\nabla f_{\\theta}(z^{*})+\\alpha\\nabla c(z^{*})||_{2}>\\tau$ then continue $//$ Discard $\\alpha$ if best norm exceeds $\\tau$ end if $g\\gets-(1-\\alpha)f_{\\theta}(z^{*})+\\alpha\\left[\\mathbb{E}_{\\mathcal{D}_{n}}[c(z_{j}^{\\prime})]-c(z^{*})\\right]$ if $g>g^{*}$ then \u03b1\u2217\u2190\u03b1 and g\u2217\u2190g // Implements (13) end if ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2 Generative Adversarial BayesOpt (GABO) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Input: surrogate objective $f_{\\theta}:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$ , offline dataset   \n$\\bar{D_{n}}=\\{z_{j}^{\\prime}\\}_{j=1}^{n^{-}}$ , acquisition function $a$ , iterative sampling   \nbudget $T$ , sampling batch size $b$ , number of generator steps   \nper source critic training $n_{\\mathrm{generator}}$ , oracle query budget $k$   \nAdaptiveSCR Input: $\\alpha$ step size $\\Delta\\alpha$ , search budget $\\boldsymbol{\\mathbf{\\rho}}_{\\perp}$ ,   \nnorm threshold $\\tau$   \nDefine: Differentiable source critic $c:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$   \nDefine: Lagrangian $\\mathcal{L}(z;\\alpha):\\mathbb{R}^{d}\\times\\mathbb{R}\\rightarrow\\mathbb{R}$ // Eq. (8) $\\begin{array}{r}{\\mathcal{L}(z;\\boldsymbol{\\alpha})=-f_{\\theta}(z)+\\frac{\\alpha}{1-\\alpha}[\\mathbb{E}_{z^{\\prime}\\sim\\mathcal{D}_{n}}[c(\\boldsymbol{z}^{\\prime})]-c(z)]}\\end{array}$   \nSample candidates $\\mathcal{Z}^{1}\\gets\\{z_{i}^{1}\\}_{i=1}^{b}\\sim$ SobolSequence   \n// Train the source critic per Eq. (6) to optimality:   \n$c\\gets\\mathrm{argmax}_{||c||_{L}\\leq K}W_{1}(\\mathcal{D}_{n},\\bar{\\mathcal{Z}}^{1})$ $=\\operatorname{argmax}_{|\\mathbf{\\Theta}|_{\\mathbf{\\Theta}}||_{\\mathbf{\\Theta}}\\leq K}\\left[\\mathbb{E}_{z^{\\prime}\\sim\\mathcal{D}_{n}}[c(z^{\\prime})]-\\mathbb{E}_{z\\sim\\mathcal{Z}^{1}}[c(z)]\\right]$   \n$\\boldsymbol{\\chi}\\gets\\mathbf{AdaptiveSCR}(f_{\\theta},c,\\mathcal{D}_{n},\\Delta\\alpha,\\mathcal{B},\\tau)$ // Alg. (1)   \nEvaluate candidates $\\mathcal{V}^{1}\\gets\\{y_{i}^{1}\\}_{i=1}^{b}=\\{-\\mathcal{L}(z_{i}^{1};\\alpha)\\}_{i=1}^{b}$   \nPlace Gaussian Process (GP) prior on $f_{\\theta}$   \nfor $t$ p idna $2,3,\\ldots,T$ odno with $f_{\\theta}$ $\\mathscr{D}_{t-1}=\\{(\\mathcal{Z}^{m},\\mathcal{V}^{m})\\}_{m=1}^{t-1}$ $\\footnote{T w o t y p i c a l a p p l i c a t i o n s c e n a r i o s f o r t h e p r o p o s e d s y s t e m a r e h e a l t h c a r e,a n d l o g i s t i c s a n d w a r e h o u s i n g,i n w h i c h m u l t i p l e I o T d e v i c e s a r e d e p l o y e d c l o s e t o t h e r e c e i v e r a n d t h e t i m e d e l a y b e t w e e n t h e d i r e c t l i n k a n d b a c k s c a t t e r l i n k i s t h u s n e g l i g i b l e.}$ Sample candidates $\\mathcal{Z}^{t}\\gets\\{z_{i}^{t}\\}_{i=1}^{b}$ according to $a$ $\\alpha\\gets\\mathbf{AdaptiveSCR}(f_{\\theta},c,\\mathcal{D}_{n},\\Delta\\alpha,\\mathcal{B},\\tau)$ Evaluate samples $\\mathcal{V}^{t}\\leftarrow\\{y_{i}^{t}\\}_{i=1}^{b}=\\{-\\mathcal{L}(z_{i}^{t};\\alpha)\\}_{i=1}^{b}$ if $t$ mod $n_{\\mathrm{generator}}$ equals 0 then $//$ Train the source critic per Eq. (6) to optimality: $\\begin{array}{r l}&{c\\gets\\operatorname*{argmax}_{||c||_{L}\\leq K}\\hat{W_{1}({\\mathcal D}_{n},\\tilde{{\\mathcal Z}}^{t})}\\qquad\\qquad\\qquad}\\\\ &{\\quad=\\operatorname*{argmax}_{||c||_{L}\\leq K}\\left[\\mathbb{E}_{z^{\\prime}\\sim{\\mathcal D}_{n}}[c(z^{\\prime})]-\\mathbb{E}_{z\\sim{\\mathcal Z}^{t}}[c(z)]\\right]}\\\\ &{\\quad\\sim\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}$ ondif ", "page_idx": 6}, {"type": "text", "text": "return the top $k$ samples from the $T\\times b$ observations $\\mathcal{D}_{T}\\overset{\\cdot}{=}\\{\\{(z_{i}^{m},y_{i}^{m})\\}_{i=1}^{b}\\}_{m=1}^{T}$ according to $y_{i}^{m}$ ", "page_idx": 6}, {"type": "text", "text": "simulated annealing (Anneal) Kirkpatrick et al. (1983). We also compare our method against the more recently introduced algorithms TuRBO-qEI (Eriksson et al., 2019a), COM (Trabucco et al., ", "page_idx": 6}, {"type": "text", "text": "2021), RoMA (Yu et al., 2021), BDI (Chen et al., 2022), DDOM (Krishnamoorthy et al., 2023), BONET (Mashkaria et al., 2023), ExPT (Nguyen et al., 2023), ROMO (Chen et al., 2023), and BootGen (Kim et al., 2023). Because BootGen is proposed by Kim et al. (2023) as an optimization method specifically for biological sequence design, we only assess this baseline method on the five relevant tasks in our evaluation suite. ", "page_idx": 7}, {"type": "text", "text": "Conditional MBO Tasks. To our knowledge, prior work in conditional model-based optimization is limited, and so previously reported algorithms are not equipped to solve such tasks out-of-the-box. Chen et al. (2023) explore such tasks in their work, but primarily focus on conditional tasks that are built by arbitrarily fixing certain design dimensions from unconstrained problems, which are not representative of true conditional optimization problems in the real world. In our work, we introduce the Warfarin task to assess methods on their ability to design an optimal therapeutic drug regiment conditioned on a fixed patient state and lab values. To assess existing methods on this task, we implement conditional proxies of all baselines employing a first-order optimization schema via partial gradient ascent to only update the warfarin dose dimension while leaving the patient attribute conditional dimensions unchanged. Conditional BO-based methods are implemented by fitting separate Gaussian processes for each patient. In conditional DDOM, we exchange the algorithm\u2019s diffusion model-based backbone with a conditional score-based diffusion model (Gu et al., 2023). ", "page_idx": 7}, {"type": "text", "text": "Of note, the BONET algorithm (Mashkaria et al., 2023) requires multiple observations for any given patient to construct synthetic optimization trajectories. However, the key challenge in conditional MBO is that each condition (i.e., patient) has no past observations (i.e., warfarin doses), and instead relies on learning from offilne datasets constructed from different permutations of condition values As a result, the BONET algorithm is unable to be evaluated on conditional MBO tasks. ", "page_idx": 7}, {"type": "text", "text": "5.3 Main Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Scoring of one-shot optimization candidates is shown in Table 1. Across all eight assessed tasks spanning a wide range of scientific domains, GABO with our aSCR algorithm achieved the best average rank of 3.8 when compared to other existing methods (next best is 5.5). Furthermore, GABO was able to propose top $k=1$ candidate designs that outperform the best design in the pre-existing offline dataset for 6 of the 8 tasks\u2013greater than any of the other methods assessed. If a larger oracle evaluation budget is available (i.e., $k=128)$ ), GABO with aSCR performs even better, achieving the best average rank of 3.0 (next best is 4.6). GABO is also the best algorithm on 3 of the 8 tasks and second best on 2 tasks according to this evaluation metric. Altogether, our results suggest that GABO is a promising method for proposing optimal design candidates in offline MBO. ", "page_idx": 7}, {"type": "text", "text": "Importantly, our aSCR algorithm improves upon both the na\u00efve BO-qEI and Grad. Ascent parent optimizers assessed. GABO outperforms both baseline BO-based optimization methods in our evaluation suite: BO (TuRBO) only achieves a rank of 8.8 (9.0) on the top $k=1$ evaluation metric and a rank of 6.6 (7.4) on the top $k=128$ metric. Similarly, GAGA scores an average rank of 7.4 (7.6) on the top $k=1$ ( $k=128)$ ) evaluation metric; by leveraging aSCR, GAGA outperforms its base parent optimizer (Grad. Ascent), which only achieves an average rank of 9.0 and 11.0 on the same two evaluation metrics, respectively. Our results show that using aSCR to adaptively penalize the objective of two popular optimization methods can improve their offline performance. ", "page_idx": 7}, {"type": "text", "text": "Qualitative Evaluation: Penalized LogP Task. We evaluate GABO against na\u00efve BO-qEI for the LogP task by inspecting the three-dimensional chemical structures of the top-scoring candidate molecules. As a general principle, molecules that are associated with high Penalized LogP scores are hydrophobic with minimal ring structures and therefore often feature long hydrocarbon backbones (Ertl & Schuffenhauer, 2009). In Figure 2, we see that BO-qEI using the unconstrained surrogate objective generates a candidate molecule of hydrogen and carbon atoms. However, the proposed candidate includes two rings in its structure, resulting in a suboptimal oracle Penalized LogP score. ", "page_idx": 7}, {"type": "text", "text": "We hypothesize that this may be due to a lack of ring-containing example molecules in the offline dataset, as only $6.7\\%$ $(2.7\\%)$ of observed molecules contain at least one (two) carbon ring(s). As a result, the surrogate objective model estimator returns more inaccurate Penalized LogP estimates for input ring-containing structures (surrogate model root mean squared error $(\\mathrm{RMSE})=25.5$ for offline dataset molecules with at least 2 rings; $\\mathrm{RMSE}=16.5$ for those with at least 1 ring; and $\\mathrm{RMSE}=4.6$ for those with at least 0 rings), leading to sub-par BO-qEI optimization performance as the unconstrained algorithm extrapolates against the surrogate to find \u201coptimal\u201d molecules that ", "page_idx": 7}, {"type": "text", "text": "Table 1: Constrained Budget $(k=1$ ) Oracle Evaluation Each method proposes a single design that is evaluated using the oracle function to report the final score (higher is better) across 10 random seeds reported as mean $\\pm$ standard deviation. $\\mathcal{D}$ (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean one-shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. \u2217Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022). ", "page_idx": 8}, {"type": "table", "img_path": "3RxcarQFRn/tmp/9ff955bce8f489668ecda557a21aa068358bcbeeb3774d07a6b1a08b7740c1d6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 2: Relaxed Budget $\\!\\!\\!k=128)$ ) Oracle Evaluation Each method now proposes 128 designs that are evaluated using the oracle function, and maximum score out of these 128 designs is reported below (averaged across 10 random seeds and reported as mean $\\pm$ standard deviation). $\\mathcal{D}$ (best) reports the top oracle value in the task dataset. Each of the MBO methods are ranked by their mean $k=128$ -shot oracle score, and the average rank (lower is better) across all eight tasks is reported in the final table column. Bold (Underlined) entries indicate the best (second best) entry in the column. \u2217Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022). ", "page_idx": 8}, {"type": "table", "img_path": "3RxcarQFRn/tmp/cc769bdd08fd4d5cc92f7307f3657129f7be7092d1f9fa8a4129eb9bbbc39c48.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "are out-of-distribution. In contrast, GABO generates a candidate molecule with a long hydrocarbon backbone and no rings, resulting in a penalized logP score of 22.1\u2014greater than the best observed value in the offline dataset for the task. ", "page_idx": 8}, {"type": "text", "text": "Ablation Experiments. Taking inspiration from (Trabucco et al., 2021), it is possible to utilize our SCR algorithm in GABO without dynamically computing $\\alpha$ (and hence the Lagrange multiplier $\\lambda_{,}$ ). To better characterize the utility of aSCR, we ablate Algorithm 1 by treating $\\lambda$ instead as a hand-tunable constant hyperparameter, and test our method using different values of $\\lambda=\\alpha/(1-\\alpha)$ (Table 3). Setting $\\alpha=0$ (i.e., $\\lambda=0$ ) corresponds to na\u00efve BO against the unconstrained surrogate model, while $\\alpha\\,=\\,1$ (i.e., $\\lambda\\rightarrow\\infty.$ ) is equivalent to a WGAN-like policy. Evaluating constant values of $\\alpha$ ranging from 0 to 1, we find that there is no consistently optimal constant value for all eight optimization tasks. In contrast, our method achieves an average rank of 1.9 (2.4) on the top-1 (top-128) evaluation metric, and is one of the top two methods when compared to the ablations for at least five of the eight tasks. These results suggest that the \u2018adaptive\u2019 nature of aSCR is an important component in solving the constrained optimization problem in (7). ", "page_idx": 8}, {"type": "image", "img_path": "3RxcarQFRn/tmp/d26f612d63b80f75db69babc9fd21569fda8272a71442540d10fe50eadd4f497.jpg", "img_caption": ["Figure 2: Penalized LogP Score Maximization Sample Candidate Designs (Left) The molecule with the highest penalized LogP score of 11.3 in the offline dataset. Separately, we show the 100th percentile candidate molecules according to the surrogate objective generated from (Middle) vanilla BO-qEI and (Right) GABO. Teal- (white-) colored atoms are carbon (hydrogen). Non-hydrocarbon atoms are underlined in the SMILES (Weininger, 1988) string representations of the molecules. "], "img_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "3RxcarQFRn/tmp/3c6dda3b81fc5a53456e18bac87c62edb590aef5bef2e41dc23824c4b9dfa499.jpg", "table_caption": ["Table 3: GABO Adaptive SCR Ablation Study One-shot $\\left[k=1\\right]$ ) and few-shot $k=128)$ ) oracle evaluations averaged across 10 random seeds reported as mean $\\pm$ standard deviation. $\\mathcal{D}$ (best) reports the top oracle value in the task dataset. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Of note, the top designs found across different constant values of $\\alpha$ can be very similar for certain tasks. This reflects the inherent challenge in developing task-agnostic methods for policy regularization\u2014if the magnitudes of the unconstrained objective and regularization function vastly differ, then constant values of $\\alpha$ may over- or under- constrain the objective. Adaptive SCR overcomes this problem by dynamically setting $\\alpha$ as an implicit function of prior observations. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We propose adaptive source critic regularization (aSCR) to solve the problem of off-distribution objective evaluation in offline MBO. When leveraged with vanilla Bayesian optimization, aSCR outperforms baseline methods to achieve an average rank of 3.8 (3.0) in one-shot $k=1$ (few-shot $k=128)$ ) oracle evaluation, and most consistently proposes designs better than the offline dataset. ", "page_idx": 9}, {"type": "text", "text": "Limitations. One limitation of aSCR is that our algorithm requires preexisting knowledge of the prior distribution over the input space in order to be computationally tractable. While we have focused our experimental evaluation on tasks amenable to imposed latent space priors, further work is needed to adapt aSCR to any arbitrary configuration space. Future work may also extend aSCR to improve parent optimization methods more sophisticated than BO-qEI and Gradient Ascent explored herein. ", "page_idx": 9}, {"type": "text", "text": "Impact Statement. Offilne policy optimization methods, such as those discussed in this work, have the potential to benefti society. Such examples may include helping develop more effective drugs and individualizing patient therapies. However, as with any real-world algorithm, these methods can also be leveraged to generate potentially harmful design candidates. Careful oversight by domain experts and researchers is required to ensure that the contributions proposed herein are used for social good. ", "page_idx": 9}, {"type": "text", "text": "Funding Disclosure and Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "The authors thank Pratik Chaudhari at the University of Pennsylvania and the anonymous NeurIPS peer reviewers for their thoughtful comments, feedback, and discussion regarding this work. MSY is supported by NIH F30 MD020264. YZ and JRG are supported by NSF award IIS-2145644. JCG is supported by NIH R01 EB031722. OB is supported by NSF Award CCF-1917852. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Aglietti, V., Dhir, N., Gonz\u00e1lez, J., and Damoulas, T. Dynamic causal Bayesian optimization. In Proc NeurIPS, 2022. doi: 10.48550/arXiv.2110.13891.   \nAhn, M., Zhu, H., Hartikainen, K., Ponte, H., Gupta, A., Levine, S., and Kumar, V. ROBEL: Robotics benchmarks for learning with low-cost robots. In Proc Conf Robot Learn, volume 100 of CoRL\u201920, pp. 1300\u20131313. PMLR, 2020.   \nAngermueller, C., Belanger, D., Gane, A., Mariet, Z., Dohan, D., Murphy, K., Colwell, L., and Sculley, D. Population-based black-box optimization for biological sequence design. In Proc Int Conf Mach Learn, volume 119 of ICML\u201920, pp. 324\u201334. PMLR, 2020.   \nArjovsky, M., Chintala, S., and Bottou, L. Wasserstein generative adversarial networks. In Proc Int Conf Mach Learn, volume 70 of ICML\u201917, pp. 214\u201323. PMLR, 2017.   \nAstudillo, R. and Frazier, P. I. Bayesian optimization of composite functions. In Proc Int Conf Mach Learn, volume 97 of ICML\u201917, pp. 354\u201363. PMLR, 2019.   \nBarrera, L. A., Vedenko, A., Kurland, J. V., Rogers, J. M., Gisselbrecht, S. S., Rossin, E. J., Woodard, J., Mariani, L., Kock, K. H., Inukai, S., Siggers, T., Shokri, L., Gord\u00e2n, R., Sahni, N., Cotsapas, C., Hao, T., Yi, S., Kellis, M., Daly, M. J., Vidal, M., Hill, D. E., and Bulyk, M. L. Survey of variation in human transcription factors reveals prevalent DNA binding changes. Science, 351 (6280):1450\u20134, 2016. doi: 10.1126/science.aad2257.   \nBastani, H., Drakopoulos, K., Gupta, V., Vlachogiannis, I., Hadjichristodoulou, C., Lagiou, P., Magiorkinis, G., Paraskevis, D., and Tsiodras, S. Efficient and targeted COVID-19 border testing via reinforcement learning. Nature, 599:108\u201313, 2021. doi: 10.1038/s41586-021-04014-z.   \nBerrevoets, J., Verboven, S., and Verbeke, W. Treatment effect optimisation in dynamic environments. Journal of Causal Inference, 10(1):106\u201322, 2022. doi: 10.1515/jci-2020-0009.   \nBranin, F. H. Widely convergent method for finding multiple solutions of simultaneous nonlinear equations. IBM Journal of Research and Development, 16(5):504\u201322, 1972. doi: 10.1147/rd.165. 0504.   \nBrookes, D., Park, H., and Listgarten, J. Conditioning by adaptive sampling for robust design. In Proc Int Conf Mach Learn, volume 97 of ICML\u201919, pp. 773\u201382. PMLR, 2019.   \nBrown, N., Fiscato, M., Segler, M. H. S., and Vaucher, A. C. GuacaMol: Benchmarking models for de novo molecular design. Journal of Chemical Information and Modeling, 59:1096\u2013108, 2019. doi: 10.1021/acs.jcim.8b00839.   \nChen, C., Zhang, Y., Fu, J., Liu, X., and Coates, M. Bidirectional learning for offline infinite-width model-based optimization. In Proc NeurIPS, 2022. doi: 10.48550/arXiv.2209.07507.   \nChen, M., Zhao, H., Zhao, Y., Fan, H., Gao, H., Yu, Y., and Tian, Z. Romo: Retrieval-enhanced offilne model-based optimization. In Proc International Conf Dist Artif Intell, number 10 in DAI\u201923, pp. 1\u20139. ACM, 2023.   \nChen, Z., Min, M. R., Parthasarathy, S., and Ning, X. A deep generative model for molecule optimization via one fragment modification. Nat Mach Intell, 3:1040\u20139, 2021. doi: 10.1038/ s42256-021-00410-2.   \nConsortium, T. I. W. P. Estimation of the warfarin dose with clinical and pharmacogenetic data. New England Journal of Medicine, 360(8):753\u201364, 2009. doi: 10.1056/NEJMoa0809329.   \nDeshwal, A. and Doppa, J. Combining latent space and structured kernels for Bayesian optimization over combinatorial spaces. In Proc NeurIPS, volume 34, pp. 8185\u2013200, 2021.   \nEriksson, D. and Jankowiak, M. High dimensional Bayesian optimization with sparse axis-aligned subspaces. In Proc Unc Arti Intel, volume 161 of UAI\u201921, pp. 493\u2013503. PMLR, 2021.   \nEriksson, D., Pearce, M., Gardner, J., Turner, R. D., and Poloczek, M. Scalable global optimization via local Bayesian optimization. In Proc NeurIPS, pp. 5496\u2013507, 2019a. doi: 10.48550/arXiv. 1910.01739.   \nEriksson, D., Pearce, M., Gardner, J. R., Turner, R., and Poloczek, M. Scalable global optimization via local Bayesian optimization. In Proc NeurIPS, 2019b. doi: 10.48550/arXiv.1910.01739.   \nErtl, P. and Schuffenhauer, A. Estimation of synthetic accessibility score of drug-like molecules based on molecular complexity and fragment contributions. J Cheminform, 1(8), 2009. doi: 10.1186/1758-2946-1-8.   \nFlam-Shepherd, D., Zhu, K., and Aspuru-Guzik, A. Language models can learn complex molecule distributions. Nature Communications, 13(3293), 2022. doi: 10.1038/s41467-022-30839-x.   \nGaulton, A., Bellis, L. J., Bento, A. P., Chambers, J., Davies, M., Hersey, A., Light, Y., McGlinchey, S., Michalovich, D., Al-Lazikani, B., and Overington, J. P. ChEMBL: A large-scale bioactivity database for drug discovery. Nucleic Acids Res, 40:D1100\u20137, 2012. doi: 10.1093/nar/gkr777.   \nG\u00f3mez-Bombarelli, R., Wei, J. N., Duvenaud, D., Hern\u00e1ndez-Lobato, J. M., S\u00e1nchez-Lengeling, B., Sheberla, D., Aguilera-Iparraguirre, J., Hirzel, T. D., Adams, R. P., and Aspuru-Guzik, A. Automatic chemical design using a data-driven continuous representation of molecules. ACS Central Science, 4:268\u201376, 2018. doi: 10.1021/acscentsci.7b00572.   \nGoodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. Generative adversarial nets. In Proc NeurIPS, pp. 2672\u201380, 2014. doi: 10.48550/arXiv.1406.2661.   \nGu, X., Yang, L., Sun, J., and Xu, Z. Optimal transport-guided conditional score-based diffusion models. In Proc NeurIPS, 2023. doi: 10.48550/arXiv.2311.01226.   \nGuimaraes, G. L., Sanchez-Lengeling, B., Outeiral, C., Farias, P. L. C., and Aspuru-Guzik, A. Objective-reinforced generative adversarial networks (ORGAN) for sequence generation models. arXiv Preprint, 2017. doi: 10.48550/arXiv.1705.10843.   \nHansen, N. and Ostermeier, A. Adapting arbitrary normal mutation distributions in evolution strategies: The covariance matrix adaptation. In Proc IEEE Int Conf on Evolutionary Comp, pp. 312\u20137, 1996. doi: 10.1109/ICEC.1996.542381.   \nHvarfner, C., Hellsten, E. O., and Nardi, L. Vanilla Bayesian optimization performs great in high dimensions. arXiv Preprint, 2024. doi: 10.48550/arXiv.2402.02229.   \nKantorovich, L. and Rubinstein, G. S. On a space of totally additive functions. Vestnik Leningrad. Univ, 13:52\u20139, 1958.   \nKim, C. and Bastani, O. Learning interpretable models with causal guarantees. arXiv Preprint, 2021. doi: 10.48550/arXiv.1901.08576.   \nKim, M., Berto, F., Ahn, S., and Park, J. Bootstrapped training of score-conditioned generator for offline design of biological sequences. In Proc NeurIPS, 2023. doi: 10.48550/arXiv.2306.03111.   \nKingma, D. P. and Welling, M. Auto-encoding variational bayes. arXiv Preprint, 2013. doi: 10.48550/arXiv.1312.6114.   \nKirkpatrick, S., Gelatt, C. D., and Vecchi, M. P. Optimization by simulated annealing. Science, 220 (4598):671\u201380, 1983. doi: 10.1126/science.220.4598.671.   \nKrenn, M., H\u00e4se, F., Nigam, A., Friederick, P., and Aspuru-Guzik, A. Self-referencing embedded strings (selfies): A $100\\%$ robust molecular string representation. Machine Learning: Science and Technology, 1(4):045024, 2020. doi: 10.1088/2632-2153/aba947.   \nKrishnamoorthy, S., Mashkaria, S., and Grover, A. Diffusion models for black-box optimization. In Proc Int Conf Mach Learn, volume 202 of ICML\u201923, pp. 17842\u201357. JMLR, 2023.   \nLiu, D. C. and Nocedal, J. On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45:503\u201328, 1989. doi: 10.1007/BF01589116.   \nMashkaria, S., Krishnamoorthy, S., and Grover, A. Generative pretraining for black-box optimization. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of ICML\u201923, pp. 24173\u201397. JMLR, 2023.   \nMaus, N. T., Jones, H. T., Moore, J. S., Kusner, M. J., Bradshaw, J., and Gardner, J. R. Local latent space Bayesian optimization over structured inputs. In Proc NeurIPS, 2022. doi: 10.48550/arXiv. 2201.11872.   \nMockus, J. The Bayesian approach to global optimization. In System Modeling and Optimization, pp. 473\u2013481. Springer, 1982.   \nNguyen, T., Agrawal, S., and Grover, A. Expt: Synthetic pretraining for few-shot experimental design. In Proc NeurIPS, 2023. doi: 10.48550/arXiv.2310.19961.   \nNyikosa, F. M., Osborne, M. A., and Roberts, S. T. Bayesian optimization for dynamic problems. arXiv Preprint, 2018. doi: 10.48550/arXiv.1803.03432.   \nOsborne, M. A., Garnett, R., and Roberts, S. J. Gaussian processes for global optimization. In Int Conf Learn Intell Opt, pp. 1\u201315, 2009.   \nRamchandani, P., Bastani, H., and Wyatt, E. Unmasking human trafficking risk in commercial sex supply chains with machine learning. Social Science Research Network, 2021. doi: 10.2139/ssrn. 3866259.   \nRao, R., Bhattacharya, N., Thomas, N., Duan, Y., Chen, X., Canny, J., Abbeel, P., and Song, Y. S. Evaluating protein transfer learning with TAPE. In Proc NeurIPS, 2019. doi: 10.48550/arXiv. 1906.08230.   \nSample, P. J., Wang, B., Reid, D. W., Presnyak, V., McFadyen, I. J., Morris, D. R., and Seelig, G. Human 5\u2019UTR design and variant effect prediction from a massively parallel translation study. Nature Biotechnology, 37:803\u20139, 2019. doi: 10.1038/s41587-019-0164-5.   \nSnoek, J., Larochelle, H., and Adams, R. P. Practical Bayesian optimization of machine learning algorithms. In Proc NeurIPS, volume 25, pp. 2951\u20139, 2012. doi: 10.48550/arXiv.1206.2944.   \nSobol, I. M. On the distribution of points in a cube and the approximate evaluation of integrals. Mathematical Physics, 7:86\u2013112, 1967. doi: 10.1016/0041-5553(67)90144-9.   \nSun, S., Cao, Z., Zhu, H., and Zhao, J. A survey of optimization methods from a machine learning perspective. IEEE Transactions on Cybernetics, 50(8):3668\u201381, 2020. doi: 10.1109/TCYB.2019. 2950779.   \nSz\u00e9kely, G. J., Rizzo, M. L., and Bakirov, N. K. Measuring and testing dependence by correlation of distances. Annals of Statistics, 35(6):2769\u201394, 2007. doi: 10.1214/009053607000000505.   \nTodorov, E., Erez, T., and Tassa, Y. MuJoCo: A physics engine for model-based control. In Proc Int Conf Intell Rob Sys, pp. 5026\u201333, 2012. doi: 10.1109/IROS.2012.6386109.   \nTrabucco, B., Kumar, A., Geng, X., and Levine, S. Conservative objective models for effective offilne model-based optimization. In Proc Int Conf Mach Learn, volume 139 of ICML\u201921, pp. 10358\u201368. PMLR, 2021.   \nTrabucco, B., Geng, X., Kumar, A., and Levine, S. Design-Bench: Benchmarks for data-driven offline model-based optimization. In Proc Int Conf Mach Learn, volume 162 of ICML\u201922, pp. 21658\u201376. PMLR, 2022.   \nTripp, A., Daxberger, E., and Hern\u00e1ndez-Lobato, J. M. Sample-efficient optimization in the latent space of deep generative models via weights retraining. In Proc NeurIPS, volume 33, pp. 11259\u201372. Curran Associates, Inc., 2020.   \nTruda, G. and Marais, P. Evaluating warfarin dosing models on multiple datasets with a novel software framework and evoluationary optimisation. J Biomedical Informatics, 113:103634, 2021. doi: 10.1016/j.jbi.2020.103634.   \nWeininger, D. Smiles, A chemical language and information system. J Chem Inf Comput Sci, 28(1): 31\u20136, 1988. doi: 10.1021/ci00057a005.   \nWildman, S. A. and Crippen, G. M. Prediction of physicochemical parameters by atomic contributions. J Chem Inf Comput Sci, 39:868\u201373, 1999.   \nXu, K. and Bastani, H. Multitask learning and bandits via robust statistics. arXiv Preprint, 2023. doi: 10.48550/arXiv.2112.14233.   \nYu, S., Ahn, S., Song, L., and Shin, J. RoMA: Robust model adaptation for offline model-based optimization. In Proc NeurIPS, 2021. doi: 10.48550/arXiv.2110.14188.   \nZhou, Z., Kearnes, S., Li, L., Zare, R. N., and Riley, P. Optimization of molecules via deep reinforcement learning. Scientific Reports, 9(10752), 2019. doi: 10.1038/s41598-019-47148-x. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Additional Implementation Details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Oracle Functions. All oracle functions for the tasks assessed are either exact functions or approximate oracles developed by domain experts. Specifically, the Branin and TF-Bind-8 tasks utilize exact oracles described in detail by Branin (1972) and Barrera et al. (2016), respectively. The oracle for the Penalized LogP task is an approximate oracle from Wildman & Crippen (1999) that is the same oracle used by domain experts in the Guacamol benchmarking study (Brown et al., 2019). The GFP, UTR, and ChEMBL tasks feature approximate oracles from Snoek et al. (2012), Angermueller et al. (2020), and Trabucco et al. (2022), respectively, that were trained on a larger, hidden datasets inaccessible to us for the respective tasks. The D\u2019Kitty morphology task uses a MuJoCo (Todorov et al., 2012) simulation environment and learned control policy from Trabucco et al. (2022) to evaluate proposed designs. Finally, the Warfarin task uses a linear model (Consortium, 2009) to estimate a patient\u2019s optimal warfarin dose given their pharmacogenetic attributes. ", "page_idx": 14}, {"type": "text", "text": "Data Preprocessing. (1) For the Branin task, we sample 1000 points from the square input domain $[-5,10]\\times[0,15]$ to construct the offilne dataset, and remove the top $20\\%$ -ile according to the oracle function to make the task more challenging in line with prior work (Mashkaria et al., 2023). In this continuous task (along with the D\u2019Kitty and Warfarin tasks), we treat input designs as their own latent space mappings, such that the VAE encoder and decoder for this task are both the identity function with zero trainable parameters. (2) The offline dataset of the Penalized LogP task is the validation partition of the Guacamol dataset from Brown et al. (2019), which consists of 79,564 unique molecules and their corresponding penalized LogP scores. The input molecules are represented as SMILES strings (Weininger, 1988), which is a molecule representation format shown to frequently yield invalid molecules in prior work (Krenn et al., 2020). Therefore, we encode the molecules instead as SELFIES strings, an alternative molecule representation from Krenn et al. (2020) with $100\\%$ robustness. ", "page_idx": 14}, {"type": "text", "text": "(3) - (5) The TF-Bind-8, GFP, and UTR tasks are assessed as-released by Design-Bench from Trabucco et al. (2022)\u2014please refer to their work for task-specific descriptions. (6) - (7) In the ChEMBL and D\u2019Kitty tasks, we normalize all objective values $y$ in the offline dataset to $\\hat{y}\\,=$ $(y-y_{\\mathrm{min}})/(y_{\\mathrm{max}}-y_{\\mathrm{min}})$ as done in prior work (Mashkaria et al., 2023), where $\\hat{y}$ is the corresponding normalized objective value and $y_{\\mathrm{min}}\\ (y_{\\mathrm{max}})$ is the minimum (maximum) observed objective value in the full, unobserved dataset. Because only the bottom $60\\%$ -ile ( $40\\%$ -ile) from the full dataset is used in the available offline dataset for the ChEMBL (D\u2019Kitty) task, the respective maximum $\\hat{y}$ values are less than 1.0 (Supplementary Table A1). We also translate the original SMILES string representations in the ChEMBL task into SELFIES strings (Krenn et al., 2020) as in the LogP task. ", "page_idx": 14}, {"type": "text", "text": "(8) Finally, the Warfarin task uses the dataset of pharmacogenetic patient covariates published by Consortium (2009). We split the original dataset of 3,936 unique patient observations into training (validation) partitions with 3,736 (200) datums. The patient attributes in the Warfarin dataset consist of a combination of discrete and continuous values. All discrete attributes are one-hot encoded into binarized dimensions, and continuous values are normalized to zero mean and unit variance using the training dataset. Missing patient values were imputed following prior work (Truda & Marais, 2021). We define the cost $c(z|x)$ accrued by a patient with attributes $x\\in\\mathbb{R}^{32}$ as a function of the input dose $z\\in\\mathbb{R}$ is $c(z|x)=(z-d_{\\mathrm{oracle}}(x))^{2}$ , where $d_{\\mathrm{oracle}}:\\mathbb{R}^{32}\\rightarrow\\mathbb{R}$ is the domain-expert oracle warfarin dose estimator from Consortium (2009). The observed objective values $y$ associated with each of the training datums is calculated as $y=[c(\\bar{z}|x)-c(z|x)]/\\bar{c}(\\bar{z}|x)$ , where $\\bar{z}$ is the mean warfarin dose over the training dataset and $z$ is the true dose given to the patient. Using this constructed offline dataset, our task is then to assign optimal doses to the 200 validation patients to maximize $y$ with no prior warfarin dosing observations. ", "page_idx": 14}, {"type": "text", "text": "B Additional Experimental Results ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we provide additional experimental results that help better characterize both the strengths and limitations of GABO and GAGA. ", "page_idx": 14}, {"type": "text", "text": "B.1 How do sub-optimal design candidates proposed by GABO and GAGA perform? ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To evaluate the robustness of optimization methods, we report one-shot 90th percentile oracle scores in Supplementary Tables B1 and B2. For each method, all proposed designs are ranked according to the surrogate forward model ((8) for Generative Adversarial Bayesian Optimization (GABO) and Generative Adversarial Gradient Ascent (GAGA)), and the single 90th percentile design according to this ranking is selected and evaluated using the oracle function. We report the oracle score of this suboptimal design averaged over 10 seeds. ", "page_idx": 14}, {"type": "table", "img_path": "3RxcarQFRn/tmp/4597fc98a2730b08728b995dd76ece01e930056043fbdfc94b5bf0054fb17fdd.jpg", "table_caption": ["Table A1: MBO Datasets and Tasks Implementation details for each of the seven MBO tasks assessed in our work. \u2217Denotes the life sciences-related discrete MBO tasks offered by the DesignBench benchmarking repository (Trabucco et al., 2022). "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Our results show that GABO and GAGA do not propose suboptimal designs that are better than those proposed by other methods, such as BONET (Mashkaria et al., 2023), Simulated Annealing (Kirkpatrick et al., 1983), L-BFGS (Liu & Nocedal, 1989), and ExPT (Nguyen et al., 2023). This is not surprising, as aSCR is not designed to target this metric (and it is not our primary metric of interest). Separately for GABO, we also hypothesize that the algorithm\u2019s performance according to this metric may partially be explained by the limitations of the underlying Bayesian optimization (BO) optimization algorithm. Because BO is not an iterative first-order algorithm, the designs proposed by any BO-based algorithm often have high variance in practice\u2014this is indeed what we observe across all of our experiments, including in Table 1 and Supplementary Tables B1 and B2. ", "page_idx": 15}, {"type": "text", "text": "Finally, we note that in most applications of offilne optimization, the 90th percentile metric\u2014or any metric that does not use the best proposed design(s)\u2014is not as useful as the other metrics assessed where GABO does perform well. This is because in offilne optimization tasks with a restricted budget to query the hidden, expensive-to-evaluate oracle function, we are not interested in \u201cwasting\u201d this limited budget on subpar design candidates. While the 90th percentile and similar metrics can be helpful to understand the limitations of algorithms (as in this case), we believe that the alternative evaluation metrics reported in the main text\u2014namely, the 100th percentile top-1 and top-128 oracle score metrics\u2014are more useful and practical in assessing each of the optimization algorithms. ", "page_idx": 15}, {"type": "text", "text": "Table B1: Constrained Budget $\\left[k=1\\right]$ ) Suboptimal $90\\%$ -ile) Oracle Evaluation The oracle score of the 90th percentile design candidate according to the surrogate across 10 random seeds is reported as mean $\\pm$ standard deviation. $\\mathcal{D}$ (best) reports the top oracle value in the task dataset. The average rank across all seven tasks is reported in the final table column. Bolded (Underlined) entries indicate the best (second best) entry in the column. \u2217Denotes the life sciences-related discrete MBO tasks from Design-Bench (Trabucco et al., 2022). ", "page_idx": 15}, {"type": "table", "img_path": "3RxcarQFRn/tmp/e1a2047d1ecd4a018198bed3b04eb43620499e640b2341195639a2787e92b47d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "table", "img_path": "3RxcarQFRn/tmp/ae68013ceee3e944da2ade9dd70871fb6d2b8677c3e7708135ac8cf827b80c09.jpg", "table_caption": ["Table B2: GABO Adaptive SCR Ablation Study\u2014Constrained Budget $(k=1)$ ) Suboptimal $(90\\%$ -ile) Oracle Evaluation The oracle score of the 90th percentile design candidate according to the surrogate across 10 random seeds reported as mean $\\pm$ standard deviation. $\\mathcal{D}$ (best) reports the top oracle value in the task dataset. Average method rank across all seven tasks reported in the final column.  Denotes the life sciences-related discrete MBO tasks Design-Bench (Trabucco et al., 2022). "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "To further characterize the distribution of designs and their associated oracle scores proposed by GABO, Figure B1 plots a histogram of the oracle scores of (1) all 2,048 oracle scores, and (2) the oracle scores of the top 256 designs according to the penalized surrogate objective in (8) for the LogP task. Compared with the other optimization methods assessed, we notice that the range of oracle scores is larger for BO-based optimization methods compared with the baseline methods assessed. This helps motivate our design choice to leverage aSCR and Algorithm 1 with BO-qEI, as BO is able to explore a larger region of the design space and is an effective parent optimizer for complex design spaces. Secondly, we also find that the distribution of scores is similar between BO-qEI and GABO, even though the performance of these two methods is remarkably different in Tables 1 and 2. This is likely due to the fact that while BO enables us to explore a larger effective region of the design space (compared with first-order iterative methods), aSCR more accurately ranks proposed designs using the penalized surrogate so that we can identify promising candidates even in the low-budget oracle evaluation regime. ", "page_idx": 16}, {"type": "text", "text": "B.2 Are offline objectives and oracle function values correlated? ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A key component of GABO with Adapative SCR critical to the above discussion in Section B.1 is that generated designs score similarly according to the hidden oracle function and the regularized Lagrangian objective as in (8) in order to solve the problem of surrogate objective overestimation encountered in traditional offline optimization settings (Fig. 1). To assess this quantitatively, we computed the distance covariance $\\dot{\\mathrm{d}}\\mathrm{Cov}_{n}[\\{\\mathcal{L}(\\mathbf{x}_{k};\\lambda^{*})\\}_{k=1}^{n},\\breve{\\{}f(\\mathbf{x}_{k})\\}_{k=1}^{n}]$ between the oracle scores $f(\\mathbf{x}_{k})$ and the constrained Lagrangian scores $\\mathcal{L}(\\mathbf{x}_{k};\\lambda^{*})$ with $\\lambda=\\lambda^{*}(t)$ computed using our Adaptive SCR algorithm. The empirical distance covariance metric is computed over the $n=2048$ design candidates generated using our GABO algorithm. Briefly, the distance covariance is a nonnegative measure of dependence between two vectors which may be related nonlinearly; a greater distance covariance implies a greater degree of association between observations (Sz\u00e9kely et al., 2007). We focus our subsequent discussion on the Penalized LogP task. ", "page_idx": 16}, {"type": "text", "text": "Across five random seeds, GABO with Adaptive SCR achieves a distance covariance score of 0.535 $\\pm\\ 0.067$ (mean $\\pm$ standard deviation). In contrast, na\u00efve BO-qEI (i.e., $\\lambda\\,=\\,0$ ) only achieves a distance covariance score of $0.392\\pm0.040$ . Using $p<0.05$ as a cutoff for statistical significance, the distance covariance scores are significantly different between these two methods $p\\approx0.006$ , unpaired two-tailed $t$ -test). These results help support our conclusion that GABO with Adaptive SCR is able to provide better estimates of design candidate performance according to the hidden oracle function when compared to the corresponding unconstrained BO policy. ", "page_idx": 16}, {"type": "text", "text": "B.3 Is adaptively computing $\\alpha$ in aSCR important for the performance of GAGA? ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In our ablation experiments presented in Table 3, we showed how that \u2018adaptive\u2019 nature of aSCR is an important component in solving the constrained optimization problem in (7) for GABO, and outperforms alternative approaches that manually hand-tune $\\alpha$ (and hence $\\lambda$ ) as a constant hyperparameter. We explore whether this conclusion also applies for GAGA as well here. ", "page_idx": 16}, {"type": "text", "text": "For clarity, we first offer the explicit formulation of GAGA in Supplementary Algorithm 3. We ablate Algorithm 1 in GAGA by instead evaluating our method using different values of $\\lambda\\,=$ $\\alpha/(1-\\bar{\\alpha)}$ . As a reminder, setting $\\alpha=0$ (i.e., $\\lambda=0$ ) corresponds to na\u00efvely performing gradient ascent against the unconstrained surrogate model; setting $\\alpha=1$ (i.e., $\\lambda\\rightarrow\\infty,$ ) is equivalent to a WGAN-like generative policy. ", "page_idx": 16}, {"type": "image", "img_path": "3RxcarQFRn/tmp/3d69efef3ce4fe5ef145cc7a773cc626a48934a8d4126b09ca3a4365c3690a07.jpg", "img_caption": ["Figure B1: Distribution of Oracle Penalized LogP Scores We plot the distribution of oracle scores for the top 128 surrogate model-ranked designs in black, and the distribution for all 2,048 generated designs in light gray for each of the offilne model-based optimization methods assessed in our work across 10 random seeds. While GABO and BO-qEI have similar distributions, GABO is able to more reliably rank top-performing designs higher, such that these designs can be identified even under limited oracle query budgets. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Algorithm 3 Generative Adversarial Gradient Ascent (GAGA) ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Input: surrogate objective $f_{\\theta}\\,:\\,\\mathbb{R}^{d}\\,\\rightarrow\\,\\mathbb{R}$ , offline dataset ${\\cal D}_{n}\\;=\\;\\{z_{j}^{\\prime}\\}_{j=1}^{n}$ , iterative sampling budget $T$ ,   \nsampling batch size $b$ , number of generator steps per source critic training ngenerator, oracle query budget $k$ ,   \nstep size $\\eta$   \nAdaptiveSCR Input: $\\alpha$ step size $\\Delta\\alpha$ , search budget $\\boldsymbol{\\mathbf{\\rho}}_{\\perp}$ , norm threshold $\\tau$   \nDefine: Differentiable source critic $c:\\mathbb{R}^{d}\\rightarrow\\mathbb{R}$   \nDefine: Lagrangian $\\begin{array}{r}{\\mathcal{L}(z;\\alpha):\\mathbb{R}^{d}\\times\\mathbb{R}\\to\\mathbb{R}=-f_{\\theta}(z)+\\frac{\\alpha}{1-\\alpha}[\\mathbb{E}_{z^{\\prime}\\sim\\mathcal{D}_{n}}[c(z^{\\prime})]-c(z)]}\\end{array}$ // Eq. (8)   \nSample $\\mathcal{Z}^{1}\\gets\\{z_{i}^{1}\\}_{i=1}^{b}$ as the top $b$ designs in $\\mathcal{D}_{n}$ according to their previously observed oracle scores   \n$//$ Train the source critic per Eq. (6) to optimality:   \n$c\\gets\\mathrm{argmax}_{||c||_{L}\\leq K}W_{1}\\dot{(}\\mathcal{D}_{n},\\dot{\\mathcal{Z}}^{1})=\\mathrm{ar\\\"{gmax}}_{||c||_{L}\\leq K}\\left[\\mathbb{E}_{z^{\\prime}\\sim\\mathcal{D}_{n}}[c(z^{\\prime})]-\\mathbb{E}_{z\\sim\\mathcal{Z}^{1}}[c(z)]\\right]$   \n$\\alpha\\gets$ AdaptiveSCR $(f_{\\theta},c,D_{n},\\Delta\\alpha,B,\\tau)$ // Alg. (1)   \nEvaluate candidates $\\mathcal{V}^{1}\\gets\\{y_{i}^{1}\\}_{i=1}^{b}=\\{-\\mathcal{L}(z_{i}^{1};\\alpha)\\}_{i=1}^{b}$   \nfor $t$ in $2,3,\\ldots,T$ do $\\mathcal{Z}^{t}\\gets\\{z_{i}^{t}\\}_{i=1}^{b}=\\{z_{i}^{t-1}-\\eta\\nabla_{z_{i}^{t-1}}\\mathcal{L}(z_{i}^{t-1};\\alpha)\\}_{i=1}^{b}$ $\\alpha\\gets\\mathbf{AdaptiveSCR}(f_{\\theta},c,\\mathcal{D}_{n},\\Delta\\alpha,\\mathcal{B},\\tau)$ Evaluate samples $\\mathcal{V}^{t}\\leftarrow\\{y_{i}^{t}\\}_{i=1}^{b}=\\{-\\mathcal{L}(z_{i}^{t};\\alpha)\\}_{i=1}^{b}$ if $t$ mod $n_{\\mathrm{generator}}$ equals 0 then $//$ Train the source critic per Eq. (6) to optimality: $c\\gets\\mathrm{argmax}_{||c||_{L}\\leq K}W_{1}\\dot{(}\\mathcal{D}_{n},\\dot{\\mathcal{Z}}^{t})=\\mathrm{ar}\\dot{\\mathrm{gmax}}_{||c||_{L}\\leq K}\\left[\\mathbb{E}_{z^{\\prime}\\sim\\mathcal{D}_{n}}[c(z^{\\prime})]-\\mathbb{E}_{z\\sim\\mathcal{Z}^{t}}[c(z)]\\right]$ end if   \nend for   \nreturn the top $k$ samples from the $T\\times b$ observations $\\mathcal{D}_{T}=\\{\\{(z_{i}^{m},y_{i}^{m})\\}_{i=1}^{b}\\}_{m=1}^{T}$ according to $y_{i}^{m}$ ", "page_idx": 18}, {"type": "text", "text": "Our results are shown in Supplementary Table B3: similar to the analogous ablation results for GABO in Table 3, dynamically adjusting the strength of source critic regularization using our aSCR algorithm outperforms manually setting the value of $\\alpha$ to a constant in both the one-shot $k=1$ and few-shot $k=128$ evaluation settings. ", "page_idx": 18}, {"type": "text", "text": "B.4 What is the impact of dynamic updates to the source critic over the optimization trajectory? ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In Algorithm 2 and Supplementary Algorithm 3, we describe how generative adversarial optimization alternates between batched acquisition steps according to the optimizer and re-training the source critic on the newly sampled trajectory points. To better interrogate the significance of dynamically re-training the source critic during optimization, we compare the performance of the default GABO and GAGA algorithms (with $n_{\\mathrm{generator}}=4$ as the number of acquisition steps per critic retraining step) against the respective methods without source critic re-training (i.e., $n_{\\mathrm{generator}}=\\infty)$ ) in Supplementary Table B4. Across all three evaluation metrics and all eight tasks, dynamically retraining the source-critic improves upon the performance of the GABO when $n_{\\mathrm{generator}}=\\infty$ by $67.4\\%$ in the top-1 evaluation metric; $0.0\\%$ in the top-128 evaluation metric; and $33.5\\bar{\\%}$ in the $90\\%$ -ile evaluation metric. Intuitively, these results align with the value of the source critic in being able to implicitly set the value of the regularization strength $\\alpha$ in (8) according to the sampled trajectory points\u2014especially in the constrained budget oracle evaluation setting. ", "page_idx": 18}, {"type": "text", "text": "Interestingly, we do not observe similar performance improvements with dynamic re-training of the source critic in GAGA. Qualitatively, we find that this is because of the iterative first-order nature of the parent gradient ascent algorithm\u2014because the sampled designs are clustered in the same regions of the design space over the course of optimization, the energy landscape of the penalized surrogate (i.e., the negative of the Lagrangian expression in (8)) does not change significantly during source critic re-training. This further reinforces the optimizer to stay roughly in the same regions of the design space. As a result, it is likely that no major updates are often made to the source critic when aSCR is used in conjunction with a first-order optimization method, and so the benefit of using a finite ngenerator hyperparameter value is largely reduced when compared to its utility in GABO. ", "page_idx": 18}, {"type": "text", "text": "Table B3: GAGA Adaptive ACR Ablation Study We ablate the dynamic computation of $\\alpha$ (and hence $\\lambda$ in (8)) by instead choosing to manually fix $\\alpha$ to a constant value. A value of $\\alpha\\,=\\,0.0$ corresponds to na\u00efve gradient ascent, and a value of $\\alpha=1.0$ corresponds to a WGAN-like generative policy. Oracle values are averaged across 10 random seeds and reported as mean $\\pm$ standard deviation. In each evaluation setting, we rank all 2,048 proposed designs according to the penalized surrogate forward model in (8) and evaluate the top $k$ designs using the oracle function, reporting the maximum out of the $k$ oracle values. In the suboptimal evaluation setting, we report the oracle score of the single 90th percentile design according to the penalized surrogate ranking. Bold (Underlined) entries indicate the best (second best) entry in the column for the particular evaluation metric. \u2217Denotes the life sciences MBO tasks offered by Design-Bench (Trabucco et al., 2022). ", "page_idx": 19}, {"type": "table", "img_path": "3RxcarQFRn/tmp/363381c3064b02efc825ee02ccef6dce9d7f11549529a3d1dd63c2ec7c770f24.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "B.5 How does initialization affect the performance of GABO? ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Per Algorithm 2, GABO is based on the BO-qEI baseline optimization policy, which involves initializing the gaussian process (GP) to approximate the offline surrogate model. Consistent with prior work (Eriksson et al., 2019a; Maus et al., 2022), we initialize the GP using the pseudo-random Sobol sequence (Sobol, 1967) at the beginning of the optimization procedure. However, an alternative approach is to instead initialize the GP using the top $n_{\\mathrm{init}}$ samples from the offilne dataset. In particular, this strategy is already employed in both related work describing the baseline first-order optimization methods assessed herein, with the idea that better designs can be generated by initializing from better designs. We compare these two GP initialization strategies in Supplementary Table B5. ", "page_idx": 19}, {"type": "text", "text": "Interestingly, our results show that initializing the GABO GP from the Sobol sequence consistently outperforms initialization from the top candidates in offline dataset. We hypothesize that this may be due to the fact that top-scoring candidates likely lie in similar regions of the input space, which significantly alters the ability of the optimizer to explore other regions of the design space over the course of the optimization process. Future work may help better interrogate the relationship between GP initialization and offline optimization, which is outside the scope of this work. ", "page_idx": 19}, {"type": "text", "text": "B.6 Can the Gaussian process (GP) in GABO be directly used as the surrogate forward model? ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In Algorithm 2, we leverage a surrogate forward model $f_{\\theta}$ in model-based optimization and a separate GP to acquire samples in the Bayesian optimization framework. However, it may be possible to use the GP directly as the surrogate forward model. Our results in Supplementary Table B6 suggest that this is not an effective strategy with which to use GABO\u2014using even the simple neural-network as the surrogate function (as done in our approach in Algorithm 2) outperforms the alternative GP-based ", "page_idx": 19}, {"type": "text", "text": "Table B4: Ablating Dynamic Updates to the Source Critic We study the effect of training the source critic model exactly once (i.e., setting $n_{\\mathrm{generator}}=\\infty$ in Algorithm 2 and Supplementary Algorithm 3) as opposed to re-training the source critic model every $n_{\\mathrm{generator}}=4$ acquisition steps on the newly sampled designs. Oracle values are averaged across 10 random seeds and reported as mean $\\pm$ standard deviation. In each evaluation setting, we rank all 2,048 proposed designs according to the penalized surrogate forward model in (8) and evaluate the top $k$ designs using the oracle function, reporting the maximum out of the $k$ oracle values. In the suboptimal evaluation setting, we report the oracle score of the single 90th percentile design according to the penalized surrogate ranking. Bold entries indicate the best entry in the column for the particular optimizer and evaluation metric. \u2217Denotes the life sciences MBO tasks offered by Design-Bench (Trabucco et al., 2022). ", "page_idx": 20}, {"type": "table", "img_path": "3RxcarQFRn/tmp/230505b4fab74d875645ebf997f5ec0338bc654f42e0c81414e9c3def4208f0d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "approach in six of the eight tasks in the top-1 evaluation setting, and is non-inferior to the alternative GP-based approach in all eight tasks in the top-128 evaluation setting. These results suggest that using a more complex neural-network surrogate function for GABO leads to better optimization results than directly using the GP as the surrogate function. ", "page_idx": 20}, {"type": "text", "text": "B.7 What is the computational cost of running aSCR (i.e., Algorithm 1)? ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "At first glance, Adaptive SCR may appear to be a computationally expensive algorithm: it requires us to dynamically re-train a source critic neural network and compute the Lagrangian hyperparameter at each step through a grid search. However, in the implementation used for our experiments, the grid search to compute $\\alpha$ is highly vectorized, and the source critic re-training patience and learning rate are such that the computational cost from re-training is not too significant. As a result, we are able to run Adaptive SCR with both Bayesian Optimization (BO) and Gradient Ascent (GA) using an experimental setup with one 24-core Intel Xeon CPU and one NVIDIA RTX A6000 GPU. To benchmark our implementation, we evaluate BO and GA both with and without our Generative Adversarial (GA) source critic regularization algorithm on the Branin and Penalized LogP optimization tasks. As a reminder, the Branin task is a standard benchmarking task for offilne optimization, and the Penalized LogP task is subjectively the most challenging task assessed in our manuscript with the highest dimensional design space out of the eight assessed tasks. ", "page_idx": 20}, {"type": "text", "text": "Our results are shown in Supplementary Table B7. On the Branin toy task, aSCR increases the compute time by $257\\%$ for BO and $680\\%$ for GA, which is a significant computational cost. However, on the more challenging LogP task more representative of the tasks encountered in the applications of offline optimization, aSCR only introduces a $6.9\\%$ increase in compute time for GA and $28.9\\%$ ", "page_idx": 20}, {"type": "text", "text": "Table B5: GABO GP Initialization Ablation Study We investigate the effect of initializing the Gaussian process (GP) in GABO using the best $n_{\\mathrm{init}}$ points from the offline dataset (i.e., Best initialization strategy) versus our method in Algorithm 2 where the GP is initialized using the first $n_{\\mathrm{init}}$ points from the Sobol sequence from (Sobol, 1967) (i.e., Sobol initialization strategy). Oracle values are averaged across 10 random seeds and reported as mean $\\pm$ standard deviation. In each evaluation setting, we rank all 2,048 proposed designs according to the penalized surrogate forward model in (8) and evaluate the top $k$ designs using the oracle function, reporting the maximum out of the $k$ oracle values. In the suboptimal evaluation setting, we report the oracle score of the single 90th percentile design according to the penalized surrogate ranking. Bold entries indicate the best entry in the column for the particular optimizer and evaluation metric. \u2217Denotes the life sciences MBO tasks offered by Design-Bench (Trabucco et al., 2022). ", "page_idx": 21}, {"type": "table", "img_path": "3RxcarQFRn/tmp/a7604df63f578c509e7da719e065fb76a8876e183e5b2c742fabe120f7b5348d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "Table B6: GABO Neural Network Surrogate Ablation Study Instead of using a neural network (NN) as our surrogate forward model, we explore if the Gaussian process (GP) employed by the parent BO optimizer can directly be used as the surrogate model in GABO\u2019s framwork. Oracle values are averaged across 10 random seeds and reported as mean $\\pm$ standard deviation. In each evaluation setting, we rank all 2,048 proposed designs according to the penalized surrogate forward model in (8) and evaluate the top $k$ designs using the oracle function, reporting the maximum out of the $k$ oracle values. In the suboptimal evaluation setting, we report the oracle score of the single 90th percentile design according to the penalized surrogate ranking. Bold entries indicate the best entry in the column for the particular optimizer and evaluation metric. \u2217Denotes the life sciences MBO tasks offered by Design-Bench (Trabucco et al., 2022). ", "page_idx": 21}, {"type": "table", "img_path": "3RxcarQFRn/tmp/0c0c1e6fa383edf8122361c36a4ea5a78c4a5a29ee868b8e9dec81e675099804.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "increase for BO. Furthermore, while there are evidently additional compute costs associated with running our aSCR algorithm, we note that in most applications of offline optimization, obtaining labeled data is the main bottleneck in many practical applications. Thus, it is often worth spending this extra compute to ensure the best results for a given evaluation budget using aSCR. ", "page_idx": 21}, {"type": "text", "text": "B.8 How do the performance of GABO and other optimization methods vary with the allowed oracle query budget $k$ ? ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "To investigate this question, we vary the number of allowed $k$ -shot oracle calls in the Penalized LogP task (Supplementary Fig. B2). While the majority of first-order optimization methods we evaluated are able to reach local optima rapidly, the proposed designs from such approaches are suboptimal compared to those from GABO (and GAGA) with Adaptive SCR as the oracle query budget size increases. Separately, comparing the curves for GABO and vanilla BO-qEI, we see that GABO with Adaptive SCR is able to propose consistently superior design candidates in the small query budget regime often encountered in real-world settings. This is due to the fact that GABO regularizes the surrogate function estimates such that the proposed candidates are both high-scoring according to the surrogate objective and relatively in-distribution. Our results demonstrate that especially for real-world tasks like molecule design with complex objective function landscapes, methods such as GABO with Adaptive SCR are able to explore diverse, high-performing design candidates effectively even in the setting of small oracle query budgets. ", "page_idx": 21}, {"type": "table", "img_path": "3RxcarQFRn/tmp/507d69ed7efd1f97ef278af7bca486aab479e5bc16de9ebb0c3b946612145af2.jpg", "table_caption": ["Table B7: Computational Tractability Runtimes on a single node using one NVIDIA RTX A6000 GPU are averaged across 10 random seeds and reported as mean $\\pm$ standard deviation. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "image", "img_path": "3RxcarQFRn/tmp/56df614a7c3b6a63d8dc971096d3a02570834e8f0c7f6475da5a809c8caba33e.jpg", "img_caption": ["Figure B2: 100th Percentile Oracle Scores versus $k$ -Shot Oracle Budget Size We plot the 100th percentile oracle Penalized LogP score averaged across 10 random seeds as a function of the number of allowed oracle calls $k$ . "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "B.9 Is the optimization budget sufficient for optimization convergence? ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "For all of our experimental results, we restrict the surrogate query budget to a total of 2048 allowed offline surrogate model queries in order to ensure a fair comparison between different optimization methods. To ensure that such a budget is sufficient for optimizer convergence across different optimization methods, we plot the best achieved oracle Penalized LogP value (i.e., assuming an unlimited oracle evaluation budget) as a function of the number of optimizer surrogate queries (Supplementary Fig. B3) for the Penalized LogP task. These results show that our methods are indeed able to converge over the course of the optimization trajectory. ", "page_idx": 22}, {"type": "image", "img_path": "3RxcarQFRn/tmp/dd6d4301dd96d2e1af2f57482b92de103a6b443d4c83534eee17bc123399de11.jpg", "img_caption": ["Figure B3: Best Oracle Penalized LogP Value versus Optimization Step Count We plot the best Penalized LogP score averaged across 10 random seeds as a function of the number of surrogate queries made over the optimization trajectory. All offilne model-based optimization (MBO) methods assessed consistently converge within the allowed oracle query budget used in our experimental setup as described in Section 5.1. ", ""], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: The main claims made in the abstract and introduction are supported by the experimental results presented. The introduction includes the contributions made in the paper, and important assumptions and limitations are included where relevant. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Please see Section 6 in the main text for a focused \u2018Limitations\u2019 section and relevant discussion. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper does not include theoretical results. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The paper fully discloses all the relevant information needed to reproduce all reported experimental results of the paper. We have made our code required to reproduce our experimental results available in the Supplementary Material ZIP file. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: All data and code associated with this paper is open access and includes sufficient instructions to faithfully reproduce the experimental results reported herein. We have made the data and code available in the Supplementary Material ZIP file. The public link to the GitHub repository containing the code will be included in the Abstract in the final version (currently not linked so as to comply with double-blind review). All datasets used herein are publicly available without any limitations in public accessibility. Our data and code adhere to the NeurIPS code and data submission guidelines. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: The experimental setting is clearly described in Section 5.2 and Appendix A, and is also reproducible via the code released alongside the paper in the Supplementary Material ZIP file. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: All statistics and results included in the paper are accompanied by confidence intervals. We clearly describe the factors of variability in the confidence intervals in Section 5.2 and Appendix A. All additional details are included in relevant table captions. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Information for the resources required to reproduce the experiments are included in Section 5.2 in the main paper. More specifically, all experiments were performed on a single internal cluster with 8 NVIDIA RTX A6000 GPUs. Any particular experimental configuration required no more than 24 hours to complete using our setup. The full research project did not require more compute than the experiments reported in the paper. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The authors have reviewed the NeurIPS Code of Ethics and assert that the research described herein conforms with the Code of Ethics in every respect. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: Please see the conclusion (i.e. Section 6) in the main text for a focused \u2018Impact Statement\u2019 subsection and relevant discussion on the potential societal impacts of our work. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: Our paper does not introduce any assets that have a high risk for misuse. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The only existing assets used in the paper are the seven MBO datasets used for experimental evaluation as described in Section 5.1. All of the relevant datasets are publicly available, and the references for each of the datasets are cited in the aforementioned section. The licenses associated with each of the seven datasets made available in each of the relevant citations are properly respected. There are no restrictions with respect to accessing any of the datasets used in the paper. No scraped data was used in this paper. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: The only asset introduced in and released alongside the paper is the experimental code to reproduce the reported results. The repository containing the code is included in the Supplementary Material ZIP flie. All datasets used for the experiments discussed herein are publicly available and available online via the appropriate references in this paper and via online links included in the Supplementary Material ZIP file. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The research described herein does not involve crowdsourcing or research with human subjects. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. ", "page_idx": 29}, {"type": "text", "text": "\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The research described herein does not involve crowdsourcing or research with human subjects. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]