[{"figure_path": "kOMrm4ZJ3m/tables/tables_5_1.jpg", "caption": "Table 1: SMT and SOS timeout and error rates, benchmarked on correct Lyapunov functions.", "description": "This table presents the performance of SMT and SOS solvers in verifying the correctness of Lyapunov functions.  It shows the percentage of correct Lyapunov functions identified within 10 and 60 minute time limits, as well as the percentage of solver timeouts and incorrect Lyapunov function identifications. The results highlight the trade-off between time constraints and accuracy in verifying Lyapunov functions using these solvers.", "section": "Experimental settings"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_6_1.jpg", "caption": "Table 2: In-domain accuracy of models. Beam size (bs) 1 and 50.", "description": "This table presents the in-domain accuracy results of the trained models.  In-domain accuracy refers to how well the models perform on data from the same dataset they were trained on.  The table shows the accuracy for two beam sizes (1 and 50), with beam size 50 allowing the model to provide multiple possible solutions.  Two backward datasets (BPoly and BNonPoly) and two forward datasets (FBarr and Flyap) are included, showcasing performance differences across different model types and data sources.", "section": "5.1 In and out-of-distribution accuracy"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_7_1.jpg", "caption": "Table 3: Out-of-domain accuracy of models. Beam size 50. Columns are the test sets.", "description": "This table presents the out-of-distribution accuracy results of the models trained on the backward datasets when tested on the forward datasets and vice versa.  It demonstrates the models' ability to generalize beyond the datasets used for training.  The lower accuracy on some cross-dataset tests highlights challenges in generalizing across differing distributions of Lyapunov functions and system types.", "section": "5.1 In and out-of-distribution accuracy"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_7_2.jpg", "caption": "Table 4: Mixing backward data (BPoly) with a small number of forward examples. Beam size 50.", "description": "This table presents the results of experiments where a small number of forward-generated examples are added to the backward-generated training data (BPoly).  It shows how the addition of examples from either the FBarr (barrier functions) or FLyap (Lyapunov functions) datasets affects the model's accuracy on the held-out test sets (FLyap and FBarr).  The beam size used for the model was 50.", "section": "5.2 Enriching training distributions for improved performance"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_7_3.jpg", "caption": "Table 5: Performance comparison on different test sets. Beam size 50. PolyMixture is BPoly + 300 FBarr.", "description": "This table compares the performance of different methods for discovering Lyapunov functions on various test sets.  It shows the accuracy of SOSTOOLS, findlyap (a Python implementation of SOSTOOLS), three AI-based methods (Fossil 2, ANLC, LyzNet), and the authors' models (PolyMixture, FBarr, FLyap, BPoly).  The test sets represent different types of systems (polynomial and non-polynomial) and Lyapunov functions (general and barrier functions). PolyMixture represents a model enhanced with additional training data.", "section": "5.3 Comparing with state-of-the-art baselines"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_8_1.jpg", "caption": "Table 6: Discovering Lyapunov comparison for random systems. Beam size 50. PolyM is BPoly + 300 FBarr. NonPolyM is BNonPoly + BPoly + 300 FBarr.", "description": "This table presents the percentage of correct solutions found by different models on three datasets of random systems: polynomial systems with 2 or 3 equations (Poly3), polynomial systems with 2 to 5 equations (Poly5), and non-polynomial systems with 2 or 3 equations (NonPoly).  It compares the performance of SOSTOOLS, other AI methods (Fossil 2, ANLC, LyzNet), and the authors' models (FBarr, PolyM, NonPolyM).  The results demonstrate that the authors' models trained on generated datasets can discover unknown Lyapunov functions.", "section": "5.4 Into the wild - discovering new mathematics"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_9_1.jpg", "caption": "Table 7: Expert iteration using IntoTheWild correct guesses. The Poly3 and Poly5 test sets are regenerated, to prevent data contamination.", "description": "This table presents the results of an expert iteration process, where newly solved problems (from the FIntoTheWild set) are added to the model's training data.  It shows the performance (accuracy) of different strategies, comparing in-domain (FBarr, FLyap) and out-of-distribution (Poly3, Poly5) results after fine-tuning.  The strategies vary in the number and type of additional examples added. The goal is to evaluate the impact of incorporating real-world problem solutions on the model's ability to solve similar problems.", "section": "5.5 Expert iteration"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_17_1.jpg", "caption": "Table 8: Datasets generated. Backward systems are degree 2 to 5, forward systems degree 2 to 3. All forward systems are polynomial.", "description": "This table lists the five datasets used in the paper's experiments.  It shows the dataset name, a description of the dataset contents (whether it contains backward-generated or forward-generated samples, and whether the Lyapunov functions are polynomial or not), the size of the dataset in thousands of samples, and the approximate CPU hours required for generation.", "section": "4.3 Datasets"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_17_2.jpg", "caption": "Table 9: In-domain and out-of-domain accuracy of models. Beam size 50.", "description": "This table presents the in-domain and out-of-domain accuracy of models trained on the backward BPoly dataset of size 1 million, varying the multigen parameter. The multigen parameter controls the number of different systems generated per Lyapunov function.  The table shows that generating a moderate amount of different systems with the same Lyapunov function improves the model's ability to generalize out-of-domain. However, above a certain threshold, the performance starts to decrease.", "section": "C.1 Impact of multigeneration"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_18_1.jpg", "caption": "Table 3: Out-of-domain accuracy of models. Beam size 50. Columns are the test sets.", "description": "This table shows the out-of-distribution (OOD) accuracy of models trained on different datasets.  The rows represent the training datasets (backward datasets: BPoly, BNonPoly; forward datasets: FBarr, FLyap), and the columns represent the test datasets. The high accuracy of backward models on forward test sets and vice versa demonstrates their ability to generalize across different data distributions. The lower accuracy of forward models on backward datasets suggests that the forward training data is less diverse.", "section": "5 Results"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_18_2.jpg", "caption": "Table 11: Performance of mixing backward data (BPoly) with a small number of forward examples on forward benchmark and \\\"into the wild\\\" . Beam size 50.", "description": "This table shows the impact of adding a small number of forward examples to the training data of backward models. It demonstrates how adding just 300 examples from the FBarr dataset to the BPoly training data significantly boosts performance on the FBarr and FLyap datasets.  The results are shown for both the forward benchmark and out-of-distribution \\\"into the wild\\\" tests, demonstrating improved generalization.", "section": "5.2 Enriching training distributions for improved performance"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_18_3.jpg", "caption": "Table 6: Discovering Lyapunov comparison for random systems. Beam size 50. PolyM is BPoly + 300 FBarr. NonPolyM is BNonPoly + BPoly + 300 FBarr.", "description": "This table presents the percentage of correct solutions found by different models on three datasets of random systems: polynomial systems with 2 or 3 equations (Poly3), polynomial systems with 2 to 5 equations (Poly5), and non-polynomial systems with 2 or 3 equations (NonPoly).  It compares the performance of SOSTOOLS, other AI-based methods, and two transformer-based models (FBarr and PolyM/NonPolyM) in discovering Lyapunov functions for these randomly generated systems. The results show that the transformer-based models significantly outperform the other methods, especially on the non-polynomial dataset.", "section": "5.4 Into the wild - discovering new mathematics"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_18_4.jpg", "caption": "Table 1: SMT and SOS timeout and error rates, benchmarked on correct Lyapunov functions.", "description": "This table presents the performance of SMT and SOS solvers in verifying the correctness of Lyapunov functions.  It shows the percentage of correct Lyapunov functions, the percentage of timeouts, and the percentage of incorrect Lyapunov functions identified by the solvers.  The results are broken down based on the time allocated to each solver (10 and 60 minutes). The table provides insights into the reliability and efficiency of the different solvers in evaluating Lyapunov functions.", "section": "4.2 Forward generation"}, {"figure_path": "kOMrm4ZJ3m/tables/tables_20_1.jpg", "caption": "Table 14: Some additional examples generated from our models.", "description": "This table presents four examples of systems (left column) and their corresponding Lyapunov functions (right column) discovered by the model.  Each system is a set of differential equations, and the Lyapunov function is a scalar function that helps demonstrate the stability of the system.", "section": "F Other examples"}]