[{"figure_path": "gkOzoHBXUw/figures/figures_1_1.jpg", "caption": "Figure 1: Test loss of FlexLoRA and FedIT [43] across communication rounds under LORA ranks of 1, 8, and 200. FlexLORA demonstrates adaptability in an \u201cextreme heavy tail\u201d scenario and increasingly aligns with the performance of FedIT at the highest LORA rank as rounds progress. Implementation details are in Appendix A.", "description": "This figure compares the test loss of FlexLoRA and FedIT (a baseline federated learning method) across different communication rounds.  Three different LoRA ranks (1, 8, and 200) are used for both methods. The graph shows that FlexLoRA demonstrates adaptability even in scenarios with highly imbalanced client resources (extreme heavy tail), where the majority of clients have a high LoRA rank, while a few have a low rank.  As the number of communication rounds increases, FlexLoRA's performance gets closer to FedIT's performance at the highest LoRA rank (200).", "section": "3.2 Aggregation with Heterogeneous Ranks"}, {"figure_path": "gkOzoHBXUw/figures/figures_1_2.jpg", "caption": "Figure 2: Illustration of FlexLoRA. The server initially constructs a full-size LoRA weight, which is then averaged across client-contributed weights with different ranks. The aggregated global weights are decoupled via SVD and sent back to clients.", "description": "This figure illustrates the FlexLoRA aggregation scheme.  The server side first averages the local LoRA weights from multiple clients, each with potentially different ranks (r1 < r2 < ... < rj).  These local weights are obtained after individual clients perform local training with their own data and tasks (Translation, Sentiment Analysis, Q&A are shown as examples). Then, a full-size LoRA weight is synthesized from these averaged weights. This full-size LoRA is then decomposed using Singular Value Decomposition (SVD) before being distributed back to each client to update their local models. The difference in local rank is used to balance the trade-off between task-specific optimization and generalization.  This allows clients with more resources to contribute more broadly generalized knowledge.", "section": "3 Methodology of FlexLoRA"}, {"figure_path": "gkOzoHBXUw/figures/figures_5_1.jpg", "caption": "Figure 3: Heterogeneous resource distributions containing different ratios of various LoRA configuration types.", "description": "This figure illustrates the composition of heterogeneous resource distributions used in the experiments. Four types of LoRA configurations (Type 1 to Type 4) with different numbers of parameters are considered.  The bars show the proportion of each LoRA configuration type in four different resource distribution scenarios: Uniform, Heavy-tail-light, Heavy-tail-strong, and Normal.  The uniform distribution has equal proportions of all four types. The heavy-tail distributions have a larger proportion of either Type 1 or Type 4, reflecting the scenario where many clients have limited or abundant resources respectively. The Normal distribution has a dominant proportion of Type 2 and Type 3, indicating a more balanced distribution of client resources.", "section": "4.1 Setup for Cross-Device FL Environments"}, {"figure_path": "gkOzoHBXUw/figures/figures_6_1.jpg", "caption": "Figure 1: Test loss of FlexLoRA and FedIT [43] across communication rounds under LORA ranks of 1, 8, and 200. FlexLORA demonstrates adaptability in an \u201cextreme heavy tail\u201d scenario and increasingly aligns with the performance of FedIT at the highest LORA rank as rounds progress. Implementation details are in Appendix A.", "description": "This figure displays the test loss curves for FlexLoRA and FedIT across multiple communication rounds, under varying LoRA ranks (1, 8, and 200). It highlights FlexLoRA's adaptability, especially in scenarios with highly heterogeneous resource distribution (heavy-tail), where it gradually converges to the performance of FedIT at the largest rank.", "section": "3.2 Aggregation with Heterogeneous Ranks"}, {"figure_path": "gkOzoHBXUw/figures/figures_7_1.jpg", "caption": "Figure 1: Test loss of FlexLoRA and FedIT [43] across communication rounds under LORA ranks of 1, 8, and 200. FlexLORA demonstrates adaptability in an \u201cextreme heavy tail\u201d scenario and increasingly aligns with the performance of FedIT at the highest LORA rank as rounds progress. Implementation details are in Appendix A.", "description": "This figure shows the test loss curves for FlexLoRA and FedIT under different LORA ranks (1, 8, and 200) across multiple communication rounds.  The \"extreme heavy tail\" scenario highlights FlexLoRA's adaptability when dealing with significantly varying client resources (some with very low rank and some with high rank). FlexLoRA's performance improves over time and converges towards the performance of FedIT at a higher LORA rank, illustrating the algorithm's ability to leverage diverse client resources effectively.", "section": "3 Methodology of FlexLoRA"}, {"figure_path": "gkOzoHBXUw/figures/figures_7_2.jpg", "caption": "Figure 1: Test loss of FlexLoRA and FedIT [43] across communication rounds under LORA ranks of 1, 8, and 200. FlexLORA demonstrates adaptability in an \u201cextreme heavy tail\u201d scenario and increasingly aligns with the performance of FedIT at the highest LORA rank as rounds progress. Implementation details are in Appendix A.", "description": "This figure compares the test loss of FlexLoRA and FedIT over communication rounds for different LORA ranks (1, 8, and 200).  It shows that FlexLoRA adapts well even in scenarios with highly unequal client resource distributions (the \"extreme heavy tail\" scenario), performing comparably to FedIT with higher LORA ranks as training progresses.", "section": "3.2 Aggregation with Heterogeneous Ranks"}, {"figure_path": "gkOzoHBXUw/figures/figures_7_3.jpg", "caption": "Figure 6: The sub-figure 6(a) shows that FedIT with LoRA rank 8 has comparable test loss curves for standard and FlexLoRA integration. At rank 200, though, standard FedIT differs from other versions. 6(b) depicts singular value distributions and approximation errors, where the red cross indicates the average error for rank 30 qproj weights in specific blocks. Further details are in Appendix H.", "description": "This figure shows the impact of FlexLoRA on model performance using different LoRA ranks.  In 6(a), the test loss curves for FedIT with and without FlexLoRA are compared at LoRA ranks 8 and 200. The results show similar performance at rank 8 but differing performance at rank 200, highlighting the impact of FlexLoRA. In 6(b), singular value distributions and approximation errors are depicted for qproj weights, demonstrating the impact of using SVD in FlexLoRA for weight decomposition.", "section": "4.5 Aggregation Scheme Study"}, {"figure_path": "gkOzoHBXUw/figures/figures_18_1.jpg", "caption": "Figure 1: Test loss of FlexLoRA and FedIT [43] across communication rounds under LORA ranks of 1, 8, and 200. FlexLORA demonstrates adaptability in an \u201cextreme heavy tail", "description": "The figure shows the test loss curves for FlexLoRA and FedIT under different LoRA ranks (1, 8, and 200) across multiple communication rounds.  It highlights FlexLoRA's adaptability, particularly in scenarios with highly heterogeneous resource distributions (the \"extreme heavy tail\" scenario). As the number of communication rounds increases, FlexLoRA's performance increasingly aligns with that of FedIT at the highest LORA rank. This demonstrates FlexLoRA's ability to effectively leverage heterogeneous client resources.", "section": "3.2 Aggregation with Heterogeneous Ranks"}, {"figure_path": "gkOzoHBXUw/figures/figures_18_2.jpg", "caption": "Figure 8: Distribution of singular values and the approximation error ratio between the top i-th singular value approximated kproj weights and the actual full-rank kproj weights. The red cross denotes the average error for weights with rank 30 of kproj across blocks 1, 8, and 14.", "description": "This figure shows the singular value distribution and approximation error for kproj weights in FlexLoRA with a heavy-tail-strong resource distribution.  It demonstrates that using the top 30 singular values provides a good approximation (error ratio of approximately 0.16).", "section": "4.5 Aggregation Scheme Study"}, {"figure_path": "gkOzoHBXUw/figures/figures_19_1.jpg", "caption": "Figure 1: Test loss of FlexLoRA and FedIT [43] across communication rounds under LORA ranks of 1, 8, and 200. FlexLORA demonstrates adaptability in an \u201cextreme heavy tail", "description": "This figure shows the test loss curves for FlexLoRA and FedIT with different LoRA ranks (1, 8, and 200) across multiple communication rounds.  FlexLoRA adapts well to scenarios with heterogeneous resource distribution (heavy tail scenario), while FedIT's performance is constrained by the lowest LoRA rank among clients. As the number of communication rounds increases, FlexLoRA's performance improves and converges towards that of FedIT at the highest LORA rank.", "section": "3.2 Aggregation with Heterogeneous Ranks"}]