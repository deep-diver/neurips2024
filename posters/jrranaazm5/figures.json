[{"figure_path": "JrraNaaZm5/figures/figures_8_1.jpg", "caption": "Figure 1: The experiments on CelebA64 dataset", "description": "This figure shows the results of three different experiments on the CelebA64 dataset.  The first row (a) displays the target dataset, which contains images of people with bald heads. The second row (b) shows the results when fine-tuning all parameters of the pre-trained model. The third row (c) presents the results of fine-tuning only the encoder and decoder parameters.  The comparison visually demonstrates the superior performance of fine-tuning only the encoder and decoder, resulting in more novel and diverse images of bald individuals compared to fine-tuning all parameters, which struggles to produce significantly different images from the original target set.", "section": "6 Experiments"}, {"figure_path": "JrraNaaZm5/figures/figures_22_1.jpg", "caption": "Figure 2: The experiments on cat face dataset", "description": "This figure shows the results of experiments conducted on a cat face dataset.  The target dataset (a) consists of 10 images of cats with predominantly black fur.  The results of fine-tuning all parameters (b) show that the model struggles to generate novel images, mostly producing variations of the training images. In contrast, the results of fine-tuning only the encoder and decoder (c) show the generation of novel images with the desired feature (predominantly black fur). This illustrates the effectiveness of selectively fine-tuning specific components of the model to avoid overfitting and to produce more diverse, creative outputs.", "section": "6 Experiments"}]