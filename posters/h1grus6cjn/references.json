{"references": [{"fullname_first_author": "Sanjeev Arora", "paper_title": "Implicit regularization in deep matrix factorization", "publication_date": "2019-12-08", "reason": "This paper studies implicit regularization in deep matrix factorization, a topic highly relevant to understanding the implicit bias of optimization in robust ERM."}, {"fullname_first_author": "Pranjal Awasthi", "paper_title": "Adversarial learning guarantees for linear hypotheses and neural networks", "publication_date": "2020-07-13", "reason": "This paper provides generalization bounds for adversarially robust classification for linear models and neural networks, forming a theoretical foundation for the current work."}, {"fullname_first_author": "Suriya Gunasekar", "paper_title": "Implicit regularization in matrix factorization", "publication_date": "2017-12-04", "reason": "This paper investigates implicit regularization in matrix factorization, which is highly relevant to the study of implicit bias in optimization algorithms for robust ERM."}, {"fullname_first_author": "Suriya Gunasekar", "paper_title": "Characterizing implicit bias in terms of optimization geometry", "publication_date": "2018-07-10", "reason": "This paper characterizes the implicit bias of optimization algorithms, specifically gradient descent, which provides valuable insights for understanding the implicit bias in robust ERM."}, {"fullname_first_author": "Ziwei Ji", "paper_title": "Gradient descent aligns the layers of deep linear networks", "publication_date": "2019-05-06", "reason": "This paper analyzes the implicit bias of gradient descent in deep linear networks, which helps in understanding the impact of optimization algorithms on model robustness in the context of adversarial training."}]}