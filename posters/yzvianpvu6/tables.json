[{"figure_path": "yzviAnpvU6/tables/tables_7_1.jpg", "caption": "Table 1: Summary of attack success rate using different zeroth-order optimization methods with the final l2 distortion remains relatively consistent. The result is based on a universal attack against 100 images under T = 20000 iterations.", "description": "This table presents the results of a universal adversarial attack experiment, comparing the performance of ReLIZO against four other zeroth-order optimization methods.  The key metrics compared are the attack success rate (percentage of successful attacks) and the final l2 distortion (the magnitude of the adversarial perturbation).  All methods were run for 20,000 iterations on 100 images from the CIFAR-10 test dataset, with the goal of maintaining similar final l2 distortion across the methods for fair comparison.  The table highlights the superior performance of ReLIZO in achieving a higher attack success rate compared to other methods while keeping the final l2 distortion relatively the same.", "section": "4.3 Experiments on Black-Box Adversarial Attacks"}, {"figure_path": "yzviAnpvU6/tables/tables_8_1.jpg", "caption": "Table 2: Top-1 test classification accuracy (%) on NAS-Bench-201. The first block shows the performance of gradient-based methods quoted from the paper of NAS-Bench-201. The second block shows the performance of various ZO methods, which are implemented by ourselves on the PyTorch platform. The performance of the methods based on ZO optimizers is averaged over three independent trials.", "description": "This table presents the top-1 test classification accuracy results on the NAS-Bench-201 dataset.  It compares the performance of several gradient-based neural architecture search (NAS) methods with several zeroth-order optimization (ZO) methods. The gradient-based results are taken directly from the NAS-Bench-201 paper. The ZO method results were obtained by the authors of this paper using the PyTorch platform.  For the ZO methods, the reported accuracies are averages across three independent trials.", "section": "4.4 Experiments on Neural Architecture Search"}, {"figure_path": "yzviAnpvU6/tables/tables_8_2.jpg", "caption": "Table 3: Number of queries and the search cost (seconds) during the NAS procedure on the search space of NAS-Bench-201.", "description": "This table presents a comparison of the number of queries and the time spent on the neural architecture search (NAS) task using different zeroth-order optimization (ZO) methods.  It shows that the proposed ReLIZO method requires significantly fewer queries and less computation time than the other ZO methods while achieving comparable performance.", "section": "4.4 Experiments on Neural Architecture Search"}, {"figure_path": "yzviAnpvU6/tables/tables_9_1.jpg", "caption": "Table 4: Zero-order optimizers with different parameter efficient fine-tuning methods on OPT-1.3b model (with 1.3 billion parameters) on the Stanford Sentiment Treebank v2 (SST2) task.", "description": "This table presents the results of several zero-order optimization methods and SGD,  applied to fine-tune the OPT-1.3B language model on the SST2 dataset, using four different parameter-efficient fine-tuning techniques: full fine-tuning, LoRA, prefix-tuning, and prompt-tuning.  The table shows the accuracy achieved and memory usage for each method and technique.", "section": "4.5 Experiments on Parameter Efficient Fine-tuning"}, {"figure_path": "yzviAnpvU6/tables/tables_17_1.jpg", "caption": "Table 5: Comparison of computation complexity in one iteration between various ZO methods.", "description": "This table compares the computation complexity of different zeroth-order optimization methods in a single iteration. The complexity is expressed in big O notation and depends on the dimension of variables (d), sample size (n), and the cost of querying function evaluations (c(d)). ReLIZO's complexity is shown to be advantageous when reusing queries from previous iterations (nk).", "section": "B Comparison of Computation Complexity"}, {"figure_path": "yzviAnpvU6/tables/tables_17_2.jpg", "caption": "Table 6: Comparison of various ZO methods on small sample size N = 2.", "description": "This table compares the performance of four zeroth-order optimization (ZO) methods: ZO-SGD, ZO-signSGD, ZO-AdaMM, and ReLIZO (the proposed method) on six different optimization problems from the CUTEst test suite.  The sample size N is fixed at 2, which represents a small sample regime, to evaluate the robustness of the algorithms in data-scarce scenarios. The table shows the objective function values achieved by each method for each problem. Lower values indicate better performance.", "section": "4.2 Experiments on the Simulation Benchmark"}, {"figure_path": "yzviAnpvU6/tables/tables_17_3.jpg", "caption": "Table 7: Comparison of various ZO methods on large dimension d.", "description": "This table compares the performance of four zeroth-order optimization methods (ZO-SGD, ZO-signSGD, ZO-AdaMM, and ReLIZO) on the BOXPOWER and SROSENBR problems from the CUTEst benchmark.  The comparison is done for different dimensions (d) of the problem's variables: d=1000, d=5000, and d=10000 for SROSENBR; and d=1000, d=10000, and d=20000 for BOXPOWER. The numbers in parentheses represent the standard deviation of the results across multiple runs.  The table highlights the effectiveness of ReLIZO in handling high-dimensional optimization problems, showcasing significantly lower objective function values compared to other methods. ", "section": "4.2 Experiments on the Simulation Benchmark"}, {"figure_path": "yzviAnpvU6/tables/tables_18_1.jpg", "caption": "Table 8: Number of queries from line search, total queries, reused samples during the optimization process.", "description": "This table presents a detailed breakdown of the query counts during the optimization process for several benchmark problems.  It shows the number of queries from line search (#LS), the total number of queries (#Queries), the number of reused queries (#Reused), and the total number of queries that would have been needed without the query reuse strategy (N x T).  This demonstrates the efficiency gains achieved by ReLIZO's query reuse mechanism, showing significantly fewer queries than standard methods.", "section": "4.2 Experiments on the Simulation Benchmark"}, {"figure_path": "yzviAnpvU6/tables/tables_18_2.jpg", "caption": "Table 2: Top-1 test classification accuracy (%) on NAS-Bench-201. The first block shows the performance of gradient-based methods quoted from the paper of NAS-Bench-201. The second block shows the performance of various ZO methods, which are implemented by ourselves on the PyTorch platform. The performance of the methods based on ZO optimizers is averaged over three independent trials.", "description": "This table compares the top-1 test classification accuracy of different neural architecture search (NAS) methods on the NAS-Bench-201 benchmark.  It contrasts gradient-based methods with zeroth-order (ZO) optimization methods. The ZO methods were implemented by the authors and their performance is averaged across three independent trials.", "section": "4.4 Experiments on Neural Architecture Search"}, {"figure_path": "yzviAnpvU6/tables/tables_20_1.jpg", "caption": "Table 10: The objective value and total reuse rate of different reusable distance bound b.", "description": "This table presents the objective function values after 500 and 2000 iterations of the ReLIZO algorithm, along with the corresponding total reuse rates, for various values of the reusable distance bound  (b).  The results show how the objective function value and reuse rate change as the reusable distance bound is increased. A larger reusable distance bound allows for a higher reuse rate, but may lead to a slightly higher objective function value.", "section": "4.2 Experiments on the Simulation Benchmark"}, {"figure_path": "yzviAnpvU6/tables/tables_20_2.jpg", "caption": "Table 10: The objective value and total reuse rate of different reusable distance bound b.", "description": "This table presents the objective function values obtained after 500 and 2000 iterations of the ReLIZO algorithm, using different values for the reusable distance bound (b). It also shows the overall reuse rate achieved for each value of b. The results demonstrate the impact of the reusable distance bound on both the optimization performance and the query reuse efficiency.  A larger reusable distance bound generally leads to higher reuse rates but can potentially affect the quality of the optimization results.", "section": "4.2 Experiments on the Simulation Benchmark"}]