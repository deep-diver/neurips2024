[{"figure_path": "aXS1pwMa8I/figures/figures_2_1.jpg", "caption": "Figure 1: Local 3D patches may exhibit geometric similarity, but with different poses. When the pose is removed, these local regions appear repeatedly.", "description": "This figure illustrates the core idea behind the paper's approach.  It shows that many 3D shapes contain repeated local geometric structures, even if their poses (orientations and positions) differ significantly. By removing the effects of pose, the algorithm can learn these recurring patterns and thus achieve more robust and efficient 3D shape reconstruction.", "section": "3 Problem Statement for Equivariant Neural Vector Field"}, {"figure_path": "aXS1pwMa8I/figures/figures_3_1.jpg", "caption": "Figure 2: Overview of the proposed PEIF. Given query points, the local patches are selected using KNN. The query/patch pairs are normalized by pose transformations \u03c4. The displacements of query points to the surface are predicted by displacement predictor D. The implicit function is equivariant under the SE(3) transformations of the input. Finally, the mesh is generated by marching cubes [1] algorithm.", "description": "This figure illustrates the architecture of the proposed Patch-level Equivariant Implicit Function (PEIF).  It shows how the model takes query points as input, selects local patches using KNN, normalizes these patches and query points using pose transformations (\u03c4), and then uses a displacement predictor (D) to estimate the displacement vectors. The model is designed to be equivariant under SE(3) transformations.  Finally, a marching cubes algorithm generates the 3D mesh.", "section": "4 Equivariant Neural Implicit Function"}, {"figure_path": "aXS1pwMa8I/figures/figures_4_1.jpg", "caption": "Figure 3: Feature enhancement with IPGE.", "description": "This figure illustrates the Intrinsic Patch Geometry Extractor (IPGE) module.  The input is a patch feature. This feature is then enhanced by querying and aggregating information from a multi-head memory bank M = {M\u1d62}. Each M\u1d62 is a memory bank with multiple memory items.  The query is performed using learnable weights, creating a weighted aggregation that enhances the patch feature's representation of intrinsic 3D patch geometry. The output is the enhanced feature, representing the intrinsic patch geometry representation.", "section": "4.3 Displacement Predictor Design on Normalized Patches"}, {"figure_path": "aXS1pwMa8I/figures/figures_7_1.jpg", "caption": "Figure 11: The visual example of cross-domain evaluation on the real scanned dataset MGN [53], where the model is trained on Synthetic Room dataset [19].", "description": "This figure shows a visual comparison of cross-domain evaluation results on the MGN dataset. The model was pre-trained on the Synthetic Rooms dataset.  It highlights the ability of the proposed PEIF model to generalize to unseen real-world data, while other methods struggle with incomplete or rough surface reconstructions.  Red boxes indicate regions of interest where the model performance differences are most notable.", "section": "5.1 Results and Comparisons"}, {"figure_path": "aXS1pwMa8I/figures/figures_7_2.jpg", "caption": "Figure 1: Local 3D patches may exhibit geometric similarity, but with different poses. When the pose is removed, these local regions appear repeatedly.", "description": "This figure illustrates the core idea of the paper.  It shows that many local 3D patches on different 3D shapes share similar geometric characteristics, even though their orientations (poses) differ. The key insight is that by removing the pose variations, these repeated local patterns can be identified and efficiently represented. This leads to the concept of a patch-level pose-invariant representation, which is a crucial part of the proposed PEIF (Patch-level Equivariant Implicit Function).", "section": "3 Problem Statement for Equivariant Neural Vector Field"}, {"figure_path": "aXS1pwMa8I/figures/figures_15_1.jpg", "caption": "Figure 1: Local 3D patches may exhibit geometric similarity, but with different poses. When the pose is removed, these local regions appear repeatedly.", "description": "This figure illustrates the core idea of the paper.  Local 3D patches from various 3D shapes are shown.  While the patches have different poses (orientations and positions in 3D space), their intrinsic geometric structure is very similar. The paper leverages this observation to develop a pose-invariant representation for the patches, which improves the efficiency and robustness of 3D surface reconstruction.", "section": "3 Problem Statement for Equivariant Neural Vector Field"}, {"figure_path": "aXS1pwMa8I/figures/figures_17_1.jpg", "caption": "Figure 4: The qualitative results of ShapeNet [51] dataset. The object is selected from meshes used for class-unseen reconstruction (novel classes in Table 1).", "description": "This figure shows a qualitative comparison of the 3D object reconstruction results on the ShapeNet dataset.  The models were tested on novel classes (classes not seen during training), and the results are presented for several different methods: POCO, GIFS, ALTO, NVF, GeoUDF, GridFormer, and the authors' proposed PEIF method.  Ground truth (GT) models are also included. The image highlights the ability of PEIF to capture finer details and achieve more robust and complete reconstructions, particularly in comparison to other approaches.", "section": "5.1 Results and Comparisons"}, {"figure_path": "aXS1pwMa8I/figures/figures_17_2.jpg", "caption": "Figure 4: The qualitative results of ShapeNet [51] dataset. The object is selected from meshes used for class-unseen reconstruction (novel classes in Table 1).", "description": "This figure showcases the qualitative results of the proposed method, PEIF, on the ShapeNet dataset. It specifically focuses on class-unseen reconstruction, meaning that the model is tested on shapes that it hasn't seen during training.  The top row displays the ground truth (GT) meshes, and the bottom row shows the reconstructions generated by the PEIF model.  The figure aims to visually demonstrate the PEIF's ability to reconstruct novel objects with high fidelity and detail.", "section": "5.1 Results and Comparisons"}, {"figure_path": "aXS1pwMa8I/figures/figures_18_1.jpg", "caption": "Figure 10: Examples of results on Synthetic Room dataset.", "description": "This figure shows a comparison of the ground truth (GT) 3D reconstruction of a synthetic room scene with the reconstructions produced by several different methods: POCO, GIFS, ALTO, NVF, GeoUDF, GridFormer, and PEIF (the proposed method). The red boxes highlight areas where some methods fail to reconstruct parts of the scene accurately or completely.", "section": "5.1 Results and Comparisons"}, {"figure_path": "aXS1pwMa8I/figures/figures_18_2.jpg", "caption": "Figure 11: The visual example of cross-domain evaluation on the real scanned dataset MGN [53], where the model is trained on Synthetic Room dataset [19].", "description": "This figure shows a comparison of cross-domain evaluation results on the real scanned MGN dataset. The model was pre-trained on the Synthetic Rooms dataset.  The top row displays the ground truth (GT) 3D models of clothing items. Subsequent rows show the reconstruction results from different methods: GeoUDF, NVF, GridFormer, and the proposed PEIF. Each method's reconstruction is presented alongside extracted patches, highlighting the model's ability (or lack thereof) to generalize to unseen data. Red boxes represent correctly reconstructed patches while purple boxes indicate poorly reconstructed areas. The figure illustrates that the PEIF method achieves better generalization performance to real-world scans compared to other methods.", "section": "5.1 Results and Comparisons"}]