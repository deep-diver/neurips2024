[{"figure_path": "leeosk2RAM/figures/figures_1_1.jpg", "caption": "Figure 1: The proposed SearchLVLMs, a framework for LVLMs to access up-to-date knowledge.", "description": "This figure illustrates the SearchLVLMs framework, designed to equip Large Vision-Language Models (LVLMs) with access to current internet knowledge.  The framework starts with a Query Generator that extracts relevant search terms from a question about an image. These terms are fed into search engines (Google and Bing), and the results are parsed to extract website titles, snippets, and content.  A Hierarchical Filtering Model, consisting of a Website Filter and a Content Filter, then processes this information to select the most relevant content. This filtered content is finally used to augment the LVLMs (like GPT, Llama, and Gemini) for improved answer generation.  The example shown involves answering a question about the singer of a theme song using visual information and internet search.", "section": "3 SearchLVLMs Framework"}, {"figure_path": "leeosk2RAM/figures/figures_4_1.jpg", "caption": "Figure 2: Overall pipeline of the sample generation for the UDK-VQA dataset. For brevity, we only show one output item at several steps, such as the content segment returned by the Parser. Notably, we use queries from different time periods to scrape news from different time periods to generate training samples and test samples, which is not reflected in this figure for brevity.", "description": "This figure illustrates the pipeline for automatically generating news-related visual question answering (VQA) samples for the UDK-VQA dataset.  It begins with query collection from Google Daily Search Trends and manual sources.  These queries are used to search for and parse relevant news articles using Google and Bing.  The text is segmented, and GPT-3.5 generates question-answer pairs, an entity is extracted and replaced with its hypernym to create VQA questions.  Bing Image Search finds images, and clustering reduces outliers.  Finally, a multi-model voting mechanism assigns pseudo-scores for training the filtering model. Manual screening creates the test set, ensuring data quality and avoiding training-test overlap. Queries from different time periods generate samples from different periods, preventing data leakage.", "section": "4 UDK-VQA Dataset"}, {"figure_path": "leeosk2RAM/figures/figures_5_1.jpg", "caption": "Figure 1: The proposed SearchLVLMs, a framework for LVLMs to access up-to-date knowledge.", "description": "This figure illustrates the SearchLVLMs framework.  It shows the process of using a query generator to extract queries from a question and image, then using a search engine to find relevant websites. A hierarchical filtering model is used to efficiently select the most helpful content from these websites. Finally, this filtered content is used to prompt large vision-language models (LVLMs) for augmented generation, enhancing their ability to answer questions using up-to-date knowledge.", "section": "3 SearchLVLMs Framework"}, {"figure_path": "leeosk2RAM/figures/figures_8_1.jpg", "caption": "Figure 4: Accuracy using different LVLMs to generate pseudo-scores.", "description": "This radar chart visualizes the performance of different Large Vision-Language Models (LVLMs) when using various methods for generating pseudo-scores during the training of a hierarchical filtering model.  The models are arranged around the perimeter, with their accuracy scores represented by the radial distance from the center. The different pseudo-score generation methods are represented by different colored lines. The chart allows for a comparison of model performance across different pseudo-score strategies, showing which models benefit most from each approach. The shaded area represents the range of accuracy achieved by various models using each method.", "section": "5.4 Analysis of Pseudo-Score Generation"}, {"figure_path": "leeosk2RAM/figures/figures_9_1.jpg", "caption": "Figure 3: (a) Training samples. (b) Test samples. (c) Category statistics for the test set of UDK-VQA.", "description": "This figure shows examples of training and test samples used in the UDK-VQA dataset. The training samples (a) demonstrate the question-answer pairs generated, showing a title, snippet, and selected segment from the news articles for training the hierarchical filtering model. The test samples (b) showcase examples of how questions are constructed and presented along with their answers, which include both correct and incorrect options.  Part (c) provides a statistical breakdown of categories in the UDK-VQA test set, visualizing the distribution of various news categories, such as entertainment, politics, sports, and technology.", "section": "4 UDK-VQA Dataset"}, {"figure_path": "leeosk2RAM/figures/figures_9_2.jpg", "caption": "Figure 3: (a) Training samples. (b) Test samples. (c) Category statistics for the test set of UDK-VQA.", "description": "This figure visualizes examples of training and test samples used in the UDK-VQA dataset, highlighting the diversity of questions and images. It also shows the distribution of categories in the test set, indicating the balance and representativeness of the dataset.", "section": "4 UDK-VQA Dataset"}, {"figure_path": "leeosk2RAM/figures/figures_13_1.jpg", "caption": "Figure 2: Overall pipeline of the sample generation for the UDK-VQA dataset. For brevity, we only show one output item at several steps, such as the content segment returned by the Parser. Notably, we use queries from different time periods to scrape news from different time periods to generate training samples and test samples, which is not reflected in this figure for brevity.", "description": "This figure shows the overall pipeline for automatically generating news-related VQA samples for the UDK-VQA dataset.  It details the steps involved, starting with query collection from Google Daily Search Trends and manual searches, followed by question generation using GPT-3.5, image retrieval and clustering using Bing Image Search, pseudo-score generation using multiple LVLMs, and finally manual screening for test set quality assurance. The pipeline aims to create VQA samples that require both visual and textual understanding of up-to-date information. ", "section": "4 UDK-VQA Dataset"}]