{"references": [{"fullname_first_author": "Michael Ahn", "paper_title": "Do as I can, not as I say: Grounding language in robotic affordances", "publication_date": "2022-04-01", "reason": "This paper is foundational for long-horizon manipulation using language instructions, directly addressing limitations of prior approaches that led to the development of the PERIA framework."}, {"fullname_first_author": "Yao Mu", "paper_title": "EmbodiedGPT: Vision-Language Pre-training via Embodied Chain of Thought", "publication_date": "2023-12-01", "reason": "This work introduces the concept of embodied chain of thought reasoning for language planning, which is directly incorporated into the PERIA framework for long-horizon manipulation."}, {"fullname_first_author": "Kevin Black", "paper_title": "Zero-shot robotic manipulation with pre-trained image-editing diffusion models", "publication_date": "2023-01-01", "reason": "This paper introduces using diffusion models for vision planning and generating subgoal images, inspiring a key component of the PERIA framework."}, {"fullname_first_author": "Divyansh Garg", "paper_title": "LISA: Learning interpretable skill abstractions from language", "publication_date": "2022-12-01", "reason": "This work provides a hierarchical planning method that decomposes complex instructions into sub-tasks which is compared to and improved upon by the PERIA method."}, {"fullname_first_author": "Dongxu Li", "paper_title": "BLIP-diffusion: Pre-trained subject representation for controllable text-to-image generation and editing", "publication_date": "2023-05-14", "reason": "This paper provides a method for image editing via a pre-trained diffusion model which is used in the PERIA framework for subgoal image generation."}]}