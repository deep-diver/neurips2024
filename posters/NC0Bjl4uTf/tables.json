[{"figure_path": "NC0Bjl4uTf/tables/tables_5_1.jpg", "caption": "Table 1: The built-in IMU specifications of some smartphones. Note that since the IMUs in some types of iPhones are customized by the manufacturer, the model and price are not disclosed.", "description": "This table lists the specifications of the inertial measurement units (IMUs) built into the smartphones used in the data collection process of the paper. It shows the smartphone model, release date, IMU model, and the unit price. Note that the IMU models and prices for iPhones are not disclosed because they are customized by Apple.", "section": "4.1 Data Collection and Experimental Setup"}, {"figure_path": "NC0Bjl4uTf/tables/tables_7_1.jpg", "caption": "Table 2: Performance comparison of 6 classfiers.", "description": "This table presents a comparison of six different classifiers (1DCNN, LSTM, Transformer, RF, XGBoost, and SVM) used for Chinese handwriting recognition.  For each classifier, it shows the runtime (in seconds), memory usage (in MB), and the accuracy achieved.  The table highlights the performance trade-offs among classifiers, allowing researchers to choose the best classifier based on their specific application requirements and resource constraints.", "section": "4.3 Comparative Experiments"}, {"figure_path": "NC0Bjl4uTf/tables/tables_7_2.jpg", "caption": "Table 3: Performance comparison of six classifiers trained on samples generated by different ablation models.", "description": "This table presents the performance of six different classifiers (1DCNN, LSTM, Transformer, RF, XGBoost, and SVM) trained on datasets generated using various ablation models of the CI-GAN.  The ablation models systematically remove components of the CI-GAN (CGE, FOT, and SRA) to assess their individual contributions to the overall model performance. The \"No augmentation\" row shows the baseline performance without using CI-GAN generated data.  The results reveal the impact of each component on the classification accuracy of the different models, demonstrating the effectiveness of the CI-GAN architecture.", "section": "4.4 Ablation Study"}, {"figure_path": "NC0Bjl4uTf/tables/tables_13_1.jpg", "caption": "Table 4: Performance of different classifiers with CI-GAN generated data", "description": "This table presents the performance comparison of six different classifiers (1DCNN, LSTM, Transformer, Random Forest, XGBoost, and SVM) trained on datasets generated using three different methods: no data augmentation, traditional GAN, and CI-GAN. For each classifier and data generation method, the mean accuracy, standard deviation, and 95% confidence interval are reported. The results show that using CI-GAN significantly improves the performance of all classifiers compared to using no data augmentation and traditional GAN. The CI-GAN is able to generate high-quality diverse samples for training.", "section": "4.3 Comparative Experiments"}]