[{"figure_path": "MjD9Y05Q6i/figures/figures_1_1.jpg", "caption": "Figure 1: The quality of CAV is significantly affected by the number of training images. Here concept accuracy estimates whether the CAV faithfully represents its corresponding concept. Concept-to-class accuracy measures the similarity between the CAV and its strongly semantic-related class.", "description": "This figure shows that the quality of Concept Activation Vectors (CAVs) is highly dependent on the number of training images used.  Two metrics are plotted against shot number (number of training images): concept accuracy (how well the CAV represents the concept) and concept-to-class accuracy (how similar the CAV is to its semantically related class).  The plots reveal a strong positive correlation between the number of training images and the accuracy of the CAVs, highlighting the challenge of training high-quality CAVs for many concepts when training data is scarce.", "section": "4.1 The Quality of LG-CAV"}, {"figure_path": "MjD9Y05Q6i/figures/figures_1_2.jpg", "caption": "Figure 2: (A) LG-CAV is trained guided by activations of concept descriptions on the probe images from VL model. (B) The distribution of activation values on a concept named \"Skyscraper\" (from the Broden dataset [2]) in the target model (ResNet18) and VL model (CLIP) differs a lot.", "description": "The figure demonstrates the LG-CAV training framework and the differences in activation value distributions between the vision-language model (VL model) and the target model. (A) shows how LG-CAV leverages activations from the VL model on probe images to train the LG-CAV for a target model. (B) highlights the significant distributional difference between the two models' activation values for the concept \"Skyscraper\", emphasizing the need for a mechanism to bridge this gap during LG-CAV training.", "section": "3.3 LG-CAV"}, {"figure_path": "MjD9Y05Q6i/figures/figures_4_1.jpg", "caption": "Figure 3: Top: The original CAV is defined as the weight vector for its represented concept in the binary linear classifier. Bottom: The LG-CAV is learned by mimicking the activation values of its represented concept on the probe images R using VL model. Besides, three modules (GA module, CE module, and DSR module) are proposed to enhance the quality of LG-CAV.", "description": "This figure illustrates the architecture of the proposed LG-CAV method and compares it with the original CAV method.  The top half shows the original CAV training process, using positive and negative image features to train a binary classifier. The bottom half depicts the LG-CAV, which utilizes activations from a vision-language (VL) model and incorporates three modules (Gaussian Alignment (GA), Concept Ensemble (CE), and Deviation Sample Reweighting (DSR)) to improve training and accuracy. The figure highlights the key differences and improvements of the LG-CAV over the traditional CAV approach.", "section": "3.3 LG-CAV"}, {"figure_path": "MjD9Y05Q6i/figures/figures_8_1.jpg", "caption": "Figure 4: Ablation experiments on probe images (selection strategy & image number).", "description": "This figure presents the ablation studies conducted on the selection strategy and number of probe images used in the LG-CAV model. The left two subfigures show the comparison of concept accuracy and concept-to-class accuracy between random probe image selection and the proposed strategy (selecting the most and least activated images). The right two subfigures illustrate how the number of probe images affects the model performance in terms of concept accuracy and concept-to-class accuracy.  The results demonstrate that the proposed selection strategy and a sufficient number of probe images are crucial for achieving high-quality LG-CAVs.", "section": "4.3 Ablation Study"}, {"figure_path": "MjD9Y05Q6i/figures/figures_17_1.jpg", "caption": "Figure 4: Ablation experiments on probe images (selection strategy & image number).", "description": "This figure shows the results of ablation experiments conducted to analyze the impact of probe image selection strategy and the number of probe images on the performance of LG-CAV.  The left panel displays concept accuracy, while the right panel shows concept-to-class accuracy.  Both accuracy metrics are plotted against the number of probe images used for training, showing results for four different backbones (ResNet-18, VGG-13, DenseNet-121, and ViT-B) and comparing a random selection strategy to a more focused selection method. The results illustrate the optimal configuration for probe image selection and the number of images required to achieve superior performance. ", "section": "4.3 Ablation Study"}, {"figure_path": "MjD9Y05Q6i/figures/figures_21_1.jpg", "caption": "Figure 3: Top: The original CAV is defined as the weight vector for its represented concept in the binary linear classifier. Bottom: The LG-CAV is learned by mimicking the activation values of its represented concept on the probe images R using VL model. Besides, three modules (GA module, CE module, and DSR module) are proposed to enhance the quality of LG-CAV.", "description": "This figure illustrates the architecture of the proposed LG-CAV method in comparison to the original CAV method. The original CAV is shown on the top, while the LG-CAV is shown on the bottom, with added Gaussian Alignment Module (GA), Concept Ensemble Module (CE), and Deviation Sample Reweighting Module (DSR) to improve the LG-CAV quality. The LG-CAV learns by mimicking VL model's activation values on probe images, bridging the gap between VL model and the target model.", "section": "3.3 LG-CAV"}, {"figure_path": "MjD9Y05Q6i/figures/figures_22_1.jpg", "caption": "Figure 3: Top: The original CAV is defined as the weight vector for its represented concept in the binary linear classifier. Bottom: The LG-CAV is learned by mimicking the activation values of its represented concept on the probe images R using VL model. Besides, three modules (GA module, CE module, and DSR module) are proposed to enhance the quality of LG-CAV.", "description": "This figure illustrates the architecture of the proposed LG-CAV method, comparing it to the original CAV method. The top half shows the original CAV approach, training a binary classifier on positive and negative image features to obtain a concept activation vector. The bottom half details the LG-CAV which uses a vision-language model (VL) and incorporates three additional modules (Gaussian Alignment, Concept Ensemble, and Deviation Sample Reweighting) to improve the quality of the resulting concept activation vector.", "section": "3.3 LG-CAV"}]