[{"type": "text", "text": "PAC-Bayes-Chernoff bounds for unbounded losses ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ioar Casado Machine Learning Group Basque Center for Applied Mathematics (BCAM) icasado@bcamath.org ", "page_idx": 0}, {"type": "text", "text": "Luis A. Ortega   \nMachine Learning Group   \nComputer Science Dept. - EPS.   \nUniversidad Aut\u00f3noma de Madrid   \nluis.ortega@uam.es ", "page_idx": 0}, {"type": "text", "text": "Aritz P\u00e9rez Machine Learning Group Basque Center for Applied Mathematics (BCAM) aperez@bcamath.org ", "page_idx": 0}, {"type": "text", "text": "Andr\u00e9s R. Masegosa Department of Computer Science Aalborg University arma@cs.aau.dk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We introduce a new PAC-Bayes oracle bound for unbounded losses that extends Cram\u00e9r-Chernoff bounds to the PAC-Bayesian setting. The proof technique relies on controlling the tails of certain random variables involving the Cram\u00e9r transform of the loss. Our approach naturally leverages properties of Cram\u00e9r-Chernoff bounds, such as exact optimization of the free parameter in many PAC-Bayes bounds. We highlight several applications of the main theorem. Firstly, we show that our bound recovers and generalizes previous results. Additionally, our approach allows working with richer assumptions that result in more informative and potentially tighter bounds. In this direction, we provide a general bound under a new modeldependent assumption from which we obtain bounds based on parameter norms and log-Sobolev inequalities. Notably, many of these bounds can be minimized to obtain distributions beyond the Gibbs posterior and provide novel theoretical coverage to existing regularization techniques. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "PAC-Bayes theory provides powerful tools to analyze the generalization performance of randomized learning algorithms \u2014for an introduction to the subject see the recent surveys of Guedj (2019); Alquier (2024) and Hellstr\u00f6m et al. (2023)\u2014. Let $\\Theta$ be a model class parametrized by $\\pmb{\\theta}\\in\\bar{\\mathbb{R}}^{d}$ . With a small abuse of notation, $\\theta\\in\\Theta$ will represent both a model and its parameters. Instead of learning a single model, we consider the set of probability measures over our class, $\\mathcal{M}_{1}(\\pmb{\\Theta})$ , and aim to find the optimal distribution $\\rho^{*}\\in\\mathcal{M}_{1}(\\Theta)$ . This approach is more robust than finding the single best model in $\\Theta$ , and is tightly related to Bayesian and ensemble methods. The learning algorithm infers this distribution from a sequence of $n$ training data points $D=\\{{\\pmb x}_{i}\\}_{i=1}^{n}$ , which are assumed to be i.i.d. sampled from an unknown distribution $\\nu({\\pmb x})$ with support in $\\mathcal{X}\\subseteq\\mathbb{R}^{k}$ . ", "page_idx": 0}, {"type": "text", "text": "Given a loss function $\\ell:\\Theta\\times\\mathcal{X}\\to\\mathbb{R}_{+}$ , bounding the gap between the population risk $L(\\pmb\\theta):=$ $\\mathbb{E}_{\\nu}[\\ell(\\pmb{\\theta},X)]$ and the empirical risk $\\begin{array}{r}{\\hat{L}(\\pmb{\\theta},D):=\\frac{1}{n}\\sum_{i=1}^{n}\\ell(\\pmb{\\theta},\\pmb{x}_{i})}\\end{array}$ of individual models is the standard approach in statistical learning theory. In contrast, PAC-Bayes theory provides high-probability bounds over the population Gibbs risk $\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]$ in terms of the empirical Gibbs risk $\\mathbb{E}_{\\rho}[\\hat{L}(\\pmb{\\theta},D)]$ and an extra term measuring the dependence of $\\rho$ to the dataset $D$ . This second term involves an information measure \u2014usually the Kullback-Leibler divergence $K L(\\rho|\\pi)$ \u2014 between the data dependent posterior1 $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ and a prior $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ , chosen before observing the data. These bounds hold simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ , hence minimizing them with respect to $\\rho$ provides an appealing approach to derive new learning algorithms with theoretically sound guarantees. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "The foundational papers on PAC-Bayes theory (Shawe-Taylor and Williamson, 1997; McAllester, 1998, 1999; Seeger, 2002) worked with classification problems under bounded losses, usually the zero-one loss. This framework was significantly extended in Catoni (2007), who introduced some of the first bounds for unbounded losses. McAllester\u2019s bound (McAllester, 2003) is one of the most representative results for bounded losses: for any $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ independent of $D$ and every $\\delta\\in(0,1)$ , we have ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\sqrt{\\frac{K L(\\rho|\\pi)+\\log\\frac{2\\sqrt{n}}{\\delta}}{2n}}\\,,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ , where the above inequality holds with probability no less than $1-\\delta$ over the choice of $D\\sim\\nu^{n}$ . Another significant example under the bounded loss assumption is the Langford-Seeger-Maurer bound \u2014after (Langford and Seeger, 2001; Seeger, 2002; Maurer, 2004)\u2014. Under the same conditions as above, ", "page_idx": 1}, {"type": "equation", "text": "$$\nk l\\Big(\\mathbb{E}_{\\rho}[\\widehat{L}(D,\\pmb{\\theta})],\\mathbb{E}_{\\rho}[L(\\pmb{\\theta})]\\Big)\\leq\\frac{K L(\\rho|\\pi)+\\log\\frac{2\\sqrt{n}}{\\delta}}{n}\\,,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $k l$ is the so-called binary-kl distance, defined as $\\begin{array}{r}{k l(a,b):=a\\ln\\frac{a}{b}+(1-a)\\ln\\frac{1-a}{1-b}.}\\end{array}$ ", "page_idx": 1}, {"type": "text", "text": "These bounds illustrate typical trade-offs in PAC-Bayes theory. In (1), the relation between the empirical and the population risk is easy to interpret because the expected loss is bounded by the empirical loss plus a complexity term. More crucially, the right-hand side of the bound can be directly minimized with respect to the posterior $\\rho$ , resulting in the Gibbs posterior (Guedj, 2019). Conversely, (2) is known to be tighter than (1), but it is not straightforward to minimize because it requires inverting $k l\\left(\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb{\\theta})],\\cdot\\right)$ \u2014several techniques deal with this issue (Thiemann et al., 2017; Reeb et al., 2018)\u2014. ", "page_idx": 1}, {"type": "text", "text": "With the trade-offs among explainability, tightness, and generality in mind, the PAC-Bayes community has come up with novel bounds with applications in virtually every area of machine learning, ranging from the study of particular algorithms \u2014linear regression (Alquier and Lounici, 2011; Germain et al., 2016), matrix factorization (Alquier and Guedj, 2017), kernel PCA (Haddouche et al., 2020), ensembles (Masegosa et al., 2020; Wu et al., 2021; Ortega et al., 2022) or Bayesian inference (Germain et al., 2016; Masegosa, 2020)\u2014 and generic versions of PAC-Bayes theorems (B\u00e9gin et al., 2016; Rivasplata et al., 2020) to the study of the generalization of deep neural networks (Dziugaite and Roy, 2017; Rivasplata et al., 2019). ", "page_idx": 1}, {"type": "text", "text": "Such applications often require relaxing the assumptions of the classical PAC-Bayesian framework, such as data-independent priors, i.i.d. data or bounded losses. Here we are interested in the case of PAC-Bayes bounds for unbounded losses \u2014such as the squared error loss and the log-loss\u2014. ", "page_idx": 1}, {"type": "text", "text": "PAC-Bayes bounds for unbounded losses ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The main challenge of working with unbounded losses is that one needs to deal with an exponential moment term which cannot be easily bounded without specific assumptions about the tails of the loss. The following theorems, fundamental starting points for many works on PAC-Bayes theory over unbounded losses, illustrate this point. ", "page_idx": 1}, {"type": "text", "text": "Theorem 1 ((Alquier et al., 2016; Germain et al., 2016)). Let $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ and any $\\lambda>0$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\frac{1}{\\lambda n}\\left[K L(\\rho|\\pi)+\\log\\frac{f_{\\pi,\\nu}(\\lambda)}{\\delta}\\right],\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . Here $f_{\\pi,\\nu}(\\lambda):=\\mathbb{E}_{\\pi}\\mathbb{E}_{\\nu^{n}}\\,\\Big[e^{\\lambda n\\,(L(\\pmb{\\theta})-\\hat{L}(D,\\pmb{\\theta}))}\\Big].$ ", "page_idx": 1}, {"type": "text", "text": "This is an oracle bound, because $f_{\\pi,\\nu}(\\lambda)$ depends on the data generating distribution $\\nu^{n}$ . To obtain empirical bounds from the theorem above, the exponential term $f_{\\pi,\\nu}$ is usually bounded by making the appropriate assumptions on the tails of the loss, such as the Hoeffding assumption (Alquier et al., 2016), sub-Gaussianity (Alquier and Guedj, 2018; $\\mathrm{Xu}$ and Raginsky, 2017), sub-gamma (Germain et al., 2016) or sub-exponential (Catoni, 2004). See Section 5 of Alquier (2024) for an overview. ", "page_idx": 2}, {"type": "text", "text": "Many of these assumptions are generalized by the notion that the cumulant generating function $(C G F)$ of the (centered) loss, $\\Lambda_{\\theta}(\\lambda)$ , exists and is bounded (Banerjee and Mont\u00fafar, 2021; Rodr\u00edguez-G\u00e1lvez et al., 2024). Remember that we say $\\Lambda_{\\theta}(\\lambda)$ exists if it is bounded in some interval $[0,b)$ with $b>0$ . ", "page_idx": 2}, {"type": "text", "text": "Definition 2 (Bounded CGF). A loss function $\\ell$ has bounded CGF if for all $\\theta\\in\\Theta$ , there is a convex and continuously differentiable function $\\psi:[0,b)\\rightarrow\\mathbb{R}_{+}$ such that $\\psi(0)=\\psi^{\\prime}(0)=0$ and ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Lambda_{\\pmb\\theta}(\\lambda):=\\log\\mathbb{E}_{\\nu}\\left[e^{\\lambda\\,(L(\\pmb\\theta)-\\ell(\\pmb x,\\pmb\\theta))}\\right]\\leq\\psi(\\lambda)\\mathrm{~for~all~}\\lambda\\in[0,b).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "We will say that a loss function $\\ell$ is $\\psi$ -bounded if it satisfies the above assumption under the function $\\psi$ . In this setup, Banerjee and Mont\u00fafar (2021) obtain the following PAC-Bayes bound under the Bounded CGF assumption: ", "page_idx": 2}, {"type": "text", "text": "Theorem 3. Let \u2113be a loss with $\\psi$ -bounded CGF and $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ and any $\\lambda\\in(0,b)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\frac{K L(\\rho|\\pi)+\\log\\frac{1}{\\delta}}{\\lambda n}+\\frac{\\psi(\\lambda)}{\\lambda},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 2}, {"type": "text", "text": "Theorems 1 and 3 illustrate a pervasive problem of many PAC-Bayes bounds for unbounded losses: they often depend on a free parameter $\\lambda>0$ \u2014see for example (Alquier et al., 2016; Hellstr\u00f6m and Durisi, 2020; Guedj and Pujol, 2021; Banerjee and Mont\u00fafar, 2021; Haddouche et al., 2021)\u2014. The choice of this free parameter is crucial for the tightness of the bounds, and it cannot be directly optimized because its choice is prior to the draw of data, while the optimal $\\lambda$ would be data-dependent. The standard approach is to optimize $\\lambda$ over a grid using union-bound arguments, but the resulting $\\lambda$ is not guaranteed to be optimal. Seldin et al. (2012) carefully design the grid so that the optimal $\\lambda$ is inside its range, but their work only deals with bounded losses. See the discussion in Section 2.1.4 of Alquier (2024) for an overview. ", "page_idx": 2}, {"type": "text", "text": "Recently, Rodr\u00edguez-G\u00e1lvez et al. (2024) improved the union-bound approach for the bounded CGF scenario using a convenient partition of the event space. However, their optimization remains approximate. Hellstr\u00f6m and Durisi (2021) could circumvent this problem for the particular case of sub-Gaussian losses, but the exact optimization of $\\lambda$ for the general case remains an open question. A positive result in this direction would lift the restriction of having to optimize $\\lambda$ over restricted grids or using more complex approaches. ", "page_idx": 2}, {"type": "text", "text": "The use of the bounded CGF assumption entails another potential drawback: both uniform control of the CGF \u2014 $-\\Lambda_{\\theta}(\\lambda)\\leq\\psi(\\lambda)$ for every $\\theta\\in\\Theta$ \u2014 and integrability assumptions as in Alquier et al. $(2016)\\!\\-\\!\\mathbb{E}_{\\pi}[\\Lambda_{\\theta}(\\lambda)]\\!\\le C$ for some constant $C-$ , necessarily drop information about the different concentration properties of individual models. For example, Masegosa and Ortega (2023) show that within the class of models defined by the weights of common neural networks, the behavior of their CGFs \u2014and hence of their Cram\u00e9r transforms, which control generalization error via Cram\u00e9rChernoff bound\u2014 varies significantly. As Figure 1 shows, uniformly bounding the CGFs can result in loose worst-case bounds that ignore the properties of the models that interest us most. ", "page_idx": 2}, {"type": "text", "text": "The bounds of Seldin et al. (2012) and Haddouche et al. (2021) partially address this issue including average variances and model-dependent range functions to their bounds, which account for the fact that different models have different CGFs. However, the former only applies to bounded losses, while the latter cannot be exploited to obtain better posteriors because their model-dependent function only impacts the prior. Outside the PAC-Bayes framework, Jiao et al. (2017) generalized the bounded CGF assumption, but their result only applies to finite model sets. ", "page_idx": 2}, {"type": "text", "text": "Exploiting these differences among models within the same class could be an important line of research in PAC-Bayes theory. This approach would provide more informative generalization bounds, paving also the way for the design of better posteriors. This is one of the main appeals of our work. ", "page_idx": 2}, {"type": "table", "img_path": "CyzZeND3LB/tmp/131870f949397bf88881d93b8390f12a81480bd3f68bd759437ae1e93e9b788e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 1: Models with very different CGFs coexist within the same model class. On the left, we display several metrics for InceptionV3 models trained on CIFAR10 without regularization (Standard) and with L2 regularization $(\\mathbf{L}2)$ . Random refers to a model learned over randomly reshuffled labels and Zero refers to a model where all the weights are equal to zero. For each model, the metrics include train and test accuracy, test log-loss, $\\ell_{2}$ -norm of the parameters of the model, the variance of the log-loss function, denoted $\\mathbb{V}_{\\nu}(\\ell({\\pmb x},{\\pmb\\theta}))$ , and the expected norm of the input-gradients, denoted $\\mathbb{E}_{\\nu}$ $[\\|\\nabla_{x}\\ell(x,\\pmb{\\theta})\\|_{2}^{2}]$ . On the right, we display the estimated CGFs of each model, following Masegosa and Ortega (2023). Note how models with smaller variance $\\mathbb{V}(\\ell(x,\\pmb{\\theta}))$ , $\\ell_{2}$ -norm or inputgradient norm $\\mathbb{E}_{\\nu}$ $[\\|\\nabla_{x}\\ell(x,\\pmb{\\theta})\\|_{2}^{2}]$ have smaller CGFs. Bounds derived from Theorem 7 naturally exploit these differences. Experimental details in Appendix C. ", "page_idx": 3}, {"type": "text", "text": "Overview and Contributions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The main contribution of this paper is Theorem 7, a novel (oracle) PAC-Bayes bound for unbounded losses which extends the classic Cram\u00e9r-Chernoff bound to the PAC-Bayesian setting. The theorem is introduced in Section 3, while Section 2 contains the necessary prerequisites. As far as we know, the proof technique based on Lemma 6 is also novel and can be of independent interest. ", "page_idx": 3}, {"type": "text", "text": "We discuss the applications of our main theorem in sections 4 and 5. First, we show that our bound allows exact optimization of the free parameter $\\lambda$ incurring in a $\\log n$ penalty without resorting to union-bound approaches. In the case of bounded CGFs, we recover bounds which are optimal up to that logarithmic term. We also show that versions of many well-known bounds \u2014such as the Langford-Seeger bound\u2014 can be recovered from Theorem 7. ", "page_idx": 3}, {"type": "text", "text": "In Section 5, we show how our main theorem provides a general framework to deal with richer assumptions that result in novel, more informative, and potentially tighter bounds. In Theorem 11, we generalize the bounded CGF assumption so that there is a different bounding function, $\\psi(\\pmb\\theta,\\cdot)$ , for the CGF of each model. We illustrate this idea in three cases: generalized sub-Gaussian losses, norm-based regularization, and input-gradient regularization based on log-Sobolev inequalities. Remarkably, the bounds in Section 5 can be minimized with respect to $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ , resulting in optimal posteriors beyond Gibbs\u2019 and opening the door to the design of novel algorithms. ", "page_idx": 3}, {"type": "text", "text": "Appendix A contains the proofs not included in the paper. ", "page_idx": 3}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section we introduce the necessary prerequisites in order to prove our main theorem. Its proof relies in controlling the concentration properties of each model in $\\Theta$ using their Cram\u00e9r transform. ", "page_idx": 3}, {"type": "text", "text": "Definition 4. Let $I\\subseteq\\mathbb{R}$ be an interval and $f:I\\to\\mathbb{R}$ a convex function. The Legendre transform of $f$ is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\nf^{\\star}(a):=\\operatorname*{sup}_{\\lambda\\in I}\\;\\{\\lambda a-f(\\lambda)\\},\\quad\\forall a\\in\\mathbb{R}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Following this definition, the Legendre transform of the CGF of a model $\\theta\\in\\Theta$ is known as its Cram\u00e9r transform: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\Lambda_{\\pmb\\theta}^{\\star}(a):=\\operatorname*{sup}_{\\lambda\\in[0,b)}\\;\\{\\lambda a-\\Lambda_{\\pmb\\theta}(\\lambda)\\},\\quad\\forall a\\in\\mathbb{R}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Throughout the paper, we will use the abbreviation $g e n(\\pmb\\theta,D)$ to denote the generalization gap $L(\\pmb\\theta)-\\hat{L}(D,\\pmb\\theta)$ , in order to make the notation more compact. Cram\u00e9r\u2019s transform provides non", "page_idx": 3}, {"type": "text", "text": "asymptotic bounds on the right tail of $g e n(\\pmb\\theta,D)$ via Cram\u00e9r-Chernoff\u2019s theorem \u2014see Section 2.2 of Boucheron et al. (2013) or Section 2.2 of Dembo and Zeitouni (2009)\u2014. ", "page_idx": 4}, {"type": "text", "text": "Theorem 5 (Cram\u00e9r-Chernoff). For any $\\theta\\in\\Theta$ and $a\\in\\mathbb{R}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}_{\\nu^{n}}\\big(g e n(\\pmb{\\theta},D)\\geq a\\big)\\leq e^{-n\\Lambda_{\\pmb{\\theta}}^{\\star}(a)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Furthermore, the inequality is asymptotically tight up to exponential factors. ", "page_idx": 4}, {"type": "text", "text": "Importantly, Cram\u00e9r-Chernoff\u2019s bound can be inverted to establish high-probability generalization bounds: for any $\\delta\\in(0,1)$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}_{\\nu^{n}}\\Big(g e n(\\pmb{\\theta},D)\\leq(\\Lambda_{\\pmb{\\theta}}^{\\star})^{-1}\\big(\\frac{1}{n}\\log\\frac{1}{\\delta}\\big)\\Big)\\geq1-\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $(\\Lambda_{\\theta}^{\\star})^{-1}$ is the inverse of the Cram\u00e9r transform. We cannot directly use Theorem 5 to obtain PAC-Bayes bounds, because we need a bound which is uniform for every model. The following lemma will be our main technical tool for this purpose. ", "page_idx": 4}, {"type": "text", "text": "Lemma 6. For any $\\theta\\in\\Theta$ and $c\\geq0$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\nu^{n}}\\Big(n\\Lambda_{\\pmb\\theta}^{\\star}\\big(g e n(\\pmb\\theta,D)\\big)\\geq c\\Big)\\leq\\mathbb{P}_{X\\sim\\exp{(1)}}\\Big(X\\geq c\\Big).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This way of controlling the survival function of $\\Lambda_{\\pmb{\\theta}}^{\\star}(g e n(\\pmb{\\theta},D))$ for every $\\theta\\in\\Theta$ will allow us to bound an exponential moment term in our main theorem. ", "page_idx": 4}, {"type": "text", "text": "3 PAC-Bayes-Chernoff bound ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "As we hinted above, instead of directly introducing boundedness conditions on the loss or its CGF, we stay in the realm of oracle bounds, aiming to provide a flexible starting point for diverse applications. A key element of our theoretical approach is the averaging of the CGFs with respect to a posterior distribution. For any posterior distribution $\\rho\\in\\mathcal{M}_{1}(\\bar{\\Theta})$ , we may consider the expectation of the CGF, $\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}(\\lambda)]$ , as in Jiao et al. (2017). In analogy to the standard definition, we define the Cram\u00e9r transform of a posterior distribution $\\rho$ as the following function: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Lambda_{\\rho}^{\\star}(a):=\\operatorname*{sup}_{\\lambda\\in[0,b)}\\;\\{\\lambda a-\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}(\\lambda)]\\},\\quad a\\in\\mathbb{R}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Since the CGFs $\\Lambda_{\\theta}(\\lambda)$ are convex and continuously differentiable with respect to $\\lambda$ , their expectation $\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}(\\lambda)]$ retains the same properties. Hence according to Lemma 2.4 in Boucheron et al. (2013), the (generalized) inverse of $\\Lambda_{\\rho}^{\\star}$ exists and can be written as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\left(\\Lambda_{\\rho}^{\\star}\\right)^{-1}(s)=\\operatorname*{inf}_{\\lambda\\in[0,b)}\\;\\left\\{\\frac{s+\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}(\\lambda)]}{\\lambda}\\right\\}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "With these definitions in hand, we are ready to introduce our main result, a novel (oracle) PAC-Bayes bound for unbounded losses: ", "page_idx": 4}, {"type": "text", "text": "Theorem 7 (PAC-Bayes-Chernoff bound). Let $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\operatorname*{inf}_{\\lambda\\in[0,b)}\\left\\{\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{\\lambda(n-1)}+\\frac{\\mathbb{E}_{\\rho}[\\Lambda_{\\pmb\\theta}(\\lambda)]}{\\lambda}\\right\\}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 4}, {"type": "text", "text": "The above result gives an oracle PAC-Bayes analogue to the Cram\u00e9r-Chernoff\u2019s bound of equation (7), because the second term of the right hand side of the inequality corresponds with the inverse of $\\Lambda_{\\rho}^{\\star}$ , as described in equation (9). Theorem 7 shows that bounds like the one given in Theorem 3 can hold simultaneously for every $\\lambda>0$ \u2014and hence optimized with respect to $\\lambda$ \u2014 by paying a $\\log(n)$ penalty, virtually the same as if we were optimizing over a uniform grid of size $n$ using union-bound arguments. Although the dependence in union bound arguments can be improved to $\\log(\\log(n))$ (Alquier, 2024), our optimization is exact. ", "page_idx": 4}, {"type": "text", "text": "Furthermore, Theorem 7 also shows that the posterior minimizing its right-hand-side is involved in a three-way trade-off: firstly, $\\rho$ must explain the training data due to $\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb{\\theta})]$ ; secondly, it must be close to the prior due to the KL term $K L(\\rho|\\pi)$ ; and lastly, it must place its density in models with a lower CGF due to the $\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}(\\lambda)]$ term. We note that the first two elements are standard on most PAC-Bayesian bounds, but the role of the CGF in defining an optimal posterior $\\rho$ is novel compared to previous bounds. We explore the implications of this fact in Section 5. ", "page_idx": 5}, {"type": "text", "text": "4 Relation with previous bounds ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We first relate Theorem 7 to previous bounds. As a first application, we show how some well-known PAC-Bayes bounds can be recovered from ours. When the distribution of the loss is known, we can often compute its Cram\u00e9r transform. This happens to be the case with the zero-one loss, where we recover Langford-Seeger\u2019s bound (Seeger, 2002, Theorem 1). ", "page_idx": 5}, {"type": "text", "text": "Corollary 8. Let $\\ell$ be the $0-1$ loss and $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\nk l\\left(\\mathbb{E}_{\\rho}[\\hat{L}(\\pmb{\\theta},D)],\\mathbb{E}_{\\rho}[L(\\pmb{\\theta})]\\right)\\leq\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 5}, {"type": "text", "text": "The dependence on $n$ in Corollary 8 was further improved by Maurer (2004). However, our version is enough to illustrate the role played by Cr\u00e1mer transforms in obtaining tight PAC-Bayes bounds, which is a recent line of work by Foong et al. (2021) and Hellstr\u00f6m and Guedj (2024). ", "page_idx": 5}, {"type": "text", "text": "When the loss is of bounded CGF \u2014recall Definition 2\u2014, Theorem 7 results in a generalization of Theorem 3, where the bound holds simultaneously for every $\\lambda\\in(0,b)$ with a $\\log n$ penalty. ", "page_idx": 5}, {"type": "text", "text": "Corollary 9. Let \u2113be a loss function with $\\psi$ -bounded CGF. Let $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\operatorname*{inf}_{\\lambda\\in[0,b)}\\left\\{\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{\\lambda(n-1)}+\\frac{\\psi(\\lambda)}{\\lambda}\\right\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 5}, {"type": "text", "text": "Proof. Directly follows from the definition of $\\psi$ -bounded CGF and Theorem 7. ", "page_idx": 5}, {"type": "text", "text": "Corollary 9 is the first PAC-Bayes bound that allows exact optimization of the free parameter $\\lambda\\geq0$ for the general case of losses with bounded CGF without resorting to union-bound approaches (Seldin et al., 2012; Rodr\u00edguez-G\u00e1lvez et al., 2024), which cannot guarantee an exact minimization. Although in the particular case of sub-Gaussian losses the $\\log n$ penalty is worse than that in Hellstr\u00f6m and ", "page_idx": 5}, {"type": "text", "text": "Durisi (2021), when $\\begin{array}{r}{K L(\\rho|\\pi)\\geq\\frac{\\sqrt{6n/e}}{\\pi}-1}\\end{array}$ , Corollary 9 is tighter than the general Theorem 14 in Rodr\u00edguez-G\u00e1lvez et al. (2024). We instantiate Corollary 9 in the case of sub-Gaussian and sub-gamma losses in the Appendix B. ", "page_idx": 5}, {"type": "text", "text": "5 PAC-Bayes bounds under model-dependent assumptions ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "As discussed in the introduction, most boundedness conditions used to bound the exponential moment term in Theorem 7 discard information about the statistical properties of individual models. In this section, we show that the structure of Theorem 7 allows for a more fine-grained control of the CGFs, resulting in potentially tighter and more informative bounds. We start by generalizing Definition 2. ", "page_idx": 5}, {"type": "text", "text": "Definition 10 (Model-dependent bounded CGF). A loss function $\\ell$ has model-dependent bounded CGF if for each $\\theta\\in\\Theta$ , there is a convex and continuously differentiable function $\\bar{\\psi}(\\pmb\\theta,\\lambda)$ such that $\\psi(\\pmb\\theta,0)=\\psi^{\\prime}(\\pmb\\theta,0)=0$ and for any $\\lambda\\in[0,b)$ , ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Lambda_{\\pmb\\theta}(\\lambda):=\\log\\mathbb{E}_{\\nu}\\left[e^{\\lambda\\left(L(\\pmb\\theta)-\\ell(\\pmb x,\\pmb\\theta)\\right)}\\right]\\leq\\psi(\\pmb\\theta,\\lambda)\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "As motivated in Figure 1 and in opposition to Definition 2, this new condition acknowledges the possibility of having different bounding functions, $\\psi(\\pmb\\theta,\\lambda)$ , for each $\\Lambda_{\\theta}(\\lambda)$ . ", "page_idx": 6}, {"type": "text", "text": "Using this definition, we can easily exploit Theorem 7 to derive the following bound: ", "page_idx": 6}, {"type": "text", "text": "Theorem 11. Let $\\ell$ be a loss function satisfying Definition $I O$ . Let $\\pi\\,\\in\\,\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\operatorname*{inf}_{\\lambda\\in[0,b)}\\left\\{\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{\\lambda(n-1)}+\\frac{\\mathbb{E}_{\\rho}[\\psi(\\pmb\\theta,\\lambda)]}{\\lambda}\\right\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 6}, {"type": "text", "text": "Proof. The proof is analogue to that of Corollary 9. ", "page_idx": 6}, {"type": "text", "text": "This theorem can be understood as a PAC-Bayesian version of Theorem 2 in Jiao et al. (2017), where we allow infinite model classes. Note that if we tried to exploit this model-dependent CGF assumption on other oracle bounds, as the one shown in Theorem 1, we would end with an empirical bound where the $\\psi(\\pmb\\theta,\\lambda)$ term would be exponentially averaged by the prior, $\\ln\\mathbb{E}_{\\pi}[e^{\\psi(\\pmb{\\theta},\\lambda)}]$ , instead of having the more amenable term $\\mathbb{E}_{\\rho}[\\psi(\\pmb{\\theta},\\lambda)]$ , which directly impacts on the choice of the optimal posterior $\\rho^{\\star}$ . ", "page_idx": 6}, {"type": "text", "text": "As discussed in Section 3, the posterior distribution in Theorem 11 is involved in a three-way trade-off which has the potential to result in tighter bounds and the design of better posteriors. It is worth noting that the posterior minimizing the bound in Theorem 11 is not the standard Gibbs posterior. ", "page_idx": 6}, {"type": "text", "text": "Proposition 12. If we fix some $\\lambda>0,$ , the bound in Theorem $_{l l}$ can be minimized with respect to $\\rho\\in\\bar{\\mathcal{M}}_{1}(\\Theta)$ . The optimal posterior is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\rho^{*}(\\pmb{\\theta})\\propto\\pi(\\pmb{\\theta})\\exp\\left\\{-(n-1)\\lambda\\hat{L}(D,\\pmb{\\theta})-(n-1)\\psi(\\pmb{\\theta},\\lambda)\\right\\}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Observe that under the posterior in Proposition 12, the maximum a posteriori (MAP) estimate is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\theta_{\\mathrm{MAP}}=\\underset{\\theta\\in\\Theta}{\\mathrm{arg}\\,\\mathrm{min}}\\left\\{\\hat{L}(D,\\theta)+\\frac{1}{\\lambda}\\psi(\\pmb\\theta,\\lambda)-\\frac{1}{\\lambda(n-1)}\\ln\\pi(\\pmb\\theta)\\right\\}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "As we will illustrate below, the extra term, $\\psi(\\pmb\\theta,\\lambda)$ , can often be understood as a regularizer. In what remains, we exemplify the general recipe of Theorem 11 in several cases. To start providing concrete intuition, we instantiate Corollary 11 in the case of sub-Gaussian losses. ", "page_idx": 6}, {"type": "text", "text": "Generalized sub-Gaussian losses ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "It is well known that if $X$ is a $\\sigma^{2}$ -sub-Gaussian random variable, we have $\\mathbb{V}(X)\\leq\\sigma^{2}$ (Arbel et al., 2020). In many cases, it might not be reasonable to bound $\\mathbb{V}_{\\nu}(\\ell(\\pmb{\\theta},X))\\,\\leq\\,\\sigma^{2}$ for every $\\theta\\in\\Theta$ , because the variance of the loss function highly depends on the particular model, as illustrated in Figure 1. This is where Corollary 11 comes into play: we may assume that $\\ell(\\pmb\\theta,X)$ is $\\sigma(\\pmb\\theta)^{2}$ -subGaussian for each $\\theta\\in\\Theta$ . In this case the variance proxy $\\sigma(\\pmb\\theta)^{2}$ is specific for each model, leading to the following bound: ", "page_idx": 6}, {"type": "text", "text": "Corollary 13. Assume the loss $\\ell(\\pmb\\theta,X)$ is $\\sigma^{2}(\\pmb\\theta)$ -sub-Gaussian. Let $\\pi\\,\\in\\,\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\sqrt{2\\mathbb{E}_{\\rho}[\\sigma(\\pmb\\theta)^{2}]\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1}},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 6}, {"type": "text", "text": "Proof. Use Theorem 11 and the fact that $\\begin{array}{r}{\\psi(\\pmb\\theta,\\lambda)=\\frac{\\lambda^{2}\\sigma^{2}(\\pmb\\theta)}{2}}\\end{array}$ . Then optimize $\\lambda$ ", "page_idx": 6}, {"type": "text", "text": "This result generalizes sub-Gaussian PAC-Bayes bounds \u2014Corollary 2 in Hellstr\u00f6m and Durisi (2021) or Corollary 19\u2014 and shows that posteriors favoring models with small variance-proxy, $\\sigma^{2}(\\pmb\\theta)$ , generalize better. It is, therefore, potentially tighter than previous results, because the $\\bar{\\sigma^{2}}$ factor in standard sub-Gaussian bounds is a worst-case constant, while Corollary 13 exploits the fact that some models have much smaller variance-proxy than others. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Analogous bounds can be straightforwardly derived for generalized sub-gamma or sub-exponential losses, but Theorem 11 is not limited to explicit tail assumptions on the loss. The following subsections explore model-dependent assumptions on $\\Lambda_{\\theta}(\\lambda)$ that result in novel PAC-Bayes bounds involving well-known regularization techniques. ", "page_idx": 7}, {"type": "text", "text": "L2 regularization ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now introduce bounds based on the norm of the model parameters. For that purpose we use the following standard assumption in machine learning (Li and Orabona, 2019). ", "page_idx": 7}, {"type": "text", "text": "Assumption 1 (Parameter Lipschitz). The loss function $\\ell(x,\\pmb\\theta)$ is $M$ -Lipschitz with respect to $\\pmb{\\theta}$ , that is, for any $\\theta\\in\\Theta$ and any $x\\in\\mathcal{X}$ we have $\\|\\nabla_{\\theta}\\ell(\\mathbf{x},\\pmb{\\theta})\\|_{2}^{2}\\leq\\dot{M}$ . ", "page_idx": 7}, {"type": "text", "text": "If the model class is parametrized in such a way that the model with null parameter vector has null variance \u2014i.e., $\\mathbb{V}_{\\nu}(\\bar{\\ell}({\\boldsymbol{\\mathbf{x}}},0))\\,=\\,0$ , which is the case of a neural net with null weights\u2014, then, as shown in Masegosa and Ortega (2023), we can derive the following model-dependent bound for the CGF: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\Lambda_{\\pmb\\theta}(\\lambda)\\leq2M\\lambda^{2}\\|\\pmb\\theta\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "This case further illustrates the idea we motivated in the introduction: bounding the CGFs with model-dependent proxies for generalization. Figure 1 illustrates how models with smaller norm has increasingly smaller CGFs. ", "page_idx": 7}, {"type": "text", "text": "Using Equation (14) we obtain the following generalization bound penalizing model\u2019s L2-norm: ", "page_idx": 7}, {"type": "text", "text": "Corollary 14. If Assumption 1 holds, then for any prior distribution $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ independent of $D$ and any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws $D\\sim\\nu^{n}$ , ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\sqrt{2M\\mathbb{E}_{\\rho}\\left[\\|\\pmb\\theta\\|_{2}^{2}\\right]\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1}},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 7}, {"type": "text", "text": "Proof. The result follows from using $\\psi(\\pmb\\theta,\\lambda)=2M\\lambda^{2}\\|\\pmb\\theta\\|_{2}^{2}$ in Theorem 11 and optimizing $\\lambda$ . ", "page_idx": 7}, {"type": "text", "text": "Corollary 14 shows that models with smaller parameter norms generalize better, and provides PACBayesian certificates for norm-based regularization. Many other PAC-Bayesian bounds contains different kind of parameter norms (Germain et al., 2009, 2016; Neyshabur et al., 2017), but their parameter norm term is always introduced through the prior \u2014e.g., using a zero-centered Gaussian prior distribution\u2014. The novelty here is that this parameter norm term appears independently of the prior as a result of Theorem 11. ", "page_idx": 7}, {"type": "text", "text": "According to Proposition 12, the MAP estimate of the optimal posterior is, $\\begin{array}{r l}{\\theta_{\\mathrm{MAP}}}&{{}=}\\end{array}$ arg min\u03b8 $\\begin{array}{r l}{\\bigl\\{\\hat{L}(D,\\pmb{\\theta})+\\frac{2M}{\\lambda}\\|\\pmb{\\theta}\\|_{2}^{2}-\\frac{1}{\\lambda(n-1)}\\ln\\pi(\\pmb{\\theta})\\bigr\\}}&{{}}\\end{array}$ , which is the result of L2-regularization with tradeoff parameter $\\frac{2M}{\\lambda}$ . ", "page_idx": 7}, {"type": "text", "text": "Gradient-based regularization ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We finish this section providing novel bounds based on log-Sobolev inequalities that include a gradient term penalizing the sensitivity of models to small changes in the input data. First, let us simplify the notation for this section. We use $\\|\\nabla_{\\pmb{x}}\\ell\\|_{2}^{2}\\,:=\\,\\mathbb{E}_{\\nu}\\|\\nabla_{\\pmb{x}}\\ell(\\pmb{x},\\pmb{\\theta})\\|_{2}^{2}$ and $\\|\\widehat{\\nabla}_{\\mathbf{x}}\\ell\\|_{2}^{2}~:=$ $\\begin{array}{r}{\\frac{1}{n}\\sum_{i=1}^{n}\\|\\dot{\\nabla}_{\\pmb{x}}\\ell(\\pmb{x}_{i},\\pmb{\\theta})\\|_{2}^{2}}\\end{array}$ to denote the expected and empirical (squared) gradient norms of the loss. ", "page_idx": 7}, {"type": "text", "text": "Including a gradient-based penalization is the idea behind input-gradient regularization (Varga et al., 2017), which minimizes an objective function of the form $\\begin{array}{r}{\\bar{L}(\\bar{D0},\\pmb{\\theta})+\\frac{1}{k}\\|\\bar{\\widehat{\\nabla}}_{\\pmb{x}}\\ell\\|_{2}^{2}}\\end{array}$ , where $k>0$ is a trade-off parameter. This approach is often used to make models more robust against disturbances in input data and adversarial attacks (Ross and Doshi-Velez, 2018; Finlay and Oberman, 2021). ", "page_idx": 7}, {"type": "text", "text": "We make the connection between PAC-Bayes bounds and gradient norms assuming that $\\nu$ and $\\ell$ satisfy certain log-Sobolev inequality (Chafa\u00ef, 2004). ", "page_idx": 7}, {"type": "text", "text": "Assumption 2 (log-Sobolev). For any $\\theta\\in\\Theta$ and any $\\lambda>0$ , we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\Lambda_{\\theta}(\\lambda)\\leq\\frac{C}{2}\\lambda^{2}\\|\\nabla_{\\pmb{x}}\\ell\\|_{2}^{2},\\mathrm{~for~some~}C>0.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "For example, Assumption 2 holds when $\\nu$ is strictly uniformly log-concave, as shown in Corollary 2.1 of Chafa\u00ef (2004) \u2014this case includes the Gaussian and Weibull densities (Saumard and Wellner, 2014)\u2014. We also try to empirically verify Assumption 2 for certain class of neural networks in Appendix C.2. Assumption 2 is going to be our model-dependent bound on the CGF. We first provide a bound for expected gradients. ", "page_idx": 8}, {"type": "text", "text": "Theorem 15. If Assumption 2 is satisfied, then for any prior distribution $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ independent of $D$ and any $\\delta_{1}\\in(0,1)$ , with probability at least $1-\\delta_{1}$ over draws $D\\sim\\nu^{n}$ , ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\sqrt{2C\\mathbb{E}_{\\rho}\\left[\\|\\nabla_{\\pmb x}\\ell\\|_{2}^{2}\\right]\\frac{K L(\\rho||\\pi)+\\log\\frac{n}{\\delta_{1}}}{n-1}}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 8}, {"type": "text", "text": "Proof. Follows from the application Assumption 2 to Theorem 11 and the optimization of $\\lambda$ . ", "page_idx": 8}, {"type": "text", "text": "This bound shows that \u2014under certain regularity conditions\u2014 posteriors favoring models with smaller expected gradients, $\\|\\nabla_{\\mathbf{x}}\\ell\\|_{2}^{2}$ , generalize better, which is the heuristic behind input-gradient regularization (Varga et al., 2017). However, Theorem 15 is still an oracle bound. We can obtain a new, fully empirical one if we concatenate Corollary 15 with a PAC-Bayes concentration bound for $\\mathbb{E}_{\\rho}\\left[\\|\\nabla_{\\mathbf{\\boldsymbol{x}}}\\bar{\\ell}\\|_{2}^{2}\\right]$ . This can be done if we assume that the loss is Lipschitz w.r.t. the input-data. ", "page_idx": 8}, {"type": "text", "text": "Assumption 3 (Input-data Lipschitz). For any $\\theta\\in\\Theta$ and for any $\\pmb{x}\\in\\mathcal{X}$ , we have $\\|\\nabla_{\\pmb{x}}\\ell(\\pmb{x},\\pmb{\\theta})\\|_{2}^{2}\\leq L$ ", "page_idx": 8}, {"type": "text", "text": "Assumption 3 is satisfied in standard deep neural network architectures, and the Lipschitz constant can be efficiently estimated (Virmaux and Scaman, 2018; Fazlyab et al., 2019). ", "page_idx": 8}, {"type": "text", "text": "Theorem 16. If Assumptions 2 and 3 are satisfied, then for any prior distribution $\\pi\\,\\in\\,\\mathcal{M}_{1}(\\Theta)$ independent of $D$ and any $\\delta\\in(0,1)$ ; with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\rho}[L(\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\theta)]+\\sqrt{2C\\mathbb{E}_{\\rho}\\left[\\|\\widehat\\nabla_{x}\\ell\\|_{2}^{2}\\right]\\cdot K(\\rho,\\pi,n,\\delta)+\\sqrt{2}C L\\cdot K(\\rho,\\pi,n,\\delta)^{\\frac{3}{2}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ , where $\\begin{array}{r}{K(\\rho,\\pi,n,\\delta):=\\frac{K L(\\rho|\\pi)+\\log\\frac{2n}{\\delta}}{n-1}}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "With minimal modifications, the result above also holds under the assumption that on-average gradients are bounded, $\\|\\nabla_{\\mathbf x}\\ell\\|_{2}^{2}\\leq g$ , or when $\\|\\nabla_{\\mathbf{x}}\\ell(\\pmb{\\theta},X)\\|_{2}^{2}$ are sub-Gaussian. ", "page_idx": 8}, {"type": "text", "text": "Similar bounds with input-gradients were first introduced by Gat et al. (2022) under the assumption that the underlying distribution of data was a mixture of Gaussians plus a technical \u201cper-label loss balance\u201d assumption. However, Theorem 16 is, as far as we know, the first empirical PAC-Bayes bound for input-gradients. Furthermore, in contrast with Gat et al. (2022), our bounds optimize the free parameter $\\lambda$ and explicitly relate the gradients with the generalization ability of the posterior $\\rho\\,\\in\\,\\mathcal{M}_{1}(\\Theta)$ . The recent work of Haddouche et al. (2024) also includes gradient terms in their bounds, but they are gradients with respect to the model parameter, not input-gradients. ", "page_idx": 8}, {"type": "text", "text": "As for the optimal posterior $\\rho^{*}$ , if we minimize the bound in Theorem 15 for a fixed $\\lambda>0$ , the MAP estimate in Proposition 12 is $\\begin{array}{r}{\\theta_{\\mathrm{MAP}}=\\arg\\operatorname*{min}_{\\theta}\\{\\hat{L}(D,\\pmb\\theta)+\\lambda\\frac{C}{2}\\|\\nabla_{\\pmb x}\\ell\\|_{2}^{2}-\\frac{1}{\\lambda(n-1)}\\ln\\pi(\\pmb\\theta)\\}.}\\end{array}$ , which is the result of input-gradient regularization with trade-off parameter $\\ensuremath{\\frac{\\lambda C}{2}}$ . ", "page_idx": 8}, {"type": "text", "text": "In conclusion, the approach suggested by Theorem 11 not only provides novel insights \u2014in the form of tight bounds or PAC-Bayesian interpretations of previously known algorithms\u2014, it also hints towards the design of new regularized learning algorithms with solid theoretical guarantees. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We derived a novel PAC-Bayes oracle bound using basic properties of the Cram\u00e9r transform \u2014 Theorem 7\u2014. In general, our work aligns with very recent literature (Rodr\u00edguez-G\u00e1lvez et al., ", "page_idx": 8}, {"type": "text", "text": "2024; Hellstr\u00f6m et al., 2023) that highlights the importance of Cram\u00e9r transforms in the quest for tight PAC-Bayes bounds. This bound has the potential to be a stepping stone in the development of novel, tighter empirical PAC-Bayes bounds for unbounded losses. Firstly, because it allows exact optimization of the free parameter $\\lambda\\ >\\ 0$ without the need for more convoluted unionbound approaches. But, more relevantly, because it allows the introduction of flexible, fine-grained, model-dependent assumptions for bounding the CGF \u2014Theorem 11\u2014 which results in optimal distributions beyond Gibbs\u2019 posterior. The importance and wide applicability of this result have been illustrated with three model-dependent assumptions: generalized sub-Gaussian losses, bounds based on parameter norms, and input-gradients based on log-Sobolev inequalities. In the last case we introduce PAC-Bayes bounds including empirical input-gradients norms. ", "page_idx": 9}, {"type": "text", "text": "Limitations and future work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "A limitation of our approach is that the we are implicitly assuming that $\\ell(\\pmb\\theta,X)$ is light-tailed (equivalently, sub-exponential), as in every Cram\u00e9r-Chernoff bound. This is only partially true. Although there are specific studies for heavy-tailed losses (Alquier and Guedj, 2018; Holland, 2019; Haddouche and Guedj, 2023; Chugg et al., 2023), we avoid this limitation because we are only interested in the right tail of $g e n(\\pmb\\theta,D)$ \u2014that is, $\\mathbb{P}_{\\nu}(L(\\pmb\\theta)-\\hat{L}(D,\\pmb\\theta)\\geq a)$ for $a\\geq0$ \u2014. This is done by defining the CGF only for $\\lambda\\geq0$ . In this way, as we show in Remark 17, the finiteness of $\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]$ guarantees the existence of $\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}(\\lambda)]$ in Theorem 7. This approach is motivated by the fact that most state-of-the-art models lie in the interpolating regime, hence $\\mathbb{P}_{\\nu}(\\hat{L}(D,\\pmb{\\theta})-L(\\pmb{\\theta})\\geq a)$ for $a\\geq0$ has less practical importance. However, in the case where one is looking for two-tailed bounds, our work is restricted to sub-exponential losses. See the discussion on Section 4.2.1 of Zhang et al. (2024). ", "page_idx": 9}, {"type": "text", "text": "Given the generality of Theorem 7, the dependence of the logarithmic penalty term in the bound may be suboptimal in certain cases, as discussed in Section 4. Going beyond Lemma 6 and improving this dependence is one of the main open tasks. ", "page_idx": 9}, {"type": "text", "text": "Our results provide a systematic approach for integrating general model-dependent CGF bounds into PAC-Bayes theory, and can open exciting new research lines: they can provide a PAC-Bayesian extension of the work of Masegosa and Ortega (2023), which studies the effects of different regularization techniques and the role of invariant architectures, data augmentation and over-parametrization in generalization. Since our bounds can be applied to unbounded losses such as the log-loss, it could be interesting to apply them in a Bayesian setting (Germain et al., 2016) in order to study the relation between marginal likelihood and generalization (Lotf iet al., 2022). ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and disclosure of funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "IC acknowledges financial support from the Basque Government through the IKUR program. LO acknowledges financial support from project PID2022-139856NB-I00 funded by MCIN/ AEI/ 10.13039/501100011033/FEDER, UE and from the Autonomous Community of Madrid (ELLIS Unit Madrid). AP acknowledges financial support by the Basque Government through the BERC 2022-2025 program and Elkartek program (KK-2023/00038), and by the Ministry of Science and Innovation: BCAM Severo Ochoa accreditation CEX2021-001142- S/MICIN/AEI/10.13039/501100011033. AM acknowledges financial support from Grant PID2022- 139293NB-C31 funded by MCIN/AEI/10.13039/501100011033 and by ERDF A way of making Europe. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Pierre Alquier. User-friendly introduction to PAC-Bayes bounds. Foundations and Trends\u00ae in Machine Learning, 17(2):174\u2013303, 2024.   \nPierre Alquier and Benjamin Guedj. An oracle inequality for quasi-Bayesian nonnegative matrix factorization. Mathematical Methods of Statistics, 26:55\u201367, 2017.   \nPierre Alquier and Benjamin Guedj. Simpler PAC-Bayesian bounds for hostile data. Machine Learning, 107(5):887\u2013902, 2018.   \nPierre Alquier and Karim Lounici. PAC-Bayesian bounds for sparse regression estimation with exponential weights. Electronic Journal of Statistics, 5:127 \u2013 145, 2011.   \nPierre Alquier, James Ridgway, and Nicolas Chopin. On the properties of variational approximations of Gibbs posteriors. Journal of Machine Learning Research, 17(1):8374\u20138414, 2016.   \nJulyan Arbel, Olivier Marchal, and Hien D Nguyen. On strict sub-Gaussianity, optimal proxy variance and symmetry for bounded random variables. ESAIM: Probability and Statistics, 24:39\u201355, 2020.   \nPradeep Kr Banerjee and Guido Mont\u00fafar. Information complexity and generalization bounds. In 2021 IEEE International Symposium on Information Theory (ISIT), pages 676\u2013681. IEEE, 2021.   \nLuc B\u00e9gin, Pascal Germain, Fran\u00e7ois Laviolette, and Jean-Francis Roy. PAC-Bayesian bounds based on the R\u00e9nyi divergence. In Artificial Intelligence and Statistics, pages 435\u2013444. PMLR, 2016.   \nChristopher M. Bishop. Pattern Recognition and Machine Learning. Springer New York, NY, 2006.   \nSt\u00e9phane Boucheron, G\u00e1bor Lugosi, and Pascal Massart. Concentration inequalities: A nonasymptotic theory of independence. Oxford University Press, 2013.   \nOlivier Catoni. Statistical learning theory and stochastic optimization: Ecole d\u2019Et\u00e9 de Probabilit\u00e9s de Saint-Flour, XXXI-2001, volume 1851 of Lecture Notes in Mathematics. Springer Science & Business Media, 2004.   \nOlivier Catoni. PAC-Bayesian Supervised Classification: The Thermodynamics of Statistical Learning, volume 1277 of IMS Lecture Notes-Monograph Series. 2007.   \nDjalil Chafa\u00ef. Entropies, convexity, and functional inequalities, on $\\Phi$ -entropies and $\\Phi$ -sobolev inequalities. Journal of Mathematics of Kyoto University, 44(2):325\u2013363, 2004.   \nBen Chugg, Hongjian Wang, and Aaditya Ramdas. A unified recipe for deriving (time-uniform) PAC-Bayes bounds. Journal of Machine Learning Research, 24(372):1\u201361, 2023.   \nAmir Dembo and Ofer Zeitouni. Large deviations techniques and applications, volume 38 of Stochastic Modelling and Applied Probability. Springer Science & Business Media, 2009.   \nMonroe D Donsker and SR Srinivasa Varadhan. Asymptotic evaluation of certain Markov process expectations for large time, I. Communications on Pure and Applied Mathematics, 28(1):1\u201347, 1975.   \nGintare Karolina Dziugaite and Daniel M Roy. Computing nonvacuous generalization bounds for deep (stochastic) neural networks with many more parameters than training data. arXiv preprint arXiv:1703.11008, 2017.   \nPaul Embrechts and Marius Hofert. A note on generalized inverses. Mathematical Methods of Operations Research, 77:423\u2013432, 2013.   \nMahyar Fazlyab, Alexander Robey, Hamed Hassani, Manfred Morari, and George Pappas. Efficient and accurate estimation of Lipschitz constants for Deep Neural Networks. Advances in Neural Information Processing Systems, 32, 2019.   \nChris Finlay and Adam M Oberman. Scaleable input gradient regularization for adversarial robustness. Machine Learning with Applications, 3:100017, 2021.   \nAndrew Foong, Wessel Bruinsma, David Burt, and Richard Turner. How tight can PAC-Bayes be in the small data regime? Advances in Neural Information Processing Systems, 34:4093\u20134105, 2021.   \nNina Gantert, Steven Soojin Kim, and Kavita Ramanan. Cram\u00e9r\u2019s theorem is atypical. In Gail Letzter, Kristin Lauter, Erin Chambers, Nancy Flournoy, Julia Elisenda Grigsby, Carla Martin, Kathleen Ryan, and Konstantina Trivisa, editors, Advances in the Mathematical Sciences, pages 253\u2013270, Cham, 2016. Springer International Publishing.   \nItai Gat, Yossi Adi, Alex Schwing, and Tamir Hazan. On the importance of gradient norm in PAC-Bayesian bounds. Advances in Neural Information Processing Systems, 35:16068\u201316081, 2022.   \nPascal Germain, Alexandre Lacasse, Mario Marchand, Sara Shanian, and Fran\u00e7ois Laviolette. From PAC-Bayes bounds to KL regularization. Advances in Neural Information Processing Systems, 22, 2009.   \nPascal Germain, Francis Bach, Alexandre Lacoste, and Simon Lacoste-Julien. PAC-Bayesian theory meets Bayesian inference. Advances in Neural Information Processing Systems, 29, 2016.   \nBenjamin Guedj. A primer on PAC-Bayesian learning. arXiv preprint arXiv:1901.05353, 2019.   \nBenjamin Guedj and Louis Pujol. Still no free lunches: the price to pay for tighter PAC-Bayes bounds. Entropy, 23(11):1529, 2021.   \nMaxime Haddouche and Benjamin Guedj. PAC-Bayes generalization bounds for heavy-tailed losses through supermartingales. Transactions on Machine Learning Research, 2023.   \nMaxime Haddouche, Benjamin Guedj, and John Shawe-Taylor. Upper and lower bounds on the performance of kernel PCA. arXiv preprint arXiv:2012.10369, 2020.   \nMaxime Haddouche, Benjamin Guedj, Omar Rivasplata, and John Shawe-Taylor. PAC-Bayes unleashed: Generalisation bounds with unbounded losses. Entropy, 23(10):1330, 2021.   \nMaxime Haddouche, Paul Viallard, Umut Simsekli, and Benjamin Guedj. A PAC-Bayesian link between generalisation and flat minima. arXiv preprint arXiv:2402.08508, 2024.   \nFredrik Hellstr\u00f6m and Giuseppe Durisi. Generalization bounds via information density and conditional information density. IEEE Journal on Selected Areas in Information Theory, 1(3):824\u2013839, 2020.   \nFredrik Hellstr\u00f6m and Benjamin Guedj. Comparing comparators in generalization bounds. In International Conference on Artificial Intelligence and Statistics, pages 73\u201381. PMLR, 2024.   \nFredrik Hellstr\u00f6m and Giuseppe Durisi. Corrections to \u201cGeneralization bounds via information density and conditional information density\u201d. IEEE Journal on Selected Areas in Information Theory, 2(3):1072\u20131073, 2021.   \nFredrik Hellstr\u00f6m, Giuseppe Durisi, Benjamin Guedj, and Maxim Raginsky. Generalization Bounds: Perspectives from Information Theory and PAC-Bayes. arXiv preprint arXiv:2309.04381, 2023.   \nMatthew Holland. PAC-Bayes under potentially heavy tails. Advances in Neural Information Processing Systems, 32, 2019.   \nJiantao Jiao, Yanjun Han, and Tsachy Weissman. Dependence measures bounding the exploration bias for general measurements. In 2017 IEEE International Symposium on Information Theory (ISIT), pages 1475\u20131479. IEEE, 2017.   \nAlex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. Technical report, Toronto, ON, Canada, 2009.   \nJohn Langford and Matthias Seeger. Bounds for averaging classifiers. Technical report, School of Computer Science, Carnegie Mellon University, 2001.   \nXiaoyu Li and Francesco Orabona. On the convergence of stochastic gradient descent with adaptive stepsizes. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 983\u2013992. PMLR, 2019.   \nSanae Lotf,i Pavel Izmailov, Gregory Benton, Micah Goldblum, and Andrew Gordon Wilson. Bayesian model selection, the marginal likelihood, and generalization. In International Conference on Machine Learning, pages 14223\u201314247. PMLR, 2022.   \nAndr\u00e9s Masegosa, Stephan Lorenzen, Christian Igel, and Yevgeny Seldin. Second order PACBayesian bounds for the weighted majority vote. Advances in Neural Information Processing Systems, 33:5263\u20135273, 2020.   \nAndr\u00e9s R Masegosa and Luis A Ortega. PAC-Chernoff Bounds: Understanding Generalization in the Interpolation Regime. arXiv preprint arXiv:2306.10947, 2023.   \nAndr\u00e9s Masegosa. Learning under model misspecification: Applications to variational and ensemble methods. Advances in Neural Information Processing Systems, 33:5479\u20135491, 2020.   \nAndreas Maurer. A note on the PAC Bayesian theorem. arXiv preprint cs/0411099, 2004.   \nDavid A McAllester. Some PAC-Bayesian theorems. In Proceedings of the 11th annual conference on Computational Learning Theory, pages 230\u2013234. ACM, 1998.   \nDavid A McAllester. PAC-Bayesian model averaging. In Proceedings of the 12th annual conference on Computational Learning theory, pages 164\u2013170. ACM, 1999.   \nDavid A McAllester. PAC-Bayesian stochastic model selection. Machine Learning, 51:5\u201321, 2003.   \nBehnam Neyshabur, Srinadh Bhojanapalli, and Nathan Srebro. A PAC-Bayesian approach to spectrally-normalized margin bounds for neural networks. arXiv preprint arXiv:1707.09564, 2017.   \nLuis A Ortega, Rafael Caba\u00f1as, and Andres Masegosa. Diversity and generalization in neural network ensembles. In International Conference on Artificial Intelligence and Statistics, pages 11720\u201311743. PMLR, 2022.   \nDavid Reeb, Andreas Doerr, Sebastian Gerwinn, and Barbara Rakitsch. Learning Gaussian processes by minimizing PAC-Bayesian generalization bounds. Advances in Neural Information Processing Systems, 31, 2018.   \nOmar Rivasplata, Vikram M Tankasali, and Csaba Szepesvari. PAC-Bayes with backprop. arXiv preprint arXiv:1908.07380, 2019.   \nOmar Rivasplata, Ilja Kuzborskij, Csaba Szepesv\u00e1ri, and John Shawe-Taylor. PAC-Bayes analysis beyond the usual bounds. Advances in Neural Information Processing Systems, 33:16833\u201316845, 2020.   \nBorja Rodr\u00edguez-G\u00e1lvez, Ragnar Thobaben, and Mikael Skoglund. More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime validity. Journal of Machine Learning Research, 25(110):1\u201343, 2024.   \nAndrew Ross and Finale Doshi-Velez. Improving the adversarial robustness and interpretability of deep neural networks by regularizing their input gradients. In Proceedings of the AAAI conference on artificial intelligence, 2018.   \nAdrien Saumard and Jon A Wellner. Log-concavity and strong log-concavity: a review. Statistics surveys, 8:45, 2014.   \nMatthias Seeger. PAC-Bayesian generalisation error bounds for Gaussian process classification. Journal of machine learning research, 3(Oct):233\u2013269, 2002.   \nYevgeny Seldin, Nicol\u00f2 Cesa-Bianchi, Peter Auer, Fran\u00e7ois Laviolette, and John Shawe-Taylor. PAC-Bayes-Bernstein inequality for martingales and its application to multiarmed bandits. In Proceedings of the Workshop on On-line Trading of Exploration and Exploitation 2, pages 98\u2013111. JMLR Workshop and Conference Proceedings, 2012.   \nJohn Shawe-Taylor and Robert C. Williamson. A PAC analysis of a Bayesian estimator. In Proceedings of the 10th annual conference on Computational Learning theory, pages 2\u20139. ACM, 1997.   \nChristian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2818\u20132826, 2016.   \nNiklas Thiemann, Christian Igel, Olivier Wintenberger, and Yevgeny Seldin. A strongly quasiconvex PAC-Bayesian bound. In International Conference on Algorithmic Learning Theory, pages 466\u2013 492. PMLR, 2017.   \nD\u00e1niel Varga, Adri\u00e1n Csisz\u00e1rik, and Zsolt Zombori. Gradient regularization improves accuracy of discriminative models. arXiv preprint arXiv:1712.09936, 2017.   \nAladin Virmaux and Kevin Scaman. Lipschitz regularity of deep neural networks: analysis and efficient estimation. Advances in Neural Information Processing Systems, 31, 2018.   \nYi-Shan Wu, Andres Masegosa, Stephan Lorenzen, Christian Igel, and Yevgeny Seldin. ChebyshevCantelli PAC-Bayes-Bennett inequality for the weighted majority vote. Advances in Neural Information Processing Systems, 34:12625\u201312636, 2021.   \nAolin Xu and Maxim Raginsky. Information-theoretic analysis of generalization capability of learning algorithms. Advances in Neural Information Processing Systems, 30, 2017.   \nChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. International Conference on Learning Representations, 2017.   \nXitong Zhang, Avrajit Ghosh, Guangliang Liu, and Rongrong Wang. Improving generalization of complex models under unbounded loss using PAC-Bayes bounds. Transactions on Machine Learning Research, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We first gather some standard properties of CGFs and Cram\u00e9r transforms. ", "page_idx": 14}, {"type": "text", "text": "Let $\\mathcal{D}_{\\Lambda_{\\theta}}:=\\{\\lambda\\in\\mathbb{R}_{+}\\,\\vert\\,\\Lambda_{\\theta}(\\lambda)\\,<\\,\\infty\\}$ . Under the assumption that there is some $\\lambda>0$ such that $\\Lambda_{\\theta}(\\lambda)<\\infty$ , we have $\\mathcal{D}_{\\Lambda_{\\theta}}=[0,b)$ for some $b>0$ . Furthermore, $\\Lambda_{\\theta}$ is strictly convex and ${\\mathcal{C}}^{\\infty}$ on $(0,b)$ (Boucheron et al., 2013, Section 2.2). ", "page_idx": 14}, {"type": "text", "text": "In particular, since for any $\\lambda>0$ we have $\\Lambda_{\\theta}(\\lambda):=\\log\\mathbb{E}_{\\nu}\\left[e^{\\lambda(L(\\theta)-\\ell(x,\\theta))}\\right]\\le\\log\\mathbb{E}_{\\nu}\\left[e^{\\lambda L(\\theta)}\\right]=$ $\\lambda L(\\pmb\\theta)<\\infty$ because $\\ell\\geq0$ , we verify that $\\mathcal{D}_{\\Lambda_{\\theta}}=[0,\\infty)$ and that $\\Lambda_{\\theta}$ is strictly convex and ${\\mathcal{C}}^{\\infty}$ on $(0,\\infty)$ . ", "page_idx": 14}, {"type": "text", "text": "Remark 17. Observe that the previous proof also shows that $\\mathbb{E}_{\\rho}[L(\\pmb{\\theta})]<\\infty$ is enough to guarantee that $\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}(\\lambda)]$ is finite for every $\\lambda\\geq0$ . ", "page_idx": 14}, {"type": "text", "text": "The following technical result will be important for the proof of Lemma 6. It combines the previous remarks with Lemma 2.2.5(c) of Dembo and Zeitouni (2009). ", "page_idx": 14}, {"type": "text", "text": "Lemma 18. $\\Lambda_{\\theta}^{\\star}(a)<\\infty$ for any $a\\in[0,L(\\pmb\\theta))$ . Furthermore, $\\Lambda_{\\theta}^{\\star}$ is differentiable in $\\displaystyle\\left(0,L(\\pmb\\theta)\\right)$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. We start by proving the finiteness condition. Since $\\Lambda_{\\theta}$ is strictly convex on $(0,\\infty)$ , $\\Lambda_{\\theta}^{\\prime}$ is also strictly increasing on $(0,\\infty)$ . This means that $\\Lambda_{\\theta}^{\\prime}$ is a bijection from $(0,\\infty)$ to $\\left(\\operatorname*{inf}_{\\lambda\\in(0,\\infty)}\\Lambda_{\\pmb\\theta}^{\\prime}(\\lambda),\\operatorname*{sup}_{\\lambda\\in(0,\\infty)}\\Lambda_{\\pmb\\theta}^{\\prime}(\\lambda)\\right)$ . In other words, for every $a\\in\\displaystyle\\left(\\operatorname*{inf}_{\\lambda\\in(0,\\infty)}\\Lambda_{\\pmb\\theta}^{\\prime}(\\lambda),\\operatorname*{sup}_{\\lambda\\in(0,\\infty)}\\Lambda_{\\pmb\\theta}^{\\prime}(\\lambda)\\right),$ the equation $a=\\Lambda_{\\theta}^{\\prime}(\\lambda)$ has a unique solution $\\lambda_{a}\\in(0,\\infty)$ . ", "page_idx": 14}, {"type": "text", "text": "Now consider the function $g(\\lambda)=\\lambda a-\\Lambda_{\\theta}(\\lambda)$ . The previous observation means that $g^{\\prime}(\\lambda_{a})=0$ ,   \nand since $g$ is concave, $\\Lambda_{\\theta}^{\\star}(\\bar{a})\\stackrel{\\star}{=}\\mathrm{~\\sup~\\}\\{\\lambda a-\\Lambda_{\\theta}(\\lambda)\\}=g(\\lambda_{a})<\\infty$ . $\\lambda{\\in}(0,\\infty)$   \nIt only remains to prove that $\\operatorname*{inf}_{\\lambda\\in(0,\\infty)}\\Lambda_{\\pmb\\theta}^{\\prime}(\\lambda)=0$ and sup $\\Lambda_{\\pmb\\theta}^{\\prime}(\\lambda)=L(\\pmb\\theta)$ . The first part follows $\\lambda{\\in}(0,\\infty)$   \nfrom the fact that $\\Lambda_{\\theta}^{\\prime}(0)=0$ . The second one is equivalent to proving ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{\\lambda\\to\\infty}\\Lambda_{\\pmb\\theta}^{\\prime}(\\lambda)=\\mathrm{ess\\,sup}(L(\\pmb\\theta)-\\ell(X,\\pmb\\theta)),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where, without loss of generality, we assume that ess inf $\\ell(X,\\pmb\\theta)=0$ . This is also a standard property of CGFs (see, for example, this proof). ", "page_idx": 14}, {"type": "text", "text": "Finally, differentiability of $\\Lambda_{\\theta}^{\\star}$ follows from its finiteness in $\\lbrack0,L(\\pmb\\theta))$ and Lemma 6(5) in Gantert et al. (2016). \u53e3 ", "page_idx": 14}, {"type": "text", "text": "With the tools we gathered above, we are ready to prove our main technical lemma: ", "page_idx": 14}, {"type": "text", "text": "Lemma 6. For any $\\theta\\in\\Theta$ and $c\\geq0$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\nu^{n}}\\Big(n\\Lambda_{\\pmb\\theta}^{\\star}\\big(g e n(\\pmb\\theta,D)\\big)\\geq c\\Big)\\leq\\mathbb{P}_{X\\sim\\exp{(1)}}\\Big(X\\geq c\\Big).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. The proof relies in the properties of generalized inverses. Consider ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(n\\Lambda_{\\theta}^{\\star}(g e n(\\pmb\\theta,D))\\geq a\\Big)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "for $a\\geq0$ . We will separately consider three cases: ", "page_idx": 14}, {"type": "text", "text": "Case 1: $a/n<\\operatorname*{sup}_{x\\in(0,L(\\pmb\\theta))}\\Lambda_{\\pmb\\theta}^{\\star}(x)$ . ", "page_idx": 14}, {"type": "text", "text": "By Proposition 1(5) in Embrechts and Hofert (2013), we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(n\\Lambda_{\\theta}^{\\star}\\big(g e n(\\theta,D)\\big)\\geq a\\Big)\\leq\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(g e n(\\theta,D)\\geq(\\Lambda_{\\theta}^{*})^{-1}(a/n)\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and using the Cram\u00e9r-Chernoff bound on the right-hand side we obtain ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(n\\Lambda_{\\pmb\\theta}^{\\star}(g e n(\\pmb\\theta,D))\\geq a\\Big)\\leq e^{-n\\Lambda_{\\pmb\\theta}^{\\star}\\big((\\Lambda_{\\pmb\\theta}^{\\ast})^{-1}(a/n)\\big)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This results in ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(n\\Lambda_{\\pmb\\theta}^{\\star}(g e n(\\pmb\\theta,D))\\geq a\\Big)\\leq e^{-a}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "because $\\Lambda_{\\theta}^{\\star}$ is continuous (in fact differentiable, see Lemma 18) on $a/n$ and we can apply Proposition 1(4) in Embrechts and Hofert (2013). ", "page_idx": 15}, {"type": "text", "text": "Case 2: $a/n=\\operatorname*{sup}_{x\\in(0,L(\\pmb\\theta))}\\Lambda_{\\pmb\\theta}^{\\star}(x)$ . ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(n\\Lambda_{\\theta}^{\\star}(g e n(\\theta,D))\\geq a\\Big)=\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(g e n(\\theta,D)=L(\\theta)\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{P}_{X\\sim\\nu}\\Big(\\ell(X,\\theta)=0\\Big)^{n}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=e^{-n\\Lambda_{\\theta}^{\\star}(L(\\theta))}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "If $\\Lambda_{\\pmb\\theta}^{\\star}(L(\\pmb\\theta))\\,<\\,\\infty$ , then $a/n\\,=\\,\\Lambda_{\\pmb\\theta}^{\\star}(L(\\pmb\\theta))$ by the lower semi-continuity of $\\Lambda_{\\theta}^{\\star}$ , and the result holds. Otherwise it is trivially true. ", "page_idx": 15}, {"type": "text", "text": "Case 3: $a/n>\\operatorname*{sup}_{x\\in(0,L(\\pmb\\theta))}\\Lambda_{\\pmb\\theta}^{\\star}(x)$ . In this case ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(n\\Lambda_{\\theta}^{\\star}\\big(g e n(\\pmb{\\theta},D)\\big)\\geq a\\Big)=\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(\\Lambda_{\\theta}^{\\star}\\big(g e n(\\pmb{\\theta},D)\\big)=\\infty\\Big).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "But $\\Lambda_{\\pmb{\\theta}}^{\\star}(g e n(\\pmb{\\theta},D))=\\infty$ can only happen if $g e n(\\pmb\\theta,D)=L(\\pmb\\theta)$ and $\\Lambda_{\\pmb{\\theta}}^{\\star}(L(\\pmb{\\theta}))=\\infty$ , and this means that $\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(g e n(\\pmb{\\theta},D)=L(\\pmb{\\theta})\\Big)=0$ . ", "page_idx": 15}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 15}, {"type": "text", "text": "Now we list every result whose proof is not included in the paper. ", "page_idx": 15}, {"type": "text", "text": "Theorem 7 (PAC-Bayes-Chernoff bound). Let $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\operatorname*{inf}_{\\lambda\\in[0,b)}\\left\\{\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{\\lambda(n-1)}+\\frac{\\mathbb{E}_{\\rho}[\\Lambda_{\\pmb\\theta}(\\lambda)]}{\\lambda}\\right\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 15}, {"type": "text", "text": "Proof. For any posterior distribution $\\begin{array}{r l r}{\\rho}&{{}\\in}&{\\mathcal{M}_{1}(\\Theta)}\\end{array}$ and any positive $m\\ \\ <\\ n$ , consider $m\\Lambda_{\\varrho}^{\\star}(g e n(\\rho,D))$ , where $g e n(\\rho,D)\\,:=\\,\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\,-\\,\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]$ . The function $\\Lambda_{\\rho}^{\\star}(\\cdot)$ will play a role analogue to the convex comparator function in Rivasplata et al. (2020). Since $\\operatorname{sup}_{\\lambda}\\mathbb{E}X_{\\lambda}\\leq$ $\\mathbb{E}\\operatorname{sup}_{\\lambda}X_{\\lambda}$ , it verifies that ", "page_idx": 15}, {"type": "equation", "text": "$$\nm\\Lambda_{\\rho}^{\\star}(g e n(\\rho,D))\\leq m\\mathbb{E}_{\\rho}[\\Lambda_{\\theta}^{\\star}(g e n(\\pmb{\\theta},D))]\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Applying Donsker-Varadhan\u2019s change of measure (Donsker and Varadhan, 1975) to the right-hand side of the inequality we obtain ", "page_idx": 15}, {"type": "equation", "text": "$$\nm\\Lambda_{\\rho}^{\\star}\\left(g e n(\\rho,D)\\right)\\leq K L(\\rho|\\pi)+\\log\\mathbb{E}_{\\pi}\\left(e^{m\\Lambda_{\\theta}^{\\star}\\left(g e n(\\theta,D)\\right)}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "We can now apply Markov\u2019s inequality to the random variable $\\mathbb{E}_{\\pi}\\left(e^{m\\Lambda_{\\theta}^{\\star}(g e n(\\pmb{\\theta},D))}\\right)$ . Thus, with probability at least $1-\\delta$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\nm\\Lambda_{\\rho}^{\\star}\\left(g e n(\\rho,D)\\right)\\leq K L(\\rho|\\pi)+\\log\\frac{1}{\\delta}+\\log\\mathbb{E}_{\\nu^{n}}\\mathbb{E}_{\\pi}\\left(e^{m\\Lambda_{\\theta}^{\\star}\\left(g e n(\\theta,D)\\right)}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $\\pi$ is data-independent, we can swap both expectations using Fubini\u2019s theorem, so that we need to bound $\\mathbb{E}_{\\nu^{n}}$ $\\stackrel{\\cdot}{e}^{m\\Lambda_{\\theta}^{\\bar{\\star}}(g e n(\\theta,D))})$ for any fixed $\\theta\\in\\Theta$ . Here is where Lemma 6 comes into play: we have that for any $c>0$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}_{D\\sim\\nu^{n}}\\left(n\\Lambda_{\\theta}^{\\star}(g e n(\\theta,D))\\ge\\frac{n}{m}c\\right)\\le\\mathbb{P}_{X\\sim\\exp{(1)}}\\left(X\\ge\\frac{n}{m}c\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since $X\\sim\\exp(1)$ , we get $k X\\sim\\exp(\\frac{1}{k})$ . Thus, multiplying by $\\textstyle{\\frac{m}{n}}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}_{D\\sim\\nu^{n}}\\left(m\\Lambda_{\\theta}^{\\star}(g e n(\\pmb\\theta,D))\\ge c\\right)\\le\\mathbb{P}_{X\\sim\\exp{(\\frac{n}{m})}}\\Big(X\\ge c\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "which in turn results in ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\mathbb P}_{\\nu^{n}}\\Big(e^{m\\Lambda_{\\theta}^{\\star}(g e n(\\theta,D))}\\geq t\\Big)\\leq{\\mathbb P}_{\\exp\\left(\\frac{n}{m}\\right)}\\Big(e^{X}\\geq t\\Big)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for any $t\\geq1$ . Finally, since $\\begin{array}{r}{X\\sim\\exp(\\frac{n}{m})}\\end{array}$ , we have $e^{X}\\sim$ Pareto $\\textstyle\\left({\\frac{n}{m}},1\\right)$ . Thus, for any $t\\geq1$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}_{\\nu^{n}}\\Big(e^{m\\Lambda_{\\theta}^{\\star}(g e n(\\theta,D))}\\geq t\\Big)\\leq\\mathbb{P}_{\\mathrm{Pareto}\\big(\\frac{n}{m},1\\big)}\\Big(X\\geq t\\Big).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Using that for any random variable $Z$ with support $\\Omega\\subseteq\\mathbb{R}_{+}$ , its expectation can be written as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[Z]=\\int_{\\Omega}P(Z\\geq z)d z\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "we obtein the desired bound: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}_{D\\sim\\nu^{n}}\\Big(e^{m\\Lambda_{\\theta}^{*}(g e n(\\theta,D))}\\Big)=\\displaystyle\\int_{1}^{\\infty}\\mathbb{P}_{D\\sim\\nu^{n}}\\Big(e^{m\\Lambda_{\\theta}^{*}(g e n(\\theta,D))}\\geq t\\Big)d t}&{}\\\\ {\\quad}&{\\leq\\displaystyle\\int_{1}^{\\infty}\\mathbb{P}_{X\\sim\\mathrm{Pareto}\\left(\\frac{n}{m},1\\right)}\\Big(X\\geq t\\Big)d t}\\\\ {\\quad}&{=\\mathbb{E}_{X\\sim\\mathrm{Pareto}\\left(\\frac{n}{m},1\\right)}\\left(X\\right)}\\\\ {\\quad}&{=\\frac{\\frac{n}{m}}{\\frac{n}{m}-1}=\\frac{n}{n-m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Observe how the condition $m<n$ is crucial because a Pareto $(1,1)$ has no finite mean. In conclusion, with probability at least $1-\\delta$ we have ", "page_idx": 16}, {"type": "equation", "text": "$$\nm\\Lambda_{\\rho}^{\\star}\\bigl(g e n(\\rho,D)\\bigr)\\leq K L(\\rho|\\pi)+\\log\\frac{n}{n-m}+\\log\\frac{1}{\\delta}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Dividing by $m$ , setting $m=n-1$ and applying $(\\Lambda_{\\rho}^{\\star})^{-1}(\\cdot)$ in both sides concludes the proof. ", "page_idx": 16}, {"type": "text", "text": "Corollary 8. Let $\\ell$ be the $0-1$ loss and $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\nk l\\left(\\mathbb{E}_{\\rho}[\\hat{L}(\\pmb{\\theta},D)],\\mathbb{E}_{\\rho}[L(\\pmb{\\theta})]\\right)\\leq\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1},\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. We know that $\\ell(\\pmb\\theta,X)\\ \\sim\\ \\mathrm{Bin}(L(\\pmb\\theta))$ , hence following the approach in Section 2.2 of Boucheron et al. (2013), we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\Lambda_{\\pmb\\theta}^{\\star}(a)=k l\\left(L(\\pmb\\theta)-a|L(\\pmb\\theta)\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "From the proof of Theorem 7 we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[\\Lambda_{\\pmb\\theta}^{\\star}(g e n(\\pmb\\theta,D))]\\leq\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1}\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and the result follows from the convexity of $k l$ and Jensen\u2019s inequality. ", "page_idx": 16}, {"type": "text", "text": "Proposition 12. If we fix some $\\lambda>0$ , the bound in Theorem $_{l l}$ can be minimized with respect to $\\rho\\in\\bar{\\mathcal{M}}_{1}(\\Theta)$ . The optimal posterior is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\rho^{*}(\\pmb{\\theta})\\propto\\pi(\\pmb{\\theta})\\exp\\left\\{-(n-1)\\lambda\\hat{L}(D,\\pmb{\\theta})-(n-1)\\psi(\\pmb{\\theta},\\lambda)\\right\\}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. We can solve the constrained minimization problem using standard results from variational calculus \u2014see Appendices $\\mathrm{D}$ and $\\boldsymbol{\\mathrm E}$ of Bishop (2006) for a succinct introduction\u2014. We need to minimize the functional ", "page_idx": 16}, {"type": "equation", "text": "$$\nB_{\\pi,\\lambda}[\\rho]:=\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb{\\theta})]+\\frac{\\mathbb{E}_{\\rho}[\\psi(\\pmb{\\theta},\\lambda)]}{\\lambda}+\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{\\lambda(n-1)}+\\gamma\\left(\\int_{\\Theta}\\rho(\\pmb{\\theta})d\\theta-1\\right),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\gamma\\geq0$ is the Lagrange multiplier. For this purpose, we compute the functional derivative of $B_{\\pi,\\lambda}\\lbrack\\rho\\rbrack$ wrt $\\rho$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\frac{\\delta\\mathcal{B}_{\\pi,\\lambda}}{\\delta\\rho}=\\hat{L}(D,\\pmb\\theta)+\\frac{\\psi(\\pmb\\theta,\\lambda)}{\\lambda}+\\frac{1}{\\lambda(n-1)}\\left(\\log\\frac{\\rho}{\\pi}+1\\right)+\\gamma,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and find $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ satisfying \u03b4B\u03b4\u03c0\u03c1,\u03bb = 0, which results in the desired \u03c1\u2217after straightforward algebraic manipulations. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Theorem 16. If Assumptions 2 and 3 are satisfied, then for any prior distribution $\\pi\\,\\in\\,\\mathcal{M}_{1}(\\Theta)$ independent of $D$ and any $\\delta\\in(0,1)$ ; with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\rho}[L(\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\theta)]+\\sqrt{2C\\mathbb{E}_{\\rho}\\left[\\|\\widehat\\nabla_{x}\\ell\\|_{2}^{2}\\right]\\cdot K(\\rho,\\pi,n,\\delta)+\\sqrt{2}C L\\cdot K(\\rho,\\pi,n,\\delta)^{\\frac{3}{2}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ , where $\\begin{array}{r}{K(\\rho,\\pi,n,\\delta):=\\frac{K L(\\rho|\\pi)+\\log\\frac{2n}{\\delta}}{n-1}}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "Proof. By Assumption 3, $\\|\\nabla_{\\pmb{x}}\\ell(\\pmb{\\theta},\\pmb{x})\\|_{2}^{2}\\leq L$ for any $\\theta\\in\\Theta$ and any $x\\in\\mathcal{X}$ \u2014note that with this we can already obtain a bound that includes a model-dependent Lipschitz constant $L(\\theta)$ \u2014. In particular, $\\|\\nabla_{\\mathbf{x}}\\ell(\\pmb{\\theta},X)\\|_{2}^{2}$ is $\\frac{L^{2}}{4}$ -sub-Gaussian. Thus we can use Corollary 5.3 in Hellstr\u00f6m et al. (2023) and obtain the following PAC-Bayes bound: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}\\left[\\|\\nabla_{\\mathbf{x}}\\ell\\|_{2}^{2}\\right]\\leq\\mathbb{E}_{\\rho}\\left[\\|\\widehat{\\nabla}_{\\mathbf{x}}\\ell\\|_{2}^{2}\\right]+\\frac{L}{\\sqrt{2}}\\sqrt{\\frac{K L(\\rho|\\pi)+\\log\\frac{\\sqrt{n}}{\\delta_{2}}}{n-1}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "with probability at least $1-\\delta_{2}$ . ", "page_idx": 17}, {"type": "text", "text": "Now taking $\\begin{array}{r}{\\delta_{1}=\\delta_{2}=\\frac{\\delta}{2}}\\end{array}$ , the bound in Theorem 15 and the one in (26) hold simultaneously with probability at least $1-\\delta$ . Finally, plugging (26) in Theorem 15 we obtain the desired result. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "B PAC-Bayes bounds for losses with bounded CGF ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Corollary 19. Assume the loss is $\\sigma^{2}$ -sub-Gaussian. Let $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\sqrt{2\\sigma^{2}\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. Follows from the fact that $(\\psi^{*})^{-1}(s)\\;=\\;\\sqrt{2\\sigma^{2}s}\\;$ for $\\sigma^{2}$ -sub-Gaussian random variables (Boucheron et al., 2013, Section 2). \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Corollary 20. Assume the loss is $(\\sigma^{2},c)$ -sub-gamma. Let $\\pi\\in\\mathcal{M}_{1}(\\Theta)$ be any prior independent of $D$ . Then, for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ over draws of $D\\sim\\nu^{n}$ , ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}_{\\rho}[L(\\pmb\\theta)]\\leq\\mathbb{E}_{\\rho}[\\hat{L}(D,\\pmb\\theta)]+\\sqrt{2\\sigma^{2}\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1}}+c\\frac{K L(\\rho|\\pi)+\\log\\frac{n}{\\delta}}{n-1},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "simultaneously for every $\\rho\\in\\mathcal{M}_{1}(\\Theta)$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. Follows from the fact that $(\\psi^{*})^{-1}(s)=\\sqrt{2\\sigma^{2}s}+c s$ for $(\\sigma^{2},c)$ -sub-gamma random variables (Boucheron et al., 2013, Section 2). \u53e3 ", "page_idx": 17}, {"type": "text", "text": "C Experimental details ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Models and data ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As for the experimental setting for Figure 1 and the verification of Assumption 2; we have used the small InceptionV3 architecture (Szegedy et al., 2016) used in Zhang et al. (2017), where the total number of parameters of the model is 1.814.106. We trained the model in the CIFAR10 dataset (Krizhevsky et al., 2009) with the default train/test split using SGD with momentum 0.9 and learning rate 0.01 with exponential decay of 0.95. All models are trained for 30.000 iterations of batches of size 200 or until the train loss is under 0.005. These settings are selected to ensure that the random label model converges to an interpolator. For $\\ell_{2}$ regularization, the multiplicative factor is 0.01. We include a Jupyter Notebook in the Supplementary Material with the code for reproducing our experiments and figures. ", "page_idx": 18}, {"type": "text", "text": "From the definition of the log-loss, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Lambda_{\\theta}(\\lambda)=\\ln\\mathbb{E}_{\\nu}\\left[e^{\\lambda(L(\\theta)-\\ell(y,\\mathbf{x},\\theta))}\\right]=\\ln\\mathbb{E}_{\\nu}\\left[p(y|x,\\theta)^{\\lambda}\\right]-\\mathbb{E}_{\\nu}[\\ln p(y|x,\\theta)^{\\lambda}]\\,,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "and we estimate the expectations using the test data: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Lambda_{\\theta}(\\lambda)\\approx\\ln\\left(\\frac{1}{M}\\sum_{({\\pmb x},{\\pmb y})\\in{\\cal D}^{t e s t}}p({\\pmb y}|{\\pmb x},{\\pmb\\theta})^{\\lambda}\\right)-\\frac{1}{M}\\sum_{({\\pmb x},{\\pmb y})\\in{\\cal D}^{t e s t}}\\ln p({\\pmb y}|{\\pmb x},{\\pmb\\theta})^{\\lambda}\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We also estimated $\\mathbb{V}(\\ell)$ and $\\Vert\\nabla_{x}\\ell\\Vert_{2}$ using $D^{t e s t}$ . ", "page_idx": 18}, {"type": "text", "text": "C.2 Experimental backing for Assumption 2 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We now experimentally evaluate Assumption 2 in the same setup as above. We need to show that there is certain $C>0$ such that for any $\\lambda>0$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Lambda_{\\theta}(\\lambda)\\leq\\frac{C}{2}\\lambda^{2}\\|\\nabla_{x}\\ell\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for every $\\theta\\in\\Theta$ . Since in this case each $\\pmb{\\theta}$ represents a configuration of weights in the InceptionV3 architecture, we cannot strictly verify the assumption for every $\\pmb{\\theta}$ , however, we provide empirical backing for its feasibility. ", "page_idx": 18}, {"type": "text", "text": "We estimate \u039b\u03b8(\u03bb) and \u2225\u2207x\u2113\u222522 with test data and plot0.5\u03bb\u039b2\u03b8\u2225(\u2207\u03bb)x\u2113\u222522 for the three different models introduced in Figure 1 (in the case of Zero the inequality trivially holds). ", "page_idx": 18}, {"type": "text", "text": "We plot the results in Figure 2, showing that the quantity of interest decreases with $\\lambda$ and that it is reasonable to expect Assumption 2 holding with $C<1$ . Observe that by a simple call to L\u2019Hopital\u2019s rule, one can see that limx\u21920+0.5\u03bb\u039b2\u03b8\u2225(\u2207\u03bb)x\u2113\u222522 =\u2225\u2207V(x\u2113\u2113)\u222522 . ", "page_idx": 18}, {"type": "image", "img_path": "CyzZeND3LB/tmp/66d22367bb5696cdce5004e4f0334f44a0677035beacd1136dc8b414a0f79d5c.jpg", "img_caption": ["Figure 2: The plots of $\\frac{\\Lambda_{\\theta}(\\lambda)}{0.5\\lambda^{2}\\|\\nabla_{x}\\ell\\|_{2}^{2}}$ in two different scales. In the case of these models, Assumption 2 holds with $C\\approx0.005$ . "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We mention and discuss bounds and techniques that are introduced later in the paper. Limitations of the assumptions are also mentioned. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: Both during related work discussion and in the conclusions. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: Yes, complete proofs are included in Appendix A, and the assumptions are discussed and justified. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We include our code in the supplementary material, and the details of the implementations are discussed in Appendix C. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The same as above. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes]   \nJustification: Yes, in Appendix C. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [No] ", "page_idx": 21}, {"type": "text", "text": "Justification: Not necessary. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: No relevant issues in our work. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [No] ", "page_idx": 22}, {"type": "text", "text": "Justification: This is a theoretical work aiming towards better understanding generalization, no negative societal impact. Potential positive impact. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: [NA] ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 23}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 24}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] Justification: [NA] Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 24}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] Justification: [NA] ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}]