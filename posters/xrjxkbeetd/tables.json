[{"figure_path": "XRJXKBeeTD/tables/tables_6_1.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the performance comparison of different methods on three benchmark datasets (ImageNet-{R, S}, VTAB, and Office-Home).  It compares the accuracy of pre-trained models, models fine-tuned on a subset of classes, a state-of-the-art (SOTA) fine-tuning method, and models with post-processing calibration.  The metrics presented include overall accuracy (Accy), accuracy on fine-tuning classes (Accs/y), accuracy on absent classes (Accu/y). An oracle model, trained with both fine-tuning and absent classes, is included as an upper bound for comparison. The table demonstrates the effectiveness of post-processing calibration in recovering the accuracy of absent classes that was lost during the fine-tuning process.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_6_2.jpg", "caption": "TABLE 2. Results in AUSUC.", "description": "This table presents the Area Under the Seen-Unseen Curve (AUSUC) for three different methods: Pre-trained, Tu et al. [49], and Fine-tuning, across three benchmark datasets: ImageNet-{R, S}, VTAB, and Office-Home. AUSUC is a metric used to evaluate the performance of fine-tuning models on both seen and unseen classes. The higher the AUSUC, the better the model's performance. The results show that fine-tuning achieves better results than the other two methods across all three datasets.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_16_1.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the results of post-processing calibration experiments on various datasets.  It shows the accuracy (Acc) of classifying both fine-tuning and absent classes, comparing the performance of the pre-trained model, the fine-tuned model, and the fine-tuned model with post-processing calibration applied using different methods. The \"Oracle\" row represents an upper bound, where the model is trained with both fine-tuning and absent class data.  The results demonstrate that post-processing calibration effectively improves the accuracy on absent classes, often achieving performance comparable to or exceeding the state-of-the-art (SOTA) methods that use more complex training strategies.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_18_1.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the performance comparison of different methods in terms of accuracy on fine-tuning classes and absent classes.  The methods include a pre-trained model, fine-tuning, fine-tuning with post-processing calibration using different approaches (ALG, PCV, and an oracle method), and a state-of-the-art method from previous research. The results are shown for different datasets: ImageNet-{R,S}, VTAB, and Office-Home.  The 'Oracle' row shows the upper bound performance achievable if the model was trained with both fine-tuning and absent classes.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_21_1.jpg", "caption": "TABLE 6. The performance comparison between the neural network (NN) classifier with the FC layer and the cosine classifier.", "description": "This table compares the performance of two classifiers: a neural network (NN) classifier with a fully connected (FC) layer and a cosine classifier.  The comparison is done using several metrics including AUSUC (Area Under the Seen-Unseen Curve), Accy/y (accuracy of classifying fine-tuning class data to all classes), Accs/y (accuracy of classifying fine-tuning class data to fine-tuning classes), and Accu/y (accuracy of classifying absent class data to all classes). The results show that both classifiers achieve similar performance on the ImageNet-Variants and Office-Home benchmarks. This suggests the importance of logit calibration on the final classifier weights.", "section": "C.2 Biased Logits Towards fine-tuning Classes"}, {"figure_path": "XRJXKBeeTD/tables/tables_22_1.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the performance comparison of different methods on various datasets for image classification.  The methods include: pre-trained model (no fine-tuning), fine-tuning only, a state-of-the-art (SOTA) method from a previous paper by Tu et al. [49], fine-tuning with post-processing calibration using ALG, fine-tuning with post-processing calibration using PCV, and an oracle approach (fine-tuning with both fine-tuning and absent classes).  The metrics used to evaluate performance are Accuracy of fine-tuning classes (Accs/y), Accuracy of absent classes (Accu/y).  The table demonstrates that post-processing calibration significantly improves the accuracy of classifying absent classes, recovering much of the performance lost during fine-tuning, and even outperforming the SOTA method in some cases. The oracle model represents an upper bound on performance, showing the potential for further improvement in the absence of full datasets.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_23_1.jpg", "caption": "TABLE 8. AUSUC and NCM Accu/y demonstrate that fine-tuning outperforms frozen classifier and linear probing.", "description": "This table presents a comparison of the Area Under the Seen-Unseen Curve (AUSUC) and the Nearest Class Mean accuracy (NCM Accu/y) for four different approaches: Pre-trained, Fine-Tuning, Frozen Classifier, and Linear Probing.  The results show that the Fine-Tuning method outperforms the other three methods on both metrics. This indicates that simply fine-tuning all the model parameters is the most effective method for maintaining accuracy on both the fine-tuning classes and the absent classes, compared to freezing parts of the model (such as the classifier) or only updating a small subset of parameters (linear probing).", "section": "C.3 Should We Freeze the Linear Classifier or Feature Backbone?"}, {"figure_path": "XRJXKBeeTD/tables/tables_23_2.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the results of post-processing calibration on several datasets.  It shows the accuracy (Accs/y, Accu/y) of classifying fine-tuning and absent classes, both before and after fine-tuning, and after applying different calibration techniques.  The \"Pre-trained\" row shows the performance of the model before fine-tuning, while the \"Fine-tuning\" row displays performance after standard fine-tuning.  The remaining rows illustrate the results of the proposed calibration approaches, along with a comparison to the state-of-the-art (SOTA) method from a previous study. The \"Oracle\" row provides an upper bound, representing performance that would be achieved if the model were trained with both fine-tuning and absent classes.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_23_3.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the performance comparison of different methods for fine-tuning a pre-trained model.  It shows the accuracy (Acc) on fine-tuning classes and absent classes, separately.  The \"Pre-trained\" row shows the performance of the model before fine-tuning.  The \"Fine-tuning\" row represents the performance after fine-tuning without any calibration.  The \"Tu et al. [49]\" row shows the results obtained using the state-of-the-art (SOTA) method from a previous study. The rows with  \"Fine-tuning +...\" demonstrate the performance improvements achieved by applying post-processing calibration methods proposed in this paper (ALG, PCV, and y*). Finally, \"Oracle\" represents the upper bound performance that can be theoretically achieved if the model were fine-tuned using both fine-tuning and absent class data.  The metrics for each method (Pre-trained, Fine-tuning, Tu et al. [49], Fine-tuning + ALG, Fine-tuning + PCV, Fine-tuning + y*, Oracle) are shown for different datasets: ImageNet-{R,S}, VTAB, and Office-Home.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_24_1.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the performance comparison of different methods on various datasets (ImageNet-{R,S}, VTAB, Office-Home).  It shows the accuracy (Acc) for fine-tuning classes and absent classes, both before and after post-processing calibration. The results demonstrate that a simple post-processing calibration can significantly improve the accuracy of the fine-tuned model on absent classes, effectively recovering the pre-trained model's capabilities.  The \"Oracle\" row represents the upper bound performance achieved when the model is fine-tuned with both fine-tuning and absent class data.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_24_2.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the performance comparison between different methods for fine-tuning a pre-trained model and recognizing both fine-tuning classes and absent classes.  The methods compared include the pre-trained model's performance, fine-tuning only, the state-of-the-art (SOTA) method by Tu et al. [49], and fine-tuning with post-processing calibration using two different approaches (ALG and PCV).  An \"Oracle\" result shows the theoretical best performance achievable if the model was trained with both fine-tuning and absent class data.  The results show the effectiveness of calibration methods in improving the accuracy on absent classes.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_28_1.jpg", "caption": "TABLE 1. Post-processing calibration can effectively bring back the pre-trained model's capability in recognizing absent classes. Oracle is based on a classifier fine-tuned with both fine-tuning and absent class data.", "description": "This table presents the performance of different methods on three benchmark datasets: ImageNet-{R, S}, VTAB, and Office-Home.  The metrics shown are accuracy for fine-tuning classes (Accs/y), accuracy for absent classes (Accu/y), and overall accuracy (Accy/y).  It demonstrates the effectiveness of post-processing calibration in recovering absent class accuracy after fine-tuning a pre-trained model with only a subset of classes. The \"Oracle\" row represents the upper bound performance, achieved using fine-tuning with both fine-tuning and absent classes.  The results show that using a simple post-processing calibration method significantly improves absent class accuracy compared to standard fine-tuning.", "section": "5 Post-Processing Calibration for the Rescue"}, {"figure_path": "XRJXKBeeTD/tables/tables_29_1.jpg", "caption": "TABLE 14. Performance of fine-tuning on iWildCam benchmark.", "description": "This table shows the performance comparison between the pre-trained model and the fine-tuned model on the iWildCam benchmark.  The metrics compared include AUSUC (Area Under the Seen-Unseen Curve), Acc<sub>y/y</sub> (accuracy of classifying fine-tuning class data), Acc<sub>s/s</sub> (accuracy of classifying fine-tuning class data into fine-tuning classes only), Accu/<sub>y</sub> (accuracy of classifying absent class data), Accu/<sub>u</sub> (accuracy of classifying absent class data into absent classes only), NCM Acc<sub>s/s</sub> (Nearest Class Mean accuracy of classifying fine-tuning class data using only features), and NCM Accu/<sub>y</sub> (Nearest Class Mean accuracy of classifying absent class data using only features).  A negative value in the \u0394 row indicates a decrease in performance after fine-tuning, which was observed in the iWildCam benchmark.", "section": "D.7 iWildCam"}]