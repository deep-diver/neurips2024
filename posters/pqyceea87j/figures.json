[{"figure_path": "pqYceEa87j/figures/figures_0_1.jpg", "caption": "Figure 1: t-SNE plot of LLaMA-2-chat-7B's activations for positive (blue) and negative (red) demonstrations from HaluEval and BBQ.", "description": "This figure shows the t-distributed Stochastic Neighbor Embedding (t-SNE) visualization of the activations of the LLaMA-2-chat-7B language model.  The plot displays the activations from the first, seventeenth, and thirty-second layers. Activations from positive (truthful) and negative (hallucinatory) examples from two datasets, HaluEval and BBQ, are shown separately.  The visualization aims to illustrate the degree of separation between the positive and negative examples in the activation space, suggesting the potential for editing these representations to improve the model's behavior.", "section": "1 Introduction"}, {"figure_path": "pqYceEa87j/figures/figures_1_1.jpg", "caption": "Figure 2: An overview of Spectral Editing of Activations (SEA). The method consists of two stages: (Left) the offline calculation of the editing projections using spectral decomposition with positive, negative and neutral demonstrations. (Right) the application of the calculated editing projections during LLM inference, thus manipulating predictions.", "description": "This figure illustrates the two-stage process of Spectral Editing of Activations (SEA). The left side shows the offline stage where editing projections are calculated using spectral decomposition on positive, negative, and neutral demonstrations.  The right side depicts the online inference stage where these pre-calculated projections are applied to manipulate the LLM's predictions. This method modifies the LLM's internal representations to encourage positive behavior and discourage negative behavior, without requiring further training.", "section": "2 Method: Spectral Editing of Activations"}, {"figure_path": "pqYceEa87j/figures/figures_6_1.jpg", "caption": "Figure 3: Left: Accuracy of all methods on each group of bias type in BBQ. Right: results on BBQ's testing set. All methods are applied on LLaMA-2-Chat-7B. For accuracy (A%\u2191), higher values are better; for unknown-answer response rate (U%\u2193), bias score (BS%\u2193) and stereotypical response rate (SR%\u2193), lower is better. We use bold font for the best result in each column, and mark the methods that improve ICL. \u2020: significant improvements on ICL in A% by pair-wise t-test with p < 0.05.", "description": "This figure shows the performance of different methods on the Bias Benchmark for QA (BBQ) dataset.  The left panel displays the accuracy of In-Context Learning (ICL), LoRA Fine-tuning (LoRA-FT), and Spectral Editing of Activations (SEA) methods, broken down by bias category.  The right panel presents an overall comparison of the methods across all bias categories using four metrics: accuracy (A%\u2191), unknown answer rate (U%\u2193), bias score (BS%\u2193), and stereotypical response rate (SR%\u2193). Higher accuracy is better, while lower values are preferred for the other three metrics.  The table highlights statistically significant improvements over the ICL baseline.", "section": "3.2 Bias"}, {"figure_path": "pqYceEa87j/figures/figures_8_1.jpg", "caption": "Figure 1: t-SNE plot of LLaMA-2-chat-7B's activations for positive (blue) and negative (red) demonstrations from HaluEval and BBQ.", "description": "This figure shows a t-SNE plot visualizing the activations of the LLaMA-2-chat-7B large language model.  The plot separates activations into clusters based on whether the model's generated text is considered positive (truthful, unbiased; shown in blue) or negative (hallucinatory, biased; shown in red).  The data used to generate the plot comes from the HaluEval and BBQ benchmark datasets. The visualization helps illustrate the potential for separating positive and negative model behaviors in the activation space, suggesting that targeted modifications to these activations might be effective for improving model behavior.", "section": "1 Introduction"}, {"figure_path": "pqYceEa87j/figures/figures_9_1.jpg", "caption": "Figure 5: Visualisation for the signature values in all LLM layers on HaluEval.", "description": "The figure visualizes the signature values across all layers of six different LLMs on the HaluEval dataset.  The signature value represents the amount of information related to the model's truthfulness contained within the layer's activations. The graph shows that for most LLMs, this value is highest in the top layers, suggesting that higher-level reasoning and generation tasks are primarily responsible for truthfulness; however, the model Gemma shows a slightly different trend, with some bottom layers also containing significant truthfulness-related information.", "section": "4.7 Spectral Analysis for the Source of Model Behaviours"}, {"figure_path": "pqYceEa87j/figures/figures_15_1.jpg", "caption": "Figure 6: Visualisation for the spectrum of the covariances of activations for LLaMA-2-Chat-7B model. Y-axis values are the index for LLM's layers. X-axis index are for all directions after SVD. A brighter cell indicates that the singular value in the corresponding direction is more significant. ", "description": "This figure visualizes the spectrum of covariances of activations for the LLaMA-2-Chat-7B model. The y-axis represents the index of the LLM layers, while the x-axis represents the index of all directions after singular value decomposition (SVD). The brightness of each cell indicates the significance of the singular value in the corresponding direction. Brighter colors mean higher significance.", "section": "B Spectrum of the Covariances"}, {"figure_path": "pqYceEa87j/figures/figures_15_2.jpg", "caption": "Figure 7: t-SNE visualisation for the \u03a6-SEA editing on BBQ.", "description": "This figure visualizes the effect of applying non-linear spectral editing of activations (\u03a6-SEA) on the BBQ dataset.  It uses t-SNE to project high-dimensional LLM activations into a 2D space for visualization.  The plot shows the distributions of activations for positive demonstrations (blue), negative demonstrations (orange), the original, unedited activations (green), and the activations after applying \u03a6-SEA (red). The visualization demonstrates how \u03a6-SEA shifts the distribution of the LLM's activations, reducing the overlap between positive and negative examples and moving them towards the positive ones. This illustrates the method's ability to non-linearly steer LLM behavior towards more desirable outputs.", "section": "2.5 Non-linear Editing in Richer Space"}, {"figure_path": "pqYceEa87j/figures/figures_16_1.jpg", "caption": "Figure 1: t-SNE plot of LLaMA-2-chat-7B's activations for positive (blue) and negative (red) demonstrations from HaluEval and BBQ.", "description": "This figure shows a t-SNE plot visualizing the activations of the LLaMA-2-chat-7B large language model.  The plot displays how activations for positive (truthful) and negative (hallucinated) demonstrations from the HaluEval and BBQ datasets cluster in the activation space. The clustering suggests a degree of separability between truthful and hallucinated outputs in the model's internal representations. This visualization supports the idea that editing LLM activations could be an effective technique for steering model behavior toward more truthful outputs.", "section": "1 Introduction"}]