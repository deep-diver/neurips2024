[{"figure_path": "xNncVKbwwS/tables/tables_1_1.jpg", "caption": "Table 1: A summary of our universal algorithms and previous studies over T rounds d-dimensional functions, where LT denotes the small-loss quantity. Abbreviations: cvx \u2192 convex, exp-concave \u2192 exponentially concave, str-cvx \u2192 strongly convex, # PROJ \u2192 number of projections per round.", "description": "This table compares the proposed universal online convex optimization (OCO) algorithm with existing methods. It shows the regret bounds achieved by each algorithm for different types of convex functions (convex, exponentially concave, strongly convex), along with the number of projections required per round. The table highlights that the proposed algorithm achieves optimal regret bounds with only 1 projection per round, unlike existing methods that typically require O(log T) projections.", "section": "1 Introduction"}, {"figure_path": "xNncVKbwwS/tables/tables_28_1.jpg", "caption": "Table 1: A summary of our universal algorithms and previous studies over T rounds d-dimensional functions, where LT denotes the small-loss quantity. Abbreviations: cvx \u2192 convex, exp-concave \u2192 exponentially concave, str-cvx \u2192 strongly convex, # PROJ \u2192 number of projections per round.", "description": "This table compares the proposed universal online convex optimization (OCO) algorithm with existing state-of-the-art methods. It shows the regret bounds achieved by each algorithm for different types of convex functions (convex, exponentially concave, strongly convex), and the number of projections required per round.  The table highlights that the proposed algorithm achieves optimal regret bounds with only 1 projection per round, in contrast to existing methods that require O(log T) projections.", "section": "2 Related works"}]