[{"figure_path": "7XkwzaPMvX/tables/tables_4_1.jpg", "caption": "Table 1: The number of subjects recruited in data collection for training behavior models, and the average accuracy of the human behavior model in 5-fold cross validation for each task.", "description": "This table presents the number of participants involved in the data collection phase for training the human behavior models used in the study.  It also shows the average accuracy achieved by these models across five different cross-validation folds for each of the four decision-making tasks: Census Prediction, Recidivism Prediction, Bias Detection, and Toxicity Detection.  The model accuracy reflects how well the computational models predict human decisions on these tasks.", "section": "4 Human Behavior Model Learning"}, {"figure_path": "7XkwzaPMvX/tables/tables_5_1.jpg", "caption": "Table 2: The number of participants we recruited in the evaluation study, categorized according to the type of AI explanation they received and the task they were assigned to.", "description": "This table shows the number of participants in each experimental group during the evaluation phase of the study. The participants were divided into groups based on the type of AI explanation they received (SHAP, LIME, Adversarially Manipulated, or Benignly Manipulated) and the specific decision-making task they performed (Census, Recidivism, Bias, or Toxicity).  The numbers indicate how many participants were assigned to each of the resulting experimental conditions.", "section": "Data Collection"}, {"figure_path": "7XkwzaPMvX/tables/tables_13_1.jpg", "caption": "Table B.1: Agreement between the sum of feature importance in explanations and AI predictions, measured in terms of the Pearson correlation coefficient.", "description": "This table shows the correlation between the total importance scores assigned to features in different explanation methods (SHAP, LIME, and adversarially/benignly manipulated explanations) and the AI's prediction.  A higher correlation indicates a greater agreement between the explanation's feature importance and the AI's final decision. This helps assess the consistency and trustworthiness of the explanation methods.", "section": "B Evaluation I: Manipulating AI Explanations for Adversarial Purposes"}, {"figure_path": "7XkwzaPMvX/tables/tables_14_1.jpg", "caption": "Table C.1: The average accuracy of the independent human behavior model through 5-fold validation for each task.", "description": "This table presents the average accuracy achieved by the independent human behavior model across four different decision-making tasks.  The model's performance is evaluated using 5-fold cross-validation, providing a robust measure of its predictive capability in each task. The tasks involve predicting census data, recidivism risk, bias in text, and toxicity in text. The accuracy scores serve as a baseline for evaluating the performance improvements that may be achieved through AI-assisted decision-making.", "section": "C.1 Combining Human Decisions and AI Predictions"}, {"figure_path": "7XkwzaPMvX/tables/tables_17_1.jpg", "caption": "Table C.2: The accuracy of each method on the holdout task pools, used in following experiments to manipulate AI explanations. The best result in each row is highlighted in bold.", "description": "This table presents the accuracy of different methods for combining human and AI predictions on four decision-making tasks: Census, Recidivism, Bias Detection, and Toxicity Detection.  The methods compared include using only human decisions, only AI model predictions, a human-AI combination method, and several other truth inference methods.  The best-performing method for each task is highlighted in bold.  This table is crucial for understanding how the choice of combination method impacts the subsequent manipulation of AI explanations in the study.", "section": "C.1 Combining Human Decisions and AI Predictions"}]