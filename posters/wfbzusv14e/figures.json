[{"figure_path": "WFbZusv14E/figures/figures_5_1.jpg", "caption": "Figure 1: Empirical verification regarding the learning of the adjacency matrix.", "description": "The figure shows the adjacency matrix learned by a simplified Transformer model trained on three different datasets (D1, D2, D3) compared to the true adjacency matrix.  Dataset D1 contains paths of length 1; D2 contains paths of length 1 and 20% of paths longer than 1; and D3 contains all possible paths. The results show that the learned adjacency matrices successfully capture the structural information from the true adjacency matrix, demonstrating that the Transformer model can learn the adjacency matrix from training data.", "section": "3.2 Learning Dynamics"}, {"figure_path": "WFbZusv14E/figures/figures_5_2.jpg", "caption": "Figure 2: Empirical verification regarding the learning of the observed reachability matrix.", "description": "This figure empirically validates the theoretical analysis of how Transformer models learn the observed reachability matrix from training data.  It shows a comparison between the true reachability matrix (a), the observed reachability matrices derived from three different training datasets (b-d), and the learned WV weight matrices extracted from trained Transformer models corresponding to those datasets (e-g). The color intensity represents the learned reachability weight, revealing the model's ability to capture the observed reachability but its limitations in learning transitive reachability.", "section": "Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_6_1.jpg", "caption": "Figure 3: Accuracy on the test datasets with embedding size d = 120.", "description": "This figure shows the accuracy of the model on test datasets with different numbers of nodes and different numbers of layers and heads. The embedding size is fixed at 120.  The accuracy is shown as a heatmap, with each cell representing the accuracy for a specific configuration of the model. The accuracy generally decreases as the number of nodes increases. However, the accuracy remains relatively stable as the number of heads increases, and shows at most a slight improvement as the number of layers increases.", "section": "4 Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_7_1.jpg", "caption": "Figure 8: The average attention in 1-layer and 1-head Transformers.", "description": "This figure visualizes the average attention weights in one-layer, one-head Transformer models across various graph sizes (100, 200, 300, 400, and 500 nodes). Each heatmap represents the average attention weights when predicting the next token in a path, with the rows corresponding to the current node's position and the columns indicating the potential next nodes.  Darker colors represent higher attention weights, highlighting the nodes most strongly considered when selecting the subsequent node in the path.  The results suggest that the attention mechanisms strongly focus on the target node while predicting the next node in the path.", "section": "4.2 Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_7_2.jpg", "caption": "Figure 7: Accuracy on the test datasets with embedding size d = 120.", "description": "This figure shows the accuracy of the model on test datasets with different numbers of nodes (100, 200, 300, 400, 500) and various Transformer architectures (different numbers of layers and heads).  It demonstrates how the model's performance varies with the size and complexity of the graph and the model's architecture.", "section": "4 Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_9_1.jpg", "caption": "Figure 3: Accuracy on the test datasets with embedding size d = 120.", "description": "This figure shows the accuracy of the model on test datasets with different numbers of nodes (100, 200, 300, 400) and different numbers of layers and heads in the Transformer architecture. The embedding size is fixed at 120. Each cell in the heatmap represents the accuracy for a specific configuration.", "section": "4 Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_17_1.jpg", "caption": "Figure 3: Accuracy on the test datasets with embedding size d = 120.", "description": "This figure shows the accuracy of the autoregressive Transformer models on test datasets with different numbers of nodes (100, 200, 300, 400) and embedding size d=120.  Each sub-figure represents a different number of nodes in the graph, showing the accuracy for different numbers of layers (1-6) and heads (1-6) in the Transformer model.  The color scale represents the accuracy, with darker shades indicating higher accuracy. The figure illustrates the performance of various Transformer model configurations in the path-finding task.", "section": "4 Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_18_1.jpg", "caption": "Figure 7: Accuracy on the test datasets with embedding size d = 120.", "description": "This figure presents the accuracy of the test datasets with embedding size d=120, for different graph sizes (number of nodes) and different Transformer configurations (number of layers and number of heads). Each bar represents the average accuracy over multiple trials.  The figure demonstrates how the accuracy varies with different network sizes and architecture choices, providing insights into the performance trade-offs.", "section": "4 Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_18_2.jpg", "caption": "Figure 3: Accuracy on the test datasets with embedding size d = 120.", "description": "This figure presents the accuracy of the Transformer models on test datasets with different numbers of nodes (100, 200, 300, 400) and varying numbers of layers and attention heads.  The embedding size is fixed at 120.  The results showcase the impact of model architecture complexity on path-finding accuracy across different graph sizes.", "section": "4 Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_19_1.jpg", "caption": "Figure 3: Accuracy on the test datasets with embedding size d = 120.", "description": "This figure shows the accuracy of the Transformer models on test datasets with different numbers of nodes (100, 200, 300, 400).  The accuracy is shown for various configurations of the Transformer, with different numbers of layers (1-6) and heads (1-6). The heatmap visualizes how accuracy changes across different model architectures and dataset sizes. This helps to understand how model parameters and dataset complexity affect the accuracy in path-finding tasks.", "section": "4 Empirical Evaluations: Peeking into a Trained Transformer"}, {"figure_path": "WFbZusv14E/figures/figures_20_1.jpg", "caption": "Figure 11: Accuracy, attention, and adjacency matrix results for the experiment on Blocksworld benchmark.", "description": "This figure presents the results of an experiment on the Blocksworld benchmark, which is a classic planning task.  It shows the adjacency matrix of the graph representing the Blocksworld states and actions, the WM' matrix learned by a 1-layer, 1-head Transformer model, and the average attention weights during the task.  The accuracy curve and average weight gap over training iterations are also shown, demonstrating the model's learning dynamics and how well it captures the underlying graph structure. The results illustrate the Transformer's ability to learn the adjacency matrix and its use of attention for planning.", "section": "F Path-planning in Blocksworld"}, {"figure_path": "WFbZusv14E/figures/figures_20_2.jpg", "caption": "Figure 12: Experiment for reachability on Blocksworld benchmark.", "description": "This figure visualizes the observed reachability matrix from the training data and the learned reachability matrix (WV') from a trained 1-layer, 1-head Transformer on the Blocksworld dataset.  It also shows the average weight gap between observed and unobserved reachabilities over training iterations. The results demonstrate the model's ability to learn observed reachability but its limitation in capturing unobserved or transitive reachability relationships. The heatmap shows the weight matrix, with darker colors indicating stronger reachability relationships learned by the model. The graph displays the gap between the average weights of observed and unobserved reachability relationships over training iterations for different embedding sizes. The consistent increase in this gap signifies the model's increasing ability to distinguish between observed and unobserved relationships.", "section": "F Path-planning in Blocksworld"}]