{"references": [{"fullname_first_author": "Yulong Liu", "paper_title": "Brainclip: Bridging brain and visual-linguistic representation via clip for generic natural visual stimulus decoding from fmri", "publication_date": "2023-02-28", "reason": "This paper proposes a novel method for decoding fMRI data using contrastive learning and CLIP, which is directly relevant to the current paper's approach of visual decoding using EEG and MEG."}, {"fullname_first_author": "Paul S Scotti", "paper_title": "Reconstructing the mind's eye: fmri-to-image with contrastive learning and diffusion priors", "publication_date": "2023-05-23", "reason": "This paper introduces a novel framework combining contrastive learning and diffusion models for fMRI-based image reconstruction, which is closely related to the current paper's method that uses EEG/MEG data and a two-stage diffusion model."}, {"fullname_first_author": "Tao Fang", "paper_title": "Alleviating the semantic gap for generalized fmri-to-image reconstruction", "publication_date": "2023-12-31", "reason": "This paper addresses the challenge of reconstructing images from fMRI data, focusing on reducing the semantic gap between fMRI representations and image features, which is directly relevant to the current paper's goal of high-quality image reconstruction from EEG/MEG data."}, {"fullname_first_author": "Yonghao Song", "paper_title": "Decoding natural images from eeg for object recognition", "publication_date": "2023-08-23", "reason": "This paper presents a significant advancement in EEG-based visual decoding using contrastive learning and a ShallowNet-based encoder, providing a baseline for comparison and further research in the field."}, {"fullname_first_author": "Tijl Grootswagers", "paper_title": "Human eeg recordings for 1,854 concepts presented in rapid serial visual presentation streams", "publication_date": "2022-01-01", "reason": "This paper introduces the THINGS-EEG dataset, which is extensively used in the current study for evaluating the performance of different EEG encoders in visual decoding tasks, showcasing its importance as a benchmark dataset."}]}