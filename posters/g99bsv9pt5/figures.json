[{"figure_path": "G99BSV9pt5/figures/figures_0_1.jpg", "caption": "Figure 1: Relational Concept Bottleneck Models can correctly predict and explain Bart's (B) citizenship by considering Homer's (H) citizenship and his status as Bart's parent.", "description": "This figure illustrates the basic architecture of Relational Concept Bottleneck Models (R-CBMs). It shows Homer (H) and Bart (B) as input entities with their features (male(H), parent(H, B), US(H), male(B)). These features are processed through an atom encoder and a task predictor to predict Bart's citizenship (US(B)). The model uses relational information (e.g., parent relationship) to infer Bart's citizenship based on Homer's citizenship and the parent relationship.  The orange arrow indicates the inference process from Homer's features to Bart's citizenship prediction.", "section": "1 Introduction"}, {"figure_path": "G99BSV9pt5/figures/figures_2_1.jpg", "caption": "Figure 2: The graph represents the dependencies among the atoms. Here, the atom p4(b) can be predicted either from the orange [p3(b), p2(a, b), p1(b, a)] or violet [p1(b, c), p2(c, b)] tuples of neighbours. We used different colors to identify different hyperedges.", "description": "This figure illustrates the atom dependency graph used in Relational Concept Bottleneck Models (R-CBMs). Each node represents a ground atom, and hyperedges (directed) represent the dependencies between atoms.  The figure shows that a target atom, p4(b), can be predicted from two different sets of source atoms, represented by different colored hyperedges. This exemplifies how R-CBMs consider multiple dependency paths when making predictions, unlike standard CBMs that only process one input at a time. The orange hyperedges represent one pathway to predict p4(b) whereas the violet hyperedges represent an alternative pathway.", "section": "3.1 Relational Concept Bottlenecks"}, {"figure_path": "G99BSV9pt5/figures/figures_4_1.jpg", "caption": "Figure 3: In R-CBMs (i) the atom encoder g maps input entities to a set of ground atoms (red/green indicate the ground atom label false/true), (ii) the relational bottleneck guides the selection of concept atoms by considering all the possible variable substitutions in \u0398, (iii) the atom predictor f maps the selected atoms into a task prediction, and (iv) the aggregator combines all evidence into a final task prediction.", "description": "This figure illustrates the architecture of Relational Concept Bottleneck Models (R-CBMs).  It shows how input entities are encoded into ground atoms representing facts or relationships (i). These atoms then pass through a relational bottleneck which selectively chooses relevant concept atoms based on possible variable substitutions (ii). A task predictor processes these selected atoms generating predictions for the task (iii), and finally, an aggregator combines these predictions to arrive at a final prediction (iv). The red and green colors indicate whether the ground atom is labelled true or false.", "section": "3 Relational Concept Bottleneck Models"}, {"figure_path": "G99BSV9pt5/figures/figures_7_1.jpg", "caption": "Figure 4: Model generalization on Hanoi OOD on the number of disks. Only R-CBMs are able to generalize effectively to settings larger than the ones they are trained on.", "description": "This figure shows the results of an out-of-distribution (OOD) generalization experiment using the Tower of Hanoi dataset.  The x-axis represents the number of disks in the test set, while the y-axis represents the task AUC (Area Under the ROC Curve).  Different models are compared: R-CBM, Relational Black Box, Flat-CBM, and CBM. The results demonstrate that R-CBMs are significantly more robust to OOD scenarios, maintaining high performance even when the test set has a larger number of disks (more complexity) than the training set.  Other models' performance degrades sharply in these OOD scenarios.", "section": "5 Key Findings"}, {"figure_path": "G99BSV9pt5/figures/figures_14_1.jpg", "caption": "Figure 3: In R-CBMs (i) the atom encoder g maps input entities to a set of ground atoms (red/green indicate the ground atom label false/true), (ii) the relational bottleneck guides the selection of concept atoms by considering all the possible variable substitutions in \u0398, (iii) the atom predictor f maps the selected atoms into a task prediction, and (iv) the aggregator combines all evidence into a final task prediction.", "description": "This figure illustrates the architecture of Relational Concept Bottleneck Models (R-CBMs).  It shows how the model processes input entities, maps them to ground atoms, uses a relational bottleneck to select relevant concept atoms, predicts task outcomes based on selected atoms, and finally aggregates these predictions for the final output.  The use of red and green to indicate true/false ground atom labels highlights the interpretability aspect of the model.", "section": "3 Relational Concept Bottleneck Models"}]