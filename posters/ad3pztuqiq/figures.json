[{"figure_path": "Ad3PzTuqIq/figures/figures_2_1.jpg", "caption": "Figure 1: Left panel: The B-Rep elements and their topological connectivity in the form of LARbrep with edge-vertex characteristic matrix M\u2081 and face-vertex characteristic matrix M2. Right panel: The proposed point-to-BRep adjacency representation LARped and its characteristic matrices M\u2081 and M\u2082 for points on edges (in red) and faces (in blue).", "description": "This figure illustrates the core concept of the paper: a novel point-to-BRep adjacency representation. The left panel shows a Boundary Representation (B-Rep) of a pyramid, including its vertices, edges, and faces, and their topological connectivity represented using Linear Algebraic Representation (LAR). The right panel shows how this representation is adapted to a point cloud scenario, enabling the use of B-Rep topological information for direct neural supervision.  Key to the adaptation is the mapping of points to their corresponding B-Rep elements, facilitating the use of the LAR representation with point cloud data.  Characteristic matrices (M1 and M2) are used to represent the adjacency between elements in both representations.", "section": "3 Point-to-BRep Adjacency Formulation"}, {"figure_path": "Ad3PzTuqIq/figures/figures_4_1.jpg", "caption": "Figure 2: SpelsNet architecture overview. The SparseCNN encoder outputs the point-wise spatial embeddings Fe. Primitive types and membership segmentation learning is done in spatial domain in the SpelsNetsp module together with topological supervision by B-Rep-level elements and structure prediction in Graph Neural Network in the SpelsNetvef.", "description": "This figure shows the architecture of the SpelsNet model.  The model consists of two main components: SpelsNetsp, which handles spatial domain classification and segmentation, and SpelsNetvef, which uses B-Rep topological supervision to improve accuracy.  SpelsNet takes a point cloud as input and produces edge and face types (Te and Tf), as well as their corresponding segmentation maps (We and Wf). The spatial component uses a SparseCNN encoder and MLPs to extract features and predict types and memberships. The topological component utilizes a Graph Neural Network and a proposed point-to-BRep adjacency representation to learn the B-Rep structure and integrate topological information into the segmentation process.", "section": "4 Proposed Network"}, {"figure_path": "Ad3PzTuqIq/figures/figures_7_1.jpg", "caption": "Figure 3: Visual results of comparisons on ABCParts-VEF for PrimitiveNet and our SpelsNet. From-left-to-right: input point cloud, face types (Tf) and segmentation (Wf), edge types (Te) and segmentation (We).", "description": "This figure compares the results of three different methods for segmenting point clouds into surface primitives: PrimitiveNet, ComplexGen, and SpelsNet (the authors' method).  Each row shows the same object processed by all three methods. From left to right, we can see the input point cloud, ground truth segmentation (GT) showing the correct surface and edge types, PrimitiveNet's results, ComplexGen's results, and finally SpelsNet's results.  Each column shows different aspects of the segmentation: face types (Tf), face segmentations (Wf), edge types (Te), and edge segmentations (We). This allows for a visual comparison of the performance of all three methods in terms of both accuracy of primitive type classification and accuracy of the segmentation itself.  The figure highlights SpelsNet's superior performance.", "section": "5.2 Classification and Segmentation Evaluation"}, {"figure_path": "Ad3PzTuqIq/figures/figures_8_1.jpg", "caption": "Figure 3: Visual results of comparisons on ABCParts-VEF for PrimitiveNet and our SpelsNet. From-left-to-right: input point cloud, face types (Tf) and segmentation (Wf), edge types (Te) and segmentation (We).", "description": "This figure presents a visual comparison of the results obtained by PrimitiveNet and SpelsNet on the ABCParts-VEF dataset. For each model, four columns showcase (from left to right): the input point cloud; the predicted face types and segmentation; the predicted edge types and segmentation; and a combined view of face and edge types and segmentation.  The figure highlights the differences in the quality of segmentation and the accuracy of predicted types produced by each method.  The superior performance of SpelsNet in both areas is visually evident.", "section": "5.2 Classification and Segmentation Evaluation"}, {"figure_path": "Ad3PzTuqIq/figures/figures_8_2.jpg", "caption": "Figure 2: SpelsNet architecture overview. The SparseCNN encoder outputs the point-wise spatial embeddings Fe. Primitive types and membership segmentation learning is done in spatial domain in the SpelsNetsp module together with topological supervision by B-Rep-level elements and structure prediction in Graph Neural Network in the SpelsNetvef.", "description": "This figure shows the architecture of the SpelsNet model, which is composed of two main components: SpelsNetsp and SpelsNetvef. SpelsNetsp performs spatial domain classification and segmentation, while SpelsNetvef leverages B-Rep topological supervision.  The model takes a point cloud as input and processes it through a SparseCNN encoder. This produces spatial embeddings, which are then used for type classification and membership segmentation in the SpelsNetsp module.  The results from this module and B-Rep topological supervision are combined in the SpelsNetvef module for final structure prediction using a Graph Neural Network.  The output includes the primitive type and the membership segmentation for each point.", "section": "4 Proposed Network"}, {"figure_path": "Ad3PzTuqIq/figures/figures_9_1.jpg", "caption": "Figure 3: Visual results of comparisons on ABCParts-VEF for PrimitiveNet and our SpelsNet. From-left-to-right: input point cloud, face types (Tf) and segmentation (Wf), edge types (Te) and segmentation (We).", "description": "This figure shows a comparison of the results obtained by PrimitiveNet and SpelsNet on the ABCParts-VEF dataset. The figure presents visual examples of input point clouds, ground truth (GT), PrimitiveNet predictions, and SpelsNet predictions for both face and edge types and segmentations. It highlights the differences in the quality and accuracy of the predictions for different methods.", "section": "5.2 Classification and Segmentation Evaluation"}, {"figure_path": "Ad3PzTuqIq/figures/figures_9_2.jpg", "caption": "Figure 2: SpelsNet architecture overview. The SparseCNN encoder outputs the point-wise spatial embeddings Fe. Primitive types and membership segmentation learning is done in spatial domain in the SpelsNetsp module together with topological supervision by B-Rep-level elements and structure prediction in Graph Neural Network in the SpelsNetvef.", "description": "This figure provides a detailed overview of the SpelsNet architecture, a neural network designed for segmenting 3D point clouds into boundary representation (B-Rep) elements.  It highlights the two main components: SpelsNetsp, which handles spatial domain classification and segmentation, and SpelsNetvef, which incorporates B-Rep topological supervision using a graph neural network. The flow of information from the input point cloud through the SparseCNN encoder, various processing modules, and finally to the output (primitive types and membership segmentation) is clearly illustrated.", "section": "4 Proposed Network"}]