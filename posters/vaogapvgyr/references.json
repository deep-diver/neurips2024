{"references": [{"fullname_first_author": "OpenAI", "paper_title": "GPT-4 Technical Report", "publication_date": "2024-03-01", "reason": "This paper is a comprehensive technical report on GPT-4, a leading large language model, directly relevant to the current research on improving LLM arithmetic capabilities."}, {"fullname_first_author": "Zheng Yuan", "paper_title": "How well do large language models perform in arithmetic tasks?", "publication_date": "2023-07-15", "reason": "This paper directly addresses the limitations of LLMs in performing arithmetic tasks, providing a strong foundation and context for the current research focused on solving this limitation."}, {"fullname_first_author": "Owen Dugan", "paper_title": "OccamNet: A Fast Neural Model for Symbolic Regression at Scale", "publication_date": "2020-07-15", "reason": "This paper introduces the OccamNet architecture, a core component of the proposed OccamLLM framework, and demonstrates its effectiveness in symbolic mathematical operations."}, {"fullname_first_author": "Marek Kadl\u010d\u00edk", "paper_title": "Calc-X and Calcformers: Empowering arithmetical chain-of-thought through interaction with symbolic systems", "publication_date": "2023-05-01", "reason": "This paper explores a related approach to enhancing LLM arithmetic by leveraging external tools, which provides valuable comparative context and insights for evaluating the proposed single-step method."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the chain-of-thought prompting technique, a significant advancement in prompting strategies for LLMs that serves as a foundation for comparison and potential integration with the proposed method."}]}