[{"figure_path": "4D7hnJ9oM6/tables/tables_4_1.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table presents the accuracy results obtained using different text ensembles (single template vs. text average) for image classification on various datasets: CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C.  The results demonstrate the effectiveness of employing a text averaging technique to boost the overall test-time performance in comparison to the use of a single text template for prompt generation. The improvements in accuracy are shown across different datasets exhibiting varying levels of difficulty and domain shifts.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_5_1.jpg", "caption": "Table 2: Accuracy (%) of our method for different batch sizes compared to CLIP.", "description": "This table presents the accuracy of the proposed WATT method across different batch sizes (BS) on the CIFAR-10, CIFAR-10.1, and CIFAR-10-C datasets. The results are compared against the baseline CLIP model.  The table demonstrates the robustness of WATT across varying batch sizes, highlighting its ability to maintain high accuracy even with smaller batch sizes.", "section": "3 Method"}, {"figure_path": "4D7hnJ9oM6/tables/tables_7_1.jpg", "caption": "Table 3: Accuracy (%) obtained with different averaging strategies.", "description": "This table compares the performance of three different averaging strategies: Text averaging, Output averaging, and Weight averaging (the proposed WATT method).  The results are shown for various datasets (CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C), and different numbers of iterations of the weight averaging process are included for the WATT method. The table demonstrates that the weight averaging strategy generally outperforms the other methods, showcasing the effectiveness of the proposed WATT approach for test-time adaptation.", "section": "Results"}, {"figure_path": "4D7hnJ9oM6/tables/tables_8_1.jpg", "caption": "Table 4: Accuracy (%) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets. WATT-P refers to our method with Parallel MTWA and WATT-S to the Sequential MTWA variant of WATT.", "description": "This table presents the accuracy results of different methods (CLIP, TENT, TPT, TDA, DiffTPT, SAR, CLIPARTT, WATT-P, and WATT-S) on various CIFAR datasets (CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C).  It shows the performance of these methods on both the original datasets and on datasets with common corruptions. WATT-P and WATT-S represent two variations of the proposed WATT method, using parallel and sequential multi-template weight averaging, respectively.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_8_2.jpg", "caption": "Table 5: Comparison of different TTA methods with a batch size equal to 1.", "description": "This table compares the performance of various Test-Time Adaptation (TTA) methods, including the proposed WATT-P, on CIFAR-10, CIFAR-10.1, and CIFAR-10-C datasets when using a batch size of 1.  It highlights the relative performance gains of WATT-P compared to existing methods (CLIP, TPT, SAR, MEMO, and CLIPArTT) in low-data adaptation scenarios.  The results demonstrate that WATT-P achieves the highest accuracy across all datasets without requiring image augmentation, a common practice in previous TTA approaches.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_9_1.jpg", "caption": "Table 6: Accuracy (%) on different domains of VisDA-C, OfficeHome, PACS and VLCS datasets.", "description": "This table presents the accuracy results of different test-time adaptation methods (CLIP, TENT, TPT, CLIPARTT, WATT-P, and WATT-S) across four distinct datasets: VisDA-C, OfficeHome, PACS, and VLCS.  Each dataset represents a different type of domain shift (simulated, video, texture, and style), and the results show how well each method adapts to these various shifts.  The table provides a comprehensive comparison of the different methods' generalization capabilities in diverse scenarios.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_14_1.jpg", "caption": "Table 7: Comparison of computational cost of different methods.", "description": "This table compares the computational cost, including adaptation time, memory usage, and the percentage of learnable parameters, for various test-time adaptation (TTA) methods.  The methods compared include WATT-S (Sequential Multi-Template Weight Averaging), WATT-P (Parallel Multi-Template Weight Averaging), TENT, CLIPArTT, SAR, MEMO, and DiffTPT.  It demonstrates that WATT-S and WATT-P are computationally efficient compared to other methods, especially considering their robustness.  The results showcase a balance between efficiency and effectiveness, highlighting the advantages of the proposed WATT approach.", "section": "Supplementary Material"}, {"figure_path": "4D7hnJ9oM6/tables/tables_14_2.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table shows the accuracy achieved using different text ensembles at the test time. The results are presented for various datasets including CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C. The table compares the performance of using a single template versus using an average of multiple templates.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_15_1.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table presents the accuracy achieved using different text ensemble strategies at test time.  It compares the performance of using a single template versus averaging embeddings from multiple templates. The results are shown for various datasets: CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C, demonstrating the effectiveness of the text averaging approach across diverse datasets and corruption types.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_15_2.jpg", "caption": "Table 9: Performance comparison of SigLip and WATT-S on different datasets", "description": "This table compares the performance of the SigLip model and the proposed WATT-S method on five different datasets: CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C.  The datasets represent variations in complexity and the presence of corruptions.  The results show a significant improvement in accuracy achieved by WATT-S across all datasets, highlighting its effectiveness in adapting to different data distributions.", "section": "G Experiments with another VLM"}, {"figure_path": "4D7hnJ9oM6/tables/tables_15_3.jpg", "caption": "Table 10: Accuracy (%) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets with ViT-B/16 and ViT-L/14 as visual encoders.", "description": "This table presents the accuracy results achieved by different methods (CLIP, TENT, TPT, CLIPArTT, WATT-P, and WATT-S) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets.  The results are broken down by backbone model used (ViT-B/16 and ViT-L/14). It showcases the performance of the proposed WATT method in comparison to state-of-the-art techniques across various datasets and image corruption levels.", "section": "5 Results"}, {"figure_path": "4D7hnJ9oM6/tables/tables_16_1.jpg", "caption": "Table 6: Accuracy (%) on different domains of VisDA-C, OfficeHome, PACS and VLCS datasets.", "description": "This table presents the accuracy of different test-time adaptation methods (CLIP, TENT, TPT, CLIPARTT, WATT-P, and WATT-S) on four different domain generalization datasets: VisDA-C, OfficeHome, PACS, and VLCS.  Each dataset represents a different type of domain shift, allowing for a comprehensive evaluation of the methods' robustness across various data distributions and image categories. VisDA-C includes 3D-rendered images and YouTube video frames, OfficeHome contains product, clipart, art, and real-world images, PACS includes art, cartoons, photos, and sketches, and VLCS contains images from Caltech-101, LabelMe, SUN09, and VOC2007. The results show how well each method generalizes to unseen data.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_17_1.jpg", "caption": "Table 6: Accuracy (%) on different domains of VisDA-C, OfficeHome, PACS and VLCS datasets.", "description": "This table presents the accuracy results of different test-time adaptation methods on four domain generalization datasets: VisDA-C, OfficeHome, PACS, and VLCS.  Each dataset contains images from different visual domains (e.g., photos, sketches, cartoons). The table shows how well each method adapts to these domain shifts, comparing the performance to a baseline CLIP model.  The results are broken down by dataset and domain, providing a detailed comparison of the effectiveness of various adaptation methods.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_17_2.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table shows the accuracy achieved using different text ensemble methods at test time.  The \"single_temp\" column represents the accuracy using a single template, while the \"text_avg\" column shows the accuracy when averaging the embeddings from multiple text templates.  The results are presented for different datasets (CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, CIFAR-100-C), illustrating the impact of text ensemble on the model's performance across various datasets and scenarios.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_17_3.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table presents the accuracy achieved using different text ensemble methods at test time. The results are presented for various datasets including CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C.  Each dataset represents a different challenge in terms of image classification, with some including various types of corruptions or domain shifts. The table compares the performance of using a single text template versus an average of multiple text templates.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_18_1.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table presents the accuracy achieved using different text ensembles at test time.  It shows the results for single template approach and text average approach on several datasets: CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C. The text average method uses the embedding from all the templates.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_18_2.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table shows the accuracy achieved by using different text prompt ensemble methods during the testing phase. The results are presented for several benchmark datasets, including CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C.  It compares the performance of using a single template versus averaging the embeddings from multiple templates (text_avg).", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_19_1.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table shows the accuracy achieved using different text ensemble methods at test time. The results are presented for various datasets, including CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C.  The table compares the performance of using a single template versus averaging the embeddings from multiple templates. This helps demonstrate the impact of the text ensemble strategy on test-time adaptation.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_19_2.jpg", "caption": "Table 1: Accuracy (%) with different text ensembles at test time.", "description": "This table presents the accuracy results achieved using different text ensemble methods at test time.  The 'single_temp' column shows the accuracy when a single template is used for text prompts.  The 'text_avg' column demonstrates the improved accuracy obtained by averaging text embeddings from multiple templates. The table compares the performance across different datasets (CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, CIFAR-100-C), highlighting the effectiveness of the text averaging approach.  The results show that averaging text embeddings from multiple templates consistently improves the classification accuracy across all datasets.", "section": "3.1 Transductive TTA loss"}, {"figure_path": "4D7hnJ9oM6/tables/tables_20_1.jpg", "caption": "Table 4: Accuracy (%) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets. WATT-P refers to our method with Parallel MTWA and WATT-S to the Sequential MTWA variant of WATT.", "description": "This table presents the accuracy results of the proposed WATT method (both Parallel and Sequential MTWA variants) compared to several other state-of-the-art Test-Time Adaptation (TTA) methods on various CIFAR datasets.  The datasets include CIFAR-10, CIFAR-10.1 (a natural shift from CIFAR-10), and CIFAR-10-C (CIFAR-10 with 15 common corruptions), along with their 100-class counterparts. The results show the accuracy achieved by each method on these datasets. WATT-P denotes the parallel version of the WATT method, while WATT-S is the sequential version.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_20_2.jpg", "caption": "Table 4: Accuracy (%) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets. WATT-P refers to our method with Parallel MTWA and WATT-S to the Sequential MTWA variant of WATT.", "description": "This table presents the accuracy of different methods on various CIFAR datasets.  It compares the performance of CLIP, TENT, TPT, TDA, DiffTPT, SAR, CLIPArTT, WATT-P (Parallel Multi-Template Weight Averaging), and WATT-S (Sequential Multi-Template Weight Averaging). The datasets include CIFAR-10, CIFAR-10.1, CIFAR-10-C (CIFAR-10 with common corruptions), CIFAR-100, and CIFAR-100-C (CIFAR-100 with common corruptions).  The table highlights the effectiveness of WATT-P and WATT-S compared to existing test-time adaptation methods across a range of dataset corruptions.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_21_1.jpg", "caption": "Table 4: Accuracy (%) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets. WATT-P refers to our method with Parallel MTWA and WATT-S to the Sequential MTWA variant of WATT.", "description": "This table presents the accuracy results of different methods on various CIFAR datasets.  It compares the performance of the proposed WATT method (using both parallel and sequential multi-template weight averaging) against several other state-of-the-art test-time adaptation (TTA) methods, including CLIP, TENT, TPT, TDA, DiffTPT, SAR, and CLIPArTT. The datasets include the standard CIFAR-10 and CIFAR-100, along with their corrupted versions CIFAR-10-C and CIFAR-100-C, and the CIFAR-10.1 dataset which represents a natural domain shift from CIFAR-10. The results demonstrate the effectiveness of WATT in handling various levels of domain shifts and corruption compared to existing TTA techniques.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_21_2.jpg", "caption": "Table 4: Accuracy (%) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets. WATT-P refers to our method with Parallel MTWA and WATT-S to the Sequential MTWA variant of WATT.", "description": "This table presents the accuracy of different methods (CLIP, TENT, TPT, TDA, DiffTPT, SAR, CLIPARTT, WATT-P, and WATT-S) on various CIFAR datasets.  The CIFAR datasets are standard image classification datasets, with CIFAR-10-C and CIFAR-100-C representing corrupted versions of the datasets, simulating real-world image degradation.  WATT-P and WATT-S represent two variants of the proposed WATT method, differing in their weight averaging strategy (Parallel and Sequential, respectively). The table allows a comparison of the performance of WATT against state-of-the-art test-time adaptation methods across diverse datasets.", "section": "5.2 Comparison to SOTA methods"}, {"figure_path": "4D7hnJ9oM6/tables/tables_22_1.jpg", "caption": "Table 4: Accuracy (%) on CIFAR-10, CIFAR-10.1, CIFAR-10-C, CIFAR-100, and CIFAR-100-C datasets. WATT-P refers to our method with Parallel MTWA and WATT-S to the Sequential MTWA variant of WATT.", "description": "This table presents the accuracy results (%) achieved by different methods on various CIFAR datasets. It compares the performance of CLIP (baseline), TENT, TPT, TDA, DiffTPT, SAR, CLIPArTT, WATT-P (Parallel Multi-Template Weight Averaging), and WATT-S (Sequential Multi-Template Weight Averaging).  The datasets include CIFAR-10, CIFAR-10.1 (a natural shift from CIFAR-10), CIFAR-10-C (CIFAR-10 with 15 common corruptions), CIFAR-100, and CIFAR-100-C (CIFAR-100 with 15 common corruptions).  This allows for a comprehensive evaluation of the methods' performance under various degrees of domain shift and corruption.", "section": "5.2 Comparison to SOTA methods"}]