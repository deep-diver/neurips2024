{"references": [{"fullname_first_author": "Yuval Alaluf", "paper_title": "Cross-image attention for zero-shot appearance transfer", "publication_date": "2024-00-00", "reason": "This paper proposes a novel cross-image attention mechanism for zero-shot appearance transfer, a technique highly relevant to the core methodology of the target paper."}, {"fullname_first_author": "Kaiming He", "paper_title": "Masked Autoencoders Are Scalable Vision Learners", "publication_date": "2022-00-00", "reason": "This foundational work introduces the Masked Autoencoder (MAE) framework, a self-supervised approach for training vision transformers that is directly related to the self-supervised foundation models used in the target paper."}, {"fullname_first_author": "Maxime Oquab", "paper_title": "DINOv2: Learning Robust Visual Features without Supervision", "publication_date": "2023-00-00", "reason": "This paper introduces DINOv2, a self-supervised model for learning robust visual features, which is a key component and baseline in the experimental evaluation of the target paper."}, {"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment anything", "publication_date": "2023-00-00", "reason": "This work introduces the Segment Anything Model (SAM), a foundation model for image segmentation used as a component in the target paper's personalized segmentation approach."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-00-00", "reason": "This paper introduces high-resolution image synthesis using latent diffusion models, which are foundational to the text-to-image diffusion models explored in the target paper."}]}