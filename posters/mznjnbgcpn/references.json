{"references": [{"fullname_first_author": "Herbert Robbins", "paper_title": "A stochastic approximation method", "publication_date": "1951-01-01", "reason": "This paper introduces the stochastic approximation method, a fundamental concept underlying many first-order optimization algorithms."}, {"fullname_first_author": "Yurii Evgen'evich Nesterov", "paper_title": "A method of solving a convex programming problem with convergence rate O(1/k^2)", "publication_date": "1983-01-01", "reason": "This foundational work introduced a method for solving convex programming problems with significantly improved convergence rate compared to previous methods, setting the stage for accelerated gradient methods."}, {"fullname_first_author": "John Duchi", "paper_title": "Adaptive subgradient methods for online learning and stochastic optimization", "publication_date": "2011-01-01", "reason": "This paper introduced adaptive subgradient methods, which dynamically adjust step sizes, leading to improvements in convergence speed and robustness for various optimization problems."}, {"fullname_first_author": "Diederik P. Kingma", "paper_title": "Adam: A method for stochastic optimization", "publication_date": "2014-01-01", "reason": "Adam is a widely used adaptive learning rate optimization algorithm known for its effectiveness and efficiency in training deep learning models."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-01-01", "reason": "This paper introduced proximal policy optimization (PPO), a reinforcement learning algorithm that has achieved significant success due to its ability to effectively balance exploration and exploitation."}]}