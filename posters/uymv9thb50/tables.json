[{"figure_path": "Uymv9ThB50/tables/tables_5_1.jpg", "caption": "Table 1: Automatic evaluation of embedding-level attack performance. All criteria except for ASR-keyword are evaluated by GPT-4. The best results are in bold and the second best are underlined. \u2206 = SCAV - Best baseline.", "description": "This table presents the quantitative results of embedding-level attacks on two LLMs (LLaMA-2 7B-Chat and LLaMA-2 13B-Chat) using three different methods (JRE, RepE, and SCAV).  The evaluation metrics include ASR-keyword (attack success rate based on keyword matching), ASR-answer (attack success rate based on whether the LLM provides a relevant answer), ASR-useful (attack success rate based on whether the LLM provides a useful response), and Language flaws (the number of language flaws in the LLM's response).  The table shows that SCAV consistently outperforms the baselines across all metrics, achieving significantly higher attack success rates and better response quality.  The \u2206 column shows the improvement of SCAV over the best-performing baseline for each metric.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_5_2.jpg", "caption": "Table 2: Human evaluation of embedding-level attack performance. A = SCAV \u2013 Best baseline.", "description": "This table presents the results of a human evaluation comparing the performance of the proposed SCAV method against existing baselines (JRE and RepE) for embedding-level attacks. The evaluation is based on three criteria: ASR-answer (the percentage of times the LLM provided a relevant answer), ASR-useful (the percentage of times the response was useful), and Language flaws (the number of language errors). The results show that SCAV significantly outperforms the baselines across all three metrics, with a substantial increase in ASR-answer and ASR-useful and a substantial decrease in Language flaws. The delta (\u0394) column shows the improvement achieved by SCAV over the best baseline for each metric.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_6_1.jpg", "caption": "Table 3: Evaluation of prompt-level attack performance. A = SCAV \u2013 Best baseline.", "description": "This table compares the performance of the proposed SCAV method with other baseline methods for prompt-level attacks.  It shows the results on two datasets (Advbench and StrongREJECT) and evaluates four criteria: ASR-keyword, ASR-answer, ASR-useful, and Language flaws.  The improvements shown by SCAV compared to the best baseline are quantified using the '\u0394' column.  Higher values are generally better for the first three criteria and lower is better for the last criterion.", "section": "3.3 Prompt-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_6_2.jpg", "caption": "Table 4: Attack transferability study: applying attack prompts learned for LLaMA to GPT-4. \u2206 = SCAV - Best baseline.", "description": "This table presents the results of applying prompts learned from LLaMA models to GPT-4. It demonstrates the transferability of attack prompts learned by studying the inner workings of certain white-box models, showing their potential usefulness for other black-box APIs.  The table compares the performance of the SCAV method against baseline methods across four evaluation criteria: ASR-keyword, ASR-answer, ASR-useful, and Language flaws.  The delta (\u2206) column shows the improvement of SCAV over the best baseline method for each metric.", "section": "3.3 Prompt-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_7_1.jpg", "caption": "Table 5: Attacking 7 well-known open-source LLMs by using SCAV. All LLMs provide relevant answers to more than 85% malicious instructions (ASR-answer), except for one on Advbench (ASR-answer is 78%).", "description": "This table presents the results of attacking seven well-known open-source LLMs using the SCAV method.  The table shows the attack success rate and response quality for each LLM on two datasets (Advbench and StrongREJECT). The results indicate that all LLMs provide relevant answers to a high percentage of malicious instructions, highlighting the severity of safety risks in current LLMs.", "section": "4.1 Are Aligned LLMs Really Safe?"}, {"figure_path": "Uymv9ThB50/tables/tables_7_2.jpg", "caption": "Table 6: Attacking GPT-4 API by using different combinations of attack methods. When combining all prompt-level attack methods (All), GPT-4 returns useful responses to 84% (or 54%) malicious instructions on Advbench (or StrongREJECT), with a majority of them having no language flaws.", "description": "This table presents the results of attacking GPT-4 using different combinations of prompt-level attack methods, including SCAV, AutoDAN, and DeepInception.  The results show the attack success rates (ASR-keyword, ASR-answer, ASR-useful) and language quality (Language flaws) for different combinations of attacks.  The \"All\" row represents the best results obtained by combining all methods. The results show that even a cutting-edge model like GPT-4 is vulnerable to these attacks.", "section": "Black-box LLM APIs"}, {"figure_path": "Uymv9ThB50/tables/tables_13_1.jpg", "caption": "Table 1: Automatic evaluation of embedding-level attack performance. All criteria except for ASR-keyword are evaluated by GPT-4. The best results are in bold and the second best are underlined. A = SCAV - Best baseline.", "description": "This table presents the quantitative results of embedding-level attacks on two LLMs (LLaMA-2 7B-Chat and LLaMA-2 13B-Chat) using three different methods (JRE, RepE, and SCAV).  The evaluation metrics include ASR-keyword, ASR-answer, ASR-useful, and Language flaws.  Higher scores are better for ASR-keyword, ASR-answer, and ASR-useful, while lower scores are better for Language flaws.  The table also shows the improvement achieved by SCAV compared to the best baseline.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_19_1.jpg", "caption": "Table 1: Automatic evaluation of embedding-level attack performance. All criteria except for ASR-keyword are evaluated by GPT-4. The best results are in bold and the second best are underlined. \u0394 = SCAV - Best baseline.", "description": "This table presents the quantitative results of embedding-level attacks on two LLMs (LLaMA-2 7B-Chat and LLaMA-2 13B-Chat) using three methods (JRE, RepE, and SCAV).  The evaluation metrics include ASR-keyword (attack success rate based on keyword matching), ASR-answer (attack success rate based on whether the LLM provides a relevant answer), ASR-useful (attack success rate based on whether the response is useful), and Language flaws (the number of language flaws in the response).  The SCAV method consistently outperforms the baselines across all metrics, indicating its effectiveness in generating high-quality and successful attacks.  The table also shows the difference in performance (\u0394) between SCAV and the best baseline for each metric, highlighting the significant improvement achieved by SCAV.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_19_2.jpg", "caption": "Table 1: Automatic evaluation of embedding-level attack performance. All criteria except for ASR-keyword are evaluated by GPT-4. The best results are in bold and the second best are underlined.  \u0394 = SCAV - Best baseline.", "description": "This table presents the quantitative results of embedding-level attacks on two LLMs (LLaMA-2 7B-Chat and LLaMA-2 13B-Chat) using three methods (JRE, RepE, and SCAV).  The evaluation metrics include ASR-keyword (attack success rate based on keyword matching), ASR-answer (attack success rate based on whether the LLM provides a relevant answer), ASR-useful (attack success rate considering the usefulness of the response), and Language flaws (a measure of the quality of the LLM's response, such as repetition, inconsistency, and unspecific content).  The table highlights the superiority of the SCAV method in achieving a higher attack success rate with better response quality and fewer language flaws compared to the baselines. The difference between SCAV and the best baseline is also calculated (\u0394).", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_19_3.jpg", "caption": "Table 1: Automatic evaluation of embedding-level attack performance. All criteria except for ASR-keyword are evaluated by GPT-4. The best results are in bold and the second best are underlined. \u0394 = SCAV - Best baseline.", "description": "This table presents the quantitative results of embedding-level attacks on two LLMs (LLaMA-2 7B-Chat and LLaMA-2 13B-Chat) using three different methods (JRE, RepE, and SCAV).  The evaluation metrics include ASR-keyword (attack success rate based on keyword matching), ASR-answer (attack success rate based on whether the LLM provides a relevant answer), ASR-useful (attack success rate based on whether the LLM provides a useful answer), and Language flaws (the number of language flaws in the LLM response).  The \u0394 column shows the improvement of SCAV over the best baseline for each metric.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_20_1.jpg", "caption": "Table 12: ASR-keyword (%) w.r.t different regularization terms (Advbench, LLaMA-2-7B-Chat)", "description": "This table shows the impact of different regularization terms (L1 and L2) on the ASR-keyword metric when using the Advbench dataset and the LLaMA-2-7B-Chat model.  The results are presented for different values of the regularization parameter lambda (\u03bb). The table demonstrates the sensitivity of the attack's success rate to the choice of regularization technique and strength.", "section": "E.1.2 Selection for Po and P\u2081"}, {"figure_path": "Uymv9ThB50/tables/tables_21_1.jpg", "caption": "Table 13: ASR-keyword (%) w.r.t. varying Po and P\u2081 (Advbench, LLaMA-2-7B-Chat)", "description": "This table shows the impact of varying the probability thresholds (Po and P1) on the attack success rate (ASR-keyword).  The results are shown for the Advbench dataset and the LLaMA-2-7B-Chat model.  It demonstrates the sensitivity of the attack performance to these parameters and the optimal range of values for achieving a high ASR-keyword.", "section": "E.1.2 Selection for Po and P\u2081"}, {"figure_path": "Uymv9ThB50/tables/tables_23_1.jpg", "caption": "Table 1: Automatic evaluation of embedding-level attack performance. All criteria except for ASR-keyword are evaluated by GPT-4. The best results are in bold and the second best are underlined. \u0394 = SCAV - Best baseline.", "description": "This table presents the quantitative results of embedding-level attacks on two LLMs (LLaMA-2 7B-Chat and LLaMA-2 13B-Chat) using three different methods: JRE, RepE, and SCAV.  The evaluation metrics include ASR-keyword, ASR-answer, ASR-useful, and Language flaws.  The SCAV method consistently outperforms the baselines across all metrics, indicating a significant improvement in attack success rate and response quality. The delta values (\u0394) show the performance difference between SCAV and the best-performing baseline for each LLM and metric.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_23_2.jpg", "caption": "Table 15: Attacking LLMs with embedding-level SCAV on Harmbench.", "description": "This table presents the results of the embedding-level attacks using SCAV on the Harmbench dataset. It shows the performance of the attacks in terms of ASR-keyword (the percentage of attacks that successfully trigger a response without refusal keywords), ASR-answer (the percentage of attacks that provide relevant answers to malicious instructions), ASR-useful (the percentage of attacks that provide useful answers), and Language Flaws (the number of language flaws in the responses). The results are shown for two different LLMs: LLaMA-2-7B-Chat and LLaMA-2-13B-Chat.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_23_3.jpg", "caption": "Table 16: Attacking more LLMs with embedding-level SCAV on Advbench.", "description": "This table presents the results of applying the embedding-level SCAV attack method to a wider range of LLMs beyond those primarily featured in the paper. It shows the performance metrics (ASR-keyword, ASR-answer, ASR-useful, Language Flaws) for each model. The results highlight the effectiveness of SCAV across various open-source models, showcasing consistent high success rates in generating relevant and useful malicious responses.", "section": "3.2 Embedding-Level Attack Results"}, {"figure_path": "Uymv9ThB50/tables/tables_26_1.jpg", "caption": "Table 17: Attacking LLaMA-2-7B-Chat with different prompt-level defense methods.", "description": "This table presents the results of applying various prompt-level defense methods (Self-reminder, ICD, and Paraphrasing) against attacks on the LLaMA-2-7B-Chat model.  The results are evaluated using four criteria: ASR-keyword, ASR-answer, ASR-useful, and Language Flaws.  The table shows the attack success rates and the quality of the model's responses after applying the defense mechanisms.  The purpose is to assess the effectiveness of these defenses in mitigating the vulnerabilities of the model to attacks.", "section": "4.2 Are Existing Unlearn Methods Really Effective?"}, {"figure_path": "Uymv9ThB50/tables/tables_26_2.jpg", "caption": "Table 18: Attacking LLMs with adversarial training [44] on Advbench.", "description": "This table presents the results of attacking two LLMs (LLaMA-3-8B-Instruct-RR and Mistral-7B-Instruct-RR) that have undergone adversarial training using the circuit breaker method [44] on the Advbench dataset.  The table shows the attack success rate based on keyword matching (ASR-keyword), the percentage of responses that provide relevant answers (ASR-answer), the percentage of useful responses (ASR-useful), and the average number of language flaws in the model's responses (Language Flaws). The results indicate whether adversarial training effectively mitigates the proposed attacks. ", "section": "G Mitigation"}]