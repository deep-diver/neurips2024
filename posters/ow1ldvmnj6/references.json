{"references": [{"fullname_first_author": "Rombach, R.", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-20", "reason": "This paper introduces Stable Diffusion, the foundation model used in the current research."}, {"fullname_first_author": "Ramesh, A.", "paper_title": "Zero-shot text-to-image generation", "publication_date": "2021-07-18", "reason": "This paper is foundational to the field of text-to-image generation and is frequently cited in the literature."}, {"fullname_first_author": "Ho, J.", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces the core denoising diffusion model framework upon which many text-to-image models are based."}, {"fullname_first_author": "Radford, A.", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "CLIP, introduced in this paper, is a crucial component of many text-to-image models, providing the image-text embedding necessary for alignment."}, {"fullname_first_author": "Huang, K.", "paper_title": "T2I-CompBench: A comprehensive benchmark for open-world compositional text-to-image generation", "publication_date": "2023-12-01", "reason": "This paper provides a benchmark dataset used for evaluating the performance of text-to-image models and is integral to the current study's experimental design."}]}