[{"figure_path": "OW1ldvMNJ6/tables/tables_6_1.jpg", "caption": "Table 1: T2I-CompBench result. The best score is in blue, with the second-best score in green", "description": "This table presents the quantitative results of the proposed CoMat model and other state-of-the-art models on the T2I-CompBench benchmark.  T2I-CompBench evaluates text-to-image alignment across six sub-categories: color binding, shape binding, texture binding, spatial relationships, non-spatial relationships, and complex compositions. The table shows the performance of each model in each sub-category, highlighting the best and second-best scores.  The improvements achieved by CoMat-SD1.5 and CoMat-SDXL over their respective baseline models (SD1.5 and SDXL) are also indicated.", "section": "5.1 Experimental Setup"}, {"figure_path": "OW1ldvMNJ6/tables/tables_7_1.jpg", "caption": "Table 2: TIFA and DPG-Bench results.", "description": "This table presents a comparison of the performance of different models on two benchmarks: TIFA (Text-to-Image Faithfulness Assessment) and DPG-Bench (Dense Prompt Generation Benchmark).  The TIFA benchmark evaluates the alignment between generated images and textual descriptions, while DPG-Bench focuses on complex and detailed prompts.  The table shows the scores achieved by each model on both benchmarks, illustrating the relative performance of each model in generating images that accurately reflect the given text instructions, particularly in the context of complex scenes and descriptions.", "section": "5.2 Quantitative Results"}, {"figure_path": "OW1ldvMNJ6/tables/tables_8_1.jpg", "caption": "Table 4: Impact of concept activation and attribute concentration. 'CA' and 'AC' denote concept activation and attribute concentration respectively.", "description": "This table presents the ablation study results focusing on the impact of concept activation (CA) and attribute concentration (AC) modules on the text-to-image alignment performance.  It shows the performance improvement on six sub-categories of the T2I-CompBench benchmark (color, shape, texture, spatial, non-spatial, and complex) when either CA or AC module is added, or when both are combined.  The baseline model is SDXL.  The results demonstrate that both CA and AC contribute to improved alignment, with the combination yielding the best results.", "section": "5.4 Ablation Study"}, {"figure_path": "OW1ldvMNJ6/tables/tables_8_2.jpg", "caption": "Table 5: The impact of different image-to-text models.", "description": "This table shows the impact of using different image-to-text models on the performance of the CoMat model.  Specifically, it presents the results of the CoMat model on the T2I-CompBench benchmark, broken down by sub-categories (Color, Shape, Texture, Spatial, Non-Spatial) for Attribute Binding and Object Relationship, and an overall Complex score. The table compares results obtained when using the BLIP, GIT, and LLaVA image-to-text models with a baseline (N/A) that does not use an image-to-text model. The higher the score, the better the performance.", "section": "5.4 Ablation Study"}, {"figure_path": "OW1ldvMNJ6/tables/tables_9_1.jpg", "caption": "Table 6: Success rate of prompt attack.", "description": "This table presents the success rate of a prompt attack on two models: SD1.5 and CoMat-SD1.5. The attack method aims to generate misaligned images by crafting adversarial prompts. The success rate is defined as the percentage of generated images that are mistakenly classified by a visual classifier. Results are shown for both short and long prompts.", "section": "5.5 Robustness Analysis"}, {"figure_path": "OW1ldvMNJ6/tables/tables_19_1.jpg", "caption": "Table 7: Statistics of image-to-text models.", "description": "This table presents the number of parameters and sensitivity scores for three different image-to-text models: BLIP, GIT, and LLaVA.  The sensitivity score reflects the models' ability to distinguish between correct and incorrect image captions, indicating their suitability for use in the concept activation module of the CoMat model.  Higher sensitivity scores suggest better performance.", "section": "5.4 Ablation Study"}, {"figure_path": "OW1ldvMNJ6/tables/tables_21_1.jpg", "caption": "Table 1: T2I-CompBench result. The best score is in blue, with the second-best score in green", "description": "This table presents the results of the T2I-CompBench benchmark, a comprehensive evaluation of text-to-image alignment capabilities.  It compares different models across six sub-categories of text-to-image alignment: color binding, shape binding, texture binding, spatial relationships, non-spatial relationships, and complex compositions.  The best and second-best scores for each sub-category are highlighted in blue and green respectively, offering a clear comparison of model performance across various aspects of alignment.", "section": "5.1 Experimental Setup"}]