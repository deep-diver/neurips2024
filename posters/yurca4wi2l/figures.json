[{"figure_path": "yURca4wi2L/figures/figures_1_1.jpg", "caption": "Figure 1: Temporally consistent restoration in video ATM is challenging. State-of-the-art methods like DATUM (2) (CVPR\u201924) and TMT (3)(TCI\u201923), designed for video ATM, fail to maintain temporal consistency in real-world atmospheric turbulence. For instance, they produce flickering artifacts on a static pole.", "description": "This figure demonstrates the challenge of achieving temporally consistent restoration in videos affected by atmospheric turbulence. It shows that existing state-of-the-art methods (DATUM and TMT) struggle to maintain consistency across frames, resulting in flickering artifacts even in a static scene.  The figure highlights the need for new methods that specifically address this temporal inconsistency issue.", "section": "1 Introduction"}, {"figure_path": "yURca4wi2L/figures/figures_2_1.jpg", "caption": "Figure 5: Visualization of our method's effectiveness in mitigating real-world atmospheric turbulence compared to existing methods. The leftmost image shows the original frame with a green box marking the zoom-in crop area for KLT tracking and a red line for the Y-t slice, shown in the bottom left. The right side displays two rows: the first shows zoom-in KLT tracking results for baseline methods and their outputs enhanced by our method, and the second shows zoom-in Y-t slices highlighting the temporal consistency achieved. Note the significant reduction in erratic movements in our results.", "description": "This figure compares the performance of ConVRT against state-of-the-art methods on real-world atmospheric turbulence data.  It shows the original video frame, results from applying other methods individually, and the results after applying ConVRT to those other methods' outputs.  Key comparisons are made using \"patches\" (zoomed-in regions), and Y-t slices (showing temporal evolution of a single vertical line in the frame). ConVRT is shown to reduce artifacts and achieve improved temporal consistency.", "section": "4 Experiments"}, {"figure_path": "yURca4wi2L/figures/figures_3_1.jpg", "caption": "Figure 3: Comparison of different learning approaches for image and video ATM. (a) ATM methods in supervised learning face challenges in domain adaptation for real-world data. (b) Self-supervised learning ATM methods mostly explore static video sequences, outputting one frame from multiple frames as input. (c) Our hybrid pipeline is tailored for video ATM, combining supervised pre-training and self-supervised learning to achieve consistent video restoration through turbulence", "description": "This figure compares three different learning approaches for atmospheric turbulence mitigation (ATM) in images and videos.  (a) shows supervised learning, which uses paired training data (clean and distorted) generated by a turbulence simulator. This approach struggles with real-world data because simulated and real turbulence differ. (b) illustrates self-supervised learning, which uses unpaired data and learns from internal data patterns or lucky images. This method often produces inconsistent results and struggles with motion. (c) presents the authors' hybrid approach (ConVRT), which combines supervised pre-training on synthetic data with self-supervised learning on real data.  It introduces a neural representation that separates spatial and temporal information for improved temporal consistency.", "section": "1.2 Motivation and Contribution"}, {"figure_path": "yURca4wi2L/figures/figures_4_1.jpg", "caption": "Figure 4: Illustration of the proposed method. ConVRT represents a video with two fields: the Temporal Deformation Field (Tfield) and the Spatial Content Field (Sfield). Regularization is applied by constraining the dimensions of the Temporal Feature Map. Similarly, reducing the size of the deformation MLP serves as additional regularization to promote temporal consistency.", "description": "This figure illustrates the architecture of the ConVRT model, which consists of two main components: the Temporal Deformation Field (Tfield) and the Spatial Content Field (Sfield). The Tfield uses a Hadamard product to combine spatial and temporal feature maps and an MLP to output deformation offsets. The Sfield uses the offsets to warp a canonical spatial feature map and an MLP to predict the RGB intensity values. The model is regularized by constraining the dimensions of the temporal feature map and the size of the deformation MLP to promote temporal consistency.", "section": "3 Method"}, {"figure_path": "yURca4wi2L/figures/figures_6_1.jpg", "caption": "Figure 5: Visualization of our method's effectiveness in mitigating real-world atmospheric turbulence compared to existing methods. The leftmost image shows the original frame with a green box marking the zoom-in crop area for KLT tracking and a red line for the Y-t slice, shown in the bottom left. The right side displays two rows: the first shows zoom-in KLT tracking results for baseline methods and their outputs enhanced by our method, and the second shows zoom-in Y-t slices highlighting the temporal consistency achieved. Note the significant reduction in erratic movements in our results.", "description": "This figure showcases the results of the proposed ConVRT method compared to other state-of-the-art methods for mitigating atmospheric turbulence in real-world videos.  The visualization uses both KLT tracking (to show motion consistency) and Y-t slices (to show temporal consistency) to demonstrate that ConVRT significantly reduces erratic movements and flickering artifacts resulting from turbulence, improving temporal consistency in the restored videos.", "section": "4 Experiments"}, {"figure_path": "yURca4wi2L/figures/figures_7_1.jpg", "caption": "Figure 5: Visualization of our method's effectiveness in mitigating real-world atmospheric turbulence compared to existing methods. The leftmost image shows the original frame with a green box marking the zoom-in crop area for KLT tracking and a red line for the Y-t slice, shown in the bottom left. The right side displays two rows: the first shows zoom-in KLT tracking results for baseline methods and their outputs enhanced by our method, and the second shows zoom-in Y-t slices highlighting the temporal consistency achieved. Note the significant reduction in erratic movements in our results.", "description": "This figure compares the performance of ConVRT against state-of-the-art methods (VRT, TMT, DATUM) in mitigating real-world atmospheric turbulence.  It uses a video clip showing a static scene (a building) to highlight the temporal consistency issue. The left shows the original frame with marked regions used for close-up analysis. The right displays those close-ups, focusing on KLT tracking (showing movement over time) and Y-t slices (showing changes across frames).  ConVRT's results are markedly smoother and more temporally consistent than the baseline methods.", "section": "4 Experiments"}, {"figure_path": "yURca4wi2L/figures/figures_8_1.jpg", "caption": "Figure 7: Ablation study and canonical image visualization. Our method mitigates residual turbulence using Ltemp and lower Tres. Canonical image is visualized from Canonical Spatial Feature Map C.", "description": "This figure presents an ablation study on the impact of the temporal consistency regularization loss (Ltemp) and the temporal resolution (Tres) on the performance of the proposed method, ConVRT. It shows that using Ltemp and a lower Tres leads to better mitigation of residual turbulence, resulting in smoother temporal dynamics. The canonical image, generated from the Canonical Spatial Feature Map C, provides a clear visualization of the spatial details of the video without temporal deformation. The results demonstrate the effectiveness of the proposed method in controlling the temporal dynamics of the restored videos.", "section": "4 Experiments"}, {"figure_path": "yURca4wi2L/figures/figures_8_2.jpg", "caption": "Figure 8: Illustration of camera shake simulation using Brownian Motion. In the Y-t slice plots, we observe similarities between camera shake and turbulence. The plots also demonstrate the effectiveness of our approach in handling both camera shake alone and in combination with turbulence.", "description": "This figure shows the effectiveness of the proposed method in handling camera shake and turbulence.  It compares the results of the proposed method with a baseline method (DATUM) on synthetic videos with and without camera shake added, using Y-t slice plots and KLT trajectories to visualize temporal consistency and motion.", "section": "4.3 Qualitative and Quantitative Improvements on Existing Methods"}, {"figure_path": "yURca4wi2L/figures/figures_8_3.jpg", "caption": "Figure 9: Experimental results compare ConVRT with unsupervised and test-time optimization methods by Li et al. (10) and Mao et al. (9) on moving objects. Both baselines fail to capture motion, replacing moving parts with the average background, while ConVRT effectively handles them", "description": "This figure compares the performance of ConVRT against two other methods (Li et al. and Mao et al.) on video sequences containing moving objects.  The other methods struggle to accurately represent the motion of objects, often blurring or replacing them with the average background.  In contrast, ConVRT demonstrates a superior ability to preserve the motion and details of moving objects.", "section": "4.3 Qualitative and Quantitative Improvements on Existing Methods"}, {"figure_path": "yURca4wi2L/figures/figures_9_1.jpg", "caption": "Figure 5: Visualization of our method's effectiveness in mitigating real-world atmospheric turbulence compared to existing methods. The leftmost image shows the original frame with a green box marking the zoom-in crop area for KLT tracking and a red line for the Y-t slice, shown in the bottom left. The right side displays two rows: the first shows zoom-in KLT tracking results for baseline methods and their outputs enhanced by our method, and the second shows zoom-in Y-t slices highlighting the temporal consistency achieved. Note the significant reduction in erratic movements in our results.", "description": "This figure demonstrates the effectiveness of the proposed method (ConVRT) in mitigating real-world atmospheric turbulence compared to state-of-the-art methods.  It uses KLT tracking to visualize the motion of features in the video and shows how ConVRT leads to smoother and more consistent trajectories, indicating improved temporal consistency in the restoration of the video.", "section": "4 Experiments"}, {"figure_path": "yURca4wi2L/figures/figures_14_1.jpg", "caption": "Figure 11: Mitigation capability of our method without using base restoration methods for preprocessing.", "description": "This figure demonstrates the effectiveness of the proposed method (ConVRT) in mitigating atmospheric turbulence without relying on any base restoration techniques for preprocessing. It presents a comparison between the original video frame with turbulence, the results after applying ConVRT, and the results obtained using DATUM (a state-of-the-art video atmospheric turbulence mitigation method) with and without ConVRT. The comparison is made using visual inspection and analysis of KLT tracking and Y-t slice plots which show improved temporal consistency and reduced artifacts when using the proposed method.", "section": "4 Experiments"}]