[{"figure_path": "FBMsBdH0yz/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of results in this paper. One-way arrows denote strict inclusion; two-way arrows denote equivalence. PE = position embedding.", "description": "This figure summarizes the main results of the paper, showing the relationships between different classes of formal languages and their corresponding masked hard-attention transformer models.  It illustrates how various factors, such as the type of masking (strict future, strict future and past, non-strict masking), the presence or absence of position embeddings, and the depth of the transformer, affect the expressive power of the model. The relationships are represented using arrows: one-way arrows indicate strict inclusion (a smaller class is strictly contained within a larger class), and two-way arrows indicate equivalence (two classes have the same expressive power). The figure helps to visually understand the hierarchy of expressiveness established in the paper.", "section": "1 Introduction"}, {"figure_path": "FBMsBdH0yz/figures/figures_17_1.jpg", "caption": "Figure 3: Example automaton and its cascade decomposition.", "description": "This figure shows an example of a deterministic finite automaton (DFA) and how it can be decomposed into a cascade product of identity-reset automata.  The DFA (A3) is represented visually, showing its states (0-3) and transitions labeled with 'L' (left) or 'R' (right). The cascade decomposition breaks down the DFA into smaller, simpler automata, which are easier to work with. The final part of the figure depicts the \"global automaton\" of this cascade product, showing the relationship between the combined states and the original DFA.", "section": "B.5 Counter-free automata to B-RASP"}, {"figure_path": "FBMsBdH0yz/figures/figures_17_2.jpg", "caption": "Figure 3: Example automaton and its cascade decomposition.", "description": "This figure shows an example of an automaton (a finite state machine) and how it can be decomposed into a cascade of simpler automata.  The top panel (a) shows a simple automaton with two states. The middle panel (b) displays a cascade decomposition of the automaton, where the cascade is composed of three simpler automata. Each of these simpler automata has the property that for any input, the transformation of states is either a permutation (each state maps to a different state) or a constant function (all states map to the same state). The bottom panel (c) depicts the global automaton resulting from this cascade decomposition, showing its relationship to the original automaton. This decomposition is a key part of the proof that shows the equivalence between Boolean RASP and linear temporal logic for recognizing star-free languages.", "section": "3.5 Counter-free automata to B-RASP"}, {"figure_path": "FBMsBdH0yz/figures/figures_17_3.jpg", "caption": "Figure 3: Example automaton and its cascade decomposition.", "description": "This figure illustrates an example of an automaton (A3) and its decomposition into a cascade product of identity-reset automata.  Part (a) shows the original automaton A3 with states representing the number of left or right brackets currently unmatched. Part (b) shows the cascade decomposition, where each automaton is an identity-reset automaton, meaning it either keeps the state the same or changes to a new state based on the input symbol. The transitions in (b) are simplified by showing only non-self-loop transitions for clarity.  Part (c) depicts the global automaton resulting from the cascade product in part (b), showing the combined states and transitions of all the identity-reset automata in a larger automaton. The state number corresponds to the corresponding state in A3.  This decomposition is key in explaining how the authors can reduce the complexity of proving the star-free language recognition ability of transformers by breaking them down into more basic manageable units.", "section": "3 Boolean RASP"}]