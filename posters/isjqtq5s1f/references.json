{"references": [{"fullname_first_author": "Koh, P. W.", "paper_title": "Concept bottleneck models", "publication_date": "2020-00-00", "reason": "This paper introduces Concept Bottleneck Models (CBMs), the foundational model that the current research builds upon and improves."}, {"fullname_first_author": "Havasi, M.", "paper_title": "Addressing leakage in concept bottleneck models", "publication_date": "2022-00-00", "reason": "This paper addresses a critical limitation of CBMs, leakage, which is directly relevant to and addressed by the current work."}, {"fullname_first_author": "Marcinkevi\u010ds, R.", "paper_title": "Beyond concept bottleneck models: How to make black boxes intervenable?", "publication_date": "2024-00-00", "reason": "This paper directly addresses the topic of improving intervention strategies in CBMs, a key focus of the current research."}, {"fullname_first_author": "Shin, S.", "paper_title": "A closer look at the intervention procedure of concept bottleneck models", "publication_date": "2023-00-00", "reason": "This paper analyzes and improves the intervention strategy within CBMs, which is a key element addressed in the current work's improvements."}, {"fullname_first_author": "Brown, T.", "paper_title": "Language models are few-shot learners", "publication_date": "2020-00-00", "reason": "This paper provides the foundational large language model used for concept discovery in the current work, enabling the extension of the methodology to datasets without manual concept annotations."}]}