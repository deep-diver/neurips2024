[{"figure_path": "gC3BzNwqQp/figures/figures_8_1.jpg", "caption": "Figure 1: Simulation results of DEMBA algorithm with benchmarks. Top row: geometric delays. Bottom row: uniform delays. Left: E[ds] = 500, \u03bc = 100; Middle E[ds] = 100, \u03bc = 100; Right: E[ds] = 100, \u03bc = 500. Results are averaged over 100 independent runs.", "description": "This figure displays the simulation results of the DEMBA algorithm and compares its performance against benchmark algorithms (EXP) under various settings. The top row shows the results with geometrically distributed delays, while the bottom row shows results for uniformly distributed delays. Each column represents different delay parameters (E[ds] and \u03bc). The x-axis represents the number of rounds, and the y-axis represents the cumulative regret. The shaded areas represent the standard error over 100 independent runs.", "section": "7 Experiments"}, {"figure_path": "gC3BzNwqQp/figures/figures_9_1.jpg", "caption": "Figure 2: Left: Performance change of DEMBA algorithm with different contrast levels. Right: PA-DEMBA and benchmarks with non-thresholded delays. Results are averaged over 100 independent runs.", "description": "The left plot in Figure 2 shows how the performance of the DEMBA algorithm varies with different contrast levels (parameter 'e').  The contrast level affects the difficulty of distinguishing between products, and as expected, higher contrast makes learning easier. The right plot compares the performance of the PA-DEMBA algorithm (designed for non-thresholded delay settings) against benchmark algorithms. The shaded areas represent confidence intervals around the mean cumulative regret.", "section": "7 Experiments"}, {"figure_path": "gC3BzNwqQp/figures/figures_9_2.jpg", "caption": "Figure 3: Comparison with MNL-Bandit. Left: no delay; Middle E[ds] = 50; Right: E[ds] = 100. Results are averaged over 100 independent runs.", "description": "This figure compares the performance of the DEMBA algorithm against the MNL-Bandit algorithm and an explore-then-exploit (EXP) strategy under different delay conditions (no delay, E[ds] = 50, E[ds] = 100).  The results show that DEMBA consistently outperforms the EXP strategy and is comparable to MNL-Bandit in the no-delay scenario, but significantly outperforms MNL-Bandit when delays are present, highlighting its effectiveness in handling delayed feedback.", "section": "7 Experiments"}]