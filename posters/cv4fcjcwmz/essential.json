{"importance": "This paper is crucial because **it reveals a significant vulnerability in the widespread practice of sharing pre-trained molecular models** without exposing the underlying data. The research highlights that **malicious actors can extract sensitive training data from these models**, raising serious concerns about commercial confidentiality and collaborative trust. This necessitates a reassessment of current data sharing practices and motivates the development of robust data protection techniques for pre-trained models in the field.", "summary": "Researchers reveal a high risk of training data extraction from molecular pre-trained models, challenging the assumption that model sharing alone adequately protects against data theft.", "takeaways": ["Molecular pre-trained models, while beneficial for collaboration, are vulnerable to data extraction attacks.", "A novel, model-independent scoring function and molecule generation approach effectively extracts training data, even with only query access to the models.", "This research challenges the assumption that sharing pre-trained models alone provides adequate data protection."], "tldr": "Many organizations share pre-trained molecular models to facilitate drug discovery without revealing proprietary training data. However, this practice may pose privacy risks. This paper explores the risk of extracting private training molecular data from these models, which is challenging because they are non-generative and exhibit diverse model architectures. \nThe researchers introduce a novel, model-independent scoring function for evaluating molecule candidates extracted from molecular pre-trained models and a Molecule Extraction Policy Network to improve the efficiency of molecule extraction. Experimental results demonstrate that there is a considerable risk of extracting training data from pre-trained models.  This challenges the assumption that sharing only pre-trained models provides adequate data protection.", "affiliation": "Zhejiang University", "categories": {"main_category": "AI Theory", "sub_category": "Privacy"}, "podcast_path": "cV4fcjcwmz/podcast.wav"}