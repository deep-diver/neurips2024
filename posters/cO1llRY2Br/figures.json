[{"figure_path": "cO1llRY2Br/figures/figures_2_1.jpg", "caption": "Figure 1: Architecture of iReVa. The left block shows the training procedure with the newly inserted knowledge neurons. The middle block shows the inference procedure with in-scope and out-of-scope edits. We interpret the inference phase by giving some explicit examples (Please note we omit some neurons during inference due to the space limit.). When the query falls in the in-scope edit, our key-value adaptor will be activated and retrieve the corresponding knowledge. When the query falls in the out-of-scope edit, our key-value adaptor is inactive and the model retrieves knowledge from the original memory.", "description": "This figure illustrates the architecture of the iReVa model, showing the training process and inference processes for both in-scope and out-of-scope edits.  The training process shows how new knowledge neurons are added to the model. The inference process diagrams show how the key-value adaptor interacts with the original knowledge neurons depending on whether the input is within or outside the scope of the edit. In-scope edits activate the adaptor, retrieving the relevant new knowledge. Out-of-scope edits leave the adaptor inactive, relying on the original knowledge.", "section": "4 Method"}, {"figure_path": "cO1llRY2Br/figures/figures_8_1.jpg", "caption": "Figure 1: Architecture of iReVa. The left block shows the training procedure with the newly inserted knowledge neurons. The middle block shows the inference procedure with in-scope and out-of-scope edits. We interpret the inference phase by giving some explicit examples (Please note we omit some neurons during inference due to the space limit.). When the query falls in the in-scope edit, our key-value adaptor will be activated and retrieve the corresponding knowledge. When the query falls in the out-of-scope edit, our key-value adaptor is inactive and the model retrieves knowledge from the original memory.", "description": "This figure illustrates the architecture of the iReVa model, showing the training and inference processes for both in-scope and out-of-scope edits.  The left panel depicts the training process with newly added knowledge neurons. The middle and right panels show the inference process for in-scope edits (where the model uses the key-value adaptor to retrieve new knowledge) and out-of-scope edits (where the model retrieves knowledge only from the original memory), respectively.  Explicit examples are provided for clarity. ", "section": "4 Method"}, {"figure_path": "cO1llRY2Br/figures/figures_8_2.jpg", "caption": "Figure 3: Results of edits with various size on zsRE dataset with GPT2-XL as the base model.", "description": "This figure shows the results of experiments conducted to evaluate the impact of varying the number of edits on the performance of iReva and two baseline models (ROME and MEMIT) using the zsRE dataset and GPT2-XL.  The graph shows how the edit success, paraphrase success, and neighborhood success metrics change as the number of edits increases.  The results illustrate the robustness of iReva compared to the baseline models, where iReva shows consistent improvement across various numbers of edits.", "section": "6.5 Generalization Capabilities of iReVa"}, {"figure_path": "cO1llRY2Br/figures/figures_11_1.jpg", "caption": "Figure 4: Correlation between three metrics and (left) \u03b8 or \u03b1(right) of iReVa, ROME, MEMIT", "description": "This figure shows the impact of hyperparameters \u03b8 and \u03b1 on the performance of iReVa and compares it to two baselines, ROME and MEMIT. The left plot illustrates the influence of \u03b8 on Edit Success, Paraphrase Success, and Neighborhood Success. The right plot demonstrates the effect of \u03b1 on the same three metrics.  The plots show the trade-off between the metrics and how the hyperparameters affect the balance between successfully editing knowledge, generalizing to paraphrases, and maintaining specificity to avoid affecting unrelated knowledge. ", "section": "A.3 Influence of \u03b8 and \u03b1"}]