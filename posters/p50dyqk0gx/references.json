{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-11", "reason": "This paper introduces CLIP, a foundational vision-language model that is extensively used and adapted in this paper's methods and experiments."}, {"fullname_first_author": "Mitchell Wortsman", "paper_title": "Robust fine-tuning of zero-shot models", "publication_date": "2022-06-20", "reason": "This work directly addresses the robustness challenges in fine-tuning zero-shot models, a core focus of this paper, and proposes a related method (WiSE-FT) that is compared against."}, {"fullname_first_author": "Sachin Goyal", "paper_title": "Finetune like you pretrain: Improved finetuning of zero-shot vision models", "publication_date": "2023-06-20", "reason": "This paper introduces FLYP, a key baseline method for this paper, which this paper improves upon with the proposed DRM approach."}, {"fullname_first_author": "Ananya Kumar", "paper_title": "Fine-tuning can distort pretrained features and underperform out-of-distribution", "publication_date": "2022-04-01", "reason": "This paper highlights the issue of pre-trained feature distortion during fine-tuning, which is a core problem this paper aims to solve."}, {"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-01", "reason": "This paper introduces GPT-4, the large language model used to generate concept descriptions which are crucial to the proposed DRM method"}]}