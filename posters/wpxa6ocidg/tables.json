[{"figure_path": "WPxa6OcIdg/tables/tables_2_1.jpg", "caption": "Table 1: Comparison of training and inference times. The time required to train an M = 10 member ensemble on the LUNA16 dataset is shown in the second column. The third column shows the time required to generate a predictive distribution of size M \u00d7 N = 1000 for a single input.", "description": "This table compares the training and inference times for three different uncertainty quantification methods: MC-Dropout, DPS-UQ, and the proposed HyperDM method.  It shows the time taken to train a 10-model ensemble (M=10) on the LUNA16 dataset and the time needed to generate a predictive distribution (M x N = 1000 samples) for a single input.  The results highlight the computational efficiency of HyperDM compared to other methods.", "section": "2 Related Work"}, {"figure_path": "WPxa6OcIdg/tables/tables_6_1.jpg", "caption": "Table 2: Ensemble prediction quality on real-world data. Baseline image quality assessment scores are calculated on test data from a CT dataset (i.e., LUNA16) and a weather forecasting dataset (i.e., ERA5). Best scores are highlighted in red and second best scores are highlighted in blue.", "description": "This table compares the performance of three different methods (MC-Dropout, DPS-UQ, and HyperDM) for estimating uncertainty in two real-world tasks: CT reconstruction and weather forecasting.  The metrics used are SSIM, PSNR, and CRPS.  Higher SSIM and PSNR values indicate better image quality, while a lower CRPS value indicates better uncertainty estimation. The best and second-best results for each method and dataset are highlighted in red and blue, respectively.", "section": "5 Experiments"}, {"figure_path": "WPxa6OcIdg/tables/tables_15_1.jpg", "caption": "Table 2: Ensemble prediction quality on real-world data. Baseline image quality assessment scores are calculated on test data from a CT dataset (i.e., LUNA16) and a weather forecasting dataset (i.e., ERA5). Best scores are highlighted in red and second best scores are highlighted in blue.", "description": "This table compares the performance of three different methods (MC-Dropout, DPS-UQ, and HyperDM) for estimating uncertainty in two real-world applications: Computed Tomography (CT) image reconstruction (LUNA16 dataset) and weather forecasting (ERA5 dataset).  For each dataset and method, it reports the Structural Similarity Index (SSIM), Peak Signal-to-Noise Ratio (PSNR), L1 error, and Continuous Ranked Probability Score (CRPS).  Higher SSIM and PSNR values indicate better image quality, while lower L1 and CRPS values indicate better prediction accuracy and uncertainty estimation, respectively. The best and second-best results for each metric are highlighted in red and blue, respectively.", "section": "5 Experiments"}, {"figure_path": "WPxa6OcIdg/tables/tables_16_1.jpg", "caption": "Table 2: Ensemble prediction quality on real-world data. Baseline image quality assessment scores are calculated on test data from a CT dataset (i.e., LUNA16) and a weather forecasting dataset (i.e., ERA5). Best scores are highlighted in red and second best scores are highlighted in blue.", "description": "This table compares the performance of three different methods (MC-Dropout, DPS-UQ, and HyperDM) for estimating uncertainty in real-world datasets.  The metrics used are SSIM, PSNR (dB), and CRPS.  The results show that HyperDM generally achieves higher image quality and lower uncertainty scores compared to the baselines.  The use of two datasets, LUNA16 (CT scans) and ERA5 (weather forecasting), helps demonstrate the robustness and generalizability of the proposed HyperDM.", "section": "5 Experiments"}]