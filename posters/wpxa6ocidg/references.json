{"references": [{"fullname_first_author": "A. F. Agarap", "paper_title": "Deep learning using rectified linear units (relu)", "publication_date": "2018-03-15", "reason": "This paper introduces the ReLU activation function, a crucial component in many modern deep learning models, including those used in this work for CT reconstruction and weather forecasting."}, {"fullname_first_author": "D. J. MacKay", "paper_title": "A practical Bayesian framework for backpropagation networks", "publication_date": "1992-03-01", "reason": "This paper presents the foundational work on Bayesian Neural Networks (BNNs), a key method for quantifying uncertainty in machine learning that this paper builds upon."}, {"fullname_first_author": "Y. Gal", "paper_title": "Uncertainty in Deep Learning", "publication_date": "2016-01-01", "reason": "This thesis provides a comprehensive overview of uncertainty in deep learning, which is a central theme of this paper and establishes the distinction between aleatoric and epistemic uncertainty."}, {"fullname_first_author": "Y. Gal", "paper_title": "Dropout as a Bayesian approximation: Representing model uncertainty in deep learning", "publication_date": "2016-01-01", "reason": "This paper introduces the Monte Carlo dropout method, a widely used technique for uncertainty estimation in neural networks, which is compared to the proposed approach in this work."}, {"fullname_first_author": "B. Lakshminarayanan", "paper_title": "Simple and scalable predictive uncertainty estimation using deep ensembles", "publication_date": "2017-01-01", "reason": "This paper introduces the concept of deep ensembles, a powerful technique for uncertainty quantification, and the computational cost and scalability challenges associated with training ensembles is addressed by this paper."}]}