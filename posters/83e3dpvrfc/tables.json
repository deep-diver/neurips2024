[{"figure_path": "83e3DPVrFC/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparison of different L2I approaches under image resolution at 512x512.\u2018\u2191\u2019 means that the higher the better, \u2018\u2193\u2019 means that the lower the better.", "description": "This table presents a quantitative comparison of various layout-to-image (L2I) generation methods on two datasets, RC COCO and RC CC3M.  The comparison is based on three metrics: CropCLIP (object label alignment), SAMIOU (layout fidelity), and FID (image quality). The table includes both constrained and open-set methods, showing the performance of each method across the two datasets. Higher CropCLIP and SAMIOU scores are better, while a lower FID score is better.  The results are specifically for images generated at a 512x512 resolution.", "section": "5 Experiments"}, {"figure_path": "83e3DPVrFC/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative comparison of different L2I approaches under image resolution at 512x512.\u2018\u2191\u2019 means that the higher the better, \u2018\u2193\u2019 means that the lower the better.", "description": "This table presents a quantitative comparison of various Layout-to-Image (L2I) generation approaches. The comparison is done using four metrics: CropCLIP, SAMIOU, FID, and the performance is evaluated under two datasets RC COCO and RC CC3M.  The table shows the performance of different models on these datasets, highlighting the relative performance of each model based on the metrics used. The table provides a clear understanding of the relative strengths and weaknesses of the different L2I models in terms of object-label alignment and layout fidelity.", "section": "5.3 Rich-Context Layout-to-Image Generation"}, {"figure_path": "83e3DPVrFC/tables/tables_13_1.jpg", "caption": "Table 3: For LPIPS computation, each layout is inferred twice, and the score is calculated using AlexNet. A higher LPIPS score indicates a larger feature distance between two generated images with the same layouts, signifying greater sample-wise generation diversity. A higher Inception Score suggests a more varied appearance of generated images, indicating greater overall generation diversity.", "description": "This table presents the results of evaluating the diversity of generated images by two metrics: LPIPS and Inception Score.  LPIPS measures the difference in features between images generated from the same layout, with a higher score indicating more diversity. The Inception Score reflects the overall diversity of the generated images, also with a higher score representing more diversity.  The results are shown for different models, including GLIGEN, InstDiff, and two versions of the proposed model (using SD1.5 and SDXL backbones).", "section": "Layout-to-Image Generation Diversity Comparison"}, {"figure_path": "83e3DPVrFC/tables/tables_15_1.jpg", "caption": "Table 4: The performance is evaluated on RC CC3M evaluation set and all methods are sampled under their best sampling resolution as discussed in Section 5.5. It can be noticed that even with the rich-context dataset, the performance of self-attention-based modules does not show significant improvement over their performance in the Table 1 in the paper.", "description": "This table presents the quantitative results of different layout-to-image (L2I) generation methods using the Rich-Context CC3M (RC CC3M) dataset. It compares the performance of methods using different backbones (SDXL and SD1.5), datasets (Word/Phrase and Rich-context), and attention modules (Self-Attn, CrossAttn). The metrics used are CropCLIP and SAMIOU. The results show that even with a rich-context dataset, self-attention-based methods do not significantly outperform the proposed method.", "section": "5.5 Ablation Study"}]