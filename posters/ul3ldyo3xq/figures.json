[{"figure_path": "Ul3lDYo3XQ/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure illustrates the architecture of the AGILE agent system, which comprises four main modules: Large Language Model (LLM), Memory, Tools, and Executor.  The LLM acts as the policy model, generating actions (tokens) that are interpreted and executed by the Executor. The Executor interacts with the environment (including user and expert), Memory and Tools to execute the agent's actions and manage the system state.  The (b) part shows a running example in a customer service scenario, showcasing how the different modules interact in a question-answering context.  The agent uses memory, consults an expert, and updates its knowledge base through reflection and updates to memory.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_6_1.jpg", "caption": "Figure 2: Accuracy and advice rate over the following 200 sessions (c = 0.3).", "description": "This figure shows the accuracy and advice rate of different agents over 200 sessions.  The seeking advice cost (c) is set to 0.3.  It demonstrates the trend of the advice rate decreasing over time, indicating the agent's learning and increasing independence. The accuracy of agile-vic13b-ppo consistently outperforms other agents.", "section": "4.2 Results on ProductQA"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_6_2.jpg", "caption": "Figure 3: Advice rate, accuracy along with seeking advice cost c on ProductQA.", "description": "This figure shows the relationship between the seeking advice cost (c) and the resulting advice rate and accuracy on the ProductQA dataset.  As the cost (c) decreases, both the advice rate and accuracy increase. This indicates that when the cost of seeking advice is lower, the agent is more likely to seek advice and, consequently, achieve higher accuracy.  The figure visually demonstrates the trade-off between the cost of seeking advice and the accuracy achieved.", "section": "4.2 Results on ProductQA"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_7_1.jpg", "caption": "Figure 4: Advice rate over the following 200 sessions on ProductQA (c = 0.3).", "description": "This figure displays the trend of advice rate over sessions in the ProductQA experiment, with a seeking advice cost (c) set to 0.3.  It shows a consistent decrease in the advice rate of the agile-vic13b-ppo agent as more sessions are added to the trajectory.  This is because the agent progressively accumulates knowledge and becomes more independent.  The figure also shows that disabling reinforcement learning (RL) training or reflection leads to a significant increase in the advice rate, highlighting the importance of these components for reducing human costs.", "section": "4.2 Results on ProductQA"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_18_1.jpg", "caption": "Figure 5: Reward and value function loss curves during the PPO training process on ProductQA.", "description": "This figure shows two curves plotting the reward and value function loss during the Proximal Policy Optimization (PPO) training process on the ProductQA dataset.  The reward curve generally increases over the training steps, indicating that the agent's performance is improving. The value function loss curve initially decreases significantly, implying that the value function is being learned effectively, and then plateaus, suggesting convergence.  Both trends suggest that the PPO training is successful in optimizing the agent's policy.", "section": "C Supplementary experimental results on RL training"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_30_1.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure shows the architecture of the AGILE agent system, which consists of four main modules: the Large Language Model (LLM), memory, tools, and an executor.  The LLM is responsible for generating actions (tokens) based on the context, which includes information from memory and tools. The executor interacts with the environment (users or experts), retrieves information from memory and tools as instructed by the LLM, and updates the memory based on LLM's instructions.  The figure also presents a running example of the AGILE agent in a customer service question-answering scenario, illustrating the flow of information and actions within the system.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_30_2.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure shows the architecture of the AGILE agent system, which consists of four modules: Large Language Model (LLM), memory, tools, and executor.  The LLM acts as the main decision-maker, generating instructions and processing responses. The executor then interprets these instructions and interacts with the memory, tools, and environment.  Part (b) gives a running example of the system in a customer service question-answering scenario. The flow of information and actions is visualized, highlighting the interactions between the LLM and the executor, as well as the use of memory and external tools.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_31_1.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure shows the architecture of the AGILE agent system which consists of four modules: LLM, memory, tools, and executor.  The LLM is the core component generating instructions and processing responses. The executor interprets the instructions and activates the corresponding modules. Memory stores and retrieves information. Tools perform actions like searching.  The (b) part shows a running example of the system in a customer service QA setting, illustrating the flow of information and actions between the modules and the user.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_31_2.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "Figure 1(a) shows the architecture of the AGILE agent system which comprises four modules: LLM, memory, tools, and executor.  The LLM is responsible for generating instructions and processing responses. The executor interprets the LLM instructions and interacts with the other modules (memory and tools) and the environment. Figure 1(b) illustrates a running example of the AGILE agent system in a customer service QA scenario, showing how the agent interacts with the user and utilizes different modules to answer questions. The tokens (actions) generated by the LLM are highlighted in orange, while the tokens appended by the executor are highlighted in blue.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_31_3.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure shows the architecture of the AGILE agent system, which consists of four main modules: LLM, memory, tools, and executor. The LLM acts as the policy model, generating actions (tokens) that are interpreted and executed by the executor. The executor interacts with the environment (e.g., user, expert, tools), retrieving information and updating memory.  The running example illustrates a conversational QA scenario where the agent uses memory, tools and seeks advice from an expert to answer the user's question.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_31_4.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure illustrates the architecture of the AGILE agent system, which consists of four key modules: the Large Language Model (LLM), memory, tools, and an executor.  The LLM is the core of the system, generating instructions and processing responses. The executor orchestrates interactions between the LLM and other components, including memory and tools, as well as human experts and users.  The figure also shows a running example demonstrating how the various components work together during a question-answering task in a customer service context.  Orange tokens represent actions generated by the LLM, while blue tokens are those appended by the executor.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_33_1.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure shows the architecture of the AGILE agent system, which consists of four main modules: LLM, memory, tools, and executor.  The LLM serves as the core policy model, generating actions (tokens) which are then processed by the executor to interact with the environment (including users and experts), memory, and tools.  The diagram also illustrates a running example of the AGILE agent performing a customer service question-answering task, highlighting the flow of information between the modules and the use of different actions.", "section": "1 Introduction"}, {"figure_path": "Ul3lDYo3XQ/figures/figures_33_2.jpg", "caption": "Figure 1: (a) Architecture of our agent system, including LLM, memory, tools, and executor. (b) A running example of AGILE in a customer service QA environment. The tokens (actions) generated by the LLM are in orange color and the tokens appended by the executor are in blue color.", "description": "This figure shows the architecture of the AGILE agent system, which consists of four main modules: Language Model (LLM), memory, tools, and an executor. The LLM acts as the policy model, generating instructions for the executor to carry out actions such as retrieving information from memory, using tools, or interacting with users and experts. The running example illustrates a typical interaction between the AGILE agent and a user in a customer service QA scenario.  The agent uses several modules and interacts with an expert to answer a question.", "section": "1 Introduction"}]