{"references": [{"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces the Chain-of-Thought prompting method, a core concept analyzed and built upon in the current paper."}, {"fullname_first_author": "Takeshi Kojima", "paper_title": "Large language models are zero-shot reasoners", "publication_date": "2022-12-01", "reason": "This paper demonstrates that Large Language Models can perform zero-shot reasoning, providing a baseline for comparison with the chain-of-thought method."}, {"fullname_first_author": "Xuezhi Wang", "paper_title": "Self-consistency improves chain of thought reasoning in language models", "publication_date": "2022-12-01", "reason": "This paper introduces self-consistency, an important extension to the chain-of-thought method that is also evaluated in the current paper."}, {"fullname_first_author": "Karl Cobbe", "paper_title": "Training verifiers to solve math word problems", "publication_date": "2021-10-26", "reason": "This paper provides a commonly used benchmark dataset for evaluating reasoning abilities in large language models, which is also referenced in the current paper."}, {"fullname_first_author": "S\u00e9bastien Bubeck", "paper_title": "Sparks of artificial general intelligence: Early experiments with gpt-4", "publication_date": "2023-03-15", "reason": "This paper is among the first to extensively study the capabilities of GPT-4, which is also one of the LLMs used for the experiments in the current paper."}]}