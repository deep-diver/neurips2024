{"references": [{"fullname_first_author": "A. Azizi", "paper_title": "T-miner: A generative approach to defend against trojan attacks on DNN-based text classification", "publication_date": "2021-08-11", "reason": "This paper proposes T-miner, a generative defense against trojan attacks, which is directly compared against in the current paper's experiments."}, {"fullname_first_author": "K. Chen", "paper_title": "Badpre: Task-agnostic backdoor attacks to pre-trained NLP foundation models", "publication_date": "2022-04-25", "reason": "This paper introduces Badpre, a task-agnostic backdoor attack, which is used as a benchmark in the current paper's experimental evaluation of the proposed defense."}, {"fullname_first_author": "X. Chen", "paper_title": "Badnl: Backdoor attacks against NLP models with semantic-preserving improvements", "publication_date": "2021-12-06", "reason": "This paper introduces Badnl, a backdoor attack against NLP models, forming a basis for comparison and analysis in the current research."}, {"fullname_first_author": "J. Devlin", "paper_title": "BERT: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019-06-02", "reason": "This highly influential paper introduces BERT, a foundational language model used extensively in the current paper's experiments, thus shaping the context and impact of the research."}, {"fullname_first_author": "Y. Liu", "paper_title": "Piccolo: Exposing complex backdoors in NLP transformer models", "publication_date": "2022-05-22", "reason": "This paper introduces Piccolo, another significant backdoor defense method, serving as a key comparison point for evaluating the effectiveness of the proposed LT-Defense."}]}