[{"figure_path": "LDzrQB4X5w/tables/tables_1_1.jpg", "caption": "Table 1: Comparison to state-of-the-art. The following notation is used: T is the time horizon, K is the number of arms, i indexes the arms, Ai is the suboptimality gap or arm i, omax is the maximal number of outstanding observations, D = \u2211t=1 dt is the total delay, S \u2286 [T] is a set of skipped rounds, S = [T] \nbsp; S is the set of non-skipped rounds, D\u00af = \u2211t\u2208S dt is the total delay in the non-skipped rounds, and dmax is the maximal delay. We have mins(|S| + \u221aDs) \u2264 \u221aD and omax \u2264 dmax, and in some cases mins(|S| + \u221aDs) < \u221aD and omax < dmax.", "description": "This table compares the key results (regret bounds) of the proposed algorithm with those of several state-of-the-art algorithms for bandits with delayed feedback.  It highlights the differences in terms of assumptions (e.g., knowledge of maximal delay), regret bounds (stochastic and adversarial), and the use of skipping techniques to handle excessive delays.  The notation used in the regret bounds is defined in the caption, allowing for a detailed comparison of the algorithm's performance under different scenarios.", "section": "Comparison to state-of-the-art"}]