{"references": [{"fullname_first_author": "Pang Wei Koh", "paper_title": "Concept bottleneck models", "publication_date": "2020-00-00", "reason": "This paper introduces the core concept of Concept Bottleneck Models (CBMs), which is the foundation of the research presented in the current paper."}, {"fullname_first_author": "Tuomas Oikarinen", "paper_title": "Label-free concept bottleneck models", "publication_date": "2023-00-00", "reason": "This paper proposes a method to automate the training of CBMs using large language models, which is a crucial improvement over manual annotation and directly relevant to the current research."}, {"fullname_first_author": "An Yan", "paper_title": "Learning concise and descriptive attributes for visual recognition", "publication_date": "2023-00-00", "reason": "This paper is highly relevant as it proposes an approach to address one of the key limitations of previous CBM approaches, that of information leakage, which is a central focus of the current work."}, {"fullname_first_author": "Liunian Harold Li", "paper_title": "Grounded language-image pre-training", "publication_date": "2022-00-00", "reason": "This paper introduces a vision-language model (GLIP) that is leveraged in the proposed approach (VLG-CBM) to provide visually grounded concept annotation, significantly improving the faithfulness and performance of CBM."}, {"fullname_first_author": "Shilong Liu", "paper_title": "Grounding DINO: Marrying DINO with grounded pre-training for open-set object detection", "publication_date": "2023-00-00", "reason": "This paper introduces a state-of-the-art grounded object detection model that is used in VLG-CBM to enable faithful interpretability and improved performance."}]}