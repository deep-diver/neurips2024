[{"figure_path": "PcyioHOmjq/tables/tables_21_1.jpg", "caption": "Table 1: Results of the tail classes on YFCC-15M.", "description": "This table presents the frequency and accuracy of CLIP on tail classes in the YFCC-15M dataset.  The \"Freq.\" column indicates how many times each class appears in the dataset. The \"Acc.\" column shows the accuracy CLIP achieved on each class.  It highlights that even though some classes are extremely rare (appearing only once or twice), CLIP still manages to achieve relatively high accuracy on a subset of them, demonstrating robustness to data imbalance.", "section": "A.7 Can CLIP achieve robust generalization to extremely rare concepts?"}, {"figure_path": "PcyioHOmjq/tables/tables_27_1.jpg", "caption": "Table 2: Linear probing evaluation results of DINO variants pre-trained on LAIONet for 100 epochs. Extreme data imbalance makes LAIONet much harder for DINO to learn transferrable representations, and vocabulary subsampling strategy effectively helps DINO overcome such defects.", "description": "This table presents the results of transfer learning experiments using the DINO model.  Different versions of DINO were pre-trained on the LAIONet dataset, which is known for its imbalanced data distribution. The table compares the performance of vanilla DINO against versions that utilize vocabulary subsampling.  The models are evaluated across several downstream datasets (Voc, Aircr, Birds, etc.), showing improvements in transfer learning performance when vocabulary subsampling is applied.", "section": "E.5 Original numeric data of DINO transfer learning results"}]