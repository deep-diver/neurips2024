[{"figure_path": "vunJCq9PwU/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of (Calibrated) GREAT Score v.s. minimal distortion found by CW attack [7] on CIFAR-10. The results are averaged over 500 samples from StyleGAN2.", "description": "This table compares the performance of GREAT Score and the minimal distortion found by the Carlini-Wagner (CW) attack on the CIFAR-10 dataset.  For each of the seventeen models listed, it shows the RobustBench accuracy, AutoAttack accuracy, the uncalibrated GREAT Score, the calibrated GREAT Score, and the average minimal distortion from the CW attack. The results are averaged across 500 samples generated using StyleGAN2.  The table demonstrates how well GREAT Score aligns with the CW attack's findings and its capability to provide calibrated, attack-proof robustness evaluations.", "section": "4.2 Local and Global Robustness Analysis"}, {"figure_path": "vunJCq9PwU/tables/tables_7_2.jpg", "caption": "Table 2: Spearman's rank correlation coefficient on CIFAR-10 using GREAT Score, RobustBench (with test set), and Auto-Attack (with generated samples).", "description": "This table presents the Spearman's rank correlation coefficients between different model ranking methods on the CIFAR-10 dataset. It compares the rankings produced by GREAT Score, RobustBench (using its standard test set and AutoAttack), and Auto-Attack (using generated samples).  The table shows the correlation between the rankings of these methods, both before and after calibration of the GREAT Score. High correlation indicates that the different methods agree on the relative robustness of the models. The calibration improves the correlation of GREAT Score with both RobustBench and AutoAttack.", "section": "4.3 Model Ranking on CIFAR-10 and ImageNet"}, {"figure_path": "vunJCq9PwU/tables/tables_8_1.jpg", "caption": "Table 3: Robustness evaluation on ImageNet using GREAT Score, RobustBench (with test set), and Auto Attack (with generated samples). The Spearman's rank correlation coefficient for GREAT Score v.s. RobustBench and Auto-Attack v.s. RobustBench is 0.9 and 0.872, respectively.", "description": "This table presents the global robustness statistics for three different methods on the ImageNet dataset.  It shows the RobustBench Accuracy (%), AutoAttack Accuracy (%), and GREAT Score for five different models.  The Spearman's rank correlation coefficients between GREAT Score and RobustBench, and AutoAttack and RobustBench are provided, demonstrating a strong alignment in ranking between GREAT Score and RobustBench.", "section": "4.3 Model Ranking on CIFAR-10 and ImageNet"}, {"figure_path": "vunJCq9PwU/tables/tables_9_1.jpg", "caption": "Table 4: Group-wise and overall robustness evaluation for online gender classification APIs over 500 generated samples (per group).", "description": "This table presents the GREAT Score results for six online gender classification APIs, evaluated using 500 synthetically generated face images for each of four groups: Old, Young, With Eyeglasses, and Without Eyeglasses.  The GREAT Score, a metric for evaluating adversarial robustness, is calculated for each group and overall. The results demonstrate how GREAT Score can be used to analyze group-level robustness in access-limited systems, highlighting potential vulnerabilities or biases related to specific attributes (like age or eyeglasses).", "section": "4.5 Evaluation on Online Facial Recognition APIs"}, {"figure_path": "vunJCq9PwU/tables/tables_9_2.jpg", "caption": "Table 4: Group-wise and overall robustness evaluation for online gender classification APIs over 500 generated samples (per group).", "description": "This table presents the results of a robustness evaluation performed on six online gender classification APIs.  The evaluation used 500 synthetically generated face images per group, categorized by age (Old, Young) and the presence of eyeglasses (With, Without).  Two metrics are reported: the success rate of a square attack (a type of adversarial attack) and the GREAT Score (a new metric for global robustness introduced in the paper).  The table shows how the robustness of each API varies depending on the image characteristics (age and presence of eyeglasses).", "section": "4.5 Evaluation on Online Facial Recognition APIs"}, {"figure_path": "vunJCq9PwU/tables/tables_14_1.jpg", "caption": "Table 6: Main notations used in this paper", "description": "This table lists the notations used throughout the paper, providing a concise reference for readers.  Each notation is paired with its description, clarifying its meaning within the context of the paper's framework for evaluating global adversarial robustness.  The descriptions cover variable types (e.g., dimensionality, classifier), data properties (e.g., sample, perturbation), and key concepts (e.g., minimum adversarial perturbation, generative model).  Understanding this table is essential for interpreting the mathematical formulations and algorithms presented in the paper.", "section": "A Notations"}, {"figure_path": "vunJCq9PwU/tables/tables_18_1.jpg", "caption": "Table 7: Spearman's rank correlation coeffienct on CIFAR-10 using GREAT Score, RobustBench (with test set), and Auto-Attack (with generated samples) with different calibration methods.", "description": "This table presents the Spearman's rank correlation coefficients obtained by comparing the model rankings from GREAT Score against RobustBench and AutoAttack on the CIFAR-10 dataset.  The comparison is performed using four different calibration methods applied to the model outputs (softmax with temperature, sigmoid with temperature, sigmoid with temperature after softmax, and softmax with temperature after sigmoid). The table shows that the choice of calibration method significantly affects the consistency of model ranking between GREAT Score and the other methods.", "section": "4.4 Ablation Study and Run-time Analysis"}, {"figure_path": "vunJCq9PwU/tables/tables_20_1.jpg", "caption": "Table 8: Group-wise time efficiency evaluation on CIFAR-10 using GREAT Score and Auto-Attack (with 500 generated samples).", "description": "This table presents a comparison of the per-sample computation time for GREAT Score and Auto-Attack on the CIFAR-10 dataset.  The results are based on 500 generated samples and showcase a significant difference in computational efficiency between the two methods.  Each row represents a different model from the RobustBench benchmark, and the columns show the average computation time required for each method per sample. The table highlights the efficiency of GREAT Score in comparison to the attack-based AutoAttack method.", "section": "4.4 Ablation Study and Run-time Analysis"}, {"figure_path": "vunJCq9PwU/tables/tables_23_1.jpg", "caption": "Table 9: GREAT Score on CIFAR-10. The results are averaged over 500 original test samples.", "description": "This table presents a comparison of the GREAT Score, RobustBench Accuracy, and AutoAttack Accuracy for 17 different models on the CIFAR-10 dataset.  The GREAT Score is a novel metric for evaluating the global robustness of a model against adversarial attacks.  RobustBench Accuracy represents the accuracy of the model against the AutoAttack method, a strong adversarial attack. AutoAttack Accuracy is also assessed using AutoAttack but on generated samples.  The table shows the GREAT Score values calculated using 500 original test samples and compares those scores to the RobustBench and AutoAttack accuracies, demonstrating a level of agreement between the new GREAT Score metric and existing benchmark metrics.", "section": "4 Experimental Results"}]