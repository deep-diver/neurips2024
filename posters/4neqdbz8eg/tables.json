[{"figure_path": "4neqdBz8eG/tables/tables_3_1.jpg", "caption": "Table 1: Comparisons between AdamW and Adam-SPD on DomainNet. A pre-trained CLIP ViT-Base model is fine-tuned on each of the five domains in DomainNet and tested on all domains. Each row represents the evaluation of a model fine-tuned on a domain. ID performance is highlighted in blue. The last column shows the deviation of the final model from its initialization. Adam-SPD shows much better OOD performance with significantly less Deviation (||01 \u2013 00||2) than vanilla AdamW.", "description": "This table compares the performance of AdamW and Adam-SPD optimizers on the DomainNet dataset.  A CLIP ViT-Base model was fine-tuned on each of the five DomainNet domains and then tested on all domains. The table shows in-distribution (ID) and out-of-distribution (OOD) performance metrics, highlighting the superior OOD performance of Adam-SPD with significantly lower deviation from the pre-trained initialization.", "section": "4.1 DomainNet Experiments"}, {"figure_path": "4neqdBz8eG/tables/tables_6_1.jpg", "caption": "Table 1: Comparisons between AdamW and Adam-SPD on DomainNet. A pre-trained CLIP ViT-Base model is fine-tuned on each of the five domains in DomainNet and tested on all domains. Each row represents the evaluation of a model fine-tuned on a domain. ID performance is highlighted in blue. The last column shows the deviation of the final model from its initialization. Adam-SPD shows much better OOD performance with significantly less Deviation (||01 \u2013 00||2) than vanilla AdamW.", "description": "This table compares the performance of AdamW and Adam-SPD optimizers on the DomainNet dataset for image classification.  A pre-trained CLIP ViT-Base model was fine-tuned on each of the five DomainNet domains and then evaluated on all domains. The table highlights the in-distribution (ID) and out-of-distribution (OOD) performance of each optimizer, showing Adam-SPD's superior OOD performance and significantly lower deviation from the initial model weights.", "section": "4.1 DomainNet Experiments"}, {"figure_path": "4neqdBz8eG/tables/tables_7_1.jpg", "caption": "Table 2: Comparisons between L2-SP and Adam-SPD. ID dataset: {clipart}, OOD datasets: {real, sketch, quickdraw, painting}. Selective regularization can effectively restrain model's deviation (||Wt - Wo||2) and improve OOD robustness without significantly impacting ID robustness.", "description": "This table compares the performance of L2-SP and Adam-SPD on the DomainNet dataset, focusing on the impact of selective regularization on in-distribution (ID) and out-of-distribution (OOD) robustness.  It shows how different hyperparameter settings affect the trade-off between ID and OOD performance, demonstrating the benefits of selective regularization in improving OOD robustness without sacrificing ID performance.", "section": "4.2 ImageNet Experiments"}, {"figure_path": "4neqdBz8eG/tables/tables_7_2.jpg", "caption": "Table 3: ImageNet Fine-Tuning Result using CLIP ViT-Base. SPD outperforms more complicated algorithms and beats L2-SP by 8.8% by selectively imposing regularization.", "description": "This table presents the ImageNet fine-tuning results using a CLIP ViT-Base model.  It compares the performance of various methods, including Adam-SPD, on both in-distribution (ID) and out-of-distribution (OOD) image classification tasks.  The metrics used are the average accuracy across multiple OOD datasets (Im-V2, Im-Adversarial, Im-Rendition, and Im-Sketch) and the average accuracy across ID datasets (Im). Adam-SPD demonstrates superior performance compared to other methods, particularly L2-SP, highlighting the effectiveness of selective regularization.", "section": "4.2 ImageNet Experiments"}, {"figure_path": "4neqdBz8eG/tables/tables_8_1.jpg", "caption": "Table 4: Pascal Semantic Segmentation Results with SWIN-Tiny transformers (ImageNet21K pre-trained). Performance is measured by mIoU\u2191. SPD improves OOD robustness compared to vanilla fine-tuning without regularization and L2-SP by 36.5% and 5.8%, respectively.", "description": "This table presents the results of Pascal Dense Semantic Segmentation experiments.  It compares the performance of various methods (vanilla fine-tuning, adapters, BitFit, L2-SP, MARS-SP, LLRD, TPGM, FTP, and Adam-SPD) on the clean PASCAL dataset and several corrupted versions (fog, defocus, gaussian noise, and brightness) using a Swin-Tiny transformer model. The metrics used are mean Intersection over Union (mIoU) for ID (In-distribution) and OOD (Out-of-distribution) performance. The table highlights the improvements in OOD robustness achieved by the Adam-SPD method, outperforming others and showing significant gains compared to vanilla fine-tuning and L2-SP.", "section": "4.3 PASACAL Dense Semantic Segmentation"}, {"figure_path": "4neqdBz8eG/tables/tables_8_2.jpg", "caption": "Table 5: Accuracy comparison of LLaMA-7B (-13B) with different adapters and optimizers on eight commonsense reasoning datasets. SPD consistently improves fine-tuning performance on multiple PEFT methods across all datasets. Note that AdamW employs uniform weight decay by default.", "description": "This table presents the results of experiments comparing the performance of different optimizers (AdamW and Adam-SPD) and parameter-efficient fine-tuning (PEFT) methods on eight commonsense reasoning datasets using the LLaMA-7B and LLaMA-13B language models.  The results show that Adam-SPD consistently outperforms AdamW across various PEFT methods, highlighting the benefits of selective projection decay for improved performance in this task.", "section": "4.4 LLAMA PEFT Fine-Tuning Experiments"}, {"figure_path": "4neqdBz8eG/tables/tables_9_1.jpg", "caption": "Table 6: Visual Question Answering Result using PaliGemma-3B. SPD outperforms baselines across ID, near OOD and far OOD datasets on multimodal tasks using LoRA. Note that L2-SP reduces to Vinilla FT with AdamW under LoRA.", "description": "This table presents the results of visual question answering experiments using the PaliGemma-3B model and LoRA.  It compares the performance of various fine-tuning methods (Vanilla FT, Linear Prob, LP-FT, WISE-FT, and Adam-SPD) across different datasets representing in-distribution (ID), near out-of-distribution (OOD), and far OOD scenarios.  The results highlight Adam-SPD's superior performance in handling out-of-distribution data.", "section": "4.5 Visual Question Answering (VQA) Experiments"}, {"figure_path": "4neqdBz8eG/tables/tables_15_1.jpg", "caption": "Table 1: Comparisons between AdamW and Adam-SPD on DomainNet. A pre-trained CLIP ViT-Base model is fine-tuned on each of the five domains in DomainNet and tested on all domains. Each row represents the evaluation of a model fine-tuned on a domain. ID performance is highlighted in blue. The last column shows the deviation of the final model from its initialization. Adam-SPD shows much better OOD performance with significantly less Deviation (||01 \u2013 00||2) than vanilla AdamW.", "description": "This table compares the performance of AdamW and Adam-SPD optimizers on the DomainNet dataset.  A pre-trained CLIP ViT-Base model is fine-tuned on five different domains, and then tested on all domains. The table shows in-distribution (ID) and out-of-distribution (OOD) accuracy, as well as the deviation of the final model from its initial parameters.  The results highlight that Adam-SPD achieves significantly better OOD performance with substantially less deviation from the initial model weights compared to AdamW.", "section": "4.1 DomainNet Experiments"}]