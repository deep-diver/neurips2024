[{"type": "text", "text": "Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mark Rowland Li Kevin Wenliang R\u00e9mi Munos Google DeepMind\u2217 Google DeepMind FAIR, Meta\u2020 Clare Lyle Yunhao Tang Will Dabney Google DeepMind Google DeepMind Google DeepMind ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We propose a new algorithm for model-based distributional reinforcement learning (RL), and prove that it is minimax-optimal for approximating return distributions in the generative model regime (up to logarithmic factors), the first result of this kind for any distributional RL algorithm. Our analysis also provides new theoretical perspectives on categorical approaches to distributional RL, as well as introducing a new distributional Bellman equation, the stochastic categorical CDF Bellman equation, which we expect to be of independent interest. Finally, we provide an experimental study comparing a variety of model-based distributional RL algorithms, with several key takeaways for practitioners. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In distributional reinforcement learning, the aim is to predict the full probability distribution of possible returns at each state, rather than just the mean return (Morimura et al., 2010a; Bellemare et al., 2017, 2023). Applications of distributional reinforcement learning range from dopamine response modelling in neuroscience (Dabney et al., 2020), to driving risk-sensitive decision-making and exploration in domains such as robotics (Bodnar et al., 2020), healthcare (B\u00f6ck et al., 2022), and algorithm discovery (Fawzi et al., 2022), as well as forming a core component of many deep reinforcement learning architectures (Bellemare et al., 2017; Dabney et al., 2018b,a; Yang et al., 2019; Bellemare et al., 2020; Shahriari et al., 2022; Wurman et al., 2022). ", "page_idx": 0}, {"type": "text", "text": "The full distribution of returns is a much richer signal than the expectation to predict. A foundational, as-yet-unanswered problem is how many sampled transitions are required to accurately estimate return distributions, and in particular, whether this task is statistically harder than estimating just the value function. We study these questions in the setting where sampled transitions are given by a generative model (Kearns et al., 2002; Kakade, 2003; Azar et al., 2013). ", "page_idx": 0}, {"type": "text", "text": "We provide a new distributional RL algorithm, the direct categorical fixed-point algorithm (DCFP), and prove that the number of samples required by this algorithm for accurate return distribution estimation matches the lower bound established by Zhang et al. (2023), up to logarithmic factors. This resolves the foundational question above, and, perhaps surprisingly, shows that in this setting, distributional RL is essentially no harder, statistically speaking, than learning a value function. ", "page_idx": 0}, {"type": "text", "text": "In addition to this central result, our analysis provides new perspectives on categorical approaches to distributional RL (Bellemare et al., 2017), including a new distributional Bellman equation, the stochastic categorical CDF Bellman equation (see Section 5.2), which we expect to be of broad use in future work on categorical distributional RL. We also provide an empirical study, comparing the newly-proposed DCFP algorithm to existing approaches to distributional RL such as quantile dynamic programming (QDP; Dabney et al., 2018b; Rowland et al., 2024), and identify several key findings for practitioners, including the importance of levels of environment stochasticity and discount factor for the relative performance of these algorithms. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Throughout the paper, we consider the problem of evaluation in an infinite-horizon Markov reward process (MRP), with finite state space $\\mathcal{X}$ , transition probabilities $P\\,\\in\\,\\mathbb{R}^{\\mathcal{X}\\times\\mathcal{X}}$ , reward function $r:\\mathcal{X}\\to[0,1]$ , and discount factor $\\gamma\\in[0,1)$ ; this encompasses the problem of policy evaluation in Markov decision processes (Sutton & Barto, 2018). A random trajectory $(X_{t},R_{t})_{t\\geq0}$ is generated from an initial state $X_{0}\\,=\\,x$ according to the conditional distributions $X_{t}\\mid(\\Bar{X_{0}^{-}},\\cdot\\cdot\\cdot,X_{t-1})\\sim$ $P(\\cdot|X_{t-1})$ , and $R_{t}\\,=\\,r(X_{t})$ . The return associated with the trajectory is given by the quantity $\\textstyle\\sum_{t\\geq0}\\gamma^{t}R_{t}$ . In RL, a central task is to estimate the value function $V^{*}:\\mathcal{X}\\xrightarrow{}\\mathbb{R}$ , defined by ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{V^{*}(x)=\\mathbb{E}[\\sum_{t\\geq0}\\gamma^{t}R_{t}\\ |\\ X_{0}=x]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "given some form of observations from the MRP. The value function defines the expected return, conditional on each possible starting state in the MRP. The value function satisfies the Bellman equation $V^{*}=T V^{*}$ , where $T:\\mathbb{R}^{\\chi}\\overset{\\bullet}{\\rightarrow}\\mathbb{R}^{\\chi}$ is defined by ", "page_idx": 1}, {"type": "equation", "text": "$$\n(T V)(x)=\\mathbb{E}_{x}[R+\\gamma V(X^{\\prime})]\\,,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $(x,R,X^{\\prime})$ is a random transition in the environment, distributed as described above. When the transition probabilities of the MRP are known, the right-hand side can be evaluated as an affine transformation of $V$ . MRP theory (see, e.g., Puterman, 2014 for an overview) then shows how (an approximation to) $V^{*}$ can be obtained. For example, a dynamic programming approach takes an initial approximation $V_{0}\\in[0,(1-\\gamma)^{-1}]^{\\chi}$ , and the sequence $(V_{k})_{k=0}^{\\infty}$ is computed via the update $V_{k+1}=T V_{k}$ ; it is guaranteed that $\\|V_{k}-V^{*}\\|_{\\infty}\\leq\\gamma^{k}(1-\\gamma)^{-1}$ . Alternatively, the linear system $V=T V$ can be solved directly with linear-algebraic methods to obtain $V^{*}$ as its unique solution. ", "page_idx": 1}, {"type": "text", "text": "2.1 Reinforcement learning with a generative model ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In many settings the transition probabilities of the MRP are unknown, and the value function must be estimated based on data comprising sampled transitions, introducing a statistical element to the problem. A commonly used model for this data is a generative model (Kearns et al., 2002; Kakade, 2003). In this setting, for each state $x\\in\\mathscr{X}$ , we observe $N$ i.i.d. samples $(X_{i}^{x})_{i=1}^{N}$ from $P(\\cdot|x)$ , and this collection of $N|\\mathcal{X}|$ samples may then be used by an algorithm to estimate the value function. Azar et al. (2013) showed that at least $N=\\Omega(\\varepsilon^{-2}(\\Bar{1}-\\gamma)^{-_{3}}\\log(|\\mathcal{X}|/\\delta))$ samples are required to obtain $\\varepsilon$ -accurate estimates of the value function with high probability (measured in $L^{\\infty}$ norm), and also showed that this bound is attained (up to logarithmic factors) by a certainty equivalence algorithm, which treats the empirically observed transition frequencies as the true ones, and solves for the value function of the corresponding MRP. ", "page_idx": 1}, {"type": "text", "text": "2.2 Distributional reinforcement learning ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Distributional RL aims to capture the full probability distribution of the random return at each state, not just its mean. Mathematically, the object of interest is the return-distribution function (RDF) $\\eta^{*}:\\mathcal{X}\\to\\mathcal{P}(\\mathbb{R})$ , defined by ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\eta^{*}(x)=\\mathcal{D}\\big(\\sum_{t=0}^{\\infty}\\gamma^{t}R_{t}\\ |\\ X_{0}=x\\big)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\mathcal{D}$ extracts the probability distribution of the input random variable. The distributional perspective on reinforcement learning has proved practically useful in a wide variety of applications, including healthcare (B\u00f6ck et al., 2022), navigation (Bellemare et al., 2020), and algorithm discovery (Fawzi et al., 2022). The central equation behind dynamic programming approaches to approximating the return distribution function is the distributional Bellman equation (Sobel, 1982; Morimura et al., 2010a; Bellemare et al., 2017), given by $\\boldsymbol{\\eta}^{*}=\\boldsymbol{\\tau}\\boldsymbol{\\eta}^{*}$ , where $T:{\\mathcal{P}}(\\mathbb{R})^{\\scriptscriptstyle\\chi}\\to{\\mathcal{P}}(\\mathbb{R})^{\\scriptscriptstyle\\chi}$ is the distributional Bellman operator, defined by ", "page_idx": 1}, {"type": "equation", "text": "$$\n({\\mathcal T}\\eta)(x)={\\mathcal D}\\big(R+\\gamma G(X^{\\prime})\\mid X=x\\big)\\,,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where independent from the random transition $(X,R,X^{\\prime})$ , we have $G(x)\\sim\\eta(x)$ for each $x\\in\\mathscr{X}$ . ", "page_idx": 1}, {"type": "text", "text": "2.3 Categorical dynamic programming ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Given an initial RDF approximation $\\eta\\in\\mathcal{P}([0,(1-\\gamma)^{-1}])^{\\chi}$ , it also holds that the update $\\eta\\leftarrow\\tau\\eta$ converges to $\\eta^{*}$ in an appropriate sense (e.g., in Wasserstein distance; see Bellemare et al., 2017), in analogy with dynamic programming algorithms for the value function, as described above. However, generally it is not possible to tractably implement repeated computation of the update $\\eta\\leftarrow\\tau\\eta$ as a means of computing approximations to return distributions; probability distributions are infinitedimensional objects, and as such computational costs quickly become prohibitive. Instead, the use of some kind of approximate, tractable representation of probability distributions is typically required. ", "page_idx": 2}, {"type": "text", "text": "Representations. In this paper, we focus on the categorical approach to distributional reinforcement learning (Bellemare et al., 2017), in which estimates of return distributions are represented as categorical distributions over a finite number of outcomes $z_{1}<\\dots<z_{m}$ . We will take $\\bar{\\{z_{1},\\dots,z_{m}\\}}$ to be an equally spaced grid over the range of possible returns $[0,(1-\\gamma)^{-1}]$ , so that $\\begin{array}{r}{z_{i}=\\frac{i-1}{m-1}(1-}\\end{array}$ $\\gamma)^{-1}$ for $i=1,\\hdots,m$ . Approximations of the RDF are then represented in the form ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\eta(x)=\\sum_{i=1}^{m}p_{i}(x)\\delta_{z_{i}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Here, $\\delta_{z}$ is the Dirac distribution at the outcome $z$ , and $p=((p_{i}(x))_{i=1}^{m}:x\\in\\mathcal{X})$ are adjustable probability mass parameters; see Figure 1(a). The number of categories $m$ can be interpreted as controlling the expressivity of the representation, and should be carefully chosen in practice to trade off between increased accuracy (larger $m$ ), and computational tractability (smaller $m$ ). ", "page_idx": 2}, {"type": "text", "text": "Dynamic programming. The iteration $\\eta\\leftarrow\\tau\\eta$ cannot be used to update the parameters $p$ in Equation (4) directly, since the distributions $(\\tau\\eta)(x)$ are no longer supported on $\\{z_{1},\\ldots,z_{m}\\}$ , and so cannot be expressed in the form given in Equation (4); see Figure 1(b). Bellemare et al. (2017) circumvent this issue by projecting the resulting distributions back onto the support set $\\{z_{1},\\ldots,z_{m}\\}$ via a map $\\Pi_{m}:{\\mathcal{P}}([0,\\stackrel{.}{(1-\\gamma)^{-1}}])\\,\\rightarrow\\,{\\mathcal{P}}(\\{\\bar{z}_{1},\\dots,z_{m}\\}])$ . Intuitively, $\\Pi_{m}$ can be thought of as allocating each outcome $z\\in[z_{i},z_{i+1}]$ to its neighbouring gridpoints $z_{i}$ and $z_{i+1}$ , in proportion to their proximity, so that the projection of the Dirac distribution $\\delta_{z}$ , is defined by ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Pi_{m}\\delta_{z}=\\frac{z_{i+1}-z}{z_{i+1}-z_{i}}\\delta_{z_{i}}+\\frac{z-z_{i}}{z_{i+1}-z_{i}}\\delta_{z_{i+1}}\\,.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "In this paper, we work with the equivalent definition of the projection $\\Pi_{m}$ given by Rowland et al. (2018, Proposition 6), in which the probability mass assigned to $z_{i}$ by $\\Pi_{m}\\nu$ is given by the expectation $\\mathbb{E}_{Z\\sim\\nu}[h_{i}(\\bar{Z})]$ , where $h_{i}:[0,(1\\!-\\!\\gamma\\dot{)}^{-1}]\\to[\\dot{0},1]$ is the \u201chat function\u201d at $z_{i}$ , which linearly interpolates between a value of 1 at $z_{i}$ , and 0 at neighbouring gridpoints $z_{i-1},z_{i+1}$ , and is 0 outside this range. Figure 1(c) illustrates $h_{i}$ and $h_{m}$ ; see Appendix $\\mathbf{B}$ for a restatement of the full definition given by Rowland et al. (2018). ", "page_idx": 2}, {"type": "text", "text": "The projected update $\\eta\\leftarrow\\Pi_{m}\\tau\\eta$ is thus guaranteed to keep $\\eta$ in the space of approximations of the form given in Equation (4), and can be viewed as a tractable alternative to the update $\\eta\\leftarrow\\tau\\eta$ described above. Rowland et al. (2018) show that despite the introduction of the additional projection map $\\Pi_{m}$ , repeated computation of the update $\\eta\\,\\leftarrow\\,\\Pi_{m}\\tau\\eta$ , referred to as categorical dynamic programming (CDP), is guaranteed to convergence to a categorical fixed point, and further, the categorical fixed point can be made arbitrarily close to the true RDF $\\eta^{*}$ by increasing $m$ , as measured by Cram\u00e9r distance (Cram\u00e9r, 1928; Sz\u00e9kely, 2003; Sz\u00e9kely & Rizzo, 2013). ", "page_idx": 2}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/198405cbedbce04fdb875366606dff0004fbb517a33f8fb1c91115fa09795553.jpg", "img_caption": ["Figure 1: (a) The density of a distribution $\\nu$ (grey), and its categorical projection $\\Pi_{m}\\nu\\ \\in$ $\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})$ (blue). (b) A categorical distribution (blue); its update after being scaled by $\\gamma$ and shifted by $r$ by the distributional Bellman operator $\\tau$ , moving its support off the grid $\\{z_{1},\\ldots,z_{m}\\}$ (pink); the resulting realigned distribution supported on the grid $\\{z_{1},\\ldots,z_{m}\\}$ after projection via $\\Pi_{m}$ (green). (c) Hat functions $h_{i}$ (solid) and $h_{m}$ (dashed). "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "Definition 2.1. The Cram\u00e9r distance $\\ell_{2}:\\mathcal{P}(\\mathbb{R})\\times\\mathcal{P}(\\mathbb{R})\\to\\mathbb{R}$ is defined by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\ell_{2}(\\nu,\\nu^{\\prime})=\\left[\\int_{\\mathbb{R}}(F_{\\nu}(t)-F_{\\nu^{\\prime}}(t))^{2}\\;\\mathrm{d}t\\right]^{1/2},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $F_{\\nu},F_{\\nu^{\\prime}}$ are the CDFs of $\\nu,\\nu^{\\prime}$ , respectively. The supremum-Cram\u00e9r distance $\\overline{{\\ell}}_{2}$ on $\\mathcal{P}(\\mathbb{R})^{\\chi}$ is defined by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\overline{{\\ell}}_{2}(\\eta,\\eta^{\\prime})=\\operatorname*{max}_{x\\in\\mathcal{X}}\\ell_{2}(\\eta(x),\\eta^{\\prime}(x))\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The central convergence results concerning CDP are summarised below. ", "page_idx": 3}, {"type": "text", "text": "Proposition 2.2. (Rowland et al., 2018). The operator $\\Pi_{m}\\mathcal{T}:\\mathcal{P}([0,(1-\\gamma)^{-1}])^{\\mathcal{X}}\\to\\mathcal{P}([0,(1-\\gamma)^{-1}])$ $\\gamma)^{-1}])^{\\chi}$ is a contraction mapping with respect to $\\overline{{\\ell}}_{2}$ , with contraction factor $\\sqrt{\\gamma}$ , and has a unique fixed point, $\\eta_{C}\\in\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})^{\\chi}$ . As a result, for any $\\eta_{0}\\in\\mathcal{P}([0,(1-\\gamma)^{-1}])^{\\chi}$ , with $\\eta_{k+1}=$ $\\Pi_{m}\\tau\\eta_{k}$ , we have $\\overline{{\\ell}}_{2}(\\eta_{k},\\eta_{C})\\leq(1-\\gamma)^{-1}\\gamma^{k}$ . Further, the distance between $\\eta_{C}$ and the true $R D F\\,\\eta^{*}$ can be bounded as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\overline{{\\ell}}_{2}(\\eta c,\\eta^{*})\\leq\\frac{1}{(1-\\gamma)\\sqrt{m-1}}\\,.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This establishes CDP as a principled approach to approximating return distributions, and also quantifies the accuracy achievable with CDP using $m$ categories, which will be central in informing our choice of $m$ to obtain a sample-efficient, accurate algorithm below. ", "page_idx": 3}, {"type": "text", "text": "3 Distributional reinforcement learning with a generative model ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The central problem we study in this paper is how to do sample-efficient distributional RL with a generative model. That is, given the samples $((X_{i}^{x})_{i=1}^{N}:x\\;\\stackrel{\\cdot}{\\in}\\;\\mathcal{X})$ described in Section 2.1, how accurate of an approximation to the return-distribution function in Equation (3) can one compute? ", "page_idx": 3}, {"type": "text", "text": "This question was raised by Zhang et al. (2023), who proposed to perform distributional dynamic programming updates $\\eta\\:\\leftarrow\\:\\hat{\\tau}\\eta$ as described in Section 2.2, using the empirical distributional Bellman operator $\\hat{\\mathcal{T}}$ derived from the empirical transition probabilities $\\hat{P}$ , defined by $\\hat{P}(y|x)\\,=$ $\\begin{array}{r}{N^{-1}\\sum_{i=1}^{N}\\mathbb{1}\\{X_{i}^{x}=y\\}}\\end{array}$ ,g  waen  ehsatviem $\\hat{\\eta}\\,\\in\\,\\mathcal{P}([0,(1-\\gamma)^{-1}])$ porfo tbhaeb itlrituye  aRt DleFa $\\eta^{*}$ $\\varepsilon\\,>\\,0$ $\\delta\\,\\in\\,(0,1)$ $w_{1}(\\hat{\\eta}(x),\\eta^{*}(x))\\,\\le\\,\\varepsilon$ $1-\\delta$ for all $x\\in\\mathscr{X}$ , whenever $N=\\widetilde\\Omega(\\varepsilon^{-2}(1-\\gamma)^{-4}\\mathrm{polylog}(1/\\delta))$ . Here, $w_{1}$ denotes the Wasserstein-1 distance between probability  distributions, defined for any $\\nu,\\nu^{\\prime}\\in\\mathcal{P}(\\mathbb{R})$ with CDFs $F_{\\nu},F_{\\nu^{\\prime}}$ by $\\begin{array}{r}{w_{1}(\\nu,\\nu^{\\prime})=\\int_{\\mathbb{R}}|\\bar{F_{\\nu}^{\\prime}}(t)-\\bar{F_{\\nu^{\\prime}}^{\\prime}}(t)|\\;\\mathrm{d}\\bar{F_{\\nu}^{\\prime}}(t).}\\end{array}$ dt . We focus on the Wasserstein-1 distance as the main metric of interest in this paper as it is particularly compatible with existing methods for analysing categorical approaches to distributional RL, and it provides upper bounds for differences of many statistical functionals of interest, such as expectations of Lipschitz functions (Villani, 2009; Peyr\u00e9 & Cuturi, 2019); and conditional-value-at-risk (Rockafellar & Uryasev, 2000, 2002; Bhat & Prashanth, 2019, CVaR). Zhang et al. (2023) also prove a lower bound of $N=\\widetilde\\Omega(\\varepsilon^{-2}(1-\\gamma)^{-3})$ samples required to obtain such an accurate prediction with high probability, which follows from a reduction to the mean-return case (Azar et al., 2013). ", "page_idx": 3}, {"type": "text", "text": "There are two natural questions that the analysis of Zhang et al. (2023) leaves open. Firstly, can the gap between the lower bound and upper bound as a function of $(1-\\gamma)^{-1}$ described above be closed? Zhang et al. (2023) conjecture that their analysis is loose, and that this gap can indeed be closed. Second, we also note that the distributional dynamic programming procedure $\\eta\\leftarrow\\hat{\\mathcal{T}}\\eta$ proposed by Zhang et al. (2023), without incorporating any restrictions on the representations of distributions, runs into severe space and memory issues, and is not practical to run (and indeed Zhang et al. (2023) introduce approximations to the algorithm when running empirically for these reasons). A remaining question is then whether there are tractable algorithms that can achieve the lower bound on sample complexity described above. Our contributions below provide a new, tractable distributional RL algorithm that attains (up to logarithmic factors) the lower bound on sample complexity provided by Zhang et al. (2023), resolving these questions. ", "page_idx": 3}, {"type": "text", "text": "4 Direct categorical fixed-point computation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our approach to obtaining a sample-efficient algorithm that is near-minimax-optimal in the sense described above begins with the categorical approach to distributional dynamic programming described in Section 2.3. We begin first by introducing a new algorithm for computing the categorical fixed point $\\eta_{C}$ referred to in Proposition 2.2 directly, that avoids computing an approximate solution via dynamic programming iterations $\\eta\\leftarrow\\Pi_{m}\\tau\\eta$ . We expect this algorithm to be of independent interest within the field of distributional reinforcement learning. ", "page_idx": 4}, {"type": "text", "text": "4.1 Direct categorical fixed-point computation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Our first contribution is to develop a new computational perspective on the projected categorical Bellman operator $\\Pi_{m}\\tau$ , which results in a new algorithm for computing the fixed point $\\eta_{\\mathrm{C}}$ exactly, without requiring the iterative CDP algorithm described in Section 2.3. ", "page_idx": 4}, {"type": "text", "text": "CDF operator and fixed-point equation. We first formulate the application of the projected categorical Bellman operator $\\Pi_{m}\\tau$ as a linear map, and give an explicit expression for the matrix representing this linear map when the input RDFs are represented with cumulative distribution functions (CDFs). We consider the effect of applying $\\Pi_{m}\\tau$ to an RDF $\\eta=\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})^{\\chi}$ , with $\\begin{array}{r}{\\eta(x)=\\sum_{i=1}^{m}p_{i}(x)\\delta_{z_{i}}}\\end{array}$ . By Rowland et al. (2018, Proposition 6), the updated probabilities for $\\begin{array}{r}{(\\Pi_{m}\\mathcal{T}\\eta)(x)=\\sum_{i=1}^{m}p_{i}^{\\prime}(x)\\delta_{z_{i}}}\\end{array}$ can be expressed as ", "page_idx": 4}, {"type": "equation", "text": "$$\np_{i}^{\\prime}(x)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m}P(y|x)h_{i,j}^{x}p_{j}(y)\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $h_{i,j}^{x}=h_{i}(r(x)+\\gamma z_{j})$ . We convert this into an expression for cumulative probabilities, rather than individual probability masses, to obtain a simpler analysis below. To do so, we introduce the encoding of $\\eta\\;\\in\\;\\mathcal{P}\\dot{(}\\{z_{1},\\ldots,z_{m}\\})^{\\chi}$ into corresponding CDF values $F\\,\\,\\in\\,\\,\\mathbb{R}^{\\mathcal{X}\\times m}$ , where $F_{i}(x)=\\eta(x)([z_{1},z_{i}])$ denotes the cumulative mass at state $x$ over the set $\\{z_{1},\\ldots,z_{i}\\}$ . ", "page_idx": 4}, {"type": "text", "text": "Proposition 4.1. If $\\eta\\in\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})^{\\chi}$ is an RDF with corresponding CDF values $F\\in\\mathbb{R}^{X\\times m}$ , then the corresponding $C D F$ values $F^{\\prime}\\in\\mathbb{R}^{X\\times m}$ for $\\Pi_{m}\\tau\\eta$ satisfy ", "page_idx": 4}, {"type": "equation", "text": "$$\nF_{i}^{\\prime}(x)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m}P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})F_{j}(y)\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{H_{i,j}^{x}=\\sum_{l\\le i}h_{l}(r(x)+\\gamma z_{j})}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "for $j=1,\\dots,m_{\\!}$ , and by convention we take $H_{i,m+1}^{x}=0$ . ", "page_idx": 4}, {"type": "text", "text": "Under this notation, we can rewrite Equation (7) simply as a matrix-vector multiplication in $\\mathbb{R}^{\\mathcal{X}\\times[m]}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\nF^{\\prime}=T_{P}F\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $T_{P}$ is the $(\\mathcal{X}\\times[m])\\times(\\mathcal{X}\\times[m])$ square matrix, with entries given by ", "page_idx": 4}, {"type": "equation", "text": "$$\nT_{P}(x,i;y,j)=P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and $F,F^{\\prime}\\in\\mathbb{R}^{\\mathcal{X}\\times m}$ above are interpreted in vectorised form. We drop dependence on $m$ from the notation $T_{P}$ for conciseness. Thus, CDP can be implemented via simple matrix multiplication on CDF values, and the CDF values $F^{*}$ for the categorical fixed point $\\eta_{C}$ solve the equation ", "page_idx": 4}, {"type": "equation", "text": "$$\nF=T_{P}F\\,,\\,\\,\\mathrm{or}\\,\\mathrm{equivalently}\\,\\,(I-T_{P})F=0\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Obtaining a system with unique solution. Equation (10) suggests that we can directly solve a linear system to obtain the exact categorical fixed point, rather than performing the iterative CDP algorithm to obtain an approximation. Note, however, that $F^{*}$ is not the unique solution of Equation (10); for example, $F=0$ is also a solution. This arises because in Equation (10), the distribution masses at each state (that is, $F_{m}(x))$ , are unconstrained. By contrast, Proposition 2.2 establishes that $\\eta_{\\mathrm{C}}$ is the unique solution of $\\eta=\\Pi_{m}\\tau\\eta$ in the space $\\mathcal{P}([z_{1},z_{m}])^{\\chi}$ , where each element $\\eta(x)$ is constrained to be a probability distribution a priori. Thus, Equation (10) requires some modification to obtain a linear system with a unique solution. This is obtained by removing $F_{m}(x)$ as a variable from the system (for each $x\\in\\mathcal{X}$ )), replacing it by the constant 1, and removing redundant rows from the resulting linear system, as the following proposition describes; the \u201caxis-aligned\u201d nature of these constraints is the benefit of working with CDF values. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Proposition 4.2. The linear system in Equation (10), with the additional linear constraints $F_{m}(x)=$ 1 for all $x\\in\\mathscr{X}$ , is equivalent to the following linear system in $\\widetilde{F}\\in\\mathbb{R}^{\\mathcal{X}\\times[m-1]}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n(I-\\widetilde{T}_{P})\\widetilde{F}=\\widetilde{H}\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the $(x,i;y,j)$ coordinate of ${\\tilde{T}}_{P}$ (for $1\\leq i,j\\leq m-1)$ is ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\widetilde{T}_{P}(x,i;y,j)=P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})\\,,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and for each $x\\in\\mathscr{X}$ , $1\\leq i\\leq m-1$ , we have $\\widetilde H(x,i)=H_{i,m}^{x}$ ", "page_idx": 5}, {"type": "text", "text": "Having moved to the inhomogeneous system over $\\mathbb{R}^{\\mathcal{X}\\times[m-1]}$ in Equation (11), we can deduce the following via the contraction theory in Proposition 2.2. ", "page_idx": 5}, {"type": "text", "text": "Proposition 4.3. The linear system in Equation (11) has a unique solution, which is precisely the CDF values $((F_{i}^{*}(x))_{i=1}^{m-1}:x\\,\\,\\!\\stackrel{\\cdot}{\\in}\\,\\mathcal{X})$ of the categorical fixed point. ", "page_idx": 5}, {"type": "text", "text": "The direct categorical fixed-point algorithm (DCFP) consists of solving the linear system in Equation (11) to obtain the exact categorical fixed point; see Algorithm 1 for a summary. ", "page_idx": 5}, {"type": "table", "img_path": "JXKbf1d4ib/tmp/ed7b38776d3560e690b0e749338fa02a1578b589a6b9605bb7ab4bad4c56e860.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "Complexity and implementation details. Representing $\\widetilde{T}_{P}$ as a dense matrix requires $O(|\\mathcal{X}|^{2}m^{2})$ space, and solving the corresponding linear system in E quation (11) with a standard linear solver requires $O(|\\mathcal{X}|^{3}m^{3})$ time. However, in many problems there are cases where the DCFP algorithm can be implemented more efficiently. Crucially, ${\\tilde{T}}_{P}$ often has sparse structure, and so sparse linear solvers may afford an opportunity to make substa ntial improvements in computational efficiency. We explore this point further empirically in Section 6, and give a theoretical perspective in Appendix G. ", "page_idx": 5}, {"type": "text", "text": "4.2 DCFP with a generative model ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We now return to the setting where the Markov reward process in which we are performing evaluation is unknown, and instead we have access to the random next-state samples $\\widehat{((X_{i}^{x})_{i=1}^{N}\\,\\colon\\,x\\,\\in\\,\\chi)}$ , as described in Section 3. Our model-based DCFP algorithm proceeds by first constructing the corresponding empirical transition probabilities $\\hat{P}$ , so that $\\begin{array}{r}{\\hat{P}(y|\\bar{x})=N^{-1}\\sum_{i=1}^{N}\\mathbb{1}\\{X_{i}^{x}=y\\}}\\end{array}$ , and then calls the DCFP procedure outlined in Algorithm 1, treating $\\hat{P}$ as the true transition probabilities of the MRP when constructing the matrix in Line 2, which we denote here by $T_{\\hat{P}}$ , to reflect the fact that it is built from $\\hat{P}$ . This produces the output CDF values $\\hat{F}$ , from which estimated return distributions can be decoded (with the convention $\\hat{F}_{0}(x)=0_{.}$ ) as ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{\\eta}(x)=\\sum_{i=1}^{m}(\\hat{F}_{i}(x)-\\hat{F}_{i-1}(x))\\delta_{z_{i}}\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "5 Sample complexity analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Our goal now is to analyse the sample complexity of model-based DCFP, as described in the previous section. We first introduce a notational shorthand that will be of extensive use in the statement and ", "page_idx": 5}, {"type": "text", "text": "proof of this result: when writing distances between distributions, such as $w_{1}(\\eta^{*}(x),\\hat{F}(x))$ , we identify CDF vectors $\\hat{F}(x)\\in\\mathbb{R}^{m}$ with the distributions they represent as in Equation (12). The core theoretical result of the paper is as follows. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5.1. Let $\\varepsilon\\,\\in\\,(0,(1-\\gamma)^{-1/2})$ and $\\delta\\,\\in\\,(0,1)$ , and suppose the number of categories satisfies $m\\geq4(1-\\gamma)^{-2}\\varepsilon^{-2}+1$ . Then the output $\\hat{F}$ of model-based DCFP with $N=\\Omega(\\varepsilon^{-2}(1-$ $\\gamma)^{-3}\\mathrm{polylog}(|\\mathcal{X}|/\\delta))$ samples satisfies, with probability at least $1-\\delta$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x\\in\\mathcal{X}}w_{1}(\\eta^{*}(x),\\hat{F}(x))\\leq\\varepsilon\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This result establishes that model-based DCFP attains the minimax lower-bound (up to logarithmic factors) for high-probability return distribution estimation in Wasserstein distance, resolving an open question raised by Zhang et al. (2023); in a certain sense, estimation of return distributions is no more statistically difficult than that of mean returns with a generative model. Note there is no direct dependence of $N$ on $m$ , so there is no statistical penalty to using a large number of categories $m$ . ", "page_idx": 6}, {"type": "text", "text": "Extensions. We note that this core result can be straightforwardly extended in several directions. In particular, similar bounds apply in the case of predicting returns for learnt near-optimal policies in MDPs (see Section F.2), for the iterative categorical DP algorithm in place of DCFP (when using sufficiently many DP updates; see Section F.1), and in the case of stochastic rewards (see Section F.3). ", "page_idx": 6}, {"type": "text", "text": "5.1 Structure of the proof of Theorem 5.1 ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The remainder of this section provides a sketch proof of Theorem 5.1; a complete proof is provided in the appendix. The proof is broadly motivated by the approaches of Azar et al. (2013), Agarwal et al. (2020), and Pananjady & Wainwright (2020), who analyse the mean-return case, and we highlight where key ideas and new mathematical objects are required in this distributional setting. In particular, we highlight the use of the stochastic categorical CDF Bellman equation, a new distributional Bellman equation that plays a key role in our analysis, which we expect to be of independent interest. ", "page_idx": 6}, {"type": "text", "text": "Reduction to Cram\u00e9r distance. The first step of the analysis is to reduce Theorem 5.1 to a statement about approximation in Cram\u00e9r distance, which is much better suited to the analysis of DCFP, owing to the results described in Section 2.3. This can be done by upper-bounding Wasserstein distance by Cram\u00e9r distance using the following result, which is proven in the appendix via Jensen\u2019s inequality. ", "page_idx": 6}, {"type": "text", "text": "Lemma 5.2. For any two distributions $\\nu,\\nu^{\\prime}\\in\\mathcal{P}([0,(1-\\gamma)^{-1}])$ , we have ", "page_idx": 6}, {"type": "equation", "text": "$$\nw_{1}(\\nu,\\nu^{\\prime})\\leq(1-\\gamma)^{-1/2}\\ell_{2}(\\nu,\\nu^{\\prime})\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 5.1 is now reducible to the following, stated in terms of the Cram\u00e9r distance. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5.3. Let $\\varepsilon~\\in~(0,1)$ and $\\delta~\\in~(0,1)$ , and suppose the number of categories satisfies $m\\;\\geq\\;4(1\\,-\\,\\gamma)^{-2}\\varepsilon^{-2}\\,+\\,1$ . Then the output $\\hat{F}$ of model-based DCFP with $N\\;=\\;\\Omega(\\varepsilon^{-2}(1\\;-\\;$ $\\gamma)^{-2}\\mathrm{polylog}(|\\mathcal{X}|/\\delta))$ samples satisfies, with probability at least $1-\\delta$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x\\in\\mathcal{X}}\\ell_{2}(\\eta^{*}(x),\\hat{F}(x))\\leq\\varepsilon\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Reduction to categorical fixed-point error. Our first step in proving Theorem 5.3 is to use the triangle inequality to split the Cram\u00e9r distance on the left-hand side of Equation (13) into a representation approximation error, and sample-based error: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\overline{{\\ell}}_{2}(\\eta^{\\ast},\\hat{F})\\leq\\overline{{\\ell}}_{2}(\\eta^{\\ast},F^{\\ast})+\\overline{{\\ell}}_{2}(F^{\\ast},\\hat{F})\\leq\\frac{1}{(1-\\gamma)\\sqrt{m-1}}+\\overline{{\\ell}}_{2}(F^{\\ast},\\hat{F})\\,,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with the second inequality following from the fixed-point quality bound in Equation (5). With $m$ as specified in the theorem statement, the first term in the right-hand side above is bounded by $\\varepsilon/2$ . Thus, it suffices to focus on the second term on the right-hand side, which quantifies the sample-based error in estimating the categorical fixed point $F^{*}$ . ", "page_idx": 6}, {"type": "text", "text": "Concentration. Through a combination of the use of a version of Bernstein\u2019s inequality in Hilbert space (Chatalic et al., 2022) and propagation of this inequality across time steps in the MRP, we next arrive at the following inequality with probability at least $1-\\delta$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\ell_{2}(\\hat{F}(x),F^{*}(x))\\leq\\tilde{O}\\Big(\\frac{1}{\\sqrt{N(1-\\gamma)}}\\sqrt{\\|(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\|_{\\infty}}+\\frac{1}{(1-\\gamma)^{3/2}N^{3/4}}\\Big)\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Here, $\\sigma_{\\hat{P}}\\in\\mathbb{R}^{\\mathcal{X}}$ is an instance of a new class of distributional object, the local squared-Cram\u00e9r variation. The general definition is given below, for the case of a general transition matrix $Q\\in\\mathbb{R}^{X\\times X}$ , to avoid conflation with the specific transition matrices $P$ and P\u02c6 that Theorem 5.3 is concerned with. Definition 5.4. For a given transition matrix $Q$ , the single-sample operator $\\hat{T}_{Q}:\\mathbb{R}^{\\mathcal{X}\\times m}\\rightarrow\\mathbb{R}^{\\mathcal{X}\\times m}$ is the random operator given by: (i) constructing a random transition matrix $\\hat{Q}$ by, for each $x\\in\\mathscr{X}$ , sampling $X^{\\prime}\\sim Q(\\cdot|x)$ , and setting ${\\hat{Q}}(X^{\\prime}|x)=1$ ; (ii) setting $\\hat{T}_{Q}=T_{\\hat{Q}}$ . ", "page_idx": 7}, {"type": "text", "text": "Definition 5.5. For a given transition matrix $Q$ with corresponding CDP fixed point $F^{Q}\\in\\mathbb{R}^{X\\times m}$ , the local squared-Cram\u00e9r variation at $Q$ , $\\sigma_{Q}\\in\\mathbb{R}^{\\mathcal{X}}$ , is defined by ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\sigma_{Q}(x)=\\mathbb{E}[\\ell_{2}^{2}((\\hat{T}_{Q}F^{Q})(x),F^{Q}(x))]\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Intuitively, the local squared-Cram\u00e9r variation $\\sigma_{Q}$ encodes the variability of the fixed point $F^{Q}$ after a sample-based, rather than exact, dynamic programming update. From this point of view, it is a natural quantity to arise in Equation (14), and plays a similar role to the variance in the classical Bernstein inequality (Bernstein, 1946). ", "page_idx": 7}, {"type": "text", "text": "In Corollary 5.12 below, we will deduce that under the conditions of Theorem 5.3, we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\|(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\|_{\\infty}\\leq\\frac{2}{1-\\gamma}\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Substituting this into Equation (14) gives $\\begin{array}{r}{\\ell_{2}(\\hat{F}(x),F^{*}(x))\\le\\widetilde O\\bigg(\\frac{1}{(1-\\gamma)\\sqrt{N}}+\\frac{1}{(1-\\gamma)^{3/2}N^{3/4}}\\bigg)}\\end{array}$ with probability at least $1-\\delta$ , for all $x\\,\\in\\,{\\mathcal{X}}$ . Now, taking $N\\,=\\,\\widetilde\\Omega((1\\,-\\,\\gamma)^{-2}\\varepsilon^{-2})$ yields that this expression is $O(\\varepsilon)$ , which completes the sketch proof of Theorem  5.3. What remains to be described is how to arrive at the bound in Equation (15); the section below provides a high-level overview of the technical details involved in obtaining it. ", "page_idx": 7}, {"type": "text", "text": "5.2 The stochastic categorical CDF Bellman equation ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "The central idea is to relate the local squared-Cram\u00e9r variation to a corresponding global notion of variation, in analogy with the variance Bellman equation (Sobel, 1982) used by Azar et al. (2013) in the mean-return case. To define this corresponding global notion, we begin by defining a new type of distributional Bellman equation, which can be intuitively thought of as encoding the result of repeatedly applying a sequence of independent single-sample operators. Again, we work with a general transition matrix $Q$ . ", "page_idx": 7}, {"type": "text", "text": "Definition 5.6. For a general transition matrix $Q$ , the stochastic categorical CDF (SC-CDF) Bellman equation is given by ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\Phi(x)\\stackrel{{\\cal D}}{=}(\\hat{T}_{Q}\\Phi)(x)\\,,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where= denotes equality in distribution. Here, $\\hat{T}_{Q}$ is a single-sample operator with respect to $Q$ , as in Definition 5.4. Each $\\Phi(x)$ is a random variable taking values in the space of valid CDF values ${\\mathcal{F}}=\\{F\\in\\mathbb{R}^{m}:0\\leq F_{1}\\leq\\dots\\leq F_{m-1}\\leq F_{m}=1\\}$ for distributions in $\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})$ , and is taken to be independent of the random operator $\\hat{T}_{Q}$ . ", "page_idx": 7}, {"type": "text", "text": "The intuition is that \u201cunravelling\u201d Equation (16) should lead to a solution of the form ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\Phi(x)\\stackrel{\\cal D}{=}\\operatorname*{lim}_{k\\rightarrow\\infty}\\hat{T}_{Q}^{(k)}\\cdot\\cdot\\cdot\\hat{T}_{Q}^{(1)}F\\,,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $(\\hat{T}_{Q}^{(i)})_{i=1}^{k}$ are independent single-sample operators, so that $\\Phi(x)$ encodes the fluctuations due to repeated CDP updates with randomly-sampled transitions. To make this intuition precise, we first verify that the SC-CDF Bellman equation has a unique solution. ", "page_idx": 7}, {"type": "text", "text": "Proposition 5.7. The SC-CDF Bellman equation in Equation (16) has a unique solution, in the sense that there is a unique distribution for each $\\Phi(x)$ such that Equation (16) holds for each $x\\in\\mathscr{X}$ . ", "page_idx": 7}, {"type": "text", "text": "We write $\\Phi^{Q}$ for the collection of random CDFs that satisfy the SC-CDF Bellman equation in Equation (16), whose existence is guaranteed by Proposition 5.7. We next relate $\\Phi^{Q}$ to the standard categorical fixed point $F^{Q}$ . ", "page_idx": 7}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/0132d8d352139aac623e950fd102d06f7c622f550ab7d2e84d340943680e1e43.jpg", "img_caption": ["Figure 2: Left: Example MRP with $r(x_{0})=1,r(x_{1})=0$ , $\\gamma=0.9$ . Right: Categorical fixed point $F^{*}(x_{0})$ with $m=15$ , and 5 independent samples from the random CDF $\\Phi^{*}(x_{0})$ . "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Proposition 5.8. For all $x\\in\\mathscr{X}$ , we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\Phi^{Q}(x)]=F^{Q}(x)\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Proposition 5.8 shows that $\\Phi^{Q}$ can indeed thought of as encoding random variation around the usual categorical fixed point $F^{Q}$ ; see Figure 2. This motivates the following. ", "page_idx": 8}, {"type": "text", "text": "Definition 5.9. For a given transition matrix $Q$ with corresponding CDP fixed point $F^{Q}\\in\\mathbb{R}^{X\\times m}$ , the global squared-Cram\u00e9r variation at $Q$ , $\\dot{\\Sigma_{Q}}\\in\\mathbb{R}^{\\lambda}$ , is defined by ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\Sigma_{Q}(x)=\\mathbb{E}[\\ell_{2}^{2}(\\Phi^{Q}(x),F^{Q}(x))]\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Remark 5.10. Note that $\\Phi^{Q}(x)$ is a doubly distributional object. It represents a probability distribution centred around the object $\\mathring{F}^{Q}(x)$ , which itself already provides a summary of the distribution of the return. This reveals a dual perspective on distributional RL itself. The distributional predictions made can serve several purposes: $(i)$ modelling the aleatoric uncertainty in the return, as is the case in the work of Bellemare et al. (2017) and much subsequent algorithmic work, and/or (ii) serving to model specific types of epistemic uncertainty in the estimation of a non-random object from random data, as used in the analysis of Azar et al. (2013) and much subsequent work on the sample complexity of reinforcement learning. The object $\\Phi^{Q}$ is motivated by both of these concerns simultaneously. ", "page_idx": 8}, {"type": "text", "text": "The following Bellman-like inequality draws a relationship between local and global squared-Cram\u00e9r variation, allowing us to make progress from Equation (15). ", "page_idx": 8}, {"type": "text", "text": "Proposition 5.11. We have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\Sigma_{Q}\\geq\\sigma_{Q}+\\gamma Q\\Sigma_{Q}-\\left(\\frac{2}{m\\sqrt{1-\\gamma}}+\\frac{1}{m^{2}(1-\\gamma)^{2}}\\right)\\mathbf{1}\\,,\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\mathbf{1}\\in\\mathbb{R}^{\\mathcal{X}}$ is a vector of ones, and the inequality above is interpreted component-wise. ", "page_idx": 8}, {"type": "text", "text": "Rearrangement and bounding of the quantities in the inequality of Proposition 5.11, in the specific case $Q={\\hat{P}}$ , yields the required inequality in Equation (15) that completes the proof of Theorem 5.3. ", "page_idx": 8}, {"type": "text", "text": "Corollary 5.12. We can bound the term $\\|(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\|_{\\infty}$ appearing in Equation (14) under the assumptions of Theorem 5.3 as follows: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\|(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\|_{\\infty}\\leq\\|\\Sigma_{\\hat{P}}\\|_{\\infty}+\\frac{1}{1-\\gamma}\\leq\\frac{2}{1-\\gamma}\\,.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "6 Empirical evaluation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To complement our theoretical analysis, which focuses on worst-case sample complexity bounds, we report empirical findings for implementations of several model-based distributional RL algorithms in the generative model setting. We compare the new DCFP algorithm introduced in Section 4.1 with quantile dynamic programming (Dabney et al., 2018b; Bellemare et al., 2023, QDP) a distinct approach to distributional RL in which return distributions are approximated via dynamic programming with a finite number of quantiles. ", "page_idx": 8}, {"type": "text", "text": "In Figure 3 (left), we report results of running DCFP and QDP on a 5-state environment with transition matrix randomly sampled from Dirichlet distributions, and entries of the immediate reward function $r\\in\\mathbb{R}^{\\mathcal{X}}$ randomly sampled from $\\mathrm{Unif}([0,1])$ , with varying numbers of atoms $m$ environment samples per state $N$ , and discount $\\gamma$ . We report the maximum $w_{1}$ -error against true return distributions (estimated via Monte Carlo sampling). All runs are repeated 30 times, and error bars are $95\\%$ bootstrapped confidence intervals. Sufficient DP iterations ensure approximate convergence to their fixed points. In Figure 3 (right), we plot estimation error against wallclock time for $m=100,N=10^{6}$ , including results for CDP (which approximates the solution of DCFP via dynamic programming; Section 2.3); line plots indicate the estimation error/wallclock time trade-off as we increase the number of DP iterations. Both DCFP and CDP methods benefit from setting the atom support based on maximal/minimal values of $r$ , as described in Appendix G. ", "page_idx": 8}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/4524fe4154384d7c5c887630c42292f347b32e74c8c7e49a8120aa7de731e035.jpg", "img_caption": ["Figure 3: Approximation error/wallclock time for a variety of distributional RL methods, discount factors, numbers of atoms, and numbers of environment samples. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "For low discount factors and atom counts QDP generally outperforms DCFP in terms of asymptotic estimation error, due to QDP\u2019s ability to modify its atom support to regions of the interval $[0,\\bar{(1-}$ $\\gamma)^{-1}]$ where mass is concentrated. However, we note that DCFP is generally faster than QDP. Further, DCFP generally outperforms QDP, in terms of both speed and estimation error, under larger discounts and/or larger atom count. We also note that particularly at high discounts, DCFP outperforms CDP in terms of wallclock time, due to DP methods requiring many iterations to converge in these cases (Rowland et al., 2018). Full results, including on several further environments, are given in Appendix G: key findings include that QDP works particularly well in near-deterministic environments, and DCFP works particularly well in settings where there are short high-probability paths from a state to itself. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We have introduced a new algorithm, DCFP, for directly computing the fixed point of CDP, a widely used distributional reinforcement learning algorithm. We then showed that this algorithm, with an appropriately chosen number of categories $m$ , achieves the minimax lower bound (up to logarithmic factors) for sample complexity of return-distribution estimation in Wasserstein distance with a generative model. Thus, this paper closes an open question raised by Zhang et al. (2023) by exhibiting an algorithm that obtains this lower bound, and shows that estimation of return distributions via a generative model is essentially no harder statistically than the task of estimating a value function. ", "page_idx": 9}, {"type": "text", "text": "Our analysis also casts new light on categorical approaches to distributional reinforcement learning in general. The newly introduced stochastic categorical CDF Bellman equation serves to encode information about statistical fluctuations of categorical approaches to distributional RL, and we expect it to be of further use in theoretical work in distributional RL generally. Our experimental results also highlight salient differences in performance for distributional RL algorithms making use of distinct representations, depending on levels of environment stochasticity and discount factor in particular. We believe further investigation of these phenomena is an interesting direction for future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We thank Dave Abel for detailed comments on a draft version of the paper. We also thank Mohammad Gheshlaghi Azar for useful conversations, and Arthur Gretton for advice on Bernstein-like inequalities in Hilbert space. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Agarwal, A., Kakade, S., and Yang, L. F. Model-based reinforcement learning with a generative model is minimax optimal. In Conference on Learning Theory, 2020.   \nAzar, M. G., Munos, R., Ghavamzadeh, M., and Kappen, H. Speedy Q-learning. In Advances in Neural Information Processing Systems, 2011.   \nAzar, M. G., Munos, R., and Kappen, H. J. Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model. Machine learning, 91:325\u2013349, 2013.   \nBastani, O., Ma, J. Y., Shen, E., and Xu, W. Regret bounds for risk-sensitive reinforcement learning. In Advances in Neural Information Processing Systems, 2022.   \nBellemare, M. G., Dabney, W., and Munos, R. A distributional perspective on reinforcement learning. In Proceedings of the International Conference on Machine Learning, 2017.   \nBellemare, M. G., Candido, S., Castro, P. S., Gong, J., Machado, M. C., Moitra, S., Ponda, S. S., and Wang, Z. Autonomous navigation of stratospheric balloons using reinforcement learning. Nature, 588(7836):77\u201382, 2020.   \nBellemare, M. G., Dabney, W., and Rowland, M. Distributional Reinforcement Learning. MIT Press, 2023. http://www.distributional-rl.org.   \nBernstein, S. The Theory of Probabilities. Gastehizdat Publishing House, 1946.   \nBhat, S. P. and Prashanth, L. A. Concentration of risk measures: A Wasserstein distance approach. In Advances in Neural Information Processing Systems, 2019.   \nB\u00f6ck, M. and Heirzinger, C. Speedy categorical distributional reinforcement learning and complexity analysis. SIAM Journal on Mathematics of Data Science, 4(2):675\u2013693, 2022.   \nB\u00f6ck, M., Malle, J., Pasterk, D., Kukina, H., Hasani, R., and Heitzinger, C. Superhuman performance on sepsis MIMIC-III data by distributional reinforcement learning. PLoS One, 17(11):e0275358, 2022.   \nBodnar, C., Li, A., Hausman, K., Pastor, P., and Kalakrishnan, M. Quantile QT-Opt for risk-aware vision-based robotic grasping. In Robotics: Science and Systems, 2020.   \nChandak, Y., Shankar, S., and Thomas, P. S. High-confidence off-policy (or counterfactual) variance estimation. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021.   \nChatalic, A., Schreuder, N., Rosasco, L., and Rudi, A. Nystr\u00f6m kernel mean embeddings. In Proceedings of the International Conference on Machine Learning, 2022.   \nCram\u00e9r, H. On the composition of elementary errors. Scandinavian Actuarial Journal, 1928(1): 13\u201374, 1928.   \nDabney, W., Ostrovski, G., Silver, D., and Munos, R. Implicit quantile networks for distributional reinforcement learning. In Proceedings of the International Conference on Machine Learning, 2018a.   \nDabney, W., Rowland, M., Bellemare, M. G., and Munos, R. Distributional reinforcement learning with quantile regression. In Proceedings of the AAAI Conference on Artificial Intelligence, 2018b.   \nDabney, W., Kurth-Nelson, Z., Uchida, N., Starkweather, C. K., Hassabis, D., Munos, R., and Botvinick, M. A distributional code for value in dopamine-based reinforcement learning. Nature, 577(7792):671\u2013675, 2020. ", "page_idx": 10}, {"type": "text", "text": "Doan, T., Mazoure, B., and Lyle, C. GAN Q-learning. arXiv, 2018. ", "page_idx": 11}, {"type": "text", "text": "Du, Y., Wang, S., and Huang, L. Provably efficient risk-sensitive reinforcement learning: Iterated CVaR and worst path. In Proceedings of the International Conference on Learning Representations, 2022.   \nDvoretzky, A., Kiefer, J., and Wolfowitz, J. Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator. The Annals of Mathematical Statistics, pp. 642\u2013669, 1956.   \nFawzi, A., Balog, M., Huang, A., Hubert, T., Romera-Paredes, B., Barekatain, M., Novikov, A., R Ruiz, F. J., Schrittwieser, J., Swirszcz, G., Silver, D., Hassabis, D., and Kohli, P. Discovering faster matrix multiplication algorithms with reinforcement learning. Nature, 610(7930):47\u201353, 2022.   \nFei, Y., Yang, Z., Chen, Y., and Wang, Z. Exponential Bellman equation and improved regret bounds for risk-sensitive reinforcement learning. In Advances in Neural Information Processing Systems, 2021a.   \nFei, Y., Yang, Z., and Wang, Z. Risk-sensitive reinforcement learning with function approximation: A debiasing approach. In Proceedings of the International Conference on Machine Learning, 2021b.   \nFreirich, D., Shimkin, T., Meir, R., and Tamar, A. Distributional multivariate policy evaluation and exploration with the Bellman GAN. In Proceedings of the International Conference on Machine Learning, 2019.   \nGretton, A., Borgwardt, K. M., Rasch, M. J., Sch\u00f6lkopf, B., and Smola, A. A kernel two-sample test. The Journal of Machine Learning Research, 13(1):723\u2013773, 2012.   \nHarris, C. R., Millman, K. J., van der Walt, S. J., Gommers, R., Virtanen, P., Cournapeau, D., Wieser, E., Taylor, J., Berg, S., Smith, N. J., Kern, R., Picus, M., Hoyer, S., van Kerkwijk, M. H., Brett, M., Haldane, A., del R\u00edo, J. F., Wiebe, M., Peterson, P., G\u00e9rard-Marchant, P., Sheppard, K., Reddy, T., Weckesser, W., Abbasi, H., Gohlke, C., and Oliphant, T. E. Array programming with NumPy. Nature, 585(7825):357\u2013362, September 2020.   \nHunter, J. D. Matplotlib: A 2d graphics environment. Computing in Science & Engineering, 9(3): 90\u201395, 2007.   \nKakade, S. M. On the sample complexity of reinforcement learning. PhD thesis, University College London, 2003.   \nKearns, M., Mansour, Y., and Ng, A. Y. A sparse sampling algorithm for near-optimal planning in large Markov decision processes. Machine learning, 49:193\u2013208, 2002.   \nLam, T., Verma, A., Low, B. K. H., and Jaillet, P. Risk-aware reinforcement learning with coherent risk measures and non-linear function approximation. In Proceedings of the International Conference on Learning Representations, 2022.   \nLi, G., Wei, Y., Chi, Y., Gu, Y., and Chen, Y. Breaking the sample size barrier in model-based reinforcement learning with a generative model. In Advances in Neural Information Processing Systems, 2020.   \nLiang, H. and Luo, Z.-Q. Bridging distributional and risk-sensitive reinforcement learning with provable regret bounds. Journal of Machine Learning Research, 2022.   \nMassart, P. The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality. The Annals of Probability, pp. 1269\u20131283, 1990.   \nMorimura, T., Sugiyama, M., Kashima, H., Hachiya, H., and Tanaka, T. Nonparametric return distribution approximation for reinforcement learning. In Proceedings of the International Conference on Machine Learning, 2010a.   \nMorimura, T., Sugiyama, M., Kashima, H., Hachiya, H., and Tanaka, T. Parametric return density estimation for reinforcement learning. In Proceedings of the Conference on Uncertainty in Artificial Intelligence, 2010b.   \nNguyen-Tang, T., Gupta, S., and Venkatesh, S. Distributional reinforcement learning via moment matching. In Proceedings of the AAAI Conference on Artificial Intelligence, 2021.   \nPananjady, A. and Wainwright, M. J. Instance-dependent $\\ell_{\\infty}$ -bounds for policy evaluation in tabular reinforcement learning. IEEE Transactions on Information Theory, 67(1):566\u2013585, 2020.   \nPeyr\u00e9, G. and Cuturi, M. Computational optimal transport: With applications to data science. Foundations and Trends $^\\mathrm{\\textregistered}$ in Machine Learning. Now Publishers, Inc., 2019.   \nPuterman, M. L. Markov decision processes: Discrete stochastic dynamic programming. John Wiley & Sons, 2014.   \nRockafellar, R. T. and Uryasev, S. Optimization of conditional value-at-risk. Journal of Risk, 2: 21\u201342, 2000.   \nRockafellar, R. T. and Uryasev, S. Conditional value-at-risk for general loss distributions. Journal of banking & finance, 26(7):1443\u20131471, 2002.   \nRowland, M., Bellemare, M. G., Dabney, W., Munos, R., and Teh, Y. W. An analysis of categorical distributional reinforcement learning. In Proceedings of the International Conference on Artificial Intelligence and Statistics, 2018.   \nRowland, M., Munos, R., Azar, M. G., Tang, Y., Ostrovski, G., Harutyunyan, A., Tuyls, K., Bellemare, M. G., and Dabney, W. An analysis of quantile temporal-difference learning. Journal of Machine Learning Research, 2024.   \nSejdinovic, D., Sriperumbudur, B., Gretton, A., and Fukumizu, K. Equivalence of distance-based and RKHS-based statistics in hypothesis testing. The Annals of Statistics, pp. 2263\u20132291, 2013.   \nShahriari, B., Abdolmaleki, A., Byravan, A., Friesen, A., Liu, S., Springenberg, J. T., Heess, N., Hoffman, M., and Riedmiller, M. Revisiting Gaussian mixture critics in off-policy reinforcement learning: A sample-based approach. arXiv, 2022.   \nSidford, A., Wang, M., Wu, X., Yang, L., and Ye, Y. Near-optimal time and sample complexities for solving Markov decision processes with a generative model. Advances in Neural Information Processing Systems, 2018.   \nSobel, M. J. The variance of discounted Markov decision processes. Journal of Applied Probability, 19(4):794\u2013802, 1982.   \nSutton, R. and Barto, A. Reinforcement learning: An introduction. MIT Press, 2nd edition, 2018.   \nSz\u00e9kely, G. J. E-statistics: The energy of statistical samples. Technical Report 05, Bowling Green State University, Department of Mathematics and Statistics Technical Report, 2003.   \nSz\u00e9kely, G. J. and Rizzo, M. L. Energy statistics: A class of statistics based on distances. Journal of statistical planning and inference, 143(8):1249\u20131272, 2013.   \nVan Rossum, G. and Drake, F. L. Python 3 Reference Manual. CreateSpace, Scotts Valley, CA, 2009.   \nVillani, C. Optimal transport: Old and new, volume 338. Springer, 2009.   \nVirtanen, P., Gommers, R., Oliphant, T. E., Haberland, M., Reddy, T., Cournapeau, D., Burovski, E., Peterson, P., Weckesser, W., Bright, J., van der Walt, S. J., Brett, M., Wilson, J., Millman, K. J., Mayorov, N., Nelson, A. R. J., Jones, E., Kern, R., Larson, E., Carey, C. J., Polat, \u02d9I., Feng, Y., Moore, E. W., VanderPlas, J., Laxalde, D., Perktold, J., Cimrman, R., Henriksen, I., Quintero, E. A., Harris, C. R., Archibald, A. M., Ribeiro, A. H., Pedregosa, F., van Mulbregt, P., and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17:261\u2013272, 2020.   \nWang, K., Kallus, N., and Sun, W. Near-minimax-optimal risk-sensitive reinforcement learning with CVaR. In Proceedings of the International Conference on Machine Learning, 2023a.   \nWang, K., Zhou, K., Wu, R., Kallus, N., and Sun, W. The beneftis of being distributional: Small-loss bounds for reinforcement learning. In Advances in Neural Information Processing Systems, 2023b. ", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Wang, Z., Gao, Y., Wang, S., Zavlanos, M. M., Abate, A., and Johansson, K. H. Policy evaluation in distributional LQR (extended version). arXiv, 2023c. ", "page_idx": 13}, {"type": "text", "text": "Waskom, M. L. seaborn: statistical data visualization. Journal of Open Source Software, 6(60):3021, 2021.   \nWu, R., Uehara, M., and Sun, W. Distributional offline policy evaluation with predictive error guarantees. In Proceedings of the International Conference on Machine Learning, 2023.   \nWurman, P. R., Barrett, S., Kawamoto, K., MacGlashan, J., Subramanian, K., Walsh, T. J., Capobianco, R., Devlic, A., Eckert, F., Fuchs, F., Gilpin, L., Khandelwal, P., Kompella, V., Lin, H., MacAlpine, P., Oller, D., Seno, T., Sherstan, C., Thomure, M. D., Aghabozorgi, H., Barrett, L., Douglas, R., Whitehead, D., D\u00fcrr, P., Stone, P., Spranger, M., and Kitano, H. Outracing champion Gran Turismo drivers with deep reinforcement learning. Nature, 602(7896):223\u2013228, 2022.   \nYang, D., Zhao, L., Lin, Z., Qin, T., Bian, J., and Liu, T.-Y. Fully parameterized quantile function for distributional reinforcement learning. In Advances in Neural Information Processing Systems, 2019.   \nYue, Y., Wang, Z., and Zhou, M. Implicit distributional reinforcement learning. In Advances in Neural Information Processing Systems, 2020.   \nYurinsky, V. Sums and Gaussian vectors. Springer, 2006.   \nZhang, L., Peng, Y., Liang, J., Yang, W., and Zhang, Z. Estimation and inference in distributional ", "page_idx": 13}, {"type": "text", "text": "reinforcement learning. arXiv, 2023. ", "page_idx": 13}, {"type": "text", "text": "APPENDICES: Near-Minimax-Optimal Distributional Reinforcement Learning with a Generative Model ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For convenience, we provide a summary of the contents of the appendices below. ", "page_idx": 14}, {"type": "text", "text": "\u2022 Appendix A provides a detailed discussion of related work.   \n\u2022 Appendix B provides additional convenient notation for the categorical CDF operator $T_{P}$ , in particular expressing it as the combination of a scaling/shifting/projecting operation, and a mixing operation over the state to be bootstrapped from. Several additional self-contained contraction results are given that are used within the main proofs of the paper.   \n\u2022 Appendix C provides proofs for the results in Section 4 concerning the formation of the linear system that is solved by the DCFP algorithm, and verification that the derived system has the unique desired solution.   \n\u2022 Appendix D provides proofs relating to the stochastic categorical CDF Bellman equation, in particular establishing the desired unique solution to this new distributional Bellman equation, and proving a key bound on the local squared-Cram\u00e9r variation that is used within the proof of the main theorem of the paper.   \n\u2022 Appendix E provides the proof of the main result of the paper, Theorem 5.1, giving full details for the steps traced through in the sketch proof in the main paper.   \n\u2022 Appendix F provides discussion of several straightforward extensions of the main result, Theorem 5.1.   \n\u2022 Appendix G provides full details relating to the experiments in the main paper, as well as additional empirical comparisons between methods for distributional RL with a generative model. ", "page_idx": 14}, {"type": "text", "text": "A Related work ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Other families of model-based distributional RL algorithms. There are many approaches to distributional RL; important choices studied previously include moments (Sobel, 1982), exponential families (Morimura et al., 2010b), categorical distributions (Bellemare et al., 2017), collections of particles (Morimura et al., 2010a; Nguyen-Tang et al., 2021), quantiles (Dabney et al., 2018b), and generative models (Doan et al., 2018; Dabney et al., 2018a; Freirich et al., 2019; Yang et al., 2019; Yue et al., 2020). Our choice of categorical representations in this work is motivated by several considerations: (i) the existence of principled dynamic programming methods for these representations, with corresponding convergence theory (Rowland et al., 2018); (ii) the flexibility of these representations to trade-off computational complexity with accuracy (by varying $m$ ) (Rowland et al., 2018); (iii) the mathematical structure of the dynamic programming operator (linear), as described in this work; and (iv) the availability of an efficient algorithm to exactly compute the DP fixed point (the DCFP algorithm proposed in Section 4.1). ", "page_idx": 14}, {"type": "text", "text": "An interesting and important direction, given our empirical findings in Section 6, is whether analyses can also be carried out for other approaches to distributional dynamic programming, such as quantile dynamic programming (QDP; Dabney et al., 2018b; Rowland et al., 2024; Bellemare et al., 2023), and fitted likelihood estimation (FLE; Wu et al., 2023). We expect challenges in extending the analysis to result due to the fact that, for example, the QDP operator is non-linear, and FLE operator applications typically do not have closed forms. Nevertheless, it would be particularly interesting to understand whether it is possible to obtain instance-dependent bounds for QDP, particularly given its strong empirical performance. Similarly, as described in Section 5, an interesting question for future work is whether it is possible to improve on the computational complexity of model-based DCFP for high-probability return-direction estimation. ", "page_idx": 14}, {"type": "text", "text": "Other statistical questions in distributional RL. B\u00f6ck & Heirzinger (2022) propose a model-free algorithm for distributional RL, speedy categorical TD-learning, motivated by categorical TD learning (Rowland et al., 2018) and speedy Q-learning (Azar et al., 2011), and prove a sample complexity bound of $\\widetilde{\\cal O}(\\varepsilon^{-2}(1-\\gamma)^{-3})$ for high probability $\\varepsilon$ -accurate estimation in Cram\u00e9r distance (which implies a non-minimax sample complexity of $\\widetilde{O}(\\varepsilon^{-2}(1-\\gamma)^{-4})$ in Wasserstein-1 distance, per Lemma 5.2). $\\mathrm{W}\\mathbf{u}$ et al. (2023) study the offline evaluation problem, in which state-action pairs are sampled from the stationary distribution of the policy, via ftited likelihood estimation (FLE) and focus on generalisation bounds, allowing for policy evaluation in environments with uncountable state spaces. Wang et al. (2023c) also study policy evaluation in this context, focusing on the LQR model. Aside from studying minimax optimality, Zhang et al. (2023) also make several other contributions on the topic of statistical efficiency of estimation for distributional RL, including analysis of asymptotic fluctuations and limit theorems, and analysis of approximations in more general metrics, including Wasserstein- $p$ , Kolmogorov-Smirnov, and total variation metrics. Their sample complexity results rely on careful analysis of the behaviour of the unprojected distributional Bellman operator $\\tau$ on certain subspaces of probability/signed measures. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "Sample complexity of mean-return estimation. The sample complexity of estimating mean returns, and the related task of obtaining a near-optimal policy, has been considered by Azar et al. (2013); Sidford et al. (2018); Pananjady & Wainwright (2020); Agarwal et al. (2020); Li et al. (2020). Interestingly, Agarwal et al. (2020), while treating the mean-return case, make use of return-binning as a proof technique. Li et al. (2020) also obtain bounds for mean-return sample complexity that apply with $\\varepsilon>(1\\!-\\!\\gamma)^{-1/2}$ for modifications of certainty-equivalent model-based algorithms; an interesting direction for future work would be to check whether the restrictions on $\\varepsilon$ in Theorem 5.1 can be lifted by incorporating ideas from this mean-return analysis to the distributional setting. Additionally, Chandak et al. (2021) consider the task of estimating the variance of returns from off-policy data, and Wang et al. (2023b) study regret minimisation properties (with respect to the expected return criterion) of distributional RL algorithms in the online setting. ", "page_idx": 15}, {"type": "text", "text": "Risk-sensitive control. The theory developed in this paper has focused on estimation of return distributions for individual policies. A natural direction for future work is to analyse identification of near-optimal policies for risk-sensitive decision criteria. Bastani et al. (2022); Wang et al. (2023a) study efficient algorithms for CVaR optimisation, while Fei et al. (2021a,b); Liang & Luo (2022) study entropic risk maximisation, and Du et al. (2022); Lam et al. (2022) study iterated CVaR optimisation, all in the online setting. ", "page_idx": 15}, {"type": "text", "text": "Further analysis. In this paper, we have resolved a conjecture of Zhang et al. (2023), obtaining a near-minimax-optimal algorithm for estimation of return distributions in Wasserstein-1 distance. Zhang et al. (2023) make contributions to several other important statistical questions regarding distributional RL, including approximation in stronger metrics such as Kolmogorov-Smirnov and total variation metrics, as well as studying asymptotic fluctuations of estimators; it will be interesting to see whether the analysis presented here can be extended to these other settings as well. ", "page_idx": 15}, {"type": "text", "text": "B Additional CDF operator notation and contractivity results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we introduce finer-grained notation for the CDF operator $T_{P}$ that allows us to straightforwardly refer to the operations that correspond to shifting/scaling/projecting, and to mixing over transition states, separately. We also establish several additional contraction lemmas that will be useful in the sections that follow. ", "page_idx": 15}, {"type": "text", "text": "B.1 Categorical hat function definition ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "For convenience, we provide the full mathematical definition of the hat functions $h_{i}:[0,(1\\!-\\!\\gamma)^{-1}]\\to$ [0, 1] used in defining the categorical projection described in the main paper, as given by Rowland et al. (2018). For $i=2,\\dots,m-1$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nh_{i}(z)={\\left\\{\\begin{array}{l l}{{\\frac{z-z_{i-1}}{z_{i}-z_{i-1}}}}&{{\\mathrm{~for~}}z\\in[z_{i-1},z_{i}]}\\\\ {{\\frac{z_{i+1}-z}{z_{i+1}-z_{i}}}}&{{\\mathrm{~for~}}z\\in[z_{i},z_{i+1}]}\\\\ {0}&{{\\mathrm{~otherwise.}}}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "For the edge case $h_{1}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nh_{1}(z)={\\\\binom{z_{2}-z}{z_{2}-z_{1}}}\\quad{\\mathrm{for}}\\,z\\in[z_{1},z_{2}]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and similarly for the edge case $h_{m}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nh_{m}(z)={\\\\\\{\\frac{z-z_{m-1}}{z_{m}-z_{m-1}}}\\quad\\mathrm{~for~}}z\\in[z_{m-1},z_{m}]\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "B.2 Finer-grained operator expression ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Recall that the CDF operator $T_{P}:\\mathbb{R}^{\\mathcal{X}\\times m}\\rightarrow\\mathbb{R}^{\\mathcal{X}\\times m}$ is represented by a matrix with elements given by ", "page_idx": 16}, {"type": "equation", "text": "$$\nT_{P}(x,i;j,y)=P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We can therefore conceptualise the application $T_{P}F$ as standard matrix-vector multiplication in the vector space $\\mathbb{R}^{X\\times m}$ . However, the expression for matrix elements in Equation (17) has additional structure that means we can express the application of $T_{P}$ in a different manner, which will be convenient in several proofs below, particularly as it separates out the influence of rewards (which remain fixed) and transition dynamics (which are estimated via samples). ", "page_idx": 16}, {"type": "text", "text": "In particular, we will regard $F\\in\\mathbb{R}^{X\\times m}$ itself as a matrix, with rows indexed by states in $\\mathcal{X}$ , and columns indexed by indices $i\\,=\\,1,\\ldots,m$ . For each state $x\\,\\in\\,{\\mathcal{X}}$ , we then introduce the matrix $B_{x}\\in\\mathbb{R}^{m\\times m}$ , with $(i,j)$ element given by ", "page_idx": 16}, {"type": "equation", "text": "$$\nH_{i,j}^{x}-H_{i,j+1}^{x}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We then have that $(T_{P}F)(x)\\in\\mathbb{R}^{m}$ can alternatively be expressed in matrix notation as ", "page_idx": 16}, {"type": "equation", "text": "$$\nP_{x}F B_{x}^{\\top}\\;,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $P_{x}$ is the row vector given by the row of $P$ corresponding to state $x\\in\\mathscr{X}$ . ", "page_idx": 16}, {"type": "text", "text": "B.3 Additional results ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Below, we provide several additional results regarding contractivity properties of $T_{P}$ . To do so, it is useful to introduce the norm $\\Vert\\cdot\\Vert_{\\ell_{2}}$ on $\\mathbb{R}^{m}$ , which we define by ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|F\\|_{\\ell_{2}}=\\left[\\frac{1}{m(1-\\gamma)}\\sum_{i=1}^{m}F_{i}(x)^{2}\\right]^{1/2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The motivation for this definition is that if we have two distributions $\\nu,\\nu^{\\prime}\\in\\mathcal{P}(\\{z_{1},\\dots,z_{m}\\})$ with corresponding CDF vectors $F,F^{\\prime}\\in\\mathbb{R}^{m}$ , then $\\ell_{2}(\\nu,\\nu^{\\prime})=\\|F-F^{\\prime}\\|_{\\ell_{2}}$ , as $\\nu,\\nu^{\\prime}$ are supported on $[0,(1-\\gamma)^{-1}]$ . Thus, under the abuse of notation $\\ell_{2}(F,F^{\\prime})$ introduced in the main paper, we have $\\bar{\\ell}_{2}(\\dot{F},F^{\\prime})=\\|F-F^{\\prime}\\|_{\\ell_{2}}$ . We also introduce a supremum version of this norm on the space $\\mathbb{R}^{\\mathcal{X}\\times m}$ , which we denote by $\\|\\cdot\\|_{\\ell_{2},\\infty}$ , and define by ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|F\\|_{\\ell_{2},\\infty}=\\operatorname*{max}_{x\\in\\mathcal{X}}\\|F(x)\\|_{\\ell_{2}}\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "for all $F\\in\\mathbb{R}^{X\\times m}$ . This norm is defined so that if we have RDFs $\\eta,\\eta^{\\prime}\\in\\mathscr{P}(\\{z_{1},\\ldots,z_{m}\\})^{\\chi}$ , and $F,F^{\\prime}\\in\\mathbb{R}^{\\mathcal{X}\\times m}$ are the corresponding CDF values, then ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\overline{{{\\ell}}}_{2}(\\eta,\\eta^{\\prime})=\\|F-F^{\\prime}\\|_{\\ell_{2},\\infty}\\,.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "With this norm defined, we can now state and prove our first result, which essentially translates the contraction result in Proposition 2.2, expressed purely in terms of probability distributions and the Cram\u00e9r distance $\\ell_{2}$ , into a slightly more general result expressed over $\\mathbb{R}^{\\mathcal{X}\\times m}$ and the norm $\\Vert\\cdot\\Vert_{\\ell_{2}}$ . ", "page_idx": 16}, {"type": "text", "text": "Proposition B.1. The operator $T_{P}\\,:\\,\\mathbb{R}^{\\mathcal{X}\\times m}\\,\\rightarrow\\,\\mathbb{R}^{\\mathcal{X}\\times m}$ is a contraction when restricted to the subspace $\\{F\\,\\in\\,\\mathbb{R}^{\\chi\\times m}\\,\\colon F_{m}(x)\\,=\\,0$ for all $x\\in\\mathcal{X}\\}$ with respect to the norm $\\|\\cdot\\|_{\\ell_{2},\\infty}$ , with contraction factor $\\sqrt{\\gamma}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. By Proposition 2.2, for any two RDF approximations $\\eta,\\eta^{\\prime}\\;\\in\\;\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})^{\\chi}$ with corresponding CDF values $F,F^{\\prime}\\in\\mathbb{R}^{X}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\overline{{\\ell}}_{2}\\bigl(\\Pi_{m}{\\cal T}\\eta,\\Pi_{m}{\\cal T}\\eta^{\\prime}\\bigr)\\leq\\sqrt{\\gamma}\\overline{{\\ell}}_{2}\\bigl(\\eta,\\eta^{\\prime}\\bigr)\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and hence we also have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|T_{P}F-T_{P}F^{\\prime}\\|_{\\ell_{2},\\infty}\\leq\\sqrt{\\gamma}\\|F-F^{\\prime}\\|_{\\ell_{2},\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Hence, $T_{P}$ is a contraction map on the set ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\{F-F^{\\prime}:0\\leq F_{1}(x)\\leq\\cdot\\cdot\\cdot\\leq F_{m}(x)=1\\,,\\;0\\leq F_{1}^{\\prime}(x)\\leq\\cdot\\cdot\\cdot\\leq F_{m}^{\\prime}(x)=1\\}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This set contains a basis for the subspace $\\{F\\in\\mathbb{R}^{X\\times m}:F_{m}(x)=0$ for all $x\\in\\mathcal{X}\\}$ . Namely, the one-hot vector at coordinate $(x,j)$ (for $j<m)$ ) can be exhibited as lying in this subspace since it can be expressed as the difference between the vectors $F,F^{\\prime}\\in\\mathbb{R}^{\\mathcal{X}\\times m}$ defined by $F_{j}(\\bar{y})=F_{j}^{\\prime}(y)=1$ for all $y\\ne x$ , and all $j=1,\\cdot\\cdot,m$ , and $F_{i}(x)=1$ for $i\\geq j$ (and 0 otherwise), and $F_{i}^{\\prime}(x)=1$ for $i\\geq j+1$ (and 0 otherwise). Since $T_{P}$ is linear, it therefore holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|T_{P}F\\|_{\\ell_{2},\\infty}\\leq\\sqrt{\\gamma}\\|F\\|_{\\ell_{2},\\infty}\\,,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "for any $F$ in the subspace $\\{F\\in\\mathbb{R}^{X\\times m}:F_{m}(x)=0$ for all $x\\in\\mathcal{X}\\}$ , as required. ", "page_idx": 17}, {"type": "text", "text": "Proposition B.2. For each $x\\in\\mathscr{X}$ , the matrix $B_{x}$ is a con\u221atraction mapping on the space $\\{F\\in\\mathbb{R}^{m}$ : $F_{m}=0\\}$ with respect to $\\Vert\\cdot\\Vert_{\\ell_{2}}$ , with contraction factor $\\sqrt{\\gamma}$ . ", "page_idx": 17}, {"type": "text", "text": "Proof. Consider a related one-state MRP, for which the reward at the single state is $r(x)$ , and the state transitions to itself with probability 1. The categorical Bellman operator associated with this MRP and the support $\\{z_{1},\\ldots,z_{m}\\}$ is precisely $B_{x}$ , and the statement of the result therefore follows as a special case of Proposition B.1. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "The next result serves as a counterpoint to Proposition B.2; it shows that if $m$ is sufficiently large, the map $B_{x}$ does not contract by too much in $\\Vert\\cdot\\Vert_{\\ell_{2}}$ . ", "page_idx": 17}, {"type": "text", "text": "Proposition B.3. For any $F,F^{\\prime}\\in\\mathcal{F}$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|B_{x}F-B_{x}F^{\\prime}\\|_{\\ell_{2}}^{2}\\geq\\gamma\\|F-F^{\\prime}\\|_{\\ell_{2}}^{2}-\\frac{2}{m(1-\\gamma)^{1/2}}-\\frac{1}{m^{2}(1-\\gamma)^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This is proven via the following lemma. ", "page_idx": 17}, {"type": "text", "text": "Lemma B.4. For any $\\nu\\,\\in\\,\\mathcal P([0,(1-\\gamma)^{-1}])$ and the projection $\\Pi_{m}\\ :\\ \\mathcal{P}([0,(1\\,-\\,\\gamma)^{-1}])\\ \\rightarrow$ $\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{2}(\\nu,\\Pi_{m}\\nu)\\leq\\frac{1}{2\\sqrt{m(1-\\gamma)}}\\,,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Further, for any $\\nu,\\nu^{\\prime}\\in\\mathcal{P}([0,(1-\\gamma)^{-1}])$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{2}(\\Pi_{m}\\nu,\\Pi_{m}\\nu^{\\prime})\\geq\\ell_{2}(\\nu,\\nu^{\\prime})-\\frac{1}{m(1-\\gamma)}\\,,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{2}^{2}(\\Pi_{m}\\nu,\\Pi_{m}\\nu^{\\prime})\\geq\\ell_{2}^{2}(\\nu,\\nu^{\\prime})-\\frac{2}{m(1-\\gamma)^{1/2}}-\\frac{1}{m^{2}(1-\\gamma)^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. By Rowland et al. (2018, Proposition 6), we have that the CDF values $F_{\\Pi_{m}\\nu}(z_{i})$ for $i=$ $1,\\ldots,m-1$ are equal to the average of the CDF values of $F_{\\nu}$ on the interval $[z_{i},z_{i+1}]$ . Therefore, in computing the squared Cram\u00e9r distance $\\ell_{2}^{2}(\\nu,\\Pi_{m}\\nu)$ , the worst-case contribution to the integral ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{2}^{2}(\\nu,\\Pi_{m}\\nu)=\\int_{0}^{(1-\\gamma)^{-1}}(F_{\\nu}(t)-F_{\\Pi_{m}\\nu}(t))^{2}\\;\\mathrm{d}t\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "from the interval $[z_{i},z_{i+1}]$ , holding $F_{\\nu}(z_{i})$ and $F_{\\nu}(z_{i+1})$ constant, is ", "page_idx": 17}, {"type": "equation", "text": "$$\n(z_{i+1}-z_{i})\\bigg(\\frac{F(z_{i+1})-F(z_{i})}{2}\\bigg)^{2}=\\frac{1}{4m(1-\\gamma)}(F(z_{i+1})-F(z_{i}))^{2}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, the worst-case value for the entire integral is ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\frac{1}{4m(1-\\gamma)}\\sum_{i=1}^{m-1}(F(z_{i})-F(z_{i+1}))^{2}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The worst-case value for the sum is 1, by interpreting this as a sum of squared probabilities, and we therefore deduce that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\ell_{2}^{2}(\\nu,\\Pi_{m}\\nu)\\leq\\frac{1}{4m(1-\\gamma)}\\,,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "leading to ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\ell_{2}(\\nu,\\Pi_{m}\\nu)\\leq\\frac{1}{2\\sqrt{m(1-\\gamma)}}\\,,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "as required for the first stated inequality. For the second and third inequalities, we apply the triangle inequality twice to obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\ell_{2}(\\nu,\\nu^{\\prime})\\leq\\ell_{2}(\\nu,\\Pi_{m}\\nu)+\\ell_{2}(\\Pi_{m}\\nu,\\Pi_{m}\\nu^{\\prime})+\\ell_{2}(\\Pi_{m}\\nu^{\\prime},\\nu^{\\prime})\\leq\\ell_{2}(\\Pi_{m}\\nu,\\Pi_{m}\\nu^{\\prime})+\\frac{1}{m(1-\\gamma)}\\sin\\frac{\\theta}{2}(\\Pi_{m}\\nu^{\\prime},\\nu^{\\prime}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "rearrangement then gives the second statement. Squaring both sides of the inequality above gives ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\ell_{2}^{2}(\\nu,\\nu^{\\prime})\\leq\\ell_{2}^{2}(\\Pi_{m}\\nu,\\Pi_{m}\\nu^{\\prime})+\\frac{2}{m(1-\\gamma)}\\ell_{2}(\\Pi_{m}\\nu,\\Pi_{m}\\nu^{\\prime})+\\frac{1}{m^{2}(1-\\gamma)^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Bounding the instance of $\\ell_{2}(\\Pi_{m}\\nu,\\Pi_{m}\\nu^{\\prime})$ in the cross-term on the right-hand side by $(1-\\gamma)^{1/2}$ and rearranging then yields the result. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "Proof of Proposition B.3. Let $\\nu,\\nu^{\\prime}\\in\\mathcal{P}(\\{z_{1},\\dots,z_{m}\\})$ be the distributions with CDF values $F,F^{\\prime}$ , respectively, and let $G,G^{\\prime}$ be random variables with CDFs $F,F^{\\prime}$ respectively, and $(x,X^{\\prime})$ an independent random transition in the MRP beginning at state $x$ . Recall from the notation introduced earlier in this section that $B_{x}F$ and $B_{x}F^{\\prime}$ are the CDF values of the distributions of $r(x)+\\gamma G$ and $r(x)+\\gamma G^{\\prime}$ after projection onto the support grid $\\{z_{1},\\ldots,z_{m}\\}$ by the projection map $\\Pi_{m}$ . Following common notation in distributional RL (Bellemare et al., 2023), we denote the distributions of $r(x)+\\gamma G$ and $r(x)+\\gamma G^{\\prime}$ by $\\left(b_{r(x),\\gamma}\\right)\\!\\#\\nu$ and $\\left(b_{r(x),\\gamma}\\right)\\!\\#\\nu^{\\prime}$ , respectively. Here, $b_{r(x),\\gamma}:\\mathbb{R}\\to\\mathbb{R}$ is the bootstrap function $b_{r(x),\\gamma}(z)=r(x)+\\gamma z$ , and $\\big(b_{r(x),\\gamma}\\big)_{\\#}\\nu$ is the push-forward distribution of $\\nu$ through $b_{r(x),\\gamma}$ (intuitively, the distribution obtained by transforming the support of $\\nu$ according to $b_{r(x),\\gamma})$ . With this notation introduced, we therefore have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\|B_{x}F-B_{x}F^{\\prime}\\|_{\\ell_{2}}^{2}=\\ell_{2}^{2}(\\Pi_{m}(\\mathrm{b}_{r(x),\\gamma})_{\\#}\\nu,\\Pi_{m}(\\mathrm{b}_{r(x),\\gamma})_{\\#}\\nu^{\\prime})}&{}\\\\ {\\overset{(a)}{\\geq}\\ell_{2}^{2}((\\mathrm{b}_{r(x),\\gamma})_{\\#}\\nu,(\\mathrm{b}_{r(x),\\gamma})_{\\#}\\nu^{\\prime})-\\frac{2}{m(1-\\gamma)^{1/2}}-\\frac{1}{m^{2}(1-\\gamma)^{2}}}&{}\\\\ {\\overset{(b)}{=}\\gamma\\ell_{2}^{2}(\\nu,\\nu^{\\prime})-\\frac{2}{m(1-\\gamma)^{1/2}}-\\frac{1}{m^{2}(1-\\gamma)^{2}}}&{}\\\\ {=\\gamma\\|F-F^{\\prime}\\|_{\\ell_{2}}^{2}-\\frac{2}{m(1-\\gamma)^{1/2}}-\\frac{1}{m^{2}(1-\\gamma)^{2}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "as required, where (a) follows from Lemma B.4, and (b) follows from homogeneity of Cram\u00e9r distance (see Rowland et al. (2018, Proof of Proposition 2)). \u53e3 ", "page_idx": 18}, {"type": "text", "text": "C Proofs of results in Section 4 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proposition 4.1. If $\\eta\\in\\mathcal{P}(\\{z_{1},\\ldots,z_{m}\\})^{\\chi}$ is an RDF with corresponding CDF values $F\\in\\mathbb{R}^{X\\times m}$ , then the corresponding CDF values $F^{\\prime}\\in\\mathbb{R}^{X\\times m}$ for $\\Pi_{m}\\tau\\eta$ satisfy ", "page_idx": 18}, {"type": "equation", "text": "$$\nF_{i}^{\\prime}(x)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m}P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})F_{j}(y)\\,,\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{H_{i,j}^{x}=\\sum_{l\\le i}h_{l}(r(x)+\\gamma z_{j})}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for $j=1,\\dots,m,$ , and by convention we take $H_{i,m+1}^{x}=0$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. Beginning by restating Equation (6), we have that if $\\eta\\,\\in\\,\\mathcal{P}(\\{z_{1},\\dots,z_{m}\\})^{\\chi}$ is an RDF with corresponding probability mass values $p\\in\\mathbb{R}^{\\mathcal{X}\\times m}$ , then the updated RDF $\\eta^{\\prime}=\\Pi_{m}\\tau\\eta$ has corresponding probability mass values $p^{\\prime}\\in\\mathbb{R}^{\\mathcal{X}\\times m}$ given by ", "page_idx": 18}, {"type": "equation", "text": "$$\np_{l}^{\\prime}(x)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m}P(y|x)h_{l,j}^{x}p_{j}(y)\\,.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "First, for $i\\in\\{1,\\ldots,m\\}$ , we sum $l$ from 1 to $i$ to yield ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{F_{i}^{\\prime}(x)=\\sum_{l\\leq i}p_{l}^{\\prime}(x)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m}P(y|x)\\sum_{l\\leq i}h_{l,j}^{x}p_{j}(y)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m}P(y|x)H_{i,j}^{x}p_{j}(y)}}\\\\ &{}&{=\\displaystyle\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m}P(y|x)H_{i,j}^{x}(F_{j}(y)-F_{j-1}(y))\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where by convention we take $F_{0}(y)\\equiv0$ . By reorganising the terms on the right-hand side, the claim now follows. ", "page_idx": 19}, {"type": "text", "text": "Proposition 4.2. The linear system in Equation (10), with the additional linear constraints $F_{m}(x)=$ 1 for all x \u2208X, is equivalent to the following linear system inF  \u2208RX\u00d7[m\u22121]: ", "page_idx": 19}, {"type": "equation", "text": "$$\n(I-\\widetilde{T}_{P})\\widetilde{F}=\\widetilde{H}\\,,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the $(x,i;y,j)$ coordinate of ${\\tilde{T}}_{P}$ (for $1\\leq i,j\\leq m-1)$ is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\widetilde{T}_{P}(x,i;y,j)=P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})\\,,\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and for each $x\\in\\mathcal{X},1\\leq i\\leq m-1$ , we have $\\widetilde H(x,i)=H_{i,m}^{x}$ ", "page_idx": 19}, {"type": "text", "text": "Proof. First, we consider a row of $F\\,=\\,T_{P}F$ that corresponds to the index $(x,i)$ , with $i\\neq m$ . Expanding under the definition of $T_{P}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nF_{i}(x)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m-1}P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})F_{j}(y)+\\sum_{y\\in\\mathcal{X}}P(y|x)H_{i,m}^{x}F_{m}(y)\\,.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since we assume the additional constraints $F_{m}(y)\\equiv1$ for all $y\\in\\mathcal{X}$ , the final term on the right-hand side can be simplified to yield ", "page_idx": 19}, {"type": "equation", "text": "$$\nF_{i}(x)=\\sum_{y\\in\\mathcal{X}}\\sum_{j=1}^{m-1}P(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})F_{j}(y)+H_{i,m}^{x}\\,.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This is precisely the row of $\\widetilde{F}=\\widetilde{T}_{P}\\widetilde{F}+\\widetilde{H}$ corresponding to index $(x,i)$ . ", "page_idx": 19}, {"type": "text", "text": "Now, we consider a row of $F\\,=\\,T_{P}F$ that corresponds to the index $(x,m)$ . Again making the substitution $F_{m}(y)\\equiv1$ for all $y\\in\\mathcal{X}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{c l c r}{{1\\equiv F_{m}(x)=\\displaystyle{\\sum_{y}\\sum_{j=1}^{m-1}P(y|x)\\overbrace{(H_{m,j}^{x}-{\\overbrace{H_{m,j+1}^{x}}})}^{=0}F_{j}(y)+\\sum_{y}P(y|x)H_{m,m}^{x}F_{m}(y)}}}\\\\ {{=\\displaystyle{\\sum_{y}P(y|x)H_{m,m}^{x}F_{m}(y)\\equiv1}\\,,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which shows that the equation is redundant, and hence can be removed from the system. The claim $H_{m,j}^{x}-H_{m,j+1}^{x}=0$ follows since in fact $\\begin{array}{r}{H_{m,j}^{x}=\\sum_{i=1.}^{m}h_{i}(r(x)+\\gamma z_{j})}\\end{array}$ , and the sum over the hat functions for any input argument is 1. In the final  equality, we have used the fact that $H_{m,m}^{x}=1$ similarly. Thus, we have deduced the claim of the proposition. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "Proposition 4.3. The linear system in Equation (11) has a unique solution, which is precisely the CDF values $((F_{i}^{*}(x))_{i=1}^{m-1}:x\\,\\'\\in\\mathcal{X})$ of the categorical fixed point. ", "page_idx": 19}, {"type": "text", "text": "Proof. By Proposition 4.2, we have that the CDF values $\\widetilde{F}^{*}$ of the categorical fixed-point solve Equation (11). Now, let us suppose that ${\\widetilde{F}}_{1},{\\widetilde{F}}_{2}$ are distinct solutions to Equation (11), aiming to obtain a contradiction. Proposition 4.2 also e sta blishes that Equation (11) is equivalent to Equation (10) with the additional conditions that $F_{m}(x)=1$ for all $x\\in\\mathscr{X}$ , so we will denote the corresponding two solutions to Equation (10) built from ${\\widetilde{F}}_{1},{\\widetilde{F}}_{2}$ (by setting the unspecified $(x,m)$ coordinates to 1) by $F_{1},F_{2}$ , respectively. ", "page_idx": 19}, {"type": "text", "text": "The idea is now to use the contractivity of the projected operator $\\Pi_{m}\\tau$ in $\\ell_{2}$ , as established in Proposition 2.2, to obtain a contradiction. Notationally, it is useful to phrase things in terms of contractivity of the CDF operator $T_{P}$ itself. We use the norms $\\Vert\\cdot\\Vert_{\\ell_{2}}$ and $\\|\\cdot\\|_{\\ell_{2},\\infty}$ , defined on $\\mathbb{R}^{m}$ and $\\mathbb{R}^{X\\times m}$ in Appendix B, which we recall here for convenience: ", "page_idx": 20}, {"type": "equation", "text": "$$\n|F\\|_{\\ell_{2}}=\\left[\\frac{1}{m(1-\\gamma)}\\sum_{i=1}^{m}F_{i}^{2}\\right]^{1/2}\\mathrm{~for~}F\\in\\mathbb{R}^{m}\\,,\\ \\ \\mathrm{and}\\ \\ \\|F\\|_{\\ell_{2},\\infty}=\\operatorname*{max}_{x\\in\\mathcal{X}}\\|F(x)\\|_{\\ell_{2}}\\mathrm{~for~}F\\in\\mathbb{R}^{X\\times m},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We therefore have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|T_{P}(F_{1}-F_{2})\\|_{\\ell_{2},\\infty}=\\|T_{P}F_{1}-T_{P}F_{2}\\|_{\\ell_{2},\\infty}=\\|F_{1}-F_{2}\\|_{\\ell_{2},\\infty}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "However, Proposition B.1 establishes that $T_{P}$ is a contraction on $\\{F\\,\\,\\in\\,\\,\\mathbb{R}^{\\mathcal{X}\\times m}\\,:\\,F_{m}(x)\\,=$ 0 for all $x\\in\\mathcal{X}\\}$ with respect to $\\|\\cdot\\|_{\\ell_{2},\\infty}$ , which contradicts the statement above, as required. ", "page_idx": 20}, {"type": "text", "text": "D Proofs relating to the stochastic CDF Bellman equation ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Before giving the proofs, we present a version of the SC-CDF Bellman equation in a purely distributional form, which will streamline the arguments. This mirrors the development of the form of the distributional Bellman equation given purely in terms of distributions (Rowland et al., 2018), rather than in random variable form as in Bellemare et al. (2017). We define the stochastic categorical CDF Bellman operator $T_{\\mathrm{SCC}}:{\\mathcal{P}}({\\mathcal{F}})^{\\mathcal{X}}\\to{\\mathcal{P}}({\\mathcal{F}})^{\\mathcal{X}}$ for each $\\psi\\in\\mathcal{P}(\\mathcal{F})^{\\mathcal{X}}$ by ", "page_idx": 20}, {"type": "equation", "text": "$$\n(\\mathcal{T}_{\\mathrm{SCC}}\\;\\psi)(x)=\\mathcal{D}((\\hat{T}_{P}\\Phi)(x))\\,,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\Phi(y)\\sim\\psi(y)$ independently of $\\hat{T}_{P}$ , and $\\mathcal{D}$ extracts the distribution of the input random variable. The purely distributional form of the SC-CDF Bellman equation is then written as a fixed point condition on $\\mathcal{P}(\\mathcal{F})^{\\mathcal{X}}$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\psi=\\tau_{\\mathrm{SCC}}\\;\\psi\\,.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We also write ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\overline{{w}}_{\\parallel\\cdot\\parallel\\ell_{2}}(\\psi,\\psi^{\\prime})=\\operatorname*{max}_{x\\in\\mathcal{X}}w_{\\parallel\\cdot\\parallel\\ell_{2}}(\\psi(x),\\psi(x^{\\prime}))\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "for the supremum-Wasserstein distance over $\\mathcal{P}(\\mathcal{F})^{\\mathcal{X}}$ with base metric $\\Vert\\cdot\\Vert_{\\ell_{2}}$ on $\\mathcal{F}$ . ", "page_idx": 20}, {"type": "text", "text": "Proposition 5.7. The SC-CDF Bellman equation in Equation (16) has a unique solution, in the sense that there is a unique distribution for each $\\Phi(x)$ such that Equation (16) holds for each $x\\in\\mathscr{X}$ . ", "page_idx": 20}, {"type": "text", "text": "Proof. We first show that the operator $\\mathcal{T}_{\\mathrm{SCC}}$ is a contraction on $\\mathcal{P}(\\mathcal{F})^{\\chi}$ with respect to the metric $\\overline{{w}}_{\\parallel\\cdot\\parallel_{\\ell_{2}}}$ . Suppose $\\psi,\\psi^{\\prime}\\in\\mathcal{P}(\\bar{\\mathcal{F}})^{\\chi}$ , and let $(\\Phi(y),\\Phi^{\\prime}(y))$ be an optimal coupling between $\\psi(y)$ and $\\psi^{\\prime}(y)$ with respect to $w_{\\parallel\\cdot\\parallel_{\\ell_{2}}}$ for each $y\\in\\mathcal{X}$ (existence of such couplings is guaranteed by Villani (2009, Theorem 4.1)). Then, letting $(x,X^{\\prime})$ be a random transition from $x$ , independent of $\\Phi,\\Phi^{\\prime}$ , we have that $(B_{x}\\Phi(X^{\\prime}),B_{x}\\Phi^{\\prime}(X^{\\prime}))$ is a valid coupling of $(\\mathcal{T}_{\\mathrm{SCC}}~\\psi)(x)$ and $(\\overbar{\\mathcal{T}}\\mathrm{scc}\\ \\psi^{\\prime})(x)$ . Then we have, using the operator notation defined in Appendix $\\mathbf{B}$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{w_{\\parallel\\cdot\\parallel_{\\ell}}((\\mathcal{T}_{\\mathrm{SCC}}~\\psi)(x),(\\mathcal{T}_{\\mathrm{SCC}}~\\psi^{\\prime})(x))\\overset{(a)}{\\leq}\\mathbb{E}\\bigg[\\|B_{x}\\Phi(X^{\\prime})-B_{x}\\Phi^{\\prime}(X^{\\prime})\\|_{\\ell_{2}}\\bigg]}\\\\ {\\overset{(b)}{\\leq}\\sqrt{\\gamma}\\mathbb{E}\\bigg[\\|\\Phi(X^{\\prime})-\\Phi^{\\prime}(X^{\\prime})\\|_{\\ell_{2}}\\bigg]}\\\\ {=\\sqrt{\\gamma}\\sum_{y\\in X}P(y|x)\\mathbb{E}\\bigg[\\|\\Phi(y)-\\Phi^{\\prime}(y)\\|_{\\ell_{2}}\\bigg]}\\\\ {\\overset{(c)}{=}\\sqrt{\\gamma}\\sum_{y\\in X}P(y|x)w_{\\parallel\\cdot\\parallel_{\\ell_{2}}}(\\psi(y),\\psi^{\\prime}(y))}\\\\ {\\leq\\sqrt{\\gamma}\\overline{{w}}_{\\parallel\\cdot\\parallel_{\\ell_{2}}}(\\psi,\\psi^{\\prime}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where (a) follows since $(B_{x}\\Phi(X^{\\prime}),B_{x}\\Phi^{\\prime}(X^{\\prime}))$ is a valid coupling of $(\\mathcal{T}_{\\mathrm{SCC}}~\\psi)(x)$ and $(\\mathcal{T}_{\\mathrm{SCC}}\\;\\psi^{\\prime})(x)$ , (b) follows by contractivity of $B_{x}$ with respect to $\\Vert\\cdot\\Vert_{\\ell_{2}}$ , as shown in Proposition B.2, and (c) follows since $(\\Phi(y),{\\dot{\\Phi}}^{\\prime}(y))$ was chosen to be an optimal coupling of $\\psi(y)$ and $\\bar{\\psi}(y^{\\prime})$ . Hence we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\overline{{w}}_{\\parallel\\cdot\\parallel\\ell_{2}}(\\mathcal{T}_{\\mathrm{SCC}}\\psi,\\mathcal{T}_{\\mathrm{SCC}}\\psi^{\\prime})\\leq\\sqrt{\\gamma}\\overline{{w}}_{\\parallel\\cdot\\parallel\\ell_{2}}(\\psi,\\psi^{\\prime})\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "proving contractivity. ", "page_idx": 21}, {"type": "text", "text": "The metric space $(\\mathcal P(\\mathcal F)^{\\mathcal X},\\overline{{\\boldsymbol w}}_{\\parallel\\cdot\\parallel\\boldsymbol\\ell_{2}})$ is complete, since the base space $(\\mathcal{F},\\|\\cdot\\|_{\\ell_{2}})$ is separable and complete (Villani, 2009, Theorem 6.18). Hence, by Banach\u2019s fixed point theorem, we obtain that there is a unique fixed point $\\psi^{*}\\in\\mathcal{P}(\\mathcal{F})^{\\chi}$ of $\\mathcal{T}_{\\mathrm{SCC}}$ . Thus, a collection of random CDFs $(\\Phi^{*}(x):x\\in\\mathcal{X})$ satisfy the SC-CDF Bellman equation in Equation (16) if and only if we have $\\Phi^{*}(x)\\sim\\psi^{*}(x)$ for all $x\\in\\mathscr{X}$ . \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Proposition 5.8. For all $x\\in\\mathscr{X}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\Phi^{Q}(x)]=F^{Q}(x)\\,.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. We take expectations on both sides of the random-variable stochastic categorical CDF Bellman equation in Equation (16), yielding: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\Phi^{Q}(x)]=\\mathbb{E}[(\\hat{T}_{Q}\\Phi^{Q})(x)]\\,.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Since $\\hat{T}_{Q}$ is a random linear map, independent of $\\Phi^{Q}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\Phi^{Q}(x)]=(\\mathbb{E}[\\hat{T}_{Q}]\\mathbb{E}[\\Phi^{Q}])(x)}\\\\ {=T_{Q}\\mathbb{E}[\\Phi^{Q}](x)\\,.\\,\\,\\,\\,\\,\\,\\,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "This states that $\\mathbb{E}[\\Phi^{Q}]\\in\\mathbb{R}^{\\mathcal{X}\\times m}$ satisfies the standard categorical Bellman equation in Equation (10), and hence $\\mathbb{E}[\\Phi^{Q}]^{\\bullet}=\\bar{F}^{Q}$ , by Proposition 2.2, as required. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "Proposition 5.11. We have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Sigma_{Q}\\geq\\sigma_{Q}+\\gamma Q\\Sigma_{Q}-\\left(\\frac{2}{m\\sqrt{1-\\gamma}}+\\frac{1}{m^{2}(1-\\gamma)^{2}}\\right)\\mathbf{1}\\,,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\mathbf{1}\\in\\mathbb{R}^{\\mathcal{X}}$ is a vector of ones, and the inequality above is interpreted component-wise. ", "page_idx": 21}, {"type": "text", "text": "Proof. We calculate, writing $\\Phi^{Q}$ as $\\Phi$ , $F^{Q}$ as $F$ , and $\\hat{T}_{Q}$ as $\\hat{T}$ to lighten notation: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Sigma_{Q}(x)=\\mathbb{E}[\\ell_{2}^{2}(\\Phi(x),F(x))]}\\\\ &{\\qquad\\quad\\overset{(a)}{=}\\mathbb{E}[\\ell_{2}^{2}((\\hat{T}\\Phi)(x),F(x))]}\\\\ &{\\qquad\\quad\\overset{(b)}{=}\\mathbb{E}[\\ell_{2}^{2}((\\hat{T}F)(x),F(x))]+\\mathbb{E}[\\ell_{2}^{2}((\\hat{T}\\Phi)(x),(\\hat{T}F)(x))]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Here, (a) follows since $\\Phi$ satisfies the random-variable version of the stochastic categorical CDF Bellman equation, (b) is a result of a Pythagorean identity for squared Cram\u00e9r distance, which we derive below: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\mathbb{E}[\\ell_{2}^{2}((\\hat{T}\\Phi)(x),F(x))]=\\mathbb{E}\\bigg[\\int_{0}^{(1-\\gamma)^{-1}}((\\hat{T}\\Phi)(x)(t)-F(x)(t))^{2}\\;\\mathrm{d}t\\bigg]}\\\\ &{}&{\\qquad=\\int_{0}^{(1-\\gamma)^{-1}}\\mathbb{E}[((\\hat{T}\\Phi)(x)(t)-F(x)(t))^{2}]\\;\\mathrm{d}t\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the integral switch follows from Fubini\u2019s theorem. Now, focusing on the integrand above, it can be written as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[(Y-\\mathbb{E}[Y])^{2}]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "with $Y=({\\hat{T}}\\Phi)(x)(t)$ , since $F(x)=\\mathbb{E}[({\\hat{T}}\\Phi)(x)]=\\mathbb{E}[\\Phi(x)]$ , by Lemma 5.8. We have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[(Y-\\mathbb{E}[Y])^{2}]=\\mathbb{E}[(Y-\\mathbb{E}[Y|\\hat{T}]+\\mathbb{E}[Y|\\hat{T}]-\\mathbb{E}[Y])^{2}]}\\\\ &{\\qquad\\qquad\\qquad=\\mathbb{E}[(Y-\\mathbb{E}[Y|\\hat{T}])^{2}]+\\mathbb{E}[(\\mathbb{E}[Y|\\hat{T}]-\\mathbb{E}[Y])^{2}]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now, $\\mathbb{E}[({\\hat{T}}\\Phi)(x)(t)\\ \\mid\\ {\\hat{T}}]\\ =\\ ({\\hat{T}}\\mathbb{E}[\\Phi])(x)(t)\\ =\\ ({\\hat{T}}F)(x)(t)$ , by linearity, which concludes the validation of step (b) above. We recognise the first term in Equation (20) as the local squared-Cram\u00e9r variation, and hence have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Sigma_{Q}(x)=\\sigma_{Q}(x)+\\mathbb{E}[\\ell_{2}^{2}((\\hat{T}\\Phi)(x),(\\hat{T}F)(x))]\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We now explicitly write the evaluation of the application of T\u02c6 at coordinate $x$ in terms of the random transition $(x,X^{\\prime})$ used to construct the single-sample random transition matrix $\\hat{Q}$ described in Definition 5.4, so that we obtain, with the operator notation of Appendix $\\mathbf{B}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[\\ell_{2}^{2}((\\hat{T}\\Phi)(x),(\\hat{T}F)(x))]=\\mathbb{E}[\\ell_{2}^{2}(B_{x}\\Phi(X^{\\prime}),B_{x}F(X^{\\prime}))]}&{}\\\\ {=\\mathbb{E}[\\mathbb{E}[\\ell_{2}^{2}(B_{x}\\Phi(X^{\\prime}),B_{x}F(X^{\\prime}))\\mid\\Phi]]}\\\\ {=\\mathbb{E}\\biggl[\\sum_{y\\in X}Q(y|x)\\ell_{2}^{2}(B_{x}\\Phi(y),B_{x}F(y))\\biggr]}\\\\ {\\overset{(a)}{\\geq}\\sum Q(y|x)\\mathbb{E}[\\ell_{2}^{2}(\\Phi(y),F(y))-\\alpha]}\\\\ {\\overset{y\\in X}{=}Q(y|x)\\mathbb{E}[\\ell_{2}^{2}(\\Phi(y),F(y))]-\\alpha}\\\\ {=\\gamma\\sum_{y\\in X}Q(y|x)\\mathbb{E}[\\ell_{2}^{2}(\\Phi(y),F(y))]-\\alpha}\\\\ {=\\gamma\\sum_{y\\in X}Q(y|x)\\mathbb{E}[\\ell_{2}^{2}(\\Phi(y),F(y))]-\\alpha}\\\\ {=\\gamma\\langle Q\\Sigma_{Q}(x)\\rangle-\\alpha,}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where (a) follows from Proposition B.3, with $\\begin{array}{r}{\\alpha=\\frac{2}{m(1-\\gamma)^{1/2}}+\\frac{1}{m^{2}(1-\\gamma)^{2}}}\\end{array}$ , meaning that we deduce ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Sigma_{Q}(x)=\\sigma_{Q}(x)+\\gamma(Q\\Sigma_{Q})(x)-\\alpha\\,,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "as required. ", "page_idx": 22}, {"type": "text", "text": "Corollary 5.12. We can bound the term $\\|(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\|_{\\infty}$ appearing in Equation (14) under the assumptions of Theorem 5.3 as follows: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\|(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\|_{\\infty}\\leq\\|\\Sigma_{\\hat{P}}\\|_{\\infty}+\\frac{1}{1-\\gamma}\\leq\\frac{2}{1-\\gamma}\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. By Proposition 5.11 applied with $Q={\\hat{P}}$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Sigma_{\\hat{P}}\\geq\\sigma_{\\hat{P}}+\\gamma\\hat{P}\\Sigma_{\\hat{P}}-\\left(\\frac{2}{m(1-\\gamma)^{1/2}}+\\frac{1}{m^{2}(1-\\gamma)^{2}}\\right)\\mathbf{1}\\,,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\mathbf{1}\\in\\mathbb{R}^{\\mathcal{X}}$ is the vector of ones. We first note that from the condition $m\\geq4\\varepsilon^{-2}(1-\\gamma)^{-2}+1$ from the statement of Theorem 5.3, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\frac{2}{m(1-\\gamma)^{1/2}}+\\frac{1}{m^{2}(1-\\gamma)^{2}}\\leq\\frac{2}{4\\varepsilon^{-2}(1-\\gamma)^{-2}(1-\\gamma)^{1/2}}+\\frac{1}{4\\varepsilon^{-2}}\\leq\\frac{\\varepsilon^{2}(1-\\gamma)^{3/2}}{2}+\\frac{\\varepsilon^{2}}{4}<1\\,,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "since $\\varepsilon\\in(0,1)$ , from the statement of Theorem 5.3. ", "page_idx": 22}, {"type": "text", "text": "We therefore have ", "page_idx": 22}, {"type": "equation", "text": "$$\n(I-\\gamma\\hat{P})\\Sigma_{\\hat{P}}\\geq\\sigma_{\\hat{P}}-{\\bf1}\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Now, $(I\\mathrm{~-~}\\gamma\\hat{P})^{-1}$ is a monotone operator (in the sense that $v_{1}~\\geq~v_{2}$ coordinatewise implies $(I-\\gamma\\hat{P})^{-1}v_{1}\\geq(I-\\gamma\\hat{P})^{-1}v_{2}$ ; this claim follows as all elements of $(I-\\gamma\\hat{P})^{-1}$ are non-negative, since it can also be written $\\sum_{k\\geq0}\\gamma^{k}\\hat{P}^{k})$ , we can apply it to both sides of the inequality above to obtain ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Sigma_{\\hat{P}}+(1-\\gamma)^{-1}{\\bf1}\\geq(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Finally, we note that since $\\Sigma_{\\hat{P}}(x)$ is an expected squared-Cram\u00e9r distance between two CDFs supported on an interval of length $(1-\\gamma)^{-1}$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Sigma_{\\hat{P}}(x)\\leq(1-\\gamma)^{-1}\\,,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "from which the claim follows. ", "page_idx": 22}, {"type": "text", "text": "E Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We begin by restating the result we seek to prove. ", "page_idx": 23}, {"type": "text", "text": "Theorem 5.1. Let $\\varepsilon\\,\\in\\,(0,(1-\\gamma)^{-1/2})$ and $\\delta\\,\\in\\,(0,1)$ , and suppose the number of categories satisfies $m\\geq4(1-\\gamma)^{-2}\\varepsilon^{-2}+1$ . Then the output $\\hat{F}$ of model-based DCFP with $N=\\Omega(\\varepsilon^{-2}(1-$ $\\gamma)^{-3}\\mathrm{polylog}(|\\mathcal{X}|/\\delta))$ samples satisfies, with probability at least $1-\\delta$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x\\in\\mathcal{X}}w_{1}(\\eta^{*}(x),\\hat{F}(x))\\leq\\varepsilon\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We arrange the proof into a sequence of smaller results, in analogy with the presentation of the sketch proof in the main paper. ", "page_idx": 23}, {"type": "text", "text": "E.1 Reduction to high-probability bounds in Cram\u00e9r distance ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Following the sketch provided in the main paper, we first restate and prove Lemma 5.2. ", "page_idx": 23}, {"type": "text", "text": "Lemma 5.2. For any two distributions $\\nu,\\nu^{\\prime}\\in\\mathcal{P}([0,(1-\\gamma)^{-1}])$ , we have ", "page_idx": 23}, {"type": "equation", "text": "$$\nw_{1}(\\nu,\\nu^{\\prime})\\leq(1-\\gamma)^{-1/2}\\ell_{2}(\\nu,\\nu^{\\prime})\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Proof. We begin by writing ", "page_idx": 23}, {"type": "equation", "text": "$$\nv_{1}(\\nu,\\nu^{\\prime})=\\int_{0}^{(1-\\gamma)^{-1}}|F_{\\nu}(t)-F_{\\nu^{\\prime}}(t)|\\,\\mathrm{d}t=(1-\\gamma)^{-1}\\left[(1-\\gamma)\\int_{0}^{(1-\\gamma)^{-1}}|F_{\\nu}(t)-F_{\\nu^{\\prime}}(t)|\\,\\mathrm{d}t\\right]\\,,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where $F_{\\nu},F_{\\nu^{\\prime}}$ are the CDFs of $\\nu,\\nu^{\\prime}$ , respectively. The quantity inside the squared brackets can be interpreted as an expectation (with $t$ ranging over the values of a uniform variate on $\\mathbb{E}_{T\\sim\\mathrm{Unif}([0,(1-\\gamma)^{-1}])}[|F_{\\nu}(T)\\stackrel{\\cdot}{-}F_{\\nu^{\\prime}}(T)|]$ , and we can therefore apply Jensen\u2019s inequality with the map $z\\mapsto z^{2}$ . This then yields ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle w_{1}(\\nu,\\nu^{\\prime})\\le(1-\\gamma)^{-1}\\left[(1-\\gamma)\\int_{0}^{(1-\\gamma)^{-1}}(F_{\\nu}(t)-F_{\\nu^{\\prime}}(t))^{2}\\;\\mathrm{d}t\\right]^{1/2}}\\ ~}\\\\ {{\\displaystyle~~~~~~~~~~~=(1-\\gamma)^{-1/2}\\ell_{2}(\\nu,\\nu^{\\prime})\\,,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "as required. ", "page_idx": 23}, {"type": "text", "text": "The first main step of the proof of Theorem 5.1 is a reduction to Theorem 5.3 via Lemma 5.2. To see this, we first restate Theorem 5.3 here for convenience. ", "page_idx": 23}, {"type": "text", "text": "Theorem 5.3. Let $\\varepsilon~\\in~(0,1)$ and $\\delta~\\in~(0,1)$ , and suppose the number of categories satisfies $m\\;\\geq\\;4(1\\,-\\,\\gamma)^{-2}\\varepsilon^{-2}\\,+\\,1$ . Then the output $\\hat{F}$ of model-based DCFP with $N\\;=\\;\\Omega(\\varepsilon^{-2}(1\\;-\\;$ $\\gamma)^{-2}\\mathrm{polylog}(|\\mathcal{X}|/\\delta))$ samples satisfies, with probability at least $1-\\delta$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x\\in\\mathcal{X}}\\ell_{2}(\\eta^{*}(x),\\hat{F}(x))\\leq\\varepsilon\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "For the proof of the reduction, suppose the statement of Theorem 5.3 holds. Now, let us take $\\varepsilon\\in(0,(1-\\gamma)^{-1/2})$ , and $m\\geq4(1-\\gamma)^{-2}\\varepsilon^{-2}+1$ , as in the assumptions of Theorem 5.1. We then define $\\widetilde{\\varepsilon}=(1-\\gamma)^{1/2}\\varepsilon$ ; note that from the assumption on $\\varepsilon$ , we have $\\widetilde{\\varepsilon}\\in(0,1)$ . Applying the result of Theorem 5.3, we therefore obtain that with $N=\\widetilde\\Omega(\\widetilde{\\varepsilon}^{-2}(1-\\gamma)^{-2}\\mathrm{polylog}(|\\mathcal{X}|/\\delta))$ , we have (with probability at least $1-\\delta$ ) ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{x\\in\\mathcal{X}}\\ell_{2}(\\eta^{*}(x),\\hat{F}(x))\\leq\\widetilde{\\varepsilon}\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "By Lemma 5.2, we therefore have (with probability at least $1-\\delta$ , for all $x\\in\\mathscr{X}$ ) ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\overline{{w}}_{1}(\\eta^{*}(x),\\hat{F}(x))\\leq(1-\\gamma)^{-1/2}\\ell_{2}(\\eta^{*}(x),\\hat{F}(x))\\leq(1-\\gamma)^{-1/2}(1-\\gamma)^{1/2}\\varepsilon=\\varepsilon\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "which is the desired inequality in Theorem 5.1. Finally, we note that the sample complexity term $\\widetilde{\\varepsilon}^{-2}(1-\\gamma)^{-2}$ can be rewritten as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\widetilde{\\varepsilon}^{-2}(1-\\gamma)^{-2}=((1-\\gamma)^{1/2}\\varepsilon)^{-2}(1-\\gamma)^{-2}=\\varepsilon^{-2}(1-\\gamma)^{-3}\\,.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Thus, we obtain the stated sample complexity in Theorem 5.1, and we have established that to prove Theorem 5.1, it is sufficient to prove Theorem 5.3. ", "page_idx": 23}, {"type": "text", "text": "E.2 Reduction to categorical fixed-point error ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The first step of the proof of Theorem 5.3 is to show that with $m$ taken sufficiently large (as described in the statement of Theorem 5.3), the Cram\u00e9r distance between the true return distributions and the categorical fixed points is small, and it is therefore sufficient to focus solely on the sample-based error in estimating the categorical fixed point. ", "page_idx": 24}, {"type": "text", "text": "By applying the triangle inequality, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\overline{{\\ell}}_{2}(\\eta^{*},\\hat{F})\\leq\\overline{{\\ell}}_{2}(\\eta^{*},F^{*})+\\overline{{\\ell}}_{2}(F^{*},\\hat{F})}\\\\ {\\displaystyle\\qquad\\leq\\frac{1}{(1-\\gamma)\\sqrt{m-1}}+\\overline{{\\ell}}_{2}(F^{*},\\hat{F})}\\\\ {\\displaystyle\\qquad\\leq\\frac{\\varepsilon}{2}+\\overline{{\\ell}}_{2}(F^{*},\\hat{F})\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where (a) follows from the fixed-point approximation bound in Equation (5), which itself is the result of Proposition 2 of Rowland et al. (2018), and (b) follows from substituting the assumed inequality for $m$ in the statement of Theorem 5.3. Thus, to establish that $\\bar{\\ell}_{2}(\\eta^{*},\\hat{F})$ is bounded by $\\varepsilon$ with probability at least $1-\\delta$ , it suffices to show that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\bar{\\ell}_{2}(F^{*},\\hat{F})<\\varepsilon/2\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "with probability at least $1-\\delta$ , as claimed. ", "page_idx": 24}, {"type": "text", "text": "E.3 Propagation of local errors ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "To begin analysing $\\bar{\\ell}_{2}(F^{*},\\hat{F})$ , we analyse the difference of vectors ${\\hat{F}}-F^{*}$ directly. We proceed in an analogous manner to Azar et al. (2013) in the mean-return case, rearranging as follows: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\hat{F}-F^{*}\\overset{(a)}{=}T_{\\hat{P}}\\hat{F}-T_{P}F^{*}}}\\\\ {{\\overset{(b)}{=}T_{\\hat{P}}\\hat{F}-T_{\\hat{P}}F^{*}+T_{\\hat{P}}F^{*}-T_{P}F^{*}}}\\\\ {{\\Longrightarrow\\ (I-T_{\\hat{P}})(\\hat{F}-F^{*})=(T_{\\hat{P}}-T_{P})F^{*}\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here, (a) follows since ${\\hat{F}},F^{*}$ are fixed points of $T_{\\hat{P}},T_{P}$ , respectively, (b) follows by adding and subtracting $T_{\\hat{P}}F^{*}$ , and the implication follows from straightforward rearrangement. ", "page_idx": 24}, {"type": "text", "text": "We would next like to rearrange Equation (21) to leave the term ${\\hat{F}}-F^{*}$ on its own. This requires some care, in checking that the operator $(I-T_{\\hat{P}})$ is invertible in an appropriate sense. ", "page_idx": 24}, {"type": "text", "text": "Lemma E.1. The operator $I-T_{\\hat{P}}:\\mathbb{R}^{\\mathcal{X}\\times m}\\rightarrow\\mathbb{R}^{\\mathcal{X}\\times m}$ is invertible on the subspace $\\{F\\in\\mathbb{R}^{X\\times m}$ : Fm(x) = 0 for all x \u2208X}, with inverse  k\u22650 T Pk\u02c6 . ", "page_idx": 24}, {"type": "text", "text": "Proof. By Proposition B.1, $T_{\\hat{P}}$ maps $\\{F\\in\\mathbb{R}^{X\\times m}:F_{m}(x)=0$ for all $x\\in\\mathcal{X}\\}$ to itself, and is a contraction on this subspace with respect to $\\ell_{2}$ , with contraction factor $\\sqrt{\\gamma}$ . It therefore follows that $I-T_{\\hat{P}}$ maps this subspace to itself, and is invertible on this subspace. Since $\\sum_{k\\geq0}T_{\\hat{P}}^{k}$ T kalso maps this subspace to itself, it follows that on this subspace, we have $\\begin{array}{r}{(I-T_{\\hat{P}})^{-1}=\\sum_{k\\geq0}\\bar{T}_{\\hat{P}}^{k},}\\end{array}$ , a s \u53e3 ", "page_idx": 24}, {"type": "text", "text": "Now, $\\begin{array}{r}{(T_{\\hat{P}}-T_{P})F^{*}\\in\\{F\\in\\mathbb{R}^{\\mathcal{X}\\times m}:F_{m}(x)=0}\\end{array}$ for all $x\\in\\mathcal{X}\\}$ , and hence from Equation (21) and Lemma E.1, it follows that ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\hat{F}-F^{*}=\\sum_{k\\geq0}T_{\\hat{P}}^{k}(T_{\\hat{P}}-T_{P})F^{*}\\,.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "The result is that we have expressed the difference in CDFs in terms of local errors $(T_{\\hat{P}}-T_{P})F^{*}$ , which are then propagated via the operator $\\sum_{k\\geq0}T_{\\hat{P}}^{k}$ . ", "page_idx": 24}, {"type": "text", "text": "E.4 Bernstein concentration bounds ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "The next step in the proof is to establish a concentration bound for the local errors $(T_{\\hat{P}}-T_{P})F^{*}$ . ", "page_idx": 25}, {"type": "text", "text": "One potential approach is to use a concentration inequality for each individual coordinate of $(T_{\\hat{P}}-$ $T_{P})\\bar{F}^{*}$ , indexed by $(x,i)$ . Azar et al. (2013) note that in the mean-return case, using a Hoeffdingstyle bound is insufficient to obtain optimal dependence of the sample complexity on $(1-\\gamma)^{-\\overline{{1}}}$ , and Zhang et al. (2023) also note this in their (non-categorical) distributional analysis. Using a Bernstein concentration inequality on each coordinate and then using a union bound can be made to work, although this then incurs a $\\log(m)$ factor in the sample complexity. If such a dependence on $m$ were tight, this would suggest that the sample complexity depends on $m$ (albeit only logarithmically), and hence there would be a trade-off between picking $m$ sufficiently large so as to obtain a low representation approximation error, as in Section E.2, and taking $m$ low so as to not unduly increase the sample complexity. However, such a dependence on $m$ can be avoided by working with concentration inequalities at the level of CDFs themselves. The Dvorestsky-Kiefer-Wolfowitz (DKW) inequality (Dvoretzky et al., 1956; Massart, 1990) behaves analogously to Hoeffding\u2019s bound, and is insufficient for obtaining a sample complexity bound with optimal $\\!\\,(1-\\gamma)^{-1}$ dependence. Instead, we make use of a Hilbert space Bernstein-style inequality (Yurinsky, 2006; Chatalic et al., 2022), by interpreting the Cram\u00e9r distance $\\ell_{2}$ as a maximum mean discrepancy (Gretton et al., 2012), which measures distances between distributions via embeddings in a (reproducing kernel) Hilbert space, allowing the Bernstein result to be applied. ", "page_idx": 25}, {"type": "text", "text": "First, we precisely describe the connection between Cram\u00e9r distance and Hilbert space. Sz\u00e9kely (2003) shows that for any distributions $\\nu,\\nu^{\\prime}\\in\\mathcal{P}([0,(1-\\gamma)^{-1}])$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\ell_{2}^{2}(\\nu,\\nu^{\\prime})=\\mathbb{E}_{X\\sim\\nu,Y\\sim\\nu^{\\prime}}[|X-Y|]-\\frac{1}{2}\\mathbb{E}_{X,X^{\\prime}\\sim\\nu}[|X-X^{\\prime}|]-\\frac{1}{2}\\mathbb{E}_{Y,Y^{\\prime}\\sim\\nu^{\\prime}}[|Y-Y^{\\prime}|]\\,.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Sejdinovic et al. (2013) show that there exists an affine embedding $\\phi:\\mathcal{P}([0,(1-\\gamma)^{-1}])\\to\\mathcal{H}$ of distributions into a Hilbert space $\\mathcal{H}$ , such that the right-hand side of the equation can also be written as the squared norm $\\|\\phi(\\nu)\\bar{-}\\phi(\\nu^{\\prime})\\|_{\\mathcal{H}}^{2}$ ; in other words, they show that the Cram\u00e9r distance is equal to a squared maximum mean discrepancy (Gretton et al., 2012). We can then appeal to the following Bernstein-style inequality for Hilbert-space-valued random variables, which is due to Chatalic et al. (2022), and based largely on Yurinsky (2006, Theorem 3.3.4). We state the result here in the usual Bernstein style of assuming almost-sure boundedness of the the random variables concerned, while Chatalic et al. (2022) use the more general formulation of assuming particular bounds on all moments. ", "page_idx": 25}, {"type": "text", "text": "Lemma E.2. (Chatalic et al., 2022, Lemma E.3) L $e t\\,Z_{1},\\dots,Z_{N}$ be i.i.d. mean-zero random variables taking values in a Hilbert space $(\\mathscr{H},\\|\\cdot\\|\\mathscr{H})$ such that $\\|Z_{1}\\|_{\\mathcal{H}}\\leq M$ almost surely. Then for any $\\delta\\in(0,1)$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\left\\|\\frac{1}{N}\\sum_{i=1}^{N}Z_{i}\\right\\|_{\\mathcal{H}}\\leq\\frac{2M\\log(2/\\delta)}{N}+\\sqrt{\\frac{2\\mathbb{E}[\\|Z_{1}\\|_{\\mathcal{H}}^{2}]\\log(2/\\delta)}{N}}\\,,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "with probability at least $1-\\delta$ . ", "page_idx": 25}, {"type": "text", "text": "To apply this result in our setting, first note that, using the notation introduced in Appendix B, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\|[(T_{\\hat{P}}-T_{P})F^{*}](x)\\right\\|_{\\ell_{2}}=\\ell_{2}((T_{\\hat{P}}F^{*})(x),F^{*}(x))}\\\\ {\\displaystyle=\\|\\phi((T_{\\hat{P}}F^{*})(x))-\\phi(F^{*}(x))\\|_{\\mathcal{H}}}\\\\ {\\displaystyle\\triangleq\\left\\|\\phi\\left(\\frac{1}{N}\\sum_{i=1}^{N}F^{*}(X_{i}^{x})B_{x}^{\\top}\\right)-\\phi(F^{*}(x))\\right\\|_{\\mathcal{H}}}\\\\ {\\displaystyle\\triangleq\\left\\|\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\phi\\left(F^{*}(X_{i}^{x})B_{x}^{\\top}\\right)-\\phi(F^{*}(x))\\right)\\right\\|_{\\mathcal{H}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where (a) follows from the expressions for $T_{\\hat{P}}$ described in Appendix B, and (b) follows from the affineness of the embedding $\\phi$ . Here again, we make use of a slight abuse of notation by writing $\\phi(F^{*}(x))$ for the embedding of the distribution supported on $\\{z_{1},\\ldots,z_{m}\\}$ , with CDF values $F^{*}(x)$ , and similarly for embeddings of other CDF vectors. ", "page_idx": 25}, {"type": "text", "text": "We can now apply the result above, noting that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\phi\\left(F^{*}(X_{i}^{x})B_{x}^{\\top}\\right)-\\phi(F^{*}(x))\\|_{\\mathcal{H}}=\\ell_{2}(F^{*}(X_{i}^{x})B_{x}^{\\top},F^{*}(x))\\le(1-\\gamma)^{-1/2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "almost surely, and ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}\\Big[\\|\\phi\\left(F^{*}(X_{i}^{x})B_{x}^{\\top}\\right)-\\phi(F^{*}(x))\\|_{\\mathcal{H}}^{2}\\Big]=\\mathbb{E}\\Big[\\ell_{2}^{2}(F^{*}(X_{i}^{x})B_{x}^{\\top},F^{*}(x))\\Big]=\\sigma(x)\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where we write $\\sigma$ as shorthand for the local squared-Cram\u00e9r variation at $P$ , introduced in Definition 5.5 with the notation $\\sigma_{P}$ . Hence, from Lemma E.2 and a union bound over the state space $\\mathcal{X}$ , we obtain that with probability $1-\\delta/2$ , we have for all $x\\in\\mathscr{X}$ that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\left\\|[(T_{\\hat{P}}-T_{P})F^{*}](x)\\right\\|_{\\ell_{2}}\\leq C_{\\mathrm{B}1}\\frac{\\sqrt{\\sigma(x)}}{\\sqrt{N}}+C_{\\mathrm{B}2}\\frac{1}{(1-\\gamma)^{1/2}N}\\,,\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{C_{\\mathrm{B1}}=\\sqrt{2\\log(4|\\mathcal{X}|/\\delta)}\\,,\\quad\\mathrm{and}\\;C_{\\mathrm{B2}}=2\\log(4|\\mathcal{X}|/\\delta)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "E.5 From population to empirical squared-Cram\u00e9r variation ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Next, we show that the population local squared-Cram\u00e9r variation in Equation (24) can be replaced with the corresponding empirical quantity; that is, the local-squared Cram\u00e9r variation at $\\bar{\\boldsymbol{P}},\\,\\sigma_{\\hat{P}}$ , incurring some additional terms in the bound. We start by calculating as follows: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma(x)=\\mathbb{E}\\bigg[\\|(\\hat{T}_{P}F^{*})(x)-(T_{P}F^{*})(x)\\|_{\\ell_{2}}^{2}\\bigg]}\\\\ &{\\quad\\quad=\\mathbb{E}\\bigg[\\|F^{*}(X^{\\prime})B_{x}^{\\top}\\|_{\\ell_{2}}^{2}\\bigg]-\\|P_{x}F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}}\\\\ &{\\quad\\quad=P_{x}\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}-\\|P_{x}F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where above we use the notation $\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}\\in\\mathbb{R}^{\\chi}$ for the vector indexed by state, so that the element corresponding to state $y\\in\\mathcal{X}$ is $\\|\\boldsymbol{F}^{*}(\\boldsymbol{y})\\boldsymbol{B}_{x}^{\\top}\\|_{\\ell_{2}}^{2}$ . To relate this quantity to ${\\hat{\\sigma}}(x)$ , we add and subtract a term, motivated by the derivation applied to standard return variance by Azar et al. (2013, Lemma 5), and rearrange as follows: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad_{Q}(x)}\\\\ &{=P_{x}[|F^{*}B_{x}^{T}|]_{2}^{2}-\\|P_{x}F^{*}B_{x}^{T}\\|_{2}^{2}}\\\\ &{=P_{x}[\\|F^{*}B_{x}^{T}\\|_{2}^{2}-\\|P_{x}F^{*}B_{x}^{T}\\|_{2}^{2}]}\\\\ &{\\qquad\\qquad+\\left(\\widehat{P}_{y}\\|^{4}F^{2}B_{x}^{T}\\|_{2}^{2}-\\|\\widehat{P}_{y}F^{*}B_{x}^{T}\\|_{2}^{2}\\right)}\\\\ &{\\qquad\\qquad+\\left(\\widehat{P}_{y}\\|^{4}F^{2}B_{y}^{T}\\|_{2}^{2}-\\|\\widehat{P}_{y}F^{*}B_{x}^{T}\\|_{2}^{2}\\right)}\\\\ &{\\qquad\\qquad+\\left(\\widehat{P}_{x}-\\widehat{P}_{y}\\|_{2}^{4}\\right)\\|F^{2}B_{y}^{T}\\|_{2}^{2}+\\Big(\\widehat{\\left(P_{x}F^{*}B_{x}^{T}\\right)}\\|_{2}-\\left\\|P_{x}F^{*}B_{y}^{T}\\right\\|_{2}^{2}\\Big)}\\\\ &{\\qquad\\qquad+\\mathbb{E}\\Big[\\big(\\widehat{\\left(T_{f}F^{*}\\right)}\\big(\\sigma_{y}^{2}-(T_{f}F^{*})^{*}(\\sigma)\\big)\\big|_{2}^{2}\\Big)\\Big]}\\\\ &{\\qquad\\qquad=(P_{x}-\\widehat{P}_{y})\\|F^{*}B_{x}^{T}\\|_{2}^{2}+(\\widehat{P}_{y}F^{*}B_{x}^{T}-P_{x}F^{*}B_{y}^{T},\\widehat{P}_{y}F^{*}B_{x}^{T}+P_{y}F^{*}B_{x}^{T})_{\\theta}}\\\\ &{\\qquad\\qquad\\qquad+\\mathbb{E}\\Big[\\big(\\widehat{\\left(T_{f}F^{*}\\right)}\\big(\\sigma_{y}^{2}-(T_{f}F^{*})^{*}(\\sigma)\\big|_{2}^{2}\\Big)\\Big]\\Big]}\\\\ &{=(P_{x}-\\widehat{P}_{y})\\|F^{*}B_{x}^{T}\\|_{2}^{2}+(\\widehat{P}_{x}F^{* \n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\langle\\ ,\\ \\rangle_{\\ell_{2}}$ is the inner product on $\\mathbb{R}^{m}$ corresponding to $\\Vert\\cdot\\Vert_{\\ell_{2}}$ , defined by ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\langle F,F^{\\prime}\\rangle_{\\ell_{2}}=\\frac{1}{m(1-\\gamma)}\\sum_{i=1}^{m}F_{i}F_{i}^{\\prime}\\,.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Focusing on the final term on the right-hand side of Equation (25), we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\|(\\widehat{T}_{j}F^{*})(x)-(T_{f}F^{*})(x)\\|_{2}^{2}\\;\\middle|\\;\\widehat{P}\\right]}\\\\ &{=\\mathbb{E}\\left[\\|(\\widehat{T}_{j}F^{*})(x)-(\\widehat{T}_{j}F^{*})(x)+(\\widehat{T}_{f}\\widehat{P})(x)-(T_{f}F^{*})(x)+(T_{f}\\widehat{P})(x)-(T_{f}\\widehat{P})(x)\\|_{2}^{2}\\;\\middle|\\;\\widehat{P}\\right]}\\\\ &{=\\mathbb{E}\\left[\\|(\\widehat{T}_{j}F^{*}-\\widehat{T}_{j}\\widehat{P})(x)-(T_{f}F^{*}-T_{f}F^{*})(x)+(\\widehat{T}_{f}\\widehat{P})(x)-(T_{f}\\widehat{P})(x)\\|_{2}^{2}\\;\\middle|\\;\\widehat{P}\\right]}\\\\ &{=\\mathbb{E}\\left[\\|(\\widehat{T}_{j}F^{*}-\\widehat{T}_{j}\\widehat{P})(x)-(T_{f}F^{*}-T_{f}\\widehat{P})(x)\\|_{2}^{2}\\right.}\\\\ &{\\qquad\\qquad+2(\\widehat{T}_{j}F^{*}-\\widehat{T}_{j}\\widehat{P})(x)-(T_{f}F^{*}-T_{f}\\widehat{P})(x),}\\\\ &{\\qquad\\qquad\\qquad\\left.+\\|(\\widehat{T}_{j}\\widehat{P})(x)-(T_{f}\\widehat{P})(x)\\|_{2}^{2}\\;\\middle|\\;\\widehat{P}\\right]}\\\\ &{\\stackrel{(a)}{\\cong}\\left(\\mathbb{E}\\|(\\widehat{T}_{j}F^{*}-\\widehat{T}_{j}\\widehat{P})(x)-(T_{f}F^{*}-T_{f}\\widehat{P})(x)\\|_{2}^{2}\\;\\middle|\\;\\widehat{P}\\right]^{1/2}}\\\\ &{\\qquad\\qquad+\\mathbb{E}\\left[\\|(\\widehat{T}_{j}\\widehat{P})(x)-(T_{f}\\widehat{P})(x)\\|_{2}^{2}\\;\\middle|\\;\\widehat{P}\\right]^{1/2}}\\\\ &{=\\left(\\mathbb{E}\\|(\\widehat{T}_{j}F^{*}-\\widehat{T}_{j}\\widehat{P})(x)-(T_{f}F^{*}-T_{f}\\widehat{P})(x)\\|_{2}^{2}\\;\\middle|\\;\\widehat{P}\\right\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where (a) follows from the Cauchy-Schwarz inequality, and we write $\\hat{\\sigma}$ as a shorthand for $\\sigma_{\\hat{P}}$ . Finally, we note that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\|(\\hat{T}_{\\hat{P}}F^{*}-\\hat{T}_{\\hat{P}}\\hat{F})(x)-(T_{\\hat{P}}F^{*}-T_{\\hat{P}}\\hat{F})(x)\\|_{\\ell_{2}}^{2}\\mid\\hat{P}]\\leq\\mathbb{E}[\\|(\\hat{T}_{\\hat{P}}F^{*}-\\hat{T}_{\\hat{P}}\\hat{F})(x)\\|_{\\ell_{2}}^{2}\\mid\\hat{P}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\overset{(a)}{\\leq}\\gamma\\mathbb{E}_{X^{\\prime}\\sim\\hat{P}_{x}}[\\|F^{*}(X^{\\prime})-\\hat{F}(X^{\\prime})\\|_{\\ell_{2}}^{2}\\mid\\hat{P}]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\gamma\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}^{2}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "with (a) following from contractivity of $B_{x}$ in $\\Vert\\cdot\\Vert_{\\ell_{2}}$ , as established in Proposition B.2. Bringing these bounds together with Equation (25), we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma(x)\\leq(P_{x}-\\hat{P}_{x})\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}+\\langle(\\hat{P}_{x}-P_{x})F^{*}B_{x}^{\\top},\\hat{P}_{x}F^{*}B_{x}^{\\top}+P_{x}F^{*}B_{x}^{\\top}\\rangle_{\\ell_{2}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\left(\\gamma\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}+\\sqrt{\\hat{\\sigma}(x)}\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We now apply concentration bounds to each of the first two terms on the right-hand side of Equation (26). ", "page_idx": 27}, {"type": "text", "text": "Lemma E.3. With probability at least $1-\\delta/2$ , we have for all $x\\in\\mathscr{X}$ , ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left|P_{x}\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}-\\hat{P}_{x}\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}\\right|\\leq C_{H}\\frac{1}{(1-\\gamma)\\sqrt{N}}\\,,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where ", "page_idx": 27}, {"type": "equation", "text": "$$\nC_{\\mathrm{H}}=\\sqrt{\\frac{\\log(4|\\mathcal{X}|/\\delta)}{2}}\\,.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Proof. The expression $P_{x}\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}-\\hat{P}_{x}\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}$ is equal to the negative of the average of $N$ i.i.d. copies of the random variable $\\|F^{*}(X^{\\prime})B_{x}^{\\top}\\|_{\\ell_{2}}^{2}$ , where $X^{\\prime}\\sim P_{x}$ , minus its expectation. Since $\\|F^{*}(X^{\\prime})B_{x}^{\\top}\\|_{\\ell_{2}}^{2}$ is bounded in $[0,(1-\\gamma)^{-1}]$ , we apply Hoeffding\u2019s inequality (for a given $x\\in\\mathscr{X}$ ) to obtain ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left|P_{x}\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}-\\hat{P}_{x}\\|F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}^{2}\\right|\\leq\\frac{1}{(1-\\gamma)\\sqrt{N}}\\sqrt{\\frac{\\log(4|\\mathcal{X}|/\\delta)}{2}}\\,,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "with probability at least $1\\!-\\!\\delta/(2|\\mathcal{X}|)$ . Taking a union bound over $x\\in\\mathscr{X}$ then yields the statement. ", "page_idx": 27}, {"type": "text", "text": "For the second term, we may re-use the Bernstein concentration bound derived above to deduce the following. ", "page_idx": 28}, {"type": "text", "text": "Lemma E.4. Suppose Equation (24) holds. Then we have, for all $x\\in\\mathscr{X}$ , ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left|\\langle(\\hat{P}_{x}-P_{x})F^{*}B_{x}^{\\top},(\\hat{P}_{x}+P_{x})F^{*}B_{x}^{\\top}\\rangle_{\\ell_{2}}\\right|\\leq2C_{\\mathrm{B}1}\\frac{1}{(1-\\gamma)\\sqrt{N}}+2C_{\\mathrm{B}2}\\frac{1}{(1-\\gamma)N}\\,.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. First, by the Cauchy-Schwarz inequality, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Big|\\langle(\\hat{P}_{x}-P_{x})F^{*}B_{x}^{\\top},(\\hat{P}_{x}+P_{x})F^{*}B_{x}^{\\top}\\rangle_{\\ell_{2}}\\Big|\\leq\\|(\\hat{P}_{x}-P_{x})F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}\\|(\\hat{P}_{x}+P_{x})F^{*}B_{x}^{\\top}\\|_{\\ell_{2}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The first of the two factors in the product on the right-hand side is precisely the term bounded on the left-hand side of Equation (24). On the right-hand side, the vector inside the $\\ell_{2}$ -norm has components in $[0,2]$ , so the norm can be straightforwardly bounded by ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left[\\frac{1}{m(1-\\gamma)}\\sum_{i=1}^{m}2^{2}\\right]^{1/2}=\\frac{2}{(1-\\gamma)^{1/2}}\\,.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Combining the inequalities for these two factors, and using the trivial bound $\\sqrt{\\sigma}(x)\\leq(1-\\gamma)^{-1/2}$ , we obtain the stated result. \u53e3 ", "page_idx": 28}, {"type": "text", "text": "Combining all these bounds together in Equation (26), and taking a union bound, we conclude that with probability at least $1-\\delta/2$ , for all $x\\in\\mathscr{X}$ we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sigma(x)\\leq(2C_{\\mathrm{B}1}+C_{\\mathrm{H}})\\frac{1}{(1-\\gamma)\\sqrt{N}}+2C_{\\mathrm{B}2}\\frac{1}{(1-\\gamma)N}+\\left(\\gamma\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}+\\sqrt{\\hat{\\sigma}(x)}\\right)^{2}\\,,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We now take square-roots of both sides, using the inequality ${\\sqrt{a+b}}\\leq{\\sqrt{a}}+{\\sqrt{b}}$ on the right-hand side to obtain ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sqrt{\\sigma(x)}\\leq\\sqrt{\\hat{\\sigma}(x)}+\\gamma\\Vert F^{*}-\\hat{F}\\Vert_{\\ell_{2},\\infty}+\\sqrt{2C_{\\mathrm{B}1}+C_{\\mathrm{H}}}\\frac{1}{(1-\\gamma)^{1/2}N^{1/4}}+\\sqrt{2C_{\\mathrm{B}2}}\\frac{1}{(1-\\gamma)^{1/2}N^{1/2}}\\,.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Substituting this into Equation (24) and taking a union bound then yields that with probability at least $1-\\delta$ , we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\left\\|[(T_{\\hat{P}}-T_{P})F^{*}](x)\\right\\|_{\\ell_{2}}\\le C_{\\mathrm{B}1}\\frac{1}{\\sqrt{N}}\\sqrt{\\hat{\\sigma}(x)}+C_{\\mathrm{B}1}\\frac{1}{\\sqrt{N}}\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}+C^{\\prime}\\frac{1}{(1-\\gamma)^{1/2}N^{3/4}}\\,,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where ", "page_idx": 28}, {"type": "equation", "text": "$$\nC^{\\prime}=C_{\\mathrm{B1}}(\\sqrt{2C_{\\mathrm{B1}}+C_{\\mathrm{H}}}+\\sqrt{2C_{\\mathrm{B2}}})+C_{\\mathrm{B2}}\\,,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "so that our concentration inequality is expressed in terms of the empirical local squared-Cram\u00e9r variation $\\hat{\\sigma}$ . ", "page_idx": 28}, {"type": "text", "text": "E.6 Converting local bounds to global bounds ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "To convert the local concentration results obtained above into a bound on $\\ell_{2}(\\hat{F}(x),F^{*}(x))$ , we first prove the following lemma. ", "page_idx": 28}, {"type": "text", "text": "Lemma E.5. For $U\\in\\{F\\in\\mathbb{R}^{\\mathcal{X}\\times m}:F_{m}(x)=0$ for all $x\\in\\mathcal{X}\\}$ , and any $k\\geq1$ , we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\|(T_{\\hat{P}}^{k}U)(x)\\|_{\\ell_{2}}\\le\\gamma^{k/2}\\sum_{x^{\\prime}\\in\\mathcal{X}}\\mathbb{P}_{\\hat{P}}(X_{k}=x^{\\prime}\\mid X_{0}=x)\\|U(x^{\\prime})\\|_{\\ell_{2}}\\,,\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $\\mathbb{P}_{\\hat{P}}$ denotes state transition probabilities for the MRP with transition matrix $\\hat{P}$ . ", "page_idx": 28}, {"type": "text", "text": "Proof. We proceed by induction. For the base case $k=1$ , we have, using the operator notation introduced in Appendix B, ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\|(T_{\\hat{P}}U)(x)\\|_{\\ell_{2}}=\\bigg\\|\\sum_{y\\in\\mathcal{X}}\\hat{P}(y|x)\\sum_{j=1}^{m-1}B_{x}U(y)\\bigg\\|_{\\ell_{2}}}\\\\ {\\displaystyle\\overset{(a)}{\\leq}\\sum_{y\\in\\mathcal{X}}\\hat{P}(y|x)\\bigg\\|B_{x}U(y)\\bigg\\|_{\\ell_{2}}}\\\\ {\\displaystyle\\overset{(b)}{\\leq}\\sum_{y\\in\\mathcal{X}}\\hat{P}(y|x)\\gamma^{1/2}\\bigg\\|U(y)\\bigg\\|_{\\ell_{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "as required. where (a) follows from the triangle inequality, and (b) follows from contractivity of $B_{x}$ in $\\Vert\\cdot\\Vert_{\\ell_{2}}$ , as established by Proposition B.2. ", "page_idx": 29}, {"type": "text", "text": "For the inductive step, we suppose that the result holds for some $l\\in\\mathbb N$ . Now, letting $k=l+1$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\|(T_{\\rho}^{(+1)}U)(x)\\|_{\\mathcal{O}}=\\left\\|(T_{\\rho}T_{\\rho}^{(+1)}U)(x)\\right\\|_{\\mathcal{O}}}&{}\\\\ &{\\qquad=\\left\\|\\displaystyle\\sum_{y\\in\\mathcal{X}}\\hat{P}(y)\\Delta_{x}(T_{\\rho}^{(+1)}\\mathcal{V})(y)\\right\\|_{\\mathcal{O}}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\sum_{y\\in\\mathcal{X}}\\hat{P}(y)\\Big\\|\\Big\\|\\Delta_{x}(T_{\\rho}^{(+1)}\\mathcal{V})(y)\\Big\\|_{\\mathcal{O}}}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\sum_{y\\in\\mathcal{X}}\\hat{P}(y)\\gamma^{(+1)}\\left\\|(T_{\\rho}^{(+1)}U)\\right\\|_{\\mathcal{O}}\\Big]}\\\\ &{\\qquad\\leq\\displaystyle\\sum_{y\\in\\mathcal{X}}\\hat{P}(y)\\gamma^{(+1)}\\left\\|(T_{\\rho}^{(+1)}\\mathcal{V})(y)\\right\\|_{\\mathcal{O}}}\\\\ &{\\qquad\\overset{(+)}{\\displaystyle\\sum_{y\\in\\mathcal{X}}}\\hat{P}(y)\\gamma^{(+1)/2}\\sum_{x\\in\\mathcal{X}}^{y\\prime}\\sum_{y\\in\\mathcal{X}}\\mathbb{P}_{\\rho}(X_{t}=x^{\\prime}\\mid X_{0}=y)\\|U(x^{\\prime})\\|_{\\mathcal{O}}}\\\\ &{\\qquad=\\displaystyle\\gamma^{(i+1)/2}\\sum_{x\\in\\mathcal{X}}\\left[\\sum_{y\\in\\mathcal{X}}\\mathbb{P}_{\\rho}(X_{t}=x^{\\prime}\\mid X_{0}=y^{\\prime}|\\mathcal{O}_{t})\\right]\\|U(x^{\\prime})\\|_{\\mathcal{O}}}\\\\ &{\\qquad=\\displaystyle\\gamma^{(i+1)/2}\\sum_{x\\in\\mathcal{X}}\\mathbb{P}_{\\rho}(X_{t+1}=x^{\\prime}\\mid X_{0}=x)\\|U(x^{\\prime})\\|_{\\mathcal{O}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "We therefore have, with probability at least $1-\\delta$ : ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ell_{2}(\\hat{F}(x),F^{*}(x))}\\\\ &{=\\|\\hat{F}(x)-F^{*}(x)\\|_{\\ell_{2}}}\\\\ &{\\overset{(a)}{=}\\bigg\\|\\Big[\\displaystyle\\sum_{k\\geq0}\\overline{{f_{k}}}(T_{f_{k}}-T_{P})F^{*}\\Big](x)\\bigg\\|_{\\ell_{2}}}\\\\ &{\\overset{(b)}{\\leq}\\displaystyle\\sum_{k\\geq0}\\left\\|\\big[\\underline{{T}}_{\\hat{P}}^{k}(T_{\\hat{P}}-T_{P})F^{*}\\Big](x)\\right\\|_{\\ell_{2}}}\\\\ &{\\overset{(c)}{\\leq}\\displaystyle\\sum_{k\\geq0}\\sum_{\\ell\\leq\\ell^{\\prime}\\leq k}\\mathbb{P}_{\\hat{P}}(X_{k}=x^{\\prime}\\mid X_{0}=x)\\gamma^{k/2}\\Bigg\\|\\Big[(T_{\\hat{P}}-T_{P})F^{*}\\Big](x^{\\prime})\\bigg\\|_{\\ell_{2}}}\\\\ &{\\overset{(d)}{\\leq}\\displaystyle\\sum_{k\\geq0}\\sum_{\\ell\\leq\\ell^{\\prime}\\leq k}\\mathbb{P}_{\\hat{P}}(X_{k}=x^{\\prime}\\mid X_{0}=x)\\gamma^{k/2}\\Bigg[C_{\\mathrm{B}}\\displaystyle\\frac{1}{\\sqrt{N}}\\sqrt{\\hat{\\sigma}(x^{\\prime})}+C_{\\mathrm{B}}\\displaystyle\\frac{1}{\\sqrt{N}}\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Here, (a) follows from Equation (22), (b) follows from the triangle inequality, and (c) follows from Lemma E.5. The step (d) is the one step in the derivation that does not hold with probability 1, but rather with probability $1-\\delta$ , and follows from the Bernstein-style bounds in Equation (27), (e) follows from algebraic manipulation using the identity $\\begin{array}{r}{\\sum_{k>0}(\\gamma^{1/2}\\hat{P})^{k}=(I-\\sqrt{\\gamma}\\hat{P})^{-1}}\\end{array}$ , as $\\hat{P}$ is a stochastic matrix, and bounding the elements of $(I-\\sqrt{\\gamma}\\bar{\\hat{P}})^{-1}\\sqrt{\\hat{\\sigma}}$ by the $L^{\\infty}$ norm of the vector, and (f) follows from the inequality $(1-\\sqrt{\\gamma})^{-1}\\leq2(1-\\gamma)^{-1}$ for $\\gamma\\in[0,1)$ . ", "page_idx": 30}, {"type": "text", "text": "Focusing now on the coefficient $\\|(I\\!-\\!\\sqrt{\\gamma}\\hat{P})^{-1}\\sqrt{\\hat{\\sigma}}\\|_{\\infty}$ , we note that similar to the analysis of Agarwal et al. (2020, Lemma 4) in the mean-return case, we can write ", "page_idx": 30}, {"type": "equation", "text": "$$\n(I-\\sqrt{\\gamma}\\hat{P})^{-1}\\sqrt{\\hat{\\sigma}}=(1-\\sqrt{\\gamma})^{-1}(1-\\sqrt{\\gamma})(I-\\sqrt{\\gamma}\\hat{P})^{-1}\\sqrt{\\hat{\\sigma}}\\,,\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "so that each row of ", "page_idx": 30}, {"type": "equation", "text": "$$\n(1-\\sqrt{\\gamma})(I-\\sqrt{\\gamma}\\hat{P})^{-1}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "forms a probability distribution, and so we may apply Jensen\u2019s inequality with the map $z\\mapsto{\\sqrt{z}}$ , to obtain ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r}{I-\\sqrt{\\gamma}\\hat{P})^{-1}\\sqrt{\\hat{\\sigma}}\\le(1-\\sqrt{\\gamma})^{-1}\\sqrt{(1-\\sqrt{\\gamma})(I-\\sqrt{\\gamma}\\hat{P})^{-1}\\hat{\\sigma}}=(1-\\sqrt{\\gamma})^{-1/2}\\sqrt{(I-\\sqrt{\\gamma}\\hat{P})^{-1}\\hat{\\sigma}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where the inequality above holds coordinate-wise. We thus obtain the inequality ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\frac{\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}\\leq}{(1-\\gamma)^{1/2}\\sqrt{N}}\\sqrt{\\|(I-\\sqrt{\\gamma}\\hat{P})^{-1}\\sqrt{\\hat{\\sigma}}\\|_{\\infty}}+\\frac{2C_{\\mathrm{B1}}}{(1-\\gamma)\\sqrt{N}}\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}+\\frac{2C^{\\prime}}{(1-\\gamma)^{3/2}N^{3/4}}\\,.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Note that the term $\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}$ appears on both sides of the inequality above. By taking $N\\geq$ $16C_{\\mathrm{B1}}^{2}(1-\\gamma)^{-2}$ , we ensure that the coefficient in front of $\\|F^{*}-\\hat{F}\\|_{\\ell_{2},\\infty}$ on the right-hand side is made smaller than $1/2$ , similar to the approach taken in the proof of instance-dependent sample complexity bounds for mean-return estimation by Pananjady & Wainwright (2020, Theorem 1(a)). Under this assumption, rearrangement yields ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\|F^{*}-{\\hat{F}}\\|_{\\ell_{2},\\infty}\\leq{\\frac{4C_{\\mathrm{B1}}}{(1-\\gamma)^{1/2}{\\sqrt{N}}}}{\\sqrt{\\|(I-{\\sqrt{\\gamma}}{\\hat{P}})^{-1}{\\sqrt{\\hat{\\sigma}}}\\|_{\\infty}}}+{\\frac{4C^{\\prime}}{(1-\\gamma)^{3/2}N^{3/4}}}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "as described in Section 5. ", "page_idx": 30}, {"type": "text", "text": "E.7 The stochastic categorical CDF Bellman equation ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We now aim to use our developments regarding the stochastic categorical CDF Bellman equation (see Section 5.2) to bound the quantity appearing within \u221athe square root. To be able to use the bound obtained in Corollary 5.12, we first replace the factor $\\sqrt{\\gamma}$ inside the square-root on the right-hand side of Equation (30) with $\\gamma$ , using the bound $(I-\\sqrt{\\gamma}P)^{-1}\\leq2(I-\\gamma P)^{-1}$ , shown by Agarwal et al. (2020, Lemma 4). This, together with Corollary 5.12, yields ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sqrt{(I-\\sqrt{\\gamma}\\hat{P})^{-1}\\hat{\\sigma}}\\leq\\sqrt{2}\\sqrt{(I-\\gamma\\hat{P})^{-1}\\hat{\\sigma}}\\leq\\sqrt{2}\\sqrt{\\frac{2}{1-\\gamma}}{\\bf1}=\\frac{2}{(1-\\gamma)^{1/2}}{\\bf1}\\,.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Thus, returning to Equation (31) and substituting this bound in, we obtain (again, with probability at least $1-\\delta$ , for all $x\\in\\mathscr{X}$ ): ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\ell_{2}(\\hat{F}(x),F^{*}(x))\\le\\frac{8C_{\\mathrm{B1}}}{(1-\\gamma)\\sqrt{N}}+\\frac{4C^{\\prime}}{(1-\\gamma)^{3/2}N^{3/4}}\\,.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "E.8 Final steps of the proof of Theorem 5.3 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We now let $N\\geq c_{0}\\varepsilon^{-2}(1-\\gamma)^{-2}$ , with $c_{0}$ any positive number satisfying ", "page_idx": 31}, {"type": "equation", "text": "$$\nc_{0}\\geq2^{10}C_{\\mathrm{B1}}^{2}\\;\\mathrm{and}\\;c_{0}>16^{4/3}(C^{\\prime})^{4/3}\\,.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Note that the first of these conditions implies the earlier assumption $N\\geq16C_{\\mathrm{B}1}^{2}(1-\\gamma)^{-2}$ made in order to arrive at Equation (31). We then conclude from Equation (32) that (with probability at least $1-\\delta$ , for all $x\\in\\mathscr{X}$ ): ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ell_{2}(\\hat{F}(x),F^{*}(x))\\leq\\frac{8C_{\\mathrm{B}1}}{\\sqrt{c_{0}}}\\varepsilon+\\frac{4C^{\\prime}}{c_{0}^{3/4}}\\varepsilon^{3/2}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{8C_{\\mathrm{B}1}}{\\sqrt{c_{0}}}\\varepsilon+\\frac{4C^{\\prime}}{c_{0}^{3/4}}\\varepsilon}\\\\ &{\\qquad\\qquad\\qquad\\leq\\varepsilon/2\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "with the final inequality following due to the assumption on $c_{\\mathrm{0}}$ making both coefficients of $\\varepsilon$ bounded by $1/4$ . This concludes the proof of Theorem 5.3. ", "page_idx": 31}, {"type": "text", "text": "To derive a concrete sample complexity bound, including logarithmic terms, we may bound the terms in Equation (33) as follows; we emphasise that we do not aim to be as tight as possible in the following analysis, but merely to provide an concrete, valid bound on $c_{\\mathrm{0}}$ . First, we have that the ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{2^{10}C_{\\mathrm{B}1}^{2}=2^{10}(\\sqrt{2\\log(4|\\mathcal{X}|/\\delta)})^{2}}}\\\\ {{=2^{11}\\log(4|\\mathcal{X}|/\\delta)\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Next, we have (introducing the shorthand $L=\\log(4|\\mathcal{X}|/\\delta)$ ): ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{16^{4/3}(C^{\\prime})^{4/3}\\leq2^{6}\\biggl(C_{81}(\\sqrt{2C_{81}+C_{\\mathrm{H}}}+\\sqrt{2C_{82}})+C_{82}\\biggr)^{4/3}}\\\\ &{\\qquad\\qquad\\qquad=2^{6}\\bigl(\\sqrt{2L}\\bigl(\\sqrt{2\\sqrt{2L}+\\sqrt{L/2}}+\\sqrt{4L}\\bigr)+2L\\bigr)^{4/3}}\\\\ &{\\qquad\\qquad\\leq2^{6}\\bigl(L\\sqrt{2}\\bigl(\\sqrt{2\\sqrt{2}+\\sqrt{1/2}}+2\\bigr)+2L\\bigr)^{4/3}}\\\\ &{\\qquad\\qquad=2^{6}L^{4/3}\\bigl(\\sqrt{2\\sqrt{2}+\\sqrt{1/2}}+2\\bigr)+2\\bigr)^{4/3}}\\\\ &{\\qquad\\qquad\\leq2^{6}L^{4/3}2^{4}}\\\\ &{\\qquad\\qquad=2^{10}L^{4/3}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We therefore conclude, for example, that taking $c_{0}\\geq2^{11}\\log(4|X|/\\delta)^{4/3}$ is sufficient. ", "page_idx": 31}, {"type": "text", "text": "F Extensions ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Below, we describe several straightforward extensions of Theorem 5.1, that allow us to give guarantees for related algorithms and problems concerning sample-efficient distributional reinforcement learning. ", "page_idx": 31}, {"type": "text", "text": "F.1 Categorical dynamic programming ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "The core theoretical result, Theorem 5.1, can be used to provide guarantees for the iterative CDP algorithm. Let us write $F_{k}\\in\\mathbb{R}^{X\\times[m]}$ for the result of applying the empirical CDP operator $\\Pi_{m}\\tau$ a total $k$ times to an initial estimate $F_{0}\\in\\mathbb{R}^{\\mathcal{X}\\times[m]}$ . By the existing categorical theory described in Proposition 2.2 (Rowland et al., 2018), we can bound the distance between the CDP estimate $F_{k}$ and the DCFP solution $\\hat{F}$ as ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\overline{{\\ell}}_{2}(F_{k},\\hat{F})\\leq\\gamma^{k/2}\\overline{{\\ell}}_{2}(F_{0},\\hat{F})\\leq\\frac{\\gamma^{k/2}}{(1-\\gamma)^{1/2}}\\,.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Thus, taking $\\begin{array}{r}{k\\ge\\frac{2\\log(1/\\varepsilon)+3\\log(1/(1-\\gamma))}{\\log(1/\\gamma)}}\\end{array}$ , this error is smaller than $\\varepsilon(1-\\gamma)^{1/2}$ . Thus, by Lemma 5.2, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\overline{{w}}_{1}(F_{k},\\hat{F})\\leq\\varepsilon\\,.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "By the triangle inequality, we therefore have that if $\\overline{{w}}_{1}(\\hat{F},\\eta^{*})\\leq\\varepsilon$ , then $\\overline{{w}}_{1}(F_{k},\\eta^{*})\\leq2\\varepsilon$ under this assumption on $k$ , and we therefore conclude that under the assumptions of Theorem 5.1, the CDP algorithm run with $\\begin{array}{r}{k\\ge\\frac{2\\log(1/\\varepsilon)+3\\log(1/(1-\\gamma))}{\\log(1/\\gamma)}}\\end{array}$ also has sample complexity $\\widetilde\\Omega(\\varepsilon^{-2}(1-\\gamma)^{-3})$ . ", "page_idx": 32}, {"type": "text", "text": "F.2 Policy optimisation ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Theorem 5.1 can also be straightforwardly adapted to obtain sample complexity results for the policy optimisation problem in Markov decision processes, in which the optimal policy must also be learnt from data, prior to estimating its return distribution. We describe one way in which this can be made concrete. Suppose we have a finite-state, finite-action MDP with reward a function of state, with a unique optimal policy $\\pi^{*}$ with an action gap $\\varepsilon\\,\\in\\,[0,(1-\\gamma)^{1/2})$ , meaning that at any state $x$ , if $a,b\\;\\in\\;A$ are the optimal action and a sub-optimal action respectively, then $Q^{\\pi^{*}}(x,b)<Q^{\\pi^{*}}(x,a)-\\varepsilon$ . Then, for example, Theorem 1 of Agarwal et al. (2020) yields that for $\\delta\\in(0,1)$ , with $N=\\widetilde O(\\tilde{\\varepsilon}^{-2}(1-\\gamma)^{-3}\\log(1/\\delta))$ sampled transitions per state-action pair we can correctly identify the o ptimal policy $\\pi^{*}$ with probability at least $1-\\delta$ . We may then form the MRP corresponding to executing the policy $\\pi^{*}$ , and may resample from the transitions used in identifying the optimal policy to compute approximate return distributions for the optimal policy; Theorem 5.1 and a union bound then guarantee $\\varepsilon$ -accurate approximations in Wasserstein distance with high probability. ", "page_idx": 32}, {"type": "text", "text": "To understand the role of the unique optimal policy assumption in our discussion above, recall that when there are multiple optimal policies, each generally has a distinct collection of return distributions, and so there is not a single object that one should hope to approximate. This is not the case with value functions, which are necessarily identical for all optimal policies. As described in earlier work on policy optimisation with distributional RL (Bellemare et al., 2017, 2023), this lack of uniqueness of optimal return distributions also leads to interesting theoretical issues when analysing algorithms such as value iteration. However, we expect a result in which one obtains an approximation to the return distributions of some optimal policy can also be obtained, even in the non-unique-optimal-policy setting. ", "page_idx": 32}, {"type": "text", "text": "F.3 Stochastic rewards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "In our main results, we have assumed that the immediate reward is a deterministic function of state. Results in mean-return RL are also commonly given under this assumption (Azar et al., 2013), since this simplifies notation and the extension to stochastic rewards is often straightforward to obtain (Pananjady & Wainwright, 2020). In this section, we describe how to modify the argument presented in the deterministic-reward case to allow for stochastic rewards. ", "page_idx": 32}, {"type": "text", "text": "Assumptions. We now consider working instead with a reward distribution function $\\mathcal{R}:\\mathcal{X}\\rightarrow$ $\\mathcal{P}([0,\\bar{1}])$ , so that ${\\mathcal{R}}(x)$ is the distribution of immediate rewards received at state $x$ . The $N$ i.i.d. transitions obtained from state $x$ are given by $(x,R_{i}^{x},X_{i}^{x})_{i=1}^{N}$ , where as before $X_{i}^{x}\\overset{\\mathrm{i.i.d.}}{\\sim}P(\\cdot|x)$ , and independently $R_{i}^{x}\\stackrel{\\mathrm{i.i.d.}}{\\sim}\\mathcal{R}(x)$ , for $i=1,\\hdots,m$ . ", "page_idx": 32}, {"type": "text", "text": "Algorithms. The categorical operator $T_{P}$ is defined in the stochastic reward case in direct analogy with the definition presented in Section 4 in the deterministic reward case. The generalisation is that the quantities $h_{i j}^{x}$ given in Equation (6), which represent the contribution to mass allocated to $z_{i}$ at $x$ due to backing up from atom $z_{j}$ , are now defined as ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{h_{i j}^{x}=\\mathbb{E}_{R\\sim\\mathcal{R}(x)}[h_{i}(R+\\gamma z_{j})]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "for each $x\\,\\in\\,{\\mathcal{X}}$ and $i,j\\,=\\,1,\\ldots,m$ . The quantities $H_{i,\\,j}^{x}$ and $T_{P}$ are defined exactly as in the deterministic case, from this generalised definition of the $h_{i,j}^{x}$ . The model-based algorithms, based on the $N$ sampled transitions at each state described above, now also approximate the $h_{i,j}^{x}$ from the empirical reward distributions $\\begin{array}{r}{\\hat{\\mathcal{R}}(x)=N^{-1}\\sum_{i=1}^{N}\\delta_{R_{i}^{x}}}\\end{array}$ , as well as $P$ . In particular, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\hat{h}_{i,j}^{x}=\\frac{1}{N}\\sum_{i=1}^{N}h_{i}\\big(R_{i}^{x}+\\gamma z_{j}\\big)\\,,\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "from which we define the corresponding estimators $\\hat{H}_{i,j}^{x}$ of $H_{i,j}^{x}$ . We now write the empirical categorical operator as $T_{\\hat{P},\\hat{\\mathcal{R}}}$ , to emphasise the dependence on the empirical reward distributions $({\\mathcal{R}}(x):x\\in{\\mathcal{X}})$ too, which is then defined as ", "page_idx": 33}, {"type": "equation", "text": "$$\nT_{\\hat{P},\\hat{\\mathcal{R}}}(x,i;y,j)=\\hat{P}(y|x)(\\hat{H}_{i,j}^{x}-\\hat{H}_{i,j+1}^{x})\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Model-based DCFP in the stochastic reward setting then simply corresponds to solving the linear system built from $T_{\\hat{P},\\hat{\\mathcal{R}}}$ appearing in Equation (11), based on this empirical categorical operator. ", "page_idx": 33}, {"type": "text", "text": "Sample complexity. The model-based DCFP algorithm also satisfies the sample complexity bound given in Theorem 5.3 (and hence in Theorem 5.1 too) in the case of stochastic rewards. Only a few additional details are required to extend the proof in the deterministic reward case to the stochastic case, which we sketch below. As before, we write $F^{*}$ for the CDF values of the true categorical fixed point and $\\hat{F}$ for the estimated fixed point obtained by running DCFP with the operator $T_{\\hat{P},\\hat{\\mathcal{R}}}$ . We also introduce the notation $T_{\\hat{P},\\mathcal{R}}$ for the categorical operator using estimated transition probabilities $\\hat{P}$ but true reward distributions $({\\mathcal{R}}(x):x\\in{\\mathcal{X}})$ , and write $\\acute{F}$ for the corresponding categorical fixed point. ", "page_idx": 33}, {"type": "text", "text": "Proof modifications. First, when performing the initial reduction to categorical fixed-point error, we invoke the triangle inequality an additional time, to obtain ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\overline{{\\ell}}_{2}(\\eta^{*},\\hat{F})\\leq\\bar{\\ell}_{2}(\\eta^{*},F^{*})+\\bar{\\ell}_{2}(F^{*},\\hat{F})+\\bar{\\ell}_{2}(\\dot{F},\\hat{F})\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "First term. As in the proof in the deterministic case, the first term on the right-hand side is $O(\\varepsilon)$ due to the assumption on $m$ in the theorem statement; in particular, Proposition 2.2 as proven by Rowland et al. (2018) holds in the case of stochastic rewards too. ", "page_idx": 33}, {"type": "text", "text": "Second term. The second term on the right-hand side of Equation (34) is bounded by following the same argument as given in Appendices E.3\u2013E.8. The only part of the argument in these sections that specifically relies on the immediate reward being deterministic, rather than relying on the contractivity of the operator (which also holds in the stochastic-reward case (Rowland et al., 2018)), is Proposition B.3, which is used in establishing Proposition 5.11 and Corollary 5.12. We state and prove a version of Proposition B.3 that holds under the weaker assumption of stochastic rewards too. ", "page_idx": 33}, {"type": "text", "text": "Proposition F.1. In the general case of stochastic immediate rewards described above, we have that for any $F,F^{\\prime}\\in{\\mathcal{F}}$ , ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\|B_{x}F-B_{x}F^{\\prime}\\|_{\\ell_{2}}^{2}\\geq\\gamma\\|F-F^{\\prime}\\|_{\\ell_{2}}^{2}-\\frac{2}{m(1-\\gamma)^{1/2}}-\\frac{1}{m^{2}(1-\\gamma)^{2}}-4\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Proof. Following the proof of Proposition B.3, we obtain ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\|B_{x}F-B_{x}F^{\\prime}\\|_{\\ell_{2}}^{2}\\ge\\ell_{2}^{2}(R+\\gamma G,R+\\gamma G^{\\prime})-\\frac{2}{m(1-\\gamma)^{1/2}}-\\frac{1}{m^{2}(1-\\gamma)^{2}}\\,,\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $R\\sim{\\mathcal{R}}(X^{\\prime})$ , and independently, $G,G^{\\prime}$ are random variables taking values in $\\{z_{1},\\ldots,z_{m}\\}$ with CDF values given by $F,F^{\\prime}$ , respectively, and we write $\\ell_{2}^{2}(R+\\gamma G,\\bar{R^{+}}\\gamma G^{\\prime})$ as shorthand for the Cram\u00e9r distance between the two distributions of these random variables, $\\mathbb{E}_{R\\sim\\mathcal{R}(x)}[(\\mathrm{b}_{R,\\gamma})_{\\#}\\nu]$ , $\\mathbb{E}_{R\\sim\\mathcal{R}(x)}[(\\mathrm{b}_{R,\\gamma})_{\\#}\\nu^{\\prime}]$ , respectively. We then use the characterisation of the squared-Cram\u00e9r distance in Equation (23) to obtain, writing $R_{1},R_{2}\\sim\\mathcal{R}(x),G_{1},G_{2}\\sim\\nu,\\,G_{1}^{\\prime},G_{2}^{\\prime}\\sim\\nu^{\\prime}$ , all independent of one another, ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~\\ell_{2}^{2}(R+\\gamma G,R+\\gamma G^{\\prime})}\\\\ &{=\\mathbb{E}[|R_{1}+\\gamma G_{1}-(R_{2}+\\gamma G_{2}^{\\prime})|]-\\frac{1}{2}\\mathbb{E}[|R_{1}+\\gamma G_{1}-(R_{2}+\\gamma G_{2})|]}\\\\ &{~~~~~-\\frac{1}{2}\\mathbb{E}[|R_{1}+\\gamma G_{1}^{\\prime}-(R_{2}+\\gamma G_{2}^{\\prime})|]}\\\\ &{\\overset{(a)}{\\geq}\\mathbb{E}[|\\gamma G_{1}-\\gamma G_{2}^{\\prime}|-2]-\\frac{1}{2}\\mathbb{E}[|\\gamma G_{1}-\\gamma G_{2}|+2]-\\frac{1}{2}\\mathbb{E}[|\\gamma G_{1}^{\\prime}-\\gamma G_{2}^{\\prime}|+2]}\\\\ &{=\\gamma\\ell_{2}^{2}(\\nu,\\nu^{\\prime})-4=\\gamma\\|F-F^{\\prime}\\|_{\\ell_{2}}^{2}-4\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "as required, where (a) follows from boundedness of the rewards, and the triangle inequality. ", "page_idx": 34}, {"type": "text", "text": "With Proposition F.1, we obtain a weaker version of Corollary 5.12 in the stochastic reward case, yielding $\\|(I-\\gamma\\hat{P})^{-1}\\sigma_{\\hat{P}}\\|_{\\infty}\\leq6(1-\\gamma)^{-1}$ , which is sufficient to conclude the claimed bound on the second term as described in Appendices E.7 & E.8, specifically yielding that this second term is $O(\\varepsilon)$ with probability at least $1-\\delta$ . ", "page_idx": 34}, {"type": "text", "text": "Third term. Finally, the third term on the right-hand side of Equation (34) is a new term that emerges specifically in the stochastic-reward case, corresponding to errors in the fixed-point solely due to mis-estimated immediate reward distributions. First, by an analogous argument to that in Section E.3, we may write ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\dot{F}-\\hat{F}=\\sum_{k=0}^{\\infty}(T_{\\hat{P},\\hat{\\mathcal{R}}})^{k}(T_{\\hat{P},\\mathcal{R}}-T_{\\hat{P},\\hat{\\mathcal{R}}})\\dot{F}\\,.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "We have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\bigg\\|\\left[\\big(T_{\\hat{P},\\mathcal{R}}-T_{\\hat{P},\\hat{\\mathcal{R}}}\\big)\\dot{F}\\right](x)\\bigg\\|_{\\ell_{2}}\\overset{(a)}{\\leq}\\ell_{2}\\big(\\mathcal{R}(x),\\hat{\\mathcal{R}}(x)\\big)\\overset{(b)}{\\leq}\\sqrt{\\frac{\\log(2|\\mathcal{X}|/\\delta)}{2N}}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "with probability at least $1-\\delta$ . Here, (a) follows by homogeneity of the Cram\u00e9r distance (Rowland et al., 2018, Proof of Proposition 2), and (b) follows from the DKW inequality (Dvoretzky et al., 1956; Massart, 1990) and a union bound. Then, using contractivity of $T_{\\hat{P},\\hat{\\mathcal{R}}}$ and the triangle inequality, we obtain ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\|\\dot{F}-\\hat{F}\\|_{\\ell_{2},\\infty}\\leq\\sum_{k=0}^{\\infty}\\gamma^{k/2}\\sqrt{\\frac{\\log(2|\\mathcal{X}|/\\delta)}{2N}}=\\widetilde{\\mathcal{O}}((1-\\gamma)^{-1}N^{-1/2})\\,,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "with probability at least $1-\\delta$ , which is $O(\\varepsilon)$ under the choice of $N$ in the theorem statement. In summary, taking a union over the events corresponding to all concentration bounds used, we obtain that $\\bar{\\ell}_{2}(\\eta^{*},\\hat{F})$ is $O(\\varepsilon)$ with probability at least $1-2\\delta$ , as required. ", "page_idx": 34}, {"type": "text", "text": "G Further experimental results and details ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "In this section, we give full details for the experiment presented in the main paper, and additionally present extended results on several additional environments. All experiments were run using the Python 3 language (Van Rossum & Drake, 2009), and made use of NumPy (Harris et al., 2020), SciPy (Virtanen et al., 2020), Matplotlib (Hunter, 2007), and Seaborn (Waskom, 2021) libraries. As all experiments are tabular, each run uses a single CPU, and timings are reported within the experimental results. ", "page_idx": 34}, {"type": "text", "text": "G.1 Environments ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We report results on four MRPs defined as follows: ", "page_idx": 34}, {"type": "text", "text": "1. Chain: 10 states arranged in a chain $x_{1}\\,\\leftrightarrow\\,x_{2}\\,\\leftrightarrow\\,\\cdots\\,\\leftrightarrow\\,x_{10}$ . Each state transitions to its neighbours with equal probability. States 1 and 10 are terminal. Only state 10 has a reward of 1, and all other states have reward 0. ", "page_idx": 34}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/7fff7dfaa67ed71b76558e4932087f40287e8fcb81c791971c6cbc137c87f7f4.jpg", "img_caption": ["Figure 4: Monte Carlo approximations of return distributions in each of the four environments tested. "], "img_footnote": [], "page_idx": 35}, {"type": "text", "text": "2. Low random: There are five states, and the transition probabilities from each state to all five states are drawn independently from a Dirichlet distribution with concentration parameter $(0.01,\\ldots,0.01)$ . The rewards for each state is drawn i.i.d. from the uniform distribution over [0, 1]. We draw these transition probability and rewards using the same random seed to yield the same MRP for all experiments. ", "page_idx": 35}, {"type": "text", "text": "3. High random: Same as the low random environment, but with transitions drawn from a Dirichlet distribution with concentration parameter $(10,\\ldots,10)$ . ", "page_idx": 35}, {"type": "text", "text": "4. Two-state: A 2-state MRP modified from Example 6.5 of Rowland et al. (2024). The transition matrix is ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\binom{0.6}{0.8}_{0.2}^{0.4}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the $(i,j)$ entry is the probability of transitioning from state $i$ to state $j$ . State 1 has reward 0, and state 2 has reward 1. ", "page_idx": 35}, {"type": "text", "text": "We chose this set of environments to include classic tabular settings such as the chain, two environments with very different levels of stochasticity (low and high random), as well as the two-state example from Rowland et al. (2024), which illustrates the nature of fixed-point approximation error incurred by QDP in environments with tight bootstrapping loops. We vary the discount factor $\\gamma\\in\\{0.8,0.9,0.95,0.99\\}$ . For reference, we plot Monte Carlo approximations of return distributions for each environment in Figure 4, with $\\gamma=0.9$ . The return samples are computed using the first-visit Monte Carlo algorithm. For each initial state, we run at least $T$ transitions such that the maximum error after $T$ transitions $\\gamma^{T}r_{\\mathrm{max}}/(1-\\gamma)<\\varepsilon$ , where $r_{\\operatorname*{max}}=1$ and we set $\\varepsilon=10^{-4}$ . This is repeated $10^{4}$ times for each state, giving at least $10^{4}$ return samples per state. ", "page_idx": 35}, {"type": "text", "text": "G.2 Algorithms ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "As described in the main paper, we compare DCFP, QDP, and CDP algorithms. For DCFP and CDP, we make use of the sparse structure of the update matrix (see Equation (9)), and implement these algorithms using SciPy\u2019s sparse matrix-vector multiplication and linear system solution methods (Virtanen et al., 2020). The mathematical details regarding the sparsity of the update matrix is described in Appendix G.3. For comparison, we also run implementations of DCFP and CDP that do not exploit this sparsity, and instead use standard dense NumPy implementations for matrixvector multiplication and linear system solution methods; these are denoted by d-DCFP and d-CDP, respectively. ", "page_idx": 36}, {"type": "text", "text": "By default the categorical methods (all variants of DCFP and CDP) use the atom locations described in the main paper: $\\begin{array}{r}{z_{i}\\,=\\,\\frac{i-1}{m-1}(1-\\gamma)^{-1}}\\end{array}$ for $i\\,=\\,1,\\ldots,m$ . These atom locations are sufficient to establish the theoretical results in the main paper, though we note that in practice, particularly when true return distributions are localised within a small sub-interval of $[0,(1^{-}\\gamma)^{-1}]$ , this setting can be overly conservative. However, in many cases, there are straightforward ways in which the choice of support can be improved, essentially by replacing the uniformly valid return range $[0,(1-\\gamma)^{-1}]$ with an a priori known environment-specific reward range. As an example, if the known range of immediate rewards forms a sub-interval $[r_{\\operatorname*{min}},r_{\\operatorname*{max}}]\\subseteq[\\bar{0},1]$ , then the return must fall into the environment-specific reward range $[r_{\\operatorname*{min}}(1-\\gamma)^{-1}$ , $r_{\\mathrm{max}}(1-\\dot{\\gamma})^{-1}]$ , and improved atom locations $\\begin{array}{r}{z_{i}=r_{\\mathrm{min}}(1-\\gamma)^{-1}+\\frac{i-1}{m-1}(r_{\\mathrm{max}}-\\bar{r}_{\\mathrm{min}}^{+})(\\bar{1}-\\gamma)^{-1}}\\end{array}$ im\u2212\u221211(rmax \u2212rmin)(1 \u2212\u03b3)\u22121 (for i = 1, . . . , m) can be used, whilst maintaining the guarantee that the support for the true return distributions lie within this interval. We thus additionally report results for versions of DCFP and CDP that use environment-specific atom locations, to investigate what practical improvements can be gained with such additional information. Specifically, for the high random and low random environments, we use the tighter bounds on support given by known $r_{\\mathrm{min}}$ and $r_{\\mathrm{max}}$ , as described above. In the chain environment, we consider using the advanced knowledge that only the transition into the terminal state is rewarding, yielding a sub-interval for possible returns of $[0,1]$ . In the two-state case, the range of possible returns is the full interval $[0,(\\dot{1}-\\gamma)^{-1}]$ , and so we do not investigate an environment-specific set of atoms in this case. However, it is clear from the Monte Carlo approximations to the return distributions in this environment in Figure 4 that these distributions do have the vast majority of their probability mass in a much smaller interval than the worst case interval $[0,(1-\\gamma)^{-1}]$ . ", "page_idx": 36}, {"type": "text", "text": "We ran all DP methods with 30,000 iterations. For all categorical DP methods, we verify that the Wasserstein distance between the last iterate to the Monte Carlo ground truth is almost identical to the Wasserstein distance between the categorical fixed-point to the ground truth. ", "page_idx": 36}, {"type": "text", "text": "G.3 Efficient implementation of CDP and DCFP ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "A straightforward implementation of CDP and DCFP is to vectorise $F$ , treating it as a vector indexed by state-index pairs $(x,i)$ , and correspondingly treat $T_{\\hat{P}}$ as a matrix whose rows and columns are indexed similarly. Iterations of CDP can then be performed by simple matrix-vector multiplications with this representation of $T_{\\hat{P}}$ , and the solution of the linear system appearing in Equation (11) that forms the core of DCFP can be implemented with a call to a standard linear system solver, such as numpy.linalg.solve (Harris et al., 2020). ", "page_idx": 36}, {"type": "text", "text": "However, the operator $T_{\\hat{P}}$ typically has some specific structure that can be exploited in implementations. In particular, we highlight here the sparse structure of $T_{\\hat{P}}$ , allowing for potential speed-ups in implementation by making use of sparse linear solvers, such as scipy.sparse.linalg.spsolve (Virtanen et al., 2020). Recall that, viewing $T_{\\hat{P}}$ as a matrix (c.f. Equation (9)), the element corresponding to the $(x,i)$ row and $(y,j)$ column is given by ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\hat{P}(y|x)(H_{i,j}^{x}-H_{i,j+1}^{x})\\,.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "In an MRP with sparse transition matrix $P$ , the empirical estimate $\\hat{P}$ inherits this sparsity, inducing sparsity in $T_{\\hat{P}}$ . In addition, there is also sparsity induced by the atom index components of the row and column indices, as we now describe. Recall from Equation (8) that $\\begin{array}{r}{H_{i,j}^{x}=\\sum_{l\\le i}^{\\cdot}h_{l}(r(x)+\\gamma z_{j})}\\end{array}$ ; see Figure 5 for an illustration the function $z\\mapsto\\sum_{l\\leq i}h_{l}(z)$ . ", "page_idx": 36}, {"type": "text", "text": "Now, suppose that for some $x\\in\\mathscr{X}$ and $1\\leq i,j\\leq m-1,H_{i,j}^{x}-H_{i,j+1}^{x}$ is non-zero. This says that the function $z\\mapsto\\sum_{l\\leq i}h_{l}(z)$ takes on different values at $r(x)+\\gamma z_{j}$ and $r(x)+\\gamma z_{j+1}$ , and since the distance between these arguments is $\\gamma$ times the grid width $(1-\\gamma)^{-1}m^{-1}$ , it follows that at least one of these two arguments must lie in the interval $[z_{i},z_{i+1}]$ ; see Figure 5. ", "page_idx": 36}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/b43b6c8f559a06a91c2de22e43b95bceebeba4ec39b39b09223ed29eb3c61673.jpg", "img_caption": ["Figure 5: The function $z\\;\\mapsto\\;\\sum_{l\\leq i}h_{l}(z)$ (grey), and a possible configuration for $r(x)+\\gamma z_{j}$ , $r(x)+\\gamma z_{j+1}$ in the event of a non-zero $H_{i,j}^{x}-H_{i,j+1}^{x}$ term. "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "", "page_idx": 37}, {"type": "text", "text": "From this observation, we deduce two forms of sparsity for the elements given in Equation (35). First, since one of $r(x)+\\gamma z_{j}$ and $r(x)+\\gamma z_{j+1}$ must lie in $[z_{i},z_{i+1}]$ , we deduce that neither of these points can lie in any interval $[z_{i^{\\prime}},z_{i^{\\prime}+1}]$ with $i^{\\prime}<i-1$ or $i^{\\prime}>i+1$ , and hence $H_{i^{\\prime},j}^{x}-H_{i^{\\prime},j}^{x}=0$ for such $i^{\\prime}$ . From this reasoning, it follows that ranging over $i$ in Equation (35), there are at most 2 non-zero elements. For large $m$ , this means that $T_{\\hat{P}}$ is very sparse. ", "page_idx": 37}, {"type": "text", "text": "Similarly, we can deduce row sparsity by noting that at most $\\lceil2/\\gamma\\rceil$ indices $j$ can have the property that $r(x)+\\gamma z_{j}$ or $r(x)+\\gamma z_{j+1}$ can lie in $[z_{i},z_{i+1}]$ , and it is only for these indices $j$ that we can have $H_{i,j}^{x}-H_{i,j+1}^{x}$ non-zero. So for $\\gamma\\approx1$ , this also implies sparsity of the elements in Equation (35) as we range over $j$ . ", "page_idx": 37}, {"type": "text", "text": "G.4 Results ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "For each setting, we repeat the experiment 30 times with different sampled transitions. We display trade-off plots (supremum-Wasserstein-1 error and wallclock time) for each of the four environments described above, in Figures 6, 7, 8, and 9, for the cases of $m\\in\\{30,100,300,1000\\}$ atoms and using $N=10^{6}$ sample transitions from each state to estimate transition matrix. These curves are obtained by averaging across the 30 repetitions. Some central themes emerge from the results. ", "page_idx": 37}, {"type": "text", "text": "In the case when the categorical methods use the environment-independent, standard atom locations $\\begin{array}{r}{z_{i}=\\frac{i-1}{m-1}(1-\\gamma)^{-1}}\\end{array}$ for $i=1,\\hdots,m$ , we find that for a given atom count $m$ , QDP often achieves the lowest asymptotic Wasserstein-1 error. A notable exception is the two-state environment; Rowland et al. (2024) observed that such environments, in which there is a short, high-probability path from a state to itself, can cause high approximation error for QDP, which we believe is the cause of the inaccuracy observed here, particularly at high discounts. However, the categorical approaches often deliver better performance as judged by wallclock time. This is owing to the efficient implementations of the linear operator, and solution methods for the linear system, that are associated with these algorithms. By contrast, the QDP operator is non-linear, and requires a call to a sorting method. We tend to observe the greatest benefits of the sparse implementation for large atom counts, as expected, and also observe the greatest beneftis of DCFP over the iterative CDP algorithm in settings with high discount factors. This is also to be expected, since the discount factor controls the rate of convergence of the DP algorithms. Note additionally that the use of environment-specific atom locations generally improves the results obtained with categorical approaches; the improvements in the chain environment are particularly strong, since the narrow return range allows for a denser packing of atom locations, by a factor of $(1-\\Bar{\\gamma})^{-1}$ , for a given atom count $m$ . ", "page_idx": 37}, {"type": "text", "text": "We also compare how the supremum-Wasserstein distance changes while the number of samples used to estimate $\\hat{P}$ increases from $10^{2}$ to $10^{6}$ . Since the categorical methods all converge to the same fixed point, we only show the result of DCFP and QDP, using $m\\in\\{30,100,300,1000\\}$ atoms. Figure 10(a) shows that the distance decreases as the number of samples increase. One exception is the QDP with 30 atoms applied to high random at high $\\gamma$ , where $N=100$ produced smallest distance on average. Figure 10(b) shows the results when the environment-specific return range is given. This substantially reduced the supremum-Wasserstein distance, especially when using a small number of atoms. ", "page_idx": 37}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/4294289496b6a03cf278c16c03b62f3a25f8261bb84c4fb167ce98fb556ce4a9.jpg", "img_caption": ["(b) Environment-specific return range "], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "Figure 6: Distance vs. run time results for the chain environment, for $\\hat{P}$ estimated from $N=10^{6}$ sample transitions. ", "page_idx": 38}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/84d1c0f33f90fcdc91e2f48cb0f1f78f1020a6d5b506b754691cfde3711c1aa9.jpg", "img_caption": ["(b) Environment-specific return range "], "img_footnote": [], "page_idx": 39}, {"type": "text", "text": "Figure 7: Distance vs. run time results for the low random environment, for $\\hat{P}$ estimated from $N\\,{=}\\,10^{6}$ sample transitions. ", "page_idx": 39}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/489d9a00bec34cec80b2ed4623e01f22f2d4f31d5dccfd87c514f4f0e4ea8017.jpg", "img_caption": ["(b) Environment-specific return range "], "img_footnote": [], "page_idx": 40}, {"type": "text", "text": "Figure 8: Distance vs. run time results for the high random environment, for $\\hat{P}$ estimated from $N\\,{=}\\,10^{6}$ sample transitions. ", "page_idx": 40}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/19057e6002d51a94bac4914a24cc6eef361fc92f6904191b5b899a3325b14226.jpg", "img_caption": [], "img_footnote": [], "page_idx": 41}, {"type": "text", "text": "Figure 9: Distance vs. run time results for the two-state environment, for P\u02c6 estimated from $N=10^{6}$ sample transitions. The return range of this environment coincides with the global return range. ", "page_idx": 41}, {"type": "image", "img_path": "JXKbf1d4ib/tmp/3c2b1829e9f911ea87b43cd43a1622935843474a99154c947cfac3438af9aa09.jpg", "img_caption": ["Figure 10: Supremum-Wasserstein distance on convergence. Error envelope indicates $95\\%$ confidence interval by bootstrapping. The return range of the two-state environment coincides with the global return range. ", "(b) Environment-specific return range "], "img_footnote": [], "page_idx": 42}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 43}, {"type": "text", "text": "Justification: The abstract and introduction describe the main contributions of the paper, and contextualise these against previous contributions in the literature.   \nGuidelines:   \n\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 43}, {"type": "text", "text": "", "page_idx": 43}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 43}, {"type": "text", "text": "Justification: The paper discusses in detail the assumptions required for the theoretical results to hold, such as using tabular representations and a generative model for sampled transitions. The experimental results also make clear the relative performance of the analysed DCFP algorithm, and other approaches to model-based distributional RL, such as quantile dynamic programming, which is not analysed in the paper. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 43}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 43}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Justification: All theoretical results are stated with precise assumptions required, and full proofs are provided in the appendix. We additionally provide a proof sketch for the main result in the paper, to aid readers with intuition. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 43}, {"type": "text", "text": "", "page_idx": 44}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 44}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Justification: We provide precise algorithm descriptions, as well as all hyperparameters used. In addition, we discuss specific details for obtaining efficient implementations, such as exploiting sparsity, in the appendices. ", "page_idx": 44}, {"type": "text", "text": "Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example   \n(a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm.   \n(b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closedsource models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 44}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? Answer: [No] ", "page_idx": 44}, {"type": "text", "text": "Justification: We do not provide code implementations, but have described our tabular algorithms and hyperparameters so that the experiments can be reproduced solely within a numerical programming framework such as NumPy.   \nGuidelines: ", "page_idx": 44}, {"type": "text", "text": "", "page_idx": 44}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 44}, {"type": "text", "text": "", "page_idx": 45}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? Answer: [Yes] Justification: Our experiments are tabular, and we describe all implementation details and hyperparameters in the appendices. ", "page_idx": 45}, {"type": "text", "text": "", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.   \n\u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 45}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate   \ninformation about the statistical significance of the experiments?   \nAnswer: [Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: We report Wasserstein distances along with $95\\%$ bootstrapped confidence intervals in our experimental results. As our experiments are tabular, we are able to run many repetitions of the results with distinct random seeds, meaning that these confidence intervals are made extremely narrow. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 45}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Justification: We describe in the appendices that since our experiments are tabular, each run uses a single CPU, and run times are reported within the experimental results.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 45}, {"type": "text", "text": "", "page_idx": 45}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: We comply with code of ethics from the conference. Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 46}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 46}, {"type": "text", "text": "Justification: The contributions are primarily theoretical and foundational, and do not lead to immediate societal impacts.   \nGuidelines:   \n\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 46}, {"type": "text", "text": "", "page_idx": 46}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA]   \nJustification: The paper concerns solely tabular methods. Guidelines:   \n\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 46}, {"type": "text", "text": "", "page_idx": 46}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification: Our experiments are solely tabular, and we cite the programming frameworks used to implement these.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 46}, {"type": "text", "text": "", "page_idx": 47}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?   \nAnswer: [NA]   \nJustification: No new assets introduced.   \nGuidelines:   \n\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 47}, {"type": "text", "text": "", "page_idx": 47}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "page_idx": 47}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA]   \nJustification: No research with human subjects. Guidelines:   \n\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 47}, {"type": "text", "text": "", "page_idx": 47}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 47}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA]   \nJustification: No research with human subjects. Guidelines:   \n\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 47}, {"type": "text", "text": "", "page_idx": 47}]