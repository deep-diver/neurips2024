[{"figure_path": "oTzydUKWpq/tables/tables_4_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-level GIAs (ITGIAs).  It shows the average accuracy of the GCN on clean data and when attacked using five different ITGIA variants. The \"Avg. cos\" column indicates the average cosine similarity between the embeddings of the inverted text generated by each ITGIA variant and the original text embeddings.  This measure reflects how well the ITGIA is able to recover the original text from the embeddings. The \"Best Emb.\" column shows the best attack performance achieved at the embedding level, serving as a baseline for comparing text-level attack effectiveness.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_5_1.jpg", "caption": "Table 2: Performance of GCN against VTGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cBest Emb.\u201d refers to the best-performing embedding-level GIAs that directly update embeddings across various injection strategies.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when attacked using Vanilla Text-level Graph Injection Attacks (VTGIAs).  It shows the attack success rate (lower is better) for three different VTGIA prompt types (Heterophily, Random, Mixing) against a clean GCN baseline. The results are compared to the best-performing embedding-level GIAs, providing a context for evaluating the effectiveness of text-level attacks.  The use of GTR (T5-based pretrained transformer) for embedding is consistent across all tests.", "section": "3 Text-Level GIAs: Interpretability Matters"}, {"figure_path": "oTzydUKWpq/tables/tables_8_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs that have undergone Inversion-based Text-Level Graph Injection Attacks (ITGIAs).  The results show the average accuracy of the GCNs after the ITGIAs have been applied.  The \"Avg. cos\" column indicates the average cosine similarity between the embeddings of the inverted text (generated from the embeddings injected by the attack) and their original embeddings.  This value reflects the similarity between the injected text and the original text at the embedding level, which gives an understanding of how well the attack mimics the original data. The \"Best Emb.\" column shows the best attack performance that was achieved using traditional embedding-level GIAs (not the text-level GIAs evaluated here), providing a benchmark to compare the performance of the ITGIAs.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_9_1.jpg", "caption": "Table 4: The performance of WTGIA against LLMs-as-predictor. The term \\textquotedblleft (w/o Nei.)\\textquotedblright means the exclusion of neighborhood information in the prompt. Methods \\textquotedblleft Clean (w/o Nei.)\\textquotedblright and \\textquotedblleft WTGIA (w Nei.)\\textquotedblright can be used as LLM-based defenders. The best results for defenders are bold.", "description": "This table presents the performance comparison between different models in node classification tasks using LLMs as predictors with or without neighborhood information.  It showcases the effectiveness of WTGIA (Word-frequency-based Text-level GIA) attacks against LLMs in a zero-shot and few-shot learning settings on three different datasets: Cora, CiteSeer, and PubMed.  The results highlight the impact of incorporating neighborhood information and the performance of LLMs as defenses against text-level graph injection attacks.", "section": "5.2 LLMs as Defender"}, {"figure_path": "oTzydUKWpq/tables/tables_13_1.jpg", "caption": "Table 5: Statistics of datasets. Edges (UnD.) stands for the number of edges after transforming each dataset into undirected. Avg. (Max) Sparsity stands for the average (max) percentage of non-zero elements in BoW embeddings of the raw texts.", "description": "This table presents the statistics of five datasets used in the paper's experiments: Cora, CiteSeer, PubMed, ogbn-arxiv, and Reddit. For each dataset, it provides the number of nodes, the number of undirected edges, the number of classes, the average node degree, and the average and maximum sparsity of the bag-of-words (BoW) embeddings of the textual features. The sparsity values reflect the percentage of non-zero elements in the BoW vectors, indicating the density of textual features per node.", "section": "2 Background and Preliminaries"}, {"figure_path": "oTzydUKWpq/tables/tables_13_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-Level Graph Injection Attacks (ITGIAs).  It shows the accuracy of GCNs after ITGIA attacks using different strategies (SeqGIA, MetaGIA, TDGIA, ATDGIA, AGIA). The average cosine similarity between inverted text embeddings and their original embeddings is also reported to evaluate the quality of text inversion.  The \"Best Emb.\" column shows the best attack performance achieved at the embedding level, serving as a comparison baseline for text-level attacks.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_13_3.jpg", "caption": "Table 7: Attack budgets on the datasets.", "description": "This table shows the attack budgets used in the experiments for five different datasets.  For each dataset, the number of injected nodes, the maximum degree of the injected nodes, the percentage of injected nodes relative to the total number of nodes, and the percentage of injected edges relative to the total number of edges are presented. These budgets represent the constraints under which the graph injection attacks were performed.", "section": "3 Text-Level GIAs: Interpretability Matters"}, {"figure_path": "oTzydUKWpq/tables/tables_16_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs injected with Inversion-based Text-level GIAs (ITGIAs).  It shows the average accuracy of the GCNs on three datasets (Cora, CiteSeer, PubMed) under different ITGIA variants and compares the performance against the best results achievable by traditional embedding-level GIAs. The average cosine similarity between the inverted text embeddings and original embeddings is also provided, indicating the interpretability of the generated text. Lower accuracy values represent stronger attack performance.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_17_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs that have undergone Inversion-based Text-level GIAs (ITGIAs).  It shows the average accuracy of the GCNs on clean graphs and graphs attacked using five different ITGIA variants.  The \"Avg. cos\" column indicates the average cosine similarity between the embeddings of the text generated from the inverted embeddings and their original counterparts.  The \"Best Emb.\" column shows the best attack performance achieved at the embedding level (without text inversion). The results are presented for three datasets: Cora, CiteSeer, and PubMed, and whether or not the Harmonious Adversarial Objective (HAO) was used.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_18_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table shows the performance of Graph Convolutional Networks (GCNs) on various datasets when attacked using Inversion-based Text-Level GIAs (ITGIAs).  It compares the performance of GCNs against five different ITGIA variants and measures the average cosine similarity between the original embeddings and those obtained after text inversion. This similarity serves as an indicator of the interpretability of the attack. The table also provides a baseline performance measure representing the best achievable attack success at the embedding level.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_18_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-level GIAs (ITGIAs).  It shows the accuracy of the GCNs on various datasets (Cora, CiteSeer, PubMed) when attacked with different ITGIA variants (SeqGIA, MetaGIA, TDGIA, ATDGIA, AGIA). The average cosine similarity between the inverted text embeddings and the original embeddings is also provided, along with the best embedding-level attack performance as a benchmark. The table highlights the trade-off between the effectiveness of text-level attacks and their interpretability, with lower accuracy indicating a stronger attack.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_19_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-level GIAs (ITGIAs).  It shows the accuracy of GCNs on three datasets (Cora, CiteSeer, and PubMed) when attacked using five different ITGIA variants. The average cosine similarity between the original embeddings and the embeddings generated by inverting text from the ITGIAs is also provided, illustrating the loss of information during the inversion process. This table helps assess the effectiveness of ITGIAs compared to the best-performing embedding-level GIAs.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_20_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs that have been attacked using Inversion-based Text-level Graph Injection Attacks (ITGIAs).  The table shows the average accuracy of the GCN on clean graphs and graphs modified by five different ITGIA variants. It also includes the average cosine similarity between the embeddings of the inverted text and the original embeddings, providing insights into the interpretability of the attacks.  The \"Best Emb.\" column provides a comparison to the best-performing embedding-level attacks. The results indicate that ITGIAs, while effective at the embedding level, perform poorly at the text level due to challenges in converting embeddings back into meaningful and coherent text.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_20_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs that have undergone Inversion-based Text-Level Graph Injection Attacks (ITGIAs).  The table shows the average accuracy of the GCN on clean (unattacked) graphs and on graphs modified by five different ITGIA variants.  The average cosine similarity between the original and inverted text embeddings is also shown.  This metric helps understand the interpretability of the generated text from the inverted embeddings. Finally, the \"Best Emb.\" column shows the best attack performance at the embedding level for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_21_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table shows the performance of Graph Convolutional Networks (GCNs) on graphs that have been attacked using Inversion-based Text-Level GIAs (ITGIAs).  The table compares the performance of GCNs on clean graphs to those attacked with five different ITGIA variants. The \"Avg. cos\" column shows the average cosine similarity between the embeddings of the generated text and the original embeddings. This indicates how well the generated text matches the original in terms of embedding space, which is relevant to the attack's success.  The \"Best Emb.\" column shows the best attack performance achieved using embedding-level GIAs for comparison, indicating the gap between the effectiveness of the embedding and text-level attacks.  Overall, the table demonstrates the tradeoff between attack effectiveness and text interpretability in ITGIAs.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_21_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table shows the performance of Graph Convolutional Networks (GCNs) on graphs attacked using Inversion-based Text-level GIAs (ITGIAs).  It compares the average accuracy of the GCN against five different ITGIA variants, using GTR embeddings for the raw text. The average cosine similarity between the original and inverted text embeddings are shown to illustrate the loss of interpretability during the text inversion process.  Finally, the table also displays the best attack performance that was achieved using embedding-level GIA methods for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_24_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-level GIAs (ITGIAs).  It shows the accuracy of the GCNs after the attack, comparing the results of five different ITGIA variants (SeqGIA, MetaGIA, TDGIA, ATDGIA, AGIA).  The table also includes the average cosine similarity between the embeddings of the generated text and their original embeddings (Avg. cos), providing insight into the text interpretability, and the best performance achieved at the embedding level (Best Emb.) for comparison. The data is broken down by dataset (Cora, CiteSeer, PubMed).", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_24_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when facing Inversion-based Text-Level GIAs (ITGIAs).  It shows the accuracy of GCNs on three datasets (Cora, CiteSeer, PubMed) under different attack methods. The average cosine similarity between the inverted text embeddings and their originals is also provided, indicating the quality of the text inversion process. Finally, it compares the performance of ITGIA to the best embedding-level attack.", "section": "Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_24_3.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the accuracy of GCNs after the attacks, and the average cosine similarity between the inverted text embeddings and original embeddings.  The \"Best Emb.\" column indicates the best attack performance achieved using traditional embedding-level GIAs, providing a comparison to the performance of text-level attacks.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_25_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs that have been attacked using Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the accuracy of the GCNs on various datasets after ITGIA attacks with different configurations. The \"Avg. cos\" column shows the average cosine similarity between the inverted text embeddings and the original embeddings, indicating the quality of text reconstruction from embeddings. The \"Best Emb.\" column indicates the best attack performance achieved by embedding-level GIAs.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_25_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on various datasets (Cora, CiteSeer, PubMed) when attacked using Inversion-based Text-level GIAs (ITGIAs).  It shows the average accuracy of GCNs on clean graphs and graphs attacked using five different ITGIA variants, along with the average cosine similarity between the inverted text embeddings and original embeddings. The \"Best Emb.\" column indicates the best attack performance achievable at the embedding level for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_25_3.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when facing Inversion-based Text-Level GIAs (ITGIAs).  It shows the accuracy of the GCN on various datasets (Cora, CiteSeer, PubMed) under different attack strategies.  The average cosine similarity between the inverted text embeddings and their originals is provided, indicating the success rate of the text inversion.  The table also compares the ITGIA's performance to the best-performing embedding-level attacks for context.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_25_4.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-Level GIAs (ITGIAs).  It shows the attack success rate (lower is better, indicating stronger attack) for five different ITGIA variants against GCNs.  The average cosine similarity between the embeddings of inverted text and the original embeddings is also reported, offering insights into the interpretability of the attacks. The \"Best Emb.\" column shows the best attack performance achieved at the embedding level, providing a benchmark comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_25_5.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the accuracy of GCNs on three benchmark datasets (Cora, CiteSeer, and PubMed) under various ITGIA attack strategies.  The average cosine similarity between the inverted text embeddings and their original embeddings is included, indicating the degree of preservation of information during the text inversion process. The table also compares the attack performance of ITGIA with the best-performing embedding-level attack on each dataset, highlighting the relative effectiveness of the proposed text-level attack.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_26_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the attack success rate (percentage decrease in GCN accuracy) for different ITGIA variants (SeqGIA, MetaGIA, TDGIA, ATDGIA, AGIA).  The average cosine similarity between the inverted text embeddings and their original embeddings is also provided, indicating the degree of information loss during the text inversion process. Finally, it compares the performance of ITGIAs with the best results achieved by traditional embedding-level GIAs.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_26_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table shows the performance of Graph Convolutional Networks (GCNs) on graphs that have been attacked using Inversion-based Text-level GIAs (ITGIAs).  The table compares the performance of GCNs on clean graphs versus graphs with injected nodes, where the injected nodes' text features were created by inverting embeddings (using the Vec2Text method). The average cosine similarity between the inverted text embeddings and the original embeddings is also shown, reflecting the quality of the text inversion process.  The \"Best Emb.\" column provides the best attack performance obtained using existing embedding-level GIAs for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_26_3.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-Level GIAs (ITGIAs).  It shows the accuracy of GCNs on three datasets (Cora, CiteSeer, PubMed) when attacked using five different ITGIA variants. The average cosine similarity between the embeddings of the inverted text and the original embeddings is also given, indicating the level of interpretability.  The \"Best Emb.\" column provides the best attack performance achieved by any of the embedding-level GIA methods, offering a comparison to the ITGIA approach.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_27_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-Level GIAs (ITGIAs).  The raw text data is embedded using the GTR method before being input to the GCN.  The table shows the average cosine similarity between the inverted text embeddings and their original embeddings for five different ITGIA variants. It also compares the performance to the best-performing embedding-level attack, indicating the effectiveness and interpretability of the ITGIA attacks.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_27_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs that have undergone Inversion-based Text-level GIAs (ITGIAs).  The raw text data is embedded using the GTR method before being input to the GCN. The table shows the average cosine similarity between the embeddings of the inverted text and their originals, providing a measure of the attack's success in maintaining text similarity after the inversion process. The \"Best Emb.\" column indicates the best attack performance achieved by five different ITGIA variants at the embedding level for comparison. ", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_27_3.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  The attack performance is measured by the average accuracy of the GCN after the ITGIA injection. The table shows the results for three different datasets (Cora, CiteSeer, and PubMed) and includes the average cosine similarity between the inverted text embeddings and their original embeddings, providing an insight into the attack's interpretability. The \"Best Emb.\" column provides the attack performance achieved by the best-performing embedding-level GIA as a benchmark for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_27_4.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs that have been attacked using Inversion-based Text-level Graph Injection Attacks (ITGIAs).  The table shows the average accuracy of the GCN on clean data, and then under several variations of the ITGIA, each of which generates text from embeddings. The 'Avg. cos' column shows how similar the embeddings of the generated text are to the original embeddings, indicating whether the generated text is meaningful. The 'Best Emb.' column gives the best attack performance achieved by traditional embedding-level GIAs for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_27_5.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-level GIAs (ITGIAs).  The raw text data is embedded using the GTR method before being input to the GCN.  The table compares the average cosine similarity between the inverted text embeddings and their original counterparts across five different ITGIA variants. It also shows the best attack performance achieved at the embedding level for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_27_6.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table shows the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs that have been attacked using Inversion-based Text-level GIAs (ITGIAs).  The table compares the accuracy of GCNs on clean graphs versus graphs modified by five different ITGIA variants.  The \"Avg. cos\" column shows the average cosine similarity between the embeddings of the inverted text produced by the ITGIAs and the original embeddings, giving an indication of how interpretable the generated text is. The \"Best Emb.\" column shows the best attack performance achieved at the embedding level (without text-based injection) for comparison purposes.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_28_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on various graph datasets when subjected to Inversion-based Text-Level GIAs (ITGIAs).  It compares the attack success rate against several baseline attack methods at both the text and embedding levels. The average cosine similarity between the original embeddings and the embeddings generated from the inverted text provides insights into the quality of the inversion process.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_28_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when attacked using Inversion-based Text-Level GIAs (ITGIAs).  It shows the average accuracy of the GCNs on three datasets (Cora, CiteSeer, PubMed) after injecting nodes with text generated by inverting embeddings. The average cosine similarity between the original embeddings and the inverted text embeddings is also provided, which reflects the interpretability of the generated text. The table also indicates the best performance achieved by embedding-level GIAs for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_28_3.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs subjected to Inversion-based Text-level GIAs (ITGIAs).  It shows the accuracy of the GCN on clean data and when attacked using different variations of ITGIA, where the injected text is generated via an inversion of embeddings.  The average cosine similarity between the inverted text embeddings and the original embeddings is also provided, along with the best attack performance achieved at the embedding level for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_28_4.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs (TAGs) when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the average accuracy of the GCN on the clean graph and graphs attacked using five different ITGIA variants (SeqGIA, MetaGIA, TDGIA, ATDGIA, AGIA).  The table also includes the average cosine similarity between the inverted text embeddings and the original embeddings, reflecting the interpretability of the attack, and a comparison to the best-performing embedding-level attack.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_29_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs injected with Inversion-based Text-Level GIAs (ITGIAs).  It shows the accuracy of GCNs after applying five different ITGIA variants, comparing results using both Bag-of-Words (BoW) and GTR embeddings. The \"Avg. cos\" column indicates the average cosine similarity between the inverted text embeddings and their originals, measuring the quality of the inversion process.  \"Best Emb.\" provides the best attack performance achieved at the embedding level (without text inversion), serving as a baseline for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_29_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on text-attributed graphs (TAGs) when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the average attack success rate (lower is better, indicating stronger attack) for various ITGIA methods, comparing their performance against a baseline (clean) GCN. The average cosine similarity between the original and inverted text embeddings is also provided, measuring the quality of text reconstruction from embeddings.  The \"Best Emb.\" column highlights the best results achieved using existing embedding-level GIAs for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_29_3.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on graphs attacked using Inversion-based Text-level GIAs (ITGIAs).  It shows the average accuracy of the GCN on several datasets (Cora, CiteSeer, PubMed) after ITGIA attacks with different strategies. The table also provides the average cosine similarity between the inverted text embeddings and the original embeddings, as well as a comparison to the best embedding-level attack performance for each dataset.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_29_4.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the accuracy of GCNs on three datasets (Cora, CiteSeer, PubMed) under different attack strategies. The average cosine similarity between the inverted text embeddings and their original embeddings are also reported, indicating the quality of the text inversion process.  Finally, it includes a comparison with the best embedding-level attack for each dataset.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_30_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on various datasets when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the average accuracy of the GCNs on clean graphs and graphs attacked using five different ITGIA variants.  The table also includes the average cosine similarity between the embeddings of the inverted text (generated by the attack) and their corresponding original embeddings, providing a measure of the attack's ability to generate realistic-looking text.  Finally, it lists the best attack performance (lowest accuracy) achieved at the embedding level, serving as a baseline for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_30_2.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when subjected to Inversion-based Text-level Graph Injection Attacks (ITGIAs).  It shows the accuracy of the GCN on various datasets (Cora, CiteSeer, PubMed) under different ITGIA variants.  The \"Avg. cos\" column indicates the average cosine similarity between the inverted text embeddings and their original counterparts, reflecting the quality of text inversion.  The \"Best Emb.\" column provides the best attack performance achievable using embedding-level methods for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_30_3.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) on various datasets (Cora, CiteSeer, PubMed) when subjected to Inversion-based Text-Level Graph Injection Attacks (ITGIAs).  It shows the average accuracy of the GCNs on clean graphs and graphs attacked by different ITGIA variants.  The \"Avg. cos\" column indicates the average cosine similarity between the embeddings of the inverted text produced by ITGIA and their corresponding original embeddings. This measures the interpretability of the generated text. The \"Best Emb.\" column shows the best attack performance achieved at the embedding level (without text inversion) for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_30_4.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table shows the performance of Graph Convolutional Networks (GCNs) on graphs attacked using Inversion-based Text-level GIAs (ITGIAs).  The raw text is embedded using the GTR method before being fed to the GCN. The table compares the performance of GCNs against five different ITGIA variants, along with a measure of cosine similarity between the inverted text embeddings and their original embeddings. The \"Best Emb.\" column indicates the best attack performance achieved at the embedding level (as a baseline for comparison with the text-level attack results).", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}, {"figure_path": "oTzydUKWpq/tables/tables_31_1.jpg", "caption": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \"Best Emb.\" represents the best attack performance across the five variants at the embedding level.", "description": "This table presents the performance of Graph Convolutional Networks (GCNs) when subjected to Inversion-based Text-level GIAs (ITGIAs).  It shows the accuracy of the GCN on various datasets (Cora, CiteSeer, PubMed) under different ITGIA attack variants.  The \"Avg. cos\" column indicates the average cosine similarity between the embeddings of the text generated from the inverted embeddings and the original embeddings.  The \"Best Emb.\" column provides the best attack performance achieved at the embedding level for comparison.", "section": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable"}]