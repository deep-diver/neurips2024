[{"type": "text", "text": "Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Runlin Lei Yuwei Hu Yuchen Ren Renmin University of China Renmin University of China Renmin University of China runlin_lei@ruc.edu.cn huyuweiyisui@ruc.edu.cn siriusren@ruc.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Zhewei Wei \u2217 Renmin University of China zhewei@ruc.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graph Neural Networks (GNNs) excel across various applications but remain vulnerable to adversarial attacks, particularly Graph Injection Attacks (GIAs), which inject malicious nodes into the original graph and pose realistic threats. Text-attributed graphs (TAGs), where nodes are associated with textual features, are crucial due to their prevalence in real-world applications and are commonly used to evaluate these vulnerabilities. However, existing research only focuses on embedding-level GIAs, which inject node embeddings rather than actual textual content, limiting their applicability and simplifying detection. In this paper, we pioneer the exploration of GIAs at the text level, presenting three novel attack designs that inject textual content into the graph. Through theoretical and empirical analysis, we demonstrate that text interpretability, a factor previously overlooked at the embedding level, plays a crucial role in attack strength. Among the designs we investigate, the Word-frequency-based Text-level GIA (WTGIA) is particularly notable for its balance between performance and interpretability. Despite the success of WTGIA, we discover that defenders can easily enhance their defenses with customized text embedding methods or large language model (LLM)\u2013based predictors. These insights underscore the necessity for further research into the potential and practical significance of text-level GIAs. The code is available at https://github.com/Leirunlin/Text-level-Graph-Attack. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graph Neural Networks (GNNs) have exhibited exceptional performance in various tasks [30, 34]. However, their vulnerability to graph adversarial attacks has been increasingly exposed. Research shows that Graph Modification Attacks (GMAs), which perturb a small portion of edges and node features of the original graph, can significantly degrade the performance of GNNs [37, 38]. Besides GMAs, Graph Injection Attacks (GIAs) generate harmful nodes and connect them to the original nodes, thereby reducing the performance of GNNs. Since adding new content to the public dataset is more practical than modifying existing content, GIAs are considered one of the most realistic graph adversarial attacks [28, 33]. ", "page_idx": 0}, {"type": "text", "text": "Text-Attributed Graphs (TAGs), characterized by nodes with text-based features, form a crucial category among various graph types. In the early stages of GNNs, textual node feature processing is decoupled from the network design. Researchers transform text into fixed embeddings to investigate GNN designs on downstream tasks [13, 8, 27]. However, recent advancements have shifted toward a non-decoupled framework that integrates raw text into the design, significantly improving the ability to capture textual characteristics and enhance performance [9, 10]. Despite this progress in GNN design, current GIAs still focus on fixed embedding, aiming at only the injection of node embeddings rather than raw text on TAGs. This leads to several practical issues: 1) The attack setting is unrealistic. In real-world scenarios like social or citation networks, it is more practical to inject nodes with raw text rather than node embeddings. For example, to attack a citation network dataset, it would be more natural to upload fake papers rather than a batch of embeddings. 2) The injected embeddings may be uninterpretable. As minor perturbations at the embedding level can lead to unpredictable semantic shifts, traditional GIAs fail to ensure that injected nodes convey understandable semantic information. 3) Increased Detectability of Attacks. Attackers usually have access only to raw text, not the processed embeddings defenders use. This discrepancy makes it challenging for attackers to mimic the embedding methods of defenders, leading to structurally abnormal embeddings. For example, embeddings based on word frequency are sparse, while those from Pre-trained Language Models (PLMs) are typically output continuous and dense. If an attacker injects dense embeddings while a defender uses a word-frequency-based model, the difference in the embedding structure makes the injected embeddings easy to detect. ", "page_idx": 1}, {"type": "image", "img_path": "oTzydUKWpq/tmp/1bb6ed986d79cfdb04bc5fb1582ef12aec5478bea6b81ec9ff3b83564be21570.jpg", "img_caption": ["Figure 1: Illustration of the Text-Level GIA setup and the three designs explored. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "To address the above limitations, in this paper, we innovatively explore text-level GIAs, comprehensively examining their implementation, performance, and challenges. We explore three text-level GIAs: Vanilla Text-level GIA (VTGIA), Inversion-based Text-level GIA (ITGIA), and Word-frequency-based Text-level GIA (WTGIA), all of which successfully inject raw text into graphs and degrade the performance of GNNs, as shown in Figure 1b. Experiment results indicate that interpretability presents a significant trade-off against attack performance. ITGIA struggles to invert embeddings to interpretable text because the interpretable regions of the injected embeddings are ill-defined. VTGIA, which solely relies on Large Language Models (LLMs) for text generation, compromises attack effectiveness for its pursuit of text interpretability. WTGIA, as a balanced approach, manages to produce harmful and coherent text more effectively. However, the trade-off between performance and interpretability, coupled with poor transferability to different embedding methods, limits the performance of text-level GIAs in practice. Moreover, LLM-based predictors are shown to significantly enhance defenses against text-level GIAs, highlighting the substantial progress still needed to refine these attacks. In summary, our contributions are as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 To the best of our knowledge, we are the first to unveil the dynamics of text-level graph adversarial attacks on TAGs, especially for GIAs. We discuss the impracticality of embedding-based GIA in real-world applications and propose a more realistic attack setting.   \n\u2022 We propose three effective text-level GIAs and demonstrate the trade-off between attack performance and text interpretability from both theoretical and empirical perspectives, providing insights for further refining text-level GIAs.   \n\u2022 We reflect on the challenges of graph adversarial attacks at the text level. We discover that simple strategies at the text level can enhance defense performance against text-level GIAs, which reemphasizes the importance of exploring GIAs at the text level. ", "page_idx": 1}, {"type": "text", "text": "2 Background and Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A Text-Attributed Graph (TAG) is represented as $\\mathcal{G}=(\\mathcal{V},\\mathcal{E},\\{s_{i}\\})$ , where $\\mathcal{V}$ is the node set and $\\mathcal{E}$ , the edge set. We denote $N$ as the number of nodes and $\\dot{\\mathbf{A}}\\in\\dot{\\{0,1\\}}^{N\\times N}$ as the adjacency matrix. For each node $v_{i}\\in\\mathcal{V}$ , a sequential text feature $s_{i}$ is associated. We focus on semi-supervised node classification tasks, where each node is categorized into one of $C$ classes. The node labels are denoted by $\\pmb{y}\\in\\{0,\\dots,C-1\\}^{N}$ . The task is to predict test labels $\\mathbf{Y}_{\\mathrm{test}}$ based on $\\mathcal{G}$ and training labels $\\mathbf{Y}_{\\mathrm{train}}$ . ", "page_idx": 2}, {"type": "text", "text": "Graph Neural Networks. We use $f_{\\theta}$ to denote a GNN parameterized by $\\theta$ . Generally, raw text $\\left\\{s_{i}\\right\\}$ is first embedded into a feature matrix $\\mathbf{X}\\in\\mathbb{R}^{N\\times F}$ using word embedding techniques, where $F$ is the output dimension. In the rest of our paper, when referring to vanilla GNNs that take text embeddings as inputs, we represent the text-attributed graph as $\\mathcal{G}=(\\mathcal{V},\\mathcal{E},\\mathbf{X})$ and express $f$ as $f(\\mathbf{X};\\mathbf{A})$ . The update process of the $l$ -th layer of $f$ can be formally described as: ", "page_idx": 2}, {"type": "equation", "text": "$$\nh_{i}^{l}=f^{l}\\left(h_{i}^{l-1},\\operatorname{AGGR}\\left(\\left\\{h_{j}^{l-1}:j\\in\\mathcal{N}_{i}\\right\\}\\right)\\right),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $h_{i}^{0}=\\mathbf{X}_{i}$ , ${\\mathcal N}_{i}$ is the neighborhood set of node $v_{i}$ , AGGR is the aggregation function, and $f^{l}$ is a message-passing layer that takes the features of $v_{i}$ and its neighbors as inputs. ", "page_idx": 2}, {"type": "text", "text": "Graph Injection Attacks and Related Works. Graph injection attacks aim to create a perturbed graph $\\mathcal{G}^{\\prime}\\,=\\,(\\mathcal{V}^{\\prime},\\mathcal{E}^{\\prime},{\\bf X}^{\\prime})$ to disrupt the accuracy of a GNN on target nodes. Formally, denote the number of injected nodes as $N_{\\mathrm{inj}}$ , and the number of nodes in the poisoned graph $\\mathcal{G}^{\\prime}$ as $N^{\\prime}$ . Then, the node set of $\\mathcal{G}^{\\prime}$ can be formulated as $\\mathcal{V}^{\\prime}=\\mathcal{V}\\cup\\mathcal{V}_{\\mathrm{inj}}$ , and: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbf{X}^{\\prime}=\\left[\\begin{array}{l}{\\mathbf{X}}\\\\ {\\mathbf{X}_{\\mathrm{inj}}}\\end{array}\\right],\\mathbf{A}^{\\prime}=\\left[\\begin{array}{c c}{\\mathbf{A}}&{\\mathbf{A}_{\\mathrm{inj}}}\\\\ {\\mathbf{A}_{\\mathrm{inj}}^{T}}&{\\mathbf{O}}\\end{array}\\right],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathbf{X}_{\\mathrm{inj}}\\in\\mathbb{R}^{N_{\\mathrm{inj}}\\times F}$ , $\\mathbf{A}_{\\mathrm{inj}}\\in\\{0,1\\}^{N\\times N_{\\mathrm{inj}}}$ , and $\\mathbf{O}\\in\\{0,1\\}^{N_{\\mathrm{inj}}\\times N_{\\mathrm{inj}}}$ ", "page_idx": 2}, {"type": "text", "text": "For the design of injected node features, one line of research focuses on statistical features to ensure unnoticeability, sacrificing attack strength by excluding learnable processes for features [25, 4]. In parallel, other works target learnable injected embeddings. Wang et al. [29] pioneer injecting fake nodes with binary features to degrade GNN performance. AFGSM [28] introduces an approximation strategy to linearize the surrogate model, efficiently solving the objective function. ", "page_idx": 2}, {"type": "text", "text": "Starting from KDDCUP 2020, research shifts towards injecting continuous node embeddings under the constraints in Equation (3) [33, 36, 2]. Denote the budget of injected nodes as $\\Delta$ , the maximum and minimum elements in the original feature matrix $\\mathbf{X}$ as $x_{\\mathrm{max}}$ and $x_{\\mathrm{min}}$ , and the maximum degree allowed for each injected node as $b$ . The objective of these GIAs can be formulated as: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\mathrm{G}^{\\prime}}{\\operatorname*{min}}\\frac{\\left\\vert\\left\\{f\\left(\\mathrm{G}^{\\prime}\\right)_{i}=y_{i},v_{i}\\in\\mathcal{V}_{T}\\right\\}\\right\\vert}{\\left\\vert\\mathcal{V}_{T}\\right\\vert}}\\\\ &{\\mathrm{s}.\\mathrm{t}.\\ N_{\\mathrm{inj}}\\leq\\Delta,d_{\\mathrm{inj}}\\leq b,\\quad x_{\\mathrm{min}}\\cdot\\mathbf{1}\\leq_{\\mathrm{e}}\\mathbf{X}_{\\mathrm{inj}}\\leq_{\\mathrm{e}}x_{\\mathrm{max}}\\cdot\\mathbf{1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\nu_{T}$ is the target node set, $d_{u}$ is the degree for node $u$ , and $\\mathbf{X}_{1}\\leq_{\\mathrm{e}}\\mathbf{X}_{2}$ indicates each element of $\\mathbf{X}_{1}$ is less than or equal to the corresponding element in $\\mathbf{X}_{2}$ . Among continuous strategies, TDGIA [36] generates node features by optimizing a feature smoothness objective function. Chen et al. [2] enhance homophily unnoticeability by adding a regularization term to the objective function. These approaches show better performance while maintaining unnoticeability at the embedding level. ", "page_idx": 2}, {"type": "text", "text": "It is worth noting that the evaluation datasets for the aforementioned GIAs are primarily TAGs [33], e.g., such as Cora and CiteSeer. However, all the studies remain at the embedding level. In our experiments, we adhere to the structural budget detailed in Equation (3), omitting embedding-level constraints as we pioneer GIAs at the text level. More related works are provided in Appendix D. ", "page_idx": 2}, {"type": "text", "text": "Evaluation Protocol. In this paper, we explore GIAs in an inductive, evasion setting, following the framework established by [33] to ensure closeness to practical scenarios. Attackers have access to the entire graph and associated labels, except for the ground-truth labels of the test set and the victim models of the defenders. l Defenders train their models on clean, unperturbed training data and then use trained models to classify unseen test data. ", "page_idx": 2}, {"type": "text", "text": "General Experiments Set-up. We conduct experiments on three TAGs, Cora [17], CiteSeer [6] and PubMed [23], which are commonly used in evaluating GIAs. The dataset statistics and attack budgets are provided in Table 5 and Table 7 in the Appendix. We adopt full splits in [33] for each dataset, which uses $60\\%$ nodes for training, $10\\%$ nodes for validation, and $30\\%$ for testing. For word embeddings techniques, we include Bag-of-Words $(\\mathbf{BoW})$ and GTR [19], a T5-based pretrained transformer that generates continuous embeddings of unit norm. The default BoW method constructs a vocabulary using raw text from the original dataset based on word frequency, with common stop-words excluded. The embedding dimension of BoW is set to 500. In the experiments, we use a 3-layer vanilla GCN or a 3-layer homophily-based defender EGNNGuard following [2]. EGNNGuard defends homophily-noticeable attacks by cutting off message-passing between nodes below the specified similarity threshold. The hyperparameters and training details are provided in Appendix H.1. We repeat each experiment 10 times and report the average performance and the standard deviation. Unless otherwise specified, we bold the best (the lowest) results. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3 Text-Level GIAs: Interpretability Matters ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Although GIAs are considered realistic graph attacks, traditional methods focus mainly on the embedding level, which can be overly idealized. Typically, attackers only have access to public raw data, such as paper content and citation networks, on platforms like arXiv, and defenders process this data more personally. Since attackers struggle to access embeddings trained by defenders, injecting nodes with suitable embeddings is challenging. Conversely, injecting new raw data into the public dataset is more realistic for attackers. This leads us to an important question: Can we generate coherent text for injection that ensures the effectiveness of attacks while maintaining interpretability? ", "page_idx": 3}, {"type": "text", "text": "3.1 Inversion-based Text-Level GIAs: Effective yet Uninterpretable ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Embedding-level GIAs have demonstrated strong attack performance against GNNs [36, 2]. To achieve text-level attacks, a straightforward idea is to use inversion methods to convert embeddings back into text. Recent advancements in text inversion methods, such as Vec2Text [18], have enabled text recovery from PLM embeddings with a $66\\%$ success rate for examples averaging 16 tokens. This breakthrough opens new possibilities for achieving text-level GIA that is comparable in performance to those at the embedding level, which we term Inversion-based Text-level GIA (ITGIA). ", "page_idx": 3}, {"type": "text", "text": "Implementation of ITGIA. ITGIA consists of two steps: generating poisoning and invertible embeddings, and then converting them into text. Since the effectiveness of current inversion methods has only been validated on normal text embeddings, it is crucial to ensure that generated embeddings lie within an interpretable and feasible region. However, defining these interpretable regions precisely is challenging. The constraint specified in Equation (3) limits generated embeddings to a cubic space, which may be overly broad for feasible embeddings. For example, PLMs typically produce embeddings located on a spherical surface with an L2-norm of 1, representing a significantly smaller region. To meet this fundamental requirement, we employ Projected Gradient Descent (PGD)[16], projecting each injected embedding onto the unit sphere after every feature update. To further address the challenge of defining interpretable regions, we incorporate Harmonious Adversarial Objective (HAO) [2] into the GIA objective function. Optimizing over HAO increases the similarity between injected embeddings and those of normal text from original datasets, thereby bringing the injected embeddings closer to interpretable regions. Details of ITGIA and HAO are provided in Appendix I.1 and H.1. Once the embeddings are obtained, we utilize the GTR inversion model in [18] with a 20-step correction process to revert embeddings back into text. ", "page_idx": 3}, {"type": "text", "text": "Analysis of Performance and Interpretability. Following [2], we use sequential injection frameworks, including the sequential variants of SeqGIA (Random injection), TDGIA, ATDGIA, MetaGIA, and AGIA as the embedding-level backbones. The results of ITGIA are displayed in Table 1. We can see the embeddings after inversion deviate significantly from the injected embeddings, as indicated by the low cosine similarity. This suggests substantial information loss during inversion, leading to poor attack performance. Figure 6 illustrates the underlying reason: although injected embeddings meet basic norm constraints, they struggle to fall within the much smaller interpretable embedding region, hindering accurate inversion. Although incorporating HAO enhances the inversion accuracy and improves attack performance, the improvement comes at the expense of embedding-level attack performance [2]. As a result, increasing HAO weights does not consistently yield better results, as shown in Figure 2. Furthermore, the generated text remains incoherent with high perplexity, as demonstrated in Appendix J. This renders real-world applications impractical and highlights the challenges faced by continuous embedding-level GIAs. ", "page_idx": 3}, {"type": "text", "text": "Table 1: Performance of GCN on graphs under ITGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cAvg. cos\u201d represents the average cosine similarity between the embeddings of the inverted text and their corresponding original embeddings across five ITGIAs. \u201cBest Emb.\u201d represents the best attack performance across the five variants at the embedding level. ", "page_idx": 4}, {"type": "table", "img_path": "oTzydUKWpq/tmp/8ed62237b6aad9e03cd1b270443d181d01bfd681bc1a9ebfdbad95a80f975f49.jpg", "table_caption": [], "table_footnote": [], "page_idx": 4}, {"type": "image", "img_path": "oTzydUKWpq/tmp/df5ff4a99732773e9afe02c8b50d964073eb15f1274128a2dc2c16f5d9740dce.jpg", "img_caption": ["Figure 2: The change of attack performance as the weight of HAO increases. Lower performance stands for better attack results. Details of the setting is given in Appendix H.1. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "3.2 LLM-based Text-Level GIAs: Interpretable yet Ineffective ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Although ITGIA manages to generate harmful text, interpretability remains challenging to address. To ensure that the generated text is both interpretable and deceptive, a direct approach is to utilize an LLM for text generation and guide it to produce poisoning content through carefully designed prompts. Based on experiences with embedding-level graph adversarial attacks, when the features of injected nodes exhibit heterophily, confusion, or irrelevance, the classification performance of their neighboring nodes is negatively affected [35]. Thus, we attempt to incorporate prior knowledge used in traditional GIAs and create prompts from three different angles: ", "page_idx": 4}, {"type": "text", "text": "Heterophily Prompt. This prompt involves sampling the text of nodes from the original dataset to generate heterophilic (dissimilar) content. Specifically, we first conduct embedding-level GIAs to obtain a perturbed graph. Next, we sample the content from the neighbors of injected nodes. Finally, we design a prompt that requests the generated content to be dissimilar to their neighboring nodes, exploiting the weakness of GNNs in handling heterophily. ", "page_idx": 4}, {"type": "text", "text": "Random Prompt. This prompt generates node text that is entirely unrelated to the original categories of the graph. For example, in the Cora dataset, the original categories are about machine learning topics. In this prompt, we generate papers in categories like sports, art, and history, which are dissimilar to all nodes in the original graph. ", "page_idx": 4}, {"type": "text", "text": "Mixing Prompt. This prompt generates node text that may be classified into multiple or even all categories. Using Cora as an example, a potential paper title could be: \u201cUnified Approach for Solving Complex Problems using Integrated Rule Learning, Neural Networks, and Probabilistic Methods\u201d. ", "page_idx": 4}, {"type": "text", "text": "After defining the prompts, we propose a simple Vanilla Text-level GIA (VTGIA). This method first generates text for the injected nodes based on the prompt via LLMs and subsequently optimizes the graph structure. We use GPT-3.5-1106 [20] as the LLM backbone for text generation, and the five sequential injection backbones same as ITGIA. The pseudo-code of VTGIA, prompts, and generated examples are provided in Appendix I.2, H.2, and J. The results are shown in Table 2. Although the generated content exhibits adversarial effects, directly producing harmful text via prompts is not sufficiently effective and is far from the optimal results achievable by attacks at the embedding level. ", "page_idx": 4}, {"type": "table", "img_path": "oTzydUKWpq/tmp/7061b430498980bc827a006cd76a445e6e744c8540b96fdbe5a2afb4029ab70a.jpg", "table_caption": ["Table 2: Performance of GCN against VTGIA. Raw text is embedded by GTR before being fed to GCN for evaluation. \u201cBest Emb.\u201d refers to the best-performing embedding-level GIAs that directly update embeddings across various injection strategies. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "4 Word-Frequency-based Text-Level GIAs ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Based on previous analysis, to achieve an interpretable and effective GIA, the following conditions should be met: 1) Guidance from Embedding-level GIA to ensure effectiveness. 2) Utilization of LLMs to guarantee interpretability. 3) A well-defined LLM task formulation to minimize information loss during the embedding-text-embedding conversion process. ", "page_idx": 5}, {"type": "text", "text": "We address these conditions by employing word-frequency-based embeddings, specifically binary Bag-of-Words (BoW) embeddings, which offer several advantages: 1) Clear physical meaning. In binary BoW embeddings, a \u20181\u2019 indicates the presence of a word, while a $\\surd0\\ '$ indicates its absence. 2) Clear task formulation. The task involves generating text containing specified words while excluding prohibited words, which can be effectively done via LLMs. 3) Controllable embedding-textembedding process. As long as the text includes specified words and excludes prohibited words, the embeddings can be exactly inverted. Building on these advantages, we design the Word-frequencybased Text-level GIA (WTGIA), leveraging BoW embeddings and the generative capabilities of LLMs. Its implementation consists of three steps: 1) Obtain binary injected embeddings. 2) Formulate embedding to text tasks for LLMs. 3) Perform multi-round corrections for LLMs. ", "page_idx": 5}, {"type": "text", "text": "4.1 Row-wise Constrained FGSM: Unnoticeable and Effective at the Embedding Level ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Implementaion of Row-wise Constrainted FGSM. To generate binary embeddings, we adopt a row-wise constrained Fast Gradient Sign Method (FGSM) algorithm based on [28]. Specifically, we first obtain vocabulary based on BoW on the original dataset. Next, we set the injected embedding $\\mathbf{X}_{\\mathrm{inj}}$ to all zeros. We then set a sparsity constraint $S$ on injected embeddings, that each embedding can retain at most $F^{\\prime}=\\lfloor S*F\\rfloor$ non-zero entries, where $F$ is the dimension of features. In each epoch, we define the flippable set as the entries in $\\mathbf{X}_{\\mathrm{inj}}$ that satisfy the sparsity constraint. Based on the element-wise gradient of the loss concerning $\\mathbf{X}_{\\mathrm{inj}}$ , we filp the most significant $B$ entries from the flippable set, where $B$ is the batch size. The process stops when all rows run out of word budgets. 2 ", "page_idx": 5}, {"type": "text", "text": "Note that the sparsity budget $S$ is a hyper-parameter that limits the use of at most $F^{\\prime}$ words from the predefined vocabulary in a single text. Intuitively, a higher number of used words intensifies the embedding-level attack but can compromise text-level interpretability, as it becomes harder to integrate more specified words naturally in the generated text. Based on the row-wise constraints, we can formally establish the relationship between embedding-level performance and unnoticeability and text-level interpretability. ", "page_idx": 5}, {"type": "text", "text": "Definition 1 (Single node GIAs towards one-hot embedding). For a target node $v_{t}$ with embedding \u2022 Performance: An attack is more effective against node $v_{t}$ if it uses more words $w_{n}\\in W_{n}$ . The intuition is that mixing words from other classes makes $x_{t}$ harder to be correctly classified. ", "page_idx": 5}, {"type": "image", "img_path": "oTzydUKWpq/tmp/4e3490b9feea34f1d7b65448765f21fb60b49a35398fb831e144b7af6996aa04.jpg", "img_caption": ["Figure 3: The Best and Average performance of FGSM against GCN and EGNNGuard among the five injection methods w.r.t increasing sparsity budgets. The results for EGNNGuard reveal that as the budget increases, FGSM attacks can satisfy the similarity constraint while significantly enhancing the attack performance at the embedding level. "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "\u2022 Unnoticeability: An attack is less detectable if the similarity between $x_{t}$ and $x_{i}$ is higher. ", "page_idx": 6}, {"type": "text", "text": "\u2022 Interpretability: An attack is more interpretable if fewer words are required to use in $x_{i}$ , which means ${x}_{i}\\cdot\\mathbf{1}$ is smaller. The intuition is that generating content with fewer specified words is easier, which fits in practical scenarios involving limited length. ", "page_idx": 6}, {"type": "text", "text": "Theorem 1. In the setting outlined in Definition $^{\\,l}$ , assume we apply a cosine similarity constraint with a threshold $c\\in(0,1)$ for unnoticeability. Specifically, this constraint requires that the cosine similarity between $x_{t}$ and $x_{i}$ satisfies $\\frac{x_{t}\\cdot x_{i}}{\\|x_{t}\\|\\|x_{i}\\|}>c$ . Let a denotes the number of words used by $x_{i}$ from the set $W_{u}$ , and $b$ denotes the number of words used by $x_{i}$ from $W_{n}$ . If the budget is m words at most to ensure interpretability, then the maximum value of $b\\,i s\\operatorname*{max}(b)=\\operatorname*{max}\\left(\\lfloor(m-c{\\sqrt{m k}}\\rfloor,0\\right)$ ", "page_idx": 6}, {"type": "text", "text": "The proof and detailed illustration for intuitions are provided in Appendix F. Theorem 1 reveals that as long as $m\\geq k$ , we can find a positive value for $b$ (disregarding the flooring operation for simplicity), effectively introducing harmful information to the target node. Practically, given the typically low value of $c$ , a destructive $x_{i}$ can be easily identified with a relatively large $m$ at the embedding level. In Figure 3, we present the average and best performance of Row-wise Constrained FGSM coupled with five sequential injection methods used in ITGIA and VTGIA against GCN and EGNNGuard. As the sparsity budget increases, the performance of EGNNGuard declines sharply, confirming that enhancements in performance are possible under the unnoticeability constraint. However, achieving significant performance degradation requires sacrificing interpretability. For example, to achieve a $10\\%$ performance drop in Cora and CiteSeer, FGSM attacks need a budget close to or exceed the maximum sparsity level of all texts belonging to the original datasets. The subsequent subsection will explore the consequences of sacrificing text-level interpretability while completing WTGIA. ", "page_idx": 6}, {"type": "text", "text": "4.2 Trade-off for Interpretability at the Text Level ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Task Formulation of LLMs. After obtaining the binary injected embeddings, we can obtain the Specified words included and the Prohibited words excluded in each text based on the BoW vocabulary. Subsequently, we formulate the task for LLMs as a \"word-to-text\" generation problem. We request LLMs to generate text under a specified length limit using specified words, optionally within a given topic based on the origin dataset. 3 Handling prohibited words is more complex. Given the sparsity of BoW embeddings, the number of prohibited words is relatively large. Directly requesting the absence of prohibited words through the prompt would be challenging for LLMs to understand. So, for closed-source LLMs like GPT, we only constrain the specified words in the prompt. For open-source LLMs, we mask their corresponding entries during the output process. ", "page_idx": 6}, {"type": "text", "text": "Masking Prohibited Words. Denote $t_{i+1}$ as the next token at time $i$ . The standard generative process for LLM can be formulated as: $t_{i+1}~=$ argmax (SoftMax (logits $(t_{i+1}\\mid t_{i},t_{i-1},\\ldots))$ . ", "page_idx": 6}, {"type": "text", "text": "where logits $(t_{i+1}\\mid t_{i},t_{i-1},.\\;.\\;.)$ are the unnormalized log probabilities of the potential next token given the previous tokens. To enforce constraints on avoiding prohibited words, we introduce a masking vector $M$ such that: $M[j]\\;=\\;0$ if token $j$ is prohibited, and 1 otherwise. The generative process is then modified by applying this mask to the logits before the SoftMax operation: $t_{i+1}=$ argmax (SoftMax (logits $(t_{i+1}\\mid t_{i},t_{i-1},.\\;.\\;.)\\odot M))$ ), where $\\odot$ represents the element-wise multiplication of the logits by the mask. This mask effectively removes words from outputs by making their probabilities negligible. ", "page_idx": 7}, {"type": "text", "text": "Multi-Round Correction. After obtaining the output from the LLM, we calculate the use rate NuNmubemrb oefr  Sofp eScpiefcieidf ieWd owrdosr dussed in the generated text and correct any omissions in their usage. Through multiple rounds of dialogue, we select the text with the highest use rate as the final output for LLMs. ", "page_idx": 7}, {"type": "text", "text": "Main Results. We utilized GPT3.5-turbo-1106 [20] as the close-source LLM and Llama3-8b [26] as the open-source LLM to implement the WTGIA. Based on Row-wise FGSM in Figure 3, we combine WTGIA with the five injection strategies and report the average results. The specific prompt details are in Appendix H.2. The length limit is specified in Table 6. The variants that use prompts that specify the generated content must belong to the original class set are marked as \"-T.\" The results are displayed in Figure 4. It can be seen that ", "page_idx": 7}, {"type": "text", "text": "\u2022 Desirable Performance: WTGIA achieves comparable attack performance to Row-wise FGSM, demonstrating strong embedding-to-text capabilities.   \n\u2022 Trade-off: Variants with topic specification perform worse than those without, sacrificing attack strength for better text-level unnoticeability.   \n\u2022 Masking Helps: Llama-WM and GPT that do not mask prohibited words generally perform worse than Llama. ", "page_idx": 7}, {"type": "text", "text": "Complete experiments and full results are given in Appendix K and Appendix L. Overall, WTGIA effectively replicates the performance of FGSM at the embedding level, achieving both effectiveness and interoperability. ", "page_idx": 7}, {"type": "image", "img_path": "oTzydUKWpq/tmp/8383870b7ff958ddb34ab461998c8ea3ce362e2a5b8e6735362bc761f5cd3f39.jpg", "img_caption": ["Figure 4: Performance of WTGIA against GCN. Sparsity budget is the average sparsity of the original dataset. Methods with -T include topic requirements in the prompt. Methods with -WM exclude masks for prohibited words in Llama. Avg Emb. represents the average FGSM attack performance at the embedding level. Lower values indicate better attack performance. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "New Trade-offs. However, we fail to further enhance performance at the text level by increasing the sparsity budget, similar to FGSM at the embedding level. As shown in Figure 5, with the increasing sparsity budget, the use rate keeps decreasing, representing a trade-off to maintain the interpretability of the generated content. In Cora and CiteSeer, the text-level attacks perform best when sparsity is around $10\\%$ . In PubMed, GPT-Topic even fails to generate meaningful text with a sparsity budget $S\\ge15\\%$ . These observations confirm that in text-level attacks, interpretability represents an additional trade-off that is overlooked in embedding-level attacks. Enhancing or evaluating performance solely at the embedding level fails to provide a practical understanding of GIAs. ", "page_idx": 7}, {"type": "image", "img_path": "oTzydUKWpq/tmp/b1dd5ffd297dc190c7ce726a94bf409f3442353131d9453b8d8dbc67e7357fb2.jpg", "img_caption": ["Figure 5: The performance of WTGIA w/o topic against GCN w.r.t sparsity budget. As the budget increases, the use rate keeps decreasing, and the attack performance increases and then decreases. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "5 New Challenges for Text-level GIAs ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "5.1 Transferbility to Different Embeddings ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In practical scenarios, defenders can employ any text embedding techniques they want to process the text once an attacker completes the injection. However, embedding-level attacks implicitly assume that defenders will use the same embeddings as the attackers during evaluation, potentially beneftiing the attackers. In fact, it is crucial to fully consider the transferability of a text attack across different text embedding technologies for text-level attacks. ", "page_idx": 8}, {"type": "text", "text": "In Table 3, we present the results of ITGIA and WTGIA when transferred to different embeddings on the Cora dataset. When transferred to GTR embeddings, WTGIA does not exhibit a significant performance advantage over ITGIA. The performance of ITGIA when transferred to BoW embeddings is even poorer. Since the injected text is highly uninterpretable and deviates significantly from the original dataset, the BoW method inherently filters out uncommon terms, rendering the injected embeddings particularly sparse and ineffective. These limitations in embedding transferability underscore the research gaps between embedding- and text-level GIAs. ", "page_idx": 8}, {"type": "table", "img_path": "oTzydUKWpq/tmp/88862b77faa85a7e0fd33ca5a97add27b3108fe6030a183fa12a53f45d75a848.jpg", "table_caption": ["Table 3: Performance of ITGIA and WTGIA-Llama transferred to different embeddings on Cora. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.2 LLMs as Defender ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Since attacks are text-level, the defenders can directly utilize LLMs as predictors for node classification tasks without necessarily employing GNNs. Taking the LLMs-as-Predictor from [3] as an example. The method feeds the formulation of the node classification task, texts of target nodes, and optionally, the sampled texts of their neighbors in the prompt. It then utilizes LLMs to predict the labels of target nodes directly. Remarkably, this method demonstrates superior performance on clean datasets. We now examine the performance of WTGIA against LLMs-as-predictor from [3]. For WTGIA, we select the strongest variant in Figure 4 for each dataset as the attacker. In the zero-shot setting, only the text of target nodes is fed to LLMs. In the few-shot setting, the text of labeled nodes with their labels is fed to LLMs as examples. On Cora and CiteSeer, we adopt the whole test set for evaluation. For PubMed, we sample 1000 nodes from the test set for evaluation. ", "page_idx": 8}, {"type": "text", "text": "The results are presented in Table 4. Remarkably, on the PubMed dataset, the baseline without the use of neighborhood information (\u201cClean (w/o Nei)\u201d) achieves outstanding performance, which is consistent with observations in [3]. Therefore, even without utilizing any neighborhood information, LLM-based predictors can achieve high accuracy in node classification, meaning defenders can evade the influence of injected nodes. For other datasets, Cora and CiteSeer, while incorporating neighborhood information enhances the performance of LLMs-as-Predictors, the \"Clean (w/o Nei.)\" ", "page_idx": 8}, {"type": "table", "img_path": "oTzydUKWpq/tmp/1039b2c06f66c3029583c45477fe8824fea25edeb07c6865acec169835ea5013.jpg", "table_caption": ["Table 4: The performance of WTGIA against LLMs-as-predictor. The term \u201c(w/o Nei.)\u201d means the exclusion of neighborhood information in the prompt. Methods \"Clean (w/o Nei.)\" and \"WTGIA (w Nei.)\" can be used as LLM-based defenders. The best results for defenders are bold. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "baseline still represents a practical upper limit for the GIAs. Even if attackers manage to degrade the performance below this baseline, defenders can turn to this neighbor-free method as a secure fallback. Consequently, the flexibility of defenders should be fully considered when evaluating GIAs at the text level in practical scenarios. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we explore the design of GIAs at the text level. We address the limitations of embeddinglevel GIAs on TAGs by extending them to the text level, which better aligns with real-world scenarios. We present three types of text-level GIA designs: ITGIA, VTGIA, and WTGIA. Our theoretical and empirical analysis reveals a trade-off between attack performance and the interpretability of the injected text. Among these methods, WTGIA achieves the best balance between performance and interpretability. Additionally, our findings indicate that defenders can effectively counter these attacks using different text embedding techniques or LLM-based predictors, highlighting the complex and challenging nature of graph adversarial attacks in practical applications. ", "page_idx": 9}, {"type": "text", "text": "7 Acknowledgement ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This research was supported in part by National Natural Science Foundation of China (No. U2241212, No. 61932001), by National Science and Technology Major Project (2022ZD0114802), by Beijing Natural Science Foundation (No. 4222028), by Beijing Outstanding Young Scientist Program No.BJJWZYJH012019100020098, By Huawei-Renmin University joint program on Information Retrieval. We also wish to acknowledge the support provided by the fund for building worldclass universities (disciplines) of Renmin University of China, by Engineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Education, Intelligent Social Governance Interdisciplinary Platform, Major Innovation & Planning Interdisciplinary Platform for the \u201cDouble-First Class\u201d Initiative, Public Policy and Decision-making Research Lab, and Public Computing Cloud, Renmin University of China. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] MV Balashov, BT Polyak, and AA Tremba. Gradient projection and conditional gradient methods for constrained nonconvex minimization. Numerical Functional Analysis and Optimization, 41(7):822\u2013849, 2020.   \n[2] Yongqiang Chen, Han Yang, Yonggang Zhang, Kaili Ma, Tongliang Liu, Bo Han, and James Cheng. Understanding and improving graph injection attack by promoting unnoticeability. In The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022.   \n[3] Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei, Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, and Jiliang Tang. Exploring the potential of large language models (llms) in learning on graphs. CoRR, abs/2307.03393, 2023.   \n[4] Junyuan Fang, Haixian Wen, Jiajing Wu, Qi Xuan, Zibin Zheng, and K Tse Chi. Gani: Global attacks on graph neural networks via imperceptible node injections. IEEE Transactions on Computational Social Systems, 2024.   \n[5] Simon Geisler, Tobias Schmidt, Hakan Sirin, Daniel Z\u00fcgner, Aleksandar Bojchevski, and Stephan G\u00fcnnemann. Robustness of graph neural networks at scale. In Marc\u2019Aurelio Ranzato, Alina Beygelzimer, Yann N. Dauphin, Percy Liang, and Jennifer Wortman Vaughan, editors, Advances in Neural Information Processing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual, pages 7637\u20137649, 2021. [6] C. Lee Giles, Kurt D. Bollacker, and Steve Lawrence. Citeseer: An automatic citation indexing system. In Proceedings of the 3rd ACM International Conference on Digital Libraries, June 23-26, 1998, Pittsburgh, PA, USA, pages 89\u201398. ACM, 1998. [7] Jiayan Guo, Lun Du, and Hengyu Liu. Gpt4graph: Can large language models understand graph structured data? an empirical evaluation and benchmarking. CoRR, abs/2305.15066, 2023. [8] William L. Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, pages 1024\u20131034, 2017. [9] Xiaoxin He, Xavier Bresson, Thomas Laurent, and Bryan Hooi. Explanations as features: Llm-based features for text-attributed graphs. CoRR, abs/2305.19523, 2023.   \n[10] Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. In Hugo Larochelle, Marc\u2019Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin, editors, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual, 2020.   \n[11] Xuanwen Huang, Kaiqiao Han, Yang Yang, Dezheng Bao, Quanjin Tao, Ziwei Chai, and Qi Zhu. Can GNN be good adapter for llms? In Tat-Seng Chua, Chong-Wah Ngo, Ravi Kumar, Hady W. Lauw, and Roy Ka-Wei Lee, editors, WWW, pages 893\u2013904. ACM, 2024.   \n[12] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings, 2015.   \n[13] Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings. OpenReview.net, 2017.   \n[14] Yuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, and Jeffrey Xu Yu. A survey of graph meets large language model: Progress and future directions. CoRR, abs/2311.12399, 2023.   \n[15] Jiawei Liu, Cheng Yang, Zhiyuan Lu, Junze Chen, Yibo Li, Mengmei Zhang, Ting Bai, Yuan Fang, Lichao Sun, Philip S. Yu, and Chuan Shi. Towards graph foundation models: A survey and beyond. CoRR, abs/2310.11829, 2023.   \n[16] Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018.   \n[17] Andrew McCallum, Kamal Nigam, Jason Rennie, and Kristie Seymore. Automating the construction of internet portals with machine learning. Inf. Retr., 3(2):127\u2013163, 2000.   \n[18] John X. Morris, Volodymyr Kuleshov, Vitaly Shmatikov, and Alexander M. Rush. Text embeddings reveal (almost) as much as text. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023, pages 12448\u201312460. Association for Computational Linguistics, 2023.   \n[19] Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Hern\u00e1ndez \u00c1brego, Ji Ma, Vincent Y. Zhao, Yi Luan, Keith B. Hall, Ming-Wei Chang, and Yinfei Yang. Large dual encoders are generalizable retrievers. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, pages 9844\u20139855. Association for Computational Linguistics, 2022.   \n[20] OpenAI. Gpt-3.5-turbo. https://openai.com/, 2023. Accessed via OpenAI API.   \n[21] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019. ", "page_idx": 10}, {"type": "text", "text": "[22] Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. In Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan, editors, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, pages 3980\u20133990. Association for Computational Linguistics, 2019.   \n[23] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Gallagher, and Tina Eliassi-Rad. Collective classification in network data. AI Mag., 29(3):93\u2013106, 2008.   \n[24] Xiangguo Sun, Jiawen Zhang, Xixi Wu, Hong Cheng, Yun Xiong, and Jia Li. Graph prompt learning: A comprehensive survey and beyond. CoRR, abs/2311.16534, 2023.   \n[25] Yiwei Sun, Suhang Wang, Xianfeng Tang, Tsung-Yu Hsieh, and Vasant G. Honavar. Adversarial attacks on graph neural networks via node injections: A hierarchical reinforcement learning approach. In WWW \u201920: The Web Conference 2020, Taipei, Taiwan, April 20-24, 2020, pages 673\u2013683. ACM / IW3C2, 2020.   \n[26] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aur\u00e9lien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. Llama: Open and efficient foundation language models. CoRR, abs/2302.13971, 2023.   \n[27] Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, and Yoshua Bengio. Graph attention networks. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings. OpenReview.net, 2018.   \n[28] Jihong Wang, Minnan Luo, Fnu Suya, Jundong Li, and Zijiang Yang and $==$ Qinghua Zheng. Scalable attack on graph data by injecting vicious nodes. Data Min. Knowl. Discov., 34(5):1363\u20131389, 2020.   \n[29] Xiaoyun Wang, Joe Eaton, Cho-Jui Hsieh, and Shyhtsun Felix Wu. Attack graph convolutional networks by adding fake nodes. CoRR, abs/1810.10751, 2018.   \n[30] Lingfei Wu, Peng Cui, Jian Pei, Liang Zhao, and Xiaojie Guo. Graph neural networks: Foundation, frontiers and applications. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2023, Long Beach, CA, USA, August 6-10, 2023, pages 5831\u20135832. ACM, 2023.   \n[31] Kaidi Xu, Hongge Chen, Sijia Liu, Pin-Yu Chen, Tsui-Wei Weng, Mingyi Hong, and Xue Lin. Topology attack and defense for graph neural networks: An optimization perspective. In Sarit Kraus, editor, Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019, pages 3961\u20133967. ijcai.org, 2019.   \n[32] Ruosong Ye, Caiqi Zhang, Runhui Wang, Shuyuan Xu, and Yongfeng Zhang. Natural language is all a graph needs. CoRR, abs/2308.07134, 2023.   \n[33] Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang, and Jie Tang. Graph robustness benchmark: Benchmarking the adversarial robustness of graph machine learning. In Proceedings of the Neural Information Processing Systems Track on Datasets and Benchmarks 1, NeurIPS Datasets and Benchmarks 2021, December 2021, virtual, 2021.   \n[34] Yanping Zheng, Lu Yi, and Zhewei Wei. A survey of dynamic graph neural networks. Frontiers of Computer Science, 19(6):196323, 2025.   \n[35] Jiong Zhu, Junchen Jin, Donald Loveland, Michael T. Schaub, and Danai Koutra. How does heterophily impact the robustness of graph neural networks?: Theoretical connections and practical implications. In Aidong Zhang and Huzefa Rangwala, editors, KDD \u201922: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022, pages 2637\u20132647. ACM, 2022.   \n[36] Xu Zou, Qinkai Zheng, Yuxiao Dong, Xinyu Guan, Evgeny Kharlamov, Jialiang Lu, and Jie Tang. TDGIA: effective injection attacks on graph neural networks. In KDD \u201921: The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, Virtual Event, Singapore, August 14-18, 2021, pages 2461\u20132471. ACM, 2021.   \n[37] Daniel Z\u00fcgner, Amir Akbarnejad, and Stephan G\u00fcnnemann. Adversarial attacks on neural networks for graph data. In Yike Guo and Faisal Farooq, editors, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD 2018, London, UK, August 19-23, 2018, pages 2847\u20132856. ACM, 2018.   \n[38] Daniel Z\u00fcgner and Stephan G\u00fcnnemann. Adversarial attacks on graph neural networks via meta learning. In 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019. ", "page_idx": 11}, {"type": "text", "text": "A Broader Impacts ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In this paper, we potentially aid in developing more advanced and sophisticated attacks through understanding text-level vulnerabilities and providing significant positive impacts by enhancing the design of robust defense mechanisms. By pioneering the exploration of text-level GIAs, we enable the creation of more effective countermeasures to protect against these advanced threats, thereby improving the overall security and resilience of systems that rely on GNNs. This dual impact highlights the importance of our work in driving both offensive and defensive advancements, ultimately contributing to safer and more secure AI applications. ", "page_idx": 12}, {"type": "text", "text": "B Open Access to Data and Code ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "GPT-turbo: https://openai.com/. In this paper, we use the GPT-3.5-turbo model provided by OpenAI for generating textual data. The model was accessed through OpenAI\u2019s API services, and all uses were in compliance with the terms of service provided by OpenAI. ", "page_idx": 12}, {"type": "text", "text": "Llama3: https://github.com/meta-llama/llama3?tab $\\mid=$ readme-ov-file. In this paper, we use Meta Llama 3, which is governed by the Meta Llama 3 Community License Agreement (Meta Platforms, Inc., released April 18, 2024). This tool is employed strictly in accordance with the terms set forth in the licensing agreement and Meta\u2019s Acceptable Use Policy. ", "page_idx": 12}, {"type": "text", "text": "Raw Data and LLMs-as-Predictors: https://github.com/CurryTang/Graph-LLM. (MIT License). ", "page_idx": 12}, {"type": "text", "text": "GIA-HAO: https://github.com/LFhase/GIA-HAO. (MIT License) ", "page_idx": 12}, {"type": "text", "text": "C Device Information ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "All our experiments are conducted on a machine with an NVIDIA A100-SXM4 (80GB memory), Intel Xeon CPU $(2.30\\,\\mathrm{GHz})$ , and 512GB of RAM. ", "page_idx": 12}, {"type": "text", "text": "D More Related Works ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Graph Injection Attacks. Graph Injection Attacks aim to decrease the performance of GNNs by injecting suspicious nodes into the original graph. The newly injected nodes are allowed to process fake features and form connections with existing nodes on the graph. Wang et al. [29] first attempt to inject fake nodes to degrade the performance of GNNs. NIPA [25] applies reinforcement learning to make graph injection decisions. AFGSM [28] uses an approximation strategy to linear the model and solve the objective function efficiently. TDGIA [36] selects edges for newly added edges based on a topological defective edge selection strategy. It then generates node features by optimizing a proposed feature smooth objective function. Chen et al. [2] add a regularization term to the existing objective function for GIA to improve homophily unnoticeability. GANI [4] employs a statistics-based approach to calculate node features, ensuring the generated features remain unnoticeable but leading to a significant decline in performance. All the GIAs mentioned are designed at the embedding level. Despite some constraints being applied to the injected features, the semantic coherence and logical consistency of generated features at the text level remain unexplored. ", "page_idx": 12}, {"type": "text", "text": "Graph Modification Attacks. Graph Modification Attacks aim to decrease the performance of GNNs by modifying the graph structure or node features of the original graphs. Nettack [37] adopts a greedy strategy to select edge and node feature perturbations with unnoticeability constraints. Z\u00fcgner et al. [38] treat the graph structure as a hyperparameter and use meta-gradients to solve the bilevel poisoning attack objective. Xu et al. [31] use Projected Gradient Descent (PGD) to find the best perturbation matrix. The above algorithms significantly degrade the performance of GNNs, yet all require $O(N^{2})$ space complexity. To address the scalability issues, Geisler et al. [5] propose PRBCD and GRBCD using Randomized Block Coordinate Descent. The algorithms are of $\\bar{O}(\\bar{|\\mathcal{E}|})$ time and space complexity and can be scaled up to datasets containing more than 1 million nodes. ", "page_idx": 12}, {"type": "text", "text": "Raw Text learning on TAGs. With the development of LLMs, works combining them with GNNs have continuously emerged, showing outstanding performance in various graph-related tasks on ", "page_idx": 12}, {"type": "text", "text": "TAGs. TAPE [9] uses LLMs as a feature enhancer to obtain high-quality node features. In InstructGLM [32], the authors propose scalable prompts based on natural language instructions that describe the topological structure of a graph. Guo et al. [7] analyze the ability of LLMs to understand graph data and solve graph-related tasks. Chen et al. [3] conduct a benchmark evaluating the performance of LLMs as the feature enhancer and the predictor, respectively. More related works about LLMs in Graph could be referred to [15, 24, 14]. Although LLMs have seen numerous applications in graph tasks, works exploring the robustness of GNNs are still sparse. ", "page_idx": 13}, {"type": "text", "text": "Although Graph Modification Attacks are powerful attacks, recent works point out that they do not align well with real-world attack scenarios [33], and they are theoretically inferior to GIAs in attack performance [2]. Moreover, while raw texts are proven to be helpful in improving the performance of graph tasks, works exploring the robustness of GNNs at the text level are still sparse. ", "page_idx": 13}, {"type": "text", "text": "E Datatset Statistics and Budgets of Attacks ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Dataset information is summarized in Table 5 and Table 6. The budget of GIAs is summarized in Table 7. ", "page_idx": 13}, {"type": "table", "img_path": "oTzydUKWpq/tmp/435903447d4aa20d0e7286da24697618e6416b0fe6f5a980b80f63c7e66db802.jpg", "table_caption": ["Table 5: Statistics of datasets. Edges (UnD.) stands for the number of edges after transforming each dataset into undirected. Avg.(Max) Sparsity stands for the average (max) percentage of non-zero elements in BoW embeddings of the raw texts. "], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "Table 6: The statistics reflect the number of words used in each dataset. \"Avg.\" represents the average word count per dataset, while \"Std.\" indicates the standard deviation of word counts. Assuming a normal distribution of word lengths, \"Avg. $^+$ 2Std.\" denotes the upper bound of the $95\\%$ confidence interval. This metric is employed as a benchmark for establishing maximum word/token limits in paper generation experiments. ", "page_idx": 13}, {"type": "table", "img_path": "oTzydUKWpq/tmp/51955048bcc292a5d63ba332e8afa482940f41f0e5b979e4e576befe776bbee5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 13}, {"type": "table", "img_path": "oTzydUKWpq/tmp/8f89e8ad1f48db5c6d40d4458d192f528e1a5f2c5c52ac80783e59bb68a7235b.jpg", "table_caption": ["Table 7: Attack budgets on the datasets. "], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "F Further Illustration and Proof to Theorem 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "The formulation for Theorem 1 relies on the below intuitions. ", "page_idx": 13}, {"type": "text", "text": "\u2022 Performance: An attack is more effective against node $v_{t}$ if it uses more words $w_{n}\\in W_{n}$ . ", "page_idx": 14}, {"type": "text", "text": "\u2022 Unnoticeability: An attack is less detectable if the similarity between $x_{t}$ and $x_{i}$ is higher. \u2022 Interpretability: An attack is more interpretable if fewer words are required to use, where the ${x}_{t}\\cdot\\mathbf{1}$ is smaller. ", "page_idx": 14}, {"type": "text", "text": "In the intuition behind performance, we actually believe that words beneficial to the classification of the target node are located in $W_{u}$ , while words detrimental to the classification of the target node are located in $W_{n}$ . However, strictly speaking, not all words in $W_{n}$ have a negative impact on the classification of the target node. Additionally, when a certain amount of classification words is introduced, the negative impact becomes marginal and does not consistently increase. Therefore, using more words $w_{n}\\in W_{n}$ does not linearly correspond to higher performance. ", "page_idx": 14}, {"type": "text", "text": "However, this does not affect the insight provided by Theorem 1. Since $k\\ll F$ , the continuous increase in the usage of $w_{n}\\in W_{n}$ within a certain range is significant. Since we do not consider situations where $m\\gg k$ , we indeed focus on \u201cuses more words $w_{n}\\;\\in\\;W_{n}$ in a certain range\u201d intrinsically. Thus, under this premise, the theorem\u2019s description of performance remains applicable. ", "page_idx": 14}, {"type": "text", "text": "Proof. The problem is formulated as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{max}\\quad b}\\\\ &{\\mathrm{s.t.}\\quad a+b\\leq m,}\\\\ &{\\quad\\quad\\frac{a}{\\sqrt{k}\\sqrt{a+b}}\\geq c.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "From inequality (6), we obtain: ", "page_idx": 14}, {"type": "equation", "text": "$$\na^{2}-c^{2}k a-c^{2}k b\\geq0,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which leads to: ", "page_idx": 14}, {"type": "equation", "text": "$$\na\\geq\\frac{c\\left(c k+\\sqrt{k(4b+c^{2}k)}\\right)}{2}\\quad\\mathrm{or}\\quad a\\leq\\frac{c\\left(c k-\\sqrt{k(4b+c^{2}k)}\\right)}{2}<0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $a$ is positive, the only feasible solution is: ", "page_idx": 14}, {"type": "equation", "text": "$$\na\\geq{\\frac{c\\left(c k+{\\sqrt{k(4b+c^{2}k)}}\\right)}{2}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "By substituting this into equation (5), we obtain: ", "page_idx": 14}, {"type": "equation", "text": "$$\nb\\leq m-a\\leq m-{\\frac{c\\left(c k+{\\sqrt{k(4b+c^{2}k)}}\\right)}{2}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Solving the resulting inequality with respect to $b$ , we find: ", "page_idx": 14}, {"type": "equation", "text": "$$\nb\\leq m-c{\\sqrt{m k}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, the solution to the maximization problem is: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{max}(b)=\\left\\lfloor m-c{\\sqrt{m k}}\\right\\rfloor.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "G Collections of Illustrations ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "G.1 Illustration of Interpretable Regions ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The illustration of interpretable regions is provided in Figure 6. ", "page_idx": 14}, {"type": "image", "img_path": "oTzydUKWpq/tmp/19290e47bf27db4508ff1db389190eb7bb43fd651103b3c3a60eee71c1c04044.jpg", "img_caption": [], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Figure 6: Illustration of the interpretable regions. Left: Feasible solution set under constraints (3). Middle: The theoretically feasible set of PLM embeddings. Right: Subset of embeddings corresponding to interpretable texts, representing a narrower selection within the feasible sets. ", "page_idx": 15}, {"type": "text", "text": "G.2 Alternative for PGD in ITGIA ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In addition to the methods mentioned in the main body of the paper, we also considered using the Riemannian Gradient Descent as a way to obtain the embedding for ITGIA. This method performs gradient descent in the tangent space of the sphere to ensure the resulting embedding\u2019s normality. ", "page_idx": 15}, {"type": "text", "text": "Formally, to solve the optimization problem ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{\\underset{x}{\\operatorname*{min}}}}&{f(x)}\\\\ {\\mathrm{subject\\,to}}&{\\|x\\|=1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "using Riemannian gradient descent, we follow these steps: ", "page_idx": 15}, {"type": "text", "text": "Initialization: Start with an initial point $x_{0}$ such that $\\|x_{0}\\|=1$ . ", "page_idx": 15}, {"type": "text", "text": "Gradient Calculation: At each iteration $k$ , compute the Euclidean gradient $\\nabla f(x_{k})$ . ", "page_idx": 15}, {"type": "text", "text": "Projection onto Tangent Space: Project the Euclidean gradient onto the tangent space of the sphere at xk: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\nabla_{R}f(x_{k})=\\nabla f(x_{k})-\\langle\\nabla f(x_{k}),x_{k}\\rangle x_{k},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\nabla_{R}f(x_{k})$ is the Riemannian gradient. ", "page_idx": 15}, {"type": "text", "text": "Update Step: Move in the direction of the Riemannian gradient and re-project onto the sphere: ", "page_idx": 15}, {"type": "equation", "text": "$$\nx_{k+1}={\\mathrm{Proj}}_{\\mathbb{S}}(x_{k}-\\alpha_{k}\\nabla_{R}f(x_{k})),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\alpha_{k}$ is the step size and $\\begin{array}{r}{\\mathrm{Proj_{S}}(y)=\\frac{y}{\\|y\\|}}\\end{array}$ ensures that the updated point lies on the sphere. ", "page_idx": 15}, {"type": "text", "text": "Iteration: Repeat steps 2-4 until convergence. ", "page_idx": 15}, {"type": "text", "text": "The PGD method we adopted can be regarded as the variant of Riemannian Gradient Descent without the \u201cProjection onto Tangent Space\u201d step. Although the Riemannian Gradient Descent has better theoretical properties [1], since we did not observe significant advantages over PGD in our experiments, we opted for the simplicity of using PGD, as discussed in the main body of our paper. ", "page_idx": 15}, {"type": "text", "text": "G.3 Illustration of Co-occurrence Constraint ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The co-occurrence constraint in [28] requires that columns that do not appear together in the original dataset must not appear together in the injected embeddings either. ", "page_idx": 15}, {"type": "text", "text": "Let $\\mathbf{X}$ be a binary feature matrix with dimensions $N\\times F$ , where $N$ represents the number of samples and $F$ represents the number of features. Each element $x_{i j}$ in the matrix $\\mathbf{X}$ is defined as: ", "page_idx": 15}, {"type": "equation", "text": "$$\nx_{i j}={\\left\\{\\begin{array}{l l}{1}&{{\\mathrm{if~word~}}j{\\mathrm{~is~present~in~text}}i,}\\\\ {0}&{{\\mathrm{otherwise}}.}\\end{array}\\right.}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The co-occurrence matrix $\\mathbf{C}$ is then an $F\\times F$ matrix where each element $c_{i j}$ , representing the pair of words $i$ and $j$ , is computed as follows: ", "page_idx": 15}, {"type": "table", "img_path": "oTzydUKWpq/tmp/0d7d076ea830c2820d2737e2cf0ddc87ea456686d1d47c0a0fbc9a45bc6f51a3.jpg", "table_caption": ["Table 8: The sparsity of co-occurrence matrix. "], "table_footnote": [], "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbf{C}=(\\mathbf{X}^{T}\\mathbf{X})>0\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here, ${\\bf X}^{T}$ is the transpose of $\\mathbf{X}$ , and the multiplication $\\mathbf{X}^{T}\\mathbf{X}$ results in a matrix where each element $c_{i j}^{\\prime}$ is the sum of the products of corresponding elements of $\\mathbf{X}$ : ", "page_idx": 16}, {"type": "equation", "text": "$$\nc_{i j}=\\sum_{k=1}^{n}x_{k i}x_{k j}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The value $c_{i j}$ represents the number of texts where both words $i$ and $j$ are present. The physical meaning of $\\bar{c}_{i j}\\ >\\ 1$ is that features $i$ and $j$ co-occur in at least one text, indicating a possible association or dependency between them within the dataset. A co-occurrence-constrained FGSM only allows filps that satisfy if word $i$ and word $j$ appear in the injected embeddings, they must have cij > 1. ", "page_idx": 16}, {"type": "text", "text": "We examine the sparsity of $\\mathbf{C}$ in Table 8. We can see that almost every two words have co-occurred before, making the constraints meaningless. ", "page_idx": 16}, {"type": "text", "text": "H Experiment Details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "H.1 Setup and Hyperparameters ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Attacks. For the injected embedding features, we use PGD [33, 2] with a learning rate of 0.01, and the training epoch is 500. An early stop of 100 epochs according to the accuracy of the surrogate model on the target nodes. For TDGIA and ATDGIA, we use the method of [36] to generate injected embeddings. The weights $k_{1}$ and $k_{2}$ are set 0.9 and 0.1 by default. The sequential step is set as 1.0 for MetaGIA to save computational costs, while 0.20 for methods. For Binary FGSM, the batch size is set to as $B=1$ in Cora and CiteSeer, and $B=50$ for PubMed. For the hyperparameters of SeqGIA, MetaGIA, and SeqAGIA, we directly follow the setting as in [2]. A simplified description of the Sequential injection framework is provided in Appendix 1, and the FGSM function is provided in Appendix 2. ", "page_idx": 16}, {"type": "text", "text": "Harmonious Adversarial Objective. The HAO constraint can be formulated as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{L}=\\mathcal{L}_{p r e d}+\\gamma\\mathcal{L}_{H A O}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here, $\\mathcal{L}_{p r e d}$ represents the cross-entropy loss on target nodes, calculated between the current predictions of the surrogate model and the original predictions made on the clean dataset by the same model. The loss term $\\bar{\\mathcal{L}_{H A O}}\\,=\\,s i m(\\mathbf{X}_{\\mathrm{inj}}^{\\prime},(\\bar{\\mathbf{X}^{\\prime}}\\mathbf{A}^{\\prime})_{\\mathrm{inj}})$ , where sim returns the cosine similarity between injected node features and propagated injected node features. We set $\\gamma=10$ in SeqGIA, SeqAGIA and MetaGIA, $\\gamma=1$ in TDGIA, ATDGIA and set $\\gamma=1e-6$ in FSGM, where we empirically find a balance in the attack performance and unnoticeability to escape from homophily-based defender. ", "page_idx": 16}, {"type": "text", "text": "Note that in Figure 2, $\\gamma$ is multiplyed by the weights as the final coefficient. Denote $\\gamma^{\\prime}=\\gamma*w$ , where $w$ is the weight listed in the ${\\bf X}$ -axis of the figure, we apply $\\mathcal{L}=\\mathcal{L}_{p r e d}+\\gamma^{\\prime}\\mathcal{L}_{H A O}$ as the final loss function. ", "page_idx": 16}, {"type": "text", "text": "Defense. For both GCN and EGNNGuard, we set the number of layers as 3 and use a hidden dimension of 64. We set the dropout rate as 0.5 and adopt Adam optimizer [12] with a learning rate of 0.01. The number of training epochs is 400. We adopt the early stop strategy with a patience of 100 epochs. The threshold is set as 0.1 following [2], which we find powerful enough in detecting noticeable injections. ", "page_idx": 16}, {"type": "text", "text": "Others. The temperature of the GPT-turbo is set as 0.7. In ITGIA, the beam-width is set as 2. In WTGIA, the max-token for gpt-turbo and Llama3 is set to 500 for Cora and CiteSeer and 550 for ", "page_idx": 16}, {"type": "text", "text": "PubMed. We set the the number of dialogs in multi-round corrections as 3. We set the max-token to avoid over-length generation. Based on the typical ratio of 0.75:1 between the number of words and the number of tokens, we proportionally scale this relationship using the data from Table 6 to obtain the specific numbers for this limitation. ", "page_idx": 17}, {"type": "text", "text": "H.2 Prompt Design ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Table 9 provides our prompt designs for different prompt strategies of vanilla text-based GIAs. The <adj/example_paper_content> is comprised of paper id, title, and abstract of adjacent/example nodes, and ... denotes flilable blanks for the model to flil in. The ${\\tt{<}}\\mathrm{{LMIN}>}$ and ${\\angle}\\mathrm{LMAX}{>}$ correspond to the length limit for each dataset as specified in Table 6. Generally, our experiments find that the current instructions allow the LLM to produce output that conforms well to the expected format without significant deviations. ", "page_idx": 17}, {"type": "table", "img_path": "oTzydUKWpq/tmp/a462c6f3b28aecb6472eed3686e01bfe8543d4f7142a38c4a5030aab13332ea9.jpg", "table_caption": ["Table 9: Prompts of vanilla text-based GIAs. Number of positive examples are set to as 5, and number of negative examples are set to as 3. "], "table_footnote": ["Table 10 provides prompts of WTGIA with different generation type. "], "page_idx": 17}, {"type": "text", "text": "I Collections of Pseudo-code ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "I.1 Pseudo-code for Sequential GIAs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "The pseudo-code for sequential node injection strategy is displayed in Algorithm 1. A simple illustration of the feature update function of SeqGIA, MetaGIA, TDGIA, and SeqAGIA is given in Algorithm 3. The pseudo-code for Binary FGSM feature update functions is displayed in Algorithm 2. For FGSM binary attacks, we implement the structure updates in the sequential node injection manner, as it is shown more powerful by previous works [28, 2]. The initialization of $\\mathbf{X}_{\\mathrm{inj}}$ is set as $\\mathbf{X}_{\\mathrm{inj}}=\\mathbf{0}$ and applying feature update function as in Algorithm 2. For the details about the structure update function $\\mathcal{H}$ of SeqGIA, MetaGIA, TDGIA, ATDGIA, AGIA, and the feature update function of TDGIA and ATDGIA, please refer to [2, 36]. ", "page_idx": 17}, {"type": "table", "img_path": "oTzydUKWpq/tmp/cc7edf6400fed2e55e17760e4f6c588a1bcb6680370354b0da60754321b115e1.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "Note that in ITGIA, if normalized, after each single epoch of feature update, we project the output $\\mathbf{X}_{\\mathrm{inj}}$ to a unit sphere. A text illustration of PGD can be found in G.2, where an alternative to vanilla PGD is discussed. ", "page_idx": 18}, {"type": "table", "img_path": "oTzydUKWpq/tmp/dc6a79f45083a4d55e6029f0ab787f178afe2a4f0125277d1a66f70e7807914f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "table", "img_path": "oTzydUKWpq/tmp/f01d630d4125bac4435ab602eb5ddad5af65ed4aaaf2decc293085385ad17469.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "Algorithm 3: Fast Gradient Sign Method (FGSM) Update for Binary Features Input :Model $f$ , features $\\mathbf{X}$ , attack features $\\mathbf{X}_{i n j}$ , adjacency matrix $\\mathbf{A}^{\\prime}$ , original labels $Y_{o r i g}$ , target indices $T$ , sparsity budget $S$ , batch size $B$ Output :Updated attack features $\\mathbf{X}_{\\mathrm{inj}}$ 1 $F\\gets\\mathbf X$ .shape[1]; $F^{\\prime}\\gets\\{S\\cdot D\\}$ // Allowed flips per node. 2 while any row $\\hbar i p s<F^{\\prime}$ do 3 $\\mathbf{X}_{c a t}\\leftarrow\\mathbf{X}\\cup\\mathbf{X}_{i n j}$ 4 $Z\\gets f(\\mathbf{X}_{c a t},\\mathbf{A}^{\\prime})$ 5 $\\nabla\\mathcal{L}\\leftarrow\\nabla_{\\mathbf{X}_{i n j}}\\mathcal{L}(Z,Y_{o r i g},T)$ 6 Determine flip mask $M\\gets(\\mathrm{Current\\,fips\\,per\\,row}<F^{\\prime})$ 7 $G_{v a l i d}\\leftarrow\\nabla\\bar{\\mathcal{L}}\\cdot M$ // Mask gradients by rows that can still flip 8 Compute flip direction $G_{f l i p}\\gets\\mathbf{sign}(G_{v a l i d})-(\\mathbf{X}_{i n j}==1)$ ) 9 Select indices of top $B$ gradients $I\\gets\\mathrm{Top-K}$ indices from $G_{f l i p}$ 10 foreach $i\\in I$ do 11 $r,c\\gets\\mathbf{Row}$ and column of index $i$ 12 if Row $r$ can still flip then 13 Flip $X_{i n j}[r,c]\\stackrel{.}{\\leftarrow}1-{\\bf X}_{i n j}[r,c]$ 14 Update the flip counter for row $r$ 15 return $\\mathbf{X}_{i n j}$ ", "page_idx": 19}, {"type": "text", "text": "I.2 Pseudo-code for Vanilla Text-Level GIAs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The pseudo-code for vanilla text-level GIAs is displayed in Algorithm 4, which is implemented in a sequential manner following SeqGIA. Note that the feature is not updated within the \u201cwhile loop\u201d since gradient information is infeasible. ", "page_idx": 19}, {"type": "text", "text": "J Interpretability of Generated Texts ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "J.1 Perplexity and Use Rate ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "We calculate perplexity based on GPT2 [21] following https://huggingface.co/docs/ transformers/perplexity. Note that due to the model capacity constraint, the output of ITGIA is truncated to 32 tokens. So, we truncate all texts into 32 tokens before calculating Perplexity to make them comparable to each other. We present the results of average perplexity, and use rate in WTGIA in Table 11, Table 12, Table 13 and Table 14. ", "page_idx": 19}, {"type": "text", "text": "In the experiments, VTGIA consistently achieves the lowest perplexity scores, indicating superior performance, followed by the WTGIA model. Conversely, ITGIA exhibits the highest perplexity, rendering it the least interpretable. Notably, even the variant incorporating -HAO fails to enhance interpretability corrsponding to normal texts. Furthermore, our findings suggest a positive correlation between model use rate and perplexity. Specifically, a lower use rate corresponds to reduced perplexity, thereby enhancing interpretability. This observation aligns with the hypothesis that as the use rate decreases, LLMs preferentially select words from a specified set that are more interpretable, rather than striving to utilize all specified words. ", "page_idx": 19}, {"type": "text", "text": "Input :Graph $\\mathcal{G}=(\\mathcal{V},\\mathcal{E},\\{s_{i}\\})$ , Class set $C$ , Number of injected nodes $N_{\\mathrm{inj}}$ , Number of target nodes $|\\nu_{T}|$ . Output :Attacked Graph $\\stackrel{\\cdot}{\\mathcal{G}^{\\prime}}=(\\mathcal{V}^{\\prime},\\mathcal{E}^{\\prime},\\{s_{i}\\}^{\\prime})$ Parameter :Sequential step $^{s t}$ , prompt type $p$ 1 $\\mathcal{V}^{\\prime}\\leftarrow\\mathcal{V}$ ; $\\mathcal{E}^{\\prime}\\leftarrow\\mathcal{E}$ 2 if $p==$ Heterophily prompt then $/*$ Integrate attacked graph into prompts \\*/ 3 $\\mathcal{V}^{\\prime}$ , $\\mathcal{E}^{\\prime}\\leftarrow$ Embedding-based GIAs 4 $\\{s_{i}\\}_{\\mathrm{inj}}\\leftarrow$ GenerateTex $\\cdot(N_{\\mathrm{inj}},\\mathcal{G}^{\\prime},\\mathcal{V}^{\\prime},\\mathcal{E}^{\\prime})$ 5 else 6 $\\{s_{i}\\}_{\\mathrm{inj}}\\leftarrow$ GenerateText(Ninj, , G\u2032) 7 $\\{s_{i}\\}^{\\prime}=\\{s_{i}\\}\\cup\\{s_{i}\\}_{\\mathrm{ir}}$ j 8 $\\mathbf{X}^{\\prime}\\gets$ TextEmbedding({si}inj) 9 $N_{\\mathrm{Total}}\\leftarrow0$ /\\* Graph structure refinement \\*/ 10 while $N_{T o t a l}<N_{i n j}$ do 11 $\\begin{array}{r l}&{n\\leftarrow\\operatorname*{min}(N_{\\mathrm{inj}}^{\\;\\;\\;}-N_{\\mathrm{Total}},\\lfloor N_{\\mathrm{inj}}\\ast s t\\rfloor)}\\\\ &{\\mathcal{V}^{\\prime},\\mathcal{E}^{\\prime}\\leftarrow\\mathrm{AdaptiveInjection}(\\mathcal{V}^{\\prime},\\mathcal{E}^{\\prime},\\mathbf{X}^{\\prime})}\\\\ &{N_{\\mathrm{Total}}\\leftarrow N_{\\mathrm{Total}}+n}\\end{array}$ 12 13 14 15 return Attacked Graph $\\mathcal{G}^{\\prime}=(\\mathcal{V}^{\\prime},\\mathcal{E}^{\\prime},\\left\\{s_{i}\\right\\}^{\\prime})$ ", "page_idx": 20}, {"type": "table", "img_path": "oTzydUKWpq/tmp/164b012fe7e80848994fdc632d49f9e21a746e764da692ad592d52b11e0fa509.jpg", "table_caption": ["Table 11: Average perplexity of raw text generated by VTGIA and ITGIA. Clean refers to the average perplexity of original dataset. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "Table 12: Average perplexity (\u2193) and use rate of raw texts generated by WTGIA w.r.t sparsity budget on Cora dataset. ", "page_idx": 20}, {"type": "table", "img_path": "oTzydUKWpq/tmp/3b1c7d3b403675a37158ba778c4cf0f1ce60902fe825387010c88347b76e643a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "oTzydUKWpq/tmp/3face010c9ca6466a650e404a0c536591b2db2e1a069c2c15fddd24982648415.jpg", "table_caption": ["Table 13: Average perplexity (\u2193) and use rate of raw texts generated by WTGIA w.r.t sparsity budget on CiteSeer dataset. "], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "oTzydUKWpq/tmp/c8cc91e78fb099042e9d675fd97efe772bf3ea387f56e58f223d6538ac975cac.jpg", "table_caption": ["Table 14: Average perplexity (\u2193) and use rate of raw texts generated by WTGIA w.r.t sparsity budget on PubMed dataset. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "J.2 Examples of VTGIA ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We show the generated examples on the Cora dataset for VTGIA, one for each prompt type. ", "page_idx": 21}, {"type": "text", "text": "Heterophily Prompt Example. Title: Reinforcement Learning Techniques for Rule Learning Optimization Abstract: This paper explores the application of reinforcement learning techniques to optimize the process of rule learning. Traditional rule-learning algorithms often struggle with complex datasets and high-dimensional feature spaces, leading to suboptimal rule sets. By leveraging the power of reinforcement learning, we propose a novel approach that dynamically adapts the rule learning process based on feedback from the environment. We start by formulating the rule learning problem as a Markov decision process, where the agent\u2019s actions are the selection and refinement of rules based on the input data. We introduce a reward function that incentivizes the discovery of rules with high predictive power while maintaining simplicity and interpretability. Through a series of experiments on benchmark datasets, we demonstrate the effectiveness of our approach in outperforming traditional rule learning methods. Furthermore, we investigate the convergence properties of our reinforcement learning algorithm and provide theoretical bounds on its performance. Our results show that by combining reinforcement learning with rule learning, we can achieve more accurate and concise rule sets, leading to improved generalization performance on unseen data. Overall, this paper contributes to the intersection of reinforcement learning and rule learning, opening up new possibilities for optimizing rule-based systems in various domains. ", "page_idx": 21}, {"type": "text", "text": "Random Prompt Example. Title: Exploring the Influence of Martial Arts on Japanese History Abstract: This paper delves into the deep-rooted connection between martial arts and the historical landscape of Japan. By tracing the evolution of various martial art forms such as Judo, Kendo, and Karate, we analyze how these disciplines have not only shaped the physical combat techniques but also contributed significantly to the cultural, philosophical, and political development of Japan. Through studying the impact of samurai warriors, martial arts schools (ryu), and renowned martial artists throughout different historical periods, this paper uncovers the intricate interplay between martial arts and Japan\u2019s societal norms, values, and power dynamics. Furthermore, by exploring the ways in which martial arts have been depicted in art, literature, and popular culture over the centuries, we gain a deeper understanding of how these practices have transcended mere combat techniques to embody spiritual, ethical, and aesthetic principles. Ultimately, this paper aims to shed light on the enduring legacy of martial arts in Japanese history and the profound influence they continue to exert on various aspects of Japanese society today. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "Mixing Prompt Example. Title: Unified Approaches in Machine Learning and Control Systems Abstract: This paper presents a novel approach to machine learning and control systems by integrating various techniques such as probabilistic methods, neural networks, case-based reasoning, genetic algorithms, theory, reinforcement learning, and rule learning. The proposed framework leverages the strengths of each approach to address complex problems in a unified manner. It introduces a new algorithm, contextual machine learning, which incorporates adaptative history-sensitive models for source separation, making use of the temporal structure of input data. Furthermore, the paper explores the application of non-linear systems in robust control and the use of functional programming by analogy in the domain of program synthesis. Additionally, it presents a learning algorithm for Disjunctive Normal Form (DNF) under the uniform distribution, with implications for the case when certain parameters are constant. The paper also discusses the use of Gaussian noise in sigmoidal belief networks and the training of such networks using slice sampling for inference and learning. Finally, it showcases the application of radial basis function networks in predicting power system security margin. Overall, this paper provides a comprehensive overview of the diverse applications and advancements in machine learning and control systems, demonstrating the potential for creating unified approaches that transcend traditional boundaries. ", "page_idx": 22}, {"type": "text", "text": "J.3 Examples of ITGIA ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We show the generated examples on the Cora dataset for ITGIA in this subsection. The output is highly uninterpretable due to ill-defined interpretable regions for injected embeddings. ", "page_idx": 22}, {"type": "text", "text": "ITGIA-TDGIA without HAO, Cos: 0.136 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\u2022 of the following: MC Dallas\u2019 NSA sign, and some of the relays of the past few years: Trumpet Jam\u2019s sinus \u2022 the liner notes of The MC6\u2019s \"Desirty Pigs\": the relayed that some of the plaque \u2022 liner notes of The MC\u2019s \"The Lion\u2019s Pie\" album: some relayed that the \u2019bumpy\u2019 fluid \u2022 the following: One of the croons of the \"Petsy on the MC12\" relayed: Demitab ", "page_idx": 22}, {"type": "text", "text": "ITGIA-TDGIA with HAO, Cos: 0.742 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "\u2022 \u201cSympteric\u201d Alignment. This is one of the best examples of how to achieve high level information retrieval algorithms using proportion   \n\u2022 \"Asymptotically\" by Grant. This is a key method for constructing local information representation systems that support multicluster connections   \n\u2022 Emilia. The \u201cProplective information with no associativity at all\u201d NNNN algorithms are based on Monte simple scenarios ", "page_idx": 22}, {"type": "text", "text": "J.4 WTGIA ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "We show the generated examples on the Cora dataset with sparsity budget set as \u201caverage\u201d for WTGIA in the subsection. We choose the FGSM-TDGIA for embedding generation. We display one example for each generation type. ", "page_idx": 22}, {"type": "text", "text": "GPT. Title: Hierarchical Recurrent Neural Networks for Visual Sequence Identification and Dimensional Improvement ", "page_idx": 22}, {"type": "text", "text": "Abstract: In this article, we demonstrate the idea of using hierarchical recurrent neural networks for visual sequence identification, resulting in dimensional improvement. We show that this approach requires the underlying mechanisms of backpropagation through time to obtain a more powerful representation of visual sequences. Additionally, we identify the nonlinear nature of the sequence identification problem and how the use of recurrent neural networks leads to nonlinear improvement in identifying visual sequences. Furthermore, we present a novel approach to dealing with hierarchical structures in visual sequences, utilizing the power of recurrent neural networks to identify objects in a hierarchical and sample-efficient manner. This work contributes to the science of visual sequence processing and demonstrates the capability of recurrent neural networks to handle complex visual sequences, such as trees, lines, and vector objects. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "GPT-Topic. Title: Hierarchical Neural Networks for Visual Sequence Identification: Exploring the Power of Recurrent Mechanisms in Computer Science ", "page_idx": 23}, {"type": "text", "text": "Abstract: This paper presents an investigation into the use of hierarchical neural networks for visual sequence identification in computer science. The underlying idea is to demonstrate the power of recurrent mechanisms in identifying dimensional visual sequences. The resulting improvement in identification accuracy leads to the direct application of backpropagation mechanisms for obtaining nonlinear vector representations of visual sequences. In addition, the paper explores the application of hierarchical neural networks in identifying hierarchical tree structures within visual sequences. The research also requires the exploration of probabilistic methods for identifying sample sequences and tree structures within visual sequences. This work contributes to the advancement of science in computer vision and object recognition by exploring the hierarchical structure of sequences. ", "page_idx": 23}, {"type": "text", "text": "Llama. Title: Harnessing the Power of Hierarchical Neural Trees for Dimensionally-Transformed Sequence Identification and Improvement through Addition and Recurrent Back-Propagation ", "page_idx": 23}, {"type": "text", "text": "Abstract: This article proposes a groundbreaking idea that combines the strengths of hierarchical neural trees and recurrent back-propagation to identify and classify nonlinear sequences. By leveraging the underlying mechanisms of neural trees and incorporating the addition of recurrent feedback, we demonstrated a remarkable improvement over conventional sequence identification methodologies through the power of back-propagation. Our methodology requires the creation of a vector-based object that represents the sequence, which is then fed into a hierarchical neural line that utilizes recurrent back-propagation to identify the underlying dimensional transformations. This leads to a resulting sample of sequences that can be analyzed and visualized to obtain a deeper comprehension of the object\u2019s underlying mechanisms. To validate our idea, we conducted a comprehensive sequence identification experiment, where we utilized a sample of sequences to train and fine-tune our hierarchical neural trees. Our resulting sequences demonstrated a remarkable capability to identify and classify nonlinear sequences, out-performing other leading methodologies, and providing a visual insight into the underlying mechanisms. This breakthrough has the power to revolutionize the science of sequence identification and has far-reaching implications for fields such as signal-processing, image-recognition, and predictive analytics. ", "page_idx": 23}, {"type": "text", "text": "Llama-Topic. Title: Hierarchical Recurrent Neural Trees for Dimensionally Reduced Sequence Identification and Power System Monitoring ", "page_idx": 23}, {"type": "text", "text": "Abstract: This article demonstrates the effectiveness of hierarchical recurrent neural trees (HRNT) for identifying sequences of nonlinear phenomena occurring within power grids. By leveraging the power of back-propagation through trees, HRNT is capable of capturing underlying mechanisms governing the system\u2019s nonlinear interactions. Our HRNT-based sequence identification idea requires a hierarchical arrangement of recurrent neural trees, which are then utilized to identify sequences of interest along a dimensional line of power transmission. Notably, our methodology leads to a resulting improvement of up to $[\\mathrm{X}]\\%$ over conventional sequence identification schemes, which has been demonstrated through a sample dataset of power system measurements. Furthermore, our HRNT-based system can effectively identify nonlinear phenomena, such as addition of harmonics, and nonlinear interactions between power system objects, leveraging the power of vector calculus to obtain a comprehensive picture. Our visualizations of the resulting sequences and underlying mechanisms have been found to be particularly insightful for power system scientists, contributing to the advancement of the science and providing a valuable addition to the scientific community. ", "page_idx": 23}, {"type": "text", "text": "K More Experiments about WTGIA and ITGIA ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "K.1 Transfer WTGIA to More Datasets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In Tables 15 and Table 16, we included the ogbn-arxiv dataset [10], containing over 160,000 nodes, and a social network dataset, Reddit [11], with more than 30,000 nodes, to evaluate the scalability and generalization of text-level GIAs. We injected 1,500 nodes into ogbn-arxiv, following the budget ", "page_idx": 23}, {"type": "text", "text": "specified in [2], and proportionally injected 500 nodes into Reddit. On both datasets, WTGIA maintains use rates above $90\\%$ and shows good attack performance when transferred to GTR. ", "page_idx": 24}, {"type": "table", "img_path": "oTzydUKWpq/tmp/630570981159124352a6e746461ac5c000e03b94a3a6f28e2e0bba59cf536056.jpg", "table_caption": ["Table 15: Performance of WTGIA with the average sparsity on the ogbn-arxiv dataset. Clean accuracy for BoW embedding is $71.87\\pm0.11$ , and for GTR embedding is $72.36\\pm0.13$ . "], "table_footnote": [], "page_idx": 24}, {"type": "table", "img_path": "oTzydUKWpq/tmp/e9e708ccbb9c9cbe79ed685fb1e9da6c682fda3836fb79893c5a66dd909128b1.jpg", "table_caption": ["Table 16: Performance of WTGIA with the average sparsity on the Reddit dataset. Clean accuracy for BoW embedding is $62.84\\pm0.89$ , and for GTR embedding is $68.28\\pm0.24$ . "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "K.2 Against More Defense Models ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In Table 17, Table 18, Table 19, Table 20, Table 21, and Table 22, we include classic methods like GAT [27] and GraphSAGE [8], as well as the EGNNGuard and Layernorm (LN) methods, which have been proven highly effective in [2]. ", "page_idx": 24}, {"type": "text", "text": "We discover interesting new results, such as LN\u2019s effectiveness on text-level GIAs not being as strong as previously reported for embedding-level attacks, especially for WTGIA. This is because embedding-level GIAs often exhibit abnormal norms, which LN exploits for defense. However, text-level GIAs derive embeddings from real text, avoiding structural anomalies and bypassing LN\u2019s defenses. This suggests that some traditional defense methods that were particularly effective may be limited to the embedding level. The EGNNGuard method is generally effective and performs well overall. As mentioned in the main paper, attackers can use techniques like HAO to bypass EGNNGuard, but this often involves trade-offs. ", "page_idx": 24}, {"type": "table", "img_path": "oTzydUKWpq/tmp/3ab16ba56d31c908cc4bf26250d6b1ceeefe9cc6b1796719115778268881879c.jpg", "table_caption": ["Table 17: ITGIA with default HAO weight against more defense models on Cora, GTR embedding. "], "table_footnote": [], "page_idx": 24}, {"type": "text", "text": "K.3 Transfer to More Embedding Methods ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In Table 23 and Table 24, we included SentenceBert all-MiniLM-L6-v2 [22] as a new embedding backbone. We find that WTGIA shows some transferability between different embeddings, but the ", "page_idx": 24}, {"type": "table", "img_path": "oTzydUKWpq/tmp/20ab962b3c056aad36485f8d2837b0f58d3f329b7c182c3b7ca50643e66a7b89.jpg", "table_caption": ["Table 18: WTGIA with average sparsity against more defense models on Cora, BoW embedding. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "oTzydUKWpq/tmp/f1575b81ef4ea5882a6b228e38f05468beb3f96ddfbc512f7a176d4103dea6ec.jpg", "table_caption": ["Table 19: ITGIA with default HAO weight against more defense models on CiteSeer, GTR embedding. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "oTzydUKWpq/tmp/987fcc9e064a206ea61f452164bffd9b947c825d51ff7d4b291a6de15bd8018c.jpg", "table_caption": ["Table 20: WTGIA with average sparsity against more defense models on CiteSeer, BoW embedding. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "oTzydUKWpq/tmp/c0f2d120389c26e76a6066a38108f08b4da2f8053af6cfc5671a0f4ee2f5c7e2.jpg", "table_caption": ["Table 21: ITGIA with default HAO weight against more defense models on PubMed, GTR embedding. "], "table_footnote": [], "page_idx": 25}, {"type": "table", "img_path": "oTzydUKWpq/tmp/e2c84247bfdecf94a3cb1989cb6c9b059c3228ecf74ecf24db28c6a8a4162511.jpg", "table_caption": ["Table 22: WTGIA with average sparsity against more defense models on PubMed, BoW embedding. "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "results are still unsatisfactory. Although GTR and SBERT are both PLM-based embeddings, the adversarial text by ITGIA performs even worse than WTGIA when transferred to SBERT. We believe the transferability of text-level GIAs remains a significant challenge. ", "page_idx": 26}, {"type": "table", "img_path": "oTzydUKWpq/tmp/6d40fec036a57d8d1026eafb11e5c3bb75ffc158df5f82941c1c9c56b4f80329.jpg", "table_caption": ["Table 23: Transferring ITGIA with default HAO weight to SBERT embedding on Cora. "], "table_footnote": [], "page_idx": 26}, {"type": "table", "img_path": "oTzydUKWpq/tmp/7e7d7e9b3fc83785e2bfb733378dbaa816c916e5646cedec4c662a087062fd31.jpg", "table_caption": ["Table 24: Transferring WTGIA with average sparsity to SBERT embedding on Cora. "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "L Full Experiment Results ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "L.1 Figure 5 for WTGIA with Topic ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "The results of WTGIA variants with topic constrained in the prompt are shown in Figure 7. ", "page_idx": 26}, {"type": "image", "img_path": "oTzydUKWpq/tmp/5209400c80d2a997d23a25956f518f35ae2be7b5245abd1ecbd7f8be03e344f2.jpg", "img_caption": [], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "Figure 7: The performance of WTGIA(w topic) against GCN w.r.t sparsity budget. As the budget increases, the use rate keeps decreasing, and the attack performance increases and then decreases. ", "page_idx": 26}, {"type": "text", "text": "L.2 Full Results for ITGIA ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Full results for ITGIA, as shown in Figure 2 are displayed in Table 1, Table 26, Table 27, and Table 28. ", "page_idx": 26}, {"type": "text", "text": "Table 25: Performance of ITGIA without HAO. Raw texts are embedded by BoW, and GTR before being fed to GCN for evaluation. ", "page_idx": 26}, {"type": "table", "img_path": "oTzydUKWpq/tmp/ad8b677e89e33db2c61b28b6520adccd338f9a329129fa5a338c5dcb19938da7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "L.3 Full Results for Row-wise FGSM ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Full results for Row-wise FGSM, as shown in Figure 3 are displayed in Table 29, Table 30, Table 31, Table 32, and Table 33. ", "page_idx": 26}, {"type": "text", "text": "Table 26: Performance of ITGIA with default HAO weight. Raw texts are embedded by BoW, and GTR before being fed to GCN for evaluation. ", "page_idx": 27}, {"type": "table", "img_path": "oTzydUKWpq/tmp/6478a450a8a4b12e37601cad57aa0e9a4838628057cdbfe637549c8f96e30f64.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "oTzydUKWpq/tmp/a865d3b6d9d0208b1ae69934ff2e910af05a651b6172bcee46710dc46413b24c.jpg", "table_caption": ["Table 27: Performance of ITGIA with $3\\mathrm{x}$ HAO weight. Raw texts are embedded by BoW, and GTR before being fed to GCN for evaluation. "], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "oTzydUKWpq/tmp/be0f85c7be2372c75648526ac27047bd985de517019c9d32246b8a7dabe6b028.jpg", "table_caption": ["Table 28: Performance of ITGIA with $5\\mathrm{x}$ HAO weight. Raw texts are embedded by BoW and GTR before being fed to GCN for evaluation. "], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "oTzydUKWpq/tmp/3dc724e52cd2ce3318997d4747e9bb73e70c87009c0762026268a11b5fbc863f.jpg", "table_caption": ["Table 29: Performance of GCN and Guard under FGSM attack with budget being average sparsity of original dataset. Models are evaluated using BoW embeddings of raw texts. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "Table 30: Performance of GCN and Guard under FGSM attack with a budget of 0.10 sparsity in the attacked embeddings. Models are evaluated using BoW embeddings of raw texts. ", "page_idx": 27}, {"type": "table", "img_path": "oTzydUKWpq/tmp/0ae3a97c2defd10be9be2a119cf7e610a9bb71b435802b814accade81b7b5679.jpg", "table_caption": [], "table_footnote": [], "page_idx": 27}, {"type": "table", "img_path": "oTzydUKWpq/tmp/189614251f3f5047f863d558e1e51811195b2318e2adf078a1495b5233b90e61.jpg", "table_caption": ["Table 31: Performance of GCN and Guard under FGSM attack with a budget of 0.15 sparsity in the attacked embeddings. Models are evaluated using BoW embeddings of raw texts. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "Table 32: Performance of GCN and Guard under FGSM attack with a budget of 0.20 sparsity in the attacked embeddings. Models are evaluated using BoW embeddings of raw texts. ", "page_idx": 28}, {"type": "table", "img_path": "oTzydUKWpq/tmp/4c5376463c0977be2ede472d9c5b5f6f68eb41210d8149b3355f7458317bfd97.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table 33: Performance of GCN and Guard under FGSM attack with a budget of 0.25 sparsity in the attacked embeddings. Models are evaluated using BoW embeddings of raw texts. ", "page_idx": 28}, {"type": "table", "img_path": "oTzydUKWpq/tmp/7545aa223140c345ccf5473f3cd55b89c78a9d6534c35fe7ceab7d54a9c11f00.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "L.4 Full Results for WTGIA ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Full results for WTGIA, as shown in Figure 5 are displayed in the below tables. For average sparsity budget: Table 34, Table 35, Table 36. ", "page_idx": 28}, {"type": "text", "text": "For sparsity budget 0.10: Table 37, Table 38. ", "page_idx": 28}, {"type": "text", "text": "For sparsity budget 0.15: Table 39, Table 40. Table 41. ", "page_idx": 28}, {"type": "text", "text": "For sparsity budget 0.20: Table 42, Table 43. Table 44. ", "page_idx": 28}, {"type": "text", "text": "Table 34: Performance of WTGIA on Cora. The sparsity budget is set as the average sparsity of the original dataset. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 28}, {"type": "table", "img_path": "oTzydUKWpq/tmp/fee23ded811add42ee089efde2879d6fec8e06da92940b7ac3f7626c48b6102e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table 35: Performance of WTGIA on CiteSeer. The sparsity budget is set as the average sparsity of the original dataset. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 28}, {"type": "table", "img_path": "oTzydUKWpq/tmp/c4300117b1ab266b25a47433407aaec83d7d72800dd1a155d1410de8d253a8f5.jpg", "table_caption": [], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Table 36: Performance of WTGIA on PubMed. The sparsity budget is set as the average sparsity of the original dataset. The injected raw texts are embedded with BoW and GTR and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 29}, {"type": "table", "img_path": "oTzydUKWpq/tmp/28137e7f6a66f27fe717569063856fad955be0229cb9f9197b6651e6cae5f0c8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "Table 37: Performance of WTGIA on Cora. The sparsity budget of the embedding is set as 0.10. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 29}, {"type": "table", "img_path": "oTzydUKWpq/tmp/7902281d09b2134a8741662a2b97abf170357ac5c6c9add4a3a541deac08d364.jpg", "table_caption": [], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "Table 38: Performance of WTGIA on CiteSeer. The sparsity budget of the embedding is set as 0.10. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 29}, {"type": "table", "img_path": "oTzydUKWpq/tmp/cf2c08d7a6e990e5fbb232739ea50405bba1b0274118787c967693f2ed50220b.jpg", "table_caption": [], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "Table 39: Performance of WTGIA on Cora. The sparsity budget of the embedding is set as 0.15. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 29}, {"type": "table", "img_path": "oTzydUKWpq/tmp/53c6f6e4c3385e96ea6e26e144c5d73a12538674d9cad9466797191082375bf0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 29}, {"type": "text", "text": "Table 40: Performance of WTGIA on CiteSeer. The sparsity budget of the embedding is set as 0.15. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 30}, {"type": "table", "img_path": "oTzydUKWpq/tmp/c61e5cc2a65802cd8fe1a5cfe7c3cde7090d6cc7e70a891d806031963d87d619.jpg", "table_caption": [], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "Table 41: Performance of WTGIA on PubMed. The sparsity budget of the embedding is set as 0.15. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. Note that GPT-Topic fails to give a meaningful response. ", "page_idx": 30}, {"type": "table", "img_path": "oTzydUKWpq/tmp/4d879c78e71ac86fd6e37d3f526c08b6b4a6409a347163ef98f714a932c37238.jpg", "table_caption": [], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "Table 42: Performance of WTGIA on Cora. The sparsity budget of the embedding is set as 0.20. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 30}, {"type": "table", "img_path": "oTzydUKWpq/tmp/2a4790eaf84b4964c12ad0f0c711d879e8aac9282d9a05172ec973416a2b1a78.jpg", "table_caption": [], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "Table 43: Performance of WTGIA on CiteSeer. The sparsity budget of the embedding is set as 0.20. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. ", "page_idx": 30}, {"type": "table", "img_path": "oTzydUKWpq/tmp/c31bb0d1d426574b45049bb7ba12987a546ad09abf2f66df4365f1d9100f2dee.jpg", "table_caption": [], "table_footnote": [], "page_idx": 30}, {"type": "text", "text": "Table 44: Performance of WTGIA on PubMed. The sparsity budget of the embedding is set as 0.20. The injected raw texts are embedded with BoW and GTR, and then evaluated using a GCN. The last column reports the average result of GIAs in the last five columns. The lowest(strongest) result in the column is bold. Note that GPT-Topic fails to give a meaningful response. ", "page_idx": 31}, {"type": "table", "img_path": "oTzydUKWpq/tmp/41abd598cd9d17df1f7e776bf248c43fb440d1ca9a478f482a45e9db2975a16a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 31}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The claims we made accurately reflect the paper\u2019s contributions and scope. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 31}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: We discuss the limitations of text-level attacks in Section 5. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. ", "page_idx": 31}, {"type": "text", "text": "\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. \u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 32}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: We provide proof to our theorem in the Appendix. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 32}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: We provide the pseudo-code in the Appendix and the code URL in the abstract. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully.   \n(c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset).   \n(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We report open access information in Appendix B. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We provide experimental settings in Appendix H.1 ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 33}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We repeat experiments 10 times and report the standard deviation in the tables. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 34}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We have included resources information in Appendix C. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We conform in every respect with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We have included Broader Impacts section in the Appendix A. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 35}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: The paper poses no such risks. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 35}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: We have included the license clarification in Appendix B. Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets. \u2022 The authors should cite the original paper that produced the code package or dataset. \u2022 The authors should state which version of the asset is used and, if possible, include a URL. ", "page_idx": 35}, {"type": "text", "text": "\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 36}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 36}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper included anonymized code in the supplementary file. The training, license, and limitations have been discussed in Appendix B, Appendix H.1. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 36}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 36}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 36}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 37}]