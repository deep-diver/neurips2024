[{"figure_path": "vIP8IWmZlN/figures/figures_3_1.jpg", "caption": "Figure 1: The sender and receiver architectures. Adapted from (Lipinski et al., 2023).", "description": "This figure shows the architecture of both the sender and receiver agents used in the experiment. The sender agent takes an observation as input and produces a message, while the receiver agent takes the message, the full sequence, and the target and distractors as inputs, and outputs the correct index of the target integer in the distractor set.  The architecture uses GRUs (Gated Recurrent Units) for processing sequential data and a Gumbel-Softmax function for message generation. The sender uses one GRU to process the observation and then passes the resulting hidden state to another GRU for message generation. The receiver uses two GRUs, one to process the message and another to process the sequence, and combines their output to make a prediction.", "section": "3 Agent Architecture"}, {"figure_path": "vIP8IWmZlN/figures/figures_5_1.jpg", "caption": "Figure 2: Examples of the different types of message compositionality that are possible to identify using the PMI algorithms.", "description": "This figure illustrates the three different message types identified by the PMI algorithms: Compositional Position Invariant, Compositional Position Variant, and Non-compositional.  Each message type is shown with example messages and corresponding observations. Compositional Position Invariant messages have a consistent meaning regardless of their position within the message; Compositional Position Variant messages have a meaning that depends on their position in the message; Non-compositional messages convey their entire meaning as a single unit. The figure visually demonstrates how different combinations of message elements lead to varied interpretations based on compositionality and position within the message.", "section": "4 Message interpretability and analysis using NPMI"}]