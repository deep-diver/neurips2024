{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is a technical report describing GPT-4, a large language model that serves as a foundational model for AMOR."}, {"fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "publication_date": "2019-01-01", "reason": "This paper demonstrates the capabilities of large language models to perform various tasks without explicit supervision, a key concept underlying AMOR's design."}, {"fullname_first_author": "Timo Schick", "paper_title": "Toolformer: Language models can teach themselves to use tools", "publication_date": "2024-01-01", "reason": "This paper introduces Toolformer, an LLM-based agent that can use external tools; this approach is relevant to AMOR's modular design and its ability to interact with external knowledge bases."}, {"fullname_first_author": "Reiichiro Nakano", "paper_title": "WebGPT: Browser-assisted question-answering with human feedback", "publication_date": "2021-12-09", "reason": "This paper introduces WebGPT, an agent that leverages a web browser for enhanced capabilities and employs human feedback for improvement, which is similar to AMOR's process feedback mechanism."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-01-01", "reason": "This paper explores chain-of-thought prompting, a technique used to improve LLMs' reasoning capabilities; this is relevant to AMOR's FSM-based reasoning logic which incorporates a sequence of steps for problem-solving."}]}