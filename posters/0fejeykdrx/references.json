{"references": [{"fullname_first_author": "Marah Abdin", "paper_title": "Phi-3 technical report: A highly capable language model locally on your phone", "publication_date": "2024-04-14", "reason": "This paper introduces Phi-3, a significant LLM used as a backbone model in the experiments, influencing the overall results and comparison with other models."}, {"fullname_first_author": "Stella Biderman", "paper_title": "Pythia: A suite for analyzing large language models across training and scaling", "publication_date": "2023-00-00", "reason": "The Pythia suite provides various LLMs of different sizes used for comparison in the experiments, which helps to study the model scaling effect and performance."}, {"fullname_first_author": "Defu Cao", "paper_title": "Tempo: Prompt-based generative pre-trained transformer for time series forecasting", "publication_date": "2023-10-00", "reason": "This paper introduces the prompt-based approach in time series forecasting using LLMs, which inspires and is related to the prompt-based approach used in this paper for human mobility data analysis."}, {"fullname_first_author": "Ching Chang", "paper_title": "LLM4TS: Two-stage fine-tuning for time-series forecasting with pre-trained LLMs", "publication_date": "2023-08-00", "reason": "This paper demonstrates the use of LLMs in time series analysis which is relevant to this paper's approach of using LLMs for sequential mobility data."}, {"fullname_first_author": "Quanjun Chen", "paper_title": "Dualsin: Dual sequential interaction network for human intentional mobility prediction", "publication_date": "2020-00-00", "reason": "This paper focuses on human mobility prediction using deep learning models which is the main task studied in this paper and is directly related to the methodology and experimental setup."}]}