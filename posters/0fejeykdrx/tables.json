[{"figure_path": "0feJEykDRx/tables/tables_5_1.jpg", "caption": "Table 1: Next location prediction (LP) performance results. A higher value indicates better performance. Red: the best, Blue: the second best. The units of all metics are expressed as e-2.", "description": "This table presents the performance of various next location prediction models on four different datasets (Gowalla, WeePlace, Brightkite, and FourSquare).  The metrics used to evaluate performance are Accuracy@1, Accuracy@5, Accuracy@20, and Mean Reciprocal Rank (MRR).  Higher values for each metric indicate better performance. The table highlights the best (red) and second-best (blue) performing models for each dataset and metric. The results are expressed as a percentage multiplied by 100.", "section": "5.1 Next Location Prediction"}, {"figure_path": "0feJEykDRx/tables/tables_5_2.jpg", "caption": "Table 2: Trajectory user link (TUL) performance results. A higher value indicates better performance. Red: the best, Blue: the second best. The units of all metics are expressed as e-2.", "description": "This table presents the performance of various methods on the Trajectory User Link (TUL) task across four different datasets (Gowalla, WeePlace, Brightkite, and Foursquare).  The performance is measured using four metrics: Accuracy at 1 (Acc@1), Accuracy at 5 (Acc@5), Accuracy at 20 (Acc@20), and Mean Reciprocal Rank (MRR). Higher values for all metrics indicate better performance. The best performing method for each metric and dataset is highlighted in red, and the second-best is highlighted in blue.  All values are expressed as percentages multiplied by 100.", "section": "5 Experiments"}, {"figure_path": "0feJEykDRx/tables/tables_6_1.jpg", "caption": "Table 3: Time Prediction (TP) preference results. A lower value indicates better performance. Red: the best, Blue: the second best. The units of all metrics are minutes.", "description": "This table presents the results of the time prediction experiments performed on four benchmark datasets (Gowalla, WeePlace, Brightkite, and FourSquare).  It compares the performance of the proposed Mobility-LLM model against several state-of-the-art baselines (IFLTPP, THP, NSTPP, DSTPP, ReMVC, SML, and CACSR) using two metrics: Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). Lower values indicate better performance. The table highlights the best and second-best performing models for each dataset using red and blue coloring, respectively. The units of the metrics are in minutes.", "section": "5.3 Time Prediction"}, {"figure_path": "0feJEykDRx/tables/tables_6_2.jpg", "caption": "Table 1: Next location prediction (LP) performance results. A higher value indicates better performance. Red: the best, Blue: the second best. The units of all metics are expressed as e-2.", "description": "This table presents the performance of various models on the next location prediction task.  It compares the performance of Mobility-LLM against several baselines across four datasets (Gowalla, WeePlace, Brightkite, and Foursquare).  Metrics used include Accuracy@1, Accuracy@5, Accuracy@20, and Mean Reciprocal Rank (MRR).  The best and second-best performing models for each metric and dataset are highlighted in red and blue, respectively.", "section": "5.1 Next Location Prediction"}, {"figure_path": "0feJEykDRx/tables/tables_9_1.jpg", "caption": "Table 6: Efficiency analysis of Mobility-LLM on WeePlace dataset on all tasks. Param. represents the total parameters of the model. Mem. denotes the GPU Memory. The ratio represents the ratio of trainable parameters (including the trainable parameters in QLoRA and the reprogramming parameters). The Time column denotes the total training time.", "description": "This table presents a detailed efficiency analysis of the Mobility-LLM model on the WeePlace dataset across three tasks: next location prediction (LP), trajectory user link (TUL), and time prediction (TP).  It shows the total number of parameters, GPU memory usage, the percentage of trainable parameters (including QLoRA and reprogramming parameters), and the total training time for various model variants.  The table allows for comparison of efficiency across different model choices and configurations. This information is vital for understanding the computational cost and resource requirements of different model setups.", "section": "5 Experiments"}, {"figure_path": "0feJEykDRx/tables/tables_18_1.jpg", "caption": "Table 7: The statics of Processed Datasets", "description": "This table presents the statistics of four processed datasets used in the paper's experiments.  For each dataset (Gowalla, WeePlace, Brightkite, and Foursquare), it shows the number of samples, users, and points of interest (POIs). This provides context for the scale and characteristics of the data used to train and evaluate the Mobility-LLM model.", "section": "5 Experiments"}, {"figure_path": "0feJEykDRx/tables/tables_21_1.jpg", "caption": "Table 8: Ablations on WeePlace dataset in all tasks. Red: the best, Blue: the second-best.", "description": "This table presents the results of ablation experiments conducted on the WeePlace dataset.  It shows the performance of the Mobility-LLM model and its variants (removing components like HTPP, VIMN, PPEL, or replacing the LLM with a transformer layer) across three downstream tasks (LP: Next Location Prediction, TUL: Trajectory User Link, TP: Time Prediction). The metrics used are Accuracy at 1, 5, and 20 (Acc@1, Acc@5, Acc@20), Mean Reciprocal Rank (MRR), Mean Absolute Error (MAE), and Root Mean Squared Error (RMSE). The best performing variant for each metric in each task is highlighted in red, and the second-best in blue, to show the impact of each model component on the overall performance.", "section": "5.1 Next Location Prediction"}, {"figure_path": "0feJEykDRx/tables/tables_21_2.jpg", "caption": "Table 1: Next location prediction (LP) performance results. A higher value indicates better performance. Red: the best, Blue: the second best. The units of all metics are expressed as e-2.", "description": "This table presents the results of next location prediction experiments using various models on four benchmark datasets (Gowalla, WeePlace, Brightkite, and FourSquare).  The metrics used to evaluate performance are Accuracy@1, Accuracy@5, Accuracy@20, and Mean Reciprocal Rank (MRR).  Higher scores indicate better prediction accuracy. The table highlights the best and second-best performing models for each dataset and metric.", "section": "5.1 Next Location Prediction"}, {"figure_path": "0feJEykDRx/tables/tables_22_1.jpg", "caption": "Table 8: Ablations on WeePlace dataset in all tasks. Red: the best, Blue: the second-best.", "description": "This table presents the results of ablation experiments performed on the WeePlace dataset.  The experiments evaluate the impact of removing key components of the Mobility-LLM model on the performance of three downstream tasks: Next Location Prediction (LP), Trajectory User Link (TUL), and Time Prediction (TP). Each row represents a different model variant, with columns showing the performance metrics for each task.  'Red' highlights the best performing variant, and 'Blue' highlights the second-best. The table provides insights into the relative contributions of different model components (HTPP, VIMN, PPEL, and the LLM itself) to the overall performance of Mobility-LLM.", "section": "E.3.1 Rusults of Variants on WeePlace"}, {"figure_path": "0feJEykDRx/tables/tables_24_1.jpg", "caption": "Table 1: Next location prediction (LP) performance results. A higher value indicates better performance. Red: the best, Blue: the second best. The units of all metics are expressed as e-2.", "description": "This table presents the results of next location prediction experiments on four datasets (Gowalla, WeePlace, Brightkite, and FourSquare).  Multiple models are compared, including several state-of-the-art (SOTA) models and the proposed Mobility-LLM model.  The metrics used to evaluate performance are Accuracy at 1 (Acc@1), Accuracy at 5 (Acc@5), Accuracy at 20 (Acc@20), and Mean Reciprocal Rank (MRR). The best and second-best performing models are highlighted in red and blue, respectively. Results are presented as percentages multiplied by 100 (e-2).", "section": "5.1 Next Location Prediction"}]