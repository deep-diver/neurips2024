[{"figure_path": "9B6J64eTp4/tables/tables_5_1.jpg", "caption": "Table 1: Part-level pose estimation results. Our method outperforms PARIS in majority of object categories while having lower variation over multiple runs in the performance.", "description": "This table presents a comparison of part-level pose estimation results between the proposed method and the baseline method (PARIS).  The metrics used are direction error (e_d), position error (e_pk), geodesic distance (e_g), and translation error (e_t). The results are shown for six different object categories: laptop, oven, stapler, fridge, blade, and storage.  Lower values indicate better performance. The table highlights that the proposed method achieves superior accuracy with less variability across multiple runs compared to the PARIS method.", "section": "5.2 Results"}, {"figure_path": "9B6J64eTp4/tables/tables_7_1.jpg", "caption": "Table 2: Articulation synthesis and part segmentation results. Average performance over 5 runs (best results in boldface).", "description": "This table presents a quantitative comparison of the proposed method against the baseline method (PARIS) in terms of articulation synthesis and part segmentation performance.  The metrics used for evaluation are Peak Signal-to-Noise Ratio (PSNR), which measures the quality of the synthesized images, and mean Intersection over Union (mIoU), which measures the accuracy of the part segmentation. The results are averaged over 5 independent runs of each method, and the best results are highlighted in bold.  The table provides a detailed breakdown of the results for both revolute and prismatic object categories.", "section": "5.2 Results"}, {"figure_path": "9B6J64eTp4/tables/tables_7_2.jpg", "caption": "Table 3: Objects with multiple parts. Errors using multiple metrics for pose estimation (averaged over all joints).", "description": "This table presents the results of the experiment on objects with multiple movable parts.  It shows the performance of the proposed method in terms of several metrics: direction error (ed), position error (ep), geodesic distance (eg), translation error (et), Peak Signal-to-Noise Ratio (PSNR), and mean Intersection over Union (mIoU).  The metrics are calculated for each object category separately, providing a comprehensive evaluation of part-level pose estimation accuracy.", "section": "5.2 Results"}, {"figure_path": "9B6J64eTp4/tables/tables_8_1.jpg", "caption": "Table 4: Ablation studies with different number of target images.", "description": "This table presents the ablation study results by varying the number of target images used for training the model.  The metrics evaluated are direction error (e<sub>d</sub>), position error (e<sub>g</sub>), and Peak Signal-to-Noise Ratio (PSNR). The results show that the model's performance improves significantly with an increasing number of target images, indicating that sufficient data is essential for effective learning.", "section": "5 Experiment"}, {"figure_path": "9B6J64eTp4/tables/tables_8_2.jpg", "caption": "Table 5: Ablation study over different initialization strategies.", "description": "This table presents the ablation study of the proposed method on the performance of pose estimation and novel view synthesis. The ablation is performed by varying two components: decoupled pose estimation (DP) and iterative refinement of voxel grid (IR). The results show that both DP and IR significantly improve the performance, indicating their importance in the proposed framework. The metrics used are direction error (ed), geodesic distance (eg), and peak signal-to-noise ratio (PSNR).", "section": "5.3 Ablation studies"}, {"figure_path": "9B6J64eTp4/tables/tables_12_1.jpg", "caption": "Table 1: Part-level pose estimation results. Our method outperforms PARIS in majority of object categories while having lower variation over multiple runs in the performance.", "description": "This table presents a comparison of part-level pose estimation results between the proposed method and the PARIS method.  The metrics used are direction error (ea), position error (ep), geodesic distance (ed), and translation error (et). Results are shown for six object categories (laptop, oven, stapler, fridge, blade, and storage). The table highlights that the proposed method achieves lower errors and less variation across multiple runs compared to PARIS, particularly for certain object categories.", "section": "5.2 Results"}, {"figure_path": "9B6J64eTp4/tables/tables_16_1.jpg", "caption": "Table 7: Comparison of rendering quality between objects in their original pose P and articulated pose P'. 'Static' refers to the rendering performance of the object in its original pose P, whereas 'Art.' indicates the rendering quality of the object in articulated pose P' using our method with the static NeRF. Objects marked with * represent those with multiple movable parts.", "description": "This table compares the rendering quality (PSNR) of objects in their original pose (Static) versus their articulated pose (Art.) using the proposed method. The difference (\u0394) is calculated to show the performance drop in the articulated pose compared to the original pose.  Objects with multiple moving parts are marked with an asterisk (*). The results highlight the impact of articulation on rendering quality, indicating that the method maintains good quality even with articulated poses.", "section": "5.2 Results"}, {"figure_path": "9B6J64eTp4/tables/tables_16_2.jpg", "caption": "Table 8: Quantitative evaluation for the same door instance. We report average performance over 5 runs. For the description of ed, ep, eg, PSNR and mIoU, please see Section 5.1 in the submission. Our method outperforms PARIS consistently in all the metrics.", "description": "This table quantitatively evaluates the performance of the proposed method and the baseline method (PARIS) on a door instance.  The metrics used include direction error (ed), position error (ep), geodesic distance (eg), Peak Signal-to-Noise Ratio (PSNR), and mean Intersection over Union (mIoU). The results show that the proposed method outperforms PARIS consistently across all metrics, indicating its superior performance in pose estimation, novel view synthesis, and part segmentation.", "section": "5.2 Results"}]