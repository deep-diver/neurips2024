[{"figure_path": "J8m0DEjxEO/figures/figures_1_1.jpg", "caption": "Figure 1: A higher attention score on the adversarial suffix can indicate a higher attack success rate. We show that the original GCG [35] is not sufficient for jailbreak, as the model may generate the first few target tokens, but may still fail to fulfill the request. In contrast, our method, AttnGCG, successfully bypasses the safety protocols rooted in LLMs by increasing the attention score on the adversarial suffix.", "description": "The figure illustrates the effect of attention manipulation on the success rate of jailbreaking attacks against LLMs.  It shows two scenarios: one using the Greedy Coordinate Gradient (GCG) method, and another using the proposed AttnGCG method.  GCG sometimes produces a few target tokens but fails to fully bypass safety protocols; AttnGCG consistently achieves higher success rates by boosting the attention score on the adversarial suffix, thus successfully jailbreaking the models. The attention scores for each component (system prompt, goal, and suffix) are represented using bar graphs, visually comparing the approaches' performance.", "section": "1 Introduction"}, {"figure_path": "J8m0DEjxEO/figures/figures_2_1.jpg", "caption": "Figure 2: The attention scores and attack success rate (ASR) of GCG [35] (left) and our method (left) on Llama-2-Chat-7B. We observe that (1) the attention score on adversarial suffix can grow simultaneously with the ASR. (2) Meanwhile, attention scores on the goal and system prompt can decrease as the training continues.", "description": "This figure shows a comparison of the performance of GCG and AttnGCG on the Llama-2-Chat-7B model.  The left panel displays the results for GCG, while the right panel shows the results for AttnGCG. Both panels show the attention scores for the goal, suffix, and system components of the input prompt, as well as the attack success rate (ASR) over training steps. The key observation is the positive correlation between the attention score on the adversarial suffix and the ASR.  As the attention on the suffix increases, the ASR also increases, while attention on the goal and system prompts tends to decrease.", "section": "2 Method"}, {"figure_path": "J8m0DEjxEO/figures/figures_3_1.jpg", "caption": "Figure 2: The attention scores and attack success rate (ASR) of GCG [35] (left) and our method (left) on Llama-2-Chat-7B. We observe that (1) the attention score on adversarial suffix can grow simultaneously with the ASR. (2) Meanwhile, attention scores on the goal and system prompt can decrease as the training continues.", "description": "This figure compares the performance of the original GCG method and the proposed AttnGCG method in terms of both attention scores and attack success rates (ASR) on the Llama-2-Chat-7B model. The left panel shows the results for GCG, while the right panel shows the results for AttnGCG. The x-axis represents the number of training steps, while the y-axis represents the attention score or ASR. The figure demonstrates that AttnGCG consistently achieves higher attention scores on the adversarial suffix, leading to significantly improved ASR compared to GCG.", "section": "2 Method"}, {"figure_path": "J8m0DEjxEO/figures/figures_5_1.jpg", "caption": "Figure 4: Attention heatmaps for initial (Step= 0), failed, and successful jailbreaking cases. The attention map captures the attention score mapping from the input prompt with goal and suffix (x-axis) to the output (y-axis). The attention scores on the goal prompt are presented in Table 2.", "description": "This figure shows attention heatmaps for three scenarios: the initial state (Step=0, failed), a failed jailbreaking attempt using GCG (Step=60, failed), and a successful jailbreaking attempt using AttnGCG (Step=60, success). The heatmaps visualize the attention scores, showing how the model's attention is distributed across different input components (goal and suffix) for each scenario. The color intensity represents the attention score, with brighter colors indicating higher attention. The figure demonstrates how AttnGCG successfully shifts the model's focus from the goal to the adversarial suffix, leading to successful jailbreaking.", "section": "3.2 Base Experiments on GCG and AttnGCG"}, {"figure_path": "J8m0DEjxEO/figures/figures_6_1.jpg", "caption": "Figure 5: Attention heatmaps for prompts derived by ICA and AutoDAN. The top two images depict the attention heatmaps from the input prompt (x-axis) to the output (y-axis), with the score of the goal input highlighted. The attention scores on the goal prompt are presented in Table 3.", "description": "This figure shows attention heatmaps for prompts generated by two different methods: ICA and AutoDAN. The top row displays the complete heatmaps, highlighting the attention distribution across the input prompt (goal and suffix) and the output tokens. The bottom row provides zoomed-in views of the goal portion of the heatmaps for a more detailed comparison.  The heatmaps visualize how the models' attention is distributed during the generation process, with warmer colors indicating higher attention scores. This visualization helps understand how these methods affect the model's focus and contribute to jailbreaking success or failure. Table 3 provides the quantitative attention scores for the goal prompt in each scenario.", "section": "3.3 Generalize AttnGCG to other attack methods"}]