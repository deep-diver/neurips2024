[{"figure_path": "g8pyTkxyIV/tables/tables_6_1.jpg", "caption": "Table 1: Comparison of ours with the comparison methods on Neural 3D Video dataset [7]. Training time: Both preprocessing and the accumulated time of all subsequent training phases. Both the training time and FPS are measured under the same machine with an NVIDIA 4090 GPU for strictly fair comparisons. \u2020: STG is done with an H100 GPU machine due to the memory issue. \u2021: Trained using a dataset split into 150 frames.", "description": "This table compares the proposed Explicit 4D Gaussian Splatting (Ex4DGS) method with other state-of-the-art dynamic novel view synthesis methods on the Neural 3D Video dataset.  The comparison includes PSNR, SSIM, and LPIPS metrics, as well as training time, model size, and frames per second (FPS).  The table is divided into sections based on whether dense or sparse COLMAP point cloud input was used, highlighting the robustness of Ex4DGS to different data conditions. Footnotes clarify specific experimental details.", "section": "5.1 Neural 3D Video Dataset"}, {"figure_path": "g8pyTkxyIV/tables/tables_7_1.jpg", "caption": "Table 2: Comparison results on the Technicolor dataset [20]. \u2020: Trained with sparse point cloud input.", "description": "This table compares the performance of different novel view synthesis methods on the Technicolor dataset.  The metrics used are PSNR, SSIM1, SSIM2, and LPIPS. The results are shown for both scenarios: using dense and sparse COLMAP point cloud inputs. The table highlights that the proposed Ex4DGS method achieves high performance even with sparse input.", "section": "5.2 Technicolor Dataset"}, {"figure_path": "g8pyTkxyIV/tables/tables_8_1.jpg", "caption": "Table 3: Ablation studies of the proposed methods.", "description": "This table presents the ablation study of the proposed method, Explicit 4D Gaussian Splatting (Ex4DGS).  It shows the impact of different components of the Ex4DGS model on its performance, as measured by PSNR, SSIM1, LPIPS, and model size (in MB).  The ablation study systematically removes or replaces different components such as the interpolation method, the temporal opacity, and the progressive training scheme to evaluate their contribution to the overall performance.", "section": "5.4 Ablation Studies"}, {"figure_path": "g8pyTkxyIV/tables/tables_14_1.jpg", "caption": "Table 4: Comparison results between without handling color changes and our complete model.", "description": "This table compares the performance of the 3DGS model (without handling color changes) against Ex4DGS (our complete model) on the Coffee Martini scene of the Neural 3D video dataset.  It shows that Ex4DGS significantly outperforms the baseline 3DGS model in terms of PSNR, SSIM1, and LPIPS, highlighting the importance of incorporating dynamic points to accurately handle changes in color and appearance.", "section": "5.4 Ablation Studies"}, {"figure_path": "g8pyTkxyIV/tables/tables_15_1.jpg", "caption": "Table 5: Ablation studies of keyframe interval selections and skipped frames.", "description": "This table presents the ablation study results on the effects of different keyframe intervals and motion magnitudes on the performance of the proposed method.  The experiment was conducted on the Cook Spinach scene from the Neural 3D Video dataset.  The table shows how PSNR, SSIM1, LPIPS, and model size (in MB) vary across different combinations of skipped frames (simulating various motion speeds) and keyframe intervals.", "section": "5.4 Ablation Studies"}, {"figure_path": "g8pyTkxyIV/tables/tables_15_2.jpg", "caption": "Table 6: Ablation studies of dynamic point conversion rate.", "description": "This table presents the ablation study results on the dynamic point conversion rate.  It shows the PSNR, SSIM1, LPIPS, and model size (in MB) achieved using different percentages of dynamic points extracted during training. The results indicate an optimal balance between the number of dynamic points and model performance; using too few or too many points can lead to suboptimal results.", "section": "5.4 Ablation Studies"}, {"figure_path": "g8pyTkxyIV/tables/tables_15_3.jpg", "caption": "Table 7: Quantitative results of the repeatedly occluded objects in the Technicolor Train scene.", "description": "This table presents a quantitative comparison of different novel view synthesis methods on the repeatedly occluded objects in the Technicolor Train scene. The metrics used for comparison are PSNR, SSIM1, and LPIPS.  The results highlight the performance of each model in handling occlusions, showing how well they maintain image quality when objects are partially or completely hidden.", "section": "5.1 Neural 3D Video Dataset"}, {"figure_path": "g8pyTkxyIV/tables/tables_16_1.jpg", "caption": "Table 8: Quantitative results of the appearing objects in Technicolor Birthday scene.", "description": "This table presents a quantitative comparison of different methods for handling newly appearing objects in the Technicolor Birthday scene. The metrics used for comparison are PSNR, SSIM1, and LPIPS.  The results show that the proposed method (Ours) outperforms the other methods, achieving significantly higher PSNR and SSIM1 values while having a much lower LPIPS value, which indicates better visual quality.", "section": "5.2 Technicolor Dataset"}, {"figure_path": "g8pyTkxyIV/tables/tables_16_2.jpg", "caption": "Table 9: Quantitative results of the extremely long video on Flame Salmon scene in Neural 3D Video dataset.", "description": "This table presents a quantitative comparison of different models on the Flame Salmon scene from the Neural 3D Video dataset using an extremely long video sequence (1000 frames).  The metrics shown are PSNR, SSIM1, LPIPS, and model size.  It highlights the performance of various methods when dealing with extended temporal durations.", "section": "5.1 Neural 3D Video Dataset"}, {"figure_path": "g8pyTkxyIV/tables/tables_17_1.jpg", "caption": "Table 1: Comparison of ours with the comparison methods on Neural 3D Video dataset [7]. Training time: Both preprocessing and the accumulated time of all subsequent training phases. Both the training time and FPS are measured under the same machine with an NVIDIA 4090 GPU for strictly fair comparisons. \u2020: STG is done with an H100 GPU machine due to the memory issue. \u2021: Trained using a dataset split into 150 frames.", "description": "This table compares the proposed Ex4DGS model with several state-of-the-art dynamic Gaussian splatting methods on the Neural 3D Video dataset.  The comparison includes metrics such as PSNR, SSIM, LPIPS, training time, model size and rendering FPS.  It highlights the performance differences under both dense and sparse point cloud input conditions.  Specific notes are provided regarding different GPU usage and dataset sizes for some methods.", "section": "5.1 Neural 3D Video Dataset"}, {"figure_path": "g8pyTkxyIV/tables/tables_18_1.jpg", "caption": "Table 1: Comparison of ours with the comparison methods on Neural 3D Video dataset [7]. Training time: Both preprocessing and the accumulated time of all subsequent training phases. Both the training time and FPS are measured under the same machine with an NVIDIA 4090 GPU for strictly fair comparisons. \u2020: STG is done with an H100 GPU machine due to the memory issue. \u2021: Trained using a dataset split into 150 frames.", "description": "This table compares the proposed Ex4DGS method with other state-of-the-art dynamic Gaussian splatting methods on the Neural 3D Video dataset.  It shows a comparison of PSNR, SSIM, and LPIPS scores, as well as training time (including preprocessing) and frames per second (FPS).  The table also notes some differences in hardware and dataset sizes used for training among the various methods.", "section": "5.1 Neural 3D Video Dataset"}]