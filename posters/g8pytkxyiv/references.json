{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2020-00-00", "reason": "This paper introduces Neural Radiance Fields (NeRF), a foundational work in novel view synthesis that heavily influences many subsequent approaches, including this paper's method."}, {"fullname_first_author": "Albert Pumarola", "paper_title": "D-Nerf: Neural radiance fields for dynamic scenes", "publication_date": "2021-00-00", "reason": "This work is highly relevant as it directly addresses the problem of dynamic scene representation, a core challenge that this paper aims to improve upon."}, {"fullname_first_author": "Tianye Li", "paper_title": "Neural 3D video synthesis from multi-view video", "publication_date": "2022-00-00", "reason": "This paper introduces a large-scale dataset for neural 3D video synthesis, which provides a benchmark for evaluating the performance of dynamic novel view synthesis methods like the one proposed in this paper."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces 3D Gaussian Splatting (3DGS), which is the foundation upon which this paper builds its approach for efficient and high-quality rendering."}, {"fullname_first_author": "Zeyu Yang", "paper_title": "Real-time photorealistic dynamic scene representation and rendering with 4D Gaussian splatting", "publication_date": "2023-00-00", "reason": "This paper explores extending Gaussian splatting to dynamic scenes, directly tackling the same problem this paper addresses, making it a key comparative work."}]}