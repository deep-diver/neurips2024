[{"figure_path": "otZPBS0un6/tables/tables_7_1.jpg", "caption": "Table 1: The cross-dataset evaluation of different methods. Blue indicates best and red indicates second best.", "description": "This table compares the performance of FreqBlender against several state-of-the-art DeepFake detection methods across multiple datasets (CDF, DFDC, DFDCP, FFIW).  It shows the Area Under the Curve (AUC) scores for each method on each dataset.  The AUC is a metric used to evaluate the performance of a binary classification model. The table highlights the best and second-best performing methods for each dataset, indicating the relative strengths of each approach in different scenarios and datasets.  This demonstrates the generalization ability of the various methods.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/tables/tables_8_1.jpg", "caption": "Table 2: The cross-manipulation evaluation of different methods.", "description": "This table presents the cross-manipulation results of different DeepFake detection methods on the FF++ dataset.  The methods are compared across four different manipulation techniques (Deepfakes, Face2Face, FaceSwap, and NeuralTextures).  The table shows the AUC scores achieved by each method on each manipulation type, as well as the average AUC across all manipulation types.  It highlights the relative performance of FreqBlender (the proposed method) against existing state-of-the-art methods (SBI-raw and SBI-c23).  The results demonstrate the effectiveness of FreqBlender in improving the generalization performance of DeepFake detection models.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/tables/tables_8_2.jpg", "caption": "Table 3: Effect of each objective term.", "description": "This table presents the ablation study results showing the impact of each objective term (Lff, Lad, Lqa, Lpi) on the overall performance of the FreqBlender method.  The \"Baseline\" row indicates the performance with all objective terms included. Subsequent rows show performance when removing one objective term at a time. This demonstrates the individual contribution of each objective to the overall effectiveness of the model.  The results are presented in terms of AUC (%) across three datasets (CDF, DFDC, DFDCP) and an average across all three. The higher AUC percentage indicates a better performance on the task of detecting DeepFakes.", "section": "5.3 Analysis"}, {"figure_path": "otZPBS0un6/tables/tables_8_3.jpg", "caption": "Table 1: The cross-dataset evaluation of different methods. Blue indicates best and red indicates second best.", "description": "This table presents the Area Under the Curve (AUC) scores achieved by different deepfake detection methods across various datasets.  Each method was tested on multiple datasets (CDF, DFDC, DFDCP, FFIW), after being trained on a single dataset (usually FF++). The table showcases the generalization ability of each method, as the differences between AUC scores across datasets highlight a model's robustness to unseen data.  Higher AUC values indicate better performance. The best and second-best results for each dataset are highlighted in blue and red, respectively.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/tables/tables_8_4.jpg", "caption": "Table 1: The cross-dataset evaluation of different methods. Blue indicates best and red indicates second best.", "description": "This table presents the Area Under the Receiver Operating Characteristic Curve (AUC) scores achieved by various deepfake detection methods across multiple datasets.  The methods are tested on four different datasets (CDF, DFDC, DFDCP, FFIW), and the table highlights the best and second-best performing methods for each dataset. The results show how well each method generalizes to unseen data, indicating its robustness and effectiveness in detecting deepfakes.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/tables/tables_9_1.jpg", "caption": "Table 6: Effect of using wild fake or SP-fake faces.", "description": "This table compares the performance of the proposed FreqBlender method using two types of pseudo-fake faces: those generated using spatial blending alone (SP-fake) and those generated using both spatial and frequency blending (indicated by a checkmark).  The results show a significant improvement in detection performance across four different datasets (CDF, DFDC, DFDCP, FFIW) when using the frequency blending method.  This highlights the effectiveness of incorporating frequency information into the generation of pseudo-fake data for enhancing the generalizability of DeepFake detection models.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/tables/tables_14_1.jpg", "caption": "Table 7: Effect of our method on different loss proportions.", "description": "This table presents the performance of the FreqBlender method under different weight combinations for the loss functions used in training the Frequency Parsing Network. It shows the AUC scores on four DeepFake detection datasets (CDF, FF++, FFIW, and DFDCP) for various weight settings (\u03bb1, \u03bb2, \u03bb3, \u03bb4). The last column displays the average AUC across these datasets. This analysis helps determine the optimal weight combination for the loss functions, which contributes to the overall effectiveness of the FreqBlender method.", "section": "5.3 Analysis"}, {"figure_path": "otZPBS0un6/tables/tables_14_2.jpg", "caption": "Table 8: Effect of our method complementary to spatial-blending Methods.", "description": "This table presents the results of experiments where the proposed FreqBlender method is combined with three existing spatial blending methods (DSP-FWA [10], I2G [15], and Face X-ray [14]) for DeepFake detection on the FF++ dataset.  The table shows the AUC (%) achieved by each of the three spatial blending methods alone and when enhanced with FreqBlender, broken down by different manipulation types (DF, F2F, FS, NT) and providing an average AUC across all manipulation types.  This demonstrates the complementary nature of FreqBlender which improves the performance of the existing spatial methods.", "section": "5.3 Analysis"}, {"figure_path": "otZPBS0un6/tables/tables_14_3.jpg", "caption": "Table 1: The cross-dataset evaluation of different methods. Blue indicates best and red indicates second best.", "description": "This table presents the Area Under the Curve (AUC) of various deepfake detection methods tested on several benchmark datasets.  The methods are categorized by input type (video or frame) and trained on different datasets. The AUC values show the performance of each method on each test dataset.  Higher AUC values represent better performance.  The best and second-best results for each dataset are highlighted in blue and red, respectively.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/tables/tables_16_1.jpg", "caption": "Table 1: The cross-dataset evaluation of different methods. Blue indicates best and red indicates second best.", "description": "This table presents the Area Under the Curve (AUC) scores achieved by various deepfake detection methods across multiple datasets (CDF, DFDC, DFDCP, FFIW). The methods are categorized into video-level and frame-level approaches, highlighting their performance on both real and fake videos from different sources.  The best and second-best results for each dataset are marked in blue and red, respectively, facilitating a clear comparison of different methods' generalization capabilities.", "section": "5.2 Results"}, {"figure_path": "otZPBS0un6/tables/tables_16_2.jpg", "caption": "Table 1: The cross-dataset evaluation of different methods. Blue indicates best and red indicates second best.", "description": "This table presents the Area Under the Curve (AUC) of different deepfake detection methods tested on several datasets.  The methods are categorized into video-level and frame-level approaches. The AUC scores show the performance of each method on the different datasets, indicating how well they can distinguish between real and fake videos or images.  The best and second-best performances are highlighted in blue and red, respectively. This helps to compare the generalizability and effectiveness of each method across various datasets and input types.", "section": "5.2 Results"}]