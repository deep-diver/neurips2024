[{"figure_path": "VXJVNdmXO4/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of Data Marketplace Approach. A buyer brings their test query (e.g., a patient's chest X-ray needing diagnosis) and a budget to the marketplace. DAVED selects the most relevant subset of seller training data to minimize prediction error on the buyer's specified test query while respecting budget constraints. Unlike prior methods that require labeled validation data, DAVED directly optimizes for test performance. This enables targeted, cost-effective data acquisition compared to purchasing entire datasets.", "description": "This figure illustrates the data marketplace approach used in the paper.  A buyer submits a test query (e.g., an X-ray) and a budget. The platform, using the buyer's query, selects the most relevant training data from various sellers.  A model is then trained on this selected data, and the prediction is returned to the buyer. The key point is that DAVED directly optimizes for test performance without needing labeled validation data, making it cost-effective and suitable for decentralized markets.", "section": "1 Introduction"}, {"figure_path": "VXJVNdmXO4/figures/figures_2_1.jpg", "caption": "Figure 2: Failures of Current Validation-based Data Valuation Methods. Current data valuation methods overfit when data dimensionality is high or validation sets are small. Using 1,000 seller datapoints (each with cost 1) of Gaussian distributed data, we compare test error across methods as buyers acquire data under different budgets. (Left) Validation-based data valuation methods overfit when the data is too high dimensional (d = 30). (Right) Even with low-dimensional data (d = 10), overfitting occurs when the validation set is too small (n = 10), resulting in worse performance than random selection. Our validation-free method (DAVED) method maintains low error in both scenarios.", "description": "This figure compares the test error of several data valuation methods against the proposed DAVED method under different budget constraints and data dimensionality.  The results show that validation-based methods suffer from overfitting when the data dimension is high or the validation set is small, resulting in higher test error compared to random selection.  In contrast, DAVED consistently maintains a low test error regardless of the data dimensionality or validation set size.", "section": "Data Acquisition versus Data Valuation"}, {"figure_path": "VXJVNdmXO4/figures/figures_7_1.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "This figure compares the test prediction error of DAVED and other data valuation methods on synthetic data with varying amounts of seller training data and budgets.  DAVED consistently outperforms other methods, particularly with smaller budgets, showing its effectiveness in efficiently acquiring data.", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_8_1.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "This figure compares the performance of DAVED (multi-step and single-step) and other data valuation methods (Data OOB, Data Shapley, DVRL, Influence, KNN Shapley, LAVA, Leave One Out, Random) in terms of test prediction error on synthetic data with varying sizes (1K, 5K, 100K datapoints) and budgets. DAVED consistently outperforms other methods, demonstrating its effectiveness in acquiring data efficiently and achieving lower prediction error.", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_9_1.jpg", "caption": "Figure 5: Computational efficiency comparison. DAVED has significantly lower computational overhead compared to model-based data valuation methods. (Left) Runtime scaling with data dimensionality (fixed 1,000 datapoints). (Right) Runtime scaling with the amount of seller data (fixed 30 dimensions). Our single-step variant is faster than even optimized methods like KNN Shapley, while the multi-step variant remains efficient while achieving better performance. Our optimization procedure only requires O(d) communication per round, which makes it particularly suited for decentralized data market settings. For Data Shapley and Leave-One-Out, some experiments were omitted due to prohibitively long runtimes.", "description": "This figure compares the computational efficiency of DAVED with other data valuation methods. The left panel shows runtime scaling with data dimensionality, while the right panel shows runtime scaling with the amount of seller data. DAVED's single-step variant is faster than other methods.  DAVED's multi-step variant is efficient and achieves better performance.  The O(d) communication complexity makes DAVED suitable for decentralized settings.", "section": "Our Methods and Implementations"}, {"figure_path": "VXJVNdmXO4/figures/figures_20_1.jpg", "caption": "Figure 6: DAVED maintains performance advantage with heterogeneous costs on synthetic data. We evaluate data selection methods on 10K synthetic Gaussian datapoints with costs randomly sampled from {1, 2, 3, 4, 5} and transformed using two cost functions: \u221ac (left) and c\u00b2 (right). Each datapoint's label noise is scaled inversely with cost (\u025b/cj) to simulate quality differences. DAVED achieves lower test MSE across budgets 1\u201330 while respecting cost constraints, demonstrating robust performance even with varying data quality and costs. Results are averaged over 100 random buyer test points.", "description": "This figure compares the performance of DAVED and other data valuation methods on synthetic data with heterogeneous costs.  The costs are randomly sampled and then transformed using two different cost functions (\u221ac and c\u00b2).  Label noise is inversely proportional to the cost, simulating that higher-cost data is of higher quality.  The results show that DAVED consistently outperforms other methods across various budget levels, maintaining a low mean squared error (MSE).", "section": "Comparing Performance on Data with Heterogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_20_2.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "This figure compares the test prediction error of DAVED and other data valuation methods on synthetic datasets with varying sizes (1K, 5K, and 100K data points). The results show that DAVED consistently achieves lower mean squared error (MSE) with fewer data points purchased, demonstrating better data acquisition efficiency.  Both the multi-step and single-step versions of DAVED outperform other methods, especially when the budget is small (5-10 data points).", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_21_1.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "The figure compares the test prediction error of DAVED and other data valuation methods on synthetic data with varying amounts of seller training data and budgets. DAVED consistently outperforms other methods, especially with small budgets.", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_21_2.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "This figure compares the test prediction error of DAVED and other data valuation methods on synthetic datasets of varying sizes (1K, 5K, and 100K data points).  It shows how DAVED consistently achieves lower mean squared error (MSE) with fewer purchased data points, demonstrating its superior data acquisition efficiency.  The benefit of DAVED is more pronounced when the budget is limited.  Results are averaged over 100 random test points.", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_22_1.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "This figure compares the performance of DAVED and other data valuation methods on synthetic data with varying amounts of seller data and budgets.  It shows that DAVED consistently achieves lower mean squared error (MSE) with fewer data points purchased, demonstrating better data acquisition efficiency.  The performance difference is particularly noticeable with smaller budgets.", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_22_2.jpg", "caption": "Figure 2: Failures of Current Validation-based Data Valuation Methods. Current data valuation methods overfit when data dimensionality is high or validation sets are small. Using 1,000 seller datapoints (each with cost 1) of Gaussian distributed data, we compare test error across methods as buyers acquire data under different budgets. (Left) Validation-based data valuation methods overfit when the data is too high dimensional (d = 30). (Right) Even with low-dimensional data (d = 10), overfitting occurs when the validation set is too small (n = 10), resulting in worse performance than random selection. Our validation-free method (DAVED) method maintains low error in both scenarios.", "description": "The figure compares the test error of various data valuation methods against DAVED (the proposed method) under different budget constraints.  It showcases how validation-based methods suffer from overfitting when the data dimensionality is high or the validation set is small, leading to poor performance compared to random selection. In contrast, DAVED maintains low error even in these challenging scenarios.", "section": "Data Acquisition versus Data Valuation"}, {"figure_path": "VXJVNdmXO4/figures/figures_23_1.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "This figure compares the performance of DAVED and several other data valuation methods on synthetic data with varying amounts of data (1K, 5K, and 100K points) and budgets.  The results show that DAVED consistently achieves lower mean squared error (MSE) with fewer data points purchased compared to other methods, highlighting its data acquisition efficiency.  The performance difference is more pronounced when the budget is limited.", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_23_2.jpg", "caption": "Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points.", "description": "The figure compares the test prediction error of DAVED and other data valuation methods under various budgets and amounts of seller data for synthetic Gaussian data.  It shows that DAVED consistently achieves lower mean squared error (MSE) with fewer purchased data points compared to other methods, especially when the budget is small.  Both the single-step and multi-step variants of DAVED perform better.", "section": "Comparing Performance on Data with Homogeneous Costs"}, {"figure_path": "VXJVNdmXO4/figures/figures_24_1.jpg", "caption": "Figure 14: Linear models in feature space approximate full model fine-tuning. We compare BERT performance on DrugLib reviews using either full fine-tuning (which updates all model parameters) or linear probing (which only trains a linear layer on frozen embeddings) on data selected by DAVED versus random selection. The similar performance patterns between these approaches empirically validates our use of kernelized linear regression in the feature space as a proxy for the full training dynamics. This aligns with recent theoretical work showing that fine-tuning of pre-trained models is well-approximated by linear models in the empirical Neural Tangent Kernel (eNTK) regime. Since our method relies on this linear approximation for efficient data selection, these results support our choice of feature extractor \u03c6 and linear modeling approach. Results show test error averaged over 100 random trials using different test reviews.", "description": "The figure compares the performance of linear probing and full fine-tuning for BERT models on DrugLib reviews using data selected by DAVED and random selection. The results show that linear probing performs similarly to fine-tuning, validating the use of kernelized linear regression as a proxy for the training dynamics and supporting the choice of a linear modeling approach for data selection. Error bars represent the average test error over 100 random trials with different test reviews.", "section": "D.5 Linear Feature Space Approximation"}, {"figure_path": "VXJVNdmXO4/figures/figures_24_2.jpg", "caption": "Figure 15: DAVED's iterative optimization matches convex solver accuracy. We compare the prediction error of Frank-Wolfe optimization with a convex optimization solver on 1,000 datapoints sampled from 30-dimensional Gaussian distribution. Both single-step and multi-step variants of our iterative approach achieve comparable accuracy to the optimal convex solution while being significantly faster to optimize. Results averaged over 100 random trials with homogeneous costs (cj = 1).", "description": "This figure compares the performance of DAVED's iterative optimization method against a convex optimization solver.  Both methods are applied to a data selection problem using 1000 data points sampled from a 30-dimensional Gaussian distribution.  The results show that DAVED's iterative approach achieves accuracy comparable to the convex solver, but with significantly faster optimization times.  The comparison is done for both the multi-step and single-step variants of DAVED.", "section": "D.6 Iterative versus Convex optimization"}, {"figure_path": "VXJVNdmXO4/figures/figures_25_1.jpg", "caption": "Figure 5: Computational efficiency comparison. DAVED has significantly lower computational overhead compared to model-based data valuation methods. (Left) Runtime scaling with data dimensionality (fixed 1,000 datapoints). (Right) Runtime scaling with the amount of seller data (fixed 30 dimensions). Our single-step variant is faster than even optimized methods like KNN Shapley, while the multi-step variant remains efficient while achieving better performance. Our optimization procedure only requires O(d) communication per round, which makes it particularly suited for decentralized data market settings. For Data Shapley and Leave-One-Out, some experiments were omitted due to prohibitively long runtimes.", "description": "This figure compares the computational efficiency of DAVED with other data valuation methods.  The left panel shows how runtime scales with increasing data dimensionality (number of features), while the right panel demonstrates runtime scaling with increasing amounts of seller data.  DAVED, particularly its single-step version, shows significantly faster runtimes compared to other methods, making it suitable for decentralized settings with limited communication.", "section": "Our Methods and Implementations"}]