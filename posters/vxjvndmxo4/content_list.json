[{"type": "text", "text": "Data Acquisition via Experimental Design for Data Markets ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Charles Lu\u2217 Baihe Huang Sai Praneeth Karimireddy Praneeth Vepakomma MIT UC Berkeley USC, UC Berkeley MBZUAI, MIT ", "page_idx": 0}, {"type": "text", "text": "Michael I. Jordan Ramesh Raskar UC Berkeley MIT ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The acquisition of training data is crucial for machine learning applications. Data markets can increase the supply of data, particularly in data-scarce domains such as healthcare, by incentivizing potential data providers to join the market. A major challenge for a data buyer in such a market is choosing the most valuable data points from a data seller. Unlike prior work in data valuation, which assumes centralized data access, we propose a federated approach to the data acquisition problem that is inspired by linear experimental design. Our proposed data acquisition method achieves lower prediction error without requiring labeled validation data and can be optimized in a fast and federated procedure. The key insight of our work is that a method that directly estimates the benefti of acquiring data for test set prediction is particularly compatible with a decentralized market setting. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "While massive training datasets enable major machine learning breakthroughs, they remain largely inaccessible outside of large companies, motivating mechanisms for broader data access. A related point is that many data owners have become resistant to having their data collected indiscriminately without their consent or without their participation in the fruits of predictive modeling, resulting in legal challenges against prominent AI companies [16, 33]. These trends motivate the study of data marketplaces, which aim to incentivize data sharing between sellers, that provide access to data, and buyers, that pay compensation for data access [11, 1, 54]. ", "page_idx": 0}, {"type": "text", "text": "For practical data acquisition scenarios, a data buyer has a specific goal in mind and, in particular, wants training data to predict their test data in a specified context. Accessing different datapoints may require varying prices associated with each datapoint, which may reflect heterogeneous cost, quality, or privacy levels for each datapoint [44, 40]. ", "page_idx": 0}, {"type": "text", "text": "For example, consider a hospital that wants to make a prediction for a specific patient\u2019s X-ray. The hospital can submit this X-ray as an unlabeled test query to the marketplace, along with a budget to access relevant training data. The marketplace selects useful training data to build a model for this specific prediction task, sharing only the final prediction rather than the raw data to protect privacy. This process can be repeated for each new patient query (see Figure 1). However, not all $\\boldsymbol{\\mathrm{X}}$ -ray images will be equally relevant. Thus, we want to select only those seller datapoints that are most useful for answering the buyer\u2019s query and fit the buyer\u2019s budget. ", "page_idx": 0}, {"type": "text", "text": "This goal of data acquisition has motivated the development of many data-valuation techniques (e.g., [23, 29, 38, 60, 52, 39, 57, 46, 30]). However, we argue that current data valuation techniques are misaligned with the data acquisition problem, particularly in the context of data marketplaces. They all face at least one of the following limitations: ", "page_idx": 0}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/9e17fe6f8bb8db9cd0008ebed3964470dc7c8bfc4266d5db1e632ee11568ce8d.jpg", "img_caption": ["Figure 1: Overview of Data Marketplace Approach. A buyer brings their test query (e.g., a patient\u2019s chest $\\Chi$ -ray needing diagnosis) and a budget to the marketplace. DAVED selects the most relevant subset of seller training data to minimize prediction error on the buyer\u2019s specified test query while respecting budget constraints. Unlike prior methods that require labeled validation data, DAVED directly optimizes for test performance. This enables targeted, cost-effective data acquisition compared to purchasing entire datasets. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "\u2022 The selection process may not be adaptive to the buyer\u2019s (unlabeled) test queries, potentially failing to identify the most relevant data. In a data marketplace, buyers typically need to purchase only a small subset of datapoints most relevant to their test data, which may follow a significantly different distribution than the overall seller data. \u2022 When adaptive selection is implemented, these techniques rely on labeled validation data, which is often impractical. Further, when a small quantity of such data is available, the selection may overfit the validation data and result in poor performance on the test queries. \u2022 The algorithms are not scalable and typically require retraining the ML model numerous times. Hence, they are unable to select from realistic seller corpora ( ${>}100\\mathrm{K}+$ datapoints). ", "page_idx": 1}, {"type": "text", "text": "Instead, we propose data acquisition via experimental design (DAVED) method that overcomes all of these limitations. Unlike most previous work in data valuation, our approach does not require a labeled validation dataset and instead directly optimizes data selection for the buyer\u2019s unlabeled test queries. ", "page_idx": 1}, {"type": "text", "text": "Additionally, our approach accounts for budget constraints and is able to weigh the price of each seller\u2019s datapoint against its potential benefit, simultaneously solving the budget and revenue allocation problems [64]. Moreover, it can be implemented in a federated manner, achieving lower prediction error even compared to centralized baselines. ", "page_idx": 1}, {"type": "text", "text": "Our contributions are the following: ", "page_idx": 1}, {"type": "text", "text": "1. Formulate the data acquisition problem for data marketplaces and demonstrate that data valuation methods make a fundamental theoretical mistake of \u201cinference after selection\u201d (Theorem 1).   \n2. Design a novel, highly scalable, and distributed data selection procedure that eliminates the need for validation data by directly selecting the most cost-effective seller data to answer the buyer\u2019s test queries (Algorithm 1).   \n3. Demonstrate state-of-the-art performance on synthetic data and medical data in various modalities (X-rays, images, and text). ", "page_idx": 1}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/a50390cef299ab7142e1af59c6ea70d798901a9622434597da61397185f378e3.jpg", "img_caption": ["Figure 2: Failures of Current Validation-based Data Valuation Methods. Current data valuation methods overfit when data dimensionality is high or validation sets are small. Using 1,000 seller datapoints (each with cost 1) of Gaussian distributed data, we compare test error across methods as buyers acquire data under different budgets. (Left) Validation-based data valuation methods overfit when the data is too high dimensional $\\ A=30)$ ). (Right) Even with low-dimensional data $\\left.d=10\\right.$ ), overfitting occurs when the validation set is too small $\\lceil n\\,=\\,10\\rceil$ ), resulting in worse performance than random selection. Our validation-free method (DAVED) method maintains low error in both scenarios. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "2 Data Acquisition versus Data Valuation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In a decentralized data marketplace, data acquisition must be performed before full data access is granted to the buyer [36]. This relates to Arrow\u2019s Information Paradox [7] \u2014 sellers are unwilling to share data before payment, while buyers need to evaluate utility before purchasing. This distinction between data valuation and data acquisition for data marketplaces is also discussed in a recent data acquisition benchmark, where data value must be estimated without requiring white-box access to the seller\u2019s data (i.e., full, unrestricted access to the data) [12]. ", "page_idx": 2}, {"type": "text", "text": "A more fundamental issue with validation-based data valuation approaches is exemplified by the Data Shapley value approach [23, 29, 38, etc.], which measures the marginal contribution of each training datapoint\u2019s improvement to a validation metric. They are great for after-the-fact attributing the relative influence of the training data. However, they cannot be used to make decisions about which datapoints should be included in the training. This is because of, as noted earlier, the \u201cinference after selection\u201d issue. Using validation data to select training data leads to substantial over-ftiting to the validation data. ", "page_idx": 2}, {"type": "text", "text": "Illustrative example: Suppose that we only have a single validation datapoint. Then, it is clear that we will select training data similar to this singular datapoint, and our selection has no hope of working on the test dataset. While this clearly demonstrates overfitting in an extreme scenario, we show in Figure 2 that increasing the validation set size does not circumvent this issue. We see that other data valuation techniques have poor test prediction errors\u2014some techniques even underperform even a random selection baseline! This clearly demonstrates overfitting. Our proposed method maintains low test error as more seller training data is selected. In Section 3, we will dig in deeper into this phenomenon and prove a very strong theoretical lower bound. We show that any approach that relies upon validation data for data selection can perform as badly as throwing away all the training data and simply training on the validation data alone! This is especially true when our budget is small compared to the dimensionality of the problem, as is likely in a data market setting \u2014 the data is typically high dimensional, and we can only select a very small fraction of the total available data. ", "page_idx": 2}, {"type": "text", "text": "3 Setup and Limitations of Prior Methods ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Description of Data Acquisition Setting. As shown in Figure 1, in our setting of data acquisition, a buyer has a budget and test data. The platform uses the buyer\u2019s data to select training datapoints from the seller that optimize buyer test error. The interaction proceeds as follows: ", "page_idx": 2}, {"type": "text", "text": "1. The buyer brings their test data $X^{\\mathrm{test}}=[x_{1}^{\\mathrm{test}},\\cdot\\cdot\\cdot,x_{m}^{\\mathrm{test}}]$ and a budget $B$ to the market platform. This test data is associated with un1known targmet labels $Y^{\\mathrm{test}}=[y_{1}^{\\mathrm{test}},\\cdot\\cdot\\cdot,y_{m}^{\\mathrm{test}}]$ . ", "page_idx": 2}, {"type": "text", "text": "2. The platform also has access to $n$ datapoints from data sellers $Z^{\\mathrm{train}}=\\{(x_{j},y_{j})\\}_{j=1,\\dots,n}$ and their associated costs $\\{c_{j}\\}_{j=1,\\ldots,n}$ . ", "page_idx": 3}, {"type": "text", "text": "3. Given only the covariates $X^{\\mathrm{test}}$ , the platform assigns a selection weight $w_{j}$ to each datapoint $(x_{j},y_{j})$ . This weight $w_{j}\\in\\{0,1\\}$ represents the discrete action of selecting datapoint $j$ . 4. The platform selects datapoints from the sellers according to $\\mathbf{w}=(w_{1},\\ldots,w_{n})$ , trains a model $f_{\\hat{\\theta}(\\mathbf{w})}$ , makes the predictions $f_{\\hat{\\theta}(\\mathbf{w})}(X^{\\mathrm{test}})$ , and distributes $c_{j}\\cdot w_{j}$ payment for each datapoint used in training. ", "page_idx": 3}, {"type": "text", "text": "In general, we do not make i.i.d assumptions between the train and test - we expect the test queries will not be similar to the total available train data. The goal then is to pick the weights w, which minimizes the prediction error for the buyer while adhering to their budget constraint $\\textstyle\\sum_{j=1}^{n}w_{j}c_{j}\\leq B$ . This gives rise to the following problem: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{w}\\in\\{0,1\\}^{n}}\\mathcal{L}(\\mathbf{w}):=\\frac{1}{m}\\sum_{i=1}^{m}\\mathbb{E}\\left[l\\left(f_{\\hat{\\theta}(\\mathbf{w})}(x_{i}^{\\mathrm{test}}),y_{i}^{\\mathrm{test}}\\right)\\right]\\quad\\mathrm{s.t.}\\,\\sum_{j=1}^{n}w_{j}c_{j}\\leq B,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $l$ is squared loss. Here, the expectation is over the conditional label distribution of $y_{i}^{\\mathrm{test}}|x_{i}^{\\mathrm{test}}$ , and the potential randomness of the algorithm. Note that this problem can not be solved because we do not know the targets $Y^{\\mathrm{test}}$ . Instead, we need to rely on a surrogate objective function (proxy) $\\hat{\\mathcal{L}}(\\mathbf{w})$ . One approach to constructing such a proxy is by using validation data. ", "page_idx": 3}, {"type": "text", "text": "Folly of Relying on Validation Data. In most data valuation methods, e.g., Data Shapley [23], the value of data is evaluated using a labeled validation set $Z^{\\mathrm{val}}=\\{(x_{j}^{\\mathrm{val}},y_{j}^{\\mathrm{val}})\\}_{j=1}^{n_{\\mathrm{val}}}$ . Implicitly, these methods assume that the known $Z^{\\mathrm{val}}$ is drawn from the same distribution as the unknown $Z^{\\mathrm{test}}$ . Then using this validation data, scores $\\left(s_{1},\\ldots,s_{n}\\right)$ are assigned to the seller training datapoints $Z^{\\mathrm{train}}$ . For two datapoints $i,j\\in$ train, the score $s_{i}>s_{j}$ if the datapoint $i$ is more valuable than $j$ [46, 30]. More concretely, $s_{i}>s_{j}$ implies that training with $i$ would lead to a smaller validation loss than if $j$ was used instead. Thus, these scores can used to select the most valuable datapoints. ", "page_idx": 3}, {"type": "text", "text": "However, note that we used the validation dataset to compute the scores. Thus, selecting the top- $\\cdot\\mathbf{k}$ scores results in implicitly minimizing the validation loss i.e., all validation-based data valuation schemes implicitly optimize the following proxy loss ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{w}\\in\\{0,1\\}^{n}}\\hat{\\mathcal{L}}^{\\mathrm{val}}(\\mathbf{w}):=\\sum_{j=1}^{n_{\\mathrm{val}}}l\\left(f_{\\hat{\\theta}(w)}(x_{j}^{\\mathrm{val}}),y_{j}^{\\mathrm{val}}\\right)\\quad\\mathrm{s.t.~}\\sum_{j=1}^{n}w_{j}c_{j}\\leq B.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This approach heavily relies on the quantity and quality of the validation dataset in order to generalize to the actual test dataset. In fact, we have the following minimax lower bound even when restricting ourselves to simple linear models. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1 (Informal version of Theorem A.1). Let $\\mathbf{w}^{*}$ denote the solution of our original problem (1) and w\u02c6 solve (2). Suppose that all our data $Z^{\\mathrm{train}},Z^{\\mathrm{val}},Z^{\\mathrm{test}}$ are drawn i.i.d. from some distribution $\\mathcal{D}_{X,Y}$ where $\\mathcal{D}_{X}$ is supported on $B_{R}^{d}$ (zero-centered ball with radius $R$ in $\\mathbb{R}^{d},$ , and $Y={\\boldsymbol{\\theta}}^{\\top}X+{\\boldsymbol{\\varepsilon}}$ where $\\varepsilon$ is independent zero-meaned noise with variance $\\sigma^{2}$ . For any training algorithm, when the number of training data is sufficiently large, with high probability, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\hat{\\theta}}\\ \\operatorname*{sup}_{\\mathcal{D}_{Y|X}}\\mathbb{E}_{X^{\\mathrm{test}}}\\left[\\mathcal{L}(\\hat{\\mathbf{w}})-\\mathcal{L}(\\mathbf{w}^{*})\\right]\\gtrsim\\frac{\\sigma^{2}d}{n_{\\mathrm{val}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "This result implies that the expected test error for any validation-based approach can in the worst-case scale as $d/n_{\\mathrm{val}}$ with high probability. This dependence on the dimension $d$ and the number of validation points $n_{\\mathrm{val}}$ highlights that this method may be suboptimal in high-dimensional settings or when the validation dataset is small. In fact, we would get the same error scaling if we threw away the training data and trained a model $\\hat{\\theta}$ on the $n_{\\mathrm{val}}$ validation datapoints alone. This explains the striking overfitting we observed earlier in Figure 2. Furthermore, obtaining a large amount of ground-truth labeled data may be challenging in many real-world applications. Instead, we propose a validation-free approach to data acquisition based on experimental design. ", "page_idx": 3}, {"type": "text", "text": "4 Our Methods and Implementations ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We propose an alternative approach based on a proxy objective. Our key assumption is that the conditional distribution $D_{y|x}\\colon y=f_{\\theta_{*}}(x)+\\epsilon$ is identical across $Z^{\\mathrm{train}}$ and $Z^{\\mathrm{test}}$ . This is a natural assumption in many domains \u2014 for instance, if an $\\Chi$ -ray exhibits indicators of a specific disease, it should receive the same diagnosis regardless of whether it appears in the training or test set. Without this assumption, our problem becomes intractable since the same $x_{j}$ could map to arbitrarily different labels across train and test sets. Under this framework, we can reformulate our problem using V-optimal experiment design [47]. ", "page_idx": 4}, {"type": "text", "text": "Step 1: Linearizing the problem. Our goal is to design a proxy loss function $\\hat{\\mathcal{L}}(\\mathbf{w})$ which approximates the true test loss ${\\mathcal{L}}(\\mathbf{w})$ . To do this, we have to reason about how different choices of training data $S\\subset Z^{\\mathrm{train}}$ could impact the prediction on a particular test datapoint in $X^{\\mathrm{test}}$ . This is a notoriously challenging problem for general deep learning models [9]. Instead, we use a linear approximation and model the complicated training dynamics with kernelized linear regression. We suppose we have a known feature-extractor $\\phi:\\bar{\\mathcal{X}}\\overset{\\cdot}{\\rightarrow}\\mathbb{R}^{d_{0}}$ and an unknown $\\theta^{*}\\in\\mathbb{R}^{d_{0}}$ such that the data is generated as ", "page_idx": 4}, {"type": "equation", "text": "$$\ny={\\theta^{*}}^{\\top}\\phi(x)+\\varepsilon\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\varepsilon$ is independent noise with mean zero and $d_{0}$ is the embedding dimensionality. The function $\\phi(\\cdot)$ can be the empirical Neural Tangent Kernel (eNTK) [27, 41, 58] of the model, or even the embeddings extracted from a deep neural network such as CLIP [49]. While this may be a bad approximation in general [61], a recent line of work has shown that such eNTK representation very closely approximates the fine-tuning dynamics of pre-trained models both theoretically [58, 42] as well as emperically [22, 63]. In fact, such linear approximations have also been used to speed up validation-based data attribution computations [46]. ", "page_idx": 4}, {"type": "text", "text": "Step 2: Experimental design proxy. Given the assumption on our data from Eqn. (3), we can use the V-optimal experiment design framework [51, 47, 26] to define a proxy objective. First, suppose that $S\\,{\\overset{.}{\\subseteq}}\\,(\\phi(X^{\\operatorname{train}}),Y^{\\operatorname{train}})$ is the subset selected by w and then we performed least-squares regression. The resulting estimate $\\hat{\\theta}(\\mathbf{w})$ can be computed in closed form as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\theta}(\\mathbf{w})=\\big(\\sum_{j=1}^{n}w_{j}\\phi(x_{j})\\phi(x_{j})^{\\top}\\big)^{\\dagger}(\\sum_{j=1}^{n}w_{j}\\phi(x_{j})y_{j})\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Henceforth, we will drop the $\\phi$ when obvious from context and simply use $x$ . We can further use Eqn. (3) to compute the expected error on an arbitrary test query $x_{0},y_{0}$ as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[(\\widehat{\\theta}(\\mathbf{w})^{\\top}x_{0}-y)^{2}|X^{\\mathrm{train}},x_{0}]\\stackrel{a_{1}}{=}\\mathbb{E}[\\big((\\widehat{\\theta}(\\mathbf{w})-\\theta^{*})^{\\top}x_{0}+\\varepsilon\\big)^{2}]}\\\\ &{\\stackrel{a_{2}}{=}x_{0}^{\\top}\\mathbb{E}[(\\widehat{\\theta}(\\mathbf{w})-\\theta^{*})(\\widehat{\\theta}(\\mathbf{w})-\\theta^{*})^{\\top}]x_{0}+\\mathbb{E}\\|\\varepsilon\\|^{2}}\\\\ &{\\stackrel{a_{3}}{=}x_{0}^{\\top}\\mathbb{E}[\\widehat{\\theta}(\\mathbf{w})\\widehat{\\theta}(\\mathbf{w})^{\\top}]x_{0}+\\mathbb{E}\\|\\varepsilon\\|^{2}}\\\\ &{\\stackrel{a_{4}}{=}x_{0}^{\\top}\\big(\\underbrace{\\sum_{j=1}^{n}w_{j}x_{j}x_{j}^{\\top}}_{=:\\mathcal{Z}(\\mathbf{w})}\\big)^{\\dag}x_{0}+\\mathbb{E}\\|\\varepsilon\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here $a_{3}$ uses the unbiasedness of the ordinary least squares (OLS) estimator and $a_{4}$ plugs in the closed form of $\\hat{\\theta}(\\mathbf{w})$ and simplifies. With this, we end up with a very clean expression for the expected test error on an arbitrary point $x_{0}$ , and the matrix $\\mathcal{T}(\\mathbf{w})$ is known as the Fisher information matrix. While regression suffices for our use case, the procedure can be extended to general linear models. Dropping the fixed $\\mathbb{E}\\|\\varepsilon\\|^{2}$ , we can use this to build our proxy function $\\hat{\\mathcal{L}}^{E D}(\\mathbf{w})$ and arrive at the following optimization problem ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\boxed{\\operatorname*{min}_{\\mathbf{w}\\in\\{0,1\\}^{n}}\\;\\left\\{\\hat{\\mathcal{L}}^{E D}(\\mathbf{w}):=1/m\\sum_{i=1}^{m}(x_{i}^{\\mathrm{test}})^{\\top}\\mathcal{Z}(\\mathbf{w})^{\\dagger}(x_{i}^{\\mathrm{test}})\\right\\}\\quad\\mathrm{s.t.~}\\sum_{j=1}^{n}w_{j}c_{j}\\leq B.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This optimization objective directly measures how useful each training point would be for predicting the specified test query. The matrix $\\mathcal{T}(\\mathbf{w})$ captures how much information each selected datapoint provides about the test point in the embedded feature space. ", "page_idx": 4}, {"type": "text", "text": "Note that our proxy function $\\hat{\\mathcal{L}}^{E D}(\\mathbf{w})$ can be computed using just $X^{\\mathrm{train}},X^{\\mathrm{test}}$ and does not even need access to training labels. Unfortunately, the objective in (4) is NP-hard to optimize [4]. We next see how to derive fast and provably good approximation algorithms for (4). ", "page_idx": 4}, {"type": "text", "text": "Step 3: Fast approximation. To make Eq. 4 amenable to gradient-based optimization, we drop the constraint that $w_{j}~\\in~\\{0,1\\}$ and allow it to be a continuous positive vector i.e., $\\textbf{w}\\geq$ 0 and $\\textstyle\\sum_{j=1}^{n}w_{j}c_{j}\\leq B$ . With this relaxation, the proxy objective $\\hat{\\mathcal{L}}^{E D}(\\mathbf{w})$ is continuous and convex in w [10]. We then run the \u201cherding\u201d variant of the Frank-Wolfe algorithm [59, 37, 53, 8, 65]. To do this, define $\\left(\\tilde{\\mathbf{w}}_{t}:=\\mathbf{w}_{t}/\\mathbf{c}\\right)$ ) for any $t$ . We start from a $\\tilde{\\mathbf{w}}_{\\mathbf{0}}=\\mathbf{e}_{0}$ and iteratively update as2 ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{w}}_{t+1}\\gets(1-\\alpha_{t})\\tilde{\\mathbf{w}}_{t}+\\alpha_{t}\\mathbf{e}_{j_{t}},\\quad\\mathrm{~where~}j_{t}=\\arg\\operatorname*{max}_{j\\in[n]}(-\\nabla_{w_{j}}\\hat{\\mathcal{L}}(\\mathbf{w}_{t})/c_{j})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that if we use the step-size $\\begin{array}{r}{\\alpha_{t}=\\frac{1}{t+1}}\\end{array}$ in (5), ${\\bf w}_{t}$ satisfies a special property at any iteration $t$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\tilde{\\mathbf{w}}_{t}\\in\\Delta^{n}\\mathrm{~and~further~}(t+1)\\tilde{\\mathbf{w}}_{t}\\in\\{0,1\\}^{n}\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Run the procedure until the last iteration $t=t_{o}$ for which we still have $\\|\\mathbf{w}_{t_{0}}\\|_{1}\\le B$ . We can adapt the theory from [8, 28] to analyze the above procedure and show the following. ", "page_idx": 5}, {"type": "text", "text": "Theorem 2 (Informal). Let us run Frank-Wolfe herding update (5) for $t_{0}$ steps such that it is last step which satisfies $\\|\\mathbf{w}_{t_{0}}\\|_{1}\\le B$ . We use $\\tilde{\\mathbf{w}}_{t_{0}}=((t_{0}+1)\\mathbf{w}_{t_{0}}/\\mathbf{c})$ as our selection vector and we would have selected $t_{0}$ datapoints. Then, under some assumptions, we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{\\mathcal{L}}^{E D}\\big((t+1)\\tilde{\\mathbf{w}}_{t_{0}}\\big)\\leq\\operatorname*{min}_{\\mathbf{w}\\in\\{0,1\\}^{n},\\sum_{j=1}^{n}w_{j}c_{j}\\leq B}\\hat{\\mathcal{L}}^{E D}(\\mathbf{w})+O\\bigg(\\frac{\\log t_{0}}{t_{0}}\\bigg)\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The above theorem shows that our continuous relaxation does not significantly affect the optimality odfa toaupro irnetssu lhta v\u2014e  ewqeu agle tc $O\\big(\\frac{\\log t_{0}}{t_{0}}\\big)$ n ,o patnidm salo  sooulru taipopnr toox ithmea toioring iqnuaall iNtyP -ihmaprrdo (v4e)s.  aIsf  walel $c$ $t_{0}=\\lfloor B/c\\rfloor$   \nincrease the budget. While better approximation guarantees are attainable [3], their procedure is significantly more involved and is not easily amenable to efficient federated implementations as ours is. ", "page_idx": 5}, {"type": "text", "text": "Step 4: Efficient federated implementation. Our practical implementation directly restricts $\\mathbf{w}\\in{\\Delta^{n}}$ instead of $\\tilde{\\bf w}$ in the theoretical implementation above i.e., we run ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbf{w}_{t+1}\\gets(1-\\alpha_{t})\\mathbf{w}_{t}+\\alpha_{t}\\mathbf{e}_{j_{t}},\\quad\\mathrm{~where~}j_{t}=\\arg\\operatorname*{max}_{j\\in[n]}(-\\nabla_{w_{j}}\\hat{\\mathcal{L}}(\\mathbf{w}_{t})/c_{j})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "This way w can be directly interpreted to be the sampling probability for different seller training datapoints. The bottleneck to efficiently implementing (6) is computing the gradient. At step $t$ , the negative gradient can be shown to be ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{g_{j}:=-\\nabla_{w_{j}}\\hat{\\mathcal{L}}({\\bf w}_{t})=1/{m}\\sum_{i=1}^{m}\\left((x_{i}^{\\mathrm{test}})^{\\top}\\mathcal{Z}({\\bf w}_{t})^{\\dag}(x_{j}^{\\mathrm{train}})\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Thus, if we have the inverse information matrix $\\mathbb{\\mathcal{Z}}(\\mathbf{w}_{t})^{\\dagger}$ pre-computed, $g_{j}$ as well as the update (6) ", "page_idx": 5}, {"type": "text", "text": "can be trivially computed by seller $j$ using only their data $x_{j_{\\mathrm{~s~}}}^{\\mathrm{train}}$ (and the test data). Next, we show how to efficiently maintain the inverse information matrix. Note that the update (6) has a special structure: all coordinates are shrunk, and then only a single coordinate of ${\\bf w}_{t}$ is increased. We can relate the resulting $\\mathcal{T}$ matrices with a rank-one update as: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{Z}(\\mathbf{w}_{t+1})=(1-\\alpha_{t})\\mathcal{Z}(\\mathbf{w}_{t})+\\alpha_{t}x_{j_{t}}x_{j_{t}}^{\\top}\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Define $P_{t}:=\\mathcal{T}(\\mathbf{w}_{t})^{\\dagger}$ . We can use the Sherman\u2013Morrison formula [50] to compute $P_{t+1}=\\mathcal{T}(\\mathbf{w}_{t+1})^{\\dagger}$ as ", "page_idx": 5}, {"type": "equation", "text": "$$\nP_{t+1}={\\frac{1}{1-\\alpha_{t}}}P_{t}-{\\frac{\\alpha_{t}P_{t}x_{j_{t}}x_{j_{t}}^{\\top}P_{t}}{1-\\alpha_{t}+\\alpha_{t}x_{j_{t}}^{\\top}P_{t}x_{j_{t}}}}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For each round $t$ , this update only involves the current matrix $P_{t}=\\mathcal{T}(\\mathbf{w}_{t})^{\\dagger}$ and the single datapoint $x_{j_{t}}$ selected for the round. Thus, the seller can also locally compute this update as well as the updated cost $\\hat{\\mathcal{L}}(\\mathbf{w})$ as in Eq. (4) for any $\\alpha_{t}$ : ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mathcal{L}}(\\mathbf{w})=\\frac{1}{m(1-\\alpha_{t})}\\sum_{i=1}^{m}\\left({x_{i}}^{\\top}\\,P_{t}\\,{x_{i}}\\right)-\\frac{\\alpha_{t}}{1+\\alpha_{t}x_{j_{t}}^{\\top}P_{t}{x_{j_{t}}}}\\sum_{i=1}^{m}\\left({x_{i}}^{\\top}P_{t}\\,{x_{j_{t}}}\\right)^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "2Here, ${\\bf{e}}_{j}$ is the standard basis vector along axis $j$ , and in $\\tilde{\\mathbf{w}}:=\\mathbf{w}/\\mathbf{c}$ , the division is performed element-wise. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 1 DAVED: Iterative Optimization Procedure ", "page_idx": 6}, {"type": "text", "text": "1: Input: buyer test datapoint $X^{\\mathrm{test}}\\,\\in\\,\\mathbb{R}^{m\\times d}$ , seller training data $X\\,\\in\\,\\mathbb{R}^{n\\times d}$ , seller weights   \n$\\mathbf{w}\\,\\in\\,\\Delta^{n}$ , iteration steps $T$ , regularization parameter $\\lambda_{\\mathrm{Reg}}\\,\\in\\,[0,1]$ , and seller datapoint costs   \n$\\mathbf{c}\\in\\mathbb{R}_{+}^{n}$   \n2: $\\mathbf{w}_{0}\\gets\\mathbb{1}/n$ # Initialize weight vector to uniform distribution   \n3: $P_{0}\\gets\\left(\\left(1-\\lambda_{\\mathrm{Reg}}\\right)X^{\\top}\\ \\mathrm{diag}(\\mathbf{w}_{0})\\ X+\\lambda_{\\mathrm{Reg}}\\cdot\\sigma_{X}I_{n\\times n}\\right)^{-1}$ # Initialize $P$ (Eq. 10)   \n4: for $t\\in\\{1,2,\\ldots,T\\}$ do   \n5: $g\\gets-\\nabla\\hat{\\mathcal{L}}(\\mathbf{w}_{t})$ # Compute negative gradients (Eq. 7)   \n6: $j_{t}\\leftarrow\\arg\\operatorname*{max}_{j}\\ \\left({g_{j}}{\\mathord{\\left/{\\vphantom{{g_{j}}{c_{j}}}}\\right.\\kern-\\nulldelimiterspace}{c_{j}}}\\right)$ # Select coordinate based on costs   \n7: $\\alpha_{t}\\gets\\tt L I N E\\_S E A R C H(\\hat{\\mathcal{L}})$ # Find optimal step size (Eq. 9)   \n8: $\\mathbf{w}_{t+1}\\leftarrow(1-\\alpha_{t})\\mathbf{w}_{t}+\\alpha_{t}\\mathbf{e}_{j_{t}}$ # Shrink weights and upweight the chosen coordinate (Eq. 6)   \n9: $P_{t+1}\\gets\\mathrm{SHERMAN\\_MORRISON}(P_{t},x_{j_{t}},\\alpha_{t})$ # Update inverse information matrix (Eq. 8)   \n10: end for   \n11: Output: Sample seller data according to $\\mathbf{w}_{T}\\in{\\Delta^{n}}$ without replacement until budget $B$ runs out. ", "page_idx": 6}, {"type": "text", "text": "Thus, a line search can be performed to determine the optimal step size $\\alpha_{t}\\in[0,1]$ to minimize the proxy loss as. This differs from (5) where we used a specific choice of $\\alpha_{t}$ . Frank-Wolfe is known to be more stable with the line search [53, 65]. The seller can communicate this $\\alpha_{t}$ and $x_{j_{t}}$ to the platform to compute the updated $P_{t+1}$ using only $O(d)$ communication. ", "page_idx": 6}, {"type": "text", "text": "An additional practical consideration is that by initializing $\\mathbf{w_{0}}=c_{1}\\mathbf{e}_{1}$ , we have an ill-conditioned inverse information matrix $P_{0}$ . We instead use an initialization of $\\mathbf{w_{0}}=\\mathbb{1}_{n}/n\\in\\Delta^{n}$ and further add a feature-wise regularization term. This makes the initial $P_{0}$ ", "page_idx": 6}, {"type": "equation", "text": "$$\nP_{0}=\\left((1-\\lambda_{\\mathrm{Reg}})\\,X^{\\top}\\;\\mathrm{diag}(\\mathbf{w}_{0})X\\;+\\lambda_{\\mathrm{Reg}}\\cdot\\mathrm{diag}({\\hat{\\sigma}})\\right)^{-1},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\begin{array}{r}{\\hat{\\sigma}_{i}=\\sqrt{\\frac{1}{n}\\sum_{j=1}^{n}(X_{j i}-\\bar{X}_{i})^{2}}}\\end{array}$ is the empirical standard deviation of feature $i$ . The complete details are summarized in Algorithm 1. ", "page_idx": 6}, {"type": "text", "text": "Single-step variant. We can also forgo the iterative process and instead linearly approximate the cost function (Eq 4) with a single step that selects the top $k$ datapoints under the budget $B$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\boxed{\\;\\mathbf{single\\_step}(x^{\\mathrm{test}},X,B)=\\mathbf{top\\_k}\\big(\\{\\sum_{i=1}^{m}\\left[(x_{i}^{\\mathrm{test}})^{\\top}P_{0}x_{j}\\right]^{2}\\}_{j=1}^{n}\\big).}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This simplified version is extremely fast while still maintaining relatively good performance. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We evaluate our proposed method for data acquisition (DAVED) against common data valuation methods on both synthetic data and four real-world medical: ", "page_idx": 6}, {"type": "text", "text": "1. Fitzpatrick17K [24], a skin lesion dataset, where the task is to predict Fitzpatrick skin tone on a 6-point scale from dermatology images.   \n2. RSNA Pediatric Bone Age dataset [25], where the task is to assess bone age (in months) from X-ray images of an infant\u2019s hand.   \n3. Medical Information Mart for Intensive Care (MIMIC-III) [31], where the task is to predict the length of hospital stay from 48 attributes such as demographics, insurance, and medical conditions.   \n4. DrugLib reviews [34], text reviews of drugs where the task is to predict ratings (1-10). ", "page_idx": 6}, {"type": "text", "text": "For validation-based methods, we use a validation set of 100 datapoints. We report mean test errors over 100 buyers. For more details on the experimental setup, see Appendix C. Our code is available at this repo: https://github.com/clu5/ data-acquisition-via-experimental-design. ", "page_idx": 6}, {"type": "text", "text": "Comparing Performance on Data with Homogeneous Costs. In Figure 3, we evaluate our method and several other data valuation methods on varying amounts of Gaussian data with homogeneous fixed costs. Compared to other methods, both multi- and single-step versions of DAVED have lower test errors across budgets on synthetic data. This performance gap is especially large when the buyer has a small budget (around 5-10 seller training datapoints). In Figure 4, we evaluate our method on real image and text data embedded through CLIP and GPT-2 feature representations. We observe that DAVED has better performance compared to most other baselines on all three datasets, highlighting that the proposed method is practical for embeddings of high-dimensional data. Table 1 summarizes our results on all datasets. For the Gaussian data and MIMIC datasets, we report the mean error of budgets from 1 to 10, while for the embedded datasets (RSNA, Fitzpatrick17K, DrugLib), we report the mean error of budgets from 1 to 100 in intervals of five. ", "page_idx": 6}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/7bb5b639a84b08de250415c125a5a3a37308bf1ca563ccf5ea243b70254847f3.jpg", "img_caption": ["Figure 3: Data Acquisition Performance across different Market Sizes on Synthetic Data. We compare test prediction error as seller training data is selected under varying budgets and amount of data for sale, with total available seller data of 1K (left), 5K (middle), and 100K (right) points. Our data selection method (DAVED) consistently achieves lower MSE with fewer purchased datapoints, i.e., better data acquisition efficiency, than other data valuation methods. Both multi-step and single-step variants of DAVED achieve lower test MSE with fewer training points compared to validation-based methods. The performance gap is especially pronounced with small budgets (5-10 points). Unless otherwise specified, all results are averaged over 100 random test points. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Comparing Performance on Data with Heterogeneous Costs. Next, we compare methods on seller data with non-homogeneous costs. We unifor\u221amly sample costs $c\\in\\{1,2,3,4,5\\}$ for each seller datapoint and consider two cost functions, $c_{j}={\\sqrt{c}}$ and $\\bar{c}_{j}={c}^{2}$ , which downweights gradient of that datapoint $x_{j}$ (see Equation 7). To simulate heterogeneous utility across datapoints, we introduce cost-dependent label noise, $\\epsilon\\sim\\mathcal{N}(\\bar{y},\\sigma^{2})$ , to each datapoint $\\tilde{y_{i}}:=y_{i}+\\beta\\tilde{\\epsilon}/c_{j}$ , where $\\bar{y}$ is the mean target value and $\\beta$ is the overall noise level, which we fix at $30\\%$ throughout our experiments. For these experiments, we did not evaluate Data Shapley [23], LOO [13], and Influence [21] that had very long runtimes. In Table 2, we report additional mean test error across budgets 1\u201330 for both cost functions. We find that our DAVID method is more budget-efficient in choosing cost-effective noisy datapoints than other methods across datasets. We provide additional plots for heterogeneous costs in Appendix D.1. ", "page_idx": 7}, {"type": "text", "text": "Comparing Runtime. In Figure 5, we compare the optimization runtime of our data selection method on 1,000 datapoints while increasing the dimensionality of the data as well as when the dimensionality is fixed to 30, and the number of seller datapoints is increased to 100,000. Data Shapley [23] and LOO [13] took too long to run for large amounts of datapoints or high dimensional data and are not reported. In both experiments, our multi-step compares favorably to efficiency-optimized techniques such as KNN Shapley [29] while our single-step method had the fastest runtime. This demonstrates that our method can scale to marketplaces with millions of datapoints. ", "page_idx": 7}, {"type": "text", "text": "Regularization Strength. In Appendix D.2, we vary the amount of regularization applied on the MIMIC, DrugLib, and RSNA datasets. We find that applying a moderate amount of regularization between 0.2 and 0.6 can lead to improved performance. Even when the information matrix is set to identity, i.e., $\\lambda=1$ , performance on the DrugLib datasets is still reasonable. Note that for all other experiments, we do not apply any regularization. ", "page_idx": 7}, {"type": "text", "text": "Amount of Buyer Data. In Appendix D.3, we vary how many buyer test datapoints are simultaneously optimized over on Gaussian-distributed, MIMIC, and RSNA datasets. While all buyer and seller data is sampled from the same distribution, the number of buyer datapoints still affects the optimization procedure. In general, we find that increasing the number of datapoints in the \u201ctest batch\u201d increases ", "page_idx": 7}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/018fc765ff8dba4d904816344fd42ea22b6f663a5bab444416cdd42dc7d0b0ee.jpg", "img_caption": ["Figure 4: Data Acquisition Performance on Real Medical Datasets. DAVED demonstrates strong performance on real-world medical imaging and drug review datasets. (Left to right) Results on Fitzpatrick17K (skin lesions), RSNA Bone Age (X-rays), and DrugLib (drug reviews) \u2014 where highdimensional raw data is embedded via CLIP (images) or GPT-2 (text). Each method selects training points under budget constraints to train a regression model on the embedded data. DAVED achieves lower test prediction error using fewer training points compared to validation-based approaches, demonstrating effectiveness on high-dimensional data. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Table 1: Test Error of Data Valuation Methods. We compared the test mean squared error on the buyer test point on a synthetic Gaussian-distributed data and four medical datasets: MIMIC, RSNA, Fitzpatrick17K, and DrugLib. The subheading denotes the number of seller training data available for that experiment, and \u201cN/A\u201d denotes that the method exceeded runtime constraints for the experiment. We optimize a separate random sample of training and validation data for each buyer and average over 100 buyers. Bolded values indicate the best-performing method and underlined values denote the second-best-performing method. ", "page_idx": 8}, {"type": "table", "img_path": "VXJVNdmXO4/tmp/105edc7c49bb8b73f60c321bd204ea4d14577d210a61df6b49d638c74bdd8dd4.jpg", "table_caption": [], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "VXJVNdmXO4/tmp/689810c0dac933e083b2fe26281b06a728c347c96e8982e2ef78d68b80952f1e.jpg", "table_caption": ["Table 2: Test Er\u221aror with Heterogeneous Costs. Comparing data selection methods for two different cost functions, $\\sqrt{c}$ and $c^{2}$ . For each budget constraint, we select seller datapoints until the budget is exceeded and calculate test prediction error on the buyer data. We average over 100 buyers and report the mean test error across budgets from 1 to 30. "], "table_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/c566717f4ee99a2a00acd69f61e382c3b458b07f436378b18044dd07a4ba4fe1.jpg", "img_caption": ["Figure 5: Computational efficiency comparison. DAVED has significantly lower computational overhead compared to model-based data valuation methods. (Left) Runtime scaling with data dimensionality (fixed 1,000 datapoints). (Right) Runtime scaling with the amount of seller data (fixed 30 dimensions). Our single-step variant is faster than even optimized methods like KNN Shapley, while the multi-step variant remains efficient while achieving better performance. Our optimization procedure only requires $O(d)$ communication per round, which makes it particularly suited for decentralized data market settings. For Data Shapley and Leave-One-Out, some experiments were omitted due to prohibitively long runtimes. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "test errors. Therefore, we recommend keeping the number of test datapoints in the buyer\u2019s \u201cquery\u201d between 1\u20138 for each data acquisition. ", "page_idx": 9}, {"type": "text", "text": "Number of Steps. In Appendix D.4, we vary the number of optimization steps in our method on the Gaussian-distributed and RSNA datasets. We find that more iterations generally improve prediction performance. Intuitively, one expects that selecting $T$ points requires at least $T$ steps of iterative optimization. We recommend setting the number of steps to be 2\u20135 times the desired budget for homogeneous costs. ", "page_idx": 9}, {"type": "text", "text": "Convex versus Iterative Optimization In Appendix D.6, we compare the iterative optimization procedure against a convex optimization solver [18]. We find that our iterative approach results in several orders of magnitude speedup while maintaining similar levels of test error. ", "page_idx": 9}, {"type": "text", "text": "Finetuning versus Linear Probe. In Figure 14, we evaluate fine-tuning versus linear probing for datapoints selected using DAVID and random selection. We find that using DAVID for fine-tuning performs similarly to linear probing results on DrugLib with BERT [17]. ", "page_idx": 9}, {"type": "text", "text": "6 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "While other validation-free methods exist [60, 5], our method uniquely combines test-adaptivity, theoretical grounding, and superior empirical performance. Moreover, a major advantage of our method is that it is amenable to federated optimization requiring $O(d)$ communication per round, making it well-suited for decentralized data marketplaces, unlike other methods that require seller data to be centralized in order to repeatedly train models to estimate data value. Additionally, our method does not require labeled data, whereas other data valuation methods assume that all datapoints come with corresponding ground-truth labels. As discussed in Section 2 and Section 3, the existing paradigm of valuing data with a validation set is suboptimal. Incidentally, the second-best performing method, Data OOB [39], is the only other method that does not use a validation set. ", "page_idx": 9}, {"type": "text", "text": "Limitations. However, our algorithm comes with some limitations that form exciting directions for future work. Our approach currently communicates every step. Instead, integrating local steps like in FedAvg [43] or Scaffold [35] would decrease communication costs. Further, integrating differential privacy techniques would provide formal privacy guarantees to the buyers and sellers [19]. While DAVED shows strong performance across datasets, its effectiveness depends on having a good feature extractor that captures relevant aspects of the data. We recommend using pre-trained foundation models (e.g., CLIP, GPT-2) as they can extract general-purpose features. Future work could explore adapting the feature extraction to specific domains or handling cases where key features are missing ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "C.L. is funded by the National Science Foundation Graduate Research Fellowship Program. This material is based upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. 2141064. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. S.P.K. and M.J. were funded by the European Union (ERC-2022-SYG-OCEAN-101071601). P.V. was partially supported by the ADIA Lab Fellowship. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Anish Agarwal, Munther Dahleh, and Tuhin Sarkar. A marketplace for data: An algorithmic solution. In Proceedings of the 2019 ACM Conference on Economics and Computation, pages 701\u2013726, 2019.   \n[2] S Damla Ahipa\u00b8sao\u02d8glu and Michael J Todd. A modified frank\u2013wolfe algorithm for computing minimum-area enclosing ellipsoidal cylinders: Theory and algorithms. Computational Geometry, 46(5):494\u2013519, 2013.   \n[3] Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-parameterization. In International conference on machine learning, pages 242\u2013252. PMLR, 2019. [4] Zeyuan Allen-Zhu, Yuanzhi Li, Aarti Singh, and Yining Wang. Near-optimal discrete optimization for experimental design: A regret minimization approach. Mathematical Programming, 186:439\u2013478, 2021.   \n[5] Mohammad Mohammadi Amiri, Frederic Berdoz, and Ramesh Raskar. Fundamentals of taskagnostic data valuation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 9226\u20139234, 2023. [6] Muhammad Jehangir Amjad, Christophe Diot, Dimitris Konomis, Branislav Kveton, Augustin Soule, and Xiaolong Yang. Optimal probing with statistical guarantees for network monitoring at scale. arXiv preprint arXiv:2109.07743, 2021.   \n[7] Kenneth Joseph Arrow. Economic welfare and the allocation of resources for invention. Springer, 1972. [8] Francis Bach, Simon Lacoste-Julien, and Guillaume Obozinski. On the equivalence between herding and conditional gradient algorithms. In International Conference on Machine Learning, 2012. [9] Samyadeep Basu, Philip Pope, and Soheil Feizi. Influence functions in deep learning are fragile. arXiv preprint arXiv:2006.14651, 2020.   \n[10] Stephen P Boyd and Lieven Vandenberghe. Convex optimization. Cambridge university press, 2004.   \n[11] Raul Castro Fernandez. Data-sharing markets: Model, protocol, and algorithms to incentivize the formation of data-sharing consortia. Proceedings of the ACM on Management of Data, 1(2): 1\u201325, 2023.   \n[12] Lingjiao Chen, Bilge Acun, Newsha Ardalani, Yifan Sun, Feiyang Kang, Hanrui Lyu, Yongchan Kwon, Ruoxi Jia, Carole-Jean Wu, Matei Zaharia, et al. Data acquisition: A new frontier in data-centric AI. arXiv preprint arXiv:2311.13712, 2023.   \n[13] R Dennis Cook. Detection of influential observation in linear regression. Technometrics, 19(1): 15\u201318, 1977.   \n[14] Thomas M Cover. Elements of Information Theory. John Wiley & Sons, 1999.   \n[15] S Damla Ahipasaoglu, Peng Sun, and Michael J Todd. Linear convergence of a modified frank\u2013wolfe algorithm for computing minimum-volume enclosing ellipsoids. Optimisation Methods and Software, 23(1):5\u201319, 2008.   \n[16] Deven R Desai and Mark Riedl. Between copyright and computer science: The law and ethics of generative ai. arXiv preprint arXiv:2403.14653, 2024.   \n[17] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.   \n[18] Steven Diamond and Stephen Boyd. CVXPY: A Python-embedded modeling language for convex optimization. The Journal of Machine Learning Research, 17(1):2909\u20132913, 2016.   \n[19] Cynthia Dwork. Differential privacy. In International colloquium on automata, languages, and programming, pages 1\u201312. Springer, 2006.   \n[20] Valerii Vadimovich Fedorov. Theory of optimal experiments. Elsevier, 2013.   \n[21] Vitaly Feldman and Chiyuan Zhang. What neural networks memorize and why: Discovering the long tail via influence estimation. Advances in Neural Information Processing Systems, 33: 2881\u20132891, 2020.   \n[22] Stanislav Fort, Gintare Karolina Dziugaite, Mansheej Paul, Sepideh Kharaghani, Daniel M Roy, and Surya Ganguli. Deep learning versus kernel learning: an empirical study of loss landscape geometry and the time evolution of the neural tangent kernel. Advances in Neural Information Processing Systems, 33:5850\u20135861, 2020.   \n[23] Amirata Ghorbani and James Zou. Data Shapley: Equitable valuation of data for machine learning. In International Conference on Machine Learning, pages 2242\u20132251. PMLR, 2019.   \n[24] Matthew Groh, Caleb Harris, Luis Soenksen, Felix Lau, Rachel Han, Aerin Kim, Arash Koochek, and Omar Badri. Evaluating deep neural networks trained on clinical images in dermatology with the Fitzpatrick 17k dataset. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1820\u20131828, 2021.   \n[25] Safwan S Halabi, Luciano M Prevedello, Jayashree Kalpathy-Cramer, Artem B Mamonov, Alexander Bilbily, Mark Cicero, Ian Pan, Lucas Ara\u00fajo Pereira, Rafael Teixeira Sousa, Nitamar Abdala, et al. The rsna pediatric bone age machine learning challenge. Radiology, 290(2): 498\u2013503, 2019.   \n[26] Baihe Huang, Sai Praneeth Karimireddy, and Michael I Jordan. Evaluating and incentivizing diverse data contributions in collaborative learning. arXiv preprint arXiv:2306.05592, 2023.   \n[27] Arthur Jacot, Franck Gabriel, and Cl\u00e9ment Hongler. Neural tangent kernel: Convergence and generalization in neural networks. Advances in neural information processing systems, 31, 2018.   \n[28] Martin Jaggi. Revisiting frank-wolfe: Projection-free sparse convex optimization. In International conference on machine learning, pages 427\u2013435. PMLR, 2013.   \n[29] Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nezihe Merve Gurel, Bo Li, Ce Zhang, Costas J Spanos, and Dawn Song. Efficient task-specific data valuation for nearest neighbor algorithms. arXiv preprint arXiv:1908.08619, 2019.   \n[30] Kevin Fu Jiang, Weixin Liang, James Zou, and Yongchan Kwon. Opendataval: a unified benchmark for data valuation. arXiv preprint arXiv:2306.10577, 2023.   \n[31] Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. MIMIC-III, a freely accessible critical care database. Scientific data, 3(1):1\u20139, 2016.   \n[32] Hoang Anh Just, Feiyang Kang, Jiachen T Wang, Yi Zeng, Myeongseob Ko, Ming Jin, and Ruoxi Jia. Lava: Data valuation without pre-specified learning algorithms. arXiv preprint arXiv:2305.00054, 2023.   \n[33] Zeynep \u00dclk\u00fc Kahveci. Attribution problem of generative ai: a view from us copyright law. Journal of Intellectual Property Law and Practice, 18(11):796\u2013807, 2023.   \n[34] Surya Kallumadi and Felix Grer. Drug Review Dataset (Druglib.com). UCI Machine Learning Repository, 2018. DOI: https://doi.org/10.24432/C55G6J.   \n[35] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich, and Ananda Theertha Suresh. Scaffold: Stochastic controlled averaging for federated learning. In International conference on machine learning, pages 5132\u20135143. PMLR, 2020.   \n[36] Javen Kennedy, Pranav Subramaniam, Sainyam Galhotra, and Raul Castro Fernandez. Revisiting online data markets in 2022: A seller and buyer perspective. ACM SIGMOD Record, 51(3): 30\u201337, 2022.   \n[37] Leonid G Khachiyan. Rounding of polytopes in the real number model of computation. Mathematics of Operations Research, 21(2):307\u2013320, 1996.   \n[38] Yongchan Kwon and James Zou. Beta Shapley: a unified and noise-reduced data valuation framework for machine learning. arXiv preprint arXiv:2110.14049, 2021.   \n[39] Yongchan Kwon and James Zou. Data-oob: Out-of-bag estimate as a simple and efficient data value. arXiv preprint arXiv:2304.07718, 2023.   \n[40] Chao Li, Daniel Yang Li, Gerome Miklau, and Dan Suciu. A theory of pricing private data. ACM Transactions on Database Systems (TODS), 39(4):1\u201328, 2014.   \n[41] Philip M Long. Properties of the after kernel. arXiv preprint arXiv:2105.10585, 2021.   \n[42] Sadhika Malladi, Alexander Wettig, Dingli Yu, Danqi Chen, and Sanjeev Arora. A kernel-based view of language model fine-tuning. In International Conference on Machine Learning, pages 23610\u201323641. PMLR, 2023.   \n[43] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. Communication-efficient learning of deep networks from decentralized data. In Artificial Intelligence and Statistics, pages 1273\u20131282. PMLR, 2017.   \n[44] Aileen Nielsen. Whose data, whose value? simple exercises in data and modeling evaluation with implications for technology law and policy. New York University Law Review, 99:63, 2023.   \n[45] Raymond EAC Paley and Antoni Zygmund. A note on analytic functions in the unit circle. In Mathematical Proceedings of the Cambridge Philosophical Society, volume 28, pages 266\u2013272. Cambridge University Press, 1932.   \n[46] Sung Min Park, Kristian Georgiev, Andrew Ilyas, Guillaume Leclerc, and Aleksander Madry. Trak: Attributing model behavior at scale. arXiv preprint arXiv:2303.14186, 2023.   \n[47] Friedrich Pukelsheim. Optimal design of experiments. SIAM, 2006.   \n[48] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.   \n[49] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748\u20138763. PMLR, 2021.   \n[50] Jack Sherman and Winifred J Morrison. Adjustment of an inverse matrix corresponding to a change in one element of a given matrix. The Annals of Mathematical Statistics, 21(1):124\u2013127, 1950.   \n[51] SD Silvey. Optimal design measures with singular information matrices. Biometrika, 65(3): 553\u2013559, 1978.   \n[52] Rachael Hwee Ling Sim, Xinyi Xu, and Bryan Kian Hsiang Low. Data valuation in machine learning:\u201cingredients\u201d, strategies, and open challenges. In Proc. IJCAI, pages 5607\u20135614, 2022.   \n[53] Peng Sun and Robert M Freund. Computation of minimum-volume covering ellipsoids. Operations Research, 52(5):690\u2013706, 2004.   \n[54] Matias Travizano, Carlos Sarraute, Mateusz Dolata, Aaron M French, and Horst Treiblmaier. Wibson: A case study of a decentralized, privacy-preserving data marketplace. Blockchain and distributed ledger technology use cases: Applications and lessons learned, pages 149\u2013170, 2020.   \n[55] Joel A Tropp. User-friendly tail bounds for sums of random matrices. Foundations of computational mathematics, 12:389\u2013434, 2012.   \n[56] Martin J Wainwright. High-Dimensional Statistics: A Non-Asymptotic Viewpoint, volume 48. Cambridge university press, 2019.   \n[57] Jiachen T Wang and Ruoxi Jia. Data banzhaf: A robust data valuation framework for machine learning. In International Conference on Artificial Intelligence and Statistics, pages 6388\u20136421. PMLR, 2023.   \n[58] Jason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.   \n[59] Henry P Wynn. The sequential generation of $d$ -optimum experimental designs. The Annals of Mathematical Statistics, 41(5):1655\u20131664, 1970.   \n[60] Xinyi Xu, Zhaoxuan Wu, Chuan Sheng Foo, and Bryan Kian Hsiang Low. Validation free and replication robust volume-based data valuation. Advances in Neural Information Processing Systems, 34:10837\u201310848, 2021.   \n[61] Greg Yang and Edward J Hu. Feature learning in infinite-width neural networks. arXiv preprint arXiv:2011.14522, 2020.   \n[62] Jinsung Yoon, Sercan Arik, and Tomas Pfister. Data valuation using reinforcement learning. In International Conference on Machine Learning, pages 10842\u201310851. PMLR, 2020.   \n[63] Yaodong Yu, Alexander Wei, Sai Praneeth Karimireddy, Yi Ma, and Michael Jordan. Tct: Convexifying federated learning using bootstrapped neural tangent kernels. Advances in Neural Information Processing Systems, 35:30882\u201330897, 2022.   \n[64] Boxin Zhao, Boxiang Lyu, Raul Castro Fernandez, and Mladen Kolar. Addressing budget allocation and revenue allocation in data market environments using an adaptive sampling algorithm. arXiv preprint arXiv:2306.02543, 2023.   \n[65] Renbo Zhao and Robert M Freund. Analysis of the frank\u2013wolfe method for convex composite optimization involving a logarithmically-homogeneous barrier. Mathematical programming, 199(1):123\u2013163, 2023. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Proof of Theorem 1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Theorem A.1. Let w\u2217denote the solution of Problem (1) and let w\u02c6 denote the solution of Problem (2). Let the data Zval, Ztest are drawn i.i.d. from the distribution DX,Y where DX is supported on BdR (zero-centered ball with radius $R$ in $\\mathbb{R}^{d}$ ), and $\\boldsymbol{Y}=\\boldsymbol{\\theta}^{\\intercal}\\boldsymbol{X}+\\boldsymbol{\\eta}$ where $\\eta$ is independent zero-meaned noise with variance $\\sigma^{2}$ . Suppose $\\mathcal{D}_{X}$ and the training data $X^{\\mathrm{train}}$ is supported on $B_{R}^{d}$ (zero-centered ball with radius $R$ in $\\mathbb{R}^{d}$ ) and $l$ is square loss, then there exist numerical constants, $c_{1},c_{2},c_{3}$ , such that: ", "page_idx": 14}, {"type": "text", "text": "1. With probability at least $1-\\exp\\left(-c_{1}n_{\\mathrm{val}}/R^{2}\\right)$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\hat{\\theta}}\\ \\operatorname*{sup}_{\\mathcal{D}_{Y|X},X^{\\mathrm{train}}}\\mathbb{E}_{X^{\\mathrm{test}}}\\left[\\mathcal{L}(\\hat{\\mathbf{w}})-\\mathcal{L}(\\mathbf{w}^{*})\\right]\\geq\\frac{c_{2}\\sigma^{2}d}{n_{\\mathrm{val}}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "2. If there exists $\\kappa>0$ such that $\\lambda(\\mathbb{E}_{x\\sim\\mathcal{D}_{X}}[x^{\\otimes4}])\\le\\kappa\\cdot\\lambda\\left(\\mathbb{E}_{x\\sim\\mathcal{D}_{X}}[x^{\\otimes2}]^{\\otimes2}\\right)$ (here $\\lambda$ denotes the largest eigenvalue and $\\otimes$ denotes the outer product), then for any training algorithm used by the platform, with probability at least $\\begin{array}{r}{0.\\dot{9}9-\\exp\\left(-c_{1}\\dot{n}_{\\mathrm{val}}/\\dot{R}^{2}\\right)-\\frac{c_{3}\\ddot{\\kappa}}{\\kappa+m}}\\end{array}$ , we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\mathcal{D}_{Y|X},X^{\\operatorname{train}}}\\mathcal{L}(\\hat{\\mathbf{w}})-\\mathcal{L}(\\mathbf{w}^{*})\\geq\\frac{c_{2}\\sigma^{2}d}{n_{\\mathrm{val}}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. Let $f_{\\theta}(x)=\\theta^{\\top}x$ and $\\mathcal{E}=N(0,\\sigma^{2})$ . Define the parameter space resulting from the training algorithm: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Theta=\\left\\{\\hat{\\theta}(\\mathbf{w}):\\mathbf{w}\\in\\Delta([m])\\right\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "When $n$ is sufficiently large, Lemma A.2 implies that there exists $\\{\\theta_{1},\\theta_{2},\\ldots,\\theta_{K}\\}\\subset\\Theta$ such that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\theta_{i}^{\\top}X^{\\mathrm{val}}\\right\\|_{2}\\lesssim\\delta\\sqrt{n_{\\mathrm{val}}},\\ \\forall i\\in[K]\\ \\ \\ \\ }\\\\ {\\left\\|(\\theta_{i}-\\theta_{j})^{\\top}X^{\\mathrm{val}}\\right\\|_{2}\\asymp\\delta\\sqrt{n_{\\mathrm{val}}},\\ \\forall i<j\\in[K].}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Let $\\mathbb{P}_{\\theta_{i}}$ denote the conditional distribution $\\mathcal{D}_{y\\mid x}$ of the target when the underlying model parameter is $\\theta_{i}$ , it then follows that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathrm{KL}(\\mathbb{P}_{\\theta_{i}}\\|\\mathbb{P}_{\\theta_{j}})\\lesssim\\frac{n\\delta^{2}}{\\sigma^{2}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Applying Lemma A.3, we obtain that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\hat{\\theta}}\\operatorname*{sup}_{\\mathcal{D}_{Y|X},X^{\\mathrm{train}}}\\mathbb{E}\\left[\\frac{1}{n_{\\mathrm{val}}}\\left\\lVert\\left(\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*}\\right)^{\\top}X^{\\mathrm{val}}\\right\\rVert_{2}^{2}\\right]\\gtrsim\\frac{c_{2}\\sigma^{2}d}{n_{\\mathrm{val}}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Now define $\\Sigma\\ =\\ \\mathbb{E}_{x\\sim\\mathcal{D}_{X}}[x x^{\\top}]$ , by Lemma A.4, we have that with probability at least $1\\,-$ $\\exp(-\\Omega(n_{\\mathrm{val}}/R^{2}))$ ), ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\frac{1}{2}}\\Sigma\\preceq X^{\\mathrm{val}}(X^{\\mathrm{val}})^{\\top}\\preceq2\\Sigma.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Notice that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}_{X^{\\mathrm{test}}}\\left[\\mathcal{L}(\\hat{\\mathbf{w}})-\\mathcal{L}(\\mathbf{w}^{*})\\right]=\\left\\lVert(\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*})^{\\top}\\right\\rVert_{\\Sigma}^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, under the event of Eq. (12), Eq. (13) implies that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\hat{\\theta}}{\\operatorname*{inf}}\\ \\underset{\\mathcal{D}_{Y|X},X^{\\mathrm{train}}}{\\operatorname*{sup}}\\mathbb{E}_{X^{\\mathrm{test}}}\\left[\\mathcal{L}(\\hat{\\mathbf{w}})-\\mathcal{L}(\\mathbf{w}^{*})\\right]\\geq\\underset{\\hat{\\theta}}{\\operatorname*{inf}}\\ \\underset{\\mathcal{D}_{Y|X},X^{\\mathrm{train}}}{\\operatorname*{sup}}\\frac{1}{2}\\mathbb{E}\\left[\\frac{1}{n_{\\mathrm{val}}}\\left\\|(\\hat{\\theta}(\\hat{w})-\\theta^{*})^{\\top}X^{\\mathrm{val}}\\right\\|_{2}^{2}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\gtrsim\\frac{c_{2}\\sigma^{2}d}{n_{\\mathrm{val}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "This establishes the first inequality. ", "page_idx": 14}, {"type": "text", "text": "For the second inequality, we have that under the condition $\\begin{array}{r l r}{\\lambda(\\mathbb{E}_{x\\sim\\mathcal{D}_{X}}[x^{\\otimes4}])}&{{}\\le}&{\\kappa}\\end{array}$ \u00b7 $\\lambda\\left(\\mathbb{E}_{x\\sim\\mathcal{D}_{X}}[x^{\\otimes2}]^{\\otimes2}\\right)$ , the following holds ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname{Var}_{x\\sim D_{X}}\\left(\\left\\langle\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*},x\\right\\rangle^{2}\\right)=\\mathbb{E}\\left[\\left\\langle\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*},x\\right\\rangle^{4}\\right]-\\mathbb{E}\\left[\\left\\langle\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*},x\\right\\rangle^{2}\\right]^{2}}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\mathbb{E}\\left[\\left\\langle(\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*})^{\\otimes4},x^{\\otimes4}\\right\\rangle\\right]-\\mathbb{E}\\left[\\left\\langle\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*})^{\\otimes2},x^{\\otimes2}\\right\\rangle^{2}\\right]}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ =\\left\\langle(\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*})^{\\otimes4},\\mathbb{E}\\left[x^{\\otimes4}\\right]-\\mathbb{E}\\left[x^{\\otimes2}\\right]^{\\otimes2}\\right\\rangle}\\\\ &{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\leq(\\kappa-1)\\cdot\\mathbb{E}\\left[\\left\\langle\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*},x\\right\\rangle^{2}\\right]^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By Lemma A.5, for any $\\theta$ and $\\theta^{*}$ , we have that with probability at least $\\textstyle{0.99-O\\left({\\frac{\\kappa}{\\kappa+m}}\\right)}$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{L}(\\hat{\\mathbf{w}})-\\mathcal{L}(\\mathbf{w}^{*})=\\displaystyle\\frac{1}{m}\\left\\|(\\theta-\\theta^{*})^{\\top}X^{\\mathrm{test}}\\right\\|_{2}^{2}}&{}\\\\ {\\displaystyle=\\frac{1}{m}\\sum_{i=1}^{m}\\left\\langle\\theta-\\theta^{*},x_{i}^{\\mathrm{test}}\\right\\rangle^{2}}&{}\\\\ {\\displaystyle}&{\\geq0.0001\\cdot\\left\\|(\\hat{\\theta}(\\hat{\\mathbf{w}})-\\theta^{*})^{\\top}\\right\\|_{\\Sigma}^{2}}\\\\ &{\\displaystyle\\gtrsim\\frac{c_{2}\\sigma^{2}d}{n_{\\mathrm{val}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Combining this and the first inequality by union bound, we establish the second inequality. ", "page_idx": 15}, {"type": "text", "text": "A.1 Supporting Lemma ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Lemma A.2 (Metric entropy, Wainwright [56]). Let $\\|\\cdot\\|$ denote the Euclidean norm on $\\mathbb{R}^{d}$ and let $\\mathbb{B}$ be the unit balls (i.e., $\\mathbb{B}=\\{\\theta\\in\\mathbb{R}^{d}|\\lVert\\theta\\rVert\\leq1\\},$ ). Then the $\\delta$ -covering number of $\\mathbb{B}$ in the $\\|\\cdot\\|$ -norm obeys the bounds ", "page_idx": 15}, {"type": "equation", "text": "$$\nd\\log\\left(\\frac{1}{\\delta}\\right)\\leq\\log N(\\delta;\\mathbb{B},\\|\\cdot\\|)\\leq d\\log\\left(1+\\frac{2}{\\delta}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma A.3 (Fano\u2019s inequality, Cover [14]). When $\\theta$ is uniformly distributed over the index set $[M]$ , then for any estimator $\\hat{\\theta}$ such that $\\theta\\to Z\\to{\\hat{\\theta}}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}[\\hat{\\theta}(Z)\\neq\\theta]\\ge1-\\frac{I(Z;\\theta)+\\log2}{\\log M}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma A.4 (Matrix-Chernoff bound, Tropp [55]). Consider an independent sequence $\\{X_{i}\\}_{i=1}^{k}$ of random, self-adjoint matrices in $M_{n}$ satisfying $X_{i}\\geq0$ and $\\lambda_{m a x}(X_{i})\\leq R$ almost surely, for each $i\\in\\{1,\\ldots,k\\}$ . Define ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mu_{m i n}:=\\lambda_{m i n}\\left(\\sum_{i=1}^{k}\\mathbb{E}X_{i}\\right),}\\\\ {\\displaystyle\\mu_{m a x}:=\\lambda_{m a x}\\left(\\sum_{i=1}^{k}\\mathbb{E}X_{i}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\mathbb{P}\\left\\{\\lambda_{m a x}\\left(\\displaystyle\\sum_{i=1}^{k}X_{i}\\right)\\geq(1+\\delta)\\mu_{m a x}\\right\\}<n\\left(\\displaystyle\\frac{\\mathrm{e}^{\\delta}}{(1+\\delta)^{1+\\delta}}\\right)^{\\frac{\\mu_{m a x}}{R}}}&{f o r\\,\\delta\\geq0;}\\\\ {\\mathbb{P}\\left\\{\\lambda_{m i n}\\left(\\displaystyle\\sum_{i=1}^{k}X_{i}\\right)\\leq(1-\\delta)\\mu_{m i n}\\right\\}<n\\left(\\displaystyle\\frac{\\mathrm{e}^{-\\delta}}{(1-\\delta)^{1-\\delta}}\\right)^{\\frac{\\mu_{m i n}}{R}}}&{f o r\\,\\delta\\in[0,1].}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Lemma A.5 (Paley\u2013Zygmund inequality, Paley and Zygmund [45]). If $Z$ is a random variable with finite variance and $Z\\ge0$ almost surely, then ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}(Z>\\theta\\,\\mathbb{E}[Z])\\ge(1-\\theta)^{2}\\frac{\\mathbb{E}[Z]^{2}}{\\mathbb{E}[Z^{2}]},\\,\\forall\\theta\\in(0,1).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "B Convergence Rate of Frank-Wolfe (Proof of Theorem 2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Setup. We mostly follow the proof technique in Bach et al. [8] and Jaggi [28]. Recall the optimization problem for the optimal design loss Eq. (4): ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{w}\\in\\mathcal{D}}\\mathcal{L}(\\mathbf{w}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here, $\\mathcal{D}$ is the scaled simplex defined by the constraints $\\textbf{w}\\in\\mathbb{R}_{\\ge0}^{n}$ and j=1 cjwj \u2264B. The Frank-Wolfe update on this function is then: For $t=1,2,\\ldots$ , repeatedly perform the following steps ", "page_idx": 16}, {"type": "text", "text": "$\\begin{array}{r}{\\mathbf{\\nabla}\\bullet\\,\\mathrm{Compute}\\;\\mathbf{s}_{t}=\\arg\\operatorname*{max}_{\\mathbf{u}\\in\\mathcal{D}}\\langle\\nabla\\mathcal{L}(\\mathbf{w}_{t}),\\mathbf{w}_{t}-\\mathbf{u}\\rangle.}\\end{array}$ update $\\mathbf{w}_{t+1}=(1-\\alpha_{t})\\mathbf{w}_{t}+\\alpha_{t}\\mathbf{s}_{t}$ ", "page_idx": 16}, {"type": "text", "text": "Note that this update procedure is identical to the updates in Eq. 5. We can then define the duality gap as ", "page_idx": 16}, {"type": "equation", "text": "$$\ng(\\mathbf{w})=\\operatorname*{sup}_{\\mathbf{s}\\in\\mathcal{D}}\\langle\\mathbf{w}-\\mathbf{s},\\nabla\\mathcal{L}(\\mathbf{w})\\rangle.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We also define the curvature constant ", "page_idx": 16}, {"type": "equation", "text": "$$\nC_{l}=\\operatorname*{sup}_{\\mathbf{s},\\mathbf{w}\\in\\mathcal{D}}\\quad\\frac{2}{\\gamma^{2}}\\left(\\mathcal{L}(\\mathbf{u})-\\mathcal{L}(\\mathbf{w})-\\langle\\mathbf{u}-\\mathbf{w},\\nabla\\mathcal{L}(\\mathbf{w})\\rangle\\right).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We assume that the curvature constant is finite, i.e., $C_{l}<\\infty$ . This is true for ${\\mathcal{L}}(\\mathbf{w})$ as long as both the algorithm and the true optimum are bounded away from the boundary of $\\mathcal{D}$ \u2014 see detailed discussions on this in Ahipa\u00b8sao\u02d8glu and Todd [2]. A better analysis might be able to avoid this assumption, e.g., Zhao and Freund [65] use certain homogeneity properties of ${\\mathcal{L}}(\\mathbf{w})$ to derive better assumption-free convergence rates for the FW method on D-optimal experiment design. We leave the question of adapting these results to our setting (V-optimal experiment design) for a challenging future work. ", "page_idx": 16}, {"type": "text", "text": "Lemma B.1 (Lemma 5, [28]). For any $\\alpha\\in(0,1)$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\mathbf{w}_{t+1})\\leq\\mathcal{L}(\\mathbf{w}_{t})-\\alpha_{t}g(\\mathbf{w}_{t})+\\frac{\\alpha_{t}^{2}}{2}C_{l}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Theorem B.2. In the Frank-Wolfe algorithm, our update algorithm in Eq. $^{5}$ uses $\\begin{array}{r}{\\alpha_{t}=\\frac{1}{t+1}}\\end{array}$ . For this, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\mathbf{w}_{t})\\leq\\operatorname*{min}_{\\mathbf{w}\\in\\mathcal{D}}\\mathcal{L}(\\mathbf{w})+\\frac{C_{l}(1+\\log t)}{2t}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. Define $\\begin{array}{r}{h(\\mathbf{w})=\\mathcal{L}(\\mathbf{w})-\\operatorname*{min}_{\\mathbf{w}\\in\\mathcal{D}}\\mathcal{L}(\\mathbf{w})}\\end{array}$ . Using Lemma B.1, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{h(\\mathbf w_{t})\\leq h(\\mathbf w_{t-1})-\\alpha_{t-1}g(\\mathbf w_{t-1})+\\frac{\\alpha_{t-1}^{2}}{2}C_{l}}\\\\ &{\\qquad\\leq h(\\mathbf w_{t-1})-\\alpha_{t-1}h(\\mathbf w_{t-1})+\\frac{\\alpha_{t-1}^{2}}{2}C_{l}}\\\\ &{\\qquad=(1-\\alpha_{t-1})h(\\mathbf w_{t-1})+\\frac{\\alpha_{t-1}^{2}}{2}C_{l}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here we used the convexity of $\\mathcal{L}$ as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{g(\\mathbf{w}_{t-1})=\\underset{\\mathbf{s}\\in\\mathcal{D}}{\\operatorname*{sup}}\\langle\\mathbf{w}_{t-1}-\\mathbf{s},\\nabla\\mathcal{L}(\\mathbf{w}_{t-1})\\rangle}\\\\ &{\\quad\\quad\\quad\\quad\\geq\\langle\\mathbf{w}_{t-1}-\\mathbf{w}^{*},\\nabla\\mathcal{L}(\\mathbf{w}_{t-1})\\rangle}\\\\ &{\\quad\\quad\\quad\\geq\\mathcal{L}(\\mathbf{w}_{t-1})-\\underset{\\mathbf{w}\\in\\mathcal{D}}{\\operatorname*{min}}\\,\\mathcal{L}(\\mathbf{w})\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Continuing our derivation, recall we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\displaystyle h(\\mathbf{w}_{t})\\le(1-\\alpha_{t-1})h(\\mathbf{w}_{t-1})+\\frac{\\alpha_{t-1}^{2}}{2}C_{l}}}\\\\ &{}&{=\\displaystyle\\frac{t-1}{t}h(\\mathbf{w}_{t-1})+\\frac{1}{2t^{2}}C_{l}\\quad\\le\\quad\\displaystyle\\frac{t-2}{t}h(\\mathbf{w}_{t-1})\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nt\\cdot h(\\mathbf{w}_{t})\\leq(t-1)h(\\mathbf{w}_{t-1})+\\frac{C_{l}}{2t}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Unrolling this recursion, we get ", "page_idx": 17}, {"type": "equation", "text": "$$\nt\\cdot h(\\mathbf{w}_{t})\\leq\\sum_{k=1}^{t-1}\\sum\\frac{C_{l}}{2k}\\leq\\frac{C_{l}(1+\\log t)}{2}\\,.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This yields the theorem claim. ", "page_idx": 17}, {"type": "text", "text": "Finally, to finish the proof of Theorem 2, note that adding additional constraints only increases the loss, i.e., ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{w}\\in\\mathcal{D}}\\mathcal{L}(\\mathbf{w})\\leq\\operatorname*{min}_{\\mathbf{w}\\in\\mathcal{D}\\mathrm{~and~}\\mathbf{w}\\in\\{0,1\\}^{n}}\\mathcal{L}(\\mathbf{w}).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence, we showed a $O(\\log t/t)$ approximation to the otherwise intractable combinatorial problem. With additional assumptions on the structure of the loss function, one can even show improved quadratic or even exponential approximations [15, 8]. Finally, we note that Frank-Wolfe is a wellknown method to efficiently approximate the optimal experiment design objective [59, 20, 2] and this also motivates using this approach in practice [2, 6]. ", "page_idx": 17}, {"type": "text", "text": "C Experimental Setup ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For each buyer test point, we optimize each selection algorithm over the 1,000 seller datapoints and select the highest value data based on the validation set of 100 datapoints (our method and Data OOB do not use the validation set). For each test point, we train a linear regression model on the selected seller points and report test mean squared error (MSE) on the buyer\u2019s data and average test error over 100 buyers. ", "page_idx": 17}, {"type": "text", "text": "For reproducibility, our full implementation is available at: https://github.com/clu5/ data-acquisition-via-experimental-design. ", "page_idx": 17}, {"type": "text", "text": "C.1 Implementation Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We conduct all experiments on an Intel Xeon E5-2620 CPU with 40 cores and a Nvidia GTX 1080 Ti GPU. For implementation of baseline data valuation methods, we use the OpenDataVal package [30] version 1.2.1. We use the default hyperparameter settings for all methods except for Data Shapley (changed 100 Monte-Carlo epochs with 10 models per iteration), Influence Subsample (from 1000 to 500 models), and Data OOB (from 1, 000 to 500 models) to reduce computational runtime. ", "page_idx": 17}, {"type": "text", "text": "In our experiments, we use the following setting of hyperparameters for DAVED: ", "page_idx": 17}, {"type": "text", "text": "\u2022 500 iterations for multi-step variant, 1 iteration for single-step variance   \n\u2022 Line search for step size $\\alpha\\in(0,0.9)$   \n\u2022 Regularization $\\lambda=0$ (unless otherwise specified)   \n\u2022 No early stopping ", "page_idx": 17}, {"type": "text", "text": "For experiments with heterogeneous costs,\u221a we uniformly sample costs $c\\in\\{1,2,3,4,5\\}$ for each seller datapoint and apply either $h(c)\\,=\\,\\sqrt{\\,c\\,}$ or $h(c)={\\dot{c}}^{2}$ as the cost function. Noisy labels are generated by adding Gaussian noise scaled inversely proportional to the cost, with overall noise level set to $30\\%$ . ", "page_idx": 17}, {"type": "text", "text": "C.2 Dataset Details and Processing ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "For Fitzpatrick17K and RSNA Bone Age datasets, each image was embedded through a CLIP ViT-B/32 model [49], while for the DrugLib dataset, each text review was embedded through GPT-2 model [48] with a max context length of 4096. ", "page_idx": 18}, {"type": "text", "text": "For the Gaussian dataset, we generate a regression dataset according to the following Python code: ", "page_idx": 18}, {"type": "table", "img_path": "VXJVNdmXO4/tmp/7b34982bc24b2c3edbb2b6fd441212b22c0841326be0abb18de549c1032c5670.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "The RSNA Pediatric Bone Age Challenge (2017) dataset [25] may be downloaded here https://www.rsna.org/rsnai/ai-image-challenge/ rsna-pediatric-bone-age-challenge-2017. We use the training set for our experiments, resulting in 12,611 images in total. Using the following function, each image was embedded through a pre-trained CLIP ViT-B/32 model. ", "page_idx": 18}, {"type": "table", "img_path": "VXJVNdmXO4/tmp/4e1ac6e87f851d727c028bcc0eb1277937ecf8a8a893a3a3042af2f5787fd9e0.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "The Fitzpatrick17K [24] can be downloaded from here https://github.com/mattgroh/ fitzpatrick17k. Missing or corrupted images were excluded, resulting in 16,536 total images. Some images were annotated with two separate annotation platforms. We averaged the two skin type ratings for these images, resulting in 12 possible labels (0\u20136 in 0.5 increments). Each image was embedded in a fashion similar to the RSNA Bone Age dataset. ", "page_idx": 18}, {"type": "text", "text": "The MIMIC dataset [31] can be accessed here https://physionet.org/content/ mimiciii/1.4/. The task is to predict the length of stay (LOS) in the number of days a patient stays in the Intensive Care Unit. The dataset contains 51,036 rows with both real-valued and one-hot-encoded attributes with the following names: ", "page_idx": 18}, {"type": "text", "text": "\u201cLOS\u201d , \u201cblood\u201d , \u201ccirculatory\u201d , \u201ccongenital\u201d , \u201cdigestive\u201d , \u201cendocrine\u201d , \u201cgenitourinary\u201d , \u201cinfectious\u201d , \u201cinjury\u201d , \u201cmental\u201d , \u201cmisc\u201d , \u201cmuscular\u201d , \u201cneoplasms\u201d , \u201cnervous\u201d , \u201cpregnancy\u201d , \u201cprenatal\u201d , \u201crespiratory\u201d , \u201cskin\u201d , \u201cGENDER\u201d , \u201cICU\u201d , \u201cNICU\u201d , \u201cADM_ELECTIVE\u201d , \u201cADM_EMERGENCY\u201d , \u201cADM_NEWBORN\u201d , \u201cADM_URGENT\u201d , \u201cINS_Government\u201d , \u201cINS_Medicaid\u201d , \u201cINS_Medicare\u201d , \u201cINS_Private\u201d , \u201cINS_Self Pay\u201d , \u201cREL_NOT SPECIFIED\u201d , \u201cREL_RELIGIOUS\u201d , \u201cREL_UNOBTAINABLE\u201d , \u201cETH_ASIAN\u201d , \u201cETH_BLACK/AFRICAN AMERICAN\u201d , \u201cETH_HISPANIC/LATINO\u201d , \u201cETH_OTHER/UNKNOWN\u201d , \u201cETH_WHITE\u201d , \u201cAGE_middle_adult\u201d , \u201cAGE_newborn\u201d , \u201cAGE_senior\u201d , \u201cAGE_young_adult\u201d , \u201cMAR_DIVORCED\u201d , \u201cMAR_LIFE PARTNER\u201d , \u201cMAR_MARRIED\u201d , \u201cMAR_SEPARATED\u201d , \u201cMAR_SINGLE\u201d , \u201cMAR_UNKNOWN (DEFAULT)\u201d , \u201cMAR_WIDOWED\u201d ", "page_idx": 18}, {"type": "text", "text": "Each attribute was min-max scaled to lie in the range [0, 1]. ", "page_idx": 19}, {"type": "text", "text": "The DrugLib dataset [34] can be downloaded here https://archive.ics.uci.edu/ dataset/461/drug+review+dataset+druglib $^+$ com. The task is to predict overall patient satisfaction with a drug\u2019s side effects and effectiveness on a ten-point scale. We format each review using the following prompt template to feed GPT-2: ", "page_idx": 19}, {"type": "text", "text": "Benefits: $\\mathsf{S}$ BENEFITS_REVIEW Side effects: \\$SIDE_EFFECTS_REVIEW Comments: $\\mathsf{S}$ COMMENTS_REVIEW ", "page_idx": 19}, {"type": "text", "text": "where $\\mathsf{S}$ BENEFITS_REVIEW is the corresponding portion of the drug review. ", "page_idx": 19}, {"type": "table", "img_path": "VXJVNdmXO4/tmp/c9a65bb298aae602d4e82e0c42839b588be441b90efc14bd52f6c02265041a66.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "C.3 Evaluation Protocol ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For all experiments (unless otherwise specified), we use the following evaluation settings: ", "page_idx": 19}, {"type": "text", "text": "\u2022 Training split: Variable number of seller points (1K\u2013100K)   \n\u2022 Validation split: 100 points for baseline data valuation methods   \n\u2022 Test split: 100 buyer points evaluated independently   \n\u2022 Metrics: Mean squared error averaged over all buyer points   \n\u2022 Budget ranges: 1\u201330 for cost experiments, 1\u2013150 otherwise Number of random seeds: All results averaged over 3 seeds ", "page_idx": 19}, {"type": "text", "text": "For a fair comparison, we use the same train/validation/test splits across all methods for each random seed. The validation set is only used by data valuation baseline methods that require it \u2014 our method DAVED operates directly on the test queries without requiring validation data. ", "page_idx": 19}, {"type": "text", "text": "D Additional Experiments ", "text_level": 1, "page_idx": 20}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/450e84857eebd2e02bf54378a2b9d5775f1f260f2a86fe5ad7baefd9672e75ba.jpg", "img_caption": ["D.1 Budget Results with Heterogeneous Costs "], "img_footnote": [], "page_idx": 20}, {"type": "text", "text": "Figure 6: DAVED maintains performance advantage with heterogeneous costs on synthetic data. We evaluate data selection methods on 10K synthetic Gaussian datapoints with costs randomly sampled from $\\{1,2,3,4,5\\}$ and transformed using two cost functions: $\\sqrt{c}$ (left) and $c^{2}$ (right). Each datapoint\u2019s label noise is scaled inversely with cost $(\\varepsilon/c_{j})$ to simulate quality differences. DAVED achieves lower test MSE across budgets 1-30 while respecting cost constraints, demonstrating robust performance even with varying data quality and costs. Results are averaged over 100 random buyer test points. ", "page_idx": 20}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/4f44d328e70a9b543578a247ba9e1ba3d3c2feb10b2020628578f0e4cfed949f.jpg", "img_caption": ["Figure 7: Comparing performance on MIMIC healthcare data with heterogeneous costs. Experiments on MIMIC-III dataset (35\u221aK patients with 48 normalized clinical features) compare performance under two cost functions: $\\sqrt{c}$ (left) and $c^{2}$ (right). Costs are uniformly sampled from $1,2,3,4,5$ per datapoint. Label noise $\\varepsilon\\sim\\mathcal{N}(0,\\sigma^{2})$ is scaled by $\\bar{y}/h(c_{j})$ where $\\bar{y}$ is the mean label value and $h(c)$ is the cost function, modeling how higher-cost data has lower noise. DAVED achieves lower prediction error for length-of-stay prediction across budgets 1-30. Results averaged over 100 random test patients. "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/4a40ebee90cc20eb8cb2818b5247a1c46821d98a72a6586849a3cda5ef0852ef.jpg", "img_caption": ["Figure 8: Comparing performance on Fitzpatrick skin lesion dataset with varying costs. E\u221avaluation on Fitzpatrick17K dataset (15K images embedded through CLIP) under two cost functions: $\\sqrt{c}$ (left) and $c^{2}$ (right). Costs sampled from $1,2,3,4,5$ with noise $\\varepsilon\\sim\\mathcal{N}(0,\\sigma^{2})$ scaled by $\\bar{y}/h(c_{j})$ , where $\\bar{y}$ is the mean Fitzpatrick score and $h(c)$ is the cost function. This scaling ensures highercost images have proportionally less label noise. DAVED achieves consistent performance while respecting heterogeneous cost constraints. Results averaged over 100 random test images. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/4492498bc9421b49a068b9e4450821a0c98356de3563787ead03af1e7ecf23d8.jpg", "img_caption": ["Figure 9: Comparing performance on RSNA bone age prediction with cost variations. A\u221analysis on RSNA Bone Age dataset (12K X-ray images embedded via CLIP) using cost functions $\\sqrt{c}$ (left) and $c^{2}$ (right). With costs sampled from $1,2,3,4,5$ and label noise $\\varepsilon\\sim\\mathcal{N}(\\bar{0},\\sigma^{2})$ scaled by $\\bar{y}/h(c_{j})$ , where $\\bar{y}$ is the mean age and $h(c)$ is the cost function. This models how higher-cost $\\boldsymbol{\\mathrm{X}}$ -rays have more accurate age labels. DAVED maintains superior prediction accuracy compared to other data valuation baselines. Results show mean error over 100 random test $\\Chi$ -rays. "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/f6b63912a7a529cf0814e2d158c802cf7aec2eb1a04aa98929b7d7bf8ddd5684.jpg", "img_caption": ["Figure 10: Comparing performance on drug review text data with heterogeneous cos\u221ats. Evaluation on DrugLib reviews (3.5K reviews embedded using GPT-2) under cost functions $\\sqrt{c}$ and $c^{2}$ . Costs sampled from $1,2,3,4,5$ with noise $\\varepsilon\\sim\\mathcal{N}(0,\\sigma^{2})$ scaled by $\\bar{y}/h(c_{j})$ , where $\\bar{y}$ is the mean rating and $h(c)$ is the cost function, reflecting how higher-cost reviews tend to have more reliable ratings. DAVED achieves robust rating prediction performance despite varying data quality. Results averaged over 100 random test reviews. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/49b137b55fa04b2c818cc4072d99486a4bfb52f70ef3c490f35ba37e20f9b400.jpg", "img_caption": ["D.2 Regularization ", "Figure 11: Regularization strength significantly impacts DAVED performance across domains. We evaluate prediction error versus budget as $\\lambda$ varies from 0 (no regularization) to 1 (identity information matrix) on: MIMIC dataset (length-of-stay prediction), DrugLib reviews (rating prediction with GPT-2 embeddings), and RSNA Bone Age (age prediction from $\\Chi$ -rays using CLIP embeddings). Moderate regularization $\\lambda$ between 0.2\u20130.6) improves stability and performance by better conditioning the information matrix, though DAVED remains effective even without regularization. Results averaged over 100 random test points per budget level. "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/6a55ddcb27a45cb7af58444147b84503fcc852b6e72e7713c0152e789a7b479a.jpg", "img_caption": ["Figure 12: Buyer test set size affects prediction performance of DAVED. We vary the number of simultaneous test points (1 to 32) being optimized over for: Gaussian synthetic data (30 dimensions), MIMIC clinical data (48 dimensions), and RSNA Bone Age $\\boldsymbol{\\mathrm{X}}$ -rays (512 dimensions). While all buyer and seller data follow the same distribution within each dataset, increasing test batch size leads to higher prediction errors as the optimization problem becomes more challenging. Results suggest keeping buyer queries to 1-8 test points for optimal performance. Each curve shows mean error over 100 random trials with different test sets. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/ccb549dcddbf658bd909bcb6767b7e754957b411427221a8036d4c6f48951aa9.jpg", "img_caption": ["D.4 Number of Iteration Steps ", "Figure 13: Number of optimization steps impacts DAVED performance. We evaluate prediction error versus budget while varying optimization steps from 1 to 1, 000 on Gaussian data (30 dimensions) and RSNA Bone Age dataset (embedded through CLIP). More iterations generally improve performance as the algorithm better approximates the optimal selection weights. For homogeneous costs $(c_{j}=1)$ , we recommend using 2-5 times more optimization steps than the desired budget to ensure convergence. Results show mean error over 100 random test points per configuration. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/f71cfc1f0b85c86b002f595646f7bf6be50ac3b90d5caf7863d09495f16dd5e8.jpg", "img_caption": ["Figure 14: Linear models in feature space approximate full model fine-tuning. We compare BERT performance on DrugLib reviews using either full fine-tuning (which updates all model parameters) or linear probing (which only trains a linear layer on frozen embeddings) on data selected by DAVED versus random selection. The similar performance patterns between these approaches empirically validates our use of kernelized linear regression in the feature space as a proxy for the full training dynamics. This aligns with recent theoretical work showing that fine-tuning of pre-trained models is well-approximated by linear models in the empirical Neural Tangent Kernel (eNTK) regime. Since our method relies on this linear approximation for efficient data selection, these results support our choice of feature extractor $\\phi$ and linear modeling approach. Results show test error averaged over 100 random trials using different test reviews. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/09fad8a734bbf689be7ad2158b7c6fe16e05f8e86a69bb27d7d17487b993e37c.jpg", "img_caption": ["D.6 Iterative versus Convex optimization ", "Figure 15: DAVED\u2019s iterative optimization matches convex solver accuracy. We compare the prediction error of Frank-Wolfe optimization with a convex optimization solver on 1, 000 datapoints sampled from 30-dimensional Gaussian distribution. Both single-step and multi-step variants of our iterative approach achieve comparable accuracy to the optimal convex solution while being significantly faster to optimize. Results averaged over 100 random trials with homogeneous costs $(c_{j}=1)$ ). "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "VXJVNdmXO4/tmp/188ae20327a838dc5c4cc1a4210da2929b456a076b66365945fe8ba72efbc9cf.jpg", "img_caption": ["Figure 16: DAVED provides orders of magnitude runtime speedup over convex optimization. Runtime comparison between Frank-Wolfe iterative approach and convex solver for the data selection problem on 1000 datapoints from 30-dimensional Gaussian distribution. Our iterative method achieves several orders of magnitude speedup while maintaining similar levels of prediction error (see Figure 15). The single-step variant provides additional acceleration with minimal performance loss "], "img_footnote": [], "page_idx": 25}, {"type": "text", "text": "E Broader Impacts ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We believe that AI developers face important ethical questions when acquiring data for AI development, as highlighted by recent class-action lawsuits against AI companies regarding data consent and compensation. Our work presents a scalable and decentralized approach to data acquisition that can help address these concerns. By enabling targeted selection of the most valuable datapoints, our method reduces both costs and potential privacy risks compared to broad, indiscriminate data access [44]. The decentralized nature of our approach enhances transparency and gives individual data owners more control over how their data is shared and used, while avoiding the privacy and security risks of centralizing data with brokers. However, while our method enables more efficient and privacy-preserving data transactions that could democratize access to high-quality training data, especially in domains like healthcare, several societal and technical challenges remain. These include ensuring fair compensation for data owners, preventing misuse of acquired data, and developing appropriate governance frameworks for decentralized data markets. Addressing these challenges will be crucial for the responsible development of data marketplaces that can sustainably increase the supply of training data while protecting individual privacy and data rights. ", "page_idx": 25}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The abstract and introduction clearly state our main contributions and scope. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 26}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Justification: We address the limitations of our methods in Section 6. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 26}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: We provide proofs of all main theorems in Appendix 1 and Appendix B. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 27}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: We provide complete implementation details, hyperparameters, and experimental setup in Appendix C. Our code is publicly available at https://github.com/ clu5/data-acquisition-via-experimental-design. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 27}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: In the supplemental material, we provide a simplified code example and will release the full codebase in a public code repository upon acceptance. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 28}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: We provide details of our experimental setup in Appendix C. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 28}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: All experimental results are averaged over 100 random test trials. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Hardware specs and runtime analysis provided in Appendix C and Figure 5. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 29}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Our research complies with NeurIPS Code of Ethics. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 29}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Appendix E discusses both the beneftis and risks of our work in the context of data marketplaces. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 29}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 30}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: We believe this paper does not pose such risks as we do not release any new models or datasets. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 30}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We cite and provide links to all datasets used in Appendix C. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: This paper does not introduce any new datasets or models. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 31}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Our research does not involve crowdsourcing or human subjects. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 31}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: No human subjects research was conducted. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}]