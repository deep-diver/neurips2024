{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-00-00", "reason": "This paper is foundational to the field of vision transformers and is frequently cited as the starting point for many subsequent works in this area."}, {"fullname_first_author": "Haotian Liu", "paper_title": "Visual instruction tuning", "publication_date": "2024-00-00", "reason": "This paper introduces a new approach for training vision-language models that significantly improves their performance on various tasks, making it a highly relevant and important reference."}, {"fullname_first_author": "Ze Liu", "paper_title": "Swin transformer: Hierarchical vision transformer using shifted windows", "publication_date": "2021-00-00", "reason": "This paper introduces the Swin Transformer architecture, which has become a highly influential model in the field of computer vision, impacting many subsequent works."}, {"fullname_first_author": "Daniel Bolya", "paper_title": "Token merging: Your ViT but faster", "publication_date": "2023-00-00", "reason": "This paper introduces the concept of token merging in vision transformers which is the primary focus of the current paper."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "CLIP model, introduced in this paper, is used extensively in the current paper's experiments and is a highly influential model in the field of vision and language."}]}