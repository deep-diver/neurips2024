[{"figure_path": "nkwPiBSw1f/tables/tables_7_1.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents the performance comparison of various models (Centralized, FedIT, FedLORA, Local-finetuned, FedDPA-F, and FedDPA-T) on a federated dataset for both personalization (performance on the targeted local task) and test-time personalization (performance on unseen test tasks).  The results are broken down by individual NLP tasks (Paraphrase, Entailment, Structure to Text, Text Formatting, Linguistic Acceptability, Word Disambiguation, Coreference, and Question Classification) and provide average scores across tasks.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_7_2.jpg", "caption": "Table 2: Personalization and test-time personalization results of different models on federated dataset 2. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Reading Com represents the reading comprehension task.", "description": "This table presents the performance of various federated learning models on a second federated dataset.  It shows how well the models perform in terms of personalization (on the targeted tasks for each client) and test-time personalization (on tasks unseen during training).  FedDPA-F and FedDPA-T are the authors' proposed methods, distinguished by whether local adapters are fine-tuned or trained from scratch. The table provides a quantitative comparison across multiple tasks.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_8_1.jpg", "caption": "Table 4: Ablation study of updating weight. P represents personalization, and TTP represents test-time personalization.", "description": "This table presents the results of an ablation study on the updating weight (\u03b1) used in the FedDPA-T model.  It shows the performance of the model in terms of personalization (P) and test-time personalization (TTP) across two federated datasets (Dataset 1 and Dataset 2) with different values of \u03b1 (0.3, 0.5, and 0.7). The results demonstrate how the weighting of the local and global adapters affects the model's performance on both targeted tasks and unseen test-time tasks. The aim is to find the optimal balance between personalization and generalization.", "section": "6.2 Ablation Study"}, {"figure_path": "nkwPiBSw1f/tables/tables_13_1.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents a comparison of different models' performance on a federated dataset in terms of personalization (accuracy on the targeted task) and test-time personalization (average accuracy across all tasks including unseen test-time tasks).  The models compared include a centralized model, FedIT, FedLoRA, a locally finetuned model, and two variants of the proposed Federated Dual-Personalizing Adapter (FedDPA): one with local fine-tuning (FedDPA-F) and one with local training (FedDPA-T).  The table shows the performance for three specific tasks: Linguistic Acceptability, Word Disambiguation, and Question Classification, alongside an average score across all tasks.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_13_2.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents a comparison of the performance of different models on a federated dataset focusing on two key aspects: personalization (how well the model adapts to individual client data) and test-time personalization (how well the model generalizes to new, unseen tasks during the testing phase).  The models compared include centralized training (all data combined), FedIT, FedLORA, a locally fine-tuned model, and two versions of the proposed FedDPA method (one with fine-tuning of the local adapter and one with training of the local adapter). The results are shown for several NLP tasks:  linguistic acceptability, word disambiguation, coreference, paraphrase, entailment, question classification, and text-to-structure.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_13_3.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents a comparison of the performance of various models on a federated dataset, focusing on two key aspects: personalization (how well the model adapts to specific client data) and test-time personalization (how well the model generalizes to unseen tasks during testing).  The models compared include centralized, FedIT, FedLoRA, locally fine-tuned models, and the proposed FedDPA models (FedDPA-F and FedDPA-T).  The table shows performance metrics for several NLP tasks.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_14_1.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents a comparison of various Federated Foundation Models (FFMs) on two key performance metrics: personalization and test-time personalization.  Personalization measures how well each model adapts to the specific tasks of individual clients, whereas test-time personalization assesses the models' ability to generalize to new, unseen tasks during the testing phase.  The table includes results for several baseline FFMs, as well as the proposed FedDPA-F and FedDPA-T models. The results are broken down by individual tasks (Linguistic, Word Disambiguation, Question Classification) to provide a detailed comparison of model performance.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_14_2.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents a comparison of different model's performance on a federated dataset focusing on two key aspects: personalization (how well the model adapts to each client's specific task) and test-time personalization (how well it generalizes to unseen tasks during testing).  It compares a centralized model, FedIT, FedLoRA, a local-finetuned model, and two versions of the proposed FedDPA model (FedDPA-F and FedDPA-T).  The results are broken down by specific NLP tasks (Linguistic, Word Disambiguation, Coreference, Paraphrase, Question Classification, and Text-to-Text).", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_15_1.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents the performance comparison of various federated learning models on a specific dataset.  It shows the performance in terms of personalization (how well the model adapts to individual user preferences) and test-time personalization (how well the model generalizes to new, unseen tasks).  The models compared include a centralized model (trained on all data), a local-finetuned model (trained only on local data), FedIT, FedLoRA, and two versions of the proposed FedDPA model (FedDPA-F and FedDPA-T, which differ in how the local adapter is trained).  Results are presented for several NLP tasks, including linguistic acceptability, word disambiguation, and question classification.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_16_1.jpg", "caption": "Table 9: Ablation study of similarity metric (Sim). P represents personalization, and TTP represents test-time personalization. -L2 represents using the L2-Norm as metric, Pearson represents using the Pearson correlation as metric, and Cosine represents using the cosine similarity as the metric.", "description": "This table presents the ablation study results on the impact of different similarity metrics used in the instance-wise dynamic weighting mechanism of the FedDPA model.  It compares the performance of the model using three different similarity metrics: L2-norm, Pearson correlation, and cosine similarity, for both personalization and test-time personalization tasks. The results show that the cosine similarity metric outperforms the other two metrics in terms of both personalization and test-time personalization performance.", "section": "6.2 Ablation Study"}, {"figure_path": "nkwPiBSw1f/tables/tables_16_2.jpg", "caption": "Table 10: Ablation study of instance representations (Emb). P represents personalization, and TTP represents test-time personalization. LAST represents using the embedding of the final token from the final hidden layer of LLM as instance representation, and AVG represents using the average embedding of all tokens from the final hidden layer of LLM as instance representation.", "description": "This table presents the ablation study result of the instance representation method in the proposed FedDPA model. Two different methods were compared: using the embedding of the last token from the final hidden layer of the LLM (LAST) and using the average embedding of all tokens from the final hidden layer of the LLM (AVG). The results are reported for both personalization (P) and test-time personalization (TTP) performance on Federated Dataset 1.", "section": "6.2 Ablation Study"}, {"figure_path": "nkwPiBSw1f/tables/tables_16_3.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table presents a comparison of different models' performance on a federated dataset focusing on two aspects: personalization (how well the model performs on the specific tasks for each client) and test-time personalization (how well the model generalizes to unseen tasks).  It shows the average performance across several NLP tasks for each model, including the proposed FedDPA models (FedDPA-F and FedDPA-T, which represent different approaches to local adapter training).  The results highlight the trade-offs between personalization and generalization to new tasks.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_17_1.jpg", "caption": "Table 1: Personalization and test-time personalization results of different models on federated dataset 1. FedDPA-F represents the model with the local fine-tuning adapter and FedDPA-T represents the model with the local training adapter. Linguistic represents the linguistic acceptability task, Word Dis represents the word disambiguation task, and Question CLS represents question classification task.", "description": "This table compares the performance of different models (Centralized, FedIT, FedLORA, Local-finetuned, FedDPA-F, and FedDPA-T) on a federated dataset for both personalization (performance on the target local task) and test-time personalization (average performance across all tasks, including test-time tasks).  The results show that FedDPA models generally outperform other methods, particularly FedDPA-F for test-time personalization.", "section": "5.2 Main Results"}, {"figure_path": "nkwPiBSw1f/tables/tables_17_2.jpg", "caption": "Table 13: Average inference time per instance. Auto represents the instance-wise dynamic weighting mechanism.", "description": "This table presents the average inference time per instance for different models.  It compares the inference time of FedLoRA, FedDPA without the instance-wise dynamic weighting mechanism (FedDPA (w/o auto)), and FedDPA with the mechanism. The table shows that adding the instance-wise dynamic weighting mechanism increases the inference time slightly, but the increase is minimal, demonstrating that the improved performance comes at a low computational cost.", "section": "B.4 Communication and Computation Analysis"}, {"figure_path": "nkwPiBSw1f/tables/tables_18_1.jpg", "caption": "Table 14: Test-time performance on unseen tasks. All models are trained on Federated Dataset 1, and these unseen test-time tasks are not included in Federated Dataset 1. AVG represents the average score across all clients for this task, while MAX represents the highest score among these clients for this task. The best performance for AVG is bolded, and the best performance for MAX is underlined.", "description": "This table presents the results of applying four different federated learning models (FedIT, FedLORA, FedDPA-F, and FedDPA-T) to three unseen test-time tasks: summarization, reading comprehension, and open-domain question answering.  The models were initially trained on Federated Dataset 1, which contained seen tasks. The table shows both the average (AVG) and maximum (MAX) performance scores across all clients for each model on each unseen task.  The purpose is to evaluate the models' ability to generalize to tasks not seen during training, simulating a real-world scenario.", "section": "C Discussions"}]