[{"figure_path": "h0rbjHyWoa/figures/figures_1_1.jpg", "caption": "Figure 1: We study semantic segmentation with both semantic-shift and covariate-shift regions. (a) Training for Out-of-distribution (OOD) detection alone [31] yields high uncertainty for both types of shifts, whereas training for domain generalization (DG) alone [9] tends to produce low uncertainty for both. Our method effectively differentiates between the two, generating high uncertainty only for semantic-shift regions. (b) We achieve strong performance in both OOD detection and domain-generalized semantic segmentation. (c) This is achieved by coherently augmenting original images (first row) with both covariate and semantic shifts (second row).", "description": "This figure illustrates the core idea of the paper.  It shows that existing methods struggle to distinguish between domain shifts (changes in background, lighting, etc.) and semantic shifts (appearance of new objects). The authors' method is designed to handle both types of shifts by effectively generating training data with both, and it improves performance in both out-of-distribution detection and domain generalization.", "section": "1 Introduction"}, {"figure_path": "h0rbjHyWoa/figures/figures_3_1.jpg", "caption": "Figure 2: Method Overview: (a) A novel generative-based data augmentation strategy that supplements training data with both covariate and semantic shifts in a coherent manner. (2) A semantic-exclusive uncertainty function with two-stage noise-aware training to encourage invariant feature learning for covariate-shift regions while maintaining high uncertainty for semantic-shift regions.", "description": "This figure illustrates the method overview of the proposed approach. The left side (a) shows the data augmentation strategy using a generative model to create images with both covariate and semantic shifts. The right side (b) shows the two-stage training process that refines the uncertainty function and features of the segmentation model. The two stages work in concert to enable the model to differentiate between covariate and semantic shifts. The resulting model generates high uncertainty for semantic shifts and low uncertainty for covariate shifts.", "section": "3. Method"}, {"figure_path": "h0rbjHyWoa/figures/figures_7_1.jpg", "caption": "Figure 3: Comparison of Uncertainty Maps. Our method robustly detects anomalies under covariate shifts across five datasets (first five columns) and generated data (last column). The previous method RPL [31] failed to distinguish domain from semantic shifts, producing high uncertainty in both cases. In Fig. 3, we visualize the uncertainty map output by our method using the DeepLabv3+ architecture. Compared to the previous state-of-the-art method, RPL [31], our model assigns higher uncertainty scores to anomalous objects and lower uncertainty scores to covariate shifts. This highlights the efficacy of our method in distinguishing between domain shifts and semantic shifts.", "description": "This figure compares uncertainty maps generated by the proposed method and the baseline method (RPL) across various datasets with both semantic and domain shifts.  It demonstrates the ability of the proposed method to accurately identify semantic shifts (anomalies) while being robust to covariate shifts, unlike the baseline.", "section": "4.3 Results on Anomaly Segmentation Benchmarks"}, {"figure_path": "h0rbjHyWoa/figures/figures_9_1.jpg", "caption": "Figure 4: Method Overview: (a) A novel generative-based data augmentation strategy that supplements training data with both covariate and semantic shifts in a coherent manner. (2) A semantic-exclusive uncertainty function with two-stage noise-aware training to encourage invariant feature learning for covariate-shift regions while maintaining high uncertainty for semantic-shift regions.", "description": "This figure shows a schematic overview of the proposed method.  The left side (a) details a novel generative data augmentation strategy to create images with both covariate and semantic shifts. The right side (b) illustrates a semantic-exclusive uncertainty function used in a two-stage noise-aware training process. The goal is to learn a model that differentiates between the two types of shifts and responds appropriately to each.", "section": "3.2 Coherent Generative-based Augmentation"}, {"figure_path": "h0rbjHyWoa/figures/figures_16_1.jpg", "caption": "Figure 3: Comparison of Uncertainty Maps. Our method robustly detects anomalies under covariate shifts across five datasets (first five columns) and generated data (last column). The previous method RPL [31] failed to distinguish domain from semantic shifts, producing high uncertainty in both cases. In Fig. 3, we visualize the uncertainty map output by our method using the DeepLabv3+ architecture. Compared to the previous state-of-the-art method, RPL [31], our model assigns higher uncertainty scores to anomalous objects and lower uncertainty scores to covariate shifts. This highlights the efficacy of our method in distinguishing between domain shifts and semantic shifts.", "description": "This figure compares uncertainty maps generated by the proposed method and a previous state-of-the-art method (RPL). It shows that the proposed method more accurately distinguishes between semantic shifts (anomalies) and covariate shifts (changes in image appearance) by assigning higher uncertainty to anomalies and lower uncertainty to covariate shifts. The visualization uses the DeepLabv3+ architecture.", "section": "4.3 Results on Anomaly Segmentation Benchmarks"}, {"figure_path": "h0rbjHyWoa/figures/figures_19_1.jpg", "caption": "Figure 6: Visualization of Generated Images. Row 1: Original images from Cityscapes. Row 2: Generated images featuring both semantic and domain shifts. Row 3: Selection map used to calculate selected cross-entropy loss during training. Row 4: Cross-entropy loss map used to produce the selection map (excluding the OOD regions, which are not involved in known class segmentation loss calculation). Below each column, we display the weather, time, and location prompts that guide the model in generating diverse covariate shifts, along with the OOD prompts for object generation. Red boxes highlight generation errors.", "description": "This figure visualizes the generated images with both semantic and domain shifts. The first row shows the original images from the Cityscapes dataset. The second row displays the generated images, where novel objects are seamlessly integrated into the scenes with various covariate shifts (e.g., weather, lighting). The third row shows the selection maps used to calculate the cross-entropy loss during training. The fourth row displays the cross-entropy loss maps, highlighting the regions with high uncertainty scores. The captions below each column specify the weather conditions, time, and location prompts used to generate these images, along with the type of novel objects added.", "section": "D Visualization of Generated Data"}]