[{"figure_path": "drpJ7KOr3F/tables/tables_6_1.jpg", "caption": "Table 1: Comparison with other CL methods on each modalities of in-domain datasets. We label the best and second methods with bold and underline styles. The top gray block indicates the upper-bound scores Tm of transfer learning capability to adapt the new modality.", "description": "This table compares the performance of the proposed PathWeave method with other Continual Learning (CL) methods on five different modalities (image, video, audio, depth, and 3D point cloud).  The metrics used are transfer learning capability (T) and forgetting rate (F) for each modality transition.  The table highlights the superior performance of PathWeave in terms of both high transfer learning capability and low forgetting, particularly when transitioning to more complex modalities like audio and 3D point clouds.", "section": "5.2 Comparison with State-of-the-art Methods"}, {"figure_path": "drpJ7KOr3F/tables/tables_6_2.jpg", "caption": "Table 1: Comparison with other CL methods on each modalities of in-domain datasets. We label the best and second methods with bold and underline styles. The top gray block indicates the upper-bound scores Tm of transfer learning capability to adapt the new modality.", "description": "This table compares the performance of the proposed PathWeave method with other Continual Learning (CL) methods on in-domain datasets across five modalities (Image, Video, Audio, Depth, and 3D).  The metrics used evaluate the transfer learning capability (Tm) to adapt to new modalities and the forgetting rate (Fm) during continual learning.  The table highlights the effectiveness of PathWeave in maintaining performance on previously learned modalities while adapting to new ones.", "section": "5.2 Comparison with State-of-the-art Methods"}, {"figure_path": "drpJ7KOr3F/tables/tables_7_1.jpg", "caption": "Table 3: Comparison with state-of-the-art methods on training parameters, data requirements and some performance. \u201cAll Modal\u201d indicates whether fine-tuning on all modality datasets is included. \u201c\u2020\u201d represents the same hyperparameters and training settings of different methods for fair comparison.", "description": "This table compares the proposed method (PathWeave) with other state-of-the-art multimodal large language models (MLLMs) in terms of training parameters, data requirements, training time, GPU usage, and performance on three multimodal question answering tasks (MSVD QA, Clotho Caps, and Modelnet Cls). The table shows that PathWeave achieves comparable performance with significantly fewer parameters and less training data, demonstrating its efficiency and scalability.", "section": "5 Experiments"}, {"figure_path": "drpJ7KOr3F/tables/tables_7_2.jpg", "caption": "Table 4: Ablation study of different parts for the influence of the each modalities' performance. We label the best and second methods with bold and underline styles.", "description": "This ablation study investigates the impact of different components of the PathWeave framework on the performance of each modality.  Specifically, it compares the full model (ours) against versions without the MoE-based gating module and without the in-adapter module.  The results show the contributions of each component to the overall performance across various modalities. The best performing method for each modality is highlighted in bold, indicating the importance of the complete AnA framework.", "section": "5.3 Ablation Study"}, {"figure_path": "drpJ7KOr3F/tables/tables_8_1.jpg", "caption": "Table 4: Ablation study of different parts for the influence of the each modalities' performance. We label the best and second methods with bold and underline styles.", "description": "This table presents the ablation study results on the performance of different parts of the proposed method (PathWeave) across various modalities. It shows the impact of removing certain components, such as the MoE-based gating module or the In-Adapter, on the overall performance. By comparing the performance metrics across modalities with and without these components, the table highlights the effectiveness and contribution of each component in the PathWeave framework.", "section": "5.3 Ablation Study"}, {"figure_path": "drpJ7KOr3F/tables/tables_14_1.jpg", "caption": "Table A6: Datasets for continually uni-modal finetuning. Our datasets are extensions of X-InstructBLIP [20], in contrast, we additionally included depth data and removed inaccessible video data WebVid2M [76]. * represent data we generated ourselves.", "description": "This table lists the datasets used for continual uni-modal fine-tuning in the PathWeave model.  It details the size and source of each dataset for five modalities: image, video, audio, 3D, and depth.  The datasets are primarily drawn from existing multimodal datasets, but with additions and modifications to suit the continual learning approach. Notably, depth data was added, and inaccessible WebVid2M video data was removed.  The \u2018*\u2019 indicates datasets that were generated by the authors of the paper.", "section": "A.1 Dataset Details"}, {"figure_path": "drpJ7KOr3F/tables/tables_14_2.jpg", "caption": "Table A7: Hyper-parameters for modality continue learning. We keep all the learning rate decrease from 1e-5 and cosine annealing strategy with 0.5 decay weight. The warm-up phase starts from 1e-8 and lasts for 1000 iterations for all modality training.", "description": "This table details the hyperparameters used during the training process for each modality in the Continual Learning of Modality (MCL) benchmark.  It specifies the number of iterations, batch size (for training and validation), and learning rate for each modality (video, audio, depth, and 3D).  The consistent hyperparameters across all modalities show that the authors maintained a uniform training approach to compare the results across different modalities.", "section": "A.2 Training & Evaluation Details"}, {"figure_path": "drpJ7KOr3F/tables/tables_15_1.jpg", "caption": "Table 1: Comparison with other CL methods on each modalities of in-domain datasets. We label the best and second methods with bold and underline styles. The top gray block indicates the upper-bound scores Tm of transfer learning capability to adapt the new modality.", "description": "This table compares the performance of the proposed PathWeave method against other continual learning (CL) methods on five different modalities (image, video, audio, depth, and 3D).  The table shows the transfer learning capability (Tm) for each modality transition, indicating how well each method adapts to a new modality.  Lower scores in the F columns represent less catastrophic forgetting, indicating better memory retention of previous modalities. The best and second-best performing methods are highlighted.", "section": "5.2 Comparison with State-of-the-art Methods"}, {"figure_path": "drpJ7KOr3F/tables/tables_16_1.jpg", "caption": "Table 1: Comparison with other CL methods on each modalities of in-domain datasets. We label the best and second methods with bold and underline styles. The top gray block indicates the upper-bound scores Tm of transfer learning capability to adapt the new modality.", "description": "This table compares the performance of the proposed method (PathWeave) against other Continual Learning (CL) methods on five different modalities (image, video, audio, depth, and 3D).  The metrics used are the transfer learning capability (Tm) and forgetting rate (Fm) for each modality transition.  In-domain datasets are used for evaluation.  The table highlights the best performing method for each transition using bold and underline formatting. The top row shows upper-bound scores representing the best possible transfer learning performance.", "section": "5.2 Comparison with State-of-the-art Methods"}, {"figure_path": "drpJ7KOr3F/tables/tables_16_2.jpg", "caption": "Table 1: Comparison with other CL methods on each modalities of in-domain datasets. We label the best and second methods with bold and underline styles. The top gray block indicates the upper-bound scores Tm of transfer learning capability to adapt the new modality.", "description": "This table compares the performance of different continual learning (CL) methods on five different modalities (image, video, audio, depth, and 3D) using in-domain datasets.  The table shows the transfer learning capability (Tm) and forgetting rate (Fm) for each method and modality.  The top row indicates the upper bound performance of each modality, representing the best possible performance achievable using a transfer learning approach. Lower numbers in the forgetting rate (Fm) columns are better, indicating less catastrophic forgetting.", "section": "5.2 Comparison with State-of-the-art Methods"}, {"figure_path": "drpJ7KOr3F/tables/tables_16_3.jpg", "caption": "Table 1: Comparison with other CL methods on each modalities of in-domain datasets. We label the best and second methods with bold and underline styles. The top gray block indicates the upper-bound scores Tm of transfer learning capability to adapt the new modality.", "description": "This table compares the performance of PathWeave against other continual learning methods on in-domain datasets across five modalities: image, video, audio, depth, and 3D point cloud.  The metrics used are transfer learning capability (Tm) and forgetting rate (Fm) for each modality transition.  The top row shows the upper bound performance achievable through full fine-tuning for each modality.", "section": "5.2 Comparison with State-of-the-art Methods"}, {"figure_path": "drpJ7KOr3F/tables/tables_18_1.jpg", "caption": "Table A12: More details of hyperparameters used on each of the datasets.", "description": "This table shows the detailed hyperparameter settings used for each dataset in the Continual Learning of Multi-Modality (MCL) benchmark.  It provides specific prompt instructions, length penalties, minimum lengths, and maximum lengths for each modality and dataset, offering a more nuanced understanding of the experimental setup.", "section": "A.2 Training & Evaluation Details"}]