{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, a vision-language model that is foundational to the proposed method and is used for its strong zero-shot performance."}, {"fullname_first_author": "Chunjiang Ge", "paper_title": "Domain adaptation via prompt learning", "publication_date": "2023-01-01", "reason": "This paper first introduces the use of prompts for domain adaptation, which directly inspired the current work's approach to prompt engineering."}, {"fullname_first_author": "Haoran Chen", "paper_title": "Multi-prompt alignment for multi-source unsupervised domain adaptation", "publication_date": "2022-01-01", "reason": "This paper extends prompt learning to multi-source domain adaptation, providing a basis for the current paper's extension to multi-source scenarios."}, {"fullname_first_author": "Mingsheng Long", "paper_title": "Deep transfer learning with joint adaptation networks", "publication_date": "2017-01-01", "reason": "This paper is a highly influential work in unsupervised domain adaptation, addressing the trade-off between domain alignment and classification performance which the current work also tackles."}, {"fullname_first_author": "Yaroslav Ganin", "paper_title": "Domain-adversarial training of neural networks", "publication_date": "2016-01-01", "reason": "This paper introduces domain-adversarial training, a key technique in unsupervised domain adaptation that the current work builds upon."}]}