[{"figure_path": "ogk236hsJM/tables/tables_6_1.jpg", "caption": "Table 1: Unconditional sample quality on CIFAR-10. \u2020 means method we reproduced.", "description": "This table presents the FID (Frechet Inception Distance) scores for various generative models on the CIFAR-10 dataset, comparing unconditional image generation.  Lower FID indicates better image quality.  The table compares models with different architectures, highlighting the performance of the proposed SIM model against others using the same or different architecture as the teacher model. The NFE (number of forward diffusion evaluations) column indicates the computational cost of generating samples.  The \"\u2020\" symbol indicates methods that were reproduced by the authors for fair comparison.", "section": "4.1 One-step CIFAR10 Generation"}, {"figure_path": "ogk236hsJM/tables/tables_6_2.jpg", "caption": "Table 1: Unconditional sample quality on CIFAR-10. \u2020 means method we reproduced.", "description": "This table presents the FID (Frechet Inception Distance) scores for various generative models on the CIFAR-10 dataset, focusing on unconditional image generation.  Lower FID scores indicate better image quality. The table compares the performance of the proposed SIM method to other state-of-the-art diffusion models, with a particular emphasis on models using the same architecture as the EDM (Energy-based Diffusion Model) that serves as the baseline for the SIM distillation. The NFE (Number of Function Evaluations) column shows the number of steps in the generation process.", "section": "4.1 One-step CIFAR10 Generation"}, {"figure_path": "ogk236hsJM/tables/tables_9_1.jpg", "caption": "Table 3: Quantitative comparisons with frontier text-to-image models on COCO-2017 validation dataset. The user preference is the winning rate of our user study on SIM-DiT-600M against 20-step PixelArt-a. * means the results evaluated on the SAM-LLaVA-Caption10M dataset, and SIM-DiT-600M means the SIM generator distilled from PixelArt-a-600M, excluding those in the T5 text encoder. The distillation cost M GPU\u00d7 N Days means the model did not report the cost.", "description": "This table quantitatively compares the SIM-DiT-600M model's performance with other state-of-the-art text-to-image models on the COCO-2017 validation dataset.  Metrics include Aesthetic Score, Image Reward, Pick Score, and User Preference (based on a human preference study).  The table also notes the computational cost of training each model, highlighting the efficiency of SIM-DiT-600M.  A separate row shows a comparison on the SAM-LLaVA-Caption10M dataset.", "section": "4.2 Transformer-based One-step Text-to-Image Generator"}, {"figure_path": "ogk236hsJM/tables/tables_25_1.jpg", "caption": "Table 1: Unconditional sample quality on CIFAR-10. \u2020 means method we reproduced.", "description": "This table presents the results of unconditional image generation on the CIFAR-10 dataset using various methods.  The table compares different approaches in terms of Number of Function Evaluations (NFE) needed for image generation and the Fr\u00e9chet Inception Distance (FID) score, a measure of sample quality (lower is better).  The methods are categorized into those with different architectures compared to the EDM model and those with the same architecture.  The goal is to showcase the single-step generator's performance against the original multi-step diffusion model in terms of both efficiency and image quality.", "section": "4.1 One-step CIFAR10 Generation"}, {"figure_path": "ogk236hsJM/tables/tables_27_1.jpg", "caption": "Table 5: Hyperparameters used for SIM on CIFAR10 EDM Distillation", "description": "This table lists the hyperparameters used in the Score Implicit Matching (SIM) experiments on the CIFAR-10 dataset using the EDM diffusion model.  It shows the settings for both the teacher diffusion model (DM s) and the one-step generator model (Generator g\u03b8) for both unconditional and class-conditional generation.  Hyperparameters include the learning rate, batch size, the chosen time step (\u03c3(t*)), Adam optimizer parameters (\u03b20, \u03b21), the time distribution used (either PEDM or PSIM), the weighting function (\u03bbEDM or 1), the loss function used (B.2 or B.13), and the number of GPUs used.", "section": "4.1 One-step CIFAR10 Generation"}]