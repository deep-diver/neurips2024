[{"figure_path": "tmX1AUmkl6/figures/figures_1_1.jpg", "caption": "Figure 1: Evaluation of video dynamics. (a) Illustration of dynamics at multiple temporal granularities. (b) Video quality distribution w.r.t. dynamic scores. (Best viewed in color)", "description": "The figure illustrates the concept of video dynamics at multiple temporal granularities. Subfigure (a) shows how dynamics are categorized into three levels: inter-frame, inter-segment, and video-level. Each level represents different temporal scales of changes in the video content. Subfigure (b) demonstrates the relationship between video quality and dynamics scores. It shows how various quality aspects (naturalness, quality, aesthetic, smoothness) change according to different dynamics score values.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_2_1.jpg", "caption": "Figure 2: Flowchart to calculate dynamics metrics based on dynamics scores and text prompts.", "description": "This flowchart illustrates the DEVIL evaluation protocol.  It shows how text prompts are used to generate videos using various T2V models.  The generated videos are then analyzed using the defined dynamics scores (inter-frame, inter-segment, and video-level). Finally, these scores are used to calculate the overall dynamics metrics: dynamics range and dynamics controllability. These metrics provide a comprehensive evaluation of the T2V models' performance, focusing on the dynamics of video generation.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_3_1.jpg", "caption": "Figure 3: (a) Distribution of dynamics grades for text prompts from DEVIL, Vbench [24], and EvalCrafter [27]. (b) Word cloud of the text prompt benchmark of DEVIL.", "description": "This figure shows a comparison of the distribution of dynamics grades in three different text prompt benchmarks: DEVIL, VBench, and EvalCrafter.  Subfigure (a) is a bar chart illustrating the number of prompts categorized into five dynamic grades (Static, Low, Medium, High, Very High) for each benchmark.  It visually represents the relative proportions of various dynamic levels in each dataset. Subfigure (b) is a word cloud visualization of the text prompts from the DEVIL benchmark, where the size of each word represents its frequency. This provides an overview of the types of language used to describe different levels of dynamics.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_4_1.jpg", "caption": "Figure 4: Video dynamics at different temporal granularities: (a) Inter-frame Dynamics, (b) Inter-segment Dynamics, and (c) Video-level Dynamics.", "description": "This figure illustrates the three levels of video dynamics considered in the DEVIL evaluation protocol. (a) Inter-frame dynamics focuses on the changes between consecutive frames, capturing fast and prominent content variations. (b) Inter-segment dynamics analyzes the changes between video segments (each containing K frames), reflecting mid-speed transitions and motion patterns. (c) Video-level dynamics considers the overall content diversity and the frequency of changes throughout the video, encompassing the overall content diversity and frequency of changes.", "section": "3.2 Dynamics Scores"}, {"figure_path": "tmX1AUmkl6/figures/figures_8_1.jpg", "caption": "Figure 5: Video quantity density w.r.t. dynamics score of the WebVid-2M dataset.", "description": "This figure shows the distribution of dynamics scores in the WebVid-2M dataset.  The x-axis represents the dynamics score, ranging from 0 to 1, and the y-axis represents the density of videos with that particular dynamics score.  The distribution is heavily skewed towards lower dynamics scores, indicating that the majority of videos in this dataset have relatively low dynamic content. This observation highlights the bias in existing datasets, where videos with high dynamic content are under-represented.", "section": "5.6 Insights from Video Dynamics Analysis"}, {"figure_path": "tmX1AUmkl6/figures/figures_9_1.jpg", "caption": "Figure 6: Distributions of video quantity and quality scores along the dynamics score for various video generation models including: GEN-2 [2], Pika [4], VideoCrafter2(VC-2) [14], Open-Sora(OS) [23], StreamingT2V [19] and FreeNoise-Lavie(FN) [31]. Subplot (a) shows video quantity distribution. Subplots (b) display the distribution of quality score of generated videos in terms of Background Consistency, Motion Smoothness, and Naturalness, respectively. All videos are generated based on our text prompt benchmark.", "description": "This figure shows the distribution of video quantity and quality scores across different dynamics scores for six video generation models.  Subfigure (a) displays the number of videos generated at each dynamics score. Subfigure (b) presents the distributions of quality scores (Video Quality, Background Consistency, Motion Smoothness, and Naturalness) for each dynamics level. The results illustrate how the quality of generated videos and their quantity relate to the dynamics levels present in the videos.", "section": "5 Experiment"}, {"figure_path": "tmX1AUmkl6/figures/figures_16_1.jpg", "caption": "Figure 2: Flowchart to calculate dynamics metrics based on dynamics scores and text prompts.", "description": "This flowchart illustrates the process of calculating dynamics metrics using DEVIL.  It starts with text prompts, which are used to generate videos using various T2V models.  These videos are then analyzed to extract dynamics scores at different temporal granularities (inter-frame, inter-segment, and video-level). These scores, along with the original text prompts, are used to calculate the final dynamics metrics, which assess the model's ability to generate videos with appropriate dynamics and align them with the textual descriptions.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_16_2.jpg", "caption": "Figure 2: Flowchart to calculate dynamics metrics based on dynamics scores and text prompts.", "description": "This flowchart illustrates the DEVIL (Dynamics Evaluation protocol for Video and Language) framework.  It shows how text prompts are used to generate videos using various T2V (text-to-video) models. The generated videos then undergo analysis to extract dynamics scores at multiple temporal granularities (inter-frame, inter-segment, and video-level). These dynamics scores, combined with the original text prompts, are used to calculate overall dynamics metrics (e.g., dynamics range and controllability), providing a comprehensive evaluation of the T2V model's ability to generate videos with dynamic content aligned to the input text.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_16_3.jpg", "caption": "Figure 7: Illustration of prompt coarse categorization using GPT-4 [30].", "description": "This figure illustrates the process of categorizing dynamics grades using GPT-4.  The process involves providing GPT-4 with text prompts and asking it to classify them based on the level of dynamic content.  To enhance accuracy, detailed criteria and examples are provided. After the initial GPT-4 classification, human annotators refine the classifications to ensure high accuracy. The end result is a benchmark of approximately 800 text prompts with dynamics grades.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_17_1.jpg", "caption": "Figure 8: Illustration of naturalness calculation for generated videos using Gemini-1.5 Pro [1].", "description": "This figure shows how the Gemini-1.5 Pro model evaluates the naturalness of generated videos.  It presents two example video sequences. The first example shows a video of apples on a tree, which is rated as \"Almost Realistic.\" The second video shows a dog running in traffic, which is rated as \"Clearly Unrealistic.\"  The model identifies and highlights anomalies (e.g. the dog's legs appearing unnatural in the second example), which directly influence its realism classification.  The figure visually demonstrates the key aspects of how the model's naturalness score is determined, combining both visual analysis and behavioral assessment.", "section": "Details of Naturalness"}, {"figure_path": "tmX1AUmkl6/figures/figures_18_1.jpg", "caption": "Figure 2: Flowchart to calculate dynamics metrics based on dynamics scores and text prompts.", "description": "This flowchart illustrates the DEVIL evaluation protocol, showing how dynamics metrics are calculated. It starts with text prompts that are categorized into different dynamics levels. These prompts are then used to generate videos using various T2V models. The generated videos are then processed to extract dynamics scores across multiple temporal granularities (inter-frame, inter-segment, and video-level). Finally, these dynamics scores, along with the initial text prompts, are used to calculate the final dynamics metrics, enabling a comprehensive evaluation of the T2V models based on their ability to generate videos with various dynamics levels.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_18_2.jpg", "caption": "Figure 4: Video dynamics at different temporal granularities: (a) Inter-frame Dynamics, (b) Inter-segment Dynamics, and (c) Video-level Dynamics.", "description": "This figure illustrates the three levels of dynamics considered in the paper: inter-frame, inter-segment, and video-level.  Inter-frame dynamics focuses on changes between consecutive frames. Inter-segment dynamics looks at changes between larger segments of the video. Video-level dynamics considers the overall dynamic variation across the entire video. Each level is visually represented to show different granularities of motion and change. ", "section": "3.2 Dynamics Scores"}, {"figure_path": "tmX1AUmkl6/figures/figures_18_3.jpg", "caption": "Figure 1: Evaluation of video dynamics. (a) Illustration of dynamics at multiple temporal granularities. (b) Video quality distribution w.r.t. dynamic scores. (Best viewed in color)", "description": "This figure shows two aspects of video dynamics. (a) illustrates the concept of dynamics at three different temporal granularities: inter-frame, inter-segment, and video-level. Each granularity represents a different scale of temporal change, from instantaneous changes between frames to longer-term variations across segments and overall video.  (b) shows how video quality correlates with the dynamics scores.  The distribution demonstrates that video quality (measured by aspects such as naturalness, quality, aesthetics, smoothness) is influenced by the level of dynamics present in the video.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_19_1.jpg", "caption": "Figure 4: Video dynamics at different temporal granularities: (a) Inter-frame Dynamics, (b) Inter-segment Dynamics, and (c) Video-level Dynamics.", "description": "This figure illustrates the three levels of video dynamics introduced in the paper: inter-frame, inter-segment, and video-level. Each level captures dynamics at a different temporal granularity. Inter-frame dynamics focuses on changes between consecutive frames, inter-segment dynamics considers changes across longer video segments, and video-level dynamics encompasses overall content diversity and change frequency throughout the entire video.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_19_2.jpg", "caption": "Figure 3: (a) Distribution of dynamics grades for text prompts from DEVIL, Vbench [24], and EvalCrafter [27]. (b) Word cloud of the text prompt benchmark of DEVIL.", "description": "This figure shows the distribution of dynamics grades across different datasets (DEVIL, Vbench, and EvalCrafter).  Subfigure (a) uses bar charts to compare the frequency of prompts categorized by five dynamics grades (Static, Low, Medium, High, Very High) in each dataset.  This visually demonstrates how the relative emphasis on dynamics varies across existing benchmarks. Subfigure (b) presents a word cloud of the text prompts used in the DEVIL benchmark, illustrating the nature of language used to prompt for videos with varying levels of dynamic content.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_19_3.jpg", "caption": "Figure 4: Video dynamics at different temporal granularities: (a) Inter-frame Dynamics, (b) Inter-segment Dynamics, and (c) Video-level Dynamics.", "description": "This figure illustrates the three levels of video dynamics considered in the DEVIL evaluation protocol.  (a) Inter-frame dynamics focuses on changes between consecutive frames, such as optical flow or perceptual hash differences. (b) Inter-segment dynamics analyzes changes between video segments composed of multiple frames, using metrics like patch-level aperiodicity and global aperiodicity. (c) Video-level dynamics considers the overall diversity and frequency of changes throughout the entire video using metrics like temporal entropy and temporal semantic diversity.  Each level represents a different temporal granularity for assessing video dynamism.", "section": "3 Dynamics Evaluation Protocol"}, {"figure_path": "tmX1AUmkl6/figures/figures_20_1.jpg", "caption": "Figure 6: Distributions of video quantity and quality scores along the dynamics score for various video generation models including: GEN-2 [2], Pika [4], VideoCrafter2(VC-2) [14], Open-Sora(OS) [23], StreamingT2V [19] and FreeNoise-Lavie(FN) [31]. Subplot (a) shows video quantity distribution. Subplots (b) display the distribution of quality score of generated videos in terms of Background Consistency, Motion Smoothness, and Naturalness, respectively. All videos are generated based on our text prompt benchmark.", "description": "This figure shows the distribution of video quantity and quality scores for six different video generation models across various dynamics scores.  The top panel (a) displays the number of videos generated at different dynamics levels. The bottom panels (b) show the distribution of quality scores (background consistency, motion smoothness, and naturalness) at different dynamics levels for each model. The results illustrate the relationship between video dynamics and the quality of generated videos, demonstrating how common metrics often show negative correlation with dynamics.", "section": "5 Experiment"}, {"figure_path": "tmX1AUmkl6/figures/figures_20_2.jpg", "caption": "Figure 4: Video dynamics at different temporal granularities: (a) Inter-frame Dynamics, (b) Inter-segment Dynamics, and (c) Video-level Dynamics.", "description": "This figure illustrates the concept of video dynamics across three temporal granularities. (a) shows inter-frame dynamics, focusing on changes between consecutive frames.  (b) illustrates inter-segment dynamics, analyzing changes between video segments.  Finally, (c) depicts video-level dynamics, which examines the overall dynamics of the entire video.", "section": "3 Dynamics Evaluation Protocol"}]