[{"figure_path": "uaNZvF1VFe/figures/figures_8_1.jpg", "caption": "Figure 1: Results for CIFAR-10 dataset in the centralized environment.", "description": "The figure shows the training loss, gradient norm and testing accuracy curves for different algorithms on the CIFAR-10 dataset in a centralized environment. The algorithms compared include signSGD, signSGD-SIM, SignSVRG, SSVR, and SSVR-FS.  The results illustrate the convergence speed and performance of each algorithm in terms of training loss reduction, gradient norm decrease, and testing accuracy improvement.  It visually compares the effectiveness of the proposed SSVR and SSVR-FS methods against existing sign-based methods.", "section": "5.1 Evaluation of SSVR and SSVR-FS methods in the centralized environment"}, {"figure_path": "uaNZvF1VFe/figures/figures_8_2.jpg", "caption": "Figure 2: Results for CIFAR-100 dataset in the distributed environment.", "description": "The figure shows the training loss and testing accuracy curves for different sign-based algorithms on the CIFAR-100 dataset in a distributed setting with 4 and 8 nodes.  It compares the performance of the proposed SSVR-MV method against existing sign-based methods like signSGD, Signum, SSDM, Sto-signSGD, and MV-signSGD-SIM. The results visualize the effectiveness of the SSVR-MV method in achieving lower training loss and higher testing accuracy in both homogeneous and heterogeneous distributed learning environments.", "section": "Evaluation of SSVR and SSVR-FS methods in the centralized environment"}, {"figure_path": "uaNZvF1VFe/figures/figures_25_1.jpg", "caption": "Figure 1: Results for CIFAR-10 dataset in the centralized environment.", "description": "This figure shows the training loss, gradient norm and testing accuracy for different algorithms on the CIFAR-10 dataset in a centralized setting. The algorithms compared include signSGD, signSGD-SIM, SignSVRG, SSVR, and SSVR-FS. The results show that the proposed SSVR and SSVR-FS methods achieve superior performance in terms of testing accuracy, and the SSVR algorithm outperforms other algorithms in terms of gradient norm reduction.", "section": "5 Evaluation of SSVR and SSVR-FS methods in the centralized environment"}, {"figure_path": "uaNZvF1VFe/figures/figures_26_1.jpg", "caption": "Figure 1: Results for CIFAR-10 dataset in the centralized environment.", "description": "The figure shows the training loss, gradient norm, and testing accuracy curves for different sign-based algorithms (signSGD, signSGD-SIM, SignSVRG, SSVR, SSVR-FS) trained on the CIFAR-10 dataset in a centralized environment.  The algorithms are compared to show the effectiveness of the proposed variance reduction methods (SSVR and SSVR-FS) in improving convergence and testing accuracy. ", "section": "5.1 Evaluation of SSVR and SSVR-FS methods in the centralized environment"}, {"figure_path": "uaNZvF1VFe/figures/figures_33_1.jpg", "caption": "Figure 1: Results for CIFAR-10 dataset in the centralized environment.", "description": "This figure compares the performance of various sign-based algorithms on the CIFAR-10 dataset in a centralized setting.  It shows the training loss, gradient norm, and testing accuracy over epochs for methods such as signSGD, signSGD-SIM, SignSVRG, SSVR, and SSVR-FS.  The results demonstrate the effectiveness of the proposed SSVR and SSVR-FS methods in achieving lower training loss and higher testing accuracy.", "section": "5.1 Evaluation of SSVR and SSVR-FS methods in the centralized environment"}, {"figure_path": "uaNZvF1VFe/figures/figures_35_1.jpg", "caption": "Figure 1: Results for CIFAR-10 dataset in the centralized environment.", "description": "This figure shows the results of training a ResNet18 model on the CIFAR-10 dataset using various sign-based optimization algorithms in a centralized setting.  The algorithms compared are signSGD, signSGD-SIM, SignSVRG, SSVR, and SSVR-FS. The plot displays the training loss and testing accuracy over 200 epochs.  The purpose is to demonstrate the effectiveness of the proposed SSVR and SSVR-FS methods compared to existing sign-based methods in terms of convergence speed and testing accuracy.", "section": "5 Evaluation of SSVR and SSVR-FS methods in the centralized environment"}, {"figure_path": "uaNZvF1VFe/figures/figures_35_2.jpg", "caption": "Figure 4: Results for CIFAR-10 dataset with different \u03b2.", "description": "The figure shows the training loss and testing accuracy curves for the CIFAR-10 dataset using the SSVR method with different momentum parameter \u03b2 values (0.3, 0.5, 0.7, 0.9, 0.99).  The x-axis represents the training epoch, and the y-axis shows both training loss and testing accuracy. Each line represents the average result over five different runs, with shaded regions indicating the standard deviation.  The plot aims to demonstrate the impact of momentum on the convergence behavior of the SSVR algorithm and its insensitivity to variations within a certain range of \u03b2 values.", "section": "5.1 Evaluation of SSVR and SSVR-FS methods in the centralized environment"}, {"figure_path": "uaNZvF1VFe/figures/figures_35_3.jpg", "caption": "Figure 5: Results for CIFAR-10 dataset with different batch sizes.", "description": "This figure shows the impact of different batch sizes (BS) on the performance of the SSVR algorithm on the CIFAR-10 dataset.  The left panel displays the training loss curves, showing a similar downward trend across all batch sizes. The right panel presents the corresponding testing accuracy. While there is a slight improvement with larger batch sizes, the overall performance remains relatively consistent, suggesting that the SSVR algorithm is not highly sensitive to the choice of batch size.", "section": "5 Experiments"}]