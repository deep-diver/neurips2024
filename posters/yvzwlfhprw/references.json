{"references": [{"fullname_first_author": "Takuya Akiba", "paper_title": "Optuna: A Next-Generation Hyperparameter Optimization Framework", "publication_date": "2019-08-01", "reason": "This paper introduces Optuna, a hyperparameter optimization framework used for the experiments in this paper."}, {"fullname_first_author": "Matthias Althoff", "paper_title": "Reachability Analysis and its Application to the Safety Assessment of Autonomous Cars", "publication_date": "2010-01-01", "reason": "This thesis provides the foundation for the safety analysis and methods used in the current paper's safety-related experiments."}, {"fullname_first_author": "Scott Fujimoto", "paper_title": "Addressing Function Approximation Error in Actor-Critic Methods", "publication_date": "2018-07-01", "reason": "This paper addresses function approximation errors in actor-critic methods, which is highly relevant to the reinforcement learning algorithms used in this paper."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal Policy Optimization Algorithms", "publication_date": "2017-07-01", "reason": "This paper introduces the Proximal Policy Optimization (PPO) algorithm, which is the foundation for the reinforcement learning algorithm used in this paper's experiments."}, {"fullname_first_author": "Richard S. Sutton", "paper_title": "Policy Gradient Methods for Reinforcement Learning with Function Approximation", "publication_date": "1999-01-01", "reason": "This paper provides a foundational understanding of policy gradient methods, which are central to the continuous action masking techniques explored in this paper."}]}