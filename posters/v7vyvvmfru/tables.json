[{"figure_path": "v7vYVvmfru/tables/tables_4_1.jpg", "caption": "Algorithm 1 STOCHASTIC NESTEROV ACCELERATED GRADIENT METHOD (SNAG)", "description": "This algorithm details the steps of the Stochastic Nesterov Accelerated Gradient Method, which is a crucial subroutine used within the AccBO algorithm for updating the lower-level variable. It leverages momentum to accelerate convergence towards the optimal solution of the lower-level problem, given a fixed upper-level variable. The algorithm iteratively updates the lower-level variable using stochastic gradient information, incorporating momentum from previous iterations.  It's an adaptation of the Nesterov Accelerated Gradient method to handle stochasticity.", "section": "4 Algorithm and Analysis"}]