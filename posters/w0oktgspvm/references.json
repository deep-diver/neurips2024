{"references": [{"fullname_first_author": "Tom B. Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-05-14", "reason": "This paper is foundational to the concept of in-context learning, which is central to the current paper's approach."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-04-14", "reason": "This paper introduces Flamingo, a large multimodal model that achieves state-of-the-art results on various vision and language tasks, providing a key model for the current research."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-VL: A frontier large vision-language model with versatile abilities", "publication_date": "2023-08-12", "reason": "This paper introduces Qwen-VL, one of the core models used in the experiments, showcasing its advanced capabilities in multimodal in-context learning."}, {"fullname_first_author": "Shouyuan Chen", "paper_title": "Extending context window of large language models via positional interpolation", "publication_date": "2023-06-15", "reason": "This paper addresses the challenge of limited context length in LLMs, a problem directly relevant to the limitations addressed by the current paper's approach."}, {"fullname_first_author": "Sivan Doveh", "paper_title": "Towards multimodal in-context learning for vision & language models", "publication_date": "2024-03-12", "reason": "This paper directly tackles the challenge of multimodal in-context learning, making it highly relevant to the current paper's contributions."}]}