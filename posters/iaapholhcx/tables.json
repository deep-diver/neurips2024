[{"figure_path": "IAAPhOLhcX/tables/tables_8_1.jpg", "caption": "Table 1: The Difference Between Lower Bound and Upper Bound of Pruning Ratio.", "description": "This table presents the difference between the theoretically calculated lower bound and upper bound of the pruning ratio for various network architectures and datasets.  The smaller the difference (\u0394), the tighter the bounds and the more accurate the theoretical prediction of the pruning limit.", "section": "4 Achievable Scheme & Computational Issues"}, {"figure_path": "IAAPhOLhcX/tables/tables_9_1.jpg", "caption": "Table 2: Comparison between Theoretical and Actual Values of Pruning Ratio", "description": "This table presents a comparison of the theoretical and actual pruning ratios obtained from experiments across various datasets and models.  The \"Theo. Value\" column shows the theoretically predicted pruning ratios based on the paper's formulas, while the \"Actual Value\" column displays the empirically observed pruning ratios.  The difference between the theoretical and actual values, expressed as a percentage, is provided in the \u0394 column. This comparison helps validate the accuracy of the theoretical model proposed in the paper for predicting pruning ratios.", "section": "Experiments"}, {"figure_path": "IAAPhOLhcX/tables/tables_14_1.jpg", "caption": "Table 10: Performance comparison of various pruning algorithms.", "description": "This table compares the performance of the proposed one-shot magnitude pruning algorithm ('LOMP') with four baseline algorithms: dense training and three other pruning algorithms (Rare Gems, Iterative Magnitude Pruning, and Smart-Ratio). The comparison is done across various datasets and models, considering the test accuracy achieved at different sparsity levels. The results showcase the superior performance of the proposed LOMP algorithm compared to the other methods.", "section": "G.2 Comparison of Pruning Algorithms"}, {"figure_path": "IAAPhOLhcX/tables/tables_15_1.jpg", "caption": "Table 2: Comparison between Theoretical and Actual Values of Pruning Ratio", "description": "This table compares the theoretical pruning ratios calculated using the formulas derived in the paper with the actual pruning ratios observed in experiments across various datasets and network architectures.  The percentage difference between the theoretical and actual values is also provided to show the accuracy of the theoretical predictions.", "section": "Experiments"}, {"figure_path": "IAAPhOLhcX/tables/tables_15_2.jpg", "caption": "Table 10: Performance comparison of various pruning algorithms.", "description": "This table presents a comparison of the performance of different pruning algorithms, including the proposed LOMP method and four baseline methods (dense weight training, Rare Gems, Iterative Magnitude Pruning, and Smart-Ratio). The performance is evaluated in terms of test accuracy at top-1, using different sparsity levels.  The results show that the proposed LOMP algorithm outperforms the baseline methods across various datasets and network architectures.", "section": "G.2 Comparison of Pruning Algorithms"}, {"figure_path": "IAAPhOLhcX/tables/tables_15_3.jpg", "caption": "Table 10: Performance comparison of various pruning algorithms.", "description": "This table presents a comparison of the performance of different pruning algorithms, including the proposed LOMP method and several baselines (dense training, Rare Gems, Iterative Magnitude Pruning, and Smart-Ratio).  The performance is evaluated across different datasets and models in terms of accuracy at top-1 and sparsity. It demonstrates the superior performance of the proposed LOMP algorithm, particularly at higher sparsity levels.", "section": "G.2 Comparison of Pruning Algorithms"}, {"figure_path": "IAAPhOLhcX/tables/tables_16_1.jpg", "caption": "Table 7: Hyper Parameters used for different Datasets and Models.", "description": "This table lists the hyperparameters used for training different deep neural network models on various datasets.  It shows the batch size, number of epochs, optimizer (Stochastic Gradient Descent), learning rate (LR), momentum, warm-up period, weight decay, use of cosine annealing learning rate schedule (CosineLR), and the lambda regularization parameter. Each row represents a unique model-dataset combination with its corresponding hyperparameter settings.", "section": "B.3 Training Hyper-parameters Setup"}, {"figure_path": "IAAPhOLhcX/tables/tables_16_2.jpg", "caption": "Table 8: Hyper Parameters used in SLQ Algorithm.", "description": "This table shows the hyperparameters used in the Stochastic Lanczos Quadrature (SLQ) algorithm for computing the Gaussian width.  The hyperparameters include the number of runs, iterations, bins, and squared sigma for different models and datasets.  These parameters are crucial for the accurate estimation of the Gaussian width, which is a key component in the paper's theoretical analysis of the pruning ratio.", "section": "B.4 Sublevel Set Parameters Setup."}, {"figure_path": "IAAPhOLhcX/tables/tables_26_1.jpg", "caption": "Table 9: The TV Distance Between the Distribution of Weights.", "description": "This table presents the total variation (TV) distance between the distributions of trained weights for different network architectures (FC5, FC12, AlexNet, VGG16, ResNet18, ResNet50) trained on various datasets (CIFAR10, CIFAR100, TinyImagenet). The TV distance measures the difference between the weight distributions obtained from multiple independent training runs. The smaller the distance, the more similar the weight distributions across training runs, suggesting the weight distribution is consistent and independent of the specific initialization. This table validates the robustness of the weight magnitude distribution regardless of initialization.", "section": "G.1 The Distance Between the Distribution of Weights"}, {"figure_path": "IAAPhOLhcX/tables/tables_26_2.jpg", "caption": "Table 10: Performance comparison of various pruning algorithms.", "description": "This table compares the performance of the proposed LOMP algorithm with several other pruning algorithms (RG, IMP, SR) across various datasets and models.  It shows the dense accuracy, sparsity, and top-1 test accuracy for each method. LOMP consistently outperforms the other methods, especially at higher sparsity levels.", "section": "G.2 Comparison of Pruning Algorithms"}, {"figure_path": "IAAPhOLhcX/tables/tables_27_1.jpg", "caption": "Table 11: The pruning performance (model accuracy) of various methods on MLPNet, ResNet20, and ResNet50. As to the performance of MP, WF, CBS, CHITA, and EWR, we adopt the results reported in [4]. We take five runs for our approaches and report the mean and standard error (in the brackets). The best accuracy values (significant) are highlighted in bold. Here sparsity denotes the fraction of zero weights in convolutional and dense layers.", "description": "This table compares the pruning performance (model accuracy) of the proposed LOMP algorithm against other state-of-the-art pruning methods.  The comparison is conducted on three different network architectures (MLPNet, ResNet20, and ResNet50) at various sparsity levels. The results demonstrate the superiority of LOMP, particularly at high sparsity levels.", "section": "G.3 Comparison of Pruning as Optimization"}]