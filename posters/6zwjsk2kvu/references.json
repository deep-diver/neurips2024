{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduced NeRFs, a foundational technique for novel view synthesis that many subsequent works, including this one, build upon."}, {"fullname_first_author": "Andreas Blattmann", "paper_title": "Stable video diffusion: Scaling latent video diffusion models to large datasets", "publication_date": "2023-11-15", "reason": "This paper introduces a high-quality video diffusion model that's crucial for generating realistic dynamic content, a key element of this paper's video-to-4D generation approach."}, {"fullname_first_author": "Ben Poole", "paper_title": "Dreamfusion: Text-to-3d using 2d diffusion", "publication_date": "2023-00-00", "reason": "DreamFusion's approach to 3D generation from 2D diffusion models is a direct inspiration for the methods used in this paper, demonstrating the effectiveness of the underlying technique."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper presents Gaussian splatting, an efficient representation for 3D scenes used in this paper, showcasing its ability to handle both geometry and appearance effectively."}, {"fullname_first_author": "Antoine Gu\u00e9don", "paper_title": "SuGaR: Surface-aligned Gaussian splatting for efficient 3D mesh reconstruction and high-quality mesh rendering", "publication_date": "2023-11-00", "reason": "SuGaR's hybrid representation, combining meshes and Gaussian splatting, is central to this paper's approach, enhancing both geometry and texture modeling."}]}