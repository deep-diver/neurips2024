[{"figure_path": "6ZwJSk2kvU/figures/figures_1_1.jpg", "caption": "Figure 1: Given monocular videos, our method is able to generate high-fidelity dynamic meshes. We also produce a composited scene demo (top bar and left side of the figure) with the generated dynamic meshes, showcasing our method's compatibility with modern 3D engines.", "description": "This figure demonstrates the capabilities of the DreamMesh4D method.  The top row shows a composite scene demo, created by integrating the generated dynamic 3D models into a larger virtual environment. The bottom row shows a sequence of generated dynamic objects (rabbits, goats, and Patrick Star) at different time steps (Time1, Time2, Time3, Time4).  This visually showcases the method's ability to generate high-fidelity, temporally consistent 4D models that are compatible with modern 3D graphics engines, suggesting potential use in gaming and film.", "section": "1 Introduction"}, {"figure_path": "6ZwJSk2kvU/figures/figures_4_1.jpg", "caption": "Figure 2: Overview of DreamMesh4D. In static stage shown in top left part, a reference image is picked from the input video from with we generate a Gaussian-mesh hybrid representation through a image-to-3D pipeline. As for dynamic stage, we build a deformation graph between mesh vertices and sparse control nodes, and then the mesh and surface Gaussians are deformed by fusing the deformation of control nodes predicted by a MLP through a novel adaptive hybrid skinning algorithm.", "description": "This figure shows a pipeline overview of the DreamMesh4D method. The static stage involves generating a coarse mesh from a reference image, refining it using Gaussian splatting, and optimizing it with SuGaR.  The dynamic stage builds a deformation graph using sparse control points, predicts control point transformations with an MLP, and applies these transformations to the mesh and Gaussian splatting using adaptive hybrid skinning. ", "section": "3 Method"}, {"figure_path": "6ZwJSk2kvU/figures/figures_6_1.jpg", "caption": "Figure 3: Qualitative comparison with baselines. We compare our method with 4 previous video-to-4D methods. The first row provides two ground truth frames for each case. For each compared method, we render each case under reference view and another novel view at the two timestamps. The result demonstrates that our method is able to generate sharper 4D content with rich details, especially for the novel views.", "description": "This figure compares the results of the proposed DreamMesh4D method against four other state-of-the-art video-to-4D generation methods.  It shows the generated 3D models of three different objects (rabbit, skull, panda) at two different time steps (t1, t2), viewed from both the reference camera angle and a novel view. The comparison highlights DreamMesh4D's ability to produce sharper, more detailed 3D models, particularly in the novel view, suggesting superior spatial-temporal consistency and rendering quality.", "section": "4.2 Comparison"}, {"figure_path": "6ZwJSk2kvU/figures/figures_8_1.jpg", "caption": "Figure 4: Qualitative evaluation of ablation studies on: (a) choice between GeoDist and EucDist for deformation graph (DG) construction; (b) our proposed adaptive hybrid skinning (AHS) against LBS and DQS; (c) effects of ARAP and normal consistency (NC) loss.", "description": "This figure presents ablation studies to analyze the impact of different components on the performance of the proposed method. It shows a qualitative comparison and visualizes the impact of choosing GeoDist over EucDist for deformation graph construction, using adaptive hybrid skinning (AHS) instead of LBS or DQS, and the effects of ARAP and normal consistency loss.  The results demonstrate the benefits of the proposed choices and techniques on generating high-quality dynamic meshes.", "section": "4.3 Ablation Study"}, {"figure_path": "6ZwJSk2kvU/figures/figures_9_1.jpg", "caption": "Figure 5: Qualitative comparison on 3D representation between 3D Gaussians and Gaussian-mesh hybrid representation. When utilizing 3D Gaussians as our base 3D representation, the texture is blurry on the parts unseen in reference image. As a comparison, the texture is clean and of high quality under every view when employing the Gaussian-mesh hybrid representation.", "description": "This figure compares the visual quality of 3D object generation using two different representations: 3D Gaussians and the Gaussian-mesh hybrid. The results show that the Gaussian-mesh hybrid representation produces significantly better texture quality, especially for parts of the object not directly visible in the reference image.", "section": "4.3 Ablation Study"}, {"figure_path": "6ZwJSk2kvU/figures/figures_14_1.jpg", "caption": "Figure 6: Additional qualitative comparison with baselines.", "description": "This figure provides additional qualitative comparisons of the proposed method against four baseline video-to-4D methods.  It shows the generated results for four different objects (dinosaur, alligator, fish, and a person) at two different timestamps (t1 and t2). The reference images are provided in the top row.  The goal is to visually demonstrate the improved rendering quality and detail preservation offered by the proposed method compared to existing approaches.", "section": "A.1 Additional Qualitative Results"}, {"figure_path": "6ZwJSk2kvU/figures/figures_16_1.jpg", "caption": "Figure 7: Qualitative comparison on the number of Gaussians per face. The appearance quality of details (e.g., the eyes and nose) is getting better when binding more number of Gaussians on triangle face.", "description": "This figure shows the effect of using different numbers of Gaussians per triangle face on the quality of the generated mesh. The results demonstrate that increasing the number of Gaussians improves the detail and sharpness of the generated mesh, especially for fine details like the eyes and nose.  The top row presents the reference images, while the bottom row shows zoomed-in views of the eyes and nose region under different Gaussian configurations.", "section": "A.3 Additional Experiments"}]