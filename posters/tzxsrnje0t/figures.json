[{"figure_path": "TzxSrNJE0T/figures/figures_8_1.jpg", "caption": "Figure 1: Negative Log-Likelihood on the test set for Different Generative Models with Adagrad, RMSProp, and Adam on CIFAR-10. Bold lines represent the mean over 5 independent runs.", "description": "This figure shows the negative log-likelihood on the CIFAR-10 test set for three generative models (VAE, IWAE, and BR-IWAE) trained using three different optimization algorithms (Adagrad, RMSProp, and Adam).  Each model and algorithm combination is represented by a line, with the bold lines indicating the average performance across 5 independent runs. The plot visualizes how the different models and optimization algorithms affect the model's performance on the test dataset, demonstrating the impact of bias reduction techniques (BR-IWAE) and the choice of optimizer on the final model's ability to generate realistic data.", "section": "Experiments with IWAE and BR-IWAE"}, {"figure_path": "TzxSrNJE0T/figures/figures_9_1.jpg", "caption": "Figure 2: Value of ||\u2207V(\u03b8n)||\u00b2 in IWAE with Adagrad (on the left), RMSProp, and Adam (on the right). Bold lines represent the mean over 5 independent runs. Figures are plotted on a logarithmic scale for better visualization. Both figures have the same scale, so we have not shown the dashed theoretical curves on the right for better clarity.", "description": "This figure shows the squared gradient norm (||\u2207V(\u03b8n)||\u00b2) for IWAE using Adagrad, RMSProp, and Adam optimizers.  The plots are on a logarithmic scale to better visualize the convergence rate.  The solid lines represent the average over 5 independent runs, with shaded areas showing variability. Dashed lines indicating theoretical convergence rates are shown only in the left plot (Adagrad). The figure demonstrates how the gradient norm decreases over epochs for each optimizer, illustrating their convergence behavior.", "section": "Experiments with IWAE and BR-IWAE"}, {"figure_path": "TzxSrNJE0T/figures/figures_36_1.jpg", "caption": "Figure 3: Value of V(\u03b8n) \u2013 V(\u03b8*) (on the left) and ||\u2207V(\u03b8n)||2 (on the right) with Adagrad for different values of rn = n\u2212r and a learning rate \u03b3n = n\u22121/2. The dashed curve corresponds to the expected convergence rate O(n\u22121/4) for r = 1/4 and O(n\u22121/2) for r \u2265 1/2.", "description": "This figure displays the results of an experiment using the Adagrad algorithm with varying bias terms (rn) and a learning rate of n\u207b\u00b9/\u00b2. The left panel shows the convergence of the objective function V(\u03b8n) towards its minimum V(\u03b8*), while the right panel shows the convergence of the gradient norm ||\u2207V(\u03b8n)||\u00b2.  Different lines represent different bias decay rates (r = 1, 1/4, 1/2, 1, 2, 0), demonstrating the impact of bias on convergence speed. The dashed lines represent the theoretically expected convergence rates of O(n\u207b\u00b9/\u2074) and O(n\u207b\u00b9/\u00b2) depending on the bias decay rate.", "section": "E.1 Experiment with a Synthetic Time-Dependent Bias"}, {"figure_path": "TzxSrNJE0T/figures/figures_37_1.jpg", "caption": "Figure 2: Value of ||\u2207V(\u03b8n)||\u00b2 in IWAE with Adagrad (on the left), RMSProp, and Adam (on the right). Bold lines represent the mean over 5 independent runs. Figures are plotted on a logarithmic scale for better visualization. Both figures have the same scale, so we have not shown the dashed theoretical curves on the right for better clarity.", "description": "This figure shows the squared gradient norm over epochs for IWAE using three different optimization algorithms: Adagrad, RMSProp, and Adam.  The plots are on a logarithmic scale for better visualization, and the solid lines show the mean of 5 independent runs.  The dashed lines (only shown on the left plot) represent the theoretical convergence rate.", "section": "Experiments with IWAE and BR-IWAE"}, {"figure_path": "TzxSrNJE0T/figures/figures_37_2.jpg", "caption": "Figure 2: Value of ||\u2207V(\u03b8n)||\u00b2 in IWAE with Adagrad (on the left), RMSProp, and Adam (on the right). Bold lines represent the mean over 5 independent runs. Figures are plotted on a logarithmic scale for better visualization. Both figures have the same scale, so we have not shown the dashed theoretical curves on the right for better clarity.", "description": "This figure shows the squared gradient norm (||\u2207V(\u03b8n)||\u00b2) over epochs for IWAE using three different adaptive algorithms: Adagrad, RMSProp, and Adam.  The plots illustrate the convergence rate of the algorithms, with bold lines representing the average over five runs. The logarithmic scale is used for easier visualization of the convergence behavior. The dashed lines (theoretical convergence rates), omitted from the right-hand plots for clarity, would have shown expected convergence rates for different bias values.", "section": "5.2 Experiments with IWAE and BR-IWAE"}, {"figure_path": "TzxSrNJE0T/figures/figures_38_1.jpg", "caption": "Figure 2: Value of ||\u2207V(\u03b8n)||\u00b2 in IWAE with Adagrad (on the left), RMSProp, and Adam (on the right). Bold lines represent the mean over 5 independent runs. Figures are plotted on a logarithmic scale for better visualization. Both figures have the same scale, so we have not shown the dashed theoretical curves on the right for better clarity.", "description": "This figure shows the squared gradient norm for IWAE using Adagrad, RMSProp, and Adam.  The plots are on a logarithmic scale to better visualize the convergence rates. Dashed lines representing theoretical convergence rates are only shown in the left plot for clarity.", "section": "Experiments with IWAE and BR-IWAE"}, {"figure_path": "TzxSrNJE0T/figures/figures_38_2.jpg", "caption": "Figure 1: Negative Log-Likelihood on the test set for Different Generative Models with Adagrad, RMSProp, and Adam on CIFAR-10. Bold lines represent the mean over 5 independent runs.", "description": "The figure displays the test set negative log-likelihood for three generative models (VAE, IWAE, and BR-IWAE) trained using three different optimization algorithms (Adagrad, RMSProp, and Adam). Each line represents the average performance over five independent runs, with bold lines indicating the mean performance.  The graph illustrates the comparative performance of different generative models and optimizers on the CIFAR-10 dataset.", "section": "Experiments with IWAE and BR-IWAE"}, {"figure_path": "TzxSrNJE0T/figures/figures_39_1.jpg", "caption": "Figure 2: Value of ||\u2207V(\u03b8n)||\u00b2 in IWAE with Adagrad (on the left), RMSProp, and Adam (on the right). Bold lines represent the mean over 5 independent runs. Figures are plotted on a logarithmic scale for better visualization. Both figures have the same scale, so we have not shown the dashed theoretical curves on the right for better clarity.", "description": "This figure displays the squared gradient norm (||\u2207V(\u03b8n)||\u00b2) over epochs for IWAE using three different adaptive optimizers: Adagrad, RMSProp, and Adam.  The plots show the mean over 5 independent runs, and use a logarithmic scale for easier visualization. The left panel shows the results for Adagrad, while the right panel shows RMSProp and Adam. Dashed lines representing theoretical convergence rates are included only in the left panel for clarity. The figure illustrates the convergence behavior of these optimizers on the IWAE objective function.", "section": "Experiments with IWAE and BR-IWAE"}, {"figure_path": "TzxSrNJE0T/figures/figures_39_2.jpg", "caption": "Figure 9: IWAE on the CIFAR-10 Dataset with Adam for different values of \u03b4. Lines represent the mean over 5 independent runs.", "description": "This figure shows the impact of the regularization parameter \u03b4 on the performance of IWAE using the Adam optimizer on the CIFAR-10 dataset.  The test loss (negative log-likelihood) is plotted against the number of epochs for various values of \u03b4 (10\u207b\u2078, 10\u207b\u2075, 0.001, 0.01, 0.05, 0.1). Each line represents the average of 5 independent runs.  The results aim to show how the choice of this regularization parameter affects the convergence rate and overall performance of IWAE with Adam.", "section": "Additional Experiments on CIFAR-10 Dataset"}, {"figure_path": "TzxSrNJE0T/figures/figures_40_1.jpg", "caption": "Figure 10: Negative Log-Likelihood on the test set of the CIFAR-10 Dataset for IWAE with Adagrad (on the left) RMSProp (on the right) for Different Values of \u03b1 over time (in seconds). Bold lines represent the mean over 5 independent runs.", "description": "This figure shows the negative log-likelihood on the CIFAR-10 test set for IWAE using Adagrad and RMSprop optimizers.  The x-axis represents the training time in seconds, and the y-axis represents the test loss. Multiple lines are plotted for different values of \u03b1 (alpha), a hyperparameter that influences the bias of the gradient estimator.  The bold lines represent the average test loss over five independent runs; shaded regions indicate variability.  The plot shows how the convergence speed of the IWAE algorithm with different optimizers and the values of \u03b1. ", "section": "Experiments with IWAE and BR-IWAE"}]