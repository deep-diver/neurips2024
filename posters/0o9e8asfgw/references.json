{"references": [{"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment Anything", "publication_date": "2023-04-02", "reason": "This is the core subject of the paper, proposing a foundational vision model for image segmentation."}, {"fullname_first_author": "Ian J Goodfellow", "paper_title": "Explaining and harnessing adversarial examples", "publication_date": "2014-12-01", "reason": "This paper is foundational to the field of adversarial attacks against deep learning models, which is directly relevant to the paper's focus on attacking the Segment Anything Model."}, {"fullname_first_author": "Anurag Arnab", "paper_title": "On the robustness of semantic segmentation models to adversarial attacks", "publication_date": "2018-01-01", "reason": "This paper is highly relevant as it directly addresses the robustness of semantic segmentation models against adversarial attacks, which is the core problem this paper tackles."}, {"fullname_first_author": "Seyed-Mohsen Moosavi-Dezfooli", "paper_title": "Universal adversarial perturbations", "publication_date": "2017-01-01", "reason": "This paper introduces the concept of universal adversarial perturbations, which are central to the proposed attack method in this paper."}, {"fullname_first_author": "Jindong Gu", "paper_title": "SegPGD: An effective and efficient adversarial attack for evaluating and boosting segmentation robustness", "publication_date": "2022-01-01", "reason": "This paper describes a state-of-the-art adversarial attack against segmentation models, which is used as a comparison point for the new attack proposed in the paper."}]}