[{"figure_path": "0o9E8AsFgW/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of fooling SAM using UAP", "description": "This figure illustrates the process of attacking the Segment Anything Model (SAM) using a Universal Adversarial Perturbation (UAP).  A benign example image is shown, which is then modified by adding a UAP, creating an adversarial example. This adversarial example is fed into SAM, along with a prompt, and the output is \"Segment Nothing\", a black mask indicating the failure to segment any objects. This shows the effectiveness of the UAP in fooling the SAM model.", "section": "3 Methodology"}, {"figure_path": "0o9E8AsFgW/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of the proposed shadow target strategy", "description": "This figure illustrates the shadow target strategy used in DarkSAM.  It shows how multiple prompts are used on benign example images to obtain multiple segmentation masks from SAM. These individual masks are then merged to create a single \"blueprint\" mask that represents the key semantic features of the image. This blueprint mask is then used as the attack target for generating the universal adversarial perturbation (UAP). This addresses the challenge of dealing with varying inputs (both images and prompts) in the prompt-guided image segmentation model SAM by creating a stable and consistent target for the attack, irrespective of the actual prompt used.", "section": "3.2 Intuition Behind DarkSAM"}, {"figure_path": "0o9E8AsFgW/figures/figures_4_1.jpg", "caption": "Figure 3: The framework of DarkSAM", "description": "This figure illustrates the DarkSAM framework, which consists of a spatial attack and a frequency attack. The spatial attack involves semantically decoupling the foreground and background of an image and then scrambling SAM's decision by destroying the features of the foreground and background. The frequency attack enhances the attack effectiveness by distorting the high-frequency components (texture information) of the image while maintaining consistency in their low-frequency components (shape information).  Both attacks use a single UAP to mislead SAM into incorrectly segmenting images, regardless of the prompts.", "section": "3.3 DarkSAM: A Complete Illustration"}, {"figure_path": "0o9E8AsFgW/figures/figures_7_1.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows the qualitative results of applying DarkSAM attacks to the Segment Anything Model (SAM). It compares the segmentation results of benign images with those of adversarial examples created using point and box prompts, under three different prompting modes (point, box, and segment everything). The results are shown for four different datasets: ADE20K, MS-COCO, Cityscapes, and SA-1B. The figure demonstrates how DarkSAM successfully fools SAM into producing incorrect segmentations.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_8_1.jpg", "caption": "Figure 3: The framework of DarkSAM", "description": "This figure illustrates the framework of DarkSAM, a novel prompt-free hybrid spatial-frequency universal adversarial attack against prompt-guided image segmentation models. It shows how DarkSAM works in both the spatial and frequency domains. In the spatial domain, DarkSAM divides the SAM output into foreground and background, then scrambles SAM's decision by destroying the features of both foreground and background. In the frequency domain, it enhances attack effectiveness by distorting the high-frequency components of the image while maintaining consistency in the low-frequency components.  The combined spatial and frequency attacks aim to fool SAM into not segmenting any objects.", "section": "3.3 DarkSAM: A Complete Illustration"}, {"figure_path": "0o9E8AsFgW/figures/figures_9_1.jpg", "caption": "Figure 6: Visualizations of the comparison study", "description": "This figure compares the performance of DarkSAM against other UAP methods (UAP, UAPGD, SSP, SegPGD, and Attack-SAM) and various prompt types (point, box, and all).  The visualizations show the segmentation masks generated by SAM for benign and adversarial examples.  The plots in (a) to (e) show the ablation study results, demonstrating the effectiveness of different modules, varying prompt numbers, perturbation budget, and thresholds on the attack performance.", "section": "4.4 Comparison Study"}, {"figure_path": "0o9E8AsFgW/figures/figures_14_1.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows the qualitative results of the DarkSAM attack against the SAM model on four datasets.  The top row displays the original images with point prompts used for the segmentation. The middle row shows the segmentation masks produced by SAM from the original, unmodified images.  The bottom row shows the segmentation masks produced by SAM after the DarkSAM attack has been applied. The results demonstrate the effectiveness of the DarkSAM attack in preventing the SAM model from correctly segmenting objects in the images across various prompt types.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_15_1.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows the results of applying the Segment Anything Model (SAM) to both benign and adversarial examples from four different datasets.  The top row shows the original images and the bottom two rows show the segmentation masks generated by SAM for the benign images (middle row) and the adversarial images (bottom row) using point and box prompts. The figure demonstrates the effectiveness of DarkSAM in fooling SAM into producing incorrect segmentations.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_15_2.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows the results of applying the SAM model to both benign and adversarial examples from four datasets. It compares the segmentation results obtained using point and box prompts, and also shows the results for the \"segment everything\" mode, which is a special prompt that aims to segment the entire image.  The comparison highlights how the adversarial examples are able to fool SAM into producing incorrect segmentation masks, illustrating the effectiveness of the DarkSAM attack.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_16_1.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows a qualitative comparison of SAM's segmentation results on benign and adversarial examples from four different datasets (ADE20K, COCO, Cityscapes, SA-1B).  Three prompt types are used (point, box, and \"segment everything\").  The goal is to visually demonstrate DarkSAM's effectiveness in fooling SAM into producing incorrect segmentations regardless of the prompt type.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_16_2.jpg", "caption": "Figure 3: The framework of DarkSAM", "description": "This figure illustrates the DarkSAM framework, which consists of two main attack components: a semantic decoupling-based spatial attack and a texture distortion-based frequency attack.  The spatial attack manipulates the foreground and background features of an image to mislead the SAM model. The frequency attack distorts high-frequency components while preserving low-frequency components, aiming to further confuse the model's segmentation capabilities.  The combined effect of both attacks renders SAM incapable of performing object segmentation across a range of inputs.", "section": "3.3 DarkSAM: A Complete Illustration"}, {"figure_path": "0o9E8AsFgW/figures/figures_16_3.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows a qualitative comparison of SAM's segmentation performance on benign and adversarial examples across four datasets (ADE20K, MS-COCO, Cityscapes, SA-1B) and three prompt types (point, box, and \"segment everything\").  The results visually demonstrate the effectiveness of DarkSAM in fooling SAM, causing it to fail to segment the objects in the adversarial examples. The \"segment everything\" mode shows how DarkSAM affects the model's ability to segment everything within the image.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_17_1.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows a qualitative comparison of the SAM model's performance on benign and adversarial examples across four datasets (ADE20K, MS-COCO, Cityscapes, SA-1B).  It demonstrates the impact of DarkSAM's attack on SAM's segmentation ability using different types of prompts (point, box, and segment everything). The top row presents the original images with prompts, and the middle and bottom rows show the segmentation results for benign and adversarial images, respectively. The results illustrate how DarkSAM effectively fools the SAM model into generating incorrect segmentations.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_17_2.jpg", "caption": "Figure A8: The results (%) of ablation study about random seeds", "description": "This figure shows the ablation study results about the effect of random seeds on DarkSAM's performance.  The ASR (Attack Success Rate) is plotted against the number of random seeds used for both point prompts (P2P) and box prompts (B2B).  The results indicate DarkSAM maintains consistent performance regardless of the random seed used.", "section": "Supplementary Ablation Study"}, {"figure_path": "0o9E8AsFgW/figures/figures_18_1.jpg", "caption": "Figure 4: Visualizations of SAM segmentation results for adversarial examples across four datasets. The first four columns and the middle four columns display the segmentation results for point and box prompts, respectively. The last three columns show results under the segment everything mode for benign examples, as well as adversarial examples created using point and box prompts, respectively.", "description": "This figure shows the results of applying the Segment Anything Model (SAM) to both benign and adversarial examples from four different datasets.  It demonstrates the impact of DarkSAM's attack on SAM's ability to segment images under various prompt types (point, box, and \"segment everything\").  The visual comparison between benign and adversarial results highlights DarkSAM's effectiveness in causing SAM to fail in object segmentation.", "section": "4.2 Attack Performance"}, {"figure_path": "0o9E8AsFgW/figures/figures_19_1.jpg", "caption": "Figure A1: Qualitative results of the DarkSAM using point prompts on SAM-L under point prompts", "description": "This figure shows qualitative results of DarkSAM attack using point prompts on SAM-L (Segment Anything Model with ViT-L backbone) under point prompts.  It presents a comparison between benign examples (correctly segmented by SAM-L) and adversarial examples generated by DarkSAM (incorrectly segmented by SAM-L). The results visualize how DarkSAM successfully fools SAM-L, causing it to produce incorrect segmentation masks across various images. ", "section": "Supplementary Attack Performance"}]