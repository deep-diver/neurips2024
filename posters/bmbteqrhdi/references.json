{"references": [{"fullname_first_author": "Jakub Kone\u010dn\u1ef3", "paper_title": "Federated learning: Strategies for improving communication efficiency", "publication_date": "2016-10-26", "reason": "This paper is foundational to the field of federated learning, introducing key concepts and challenges addressed in the current work."}, {"fullname_first_author": "Peter Kairouz", "paper_title": "Advances and open problems in federated learning", "publication_date": "2021-00-00", "reason": "This survey paper provides a comprehensive overview of federated learning, highlighting many of the challenges and directions that motivate the proposed method."}, {"fullname_first_author": "Honggu Kang", "paper_title": "Nefl: Nested federated learning for heterogeneous clients", "publication_date": "2023-08-00", "reason": "This recent work explores model heterogeneity in federated learning, presenting a technique that is directly compared to in this paper."}, {"fullname_first_author": "Samiul Alam", "paper_title": "Fedrolex: Model-heterogeneous federated learning with rolling sub-model extraction", "publication_date": "2022-00-00", "reason": "This is a highly relevant comparative work that proposes a dynamic submodel extraction method, which is directly contrasted with the proposed approach."}, {"fullname_first_author": "Feijie Wu", "paper_title": "Sign bit is enough: A learning synchronization framework for multi-hop all-reduce with ultimate compression", "publication_date": "2022-00-00", "reason": "This paper addresses the communication efficiency in federated learning, which is a critical aspect relevant to optimizing the performance of the method presented here."}]}