[{"figure_path": "bMbteQRhDI/tables/tables_5_1.jpg", "caption": "Table 1: Test accuracy under four different submodel sizes. To be more specific, the columns from \"Local\" to \"Model (1.0)\" evaluate the test accuracy on the local test datasets, while \"Global\" evaluates the test accuracy of the global model on the global test dataset.", "description": "This table presents the test accuracy results of four different model sizes (1/64, 1/16, 1/4, 1.0) on CIFAR-10, CIFAR-100, and AGNEWS datasets.  For each dataset and model size, it shows the average test accuracy across multiple clients (\"Local\") as well as the global model accuracy (\"Global\"). The \"Local\" accuracy reflects the performance of the submodel trained on each client's local dataset, while the \"Global\" accuracy reflects the performance of the aggregated global model.", "section": "6.2 Submodel Performance on Local Dataset"}, {"figure_path": "bMbteQRhDI/tables/tables_18_1.jpg", "caption": "Table 1: Test accuracy under four different submodel sizes. To be more specific, the columns from \"Local\" to \"Model (1.0)\" evaluate the test accuracy on the local test datasets, while \"Global\" evaluates the test accuracy of the global model on the global test dataset.", "description": "This table presents the test accuracy results for four different submodel sizes (1/64, 1/16, 1/4, 1.0) across three datasets (CIFAR-10, CIFAR-100, and AGNews).  The \"Local\" columns show the average test accuracy achieved by the submodels on each client's local dataset, illustrating the performance of locally customized models. The \"Global\" column indicates the test accuracy achieved by the global model (aggregated from the submodels) on a global test dataset. This comparison helps to evaluate both the effectiveness of the submodels in adapting to local data and their generalization capability to unseen data.", "section": "Experiments"}, {"figure_path": "bMbteQRhDI/tables/tables_27_1.jpg", "caption": "Table 3: Hyperparameter Settings", "description": "This table lists the hyperparameters used in the experiments for CIFAR-10, CIFAR-100, and AGNews datasets.  It specifies the number of local epochs, batch size, communication rounds, optimizer used (SGD or AdamW), learning rate range (log10 scale), and momentum values.", "section": "6.1 Setup"}, {"figure_path": "bMbteQRhDI/tables/tables_27_2.jpg", "caption": "Table 1: Test accuracy under four different submodel sizes. To be more specific, the columns from \"Local\" to \"Model (1.0)\" evaluate the test accuracy on the local test datasets, while \"Global\" evaluates the test accuracy of the global model on the global test dataset.", "description": "This table presents the test accuracy results under four different submodel sizes (1/64, 1/16, 1/4, 1.0) for three datasets: CIFAR-10, CIFAR-100, and AGNews.  For each dataset and submodel size, it shows the test accuracy on local datasets (\"Local\"), representing the average accuracy across clients' individual local test sets, and the global test accuracy (\"Global\"), which indicates the accuracy of the aggregated global model tested on a common global test set. The results highlight the performance of different model sizes for different model heterogeneity scenarios.", "section": "Experiments"}, {"figure_path": "bMbteQRhDI/tables/tables_28_1.jpg", "caption": "Table 5: Test accuracy under five different submodel sizes on different datasets. To be more specific, the columns from \"Local\" to \"Model (1.0)\" evaluate the test accuracy on the local test datasets, while \"Global\" evaluates the test accuracy of the global model on the global test dataset.", "description": "This table presents the test accuracy results achieved by FIARSE and other baseline methods under five different submodel sizes (0.04, 0.16, 0.36, 0.64, 1.0) across three datasets: CIFAR-10, CIFAR-100, and AGNews.  For each dataset and model size, it shows both the local accuracy (average accuracy across all clients' local test sets) and the global accuracy (accuracy of the globally aggregated model on a global test set). This allows for a comparison of how well each method generalizes and how well it performs on resource-constrained devices (smaller submodels).", "section": "6.2 Submodel Performance on Local Dataset"}, {"figure_path": "bMbteQRhDI/tables/tables_29_1.jpg", "caption": "Table 6: Test accuracy under four different submodel sizes on CIFAR-100 for ablation study. To be more specific, the columns within \u201cLocal\u201d evaluate the test accuracy on the local test datasets, while \u201cGlobal\u201d evaluates the test accuracy of the global model on the global test dataset.", "description": "This table presents the results of an ablation study on CIFAR-100 dataset to demonstrate the effectiveness of the proposed FIARSE.  It compares the performance of FIARSE against a pruning-greedy baseline and a layer-wise FIARSE variant across four different submodel sizes (1/64, 1/16, 1/4, 1.0).  The \"Local\" columns show the average test accuracy across all clients, while the \"Global\" columns show the test accuracy of the globally aggregated model. The average accuracy across all model sizes is also provided for both local and global evaluations. This allows for a comparison of the proposed method's performance against simpler baselines with different submodel extraction strategies. ", "section": "6. Experiments"}, {"figure_path": "bMbteQRhDI/tables/tables_29_2.jpg", "caption": "Table 5: Test accuracy under five different submodel sizes on different datasets. To be more specific, the columns from \"Local\" to \"Model (1.0)\" evaluate the test accuracy on the local test datasets, while \"Global\" evaluates the test accuracy of the global model on the global test dataset.", "description": "This table presents the test accuracy results obtained using five different submodel sizes (0.04, 0.16, 0.36, 0.64, 1.0) on the CIFAR-10, CIFAR-100, and AGNews datasets.  The results are categorized into \"Local\" accuracy (evaluated on the local test datasets of each client) and \"Global\" accuracy (evaluated using the global test dataset).  This comparison helps assess the performance of the model at both the individual client level and the overall global level.", "section": "Experiments"}]