{"references": [{"fullname_first_author": "Nelson Elhage", "paper_title": "A mathematical framework for transformer circuits", "publication_date": "2021", "reason": "This paper introduces the concept of \"transformer circuits,\" a framework for understanding the internal workings of transformer language models, which is heavily used and built upon in the current paper."}, {"fullname_first_author": "Kevin Wang", "paper_title": "Interpretability in the wild: a circuit for indirect object identification in gpt-2 small", "publication_date": "2022", "reason": "This paper discovers a specific circuit in GPT-2 that is used for indirect object identification, which the current paper uses as a case study to analyze and explain low-rank communication channels and their role in model behaviour."}, {"fullname_first_author": "Stella Biderman", "paper_title": "Pythia: A suite for analyzing large language models across training and scaling", "publication_date": "2023", "reason": "This paper provides a valuable benchmark suite of language models, Pythia, which the current paper uses to validate its findings about the generalizability of its observations about low-rank communication channels across different model scales."}, {"fullname_first_author": "Aleksandar Makelov", "paper_title": "Is this the subspace you are looking for? an interpretability illusion for subspace activation patching", "publication_date": "2024", "reason": "This paper discusses the potential pitfalls of interpreting model behaviour through subspace analysis alone, which the current paper addresses by combining subspace analysis with weight matrix decomposition for more robust insights."}, {"fullname_first_author": "Chengcheng Feng", "paper_title": "TriLORA: Integrating SVD for advanced style personalization in text-to-image generation", "publication_date": "2024", "reason": "This paper utilizes singular value decomposition (SVD) to improve the interpretability of large language models which the current work also leverages SVD for a similar purpose."}]}