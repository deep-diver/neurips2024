{"references": [{"fullname_first_author": "Prafulla Dhariwal", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This paper is foundational to the field of diffusion models, establishing their superiority over GANs in image generation."}, {"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduced denoising diffusion probabilistic models, a fundamental framework for many subsequent diffusion models."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-05-01", "reason": "This paper introduced Vision Transformers, which are highly relevant to the architecture of Diffusion Transformers."}, {"fullname_first_author": "Ashish Vaswani", "paper_title": "Attention is all you need", "publication_date": "2017-12-01", "reason": "This paper introduced the Transformer architecture, a fundamental component of Diffusion Transformers."}, {"fullname_first_author": "Yuzhang Shang", "paper_title": "Post-training quantization on diffusion models", "publication_date": "2023-01-01", "reason": "This paper is highly relevant as it directly addresses the topic of post-training quantization for diffusion models, providing a key baseline for comparison."}]}