[{"figure_path": "nXYedmTf1T/figures/figures_1_1.jpg", "caption": "Figure 1: Benchmark performance comparison.", "description": "This radar chart visualizes the performance comparison of CSR against several baseline methods across ten benchmark datasets. Each axis represents a benchmark, and the values indicate the performance scores.  The chart effectively shows CSR's improvement over baseline methods across various tasks and its strength in achieving modality alignment.", "section": "1 Introduction"}, {"figure_path": "nXYedmTf1T/figures/figures_2_1.jpg", "caption": "Figure 2: The CSR framework operates an iterative process of preference data generation and learning. During preference data generation, CSR utilizes a sentence-level beam search approach to construct responses sentence by sentence, assigning a reward to each sentence. This reward, initially generated by the model itself, is then calibrated using image-relevance information. Preferences are determined based on the cumulative reward for each response. In each iteration, CSR generates new preference data and performs preference learning based on this data, continuously enhancing the model's performance.", "description": "This figure illustrates the iterative process of the Calibrated Self-Rewarding (CSR) framework.  It begins with user input (image and text prompt) fed into a Vision-Language Model (VLLM). The VLLM uses sentence-level beam search to generate candidate sentences, each receiving an initial reward score.  This score is then calibrated using image-relevance information. The sentences with the highest and lowest cumulative calibrated reward scores are selected as preferred and dispreferred responses, respectively. This preference data is then used to fine-tune the VLLM in the next iteration, improving the model's performance over time.", "section": "3 Calibrated Self-Rewarding Vision Language Models"}, {"figure_path": "nXYedmTf1T/figures/figures_5_1.jpg", "caption": "Figure 1: Benchmark performance comparison.", "description": "This figure compares the performance of the proposed Calibrated Self-Rewarding (CSR) approach with other state-of-the-art methods across various benchmark datasets.  The results are presented in a radar chart format, allowing for a visual comparison of the methods' performance across multiple evaluation metrics.  Each axis of the radar chart represents a different benchmark dataset (e.g., MME, SEED, LLaVAW, MMB, MM-Vet, SQA, VisWiz, GQA, POPE, CHAIRS, CHAIR1), and the distance from the center of the chart to each point represents the performance score on that specific dataset. The chart visually demonstrates the improvement achieved by the CSR method over existing methods.", "section": "1 Introduction"}, {"figure_path": "nXYedmTf1T/figures/figures_6_1.jpg", "caption": "Figure 1: Benchmark performance comparison.", "description": "This figure shows a radar chart comparing the performance of the proposed Calibrated Self-Rewarding (CSR) approach with several baseline methods across various benchmark datasets. Each axis represents a different benchmark, and the values show the performance score achieved by each method on that benchmark. CSR outperforms the baselines in most of the benchmarks, demonstrating its effectiveness in improving modality alignment in large vision-language models.", "section": "1 Introduction"}, {"figure_path": "nXYedmTf1T/figures/figures_6_2.jpg", "caption": "Figure 1: Benchmark performance comparison.", "description": "This figure presents a radar chart comparing the performance of the proposed Calibrated Self-Rewarding (CSR) approach with several baseline methods across various vision-language benchmarks.  Each axis represents a different benchmark or task (e.g., MME, SEED, LLaVAW, etc.), and the radial distance from the center indicates the performance score achieved by each method on that specific benchmark. The CSR method demonstrates superior performance across most of the benchmarks, highlighting its effectiveness in enhancing modality alignment and reducing hallucinations in vision-language models.", "section": "1 Introduction"}, {"figure_path": "nXYedmTf1T/figures/figures_7_1.jpg", "caption": "Figure 2: The CSR framework operates an iterative process of preference data generation and learning. During preference data generation, CSR utilizes a sentence-level beam search approach to construct responses sentence by sentence, assigning a reward to each sentence. This reward, initially generated by the model itself, is then calibrated using image-relevance information. Preferences are determined based on the cumulative reward for each response. In each iteration, CSR generates new preference data and performs preference learning based on this data, continuously enhancing the model's performance.", "description": "This figure illustrates the iterative process of the Calibrated Self-Rewarding (CSR) framework.  It shows how CSR generates candidate responses sentence by sentence using beam search, assigning a calibrated reward (combining self-generated and image-relevance scores) to each sentence.  The highest and lowest cumulative reward responses are selected as preferred and dispreferred, respectively, to create preference data for fine-tuning the model in the next iteration. This iterative process leads to continuous model improvement.", "section": "3 Calibrated Self-Rewarding Vision Language Models"}, {"figure_path": "nXYedmTf1T/figures/figures_8_1.jpg", "caption": "Figure 1: Benchmark performance comparison.", "description": "This figure compares the performance of the proposed CSR method against several baseline and state-of-the-art methods across various vision-language benchmarks.  It visually represents the relative improvements achieved by CSR in terms of accuracy and other relevant metrics. The benchmarks shown include comprehensive benchmarks (MME, SEEDbench, LLaVAW, MMbench, MM-Vet), general VQA (ScienceQA, VisWiz, GQA), and hallucination benchmarks (POPE, CHAIR).  The radar chart format allows for a quick comparison of performance across multiple tasks.", "section": "1 Introduction"}, {"figure_path": "nXYedmTf1T/figures/figures_15_1.jpg", "caption": "Figure 1: Benchmark performance comparison.", "description": "This figure presents a radar chart comparing the performance of the proposed Calibrated Self-Rewarding (CSR) approach with several baselines across various vision-language benchmarks.  Each axis represents a different benchmark (e.g., MME, SEED, LLaVAW, etc.), and the radial distance from the center indicates the performance score on that benchmark. The chart visually demonstrates the superior performance of CSR compared to other methods, highlighting its effectiveness in improving modality alignment and reducing hallucinations in vision-language models.", "section": "1 Introduction"}, {"figure_path": "nXYedmTf1T/figures/figures_20_1.jpg", "caption": "Figure 1: Benchmark performance comparison.", "description": "This figure shows a radar chart comparing the performance of the proposed Calibrated Self-Rewarding (CSR) approach with several baselines across ten benchmarks.  Each benchmark is represented by an axis, and the performance of each method is represented by a point on that axis. The further the point is from the center, the better the performance.  The chart visually demonstrates that CSR outperforms the existing state-of-the-art methods, achieving substantial improvements in performance across all benchmarks.", "section": "1 Introduction"}]