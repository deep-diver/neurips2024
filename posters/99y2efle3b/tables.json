[{"figure_path": "99y2EfLe3B/tables/tables_6_1.jpg", "caption": "Table 1: Experimental evaluation of SepRe method on the WSJ0-2Mix dataset. ML denotes the multi-loss. In (a), all the methods were trained with ML, and the numbers in the left and right of the '/' symbol were obtained for the tiny and base models, respectively. In (b), when ML was used for training, we indicated the numbers of parameters including the additional output layer for an auxiliary output for \u015dj, which were denoted with asterisk *. Note that the additional output layers were not required during inference.", "description": "This table presents the experimental results of the proposed SepRe method on the WSJ0-2Mix dataset. It compares different decoder designs (late split, early split with multiple decoders, early split with shared decoder, and early split with shared decoder and cross-speaker (CS) transformer) and evaluates the impact of multi-loss training.  The results are shown for both tiny and base model sizes, indicating the performance at different model scales. Note that additional parameters are included for multi-loss, but these are not used during inference.", "section": "5.1 Ablation studies of SepRe method"}, {"figure_path": "99y2EfLe3B/tables/tables_6_2.jpg", "caption": "Table 2: Application of SepRe to other networks. From the original separator of Conv-TasNet and Sepformer, we applied the SepRe method with multi-loss (ML) and evaluated on the WSJ0-2Mix dataset.", "description": "This table presents the results of applying the proposed SepRe method (Separation-Reconstruction method with cross-speaker attention) to two existing speech separation networks: Conv-TasNet and Sepformer.  The original separators of both networks were modified by incorporating the ESSD (Early Split with Shared Decoder) framework and multi-loss training. The table compares the performance (SI-SNRi in dB) and model size (parameters in millions) of the modified networks to their original versions and also to various combinations of features within the SepRe method (including and excluding Cross-Speaker modules and multi-loss training).  The results highlight the effectiveness of the SepRe method in improving speech separation performance across different network architectures.", "section": "5 Results"}, {"figure_path": "99y2EfLe3B/tables/tables_7_1.jpg", "caption": "Table 3: Ablation studies for unit blocks on our SepReformer-B on the WSJ0-2Mix dataset. Various configurations of BE and BD were evaluated to assess the relative importance of encoder and decoder. Also, we validated the proposed EGA and GCFN modules.", "description": "This table presents ablation study results on SepReformer-B, a variation of the proposed model, using the WSJ0-2Mix dataset.  It investigates the impact of different configurations of encoder (BE) and decoder (BD) blocks, varying their number of repetitions.  The study also examines the effectiveness of the proposed Efficient Global Attention (EGA) and Gated Convolutional Feed-Forward Network (GCFN) modules by comparing their performance against standard alternatives like Multi-Head Self-Attention (MHSA) with downsampling and upsampling,  EGA without a linear gate, a standard FFN (Feed-Forward Network), an FFN with depthwise convolution, and an FFN with GLU (Gated Linear Unit) activation. The results indicate the optimal configuration of BE and BD blocks, and show the performance gains achieved by using the proposed EGA and GCFN modules compared to standard alternatives.", "section": "5.3 Ablation studies of unit blocks"}, {"figure_path": "99y2EfLe3B/tables/tables_7_2.jpg", "caption": "Table 4: Comparison with various long sequence models in speech separation of WSJ0-2Mix. MS denotes multi-scale. For our model, global and local blocks were repeated 22 times with F = 128.", "description": "This table compares the proposed SepReformer model's performance against other state-of-the-art models for long-sequence speech separation on the WSJ0-2Mix dataset.  It shows a comparison of the model parameters (in millions), the number of multiply-accumulate operations (MACs, in Giga), and the SI-SNRi (Scale-Invariant Signal-to-Noise Ratio) in dB. The table highlights that the SepReformer model achieves competitive performance with significantly fewer parameters and MACs compared to other models that employ various techniques for handling long sequences such as TCNs, dual-path architectures, and multi-scale models.", "section": "5 Results"}, {"figure_path": "99y2EfLe3B/tables/tables_8_1.jpg", "caption": "Table 1: Experimental evaluation of SepRe method on the WSJ0-2Mix dataset. ML denotes the multi-loss. In (a), all the methods were trained with ML, and the numbers in the left and right of the '/' symbol were obtained for the tiny and base models, respectively. In (b), when ML was used for training, we indicated the numbers of parameters including the additional output layer for an auxiliary output for \u015dj, which were denoted with asterisk *. Note that the additional output layers were not required during inference.", "description": "This table presents the experimental results of the SepRe method on the WSJ0-2Mix dataset, comparing different decoder designs (with and without multi-loss) and their impact on performance.  It shows how the early split with shared decoder and cross-speaker transformer improves performance and efficiency compared to late-split and multiple decoder structures. The effect of multi-loss on various architectures is also analyzed.", "section": "5 Results"}, {"figure_path": "99y2EfLe3B/tables/tables_8_2.jpg", "caption": "Table 5: Evaluation on various benchmark dataset of WSJ0-2MIX, WHAM!, WHAMR!, and Libri2Mix. \"+\" denotes that the networks use additional speaker information.", "description": "This table compares the performance of SepReformer with other state-of-the-art speech separation models on four benchmark datasets: WSJ0-2Mix, WHAM!, WHAMR!, and Libri2Mix.  The metrics used are SI-SNRi and SDRi, which measure the signal-to-noise ratio and source-to-distortion ratio, respectively, reflecting the quality of the separated speech.  The table also shows the number of parameters (Params.) and Multiply-Accumulate operations (MACs) for each model, indicating computational complexity. The '+' symbol indicates models that use additional speaker information during training.", "section": "5 Results"}, {"figure_path": "99y2EfLe3B/tables/tables_17_1.jpg", "caption": "Table 6: Comparison of shared and multiple speaker split layer based on SepReformer-L with DM on the WSJ0-2Mix, WHAM!, and WHAMR! dataset.", "description": "This table presents a comparison of two different speaker split layer architectures used in the SepReformer model, specifically the \"weight-shared layer\" and the \"multiple layer\" approaches.  The results are evaluated on three different speech separation datasets: WSJ0-2Mix, WHAM!, and WHAMR!. For each dataset and architecture, the table shows the model's size in terms of parameters (Params. in millions) and its performance metrics: SI-SNRI and SDRi (in dB).  SI-SNRI and SDRi represent the scale-invariant signal-to-noise ratio and source-to-distortion ratio, respectively; both are common metrics to evaluate the quality of speech separation. The table helps assess the impact of the different speaker split designs on the overall performance of the SepReformer model.", "section": "5.1 Ablation studies of SepRe method"}, {"figure_path": "99y2EfLe3B/tables/tables_18_1.jpg", "caption": "Table 7: Perceptual evaluation by PESQ and eSTOI on WHAMR! dataset.", "description": "This table presents a comparison of the perceptual quality of speech signals processed using three different methods: No Processing (baseline), TF-GridNet, and the proposed SepReformer-L. The evaluation is performed using two metrics: PESQ (Perceptual Evaluation of Speech Quality) and eSTOI (Extended Short-Time Objective Intelligibility). The results show that SepReformer-L achieves a significant improvement in perceptual quality compared to the baseline and a slight improvement compared to TF-GridNet, indicating its effectiveness in enhancing the intelligibility of speech signals even in challenging conditions such as noise and reverberation.", "section": "5 Results"}, {"figure_path": "99y2EfLe3B/tables/tables_19_1.jpg", "caption": "Table 8: WERs (%) of utterance-wise evaluation on the LibriCSS dataset for the baseline without any processing for input data acquired at the center microphone and separation by LSTM, Conformer, DPRNN, and the proposed SepReformer.", "description": "This table presents the Word Error Rates (WER) achieved by different speech separation methods on the LibriCSS dataset.  The LibriCSS dataset is designed to evaluate speech separation in realistic meeting scenarios with varying degrees of speech overlap. The table shows WERs for different overlap ratios (0%, 10%, 20%, 30%, 40%) and compares the performance of the proposed SepReformer-B model against baselines such as LSTM, Conformer, and DPRNN. A 'No Processing' baseline is included to demonstrate the WER without any speech separation.", "section": "5.3 Ablation studies of unit blocks"}]