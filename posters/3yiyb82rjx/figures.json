[{"figure_path": "3YIyB82rjX/figures/figures_1_1.jpg", "caption": "Figure 1: Heterogeneous feature space models in real-world scenario.", "description": "This figure illustrates how different feature engineering approaches can lead to heterogeneous models within a clinical database (OMOP Common Data Model). Experts might use different subsets of standardized tables (person, diagnose, laboratory, drug) to build models for a task like drug safety analysis. This results in models with varying feature spaces, requiring a mechanism to manage and leverage them effectively.  The example highlights the challenges of the learnware paradigm in real-world scenarios where feature spaces are not always homogenous.", "section": "1 Introduction"}, {"figure_path": "3YIyB82rjX/figures/figures_2_1.jpg", "caption": "Figure 2: An illustration of the learnware paradigm with heterogeneous feature spaces", "description": "This figure illustrates the workflow of a learnware dock system. Developers submit their models and specifications (developer task 1 to N), which are then accommodated by the system. The system generates a system-level specification for each model and stores them as learnwares.  Users submit their task requirements (user task) and the system recommends the most helpful model(s) for reuse, leveraging models from diverse feature spaces even if no model is explicitly tailored to the user's task.", "section": "3 Problem setup"}, {"figure_path": "3YIyB82rjX/figures/figures_3_1.jpg", "caption": "Figure 3: Label information is beneficial for matching.", "description": "The figure shows five models with uniform distributions, four with circular support sets and one with a square support set. It illustrates that matching models solely on marginal distributions is insufficient, as models with the same marginal distribution can have different conditional distributions and thus be unsuitable for certain user tasks.  Additionally, it highlights how models with different marginal distributions, but similar conditional distributions, are overlooked when using only marginal distributions for model selection.  The figure emphasizes the importance of incorporating conditional distributions and label information to improve model matching.", "section": "4.2 Improve matching model and user task with label information"}, {"figure_path": "3YIyB82rjX/figures/figures_8_1.jpg", "caption": "Figure 4: User performance curve for classification tasks.", "description": "This figure displays the performance of the proposed ensemble method compared to self-training on several classification datasets.  The x-axis represents the number of labeled data points used, and the y-axis represents accuracy or RMSE (Root Mean Squared Error), depending on whether it is a classification or regression task.  The plots show that the ensemble method generally outperforms self-training, especially when the number of labeled data points is low.  The performance difference between the methods tends to decrease as the number of labeled data points increases.  The figure also includes a panel that shows the win ratio (percentage of tasks where the ensemble method outperformed self-training) and dataset count for different ranges of labeled data.", "section": "6.3 Evaluation on users with different size of labeled data"}, {"figure_path": "3YIyB82rjX/figures/figures_8_2.jpg", "caption": "Figure 4: User performance curve for classification tasks.", "description": "The figure shows the performance comparison between self-training and ensemble methods on several classification tasks with varying numbers of labeled data points.  It illustrates how the ensemble approach using the learnware dock system consistently outperforms self-training, especially when limited labeled data is available.  The results highlight the effectiveness of leveraging pre-trained models from the learnware dock even with limited labeled user data.", "section": "6.3 Evaluation on users with different size of labeled data"}, {"figure_path": "3YIyB82rjX/figures/figures_19_1.jpg", "caption": "Figure 6: summarized mechanisms for RKME\u2081 generation.", "description": "This figure illustrates the two main processes involved in generating the RKME\u2081 specification and user requirements.  For specification generation, it begins with original data which is input into a model to generate pseudo-labeled data.  The pseudo-labeled data is then used to create a reduced set by sketching the marginal distribution Px. A further step, currently only supporting classification, is to use the model to sketch the conditional distribution Px|Y, resulting in a labeled reduced set. In requirement generation, the process begins with user data.  For regression, the process involves sketching the marginal distribution Px to obtain a reduced set. For classification, the process includes sketching both Px and Px|Y using a model trained on the user\u2019s data to generate a labeled reduced set.", "section": "F Experiments"}, {"figure_path": "3YIyB82rjX/figures/figures_21_1.jpg", "caption": "Figure 4: User performance curve for classification tasks.", "description": "This figure displays the performance of self-training versus ensemble methods on classification tasks using different amounts of labeled data.  It shows that the ensemble method consistently outperforms self-training, even with larger amounts of labeled data. The performance is broken down by dataset to highlight the differences in performance across datasets.", "section": "6.3 Evaluation on users with different size of labeled data"}]