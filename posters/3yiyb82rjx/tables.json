[{"figure_path": "3YIyB82rjX/tables/tables_7_1.jpg", "caption": "Table 1: Accuracy (%) (mean \u00b1 std) on user data true labels. The best performance is in bold.", "description": "This table presents the accuracy results for classification tasks.  It compares the performance of the proposed methods (Ourbasic, Ourunify, Ourcls) against several baseline methods (Lightgbm, TabPFN, Alignunlabel, Alignlabel, Transtab, Xtab, Hetero) across various datasets. The best-performing method for each dataset is highlighted in bold. The \"Ourunify w/t/l\" and \"Ourcls w/t/l\" rows show the number of wins, ties, and losses for each method across all datasets.", "section": "6.2 Performance on user tasks"}, {"figure_path": "3YIyB82rjX/tables/tables_7_2.jpg", "caption": "Table 2: RMSE (mean \u00b1 std) on user data true labels. The best performance is emphasized in bold.", "description": "This table presents the Root Mean Squared Error (RMSE) achieved by different methods on regression tasks using true labels from user data.  Lower RMSE values indicate better performance. The results are averaged over multiple trials, and standard deviations are included to show variability. The best performing method for each dataset is highlighted in bold.", "section": "6.2 Performance on user tasks"}, {"figure_path": "3YIyB82rjX/tables/tables_12_1.jpg", "caption": "Table 1: Accuracy (%) (mean \u00b1 std) on user data true labels. The best performance is in bold.", "description": "This table presents the average accuracy (with standard deviation) achieved by different methods on user data for various classification tasks. The methods compared include LightGBM, TabPFN, Alignunlabel, Alignlabel, Transtab, Xtab, Hetero, Our basic, Our unify, and Our cls.  The best performing method for each task is highlighted in bold. This allows for a comparison of the proposed methods against existing techniques and variations of the proposed approach, showing the impact of different design choices on performance.", "section": "6.2 Performance on user tasks"}, {"figure_path": "3YIyB82rjX/tables/tables_19_1.jpg", "caption": "Table 4: Details for classification tasks", "description": "This table presents the details of the 23 classification datasets used in the experiments.  For each dataset, it shows the number of classes, the number of features, and the total number of instances.", "section": "6.1 Experiment setup"}, {"figure_path": "3YIyB82rjX/tables/tables_20_1.jpg", "caption": "Table 5: Details for regression tasks", "description": "This table presents the details of seven regression datasets used in the experiments.  For each dataset, the number of classes, the number of features, and the number of instances are provided.  All datasets have only one class, but vary significantly in the number of features and instances. This information is crucial for understanding the scale and characteristics of the data used in the evaluation of the proposed learnware approach.", "section": "F.1 More details for basic information"}, {"figure_path": "3YIyB82rjX/tables/tables_21_1.jpg", "caption": "Table 1: Accuracy (%) (mean \u00b1 std) on user data true labels. The best performance is in bold.", "description": "This table presents the accuracy (mean \u00b1 standard deviation) achieved on the user's data true labels for various classification tasks. Different methods are compared: LightGBM, TabPFN, Alignunlabel, Alignlabel, Transtab, Xtab, Hetero, Ourbasic, Ourunify, and Ourcls.  The best performing method for each task is highlighted in bold. The table also provides the average accuracy across all tasks for each method and a win count (number of times a method achieved the best performance).", "section": "6.2 Performance on user tasks"}, {"figure_path": "3YIyB82rjX/tables/tables_21_2.jpg", "caption": "Table 7: Ablation study for subspace learning loss by adding loss in sequence for regression tasks.", "description": "This table shows the RMSE results of ablation study on regression tasks.  The ablation study progressively adds loss functions (contrastive, reconstruction, supervised) to evaluate their individual and combined effects on the model's performance. The results demonstrate that incorporating all three loss functions yields the best performance (lowest RMSE).", "section": "6.3 Evaluation on users with different size of labeled data"}]