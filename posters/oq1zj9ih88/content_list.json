[{"type": "text", "text": "Penalty-based Methods for Simple Bilevel Optimization under H\u00f6lderian Error Bounds ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Pengyu Chen\u2217 Xu Shi\u2217 Rujun Jiang\u2020 School of Data Science School of Data Science School of Data Science Fudan University Fudan University Fudan University pychen22@m.fudan.edu.cn xshi22@m.fudan.edu.cn rjjiang@fudan.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Jiulin Wang School of Data Science Fudan University wangjiulin@fudan.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "This paper investigates simple bilevel optimization problems where we minimize an upper-level objective over the optimal solution set of a convex lower-level objective. Existing methods for such problems either only guarantee asymptotic convergence, have slow sublinear rates, or require strong assumptions. To address these challenges, we propose a penalization framework that delineates the relationship between approximate solutions of the original problem and its reformulated counterparts. This framework accommodates varying assumptions regarding smoothness and convexity, enabling the application of specific methods with different complexity results. Specifically, when both upper- and lower-level objectives are composite convex functions, under an $\\alpha$ -H\u00f6lderian error bound condition and certain mild assumptions, our algorithm attains an $(\\epsilon,\\epsilon^{\\beta})$ -optimal solution of the original problem for any $\\beta\\,>\\,0$ within $\\mathcal{O}\\left(\\sqrt{{1}/{\\epsilon^{\\operatorname*{max}\\left\\{{\\alpha,\\beta}\\right\\}}}}\\right)$ iterations. The result can be improved further if the smooth part of the upper-level objective is strongly convex. We also establish complexity results when the upper- and lowerlevel objectives are general nonsmooth functions. Numerical experiments demonstrate the effectiveness of our algorithms. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Bilevel optimization involves embedding one optimization problem within another, creating a hierarchical structure where the upper-level problem\u2019s feasible set is influenced by the lower-level problem. This framework frequently occurs in various real-world scenarios, such as meta-learning [Bertinetto et al., 2018, Rajeswaran et al., 2019], hyper-parameter optimization [Chen et al., 2024, Franceschi et al., 2018, Shaban et al., 2019], reinforcement learning [Mingyi et al., 2020] and adversarial learning [Bishop et al., 2020, Wang et al., 2021, 2022]. In this paper, we concentrate on a subset of bilevel optimization known as simple bilevel optimization (SBO), which has garnered significant interest in the machine learning community due to its relevance in dictionary learning [Beck and Sabach, 2014, Jiang et al., 2023], lexicographic optimization [Kissel et al., 2020, Gong et al., 2021], lifelong learning [Malitsky, 2017, Jiang et al., 2023]; see more details in Appendix A. ", "page_idx": 0}, {"type": "text", "text": "SBO aims to find an optimal solution that minimizes the upper-level objective over the solution set of the lower-level problem. In other words, we are interested in solving the following problem: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}F(\\mathbf{x})\\quad\\mathrm{s.t.}\\,\\,\\,\\mathbf{x}\\in\\arg\\operatorname*{min}_{\\mathbf{z}\\in\\mathbb{R}^{n}}G(\\mathbf{z}).\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Here $F,G:\\mathbb{R}^{n}\\to\\mathbb{R}\\bigcup\\{\\infty\\}$ are proper, convex, and lower semi-continuous functions. We also assume that the optimal  solution set of the lower-level problem, denoted as $X_{\\mathrm{opt}}$ , is nonempty. Moreover, since $G$ is convex and lower semi-continuous, it holds that $X_{\\mathrm{opt}}$ is closed and convex [Bertsekas et al., 2003, Proposition 1.2.2 and Page 49]. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we first reformulate problem (P) into the constrained form: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}F(\\mathbf{x})\\quad\\mathrm{s.t.}\\ G(\\mathbf{x})-G^{*}\\leq0,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $G^{*}$ represents the optimal value of the unconstrained lower-level problem. ", "page_idx": 1}, {"type": "text", "text": "Based on this reformulation, we consider the following penalization of $(\\mathrm{P_{Val}})$ , ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\Phi_{\\gamma}(\\mathbf{x})=F(\\mathbf{x})+\\gamma p(\\mathbf{x}),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $p(\\mathbf{x}):=G(\\mathbf{x})-G^{*}$ is the so-called residual function and $\\gamma>0$ is the penalized parameter.   \nObviously, we have $p(\\mathbf{x})\\geq0$ , and $p(\\mathbf{x})=0$ if and only if $\\mathbf{x}\\in X_{\\mathrm{opt}}$ . ", "page_idx": 1}, {"type": "text", "text": "Denote $F^{*}$ and $G^{*}$ as the optimal values of problem (P) and the lower-level problem $\\mathrm{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\;G(\\mathbf{x})$ , respectively. We aim to find an $(\\epsilon_{F},\\epsilon_{G})$ -optimal solution $\\tilde{\\mathbf{x}}^{*}$ of problem (P), which satisfies ", "page_idx": 1}, {"type": "equation", "text": "$$\nF(\\tilde{\\mathbf{x}}^{*})-F^{*}\\leq\\epsilon_{F},\\quad G(\\tilde{\\mathbf{x}}^{*})-G^{*}\\leq\\epsilon_{G}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Moreover, a point $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is said to be an $\\epsilon_{}$ -optimal solution of problem $(\\mathsf{P}_{\\gamma})$ if ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Phi_{\\gamma}(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-\\Phi_{\\gamma}^{*}\\leq\\epsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\Phi_{\\gamma}^{*}$ is the optimal value of problem $(\\mathrm{{P}}_{\\gamma})$ . ", "page_idx": 1}, {"type": "text", "text": "1.1 Related work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Various approaches have been developed to solve problem (P) [Cabot, 2005, Solodov, 2007, Sabach and Shtern, 2017, Dutta and Pandit, 2020, Gong et al., 2021]. Among those, one category that is the most related to penalization formulation $(\\mathbf{P}_{\\gamma})$ is the regularization method, which integrates the upper- and lower-level objectives through Tikhonov regularization [Tikhonov and Arsenin, 1977] ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\eta(\\mathbf{x}):=\\sigma F(\\mathbf{x})+G(\\mathbf{x}),\n$$", "text_format": "latex", "page_idx": 1}, {"type": "equation", "text": "$$\n\\left(\\mathrm{P_{Reg}}\\right)\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $\\sigma$ is the so-called regularization parameter. When $F$ is strongly convex and its domain is compact, Amini and Yousefian [2019] extended the IR-PG method from Solodov [2007], which achieved a asymptotic convergence rate for the upper-level problem and a convergence rate of $\\mathcal{O}\\left(1/K^{0.5-b}\\right)$ for the lower-level problem, where $b\\in(0,0.5)$ . Malitsky [2017] studied a version of Tseng\u2019s accelerated gradient method and showed a convergence rate of ${\\mathcal{O}}\\left(1/K\\right)$ for the lower-level problem, while the convergence rate for the upper-level objective is not explicitly provided. Kaushik and Yousefian [2021] proposed an iteratively regularized gradient (a-IRG) method which obtains a complexity of $\\bar{O}\\left(1/\\dot{K}^{0.5-b}\\right)$ and $\\mathcal{O}\\left(1/K^{b}\\right)$ for the upper- and lower-level objective, respectively, where $b\\in(0,0.5)$ . Inspired by this research, and under a quasi-Lipschitz assumption for $F$ , Merchav and Sabach [2023] introduced a bi-subgradient (Bi-SG) method. This method demonstrates convergence rates of ${\\mathcal{O}}(1/K^{b})$ and ${\\mathcal O}(1/K^{1-\\bar{b}})$ for the lower- and upper-level objectives, respectively, where $b\\in(0.5,1)$ . In their framework, the convergence rate of the upper-level objective can be improved to be linear when $F$ is strongly convex. Recently, under the weak-sharp minima assumption of the lower-level problem, Samadi et al. [2023] proposed a regularized accelerated proximal method (RAPM), showing a convergence rate of $\\mathcal{O}(1/K^{2})$ for both upper- and lower-level objectives. When the domain is compact and $F,G$ are both smooth, Giang-Tran et al. [2023] proposed an iteratively regularized conditional gradient (IR-CG) method, which ensures convergence rates of $\\mathcal{O}(1/K^{p})$ and $\\bar{O(1/K^{1-p})}$ for upper- and lower-level objectives, respectively, where $\\bar{p}\\in(0,1)$ . ", "page_idx": 1}, {"type": "text", "text": "Despite the abundance of existing methodologies yielding non-asymptotic convergence outcomes, their efficacy is frequently contingent upon additional assumptions. Denote $L_{f_{1}}$ and $L_{g_{1}}$ as the Lipschitz constants for the gradients of the smooth components in the upper- and lower-level objectives, respectively. Specifically, when $F$ is strongly convex and $G$ is smooth, Beck and Sabach [2014] presented the Minimal Norm Gradient (MNG) method and provided the asymptotic convergence to the optimal solution set and a convergence rate of ${\\mathcal O}\\left(L_{g_{1}}^{2}/\\dot{\\epsilon}^{2}\\right)$ for the lower-level problem. When $F$ is assumed to be smooth, Jiang et al. [2023] introduced a conditional gradient-based bilevel optimization (CG-BiO) method, which invokes at most $\\mathcal{O}\\left(\\operatorname*{max}\\{L_{f_{1}}/\\epsilon_{F},\\bar{L_{g_{1}}}/\\epsilon_{G}\\}\\right)$ of linear optimization oracles to achieve an $(\\epsilon_{F},\\epsilon_{G})$ -optimal solution. Shen et al. [2023] combined an online framework with the mirror descent algorithm and established a convergence rate of ${\\mathcal{O}}(1/\\epsilon^{3})$ for both upper- and lower-level objectives, assuming a compact domain and boundedness of the functions and gradients at both levels. Furthermore, they showed that the convergence rate can be improved to $\\mathcal{O}(1/\\epsilon^{2})$ under additional structural assumptions. For a concise overview of overall methodologies, including their assumptions and convergence outcomes, refer to Table 1 in Appendix B. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "For general bilevel optimization problems, there have been recent results on convergent guarantees [Shen and Chen, 2023, Sow et al., 2022, Chen et al., 2023, Huang, 2023]. Among those, the one that is the most related to ours is [Shen and Chen, 2023]. It investigates the case when the upper-level objective is nonconvex and gives convergence results under additional assumptions [Shen and Chen, 2023, Theorem 3 and 4]. However, as the general bilevel optimization problem is nonconvex, the algorithms in the literature often converge to weak stationary points, while our method for SBO converges to global optimal solution. ", "page_idx": 2}, {"type": "text", "text": "1.2 Our approach ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our approach is straightforward. Firstly, we introduce a penalization framework delineating the connection between approximate solutions of problems (P) and $(\\mathbf{P}_{\\gamma})$ . This framework enables the attainment of an $(\\epsilon_{F},\\epsilon_{G})$ -optimal solution by solving problem $(\\mathsf{P}_{\\gamma})$ approximately. Subsequently, our focus shifts solely to resolving the unconstrained problem $(\\mathsf{P}_{\\gamma})$ . Depending on varying assumptions regarding smoothness and convexity, we can employ different methods such as the accelerated proximal gradient (APG) methods [Beck and Teboulle, 2009, Nesterov, 2013, Lin and Xiao, 2014] to solve problem $(\\mathrm{{P}}_{\\gamma})$ . We summarize our main contributions as follows. ", "page_idx": 2}, {"type": "text", "text": "\u2022 We propose a framework that explicitly examines the relationship between an $\\epsilon$ -optimal solution of penalty formulation $(\\mathbf{P}_{\\gamma})$ and an $(\\epsilon_{F},\\epsilon_{G})$ -optimal solution of problem (P). We also provide a lower bound for the metric $F(\\mathbf{x})-F^{*}$ .   \n\u2022 When $F$ and $G$ are both composite convex functions, we provide a penalty-based APG algorithm that attains an $(\\epsilon,\\epsilon^{\\beta})$ -optimal solution of problem (P) within $\\mathcal{O}(\\sqrt{{1}/{\\epsilon^{\\operatorname*{max}}\\{\\alpha,\\beta\\}}})$ iterations. If the upper-level objective is strongly convex, the complexity can be improved to $\\mathcal{O}(\\sqrt{1/\\epsilon^{\\operatorname*{max}\\{\\alpha-1,\\beta-1\\}}}\\log\\frac{1}{\\epsilon})$ . We also apply our method for the scenario where both the upper- and lower-level objectives are generalized nonsmooth convex functions.   \n\u2022 We present adaptive versions of PB-APG and PB-APG-sc with warm-start, which dynamically adjust the penalty parameters, and solve the associated penalized problem with adaptive accuracy. The adaptive ones have similar complexity results as their primal counterparts but can achieve superior performance in some experiments. ", "page_idx": 2}, {"type": "text", "text": "Utilizing the penalization method to address the original SBO problem is a novel approach. While Tikhonov regularization may seem similar to our framework, its principles differ. Implementing Tikhonov regularization necessitates the \"slow condition\" $\\begin{array}{r}{(\\operatorname*{lim}_{k\\to\\infty}\\sigma_{k}\\ ^{\\ \u3001}=\\ 0,\\sum_{k=0}^{\\infty}\\sigma_{k}\\ =\\ +\\infty)}\\end{array}$ , which requires iterative solutions for each iteration. In contrast, our method sim ply involves solving a single optimization problem $(\\mathsf{P}_{\\gamma})$ for a given $\\gamma$ . Furthermore, we establish a relationship between the approximate solutions of the original bilevel problem and those of the reformulated single-level problem $(\\mathbf{P}_{\\gamma})$ for a specific $\\gamma$ . This is the first theoretical result connecting the original bilevel problem to the penalization problem, accompanied by an optimal non-asymptotic complexity result. ", "page_idx": 2}, {"type": "text", "text": "2 The penalization framework ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We begin by outlining specific assumptions for $F$ and $G$ , as detailed below.   \nAssumption 2.1. The set $\\begin{array}{r}{S:=\\bigcup_{\\mathbf{x}\\in X_{\\mathrm{opt}}}\\partial F(\\mathbf{x})}\\end{array}$ is bounded with a diameter $l_{F}:=\\operatorname*{max}_{\\xi\\in S}\\|\\xi\\|$ . ", "page_idx": 2}, {"type": "text", "text": "Note that the type of subdifferential $\\partial F$ used here is the most general form for a convex function, as detailed in [Bertsekas et al., 2003, Section 4.2]. When the upper-level objective $F$ is non-convex, ", "page_idx": 2}, {"type": "text", "text": "we replace the assumption with the condition that the upper-level objective is Lipschitz continuous (cf. Theorems 2.7 and 2.8). ", "page_idx": 3}, {"type": "text", "text": "Assumption 2.2 (H\u00f6lderian error bound). The function $p(\\mathbf{x}):=G(\\mathbf{x})-G^{*}$ satisfies the H\u00f6lderian error bound with exponent $\\alpha\\geq1$ and $\\rho>0$ . Namely, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{dist}(\\mathbf x,X_{\\mathrm{opt}})^{\\alpha}\\leq\\rho p(\\mathbf x),\\forall\\mathbf x\\in\\mathrm{dom}(G),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\mathrm{dist}(\\mathbf x,X_{\\mathrm{opt}}):=\\operatorname*{inf}_{\\mathbf y\\in X_{\\mathrm{opt}}}\\|\\mathbf x-\\mathbf y\\|$ . ", "page_idx": 3}, {"type": "text", "text": "We remark that H\u00f6lderian error bounds are satisfied by many practical problems and widely used in optimization literature [Pang, 1997, Bolte et al., 2017, Zhou and So, 2017, Roulet and d\u2019Aspremont, 2020, Jiang and Li, 2022]. There are two notable special cases: (i) when $\\alpha=1$ , we often refer to $X_{\\mathrm{opt}}$ as a set of weak sharp minima of $G$ [Burke and Ferris, 1993, Studniarski and Ward, 1999, Burke and Deng, 2005, Samadi et al., 2023]; (ii) when $\\alpha=2$ , Assumption 2.2 is known as the quadratic growth condition [Drusvyatskiy and Lewis, 2018a]. Additional examples of functions exhibiting H\u00f6lderian error bound, along with their corresponding parameters, are presented in Appendix C. ", "page_idx": 3}, {"type": "text", "text": "We are now ready to establish the connection between approximate solutions of problems $({\\bf P})$ and $(\\mathbf{P}_{\\gamma})$ . The subsequent two lemmas build upon the work of Shen and Chen [2023] for (general) bilevel optimization. Compared with their work, we generalize the exponent $\\alpha$ from 2 to $\\alpha\\geq1$ , providing a more general result. Furthermore, we also derive a lower bound for the penalized parameter for all $\\alpha\\geq1$ and present a theoretical framework for these scenarios. ", "page_idx": 3}, {"type": "text", "text": "Lemma 2.3. Suppose that Assumptions 2.1 and 2.2 hold with $\\alpha>1$ . Then, for any $\\epsilon>0$ , an optimal solution of problem (P) is an \u03f5-optimal solution of problem $(\\mathbf{P}_{\\gamma})$ ) when $\\gamma\\geq\\dot{\\rho}l_{F}^{\\alpha}(\\dot{\\alpha}-1)^{\\alpha-1}\\alpha^{-\\bar{\\alpha}}\\epsilon^{1-\\alpha}$ . ", "page_idx": 3}, {"type": "text", "text": "Lemma 2.3 establishes the relationship between an optimal solution of problem (P) and an $\\epsilon$ -optimal solution of problem $(\\mathbf{P}_{\\gamma})$ when $\\alpha>1$ . It also provides a lower bound for $\\gamma$ , which plays a pivotal role in the complexity results. The proofs of this paper are deferred to Appendix E. ", "page_idx": 3}, {"type": "text", "text": "The lemma presented below yields a more favorable outcome when $\\alpha=1$ , which is referred to as exact penalization. Notably, this specific result is not discussed in Shen and Chen [2023]. ", "page_idx": 3}, {"type": "text", "text": "Lemma 2.4. Suppose that Assumptions 2.1 and 2.2 hold with $\\alpha=1$ . Then an optimal solution of problem (P) is also an optimal solution of problem $(\\mathbf{P}_{\\gamma})$ i $\\mathrm{~\\bar{~}{\\gamma}~}\\geq\\rho l_{F}$ , and vice versa $i f\\gamma>\\rho l_{F}$ . $I n$ this case, we say that there is an exact penalization between problems (P) and $(\\mathsf{P}_{\\gamma})$ . ", "page_idx": 3}, {"type": "text", "text": "For simplicity, we define ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\gamma^{*}=\\left\\{\\begin{array}{r l r}&{\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon^{1-\\alpha}}&{\\mathrm{if}\\ \\alpha>1}\\\\ &{\\rho l_{F}}&{\\mathrm{if}\\ \\alpha=1}\\end{array}.\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Based on Lemmas 2.3 and 2.4, we give an overall relationship of approximate solutions between problems $(\\mathbf{P}_{\\gamma})$ and (P). ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.5. Suppose that Assumptions 2.1 and 2.2 hold. For any given $\\epsilon>0$ and $\\beta>0$ , let ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\gamma=\\gamma^{*}+\\left\\{\\begin{array}{l l}{\\begin{array}{r l r}&{{2l}_{F}^{\\beta}\\epsilon^{1-\\beta}}&{{i f\\alpha>1,}}\\\\ &{{l}_{F}^{\\beta}\\epsilon^{1-\\beta}}&{{i f\\alpha=1,}}\\end{array}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "with $\\gamma^{*}$ defined in (2). If $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an \u03f5-optimal solution of problem $(\\mathbf{P}_{\\gamma})$ , then $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an $(\\epsilon,l_{F}^{-\\beta}\\epsilon^{\\beta})$ - optimal solution of problem $\\mathbf{\\tau}(\\mathbf{P})$ . ", "page_idx": 3}, {"type": "text", "text": "Particularly, we are also able to establish a lower bound for $F(\\tilde{x}_{\\gamma}^{*})-F^{*}$ under the same conditions outlined in Theorem 2.5. ", "page_idx": 3}, {"type": "text", "text": "Theorem 2.6. Suppose that the conditions in Theorem 2.5 hold. Then, $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ satisfies the following suboptimality lower bound, ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-F^{*}\\geq-l_{F}(\\rho l_{F}^{-\\beta}\\epsilon^{\\beta})^{\\frac{1}{\\alpha}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "By setting $\\beta=\\alpha$ , we obtain $F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-F^{*}\\geq-\\rho^{\\frac{1}{\\alpha}}\\epsilon$ . which along with Theorem 2.5 gives ", "page_idx": 3}, {"type": "equation", "text": "$$\n|F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-F^{*}|\\leq\\operatorname*{max}\\{\\epsilon,\\rho^{\\frac{1}{\\alpha}}\\epsilon\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We emphasize that the lower bound established in Theorem 2.6 is an intrinsic property of problem (P) under Assumptions 2.1 and 2.2. This property is independent of the algorithms we present. ", "page_idx": 3}, {"type": "text", "text": "2.1 Analysis of non-convex upper-level ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Note that the upper-level objective $F$ is required to be convex in the above context (cf. Theorem 2.5). This raises a question: while Theorem 2.5 establishes the relationship between approximate solutions of problems $({\\bf P})$ and $(\\mathbf{P}_{\\gamma})$ , the distinction between the global or local optimal solutions of problem (P) and $(\\mathsf{P}_{\\gamma})$ remains unclear when $F$ is non-convex. ", "page_idx": 4}, {"type": "text", "text": "We first establish the relationship between global optimal solutions of problems (P) and $(\\mathbf{P}_{\\gamma})$ when $F$ is non-convex, which is similar to Theorem 2.5. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2.7. Suppose that Assumption 2.2 holds, $G$ is convex, and $F$ is $l$ -Lipschitz continuous on $\\mathrm{dom}(F)$ . For any given $\\epsilon>0$ and $\\bar{\\beta}>0$ , let ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\gamma=\\gamma^{*}+\\left\\{\\begin{array}{l l}{\\begin{array}{r l r}&{{2l}^{\\beta}\\epsilon^{1-\\beta}}&{{i f\\alpha>1},}\\\\ &{{l}^{\\beta}\\epsilon^{1-\\beta}}&{{i f\\alpha=1,}}\\end{array}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\gamma^{*}$ is given by (2). If $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an $\\epsilon$ -global optimal solution of problem $(\\mathsf{P}_{\\gamma})$ , then $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an $(\\epsilon,l^{-\\beta}\\epsilon^{\\beta})$ -global optimal solution of problem (P). ", "page_idx": 4}, {"type": "text", "text": "Theorem 2.7 provides the relationship between the global optimal solutions of problems $(\\mathbf{P}_{\\gamma})$ and (P). However, the relationship between local optimal solutions of these problems is more intricate than those of the global ones [Shen and Chen, 2023]. Given $r>0$ and $\\mathbf{z}\\in\\mathbb{R}^{n}$ , define $B(\\mathbf{z},r):=$ $\\left\\{\\mathbf{x}\\in\\mathbb{R}^{n}:\\|\\mathbf{x}-\\mathbf{z}\\|\\leq r\\right\\}$ . We present the following theorem, which demonstrates that local optimal solutions of problem $(\\mathbf{P}_{\\gamma})$ can serve as approximate local optimal solutions of problem (P). ", "page_idx": 4}, {"type": "text", "text": "Theorem 2.8. Suppose that Assumption 2.2 holds and $G$ is convex. Let $\\mathbf{x}_{\\gamma}^{*}$ be a local optimal solution of problem $(\\mathsf{P}_{\\gamma})$ on $B(\\mathbf{x}_{\\gamma}^{*},r)$ . Assume $F$ is $l$ -Lipschitz continuous on $B(\\mathbf{x}_{\\gamma}^{\\ast},r)$ . Then $\\mathbf{x}_{\\gamma}^{*}$ is an approximate local optimal solution of problem (P) that satisfies $F(\\mathbf{x}_{\\gamma}^{*})-F_{\\mathcal{B}}^{*}\\leq0$ and $G(\\mathbf{x}_{\\gamma}^{*})\\!-\\!G^{*}\\leq$ $\\epsilon$ when $\\alpha>1$ and $\\gamma\\ge\\left(\\frac{\\rho l^{\\alpha}}{\\epsilon^{\\alpha-1}}\\right)^{\\frac{1}{\\alpha}}$ , where $F_{B}^{*}$ is the optimal value of problem (P) on $B(\\mathbf{x}_{\\gamma}^{*},r)\\cap X_{\\mathrm{opt}}$ . Furthermore, $\\mathbf{x}_{\\gamma}^{*}$ is a local optimal solution of problem (P) when $\\alpha=1$ and $\\gamma>\\rho l$ . ", "page_idx": 4}, {"type": "text", "text": "Indeed, the relationship between approximate local optimal solutions of problems $(\\mathsf{P}_{\\gamma})$ and (P) is more intricate than the connection among global solutions presented in Theorem 2.5. These interactions will be the focus of our future work. The proofs of Theorems 2.7 and 2.8 are presented in Appendixes E.5 and E.6. ", "page_idx": 4}, {"type": "text", "text": "3 Main algorithms ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we concentrate on addressing problem (P), making various assumptions, and offering distinct convergence outcomes. ", "page_idx": 4}, {"type": "text", "text": "3.1 The objectives are both composite ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this scenario, we address problem (P) where $F$ and $G$ are both composite functions, i.e., ${\\textbf{\\textit{F}}}=$ $f_{1}+f_{2}$ and $G=g_{1}+g_{2}$ . ", "page_idx": 4}, {"type": "text", "text": "Assumption 3.1. $F$ and $G$ satisfy the following assumptions. ", "page_idx": 4}, {"type": "text", "text": "(1) The gradient of $f_{1}(\\mathbf{x})$ , denoted as $\\nabla f_{1}$ , is $L_{f_{1}}$ -Lipschitz continuous on $\\mathrm{dom}(F)$ ;   \n(2) The gradient of $g_{1}(\\mathbf{x})$ , denoted as $\\nabla g_{1}$ , is $L_{g_{1}}$ -Lipschitz continuous on $\\mathrm{dom}(G)$ ;   \n(3) $f_{2}$ and $g_{2}$ are proper, convex, lower semicontinuous, and possibly non-smooth. ", "page_idx": 4}, {"type": "text", "text": "We remark that Assumption 3.1(1)(3) is more general than many existing papers in the literature. Specifically, while previous works such as Beck and Sabach [2014], Amini and Yousefian [2019], Jiang et al. [2023], Giang-Tran et al. [2023] require the upper-level objective to be smooth or strongly convex, we simply assume that $F$ is a composite function composed of a smooth convex function and a possibly non-smooth convex function. For the lower-level objective, previous works such as Beck and Sabach [2014], Amini and Yousefian [2019], Jiang et al. [2023], Giang-Tran et al. [2023] impose smoothness assumptions and, in some cases, convexity and compactness constraints on the domain; while our approach does not require these additional constraints, allowing for more flexibility and generality as presented in Assumption 3.1(2)(3). ", "page_idx": 4}, {"type": "text", "text": "We are now prepared to introduce two algorithms: the penalty-based accelerated proximal gradient (PB-APG) algorithm and its adaptive counterpart, the aPB-APG to solve problem $(\\mathbf{P}_{\\gamma})$ and, subsequently, to obtain an $(\\epsilon_{F},\\epsilon_{G})$ -optimal solution of problem (P). ", "page_idx": 5}, {"type": "text", "text": "To simplify notations, we omit the constant term $-\\gamma G^{*}$ , and rewrite problem $(\\mathbf{P}_{\\gamma})$ as follows, ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\Phi_{\\gamma}(\\mathbf{x}):=\\phi_{\\gamma}(\\mathbf{x})+\\psi_{\\gamma}(\\mathbf{x}),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "equation", "text": "$$\n(\\mathbf{P}_{\\Phi})\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\phi_{\\gamma}(\\mathbf{x})=f_{1}(\\mathbf{x})+\\gamma g_{1}(\\mathbf{x})$ and $\\psi_{\\gamma}(\\mathbf{x})=f_{2}(\\mathbf{x})+\\gamma g_{2}(\\mathbf{x})$ represent the smooth and nonsmooth parts, respectively. Then, it follows that the gradient of $\\phi_{\\gamma}(\\mathbf{x})$ is $L_{\\gamma}$ -Lipschitz continuous with $L_{\\gamma}=L_{f_{1}}+\\gamma L_{g_{1}}$ . ", "page_idx": 5}, {"type": "text", "text": "To implement the APG methods, we need another assumption concerning $\\psi_{\\gamma}(\\mathbf{x})$ . ", "page_idx": 5}, {"type": "text", "text": "Assumption 3.2. For any $\\gamma>0$ , the function $\\psi_{\\gamma}(\\mathbf{x})$ is prox-friendly, i.e., the proximal mapping ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname{prox}_{t\\psi_{\\gamma}}(\\mathbf{y}):=\\underset{\\mathbf{x}\\in\\mathbb{R}^{n}}{\\arg\\operatorname*{min}}\\{\\psi_{\\gamma}(\\mathbf{x})+\\frac{1}{2t}\\|\\mathbf{x}-\\mathbf{y}\\|^{2}\\},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "is easy to compute for any $t>0$ . ", "page_idx": 5}, {"type": "text", "text": "The function $\\psi_{\\gamma}(\\mathbf{x})$ represents the sum of two non-smooth functions, and proximal mapping for such function sums is widely studied and used in the literature [Yu, 2013, Pustelnik and Condat, 2017, Adly et al., 2019, Boob et al., 2023, Latafat et al., 2023]. This assumption is also a more general requirement compared to many existing algorithms [Sabach and Shtern, 2017, Giang-Tran et al., 2023]. It is important to note that our assumption is more general than existing literature. In the simple bilevel literature, when employing proximal mappings, researchers often consider the scenario where only one level contains a nonsmooth term (see, e.g., [Jiang et al., 2023, Doron and Shtern, 2023, Samadi et al., 2023, Merchav and Sabach, 2023]). In this case, the proximal mapping of the sum $f_{2}+\\gamma g_{2}$ is then reduced to the proximal mapping of either $f_{2}$ or $g_{2}$ , which is a more easily satisfied condition. ", "page_idx": 5}, {"type": "text", "text": "3.1.1 Accelerated proximal gradient-based algorithm ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We apply the APG algorithm [Beck and Teboulle, 2009, Lin and Xiao, 2014, Nesterov, 2013] to solve problem $(\\mathrm{P_{\\Phi}})$ , as outlined in Algorithm 1. Moreover, if the Lipschitz constant $L_{\\gamma}$ is unknown or computationally infeasible, line search [Beck and Teboulle, 2009] can be adopted and will yield almost the same complexity bound. For brevity, we denote Algorithm 1 as $\\bar{\\hat{\\textbf{x}}}=$ $\\mathrm{PB-APG}(\\phi_{\\gamma},\\psi_{\\gamma},L_{f_{1}},L_{g_{1}},{\\bf x}_{0},\\epsilon)$ , where $\\hat{\\bf x}$ represents an $\\epsilon$ -optimal solution of $(\\mathrm{P_{\\Phi}})$ . ", "page_idx": 5}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/17ebde8817b933dcf264c68fa1a196abb7cdb1cfa1730a07cbc3d7aae18cd5dd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "In Algorithm 1, we stop the loop of Line. 3 - 4 if the number of iterations satisfies that: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\frac{2(L_{f}+\\gamma L_{g})R^{2}}{(k+1)^{2}}\\leq\\epsilon,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $R$ is a constant that satisfies $\\|\\mathbf{x}_{0}-\\mathbf{x}^{*}\\|\\leq R$ . ", "page_idx": 5}, {"type": "text", "text": "Combining Theorem 2.5 and [Tseng, 2008, Corollary 2], we establish the following complexity result for problem (P). ", "page_idx": 5}, {"type": "text", "text": "sTahtiesofrieesm .  thLaett sbuem oenns  a2s. 1i,n  2T.2h,e o3r.e1 ma n2d.5 .3. 2A lhgoolrdi tahnmd h ge esneeqruateensc ea $\\{t_{k}\\}$ o-roiptthimm a1l $\\begin{array}{r l r}{\\frac{1-t_{k+1}}{t_{k+1}^{2}}}&{{}\\le}&{\\frac{1}{t_{k}^{2}}}\\end{array}$ $\\gamma$ $^{\\,l}$ $(\\epsilon,l_{F}^{-\\beta}\\epsilon^{\\beta})$ solution of problem (P) after at most $K$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\epsilon}}+\\sqrt{\\frac{l_{F}^{\\operatorname*{max}\\{\\alpha,\\beta\\}}L_{g_{1}}}{\\epsilon^{\\operatorname*{max}\\{\\alpha,\\beta\\}}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Note that Theorem 3.3 encompasses all possible relationships between the magnitudes of $\\epsilon_{F}$ and $\\epsilon{\\boldsymbol{G}}$ in (1), as $\\alpha\\ \\geq\\ 1$ and $\\beta~>~0$ are arbitrary. Specially, if $\\alpha\\ =\\ 1$ and $\\beta\\ \\leq\\ \\alpha$ , the number of iterations is $K\\,=$ $\\mathcal{O}\\left(\\sqrt{(L_{f_{1}}+l_{F}L_{g_{1}})/\\epsilon}\\right)$ . This result matches the lower bound complexity for unconstrained smooth or convex composite optimization [Nemirovsky and Yudin, 1983, Woodworth and Srebro, 2016]. Additionally, if $g_{1}\\equiv0$ , the number of iterations for obtaining an $(\\epsilon,\\epsilon^{\\beta})$ -optimal solution of problems (P) is independent of $\\gamma$ , which can be improved to $K=\\mathcal{O}(\\sqrt{L_{f_{1}}/\\epsilon})$ . ", "page_idx": 6}, {"type": "text", "text": "Remark 3.4. It is noteworthy that Theorem 1 in a previous paper Samadi et al. [2023] provides the first method that needs $\\mathcal{O}(\\sqrt{(L_{g_{1}}+l_{F}L_{g_{1}})/\\epsilon})$ iterations to achieve an $(\\epsilon,\\epsilon)$ solution if $\\alpha=1$ and $F$ is smooth. Nevertheless, our methodology diverges in various respects. First, our approach is rooted in the penalization formulation of problem $(\\mathrm{{P}_{V a l}})$ , while the approach proposed by Samadi et al. [2023] is based on the Tikhonov regularization [Tikhonov and Arsenin, 1977]. Second, we provide a theoretical framework that clearly delineates the relationship between approximate solutions of problems (P) and $(\\mathrm{P}_{\\gamma})$ for all cases of $\\alpha\\,\\geq\\,1$ and $F$ is non-convex, as indicated in Lemmas 2.3, 2.4 and Theorems 2.5, 2.7, 2.8. Therefore, we can first shift our focus from (P) to $(\\mathrm{P}_{\\gamma})$ based on the penalization framework and then use various methods to solve $(\\mathrm{P}_{\\gamma})$ , not limited to using the APG methods. Besides, the association between approximate solutions of problem $({\\bf P})$ and $(\\mathbf{P}_{\\gamma})$ differs significantly based on whether $\\alpha\\,>\\,1$ or $\\alpha\\,=\\,1$ . For the case of $\\alpha\\,>\\,1$ , the lower bound comprehensively integrates the accuracy parameter $\\epsilon$ , which results in a more sophisticated analysis of the convergence result, while Samadi et al. [2023] did not consider the situation when $\\alpha>1$ . Third, our method applies to the case that $F$ is composite, while Samadi et al. [2023] requires $F$ to be smooth. Finally, we also propose an adaptive version of our algorithm (see Algorithm 2) that does not require an estimate of $\\gamma$ . ", "page_idx": 6}, {"type": "text", "text": "3.1.2 Adaptive version with warm-start mechanism ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In practice, the penalty parameter $\\gamma$ might be difficult to determine. This motivates us to propose Algorithm 2, which adaptively updates $\\gamma$ and invokes PB-APG with dynamic $\\gamma$ and solution accuracies. ", "page_idx": 6}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/15fcdb77ac0892355e4a8fa63a80205859b518cf4a1dce9c1d0cba3a1b64d6d8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "In Algorithm 2, we adaptively update the penalty parameter $\\gamma_{k}$ , and invoke the PB-APG to generate an approximate solution for $(\\mathbf{P}_{\\gamma})$ with accuracy $\\epsilon=\\epsilon_{k}$ . Meanwhile, a warm-start mechanism is employed, meaning that the initial point for each subproblem is the output of the preceding subproblem. The convergence result of Algorithm 2 is as follows. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.5. Suppose that Assumptions 2.1, 2.2, 3.1, and 3.2 hold. Also assume that for every outcome of inner loop in Algorithm 2, $\\|\\mathbf{x}_{k}-\\mathbf{x}_{k}^{*}\\|\\leq R$ . Let $\\epsilon_{0}>0$ be given. ", "page_idx": 6}, {"type": "text", "text": "\u2022 When $\\alpha\\,>\\,1$ , set $\\nu>\\eta^{\\alpha-1}$ , and define $N:=\\lceil\\log_{\\eta^{1-\\alpha}\\nu}(\\rho L_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon_{0}^{1-\\alpha}/\\gamma_{0})\\rceil+$ and $\\gamma_{k}^{\\ast}:=\\rho L_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon_{0}^{1-\\alpha}\\eta^{k(\\alpha-1)},$ . \u2022 When $\\alpha=1$ , set $\\nu>1$ , and define $N:=\\lceil\\log_{\\nu}(\\rho l_{F}/\\gamma_{0})\\rceil+$ and $\\gamma_{k}^{*}:=\\rho L_{F}$ . ", "page_idx": 6}, {"type": "text", "text": "Then, for any $k\\geq N$ , Algorithm 2 generates an $\\Big(\\frac{\\epsilon_{0}}{\\eta^{k}}\\,,\\,\\frac{2\\epsilon_{0}}{\\eta^{k}\\big(\\gamma_{0}\\nu^{k}\\!-\\!\\gamma_{k}^{*}\\big)}\\Big)$ -optimal solution of problem (P) after at most $K$ iterations, where $K$ satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}\\eta^{k}}{\\epsilon_{0}}}+\\sqrt{\\frac{L_{g_{1}}\\gamma_{0}(\\eta\\nu)^{k}}{\\epsilon_{0}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Theorem 3.5 shows that for any given initial accuracy $\\epsilon_{0}>0$ , Algorithm 2 can produce an approximate solution of problem (P) with the desired accuracy. ", "page_idx": 6}, {"type": "text", "text": "Remark 3.6. From Theorem 3.5, one can obtain an $(\\epsilon,\\frac{\\epsilon}{\\gamma_{0}\\nu^{k}-\\gamma_{k}^{*}})$ -optimal solution of problem (P) within $\\mathcal{O}(\\sqrt{L_{f_{1}}/\\epsilon}+\\sqrt{L_{g_{1}}/\\epsilon^{\\alpha}})$ iterations when $\\epsilon/\\eta\\,\\leq\\,\\epsilon_{0}/\\eta^{k}\\,\\leq\\,\\epsilon$ , which is similar to the complexity results in Theorem 3.3. ", "page_idx": 6}, {"type": "text", "text": "3.1.3 The upper-level objective is strongly convex ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We investigate the convergence outcomes when the smooth part of the upper-level objective exhibits strong convexity. ", "page_idx": 7}, {"type": "text", "text": "Assumption 3.7. $f_{1}(\\mathbf{x})$ is $\\mu$ -strongly convex on $\\mathrm{dom}(F)$ with $\\mu>0$ . ", "page_idx": 7}, {"type": "text", "text": "Assumption 3.7 is another widely adopted setting in the existing SBO literature [Beck and Sabach, 2014, Sabach and Shtern, 2017, Amini and Yousefian, 2019, Merchav and Sabach, 2023]. Here, we propose a variant of PB-APG that can provide better complexity results than existing methods. Our main integration is an APG-based algorithm, which has been studied in the existing literature [Nesterov, 2013, Lin and Xiao, 2014, Xu, 2022]. In this paper, we adopt the algorithm proposed in Lin and Xiao [2014] and modify it with a constant step-size for simplicity as in Algorithm 3. Similar to Algorithm 1, we denote Algorithm 3 by \u02c6x $=\\mathrm{PB-APG-sc}(\\phi_{\\gamma},\\psi_{\\gamma},\\mu,\\bar{L}_{f_{1}},L_{g_{1}},{\\bf y}_{0},\\epsilon)$ . ", "page_idx": 7}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/0f5010affa064edd26447ae4b9331674da2a7e7c0bc4411fd525eedcf9cfb6dc.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "The convergence analysis of Algorithm 3 is in the existing literature [Nesterov, 2013, Lin and Xiao, 2014].   \nCombining [Lin and Xiao, 2014, Theorem 1] and Theorem 2.5, we have the following complexity result. ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.8. Suppose that Assumptions 2.1, 2.2, 3.1, 3.2, and 3.7 hold. Algorithm 3 can produce an $(\\epsilon,l_{F}^{-\\beta}\\epsilon^{\\beta})$ -optimal solution of problem (P) after at most $K$ iterations, where $K$ satisfies ", "page_idx": 7}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}^{\\operatorname*{max}\\{\\alpha,\\beta\\}}L_{g_{1}}}{\\epsilon^{\\operatorname*{max}\\{\\alpha-1,\\beta-1\\}}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Theorem 3.8 improves the complexity results of Theorem 3.3 significantly. Specifically, when $0<\\beta\\leq\\alpha=1$ , the convergence rate can be improved to be linear, i.e., $\\begin{array}{r}{K=\\mathcal{O}(\\sqrt{L_{f_{1}}/\\mu}\\log\\frac{1}{\\epsilon})}\\end{array}$ . ", "page_idx": 7}, {"type": "text", "text": "Additionally, we present an adaptive variant of PB-APG-sc, termed aPB-APG-sc, which adaptively executes $\\mathbf{x}_{k}=\\mathrm{PB-APG-sc}(\\phi_{k},\\psi_{k},\\mu,L_{f_{1}},L_{g_{1}},\\mathbf{x}_{k-1},\\epsilon_{k})$ and enjoys the similar complexity results of Algorithm 3, as delineated in Algorithm 4 within Appendix D.1. ", "page_idx": 7}, {"type": "text", "text": "3.2 The objectives are both non-smooth ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we focus on the scenario where both the upper- and lower-level objectives are non-smooth, namely, $f_{1}~=~g_{1}~\\equiv~0$ . Additionally, we assume that there is a point $x~\\in~C$ in the lower level problem, where $C$ is either $\\mathbb{R}^{n}$ (the unconstrained case) or a nonempty closed and convex set satisfying $\\bar{C}\\subseteq$ int $(\\operatorname{dom}(F)\\bigcap\\operatorname{dom}(G))$ . ", "page_idx": 7}, {"type": "text", "text": "It is worth noting that in the case where both $F$ and $G$ are non-smooth, the convergence result may not be as favorable as those in the previous scenarios. This is primarily due to the limited availability of information and unfavorable properties concerning $F$ and $G$ . In this case, we employ a subgradient method to solve problem $(\\mathbf{P}_{\\gamma})$ , which has been extensively studied in the existing literature [Shor, 2012, Bubeck et al., 2015, Beck, 2017, Nesterov, 2018]. Specifically, we update ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{x}_{k+1}=\\mathrm{Proj}_{C}(\\mathbf{x}_{k}-\\eta_{k}\\xi_{k}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\xi_{k}\\in\\partial\\Phi_{\\gamma}(\\mathbf{x}_{k})$ is an subgradient of $\\Phi_{\\gamma}(\\mathbf{x}_{k})$ , and $\\mathrm{Proj}_{C}(\\mathbf{x})$ is the projection of $\\mathbf{x}$ onto $C$ . ", "page_idx": 7}, {"type": "text", "text": "Let $\\mathbf{x}_{\\gamma}^{*}$ be an optimal solution of problem $\\displaystyle(\\mathrm{{P}}_{\\gamma})$ ) and suppose that there exists a constant $R$ such that $\\|\\mathbf{x}_{0}-\\mathbf{x}_{\\gamma}^{*}\\|\\leq$ $R$ . Motivated by Theorem 8.28 in Beck [2017], we establish the subsequent complexity result for problem (P). ", "page_idx": 7}, {"type": "text", "text": "Theorem 3.9. Suppose that Assumption 3.1(3) holds, $f_{2}$ and $g_{2}$ are $l_{f_{2}}$ - and $l_{g_{2}}$ -Lipschitz continuous, respectively. Set step-size \u03b7k = l\u03b3\u221aRk+1 in (4). Then, the subgradient method produces an $(\\epsilon,l_{f_{2}}^{-\\beta}\\epsilon^{\\beta})$ -optimal ", "page_idx": 7}, {"type": "text", "text": "solution of problem (P) after at most $K$ iterations, where $K$ satisfies ", "page_idx": 8}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{\\operatorname*{max}\\{2\\alpha,2\\beta\\}}l_{g_{2}}^{2}}{\\epsilon^{\\operatorname*{max}\\{2\\alpha,2\\beta\\}}}\\right).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "For non-smooth SBO problems, our method has lower complexity compared to existing approaches. Specifically, under a bounded domain assumption, Helou and Sim\u00f5es [2017] simply proposed an $\\epsilon$ -subgradient method with an asymptotic rate towards the optimal solution set. The a-IRG method in Kaushik and Yousefian [2021] achieved convergence rates of $\\mathcal{O}(1/\\epsilon^{\\frac{1}{0.5-b}})$ and $\\mathcal{O}(1/\\epsilon^{\\frac{1}{b}})$ for the upper- and lower-level objectives, respectively, where $b~\\in~(0,0.5)$ . Setting $b\\,=\\,0.25$ yields the convergence rates of ${\\mathcal{O}}(1/\\epsilon^{4})$ for both upper- and lower-level objectives, which indicates that our complexity is more efficient than theirs when $\\alpha<2$ and $\\beta\\leq\\alpha$ . Furthermore, the online framework proposed in Shen et al. [2023] performed a complexity of $\\mathcal{O}(1/\\epsilon^{3})$ for both upper- and lower-level objectives. Similarly, our approach prevails over theirs when $\\alpha<1.5$ and $\\beta\\leq\\alpha$ . ", "page_idx": 8}, {"type": "text", "text": "Strongly convex upper-level objective. Based on Theorem 8.31 in Beck [2017], we next explore the improved complexity result for problem (P) when $f_{2}$ is additionally strongly convex. ", "page_idx": 8}, {"type": "text", "text": "Theorem 3.10. Suppose that Assumption 3.1(3) holds, $C\\subseteq$ int $(\\operatorname{dom}(F)\\bigcap\\operatorname{dom}(G))$ , $f_{2}$ is $l_{f_{2}}$ -Lipschitz continuous and $\\mu_{f_{2}}$ -strongly convex3, and $g_{2}$ is $l_{g_{2}}$ -Lipschitz continuous. C hoose step-size $\\begin{array}{r}{\\eta_{k}\\,=\\,\\frac{2}{\\mu_{f_{2}}(k+1)}}\\end{array}$ in (4). Then, the subgradient method produces an $(\\epsilon,l_{f_{2}}^{-\\beta}\\epsilon^{\\beta})$ -optimal solution of problem (P) after at most $K$ iterations, where $K$ satisfies ", "page_idx": 8}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{\\operatorname*{max}\\{2\\alpha,2\\beta\\}}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon^{\\operatorname*{max}\\{2\\alpha-1,2\\beta-1\\}}}\\right).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "To our knowledge, within the context of Theorem 3.10, current findings fail to exploit strong convexity to enhance results. However, our approach capitalizes on distinct structural characteristics that yield superior complexity outcomes relative to Theorem 3.9 in cases where $\\alpha<2$ and $\\beta\\leq\\alpha$ . ", "page_idx": 8}, {"type": "text", "text": "4 Numerical experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We apply our Algorithms 1, 2, 3 and 4 to two simple bilevel optimization problems from the motivating examples in Appendix A. The performances of our methods are compared with several existing methods: MNG [Beck and Sabach, 2014], BiG-SAM [Sabach and Shtern, 2017], DBGD [Gong et al., 2021], a-IRG [Kaushik and Yousefian, 2021], CG-BiO [Jiang et al., 2023], Bi-SG [Merchav and Sabach, 2023] and R-APM [Samadi et al., 2023]. For practical efficiency, we use the Greedy FISTA algorithm proposed in Liang et al. [2022] as the APG method in our approach. Detailed settings and additional experimental results are presented in Appendix F. ", "page_idx": 8}, {"type": "image", "img_path": "oQ1Zj9iH88/tmp/3f560c206dee69e7ec9431bf8416ad7765b8ad66abc9b9bea33caee3fbf5fb84.jpg", "img_caption": ["Figure 1: Performances of methods in LRP. ", "Figure 2: Performances of methods in LSRP. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.1 Logistic regression problem (LRP) ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The LRP reads ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\frac{1}{2}\\|\\mathbf{x}\\|^{2}\\quad\\mathrm{s.t.~}\\mathbf{x}\\in\\underset{\\mathbf{z}\\in\\mathbb{R}^{n}}{\\arg\\operatorname*{min}}\\,\\frac{1}{m}\\sum_{i=1}^{m}\\log(1+\\exp(-\\mathbf{a}_{i}^{\\mathrm{T}}\\mathbf{z}b_{i}))+I_{C}(\\mathbf{z}),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $I_{C}(\\mathbf{x})$ is the indicator function of the set $C\\,=\\,\\{{\\mathbf{x}}\\,\\in\\,\\mathbb{R}^{n}\\,:\\,\\|{\\mathbf{x}}\\|_{1}\\,\\leq\\,\\theta\\}$ with $\\theta=10$ . Our goal is to find a solution to the lower-level problem with the smallest Euclidean norm. The upper-level objective only consists of the smooth part, which is 1-strongly convex and 1-smooth; meanwhile, the lower-level objective is a composite function, where the smooth part is ${\\frac{\\cdot_{1}}{4m}}\\lambda_{\\operatorname*{max}}(A^{\\mathrm{T}}A)$ -smooth, and the nonsmooth part is prox-friendly [Duchi et al., 2008]. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "In this experiment, we compare our methods with MNG, BiG-SAM, DBGD, a-IRG, CG-BiO, and Bi-SG. We plot the values of residuals of the lower-level objective $G(\\mathbf{x}_{k})-G^{*}$ and the upper-level objective over time in Figure 1. ", "page_idx": 9}, {"type": "text", "text": "As shown in Figure 1, the PB-APG, aPB-APG, PB-APG-sc, and aPB-APG-sc algorithms exhibit significantly faster convergence performance than the other methods for both lower- and upper-level objectives, although R-APM attains similar outcomes, our PB-APG and PB-APG-sc ensure a more rapid decline than it, as shown in the first subfigure of Figure 1. This is because our methods achieve lower optimal gaps and desired function values of the lower- and upper-level objectives with less execution time. This observation confirms the improved complexity results stated in the theorems above. Although the high exactness of our methods for the lower-level problem leads to larger upper-level objectives, Table 3 in Appendix F.1 shows that our methods are much closer to the optimal value. This is reasonable because the other methods exhibit lower accuracy at the lower-level problem, resulting in larger feasible sets compared to the lower-level optimal solution set $X_{\\mathrm{opt}}$ . In addition, Figure 1 demonstrates that aPB-APG and aPB-APG-sc outperform PB-APG and PB-APG-sc in terms of convergence rate. This improvement can be attributed to the adaptiveness incorporated in Algorithms 2 and 4. ", "page_idx": 9}, {"type": "text", "text": "4.2 Least squares regression problem (LSRP) ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "The LSRP has the following form: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\frac{\\tau}{2}\\|\\mathbf{x}\\|^{2}+\\|\\mathbf{x}\\|_{1}\\quad\\mathrm{s.t.}\\ \\mathbf{x}\\in\\underset{\\mathbf{z}\\in\\mathbb{R}^{n}}{\\arg\\operatorname*{min}}\\frac{1}{2m}\\left\\|A\\mathbf{z}-b\\right\\|^{2},\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where $\\tau=0.02$ regulates the trade-off between $\\ell_{1}$ and $\\ell_{2}$ norms. We aim to find a sparse solution for the lowerlevel problem. The upper-level objective is formulated as a composite function, which consists of a $\\tau$ -strongly convex and $\\tau$ -smooth component, along with a proximal-friendly non-smooth component [Beck, 2017]. The lower-level objective is a smooth function with a smoothness parameter of $\\textstyle{\\frac{1}{m}}\\lambda_{\\operatorname*{max}}({\\dot{A}}^{\\mathrm{T}}A)$ . ", "page_idx": 9}, {"type": "text", "text": "In this experiment, we compare the performances of our methods with a-IRG, BiG-SAM, and Bi-SG. We plot the values of residuals of lower-level objective $G(\\mathbf{x}_{k})-G^{*}$ and the upper-level objective over time in Figure 2. ", "page_idx": 9}, {"type": "text", "text": "Figure 2 shows that the proposed PB-APG, aPB-APG, PB-APG-sc, and aPB-APG-sc converge faster than the compared methods for both the lower- and upper-level objectives, as well. For the upper-level objective, our methods achieve larger function values than other methods, except BiG-SAM $\\delta=0.01$ ). This is because our methods attain higher accuracy for the lower-level objective than other methods. We have similar observations in Section 4.1. Furthermore, Figure 1 also demonstrates that the adaptive mechanism produces staircase-shaped curves for aPB-APG and aPB-APG-sc, which might prevent undesirable fluctuations in PB-APG and PB-APGsc. ", "page_idx": 9}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper proposes a penalization framework that effectively addresses the challenges inherent in simple bilevel optimization problems. By delineating the relationship between approximate solutions of the original problem and its penalized reformulation, we enable the application of specific methods under varying assumptions for the original problem. Under the H\u00f6lderian error bound condition, our methods achieve superior complexity results compared to the existing methods. The performance is further improved when the smooth component of the upper-level objective is strongly convex. Additionally, we extend our framework to scenarios involving general nonsmooth objectives. Numerical experiments also validate the effectiveness of our algorithms. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work is partly supported by the National Key R&D Program of China under grant 2023YFA1009300, National Natural Science Foundation of China under grants 12171100 and the Major Program of NFSC (72394360,72394364). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Samir Adly, Lo\u00efc Bourdin, and Fabien Caubet. On a decomposition formula for the proximal operator of the sum of two convex functions. Journal of Convex Analysis, 26(2):699\u2013718, 2019. ", "page_idx": 9}, {"type": "text", "text": "Mostafa Amini and Farzad Yousefian. An iterative regularized incremental projected subgradient method for a class of bilevel optimization problems. In 2019 American Control Conference (ACC), pages 4069\u20134074. IEEE, 2019. ", "page_idx": 10}, {"type": "text", "text": "Amir Beck. First-order methods in optimization. SIAM, 2017.   \nAmir Beck and Shoham Sabach. A first order method for finding minimal norm-like solutions of convex optimization problems. Mathematical Programming, 147(1-2):25\u201346, 2014.   \nAmir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183\u2013202, 2009.   \nLuca Bertinetto, Joao F Henriques, Philip HS Torr, and Andrea Vedaldi. Meta-learning with differentiable closed-form solvers. arXiv preprint arXiv:1805.08136, 2018.   \nDimitri Bertsekas, Angelia Nedic, and Asuman Ozdaglar. Convex analysis and optimization, volume 1. Athena Scientific, 2003.   \nNicholas Bishop, Long Tran-Thanh, and Enrico Gerding. Optimal learning from verified training data. Advances in Neural Information Processing Systems, 33:9520\u20139529, 2020.   \nJ\u00e9r\u00f4me Bolte, Trong Phong Nguyen, Juan Peypouquet, and Bruce W Suter. From error bounds to the complexity of first-order descent methods for convex functions. Mathematical Programming, 165:471\u2013507, 2017.   \nDigvijay Boob, Qi Deng, and Guanghui Lan. Stochastic first-order methods for convex and nonconvex functional constrained optimization. Mathematical Programming, 197(1):215\u2013279, 2023.   \nS\u00e9bastien Bubeck et al. Convex optimization: Algorithms and complexity. Foundations and Trends\u00ae in Machine Learning, 8(3-4):231\u2013357, 2015.   \nJames V. Burke and Sien Deng. Weak sharp minima revisited, part ii: application to linear regularity and error bounds. Mathematical Programming, 104(2-3):235\u2013261, 2005.   \nJames V Burke and Michael C Ferris. Weak sharp minima in mathematical programming. SIAM Journal on Control and Optimization, 31(5):1340\u20131359, 1993.   \nAlexandre Cabot. Proximal point algorithm controlled by a slowly vanishing term: applications to hierarchical minimization. SIAM Journal on Optimization, 15(2):555\u2013572, 2005.   \nH. Chen, H. Xu, R. Jiang, et al. Lower-level duality based reformulation and majorization minimization algorithm for hyperparameter optimization. In Proceedings of the International Conference on Artificial Intelligence and Statistics, pages 784\u2013792. PMLR, 2024.   \nL. Chen, J. Xu, and J. Zhang. Bilevel optimization without lower-level strong convexity from the hyperobjective perspective. arXiv preprint arXiv:2301.00712, 2023.   \nDamek Davis and Dmitriy Drusvyatskiy. Stochastic model-based minimization of weakly convex functions. SIAM Journal on Optimization, 29(1):207\u2013239, 2019.   \nStephan Dempe, Nguyen Dinh, Joydeep Dutta, and Tanushree Pandit. Simple bilevel programming and extensions. Mathematical Programming, 188:227\u2013253, 2021.   \nLior Doron and Shimrit Shtern. Methodology and first-order algorithms for solving nonsmooth and nonstrongly convex bilevel optimization problems. Mathematical Programming, 201:521\u2013558, 2023.   \nDmitriy Drusvyatskiy and Adrian S. Lewis. Error bounds, quadratic growth, and linear convergence of proximal methods. Mathematics of operations research, 43(3):919\u2013948, 2018a.   \nDmitriy Drusvyatskiy and Adrian S Lewis. Error bounds, quadratic growth, and linear convergence of proximal methods. Mathematics of Operations Research, 43(3):919\u2013948, 2018b.   \nJohn Duchi, Shai Shalev-Shwartz, Yoram Singer, and Tushar Chandra. Efficient projections onto the l 1-ball for learning in high dimensions. In Proceedings of the 25th international conference on Machine learning, pages 272\u2013279, 2008.   \nJoydeep Dutta and Tanushree Pandit. Algorithms for simple bilevel programming. Bilevel Optimization: Advances and Next Challenges, pages 253\u2013291, 2020.   \nLuca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo Grazzi, and Massimiliano Pontil. Bilevel programming for hyperparameter optimization and meta-learning. In International conference on machine learning, pages 1568\u20131577. PMLR, 2018.   \nMichael P Friedlander and Paul Tseng. Exact regularization of convex programs. SIAM Journal on Optimization, 18(4):1326\u20131350, 2008.   \nKhanh-Hung Giang-Tran, Nam Ho-Nguyen, and Dabeen Lee. Projection-free methods for solving convex bilevel optimization problems. arXiv preprint arXiv:2311.09738, 2023.   \nChengyue Gong, Xingchao Liu, and Qiang Liu. Bi-objective trade-off with dynamic barrier gradient descent. In International Conference on Neural Information Processing Systems, pages 29630\u201329642, 2021.   \nElias S Helou and Lucas EA Sim\u00f5es. \u03f5-subgradient algorithms for bilevel convex optimization. Inverse Problems, 33(5):055020, 2017.   \nF. Huang. On momentum-based gradient methods for bilevel optimization with nonconvex lower-level. arXiv preprint arXiv:2303.03944, 2023.   \nRuichen Jiang, Nazanin Abolfazli, Aryan Mokhtari, and Erfan Yazdandoost Hamedani. A conditional gradientbased method for simple bilevel optimization with convex lower-level problem. In International Conference on Artificial Intelligence and Statistics, pages 10305\u201310323. PMLR, 2023.   \nRujun Jiang and Xudong Li. H\u00f6lderian error bounds and kurdyka-\u0142ojasiewicz inequality for the trust region subproblem. Mathematics of Operations Research, 47(4):3025\u20133050, 2022.   \nHarshal D. Kaushik and Farzad Yousefian. A method with convergence rates for optimization problems with variational inequality constraints. SIAM Journal on Optimization, 31(3):2171\u20132198, 2021.   \nMatthias Kissel, Martin Gottwald, and Klaus Diepold. Neural network training with safe regularization in the null space of batch activations. In Artificial Neural Networks and Machine Learning\u2013ICANN 2020: 29th International Conference on Artificial Neural Networks, Bratislava, Slovakia, September 15\u201318, 2020, Proceedings, Part II 29, pages 217\u2013228. Springer, 2020.   \nPuya Latafat, Andreas Themelis, Silvia Villa, and Panagiotis Patrinos. Adabim: An adaptive proximal gradient method for structured convex bilevel optimization. arXiv preprint arXiv:2305.03559, 2023.   \nJingwei Liang, Tao Luo, and Carola-Bibiane Schonlieb. Improving fast iterative shrinkage-thresholding algorithm: Faster, smarter, and greedier. SIAM Journal on Scientific Computing, 44(3):A1069\u2013A1091, 2022.   \nQihang Lin and Lin Xiao. An adaptive accelerated proximal gradient method and its homotopy continuation for sparse optimization. In International Conference on Machine Learning, pages 73\u201381. PMLR, 2014.   \nZhi-Quan Luo, Jong-Shi Pang, Daniel Ralph, and Shi-Quan Wu. Exact penalization and stationarity conditions of mathematical programs with equilibrium constraints. Mathematical Programming, 75(1):19\u201376, 1996.   \nYura Malitsky. Chambolle-Pock and Tsengs methods: relationship and extension to the bilevel optimization. arXiv preprint arXiv:1706.02602, 2017.   \nRoey Merchav and Shoham Sabach. Convex bi-level optimization problems with nonsmooth outer objective function. SIAM Journal on Optimization, 33(4):3114\u20133142, 2023.   \nHong Mingyi, Wai Hoi-To, Wang Zhaoran, and Zhuoran Yang. A two-timescale framework for bilevel optimization: Complexity analysis and application to actor-critic. arXiv preprint arXiv:2007.05170, 2020.   \nArkadij Semenovic\u02c7 Nemirovsky and David Borisovich Yudin. Problem complexity and method efficiency in optimization. Wiley, 1983.   \nYurii Nesterov. Gradient methods for minimizing composite functions. Mathematical programming, 140(1): 125\u2013161, 2013.   \nYurii Nesterov. Lectures on convex optimization, volume 137. Springer, 2018.   \nJong Shi Pang. Error bounds in mathematical programming. Mathematical Programming, 79(1-3):299\u2013332, 1997.   \nNelly Pustelnik and Laurent Condat. Proximity operator of a sum of functions; application to depth map estimation. IEEE Signal Processing Letters, 24(12):1827\u20131831, 2017.   \nAravind Rajeswaran, Chelsea Finn, Sham M Kakade, and Sergey Levine. Meta-learning with implicit gradients. Advances in neural information processing systems, 32, 2019.   \nVincent Roulet and Alexandre d\u2019Aspremont. Sharpness, restart and acceleration. SIAM Journal on Optimization, 30(1):262\u2013289, 2020.   \nShoham Sabach and Shimrit Shtern. A first order method for solving convex bilevel optimization problems. SIAM Journal on Optimization, 27(2):640\u2013660, 2017.   \nSepideh Samadi, Daniel Burbano, and Farzad Yousefian. Achieving optimal complexity guarantees for a class of bilevel convex optimization problems. arXiv preprint arXiv:2310.12247, 2023.   \nAmirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron Boots. Truncated back-propagation for bilevel optimization. In The 22nd International Conference on Artificial Intelligence and Statistics, pages 1723\u2013 1732. PMLR, 2019.   \nHan Shen and Tianyi Chen. On penalty-based bilevel gradient descent method. In Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 30992\u201331015. PMLR, 23\u201329 Jul 2023.   \nLingqing Shen, Nam Ho-Nguyen, and Fatma K\u0131l\u0131n\u00e7-Karzan. An online convex optimization-based framework for convex bilevel optimization. Mathematical Programming, 198(2):1519\u20131582, 2023.   \nNaum Zuselevich Shor. Minimization methods for non-differentiable functions, volume 3. Springer Science & Business Media, 2012.   \nMikhail Solodov. An explicit descent method for bilevel convex optimization. Journal of Convex Analysis, 14 (2):227\u2013237, 2007.   \nD. Sow, K. Ji, Z. Guan, and et al. A primal-dual approach to bilevel optimization with multiple inner minima. arXiv preprint arXiv:2203.01123, 2022.   \nMarcin Studniarski and Doug E Ward. Weak sharp minima: characterizations and sufficient conditions. SIAM Journal on Control and Optimization, 38(1):219\u2013236, 1999.   \nAndre Nikolaevich Tikhonov and V. I. A. K. Arsenin. Solutions of ill-posed problems. Wiley, 1977.   \nPaul Tseng. On accelerated proximal gradient methods for convex-concave optimization. unpublished manuscript, 2008.   \nJiali Wang, He Chen, Rujun Jiang, Xudong Li, and Zihao Li. Fast algorithms for stackelberg prediction game with least squares loss. In International Conference on Machine Learning, pages 10708\u201310716. PMLR, 2021.   \nJiali Wang, Wen Huang, Rujun Jiang, Xudong Li, and Alex L Wang. Solving stackelberg prediction game with least squares loss via spherically constrained least squares reformulation. In International Conference on Machine Learning, pages 22665\u201322679. PMLR, 2022.   \nBlake E Woodworth and Nati Srebro. Tight complexity bounds for optimizing composite objectives. Advances in neural information processing systems, 29, 2016.   \nYangyang Xu. First-order methods for problems with o (1) functional constraints can have almost the same convergence rate as for unconstrained problems. SIAM Journal on Optimization, 32(3):1759\u20131790, 2022.   \nYao-Liang Yu. On decomposing the proximal map. Advances in neural information processing systems, 26, 2013.   \nJinshan Zeng, Tim Tsz-Kit Lau, Shaobo Lin, and Yuan Yao. Global convergence of block coordinate descent in deep learning. In International conference on machine learning, pages 7313\u20137323. PMLR, 2019.   \nZirui Zhou and Anthony Man-Cho So. A unified approach to error bounds for structured convex optimization problems. Mathematical Programming, 165:689\u2013728, 2017. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Motivating examples ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Many machine learning applications involve a primary objective $G$ , which usually represents the training loss, and a secondary objective $F$ , which can be a regularization term or an auxiliary loss. A common approach for such problems is to optimize $G$ fully and then use $F$ to select the optimal solutions from the ones obtained for $G$ . This is called lexicographic optimization [Kissel et al., 2020, Gong et al., 2021]. Two classes of lexicographic optimization problems are the regularized problem, also known as the ill-posed optimization problem [Amini and Yousefian, 2019, Jiang et al., 2023], and the over-parameterized regression [Jiang et al., 2023], where the upper-level objectives are the regularization terms or loss functions, and the lower-level objectives are the loss functions and the constraint terms. We present some examples of these classes of problems as follows. ", "page_idx": 13}, {"type": "text", "text": "Example A.1 (Linear Inverse Problems). Linear inverse problems aim to reconstruct a vector $\\mathbf{x}\\,\\in\\,\\mathbb{R}^{n}$ from measurements $b\\in\\mathbb{R}^{m}$ that satisfy $b\\,=\\,A\\mathbf{x}+\\rho\\varepsilon$ , where $A:\\mathbb{R}^{n}\\,\\rightarrow\\,\\mathbb{R}^{m}$ is a linear mapping, $\\varepsilon\\,\\in\\,\\mathbb{R}^{m}$ is unknown noise, and $\\rho>0$ is its magnitude. Various optimization techniques can address these problems. We focus on the bilevel formulation, widely adopted in the literature [Beck and Sabach, 2014, Sabach and Shtern, 2017, Dempe et al., 2021, Latafat et al., 2023, Merchav and Sabach, 2023]. ", "page_idx": 13}, {"type": "text", "text": "The lower-level objective in the bilevel formulation is given by ", "page_idx": 13}, {"type": "equation", "text": "$$\nG(\\mathbf{x})=\\frac{1}{2m}\\left\\|A\\mathbf{x}-b\\right\\|^{2}+I_{C}(\\mathbf{x}),\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $I_{C}(\\mathbf{x})$ is the indicator function of a set $C$ that satifies $I_{C}(\\mathbf{x})\\,=\\,0$ if $\\textbf{x}\\in{\\cal C}$ , and $I_{C}(\\mathbf{x})\\,=\\,+\\infty$ if $\\textbf{x}\\notin\\ C$ . The set $C$ is a closed, convex set that can be chosen as $C\\,=\\,\\mathbb{R}^{n}$ , $C\\,=\\,\\{{\\mathbf{x}}\\,\\in\\,\\mathbb{R}^{n}\\,:\\,{\\mathbf{x}}\\,\\geq\\,0\\}$ , or $C=\\{\\mathbf{x}\\in\\mathbb{R}^{n}:\\|\\mathbf{x}\\|_{1}\\leq\\theta\\}$ for some $\\theta>0$ . ", "page_idx": 13}, {"type": "text", "text": "This problem may have multiple minimizer solutions. Hence, a reasonable option is to consider the minimal norm solution problem, i.e., find the optimal solution with the smallest Euclidean norm [Beck and Sabach, 2014, Sabach and Shtern, 2017, Latafat et al., 2023]: ", "page_idx": 13}, {"type": "equation", "text": "$$\nF(\\mathbf{x})={\\frac{1}{2}}\\left\\|\\mathbf{x}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "We need to solve the simple bilevel optimization problem: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\frac{1}{2}\\|\\mathbf{x}\\|^{2}\\quad\\mathrm{s.t.~}\\,\\mathbf{x}\\in\\underset{\\mathbf{z}\\in\\mathbb{R}^{n}}{\\arg\\operatorname*{min}}\\frac{1}{2m}\\left\\|A\\mathbf{z}-b\\right\\|^{2}+I_{C}(\\mathbf{z}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Example A.2 (Sparse Solution of Linear Inverse Problems). Consider the same setting as in Example A.1, but with the additional goal of finding a sparse solution among all the minimizers of the linear inverse problem (7). This can simplify the model and improve computational efficiency. To achieve sparsity, we can use any function that encourages it. One such function is the well-known elastic net regularization [Friedlander and Tseng, 2008, Amini and Yousefian, 2019, Merchav and Sabach, 2023], which is defined as ", "page_idx": 13}, {"type": "equation", "text": "$$\nF(\\mathbf{x})=\\left\\|\\mathbf{x}\\right\\|_{1}+{\\frac{\\tau}{2}}\\left\\|\\mathbf{x}\\right\\|^{2},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\tau>0$ regulates the trade-off between $\\ell_{1}$ and $\\ell_{2}$ norms. ", "page_idx": 13}, {"type": "text", "text": "This example corresponds to our second experiment in Section 4.2. ", "page_idx": 13}, {"type": "text", "text": "Example A.3 (Logistic Regression Problem). The logistic regression problem aims to map the feature vectors ${\\bf a}_{i}$ to the target labels $b_{i}$ . A standard machine learning technique for this problem is to minimize the logistic loss function over the given dataset [Amini and Yousefian, 2019, Gong et al., 2021, Jiang et al., 2023, Latafat et al., 2023, Merchav and Sabach, 2023]. We assume that the dataset consists of a feature matrix $A\\in\\mathbb{R}^{m\\times n}$ and a label vector $b\\in\\mathbb{R}^{m}$ , with $b_{i}\\in\\{-1,1\\}$ for each $i$ . The logistic loss function is defined as ", "page_idx": 13}, {"type": "equation", "text": "$$\ng_{1}(\\mathbf{x})=\\frac{1}{m}\\sum_{i=1}^{m}\\log(1+\\exp(-\\mathbf{a}_{i}^{\\mathrm{T}}\\mathbf{x}b_{i})).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Over-fitting is a common issue when the number of features is large compared to the number of instances $m$ . A possible approach is to regularize the logistic objective function with a specific function or a constraint [Jiang et al., 2023, Merchav and Sabach, 2023]. For instance, we can use $g_{2}\\big(\\mathbf{x}\\big)^{\\flat}=I_{C}(\\mathbf{x})$ , where $I_{C}(\\mathbf{x})$ is the indicator of the set $C=\\{\\mathbf{x}\\in\\mathbb{R}^{n}:\\|\\mathbf{x}\\|_{1}\\leq\\theta\\}$ , as in Example A.1. ", "page_idx": 13}, {"type": "text", "text": "This problem may also have multiple optimal solutions. Hence, a natural extension is to consider the minimal norm solution problem [Gong et al., 2021, Jiang et al., 2023, Latafat et al., 2023], as in Example A.1. This requires solving the following problem: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}\\frac{1}{2}\\|\\mathbf{x}\\|^{2}\\quad\\mathrm{s.t.~}\\mathbf{x}\\in\\underset{\\mathbf{z}\\in\\mathbb{R}^{n}}{\\arg\\operatorname*{min}}\\,\\frac{1}{m}\\sum_{i=1}^{m}\\log(1+\\exp(-\\mathbf{a}_{i}^{\\mathrm{T}}\\mathbf{z}b_{i}))+I_{C}(\\mathbf{z}).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "When choosing $C=\\{\\mathbf{x}\\in\\mathbb{R}^{n}:\\|\\mathbf{x}\\|_{1}\\leq\\theta\\}$ for some $\\theta>0$ , it corresponds to our first experiment in Section 4.1. ", "page_idx": 14}, {"type": "text", "text": "Example A.4 (Over-parameterized Regression Problem). The linear regression problem aims to find a parameter vector $\\textbf{x}\\in\\mathbb{R}^{n}$ that minimizes the training loss $\\ell_{\\mathrm{tr}}(\\mathbf{x})$ over the training dataset $\\mathcal{D}_{\\mathrm{tr}}$ . Without explicit regularization, the over-parameterized regression problem has multiple minima. However, these minima may have different generalization performance. Therefore, we introduce a secondary objective, such as the validation loss over a validation set $\\mathcal{D}_{\\mathrm{val}}$ , to select one of the global minima of the training loss. This results in the following bilevel problem: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\mathbf{x}\\in\\mathbb{R}^{n}}F(\\mathbf{x}):=\\ell_{\\mathrm{val}}(\\mathbf{x})\\quad\\mathrm{s.t.~}\\,\\mathbf{x}\\in\\arg\\operatorname*{min}_{\\mathbf{z}\\in\\mathbb{R}^{n}}G(\\mathbf{z}):=\\ell_{\\mathrm{tr}}(\\mathbf{z}).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "For instance, we can consider the sparse linear regression problem, where the lower-level objective consists of the training error and a regularization term, namely, $\\begin{array}{r}{\\dot{G(\\mathbf{x})}\\,=\\,\\frac{1}{2}\\|A_{\\mathrm{tr}}\\mathbf{x}-b_{\\mathrm{tr}}\\|^{2}+I_{C}(\\mathbf{x})}\\end{array}$ . Here, $I_{C}(\\mathbf{x})$ denotes the indicator of a convex set, as in Example A.2. The upper-level objective is the validation error, i.e., $\\begin{array}{r}{F(\\mathbf{x})=\\frac{1}{2}\\|A_{\\mathrm{val}}\\mathbf{x}-b_{\\mathrm{val}}\\|^{2}}\\end{array}$ . The linear regression problem is over-parameterized when the number of features $n$ is larger than the number of data instances in the training set. ", "page_idx": 14}, {"type": "text", "text": "B Comparison between simple bilevel optimization methods ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Table 1: Summary of simple bilevel optimization algorithms. The abbreviations \u201cSC,\" \u201cC,\", \u201cdiff\", \u201ccomp\", \u201cWS\" and $\\bullet\\epsilon{\\bf C}3\"$ represent \u201cstrongly convex,\" \u201cconvex,\", \u201cdifferentiable\", \u201ccomposite\", \u201cweak sharpness\" and \u201cConvex objective with Convex Compact constraints,\" respectively. The abbreviation $\\alpha$ -HEB refers to H\u00f6lderian error bound with exponent parameter $\\alpha$ . We only include the gradients Lipschitz constant in the complexity result when its relation to the complexity is clear; otherwise, we omit it. Notation $l_{F}$ is the upper bound of subdifferentials of $F$ , $L_{f_{1}}$ and $L_{g_{1}}$ are the Lipschitz constants of $\\nabla f_{1}$ and $\\nabla g_{1}$ , respectively. ", "page_idx": 14}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/5b68580432d503c96df8b26f108d85198a1d383114551ec0ba9091f8744c020d.jpg", "table_caption": [], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "C Examples of functions satisfying the H\u00f6lderian error bound ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We present several examples of functions that satisfy the H\u00f6lderian error bound Assumption 2.2 and their corresponding exponent parameter $\\alpha$ in Table 2. We also provide some clarifications for Table 2 below. The abbreviations $^{\\ast}Q\\in\\mathbb{S}^{n,\\ast}$ and $^{\\ast}Q\\succ0^{\\ast}$ stand for $^{\\ast}Q$ is a symmetric matrix of order $_n$ and a positive definite matrix, respectively. We refer the reader to Pang [1997], Bolte et al. [2017], Zhou and So [2017], Jiang and Li [2022], Doron and Shtern [2023] and the references therein for more examples of functions that satisfy H\u00f6lderian error bound Assumption 2.2. Furthermore, it is noteworthy that numerous applications in neural networks, such as deep neural networks (DNNs), also comply with this assumption, as discussed in Bolte et al. [2017], Zeng et al. [2019]. ", "page_idx": 14}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/d09f7cf898e18ee064f28f3e3a198c21e298e75844511ba69168a79b54c77cf0.jpg", "table_caption": ["Table 2: Summary of some functions satisfying H\u00f6lderian error bound with corresponding exponents. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "D Supplementary results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "D.1 Adaptive version of PB-APG method with strong convexity assumption ", "text_level": 1, "page_idx": 15}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/7c69be0c6cf7a4daed7fea0d117504986ac57b098c120223b93c8649499f46ba.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Similar to Algorithm 2, we have the following convergence results of Algorithm 4. ", "page_idx": 15}, {"type": "text", "text": "Theorem D.1. Suppose that Assumptions 2.1, 2.2, 3.1, 3.2, and 3.7 hold. Let $\\epsilon_{0}>0$ be given. ", "page_idx": 15}, {"type": "text", "text": "Then, for any $k\\geq N$ , Algorithm 2 generates an $\\Big(\\frac{\\epsilon_{0}}{\\eta^{k}}\\,,\\,\\frac{2\\epsilon_{0}}{\\eta^{k}(\\gamma_{0}\\nu^{k}\\!-\\!\\gamma_{k}^{*})}\\Big)$ -optimal solution of problem (P) after at most $K$ iterations, where $K$ satisfies ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{\\eta^{k}}{\\epsilon_{0}}+\\sqrt{\\frac{\\nu^{k}l_{F}^{\\operatorname*{max}\\{\\alpha,\\beta\\}}L_{g_{1}}}{\\epsilon^{\\operatorname*{max}\\{\\alpha-1,\\beta-1\\}}}}\\log\\frac{\\eta^{k}}{\\epsilon_{0}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The proof is similar to the proof of Theorem 3.5 in Appendix E.8. So we omit it here. ", "page_idx": 15}, {"type": "text", "text": "E Proofs of main results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we propose the proofs of our main convergence results in this paper. ", "page_idx": 15}, {"type": "text", "text": "E.1 Proof of Lemma 2.3 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof. Since $X_{\\mathrm{opt}}$ is closed and convex [Beck and Sabach, 2014], the projection of any $\\textbf{x}\\in\\mathbb{R}^{n}$ onto $X_{\\mathrm{opt}}$ , denoted as $\\bar{\\bf x}$ , exists and is unique. Furthermore, it holds that d $\\mathrm{ist}(\\mathbf{x},X_{\\mathrm{opt}})=\\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|$ . ", "page_idx": 15}, {"type": "text", "text": "Then, by Assumption 2.1, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F(\\mathbf{x})-F(\\bar{\\mathbf{x}})\\geq-\\xi^{\\top}(\\mathbf{x}-\\bar{\\mathbf{x}})\\geq-\\|\\xi\\|\\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|\\geq-l_{F}\\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|,\\,\\forall\\xi\\in\\partial F(\\bar{\\mathbf{x}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Choosing $\\gamma^{\\ast}=\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon^{1-\\alpha}$ , it follows that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{F(\\mathbf{x})-F(\\bar{\\mathbf{x}})+\\gamma^{*}p(\\mathbf{x})\\overset{(10)}{\\geq}-l_{F}\\Vert\\mathbf{x}-\\bar{\\mathbf{x}}\\Vert+\\gamma^{*}p(\\mathbf{x})}\\\\ &{\\overset{(a)}{\\geq}-l_{F}\\Vert\\mathbf{x}-\\bar{\\mathbf{x}}\\Vert+\\frac{\\gamma^{*}}{\\rho}\\Vert\\mathbf{x}-\\bar{\\mathbf{x}}\\Vert^{\\alpha}}\\\\ &{\\overset{\\geq}\\underbrace{\\operatorname*{min}}_{\\geq0}-l_{F}\\mathbf{z}+\\frac{\\gamma^{*}}{\\rho}\\mathbf{z}^{\\alpha}}\\\\ &{\\overset{(b)}{=}-\\epsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $(a)$ follows from the H\u00f6lderian error bound assumption of $p(\\mathbf x)$ , and $(b)$ is from the fact that $\\textbf{y}=$ $\\begin{array}{r}{-l_{F}\\mathbf{z}+\\frac{\\gamma^{\\ast}}{\\rho}\\mathbf{z}^{\\alpha}}\\end{array}$ attains its minimum at $\\begin{array}{r}{\\mathbf{z}^{\\ast}=\\left(\\frac{\\rho l_{F}}{\\alpha\\gamma^{\\ast}}\\right)^{\\frac{1}{\\alpha-1}}}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "Since $\\bar{\\bf x}\\in X_{\\mathrm{opt}}$ is feasible for problem (P), we have $F(\\bar{\\bf x})\\geq F^{*}$ . This along with (11) indicates ", "page_idx": 16}, {"type": "equation", "text": "$$\nF(\\mathbf{x})+\\gamma p(\\mathbf{x})-F^{*}\\geq F(\\mathbf{x})+\\gamma^{*}p(\\mathbf{x})-F(\\bar{\\mathbf{x}})\\geq-\\epsilon,\\quad\\forall\\mathbf{x}\\in\\mathbb{R}^{d}\\;{\\mathrm{and}}\\;\\gamma\\geq\\gamma^{*}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $\\mathbf{x}^{*}$ be an optimal solution of (P) so that $F(\\mathbf{x}^{*})=F^{*}$ . In addition, since $\\mathbf{x}^{*}\\in X_{\\mathrm{opt}}$ , we have $p(\\mathbf{x}^{*})=0$ . Combine these results with (12), we have ", "page_idx": 16}, {"type": "equation", "text": "$$\nF(\\mathbf{x}^{*})+\\gamma p(\\mathbf{x}^{*})=F^{*}\\overset{(12)}{\\leq}F(\\mathbf{x})+\\gamma p(\\mathbf{x})+\\epsilon,\\quad\\forall\\mathbf{x}\\in\\mathbb{R}^{d}\\mathrm{~and~}\\gamma\\geq\\gamma^{*}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "This demonstrates that an optimal solution of (P) is an $\\epsilon$ -optimal solution for $(\\mathrm{P}_{\\gamma})$ . ", "page_idx": 16}, {"type": "text", "text": "E.2 Proof of Lemma 2.4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof. The proof is motivated by Theorem 1 in Luo et al. [1996]. Denote $\\mathbf{x}^{*},\\mathbf{x}_{\\gamma}^{*}$ as optimal solutions of problem $({\\bf P})$ and $(\\mathbf{P}_{\\gamma})$ , respectively. ", "page_idx": 16}, {"type": "text", "text": "For any $\\mathbf{x}\\in\\mathbb{R}^{n}$ , let $\\bar{\\bf x}$ be the projection of $\\mathbf{x}$ onto $X_{\\mathrm{opt}}$ . Then $\\bar{\\bf x}$ is a feasible solution of (P) and $F(\\bar{\\mathbf{x}})\\geq F(\\mathbf{x}^{*})$ holds. Then we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{F(\\mathbf{x})+\\gamma p(\\mathbf{x})=F(\\bar{\\mathbf{x}})+F(\\mathbf{x})-F(\\bar{\\mathbf{x}})+\\gamma p(\\mathbf{x})}\\\\ &{\\phantom{a a a a a a}\\geq F(\\mathbf{x}^{*})+F(\\mathbf{x})-F(\\bar{\\mathbf{x}})+\\gamma p(\\mathbf{x})}\\\\ &{\\phantom{a a a a a a a}\\geq F(\\mathbf{x}^{*})-l_{F}\\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|+\\frac{\\gamma}{\\rho}\\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|}\\\\ &{\\phantom{a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a}}\\\\ &{\\phantom{a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a}}=F(\\mathbf{x}^{*})+(\\frac{\\gamma}{\\rho}-l_{F})\\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|}\\\\ &{\\phantom{a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a}}}\\\\ &{\\phantom{a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a a}}\\sum_{k}F(\\mathbf{x}^{*})=F(\\mathbf{x}^{*})+\\gamma p(\\mathbf{x}^{*}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $(a)$ follows from (10) and the H\u00f6lderian error bound assumption of $p(\\mathbf{x})$ , and $(b)$ follows from $\\gamma\\ge\\rho l_{F}$ .   \nTherefore, we conclude that $\\mathbf{x}^{*}$ is an optimal solution of $(\\mathbf{P}_{\\gamma})$ . ", "page_idx": 16}, {"type": "text", "text": "For the converse part, let $\\bar{\\mathbf{x}}_{\\gamma}^{*}$ be the projection of $\\mathbf{x}_{\\gamma}^{*}$ onto $X_{\\mathrm{opt}}$ . Then $\\bar{\\mathbf{x}}_{\\gamma}^{*}$ is a feasible solution of (P). Therefore, it holds that $F(\\bar{\\mathbf{x}}_{\\gamma}^{\\bar{*}})\\geq F(\\mathbf{x}^{*})$ . Similarly, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{F(\\mathbf{x^{*}})=F(\\mathbf{x^{*}})+\\gamma p(\\mathbf{x^{*}})}\\\\ &{\\phantom{\\sum}\\ge F(\\mathbf{x_{\\gamma}^{*}})+\\gamma p(\\mathbf{x_{\\gamma}^{*}})}\\\\ &{\\phantom{\\sum}=F(\\mathbf{x_{\\gamma}^{*}})-F(\\mathbf{x^{*}})+F(\\mathbf{x^{*}})+\\gamma p(\\mathbf{x_{\\gamma}^{*}})}\\\\ &{\\phantom{\\sum}E(\\mathbf{x^{*}})+F(\\mathbf{x_{\\gamma}^{*}})-F(\\bar{\\mathbf{x}_{\\gamma}^{*}})+\\gamma p(\\mathbf{x_{\\gamma}^{*}})}\\\\ &{\\overset{\\textmd{(c)}}\\ge F(\\mathbf{x^{*}})-l_{F}\\Vert\\mathbf{x_{\\gamma}^{*}}-\\bar{\\mathbf{x}_{\\gamma}^{*}}\\Vert+\\frac{\\gamma}{\\rho}\\Vert\\mathbf{x_{\\gamma}^{*}}-\\bar{\\mathbf{x}_{\\gamma}^{*}}\\Vert}\\\\ &{\\ge F(\\mathbf{x^{*}})+(\\frac{\\gamma}{\\rho}-l_{F})\\Vert\\mathbf{x_{\\gamma}^{*}}-\\bar{\\mathbf{x}_{\\gamma}^{*}}\\Vert}\\\\ &{\\ge F(\\mathbf{x^{*}}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the inequality $(c)$ follows from (10) and the H\u00f6lderian error bound assumption of $p(\\mathbf{x})$ . ", "page_idx": 16}, {"type": "text", "text": "Therefore, all inequalities in (15) become equalities. We deduce that $\\|\\mathbf{x}_{\\gamma}^{*}-\\bar{\\mathbf{x}}_{\\gamma}^{*}\\|=0$ if $\\gamma>\\rho l_{F}$ , implying that $\\mathbf{x}_{\\gamma}^{*}$ is in $X_{\\mathrm{opt}}$ , i.e., $p(\\mathbf{x}_{\\gamma}^{*})=0$ . Furthermore, as the first inequality of (15) becomes an equality, we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\nF(\\mathbf{x}^{*})=F(\\mathbf{x}_{\\gamma}^{*})+\\gamma p(\\mathbf{x}_{\\gamma}^{*})=F(\\mathbf{x}_{\\gamma}^{*}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Therefore, $\\mathbf{x}_{\\gamma}^{*}$ is also an optimal solution of (P). ", "page_idx": 16}, {"type": "text", "text": "E.3 Proof of Theorem 2.5 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. Denote $\\mathbf{x}^{*}$ , $\\mathbf{x}_{\\gamma}^{*}$ as optimal solutions of problem (P) and $(\\mathbf{P}_{\\gamma})$ , respectively. ", "page_idx": 17}, {"type": "text", "text": "\u2022 Case of $\\alpha>1$ . Since $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an $\\epsilon$ -optimal solution of $(\\mathbf{P}_{\\gamma})$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nF(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})\\leq F(\\mathbf{x})+\\gamma p(\\mathbf{x})+\\epsilon,\\quad\\forall\\mathbf{x}\\in\\mathbb{R}^{n}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Note that the arguments in the proof of Lemma 2.3 still hold. Substituting $\\mathbf{x}\\,=\\,\\mathbf{x}^{*}$ into (16) and utilizing $p(\\mathbf{x}^{*})=0$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nF(\\widetilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma p(\\widetilde{\\mathbf{x}}_{\\gamma}^{*})\\leq F(\\mathbf{x}^{*})+\\epsilon=F(\\mathbf{x}^{*})+\\gamma^{*}p(\\mathbf{x}^{*})+\\epsilon\\leq F(\\widetilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma^{*}p(\\widetilde{\\mathbf{x}}_{\\gamma}^{*})+2\\epsilon,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last inequality follows from setting $\\mathbf{x}=\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ in (13). Then, it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\np(\\tilde{\\bf x}_{\\gamma}^{*})\\leq\\frac{2\\epsilon}{\\gamma-\\gamma^{*}}=\\frac{2\\epsilon}{2l_{F}^{\\beta}\\epsilon^{1-\\beta}}=l_{F}^{-\\beta}\\epsilon^{\\beta}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "By setting $\\mathbf{x}=\\mathbf{x}^{*}$ in (16), we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nF(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-F(\\mathbf{x}^{*})\\leq\\gamma(p(\\mathbf{x}^{*})-p(\\tilde{\\mathbf{x}}_{\\gamma}^{*}))+\\epsilon.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Using the fact that $p(\\mathbf{x}^{*})=0\\leq p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})$ , we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nF(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-F(\\mathbf{x}^{*})\\leq\\epsilon.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Combing (18) with (17), we conclude that $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an $(\\epsilon,l_{F}^{-\\beta}\\epsilon^{\\beta})$ -optimal solution of (P). ", "page_idx": 17}, {"type": "text", "text": "\u2022 Case of $\\alpha=1$ . Since $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an $\\epsilon$ -optimal solution of $\\displaystyle(\\mathbf{P}_{\\gamma})$ ), we have ", "page_idx": 17}, {"type": "equation", "text": "$$\nF(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})\\leq F(\\mathbf{x}_{\\gamma}^{*})+\\gamma p(\\mathbf{x}_{\\gamma}^{*})+\\epsilon.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "On the one hand, as $\\gamma=\\gamma^{*}+l_{F}^{\\beta}\\epsilon^{1-\\beta}>\\gamma^{*}$ , by Lemma 2.4, $\\mathbf{x}_{\\gamma}^{*}$ is an optimal solution of (P). On the other hand, since $\\gamma\\geq\\gamma^{*}$ , according to Lemma 2.4, $\\mathbf{x}^{*}$ is also an optimal solution of $(\\mathbf{P}_{\\gamma})$ . Therefore, $p(\\mathbf{x}^{*})=0$ and $p(\\mathbf{x}_{\\gamma}^{*})=0$ , it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{F(\\mathbf{x}^{*})\\leq F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})}\\\\ &{\\overset{(19)}{\\leq}F(\\mathbf{x}_{\\gamma}^{*})+\\gamma p(\\mathbf{x}_{\\gamma}^{*})+\\epsilon}\\\\ &{=F(\\mathbf{x}_{\\gamma}^{*})+\\gamma^{*}p(\\mathbf{x}_{\\gamma}^{*})+\\epsilon}\\\\ &{=F(\\mathbf{x}^{*})+\\gamma^{*}p(\\mathbf{x}^{*})+\\epsilon}\\\\ &{\\leq F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma^{*}p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\epsilon,}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first inequality follows from the fact that $\\mathbf{x}^{*}$ is an optimal solution of $(\\mathrm{{P}}_{\\gamma})$ , and the last inequality follows from the optimality of $\\mathbf{x}^{*}$ to $(\\mathbf{P}_{\\gamma})$ when $\\gamma\\geq\\gamma^{*}$ . ", "page_idx": 17}, {"type": "text", "text": "The second inequality of (20) and $p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})\\geq0$ imply that ", "page_idx": 17}, {"type": "equation", "text": "$$\nF(\\tilde{\\mathbf{x}}_{\\gamma}^{*})\\leq F(\\mathbf{x}_{\\gamma}^{*})+\\gamma p(\\mathbf{x}_{\\gamma}^{*})+\\epsilon=F(\\mathbf{x}^{*})+\\gamma p(\\mathbf{x}^{*})+\\epsilon\\leq F(\\mathbf{x}^{*})+\\epsilon.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "That is, it holds that ", "page_idx": 17}, {"type": "equation", "text": "$$\nF(\\tilde{\\mathbf{x}}_{\\gamma}^{*})\\leq F(\\mathbf{x}^{*})+\\epsilon.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "In addition, from (20), we have $F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})\\leq F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\gamma^{*}p(\\tilde{\\mathbf{x}}_{\\gamma}^{*})+\\epsilon$ , which implies that ", "page_idx": 17}, {"type": "equation", "text": "$$\np(\\tilde{\\bf x}_{\\gamma}^{*})\\leq\\frac{\\epsilon}{\\gamma-\\gamma^{*}}=\\frac{\\epsilon}{l_{F}^{\\beta}\\epsilon^{1-\\beta}}=l_{F}^{-\\beta}\\epsilon^{\\beta}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "This result along with (21) demonstrate that $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ is an $(\\epsilon,l_{F}^{-\\beta}\\epsilon^{\\beta})$ -optimal solution of (P). ", "page_idx": 17}, {"type": "text", "text": "E.4 Proof of Theorem 2.6 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. Let $\\hat{\\mathbf{x}}_{\\gamma}^{*}$ be the projection of $\\tilde{\\mathbf{x}}_{\\gamma}^{*}$ on $X_{\\mathrm{opt}}$ , we have $\\|\\tilde{\\mathbf{x}}_{\\gamma}^{*}-\\hat{\\mathbf{x}}_{\\gamma}^{*}\\|=\\mathrm{dist}(\\tilde{\\mathbf{x}}_{\\gamma}^{*},X_{\\mathrm{opt}})$ . ", "page_idx": 17}, {"type": "text", "text": "By Assumption 2.2, the following inequality holds, ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|\\widetilde{\\mathbf{x}}_{\\gamma}^{*}-\\widehat{\\mathbf{x}}_{\\gamma}^{*}\\|^{\\alpha}\\leq\\rho p(\\widetilde{\\mathbf{x}}_{\\gamma}^{*})\\overset{(a)}{\\leq}\\rho l_{F}^{-\\beta}\\epsilon^{\\beta}\\implies\\|\\widetilde{\\mathbf{x}}_{\\gamma}^{*}-\\widehat{\\mathbf{x}}_{\\gamma}^{*}\\|\\leq\\left(\\rho l_{F}^{-\\beta}\\epsilon^{\\beta}\\right)^{\\frac{1}{\\alpha}},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $(a)$ follows from (17) when $\\alpha>1$ or from (22) when $\\alpha=1$ . ", "page_idx": 17}, {"type": "text", "text": "By Assumption 2.1, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-F^{*}\\geq F(\\tilde{\\mathbf{x}}_{\\gamma}^{*})-F(\\hat{\\mathbf{x}}_{\\gamma}^{*})\\overset{(10)}{\\geq}-l_{F}\\|\\tilde{\\mathbf{x}}_{\\gamma}^{*}-\\hat{\\mathbf{x}}_{\\gamma}^{*}\\|\\geq-l_{F}\\left(\\rho l_{F}^{-\\beta}\\epsilon^{\\beta}\\right)^{\\frac{1}{\\alpha}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the first inequality follows from $F(\\hat{\\mathbf{x}}_{\\gamma}^{*})\\geq F^{*}$ and $\\hat{\\mathbf{x}}_{\\gamma}^{*}\\in X_{\\mathrm{opt}}$ . ", "page_idx": 17}, {"type": "text", "text": "E.5 Proof of Theorem 2.7 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. For any $\\mathbf{x}\\in\\mathrm{dom}(F)$ , let $\\bar{\\bf x}$ be the projection of $\\mathbf{x}$ onto $X_{\\mathrm{opt}}$ , where the existence and uniqueness of $\\bar{\\bf x}$ follows from that $X_{\\mathrm{opt}}$ is closed and convex. Since $F$ is $l$ -Lipschitz continuous, similar to (10), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\nF(\\mathbf{x})-F(\\bar{\\mathbf{x}})\\geq-l\\|\\mathbf{x}-\\bar{\\mathbf{x}}\\|,\\ \\forall\\xi\\in\\partial F(\\bar{\\mathbf{x}}).\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, all the requirements of (10) in equations (11), (14) and (15) can be replaced by (24). This implies that Lemmas 2.3 and 2.4 also hold for the global solutions of problems (P) and $(\\mathbf{P}_{\\gamma})$ when $F$ is non-convex. Then, the final result follows a similar pattern to Theorem 2.5. Here we omit it. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "E.6 Proof of Theorem 2.8 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. Let \u00afx\u2217\u03b3 be the projection of x\u2217\u03b3 onto Xopt and \u02c6x\u2217\u03b3 = cx\u2217\u03b3 + (1 \u2212c)\u00afx\u2217\u03b3 with c = min{1, 1 \u2212\u2225x\u2217\u03b3r\u2212\u00afx\u2217\u03b3\u2225}, which implies that $\\hat{\\mathbf{x}}_{\\gamma}^{*}\\in B(\\mathbf{x}_{\\gamma}^{*},r)$ . Then, we have ", "page_idx": 18}, {"type": "text", "text": "$F(\\mathbf{x}_{\\gamma}^{*})+\\gamma p(\\mathbf{x}_{\\gamma}^{*})\\leq F(\\hat{\\mathbf{x}}_{\\gamma}^{*})+\\gamma p(\\hat{\\mathbf{x}}_{\\gamma}^{*})\\overset{(i)}{\\leq}F(\\hat{\\mathbf{x}}_{\\gamma}^{*})+\\gamma(c p(\\mathbf{x}_{\\gamma}^{*})+(1-c)p(\\bar{\\mathbf{x}}_{\\gamma}^{*}))=F(\\hat{\\mathbf{x}}_{\\gamma}^{*})+\\gamma c p(\\mathbf{x}_{\\gamma}^{*}),$ (25) where inequality $(i)$ follows from the convexity of $p(\\mathbf{x})$ . ", "page_idx": 18}, {"type": "text", "text": "Inequality (25) demonstrates that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma(1-c)p(\\mathbf{x}_{\\gamma}^{*})\\leq F(\\hat{\\mathbf{x}}_{\\gamma}^{*})-F(\\mathbf{x}_{\\gamma}^{*})\\leq l\\|\\hat{\\mathbf{x}}_{\\gamma}^{*}-\\mathbf{x}_{\\gamma}^{*}\\|=l(1-c)\\|\\mathbf{x}_{\\gamma}^{*}-\\bar{\\mathbf{x}}_{\\gamma}^{*}\\|\\leq l(1-c)(\\rho p(\\mathbf{x}_{\\gamma}^{*}))^{\\frac{1}{\\alpha}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the second inequality follows from the $l$ -Lipschitz continuity of $F$ on $B(\\mathbf{x}_{\\gamma}^{*},r)$ . Therefore, it holds that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\gamma p(\\mathbf{x}_{\\gamma}^{*})\\leq l(\\rho p(\\mathbf{x}_{\\gamma}^{*}))^{\\frac{1}{\\alpha}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "\u2022 Case of $\\alpha\\,>\\,1$ . By (26), we have $\\begin{array}{r}{p(\\mathbf{x}_{\\gamma}^{*})\\,\\leq\\,\\big(\\frac{\\rho l^{\\alpha}}{\\gamma^{\\alpha}}\\big)^{\\frac{1}{\\alpha-1}}}\\end{array}$ , which demonstrates that $p(\\mathbf{x}_{\\gamma}^{*})\\;\\leq\\;\\epsilon$ if $\\begin{array}{r}{\\gamma\\ge\\left(\\frac{\\rho l^{\\alpha}}{\\epsilon^{\\alpha-1}}\\right)^{\\frac{1}{\\alpha}}}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "Then, for any $\\mathbf{x}_{\\gamma}\\in B(\\mathbf{x}_{\\gamma}^{*},r)$ that also satisfies $p(\\mathbf{x}_{\\gamma})\\leq p(\\mathbf{x}_{\\gamma}^{*})\\leq\\epsilon$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\nF(\\mathbf{x}_{\\gamma}^{*})+\\gamma p(\\mathbf{x}_{\\gamma}^{*})\\leq F(\\mathbf{x}_{\\gamma})+\\gamma p(\\mathbf{x}_{\\gamma}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which implies that $F(\\mathbf{x}_{\\gamma}^{*})-F(\\mathbf{x}_{\\gamma})\\leq\\gamma(p(\\mathbf{x}_{\\gamma})-p(\\mathbf{x}_{\\gamma}^{*}))\\leq0.$ . The desired result follows. ", "page_idx": 18}, {"type": "text", "text": "\u2022 Case of $\\alpha=1$ . By (26), we have $p(\\mathbf{x}_{\\gamma}^{*})=0$ if $\\gamma>\\rho l$ . Therefore, for any $\\mathbf{x}_{\\gamma}\\in\\mathcal{B}(\\mathbf{x}_{\\gamma}^{*},r)\\cap X_{\\mathrm{opt}}$ , by the definition of $\\mathbf{x}_{\\gamma}^{*}$ , it holds that ", "page_idx": 18}, {"type": "equation", "text": "$$\nF(\\mathbf{x}_{\\gamma}^{*})+\\gamma p(\\mathbf{x}_{\\gamma}^{*})\\leq F(\\mathbf{x}_{\\gamma})+\\gamma p(\\mathbf{x}_{\\gamma}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which demonstrates that $F(\\mathbf{x}_{\\gamma}^{*})\\leq F(\\mathbf{x}_{\\gamma})$ . The desired result follows. ", "page_idx": 18}, {"type": "text", "text": "E.7 Proof of Theorem 3.3 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. From [Beck, 2017, Theorem 10.34], the objective value after $K$ iterations can be bounded by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Phi_{\\gamma}(\\mathbf{x}_{K})-\\Phi_{\\gamma}^{*}\\leq\\frac{2L_{\\gamma}\\|\\mathbf{x}_{0}-\\mathbf{x}^{*}\\|^{2}}{(K+1)^{2}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $L_{\\gamma}=L_{f_{1}}+\\gamma L_{g_{1}}$ . ", "page_idx": 18}, {"type": "text", "text": "Combining this with our stopping criterion, we find that after $K$ iterations, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Phi_{\\gamma}(\\mathbf{x}_{K})-\\Phi_{\\gamma}^{*}\\leq\\epsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "This indicates that we obtain an $\\epsilon$ -optimal solution to problem $(\\mathrm{{P}}_{\\gamma})$ . The value of $K$ satisfies: ", "page_idx": 18}, {"type": "equation", "text": "$$\nK=\\sqrt{\\frac{2(L_{f_{1}}+\\gamma L_{g_{1}})}{\\epsilon}}R-1.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Specifically, we analyze the value of $K$ in various scenarios in the form of $O(\\cdot)$ . ", "page_idx": 18}, {"type": "text", "text": "\u2022 Case of $\\alpha\\,>\\,1$ . In this case, $\\gamma\\,=\\,\\gamma^{*}\\,+\\,2l_{F}^{\\beta}\\epsilon^{1-\\beta}$ comprises two components: $\\gamma^{*}$ and $2l_{F}^{\\beta}\\epsilon^{1-\\beta}$ . Therefore, it is natural to discuss which of these two components plays the dominant role in the complexity results. First, we write $K$ in the form: ", "page_idx": 18}, {"type": "equation", "text": "$$\nK=\\sqrt{\\frac{2\\big(L_{f_{1}}+(\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon^{1-\\alpha}+2l_{F}^{\\beta}\\epsilon^{1-\\beta})L_{g_{1}}\\big)}{\\epsilon}}R-1.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "If $\\beta<\\alpha$ , the dominating term in $\\gamma$ is $\\gamma^{*}=\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+l_{F}^{\\alpha}\\epsilon^{1-\\alpha}L_{g_{1}}}{\\epsilon}}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\epsilon}}+\\sqrt{\\frac{l_{F}^{\\alpha}L_{g_{1}}}{\\epsilon^{\\alpha}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "If $\\beta=\\alpha$ , we have $\\gamma=\\left(\\rho(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}+2\\right)l_{F}^{\\alpha}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+l_{F}^{\\alpha}\\epsilon^{1-\\alpha}L_{g_{1}}}{\\epsilon}}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\epsilon}}+\\sqrt{\\frac{l_{F}^{\\alpha}L_{g_{1}}}{\\epsilon^{\\alpha}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "If $\\beta>\\alpha$ , the dominating term in $\\gamma$ is $2l_{F}^{\\beta}\\epsilon^{1-\\beta}$ . Then, the number of iterations is ", "page_idx": 19}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+2l_{F}^{\\beta}\\epsilon^{1-\\beta}L_{g_{1}}}{\\epsilon}}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\epsilon}}+\\sqrt{\\frac{l_{F}^{\\beta}L_{g_{1}}}{\\epsilon^{\\beta}}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "\u2022 Case of $\\alpha=1$ . In this case, $\\gamma=\\gamma^{*}+l_{F}^{\\beta}\\epsilon^{1-\\beta}$ , where $\\gamma^{*}=\\rho l_{F}$ . Similarly, we explore which of these two elements plays a more significant role. ", "page_idx": 19}, {"type": "text", "text": "If $\\beta<1$ , the dominating term in $\\gamma$ is $\\gamma^{*}$ . Then, the number of iterations is ", "page_idx": 19}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\rho l_{F}L_{g_{1}}}{\\epsilon}}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\epsilon}}+\\sqrt{\\frac{l_{F}L_{g_{1}}}{\\epsilon}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "If $\\beta=1$ , we have $\\gamma=(\\rho+1)l_{F}\\epsilon^{1-\\alpha}$ . Then the number of iterations is ", "page_idx": 19}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+(\\rho+1)l_{F}L_{g_{1}}}{\\epsilon}}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\epsilon}}+\\sqrt{\\frac{l_{F}L_{g_{1}}}{\\epsilon}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "If $\\beta>1$ , the dominating term in $\\gamma$ is $l_{F}^{\\beta}\\epsilon^{1-\\beta}$ . Then, the number of iterations is ", "page_idx": 19}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+l_{F}^{\\beta}\\epsilon^{1-\\beta}L_{g_{1}}}{\\epsilon}}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\epsilon}}+\\sqrt{\\frac{l_{F}^{\\beta}L_{g_{1}}}{\\epsilon^{\\beta}}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Combining the above results, we conclude that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\sqrt{\\frac{{L_{f_{1}}}}{\\epsilon}}+\\sqrt{\\frac{{l_{F}^{\\operatorname*{max}\\{\\alpha,\\beta\\}}L_{g_{1}}}}{{\\epsilon^{\\operatorname*{max}\\{\\alpha,\\beta\\}}}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "E.8 Proof of Theorem 3.5 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. In this proof, we denote $\\Phi_{k}^{*}$ as the optimal value of problem $\\displaystyle(\\mathrm{{P}}_{\\gamma})$ ) when $\\gamma=\\gamma_{k}$ , and $\\mathbf{x}_{k}$ as the output of PB-APG (Algorithm 1) in the $k$ -th iteration. ", "page_idx": 19}, {"type": "text", "text": "\u2022 Case of $\\alpha>1$ . Suppose that $N$ is the smallest nonnegative integer such that $\\gamma_{N}\\geq\\gamma_{N}^{*}:=\\rho l_{F}^{\\alpha}(\\alpha-$ $1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon_{N}^{1-\\alpha}$ . In this case, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\gamma_{N}=\\gamma_{0}\\nu^{N}\\geq\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon_{N}^{1-\\alpha}=\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon_{0}^{1-\\alpha}(1/\\eta)^{(1-\\alpha)N},\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which is equivalent to ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma_{0}\\left(\\nu\\eta^{1-\\alpha}\\right)^{N}\\geq\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon_{0}^{1-\\alpha}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "From (29), after at most N := \u2308log\u03b71\u2212\u03b1\u03bd $\\begin{array}{r}{N:=\\lceil\\log_{\\eta^{1-\\alpha_{\\nu}}}\\left(\\frac{\\rho l_{F}^{\\alpha}\\left(\\alpha-1\\right)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon_{0}^{1-\\alpha}}{\\gamma_{0}}\\right)\\rceil+}\\end{array}$ iterations, (28) holds. ", "page_idx": 19}, {"type": "text", "text": "Since $x_{N}=\\mathrm{PB-APG}(\\phi_{N},\\psi_{N},L_{f_{1}},L_{g_{1}},{\\bf x}_{N-1},\\epsilon_{N})$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Phi_{N}(\\mathbf{x}_{N})-\\Phi_{N}^{*}\\le\\epsilon_{N},\\quad\\gamma_{N}\\ge\\gamma_{N}^{*},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which shows that $\\mathbf{x}_{N}$ is an $\\epsilon_{N}$ -optimal solution of $(\\mathbf{P}_{\\gamma})$ with $\\gamma=\\gamma_{N}$ . From the proof in Theorem 2.5 (see inequalities (17) and (18) in Appendix E.3), $\\mathbf{x}_{N}$ is also an $\\Big(\\frac{\\epsilon_{0}}{\\eta^{N}},\\,\\frac{{\\bar{2}}\\epsilon_{0}}{\\eta^{N}\\big(\\gamma_{0}\\nu^{N}-\\gamma_{N}^{*}\\big)}\\Big)$ -optimal solution of problem (P). ", "page_idx": 20}, {"type": "text", "text": "Furthermore, note that for any iteration $k\\geq N$ , inequality (29) always holds, which means that the following statement holds for any $k\\geq N$ : ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Phi_{k}(\\mathbf{x}_{k})-\\Phi_{k}^{*}\\leq\\epsilon_{k},\\quad\\gamma_{k}\\geq\\gamma_{k}^{*}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Let $I_{k}$ be the number of iterations of PB-APG required to satisfy (30) at the $k$ -th iteration of aPBAPG. Then, for any $k\\geq N$ , the total number of iterations is ", "page_idx": 20}, {"type": "equation", "text": "$$\nK=I_{0}+I_{1}+\\cdot\\cdot\\cdot+I_{k}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "From [Beck, 2017, Theorem 10.34], the number of iterations in $i$ -th inner loop satisfies: ", "page_idx": 20}, {"type": "equation", "text": "$$\nI_{i}=\\sqrt{\\frac{2(L_{f_{1}}+\\gamma_{i}L_{g_{1}})}{\\epsilon_{i}}}\\|\\mathbf{x}_{i-1}-\\mathbf{x}_{i}^{*}\\|-1,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\mathbf{x}_{i}^{*}$ is the optimal solution in $i$ -th inner loop. Then we have that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle K=\\sum_{i=0}^{k}\\sqrt{\\frac{2(L_{f_{1}}+\\gamma_{i}L_{g_{1}})}{\\epsilon_{i}}}\\|{\\mathbf x}_{i-1}-{\\mathbf x}_{i}^{*}\\|-k}\\\\ {\\displaystyle\\leq\\sum_{i=0}^{k}\\sqrt{\\frac{2(L_{f_{1}}+\\gamma_{k}L_{g_{1}})}{\\epsilon_{i}}}R-k}\\\\ {\\displaystyle=\\frac{\\eta^{\\frac{k}{2}}-1}{\\eta^{\\frac{1}{2}}-1}\\sqrt{\\frac{2(L_{f_{1}}+\\gamma_{0}\\nu^{k}L_{g_{1}})}{\\epsilon_{0}}}-k.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "For simplicity, we can also use $O(\\cdot)$ to show the value of $K$ . ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{K=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{0}L_{g_{1}}}{6}}\\right)+\\cdots+\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{k}L_{g_{1}}}{6}}\\right)}\\\\ &{\\quad\\le\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{k}L_{g_{1}}}{6}}\\right)+\\cdots+\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{k}L_{g_{1}}}{6}}\\right)}\\\\ &{\\quad=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{k}L_{g_{1}}}{6}}\\left(1+\\sqrt{1/\\eta}+\\sqrt{1/\\eta^{2}}+\\cdots+\\sqrt{1/\\eta^{k}}\\right)\\right)}\\\\ &{\\quad=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{k}L_{g_{1}}}{6}}\\right)}\\\\ &{\\quad=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}\\eta^{k}}{6}}+\\sqrt{\\frac{L_{g_{1}}\\gamma_{0}(\\eta\\psi)^{k}}{6}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "\u2022 Case of $\\alpha=1$ . Suppose that after $N$ updates, we have $\\gamma_{N}\\ge\\rho l_{F}$ , i.e., ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\gamma_{0}\\nu^{N}\\geq\\rho l_{F}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This demonstrates that after for all $\\begin{array}{r}{k\\geq N:=\\log_{\\nu}\\left(\\frac{\\rho l_{F}}{\\gamma_{0}}\\right)}\\end{array}$ , (31) always holds. ", "page_idx": 20}, {"type": "text", "text": "Similar to the case of $\\alpha>1$ , the total iteration number is: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{K=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{0}L_{g_{1}}}{\\epsilon_{0}}}\\right)+\\cdots+\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{k}L_{g_{1}}}{\\epsilon_{k}}}\\right)}\\\\ &{\\quad=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\gamma_{k}L_{g_{1}}}{\\epsilon_{k}}}\\right)}\\\\ &{\\quad=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}\\eta^{k}}{\\epsilon_{0}}}+\\sqrt{\\frac{L_{g_{1}}\\gamma_{0}\\left(\\eta\\nu\\right)^{k}}{\\epsilon_{0}}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "E.9 Proof of Theorem 3.8 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Before proving Theorem 3.8, we need the following lemma that is modified from Theorem 1 in Lin and Xiao [2014], we state it in the subsequent lemma for completeness. ", "page_idx": 21}, {"type": "text", "text": "Lemma E.1. Suppose that Assumptions 2.1, 3.1, 3.2, and 3.7 hold. Let $\\mathbf{x}_{\\gamma}^{*}$ be an optimal solution of problem $(\\mathbf{P}_{\\gamma})$ and suppose that there exists a constant $R$ such that max $\\{\\|\\mathbf{y}_{0}-\\mathbf{x}_{\\gamma}^{*}\\|$ , $\\|\\widetilde{\\mathbf x}\\!-\\!\\mathbf x_{\\gamma}^{*}\\|\\}\\leq R$ . Then, the sequence $\\{{\\bf x}_{k}\\}$ generated by Algorithm 3 satisfy ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Phi_{\\gamma}(\\mathbf{x}_{k})-\\Phi_{\\gamma}(\\mathbf{x}_{\\gamma}^{*})\\leq\\left(\\frac{L_{\\gamma}+\\mu}{2}R^{2}\\right)\\left(1-\\sqrt{\\frac{\\mu}{L_{\\gamma}}}\\right)^{k}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. Denote $L_{\\gamma}=L_{f_{1}}+\\gamma L_{g_{1}}$ . By Theorem 3.1 in Beck and Teboulle [2009], we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\Phi_{\\gamma}(\\tilde{\\mathbf{x}})-\\Phi_{\\gamma}(\\mathbf{x}_{\\gamma}^{*})\\leq\\frac{L_{\\gamma}}{2}\\|\\mathbf{y}_{0}-\\mathbf{x}_{\\gamma}^{*}\\|^{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Utilize Theorem 1 in Lin and Xiao [2014], we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Phi_{\\gamma}(\\mathbf{x}_{k})-\\Phi_{\\gamma}(\\mathbf{x}_{\\gamma}^{*})\\leq\\left(\\Phi_{\\gamma}(\\widetilde{\\mathbf{x}})-\\Phi_{\\gamma}(\\mathbf{x}_{\\gamma}^{*})+\\frac{\\mu}{2}\\|\\widetilde{\\mathbf{x}}-\\mathbf{x}_{\\gamma}^{*}\\|^{2}\\right)\\left(1-\\sqrt{\\frac{\\mu}{L_{\\gamma}}}\\right)^{k}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\overset{(33)}{\\leq}\\left(\\frac{L_{\\gamma}}{2}\\|\\mathbf{y}_{0}-\\mathbf{x}_{\\gamma}^{*}\\|^{2}+\\frac{\\mu}{2}\\|\\widetilde{\\mathbf{x}}-\\mathbf{x}_{\\gamma}^{*}\\|^{2}\\right)\\left(1-\\sqrt{\\frac{\\mu}{L_{\\gamma}}}\\right)^{k}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left(\\frac{L_{\\gamma}+\\mu}{2}R^{2}\\right)\\left(1-\\sqrt{\\frac{\\mu}{L_{\\gamma}}}\\right)^{k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "By Lemma E.1, we are now prepared to prove Theorem 3.8. ", "page_idx": 21}, {"type": "text", "text": "Proof. By Lemma E.1, the number of iterations required to achieve an $\\epsilon$ -optimal solution for problem $(\\mathbf{P}_{\\gamma})$ is ", "page_idx": 21}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{\\gamma}}{\\mu}}\\log\\left(\\frac{L_{\\gamma}+\\mu}{2\\epsilon}R^{2}\\right)\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{\\gamma}}{\\mu}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "\u2022 Case of $\\alpha>1,$ . In this case, $\\gamma=\\gamma^{*}+2l_{F}^{\\beta}\\epsilon^{1-\\beta}$ , where $\\gamma^{\\ast}=\\rho l_{F}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon^{1-\\alpha}$ . ", "page_idx": 21}, {"type": "text", "text": "If $\\beta<\\alpha$ , the dominating term in $\\gamma$ is $\\gamma^{*}$ . Then, the number of iterations is ", "page_idx": 21}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+l_{F}^{\\alpha}\\epsilon^{1-\\alpha}L_{g_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}^{\\alpha}L_{g_{1}}}{\\epsilon^{\\alpha-1}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If $\\beta=\\alpha$ , we have $\\gamma=\\left(\\rho(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}+2\\right)l_{F}^{\\alpha}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 21}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+l_{F}^{\\alpha}\\epsilon^{1-\\alpha}L_{g_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}^{\\alpha}L_{g_{1}}}{\\epsilon^{\\alpha-1}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If $\\beta>\\alpha$ , the dominating term in $\\gamma$ is $2l_{F}^{\\beta}\\epsilon^{1-\\beta}$ . Then, the number of iterations is ", "page_idx": 21}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+2l_{F}^{\\beta}\\epsilon^{1-\\beta}L_{g_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}^{\\beta}L_{g_{1}}}{\\epsilon^{\\beta-1}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "\u2022 Case of $\\alpha=1$ . When $\\alpha=1$ , $\\gamma$ can be written as $\\gamma=\\gamma^{*}+l_{F}^{\\beta}\\epsilon^{1-\\beta}$ , where $\\gamma^{*}=\\rho l_{F}$ ", "page_idx": 21}, {"type": "text", "text": "If $\\beta<1$ , the dominating term in $\\gamma$ is $\\gamma^{*}$ . Then, the number of iterations is ", "page_idx": 21}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\rho l_{F}L_{g_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}L_{g_{1}}}{\\epsilon^{\\alpha-1}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If $\\beta=1$ , we have $\\gamma=(\\rho+1)l_{F}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 21}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+\\rho l_{F}L_{g_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}L_{g_{1}}}{\\epsilon^{\\alpha-1}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "If $\\beta>1$ , the dominating term in $\\gamma$ is $l_{F}^{\\beta}\\epsilon^{1-\\beta}$ . Then, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}+l_{F}^{\\beta}\\epsilon^{1-\\beta}L_{g_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}\\right)=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}^{\\beta}L_{g_{1}}}{\\epsilon^{\\beta-1}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Combining the above results, we conclude that ", "page_idx": 22}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\sqrt{\\frac{L_{f_{1}}}{\\mu}}\\log\\frac{1}{\\epsilon}+\\sqrt{\\frac{l_{F}^{\\operatorname*{max}\\{\\alpha,\\beta\\}}L_{g_{1}}}{\\epsilon^{\\operatorname*{max}\\{\\alpha-1,\\beta-1\\}}}}\\log\\frac{1}{\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "E.10 Proof of Theorem 3.9 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proof. Denote $l_{\\gamma}\\,=\\,l_{f_{2}}+\\gamma l_{g_{2}}$ . Define $\\Phi_{\\gamma,b e s t}^{K}\\,=\\,\\operatorname*{min}_{i=0,\\dots,K}\\Phi_{\\gamma}(\\mathbf{x}_{i})$ min \u03a6\u03b3(xi) and \u02c6\u03a6\u03b3K,,bjes $\\hat{\\Phi}_{\\gamma,b e s t}^{K,j}\\,=\\,\\operatorname*{min}_{i=j,\\dots,K}\\Phi_{\\gamma}(\\mathbf{x}_{i})$ for all $0\\le j\\le K$ . We claim that the sequence generated by the subgradient method satisfies ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\Phi_{\\gamma,b e s t}^{K}-\\Phi_{\\gamma}^{*}\\leq\\frac{l_{\\gamma}}{4}\\frac{R^{2}+2\\log2}{\\sqrt{K+2}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Specifically, from Lemma 8.24 in Beck [2017], for all $0\\le j\\le K$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\hat{\\Phi}_{\\gamma,b e s t}^{K,j}-\\Phi_{\\gamma}^{*}\\leq\\frac{1}{2}\\frac{R^{2}+\\sum_{k=j}^{K}\\eta_{k}^{2}\\|\\xi_{k}\\|^{2}}{\\sum_{k=j}^{K}\\eta_{k}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Define $\\lfloor\\cdot\\rfloor$ and $\\lceil\\cdot\\rceil$ as rounding up and rounding down, respectively. Let $\\begin{array}{r}{j=\\left\\lfloor\\frac{K}{2}\\right\\rfloor}\\end{array}$ in (36), by the definition of step-size $\\begin{array}{r}{\\eta_{k}=\\frac{R}{l_{\\gamma}\\sqrt{k+1}}}\\end{array}$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\hat{\\Phi}_{\\gamma,b e s t}^{K,j}-\\Phi_{\\gamma}^{*}\\leq\\frac{l_{\\gamma}}{2}\\frac{R^{2}+\\sum_{k=\\lfloor\\frac{K}{2}\\rfloor}^{K}\\frac{1}{k+1}}{\\sum_{k=\\lfloor\\frac{K}{2}\\rfloor}^{K}\\frac{1}{\\sqrt{k+1}}}\\leq\\frac{l_{\\gamma}}{4}\\frac{R^{2}+2\\log2}{\\sqrt{K+2}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where the second inequality follows from that $\\begin{array}{r l r}{\\sum_{k=\\lfloor\\frac{K}{2}\\rfloor}^{K}\\frac{1}{k+1}}&{\\le}&{\\int_{\\lceil\\frac{K}{2}\\rceil-1}^{K}\\frac{1}{s+1}d s\\quad\\le\\quad2\\log2}\\end{array}$ and $\\begin{array}{r}{\\sum_{k=\\lfloor\\frac{K}{2}\\rfloor}^{K}\\frac{1}{\\sqrt{k+1}}\\ge\\int_{\\lceil\\frac{K}{2}\\rceil}^{K+1}\\frac{1}{\\sqrt{s+1}}d s\\ge\\frac{1}{2}\\sqrt{K+2}.}\\end{array}$ ", "page_idx": 22}, {"type": "text", "text": "From the fact that $\\Phi_{\\gamma,b e s t}^{K}\\leq\\hat{\\Phi}_{\\gamma,b e s t}^{K,j}$ , The desired result of (35) follows. ", "page_idx": 22}, {"type": "text", "text": "Then, inequality (35) demonstrates that the number of iterations to obtain an $\\epsilon$ -optimal solution for problem $(\\mathbf{P}_{\\gamma})$ is ", "page_idx": 22}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}+\\gamma l_{g_{2}}}{\\epsilon}\\right)^{2}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "\u2022 Case of $\\alpha>1$ . we have $\\gamma=\\gamma^{*}+2l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}$ and $\\gamma^{*}=\\rho l_{f_{2}}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon^{1-\\alpha}.$ ", "page_idx": 22}, {"type": "text", "text": "If $\\beta<\\alpha$ , the dominating term in $\\gamma$ is $\\gamma^{*}$ . Then, the number of iterations is ", "page_idx": 22}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}+l_{f_{2}}^{\\alpha}\\epsilon^{1-\\alpha}l_{g_{2}}}{\\epsilon}\\right)^{2}=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{2\\alpha}l_{g_{2}}^{2}}{\\epsilon^{2\\alpha}}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "If $\\beta=\\alpha$ , we have $\\gamma=\\left(\\rho(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}+2\\right)l_{F}^{\\alpha}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 22}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}+l_{f_{2}}^{\\alpha}\\epsilon^{1-\\alpha}l_{g_{2}}}{\\epsilon}\\right)^{2}=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{2\\alpha}l_{g_{2}}^{2}}{\\epsilon^{2\\alpha}}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "If $\\beta>\\alpha$ , the dominating term in $\\gamma$ is $2l_{F}^{\\beta}\\epsilon^{1-\\beta}$ . Then, the number of iterations is ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\frac{l_{f_{2}}+2l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}l_{g_{2}}}{\\epsilon}\\right)^{2}=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{2\\beta}l_{g_{2}}^{2}}{\\epsilon^{2\\beta}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "\u2022 Case of $\\alpha=1$ . we have $\\gamma=\\gamma^{*}+l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}$ and $\\gamma^{*}=\\rho l_{f_{2}}$ ", "page_idx": 23}, {"type": "text", "text": "If $\\beta<1$ , the dominating term in $\\gamma$ is $\\gamma^{*}$ . Then, the number of iterations is ", "page_idx": 23}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}+\\rho l_{f_{2}}l_{g_{2}}}{\\epsilon}\\right)^{2}=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{2}l_{g_{2}}^{2}}{\\epsilon^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $\\beta=1$ , we have $\\gamma=(\\rho+1)l_{F}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 23}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}+\\rho l_{f_{2}}l_{g_{2}}}{\\epsilon}\\right)^{2}=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{2}l_{g_{2}}^{2}}{\\epsilon^{2}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $\\beta>1$ , the dominating term in $\\gamma$ is $l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}$ . Then, the number of iterations is ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\frac{l_{f_{2}}+l_{f_{2}}^{\\beta}l_{g_{2}}\\epsilon^{1-\\beta}}{\\epsilon}\\right)^{2}=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{2\\beta}l_{g_{2}}^{2}}{\\epsilon^{2\\beta}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Combining the above results, we conclude that ", "page_idx": 23}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\epsilon^{2}}+\\frac{l_{f_{2}}^{\\operatorname*{max}\\{2\\alpha,2\\beta\\}}l_{g_{2}}^{2}}{\\epsilon^{\\operatorname*{max}\\{2\\alpha,2\\beta\\}}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "E.11 Proof of Theorem 3.10 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Proof. Denote $l_{\\gamma}=l_{f_{2}}+\\gamma l_{g_{2}}$ , define $\\Phi_{\\gamma,b e s t}^{K}=\\operatorname*{min}_{i=0,...,K}\\Phi_{\\gamma}(\\mathbf{x}_{i})$ . From Theorem 8.31 in Beck [2017], the sequence generated by the subgradient method satisfies ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Phi_{\\gamma,b e s t}^{K}-\\Phi_{\\gamma}^{*}\\leq\\frac{2l_{\\gamma}^{2}}{\\mu_{f_{2}}(K+1)}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This demonstrates that the number of iterations to obtain an $\\epsilon$ -optimal solution for problem $(\\mathrm{P}_{\\gamma})$ is ", "page_idx": 23}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{(l_{f_{2}}+\\gamma l_{g_{2}})^{2}}{\\mu_{f_{2}}\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "\u2022 Case of $\\alpha>1$ . we have $\\gamma=\\gamma^{*}+2l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}$ and $\\gamma^{\\ast}=\\rho l_{f_{2}}^{\\alpha}(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}\\epsilon^{1-\\alpha}$ ", "page_idx": 23}, {"type": "text", "text": "If $\\beta<\\alpha$ , the dominating term in $\\gamma$ is $\\gamma^{*}$ . Then, the number of iterations is ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\frac{\\left(l_{f_{2}}+l_{f_{2}}^{\\alpha}\\epsilon^{1-\\alpha}l_{g_{2}}\\right)^{2}}{\\mu_{f_{2}}\\epsilon}\\right)=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{2\\alpha}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon^{2\\alpha-1}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $\\beta=\\alpha$ , we have $\\gamma=\\left(\\rho(\\alpha-1)^{\\alpha-1}\\alpha^{-\\alpha}+2\\right)l_{F}^{\\alpha}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{K=\\mathcal{O}\\left(\\frac{\\left(l_{f_{2}}+l_{f_{2}}^{\\alpha}\\epsilon^{1-\\alpha}l_{g_{2}}\\right)^{2}}{\\mu_{f_{2}}\\epsilon}\\right)=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{2\\alpha}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon^{2\\alpha-1}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $\\beta>\\alpha$ , the dominating term in $\\gamma$ is $2l_{F}^{\\beta}\\epsilon^{1-\\beta}$ . Then, the number of iterations is ", "page_idx": 23}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{(l_{f_{2}}+2l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}l_{g_{2}})^{2}}{\\mu_{f_{2}}\\epsilon}\\right)=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{2\\beta}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon^{2\\beta-1}}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "\u2022 Case of $\\alpha>1$ . we have $\\gamma=\\gamma^{*}+l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}$ and $\\gamma^{*}=\\rho l_{f_{2}}$ . ", "page_idx": 23}, {"type": "text", "text": "If $\\beta<1$ , the dominating term in $\\gamma$ is $\\gamma^{*}$ . Then, the number of iterations is ", "page_idx": 23}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{(l_{f_{2}}+\\rho l_{f_{2}}l_{g_{2}})^{2}}{\\mu_{f_{2}}\\epsilon}\\right)=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{2}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $\\beta=1$ , we have $\\gamma=(\\rho+1)l_{F}\\epsilon^{1-\\alpha}$ . Then, the number of iterations is ", "page_idx": 24}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{(l_{f_{2}}+\\rho l_{f_{2}}l_{g_{2}})^{2}}{\\mu_{f_{2}}\\epsilon}\\right)=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{2}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "If $\\beta>1$ , the dominating term in $\\gamma$ is $l_{f_{2}}^{\\beta}\\epsilon^{1-\\beta}$ . Then, the number of iterations is ", "page_idx": 24}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{(l_{f_{2}}+l_{f_{2}}^{\\beta}l_{g_{2}}\\epsilon^{1-\\beta})^{2}}{\\mu_{f_{2}}\\epsilon}\\right)=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{2\\beta}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon^{2\\beta-1}}\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Combining the above results, we conclude that ", "page_idx": 24}, {"type": "equation", "text": "$$\nK=\\mathcal{O}\\left(\\frac{l_{f_{2}}^{2}}{\\mu_{f_{2}}\\epsilon}+\\frac{l_{f_{2}}^{\\operatorname*{max}\\{2\\alpha,2\\beta\\}}l_{g_{2}}^{2}}{\\mu_{f_{2}}\\epsilon^{\\operatorname*{max}\\{2\\alpha-1,2\\beta-1\\}}}\\right).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "F Implementation details ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In this section, we provide supplementary experiment settings and results. Specifically, in Appendix F.1, we present the detailed experimental settings, and in Appendix F.2, we provide the detailed experimental results. Additionally, in Appendix F.3 and F.4, we conduct experiments with different values of penalty parameter $\\gamma$ and solution accuracy \u03f5, respectively. ", "page_idx": 24}, {"type": "text", "text": "F.1 Experiment setting ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "All simulations are implemented using MATLAB R2023a on a PC running Windows 11 with an AMD (R) Ryzen (TM) R7-7840H CPU (3.80GHz) and 16GB RAM. ", "page_idx": 24}, {"type": "text", "text": "F.1.1 Experiment setting of Section 4.1 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We conduct the first experiment using the a1a.t data from LIBSVM datasets5. This data consists of 30, 956 instances, each with $n=123$ features. For this experiment, a sample of 1, 000 instances is taken from the data, denoted as $A$ . The corresponding labels for these instances are denoted as $^b$ , where each label $b_{i}$ is either $-1$ or 1, corresponding to the $i$ -th instance ${\\bf a}_{i}$ . ", "page_idx": 24}, {"type": "text", "text": "The Greedy FISTA algorithm [Liang et al., 2022] is used as a benchmark to compute $G^{*}$ . To compute the proximal mapping of $f_{2}(\\mathbf{x})+\\gamma g_{2}(\\mathbf{x})$ in problem $(\\mathbf{P}_{\\gamma})$ , i.e, projection onto a 1-norm ball, we utilize the method proposed in Duchi et al. [2008], which performs exact projection in $\\mathcal{O}(n)$ expected time, where n is the dimension of $\\mathbf{x}$ . ", "page_idx": 24}, {"type": "text", "text": "For the PB-APG and PB-APG-sc algorithms, we set the value of $\\gamma=10^{5}$ , and we terminate the algorithms when $\\|\\mathbf{x}_{k+1}-\\mathbf{x}_{k}\\|\\,\\leq\\,10^{-10}$ . For the aPB-APG and aPB-APG-sc algorithms, we set $\\gamma_{0}~=~\\textstyle{\\frac{1}{2^{5}}}$ , $\\nu\\,=\\,20$ , $\\eta=10,$ and $\\epsilon_{0}=10^{-6}$ . The iterations of these two algorithms continue until $\\epsilon_{k}$ reaches $10^{-10}$ (meanwhile, $\\gamma=10^{5}$ ). ", "page_idx": 24}, {"type": "text", "text": "We compare our methods with MNG, BiG-SAM, DBGD, a-IRG, CG-BiO, Bi-SG, and R-APM in this experiment. Specifically, for R-APM [Samadi et al., 2023], the regularization parameter $\\eta$ is set to $\\eta=1/\\gamma$ , reflecting the equivalence of the penalty formulation $(\\mathrm{P}_{\\gamma})$ to $\\left(\\mathrm{P_{Reg}}\\right)$ , with $\\sigma=1/\\bar{\\gamma}$ , as previously discussed. ", "page_idx": 24}, {"type": "text", "text": "We note that the termination criterion $\\|\\mathbf{x}_{k+1}-\\mathbf{x}_{k}\\|\\leq10^{-10}$ used in our experiments is different from the one proposed in our algorithms since the parameters required for the latter are not easily measurable. Nevertheless, this termination criterion is also widely used in the literature, as it corresponds to a gradient mapping [Beck, 2017, Nesterov, 2018, Davis and Drusvyatskiy, 2019]. Furthermore, Theorem 3.5 of Drusvyatskiy and Lewis [2018b] implies that $\\|{\\bf x}_{k+1}-{\\bf x}_{k}\\|$ also measures the distance to the optimal solution set. ", "page_idx": 24}, {"type": "text", "text": "F.1.2 Experiment setting of Section 4.2 ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "In the second experiment, we address the problem of least squares regression using the YearPredictionMSD data from the UCI Machine Learning Repository6. This data consists of 515, 345 songs with release years ranging from 1992 to 2011. Each song has 90 features, and the corresponding release year is used as the label. ", "page_idx": 24}, {"type": "text", "text": "For this experiment, a sample of $m=1,000$ songs is taken from the data, and the feature matrix and release years vector are denoted as $A$ and $^b$ , respectively. ", "page_idx": 25}, {"type": "text", "text": "Following Section 5.2 in Merchav and Sabach [2023], we apply the min-max scaling technique to normalize the feature matrix $A$ . Additionally, we add an intercept term and 90 collinear features to $A$ such that the resulting matrix $A^{T}A$ becomes positive semi-definite, which implies that the feasible set $X_{\\mathrm{opt}}$ is not a singleton. ", "page_idx": 25}, {"type": "text", "text": "We compare our methods with a-IRG, BiG-SAM, and Bi-SG in this experiment. Specifically, for BiG-SAM [Sabach and Shtern, 2017], we consider the accuracy parameter $\\delta$ for the Moreau envelope with two values, namely $\\delta=1$ and $\\delta=0.01$ . ", "page_idx": 25}, {"type": "text", "text": "To benchmark the performance, we utilize the MATLAB function lsqminnorm to compute $G^{*}$ . Moreover, we follow the parameter settings outlined in Section 4.1. ", "page_idx": 25}, {"type": "text", "text": "F.2 Detailed results of experiments ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "To approximate the optimal value $F^{*}$ , we use the MATLAB function fmincon to solve a relaxed version of the function-value-based reformulations in equation $(\\mathrm{{P}_{V a l}})$ . In this relaxed version, we replace the constraint in $(\\mathrm{{P}\\mathrm{{Val}})}$ with $G(\\mathbf{x})-G^{*}\\leq\\varepsilon$ , where $\\varepsilon=10^{-\\,\\mathrm{{i}0}}$ . This allows us to obtain an approximation of the optimal value while allowing for a small deviation from the true optimal value G\u2217. ", "page_idx": 25}, {"type": "text", "text": "We gather the total number of iterations for our methods, as well as the lower- and upper-level objective values and the optimal gaps for all the methods, in Table 3. Subsequently, we compare the optimal gaps of all methods, which are defined as $G(\\mathbf{x})-G^{*}$ and $F(\\mathbf{x})-F^{*}$ for the lower- and upper-level optimal gaps, respectively. ", "page_idx": 25}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/ec3ba2cb0f7073e557397d893131d371afc5b74251e545f393238c4e0b69d0ec.jpg", "table_caption": ["Table 3: Methods comparison: lower- and upper-level objectives and optimal gaps "], "table_footnote": [], "page_idx": 25}, {"type": "text", "text": "Table 3 reveals that for the logistic regression problem (5), our PB-APG, aPB-APG, PB-APG-sc, and aPB-APGsc exhibit almost identical function values for both objectives, surpassing other methods in terms of optimal gaps for the lower- and upper-level objectives (measured by the numerical value of the upper-level objective). In the case of the least squares regression problem (6), aPB-APG achieves the smallest optimal gaps for both objectives, followed by PB-APG and PB-APG-sc. These results demonstrate that our methods, despite yielding larger upper-level function values, generate solutions that are significantly closer to the optimal solution, as depicted in Figure 1. Additionally, for the problem in (5), both aPB-APG and aPB-APG-sc require fewer iterations than PB-APG and PB-APG-sc, respectively. This can be attributed to the warm-start mechanism employed in aPB-APG and aPB-APG-sc. Moreover, for the problem in (6), both aPB-APG and aPB-APG-sc require more iterations than PB-APG and PB-APG-sc, respectively. However, they exhibit staircase-shaped curves, which avoid the unwanted oscillations in PB-APG and PB-APG-sc, we have a similar observation in Figure 2. ", "page_idx": 25}, {"type": "text", "text": "F.3 Supplementary experiments for different penalty parameters ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section, we investigate the impact of different values of penalty parameter $\\gamma$ on the experimental results of problems (5) and (6). We set $\\gamma$ to be either $2\\times10^{4}$ or $5\\times10^{5}$ for PB-APG and PB-APG-sc, and choose the corresponding $\\gamma_{0}$ values as $\\frac{0.2}{2^{5}}$ or $\\frac{5}{2^{5}}$ for aPB-APG and aPB-APG-sc, respectively. The remaining settings are the same as in Section 4. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "We plot the values of the residuals of the lower-level objective $G(\\mathbf{x}_{k})-G^{*}$ and the upper-level objective over time in Figures 3 and 4. Additionally, we also collect the total number of iterations, the lower- and upper-level objective values, and the optimal gaps of our methods in Table 4 for problems (5) and (6) with different values of $\\gamma$ . ", "page_idx": 26}, {"type": "image", "img_path": "oQ1Zj9iH88/tmp/892a6f8147a33a01fc387666c22e0b05af939834681bda033c2d71dbe8183fb2.jpg", "img_caption": ["Figure 3: LRP (5) with $\\gamma=2\\times10^{4}$ (left two subfigures) and $\\gamma=5\\times10^{5}$ (right two subfigures). "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "oQ1Zj9iH88/tmp/fa846e57d7dc42c52487e3c0b05510cba0b8feb541e42094332d6bab697eeaa5.jpg", "img_caption": ["Figure 4: LSRP (6) with $\\gamma=2\\times10^{4}$ (left two subfigures) and $\\gamma=5\\times10^{5}$ (right two subfigures). "], "img_footnote": [], "page_idx": 26}, {"type": "text", "text": "As Figures 3 and 4 show, our methods consistently outperform the other methods for both the lower- and upperlevel objectives, irrespective of the penalty parameter $\\gamma$ , since our methods achieve lower optimal gaps and desired function values for the lower- and upper-level objectives, respectively. The only exception is problem (6) with $\\gamma=5\\times10^{5}$ , as the third subfigure of Figure 4 shows, since we do not set the solution accuracy of BiG-SAM $\\left.\\delta=0.01\\right\\rangle$ ), it attains a lower optimal gap than our PB-APG-sc and aPB-APG-sc for the lower-level objective. However, BiG-SAM $(\\delta\\,=\\,0.01)$ ) produces significantly worse upper-level objective values, which are much larger than the objective values of our methods. ", "page_idx": 26}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/bfa3817ca5d1ca787abdfe0b61d25846757fd42545b2431bb094258768159a76.jpg", "table_caption": ["Table 4: Lower- and upper-level objectives and optimal gaps with different penalty parameters for problem (5). "], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Tables 3, 4, and 5 reveal that the number of iterations for our methods increases as penalty parameter $\\gamma$ increases. However, it is worth noting that the accuracy of the obtained solutions also increases, as indicated by the decreasing optimal gaps of the lower- and upper-level objectives. This observation confirms that the complexity results and solution accuracies of our methods are indeed dependent on the choice of penalty parameters, specifically, $L_{\\gamma}$ , as demonstrated in corresponding Theorem 3.3 and other related theorems. ", "page_idx": 26}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/17fffe463ee3c8474e098b184c47eecd62e46b502102f8648db42e0dfaf78b1a.jpg", "table_caption": ["Table 5: Lower- and upper-level objectives and optimal gaps with different penalty parameters for problem (6). "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "F.4 Supplementary experiments for different solution accuracies ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we investigate the impact of different solution accuracies on the experimental results of problems (5) and (6). We set $\\epsilon$ to be either $10^{\\pm4}$ or $10^{-7}$ and terminate the algorithms for PB-APG and PB-APG-sc when $\\|{\\bf x}_{k+1}-{\\bf x}_{k}\\|\\le\\epsilon$ . For aPB-APG and aPB-APG-sc, we choose the corresponding $\\epsilon_{0}$ values as 1 or $10^{-3}$ . The remaining settings are the same as in Section 4. ", "page_idx": 27}, {"type": "text", "text": "We also plot the values of the residuals of the lower-level objective $G(\\mathbf{x}_{k})-G^{*}$ and the upper-level objective over time in Figures 5 and 6. Additionally, we also collect the total number of iterations, the lower- and upperlevel objective values, and the optimal gaps of our methods in Table 6 for problems (5) and (6) with different solution accuracies. ", "page_idx": 27}, {"type": "image", "img_path": "oQ1Zj9iH88/tmp/a478fd57f5d7ef28b0189cbbec4b230620b75291a840130b3679e8b2e7ca3c53.jpg", "img_caption": ["Figure 5: LRP (5) with $\\epsilon=10^{-4}$ (left two subfigures) and $\\epsilon=10^{-7}$ (right two subfigures). "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "oQ1Zj9iH88/tmp/515112fff37f62c3355d39e85c649407dffc2895224ecc1e3b629b9442ab5338.jpg", "img_caption": ["Figure 6: LSRP (6) with $\\epsilon=10^{-4}$ (left two subfigures) and $\\epsilon=10^{-7}$ (right two subfigures). "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "From Figures 5 and 6, it is evident that in most cases, our methods outperform the other methods in terms of both the lower- and upper-level objectives. However, there is an exception in the case of the upper-level objective for problem (6) when $\\epsilon\\,=\\,\\mathrm{\\dot{10}^{-4}}$ . As illustrated in the second subfigure in Figure 6, our methods exhibit larger function values for the upper-level objective compared to the other methods (except BiG-SAM $\\!\\!\\!\\delta=0.01)$ )), despite still achieving smaller optimal gaps for the lower-level objective. This discrepancy actually indicates that our methods have not yet achieved the desired accuracy when $\\epsilon=10^{-4}$ , and it is important to note that $\\|{\\bf x}_{k+1}-{\\bf x}_{k}\\|\\le\\epsilon$ is not the termination criterion in our proposed algorithms, as explained in Appendix F.1. Therefore, the larger optimality gaps for the upper-level objective in this case may be attributed to the termination criterion. ", "page_idx": 27}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/bc9f365e348d7bd5e55e6dc7434d4b8c4c89a0f972b6a55ead7df5aaa098c414.jpg", "table_caption": ["Table 6: Lower- and upper-level objectives and optimal gaps with different solution accuracies for problem (5). "], "table_footnote": [], "page_idx": 28}, {"type": "table", "img_path": "oQ1Zj9iH88/tmp/e8da1c3f8d8a480e13e8003a11a455700285b71b791232ef7d57849ed147eaca.jpg", "table_caption": ["Table 7: Lower- and upper-level objectives and optimal gaps with different solution accuracies for problem (6). "], "table_footnote": [], "page_idx": 28}, {"type": "text", "text": "Tables 3, 6, and 7 demonstrate that the number of iterations for our methods also increases with the solution accuracy, while the optimal gaps of the lower- and upper-level objectives decrease correspondingly. This finding confirms that the number of iterations and the optimal gaps are influenced by the solution accuracy, as illustrated in the expressions for the number of iterations provided by Theorem 3.3 and other related theorems. ", "page_idx": 28}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "1. Claims ", "page_idx": 29}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Please refer to Abstract and Section 1. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: Please refer to the assumptions adopted in this paper (e.g. Assumptions 2.1, 2.2, and 3.2), our study is based on these assumptions. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Please refer to the theorems and the proofs of them in this paper, please refer to Appendix E. For example, Theorem 3.3 and its proof in Appendix E.7. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and cross-referenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: Please refer to Section 4 and Appendix F. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: Please refer to Section 4 and Appendix F and the supplemental material. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/public/ guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so No is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: Please refer to Section 4 and Appendix F. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them.   \n\u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [No] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: The error bars are not applicable in this paper. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: Please refer to Section 4 and Appendix F. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. ", "page_idx": 31}, {"type": "text", "text": "\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: Please refer to Section 4 and Appendix F. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake proflies, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: All the creators or original owners of assets are properly credited, and the license and terms of use are explicitly mentioned and properly respected, please refer to Section 4 and Appendix F. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: Please refer to the supplemental materials and the \u2018README.m\u2019 file. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 33}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}]