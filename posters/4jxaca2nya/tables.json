[{"figure_path": "4jXaca2NYa/tables/tables_1_1.jpg", "caption": "Table 1: Comparisons of recent onboard and offboard perception models. Seg., Det., Occ. represent 3D segmentation, 3D object detection, occupancy prediction, respectively. HLF means training in a human-label-free manner. Grounding highlights models that can respond with text prompts. Zero. stands for the zero-shot capability for unseen classes.", "description": "This table compares several existing onboard and offboard perception models across various criteria, including their use of LiDAR and image data, their ability to perform 3D segmentation, detection, and occupancy prediction, whether they are trained in a human-label-free manner, if they support grounding (responding to text prompts), and if they have zero-shot capabilities for unseen classes.  It helps to highlight the unique features of the proposed ZOPP model in comparison to prior art.", "section": "Related Work"}, {"figure_path": "4jXaca2NYa/tables/tables_7_1.jpg", "caption": "Table 2: Verifying 3D object detection ability of our ZOPP on WOD val set. Metrics are 3D AP of L2 difficulties for Vehicle, Pedestrian, and Cyclist.", "description": "This table presents the performance of the ZOPP model on the Waymo Open Dataset validation set for 3D object detection.  It shows the Average Precision (AP) and Recall for vehicles, pedestrians, and cyclists, using two different matching criteria: Intersection over Union (IoU) and BEV distance.  The results demonstrate the effectiveness of ZOPP in 3D object detection across different difficulty levels (L2).", "section": "Main Results"}, {"figure_path": "4jXaca2NYa/tables/tables_7_2.jpg", "caption": "Table 3: Comparisons of fully-supervised detectors and human-label-free methods. We re-implement these methods and report the AP performance (IoU criterion) of Vehicle within camera FOVs across different distance ranges.", "description": "This table compares the Average Precision (AP) performance of various 3D object detection methods, categorized as fully-supervised and human-label-free.  The comparison is done across three different distance ranges (0-30m, 30-50m, and 50+m) to illustrate the impact of distance on performance. The IoU criterion is used for evaluating the accuracy of bounding boxes.  The results highlight the performance differences between methods trained with human-labeled data versus those that do not require human labels.", "section": "4 Main Results"}, {"figure_path": "4jXaca2NYa/tables/tables_8_1.jpg", "caption": "Table 4: Comparisons of ZOPP and state-of-the-art LiDAR semantic segmentation methods.", "description": "This table compares the performance of the proposed ZOPP method against other state-of-the-art LiDAR semantic segmentation methods.  The comparison is done using various metrics across different object categories (vehicle, motorcyclist, bicyclist, pedestrian, sign, traffic light, pole, cone, bicycle, motorcycle, building, vegetation, tree trunk, curb, road, lane marker, other ground, walkable, sidewalk).  The results show how ZOPP performs relative to existing methods in terms of accuracy for semantic segmentation of LiDAR point cloud data.", "section": "Main Results"}, {"figure_path": "4jXaca2NYa/tables/tables_9_1.jpg", "caption": "Table 5: Comparison of 3D occupancy prediction performance.", "description": "This table compares the performance of ZOPP against other state-of-the-art methods on 3D occupancy prediction.  The metrics used include mean Intersection over Union (mIoU) and Average Precision (AP) for various object categories (vehicle, bicyclist, pedestrian, etc.). The table highlights the strengths and weaknesses of ZOPP in relation to existing approaches.", "section": "4.2 Main Results"}, {"figure_path": "4jXaca2NYa/tables/tables_15_1.jpg", "caption": "Table 2: Verifying 3D object detection ability of our ZOPP on WOD val set. Metrics are 3D AP of L2 difficulties for Vehicle, Pedestrian, and Cyclist.", "description": "This table presents the results of the 3D object detection performance evaluation on the Waymo Open Dataset (WOD) validation set. The evaluation metrics used are Average Precision (AP) and Recall, calculated for different levels of difficulty (L2) and across various object categories (Vehicle, Pedestrian, and Cyclist).  The table demonstrates the ability of the proposed ZOPP framework to accurately detect 3D objects in autonomous driving scenes.", "section": "4.2 Main Results"}, {"figure_path": "4jXaca2NYa/tables/tables_16_1.jpg", "caption": "Table 8: Comparisons of ZOPP on semantic segmentation before and after the proposed parallax occlusion and noise filtering.", "description": "This table compares the performance of semantic segmentation on various object categories before and after applying parallax occlusion and noise filtering.  The results demonstrate the improvement in segmentation accuracy achieved by this filtering module, particularly for foreground objects.  Note that the performance on objects like signs and traffic lights, which are typically less affected by occlusion, remains relatively consistent.", "section": "D.3 Parallax Occlusion and Noise Filtering"}, {"figure_path": "4jXaca2NYa/tables/tables_18_1.jpg", "caption": "Table 9: Verifying the effect of parallax noise filtering and point completion for 3D bounding box interpretation on WOD val set. Metrics are Recall of L2 difficulties for Vehicle, Pedestrian, and Cyclist with IoU criterion. The results are in the FOV of the cameras.", "description": "This table presents the recall of the 3D bounding box interpretation on the Waymo Open Dataset validation set before and after applying parallax noise filtering and point completion.  The metrics used are Recall of L2 difficulties (IoU criterion) for vehicles, pedestrians, and cyclists.  The results are limited to the field of view of the cameras.", "section": "D.4 Point completion"}]