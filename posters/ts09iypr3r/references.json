{"references": [{"fullname_first_author": "P. Abbeel", "paper_title": "Apprenticeship learning via inverse reinforcement learning", "publication_date": "2004-00-00", "reason": "This paper introduces a novel approach to reinforcement learning, where an agent learns from an expert's demonstrations rather than explicit rewards, which is highly relevant to the current paper's exploration of concave utility reinforcement learning."}, {"fullname_first_author": "D. Adamskiy", "paper_title": "A closer look at adaptive regret", "publication_date": "2016-00-00", "reason": "This paper provides a comprehensive analysis of adaptive regret, a crucial concept in online learning which is essential to the current paper's investigation of non-stationary environments."}, {"fullname_first_author": "P. Auer", "paper_title": "Near-optimal regret bounds for reinforcement learning", "publication_date": "2008-00-00", "reason": "This is a foundational paper in reinforcement learning that establishes near-optimal regret bounds, a key benchmark for the current paper's novel algorithm."}, {"fullname_first_author": "N. Cesa-Bianchi", "paper_title": "Prediction, Learning, and Games", "publication_date": "2006-00-00", "reason": "This book provides a comprehensive overview of prediction, learning, and game theory, offering a theoretical foundation for the current paper's utilization of online learning techniques."}, {"fullname_first_author": "Y. Freund", "paper_title": "A decision-theoretic generalization of on-line learning and an application to boosting", "publication_date": "1997-00-00", "reason": "This paper introduces the influential framework of online learning with expert advice, which forms a theoretical basis for the meta-learning approach used in the current work."}]}