[{"figure_path": "vMMzjCr5Zj/tables/tables_6_1.jpg", "caption": "Table 1: Average zero-shot forecast performance (measured as RMSE over 10 runs) of LPTM and pre-trained baselines. The best model is in bold.", "description": "This table presents a comparison of the root mean squared error (RMSE) achieved by LPTM and several other pre-trained baselines across multiple time series forecasting tasks.  The performance is evaluated under zero-shot conditions, meaning that no further fine-tuning of the pre-trained models was performed before testing on the benchmarks. The results are averaged over 10 independent runs to ensure reliability, and the best performing model for each task is highlighted in bold.", "section": "Results"}, {"figure_path": "vMMzjCr5Zj/tables/tables_7_1.jpg", "caption": "Table 1: Average zero-shot forecast performance (measured as RMSE over 10 runs) of LPTM and pre-trained baselines. The best model is in bold.", "description": "This table presents a comparison of the root mean squared error (RMSE) achieved by the proposed LPTM model and several pre-trained baseline models on eight different forecasting tasks. The performance is evaluated under zero-shot settings, meaning the models are not fine-tuned for any specific task before evaluation. The best-performing model for each task is highlighted in bold.", "section": "6 Results"}, {"figure_path": "vMMzjCr5Zj/tables/tables_8_1.jpg", "caption": "Table 1: Average zero-shot forecast performance (measured as RMSE over 10 runs) of LPTM and pre-trained baselines. The best model is in bold.", "description": "This table presents the results of a zero-shot forecasting experiment comparing the performance of the proposed Large Pre-trained Time-series Model (LPTM) against several pre-trained baseline models across various time series forecasting tasks.  The performance metric used is the Root Mean Squared Error (RMSE), averaged across 10 runs for each model and task.  The tasks are performed without any fine-tuning of the models, hence the term \"zero-shot\". The best performing model for each task is highlighted in bold.", "section": "6 Results"}, {"figure_path": "vMMzjCr5Zj/tables/tables_14_1.jpg", "caption": "Table 4: Average training time (minutes) till convergence for LPTM and neural baselines. LPTM-TB shows the time taken by LPTM to reach performance of top baseline (in benchmarks where LPTM outperforms it). Since some baselines are specific to forecasting or classification and we do not beat the state-of-art in few benchmarks we designate these cells in the table as NA.", "description": "This table presents the average training time in minutes until convergence for the LPTM model and several neural baseline models across various time series forecasting and classification tasks.  The models are evaluated on their performance on eight different datasets, and the training time is shown for each. The LPTM-TB column shows the time taken by LPTM to achieve the performance of the best baseline model in the cases where LPTM outperforms the other baselines.", "section": "Appendix B Data efficiency"}, {"figure_path": "vMMzjCr5Zj/tables/tables_17_1.jpg", "caption": "Table 1: Average zero-shot forecast performance (measured as RMSE over 10 runs) of LPTM and pre-trained baselines. The best model is in bold.", "description": "This table presents the results of a zero-shot forecasting experiment comparing the performance of the proposed LPTM model against several pre-trained baselines across multiple datasets.  The performance metric is the Root Mean Squared Error (RMSE), averaged over 10 runs. The best performing model for each dataset is highlighted in bold.", "section": "6 Results"}, {"figure_path": "vMMzjCr5Zj/tables/tables_17_2.jpg", "caption": "Table 1: Average zero-shot forecast performance (measured as RMSE over 10 runs) of LPTM and pre-trained baselines. The best model is in bold.", "description": "This table presents the results of a zero-shot forecasting experiment comparing the performance of the proposed Large Pre-trained Time-series Model (LPTM) against several state-of-the-art pre-trained baselines.  The performance metric used is Root Mean Squared Error (RMSE), averaged over 10 independent runs. The models were evaluated on eight different forecasting tasks across various domains, including influenza forecasting, electricity demand, and traffic flow. The best performing model for each task is highlighted in bold.", "section": "6 Results"}]