[{"figure_path": "hEKSSsv5Q9/figures/figures_1_1.jpg", "caption": "Figure 1: The probability curvatures distribution of the surrogate model (GPT-2), the target model (Llama-3) and the model after alignment (GPT-2_DALD) on human-written passages and machine-generated passages from PubMed dataset.", "description": "This figure compares the probability curvature distributions of three models: a surrogate model (GPT-2), a target model (Llama-3), and the surrogate model after alignment with the target model's distribution (GPT-2_DALD).  The distributions are shown separately for human-written and machine-generated text from the PubMed dataset.  The alignment process aims to make the surrogate model's distribution more similar to that of the target model, improving the accuracy of detecting machine-generated text in a black-box setting.  The visual comparison shows that after alignment, the GPT-2_DALD model's distribution becomes much closer to the Llama-3 model's distribution for both human and machine-generated texts.", "section": "3 Method"}, {"figure_path": "hEKSSsv5Q9/figures/figures_1_2.jpg", "caption": "Figure 2: The performance comparison of a static surrogate model on different target models including ChatGPT (GPT-3.5) and GPT-4. The results are based on Fast-DetectGPT with GPT-Neo-2.7B as the surrogate model.", "description": "This figure shows the performance of a static surrogate model (GPT-Neo-2.7B) used within the Fast-DetectGPT framework when trying to detect various versions of the ChatGPT (GPT-3.5) and GPT-4 models.  The x-axis represents different versions of the target models (GPT-3.5 and GPT-4 released on different dates). The y-axis shows the Area Under the ROC Curve (AUROC), a metric representing the model's ability to distinguish between human-written text and AI-generated text.  The significant drop in AUROC for later model versions highlights the limitation of using a static surrogate model for detecting constantly evolving LLMs.", "section": "1 Introduction"}, {"figure_path": "hEKSSsv5Q9/figures/figures_3_1.jpg", "caption": "Figure 3: An overview of our proposed DALD framework. Our method aligns the distribution of the surrogate model and the target model.", "description": "This figure illustrates the DALD framework, highlighting the key difference between existing methods (Fast-DetectGPT) and the proposed approach.  Fast-DetectGPT uses a misaligned surrogate model, leading to inaccurate classification of human-written vs. AI-generated text. In contrast, DALD aligns the surrogate model's distribution with the target model's distribution using parameter-efficient instruction tuning on a corpus of known LLM-generated text.  This alignment significantly improves the accuracy of the text classification. The figure visually shows how the DALD method addresses the distribution mismatch problem by fine-tuning the surrogate model to match the target model, thus leading to improved performance in black-box LLM detection.", "section": "3 Method"}, {"figure_path": "hEKSSsv5Q9/figures/figures_6_1.jpg", "caption": "Figure 4: The FPR-TPR curve of different methods on XSum, Writing and PubMed dataset. The results show that our method achieves highest score at low FPR compared with DNA-GPT and Fast-DetectGPT.", "description": "This figure displays the Receiver Operating Characteristic (ROC) curves for three different LLM detection methods (DNA-GPT, Fast-DetectGPT, and DALD) across three distinct datasets (XSum, Writing, PubMed).  The ROC curve plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.  The curves visually demonstrate the performance of each method, highlighting DALD's superior performance at lower FPR values indicating a better balance between correctly identifying LLM-generated text and minimizing false positives.", "section": "4.2 Main Results"}, {"figure_path": "hEKSSsv5Q9/figures/figures_6_2.jpg", "caption": "Figure 5: AUROC results from our fine-tuned surrogate model with different training dataset size.", "description": "This figure demonstrates the impact of training dataset size on the Area Under the Receiver Operating Characteristic (AUROC) curve for the proposed Distribution-Aligned LLMs Detection (DALD) method.  Three datasets (XSum, Writing, PubMed) are used to evaluate the model's performance with two different surrogate models (LLaMA-2 and LLaMA-3).  The results show how AUROC increases as the size of the training dataset grows, eventually plateauing, indicating that DALD is effective with a relatively small training dataset, and the performance difference between two surrogate models are insignificant.", "section": "4 Experiments"}, {"figure_path": "hEKSSsv5Q9/figures/figures_8_1.jpg", "caption": "Figure 6: Results comparison on samples with the adversarial attack. The performance improvement with our method on different methods shows that our method is robust to adversarial attacks.", "description": "This figure shows the robustness of the proposed method (DALD) against adversarial attacks.  The AUROC (Area Under the Receiver Operating Characteristic curve) is plotted against the ratio of revisions made to the original text.  The graph compares the performance of DNA-GPT and Fast-DetectGPT, both individually and after incorporating the DALD improvements.  It demonstrates that DALD consistently improves the robustness of both DNA-GPT and Fast-DetectGPT against adversarial attacks, maintaining higher AUROC scores even when a significant portion of the text is revised.", "section": "4.3 Experimental Analysis"}]