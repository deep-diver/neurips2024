{"references": [{"fullname_first_author": "Ribeiro", "paper_title": "\"why should I trust you?: Explaining the predictions of any classifier", "publication_date": "2016-06-01", "reason": "This paper introduces LIME, a popular local explanation method, which is used as a basis for the paper's definition of local explainability and is frequently compared to other methods."}, {"fullname_first_author": "Lundberg", "paper_title": "A unified approach to interpreting model predictions", "publication_date": "2017-12-01", "reason": "This paper introduces SHAP, another popular local explanation method, which is analyzed in the paper's examples and is relevant to the discussion on the locality of explanations."}, {"fullname_first_author": "Ribeiro", "paper_title": "Anchors: High-precision model-agnostic explanations", "publication_date": "2018-01-01", "reason": "This paper introduces Anchors, a local explanation method that is used as a key example in the paper due to its explicit consideration of the locality of explanations."}, {"fullname_first_author": "Smilkov", "paper_title": "Smoothgrad: removing noise by adding noise", "publication_date": "2017-06-01", "reason": "This paper introduces SmoothGrad, a gradient-based explanation method, which is discussed as an example of gradient-based explanation techniques."}, {"fullname_first_author": "Agarwal", "paper_title": "Towards the unification and robustness of perturbation and gradient-based explanations", "publication_date": "2021-07-01", "reason": "This paper provides a general theoretical analysis of gradient-based explanations, which are a focus of the paper, and discusses their properties."}]}