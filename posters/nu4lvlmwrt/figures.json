[{"figure_path": "nU4lvlMwrt/figures/figures_1_1.jpg", "caption": "Figure 1: Comparison with specific (a) and (b). The Figure 2: Directly adapting the general segmentation model to ultra image scene will cause fragmentation phenomenon (a): the prediction results of the edge areas between adjacent patches (even in overlapped patches) are inconsistent.", "description": "This figure compares two approaches for ultra image segmentation.  (a) shows a specific method that uses a combination of global and local branches, while (b) shows a general model which directly adapts a general segmentation model to the ultra-high-resolution image. The figure highlights the fragmentation problem encountered when directly using a general segmentation model with sliding windows on ultra images: inconsistencies in predictions arise at patch boundaries. Figure 2 further illustrates this fragmentation, contrasting the fragmented prediction results with the ground truth.", "section": "1 Introduction"}, {"figure_path": "nU4lvlMwrt/figures/figures_3_1.jpg", "caption": "Figure 3: The Architecture of SGNet. An ultra image I is randomly cropped to obtain a local patch Ilocal and a surrounding patch Iglobal containing more context information of any size, which are respectively sent to the general segmentation module and the surrounding context-guided branch to extract features. The resulting features are aggregated through simple concatenation and used to generate high-quality predictions. General segmentation module can be applied to any segmentation model, and surrounding context-guided branch consistently achieves stable improvements on it. LN, W-MSA, and GAP stand for layer normalization, window-based multi-head self-attention, and global average pooling, respectively.", "description": "This figure illustrates the architecture of the proposed SGNet framework for ultra image segmentation. It shows how a local patch and its surrounding context are processed by two separate branches: a general segmentation module and a surrounding context-guided branch.  The output feature maps from both branches are then concatenated and fed into segmentation heads to generate the final prediction.  The surrounding context-guided branch incorporates a surrounding context integration module to leverage information from the broader area around the local patch. The framework also uses loss functions to improve boundary consistency between predictions of adjacent patches and the overall segmentation accuracy.", "section": "3.2 Architecture"}, {"figure_path": "nU4lvlMwrt/figures/figures_6_1.jpg", "caption": "Figure 9: The qualitative results of different methods in DeepGlobe (top row, 2448x2448) and Inria Aerial (bottom row, 5000x5000).", "description": "This figure compares the qualitative segmentation results of different methods on two datasets: DeepGlobe and Inria Aerial.  The top row shows results for DeepGlobe images (2448x2448 resolution), while the bottom row presents results for Inria Aerial images (5000x5000 resolution). Each row displays the original image, the ground truth segmentation, and the results obtained using FCtL, ISDNet, and the proposed SGNet method.  The visual comparison highlights the differences in accuracy and boundary delineation between the various methods.", "section": "E More Qualitative Result"}, {"figure_path": "nU4lvlMwrt/figures/figures_7_1.jpg", "caption": "Figure 10: The comparison of adding SCB on different models in Cityscapes (2048\u00d71024).", "description": "This figure compares the performance of adding the Surrounding Context-guided Branch (SCB) to different general segmentation models in the Cityscapes dataset. The images show the ground truth, results from HRNet and DeepLabV3Plus alone, and results from the same models with SCB added.  The addition of SCB improves segmentation accuracy for all models, demonstrating its effectiveness in enhancing overall segmentation performance.", "section": "4.4 Ablation Study"}, {"figure_path": "nU4lvlMwrt/figures/figures_13_1.jpg", "caption": "Figure 7: Comparison of existing architectures of ultra image segmentation.", "description": "This figure compares five different architectures for ultra image segmentation: (a) Whole Inference, (b) Slide Inference, (c) Global & Local, (d) Shallow & Deep, and (e) Ours (SGNet).  Whole inference uses a resized image as input to a general segmentation model, losing detail. Slide inference processes the image in overlapping patches, which can lead to inconsistencies at patch boundaries. Global & Local and Shallow & Deep approaches use both global and local information but may have limitations in scalability or computational cost. The authors' proposed architecture (SGNet) is designed to leverage surrounding context for enhanced accuracy and scalability.", "section": "3 Methodology"}, {"figure_path": "nU4lvlMwrt/figures/figures_15_1.jpg", "caption": "Figure 8: The visualization of different methods in CelebAMask-HQ. We resized the images from 1024 to 2448 pixels to simulate ultra-high resolution and used sliding window of size 512 without overlap for inference.", "description": "This figure compares the performance of SGNet and DeepLabV3Plus on the CelebAMask-HQ dataset.  To simulate ultra-high resolution images, the images were upscaled from 1024 pixels to 2448 pixels. A sliding window approach with a window size of 512 pixels and no overlap was used for inference. The figure shows that SGNet produces more accurate and detailed segmentations compared to DeepLabV3Plus.", "section": "D Large Scale Human Subject Segmentation Study"}, {"figure_path": "nU4lvlMwrt/figures/figures_16_1.jpg", "caption": "Figure 9: The qualitative results of different methods in DeepGlobe (top row, 2448x2448) and Inria Aerial (bottom row, 5000x5000).", "description": "This figure shows a qualitative comparison of the proposed SGNet method against other state-of-the-art ultra image segmentation methods (FCtL and ISDNet) on the DeepGlobe and Inria Aerial datasets.  The top row displays results for a DeepGlobe image (2448x2448 resolution), while the bottom row shows results for an Inria Aerial image (5000x5000 resolution).  Each row presents the original image, ground truth segmentation, and segmentation results for FCtL, ISDNet, and the proposed SGNet. The visual comparison highlights the improved accuracy and boundary consistency achieved by SGNet.", "section": "E More Qualitative Result"}, {"figure_path": "nU4lvlMwrt/figures/figures_16_2.jpg", "caption": "Figure 10: The comparison of adding SCB on different models in Cityscapes (2048\u00d71024).", "description": "This figure compares the results of adding the Surrounding Context-guided Branch (SCB) to two different general segmentation models (DeepLab and HRNet) on the Cityscapes dataset. It visually demonstrates the improvement in segmentation accuracy achieved by incorporating the SCB, showcasing its effectiveness in refining the predictions of these models.", "section": "4.4 Ablation Study"}, {"figure_path": "nU4lvlMwrt/figures/figures_16_3.jpg", "caption": "Figure 11: The comparison of adding SCB on different models in Gleason (5120\u00d75120).", "description": "This figure shows a comparison of the Gleason dataset segmentation results using HRNet and DeepLabV3Plus models, both with and without the addition of the Surrounding Context-guided Branch (SCB). The top row displays the original image, the HRNet model prediction, and the DeepLabV3Plus model prediction. The bottom row shows the ground truth, the HRNet model with SCB, and the DeepLabV3Plus model with SCB. This visualization demonstrates the improvement in segmentation accuracy provided by incorporating SCB into the base models.", "section": "4.4 Ablation Study"}]