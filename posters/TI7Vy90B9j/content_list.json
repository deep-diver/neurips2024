[{"type": "text", "text": "Boosting Perturbed Gradient Ascent for Last-Iterate Convergence in Games ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 This paper introduces a payoff perturbation technique, introducing a strong convex  \n2 ity to players\u2032 payoff functions in games. This technique is specifically designed   \n3 for first-order methods to achieve last-iterate convergence in games where the   \n4 gradient of the payoff functions is monotone in the strategy profile space, poten  \n5 tially containing additive noise. Although perturbation is known to facilitate the   \n6 convergence of learning algorithms, the magnitude of perturbation requires careful   \n7 adjustment to ensure last-iterate convergence. Previous studies have proposed a   \n8 scheme in which the magnitude is determined by the distance from an anchoring   \n9 or reference strategy, which is periodically re-initialized. In response, this paper   \n0 proposes Gradient Ascent with Boosting Payoff Perturbation, which incorporates a   \n1 novel perturbation into the underlying payoff function, maintaining the periodically   \n2 re-initializing anchoring strategy scheme. This innovation empowers us to provide   \n3 faster last-iterate convergence rates against the existing payoff perturbed algorithms,   \n4 even in the presence of additive noise. ", "page_idx": 0}, {"type": "text", "text": "151 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "16  This study considers online learning in monotone games, where the gradient of the payoff function is   \n17 monotone in the strategy profile space. Monotone games encompassed diverse well-studied games as   \n18 special instances, such as concave-convex games, zero-sum polymatrix games [Cai and Daskalakis,   \n19 2011, Cai et al., 2016], $\\lambda$ -cocoercive games [Lin et al., 2020], and Cournot competition [Bravo et al.,   \n20 2018]. Due to their wide-ranging applications, there has been growing interest in developing learning   \n21 algorithms to compute Nash equilibria in monotone games.   \n22 Typical learning algorithms such as Gradient Ascent [Zinkevich, 2003] and Multiplicative Weights   \n23 Update [Bailey and Piliouras, 2018] have been extensively studied and shown to converge to equilibria   \n24 in an average-iterate sense, which is termed average-iterate convergence. However, averaging the   \n25 strategies can be undesirable because it can lead to additional memory or computational costs in the   \n26 context of training Generative Adversarial Networks [Goodfellow et al., 2014] and preference-based   \n27 fine-tuning of large language models [Munos et al., 2023, Swamy et al., 2024]. In contrast, last-iterate   \n28 convergence, in which the updated strategy profile itself converges to a Nash equilibrium, has emerged   \n29  as a stronger notion than average-iterate convergence.   \n30 Payoff-perturbed algorithms have recently been regaining attention in this context [Sokota et al.,   \n31 2023, Liu et al., 2023]. Payoff perturbation is a classical technique, e.g., [Facchinei and Pang, 2003]   \n32 and introduces a strongly convex penalty to the players\u2019 payoff functions to stabilize learning, which   \n33 leads to convergence to approximate equilibria, not only in the full feedback setting where the perfect   \n34 gradient vector of the payoff function can be used to update strategies, but also in the noisy feedback   \n35setting where the gradient vector is contaminated by noise.   \n36  However, to ensure convergence toward a Nash equilibrium of the underlying game, the magnitude   \n37 of perturbation requires careful adjustment. As a remedy, it is adjusted by the distance from an   \n38 anchoring or reference strategy. Koshal et al. [2010] and Tatarenko and Kamgarpour [2019] simply   \n39 decay the magnitude in each iteration, and their methods asymptotically converge, since the perturbed   \n40 function gradually loses strong convexity. In response to this, recent studies [Perolat et al., 2021, Abe   \n41 et al., 2023, 2024] re-initialize the anchoring strategies periodically, or in a predefined interval, so   \n42 that they keep the perturbed function strongly convex and achieve non-asymptotic convergence.   \n43 We should also mention the optimistic family of learning algorithms, which incorporates recency   \n44 bias and exhibits last-iterate convergence [Daskalakis et al., 2018, Daskalakis and Panageas, 2019,   \n45 Mertikopoulos et al., 2019, Wei et al., 2021]. Unfortunately, the property has mainly been proven in   \n46 the full feedback setting. Although it might empirically work with noisy feedback, the convergence   \n47 is slower, as demonstrated in Section 6. The fast convergence in the noisy feedback setting is another   \n48 reason why payoff-perturbed algorithms have been gaining renewed interest.   \n49  This paper, in particular, focuses on Adaptively Perturbed Mirror Descent (APMD) [Abe et al., 2024],   \n50 which achieves $\\tilde{\\mathcal{O}}(1/\\sqrt{T})^{1}$ and $\\tilde{\\mathcal{O}}(1/T^{\\frac{1}{10}})$ last-iterate convergence rates in the full/noisy feedback   \n51 setting, respectively. The motivation of this study lies in improving the convergence rates of APMD.   \n52  We propose an elegant one-line modification of APMD, which effectively accelerates convergence.   \n53  In fact, we just add the difference between the current anchoring strategy and the initial anchoring   \n54  strategy to the payoff perturbation function in APMD.   \n5  Our contributions are manifold. Firstly, we propose a novel payoff-perturbed learning algorithm   \n56 named Gradient Ascent with Boosting Payoff Perturbation (GABP). This method incorporates a   \n57 unique perturbation payoff function, enabling it to achieve faster convergence rates than APMD. Sub  \n58 sequently, we prove that GABP exhibits accelerated $\\tilde{\\mathcal{O}}(1/T)$ and $\\tilde{\\mathcal{O}}(1/\\bar{T}^{\\frac{1}{7}})$ last-iterate convergence   \n59 rates to a Nash equilibrium with full and noisy feedback, respectively. We further show that each   \n60 player's individual regret is at most $\\mathcal{O}\\left((\\ln T)^{2}\\right)$ in the full feedback setting, provided all players play   \n61 according to GABP. Finally, through our experiments, we demonstrate the competitive or superior   \n62  performance of GABP over Optimistic Gradient Ascent [Daskalakis et al., 2018, Wei et al., 2021]   \n63  and APMD in concave-convex games, irrespective of the presence of noise. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "64  2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "65  Monotone games. In this study, we focus on a continuous multi-player game, which is denoted   \n66 as $\\left([N],(\\Bar{\\mathcal{X}_{i}})_{i\\in[N]},(v_{i})_{i\\in[N]}\\right)$ $[\\dot{N}]\\,=\\,\\{1,2,\\cdot\\cdot\\cdot\\,,N\\}$ denotes the set of $N$ players. Each player   \n67 $i\\,\\in\\,[N]$ chooses a strategy $\\pi_{i}$ from a $d_{i}$ -dimensional compact convex strategy space $\\mathcal{X}_{i}$ , and we   \n68   write $\\begin{array}{r}{\\dot{\\boldsymbol{\\mathcal{X}}}=\\prod_{i\\in[N]}\\boldsymbol{\\mathcal{X}}_{i}}\\end{array}$ . Each player $i$ aims to maximize her payoff function $v_{i}:\\mathcal{X}\\rightarrow\\mathbb{R}$ which   \n69  s differentiable on $\\mathcal{X}$ . We denote $\\textstyle\\pi_{-i}\\in\\prod_{j\\neq i}X_{j}$ as the strategies of all players except player $i$   \n70  and $\\pi=(\\pi_{i})_{i\\in[N]}\\in\\mathcal{X}$ as the strategy profie. This paper particularly studies learning in smooth   \n71 monotone games, where the gradient operator $V(\\cdot)\\,=\\,(\\nabla_{\\pi_{i}}v_{i}(\\cdot))_{i\\in[N]}$ of the payoff functions is   \n72monotone: $\\forall\\pi,\\pi^{\\prime}\\in\\mathcal{X}$ ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\langle V(\\pi)-V(\\pi^{\\prime}),\\pi-\\pi^{\\prime}\\rangle\\leq0,\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "73 and $L$ -Lipschitz for $L>0$ ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|V(\\pi)-V(\\pi^{\\prime})\\|\\le L\\,\\|\\pi-\\pi^{\\prime}\\|\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "74where $\\|\\cdot\\|$ denotes the $\\ell_{2}$ -norm. ", "page_idx": 1}, {"type": "text", "text": "75 Many common and well-studied games, such as concave-convex games, zero-sum polymatrix games   \n76 [Cai et al., 2016], $\\lambda$ -cocoercive games [Lin et al., 2020], and Cournot competition [Bravo et al.   \n77 2018], are included in the class of monotone games.   \n78  Example 2.1 (Concave-Convex Games). Consider a game defined by $(\\{1,2\\},(\\mathcal{X}_{1},\\mathcal{X}_{2}),(v,-v))$ \uff0c   \n79where $v:\\mathcal{X}_{1}\\times\\mathcal{X}_{2}\\rightarrow\\mathbb{R}$ . In this game, player 1 wishes to maximize $v$ , while player 2 aims to   \n80 minimize $v$ .If $v$ is concave in $x_{1}\\in\\mathcal{X}_{1}$ and convex in $x_{2}\\in\\mathcal{X}_{2}$ , the game is called a concave-convex   \n81 game or minimax optimization problem, and it is not hard to see that this game is a special case of   \n82monotone games.   \n83  Nash equilibrium and gap function.  A Nash equilibrium [Nash, 1951] is a widely used solution   \n84 concept for a game, which is a strategy profile where no player can gain by changing her own strategy.   \n85 Formally, a strategy profile $\\pi^{*}\\in\\mathcal{X}$ is called a Nash equilibrium, if and only if $\\pi^{*}$ satisfies the   \n86 following condition: ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\forall i\\in[N],\\forall\\pi_{i}\\in\\mathcal{X}_{i},\\;v_{i}(\\pi_{i}^{*},\\pi_{-i}^{*})\\geq v_{i}(\\pi_{i},\\pi_{-i}^{*}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "87 We define the set of all Nash equilibria to be $\\Pi^{*}$ . It has been shown that there exists at least one Nash   \n88  equilibrium [Debreu, 1952] for any smooth monotone games.   \n89 To quantify the proximity to Nash equilibrium for a given strategy profile $\\pi\\in\\mathcal{X}$ ,weusethegap   \n90  function, which is defined as: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{GAP}(\\pi):=\\operatorname*{max}_{\\tilde{\\pi}\\in\\mathcal{X}}\\left\\langle V(\\pi),\\tilde{\\pi}-\\pi\\right\\rangle.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "91 Additionally, we use another measure of proximity to Nash equilibrium, referred to as the tangent   \n92 residual. This measure is defined as: ", "page_idx": 2}, {"type": "equation", "text": "$$\nr^{\\mathrm{tan}}(\\pi):=\\operatorname*{min}_{a\\in N_{x}(\\pi)}\\left\\lVert-V(\\pi)+a\\right\\rVert,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "93  where $\\begin{array}{r}{N_{\\mathcal{X}}(\\pi)=\\{(a_{i})_{i\\in[N]}\\in\\prod_{i=1}^{N}\\mathbb{R}^{d_{i}}\\mid\\sum_{i=1}^{N}\\langle a_{i},\\pi_{i}^{\\prime}-\\pi_{i}\\rangle\\le0,\\,\\forall\\pi^{\\prime}\\in\\mathcal{X}\\}}\\end{array}$ is the normal cone of   \n94 $\\pi\\in\\mathcal{X}$ . It is easy to see that $\\mathrm{GAP}(\\pi)\\geq0$ (resp. $r^{\\mathrm{tan}}(\\pi)\\geq0)$ for any $\\pi\\in\\mathcal{X}$ , and the equality holds   \n95  f and only if $\\pi$ is a Nash equilibrium. Defining $D:=\\operatorname*{sup}_{\\pi,\\pi^{\\prime}\\in\\mathcal{X}}\\|\\pi-\\pi^{\\prime}\\|$ as the diameter of $\\mathcal{X}$ , the   \n96 gap function for any given strategy profile $\\pi\\in\\mathcal{X}$ is upper bounded by its tangent residual. ", "page_idx": 2}, {"type": "text", "text": "97Lemma 2.2 (Lemma 2 of Cai et al. [2022a]). For any $\\pi\\in\\mathcal{X}$ wehave: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{GAP}(\\pi)\\leq D\\cdot r^{\\tan}(\\pi).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "98 The gap function and the tangent residual are standard measures of proximity to Nash equilibrium;   \n99e.g., it has been used in Cai and Zheng [2023], Abe et al. [2024].   \n100 Problem setting.  This study focuses on the online learning setting in which the following process   \n101 repeats from iterations $t=1$ to $T$ : (i) Each player $i\\in[N]$ chooses her strategy $\\pi_{i}^{t}\\in\\mathcal{X}_{i}$ , based on   \n102 previously observed feedback; (i) Each player $i$ receives the (noisy) gradient vector $\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})$ as   \n103 feedback. This study examines two feedback models: full feedback and noisy feedback. In the full   \n104 feedback setting, each player observes the perfect gradient vector $\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})=\\nabla_{\\pi_{i}}v_{i}(\\pi^{t})$ . In the   \n105 noisy feedback setting, each player's gradient feedback $\\nabla_{\\pi_{i}}v_{i}(\\pi^{t})$ is contaminated by an additive   \n106  noise vector $\\xi_{i}^{t}$ , i.e., $\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})\\,=\\,\\nabla_{\\pi_{i}}v_{i}(\\pi^{t})+\\xi_{i}^{t}$ ,where $\\xi_{i}^{t}\\,\\in\\,\\mathbb{R}^{d_{i}}$ . Throughout the paper, we   \n107 assume that $\\xi_{i}^{t}$ is the zero-mean and bounded-variance noise vector at each iteration $t$   \n108 Adaptively perturbed Mirror Descent. To facilitate the convergence in the online learning setting,   \n109 recent studies have utilized a payoff perturbation technique, where payoff functions are perturbed by   \n110 strongly convex functions [Sokota et al., 2023, Liu et al., 2023, Abe et al., 2022]. However, while   \n111 the addition of these strongly convex functions leads learning algorithms to converge to a stationary   \n112 point, this stationary point may be significantly distant from a Nash equilibrium. Therefore, the   \n113 magnitude of perturbation requires careful adjustment. Perolat et al. [2021], Abe et al. [2023, 2024]   \n114 have introduced a scheme in which the magnitude is determined by the distance (or divergence   \n115 function) from an anchoring strategy $\\sigma_{i}$ , which is periodically re-initialized. Specifically, Adaptively   \n116 Perturbed Mirror Descent (APMD) [Abe et al., 2024] perturbs each player's payoff function by a   \n117 strongly convex divergence function $G(\\pi_{i},\\sigma_{i}):\\mathcal{X}_{i}\\times\\bar{\\mathcal{X}_{i}}\\rightarrow[0,\\infty)$ , where the anchoring strategy $\\sigma_{i}$   \n118 is periodically replaced by the current strategy $\\pi_{i}^{t}$ every predefined iterations $T_{\\sigma}$   \n119  Let us define $\\sigma_{i}^{k(t)}$ as the anchoring strategy after $k(t)$ updates. Since $\\sigma_{i}$ is overwritten every $T_{\\sigma}$   \n120 iterations, we can write $k(t)=\\lfloor(t-1)/T_{\\sigma}\\rfloor+1$ and T(k(t)-1)+1. Except for the payoff   \n121 perturbation and the update of the anchor strategy, APMD updates each player $i$ 's strategy in the   \n122 same way as standard Mirror Descent algorithms: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\pi_{i}^{t+1}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{\\eta_{t}\\left\\langle\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})-\\mu\\nabla_{\\pi_{i}}G(\\pi_{i}^{t},\\sigma_{i}^{k(t)}),x\\right\\rangle-D_{\\psi}(x,\\pi_{i}^{t})\\right\\},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Require: Learning rates $\\{\\eta_{t}\\}_{t\\ge0}$ , perturbation strength $\\mu$ update interval $T_{\\sigma}$ , initial strategy $\\pi_{i}^{1}$   \n1: $k\\leftarrow1,\\;\\tau\\leftarrow0$   \n2: $\\sigma_{i}^{1}\\gets\\pi_{i}^{1}$   \n3: for $t=1,2,\\cdots,T$ do   \n4:  Receive the gradient feedback $\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})$   \n5: Update the strategy by   \n$\\pi_{i}^{t+1}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{\\eta_{t}\\left\\langle\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})-\\mu\\frac{\\sigma_{i}^{k}-\\sigma_{i}^{1}}{k+1}-\\mu\\left(\\pi_{i}^{t}-\\sigma_{i}^{k}\\right),x\\right\\rangle-\\frac{1}{2}\\left\\lVert x-\\pi_{i}^{t}\\right\\rVert^{2}\\right\\}$   \n6: $\\tau\\gets\\tau+1$   \n7: if T = T\u3002 then   \n8: $\\begin{array}{l}{{k\\leftarrow k+1,\\;\\tau\\leftarrow0}}\\\\ {{\\sigma_{i}^{k}\\leftarrow\\pi_{i}^{t+1}}}\\end{array}$   \n9:   \n10: end if   \n11\u00b7 end for   \n123  where $\\eta_{t}$ is the learning rate at iteration $t$ $\\mu\\in(0,\\infty)$ is the perturbation strength, and $D_{\\psi}(\\pi_{i},\\pi_{i}^{\\prime})=$   \n124 $\\psi(\\pi_{i})\\dot{-}\\,\\psi(\\pi_{i}^{\\prime})\\nonumber\\,-\\langle\\nabla\\bar{\\psi}(\\pi_{i}^{\\prime}),\\pi_{i}-\\pi_{i}^{\\prime}\\rangle$ as the Bregman divergence associated with a strictly convex   \n125 function $\\psi:\\mathcal{X}_{i}\\to\\mathbb{R}$ . When both $G$ and $D_{\\psi}$ is set to the squared $\\ell^{2}$ -distance, this algorithm can be   \n126 equivalently written as: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi_{i}^{t+1}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{\\eta_{t}\\left\\langle\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})-\\mu\\left(\\pi_{i}^{t}-\\sigma_{i}^{k(t)}\\right),x\\right\\rangle-\\frac{1}{2}\\left\\lVert x-\\pi_{i}^{t}\\right\\rVert^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "127We refer to this version of APMD as Adaptively Perturbed Gradient Ascent (APGA). Abe et al.   \n128 [2024] have shown that APGA exhibits the convergence rates of $\\tilde{\\mathcal{O}}(1/\\sqrt{T})$ and $\\tilde{\\mathcal{O}}(1/T^{\\frac{1}{10}})$ With full   \n129 and noisy feedback, respectively. ", "page_idx": 3}, {"type": "text", "text": "130 3  Gradient ascent with boosting payoff perturbation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "131 This section proposes an accelerated version of APGA, Gradient Ascent with Boosting Payoff   \n132 Perturbation (GABP). The pseudo-code of GABP is outlined in Algorithm 1. In order to obtain faster   \n133 last-iterate convergence rates compared to APGA, GABP introduces a novel payoff perturbation term   \n134  in addition to APGA's original payoff perturbation term, $\\mu\\left(\\pi_{i}^{t}-\\sigma_{i}^{k(t)}\\right)$ . Formally, GABP updates   \n135  each player's strategy as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi_{i}^{t+1}=\\arg\\operatorname*{max}_{\\substack{x\\in\\mathcal{X}_{i}}}\\left\\{\\eta_{t}\\left\\langle\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})-\\underbrace{\\mu_{i}^{\\mathcal{N}_{i}(t)}-\\sigma_{i}^{1}}_{(*)}-\\mu\\left(\\pi_{i}^{t}-\\sigma_{i}^{k(t)}\\right),x\\right\\rangle-\\frac{1}{2}\\left\\Vert x-\\pi_{i}^{t}\\right\\Vert^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "136 The term $(*)$ is our proposed additional perturbation term. It shrinks as $k(t)$ , the number of updates   \n137 of ag(),inerases.   \n138 For a more intuitive explanation of the proposed perturbation term, we present the following update   \n139  rule, which is equivalent to (4): ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pi_{i}^{t+1}=\\operatorname*{arg\\,max}_{x\\in\\mathcal{X}_{i}}\\left\\{\\eta_{t}\\left\\langle\\widehat{\\nabla}_{\\pi}v_{i}(\\pi^{t})-\\mu\\left(\\pi_{i}^{t}-\\frac{k(t)\\sigma_{i}^{k(t)}+\\sigma_{i}^{1}}{k(t)+1}\\right),x\\right\\rangle-\\frac{1}{2}\\left\\lVert x-\\pi_{i}^{t}\\right\\rVert^{2}\\right\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "140 From this formula, it appears that GABP replaces the reference strategy k(t) for the perturbation t1 temin( ofFAPGA wih $\\frac{k(t)\\sigma_{i}^{k(t)}\\!+\\!\\sigma_{i}^{1}}{k(t)\\!+\\!1}$ 142 gradually than in APGA, leading to further stabilization of the learning dynamics. There is a tradeoff ", "page_idx": 3}, {"type": "text", "text": "143 between the shrinking speed of the term $(^{*})$ and the stabilizing impact on the last-iterate convergence   \n14  rate of GABP. The shrinking speed of $1/(k(t)+1)$ achieves a faster convergence rate, and we believe   \n145 that this represents the optimal balance for this trade-off. Although one might think that the term $(*)$   \n146 is closely related to Accelerated Optimistic Gradient (AOG) [Cai and Zheng, 2023], we discuss the   \n147 detail in Appendix F to be concise and avoid a complicated explanation. ", "page_idx": 4}, {"type": "text", "text": "148  4 Last-iterate convergence rates ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "149 This section provides the last-iterate convergence rates of GABP in the full/noisy fedback seting,   \n150respectively. ", "page_idx": 4}, {"type": "text", "text": "151 4.1  Full feedback setting ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "152 First, we demonstrate the last-iterate convergence rate of GABP with full feedback where each player   \n153 receives the perfect gradient vector as feedback at each iteration $t$ i.e., $\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})=\\nabla_{\\pi_{i}}v_{i}(\\pi^{t})$   \n154  Theorem 4.1 shows that the last-iterate strategy profile $\\pi^{T}$ updated by GABP converges to a Nash   \n155 equilibrium with an $\\tilde{\\mathcal{O}}(1/T)$ rate in the full feedback setting.   \n156Theorem4.1. If we use the constant learning rate $\\begin{array}{r}{\\eta_{t}=\\eta\\in\\left(0,\\frac{\\mu}{(L+\\mu)^{2}}\\right)}\\end{array}$ and the constant perturba  \n157 tion strengh $\\mu>0$ and set $\\begin{array}{r}{T_{\\sigma}=c\\cdot\\operatorname*{max}(1,\\frac{6\\ln3(T+1)}{\\ln(1+\\eta\\mu)})}\\end{array}$ for someconstant $c\\geq1$ then the strategy   \n158 $\\pi^{t}$ updated by GABP satisfies for any $t\\in\\{2,3,\\cdot\\cdot\\cdot,T+1\\}$ ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{GAP}(\\pi^{t})\\le\\frac{17c D^{2}\\,\\left(\\frac{6\\ln3(T+1)}{\\ln(1+\\eta\\mu)}+1\\right)}{t-1}\\,\\left(\\mu+\\frac{1+\\eta L}{\\eta}\\right),a n d}\\\\ &{r^{\\tan}(\\pi^{t})\\le\\frac{17c D\\,\\left(\\frac{6\\ln3(T+1)}{\\ln(1+\\eta\\mu)}+1\\right)}{t-1}\\,\\left(\\mu+\\frac{1+\\eta L}{\\eta}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "159 This rate is significantly faster than APGA's rate of $\\tilde{\\mathcal{O}}(1/\\sqrt{T})$ . Moreover, it is a competitive rate   \n160 compared to the previous state-of-the-art rate of $\\mathcal{O}(1/T)$ [Yoon and Ryu, 2021, Cai and Zheng, 2023].   \n161 Note that the rate in Theorem 4.1 holds for any constant perturbation strength $\\mu>0$ ", "page_idx": 4}, {"type": "text", "text": "162 4.1.1 Proof sketch of Theorem 4.1 ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "163 To derive the bound of the gap function $\\operatorname{GAP}(\\pi^{t})$ , it is sufficient to derive that of $r^{\\mathrm{tan}}(\\pi^{t})$ due to   \n164 Lemma 2.2. This section provides the proof sketch of Theorem 4.1. The complete proof is placed in   \n165AppendixB.   \n166 (1) Decomposition of the tangent residual of the last-iterate strategy profile.  From the first  \n167 order optimality condition for $\\pi^{t}$ , we can see that $\\begin{array}{r}{V(\\pi^{t-1})\\,-\\,\\mu\\left(\\pi^{t-1}-\\frac{k(t-1)\\sigma^{k(t-1)}+\\sigma^{1}}{k(t-1)+1}\\right)\\,-}\\end{array}$   \n168 $\\textstyle{\\frac{1}{\\eta}}\\left(\\pi^{t}-\\pi^{t-1}\\right)\\;\\in\\;N_{\\mathcal{X}}(\\pi^{t})$ . Therefore, from the triangle inequality and $L$ -smoothness (2) of the   \n169 gradient operator, the tangent residual $r^{\\mathrm{tan}}(\\pi^{t})$ can be bounded as: ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{r^{\\mathrm{tan}}(\\pi^{t})=\\underset{a\\in N_{\\mathcal{X}}(\\pi^{t})}{\\mathrm{min}}\\left\\|-V(\\pi^{t})+a\\right\\|}&{}\\\\ &{\\qquad\\le\\mathcal{O}\\left(\\left\\|\\pi^{t}-\\pi^{t-1}\\right\\|\\right)+\\mathcal{O}\\left(\\left\\|\\pi^{t-1}-\\sigma^{k(t-1)}\\right\\|\\right)+\\mathcal{O}\\left(\\frac{1}{k(t-1)+1}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "170 Let us define the stationary point $\\pi^{\\mu,\\sigma^{k(t)}}$ , which satisfies the following condition: $\\forall i\\in[N]$ \uff0c ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\pi_{i}^{\\mu,\\sigma^{k(t)}}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{v_{i}\\big(x,\\pi_{-i}^{\\mu,\\sigma^{k(t)}}\\big)-\\frac{\\mu}{2}\\left\\|x-\\hat{\\sigma}^{k(t)}\\right\\|^{2}\\right\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "171  where 0 $\\begin{array}{r}{\\hat{\\sigma}_{i}^{k(t)}=\\frac{k(t)\\sigma_{i}^{k(t)}+\\sigma_{i}^{1}}{k(t)+1}}\\end{array}$ W ill show that $\\pi^{t}$ converges to the stationary point $\\pi^{\\mu,\\sigma^{k(t)}}$ at an   \n172  exponential rate later. By using $\\pi^{\\mu,\\sigma^{k(t)}}$ and applying the triangle inequality to $\\lVert\\boldsymbol{\\pi}^{t}-\\boldsymbol{\\pi}^{t-1}\\rVert$ , we de  \n173  compose the term of ${\\mathcal{O}}(\\|{\\boldsymbol{\\pi}}^{t}\\,-\\,{\\boldsymbol{\\pi}}^{t-1}\\|)$ into ${\\mathcal{O}}(\\|{\\boldsymbol{\\pi}}^{t}-{\\boldsymbol{\\pi}}^{\\mu,\\sigma^{k(t-1)}}\\|)$ 'll) and O(ll\u03c0\u03bc,k(t-1) $\\mathcal{O}(\\|\\pi^{\\mu,\\sigma^{k(t-1)}}\\,-\\,\\pi^{t-1}\\|)$ ", "page_idx": 4}, {"type": "text", "text": "174 Similarly,the tem of(1 -gk(t1)) is decmosed into(1 -\u03bcg(- and ${\\mathcal{O}}(\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\sigma^{k(t-1)}\\|)$ . Then, the tangent residual is bounded as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{r^{\\mathrm{tan}}(\\pi^{t})\\leq\\mathcal{O}\\left(\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\pi^{t}\\right\\|\\right)+\\mathcal{O}\\left(\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\pi^{t-1}\\right\\|\\right)}\\\\ &{\\qquad\\qquad+\\mathcal{O}\\left(\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\sigma^{k(t-1)}\\right\\|\\right)+\\mathcal{O}\\left(\\frac{1}{k(t-1)+1}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "176Therefore, itis eoughtoderivetheconvergence rat $\\lVert\\pi^{\\mu,\\sigma^{k(t)-1}}-\\pi^{t}\\rVert$ and $\\left|\\left|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\sigma^{k(t-1)}\\right|\\right|$ ", "page_idx": 5}, {"type": "text", "text": "177 (2) Convergence rate of $\\pi^{t}$ to the stationary point $\\pi^{\\mu,\\sigma^{k(t)}}$ . Using the strong convexity of the   \n178perturbaion payffunction, $\\frac{\\mu}{2}\\|\\boldsymbol{x}-\\boldsymbol{\\hat{\\sigma}}_{i}^{k(t)}\\|^{2}$ .we show that $\\pi^{t}$ converges to $\\pi^{\\mu,\\sigma^{k(t)}}$ exponentially   \n179 fast (in Lemma B.1). That is, we have for any $t\\geq1$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t}\\right\\|^{2}\\leq\\left(\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t)-1)T_{\\sigma}-1}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "180 Since the first and second terms of the right-hand side of (5) are bounded by the distance between the   \n181 stationary point and the anchoring strategy by using (6), we have: ", "page_idx": 5}, {"type": "equation", "text": "$$\nr^{\\mathrm{tan}}(\\pi^{t})\\leq\\mathcal{O}\\left(\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\sigma^{k(t-1)}\\right\\|\\right)+\\mathcal{O}\\left(\\frac{1}{k(t-1)+1}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "2(\u2462)Potntial ftionfoboing tdistacebtw( and $\\sigma^{k(t)-1}$ . To derive the   \n183upr bound on $\\left|\\left|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\sigma^{k(t-\\mathrm{i})}\\right|\\right|$ we define thefolowing potental funetion $P^{k(t)}$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P^{k(t)}:=\\frac{k(t)(k(t)+1)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\|^{2}}\\\\ &{\\qquad\\qquad+\\left.k(t)(k(t)+1)\\left\\langle\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}},\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "184  By some algebra, we can see that $P^{k(t)}$ is approximately non-increasing (in Lemma B.3). That is, we   \n185 have for any $t\\geq1$ such that $k(t)\\geq2$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{P^{k(t)+1}\\leq P^{k(t)}+(k(t)+1)^{2}\\cdot\\mathcal{O}\\left(\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)+1}\\right\\|+\\left\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\sigma^{k(t)}\\right\\|\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\begin{array}{r}{\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)+1}\\right\\|+\\left\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\sigma^{k(t)}\\right\\|\\le\\mathcal{O}\\left(\\frac{1}{(k(t)+1)^{3}}\\right)}\\end{array}$ 187  for a sufficiently large $T_{\\sigma}$ . Therefore, under the assumption that $T_{\\sigma}\\geq\\Omega\\left(\\ln T\\right)$ , by telescoping of (8) 188 and some algebra, we can derive the following upper bound on $\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|$ (in Lemma B.2): ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|\\leq\\mathcal{O}\\left(\\frac{1}{k(t)+1}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "189 (4) Putting it all together: last-iterate convergence rate of $\\pi^{t}$ .By combining (7) and (9), we get   \n190 $\\begin{array}{r}{r^{\\tan}(\\pi^{t})\\leq\\mathcal{O}\\left(\\frac{1}{k(t-1)+1}\\right)}\\end{array}$ Therefore, since $\\begin{array}{r}{k(t)=\\lfloor\\frac{t-1}{T_{\\sigma}}\\rfloor{+}1}\\end{array}$ ithold that $\\begin{array}{r}{r^{\\mathrm{tan}}(\\pi^{t})\\le\\mathcal{O}\\left(\\frac{T_{\\sigma}}{t+T_{\\sigma}-2}\\right)}\\end{array}$   \n191 Finally, taking $\\dot{T}_{\\sigma}=\\Theta(\\dot{\\ln{T}})$ , we have: ", "page_idx": 5}, {"type": "equation", "text": "$$\nr^{\\mathrm{tan}}(\\pi^{t})\\leq\\mathcal{O}\\left(\\frac{\\ln T}{t-1}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "192 The upper bound on the gap function is immediately obtained since we have Lemma 2.2. ", "page_idx": 5}, {"type": "text", "text": "193 4.2  Noisy feedback setting ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "194 Next, we establish the last-iterate convergence rate in the noisy feedback setting, where each   \n195 player $i$ observes a noisy gradient vector contaminated by an additive noise vector $\\xi_{i}^{t}\\ \\in\\ \\mathbb{R}^{d_{i}}$   \n196 $\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t})+\\xi_{i}^{t}$ :We assume that the noisy vector $\\xi_{i}^{t}$ is zero-mean and its variance is bounded.   \n197 Formally, defining the sigma-algebra generated by the history of the observations as $\\mathcal{F}_{t}\\;:=\\;$   \n198 $\\sigma\\left(\\big(\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{1})\\big)_{i\\in[N]},\\ldots,\\big(\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t-1})\\big)_{i\\in[N]}\\right)$ \uff0c $\\forall t\\geq1$ the noisy vector $\\xi_{i}^{t}$ is assumed to satisfy   \n199 the following conditions:   \n200 Assumption 4.2. For all $t\\geq1$ and $i\\in[N]$ the noise vector $\\xi_{i}^{t}$ satisfies the following properties: (a)   \n201 Zero-mean: $\\mathbb{E}[\\xi_{i}^{t}|\\mathcal{F}_{t}]=(0,\\cdots,0)^{\\top};(b$ Bounded variance: $\\mathbb{E}[\\|\\xi_{i}^{t}\\|^{2}|\\mathcal{F}_{t}]\\le C^{2}$ with some constant   \n202 $C>0$   \n203 Assumption 4.2 is standard in online learning in games with noisy feedback [Mertikopoulos and   \n204 Zhou, 2019, Hsieh et al., 2019, Abe et al., 2024] and stochastic optimization [Nemirovski et al., 2009,   \n205 Nedic and Lee, 2014]. Under Assumption 4.2 and a decreasing learning rate sequence $\\eta_{t}$ , we can   \n206  obtain a faster last convergence rate $\\tilde{\\mathcal{O}}(1/T^{\\frac{1}{7}})$ than the convergence rate $\\tilde{\\mathcal{O}}(1/T^{\\frac{1}{10}})$ of APGA.   \n207 Theorem 4.3. Let = ,0 = 3u+8L2. \uff1aSuppose that Assumption 4.2 holds and $V(\\pi)\\leq\\zeta$ for   \n208 any $\\pi\\in\\mathcal{X}$ We also assume that $T_{\\sigma}$ is set to satisfy $T_{\\sigma}=c\\cdot\\operatorname*{max}(T^{\\frac{6}{7}},1)$ for some constant $c\\geq1$   \n209If we use the constant perturbation strength $\\mu\\,>\\,0$ and the decreasing learning rate sequence   \n210 10mg = (-Ta(k(t)-1)+20 then the straegyT+1 satisfes: ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathrm{GAP}(\\pi^{T+1})\\right]}\\\\ &{\\leq\\frac{26c\\left(D(\\mu+L)+\\zeta\\right)\\sqrt{(D+1)(D+\\theta)+\\kappa}}{T^{\\frac{1}{\\tau}}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "211 Note that the non-increasing property, as described in (8), of the potential function holds regardless   \n212 of the presence of noise. This implies that a proof technique similar to the one used with the potential   \n213 function in the full feedback setting can also be applied in the noisy feedback setting. The detailed   \n214  proof can be found in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "215  5   Individual regret bound ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "216  In this section, we present an upper bound on an individual regret for each player. Specifically,   \n217 we examine two performance measures in our study: the external regret and the dynamic regret   \n218 [Zinkevich, 2003]. The external regret is a conventional measure in online learning. In online learning   \n219 in games, the external regret for player $i$ is defined as the gap between the player's realized cumulative   \n220 payoff and the cumulative payoff of the best fixed strategy in hindsight: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname{Reg}_{i}(T):=\\operatorname*{max}_{x\\in\\mathcal{X}_{i}}\\sum_{t=1}^{T}\\left(v_{i}(x,\\pi_{-i}^{t})-v_{i}(\\pi^{t})\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "221 The dynamics regret is a much stronger performance metric, which is given by: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{DynamicReg}_{i}(T):=\\sum_{t=1}^{T}\\left(\\operatorname*{max}_{x\\in\\mathcal{X}_{i}}v_{i}\\big(x,\\pi_{-i}^{t}\\big)-v_{i}\\big(\\pi^{t}\\big)\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "222 We show in Theorem 5.1 that the individual regret is at most $\\mathcal{O}\\left((\\ln T)^{2}\\right)$ if each player $i\\in[N]$ plays   \n223 according to GABP in the full feedback setting: ", "page_idx": 6}, {"type": "text", "text": "224 Theorem 5.1. In the same setup of Theorem 4.1, we have for any player $i\\in[N]$ and $T\\geq3$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathrm{Reg}_{i}(T)\\leq\\mathrm{DynamicReg}_{i}(T)\\leq\\mathcal{O}\\left((\\ln T)^{2}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "225   This regret bound is significantly superior to the $\\mathcal{O}(\\sqrt{T})$ regret bound of Optimistic Gradient Ascent,   \n226 and it is slightly inferior to the $\\mathcal{O}(\\ln T)$ regret bound of AOG [Cai and Zheng, 2023]. The proof is   \n227 given in Appendix D. ", "page_idx": 6}, {"type": "text", "text": "228 6 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "229  In this section, we present the empirical results of our GABP, comparing its performance with   \n230 Adaptively Perturbed Gradient Ascent (APGA) [Abe et al., 2024] and Optimistic Gradient Ascent   \n231 (OGA) [Daskalakis et al., 2018, Wei et al., 2021]. We conduct experiments on two classes of concave  \n232  convex games. The first experiment is carried out on random payoff games, which are two-player   \n233 zero-sum normal-form games with payoff matrices of size $d$ . In this game, each player's strategy   \n234  space is represented by the $d$ -dimensional probability simplex, i.e., $\\mathcal{X}_{1}\\,=\\,\\mathcal{X}_{2}\\,=\\,\\Delta^{d}$ . All entries   \n235  of the payoff matrix are drawn independently from a uniform distribution over the interval $[-1,1]$   \n236  We set $d=50$ and the initial strategies are set to $\\textstyle\\pi_{1}^{1}=\\pi_{2}^{1}={\\frac{1}{d}}\\mathbf{1}$ . The second instance is a hard   \n237 concave-convex game [Ouyang and Xu, 2021], formulated as the following max-min optimization   \n238 problem: $\\scriptstyle\\operatorname*{max}_{x\\in{\\mathcal{X}}_{1}}\\operatorname*{min}_{y\\in{\\mathcal{X}}_{2}}f(x,y)$ where $\\begin{array}{r}{f(x,y)=-\\frac{1}{2}x^{\\top}H x+h^{\\top}x+\\zeta(A x-b,y)^{\\top}}\\end{array}$ Following   \n239 the setup in Cai and Zheng [2023], we choose $\\mathcal{X}_{1}=\\mathcal{X}_{2}=[-200,200]^{d}$ with $d=100$ . The precise   \n240  terms of $H\\in\\mathbb{R}^{d\\times d},A\\in\\bar{\\mathbb{R}}^{d\\times d},b\\in\\mathbb{R}^{d}$ and $h\\in\\mathbb{R}^{d}$ are provided in Appendix E.2. All algorithms   \n241 are executed with initial strategies $\\textstyle\\pi_{1}^{1}=\\pi_{2}^{1}={\\frac{1}{n}}\\mathbf{1}$ . The detailed hyperparameters of the algorithms,   \n242 tuned for best performance, are shown in Table $^{1}$ in Appendix E.3.   \n243 The numerical results of the random payoff game and the hard concave-convex game are shown in   \n244  Figure 1. Both the full feedback and noisy feedback experiments in the random payoff game were   \n245  conducted with 50 different random seeds, which corresponds to using 50 different payoff matrices.   \n246 For experiments on the hard concave-convex game with noisy feedback, we use 10 different random   \n247 seeds. We assume that the noise vector $\\xi_{i}^{t}$ is generated from the multivariate Gaussian distribution   \n248 $\\mathcal{N}(0,\\;0.1^{2}\\mathbf{I})$ in an i.i.d. manner for both games. We observe that GABP exhibits competitive or faster   \n249 performance over APGA and OGA in all experiments.   \n250 Figure 2 illustrates the dynamic regret in the hard concave-convex game. GABP exhibits lower   \n251 regret than APGA and OGA in both settings, demonstrating its efficiency and robustness. Note that   \n252 APGA and OGA exhibit almost identical trajectories with full feedback, with their plots overlapping   \n253completely. ", "page_idx": 6}, {"type": "image", "img_path": "TI7Vy90B9j/tmp/9138ebd57574057e3967b8c08de0e98a3835717fcac5522008d330d06ce00446.jpg", "img_caption": ["Figure 1: Performance of $\\pi^{t}$ for GABP, APGA, and OGA with full and noisy feedback in the random payoff and hard concave-convex games, respectively. The shaded area represents the standard errors. Note that we report the gap function for the random payoff game, while the tangent residual is reported for the hard concave-convex game. "], "img_footnote": [], "page_idx": 7}, {"type": "image", "img_path": "TI7Vy90B9j/tmp/dc73ea1d2d897d92ea6e997325054415b4a5aa22f57d977a474cecfdf5938ae5.jpg", "img_caption": ["Figure 2: Dynamic regret for GABP, APGA, and OGA with full and noisy feedback. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "254 7Related literature ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "255 No-regret learning algorithms have been extensively studied with the intent of achieving key objectives   \n256 such as average-iterate convergence or last-iterate convergence. Recently, learning algorithms   \n257 introducing optimism [Rakhlin and Sridharan, 2013a,b], such as optimistic Follow the Regularized   \n258 Leader [Shalev-Shwartz and Singer, 2006] and optimistic Mirror Descent [Zhou et al., 2017, Hsieh   \n259 et al., 2021], have been introduced to admit last-iterate convergence in a broad spectrum of game   \n260 settings. These optimistic algorithms with full feedback have been shown to achieve last-iterate   \n261 convergence in various classes of games, including bilinear games [Daskalakis et al., 2018, Daskalakis   \n262 and Panageas, 2019, Liang and Stokes, 2019, de Montbrun and Renault, 2022], cocoercive games   \n263 [Lin et al., 2020], and saddle point problems [Daskalakis and Panageas, 2018, Mertikopoulos et al.,   \n264 2019, Golowich et al., 2020b, Wei et al., 2021, Lei et al., 2021, Yoon and Ryu, 2021, Lee and Kim,   \n265 2021, Cevher et al., 2023]. Recent studies have provided finite convergence rates for monotone games   \n266 [Golowich et al., 2020a, Cai et al., 2022a,b, Gorbunov et al., 2022, Cai and Zheng, 2023].   \n267 Compared to the full feedback setting, there are significant challenges in learning with noisy feedback.   \n268 For example, a learning algorithm must estimate the gradient from feedback that is contaminated by   \n269 noise. Despite the challenge, a vast literature has successfully achieved last-iterate convergence with   \n270 noisy feedback in specific classes of games, including potential games [Cohen et al., 2017], strongly   \n271 monotone games [Giannou et al., 2021b,a], and two-player zero-sum games [Abe et al., 2023]. These   \n272 results have often leveraged unique structures of their payoff functions, such as strict (or strong)   \n273 monotonicity [Bravo et al., 2018, Kannan and Shanbhag, 2019, Hsieh et al., 2019, Anagnostides   \n274 and Panageas, 2022] and strict variational stability [Mertikopoulos et al., 2019, Azizian et al., 2021,   \n275 Mertikopoulos and Zhou, 2019, Mertikopoulos et al., 2022]. Without these restrictions, convergence   \n276 is mainly demonstrated in an asymptotic manner, with no quantification of the rate [Koshal et al.,   \n277 2010, 2013, Yousefian et al., 2017, Tatarenko and Kamgarpour, 2019, Hsieh et al., 2020, 2022, Abe   \n278 et al., 2023]. Consequently, an exceedingly large number of iterations might be necessary to reach an   \n279  equilibrium.   \n280 There have been several studies focusing on payoff-regularized learning, where each player's payoff   \n281 or utility function is perturbed or regularized via strongly convex functions [Cen et al., 2021, 2023,   \n282 Pattathil et al., 2023]. Previous studies have successfully achieved convergence to stationary points,   \n283 which are approximate equilibria. For instance, Sokota et al. [2023] have demonstrated that their   \n284 perturbed mirror descent algorithm converges to a quantal response equilibrium [McKelvey and   \n285 Palfrey, 1995, 1998]. Similar results have been obtained with the Boltzmann Q-learning dynam  \n286 ics [Tuyls et al., 2006] and penalty-regularized dynamics [Coucheney et al., 2015] in continuous-time   \n287 settings [Leslie and Collins, 2005, Abe et al., 2022, Hussain et al., 2023]. To ensure convergence   \n288 toward a Nash equilibrium of the underlying game, the magnitude of perturbation requires careful   \n289 adjustment. Several learning algorithms have been proposed to gradually reduce the perturbation   \n290 strength $\\mu$ in response to this [Bernasconi et al., 2022, Liu et al., 2023, Cai et al., 2023]. These   \n291 include well-studied methods such as iterative Tikhonov regularization [Facchinei and Pang, 2003,   \n292 Koshal et al., 2010, Tatarenko and Kamgarpour, 2019]. Alternatively, Perolat et al. [2021] and Abe   \n293 et al. [2023] have employed a payoff perturbation scheme, where the magnitude of perturbation is   \n294 determined by the distance from an anchoring strategy, which is periodically re-initialized by the   \n295 current strategy. Recently, Abe et al. [2024] have established $\\tilde{\\mathcal{O}}(1/\\sqrt{T})$ and $\\tilde{\\mathcal{O}}(1/T^{\\frac{1}{10}})$ last-iterate   \n296 convergence rates for the payoff perturbation scheme in the full/noisy feedback setting, respectively.   \n297 Our algorithm achieves faster $\\tilde{\\mathcal{O}}(1/T)$ and $\\tilde{\\mathcal{O}}(1/T^{\\frac{1}{7}})$ last-iterate convergence rates by modifying the   \n298 periodically re-initializing anchoring strategy scheme so that the anchoring strategy evolves more   \n299  gradually. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "300 8 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "301 This study proposes a novel payoff-perturbed algorithm, Gradient Ascent with Boosting Payoff   \n302Perturbation, which achieves $\\tilde{\\mathcal{O}}(1/T)$ and $\\tilde{\\mathcal{O}}(1/\\bar{T}^{\\frac{1}{7}})$ last-iterate convergence rates in monotone   \n303 games with full/noisy feedback, respectively. Extending our results in settings where each player   \n304 only observes bandit feedback is an intriguing and challenging future direction. ", "page_idx": 8}, {"type": "text", "text": "305 References ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "306 Kenshi Abe, Mitsuki Sakamoto, and Atsushi Iwasaki. Mutation-driven follow the regularized leader   \n307 for last-iterate convergence in zero-sum games. In UAl, pages 1-10, 2022.   \n308  Kenshi Abe, Kaito Ariu, Mitsuki Sakamoto, Kentaro Toyoshima, and Atsushi Iwasaki. Last-iterate   \n309 convergence with full and noisy feedback in two-player zero-sum games. In AISTATS, pages   \n310 7999-8028,2023.   \n311 Kenshi Abe, Kaito Ariu, Mitsuki Sakamoto, and Atsushi Iwasaki. Adaptively perturbed mirror   \n312 descent for learning in games. In ICML, 2024.   \n313 Ioannis Anagnostides and Ioannis Panageas. Frequency-domain representation of first-order methods:   \n314 A simple and robust framework of analysis. In SOSA, pages 131-160, 2022.   \n315 Waiss Azizian, Franck Iutzeler, Jerome Malick, and Panayotis Mertikopoulos. The last-iterate   \n316 convergence rate of optimistic miror descent in stochastic variational inequalities. In COLT, pages   \n317 326-358, 2021.   \n318  James P Bailey and Georgios Piliouras. Multiplicative weights update in zero-sum games. In   \n319 Economics and Computation, pages 321-338, 2018.   \n320 Martino Bernasconi, Alberto Marchesi, and Francesco Trovo. Last-iterate convergence to trembling  \n321 hand perfect equilibria. arXiv preprint arXiv:2208.08238, 2022.   \n322 Mario Bravo, David Leslie, and Panayotis Mertikopoulos. Bandit learning in concave N-person   \n323 games. In NeurIPS, pages 5666-5676, 2018.   \n324  Yang Cai and Constantinos Daskalakis. On minmax theorems for multiplayer games. In SODA,   \n325 pages 217-234, 2011.   \n326  Yang Cai and Weiqiang Zheng. Doubly optimal no-regret learning in monotone games. In ICML,   \n327 pages 3507-3524, 2023.   \n328 Yang Cai, Ozan Candogan, Constantinos Daskalakis, and Christos Papadimitriou. Zero-sum polyma  \n329 trix games: A generalization of minmax. Mathematics of Operations Research, 41(2):648-655,   \n330 2016.   \n331 Yang Cai, Argyris Oikonomou, and Weiqiang Zheng. Finite-time last-iterate convergence for learning   \n332 in multi-player games. In NeurIPS, pages 33904-33919, 2022a.   \n333 Yang Cai, Argyris Oikonomou, and Weiqiang Zheng. Tight last-iterate convergence of the extragradi  \n334 ent method for constrained monotone variational inequalities. arXiv preprint arXiv:2204.09228,   \n335 2022b.   \n336 Yang Cai, Haipeng Luo, Chen- Yu Wei, and Weiqiang Zheng. Uncoupled and convergent learning in   \n337 two-player zero-sum markov games with bandit feedback. In NeurIPS, pages 36364-36406, 2023.   \n338 Shicong Cen, Yuting Wei, and Yuejie Chi. Fast policy extragradient methods for competitive games   \n339 with entropy regularization. In NeurIPS, pages 27952-27964, 2021.   \n340 Shicong Cen, Yuejie Chi, Simon S Du, and Lin Xiao. Faster last-iterate convergence of policy   \n341 optimization in zero-sum Markov games. In ICLR, 2023.   \n342 Volkan Cevher, Georgios Piliouras, Ryann Sim, and Stratis Skoulakis. Min-max optimization made   \n343 simple: Approximating the proximal point method via contraction maps. In Symposium on   \n344 Simplicity in Algorithms (SOSA), pages 192-206, 2023.   \n345 Johanne Cohen, Am\u00e9lie H\u00e9liou, and Panayotis Mertikopoulos. Learning with bandit feedback in   \n346 potential games. In NeurIPS, pages 6372-6381, 2017.   \n347  Pierre Coucheney, Bruno Gaujal, and Panayotis Mertikopoulos. Penalty-regulated dynamics and   \n348 robust learning procedures in games. Mathematics of Operations Research, 40(3):611-633, 2015.   \n349 Constantinos Daskalakis and Ioannis Panageas. The limit points of (optimistic) gradient descent in   \n350 min-max optimization. In NeurIPS, pages 9256-9266, 2018.   \n351 Constantinos Daskalakis and Ioannis Panageas. Last-iterate convergence: Zero-sum games and   \n352 constrained min-max optimization. In ITCS, pages 27:1-27:18, 2019.   \n353 Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, and Haoyang Zeng. Training GANs with   \n354 optimism. In ICLR, 2018.   \n35 Etienne de Montbrun and J\u00e9rome Renault. Convergence of optimistic gradient descent ascent n   \n356 bilinear games. arXiv preprint arXiv:2208.03085, 2022.   \n357 Gerard Debreu. A social equilibrium existence theorem. Proceedings of the National Academy of   \n358 Sciences, 38(10):886-893, 1952.   \n359Francisco Facchinei and Jong-Shi Pang. Finite-dimensional variational inequalities and complemen  \n360 tarity problems. Springer, 2003.   \n361 Angeliki Giannou, Emmanouil Vasileios Vlatakis-Gkaragkounis, and Panayotis Mertikopoulos.   \n362 Survival of the strictest: Stable and unstable equilibria under regularized learning with partial   \n363 information. In COLT, pages 2147-2148, 2021a.   \n364 Angeliki Giannou, Emmanouil-Vasileios Vlatakis-Gkaragkounis, and Panayotis Mertikopoulos. On   \n365 the rate of convergence of regularized learning in games: From bandits and uncertainty to optimism   \n366 and beyond. In NeurIPS, pages 22655-22666, 2021b.   \n367 Noah Golowich, Sarath Pattathil, and Constantinos Daskalakis. Tight last-iterate convergence rates   \n368  for no-regret learning in multi-player games. In NeurIPS, pages 20766-20778, 2020a.   \n369 Noah Golowich, Sarath Pattathil, Constantinos Daskalakis, and Asuman Ozdaglar. Last iterate is   \n370 slower than averaged iterate in smooth convex-concave saddle point problems. In COLT, pages   \n371 1758-1784, 2020b.   \n372  Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherji Ozair,   \n373 Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NeurIPS, pages 2672-2680,   \n3742014.   \n375  Eduard Gorbunov, Adrien Taylor, and Gauthier Gidel. Last-iterate convergence of optimistic gradient   \n376 method for monotone variational inequalities. In NeurIPS, pages 21858-21870, 2022.   \n377Yu-Guan Hsieh, Franck Iutzeler, J\u00e9rome Malick, and Panayotis Mertikopoulos. On the convergence   \n378 of single-call stochastic extra-gradient methods. In NeurIPS, pages 6938-6948, 2019.   \n379 Yu-Guan Hsieh, Franck utzeler, Jerome Malick, and Panayotis Mertikopoulos. Explore aggressively.   \n380 update conservatively: Stochastic extragradient methods with variable stepsize scaling. In NeurIPS,   \n381 pages 16223-16234, 2020.   \n382  Yu-Guan Hsieh, Kimon Antonakopoulos, and Panayotis Mertikopoulos. Adaptive learning in   \n383 continuous games: Optimal regret bounds and convergence to Nash equilibrium. In COLT, pages   \n384 2388-2422, 2021.   \n385Yu-Guan Hsieh, Kimon Antonakopoulos, Volkan Cevher, and Panayotis Mertikopoulos. No-regret   \n386 learning in games with noisy feedback: Faster rates and adaptivity via learning rate separation. In   \n387 NeurIPS, pages 6544-6556, 2022.   \n388 Aamal Abbas Hussain, Francesco Belardinelli, and Georgios Piliouras. Asymptotic convergence and   \n389 performance of multi-agent Q-learning dynamics. arXiv preprint arXiv:2301.09619, 2023.   \n390 Aswin Kannan and Uday V. Shanbhag. Optimal stochastic extragradient schemes for pseudomonotone   \n391 stochastic variational inequality problems and their variants. Computational Optimization and   \n392 Applications, 74(3):779-820, 2019.   \n393 Jayash Koshal, Angelia Nedic, and Uday V Shanbhag. Single timescale regularized stochastic   \n394 approximation schemes for monotone nash games under uncertainty. In CDC, pages 231-236.   \n395 IEEE, 2010.   \n396  Jayash Koshal, Angelia Nedic, and Uday V. Shanbhag. Regularized iterative stochastic approximation   \n397 methods for stochastic variational inequality problems. IEEE Transactions on Automatic Control,   \n398 58(3):594-609, 2013.   \n39  Sucheol Lee and Donghwan Kim. Fast extra gradient methods for smooth structured nonconvex  \n400 nonconcave minimax problems. In NeurIPS, pages 22588-22600, 2021.   \n401 Qi Lei, Sai Ganesh Nagarajan, Ioannis Panageas, et al. Last iterate convergence in no-regret learning:   \n402 constrained min-max optimization for convex-concave landscapes. In AISTATS, pages 1441-1449,   \n403 2021.   \n404  David S Leslie and Edmund J Collins. Individual q-learning in normal form games. SIAM Journal   \n405 on Control and 0ptimization, 44(2):495-514, 2005.   \n406 Tengyuan Liang and James Stokes. Interaction matters: A note on non-asymptotic local convergence   \n407 of generative adversarial networks. In AISTATS, pages 907-915, 2019.   \n408 Tianyi Lin, Zhengyuan Zhou, Panayotis Mertikopoulos, and Michael Jordan. Finite-time last-iterate   \n409 convergence for multi-agent learning in games. In ICML, pages 6161-6171, 2020.   \n410Mingyang Liu, Asuman Ozdaglar, Tiancheng Yu, and Kaiqing Zhang. The power of regularization in   \n411 solving extensive-form games. In ICLR, 2023.   \n412  Richard D McKelvey and Thomas R Palfrey. Quantal response equilibria for normal form games.   \n413 Games and economic behavior, 10(1):6-38, 1995.   \n414 Richard D McKelvey and Thomas R Palfrey. Quantal response equilibria for extensive form games.   \n415 Experimental economics, 1:9-41, 1998.   \n416 Panayotis Mertikopoulos and Zhengyuan Zhou. Learning in games with continuous action sets and   \n417 unknown payoff functions. Mathematical Programming, 173(1):465-507, 2019.   \n418  Panayotis Mertikopoulos, Bruno Lecouat, Houssam Zenati, Chuan-Sheng Foo, Vijay Chandrasekhar,   \n419 and Georgios Piliouras. Optimistic mirror descent in saddle-point problems: Going the extra   \n420 (gradient) mile. In ICLR, 2019.   \n421 Panayotis Mertikopoulos, Ya-Ping Hsieh, and Volkan Cevher. Learning in games from a stochastic   \n422 approximation viewpoint. arXiv preprint arXiv:2206.03922, 2022.   \n423  Remi Munos, Michal Valko, Daniele Calandriello, Mohammad Gheshlaghi Azar, Mark Rowland,   \n424 Zhaohan Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Andrea Michi, et al. Nash   \n425 learning from human feedback. arXiv preprint arXiv:2312.00886, 2023.   \n426 John Nash. Non-cooperative games. Annals of mathematics, pages 286-295, 1951.   \n427 Angelia Nedic and Soomin Lee. On stochastic subgradient mirror-descent algorithm with weighted   \n428 averaging. SIAM Journal on Optimization, 24(1):84-107, 2014.   \n429  A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to   \n430 stochastic programming. SIAM Journal on Optimization, 19(4):1574-1609, 2009.   \n431 Yuyuan Ouyang and Yangyang Xu. Lower complexity bounds of first-order methods for convex  \n432 concave bilinear saddle-point problems. Mathematical Programming, 185(1):1-35, 2021.   \n433 Sarath Pattathil, Kaiqing Zhang, and Asuman Ozdaglar. Symmetric (optimistic) natural policy   \n434 gradient for multi-agent learning with parameter convergence. In AISTATS, pages 5641-5685,   \n435 2023.   \n436  Julien Perolat, Remi Munos, Jean-Baptiste Lespiau, Shayegan Omidshafiei, Mark Rowland, Pedro   \n437 Ortega, Neil Burch, Thomas Anthony, David Balduzzi, Bart De Vylder, et al. From Poincare   \n438 recurrence to convergence in imperfect information games: Finding equilibrium via regularization.   \n439 In ICML, pages 8525-8535, 2021.   \n440 Alexander Rakhlin and Karthik Sridharan. Online learning with predictable sequences. In COLT,   \n441 pages 993-1019, 2013a.   \n442 Sasha Rakhlin and Karthik Sridharan. Optimization, learning, and games with predictable sequences.   \n443 In NeurIPS, pages 3066-3074, 2013b.   \n444 Shai Shalev-Shwartz and Yoram Singer. Convex repeated games and fenchel duality. Advances in   \n445 neural information processing systems, 19, 2006.   \n446  Samuel Sokota, Ryan D'Orazio, J Zico Kolter, Nicolas Loizou, Marc Lanctot, Ioannis Mitliagkas   \n447 Noam Brown, and Christian Kroer. A unified approach to reinforcement learning, quantal response   \n448 equilibria, and two-player zero-sum games. In ICLR, 2023.   \n449 Gokul Swamy, Christoph Dann, Rahul Kidambi, Zhiwei Steven Wu, and Alekh Agarwal. A minimaxi  \n450 malist approach to reinforcement learning from human feedback. arXiv preprint arXiv:2401.04056,   \n451 2024.   \n452  Tatiana Tatarenko and Maryam Kamgarpour. Learning Nash equilibria in monotone games. In CDC,   \n453 pages 3104-3109. IEEE, 2019.   \n454  Karl Tuyls, Pieter Jan Hoen, and Bram Vanschoenwinkel. An evolutionary dynamical analysis   \n455 of multi-agent learning in iterated games. Autonomous Agents and Multi-Agent Systems, 12(1):   \n456 115-153, 2006.   \n457 Chen- Yu Wei, Chung-Wei Lee, Mengxiao Zhang, and Haipeng Luo. Linear last-iterate convergence   \n458 in constrained saddle-point optimization. In ICLR, 2021.   \n459  TaeHo Yoon and Ernest K Ryu. Accelerated algorithms for smooth convex-concave minimax   \n460 problems with ${\\mathcal{O}}(1/k^{2})$ rate on squared gradient norm. In ICML, pages 12098-12109, 2021.   \n461 Farzad Yousefian, Angelia Nedic, and Uday V Shanbhag. On smoothing, regularization, and averaging   \n462 in stochastic approximation methods for stochastic variational inequality problems. Mathematical   \n463 Programming, 165:391-431, 2017.   \n464 Zhengyuan Zhou, Panayotis Mertikopoulos, Aris L Moustakas, Nicholas Bambos, and Peter Glynn.   \n465 Mirror descent learning in continuous games. In CDC, pages 5776-5783. IEEE, 2017.   \n466 Martin Zinkevich. Online convex programming and generalized infinitesimal gradient ascent. In   \n467 ICML, pages 928-936, 2003. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "468 A Broader impact ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "469  Our study can bring about a positive impact on society by contributing to the advancement of the   \n470  Game AI industry. However, as far as we can envision, there are no conceivable negative social   \n471 impacts. ", "page_idx": 12}, {"type": "text", "text": "472B Proofs for Theorem 4.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "473 B.1 Proof of Theorem 4.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "474 Proof of Theorem 4.1. From the first-order optimality condition for $\\pi^{t}$ , we have for any $x\\in\\mathscr{X}$ ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\left\\langle V(\\pi^{t-1})-\\mu\\left(\\pi^{t-1}-{\\frac{k(t-1)\\sigma^{k(t-1)}+\\sigma^{1}}{k(t-1)+1}}\\right)-{\\frac{1}{\\eta}}\\left(\\pi^{t}-\\pi^{t-1}\\right),\\pi^{t}-x\\right\\rangle\\geq0,\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "$\\begin{array}{r}{V(\\pi^{t-1})-\\mu\\left(\\pi^{t-1}-\\frac{k(t-1)\\sigma^{k(t-1)}+\\sigma^{1}}{k(t-1)+1}\\right)-\\frac{1}{\\eta}\\left(\\pi^{t}-\\pi^{t-1}\\right)\\in N_{\\mathcal{X}}(\\pi^{t})}\\end{array}$ . Thus, the tangent 476  residual for $\\pi^{t}$ can be bounded as: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{r^{\\mathsf{t a n}}(\\pi^{t})=\\operatorname*{min}_{a\\in N_{x}(\\pi^{t})}\\left\\|-V(\\pi^{t})+a\\right\\|}}\\\\ &{\\qquad\\le\\left\\|-V(\\pi^{t})+V(\\pi^{t-1})-\\mu\\left(\\pi^{t-1}-\\frac{k(t-1)\\sigma^{k(t-1)}+\\sigma^{1}}{k(t-1)+1}\\right)-\\frac{1}{\\eta}\\left(\\pi^{t}-\\pi^{t-1}\\right)\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "477 Letting us define ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\pi_{i}^{\\mu,\\sigma^{k}}=\\arg\\operatorname*{max}_{\\pi_{i}\\in\\mathcal{X}_{i}}\\left\\{v_{i}(\\pi_{i},\\pi_{-i}^{\\mu,\\sigma^{k}})-\\frac{\\mu}{2}\\left\\|\\pi_{i}-\\frac{k\\sigma_{i}^{k}+\\sigma_{i}^{1}}{k+1}\\right\\|^{2}\\right\\},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "478  then we get by triangle inequality: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathsf{A a}(\\pi^{k})\\le\\left\\|-V(\\pi^{k})+V(\\pi^{t-1})-\\frac{\\mu}{k(t-1)+1}\\left(\\sigma^{k(t-1)}-\\sigma^{1}\\right)\\right.}\\\\ &{\\qquad\\left.-\\mu\\left(\\pi^{\\mu,\\theta}^{\\alpha(t-1)}-\\pi^{\\mu,\\theta}^{\\alpha(t-1)}+\\pi^{\\mu-1}-\\sigma^{k(t-1)}\\right)-\\frac{1}{\\eta}(\\pi^{\\mu}-\\pi^{\\mu-1})\\right\\|}\\\\ &{\\le\\left\\|-V(\\pi^{t})+V(\\pi^{t-1})\\right\\|+\\frac{\\mu}{k(t-1)+1}\\left\\|\\sigma^{k(t-1)}-\\sigma^{1}\\right\\|}\\\\ &{\\qquad+\\mu\\left\\|\\pi^{\\mu,\\theta}^{\\alpha(t-1)}-\\sigma^{1(t-1)}\\right\\|+\\mu\\left\\|\\sigma^{\\mu,\\theta}^{\\alpha(t-1)}-\\pi^{\\mu-1}\\right\\|+\\frac{1}{\\eta}\\left\\|\\pi^{t}-\\pi^{t-1}\\right\\|}\\\\ &{\\le\\frac{1+\\eta\\,L}{\\eta}\\left\\|\\pi^{t}-\\pi^{t-1}\\right\\|+\\frac{\\mu D}{k(t-1)+1}}\\\\ &{\\qquad+\\mu\\left\\|\\pi^{\\mu,\\theta}^{\\alpha(t-1)}-\\sigma^{1(t-1)}\\right\\|+\\mu\\left\\|\\pi^{\\mu,\\theta}^{\\alpha(t-1)}-\\pi^{t-1}\\right\\|}\\\\ &{\\le\\frac{1+\\eta\\,L}{\\eta}\\left\\|\\pi^{\\mu,\\theta}^{\\alpha(t-1)}-\\pi^{\\mu}\\right\\|+\\frac{\\mu D}{k(t-1)+1}+\\mu\\left\\|\\pi^{\\mu,\\theta}^{\\alpha(t-1)}-\\sigma^{k(t-1)}\\right\\|}\\\\ &{\\qquad+\\left(\\mu+\\frac{1+\\eta\\,L}{\\eta}\\right)\\left\\|\\pi^{\\mu,\\theta}^{\\alpha(t-1)}-\\pi^{\\mu-1}\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "479 In terms ofupper boundon $\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\pi^{t}\\right\\|$ and $\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\pi^{t-1}\\right\\|$ we introduce thefllowing   \n480 lemma: ", "page_idx": 13}, {"type": "text", "text": "481 LemmaB.1. If we use the constant learning rate $\\begin{array}{r}{\\eta_{t}=\\eta\\in\\left(0,\\frac{\\mu}{(L+\\mu)^{2}}\\right)}\\end{array}$ we have for any $t\\geq1$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t}\\right\\|^{2}\\leq\\left(\\displaystyle\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t)-1)T_{\\sigma}-1}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|^{2},}\\\\ &{\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}\\leq\\left(\\displaystyle\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t)-1)T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "482 Combining (10) and Lemma B.1, we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\nr^{\\mathrm{tan}}(\\pi^{t})\\leq2\\left(\\mu+\\frac{1+\\eta L}{\\eta}\\right)\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\sigma^{k(t-1)}\\right\\|+\\frac{\\mu D}{k(t-1)+1}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "483 Next, we derive the following upper bound on $\\left\\|\\pi^{\\mu,\\sigma^{k(t-1)}}-\\sigma^{k(t-1)}\\right\\|$ ", "page_idx": 13}, {"type": "text", "text": "484 LemmaB.2. Ifwe set nt =n E (0, (Lpa) andT \u2265max(1, 3\u00b1) , la3(T+t), we have for any \u2265 1: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|\\leq{\\frac{8D}{k(t)+1}}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "485  By combining (11) and Lemma B.2, we get: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{r^{\\tan}(\\pi^{t})\\leq\\displaystyle\\frac{16D}{k(t-1)+1}\\left(\\mu+\\frac{1+\\eta L}{\\eta}\\right)+\\frac{\\mu D}{k(t-1)+1}}}\\\\ {{\\qquad\\mathrm{}\\leq\\displaystyle\\frac{17D}{k(t-1)+1}\\left(\\mu+\\frac{1+\\eta L}{\\eta}\\right).}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "486 Therefore, since $\\begin{array}{r}{k(t)=\\lfloor\\frac{t-1}{T_{\\sigma}}\\rfloor+1.}\\end{array}$ it holds that: ", "page_idx": 13}, {"type": "equation", "text": "$$\nr^{\\mathrm{tan}}(\\pi^{t})\\leq\\frac{17D T_{\\sigma}}{t+T_{\\sigma}-2}\\left(\\mu+\\frac{1+\\eta L}{\\eta}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "487   Finally, taking $\\begin{array}{r}{T_{\\sigma}=c\\cdot\\operatorname*{max}(1,\\frac{6\\ln3(T+1)}{\\ln(1+\\eta\\mu)})}\\end{array}$ : 6ln3(T+1) ), we have: ", "page_idx": 13}, {"type": "equation", "text": "$$\nr^{\\mathrm{tan}}(\\pi^{t})\\leq\\frac{17c D\\left(\\frac{6\\ln3(T+1)}{\\ln(1+\\eta\\mu)}+1\\right)}{t-1}\\left(\\mu+\\frac{1+\\eta L}{\\eta}\\right).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "489 B.2 Proof of Lemma B.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "490 Proof of Lemma B.1. First, we have for any three vectors $a,b,c$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n{\\frac{1}{2}}\\left\\|a-b\\right\\|^{2}-{\\frac{1}{2}}\\left\\|a-c\\right\\|^{2}+{\\frac{1}{2}}\\left\\|b-c\\right\\|^{2}=\\left\\langle c-b,a-b\\right\\rangle.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "491 Thus, we have for any $t\\geq1$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\pi^{t+1}\\right\\Vert^{2}-\\frac{1}{2}\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\pi^{t}\\right\\Vert^{2}+\\frac{1}{2}\\left\\Vert\\pi^{t+1}-\\pi^{t}\\right\\Vert^{2}=\\left\\langle\\pi^{t}-\\pi^{t+1},\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\pi^{t+1}\\right\\rangle.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "492  Here, let us define Gk(t)  k(t)ab(t)+o. . Then, from the first-order optimality condition for $\\pi^{t+1}$ ,we   \n493 have for any $t\\geq1$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\langle\\eta\\left(V(\\pi^{t})-\\mu\\left(\\pi^{t}-\\hat{\\sigma}^{k(t)}\\right)\\right)-\\pi^{t+1}+\\pi^{t},\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle\\geq0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "4Smilarly,frmthefrst-orderopalityconditnfor , we get: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\langle V(\\pi^{\\mu,\\sigma^{k(t)}})-\\mu\\left(\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right),\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\rangle\\geq0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "495 Combining (12), (13), and (14) yields: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{2}\\left\\|\\pi^{\\mu,\\nu(1)}-\\pi^{\\mu+1}\\right\\|^{2}-\\frac{1}{2}\\left\\|\\pi^{\\mu,\\nu(1)}-\\pi^{\\nu}\\right\\|^{2}+\\frac{1}{2}\\left\\|\\pi^{\\mu+1}-\\pi^{\\mu}\\right\\|^{2}}\\\\ &{\\le\\eta\\left\\langle V(\\pi^{\\mu})-\\mu\\left(\\pi^{\\nu}\\!-\\!\\delta^{\\nu(1)}\\right),\\pi^{\\mu+1}-\\pi^{\\mu,\\nu(1)}\\right\\rangle}\\\\ &{=\\eta\\left\\langle V(\\pi^{\\mu+1})-\\mu\\left(\\pi^{\\mu+1}\\!-\\!\\delta^{\\nu(1)},\\pi^{\\nu(1)}\\!-\\!\\pi^{\\mu,\\nu(1)}\\right)\\right\\rangle}\\\\ &{\\quad+\\eta\\left\\langle V(\\pi^{\\mu})-V(\\pi^{\\mu+1})-\\mu\\left(\\pi^{\\ell}-\\pi^{\\nu+1}\\right),\\pi^{\\mu+1}-\\pi^{\\mu,\\nu(1)}\\right\\rangle}\\\\ &{\\le\\eta\\left\\langle V(\\pi^{\\mu,\\nu(1)})-\\mu\\left(\\pi^{\\mu+1}-\\delta^{\\nu(1)}\\right),\\pi^{\\mu+1}-\\pi^{\\mu,\\nu(1)}\\right\\rangle}\\\\ &{\\quad+\\eta\\left\\langle V(\\pi^{\\mu})-V(\\pi^{\\nu+1})-\\mu\\left(\\pi^{\\ell}-\\pi^{\\mu+1}\\right),\\pi^{\\mu+1}-\\pi^{\\mu,\\nu(1)}\\right\\rangle}\\\\ &{=\\eta\\left\\langle V(\\pi^{\\mu})-\\mu\\left(\\pi^{\\mu}\\!-\\!\\delta^{\\nu(1)}\\right)\\!-\\!\\pi^{\\mu+1}\\!-\\!\\pi^{\\mu,\\nu(1)}\\right\\rangle}\\\\ &{\\quad+\\eta\\left\\langle V(\\pi^{\\mu})-V(\\pi^{\\mu+1})-\\mu\\left(\\pi^{\\ell}-\\pi^{\\mu+1}\\right),\\pi^{\\mu+1}-\\pi^{\\mu,\\nu(1)}\\right\\rangle-\\eta\\mu\\left\\|\\pi^{\\mu+1}-\\pi^{\\mu,\\nu(1)}\\right\\|^{2}}\\\\ &{\\quad+\\eta\\left\\langle V(\\pi^{\\mu})-V(\\pi^{\\mu+1})-\\mu\\left(\\pi^{\\ell}-\\pi^{\\mu+1}\\right),\\pi^{\\mu+1}-\\pi^{\\mu,\\nu(1)}\\right\\rangle}\\\\ &{\\le-\\eta\\mu\\left\\|\\pi^{\\mu+1}-\\pi^{\\mu,\\nu \n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "496 where the second inequality follows from (1). From Cauchy-Schwarz inequality and Young's   \n497 inequality, the second term in the right-hand side of this inequality can be bounded by: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\eta\\left\\langle V(\\pi^{t})-V(\\pi^{t+1})-\\mu\\left(\\pi^{t}-\\pi^{t+1}\\right),\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k}(t)}\\right\\rangle}\\\\ &{=\\eta\\left\\langle V(\\pi^{t})-V(\\pi^{t+1}),\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k}(t)}\\right\\rangle-\\eta\\mu\\left\\langle\\pi^{t}-\\pi^{t+1},\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k}(t)}\\right\\rangle}\\\\ &{\\leq\\eta\\left(\\left\\|V(\\pi^{t})-V(\\pi^{t+1})\\right\\|+\\mu\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|\\right)\\cdot\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k}(t)}\\right\\|}\\\\ &{\\leq\\eta(L+\\mu)\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|\\cdot\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k}(t)}\\right\\|}\\\\ &{\\leq\\frac{1}{2}\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|^{2}+\\frac{\\eta^{2}\\left(L+\\mu\\right)^{2}}{2}\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k}(t)}\\right\\|^{2}}\\\\ &{\\leq\\frac{1}{2}\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|^{2}+\\frac{\\eta\\mu}{2}\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k}(t)}\\right\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "498 where the second inequality follow from (2), and the last inequality follows from the assumption that   \n499 $\\begin{array}{r}{\\eta\\le\\frac{\\mu}{(L+\\mu)^{2}}}\\end{array}$ . By combining (15) and (16), we get: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{1}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}-\\displaystyle\\frac{1}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t}\\right\\|^{2}+\\displaystyle\\frac{1}{2}\\left\\|\\pi^{t+1}-\\pi^{t}\\right\\|^{2}}\\\\ {\\displaystyle\\leq-\\displaystyle\\frac{\\eta\\mu}{2}\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}+\\displaystyle\\frac{1}{2}\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "500 Thus, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{1+\\eta\\mu}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}\\leq\\frac{1}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "501   Therefore, we have for any $t\\geq1$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}\\leq\\frac{1}{1+\\eta\\mu}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "502 Furthermore, since $k(s)=k(t)$ for $s\\in[(k(t)-1)T_{\\sigma}+1,t]$ we have for such $s$ that: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{s+1}\\right\\|^{2}\\leq\\frac{1}{1+\\eta\\mu}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{s}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "503 Therefore, by applying this inequality from $t,t-1,\\cdot\\cdot\\cdot,(k(t)-1)T_{\\sigma}+1$ , we get for any $t\\geq1$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}\\leq\\left(\\displaystyle\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t)-1)T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{(k(t)-1)T_{\\sigma}+1}\\right\\|^{2}}\\\\ &{\\qquad\\qquad\\qquad=\\left(\\displaystyle\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t)-1)T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "504  Here, since $k(t)=k(t+1)$ when $t$ satisfies that $t\\neq T_{\\sigma}\\,\\left\\lfloor\\frac{t}{T_{\\sigma}}\\right\\rfloor$ , we have for such $t$ that: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k(t+1)}}-\\pi^{t+1}\\right\\|^{2}\\leq\\left(\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t+1)-1)T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k(t+1)}}-\\sigma^{k(t+1)}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "505 On the other hand, when $t$ satisfies that $\\begin{array}{r}{t=T_{\\sigma}\\left\\lfloor\\frac{t}{T_{\\sigma}}\\right\\rfloor}\\end{array}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{k(t+1)=\\left\\lfloor\\frac{T_{\\sigma}\\,\\left\\lfloor\\frac{t}{T_{\\sigma}}\\right\\rfloor+1-1}{T_{\\sigma}}\\right\\rfloor+1=\\left\\lfloor\\frac{t}{T_{\\sigma}}\\right\\rfloor+1}\\\\ &{\\Rightarrow(k(t+1)-1)T_{\\sigma}=T_{\\sigma}\\,\\left\\lfloor\\frac{t}{T_{\\sigma}}\\right\\rfloor=t}\\\\ &{\\Rightarrow\\pi^{t+1}=\\pi^{(k(t+1)-1)T_{\\sigma}+1}=\\sigma^{k(t+1)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "508Therefoe, wehave for any $t\\geq1$ such hat $\\begin{array}{r}{t=T_{\\sigma}\\left\\lfloor\\frac{t}{T_{\\sigma}}\\right\\rfloor}\\end{array}$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\left\\|\\pi^{\\mu,\\sigma^{k(t+1)}}-\\pi^{t+1}\\right\\|^{2}=\\left\\|\\pi^{\\mu,\\sigma^{k(t+1)}}-\\sigma^{k(t+1)}\\right\\|^{2}}\\\\ {\\qquad\\qquad\\qquad=\\left(\\displaystyle\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t+1)-1)T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k(t+1)}}-\\sigma^{k(t+1)}\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "507 By combining (17), (18), and (19), we have for any $t\\geq1$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}\\leq\\left(\\displaystyle\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t)-1)T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|^{2},}\\\\ &{\\left\\|\\pi^{\\mu,\\sigma^{k(t+1)}}-\\pi^{t+1}\\right\\|^{2}\\leq\\left(\\displaystyle\\frac{1}{1+\\eta\\mu}\\right)^{t-(k(t+1)-1)T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k(t+1)}}-\\sigma^{k(t+1)}\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "510Proof of Lemma B.2. First, we have for any Nash equilibrium $\\pi^{*}\\in\\Pi^{*}$ and $t\\geq1$ such that $k(t)\\geq1$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{k(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\|^{2}+(k(t)+1)(k(t)+2)\\left\\langle\\bar{\\sigma}^{(k(t)+1)}-\\pi^{\\mu,\\mu^{(1)}},\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t)}\\right\\rangle}\\\\ &{=\\frac{k(t)+1}{2})(k(t)+2)\\left\\|\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\|^{2}}\\\\ &{\\quad+(k(t)+1)\\left\\langle\\left(k(t)+1\\right)\\sigma^{(k(t)+1)}+\\sigma^{(1)}-(k(t)+2)\\pi^{\\mu,\\mu^{(1)}},\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\rangle}\\\\ &{=\\frac{(k(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\|^{2}+(k(t)+1)\\left\\langle\\sigma^{(1)}-\\sigma^{(k(t)+1)},\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\rangle}\\\\ &{\\quad+(k(t)+1)(k(t)+2)\\left\\langle\\sigma^{(k(t)+1)}-\\pi^{\\mu,\\mu^{(1)}},\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\rangle}\\\\ &{=\\frac{(k(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\|^{2}+(k(t)+1)\\left\\langle\\sigma^{(1)}-\\pi^{\\mu,\\mu^{(1)}},\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\rangle}\\\\ &{\\quad+(k(t)+1)^{2}\\left\\langle\\sigma^{(k(t)+1)}-\\pi^{\\mu,\\mu^{(1)}},\\pi^{\\mu,\\mu^{(1)}}-\\bar{\\sigma}^{(k(t))}\\right\\rangle}\\\\ &{=\\frac{(k(t)+1)^{2}}{2}\\left\\langle\\bar{\\sigma}^{(k(t)+2)}\\right\\|\\frac{1}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "511Here, the frst-orderoptimalty conditionfor t ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\int_{V}(\\pi^{\\mu,\\sigma^{k(t)}})-\\mu\\left(\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right),\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{*}\\right)\\geq0}\\\\ &{\\Rightarrow\\left\\langle\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)},\\pi^{*}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle\\geq\\displaystyle\\frac{1}{\\mu}\\left\\langle V(\\pi^{\\mu,\\sigma^{k(t)}}),\\pi^{*}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle\\geq\\displaystyle\\frac{1}{\\mu}\\left\\langle V(\\pi^{*}),\\pi^{*}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "512  where we use (1) and the fact that $\\pi^{*}$ is a Nash equilibrium. Combining these inequalities yields: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\displaystyle\\hat{\\mathcal{k}}(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}+(k(t)+1)(k(t)+2)\\left\\langle\\hat{\\sigma}^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\rangle}\\\\ &{\\geq\\frac{\\displaystyle(k(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}+(k(t)+1)\\left\\langle\\sigma^{1}-\\pi^{*},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\rangle}\\\\ &{\\quad+\\left(k(t)+1\\right)^{2}\\left\\langle\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "513  From Young's inequality, we have for any $\\rho_{1},\\rho_{2}>0$ ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{k(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}+(k(t)+1)(k(t)+2)\\left\\langle\\hat{\\sigma}^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}}\\\\ &{\\geq\\frac{(k(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}-\\frac{\\rho_{1}(k(t)+1)}{2}\\left\\|\\sigma^{1}-\\pi^{*}\\right\\|^{2}-\\frac{(k(t)+1)}{2\\rho_{1}}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}}\\\\ &{\\quad-\\frac{\\rho_{2}(k(t)+1)^{2}}{2}\\left\\|\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}-\\frac{(k(t)+1)^{2}}{2\\rho_{2}}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}}\\\\ &{=\\left(\\frac{(k(t)+1)(k(t)+2)}{2}-\\frac{k(t)+1}{2\\rho_{1}}-\\frac{(k(t)+1)^{2}}{2\\rho_{2}}\\right)\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}}\\\\ &{\\quad-\\frac{\\rho_{1}(k(t)+1)}{2}\\left\\|\\sigma^{1}-\\pi^{*}\\right\\|^{2}-\\frac{\\rho_{2}(k(t)+1)^{2}}{2}\\left\\|\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "514 By setting $\\begin{array}{r}{\\rho_{1}=\\frac{4}{k(t)+2},\\rho_{2}=\\frac{4(k(t)+1)}{k(t)+2}}\\end{array}$ , we obtain: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\displaystyle\\big\\langle k(t)+1\\big\\rangle(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}+(k(t)+1)(k(t)+2)\\left\\langle\\hat{\\sigma}^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\rangle}\\\\ &{\\geq\\frac{(k(t)+1)(k(t)+2)}{4}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}-\\frac{2(k(t)+1)}{k(t)+2}\\left\\|\\sigma^{1}-\\pi^{*}\\right\\|^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad-\\frac{2(k(t)+1)^{3}}{k(t)+2}\\left\\|\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}}\\\\ &{\\geq\\frac{(k(t)+1)(k(t)+2)}{4}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}-2\\left\\|\\sigma^{1}-\\pi^{*}\\right\\|^{2}-2(k(t)+1)^{2}\\left\\|\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "515  Here, we introduce the following lemma: ", "page_idx": 17}, {"type": "text", "text": "516Lemma B.3. For any $t\\geq1$ suchthat $k(t)\\geq2$ we have: ", "text_level": 1, "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\displaystyle\\hat{\\mathcal{L}}(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}+(k(t)+1)(k(t)+2)\\left\\langle\\hat{\\sigma}^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\rangle}\\\\ &{\\le\\frac{k(t)(k(t)+1)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\|^{2}+k(t)(k(t)+1)\\left\\langle\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}},\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\rangle}\\\\ &{\\quad+(k(t)+1)\\left\\langle(k(t)+1)(\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)+1})+k(t)(\\sigma^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}}),\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "517 By combining (20) and Lemma B.3, we get: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\sinh(\\vartheta_{1}(t)+1)\\sinh(\\vartheta_{2}(t)-\\varphi_{1}(t))}{\\sinh(\\vartheta_{3}(t)+1)}-\\sinh^{2}\\left(1+(\\vartheta_{1}(t)+1)(\\vartheta_{2}(t)+\\varphi_{2}(t^{\\prime\\prime\\prime})+\\varphi_{3}(t^{\\prime\\prime\\prime}))\\right)}\\\\ &{\\leq(\\vartheta_{1}(t)+1)\\cosh(\\vartheta_{3}(t)+2)\\left[\\varphi_{1}(t^{\\prime\\prime\\prime})-\\sinh^{2}\\left(1+(\\vartheta_{1}(t)+1)(\\vartheta_{2}(t)+\\varphi_{2}(t^{\\prime\\prime\\prime})+\\varphi_{3}(t^{\\prime\\prime\\prime}))\\right)\\right]}\\\\ &{+2\\left[\\varphi_{1}(t^{\\prime\\prime\\prime})-\\cosh^{2}\\left(2+(\\vartheta_{1}(t)+1)^{2}\\right)\\sinh(\\vartheta_{2}(t)-\\varphi_{3}(t^{\\prime\\prime\\prime}))\\right]}\\\\ &{\\leq3\\cosh^{2}-\\vartheta_{1}(t)+\\cosh^{2}\\left(\\varphi_{1}(t^{\\prime\\prime})-\\varphi_{3}(t^{\\prime\\prime\\prime})-\\vartheta_{2}(t^{\\prime\\prime})\\right)+2\\left[\\varphi_{1}^{\\prime\\prime}-\\tau\\right]^{2}+2(\\vartheta_{1}(t)+1)\\mathfrak{p}\\right]\\frac{1}{\\sinh{\\tau}}-\\eta_{1}}\\\\ &{+\\frac{\\sqrt{3}}{2}\\left(\\vartheta_{1}(t)+1\\right)\\bigl(\\vartheta_{2}(t)-\\varphi_{2}(t^{\\prime\\prime})+\\vartheta_{1}(t^{\\prime\\prime}-\\varphi_{3}(t^{\\prime\\prime\\prime}))\\bigr)\\beta-\\eta_{1}\\cdots\\varnothing^{2}}\\\\ &{=3\\left[\\varphi_{1}^{\\prime\\prime\\prime}-\\vartheta_{1}(t^{\\prime})\\right]^{2}+2\\left(2+(\\vartheta_{2}(t)+3)\\cosh^{2}\\varphi_{1}(t^{\\prime\\prime})-\\vartheta_{2}(t^{\\prime})+2\\left[\\varphi_{1}^{\\prime\\prime}-\\tau\\right]^{2}\\right)}\\\\ &{+2(\\vartheta_{1}(t)+1)\\mathfrak{p}\\right]\\frac{1}{\\sinh{\\tau}}+\\frac{\\mathfrak{p}}{2}\\left(\\vartheta_{2}(t)+1\\right)\\mathfrak{p}\\mathfrak{p}(t^{\\prime})-\\\n$$$$\n\\begin{array}{r l}&{\\quad\\varepsilon\\prod_{j=1}^{n}\\varepsilon\\quad\\Bigg(\\textrm{J}_{j}^{\\varepsilon\\varepsilon\\varepsilon}\\Big)}\\\\ &{=\\underset{0\\leq}{\\sum}(\\varepsilon^{(j)}+1)^{\\varepsilon^{\\prime}}\\Bigg(\\textrm{J}_{j}^{\\varepsilon\\varepsilon\\varepsilon}\\Big)+2\\left(\\varepsilon^{(j)}+\\varepsilon^{(j)}-3\\varepsilon^{(j)}\\right)\\textrm{t}\\Bigg(x^{\\varepsilon}-x^{\\varepsilon}\\Big)+2\\left\\{\\varepsilon^{(j)}+1\\right\\}^{2}}\\\\ &{\\quad+2\\left(1+1\\right)\\left(\\varepsilon^{(j)}+1\\right)\\left(x^{\\varepsilon}-x^{\\varepsilon}\\right)\\textrm{t}\\Bigg(\\textrm{J}_{j}^{\\varepsilon\\varepsilon\\varepsilon}\\Big)+\\frac{\\varepsilon^{(j)}}{2}\\left(1+1\\right)\\left(\\varepsilon^{(j)}-6\\varepsilon^{(j)}\\right)+\\textrm{t}\\Bigg(x^{\\varepsilon}-x^{\\varepsilon}\\Big)\\Bigg\\},}\\\\ &{=\\underset{0\\leq}{\\sum}\\Bigg(\\varepsilon^{(j)}-\\varepsilon^{(j)}+2\\left(\\varepsilon^{(j)}-3\\varepsilon^{(j)}-6\\varepsilon^{(j)}-3\\varepsilon^{(j)}+4\\left(2\\varepsilon^{(j)}-3\\varepsilon^{(j)}-6\\varepsilon^{(j)}\\right)}\\\\ &{\\quad+2\\left\\{\\varepsilon^{(j)}-1\\right\\}^{2}+2\\left(\\varepsilon^{(j)}+1\\right)\\left(\\textrm{J}_{j}^{\\varepsilon\\varepsilon\\varepsilon}\\right)\\textrm{t}-\\varepsilon^{(j)}\\textrm{t}\\Bigg)}\\\\ &{\\quad+\\frac{2}{3}\\left(1+1\\right)\\left(\\varepsilon^{(j)}+1\\right)\\left(\\left(\\varepsilon^{(j)}-6\\varepsilon^{(j)}+1\\right)\\left(\\varepsilon^{(j)}-3\\varepsilon^{(j)}+1\\right)\\varepsilon^{(j)}-\\varepsilon^{(j)}\\textrm{t}\\right)}\\\\ &{=\\underset{0\\leq}{\\sum}\\Bigg(\\varepsilon^{(j)}-\\varepsilon^{(j)}+\\frac{2}{3}\\left(1+\\left(\\varepsilon^{(j)}-x^{\\varepsilon}\\right)\\varepsilon^{(j)}-6\\varepsilon^{(j)}+2\\varepsilon^{(j)}+12\\varepsilon^{(j)}+1\\right)\\varepsilon^{(j)}\\textrm{t}-\\varepsilon^{(j)}}\\\\ &{\\quad+\\frac{2}{3}\\left(1+1\\right)\\left(\\varepsilon^{(j)}+\\left(1+1\\right)\\left(\\varepsilon^{(j)}-6\\varepsilon^{(j)}+1\\right)\\left(1-\\\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "518 Therefore, we have for any $t\\geq1$ such that $k(t)\\geq2$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\hat{\\sigma}^{k\\left(t\\right)}\\right\\|^{2}\\leq\\frac{12D^{2}}{(k(t)+1)^{2}}+8\\left\\|\\sigma^{k\\left(t\\right)+1}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\|^{2}+8D\\sum_{l=1}^{k(t)}\\left\\|\\pi^{\\mu,\\sigma^{l}}-\\sigma^{l+1}\\right\\|.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "519  By the definition of ok(t), ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|^{2}+\\displaystyle\\frac{\\left\\|\\sigma^{k(t)}-\\sigma^{1}\\right\\|^{2}}{(k(t)+1)^{2}}+\\displaystyle\\frac{2}{k(t)+1}\\left\\langle\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)},\\sigma^{k(t)}-\\sigma^{1}\\right\\rangle}\\\\ &{\\leq\\displaystyle\\frac{12D^{2}}{(k(t)+1)^{2}}+8\\left\\|\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}+8D\\displaystyle\\sum_{l=1}^{k(t)}\\left\\|\\pi^{\\mu,\\sigma^{l}}-\\sigma^{l+1}\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "520 Therefore, from Cauchy-Schwarz inequality, we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\vert\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\vert\\right\\vert^{2}}\\\\ &{\\le\\displaystyle\\frac{2}{k(t)+1}\\left\\langle\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)},\\sigma^{1}-\\sigma^{k(t)}\\right\\rangle+\\frac{12D^{2}}{(k(t)+1)^{2}}}\\\\ &{\\displaystyle\\ \\ +\\left8\\left\\|\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}+8D\\sum_{l=1}^{k(t)}\\left\\|\\pi^{\\mu,\\sigma^{l}}-\\sigma^{l+1}\\right\\|}\\\\ &{\\le\\displaystyle\\frac{2D}{k(t)+1}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|+\\frac{12D^{2}}{(k(t)+1)^{2}}+8\\left\\|\\sigma^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}+8D\\sum_{l=1}^{k(t)}\\left\\|\\pi^{\\mu,\\sigma^{l}}-\\sigma^{l+1}\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "521 Furthermore, from Lemma B.1, we have for any $k\\geq1$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k}}-\\sigma^{k+1}\\right\\|^{2}\\leq\\left(\\frac{1}{1+\\eta\\mu}\\right)^{T_{\\sigma}}\\left\\|\\pi^{\\mu,\\sigma^{k}}-\\sigma^{k}\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "522 Combining (21) nad (22), we have for any $t\\geq1$ such that $k(t)\\geq2$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left\\Vert\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\Vert^{2}\\leq\\frac{2D}{k(t)+1}\\left\\Vert\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\Vert+\\frac{12D^{2}}{(k(t)+1)^{2}}}\\\\ {\\displaystyle\\qquad\\qquad\\qquad+\\,8\\left(\\frac{1}{1+\\eta\\mu}\\right)^{T_{\\sigma}}\\left\\Vert\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\Vert^{2}+8D^{2}k(t)\\left(\\frac{1}{1+\\eta\\mu}\\right)^{\\frac{T_{\\sigma}}{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "$\\begin{array}{r}{T_{\\sigma}\\geq\\operatorname*{max}(1,\\frac{6\\ln3(T+1)}{\\ln(1+\\eta\\mu)})\\Rightarrow\\left(\\frac{1}{1+\\eta\\mu}\\right)^{T_{\\sigma}}\\leq\\frac{(k(t)+1)^{3}}{(1+\\eta\\mu)^{T_{\\sigma}}}\\leq\\frac{1}{16}}\\end{array}$ ++ \u2264 we have for k(t)\u22652: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\frac{1}{2}\\left(\\left\\|\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\|-\\frac{2D}{k(t)+1}\\right)^{2}\\leq\\frac{2D^{2}}{(k(t)+1)^{2}}+\\frac{12D^{2}}{(k(t)+1)^{2}}+\\frac{D^{2}}{2(k(t)+1)^{2}}\\leq\\frac{16D^{2}}{(k(t)+1)^{2}},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "524 and then: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|{\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}}\\right\\|\\leq{\\frac{2D}{k(t)+1}}+{\\frac{4{\\sqrt{2}}D}{k(t)+1}}\\leq{\\frac{8D}{k(t)+1}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "525 On the other hand, for $k(t)=1$ , we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{1}}-\\sigma^{1}\\right\\|\\leq D\\leq{\\frac{8D}{1+1}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "526  In summary, for any $t\\geq1$ , we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|\\leq{\\frac{8D}{k(t)+1}}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "529Prfof Lemma B3. From the frst-order optimality conditionfor Tkt) ,wehave: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left\\langle V(\\pi^{\\mu,\\sigma^{k(t)}})-\\mu(\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}),\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{\\mu,\\sigma^{k(t)-1}}\\right\\rangle\\geq0.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "50Similalyfmthefstrdeomalitydiono ,we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\left\\langle V(\\pi^{\\mu,\\sigma^{k(t)-1}})-\\mu(\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}),\\pi^{\\mu,\\sigma^{k(t)-1}}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle\\geq0.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "531 Summing up these inequalities, we get for any $t\\geq1$ such that $k(t)\\geq2$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\leq\\Big\\langle V\\big(\\eta^{\\alpha,\\beta}(t^{(i)})-V\\big(\\pi^{\\beta,\\alpha^{(i)}(i-1)}\\big),\\pi^{\\beta,\\alpha^{(i)}(i)}-\\pi^{\\beta,\\beta^{(i)(i)-1}}\\Big\\rangle-\\mu\\Big\\langle\\pi^{\\beta,\\alpha^{(i)}(i)}-\\bar{\\beta}^{\\dot{\\kappa}(i)},\\pi^{\\beta,\\alpha^{(i)}(i)}-\\pi^{\\beta,\\beta^{(i)(i)}}\\Big\\rangle}\\\\ &{\\quad+\\mu\\Big\\langle\\bar{\\beta}^{\\dot{\\kappa}(i)-1}-\\pi^{\\beta,\\alpha^{(i)}(i)},\\pi^{\\beta,\\alpha^{(i)(i)}}-\\pi^{\\beta,\\beta^{(i)}(i)}\\Big\\rangle}\\\\ &{\\leq-\\mu\\Big\\langle\\pi^{\\beta,\\alpha^{(i)}(i)}-\\bar{\\beta}^{\\dot{\\kappa}(i)},\\pi^{\\beta,\\alpha^{(i)}(i)}-\\pi^{\\beta,\\beta^{(i)(i)}(i)-1}\\Big\\rangle+\\mu\\Big\\langle\\bar{\\beta}^{\\dot{\\kappa}(i)-1}-\\pi^{\\mu,\\alpha^{(i)(i)}(1)},\\pi^{\\beta,\\alpha^{(i)(i)}(1)}-\\pi^{\\beta,\\alpha^{(i)(i)}(1)}\\Big\\rangle}\\\\ &{=-\\mu\\Big\\langle\\pi^{\\beta,\\alpha^{(i)}(i)}-\\bar{\\sigma}^{\\dot{\\kappa}(i)}+\\sigma^{\\dot{\\kappa}(i)}-\\bar{\\sigma}^{\\dot{\\kappa}(i)},\\pi^{\\beta,\\alpha^{(i)(i)}(1)}-\\sigma^{\\dot{\\kappa}(i)}+\\sigma^{\\dot{\\kappa}(i)}-\\pi^{\\beta,\\alpha^{(i)(i)}(1)}\\Big\\rangle}\\\\ &{\\quad+\\mu\\Big\\langle\\bar{\\beta}^{\\dot{\\kappa}(i)-1}-\\pi^{\\mu,\\beta^{(i)(i)}(1)},\\pi^{\\mu,\\alpha^{(i)(i)}(1)}-\\pi^{\\beta,\\beta^{(i)(i)}(1)}\\Big\\rangle}\\\\ &{=-\\mu\\Big\\lVert\\pi^{\\beta,\\alpha^{(i)}(i)}-\\sigma^{\\dot{\\kappa}(i)}\\Big\\rVert^{2}-\\mu\\Big\\langle\\pi^{\\beta,\\beta^{(i)(i)}(1)}-\\sigma^{\\dot{\\kappa}(i)},\\sigma^{\\dot{\\kappa}(i)}-\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "532 Here, for any vectors $a,b,c$ , it holds that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{{\\langle a-b,b-c\\rangle=\\displaystyle\\frac{1}{2}\\|a-c\\|^{2}-\\displaystyle\\frac{1}{2}\\|b-c\\|^{2}-\\displaystyle\\frac{1}{2}\\|a-b\\|^{2},}}\\\\ {{\\langle a-b,c-d\\rangle=\\displaystyle\\frac{1}{2}\\|a-b\\|^{2}+\\displaystyle\\frac{1}{2}\\|c-d\\|^{2}-\\displaystyle\\frac{1}{2}\\|d-c+a-b\\|^{2}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "533 Thus, we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{0\\leq-\\mu\\left\\|\\pi^{\\alpha,\\alpha^{(1)}}-\\pi^{\\alpha(1)}\\right\\|^{2}-\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}}-\\pi^{\\alpha,\\alpha^{(1)}-1}\\right\\|^{2}}\\\\ &{\\quad+\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}(1)}-\\sigma^{\\alpha(1)}\\right\\|^{2}+\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}}-\\sigma^{\\alpha(1)}\\right\\|^{2}}\\\\ &{\\quad+\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}}-\\sigma^{\\alpha(1)}\\right\\|^{2}-\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}(1)}-\\sigma^{\\alpha(1)}\\right\\|^{2}-\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}}-\\pi^{\\alpha,\\alpha^{(1)}(1)-1}\\right\\|^{2}}\\\\ &{\\quad+\\frac{\\mu}{2}\\left\\|\\sigma^{\\alpha(1)}-\\sigma^{\\alpha(1)}\\right\\|^{2}+\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}}-\\pi^{\\alpha(1)(1)-1}\\right\\|^{2}}\\\\ &{\\quad-\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\alpha^{(1)}}-\\pi^{\\alpha,\\beta^{(1)}(1)-1}+\\frac{\\delta}{2}(\\nu^{\\alpha,1}-\\sigma^{\\alpha(1)})^{2}\\right\\|^{2}}\\\\ &{=-\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\beta^{(1)}}-\\pi^{\\alpha,\\beta^{(1)}(1)-1}\\right\\|^{2}+\\frac{\\mu}{2}\\left\\|\\frac{\\delta}{2}(\\nu^{\\alpha}-\\sigma^{\\beta(1)}-\\sigma^{\\beta(1)}-1)\\right\\|^{2}}\\\\ &{\\quad-\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\beta^{(1)}}-\\pi^{\\beta,\\alpha^{(1)}(1)-1}+\\frac{\\delta}{2}(\\nu^{\\alpha}-\\sigma^{\\beta(1)}-\\sigma^{\\alpha(1)(1)}-\\right.}\\\\ &{\\quad\\left.-\\frac{\\mu}{2}\\left\\|\\pi^{\\alpha,\\beta^{(1)}}-\\pi^{\\beta,\\alpha \n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\displaystyle\\frac{\\mu}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\|^{2}+\\displaystyle\\frac{\\mu}{2}\\left\\|\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}}\\right\\|^{2}-\\displaystyle\\frac{\\mu}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{\\mu,\\sigma^{k(t)-1}}\\right\\|^{2}}\\\\ &{\\quad+\\displaystyle\\mu\\left\\langle\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}},\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "534 Here, from the definition of $\\hat{\\sigma}^{k(t)}$ , we have: ", "page_idx": 20}, {"type": "text", "text": "$\\begin{array}{r l}&{\\frac{1}{n}\\left[\\begin{array}{l}{\\rho\\left(k^{0}\\right)-\\rho\\left(k^{0}\\right)^{\\ast}-\\frac{1}{n}\\left(k^{0}-n^{0}\\mathrm{e}^{\\rho\\left(k^{-1}\\right)^{\\ast}}\\right)^{2}}\\\\ {-\\frac{1}{n}\\left(\\frac{1}{k^{0}}\\frac{\\rho\\left(k^{0}\\right)^{\\ast}+\\alpha^{2}\\mathrm{e}^{\\left(k^{0}\\right)^{\\ast}}}{\\rho\\left(k^{0}\\right)}-\\frac{1}{n}\\frac{\\rho\\left(k^{0}\\right)^{\\ast}-\\rho\\left(k^{0}-n^{0}\\mathrm{e}^{\\left(k^{0}\\right)^{\\ast}}\\right)^{2}}{\\rho\\left(k^{0}\\right)}-\\frac{1}{n}\\frac{\\rho\\left(k^{0}\\right)^{\\ast}}{\\rho\\left(k^{0}\\right)}-\\frac{1}{n}\\frac{\\rho\\left(k^{0}\\right)^{\\ast}}{\\rho\\left(k^{0}\\right)}\\right]^{2}}\\\\ {-\\frac{1}{n}\\left[\\frac{\\rho\\left(k^{0}\\right)^{\\ast}(1+\\rho^{0}\\mathrm{e}^{\\left(k^{0}\\right)}-\\rho\\left(k^{0}\\right)^{\\ast}+\\alpha^{2}\\mathrm{e}^{\\left(k^{0}\\right)}-\\rho\\left(k^{0}\\right)^{\\ast}+\\frac{1}{n}\\frac{\\rho\\left(k^{0}\\right)^{\\ast}\\left(k^{0}-n^{0}\\mathrm{e}^{\\left(k^{0}\\right)}-\\rho\\left(k^{0}\\right)^{\\ast}\\right)^{2}}{\\rho\\left(k^{0}\\right)}-\\frac{1}{n}\\frac{\\rho\\left(k^{0}\\right)^{\\ast}\\left(k^{0}-n^{0}\\mathrm{e}^{\\left(k^{0}\\right)}-\\rho\\left(k^{0}\\right)^{\\ast}\\right)^{2}}{\\rho\\left(k^{0}\\right)}}\\\\ {+\\frac{1}{n}\\left(\\frac{\\rho\\left(k^{0}\\right)^{\\ast}\\left(1+\\rho^{0}\\right)^{\\ast}-\\rho\\left(k^{0}\\right)^{\\ast}-2\\left(k^{0}\\right)+1}{\\rho\\left(k^{0}\\right)}-\\frac{1}{n}\\frac{\\rho\\left(k^{0}\\right)^{\\ast}\\left(k^{0}-n^{0}\\mathrm{e}^{\\left(k^{0}\\right)}-\\rho\\left(k^{0 $ +\u03c0M,gk(t)-1 $\\begin{array}{r l}{=}&{\\frac{1}{2{\\varDelta}t}\\left(\\gamma{\\varDelta}(t)+\\gamma{\\varDelta}^{(1)}\\right)+2{\\varDelta}^{(2)}-24{\\varDelta}^{(1)}+2{\\varDelta}^{(2)}\\left(\\varDelta^{(1)}-2{\\varDelta}^{(1)}\\right){\\varDelta}^{(1)}-{\\varDelta}^{(2)}\\left(\\varDelta^{(1)}-2{\\varDelta}^{(1)}\\right)}\\\\ &{+\\frac{1}{2{\\varDelta}t}\\left(\\gamma{\\varDelta}^{(1)}-2{\\varDelta}^{(2)}+(3{\\varDelta}^{(1)}+2{\\varDelta}^{(2)}-24{\\varDelta}^{(1)})\\left(\\varDelta^{(1)}-2{\\varDelta}^{(1)}\\right)\\right)}\\\\ &{+\\frac{1}{2{\\varDelta}t}\\left(\\gamma-\\gamma\\right)+\\left(\\varDelta^{(1)}-2{\\varDelta}^{(2)}+\\gamma^{(1)}\\right)}\\\\ &{+\\frac{1}{2{\\varDelta}t}\\left(\\gamma-\\gamma\\right)+\\left(\\varDelta^{(1)}-2{\\varDelta}^{(2)}+\\gamma^{(1)}\\right)+2{\\varDelta}^{(2)}-24{\\varDelta}^{(1)}}\\\\ {=}&{\\frac{1}{2{\\varDelta}t}\\left(\\gamma^{(2)}-676-\\gamma^{(1)}\\varDelta^{(1)}-\\gamma^{(2)}\\right)}\\\\ &{+\\frac{1}{2{\\varDelta}t}\\left(\\gamma-\\gamma\\right)+\\left(\\varDelta^{(1)}-2{\\varDelta}^{(1)}-\\gamma^{(1)}\\right)+2{\\varDelta}^{(1)}+\\left(\\varDelta^{(2)}-2{\\varDelta}^{(1)},\\beta{\\varDelta}^{(2)}-{\\pi}^{(2)}\\right)}\\\\ &{+\\frac{1}{2{\\varDelta}t}\\left(\\gamma^{(2)}-676-\\gamma^{(2)}\\right)}\\\\ &{+\\frac{1}{2{\\varDelta}t}\\left(\\gamma^{(1)}-1676-\\gamma^{(2)}\\right)-676+\\gamma^{(3)}}\\\\ &{+\\frac{1}{2{\\varDelta}t}\\left(\\gamma^{(2)}-7676-\\gamma^{(3)},\\beta{\\varDelta}^{(1)}-240\\gamma^{(2)},\\beta{\\varDelta}^{(1)}-\\gamma^{(3)}\\right)}\\\\ &{$ (24) ", "page_idx": 20}, {"type": "text", "text": "535 Combining (23) and (24) yields for any $t\\geq1$ such that $k(t)\\geq2$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{k(t)+2}{2k(t)}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}+\\frac{k(t)+2}{k(t)}\\left\\langle\\hat{\\sigma}^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\rangle}\\\\ &{\\le\\displaystyle\\frac{1}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\|^{2}+\\left\\langle\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}},\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\rangle}\\\\ &{\\quad+\\displaystyle\\frac{1}{k(t)}\\left\\langle(k(t)+1)(\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)+1})+k(t)(\\sigma^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}}),\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "536  Multiplying both sides by $k(t)(k(t)+1)$ , we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{\\dot{k}(t)+1)(k(t)+2)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\|^{2}+(k(t)+1)(k(t)+2)\\left\\langle\\hat{\\sigma}^{k(t)+1}-\\pi^{\\mu,\\sigma^{k(t)}},\\pi^{\\mu,\\sigma^{k(t)}}-\\hat{\\sigma}^{k(t)}\\right\\rangle.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\frac{k(t)(k(t)+1)}{2}\\left\\|\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\|^{2}+k(t)(k(t)+1)\\left\\langle\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}},\\pi^{\\mu,\\sigma^{k(t)-1}}-\\hat{\\sigma}^{k(t)-1}\\right\\rangle}\\\\ &{\\ \\ +\\left(k(t)+1\\right)\\left\\langle(k(t)+1)(\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)+1})+k(t)(\\sigma^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)-1}}),\\hat{\\sigma}^{k(t)}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "537 ", "page_idx": 21}, {"type": "text", "text": "538 C Proofs for Theorem 4.3 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "539 C.1 Proof of Theorem 4.3 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "540 Proof of Theorem 4.3. Let us define $\\begin{array}{r}{K:=\\frac{T}{T_{\\sigma}}}\\end{array}$ . We can decompose the gap function for $\\pi^{T+1}$ as   \n541 follows: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{\\mu}_{\\mathrm{2}:\\mathrm{air}}^{\\mathrm{2}:\\mathrm{air}}\\:\\cdots\\:\\pi^{T+1}}\\\\ &{=\\underset{x\\in X}{\\operatorname*{max}}\\left\\langle V(\\pi^{\\pi^{\\mu}+1}),x-\\pi^{\\mu,\\sigma^{K}}\\right\\rangle}\\\\ &{=\\underset{x\\in X}{\\operatorname*{max}}\\left(\\left\\langle V(\\pi^{\\mu,\\sigma^{K}}),x-\\pi^{\\mu,\\sigma^{K}}\\right\\rangle-\\left\\langle V(\\pi^{\\mu,\\sigma^{K}}),x-\\pi^{\\mu,\\sigma^{K}}\\right\\rangle+\\left\\langle V(\\pi^{T+1}),x-\\pi^{T+1}\\right\\rangle\\right)}\\\\ &{=\\underset{x\\in X}{\\operatorname*{max}}\\left(\\left\\langle V(\\pi^{\\mu,\\sigma^{K}}),x-\\pi^{\\mu,\\sigma^{K}}\\right\\rangle-\\left\\langle V(\\pi^{\\mu,\\sigma^{K}})-V(\\pi^{T+1}),x-\\pi^{T+1}\\right\\rangle+\\left\\langle V(\\pi^{\\mu,\\sigma^{K}}),\\pi^{\\mu,\\sigma^{K}}-\\pi\\right.\\right.}\\\\ &{\\left.\\left.\\leq\\underset{x\\in X}{\\operatorname*{max}}\\left(\\left\\langle V(\\pi^{\\mu,\\sigma^{K}}),x-\\pi^{\\mu,\\sigma^{K}}\\right\\rangle+D\\left\\|V(\\pi^{\\mu,\\sigma^{K}})-V(\\pi^{T+1})\\right\\|+\\zeta\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|\\right)\\right.}\\\\ &{\\leq\\left.\\mathbb{G}\\left\\mathrm{AP}(\\pi^{\\mu,\\sigma^{K}})+(L D+\\zeta)\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|}\\\\ &{\\leq D\\cdot\\underset{c\\in X}{\\operatorname*{min}}\\left(\\left\\langle\\Pi^{\\mu,\\sigma^{K}}\\right\\rangle+\\left\\|-V(\\pi^{\\mu,\\sigma^{K}})+c\\right\\|+(L D+\\zeta)\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "542where the last inequality follows from Lemma 2.2. From the first-order optimality condition for   \n543 $\\pi^{\\mu,\\sigma^{K}}$ we haveforany $x\\in\\mathscr{X}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left\\langle V(\\pi^{\\mu,\\sigma^{K}})-\\mu\\left(\\pi^{\\mu,\\sigma^{K}}-\\frac{K\\sigma^{K}+\\sigma^{1}}{K+1}\\right),\\pi^{\\mu,\\sigma^{K}}-x\\right\\rangle\\geq0,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "$\\begin{array}{r}{V(\\pi^{\\mu,\\sigma^{K}})-\\mu\\left(\\pi^{\\mu,\\sigma^{K}}-\\frac{K\\sigma^{K}+\\sigma^{1}}{K+1}\\right)\\in N_{\\mathcal{X}}(\\pi^{\\mu,\\sigma^{K}})}\\end{array}$ Thus, the gap function for $\\pi^{T+1}$ can 545  be bounded by: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{GAP}(\\pi^{T+1})\\leq\\mu D\\cdot\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\frac{K\\sigma^{K}+\\sigma^{1}}{K+1}\\right\\|+(L D+\\zeta)\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|}\\\\ &{\\qquad\\qquad=\\mu D\\cdot\\left\\|\\frac{\\sigma^{K}-\\sigma^{1}}{K+1}+\\pi^{\\mu,\\sigma^{K}}-\\sigma^{K}\\right\\|+(L D+\\zeta)\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|}\\\\ &{\\qquad\\qquad\\leq\\mu D\\cdot\\left(\\displaystyle\\frac{D}{K+1}+\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\sigma^{K}\\right\\|\\right)+(L D+\\zeta)\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "546  Taking its expectation yields: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathrm{GAP}(\\pi^{T+1})\\right]\\leq\\frac{\\mu D^{2}}{K+1}+\\mu D\\cdot\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\sigma^{K}\\right\\|\\right]+(L D+\\zeta)\\cdot\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|\\right]}\\\\ &{\\qquad\\qquad\\qquad\\leq\\frac{\\mu D^{2}}{K+1}+\\mu D\\cdot\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\sigma^{K}\\right\\|\\right]+(L D+\\zeta)\\cdot\\sqrt{\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\|^{2}\\right]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "547 Here, we derive the following upper bound on $\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\Vert^{2}\\right]$ ", "page_idx": 21}, {"type": "text", "text": "548 Lemma C.1. Let  = \u4e9b,0 = 3u+8L2. . Suppose that Assumption 4.2 holds. If we set $\\eta_{t}~=$   \n549 k(t-Ta(k(t)-1)+20, we have for any t \u2265 1: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left[\\left\\|\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\pi^{t+1}\\right\\|^{2}\\right]\\leq\\frac{2\\theta}{\\kappa\\left(t-(k(t)-1)T_{\\sigma}\\right)+2\\theta}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa\\left(t-(k(t)-1)T_{\\sigma}\\right)}{2\\theta}+1\\right)\\right)\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "550 Setting $t=T=K T_{\\sigma}$ , we can write $\\begin{array}{r}{k(t)=\\lfloor\\frac{K T_{\\sigma}-1}{T_{\\sigma}}\\rfloor+1=K}\\end{array}$ Therefore, from Lemma C.1, we   \n551have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{K}}-\\pi^{T+1}\\right\\Vert^{2}\\right]\\leq\\frac{2\\theta}{\\kappa T_{\\sigma}+2\\theta}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T_{\\sigma}}{2\\theta}+1\\right)\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "552 On the other hand, in terms of $\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\Vert\\right]$ , we introduce the following lemma: ", "page_idx": 22}, {"type": "text", "text": "553 Lemma C.2.Ifwe set $\\begin{array}{r}{\\eta_{t}=\\frac{1}{\\kappa(t-T_{\\sigma}(k(t)-1))+2\\theta}}\\end{array}$ and $T_{\\sigma}\\geq\\operatorname*{max}(1,T^{\\frac{6}{7}})$ we have for any $t\\geq1$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\natural\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\Vert\\right]\\leq\\frac{6\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}\\right)}{k(t)}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "554  By setting $t=K T_{\\sigma}$ in this lemma, we get: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{K}}-\\sigma^{K}\\right\\Vert\\right]\\leq\\frac{6\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}\\right)}{K}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "555 Combining (25), (26), and (27), we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\mathrm{GAP}(\\sigma^{K+1})\\right]}\\\\ &{\\le\\frac{\\mu D^{2}}{K+1}+\\mu D\\cdot\\frac{6\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}\\right)}{K}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{\\phantom{2p c}+(L D+\\zeta)\\cdot\\sqrt{\\frac{2\\theta}{\\kappa T_{\\sigma}+2\\theta}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T_{\\sigma}}{2\\theta}+1\\right)\\right)}}\\\\ &{\\le\\mu D^{2}\\frac{T_{\\sigma}}{T}+\\mu D\\cdot\\frac{6T_{\\sigma}\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}\\right)}{T}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{\\phantom{2p c}+(L D+\\zeta)\\cdot\\sqrt{\\frac{2\\theta}{\\kappa T_{\\sigma}}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "556  where the second inequality follows from $\\begin{array}{r}{K=\\frac{T}{T_{\\sigma}}}\\end{array}$ . Finally, since $T_{\\sigma}=c\\cdot\\operatorname*{max}(1,T^{\\frac{6}{7}})$ , we have for   \n557 any $T\\geq T_{\\sigma}$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left\\{\\left[\\boldsymbol{\\mathrm{GAP}}(\\sigma^{\\mathrm{Ar}})\\right]\\right\\}}\\\\ &{\\leq\\frac{c\\mu D^{2}}{T^{4}}+\\frac{6\\mu D}{\\gamma}\\left(\\sqrt{\\kappa}+\\sqrt{\\beta}+\\sqrt{D\\theta}+\\sqrt{D}\\right)\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{\\quad+\\frac{(L D+\\zeta)}{T^{4}}\\sqrt{\\frac{2\\theta}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}}\\\\ &{\\leq\\frac{6\\mu D\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}+D\\right)}{T^{4}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{\\quad+\\frac{(L D+\\zeta)\\sqrt{2\\theta}}{T^{4}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{\\leq\\frac{9c(\\mu D+L D+\\zeta)\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}+D\\right)}{T^{4}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "558  Since $T=T_{\\sigma}K$ , we have finally: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\vdots[\\mathrm{Gr}(\\pi^{T+1})]}\\\\ &{\\le\\frac{9c(\\mu\\boldsymbol{D}+L D+\\zeta)\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}+D\\right)}{T^{\\dagger}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{=\\frac{9c(D(\\mu+L)+\\zeta)\\left(\\sqrt{\\kappa}+(\\sqrt{D}+1)(\\sqrt{D}+\\sqrt{\\theta})\\right)}{T^{\\dagger}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{\\le\\frac{18c(D(\\mu+L)+\\zeta)\\left(\\sqrt{\\kappa}+\\sqrt{(D+1)(D+\\theta)}\\right)}{T^{\\dagger}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)}\\\\ &{\\le\\frac{26c(D(\\mu+L)+\\zeta)\\sqrt{(D+1)(D+\\theta)}+\\kappa}{T^{\\dagger}}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "559 ", "page_idx": 23}, {"type": "text", "text": "560 C.2 Proof of Lemma C.1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "561 Proof of Lemma C.1. From the frst-order optimality condition for $\\pi^{t+1}$ ,we have for $t\\geq1$ ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\left\\langle\\eta_{t}\\left(\\hat{V}(\\pi^{t})-\\mu(\\pi^{t}-\\hat{\\sigma}^{k(t)})\\right)-\\pi^{t+1}+\\pi^{t},\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle\\geq0.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "562 Combining (28), (12), and (14), we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{n}\\left\\|w^{k_{1}-n}-w^{k_{1}-1}\\right\\|^{2}-\\frac{1}{n}\\left\\|w^{k_{2}-n}-w^{k_{1}}\\right\\|^{2}+\\frac{1}{n}\\left\\|w^{k_{1}-n}-w^{k_{1}-n}\\right\\|^{2}}\\\\ &{\\leq\\Re\\left\\langle V(u^{k_{1}-n})-\\theta(u^{k_{2}-n})\\right\\rangle,}\\\\ &{=\\left\\langle V(u^{k_{1}-n})-\\theta(u^{k_{1}-n})+w^{k_{2}-n}\\right\\rangle+w^{k_{2}-n+n}\\right\\rangle}\\\\ &{\\leq\\Re\\left\\langle V(u^{k_{2}-n})-\\theta(u^{k_{1}-n}-\\theta(u^{k_{2}-n}))+\\theta(u^{k_{2}-n}-w^{k_{1}-n})+\\theta(u^{k_{1}-n})-\\theta(u^{k_{2}-n}-u^{k_{1}})\\right\\rangle,}\\\\ &{\\leq\\Re\\left\\langle V(u^{k_{2}-n})-\\theta(u^{k_{1}-n})+\\theta(u^{k_{2}})+w^{k_{2}-n}\\right\\rangle+\\Re\\left\\langle V(u^{k_{1}-n})-\\theta(u^{k_{2}-n})-\\theta(u^{k_{1}-n})\\right\\rangle}\\\\ &{=\\Re\\left\\langle V(u^{k_{2}-n})-\\theta(u^{k_{2}-n})-\\theta(u^{k_{1}})+w^{k_{2}-n}\\right\\rangle-\\theta(u^{k_{2}})\\left\\|w^{k_{1}-n}-w^{k_{1}-n}\\right\\rangle}\\\\ &{\\quad+\\underbrace{\\theta}_{u}\\left\\langle V(u^{k_{2}-n})-w^{k_{1}-n}\\right\\rangle+\\underbrace{\\theta}_{u}\\left\\langle V(u^{k_{2}-n})-w^{k_{2}-n}\\right\\rangle-\\underbrace{\\theta}_{u^{k_{2}-n}}+w^{k_{2}-n}\\right\\rangle+\\underbrace{\\theta}_{u}\\left\\langle\\zeta_{u^{k_{1}-n}}\\right\\rangle}\\\\ &{\\leq-\\eta_{0}\\left\\|w^{k_{2}-n}-w^{k_{1}-n}\\right\\|^{2}+\\underbrace{\\eta}_{u^{k_{2}-n}}+w^{k_{1}-n}+\\underbrace{\\eta}_{u^{k_{1}-n}}+ \n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "563 where the third inequality follows from (1). From Cauchy-Schwarz inequality and Young's inequality,   \n564  the fourth term on the right-hand side of this inequality can be bounded by: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\langle V(\\pi^{t})-V(\\pi^{t+1}),\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\rangle}\\\\ &{\\leq\\left\\|V(\\pi^{t})-V(\\pi^{t+1})\\right\\|\\cdot\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|}\\\\ &{\\leq L\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|\\cdot\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\leq\\frac{2L^{2}}{\\mu}\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|^{2}+\\frac{\\mu}{8}\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}}\\\\ {\\displaystyle\\leq\\frac{2L^{2}}{\\mu}\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|^{2}+\\frac{\\mu}{4}\\left\\|\\pi^{t}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}+\\frac{\\mu}{4}\\left\\|\\pi^{t+1}-\\pi^{t}\\right\\|^{2}}\\\\ {\\displaystyle=\\left(\\frac{4L^{2}}{\\mu}+\\frac{\\mu}{2}\\right)\\frac{\\left\\|\\pi^{t}-\\pi^{t+1}\\right\\|^{2}}{2}+\\frac{\\mu}{2}\\frac{\\left\\|\\pi^{t}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\|^{2}}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "565 By combining (29) and (30), we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left|\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\pi^{\\mu+1}\\right|\\right|^{2}\\leq-\\eta_{\\ell}\\mu\\left\\|\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\|^{2}+\\left(1-\\frac{\\eta_{\\ell}\\mu}{2}\\right)\\left\\|\\pi^{t}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\|^{2}}&{}\\\\ {\\qquad-\\left(1-\\eta_{t}\\left(\\frac{3\\mu}{2}+\\frac{4L^{2}}{\\mu}\\right)\\right)\\left\\|\\pi^{t+1}-\\pi^{t}\\right\\|^{2}+2\\eta_{t}\\left\\langle\\xi^{\\ell},\\pi^{t+1}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\rangle}&{}\\\\ {\\leq\\left(1-\\frac{\\eta_{t}\\mu}{2}\\right)\\left\\|\\pi^{t}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\|^{2}-\\left(1-\\eta_{t}\\left(\\frac{3\\mu}{2}+\\frac{4L^{2}}{\\mu}\\right)\\right)\\left\\|\\pi^{t+1}-\\pi^{t}\\right\\|^{2}}&{}\\\\ {\\quad+\\;2\\eta_{t}\\left\\langle\\xi^{\\ell},\\pi^{t}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\rangle+2\\eta_{t}\\left\\langle\\xi^{\\ell},\\pi^{t+1}-\\pi^{t}\\right\\rangle}&{}\\\\ {=(1-\\eta_{t}\\kappa)\\left\\|\\pi^{t}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\|^{2}-(1-\\eta_{t}\\theta)\\left\\|\\pi^{t+1}-\\pi^{t}\\right\\|^{2}}&{}\\\\ {\\qquad+\\;2\\eta_{t}\\left\\langle\\xi^{\\ell},\\pi^{t}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\rangle+2\\eta_{t}\\left\\langle\\xi^{\\ell},\\pi^{t+1}-\\pi^{t}\\right\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "566 By taking the expectation conditioned on $\\mathcal{F}_{t}$ for both sides and using Assumption 4.2 (a) and (b), ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\Vert u^{t,n+1}-u^{t+1}\\right\\Vert^{2}\\;\\middle|\\;F_{t}\\right]}\\\\ &{\\leq(1-\\eta_{t})\\varepsilon\\left[\\left\\Vert u^{t}-\\eta u^{t,n}\\right\\Vert^{2}\\;\\middle|\\;F_{t}\\right]-(1-\\eta_{t}\\theta)\\mathbb{E}\\left[\\left\\Vert u^{t+1}-\\pi\\right\\Vert^{2}\\;)\\;\\middle|F_{t}\\right]}\\\\ &{\\quad+2\\eta_{t}\\left\\langle\\mathbb{E}\\left[\\varepsilon\\left\\Vert\\tilde{\\varepsilon}_{t}\\right\\Vert,\\eta_{t}\\right]\\pi_{t}-\\eta_{t}\\varepsilon u^{t,n+0}\\right\\rangle+2\\eta_{t}\\mathbb{E}\\left[\\left\\langle\\varepsilon\\left\\vert\\tau^{t+1}-\\pi\\right\\vert^{2}\\;\\middle|F_{t}\\right\\rangle\\right]}\\\\ &{=(1-\\eta_{t})\\left\\Vert u^{t}-\\eta u^{t,n+1}\\right\\Vert^{2}-(1-\\eta_{t}\\theta)\\mathbb{E}\\left[\\left\\Vert u^{t+1}-\\pi\\right\\Vert^{2}\\;)\\;\\middle|F_{t}\\right]+2\\eta_{t}\\mathbb{E}\\left[\\left\\langle\\xi\\left\\vert\\tau^{t},\\eta^{t+1}-\\pi\\right\\rangle\\;\\middle|F_{t}\\right]}\\\\ &{\\leq(1-\\eta_{t})\\left\\Vert u^{t}-\\eta u^{t,n+1}\\right\\Vert^{2}-(1-\\eta_{t}\\theta)\\mathbb{E}\\left[\\left\\Vert u^{t+1}-\\pi\\right\\Vert^{2}\\;)\\;\\middle|F_{t}\\right]}\\\\ &{\\quad+\\frac{\\eta_{t}\\tilde{\\varepsilon}}{1-\\eta_{t}\\theta}\\int\\left[\\left\\Vert\\varepsilon\\right\\Vert^{2}\\;\\middle|F_{t}\\right]+(1-\\eta_{t}\\theta)\\mathbb{E}\\left[\\left\\Vert u^{t+1}-\\pi\\right\\Vert^{2}\\;)\\;\\middle|F_{t}\\right]}\\\\ &{\\leq(1-\\eta_{t})\\left\\Vert u^{t}-\\eta u^{t,\\varepsilon+1}\\right\\Vert^{2}+\\frac{\\eta_{t}^{2}}{1-\\eta_{t}\\theta}\\mathbb{E}\\left[\\left\\Vert\\varepsilon\\right\\Vert^{2}\\;\\middle|F_{t}\\right]}\\\\ &{\\leq(1-\\eta_{t})\\left\\Vert u^{t}-\\eta u^{t,\\varepsilon+1}\\right\\Vert^{2}+2\\eta_{t}\\mathbb{E}\\left[\\left\\Vert\\xi\\right\\Vert^{2}\\;\\middle|F_{t}\\right]}\\\\ &{\\leq(1-\\eta_{t})\\left\\Vert u^{t}-\\eta u^{\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "7The $\\begin{array}{r}{\\eta_{t}=\\frac{1}{\\kappa(t-T_{\\sigma}(k(t)-1))+2\\theta}}\\end{array}$ .we have for any $t\\geq1$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\Vert^{2}\\;|\\;\\mathcal{F}_{t}\\right]\\le\\left(1-\\frac{1}{t-T_{\\sigma}(k(t)-1)+2\\theta/\\kappa}\\right)\\left\\Vert\\pi^{t}-\\pi^{\\mu,\\sigma^{k(t)}}\\right\\Vert^{2}+2\\eta_{t}^{2}C^{2}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "568  Rearranging and taking the expectations, we get: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(t-T_{\\sigma}(k(t)-1)+2\\theta/\\kappa\\right)\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}\\right]}\\\\ &{\\leq\\left(t-1-T_{\\sigma}(k(t)-1)+2\\theta/\\kappa\\right)\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t}\\right\\|^{2}\\right]+\\frac{2C^{2}}{\\kappa\\left(\\kappa\\left(t-T_{\\sigma}(k(t)-1)\\right)+2\\theta\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "569  Since $k(s)=k(t)$ for any $s\\in[(k(t)-1)T_{\\sigma}+1,T]$ , telescoping the sum yields: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(t-T_{\\sigma}(k(t)-1)+2\\theta/\\kappa\\right)\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\Vert^{2}\\right]}\\\\ &{\\leq(s-1-T_{\\sigma}(k(t)-1)+2\\theta/\\kappa)\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{s}\\right\\Vert^{2}\\right]+\\displaystyle\\sum_{m=s}^{t}\\frac{2C^{2}}{\\kappa\\left(\\kappa(m-T_{\\sigma}(k(t)-1))+2\\theta\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "570Defining $s=(k(t)-1)T_{\\sigma}+1$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(t-T_{\\sigma}(k(t)-1)+2\\theta/\\kappa\\right)\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{t+1}\\right\\|^{2}\\right]}\\\\ &{\\leq\\displaystyle\\frac{2\\theta}{\\kappa}\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\pi^{(k(t)-1)T_{\\sigma}+1}\\right\\|^{2}\\right]+\\displaystyle\\frac{2C^{2}}{\\kappa}\\sum_{m=(k(t)-1)T_{\\sigma}+1}^{t}\\frac{1}{\\kappa(m-T_{\\sigma}(k(t)-1))+2\\theta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "571 Therefore, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\pi^{t+1}\\right\\Vert^{2}\\right]\\leq\\frac{2\\theta}{\\kappa\\left(t-T_{\\sigma}\\left(k\\left(t\\right)-1\\right)\\right)+2\\theta}\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\pi^{\\left(k\\left(t\\right)-1\\right)T_{\\sigma}+1}\\right\\Vert^{2}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\frac{2C^{2}}{\\kappa\\left(t-T_{\\sigma}\\left(k\\left(t\\right)-1\\right)\\right)+2\\theta}\\underset{m=1}{\\overset{t-(k\\left(t\\right)-1)T_{\\sigma}}{\\sum}}\\frac{1}{\\kappa m+2\\theta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "572 Here, we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{m=1}^{t-(k(t)-1)T_{\\sigma}}\\frac{1}{\\kappa m+2\\theta}\\leq\\int_{0}^{t-(k(t)-1)T_{\\sigma}}\\frac{1}{\\kappa x+2\\theta}d x=\\frac{1}{\\kappa}\\ln\\left(\\frac{\\kappa\\left(t-(k(t)-1)T_{\\sigma}\\right)}{2\\theta}+1\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "573 Combining (31), (32), and the fact that $\\pi^{(k(t)-1)T_{\\sigma}+1}=\\sigma^{k(t)}$ , we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\pi^{t+1}\\right\\Vert^{2}\\right]}\\\\ &{\\leq\\frac{2\\theta}{\\kappa\\left(t-(k(t)-1)T_{\\sigma}\\right)+2\\theta}\\left(\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\Vert^{2}\\right]+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa\\left(t-(k(t)-1)T_{\\sigma}\\right)}{2\\theta}+1\\right)\\right)}\\\\ &{\\leq\\frac{2\\theta}{\\kappa\\left(t-(k(t)-1)T_{\\sigma}\\right)+2\\theta}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa\\left(t-(k(t)-1)T_{\\sigma}\\right)}{2\\theta}+1\\right)\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "574 ", "page_idx": 25}, {"type": "text", "text": "575 C.3 Proof of Lemma C.2 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "576  Proof of Lemma C.2. First, from Lemma C.1, we have for any $k\\geq1$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k}}-\\sigma^{k+1}\\right\\Vert^{2}\\right]\\leq\\frac{2\\theta}{\\kappa T_{\\sigma}+2\\theta}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T_{\\sigma}}{2\\theta}+1\\right)\\right).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "577 Moreover, by taking the expectation of (21), we have for any $t\\geq1$ such that $k(t)\\geq2$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\sigma^{k\\left(t\\right)}\\right\\Vert^{2}\\right]\\leq\\displaystyle\\frac{2D}{k(t)+1}\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\sigma^{k\\left(t\\right)}\\right\\Vert\\right]+\\displaystyle\\frac{12D^{2}}{(k(t)+1)^{2}}}\\\\ {\\displaystyle+\\,8\\mathbb{E}\\left[\\left\\Vert\\sigma^{k\\left(t\\right)+1}-\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}\\right\\Vert^{2}\\right]+8D\\displaystyle\\sum_{l=1}^{k(t)}\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{l}}-\\sigma^{l+1}\\right\\Vert\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "578  Combining these inequalities, we get for any $t\\geq1$ such that $k(t)\\geq2$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\sigma^{k\\left(t\\right)}\\right\\Vert^{2}\\right]\\leq\\frac{2D}{k(t)+1}\\mathbb{E}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\left(t\\right)}}-\\sigma^{k\\left(t\\right)}\\right\\Vert\\right]+\\frac{12D^{2}}{(k(t)+1)^{2}}}\\\\ &{\\quad+\\,\\frac{16\\theta}{\\kappa T_{\\sigma}}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T_{\\sigma}}{2\\theta}+1\\right)\\right)+8D k(t)\\sqrt{\\frac{2\\theta}{\\kappa T_{\\sigma}}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T_{\\sigma}}{2\\theta}+1\\right)\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "579 Since $\\begin{array}{r}{T_{\\sigma}\\geq\\operatorname*{max}(1,T^{\\frac{6}{7}})\\Rightarrow\\frac{k(t)^{3}}{\\sqrt{T_{\\sigma}}}\\leq1}\\end{array}$ we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\left(\\left\\|\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\|-\\frac{D}{k(t)+1}\\right)^{2}\\right]\\leq\\frac{13D^{2}}{k(t)^{2}}+\\frac{16\\theta}{\\kappa k(t)^{2}}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\,\\frac{8D}{k(t)^{2}}\\sqrt{\\frac{2\\theta}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "580  Since $\\mathbb{E}[X]^{2}\\leq\\mathbb{E}[X^{2}]$ for any random variable $X$ , we get: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{13D^{2}}{k(t)^{2}}+\\frac{16\\theta}{\\kappa k(t)^{2}}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)+\\frac{8D}{k(t)^{2}}\\sqrt{\\frac{2\\theta}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}}\\\\ &{\\geq\\mathbb{E}\\left[\\left(\\left\\|\\pi^{\\mu,\\sigma^{\\kappa(t)}}-\\sigma^{\\kappa(t)}\\right\\|-\\frac{D}{k(t)+1}\\right)^{2}\\right]}\\\\ &{\\geq\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{\\kappa(t)}}-\\sigma^{\\kappa(t)}\\right\\|-\\frac{D}{k(t)+1}\\right]^{2}}\\\\ &{=\\left(\\mathbb{E}\\left[\\left\\|\\pi^{\\mu,\\sigma^{\\kappa(t)}}-\\sigma^{\\kappa(t)}\\right\\|\\right]-\\frac{D}{k(t)+1}\\right)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "581 Then, we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\xi\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{k\\,(t)}}-\\sigma^{k\\,(t)}\\right\\Vert\\right]}\\\\ &{\\le\\frac{D}{k(t)}+\\frac{4D}{k(t)}+\\frac{4\\sqrt{\\theta}}{\\sqrt{\\kappa}k(t)}\\sqrt{D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)}+\\frac{3\\sqrt{D}}{k(t)}\\left(\\frac{2\\theta}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)\\right)^{\\frac{1}{4}}}\\\\ &{\\le\\frac{5(\\sqrt{\\kappa}+\\sqrt{\\theta})}{k(t)\\sqrt{\\kappa}}\\sqrt{D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)}+\\frac{6\\sqrt{D}(\\sqrt{\\theta}+1)}{k(t)}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+\\right.}\\\\ &{\\le\\frac{6\\left.\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}\\right)\\right)}{k(t)}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "582Furthermore, for $k(t)=1$ , we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{\\xi}\\left[\\left\\Vert\\pi^{\\mu,\\sigma^{1}}-\\sigma^{1}\\right\\Vert\\right]\\leq D\\leq\\frac{6\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D}\\right)}{1}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "583  Therefore, we have for any $t\\geq1$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathop{\\mathbb{Z}}\\left[\\left\\|\\pi^{\\mu,\\sigma^{k(t)}}-\\sigma^{k(t)}\\right\\|\\right]\\le\\frac{6\\left(\\sqrt{\\kappa}+\\sqrt{\\theta}+\\sqrt{D\\theta}+\\sqrt{D})\\right)}{k(t)}\\left(\\sqrt{\\frac{1}{\\kappa}\\left(D^{2}+\\frac{C^{2}}{\\kappa\\theta}\\ln\\left(\\frac{\\kappa T}{2\\theta}+1\\right)\\right)}+1\\right).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "584 ", "page_idx": 26}, {"type": "text", "text": "585 D Proof of Theorem 5.1 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "586  Proof of Theorem 5.1. By the definition of dynamic regret, we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{DynamicReg}_{i}(T)=\\displaystyle\\sum_{t=1}^{T}\\left(\\operatorname*{max}_{\\boldsymbol{x}\\in\\mathcal{X}_{i}}v_{i}(\\boldsymbol{x},\\pi_{-i}^{t})-v_{i}(\\pi^{t})\\right)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathcal{O}(1)+\\displaystyle\\sum_{t=3}^{T}\\sum_{i=1}^{N}\\left(\\operatorname*{max}_{\\boldsymbol{x}\\in\\mathcal{X}_{i}}v_{i}(\\boldsymbol{x},\\pi_{-i}^{t})-v_{i}(\\pi^{t})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "587 Here, we introduce the following lemma: ", "page_idx": 26}, {"type": "text", "text": "588 Lemma D.1 (Lemma 2 of Cai et al. [2022a]). For any $\\pi\\in\\mathcal{X}$ wehave: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{N}\\left(\\operatorname*{max}_{\\tilde{\\pi}_{i}\\in\\mathcal{X}_{i}}v_{i}(\\tilde{\\pi}_{i},\\pi_{-i})-v_{i}(\\pi)\\right)\\leq\\mathrm{GAP}(\\pi)\\leq D\\cdot\\operatorname*{max}_{\\tilde{\\pi}\\in\\mathcal{X}}\\langle V(\\pi),\\tilde{\\pi}-\\pi\\rangle.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "589 Therefore, we have: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathrm{DynamicReg}_{i}(T)\\leq\\mathcal{O}(1)+\\sum_{t=3}^{T}\\mathrm{GAP}(\\pi^{t}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "590 Thus, from Theorem 4.1: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{DynamicReg}_{i}(T)\\le\\mathcal{O}(1)+\\displaystyle\\sum_{t=3}^{T}\\mathcal{O}\\left(\\frac{\\ln T}{t}\\right)}&{{}}\\\\ {\\le\\mathcal{O}\\left((\\ln T)^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "591 ", "page_idx": 27}, {"type": "text", "text": "592 E Experimental details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "593  E.1  Information on the computer resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "594  The experiments were conducted on macOS Sonoma 14.4.1 with Apple M2 Max and 32GB RAM. ", "page_idx": 27}, {"type": "text", "text": "595   E.2  Hard concave-convex game ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "596  Following the setup in Ouyang and $\\mathrm{Xu}$ [2021], Cai and Zheng [2023], we choose ", "page_idx": 27}, {"type": "equation", "text": "$$\nA=\\frac{1}{4}\\left[\\begin{array}{l l l l l}&&{\\hdots}&{-1}&{1}\\\\ &&{\\hdots}&{\\cdots}&\\\\ {-1}&{1}&{1}&&\\\\ {1}&&&&\\end{array}\\right]\\in\\mathbb{R}^{n\\times n},\\quad b=\\frac{1}{4}\\left[\\begin{array}{l}{1}\\\\ {1}\\\\ {\\cdots}\\\\ {1}\\\\ {1}\\end{array}\\right]\\in\\mathbb{R}^{n},\\quad h=\\frac{1}{4}\\left[\\begin{array}{l}{0}\\\\ {0}\\\\ {\\cdots}\\\\ {0}\\\\ {1}\\end{array}\\right]\\in\\mathbb{R}^{n},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "597 and $H=2A^{\\top}A$ ", "page_idx": 27}, {"type": "text", "text": "598 E.3 Hyperparameters ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "599 For each game, we carefully tuned the hyperparameters for each algorithm to ensure optimal perfor  \n600 mance. The specific parameters for each game and setting are summarized in Table 1. ", "page_idx": 27}, {"type": "table", "img_path": "TI7Vy90B9j/tmp/8ce38462f744228e446a58219744ef180474c18abcfdf5ce3265046b50a34746.jpg", "table_caption": [], "table_footnote": ["Table 1: Hyperparameters "], "page_idx": 27}, {"type": "text", "text": "601 F  Relationship with accelerated optimistic gradient algorithm ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "602 Our GABP bears some relation to Accelerated Optimistic Gradient (AOG) [Cai and Zheng, 2023],   \n603 which updates the strategy by: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pi_{i}^{t+\\frac{1}{2}}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{\\left\\langle\\eta\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t-\\frac{1}{2}})+\\frac{\\pi_{i}^{1}-\\pi_{i}^{t}}{t+1},x\\right\\rangle-\\frac{1}{2}\\left\\lVert x-\\pi_{i}^{t}\\right\\rVert^{2}\\right\\},}\\\\ {\\pi_{i}^{t+1}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{\\left\\langle\\eta\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t+\\frac{1}{2}})+\\frac{\\pi_{i}^{1}-\\pi_{i}^{t}}{t+1},x\\right\\rangle-\\frac{1}{2}\\left\\lVert x-\\pi_{i}^{t}\\right\\rVert^{2}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "604   This can be equivalently written as: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pi_{i}^{t+\\frac{1}{2}}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{\\eta\\left\\langle\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t-\\frac{1}{2}}),x\\right\\rangle-\\frac{1}{2}\\left\\|x-\\frac{t\\pi_{i}^{t}+\\pi_{i}^{1}}{t+1}\\right\\|^{2}\\right\\},}\\\\ {\\pi_{i}^{t+1}=\\underset{x\\in\\mathcal{X}_{i}}{\\arg\\operatorname*{max}}\\left\\{\\eta\\left\\langle\\widehat{\\nabla}_{\\pi_{i}}v_{i}(\\pi^{t+\\frac{1}{2}}),x\\right\\rangle-\\frac{1}{2}\\left\\|x-\\frac{t\\pi_{i}^{t}+\\pi_{i}^{1}}{t+1}\\right\\|^{2}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "605 This means that AOG employs a convex combination $\\frac{t\\pi_{i}^{t}\\!+\\!\\pi_{i}^{1}}{t\\!+\\!1}$ of the current strategy $\\pi_{i}^{t}$ and initial   \n606 strategy $\\pi_{i}^{1}$ as the proximal point in gradient ascent. However, our GABP diverges from AOG in that it   \n607 uses a convex combinaion $\\frac{k(t)\\sigma_{i}^{k(t)}\\!+\\!\\sigma_{i}^{1}}{k(t)\\!+\\!1}$ ofo $\\sigma_{i}^{k(t)}$ and $\\sigma_{i}^{1}$ as the reference strategy for the perturbation   \n608 term. ", "page_idx": 28}, {"type": "text", "text": "609 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "6 \u00b7 The answer NA means that the abstract and introduction do not include the claims 7 made in the paper.   \n8 \u00b7 The abstract and/or introduction should clearly state the claims made, including the 9 contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n:1 \u00b7 The claims made should match theoretical and experimental results, and refect how 2 much the results can be expected to generalize to other settings.   \n3 \u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals 4 are not attained by the paper. ", "page_idx": 29}, {"type": "text", "text": "625 2. Limitations ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: In \u201cIntroduction\" and \u201cConclusion\", we have reiterated the limitation of this study. ", "page_idx": 29}, {"type": "text", "text": "\uff09 Guidelines: \u00b7 The answer NA means that the paper has no limitation while the answer No means that   \n\uff1f the paper has limitations, but those are not discussed in the paper.   \n3 \u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper. \u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the   \n3 implications would be.   \n\uff0c \u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n\uff09 only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\uff1a \u00b7 The authors should reflect on the factors that influence the performance of the approach.   \n3 For example, a facial recognition algorithm may perform poorly when image resolution   \n+ is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. \u00b7 The authors should discuss the computational efficiency of the proposed algorithms   \n3 and how they scale with dataset size. \u00b7 If applicable, the authors should discuss possible limitations of their approach to   \n\uff09 address problems of privacy and fairness. \u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n3 limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "57 3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "658 Question: For each theoretical result, does the paper provide the full set of assumptions and   \n659 a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: Please see the theoretical results and their proofs in the Appendix. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 30}, {"type": "text", "text": "73 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We have provided descriptions of experimental setups in the experiments section. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might sufice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "716 Answer: [Yes]   \n717 Justification: We have included the experimental code in the supplementary material.   \n718 Guidelines:   \n719 \u00b7 The answer NA means that paper does not include experiments requiring code.   \n720 \u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips. cc/   \n721 public/guides/CodeSubmissionPolicy) for more details.   \n722 \u00b7 While we encourage the release of code and data, we understand that this might not be   \n723 possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not   \n724 including code, unless this is central to the contribution (e.g., for a new open-source   \n725 benchmark).   \n726 \u00b7 The instructions should contain the exact command and environment needed to run to   \n727 reproduce the results. See the NeurIPS code and data submission guidelines (https :   \n728 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n729 \u00b7 The authors should provide instructions on data access and preparation, including how   \n730 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n731 \u00b7 The authors should provide scripts to reproduce all experimental results for the new   \n732 proposed method and baselines. If only a subset of experiments are reproducible, they   \n733 should state which ones are omitted from the script and why.   \n734 \u00b7 At submission time, to preserve anonymity, the authors should release anonymized   \n735 versions (if applicable).   \n736 \u00b7 Providing as much information as possible in supplemental material (appended to the   \n737 paper) is recommended, but including URLs to data and code is permitted.   \n738 6. Experimental Setting/Details   \n739 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n740 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n741 results?   \n742 Answer: [Yes]   \n743 Justification: We have provided descriptions of experimental setups in the experiments   \n744 section.   \n745 Guidelines:   \n746 \u00b7 The answer NA means that the paper does not include experiments.   \n747 \u00b7 The experimental setting should be presented in the core of the paper to a level of detail   \n748 that is necessary to appreciate the results and make sense of them.   \n749 \u00b7 The full details can be provided either with the code, in appendix, or as supplemental   \n750 material.   \n751 7. Experiment Statistical Significance   \n752 Question: Doesthe paper report error bars suitably and correctly defined or other appropriate   \n753 information about the statistical significance of the experiments?   \n754 Answer: [Yes]   \n755 Justification: Please see Figures.   \n756 Guidelines:   \n757 \u00b7 The answer NA means that the paper does not include experiments.   \n758 \u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n759 dence intervals, or statistical signifcance tests, at least for the xperiments that support   \n760 the main claims of the paper.   \n761 \u00b7 The factors of variability that the error bars are capturing should be clearly stated (for   \n762 example, train/test split, initialization, random drawing of some parameter, or overall   \n763 run with given experimental conditions).   \n764 \u00b7 The method for calculating the error bars should be explained (closed form formula,   \n765 call to a library function, bootstrap, etc.)   \n766 \u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n767 \u00b7 It should be clear whether the error bar is the standard deviation or the standard error   \n768 of the mean.   \n769 \u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n770 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n771 of Normality of errors is not verified.   \n772 \u00b7 For asymmetric distributions, the authors should be careful not to show in tables or   \n773 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n774 error rates).   \n775 If errorbars arerported in tabls orplots,The authors should explain in the text ow   \n776 they were calculated and reference the corresponding figures or tables in the text.   \n777 8. Experiments Compute Resources   \n778 Question: For each experiment, does the paper provide suficient information on the com  \n779 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n780 the experiments?   \n781 Answer: [Yes]   \n782 Justification: We have shown the computer resources for this study in Appendix E.   \n783 Guidelines:   \n784 \u00b7 The answer NA means that the paper does not include experiments.   \n785 \u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n786 or cloud provider, including relevant memory and storage.   \n787 \u00b7 The paper should provide the amount of compute required for each of the individual   \n788 experimental runs as well as estimate the total compute.   \n789 \u00b7 The paper should disclose whether the full research project required more compute   \n790 than the experiments reported in the paper e.g prelminary or failed experiments that   \n791 didn't make it into the paper).   \n792 9. Code Of Ethics   \n793 Question: Does the research conducted in the paper conform, in every respect, with the   \n794 NeurlPS Code of Ethics https ://neurips. cc/public/EthicsGuidelines?   \n795 Answer: [Yes]   \n796 Justification: We have carefully reviewed and followed the NeurIPS Code of Ethics.   \n797 Guidelines:   \n798 \u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n799 \u00b7 If the authors answer No, they should explain the special circumstances that require a   \n800 deviation from the Code of Ethics.   \n801 \u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n802 eration due to laws or regulations in their jurisdiction).   \n803 10. Broader Impacts   \n804 Question: Does the paper discuss both potential positive societal impacts and negative   \n805 societal impacts of the work performed?   \n806 Answer: [Yes]   \n807 Justification: We have described the potential societal impacts of our study in Appendix A.   \n808 Guidelines:   \n809 \u00b7 The answer NA means that there is no societal impact of the work performed.   \n810 \u00b7 If the authors answer NA or No, they should explain why their work has no societal   \n811 impact or why the paper does not address societal impact.   \n812 \u00b7 Examples of negative societal impacts include potential malicious or unintended uses   \n813 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n814 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n815 groups), privacy considerations, and security considerations.   \n816 \u00b7 The conference expects that many papers will be foundational research and not tied   \n817 to particular applications, lt alone deployments. However, if there is a direct path to   \n818 any negative applications, the authors should point it out. For example, it is legitimate   \n819 to point out that an improvement in the quality of generative models could be used to   \n820 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n821 that a generic algorithm for optimizing neural networks could enable people to train   \n822 models that generate Deepfakes faster.   \n823 \u00b7 The authors should consider posible harms that could arise when the technology is   \n824 being used as intended and functioning correctly, harms that could arise when the   \n825 technology is being used as intended but gives incorrect results, and harms following   \n826 from (intentional or unintentional) misuse of the technology.   \n827 \u00b7If there are negative societal impacts, the authors could also discuss possible mitigation   \n828 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n829 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n830 feedback over time, improving the efficiency and accessibility of ML).   \n831 11. Safeguards   \n832 Question: Does the paper describe safeguards that have been put in place for responsible   \n833 releaseof datarmdls tat haveahighrisfrmiuse  rtrand nguage l   \n834 image generators, or scraped datasets)?   \n835 Answer: [NA]   \n836 Justification: There are no such risks associated with the paper.   \n837 Guidelines:   \n838 \u00b7 The answer NA means that the paper poses no such risks.   \n839 \u00b7 Released models that have a high risk for misuse or dual-use should be released with   \n840 necessary safeguards to allow for controlled use of the model, for example by requiring   \n841 that users adhere to usage guidelines or restrictions to access the model or implementing   \n842 safety filters.   \n843 \u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n844 should describe how they avoided releasing unsafe images.   \n845 We recognize that providing effective safeguards is challenging, and many papers do   \n846 not require this, but we encourage authors to take this into account and make a best   \n847 faith effort.   \n848 12. Licenses for existing assets   \n849 Question: Are the creators or original owners of assets (e.g, code, data, models), used in   \n850 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n851 properly respected?   \n852 Answer: [NA]   \n853 Justification: This study does not use existing assets.   \n854 Guidelines:   \n855 \u00b7 The answer NA means that the paper does not use existing assets.   \n856 \u00b7The authors should cite the original paper that produced the code package or dataset.   \n857 \u00b7 The authors should state which version of the asset is used and, if possible, include a   \n858 URL.   \n859 \u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n860 \u00b7 For scraped data from a particular source (e.g, website),the copyright and terms of   \n861 service of that source should be provided.   \n862 \u00b7 If assets are released, the license, copyright information, and terms of use in the   \n863 package houldbe providedoropular datasetspaerswithcodeom/datasets   \n864 has curated licenses for some datasets. Their licensing guide can help determine the   \n865 license of a dataset.   \n866 \u00b7 For existing datasets that are re-packaged, both the original license and the license of   \n867 the derived asset (if it has changed) should be provided.   \n368 \u00b7 If this information is not available online, the authors are encouraged to reach out to   \n369 the asset's creators.   \n370 13. New Assets   \n371 Question: Are new assets introduced in the paper well documented and is the documentation   \n372 provided alongside the assets?   \n373 Answer: [NA]   \n374 Justification: This paper does not release new assets.   \n375 Guidelines:   \n376 \u00b7 The answer NA means that the paper does not release new assets.   \n377 \u00b7 Researchers should communicate the details of the dataset/code/model as part of their   \n378 submissions via structured templates. This includes details about training, license,   \n379 limitations, etc.   \n380 \u00b7 The paper should discuss whether and how consent was obtained from people whose   \n381 asset is used.   \n382 \u00b7 At submission time, remember to anonymize your assets (if applicable). You can either   \n383 create an anonymized URL or include an anonymized zip file.   \n384 14. Crowdsourcing and Research with Human Subjects   \n385 Question: For crowdsourcing experiments and research with human subjects, does the paper   \n386 include the full text of instructions given to participants and screenshots, if applicable, as   \n387 well as details about compensation (if any)?   \n388 Answer: [NA]   \n389 Justification: This paper does not involve crowdsourcing nor research with human subjects.   \n390 Guidelines:   \n391 \u00b0 The answer NA means that the paper does not involve crowdsourcing nor research with   \n392 human subjects.   \n393 \u00b7 Including this information in the supplemental material is fine, but if the main contribu  \n394 tion of the paper involves human subjects, then as much detail as possible should be   \n395 included in the main paper.   \n396 \u00b7 According to the NeurIPS Code of Ethics, workers involved in data collection, curation,   \n397 or other labor should be paid at least the minimum wage in the country of the data   \n398 collector.   \n399 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n300 Subjects   \n301 Question: Does the paper describe potential risks incurred by study participants, whether   \n302 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n303 approvals (or an equivalent approval/review based on the requirements of your country or   \n304 institution) were obtained?   \n305 Answer: [NA]   \n306 Justification: This paper does not involve crowdsourcing nor research with human subjects.   \n307 Guidelines:   \n308 \u00b0 The answer NA means that the paper does not involve crowdsoureing nor research with   \n309 human subjects.   \n310 \u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent)   \n311 may be required for any human subjects research. If you obtained IRB approval, you   \n312 should clearly state this in the paper.   \n313 \u00b7 We recognize that the procedures for this may vary significantly between institutions   \n314 and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the   \n315 guidelines for their institution.   \n316 \u00b7 For initial submissions, do not include any information that would break anonymity (if   \n317 applicable), such as the institution conducting the review. ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}]