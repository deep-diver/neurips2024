[{"figure_path": "xO9GHdmK76/tables/tables_7_1.jpg", "caption": "Table 1: ImageNet classification results. We compare our models with state-of-the-art models with comparable parameters, the Top-1 accuracy is reported on the ImageNet-1K validation set.", "description": "This table presents the ImageNet-1K validation results for various state-of-the-art models and the proposed InfiNet models.  It compares the Top-1 accuracy, number of parameters (in millions), and FLOPs (in billions) for each model.  The models are categorized by the type of feature interaction they utilize (no interaction, finite-order interaction, and infinite-dimensional interaction using the InfiNet approach). This comparison helps to demonstrate the performance gains achieved by InfiNet's infinite-dimensional feature interaction.", "section": "6 Experiments"}, {"figure_path": "xO9GHdmK76/tables/tables_8_1.jpg", "caption": "Table 2: Object detection and semantic segmentation results on MS COCO and ADE20K.", "description": "This table presents a comparison of the performance of different models on object detection and semantic segmentation tasks using the MS COCO and ADE20K datasets.  The models compared include various versions of ConvNeXt, Swin, and HorNet, along with the InfiNet model proposed in the paper.  For each model, the table shows the results in terms of box AP, mask AP, mIoU (mean Intersection over Union), and the number of parameters (Params) and FLOPS (floating-point operations). The results demonstrate the superior performance of InfiNet compared to the baseline models, particularly for the larger models.", "section": "6 Experiments"}, {"figure_path": "xO9GHdmK76/tables/tables_8_2.jpg", "caption": "Table 3: More Results on isotropic models and different kind of Reproducing Kernel", "description": "This table presents the results of experiments conducted using isotropic models and different reproducing kernels.  It compares the performance of various models (ConvNeXt-S, Conv2Former, DeiT-S, HorNet-S, and InfiNet-S) with different interaction orders (none, 2, 3, 2-5, and infinity).  The ablation study section focuses on the InfiNet architecture, testing the impact of changing the kernel's order (none, 2, 4, and 6) on performance, and comparing it against the original InfiNet-T model.  Both sections report the parameters (M), FLOPs (G), and Top-1 accuracy (%).", "section": "6 Experiments"}, {"figure_path": "xO9GHdmK76/tables/tables_12_1.jpg", "caption": "Table 4: Training details for ImageNet-1K experiments", "description": "This table details the training configurations used for the ImageNet-1K experiments in the paper. It lists various hyperparameters, optimization techniques, data augmentation strategies, and regularization methods employed during training.", "section": "A.1 Training Details"}, {"figure_path": "xO9GHdmK76/tables/tables_12_2.jpg", "caption": "Table 1: ImageNet classification results. We compare our models with state-of-the-art models with comparable parameters, the Top-1 accuracy is reported on the ImageNet-1K validation set.", "description": "This table compares the performance of the proposed InfiNet models with several state-of-the-art models on the ImageNet-1K dataset.  It shows the Top-1 accuracy, the number of model parameters (in millions), and the number of floating point operations (in billions). The table is divided into two sections: models trained only on ImageNet-1K and models pre-trained on ImageNet-21K and then fine-tuned on ImageNet-1K.  For each model, the table indicates whether it uses interaction of orders 0, 2, 3, 2-5, 4, or infinite, highlighting the impact of different interaction mechanisms on performance.", "section": "6 Experiments"}]