[{"figure_path": "bIFHHf2RoD/figures/figures_1_1.jpg", "caption": "Figure 1: CulturePark is an LLM-based multi-agent communication platform for cultural data collection. Leveraging CulturePark, we can collect a cross-cultural dialogue dataset, which can then be used for fine-tuning culturally specific LLMs to be applied to different downstream tasks: content moderation, cultural alignment, and cultural education.", "description": "This figure illustrates the CulturePark framework. It shows how multiple LLMs, each representing a different culture, interact to generate a cross-cultural dialogue dataset. This dataset is then used to fine-tune culture-specific LLMs for downstream applications such as content moderation, cultural alignment, and cultural education.  The diagram visually represents the multi-agent communication process, highlighting the diverse cultural backgrounds of the agents and the resulting dataset's application in improving LLMs' cross-cultural understanding.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_5_1.jpg", "caption": "Figure 2: Cross-cultural dialogue and data refinement for fine-tuning LLMs using CulturePark.", "description": "This figure shows the process of generating a cross-cultural dialogue dataset using CulturePark and refining it for fine-tuning. (a) illustrates the multi-agent communication platform where agents from different cultures engage in discussions.  (b) details the refinement process: extracting opinions, verifying factual accuracy, and removing redundancy to create a high-quality dataset for fine-tuning LLMs.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_6_1.jpg", "caption": "Figure 3: Results on content moderation.", "description": "This radar chart visualizes the performance of different LLMs on seven content moderation tasks across eight cultures.  Each axis represents a different task (hate, offensive, abusive, bias, spam, threat, stance), and each point on the axis represents the F1 score achieved by a specific model in a given culture. The models compared include GPT-3.5, GPT-4, Gemini, CultureLLM, and two versions of the CulturePark model (fine-tuned with GPT-3.5 and GPT-4).  The chart allows for a direct comparison of the relative strengths and weaknesses of each model across diverse cultural contexts and downstream tasks.", "section": "4.1 Evaluation on content moderation tasks"}, {"figure_path": "bIFHHf2RoD/figures/figures_7_1.jpg", "caption": "Figure 4: Results on culture alignment via Hofstede's Cultural Dimensions Theory.", "description": "This figure compares the cultural alignment of models (powered by GPT-3.5-Turbo) with GPT-3.5-turbo and GPT-4 using Hofstede's Cultural Dimensions Theory.  The Euclidean distance between the model's answers and Hofstede's data across six cultural dimensions (Power Distance Index (PDI), Individualism vs. Collectivism (IDV), Masculinity vs. Femininity (MAS), Uncertainty Avoidance Index (UAI), Long-Term Orientation vs. Short-Term Orientation (LTO), and Indulgence vs. Restraint (IND)) is shown for eight different cultures (Arabic, Bengali, Chinese, German, Korean, Portuguese, Spanish, and Turkish).  The results indicate the GPT-3.5-Turbo-based models outperform both GPT-3.5-turbo and GPT-4 across all cultures, demonstrating better cultural alignment.", "section": "4.2 Evaluation on cultural alignment via Hofstede's Cultural Dimensions Theory"}, {"figure_path": "bIFHHf2RoD/figures/figures_8_1.jpg", "caption": "Figure 5: More discussions on CulturePark.", "description": "This figure presents a comparative analysis of CulturePark against other methods in three aspects. (a) shows the benefits of cross-cultural communication in CulturePark compared to directly generating data using GPT models for content moderation. (b) illustrates the diversity gain achieved by CulturePark compared to CultureLLM. (c) demonstrates the impact of cultural background and gender on the quality of generated data. (d) showcases the performance of various models on the BIG-Bench Hard benchmark. The results show that CulturePark's approach leads to improved results in cultural understanding and alignment compared to other techniques.", "section": "5 Discussion"}, {"figure_path": "bIFHHf2RoD/figures/figures_8_2.jpg", "caption": "Figure 3: Results on content moderation.", "description": "The radar chart compares the performance of the CulturePark models with other baselines on content moderation tasks across different cultures. The results show that the CulturePark models outperform GPT-4 on five cultures and approach GPT-4's performance on the remaining three cultures. This demonstrates the effectiveness of the CulturePark framework in generating high-quality cross-cultural data for fine-tuning LLMs.", "section": "4.1 Evaluation on content moderation tasks"}, {"figure_path": "bIFHHf2RoD/figures/figures_16_1.jpg", "caption": "Figure 1: CulturePark is an LLM-based multi-agent communication platform for cultural data collection. Leveraging CulturePark, we can collect a cross-cultural dialogue dataset, which can then be used for fine-tuning culturally specific LLMs to be applied to different downstream tasks: content moderation, cultural alignment, and cultural education.", "description": "This figure illustrates the CulturePark framework, which uses multiple large language models (LLMs) to simulate cross-cultural conversations.  These conversations generate a dataset used to fine-tune culture-specific LLMs for applications such as content moderation, cultural alignment, and cultural education.  The diagram shows the different agents representing various cultures, the dialogue generation process, and the downstream applications of the fine-tuned LLMs.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_17_1.jpg", "caption": "Figure 8: After multi-turn communications, we get a cross-cultural dialogues dataset (CCD), which involves data on 8 different cultures. CCD contains human belief (59.68%), norm (29.54%), and custom (10.78%).", "description": "This figure is a pie chart that shows the distribution of topics in the cross-cultural dialogue dataset generated by CulturePark.  The dataset contains data from 8 different cultures and is categorized into three main topics: human belief, norm, and custom.  Human belief is further broken down into religious, social, and ethical beliefs. Norm is broken down into descriptive, prescriptive, and traditional norms. Custom is further categorized into social, family, and community customs. The percentages shown represent the proportion of each category in the overall dataset.", "section": "B Details on the cross-cultural dialogue"}, {"figure_path": "bIFHHf2RoD/figures/figures_25_1.jpg", "caption": "Figure 1: CulturePark is an LLM-based multi-agent communication platform for cultural data collection. Leveraging CulturePark, we can collect a cross-cultural dialogue dataset, which can then be used for fine-tuning culturally specific LLMs to be applied to different downstream tasks: content moderation, cultural alignment, and cultural education.", "description": "This figure illustrates the CulturePark framework, an LLM-powered system that simulates cross-cultural communication to collect high-quality cultural data.  Multiple LLMs, each representing a different culture, engage in conversations.  The data collected is then used to train culturally specific LLMs for tasks like content moderation, cultural alignment, and cultural education.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_26_1.jpg", "caption": "Figure 2: Cross-cultural dialogue and data refinement for fine-tuning LLMs using CulturePark.", "description": "This figure shows the process of generating and refining data for fine-tuning large language models (LLMs) using the CulturePark framework.  (a) illustrates the generation of cross-cultural dialogues through multi-agent communication between an English-speaking agent and agents representing different cultures.  (b) details the data refinement process, which involves extracting opinions, performing factual verification, and removing redundancy to improve the quality and diversity of the data.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_26_2.jpg", "caption": "Figure 2: Cross-cultural dialogue and data refinement for fine-tuning LLMs using CulturePark.", "description": "This figure illustrates the process of generating and refining data for training culturally specific LLMs using the CulturePark framework. (a) shows a multi-agent conversation between an English-speaking agent and agents from different cultures. (b) details the data refinement process which includes extracting opinions, verifying their factual accuracy, and removing redundant information to improve data quality and diversity. This refined dataset is then used for fine-tuning the LLMs.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_27_1.jpg", "caption": "Figure 2: Cross-cultural dialogue and data refinement for fine-tuning LLMs using CulturePark.", "description": "This figure shows the process of generating a cross-cultural dialogue dataset and the subsequent refinement of this data for fine-tuning large language models (LLMs).  The left panel (a) illustrates the multi-agent communication framework (CulturePark) that simulates cross-cultural dialogues by having different LLM agents interact, representing diverse cultural viewpoints and backgrounds.  The resulting dialogues are then refined (b) to remove redundancy and ensure factual accuracy via a pipeline involving opinion extraction, factual verification, and redundancy removal (using k-means clustering). The refined dataset is then used for fine-tuning culture-specific LLMs. This figure highlights CulturePark's core functionality: generating diverse and high-quality cross-cultural data for LLM training.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_28_1.jpg", "caption": "Figure 2: Cross-cultural dialogue and data refinement for fine-tuning LLMs using CulturePark.", "description": "This figure shows the process of generating a cross-cultural dialogue dataset using CulturePark and then refining that dataset for fine-tuning LLMs.  (a) illustrates the multi-agent communication process with agents representing different cultures generating a dialogue.  (b) details the refinement steps: extracting opinions from the dialogue, verifying the factual accuracy of these opinions, and removing redundant information to improve dataset diversity.", "section": "3 CulturePark"}, {"figure_path": "bIFHHf2RoD/figures/figures_28_2.jpg", "caption": "Figure 2: Cross-cultural dialogue and data refinement for fine-tuning LLMs using CulturePark.", "description": "This figure shows the process of generating cross-cultural dialogue data using CulturePark and then refining that data for fine-tuning.  The left side (a) illustrates the multi-agent communication platform where agents from different cultures interact. The right side (b) details the data refinement process, which includes opinion extraction, factual verification, and redundancy removal to ensure high-quality data for training culturally specific LLMs.", "section": "3 CulturePark"}]