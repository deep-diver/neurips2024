{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Language models are unsupervised multitask learners", "publication_date": "2019-01-01", "reason": "This paper introduces the concept of language models as unsupervised multitask learners, which is foundational to the approach of using a similar paradigm for image generation."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2022-06-01", "reason": "This paper introduces high-resolution image synthesis using latent diffusion models, which is a key method used in the paper and a major advancement in image generation."}, {"fullname_first_author": "Patrick Esser", "paper_title": "Taming transformers for high-resolution image synthesis", "publication_date": "2021-06-01", "reason": "This paper introduces a method to improve the performance of transformers for high-resolution image synthesis, which is directly relevant to the paper's approach."}, {"fullname_first_author": "Mark Chen", "paper_title": "Generative pretraining from pixels", "publication_date": "2020-07-13", "reason": "This paper introduces generative pre-training from pixels, a fundamental technique used in image generation models."}, {"fullname_first_author": "Huiwen Chang", "paper_title": "Maskgit: Masked generative image transformer", "publication_date": "2022-06-01", "reason": "This paper introduces the MaskGIT model, a masked image modeling approach used in the paper for image generation, and provides a comparison with the proposed method."}]}