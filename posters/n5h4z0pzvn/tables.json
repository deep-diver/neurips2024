[{"figure_path": "N5H4z0Pzvn/tables/tables_8_1.jpg", "caption": "Table 1: Divergence minimization achieves better than or similar accuracy compared to enforcing TB.", "description": "This table presents the average L1 error for each of the five generative tasks (Bayesian phylogenetic inference, sequence generation, set generation, Gaussian mixtures, and banana-shaped distribution) using different loss functions (TB, Reverse KL, Forward KL, Renyi-alpha, and Tsallis-alpha). The results show that minimizing divergence-based objectives often achieves similar or better accuracy than minimizing the trajectory balance (TB) loss, a commonly used method in GFlowNet training.", "section": "5.2 Assessing convergence speed"}]