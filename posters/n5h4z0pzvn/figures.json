[{"figure_path": "N5H4z0Pzvn/figures/figures_4_1.jpg", "caption": "Figure 1: Mode-seeking (\u03b1 = 2) versus mass-covering (\u03b1 = -2) behaviour in \u03b1-divergences.", "description": "This figure illustrates how the choice of the \u03b1 parameter in Renyi-\u03b1 and Tsallis-\u03b1 divergences affects the learning dynamics of GFlowNets.  Specifically, it shows early-stage training results for sampling from a homogeneous mixture of Gaussian distributions.  When \u03b1 is large and negative (\u03b1 = -2), the GFlowNet covers the target distribution's modes broadly.  Conversely, a large positive \u03b1 (\u03b1 = 2) causes the model to focus on a single high-probability region. An intermediate value of \u03b1 = 0.5 achieves the most accurate approximation of the target distribution.", "section": "Divergence measures for learning GFlowNets"}, {"figure_path": "N5H4z0Pzvn/figures/figures_5_1.jpg", "caption": "Figure 2: Variance of the estimated gradients as a function of the trajectories' batch size. Our control variates greatly reduce the estimator's variance, even for relatively small batch sizes.", "description": "This figure shows how the variance of estimated gradients changes with the batch size of trajectories used in training GFlowNets.  The results compare gradient estimation with and without the use of control variates (CVs).  It demonstrates that incorporating CVs significantly reduces the variance, especially noticeable in smaller batch sizes, leading to more stable and efficient training.", "section": "Control variates for low-variance gradient estimation"}, {"figure_path": "N5H4z0Pzvn/figures/figures_7_1.jpg", "caption": "Figure 3: Divergence-based learning objectives often lead to faster training than TB loss. Notably, contrasting with the experiments of [56], there is no single best loss function always conducting to the fastest convergence rate, and minimizing well-known divergence measures is often on par with or better than minimizing the TB loss in terms of convergence speed. Results were averaged across three different seeds. Also, we fix \u03b1 = 0.5 for both Tsallis-\u03b1 and Renyi-\u03b1 divergences.", "description": "This figure compares the convergence speed of different divergence-based learning objectives against the trajectory balance (TB) loss for training GFlowNets on various generative tasks.  The results show that while there isn't a single best-performing loss function across all tasks, divergence-based methods frequently achieve comparable or faster convergence compared to the TB loss. The average results across multiple random seeds are presented for each task and loss function, with \u03b1 fixed at 0.5 for Tsallis-\u03b1 and Renyi-\u03b1 divergences.", "section": "5.2 Assessing convergence speed"}, {"figure_path": "N5H4z0Pzvn/figures/figures_8_1.jpg", "caption": "Figure 4: Average reward for the K highest scoring samples (top-K) and Number of Modes found during training for the tasks of sequence design, set generation, hypergrid and DAG environments. With the only exception of the hypergrid task, the minimization of divergence-based measures leads to similar and often faster discovery of high-valued states relatively to their balance-based counterparts.", "description": "This figure compares the performance of different loss functions (divergence-based vs balance-based) in four different generative tasks: sequence generation, set generation, hypergrid navigation and directed acyclic graph (DAG) generation.  It plots two key metrics: the average reward of the top K samples and the number of modes discovered during training. The results show that divergence-based losses generally lead to faster discovery of high-reward states and a larger number of modes, except in the hypergrid task.", "section": "5.2 Assessing convergence speed"}, {"figure_path": "N5H4z0Pzvn/figures/figures_8_2.jpg", "caption": "Figure 5: Learned distributions for the banana-shaped target. Tsallis-a, Renyi-a and for. KL leads to a better model than TB and Rev. KL, which behave similarly - as predicted by Proposition 1.", "description": "This figure compares the learned distributions for different divergence measures (TB, Tsallis-\u03b1, Renyi-\u03b1, Reverse KL, Forward KL) against the target banana-shaped distribution.  The heatmaps visually represent the probability density of the learned distributions. It shows that Tsallis-\u03b1, Renyi-\u03b1, and Forward KL yield better approximations compared to TB and Reverse KL, aligning with the theoretical prediction of Proposition 1.", "section": "5.2 Assessing convergence speed"}, {"figure_path": "N5H4z0Pzvn/figures/figures_9_1.jpg", "caption": "Figure 6: Learning curves for different objective functions in the task of set generation. The reduced variance of the gradient estimates notably increases training stability and speed.", "description": "This figure compares the learning curves for different divergence measures (forward KL, reverse KL, Renyi-a, Tsallis-a) with and without control variates (CVs) in the set generation task. It demonstrates that using CVs significantly reduces the variance of gradient estimates, leading to more stable and faster training convergence for all divergence measures.", "section": "5.3 Reducing the variance of the estimated gradients"}, {"figure_path": "N5H4z0Pzvn/figures/figures_22_1.jpg", "caption": "Figure 3: Divergence-based learning objectives often lead to faster training than TB loss. Notably, contrasting with the experiments of [56], there is no single best loss function always conducting to the fastest convergence rate, and minimizing well-known divergence measures is often on par with or better than minimizing the TB loss in terms of convergence speed. Results were averaged across three different seeds. Also, we fix a = 0.5 for both Tsallis-a and Renyi-a divergences.", "description": "This figure compares the convergence speed of different divergence-based learning objectives against the trajectory balance (TB) loss for training GFlowNets.  The results show that while there's no single best objective, divergence-based methods generally converge faster or comparably to TB loss across various generative tasks. The average results over multiple runs are plotted for each objective and task.", "section": "5.2 Assessing convergence speed"}, {"figure_path": "N5H4z0Pzvn/figures/figures_22_2.jpg", "caption": "Figure 1: Mode-seeking (\u03b1 = 2) versus mass-covering (\u03b1 = -2) behaviour in \u03b1-divergences.", "description": "This figure illustrates how the choice of the \u03b1 parameter in Renyi-\u03b1 and Tsallis-\u03b1 divergences affects the learning dynamics of GFlowNets.  The figure shows heatmaps representing learned distributions for different \u03b1 values (-2, -1, 0.5, 2) alongside the target distribution.  A large negative \u03b1 causes the model to broadly cover the target distribution's mass, while a large positive \u03b1 results in the model focusing on a single high-probability mode.  An intermediate value (\u03b1=0.5) provides the most accurate approximation of the target.", "section": "3 Divergence measures for learning GFlowNets"}, {"figure_path": "N5H4z0Pzvn/figures/figures_22_3.jpg", "caption": "Figure 3: Divergence-based learning objectives often lead to faster training than TB loss. Notably, contrasting with the experiments of [56], there is no single best loss function always conducting to the fastest convergence rate, and minimizing well-known divergence measures is often on par with or better than minimizing the TB loss in terms of convergence speed. Results were averaged across three different seeds. Also, we fix \u03b1 = 0.5 for both Tsallis-\u03b1 and Renyi-\u03b1 divergences.", "description": "This figure compares the training speed of GFlowNets using different loss functions: reverse KL divergence, KL divergence, Renyi-\u03b1 divergence, Tsallis-\u03b1 divergence, trajectory balance (TB) loss, and detailed balance (DB) loss.  The results show that divergence-based losses often lead to faster convergence than TB loss, although there's no single best loss function for all tasks.  The results were averaged across multiple trials to account for variability.", "section": "5.2 Assessing convergence speed"}]