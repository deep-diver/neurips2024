[{"figure_path": "ncqauwSyl5/tables/tables_7_1.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents a comparison of the mean absolute errors (MAE) for energy and forces predicted by different machine learning models on seven large molecules from the MD22 dataset.  The models compared include various geometric graph neural networks (GNNs) with and without the proposed Neural P\u00b3M enhancement. The table highlights the best performing model for each molecule and metric (energy and force).  The diameter of each molecule is also provided as a contextual factor.", "section": "4.3 MD22"}, {"figure_path": "ncqauwSyl5/tables/tables_8_1.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents a comparison of the mean absolute errors (MAE) for energy and forces predicted by different models on seven large molecules from the MD22 dataset.  The models compared include ViSNet, SGDML, SO3KRATES, Allegro, Equiformer, MACE, baseline Ewald summation, LSRM, and the proposed Neural P\u00b3M.  The table highlights the best-performing model for each molecule and metric (energy and force). The diameters of the molecules are also provided for context.", "section": "4.3 MD22"}, {"figure_path": "ncqauwSyl5/tables/tables_8_2.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents a comparison of the mean absolute errors (MAE) for energy and forces predicted by several state-of-the-art models on seven large molecules from the MD22 dataset.  The models include ViSNet, SGDML, SO3KRATES, Allegro, Equiformer, MACE, Ewald, LSRM, and Neural P\u00b3M. The table highlights the best-performing model for each molecule and metric (energy and force).  The diameter of each molecule is also included, indicating that larger molecules pose a more significant challenge to these models.", "section": "4.3 MD22"}, {"figure_path": "ncqauwSyl5/tables/tables_12_1.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents a comparison of the mean absolute errors (MAE) for energy and forces predicted by different models on seven large molecules from the MD22 dataset.  The models compared include ViSNet, SGDML, SO3KRATES, Allegro, Equiformer, MACE, Baseline Ewald, LSRM, and Neural P\u00b3M. The table highlights the best-performing model for each molecule and metric (energy and force). The diameter of each molecule is also provided to give context to the results.", "section": "4.3 MD22"}, {"figure_path": "ncqauwSyl5/tables/tables_18_1.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents a comparison of the mean absolute errors (MAE) for energy and forces predicted by different models on seven large molecules from the MD22 dataset.  The models compared include ViSNet, SGDML, SO3KRATES, Allegro, Equiformer, and MACE, along with baselines using Ewald summation and LSRM.  The table highlights the best-performing model for each molecule and metric (energy and forces), showing the effectiveness of the Neural P\u00b3M framework in improving accuracy.", "section": "4.3 MD22"}, {"figure_path": "ncqauwSyl5/tables/tables_18_2.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents a comparison of the mean absolute errors (MAE) for energy and forces predicted by various state-of-the-art models on seven large molecules from the MD22 dataset.  The models compared include ViSNet, SGDML, SO3KRATES, Allegro, Equiformer, MACE, and ViSNet integrated with Neural P\u00b3M (baseline).  The table highlights the best performing model for energy and force prediction for each molecule, demonstrating the superior performance of Neural P\u00b3M in most cases.", "section": "4.3 MD22"}, {"figure_path": "ncqauwSyl5/tables/tables_19_1.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents the mean absolute errors (MAE) for energy and forces predicted by several state-of-the-art models and the proposed Neural P\u00b3M model on seven large molecules from the MD22 dataset.  The results are compared to show that Neural P\u00b3M achieves the best performance on most of the molecules, particularly on the larger ones, highlighting its ability to accurately model long-range interactions.", "section": "4.3 MD22"}, {"figure_path": "ncqauwSyl5/tables/tables_20_1.jpg", "caption": "Table 1: Mean absolute errors (MAE) of energy (kcal/mol) and forces (kcal/mol/\u00c5) for seven large molecules on MD22 compared with state-of-the-art models. The best one in each category is highlighted in bold.", "description": "This table presents a comparison of the mean absolute errors (MAE) in energy and force predictions for seven large molecules from the MD22 dataset.  It compares the performance of the ViSNet model enhanced with Neural P\u00b3M against several state-of-the-art methods (SGDML, SO3KRATES, Allegro, Equiformer, and MACE).  The best performing method for each molecule (energy and force) is highlighted in bold, showcasing the effectiveness of the Neural P\u00b3M enhancement.", "section": "4.3 MD22"}]