[{"figure_path": "tFB5SsabVb/figures/figures_3_1.jpg", "caption": "Figure 1: Left two: Trajectories of a non-interacting system and an interacting system (using interaction matrix A), under the same initial conditions. Right two: Replica of the left two systems but the initial conditions are changed. Trajectories change on the rightmost plot.", "description": "This figure visually demonstrates the key difference between interacting and non-interacting systems.  The left two panels show trajectories for three variables in a system, once with no interaction (A = 0, the zero matrix) and once with interaction (A is a specified adjacency matrix). The same initial conditions are used in both scenarios. The rightmost two panels repeat the experiment, but with different initial conditions.  This highlights how the trajectories change significantly in the presence of interaction when different initial conditions are used, whereas there's no such change in the non-interacting case. This illustrates the impact of systemic interaction on the overall system dynamics.", "section": "DAG-Based ODE as Continuous-Time Models"}, {"figure_path": "tFB5SsabVb/figures/figures_6_1.jpg", "caption": "Figure 2: Comparison with neural flow for forecasting on synthetic systems. (ResNet flow).", "description": "This figure compares the performance of neural flows and GNeuralFlow (with both learned and true graphs) on forecasting tasks across four synthetic datasets (Sink, Triangle, Sawtooth, and Square).  Each dataset represents a system of interacting time series with a varying number of nodes (3 to 30). The plot shows that GNeuralFlow consistently outperforms standard neural flows in terms of Mean Squared Error (MSE), demonstrating the benefit of incorporating systemic interactions through graph-based modeling.", "section": "5.1 Synthetic Systems"}, {"figure_path": "tFB5SsabVb/figures/figures_7_1.jpg", "caption": "Figure 3: Graph learning quality and forecast quality. Top two rows: Sink (20 nodes); bottom row: all four datasets (20 nodes).", "description": "This figure presents the results of graph learning quality and forecast quality. The top two rows show the results for the 'Sink' dataset with 20 nodes, demonstrating the effects of varying noise levels on the accuracy of graph learning and forecasting. The bottom row displays a summary of the results across all four datasets (Sink, Triangle, Sawtooth, and Square), providing a comparative analysis of graph learning performance and forecast accuracy under different noise conditions. The metrics used for evaluation are True Positive Rate (TPR), False Discovery Rate (FDR), False Positive Rate (FPR), and Structural Hamming Distance (SHD).", "section": "5 Experiments"}]