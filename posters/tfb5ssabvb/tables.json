[{"figure_path": "tFB5SsabVb/tables/tables_7_1.jpg", "caption": "Table 1: Comparison with non-graph neural flows/ODE, graph ODE, and other time series methods on synthetic systems (5-node graphs). Best is boldfaced and second-best is highlighted in gray.", "description": "This table presents a comparison of the proposed GNeuralFlow model with various baseline methods on four synthetic time series datasets. The baselines include Neural ODE, neural flows (ResNet, GRU, Coupling), GRU-D, graph ODEs (GDE, LG-ODE, CF-GODE), and graph learning methods (NRI, dNRI). The table shows the Mean Squared Error (MSE) achieved by each method on each dataset. The best performing method for each dataset is shown in boldface, and the second-best method is highlighted in gray.  The results demonstrate the superior performance of GNeuralFlow compared to other methods across various graph structures and complexities.", "section": "5 Experiments"}, {"figure_path": "tFB5SsabVb/tables/tables_8_1.jpg", "caption": "Table 2: Time comparison (in seconds) with neural ODE and neural flows on synthetic systems.", "description": "This table compares the computational time (in seconds) taken by Neural ODE, Neural Flows (ResNet, GRU, Coupling), and GNeuralFlow (ResNet, GRU, Coupling) on four different synthetic datasets (Sink, Triangle, Sawtooth, and Square).  It demonstrates the relative computational efficiency of each method. GNeuralFlow, while more computationally expensive than the corresponding neural flows, is still more efficient than Neural ODE, which uses numerical ODE solvers. The results highlight the trade-off between model complexity and computational cost.", "section": "5 Experiments"}, {"figure_path": "tFB5SsabVb/tables/tables_8_2.jpg", "caption": "Table 1: Comparison with non-graph neural flows/ODE, graph ODE, and other time series methods on synthetic systems (5-node graphs). Best is boldfaced and second-best is highlighted in gray.", "description": "This table presents a comparison of the proposed GNeuralFlow model with several baseline methods on four synthetic time series datasets.  Each dataset represents a system of interacting time series with a known graph structure.  The table shows the Mean Squared Error (MSE) achieved by each method on the forecasting task, broken down by dataset.  The best performing method for each dataset is bolded, and the second-best is highlighted in gray. The methods compared include various neural ODE and flow approaches, along with graph-based ODE methods and other state-of-the-art time series models. The results highlight the superior performance of the proposed GNeuralFlow, demonstrating the benefit of incorporating graph structure and conditional dependencies in the modeling process.", "section": "5 Experiments"}, {"figure_path": "tFB5SsabVb/tables/tables_9_1.jpg", "caption": "Table 1: Comparison with non-graph neural flows/ODE, graph ODE, and other time series methods on synthetic systems (5-node graphs). Best is boldfaced and second-best is highlighted in gray.", "description": "This table compares the performance of GNeuralFlow against various baselines on five synthetic datasets (Sink, Triangle, Sawtooth, and Square) each with a 5-node graph.  The metrics used to evaluate the models are Mean Squared Error (MSE). The table highlights the best performing model (boldfaced) and the second-best performing model (in gray) for each dataset. The baselines include Neural ODE, neural flows with different architectures (ResNet, GRU, Coupling), Graph ODE models (GDE, LG-ODE, CF-GODE), and graph learning methods (NRI, dNRI), and non-graph based GRU model (GRU-D). GNeuralFlow is tested with three different architectures (ResNet, GRU, Coupling) as well, demonstrating improved performance across all datasets compared to the baselines.", "section": "5 Experiments"}, {"figure_path": "tFB5SsabVb/tables/tables_14_1.jpg", "caption": "Table 1: Comparison with non-graph neural flows/ODE, graph ODE, and other time series methods on synthetic systems (5-node graphs). Best is boldfaced and second-best is highlighted in gray.", "description": "This table compares the performance of GNeuralFlow against several baseline methods on four synthetic time series datasets.  The datasets have 5 nodes in their underlying graph structure. Each model's Mean Squared Error (MSE) is reported, with the best performance in bold and the second-best highlighted in gray.  The baseline methods include traditional neural ODE and neural flow approaches, graph-based ODE models (GDE, LG-ODE, CF-GODE), and other time series models such as NRI and dNRI. The table shows that GNeuralFlow significantly outperforms all baselines on all datasets.", "section": "5 Experiments"}, {"figure_path": "tFB5SsabVb/tables/tables_16_1.jpg", "caption": "Table 5: Experiment settings and datasets.", "description": "This table summarizes the settings and datasets used in the paper's experiments.  It includes both synthetic and real-life datasets. For each dataset, it specifies the method used (regression or smoothing), the tasks and metrics evaluated, the number of nodes (n), the number of time points (N), the number of samples, and the train/validation/test split.", "section": "5 Experiments"}, {"figure_path": "tFB5SsabVb/tables/tables_17_1.jpg", "caption": "Table 1: Comparison with non-graph neural flows/ODE, graph ODE, and other time series methods on synthetic systems (5-node graphs). Best is boldfaced and second-best is highlighted in gray.", "description": "This table compares the performance of GNeuralFlow against other methods (Neural ODE, neural flows, graph ODEs, graph learning methods, and a non-graph GRU) on four synthetic datasets (Sink, Triangle, Sawtooth, and Square).  The results show MSE (Mean Squared Error) for each method.  GNeuralFlow consistently outperforms other methods, highlighting the benefits of its graph-based continuous-time approach. The table includes results for various flow architectures within GNeuralFlow and other methods.", "section": "5 Experiments"}]