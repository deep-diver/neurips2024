[{"figure_path": "Q4NWfStqVf/figures/figures_9_1.jpg", "caption": "Figure 1: Cumulative regret (left three, K = 5,10,15) and runtime per round (rightmost one, K = 15) under uniform rewards (first row) and non-uniform rewards (second row) with v0 = 1.", "description": "This figure displays the performance of three different algorithms (UCB-MNL, TS-MNL, and OFU-MNL+) in terms of cumulative regret and runtime per round.  The results are shown for both uniform and non-uniform reward settings, with different assortment sizes (K=5, 10, 15). The left three graphs show cumulative regret for each setting, and the rightmost graph shows runtime per round for K=15. This allows for a direct comparison of the algorithms' performance under various conditions.", "section": "7 Numerical Experiments"}, {"figure_path": "Q4NWfStqVf/figures/figures_54_1.jpg", "caption": "Figure 1: Cumulative regret (left three, K = 5,10,15) and runtime per round (rightmost one, K = 15) under uniform rewards (first row) and non-uniform rewards (second row) with vo = 1.", "description": "This figure shows the cumulative regret and runtime per round for three different assortment sizes (K=5, 10, 15) under both uniform and non-uniform reward settings.  The left three plots display the cumulative regret, while the rightmost plot shows the runtime per round for K=15. The top row represents uniform rewards, and the bottom row represents non-uniform rewards.  The results visually demonstrate the performance of the OFU-MNL+ algorithm compared to UCB-MNL and TS-MNL across different settings.", "section": "7 Numerical Experiments"}, {"figure_path": "Q4NWfStqVf/figures/figures_54_2.jpg", "caption": "Figure 1: Cumulative regret (left three, K = 5,10,15) and runtime per round (rightmost one, K = 15) under uniform rewards (first row) and non-uniform rewards (second row) with v0 = 1.", "description": "This figure presents the comparison results for cumulative regret and runtime per round for three algorithms: UCB-MNL, TS-MNL, and OFU-MNL+. The results are shown for different assortment sizes (K = 5, 10, 15) under both uniform and non-uniform reward settings. The left three plots illustrate the cumulative regret over 3000 rounds, while the rightmost plot displays the runtime per round for K=15.  The results show that OFU-MNL+ consistently outperforms UCB-MNL and TS-MNL in terms of cumulative regret, and maintains a constant runtime per round, unlike the other two algorithms. The figure also visually demonstrates that increasing the assortment size K leads to reduced regret under the uniform reward setting but not under non-uniform rewards.", "section": "Numerical Experiments"}]