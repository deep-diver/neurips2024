{"importance": "This paper is crucial for **reinforcement learning (RL)** researchers and practitioners because it exposes a significant vulnerability\u2014backdoor attacks\u2014that could compromise the safety and reliability of RL systems in real-world applications.  The research highlights the limitations of existing defense mechanisms and proposes a novel, more robust attack framework, significantly advancing the field's understanding of adversarial threats and prompting the development of stronger countermeasures.", "summary": "SleeperNets: A universal backdoor attack against RL agents, achieving 100% success rate across diverse environments while preserving benign performance.", "takeaways": ["Static reward poisoning is insufficient for reliable backdoor attacks in RL.", "A novel \"outer-loop\" threat model and dynamic reward poisoning technique significantly improves attack success and stealth.", "SleeperNets demonstrates superior backdoor attack capabilities compared to existing methods across various environments."], "tldr": "Reinforcement Learning (RL) is increasingly used in safety-critical applications, making its security paramount.  Existing backdoor attacks, a particularly insidious form of attack where malicious code is inserted during training, suffer from limitations such as inability to generalize across different environments. These attacks primarily rely on static reward poisoning, which modifies the rewards during training to force specific actions under particular conditions (triggers). However, static poisoning's effectiveness is limited and easily detectable. \nThis paper introduces SleeperNets, a novel universal backdoor attack that leverages a dynamic reward poisoning strategy within a new \"outer-loop\" threat model.  Unlike previous methods, SleeperNets links the adversary's goals with finding an optimal policy, guaranteeing attack success theoretically.  Experiments across six diverse environments show SleeperNets significantly outperforms existing attacks in terms of success rate and stealth, achieving a 100% success rate while maintaining near-optimal benign performance.", "affiliation": "Khoury College of Computer Sciences, Northeastern University", "categories": {"main_category": "Machine Learning", "sub_category": "Reinforcement Learning"}, "podcast_path": "HkC4OYee3Q/podcast.wav"}