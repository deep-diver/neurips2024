{"importance": "This paper is crucial for researchers working with **large-scale online decision-making problems** where memory is limited. It offers efficient, near-optimal algorithms for Lipschitz bandits, a common framework for such problems, opening avenues for applications in **recommendation systems, online advertising, and other areas** where resource constraints are a major concern. The **O(T) time and O(1) space complexities** of the proposed algorithms significantly improve upon existing methods.", "summary": "New algorithms achieve near-optimal regret in stochastic Lipschitz bandits with bounded memory, using only O(1) arms and O(T) time.", "takeaways": ["Near-optimal regret is achieved in stochastic Lipschitz bandits with limited memory.", "The proposed algorithms use only O(1) arms and have O(T) time complexity.", "Numerical results demonstrate the efficiency of the new algorithms."], "tldr": "Many real-world applications involve sequential decision-making problems with large action spaces, often with limited memory resources. The Lipschitz bandits framework models such scenarios, assuming a relationship between the similarity of actions and their expected rewards. However, previous algorithms for Lipschitz bandits either require storing a large number of arms in memory or suffer from high time complexity. This research addresses this limitation by focusing on the bounded memory stochastic Lipschitz bandits problem, where the algorithm is restricted in how many arms it can store. \nThe researchers propose two novel algorithms that achieve near-optimal regret while significantly improving on time and space complexities. The first, MBUD, uses uniform discretization and an explore-first strategy. The second, MBAD, uses an adaptive discretization strategy. Both algorithms achieve near-optimal regret, with MBAD exhibiting instance-dependent regret bounds. Importantly, both algorithms store only a constant number of arms, achieving almost optimal space complexity of O(1), unlike prior works.  The time complexity is also nearly optimal at O(T). Numerical experiments confirm the efficiency of these algorithms.", "affiliation": "string", "categories": {"main_category": "Machine Learning", "sub_category": "Reinforcement Learning"}, "podcast_path": "SOxxGATGsl/podcast.wav"}