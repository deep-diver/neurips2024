[{"type": "text", "text": "DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hengkang Wang1 Xu Zhang2\u2217 Taihui Li1 Yuxiang Wan1 Tiancong Chen1 Ju Sun1 1Department of Computer Science and Engineering, University of Minnesota {wang9881,lixx5027,wan01530,chen6271,jusun}@umn.edu 2Amazon.com Inc., spongezhang@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Pretrained diffusion models (DMs) have recently been popularly used in solving inverse problems (IPs). The existing methods mostly interleave iterative steps in the reverse diffusion process and iterative steps to bring the iterates closer to satisfying the measurement constraint. However, such interleaving methods struggle to produce final results that look like natural objects of interest (i.e., manifold feasibility) and fit the measurement (i.e., measurement feasibility), especially for nonlinear IPs. Moreover, their capabilities to deal with noisy IPs with unknown types and levels of measurement noise are unknown. In this paper, we advocate viewing the reverse process in DMs as a function and propose a novel plug-in method for solving IPs using pretrained DMs, dubbed DMPlug. DMPlug addresses the issues of manifold feasibility and measurement feasibility in a principled manner, and also shows great potential for being robust to unknown types and levels of noise. Through extensive experiments across various IP tasks, including two linear and three nonlinear IPs, we demonstrate that DMPlug consistently outperforms state-of-the-art methods, often by large margins especially for nonlinear IPs. The code is available at https://github.com/sun-umn/DMPlug. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Inverse problems $(\\mathrm{IPs})$ are prevalent in numerous fields, such as computer vision, medical imaging, remote sensing, and autonomous driving [1\u20134]. The goal of IPs is to recover an unknown object $\\textbf{\\em x}$ from noisy measurements ${\\pmb y}={\\pmb{\\mathcal A}}({\\pmb x})+{\\pmb n}$ , where $\\boldsymbol{\\mathcal{A}}$ is a (possibly nonlinear) forward model and $\\mathbfit{\\Delta}$ denotes the measurement noise. IPs are often ill-posed: typically, even if $\\textit{\\textbf{y}}$ is noiseless, $\\textbf{\\em x}$ cannot be uniquely determined from $\\textit{\\textbf{y}}$ and $\\boldsymbol{\\mathcal{A}}$ . Hence, incorporating prior knowledge on $\\textbf{\\em x}$ is necessary to obtain a reliable estimate of the underlying $\\textbf{\\em x}$ . ", "page_idx": 0}, {"type": "text", "text": "Traditionally, IPs are solved in the regularized data-ftiting framework, often motivated as performing the Maximum a Posterior (MAP) inference: ", "page_idx": 0}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}{\\operatorname*{min}_{x}\\ \\ell(y,A(x))+\\Omega(\\pmb{x})}&{}&{\\ell(y,A(x)):\\mathrm{data\\-fitting\\loss,\\}\\Omega(\\pmb{x}):\\mathrm{regularizer}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 0}, {"type": "text", "text": "Here, minimizing the data-ftiting loss promotes ${\\pmb y}\\approx{\\mathcal A}({\\pmb x})$ , and the regularizer encodes prior knowledge on $\\textbf{\\em x}$ . Recently, the advent of deep learning (DL) has brought about a few new algorithmic ideas to solve IPs. For example, given a training set of measurement-object pairs, i.e., $\\{({\\bar{y_{i}}},{\\bar{x_{i}}})\\}_{i=1,\\dots,N},$ one can hope to train a DL model that directly predicts $\\textbf{\\em x}$ for a given $\\textit{\\textbf{y}}$ [5\u201316]. However, such hopes can be shattered by practical challenges in collecting massive and realistic paired training sets, especially for complex IPs [17, 18]. Even if such challenges can be tackled, one may need to collect a new training set and train a new DL model for every new IP [15], overlooking potential shared priors on $\\textbf{\\em x}$ across IPs. An attractive alternative family of ideas combine pretrained priors on $\\textbf{\\em x}$ and regularized data-fitting in Eq. (1). For example, they first model the distribution of $\\textbf{\\em x}$ using deep generative models, such as generative adversarial networks (GANs) and diffusion models (DMs), based on training sets of the form $\\{\\pmb{x}_{i}\\}_{i=1,...,N}$ , and then encode these pretrained generative priors when solving Eq. (1). In this way, pretrained priors on $\\textbf{\\em x}$ can be reused in an off-the-shelf manner in different IPs about the same family of structured objects. ", "page_idx": 0}, {"type": "image", "img_path": "81IFFsfQUj/tmp/1514c43ef5f480f9182f30a5772332c824d448fb2ffc1a5ac615cc08e99c83c2.jpg", "img_caption": ["Figure 1: Visualization of sample results from our DMPlug method (Ours) and main competing methods (DPS [19] and Resample [20] for super-resolution, inpainting, and nonlinear deblurring; BlindDPS [21] and Stripformer [6] for blind image deblurring (BID) and BID with turbulence) on IPs we focus on in this paper. All measurements contain Gaussian noise with $\\sigma=0.01$ . "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "In this paper, we focus on solving IPs with pretrained DMs. DMs have recently emerged as a dominant family of deep generative models due to their relative stability during training (e.g., vs. GANs) and their strong capabilities to generate photorealistic images (and, depending on applications, other structured objects) once trained [22\u201327]. These strengths of DMs have motivated ideas to use pretrained DMs to solve IPs, such as denoising, superresolution, inpainting, deblurring, and phase retrieval [28, 29, 20, 30\u201333, 21, 26, 27, 34]. Most of these ideas interleave iterative reverse diffusion steps and iterative steps (sometimes projection steps, especially for linear IPs) to move closer to the feasibility set $\\{\\pmb{x}|\\pmb{y}=\\mathcal{A}(\\pmb{x})\\}$ (see Fig. 3 and Fig. 4 (1)). However, they typically cannot guarantee the final convergence of the iteration sequence to either the feasible set (i.e., measurement feasibility), or the object manifold $\\mathcal{M}$ captured by pretrained DMs (i.e., manifold feasibility), as they have modified both iterative processes (see detailed arguments in Section 2). ", "page_idx": 1}, {"type": "image", "img_path": "81IFFsfQUj/tmp/27e1a8029b028d1259f45fdf854b118dee873d6174c42f8e9644115b5fd28ae5.jpg", "img_caption": ["Figure 2: Evolution of the data-fitting loss $\\lVert\\bar{\\pmb{y}}-\\mathcal{A}(\\pmb{x})\\rVert_{2}^{2}$ of our DMPlug method vs. SOTA methods over percentage progress, for noiseless nonlinear deblurring on the CelebA dataset. Here, the percentage progress is calculated with respect to the total number of iterations taken by each method. The shadow regions indicate the ranges of the loss over 50 instances. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Fig. 1 shows visible artifacts produced by these ideas on several IPs, highlighting (Issue 1) insufficient manifold feasibility. To quickly confirm (Issue 2) insufficient measurement feasibility, we experiment on noiseless instances of the nonlinear deblurring problem (a nonlinear IP) following [20, 19], and find that state-of-the-art (SOTA) methods fail to find an $\\textbf{\\em x}$ that satisfies ${\\pmb y}={\\mathcal A}({\\pmb x})$ , as shown in Fig. 2. Furthermore, most SOTA DM-based methods for IPs assume known noise types (e.g., often Gaussian) and known, often very low, noise levels, casting doubts on their performance when faced with unknown noise types and levels, i.e., (Issue 3) robustness to unknown noise types and levels, as we confirm in Table 4. ", "page_idx": 1}, {"type": "image", "img_path": "81IFFsfQUj/tmp/01b81f25cdb691abb99f403c4bfbfd4f7353ef34faaca2645f533c33868c5342.jpg", "img_caption": ["Figure 3: Interleaving methods (left) vs. our DMPlug method (right) for solving IPs using pretrained DMs. While interleaving methods cannot ensure the feasibility of the final estimate for either the object manifold $\\mathcal{M}$ or the feasible set $\\{\\pmb{x}|\\pmb{y}=\\mathcal{A}(\\pmb{x})\\}$ , our DMPlug method ensures the manifold feasibility while promoting ${\\pmb y}\\,\\approx\\,A({\\pmb x})$ through global optimization. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Our contributions In this paper, we propose a novel plug-in method, dubbed DMPlug, to solve IPs with pretrained DMs to mitigate all of the above three issues. DMPlug departs from the popular and dominant interleaving line of ideas by viewing the whole reverse diffusion process as a function $\\mathcal{R}(\\cdot)$ , consisting of multiblock stacked DL models, mapping from the seed space to the object manifold $\\mathcal{M}$ . This novel perspective allows us to naturally parameterize the object to be recovered as $\\pmb{x}=\\mathcal{R}(\\pmb{z})$ and then plug this reparametrization into Eq. (1), leading to a unified optimization formulation with respect to the seed $_{z}$ . Conceptually, since $\\mathcal{R}(z)$ probably produces a feasible point on the object manifold $\\mathcal{M}$ and global optimization of the unified formulation encourages $\\pmb{y}\\approx\\mathcal{A}(\\mathcal{R}(\\pmb{z}))$ , the optimized $_{\\textit{z}}$ could lead to an $\\pmb{x}=\\mathcal{R}(\\pmb{z})$ that enjoys both manifold and measurement feasibility, i.e., (tackling Issues 1 & 2). Fig. 3 and Fig. 4 schematically illustrate the dramatic difference between interleaving methods and our plug-in method (DMPlug), and Figs. 1 and 2 confirms DMPlug\u2019s strong capability in finding feasible solutions. For noisy IPs with unknown noise types and levels, we observe that our DmPlug enjoys a benign \u201cearly-learning-then-overftiting\u201d (ELTO) property: the quality of the estimated object climbs first to a peak and then degrades once the noise is picked up, as shown in Fig. 6 (2). This benign property, in combination with appropriate early-stopping (ES) methods that stop the estimate sequence near the peak, allows our method to solve IPs without the exact noise information, i.e., (tackling Issue 3), as shown in Table 4). Fortunately, we find that an ES method, ES-WMV [35] (co-developed by a subset of the current authors), works well for this purpose (see Table 4). ", "page_idx": 2}, {"type": "text", "text": "Our contributions can be summarized as follows. (1) In Section 3.1, we pioneer a novel plugin method, DMPlug, which is significantly different from the prevailing interleaving methods, to solve IPs with pretrained DMs. Then we make the proposed method practical in terms of computational and memory expenses by leveraging one key observation; (2) In Section 4 and Appendix E, we perform extensive experiments on various linear and nonlinear IPs and show that our method outperforms SOTA methods, both qualitatively and quantitatively\u2014often by large margins, especially on nonlinear IPs. For example, measured in PSNR, our method can lead SOTA methods by about 2dB and $3\\sim6\\mathrm{dB}$ for linear and nonlinear IPs, respectively. Moreover, our method demonstrates flexibility in employing different priors and optimizers, as explored in Section 4.3; (3) In Section 3.3, we observe an early-learning-then-overfitting (ELTO) property, i.e., that our DMPlug tends to recover the desirable object first and then overfit to the potential noise. By taking advantage of this benign property and integrating the ES method ES-WMV [35], our method is the first to achieve robustness to unknown noise types and levels, leading SOTA methods by about 1dB and $3.5\\mathrm{dB}$ in terms of PSNR for linear and nonlinear IPs, respectively. ", "page_idx": 2}, {"type": "text", "text": "2 Background and related work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Diffusion models (DMs) The denoising diffusion probabilistic model (DDPM) [23] is a seminal DM for unconditional image generation. It gradually transforms $x_{0}\\sim p_{\\mathrm{data}}$ into total noise $x_{T}\\sim$ $\\mathcal{N}(\\mathbf{0},\\boldsymbol{I})$ (i.e., forward diffusion process) and then learns to gradually recover $\\scriptstyle{x_{0}}$ from ${\\mathbf{}}x_{T}$ through ", "page_idx": 2}, {"type": "text", "text": "incremental denoising (i.e., reverse diffusion process). The f\u221aorward process can be described by a stochastic differential equation (SDE), $d{\\pmb x}=\\dot{-}\\beta_{t}/2\\cdot{\\pmb x}d t+\\sqrt{\\beta_{t}}d{\\pmb w}$ , where $\\beta_{t}$ is the noise schedule and $\\pmb{w}$ is the standard Wiener process. The corresponding reverse process is described by ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\left({\\mathrm{Reverse~SDE~for~DDPM}}\\right)\\,d x=-\\beta_{t}\\left[x/2+\\nabla_{x}\\log p_{t}(x)\\right]d t+{\\sqrt{\\beta_{t}}}d{\\overline{{w}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, $\\overline{{\\pmb{w}}}$ is the time-reversed standard Wiener process, $p_{t}(\\pmb{x})$ is the probability density at time $t$ , and $\\nabla_{\\pmb{x}}\\log p_{t}(\\pmb{x})$ is the (Stein) score function, which is approximated by a DL model ${\\pmb\\varepsilon}_{\\pmb\\theta}^{(t)}({\\pmb x})$ via score matching methods during DM training [36, 37]. For discrete settings, given time steps $\\bar{t}\\in\\{1,\\ldots,T\\}$ , a variance schedule $\\beta_{1},\\ldots,\\beta_{T}$ , $\\alpha_{t}\\doteq1-\\beta_{t}$ with $\\alpha_{T}\\rightarrow0$ , and $\\begin{array}{r}{\\bar{\\alpha}_{t}\\doteq\\prod_{s=1}^{t}\\alpha_{s}}\\end{array}$ , the DDPM has the forward process $\\pmb{x}_{t}=\\sqrt{1-\\beta_{t}}\\pmb{x}_{t-1}+\\sqrt{\\beta_{t}}z$ and the reverse process ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{(DDPM)}\\;x_{t-1}=1/\\sqrt{\\alpha_{t}}\\cdot\\Big(x_{t}-\\beta_{t}/\\sqrt{1-\\bar{\\alpha}_{t}}\\cdot\\varepsilon_{\\theta}^{(t)}(x_{t})\\Big)+\\sqrt{\\beta_{t}}z,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $z\\sim\\mathcal{N}(\\mathbf{0},I)$ . As the DDPM has a slow reverse/sampling process, [24] proposes the denoising diffusion implicit model (DDIM) to mitigate this issue. With the same notation as that of the DDPM, the DDIM makes a crucial change to the DDPM: relaxing the forward process to be non-Markovian by making $\\pmb{x}_{t}$ depend on both $\\scriptstyle x_{0}$ and $x_{t-1}$ . This simple change allows skipping iterative steps in the reverse process, without retraining the DDPM. This leads to much smaller numbers of reverse steps, and hence substantial speedup in sampling. The reverse process is now defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\left(\\mathrm{DDIM}\\right)x_{t-1}\\!=\\!\\sqrt{\\bar{\\alpha}_{t-1}}\\widehat{x}_{0}(x_{t})\\!+\\!\\sqrt{1-\\bar{\\alpha}_{t-1}}\\varepsilon_{\\theta}^{(t)}(x_{t}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\widehat{\\pmb{x}}_{0}(\\pmb{x}_{t})\\doteq[\\pmb{x}_{t}-\\sqrt{1-\\bar{\\alpha}_{t}}\\pmb{\\varepsilon}_{\\pmb{\\theta}}^{(t)}(\\pmb{x}_{t})]/\\sqrt{\\bar{\\alpha}_{t}}$ is the predicted $\\pmb{x}_{0}$ with $\\pmb{x}_{t}$ ", "page_idx": 3}, {"type": "text", "text": "Pretrained DMs for solving IPs Ideas for solving IPs with DMs can be classified into two categories: supervised and zero-shot [31, 38]. The former trains DM-based $\\mathrm{IP}$ solvers based on paired training sets of the form $\\{(y_{i},\\pmb{x}_{i})\\}$ and is hence not our focus here (see our arguments in Section 1). The latter makes use of pretrained DMs as data-driven priors: (I) Most of the work in this category considers modeling $p_{t}(\\pmb{x}|\\pmb{y})$ directly and replaces the (unconditional) score function $\\nabla_{\\pmb{x}}\\log p_{t}(\\bar{\\pmb{x}})$ in Eq. (2) by the conditional score function $\\nabla_{x}\\log p_{t}(\\pmb{x}|\\pmb{y})=\\nabla_{x}\\log p_{t}(\\pmb{x})+\\nabla_{x}\\log p_{t}(\\pmb{y}|\\pmb{x})$ , leading to the conditional reverse SDE ", "page_idx": 3}, {"type": "equation", "text": "$$\nd\\pmb{x}=[-\\beta_{t}/2\\cdot\\pmb{x}-\\beta_{t}(\\nabla_{\\pmb{x}}\\log p_{t}(\\pmb{x})+\\nabla_{\\pmb{x}}\\log p_{t}(\\pmb{y}|\\pmb{x}))]\\,d t+\\sqrt{\\beta_{t}}d\\pmb{\\overline{{{w}}}}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, while $\\nabla_{\\pmb{x}}\\log p_{t}(\\pmb{x})$ can be naturally approximated by the pretrained score function ${\\pmb\\varepsilon}_{\\pmb\\theta}^{(t)}({\\pmb x})$ $\\nabla_{x}\\log p_{t}({\\pmb y}|{\\pmb x})$ is intractable as $\\textit{\\textbf{y}}$ does not directly depend on ${\\mathbf{}}x(t)^{2}$ . Ideas to circumvent this difficulty include approximating $p_{t}(\\pmb{y}|\\pmb{x}(t))$ by $p_{t}({\\pmb y}|\\widehat{{\\pmb x}}(0)[{\\pmb x}(t)])$ , where ${\\widehat x}(0)[{\\pmb x}(t)]$ is implemented as $\\widehat{\\pmb{x}}_{0}(\\pmb{\\bar{x}}_{t})$ of Eq. (4) in discretization [19, 21], and  interleaving unco  nditional reverse steps of Eq. (3) or Eq. (4) and (approximate) projections onto the feasible set $\\{\\pmb{x}|\\pmb{y}=\\mathcal{A}(\\pmb{x})\\}$ to bypass the likelihood $p_{t}(\\pmb{y}|\\pmb{x})$ [39, 30, 33, 32, 40, 41, 20]; $(\\mathbf{II})$ An interesting alternative is to recall that the MAP framework (see also Eq. (1)) involves $\\mathrm{max}_{x}$ $\\log p({\\pmb y}|{\\pmb x})+\\log p({\\pmb x})$ , and first-order methods, especially proximal-gradient style methods, to optimize the MAP formulation typically only need to access $p(x)$ through $\\nabla_{\\mathbf{x}}\\log{p(\\mathbf{x})}$ , i.e., the score function\u2014the central object in DMs! So, one can derive $\\boldsymbol{\\mathrm{IP}}$ solvers by wrapping pretrained DMs around first-order methods for (approximately) optimizing the MAP formulation, see, e.g., [27, 28]. ", "page_idx": 3}, {"type": "text", "text": "Despite the disparate conceptual ways of utilizing pretrained DM priors, most of the methods under $\\mathbf{\\rho}(\\mathbf{I})$ and $(\\mathbf{II})$ proposed in the literature so far follow a single algorithmic template, i.e., Algorithm 1. There, Lines 3-5 are simply a reverse iterative step in the DDIM (Eq. (4); obviously, one could replace this by a reverse iterative step in other appropriate pretrained DMs. Line 6 helps move the iterate closer or onto the feasible set $\\{{\\pmb x}|{\\pmb y}={\\mathcal A}({\\bar{\\pmb x}})\\}$ . In other words, these methods interleave iterative steps to move toward the data manifold $\\mathcal{M}$ defined by the pretrained DM and iterative steps to move toward the feasible set $\\{\\pmb{x}|\\pmb{y}=\\mathcal{A}(\\pmb{x})\\}$ , i.e., as illustrated in Fig. 3 (left). However, it is unclear, a priori, whether such interleaving iterative sequence will converge to either, leading to concerns about (Issue 1) insufficient manifold feasibility and (Issue 2) insufficient measurement feasibility. In fact, our Figs. 1 and 2 confirm these issues empirically, echoing observations made in several prior papers [20, 42, 30]. In principle, Issue 2 can be mitigated by ensuring that Line 6 finds a feasible ", "page_idx": 3}, {"type": "image", "img_path": "81IFFsfQUj/tmp/9680921f628c373aec640d8fbfd0b9b8babf698a08e87d236b5b0fa66c2c39e4.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Figure 4: Comparison of prevailing interleaving methods and our plug-in method $x_{i-1}$ for $\\{\\pmb{x}|\\pmb{y}=\\mathcal{A}(\\pmb{x})\\}$ in each iteration [39, 30, 33, 32, 40, 41, 20]. However, this is possible only for easy IPs (e.g., linear IPs where we can perform a closed-form projection) and is difficult for typical nonlinear IPs as hard nonconvex problems are entailed. Moreover, although most of these methods have considered noisy IPs alongside noiseless ones [39, 30, 33, 32, 20, 28, 19, 21, 29], their common assumption about known noise types (often Gaussian) and levels (often low) is unrealistic: there are many types of measurement noise in practice\u2014often hybrid from multiple sources [43], and the noise levels are usually unknown and hard to estimate [44], raising concerns about (Issue 3) the robustness of these methods to unknown noise types and levels; see Section 4.2. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "3 Method ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we propose a simple plug-in method, DMPlug, to solve IPs with pretrained DMs to address Issues 1 & 2 in Section 3.1, discuss its connection to and difference from several familiar ideas in Section 3.2, and finally explain how to integrate an early-stopping strategy, ES-WMV [35], into our plug-in method to address Issue 3 in Section 3.3, leading to an algorithm, DMPlug+ES-WMV, summarized in Algorithm 3, that solves IPs with pretrained DMs under the regularized data-fitting framework Eq. (1), even in the presence of unknown noise. ", "page_idx": 4}, {"type": "text", "text": "3.1 Our plug-in method: DMPlug ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Reverse process as a function and our plug-in method Interleaving methods discussed above can have trouble satisfying both manifold feasibility and measurement feasibility because they interleave and hence modify both processes. Although projection-style modifications can improve measurement feasibility [39, 30, 33, 32, 40, 41, 20], their application to nonlinear IPs seems tricky, and a single \u201cprojection\u201d step could be as difficult and expensive as solving the original problem due to the typical nonconvexity induced by the nonlinearity in $\\boldsymbol{\\mathcal{A}}$ [28, 20]. In contrast, we propose viewing the whole reverse process as a function $\\mathcal{R}(\\cdot)$ that maps from the seed space to the object space (or the object manifold M). Mathematically, if we write a single inverse step as a function g that depends on \u03b5(\u03b8i ), i.e., $g_{\\varepsilon_{\\pm}^{(i)}}$ for the $i$ -th reverse step that maps $x_{i+1}$ to $\\pmb{x}_{i}$ , then ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{R}=g_{\\varepsilon_{\\theta}^{(0)}}\\circ g_{\\varepsilon_{\\theta}^{(1)}}\\circ\\cdot\\cdot\\cdot\\circ g_{\\varepsilon_{\\theta}^{(T-2)}}\\circ g_{\\varepsilon_{\\theta}^{(T-1)}}.\\qquad\\mathrm{(\\o~means~function~composition)}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that for the DDPM, and those DMs based on SDEs in general, $\\mathcal{R}$ is a stochastic function due to noise injection in each step. To reduce technicality, we focus on DMs based on ordinary differential equations (ODEs), in particular, the DDIM, due to their increasing popularity [45, 46], resulting in deterministic $\\mathcal{R}$ \u2019s. This conceptual leap allows us to reparametrize our object of interest as $\\pmb{x}=\\mathcal{R}(\\pmb{z})$ and plug this reparametrization into the traditional regularized data-fitting framework in Eq. (1), yielding the following unified optimization formulation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbf{D}\\mathbf{M}\\mathbf{P}\\mathbf{l}\\mathbf{u}\\mathbf{g})\\;z^{*}\\in\\arg\\operatorname*{min}_{z}\\;\\ell(\\pmb{y},\\mathcal{A}(\\mathcal{R}(z)))+\\Omega(\\mathcal{R}(z)),\\qquad\\mathbf{{x}^{*}}=\\mathcal{R}(z^{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We stress that here the optimization is with respect to the seed variable $_{\\textit{z}}$ , given the pretrained reverse process $\\mathcal{R}$ . Since we never modify the reverse diffusion process $\\mathcal{R}$ , we expect $\\mathcal{R}(z)$ to produce an object on the object manifold $\\mathcal{M}$ , i.e., enforcing manifold feasibility to address Issue 1. Moreover, optimizing the unified formulation Eq. (7) is expected to promote $\\pmb{y}\\approx\\mathcal{A}(\\mathcal{R}(\\pmb{z}^{*}))$ , inherent in the regularized data-ftiting framework, i.e., promoting data feasibility to address Issue 2. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "When there are multiple objects of interest in the IP under consideration, i.e., ${\\pmb y}={\\mathcal{A}}({\\pmb x}_{1},\\cdot\\cdot\\cdot,{\\pmb x}_{k})\\!+\\!{\\pmb n}$ with $k$ objects (e.g., in blind image deblurring ${\\pmb y}=\\mathcal{A}({\\pmb k},{\\pmb x})+{\\pmb n}$ , both the blur kernel $\\pmb{k}$ and sharp image $\\textbf{\\em x}$ are objects of interest, where ${\\mathcal{A}}({\\pmb k},{\\pmb x})={\\pmb k}*{\\pmb x}$ ; see also Appendix C.4), different objects may have different priors that should be encoded and treated differently. Our unified optimization formulation Eq. (7) facilitates the natural integration of multiple priors. Another bonus feature of our unified formulation lies in the flexibility in choosing numerical optimization solvers. We briefly explore both aspects in Section 4.3. ", "page_idx": 5}, {"type": "text", "text": "Fast samplers for memory and computational efficiency When implementing DMPlug with typical gradient-based solvers, e.g., ADAM [47], the gradient calculation in each iterative step requires a forward and a backward pass through the entire $\\mathcal{R}$ , i.e., $T$ blocks of the basic DL model in the given DM. For high-quality image generation [23\u201325], $T$ is typically tens or hundreds, resulting in prohibitive memory and computational burdens. To resolve this, we use the DDIM, which allows skipping reverse sampling steps thanks to its non-Markovian property, as the sampler $\\mathcal{R}$ . We observe, to our surprise and also in our favor, that a very small number of reverse steps, such as 3, is sufficient for our method to beat SOTA methods on all IPs we evaluate (see Fig. 5 and Section 4), and further increasing the number does not substantially improve the performance (actually even slightly degrades it perhaps due to the numerical difficulty caused by vanishing gradients as more steps are included). So, we default the number of reverse steps to 3 unless otherwise stated. This number is not sufficient for generating high-quality photorealistic images with existing DMs, but is good enough for our method. The discrepancy suggests a fundamental difference between image generation and image \u201cregression\u201d involved in solving IPs\u2014we leave this for future work. ", "page_idx": 5}, {"type": "image", "img_path": "81IFFsfQUj/tmp/a6bd14b17a6a9d53b0533e78ade775380907ed0aaee22affc5da08ade0cf08e2.jpg", "img_caption": ["Figure 5: PSNR $\\mathbf{\\mu(dB)}$ vs. periteration wall-clock time (s) running on an NVIDIA A100, for various reverse steps in $\\mathcal{R}$ . Experiments on CelebA for $4\\times$ super-resolution; solver: ADAM; maximum iterations: 6, 000 "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "3.2 Seemingly similar ideas ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "(A) GAN inversion for IPs Our plug-in method is reminiscent of GAN inversion to solve IPs [48, 49]: for a pretrained GAN generator $G_{\\theta}$ , GAN inversion performs a similar reparametrization ${\\pmb x}=G_{\\pmb\\theta}({\\pmb z})$ and plugs it into Eq. (1). The remaining task is also to minimize the resulting formulation with respect to the trainable seed $_{z}$ , and produce an ${\\pmb x}=G_{\\pmb\\theta}({\\pmb z}^{*})$ through a solution $z^{*}$ . However, there are numerous signs that GAN inversion does not work well for IPs. For example, [50] also finetunes the generator $G_{\\theta}$ alongside the trainable seed to boost performance, and [33, 32] report superior performance of DM-based methods compared to GAN-inversion-based ones for solving IPs; (B) Diffusion inversion (DI) Given an object $\\textbf{\\em x}$ , DI aims to find a seed $_{\\textit{z}}$ so that $\\mathcal{R}(z)$ reproduces $\\textbf{\\em x}$ , an important algorithmic component for DM-based image and text editing [51\u201353, 24, 54, 55]. A popular choice for DI is to modify DDIM [53, 24, 54, 55]. Although we cannot use DI to solve general IPs, DI can be considered as an IP and solved through $\\operatorname*{min}_{z}$ $\\ell(\\pmb{x},\\mathcal{R}(z))$ using our plug-in method. (C) Algorithm unrolling (AU) The multiblock structure in $\\mathcal{R}$ also resembles those DL models used in AU, a popular family of supervised methods for solving IPs [56, 16]. In AU, the trainable DL model also consists of multiple blocks of basic DL models, induced by unfolded iterative steps to solve Eq. (1). While in AU the weights in these DL blocks are trainable, the weights in our DL blocks are fixed. More importantly, as a supervised approach, AU requires paired training sets of the form $\\{(\\pmb{y}_{i},\\pmb{x}_{i})\\}_{i=1,...,N}$ , in contrast to the zero-shot nature of our method here. ", "page_idx": 5}, {"type": "text", "text": "3.3 Achieving robustness to unknown noise ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The early-learning-then-overfitting (ELTO) phenomenon When $\\textit{\\textbf{y}}$ contains noise, solving Eq. (7) can promote measurement feasibility, i.e., $\\bar{\\pmb{y}}\\stackrel{\\bar{\\sim}}{\\approx}\\mathcal{A}(\\mathcal{R}(\\pmb{z}^{*}))$ , but $\\b{\\mathscr{A}}(\\mathscr{R}(z^{*}))$ may also learn the noise, i.e., overfitting to noise. Interestingly, our method seems to favor desirable content and resist noise: (A) our method converges much faster when used to regress clean natural images than random noise (Fig. 6 (1), suggesting that our method shows high resistance to noise and low resistance to structured content, and (B) when performing regression against a noisy image $\\pmb{x}=\\pmb{x}_{0}+\\pmb{n}$ , our method, although powerful enough to overfti the noisy image $\\textbf{\\em x}$ ultimately, picks up the desired image content first and then learns the noise, leading to a hallmark \u201cearly-learning-then-overftiting\u201d (ELTO) phenomenon so that the recovery quality climbs to a peak before the potential degradation due to noise (Fig. 6 (2)). We stress that similar ELTO phenomena have been widely reported in the literature on using deep image priors (DIPs) to solve IPs [57\u201361], although this is the first time this phenomenon has been reported for DM-based methods. Inspired by related studies in DIP, we also perform a spectral analysis of intermediate recovery and reveal that our method has a spectral bias toward low-frequency components during learning, similar to DIP methods; see Appendix B. ", "page_idx": 5}, {"type": "image", "img_path": "81IFFsfQUj/tmp/475307dcba8b6b449949cff16574f6d8635532bbf0dd52c769094487926fa031.jpg", "img_caption": ["Figure 6: The recovery performance of our method on image regression with (1): (a) a clean natural image, (b) the same image with pixels randomly shuffled, (c) random noise iid sampled from $\\mathrm{Uniform}(0,1)$ , and (2) a noisy natural image with Gaussian noise at $\\sigma=0.08$ . Here, image regression means, given any image $\\textbf{\\em x}$ , performing $\\operatorname*{min}_{z}$ $\\ell(\\pmb{x},\\mathcal{R}(z))$ . "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Achieving robustness via early stopping (ES) One may wonder how widely this ELTO phenomenon occurs when using our DMPlug to solve IPs. Besides extensive additional visual confirmation (see Appendix F), in Table 4 we show that our method, without using the noise information, leads the SOTA methods in terms of peak performance during iteration\u2014particularly, by large margins on non-linear deblurring. The quantitative results suggest that the ELTO phenomenon is likely widespread, especially across noise types and levels. Hence, if we can perform proper early stopping (ES) to locate the peak performance, we tackle Issue 3. Deriving an effective ES strategy here is nontrivial, as in practice we do not have groundtruth images to compute any reference-based performance metrics such as PSNR. Fortunately, in the DIP literature, [35] discovers that for DIP-based methods for IPs, the valleys of the running-variance curves of the intermediate reconstructions are well aligned with the performance peaks. Based on this crucial observation, they propose an ES strategy, ES-WMV, that can accurately detect performance peaks with small performance loss on various IP tasks. Inspired by their success, we integrate the ES-WMV strategy into our plug-in method and find that ES-WMV is highly synergetic with our method and performs reliable ES with negligible performance loss (see Table 4). Details of the entire algorithm can be found in Algorithm 3. ", "page_idx": 6}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we evaluate our plug-in method, DMPlug, and compare it with other SOTA methods on two linear IPs, including super-resolution and inpainting, and three nonlinear IPs, including nonlinear deblurring, blind image deblurring (BID), and BID with turbulence. Following [20], we construct the evaluation sets by sampling 100 images from CelebA [62], FFHQ [63] and LSUNbedroom [64], respectively, and resizing all images to $256\\times256$ ; we measure recovery quality using three standard metrics for image restoration, including peak signal-to-noise-ratio (PSNR), structural similarity index (SSIM) and Learned Perceptual Image Patch Similarity (LPIPS) [65] with the default backbone. We describe in detail the five IPs tested and the formulations we use for them in Appendix C; we provide implementation details of our method and the competing methods in ", "page_idx": 6}, {"type": "text", "text": "Appendix D; we include comparisons of computational costs, along with more quantitative and qualitative results in Appendix E. ", "page_idx": 7}, {"type": "table", "img_path": "81IFFsfQUj/tmp/b369d9d40e78133fcbe2a1ea1e07a743bdc8477534b59e97e413ab4073cfd575.jpg", "table_caption": ["Table 1: (Nonlinear IP) Nonlinear deblurring with additive Gaussian noise $(\\sigma=0.01)$ ). (Bold: best, under: second best, green: performance increase, red: performance decrease) "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "4.1 IP tasks and experimental results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Linear IPs Due to space constraints, our experimental results on Super-resolution & inpainting are included in Appendix E.2. Our DMPlug can lead the best SOTA methods by about 2dB in PSNR and 0.02 in SSIM on average, respectively. ", "page_idx": 7}, {"type": "text", "text": "Nonlinear IPs Nonlinear d ring We use the learned blurring operators from [66] with a known Gaussian-shaped kernel and Gaussian additive noise with $\\sigma~=~0.01$ , following [20, 19]. We compare our DMPlug against several strong baselines: Blur Kernel Space (BKS)- styleGAN2 [66] based on GAN priors, BKS-generic [66] based on HyperLaplacian priors [68], and DM-based methods that can handle nonlinear IPs, including MCG, ILVR, DPS and ReSample. Despite the advancements ", "page_idx": 7}, {"type": "table", "img_path": "81IFFsfQUj/tmp/021c3f4bdce635aa3de94364b599274c661b2bfd9d67b8747e17a316308425c5.jpg", "table_caption": ["eblur- Table 2: (Nonlinear IP) BID with turbulence with additive Gaussian noise $(\\sigma=0.01)$ ). (Bold: best, under: second bes green: performance increase, red: performance decrease) "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "made by the recent ReSample [20] to enhance the DPS method, from Table 1, it is evident that our DMPlug can still significantly outperform the SOTA ReSample by substantial margins. Specifically, our method improves LPIPS, PSNR, and SSIM by 0.05, 4.5dB, and 0.07, respectively, across the three datasets on average. In addition, our DMPlug delivers a more faithful and precise restoration of details, as shown in Fig. 1. ", "page_idx": 7}, {"type": "text", "text": "BID & BID with turbulence BID is about recovering a sharp image $\\textbf{\\em x}$ (and kernel $\\pmb{k}$ ) from $\\pmb{y}=$ $\\pmb{k}*\\pmb{x}+\\pmb{n}$ where $^*$ denotes the linear convolution and the spatially invariant blur kernel $^k$ is unknown; for BID with turbulence which often arises in long-range imaging through atmospheric turbulence, we model the forward process as a simplified \u201ctilt-then-blur\u201d process, following [69]: ${\\pmb y}={\\pmb k}*{\\mathcal T}_{\\phi}({\\pmb x})\\,+{\\pmb n}$ , where $\\tau_{\\phi}(\\cdot)$ is the tilt operation parameterized by unknown $\\phi$ (see more details in Appendix C). We mainly compare our DMPlug to two DM-based models, including ILVR and BlindDPS [21], which is an extension of DPS. In addition, we choose two classical MAP-based methods, i.e., Pan-Dark Channel Prior (Pan-DCP) [70] and Pan- $\\ell_{0}$ [71], DIP-based SelfDeblur [72], and four methods that are based on supervised training on paired datasets, including DeBlurGANv2 [5], Stripformer [6], MPRNet [7] and TSR-WGAN [67]. It is important to mention that BlindDPS [21] use pretrained DMs not only for images but also for blur kernels (and tilt maps), lending it an unfair advantage over other methods. Although our method is flexible in working with multiple DM priors, as shown in Section 4.3, we opt to only use the pretrained DMs for images to ensure a fair comparison. Tables 2 and 3 show that our method, despite using fewer priors than BlindDPS, can surpass the best competing methods by approximately 0.03, 4.5dB, and 0.1 in terms of LPIPS, PSNR, and SSIM, respectively, on average. In Fig. 1, the reconstructions of our method look sharper and more precise than those of the main competitors. ", "page_idx": 7}, {"type": "table", "img_path": "81IFFsfQUj/tmp/d16f1262598e0b9cb0b7cffcb5e6229c733217bc17f98a9d03edfd6b08f7a5b6.jpg", "table_caption": ["Table 3: (Nonlinear IP) BID with additive Gaussian noise $\\left(\\sigma=0.01\\right)$ ). (Bold: best, under: second best, green: performance increase, red: performance decrease) "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "4.2 Robustness to unknown noise ", "text_level": 1, "page_idx": 8}, {"type": "image", "img_path": "81IFFsfQUj/tmp/eee2ac940da8067a1b9b545da9efc23dc9588817bbbb55bae0fa14554455b69d.jpg", "img_caption": ["Figure 7: (Robustness) Visualization of sample results from our DMPlug and main competing $4\\times$ super(top) and deblurring (bottom) with low-level "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "For robustness experiments, we choose super-resolution and nonlinear deblurring to represent linear and nonlinear IPs, respectively. To simulate scenarios involving unknown noise, we generate measurements with four types of noise: Gaussian, impulse, shot, and speckle noise, and across two different noise levels: low (level-1) and high (level-2), following [43] (see details in Appendix D.1), but we use the same formulation and code for each IP designed for mild Gaussian noise, regardless of the actual noise type and level. Table 4 and Fig. 7 clearly show that (1) most current IP solvers, except for DPS, suffer from the robustness issue, corroborating the hypotheses made in Section 2, and (2) the peak performance of our DMPlug can lead SOTA methods by around 1dB and $3.5\\mathrm{dB}$ in PSNR for the two tasks, respectively. To check the compatibility of our method with ES-WMV [35], we measure the detection performance via PSNR gaps, i.e., the absolute PSNR difference between the peak and the detected ES point following [35, 59]. Table 4 indicates that the detection gaps in the two exemplary tasks are nearly negligible, with PSNR gaps smaller than $0.5\\mathrm{dB}$ and 0.2dB, respectively. This suggests that the proposed method is highly synergetic with ES-WMV. ", "page_idx": 8}, {"type": "text", "text": "4.3 Ablation studies ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We conduct two ablation studies to demonstrate the flexibility of our method in terms of using multiple and non-DDIM DM priors and using alternative optimizers. (Flexibility of using DM priors) First, we explore the possibility of using different types of DMs. For super-resolution, we show in Table 5 that latent diffusion models (LDMs) [74, 25] are also synergetic with our method. Next, we study the potential of using multiple DMs together, taking BID with turbulence as an example. Using extra pretrained DMs for blur kernels and tilt maps from [21], our method can achieve even better reconstruction results. (Flexibility of using alternative optimizers) Here, we test the built-in ADAM [47] and L-BFGS [75] optimizers in PyTorch, with several different learning rates to solve Eq. (7). As shown in Table 6, the best ADAM and L-BFGS combinations can lead to comparable performance for our DMPlug. We choose ADAM as the default optimizer because in PyTorch, optimizing multiple groups of variables with different learning rates\u2014as for the case of BID (with turbulence)\u2014is easy to program with ADAM but tricky for L-BFGS. ", "page_idx": 8}, {"type": "table", "img_path": "81IFFsfQUj/tmp/040fc28e98af98572c35040078008047683d9577296d9210b5a1811955a2b3de.jpg", "table_caption": ["Table 4: (Robustness and ES) Super-resolution and nonlinear deblurring on CelebA [62] with different types and levels of noise. We only show $\\mathrm{PSNR}\\uparrow$ and PSNR ${\\mathrm{Gap}}{\\downarrow}$ to save space. (Bold: best, under: second best, green: performance increase, red: performance decrease) "], "table_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "81IFFsfQUj/tmp/16c8523dd298aa56ea08e09d581d031cefce9c2bf734627e0074894d771e8c19.jpg", "table_caption": ["Table 5: (Flexibility) Ablation on different priors for $\\textbf{\\em x}$ , $\\pmb{k}$ and $\\phi$ on 50 cases from CelebA [62] for super-resolution (SR), nonlinear deblurring (ND), and BID with turbulence. "], "table_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "81IFFsfQUj/tmp/44340ac5f98eea64d37664dede8e8f50e5c52e712c3263e764c1d3f2c298ca05.jpg", "table_caption": ["Table 6: (Flexibility) Ablation on different optimizers and learning rates on 50 cases from CelebA [62] for super-resolution. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Discussion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we focus on solving IPs with pretrained DMs. To deal with (Issue 1) insufficient manifold feasibility and (Issue 2) insufficient measurement feasibility of the prevailing interleaving methods, we pioneer a novel plug-in method, DMPlug, and make it practical in terms of computation and memory requirements. Taking advantage of a benign ELTO property and integrating an ES method ES-WMV [35], our method is the first to achieve robustness to unknown noise (Issue 3). Extensive experiment results demonstrate that our method can lead SOTA methods, both qualitatively and quantitatively\u2014often by large margins, particularly for nonlinear IPs. As for limitations, our empirical results in Section 3.1 suggest a fundamental gap between image generation and regression using pretrained DMs, that we have not managed to nail down. Also, our work is mostly empirical, and we leave a solid theoretical understanding for future work. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Wang H. is partially supported by a UMN CSE DSI PhD Fellowship. Wan Y. is partially supported by a UMN CSE InterS&Ections Seed Grant. This research is part of AI-CLIMATE:\u201cAI Institute for Climate-Land Interactions, Mitigation, Adaptation, Tradeoffs and Economy,\u201d and is supported by USDA National Institute of Food and Agriculture (NIFA) and the National Science Foundation (NSF) National AI Research Institutes Competitive Award no. 2023-67021-39829. The authors acknowledge the Minnesota Supercomputing Institute (MSI) at the University of Minnesota for providing resources that contributed to the research results reported in this article. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] J. Janai, F. G\u00fcney, A. Behl, and A. Geiger, \u201cComputer Vision for Autonomous Vehicles: Problems, Datasets and State of the Art,\u201d Mar. 2021, arXiv:1704.05519 [cs]. [Online]. Available: http://arxiv.org/abs/1704.05519   \n[2] R. Szeliski, Computer Vision: Algorithms and Applications, ser. Texts in Computer Science. Cham: Springer International Publishing, 2022. [Online]. Available: https://link.springer.com/10.1007/ 978-3-030-34372-9   \n[3] R. Olsen and R. Olsen, \u201cIntroduction to Remote Sensing,\u201d Jan. 2007, book Title: Remote Sensing from Air and Space ISBN: 9780819462350 Publisher: SPIE. [Online]. Available: https://spiedigitallibrary.org/eBooks/PM/Remote-Sensing-from-Air-and-Space/Chapter1/ Introduction-to-Remote-Sensing/10.1117/3.673407.ch1   \n[4] J. Sylvester and C. L. Epstein, \u201cIntroduction to the Mathematics of Medical Imaging,\u201d in The American Mathematical Monthly, vol. 112, May 2005, p. 479, iSSN: 00029890 Issue: 5. [Online]. Available: https://www.jstor.org/stable/10.2307/30037514?origin=crossref   \n[5] O. Kupyn, T. Martyniuk, J. Wu, and Z. Wang, \u201cDeblurGAN-v2: Deblurring (Orders-of-Magnitude) Faster and Better,\u201d Aug. 2019, arXiv:1908.03826 [cs]. [Online]. Available: http://arxiv.org/abs/1908.03826   \n[6] F.-J. Tsai, Y.-T. Peng, Y.-Y. Lin, C.-C. Tsai, and C.-W. Lin, \u201cStripformer: Strip Transformer for Fast Image Deblurring,\u201d Jul. 2022, arXiv:2204.04627 [cs]. [Online]. Available: http://arxiv.org/abs/2204.04627   \n[7] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, M.-H. Yang, and L. Shao, \u201cMultiStage Progressive Image Restoration,\u201d Mar. 2021, arXiv:2102.02808 [cs]. [Online]. Available: http://arxiv.org/abs/2102.02808 [8] M. Delbracio and P. Milanfar, \u201cInversion by direct iteration: An alternative to denoising diffusion for image restoration,\u201d Transactions on Machine Learning Research, 2023, featured Certification. [Online]. Available: https://openreview.net/forum?id $\\fallingdotseq$ VmyFF5lL3F   \n[9] D. Gilton, G. Ongie, and R. Willett, \u201cDeep Equilibrium Architectures for Inverse Problems in Imaging,\u201d Jun. 2021, arXiv:2102.07944 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2102.07944   \n[10] Z. Luo, F. K. Gustafsson, Z. Zhao, J. Sj\u00f6lund, and T. B. Sch\u00f6n, \u201cImage Restoration with Mean-Reverting Stochastic Differential Equations,\u201d May 2023, arXiv:2301.11699 [cs]. [Online]. Available: http://arxiv.org/abs/2301.11699   \n[11] L. Guo, C. Wang, W. Yang, S. Huang, Y. Wang, H. Pfister, and B. Wen, \u201cShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow Removal,\u201d Dec. 2022, arXiv:2212.04711 [cs]. [Online]. Available: http://arxiv.org/abs/2212.04711   \n[12] J. Whang, M. Delbracio, H. Talebi, C. Saharia, A. G. Dimakis, and P. Milanfar, \u201cDeblurring via Stochastic Refinement,\u201d Dec. 2021, arXiv:2112.02475 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2112.02475   \n[13] S. Gao, X. Liu, B. Zeng, S. Xu, Y. Li, X. Luo, J. Liu, X. Zhen, and B. Zhang, \u201cImplicit Diffusion Models for Continuous Super-Resolution,\u201d Sep. 2023, arXiv:2303.16491 [cs]. [Online]. Available: http://arxiv.org/abs/2303.16491   \n[14] O. Kupyn, V. Budzan, M. Mykhailych, D. Mishkin, and J. Matas, \u201cDeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks,\u201d Apr. 2018, arXiv:1711.07064 [cs]. [Online]. Available: http://arxiv.org/abs/1711.07064   \n[15] G. Ongie, A. Jalal, C. A. Metzler, R. G. Baraniuk, A. G. Dimakis, and R. Willett, \u201cDeep Learning Techniques for Inverse Problems in Imaging,\u201d May 2020, arXiv:2005.06001 [cs, eess, stat]. [Online]. Available: http://arxiv.org/abs/2005.06001   \n[16] V. Monga, Y. Li, and Y. C. Eldar, \u201cAlgorithm Unrolling: Interpretable, Efficient Deep Learning for Signal and Image Processing,\u201d Aug. 2020, arXiv:1912.10557 [cs, eess]. [Online]. Available: http://arxiv.org/abs/1912.10557   \n[17] K. Zhang, W. Ren, W. Luo, W.-S. Lai, B. Stenger, M.-H. Yang, and H. Li, \u201cDeep Image Deblurring: A Survey,\u201d May 2022, arXiv:2201.10700 [cs]. [Online]. Available: http://arxiv.org/abs/2201.10700   \n[18] J. Koh, J. Lee, and S. Yoon, \u201cSingle-image deblurring with neural networks: A comparative survey,\u201d Computer Vision and Image Understanding, vol. 203, p. 103134, Feb. 2021. [Online]. Available: https://linkinghub.elsevier.com/retrieve/pii/S1077314220301533   \n[19] H. Chung, J. Kim, M. T. Mccann, M. L. Klasky, and J. C. Ye, \u201cDiffusion Posterior Sampling for General Noisy Inverse Problems,\u201d Feb. 2023, arXiv:2209.14687 [cs, stat]. [Online]. Available: http://arxiv.org/abs/2209.14687   \n[20] B. Song, S. M. Kwon, Z. Zhang, X. Hu, Q. Qu, and L. Shen, \u201cSolving Inverse Problems with Latent Diffusion Models via Hard Data Consistency,\u201d Oct. 2023, arXiv:2307.08123 [cs]. [Online]. Available: http://arxiv.org/abs/2307.08123   \n[21] H. Chung, J. Kim, S. Kim, and J. C. Ye, \u201cParallel Diffusion Models of Operator and Image for Blind Inverse Problems,\u201d Nov. 2022, arXiv:2211.10656 [cs, stat]. [Online]. Available: http://arxiv.org/abs/2211.10656   \n[22] P. Dhariwal and A. Nichol, \u201cDiffusion Models Beat GANs on Image Synthesis,\u201d Jun. 2021, arXiv:2105.05233 [cs, stat]. [Online]. Available: http://arxiv.org/abs/2105.05233   \n[23] J. Ho, A. Jain, and P. Abbeel, \u201cDenoising Diffusion Probabilistic Models,\u201d Dec. 2020, arXiv:2006.11239 [cs, stat]. [Online]. Available: http://arxiv.org/abs/2006.11239   \n[24] J. Song, C. Meng, and S. Ermon, \u201cDenoising Diffusion Implicit Models,\u201d Oct. 2022, arXiv:2010.02502 [cs]. [Online]. Available: http://arxiv.org/abs/2010.02502   \n[25] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, \u201cHigh-Resolution Image Synthesis with Latent Diffusion Models,\u201d Apr. 2022, arXiv:2112.10752 [cs]. [Online]. Available: http://arxiv.org/abs/2112.10752   \n[26] Y. He, N. Murata, C.-H. Lai, Y. Takida, T. Uesaka, D. Kim, W.-H. Liao, Y. Mitsufuji, J. Z. Kolter, R. Salakhutdinov, and S. Ermon, \u201cManifold Preserving Guided Diffusion,\u201d Oct. 2023. [Online]. Available: https://openreview.net/forum?id=o3BxOLoxm1   \n[27] X. Xu and Y. Chi, \u201cProvably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction.\u201d [Online]. Available: https://www. semanticscholar.org/paper/Provably-Robust-Score-Based-Di%EF%AC%80usion-Posterior-for-Xu-Chi/ a713ae4d638ef679a7165fbf7301a6c045e2588d?utm_source $:=$ alert_email&utm_content=LibraryFolder& utm_campaign $\\lvert\\overline{{-}}.$ AlertEmails_DAILY&utm_term=LibraryFolder&email_index=0-0-0&utm_medium $\\lvert\\overline{{-}}$ 33840575&citedSort=relevance&citedQueryString=Denoising%20Diffusion%20Models%20for% 20Plug-and-Play%20Image%20Restoration   \n[28] Y. Zhu, K. Zhang, J. Liang, J. Cao, B. Wen, R. Timofte, and L. Van Gool, \u201cDenoising Diffusion Models for Plug-and-Play Image Restoration,\u201d May 2023, arXiv:2305.08995 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2305.08995   \n[29] X. Meng and Y. Kabashima, \u201cDiffusion Model Based Posterior Sampling for Noisy Linear Inverse Problems,\u201d Jan. 2024, arXiv:2211.12343 [cs, math, stat]. [Online]. Available: http: //arxiv.org/abs/2211.12343   \n[30] H. Chung, B. Sim, D. Ryu, and J. C. Ye, \u201cImproving Diffusion Models for Inverse Problems using Manifold Constraints,\u201d Oct. 2022, arXiv:2206.00941 [cs, stat]. [Online]. Available: http://arxiv.org/abs/2206.00941   \n[31] X. Li, Y. Ren, X. Jin, C. Lan, X. Wang, W. Zeng, X. Wang, and Z. Chen, \u201cDiffusion Models for Image Restoration and Enhancement \u2013 A Comprehensive Survey,\u201d Aug. 2023, arXiv:2308.09388 [cs]. [Online]. Available: http://arxiv.org/abs/2308.09388   \n[32] B. Kawar, M. Elad, S. Ermon, and J. Song, \u201cDenoising Diffusion Restoration Models,\u201d Oct. 2022, arXiv:2201.11793 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2201.11793   \n[33] Y. Wang, J. Yu, and J. Zhang, \u201cZero-Shot Image Restoration Using Denoising Diffusion Null-Space Model,\u201d Dec. 2022, arXiv:2212.00490 [cs]. [Online]. Available: http://arxiv.org/abs/2212.00490   \n[34] G. Liu, H. Sun, J. Li, F. Yin, and Y. Yang, \u201cAccelerating Diffusion Models for Inverse Problems through Shortcut Sampling,\u201d May 2024, arXiv:2305.16965 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2305.16965   \n[35] H. Wang, T. Li, Z. Zhuang, T. Chen, H. Liang, and J. Sun, \u201cEarly Stopping for Deep Image Prior,\u201d Dec. 2023, arXiv:2112.06074 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2112.06074   \n[36] A. Hyv\u00e4rinen, \u201cEstimation of Non-Normalized Statistical Models by Score Matching,\u201d Journal of Machine Learning Research, vol. 6, no. 24, pp. 695\u2013709, 2005. [Online]. Available: http://jmlr.org/papers/v6/hyvarinen05a.html   \n[37] Y. Song and S. Ermon, \u201cGenerative Modeling by Estimating Gradients of the Data Distribution,\u201d Oct. 2020, arXiv:1907.05600 [cs, stat]. [Online]. Available: http://arxiv.org/abs/1907.05600   \n[38] J. Song, C. Meng, and A. Vahdat, \u201cDenoising diffusion models: A generative learning big bang,\u201d Nov. 2023, CVPR 2023 Tutorial. [Online]. Available: https://cvpr2023-tutorial-diffusion-models.github.io/   \n[39] Z. Kadkhodaie and E. Simoncelli, \u201cStochastic Solutions for Linear Inverse Problems using the Prior Implicit in a Denoiser,\u201d in Advances in Neural Information Processing Systems, vol. 34. Curran Associates, Inc., 2021, pp. 13 242\u201313 254. [Online]. Available: https: //proceedings.neurips.cc/paper/2021/hash/6e28943943dbed3c7f82fc05f269947a-Abstract.html   \n[40] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole, \u201cScore-Based Generative Modeling through Stochastic Differential Equations,\u201d Feb. 2021, arXiv:2011.13456 [cs, stat]. [Online]. Available: http://arxiv.org/abs/2011.13456   \n[41] J. Choi, S. Kim, Y. Jeong, Y. Gwon, and S. Yoon, \u201cILVR: Conditioning Method for Denoising Diffusion Probabilistic Models,\u201d Sep. 2021, arXiv:2108.02938 [cs]. [Online]. Available: http://arxiv.org/abs/2108.02938   \n[42] Y. Sanghvi, Y. Chi, and S. H. Chan, \u201cKernel diffusion: An alternate approach to blind deconvolution,\u201d arXiv preprint arXiv:2312.02319, 2023.   \n[43] D. Hendrycks and T. Dietterich, \u201cBenchmarking Neural Network Robustness to Common Corruptions and Perturbations,\u201d Mar. 2019, arXiv:1903.12261 [cs, stat]. [Online]. Available: http://arxiv.org/abs/1903.12261   \n[44] F. Li, F. Fang, Z. Li, and T. Zeng, \u201cSingle image noise level estimation by artificial noise,\u201d Signal Processing, vol. 213, p. 109215, Dec. 2023. [Online]. Available: https: //www.sciencedirect.com/science/article/pii/S016516842300289X   \n[45] C. Lu, Y. Zhou, F. Bao, J. Chen, C. Li, and J. Zhu, \u201cDPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps,\u201d Advances in Neural Information Processing Systems, vol. 35, pp. 5775\u20135787, Dec. 2022. [Online]. Available: https://proceedings.neurips.cc/paper_files/paper/ 2022/hash/260a14acce2a89dad36adc8eefe7c59e-Abstract-Conference.html   \n[46] K. Zheng, C. Lu, J. Chen, and J. Zhu, \u201cDPM-Solver-v3: Improved Diffusion ODE Solver with Empirical Model Statistics,\u201d Advances in Neural Information Processing Systems, vol. 36, pp. 55 502\u201355 542, Dec. 2023. [Online]. Available: https://proceedings.neurips.cc/paper_files/paper/2023/ hash/ada8de994b46571bdcd7eeff2d3f9cff-Abstract-Conference.html   \n[47] D. P. Kingma and J. Ba, \u201cAdam: A Method for Stochastic Optimization,\u201d Jan. 2017, arXiv:1412.6980 [cs]. [Online]. Available: http://arxiv.org/abs/1412.6980   \n[48] A. Creswell and A. A. Bharath, \u201cInverting The Generator Of A Generative Adversarial Network,\u201d Nov. 2016, arXiv:1611.05644 [cs]. [Online]. Available: http://arxiv.org/abs/1611.05644   \n[49] J.-Y. Zhu, P. Kr\u00e4henb\u00fchl, E. Shechtman, and A. A. Efros, \u201cGenerative Visual Manipulation on the Natural Image Manifold,\u201d Dec. 2018, arXiv:1609.03552 [cs]. [Online]. Available: http://arxiv.org/abs/1609.03552   \n[50] X. Pan, X. Zhan, B. Dai, D. Lin, C. C. Loy, and P. Luo, \u201cExploiting Deep Generative Prior for Versatile Image Restoration and Manipulation,\u201d Jul. 2020, arXiv:2003.13659 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2003.13659   \n[51] X. Su, J. Song, C. Meng, and S. Ermon, \u201cDual Diffusion Implicit Bridges for Image-to-Image Translation,\u201d Mar. 2023, arXiv:2203.08382 [cs]. [Online]. Available: http://arxiv.org/abs/2203.08382   \n[52] A. Hertz, R. Mokady, J. Tenenbaum, K. Aberman, Y. Pritch, and D. Cohen-Or, \u201cPrompt-to-Prompt Image Editing with Cross Attention Control,\u201d Aug. 2022, arXiv:2208.01626 [cs]. [Online]. Available: http://arxiv.org/abs/2208.01626   \n[53] G. Kim, T. Kwon, and J. C. Ye, \u201cDiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation,\u201d Aug. 2022, arXiv:2110.02711 [cs]. [Online]. Available: http://arxiv.org/abs/2110.02711   \n[54] R. Mokady, A. Hertz, K. Aberman, Y. Pritch, and D. Cohen-Or, \u201cNull-text Inversion for Editing Real Images using Guided Diffusion Models,\u201d Nov. 2022, arXiv:2211.09794 [cs]. [Online]. Available: http://arxiv.org/abs/2211.09794   \n[55] B. Wallace, A. Gokul, and N. Naik, \u201cEDICT: Exact Diffusion Inversion via Coupled Transformations,\u201d pp. 22 532\u201322 541, 2023. [Online]. Available: https://openaccess.thecvf.com/content/CVPR2023/html/ Wallace_EDICT_Exact_Diffusion_Inversion_via_Coupled_Transformations_CVPR_2023_paper.html   \n[56] K. Gregor and Y. LeCun, \u201cLearning fast approximations of sparse coding,\u201d in Proceedings of the 27th International Conference on International Conference on Machine Learning, ser. ICML\u201910. Madison, WI, USA: Omnipress, Jun. 2010, pp. 399\u2013406.   \n[57] D. Ulyanov, A. Vedaldi, and V. Lempitsky, \u201cDeep Image Prior,\u201d International Journal of Computer Vision, vol. 128, no. 7, pp. 1867\u20131888, Jul. 2020, arXiv:1711.10925 [cs, stat]. [Online]. Available: http://arxiv.org/abs/1711.10925   \n[58] T. Li, Z. Zhuang, H. Liang, L. Peng, H. Wang, and J. Sun, \u201cSelf-Validation: Early Stopping for Single-Instance Deep Generative Priors,\u201d Oct. 2021, arXiv:2110.12271 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2110.12271   \n[59] T. Li, H. Wang, Z. Zhuang, and J. Sun, \u201cDeep Random Projector: Accelerated Deep Image Prior,\u201d pp. 18 176\u201318 185, 2023. [Online]. Available: https://openaccess.thecvf.com/content/CVPR2023/html/Li_ Deep_Random_Projector_Accelerated_Deep_Image_Prior_CVPR_2023_paper.html   \n[60] Z. Shi, P. Mettes, S. Maji, and C. G. M. Snoek, \u201cOn Measuring and Controlling the Spectral Bias of the Deep Image Prior,\u201d Dec. 2021, arXiv:2107.01125 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2107.01125   \n[61] Z. Zhuang, T. Li, H. Wang, and J. Sun, \u201cBlind Image Deblurring with Unknown Kernel Size and Substantial Noise,\u201d International Journal of Computer Vision, vol. 132, no. 2, pp. 319\u2013348, Feb. 2024, arXiv:2208.09483 [cs, eess]. [Online]. Available: http://arxiv.org/abs/2208.09483   \n[62] Z. Liu, P. Luo, X. Wang, and X. Tang, \u201cDeep Learning Face Attributes in the Wild,\u201d Sep. 2015, arXiv:1411.7766 [cs]. [Online]. Available: http://arxiv.org/abs/1411.7766   \n[63] T. Karras, S. Laine, and T. Aila, \u201cA Style-Based Generator Architecture for Generative Adversarial Networks,\u201d Mar. 2019, arXiv:1812.04948 [cs, stat]. [Online]. Available: http://arxiv.org/abs/1812.04948   \n[64] F. Yu, A. Seff, Y. Zhang, S. Song, T. Funkhouser, and J. Xiao, \u201cLSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop,\u201d Jun. 2016, arXiv:1506.03365 [cs]. [Online]. Available: http://arxiv.org/abs/1506.03365   \n[65] R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang, \u201cThe Unreasonable Effectiveness of Deep Features as a Perceptual Metric,\u201d Apr. 2018, arXiv:1801.03924 [cs]. [Online]. Available: http://arxiv.org/abs/1801.03924   \n[66] P. Tran, A. T. Tran, Q. Phung, and M. Hoai, \u201cExplore Image Deblurring via Encoded Blur Kernel Space,\u201d pp. 11 956\u201311 965, 2021. [Online]. Available: https://openaccess.thecvf.com/content/CVPR2021/html/ Tran_Explore_Image_Deblurring_via_Encoded_Blur_Kernel_Space_CVPR_2021_paper.html   \n[67] D. Jin, Y. Chen, Y. Lu, J. Chen, P. Wang, Z. Liu, S. Guo, and X. Bai, \u201cNeutralizing the impact of atmospheric turbulence on complex scene imaging via deep learning,\u201d Nat. Mach. Intell., vol. 3, no. 10, pp. 876\u2013884, 2021. [Online]. Available: https://doi.org/10.1038/s42256-021-00392-1   \n[68] D. Krishnan and R. Fergus, \u201cFast Image Deconvolution using Hyper-Laplacian Priors,\u201d in Advances in Neural Information Processing Systems, vol. 22. Curran Associates, Inc., 2009. [Online]. Available: https://papers.nips.cc/paper_files/paper/2009/hash/3dd48ab31d016ffcbf3314df2b3cb9ce-Abstract.html   \n[69] S. H. Chan, \u201cTilt-then-Blur or Blur-then-Tilt? Clarifying the Atmospheric Turbulence Model,\u201d IEEE Signal Processing Letters, vol. 29, pp. 1833\u20131837, 2022, arXiv:2207.06377 [eess]. [Online]. Available: http://arxiv.org/abs/2207.06377   \n[70] J. Pan, D. Sun, H. Pfister, and M.-H. Yang, \u201cDeblurring Images via Dark Channel Prior,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 40, no. 10, pp. 2315\u20132328, Oct. 2018, conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence. [Online]. Available: https://ieeexplore.ieee.org/document/8048543   \n[71] J. Pan, Z. Hu, Z. Su, and M.-H. Yang, \u201cL_0 -Regularized Intensity and Gradient Prior for Deblurring Text Images and Beyond,\u201d IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 39, no. 2, pp. 342\u2013355, Feb. 2017, conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/7448477?casa_token=BY5p4dV5BVwAAAAA: LaPxWMHRFDbrXQYcJmp247D-oOPlvPitreoe4MXKkd53Ku96bdoLz_-JE7lug9H9Cm-CxJlpxkI   \n[72] D. Ren, K. Zhang, Q. Wang, Q. Hu, and W. Zuo, \u201cNeural Blind Deconvolution Using Deep Priors,\u201d Mar. 2020, arXiv:1908.02197 [cs]. [Online]. Available: http://arxiv.org/abs/1908.02197   \n[73] S. H. Chan, X. Wang, and O. A. Elgendy, \u201cPlug-and-Play ADMM for Image Restoration: Fixed Point Convergence and Applications,\u201d Nov. 2016, arXiv:1605.01710 [cs]. [Online]. Available: http://arxiv.org/abs/1605.01710   \n[74] A. Vahdat, K. Kreis, and J. Kautz, \u201cScore-based generative modeling in latent space,\u201d Advances in Neural Information Processing Systems, vol. 34, pp. 11 287\u201311 302, 2021.   \n[75] D. C. Liu and J. Nocedal, \u201cOn the limited memory BFGS method for large scale optimization,\u201d Mathematical Programming, vol. 45, no. 1, pp. 503\u2013528, Aug. 1989. [Online]. Available: https://doi.org/10.1007/BF01589116   \n[76] H. Chihaoui, A. Lemkhenter, and P. Favaro, \u201cZero-shot Image Restoration via Diffusion Inversion,\u201d Oct. 2023. [Online]. Available: https://openreview.net/forum?id=ZnmofqLWMQ   \n[77] M. Heusel, H. Ramsauer, T. Unterthiner, B. Nessler, and S. Hochreiter, \u201cGans trained by a two time-scale update rule converge to a local nash equilibrium,\u201d Advances in neural information processing systems, vol. 30, 2017.   \n[78] P. Chakrabarty and S. Maji, \u201cThe Spectral Bias of the Deep Image Prior,\u201d Dec. 2019, arXiv:1912.08905 [cs]. [Online]. Available: http://arxiv.org/abs/1912.08905   \n[79] D. L. Ruderman, \u201cThe statistics of natural images,\u201d Network: Computation in Neural Systems, vol. 5, no. 4, pp. 517\u2013548, Jan. 1994. [Online]. Available: https://www.tandfonline.com/doi/full/10.1088/0954-898X_ 5_4_006   \n[80] Z. Dou and Y. Song, \u201cDiffusion Posterior Sampling for Linear Inverse Problem Solving: A Filtering Perspective,\u201d Oct. 2023. [Online]. Available: https://openreview.net/forum?id=tplXNcHZs1   \n[81] L. Rout, N. Raoof, G. Daras, C. Caramanis, A. G. Dimakis, and S. Shakkottai, \u201cSolving Linear Inverse Problems Provably via Posterior Sampling with Latent Diffusion Models,\u201d Jul. 2023. [Online]. Available: https://arxiv.org/abs/2307.00619v1 ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Remarks on the concurrent work [76] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "We became aware of the unpublished concurrent work, SHRED [76], when we were finalizing the details of our method in mid Jan 2024 (We started the current project in Oct 2023). Although the core idea of SHRED is the same as that of our DMPlug, there are a few crucial differences between [76] and the current paper. (1) Motivation: [76] aims only at addressing manifold feasibility, while the current paper targets manifold feasibility, measurement feasibility, and robustness to unknown noise, simultaneously; (2) Integral components: Since achieving robustness to unknown noise is part of our goal, the ES-WMV ES strategy is integral to our method, besides the unified optimization formulation Eq. (7) shared with [76]; (3) Key hyperparameters: To address the computational and memory bottleneck induced by reverse steps, we use only 3 reverse steps for all IPs we test, vs. the 10 or more reverse steps used in [76]. So, our current setting makes the method much more practical; (4) Flexibility: Our framework allows for the use of more than one pre-trained DM prior when available, as shown in Section 4.3, while [76] uses only a single DM prior as proposed in their Eqs. (17) to (19); (5) Experimental evaluation: [76] focuses on linear IPs, including inpainting, super-resolution, compressive sensing, and one nonlinear IP\u2014blind deconvolution, i.e., blind image deburring (BID). We focus our evaluation on nonlinear IPs, including nonlinear deblurring, BID, and BID with turbulence, besides linear IPs (inpainting and super-resolution). Moreover, [76] measures performance only by perceptual metrics, LPIPS [65] and FID [77], while we measure performance by both the perceptual metric LPIPS and the classical metrics PSNR and SSIM. In addition, [76] does not even compare their method with clear SOTA methods that use pre-trained DM, e.g., DPS [19], which they obviously were aware of (cited in the paper), whereas our comparison is more comprehensive. ", "page_idx": 14}, {"type": "text", "text": "B Spectral bias of our DMPlug ", "text_level": 1, "page_idx": 14}, {"type": "image", "img_path": "81IFFsfQUj/tmp/2040e114719ebad98c86c1fd62adcd44bea1e90d5cc0646097ce35825e975e8a.jpg", "img_caption": ["Figure 8: (1) The spectral bias of DMPlug with the $A D A M$ solver [47]. (2) The spectral bias of DMPlug with the L-BFGS solver [75]. The IP we experiment with here is regression against a noisy image with Gaussian noise at $\\sigma=0.08$ , i.e., the same denoising problem as in Fig. 6 (2). "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "One may wonder why the ELTO phenomenon occurs. Here, we borrow the ideas of spectral biases and spectral analysis from the DIP literature [78, 60, 59, 61] to shed some light on this. The theory of spectral biases for DIP states that low-frequency components are learned much faster than highfrequency components during DIP learning. Spectral biases in DIP lead to the ELTO phenomenon in DIP: because natural images are typically low-frequency dominant [79], the different learning paces imply that DIP learns mostly the desired image content (low-frequency image content plus the low-frequency part of noise) in the early stage, but gradually picks up the high-frequency part of noise in the late stage, resulting in performance degradation after a certain quality peak. Spectral analysis provides a quantitative visualization of spectral biases. ", "page_idx": 14}, {"type": "text", "text": "Here, we perform a similar spectral analysis of our DMPlug learning process to demonstrate its spectral biases, which causes the ELTO phenomenon. To measure spectral biases, we follow [59, 61] and use frequency band errors $(F B E s)$ . For an groundtruth image $\\textbf{\\em x}$ and its estimate $\\widehat{\\mathbf{x}}$ , the calculation of this metric goes as follows. First, we calculate the pointwise relative error pointw i se in the Fourier domain, i.e., $|{\\mathcal{F}}({\\pmb x})-{\\mathcal{F}}(\\widehat{{\\pmb x}})|\\,/|{\\mathcal{F}}({\\pmb x})|$ . Then, we divide the Fourier frequencies into five radial bands, compute the bandwise mean errors, i.e., the frequency-band errors (FBEs). ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "We visualize the evolution of FBEs of DMPlug over all five frequency bands in Fig. 8. The disparate learning paces across the frequency bands are evident: the lowest-frequency band is learned much more rapidly than the other bands, which is consistent between two different optimization solvers. With spectral biases similar to those in DIP, we can explain the ELTO phenomenon in DMPlug following the argument above for DIP. ", "page_idx": 15}, {"type": "text", "text": "C Setup details of the inverse problems we test ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "For super-resolution, inpainting, and nonlinear deblurring, we use the forward models from two of main competing methods [19, 20]; for BID and BID with turbulence, we follow the forward models from BlindDPS [21]\u2014the SOTA DM-based method. Moreover, following [19, 20], all the measurements contain additive Gaussian noise with $\\sigma=0.01$ . Our loss $\\ell$ by default is the MSE loss. ", "page_idx": 15}, {"type": "text", "text": "C.1 Super-resolution ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In noisy image super-resolution, the goal is to reconstruct a clean RGB image $\\textbf{\\em x}$ from a noisy downsampled version $\\pmb{\\dot{y}}=\\pmb{\\mathcal{D}}(\\pmb{x})+\\pmb{n}$ , where $\\mathcal{D}(\\cdot):[0,1]^{3\\times t H\\times t W}\\to[0,1]^{3\\times H\\times W}$ is a downsampling operator that resizes an image with dimensions $t H$ by $t W$ by the factor $t$ and $\\mathbfit{\\Delta}$ models additive noise. We set $t=4$ in Section 4. To ensure a fair comparison, we do not include any explicit regularization terms in the formulation: ", "page_idx": 15}, {"type": "equation", "text": "$$\n(\\mathbf{Super-resolution})\\,z^{*}=\\arg\\operatorname*{min}_{z}\\,\\,\\ell(y,\\mathcal{D}(\\mathcal{R}(z))),\\qquad x^{*}=\\mathcal{R}(z^{*}).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "C.2 Inpainting ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In noisy image inpainting, a clean RGB image $\\pmb{x}\\,\\in\\,[0,1]^{3\\times H\\times W}$ is only partially observed and then contaminated by additive noise $\\mathbfit{\\Delta}$ , described by the forward model ${\\pmb y}={\\pmb m}\\odot{\\pmb x}+{\\pmb n}$ , where $m\\in\\{0,1\\}^{3\\times H\\times W}$ is a binary mask and $\\odot$ denotes the Hadamard product. Given $\\textit{\\textbf{y}}$ and $\\mathbf{\\nabla}m$ , the goal is to reconstruct $\\textbf{\\em x}$ . Following [20], the masks for the three channels of $\\mathbf{\\nabla}m$ are identical, and $70\\%$ of the mask values are randomly set to 0. To ensure a fair comparison, we do not include any explicit regularization terms in the formulation: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbf{Inpainting})\\ z^{*}=\\arg\\operatorname*{min}_{z}\\ \\ell(\\pmb{y},\\pmb{m}\\odot\\mathcal{R}(z)),\\qquad\\pmb{x}^{*}=\\mathcal{R}(z^{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "C.3 Nonlinear deblurring ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We follow the setup in [19] which is inspired by [66]. Recently, [66] has proposed to learn data-driven blurring models from paired blurry-sharp training sets of the form $\\{({\\pmb y}_{i},{\\pmb x}_{i})\\}_{i=1,\\dots,N}$ through ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\alpha^{*},\\beta^{*}=\\arg\\operatorname*{min}_{\\alpha,\\beta}\\sum_{i=1}^{N}||y_{i}-\\mathcal{F}_{\\alpha}(x_{i},\\mathcal{G}_{\\beta}(\\pmb{x}_{i},\\pmb{y}_{i}))||,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\mathcal{G}_{\\beta}(\\cdot,\\cdot)$ predicts the latent blur kernel associated with the input blurry-sharp image pair, and $\\psi_{\\beta}(\\cdot,\\cdot)$ models real-world nonlinear blurring process given the input image-kernel pair. To study the performance of its DPS method on nonlinear IPs, [19] proposes the following nonlinear deblurring problem with a known Gaussian-shaped kernel: ", "page_idx": 15}, {"type": "equation", "text": "$$\ny={\\mathcal{F}}_{\\alpha^{*}}(x,g)+n,\\quad{\\mathrm{where~}}g\\in\\mathbb{R}^{64\\times64}{\\mathrm{~is~Gaussian-shaped~with~}}\\sigma=3.0.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The task here is to recover $\\textbf{\\em x}$ from $\\textit{\\textbf{y}}$ and the forward model $\\mathcal{F}_{\\alpha^{*}}(\\cdot,\\pmb{g})$ . Our formulation follows [19] and does not include extra regularizers: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbf{Nonlinear\\;deblurring})\\;z^{*}=\\arg\\operatorname*{min}_{z}\\;\\ell(y,\\mathcal{F}_{\\alpha^{*}}(\\mathcal{R}(z),g)),\\qquad x^{*}=\\mathcal{R}(z^{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "C.4 Blind image deblurring (BID) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "BID is about recovering a sharp image $\\textbf{\\em x}$ from ${\\pmb y}={\\pmb k}*{\\pmb x}+{\\pmb n}$ where $^*$ denotes the linear convolution and the spatially invariant blur kernel $^k$ is also unknown. It is a nonlinear IP because the forward model ${\\mathcal{A}}({\\pmb k},{\\pmb x})={\\pmb k}*{\\pmb x}$ is nonlinear. In solving BID under the regularized data-ftiting framework in Eq. (1), $\\ell_{2}$ or $\\ell_{1}$ data-fitting loss, and the sparse gradient prior to $\\textbf{\\em x}$ enforced by $\\bar{R_{x}(\\pmb{x})}=\\|\\nabla\\pmb{x}\\|_{1}$ or $R_{\\mathbf{\\pmb{x}}}(\\mathbf{\\pmb{x}})=\\|\\nabla\\pmb{\\mathbf{\\b{x}}}\\|_{1}/\\|\\nabla\\pmb{\\mathbf{\\b{x}}}\\|_{2}$ are typically used. In addition, because of the scale ambiguity in the forward model, i.e., $\\pmb{k}*\\pmb{x}=(\\alpha\\pmb{k})*(\\frac{1}{\\alpha}\\pmb{x})$ for any $\\alpha>0$ , the scale of $^k$ is often fixed by requiring $\\pmb{k}$ to be on the standard simplex (i.e., $\\mathbf{\\forall}k\\geq\\mathbf{0},\\mathbf{1}^{\\intercal}k=1)$ or on the sphere (i.e., $\\|\\pmb{k}\\|_{2}=1;$ ). [18, 17, 61] provide detailed coverage of these priors and regularizers. For our experiments here, we follow the settings in BlindDPS [19]: all the blur kernels are simulated with the size of $64\\times64$ ; the standard deviation of the Gaussian kernels is set to 3.0 and the intensity of the motion blur kernels is adjusted to 0.5. It is important to mention that BlindDPS [21] uses pretrained DMs not only for images but also for blur kernels, giving it an unfair advantage over other methods. But to ensure a fair comparison with other competing methods that only use data-driven image priors, we only use pretrained DMs for the image, plus the typical simplex constraint that is also used in BlindDPS: ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\mathbf{B}\\mathbf{I}\\mathbf{D})\\mathbf{\\phi}_{z}^{*},k^{*}=\\arg\\operatorname*{min}_{z,k}\\mathbf{\\phi}\\ell(y,\\operatorname{SoftMax}(k)*\\mathcal{R}(z)),\\qquad x^{*}=\\mathcal{R}(z^{*}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where Soft $\\operatorname{Max}(k)$ leads to a kernel estimate that lies on the standard simplex. ", "page_idx": 16}, {"type": "text", "text": "C.5 BID with turbulence ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "BID with turbulence often arises in long-range imaging through atmospheric turbulence. The forward imaging process can be modeled as a simplified \u201ctilt-then-blur\u201d process, following [69]: $\\textit{\\textbf{y}}\\equiv$ $k*\\bar{\\mathcal{T}}_{\\phi}(\\pmb{x})+\\pmb{n}$ , where the tilt operator $\\mathcal{T}_{\\phi}(\\cdot)$ applies the spatially varying vector field $\\phi$ to the image $\\textbf{\\em x}$ so that pixels of $\\textbf{\\em x}$ are moved around according to the vector field $\\phi$ , i.e., ${\\mathcal{T}}_{\\phi}({\\boldsymbol{x}})[p_{i}+\\phi_{i}]={\\boldsymbol{x}}[p_{i}]$ where $\\textstyle p_{i}$ \u2019s are the pixel coordinates. In BID with turbulence, none of the $k,x,\\phi$ is known and the task is to jointly estimate them from the measurement $\\textit{\\textbf{y}}$ . So, it is clear that this BID variant is strictly more difficult than BID itself. We follow BlindDPS [21] for data generation: the blur kernel comes from the point spread function (PSF) and takes a Gaussian shape with standard deviation 3.0; the tilt maps are generated as iid Gaussian random vectors over the pixel grid. Similar to the BID case, BlindDPS [21] use pretrained DMs for all three objects: image, kernel, and tilt map, unfair to other methods. We again use pretrained DMs for the image only. For the kernel, we again only impose the simplex constraint through a SoftMax activation. For the tilt map, inspired by the fact that the tilt vectors are small-magnitude random vectors, we initialize the map from a zero-mean Gaussian distribution with a small standard deviation and set an extremely small learning rate. Our final formulation for this task is ", "page_idx": 16}, {"type": "text", "text": "(BID with turbulence) $\\begin{array}{r}{z^{*},k^{*},\\phi^{*}=\\arg\\operatorname*{min}_{z,k,\\phi}\\ \\ell(y,\\mathrm{SoftMax}(k)*T_{\\phi}(\\mathcal{R}(z))),\\ x^{*}=\\mathcal{R}(z^{*}).}\\end{array}$ (14) ", "page_idx": 16}, {"type": "text", "text": "D More implementation details ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "D.1 Noise generation ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Following $[43]^{3}$ , we simulate four types of noise, with two intensity levels for each type. The detailed information is as follows. Gaussian noise: zero-mean additive Gaussian noise with variance 0.08 and 0.12 for low and high noise levels, respectively; Impulse noise: also known as salt-and-pepper noise, replacing each pixel with probability $p\\in[0,1]$ in a white or black pixel with half chance each. Low and high noise levels correspond to $p=0.03$ and 0.06, respectively; Shot noise: also known as Poisson noise. For each pixel, $x\\in[0,1]$ , the noisy pixel is Poisson distributed with the rate $\\lambda x$ , where $\\lambda$ is 60 and 25 for low and high noise levels, respectively; Speckle noise: for each pixel $x\\in[0,1]$ , the noisy pixel is $x(1+\\epsilon)$ , where $\\epsilon$ is zero-mean Gaussian with a variance level 0.15 and 0.20 for low and high noise levels, respectively. ", "page_idx": 16}, {"type": "text", "text": "D.2 Additional implementation details of our method ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We employ the following setup for our methods across all IP tasks. For $\\mathcal{R}(\\cdot)$ , we take the standard pretrained DMs from $[2\\bar{2}]^{4}$ and $[41]^{5}$ and use the standard DDIM [24] sampler with only 3 reverse steps based on Fig. 5; we also use pretrained latent diffusion models (LDMs) $[25]^{6}$ to obtain the results reported in Table 5. We use the pretrained DMs for blur kernels and tilt maps from $[21]^{7}$ to obtain the results reported in Table 5. For $\\ell(\\cdot)$ , we choose the standard MSE loss. For $\\Omega(\\cdot)$ , we use the typical explicit regularizers for each task to make the comparisons fair. The default optimizer is $A D A M$ and the learning rate (LR) for $_{z}$ is $1\\times10^{-2}$ ; for BID (with turbulence), the LRs for blur kernel and the tilt map are $\\bar{1}\\times10^{-1}$ and $1\\times10^{-7}$ , respectively. For the maximum numbers of iterations, we set 5, 000 and 10, 000 for linear and nonlinear IPs, respectively, which empirically allow good convergence. We perform all experiments on NVIDIA A100 GPUs with 40GB memory each. ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "table", "img_path": "81IFFsfQUj/tmp/690086f7ee2eb0a7eb976b925e644bb4f8d0472759dc17f2c9783335f53bdb0a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "Early stopping (ES) using ES-WMV The \u201cearly-learning-then-overfitting\u201d (ELTO) phenomenon has been widely reported in the literature on deep image prior (DIP) [57\u201360, 35], and ES-WMV [35] is an ES strategy that achieves the SOTA ES performance for DIP applied to various IPs. In ES-EMV, the running variance (VAR) is defined as: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{VAR}(t)\\stackrel{.}{=}\\frac{1}{W}\\sum_{w=0}^{W-1}\\|\\pmb{x}^{t+w}-1/W\\cdot\\sum_{i=0}^{W-1}\\pmb{x}^{t+i}\\|_{F}^{2},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $W$ is the window size and $\\pmb{x}^{i}$ denotes the recovery at iteration $i$ . [35] observes that the first major valley of the VAR curve is often well aligned with the peak of the PSNR curve. Based on this, [35] introduces an online algorithm to detect the first major valley of the VAR curve: if the minimal VAR does not change over $P$ consecutive steps, i.e., the VAR does not decrease further over $P$ consecutive steps, the iteration process is stopped. The combined algorithm, ES-WMV-integrated DMPlug, is described in Algorithm 3. For implementation, we use the official code of ES-WMV8. For super-resolution with unknown noise, we set its patience number as 100 and its window size as 10; for nonlinear deblurring with unknown noise, we set its patience number as 300 and its window size as 50. Table 4 indicates that the detection gaps in the two exemplary tasks are nearly negligible, with PSNR gaps smaller than 0.5dB and $\\mathrm{0.2dB}$ , respectively. This suggests that our DMPlug is highly synergetic with ES-WMV. ", "page_idx": 17}, {"type": "text", "text": "D.3 Implementations of competing methods ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We use the default code and settings of each competitor\u2019s official implementation, listed below. ", "page_idx": 17}, {"type": "text", "text": "\u2022 ADMM-PnP [73]: https://github.com/kanglin755/plug_and_play_admm   \n\u2022 DMPS [29]: https://github.com/mengxiangming/dmps   \n\u2022 DDRM [32]: https://github.com/bahjat-kawar/ddrm   \n\u2022 DPS [19] & MCG [30]: https://github.com/DPS2022/diffusion-posterior-sampling   \n\u2022 ILVR [41]: https://github.com/jychoi118/ilvr_adm   \n\u2022 ReSample [20]: https://github.com/soominkwon/resample/tree/main   \n\u2022 BKS [66]: https://github.com/VinAIResearch/blur-kernel-space-exploring   \n\u2022 SelfDeblur [72]: https://github.com/csdwren/SelfDeblur   \n\u2022 DeBlurGANv2 [5]: https://github.com/VITA-Group/DeblurGANv2   \n\u2022 Stripformer [6]: https://github.com/pp00704831/Stripformer-ECCV-2022-   \n\u2022 MPRNet [7]: https://github.com/swz30/MPRNet   \n\u2022 Pan-DCP [70]: https://jspan.github.io/projects/dark-channel-deblur/index.html   \n\u2022 Pan- $\\scriptstyle\\mathcal{E}_{0}$ [71]: https://jspan.github.io/projects/text-deblurring/index.html   \n\u2022 BlindDPS [21]: https://github.com/BlindDPS/blind-dps   \n\u2022 TSR-WGAN [67]: https://codeocean.com/capsule/9958894/tree/v1   \n\u2022 FPS [80]: https://github.com/ZehaoDou-official/FPS-SMC-2023   \n\u2022 DiffPIR [28]: https://github.com/yuanzhi-zhu/DiffPIR ", "page_idx": 18}, {"type": "text", "text": "E More experiment results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "E.1 Computational Efficiency ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As shown in Table 7, we find that the memory usage of our method is in the same order as that of most other algorithms. When it comes to speed, our implementation using L-BFGS is significantly faster than the ADAM version. Although our method with L-BFGS remains somewhat slow, it surpasses the performance of ReSample. We will explore further acceleration of our method in future work. ", "page_idx": 18}, {"type": "text", "text": "Table 7: Wall-clock time (seconds) and memory usage (GB) of various algorithms for superresolution on the CelebA [62] dataset, tested on a single NVIDIA A100 GPU. (Ours-A: ours with ADAM, Ours-L: ours with L-BFGS) ", "page_idx": 18}, {"type": "table", "img_path": "81IFFsfQUj/tmp/aab79be72bbc1681f3e46a9f7ab64c9466b7aabd446523bd7fa94ff444cf531e.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "E.2 Quantitative results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Super-resolution & inpainting Following [20, 19], to generate measurements, we use bicubic downsampling for super-resolution $(4\\times)$ and a random mask with $70\\%$ missing pixels for inpainting; all measurements contain additive Gaussian noise with $\\sigma=0.01$ . We compare our method with Plugand-Play using ADMM (ADMM-PnP) [73] and several SOTA DM-based methods: Diffusion Model based Posterior Sampling (DMPS) [29], Denoising Diffusion Destoration Models (DDRM) [32], Manifold Constrained Gradients (MCG) [30], Iterative Latent Variable Refinement (ILVR) [41], Diffusion Posterior Sampling (DPS) [19], and ReSample [20]. The quantitative results are reported in Tables 8 to 10, with qualitative results visualized in Fig. 1. It is clear that our DMPlug consistently outperforms all competing methods on the three datasets, both quantitatively and qualitatively. Specifically, while there is no significant improvements in terms of LPIPS, the proposed method can lead the best SOTA methods by about 2dB in PSNR and 0.02 in SSIM on average, respectively. ", "page_idx": 18}, {"type": "text", "text": "E.3 Qualitative results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "F More early stopping results ", "text_level": 1, "page_idx": 18}, {"type": "table", "img_path": "81IFFsfQUj/tmp/03bad1e27e3ec71ba1688c821107a5982bf28bd10d64b135077b6bd04a5b78ac.jpg", "table_caption": ["Table 8: (Linear IPs) Super-resolution and inpainting with additive Gaussian noise $(\\sigma=0.01)$ ). (Bold: best, under: second best, green: performance increase, red: performance decrease) "], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "81IFFsfQUj/tmp/f22f5c91ced721ded959ab6911621f061876dd893ba5bb1f6303d7364e5ad698.jpg", "table_caption": ["Table 9: (Linear IPs) Super-resolution and inpainting on LSUN-bedroom [64] with additive Gaussian noise $(\\sigma\\,=\\,0.01)$ ). (Bold: best, under: second best, green: performance increase, red: performance decrease) "], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "81IFFsfQUj/tmp/ada114010f873139108ea668ec23fe0591eac18a9a318a41c682271677291346.jpg", "table_caption": ["Table 10: (Linear IPs) Super-resolution and inpainting on CelebA [62] with additive Gaussian noise $\\sigma=0.01)$ ). (Bold: best, under: second best, green: performance increase, red: performance decrease) "], "table_footnote": [], "page_idx": 19}, {"type": "image", "img_path": "81IFFsfQUj/tmp/6477ce3220e73c4c4e649fa226aac4872534159eba452f5efa3e4f6964b0bff9.jpg", "img_caption": ["Figure 9: (Linear IP) Visualization of sample results from the plug-in method (Ours) and competing methods for $4\\times$ super-solution. All measurements contain Gaussian noise with $\\sigma=0.01$ . "], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "81IFFsfQUj/tmp/b70ed51d81eaa25c2ba4360fd226365d09868446633e247fa82a1a91a69c48d6.jpg", "img_caption": ["Figure 10: (Linear IP) Visualization of sample results from the plug-in method (Ours) and competing methods for inpainting (random $70\\%$ ). All measurements contain Gaussian noise with $\\sigma=0.01$ . "], "img_footnote": [], "page_idx": 21}, {"type": "image", "img_path": "81IFFsfQUj/tmp/0a2b42bb7ab7506cf841e1285d5d27a10737fdbe7de49f5517158b388cd1e84b.jpg", "img_caption": ["Figure 11: (Nonlinear IP) Visualization of sample results from the plug-in method (Ours) and competing methods for nonlinear deblurring. All measurements contain Gaussian noise with $\\sigma=0.01$ . "], "img_footnote": [], "page_idx": 22}, {"type": "image", "img_path": "81IFFsfQUj/tmp/34a636f7b71a4f76cea4af4329b708a872e9602657d5ec2b1a270558822eea05.jpg", "img_caption": ["Figure 12: (Nonlinear IP) Visualization of sample results from the plug-in method (Ours) and competing methods for BID (motion). All measurements contain Gaussian noise with $\\sigma=0.01$ . "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "81IFFsfQUj/tmp/de8bb0b0d151d75aff1bafd4724a97154b98e1cdec394f3aac95b75e7f27f570.jpg", "img_caption": ["Figure 13: (Nonlinear IP) Visualization of sample results from the plug-in method (Ours) and competing methods for BID (Gaussian). All measurements contain Gaussian noise with $\\sigma=0.01$ . "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "81IFFsfQUj/tmp/bb2476d86439702622df79431628e79b7f8a6ff6021d8d88616172c965123753.jpg", "img_caption": ["Figure 14: (Nonlinear IP) Visualization of sample results from the plug-in method (Ours) and competing methods for BID with turbulence. All measurements contain Gaussian noise with $\\sigma=0.01$ . "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "81IFFsfQUj/tmp/e73e790416b5fee7c3a567e2c25bc02caaedede4c18713e3d2e86a2b84af8b4e.jpg", "img_caption": ["Figure 15: (Robustness) Visualization of sample results from the plug-in method (Ours) and competing methods for $4\\times$ super-resolution. We generate measurements with four types of noise\u2014Gaussian, impulse, shot, and speckle noise\u2014across two different noise levels: low (level-1) and high (level-2), following [43]. (top: low-level noise; bottom: high-level noise) "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "81IFFsfQUj/tmp/ccb985b74bad587a82e739ba106854f8945625b1ec58705c595a5687cb14c6d4.jpg", "img_caption": ["Figure 16: (Robustness) Visualization of sample results from the plug-in method (Ours) and competing methods for nonlinear deblurring. We generate measurements with four types of noise\u2014Gaussian, impulse, shot, and speckle noise\u2014across two different noise levels: low (level-1) and high (level-2), following [43]. (top: low-level noise; bottom: high-level noise) "], "img_footnote": [], "page_idx": 27}, {"type": "image", "img_path": "81IFFsfQUj/tmp/d32bd66e509e98a4e149ede27433b1cfbd4d2be5b078d25ef4a85f7d47bbc258.jpg", "img_caption": ["Figure 17: (Early stopping) Our DMPlgu with ES-WMV [35] for $4\\times$ super-resolution with different types and levels of noise. (top: low-level noise; bottom: high-level noise). Red curves are PSNR curves, and blue curves are VAR curves. The green bars indicate the detected ES point. "], "img_footnote": [], "page_idx": 28}, {"type": "image", "img_path": "81IFFsfQUj/tmp/6eea31ee0369cac586b0e41f9b5591dda8ad4b1a9cb811ce6b2feae16d8d0cb3.jpg", "img_caption": ["Figure 18: (Early stopping) Our DMPlug with ES-WMV [35] for nonlinear deblurring with different types and levels of noise. (top: low-level noise; bottom: high-level noise). Red curves are PSNR curves, and blue curves are VAR curves. The green bars indicate the detected ES point. "], "img_footnote": [], "page_idx": 29}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: We clearly claim the scope and contributions of this paper in both abstract and introduction. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: We discuss the limitations of this work in Section 5. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 30}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: All the formulas are numbered and cross-referenced. Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 31}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Justification: We provide all the experiment details in Section 4, Appendix C and Appendix D. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 31}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We provide all the essential code for this paper. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 32}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: We provide all the experiment details in Section 4, Appendix C and Appendix D. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 32}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 32}, {"type": "text", "text": "Answer: [No] ", "page_idx": 32}, {"type": "text", "text": "Justification: First, we conduct extensive experiments in this paper and report the mean results. We do not anticipate significant fluctuations in the results. Second, we are afraid that adding the statistical significance of the experiments will mess this paper up because our tables are already very dense, but we are willing to provide them if needed. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: We provide the experiment compute resources in Appendix D.2. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 33}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: This paper is strictly with the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 33}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: We discuss the societal impacts in Section 5. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper only uses existing pretrained models for zero-shot tasks. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 34}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: We provide all the code and models we have used in Appendix D. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 34}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The new assets in this paper are well documented. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 35}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 35}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 35}]