[{"figure_path": "T0axIflVDD/tables/tables_4_1.jpg", "caption": "Table 1: Properties of datasets and used hyperparameter K of each dataset.", "description": "This table presents the characteristics of eight benchmark datasets used in the paper for multivariate time series forecasting.  For each dataset, it shows the trend variation (differences in means across different sections), seasonality variation (average variance over the Fourier spectrum), and the chosen hyperparameter K (number of dominant frequency components considered).  These values are relevant because they illustrate the varying degrees of non-stationarity present in each dataset and how the model parameters were adjusted to suit.", "section": "4.1 Experiment Setup"}, {"figure_path": "T0axIflVDD/tables/tables_5_1.jpg", "caption": "Table 2: Forecasting errors with and without FAN. The bold values indicate the best performance.", "description": "This table presents the Mean Absolute Error (MAE) and Mean Squared Error (MSE) for various time series forecasting models, both with and without the application of the proposed Frequency Adaptive Normalization (FAN) method.  The results are shown for different prediction lengths (96, 168, 336, and 720 steps) across eight benchmark datasets (ETTm2, Exchange, Electricity, Traffic, and Weather). The bold values highlight the best-performing model for each metric and dataset.", "section": "4.2 Main Results"}, {"figure_path": "T0axIflVDD/tables/tables_6_1.jpg", "caption": "Table 3: The MSE performance averaged across all steps. Bold values indicate the best performance.", "description": "This table presents a comparison of the Mean Squared Error (MSE) achieved by FAN and three other reversible instance normalization methods (SAN, Dish-TS, RevIN) across four different forecasting backbones (DLinear, FEDformer, Informer, SCINet) and eight datasets.  The MSE is averaged across all prediction steps.  Bold values highlight the best-performing method for each combination of backbone and dataset. This allows for an assessment of FAN's performance improvement relative to existing normalization techniques.", "section": "4.3 Comparison With Reversible Instance Normalization Methods"}, {"figure_path": "T0axIflVDD/tables/tables_8_1.jpg", "caption": "Table 4: Forecasting errors under the multivariant setting with respect to variations of FAN with SCINet backbone. The best performances are highlighted in bold.", "description": "This table presents the results of ablation studies conducted on two datasets (ETTh1 and Weather) to evaluate the effectiveness of different components within the FAN model.  Three variants of the FAN model are compared against the full FAN model: one without the non-stationary pattern prediction module, one using only the stationary forecasting backbone, and one without the stationary reconstruction step.  The results are reported in terms of MAE and MSE for prediction lengths of 96, 168, 336, and 720 time steps, with the best performance for each metric highlighted in bold.  The analysis helps to understand the relative contribution of each component of the FAN framework.", "section": "4.5 Ablation Studies"}, {"figure_path": "T0axIflVDD/tables/tables_18_1.jpg", "caption": "Table 2: Forecasting errors with and without FAN. The bold values indicate the best performance.", "description": "This table presents the Mean Absolute Error (MAE) and Mean Squared Error (MSE) for eight benchmark datasets across four different forecasting models (DLinear, Informer, FEDformer, and SCINet) with and without the proposed Frequency Adaptive Normalization (FAN) method.  The results demonstrate the improvement in forecasting accuracy achieved by incorporating FAN with each model.  The bold values highlight the best performance for each dataset and model, indicating where FAN provides the greatest benefit.", "section": "4.2 Main Results"}, {"figure_path": "T0axIflVDD/tables/tables_19_1.jpg", "caption": "Table 8: Forecasting errors under the multivariate setting. The bold values indicate best performance.", "description": "This table presents the results of a multivariate forecasting experiment on synthetic data, comparing FAN's performance against three other reversible normalization methods (SAN, Dish-TS, RevIN).  The experiment used a DLinear backbone model and varied the complexity of the synthetic time series (Syn-5 through Syn-9, reflecting an increasing number of composite frequencies). The table shows the MAE and MSE for each method and dataset, highlighting FAN's consistent and significant performance improvements across different levels of complexity.", "section": "E.1 Experiment On Synthetic Data"}, {"figure_path": "T0axIflVDD/tables/tables_19_2.jpg", "caption": "Table 8: Forecasting errors under the multivariate setting. The bold values indicate best performance.", "description": "This table presents the results of a multivariate forecasting experiment on synthetic data using the DLinear model as the backbone.  It compares the performance of FAN against three other reversible normalization methods (SAN, Dish-TS, and RevIN) across five different synthetic datasets (Syn-5 to Syn-9).  Each synthetic dataset consists of a combination of multiple sinusoidal signals with linearly varying amplitudes and periodicities.  The table shows the MAE and MSE for each method and dataset, highlighting the performance improvement achieved by FAN over the baselines. The improvement is expressed as a percentage increase in MAE and MSE for FAN compared to each of the other methods.", "section": "E.1 Experiment On Synthetic Data"}, {"figure_path": "T0axIflVDD/tables/tables_20_1.jpg", "caption": "Table 2: Forecasting errors with and without FAN. The bold values indicate the best performance.", "description": "This table presents the Mean Absolute Error (MAE) and Mean Squared Error (MSE) for eight benchmark datasets, comparing forecasting models with and without the Frequency Adaptive Normalization (FAN) method.  The results show the improvements achieved by incorporating FAN into various forecasting models (DLinear, Informer, FEDformer, and SCINet) across different prediction lengths (96, 168, 336, and 720 steps).  Bold values highlight the best performance for each metric and prediction length.", "section": "4.2 Main Results"}, {"figure_path": "T0axIflVDD/tables/tables_21_1.jpg", "caption": "Table 2: Forecasting errors with and without FAN. The bold values indicate the best performance.", "description": "This table presents the Mean Absolute Error (MAE) and Mean Squared Error (MSE) for eight benchmark datasets across four different forecasting models (DLinear, Informer, FEDformer, and SCINet).  Each model is evaluated both with and without the proposed Frequency Adaptive Normalization (FAN) method. The results show the improvements achieved by using FAN for each model and dataset.  Bold values highlight the best performance for each metric and configuration.", "section": "4.2 Main Results"}, {"figure_path": "T0axIflVDD/tables/tables_22_1.jpg", "caption": "Table 2: Forecasting errors with and without FAN. The bold values indicate the best performance.", "description": "This table presents the Mean Absolute Error (MAE) and Mean Squared Error (MSE) for eight different time series forecasting datasets.  The results are shown for four different forecasting models (DLinear, Informer, FEDformer, SCINet) with and without the application of the Frequency Adaptive Normalization (FAN) method proposed in the paper.  The bold values highlight the best performing model for each dataset and prediction length.", "section": "4.2 Main Results"}]