[{"figure_path": "4vp0edVY4o/tables/tables_7_1.jpg", "caption": "Table 1: Results for task-incremental learning using BERT-base encoder. We report the averaged accuracy (ACC) and forgetting (FGT) with their standard deviations (std) on five random seeds. Bold scores are the best scores and underline scores are the second best. 'OOT' means out of time.", "description": "This table presents the results of task-incremental learning experiments using a BERT-base encoder.  It compares various continual learning (CL) methods across four datasets: Yahoo, DB, News Series, and an aggregate of all three. For each method and dataset, the table shows the average accuracy (ACC) and forgetting (FGT) across five runs, along with standard deviations.  Higher ACC indicates better performance, while lower FGT suggests less catastrophic forgetting.  Bold values represent the best performance, and underlined values indicate the second best.  'OOT' indicates that the experiment ran out of time.", "section": "5 Experiments"}, {"figure_path": "4vp0edVY4o/tables/tables_8_1.jpg", "caption": "Table 1: Results for task-incremental learning using BERT-base encoder. We report the averaged accuracy (ACC) and forgetting (FGT) with their standard deviations (std) on five random seeds. Bold scores are the best scores and underline scores are the second best. 'OOT' means out of time.", "description": "This table presents the results of task-incremental learning experiments using a BERT-base encoder.  It compares various continual learning (CL) methods across three datasets (Yahoo, DB, and News Series) and an aggregate of all datasets.  The metrics reported are average accuracy (ACC) and forgetting (FGT), each with standard deviations calculated across five random seeds.  The best and second-best results are highlighted in bold and underlined, respectively. Results exceeding the allotted time are noted as 'OOT'.", "section": "5. Results"}, {"figure_path": "4vp0edVY4o/tables/tables_8_2.jpg", "caption": "Table 3: Alignment quantification on SNLI and News Series. We report Recall@20 on three random seeds.", "description": "This table presents the Recall@20 scores for four different models (FT, C-LoRA, Wire-Fixed, and Wire-Neigh) on two datasets (SNLI and News Series).  Recall@20 measures the proportion of correctly identified task-related tokens among the top 20 predicted tokens, assessing the models' ability to align data representations. The results show that the proposed alignment models (Wire-Fixed and Wire-Neigh) significantly outperform the baseline models (FT and C-LoRA) in terms of Recall@20, demonstrating the effectiveness of their alignment approach.", "section": "5.4 Additional Analysis and Ablations"}, {"figure_path": "4vp0edVY4o/tables/tables_9_1.jpg", "caption": "Table 4: Average ACC with different s in C-LORA, Wire-Neigh on News Series.", "description": "This table presents the average accuracy (ACC) results obtained from experiments on the News Series dataset using different scaling factors (s) for two alignment models: Wire-Neigh and C-LORA, with and without the probing-first (PF) strategy. The scaling factor (s) controls the balance between using pre-trained and task-specific information for generating data representations.  The table shows how the average accuracy changes with various scaling factors and how the probing-first strategy affects the performance.", "section": "5.4 Additional Analysis and Ablations"}, {"figure_path": "4vp0edVY4o/tables/tables_9_2.jpg", "caption": "Table 1: Results for task-incremental learning using BERT-base encoder. We report the averaged accuracy (ACC) and forgetting (FGT) with their standard deviations (std) on five random seeds. Bold scores are the best scores and underline scores are the second best. 'OOT' means out of time.", "description": "This table presents the results of task-incremental learning experiments using a BERT-base encoder.  It compares various continual learning methods across three datasets (Yahoo, DB, News Series) and an aggregate of all three.  For each method, the average accuracy (ACC) and forgetting (FGT) are reported along with standard deviations across five random seeds.  The best and second-best results are highlighted in bold and underlined, respectively.  'OOT' indicates that the experiment did not complete within the allocated time.", "section": "5 Experiments"}]