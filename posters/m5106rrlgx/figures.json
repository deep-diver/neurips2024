[{"figure_path": "m5106RRLgx/figures/figures_1_1.jpg", "caption": "Figure 1: The scaling behavior of Vote and Filter-Vote. Interestingly, their performance is often a non-monotonic function of the number of LM calls. For example, as the number LM calls increases, Vote's performance initially increases but then decreases, while Filter-Vote's performance initially decreases but then increases on the MMLU PHYSICS dataset.", "description": "This figure displays the scaling behavior of two compound AI systems, Vote and Filter-Vote, across four different language tasks (MMLU Physics, TruthfulQA, GPQA, and Averitec).  The x-axis represents the number of language model (LM) calls made by the system, and the y-axis represents the system's performance. The surprising finding is that performance is not always monotonically increasing with the number of LM calls. In some cases, performance improves initially, then decreases; in others, it decreases and then increases. This non-monotonic relationship highlights the complexity of compound AI systems and the need for a deeper understanding of how to optimize their design.", "section": "1 Introduction"}, {"figure_path": "m5106RRLgx/figures/figures_2_1.jpg", "caption": "Figure 1: The scaling behavior of Vote and Filter-Vote. Interestingly, their performance is often a non-monotonic function of the number of LM calls. For example, as the number LM calls increases, Vote's performance initially increases but then decreases, while Filter-Vote's performance initially decreases but then increases on the MMLU PHYSICS dataset.", "description": "The figure shows the performance of Vote and Filter-Vote models on four different datasets (MMLU Physics, TruthfulQA, GPQA, and Averitec) as the number of language model (LM) calls increases.  Surprisingly, the performance is not consistently increasing with more LM calls; instead, it often shows a non-monotonic trend, initially increasing, then decreasing or vice versa, depending on the dataset and the model.", "section": "Main Contributions"}, {"figure_path": "m5106RRLgx/figures/figures_3_1.jpg", "caption": "Figure 1: The scaling behavior of Vote and Filter-Vote. Interestingly, their performance is often a non-monotonic function of the number of LM calls. For example, as the number LM calls increases, Vote's performance initially increases but then decreases, while Filter-Vote's performance initially decreases but then increases on the MMLU PHYSICS dataset.", "description": "This figure shows the performance of Vote and Filter-Vote models on four different datasets (MMLU Physics, TruthfulQA, GPQA, and AVERITEC) as the number of LM calls increases.  It demonstrates a surprising non-monotonic relationship: performance does not always increase with the number of calls. Instead, the performance first increases and then decreases for Vote in some cases (and the opposite pattern for Filter-Vote). This behavior is attributed to the diversity of query difficulties within the dataset.", "section": "1 Introduction"}, {"figure_path": "m5106RRLgx/figures/figures_4_1.jpg", "caption": "Figure 3: How the query difficulties shape the landscape of a one-layer Voting Inference System's performance. Informally, if the overall task is \u201ceasy\u201d (p1 + p2 > 1), but the fraction of \"hard\" queries is large (a < 1 \u2212  +), then as the number of LM calls increases, the Voting Inference Systems' performance increases first but then decreases. We call such a landscape a \u201cinverse U shape\". Similarly, if the overall task is \"hard\" (p1 + p2 < 1), but the fraction of \u201chard\u201d queries is small (a > 1 \u2212  +), then enlarging the number of LM calls leads an initial decrease and then increase. Such a landscape is called a \u201cU shape\u201d. When a is large, the U-shape is less likely to occur while the inverse U-shape becomes more common. Smaller a leads to an opposite trend.", "description": "This figure shows how the difficulty of queries affects the performance of a Voting Inference System. The x-axis represents the difficulty of one subset of queries, and the y-axis represents the difficulty of another subset. The different colored regions represent different performance trends (increasing, decreasing, inverse U-shape, U-shape).  The parameter 'a' controls the proportion of easy queries in the task, influencing which performance trend dominates.", "section": "4 Analytical Model of Scaling Behavior"}, {"figure_path": "m5106RRLgx/figures/figures_7_1.jpg", "caption": "Figure 4: A case study on the AVERITEC dataset. (a) As more LM calls are invoked, the overall performance of Vote and Filter-Vote both initially increases but then decreases. (b) This U-shape can be perfected explained by the opposite effects on easy and difficult queries: More LM calls lead to higher performance on easy queries, but lower performance on difficult ones. (c) Our analytical scaling model accurately predicts the empirical performance. (d) Examples of an easy query and a difficult one. One LM call gives the correct answer with probability higher than any other answers (67%), and thus Vote with more calls eventually gives the correct answer. For the difficult query, the probability of the correct answer (34%) is lower than that of an incorrect answer (56%). Thus, Vote with more LM calls eventually always generates a wrong answer.", "description": "This figure shows a case study using the AVERITEC dataset to demonstrate the non-monotonic scaling behavior of Vote and Filter-Vote.  The subfigures break down the overall performance (a) into performance on easy and difficult queries (b), showing that more LM calls improve easy queries but hurt hard queries.  Subfigure (c) validates the accuracy of the analytical scaling model in predicting performance, and (d) provides example queries illustrating why this behavior occurs.", "section": "Experiments"}, {"figure_path": "m5106RRLgx/figures/figures_8_1.jpg", "caption": "Figure 1: The scaling behavior of Vote and Filter-Vote. Interestingly, their performance is often a non-monotonic function of the number of LM calls. For example, as the number LM calls increases, Vote's performance initially increases but then decreases, while Filter-Vote's performance initially decreases but then increases on the MMLU PHYSICS dataset.", "description": "This figure displays the performance of Vote and Filter-Vote models across four different datasets (MMLU Physics, TruthfulQA, GPQA, and Averitec) as the number of Language Model (LM) calls increases.  The key observation is the non-monotonic relationship between the number of LM calls and model performance. In some cases, performance improves initially with more LM calls, but then begins to decline; while in others, the opposite is true \u2013 performance dips initially before improving with more calls. This unexpected behavior highlights the complexities of scaling compound AI systems.", "section": "Main Contributions"}, {"figure_path": "m5106RRLgx/figures/figures_9_1.jpg", "caption": "Figure 2: Performance breakdown on MMLU PYHSICS. As the number of LM calls increases, Vote and Filter-Vote perform increasingly better on easy queries but increasingly worse on difficult ones.", "description": "This figure shows the performance of Vote and Filter-Vote models on the MMLU Physics dataset, broken down by query difficulty.  It demonstrates that increasing the number of LM calls improves performance on easier queries but reduces performance on more challenging ones. This non-monotonic behavior helps to explain the overall non-monotonic scaling properties observed in Figure 1.", "section": "4 Analytical Model of Scaling Behavior"}, {"figure_path": "m5106RRLgx/figures/figures_23_1.jpg", "caption": "Figure 7: Mean square error of the performance predicted by our proposed scaling law on synthesized datasets with varying bi-level difficulties. Here, we fit the scaling law by performance evaluated at K = 1, 2, 3, 4, 5, and evaluate its performance for K from 1 to 100. Overall, we observe that the predicted performance accurately matches the empirical evaluation.", "description": "This figure shows the mean squared error between the predicted performance using the analytical scaling model and the actual performance of the Vote model on synthetic datasets with varying bi-level difficulties.  The model is fit using performance data from 1 to 5 LM calls, and then its predictions are evaluated across a range of 1-100 calls. The results show that the model's predictions closely match the actual performance, highlighting the accuracy of the scaling law in capturing the relationship between the number of LM calls and the performance.", "section": "D.5 Performance Estimation via Our Proposed Scaling Law"}]