[{"figure_path": "AthZ2g6VE2/figures/figures_7_1.jpg", "caption": "Figure 1: Comparison of several algorithms with several compressors on logistic regression with the 'a5a' dataset from the LibSVM, which has d = 122 and 6,414 data points. We chose different values of n to illustrate the two regimes n < d and n > d, as discussed at the end of Section 3.", "description": "This figure compares various communication-efficient algorithms for distributed learning using different compressors on a logistic regression task with the 'a5a' dataset.  The x-axis represents the number of communicated bits, and the y-axis represents the error (f(x) - f*).  The figure shows the performance of LoCoDL against several baseline methods, demonstrating its superior performance, especially in the context of different compression strategies and varying numbers of clients (n).", "section": "4 Experiments"}, {"figure_path": "AthZ2g6VE2/figures/figures_16_1.jpg", "caption": "Figure 2: Comparison of several algorithms with several compressors on logistic regression with the 'diabetes' dataset from the LibSVM, which has d = 8 and 768 data points. We chose different values of n to illustrate the three regimes: n < d, n \u2248 d, n > d\u00b2, as discussed at the end of Section 3.", "description": "This figure compares various algorithms' performance on a logistic regression task using the 'diabetes' dataset.  The x-axis represents the number of communicated bits, and the y-axis shows the objective function value (f(x) - f*).  Different algorithms (LoCoDL, ADIANA, DIANA, 5GCS-CC, CompressedScaffnew, GradSkip, Scaffold) and compressor types (rand-k, natural, combinations) are evaluated across three different numbers of clients (n=6, n=37, n=73) to demonstrate performance across different scaling regimes relative to the data dimension (d=8). The results highlight LoCoDL's superior communication efficiency compared to other algorithms.", "section": "4 Experiments"}, {"figure_path": "AthZ2g6VE2/figures/figures_17_1.jpg", "caption": "Figure 2: Comparison of several algorithms with several compressors on logistic regression with the 'diabetes' dataset from the LibSVM, which has d = 8 and 768 data points. We chose different values of n to illustrate the three regimes: n < d, n \u2248 d, n > d\u00b2, as discussed at the end of Section 3.", "description": "This figure compares the performance of various algorithms (LoCoDL, ADIANA, DIANA, 5GCS-CC, CompressedScaffnew, GradSkip, Scaffold) with different compressors (Rand-1, Rand-2, Natural, Rand-1+Natural, l1-select) on a logistic regression task using the 'diabetes' dataset.  The x-axis represents the number of communicated bits, and the y-axis shows the function value minus the optimal function value (f(x)-f*).  Three subplots show results for different numbers of clients (n=6, n=37, n=73), illustrating how algorithm performance varies across different scaling regimes relative to the data dimension (d=8).", "section": "4 Experiments"}, {"figure_path": "AthZ2g6VE2/figures/figures_17_2.jpg", "caption": "Figure 1: Comparison of several algorithms with several compressors on logistic regression with the 'a5a' dataset from the LibSVM, which has d = 122 and 6,414 data points. We chose different values of n to illustrate the two regimes n < d and n > d, as discussed at the end of Section 3.", "description": "This figure compares the performance of various algorithms (LoCoDL, ADIANA, DIANA, 5GCS-CC, CompressedScaffnew, GradSkip, Scaffold) using different compressors (rand-k, natural, combination of rand-k and natural, l1-select) on a logistic regression task with the 'a5a' dataset.  The x-axis represents the number of communicated bits, and the y-axis represents the objective function value. The two subfigures show results for different numbers of clients (n), illustrating the performance differences between the algorithms in low-client and high-client regimes, relative to the data dimension (d).", "section": "4 Experiments"}]