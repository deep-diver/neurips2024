[{"type": "text", "text": "IPM-LSTM: A Learning-Based Interior Point Method for Solving Nonlinear Programs ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Xi Gao1, Jinxin Xiong2,3, Akang Wang2,3,\\*, Qihong Duan1, Jiang Xue1,\\*, and Qingjiang $S\\mathrm{hi}^{2,4}$ ", "page_idx": 0}, {"type": "text", "text": "1School of Mathematics and Statistics, Xi\u2019an Jiaotong University, Xi\u2019an, China 2Shenzhen Research Institute of Big Data, China   \n3School of Data Science, The Chinese University of Hong Kong, Shenzhen, China 4School of Software Engineering, Tongji University, Shanghai, China ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Solving constrained nonlinear programs (NLPs) is of great importance in various domains such as power systems, robotics, and wireless communication networks. One widely used approach for addressing NLPs is the interior point method (IPM). The most computationally expensive procedure in IPMs is to solve systems of linear equations via matrix factorization. Recently, machine learning techniques have been adopted to expedite classic optimization algorithms. In this work, we propose using Long Short-Term Memory (LSTM) neural networks to approximate the solution of linear systems and integrate this approximating step into an IPM. The resulting approximate NLP solution is then utilized to warm-start an interior point solver. Experiments on various types of NLPs, including Quadratic Programs and Quadratically Constrained Quadratic Programs, show that our approach can significantly accelerate NLP solving, reducing iterations by up to $60\\%$ and solution time by up to $70\\%$ compared to the default solver. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Constrained Nonlinear Programs (NLPs) represent a category of mathematical optimization problems in which the objective function, constraints, or both, exhibit nonlinearity. Popular NLP variants encompass Quadratic Programs (QPs), Quadratically Constrained Quadratic Programs (QCQPs), semi-definite programs, among others. These programs are commonly classified as convex or non-convex, contingent upon the characteristics of their objective function and constraints. The versatility of NLPs allows for their application across a wide array of domains, including power systems (Conejo and Baringo, 2018), robotics (Schaal and Atkeson, 2010), and wireless communication networks (Chiang, 2009). ", "page_idx": 0}, {"type": "text", "text": "The primal-dual Interior Point Method (IPM) stands as a preeminent algorithm for addressing NLPs (Nesterov and Nemirovskii, 1994; Nocedal and Wright, 1999). It initiates with an infeasible solution positioned sufficiently far from the boundary. Subsequently, at each iteration, the method refines the solution by solving a system of linear equations, thereby directing it towards the optimal solution. Throughout this iterative process, the algorithm progresses towards feasibility and optimality while keeping the iterate well-centered, ultimately converging to the optimal solution. However, a notable computational bottleneck arises during the process of solving linear systems, necessitating matrix decomposition with a runtime complexity of $O(n^{3})$ . ", "page_idx": 0}, {"type": "text", "text": "Recently, the Learning to Optimize (L2O) (Bengio et al., 2021; Chen et al., 2024; Gasse et al., 2022) paradigm has emerged as a promising methodology for tackling various optimization problems, ", "page_idx": 0}, {"type": "text", "text": "IPM-LSTM ", "text_level": 1, "page_idx": 1}, {"type": "image", "img_path": "9c3IiAWeiN/tmp/010eaa48983ff5ca347dae48a66b06211c4c6b8bcf1bddab7030df4bd5de7f54.jpg", "img_caption": ["Figure 1: An illustration of the IPM-LSTM approach. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "spanning unconstrained optimization (Chen et al., 2022a), linear optimization (Chen et al., 2022b; Li et al., 2024), and combinatorial optimization (Baker, 2019; Gasse et al., 2022; Han et al., 2023). Its ability to encapsulate common optimization patterns renders it particularly appealing. Noteworthy is the application of learning techniques to augment traditional algorithms such as the gradient descent method (Andrychowicz et al., 2016), simplex method (Liu et al., 2024), and IPM (Qian et al., 2024). ", "page_idx": 1}, {"type": "text", "text": "We observe that existing works on learning-based IPMs primarily concentrate on solving LPs (Qian et al., 2024). Motivated by the robustness and efficiency of IPMs for general NLPs, we pose the following question: ", "page_idx": 1}, {"type": "text", "text": "Can we leverage L2O techniques to expedite IPMs for NLPs? ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "In this study, we propose the integration of Long Short-Term Memory (LSTM) neural networks to address the crucial task of solving systems of linear equations within IPMs, introducing a novel approach named IPM-LSTM. An illustration of the IPM-LSTM approach is depicted in Figure 1. Specifically, we substitute the conventional method of solving linear systems with an unconstrained optimization problem, leveraging LSTM networks to identify near-optimal solutions for the latter. We integrate a fixed number of IPM iterations into the LSTM loss function and train these networks within the self-supervised learning framework. The substitution is embedded within a classic IPM to generate search directions. Ideally, the primal-dual solution provided by IPM-LSTM should be well-centered with respect to the boundary and associated with a small duality gap. Finally, we utilize such approximate primal-dual solution pairs to warm-start an interior point solver. IPM-LSTM has several attractive features: $(i)$ it can be applied to general $N\\!L P s$ ; (ii) it strikes a good balance between feasibility and optimality in the returned solutions; (iii) it can warm-start and thereby accelerate interior point solvers. ", "page_idx": 1}, {"type": "text", "text": "The distinct contributions of our work can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 Approximating Solutions to Linear Systems via LSTM: This study marks the first attempt to employ learning techniques for approximating solutions of linear systems in IPMs, achieving significant speedup compared to traditional linear algebra approaches.   \n\u2022 Two-Stage Framework: We introduce a two-stage L2O framework. In the first stage, IPMLSTM generates high-quality primal-dual solutions. In the second stage, these solutions are used to warm-start an interior point solver. This framework effectively accelerates the solving process of IPMs while yielding optimal solutions.   \n\u2022 Empirical Results: Compared with existing L2O algorithms, IPM-LSTM demonstrates favorable performance in terms of solution feasibility and optimality across various NLP types, including QPs and QCQPs. Utilizing these solutions as initial points in the state-of-the-art NLP solver IPOPT (W\u00e4chter and Biegler, 2006) reduces iterations by up to $60\\%$ and solution time by up to $70\\%$ . ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Constrained L2O. Approaches utilizing L2O for constrained optimization can be broadly categorized into two directions: (i) direct learning of the mapping from optimization inputs to full solutions, and (ii) integration of learning techniques alongside or within optimization algorithms (Bengio et al., 2021; Donti et al., 2021). Previous works (Fioretto et al., 2020; Huang et al., 2021; Pan et al., 2023) adopted the former approach, employing a supervised learning scheme to train the mapping. However, this method necessitates a large number of (near-)optimal solutions as training samples, making it resource-intensive. From a self-supervised learning perspective, an intuitive approach is to incorporate the objective and penalization for constraint violation directly into the loss function (Kim et al., 2023; Park and Van Hentenryck, 2023). Nevertheless, such an approach may not guarantee the feasibility of the returned solutions. To address the feasibility issue, notable works such as Donti et al. (2021) first predict a partial solution via neural networks and then complete the full solution by utilizing equality constraints, iteratively correcting the solution towards the satisfaction of inequalities by applying gradient-based methods. However, for general nonlinear inequalities, this correction step may not ensure feasibility (Liang et al., 2023). Other approaches like Li et al. (2023) utilized gauge mappings to enforce feasibility for linear inequalities, while Liang et al. (2023) proposed the homeomorphic projection scheme to guarantee feasibility. However, these methods have limitations; the former is only applicable to linearly constrained problems, and the latter works for problems with feasibility regions homeomorphic to a unit ball. Another critical issue with the approach in Donti et al. (2021) is that the completion step may fail during training when the equality system with some fixed variables becomes infeasible, as highlighted in Han et al. (2024) and Zeng et al. (2024). Consequently, such an approach will not succeed during the training stage. To mitigate this issue, Han et al. (2024) proposed solving a projection problem if the completion step fails. However, the computationally expensive projection step may still be necessary during inference, which hinders its practical value. ", "page_idx": 2}, {"type": "text", "text": "Learning-Based IPMs. Primal-dual IPMs are polynomial-time algorithms used for solving constrained optimization problems such as LPs and NLPs. The work of Qian et al. (2024) demonstrated that properly designed Graph Neural Networks (GNNs) can theoretically align with IPMs for LPs, enabling GNNs to function as lightweight proxies for solving LPs. However, extending this alignment to NLPs is challenging as representation learning for general NLPs remains unknown. Another avenue of research in learning-based IPMs involves warm-starting implementation. Previous works like Baker (2019), Diehl (2019) and Zhang and Zhang (2022) addressed alternative current optimal power flow (ACOPF) applications and proposed using learning models, such as GNNs, to learn the mapping between ACOPF and its optimal solutions. These predicted solutions are then utilized as initial points to warm-start an interior point optimizer. However, even if these solutions are close to the optimal ones, they may not be well-centered with respect to the trajectory in IPMs, causing the optimizer to struggle in progressing towards feasibility and optimality (Forsgren, 2006). ", "page_idx": 2}, {"type": "text", "text": "3 Approach ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 The Classic IPM ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We focus on solving the following NLP (1): ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle{\\operatorname*{min}_{x\\in\\mathbb{R}^{n}}}}&{\\ f(x)}\\\\ {\\mathrm{s.t.}\\ }&{h(x)=0}\\\\ &{x\\geq0}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where the functions $f\\,:\\,\\mathbb{R}^{n}\\,\\rightarrow\\,\\mathbb{R}$ and $h:\\mathbb{R}^{n}\\,\\rightarrow\\,\\mathbb{R}^{m}$ are all assumed to be twice continuously differentiable. Problems with general nonlinear inequality constraints can be reformulated in the above form by introducing slack variables. We note that for simplicity, we assume all variables in (1) are non-negative, though NLPs with arbitrary variable bounds can also be handled effectively. Readers are referred to Appendix A for details. ", "page_idx": 2}, {"type": "text", "text": "The primal-dual IPM stands as one of the most widely utilized approaches for addressing NLPs. It entails iteratively solving the perturbed Karush-Kuhn-Tucker (KKT) conditions (2) for a decreasing ", "page_idx": 2}, {"type": "text", "text": "sequence of parameters $\\mu$ converging to zero. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\nabla f(x)+\\lambda^{\\top}\\nabla h(x)-z=0\\qquad h(x)=0}\\\\ &{\\mathrm{diag}(z)\\mathrm{diag}(x)e=\\mu e\\qquad}&{x,z\\geq0}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\lambda\\in\\mathbb{R}^{m}$ and $z\\in\\mathbb{R}_{+}^{n}$ denote the corresponding dual variables, $\\mathrm{diag(\\cdot)}$ represents a diagonal matrix, and $e$ is a vector of ones. Let $F(x,\\lambda,z)=0$ denote the system of nonlinear equations in (2). We then employ a one-step Newton\u2019s method to solve such a system, aiming to solve systems of linear equations (3). ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\left[\\!\\!\\begin{array}{c c c}{\\nabla^{2}f({\\boldsymbol x})+\\lambda^{\\top}\\nabla^{2}h({\\boldsymbol x})}&{\\nabla h^{\\top}({\\boldsymbol x})}&{-I}\\\\ {\\nabla h({\\boldsymbol x})}&&{}\\\\ {\\operatorname{diag}(z)}&{\\operatorname{diag}({\\boldsymbol x})\\right]\\left[\\!\\!\\begin{array}{c}{\\Delta{\\boldsymbol x}}\\\\ {\\Delta{\\boldsymbol\\lambda}}\\\\ {\\Delta{\\boldsymbol z}}\\end{array}\\!\\!\\right]=-F({\\boldsymbol x},\\lambda,z)\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The IPM commences with an initial solution $(x^{0},\\lambda^{0},z^{0})$ such that $x^{0},z^{0}>0$ . At iteration $k$ , the linear system (3) defined by the current iterate $(x^{k},\\lambda^{k},z^{k})$ is solved, with $\\mu:=\\sigma\\left[\\left(z^{k}\\right)^{\\top}x^{k}\\right]/n$ being the perturbation parameter and constant $\\sigma\\in(0,1)$ . A line-search fliter step along the direction $(\\Delta x^{k},\\Delta\\lambda^{k},\\Delta z^{k})$ is then performed to ensure boundary condition satisfaction as well as sufficient progress towards objective value improvement or constraint violation reduction. This process iterates until convergence criteria, such as achieving optimality and feasibility within specified tolerances, are met. The IPM is guaranteed to converge to a KKT point with a superlinear rate. A pseudocode of the IPM is presented as Algorithm 1. ", "page_idx": 3}, {"type": "text", "text": "Algorithm 1 The classic IPM ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Inputs: An initial solution $(x^{0},\\lambda^{0},z^{0})$ , $\\sigma\\in(0,1)$ , $k\\leftarrow0$   \nOutputs: The optimal solution $(x^{*},\\lambda^{*},z^{*})$   \n1: while not converged do   \n2: Update $\\mu^{k}$   \n3: Solve the system $J^{k}\\left[(\\Delta x^{k})^{\\top},(\\Delta\\lambda^{k})^{\\top},(\\Delta z^{k})^{\\top}\\right]^{\\top}=-F^{k}$   \n4: Choose $\\alpha^{k}$ via a line -search filter method   \n5: $(x^{k+1},\\lambda^{k+1},z^{k+1})\\gets(x^{k},\\lambda^{k},z^{k})+\\alpha^{k}(\\Delta x^{k},\\Delta\\lambda^{k},\\Delta z^{k})$   \n6: $k\\gets k+1$   \n7: end while ", "page_idx": 3}, {"type": "text", "text": "We note that, in classic IPMs, one typically reformulates the system (3) and then solves a reduced system of equations (i.e., augmented system) for greater efficiency. However, in this work, we are interested in the full systems since they are associated with smaller condition numbers (Greif et al., 2014) that are critical to the performance of our proposed approach. Additionally, various techniques have been proposed to enhance the robustness and efficiency of IPMs, including secondorder correction, inertial correction, and feasibility restoration. Interested readers are referred to W\u00e4chter and Biegler (2006) for further details about IPMs. ", "page_idx": 3}, {"type": "text", "text": "3.2 Approximating Solutions to Linear Systems ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The small number of iterations in IPMs does not always guarantee efficiency because, at times, IPMs encounter a high per-iteration cost of linear algebra operations. In the worst-case scenario, the cost of solving a dense optimization problem using a direct linear algebra method to solve the Newton equation system (3) may reach $\\bar{O(n^{3})}$ flops per iteration. This motivates us to avoid computing exact solutions to linear systems and instead focus on their approximations. Toward this goal, we consider the following least squares problem (4): ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{y}\\frac{1}{2}\\left\\|J^{k}y+F^{k}\\right\\|^{2},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\lVert\\cdot\\rVert$ denotes the Euclidean norm. If (3) is solvable, then an optimal solution to problem (4) is also the exact solution $\\left[(\\Delta x^{k})^{\\top},(\\Delta\\lambda^{k})^{\\top},(\\Delta z^{k})^{\\top}\\right]^{\\top}$ to system (3). Otherwise, we resort to an approximation of the latter. This perspective is similar to the inexact IPM (Bellavia, 1998; Dexter et al., 2022). ", "page_idx": 3}, {"type": "text", "text": "Assumption 1. At iteration $k$ , we could identify some $y^{k}$ such that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\|J^{k}y^{k}+F^{k}\\|\\leq\\eta\\left[\\left(z^{k}\\right)^{\\top}x^{k}\\right]/n}\\\\ {\\|y^{k}\\|\\leq(1+\\sigma+\\eta)\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\eta\\in(0,1)$ and $F_{0}(x^{k},\\lambda^{k},z^{k})$ denotes $F(x^{k},\\lambda^{k},z^{k})$ with $\\mu=0$ . ", "page_idx": 4}, {"type": "text", "text": "To satisfy Assumption 1, the approximate solution $y^{k}$ has to be bounded and accurate enough, regardless of whether $J^{k}$ is invertible. ", "page_idx": 4}, {"type": "text", "text": "Proposition 1 (Bellavia (1998)). If $(x^{k},\\lambda^{k},z^{k})$ is generated such that Assumption $^{\\,l}$ is satisfied, let $(x^{*},\\lambda^{*},z^{*})$ denote a limit point of the sequence $\\{(x^{k},\\lambda^{k},z^{k})\\}$ , then $\\{(x^{k},\\lambda^{k},z^{k})\\}$ converges to $(x^{*},\\lambda^{*},z^{*})$ and $F_{0}(x^{*},\\lambda^{*},z^{*})=0$ . ", "page_idx": 4}, {"type": "text", "text": "Proposition 1 implies that if solutions with specified accuracy for linear systems in Step 3 are found, the IPM would converge. ", "page_idx": 4}, {"type": "text", "text": "3.3 The IPM-LSTM Approach ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The problem (4) is an unconstrained convex optimization problem. Various L2O methods have been proposed to solve such problems (Chen et al., 2022a; Gregor and LeCun, 2010; Liu et al., 2023). We will employ the LSTM networks in our L2O method for addressing problem (4), hence our approach is called \u201cIPM-LSTM\u201d. ", "page_idx": 4}, {"type": "text", "text": "Model Architecture. LSTM is a type of recurrent neural network designed to effectively capture and maintain long-term dependencies in sequential data (Yu et al., 2019). LSTM networks are commonly considered suitable for solving unconstrained optimization problems due to the resemblance between LSTM recurrent calculations and iterative algorithms (Andrychowicz et al., 2016; Liu et al., 2023; Lv et al., 2017). ", "page_idx": 4}, {"type": "text", "text": "The LSTM network consists of $T$ cells parameterized by the same learnable parameters $\\theta$ . Each cell can be viewed as one iteration of a traditional iterative method, as illustrated in Figure 2. Let $\\begin{array}{r}{\\phi(y):=\\frac{1}{2}\\left\\|J^{k}y+F^{k}\\right\\|^{2}}\\end{array}$ for convenience. The $t$ -th cell takes the previous estimate $y_{t-1}$ and the gradient $(J^{\\dot{k}})^{\\top}(J^{k}y_{t-1}+F^{k})$ as the input and outputs the current estimate $y_{t}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{y_{t}:=\\mathrm{LSTM}_{\\theta}\\left(\\left[y_{t-1},(J^{k})^{\\top}(J^{k}y_{t-1}+F^{k})\\right]\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The $T$ -th cell yields $y_{T}$ as an approximate solution to problem (4). As suggested by Andrychowicz et al. (2016) and Liu et al. (2023), we utilize a coordinate-wise LSTM that shares parameters not only across different LSTM cells but also for all coordinates of $y$ . ", "page_idx": 4}, {"type": "image", "img_path": "9c3IiAWeiN/tmp/cfe43b4905b41b52649b7ef966f3a986d4be2e869aad82c0dce0d87d92d5c0dc.jpg", "img_caption": ["Figure 2: The LSTM architecture for solving min $\\phi(y)$ . y "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Model Training. We train the proposed optimizer by finding the optimal $\\theta$ in (7) on a dataset $\\mathcal{M}$ of NLPs. Each sample in $\\mathcal{M}$ is an instance of the optimization problem. During training, we apply the optimizer to each instance $M\\in\\mathcal{M}$ , performing $K$ IPM iterations in the outer loop and $T$ LSTM ", "page_idx": 4}, {"type": "text", "text": "time steps in the inner loop, generating a sequence of iterates $\\{(y_{1}^{1},...,y_{T}^{1}),...,(y_{1}^{K},...,y_{T}^{K})\\}$ where the superscript $k$ denotes the IPM iteration number. We then optimize $\\theta$ by minimizing the following loss function: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\theta}\\frac{1}{\\left|\\mathcal{M}\\right|}\\sum_{M\\in\\mathcal{M}}\\left(\\frac{1}{K}\\sum_{k=1}^{K}\\frac{1}{T}\\sum_{t=1}^{T}\\frac{1}{2}\\left\\|J^{k}y_{t}^{k}(\\theta)+F^{k}\\right\\|^{2}\\right)_{M},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the subscript $M$ indicates that the corresponding term is associated with instance $M$ . Clearly, our model training falls into the category of self-supervised learning. To mitigate memory issues caused by excessively large computational graphs, we employ truncated backpropagation through time after each IPM iteration during training, as done in Chen et al. (2022a) and Liu et al. (2023). ", "page_idx": 5}, {"type": "text", "text": "Preconditioning. The Hessian matrix of $\\phi(y)$ is $(J^{k})^{\\top}J^{k}$ , whose condition number, $\\kappa((J^{k})^{\\top}J^{k})$ , is the square of that of $J^{k}$ . Consequently, $\\kappa((J^{k})^{\\top}J^{k})$ can easily become very large. Since solving system (4) via LSTM networks emulates iterative first-order methods, the value of $\\kappa((J^{k})^{\\top}J^{k})$ strongly affects the performance of LSTM networks. To address this issue, we employ a simple diagonal preconditioning technique that rescales the Hessian matrix $(J^{k})^{\\top}J^{k}$ using the Ruiz scaling method (Ruiz, 2001) to decrease its condition number. ", "page_idx": 5}, {"type": "text", "text": "3.4 Two-Stage Framework ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To further enhance the solution quality, we propose a two-stage framework that initially obtains a nearoptimal and well-centered primal-dual solution via IPM-LSTM and then utilizes this approximate solution to warm-start an interior point solver. In this study, we select IPOPT (W\u00e4chter and Biegler, 2006), an IPM-based solver renowned for its robustness and efficiency in optimizing NLPs. ", "page_idx": 5}, {"type": "text", "text": "Our two-stage framework works as follows: Given an NLP (1), we generate an initial point $(x^{0},\\lambda^{0},z^{0})$ and formulate the least squares problem (4). Subsequently, the trained LSTM network with $T$ cells solves this problem and returns a search direction. We then employ the simple fractional-to-boundary method (W\u00e4chter and Biegler, 2006) to determine the step size and reach the new iterate. This procedure is iterated $K$ times, resulting in a primal-dual solution $(x^{K},\\lambda^{K},z^{K})$ . Finally, the obtained solution serves as the warm-start solution for IPOPT, leading to the optimal solution $x^{*}$ upon IPOPT convergence. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1 Experimental Settings ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We evaluate our approach and compare its performance against traditional methods as well as L2O algorithms for solving various types of NLPs. Furthermore, we also quantify the warm-starting effect of our proposed two-stage approach. Our code is available at https://github.com/NetSysOpt/IPMLSTM. ", "page_idx": 5}, {"type": "text", "text": "Baseline Algorithms. In our experiments, we denote our algorithm by IPM-LSTM and compare it against both traditional optimizers and L2O algorithms. The traditional optimizers considered are: (i) OSQP (Stellato et al., 2020): an ADMM-based solver designed for convex QPs. (ii) IPOPT 3.14.8 (W\u00e4chter and Biegler, 2006): a state-of-the-art IPM-based solver for NLPs with the default linear solver MUMPS (Amestoy et al., 2000) and a convergence tolerance of $10^{-4}$ . We also assess several L2O algorithms, including: (i) NN (Donti et al., 2021): a straightforward deep learning approach that integrates the objective function and penalty for constraint violations into the loss function. (ii) DC3 (Donti et al., 2021): an end-to-end method that uses \u201ccompletion\u201d steps to maintain equality constraints and \u201ccorrection\u201d steps for inequality feasibility. (iii) DeepLDE (Kim et al., 2023): an algorithm that trains neural networks using a primal-dual approach to impose inequality constraints and employs \u201ccompletion\u201d for equality constraints. (iv) PDL (Park and Van Hentenryck, 2023): a self-supervised learning method that jointly trains two networks to approximate primal and dual solutions. (v) LOOP-LC (Li et al., 2023): a neural approximator that maps inputs of linearly constrained models to high-quality feasible solutions using gauge maps. (vi) H-Proj (Liang et al., 2023): a method that applies a homeomorphic projection scheme to post-process solutions resulting from the completion step in DC3. ", "page_idx": 5}, {"type": "text", "text": "Datasets. The dataset used in this paper includes randomly generated benchmarks obtained from Chen and Burer (2012), Donti et al. (2021) and Liang et al. (2023), as well as real-world instances from Globallib (see http://www.minlplib.org). These benchmarks encompass QPs, QCQPs, and simplex non-convex programs. For each case, we generate 10, 000 samples and divide them into a $10:1:1$ ratio for training, validation, and testing, respectively. All numerical results are reported for the test set. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Model Settings. All LSTM networks have a single layer and are trained using the Adam optimizer (Kingma, 2014). During IPM-LSTM training, an early stopping strategy with a patience of 50 is employed, halting training if no improvement is observed for 50 iterations, while satisfying inequality and equality constraints violation less than 0.005 and 0.01. The learning rate is 0.0001, and the batch size is 128 for each task. Additional IPM-LSTM parameters for each task are provided in Appendix C. ", "page_idx": 6}, {"type": "text", "text": "Evaluation Configuration. All our experiments were conducted on an NVIDIA RTX A6000 GPU, an Intel Xeon 2.10GHz CPU, using Python 3.10.0 and PyTorch 1.13.1. ", "page_idx": 6}, {"type": "text", "text": "4.2 Computational Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Convex QPs. We consider convex QPs with both equality and inequality constraints: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}{\\displaystyle\\operatorname*{min}_{x\\in\\mathbb{R}^{n}}}&{\\frac{1}{2}x^{\\top}Q_{0}x+p_{0}^{\\top}x}\\\\ {\\mathrm{s.t.}\\;\\;}&{p_{j}^{\\top}x\\leq q_{j}}&&{j=1,\\cdots\\,,l}\\\\ &{p_{j}^{\\top}x=q_{j}}&&{j=l+1,\\cdots\\,,m}\\\\ &{x_{i}^{L}\\leq x_{i}\\leq x_{i}^{U}}&&{i=1,\\cdots\\,,n}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $Q_{0}\\in\\mathbb{S}_{+}^{n}$ , $p_{j}\\in\\mathbb{R}^{n}$ , $q_{j}\\in\\mathbb{R}$ , $x_{i}^{L}\\in\\mathbb{R}\\cup\\{-\\infty\\}$ and $x_{i}^{U}\\in\\mathbb{R}\\cup\\{+\\infty\\}$ . We conduct experiments on two groups of QPs, each instance with 200 variables, 100 inequalities and 100 equalities. The first group is generated in the same way as Donti et al. (2021), where only the right hand sides of equality constraints are perturbed while the second one considers perturbation for all model parameters. Let \u201cConvex QP (RHS)\u201d denote the former and \u201cConvex QPs (ALL)\u201d denote the latter. It is noteworthy that, in line with Donti et al. (2021), we also investigate the performance of IPM-LSTM and baseline algorithms on smaller-scale convex QPs. Interested readers are directed to Appendix D for details. ", "page_idx": 6}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/9b4f58bc162166bc921ccd8a201ef1123741bb8c30ef80a4e16fb93ed857b68f.jpg", "table_caption": ["Table 1: Computational results on convex QPs. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "We ran IPM-LSTM and all baseline algorithms on the test set \u201cConvex QPs (RHS)\u201d, and we reported their computational results, which were averaged across 833 instances. The results are presented in Table 1. We denote this experiment by \u201cEnd-to-End\u201d for convenience. The columns labeled \u201cMax Ineq.\u201d, \u201cMean Ineq.\u201d, \u201cMax Eq.\u201d, and \u201cMean Eq.\u201d denote the maximum and mean violations for inequalities and equalities, respectively. The columns \u201cObj.\u201d and \u201cTime (s)\u201d represent the final primal objective and the runtime in seconds. Both OSQP and IPOPT solved these instances to guaranteed optimality, with OSQP being significantly more efficient due to its specialization as a QP-specific solver. All L2O baseline algorithms returned solutions very quickly. However, solutions generated by NN and PDL exhibited significant constraint violations. While the solutions from DC3 and DeepLDE were nearly feasible, they corresponded to inferior objective values. On the other hand, LOOP-LC produced feasible and near-optimal solutions, whereas H-Proj generated feasible solutions but with larger objective values. Solutions identified by IPM-LSTM showed mild constraint violations but yielded superior objective values very close to the optimal values. Clearly, IPM-LSTM effectively balances feasibility and optimality in the returned solutions. This comes at the cost of longer runtime compared to the L2O baseline algorithms, as the baselines typically employ simple multi-layer perceptrons, whereas IPM-LSTM utilizes a neural network with several dozen LSTM cells. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Since IPM-LSTM is designed to provide interior point optimizers with high-quality initial points, we fed the returned primal-dual solution pair to IPOPT and reported the performance in Table 1. For comparison, we also provided IPOPT with initial points generated from other L2O algorithms. The columns labeled \u201cIte.\u201d and \u201cTime (s)\u201d under \u201cIPOPT (warm-start)\u201d indicate the number of iterations and solver time, respectively, while the column \u201cTotal Time (s)\u201d represents the cumulative time for running both the L2O algorithms and IPOPT. The final column, \u201cGain (Ite/Time)\u201d, shows the reduction in iteration number and solution time, with the default IPOPT iteration number listed in the \u201cIte.\u201d column for reference. When initial solutions from IPM-LSTM and most L2O baseline algorithms (except DeepLDE) were used, IPOPT converged with fewer iterations and reduced solution time. Notably, IPM-LSTM achieved the most significant reduction in iterations, from 12.5 to 7.2, and decreased the average solver time from 0.642 seconds to 0.37 seconds. Including the computational time for IPM-LSTM, the total runtime was 0.545 seconds, reflecting a $15.1\\%$ reduction in time. It is worth noting that while IPM-LSTM did not yield the maximum solution time reduction, this was due to its relatively high computational expense. ", "page_idx": 7}, {"type": "text", "text": "To our knowledge, there is no existing representation learning approach for general convex QPs. Since the aforementioned L2O baseline algorithms depend on specific representations of QPs, they are not applicable to \u201cConvex QPs (ALL)\u201d. Therefore, we only provide results for OSQP, IPOPT, and IPM-LSTM. We also report computational results averaged across 833 instances in the test set \u201cConvex QPs (ALL)\u201d, presented in Table 1. The results demonstrate that IPM-LSTM can identify high-quality solutions for general convex QPs, and using these solutions as initial points can reduce iterations by $35.7\\%$ and solution time by $7.5\\%$ . ", "page_idx": 7}, {"type": "text", "text": "Convex QCQPs. We now turn to convex QCQPs with both equaltity and inequality constraints: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\min_{x\\in\\mathbb{R}^{n}}}&{\\frac{1}{2}x^{\\top}Q_{0}x+p_{0}^{\\top}x}\\\\ {\\mathrm{s.t.}\\quad}&{x^{\\top}Q_{j}x+p_{j}^{\\top}x\\leq q_{j}\\quad\\qquad j=1,\\cdots,l}\\\\ &{p_{j}^{\\top}x=q_{j}\\quad\\qquad\\qquad j=l+1,\\cdots\\,,m}\\\\ &{x_{i}^{L}\\leq x_{i}\\leq x_{i}^{U}\\quad\\qquad\\qquad i=1,\\cdots\\,,n}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $Q_{j}\\in\\mathbb{S}_{+}^{n}$ , $p_{j}\\in\\mathbb{R}^{n}$ , $q_{j}\\in\\mathbb{R}$ , $x_{i}^{L}\\in\\mathbb{R}\\cup\\{-\\infty\\}$ and $x_{i}^{U}\\in\\mathbb{R}\\cup\\{\\infty\\}$ . Similar to our experiments on convex $\\mathrm{QPs}$ , we also consider two groups of convex QCQPs, each with 200 variables, 100 inequality constraints, and 100 equality constraints. The first group (denoted as \u201cConvex QCQPs (RHS)\u201d) is generated as described in Liang et al. (2023), with perturbations only to the right-hand sides of the equality constraints. The second group (denoted as \u201cConvex QCQPs (ALL)\u201d) considers perturbations to all parameters. We also refer readers to Appendix $\\mathrm{D}$ for computational experiments on smaller-sized convex QCQPs. ", "page_idx": 7}, {"type": "text", "text": "We omit OSQP and LOOP-LC since the former cannot handle QCQPs, while the latter is only applicable to linearly constrained problems. We evaluate IPM-LSTM and compare it against the remaining baseline algorithms. The computational results are reported in Table 2. Again, solutions produced by NN and PDL exhibit significant constraint violations, while those from DC3 and H-Proj are of high quality in terms of feasibility and optimality. Once more, the solutions produced by DeepLDE were deemed feasible but exhibited inferior objective values. Conversely, our approach, IPM-LSTM, produced solutions with superior objective values albeit with minor infeasibility. Compared to the baseline algorithms, utilizing solutions from IPM-LSTM to warm-start IPOPT resulted in the most substantial reduction in iterations. ", "page_idx": 7}, {"type": "text", "text": "As the aforementioned L2O baseline algorithms are not applicable to \u201cConvex QCQPs (ALL)\u201d, we only report computational results for IPOPT and IPM-LSTM in Table 2. The IPM-LSTM approach produced high-quality approximate solutions to convex QCQPs, and warm-starting IPOPT with these solutions accelerated IPOPT by $11.4\\%$ , with a $33.1\\%$ reduction in iterations. ", "page_idx": 7}, {"type": "text", "text": "Non-convex QPs. We now consider non-convex $\\mathrm{QPs}$ of exactly the same form as (8) but with $Q_{0}$ being indefinite. We take 8 representative non-convex QPs from the datasets Globallib and ", "page_idx": 7}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/c44ee7ac880c243088efbc5d8c98c1650c19b32bad7695681e0cd8c529a2e2f5.jpg", "table_caption": ["Table 2: Computational results on convex QCQPs. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "RandQP (Chen and Burer, 2012), each with up to 50 variables and 20 constraints, and perturb the relevant parameters for instance generation. Details can be found in Appendix D.2. ", "page_idx": 8}, {"type": "text", "text": "Among all the baselines, only IPOPT is applicable to these general non-convex QPs. Hence, we report computational results for IPOPT and IPM-LSTM in Table 3. IPOPT solved these instances to local optimality, while IPM-LSTM identified high-quality approximate solutions very efficiently. Using these primal-dual approximations to warm-start IPOPT resulted in an iteration reduction of up to $63.9\\%$ and a solution time reduction of up to $70.5\\%$ . ", "page_idx": 8}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/2682a938f6929d02fe4bc06b83c2beb95c2bce387908795d18e53f40532eaf94.jpg", "table_caption": ["Table 3: Computational results on non-convex QPs. "], "table_footnote": ["Max Vio. denotes the maximum constraint violation. "], "page_idx": 8}, {"type": "text", "text": "Simple non-convex programs. Following the approach outlined in Donti et al. (2021), we consider a set of simple non-convex programs where the linear objective term in (8) is substituted with $p_{0}^{\\top}\\sin(x)$ . These instances were generated using the same methodology as Donti et al. (2021). We subject these problems to evaluation using both IPM-LSTM and baseline algorithms. Once again, the computational results underscore the high-quality solutions obtained by IPM-LSTM and its superior warm-starting capability. Detailed results are provided in Appendix D.4. ", "page_idx": 8}, {"type": "text", "text": "4.3 Performance Analysis of IPM-LSTM ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In Assumption 1, we posit that the linear systems (3) can be solved with an acceptable residual (Condition (5)) and that the solutions are properly bounded (Condition (6)). Although the LSTM network cannot guarantee the satisfaction of these conditions, we empirically assess the validity of Assumption 1 in IPM-LSTM. We plot the progress of $\\left\\|J^{k}y^{k}+F^{k}\\right\\|,\\stackrel{\\cdot}{\\eta}\\left[\\left(z^{k}\\right)^{\\top}x^{k}\\right]/n,\\left\\|y^{k}\\right\\|$ , and $\\left\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\right\\|$ as the IPM iterations increase in Figu re 3(a) and 3 (b). Condition (5)  is m ostly s atisfied except d uring the first few iterations, while Condition (6) is strictly satisfied across all IPM iterations. To assess the precision of the approximate solutions as the LSTM time steps increase, we plot the progress of the residual for linear systems (3) in Figure 3(c). At IPM iteration $k$ , the residual decreases monotonically towards 0 as the LSTM time steps increase, indicating that LSTM networks can produce high-quality approximate solutions to system (3). The approximation quality improves with the number of IPM iterations. As shown in Figure 3(d), the primal objective decreases monotonically towards the optimal value with increasing IPM iterations, empirically demonstrating the convergence of IPM-LSTM. Note that the condition number $\\kappa((J^{k})^{\\top}J^{\\dot{k}})$ becomes quite large in the later IPM iterations, which can adversely affect the performance of LSTM networks in obtaining approximations to systems (3). Consequently, we terminate IPM-LSTM after a finite number of iterations. Further analysis regarding the number of IPM iterations and LSTM time steps is presented in Appendix D.5. Additionally, we include the performance of IPM-LSTM under various hyperparameter settings in Appendix D.5. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "image", "img_path": "9c3IiAWeiN/tmp/b33677f44537bb490cd22b833e9976aa94aeb440e676843f700b9bc48fc5b706.jpg", "img_caption": ["Figure 3: The performance analysis of IPM-LSTM on a convex QP (RHS). "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "5 Limitations and Conclusions ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we present a learning-based IPM called IPM-LSTM. Specifically, we propose approximating solutions of linear systems in IPMs by solving least square problems using trained LSTM networks. We demonstrate that IPMs with this approximation procedure still converge. The solutions returned by IPM-LSTM are used to warm-start interior point optimizers. Our computational experiments on various types of NLPs, including general QPs and QCQPs, showcase the effectiveness of IPM-LSTM and its ability to accelerate IPOPT. Although IPM-LSTM generates high-quality primal-dual solutions, it is relatively computationally expensive due to the utilization of multi-cell LSTM networks. In future endeavors, we aim to investigate the efficacy of employing low-complexity neural networks to approximate solutions of linear systems within IPMs. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by the National Key R&D Program of China under grant 2022YFA1003900. Jinxin Xiong and Akang Wang also gratefully acknowledge support from the National Natural Science Foundation of China (Grant No. 12301416), the Shenzhen Science and Technology Program (Grant No. RCBS20221008093309021), the Guangdong Basic and Applied Basic Research Foundation (Grant No. 2024A1515010306) and Longgang District Special Funds for Science and Technology Innovation (LGKCSDPT2023002). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Patrick R Amestoy, Iain S Duff, Jean-Yves L\u2019Excellent, and Jacko Koster. Mumps: a general purpose distributed memory sparse solver. In International Workshop on Applied Parallel Computing, pages 121\u2013130. Springer, 2000. ", "page_idx": 9}, {"type": "text", "text": "Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. Learning to learn by gradient descent by gradient descent. Advances in neural information processing systems, 29, 2016.   \nKyri Baker. Learning warm-start points for ac optimal power flow. In 2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP), pages 1\u20136. IEEE, 2019.   \nStefania Bellavia. Inexact interior-point method. Journal of Optimization Theory and Applications, 96:109\u2013121, 1998.   \nYoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial optimization: a methodological tour d\u2019horizon. European Journal of Operational Research, 290(2):405\u2013421, 2021.   \nJieqiu Chen and Samuel Burer. Globally solving nonconvex quadratic programming problems via completely positive programming. Mathematical Programming Computation, 4(1):33\u201352, 2012.   \nTianlong Chen, Xiaohan Chen, Wuyang Chen, Howard Heaton, Jialin Liu, Zhangyang Wang, and Wotao Yin. Learning to optimize: A primer and a benchmark. Journal of Machine Learning Research, 23(189):1\u201359, 2022a.   \nXiaohan Chen, Jialin Liu, and Wotao Yin. Learning to optimize: A tutorial for continuous and mixed-integer optimization. Science China Mathematics, pages 1\u201372, 2024.   \nZiang Chen, Jialin Liu, Xinshang Wang, and Wotao Yin. On representing linear programs by graph neural networks. In The Eleventh International Conference on Learning Representations, 2022b.   \nMung Chiang. Nonconvex optimization for communication networks. Advances in Applied Mathematics and Global Optimization: In Honor of Gilbert Strang, pages 137\u2013196, 2009.   \nAntonio J Conejo and Luis Baringo. Power system operations, volume 14. Springer, 2018.   \nGregory Dexter, Agniva Chowdhury, Haim Avron, and Petros Drineas. On the convergence of inexact predictorcorrector methods for linear programming. In International Conference on Machine Learning, pages 5007\u20135038. PMLR, 2022.   \nFrederik Diehl. Warm-starting ac optimal power flow with graph neural networks. In 33rd Conference on Neural Information Processing Systems (NeurIPS 2019), pages 1\u20136, 2019.   \nPriya L Donti, David Rolnick, and J Zico Kolter. Dc3: A learning method for optimization with hard constraints. In International Conference on Learning Representations, 2021.   \nStanley C Eisenstat and Homer F Walker. Globally convergent inexact newton methods. SIAM Journal on Optimization, 4(2):393\u2013422, 1994.   \nFerdinando Fioretto, Terrence WK Mak, and Pascal Van Hentenryck. Predicting ac optimal power flows: Combining deep learning and lagrangian dual methods. In Proceedings of the AAAI conference on artificial intelligence, volume 34, pages 630\u2013637, 2020.   \nAnders Forsgren. On warm starts for interior methods. In System Modeling and Optimization: Proceedings of the 22nd IFIP TC7 Conference held from July 18\u201322, 2005, in Turin, Italy 22, pages 51\u201366. Springer, 2006.   \nMaxime Gasse, Simon Bowly, Quentin Cappart, Jonas Charfreitag, Laurent Charlin, Didier Ch\u00e9telat, Antonia Chmiela, Justin Dumouchelle, Ambros Gleixner, Aleksandr M Kazachkov, et al. The machine learning for combinatorial optimization competition (ml4co): Results and insights. In NeurIPS 2021 competitions and demonstrations track, pages 220\u2013231. PMLR, 2022.   \nKarol Gregor and Yann LeCun. Learning fast approximations of sparse coding. In Proceedings of the 27th international conference on international conference on machine learning, pages 399\u2013406, 2010.   \nChen Greif, Erin Moulding, and Dominique Orban. Bounds on eigenvalues of matrices arising from interior-point methods. SIAM Journal on Optimization, 24(1):49\u201383, 2014.   \nJiayu Han, Wei Wang, Chao Yang, Mengyang Niu, Cheng Yang, Lei Yan, and Zuyi Li. FRMNet: A Feasibility Restoration Mapping Deep Neural Network for AC Optimal Power Flow. IEEE Transactions on Power Systems, pages 1\u201311, 2024. ISSN 0885-8950, 1558-0679. doi: 10.1109/TPWRS.2024.3354733. URL https://ieeexplore.ieee.org/document/10411984/.   \nQingyu Han, Linxin Yang, Qian Chen, Xiang Zhou, Dong Zhang, Akang Wang, Ruoyu Sun, and Xiaodong Luo. A gnn-guided predict-and-search framework for mixed-integer linear programming. In The Eleventh International Conference on Learning Representations, 2023.   \nWanjun Huang, Xiang Pan, Minghua Chen, and Steven H Low. Deepopf-v: Solving ac-opf problems efficiently. IEEE Transactions on Power Systems, 37(1):800\u2013803, 2021.   \nHongseok Kim et al. Self-supervised equality embedded deep lagrange dual for approximate constrained optimization. arXiv preprint arXiv:2306.06674, 2023.   \nDP Kingma. Adam: a method for stochastic optimization. In Int Conf Learn Represent, 2014.   \nBingheng Li, Linxin Yang, Yupeng Chen, Senmiao Wang, Qian Chen, Haitao Mao, Yao Ma, Akang Wang, Tian Ding, Jiliang Tang, et al. Pdhg-unrolled learning-to-optimize method for large-scale linear programming. In Forty-first International Conference on Machine Learning, 2024.   \nMeiyi Li, Soheil Kolouri, and Javad Mohammadi. Learning to solve optimization problems with hard linear constraints. IEEE Access, 2023.   \nEnming Liang, Minghua Chen, and Steven Low. Low complexity homeomorphic projection to ensure neuralnetwork solution feasibility for optimization over (non-) convex set. In Conference on Parsimony and Learning (Recent Spotlight Track), 2023.   \nJialin Liu, Xiaohan Chen, Zhangyang Wang, Wotao Yin, and HanQin Cai. Towards constituting mathematical structures for learning to optimize. In International Conference on Machine Learning, pages 21426\u201321449. PMLR, 2023.   \nTianhao Liu, Shanwen Pu, Dongdong Ge, and Yinyu Ye. Learning to pivot as a smart expert. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 38, pages 8073\u20138081, 2024.   \nKaifeng Lv, Shunhua Jiang, and Jian Li. Learning gradient descent: Better generalization and longer horizons. In International Conference on Machine Learning, pages 2247\u20132255. PMLR, 2017.   \nYurii Nesterov and Arkadii Nemirovskii. Interior-point polynomial algorithms in convex programming. SIAM, 1994.   \nJorge Nocedal and Stephen J Wright. Numerical optimization. Springer, 1999.   \nXiang Pan, Minghua Chen, Tianyu Zhao, and Steven H. Low. Deepopf: A feasibility-optimized deep neural network approach for ac optimal power flow problems. IEEE Systems Journal, 17(1):673\u2013683, 2023. doi: 10.1109/JSYST.2022.3201041.   \nSeonho Park and Pascal Van Hentenryck. Self-supervised primal-dual learning for constrained optimization. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 4052\u20134060, 2023.   \nChendi Qian, Didier Ch\u00e9telat, and Christopher Morris. Exploring the power of graph neural networks in solving linear optimization problems. In International Conference on Artificial Intelligence and Statistics, pages 1432\u20131440. PMLR, 2024.   \nDaniel Ruiz. A scaling algorithm to equilibrate both rows and columns norms in matrices. Technical report, CM-P00040415, 2001.   \nStefan Schaal and Christopher G Atkeson. Learning control in robotics. IEEE Robotics & Automation Magazine, 17(2):20\u201329, 2010.   \nB. Stellato, G. Banjac, P. Goulart, A. Bemporad, and S. Boyd. OSQP: an operator splitting solver for quadratic programs. Mathematical Programming Computation, 12(4):637\u2013672, 2020. doi: 10.1007/s12532-020-00179-2. URL https://doi.org/10.1007/s12532-020-00179-2.   \nAndreas W\u00e4chter and Lorenz T Biegler. On the implementation of an interior-point fliter line-search algorithm for large-scale nonlinear programming. Mathematical programming, 106:25\u201357, 2006.   \nYong Yu, Xiaosheng Si, Changhua Hu, and Jianxun Zhang. A review of recurrent neural networks: Lstm cells and network architectures. Neural computation, 31(7):1235\u20131270, 2019.   \nSihan Zeng, Youngdae Kim, Yuxuan Ren, and Kibaek Kim. QCQP-Net: Reliably Learning Feasible Alternating Current Optimal Power Flow Solutions Under Constraints, January 2024. URL http://arxiv.org/abs/ 2401.06820. arXiv:2401.06820 [cs, math] version: 1.   \nLing Zhang and Baosen Zhang. Learning to solve the ac optimal power flow via a lagrangian approach. In 2022 North American Power Symposium (NAPS), pages 1\u20136, 2022. doi: 10.1109/NAPS56150.2022.10012237. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A Implementation Details ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The general NLP considered in this paper can be formulated as: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{c l l}{\\displaystyle\\operatorname*{min}_{x\\in\\mathbb R^{n}}}&{f(x),\\ }\\\\ {\\mathrm{~s.t.~}}&{g(x)+s=0}&\\\\ &{h(x)=0}&\\\\ &{s\\geq0}&\\\\ &{x_{i}\\geq x_{i}^{L},\\quad}&{i\\in I^{L}}\\\\ &{x_{i}\\leq x_{i}^{U},\\quad}&{i\\in I^{U}}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $f:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}$ , $g:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{m_{\\mathrm{ineq}}}$ , and $h:\\mathbb{R}^{n}\\rightarrow\\mathbb{R}^{m_{\\mathrm{cq}}}$ are twice continuously differentiable functions; $s\\,\\in\\,\\mathbb{R}^{m_{\\mathrm{ineq}}}$ is the slack variable corresponding to the inequality constraints; $I^{L}=\\{i:$ $x_{i}^{L}\\neq-\\infty\\}$ and $I^{U}=\\{i:x_{i}^{U}\\neq\\infty\\}$ . The Lagrangian function is defined as: ", "page_idx": 12}, {"type": "equation", "text": "$$\nL\\left(x,\\eta,\\lambda,s,z^{L},z^{U}\\right):=f(x)+\\eta^{\\top}g(x)+\\lambda^{\\top}h(x)-\\sum_{i\\in I^{L}}z_{i}^{L}\\left(x_{i}-x_{i}^{L}\\right)-\\sum_{i\\in I^{U}}z_{i}^{U}\\left(x_{i}^{U}-x_{i}\\right).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\eta\\in\\mathbb{R}^{m_{\\mathrm{ineq}}}$ and $\\lambda\\in\\mathbb{R}^{m_{\\mathrm{cq}}}$ are the corresponding dual variables. The perturbed KKT conditions are given by: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\{\\begin{array}{l l}{\\nabla f(x)+\\eta^{\\top}\\nabla g(x)+\\lambda^{\\top}\\nabla h(x)-z^{L}+z^{U}=0}\\\\ {g(x)+s=0}\\\\ {\\operatorname{diag}(\\eta)\\mathrm{diag}(s)e=\\mu e}\\\\ {\\eta\\geq0,s\\geq0,h(x)=0}\\\\ {z_{i}^{L}(x_{i}-x_{i}^{L})=\\mu,i\\in I^{L}}\\\\ {z_{i}^{U}(x_{i}^{U}-x_{i})=\\mu,i\\in I^{U}}\\\\ {z_{i}^{L}\\geq0,i\\in I^{L},z_{i}^{U}\\geq0,i\\in I^{U}}\\\\ {x_{i}\\geq x_{i}^{L},i\\in I^{L},x_{j}\\leq x_{j}^{U},j\\in I^{U}}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "The nonlinear system extracted from the KKT conditions is represented as: ", "page_idx": 12}, {"type": "equation", "text": "$$\nF(x,\\eta,\\lambda,s,z^{L},z^{U})=0\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where ", "page_idx": 12}, {"type": "equation", "text": "$$\nF(x,\\eta,\\lambda,s,z^{L},z^{U})=\\left(\\begin{array}{c}{{\\nabla f(x)+\\eta^{\\top}\\nabla g(x)+\\lambda^{\\top}\\nabla h(x)-z^{L}+z^{U}}}\\\\ {{g(x)+s}}\\\\ {{\\mathrm{diag}(\\eta)\\mathrm{diag}(s)e-\\mu e}}\\\\ {{h(x)}}\\\\ {{\\mathrm{diag}(z^{L})\\mathrm{diag}(x-x^{L})e-\\mu e}}\\\\ {{\\mathrm{diag}(z^{U})\\mathrm{diag}(x^{U}-x)e-\\mu e}}\\end{array}\\right)=0\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "The Jacobian matrix of $F(x,\\eta,\\lambda,s,z^{L},z^{U})$ is: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\iota(x,\\eta,\\lambda,s,z^{L},z^{U}):=\\left(\\begin{array}{c c c c c c}{\\nabla^{2}L(x,\\eta,\\lambda,z^{L},z^{U}),}&{\\nabla g(x)^{\\top},}&{\\nabla h(x)^{\\top},}&{0,}&{-I,}&{I}\\\\ {\\nabla g(x),}&{0,}&{0,}&{I,}&{0,}&{0}\\\\ {0,}&{\\mathrm{~diag}(s),}&{0,}&{\\mathrm{~diag}(\\eta),}&{0,}&{0}\\\\ {\\nabla h(x),}&{0,}&{0,}&{0,}&{0,}&{0}\\\\ {\\mathrm{~diag}(z^{L}),}&{0,}&{0,}&{0,}&{\\mathrm{~diag}(x-x^{L}),}&{0}\\\\ {-\\mathrm{diag}(z^{U}),}&{0,}&{0,}&{0,}&{0,}&{\\mathrm{~diag}(x^{U}-x)}\\end{array}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\nabla^{2}L\\left(x,\\eta,\\lambda,s,z^{L},z^{U}\\right)=\\nabla^{2}f(x)+\\sum_{i=1}^{m_{\\mathrm{ineq}}}\\eta_{i}\\nabla^{2}g_{i}(x)+\\sum_{j=1}^{m_{\\mathrm{eq}}}\\lambda_{j}\\nabla^{2}h_{j}(x)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "For convenience, we define the updates of primal and dual variables as: ", "page_idx": 12}, {"type": "equation", "text": "$$\ny:=\\left(\\begin{array}{c}{\\Delta x}\\\\ {\\Delta\\eta}\\\\ {\\Delta\\lambda}\\\\ {\\Delta s}\\\\ {\\Delta z^{L}}\\\\ {\\Delta z^{U}}\\end{array}\\right).\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Then the linear system obtained from one-step Newton\u2019s method is shown as: ", "page_idx": 13}, {"type": "equation", "text": "$$\nJ\\left(x,\\eta,\\lambda,s,z^{L},z^{U}\\right)y=-F\\left(x,\\eta,\\lambda,s,z^{L},z^{U}\\right)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Initial points. If dual variables $\\eta,\\,s,\\,z^{L}$ , and $z^{U}$ exist, their initial values are set to 1. If the dual variable $\\lambda$ exists, its initial value is set to 0. The initial value of the primal variable $x$ can be formulated as: ", "page_idx": 13}, {"type": "equation", "text": "$$\nx_{i}=\\left\\{\\begin{array}{l l}{z_{i}^{L}+1,}&{i\\in I^{L}\\backslash I^{U}}\\\\ {z_{i}^{U}-1,}&{i\\in I^{U}\\backslash I^{L}}\\\\ {(z_{i}^{L}+z_{i}^{U})/2,}&{i\\in I^{L}\\cap I^{U}}\\\\ {0,}&{\\mathrm{otherwise}.}\\end{array}\\right..\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The step length. If the dual variables $\\eta,\\,s,\\,z^{L}$ and $z^{U}$ exist, their step lengths are chosen as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha^{\\eta}:=\\operatorname*{sup}\\big\\{\\alpha\\in\\left(0,1\\big]\\mid\\eta_{i}+\\alpha\\Delta\\eta_{i}\\geq0,i=1,\\cdots\\,,m_{\\mathrm{ineq}}\\big\\}}\\\\ &{\\alpha^{s}:=\\operatorname*{sup}\\big\\{\\alpha\\in\\left(0,1\\big]\\mid s_{i}+\\alpha\\Delta s_{i}\\geq0,i=1,\\cdots\\,,m_{\\mathrm{ineq}}\\big\\}}\\\\ &{\\quad\\alpha^{z^{L}}:=\\operatorname*{sup}\\big\\{\\alpha\\in\\left(0,1\\big]\\mid z_{i}^{L}+\\alpha\\Delta z_{i}^{L}\\geq0,i\\in I^{L}\\right\\}}\\\\ &{\\alpha^{z^{U}}:=\\operatorname*{sup}\\big\\{\\alpha\\in\\left(0,1\\big]\\mid z_{i}^{U}+\\alpha\\Delta z_{i}^{U}\\geq0,i\\in I^{U}\\big\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "If $x$ is bounded, the step sizes for $x$ and $\\lambda$ are chosen to be equal as: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\alpha^{\\lambda},\\alpha^{x}:=\\operatorname*{sup}\\left\\lbrace\\alpha\\in(0,1]\\mid x_{i}+\\alpha\\Delta x_{i}\\geq x_{i}^{L},i\\in I^{L};x_{i}+\\alpha\\Delta x_{i}\\leq x_{i}^{U},i\\in I^{U}\\right\\rbrace\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "If $x$ is unbounded but inequality constraints exist, the step lengths for $x$ and $\\lambda$ are chosen the same as the step length for $s$ . If $x$ is unbounded and there are no inequality constraints, the step lengths for $x$ and $\\lambda$ are chosen to be 1. In our experiments, additional line search procedures for step lengths, as described in Bellavia (1998), were not implemented in order to save computational time. ", "page_idx": 13}, {"type": "text", "text": "B Proof of Proposition 1 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Proof. Step 1. Let $\\delta>0$ , suppose that $(x^{k},\\lambda^{k},z^{k})\\in N_{\\delta}(x^{*},\\lambda^{*},z^{*}):=\\{(x,\\lambda,z)\\mid\\|(x,\\lambda,z)-$ $\\left(x^{*},\\lambda^{*},z^{*}\\right)\\parallel<\\delta\\}$ . Define $\\sigma:=\\operatorname*{min}\\{\\sigma^{k}\\}$ and $\\eta:=\\operatorname*{min}\\{\\eta^{k}\\}$ , where $\\sigma^{k}$ and $\\eta^{k}$ are chosen to satisfy the update rule (11) in Bellavia (1998). Then from the Assumption 1: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\|y^{k}\\|\\leq(1+\\sigma^{k}+\\eta^{k})\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "By using the steplength $\\alpha^{k}$ obtained from the line search method of Bellavia (1998) and defining: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\hat{\\eta}^{k}=1-\\alpha^{k}\\left(1-\\sigma^{k}-\\eta^{k}\\right)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "we obtain: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{l l l}{\\|p^{k}\\|}&{=}&{\\|\\alpha^{k}y^{k}\\|}\\\\ &{=}&{\\|\\frac{(1-\\hat{\\eta}^{k})\\alpha^{k}y^{k}}{1-(1-\\alpha^{k}(1-\\sigma^{k}-\\eta^{k}))}\\|}\\\\ &{=}&{\\frac{1-\\hat{\\eta}^{k}}{1-\\sigma^{k}-\\eta^{k}}\\|y^{k}\\|}\\\\ &{\\leq}&{(1-\\hat{\\eta}^{k})\\frac{1+\\sigma^{k}+\\eta^{k}}{1-\\sigma^{k}-\\eta^{k}}\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|}\\\\ &{\\leq}&{(1-\\hat{\\eta}^{k})\\Gamma\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\begin{array}{r}{\\Gamma\\,=\\,\\frac{1+\\eta_{\\mathrm{max}}}{1-\\eta_{\\mathrm{max}}}}\\end{array}$ , $(\\sigma^{k}+\\eta^{k})\\;\\in\\;(0,\\eta_{\\mathrm{max}})$ and $\\eta_{\\mathrm{max}}~\\in~(0,1)$ . Then, there exists a constant $\\Gamma$ independent of $k$ such that (24) holds, whenever $y^{k}$ is bounded by $(1+\\sigma^{k}+\\eta^{k})\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|$ . Hence, from Theorem 3.5 of Eisenstat and Walker (1994), it follows that $(x^{k},\\lambda^{k},z^{k})\\to(x^{*},\\lambda^{*},z^{*})$ . ", "page_idx": 13}, {"type": "text", "text": "Step 2. In this step, we aim to prove that the step size $\\alpha^{k}$ of the inexact IPM is bounded away from 0. Given that Assumption 1 is satisfied, it follows that $\\|J^{k}y^{k}+F^{k}\\|$ and $\\|y^{k}\\|$ are both bounded. Then we assume the first two equations of $F_{0}(x,\\lambda,z)$ are Lipschitz continuous gradient with constant $L$ . The remaining proofs are consistent with Theorem 3.2 in Bellavia (1998). ", "page_idx": 13}, {"type": "text", "text": "Step 3. The line search method of Bellavia (1998) enables $\\alpha^{k}$ to satisfy: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\|F_{0}(x^{k+1},\\lambda^{k+1},z^{k+1})\\|\\le(1-\\beta(1-\\hat{\\eta}^{k}))\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\beta\\in(0,1)$ . Therefore $\\{\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|\\}$ is decreasing and bounded, hence, it is convergent. Based on Assumption 1, (24) holds. Furthermore, we assume $\\left\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\right\\|\\neq0$ and $\\delta$ is chosen sufficiently small so that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|F_{0}(x_{2},\\lambda_{2},z_{2})-F_{0}(x_{1},\\lambda_{1},z_{1})-J(x_{1},\\lambda_{1},z_{1})[(x_{2}-x_{1})^{\\top},(\\lambda_{2}-\\lambda_{1})\\top,(z_{2}-z_{1})^{\\top}]^{\\top}\\|}\\\\ &{\\qquad\\qquad\\leq((1-\\beta)/\\Gamma)\\|[(x_{2}-x_{1})^{\\top},(\\lambda_{2}-\\lambda_{1})^{\\top},(z_{2}-z_{1})^{\\top}]^{\\top}\\|}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "is satisfied, whenever $(x_{1},\\lambda_{1},z_{1}),(x_{2},\\lambda_{2},z_{2})\\in N_{2\\delta}(x^{*},\\lambda^{*},z^{*})$ . Define ", "page_idx": 14}, {"type": "equation", "text": "$$\nS:=\\operatorname*{sup}_{(x,\\lambda,z)\\in N_{\\delta}(x^{*},\\lambda^{*},z^{*})}\\|F_{0}(x,\\lambda,z)\\|,\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "then based on Lemma 5.1 of Eisenstat and Walker (1994), the loop of backtracking line search of Bellavia (1998) will terminate with ", "page_idx": 14}, {"type": "equation", "text": "$$\n1-\\hat{\\eta}^{k}\\geq\\operatorname*{min}(\\alpha^{k}(1-\\sigma^{k}-\\eta^{k}),\\theta\\delta/(\\Gamma S))\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\theta\\in(0,1)$ is a control parameter. This implies that the series $\\sum_{k=0}^{\\infty}(1-\\hat{\\eta}^{k})$ is divergent. By applying (25) iteratively, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|\\leq(1-\\beta(1-\\hat{\\eta}^{k-1}))\\|F_{0}(x^{k-1},\\lambda^{k-1},z^{k-1})\\|}\\\\ &{\\qquad\\qquad\\leq\\|F_{0}(x^{0},\\lambda^{0},z^{0})\\|\\displaystyle\\prod_{0\\leq j<k}(1-\\beta(1-\\hat{\\eta}^{j}))}\\\\ &{\\qquad\\qquad\\leq\\|F_{0}(x^{0},\\lambda^{0},z^{0})\\|\\mathrm{exp}(-\\beta\\displaystyle\\sum_{0\\leq j<k}(1-\\hat{\\eta}^{j})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $\\beta>0$ and $1-\\hat{\\eta}^{j}\\ge0$ , the divergence of series $\\sum_{j=0}^{\\infty}(1-\\hat{\\eta}^{j})$ implies $\\|F_{0}(x^{k},\\lambda^{k},z^{k})\\|\\to0$ . ", "page_idx": 14}, {"type": "text", "text": "C Datasets and Parameter setting ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The key hyperparameters for each task, including $K,T$ , and the hidden dimension of LSTM networks, are listed in Table 4. Generally, IPM-LSTM demonstrates improved performance with larger values of $K$ and $T$ , although this comes at the cost of increased computational time. Increasing $T$ could enhance the quality of solutions to the linear system. In this study, $K$ is maintained at the same value for both training and testing. Further analysis can be found in Appendix D.5. ", "page_idx": 14}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/17dd86691ac2c463be64c41bd13c34b4ad58fb3e0de9180d5f131d347d23a4e2.jpg", "table_caption": ["Table 4: Instance information and hyperparameter settings. "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "D Experimental Results ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "D.1 Convex QPs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The performance on convex QPs, including \u201cConvex QPs (RHS)\u201d and \u201cConvex QPs (ALL)\u201d, each instance with 100 variables, 50 inequality constraints, and 50 equality constraints, is shown in Table 5. From Table 5, IPM-LSTM provided the best objective value with acceptable constraint violations. ", "page_idx": 15}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/bcc80de33935f47e47b62a139017be6bbe98b0062ce1362932d5ae08c11cd538.jpg", "table_caption": ["Table 5: Computational results on convex QPs "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Also, IPM-LSTM achieved the most significant reduction in iterations when the returned primal-dual solution pair is utilized for warm-starting IPOPT. ", "page_idx": 15}, {"type": "text", "text": "D.2 Non-convex QPs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "For non-convex QPs (8), all the non-zero elements without any special physical meaning, such as all zeros or all ones, are multiplied by a value generated from a uniform distribution in the range [0.8, 1.2]. If the original elements are integers, we will perform an additional rounding operation. We use \u201cp\u201d and \u201cr\u201d to represent these operations, respectively, and use \u201cc\u201d to denote the case without perturbation. The detailed perturbation rules for each instance are shown as: ", "page_idx": 15}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/ba47c0f5611561dab773ce4e1ee7a4a2919db724b06b6a392d8315d1ee6c1564.jpg", "table_caption": ["Table 6: Perturbation rules. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "D.3 Convex QCQPs ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The performance on convex QPs, including \u201cConvex QCQPs (RHS)\u201d and \u201cConvex QCQPs (ALL)\u201d, each instance with 100 variables, 50 inequality constraints, and 50 equality constraints, is shown in Table 7. From Table 7, IPM-LSTM provided the best objective value with acceptable constraint violations. Also, IPM-LSTM achieved the most significant reduction in iterations when the returned primal-dual solution pair is utilized for warm-starting IPOPT. ", "page_idx": 15}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/7884c7befb0f838f5e92928d65fe41dbc0051d67e1c340c620fc030914f61260.jpg", "table_caption": ["Table 7: Computational results on convex QCQPs "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "D.4 A Simple Non-convex Program ", "text_level": 1, "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l l}{\\displaystyle\\min_{x\\in\\mathbb{R}^{n}}}&{\\frac{1}{2}x^{\\top}Q_{0}x+p_{0}^{\\top}\\sin(x)}\\\\ {\\mathrm{s.t.}}&{p_{j}^{\\top}x\\leq q_{j}}&&{j=1,\\cdots,l}\\\\ &{p_{j}^{\\top}x=q_{j}}&&{j=l+1,\\cdots,m}\\\\ &{x_{i}^{L}\\leq x_{i}\\leq x_{i}^{U}}&&{i=1,\\cdots,n}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The performance on simple non-convex programs (30), including \u201cNon-convex Programs (RHS)\u201d and \u201cNon-convex Programs (ALL)\u201d, each instance with 100/200 variables, 50/100 inequality constraints, and 50/100 equality constraints, is shown in Table 8. From this table, IPM-LSTM provided the best objective value with acceptable constraint violations. Also, IPM-LSTM achieved the most significant reduction in iterations when the returned primal-dual solution pair is utilized for warm-starting IPOPT. ", "page_idx": 16}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/727168540f9abce96677baae4537d913b17c090d5b8bf0b02922a2eb96437d67.jpg", "table_caption": ["Table 8: Computational results on non-convex programs "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "D.5 Performance Analysis ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "D.5.1 The Number of LSTM Time Steps ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The number of LSTM time steps $T$ is a key hyperparameter which decides the performance-efficiency trade-off of IPM-LSTM. To illustrate this, we conduct experiments on a convex QP (RHS) problem with 100 variables, 50 inequality constraints, and 50 equality constraints, investigating the quality of approximate solutions under different LSTM time step settings. As shown in Table 9, the IPM-LSTM with deeper LSTM architectures generally yields better approximate solutions (with lower objective values, smaller constraint violation and better warm-start performance) but with longer computational time. Specifically, the IPM-LSTM with 60 and 70 time steps achieves most significant reductions in warm-starting iteration count and total runtime, respectively. However, taking into account the end-to-end solution time, we have opted to set $T$ to 50 in our experiments. At each IPM iteration, as the LSTM network depth increases, $\\|J^{k}y^{k}+F^{k}\\|$ decreases (see Figure 5(a)). This indicates an improvement in the quality of solutions to the linear systems. Furthermore, the corresponding IPM-LSTM converges faster (e.g., fewer IPM iterations) when the LSTM network becomes deeper (see Figure 4). ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/698fbb92b29022779a8f94a74c691ee0884f808e14dafad8a667c5e46ecf7d4b.jpg", "table_caption": ["Table 9: Computational results on convex QPs (RHS) under different LSTM time steps. "], "table_footnote": [], "page_idx": 17}, {"type": "image", "img_path": "9c3IiAWeiN/tmp/8d719cbbd966faf563eafc8f66c04a76d5f2de7d032ddacc5ee7f227e32a9aff.jpg", "img_caption": ["Figure 4: The objective values returned by IPM-LSTM at each IPM iteration on a convex QP (RHS). "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "D.5.2 Linear System Solutions ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In order to provide an more specific presentation of how accurately the LSTM performs, we report the detailed values of Figure 3(a) in Table 10. We can conclude that, $\\|J^{k}y^{k}+\\mathring{F}^{k}\\|$ is roughly in the same order of magnitude as $\\eta[(z^{k})^{\\top}x^{k}]/n$ at each IPM iteration. To reveal the relationship between the error of the linear system solution $\\|J^{k}y^{k}+F^{k}\\|$ and the LSTM time steps, hidden dimensions, training sizes and test sizes, we conduct experiments on representative convex QP (RHS) problems with 100 variables, 50 inequality constraints, and 50 equality constraints, and the results are included in Figure 5. ", "page_idx": 17}, {"type": "text", "text": "\u2022 In Figure 5(a), with the number of LSTM time steps increasing, $\\|J^{k}y^{k}+F^{k}\\|$ decreases. \u2022 In Figure 5(b), we consider LSTMs with 25, 50, 75, and 100 hidden dimensions and find that an LSTM with a hidden dimension of 50, as used in our manuscript, generally performs the best (e.g., the smallest $\\|J^{k}y^{k}+F^{k}\\|)$ . \u2022 In Figure 5(c), a larger training set is more beneficial for model training. The training set size in our experiment is 8,334, and the error in solving the linear system $\\|J^{k}y^{k}+F^{\\tilde{k}}\\|$ is smaller compared with the case of 4,000 or 6,000 training samples. ", "page_idx": 17}, {"type": "text", "text": "\u2022 As shown by Figure 5(d), the number of samples in the test set does not affect the performance of LSTM for solving linear systems. ", "page_idx": 18}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/4cce488be8076e514add57f2615f96c669d701d4931e4145baf01c795411d9a2.jpg", "table_caption": ["Table 10: The detailed values of Figure 3(a). "], "table_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "9c3IiAWeiN/tmp/a1e972920b34ee0b4d17278af64ff2864a0135f5e36d522dd9a067242e0f967e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 5: The relationship between the error of the linear system solution with different parameter settings of LSTM. ", "page_idx": 18}, {"type": "text", "text": "We take the log of the y-axis in Figure 3(a) and plot it in Figure 6(a). Roughly speaking, $\\|J^{k}y^{k}+$ $F^{k}\\|$ is smaller than $\\bar{\\eta}\\bar{[(z^{k})^{\\top}x^{k}]/{n}}$ in the first $40\\;\\mathrm{IPM}$ iterations, while $\\|J^{k}y^{k}+F^{k}\\|$ surpasses $\\eta[(\\hat{z}^{k})^{\\top}x^{k}]/n$ in the later IPM iterations. We increase the number of LSTM time steps and report the computational results in Figure 6(b). From Figure 6, we can claim that with the number of LSTM time steps increasing, $\\|J^{k}\\bar{y^{k}}+F^{\\dot{k}}\\|$ becomes smaller. ", "page_idx": 18}, {"type": "image", "img_path": "9c3IiAWeiN/tmp/388c2bbc93cbdad8f6760aec4ff0fb511c39e03dd773156b7bc0bb94d9bf02ff.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Figure 6: Equation (5) under different LSTM time steps. The first number in the parentheses denotes the number of IPM iterations, while the second one represents the number of LSTM time steps. ", "page_idx": 18}, {"type": "text", "text": "D.5.3 Condition Numbers ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The LSTM approach for solving linear systems is negatively affected by their large condition numbers. To demonstrate this, we consider the least squares problem ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{y\\in\\mathbb{R}^{l}}\\phi(y):=\\frac{1}{2}\\left\\|J^{k}y+F^{k}\\right\\|^{2}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "We utilize a first-order method (e.g., steepest descent method) to minimize $\\phi(y)$ and achieve a linear convergence rate (Nocedal and Wright, 1999), i.e., ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\phi\\left(y^{t+1}\\right)-\\phi\\left(y^{\\star}\\right)\\leq\\left(1-\\frac{2}{\\left(\\kappa\\left(J^{k}\\right)\\right)^{2}+1}\\right)^{2}\\left(\\phi\\left(y^{t}\\right)-\\phi\\left(y^{\\star}\\right)\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "As we discussed in Section 3.3, since solving linear systems via LSTM networks emulates iterative first-order methods, thus the value of $\\kappa\\left(J^{k}\\right)$ affects the performance of LSTM networks. However, LSTM networks can empirically achieve a faster convergence rate than traditional first-order algorithms when solving the same least squares problems as shown in the computational studies (Section 3.1) of Andrychowicz et al. (2016). In order to alleviate the effect of large condition numbers, as discussed in Section 3.3, we have employed preconditioning techniques. To illustrate its effect, we conduct experiments on the simple non-convex programs, and report $\\kappa\\left(J^{k}\\right)$ and their values after preconditioning (in parantheses) across several IPM iterations (e.g., $1^{s t}$ , $10^{t h}$ , $20^{t h}$ , $50^{t h}$ , $100^{t h\\cdot}$ ) in Table 11. We can conclude that the condition numbers $\\kappa\\left(J^{k}\\right)$ remain within reasonable magnitudes even during the later IPM iterations, and are significantly reduced after applying the preconditioning technique. ", "page_idx": 19}, {"type": "table", "img_path": "9c3IiAWeiN/tmp/85ecfa3d12f0b33d5ce1b470b0b82c18ec1872529ecfe3d03abf3902b0654df3.jpg", "table_caption": ["Table 11: The condition numbers of simple non-convex programs in IPM iteration process. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Please refer to Abstract and Section 1. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 20}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Justification: Please refer to Section 5. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 20}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: Please refer to Section 3.2 and Appendix B. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 21}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: Please refer to Section 3. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 21}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Please refer to Section 4.1 for data. Our code will be available to public once our work is accepted, as mentioned in Section 1. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 22}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Please refer to Section 4.1 and Appendix C. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 22}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: Please refer to Section 4.2. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Please refer to Section 4.1. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 23}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The research presented in this paper adheres to the NeurIPS Code of Ethics. Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 23}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: There are many potential societal consequences of our work, none of which we feel must be specifically highlighted here. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our paper does not present any such risks. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 24}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Please refer to Section 4.1. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 24}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 25}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: Our paper does not release new assets. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 25}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: Our paper does not involve any crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 25}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: Our paper does not involve any crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 25}]