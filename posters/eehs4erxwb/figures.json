[{"figure_path": "EehS4erXWB/figures/figures_0_1.jpg", "caption": "Figure 1: Two examples of PC assembly. Given a pair of PCs, the proposed method BITR transforms the source PC (red) to align the reference PC (blue). The input PCs may be overlapped (a) or non-overlapped (b).", "description": "This figure shows two examples of point cloud (PC) assembly, a task where the goal is to find a rigid transformation that aligns one PC to another.  The left side displays the input point clouds: (a) shows an example where the point clouds partially overlap, (b) shows an example where they do not overlap. The red point cloud represents the source PC, and the blue represents the reference PC.  The right side shows the results of applying the proposed method (BITR) \u2013 the red point clouds have been transformed to align with the blue reference point clouds.", "section": "1 Introduction"}, {"figure_path": "EehS4erXWB/figures/figures_0_2.jpg", "caption": "Figure 1: Two examples of PC assembly. Given a pair of PCs, the proposed method BITR transforms the source PC (red) to align the reference PC (blue). The input PCs may be overlapped (a) or non-overlapped (b).", "description": "This figure shows two examples of point cloud (PC) assembly, a task where the goal is to find the rigid transformation that aligns one PC (the source) to another (the reference).  The figure illustrates two scenarios: (a) where the source and reference PCs overlap, and (b) where they do not. In both cases, the proposed method, BITR, transforms the red (source) PC to match the blue (reference) PC.", "section": "1 Introduction"}, {"figure_path": "EehS4erXWB/figures/figures_1_1.jpg", "caption": "Figure 2: An overview of BITR. The input 3-D PCs X and Y are first merged into a 6-D PC Z by concatenating the extracted key points X and Y. Then, Z is fed into a SE(3) \u00d7 SE(3)-transformer to obtain equivariant features \u00ee, tx and ty. These features are finally projected to SE(3) as the output.", "description": "This figure shows the architecture of the proposed method, SE(3)-bi-equivariant transformer (BITR).  It illustrates the two main steps: 1) Point cloud merge, where the input point clouds X and Y are merged into a 6D point cloud Z by extracting and concatenating keypoints.  2) Feature extraction, where the 6D point cloud Z is passed through a SE(3) x SE(3)-transformer to extract equivariant features (r\u0302, tx, ty). Finally, these features are projected into the SE(3) group to obtain the final output, which is the rigid transformation.", "section": "4 SE(3)-bi-equivariant transformer"}, {"figure_path": "EehS4erXWB/figures/figures_7_1.jpg", "caption": "Figure 3: The results of BITR on a test example (a), and the swapped (b), scaled (d) and rigidly perturbed (c) inputs. The red, yellow and blue colors represent the source, transformed source and reference PCs respectively.", "description": "This figure shows four point cloud assembly results from the BITR model. The first image shows the original input point clouds (source and reference).  The subsequent three images show results from the same input point clouds but with different transformations:  swapped (source and reference PCs are exchanged), rigidly perturbed (source and reference are rotated and translated), and scaled (source and reference PCs are scaled). The consistency of the results across these transformations demonstrates the model's robustness to changes in input orientation, position, and scale.", "section": "6.2 A proof-of-concept example"}, {"figure_path": "EehS4erXWB/figures/figures_8_1.jpg", "caption": "Figure 4: Assembly results on the airplane dataset. * denotes methods which require the true canonical poses of the input PCs.", "description": "This figure shows the performance comparison of different methods for the airplane dataset.  The x-axis represents the PC size ratio (the percentage of the raw PC kept by cropping). The y-axis on the left shows the rotation error (\u2206r), and the y-axis on the right shows the translation error (\u2206t).  The methods compared include GEO, ROI, NSM, LEV, BITR, and BITR+ICP. The asterisk (*) indicates that the methods require the true canonical poses of the input PCs.  The results indicate that BITR outperforms other methods when the PC size ratio is small (less overlap), and its performance is close to the best methods when the PC size ratio is large (more overlap), especially with ICP refinement.", "section": "6.3 Results on ShapeNet"}, {"figure_path": "EehS4erXWB/figures/figures_8_2.jpg", "caption": "Figure 5: A result of BITR on assembling a motorbike and a car.", "description": "This figure shows an example of the BITR method assembling two point clouds representing a motorbike and a car.  The goal is to find the rigid transformation that aligns the source point cloud (the car) to the reference point cloud (the motorbike).  This illustrates the capability of BITR to handle non-overlapped point clouds, a significant challenge in point cloud assembly.", "section": "6.3.2 Inter-class assembly"}, {"figure_path": "EehS4erXWB/figures/figures_9_1.jpg", "caption": "Figure 6: The results of BITR on bowl-placing. We present the input PCs (left panel) and the assembled results (right panel). BITR can generally place the bowl (red) on the plate (green) (a), but it sometimes produces unrealistic results where collision exists (b).", "description": "This figure shows two examples of the results from applying the BITR model to the bowl-placing task.  The left panels show the initial configurations of the bowl (red) and plate (green). The right panels show the results of applying the BITR algorithm. The first example demonstrates a successful placement where the bowl is correctly positioned on the plate. The second example shows a failure case where the bowl is incorrectly positioned, resulting in a collision. The gray points in the figures represent the environment.", "section": "6.6 Results on visual manipulation"}, {"figure_path": "EehS4erXWB/figures/figures_26_1.jpg", "caption": "Figure 3: The results of BITR on a test example (a), and the swapped (b), scaled (d) and rigidly perturbed (c) inputs. The red, yellow and blue colors represent the source, transformed source and reference PCs respectively.", "description": "This figure shows the results of applying BITR to a test example and its variations. The first image (a) displays the original result, while (b), (c), and (d) show results for swapped, rigidly perturbed, and scaled inputs respectively.  The consistency of the results across these different scenarios visually demonstrates the method's robustness to variations in input data and its SE(3)-bi-equivariance, swap-equivariance and scale-equivariance.", "section": "6.2 A proof-of-concept example"}, {"figure_path": "EehS4erXWB/figures/figures_27_1.jpg", "caption": "Figure 8: The training process of BITR on the airplane dataset with s = 0.4. All metrics are measured on the validation set.", "description": "This figure shows the training curves of the proposed BITR model on the airplane dataset. The curves display the loss function, rotation error (\u0394r), and translation error (\u0394t) over 10000 training epochs.  The metrics are calculated using the validation set to monitor the model's performance and prevent overfitting.  The curves show a general downward trend, indicating that the model is learning and improving its accuracy throughout the training process. The slight fluctuations in the curves may represent the model's progress in learning complex features or might be due to the stochastic nature of the training process.", "section": "6.3 Results on ShapeNet"}, {"figure_path": "EehS4erXWB/figures/figures_27_2.jpg", "caption": "Figure 9: The PC registration results of BITR on the airplane dataset. The input PCs are represented using light colors, and the learned key points are represented using dark and large points.", "description": "This figure shows four examples of point cloud registration using the proposed BITR method. Each subfigure shows the input point clouds (in light colors) and the 32 key points (in dark colors). The goal is to align the red point cloud (source) to the blue point cloud (reference). Different values of the size ratio s (0.7, 0.5, 0.4, and 0.3) are used in different subfigures.  These different size ratios demonstrate that the method can handle various degrees of overlap between the point clouds.", "section": "6.3 Results on ShapeNet"}, {"figure_path": "EehS4erXWB/figures/figures_27_3.jpg", "caption": "Figure 4: Assembly results on the airplane dataset. * denotes methods which require the true canonical poses of the input PCs.", "description": "This figure shows the performance comparison of different methods for the airplane dataset in terms of PC size ratio. The x-axis represents the PC size ratio (s), which varies from 0.3 to 0.7.  The y-axis represents the rotation error (\u2206r).  The figure shows that BITR outperforms all baseline methods when s is small (s \u2264 0.5). When s is large (s > 0.5), BITR performs worse than GEO, but still outperforms other baselines. However, since BITR results are sufficiently close to optimum (\u2206r \u2264 20), ICP refinement can lead to improved results that are close to GEO. The methods marked with '*' require the true canonical poses of the input PCs.", "section": "6.3 Results on ShapeNet"}, {"figure_path": "EehS4erXWB/figures/figures_28_1.jpg", "caption": "Figure 11: Results of reassembling wine bottle fragments. We compare the proposed BITR with DGL [44], NSM [7] and LEV [38]. Zoom in to see the details.", "description": "This figure compares the results of reassembling wine bottle fragments using four different methods: DGL, NSM, LEV, and the proposed BITR method.  Each method is shown assembling the same fragments, allowing a visual comparison of their performance. The results highlight BITR's superior performance in this task.", "section": "6.4 Results on fragment reassembly"}, {"figure_path": "EehS4erXWB/figures/figures_29_1.jpg", "caption": "Figure 1: Two examples of PC assembly. Given a pair of PCs, the proposed method BITR transforms the source PC (red) to align the reference PC (blue). The input PCs may be overlapped (a) or non-overlapped (b).", "description": "This figure shows two examples of point cloud (PC) assembly using the proposed method, BITR. In (a), two overlapped PCs representing the same object are shown before and after alignment. In (b), two non-overlapped PCs are shown, also before and after alignment with BITR. The red PC represents the source PC that is transformed using BITR to align it with the blue reference PC.", "section": "1 Introduction"}, {"figure_path": "EehS4erXWB/figures/figures_29_2.jpg", "caption": "Figure 3: The results of BITR on a test example (a), and the swapped (b), scaled (d) and rigidly perturbed (c) inputs. The red, yellow and blue colors represent the source, transformed source and reference PCs respectively.", "description": "This figure shows the results of the proposed method, BITR, on a test example and three variations of the input.  (a) shows the original test example, (b) shows the result when the source and target point clouds are swapped, (c) shows the result when the inputs are randomly rotated and translated, and (d) shows the result when the inputs are scaled. The consistent results demonstrate the method's robustness to different input configurations and its equivariance properties.", "section": "6.2 A proof-of-concept example"}]