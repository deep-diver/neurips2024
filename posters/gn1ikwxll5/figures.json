[{"figure_path": "gN1iKwxlL5/figures/figures_3_1.jpg", "caption": "Figure 1: Illustration of the proposed DLL scheme. Given input data (A, b, H, h, c), a neural network first predicts y \u2208 Rn. Next, a conic projection layer computes a conic-feasible \u0177 \u2208 K*, which is then completed into a full dual-feasible solution (\u0177, \u1e91). The model is trained in a self-supervised fashion, by updating the weights \u03b8 to maximize the Lagrangian dual bound L(\u0177).", "description": "The figure illustrates the Dual Lagrangian Learning (DLL) scheme. It shows how a neural network, given input data (A, b, H, h, c), predicts a dual variable y. This y is then projected onto the feasible region K* using a conic projection layer to produce a conic feasible \u0177. Then, a dual completion procedure completes \u0177 into a full dual feasible solution (\u0177, \u1e91). The model is trained by maximizing the Lagrangian dual bound L(\u0177) using a gradient step. The figure also highlights the three fundamental building blocks of DLL: (1) dual conic completion, (2) conic projection layers, and (3) a self-supervised learning algorithm.", "section": "4 Dual Lagrangian Learning (DLL)"}, {"figure_path": "gN1iKwxlL5/figures/figures_20_1.jpg", "caption": "Figure 1: Illustration of the proposed DLL scheme. Given input data (A, b, H, h, c), a neural network first predicts y \u2208 Rn. Next, a conic projection layer computes a conic-feasible \u0177 \u2208 K*, which is then completed into a full dual-feasible solution (\u0177, 2). The model is trained in a self-supervised fashion, by updating the weights \u03b8 to maximize the Lagrangian dual bound L(\u0177).", "description": "The figure illustrates the Dual Lagrangian Learning (DLL) methodology.  It shows the process of taking input data (A, b, H, h, c), using a neural network to predict a dual variable (y), projecting it onto a feasible space (\u0177 \u2208 K*), completing it to a full dual-feasible solution (\u0177, z), and then training the model to maximize the Lagrangian dual bound, using a self-supervised learning approach.", "section": "4 Dual Lagrangian Learning (DLL)"}, {"figure_path": "gN1iKwxlL5/figures/figures_20_2.jpg", "caption": "Figure 2: Production planning instances: convergence plots of average Lagrangian dual bound on training and validation sets for DLL and DC3 models, as a function of the number of training epochs.", "description": "This figure shows the convergence plots of the average Lagrangian dual bound for both DLL and DC3 models on the training and validation sets.  The plots illustrate the Lagrangian dual bound as a function of the number of training epochs for different problem sizes (n=10, 20, 50, 100, 200, 500).  It highlights the faster convergence speed of DLL compared to DC3, especially evident in larger problems.", "section": "5 Numerical experiments"}]