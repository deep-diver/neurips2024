[{"type": "text", "text": "Local Differential Privacy for Mixtures of Experts ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Anonymous Author(s)   \nAffiliation   \nAddress   \nemail ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "1 We introduce a new approach to the mixture of experts model that consists in   \n2 imposing local differential privacy on the gating mechanism. This is theoretically   \n3 justified by statistical learning theory. Notably, we provide generalization bounds   \n4 specifically tailored for mixtures of experts, leveraging the one-out-of- ${\\mathbf{\\nabla}}n$ gating   \n5 mechanism rather than the more common $n$ -out-of- ${\\boldsymbol{n}}$ mechanism. Moreover,   \n6 through experiments, we show that our approach improves the generalization   \n7 ability of mixtures of experts. ", "page_idx": 0}, {"type": "text", "text": "8 1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "9 Mixtures of experts, initially introduced by Jacobs et al. [1991], have found widespread use in   \n10 modeling sequential data, including applications in classification, regression, pattern recognition and   \n11 feature selection tasks (St\u00e4dler et al. [2010] and Khalili and Lin [2013]). One of the fundamental   \n12 motivations behind mixtures of experts is their ability to break down complex problems into more   \n13 manageable sub-problems, potentially simplifying the overall task. The structure of these models is   \n14 well suited to capturing unobservable heterogeneity in the data generation process, dealing with this   \n15 problem by splitting the data into homogeneous subsets (with the gating network) and associating   \n16 each subset with an expert. This intuitive architecture has led to significant interest in mixture of   \n17 experts models, resulting in a wealth of research (Yuksel et al. [2012]), ranging from simple mixtures   \n18 of experts ( Jacobs et al. [1991], Jordan and Jacobs [1993]) to sparsely gated models (Shazeer et al.   \n19 [2017]). Moreover, this architecture has inspired the development of various other models, such as   \n20 switch transformers (Fedus et al. [2022]). However, despite the considerable attention mixtures of   \n21 experts have received, advancements in their theoretical analysis have been relatively limited. Azran   \n22 and Meir [2004] proved data-dependent risk bounds for mixtures of experts (with the $n$ -out-of- $n$   \n23 gating mechanism) using Rademacher complexity, but they exhibit a dependence on the complexity   \n24 of the class of gating networks and the sum of the complexities of the expert classes, which reflects   \n25 the complex structure of mixtures of experts but unfortunately leads to potentially large bounds. We   \n26 are not aware of other work proving generalization bounds specifically tailored to mixtures of experts.   \n27 To make theoretical progress, we utilize a well-known privacy-preserving technique called Local   \n28 Differential Privacy (LDP). It was initially introduced by Dwork [2006] and has since been widely   \n29 used to preserve privacy for individual data points as in Kasiviswanathan et al. [2010]. This is   \n30 achieved by introducing stochasticity in algorithm outputs to control their dependence on specific   \n31 inputs. This stochasticity is generally quantified by a positive real number \u03f5. In this case, we write   \n32 $\\epsilon$ -LDP instead of just LDP. The parameter $\\epsilon$ quantifies the level of privacy protection in the local   \n33 differential privacy mechanism. A smaller value indicates stronger privacy protection, which requires   \n34 the addition of more noise.   \n35 In this work, we exploit this noise for regularization in our models by imposing the $\\epsilon_{}$ -LDP condition   \n36 on their gating networks. This method allows us to leverage the numerous benefits of the most   \n37 complex architectures, such as neural networks, without compromising theoretical guarantees on risk.   \n38 By relying on LDP, we offer tight theoretical guarantees on the risk of mixtures of experts models,   \n39 provided with the one-out-of- $^{\\cdot n}$ gating mechanism. Unlike the very few existing guarantees, these   \n40 bounds depend only logarithmically on the number of experts we have, and the complexity of the   \n41 gating network only appears in our bounds through the parameter $\\epsilon$ of the LDP condition. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "42 2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "43 Let $\\mathcal{X}$ be the instance space, $\\boldsymbol{\\wp}$ the label space, and $\\mathcal{V}^{\\prime}$ the output space (which can be different   \n44 from $\\boldsymbol{{y}}$ ). As is usual in supervised learning, we assume that data $(x,y)\\in\\mathcal{X}\\times\\mathcal{Y}$ are generated   \n45 independently from an unknown probability distribution $\\mathcal{D}$ . We consider a training set of $m$ examples   \n46 $\\bar{S}=\\bar{((x_{1},y_{1}),\\dots,(x_{m},y_{m}))}\\overset{\\cdot}{\\sim}\\mathcal{D}^{m}$ and a bounded loss function $\\ell\\colon\\mathcal{V}^{\\prime}\\times\\mathcal{V}\\rightarrow[0,1]$ . ", "page_idx": 1}, {"type": "text", "text": "47 2.1 Mixtures of experts ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "48 We consider classes $\\mathcal{H}_{i}$ of experts $h_{i}\\colon\\mathcal{X}\\rightarrow\\mathcal{Y}^{\\prime}$ for $i=1,\\hdots,n$ . Let $\\mathcal{G}$ be a set of gating functions   \n49 $\\mathbf{g}\\colon X\\to[0,1]^{n}$ such that, given any $x\\,\\in\\,{\\mathcal{X}}$ , we have that $\\textstyle\\sum_{i=1}^{n}g_{i}(x)\\,=\\,1$ , where $\\bar{g_{i}}(x)$ is the   \n50 $i$ -th component of $\\mathbf{g}(x)$ . This means that each gating function defines a probability distribution on   \n51 $[n]=\\{1,\\cdot\\cdot,n\\}$ for each $x\\in\\mathscr{X}$ , where $g_{i}(x)$ is the probability of $i$ .   \n52 In this work, a mixture of experts consists of $n$ experts, $\\mathbf{h}=\\left(h_{1},\\ldots,h_{n}\\right)\\in\\mathcal{H}_{1}\\times\\cdots\\times\\mathcal{H}_{n}$ , a   \n53 gating function $\\mathbf{g}\\in\\mathcal{G}$ and a gating mechanism that combines the outputs of the experts and the   \n54 output of the gating function to produce the final output. Our models use the stochastic one-out-of- $n$   \n55 gating mechanism, as described in Jacobs et al. [1991]. It is defined as follows: to make a prediction   \n56 with $\\begin{array}{r}{\\mathbf{\\bar{(g,h)}}\\in\\mathcal{G}\\times\\prod_{i=1}^{n}\\mathcal{H}_{i}}\\end{array}$ given an instance $x$ , draw $i\\sim\\mathbf{g}(x)$ and output $h_{i}(x)$ . This stochastic   \n57 predictor has risk and empirical risk defined by, respectively, ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\nR(\\mathbf{g},\\mathbf{h})=\\underset{(x,y)\\sim{\\cal D}}{\\mathbb{E}}\\underset{i\\sim\\mathbf{g}(x)}{\\mathbb{E}}\\ell(h_{i}(x),y),\\quad\\mathrm{and}\\quad R_{S}(\\mathbf{g},\\mathbf{h})=\\frac{1}{m}\\sum_{j=1}^{m}\\underset{i\\sim\\mathbf{g}(x_{j})}{\\mathbb{E}}\\ell(h_{i}(x_{j}),y_{j}).\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "58 The preference for the one-out-of- ${\\mathbf{\\nabla}}n$ gating mechanism over the $n$ -out-of- ${\\cdot n}$ mechanism in mixtures   \n59 of experts is justified by its ability to induce sparsity and noise, enhancing computational efficiency   \n60 and robustness to overftiting. This sparsity also offers scalability beneftis, particularly in large-scale   \n61 applications, where activating all experts for each input can lead to increased computational and   \n62 memory requirements as explained in Shazeer et al. [2017] and Jacobs et al. [1991]. Moreover, the   \n63 one-out-of- ${\\cdot n}$ mechanism is more amenable to certain kinds of theoretical analysis, including ours. ", "page_idx": 1}, {"type": "text", "text": "64 2.2 Local Differential Privacy ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "65 Definition 2.1. Let $\\mathcal{T}$ be a finite set, consider a mechanism that produces an output $i\\in\\mathcal{Z}$ , given an   \n66 input $x\\in\\mathscr{X}$ , with probability $\\mathbb{P}(i\\,|\\,x)$ , and let $\\epsilon$ be a nonnegative real number. Then, the mechanism   \n67 satisfies the $\\epsilon$ -Local Differential Privacy ( $\\mathbf{\\Xi}_{\\epsilon}$ -LDP) property if and only if ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{P}(i\\,|\\,x)\\leq e^{\\epsilon}\\,\\mathbb{P}(i\\,|\\,x^{\\prime})\\quad{\\mathrm{for~all~}}x,x^{\\prime}\\in{\\mathcal{X}}{\\mathrm{~and~all~}}i\\in{\\mathcal{Z}}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Unless stated otherwise, we assume that each $\\mathbf{g}\\in\\mathcal{G}$ satisfies $\\epsilon$ -LDP, for some fixed nonnegative real number $\\epsilon$ . Since we can interpret $\\mathbf{g}$ as a random mechanism that, given $x\\in\\mathscr{X}$ , selects $i\\in[n]$ with probability $g_{i}(x)$ , the condition of $\\epsilon$ -LDP amounts to the following: ", "page_idx": 1}, {"type": "equation", "text": "$$\ng_{i}(x)\\leq e^{\\epsilon}g_{i}(x^{\\prime})\\quad{\\mathrm{for~all~}}x,x^{\\prime}\\in\\mathcal{X}{\\mathrm{~and~all~}}i\\in[n].\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "68 Since $\\epsilon_{}$ -LDP is an important condition for all of our theoretical results, we provide a practical way   \n69 of obtaining gating functions satisfying $\\epsilon$ -LDP from an arbitrary set $\\mathcal{F}$ of bounded functions, in the   \n70 form of the following theorem.   \n71 Theorem 2.2. Let $b>0$ and $\\beta\\geq0$ be real numbers, and suppose that $\\mathcal{F}$ is a set of functions   \n72 $\\mathbf{f}:\\mathcal{X}\\to[-b,b]^{n}$ . Let $\\mathcal{G}$ be the set of functions $\\mathbf{g}:\\mathcal{X}\\rightarrow[0,1]^{n}$ defined by ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\ng_{i}(x)\\;=\\;\\frac{\\exp(\\beta f_{i}(x)+c_{i})}{\\sum_{k=1}^{n}\\exp(\\beta f_{k}(x)+c_{k})},\\quad w h e r e\\;\\mathbf{f}=(f_{1},\\ldots,f_{n})\\in\\mathcal{F}\\;a n d\\left(c_{1},\\ldots,c_{n}\\right)\\in\\mathbb{R}^{n}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "73 Then, each $\\mathbf{g}\\in\\mathcal{G}$ satisfies $4\\beta b$ -LDP. ", "page_idx": 1}, {"type": "text", "text": "74 Proof. The proof is obtained by performing simple calculations, bounding the ratio $g_{i}(x)/g_{i}(x^{\\prime})$ , for   \n75 all $x,x^{\\prime}\\in\\mathcal{X}$ and all $i\\in[n]$ . The detailed proof is given in Appendix A. \u53e3 ", "page_idx": 1}, {"type": "text", "text": "76 3 PAC-Bayesian bounds for mixtures of experts ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "To apply the PAC-Bayes theory, we need to add a level of stochasticity to our predictors: instead of training experts $h_{i}$ , we train probability measures $Q_{i}$ on each expert set $\\mathcal{H}_{i}$ . For convenience, we write $Q=Q_{1}\\otimes\\cdots\\otimes Q_{n}$ . Now, putting everything together, a mixture of experts $(\\mathbf{g},Q)$ makes predictions as follows: given $x\\in\\mathscr{X}$ , draw $i\\sim\\mathbf{g}(x)$ , then draw $h\\sim Q_{i}$ , and finally output $h(x)$ . Such a predictor has risk and empirical risk defined by, respectively, ", "page_idx": 2}, {"type": "equation", "text": "$$\nR(\\mathbf{g},Q)=\\underset{\\mathbf{h}\\sim Q}{\\mathbb{E}}R(\\mathbf{g},\\mathbf{h})\\quad\\mathrm{and}\\quad R_{S}(\\mathbf{g},Q)=\\underset{\\mathbf{h}\\sim Q}{\\mathbb{E}}R_{S}(\\mathbf{g},\\mathbf{h}).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "77 Notice that, though probability distributions have replaced the individual experts, there is no need to   \n78 define a probability distribution on the gating functions to get a PAC-Bayesian bound. Training a   \n79 single gating function will do, and, remarkably, Lemma 3.1 below shows that it can be obtained from   \n80 a very complicated function, such as a neural network, provided we impose $\\epsilon$ -LDP (for example, with   \n81 Theorem 2.2).   \n82 Finally, let us recall the notion of Kullback-Leibler $(K L)$ divergence. Given probability distributions   \n83 $Q_{i}$ and $P_{i}$ on $\\mathcal{H}_{i}$ , it is defined by ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "equation", "text": "$$\n\\operatorname{KL}(Q_{i}\\,\\|\\,P_{i})={\\left\\{\\!\\!\\!\\begin{array}{l l}{\\underbrace{\\mathbb{E}}_{h\\sim Q_{i}}\\ln{\\frac{d Q_{i}}{d P_{i}}}(h)}&{{\\mathrm{if~}}Q_{i}\\ll P_{i}}\\\\ {\\infty}&{{\\mathrm{otherwise,}}}\\end{array}\\!\\!\\right.}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "84 where $d Q_{i}/d P_{i}$ is a Radon-Nikodym derivative. ", "page_idx": 2}, {"type": "text", "text": "85 Lemma 3.1. We consider mixtures of experts as defined in section 2.1 and provided with the one  \n86 out-of- ${\\boldsymbol{n}}$ routing mechanism. Let $\\Delta:\\mathbb{R}^{\\hat{2}}\\rightarrow\\mathbb{R}$ be a convex function that is decreasing in its first   \n87 argument and increasing in its second argument, and let $\\epsilon$ be a nonnegative real number. Then, for   \n88 any $\\mathbf{g}\\in\\mathcal{G}$ that satisfies the $\\epsilon$ -LDP property, for any $Q=Q_{1}\\otimes\\cdot\\cdot\\otimes Q_{n}$ on $\\mathcal{H}_{1}\\times\\cdot\\cdot\\cdot\\times\\mathcal{H}_{n}$ , and for   \n89 any $x^{\\prime}\\in\\mathcal{X}$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Delta\\big(e^{\\epsilon}R_{S}(\\mathbf{g},Q),e^{-\\epsilon}R(\\mathbf{g},Q)\\big)\\leq\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\,\\Delta\\big(R_{S}(Q_{i}),R(Q_{i})\\big)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathtt{R}(Q_{i})=\\mathbb{E}_{x\\sim\\mathcal{D}}\\mathbb{E}_{h\\sim Q_{i}}\\,\\ell(h(x),y)\\;a n d\\;R_{S}(Q_{i})=\\frac{1}{m}\\sum_{j=1}^{m}\\mathbb{E}_{h\\sim Q_{i}}\\,\\ell(h(x_{j}),y_{j}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "91 Proof. Since the gating function satisfies $\\epsilon$ -LDP, we have that $e^{-\\epsilon}g_{i}(x^{\\prime})\\,\\leq\\,g_{i}(x)\\,\\leq\\,e^{\\epsilon}g_{i}(x^{\\prime})$ for   \n92 all $x,x^{\\prime}\\in\\mathcal{X}$ and all $i^{\\bar{}}\\in[n]$ . It follows that $e^{\\epsilon}R_{S}(\\mathbf{g},Q)\\geq\\mathbb{E}_{i\\sim\\mathbf{g}(x^{\\prime})}\\,R_{S}(Q_{i})$ and $e^{-\\epsilon}R({\\bf g},Q)\\le$   \n93 $\\mathbb{E}_{i\\sim\\mathbf{g}(x^{\\prime})}\\,R(Q_{i})$ . Given that $\\Delta$ is decreasing in its first argument and increasing in its second argument,   \n94 we find that ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\Delta\\big(e^{\\epsilon}R_{S}(\\mathbf{g},Q),e^{-\\epsilon}R(\\mathbf{g},Q)\\big)\\leq\\Delta\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R_{S}(Q_{i}),\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R(Q_{i})\\Big)\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "95 Since $\\Delta$ is a convex function, we can apply Jensen\u2019s inequality to the expression on the right-hand   \n96 side, yielding the desired result. \u53e3 ", "page_idx": 2}, {"type": "text", "text": "97 Different choices of function $\\Delta$ will allow us to obtain different PAC-Bayes bounds: ", "page_idx": 2}, {"type": "text", "text": "\u2022 Let $\\Delta(u,v)=v-u$ . This is compatible with typical PAC-Bayes bounds on the difference between the true and empirical risks.   \n\u2022 Given $\\lambda>1/2$ , let $\\Delta$ be defined by $\\begin{array}{r}{\\Delta(u,v)=v-\\frac{2\\lambda}{2\\lambda-1}u}\\end{array}$ 2\u03bb2\u03bb\u22121u. This choice is compatible with a Catoni-type bound, as we will see below.   \n\u2022 Let $\\Delta$ be defined by $\\Delta(u,v)\\;=\\;\\mathrm{kl}(u\\,\\Vert\\,v)\\;=\\;u\\ln\\frac{u}{v}\\,+\\,(1\\,-\\,u)\\ln\\frac{1-u}{1-v}$ . This choice is compatible with a Langford-Seeger-type bound. However, note that the function $\\Delta$ defined here does not quite obey the hypotheses of lemma 3.1. Indeed, it is only defined for $(u,v)\\in$ $[0,1]^{2}$ , and only has the right monotonicity properties on the set $\\{(u,\\dot{v})\\in[0,1]^{2}\\mid\\dot{u}\\leq\\dot{v}\\}$ . We can remedy those defects through small adjustments to the proof. ", "page_idx": 2}, {"type": "text", "text": "107 We prove a generalization bound of Catoni-type as an illustration of the machinery just described. ", "page_idx": 2}, {"type": "text", "text": "108 Theorem 3.2 (Theorem 2 in McAllester [2013]). Let $\\delta\\in(0,1)$ and $\\lambda>1/2$ . Fix $i\\in[n]$ , and let $P_{i}$   \n109 be a probability measure on $\\mathcal{H}_{i}$ (chosen without seeing the training data). Then, with probability at   \n110 least $1-\\delta$ over the draws of $S$ , for all probability measures $Q_{i}$ on $\\mathcal{H}_{i}$ , we have that ", "page_idx": 3}, {"type": "equation", "text": "$$\nR(Q_{i})\\leq{\\frac{2\\lambda}{2\\lambda-1}}{\\bigg(}R_{S}(Q_{i})+{\\frac{\\lambda}{m}}{\\Big(}\\mathrm{KL}(Q_{i}\\,\\|\\,P_{i})+\\ln{\\frac{1}{\\delta}}{\\Big)}{\\bigg)}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "111 Theorem 3.3. Let $\\delta\\in(0,1)$ , $\\epsilon\\geq0$ , and $\\lambda>1/2$ . For each $i\\in[n]$ , let $P_{i}$ be a probability measure   \n112 on $\\mathcal{H}_{i}$ (chosen without seeing the training data). Then, with probability at least $1-\\delta$ over the draws   \n113 of $S$ , for all probability measures $Q=Q_{1}\\otimes\\cdot\\cdot\\otimes Q_{n}$ on $\\mathcal{H}$ , all $\\mathbf{g}\\in\\mathcal{G}$ that satisfy $\\epsilon{-}L D P,$ and all   \n114 $x^{\\prime}\\in\\mathcal{X}$ , we have that ", "page_idx": 3}, {"type": "equation", "text": "$$\nR(\\mathbf{g},Q)\\leq\\frac{2\\lambda e^{\\epsilon}}{2\\lambda-1}\\Bigg(e^{\\epsilon}R_{S}(\\mathbf{g},Q)+\\frac{\\lambda}{m}\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\mathrm{KL}(Q_{i}\\,\\|\\,P_{i})+\\ln\\frac{n}{\\delta}\\Big)\\Bigg).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "115 Proof. By $n$ applications of Theorem 3.2, we have that, for each $i\\in[n]$ , with probability at least   \n116 $1-\\delta/n$ , for all $Q_{i}$ , ", "page_idx": 3}, {"type": "equation", "text": "$$\nR(Q_{i})\\leq{\\frac{2\\lambda}{2\\lambda-1}}{\\bigg(}R_{S}(Q_{i})+{\\frac{\\lambda}{m}}{\\Big(}\\mathrm{KL}(Q_{i}\\,\\|\\,P_{i})+\\ln{\\frac{n}{\\delta}}{\\Big)}{\\bigg)}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "117 We can make all these inequalities (for each $i\\in[n])$ hold simultaneously with a union bound. Now,   \n118 applying Lemma 3.1 with $\\begin{array}{r}{\\Delta(u,v)=v-\\frac{2\\lambda}{2\\lambda-1}u}\\end{array}$ , we find that, with probability at least $1-\\delta$ , for all   \n119 $Q$ , all $\\mathbf{g}\\in\\mathcal{G}$ and all $x^{\\prime}\\in\\mathcal{X}$ , we have that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{e^{-\\epsilon}R(\\mathbf{g},Q)-\\frac{2\\lambda e^{\\epsilon}}{2\\lambda-1}R_{S}(\\mathbf{g},Q)\\leq\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\Big(R(Q_{i})-\\frac{2\\lambda}{2\\lambda-1}R_{S}(Q_{i})\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\frac{2\\lambda^{2}}{(2\\lambda-1)m}\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\mathrm{KL}(Q_{i}\\|P_{i})+\\ln\\frac{n}{\\delta}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "120 We also give a bound of Langford-Seeger type, since they are generally recognized as among the   \n121 tightest PAC-Bayes bounds available, and to prove the flexibility of our approach.   \n122 Theorem 3.4. Let $\\delta\\in(0,1)$ , $\\epsilon\\geq0$ , and $m\\geq8.$ . For each $i\\in[n]$ , let $P_{i}$ be a probability measure   \n123 on $\\mathcal{H}_{i}$ (chosen without seeing the training data). Then, with probability at least $1-\\delta$ over the draws   \n124 of $S$ , for all probability measures $Q=Q_{1}\\otimes\\cdot\\cdot\\otimes Q_{n}$ on $\\mathcal{H}$ , all $\\mathbf{g}\\in\\mathcal{G}$ that satisfy $\\epsilon$ -LDP, and all   \n125 $x^{\\prime}\\in\\mathcal{X}$ , we have that, either ${\\cal R}({\\bf g},Q)<e^{2\\epsilon}{\\cal R}_{S}({\\bf g},Q)$ , or ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname{kl}(e^{\\epsilon}R_{S}(\\mathbf{g},Q)\\,\\|\\,e^{-\\epsilon}R(\\mathbf{g},Q))\\leq\\frac{1}{m}\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\,\\operatorname{KL}(Q_{i}\\,\\|\\,P_{i})+\\ln\\frac{2n\\sqrt{m}}{\\delta}\\Big).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "126 Proof. The proof, which is similar to that of Theorem 3.3, is available in Appendix A. ", "page_idx": 3}, {"type": "text", "text": "127 3.1 Comparison with other bounds ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "128 Very few generalizations bound tailored specifically to mixtures of experts appear in the literature,   \n129 and those we could find do not apply to mixtures of experts with the one-out-of- ${\\cdot n}$ gating mechanism.   \n130 We can, however, compare our bounds to those obtained by naively applying generic PAC-Bayes   \n131 generalization bounds to mixtures of experts. In this case, we need to consider classifiers of the form   \n132 $\\bar{(Q_{\\mathcal{G}},Q)}$ , where $Q_{\\mathcal{G}}$ is a probability measure on $\\mathcal{G}$ , and $Q=Q_{1}\\otimes\\cdots\\otimes Q_{n}$ is a probability measure   \n133 on $\\mathcal{H}_{1}\\times\\cdot\\cdot\\cdot\\times\\mathcal{H}_{n}$ as before. Then, note that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{KL}(Q_{\\mathcal{G}}\\otimes Q_{1}\\otimes\\cdot\\cdot\\cdot\\otimes Q_{n}\\,\\|\\,P_{\\mathcal{G}}\\otimes P_{1}\\otimes\\cdot\\cdot\\cdot\\otimes P_{n})=\\mathrm{KL}(Q_{\\mathcal{G}}\\,\\|\\,P_{\\mathcal{G}})+\\sum_{i=1}^{n}\\mathrm{KL}(Q_{i}\\,\\|\\,P_{i}).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "134 This means that a generic PAC-Bayes bound applied to mixtures of experts will depend on the sum of   \n135 the KL divergences corresponding to the gating functions and each of the experts. Obviously, this   \n136 sum could be very large. By imposing $\\epsilon$ -LDP to the gating functions as in our approach, we can   \n137 eliminate the stochasticity associated to the gating functions, and rid our bounds of the (potentially   \n138 very large) ${\\mathrm{KL}}(Q_{\\mathcal{G}}\\parallel P_{\\mathcal{G}})$ term. Instead, it is $\\epsilon$ -LDP which controls our gating functions to ensure   \n139 generalization. Furthermore, our bounds replace the sum of the KL divergences of the experts by   \n140 a $\\mathbf{g}(\\boldsymbol{x}^{\\prime})$ -weighted average, which means we can have many more experts with almost no penalty   \n141 from the theoretical point of view. Indeed, our bounds only depend on the number $n$ of experts   \n142 logarithmically, through the use of the union bound. ", "page_idx": 3}, {"type": "text", "text": "143 4 Rademacher bounds for mixtures of experts ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "144 Let us start with a slight modification of Lemma 3.1. ", "page_idx": 4}, {"type": "text", "text": "145 Lemma 4.1. We consider mixtures of experts as defined in section 2.1 and provided with the one  \n146 out-of- ${\\boldsymbol{n}}$ routing mechanism. Let $\\Delta:\\mathbb{R}^{\\hat{2}}\\rightarrow\\mathbb{R}$ be a convex function that is decreasing in its first   \n147 argument and increasing in its second argument, and let $\\epsilon$ be a nonnegative real number. Then, for   \n148 any $\\mathbf{g}\\in\\mathcal{G}$ that satisfies the $\\epsilon$ -LDP property, for any $\\mathbf{h}\\in\\mathcal{H}$ , and for any $x^{\\prime}\\in\\mathcal{X}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\Delta\\big(e^{\\epsilon}R_{S}({\\bf g},{\\bf h}),e^{-\\epsilon}R({\\bf g},{\\bf h})\\big)\\leq\\operatorname*{\\mathbb{E}}_{i\\sim{\\bf g}(x^{\\prime})}\\Delta\\big(R_{S}(h_{i}),R(h_{i})\\big)\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "149 where $R(h_{i})=\\mathbb{E}_{x\\sim\\mathcal{D}}\\,\\ell(h_{i}(x),y)$ and $\\begin{array}{r}{R_{S}(h_{i})=\\frac{1}{m}\\sum_{j=1}^{m}\\ell(h_{i}(x_{j}),y_{j}).}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "150 Proof. The proof is similar to that of Lemma 3.1 and is provided in Appendix A. ", "page_idx": 4}, {"type": "text", "text": "151 Let us now recall the following definition. ", "page_idx": 4}, {"type": "text", "text": "152 Definition 4.2 (Rademacher complexity). Given a space $\\mathcal{H}$ of predictors, a loss function $\\ell$ , and a   \n153 data generating distribution $\\mathcal{D}$ , the Rademacher complexity $\\mathcal{R}(\\ell\\circ\\mathcal{H})$ is defined by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{R}(\\ell\\circ\\mathcal{H})\\;=\\;\\underset{S\\sim\\mathcal{D}^{m}}{\\mathbb{E}}\\:\\underset{\\sigma}{\\mathbb{E}}\\:\\underset{h\\in\\mathcal{H}}{\\operatorname*{sup}}\\:\\frac{1}{m}\\sum_{j=1}^{m}\\sigma_{j}\\ell(h(x_{j}),y_{j}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "154 where $\\pmb{\\sigma}=(\\sigma_{1},\\ldots,\\sigma_{m})$ is distributed uniformly on $\\{-1,1\\}^{m}$ . ", "page_idx": 4}, {"type": "text", "text": "155 Our main theorem will make use of the following well-known risk bound. ", "page_idx": 4}, {"type": "text", "text": "156 Theorem 4.3 (Basic Rademacher risk bound). Given a $[0,1]$ -valued loss function $\\ell$ , with probability   \n157 at least $1-\\delta,$ , for all $h\\in\\mathcal H$ , we have that ", "page_idx": 4}, {"type": "equation", "text": "$$\nR(h)\\ \\leq R_{S}(h)+2\\mathcal{R}(\\ell\\circ\\mathcal{H})+\\sqrt{\\frac{2\\ln(2/\\delta)}{m}}\\,.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "158 Theorem 4.4. Let $\\delta\\in(0,1)$ and $\\epsilon\\geq0$ . Given a $[0,1]$ -valued loss function $\\ell$ , then, with probability   \n159 at least $1-\\delta$ over the draws of $S$ , for all $\\mathbf{h}\\in\\mathcal{H}_{1}\\times\\cdot\\cdot\\times\\mathcal{H}_{n},$ , for all $\\mathbf{g}\\in\\mathcal{G}$ that satisfy $\\epsilon{-}L D P,$ and   \n160 all $x^{\\prime}\\in\\mathcal{X}$ , we have that ", "page_idx": 4}, {"type": "equation", "text": "$$\nR(\\mathbf{g},\\mathbf{h})\\leq e^{\\epsilon}\\biggl(e^{\\epsilon}R_{S}(\\mathbf{g},\\mathbf{h})+2\\operatorname*{lim}_{i\\sim\\mathbf{g}(x^{\\prime})}\\mathcal{R}(\\ell\\circ\\mathcal{H}_{i})+\\sqrt{\\frac{2\\ln(2n/\\delta)}{m}}\\biggr).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "161 Proof. By $n$ applications of Theorem 4.3, we have that, for each $i\\in[n]$ , with probability at least   \n162 $1-\\delta/n$ , for all $h_{i}\\in\\mathcal{H}_{i}$ , ", "page_idx": 4}, {"type": "equation", "text": "$$\nR(h_{i})\\leq R_{S}(h_{i})+2\\mathcal{R}(\\ell\\circ\\mathcal{H}_{i})+\\sqrt{\\frac{2\\ln(2n/\\delta)}{m}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "163 We can make all these inequalities (for each $i\\in[n],$ ) hold simultaneously with a union bound. Now,   \n164 applying Lemma 4.1 with $\\Delta(u,v)\\,=\\,v\\,-\\,u$ , we find that, with probability at least $1-\\delta$ , for all   \n165 $\\mathbf{h}\\in\\mathcal{H}_{1}\\times\\cdot\\cdot\\times\\mathcal{H}_{n}$ , all $\\mathbf{g}\\in\\mathcal{G}$ and all $x^{\\prime}\\in\\mathcal{X}$ , we have that ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{e^{-\\epsilon}R(\\mathbf{g},\\mathbf{h})-e^{\\epsilon}R_{S}(\\mathbf{g},\\mathbf{h})\\leq\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\big(R(h_{i})-R_{S}(h_{i})\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\Bigg(2\\mathcal{R}(\\ell\\circ\\mathcal{H}_{i})+\\sqrt{\\frac{2\\ln(2n/\\delta)}{m}}\\Bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "166 Note, that the risk bound of Theorem 4.4 depends only on the average Rademacher complexity of   \n167 the classes of experts instead of the sum of their Rademacher complexities. Note also that, as in the   \n168 previous section, the complexity of $\\mathcal{G}$ does not affect the risk bound. Finally, the risk bound does not   \n169 hold uniformly for all values of $\\epsilon$ . However, by the union bound, the theorem holds for any fixed set   \n170 $\\{\\epsilon_{1},\\hdots,\\epsilon_{k}\\}$ if we replace $\\delta$ by $\\delta/k$ . Consequently, this suggests a learning algorithm that minimizes   \n171 $R_{S}({\\bf g},{\\bf h})$ for $\\epsilon\\in\\bar{\\{\\epsilon_{1},\\bar{\\,}\\dots,\\epsilon_{k}\\}}$ .   \n172 Also note that Lemma 4.1 allows us to obtain risk bounds for mixtures of experts as long as we   \n173 have bounds on $\\Delta(R_{S}(h_{i}),R(h_{i}))$ which hold with high probability, whether they are based on   \n174 Rademacher complexity, margins, VC dimension, or algorithmic stability. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "175 4.1 The need to use adaptive experts ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "176 Following these theoretical results, we may be tempted to use a gating network satisfying $\\epsilon$ -LDP to   \n177 accomplish a learning task all by itself using non-adaptive experts, that is, experts $h_{i}$ each taking   \n178 a constant value, no matter the input: $h_{i}(x)\\,=\\,i$ for all $x\\,\\in\\,{\\mathcal{X}}$ . In that case, each Rademacher   \n179 complexity $\\mathcal{R}(\\ell\\circ\\mathcal{H}_{i})$ is zero and we can show that Theorem 4.4 can become vacuous under reasonable   \n180 circumstances.   \n181 Consider, for example, the binary classification case with the 0-1 loss. In that case, we have two   \n182 experts $h_{+1}$ and $h_{-1}$ such that $h_{+1}(x)=+1$ and $h_{-1}(x)=-1$ for all $x\\in\\mathscr{X}$ , and a gating network   \n183 $\\mathbf{g}=(g_{+1},g_{-1})$ . Then, the following holds: ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{S}(\\mathbf{g},\\mathbf{h})=\\displaystyle\\frac{1}{m}\\sum_{j=1}^{m}\\underset{i\\sim\\mathrm{g}(x_{j})}{\\mathbb{E}}\\,\\ell_{0,1}(h_{i}(x_{j}),y_{j})}\\\\ &{\\phantom{\\mathbb{E}}=\\displaystyle\\frac{1}{m}\\sum_{j=1}^{m}\\underset{i\\sim\\mathrm{g}(x_{j})}{\\mathbb{E}}\\,1(h_{i}(x_{j})\\neq y_{j})}\\\\ &{\\phantom{\\mathbb{E}}\\ge\\displaystyle\\frac{1}{m}\\sum_{j=1}^{m}\\sum_{i\\in\\mathbb{Z}}e^{-\\epsilon}\\operatorname*{max}_{x^{\\prime}\\in\\mathcal{X}}g_{i}(x^{\\prime})\\mathbf{1}(h_{i}(x_{j})\\neq y_{j}),\\quad\\mathrm{with}\\,\\mathcal{I}=\\left\\{+1,-1\\right\\}}\\\\ &{\\phantom{\\mathbb{E}}=e^{-\\epsilon}\\frac{1}{m}\\sum_{j=1}^{m}\\underset{x^{\\prime}\\in\\mathcal{X}}{\\mathbb{E}}\\,\\mathfrak{m}_{x^{\\prime}}\\mathfrak{g}_{j}(x^{\\prime}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "184 Under the assumption that the classes are balanced, meaning that the (marginal) probability of a   \n185 positive label is equal to the (marginal) probability of a negative label, we have the following: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\displaystyle\\operatorname*{lim}_{m\\to\\infty}\\frac{1}{m}\\sum_{j=1}^{m}\\underset{x^{\\prime}\\in\\mathcal{X}}{\\operatorname*{max}}\\,g_{-y_{j}}(x^{\\prime})=\\frac{1}{2}\\Big(\\underset{x^{\\prime}\\in\\mathcal{X}}{\\operatorname*{max}}\\,g_{-1}(x^{\\prime})+\\underset{x^{\\prime}\\in\\mathcal{X}}{\\operatorname*{max}}\\,g_{+1}(x^{\\prime})\\Big)}\\\\ &{}&{\\displaystyle\\geq\\frac{1}{2}\\,\\underset{x^{\\prime}\\in\\mathcal{X}}{\\operatorname*{max}}\\big(g_{-1}(x^{\\prime})+g_{+1}(x^{\\prime})\\big)=\\frac{1}{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "186 It follows that, in the limit $m\\rightarrow\\infty$ , the risk bound of Theorem 4.4 for any $\\mathbf{g}$ has a value of at least   \n187 $e^{\\epsilon}/2\\geq1/2$ . Consequently, the risk bound becomes large or even vacuous in this regime, highlighting   \n188 the importance of having adaptive experts of finite complexity that can drive the empirical risk to   \n189 zero when they are selected by the gating network. ", "page_idx": 5}, {"type": "text", "text": "190 5 Experiments and results ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "191 In what follows, we consider mixtures of $n$ linear experts in binary classification tasks. Let $\\mathcal{X}=\\mathbb{R}^{d}$   \n192 for some positive integer $d$ . Let $S$ be a training set of m examples. Each expert, denoted by $h_{i}$ , where   \n193 $i$ ranges from 1 to $n$ , is characterized by a weight vector $\\mathbf{w}_{i}$ . Given an input $\\mathbf{x}\\in\\mathcal{X}$ , the output of the   \n194 expert $h_{i}$ is given by $h_{i}(\\mathbf{x})=\\mathbf{w}_{i}\\cdot\\mathbf{x}$ . We use the probit loss function $\\ell=\\Phi$ , which can be seen as a   \n195 smooth surrogate to the 0-1 loss function, when it is used with an argument of the form ywi\u00b7x. In this   \n196 case, $R(\\mathbf{g},Q)$ and $R_{S}(\\mathbf{g},Q)$ are given by: ", "page_idx": 5}, {"type": "equation", "text": "$$\nR(\\mathbf{g},Q)=\\underset{(\\mathbf{x},y)\\sim\\mathcal{D}}{\\mathbb{E}}\\underset{i\\sim\\mathbf{g}(\\mathbf{x})}{\\mathbb{E}}\\,\\Phi\\!\\left(\\frac{y\\mathbf{w}_{i}\\cdot\\mathbf{x}}{\\lVert\\mathbf{x}\\rVert}\\right)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "197 and ", "page_idx": 5}, {"type": "equation", "text": "$$\nR_{S}(\\mathbf{g},Q)=\\frac{1}{m}\\sum_{j=1}^{m}\\sum_{i=1}^{n}g_{i}(\\mathbf{x}_{j})\\Phi\\bigg(\\frac{y_{j}\\mathbf{w}_{i}\\cdot\\mathbf{x}_{j}}{\\left\\|\\mathbf{x}_{j}\\right\\|}\\bigg),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "198 where $\\begin{array}{r}{\\Phi(x)=\\frac{1}{\\sqrt{2\\pi}}\\int_{x}^{+\\infty}e^{-t^{2}/2}\\,d t}\\end{array}$ provides the probability that a standard normal random variable   \n199 is greater than a given value $x$ .   \n200 To illustrate the regularizing effect of the LDP condition, we carried out several experiments, on   \n201 different datasets, by minimizing the empirical risk as defined in Equation 1. For all experiments, our   \n202 models consist of mixtures of $n=100$ linear experts and a gating network. The gating network is a   \n203 neural network having 2 hidden layers. It is parameterized by weights $\\mathbf{W}_{1}\\in\\mathbb{R}^{64\\times d}$ , where $d$ is the   \n204 dimension of input vectors, $\\mathbf{W}_{2}\\in\\mathbb{R}^{64\\times64}$ , and $\\mathbf{W}_{3}\\in\\mathbb{R}^{n\\times\\bar{6}4}$ , and biases $\\mathbf{b}_{1}\\in\\mathbb{R}^{64}$ , $\\mathbf{b}_{2}\\in\\mathbb{R}^{64}$ and   \n205 $\\mathbf{b}_{3}\\in\\mathbb{R}^{n}$ . Given an input $\\mathbf{x}\\in\\mathbb{R}^{d}$ , the output of the gating network $\\mathbf{g}(\\mathbf{x})=(g_{1}(\\mathbf{x}),\\dots,g_{n}(\\mathbf{x}))$ is   \n206 computed as follows: first, we compute $\\mathbf{f}_{0}(\\mathbf{x})=\\operatorname{tanh}(\\mathbf{W}_{2}\\operatorname{ReLU}(\\mathbf{W}_{1}\\mathbf{x}+\\mathbf{b}_{1})+\\mathbf{b}_{2})$ . Then, when   \n207 we want the $\\epsilon$ -LDP condition to be satisfied, we ensure that the outputs are between $-\\epsilon/4$ and $\\epsilon/4$ : ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbf{f}(\\mathbf{x})=\\left\\{\\begin{array}{l l}{\\frac{\\epsilon\\mathbf{W}_{3}\\mathbf{f}_{0}(\\mathbf{x})}{4||\\mathbf{f}_{0}(\\mathbf{x})|||\\mathbf{W}_{3}||_{F}}}&{\\mathrm{if~the~gating~network~must~satisfy~}\\epsilon\\mathrm{-LDP}}\\\\ {\\mathbf{W}_{3}\\mathbf{f}_{0}(\\mathbf{x})}&{\\mathrm{otherwise}.}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "208 Note that tanh is the hyperbolic tangent activation function, ReLU the Rectified Linear Unit function,   \n209 $\\|\\mathbf{W}_{3}\\|_{F}$ the Frobenius norm of the matrix $\\mathbf{W}_{3}$ , and $\\|\\mathbf{f}_{0}(\\mathbf{x})\\|$ the euclidean norm of the vector $\\mathbf{f}_{0}(\\mathbf{x})$ .   \n210 Indeed, if we let $\\mathbf{W}_{3}^{i}$ denote the $i$ -th row of $\\mathbf{W}_{3}$ , then the $i$ -th component of ${\\bf W}_{3}{\\bf f}_{0}({\\bf x})$ is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbf{W}_{3}^{i}\\cdot\\mathbf{f}_{0}(\\mathbf{x})\\leq\\|\\mathbf{W}_{3}^{i}\\|\\|\\mathbf{f}_{0}(\\mathbf{x})\\|\\leq\\|\\mathbf{W}_{3}\\|_{F}\\|\\mathbf{f}_{0}(\\mathbf{x})\\|,\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "211 by the Cauchy-Schwarz inequality and the definition of the Frobenius norm. The reason we use   \n212 the Frobenius norm instead of directly using $\\lVert\\mathbf{W}_{3}^{i}\\rVert$ is to preserve the proportions between the   \n213 components of ${\\bf W}_{3}{\\bf f}_{0}({\\bf x})$ when setting up $\\epsilon$ -LDP. ", "page_idx": 6}, {"type": "text", "text": "214 The final output of the gating network is given by ", "page_idx": 6}, {"type": "equation", "text": "$$\ng_{i}(\\mathbf{x})\\ =\\frac{\\exp(f_{i}(\\mathbf{x})+(\\mathbf{b}_{3})_{i})}{\\sum_{k=1}^{n}\\exp(f_{k}(\\mathbf{x})+(\\mathbf{b}_{3})_{k})}\\quad\\mathrm{for\\,all}\\quad i\\in[n].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "215 In our experiments, we ran the Stochastic Gradient Descent algorithm 10 times with a learning rate   \n216 fixed to 0.1. In each experiment, we trained the model for 1000 epochs, except for the MNIST   \n217 dataset, where the training duration was shortened to 300 epochs due to dataset size. We allocated   \n218 approximately $75\\%$ of the data to the training set and the remaining $25\\%$ to the test set. At the   \n219 outset of each experiment, the weights of our neural networks were reinitialized to ensure a fresh   \n220 starting point. After each training run, we computed both the training and test loss values to evaluate   \n221 the model\u2019s performance. We first ran the training without imposing any constraints on the gating   \n222 network, except for the architecture. Then, we ran several experiments with a gating mechanism   \n223 satisfying $\\epsilon$ -LDP, with $\\epsilon\\in\\{0.5,2,4,5,10\\}$ . A summary of the results is shown in Table 1. One can   \n224 observe that regularization with $\\epsilon$ -LDP improves results in practice, and this regularization is even   \n225 more evident when the models employing a gating network not satisfying LDP overfti heavily, as in   \n226 the Breast Cancer and Heart experiments. The regularization effect is slightly less pronounced on   \n227 MNIST, where the overftiting is not as severe as with the previous datasets. We can also observe the   \n228 importance of choosing the right hyperparameter $\\epsilon$ . Indeed, if the value is too small, the output of the   \n229 gating network becomes insufficiently dependent on the input $\\mathbf{x}$ . In this case, the experts have to do   \n230 all the work, and the gating network does not allow them to specialize in well-defined subsets of the   \n231 instance space. This makes our model closer to a weighted sum of linear classifiers and significantly   \n232 reduces its performance. Conversely, if $\\epsilon$ is overly large, our model tends towards a situation where   \n233 the LDP condition does not hold, making it prone to overfitting.   \n234 Note that our experiments are executed on GPUs in order to parallelize computations and take   \n235 advantage of the sparsity of our model, but they can also be performed without GPUs. The duration   \n236 of experiments can range from a few minutes for small datasets such as Breast Cancer to around 3   \n237 hours for large datasets like MNIST. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "238 6 Conclusion ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "239 In this work, we introduce a new way to regularize mixtures of experts. We provide both theoretical   \n240 and algorithmic contributions in this regard. Our approach offers a significant advantage in that   \n241 it allows us to harness the remarkable performances of neural networks by using them as gating   \n242 networks, without being constrained by their architecture or their complexity from the theoretical   \n243 point of view. By imposing LDP, we obtain nonvacuous bounds on the mixture of experts\u2019 risk. Our   \n244 bounds can become significantly tighter than those presented in section 3.1 and those presented in ", "page_idx": 6}, {"type": "text", "text": "Table 1: Experiment results for mixtures of 100 linear models applied to binary classification tasks: Ads, Breast Cancer [Zwitter and Soklic, 1988], Heart [Janosi et al., 1988] and MNIST [Deng, 2012]. The objective is to minimize the empirical risk as defined in Equation 1. We report the mean training loss $(R_{S})$ and mean test loss $(R_{T})$ , averaged over ten runs, along with their associated standard deviations.2 ", "page_idx": 7}, {"type": "table", "img_path": "cdYIL6OQr6/tmp/f039298d626f80ce1e96bf3a0b8a33938dcb2c757797b05242435ec17540766c.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "245 Azran and Meir [2004], especially in cases where the empirical risk is close to zero and $\\epsilon<\\ln n$ .   \n246 However, as the empirical risk is multiplied by $e^{\\epsilon}$ , the bounds can become loose when $\\epsilon$ is large and   \n247 the empirical risk is significant.   \n248 Even though the $\\epsilon$ -LDP condition is easy to set up, a challenge arises in striking a balance between   \n249 the parameter $\\epsilon$ and the KL divergence or the Rademacher complexity of our experts. Our method   \n250 introduces an extra hyperparameter $\\epsilon$ to optimize but does not provide theoretical guidance on   \n251 configuring it. This forces us to navigate a trade-off between the value of $\\epsilon$ , which measures the   \n252 extent to which the output of the gating network can depend on a given $x\\in\\mathscr{X}$ , and the complexity   \n253 of our experts, which reflects how well our model captures the data distribution. Finding the right   \n254 balance requires empirical testing and careful consideration and can open up new avenues of study in   \n255 the future. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "256 References ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "257 Robert A. Jacobs, Michael I. Jordan, Steven J. Nowlan, and Geoffrey E. Hinton. Adaptive mixtures   \n258 of local experts. Neural Computation, 3(1):79\u201387, 1991. doi: 10.1162/neco.1991.3.1.79.   \n259 Nicolas St\u00e4dler, Peter B\u00fchlmann, and Sara van de Geer. l1-penalization for mixture regression models   \n260 (with discussion). TEST, 19(2):209\u2013285, 2010. doi: 10.1007/s11749-010-0197-z.   \n261 Abbas Khalili and Shili Lin. Regularization in finite mixture of regression models with diverging   \n262 number of parameters. Biometrics, 69, 04 2013. doi: 10.1111/biom.12020. ", "page_idx": 7}, {"type": "text", "text": "263 Seniha Yuksel, Joseph Wilson, and Paul Gader. Twenty years of mixture of experts, 08 2012. ", "page_idx": 7}, {"type": "text", "text": "264 M.I. Jordan and R.A. Jacobs. Hierarchical mixtures of experts and the em algorithm. In Proceedings   \n265 of 1993 International Conference on Neural Networks (IJCNN-93-Nagoya, Japan), volume 2,   \n266 pages 1339\u20131344 vol.2, 1993. doi: 10.1109/IJCNN.1993.716791.   \n267 Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton, and   \n268 Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts layer, 2017.   \n269 URL https://arxiv.org/abs/1701.06538.   \n270 William Fedus, Barret Zoph, and Noam Shazeer. Switch transformers: Scaling to trillion parameter   \n271 models with simple and efficient sparsity, 2022.   \n272 Arik Azran and Ron Meir. Data dependent risk bounds for hierarchical mixture of experts classifiers.   \n273 In John Shawe-Taylor and Yoram Singer, editors, Learning Theory, pages 427\u2013441, Berlin,   \n274 Heidelberg, 2004. Springer Berlin Heidelberg. ISBN 978-3-540-27819-1.   \n275 Cynthia Dwork. Differential privacy. In Michele Bugliesi, Bart Preneel, Vladimiro Sassone, and Ingo   \n276 Wegener, editors, Automata, Languages and Programming, pages 1\u201312, Berlin, Heidelberg, 2006.   \n277 Springer Berlin Heidelberg. ISBN 978-3-540-35908-1.   \n278 Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova, and Adam   \n279 Smith. What can we learn privately?, 2010.   \n280 David McAllester. A PAC-bayesian tutorial with a dropout bound, 2013.   \n281 Matjaz Zwitter and Milan Soklic. Breast Cancer. UCI Machine Learning Repository, 1988. DOI:   \n282 https://doi.org/10.24432/C51P4M.   \n283 Andras Janosi, William Steinbrunn, Matthias Pfisterer, and Robert Detrano. Heart Disease. UCI   \n284 Machine Learning Repository, 1988. DOI: https://doi.org/10.24432/C52P4X.   \n285 Li Deng. The MNIST database of handwritten digit images for machine learning research. IEEE   \n286 Signal Processing Magazine, 29(6):141\u2013142, 2012.   \n287 Michael D. Perlman. Jensen\u2019s inequality for a convex vector-valued function on an infinite  \n288 dimensional space. Journal of Multivariate Analysis, 4(1):52\u201365, 1974. ISSN 0047-259X. doi:   \n289 https://doi.org/10.1016/0047-259X(74)90005-0. URL https://www.sciencedirect.com/   \n290 science/article/pii/0047259X74900050.   \n291 Andreas Maurer. A note on the PAC bayesian theorem, 2004. ", "page_idx": 8}, {"type": "text", "text": "292 A Proofs and auxiliary results ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "293 Proof of theorem 2.2. Given $x\\in\\mathscr{X}$ , let $\\begin{array}{r}{Z(x)=\\sum_{i=1}^{n}\\exp(\\beta f_{i}(x)+c_{i})}\\end{array}$ , for convenience.   \n294 For all $x,x^{\\prime}\\in\\mathcal{X}$ and all $i\\in[n]$ , we have that ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{g_{i}(x)}{g_{i}(x^{\\prime})}=\\exp\\bigl(\\beta(f_{i}(x)-f_{i}(x^{\\prime}))\\bigr)\\cfrac{1}{Z(x)}\\sum_{k=1}^{n}\\exp(\\beta f_{k}(x^{\\prime})+c_{k})}\\\\ &{\\qquad=\\exp\\bigl(\\beta(f_{i}(x)-f_{i}(x^{\\prime}))\\bigr)\\cfrac{1}{Z(x)}\\sum_{k=1}^{n}\\exp(\\beta f_{k}(x)+c_{k})\\exp\\bigl(\\beta(f_{k}(x^{\\prime})-f_{k}(x))\\bigr)}\\\\ &{\\qquad\\underset{i\\in[n];x_{1},x_{2}\\in\\mathcal{X}}{\\operatorname*{max}}\\exp\\bigl(2\\beta(f_{i}(x_{1})-f_{i}(x_{2}))\\bigr)\\cfrac{1}{Z(x)}\\sum_{k=1}^{n}\\exp(\\beta f_{k}(x)+c_{k})}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "295 Theorem A.1 (Jensen\u2019s inequality, proposition 1.1 in Perlman [1974]). Let $\\Omega$ be a probability space,   \n296 let $A$ be a convex subset of $\\mathring{\\mathbb{R}}^{k}$ , let $X\\colon\\Omega\\to A$ be an integrable vector-valued random variable, and   \n297 let $\\phi:A\\rightarrow\\mathbb{R}$ be a convex function. Then, $\\mathbb{E}X\\in A$ , and $\\phi(\\mathbb{E}X)\\leq\\mathbb{E}\\,\\phi(X)$ (in particular, the   \n298 right-hand side of this inequality exists, though it may be infinite).   \n299 Theorem A.2 (Theorem 5 in Maurer [2004]). Let $\\delta\\in(0,1)$ and $m\\geq8$ . Fix $i\\in[n]$ , and let $P_{i}$ be $a$   \n300 probability measure on $\\mathcal{H}_{i}$ (chosen without seeing the training data). Then, with probability at least   \n301 $1-\\delta$ over the draws of $S$ , for all probability measures $Q_{i}$ on $\\mathcal{H}_{i}$ , we have that ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "equation", "text": "$$\n\\operatorname{kl}(R_{S}(Q_{i})\\,\\|\\,R(Q_{i}))\\leq{\\frac{1}{m}}{\\Big(}\\operatorname{KL}(Q_{i}\\,\\|\\,P_{i})+\\ln{\\frac{2{\\sqrt{m}}}{\\delta}}{\\Big)}.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "302 Proof of theorem 3.4. As remarked earlier, the function $(u,v)\\rightarrow\\mathrm{kl}(u\\,\\|\\,v):[0,1]^{2}\\rightarrow\\mathbb{R}$ does not   \n303 exactly satisfy the hypotheses of lemma 3.1, but it is convex. Moreover, on $\\{(u,\\bar{v})\\in[0,1]^{2}\\,|\\,u\\leq v\\,\\}$ ,   \n304 it is decreasing in its first argument and increasing in its second argument. Also note that, assuming   \n305 that $R({\\bf g},Q)\\stackrel{\\bullet}{\\geq}e^{2\\epsilon}R_{S}({\\bf g},\\breve{Q})$ , then we also have the following inequalities: ", "page_idx": 9}, {"type": "equation", "text": "$$\n0\\leq\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R_{S}(Q_{i})\\leq e^{\\epsilon}R_{S}(\\mathbf{g},Q)\\leq e^{-\\epsilon}R(\\mathbf{g},Q)\\leq\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R(Q_{i})\\leq1.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "306 It follows that ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{kl}(e^{\\epsilon}R_{S}(\\mathbf{g},Q)\\|\\,e^{-\\epsilon}R(\\mathbf{g},Q))\\leq\\mathrm{kl}\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R_{S}(Q_{i})\\,\\Big\\|\\,e^{-\\epsilon}R(\\mathbf{g},Q)\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\mathrm{kl}\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R_{S}(Q_{i})\\,\\Big\\|\\,\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R(Q_{i})\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "307 and therefore ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{kl}(e^{\\epsilon}R_{S}(\\mathbf{g},Q)\\,\\|\\,e^{-\\epsilon}R(\\mathbf{g},Q))\\leq\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\,\\mathrm{kl}\\big(R_{S}(Q_{i})\\,\\|\\,R(Q_{i})\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "308 by Jensen\u2019s inequality. Now, by theorem A.2, for a fixed $i$ , with probability at least $1-\\delta/n$ , we have   \n309 that ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\operatorname{kl}(R_{S}(Q_{i})\\,\\|\\,R(Q_{i}))\\leq{\\frac{1}{m}}{\\Bigl(}\\operatorname{KL}(Q_{i}\\,\\|\\,P_{i})+\\ln{\\frac{2n{\\sqrt{m}}}{\\delta}}{\\Bigr)}.\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "310 We can make the above inequality hold for all $i\\in[n]$ simultaneously with the union bound. Then,   \n311 with probability at least $1-\\delta$ , for all $(\\mathbf{g},Q)$ , given that $R({\\bf g},Q)\\ge e^{\\textstyle\\frac{\\mathfrak{2}\\epsilon}{2\\epsilon}}R_{S}({\\bf g},Q)$ , we have that ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\operatorname{kl}(e^{\\epsilon}R_{S}(\\mathbf{g},Q)\\,\\|\\,e^{-\\epsilon}R(\\mathbf{g},Q))\\leq\\frac{1}{m}\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}\\,\\operatorname{KL}(Q_{i}\\,\\|\\,P_{i})+\\ln\\frac{2n\\sqrt{m}}{\\delta}\\Big).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "312 Proof of Lemma 4.1. Since the gating function satisfies $\\epsilon$ -LDP, we have that $e^{-\\epsilon}g_{i}(x^{\\prime})\\leq g_{i}(x)\\leq$   \n313 $e^{\\epsilon}g_{i}(x^{\\prime})$ for all $x,x^{\\prime}\\,\\in\\,\\mathcal{X}$ and all $\\bar{i}\\in[n]$ . It follows that $e^{\\epsilon}R_{S}(\\mathbf{g},\\mathbf{h})\\:\\geq\\:\\mathbb{E}_{i\\sim\\mathbf{g}(x^{\\prime})}\\:R_{S}(h_{i})$ and   \n314 $e^{-\\epsilon}R(\\mathbf{g},\\mathbf{h})\\leq\\mathbb{E}_{i\\sim\\mathbf{g}(x^{\\prime})}\\,R(h_{i})$ . Given that $\\Delta$ is decreasing in its first argument and increasing in its   \n315 second argument, we find that ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\Delta\\big(e^{\\epsilon}R_{S}(\\mathbf{g},\\mathbf{h}),e^{-\\epsilon}R(\\mathbf{g},\\mathbf{h})\\big)\\leq\\Delta\\Big(\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R_{S}(h_{i}),\\underset{i\\sim\\mathbf{g}(x^{\\prime})}{\\mathbb{E}}R(h_{i})\\Big)\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "316 Since $\\Delta$ is a convex function, we can apply Jensen\u2019s inequality to the expression on the right-hand   \n317 side, yielding the desired result. \u53e3 ", "page_idx": 9}, {"type": "text", "text": "318 NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "19 1. Claims   \n320 Question: Do the main claims made in the abstract and introduction accurately reflect the   \n321 paper\u2019s contributions and scope?   \n322 Answer: [Yes]   \n323 Justification: Our claims are supported by theorems, which we prove, and by experiments.   \n324 Guidelines:   \n325 \u2022 The answer NA means that the abstract and introduction do not include the claims   \n326 made in the paper.   \n327 \u2022 The abstract and/or introduction should clearly state the claims made, including the   \n328 contributions made in the paper and important assumptions and limitations. A No or   \n329 NA answer to this question will not be perceived well by the reviewers.   \n330 \u2022 The claims made should match theoretical and experimental results, and reflect how   \n331 much the results can be expected to generalize to other settings.   \n332 \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals   \n333 are not attained by the paper.   \n334 2. Limitations   \n335 Question: Does the paper discuss the limitations of the work performed by the authors?   \n336 Answer: [Yes]   \n337 Justification: We discuss the limitations of the work in the conclusion section.   \n338 Guidelines:   \n339 \u2022 The answer NA means that the paper has no limitation while the answer No means that   \n340 the paper has limitations, but those are not discussed in the paper.   \n341 \u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n342 \u2022 The paper should point out any strong assumptions and how robust the results are to   \n343 violations of these assumptions (e.g., independence assumptions, noiseless settings,   \n344 model well-specification, asymptotic approximations only holding locally). The authors   \n345 should reflect on how these assumptions might be violated in practice and what the   \n346 implications would be.   \n347 \u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was   \n348 only tested on a few datasets or with a few runs. In general, empirical results often   \n349 depend on implicit assumptions, which should be articulated.   \n350 \u2022 The authors should reflect on the factors that influence the performance of the approach.   \n351 For example, a facial recognition algorithm may perform poorly when image resolution   \n352 is low or images are taken in low lighting. Or a speech-to-text system might not be   \n353 used reliably to provide closed captions for online lectures because it fails to handle   \n354 technical jargon.   \n355 \u2022 The authors should discuss the computational efficiency of the proposed algorithms   \n356 and how they scale with dataset size.   \n357 \u2022 If applicable, the authors should discuss possible limitations of their approach to   \n358 address problems of privacy and fairness.   \n359 \u2022 While the authors might fear that complete honesty about limitations might be used by   \n360 reviewers as grounds for rejection, a worse outcome might be that reviewers discover   \n361 limitations that aren\u2019t acknowledged in the paper. The authors should use their best   \n362 judgment and recognize that individual actions in favor of transparency play an impor  \n363 tant role in developing norms that preserve the integrity of the community. Reviewers   \n364 will be specifically instructed to not penalize honesty concerning limitations.   \n365 3. Theory Assumptions and Proofs   \nQuestion: For each theoretical result, does the paper provide the full set of assumptions and   \n366   \n67 a complete (and correct) proof? ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 10}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not include theoretical results.   \n4 \u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n6 \u2022 All assumptions should be clearly stated or referenced in the statement of any theorems. \u2022 The proofs can either appear in the main paper or the supplemental material, but if   \n8 they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n0 \u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. \u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 11}, {"type": "text", "text": "383 4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "384 Question: Does the paper fully disclose all the information needed to reproduce the main ex  \n385 perimental results of the paper to the extent that it affects the main claims and/or conclusions   \n86 of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 11}, {"type": "text", "text": "Justification: All datasets used are freely available, and we describe the architecture of the model and the hyperparameters of our experiments in detail. We also provide the code used to run our experiments as supplemental material. ", "page_idx": 11}, {"type": "text", "text": "Guidelines: ", "page_idx": 11}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 11}, {"type": "text", "text": "423 5. Open access to data and code   \n424 Question: Does the paper provide open access to the data and code, with sufficient instruc  \n425 tions to faithfully reproduce the main experimental results, as described in supplemental   \n426 material?   \n427 Answer: [Yes]   \n428 Justification: All datasets used in our experiments are freely available. The code used to run   \n429 our experiments is provided as supplemental material.   \n430 Guidelines:   \n431 \u2022 The answer NA means that paper does not include experiments requiring code.   \n432 \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/   \n433 public/guides/CodeSubmissionPolicy) for more details.   \n434 \u2022 While we encourage the release of code and data, we understand that this might not be   \n435 possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not   \n436 including code, unless this is central to the contribution (e.g., for a new open-source   \n437 benchmark).   \n438 \u2022 The instructions should contain the exact command and environment needed to run to   \n439 reproduce the results. See the NeurIPS code and data submission guidelines (https:   \n440 //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n441 \u2022 The authors should provide instructions on data access and preparation, including how   \n442 to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n443 \u2022 The authors should provide scripts to reproduce all experimental results for the new   \n444 proposed method and baselines. If only a subset of experiments are reproducible, they   \n445 should state which ones are omitted from the script and why.   \n446 \u2022 At submission time, to preserve anonymity, the authors should release anonymized   \n447 versions (if applicable).   \n448 \u2022 Providing as much information as possible in supplemental material (appended to the   \n449 paper) is recommended, but including URLs to data and code is permitted.   \n450 6. Experimental Setting/Details   \n451 Question: Does the paper specify all the training and test details (e.g., data splits, hyper  \n452 parameters, how they were chosen, type of optimizer, etc.) necessary to understand the   \n453 results?   \n454 Answer: [Yes]   \n455 Justification: Experimental details are provided in section 5.   \n456 Guidelines:   \n457 \u2022 The answer NA means that the paper does not include experiments.   \n458 \u2022 The experimental setting should be presented in the core of the paper to a level of detail   \n459 that is necessary to appreciate the results and make sense of them.   \n460 \u2022 The full details can be provided either with the code, in appendix, or as supplemental   \n461 material.   \n462 7. Experiment Statistical Significance   \n463 Question: Does the paper report error bars suitably and correctly defined or other appropriate   \n464 information about the statistical significance of the experiments?   \n465 Answer: [Yes]   \n466 Justification: In experiments, we had multiple runs and reported averages along with standard   \n467 deviations.   \n468 Guidelines:   \n469 \u2022 The answer NA means that the paper does not include experiments.   \n470 \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confi  \n471 dence intervals, or statistical significance tests, at least for the experiments that support   \n472 the main claims of the paper.   \n473 \u2022 The factors of variability that the error bars are capturing should be clearly stated (for   \n474 example, train/test split, initialization, random drawing of some parameter, or overall   \n475 run with given experimental conditions).   \n476 \u2022 The method for calculating the error bars should be explained (closed form formula,   \n477 call to a library function, bootstrap, etc.)   \n478 \u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n479 \u2022 It should be clear whether the error bar is the standard deviation or the standard error   \n480 of the mean.   \n481 \u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should   \n482 preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis   \n483 of Normality of errors is not verified.   \n484 \u2022 For asymmetric distributions, the authors should be careful not to show in tables or   \n485 figures symmetric error bars that would yield results that are out of range (e.g. negative   \n486 error rates).   \n487 \u2022 If error bars are reported in tables or plots, The authors should explain in the text how   \n488 they were calculated and reference the corresponding figures or tables in the text.   \n489 8. Experiments Compute Resources   \n490 Question: For each experiment, does the paper provide sufficient information on the com  \n491 puter resources (type of compute workers, memory, time of execution) needed to reproduce   \n492 the experiments?   \n493 Answer: [Yes]   \n494 Justification: We provide information on the type of compute workers (GPU) and time of   \n495 execution in section 5.   \n496 Guidelines:   \n497 \u2022 The answer NA means that the paper does not include experiments.   \n498 \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster,   \n499 or cloud provider, including relevant memory and storage.   \n500 \u2022 The paper should provide the amount of compute required for each of the individual   \n501 experimental runs as well as estimate the total compute.   \n502 \u2022 The paper should disclose whether the full research project required more compute   \n503 than the experiments reported in the paper (e.g., preliminary or failed experiments that   \n504 didn\u2019t make it into the paper).   \n505 9. Code Of Ethics   \n506 Question: Does the research conducted in the paper conform, in every respect, with the   \n507 NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?   \n508 Answer: [Yes]   \n509 Justification: In this work, we provide theoretical results that do not have any direct negative   \n510 impact on society and do not pose any obvious ethical problem. We have ensured to cite our   \n511 sources and adhere to the NeurIPS Code of Ethics.   \n512 Guidelines:   \n513 \u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n514 \u2022 If the authors answer No, they should explain the special circumstances that require a   \n515 deviation from the Code of Ethics.   \n516 \u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consid  \n517 eration due to laws or regulations in their jurisdiction).   \n518 10. Broader Impacts   \n519 Question: Does the paper discuss both potential positive societal impacts and negative   \n520 societal impacts of the work performed?   \n521 Answer: [NA]   \n522 Justification: Our paper has a theoretical orientation and no clear negative impacts.   \n523 Guidelines:   \n524 \u2022 The answer NA means that there is no societal impact of the work performed.   \n525 \u2022 If the authors answer NA or No, they should explain why their work has no societal   \n526 impact or why the paper does not address societal impact.   \n527 \u2022 Examples of negative societal impacts include potential malicious or unintended uses   \n528 (e.g., disinformation, generating fake profiles, surveillance), fairness considerations   \n529 (e.g., deployment of technologies that could make decisions that unfairly impact specific   \n530 groups), privacy considerations, and security considerations.   \n531 \u2022 The conference expects that many papers will be foundational research and not tied   \n532 to particular applications, let alone deployments. However, if there is a direct path to   \n533 any negative applications, the authors should point it out. For example, it is legitimate   \n534 to point out that an improvement in the quality of generative models could be used to   \n535 generate deepfakes for disinformation. On the other hand, it is not needed to point out   \n536 that a generic algorithm for optimizing neural networks could enable people to train   \n537 models that generate Deepfakes faster.   \n538 \u2022 The authors should consider possible harms that could arise when the technology is   \n539 being used as intended and functioning correctly, harms that could arise when the   \n540 technology is being used as intended but gives incorrect results, and harms following   \n541 from (intentional or unintentional) misuse of the technology.   \n542 \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation   \n543 strategies (e.g., gated release of models, providing defenses in addition to attacks,   \n544 mechanisms for monitoring misuse, mechanisms to monitor how a system learns from   \n545 feedback over time, improving the efficiency and accessibility of ML).   \n546 11. Safeguards   \n547 Question: Does the paper describe safeguards that have been put in place for responsible   \n548 release of data or models that have a high risk for misuse (e.g., pretrained language models,   \n549 image generators, or scraped datasets)?   \n550 Answer: [NA]   \n551 Justification: Our models are trained on freely available datasets as a way to prove the   \n552 efficacy of our approach, but they pose no risk as such.   \n553 Guidelines:   \n554 \u2022 The answer NA means that the paper poses no such risks.   \n555 \u2022 Released models that have a high risk for misuse or dual-use should be released with   \n556 necessary safeguards to allow for controlled use of the model, for example by requiring   \n557 that users adhere to usage guidelines or restrictions to access the model or implementing   \n558 safety filters.   \n559 \u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors   \n560 should describe how they avoided releasing unsafe images.   \n561 \u2022 We recognize that providing effective safeguards is challenging, and many papers do   \n562 not require this, but we encourage authors to take this into account and make a best   \n563 faith effort.   \n564 12. Licenses for existing assets   \n565 Question: Are the creators or original owners of assets (e.g., code, data, models), used in   \n566 the paper, properly credited and are the license and terms of use explicitly mentioned and   \n567 properly respected?   \n568 Answer: [Yes]   \n569 Justification: We use openly accessible datasets and ensure to cite them properly when   \n570 necessary.   \n571 Guidelines:   \n572 \u2022 The answer NA means that the paper does not use existing assets.   \n573 \u2022 The authors should cite the original paper that produced the code package or dataset.   \n574 \u2022 The authors should state which version of the asset is used and, if possible, include a   \n575 URL.   \n576 \u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset. ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 15}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes]   \nJustification: The code is provided as supplemental material and the details are given in the README file. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 15}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 15}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 15}, {"type": "text", "text": "Justification: The paper does not involve research with human subjects nor crowdsourcing. Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 15}, {"type": "text", "text": "17 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human   \n18 Subjects   \n19 Question: Does the paper describe potential risks incurred by study participants, whether   \n20 such risks were disclosed to the subjects, and whether Institutional Review Board (IRB)   \n21 approvals (or an equivalent approval/review based on the requirements of your country or   \n22 institution) were obtained?   \n23 Answer: [NA]   \n24 Justification: The paper does not involve research with human subjects.   \n25 Guidelines:   \n26 \u2022 The answer NA means that the paper does not involve crowdsourcing nor research with   \n27 human subjects. ", "page_idx": 15}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 16}]