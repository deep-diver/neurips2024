[{"type": "text", "text": "DDN: Dual-domain Dynamic Normalization for Non-stationary Time Series Forecasting ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tao Dai1,,\u2217 Beiliang $\\mathbf{W}\\mathbf{u}^{1};$ ,,\u2217 Peiyuan Liu2,,\u2020 Naiqi $\\mathbf{L}\\mathbf{i}^{2};$ ,\u2020 Xue Yuerong2, Shu-Tao $\\mathbf{Xia^{2}}$ , Zexuan Zhu1 1College of Computer Science and Software Engineering, Shenzhen University, China 2Tsinghua Shenzhen International Graduate School, Tsinghua University, China {daitao.edu, peiyuanliu.edu, linaiqi.thu} $@$ gmail.com; xiast $@$ sz.tsinghua.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Deep neural networks (DNNs) have recently achieved remarkable advancements in time series forecasting (TSF) due to their powerful ability of sequence dependence modeling. To date, existing DNN-based TSF methods still suffer from unreliable predictions for real-world data due to its non-stationarity characteristics, i.e., data distribution varies quickly over time. To mitigate this issue, several normalization methods (e.g., SAN) have recently been specifically designed by normalization in a fixed period/window in the time domain. However, these methods still struggle to capture distribution variations, due to the complex time patterns of time series in the time domain. Based on the fact that wavelet transform can decompose time series into a linear combination of different frequencies, which exhibits distribution variations with time-varying periods, we propose a novel Dual-domain Dynamic Normalization (DDN) to dynamically capture distribution variations in both time and frequency domains. Specifically, our DDN tries to eliminate the non-stationarity of time series via both frequency and time domain normalization in a sliding window way. Besides, our DDN can serve as a plug-in-play module, and thus can be easily incorporated into other forecasting models. Extensive experiments on public benchmark datasets under different forecasting models demonstrate the superiority of our DDN over other normalization methods. Code is available at https://github.com/Hank0626/DDN. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Deep neural networks (DNNs) with powerful dependency modeling capability have recently been widely used in time series forecasting (TSF) applications, including weather prediction [1], energy consumption estimation [2], and traffic flow forecasting [3]. Despite the great advancements of DNN-based TSF methods [4, 5, 6, 7], they still suffer from unreliable predictions for real-world data due to its non-stationary nature of real-world time series, i.e., data distribution within the series varies quickly over time (a.k.a, distribution drift [8, 9, 10]). Such non-stationary challenge limits the real applications of DNN-based TSF methods. ", "page_idx": 0}, {"type": "text", "text": "To mitigate the problem of distribution drift, the classic reversible normalization [11] has recently been proposed with a two-stage pipeline of normalization and de-normalization. The former stage of normalization eliminates non-stationary factors for converting a non-stationary sequence into a stationary sequence, which has to acquire the mean and standard deviation of the sequence before. The latter stage of de-normalization reconstructs non-stationary information from the distribution prediction model or directly reuses the mean and standard deviation acquired in normalization. ", "page_idx": 0}, {"type": "image", "img_path": "RVZfra6sZo/tmp/8e9332b0f41453c0aba6ec5e93251062ec2b6a30313aaea604abc4690d6b135a.jpg", "img_caption": ["Figure 1: (a) Existing methods with a fixed period/window normalization struggle to capture distribution variations. (b) Our method dynamically captures distribution variations in both time and frequency domains. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Later, several advanced variants of reversible normalization [12, 13, 14] have achieved impressive performance by further alleviating the non-stationary property of real-world time series. ", "page_idx": 1}, {"type": "text", "text": "Despite the great success of normalization methods, existing methods are limited in capturing distribution variations by performing normalization with a fixed period/window. As shown in Figure 1a, either existing coarse-grained (e.g., RevIN [11]) or fine-grained normalization (e.g., SAN [14]) in single time domain tends to produce sub-optimal performance. On the other hand, it is known that wavelet transform can decompose time series into a time-dependent sum of frequency components, which exhibits distribution variations with time-varying periods (see Figure 1b). Thus, making full use of such frequency information is helpful to capture distribution variations with time-varying periods and intensities. These observations motivate us to develop a more powerful normalization strategy to dynamically capture distribution variations. ", "page_idx": 1}, {"type": "text", "text": "In this paper, we propose a novel Dual-domain Dynamic Normalization (DDN) framework to dynamically capture distribution variations in both times and frequency domains in a sliding window way. Specifically, our DDN decomposes the original time series into different frequency components, including low-frequency and high-frequency components, based on Discrete Wavelet Transform (DWT) [15, 16]. Followed by performing sliding normalization in an individual frequency component with proper window size (see Figure 1b), which is helpful to capture distribution variations with time-varying periods and intensities. Besides, time domain normalization is developed to compute local sliding statistics [17], including sliding mean and sliding standard deviation. Unlike the previous works that process a coarse-grained level, our DDN leverages fine-grained a more informative sliding window to calculate distribution characteristics for every time step. ", "page_idx": 1}, {"type": "text", "text": "Our main contributions can be summarized as: (i) We propose a novel Dual-domain Dynamic Normalization (DDN) to dynamically capture distribution variations in both time and frequency domains with sliding statistics. Compared with previous works, our DDN is capable of dynamically reflecting the rapid variations to time series. (ii) Our DDN aims to eliminate non-stationary factors with frequency domain normalization and time domain normalization. Beneftiing from the complementary properties of the time and frequency domain information, it allows our DDN to further clarify non-stationary factors and reconstruct non-stationary information. (iii) Extensive experiments demonstrate the effectiveness of our DDN, by achieving significant performance improvements across various baseline models on seven real-world datasets. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1 Deep Models for Time Series Forecasting ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Reviewing the development of time series forecasting based on deep models, early methods [18, 19, 20] often integrated cross-dimension information in embedding module, then modeling cross-time information. In contrast, recent Sota methods indicate that two modeling ways can be better: CI (Channel Independent) and CD (Channel Dependent). The primary distinction between the two approaches lies in the former focusing only on cross-time features but the latter incorporating crossdimension features. Theoretically, the latter can leverage more information and achieve higher prediction accuracy [21, 22, 23]. In practice, for relatively short input series, CD methods [24, 25] achieve comparable or even better performance than the CI methods. However, for longer input sequences, the situation is often the opposite[26, 4, 27]. In recent research, this difference can be attributed to the CD having higher capacity but often lacking robustness in predicting distributional drift than CI [28, 29], while longer series typically experience more severe distributional drift. The superior performance of CI highlights the importance of handling distribution drift, and it is a valuable direction in the current research on time series forecasting. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2.2 Stationary for Time Series Forecasting ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "RevIN [11] was the first work to apply reversible normalization for time series forecasting, which assumes that history and future sequences share the same distribution. It counts distribution statistics of historical sequence for both normalization and de-normalization. Due to its simplicity and impressive effectiveness, it has been widely used in recent works [30, 31]. However, RevIN overlooks the distributional differences between historical and future sequences. Building upon RevIN, DishTS [12] proposes different distribution characteristics for historical and future sequences, using a distribution forecasting model to predict mean and standard deviation. Concurrently, NST [13] employs a module to provide more consistent distribution with future distribution, which can refer to appendix B. Furthermore, SAN [14] notes that existing distribution assumptions may not adapt to the scenario that time series points rapidly change over time [32, 33] and proposes a more fine-grained method, which supposes the distribution characteristics of time points is different between slices but same within a slice. Nevertheless, SAN still stops at the slice level, rather than the time series point level. Meanwhile, existing works lack consideration of the discrepancies between low and high frequencies, leading to insufficient consideration of non-stationary information. ", "page_idx": 2}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In the realm of multivariate time series forecasting, we consider a historical sequence $\\boldsymbol{X}\\in\\mathbb{R}^{M\\times L}$ and aim to predict the corresponding future sequence $\\pmb{Y}\\in\\mathbb{R}^{M\\times T}$ , $M$ is the number of channels. DDN is a model-agnostic plugin designed to align the distribution characteristics of $\\mathbf{\\deltaX}$ and accurately estimate the distribution of $\\mathbf{\\deltaY}$ . In this section, we will comprehensively outline the pipeline of the entire framework and elaborate on how to remove and reconstruct non-stationary factors of time series. To enhance clarity and facilitate understanding of subsequent chapters, the key notations used in this paper are summarized in Table 1, and the framework can be referred to in Figure 2. ", "page_idx": 2}, {"type": "table", "img_path": "RVZfra6sZo/tmp/ae7cc29382b863fb8c2439add55136f3682c011ad0362799f566083c68f4b14b.jpg", "table_caption": [], "table_footnote": ["Table 1: Summary of key mathematical notations "], "page_idx": 2}, {"type": "text", "text": "3.1 Overall Framework ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "As depicted in Figure 2, we first eliminate non-stationary factors via both the Frequency Domain Normalization (FDN) and the Time Domain Normalization (TDN). These processes output two stationary sequences and two sets of distribution characteristics. Two stationary sequences weighted to a sequence and input to the time series Forecasting Model (FM) for future sequence forecasting, while two sets of non-stationary factors input to Distribution Prediction Model (DPM) and predict future non-stationary factors. Finally, these factors are weighted together and incorporated with forecasting output to reconstruct non-stationary factors by de-normalization. Here, $\\theta_{d}$ and $\\theta_{f}$ correspond to the parameters of DPM and FM, and the training strategy can be seen in the section 3.4. ", "page_idx": 2}, {"type": "image", "img_path": "RVZfra6sZo/tmp/0d3f47a8f4f0395d39c6e000660b8b95d243a51016bbedcc2655732360d773d8.jpg", "img_caption": ["Figure 2: The comprehensive time series forecasting framework comprises a time series forecasting model and an auxiliary module designed for handling non-stationary factors. This auxiliary module consists of two sub-modules: one for eliminating non-stationary factors and another for reconstructing them. The non-stationary factor elimination sub-module includes Time Domain Normalization and Frequency Domain Normalization, while the non-stationary factor reconstruction sub-module incorporates a distribution prediction module. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3.2 Non-stationarity Elimination ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "For each series $\\pmb{x}^{i}$ , we perform a sliding window along the temporal dimension to acquire distribution characteristics, then replicate padding that will align the length of sliding statistics to the original series. Finally, sliding mean $\\pmb{\\mu}^{i}$ and sliding standard deviation $\\sigma^{i}$ represent to the distribution characteristics of $\\pmb{x}^{i}$ . This process can be described as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\mu_{j}^{i}=\\frac{1}{2k+1}\\sum_{-k}^{k}x_{j+t}^{i},\\quad\\left(\\sigma_{j}^{i}\\right)^{2}=\\frac{1}{2k+1}\\sum_{-k}^{k}\\left(x_{j+t}^{i}-\\mu_{j}^{i}\\right)^{2},}\\\\ {\\displaystyle\\mu^{i}=\\mathrm{Pad}(\\{\\mu_{k+1}^{i},\\cdot\\cdot\\cdot\\cdot,\\mu_{L-k}^{i}\\}),\\quad\\sigma^{i}=\\mathrm{Pad}(\\{\\sigma_{k+1}^{i},\\cdot\\cdot\\cdot,\\sigma_{L-k}^{i}\\})}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here $2k+1$ is the size of the sliding window, and stride is 1. After that, the size of sliding statistics is $L-2k$ . Where $\\mu_{j}{}^{i}$ and $\\sigma_{j}{}^{i}$ represent the mean value and standard deviation value of the $j^{t h}$ time point respectively, where $j\\ \\bar{\\in}\\ \\{k+1,\\cdot\\cdot\\cdot\\ ,L-k\\}$ . To make sure each time point possesses corresponding sliding statistics. We copy the sliding statistics closest in time by $\\mathrm{Pad}\\left(\\cdot\\right)$ operation, the obtaining $\\pmb{\\mu}_{i}$ and $\\pmb{\\sigma_{i}}$ are used to achieve the transformation from non-stationary sequences to stationary sequences. The process is as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\bar{\\pmb{x}}^{i}=\\frac{1}{\\pmb{\\sigma}^{i}+\\epsilon}\\odot\\left(\\pmb{x}^{i}-\\pmb{\\mu}^{i}\\right),\\quad\\epsilon>0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, $\\bar{\\pmb{x}}^{i}$ is the stationary series, $\\epsilon$ is a positive number to prevent the denominator from zero, and $\\odot$ denotes the element-wise product. By this sliding normalization, annotated as SlidingNorm $(\\cdot)$ , we can acquire the non-stationary factors of each time point and convert non-stationary sequences to stationary sequences. ", "page_idx": 3}, {"type": "text", "text": "Frequency Domain Normalization. In this branch, to exhaustively unveil non-stationary factors and eliminate them accurately. Discrete Wavelet Transform (DWT) is conducted on $\\pmb{x}_{i}$ to separate the low-frequency component $\\pmb{x}_{l}^{i}$ and high-frequency component ${\\pmb x}_{h}^{i}$ . Subsequently, we acquire and eliminate their non-stationary factors. The process is as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{{\\pmb x}_{l}^{i},{\\pmb x}_{h}^{i}=\\mathrm{DWT}_{\\phi_{l,h}}({\\pmb x}^{i}),}}\\\\ {{\\mp_{l}^{i},{\\pmb\\mu}_{l}^{i},{\\pmb\\sigma}_{l}^{i}=\\mathrm{SlidingNorm}({\\pmb x}_{l}^{i}),\\quad\\bar{{\\pmb x}}_{h}^{i},{\\pmb\\mu}_{h}^{i},{\\pmb\\sigma}_{h}^{i}=\\mathrm{SlidingNorm}({\\pmb x}_{h}^{i}),}}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here, $\\phi_{l,h}$ is a pair of learnable wavelet bases. $\\bar{\\pmb{x}}_{l}^{i},\\,\\pmb{\\mu}_{l}^{i}$ , and $\\boldsymbol{\\sigma}_{l}^{i}$ represent the stationary sequence, sliding mean, and sliding standard deviation of the low-frequency component. While $\\bar{\\pmb{x}}_{h}^{i},\\pmb{\\mu}_{h}^{i}$ , and ${\\pmb\\sigma}_{h}^{i}$ denote those of the high-frequency component. In practice, different types of DWT have different padding lengths and lead to different output lengths. To ensure a consistent and clear output length, Inverse Discrete Wavelet Transform (IDWT) performs to restore a definite size. The process is as follows: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\mathbf{x}}^{i}=\\mathrm{IDWT}_{\\phi_{l,h}}(\\bar{x}_{l}^{i},\\bar{x}_{h}^{i}),\\quad\\hat{\\mu}^{i}=\\mathrm{IDWT}_{\\phi_{l,h}}(\\mu_{l}^{i},\\mu_{h}^{i}),~\\hat{\\sigma}^{i}=\\mathrm{IDWT}_{\\phi_{l,h}}(\\sigma_{l}^{i},\\sigma_{h}^{i}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Where $\\hat{\\pmb x}^{i},\\,\\hat{\\pmb\\mu}^{i}$ , and ${\\hat{\\pmb{\\sigma}}}^{i}$ encompass the stationary sequences, sliding means, and sliding standard deviations of different frequency components. Through these operations, the output stationary sequence and distribution statistics maintain consistency with the dimensions of the input nonstationary sequence. ", "page_idx": 4}, {"type": "text", "text": "Time Domain Normalization. We conduct the same manners in the time domain without frequency decomposition. The process can be formulated as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{\\pmb{x}}^{i},\\pmb{\\mu}^{i},\\pmb{\\sigma}^{i}=\\mathrm{SlidingNorm}(\\pmb{x}^{i}),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The wavelet transform in FDN typically involves padding, which can potentially distort the statistical distribution information of the decomposed sequences. To address this, we implement sliding normalization directly on the original sequence. Consequently, the resulting distribution information is utilized for predicting future distributions, while the output stationary sequence is weighted with the stationary sequence derived from FDN. ", "page_idx": 4}, {"type": "text", "text": "Stationary Sequences Weighting. Two stationary sequences from FDN and TDN will be weighted to a stationary output, which can be expressed as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{\\pmb{x}}^{i}=\\bar{\\pmb{x}}^{i}\\cdot\\beta+\\hat{\\pmb{x}}^{i}\\cdot\\alpha.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, $\\alpha$ is a trainable parameter and $\\beta\\,=\\,1\\,-\\,\\alpha$ . The weighted ${\\bar{\\pmb{x}}}^{i}$ serves as the final stationary sequence, which is then inputted into FM for stable forecasting. ", "page_idx": 4}, {"type": "text", "text": "3.3 Non-stationarity Reconstruction ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We acquire two sets of sliding statistics reflecting distribution variations after FDN and TDN. Later, we refer to the structure of existing distribution prediction works [34, 12] to predict future distribution. Initially, we calculate the mean value of each sliding statistic to compute the statistical differences. Subsequently, the difference and original series are inputted for future difference prediction. Ultimately, these predicted differences added to the mean value as future sliding statistics. ", "page_idx": 4}, {"type": "text", "text": "Frequency Domain Prediction. As shown in Figure 3, for the distribution statistics of FDN, we predict future statistics by distribution prediction model and formulate as: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\hat{\\pmb{\\sigma}}_{\\Delta}^{i}=\\mathrm{SP}\\left(\\hat{\\pmb{\\sigma}}^{i}-\\sigma_{f}^{i},\\pmb{x}^{i}\\right),\\quad\\hat{\\pmb{\\sigma}}_{\\ast}^{i}=\\hat{\\pmb{\\sigma}}_{\\Delta}^{i}+\\sigma_{f}^{i},}\\\\ {\\hat{\\pmb{\\mu}}_{\\Delta}^{i}=\\mathrm{MP}\\left(\\hat{\\pmb{\\mu}}^{i}-\\mu_{f}^{i},\\pmb{x}^{i}-\\mu_{f}^{i}\\right),\\quad\\hat{\\pmb{\\mu}}_{\\ast}^{i}=\\hat{\\pmb{\\mu}}_{\\Delta}^{i}+\\mu_{f}^{i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, $\\mu_{f}^{i}$ and $\\sigma_{f}^{i}$ are the mean values of ${\\hat{\\pmb{\\mu}}}^{i}$ and ${\\hat{\\pmb{\\sigma}}}^{i}$ . While $\\hat{\\pmb{\\mu}}_{*}^{i}$ and $\\hat{\\sigma}_{\\ast}^{i}$ denote the prediction of ${\\hat{\\pmb{\\mu}}}^{i}$ and ${\\hat{\\pmb{\\sigma}}}^{i}$ . The MP is a mean prediction branch, and the SP is a standard deviation prediction branch. They are affiliated with DPM and adopt the same network structure. ", "page_idx": 4}, {"type": "text", "text": "Time Domain Prediction As the above frequency domain prediction process, for the distribution statistics of TDN, this prediction process can be formulated as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pmb{\\sigma}_{\\Delta}^{i}=\\mathrm{SP}\\left(\\pmb{\\sigma}^{i}-\\sigma_{o}^{i},\\pmb{x}^{i}\\right),\\quad\\pmb{\\sigma}_{\\ast}^{i}=\\pmb{\\sigma}_{\\Delta}^{i}+\\sigma_{o}^{i},}\\\\ {\\pmb{\\mu}_{\\Delta}^{i}=\\mathrm{MP}\\left(\\pmb{\\mu}^{i}-\\mu_{o}^{i},\\pmb{x}^{i}-\\mu_{o}^{i}\\right),\\quad\\pmb{\\mu}_{\\ast}^{i}=\\pmb{\\mu}_{\\Delta}^{i}+\\mu_{o}^{i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Here, $\\mu_{o}^{i}$ and $\\boldsymbol{\\sigma}_{o}^{i}$ are the mean values of $\\pmb{\\mu}^{i}$ and $\\sigma^{i}$ , respectively. Likewise, $\\pmb{\\mu}_{*}^{i}$ and $\\boldsymbol{\\sigma}_{\\ast}^{i}$ denote the prediction of $\\pmb{\\mu}^{\\imath}$ and $\\sigma^{i}$ . The SP and the MP are noted in frequency domain prediction. ", "page_idx": 4}, {"type": "image", "img_path": "RVZfra6sZo/tmp/d731b616d21dedeb3e67771ce74e6987deff9131d72047f21df2ce27a3f47a10.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 3: The architecture of the distribution prediction model primarily consists of two predictive branches: the Mean Prediction branch and the Standard Deviation (Std) Prediction branch. The specific network structure of these branches is illustrated in the Prediction Branch. ", "page_idx": 5}, {"type": "text", "text": "De-normalization. After the aforementioned distribution predictions, two sets of estimated distribution statistics will be gained. Which are weighted to reconstruct the non-stationary information of the output of the time series forecasting model. This process can be described as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mu_{*}^{i}=\\mu_{*}^{i}\\cdot\\beta+\\hat{\\mu}_{*}^{i}\\cdot\\alpha,\\ }&{\\sigma_{*}^{i}=\\sigma_{*}^{i}\\cdot\\beta+\\hat{\\sigma}_{*}^{i}\\cdot\\alpha,\\quad\\bar{\\pmb{x}}^{i}=\\bar{\\pmb{x}}^{i}\\cdot\\beta+\\hat{\\pmb{x}}^{i}\\cdot\\alpha.}\\\\ &{y_{*}^{i}=\\bar{y}_{*}^{i}\\odot\\left(\\sigma_{*}^{i}+\\epsilon\\right)+\\mu_{*}^{i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Where $\\bar{\\pmb{y}}_{\\ast}^{i}$ is the output of the time series forecasting model, and $\\pmb{y}_{\\ast}^{i}$ represents the predicted sequence after reconstructing non-stationary information. While $\\alpha,\\beta$ , and $\\epsilon$ mentioned before. ", "page_idx": 5}, {"type": "text", "text": "3.4 Collaborative Training ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Distribution prediction and future series forecasting are essentially a bi-level optimization problem [35, 36, 37], where distribution outputs significantly impact the future series output. To enhance the training effects of our models, we pre-train the DPM to yield a relatively well-trained DPM. This procedure can be formulated as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\theta_{d}=\\arg\\operatorname*{min}_{\\mathrm{MSE}}\\left(\\left(\\mu_{\\ast}^{i},\\sigma_{\\ast}^{i}\\right),\\left(\\mu_{y}^{i},\\pmb{\\sigma}_{y}^{i}\\right),\\theta_{d}\\right).\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Where $\\theta_{d}$ represents the parameters of the DPM, it is noteworthy that the wavelet bases $\\phi_{l,h}$ and the weighted factor $\\alpha$ belong to $\\theta_{d}$ . We select the mean square error (MSE) as our loss function between the predicted distribution and the ground truth of the distribution, acquired from the future sequence through TDN. Subsequently, assuming a total training duration of $T$ epochs, the parameters $\\theta_{d}$ of the DPM will be frozen, then we train FM for $T_{1}$ epochs. Finally, DPM and FM will be subject to collaborative training during the remaining $T-T_{1}$ epochs. The process is as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\theta_{f}=\\arg\\operatorname*{min}_{\\mathrm{MSE}}\\left(y_{\\ast}^{i},y_{y}^{i},\\theta_{f}\\right),\\quad\\mathrm{if}\\ t\\leq T_{1},}\\\\ {\\{\\theta_{d},\\theta_{f}\\}=\\arg\\displaystyle\\operatorname*{min}_{\\mathrm{MSE}}\\left(y_{\\ast}^{i},y_{y}^{i},\\{\\theta_{d},\\theta_{f}\\}\\right),\\quad\\mathrm{otherwise}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Where $t$ denotes the $t^{t h}$ epoch during the training process, and $\\phi_{f}$ represents the parameters of the FM. We train DPM and FM concurrently to mitigate potential errors in the pretraining stage, as the ground truth of distribution is drived from future sequences based on distritution assumption. This ground truth is somewhat inconsistent with the actual situation and fails to account for high-frequency distribution changes. Consequently, we pretrain the DPM using assumption-based distribution ground truth, and then collaborative train it jointly based on the loss derived from the future sequences. ", "page_idx": 5}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we conduct comprehensive experiments on multiple real-world time series datasets to assess the effectiveness of our proposed reversible normalization method DDN. ", "page_idx": 5}, {"type": "text", "text": "Datasets We conduct extensive experiments on these seven popular real-world datasets [18], including Electricity Transformer Temperature (ETT) with its four subsets (ETTh1, ETTh2, ETTm1, ETTm2), Weather, Electricity, and Traffic. The setting of these datasets following original works [18, 20], and more descriptions about these datasets present in appendix A.1. ", "page_idx": 6}, {"type": "text", "text": "Baselines. DDN is a model-agnostic method that can be applied to any mainstream time series forecasting model. To demonstrate its versatility, we integrate DDN into several representative models, including the earlier proposed models FEDformer [19] and Autoformer [20], the CI model DLinear [27], and the CD model iTransformer [24]. ", "page_idx": 6}, {"type": "text", "text": "Implementation details. Our experiments were conducted three times with a consistent random seed and averaged to mean values. The Mean Square Error (MSE) and Mean Absolute Error (MAE) are chosen as evaluation metrics, with MSE serving as the training loss. All models use the same prediction lengths $T\\,=\\,\\{96,192,336,720\\}$ . For the look-back window $L$ , Autoformer [20] and FEDformer [19] use $L\\,=\\,96$ , while DLinear [27] and iTransformer [24] utilize $L\\,=\\,336$ and $L\\,=\\,720$ respectively. The wavelet bases initialize to the \u201ccoiflet\u201d bases, the default size of our sliding window is set to 7 for information content and temporal locality balance, and $\\alpha$ starts at zero. More implementation details of our experiments can be referred to appendix A.2. ", "page_idx": 6}, {"type": "text", "text": "4.1 Main Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "As illustrated, the DDN method significantly enhances the predictive performance of the four different baselines across nearly all datasets. For the MSE metric, this improvement is particularly evident in the three relatively large datasets: Weather, Electricity, and Traffic. Utilizing DDN, Autoformer achieves a relative error reduction of $19.2\\%$ , $24.7\\%$ , and $25.6\\%$ , respectively, while FEDformer achieves a relative error reduction of $13.1\\%$ , $16.2\\%$ , and $22.3\\%$ . Similarly, incorporating the DDN into the other models also results in substantial performance gains. Additionally, Autoformer, FEDformer, and DLinear do not employ reversible normalization in official implements. While iTransformer utilizes the RevIN [11] normalization technique based on static statistics. However, replacing the RevIN module in iTransformer with the DDN module still yields significant performance improvements. These results strongly demonstrate that DDN makes the baseline model more robust in forecasting. ", "page_idx": 6}, {"type": "table", "img_path": "RVZfra6sZo/tmp/795dea342bdf923f1813bdee0e42a80efb26e64a775bd37178d62462f45ab338.jpg", "table_caption": [], "table_footnote": ["Table 2: Multivariate long-term forecasting results. The best results are highlighted in bold. More results can be found in Appendix D.1. "], "page_idx": 6}, {"type": "text", "text": "4.2 Comparison With Reversible Normalization Methods ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Quantitative evaluation. In this part, we compare recent representative reversible normalization methods using the average MSE metric across four prediction lengths in $\\{96,192,336,720\\}$ . Detailed descriptions of these methods and links for access are provided in the Appendix B. As shown in Table 3, DDN not only significantly enhances the predictive performance of the baseline models, including RevIN [11], NTS [13], and Dish-TS [12], but also demonstrates superior results when compared to existing reversible normalization methods. For instance, taking the recent slice-level SAN [14] method as an example, DDN achieves substantial improvements even upon its solid foundation. Further comparative details are detailed in Appendix D.2. ", "page_idx": 7}, {"type": "table", "img_path": "RVZfra6sZo/tmp/009373c53a9a1ff5580009e464814a31161e8bddc0900c25b8fc7223cd12c1f9.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "RVZfra6sZo/tmp/466cb4dd66068b4ffbd3d760d517b4a5df20297b415cf408d82e3bf9356561c2.jpg", "table_caption": ["Table 3: Comparison between DDN and existing reversible normalization methods of varying granularities. IMP represents the relative percentage improvement of DDN over the original sequence. The best results are highlighted in bold. "], "table_footnote": ["Table 4: Comparison of forecasting errors between the DDN and SAN. The best results are highlighted in bold. "], "page_idx": 7}, {"type": "text", "text": "Considering that early models often lacked robust generalizability as their naive modeling strategies, we additionally included comparisons with two recent representative models: DLinear [27] (modeling features with CI) and iTransformer [24] (modeling features with CD). These methods already have good non-stationary adaptability, so they can better reflect the performance upper limit of fine-grained normalization methods. As illustrated in table 4, DDN significantly outperforms the recent stateof-the-art model SAN in handling non-stationary information. Overall, DDN almost achieves the best performance compared to SAN in every forecasting case. Specifically, on the Traffic dataset, SAN [14] struggles to achieve satisfactory predictive performance and even performs worse than the original predictive model. In contrast, DDN demonstrates effects by a finer-grain non-stationarity processing. ", "page_idx": 7}, {"type": "text", "text": "Qualitative Evaluation. As shown in the figure 4, we compare DDN with reversible normalization methods at different granularities. It can be observed that there are significant differences among the various reversible normalization methods, which are related to their specific implementations. From subplots (a) and (b), it is evident that RevIN [11] reconstructs non-stationary information based on the distribution characteristics of historical sequences, making the distribution of the predicted sequence closer to that of the historical sequence rather than future sequence. However, as significant distribution differences between historical and future sequences, this approach may even degrade the predictive accuracy. Comparing subplots (c) and (d), although slice level SAN [14] significantly improves overall predictive performance, it still lags behind point level DDN in terms of fine-grained variations. Additionally, it is worth highlighting that the fine-grained capability of DDN enables the reconstructed sequence to exhibit rapid local fluctuations flexibly. More comparisons can be found in Appendix C. ", "page_idx": 7}, {"type": "image", "img_path": "RVZfra6sZo/tmp/ef2bfac62bf0b7f77b23a4e7566b046d248464a35d3bfa62c4ec9bf7643781fc.jpg", "img_caption": ["Figure 4: Comparison of reversible normalization methods, samples from DLiner [27] weather dataset forecasting. Green solid lines represent the mean of the historical and predicted sequences. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "4.3 Dual-domain Dynamic Normalization Analysis ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To validate the effectiveness of FDN and TDN, we conducted ablation studies comparing the predictive performance when only using FDN or TDN for non-stationary processing. It is important to note that when using FDN only for non-stationary processing, the ground truth of DPM pretraining comes from the non-stationary factors of FDN on future sequences. Correspondingly, wavelet bases will be set to nonlearnable parameters when we use FDN only. Meanwhile, for a fair comparison, both FDN and TDN in DDN utilize the same prediction model and share parameters, thereby avoiding the misconception that the superior performance of DDN stems from a larger parameter space in the prediction model. ", "page_idx": 8}, {"type": "text", "text": "The results of the ablation studies, as shown in Table 5, indicate that both FDN and TDN achieved outstanding performance, with FDN often reaching comparable or even superior predictive results compared to TDN alone. Furthermore, when we use FDN and TDN simultaneously, the predictive performance of DDN approaches even surpasses the best performance of FDN or TDN alone. It validates the effectiveness of TDN in capturing fine-grained non-stationarity at the point level in the time domain while confirming the robustness of FDN separating frequency components with different rapid changes in the frequency domain, thus enabling more refined non-stationary processing. ", "page_idx": 8}, {"type": "table", "img_path": "RVZfra6sZo/tmp/75cbf2b6a5d8fb82dacc2423db80abb86dd4758a1f33c55263de2dacd3a86e86.jpg", "table_caption": [], "table_footnote": ["Table 5: Ablation study of FDN and TDN. \u201cTDN Only\" and \u201cFDN Only\" indicate normalization using TDN only and FDN only, respectively. The best results are highlighted in bold. "], "page_idx": 8}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this work, we propose Dual-domain Dynamic Normalization (DDN), a novel method that dynamically captures non-stationary factors in time series forecasting, addressing sudden changes and distribution drifts in both time and frequency domains. Specifically, DDN employs sliding normalization in the time domain to eliminate and reconstruct non-stationary factors at a fine-grained level. In the frequency domain, it decomposes time series into high and low frequencies, effectively capturing rapid variations and sudden changes. As a model-agnostic auxiliary module, DDN significantly enhances the predictive performance of various forecasting models. Extensive experiments on seven real-world datasets validate the superiority of DDN, demonstrating its effectiveness in addressing distribution drift and improving the reliability of time series predictions. ", "page_idx": 9}, {"type": "text", "text": "6 Acknowledgments ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work is supported in part by the National Natural Science Foundation of China, under Grant (62302309, 62171248), Shenzhen Science and Technology Program (JCYJ20220818101014030, JCYJ20220818101012025), and the PCNL KEY project (PCL2023AS6-1). ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] Zahra Karevan and Johan AK Suykens. Transductive lstm for time-series prediction: An application to weather forecasting. Neural Networks, 125:1\u20139, 2020. 1   \n[2] Chirag Deb, Fan Zhang, Junjing Yang, Siew Eang Lee, and Kwok Wei Shah. A review on time series forecasting techniques for building energy consumption. Renewable and Sustainable Energy Reviews, 74:902\u2013924, 2017. 1 [3] Marco Lippi, Matteo Bertini, and Paolo Frasconi. Short-term traffic flow forecasting: An experimental comparison of time-series analysis and supervised learning. IEEE Transactions on Intelligent Transportation Systems, 14(2):871\u2013882, 2013. 1   \n[4] Tao Dai, Beiliang Wu, Peiyuan Liu, Naiqi Li, Jigang Bao, Yong Jiang, and Shu-Tao Xia. Periodicity decoupling framework for long-term series forecasting. In The Twelfth International Conference on Learning Representations, 2024. 1, 3   \n[5] Nikita Kitaev, \u0141ukasz Kaiser, and Anselm Levskaya. Reformer: The efficient transformer. arXiv preprint arXiv:2001.04451, 2020. 1   \n[6] Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang, and Xifeng Yan. Enhancing the locality and breaking the memory bottleneck of transformer on time series forecasting. Advances in neural information processing systems, 32, 2019. 1 [7] Ruofeng Wen, Kari Torkkola, Balakrishnan Narayanaswamy, and Dhruv Madeka. A multihorizon quantile recurrent forecaster. arXiv preprint arXiv:1711.11053, 2017. 1   \n[8] Tonya Fields, George Hsieh, and Jules Chenou. Mitigating drift in time series data with noise augmentation. In 2019 International Conference on Computational Science and Computational Intelligence (CSCI), pages 227\u2013230. IEEE, 2019. 1   \n[9] Jie Lu, Anjin Liu, Fan Dong, Feng Gu, Joao Gama, and Guangquan Zhang. Learning under concept drift: A review. IEEE transactions on knowledge and data engineering, 31(12):2346\u2013 2363, 2018. 1   \n[10] Wendi Li, Xiao Yang, Weiqing Liu, Yingce Xia, and Jiang Bian. Ddg-da: Data distribution generation for predictable concept drift adaptation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 4092\u20134100, 2022. 1   \n[11] Taesung Kim, Jinhee Kim, Yunwon Tae, Cheonbok Park, Jang-Ho Choi, and Jaegul Choo. Reversible instance normalization for accurate time-series forecasting against distribution shift. In International Conference on Learning Representations, 2021. 1, 2, 3, 7, 8, 21, 22   \n[12] Wei Fan, Pengyang Wang, Dongkun Wang, Dongjie Wang, Yuanchun Zhou, and Yanjie Fu. Dish-ts: a general paradigm for alleviating distribution shift in time series forecasting. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 7522\u20137529, 2023. 2, 3, 5, 8, 21, 22   \n[13] Yong Liu, Haixu Wu, Jianmin Wang, and Mingsheng Long. Non-stationary transformers: Exploring the stationarity in time series forecasting. Advances in Neural Information Processing Systems, 35:9881\u20139893, 2022. 2, 3, 8, 21, 22   \n[14] Zhiding Liu, Mingyue Cheng, Zhi Li, Zhenya Huang, Qi Liu, Yanhu Xie, and Enhong Chen. Adaptive normalization for non-stationary time series forecasting: A temporal slice perspective. Advances in Neural Information Processing Systems, 36, 2024. 2, 3, 8, 9, 21, 22   \n[15] Pimwadee Chaovalit, Aryya Gangopadhyay, George Karabatis, and Zhiyuan Chen. Discrete wavelet transform-based time series analysis and mining. ACM Computing Surveys (CSUR), 43(2):1\u201337, 2011. 2   \n[16] Shyh-Jier Huang and Cheng-Tao Hsieh. Coiflet wavelet transform applied to inspect power system disturbance-generated signals. IEEE Transactions on Aerospace and Electronic Systems, 38(1):204\u2013210, 2002. 2   \n[17] Eric Zivot, Jiahui Wang, Eric Zivot, and Jiahui Wang. Rolling analysis of time series. Modeling financial time series with S-Plus\u00ae, pages 299\u2013346, 2003. 2   \n[18] Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang. Informer: Beyond efficient transformer for long sequence time-series forecasting. In Proceedings of the AAAI conference on artificial intelligence, volume 35, pages 11106\u201311115, 2021. 2, 7, 20   \n[19] Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. Fedformer: Frequency enhanced decomposed transformer for long-term series forecasting. In International conference on machine learning, pages 27268\u201327286. PMLR, 2022. 2, 7, 21, 26   \n[20] Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. Autoformer: Decomposition transformers with auto-correlation for long-term series forecasting. Advances in neural information processing systems, 34:22419\u201322430, 2021. 2, 7, 20, 21, 26   \n[21] Yi Zheng, Qi Liu, Enhong Chen, Yong Ge, and J Leon Zhao. Exploiting multi-channels deep convolutional neural networks for multivariate time series classification. Frontiers of Computer Science, 10:96\u2013112, 2016. 3   \n[22] Andreia Dionisio, Rui Menezes, and Diana A Mendes. Mutual information: a measure of dependency for nonlinear time series. Physica A: Statistical Mechanics and its Applications, 344(1-2):326\u2013329, 2004. 3   \n[23] Stefan Frenzel and Bernd Pompe. Partial mutual information for coupling analysis of multivariate time series. Physical review letters, 99(20):204101, 2007. 3   \n[24] Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and Mingsheng Long. itransformer: Inverted transformers are effective for time series forecasting. In The Twelfth International Conference on Learning Representations, 2023. 3, 7, 8, 20, 21   \n[25] Yunhao Zhang and Junchi Yan. Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting. In The eleventh international conference on learning representations, 2022. 3   \n[26] Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth 64 words: Long-term forecasting with transformers. In The Eleventh International Conference on Learning Representations, 2022. 3   \n[27] Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are transformers effective for time series forecasting? In Proceedings of the AAAI conference on artificial intelligence, volume 37, pages 11121\u201311128, 2023. 3, 7, 8, 9, 21, 24, 25 [28] Qingsong Wen, Weiqi Chen, Liang Sun, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan, et al. Onenet: Enhancing time series forecasting models under concept drift by online ensembling. Advances in Neural Information Processing Systems, 36, 2024. 3 [29] Lu Han, Han-Jia Ye, and De-Chuan Zhan. The capacity and robustness trade-off: Revisiting the channel independent strategy for multivariate time series forecasting. arXiv preprint arXiv:2304.05206, 2023. 3 [30] Luo donghao and wang xue. ModernTCN: A modern pure convolution structure for general time series analysis. In The Twelfth International Conference on Learning Representations,   \n2024. 3 [31] Xue Wang, Tian Zhou, Qingsong Wen, Jinyang Gao, Bolin Ding, and Rong Jin. Card: Channel aligned robust blend transformer for time series forecasting. In The Twelfth International Conference on Learning Representations, 2023. 3 [32] Shohreh Deldari, Daniel V Smith, Hao Xue, and Flora D Salim. Time series change point detection with self-supervised contrastive predictive coding. In Proceedings of the Web Conference   \n2021, pages 3124\u20133135, 2021. 3 [33] Kwei-Herng Lai, Daochen Zha, Junjie Xu, Yue Zhao, Guanchu Wang, and Xia Hu. Revisiting time series outlier detection: Definitions and benchmarks. In Thirty-ffith conference on neural information processing systems datasets and benchmarks track (round 1), 2021. 3 [34] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016. 5 [35] Risheng Liu, Jiaxin Gao, Jin Zhang, Deyu Meng, and Zhouchen Lin. Investigating bi-level optimization for learning and vision from a unified perspective: A survey and beyond. IEEE Transactions on Pattern Analysis and Machine Intelligence, 44(12):10045\u201310067, 2021. 6 [36] El-Ghazali Talbi. A taxonomy of metaheuristics for bi-level optimization. In Metaheuristics for bi-level optimization, pages 1\u201339. Springer, 2013. 6 [37] Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, and Edison Guo. On differentiating parameterized argmin and argmax problems with application to bi-level optimization. arXiv preprint arXiv:1607.05447, 2016. 6 [38] Graham Elliott, Thomas J Rothenberg, and James H Stock. Efficient tests for an autoregressive unit root, 1992. 20 [39] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 20 ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 12}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 12}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 12}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 12}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 12}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 12}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 12}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 12}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Justification: We have clearly outlined the main contributions of this paper in the abstract and introduction sections. ", "page_idx": 12}, {"type": "text", "text": "Guidelines: ", "page_idx": 12}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 12}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 12}, {"type": "text", "text": "Justification: We have mentioned it in both the methods and experimental analysis sections. Guidelines: ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 13}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Justification: We have clearly outlined the assumption and proof of this paper in the Introduction, Method, and Appendix sections. ", "page_idx": 13}, {"type": "text", "text": "Guidelines: ", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 13}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 13}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 13}, {"type": "text", "text": "Justification: We have clearly outlined the experiment details in the Experiments and Appendix sections.   \nGuidelines: ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 14}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 14}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Justification: We provide the code link in the abstract. ", "page_idx": 14}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ", "page_idx": 14}, {"type": "text", "text": "\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 15}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: We have clearly outlined the experiment details in the Experiments and Appendix sections. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 15}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: We have conducted relevant analysis in both the experimental and appendix sections and the experimental results were obtained by averaging three times. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 15}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 15}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 15}, {"type": "text", "text": "Justification: We have clearly outlined the GPU version, programming languages and main libraries in the Appendix sections. ", "page_idx": 15}, {"type": "text", "text": "Guidelines: ", "page_idx": 15}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 15}, {"type": "text", "text": "\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 16}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: Our research conducted in the paper conform the ethics. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 16}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 16}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 16}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 16}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 16}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 16}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 17}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: We have clearly outlined the links of these assets in the Appendix sections. Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 17}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 17}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 17}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 17}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 18}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 18}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 18}, {"type": "text", "text": "Justification: This paper paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 18}, {"type": "text", "text": "A Experiments Setting ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "A.1 Dataset Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Our comprehensive experiments are conducted on seven time series datasets. Consistent with the methodologies of [18, 20, 24], we partition all datasets chronologically into training, validation, and testing subsets. Specifically, for the ETT dataset, we adopted a 6:2:2 split ratio, while a 7:1:2 ratio was utilized for the other datasets. Detailed descriptions of these datasets are as follows: ", "page_idx": 19}, {"type": "text", "text": "(1) ETT-small3 (Electricity Transformer Temperature) dataset: Comprises data from electricity transformers in two regions of China, collected between July 2016 and July 2018. It offers two different granularities: ETTh (1 hour) and ETTm (15 minutes). Each data point includes the value of oil temperature and six external power load features.   \n(2) Weather4 dataset: Comprises 21 distinct meteorological measurements in Germany, recorded every 10 minutes throughout 2020. It features key indicators such as air temperature and visibility, providing an in-depth view of weather patterns.   \n(3) Electricity5 dataset: Contains hourly electricity consumption data in kilowatt-hours (kWh) for 321 clients from 2012 to 2014, sourced from the UCI Machine Learning Repository.   \n(4) Traffic6 dataset: Features hourly data on road occupancy rates from 862 detectors in the San Francisco Bay area freeways, covering 2015 to 2016. ", "page_idx": 19}, {"type": "text", "text": "We provide access to all datasets through https://github.com/thuml/iTransformer. Detailed statistics for these datasets, including time steps, channels, and ADF test [38] results (evaluate the stationarity of a time series; a smaller value indicates greater non-stationarity.), are presented in Table A.1. ", "page_idx": 19}, {"type": "table", "img_path": "RVZfra6sZo/tmp/2698603864183aa2ee67ad40ff2040995588cc97598de7cdfe583b58fde5614c.jpg", "table_caption": ["Table 6: The statistics of datasets. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "A.2 Setting Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "All experiments were conducted using PyTorch on a single NVIDIA 3090 24GB GPU. We utilize the ADAM optimizer [39] with an initial learning rate of $\\bar{1}e^{-4}$ for the distribution prediction model and employing Mean Squared Error (MSE) loss. The batch size, training epochs, and other baseline settings remain consistent with iTransformer [24]. The network for mean or standard deviation prediction comprises two feedforward Neural Network (FFN) layers, with dimensions of 512 for the first layer and 1024 for the second layer. We initialize the wavelet as Coiflet3, with $\\alpha$ starting from 0. We conduct pre-training for 5 epochs and commence collaborative training from either the first or second epoch based on specific settings and datasets, aiming for improved training and model ftiting. ", "page_idx": 19}, {"type": "text", "text": "A.3 Baseline Methods ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Our baseline methods are described as follows: ", "page_idx": 20}, {"type": "text", "text": "\u2022 Autoformer [20] is a transformer-based approach that adopts a decomposition strategy to learn complex temporal patterns in long-term prediction scenarios, decomposing time series into trend, cycle, and seasonal components, reflecting the long-term and seasonal aspects of the sequence data, respectively. The source code is available at https://github.com/ thuml/Autoformer.   \n\u2022 FEDformer [19] is a hybrid Transformer-based model that integrates seasonal-trend decomposition and frequency enhancements. It can efficiently capture both global variations and intricate patterns. The source code is available at https://github.com/MAZiqing/ FEDformer.   \n\u2022 DLinear [27] is a one-layer linear model challenging the efficacy of Transformer-based approaches in long-term time series forecasting, demonstrating superior performance on multiple datasets. The source code is available at https://github.com/cure-lab/ LTSF-Linear.   \n\u2022 iTransformer [24] is a transformer-based model. The time series serve as variable tokens, utilizing self-attention mechanisms to capture correlations between multiple variables and using feedforward networks to encode the sequence representation. The source code is available at https://github.com/thuml/iTransformer. ", "page_idx": 20}, {"type": "text", "text": "B Reversible Normalization ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Related reversible normalization methods are described in table 7, and they are described as follows: ", "page_idx": 20}, {"type": "text", "text": "\u2022 RevIN [11] introduces a data normalization method that addresses the limitations of simply eliminating non-stationary information, which can result in the loss of valuable data that the model needs to learn effectively. Unlike traditional methods that may lead to the model\u2019s inability to capture these critical non-stationary factors, this work proposes, for the first time, an explicit restoration of non-stationary information after the model\u2019s output. This ensures that while the model can learn without being affected by data drift, it also retains the essential non-stationary information. The source code is available at https: //github.com/ts-kim/RevIN.   \n\u2022 NST [13] unlikes traditional time series forecasting methods that reduce non-stationarity by stabilizing the original data, this approach contradicts the importance of predicting sudden events in time series forecasting and overlooks the prevalence of non-stationary data in real-world scenarios, ultimately leading to overly stabilized modeling and prediction. To address this, this paper proposes a novel network architecture composed of sequence stabilization and inverse stabilization attention mechanisms. The source code is available at https://github.com/thuml/Nonstationary_Transformers.   \n\u2022 Dish-TS [12] notes that existing work on distribution shift in time series is often limited by distribution quantization and tends to overlook the potential distribution shift between the look back window and the horizon. To address this, this paper proposes using an MLP-based network to predict mean and standard deviation separately for the look back and horizon windows. The source code is available at https://github.com/weifantt/Dish-TS.   \n\u2022 SAN [14] indicates previous efforts on addressing non-stationarity have attempted to reduce it through normalization techniques. However, these methods typically overlook the distributional differences between input sequences and horizon sequences, assuming that all time points within the same instance share identical statistical properties. This overly idealistic approach can lead to suboptimal improvements. To address this issue, this paper introduces a novel slice-level adaptive normalization method. The source code is available at https://github.com/icantnamemyself/SAN. ", "page_idx": 20}, {"type": "text", "text": "Although NST [13] claims that non-stationary information can enhance feature diversity, previous methods have suffered from over-stationarization and inadequate consideration of non-stationary information utilization. However, it is noteworthy that, upon reviewing the current implementation of the non-stationary transformer, the designed non-stationary information extraction module and the corresponding integration of this information into intermediate feature learning can essentially be seen as a mode that employs a distribution prediction network to estimate future non-stationary information and learns through the prediction network. Figure 5 presents a visual comparison of the effects with and without the integration of non-stationary information extraction. It is evident that the non-stationary information extraction and integration module fundamentally enables more accurate reconstruction of non-stationary information, such as mean value. ", "page_idx": 20}, {"type": "image", "img_path": "RVZfra6sZo/tmp/c70e2fa624d9bec206f369fd1b47506cc3a27bcd2a4f95ceca7f5eef4919daa3.jpg", "img_caption": ["Figure 5: The comparison of NST [13], \u201dMerge\u201d means using non-stationary factors extraction module and merge to feature, \u2019No Merge\u201d is the opposite. ", "Table 7: Comparative overview of non-stationary processing techniques in time series forecasting. \u201cGranularity\u201d and \u201cEstimation\u201d denote the normalization fineness and the prediction derivation method, respectively. "], "img_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "RVZfra6sZo/tmp/88dc65f6b9d1868a488eb6e2d2bfddfac7088030645838d6efbbd84018f0df1a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "B.1 Discrete Wavelet Transform ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "The Discrete Wavelet Transform (DWT) offers a nuanced approach to signal analysis by decomposing a time series into distinct frequency bands at multiple resolutions. This method is particularly adept at pinpointing both frequency and temporal aspects of a signal, making it invaluable for analyzing non-stationary time series. Initially, the general DWT of a time series $x(t)$ is expressed through the wavelet coefficients: ", "page_idx": 22}, {"type": "equation", "text": "$$\nx_{\\phi}(a,b)={\\frac{1}{\\sqrt{|a|}}}\\sum_{t}x(t)\\cdot\\phi\\left({\\frac{t-b}{a}}\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $a$ and $b$ denote the scaling and translation parameters, respectively, and $\\phi$ is the mother wavelet function. Building upon this foundation, the DWT isolates the approximation coefficients (AC) and detail coefficients (DC), which capture distinct signal characteristics: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{x_{a c}^{i}=\\mathrm{DWT}_{\\phi_{\\mathrm{low}}}(x^{i})=\\displaystyle\\sum_{t}x(t)\\cdot\\phi_{\\mathrm{low}}(t),}\\\\ &{x_{d c}^{i}=\\mathrm{DWT}_{\\phi_{\\mathrm{high}}}(x^{i})=\\displaystyle\\sum_{t}x(t)\\cdot\\phi_{\\mathrm{high}}(t),}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\phi_{\\mathrm{low}}(t)$ represents the low-pass filter and $\\phi_{\\mathrm{high}}(t)$ the high-pass filter. Together, these filters facilitate the separation of the input time series into $x_{a c}^{i}$ and $x_{d c}^{i}$ . The AC coefficients $x_{a c}^{i}$ embody the low-frequency components that outline the overarching trends within the time series, whereas the DC coefficients $\\dot{x}_{d c}^{i}$ encompass the high-frequency components, often associated with transient or noise elements in the signal. ", "page_idx": 22}, {"type": "text", "text": "The Inverse Discrete Wavelet Transform (IDWT) is then utilized to reconstruct the signal from its wavelet coefficients. The IDWT is the process that combines the AC and DC to form the original signal or an approximation of it. The reconstruction using IDWT can be written as: ", "page_idx": 22}, {"type": "equation", "text": "$$\nx^{i}(t)=\\mathrm{IDWT}(x_{a c}^{i},x_{d c}^{i})=\\sum_{a}x_{a c}^{i}(a)\\cdot\\phi_{a c}(a,t)+\\sum_{b}x_{d c}^{i}(b)\\cdot\\phi_{d c}(b,t)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\phi_{a c}(a,t)$ and $\\phi_{d c}(b,t)$ are the reconstruction functions from the approximation and detail coefficients, respectively. The wavelet transform, with its ability to localize both frequency and time, provides a powerful framework for signal analysis, particularly for signals like time series that contain non-stationary elements. ", "page_idx": 22}, {"type": "image", "img_path": "RVZfra6sZo/tmp/8b924993c422d707a371902f1c61ebbd5c6898909f8a9499c8685491e0eb0959.jpg", "img_caption": ["Figure 6: Comparison of reversible normalization methods, samples from DLiner [27] weather dataset forecasting. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "RVZfra6sZo/tmp/b28ac7d78896ff7f53d7bf2107a5362033be5e9d49386b24b574faa8fe879ea9.jpg", "img_caption": ["Figure 7: Comparison of reversible normalization methods, samples from DLiner [27] weather dataset forecasting. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "RVZfra6sZo/tmp/2da70fc305c08e78f89f25258978464ebd6ff0cad29a92d9ec1b21d93d6e7793.jpg", "img_caption": ["Figure 8: Comparison of reversible normalization methods, samples from DLiner [27] weather dataset forecasting. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "C Visualization of Experiments ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "As illustrated in Figure 4, we present visual comparisons of predictions between different reversible normalization methods on the Weather dataset using DLinear [27]. The look-back window $L$ is 336, and the prediction length $T$ is 192. As discussed in Section 4.2, Figures 6, 7, and 8 highlight the necessity of a distribution change prediction module. Meanwhile, Figures 9 and 10 demonstrate the DDN method\u2019s superior capability in capturing details compared to the SAN method. This is particularly evident in the richer rapid changes present in its predictive output, allowing for dynamic adaptation and alignment with the rapidly changing data series in specific datasets. ", "page_idx": 23}, {"type": "text", "text": "To further substantiate this point, we conducted a visual comparison on the relatively smooth Traffic dataset in Figure 11, where these rapid changes also corresponded well with those in the original sequence, contrasting with the Weather dataset. This comparison underscores the enhanced detail and adaptability of the DDN method across different datasets. ", "page_idx": 23}, {"type": "image", "img_path": "RVZfra6sZo/tmp/52ceef29f3e959caccc6cca76b441b36b94157d45b19160bce3eeb89a821bb3e.jpg", "img_caption": ["Figure 9: Comparison with slice level reversible normalization, samples from DLiner [27] weather dataset forecasting. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "RVZfra6sZo/tmp/8bdea819be0acde40c57e27bb1628d3241870afbb2a3bf57d1756eba1a978372.jpg", "img_caption": ["Figure 10: Comparison with slice level reversible normalization, samples from DLiner [27] weather dataset forecasting. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "RVZfra6sZo/tmp/62f07f8584aa4d6e9233d844427510c8628d820fb56e5cd868de74d872fcd7e0.jpg", "img_caption": ["Figure 11: Our DDN reversible normalization method, samples from DLiner [27] Traffic dataset forecasting. "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "D Quantitative Evaluation Supplement ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "D.1 Multivariable Forecasting Results of ETT ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "As illustrated in table 8, we present the comprehensive multivariate forecasting results on the ETT dataset in Table 5, encompassing the hourly datasets ETTh1 and ETTh2, as well as the 15- ", "page_idx": 24}, {"type": "text", "text": "minute datasets ETTm1 and ETTm2. The data clearly indicate that DDN demonstrates substantial enhancements across these datasets when applied to various backbone models. ", "page_idx": 25}, {"type": "table", "img_path": "RVZfra6sZo/tmp/8600101e5dce293e88674f7ca32280e1c954bbde4b849599974e41af2e517edc.jpg", "table_caption": [], "table_footnote": ["Table 8: Forecasting results comparison under different prediction lengths $T\\in\\{96,192,336,720\\}$ on ETT dataset. The input sequence length $L=96$ for Autoformer and FEDformer, $L=336$ for DLinear, and $L=720$ for iTransformer. The bold values indicate best performance. "], "page_idx": 25}, {"type": "text", "text": "D.2 Comparison between DDN and Reversible Normalization Methods ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "This section comprehensively compares DDN with existing reversible normalization methods. As shown in Table 9, our method consistently achieves state-of-the-art performance across almost all datasets, with a slight under-performance on the ETTm1 dataset compared to SAN. This demonstrates the versatility and effectiveness of our approach. ", "page_idx": 25}, {"type": "text", "text": "D.3 Collaborative Training Ablation ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Although recent works have shown that the two-stage training strategy effectively enhances the training of distribution prediction models, this training overly relies on the distribution ground truth obtained through distribution assumptions, which often contain inaccuracies. To address this, we introduce a collaborative training strategy that adjusts the distribution prediction model using the MSE loss between the actual sequence and the prediction during training. As illustrated in table 10, collaborative training generally yields superior training outcomes, and its lower bound in performance is comparable to that of the two-stage training strategy. This indicates that collaborative training can better mitigate the errors introduced by distribution assumptions and improve the accuracy of distribution prediction models. ", "page_idx": 25}, {"type": "text", "text": "D.4 Univariate Forecasting Results ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Following the same settings as our main experiment, we present the univariate forecasting results of Autoformer [20] and FEDformer [19] across three datasets, including Weather, Electricity, and Traffic, in Table 11. Similar to the multivariate forecasting results, DDN consistently enhances the performance of mainstream forecasting models in nearly all cases. It demonstrates that DDN is applicable in both multivariate time series forecasting and univariate forecasting. ", "page_idx": 25}, {"type": "table", "img_path": "RVZfra6sZo/tmp/f3176d592fef9edd4082b1bb7dc5144b27ebef76120c86113b379ee00c5ca402.jpg", "table_caption": [], "table_footnote": ["Table 9: Comparison of forecasting errors between different reversible normalization methods. The bold values indicate best performance. "], "page_idx": 26}, {"type": "table", "img_path": "RVZfra6sZo/tmp/1fe142de744bced7f0f65de6f94701ec5a3f9bcc7c0575aee604e5d5955af383.jpg", "table_caption": [], "table_footnote": [], "page_idx": 26}, {"type": "text", "text": "Table 10: Comparison between the collaborative training strategy and the conventional two-stage training strategy. \"Co-train\" denotes the use of the collaborative training strategy, while \"Wo Co-train\" signifies the approach where the distribution prediction model\u2019s parameters are frozen after pre-training, and only the time series forecasting model is trained. The bold values indicate best performance. ", "page_idx": 26}, {"type": "table", "img_path": "RVZfra6sZo/tmp/9dd4546ff903fdc62f548f64c1c8a4b0fa2e848fc9e100c57b926f499a6a1142.jpg", "table_caption": [], "table_footnote": ["Table 11: Univariate forecasting results. The bold values indicate best performance. "], "page_idx": 27}]