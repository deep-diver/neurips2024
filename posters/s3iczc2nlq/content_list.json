[{"type": "text", "text": "A Nearly Optimal and Low-Switching Algorithm for Reinforcement Learning with General Function Approximation ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Heyang Zhao Department of Computer Science University of California, Los Angeles Los Angeles, CA 90095 hyzhao@cs.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Jiafan He ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Computer Science University of California, Los Angeles Los Angeles, CA 90095 jiafanhe19@ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Quanquan Gu Department of Computer Science University of California, Los Angeles Los Angeles, CA 90095 qgu@cs.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The exploration-exploitation dilemma has been a central challenge in reinforcement learning (RL) with complex model classes. In this paper, we propose a new algorithm, Monotonic Q-Learning with Upper Confidence Bound (MQL-UCB) for RL with general function approximation. Our key algorithmic design includes (1) a general deterministic policy-switching strategy that achieves low switching cost, (2) a monotonic value function structure with carefully controlled function class complexity, and (3) a variance-weighted regression scheme that exploits historical trajectories with high data efficiency. MQL-UCB achieves minimax optimal regret of $\\widetilde{O}(d\\sqrt{H K})$ when $K$ is sufficiently large and near-optimal policy switching cost of $\\widetilde{O}(d H)$ , with $d$ being the eluder dimension of the function class, $H$ being the planning horizon, and $K$ being the number of episodes. Our work sheds light on designing provably sample-efficient and deployment-efficient Q-learning with nonlinear function approximation. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In reinforcement learning (RL), a learner interacts with an unknown environment and aims to maximize the cumulative reward. As one of the most mainstream paradigms for sequential decisionmaking, RL has extensive applications in many real-world problems (Kober et al., 2013; Mnih et al., 2015; Lillicrap et al., 2015; Zoph and Le, 2016; Zheng et al., 2018). Theoretically, the RL problem is often formulated as a Markov Decision Process (MDP) (Puterman, 2014). Achieving the optimal regret bound for various MDP settings has been a long-standing fundamental problem in RL research. In tabular MDPs where the state space $\\boldsymbol{S}$ and the action space $\\boldsymbol{\\mathcal{A}}$ are finite, the optimal regret bound has been well-established, ranging from the episodic setting (Azar et al., 2017; Zanette and Brunskill, 2019; Simchowitz and Jamieson, 2019; Zhang et al., 2020), average-reward setting (Zhang and Ji, 2019) to the discounted setting (He et al., 2021b). Nevertheless, these regret guarantees are intolerably large in many real-world applications, where the state space $\\boldsymbol{S}$ and the action space $\\boldsymbol{\\mathcal{A}}$ are often large or even infinite. ", "page_idx": 0}, {"type": "text", "text": "As is commonly applied in applications, function approximation has been widely studied by theorists to demonstrate the generalization across large state-action spaces, proving the performance guarantees of various RL algorithms for specific function classes. There are recent works on RL with linear function approximation under different assumptions such as linear MDPs (Yang and Wang, 2019; Jin et al., 2020), linear mixture MDPs (Modi et al., 2020; Ayoub et al., 2020; Zhou et al., 2021a). Among them, Zhou et al. (2021a) achieved nearly optimal regret bounds for linear mixture MDPs through a model-based approach adopting variance-weighted linear regression. Later, Hu et al. (2022) proposed LSVI-UCB $^+$ algorithm, making an attempt to improve the regret for linear MDP through an over-optimistic value function approach. However, their analysis was later discovered to suffer from a technical issue (Agarwal et al., 2022; He et al., 2022). To fix this issue, Agarwal et al. (2022) introduced similar over-optimistic value functions to construct a monotonic variance estimator and a non-Markov policy, achieving the first statistically optimal regret for linear MDPs. They also proposed a novel algorithm dubbed $\\mathrm{vo}Q\\mathrm{L}$ for RL with general function approximation. Concurrently, He et al. (2022) proposed LSVI-UCB $^{++}$ , which takes a different approach and employs a rare-switching technique to obtain the optimal regret. In a parallel line of research, there has been a growing body of literature proposing more general frameworks to unify sample efficient RL algorithms, e.g., Bellman rank (Jiang et al., 2017), Witness rank (Sun et al., 2019), eluder dimension (Russo and Van Roy, 2013), Bellman eluder dimension (Jin et al., 2021), Bilinear Classes (Du et al., 2021), Decision-Estimation Coefficient (Foster et al., 2021), Admissible Bellman Characterization (Chen et al., 2022) and Decoupling Coefficient (Agarwal and Zhang, 2022a,b). However, when applying these frameworks to linear MDPs, none of them can achieve the minimax optimal regret. To our knowledge, Agarwal et al. (2022) is the only algorithmic framework achieving optimal regret for RL beyond linear function approximation. Since VOQL requires a non-Markov planning procedure, where the resulting policy does not act greedily with respect to a single optimistic value function, it is natural to ask ", "page_idx": 1}, {"type": "text", "text": "Can we develop a RL algorithm with Markov policy to solve MDPs with general function approximationand achieve the optimal regret? ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "While the sample efficiency of RL algorithms for MDPs with nonlinear function classes has been comprehensively researched, deployment effciency (Matsushima et al., 2020) is also a major concern in many real-world application scenarios. For example, in recommendation systems (Afsar et al., 2022), it may take several weeks to deploy a new recommendation policy. On the other hand, the system is capable of collecting an enormous amount of data every minute implementing a fixed policy. As a result, it is computationally inefficient to change the executed policy after each data point is collected as is demanded by most of the online RL algorithms in theoretical studies. To resolve this issue, Bai et al. (2019) first introduced the concept of switching cost, defined as the number of policy updates. Following this concept, a series of RL algorithms have been proposed on the theoretical side with low switching cost guarantees (e.g., Zhang et al., 2020; Wang et al., 2021; Qia0 et al., 2022; Kong et al., 2021; Velegkas et al., 2022; Li et al., 2023). Xiong et al. (2023) considered low-switching RL with general function approximation, which achieves $\\tilde{O}(d H)$ switching cost. However, their algorithm has an intractable planning phase and is not statistically optimal. Kong et al. (2021), Velegkas et al. (2022), and Li et al. (2023) considered RL with general function approximation, all of which achieved the switching cost of $O(d^{2}H\\mathrm{polylog}(K))$ , where $d$ is the eluder dimension of the underlying function class, $H$ is the planning horizon, and $K$ is the number of episodes. In contrast, Ga0 et al. (2021) proved an $\\Omega(d\\bar{H}/\\log d)$ lower bound of switching cost for any deterministic algorithms in learning linear MDPs. Therefore, the following question remains open: ", "page_idx": 1}, {"type": "text", "text": "Can we design an effcient algorithm with $\\widetilde{O}(d H)$ switching cost for MDPs with bounded eluder dimension? ", "page_idx": 1}, {"type": "text", "text": "In this paper, we answer the above two questions simultaneously by proposing a novel algorithm Monotonic $Q$ -Learning with UCB (MQL-UCB) with all the aforementioned appealing properties. At the core of our algorithmic design are the following innovative techniques: ", "page_idx": 1}, {"type": "table", "img_path": "s3icZC2NLq/tmp/4bb61c4aeba5aa1e5c5f0e655c65ad1cfc1dddf0c5c3d36cd89153015deea5f7.jpg", "table_caption": ["Table 1: A comparison of existing algorithms in terms of regret and switching cost for linear MDP and general function class with bounded eluder dimension and Bellman completeness. The results hold for in-homogeneous episodic RL with horizon length $H$ , number of episodes $K$ where the total reward obtained in an episode is not larger than 1. For regret, we only present the leading term when $K$ is large enough compared to other variables and hide poly-logarithmic factors in $K$ $d$ or dim, $H$ and the constant. For linear MDPs, $d$ is the dimension of the feature vectors. For general function class, dim is a shorthand of the eluder dimension of the underlying function class, $N$ is the covering number of the value function class, and $N_{S,A}$ is the covering number of the state-action space. "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "\u00b7 We propose a novel policy-switching strategy based on the cumulative sensitivity of historical data. To the best of our knowledge, this is the first computationally-tractable deterministic rare-switching algorithm for RL with general function approximation which achieves $\\widetilde{O}(d H)$ switchingcost.We also prove a nearly matching lower bound for any algorithm with arbitrary policies including both deterministic and stochastic policies (See Theorem B.1). Previous approaches for low switching cost in RL with general function approximation are sampling-based (Kong et al., 2021; Velegkas et al., 2022; Li et al., 2023) and highly coupled with a sub-sampling technique used for regression, making it less efficient. When restricted to the linear case, sampling-based rare-switching has a worse switchingcost of $\\widetilde{\\cal O}(d^{2}H)$ (Section 3.3 in Kong et al. 2021; Theorem 3.3 in Velegkas et al. 2022; Section C in Li et al. 2023) than that in Wang et al. (2021). ", "page_idx": 2}, {"type": "text", "text": "\u00b7 With the novel policy-switching scheme, we illustrate how to reduce the complexity of value function classes while maintaining a series of monotonic value functions, strictly generalizing theLSVI-UCB $^{++}$ algorithm (He et al., 2022) to general function class with bounded eluder dimension. Based on the structure of the value functions, we further demonstrate how MQL-UCB achieves a variance-dependent regret bound that can gracefully reduce to a nearly constant regret for deterministic MDPs. While in the worst case, our algorithm still attains a nearly minimax optimal regret guarantee. Our work is the first work for RL with general function approximation that achieves the nearly minimax optimal regret when specialized to linear MDPs, while still enjoys simple Markov planning phase. ", "page_idx": 2}, {"type": "text", "text": "It is worth noting that recently, Qiao et al. (2023) also considered RL with low-switching cost beyond linear function approximation, i.e., MDPs with low inherent Bellman error (Zanette et al., 2020b) and generalized linear MDPs (Wang et al., 2020b). Their approach can be seen as a slight extension of RL with low-switching cost for linear MDPs, since in both settings, the covariance matrix still exists and they can still use the determinant of the covariance as a criterion for policy switching. ", "page_idx": 2}, {"type": "text", "text": "Notation. We use lower case letters to denote scalars and use lower and upper case bold face letters to denote vectors and matrices respectively. We denote by $[n]$ the set $\\{1,\\ldots,n\\}$ . For two positive sequences $\\left\\{a_{n}\\right\\}$ and $\\left\\{b_{n}\\right\\}$ with $n=1,2,\\ldots,$ we write $a_{n}=O(b_{n})$ if there exists an absolute constant $C>0$ such that $a_{n}\\leq C b_{n}$ holds for all $n\\geq1$ and write $a_{n}=\\Omega(b_{n})$ if there exists an absolute constant $C>0$ such that $a_{n}\\geq C b_{n}$ holds for all $n\\geq1$ .We use $\\widetilde O(\\cdot)$ to further hide the polylogarithmic factors except log-covering numbers. We use $\\mathbb{1}\\{\\cdot\\}$ to denote the indicator function. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "2.1 Time-Inhomogeneous Episodic MDP ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "$\\mathcal{M}=M(\\mathcal{S},\\mathcal{A},H,\\{\\mathbb{P}_{h}\\}_{h=1}^{H},\\{r_{h}\\}_{h=1}^{H})$ $\\boldsymbol{S}$ $\\boldsymbol{\\mathcal{A}}$   \n$H$ is the length of each episode, ${\\vec{\\mathbb{P}_{h}}}:S\\times A\\times S\\rightarrow[0,1]$ is the transition probability function at stage $h$ which denotes the probability for state $s$ to transfer to the next state $s^{\\prime}$ with current action $a$ and $r_{h}:S\\times A\\to[0,1]$ isthe deterministicreward functionat stage $h$ A policy $\\pi:=\\{\\pi_{h}\\}_{h=1}^{H}$ isa collection of mappings $\\pi_{h}$ from an observed state $s\\in S$ to the simplex of action space $\\boldsymbol{\\mathcal{A}}$ . For any policy $\\pi=\\{\\pi_{h}\\}_{h=1}^{\\dot{H}}$ and stage $h\\in[H]$ , we define the value function $V_{h}^{\\pi}(s)$ and the action-value function $Q_{h}^{\\pi}(s,a)$ as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\nQ_{h}^{\\pi}(s,a)=r_{h}(s,a)+\\mathbb{E}\\bigg[\\sum_{h^{\\prime}=h+1}^{H}r_{h^{\\prime}}\\bigl(s_{h^{\\prime}},\\pi_{h^{\\prime}}(s_{h^{\\prime}})\\bigr)\\bigg|s_{h}=s,a_{h}=a\\bigg],V_{h}^{\\pi}(s)=Q_{h}^{\\pi}(s,\\pi_{h}(s)),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $s_{h^{\\prime}+1}\\,\\sim\\,\\mathbb{P}_{h^{\\prime}}\\bigl(\\cdot\\vert s_{h^{\\prime}},a_{h^{\\prime}}\\bigr)$ Then, we further define the optimal value function $V_{h}^{*}$ and the optimal action-value function $Q_{h}^{*}$ as $V_{h}^{*}(s)=\\operatorname*{max}_{\\pi}V_{h}^{\\pi}(s)$ and $Q_{h}^{*}(s,a)=\\operatorname*{max}_{\\pi}Q_{h}^{\\pi}\\dot{(s,a)}$ : For simplicity, we assume the total reward for each possible trajectory $\\left({{s}_{1}},{{a}_{1}},...,{{s}_{H}},{{a}_{H}}\\right)$ satisfies $\\begin{array}{r}{\\sum_{h=1}^{H}r_{h}(s_{h},a_{h})\\le1}\\end{array}$ $V_{h}^{\\pi}(\\cdot)$ $Q_{h}^{\\pi}(\\cdot,\\cdot)$   \n$[0,1]$ $V:S\\rightarrow\\mathbb{R}$ $h\\in[H]$   \noperator $\\mathcal{T}_{h}$ and second-order Bellman operator $\\mathcal{T}_{h}^{2}$ on function $V$ ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{T}_{h}V(s_{h},a_{h})=\\mathbb{E}_{s_{h+1}}\\big[r_{h}+V(s_{h+1})|s_{h},a_{h}\\big],\\mathcal{T}_{h}^{2}V(s_{h},a_{h})=\\mathbb{E}_{s_{h+1}}\\Big[\\big(r_{h}+V(s_{h+1})\\big)^{2}|s_{h},a_{h}\\Big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $s_{h+1}\\sim\\mathbb{P}_{h}(\\cdot|s_{h},a_{h})$ and $r_{h}=r_{h}(s_{h},a_{h})$ . For simplicity, we further define $\\lbrack\\mathbb{P}_{h}V](s,a)=$ $\\mathbb{E}_{s^{\\prime}\\sim\\mathbb{P}_{h}(\\cdot|s,a)}V(s^{\\prime})$ and $[\\mathbb{V}_{h}V](s,a)=T_{h}^{2}V(s_{h},a_{h})-\\left(\\mathscr{T}_{h}V(s_{h},a_{h})\\right)^{2}$ . Using this notation, for each stage $h\\in[H]$ , the Bellman equation and Bellman optimality equation take the following forms: ", "page_idx": 3}, {"type": "equation", "text": "$$\nQ_{h}^{\\pi}(s,a)=\\mathcal{T}_{h}V_{h+1}^{\\pi}(s,a),\\quad Q^{*}(s,a)=\\mathcal{T}_{h}V_{h+1}^{*}(s,a),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $V_{H+1}^{\\pi}(\\cdot)\\,=\\,V_{H+1}^{*}(\\cdot)\\,=\\,0$ . At the beginning of each episode $k\\,\\in\\,[K]$ , the agent selects a policy $\\pi^{k}$ to be executed throughout the episode, and an initial state $s_{1}^{k}$ is arbitrarily selected by the environment. For each stage $h\\in[H]$ , the agent first observes the current state $s_{h}^{k}$ , chooses an action following the policy $\\pi_{h}^{k}$ then transitst the next state with $s_{h+1}^{k}\\sim\\mathbb{P}_{h}(\\cdot|s_{h}^{k},a_{h}^{\\dot{k}})$ and reward $r_{h}(s_{h},a_{h})$ . Based on the protocol, we defined the suboptimality gap in episode $k$ as the difference between the value function for selected policy $\\pi^{k}$ and the optimal value function $V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi^{k}}(s_{1}^{k})$ Based on these definitions, we can define the regret in the first $K$ episodes as follows: ", "page_idx": 3}, {"type": "text", "text": "Definition 2.1. For any RL algorithm $\\mathtt{A L g}$ , the regret in the first $K$ episodes is denoted by the sum of the suboptimality for episode $k=1,\\ldots,K$ ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname{Regret}(K)=\\sum_{k=1}^{K}V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi^{k}}(s_{1}^{k}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\pi^{k}$ is the agent's policy at episode $k$ ", "page_idx": 3}, {"type": "text", "text": "2.2  Function Classes and Covering Numbers ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Assumption 2.2 (Completeness). Given $\\mathcal{F}:=\\{\\mathcal{F}_{h}\\}_{h=1}^{H}$ which is composed of bounded functions $f_{h}:S\\times A\\to[0,L]$ . We assume that for any function $\\bar{V}:\\mathcal{S}\\to[0,1]$ there exists $f_{1},f_{2}\\in\\mathcal{F}_{h}$ such that for any $(s,a)\\in S\\times A$ \uff0c ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{s^{\\prime}\\sim\\mathbb{P}_{h}(\\cdot\\vert s,a)}\\big[r_{h}(s,a)+V(s^{\\prime})\\big]=f_{1}(s,a),\\mathrm{~and~}\\mathbb{E}_{s^{\\prime}\\sim\\mathbb{P}_{h}(\\cdot\\vert s,a)}\\Big[\\big(r_{h}(s,a)+V(s^{\\prime})\\big)^{2}\\Big]=f_{2}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We assume that $L=O(1)$ throughout the paper. ", "page_idx": 3}, {"type": "text", "text": "Remark 2.3. Completeness is a fundamental assumption in RL with general function approximation, as recognized in Wang et al. (2020b); Jin et al. (2021); Agarwal et al. (2022). Our assumption is the same as that in Agarwal et al. (2022) and is slightly stronger than that in Wang et al. (2020a) and ", "page_idx": 3}, {"type": "text", "text": "Jin et al. (2021). More specifically, in Wang et al. (2020a), completeness is only required for the first-order Bellman operator. In contrast, we necessitate completeness with respect to the second-order Bellman operator, which becomes imperative during the construction of variance-based weights. Jin et al. (2021) only requires the completeness for the function class $\\mathcal{F}_{h+1}$ ${\\mathcal{T}}_{h}{\\mathcal{F}}_{h+1}\\subseteq{\\mathcal{F}}_{h})$ . However, the GOLF algorithm (Jin et al., 2021) requires solving an intricate optimization problem across the entire episode. In contrast, we employ pointwise exploration bonuses as an alternative strategy, which requires the completeness for function class $\\bar{\\nu}\\bar{=}\\left\\{V:\\mathcal{S}\\to[0,1]\\right\\}$ ,i.e., $\\mathcal{T}_{h}\\mathcal{V}\\subseteq\\mathcal{F}_{h}$ .The completeness assumption on the second moment is first introduced by Agarwal et al. (2022), and is crucial for obtaining a tighter regret bound. More specifically, making use of the variance of the value function at the next state is known to be crucial to achieve minimax-optimal regret bound in RL ranging from tabular MDPs (Azar et al., 2017) to linear mixture MDPs (Zhou et al., 2021a) and linear MDPs (He et al., 2022). In RL with general function approximation, the second-moment compleness assumption makes the variance of value functions computationally tractable. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.4 (Generalized Eluder dimension, Agarwal et al. 2022). Let $\\lambda\\geq0$ , a sequence of state-action pairs $\\mathbf{Z}\\,=\\,\\{z_{i}\\}_{i\\in[T]}$ and a sequence of positive numbers $\\pmb{\\sigma}=\\{\\sigma_{i}\\}_{i\\in[T]}$ . The generalized Eluder dimension of a function class $\\mathcal{F}:\\mathcal{S}\\times\\mathcal{A}\\rightarrow[0,L]$ with respect to $\\lambda$ is defined by $\\begin{array}{r}{\\dim_{\\alpha,T}(\\mathcal F):=\\operatorname*{sup}_{\\mathbf Z,\\sigma:|Z|=T,\\sigma\\geq\\alpha}\\dim(\\mathcal F,\\mathbf Z,\\sigma),}\\end{array}$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\dim({\\mathcal F},{\\mathbf Z},\\sigma):=\\sum_{i=1}^{T}\\operatorname*{min}\\bigg(1,\\frac{1}{\\sigma_{i}^{2}}D_{{\\mathcal F}}^{2}(z_{i};z_{[i-1]},\\sigma_{[i-1]})\\bigg),}\\\\ {D_{{\\mathcal F}}^{2}(z;z_{[t-1]},\\sigma_{[t-1]}):=\\displaystyle\\operatorname*{sup}_{f_{1},f_{2}\\in{\\mathcal F}}\\frac{(f_{1}(z)-f_{2}(z))^{2}}{\\sum_{s\\in[t-1]}\\frac{1}{\\sigma_{s}^{2}}(f_{1}(z_{s})-f_{2}(z_{s}))^{2}+\\lambda}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We write $\\begin{array}{r}{\\dim_{\\alpha,T}(\\mathcal{F}):=H^{-1}\\cdot\\sum_{h\\in[H]}\\dim_{\\alpha,T}(\\mathcal{F}_{h})}\\end{array}$ for short when $\\mathcal{F}$ is a collction of function classes $\\mathcal{F}=\\{\\mathcal{F}_{h}\\}_{h=1}^{H}$ in the context. ", "page_idx": 4}, {"type": "text", "text": "Remark 2.5. The $D_{\\mathcal{F}}^{2}$ quantity has been introduced in Agarwal et al. (2022) and Ye et al. (2023) to quantify the uncertainty of a state-action pair given a collected dataset with corresponding weights. It was inspired by Gentile et al. (2022) where an unweighted version of uncertainty has been defined for active learning. Prior to that, Wang et al. (2020a) introduced a similar \u00e9sensitivity\u2019 measure to determine the sampling probability in their sub-sampling framework. As discussed in Agarwal et al. (2022), when specialized to linear function classes, $D_{\\mathcal{F}}^{2^{\\circ}}(z_{t};z_{[t-1]},\\sigma_{[t-1]})$ can be written as the elliptical normn $\\|z_{t}\\|_{\\Sigma_{t-1}^{-1}}^{2}$ , where $\\Sigma_{t-1}$ istheweghtvrianmaxf tfeaeet $z_{[t-1]}$ ", "page_idx": 4}, {"type": "text", "text": "Definition 2.6 (Bonus oracle $\\bar{D}_{\\mathcal{F}.}^{2}$ 0. In this paper, the bonus oracle is denoted by $\\bar{D}_{\\mathcal{F}}^{2}$ , which computes the estimated uncertainty of a state-action pair $z\\,=\\,(s,a)\\,\\in\\,{\\mathcal{S}}\\,\\times\\,A$ with respect to historical data $z_{[t-1]}$ and corresponding weights $\\sigma_{[t-1]}$ . In detail, we assume that a computable function $\\bar{D}_{\\mathcal{F}}^{2}(z;z_{[t-1]},\\sigma_{[t-1]})$ $\\bar{D}_{\\mathcal{F}}(z;z_{[t-1]},\\bar{\\sigma}_{[t-1]})\\in[1,C]$ , where $C$ is a fixed constant. ", "page_idx": 4}, {"type": "text", "text": "Remark 2.7. Agarwal et al. (2022) also assumed access to such a bonus oracle defined in Definition 2.6, where they assume that the bonus oracle finds a proper bonus from a finite bonus class (Definition 3, Agarwal et al. 2022). Our definition is slightly different in the sense that the bonus class is not assumed to be finite but with a finite covering number. Previous works by Kong et al. (2021) and Wang et al. (2020a) proposed a sub-sampling idea to compute such a bonus function efficiently in general cases, which is also applicable in our framework. In a similar nonlinear RL setting, Ye et al. (2023) assumed that the uncertainly $D_{\\mathcal{F}}^{2}$ can be directly computed, which is a slightly stronger assumption. But essentially, these differences in bonus assumption only lightly affect the algorithm structure. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.8 (Covering numbers of function classes). For any $\\epsilon>0$ , we define the following covering numbers of the involved function classes: ", "page_idx": 4}, {"type": "text", "text": "1. For each $h\\in[H]$ , there exists an $\\epsilon$ -cover $\\mathcal{C}(\\mathcal{F}_{h},\\epsilon)\\subseteq\\mathcal{F}_{h}$ with size $|\\mathcal{C}(\\mathcal{F}_{h},\\epsilon)|\\leq N(\\mathcal{F}_{h},\\epsilon)$ , such that for any $f\\in\\mathcal{F}$ , there exists $f^{\\prime}\\in\\mathcal{C}(\\mathcal{F}_{h},\\epsilon)$ , such that $\\|f-f^{\\prime}\\|_{\\infty}\\leq\\epsilon$ . For any $\\epsilon>0$ ,we define the uniform covering number of $\\mathcal{F}$ with respect to $\\epsilon$ as $\\begin{array}{r}{N_{\\mathcal{F}}(\\epsilon):=\\operatorname*{max}_{h\\in[H]}N(\\mathcal{F}_{h},\\epsilon)}\\end{array}$   \n2. There exists a bonus class $B:S\\times A\\rightarrow\\mathbb{R}$ such that for any $t\\geq0,z_{[t]}\\in(S\\times A)^{t},\\sigma_{[t]}\\in\\mathbb{R}^{t},$ the oracle defined in Definition $2.6\\;\\bar{D}_{\\mathcal{F}}(\\cdot;z_{[t]},\\sigma_{[t]})$ is in $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$   \n3. For bonus class $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ , there exists an $\\epsilon$ -cover $\\mathcal{C}(\\boldsymbol{B},\\epsilon)\\subseteq\\mathcal{B}$ with size $|{\\mathcal{C}}(B,\\epsilon)|\\leq N(B,\\epsilon)$ , such that for any $b\\in\\mathfrak{B}$ , there exists $b^{\\prime}\\in\\mathcal{C}(\\mathcal{B},\\epsilon)$ , such that $\\|b-b^{\\prime}\\|_{\\infty}\\leq\\epsilon$ ", "page_idx": 4}, {"type": "text", "text": "Remark 2.9. In general function approximation, it is common to introduce the additional assumption on the covering number of bonus function classes. For example, in Ye et al. (2023), Agarwal and Zhang (2022a), and Di et al. (2023), the covering number of the bonus function class is bounded. ", "page_idx": 5}, {"type": "text", "text": "3  Algorithm and Key Techniques ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "In this section, we will introduce our new algorithm, MQL-UCB. The detailed algorithm is provided in Algorithm 1. Our algorithm's foundational framework follows the Upper Confidence Bound (UCB) approach. In detail, for each episode $k\\,\\in\\,[K]$ , we construct an optimistic value function $Q_{k,h}(s,a)$ during the planning phase. Subsequently, in the exploration phase, the agent interacts with the environment, employing a greedy policy based on the current optimistic value function $Q_{k,h}(s,a)$ Once the agent obtains the reward $r_{h}^{k}$ and transitions to the next state $s_{h+1}^{k}$ , these outcomes are incorporated into the dataset, contributing to the subsequent planning phase. We will proceed to elucidate the essential components of our method. ", "page_idx": 5}, {"type": "text", "text": "3.1  Rare Policy Switching ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "For MQL-UCB algorithm, the value functions $Q_{k,h},{\\check{Q}}_{k,h}$ , along with their corresponding policy $\\pi_{k}$ undergo updates when the agent collects a sufficient number of trajectories within the dataset that could significantly diminish the uncertainty associated with the Bellman operator $\\tau_{h}V(\\cdot,\\cdot)$ through the weighted regression. In the context of linear bandits (Abbasi-Yadkori et al., 2011) or linear MDPs (He et al., 2022), the uncertainty pertaining to the least-square regression is quantified by the covariance matrix $\\Sigma_{k}$ . In this scenario, the agent adjusts its policy once the determinant of the covariance matrix doubles, employing a determinant-based criterion. Nevertheless, in the general function approximation setting, such a method is not applicable in the absence of the covariance matrix which serves as a feature extractor in the linear setting. Circumventing this issue, Kong et al. (2021) proposed a sub-sampling-based method to achieve low-switching properties in nonlinear RL. Their subsampling technique is inspired by Wang et al. (2021), which showed that one only needs to maintain a small subset of historical data to obtain a sufficiently accurate least-square estimator. Such a subset can be generated sequentially according to the sensitivity of a new coming data point. However, their approach leads to a switching cost of $\\widetilde{\\cal O}(d^{2}H)$ , which does not match the lower bound in linear MDPs proposed by Gao et al. (2021). ", "page_idx": 5}, {"type": "text", "text": "To resolve this issue, we proposed a more general deterministic policy-updating framework for nonlinear RL In detail, we use $\\bar{D}_{\\mathcal{F}_{h}}^{2}(z_{i,h};z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h})$ to evaluate the information collected at the episode $i$ given the last updating $k_{l a s t}$ . Once the collected information goes beyond a threshold $\\chi$ from last updating, i.e., ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\sum_{i=k_{l a s t}}^{k-1}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}\\bar{D}_{\\mathcal{F}_{h}}^{2}\\big(z_{i,h};z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h}\\big)\\geq\\chi.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "the agent will perform updates on both the optimistic estimated value function and the pessimistic value function. Utilizing the $D_{\\mathcal{F}_{h}}^{2}$ -based criterion, we will show that the number of policy updates can be bounded by $O(H\\cdot\\dim_{\\alpha,K}({\\mathcal{F}}))$ . This further reduces the complexity of the optimistic value function class and removes additional factors from a uniform convergence argument over the function class. Specifically, we showcase under our rare-switching framework, the $\\epsilon$ -covering number of the optimistic and the pessimistic value function class at episode $k$ is bounded by ", "page_idx": 5}, {"type": "equation", "text": "$$\nN_{\\epsilon}(k):=[N_{\\mathcal{F}}(\\epsilon/2)\\cdot N(\\mathcal{B},\\epsilon/2\\widehat{\\beta}_{K})]^{l_{k}+1},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where ${\\widehat{\\beta}}_{K}$ is the maximum confidence radius as shown in Algorithm 1, which will be specified in Lemmas G.3 and G.4, $l_{k}$ is the number of policy switches before the end of the $k$ -th episode according to Algorithm 1. ", "page_idx": 5}, {"type": "text", "text": "3.2  Weighted Regression ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The estimationof $Q$ function in MQL-UCB extends LSVI-UCB proposed by Jin et al. (2020) to general function classes. While the estimators in LsVI-UCB are computed from the classic least ", "page_idx": 5}, {"type": "text", "text": "squares regression, we construct the estimated value function $\\widehat{f}_{k,h}$ for general function classes by solving the following weighted regression: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widehat f_{k,h}=\\underset{f_{h}\\in\\mathcal{F}_{h}}{\\mathrm{argmin}}\\,\\sum_{i\\in[k-1]}\\frac{1}{\\overline{{\\sigma}}_{i,h}^{2}}\\big(f_{h}\\big(s_{h}^{i},a_{h}^{i}\\big)-r_{h}^{i}-V_{k,h+1}\\big(s_{h+1}^{i}\\big)\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In the weighted regression, we set the weight $\\bar{\\sigma}_{k,h}$ as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\bar{\\sigma}_{k,h}=\\operatorname*{max}\\big\\{\\sigma_{k,h},\\alpha,\\gamma\\cdot\\bar{D}_{\\mathcal{F}_{h}}^{1/2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\big\\},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\sigma_{k,h}$ is the estimated variance for the stochastic transition process, $\\bar{D}_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})$ denotes the uncertainty of the estimated function $\\widehat{f}_{k,h}$ conditioned on the historical observations and ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\gamma^{2}:=\\log\\Big(\\Big(2H K^{2}\\big(2\\log(L^{2}k/\\alpha^{4})+2\\big)\\cdot\\big(\\log(4L/\\alpha^{2})+2\\big)\\cdot N_{\\mathcal{F}}^{4}(\\epsilon)\\cdot N_{\\epsilon}^{2}(K)\\Big)/\\delta\\Big)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "is used to properly balance the uncertainty across various state-action pairs. It is worth noting that Ye et al. (2023) also introduced the uncertainty-aware variance in the general function approximation with a distinct intention to deal with the adversarial corruption from the attacker. In addition, according to the weighted regression, with high probability, the Bellman operator $\\ensuremath{\\mathcal{T}}_{h}V_{k,h}$ satisfies: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\lambda+\\sum_{i\\in[k-1]}\\bar{\\sigma}_{i,h}^{-2}\\left(\\widehat{f}_{k,h}\\big(s_{h}^{i},a_{h}^{i}\\big)-\\mathcal{T}_{h}V_{k,h+1}\\big(s_{h}^{i},a_{h}^{i}\\big)\\right)^{2}\\le\\widehat{\\beta}_{k}^{2},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\widehat{\\beta}_{k}$ is the exploration radius for the $Q$ functions, which will be specified in Theorem 4.1. According to the definition of Generalized Eluder dimension, the estimation error between the estimated function $\\widehat{f}_{k,h}$ and the Bellman operator is upper bounded by: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widehat{f}_{k,h}(s,a)-7\\!\\!\\!\\!\\slash_{\\!\\!\\!\\:}V_{k,h+1}(s,a)\\right|\\leq\\widehat{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Therefore,  we  introduce the  exploration  bonus $b_{k,h}$ and  construct  the  optimistic  value function $Q_{k,h}(s,a)$ ,i.e., $\\begin{array}{r c l}{{Q_{k,h}(s,a)}}&{{\\approx}}&{{\\widehat{f}_{k,h}(s,a)\\;+\\;b_{k,h}(s,a)}}\\end{array}$ where $\\begin{array}{r l r}{b_{k,h}(s,a)}&{{}=}&{\\widehat{\\beta}_{k}}\\end{array}$ $\\bar{D}_{\\mathcal{F}}\\big((s,a);z_{[k-1],h},\\sigma_{[k-1],h}\\big)$ . Inspired by Hu et al. (22); He e al (22); Agarwal e al. (22),in order to estimate the gap between the optimistic value function $V_{k,h}(s)$ and the optimal value function $V_{h}^{*}(s)$ , we further construct the pessimistic estimator $\\widecheck{f}_{k,h}$ by the following weighted regression ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\check{f}_{k,h}=\\underset{f_{h}\\in\\mathcal{F}_{h}}{\\mathrm{argmin}}\\,\\sum_{i\\in[k-1]}\\frac{1}{\\overline{{\\sigma}}_{i,h}^{2}}\\big(f_{h}\\big(s_{h}^{i},a_{h}^{i}\\big)-r_{h}^{i}-\\check{V}_{k,h+1}\\big(s_{h+1}^{i}\\big)\\big)^{2},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "and introduce a negative exploration bonus when generating the pessimistic estimator. $\\check{Q}_{k,h}(s,a)\\approx$ $\\widecheck{f}_{k,h}(s,a)\\!-\\!\\widecheck{b}_{k,h}(s,a)$ where $\\check{b}_{k,h}(s,a)=\\check{\\beta}_{k}\\cdot\\bar{D}_{\\mathcal{F}}((s,a);z_{[k-1],h},\\sigma_{[k-1],h}.$ Different from Agarwal et al. (2022), the pessimistic value function $\\widecheck{f}_{k,h}$ is computed from a similar weighted-regression scheme as in the case of the optimistic estimator, leading to a tighter confidence set. ", "page_idx": 6}, {"type": "text", "text": "3.3Variance Estimator ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this subsection, we provide more details about the variance estimator $\\sigma_{k,h}$ , which measures the variance of the value function $V_{k,h+1}(s_{h+1}^{k})$ caused by the stochastic transition from state-action pair $(s_{h.}^{k},a_{h}^{k})$ .According to the defnition of $\\widehat{f}_{k,h}$ thediffecebetwenthetat $\\widehat{f}_{k,h}$ and $\\pi_{h}V_{k,h+1}$ satisfies ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\nu+\\sum_{i\\in[k-1]}\\frac{1}{\\overline{{\\sigma}}_{i,h}^{2}}\\big(\\widehat f_{k,h}(s_{h}^{i},a_{h}^{i})-7_{h}V_{k,h+1}(s_{h}^{i},a_{h}^{i})\\big)^{2}\\leq2\\sum_{i\\in[k-1]}\\frac{1}{\\overline{{\\sigma}}_{i,h}^{2}}\\big(f(s_{h}^{i},a_{h}^{i})-\\widehat f_{k}^{*}(s_{h}^{i},a_{h}^{i})\\big)\\cdot\\widehat\\eta_{h}^{i}(V_{k,h+1}),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the noise $\\widehat{\\eta}_{h}^{k}(V)\\;=\\;r_{h}^{k}\\,+\\,V(s_{h+1}^{k})\\,-\\,\\mathbb{E}_{s^{\\prime}\\sim\\mathbb{P}_{h}(s_{h}^{k},a_{h}^{k})}[r_{h}(s_{h}^{k},a_{h}^{k},s^{\\prime})\\,+\\,V(s^{\\prime})]$ denotes the stochastic transition noise for the value function $V$ . However, the generation of the target function $V_{k,h+1}$ relies on previously collected data $z_{[k_{\\mathrm{last}}]}$ , thus violating the conditional independence property. Consequently, the noise term $\\widehat{\\eta}_{h}^{k}(V_{k,h+1})$ may not be unbiased. To address this challenge, it becomes imperative to establish a uniform convergence property over the potential function class, which is first introduced in linear MDPs by Jin et al. (2020). ", "page_idx": 6}, {"type": "text", "text": "Following the previous approach introduced by Azar et al. (2017); Hu et al. (2022); Agarwal et al. (2022); He et al. (2022), we decompose the noise of optimistic value function $\\widehat{\\eta}_{h}^{k}(V_{k,h+1})$ into the ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1 Monotonic Q-Learning with UCB (MQL-UCB) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Require: Regularization parameter $\\lambda$ , confidence radius $\\{\\widetilde{\\beta}_{k}\\}_{k\\in[K]},\\{\\widehat{\\beta}_{k}\\}_{k\\in[K]}$ and $\\{{\\widecheck{\\beta}}_{k}\\}_{k\\in[K]}$   \n1: Initialize $k_{\\mathrm{last}}=0$ . For each stage $h\\in[H]$ and state-action $(s,a)\\in S\\times A$ , set $Q_{0,h}(s,a)\\gets$   \n$H,{\\check{Q}}_{0,h}(s,a)\\gets0.$   \n2: for episodes $k=1,\\ldots,K$ do   \n3: Received the initial state $s_{1}^{k}$   \n4: for stage $h=H,\\ldots,1$ do   \n56 $h^{\\prime}\\in[H]$   \n7: $\\begin{array}{r l}&{\\widehat{f}_{k,h}\\leftarrow\\operatorname{argmin}_{f_{h}\\in\\mathcal{F}_{h}}\\dot{\\sum}_{i\\in[k-1]}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}\\big(f_{h}(s_{h}^{i},a_{h}^{i})-r_{h}^{i}-V_{k,h+1}(s_{h+1}^{i})\\big)^{2}.}\\\\ &{\\check{f}_{k,h}\\leftarrow\\operatorname{argmin}_{f_{h}\\in\\mathcal{F}_{h}}\\sum_{i\\in[k-1]}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}\\big(f_{h}(s_{h}^{i},a_{h}^{i})-r_{h}^{i}-\\check{V}_{k,h+1}(s_{h+1}^{i})\\big)^{2}.}\\\\ &{\\tilde{f}_{k,h}\\leftarrow\\operatorname{argmin}_{f_{h}\\in\\mathcal{F}_{h}}\\sum_{i\\in[k-1]}\\big(f_{h}(s_{h}^{i},a_{h}^{i})-\\big(r_{h}^{i}+V_{k,h+1}(s_{h+1}^{i})\\big)^{2}\\big)^{2}.}\\\\ &{Q_{k,h}(s,a)\\leftarrow\\operatorname*{min}\\Big\\{\\widehat{f}_{k,h}(s,a)+b_{k,h}(s,a),Q_{k-1,h}(s,a),1\\Big\\}.}\\\\ &{\\check{Q}_{k,h}(s,a)\\leftarrow\\operatorname*{max}\\Big\\{\\check{f}_{k,h}(s,a)-\\check{b}_{k,h}(s,a),\\check{Q}_{k-1,h}(s,a),0\\Big\\}.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\dots}\\end{array}$   \n8:   \n9:   \n10:   \n11: Set the last updating episode $k_{\\mathrm{last}}\\leftarrow k$ and number of policies as $l_{k}\\gets l_{k-1}+1$   \n12: else   \n13: $\\begin{array}{r}{\\stackrel{\\mathbf{v}}{Q}_{k,h}(s,a)\\xleftarrow{Q}_{k-1,h}(s,a),\\stackrel{\\forall}{Q}_{k,h}(s,a)\\xleftarrow{Q}_{k-1,h}(s,a)}\\end{array}$ and $l_{k}\\gets l_{k-1}$   \n14: end if   \n15: Set the policy $\\pi^{k}$ as $\\begin{array}{r}{\\pi_{h}^{k}(\\cdot)\\ \\gets\\ \\operatorname*{argmax}_{a\\in\\mathcal{A}}Q_{k,h}(\\cdot,a).\\ \\ V_{k,h}(s)\\ \\gets\\ \\operatorname*{max}_{a}Q_{k,h}(s,a),}\\end{array}$   \n$\\check{V}_{k,h}(s)\\gets\\operatorname*{max}_{a}\\check{Q}_{k,h}(\\dot{s,a})$   \n16: end for   \n17: for stage $h=1,\\ldots,H$ do.   \n18: Take action $a_{h}^{k}\\leftarrow\\pi_{h}^{k}(s_{h}^{k})$ and receive ext state $s_{h+1}^{k}$   \n19: Set the estimated  variance $\\sigma_{k,h}$ as in (3.4) and set $\\begin{array}{r l r}{\\bar{\\sigma}_{k,h}}&{{}\\leftarrow}&{\\operatorname*{max}\\left\\{\\sigma_{k,h},\\alpha,\\gamma\\right.}\\end{array}$   \n$D_{\\mathcal{F}_{h}}^{1/2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\Bigr\\}.$   \n20: end for ", "page_idx": 7}, {"type": "text", "text": "21: end for ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "noise of optimal value function $\\widehat{\\eta}_{h}^{k}(V_{h+1}^{*})$ and the noise $\\widehat{\\eta}_{h}^{k}\\bigl(V_{k,h+1}-V_{h+1}^{*}\\bigr)$ to reduce the extra $\\log\\left(N_{\\epsilon}(K)\\right)$ dependency in the confidence radius. With the noise decomposition, we evaluate the variances $[\\mathbb{V}_{h}V_{h+1}^{*}](s,a)$ and $\\left[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{*})\\right](s,a)$ separately. ", "page_idx": 7}, {"type": "text", "text": "For the variance of the optimal value function $[\\mathbb{V}_{h}V_{h+1}^{*}](s,a)$ since the optimal value function $V_{h+1}^{*}$ is independent with the collected data $z_{[k_{\\mathrm{last}}]}$ , it prevents a uniform convergence-based argument over the function class. However, the optimal value function $V_{h+1}^{*}$ is unobservable, and it requires several steps to estimate the variance. In summary, we utilize the optimistic function $V_{k,h+1}$ to approximate the optimal value function $V_{h+1}^{*}$ and calculate the estimated variance $[\\bar{\\nabla}_{h}V_{k,h}]$ as the difference between the second-order moment and the square of the first-order moment of $V_{k,h}$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\lbrack\\bar{\\mathbb{V}}_{k,h}{V}_{k,h+1}]=\\widetilde{f}_{k,h}-\\widehat{f}_{k,h}^{2}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Here, the approximate second-order moment $\\widetilde{f}_{k,h}$ and the approximate first-order moment $\\widehat{f}_{k,h}$ is generated by the least-square regression (Lines 6 and 8). In addition, we introduce the exploration bonus $E_{k,h}$ to control the estimation error between the estimated variance and the true variance of $V_{k,h+1}$ and $F_{k,h}$ to control the sub-optimality gap between $V_{k,h+1}$ and $V_{h+1}^{*}$ ", "page_idx": 7}, {"type": "text", "text": "A $\\begin{array}{r l}&{\\bar{z}_{k,h}=(2L\\beta_{k}+\\widetilde{\\beta}_{k})\\operatorname*{min}\\big(1,\\bar{D}_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\big),}\\\\ &{\\bar{\\tau}_{k,h}=\\big(\\log(N(\\mathcal{F},\\epsilon)\\cdot N_{\\epsilon}(K))\\big)\\cdot\\operatorname*{min}\\big(1,2\\widehat{f}_{k,h}(s_{h}^{k},a_{h}^{k})-2\\check{f}_{k,h}(s_{h}^{k},a_{h}^{k})+4\\beta_{k}\\bar{D}_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\big),}\\end{array}$ where ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widetilde{\\beta}_{k}=\\sqrt{128\\log\\frac{N_{\\epsilon}(k)\\cdot N(\\mathcal{F},\\epsilon)\\cdot H}{\\delta}+64L\\epsilon\\cdot k},\\beta_{k}=\\sqrt{128\\cdot\\log\\frac{N_{\\epsilon}(k)\\cdot N(\\mathcal{F},\\epsilon)H}{\\delta}+64L\\epsilon\\cdot k/\\alpha^{2}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "For the variance of the sub-optimality gap, $\\left[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{*})\\right](s,a)$ ,based on the structure of optimistic and pessimistic value function, it can be approximate and upper bounded by ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\lbrack\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{*})](s_{h}^{k},a_{h}^{k})\\le2\\lbrack\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{*})\\rbrack(s_{h}^{k},a_{h}^{k})\n$$", "text_format": "latex", "page_idx": 7}, {"type": "equation", "text": "$$\n\\leq2[\\mathbb{P}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})](s_{h}^{k},a_{h}^{k})\\approx2\\widehat{f}_{k,h}(s_{h}^{k},a_{h}^{k})-2\\check{f}_{k,h}(s_{h}^{k},a_{h}^{k}),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where the approximate first-order moments $\\widehat{f}_{k,h},\\,\\check{f}_{k,h}$ are generated by the least-square regression (Lines 6 and 7) and can be dominated by the exploration bonus $F_{k,h}$ ", "page_idx": 8}, {"type": "text", "text": "In summary, we construct the estimated variance $\\sigma_{k,h}$ as: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sigma_{k,h}=\\sqrt{[\\bar{\\mathbb{V}}_{k,h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})+E_{k,h}+F_{k,h}}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "3.4 Monotonic Value Function ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "As we discussed in the previous subsection, we decompose the value function $V_{k,h}$ and evaluate the variance $[\\mathbb{V}_{h}V_{h+1}^{*}](s,a)$ \uff0c $\\left[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{*})\\right](s,a)$ separately. However, for each state-action pair $(s_{h}^{k},a_{h}^{k})$ and any subsequent episode $i>k$ , the value function $V_{i,h}$ and corresponding variance $\\left[\\ddot{\\mathbb{V}}_{h}(\\ddot{V}_{i,h+1}-V_{h+1}^{*})\\right](s_{h}^{k},a_{h}^{k})$ may differ from the previous value function $V_{k,h}$ and variance $\\left[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{*})\\right](s_{h}^{k},a_{h}^{k})$ . Extending the idea proposed by He et al. (2022) for linear MDPs, we ensure that the pessimistic value function $\\check{Q}_{k,h}$ maintains a monotonically increasing property during updates, while the optimistic value function $Q_{k,h}$ maintains a monotonically decreasing property. Leveraging these monotonic properties, we can establish an upper bound on the variance as follows: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{V}_{h}\\big(V_{i,h+1}-V_{h+1}^{*}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\le2[\\mathbb{P}_{h}\\big(V_{i,h+1}-\\check{V}_{i,h+1}\\big)]\\big(s_{h}^{k},a_{h}^{k}\\big)\\le2[\\mathbb{P}_{h}\\big(V_{k,h+1}-\\check{V}_{k,h+1}\\big)]\\big(s_{h}^{k},a_{h}^{k}\\big)\\le F_{k,h}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "In this scenario, the previously employed variance estimator $\\sigma_{k,h}$ offers a consistent and uniform upper bound for the variance across all subsequent episodes. ", "page_idx": 8}, {"type": "text", "text": "4 Main Results ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we present the main theoretical results. In detail, we provide the regret upper bound of Algorithm MQL-UCB in Theorem 4.1. As a complement, in Section B.1, we provide a lower bound on the communication complexity for cooperative linear MDPs. Finally, in Section B.2, we discussed the connection between the generalized eluder dimension and the standard eluder dimension. ", "page_idx": 8}, {"type": "text", "text": "The following theorem provides the regret upper bound of Algorithm MQL-UCB. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.1. Suppose Assumption 2.2 holds for function classes $\\mathcal{F}:=\\{\\mathcal{F}_{h}\\}_{h=1}^{H}$ and Definition 2.4 holds with $\\lambda\\:=\\:1$ . If we set $\\alpha\\;=\\;1/\\sqrt{K H}$ \uff0c $\\epsilon\\;=\\;(K L H)^{-1}$ , and set $\\bar{\\beta}_{k}^{2}\\;=\\;\\check{\\beta}_{k}^{2}\\;:=\\;$ 2(2g(\u00b2k/a)+2)(og(4L/a\u00b2)+2) [log(N(e) +1] + O(X) + O(ekL/a\u00b22),then wih probability $1-O(\\delta)$ , the regret of MQL-UCB is upper bounded as follows: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Regret}(K)=\\tilde{O}\\big(\\sqrt{\\dim(\\mathcal{F})\\log N\\cdot H\\mathrm{Var}_{K}}\\big)}\\\\ &{\\,+\\,\\widetilde{O}\\big(H^{2.5}\\dim^{2}(\\mathcal{F})\\sqrt{\\log N}\\log(N\\cdot N_{b})\\big)\\cdot\\sqrt{H\\log N+\\dim(\\mathcal{F})\\log(N\\cdot N_{b})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where $\\begin{array}{r}{\\mathrm{Var}_{K}:=\\sum_{k=1}^{K}\\sum_{h=1}^{H}[\\mathbb{V}_{h}V_{h+1}^{\\pi^{k}}](s_{h}^{k},a_{h}^{k})=\\widetilde O(K)}\\end{array}$ wedenoethe covering mumbero bonus function class by $N_{b}$ , the covering number of function class by and the dimension $\\dim_{\\alpha,K}({\\mathcal{F}})$ by $\\dim({\\mathcal{F}})$ . Meanwhile, the switching cost of Algorithm 1 is $O(\\dim_{\\alpha,K}(\\mathcal{F})\\cdot H)$ ", "page_idx": 8}, {"type": "text", "text": "In the worst case, when the number of episodes $K$ is sufficiently large, the leading term in our regret bound is ${\\widetilde{O}}\\big({\\sqrt{\\dim(\\mathcal{F})\\log N\\cdot H K}}\\big)$ . Our result matches the optimal regret achieved by Agarwal et al. (2022). While their proposed algorithm involves the execution of a complicated and nonMarkovian policy with an action selection phase based on two series of optimistic value functions and the prefix trajectory, MQL-UCB only requires the knowledge of the current state and a single optimistic state-action value function $Q$ to make a decision over the action space. In addition, our theorem also provides a variance-dependent regret bound, which is adaptive to the randomness of the underlying MDP encountered by the agent. Our definition of $\\mathrm{Var}_{K}$ is inspired by Zhao et al. (2023) and Zhou et al. (2023), which studied variance-adaptive RL under tabular MDP setting and linear mixture MDP setting, respectively. ", "page_idx": 8}, {"type": "text", "text": "As a direct application, we also present the regret guarantee of MQL-UCB for linear MDPs. ", "page_idx": 8}, {"type": "text", "text": "Corollary 4.2. Under the same conditions of Theorem 4.1, assume that the underlying MDP is a linear MDP such that $\\mathcal{F}:=\\{\\mathcal{F}_{h}\\}_{h\\in[H]}$ is composed of linear function classes with a known feature mapping over the state-action space $\\phi:S\\times A\\rightarrow\\mathbb{R}^{d}$ . If we set $\\lambda=1$ \uff0c $\\alpha=1/\\sqrt{K}$ , then with probability $1-O(\\delta)$ , the following cumulative regret guarantee holds for MQL-UCB: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\mathrm{Regret}(K)=\\widetilde O\\big(d\\sqrt{H K}+H^{2.5}d^{5}\\sqrt{H+d^{2}}\\big).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Remark 4.3. The leading term in our regret bound, as demonstrated in Corollary 4.2, matches the lower bound proved in Zhou et al. (2021a) for linear MDPs. Similar optimal regrets have also been accomplished by He et al. (2022) and Agarwal et al. (2022) for linear MDPs. Since we also apply weighted regression to enhance the precision of our pessimistic value functions, the lower order term (i.e., $H^{2.5}d^{5}\\sqrt{H+d^{2}})$ in our regret has a better dependency on $H$ than $\\mathrm{vo}Q\\mathrm{L}$ (Agarwal et al., 2022) and LSVI-UCB $^{++}$ (He et al., 2022), which may be of independent interest when considering long-horizon MDPs. In addition, the switching cost of Algorithm 1 is bounded by $\\widetilde{O}(d H)$ , which matches the lower bound in Gao et al. (2021) for deterministic algorithms and our new lower bound in Theorem B.1 for arbitrary algorithms up to logarithmic factors. For more details about our lower bound, please refer to Appendix E. ", "page_idx": 9}, {"type": "text", "text": "5  Conclusion and Future Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In this paper, we delve into the realm of RL with general function approximation. We proposed the MQL-UCB algorithm with an innovative uncertainty-based rare-switching strategy in general function approximation. Notably, our algorithm only requires $\\widetilde{\\cal O}(d H)$ updating times, which matches with the lower bound established by Gao et al. (2021) up to logarithmic factors, and obtains a $\\widetilde{O}(d\\sqrt{H K})$ regret guarantee, which is near-optimal when restricted to the linear cases. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We thank the anonymous reviewers for their helpful comments. HZ is partially supported by the research award from Cisco. JH and QG are partially supported by the research fund from UCLAAmazon Science Hub. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "ABBASI- YADKORI, Y., PAL, D. and SZEPESVARI, C. (2011). Improved algorithms for linear stochastic bandits. Advances in neural information processing systems 24 2312-2320.   \nAFSAR, M. M., CRUMP, T. and FAR, B. (2022). Reinforcement learning based recommender systems: A survey. ACM Computing Surveys 55 1-38.   \nAGARWAL, A., JIN, Y. and ZHANG, T. (2022). Voql: Towards optimal regret in model-free rl with nonlinear function approximation. arXiv preprint arXiv:2212.06069 .   \nAGARWAL, A. and ZHANG, T. (2022a). Model-based rl with optimistic posterior sampling: Structural conditions and sample complexity. Advances in Neural Information Processing Systems 35 35284 35297.   \nAGARWAL, A. and ZHANG, T. (2022b). Non-linear reinforcement learning in large action spaces: Structural conditions and sample-effciency of posterior sampling. In Conference on Learning Theory.PMLR.   \nAYOUB, A., JIA, Z., SZEPESVARI, C., WANG, M. and YANG, L. (2020). Model-based reinforcement learning with value-targeted regression. In International Conference on Machine Learning. PMLR.   \nAZAR, M. G., OsBAND, I. and MUNOs, R. (2017). Minimax regret bounds for reinforcement learning. In International Conference on Machine Learning. PMLR.   \nBAI, Y., XIE, T., JIANG, N. and WANG, Y.-X. (2019). Provably effcient q-learning with low switching cost. Advances in Neural Information Processing Systems 32.   \nCHEN, Z., LI, C. J., YUAN, H., GU, Q. and JORDAN, M. (2022). A general framework for sample-efficient function approximation in reinforcement learning. In The Eleventh International Conference on Learning Representations.   \nDANN, C., JIANG, N., KRISHNAMURTHY, A., AGARWAL, A., LANGFORD, J. and SCHAPIRE, R. E. (2018). On oracle-efficient pac rl with rich observations. Advances in neural information processing systems 31.   \nD1, Q., ZHAO, H., HE, J. and GU, Q. (2023). Pessimistic nonlinear least-squares value iteration for offine reinforcement learning. arXiv preprint arXiv:2310.01380 .   \nDU, S., KAKADE, S., LEE, J., LOVETT, S., MAHAJAN, G., SUN, W. and WANG, R. (2021). Bilinear classes: A structural framework for provable generalization in rl. In International Conference on Machine Learning. PMLR.   \nDU, S. S., KAKADE, S. M., WANG, R. and YANG, L. F. (2019). Is a good representation sufficient for sample efficient reinforcement learning? In International Conference on Learning Representations.   \nFOSTER, D. J., KAKADE, S. M., QIAN, J. and RAKHLIN, A. (2021). The statistical complexity of interactive decision making. arXiv preprint arXiv:2112.13487 .   \nGAO, M, XIE, T., DU, S. S. and YANG, L. F. (2021). A provably effcient algorithm for linear markov decision process with low switching cost. arXiv preprint arXiv:2101.00494 .   \nGENTILE, C., WANG, Z. and ZHANG, T. (2022). Achieving minimax rates in pool-based batch active learning. In International Conference on Machine Learning. PMLR.   \nHAN, Y., ZHOU, Z., ZHOU, Z., BLANCHET, J., GLYNN, P. W. and YE, Y. (2020). Sequential batch learning in finite-action linear contextual bandits. arXiv preprint arXiv:2004.06321 .   \nHE, J., ZHA0, H., ZHOU, D. and GU, Q. (2022). Nearly minimax optimal reinforcement learning for linear markov decision processes. arXiv preprint arXiv:2212.06132 .   \nHE, J., ZHOU, D. and GU, Q. (2021a). Logarithmic regret for reinforcement learning with linear function approximation. In International Conference on Machine Learning. PMLR.   \nHE, J., ZHOU, D. and GU, Q. (2021b). Nearly minimax optimal reinforcement learning for discounted mdps. Advances in Neural Information Processing Systems 34 22288-22300.   \nHU, P., CHEN, Y. and HUANG, L. (2022). Nearly minimax optimal reinforcement learning with linear function approximation. In International Conference on Machine Learning. PMLR.   \nHUANG, J., CHEN, J., ZHAO, L., QIN, T., JIANG, N. and LIU, T-Y. (2022). Towards deploymentefficient reinforcement learning: Lower bound and optimality. arXiv preprint arXiv:2202.06450   \nJIA, Z., YANG, L., SZEPESVARI, C. and WANG, M. (2020). Model-based reinforcement larning with value-targeted regression. In Learning for Dynamics and Control. PMLR.   \nJIANG, N., KRISHNAMURTHY, A., AGARWAL, A., LANGFORD, J. and SCHAPIRE, R. E. (2017). Contextual decision processes with low bellman rank are pac-learnable. In International Conference on Machine Learning. PMLR.   \nJIN, C., ALLEN-ZHU, Z., BUBECK, S. and JoRDAN, M. I. (2018). Is q-learning provably efficient? Advances in neural information processing systems 31.   \nJIN, C., LIU, Q. and MIRYO0sEFI, S. (2021). Bellman eluder dimension: New rich classes of rl problems, and sample-effcient algorithms. Advances in neural information processing systems 34 13406-13418.   \nJIN, C., YANG, Z., WANG, Z. and JORDAN, M. 1. (2020). Provably efficient reinforcement learning with linear function approximation. In Conference on Learning Theory. PMLR.   \nKOBER, J., BAGNELL, J. A. and PETERs, J. (2013). Reinforcement learning in robotics: A survey. The International Journal of Robotics Research 32 1238-1274.   \nKONG, D., SALAKHUTDINOV, R., WANG, R. and YANG, L. F. (2021). Online sub-sampling for reinforcement learning with general function approximation. arXiv preprint arXiv:2106.07203 .   \nL1, Y., WANG, Y., CHENG, Y. and YANG, L. (2023). Low-switching policy gradient with exploration via online sensitivity sampling. In International Conference on Machine Learning. PMLR.   \nLILLICRAP, T. P, HUNT, J. J., PRITZEL, A., HEESS, N., EREZ, T., TASSA, Y., SILVER, D. and WIERSTRA, D. (2015). Continuous control with deep reinforcement learning. arXiv preprint arXiv:1509.02971 .   \nMATSUSHIMA, T., FURUTA, H., MATSUO, Y., NACHUM, O. and GU, S. (2020). Deploymentefficient reinforcement learning via model-based ofline optimization. In International Conference on Learning Representations.   \nMNIH, V., KAVUKCUOGLU, K., SILVER, D., RUSU, A. A., VENESS, J., BELLEMARE, M. G., GRAVES, A., RIEDMILLER, M., FIDJELAND, A. K., OSTROVSKI, G. ET AL. (2015). Human-level control through deep reinforcement learning. nature 518 529-533.   \nMODI, A., JIANG, N., TEWARI, A. and SINGH, S. (2020). Sample complexity of reinforcement learning using linearly combined model ensembles. In International Conference on Artificial Intelligence and Statistics.   \nPUTERMAN, M. L. (2014). Markov decision processes: discrete stochastic dynamic programming. John Wiley & Sons.   \nQIAO, D., YIN, M., MIN, M. and WANG, Y.-X. (2022). Sample-eficient reinforcement learning with loglog (t) switching cost. In International Conference on Machine Learning. PMLR.   \nQIAO, D., YIN, M. and WANG, Y-X. (2023). Logarithmic switching cost in reinforcement learning beyond linear mdps. arXiv preprint arXiv:2302.12456 .   \nRUAN, Y., YANG, J. and ZHOU, Y. (2021). Linear bandits with limited adaptivity and learning distributional optimal design. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing.   \nRUsso, D. and VAN RoY, B. (2013). Eluder dimension and the sample complexity of optimistic exploration. Advances in Neural Information Processing Systems 26.   \nRUsso, D. and VAN RoY, B. (2014). Learning to optimize via posterior sampling. Mathematics of Operations Research 39 1221-1243.   \nSIMCHOWITZ, M. and JAMIESON, K. G. (2019). Non-asymptotic gap-dependent regret bounds for tabular mdps. Advances in Neural Information Processing Systems 32.   \nSUN, W., JIANG, N., KRISHNAMURTHY, A., AGARWAL, A. and LANGFORD, J. (2019). Modelbased rl in contextual decision processes: Pac bounds and exponential improvements over modelfree approaches. In Conference on learning theory. PMLR.   \nVELEGKAs, G., YANG, Z. and KARBASI, A. (2022). Reinforcement learning with logarithmic regret and policy switches. Advances in Neural Information Processing Systems 35 36040-36053.   \nWANG, R., SALAKHUTDINOV, R. R. and YANG, L. (2020a). Reinforcement learning with general value function approximation: Provably efficient approach via bounded eluder dimension. Advances in Neural Information Processing Systems 33 6123-6135.   \nWANG, T., ZHOU, D. and GU, Q. (2021). Provably efficient reinforcement learning with linear function approximation under adaptivity constraints. Advances in Neural Information Processing Systems 34 13524-13536.   \nWANG, Y., WANG, R., DU, S. S. and KRISHNAMURTHY, A. (202Ob). Optimism in reinforcement learning with generalized linear function approximation. In International Conference on Learning Representations.   \nXIONG, N., YANG, Z. and WANG, Z. (2023). A general framework for sequential decision-making under adaptivity constraints. arXiv preprint arXiv:2306.14468 .   \nYANG, L. and WANG, M. (2019). Sample-optimal parametric q-learning using linearly additive features. In International Conference on Machine Learning. PMLR.   \nYANG, L. and WANG, M. (2020). Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound. In International Conference on Machine Learning. PMLR.   \nYE, C., XIONG, W., GU, Q. and ZHANG, T. (2023). Corruption-robust algorithms with uncertainty weighting for nonlinear contextual bandits and markov decision processes. In International Conference on Machine Learning. PMLR.   \nZANETTE, A., BRANDFONBRENER, D., BRUNSKILL, E., PIROTTA, M. and LAZARIC, A. (2020a). Frequentist regret bounds for randomized least-squares value iteration. In International Conference on Artificial Intelligence and Statistics.   \nZANETTE, A. and BRUNSKILL, E. (2019). Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds. In International Conference on Machine Learning. PMLR.   \nZANETTE, A., LAZARIC, A., KOCHENDERFER, M. and BRUNSKILL, E. (202Ob). Learning near optimal policies with low inherent bellman eror. In International Conference on Machine Learning. PMLR.   \nZHANG, Z. and J1, X. (2019). Regret minimization for reinforcement learning by evaluating the optimal bias function. Advances in Neural Information Processing Systems 32.   \nZHANG, Z., J1, X. and DU, S. (2021). Is reinforcement learning more difficult than bandits? a near-optimal algorithm escaping the curse of horizon. In Conference on Learning Theory. PMLR.   \nZHANG, Z., JIANG, Y., ZHOU, Y. and J1, X. (2022). Near-optimal regret bounds for multi-batch reinforcement learning. Advances in Neural Information Processing Systems 35 24586-24596.   \nZHANG, Z., ZHOU, Y. and JI, X. (2020). Almost optimal model-free reinforcement learningvia reference-advantage decomposition. Advances in Neural Information Processing Systems 33 15198-15207.   \nZHAO, H., HE, J., ZHOU, D., ZHANG, T. and GU, Q. (2023). Variance-dependent regret bounds for linear bandits and reinforcement learning: Adaptivity and computational effciency. arXiv preprint arXiv:2302.10371 .   \nZHENG, G., ZHANG, F., ZHENG, Z., XIANG, Y, YUAN, N. J., XIE, X. and LI, Z. (2018). Drn: A deep reinforcement learning framework for news recommendation. In Proceedings of the 2018 world wide web conference.   \nZHOU, D. and GU, Q. (2022). Computationally efficient horizon-free reinforcement learning for linear mixture mdps. arXiv preprint arXiv:2205.11507 .   \nZHOU, D., GU, Q. and SZEPEsVARI, C. (2021a). Nearly minimax optimal reinforcement learning for linear mixture markov decision processes. In Conference on Learning Theory. PMLR.   \nZHOU, D., HE, J. and GU, Q. (2021b). Provably efficient reinforcement learning for discounted mdps with feature mapping. In International Conference on Machine Learning. PMLR.   \nZHOU, R., ZIHAN, Z. and DU, S. S. (2023). Sharp variance-dependent bounds in reinforcement learning: Best of both worlds in stochastic and deterministic environments. In International Conference on Machine Learning. PMLR.   \nZOPH, B. and LE, Q. V. (2016). Neural architecture search with reinforcement learning. arXiv preprint arXiv:1611.01578 . ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Additional Related Work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 RL with Linear Function Approximation ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In recent years, a substantial body of research has emerged to address the challenges of solving Markov Decision Processes (MDP) with linear function approximation, particularly to handle the vast state and action spaces (Jiang et al., 2017; Dann et al., 2018; Yang and Wang, 2019; Du et al., 2019; Sun et al., 2019; Jin et al., 2020; Wang et al., 2020b; Zanette et al., 2020a; Yang and Wang, 2020; Modi et al., 2020; Ayoub et al., 2020; Zhou et al., 2021a; He et al., 2021a; Zhou and Gu, 2022; He et al., 2022; Zhao et al., 2023). These works can be broadly categorized into two groups based on the linear structures applied to the underlying MDP. One commonly employed linear structure is known as the linear MDP (Jin et al., 2020), where the transition probability function $\\mathbb{P}_{h}$ and reward function $r_{h}$ are represented as linear functions with respect to a given feature mapping $\\phi:S\\times A\\rightarrow\\mathbb{R}^{d}$ Under this assumption, the LSVI-UCB algorithm (Jin et al., 2020) has been shown to achieve a regret guarantee of $\\widetilde{\\cal O}(\\sqrt{d^{3}H^{4}K})$ . Subsequently, Zanette et al. (2020a) introduced the RLSVI algorithm, utilizing the Thompson sampling method, to attain a regret bound of $\\widetilde{\\cal O}(\\sqrt{d^{4}H^{5}K})$ . More recently, He et al. (2022) improved the regret guarantee to $\\widetilde{\\cal O}(\\sqrt{d^{2}H^{3}{\\cal K}})$ with the LSVI-UCB $^{++}$ algorithm, aligning with the theoretical lower bound in Zhou et al. (2021a) up to logarithmic factors. Another line of research has focused on linear mixture MDPs (Modi et al., 2020; Yang and Wang, 2020; Jia et al., 2020; Ayoub et al., 2020; Zhou et al., 2021a), where the transition probability is expressed as a linear combination of basic models $\\mathbb{P}_{1},\\mathbb{P}_{2},..,\\mathbb{P}_{d}$ . For linear mixture MDPs, Jia et al. (2020) introduced the UCRL-VTR algorithm, achieving a regret guarantee of $\\widetilde{\\cal O}(\\sqrt{d^{2}H^{4}K})$ . Subsequently, Zhou et al. (2021a) enhanced this result to $\\widetilde{\\cal O}(\\sqrt{d^{2}H^{3}{\\cal K}})$ , reaching a nearly minimax optimal regret bound. Recently, several works focused on time-homogeneous linear mixture MDPs, and removed the dependency on the episode length (horizon-free) (Zhang and Ji, 2019; Zhou et al., 2021b; Zhao et al., 2023). ", "page_idx": 13}, {"type": "text", "text": "A.2 RL with General Function Approximation ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Recent years have witnessed a furry of progress on RL with nonlinear function classes. To explore the theoretical limits of RL algorithms, various complexity measures have been developed to characterize the hardness of RL instances such as Bellman rank (Jiang et al., 2017), Witness rank (Sun et al. 2019), eluder dimension (Russo and Van Roy, 2013), Bellman eluder dimension (Jin et al., 2021), Bilinear Classes (Du et al., 2021), Decision-Estimation Coefficient (Foster et al., 2021), Admissible Bellman Characterization (Chen et al., 2022), generalized eluder dimension (Agarwal et al., 2022). Among them, only Agarwal et al. (2022) yields a near-optimal regret guarantee when specialized to linear MDPs. In their paper, they proposed a new framework named generalized eluder dimension to handle the weighted objects in weighted regression, which can be seen as a variant of eluder dimension. In their proposed algorithm $\\mathrm{vO}Q\\mathrm{L}$ , they adopted over-optimistic and over-pessimistic value functions in order to bound the variance of regression targets, making it possible to apply a weighted regression scheme in the model-free framework. ", "page_idx": 13}, {"type": "text", "text": "A.3 RL with Low Switching Cost ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Most of the aforementioned approaches necessitate updating both the value function and the corresponding policy in each episode, a practice that proves to be inefficient when dealing with substantial datasets. To overcome this limitation, a widely adopted technique involves dividing the time sequence into several epochs and updating the policy only between different epochs. In the context of the linear bandit problem, Abbasi- Yadkori et al. (2011) introduced the rarely-switching OFUL algorithm, where the agent updates the policy only when the determinant of the covariance matrix doubles. This method enables the algorithm to achieve near-optimal regret of $\\widetilde{O}(\\sqrt{K})$ while maintaining policy updates to ${\\widetilde{O}}(d\\log K)$ times. When the number of arms, denoted as $|\\mathcal D|$ , is finite, Ruan et al. (2021) proposed an algorithm with regret bounded by $\\widetilde{O}(\\sqrt{d K})$ and a mere ${\\widetilde{O}}(d\\log d\\log K)$ policy-updating times. In the realm of episodic reinforcement learning, Bai et al. (2019) and Zhang et al. (2021) delved into tabular Markov Decision Processes, introducing algorithms that achieve a regret of $\\widetilde{O}(\\sqrt{T})$ and ${\\widetilde{O}}(S A\\log K)$ updating times. Wang et al. (2021) later extended these results to linear MDPs, unveiling the LSVI-UCB-RareSwitch algorithm. LSVI-UCB-RareSwitch delivers a regret bound of $\\widetilde{\\cal O}(d^{3}H^{4}K)$ with a policy switching frequency of ${\\widetilde{O}}(d\\log T)$ , which matches the lower bound of the switching cost (Gao et al., 2021) up to logarithmic terms. Furthermore, if the policy is updated within fixed-length epochs (Han et al., 2020), the method is termed batch learning model, but this falls beyond the scope of our current work. In addition, with the help of stochastic policies, Zhang et al. (2022) porposed an algorithm with $\\widetilde{O}(\\sqrt{K})$ regret guarantee and only ${\\widetilde{O}}(H)$ swithcing cost for learning tabular MDPs. Later, Huang et al. (2022) employed the stochastic policy in learning linear MDPs, which is able to find an $\\epsilon$ -optimal policy with only ${\\widetilde{O}}(H)$ switching cost. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "B Additional Results ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Lower Bound for the Switching Cost ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "As a complement, we prove a new lower bound on the switching cost for RL with linear MDPs. Note that linear MDPs lie in the class of MDPs studied in our paper with bounded generalized eluder dimension. In particular, the generalized eluder dimension of linear MDPs is ${\\widetilde{O}}(d)$ ", "page_idx": 14}, {"type": "text", "text": "Theorem B.1. For any algorithm Alg with expected switching cost less than $d H/(16\\log K)$ ,there exists a hard-to-learn linear MDP, such that the expected regret of $\\mathbf{A}\\mathbf{l}\\mathbf{g}$ is at least $\\Omega(K)$ ", "page_idx": 14}, {"type": "text", "text": "Remark B.2. Theorem B.1 suggests that, to achieve a sublinear regret guarantee, an $\\widetilde\\Omega(d H)$ switching cost is inevitable. This lower bound does not violate the minimax upper bound of ${\\widetilde{O}}(H)$ proved in Zhang et al. (2022); Huang et al. (2022), which additionally assume that the initial state $s_{1}^{k}$ is either fixed or sampled from a fixed distribution. In contrast, our work and Gao et al. (2021) allow the initial state to be adaptively chosen by an adversarial environment, bringing more challenges to the learning of linear MDPs. When comparing our lower bound with the result in Gao et al. (2021), it is worth noting that their focus is solely on deterministic algorithms, and they suggest that an $\\widetilde\\Omega(d H)$ switching cost is necessary. As a comparison, our result holds for any algorithm with arbitrary policies including both deterministic and stochastic policies. ", "page_idx": 14}, {"type": "text", "text": "B.2Connection Between $D_{\\mathcal{F}}^{2}$ -Uncertainty and Eluder Dimension ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Previous work by Agarwal et al. (2022) achieved the optimal regret bound ${\\widetilde{O}}({\\sqrt{\\dim({\\mathcal{F}})\\log N\\cdot H K}})$ where $\\dim({\\mathcal{F}})$ is defined as the generalized eluder dimension as stated in Definition 2.4. However, the connection between generalized eluder dimension and eluder dimension proposed by Russo and Van Roy (2013) is still under-discussed 2. Consequently, their results could not be directly compared with the results based on the classic eluder dimension measure (Wang et al., 2020a) or the more general Bellman eluder dimension (Jin et al., 2021). ", "page_idx": 14}, {"type": "text", "text": "In this section, we make a first attempt to establish a connection between generalized eluder dimension and eluder dimension in Theorem B.3. ", "page_idx": 14}, {"type": "text", "text": "Theorem B.3. For a function space $\\mathcal{G}$ \uff0c $\\alpha~>~0$ , let dim be defined in Definition 2.4. WLOG, we assume that for all $g\\,\\in\\,{\\mathcal{G}}$ and $z\\,\\in\\,{\\mathcal{Z}}$ \uff0c $|g(z)|\\,\\leq\\,1$ .Then the following inequality between $\\mathrm{dim}(\\mathcal{F},\\mathbf{Z},\\sigma)$ and $\\mathrm{dim}_{E}(\\mathcal{G},1/\\sqrt{T})$ holds for all $\\mathbf{Z}:=\\{z_{i}\\}_{i\\in[T]}$ with $z_{i}\\in\\mathcal{Z}$ and $\\pmb{\\sigma}:=\\{\\sigma_{i}\\}_{i\\in[T]}$ s.t. $\\alpha\\leq\\sigma_{i}\\leq M\\,\\,\\forall i\\in[T]$ $\\sum_{i\\in[T]}\\operatorname*{min}\\Big(1,\\frac{1}{\\sigma_{i}^{2}}D_{\\mathcal{G}}^{2}\\big(z_{i};z_{[i-1]},\\sigma_{[i-1]}\\big)\\Big)\\leq O\\big(\\dim_{E}(\\mathcal{F},1/\\sqrt{T})\\log T\\log\\lambda T\\log(M/\\alpha)+\\lambda^{-1}\\big).$ ", "page_idx": 14}, {"type": "text", "text": "According to Theorem B.3, the generalized eluder dimension is upper bounded by eluder dimension up to logarithmic terms. When the number of episodes $K$ is sufficiently large, the leading term in our regret bound in Theorem 4.1 is $\\widetilde{O}\\big(\\sqrt{\\dim_{E}(\\mathcal{F})\\log\\mathcal{N}\\cdot H K}\\big)$ ,where $\\dim_{E}({\\mathcal{F}})$ is the eluder dimension of the function class $\\mathcal{F}$ ", "page_idx": 14}, {"type": "text", "text": "C Proof of Theorem B.3 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "To start with, we first recall the concept of eluder dimension as follows. ", "page_idx": 14}, {"type": "text", "text": "Definition C.1 (Definition of eluder dimension, Russo and Van Roy 2013). The eluder dimension of a function class $\\mathcal{G}$ withdomain $\\mathcal{Z}$ is defined as follows: ", "page_idx": 15}, {"type": "text", "text": "\u00b7 A point $z\\in{\\mathcal{Z}}$ .s $\\epsilon$ -dependent on $z_{1},z_{2},\\cdot\\cdot\\cdot\\,,z_{k}\\in{\\mathcal{Z}}$ with respect to $\\mathcal{G}$ , if for all $g_{1},g_{2}\\in\\mathcal{G}$ such that $\\begin{array}{r}{\\sum_{i=1}^{k}\\left[g_{1}(z_{i})-g_{2}(z_{i})\\right]^{2}\\le\\epsilon}\\end{array}$ it holds that $|g_{1}(z)-g_{2}(z)|\\le\\epsilon$   \n\u00b7 Further $z$ is said to be $\\epsilon$ -independent of $z_{1},z_{2},\\cdot\\cdot\\cdot\\,,z_{k}$ with respect to $\\mathcal{G}$ , if $z$ is not dependent on $z_{1},z_{2},\\cdot\\cdot\\cdot\\,,z_{k}$   \n\u00b7 The eluder dimension of $\\mathcal{G}$ , denoted by $\\mathrm{dim}_{E}(\\mathcal{G},\\epsilon)$ , is the length of the longest sequence of elements in $\\mathcal{Z}$ such that every element is $\\epsilon^{\\prime}$ -independent of its predecessors for some $\\epsilon^{\\prime}\\geq\\epsilon$ ", "page_idx": 15}, {"type": "text", "text": "With this definition, we can prove Theorem B.3. ", "page_idx": 15}, {"type": "text", "text": "Proof of Theorem B.3. Let $\\mathcal{T}_{j}$ $(1\\leq j\\leq\\lceil\\log_{2}M/\\alpha\\rceil)$ be the index set such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{Z}_{j}=\\left\\{t\\in[T]|\\sigma_{t}\\in[2^{j-1}\\cdot\\alpha,2^{j}\\alpha]\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then we focus on the summation over $\\mathcal{T}_{j}$ for each $j$ . For simplicity, we denote the subsequence $\\{z_{i}\\}_{i\\in\\mathbb{Z}_{j}}$ by $\\{x_{i}\\}_{i\\in[|Z_{j}|]}$ . Then we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\ell\\leq T_{j}}\\operatorname*{min}\\left(1,\\frac{1}{\\sigma_{i}^{2}}D_{\\mathcal{G}}^{2}\\left(z_{i};z_{[i-1]},\\sigma_{[i-1]}\\right)\\right)\\leq\\displaystyle\\sum_{i\\in[\\mathbb{Z}_{j}]}\\operatorname*{min}\\left(1,4D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right)\\right)\\,,}\\\\ &{\\displaystyle\\texttt{d}\\sum_{i\\in[\\mathbb{Z}_{j}]}\\operatorname*{min}\\left(1,4D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right),}\\\\ &{\\displaystyle\\qquad\\qquad\\sum_{i\\in[\\mathbb{Z}_{j}]}\\operatorname*{min}\\left(1,4D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right)\\right)}\\\\ &{\\displaystyle\\qquad\\qquad\\leq4/\\lambda+\\displaystyle\\sum_{i\\in[\\mathbb{Z}_{j}]}4\\int_{1/\\lambda T}^{1}\\mathbb{I}\\left\\{D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right)\\geq\\rho\\right\\}\\,\\mathrm{d}\\rho}\\\\ &{\\displaystyle\\leq4/\\lambda+4\\int_{1/\\lambda T}^{1}\\sum_{i\\in[\\mathbb{Z}_{j}]}\\mathbb{I}\\left\\{D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right)\\geq\\rho\\right\\}\\,\\mathrm{d}\\rho.}\\end{array}\n$$To boun ", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then we proceed by bounding the summation $\\begin{array}{r}{\\sum_{i\\in[|\\mathbb{Z}_{j}|]}\\mathbb{1}\\left\\{D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},\\mathbf{1}_{[i-1]}\\right)\\geq\\rho\\right\\}}\\end{array}$ for each $\\rho\\ge1/(\\lambda T)$ . For short, let $d:=\\dim_{E}(\\mathcal{G},1/\\sqrt{T})$ . Essentially, it suffices to provide an upper bound of the cardinality of the subset $\\mathcal{I}_{j}:=\\left\\lbrace i\\in\\mathcal{T}_{j}|D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right)\\geq\\rho\\right\\rbrace$ ", "page_idx": 15}, {"type": "text", "text": "For each $i\\in\\mathcal{I}_{j}$ , since $D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right)\\ge\\rho$ , there exists $g_{1},g_{2}$ in $\\mathcal{G}$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{(g_{1}(x_{i})-g_{2}(x_{i}))^{2}}{\\sum_{t\\in[i-1]}(g_{1}(x_{t})-g_{2}(x_{t}))^{2}+\\lambda}\\ge\\rho/2.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Here $(g_{1}(x_{i})-g_{2}(x_{i}))^{2}\\geq\\lambda\\rho\\geq1/T$ . Denote such value of $(g_{1}(x_{i})-g_{2}(x_{i}))^{2}$ by $L(x_{i})$ . Then we consider split $c J_{j}$ into $\\lceil\\log_{2}T\\rceil$ layers such that in each layer $\\mathcal{J}_{j}^{k}\\,\\left(k\\,\\in\\,\\lceil\\lceil\\log_{2}T\\rceil\\right)$ , we have $1/T\\le\\xi\\le L(x_{i})\\le2\\xi$ for some $\\xi$ ", "page_idx": 15}, {"type": "text", "text": "Denote the cardinality of $\\mathcal{I}_{j}^{k}$ by $A$ and the subsequence $\\{x_{i}\\}_{i\\in\\mathbb{Z}_{j}^{k}}$ by $\\{y_{i}\\}_{i\\in[A]}$ . For the elements in $\\{y\\}$ , we dynamically maintain $\\lfloor A/d\\rfloor$ queues of elements. We enumerate through $\\{y\\}$ in its original order and put the current element $y_{i}$ into the queue $Q$ such that $y_{i}$ is $\\xi$ -independent of the current elements in $Q$ . By the Pigeonhole principle and the definition of eluder dimension $d$ , we can find an element $y_{i}$ in $\\{y\\}$ such that $y_{i}$ is $\\xi$ -dependent of all the $\\lfloor A/d\\rfloor$ queues before $i$ ", "page_idx": 15}, {"type": "text", "text": "Then by the definition of $L(y_{i})$ and $\\xi$ , we can choose $g_{1},g_{2}$ such that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{(g_{1}(y_{i})-g_{2}(y_{i}))^{2}}{\\sum_{t\\in[i-1]}(g_{1}(y_{t})-g_{2}(y_{t}))^{2}+\\lambda}\\geq\\rho/2,\\quad2\\xi\\geq(g_{1}(y_{t})-g_{2}(y_{t}))^{2}\\geq\\xi.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By the $\\xi$ -dependencies, we have $\\begin{array}{r}{\\sum_{t\\in[i-1]}(g_{1}(y_{t})\\,-\\,g_{2}(y_{t}))^{2}\\;\\geq\\;\\lfloor A/d\\rfloor\\,\\cdot\\,\\xi}\\end{array}$ .At the same time, $\\begin{array}{r}{\\sum_{t\\in[i-1]}(g_{1}(y_{t})-g_{2}(y_{t}))^{2}\\leq4\\xi/\\rho}\\end{array}$ due to (C.2). Thus, we deduce that $A=|\\mathcal{J}_{j}^{k}|\\leq O(d/\\rho)$ for all $k\\in[\\lceil\\log_{2}T\\rceil]$ . Substituting it into (C.1), we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{i\\in[\\vert\\mathcal{Z}_{j}\\vert]}\\operatorname*{min}\\left(1,4D_{\\mathcal{G}}^{2}\\left(x_{i};x_{[i-1]},1_{[i-1]}\\right)\\right)\\le4/\\lambda+4\\int_{1/\\lambda T}^{1}O(d/\\rho\\cdot\\log_{2}T)\\mathrm{d}\\rho}}\\\\ &{}&{=O(d\\log_{2}T\\cdot\\log\\lambda T+\\lambda^{-1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Here $j$ is chosen arbitrarily. Hence, the generalized eluder dimension can be further bounded as follows: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sum_{i\\in[T]}\\operatorname*{min}\\bigg(1,\\frac{1}{\\sigma_{i}^{2}}D_{\\mathcal{G}}^{2}\\left(z_{i};z_{[i-1]},\\sigma_{[i-1]}\\right)\\bigg)\\leq O(\\dim_{E}(\\mathcal{F},1/\\sqrt{T})\\log T\\log\\lambda T\\log(M/\\alpha)+\\lambda^{-1}).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In the following part, we will also discuss the issue in Agarwal et al. (2022) about the relationship between the standard eluder dimension $\\dim_{E}$ and the generalized eluder dimension dim. In detail, Agarwal et al. (2022) proposed the concept of Generalized Eluder dimension and made the following claim: ", "page_idx": 16}, {"type": "text", "text": "Lemma C.2 (Remark 4, Agarwal et al. 2022). If we set the weight $\\sigma=1$ , then the Generalized Eluder dimension $\\begin{array}{r}{\\mathrm{dim}=\\operatorname*{sup}_{\\mathbf{Z},\\pmb{\\sigma}:|Z|=T}\\dim(\\mathcal{F},\\mathbf{Z},\\mathbf{1})}\\end{array}$ satisfied ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathrm{dim}\\le\\mathrm{dim}_{E}(\\mathcal{F},\\sqrt{\\lambda/T})+1,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathrm{dim}_{E}$ denotes the standard Eluder dimension proposed in Russo and Van Roy (2013). In the proof of Remark 4, Agarwal et al. (2022) claims that given the standard Eluder dimension $\\bar{\\mathrm{dim}}_{E}(\\mathcal{F},\\sqrt{\\lambda})\\ =\\ n$ , there are at most $n$ different (sorted) indices $\\{t_{1},t_{2},..\\}$ such that $D_{\\mathcal{F}}^{2}(z_{t_{i}};z_{t_{i}-1]},\\mathbf{1})\\ge\\epsilon^{2}/\\lambda$ . However, according to the definition of $D_{\\mathcal{F}}^{2}$ -uncertainty, we only have ", "page_idx": 16}, {"type": "equation", "text": "$$\nD_{\\mathcal{F}}^{2}(z;z_{[t-1]},\\mathbf{1}):=\\operatorname*{sup}_{f_{1},f_{2}\\in\\mathcal{F}}\\frac{(f_{1}(z)-f_{2}(z))^{2}}{\\sum_{s\\in[t-1]}(f_{1}(z_{s})-f_{2}(z_{s}))^{2}+\\lambda}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "However, $z_{t_{i}}$ is $\\epsilon$ -dependence with $z_{1},..,z_{t_{i}-1}$ is only a sufficient condition for the uncertainty $D_{\\mathcal{F}}^{2}(z;z_{[t-1]},\\mathbf{1})$ rather than necessary condition. In cases where both $(f_{1}(z)-f_{2}(z))^{2}\\ge\\epsilon^{2}$ and $\\begin{array}{r}{\\sum_{s\\in[t-1]}(\\dot{f_{1}}(z_{s})-f_{2}(z_{s}))^{2}\\geq\\epsilon^{2}}\\end{array}$ hold, the uncertainty $D_{\\mathcal{F}}^{2}(z;z_{[t-1]},\\mathbf{1})$ may exceed $\\epsilon^{2}/\\lambda$ , yet it will not be counted within the longest $\\epsilon$ -independent sequence for the standard Eluder dimension. ", "page_idx": 16}, {"type": "text", "text": "D Proof of Theorem 4.1 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we provide the proof of Theorem 4.1. ", "page_idx": 16}, {"type": "text", "text": "D.1  High Probability Events ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this subsection, we define the following high-probability events: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{E}_{k,h}^{\\widetilde f}=\\left\\{\\lambda+\\displaystyle\\sum_{i\\in[k-1]}\\left(\\widetilde f_{k,h}(s_{h}^{i},a_{h}^{i})-7_{h}^{2}V_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\le\\widetilde\\beta_{k}^{2}\\right\\},}\\\\ {\\mathcal{E}_{k,h}^{\\widehat f}=\\left\\{\\lambda+\\displaystyle\\sum_{i\\in[k-1]}\\frac{1}{\\widetilde\\sigma_{i,h}^{2}}\\left(\\widehat f_{k,h}(s_{h}^{i},a_{h}^{i})-7_{h}V_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\le\\beta_{k}^{2}\\right\\},}\\\\ {\\mathcal{E}_{k,h}^{\\widetilde f}=\\left\\{\\lambda+\\displaystyle\\sum_{i\\in[k-1]}\\frac{1}{\\widetilde\\sigma_{i,h}^{2}}\\left(\\check{f}_{k,h}(s_{h}^{i},a_{h}^{i})-7_{h}\\check{V}_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\le\\beta_{k}^{2}\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where ", "page_idx": 17}, {"type": "text", "text": "$\\tilde{\\mathsf{J}}_{k}:=\\sqrt{128\\log\\frac{N_{\\epsilon}(k)\\cdot N_{\\mathcal{F}}(\\epsilon)\\cdot H}{\\delta}+64L\\epsilon\\cdot k},\\ \\beta_{k}:=\\sqrt{128\\cdot\\log\\frac{N_{\\epsilon}(k)\\cdot N_{\\mathcal{F}}(\\epsilon)H}{\\delta}+64L\\epsilon\\cdot k/\\alpha^{2}}.$ $\\underline{{\\mathcal{E}_{k,h}^{f}}},\\underline{{\\mathcal{E}_{k,h}^{f}}}$ and $\\underline{{\\xi}}_{k,h}^{\\check{f}}$ are the hoeffding-type concentration results for $\\widetilde{f}_{k,h},\\,\\widehat{f}_{k,h}$ and $\\widecheck{f}_{k,h}$ respectively. Then we define the following bellman-type concentration events for $\\widehat{f}_{k,h},\\;\\widecheck{f}_{k,h}$ , which implies a tighter confidence set due to carefully designed variance estimators and an inverse-variance weighted regression scheme for the general function classes. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\hat{\\mathbf{\\eta}}_{h}^{\\hat{f}}=\\left\\{\\lambda+\\displaystyle\\sum_{i=1}^{k-1}\\frac{1}{(\\bar{\\sigma}_{i,h^{\\prime}})^{2}}\\left(\\hat{f}_{k,h^{\\prime}}(s_{h^{\\prime}}^{i},a_{h^{\\prime}}^{i})-\\mathcal{T}_{h^{\\prime}}V_{k,h^{\\prime}+1}(s_{h^{\\prime}}^{i},a_{h^{\\prime}}^{i})\\right)^{2}\\le\\hat{\\beta}_{k}^{2},\\mathrm{~}\\forall h\\le h^{\\prime}\\le H,k\\in[K]\\right\\},}\\\\ &{\\tilde{\\mathbf{\\eta}}_{h}^{\\check{f}}=\\left\\{\\lambda+\\displaystyle\\sum_{i=1}^{k-1}\\frac{1}{(\\bar{\\sigma}_{i,h^{\\prime}})^{2}}\\left(\\check{f}_{k,h^{\\prime}}(s_{h^{\\prime}}^{i},a_{h^{\\prime}}^{i})-\\mathcal{T}_{h^{\\prime}}V_{k,h^{\\prime}+1}(s_{h^{\\prime}}^{i},a_{h^{\\prime}}^{i})\\right)^{2}\\le\\check{\\beta}_{k}^{2},\\mathrm{~}\\forall h\\le h^{\\prime}\\le H,k\\in[K]\\right\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{\\beta}_{k}^{2}=\\breve{\\beta}_{k}^{2}:=O\\left(\\log\\frac{2k^{2}\\left(2\\log(L^{2}k/\\alpha^{4})+2\\right)\\cdot\\left(\\log(4L/\\alpha^{2})+2\\right)}{\\delta/H}\\right)\\cdot\\left[\\log(N_{\\mathcal{F}}(\\epsilon))+1\\right]}\\\\ &{\\ +O(\\lambda)+O(\\epsilon k L/\\alpha^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "We also define the following events which are later applied to prove the concentration of $\\widehat{f}_{k,h}$ and $\\widecheck{f}_{k,h}$ by induction. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\bar{\\mathcal{E}}_{k,h}^{\\hat{f}}=\\bigg\\{\\lambda+\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left(\\widehat{f}_{k,h}(s_{h}^{i},a_{h}^{i})-{\\mathcal{T}}_{h}V_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\leq\\widehat{\\beta}_{k}^{2}\\bigg\\},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\widehat{\\mathbb{1}}_{i,h}$ is the shorthand for the following product of indicator functions ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\hat{\\mathbb{\\Gamma}}_{i,h}:=\\mathbb{1}\\left([\\mathbb{V}_{h}V_{h+1}^{*}](s_{h}^{i},a_{h}^{i})\\leq\\bar{\\sigma}_{i,h}^{2}\\right)\\cdot\\mathbb{1}\\left([\\mathcal{T}_{h}V_{i,h+1}-\\mathcal{T}V_{h+1}^{*}]\\leq(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))^{-1}\\bar{\\sigma}_{i,h}^{2}\\right)}}\\\\ &{}&{\\cdot\\mathbb{1}\\left(V_{i,h+1}(s)\\geq V_{h+1}^{*}(s)\\quad\\forall s\\in\\mathcal{S}\\right).\\quad}&{\\quad}\\\\ &{}&{\\bar{\\mathcal{E}}_{k,h}^{\\check{f}}=\\left\\{\\lambda+\\sum_{i\\in[k-1]}\\frac{\\widecheck{\\mathbb{\\Gamma}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\check{f}_{k,h}(s_{h}^{i},a_{h}^{i})-\\mathcal{T}_{h}\\check{V}_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\leq\\check{\\beta}_{k}^{2}\\right\\},\\quad}&{\\quad(\\mathrm{D}.7)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\check{\\mathbb{1}}_{i,h}$ is the shorthand for the following product of indicator functions ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{\\Gamma}_{i,h}:=\\mathbb{1}\\left([\\mathbb{V}_{h}V_{h+1}^{*}](s_{h}^{i},a_{h}^{i})\\leq\\bar{\\sigma}_{i,h}^{2}\\right)\\cdot\\mathbb{1}\\left([\\mathcal{T}V_{h+1}^{*}-\\mathcal{T}_{h}\\check{V}_{i,h+1}]\\leq(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))^{-1}\\bar{\\sigma}_{i,h}^{2}\\right)}}\\\\ &{}&{\\cdot\\mathbb{1}\\left(\\check{V}_{i,h+1}(s)\\leq V_{h+1}^{*}(s)\\quad\\forall s\\in\\mathcal{S}\\right).\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad(\\mathrm{D}.8)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "The following Lemmas suggest that previous events hold with high probability. ", "page_idx": 17}, {"type": "text", "text": "Lemma D.1. Let $\\widetilde{f}_{k,h}$ be defned as in line 8ofAlgorithm 1, we have $\\underline{{\\xi}}^{\\widetilde{f}}:=\\bigcap_{k\\ge1,h\\in[H]}\\underline{{\\xi}}_{k,h}^{\\widetilde{f}}$ holds with probability t east $1-\\delta$ where $\\underline{{\\mathcal{E}}}_{k,h}^{\\widetilde f}$ is defined in D.1).   \nLemma D.2. Let $\\widehat{f}_{k,h}$ beded asi ofAgor1 w $\\underline{{\\xi}}^{\\hat{f}}:=\\bigcap_{k\\ge1,h\\in[H]}\\underline{{\\xi}}_{k,h}^{\\hat{f}}$ holds with probability at least $1-\\delta$ where $\\underline{{\\mathcal{E}}}_{k,h}^{\\hat{f}}$ is defined in D.2).   \nLemma D3. Let $\\widecheck{f}_{k,h}$ beded asifAgorw $\\begin{array}{r}{\\underline{{\\xi}}^{\\check{f}}:=\\bigcap_{k\\geq1,h\\in[H]}\\underline{{\\xi}}_{k,h}^{\\check{f}}}\\end{array}$ holds with probability at least $1-\\delta$ , where Et,h is defined in (D.3).   \nLemma D.4. Let $\\widehat{f}_{k,h}$ bededas fAgorw $\\begin{array}{r}{\\bar{\\mathcal{E}}^{\\hat{f}}:=\\bigcap_{k\\geq1,h\\in[H]}\\bar{\\mathcal{E}}_{k,h}^{\\hat{f}}}\\end{array}$ holds with probability at last $1-2\\delta$ where $\\mathcal{E}_{k,h}^{\\hat{f}}$ is defined in D.5). ", "page_idx": 17}, {"type": "text", "text": "Lemma D.5. Let $\\widecheck{f}_{k,h}$ be defined as in line $\\cdot$ of Algorithm 1, we have $\\bar{\\mathcal{E}}^{\\check{f}}$ holds with probability at least $1-2\\delta$ ", "page_idx": 17}, {"type": "text", "text": "D.2  Optimism and Pessimism ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Based on the high probability events, we have the following lemmas for the function $\\widehat{f}_{k,h}(s,a)$ and $\\check{f}_{k,h}(s,a)$ ", "page_idx": 18}, {"type": "text", "text": "Lemma D.6. On the events $\\mathcal{E}_{h}^{\\hat{f}}$ and $\\mathcal{E}_{h}^{\\breve{f}}$ for each episode $k\\in[K]$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl|\\widehat{f}_{k,h}(s,a)-\\mathcal{T}_{h}V_{k,h+1}(s,a)\\bigr|\\leq\\widehat{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\\\ &{\\bigl|\\check{f}_{k,h}(s,a)-\\mathcal{T}_{h}\\check{V}_{k,h+1}(s,a)\\bigr|\\leq\\check{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $z=(s,a)$ and $z_{[k-1],h}=\\{z_{1,h},z_{2,h},..,z_{k-1,h}\\}$ ", "page_idx": 18}, {"type": "text", "text": "Lemma D.7. On the events $\\mathcal{E}_{h+1}^{\\hat{f}}$ and $\\mathscr{E}_{h+1}^{\\check{f}}$ for each tage $h\\leq h^{\\prime}\\leq H$ and episode $k\\in[K]$ we have $Q_{k,h}(s,a)\\geq Q_{h}^{*}(s,a)\\geq\\check{Q}_{k,h}(s,a)$ . Furthermore, for the value functions $V_{k,h}(s)$ and $\\check{V}_{k,h}(s)$ we have $V_{k,h}(s)\\geq V_{h}^{*}(s)\\geq\\check{V}_{k,h}(s)$ ", "page_idx": 18}, {"type": "text", "text": "D.3Monotonic Variance Estimator ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In this subsection, we introduce the following lemmas to construct the monotonic variance estimator. Lemma D.8. On the events $\\mathcal{E}^{\\tilde{f}},\\mathcal{E}^{\\hat{f}}$ and $\\mathcal{E}^{\\widecheck{f}}$ for each episode $k\\in[K]$ and stage $h\\in[H]$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\widehat{f}_{k,h}(s,a)-{\\mathcal T}_{h}V_{k,h+1}(s,a)|\\leq\\beta_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\\\ &{|\\check{f}_{k,h}(s,a)-{\\mathcal T}_{h}\\check{V}_{k,h+1}(s,a)|\\leq\\beta_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\\\ &{|\\widetilde{f}_{k,h}(s,a)-{\\mathcal T}_{h}^{2}V_{k,h+1}(s,a)|\\leq\\widetilde{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $z=(s,a)$ and $z_{[k-1],h}=\\{z_{1,h},z_{2,h},..,z_{k-1,h}\\}$ ", "page_idx": 18}, {"type": "text", "text": "Lemma Dig On the events $\\underline{{\\xi}}^{\\tilde{f}},\\,\\underline{{\\xi}}^{\\tilde{f}},\\,\\underline{{\\xi}}^{\\check{f}},\\,\\mathcal{E}_{h+1}^{\\hat{f}},\\,\\mathcal{E}_{h+1}^{\\check{f}}$ fo each episode $k\\ \\in\\ [K]$ variance $[\\bar{\\mathbb{V}}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})$ satisfies the following inequalities: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|[\\bar{\\mathbb{V}}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{V}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})|\\leq E_{k,h},}\\\\ &{|[\\bar{\\mathbb{V}}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{V}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})|\\leq E_{k,h}+F_{k,h}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Lemma D.10. On the events &f,&, Eh+1, for each episode $k\\in[K]$ and $i>k$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\cdot\\big[\\mathbb{V}_{h}(V_{i,h+1}-V_{h+1}^{*})\\big](s_{h}^{k},a_{h}^{k})\\le F_{i,h},}\\\\ {(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\cdot\\big[\\mathbb{V}_{h}(V_{h+1}^{*}-\\check{V}_{i,h+1})\\big](s_{h}^{k},a_{h}^{k})\\le F_{i,h},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Based on previous lemmas, we can construct an optimistic estimator $\\sigma_{k,h}$ for the transition variance.   \nUnder this situation, the weighted regression have the following guarantee. ", "page_idx": 18}, {"type": "text", "text": "Lemma D.11. If the events $\\underline{{\\mathcal{E}}}^{\\tilde{f}},\\underline{{\\mathcal{E}}}^{\\hat{f}},\\underline{{\\mathcal{E}}}^{\\check{f}},\\bar{\\mathcal{E}}^{\\hat{f}}$ and $\\bar{\\mathcal{E}}^{\\breve{f}}$ hold, then events $\\mathcal{E}^{\\hat{f}}=\\mathcal{E}_{1}^{\\hat{f}}$ and $\\mathcal{E}^{\\widecheck{f}}=\\mathcal{E}_{1}^{\\widecheck{f}}$ hold. ", "page_idx": 18}, {"type": "text", "text": "D.4 Proof of Regret Bound ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In the subsection, we first define the following high proSbability events to control the stochastic noise from the transition process: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\dot{\\cdot}_{1}=\\left\\{\\forall h^{\\prime}\\in[H],\\sum_{k=1}^{K}\\sum_{h=h^{\\prime}}^{H}[\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})]\\big({s}_{h}^{k},{a}_{h}^{k}\\big)-\\sum_{k=1}^{K}\\sum_{h=h^{\\prime}}^{H}\\left(V_{k,h+1}\\big({s}_{h+1}^{k}\\big)-V_{h+1}^{\\pi^{k}}\\big({s}_{h+1}^{k}\\big)\\right)\\right\\}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\le2\\sqrt\\sum_{k=1}^{K}\\sum_{h=h^{\\prime}}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)\\right)}\\\\ {\\displaystyle\\le\\left\\{\\forall h^{\\prime}\\in[H],\\sum_{k=1}^{K}\\sum_{h=h^{\\prime}}^{H}[\\mathbb{P}_{h}(V_{k,h+1}-\\widecheck{V}_{k,h+1})]\\big(s_{h}^{k},a_{h}^{k}\\big)-\\sum_{k=1}^{K}\\sum_{h=h^{\\prime}}^{H}\\big(V_{k,h+1}\\big(s_{h+1}^{k}\\big)-\\widecheck{V}_{k,h+1}\\big(s_{h+1}^{k}-s_{h+1}^{k}\\big)\\big)\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\leq2\\sqrt{\\sum_{k=1}^{K}\\sum_{h=h^{\\prime}}^{H}[\\Psi_{h}(V_{k,h+1}-\\check{V}_{k,h+1})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "According to Freedman inequality (Lemma H.5), we directly have the following results. ", "page_idx": 19}, {"type": "text", "text": "Lemma D.12. Events ${\\mathcal{E}}_{1}$ and $\\mathcal{E}_{2}$ hold with probability at least $1-2\\delta$ ", "page_idx": 19}, {"type": "text", "text": "Proof. Fix an arbitrary $h\\in[H]$ . Applying Lemma H.5, we have the following inequality: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})\\big](s_{h}^{k},a_{h}^{k})-\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}\\big(V_{k,h+1}(s_{h+1}^{k})-V_{h+1}^{\\pi^{k}}(s_{h+1}^{k})\\big)}\\\\ &{\\displaystyle\\leq2\\sqrt{\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Applying a union bound for (D.9) across all $h\\in[H],k\\geq0$ we have Event ${\\mathcal{E}}_{1}$ holds with probability at least $1-2\\delta$ ", "page_idx": 19}, {"type": "text", "text": "Similarly, we also have the corresponding high-probability bound for $\\mathcal{E}_{2}$ ", "page_idx": 19}, {"type": "text", "text": "Next, we need the following lemma to control the summation of confidence radius. ", "page_idx": 19}, {"type": "text", "text": "Lemma D.13. For any parameters $\\beta\\geq1$ and stage $h\\in[H]$ , the summation of confidence radius over episode $k\\in[K]$ is upper bounded by ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{k=1}^{K}\\operatorname*{min}\\Big(\\beta D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),1\\Big)}\\\\ {\\displaystyle\\leq(1+\\beta\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+2\\beta\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F}_{h})}\\sqrt{\\displaystyle\\sum_{k=1}^{K}(\\sigma_{k,h}^{2}+\\alpha^{2})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $z=(s,a)$ and $z_{[k-1],h}=\\{z_{1,h},z_{2,h},..,z_{k-1,h}\\}.$ ", "page_idx": 19}, {"type": "text", "text": "Then, we can decompose the total regret in the first $K$ episode to the summation of variance $\\begin{array}{r}{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\sigma_{k,h}^{2}}\\end{array}$ as the following lemma. ", "page_idx": 19}, {"type": "text", "text": "Lemma D.14. On the events $\\mathcal{E}^{\\hat{f}}=\\mathcal{E}_{1}^{\\hat{f}}$ $\\mathcal{E}^{\\widecheck{f}}=\\mathcal{E}_{1}^{\\widecheck{f}}$ and ${\\mathcal{E}}_{1}$ fo each stage $h\\in[H]$ the regret in the first $K$ episodes can be decomposed and controlled as: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{k=1}^{K}\\big(V_{k,h}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\big)\\le2C H(1+\\chi)(1+\\widehat\\beta_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F})}\\\\ {\\displaystyle\\qquad+\\,4C(1+\\chi)\\widehat\\beta_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\underset{k=1}{\\overset{K}{\\sum}}\\underset{h=1}{\\overset{H}{\\sum}}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\\\ {\\displaystyle\\qquad+\\,2\\sqrt{\\underset{k=1}{\\overset{K}{\\sum}}\\underset{h^{\\prime}=h}{\\overset{H}{\\sum}}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K(\\mathcal{F}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and for all stage $h\\in[H]$ , we further have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{s=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\big[\\mathbb{P}_{h}\\big(V_{k,h+1}-V_{h+1}^{\\pi^{k}}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ {\\displaystyle\\leq2C H^{2}(1+\\chi)(1+\\widehat\\beta_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F})+4C H(1+\\chi)\\widehat\\beta_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F}_{h})}\\sqrt{H\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\nH\\left(2\\sqrt{\\sum_{k=1}^{K}\\sum_{h=1}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)\\right)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "In addition, the gap between the optimistic value function $V_{k,h}(s)$ and pessimistic value function $\\check{V}_{k,h}(s)$ can be upper bounded by the following lemma. ", "page_idx": 20}, {"type": "text", "text": "Lemma D.15. On the events $\\mathcal{E}^{\\hat{f}}=\\mathcal{E}_{1}^{\\hat{f}}$ \uff0c1 $\\mathcal{E}^{\\widecheck{f}}=\\mathcal{E}_{1}^{\\widecheck{f}}$ and $\\mathcal{E}_{2}$ for each stage $h\\in[H]$ , the regret in the first $K$ episodes can be decomposed and controlled as: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{k=1}^{K}\\big(V_{k,h}(s_{h}^{k})-\\breve{V}_{k,h}(s_{h}^{k})\\big))\\leq4C H(1+\\chi)(1+\\hat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})}\\\\ {\\displaystyle\\quad+\\,8C(1+\\chi)\\hat{\\beta}_{k}\\sqrt{\\mathrm{dim}_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\\\ {\\displaystyle\\quad+\\,2\\sqrt{\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-\\breve{V}_{k,h+1})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "and for all stage $h\\in[H]$ , we further have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{\\kappa=1}^{K}\\sum_{h=1}^{H}\\big[\\mathbb{P}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}}\\\\ &{\\le4C H^{2}(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+8C H(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\sum_{k=1}^{K}\\!\\!\\!\\sum_{h=1}^{H}\\!\\!\\!(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\\\ &{\\quad+\\,2H\\left(2\\sqrt{\\sum_{k=1}^{K}\\!\\!\\!\\sum_{h=h}^{H}\\!\\!\\!\\big[\\mathbb{V}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})\\big](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}\\!\\!\\operatorname{X})\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We define the following high probability event ${\\mathcal{E}}_{3}$ to control the summation of variance. ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathcal{E}_{3}=\\bigg\\{\\sum_{k=1}^{K}\\sum_{h=1}^{H}[\\mathbb{V}_{h}{V}_{h+1}^{\\pi^{k}}](s_{h}^{k},a_{h}^{k})\\leq3K+3H\\log(1/\\delta)\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "According to Jin et al. (2018) $(\\mathrm{Lemma}\\,\\mathrm{C}.5)^{3}$ , with probability at least $1-\\delta$ . Condition on this event, the summation of variance $\\begin{array}{r}{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\sigma_{k,h}^{2}}\\end{array}$ can be upper boundedby the following lemma. ", "page_idx": 20}, {"type": "text", "text": "Lemma D.16. On the events $\\mathcal{E}_{1},\\mathcal{E}_{2},\\mathcal{E}_{3},\\mathcal{E}^{\\hat{f}}=\\mathcal{E}_{1}^{\\hat{f}}$ and $\\mathcal{E}^{\\widecheck{f}}=\\mathcal{E}_{1}^{\\widecheck{f}}$ , the total estimated variance isupper bounded by: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\sigma_{k,h}^{2}\\le(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\times\\widetilde{O}\\big((1+\\gamma^{2})(\\beta_{k}+H\\widehat{\\beta}_{k}+\\widetilde{\\beta}_{k})H\\dim_{\\alpha,K}(\\mathcal{F})\\big)}}\\\\ &{}&{\\quad+\\;(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))^{2}\\times\\widetilde{O}\\big((\\beta_{k}+H\\widehat{\\beta}_{k}+\\widetilde{\\beta}_{k})^{2}H\\dim_{\\alpha,K}(\\mathcal{F})\\big)}\\\\ &{}&{\\quad+\\;\\widetilde{O}(\\mathrm{Var}_{K}+K H\\alpha^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "With all previous lemmas, we can prove Theorem 4.1 ", "page_idx": 20}, {"type": "text", "text": "Proof of Theorem 4.1. The low switching cost result is given by Lemma G.1. ", "page_idx": 20}, {"type": "text", "text": "3Jin et al. (2018) showed that $\\begin{array}{r l r}{\\sum_{k=1}^{K}\\sum_{h=1}^{H}[\\mathbb{V}_{h}{V}_{h+1}^{\\pi^{k}}](s_{h}^{k},a_{h}^{k})}&{{}=}&{\\widetilde O(K H^{2}\\;+\\;H^{3})}\\end{array}$ When $\\sum h=1^{H}r_{h}(s_{h},a_{h})\\leq H$ In this work, we assume the total reward satisfied $\\begin{array}{r}{\\sum_{h=1}^{H}r_{h}(s_{h},a_{h})\\le1}\\end{array}$ and the summation of variance is upper bounded by ${\\widetilde{O}}(K+H)$ ", "page_idx": 20}, {"type": "text", "text": "After taking a union bound, the high probability events $\\mathcal{E}_{1},\\mathcal{E}_{2},\\mathcal{E}_{3},\\underline{{\\mathcal{E}}}^{\\widetilde{f}},\\underline{{\\mathcal{E}}}^{\\widetilde{f}},\\underline{{\\mathcal{E}}}^{\\widetilde{f}},\\bar{\\mathcal{E}}^{\\widehat{f}}$ and $\\bar{\\mathcal{E}}^{\\check{f}}$ hold with probability at least $1-10\\delta$ . Conditioned on these events, the regret is upper bounded by ", "page_idx": 21}, {"type": "text", "text": "Regret(K) ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\frac{\\kappa}{\\mathrm{Kn}}\\left(V(\\tau_{k})-V\\right)(\\tau_{k}^{\\star})}\\\\ &{=\\underset{0\\leq t\\leq0}{\\leq}(\\tau_{k}(k_{1})+\\kappa_{1}^{\\star})\\Bigg(\\tau_{k}^{\\star}\\Bigg)}\\\\ &{\\leq\\underset{0\\leq t\\leq0}{\\leq}(\\tau_{k}(k_{1})+\\kappa_{1}^{\\star})(\\lambda_{0}\\kappa_{1}(s)+\\sigma_{\\eta}\\left(\\left[\\sqrt{\\frac{K}{\\sum_{k=1}^{k}\\gamma_{k}}}\\gamma_{k}(k_{1}\\kappa_{1}-\\tau_{k+1}^{\\star})(\\tau_{k}+\\sigma_{\\eta})\\right]\\right)}\\\\ &{\\quad+\\varepsilon(\\tau_{k}+\\lambda_{1})\\kappa_{1}^{\\star}\\sqrt{\\operatorname*{imin}_{\\varepsilon}(\\lambda_{0}\\kappa_{1}\\delta^{\\prime})}\\sqrt{\\underset{0\\leq t\\leq0}{\\sum_{k=1}^{k}\\gamma_{k}}}(\\tau_{k}^{\\star}\\log\\left(\\tau_{k}+\\sigma_{\\eta}\\right)}\\\\ &{\\leq\\varepsilon\\mathrm{Z}\\tau(t)+1)(\\lambda_{0}+\\delta_{0}^{\\star})^{2}\\operatorname*{im}_{\\varepsilon}(s)+\\beta\\Bigg(\\left[\\sum_{k=1}^{k}\\gamma_{k}(s)_{k}(\\kappa_{1}-\\tau_{k+1}^{\\star})(\\delta_{0}+\\sigma_{\\eta})\\right]}\\\\ &{\\quad+\\varepsilon(\\tau_{k}+\\lambda_{1})\\kappa_{1}^{\\star}\\sqrt{\\operatorname*{im}_{\\varepsilon}(\\lambda_{0}\\kappa_{1}\\delta^{\\prime})}\\sqrt{\\underset{0\\leq t\\leq0}{\\sum_{k=1}^{k}\\gamma_{k}}}(\\tau_{k}^{\\star}\\log\\left(\\tau_{k}+\\sigma_{\\eta}\\right)}\\\\ &{\\leq\\delta^{2}\\pi/(1+\\delta_{0})(\\lambda_{0}+\\delta_{1})+\\beta\\Bigg(\\lambda_{1}\\sqrt{\\operatorname*{im}_{\\varepsilon}(\\lambda_{0}\\kappa_{1}\\delta^{\\prime})}\\sqrt{\\underset{0\\leq t\\leq0}{\\sum_{k=1}^{k}\\gamma_{k}}}(\\tau_{k}+\\sigma_{\\eta})}\\\\ &{\\leq\\delta^{2}\\pi/(1+\\delta_{0})(\\lambda_{0}+\\delta_{1})+\\beta\\\n$$$$\n\\begin{array}{r l}&{\\quad+\\alpha(1+\\lambda)\\lambda_{K}\\sqrt{\\operatorname*{min}_{\\lambda}(P)}\\Bigg[\\eta_{1}\\frac{\\eta_{2}^{K}}{\\sum_{k=1}^{M}(\\lambda)}(\\eta_{2}^{K}+\\alpha^{(k)})}\\\\ &{\\leq\\lambda^{2\\!}\\pi(1+\\lambda)(1+\\lambda_{K}^{2\\!})^{2\\!}\\sinh_{M,K}(\\eta_{3}+\\alpha^{(k)})+\\Bigg(\\sqrt{\\frac{\\lambda}{\\sqrt{\\operatorname*{man}_{\\lambda}(\\lambda)}}}\\sqrt{\\eta_{1}(\\lambda)}\\sinh_{M,K}(\\eta_{2}^{K})\\Bigg)(\\lambda)\\Bigg]}\\\\ &{\\quad+\\alpha(1+\\lambda)\\lambda_{K}\\sqrt{\\operatorname*{min}_{\\lambda}(P)}\\sqrt{\\prod_{k=1}^{M}\\frac{\\eta_{1}^{K}}{\\sum_{k=1}^{M}(\\lambda)^{2!}}}}\\\\ &{\\leq\\xi^{2\\!\\!K}[(1+\\lambda)(\\frac{1+\\lambda_{K}^{2\\!}}{\\xi})^{2\\!}\\sinh_{M,K}(\\eta_{3}+\\alpha^{(k)})+\\Big(\\widehat{\\beta}_{\\operatorname*{man}_{\\lambda}(\\lambda)}\\sqrt{\\eta_{1}\\frac{\\lambda}{\\sqrt{\\operatorname*{man}_{\\lambda}(\\lambda)}}}\\prod_{l=\\lambda}^{0}(\\eta_{2}^{K}+\\alpha^{(k)})\\Big)}\\\\ &{\\leq\\xi^{2\\!}\\left(\\eta\\!\\operatorname*{min}_{\\lambda}(P)\\!+\\!(\\frac{1+\\lambda_{K}^{2\\!}}{\\xi})^{2\\!}\\right)+\\overline{{\\left(\\widehat{\\beta}_{\\operatorname*{man}_{\\lambda}(\\lambda)}\\sqrt{\\eta_{1}(\\lambda)}-\\sqrt{\\lambda}\\right)}}}\\\\ &{=\\displaystyle(\\overline{{\\beta}}\\left(\\operatorname*{min}_{\\lambda}(P)\\!+\\!(\\lambda)\\!+\\!\\beta_{1}^{2\\!})\\sinh_{M,K}(\\eta_{1}\\!-\\!\\lambda)\\!+\\!\\beta_{1}^{2\\!}\\sinh_{M,K}(\\eta_{2}^{K})\\!\\right)+\\beta\\left(\\eta\\!\\operatorname*{man}_{\\lambda}(P)\\!+\\!(\\lambda)\\right)}\\\\ &{\\quad+\\displaystyle(\\overline{{\\beta}}^{\\operatorname*{man}_{\\lambda}(\\lambda)}\\!\\cdot\\!\\beta_{1}\\!+\\!\\gamma \n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the first inequality holds due to Lemma D.7, the second inequality holds due to Lemma D.14, the third inequality follows from Lemma D.7 and $\\operatorname{Var}[X]\\leq\\mathbb{E}[X]\\cdot\\dot{M}$ if random variable $X$ is in $[0,M]$ , the fourth inequality holds due to (F.41) and $2a\\dot{b}\\le a^{2}+\\dot{b}^{2}$ , the last inequality holds due to Lemma D.16. Thus, we complete the proof of Theorem 4.1. ", "page_idx": 21}, {"type": "text", "text": "We can reorganize (D.11) into the following upper bound for regret, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Regret}(K)=\\widetilde{O}(\\sqrt{\\dim(\\mathcal{F})\\log N\\cdot H\\mathrm{Var}_{K}})}\\\\ &{\\qquad\\qquad\\qquad+\\,\\widetilde{O}\\left(H^{2.5}\\dim^{2}(\\mathcal{F})\\sqrt{\\log N}\\log(N\\cdot N_{b})\\cdot\\sqrt{H\\log N+\\dim(\\mathcal{F})\\log(N\\cdot N_{b})}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where we denote the covering number of bonus function class $\\begin{array}{r}{N\\left(\\boldsymbol{B},\\frac{1}{2K H L\\hat{\\beta}_{K}}\\right)}\\end{array}$ by $N_{b}$ , the covering number of function class $\\mathcal{F}$ by $N$ and the dimension $\\dim_{\\alpha,K}({\\mathcal{F}})$ by $\\dim({\\mathcal{F}})$ . Since $\\mathcal{E}_{3}$ occurs with high probability according to Jin et al. (2018) (Lemma C.5), we have $\\operatorname{Var}_{K}=\\widetilde{O}(K)$ , which matches the worst-case minimax optimal regret bound of MDPs with general function approximation. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "D.5  Proof Sketch of Regret Bound ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "In this subsection, we provide a proof sketch on the regret bound and show how our policy-switching strategyworks. ", "page_idx": 22}, {"type": "text", "text": "First, we introduce the following lemma which illustrates the stability of the bonus function after using the uncertainty-based policy-switching condition. ", "page_idx": 22}, {"type": "text", "text": "Lemma D.17 (Restatement of Lemma G.2). If the policy is not updated at episode $k$ , the uncertainty of all state-action pair $z=(s,a)\\in S\\times A$ and stage $h\\in[H]$ satisfies the following stability property: ", "page_idx": 22}, {"type": "equation", "text": "$$\nD_{\\mathcal{F}_{h}}^{2}\\bigl(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\bigr)\\geq\\frac{1}{1+\\chi}D_{\\mathcal{F}_{h}}^{2}\\bigl(z;z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h}\\bigr).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "With Lemma G.2, we can then conver $\\cdot D_{\\mathcal{F}_{h}}^{2}(z;z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h}$ in the bonus term into $D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})$ with a cost of an additional $1+\\chi$ constant. ", "page_idx": 22}, {"type": "text", "text": "As a direct consequence of Lemma G.2, We have the following lemma, which controls the gap between optimistic value functions and real value functions resulting from the exploration bonuses. ", "page_idx": 22}, {"type": "text", "text": "Lemma D.18 (Restatement of Lemma D.14). On the events $\\mathcal{E}^{\\hat{f}}=\\mathcal{E}_{1}^{\\hat{f}}$ \uff0c $\\mathcal{E}^{\\widecheck{f}}=\\mathcal{E}_{1}^{\\widecheck{f}}$ and ${\\mathcal{E}}_{1}$ , for each stage $h\\in[H]$ , the regret in the first $K$ episodes can be decomposed and controlled as: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{k=1}^{K}\\big(V_{k,h}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\big)\\le2C H(1+\\chi)(1+\\widehat\\beta_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F})}\\\\ {\\displaystyle\\qquad+\\,4C(1+\\chi)\\widehat\\beta_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\underset{k=1}{\\overset{K}{\\sum}}\\underset{h=1}{\\overset{H}{\\sum}}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\\\ {\\displaystyle\\qquad+\\,2\\sqrt{\\underset{k=1}{\\overset{K}{\\sum}}\\underset{h^{\\prime}=h}{\\overset{H}{\\sum}}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K(\\mathcal{F}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "and for all stage $h\\in[H]$ , we further have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{\\ell=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\big[\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})\\big](s_{h}^{k},a_{h}^{k})}\\\\ {\\displaystyle\\leq2C H^{2}(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F})+4C H(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F}_{h})}\\sqrt{H\\displaystyle\\sum_{k=1}^{K}\\!\\!\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\\\ {\\displaystyle\\qquad+\\,H\\left(2\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\!\\!\\sum_{h=1}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K(\\chi))\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "As a need to bound the sum of bonuses corresponding to a weighted regression target, we derive the following results on the sum of inverse weights. ", "page_idx": 22}, {"type": "text", "text": "Lemma D.19 (Informal version of Lemma D.16). With high probability, the total estimated variance is upper bounded by: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\sigma_{k,h}^{2}\\le(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\times\\widetilde O\\big((1+\\gamma^{2})(\\beta_{k}+H\\widehat\\beta_{k}+\\widetilde\\beta_{k})H\\dim_{\\alpha,K}(\\mathcal{F})\\big)}&{}\\\\ {\\displaystyle+\\left(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K)\\right)^{2}\\times\\widetilde O\\big((\\beta_{k}+H\\widehat\\beta_{k}+\\widetilde\\beta_{k})^{2}H\\dim_{\\alpha,K}(\\mathcal{F})\\big)}&{}\\\\ {\\displaystyle+\\,\\widetilde O(\\mathrm{Var}_{K}+K H\\alpha^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof sketch of Theorem 4.1. As the result of optimism, we have shown that with high probability, for all $k,h\\in[K]\\times[H],V_{k}$ $V_{k,h}$ is an upper bound for $V_{h}^{*}$ . Hence, we further have, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname{Regret}(K)=\\sum_{k=1}^{K}\\left(V_{1}^{*}(s_{1}^{k})-V_{k,1}^{\\pi^{k}}(s_{1}^{k})\\right)\\leq\\sum_{k=1}^{K}\\left(V_{k,1}(s_{1}^{k})-V_{k,1}^{\\pi^{k}}(s_{1}^{k})\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ker^{\\mathrm{ret}}(K)\\leq2C H(1+\\chi)(1+\\widehat{\\beta}_{K}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F})+\\tilde{O}\\left(\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}[\\Psi_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})}\\right)}\\\\ &{\\qquad\\qquad+\\,4C(1+\\chi)\\widehat{\\beta}_{K}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{\\displaystyle H\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the second term can be bounded by applying Lemma D.14 repeatedly and the third term can be controlled by Lemma D.16. ", "page_idx": 23}, {"type": "text", "text": "Then after substituting the value of $\\widehat{b}e t a_{K},\\gamma$ and $\\alpha$ , we conclude that with high probability, ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Regret}(K)=\\widetilde{O}(\\sqrt{\\dim(\\mathcal{F})\\log N\\cdot H\\mathrm{Var}_{K}})}\\\\ &{\\qquad\\qquad\\qquad+\\,\\widetilde{O}\\left(H^{2.5}\\dim^{2}(\\mathcal{F})\\sqrt{\\log N}\\log(N\\cdot N_{b})\\cdot\\sqrt{H\\log N+\\dim(\\mathcal{F})\\log(N\\cdot N_{b})}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Please refer to Subsection D.4 for the detailed calculation of this part. ", "page_idx": 23}, {"type": "text", "text": "E Proof of Theorem B.1 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "In this section, we provide the proof of Theorem B.1. To prove the lower bound, we create a series of hard-to-learn MDPs as follows. Each hard-to-learn MDP comprises $d/4$ distinct sub-MDPs denoted as $\\mathcal{M}_{1},..,\\mathcal{M}_{d/4}$ . Each sub-MDP $\\mathcal{M}_{i}$ is characterized by two distinct states, initial state $s_{i,0}$ and absorbing state $s_{i,1}$ , and shares the same action set $\\mathcal{A}=\\{a_{0},a_{1}\\}$ . Since the state and action spaces are finite, these tabular MDPs can always be represented as linear MDPs with dimension $|{\\bar{S}}|\\times|A|=d$ ", "page_idx": 23}, {"type": "text", "text": "To generate each sub-MDP $\\mathcal{M}_{i}$ , for all stage $h\\in[H]$ , a special action $a_{i,h}$ is uniformly randomly selected from the action set $\\{a_{0},a_{1}\\}$ . Given the current state $s_{i,0}$ , the agent transitions to the state $s_{i,0}$ if it takes the special action $a_{i,h}$ . Otherwise, the agent transitions to the absorbing state $s_{i,1}$ and remains in that state in subsequent stages. The agent will receive the reward 1 if it takes the special action $\\boldsymbol{a}_{i,H}$ at the state $s_{i,0}$ during the last stage $H$ . Otherwise, the agent always receives reward 0. In this scenario, for sub-MDP $\\mathcal{M}_{i}$ , the optimal policy entails following the special action sequence $(a_{i,1},a_{i,2},...,a_{i,H})$ to achieve a total reward of 1. In contrast, any other action sequence fails to yield any reward. ", "page_idx": 23}, {"type": "text", "text": "Now, we partition the $K$ episodes to $d/4$ different distinct epochs. For each epoch (ranging from episodes $\\bar{4}(i-1)K/d+1$ to episode $4i K/d)$ , we initialize the state as $s_{i,0}$ and exclusively focus on the sub-MDP $\\mathcal{M}_{i}$ . The regret in each epoch can be lower bounded separately as follows: ", "page_idx": 23}, {"type": "text", "text": "Lemma E.1. For each epoch $i\\in[d/4]$ and any algorithm Alg capable of deploying arbitrary policies, if the expected switching cost in epoch $i$ is less than $H/(2\\log K)$ , the expected regret of Alg in the $i$ -th epoch is at least $\\Omega(\\bar{K}/d)$ ", "page_idx": 23}, {"type": "text", "text": "Proof of Lemma E.1. Given that each sub-MDP is independently generated, policy updates before epoch $i$ only offer information for the sub-MDPs $\\mathcal{M}_{1},...,\\mathcal{M}_{i-1}$ and do not provide any information for the current epoch $i$ . In this scenario, there is no distinction between epochs and for simplicity, we only focus on the first epoch, encompassing episodes 1 to $4K/d$ ", "page_idx": 23}, {"type": "text", "text": "Now, let $k_{0}\\,=\\,0$ and we denote $\\kappa=\\{k_{1},k_{2},\\ldots\\}$ as the set of episodes where the algorithm Alg updates the policy. If Alg does not update the policy $i$ times, we set $k_{i}=4K/d+1$ . For simplicity, we set $C=2\\log K$ and for each $i\\leq H/C$ , we define the events $\\mathcal{E}$ as the algorithm $\\mathbf{A}\\mathbf{l}\\mathbf{g}$ has not reached the state $s_{1,0}$ at the stage $i C$ before the episode $k_{i}$ ", "page_idx": 23}, {"type": "text", "text": "Conditioned on the events $\\mathcal{E}_{1},...,\\mathcal{E}_{i-1}$ , the algorithm Alg does not gather any information about the special action $^{a_{1,h}}$ for stage $h\\geq(i-1)C+1$ . In this scenario, the special actions can still be considered as uniformly randomly selected from the action set $a_{0},a_{1}$ . For each episode between $k_{i-1}$ and $k_{i}$ , the probability that a policy $\\pi$ arrives at state $s_{1,0}$ at stage $^{i C}$ is upper-bounded by: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathfrak{L}_{a_{1,(i-1)C+1},\\ldots,a_{1,i C}}\\left[\\Pi_{h=1}^{i C}\\operatorname*{Pr}(\\pi_{h}(s_{1,0})=a_{1,h})\\right]\\le\\mathbb{E}_{a_{1,(i-1)C+1},\\ldots,a_{1,i C}}\\left[\\Pi_{h=(i-1)C+1}^{i C}\\operatorname*{Pr}(\\pi_{h}(s_{1,0})=a_{1,(i-1)C+1})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the first inequality holds due to $\\pi(s_{1,0})=a_{1,h})\\leq1$ and the second equation holds due to the random generation process of the special actions. Notice that there are at most $K$ episodes between the $k_{i-1}$ and $k_{i}$ and after applying an union bound for all episodes, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}({\\mathcal{E}}_{i}|{\\mathcal{E}}_{1},...,{\\mathcal{E}}_{i-1})\\leq1-{\\frac{K}{2^{C}}}=1-{\\frac{1}{K}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Furthermore, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathrm{v}_{\\mathsf{r}}(\\mathcal{E}_{H/C})\\le\\operatorname*{Pr}(\\mathcal{E}_{1}\\cap\\mathcal{E}_{2}\\cap\\mathcal{E}_{3}\\cap\\ldots\\cap\\mathcal{E}_{H/C})=\\Pi_{i=1}^{H/C}\\operatorname*{Pr}(\\mathcal{E}_{i}|\\mathcal{E}_{1},\\ldots,\\mathcal{E}_{i-1})\\le(1-\\frac{1}{1K})^{H/C}\\le1-\\frac{E_{\\mathsf{N}}^{\\star}(\\mathcal{E}_{1}\\cap\\mathcal{E}_{2})}{C_{i}}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Notice that the agent cannot receive any reward unless it has reached the state $s_{i,0}$ at the last stage $H$ . Therefore, the expected regret for the algorithm Alg for the sub-MDP $\\mathcal{M}$ can be bounded by the switchingcost $\\delta$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\quad}&{\\mathbb{E}_{\\mathcal{M}}[\\mathrm{Regret}(\\mathbf{A}\\mathbf{j})]\\geq\\mathbb{E}_{\\mathcal{M}}[\\mathbb{1}(\\mathcal{E}_{H/C})\\times(k_{H/C}-1)]}\\\\ &{\\qquad\\qquad\\qquad\\geq\\mathbb{E}_{\\mathcal{M}}[k_{H/C}-1]-\\displaystyle\\frac{H}{C}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\mathbb{E}_{\\mathcal{M}}\\left[\\mathbb{1}(\\delta<H/C)\\cdot K/d\\right]-\\displaystyle\\frac{H}{C}}\\\\ &{\\qquad\\qquad\\qquad\\geq4K/d-\\mathbb{E}_{\\mathcal{M}}\\left[\\delta\\right]\\cdot\\displaystyle\\frac{4K C}{d H}-\\displaystyle\\frac{H}{C},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the first inequality holds due to the fact that the agent receives no reward before $k_{H/C}$ conditioned on the event $\\mathcal{E}_{H/C}$ , the second inequality holds due to (E.1) with $k_{H/C}-1\\leq K$ , the third inequality holds due to the definition of $k_{H/C}$ and the last inequality holds due to $\\mathbb{E}[\\mathbb{1}(x\\geq$ $a)]\\leq\\mathbb{E}[x]/a$ for any non-negative random variable $x$ . According to the result in (E.1), if the expected switching $\\dot{\\mathbb{E}}[\\delta]\\le\\dot{H}/(2C)$ , the expected regret is at least $\\Omega(K)$ , when $K$ is large enough compared to $H$ \u53e3 ", "page_idx": 24}, {"type": "text", "text": "With Lemma B.1, we can prove Theorem B.1. ", "page_idx": 24}, {"type": "text", "text": "Proof of Theorem B.1. For these constructed hard-to-learn MDPs and any given algorithm Alg, we denote the expected switching cost for sub-MDP $\\mathcal{M}_{i}$ as $\\delta_{i}$ ", "page_idx": 24}, {"type": "text", "text": "According to Lemma E.1, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{\\boldsymbol{\\mathcal{M}}_{i}}[\\mathrm{Regret}(\\mathbf{A}\\mathbf{lg})]\\ge\\mathrm{Pr}\\left(\\delta_{i}<H/(2\\log K)\\right)\\cdot K/d}\\\\ &{\\qquad\\qquad\\qquad\\ge\\left(1-\\mathbb{E}_{\\boldsymbol{\\mathcal{M}}_{i}}[\\delta_{i}]\\cdot2\\log K/H\\right)\\cdot K/d,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the first inequality holds due to lemma B.1 and last inequality holds due to. $\\mathbb{E}[\\mathbb{1}(x\\geq a)]\\leq$ $\\mathbb{E}[x]/a$ for any non-negative random variable $x$ . Taking a summation of (E.3) for all sub-Mdps, we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\mathbb{E}_{\\boldsymbol{\\mathcal{M}}}[\\mathrm{Regret}(\\mathbf{A}\\mathbf{l}\\mathbf{g})]=\\displaystyle\\sum_{i=1}^{d/4}\\mathbb{E}_{{\\boldsymbol\\mathcal{M}}_{i}}[\\mathrm{Regret}(\\mathbf{A}\\mathbf{l}\\mathbf{g})]}\\\\ {\\displaystyle\\geq\\sum_{i=1}^{d/4}\\left(1-\\mathbb{E}_{{\\boldsymbol\\mathcal{M}}_{i}}[\\delta_{i}]\\cdot2\\log K/H\\right)\\cdot K/d}\\\\ {\\displaystyle=\\left(d/4-\\mathbb{E}_{{\\boldsymbol\\mathcal{M}}}[\\delta]\\cdot2\\log K/H\\right)\\cdot K/d,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\delta$ is the total expected switching cost. Therefore, for any algorithm with total expected switching cost less than $d H/(16\\log K)$ , the expected is lower bounded by ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{\\mathcal{M}}[\\mathrm{Regret}(\\mathbf{A}\\mathbf{I}\\mathbf{g})]\\ge(d/4-\\mathbb{E}_{\\mathcal{M}}[\\delta]\\cdot2\\log K/H)\\cdot K/d\\ge K/8.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, we finish the proof of Theorem B.1. ", "page_idx": 24}, {"type": "text", "text": "F Proof of Lemmas in Appendix D ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section, we provide the detailed proof of lemmas in Appendix D. ", "page_idx": 25}, {"type": "text", "text": "F.1 Proof of High Probability Events ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "F.1.1 Proof of Lemma D.1 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Proof of Lemma $D.I$ We first prove that for an arbitrarily chosen $h\\in[H],\\underline{{\\mathcal{E}}}_{k,h}^{\\tilde{f}}$ holds with probability at least $1-\\delta/H$ for all $k$ ", "page_idx": 25}, {"type": "text", "text": "For simplicity, in this proof, we denote $\\mathcal{T}_{h}^{2}V_{k,h+1}(s_{h}^{i},a_{h}^{i})$ as $\\widetilde{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})$ where $\\widetilde{f}_{k}^{*}\\,\\in\\,\\mathcal{F}_{h}$ exists due to our assumption. For any function $V\\;:\\;{\\cal S}\\;\\rightarrow\\;[0,1]$ ,let $\\widetilde{\\eta}_{h}^{k}(V)\\ =\\ \\left(r_{h}^{k}+V(s_{h+1}^{k})\\right)^{2}\\,-$ $\\mathbb{E}_{s^{\\prime}\\sim s_{h}^{k},a_{h}^{k}}\\left[\\left(r(s_{h}^{k},a_{h}^{k},s^{\\prime})+V(s^{\\prime})\\right)^{2}\\right]\\!.$ ", "page_idx": 25}, {"type": "text", "text": "By simple calculation, for all $f\\in\\mathcal{F}_{h}$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in[k-1]}\\left(f(s_{h}^{i},a_{h}^{i})-\\widetilde{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}+2\\displaystyle\\sum_{i\\in[k-1]}\\left(f(s_{h}^{i},a_{h}^{i})-\\widetilde{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widetilde{\\eta}_{h}^{i}(V_{k,h+1})}\\\\ &{=\\displaystyle\\sum_{i\\in[k-1]}\\left[\\left(r_{h}^{i}+V_{k,h+1}(s_{h}^{i})\\right)^{2}-f(s_{h}^{i},a_{h}^{i})\\right]^{2}-\\displaystyle\\sum_{i\\in[k-1]}\\left[\\left(r_{h}^{i}+V_{k,h+1}(s_{h}^{i})\\right)^{2}-\\widetilde{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right]^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Due to the definition of $\\widetilde{f}_{k,h}$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\sum_{\\substack{(i,j)\\in[k-1]\\times[H]}}\\left(\\widetilde{f}_{k,h}(s_{j}^{i},a_{j}^{i})-\\widetilde{f}_{k}^{*}(s_{j}^{i},a_{j}^{i})\\right)^{2}+2I(\\widetilde{f}_{k,h},\\widetilde{f}_{k}^{*},V_{k,h+1})\\le0.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Then we give a high probability bound for $-I(f,\\widetilde{f}_{k}^{*},V_{k,h+1})$ through the following calculation. Applying Lemma H.4, for fixed $f,\\,{\\bar{f}}$ and $V$ , with probability at least $1-\\delta$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-I(f,\\bar{f},V):=-\\displaystyle\\sum_{i\\in[k-1]}\\big(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\big)\\cdot\\widetilde{\\eta}_{h}^{i}(V)}\\\\ &{\\qquad\\qquad\\qquad\\leq8\\lambda\\displaystyle\\sum_{i\\in[k-1]}\\big(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\big)^{2}+\\displaystyle\\frac{1}{\\lambda}\\cdot\\log\\displaystyle\\frac{1}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By the definition of $V$ in line $\\cdot$ of Algorithm 1, $V_{k,h+1}$ lies in the optimistic value function class $\\mathcal{V}_{k}$ defined in (G.4). Applying a union bound for all the value functions $V^{c}$ in the corresponding $\\epsilon$ -net $\\mathcal{V}^{c}$ , we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n-I(f,\\bar{f},V^{c})\\leq\\frac{1}{4}\\sum_{i\\in[k-1]}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}+32\\cdot\\log\\frac{N_{\\epsilon}(k)}{\\delta}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "holds for all $k$ with probability at least $1-\\delta$ ", "page_idx": 25}, {"type": "text", "text": "For all $V$ such that $\\|V-V^{c}\\|_{\\infty}\\leq\\epsilon$ ,we have $|\\eta_{h}^{i}(V)-\\eta_{h}^{i}(V^{c})|\\le4\\epsilon$ . Therefore, with probability $1-\\delta$ , the following bound holds for $I(f,{\\bar{f}},V_{k,h+1})$ ", "page_idx": 25}, {"type": "equation", "text": "$$\n-I(f,\\bar{f},V_{k,h+1})\\leq\\frac{1}{4}\\sum_{i\\in[k-1]}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}+32\\cdot\\log\\frac{N_{\\epsilon}(k)}{\\delta}+4\\epsilon\\cdot k.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To further bound $I(\\widetilde{f}_{k,h},\\widetilde{f}_{k}^{*},V_{k,h+1})$ in (F.1), we apply an $\\epsilon$ -covering argument on $\\mathcal{F}_{h}$ and show that with probability at least $1-\\delta$ \uff0c ", "page_idx": 25}, {"type": "equation", "text": "$$\n-I(\\widetilde{f}_{k,h},\\widetilde{f}_{k}^{*},V_{k,h+1})\\leq\\frac{1}{4}\\sum_{i\\in[k-1]}\\left(\\widetilde{f}_{k,h}(s_{h}^{i},a_{h}^{i})-\\widetilde{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}+32\\cdot\\log\\frac{N_{\\epsilon}(k)\\cdot N_{\\mathcal{F}}(\\epsilon)}{\\delta}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "for probability at least $1-\\delta$ ", "page_idx": 26}, {"type": "text", "text": "Substituting (F.2) into (F.1) and rearranging the terms, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k-1]}\\left(\\widetilde{f}_{k,h}\\big(s_{h}^{i},a_{h}^{i}\\big)-\\widetilde{f}_{k}^{*}\\big(s_{h}^{i},a_{h}^{i}\\big)\\right)^{2}\\leq128\\log\\frac{N_{\\epsilon}(k)\\cdot N_{\\mathcal{F}}(\\epsilon)\\cdot H}{\\delta}+64L\\epsilon\\cdot k\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "for all $k$ with probability at least $1-\\delta/H$ ", "page_idx": 26}, {"type": "text", "text": "Finally, we apply a union bound over all $h\\in[H]$ to conclude that $\\mathcal E^{\\widetilde f}$ holds with probability at least $1-\\delta$ ", "page_idx": 26}, {"type": "text", "text": "F.1.2 Proof of Lemmas D.2 and D.3 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Proof of Lemma $D.2$ .Similar to the proof of Lemma D.1, we first prove that for an arbitrarily chosen h E [H],Ek.h holds with probability at least $1-\\delta/H$ for all $k$ ", "page_idx": 26}, {"type": "text", "text": "In this proof, we denote $\\mathcal{T}_{h}V_{k,h+1}\\big(\\boldsymbol{s}_{h}^{i},\\boldsymbol{a}_{h}^{i}\\big)$ as $\\hat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})$ where $\\hat{f}_{k}^{*}\\in\\mathcal{F}_{h}$ exists due to our assumption. For any function $V:S\\rightarrow[0,1]$ let $\\widehat{\\eta}_{h}^{k}(V)=\\left(r_{h}^{k}+V(s_{h+1}^{k})\\right)-\\mathbb{E}_{s^{\\prime}\\sim s_{h}^{k},a_{h}^{k}}\\left[r_{h}(s_{h}^{k},a_{h}^{k},s^{\\prime})+V(s^{\\prime})\\right]$ For all $f\\in\\mathcal{F}_{h}$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\boldsymbol{\\epsilon}[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}+2\\sum_{\\scriptstyle\\underbrace{i\\in[k-1]}}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{k,h+1})}\\\\ &{=\\displaystyle\\sum_{\\scriptstyle i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})^{2}-f(s_{h}^{i},a_{h}^{i})\\right]^{2}-\\sum_{\\scriptstyle i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right]}\\\\ &{\\displaystyle=\\sum_{\\scriptstyle i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})^{2}-f(s_{h}^{i},a_{h}^{i})\\right]^{2}-\\sum_{\\scriptstyle i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By the definition of $\\widehat{f}_{k,h}$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widehat{f}_{k,h}\\big(s_{h}^{i},a_{h}^{i}\\big)-\\widehat{f}_{k}^{*}\\big(s_{h}^{i},a_{h}^{i}\\big)\\right)^{2}+2I(\\widehat{f}_{k,h},V_{k,h+1})\\leq0.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then we give a high probability bound for $-I(\\widehat{f}_{k,h},\\widehat{f}_{k}^{*},V_{k,h+1})$ through the following calculation. Applying Lemma H.4, for fixed $f,\\,{\\bar{f}}$ and $V$ , with probability at least $1-\\delta$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-I(f,\\bar{f},V):=-\\displaystyle\\sum_{i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\hat{\\eta}_{h}^{i}(V)}\\\\ &{\\qquad\\qquad\\leq8\\lambda\\displaystyle\\frac{1}{\\alpha^{2}}\\sum_{i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}+\\displaystyle\\frac{1}{\\lambda}\\cdot\\log\\displaystyle\\frac{1}{\\delta}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "By the definition of $V$ in line $\\cdot$ of Algorithm 1, $V_{k,h+1}$ lies in the optimistic value function class $\\mathcal{V}_{k}$ defined in (G.4). Applying a union bound for all the value functions $V^{c}$ in the corresponding $\\epsilon$ -net $\\mathcal{V}^{c}$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n-I(f,\\bar{f},V^{c})\\leq\\frac{1}{4}\\sum_{i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}+\\frac{32}{\\alpha^{2}}\\cdot\\log\\frac{N_{\\epsilon}(k)}{\\delta}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "holds for all $k$ with probability at least $1-\\delta$ ", "page_idx": 26}, {"type": "text", "text": "For all $V$ such that $\\|V-V^{c}\\|_{\\infty}\\leq\\epsilon$ we have $|\\eta_{h}^{i}(V)-\\eta_{h}^{i}(V^{c})|\\le4\\epsilon$ . Therefore, with probability $1-\\delta$ , the following bound holds for $I(f,{\\bar{f}},V_{k,h+1})$ ", "page_idx": 26}, {"type": "equation", "text": "$$\n-I(f,\\bar{f},V_{k,h+1})\\leq\\frac{1}{4}\\sum_{i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}+\\frac{32}{\\alpha^{2}}\\cdot\\log\\frac{N_{\\epsilon}(k)}{\\delta}+4\\epsilon\\cdot k/\\alpha^{2}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "To further bound $I(\\widehat{f}_{k,h},\\widehat{f}_{k}^{*},V_{k,h+1})$ in (F.3), we apply an $\\epsilon$ -covering argument on $\\mathcal{F}_{h}$ and show that with probability at least $1-\\delta$ \uff0c ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{-I(\\hat{f}_{k,h},\\hat{f}_{k}^{*},V_{k,h+1})\\leq\\frac{1}{4}\\displaystyle\\sum_{i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\hat{f}_{k,h}(s_{h}^{i},a_{h}^{i})-\\hat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}+32\\cdot\\log\\frac{N_{\\epsilon}(k)\\cdot N_{\\mathcal{F}}(\\epsilon)}{\\delta}}\\\\ &{}&{+\\,16L\\epsilon\\cdot k/\\alpha^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Substituting (F.4) into (F.3) and rearranging the terms, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k-1]}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widehat{f}_{k,h}(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\leq128\\cdot\\log\\frac{N_{\\epsilon}(k)\\cdot N_{\\mathcal{F}}(\\epsilon)H}{\\delta}+64L\\epsilon\\cdot k/\\alpha^{2}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "for all $k$ with probability at least $1-\\delta/H$ . Then we can complete the proof by using a union bound over all $h\\in[H]$ \u53e3 ", "page_idx": 27}, {"type": "text", "text": "Proof of Lemma $D.3$ .The proof is almost identical to the proof of Lemma D.2. ", "page_idx": 27}, {"type": "text", "text": "F.1.3 Proof of Lemmas D.4 and D.5 ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Proof of Lemma D.4. Similar to the proof of Lemma D.1, we first prove that for an arbitrary $h\\in[H]$ $\\bar{\\mathcal{E}}_{k,h}^{\\hat{f}}$ holds with probability at least $1-\\delta/H$ for all $k$ ", "page_idx": 27}, {"type": "text", "text": "In this proof, we denote $\\mathcal{T}_{h}V_{k,h+1}\\big(\\boldsymbol{s}_{h}^{i},\\boldsymbol{a}_{h}^{i}\\big)$ as $\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})$ where $\\hat{f}_{k}^{*}\\in\\mathcal{F}$ exists due to our assumption. For any function $V:S\\rightarrow[0,1]$ let $\\ddot{\\eta}_{h}^{k}(\\ddot{V})=\\left(\\ddot{r}_{h}^{k}+\\ddot{V}(s_{h+1}^{k})\\right)-\\ddot{\\mathbb{E}}_{s^{\\prime}\\sim s_{h}^{k},a_{h}^{k}}\\left[r_{h}(s_{h}^{k},a_{h}^{k},s^{\\prime})+V(s^{\\prime})\\right]$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\langle\\mathbb{k}-1\\mid}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}+2\\\\\\\\\\\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{k,h+1})}\\\\ &{=\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})^{2}-f(s_{h}^{i},a_{h}^{i})\\right]^{2}-\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right]}\\\\ &{=\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})^{2}-f(s_{h}^{i},a_{h}^{i})\\right]^{2}-\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left[r_{h}^{i}+V_{k,h+1}(s_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Due to the definition of $\\widehat{f}_{k,h}$ , we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widehat{f}_{k,h}\\big(s_{h}^{i},a_{h}^{i}\\big)-\\widehat{f}_{k}^{*}\\big(s_{h}^{i},a_{h}^{i}\\big)\\right)^{2}+2I(\\widehat{f}_{k,h},V_{k,h+1})\\leq0.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then it suffices to bound the value of $I(f,\\bar{f},V_{k,h+1})$ for all $f,{\\bar{f}}\\in{\\mathcal{F}}$ ", "page_idx": 27}, {"type": "text", "text": "Unlike the proof for Lemma D.1, we decompose $I(f,{\\bar{f}},V_{k,h+1})$ into two parts: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I(f,\\bar{f},V_{k,h+1})=\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{h+1}^{*})}\\\\ &{\\quad\\quad\\quad+\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{k,h+1}-V_{h+1}^{*}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then we bound the two terms separately. ", "page_idx": 27}, {"type": "text", "text": "For the first term, we first check the following conditions before applying Lemma H.2, which is a variant of Freedman inequality. For fixed $f$ and $\\bar{f}$ wehave ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{h+1}^{*})\\right]=0,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "since $s_{h+1}^{i}$ is sampled from $\\mathbb{P}_{h}(\\cdot|s_{h}^{i},a_{h}^{i})$ ", "page_idx": 27}, {"type": "text", "text": "Next, we need to derive a bound for the maximum absolute value of each \u2018weighted\u2019 transition noise: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\operatorname*{max}_{\\in[k-1]}\\left|\\frac{\\widehat{\\mathbb{f}}_{i,h}}{\\big(\\widehat{\\sigma}_{h,h}\\big)^{2}}\\left(f\\big(s_{h}^{i},a_{h}^{i}\\big)-\\bar{f}\\big(s_{h}^{i},a_{h}^{i}\\big)\\right)\\cdot\\widehat{\\eta}_{h}^{i}\\big(V_{h+1}^{*}\\big)\\right|}\\\\ &{\\le4\\displaystyle\\operatorname*{max}_{i\\in[k-1]}\\left|\\frac{\\widehat{\\mathbb{f}}_{i,h}}{\\Big(\\widehat{\\sigma}_{i,h}\\Big)^{2}}\\left(f\\big(s_{h}^{i},a_{h}^{i}\\big)-\\bar{f}\\big(s_{h}^{i},a_{h}^{i}\\big)\\right)\\right|}\\\\ &{\\le4\\displaystyle\\operatorname*{max}_{i\\in[k-1]}\\frac{1}{\\Big(\\widehat{\\sigma}_{i,h}\\Big)^{2}}\\sqrt{D_{\\widehat{\\mathcal{F}}_{h}}^{2}\\left(z_{i,h};z_{\\lfloor i-1\\rfloor,h},\\bar{\\sigma}_{\\lfloor i-1\\rfloor,h}\\right)\\left(\\sum_{\\tau\\in[k-1]}\\frac{\\widehat{\\mathbb{f}}_{\\tau,h}}{\\left(\\overline{{\\sigma}}_{\\tau,h}\\right)^{2}}\\left(f\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)-\\bar{f}\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)\\right)^{2}+\\lambda\\right)}}\\\\ &{\\le4\\cdot\\gamma^{-2}\\sqrt{\\displaystyle\\sum_{\\tau\\in[k-1]}\\frac{\\widehat{\\mathbb{f}}_{\\tau,h}}{\\left(\\overline{{\\sigma}}_{\\tau,h}\\right)^{2}}\\left(f\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)-\\bar{f}\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)\\right)^{2}+\\lambda,}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the second inequality follows from the definition of $\\mathcal{D}_{\\mathcal{F}_{h}}$ in Definition 2.4, the last inequality holdsince $\\bar{\\sigma}_{i,h}\\geq\\gamma\\cdot D_{\\mathcal{F}_{h}}^{1/2}\\big(z_{i,h};z_{[i-1],h},\\bar{\\sigma}_{[i-1],h}\\big)$ acording t line 1 in Agortm 1. rom the definition of $\\widehat{\\mathbb{1}}_{i,h}$ in (D.6) we directly obtain the following upper bound of the variance: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in[k-1]}\\mathbb{E}\\left[\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{4}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\cdot\\widehat{\\eta}_{h}^{i}(V_{h+1}^{*})^{2}\\right]}\\\\ &{\\displaystyle\\leq4\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\leq4L^{2}k/\\alpha^{2}:=V.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Applying Lemma H.2 with $V=4L^{2}k/\\alpha^{2}$ $M=2L/\\alpha^{2}$ and $v=m=1$ , for fixed $f,\\,{\\bar{f}},\\,k$ , with probability at least $1-\\delta/(2k^{2}\\cdot N_{\\mathcal{F}}(\\epsilon)\\stackrel{\\cdot}{\\cdot}H)$ \uff0c ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{h+1}^{*})}\\\\ &{\\le\\displaystyle\\nu\\sqrt{2\\left(8\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}+1\\right)}}\\\\ &{\\quad+\\displaystyle\\frac{2}{3}\\iota^{2}\\left(8\\gamma^{-2}\\sqrt{\\sum_{\\tau\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{\\tau,h}}{(\\overline{{\\sigma}}_{\\tau,h})^{2}}\\left(f(s_{h}^{\\tau},a_{h}^{\\tau})-\\bar{f}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda}+1\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\leq\\left(4\\iota+\\frac{16}{3}\\iota^{2}\\gamma^{-2}\\right)\\sqrt{\\sum_{\\tau\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{\\tau,h}}{(\\bar{\\sigma}_{\\tau,h})^{2}}\\left(f(s_{h}^{\\tau},a_{h}^{\\tau})-\\bar{f}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda}+\\sqrt{2}\\iota+\\frac{2}{3}\\iota^{2},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$\\begin{array}{r}{\\iota:=\\iota_{1}(k,h,\\delta)=\\sqrt{\\log\\frac{2k^{2}\\left(2\\log(\\frac{4L^{2}k}{\\alpha^{2}})+2\\right)\\cdot\\left(\\log(\\frac{4L}{\\alpha^{2}})+2\\right)\\cdot N_{\\mathcal{F}}(\\epsilon)}{\\delta/H}}.}\\end{array}$ ", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Using a union bound across all $f,\\bar{f}\\in\\mathcal{C}(\\mathcal{F}_{h},\\epsilon)$ and $k\\geq1$ , with probability at least $1-\\delta/H$ \uff0c ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{\\big(\\overline{{\\sigma}}_{i,h}\\big)^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{h+1}^{*})}\\\\ &{\\leq\\left(4\\iota+\\frac{16}{3}\\iota^{2}\\gamma^{-2}\\right)\\sqrt{\\displaystyle\\sum_{\\tau\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{\\tau,h}}{(\\overline{{\\sigma}}_{\\tau,h})^{2}}\\left(f(s_{h}^{\\tau},a_{h}^{\\tau})-\\bar{f}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda}+\\sqrt{2}\\iota+\\frac{2}{3}\\iota^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "holds for all $f,\\bar{f}\\in\\mathcal{C}(\\mathcal{F}_{h},\\epsilon)$ and $k$ . Due to the definition of $\\epsilon$ -net, we deduce that for $\\widehat{f}_{k,h}$ and $\\hat{f}_{k}^{*}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n-\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widehat{f}_{k,h}(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{h+1}^{*})\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\leq\\left(4\\iota+\\frac{16}{3}\\iota^{2}\\gamma^{-2}\\right)\\sqrt{\\underset{\\tau\\in[k-1]}{\\sum}\\frac{\\widehat{\\mathbb{1}}_{\\tau,h}}{(\\overline{{\\sigma}}_{\\tau,h})^{2}}\\left(\\widehat{f}_{k,h}(s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat{f}_{k}^{*}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda}+\\sqrt{2}\\iota+\\frac{2}{3}\\iota^{2}}\\\\ &{\\quad+\\left(4\\iota+\\frac{16}{3}\\iota^{2}\\gamma^{-2}\\right)\\sqrt{16k\\epsilon L/\\alpha^{2}}+8\\epsilon k/\\alpha^{2}.}&{()}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "For the second term in (F.6), the following inequality holds for all $V\\in\\mathcal{V}_{k,h+1}$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\left[\\frac{1}{(\\tilde{\\sigma}_{i},h_{h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\tilde{\\eta}_{h}^{i}(V-V_{h+1}^{*})\\right]=0,}\\\\ &{\\underset{i\\in\\mathbb{K}^{1}\\times1}{\\operatorname*{max}}\\left|\\left(\\frac{1}{\\tilde{\\sigma}_{i,h}}\\right)\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\tilde{\\eta}_{h}^{i}(V-V_{h+1}^{*})\\right|}\\\\ &{\\leq4\\underset{i\\in\\mathbb{K}^{1}\\times1}{\\operatorname*{max}}\\left|\\left(\\frac{1}{\\tilde{\\sigma}_{i,h}}\\right)\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\right|}\\\\ &{\\leq4\\underset{i\\in\\mathbb{K}^{1}\\times1}{\\operatorname*{max}}\\frac{1}{\\left(\\tilde{\\sigma}_{i,h}\\right)^{2}}\\sqrt{\\mathcal{D}_{\\mathcal{F}_{h}}^{2}\\left(z_{i,h};z_{\\{i-1\\},h},\\bar{\\sigma}_{\\lfloor i-1\\}\\rfloor,h\\right)\\underset{\\tau\\in[\\mathbb{K}^{1}]}{\\sum}\\frac{1}{\\left(\\tilde{\\sigma}_{\\tau,h}\\right)^{2}}\\left(f(s_{h}^{\\tau},a_{h}^{\\tau})-\\bar{f}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda}}\\\\ &{=4\\cdot\\gamma^{-2}\\sqrt{\\underset{\\tau\\in[\\mathbb{K}^{1}]}{\\sum}\\frac{1}{(\\tilde{\\sigma}_{\\tau,h})^{2}}\\left(f(s_{h}^{\\tau},a_{h}^{\\tau})-\\bar{f}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the calculation is similar to that in (F.7). ", "page_idx": 29}, {"type": "text", "text": "We denote the sum of variance by $\\operatorname{Var}(V-V_{h+1}^{*})$ as follows for simplicity: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}(V-V_{h+1}^{*}):=\\displaystyle\\sum_{i\\in[k-1]}\\mathbb{E}\\left[\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{4}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\cdot\\widehat{\\eta}_{h}^{i}(V-V_{h+1}^{*})^{2}\\right]}\\\\ &{\\qquad\\qquad\\qquad\\leq k\\cdot L^{2}/\\alpha^{4}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "For $V_{k,h+1}$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Var}(V_{k,h+1}-V_{h+1}^{*}):=\\displaystyle\\sum_{i\\in[k-1]}\\mathbb{E}\\left[\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{4}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\cdot\\widehat{\\eta}_{h}^{i}(V_{k,h+1}-V_{h+1}^{*})^{2}\\right]}\\\\ {\\le\\displaystyle\\frac{4}{\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K)}\\sum_{i\\in[k-1]}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the second inequality holds due to the definition of $\\widehat{\\mathbb{1}}_{i,h}$ in (D.6) ", "page_idx": 29}, {"type": "text", "text": "With a similar argument as shown in $(\\mathrm{F.8}){\\sim}(\\mathrm{F.}12)$ , we have with probability at least $1-\\delta/(2k^{2}\\cdot$ $N_{\\mathcal{F}}(\\epsilon)\\cdot N_{\\epsilon}(k-1)\\cdot H)$ , for a fixed $f,{\\bar{f}},\\,l$ $k$ and $V$ , (applying Lemma H.2, with $V=k\\cdot L^{2}/\\alpha^{4}$ and $M=2L/\\alpha^{2}$ \uff0c $v=(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))^{-1/2}$ \uff0c $m=v^{2}$ \uff09 ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat\\mathbb{1}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(f(s_{h}^{i},a_{h}^{i})-\\bar{f}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{k,h+1}-V_{h+1}^{*})}\\\\ &{\\leq\\iota\\sqrt{2\\left(2\\mathrm{Var}(V-V_{h+1}^{*})+\\left(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K)\\right)^{-1}\\right)}}\\\\ &{+\\displaystyle\\frac{2}{3}\\iota^{2}\\left(8\\gamma^{-2}\\sqrt{\\displaystyle\\sum_{\\tau\\in[k-1]}\\frac{\\widehat\\mathbb{1}_{\\tau,h}}{(\\bar{\\sigma}_{\\tau,h})^{2}}\\left(f(s_{h}^{\\tau},a_{h}^{\\tau})-\\bar{f}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda+\\left(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K)\\right)^{-1}\\right)}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\log\\frac{2k^{2}\\left(2\\log\\frac{L^{2}k(\\log N_{\\mathcal{F}}(\\epsilon)\\cdot N_{\\epsilon}(K))^{1/2}}{\\alpha^{4}}+2\\right)\\cdot\\left(\\log(\\frac{4L(\\log N_{\\mathcal{F}}(\\epsilon)\\cdot N_{\\epsilon}(K))}{\\alpha^{2}})+2\\right)\\cdot N_{\\mathcal{F}}(\\epsilon)\\cdot N_{\\epsilon}(k)}{\\delta/H}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\n\\leq\\log\\frac{2k^{2}\\left(2\\log\\frac{L^{2}k}{\\alpha^{4}}+2\\right)\\cdot\\left(\\log(\\frac{4L}{\\alpha^{2}})+2\\right)\\cdot N_{\\mathcal{F}}^{4}(\\epsilon)\\cdot N_{\\epsilon}^{2}(K)}{\\delta/H}:=\\iota_{2}^{2}(k,h,\\delta).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Using a union bound over all $(f,\\bar{f},V)\\in\\mathcal{C}(\\mathcal{F}_{h},\\epsilon)\\times\\mathcal{C}(\\mathcal{F}_{h},\\epsilon)\\times\\mathcal{V}_{k,h+1}^{c}$ and all $k\\geq1$ we have the inequality above holds for all such $f,{\\bar{f}},V,k$ with probability at least $1-\\delta/H$ ", "page_idx": 30}, {"type": "text", "text": "There exists a $V_{k,h+1}^{c}$ in the $\\epsilon$ -net such that $\\|V_{k,h+1}-V_{k,h+1}^{c}\\|_{\\infty}\\leq\\epsilon.$ Then we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\displaystyle\\sum_{i\\in[k-1]}\\frac{\\widehat{\\Omega}_{i,h}}{(\\check{\\sigma}_{i,h})^{2}}\\left(\\widehat{f}_{k,h}(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)\\cdot\\widehat{\\eta}_{h}^{i}(V_{k,h+1}-V_{h+1}^{*})}\\\\ &{\\leq O\\left(\\displaystyle\\frac{t_{2}(k,h,\\delta)}{\\sqrt{\\log N_{F}(\\epsilon)+\\log N_{\\epsilon}(K)}}+\\frac{t_{2}(k,h,\\delta)^{2}}{\\gamma^{-2}}\\right)}\\\\ &{\\cdot\\displaystyle\\sqrt{\\sum_{\\tau\\in[k-1]}\\frac{\\widehat{\\Omega}_{\\tau,h}}{(\\bar{\\sigma}_{\\tau,h})^{2}}\\left(\\widehat{f}_{k,h}(s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat{f}_{k}^{*}(s_{h}^{\\tau},a_{h}^{\\tau})\\right)^{2}+\\lambda}}\\\\ &{+O(\\epsilon k L/\\alpha)^{2})+O\\left(\\frac{\\iota_{2}^{2}(k,h,\\delta)}{\\log N_{F}(\\epsilon)+\\log N_{\\epsilon}(K)}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "for all $k$ with at least probability $1-\\delta/H$ ", "page_idx": 30}, {"type": "text", "text": "Substituting (F.15) and (F.12) into (F.5), we can conclude that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\<[k-1]}\\frac{\\widehat{\\mathbb{1}}_{i,h}}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widehat f_{k,h}(s_{h}^{i},a_{h}^{i})-\\widehat f_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}}\\\\ &{\\le O\\left(\\left(\\frac{\\iota_{2}(k,h,\\delta)}{\\sqrt{\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\mathcal{\\epsilon}}(K)}}+\\iota_{2}(k,h,\\delta)^{2}\\cdot\\gamma^{-2}\\right)^{2}\\right)+O\\left(\\left(\\iota_{1}(k,h,\\delta)+\\iota_{1}(k,h,\\delta)^{2}/\\gamma^{2}\\right)^{2}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "From the definition of $\\gamma$ in (3.3), we can rewrite the upper bound of the squared loss ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\lambda+\\underset{i\\in[k-1]}{\\sum}\\frac{\\widehat{\\mathbb{I}}_{i,h}}{(\\overline{{\\sigma}}_{i,h})^{2}}\\left(\\widehat{f}_{k,h}(s_{h}^{i},a_{h}^{i})-\\widehat{f}_{k}^{*}(s_{h}^{i},a_{h}^{i})\\right)^{2}}\\\\ &{\\leq O\\left(\\log\\frac{2k^{2}\\left(2\\log\\frac{L^{2}k}{\\alpha^{4}}+2\\right)\\cdot\\left(\\log(\\frac{4L}{\\alpha^{2}})+2\\right)}{\\delta/H}\\right)\\cdot\\left[\\log(N_{\\mathcal{F}}(\\epsilon))+1\\right]+O(\\lambda)+O(\\epsilon k L/\\alpha^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof of Lemma D.5. The proof is almost identical to the proof of Lemma D.4. ", "page_idx": 30}, {"type": "text", "text": "F.2 Proof of Optimism and Pessimism ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "F.2.1 Proof of Lemma D.6 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Proof of Lemma D.6. According to the definition of $D_{\\mathcal{F}}^{2}$ function, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl(\\widehat f_{k,h}(s,a)-\\mathcal{T}_{h}V_{k,h+1}(s,a)\\bigr)^{2}}\\\\ &{\\leq D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\times\\left(\\lambda+\\displaystyle\\sum_{i=1}^{k-1}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widehat f_{k,h}(s_{h}^{i},a_{h}^{i})-\\mathcal{T}_{h}V_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\right)}\\\\ &{\\leq\\widehat\\beta_{k}^{2}\\times D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where the first inequality holds due the definition of $D_{\\mathcal{F}}^{2}$ function with the Assumption 2.2 and the second inequality holds due to the events $\\mathcal{E}_{h}^{\\hat{f}}$ Thus, we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widehat{f}_{k,h}(s,a)-7\\!\\!\\!\\slash_{\\!\\!\\:}V_{k,h+1}(s,a)\\right|\\leq\\widehat{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "With a similar argument, for the pessimistic value function $\\widecheck{f}_{k,h}$ ,wehave ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(\\check{f}_{k,h}(s,a)-{\\mathcal T}_{h}\\check{V}_{k,h}(s,a)\\right)^{2}}\\\\ &{\\leq D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\times\\left(\\lambda+\\displaystyle\\sum_{i=1}^{k-1}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\check{f}_{k,h}(s_{h}^{i},a_{h}^{i})-{\\mathcal T}_{h}\\check{V}_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\right)}\\\\ &{\\leq\\check{\\beta}_{k}^{2}\\times D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the first inequality holds due to the definition of $D_{\\mathcal{F}}^{2}$ function with the Assumption 2.2 and the second inequality holds due to the events $\\mathcal{E}_{h}^{\\breve{f}}$ . In addition, we have, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\check{f}_{k,h}(s,a)-\\mathcal{T}_{h}\\check{V}_{k,h+1}(s,a)\\right|\\leq\\widehat{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Thus, we complete the proof of Lemma D.6. ", "page_idx": 31}, {"type": "text", "text": "F.2.2 Proof of Lemma D.7 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Proof of Lemma $D.7.$ We use induction to prove the optimistic and pessimistic property. First, we study the basic case with the last stage $H+1$ .In this situation, $Q_{k,H+1}(s,\\stackrel{.}{a})\\ =\\ \\dot{Q}_{h}^{*}(s,a)\\ =$ $\\check{Q}_{k,h}(s,a)\\,=\\,0$ and $V_{k,h}(s)=V_{h}^{*}(s)=\\check{V}_{k,h}(s)=0$ hold for all state $s\\,\\in\\,S$ and action $a\\in{\\mathcal{A}}$ Therefore, Lemma D.7 holds for the basic case (stage $H+1)$ ", "page_idx": 31}, {"type": "text", "text": "Second, if Lemma D.7 holds for stage $h+1$ , then we focus on the stage $h$ . Notice that the event $\\widetilde{\\mathcal{E}}_{h}$ directly implies the event $\\widetilde{\\mathcal{E}}_{h+1}$ Therefore, according to the induction assumption, the following inequality holds for all state $s\\in S$ and episode $k\\in[K]$ ", "page_idx": 31}, {"type": "equation", "text": "$$\nV_{k,h+1}(s)\\geq V_{h+1}^{*}(s)\\geq\\breve{V}_{k,h}(s).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Thus, for all episode $k\\in[K]$ and state-action pair $(s,a)\\in S\\times A$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{f}_{k,h}(s,a)+b_{k,h}(s,a)-Q_{h}^{*}(s,a)}\\\\ &{\\geq\\mathcal{T}_{h}V_{k,h+1}(s,a)-\\widehat{\\beta}_{k}\\cdot D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})+b_{k,h}(s,a)-Q_{h}^{*}(s,a)}\\\\ &{\\geq\\mathcal{T}_{h}V_{k,h+1}(s,a)-Q_{h}^{*}(s,a)}\\\\ &{=\\mathbb{P}_{h}V_{k,h+1}(s,a)-\\mathbb{P}_{h}V_{h}^{*}(s,a)}\\\\ &{\\geq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the first inequality holds due to Lemma D.6, the second inequality holds due to the definition of the exploration bonus $b_{k,h}$ and the last inequality holds due to the (F.16). Therefore, the optimal value function $Q_{h}^{*}(s,a)$ is upper bounded by ", "page_idx": 31}, {"type": "equation", "text": "$$\nQ_{h}^{*}(s,a)\\leq\\operatorname*{min}\\Big\\{\\operatorname*{min}_{1\\leq i\\leq k}\\widehat{f}_{i,h}(s,a)+b_{i,h}(s,a),1\\Big\\}\\leq Q_{k,h}(s,a),\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the first inequality holds due to (F.17) with the fact that $Q_{h}^{*}(s,a)\\leq1$ and the second inequality holds due to the update rule of value function $Q_{k,h}$ ", "page_idx": 31}, {"type": "text", "text": "With a similar argument, for the pessimistic estimator $\\widecheck{f}_{k,h}$ ,wehave ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\check{f}_{k,h}(s,a)-b_{k,h}(s,a)-Q_{h}^{*}(s,a)}\\\\ &{\\leq{\\mathcal{T}}_{h}\\check{V}_{k,h+1}(s,a)+\\check{\\beta}_{k}\\cdot{\\cal D}_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})-b_{k,h}(s,a)-Q_{h}^{*}(s,a)}\\\\ &{\\leq{\\mathcal{T}}_{h}\\check{V}_{k,h+1}(s,a)-Q_{h}^{*}(s,a)}\\\\ &{={\\mathbb{P}}_{h}\\check{V}_{k,h+1}(s,a)-{\\mathbb{P}}_{h}V_{h}^{*}(s,a)}\\\\ &{\\leq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the first inequality holds due to Lemma D.6, the second inequality holds due to the definition of the exploration bonus $b_{k,h}$ and the last inequality holds due to the (F.19). Therefore, the optimal value function $Q_{h}^{*}(s,a)$ is lowerbounded by ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q_{h}^{*}(s,a)\\geq\\operatorname*{max}\\Big\\{\\underset{1\\leq i\\leq k}{\\operatorname*{max}}\\breve{f}_{i,h}(s,a)-b_{i,h}(s,a),0\\Big\\}\\geq\\breve{Q}_{k,h}(s,a),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality holds due to (F.19) with the fact that $Q_{h}^{*}(s,a)\\geq0$ and the second inequality holds due to the update rule of value function $\\check{Q}_{k,h}$ ", "page_idx": 32}, {"type": "text", "text": "Furthermore, for the value functions $V_{k,h}$ and $\\check{V}_{\\boldsymbol{k},h}$ ,we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{k,h}(s)=\\displaystyle\\operatorname*{max}_{a}Q_{k,h}(s,a)\\geq\\displaystyle\\operatorname*{max}_{a}Q_{h}^{*}(s,a)=V_{h}^{*}(s),}\\\\ &{\\check{V}_{k,h}(s)=\\displaystyle\\operatorname*{max}_{a}\\check{Q}_{k,h}(s,a)\\leq\\displaystyle\\operatorname*{max}_{a}Q_{h}^{*}(s,a)=V_{h}^{*}(s),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality holds due to (F.18) and the second inequality holds due to (F.20). Thus, by induction, we complete the proof of Lemma D.7. \u53e3 ", "page_idx": 32}, {"type": "text", "text": "F.3Proof of Monotonic Variance Estimator ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "F.3.1 Proof of Lemma D.8 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Proof of Lemma D.8. According to the definition of $D_{\\mathcal{F}}^{2}$ function, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl(\\widehat f_{k,h}(s,a)-\\mathcal{T}_{h}V_{k,h+1}(s,a)\\bigr)^{2}}\\\\ &{\\leq D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\times\\left(\\lambda+\\displaystyle\\sum_{i=1}^{k-1}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widehat f_{k,h}(s_{h}^{i},a_{h}^{i})-\\mathcal{T}_{h}V_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\right)}\\\\ &{\\leq\\beta_{k}^{2}\\times D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality holds due the definition of $D_{\\mathcal{F}}^{2}$ function with the Assumption 2.2 and the second inequality holds due to the events $\\mathcal{E}^{\\hat{f}}$ .Thus, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widehat{f}_{k,h}(s,a)-7\\!\\!\\!\\slash_{\\!\\!\\!h}V_{k,h+1}(s,a)\\right|\\leq\\beta_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "For the pessimistic value function $\\widecheck{f}_{k,h}$ ,we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(\\check{f}_{k,h}(s,a)-{\\mathcal T}_{h}\\check{V}_{k,h}(s,a)\\right)^{2}}\\\\ &{\\leq D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\times\\left(\\lambda+\\displaystyle\\sum_{i=1}^{k-1}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\check{f}_{k,h}(s_{h}^{i},a_{h}^{i})-{\\mathcal T}_{h}\\check{V}_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\right)}\\\\ &{\\leq\\beta_{k}^{2}\\times D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality holds due the definition of $D_{\\mathcal{F}}^{2}$ function with the Assumption 2.2 and the second inequality holds due to the events $\\underline{{\\mathcal{E}}}^{\\widecheck{f}}$ . In addition, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\check{f}_{k,h}(s,a)-\\mathcal{T}_{h}\\check{V}_{k,h+1}(s,a)\\right|\\leq\\beta_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "With a similar argument, for the second-order estimator $\\widetilde{f}_{k,h}$ ,wehave ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(\\widetilde{f}_{k,h}(s,a)-T_{h}^{2}V_{k,h}(s,a)\\right)^{2}}\\\\ &{\\leq D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\times\\left(\\lambda+\\displaystyle\\sum_{i=1}^{k-1}\\frac{1}{(\\bar{\\sigma}_{i,h})^{2}}\\left(\\widetilde{f}_{k,h}(s_{h}^{i},a_{h}^{i})-T_{h}^{2}V_{k,h+1}(s_{h}^{i},a_{h}^{i})\\right)^{2}\\right)}\\\\ &{\\leq\\widetilde{\\beta}_{k}^{2}\\times D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality holds due the definition of $D_{\\mathcal{F}}^{2}$ function with the Assumption 2.2 and the second inequality holds due to the events $\\mathcal{E}^{\\widetilde{f}}$ . Therefore, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\widetilde{f}_{k,h}(s,a)-{\\mathcal T}_{h}^{2}V_{k,h}(s,a)\\right|\\le\\widetilde{\\beta}_{k}D_{{\\mathcal F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Now, we complete the proof of Lemma D.8. ", "page_idx": 32}, {"type": "text", "text": "F.3.2 Proof of Lemma D.9 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Proof of Lemma D.9. First, according to Lemma D.8, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big|\\big|\\bar{\\Psi}_{h}V_{k,h+1}\\big|\\big(s_{h}^{k},a_{h}^{k}\\big)-\\big[\\Psi_{h}V_{k,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big|}\\\\ &{=\\Big|\\widetilde{f}_{k,h}-\\widehat{f}_{k,h}^{2}-\\big[\\mathbb{P}_{h}V_{k,h+1}^{2}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)+\\big(\\big[\\mathbb{P}_{h}V_{k,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big)^{2}\\Big|}\\\\ &{\\leq\\Big|\\widehat{f}_{k,h}^{2}-\\big(\\big[\\mathbb{P}_{h}V_{k,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big)^{2}\\Big|+\\big|\\widetilde{f}_{k,h}-\\big[\\mathbb{P}_{h}V_{k,h+1}^{2}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big|}\\\\ &{\\leq2L\\Big|\\widehat{f}_{k,h}-\\big(\\big[\\mathbb{P}_{h}V_{k,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big)\\Big|+\\big|\\widetilde{f}_{k,h}-\\big[\\mathbb{P}_{h}V_{k,h+1}^{2}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big|}\\\\ &{\\leq\\big(2L\\beta_{k}+\\widetilde{\\beta}_{k}\\big)D_{\\mathcal{F}_{h}}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big)}\\\\ &{=E_{k,h},}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the first inequality holds due to $|a+b|\\,\\leq\\,|a|+|b|$ , the second inequality holds due to $|a^{2}-b^{2}|=|a-b|\\,\\bar{\\cdot}\\,|a+b|\\leq|a-b|\\cdot2\\operatorname*{max}(|a|,|b|)$ and the last inequalirtnholds due to Lemma D.8. ", "page_idx": 33}, {"type": "text", "text": "For the difference between variances $[\\mathbb{V}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})$ and $[\\mathbb{V}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})$ , it can be upper bounded by ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big|[\\mathbb{V}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{V}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})\\big|}\\\\ &{=\\Big|[\\mathbb{P}_{h}V_{k,h+1}^{2}](s_{h}^{k},a_{h}^{k})-\\big([\\mathbb{P}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})\\big)^{2}-[\\mathbb{P}_{h}(V_{h+1}^{*})^{2}](s_{h}^{k},a_{h}^{k})+\\big([\\mathbb{P}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})\\big)^{2}\\Big|}\\\\ &{\\le\\big|[\\mathbb{P}_{h}V_{k,h+1}^{2}](s_{h}^{k},a_{h}^{k})-[\\mathbb{P}_{h}(V_{h+1}^{*})^{2}](s_{h}^{k},a_{h}^{k})\\big|+\\Big|\\big([\\mathbb{P}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})\\big)^{2}-\\big([\\mathbb{P}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})\\big)^{2}}\\\\ &{\\le4\\big([\\mathbb{P}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{P}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})\\big)}\\\\ &{\\le\\big([\\mathbb{P}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{P}_{h}\\check{V}_{k,h+1}](s_{h}^{k},a_{h}^{k})\\big)}\\\\ &{\\le\\widehat f_{k,h}(s_{h}^{k},a_{h}^{k})-\\check{f}_{k,h}(s_{h}^{k},a_{h}^{k})+2\\beta_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the first inequality holds due to $|a+b|\\,\\leq\\,|a|+|b|$ , the second inequality holds due to $1\\geq V_{k,h+1}(\\cdot)\\geq V_{h+1}^{*}(\\cdot)\\geq0$ (Lemma D.7), the third inequality holds due to $\\bar{V}_{h+1}^{*}(\\cdot)\\geq\\check{V}_{k,h+1}(\\cdot)$ (Lemma D.7) and the last inequality holds due to Lemma D.8. Combining the results in (F.21) and (F.22) with the fact that $0\\leq V_{k,h+1}(\\cdot),V_{h+1}^{*}(\\cdot)\\leq1$ wehave ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|[\\bar{\\mathbb{V}}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{V}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})\\right|}\\\\ &{\\le\\left|[\\bar{\\mathbb{V}}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{V}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})\\right|+\\left|[\\mathbb{V}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{V}_{h}V_{h+1}^{*}](s_{h}^{k},a_{h}^{k})\\right|}\\\\ &{\\le E_{k,h}+F_{k,h}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Thus, we complete the proof of Lemma D.9. ", "page_idx": 33}, {"type": "text", "text": "F.3.3Proof of Lemma D.10 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Proof of Lemma $D.I O$ . On the events $\\underline{{\\mathcal{E}}}^{\\hat{f}}$ and $\\mathcal{E}_{h+1}^{\\hat{f}}$ h+1, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big[\\mathbb{V}_{h}\\big(V_{i,h+1}-V_{h+1}^{*}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ &{=\\big[\\mathbb{P}_{h}\\big(V_{i,h+1}-V_{h+1}^{*}\\big)^{2}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)-\\big(\\big[\\mathbb{P}_{h}\\big(V_{i,h+1}-V_{h+1}^{*}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big)^{2}}\\\\ &{\\le\\big[\\mathbb{P}_{h}\\big(V_{i,h+1}-V_{h+1}^{*}\\big)^{2}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ &{\\le2\\big[\\mathbb{P}_{h}\\big(V_{i,h+1}-V_{h+1}^{*}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ &{\\le2\\big(\\big[\\mathbb{P}_{h}V_{i,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)-\\big[\\mathbb{P}_{h}\\check{V}_{k,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big)}\\\\ &{\\le2\\big(\\big[\\mathbb{P}_{h}V_{k,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)-\\big[\\mathbb{P}_{h}\\check{V}_{k,h+1}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the first equation holds since the reward function is deterministic, the second inequality holds due to Lemma D.7 with the fact that $0\\leq V_{i,h+1}(s),V_{h+1}^{*}(s)\\leq_{-}1$ and the third inequality holds due to Lemma D.7 and the last inequality holds due to the fact that $V_{k,h+1}\\geq V_{i,h+1}$ ", "page_idx": 33}, {"type": "text", "text": "With a similar argument, on the events & and Ef $\\mathscr{E}_{h+1}^{\\check{f}}$ h+1, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big[\\mathbb{V}_{h}\\big(V_{h+1}^{*}-\\check{V}_{i,h+1}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ &{=\\big[\\mathbb{P}_{h}\\big(V_{h+1}^{*}-\\check{V}_{i,h+1}\\big)^{2}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)-\\big(\\big[\\mathbb{P}_{h}\\big(V_{h+1}^{*}-\\check{V}_{i,h+1}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big)^{2}}\\\\ &{\\leq\\big[\\mathbb{P}_{h}\\big(V_{h+1}^{*}-\\check{V}_{i,h+1}\\big)^{2}\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ &{\\leq2\\big[\\mathbb{P}_{h}\\big(V_{h+1}^{*}-\\check{V}_{i,h+1}\\big)\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ &{\\leq2\\big([\\mathbb{P}_{h}V_{k,h+1}]\\big(s_{h}^{k},a_{h}^{k}\\big)-[\\mathbb{P}_{h}\\check{V}_{i,h+1}]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big)}\\\\ &{\\leq2\\big([\\mathbb{P}_{h}V_{k,h+1}]\\big(s_{h}^{k},a_{h}^{k}\\big)-[\\mathbb{P}_{h}\\check{V}_{k,h+1}]\\big(s_{h}^{k},a_{h}^{k}\\big)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the first inequality holds since the reward function is deterministic, the second and third inequality holds due to Lemma D.7 with the fact that $0\\;\\leq\\;\\check{V}_{i,h+1}(s),V_{h+1}^{*}(s)\\;\\leq\\;H$ the last inequality the fact $\\check{V}_{k,h+1}(s)\\le\\check{V}_{i,h+1}(s)$ . For both variances $\\left[\\mathbb{V}_{h}(V_{i,h+1}-V_{h+1}^{*})\\right](s_{h}^{k},a_{h}^{k})$ and $\\left[\\mathbb{V}_{h}(V_{h+1}^{*}-\\check{V}_{i,h+1})\\right](s_{h}^{k},a_{h}^{k})$ they are upper bounded by ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2\\big([\\mathbb{P}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{P}_{h}\\check{V}_{k,h+1}](s_{h}^{k},a_{h}^{k})\\big)}\\\\ &{\\ =2\\mathcal{T}_{h}V_{k,h+1}(s_{h}^{k},a_{h}^{k})-2\\mathcal{T}_{h}\\check{V}_{k,h+1}\\big(s_{h}^{k},a_{h}^{k}\\big)}\\\\ &{\\ \\le2\\widehat{f}_{k,h}\\big(s_{h}^{k},a_{h}^{k}\\big)-2\\check{f}_{k,h}\\big(s_{h}^{k},a_{h}^{k}\\big)+4\\beta_{k}D_{\\mathcal{F}_{h}}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the first inequality holds due to Lemma D.8 and the second inequality holds due to the definitionof $F_{k,h}$ . Substituting the result in (F.25) into (F.23), (F.24) and combining the fact that $\\left[\\mathbb{V}_{h}(V_{i,h+1}-V_{h+1}^{*})\\right](s_{h}^{k},a_{h}^{k})$ $\\left[\\mathbb{V}_{h}(V_{h+1}^{*}-\\check{V}_{i,h+1})\\right](s_{h}^{k},a_{h}^{k})\\le1$ , we finish the proof of Lemma D.10. \u53e3 ", "page_idx": 34}, {"type": "text", "text": "F.4Proof of Lemmas in Section D.4 ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "F.4.1 Proof of Lemma D.11 ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Proof of Lemma D.1l. We use induction to shows that the conclusion in Lemma D.7 and events $\\mathcal{E}_{h}^{\\hat{f}},\\mathcal{E}_{H}^{\\breve{f}}$ hold for ach stage $h\\in[H]$ Frst forthe ai situatio (tage $H+1;$ \uff0c $Q_{k,H+1}(s,a)=$ $\\begin{array}{r}{\\ddot{Q_{h}^{*}}(s,a)=\\check{Q}_{k,h}(s,a)=0}\\end{array}$ and $V_{k,h}(s)=V_{h}^{*}(s)=\\check{V}_{k,h}(s)=0$ hold for all state $s\\in S$ and action $a\\in A$ . Therefore, Lemma D.7 holds for the basic case (stage $H+1$ ", "page_idx": 34}, {"type": "text", "text": "Second, if Lemma D.7 holds for stage $h+1$ , then we focus on the stage $h$ . According to Lemmas D.10 and Lemma D.9, we have the following inequalities: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{i,h}^{2}=[\\bar{\\mathbb{V}}_{h}V_{i,h+1}](s_{h}^{i},a_{h}^{i})+E_{i,h}+D_{i,h}\\geq[\\bar{\\mathbb{V}}_{h}V_{h+1}^{*}](s_{h}^{i},a_{h}^{i}),}\\\\ &{\\sigma_{i,h}^{2}\\geq F_{i,h}\\geq(\\log N_{\\mathscr{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\cdot\\big[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{*})\\big](s_{h}^{i},a_{h}^{i}),}\\\\ &{\\sigma_{i,h}^{2}\\geq F_{i,h}\\geq(\\log N_{\\mathscr{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\cdot\\big[\\mathbb{V}_{h}(V_{h+1}^{*}-\\check{V}_{k,h+1})\\big](s_{h}^{i},a_{h}^{i}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the first inequality holds due to Lemma D.9, the second and third inequality holds due to Lemma D.1. Thus, the indicator function in events $\\bar{\\mathcal{E}}_{h}^{\\hat{f}}$ and $\\bar{\\mathcal{E}}_{h}^{\\breve{f}}$ hold, whih implies events $\\mathcal{E}_{h}^{\\tilde{f}},\\mathcal{E}_{H}^{\\check{f}}$ hold. Furthermore, when events &f, $\\mathcal{E}_{H}^{\\widecheck{f}}$ hold, then Lemma D.7 holds for stage $h$ . Thus, we complete the proof of Lemma D.11 by induction. \u53e3 ", "page_idx": 34}, {"type": "text", "text": "F.4.2 Proof of Lemma D.13 ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Proof of Lemma $D.13$ . For each stage $h$ , we divide the episodes $\\{1,2,..,K\\}$ to the following sets: ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Z_{1}=\\{k\\in[K]:D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}\\geq1\\},}\\\\ &{Z_{2}=\\{k\\in[K]:D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}<1,\\bar{\\sigma}_{k,h}=\\sigma_{k,h}\\},}\\\\ &{Z_{3}=\\{k\\in[K]:D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}<1,\\bar{\\sigma}_{k,h}=\\alpha\\},}\\\\ &{Z_{4}=\\{k\\in[K]:D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}<1,\\bar{\\sigma}_{k,h}=\\gamma\\times D_{\\mathcal{F}_{h}}^{1/2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The number of episode in set ${\\mathcal{T}}_{1}$ is upper bounded by ", "page_idx": 35}, {"type": "equation", "text": "$$\n|\\mathcal{Z}_{1}|=\\sum_{k\\in\\mathbb{Z}_{1}}\\operatorname*{min}\\Big(D_{\\mathcal{F}_{h}}^{2}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big)/\\bar{\\sigma}_{k,h}^{2},1\\Big)\\le\\mathrm{dim}_{\\alpha,K}(\\mathcal{F}_{h}),\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the equation holds due to $D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}^{2}\\geq1$ and the inequality holds due to the definition of Generalized Eluder dimension. Thus, for set $\\mathcal{T}_{1}$ , the summation of confidence radius is upper bounded by ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathbb{Z}_{1}}\\operatorname*{min}\\Big(\\beta D_{\\mathcal{F}_{h}}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big),1\\Big)\\leq|\\mathbb{Z}_{1}|\\leq\\mathrm{dim}_{\\alpha,K}\\big(\\mathcal{F}_{h}\\big).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "For set $\\mathcal{T}_{2}$ , the summation of confidence radius is upper bounded by ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k\\in\\mathbb{Z}_{2}}\\operatorname*{min}\\left(\\beta D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),1\\right)}\\\\ &{\\le\\displaystyle\\sum_{k\\in\\mathbb{Z}_{2}}\\beta D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})}\\\\ &{\\le\\displaystyle\\beta\\sqrt{\\sum_{k\\in\\mathbb{Z}_{2}}\\sigma_{k,h}^{2}}\\cdot\\sqrt{\\sum_{k\\in\\mathbb{Z}_{2}}D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}^{2}}}\\\\ &{\\le\\beta\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F}_{h})}\\sqrt{\\sum_{k\\in\\mathbb{Z}_{2}}\\sigma_{k,h}^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the second inequality holds due to Cauchy-Schwartz inequality with $\\sigma_{k,h}\\,=\\,\\bar{\\sigma}_{k,h}$ and the last inequality holds due to the definition of Generalized Eluder dimension with the fact that $D_{\\mathcal{F}_{h}}(z;\\bar{z}_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}<1$ ", "page_idx": 35}, {"type": "text", "text": "With a similar argument, the summation of confidence radius over set $\\mathcal{T}_{3}$ is upper bounded by ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k\\in\\mathbb{Z}_{3}}\\operatorname*{min}\\left(\\beta D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),1\\right)}\\\\ &{\\le\\displaystyle\\sum_{k\\in\\mathbb{Z}_{3}}\\beta D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})}\\\\ &{\\le\\displaystyle\\beta\\sqrt{\\sum_{k\\in\\mathbb{Z}_{3}}\\alpha^{2}}\\cdot\\sqrt{\\sum_{k\\in\\mathbb{Z}_{3}}D_{\\mathcal{F}_{h}}^{2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}^{2}}}\\\\ &{\\le\\beta\\sqrt{\\mathrm{dim}_{\\alpha,K}(\\mathcal{F}_{h})}\\sqrt{\\sum_{k\\in\\mathbb{Z}_{3}}\\alpha^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the second inequality holds due to Cauchy-Schwartz inequality with $\\bar{\\sigma}_{k,h}~=~\\alpha$ and the last inequality holds due to the definition of Generalized Eluder dimension with the fact that $D_{\\mathcal{F}_{h}}(z;\\bar{z}_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}<1$ ", "page_idx": 35}, {"type": "text", "text": "Finally, the summation of confidence radius over set $\\mathcal{Z}_{4}$ is upper bounded by With a similar argument, the summation of confidence radius over set $\\mathcal{T}_{3}$ is upper bounded by ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k\\in\\mathbb{Z}_{4}}\\operatorname*{min}\\Big(\\beta D_{\\mathcal{F}_{h}}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big),1\\Big)}\\\\ &{\\le\\displaystyle\\sum_{k\\in\\mathbb{Z}_{4}}\\beta D_{\\mathcal{F}_{h}}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big)}\\\\ &{=\\displaystyle\\sum_{k\\in\\mathbb{Z}_{4}}\\beta\\gamma^{2}D_{\\mathcal{F}_{h}}^{2}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big)/\\bar{\\sigma}_{k,h}^{2}}\\\\ &{\\le\\beta\\gamma^{2}\\dim_{\\alpha,K}(\\mathcal{F}_{h}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the fis equation holds due to $\\bar{\\sigma}_{k,h}=\\gamma\\times D_{\\mathcal{F}_{h}}^{1/2}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})$ and the last inequlity holds due to the defnition of Generalized Eluder dimension with $D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})/\\bar{\\sigma}_{k,h}<$ 1. ", "page_idx": 35}, {"type": "text", "text": "Combining the results in (F.26), (F.27), (F.28) and (F.29), we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{k=1}^{K}\\operatorname*{min}\\Big(\\beta D_{\\mathcal{F}_{h}}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big),1\\Big)}\\\\ {\\displaystyle\\leq(1+\\beta\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+2\\beta\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F}_{h})}\\sqrt{\\displaystyle\\sum_{k=1}^{K}(\\sigma_{k,h}^{2}+\\alpha^{2})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Thus, we complete the proof of Lemma D.13. ", "page_idx": 36}, {"type": "text", "text": "F.4.3 Proof of Lemma D.14 ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Proof of Lemma $D.I4$ .First, for each stage $h\\in[H]$ and episode $k\\in[K]$ , the gap between $V_{k,h}(s_{h}^{k})$ and $V_{h}^{\\pi^{k}}(s_{h}^{k})$ can be decomposed as: ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{k,h}(\\boldsymbol{s}_{h}^{k})-V_{n}^{k}(\\boldsymbol{s}_{h}^{k})}\\\\ &{=Q_{k,h}(\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})-Q_{h}^{\\pi^{k}}(\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})}\\\\ &{\\le\\operatorname*{min}\\Big(\\widehat{f}_{h_{n}h_{n}}(\\boldsymbol{s},\\boldsymbol{a})+b_{k_{\\operatorname*{min}}}(\\boldsymbol{s},\\boldsymbol{a}),1\\Big)-{\\mathcal{T}}_{h}V_{k,h+1}(\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})}\\\\ &{\\qquad+{\\mathcal{T}}_{h}V_{k,h+1}(\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})-{\\mathcal{T}}_{h}V_{h+1}^{\\pi^{k}}(\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})}\\\\ &{\\le\\big[\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})\\big](\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})+\\operatorname*{min}\\big(\\widehat{\\beta}_{k_{\\operatorname*{max}}}D_{f_{h}}(\\boldsymbol{z};\\boldsymbol{z}_{[k_{\\operatorname*{max}}-1],h},\\boldsymbol{\\bar{\\sigma}}_{[k_{\\operatorname*{max}}-1],h}),1\\big)+\\operatorname*{min}\\big(b_{k_{\\operatorname*{min}}}(\\boldsymbol{s}_{h}^{k})}\\\\ &{\\le\\big[\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})\\big](\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})+2C\\cdot\\operatorname*{min}\\big(\\widehat{\\beta}_{k_{\\operatorname*{max}}}D_{f_{h}}(\\boldsymbol{z}_{:}\\boldsymbol{z}_{[k_{\\operatorname*{max}}-1],h},\\boldsymbol{\\bar{\\sigma}}_{[k_{\\operatorname*{max}}-1],h}),1\\big)}\\\\ &{\\le\\big[\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})\\big](\\boldsymbol{s}_{h}^{k},\\boldsymbol{a}_{h}^{k})+2C(1+\\\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the first inequality holds due to the definition of value function $Q_{k,h}(s_{h}^{k},a_{h}^{k})$ , the second inequality holds due to Lemma D.6, the third inequality holds due to $b_{k_{\\mathrm{last}},h}\\widetilde{\\left(s_{h}^{k},a_{h}^{k}\\right)}\\ \\leq$ $C\\cdot D_{\\mathcal{F}_{h}}\\big(z;z_{[k_{\\mathrm{last}}-1],h},\\bar{\\sigma}_{[k_{\\mathrm{last}}-1],h}\\big)$ and the last inequality holds due to Lemma G.2. Taking a summation of (F.30) over all episode $\\dot{k}\\in[K]$ and stage $h^{\\prime}\\geq h$ ,wehave ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k=1}^{K}\\left(V_{k,h}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\right)}\\\\ &{\\le\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}\\left(\\left[\\mathbb{P}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})\\right](s_{h}^{k},a_{k}^{k})-\\left(V_{k,h+1}(s_{h+1}^{k})-V_{h+1}^{\\pi^{k}}(s_{h+1}^{k})\\right)\\right)}\\\\ &{\\qquad+\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}2C(1+\\chi)\\cdot\\operatorname*{min}\\left(\\hat{\\beta}_{k}D_{\\mathbb{P}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),1\\right)}\\\\ &{\\le\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{2C(1+\\chi)}\\operatorname*{min}\\left(\\hat{\\beta}_{k}D_{\\mathbb{P}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),1\\right)}\\\\ &{\\qquad+2\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=1}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{k}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "equation", "text": "$$\n\\leq\\sum_{h^{\\prime}=h}^{H}2C(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h^{\\prime}})+\\sum_{h^{\\prime}=h}^{H}4C(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F}_{h^{\\prime}})}\\sqrt{\\sum_{k=1}^{K}(\\sigma_{k,h^{\\prime}}^{2}+\\alpha^{2})}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "equation", "text": "$$\n+\\,2\\sqrt{\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\leq2C H(1+\\chi)(1+\\widehat\\beta_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+4C(1+\\chi)\\widehat\\beta_{k}\\sqrt{\\displaystyle\\sum_{h^{\\prime}=h}^{H}\\dim_{\\alpha,K}(\\mathcal{F}_{h^{\\prime}})}\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}(\\sigma_{k,h^{\\prime}}^{2}+\\alpha^{2})}}\\\\ {\\displaystyle\\qquad+\\,2\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}[\\nabla_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)}+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\\\\ {\\displaystyle\\leq2C H(1+\\chi)(1+\\widehat\\beta_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+4C(1+\\chi)\\widehat\\beta_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\\\ {\\displaystyle\\qquad+\\,2\\left[\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}\\in\\mathcal{V}_{h}}^{H}[\\nabla_{k,h+1}-V_{h+1}^{\\pi^{k}})\\|{\\boldsymbol{\\phi}}^{k}\\|\\boldsymbol{\\phi}^{k}\\|\\right](s)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\n+\\,2\\sqrt{\\sum_{k=1}^{\\Lambda}\\sum_{h^{\\prime}=h}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where the first inequality holds due to (F.30), the second inequality holds due to event ${\\mathcal{E}}_{1}$ , the third inequality holds due to Lemma D.13, the fourth inequality holds due to Cauchy-Schwartz inequality dand thelastineguait holdsdeto $\\begin{array}{r}{\\sum_{h^{\\prime}=h}^{H}\\dim_{\\alpha,K}(\\bar{\\mathcal{F}}_{h^{\\prime}})\\leq\\sum_{h^{\\prime}=1}^{H}\\dim_{\\alpha,K}(\\bar{\\mathcal{F}}_{h^{\\prime}})=H\\dim_{\\alpha,K}(\\bar{\\mathcal{F}})}\\end{array}$ Furthermore, taking a summation of (F.31), we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\displaystyle\\sum_{k=1}^{N}\\sum_{i=1}^{N}\\left[\\left(\\mathrm{P}_{k}(\\mathrm{K}_{i}\\mathrm{k}_{i}\\mathrm{\\scriptscriptstyleA}_{i}-\\mathrm{P}_{k}^{i,k})\\right)(\\mathrm{K}_{i}\\mathrm{\\scriptscriptstyleA}_{j}\\mathrm{\\scriptscriptstyleA}_{k})\\right.}{\\displaystyle\\sum_{k=1}^{N}\\left(\\mathrm{P}_{k}(\\mathrm{K}_{i}\\mathrm{k}_{i}\\mathrm{\\scriptscriptstyleA}_{j}\\mathrm{\\scriptscriptstyleA}_{k})-\\mathrm{P}_{k}^{i,k}\\mathrm{\\scriptscriptstyleA}_{k}^{i}\\mathrm{\\scriptscriptstyleA}_{k}^{i}\\mathrm{\\scriptscriptstyleA}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleA}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyleB}_{k}^{i}\\mathrm{\\scriptscriptstyle B \n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where the first inequality holds due to event ${\\mathcal{E}}_{1}$ and the second inequality holds due to (F.31). Thus, we complete the proof of Lemma D.14. \u53e3 ", "page_idx": 37}, {"type": "text", "text": "F.4.4 Proof of Lemma D.15 ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Proof of Lemma D.15. Similar to the proof of Lemma D.14, for each stage $h\\,\\in\\,[H]$ andepisode $k\\in[K]$ , thegapbetween $V_{k,h}(s_{h}^{k})$ and $\\check{V}_{k,h}(s_{h}^{k})$ canbe decomposed as: ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{k,h}(s_{h}^{k})-\\breve{V}_{k,h}(s_{h}^{k})}\\\\ &{\\leq Q_{k,h}(s_{h}^{k},a_{h}^{k})-\\breve{Q}_{k,h}(s_{h}^{k},a_{h}^{k})}\\\\ &{\\leq\\operatorname*{min}\\Big(\\widehat{f}_{k_{\\mathrm{last}},h}(s,a)+b_{k_{\\mathrm{last}},h}(s,a),1\\Big)-\\mathcal{T}_{h}V_{k,h+1}(s_{h}^{k},a_{h}^{k})}\\\\ &{\\qquad-\\operatorname*{max}\\Big(\\check{f}_{k_{\\mathrm{last}},h}(s,a)-b_{k_{\\mathrm{last}},h}(s,a),0\\Big)+\\mathcal{T}_{h}\\check{V}_{k,h+1}(s_{h}^{k},a_{h}^{k})}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad+\\;\\mathcal{T}_{h}V_{k,h+1}(s_{h}^{k},a_{h}^{k})-\\mathcal{T}_{h}\\check{V}_{k,h+1}(s_{h}^{k},a_{h}^{k})}\\\\ &{\\leq\\big[\\mathbb{P}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})\\big](s_{h}^{k},a_{h}^{k})+2\\cdot\\operatorname*{min}\\big(\\widehat{\\beta}_{k_{\\mathrm{lat}}}D_{\\mathcal{F}_{h}}(z;z_{[k_{\\mathrm{lat}}-1],h},\\bar{\\sigma}_{[k_{\\mathrm{lat}}-1],h}),1\\big)}\\\\ &{\\quad\\quad+\\,2\\cdot\\operatorname*{min}\\big(b_{k_{\\mathrm{lat}},h}(s_{h}^{k},a_{h}^{k}),1\\big)}\\\\ &{\\leq\\big[\\mathbb{P}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})\\big](s_{h}^{k},a_{h}^{k})+4C\\cdot\\operatorname*{min}\\big(\\widehat{\\beta}_{k_{\\mathrm{lat}}}D_{\\mathcal{F}_{h}}(z;z_{[k_{\\mathrm{lat}}-1],h},\\bar{\\sigma}_{[k_{\\mathrm{lat}}-1],h}),1\\big)}\\\\ &{\\leq\\big[\\mathbb{P}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})\\big](s_{h}^{k},a_{h}^{k})+4C(1+\\chi)\\cdot\\operatorname*{min}\\big(\\widehat{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h},1\\big)}\\\\ &{=V_{k,h+1}(s_{h+1}^{k})-\\check{V}_{k,h+1}(s_{h+1}^{k})+\\big[\\mathbb{P}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})\\big](s_{h}^{k},a_{h}^{k})-\\big(V_{k,h+1}(s_{h+1}^{k})-\\check{V}_{k,h+1}(s_{h+1}^{k})-\\check{V}_{k,h+1}(s_{h+1}^{k})\\big)}\\\\ &{\\quad\\quad+\\,4C(1+\\chi)\\cdot\\operatorname*{min}\\big(\\widehat{\\beta}_{k}D_{\\mathcal{F\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the first and second inequalities hold due to the defnition of $\\check{V}_{k,h}(s_{h}^{k})$ and $V_{k,h}(s_{h}^{k})$ , the third inequality holds due to Lemma D.6 with $\\widehat{\\beta}_{k_{\\mathrm{last}}}\\,=\\,\\breve{\\beta}_{k_{\\mathrm{last}}}$ , the fourth inequality holds due to $b_{k_{\\mathrm{last}},h}(s_{h}^{k},a_{h}^{k})\\leq C\\cdot D_{\\mathcal{F}_{h}}(z;z_{[k_{\\mathrm{last}}-1],h},\\bar{\\sigma}_{[k_{\\mathrm{last}}-1],h})$ and the last inequality holds due t Lemma G.2. Taking a summation of (F.32) over all episode $k\\in[K]$ and stage $h^{\\prime}\\geq h$ ,we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{k=1}^{K}\\left(V_{k,h}(s_{h}^{k})-\\breve{V}_{k,h}(s_{h}^{k})\\right)}\\\\ &{\\le\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}\\left([\\mathbb{P}_{h}(V_{k,h+1}-\\breve{V}_{k,h+1})]\\big(s_{h}^{k},a_{h}^{k}\\big)-\\big(V_{k,h+1}(s_{h+1}^{k})-\\breve{V}_{k,h+1}(s_{h+1}^{k})\\big)\\right)}\\\\ &{\\displaystyle\\qquad+\\sum_{k=1}^{K}\\displaystyle\\sum_{k=1}^{H}4C(1+\\chi)\\cdot\\operatorname*{min}\\big(\\hat{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),1\\big)}\\\\ &{\\le\\displaystyle\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}4C(1+\\chi)\\cdot\\operatorname*{min}\\big(\\hat{\\beta}_{k}D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}),1\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\leq\\sum_{h^{\\prime}=h}^{H}4C(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h^{\\prime}})+\\sum_{h^{\\prime}=h}^{H}8C(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F}_{h^{\\prime}})}\\sqrt{\\sum_{k=1}^{K}(\\sigma_{k,h^{\\prime}}^{2}+\\alpha^{2})}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n+\\,2\\sqrt{\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\leq4C H(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+8C(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\sum_{h^{\\prime}=h}^{H}\\dim_{\\alpha,K}(\\mathcal{F}_{h^{\\prime}})}\\sqrt{\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}(\\sigma_{k,h^{\\prime}}^{2}+\\alpha_{h^{\\prime}}^{2})}\\quad,\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n+\\,2\\sqrt{\\sum_{k=1}^{K}\\sum_{h^{\\prime}=h}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\leq4C H(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+8C(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n+\\,2\\sqrt{\\sum_{k=1}^{\\kappa}\\sum_{h^{\\prime}=h}^{H}[\\Psi_{h}(V_{k,h+1}-\\check{V}_{k,h+1})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the first inequality holds due to (F.32), the second inequality holds due to event $\\mathcal{E}_{2}$ , the third inequality holds due to Lemma D.13, the fourth inequality holds due to Cauchy-Schwartz inequality and the last inequality holds due to $\\begin{array}{r}{\\sum_{h^{\\prime}=h}^{H}\\dim_{\\alpha,K}(\\bar{\\mathcal{F}}_{h^{\\prime}})\\leq\\sum_{h^{\\prime}=1}^{H}\\dim_{\\alpha,K}(\\bar{\\mathcal{F}}_{h^{\\prime}})=H\\dim_{\\alpha,K}(\\bar{\\mathcal{F}})}\\end{array}$ ", "page_idx": 38}, {"type": "text", "text": "Furthermore, taking a summation of (F.33), we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\displaystyle\\sum_{k=1}^{N}\\sum_{i=1}^{N}\\left[\\mathbb{P}_{k}(\\hat{V}_{k,i+1}-\\tilde{V}_{k,i+1})\\right](s_{k}^{\\star},a_{k}^{\\star})}{\\displaystyle\\sum_{k=1}^{N}\\sum_{i=1}^{N}\\left(\\hat{V}_{k,i+1}+\\hat{V}_{k,i+1}^{\\star}\\right)-\\hat{V}_{k,i+1}(s_{k+1}^{\\star})}}\\\\ &{=\\displaystyle\\sum_{k=1}^{N}\\sum_{i=1}^{N}\\left(\\hat{V}_{k,i+1}(s_{k+1}^{\\star})-\\hat{V}_{k,i+1}(s_{k+1}^{\\star})\\right)}\\\\ &{\\phantom{\\sum_{k=1}^{N}\\sum_{i=1}^{N}\\left(\\hat{V}_{k}(\\hat{V}_{k,i+1}-\\hat{V}_{k,i+1})\\right)(s_{k}^{\\star},a_{k}^{\\star})-(\\hat{V}_{k,i+1}(s_{k+1}^{\\star})-\\hat{V}_{k,i+1}(s_{k+1}^{\\star}))\\right)}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\displaystyle\\sum_{k=1}^{N}\\sum_{i=1}^{N}\\left(\\hat{V}_{k,i+1}(s_{k+1}^{\\star})-\\hat{V}_{k,i+1}(s_{k+1}^{\\star})\\right)}\\\\ &{\\leq\\displaystyle\\sum_{k=1}^{N}\\sum_{i=1}^{N}\\left(\\hat{V}_{k,i+1}^{\\star}-\\hat{V}_{k,i+1}^{\\star}\\right)(\\hat{V}_{k,i}^{\\star})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad}\\\\ &{\\quad+\\mu\\left(2\\sqrt{\\frac{N-\\frac{N}{2}}{N-1}}\\nabla_{\\hat{V}}(\\hat{V}_{k,i+1}-\\hat{V}_{k,i+1})(s_{k}^{\\star},a_{k}^{\\star})\\log(2k^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)\\right)}\\\\ &{\\leq2C\\eta^{2}\\left(1+\\lambda\\right)(1+\\hat{V}_{k}^{\\star})^\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the first inequality holds due to event $\\mathcal{E}_{2}$ and the last inequality holds due to (F.33). Thus, we complete the proof of Lemma D.15. \u53e3 ", "page_idx": 39}, {"type": "text", "text": "F.4.5 Proof of Lemma D.16 ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Proof of Lemma $D.l6$ .According to the definition of estimated variance $\\sigma_{k,h}$ , the summation of variance can be decomposed as following: ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{\\displaystyle\\sum_{=1}^{K}{\\frac{H}{h=1}\\sigma_{k,h}^{2}}=\\sum_{k=1}^{K}{\\sum_{h=1}^{H}{[\\bar{\\Psi}_{k,h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})}+E_{k,h}}+F_{k,h}}\\\\ {\\displaystyle}&{\\displaystyle=\\sum_{\\ k=1}^{K}{\\sum_{h=1}^{H}{([\\bar{\\Psi}_{k,h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\Psi_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k}))}}+\\sum_{k=1}^{K}{\\sum_{h=1}^{H}{E_{k,h}}}+\\sum_{\\underset{h=1}{\\overset{k-1}{h-1}}}^{K}{F_{k,h}}}\\\\ &{\\displaystyle\\qquad+\\sum_{k=1}^{K}{\\sum_{h=1}^{H}{([\\Psi_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\Psi_{h}V_{h+1}^{\\pi^{k}}](s_{h}^{k},a_{h}^{k}))}}+\\sum_{k=1}^{K}{\\sum_{h=1}^{H}[\\Psi_{h}V_{h+1}^{\\pi^{k}}](s_{h}^{k},a_{h}^{k})}}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "For the term $I_{1}$ , it can be upper bounded by ", "page_idx": 39}, {"type": "equation", "text": "$$\nI_{1}=\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\big([\\bar{\\mathbb{V}}_{k,h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})-[\\mathbb{V}_{h}V_{k,h+1}](s_{h}^{k},a_{h}^{k})\\big)\\le\\sum_{k=1}^{K}\\sum_{h=1}^{H}E_{k,h},\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the inequality holds due to Lemma D.9. ", "page_idx": 39}, {"type": "text", "text": "For the second term $\\begin{array}{r}{I_{2}=\\sum_{k=1}^{K}\\sum_{h=1}^{H}E_{k,h}}\\end{array}$ , we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}\\sum_{h=1}^{H}E_{k,h}=\\sum_{k=1}^{K}\\sum_{h=1}^{H}(2L\\beta_{k}+\\widetilde{\\beta}_{k})\\operatorname*{min}\\Big(1,D_{\\mathcal{F}_{h}}(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\Big)\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\leq\\sum_{h=1}^{H}(2L\\beta_{h}+\\widetilde{\\beta}_{h})\\times(1+\\gamma^{2})\\,\\mathrm{dim}_{\\alpha,K}(\\mathcal{F}_{h})}}\\\\ &{\\quad+\\sum_{h=1}^{H}(2L\\beta_{h}+\\widetilde{\\beta}_{h})\\times2\\sqrt{\\mathrm{dim}_{\\alpha,K}(\\mathcal{F}_{h})}\\sqrt{\\displaystyle{\\sum_{k=1}^{K}(\\sigma_{k,h}^{2}+\\alpha^{2})}}}\\\\ &{\\leq(2L\\beta_{h}+\\widetilde{\\beta}_{h})H\\times(1+\\gamma^{2})\\,\\mathrm{dim}_{\\alpha,K}(\\mathcal{F})}\\\\ &{\\qquad+(2L\\beta_{h}+\\widetilde{\\beta}_{h})\\times2\\sqrt{\\displaystyle{\\sum_{h=1}^{H}\\mathrm{dim}_{\\alpha,K}(\\mathcal{F}_{h})}}\\sqrt{\\displaystyle{\\sum_{k=1}^{K}\\frac{H}{\\beta_{h}^{2}+\\alpha^{2}}}}}\\\\ &{=(2L\\beta_{h}+\\widetilde{\\beta}_{h})H\\times(1+\\gamma^{2})\\,\\mathrm{dim}_{\\alpha,K}(\\mathcal{F})}\\\\ &{\\qquad+(2L\\beta_{h}+\\widetilde{\\beta}_{h})\\times2\\sqrt{\\mathrm{dim}_{\\alpha,K}(\\mathcal{F})}\\sqrt{\\displaystyle{H\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where the inequality holds due to Lemma D.13 and the second inequality holds due to CauchySchwartz inequality. ", "page_idx": 40}, {"type": "text", "text": "For the term $I_{3}$ , we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}}\\\\ &{=[\\Phi_{k}\\mathbf{X}_{i}(t),}\\\\ &{=[\\Phi_{k}(V)_{i}(+\\log{R_{k}(V)})}\\\\ &{\\quad\\times\\sum_{k=1}^{N}\\sum_{\\substack{m\\in\\mathcal{N}_{k}(k)}}(\\mathbf{1}_{\\mathcal{Z}}\\hat{f}_{i,k}(V)_{i}-\\mathbf{1}_{\\mathcal{Z}}\\hat{f}_{i,k}(V)_{i}+\\mathbf{1}_{\\mathcal{Z}}\\hat{f}_{i,k}(V)_{i+1,k}\\phi_{k,m,\\cdot}(\\mathbf{1}_{\\mathcal{Z}})}\\\\ &{\\le\\{\\Phi_{k}\\mathbf{X}_{i}(V)_{i}(+\\log{R_{k}(V)})\\}}\\\\ &{\\quad\\times\\sum_{k=1}^{N}\\sum_{\\substack{m\\in\\mathcal{N}_{k}(k)}}(\\mathbf{1}_{\\mathcal{Z}}\\mathbf{F}_{i,k+1,k}(V)_{i}-\\mathbf{1}_{\\mathcal{Z}}\\mathbf{F}_{i,k+1,k}(V)_{i}\\phi_{k,m,\\cdot}^{-})+\\mathbf{1}_{\\mathcal{Z}}\\mathbf{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}}\\\\ &{\\quad\\times\\frac{t}{w\\in\\mathcal{N}_{k}(k)}}\\\\ &{\\le[\\Phi_{k}\\mathbf{X}(V)+\\log{R_{k}(V)}\\cdot\\mathbf{1}_{\\mathcal{Z}}\\mathbf{1}_{\\mathcal{Z}}\\mathbf{\\\\\\\\\\\\\\\\\\\\\\\\\\\\}\\frac{K}{w}][\\Phi_{k}(V,\\lambda_{m+1}-V,\\lambda_{m+1})(\\mathbf{1}_{\\mathcal{Z}}\\hat{f}_{i,k}^{\\star}\\phi_{k,m}^{-})]}\\\\ &{\\quad\\times\\mathrm{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\}}\\\\ &{\\le \n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where the first inequality holds due to Lemma D.8, the second inequality holds due to $V_{k,h+1}(\\cdot)\\geq$ $V_{h+1}^{*}(\\cdot)\\geq\\check{V}_{k,h+1}(\\cdot)$ , the third inequality holds due to Lemma D.13 with Cauchy-Schwartzinequality. By Lemma D.15, ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\big[\\mathbb{P}_{h}(V_{k,h+1}-\\widecheck{V}_{k,h+1})\\big]\\big(s_{h}^{k},a_{h}^{k}\\big)\\leq4C H^{2}(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})}}\\\\ &{\\quad+\\,8C H(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\underset{k=1}{\\overset{K}{\\sum}}\\underset{h=1}{\\overset{H}{\\sum}}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad+\\,2H\\left(2\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}[\\mathbb{V}_{h}(V_{k,h+1}-\\breve{V}_{k,h+1})](s_{h}^{k},a_{h}^{k})\\log(2K^{2}H/\\delta)+2\\sqrt{\\log(2K^{2}H/\\delta)}+2\\log(2K^{2}H/\\delta)}\\right)}\\\\ &{\\quad\\le\\,4C H^{2}(1+\\chi)(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+8C H(1+\\chi)\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}}\\\\ &{\\quad\\quad+\\,\\widetilde{O}\\left(H\\sqrt{\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\left[\\mathbb{P}_{h}(V_{k,h+1}-\\breve{V}_{k,h+1})\\right](s_{h}^{k},a_{h}^{k})}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where the last inequality follows from Lemma D.7. ", "page_idx": 41}, {"type": "text", "text": "Notice that for each variable $x$ \uff0c $x\\leq a{\\sqrt{x}}+b$ implies $x\\leq a^{2}+2b$ , from (F.38), we further have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{\\ell=1}^{K}\\sum_{h=1}^{H}\\left[\\mathbb{P}_{h}(V_{k,h+1}-\\check{V}_{k,h+1})\\right](s_{h}^{k},a_{h}^{k})}\\\\ {\\displaystyle\\leq\\tilde{O}\\left(C H^{2}(1+\\chi)(1+\\hat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})+C H(1+\\chi)\\hat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha_{k,h+1}^{2})}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Substituting (F.39) into (F.37), we obtain the following upper bound for $I_{3}$ ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{3}\\le\\widetilde{O}\\left((\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\,H\\widehat{\\beta}_{k}\\sqrt{\\dim_{\\alpha,K}(\\mathcal{F})}\\sqrt{H\\displaystyle\\sum_{k=1}^{K}\\sum_{h=1}^{H}(\\sigma_{k,h}^{2}+\\alpha^{2})}\\right)}\\\\ &{\\qquad+\\,\\widetilde{O}\\left((\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\cdot H^{2}(1+\\widehat{\\beta}_{k}\\gamma^{2})\\dim_{\\alpha,K}(\\mathcal{F}_{h})\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "For the term $I_{4}$ , we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\alpha=\\displaystyle\\sum_{k=1}^{k}\\sum_{i=1}^{n}\\left(|\\nabla b_{k}K_{k+\\lambda_{i}}|\\right)\\left(x_{k}^{k},u_{i}^{k}\\right)-\\left|\\nabla c_{k}V_{k+\\lambda_{i}}^{k+\\lambda_{i}}\\right|\\left(x_{k}^{k},u_{i}^{k}\\right)\\right)}\\\\ &{\\quad=\\displaystyle\\sum_{k=1}^{n}\\sum_{i=1}^{n}\\left(|\\nabla b_{k}^{2}\\lambda_{i}|u_{i}^{k}\\right)\\left(x_{k}^{k},u_{i}^{k}\\right)-\\left|\\left(\\nabla b_{k}K_{k+\\lambda_{i}}\\right)\\left(x_{k}^{k},u_{i}^{k}\\right)\\right|^{2}-\\left|\\mathbb{P}_{k}(V_{k+\\lambda_{i}}^{k+\\lambda_{1}})\\left|\\left(x_{k}^{k},u_{i}^{k}\\right)\\right|+\\left|\\mathbb{P}_{k}V_{k+\\lambda_{i}}^{k+\\lambda_{1}}\\right|\\left(x_{k}^{k},u_{i}^{k}\\right)\\right|}\\\\ &{\\quad\\le\\displaystyle\\sum_{k=1}^{n}\\sum_{i=1}^{n}\\left(|\\nabla b_{k}^{2}\\lambda_{i}|u_{i}^{k}\\right)\\left(x_{k}^{k},u_{i}^{k}\\right)-\\left|\\mathbb{P}_{k}(V_{k+\\lambda_{i}}^{k+\\lambda_{1}})\\left|\\left(x_{k}^{k},u_{i}^{k}\\right)\\right|}\\\\ &{\\le\\displaystyle\\sum_{k=1}^{n}\\sum_{i=1}^{n}\\left(|\\nabla b_{k}^{2}\\lambda_{i}|u_{i}^{k}\\right)\\left(x_{k}^{k},u_{i}^{k}\\right)-\\left|\\mathbb{P}_{k}V_{k+\\lambda_{i}}^{k+\\lambda_{1}}\\right|\\left(x_{k}^{k},u_{i}^{k}\\right)\\right)}\\\\ &{\\le\\displaystyle\\sum_{k=1}^{n}\\sum_{i=1}^{n}\\left(|\\nabla b_{k}^{2}\\lambda_{i}|u_{i}^{k}\\right)\\left(u_{k}^{k},u_{i}^{k}\\right)-\\left|\\mathbb{P}_{k}V_{k+\\lambda_{i}}^{k+\\lambda_{1}}\\right|\\left(x_{k}^{k},u_{i}^{k}\\right)}\\\\ &{\\qquad\\le\\displaystyle\\sum_ \n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where the first inequality holds due to $V_{k,h+1}(\\cdot)\\geq V_{h+1}^{*}(\\cdot)\\geq V_{h+1}^{\\pi^{k}}(\\cdot)$ , the second inequality holds due to $0\\,\\leq\\,V_{h+1}^{*}(\\cdot),V_{h+1}^{\\pi^{k}}(\\cdot)\\,\\leq\\,1$ the third inequality holds due to Lemma D.14, and the last inequality follows from Lemma D.7 and the fact that $x\\leq a{\\sqrt{x}}+b$ implies $x\\leq a^{2}+2b$ ", "page_idx": 41}, {"type": "text", "text": "For the term $I_{5}$ , according to the definition of $\\mathrm{Var}_{K}$ , we have ", "page_idx": 42}, {"type": "equation", "text": "$$\nI_{5}=\\sum_{k=1}^{K}\\sum_{h=1}^{H}[\\mathbb{V}_{h}V_{h+1}^{\\pi^{k}}](s_{h}^{k},a_{h}^{k})=\\operatorname{Var}_{K}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Substituting the results in (F.35), (F.36), (F.40), (F.41) and (F.42) into (F.34), we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\begin{array}{r l}&{\\frac{\\sinh(t)}{t}=\\operatorname*{inf}_{1}+\\dots}\\\\ &{=\\Bar{I}_{1}+\\Bar{I}_{2}+\\Bar{I}_{3}+\\Bar{I}_{5}}\\\\ &{\\le\\bigg((4\\pi\\delta_{1}+2\\Bar{I}_{3})H\\times(1+\\gamma^{2})\\operatorname*{dim}_{s}\\kappa(7)}\\\\ &{\\quad+(4\\pi\\delta_{1}+2\\Bar{I}_{3})\\times2\\sqrt{\\operatorname*{dim}_{s}\\kappa(9)}\\sqrt{\\prod_{i=1}^{K}\\sum_{j=0}^{\\frac{K}{i}}(\\sigma_{i,i}^{2}+\\sigma_{j}^{2})}+\\mathrm{Var}_{\\kappa}}\\\\ &{\\quad+(1\\delta_{1}+2\\Bar{I}_{3})(1+\\Bar{I}_{5})^{2}\\Biggr)\\operatorname*{dim}_{s}\\kappa(7)+\\mathrm{i}6\\pi\\hat{I}(1+\\gamma^{2})\\lambda_{\\times}\\sqrt{\\operatorname*{dim}_{s}(7)}\\sqrt{\\prod_{i=1}^{K}\\sum_{j=1}^{\\frac{K}{i}}(\\sigma_{i,i}^{2}}}\\\\ &{\\quad+(5\\pi)^{2}(1+\\log_{s}(1))H)^{2}\\lambda_{\\times}\\sqrt{\\operatorname*{dim}_{s}\\kappa(7)}\\Biggl\\{\\prod_{i=1}^{K}\\sum_{j=0}^{K}(\\sigma_{i,i}^{2}+\\sigma^{2})}\\\\ &{\\quad+(8\\log_{3}\\gamma(+\\log_{s}(1))H)^{2}\\lambda_{\\times}^{2}\\sqrt{\\operatorname*{dim}_{s}\\kappa(9)}\\sqrt{\\prod_{i=1}^{K}\\sum_{j=1}^{K}(\\sigma_{i,i}^{2}+\\sigma^{2})}}\\\\ &{\\quad+(5\\log_{3}\\gamma(+\\log_{3}\\kappa(5))-H^{2}(1+\\widehat{\\lambda}_{5})^{2})\\operatorname*{dim}_{s}\\kappa(7)}\\\\ &{\\le\\mathrm{Vark}+(5\\log_{3}V(+)+\\log_{3}(K))\\times\\tilde{Q}((1+\\gamma^{2})(\\mathbb{i}_{3}+H\\widetilde{\\lambda}_{\\times})^{2}+\\tilde{I}_{5})H\\dim_{s}\\kappa(7)}\\\\ &{\\quad+(1\\Theta_{3}\\gamma(+\\log_{3}(\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Notice that for each variable $x$ $x\\leq a{\\sqrt{x}}+b$ implies $x\\leq a^{2}+2b$ . With this fact, we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\sigma_{k,h}^{2}\\le(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))\\times\\widetilde{O}\\big((1+\\gamma^{2})(\\beta_{k}+H\\widehat{\\beta}_{k}+\\widetilde{\\beta}_{k})H\\dim_{\\alpha,K}(\\mathcal{F})\\big)}}\\\\ &{}&{\\quad+\\;(\\log N_{\\mathcal{F}}(\\epsilon)+\\log N_{\\epsilon}(K))^{2}\\times\\widetilde{O}\\big((\\beta_{k}+H\\widehat{\\beta}_{k}+\\widetilde{\\beta}_{k})^{2}H\\dim_{\\alpha,K}(\\mathcal{F})\\big)}\\\\ &{}&{\\quad+\\;\\widetilde{O}(\\mathrm{Var}_{K}+K H\\alpha^{2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Thus, we complete the proof of Lemma D.16. ", "page_idx": 42}, {"type": "text", "text": "G   Covering Number Argument ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "G.1  Rare Switching ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Based on the policy-updating criterion, the following lemma provides a upper bound of the switching cost. ", "page_idx": 42}, {"type": "text", "text": "Lemma G.1. The number of episodes when the algorithm updates the value function is at most $O\\left(\\dim_{\\alpha,K}({\\mathcal{F}})\\cdot H\\right)$ ", "page_idx": 42}, {"type": "text", "text": "Proof. According to line 9, the policy is updated at episode $k$ Only when there exists a stage $h\\in[H]$ suchthat ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k_{l a s t},k-1]}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}D_{\\mathcal{F}_{h}}^{2}(z_{i,h};z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h})\\geq\\chi/C.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "and ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k_{l a s t},k-2]}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}D_{\\mathcal{F}}^{2}(z_{i,h};z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h})<\\chi.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Then the following inequality holds, ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{f_{1},f_{2}\\in\\mathcal{F}_{h}}{\\operatorname*{sup}}\\frac{\\sum_{i\\in[1,k_{-2}]}\\frac{1}{\\sigma_{i,h}^{2}}\\left(f_{1}(z_{i,h})-f_{2}(z_{i,h})\\right)^{2}+\\lambda}{\\frac{1}{i\\epsilon_{[1,k_{\\alpha\\varepsilon}-1]}}\\frac{1}{\\sigma_{i,h}^{2}}\\left(f_{1}(z_{i,h})-f_{2}(z_{i,h})\\right)^{2}+\\lambda}}\\\\ &{=1+\\underset{f_{1},f_{2}\\in\\mathcal{F}_{h}}{\\operatorname*{sup}}\\frac{\\sum_{i\\in[k_{l a s t},k-2]}\\frac{1}{\\sigma_{i,h}^{2}}\\left(f_{1}(z_{i,h})-f_{2}(z_{i,h})\\right)^{2}}{\\frac{1}{i\\epsilon_{[1,h_{a s t}-1]}}\\frac{1}{\\sigma_{i,h}^{2}}\\left(f_{1}(z_{i,h})-f_{2}(z_{i,h})\\right)^{2}+\\lambda}}\\\\ &{\\leq1+\\underset{i\\in[k_{l a s t},k-2]}{\\sum}\\frac{1}{\\overline{{\\sigma_{i,h}^{2}}}}D_{\\mathcal{F}_{h}}^{2}\\left(z_{i,h};z_{[k_{a s t}-1],h},\\overline{{\\sigma}}_{[k_{l a s t}-1],h}\\right)}\\\\ &{\\leq1+\\chi,}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where the first inequality holds due to the definition of $D_{\\mathcal{F}_{h}}$ (Definition 2.4), the second inequality follows from (G.1). ", "page_idx": 43}, {"type": "text", "text": "(G.3) further gives a lower bound for the summation ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i\\in[k_{l a s t},k-1]}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}D_{\\mathcal{F}}^{2}(z_{i,h};z_{[i-1],h},\\bar{\\sigma}_{[i-1],h})}\\\\ &{\\geq\\frac{1}{1+\\chi}\\sum_{i\\in[k_{l a s t},k-1]}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}D_{\\mathcal{F}}^{2}\\big(z_{i,h};z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h}\\big)}\\\\ &{\\geq\\frac{\\chi/C}{1+\\chi}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Note that $\\begin{array}{r}{\\frac{\\chi/C}{1+\\chi}\\leq1}\\end{array}$ , we also have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k_{l a s t},k-1]}\\operatorname*{min}\\left\\{1,\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}D_{\\mathcal{F}}^{2}(z_{i,h};z_{[i-1],h},\\bar{\\sigma}_{[i-1],h})\\right\\}\\geq\\frac{\\chi/C}{1+\\chi}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Then we have an upper bound and lower bound for the following summation: ", "page_idx": 43}, {"type": "equation", "text": "$$\nl_{K}\\cdot\\frac{\\chi/C}{1+\\chi}\\leq\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\operatorname*{min}\\left\\{1,\\frac{1}{\\bar{\\sigma}_{k,h}^{2}}D_{\\mathcal{F}}^{2}(z_{k,h};z_{[k-1],h},\\bar{\\sigma}_{[k-1],h})\\right\\}\\leq\\mathrm{dim}_{\\alpha,K}(\\mathcal{F})\\cdot H.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Therefore, the number of policy switching $l_{K}$ is of order $O(\\dim_{\\alpha,K}(\\mathcal{F})\\cdot H)$ ", "page_idx": 43}, {"type": "text", "text": "Lemma G.2 (Stability of uncertainty under rare switching strategy). If the policy is not updated at episode $k$ , the uncertainty of all state-action pair $\\boldsymbol{z}=(s,a\\bar{)}\\in\\mathcal{S}\\times\\mathcal{A}$ and stage $h\\in[H]$ satisfies the following stability property: ", "page_idx": 43}, {"type": "equation", "text": "$$\nD_{\\mathcal{F}_{h}}^{2}\\bigl(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\bigr)\\geq\\frac{1}{1+\\chi}D_{\\mathcal{F}_{h}}^{2}\\bigl(z;z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h}\\bigr).\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Proof. Due to the definition of $k_{l a s t}$ in Algorithm 1, we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\sum_{i\\in[k_{l a s t},k-1]}\\frac{1}{\\bar{\\sigma}_{i,h}^{2}}D_{\\mathcal{F}}^{2}(z_{i,h};z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h})<\\chi.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "As is shown in (G.3), here we also have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{f_{1},f_{2}\\in\\mathcal{F}_{h}}\\frac{\\sum_{i\\in[1,k-1]}\\frac{1}{\\sigma_{i,h}^{2}}(f_{1}(z_{i,h})-f_{2}(z_{i,h}))^{2}+\\lambda}{\\sum_{i\\in[1,k_{l a s t}-1]}\\frac{1}{\\sigma_{i,h}^{2}}(f_{1}(z_{i,h})-f_{2}(z_{i,h}))^{2}+\\lambda}\\leq1+\\chi.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "From the definition of $D_{\\mathcal{F}_{h}}$ \uff0c", "page_idx": 44}, {"type": "equation", "text": "$$\nD_{\\mathcal{F}_{h}}^{2}\\big(z;z_{[k-1],h},\\bar{\\sigma}_{[k-1],h}\\big)\\ge\\frac{1}{1+\\chi}D_{\\mathcal{F}_{h}}^{2}\\big(z;z_{[k_{l a s t}-1],h},\\bar{\\sigma}_{[k_{l a s t}-1],h}\\big).\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "The proof is then completed due to the arbitrariness of $h$ ", "page_idx": 44}, {"type": "text", "text": "G.2Value Function Class and Its Covering Number ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "The optimistic value functions at episode $k$ and stage $h\\in[H]$ in our construction belong to the following function class: ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\mathcal{V}_{k,h}=\\left\\{V\\bigg|\\operatorname*{max}_{a\\in\\mathcal{A}}\\operatorname*{min}_{1\\le i\\le l_{k}+1}\\operatorname*{min}\\left(1,f_{i}(\\cdot,a)+\\beta\\cdot b(\\cdot,a)\\right)\\right\\},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $l_{k}$ is the number of updated policies as defined in Algorithm 1, $f_{i}\\in\\mathcal{F}_{h}$ and $b\\in\\mathcal{B}$ ", "page_idx": 44}, {"type": "text", "text": "Similarly, we also define the following pessimistic value function classes for all $k\\geq1$ ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\breve{\\mathcal{V}}_{k,h}=\\left\\{V\\bigg|\\operatorname*{max}_{a\\in\\mathcal{A}}\\operatorname*{max}_{1\\le i\\le l_{k}+1}\\operatorname*{max}\\left(0,f_{i}(\\cdot,a)-\\beta\\cdot b(\\cdot,a)\\right)\\right\\},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Lemma G.3 ( $\\epsilon_{}$ -covering number of optimistic value function classes). For optimistic value function class $\\nu_{k,h}$ defined in (G.4), we define the distance between two value functions $V_{1}$ and $V_{2}$ as $\\begin{array}{r}{\\|V_{1}-V_{2}\\|_{\\infty}:=\\operatorname*{max}_{s\\in S}|V_{1}(s)-V_{2}(s)|}\\end{array}$ . Then the $\\epsilon$ -covering number with respect to the distance function can be upper bounded by ", "page_idx": 44}, {"type": "equation", "text": "$$\nN_{\\epsilon}(k):=[N_{\\mathcal{F}}(\\epsilon/2)\\cdot N(\\mathcal{B},\\epsilon/2\\beta)]^{l_{k}+1}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Proof. By the definition of $N(\\mathcal{F},\\epsilon)$ , there exists an $\\epsilon/2$ -net of $\\mathcal{F}$ , denoted by $\\mathcal{C}(\\mathcal{F},\\epsilon/2)$ , such that for any $f\\in\\mathcal F$ , we can find $f^{\\prime}\\in\\mathcal{C}(\\mathcal{F},\\epsilon/2)$ such that $\\|\\dot{f}-f^{\\prime}\\|_{\\infty}\\leq\\epsilon/2$ . Also, there exists an $\\epsilon/2\\beta$ -net of $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}^{\\beta}$ \uff0c ${\\mathcal{C}}({\\mathcal{B}},\\epsilon/2\\beta)$ ", "page_idx": 44}, {"type": "text", "text": "Then we consider the following subset of $\\mathcal{V}_{k}$ \uff0c ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\gamma^{c}=\\left\\{V\\left|\\operatorname*{max}_{a\\in A}\\operatorname*{min}_{1\\leq i\\leq l_{k}+1}\\operatorname*{min}\\left(1,f_{i}(\\cdot,a)+\\beta\\cdot b_{i}(\\cdot,a)\\right),f_{i}\\in\\mathcal{C}(\\mathcal{F}_{h},\\epsilon/2),b_{i}\\in\\mathcal{C}(\\mathcal{B},\\epsilon/2\\beta)\\right\\}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Consider an arbitrary $V\\in\\mathcal{V}$ where $\\begin{array}{r}{V=\\operatorname*{max}_{a\\in\\mathcal{A}}\\operatorname*{min}_{1\\leq i\\leq l_{k}+1}\\operatorname*{min}(1,f_{i}(\\cdot,a)+\\beta\\cdot b_{i}(\\cdot,a))}\\end{array}$ . For each $f_{i}$ , there exists $\\bar{f}_{i}^{c}\\in\\mathcal{C}(\\mathcal{F},\\epsilon/2)$ such that $\\|f_{i}-f_{i}^{c}\\|_{\\infty}\\overset{=}{\\leq}\\epsilon/2$ . There also exists $b^{c}\\in\\mathcal{C}(B,\\epsilon/2\\beta)$ such that $\\|b-b^{c}\\|_{\\infty}\\overset{}{\\underset{}{\\sim}}\\epsilon/2\\beta$ Let Ve = maxaeA $\\mathrm{i}\\,\\mathrm{min}_{1\\leq i\\leq l_{k}+1}\\,\\mathrm{min}(1,f_{i}^{c}(\\cdot,a)+\\beta\\cdot b^{c}(\\cdot,a))\\in\\mathcal{V}^{\\dot{c}}$ It is then straightforward to check that $\\|V-V^{c}\\|_{\\infty}\\leq\\epsilon/2+\\beta\\cdot\\epsilon/2\\beta=\\epsilon$ ", "page_idx": 44}, {"type": "text", "text": "By direct calculation, we have $|\\mathcal{V}^{c}|=[N(\\mathcal{F}_{h},\\epsilon/2)\\cdot N(\\mathcal{B},\\epsilon/2\\beta)]^{l_{k}+1}.$ ", "page_idx": 44}, {"type": "text", "text": "Lemma G.4 ( $\\epsilon_{}$ -covering number of pessimistic value function classes). For pessimistic value function class $\\check{\\mathcal{V}}_{k,h}$ defined in (G.5), we define the distance between two value functions $V_{1}$ and $V_{2}$ as $\\begin{array}{r}{\\|V_{1}-V_{2}\\|_{\\infty}:=\\operatorname*{max}_{s\\in S}|V_{1}(s)-V_{2}(s)|}\\end{array}$ Then the $\\epsilon$ -coveringnumber of $\\check{\\mathcal{V}}_{k}$ with respect to the distance function can be upper bounded by $N_{\\epsilon}(k)$ defined in (G.6). ", "page_idx": 44}, {"type": "text", "text": "Proof. The proof is nearly the same as that of Lemma G.3. ", "page_idx": 44}, {"type": "text", "text": "H   Auxiliary Lemmas ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "Lemma H.1 (Azuma-Hoeffding inequality). Let $\\{x_{i}\\}_{i=1}^{n}$ be a martingale difference sequence with respect to a filtration $\\{\\mathcal{G}_{i}\\}$ satisfying $|x_{i}|\\ \\leq\\ M$ for some constant $M,\\ x_{i}$ is $\\mathcal{G}_{i+1}$ -measurable, $\\mathbb{E}[\\bar{x}_{i}|\\mathcal{G}_{i}]=0$ . Then for any $0<\\delta<1$ , with probability at least $1-\\delta$ , we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}x_{i}\\leq M{\\sqrt{2n\\log(1/\\delta)}}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Lemma H.2 (Corollary 2, Agarwal et al. 2022). Let $M\\,>\\,0,V\\,>\\,v\\,>\\,0$ be constants, and $\\{x_{i}\\}_{i\\in[t]}$ be stochastic process adapted to a filtration $\\{\\mathcal{H}_{i}\\}_{i\\in[t]}$ .Suppose $\\mathbb{E}[x_{i}|\\mathcal{H}_{i-1}]~=~0$ $|x_{i}|\\ \\leq\\ M$ and $\\begin{array}{r}{\\sum_{i\\in[t]}\\mathbb{E}[x_{i}^{2}|\\mathcal{H}_{i-1}]~\\le~V^{2}}\\end{array}$ almost surely.  Then for any $\\delta,\\epsilon\\ >\\ 0$ ,let $\\iota=$ $\\begin{array}{r}{\\sqrt{\\log\\frac{\\left(2\\log(V/v)+2\\right)\\cdot\\left(\\log(M/m)+2\\right)}{\\delta}}}\\end{array}$ we have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\sum_{i\\in[t]}x_{i}>\\iota\\sqrt{2\\left(2\\sum_{i\\in[t]}\\mathbb{E}[x_{i}^{2}|\\mathcal{H}_{i-1}]+v^{2}\\right)}+\\frac{2}{3}\\iota^{2}\\left(2\\operatorname*{max}_{i\\in[t]}|x_{i}|+m\\right)\\right)\\leq\\delta.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Lemma H.3 (Lemma 7, Russo and Van Roy 2014). Consider random variables $(Z_{n}|n\\in\\mathbb{N})$ adapted to the filtration $\\langle\\mathcal{H}_{n}:\\,n=0,1,\\ldots\\rangle$ . Assume $\\mathbb{E}\\left[\\exp\\left\\{\\lambda Z_{i}\\right\\}\\right]$ is finite for all $\\lambda$ . Define the conditional mean $\\mu_{i}=\\mathbb{E}\\left[Z_{i}\\mid\\mathcal{H}_{i-1}\\right]$ . We define the conditional cumulant generating function of the centered randomvariable $[Z_{i}-\\mu_{i}]$ by $\\psi_{i}\\left(\\lambda\\right)=\\log\\mathbb{E}\\left[\\exp\\left(\\lambda\\left[Z_{i}-\\mu_{i}\\right]\\right)\\mid\\mathcal{H}_{i-1}\\right]$ . For all $x\\geq0$ and $\\lambda\\geq0$ ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\sum_{1}^{n}\\lambda Z_{i}\\leq x+\\sum_{1}^{n}\\left[\\lambda\\mu_{i}+\\psi_{i}\\left(\\lambda\\right)\\right]\\ \\ \\forall n\\in\\mathbb{N}\\right)\\geq1-e^{-x}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Lemma H.4 (Self-normalized bound for scalar-valued martingales). Consider random variables $(v_{n}|n\\in\\mathbb{N})$ adapted to the filtration $\\langle\\mathcal{H}_{n}:\\,n=0,1,\\ldots\\rangle$ . Let $\\{\\eta_{i}\\}_{i=1}^{\\infty}$ be a sequence of real-valued random variables which is $\\mathcal{H}_{i+1}$ -measurable and is conditionally $\\sigma$ -sub-Gaussian. Then for an arbitrarily chosen $\\lambda>0$ , for any $\\delta>0$ , with probability at least $1-\\delta$ , it holds that ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}\\epsilon_{i}v_{i}\\leq\\frac{\\lambda\\sigma^{2}}{2}\\cdot\\sum_{i=1}^{n}v_{i}^{2}+\\log(1/\\delta)/\\lambda\\qquad\\forall n\\in\\mathbb{N}.\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Lemma H.5 (Lemma 10, Zhang et al. 2020). Let $(M_{n})_{n\\geq0}$ be a martingale such that $M_{0}=0$ and $|M_{n}-M_{n-1}|\\leq c$ for some $c>0$ and any $n\\geq1$ .Let $\\begin{array}{r}{\\mathrm{\\dot{Var}}_{n}=\\sum_{k=1}^{n}E[(M_{k}-M_{k-1})^{2}|\\mathcal{F}_{k-1}]}\\end{array}$ for $n\\geq0$ , where $\\mathcal{F}_{k}=\\sigma(M_{1},M_{2},\\ldots,M_{k})$ . Then for any positive integer $n$ and any $\\varepsilon,p>0$ ,wehave that ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(|M_{n}|\\geq2{\\sqrt{\\operatorname{Var}_{n}\\log\\left({\\frac{1}{p}}\\right)}}+2{\\sqrt{\\varepsilon\\log\\left({\\frac{1}{p}}\\right)}}+2c\\log\\left({\\frac{1}{p}}\\right)\\right)\\leq\\left(2n c^{2}/\\varepsilon+2\\right)p\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 45}, {"type": "text", "text": "Answer:[Yes] ", "page_idx": 45}, {"type": "text", "text": "Justification: In both abstract and introduction, we highlight the contribution in our paper. The proposed algorithm and the corresponding theoretical results are discussed in the followedsections. ", "page_idx": 45}, {"type": "text", "text": "Guidelines: ", "page_idx": 45}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and refect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 45}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 45}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 46}, {"type": "text", "text": "Justification: We explicitly list all the necessary assumptions for our theoretical analysis. Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should refect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 46}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 46}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Justification: We state all the assumptions in Section 2 and give the proof of theorems in the appendix. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 46}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 46}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 46}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 46}, {"type": "text", "text": "Justification:The paper does not include experiments. ", "page_idx": 46}, {"type": "text", "text": "Guidelines: ", "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 47}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 47}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "Justification: Paper does not include experiments requiring code ", "page_idx": 47}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https : //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so ^No\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. ", "page_idx": 47}, {"type": "text", "text": "\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). \u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 48}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 48}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 48}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 48}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 48}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 48}, {"type": "text", "text": "Guidelines: \u00b7 The answer NA means that the paper does not include experiments. ", "page_idx": 48}, {"type": "text", "text": "\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 49}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 49}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 49}, {"type": "text", "text": "Justification: The research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 49}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 49}, {"type": "text", "text": "Justification: The paper is a theoretical work with no societal impact. ", "page_idx": 49}, {"type": "text", "text": "Guidelines: ", "page_idx": 49}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 49}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 49}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 49}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 50}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 50}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 50}, {"type": "text", "text": "Justification: We have described the related works, especially those work which our work is based on with proper citations in corresponding sections. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 50}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 50}, {"type": "text", "text": "Answer: [No] ", "page_idx": 50}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 50}, {"type": "text", "text": "Guidelines: ", "page_idx": 50}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetis used.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 50}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "page_idx": 50}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: This paper does not include crowdsourcing or human subjects. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 51}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 51}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 51}, {"type": "text", "text": "Justification: This paper does not include crowdsourcing or human subjects. ", "page_idx": 51}, {"type": "text", "text": "Guidelines: ", "page_idx": 51}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 51}]