[{"figure_path": "u9ShP64FJV/figures/figures_1_1.jpg", "caption": "Figure 1: (left) Normal jailbreak process attacks aligned LLMs, where red parts represent an example of adversarial prefix and suffix. (right) Our IBProtector extracts compression information related to expected responses to mitigate jailbreaking attacks on LLMs.", "description": "This figure illustrates the difference between a normal jailbreaking attack and the proposed defense mechanism, IBProtector.  The left panel shows a standard jailbreaking attack where an adversarial prompt (prefix and suffix) manipulates the LLM into generating harmful content. The right panel shows how IBProtector mitigates this by compressing and selectively perturbing the prompt, retaining only essential information needed for a safe response.  The colored sections highlight the adversarial components of the prompts.", "section": "1 Introduction"}, {"figure_path": "u9ShP64FJV/figures/figures_3_1.jpg", "caption": "Figure 2: The model framework of IBProtector, where fire and snowflake denote frozen and trained parameters, respectively, and the small language model is optional. Given an input prompt, the extractor can extract the most informative parts for the predictor to respond to.", "description": "The figure shows the architecture of the IBProtector, a defense mechanism against adversarial attacks on LLMs.  It consists of two main components: a trainable extractor and a frozen predictor. The extractor, which uses a small language model (optional) processes the input prompt and extracts the most informative parts.  This is done by creating a mask that highlights the important tokens for the prediction. This mask is generated by optimizing the compactness and informativeness of the extraction. The extracted, masked prompt is then fed into the frozen predictor, a target large language model. The predictor generates the response to the input prompt based on this extracted information. The training process involves minimizing a loss function that considers both the compactness (minimal information loss) and the prediction quality (accurate responses). The figure illustrates the flow of data through the different components and shows how the trained extractor learns to selectively preserve essential information and reduce noise in the input.", "section": "4 Information Bottleneck Protector"}, {"figure_path": "u9ShP64FJV/figures/figures_6_1.jpg", "caption": "Figure 1: (left) Normal jailbreak process attacks aligned LLMs, where red parts represent an example of adversarial prefix and suffix. (right) Our IBProtector extracts compression information related to expected responses to mitigate jailbreaking attacks on LLMs.", "description": "This figure compares the normal jailbreaking process with the proposed IBProtector defense mechanism.  The left side shows a standard jailbreak attack, highlighting how adversarial prefixes and suffixes are used to manipulate an LLM into generating harmful content.  The right side illustrates how IBProtector works by selectively compressing and perturbing the input prompt, removing extraneous information that could trigger a harmful response while preserving essential details needed for a safe and appropriate answer.", "section": "1 Introduction"}, {"figure_path": "u9ShP64FJV/figures/figures_7_1.jpg", "caption": "Figure 4: IBProtector's extractor and Smooth LLMs defense results from other target models, where a lower ASR is better. IBProtector is interpreted as masking the most useless information, whereas Smooth is interpreted as randomizing masks where the number of copies is a way of ensemble masks.", "description": "This figure shows the transferability of IBProtector and Smooth LLMs across different LLMs.  The attack success rate (ASR) is shown for each model, comparing the original attack with IBProtector and Smooth LLMs (with 1, 2, and 4 copies). IBProtector demonstrates significantly lower ASRs across all tested models, highlighting its generalizability.  The Smooth LLM results show that increasing the number of copies (ensemble) improves its performance, but still significantly underperforms IBProtector.", "section": "5.3 Transferability"}, {"figure_path": "u9ShP64FJV/figures/figures_8_1.jpg", "caption": "Figure 2: The model framework of IBProtector, where fire and snowflake denote frozen and trained parameters, respectively, and the small language model is optional. Given an input prompt, the extractor can extract the most informative parts for the predictor to respond to.", "description": "This figure shows the architecture of the IBProtector model, which consists of a trainable extractor and a frozen predictor.  The extractor takes an input prompt and selectively compresses it, preserving only the essential information needed for the predictor to generate the appropriate response. The small language model is optional and serves as a component of the extractor.  The figure uses visual metaphors (fire and snowflake) to denote the frozen (pre-trained) and trained model components respectively. The overall design aims to improve the robustness of LLMs against adversarial prompts by focusing on informative content and reducing the impact of irrelevant information.", "section": "4 Information Bottleneck Protector"}, {"figure_path": "u9ShP64FJV/figures/figures_18_1.jpg", "caption": "Figure 1: (left) Normal jailbreak process attacks aligned LLMs, where red parts represent an example of adversarial prefix and suffix. (right) Our IBProtector extracts compression information related to expected responses to mitigate jailbreaking attacks on LLMs.", "description": "This figure shows a comparison between the normal jailbreaking process and the proposed IBProtector method. The left side illustrates a normal jailbreak attack where an adversarial prompt (with malicious prefix and suffix highlighted in red) causes the language model to generate harmful content.  The right side shows how IBProtector mitigates this by extracting only essential information from the prompt, compressing it, and then feeding the compressed information to the language model, preventing the generation of harmful content.", "section": "1 Introduction"}, {"figure_path": "u9ShP64FJV/figures/figures_20_1.jpg", "caption": "Figure 2: The model framework of IBProtector, where fire and snowflake denote frozen and trained parameters, respectively, and the small language model is optional. Given an input prompt, the extractor can extract the most informative parts for the predictor to respond to.", "description": "The figure shows the architecture of the IBProtector model. It consists of two main components: a trainable extractor and a frozen predictor. The extractor takes an input prompt and outputs a compressed sub-prompt, highlighting only the most informative parts. The predictor then uses this sub-prompt to generate a response, without needing to modify the underlying LLM. A small language model is optionally included to help the extractor, but it's not a requirement for the process to work. The figure uses fire and snowflake icons to represent the frozen (pre-trained) and trainable parts of the model.", "section": "4 Information Bottleneck Protector"}, {"figure_path": "u9ShP64FJV/figures/figures_22_1.jpg", "caption": "Figure 2: The model framework of IBProtector, where fire and snowflake denote frozen and trained parameters, respectively, and the small language model is optional. Given an input prompt, the extractor can extract the most informative parts for the predictor to respond to.", "description": "The figure shows the architecture of the IBProtector model, which consists of a trainable extractor and a frozen predictor. The extractor takes an input prompt and extracts the most informative parts, which are then passed to the predictor to generate a response.  The small language model is optional and can be used to further enhance the performance of the extractor. The figure also highlights the different components of the model and their interactions.", "section": "4 Information Bottleneck Protector"}, {"figure_path": "u9ShP64FJV/figures/figures_23_1.jpg", "caption": "Figure 2: The model framework of IBProtector, where fire and snowflake denote frozen and trained parameters, respectively, and the small language model is optional. Given an input prompt, the extractor can extract the most informative parts for the predictor to respond to.", "description": "The figure shows the architecture of the IBProtector model, which consists of a trainable extractor and a frozen predictor.  The extractor takes an input prompt and extracts the most informative parts. These informative parts are then passed to the predictor, which generates the response. A small language model is used optionally to improve the performance of the extractor. The figure highlights that the parameters of the extractor are trained, while the parameters of the predictor are frozen.", "section": "4 Information Bottleneck Protector"}, {"figure_path": "u9ShP64FJV/figures/figures_24_1.jpg", "caption": "Figure 2: The model framework of IBProtector, where fire and snowflake denote frozen and trained parameters, respectively, and the small language model is optional. Given an input prompt, the extractor can extract the most informative parts for the predictor to respond to.", "description": "The figure shows the architecture of the IBProtector, a defense mechanism against adversarial attacks on LLMs.  It consists of two main components: a trainable extractor and a frozen predictor. The extractor processes the input prompt and selectively extracts the most informative parts, compressing the prompt while preserving essential information for the LLM to generate the expected response. The predictor then uses this compressed information to generate the response.  A small language model is optionally included in the extractor to aid in the process.  The figure uses visual metaphors (fire and snowflake) to represent the frozen and trained parameters respectively.", "section": "4 Information Bottleneck Protector"}]