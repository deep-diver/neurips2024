[{"figure_path": "u9ShP64FJV/tables/tables_6_1.jpg", "caption": "Table 1: Defense results of state-of-the-art methods and IBProtector on AdvBench.", "description": "This table presents a comparison of the performance of several defense methods, including IBProtector, against two types of adversarial attacks (prompt-level and token-level) on the AdvBench dataset.  The metrics used for comparison include Attack Success Rate (ASR), Harm Score (lower is better, indicating less harmful outputs), GPT-4 Score (lower is better), and Benign Answering Rate (BAR, higher is better, showing the ability to correctly answer benign questions).  The table shows that IBProtector outperforms the other methods in mitigating both types of attacks while maintaining a high BAR.", "section": "5 Main Results"}, {"figure_path": "u9ShP64FJV/tables/tables_7_1.jpg", "caption": "Table 2: Evaluating the transferability of defensibility on EasyJailbreak datasets, where original adversarial prompts are generated by Autodan, GPTFuzz, and ReNellm.", "description": "This table presents the results of evaluating the transferability of the IBProtector's defense mechanism.  It shows the attack success rate (ASR), harm score, and GPT-4 score for different attack methods (original attacks and defense methods) on two different LLMs (Vicuna and LLaMA-2).  The goal is to assess how well IBProtector, trained on specific attacks, performs against unseen attack methods and LLMs.", "section": "5.3 Transferability"}, {"figure_path": "u9ShP64FJV/tables/tables_15_1.jpg", "caption": "Table 4: Comparison between our IBProtector and other defense methodologies.", "description": "This table compares the proposed IBProtector method with six other existing defense methods against adversarial attacks on LLMs.  The comparison is made across several key characteristics: whether each method involves fine-tuning, utilizes a filter mechanism, employs ensemble methods, performs information extraction, demonstrates transferability to unseen attacks or LLMs, supports black-box settings (without modifying the LLM), and the overall computational cost.  The table provides a concise overview of the strengths and weaknesses of various LLM defense approaches.", "section": "5 Experiments"}, {"figure_path": "u9ShP64FJV/tables/tables_18_1.jpg", "caption": "Table 1: Defense results of state-of-the-art methods and IBProtector on AdvBench.", "description": "This table presents a comparison of the performance of various defense methods, including the proposed IBProtector, against two types of jailbreaking attacks (PAIR and GCG) on two different LLMs (Vicuna and LLaMA-2).  The results are evaluated using three metrics: Attack Success Rate (ASR), Harm Score, and GPT-4 Score. Lower scores for ASR and Harm indicate better defense performance.  The TriviaQA BAR (Benign Answering Rate) is also included, with higher scores being preferable for maintaining the ability to answer benign questions.", "section": "5 Main Results"}, {"figure_path": "u9ShP64FJV/tables/tables_21_1.jpg", "caption": "Table 6: Performance report on IBProtector with or without autoregressive sampling.", "description": "This table presents the performance comparison between IBProtector with and without autoregressive sampling.  It shows the Attack Success Rate (ASR), Harm score, GPT-4 score, and Benign Answering Rate (BAR) for both prompt-level (PAIR) and token-level (GCG) jailbreaking attacks on two different LLMs: Vicuna and LLaMA-2.  Lower ASR and Harm scores indicate better performance, while a higher BAR indicates better preservation of normal functionality. The results demonstrate the impact of autoregressive sampling on the overall effectiveness of the IBProtector defense mechanism.", "section": "5.2 Main Results"}, {"figure_path": "u9ShP64FJV/tables/tables_21_2.jpg", "caption": "Table 7: Attack success rate for Cipher attacks [45] with valid responses on GPT-4.", "description": "This table presents the attack success rates of several methods against cipher-based attacks on GPT-4. The methods include the original attack, Smooth LLM, RA-LLM, Semantic Smooth, and IBProtector. The ciphers used are ASCII, Caesar, Morse, and Self Cipher. The results show the effectiveness of each defense method against different types of cipher-based attacks.", "section": "5.3 Transferability"}, {"figure_path": "u9ShP64FJV/tables/tables_22_1.jpg", "caption": "Table 1: Defense results of state-of-the-art methods and IBProtector on AdvBench.", "description": "This table presents a comparison of the performance of various defense methods, including the proposed IBProtector, against two types of jailbreak attacks (PAIR and GCG) on the AdvBench dataset.  The results are evaluated using three metrics: Attack Success Rate (ASR), Harm Score, and GPT-4 Score. Lower scores generally indicate better defense performance.  The table also includes the performance on the TriviaQA dataset to assess the impact on benign prompts.", "section": "5 Main Results"}, {"figure_path": "u9ShP64FJV/tables/tables_23_1.jpg", "caption": "Table 9: Effect of different IBProtector extractors on defense performance.", "description": "This table presents the results of experiments evaluating the impact of different small language models used as extractors within the IBProtector framework.  It shows the Attack Success Rate (ASR), Harm score reduction, GPT-4 score reduction, and Benign Answering Rate (BAR) for both prompt-level (PAIR) and token-level (GCG) attacks, along with the results for a baseline TriviaQA dataset. The goal is to assess how well different extractors generalize across various LLMs and attack methods.  The table helps determine the effectiveness of the IBProtector defense mechanism in mitigating jailbreak attempts and its generalizability across different attack methods.", "section": "5 Experiments"}, {"figure_path": "u9ShP64FJV/tables/tables_24_1.jpg", "caption": "Table 1: Defense results of state-of-the-art methods and IBProtector on AdvBench.", "description": "This table presents a comparison of the performance of various defense methods, including the proposed IBProtector, against two types of adversarial attacks (PAIR and GCG) on the AdvBench dataset.  It shows the Attack Success Rate (ASR), Harm score reduction, and GPT-4 score reduction for each method.  Lower values for ASR, Harm, and GPT-4 indicate better defense performance.  The table also includes the Benign Answering Rate (BAR) on the TriviaQA dataset, with higher values indicating better preservation of the ability to answer benign questions.  The results demonstrate IBProtector's superior performance compared to other methods.", "section": "5 Main Results"}, {"figure_path": "u9ShP64FJV/tables/tables_24_2.jpg", "caption": "Table 1: Defense results of state-of-the-art methods and IBProtector on AdvBench.", "description": "This table presents a comparison of the performance of IBProtector against other state-of-the-art defense methods on the AdvBench dataset.  It evaluates performance across three metrics (Attack Success Rate (ASR), Harm Score, and GPT-4 Score) for both prompt-level (PAIR) and token-level (GCG) jailbreaking attacks.  Lower scores for ASR and Harm indicate better defense performance, while higher scores for GPT-4 indicate better preservation of response quality.  The table shows that IBProtector significantly outperforms the other methods.", "section": "5 Main Results"}]