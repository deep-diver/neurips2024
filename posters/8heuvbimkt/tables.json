[{"figure_path": "8HeUvbImKT/tables/tables_6_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the OOD detection results of the proposed WeiPer method and other state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet-1k.  The results are reported in terms of AUROC (Area Under the Receiver Operating Characteristic Curve) and FPR95 (False Positive Rate at 95% True Positive Rate).  The table also includes ablation studies for the WeiPer method to analyze the impact of different components.  The performance of WeiPer+KLD is highlighted, showing its strengths on near-OOD datasets, especially when using ResNet backbones.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_7_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the out-of-distribution (OOD) detection results of the proposed WeiPer method and other state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet.  It shows the Area Under the Receiver Operating Characteristic curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR95) for both near and far OOD datasets.  The table highlights WeiPer's performance, especially on challenging near-OOD scenarios, and includes ablation studies to analyze the impact of different components of the method.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_8_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the OOD detection performance of WeiPer and other state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet.  It shows the Area Under the Receiver Operating Characteristic curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR95) for both \"near\" and \"far\" out-of-distribution (OOD) datasets.  The table highlights WeiPer's performance, particularly its strength on \"near\" OOD datasets using ResNet backbones, and includes ablation studies showing results with and without certain components of the method.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_15_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the OOD detection results of the proposed WeiPer method and other state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet.  The results are shown for both \"near\" and \"far\" out-of-distribution (OOD) datasets, indicating the proximity of the OOD data to the training distribution.  The table highlights the median AUROC (Area Under the Receiver Operating Characteristic curve) and FPR95 (False Positive Rate at 95% True Positive Rate) scores across multiple runs, demonstrating WeiPer's performance relative to existing methods. Ablation studies are also shown for CIFAR10 to analyze the effect of different components of the WeiPer method.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_15_2.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents a comparison of the Area Under the Receiver Operating Characteristic Curve (AUROC) and False Positive Rate at 95% True Positive Rate (FPR95) for various OOD detection methods on three benchmark datasets (CIFAR10, CIFAR100, and ImageNet).  The results are broken down by whether the Out-of-Distribution (OOD) data is positioned near or far from the training set distribution.  The table highlights the performance of the proposed WeiPer method and its variations (WeiPer+MSP, WeiPer+KLD, WeiPer+ReAct)  in comparison to existing state-of-the-art techniques.  Ablation studies for the WeiPer+KLD method are shown for CIFAR10, demonstrating its effectiveness in specific scenarios.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_15_3.jpg", "caption": "Table 6: AUROC results on ImageNet with ResNet50 on the near and far benchmark with different training set sizes. Each split is a random sample of the data set with each class appearing exactly as often as each other class. We chose the optimal set of hyperparameters on ImageNet, but reduced the number of repeats r to 50 instead of 100.", "description": "This table presents the Area Under the Receiver Operating Characteristic Curve (AUROC) scores for the ImageNet dataset using the ResNet50 model.  The results are shown for both \"near\" and \"far\" out-of-distribution (OOD) datasets,  and they are broken down by different training set sizes (1k, 5k, 10k, 50k, 100k, 500k, and 1M samples).  The experiment used the optimal hyperparameters determined previously, but with a reduced number of weight perturbations (r=50) for computational reasons. This reduction in perturbations could explain any differences between these results and those reported earlier in the paper.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_16_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the out-of-distribution (OOD) detection results of the proposed WeiPer method and several state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet.  The table shows the AUROC and FPR95 scores for each method on near and far OOD datasets.  It highlights WeiPer+KLD's strong performance, particularly on near OOD data, when using ResNet backbones, while also noting its reduced performance on ViT backbones. Ablation studies on CIFAR10 using WeiPer+KLD are included for comparison.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_17_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the out-of-distribution (OOD) detection results of the proposed WeiPer method and several state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet.  The table shows AUROC and FPR95 scores for both near and far OOD datasets.  It highlights WeiPer's competitive performance, especially on ResNet backbones, while noting the performance differences using ViT models.  Ablation studies comparing different WeiPer configurations are also included.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_18_1.jpg", "caption": "Table 9: Plotting parameters: s is the kernel size for the uniform kernel that was used for smoothing, and maxp = maxt Ez\u2208Ztrain [Pz](t) denotes the maximum of the mean density of the penultimate densities pt. The perturbed densities p\u0175z are scaled similarly.", "description": "This table presents the hyperparameters used for creating the density plots shown in Figures 3, 7, and 8.  Specifically, it lists the number of bins used in the histograms (nbins), the kernel size (s) used for smoothing the density estimates, and the maximum value of the mean density of the penultimate layer activations (maxp).  These parameters are crucial for visualizing and analyzing the activation distributions in both the original and perturbed feature spaces, which are key components in understanding and evaluating the performance of the WeiPer method.", "section": "A.4 Penultimate layer distribution"}, {"figure_path": "8HeUvbImKT/tables/tables_19_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the out-of-distribution (OOD) detection performance of the proposed WeiPer method and several state-of-the-art methods across three benchmark datasets: CIFAR-10, CIFAR-100, and ImageNet.  The table shows AUROC and FPR95 scores for both near and far OOD datasets. It highlights WeiPer+KLD's superior performance, particularly in challenging near OOD scenarios with ResNet backbones, and also points out its relative weakness with ViT backbones.  Ablation studies comparing WeiPer+KLD with and without MSP, and with random projections are also presented for the CIFAR-10 dataset.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_19_2.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the out-of-distribution (OOD) detection results of WeiPer and other state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet.  The table shows AUROC and FPR95 scores for each method on near and far OOD datasets. It highlights WeiPer's performance, particularly its strong results on near OOD datasets using ResNet backbones and its comparative performance on ViT backbones.  Ablation studies on CIFAR10, comparing WeiPer+KLD with and without MSP and with random projections, are also included.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_20_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the Area Under the Receiver Operating Characteristic curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR95) for various OOD detection methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet.  The table compares WeiPer against other state-of-the-art methods, highlighting WeiPer's performance, particularly on datasets where OOD samples are similar to in-distribution samples.  Ablation studies are also included for CIFAR10, showing the performance of WeiPer+KLD with and without Maximum Softmax Probability (MSP) and with random projections.  The results show that WeiPer+KLD performs well on ResNet backbones, but its performance declines when using Vision Transformer (ViT) backbones.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_20_2.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the out-of-distribution (OOD) detection performance of WeiPer and other state-of-the-art methods on three benchmark datasets: CIFAR-10, CIFAR-100, and ImageNet.  The results are reported in terms of AUROC and FPR95 metrics for both near and far OOD datasets.  The table also includes ablation studies for WeiPer, showing the effect of removing specific components and using random projections instead of WeiPer's weight perturbations.  The table highlights WeiPer+KLD's strong performance, especially on near OOD datasets, but also notes its performance degradation with Vision Transformers (ViTs).", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_21_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the results of the OOD detection performance comparison between WeiPer and other state-of-the-art methods on three benchmark datasets: CIFAR10, CIFAR100, and ImageNet-1K.  The table shows AUROC and FPR95 scores for near and far OOD datasets. It highlights WeiPer's superior performance on several benchmarks, particularly those with ResNet backbones and near OOD datasets.  Ablation studies using different configurations of WeiPer are also included for comparison.", "section": "4 Experiments"}, {"figure_path": "8HeUvbImKT/tables/tables_22_1.jpg", "caption": "Table 2: OOD Detection results of top performing methods on the CIFAR10, CIFAR100 and ImageNet-1K benchmarks (For a comparison with every other evaluated method of OpenOOD and standard deviation over the CIFAR models, see Appendices A.5 and A.6). The top performing results for each benchmark are displayed in bold and we underline the second best result. Due to WeiPer's random nature, we report the median AUROC score over 10 different seeds. For an easy comparison, we portray the following ablations for CIFAR10 which are seperated by a line: The KLD results are the WeiPer+KLD results without MSP and RP is WeiPer+KLD with weight independent random projections drawn from a standard Gaussian. While WeiPer+KLD performs strongly especially on near datasets using ResNet backbones, its performance deteriorates with ViTs (see Section 4 for discussion).", "description": "This table presents the Area Under the ROC Curve (AUROC) and False Positive Rate at 95% True Positive Rate (FPR95) for various OOD detection methods on CIFAR10, CIFAR100, and ImageNet datasets using ResNet and ViT backbones.  The table highlights the performance of WeiPer and its variants (WeiPer+MSP, WeiPer+ReAct, WeiPer+KLD) compared to other state-of-the-art methods.  It also shows ablation studies for WeiPer+KLD to understand the effects of removing the MSP and using random projections.", "section": "4 Experiments"}]