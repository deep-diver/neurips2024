<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions &#183; NeurIPS 2024</title>
<meta name=title content="Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions &#183; NeurIPS 2024"><meta name=description content="AI models retraining with model-annotated data incorporating human strategic responses can lead to unexpected outcomes, potentially reducing the proportion of agents with positive labels over time, wh..."><meta name=keywords content="AI Theory,Fairness,üè¢ Ohio State University,"><link rel=canonical href=https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/><link type=text/css rel=stylesheet href=/neurips2024/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/neurips2024/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/neurips2024/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/neurips2024/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/neurips2024/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/neurips2024/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/neurips2024/favicon-16x16.png><link rel=manifest href=/neurips2024/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/"><meta property="og:site_name" content="NeurIPS 2024"><meta property="og:title" content="Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions"><meta property="og:description" content="AI models retraining with model-annotated data incorporating human strategic responses can lead to unexpected outcomes, potentially reducing the proportion of agents with positive labels over time, wh‚Ä¶"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posters"><meta property="article:published_time" content="2024-09-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-26T00:00:00+00:00"><meta property="article:tag" content="AI Theory"><meta property="article:tag" content="Fairness"><meta property="article:tag" content="üè¢ Ohio State University"><meta property="og:image" content="https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/cover.png"><meta name=twitter:title content="Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions"><meta name=twitter:description content="AI models retraining with model-annotated data incorporating human strategic responses can lead to unexpected outcomes, potentially reducing the proportion of agents with positive labels over time, wh‚Ä¶"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posters","name":"Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions","headline":"Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions","abstract":"AI models retraining with model-annotated data incorporating human strategic responses can lead to unexpected outcomes, potentially reducing the proportion of agents with positive labels over time, wh\u0026hellip;","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/neurips2024\/posters\/2ujlv3kpgo\/","author":{"@type":"Person","name":"AI Paper Reviewer"},"copyrightYear":"2024","dateCreated":"2024-09-26T00:00:00\u002b00:00","datePublished":"2024-09-26T00:00:00\u002b00:00","dateModified":"2024-09-26T00:00:00\u002b00:00","keywords":["AI Theory","Fairness","üè¢ Ohio State University"],"mainEntityOfPage":"true","wordCount":"6858"}]</script><meta name=author content="AI Paper Reviewer"><link href=https://neurips.cc/ rel=me><link href=https://x.com/NeurIPSConf rel=me><link href rel=me><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://x.com/algo_diver/ rel=me><script src=/neurips2024/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/neurips2024/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/neurips2024/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/neurips2024/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/neurips2024/ class="text-base font-medium text-gray-500 hover:text-gray-900">NeurIPS 2024</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/neurips2024/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Oral
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/neurips2024/oral-ai-applications/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) AI Applications</p></a><a href=/neurips2024/oral-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) AI Theory</p></a><a href=/neurips2024/oral-image-generation/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Image Generation</p></a><a href=/neurips2024/oral-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Large Language Models</p></a><a href=/neurips2024/oral-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Others</p></a><a href=/neurips2024/oral-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Reinforcement Learning</p></a></div></div></div></div><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Spotlight
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/neurips2024/spotlight-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) AI Theory</p></a><a href=/neurips2024/spotlight-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Large Language Models</p></a><a href=/neurips2024/spotlight-optimization/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Optimization</p></a><a href=/neurips2024/spotlight-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Others</p></a><a href=/neurips2024/spotlight-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Reinforcement Learning</p></a></div></div></div></div><a href=/neurips2024/posters/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Posters</p></a><a href=/neurips2024/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/neurips2024/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Oral</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/neurips2024/oral-ai-applications/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) AI Applications</p></a></li><li class=mt-1><a href=/neurips2024/oral-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) AI Theory</p></a></li><li class=mt-1><a href=/neurips2024/oral-image-generation/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Image Generation</p></a></li><li class=mt-1><a href=/neurips2024/oral-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Large Language Models</p></a></li><li class=mt-1><a href=/neurips2024/oral-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Others</p></a></li><li class=mt-1><a href=/neurips2024/oral-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Reinforcement Learning</p></a></li><li class=mb-2></li><li class=mt-1><a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Spotlight</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/neurips2024/spotlight-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) AI Theory</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Large Language Models</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-optimization/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Optimization</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Others</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Reinforcement Learning</p></a></li><li class=mb-2></li><li class=mt-1><a href=/neurips2024/posters/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Posters</p></a></li><li class=mt-1><a href=/neurips2024/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/neurips2024/posters/2ujlv3kpgo/cover_hu1984834314651141689.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/>NeurIPS 2024</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/posters/>Posters</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/posters/2ujlv3kpgo/>Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">Automating Data Annotation under Strategic Human Agents: Risks and Potential Solutions</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time><span class="px-2 text-primary-500">&#183;</span><span>6858 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">33 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_posters/2UJLv3KPGO/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_posters/2UJLv3KPGO/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/ai-theory/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">AI Theory
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/fairness/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Fairness
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/-ohio-state-university/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Ohio State University</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviewer" src=/neurips2024/img/avatar_hu1344562329374673026.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviewer</div><div class="text-sm text-neutral-700 dark:text-neutral-400">As an AI, I specialize in crafting insightful blog content about cutting-edge research in the field of artificial intelligence</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://neurips.cc/ target=_blank aria-label=Homepage rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg fill="currentcolor" height="800" width="800" id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 491.398 491.398"><g><g id="Icons_19_"><path d="M481.765 220.422 276.474 15.123c-16.967-16.918-44.557-16.942-61.559.023L9.626 220.422c-12.835 12.833-12.835 33.65.0 46.483 12.843 12.842 33.646 12.842 46.487.0l27.828-27.832v214.872c0 19.343 15.682 35.024 35.027 35.024h74.826v-97.62c0-7.584 6.146-13.741 13.743-13.741h76.352c7.59.0 13.739 6.157 13.739 13.741v97.621h74.813c19.346.0 35.027-15.681 35.027-35.024V239.091l27.812 27.815c6.425 6.421 14.833 9.63 23.243 9.63 8.408.0 16.819-3.209 23.242-9.63 12.844-12.834 12.844-33.65.0-46.484z"/></g></g></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/NeurIPSConf target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href target=_blank aria-label=Line rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 14.707 14.707"><g><rect x="6.275" y="0" style="fill:currentColor" width="2.158" height="14.707"/></g></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/algo_diver/ target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#strategic-agents-impact>Strategic Agents&rsquo; Impact</a></li><li><a href=#model-retraining-risks>Model Retraining Risks</a></li><li><a href=#fairness-in-dynamics>Fairness in Dynamics</a></li><li><a href=#algorithmic-refinement>Algorithmic Refinement</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#strategic-agents-impact>Strategic Agents&rsquo; Impact</a></li><li><a href=#model-retraining-risks>Model Retraining Risks</a></li><li><a href=#fairness-in-dynamics>Fairness in Dynamics</a></li><li><a href=#algorithmic-refinement>Algorithmic Refinement</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>2UJLv3KPGO</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Tian Xie et el.</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href="https://openreview.net/forum?id=2UJLv3KPGO" target=_blank role=button>‚Üó OpenReview
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://neurips.cc/virtual/2024/poster/96814 target=_blank role=button>‚Üó NeurIPS Homepage
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href="https://huggingface.co/spaces/huggingface/paper-central?tab=tab-chat-with-paper&amp;paper_id=2UJLv3KPGO&amp;paper_from=neurips" target=_blank role=button>‚Üó Chat</a></p><audio controls><source src=https://ai-paper-reviewer.com/2UJLv3KPGO/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Many AI systems, especially those making consequential decisions about humans, are retrained periodically using model-generated annotations. However, humans often act strategically, adapting their behavior in response to these systems. This raises critical questions around the long-term impacts of these retraining processes on both model performance and fairness. The paper highlights risks associated with this common practice, demonstrating that the proportion of agents receiving positive labels can decrease over time, despite an increase in the overall acceptance rate.</p><p>To address these issues, the researchers propose a refined retraining process that uses probabilistic sampling for model annotations. This approach aims to stabilize the system dynamics and prevent potentially adverse outcomes. They analyze how algorithmic fairness is affected by retraining, revealing that enforcing standard fairness constraints at each retraining step may not always benefit disadvantaged groups. Experiments using synthetic and real-world datasets validate their theoretical findings, demonstrating the impact of strategic behavior on model retraining and highlighting the need for more sophisticated approaches to data annotation and fairness.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-788f1cd09ad43aeff1af1cdd994765b9></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-788f1cd09ad43aeff1af1cdd994765b9",{strings:[" Retraining ML models with model-annotated data in strategic settings can lead to unexpected long-term dynamics. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-37ee9643195e87316b9e180cd82d5370></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-37ee9643195e87316b9e180cd82d5370",{strings:[" Agents become increasingly likely to receive positive decisions as the model is retrained, but the overall proportion of positive labels can decrease. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-e6e179717e2e1779e432bb6e8514df51></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-e6e179717e2e1779e432bb6e8514df51",{strings:[" Enforcing fairness constraints in each retraining round may not benefit disadvantaged groups in the long run. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is crucial because <strong>it addresses the critical issue of automating data annotation in social domains where human behavior is strategic</strong>. It offers a novel framework for understanding long-term impacts of model retraining with strategic feedback, informing the development of more robust and fair AI systems. The findings are directly relevant to current trends in AI fairness and data feedback loops, opening new avenues for algorithmic fairness research and system design.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_0_1.jpg alt></figure></p><blockquote><p>This figure illustrates the iterative process of updating the training dataset used for retraining the ML model. It shows how the model&rsquo;s annotations, along with human annotations, are combined to create the new training dataset. The strategic feedback from agents is incorporated into the process by showing how their behavior changes in response to the current model. This continuous feedback and retraining loop is a central component of the paper&rsquo;s investigation into the long-term impacts of model retraining with strategic human feedback.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/tables_7_1.jpg alt></figure></p><blockquote><p>The table describes the settings used for generating the synthetic Gaussian dataset used in the experiments. It includes the distributions of the features (PX(Xk)), the conditional probability of the label given the features (P Y|X(1|x)), and the hyperparameters used for the experiments (n, r, T, q0). These parameters control various aspects of the experiment, such as the number of agents, the ratio of human-annotated to model-annotated samples, the number of training rounds, and the initial qualification rate.</p></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">Strategic Agents&rsquo; Impact<div id=strategic-agents-impact class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#strategic-agents-impact aria-label=Anchor>#</a></span></h4><p>The concept of &ldquo;Strategic Agents&rsquo; Impact&rdquo; in the context of machine learning models centers on how human users, aware of the model&rsquo;s decision-making process, adapt their behavior to obtain favorable outcomes. This strategic interaction significantly affects model performance and fairness over time. <strong>Humans, acting as strategic agents, may modify their features or actions to increase their likelihood of receiving a positive prediction.</strong> This behavior leads to a skewed data distribution that is no longer representative of the true population, ultimately reducing the model&rsquo;s accuracy and generalizability. <strong>Retraining the model with this strategically manipulated data further exacerbates the issue</strong>, creating a feedback loop where the model becomes increasingly biased towards rewarding strategic behavior. The long-term effects can be particularly detrimental, with the possibility of decreasing the overall proportion of agents with positive labels while individual agents increasingly receive positive decisions. Addressing this necessitates robust model retraining techniques that mitigate the impact of strategic behavior and maintain model fairness. <strong>Strategies like incorporating probabilistic sampling during model annotation or early stopping of retraining processes can help stabilize this dynamic and mitigate the risk of biased outcomes.</strong> Furthermore, carefully considering algorithmic fairness constraints throughout the retraining procedure is crucial to minimize potential societal biases and ensure equitable treatment for all agents.</p><h4 class="relative group">Model Retraining Risks<div id=model-retraining-risks class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#model-retraining-risks aria-label=Anchor>#</a></span></h4><p>Model retraining, while crucial for maintaining high performance in machine learning systems, presents significant risks, especially when dealing with strategic human agents. <strong>Continuous retraining can lead to unintended feedback loops</strong>, where the model&rsquo;s updates influence human behavior, creating a dynamic system that&rsquo;s difficult to predict and control. This may result in <strong>unexpected and potentially harmful long-term consequences</strong>. For example, a model designed to assess loan applications might inadvertently incentivize applicants to manipulate their profiles, leading to a skewed population and inaccurate model assessment. Furthermore, <strong>retraining can exacerbate existing biases</strong> and even create new ones, particularly in scenarios where the training data is incomplete or model-annotated samples are used due to cost or time constraints. To mitigate these risks, <strong>a thorough understanding of the model-agent interaction dynamics is essential</strong>. This includes analyzing how human responses change over time, accounting for any bias in training datasets, and evaluating the impact of different retraining strategies on fairness and overall system performance. Finally, <strong>developing methods to stabilize these dynamics and enhance fairness</strong> is crucial, such as employing algorithmic fairness constraints during retraining or implementing more sophisticated methods for handling model-annotated samples.</p><h4 class="relative group">Fairness in Dynamics<div id=fairness-in-dynamics class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#fairness-in-dynamics aria-label=Anchor>#</a></span></h4><p>Analyzing fairness within dynamic systems presents unique challenges. <strong>Traditional fairness metrics, often designed for static datasets, may be inadequate when populations and models evolve over time.</strong> A model deemed fair initially might become unfair as agents strategically adapt their behavior in response. This necessitates the development of <strong>time-sensitive fairness metrics</strong> that account for evolving data distributions. Furthermore, <strong>interventions aimed at restoring fairness at each step may have unintended long-term consequences</strong>, potentially exacerbating disparities in the long run. Therefore, understanding how fairness interacts with these dynamic processes is vital, and research should explore both short-term corrective actions and long-term strategies to maintain fairness in the face of evolving data and strategic behavior.</p><h4 class="relative group">Algorithmic Refinement<div id=algorithmic-refinement class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#algorithmic-refinement aria-label=Anchor>#</a></span></h4><p>Algorithmic refinement, in the context of machine learning models interacting with strategic human agents, focuses on improving model behavior and mitigating potential negative consequences. <strong>Iterative retraining</strong>, a core component, involves periodically updating the model with new data, incorporating both human and model-generated annotations. However, naive retraining can lead to undesirable feedback loops where agents strategically adapt, creating skewed data distributions and potentially undermining model performance or fairness. <strong>Sophisticated refinement strategies</strong> might involve incorporating fairness constraints during retraining, weighting samples differently, or using probabilistic model annotations to reduce bias amplification. The choice of refinement technique is crucial, as it directly influences the long-term dynamics of agent behavior and model accuracy and impacts <strong>societal welfare</strong>. A key challenge lies in balancing model accuracy with fairness and stability over time to avoid unintended consequences. Successful refinement often necessitates a deep understanding of the interaction between strategic agents and the learning system.</p><h4 class="relative group">Future Research<div id=future-research class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h4><p>Future research directions stemming from this work on automating data annotation under strategic human agents could explore several key areas. <strong>Improving the robustness of the proposed refined retraining process</strong> to handle diverse scenarios and noisy data is crucial. This involves exploring more sophisticated probabilistic models and adaptive strategies to stabilize dynamics and enhance fairness. <strong>Investigating the long-term effects of different fairness constraints</strong> on both the agent population and the model itself warrants further study, especially under various group dynamics. A deeper examination of the interaction between systematic human bias and the model&rsquo;s bias amplification is needed, potentially employing causal inference techniques. <strong>Developing methods to quantify and mitigate the amplification of systematic biases</strong> during retraining is a crucial step toward building more equitable AI systems. Finally, extending this framework beyond binary classification to multi-class settings and more complex strategic agent behaviors will unlock more realistic and impactful applications.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_1_1.jpg alt></figure></p><blockquote><p>This figure shows the evolution of student distribution and the machine learning model over three different time points (t=0, t=5, t=14). Each point represents a student with two features. The green line represents the true classifier, while the black line shows the learned classifier at each time step. The figure illustrates how the learned classifier deviates from the true classifier over time, as students strategically adapt their behaviors in response to the model.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_4_1.jpg alt></figure></p><blockquote><p>This figure illustrates how the training dataset is updated iteratively in a model retraining process that incorporates feedback from strategic human agents. At each time step t, a model f‚Çú is trained using a dataset S‚Çú, which includes previously collected data (S‚Çú‚Çã‚ÇÅ), newly collected model-annotated samples (S‚Çò,‚Çú‚Çã‚ÇÅ), and newly collected human-annotated samples (S‚Çí,‚Çú‚Çã‚ÇÅ). The model is then used to make decisions that influence agents&rsquo; future behaviors, thus influencing the composition of data in the next time step.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_6_1.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process of the ML model and how the acceptance rate increases over time due to strategic feedback from agents. It shows how the model, trained with both human and model-annotated data, becomes more likely to accept agents over time, even though the true proportion of qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_8_1.jpg alt></figure></p><blockquote><p>This figure illustrates how the training data is updated from time t to time t+1, incorporating feedback from strategic agents. At time t, the model is trained on data from time t and human annotations. Agents respond strategically to the model at time t and their behavior is used to create model annotations at time t+1. At time t+1, the model is retrained with data from time t, human annotations, and model annotations.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_17_1.jpg alt></figure></p><blockquote><p>This figure visualizes the evolution of student distribution and the machine learning model over time. It shows how the model, retrained with both human and model-annotated data, adapts to strategic student behavior. The black lines represent the learned classifier at different times, while the green lines represent the ground truth. The figure illustrates how the classifier deviates from the ground truth over time, highlighting the challenges of retraining in dynamic strategic settings.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_17_2.jpg alt></figure></p><blockquote><p>This figure shows how the student distribution and the ML model evolve over time under the model retraining process with strategic feedback. Each student has two features, and the model is retrained with both human and model-annotated samples. Students strategically adapt their behaviors to maximize their chances of getting admitted. The figure shows that over time, the learned classifier deviates from the ground truth.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_18_1.jpg alt></figure></p><blockquote><p>This figure illustrates the dynamics of the acceptance rate over time as the model is retrained with strategic feedback. It shows how, even with an increase in the proportion of qualified agents in the training dataset, the acceptance rate continues to increase over time due to the model&rsquo;s adaptation to strategic agent behaviors.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_19_1.jpg alt></figure></p><blockquote><p>This figure shows how the distribution of students and the performance of the ML model change over time as the model is retrained with both human and model-annotated data. The students strategically adapt their behavior to maximize their chances of being admitted, which in turn affects the model&rsquo;s accuracy. Over time, the model&rsquo;s decision boundary deviates more and more from the actual boundary between qualified and unqualified students.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_19_2.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time in a strategic classification setting with model retraining. It shows how the model, retrained with both human and model-annotated data, adapts to strategic agent behavior, leading to an increased acceptance rate (proportion of agents classified as positive) over time, even if the actual proportion of qualified agents might not increase.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_19_3.jpg alt></figure></p><blockquote><p>This figure shows the evolution of student distribution and the machine learning model over time in a college admission scenario. Each student is represented by two features, and the model is periodically retrained with both human-annotated and model-annotated data. Students strategically adapt their behavior to maximize their chances of admission. The figure demonstrates how the model&rsquo;s performance deviates from the ground truth over time as students strategically respond to the changing admission policies.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_19_4.jpg alt></figure></p><blockquote><p>This figure shows how the student distribution and the ML model evolve over time in a college admission scenario. Each student has two features, and the model is retrained periodically with human- and model-annotated data. Students strategically adapt their behaviors to maximize their chances of admission. The figure illustrates that the model&rsquo;s performance deviates from the ground truth over time as students&rsquo; behavior changes.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_21_1.jpg alt></figure></p><blockquote><p>This figure visualizes the evolution of student distribution and the machine learning model over time. It shows how student distribution changes as they strategically respond to the model&rsquo;s admission decisions in each round. The model is retrained periodically using human and model-annotated data. The black lines represent the learned classifier, and the green lines represent the ground truth classifier. Over time, the learned classifier deviates from the ground truth classifier, highlighting the model&rsquo;s instability under strategic behaviors.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_22_1.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decisions shift towards accepting more agents, even if the proportion of truly qualified agents might decrease. The key point is the effect of model-annotated samples which may misclassify unqualified agents as qualified, positively influencing the next model&rsquo;s acceptance rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_22_2.jpg alt></figure></p><blockquote><p>This figure shows the evolution of student distribution and the ML model over time in a college admission scenario. The left, middle, and right panels represent time steps t=0, t=5, and t=14, respectively. Each student has two features. At each time step, a classifier is retrained using human-annotated and model-annotated samples. Students strategically adapt their application packages (features) to maximize their chances of admission (best response). The black lines depict the learned classifier at each time step, while the green lines represent the true, underlying classifier. The figure illustrates how, over time, the learned classifier deviates from the true classifier due to the dynamic interaction between the strategic students and the retraining process.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_22_3.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time as the model is retrained with strategic feedback. It shows how the model&rsquo;s decision boundary changes and how agents adapt their behaviors to receive favorable outcomes. The example uses circles and squares to show qualified/unqualified applicants, while red/blue denotes admitted/rejected. The evolution of the retraining process, from t to t+1, is also visualized.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_22_4.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and how the acceptance rate increases over time. It shows how the model&rsquo;s updates affect the agents&rsquo; behavior, leading to a higher acceptance rate in subsequent rounds.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_22_5.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and how the acceptance rate increases over time due to strategic behavior of agents and model retraining with model-annotated samples. It shows how the model becomes more likely to accept agents, even if the proportion of truly qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_22_6.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and the increasing acceptance rate over time. It shows how the model, trained on human and model-annotated data, updates its decision-making process, leading to a higher proportion of agents being accepted in each subsequent round.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_22_7.jpg alt></figure></p><blockquote><p>This figure illustrates the evolution of the acceptance rate over time. It shows how, due to strategic behavior and model retraining with model-annotated data, the model becomes increasingly likely to accept agents, even if the underlying qualification rate may not be increasing. The figure visually depicts the dynamics of agents&rsquo; best responses and how model retraining incorporates that feedback, contributing to a higher acceptance rate in later iterations.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_23_1.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and how the acceptance rate increases over time as the model is retrained with strategic feedback. The model is updated with both human and model-annotated data. The plots demonstrate the change in the proportion of qualified and unqualified agents, and the effect of model retraining on agent behavior and acceptance rates.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_23_2.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time in a model retraining process with strategic feedback. It shows how, even with a small initial number of qualified agents, subsequent retraining with model-annotated samples (which may have biases) leads to higher acceptance rates.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_23_3.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decisions influence agents&rsquo; behavior, leading to a higher proportion of qualified agents in the training data with each iteration, ultimately increasing the acceptance rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_23_4.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time in a model retraining process with strategic feedback from agents. It shows how the model becomes more likely to accept agents (increasing acceptance rate) as it&rsquo;s retrained on data that includes the agents&rsquo; strategic responses, even though the proportion of actually qualified agents may decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_23_5.jpg alt></figure></p><blockquote><p>This figure illustrates the dynamics of acceptance rate in the model retraining process with strategic feedback. It shows how the model gets increasingly likely to make positive decisions as it gets retrained, leading to an increase in the acceptance rate over time. The figure highlights the reinforcing process: agents strategically adapt their behaviors based on the model, leading to an increased proportion of positive labels in the retraining dataset, which further reinforces the tendency to make positive decisions in subsequent rounds.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_23_6.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time as the model is retrained with strategic feedback. It shows how the model&rsquo;s parameters shift towards accepting a higher proportion of agents, even if the actual qualification rate might decrease. The figure highlights the positive feedback loop between model retraining and agent strategic behavior.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_24_1.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time as the model is retrained with strategic feedback. It demonstrates the positive feedback loop where an increasingly &lsquo;generous&rsquo; model leads to more agents strategically modifying their features to receive favorable outcomes, further increasing the proportion of positive labels in the training dataset.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_24_2.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. It shows the evolution of the training data and the model&rsquo;s decisions, highlighting the effect of strategic agent responses and model annotations on the acceptance rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_24_3.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decision boundary shifts, leading to a higher proportion of agents being classified as positive, even if the proportion of actually qualified agents may decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_24_4.jpg alt></figure></p><blockquote><p>This figure shows the evolution of student distribution and the ML model over time (t=0, t=5, t=14). Each student has two features, and the model is retrained periodically with human and model-annotated samples. Students strategically adapt their behavior to maximize their chances of being admitted. The figure illustrates how the learned classifier deviates from the ground truth over time, highlighting the impact of strategic behavior and model retraining.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_24_5.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time in a model retraining process with strategic feedback. It visually represents how the model&rsquo;s decision-making changes in response to strategic agents (those who adjust their actions based on the model&rsquo;s decisions) and how this dynamic influences the proportion of agents positively labeled. The illustration highlights how the model, updated with model-annotated samples, tends to become increasingly more &rsquo;lenient&rsquo; over time, accepting a higher proportion of agents, even as the proportion of truly qualified agents may not increase.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_24_6.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and how the acceptance rate increases over time due to strategic behavior of agents. The left panel shows the initial training data, the middle panel shows the agents&rsquo; best responses to the model, and the right panel shows the updated training data after retraining, resulting in a higher acceptance rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_25_1.jpg alt></figure></p><blockquote><p>This figure shows the evolution of student distribution and the machine learning model over time. The left panel shows the initial state (t=0), the middle panel shows the state at t=5, and the right panel shows the state at t=14. Each student has two features, and the model is retrained at each time step with human and model-annotated data. Students strategically adapt their behavior to maximize their chances of admission. Over time, the learned model deviates significantly from the true underlying classifier.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_25_2.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to the model retraining process. The left plot shows the initial training data, where half of the agents are qualified. In the middle plot, the agents strategically respond to the model, and more of them become qualified. Finally, in the right plot, the model is retrained with both human and model-annotated data, leading to an even higher acceptance rate in the next round.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_25_3.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and how the acceptance rate increases over time. It shows how the model, trained with both human and model-annotated data, becomes more likely to accept agents, even if the proportion of actually qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_25_4.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time as the model is retrained with strategic feedback. It shows the training data at time t, the agents&rsquo; best responses at time t+1, and the updated training data at time t+1. The key observation is that the proportion of qualified agents increases with each retraining round, leading to higher acceptance rates.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_25_5.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. It shows the transition from time t to t+1, highlighting how the model&rsquo;s decisions (admissions) affect agent behavior (qualifications). The retraining process incorporates both human and model annotations, leading to an increasing proportion of positively labeled data and thus, a more &lsquo;generous&rsquo; classifier.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_25_6.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. It shows the evolution of the agent distribution and the classifier&rsquo;s decision boundary in three time steps (t, t+1, and t+2). The acceptance rate increases because the model becomes more &lsquo;generous&rsquo; over time, admitting more agents, even though the true qualification rate may decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_26_1.jpg alt></figure></p><blockquote><p>This figure illustrates the dynamics of the acceptance rate over time. It shows how the model retraining process with strategic feedback from agents leads to an increasing acceptance rate. The figure uses a visual representation of qualified and unqualified agents and how their classifications change through iterations of retraining.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_26_2.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback. It shows how the acceptance rate increases over time as the model is retrained with both human-annotated and model-annotated data. The figure highlights the impact of strategic agents who adapt their behaviors to receive favorable outcomes.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_26_3.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. The model becomes more likely to give positive decisions (admit agents) as it is retrained, even if the actual proportion of qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_26_4.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model becomes more generous over time, accepting a higher proportion of agents, even if the true proportion of qualified agents may not increase.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_26_5.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback and shows how the acceptance rate increases over time. It visually depicts the change in the training dataset from t to t+1, highlighting the impact of model-annotated samples and strategic responses on the acceptance rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_26_6.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time in the model retraining process with strategic feedback. It shows that even though the actual qualification rate might decrease, the model increasingly accepts more agents due to the positive feedback loop between strategic agents and model retraining.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_27_1.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time as the model is retrained with strategic feedback. It shows how the model becomes more likely to accept agents (even unqualified ones) as it learns from the best responses of strategic agents and model-annotated samples.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_27_2.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model becomes more likely to accept agents as it is retrained, even if the proportion of actually qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_27_3.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. It shows that even if the true qualification rate of the population decreases, the model&rsquo;s tendency to accept agents increases as the model is updated.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_27_4.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time as the model is retrained with strategic feedback. It shows how the model becomes more likely to accept agents, even if the proportion of qualified agents decreases.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_27_5.jpg alt></figure></p><blockquote><p>This figure visualizes the evolution of student data distribution and the machine learning model over time. It shows how the model&rsquo;s classification boundary changes as it&rsquo;s retrained with both human and model-annotated data, and how students strategically adapt their behavior to increase their chance of being admitted. The divergence between the learned model and the true underlying distribution is highlighted.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_27_6.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback from agents. It shows how the acceptance rate increases over time as the model is retrained with both human and model-annotated data. The retraining process amplifies the positive decisions for the agents.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_1.jpg alt></figure></p><blockquote><p>This figure shows how the student distribution and the ML model evolve over time (t=0, 5, 14) when the model is retrained with both human and model-annotated data, and students strategically respond to maximize admission chances. Each student has two features. The plot shows the learned classifier (black line) increasingly deviates from the true classifier (green line) over time.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_2.jpg alt></figure></p><blockquote><p>This figure shows how the student distribution and the ML model evolve over time (t=0, 5, 14). Each student has two features. The model is retrained periodically with human and model-annotated data, and students strategically adapt their behavior to maximize their chances of admission. The black lines represent the learned classifier, while the green lines represent the ground truth. Over time, the learned classifier deviates from the ground truth.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_3.jpg alt></figure></p><blockquote><p>This figure illustrates the evolution of the acceptance rate over time due to model retraining with strategic feedback. It demonstrates how the model becomes more &lsquo;generous&rsquo; over time, accepting a higher proportion of agents, even if the true qualification rate might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_4.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. It starts with a training set, then shows how agents strategically respond, and finally how the model is retrained with both human and model-annotated data, leading to a higher acceptance rate in the next round.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_5.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time in a model retraining process with strategic feedback. It shows how the model&rsquo;s annotations, combined with human annotations, shift the training data distribution towards a higher proportion of positively labeled agents in each subsequent retraining round, leading to an increase in the acceptance rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_6.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time as the model is retrained with strategic feedback. It shows how the model becomes more likely to give positive decisions to agents, even though the proportion of qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_7.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time as the model is retrained with strategic feedback. It demonstrates the positive feedback loop between model updates and agent strategic responses, leading to an increasing proportion of agents receiving positive decisions.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_8.jpg alt></figure></p><blockquote><p>This figure shows how the student distribution and the ML model evolve over time (t=0, t=5, t=14). The model is retrained periodically using human and model-annotated data, and students strategically adapt their behavior to maximize their chances of admission. The figure illustrates that over time, the learned classifier deviates from the true classifier, indicating a potential long-term risk of model retraining with strategic feedback.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_33_9.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time in a model retraining process with strategic feedback. It shows how the model&rsquo;s decisions and agents&rsquo; strategic responses interact to change the data distribution and ultimately increase the acceptance rate. The model becomes more &lsquo;generous&rsquo; over time in admitting agents.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_1.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback from agents. The example shows how the model, initially classifying half the agents correctly, becomes increasingly likely to classify agents as positive (accept them) even if the underlying proportion of qualified agents remains the same or even decreases.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_2.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s annotations, combined with human annotations, shift the distribution of qualified/unqualified agents, leading to a more generous classifier that accepts a higher proportion of agents.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_3.jpg alt></figure></p><blockquote><p>This figure shows the dynamics of acceptance rate (at), qualification rate (qt), and classifier bias (Œît) under different retraining processes in two datasets (Gaussian and German Credit). The left plot shows the dynamics in Gaussian data, while the right plot is in German Credit data. In each plot, there are three lines representing at, qt, and Œît, respectively. The x-axis represents the retraining rounds, while the y-axis is the value of at, qt, and Œît. The lines show that at, qt, and Œît evolve differently under perfect information settings. For example, at always increases while qt decreases in the long run, and Œît shows more complex dynamics.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_4.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time as the model is retrained with strategic feedback. It shows how the model&rsquo;s decisions shift towards accepting more agents, even if the proportion of truly qualified agents may not increase.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_5.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and how the acceptance rate increases over time due to strategic behavior of agents. It shows how model-annotated samples with positive labels, even if based on an imperfect model, lead to a more &lsquo;generous&rsquo; classifier in the next round.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_6.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decisions (admit/reject) change the agent population distribution, ultimately leading to a higher acceptance rate. The annotations highlight the impact of model-annotated samples in the retraining process.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_7.jpg alt></figure></p><blockquote><p>The figure shows the dynamics of acceptance rate (at), qualification rate (qt), and classifier bias (Œît) for two groups (i and j) in the Credit Approval dataset under three different values of r (0.1, 0.05, and 0). Error bars represent the standard deviation. This figure is an enhanced version of Figure 12, providing error bars for improved clarity and statistical significance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_34_8.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process of the model with strategic feedback. It shows how the acceptance rate increases over time as the model is retrained with more qualified agents, while the proportion of agents with positive labels may decrease. The refined retraining process is proposed to stabilize this dynamic.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_35_1.jpg alt></figure></p><blockquote><p>This figure illustrates the increase in the acceptance rate over time. It shows how the model retraining process, incorporating strategic feedback from agents, leads to a higher proportion of agents being classified as positive, even though the true proportion of qualified agents may not increase at the same rate. The figure highlights the interaction between strategic agents and the model and demonstrates the potential for model bias.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_35_2.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time as the model is retrained with strategic feedback. It shows how the proportion of qualified agents in the training dataset increases after each retraining round, leading to a higher acceptance rate. The figure highlights the positive feedback loop between model retraining and agent behavior.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_35_3.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model becomes increasingly likely to accept agents (even unqualified ones) as it is retrained with model-annotated data that reflects the agents&rsquo; strategic responses. The retraining process gradually shifts the model towards a more generous acceptance policy.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_35_4.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback from agents. It shows how the model becomes more likely to give positive decisions as it&rsquo;s retrained, even though the proportion of qualified agents may not actually increase.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_35_5.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time in a model retraining process with strategic feedback from agents. It shows how the model&rsquo;s annotations, combined with human annotations, shift the distribution of training data toward a higher proportion of positively labeled agents in successive retraining rounds. This results in the model becoming more likely to make positive classifications, even if the true underlying proportion of positive agents does not increase.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_35_6.jpg alt></figure></p><blockquote><p>This figure illustrates the model retraining process with strategic feedback. It shows how the acceptance rate increases over time as the model is retrained with both human and model-annotated data, even though the proportion of qualified agents may decrease. This is because agents strategically adapt their behavior to maximize their chances of receiving a favorable outcome.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_36_1.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decision boundary changes, leading to more agents being classified as positive, even if their true qualification status remains unchanged.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_36_2.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. The left plot shows the initial training data. The middle plot demonstrates the strategic response of agents to the model. The right plot shows how the updated training data leads to an increased acceptance rate in the subsequent model.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_36_3.jpg alt></figure></p><blockquote><p>This figure illustrates how the training dataset is updated iteratively in the retraining process. At each time step <em>t</em>, strategic agents respond to the current model <em>f<sub>t</sub></em>. This response is then added as new data points to the training dataset, along with new human-annotated samples, to create the updated dataset for retraining at time step <em>t</em>+1. This process depicts the dynamic interaction between the model and strategic agents.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_36_4.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decisions are influenced by the agents&rsquo; strategic responses and model-annotated samples leading to higher acceptance rates in subsequent retraining rounds.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_36_5.jpg alt></figure></p><blockquote><p>This figure illustrates how the training data is updated from time t to time t+1, incorporating feedback from strategic agents. The model is trained on data at time t, and the strategic agents&rsquo; responses to that model are used to create new training data at time t+1. The process shows how model updates and agents&rsquo; strategic behaviors interact over time.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_36_6.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time as the model is retrained with strategic feedback. It shows how the model&rsquo;s decision boundary shifts due to the best responses of strategic agents, leading to a higher proportion of agents being classified as positive even if the actual proportion of qualified agents may not increase.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_37_1.jpg alt></figure></p><blockquote><p>This figure shows how the student distribution and the ML model evolve over time (t=0, 5, 14) when the model is retrained with both human and model-annotated samples, and students strategically adapt their behavior to maximize their chances of admission. The black lines represent the learned classifier, while the green lines show the ground truth. The figure highlights how the learned classifier deviates from the ground truth over time.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_37_2.jpg alt></figure></p><blockquote><p>This figure illustrates the process of updating the training data and the change in the acceptance rate over time due to the model retraining with strategic feedback. The model&rsquo;s acceptance rate increases as the model is retrained with both human-annotated and model-annotated samples.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_37_3.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. It demonstrates how model retraining with model-annotated samples, based on the previous classifier&rsquo;s output, changes the distribution of qualified/unqualified agents. The increasing proportion of positive labels in the training data leads to a more &lsquo;generous&rsquo; classifier, accepting more applicants.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_37_4.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time in the model retraining process with strategic feedback. It shows the evolution of the training data and the classifier from time t to t+1, highlighting how the model becomes increasingly likely to accept agents even though the proportion of qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_37_5.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time due to model retraining with strategic feedback. It shows the evolution of the training dataset and the classifier&rsquo;s decision-making process over three time steps (t, t+1, t+2). The inclusion of model-annotated samples with positive labels increases the proportion of positive labels in the dataset over time, leading to a more &lsquo;generous&rsquo; classifier in subsequent rounds.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_37_6.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback. It shows how the acceptance rate increases over time as the model is retrained with model-annotated samples that reflect the strategic responses of the agents. The figure highlights the potential for model retraining to amplify the positive bias.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_38_1.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback, showing how the acceptance rate increases over time. The model is retrained with both human and model-annotated data, and agents strategically adapt their behaviors in response.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_38_2.jpg alt></figure></p><blockquote><p>This figure illustrates how the acceptance rate increases over time as the model is retrained with strategic feedback. It shows the change in the training dataset and the resulting classifier at each retraining step (t, t+1). The strategic behavior of agents influences the model&rsquo;s learning, leading to an increasingly &lsquo;generous&rsquo; classifier that admits more applicants.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_38_3.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback. It shows how the acceptance rate increases over time as the model is retrained with both human and model-annotated data. The model&rsquo;s decisions influence agents&rsquo; behaviors (best response), leading to a shift in the data distribution. This shift, in turn, impacts future model training and acceptance rates.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_38_4.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process and how the acceptance rate increases over time. It shows how strategic agents&rsquo; responses to the model influence subsequent model retraining, leading to a higher acceptance rate in the following round. The figure highlights the feedback loop between strategic agents and model retraining.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_38_5.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time during the model retraining process with strategic feedback. It shows how the model&rsquo;s retraining with model-annotated and human-annotated samples leads to an increase in the proportion of agents receiving positive decisions, while the actual qualification rate may decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_38_6.jpg alt></figure></p><blockquote><p>This figure illustrates how the training data is updated during the retraining process when incorporating human strategic feedback. In each round (t), a model is trained and deployed. Strategic agents then respond optimally to this model, and their responses (including their features and the model&rsquo;s decision) are added to the training dataset to improve the model in the next round (t+1). This process creates a feedback loop between model updates and strategic agent behavior.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_39_1.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decisions (admit/reject) change the distribution of agents (qualified/unqualified), which in turn influences future model retraining, resulting in a positive feedback loop where more agents are admitted over time.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_39_2.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time. It shows how the model retraining process with strategic feedback from agents leads to a higher proportion of agents being classified as positive, even if the actual proportion of qualified agents might decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_39_3.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback, showing how the acceptance rate increases over time due to model updates and strategic agent behavior. The plots visualize the changes in agent qualification, model-annotated samples, and the overall training dataset across three time steps.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_39_4.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decisions change the agents&rsquo; behaviors, leading to a higher proportion of agents receiving positive classifications.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_39_5.jpg alt></figure></p><blockquote><p>This figure illustrates the retraining process with strategic feedback. It shows how the acceptance rate increases over time as the model is retrained with both human and model-annotated samples. The strategic agents adapt their behaviors to receive more favorable outcomes, leading to an increase in the acceptance rate of the model but not necessarily the qualification rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_39_6.jpg alt></figure></p><blockquote><p>This figure illustrates the evolution of the acceptance rate (at) over time. It shows how the model&rsquo;s retraining process, incorporating both model- and human-annotated data, leads to an increasingly &lsquo;generous&rsquo; classifier that accepts a higher proportion of agents over time. This demonstrates the feedback loop between the model and strategic agents.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_40_1.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time as the model is retrained with strategic feedback. It shows how the model&rsquo;s decisions and the agents&rsquo; responses evolve dynamically. Initially, the model has a 50% acceptance rate. However, due to strategic behavior and model retraining, the acceptance rate increases to 70% in the next round, even though the true qualification rate may remain constant or even decline.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/figures_40_2.jpg alt></figure></p><blockquote><p>This figure illustrates the increasing acceptance rate over time due to model retraining with strategic feedback. It shows how the model&rsquo;s decisions (admitted/rejected) and agents&rsquo; responses (qualified/unqualified) interact, leading to a higher proportion of agents being admitted over time.</p></blockquote></details><details><summary>More on tables</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/tables_18_1.jpg alt></figure></p><blockquote><p>This table presents the parameter settings used for the Gaussian dataset in the experiments. It shows the distributions used for the features (P<sub>Xk</sub>(x<sub>k</sub>)), the qualification function (P<sub>Y|X</sub>(1|x)), and the experimental parameters (n, r, T, q<sub>0</sub>). The parameters define various aspects of the experimental setup, such as sample sizes and the initial qualification rate.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/2UJLv3KPGO/tables_18_2.jpg alt></figure></p><blockquote><p>This table presents the parameter settings used in the experiments conducted on the Credit Approval dataset. It details the Beta distributions used to model the conditional probabilities of features X1 and X2 given the label Y (0 or 1) for two groups, i and j. The number of trials (n), the ratio of model-annotated to human-annotated samples (r), the number of retraining rounds (T), and the initial qualification rate (q0) are also specified for each group.</p></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-960a20b8c3d18d392366e68b9e682eb7 class=gallery><img src=https://ai-paper-reviewer.com/2UJLv3KPGO/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/2UJLv3KPGO/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/&amp;title=Automating%20Data%20Annotation%20under%20Strategic%20Human%20Agents:%20Risks%20and%20Potential%20Solutions" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/&amp;text=Automating%20Data%20Annotation%20under%20Strategic%20Human%20Agents:%20Risks%20and%20Potential%20Solutions" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/neurips2024/posters/2ujlv3kpgo/&amp;subject=Automating%20Data%20Annotation%20under%20Strategic%20Human%20Agents:%20Risks%20and%20Potential%20Solutions" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_posters/2UJLv3KPGO/index.md",oid_likes="likes_posters/2UJLv3KPGO/index.md"</script><script type=text/javascript src=/neurips2024/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/neurips2024/posters/e6wrwivgzx/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">AutoMix: Automatically Mixing Language Models</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/neurips2024/posters/udxhmgjvjb/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Automatic Outlier Rectification via Optimal Transport</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
AI Paper Reviewer</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/neurips2024/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/neurips2024/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>