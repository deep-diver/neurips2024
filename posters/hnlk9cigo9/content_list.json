[{"type": "text", "text": "Faster Algorithms for User-Level Private Stochastic Convex Optimization\u2217 ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Andrew Lowy   \nWisconsin Institute for Discovery   \nUniversity of Wisconsin-Madison alowy@wisc.edu ", "page_idx": 0}, {"type": "text", "text": "Daogao Liu Department of Computer Science University of Washington liudaogao@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Hilal Asi Apple Machine Learning Research hilal.asi94@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study private stochastic convex optimization (SCO) under user-level differential privacy (DP) constraints. In this setting, there are $n$ users (e.g., cell phones), each possessing $m$ data items (e.g., text messages), and we need to protect the privacy of each user\u2019s entire collection of data items. Existing algorithms for user-level DP SCO are impractical in many large-scale machine learning scenarios because: (i) they make restrictive assumptions on the smoothness parameter of the loss function and require the number of users to grow polynomially with the dimension of the parameter space; or (ii) they are prohibitively slow, requiring at least $(m n)^{3/2}$ gradient computations for smooth losses and $(\\dot{m}n)^{3}$ computations for non-smooth losses. To address these limitations, we provide novel user-level DP algorithms with state-of-the-art excess risk and runtime guarantees, without stringent assumptions. First, we develop a linear-time algorithm with state-of-the-art excess risk (for a non-trivial linear-time algorithm) under a mild smoothness assumption. Our second algorithm applies to arbitrary smooth losses and achieves optimal excess risk in $\\approx(m n)^{9/8}$ gradient computations. Third, for non-smooth loss functions, we obtain optimal excess risk in $n^{1\\bar{1}/8}m^{5/4}$ gradient computations. Moreover, our algorithms do not require the number of users to grow polynomially with the dimension. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The increasing ubiquity of machine learning (ML) systems in industry and society has sparked serious concerns about the privacy of the personal data used to train these systems. Much work has shown that ML models may violate individuals\u2019 privacy by leaking their sensitive training data [SSSS17, $\\mathrm{LLL}^{+}24\\mathrm{a}$ , $\\mathrm{LLL}^{+}24\\dot{\\mathrm{b}}]$ . For instance, large language models (LLMs) are vulnerable to black-box attacks that extract individual training examples $[\\bar{\\mathbf{C}}\\mathrm{TW}^{+}21]$ . Differential privacy (DP) [DMNS06] prevents ML models from leaking their training data. ", "page_idx": 0}, {"type": "text", "text": "The classical definition of differential privacy\u2014item-level differential privacy [DMNS06]\u2014is illsuited for many modern applications. Item-level DP ensures that the inclusion or exclusion of any one training example has a negligible impact on the model\u2019s outputs. If each person (a.k.a. user) contributes only one piece of training data, then item-level DP provides a strong guarantee that each user\u2019s data cannot be leaked. However, in many modern ML applications, such as training LLMs on users\u2019 data in federated learning, each user contributes a large number of training examples [XZ24]. ", "page_idx": 0}, {"type": "text", "text": "In such scenarios, the privacy protection that item-level DP provides for each user is insufficiently weak. ", "page_idx": 1}, {"type": "text", "text": "User-level differential privacy is a stronger privacy notion that addresses the above shortcoming of item-level DP. Informally, user-level DP ensures that the inclusion or exclusion of any one user\u2019s entire training data ( $\\ln$ samples) has a negligible impact on the model\u2019s outputs. Thus, user-level DP provides a strong guarantee that no user\u2019s data can be leaked, even when users contribute many training examples. ", "page_idx": 1}, {"type": "text", "text": "A fundamental problem in (private) machine learning is stochastic convex optimization (SCO): given a data set $\\mathcal{D}=(Z_{1},\\ldots,Z_{n})$ from $n$ i.i.d. users, each possessing $m$ i.i.d. samples from an unknown distribution $Z_{i}\\sim P^{m}$ our goal is to approximately minimize the expected population loss ", "page_idx": 1}, {"type": "equation", "text": "$$\nF(x):=\\mathbb{E}_{z\\sim P}[f(x,z)].\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Here, $f:\\mathcal{X}\\times\\mathcal{Z}\\to\\mathbb{R}$ is a loss function (e.g., cross-entropy loss), $\\mathcal{X}\\subset\\mathbb{R}^{d}$ is the parameter domain, and $\\mathcal{Z}$ is the data universe. We require that the output of the optimization algorithm $A:\\mathcal{Z}^{m n}\\to\\mathcal{X}$ satisfies user-level DP (Definition 1.3). We measure the accuracy of $\\boldsymbol{\\mathcal{A}}$ by its excess (population) risk ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathbb{E}F(A(\\mathscr{D}))-F^{*}:=\\mathbb{E}_{A,\\mathscr{D}\\sim P^{n m}}F(A(\\mathscr{D}))-\\operatorname*{min}_{x\\in\\mathscr{X}}F(x).\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Given the practical importance of user-level DP SCO, it is unsurprising that many prior works have studied this problem. The work of $[\\mathrm{LSA}^{+}21]$ initiated this line of work, and provided an excess risk lower bound of $\\Omega(1/\\sqrt{n m}+\\sqrt{d}/(\\varepsilon n\\sqrt{m}))$ , where $\\varepsilon$ is the privacy parameter. However, their upper bound was suboptimal and required strong assumptions. The wo\u221ark of [BS23] gave an algorithm that achiev\u221aes optimal risk for $\\beta$ -\u221asmooth lo\u221asses with $\\beta\\ <\\ (n/\\sqrt{m d}\\land n^{3/2}/(d\\sqrt{m}))$ , provided that $n\\,\\geq\\,\\sqrt{d}/\\varepsilon$ and $m\\,\\leq\\,\\operatorname*{max}({\\sqrt{d}},n\\varepsilon^{2}/{\\sqrt{d}})$ . These assumptions are restrictive in large-scale applications with a large number of examples per user $m$ or when the number of model parameters $d$ is large. For example, in deep learning, we often have $d\\gg n$ and an enormous smoothness parameter $\\beta\\gg1$ . Moreover, their algorithm requires $m n^{3/2}$ gradient evaluations, making it slow when the number of users $n$ is large.2 The work of $[\\mathrm{GKK}^{+}23]$ gave another user-level DP algorithm that only requires $n\\geq\\log(d)/\\varepsilon$ , but unfortunately their algorithm does not run in polynomial-time. ", "page_idx": 1}, {"type": "text", "text": "To address the deficiencies of previous works on user-level DP SCO, the recent work [AL24] provided an algorithm that achieves optimal excess risk in polynomial-time, while also only requiring $n\\geq\\log(m d)/\\varepsilon$ users. Moreover, their algorithm also works for non-smooth losses. The drawback of [AL24] is that it is even slower than the algorithm of [BS23]: for $\\beta$ -smooth losses, their algorithm requires $\\beta\\cdot(n m)^{3/2}$ gradient evaluations; for non-smooth losses, their algorithm requires $(n m)^{3}$ evaluations. ", "page_idx": 1}, {"type": "text", "text": "Evidently, the runtime requirements and parameter restrictions of existing algorithms for user-level DP SCO are prohibitive in many important ML applications. Thus, an important question is: ", "page_idx": 1}, {"type": "table", "img_path": "hNlk9cIGo9/tmp/ee49743e326914eb76f74585c7ffeae71d3f9cb4675004e8c11cb83f42130a32.jpg", "table_caption": [], "table_footnote": [], "page_idx": 1}, {"type": "text", "text": "Contribution 1. We give a positive answer to Question 1, providing a novel algorithm that achieves optimal excess risk using ma $\\therefore\\{\\beta^{1/4}(n m)^{9/8},\\beta^{1/2}n^{1/4}m^{5\\bar{/}4}\\}$ gradient computations for $\\beta.$ -smooth loss functions, with any $\\beta<\\infty$ (Theorem 3.2). For non-smooth loss functions, our algorithm achieves optimal excess risk using $n^{11/8}m^{5/4}$ gradient evaluations for non-smooth loss functions (Theorem 4.1). Our runtime bounds dominate those of all prior works in every applicable parameter regime, by polynomial factors in $n,m$ , and $d$ . Moreover, our results only require $n^{1-o(1)}\\geq\\log(d)/\\varepsilon$ users. See Table 1 for a comparison of our results vs. prior works. For example, for non-smooth loss functions, our optimal algorithm is faster than the previous state-of-the-art [AL24] by a multiplicative factor of $n^{13/8}\\dot{m}^{7/4}$ . For smooth loss functions, our optimal algorithm is faster than [AL24] by a factor of $(n m)^{3/8}\\beta^{3/4}$ (in the typical parameter regime when $n^{7}\\geq m$ ). ", "page_idx": 1}, {"type": "table", "img_path": "hNlk9cIGo9/tmp/2f82ce19aaf04f8790744168998fbf4f65d869ab7e0decf9b5a784c1e23c0b7e.jpg", "table_caption": [], "table_footnote": ["Figure 1: Optimal algorithms for user-level DP SCO. We omit logarithms, fix $L=R=1=\\varepsilon$ and $n=d$ . "], "page_idx": 2}, {"type": "text", "text": "Linear-Time Algorithms The \u201choly grail\u201d of DP SCO is a linear-time algorithm with optimal excess risk, which is unimprovable both in terms of runtime and accuracy. In the item-level DP setting, such algorithms are known to exist for smooth loss functions [FKT20, ZTOH22]. [AL24] posed an interesting open question: is there a user-level DP algorithm that achieves optimal excess risk in linear time for smooth functions? For our second contribution, we make progress towards answering this question. ", "page_idx": 2}, {"type": "text", "text": "Existing techniques for user-level DP SCO are not well-suited for linear-time algorithms. Indeed, the only prior non-trivial linear-time algorithm is the user-leve\u221al LDP algorithm of [BS23, Algorithm 5].3 Their algorithm can achieve excess risk $\\approx1/\\sqrt{n m\\varepsilon}+\\sqrt{d}/(\\sqrt{n m\\varepsilon})$ . Unfortunately, however, their algorithm requires a very stringent assumption on the smoothness parameter $\\beta<\\sqrt{n^{3}/(m d^{3})}$ , which is unlikely to hold for large-scale ML problems. Further, the result of [BS23] requires the number of users queried in each round to grow polynomially with the dimension $d.$ , and it assumes $m<d<n$ . These assumptions severely limit the applicability of [BS23, Algorithm $5J$ in practical ML scenarios. This leads us to: ", "page_idx": 2}, {"type": "table", "img_path": "hNlk9cIGo9/tmp/74678de329a86b647157b7785e5d9f5e5a04d1bfc4b99980e84b2ab5d49af0e7.jpg", "table_caption": [], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "Contribution 2. We answer Question 2 affirmatively in Theorem 2.1: under a very mild requirement on the smoothn\u221aess parameter $\\beta<\\sqrt{n m d}$ , our novel linear-time algorithm achieves excess risk of $\\approx1/\\sqrt{n m\\varepsilon}+\\sqrt{d}/(\\sqrt{n m}\\varepsilon)$ . Moreover, our algorithm does not require the number of users to grow polynomially in the dimension $d$ , and our result holds for any values of $m,d$ , and $n$ . Thus, our algorithm has excess risk matching that of [BS23], but is much more widely applicable. ", "page_idx": 2}, {"type": "text", "text": "1.1 Techniques ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We develop novel techniques and algorithms to achieve new state-of-the-art results in user-level DP SCO. Before discussing our techniques, let us review the key ideas from prior works that we build on. ", "page_idx": 2}, {"type": "text", "text": "The goal of prior works [BS23, AL24] was to develop user-level analogs of DP-SGD [BFTT19], which is optimal in the item-level setting. To d\u221ao so, they observed that each user $i$ \u2019s gradient $\\begin{array}{r}{\\frac{1}{m}\\sum_{j=1}^{m}\\overdot{\\nabla}f(x,Z_{i,j})}\\end{array}$ lies in a ball of radius $\\approx1/\\sqrt{m}$ around the population gradient $\\nabla F(x)$ with high probability, if the data is i.i.d $(Z_{i}\\,\\sim\\,P^{m})$ . Consequently, if the data is i.i.d., then replacing one user $Z_{i}~\\in~{\\mathcal{D}}$ by another user $Z_{i}^{\\prime}\\ \\in\\ D^{\\prime}$ \u221awill not change the empirical gradient $\\nabla F_{\\mathcal{D}}(x)$ by too much: $\\|\\nabla F_{\\mathcal{D}}(x)\\,-\\,\\nabla F_{\\mathcal{D}^{\\prime}}(x)\\|\\,\\lesssim\\,1/(n\\sqrt{m})$ with high probability.\u221a Thus, one would hope for a method to privatize $\\nabla F_{\\mathcal{D}}(x)$ by adding noise that scales with $1/(n{\\sqrt{m}})$ \u2014rather than $1/n-$ which would allow for optimal excess risk. [AL24] devised such a method, which was inspired by FriendlyCore $[\\mathrm{TCK}^{+}22]$ . Their method privately detects and removes \u201coutlier\u201d user gradients, and then adds noise to the average of the \u201c\u221ainlier\u201d user gradients. This outlier-removal procedure ensures privacy with noise scaling with $1/(n{\\sqrt{m}})$ , provided $n\\gtrsim1/\\varepsilon$ . Moreover, when the data is i.i.d., no outliers will be removed with high probability, leading to a nearly unbiased estimator of the empirical gradient. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Our algorithms apply variations of the outlier-removal idea of [AL24] in novel ways. ", "page_idx": 3}, {"type": "text", "text": "Our linear-time Algorithm 1 takes a different approach to outlier removal, compared to prior works. Instead of removing outlier gradients, we aim to detect and remove outlier SGD iterates.4 The high-level idea of our algorithm is to partition the $n$ users into $C\\approx1/\\varepsilon$ groups, with each group containing $\\approx n\\varepsilon$ users. For each group of users, we run $T\\approx m n\\varepsilon$ steps of online SGD using the samples in this group and obtain the average iterate of each group: $\\{\\widetilde{x}_{j}\\}_{j=1}^{C}$ . We then privately identify and remove the outlier iterates from $\\{\\tilde{x}_{j}\\}_{j=1}^{C}$ . In order to successfully do so, we need to argue that if we run \u221aonline SGD independently on user $Z$ and user $Z^{\\prime}$ to obtain $\\tilde{x}$ and ${\\tilde{x}}^{\\prime}$ respectively, then $\\|\\tilde{x}-\\tilde{x}^{\\prime}\\|\\lesssim\\eta\\sqrt{T}$ with high probability, where $\\eta$ is the SGD step size. We prove such a stability bound in Lemma 2.3, which we hope will be of independent interest. By repeating the above process $\\log(n)$ times and using iterative localization [FKT20], we obtain our state-of-the-art linear-time result. ", "page_idx": 3}, {"type": "text", "text": "Our second algorithm, Algorithm 3, builds on [AL24] in a different way. In Algorithm 3, we apply an outlier-removal procedure to users\u2019 gradients. However, unlike [AL24], we draw random minibatches of users in each iteration and apply outlier-removal to these minibatches. To make this procedure private while also achieving optimal excess risk, we combine AboveThreshold [DR14] with privacy amplification by subsampling [BBG18]. We then develop an accelerated [GL12] user-level DP algorithm that solves a carefully chosen sequence of regularized ERM problems, and applies localization in the spirit of [KLL21, AFKT21]. An obstacle that arises when we try to extend the ERM-based localization framework to the user-level DP setting is getting a tight bound on the variance of our minibatch stochastic gradient estimator that scales with $1/m$ . We overcome this obstacle in Lemma 3.5, by appealing to the stability of user-level $D P$ [BS23]. To handle non-smooth loss functions, we apply randomized smoothing to our accelerated algorithm. ", "page_idx": 3}, {"type": "text", "text": "1.2 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We consider loss functions $f:\\mathcal{X}\\times\\mathcal{Z}\\to\\mathbb{R}$ , where $\\mathcal{X}$ is a convex parameter domain and $\\mathcal{Z}$ is a data universe. Let $P$ be an unknown data distribution and $F(x):=\\mathbb{E}_{z\\sim P}{\\bigl[}f(x,z){\\bigr]}$ be the population loss function. Denote $F^{*}:=\\operatorname*{min}_{x\\in\\mathcal{X}}F(x)$ . The SCO problem is $\\scriptstyle\\operatorname*{min}_{x\\in{\\mathcal{X}}}F(x)$ . Let $\\Vert\\cdot\\Vert$ denote the $\\ell_{2}$ norm. $\\Pi_{\\mathcal{X}}(u):=\\operatorname{argmin}_{x\\in\\mathcal{X}}\\|u-x\\|^{2}$ denotes projection onto $\\mathcal{X}$ . ", "page_idx": 3}, {"type": "text", "text": "Assumptions and Notation. Function $g:\\mathcal{X}\\to\\mathbb{R}$ is $L$ -Lipschitz if $|g(x)-g(x^{\\prime})|\\leq L\\|x-x^{\\prime}\\|_{2}$ for all $x,x^{\\prime}\\,\\in\\,\\mathcal{X}$ . Function $g\\,:\\,\\mathcal{X}\\,\\rightarrow\\,\\mathbb{R}$ is $\\beta$ -smooth if $g$ is differentiable and has $\\beta$ -Lipschitz gradient: $\\|\\nabla g(x)-\\nabla g(x^{\\prime})\\|_{2}\\;\\leq\\;\\beta\\|x\\,-\\,x^{\\prime}\\|_{2}$ . Function $g\\;:\\;\\mathcal{X}\\;\\rightarrow\\;\\mathbb{R}$ is $\\mu$ -strongly convex if $\\begin{array}{r}{g(\\alpha x+(1-\\alpha)x^{\\prime})\\le\\alpha g(x)+(1-\\alpha)g(x^{\\prime})-\\frac{\\alpha(1-\\alpha)\\mu}{2}\\|x-x^{\\prime}\\|^{2}}\\end{array}$ for all $\\alpha\\in[0,1]$ and all $x,x^{\\prime}\\in\\mathcal{X}$ If $\\mu=0$ , we say $g$ is convex. ", "page_idx": 3}, {"type": "text", "text": "Assumption 1.1. 1. The convex set $\\mathcal{X}$ is compact with $\\|x-x^{\\prime}\\|\\leq R$ for all $x,x^{\\prime}\\in\\mathcal{X}$ . ", "page_idx": 3}, {"type": "text", "text": "2. The loss function $f(\\cdot,z)$ is $L$ -Lipschitz and convex for all $z\\in{\\mathcal{Z}}$ . ", "page_idx": 3}, {"type": "text", "text": "In all of the paper except for Section 4, we will also assume: ", "page_idx": 3}, {"type": "text", "text": "Assumption 1.2. The loss function $f(\\cdot,z)$ is $\\beta$ -smooth for all $z\\in{\\mathcal{Z}}$ . ", "page_idx": 3}, {"type": "text", "text": "Denote $a\\wedge b:=\\operatorname*{min}(a,b)$ . For functions $f$ and $g$ of input parameters $\\theta$ , we write $f\\lesssim g$ if there is an absolute constant $C>0$ such that $f(\\theta)\\leq C g(\\theta)$ for all permissible values of $\\theta$ . We use $\\widetilde O$ to hide logarithmic factors. Write $a\\leq\\mathsf{p o l y}(b)$ if there exists some large $J>1$ for which $a\\leq b^{J}$ . ", "page_idx": 3}, {"type": "text", "text": "Differential Privacy. ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Definition 1.3 (User-Level Differential Privacy). Let $\\varepsilon\\ge0,\\;\\delta\\in[0,1)$ . Randomized algorithm ${\\mathcal{A}}:$ $\\mathcal{Z}^{n m}\\to\\mathcal{X}$ is $(\\varepsilon,\\delta)$ -user-level differentially private (DP) if for any two datasets $\\mathcal{D}=(Z_{1},\\ldots,Z_{n})$ and $\\mathcal{D}^{\\prime}=(Z_{1}^{\\prime},\\ldots,Z_{n}^{\\prime})$ that differ in one user\u2019s data (say $Z_{i}\\neq Z_{i}^{\\prime}$ but $Z_{j}=Z_{j}^{\\prime}$ for $j\\neq i$ ), we have ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}(\\boldsymbol{\\mathcal{A}}(\\mathcal{D})\\in S)\\le e^{\\varepsilon}\\mathbb{P}(\\boldsymbol{\\mathcal{A}}(\\mathcal{D}^{\\prime})\\in S)+\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Definition 1.3 prevents any adversary from learning much more about an individual\u2019s data set than if that data had not been used for training. Appendix A contains the necessary background on DP. ", "page_idx": 4}, {"type": "text", "text": "1.3 Roadmap ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We begin with our state-of-the-art linear-time algorithm in Section 2. In Section 3, we present our error-optimal algorithm with state-of-the-art runtime for smooth loss functions. Section 4 extends our fast optimal algorithm to non-smooth loss functions. We conclude in Section 5 with a discussion and guidance on future research directions stemming from our work. ", "page_idx": 4}, {"type": "text", "text": "2 A state-of-the-art linear-time algorithm for user-level DP SCO ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we develop a new algorithm (Algorithm 1) for user-level DP SCO that runs in linear time and has state-of-the-art excess risk, without requiring any impractical assumptions. The algorithm can be seen as a user-level DP variation of the localized phased SGD of [FKT20]: we execute a sequence of SGD trajectories with geometrically decaying step sizes, shrinking both the expected distance to the population minimizer and the privacy noise over a logarithmic number of phases. ", "page_idx": 4}, {"type": "text", "text": "In each phase $i$ , we first re-set algorithmic parameters and draw a disjoint set of $n_{i}$ users $D_{i}\\subset\\mathcal{D}$ (lines 4-5). We further partition $D_{i}$ into $C$ disjoint subsets $\\{D_{i,j}\\}_{j=1}^{C}$ . For each $j\\in[C]$ , we pool together all of the $n_{i}m$ samples in $D_{i,j}$ and run one-pass online SGD on $D_{i,j}$ with initial point $x_{i-1}$ given to us from the previous phase. Next, in lines 10-20, we privately detect and remove \u201coutliers\u201d from $\\{\\tilde{x}_{i,j}\\}_{j=1}^{C}$ . That is, our goal is to privately select a subset $\\dot{S}_{i}\\subset\\{\\dot{\\tilde{x}}_{i,j}\\}_{j=1}^{C}$ , such that for any two points $\\tilde{x}_{i,j},\\tilde{x}_{i,j^{\\prime}}\\in S_{i}$ , $\\|\\widetilde{x}_{i,j}-\\widetilde{x}_{i,j^{\\prime}}\\|\\le\\tau_{i}=\\widetilde{O}(\\eta_{i}L\\sqrt{T_{i}})$ . This will enable us to add noise scaling with $\\tau_{i}$ in line 22, rather than with the much la rger worst-case sensitivity (that scales linearly with $T_{i}$ ). In order to privately select such a subset ${\\cal{S}}_{i}$ , we first compute (and privatize) the concentration score for $\\{\\tilde{x}_{i,j}\\}_{j=1}^{C^{\\prime}}$ in line 10. A small concentration score indicates that outlier removal is doomed to fail and we must halt the algorithm to avoid breaching the privacy constraint. A large concentration score indicates that $\\{\\tilde{x}_{i,j}\\}_{j=1}^{C}$ is nearly $\\tau_{i}$ -concentrated and we may proceed with outlier removal in lines 12-15. ", "page_idx": 4}, {"type": "text", "text": "Theorem 2.\u221a1 (Privacy and utility of Algorithm 1 - Informal). Let $\\varepsilon\\,\\leq\\,10$ , $\\begin{array}{r}{n^{1-o(1)}\\;\\gtrsim\\;\\frac{\\log(n/\\delta)}{\\varepsilon}}\\end{array}$ , $\\beta\\leq(L/R){\\sqrt{d m n\\varepsilon}}$ , and $m\\lesssim p o l y(n)$ . Then, Algorithm $^{\\,I}$ is $(\\varepsilon,\\delta)$ -user-level DP. Further, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}F(x_{l})-F^{*}\\leq L R\\cdot\\tilde{O}\\left(\\frac{1}{\\sqrt{n m\\varepsilon}}+\\frac{\\sqrt{d\\log(1/\\delta)}}{\\sqrt{n}\\varepsilon\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The gradient complexity of Algorithm $I\\;i s\\leq n m$ . ", "page_idx": 4}, {"type": "text", "text": "Remark 2.2 (State-of-the-art excess risk in linear time, without the restrictive assumptions). Under the assumptions that $\\beta<(L\\varepsilon^{3}/R)\\sqrt{n^{3}/m d^{3}}$ and $m\\leq d/\\varepsilon^{2}\\leq n$ , [BS23] gave a linear-time algorithm with similar excess risk to Algorithm 1. However, their assumptions are very restrictive in practice: For example, in the canonical regime $n\\,\\approx\\,d$ , their assumption on $\\beta$ rules out essentially every (non-li\u221anear) loss function. By contrast, our result holds even if the smoothness parameter is huge $\\langle\\beta\\approx\\sqrt{n m d}\\rangle$ and we only require a logarithmic number of users. Thus, our algorithm and result is applicable to many practical ML problems. ", "page_idx": 4}, {"type": "text", "text": "To prove that Algorithm 1 is private, we essentially argue that for any phase $i$ , the $\\ell_{2}$ -sensitivity of ${\\tilde{x}}_{i}$ is upper bounded by $\\tilde{O}(\\tau_{i}\\bar{/}C)$ with probability at least $1-\\delta/2$ . The argument goes roughly as follows: First, the Lapl ace noise added to $s_{i}(\\tau_{i})$ ensures that $s_{i}(\\tau_{i})$ is $\\varepsilon/4$ -user-level DP. Now, it suffices to assume $\\widehat{s}_{i}(\\bar{\\tau}_{i})\\geq4C/5$ , since otherwise the algorithm halts and outputs 0 independently of the data. Next, conditional on the high probability event that the Laplace noise is smaller than $\\widetilde O(1/\\varepsilon)$ , we know that $\\widehat{s}_{i}(\\tau_{i})\\geq4C/5\\implies s_{i}(\\tau_{i})\\geq2C/3$ with high probability by our choice of $C$ . In this case, an arg u ment along the lines of [AL24, Lemma 3.5] shows that $\\tilde{x}_{i}$ has sensitivity bounded by $\\widetilde{O}(\\tau_{i}/C)$ with probability at least $1-\\delta/2$ . See Appendix B for the detailed proof. ", "page_idx": 4}, {"type": "text", "text": "To prove the excess risk bound in Algorithm 1, the key step is to show that if the data is i.i.d., then with high probability, no points are removed from $\\{\\tilde{x}_{i,j}\\}_{j=1}^{C}$ during the outlier-removal phase ", "page_idx": 4}, {"type": "text", "text": "1 Input: Dataset $\\mathcal{D}=(Z_{1},\\ldots,Z_{n})$ , privacy parameters $(\\varepsilon,\\delta)$ , parameters $p,q>0$ , stepsize $\\eta$ ;   \n2 Set $l=\\lfloor\\log_{2}(n)\\rfloor$ , $C:=100\\log(20n m e^{\\varepsilon}/\\delta)/\\varepsilon$ ;   \n3 for $i=1,\\cdots,l$ do   \n4 Set $n_{i}=(1-(1/2)^{q})n/2^{i q}$ , $\\eta_{i}=\\eta/2^{p i}$ , $N_{i}=n_{i}/C$ , $T_{i}=N_{i}m$ ,   \n$\\tau_{i}=1000\\eta_{i}L\\sqrt{T_{i}}\\log(n d m)$ ;   \n5 Draw disjoint users $D_{i}$ of size $n_{i}$ from $\\mathcal{D}$ ;   \n6 Divide $D_{i}$ into $C$ disjoint subsets $\\{D_{i,j}\\}_{j=1}^{C}$ , each containing $|D_{i,j}|=N_{i}$ users;   \n7 for $j=1,\\cdot\\cdot\\cdot,C$ do   \n8 $\\tilde{x}_{i,j}\\gets S G D(D_{i,j},\\eta_{i},T_{i},x_{i-1})=a$ verage iterate of $T_{i}$ steps of one-pass projected SGD   \nwith data $D_{i,j}$ , stepsize $\\eta_{i}$ , and initial point $x_{i-1}$ ;   \n9 end   \n10 Compute the concentration score for $D_{i}$ :   \n$s_{i}(\\tau_{i}):=\\frac{1}{C}\\sum_{j,j^{\\prime}\\in[C]}\\mathbf{1}(\\|\\tilde{x}_{i,j}-\\tilde{x}_{i,j^{\\prime}}\\|\\leq\\tau_{i})$   \nLet $\\widehat{s}_{i}(\\tau_{i})=s_{i}(\\tau_{i})+\\mathrm{Lap}(20/\\varepsilon)$ ;   \n11 if $\\begin{array}{r}{\\widehat{s}_{i}(\\tau_{i})\\geq\\frac{4C}{5}}\\end{array}$ then   \n12 $\\mathcal{S}_{i}=\\emptyset$ ;   \n13 for $j=1,\\cdot\\cdot\\cdot,C$ do   \n14 Compute the score function of $\\begin{array}{r}{\\tilde{x}_{i,j}\\colon h_{i,j}=\\sum_{j^{\\prime}=1}^{C}\\mathbf{1}(\\|\\tilde{x}_{i,j}-\\tilde{x}_{i,j^{\\prime}}\\|\\leq2\\tau_{i});}\\end{array}$ $\\begin{array}{r}{\\mathbf{\\Phi}_{j}=\\sum_{j^{\\prime}=1}^{\\vee}\\mathbf{1}(\\|\\tilde{x}_{i,j}-\\tilde{x}_{i,j^{\\prime}}\\|\\leq2\\tau,}\\\\ {\\mathbf{\\Phi}_{p_{i,j}}=\\left\\{\\begin{array}{l l}{0}&{h_{i,j}<C/2}\\\\ {1}&{h_{i,j}\\geq2C/3}\\\\ {\\frac{h_{i,j}-C/2}{C/6}}&{o.w.}\\end{array}\\right.}\\end{array}$   \n15 Add $\\tilde{x}_{i,j}$ to $\\mathcal{S}_{i}$ with probability $p_{i,j}$ for   \n16 end   \n17 end   \n18 else   \n19 Halt; Output 0   \n20 end   \n21 Let $\\begin{array}{r}{\\tilde{x}_{i}=\\frac{1}{|S_{i}|}\\sum_{\\tilde{x}_{i,j}\\in S_{i}}\\tilde{x}_{i,j}}\\end{array}$ ;   \n22 xi \u2190x\u02dci + \u03b6i, where \u03b6i \u223cN(0, \u03c3i2 Id) with \u03c3i = 100\u03c4i l\u03b5ogC2(n/\u03b4);   \n23 end ", "page_idx": 5}, {"type": "text", "text": "24 Output: $x_{l}$ . ", "page_idx": 5}, {"type": "text", "text": "(i.e. $|S_{i}|=C)$ . If $|S_{i}|\\,=\\,C$ holds, then we can use the convergence guarantees of SGD and the localization arguments in [FKT20] to establish the excess risk guarantee. In order to prove that $|S_{i}|=C$ with high probability, we need the following novel stability lemma: ", "page_idx": 5}, {"type": "text", "text": "Lemma 2.3. Assume $f(\\cdot,z)$ is convex, $L$ -Lipschitz, and $\\beta$ -smooth on $\\mathcal{X}$ with $\\eta\\ \\leq\\ 1/\\beta$ . Let $\\tilde{x}\\leftarrow S G D(D,\\eta,T,x_{0})$ and $\\tilde{y}\\gets S G D(D^{\\prime},\\eta,T,x_{0})$ be two independent runs of projected $S G D$ , where $D,D^{\\prime}\\sim P^{N}$ are i.i.d. Then, with probability at least $1-\\zeta$ , we have ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\|\\tilde{x}-\\tilde{y}\\|\\lesssim\\eta L\\sqrt{T\\log(d T/\\zeta)}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "We prove Lemma 2.3 via induction on $t$ , using non-expansiveness of gradient descent on smooth losses [HRS16], subgaussian concentration bounds, and a union bound. ", "page_idx": 5}, {"type": "text", "text": "Lemma 2.3 implies that if the data is i.i.d., then the following events hold with high probability: $\\|\\tilde{x}_{i,j}-\\tilde{x}_{i,j^{\\prime}}\\|\\le\\tau_{i}$ for all $j,j^{\\prime}\\in[C_{i}]$ and hence $s_{i}(\\tau_{i})=C$ . Further, conditional on $s_{i}(\\tau_{i})=C$ , we know that $\\widehat{s}_{i}(\\tau_{i})\\;\\geq\\;4C/5$ with high probability, so that the algorithm does not halt. Also, $\\|\\tilde{x}_{i,j}-\\tilde{x}_{i,j^{\\prime}}\\|\\leq\\bar{\\tau}_{i}$ for all $j,j^{\\prime}$ implies $p_{i,j}=1$ for all $j$ and hence $|\\bar{S_{i}}|=C$ for all $j$ . The detailed excess risk proof is provided in Appendix B. ", "page_idx": 5}, {"type": "text", "text": "Challenges of getting optimal excess risk in linear time: In the item-level DP setting, there are several (nearly) linear time algorithms that achieve optimal excess risk for smooth DP SCO under mild smoothness conditions, such as snowball SGD [FKT20], phased SGD [FKT20], and phased ERM with output perturbation [ZTOH22]. Extending these approaches into optimal nearly linear-time user-level DP algorithms is challenging. First, the user-level DP implementation of output perturbation in $[\\mathrm{GKK}^{+}23]$ is computationally inefficient. Second, snowball SGD relies on privacy amplification by iteration, which does not extend nicely to the user-level DP case due to instability of the outlier-detection procedure in [AL24]. Specifically, since amplification by iteration intermediate only provides DP for the last iterate $x_{T}$ but not the intermediate iterates $x_{t}$ $\\left(t<T\\right)$ ), the sensitivity of the concentration score function is not $O(1)$ , which impairs DP outlier-detection. A similar instability issue arises if one tries to naively extend phased SGD to be user-level DP by applying [AL24] to user gradients. This issue motivates our Algorithm 1, which extends phased SGD in an alternative way: by applying outlier-detection/removal to the SGD iterates instead of the gradients, we can control the sensitivity of the concentration score and thus prove that our algorithm is DP. However, since the bound in Lemma 2.3 scales polynomially with $T$ (and we believe this dependence on $T$ is necessary), Algorithm 1 adds excessive noise and has suboptimal excess risk. We believe that obtaining optimal risk in linear time will require a fundamentally different user-level DP mean estimation procedure that does not suffer from the instability issue. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "3 An optimal algorithm with $\\approx(m n)^{9/8}$ gradient complexity for smooth losses ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we provide an algorithm that achieves optimal excess risk using $\\approx(m n)^{9/8}$ stochastic gradient evaluations. Our Algorithm 3 is inspired by the item-level accelerated phased ERM algorithm of [KLL21]. It applies iterative localization [FKT20] to the user-level DP accelerated minibatch SGD Algorithm 2. Algorithm 2 is a user-level DP variation of the accelerated minibatch SGD of [GL12, GL13]. ", "page_idx": 6}, {"type": "text", "text": "Our Algorithm 2 applies a DP outlier-removal procedure to the users\u2019 gradients in each iteration. We use Above Threshold [DR14] to privatize the concentration scores $s_{i}^{(t)}$ and determine whether or not most of the gradients of users in minibatch $D_{i}^{t}$ are $2\\tau$ -close to each other. If $\\widehat{s}_{i}^{t}\\geq\\widehat{\\Delta}_{i}$ , indicating that the gradients of users in $D_{i}^{t}$ are nearly $2\\tau$ -concentrated, then we proceed wit h  outlier removal in lines 8-12. We then invoke privacy amplification by subsampling [BBG18] and the advanced composition theorem [KOV15] to privatize the average of the \u201cinlier\u201d gradients with additive Gaussian noise. By properly choosing algorithmic parameters, we obtain the following results, proved in Appendix C: ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.1 (Privacy of Algorithm 3). Let $\\varepsilon\\leq10,$ , $q>0$ such that $\\begin{array}{r}{n^{1-q}\\,>\\,\\frac{100\\log(20n m d e^{\\varepsilon}/\\delta)}{\\varepsilon(1-(1/2)^{q})}}\\end{array}$ .   \nThen, Algorithm 3 is $(\\varepsilon,\\delta)$ -DP. ", "page_idx": 6}, {"type": "text", "text": "Theorem 3.2 (Utility & runtime of Algorithm 3 - Informal). Let $\\varepsilon\\leq10$ and $\\delta<1/(m n)$ . Then, Algorithm 3 yields optimal excess risk: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{E}F(x_{l})-F^{*}\\leq L R\\cdot\\widetilde{O}\\left(\\frac{1}{\\sqrt{m n}}+\\frac{\\sqrt{d\\log(1/\\delta)}}{\\varepsilon n\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The gradient complexity of this algorithm is upper bounded by ", "page_idx": 6}, {"type": "equation", "text": "$$\nm n\\left(1+\\varepsilon\\left(\\frac{\\beta R}{L}\\right)^{1/4}\\left((m n)^{1/8}\\wedge\\left(\\frac{\\varepsilon^{2}n^{2}m}{d}\\right)^{1/8}\\right)\\right)+\\sqrt{\\frac{\\beta R}{L}}\\left(\\frac{n^{1/4}m^{5/4}}{\\varepsilon}+\\left(\\frac{n^{1/2}m^{5/4}}{d^{1/4}\\varepsilon^{1/2}}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "If $n=d,\\varepsilon=1$ , and $\\beta R=L$ then the gradient complexity bound in Theorem 3.2 simplifies to $(m n)^{9/8}+n^{1/4}m^{5/4}$ . Typically, $n^{7}\\geq m$ , so that the dominant term in this bound is $(m n)^{9/8}$ . ", "page_idx": 6}, {"type": "text", "text": "Remark 3.3 (State-of-the-art runtime). The gradient complexity bound in Theorem 3.2 is superior to the runtime bounds of all existing near-optimal algorithms by polynomial factors in $n,m$ , and $d$ [BS23, $\\mathrm{GKK}^{+}23$ , AL24]. Note that while the $m n^{3/2}$ gradient complexity bound of [BS23] may appear to be better than $\\beta^{1/4}(n m)^{9/8}$ in certain parameter regimes (e.g. $m>n^{3}$ or $\\beta\\gg n m)$ , this is not the case: the result of [BS23] requires $m<n$ and $\\beta<\\sqrt{n/m}$ . ", "page_idx": 6}, {"type": "text", "text": "Remark 3.4 (Mild assumptions). Note that Theorems 3.1 and 3.2 do not require any bound on the smoothness parameter $\\beta$ , and only require the number of users to grow logarithmically: $n^{1-o(1)}\\geq$ $\\widetilde{\\Omega}(1/\\varepsilon)$ . Contrast this with the results of previous works (e.g. [BS23]). ", "page_idx": 6}, {"type": "text", "text": "Algorithm 2: User-Level DP Accelerated Minibatch $\\mathtt{S G D}(\\widehat{F}_{i},T_{i},K_{i},x_{i-1},\\tau,\\varepsilon,\\delta)$ ", "page_idx": 7}, {"type": "text", "text": "1 Initialize $x_{i-1}^{1}\\leftarrow x_{i-1}$ ;   \n2 for $t=1,\\cdot\\cdot\\cdot,T_{i}$ do   \n3 Draw $K_{i}$ random users $D_{i}^{t}=\\{Z_{i,j}^{t}\\}_{j=1}^{K_{i}}$ from $D_{i}$ uniformly with replacement;   \n4 Set noisy threshold $\\begin{array}{r}{\\widehat{\\Delta}_{i}:=\\frac{4K_{i}}{5}+\\xi_{i}}\\end{array}$ , where $\\begin{array}{r}{\\xi_{i}\\sim\\mathrm{Lap}\\left(\\frac{8}{\\varepsilon}\\right)}\\end{array}$ ;   \n5 Let $\\begin{array}{r}{q_{t}(Z):=\\frac{1}{m}\\sum_{z\\in Z}\\nabla f(\\bar{x}_{i-1}^{t},z)}\\end{array}$ for user $Z$ ;   \n6 Compute the concentration score of $D_{i}^{t}$ :   \n$s_{i}^{t}(\\tau):=\\frac{1}{K_{i}}\\sum_{Z,Z^{\\prime}\\in D_{i}^{t}}\\mathbf{1}(\\|q_{t}(Z)-q_{t}(Z^{\\prime})\\|\\leq2\\tau)$   \nLet $\\widehat{s}_{i}^{t}(\\tau)=s_{i}^{t}(\\tau_{i})+v_{i}^{t}$ , where $\\begin{array}{r}{v_{i}^{t}\\sim\\operatorname{Lap}\\left(\\frac{16}{\\varepsilon}\\right)}\\end{array}$ ;   \n7 if $\\widehat{s}_{i}^{t}(\\tau)\\geq\\widehat{\\Delta}_{i}$ then   \n8 $S_{i}^{t}=\\emptyset$ ;   \n9 for Each User $Z\\in D_{i}^{t}$ do   \n10 $\\begin{array}{r l}&{\\mathrm{Set}\\:h_{i}^{t}(Z)=\\sum_{Z^{\\prime}\\in D_{i}^{t}}\\mathbf{1}(\\|q_{t}(Z)-q_{t}(Z^{\\prime})\\|\\leq2\\tau);}\\\\ &{\\mathrm{Add~}Z\\tan S_{i}^{t}\\mathrm{~with~probability~}p_{i}^{t}(Z):=\\left\\{\\begin{array}{l l}{0}&{h_{i}^{t}(Z)<K_{i}/2}\\\\ {1}&{h_{i}^{t}(Z)\\geq2K_{i}/3}\\\\ {\\frac{h_{i}^{t}(Z)-K_{i}/2}{K_{i}/6}}&{o.w.}\\end{array}\\right.}\\end{array}$   \n11   \n12 end   \n13 $\\begin{array}{r}{g_{i}^{t}=\\frac{1}{|S_{i}^{t}|}\\sum_{Z\\in S_{i}^{t}}\\nabla\\widehat{F}(x_{i-1}^{t},Z);}\\end{array}$   \n14 $\\widehat{g}_{i}^{t}=g_{i}^{t}+\\zeta_{i}^{t}$ , where $\\zeta_{i}^{t}\\sim\\mathcal{N}(0,\\sigma_{i}^{2})$ with $\\begin{array}{r}{\\sigma_{i}=\\frac{1000\\tau\\sqrt{T_{i}}\\log\\left(n d e^{\\varepsilon}/\\delta\\right)}{\\varepsilon n_{i}}}\\end{array}$ ;   \n15 Do 1 iteration of Accelerated Minibatch SGD (AC-SA) [GL12] on $\\widehat{F}_{i}$ , using gradient   \nestimatorgit + \u03bbi(xit\u22121 \u2212xi\u22121) to obtain xit\u2212+11.   \n16 end   \n17 else   \n18 Halt; Return 0   \n19 end   \n20 end   \n21 Output xiT\u2212i1 ", "page_idx": 7}, {"type": "text", "text": "Algorithm 3: User-Level DP Accelerated Phased ERM with Outlier Gradient Removal ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "1 Input: Dataset $\\mathcal{D}=(Z_{1},\\ldots,Z_{n})$ , privacy parameters $(\\varepsilon,\\delta)$ , parameters $p,q,\\lambda>0$ ;   \n2 Set $l=\\lfloor\\log_{2}(n)\\rfloor$ and $\\tau=O(L\\log(n d m)/\\sqrt{m})$ , choose any initial point $x_{0}\\in\\mathcal{X}$ ;   \n3 for $i=1,\\cdots,l$ do   \n4 S $\\begin{array}{r l}&{\\mathsf{e t}\\,n_{i}^{'}=(1-(1/2)^{q})n/2^{i q},\\lambda_{i}=\\lambda\\cdot2^{p i},T_{i}=\\widetilde{\\Theta}(1+\\sqrt{\\beta/\\lambda_{i}}),}\\\\ &{K_{i}=500\\log(n_{i}^{2}m^{2}e^{\\varepsilon}/\\delta)\\left(\\frac{1}{\\varepsilon}+\\frac{n_{i}\\varepsilon}{\\sqrt{T_{i}\\log(1/\\delta)}}\\right);}\\end{array}$   \n5 Draw disjoint users $D_{i}$ of size $n_{i}$ from $\\mathcal{D}$ ;   \n6 Let $\\begin{array}{r}{\\widehat{F}_{i}(x):=\\frac{1}{n_{i}}\\sum_{Z_{i,j}\\in D_{i}}\\widehat{F}(x,Z_{i,j})+\\frac{\\lambda_{i}}{2}\\|x-x_{i-1}\\|^{2}}\\end{array}$ , where $\\widehat{F}(x,Z_{i,j})$ is user $Z_{i,j}$ \u2019s   \nempirical loss;   \n7 $x_{i}\\gets$ User-Level DP Accelerated Minibatch $\\mathtt{S G D}(\\widehat{F}_{i},T_{i},K_{i},x_{i-1},\\tau,\\varepsilon,\\delta).$ ;   \n8 end   \n9 Output $x_{l}$ . ", "page_idx": 7}, {"type": "text", "text": "A challenge in proving Theorem 3.2 is getting a tight bound on the variance of the the noisy minibatch stochastic gradients $\\Hat{g_{i}^{t}}$ that are used in Algorithm 2 (lines 12-14). Conditional on $S_{i}^{t}=\\dot{D_{i}^{t}}$ , it is easy tuos eorbs tuainnif ao rvmalriya antc re a  nbdoounmd.  oHf otwhee vfeorr, tmh $\\begin{array}{r}{\\mathbb{E}\\|\\widehat{g}_{i}^{t}-\\nabla\\widehat{F}_{i}(x_{i}^{t})\\|^{2}\\lesssim d\\sigma_{i}^{2}+\\frac{L^{2}}{K_{i}}}\\end{array}$ ,e soirnecme  3w.2e , asrien csea imt pdlionesg $K_{i}$ scale with $m$ . To prove Theorem 3.2, we need the following stronger result: ", "page_idx": 8}, {"type": "text", "text": "Lemma 3.5 (Variance Bound for Algorithm 2). Let $\\delta\\ \\leq\\ 1/(n m),\\varepsilon\\ \\lesssim\\ 1.$ . Denote $\\stackrel{\\sim}{F}_{i}(x)\\;:=$ $\\textstyle\\frac{1}{n_{i}}\\sum_{Z_{i,j}\\in D_{i}}\\widehat{F}(x,Z_{i,j})$ . Then, conditional on $S_{i}^{t}=D_{i}^{t}$ for all $i\\in[l],t\\in[T_{i}]$ , we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|g_{i}^{t}-\\nabla\\widetilde{F}_{i}(x_{i-1}^{t})\\|^{2}\\lesssim\\frac{L^{2}\\log(n d m)}{K m}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "for all $i\\ \\in\\ [l],t\\ \\in\\ [T_{i}].$ , where the expectation is over both the random i.i.d. draw of $\\mathcal{D}=$ $(Z_{1},.\\,.\\,.\\,,Z_{n})\\sim P^{n m}$ and the randomness in Algorithm 3. ", "page_idx": 8}, {"type": "text", "text": "The difficulty in proving Lemma 3.5 comes from the fact that the iterates $\\boldsymbol{x}_{i}^{t}$ and the data $\\mathcal{D}$ are not independent. To overcome this difficulty, we use the stability of user-level $D P$ [BS23] to argue that for all $Z\\in D_{i}$ , $\\nabla\\widehat{F}(x_{i-1}^{t},Z)$ is $\\approx L/\\sqrt{m}$ -close to $\\nabla F(x_{i-1}^{t})$ with high probability, since $x_{i-1}^{t}$ is user-level DP. A detailed proof is given in Appendix C. ", "page_idx": 8}, {"type": "text", "text": "Remark 3.6 (Strongly convex losses: Optimal excess risk with state-of-the-art runtime). If $f(\\cdot,z)$ is $\\mu$ -strongly convex, then Algorithm 3 can be combined with the meta-algorithm of [FKT20, Section 5.1] to obtain optimal excess risk ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\frac{L^{2}}{\\mu}\\cdot\\widetilde{O}\\left(\\frac{1}{n m}+\\frac{d\\ln(1/\\delta)}{\\varepsilon^{2}n^{2}m}\\right)\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "with the same gradient complexity stated in Theorem 3.2. This improves over the previous state-ofthe-art gradient complexity $\\approx\\beta(\\dot{m}n)^{3/2}$ of [AL24]. ", "page_idx": 8}, {"type": "text", "text": "4 An optimal algorithm with subquadratic gradient complexity for non-smooth losses ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we extend our accelerated algorithm from the previous section to non-smooth loss functions. To accomplish this with minimal computational cost, we apply randomized (convolution) smoothing [YNS12, DBW12] to approximate non-smooth $f$ by a $\\beta.$ -smooth $\\tilde{f}$ . We can then apply Algorithm 3 to $\\tilde{f}$ . Since convolution smoothing is by now a standard optimization technique, we defer the details and proof to Appendix D. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.1 (Privacy and utility of smoothed Algorithm 3 for non-smooth loss - informal). Let $\\varepsilon\\leq10$ , $\\delta<1/(m n)$ , and $q>0$ such that $\\begin{array}{r}{n^{1-q}>\\bar{\\frac{100\\log(20n m d e^{\\varepsilon}/\\delta)}{\\varepsilon(1-(1/2)^{q})}}}\\end{array}$ . Then, applying Algorithm 3 to the smooth approximation of $f$ yields optimal excess risk: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}F(x_{l})-F^{*}\\leq L R\\cdot\\widetilde{O}\\left(\\frac{1}{\\sqrt{m n}}+\\frac{\\sqrt{d\\log(1/\\delta)}}{\\varepsilon n\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "The gradient complexity of this algorithm is upper bounded by ", "page_idx": 8}, {"type": "equation", "text": "$$\nm n\\left(1+n^{3/8}m^{1/4}\\varepsilon^{1/4}\\right).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Remark 4.2 (State-of-the-art gradient complexity). The only previous polynomial-time algorithm that can achieve optimal excess risk for non-smooth loss functions is due to [AL24]. The algorithm of [AL24] required $(n m)^{3}+(m n)^{2}{\\sqrt{d}}$ gradient evaluations. Thus, the gradient complexity of the smoothed version of Algorithm 3 offers a significant improvement over the previous state-of-the-art. For example, if $\\varepsilon=1$ , then our algorithm is faster than the previous state-of-the-art by a multiplicative factor of at least $n^{13/8}m^{7/4}$ . ", "page_idx": 8}, {"type": "text", "text": "5 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we developed new user-level DP algorithms with improved runtime and excess risk guarantees for stochastic convex optimization without the restrictive assumptions made in prior works. Our accelerated Algorithm 3 achieves optimal excess risk for both smooth and non-smooth loss functions, with significantly smaller computational cost than the previous state-of-the-art. Our linear-time Algorithm 1 achieves state-of-the-art excess risk under much milder, more practical assumptions than existing linear-time approaches. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Our work paves the way for several intriguing future research directions. First, the question of whether there exists a linear-time algorithm that can attain the user-level DP lower bound for smooth losses remains open. In light of our improved gradient complexity bound $(\\approx(n m)^{9/8})$ ), we are now optimistic that the answer to this question is \u201cyes.\u201d We believe that our novel techniques will be key to the development of an optimal linear-time algorithm. Specifically, utilizing Lemma 2.3 to apply outlier removal to the iterates instead of the gradients appears to be pivotal. Second, the study of user-level DP SCO has been largely limited to approximate $(\\varepsilon,\\delta)$ -DP. What rates are achievable under the stronger notion of pure $\\varepsilon$ -user-level DP? Third, it would be useful to develop fast and optimal algorithms that are tailored to federated learning environments [MRTZ18, GLZW24], where only a small number of users may be available to communicate with the server in each iteration. We hope our work inspires and guides further research in this exciting and practically important area. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "AL\u2019s research is supported by NSF grant 2023239 and the AFOSR award FA9550-21-1-0084. We thank the anonymous NeurIPS reviewers for their helpful feedback. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[AFKT21] Hilal Asi, Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: Optimal rates in $\\ell_{1}$ geometry. In ICML, 2021. ", "page_idx": 10}, {"type": "text", "text": "[AL24] Hilal Asi and Daogao Liu. User-level differentially private stochastic convex optimization: Efficient algorithms with optimal rates. In International Conference on Artificial Intelligence and Statistics, pages 4240\u20134248. PMLR, 2024. [ALT24] Hilal Asi, Daogao Liu, and Kevin Tian. Private stochastic convex optimization with heavy tails: Near-optimality from simple reductions. arXiv preprint arXiv:2406.02789, 2024.   \n[BBG18] Borja Balle, Gilles Barthe, and Marco Gaboardi. Privacy amplification by subsampling: Tight analyses via couplings and divergences. In S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, editors, Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.   \n[BFTT19] Raef Bassily, Vitaly Feldman, Kunal Talwar, and Abhradeep Thakurta. Private stochastic convex optimization with optimal rates. In Advances in Neural Information Processing Systems, volume 32, 2019. [BS23] Raef Bassily and Ziteng Sun. User-level private stochastic convex optimization with optimal rates. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 1838\u20131851. PMLR, 23\u201329 Jul 2023.   \n$[\\mathbf{C}\\mathbf{T}\\mathbf{W}^{+}21]$ Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom B Brown, Dawn Song, Ulfar Erlingsson, et al. Extracting training data from large language models. In USENIX Security Symposium, volume 6, pages 2633\u20132650, 2021.   \n[DBW12] John C Duchi, Peter L Bartlett, and Martin J Wainwright. Randomized smoothing for stochastic optimization. SIAM Journal on Optimization, 22(2):674\u2013701, 2012.   \n[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. In Theory of cryptography conference, pages 265\u2013284. Springer, 2006. [DR14] Cynthia Dwork and Aaron Roth. The Algorithmic Foundations of Differential Privacy, volume 9. Now Publishers, Inc., 2014. [FKT20] Vitaly Feldman, Tomer Koren, and Kunal Talwar. Private stochastic convex optimization: optimal rates in linear time. In Proceedings of the 52nd Annual ACM SIGACT Symposium on Theory of Computing, pages 439\u2013449, 2020.   \n$[\\mathrm{GKK}^{+}23]$ Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Raghu Meka, and Chiyuan Zhang. On user-level private convex optimization. In International Conference on Machine Learning, pages 11283\u201311299. PMLR, 2023. [GL12] Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization i: A generic algorithmic framework. SIAM Journal on Optimization, 22(4):1469\u20131492, 2012. [GL13] Saeed Ghadimi and Guanghui Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, ii: Shrinking procedures and optimal algorithms. SIAM Journal on Optimization, 23(4):2061\u20132089, 2013.   \n[GLZW24] Changyu Gao, Andrew Lowy, Xingyu Zhou, and Stephen J Wright. Private heterogeneous federated learning without a trusted server revisited: Error-optimal and communication-efficient algorithms for convex losses. arXiv preprint arXiv:2407.09690, 2024. [HRS16] Moritz Hardt, Ben Recht, and Yoram Singer. Train faster, generalize better: Stability of stochastic gradient descent. In Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings of The 33rd International Conference on Machine Learning, volume 48 of Proceedings of Machine Learning Research, pages 1225\u20131234, New York, New York, USA, 20\u201322 Jun 2016. PMLR.   \n[JNG+19] Chi Jin, Praneeth Netrapalli, Rong Ge, Sham M Kakade, and Michael I Jordan. A short note on concentration inequalities for random vectors with subgaussian norm. arXiv preprint arXiv:1902.03736, 2019. [KLL21] Janardhan Kulkarni, Yin Tat Lee, and Daogao Liu. Private non-smooth erm and sco in subquadratic steps. Advances in Neural Information Processing Systems, 34:4053\u20134064, 2021.   \n[KOV15] Peter Kairouz, Sewoong Oh, and Pramod Viswanath. The composition theorem for differential privacy, 2015. [LJCJ17] Lihua Lei, Cheng Ju, Jianbo Chen, and Michael I Jordan. Non-convex finite-sum optimization via scsg methods. In Proceedings of the 31st International Conference on Neural Information Processing Systems, pages 2345\u20132355, 2017.   \n[LLL $^{+}24\\mathrm{a}]$ Zhuohang Li, Andrew Lowy, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, Bradley Malin, and Ye Wang. Analyzing inference privacy risks through gradients in machine learning. arXiv preprint arXiv:2408.16913, 2024.   \n[LLL $,+24\\mathfrak{b}$ ] Andrew Lowy, Zhuohang Li, Jing Liu, Toshiaki Koike-Akino, Kieran Parsons, and Ye Wang. Why does differential privacy with large epsilon defend against practical membership inference attacks? arXiv preprint arXiv:2402.09540, 2024. [LR22] Andrew Lowy and Meisam Razaviyayn. Private stochastic optimization with large worst-case lipschitz parameter, 2022.   \n$[\\mathrm{LSA}^{+}21]$ Daniel Levy, Ziteng Sun, Kareem Amin, Satyen Kale, Alex Kulesza, Mehryar Mohri, and Ananda Theertha Suresh. Learning with user-level privacy. Advances in Neural Information Processing Systems, 34:12466\u201312479, 2021.   \n[LUW24] Andrew Lowy, Jonathan Ullman, and Stephen Wright. How to make the gradients small privately: Improved rates for differentially private non-convex optimization. In Forty-first International Conference on Machine Learning, 2024. [McS09] Frank D McSherry. Privacy integrated queries: an extensible platform for privacypreserving data analysis. In Proceedings of the 2009 ACM SIGMOD International Conference on Management of data, pages 19\u201330, 2009.   \n[MRTZ18] Brendan McMahan, Daniel Ramage, Kunal Talwar, and Li Zhang. Learning differentially private recurrent language models. In International Conference on Learning Representations (ICLR), 2018.   \n[SSSS17] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. Membership inference attacks against machine learning models. In 2017 IEEE symposium on security and privacy $(S P)$ , pages 3\u201318. IEEE, 2017.   \n[SSSSS09] Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Stochastic convex optimization. In COLT, volume 2, page 5, 2009.   \n$[\\mathrm{TCK}^{+}22]$ Eliad Tsfadia, Edith Cohen, Haim Kaplan, Yishay Mansour, and Uri Stemmer. Friendlycore: Practical differentially private aggregation. In International Conference on Machine Learning, pages 21828\u201321863. PMLR, 2022. [Ull17] Jonathan Ullman. CS7880: rigorous approaches to data privacy, 2017. [XZ24] Zheng Xu and Yanxiang Zhang. Advances in private training for production on-device language models. https://research.google/blog/ advances-in-private-training-for-production-on-device-language-model 2024. Google Research Blog.   \n[YNS12] Farzad Yousefian, Angelia Nedi\u00b4c, and Uday V Shanbhag. On stochastic gradient and subgradient methods with adaptive steplength sequences. Automatica, 48(1):56\u201367, 2012.   \n[ZTOH22] Liang Zhang, Kiran K Thekumparampil, Sewoong Oh, and Niao He. Bring your own algorithm for optimal differentially private stochastic minimax optimization. Advances in Neural Information Processing Systems, 35:35174\u201335187, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A More Preliminaries ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Tools from Differential Privacy ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Additive Noise Mechanisms Additive noise mechanisms privatize a query by adding noise to its output, with the scale of the noise calibrated to the sensitivity of the query. ", "page_idx": 13}, {"type": "text", "text": "Definition A.1 (Sensitivity). Given a function $q:\\mathcal{Z}^{N}\\to\\mathbb{R}^{k}$ and a norm $\\lVert\\cdot\\rVert_{p}$ on $\\mathbb{R}^{k}$ , the $\\ell_{p}$ -sensitivity of $q$ is defined as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\mathcal{D}\\sim\\mathcal{D^{\\prime}}}\\|q(\\mathcal{D})-q(\\mathcal{D^{\\prime}})\\|_{p},\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the supremum is taken over all pairs of datasets that differ in one user\u2019s data. ", "page_idx": 13}, {"type": "text", "text": "Definition A.2 (Laplace Distribution). We say $X\\sim\\operatorname{Lap}(b)$ if the density of $X$ is $f(X=x)=$ $\\textstyle{\\frac{1}{2b}}\\exp(-{\\frac{|x|}{b}})$ . ", "page_idx": 13}, {"type": "text", "text": "Definition A.3 (Laplace Mechanism). Let $\\varepsilon\\,>\\,0$ . Given a function $q:\\mathcal{Z}^{N}\\,\\rightarrow\\,\\mathbb{R}^{k}$ on $\\mathbb{R}^{k}$ with $\\ell_{1}$ -sensitivity $\\Delta$ , the Laplace Mechanism $\\mathcal{M}$ is defined by ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{M}(\\mathcal{D}):=q(\\mathcal{D})+(Y_{1},\\ldots,Y_{k}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\{Y_{i}\\}_{i=1}^{k}$ are i.i.d., $\\begin{array}{r}{Y_{i}\\sim\\mathrm{Lap}\\left(\\frac{\\Delta}{\\varepsilon}\\right)}\\end{array}$ . ", "page_idx": 13}, {"type": "text", "text": "Lemma A.4 (Privacy of Laplace Mechanism [DR14]). The Laplace Mechanism is $\\varepsilon$ -DP. ", "page_idx": 13}, {"type": "text", "text": "Definition A.5 (Gaussian Mechanism). Let $\\varepsilon>0$ , $\\delta\\in(0,1)$ . Given a function $q:\\mathcal{Z}^{N}\\to\\mathbb{R}^{k}$ with $\\ell_{2}$ -sensitivity $\\Delta$ , the Gaussian Mechanism $\\mathcal{M}$ is defined by ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathcal{M}(\\mathcal{D}):=q(\\mathcal{D})+G\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where G \u223cNk 0, \u03c32Ik and \u03c32 = 2\u22062 lo\u03b52g(2/\u03b4). ", "page_idx": 13}, {"type": "text", "text": "Lemma A.6 (Privavcy of Gaussian Mechanism [DR14]). The Laplace Mechanism is $(\\varepsilon,\\delta)$ -DP. ", "page_idx": 13}, {"type": "text", "text": "Advanced Composition If we adaptively query a data set $T$ times, then the privacy guarantees of the $T$ -th query is still DP and the privacy parameters degrade gracefully: ", "page_idx": 13}, {"type": "text", "text": "Lemma A.7 (Advanced Composition Theorem [DR14]). Let $\\varepsilon\\ \\geq\\ \\ 0,\\delta,\\delta^{\\prime}\\ \\in\\ [0,1)$ . Assume $A_{1},\\cdot\\cdot\\cdot,A_{T}$ , with $A_{t}:\\mathcal{Z}^{n}\\times\\mathcal{X}\\rightarrow\\mathcal{X}$ , are each $(\\varepsilon,\\delta){\\cdot}D P\\,\\,\\,\\forall t=1,\\cdot\\cdot\\cdot\\,,T$ . Then, the adaptive composition $\\mathcal{A}(\\mathcal{D}):=\\mathcal{A}_{T}(\\mathcal{D},\\mathcal{A}_{T-1}(\\mathcal{D},\\mathcal{A}_{T-2}(X,\\cdot\\cdot\\cdot)))$ is $(\\varepsilon^{\\prime},T\\delta+\\delta^{\\prime})-$ DP for ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varepsilon^{\\prime}=\\sqrt{2T\\ln(1/\\delta^{\\prime})}\\varepsilon+T\\varepsilon(e^{\\varepsilon}-1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Privacy Amplification by Subsampling ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Lemma A.8 ([Ull17]). Let $\\mathcal{M}:\\mathcal{Z}^{M}\\to\\mathcal{X}$ be $(\\varepsilon,\\delta)$ -DP. Let $\\mathcal{M}^{\\prime}:\\mathcal{Z}^{N}\\rightarrow\\mathcal{X}$ that first selects a random subsample $\\mathcal{D}^{\\prime}$ of size $M$ from the data set $\\mathcal{D}\\in\\mathcal{Z}^{N}$ and then outputs $\\mathcal{M}(\\mathcal{D}^{\\prime})$ . Then, $\\mathcal{M}^{\\prime}$ is $(\\varepsilon^{\\prime},\\delta^{\\prime})$ -DP, where $\\begin{array}{r}{\\varepsilon^{\\prime}=\\frac{(e^{\\varepsilon}-1)M}{N}}\\end{array}$ and \u03b4\u2032 = \u03b4M. ", "page_idx": 13}, {"type": "text", "text": "AboveThreshold: AboveThreshold algorithm [DR14] which is a key tool in differential privacy to identify whether there is a query $q_{i}:\\mathcal{Z}\\to\\mathbb{R}$ in a stream of queries $q_{1},\\dots,q_{T}$ that is above a certain threshold $\\Delta$ . The AboveThreshold Algorithm 4 has the following guarantees: ", "page_idx": 13}, {"type": "text", "text": "Lemma A.9 ([DR14], Theorem 3.24). Let $\\gamma>0$ and $\\begin{array}{r}{\\alpha=\\frac{8\\log(2T/\\gamma)}{\\varepsilon}}\\end{array}$ , $k\\in[T+1]$ . AboveThreshold is $(\\varepsilon,0)$ -DP. Moreover, with probability at least $1-\\gamma,$ , for all $t\\,\\breve{\\leq}\\,k$ , we have: ", "page_idx": 13}, {"type": "text", "text": "\u2022 i $f a_{t}=\\top$ , then $q_{t}(\\mathcal{D})\\geq\\Delta-\\alpha_{*}$ ; and \u2022 $i f a_{t}=\\perp$ , then $q_{t}(D)\\leq\\Delta+\\alpha$ . ", "page_idx": 13}, {"type": "text", "text": "1 Input: Dataset $\\mathcal{D}=(Z_{1},\\ldots,Z_{n})$ , threshold $\\Delta\\in\\mathbb{R}$ , privacy parameter $\\varepsilon$ , sequence of $T$ queries   \n$q_{1},\\cdot\\cdot\\cdot\\,,q_{T}:\\mathcal{Z}^{n}\\to\\mathbb{R}$ , each with $\\ell_{1}$ -sensitivity 1;   \n2 Let $\\begin{array}{r}{\\widehat{\\Delta}:=\\Delta+\\mathrm{Lap}(\\frac{2}{\\varepsilon})}\\end{array}$ ;   \n3 for $t=1$ to $T$ do   \n4 Receive a new query $q_{t}:\\mathcal{Z}^{n}\\to\\mathbb{R}$ ;   \n5 Sample $\\begin{array}{r}{\\nu_{i}\\sim\\mathrm{Lap}(\\frac{4}{\\varepsilon})}\\end{array}$ ;   \n6 if $q_{t}(\\mathcal{D})+\\nu_{i}\\geq\\widehat{\\Delta}$ then   \n7 Output: $a_{t}=\\top$ ;   \n8 Halt;   \n9 end   \n10 else   \n11 Output: $a_{t}=\\perp$ ;   \n12 end   \n13 end ", "page_idx": 14}, {"type": "text", "text": "A.2 SubGaussian and Norm-SubGuassian Random Vectors ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Definition A.10. Let $\\zeta>0$ . We say a random vector $X$ is SubGaussian $(\\mathrm{SG}(\\zeta))$ with parameter $\\zeta$ if $\\mathbb{E}[e^{\\langle v,X-\\mathbb{E}X\\rangle}]\\leq e^{\\|v\\|^{2}\\zeta^{2}/2}$ for any $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ . Random vector $X\\in\\mathbb{R}^{d}$ is Norm-SubGaussian with parameter $\\zeta\\,(\\mathrm{nSG}(\\zeta))$ if $\\mathbb{P}[\\|X-\\mathbb{E}X\\|\\ge t]\\le2e^{-\\frac{t^{2}}{2\\zeta^{2}}}$ for all $t>0$ . ", "page_idx": 14}, {"type": "text", "text": "Theorem A.11 (Hoeffding-type inequality for norm-subGaussian, $[\\mathbf{J}\\mathbf{N}\\mathbf{G}^{+}19],$ ). Let $X_{1},\\cdot\\cdot\\cdot,X_{k}\\in$ $\\mathbb{R}^{d}$ be random vectors, and let $\\mathcal{F}_{i}=\\sigma(\\boldsymbol{x}_{1},\\cdot,\\boldsymbol{x}_{i})$ for $i\\in[k]$ be the corresponding flitration. Suppose for each $i\\in[k],\\,X_{i}\\mid\\mathcal{F}_{i-1}$ is zero-mean $\\mathrm{nSG}(\\zeta_{i})$ . Then, there exists an absolute constant $c>0$ , for any $\\gamma>0$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\left\\lVert\\sum_{i\\in[k]}X_{i}\\right\\rVert\\geq c\\sqrt{\\log(d/\\gamma)\\sum_{i\\in[k]}\\zeta_{i}^{2}}\\right]\\leq\\gamma.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Lemma A.12 $[\\mathbf{J}\\mathbf{N}\\mathbf{G}^{+}19]$ ). There exists an absolute constant $c_{:}$ , such that if $X$ is $\\mathrm{nSG}(\\zeta)$ , then for any fixed unit vector $\\boldsymbol{v}\\in\\mathbb{R}^{d}$ , $\\langle v,X\\rangle$ is $c\\zeta$ norm-SubGaussian. ", "page_idx": 14}, {"type": "text", "text": "B Proof of Theorem 2.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Theorem B.1 (Formal statement of Theorem 2.1). Suppose $n^{1-q}\\geq(100/(1\\!-\\!1/2^{q}))\\log(n/\\delta)/\\varepsilon$ for some small $q>0$ , and $m\\le n^{J}$ for some large $J>0$ . Choose $p=J+3/2$ and $\\eta=R/(L\\sqrt{d m n\\varepsilon})$ . in Algorithm $^{\\,l}$ . Then, $A$ lgorithm $^{\\,l}$ is $(\\varepsilon,\\delta)$ -user-level $D P$ and achieves excess risk ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{E}F(x_{l})-F^{*}\\leq L R\\cdot\\tilde{O}\\left(\\frac{1}{\\sqrt{n m\\varepsilon}}+\\frac{\\sqrt{d\\log(1/\\delta)}}{\\sqrt{n}\\varepsilon\\sqrt{m}}\\right),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "using nm gradient evaluations, provided $\\beta\\leq(L/R){\\sqrt{d m n\\varepsilon}}$ . ", "page_idx": 14}, {"type": "text", "text": "The gradient complexity is clear by inspection of the algorithm: The number of stochastic gradients computed during the algorithm is ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{l}T_{i}C=\\sum_{i=1}^{l}N_{i}m C=\\sum_{i=1}^{l}n_{i}m\\leq n m.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Next, we will prove the privacy statement in Theorem B.1. The following lemma ensures that if the Laplace noise added in Algorithm 1 is sufficiently small and outlier detection succeeds, then the sensitivity of ${\\tilde{x}}_{i}$ is $\\tilde{O}(\\tau_{i}/C)$ with high probability. ", "page_idx": 14}, {"type": "text", "text": "Lemma B.2. [AL24, Slight modification of Lemma 3.5] Let $i\\in[l]$ and $\\zeta>0$ . Suppose $\\mathcal{D}_{i}$ and $\\mathcal{D}_{i}^{\\prime}$ differ in the data of one user and we are in phase i of Algorithm $^{\\,l}$ . Let $E_{i}$ be the event that the Laplace noise added to the concentration score $s_{i}(\\tau_{i})$ for $\\mathcal{D}_{i}$ has absolute value less than $2C/15$ and define $E_{i}^{\\prime}$ similarly for data $\\mathcal{D}_{i}^{\\prime}$ . Denote $a_{i}:={\\mathbf1}(\\widehat{s}_{i}(\\tau_{i})\\geq4C/5)$ and $a_{i}^{\\prime}:=\\mathbf{1}(\\widehat{s}_{i}^{\\prime}(\\tau_{i})\\geq4C/5)$ , where $\\widehat{s}_{i}(\\tau_{i})$ and $\\widehat{s}_{i}^{\\prime}(\\tau_{i})$ are the noisy concentration  scores that we get when run ning phase $i$ of Algorithm $^{\\,l}$ on neighboring $\\mathcal{D}_{i}$ and $\\mathcal{D}_{i:}^{\\prime}$ , respectively. Then, conditional on $a_{i}=a_{i}^{\\prime}$ and $E_{i}\\cap E_{i}^{\\prime}$ , there is a coupling $\\Gamma_{i}$ over ${\\tilde{x}}_{i}$ and $\\tilde{x}_{i}^{\\prime}$ such that for $(y_{i},y_{i}^{\\prime})$ drawn from $\\Gamma_{i}$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|y_{i}-y_{i}^{\\prime}\\|\\lesssim\\frac{\\tau_{i}\\log(1/\\zeta)}{C}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with probability at least $1-\\zeta$ . ", "page_idx": 15}, {"type": "text", "text": "With Lemma B.2 in hand, we proceed to prove that Algorithm 1 is $(\\varepsilon,\\delta)$ -user-level DP: ", "page_idx": 15}, {"type": "text", "text": "Proof of Theorem B.1 - Privacy. Privacy: Since the $\\{D_{i}\\}_{i=1}^{l}$ are disjoint, parallel composition of DP [McS09] implies that it suffices to prove that phase $i$ is $(\\varepsilon,\\delta)$ -user-level-DP for any fixed $i$ and fixed $x_{i-1}$ . To that end, let $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ be adjacent datasets differing in the data of one user, say $Z_{i,1}\\neq Z_{i,1}^{\\prime}$ without loss of generality. We will show that the outputs of phase $i$ when run on $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ , $x_{i}:=x_{i}(D)$ and $x_{i}^{\\prime}:=x_{i}(D^{\\prime})$ respectively, are $(\\varepsilon,\\delta)$ -indistinguishable. ", "page_idx": 15}, {"type": "text", "text": "Let $E_{i}$ be the event that the Laplace noise added in phase $i$ (for data set $\\mathcal{D}$ ) has absolute value less than $2C/15$ and define $E_{i}^{\\prime}$ analogously for data set $\\mathcal{D}^{\\prime}$ . Note that $E_{i}$ and $E_{i}^{\\prime}$ are independent and $\\mathbb{P}(E_{i},E_{i}^{\\prime})\\geq1-\\delta/10e^{\\varepsilon}$ . Denote $\\zeta:=\\delta/10e^{\\varepsilon}$ . Let $a_{i}:=\\mathbf{1}(\\widehat{s}_{i}(\\tau_{i})\\geq4C/5)$ and $a_{i}^{\\prime}:=\\mathbf{1}(\\widehat{s}_{i}^{\\prime}(\\tau_{i})\\geq$ $4C/5)$ , where $\\widehat{s}_{i}(\\tau_{i})$ and $\\widehat{s}_{i}^{\\prime}(\\tau_{i})$ are the noisy concentration sc ores that we get when runnin g phase $i$ of Algorithm   1 on neig h boring $\\mathcal{D}_{i}$ and $\\mathcal{D}_{i}^{\\prime}$ , respectively. By Lemma B.2 and our choice of $C$ , we know that, conditional on $E_{i}\\cap E_{i}^{\\prime}$ and on $\\dot{a}_{i}=a_{i}^{\\prime}$ , there exists a coupling $\\Gamma$ over $(\\tilde{x}_{i},\\tilde{x}_{i}^{\\prime})$ such that for $(y_{i},y_{i}^{\\prime})$ drawn from $\\Gamma$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|y_{i}-y_{i}^{\\prime}\\|\\lesssim\\frac{\\tau_{i}\\log(1/\\zeta)}{C}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with probability at least $1-\\zeta$ . ", "page_idx": 15}, {"type": "text", "text": "Note that the sensitivity of $s_{i}$ is less than or equal to 2. Thus, by the privacy guarantees of the Laplace mechanism (Lemma A.4), we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}(a_{i}=b)\\leq e^{\\varepsilon/4}\\mathbb{P}(a_{i}^{\\prime}=b)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for any $b\\in\\{0,1\\}$ . Further, this implies ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}(a_{i}=b,E_{i})\\leq e^{\\varepsilon/4}\\left[\\mathbb{P}(a_{i}^{\\prime}=b,E_{i}^{\\prime})+\\zeta\\right].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By the bound (1), the privacy guarantee of the Gaussian mechanism (Lemma A.6), our choice of $\\sigma_{i}$ , and independence of the Laplace and Gaussian noises that we add in Algorithm 1, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}(x_{i}\\in\\mathcal{O}\\mid E_{i},a_{i}=1)\\le e^{\\varepsilon/4}\\mathbb{P}(x_{i}^{\\prime}\\in\\mathcal{O}\\mid E_{i}^{\\prime},a_{i}^{\\prime}=1)+\\frac{\\delta}{n}+\\zeta,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for any event $\\mathcal{O}\\subset\\mathcal{X}$ . ", "page_idx": 15}, {"type": "text", "text": "Moreover, since the algorithm halts and returns $x_{i}=0$ if $a_{i}=0$ , we know that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathbb{P}(x_{i}\\in\\mathcal{O}\\mid E_{i},a_{i}=0)=\\mathbb{P}(x_{i}^{\\prime}\\in\\mathcal{O}\\mid E_{i}^{\\prime},a_{i}^{\\prime}=0)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "for any event $\\mathcal{O}\\subset\\mathcal{X}$ . ", "page_idx": 15}, {"type": "text", "text": "Therefore, ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}(x_{i}\\in\\mathcal{O})=\\mathbb{P}(x_{i}\\in\\mathcal{O}\\mid E_{i})\\mathbb{P}(E_{i})+\\mathbb{P}(x_{i}\\in\\mathcal{O}\\mid E_{i}^{c})\\mathbb{P}(E_{i}^{c})}\\\\ &{\\qquad\\qquad\\leq\\mathbb{P}(x_{i}\\in\\mathcal{O}\\mid E_{i},a_{i}=1)\\mathbb{P}(E_{i},a_{i}=1)+\\mathbb{P}(x_{i}\\in\\mathcal{O}\\mid E_{i},a_{i}=0)\\mathbb{P}(E_{i},a_{i}=0)+\\mathcal{O}(\\mathcal{O}(\\mathcal{O}(\\mathcal{O}(\\mathcal{O}(\\mathcal{O})))^{2}))}\\\\ &{\\qquad\\qquad\\overset{(i)}{\\leq}e^{\\varepsilon/4}\\mathbb{P}(x_{i}^{\\prime}\\in\\mathcal{O}\\mid E_{i}^{\\prime},a_{i}^{\\prime}=1)e^{\\varepsilon/4}\\left[\\mathbb{P}(E_{i}^{\\prime},a_{i}^{\\prime}=1)+\\zeta\\right]}\\\\ &{\\qquad\\qquad+\\mathbb{P}(x_{i}^{\\prime}\\in\\mathcal{O}\\mid E_{i}^{\\prime},a_{i}^{\\prime}=0)e^{\\varepsilon/4}\\left[\\mathbb{P}(E_{i}^{\\prime},a_{i}^{\\prime}=0)+\\zeta\\right]+\\zeta}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq e^{\\varepsilon/2}\\mathbb{P}(x_{i}^{\\prime}\\in\\mathcal{O},E_{i}^{\\prime})+\\zeta\\left(2e^{\\varepsilon/2}+1\\right)}\\\\ &{\\leq e^{\\varepsilon}\\mathbb{P}(x_{i}^{\\prime}\\in\\mathcal{O})+\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $(i)$ follows from inequalities (3), (4), and (5). Thus, $x_{i}$ is $(\\varepsilon,\\delta)$ -user-level-DP. This completes the privacy proof. ", "page_idx": 16}, {"type": "text", "text": "Next, we turn to the excess risk proof. The following lemma is immediate from [FKT20, Lemma 4.5]: ", "page_idx": 16}, {"type": "text", "text": "Lemma B.3. Let $\\eta_{i}\\leq1/\\beta$ . Then, for any $y\\in\\mathcal{X}$ and all $i,j$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(\\tilde{x}_{i,j})-F(y)]\\le\\frac{\\mathbb{E}\\|y-x_{i-1}\\|^{2}}{\\eta_{i}T_{i}}+\\eta_{i}L^{2}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The next novel lemma is crucial in our analysis: ", "page_idx": 16}, {"type": "text", "text": "Lemma B.4 (Re-statement of Lemma 2.3). Assume $f(\\cdot,z)$ is convex, $L$ -Lipschitz, and $\\beta$ -smooth on $\\mathcal{X}$ with $\\eta\\le1/\\beta$ . Let $\\tilde{x}\\leftarrow S G D(D,\\eta,T,x_{0})$ and $\\tilde{y}\\gets S G D(D^{\\prime},\\eta,T,x_{0})$ be two independent runs of projected $S G D$ , where $D,D^{\\prime}\\sim P^{N}$ are i.i.d. Then, with probability at least $1-\\zeta$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|\\tilde{x}-\\tilde{y}\\|\\lesssim\\eta L\\sqrt{T\\log(d T/\\zeta)}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Proof. Let $g_{t}\\ :=\\ \\nabla f(x_{t},z_{t})$ for $z_{t}$ drawn uniformly from $D$ without replacement and $g_{t}^{\\prime}\\ :=$ $\\nabla f(y_{t},z_{t}^{\\prime})$ for $z_{t}^{\\prime}$ drawn uniformly from $D^{\\prime}$ without replacement. Let $F(x):=\\mathbb{E}_{z\\sim P}[f(x,z)]$ . ", "page_idx": 16}, {"type": "text", "text": "We will prove that $\\|x_{t}-y_{t}\\|\\lesssim\\eta L\\sqrt{T\\log(d T/\\zeta)}$ with probability at least $1-\\zeta/t$ for all $t\\in[T]$ . Note that this implies the lemma. We proceed by induction. The base case, when $t=0$ , is trivially true since $x_{0}=y_{0}$ . For the inductive hypothesis, suppose there is an absolute constant $c>0$ such that with probability at least $1-t\\zeta/T$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|x_{i}-y_{i}\\|\\leq c\\eta L\\sqrt{i\\cdot\\log(d T/\\zeta)}+2\\eta L,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "$\\forall i\\leq t$ . Then, for the inductive step, we have by non-expansiveness of projection onto convex sets, that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{x_{t+1}-y_{t+1}\\|^{2}\\leq\\|x_{t}-\\eta g_{t}-(y_{t}-\\eta g_{t}^{\\prime})\\|^{2}}\\\\ &{=\\|x_{t}-\\eta\\nabla F(x_{t})-(y_{t}-\\eta\\nabla F(y_{t}))-\\eta(g_{t}-\\nabla F(x_{t})-g_{t}^{\\prime}+\\nabla F(y_{t}))\\|^{2}}\\\\ &{=\\|x_{t}-\\eta\\nabla F(x_{t})-(y_{t}-\\eta\\nabla F(y_{t}))\\|^{2}}\\\\ &{\\phantom{x_{t}-x_{t}-y_{t}-x_{t}}-2\\eta\\langle x_{t}-\\eta\\nabla F(x_{t})-(y_{t}-\\eta\\nabla F(y_{t})),g_{t}-\\nabla F(x_{t})-g_{t}^{\\prime}+\\nabla F(y_{t})\\rangle}\\\\ &{\\phantom{x_{t}-x_{t}-y_{t}-x_{t}}+\\eta^{2}\\|g_{t}-\\nabla F(x_{t})-g_{t}^{\\prime}+\\nabla F(y_{t})\\|^{2}}\\\\ &{\\overset{(i)}{\\leq}\\|x_{t}-y_{t}\\|^{2}-2\\eta\\langle x_{t}-\\eta\\nabla F(x_{t})-(y_{t}-\\eta\\nabla F(y_{t})),g_{t}-\\nabla F(x_{t})-g_{t}^{\\prime}+\\nabla F(y_{t})\\rangle}\\\\ &{\\phantom{x_{t}-x_{t}-y_{t}-x_{t}}+4\\eta^{2}L^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $(i)$ follows from the non-expansive property of gradient descent on smooth convex function for $\\eta\\le1/\\beta$ [HRS16]. ", "page_idx": 16}, {"type": "text", "text": "Define $a_{t}:=-2\\eta\\langle x_{t}-\\eta\\nabla F(x_{t})-(y_{t}-\\eta\\nabla F(y_{t})),g_{t}-\\nabla F(x_{t})-g_{t}^{\\prime}+\\nabla F(y_{t})\\rangle.$ . By Inequality (6) and the inductive hypothesis, we obtain ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\|x_{t+1}-y_{t+1}\\|^{2}\\leq4\\eta^{2}L^{2}t+\\sum_{i=1}^{t}a_{t}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "It remains to bound $\\textstyle\\sum_{i=1}^{t}a_{i}$ . Note that $\\mathbb{E}[a_{i}\\ |\\ a_{1},\\cdot\\cdot\\cdot\\ ,a_{i-1}]=0$ , and by Lemma A.12 we know there is a constant $c>0$ such that $a_{i}$ is $\\mathrm{1SG}(c\\eta L\\|x_{i}-y_{i}\\|)$ for all $i$ . Hence by Theorem A.11, we know ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\left|\\sum_{i=1}^{t}a_{i}\\right|\\geq c\\eta L\\sqrt{\\log(d T/\\gamma)\\sum_{i\\leq t}\\|x_{i}-y_{i}\\|^{2}}\\right]\\leq1-\\zeta/T.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Conditional on the event that $\\|x_{i}-y_{i}\\|\\leq c{\\sqrt{\\log(d T/\\zeta)}}\\eta L{\\sqrt{i}}$ for all $i\\leq t$ (which happens with probability $1-t\\zeta/T$ by the inductive hypothesis), we know ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\left|\\sum_{i=1}^{t}a_{i}\\right|\\geq c^{2}(t+1)L^{2}\\eta^{2}\\log(d T/\\zeta)\\Bigg|\\|x_{i}-y_{i}\\|\\leq c\\log(d T/\\zeta)\\eta L\\sqrt{i},\\forall i\\leq t\\right]\\leq1-\\zeta/T.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence we know ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\{\\left\\|x_{t+1}-y_{t+1}\\right\\|^{2}\\geq c^{2}\\log(d T/\\zeta)\\eta^{2}L^{2}(t+1)\\Big|\\|x_{i}-y_{i}\\|\\leq c\\log(d T/\\zeta)\\eta L\\sqrt{i},\\forall i\\leq t\\right\\}\\leq1-\\zeta/T.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Combining the above pieces completes the inductive step, showing that $\\left\\|x_{t+1}\\;-\\;y_{t+1}\\right\\|\\;\\;\\leq$ $c\\sqrt{(t+1)\\log(d T/\\zeta)}\\eta L+2\\eta L$ with probability at least $1-(t+1)\\zeta/T$ . This completes the proof. ", "page_idx": 17}, {"type": "text", "text": "By combining Lemmas 2.3 and B.3 with the localization proof technique of [FKT20], we can now prove the excess risk guarantee of Theorem B.1: ", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem 2.1 - Excess risk. Excess Risk: First, we will argue that $\\begin{array}{r}{\\tilde{x}_{i}=\\frac{1}{C}\\sum_{j=1}^{C}\\tilde{x}_{i,j}}\\end{array}$ for all $i$ with high probability $\\geq1-3/n m$ . Lemma 2.3 implies that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|\\tilde{x}_{i,j}-\\tilde{x}_{i,j^{\\prime}}\\|\\le\\tau_{i}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "for all $i\\in[l],j,j^{\\prime}\\in[C]$ with probability at least $1-1/n m$ . Thus, $s_{i}(\\tau_{i})=C$ with probability at least $1-1/n m$ . Now, conditional on $s_{i}(\\tau_{i})=C$ , we have $\\widehat{s}_{i}(\\tau_{i})\\geq4C/5$ for all $i$ with probability at least $1-1/n m$ by Laplace concentration and a union bou n d. Moroever, if $\\|\\tilde{x}_{i,j}-\\tilde{x}_{i,j^{\\prime}}\\|\\le\\tau_{i}$ for all $j,j^{\\prime}$ , then $p_{i,j}=1$ for all $j$ and hence there are no outliers: ${\\cal{S}}_{i}=\\{\\tilde{x}_{i,j}\\}_{j\\in[C]}$ . By a union bound, we conclude that ${\\cal{S}}_{i}=\\{\\tilde{x}_{i,j}\\}_{j\\in[C]}$ and hence $\\begin{array}{r}{\\tilde{x}_{i}=\\frac{1}{S_{i}}\\sum_{D_{i,j}\\in S_{i}}\\tilde{x}_{i,j}}\\end{array}$ for all $i$ with probability at least $\\geq1-3/n m$ . By the law of total expectation and Lipschitz continuity, it suffices to condition on this high probability good event that $\\begin{array}{r}{\\tilde{x}_{i}=\\frac{1}{C}\\sum_{j=1}^{C}\\tilde{x}_{i,j}}\\end{array}$ for all $i$ : the total expected excess risk can only be larger than the conditional excess risk by an additive factor of at most $3L R/n m$ . ", "page_idx": 17}, {"type": "text", "text": "Now, conditional on $\\begin{array}{r}{\\tilde{x}_{i}=\\frac{1}{S_{i}}\\sum_{D_{i,j}\\in S_{i}}\\tilde{x}_{i,j}}\\end{array}$ , Lemma B.3 and Jensen\u2019s inequality implies ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(\\tilde{x}_{i})-F(\\tilde{x}_{i-1})]\\lesssim\\frac{\\mathbb{E}\\|\\tilde{x}_{i-1}-x_{i-1}\\|^{2}}{\\eta_{i}T_{i}}+\\eta_{i}L^{2}=\\frac{d\\sigma_{i-1}^{2}}{\\eta_{i}T_{i}}+\\eta_{i}L^{2}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Next, let $x_{0}^{*}:=x^{*}=\\mathrm{argmin}_{x\\in\\mathcal{X}}F(x)$ , and write ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}[F(x_{l})-F^{*}]=\\sum_{i=1}^{l}\\mathbb{E}[F(x_{i}^{*})-F(x_{i-1}^{*})]+\\mathbb{E}[F(x_{l})-F(x_{l}^{*})]}}\\\\ &{}&{\\lesssim\\frac{R^{2}}{\\eta T_{1}}+\\eta L^{2}+\\displaystyle\\sum_{i=2}^{l}\\left[\\eta_{i-1}L^{2}d+\\eta_{i}L^{2}\\right]+L^{2}\\sqrt{d}\\eta_{l}\\sqrt{T_{l}}}\\\\ &{}&{\\lesssim\\frac{R^{2}}{\\eta T_{1}}+d\\eta L^{2}+L^{2}\\sqrt{d}\\eta_{l}\\sqrt{T_{l}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Plugging in the prescribed algorithmic parameters completes the excess risk proof. ", "page_idx": 17}, {"type": "text", "text": "C Proofs of Results in Section 3 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Theorem C.1 (Re-statement of Theorem 3.1). Let $\\varepsilon\\ \\leq\\ 10,$ , $q\\ \\ >\\ \\ 0$ such that $n^{1-q}\\ \\ >$ 100 l\u03b5o(g1(\u22122(01n/m2)dqe)\u03b5/\u03b4). Then, Algorithm 3 is (\u03b5, \u03b4)-DP. ", "page_idx": 17}, {"type": "text", "text": "We require the following lemma, which is a direct consequence of [AL24, Lemma 3.5]: ", "page_idx": 17}, {"type": "text", "text": "Lemma C.2. Consider Algorithm 2. Let $\\mathcal{D}_{i}^{\\prime}$ and $\\mathcal{D}_{i}^{\\prime}$ be two data sets that differ in the data of one user. Let $E_{i}\\,=\\,\\{|v_{i}^{t}|\\,\\le\\,K_{i}/20\\,\\forall t\\,\\in\\,[T_{i}]\\cap|\\xi_{i}|\\,\\le\\,K_{i}/20\\}.$ . Define $E_{i}^{\\prime}$ similarly for independent draws of random Laplace noise: $E_{i}^{\\prime}\\,=\\,\\{|(v_{i}^{t})^{\\prime}|\\le K_{i}/20\\,\\forall t\\in[T_{i}]\\cap|\\xi_{i}^{\\prime}|\\le K_{i}/20\\}$ . Let $a_{i}^{t}\\ =$ $\\mathbf{1}(\\widehat{s}_{i}^{t}(D_{i})\\geq4K_{i}/5)$ ) and $b_{i}^{t}=\\mathbf{1}(\\widehat{s}_{i}^{t}({\\mathcal{D}}_{i}^{\\prime})\\geq4K_{i}/5)$ denote the concentration scores in iteration $t$ . The n, conditional on $E_{i}\\cap E_{i}^{\\prime}$ and  conditional on $a_{i}^{t}=b_{i}^{t}$ , there exists a coupling $\\Gamma_{i}^{t}$ over $g_{i}^{t}(\\mathcal{D}_{i})$ and $g_{i}^{t}(\\mathcal{D}_{i}^{\\prime})$ such that for $(h,h^{\\prime})$ drawn from $\\Gamma_{i}$ , we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|h-h^{\\prime}\\|\\lesssim\\frac{\\tau\\log(1/\\zeta)}{K_{i}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "with probability at least $1-\\zeta$ . ", "page_idx": 18}, {"type": "text", "text": "Proof of Theorem C.1. Note that our assumption on $n^{1-q}$ being sufficiently large implies that $n_{i}\\gtrsim$ log(n\u03b5md/\u03b4)for all i \u2208[l]. By parallel composition [McS09] and post-processing, it suffices to show that $\\{\\widehat{g}_{i}^{t}\\}_{t=1}^{T_{i}}$ satisfies $(\\varepsilon,\\delta)$ -user-level DP for any $i\\,\\in\\,[l]$ . To that end, fix any $i\\,\\in\\,[l]$ and let $\\mathcal{D}$ and $\\mathcal{D}^{\\prime}$ be adjacent datasets that differ in the data of one user such that $\\mathcal{D}_{i}\\neq\\mathcal{D}_{i}^{\\prime}$ . We will show that $\\{\\widehat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}$ and $\\{\\widehat{g}_{i}^{t}(\\mathcal{D}^{\\prime})\\}_{t=1}^{T_{i}}$ are $(\\varepsilon,\\delta)$ -indistinguishable, which will imply that Algorithm 3 is $(\\varepsilon,\\delta)$ -user-level DP. ", "page_idx": 18}, {"type": "text", "text": "Let $E_{i}=\\{|v_{i}^{t}|\\leq K_{i}/20\\,\\forall t\\in[T_{i}]\\cap|\\xi_{i}|\\leq K_{i}/20\\}$ . Define $E_{i}^{\\prime}$ similarly for independent draws of random Laplace noise: $E_{i}^{\\prime}=\\^{\\prime}\\{|\\bar{(}v_{i}^{t})^{\\prime}|\\le K_{i}/20\\,\\forall t\\in[T_{i}]\\cap|\\xi_{i}^{j}|\\le K_{i}/20\\}$ . Our choice of $K_{i}\\geq$ $\\frac{500\\log(n m d e^{\\varepsilon}/\\delta)}{\\varepsilon}$ ensures that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(E_{i}\\bigcap E_{i}^{\\prime}\\right)\\geq1-\\delta/(10e^{\\varepsilon}),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "by Laplace concentration and a union bound. Let $\\zeta:=\\delta/(10T_{i}e^{\\varepsilon})$ . ", "page_idx": 18}, {"type": "text", "text": "Let $a_{i}^{t}\\,=\\,{\\bf1}(\\widehat{s}_{i}^{t}({\\cal D})\\,\\geq\\,4K_{i}/5)$ and $b_{i}^{t}\\,=\\,{\\bf1}(\\widehat{s}_{i}^{t}({\\cal D}^{\\prime})\\,\\geq\\,{4K_{i}}/5)$ . Note that if $a_{i}^{t}\\,=\\,b_{i}^{t}\\,=\\,0$ , then $\\widehat{g}_{i}^{t}(\\mathcal{D})=0=\\widehat{g}_{i}^{t}(\\mathcal{D}^{\\prime})$ . ", "page_idx": 18}, {"type": "text", "text": "Conditional on the good event that $a_{i}^{t}=b_{i}^{t}$ for all $t$ and conditional on $E_{i}\\cap E_{i}^{\\prime}$ , we can bound the $\\ell_{2}$ -sensitivity of $g_{i}^{t}$ with high probability, via Lemma C.2 and a union bound: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\|g_{i}^{t}(\\mathcal{D})-g_{i}^{t}(\\mathcal{D}^{\\prime})\\|\\lesssim\\frac{\\tau\\log(1/\\zeta)}{K_{i}}\\lesssim\\frac{\\tau\\log(n m e^{\\varepsilon}/\\delta)}{K_{i}}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for all $t\\in[T_{i}]$ with probability at least $1-T_{i}\\zeta=1-\\delta/(10e^{\\varepsilon})$ . ", "page_idx": 18}, {"type": "text", "text": "Note that $\\{\\widehat{s}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}$ and $\\{\\widehat{s}_{i}^{t}(\\mathcal{D}^{\\prime})\\}$ are $\\varepsilon/2$ -indistinguishable by the DP guarantees of AboveThreshold in Lem ma A.9, since the  sensitivity of $s_{i}^{t}$ is upper bounded by 2. Therefore, ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=v,E_{i})\\le e^{\\varepsilon/2}\\left[\\mathbb{P}(\\{b_{i}^{t}\\}_{t=1}^{T_{i}}=v,E_{i}^{\\prime})+\\zeta\\right]\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for any $v\\in\\{0,1\\}^{T_{i}}$ . ", "page_idx": 18}, {"type": "text", "text": "Now, by the sensitivity bound (8), the privacy guarantee of the Gaussian mechanism (Lemma A.6) and our choice of $\\sigma_{i}$ , the advanced composition theorem (Lemma A.7), and privacy amplification by subsampling (Lemma A.8), we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Im(\\{\\hat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\mid E_{i}\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=v)\\le e^{\\varepsilon/2}\\mathbb{P}(\\{\\hat{g}_{i}^{t}(\\mathcal{D}^{\\prime})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\mid E_{i}^{\\prime},\\{b_{i}^{t}\\}_{t=1}^{T_{i}}=v)+(T_{i}+1)\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for any event O \u2282X. Here we also used the fact that Ki \u2265\u221aniT\u03b5 . ", "page_idx": 18}, {"type": "text", "text": "For short-hand, write $\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=1$ if $a_{i}^{t}=1$ for all $t\\in[T_{i}]$ and $\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=0$ if $a_{i}^{t}=0$ for some $t\\in[T_{i}]$ ; similarly for $b_{i}^{t}$ . Then since the algorithm halts and returns $\\{\\widehat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}=0$ if $\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=0$ we know that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\{\\hat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\mid E_{i},\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=0)=\\mathbb{P}(\\{\\hat{g}_{i}^{t}(\\mathcal{D}^{\\prime})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\mid E_{i}^{\\prime},\\{b_{i}^{t}\\}_{t=1}^{T_{i}}=0),\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "for any event $\\mathcal{O}\\subset\\mathcal{X}$ . ", "page_idx": 18}, {"type": "text", "text": "Combining the above pieces, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\{\\widehat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}\\in\\mathcal{O})=\\mathbb{P}(\\{\\widehat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\ |\\ E_{i})\\mathbb{P}(E_{i})+\\mathbb{P}(\\{\\widehat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\ |\\ E_{i}^{c})\\mathbb{P}(E_{i}^{c})\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\le\\mathbb{P}\\big(\\{\\widehat{g}_{i}^{t}({D})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\ |\\ E_{i},\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=1\\big)\\mathbb{P}\\big(E_{i},\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=1\\big)}\\\\ &{\\quad+\\mathbb{P}\\big(\\{\\widehat{g}_{i}^{t}({D})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\ |\\ E_{i},\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=0\\big)\\mathbb{P}\\big(E_{i},\\{a_{i}^{t}\\}_{t=1}^{T_{i}}=0\\big)+2T\\zeta}\\\\ &{\\stackrel{(i)}{\\le}e^{\\varepsilon/2}\\mathbb{P}\\big(\\{\\widehat{g}_{i}^{t}({D}^{\\prime})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\ |\\ E_{i}^{\\prime},\\{b_{i}^{t}\\}_{t=1}^{T_{i}}=1\\big)e^{\\varepsilon/4}\\left[\\mathbb{P}\\big(E_{i}^{\\prime},\\{b_{i}^{t}\\}_{t=1}^{T_{i}}=1\\big)+T\\zeta\\right]}\\\\ &{\\quad+\\mathbb{P}\\big(\\{\\widehat{g}_{i}^{t}({D}^{\\prime})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\ |\\ E_{i}^{\\prime},\\{b_{i}^{t}\\}_{t=1}^{T_{i}}=0\\big)e^{\\varepsilon/2}\\left[\\mathbb{P}\\big(E_{i}^{\\prime},\\{b_{i}^{t}\\}_{t=1}^{T_{i}}=0\\big)+T\\zeta\\right]+T\\zeta}\\\\ &{\\le e^{\\varepsilon/2}\\mathbb{P}\\big(\\{\\widehat{g}_{i}^{t}({D}^{\\prime})\\}_{t=1}^{T_{i}}\\in\\mathcal{O},E_{i}^{\\prime}\\big)+4T\\zeta\\left(2e^{\\varepsilon/2}+1\\right)}\\\\ &{\\le e^{\\varepsilon}\\mathbb{P}\\big(\\{\\widehat{g}_{i}^{t}({D}^{\\prime})\\}_{t=1}^{T_{i}}\\in\\mathcal{O}\\big)+\\delta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $(i)$ follows from inequalities (9), (10), and (11). Thus, $\\{\\widehat{g}_{i}^{t}(\\mathcal{D})\\}_{t=1}^{T_{i}}$ is $(\\varepsilon,\\delta)$ -user-level-DP, which implies the result. ", "page_idx": 19}, {"type": "text", "text": "Theorem C.3 (Formal statement of Theorem 3.2). Let $\\varepsilon\\leq10$ and $\\delta<1/(m n)$ . Then, choosing $\\begin{array}{r}{\\lambda=\\frac{L}{R}\\left(\\frac{1}{\\sqrt{n m}}+\\frac{\\sqrt{d}}{\\varepsilon n\\sqrt{m}}\\right)}\\end{array}$ and $p\\geq3q+2.5+\\log_{n}(\\sqrt{m})$ in Algorithm $^3$ yields optimal excess risk: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}F(x_{l})-F^{*}\\leq L R\\cdot\\widetilde{O}\\left(\\frac{1}{\\sqrt{m n}}+\\frac{\\sqrt{d\\log(1/\\delta)}}{\\varepsilon n\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The gradient complexity of this algorithm is upper bounded by ", "page_idx": 19}, {"type": "equation", "text": "$$\nm n\\left(1+\\varepsilon\\left(\\frac{\\beta R}{L}\\right)^{1/4}\\left((m n)^{1/8}\\wedge\\left(\\frac{\\varepsilon^{2}n^{2}m}{d}\\right)^{1/8}\\right)\\right)+\\sqrt{\\frac{\\beta R}{L}}\\left(\\frac{n^{1/4}m^{5/4}}{\\varepsilon}+\\left(\\frac{n^{1/2}m^{5/4}}{d^{1/4}\\varepsilon^{1/2}}\\right)\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We will need the following bound on the excess empirical risk of accelerated (noisy) SGD for the proof of Theorem C.3: ", "page_idx": 19}, {"type": "text", "text": "Lemma C.4. [GL13, Proposition $7J$ Let $x^{T}$ be computed by $T$ steps of (multi-stage) Accelerated Minibatch SGD on $\\lambda$ -strongly convex, $\\beta$ -smooth $\\widehat F$ with unbiased stochastic gradient estimator $g^{t}$ such that $\\mathbb{E}\\|g^{t}-\\nabla\\widehat{F}(x^{t})\\|^{2}\\leq V^{2}$ for all $t\\in[T]$ . Then, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\widehat{F}(x^{T})-\\operatorname*{min}_{x\\in\\mathcal{X}}\\widehat{F}(x)]\\lesssim[\\widehat{F}(x^{0})-\\operatorname*{min}_{x\\in\\mathcal{X}}\\widehat{F}(x)]\\exp\\left(-T\\sqrt{\\frac{\\lambda}{\\beta}}\\right)+\\frac{V^{2}}{\\lambda T}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Remark C.5. As noted in Lemma C.4, we technically need to call a multi-stage implementation of Algorithm 2 in line 7 of Algorithm 3 (as in [GL13]) to get the desired excess risk bound for minimizing the regularized ERM problem in each iteration. For improved readability, we omitted these details in the main body. ", "page_idx": 19}, {"type": "text", "text": "Next, we obtain a bound on the variance of the noisy stochastic minibatch gradient estimator $\\widehat{g}_{i}^{t}$ in Algorithm 2, which can then be plugged in for $V^{2}$ in Lemma C.4. ", "page_idx": 19}, {"type": "text", "text": "Lemma C.6 (Re-statement of Lemma 3.5). Let $\\delta\\ \\leq\\ 1/(n m),\\varepsilon\\ \\lesssim\\ 1.$ . Denote $\\begin{array}{r l}{\\widetilde{F}_{i}(x)}&{{}:=}\\end{array}$ $\\textstyle\\frac{1}{n_{i}}\\sum_{Z_{i,j}\\in D_{i}}\\widehat{F}(x,Z_{i,j})$ . Then, conditional on $S_{i}^{t}=D_{i}^{t}$ for all $i\\in[l],t\\in[T_{i}]$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|g_{i}^{t}-\\nabla\\widetilde{F}_{i}(x_{i-1}^{t})\\|^{2}\\lesssim\\frac{L^{2}\\log(n d m)}{K m}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "for all $i\\ \\in\\ [l],t\\ \\in\\ [T_{i}]$ , where the expectation is over both the random i.i.d. draw of $\\mathcal{D}=$ $(Z_{1},.\\,.\\,.\\,,Z_{n})\\sim P^{n m}$ and the randomness in Algorithm 3. ", "page_idx": 19}, {"type": "text", "text": "Proof. By [LJCJ17, Lemma A.1], we know that, conditional on the draw of the data $D_{i}$ and for fixed $x_{i-1}^{t}$ , the variance of the minibatch estimator of the gradient of the empirical loss is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\boldsymbol{\\uptau}\\left[\\left\\lVert g_{i}^{t}-\\nabla\\widetilde{F}_{i}(x_{i-1}^{t})\\right\\rVert^{2}\\middle|D_{i},x_{i-1}^{t}\\right]=\\mathbb{E}_{\\{i_{l}\\}_{l=1}^{K}\\sim\\mathrm{Unif}(n)}\\left[\\left\\lVert\\frac{1}{K m}\\sum_{l=1}^{K}\\sum_{j=1}^{m}\\nabla f(x_{i-1}^{t},z_{i_{l},j}^{t}))-\\nabla\\widetilde{F}_{i}(x_{i-1}^{t},z_{i_{l},j}^{t})\\right\\rVert^{2}\\right]\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\leq\\frac{\\mathbf{1}(K=n)}{K}\\frac{1}{n}\\sum_{i=1}^{n}\\left\\|\\frac{1}{m}\\sum_{j=1}^{m}[\\nabla f(x_{i-1}^{t},z_{i,j}^{t})-\\nabla\\widetilde{F}_{i}(x_{i-1}^{t})]\\right\\|^{2}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Recall $\\begin{array}{r}{\\widetilde{F}_{i}(x):=\\frac{1}{n_{i}m}\\sum_{z\\in D_{i}}f(x,z)}\\end{array}$ is the empirical loss of $D_{i}$ ", "page_idx": 20}, {"type": "text", "text": "Now, for any fixed $x$ and any $Z\\in D_{i}$ , Hoeffding\u2019s inequality implies that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\nabla\\widehat{F}(x,Z)-\\nabla F(x)\\|\\le\\tau=O\\left(\\frac{L\\sqrt{\\log(n d/\\gamma)}}{\\sqrt{m}}\\right)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with probability at least $1-\\gamma$ , where $\\begin{array}{r}{\\widehat{F}(x,Z):=\\frac{1}{m}\\sum_{z\\in Z}f(x,z)}\\end{array}$ is user $Z$ \u2019s empirical loss. Thus, by the stability of user-level DP (see [BS23, Theorem 3.4]), for any $i\\in[l],t\\in[t]$ , we have that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\lVert\\nabla\\widehat{F}(x_{i-1}^{t},Z)-\\nabla F(x_{i-1}^{t})\\rVert\\leq\\tau\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "for all $Z\\in{\\mathcal{D}}$ with probability at least $1-\\gamma^{\\prime}=n(e^{2\\varepsilon}\\gamma+\\delta)$ , since $x_{i-1}^{t}$ is $(\\varepsilon,\\delta)$ -user-level DP. To make $\\gamma^{\\prime}\\lesssim1/m$ , we choose $\\gamma=1/m n$ and use the assumptions that $\\varepsilon\\lesssim1$ and $\\delta\\leq1/m n$ . Thus, for any fixed $i,t$ we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\nabla\\widehat{F}(x_{i-1}^{t},Z)-\\nabla F(x_{i-1}^{t})\\|\\lesssim\\frac{L\\sqrt{\\log(n^{2}m d)}}{\\sqrt{m}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "for all $Z\\in{\\mathcal{D}}$ with probability at least $1-1/m$ , which implies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|\\nabla\\widehat{F}(x_{i-1}^{t},Z)-\\nabla F(x_{i-1}^{t})\\|^{2}\\lesssim\\frac{L^{2}\\log(n m d)}{m}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This also implies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|\\nabla\\widehat{F}_{\\mathcal{D}}(x_{i-1}^{t})-\\nabla F(x_{i-1}^{t})\\|^{2}\\lesssim\\frac{L^{2}\\log(n m d)}{m},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "by Jensen\u2019s inequality, where $\\widehat{F}_{\\mathcal{D}}(x)$ is the empirical loss over the entire data set $\\mathcal{D}$ . Plugging the above bounds into (12) then yields ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sharp\\|g_{i}^{t}-\\nabla\\widetilde{F}_{i}(x_{i-1}^{t})\\|^{2}\\lesssim\\frac{L^{2}\\log(n d m)}{K m}=\\mathbb{E}_{\\mathcal{D}\\sim P^{n_{m}},\\{i\\}_{i=1}^{K}\\sim\\mathrm{Unif}([n])}\\left[\\bigg\\|\\displaystyle\\frac{1}{K m}\\sum_{l=1}^{K}\\sum_{j=1}^{m}\\nabla f(x_{i-1}^{t},z_{i,j}^{t})-\\right.}\\\\ {\\left.\\lesssim\\displaystyle\\frac{1(K=n)}{K}\\cdot\\frac{L^{2}\\log^{2}(n m d)}{m},\\right.\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "completing the proof. ", "page_idx": 20}, {"type": "text", "text": "We are now ready to prove Theorem C.3: ", "page_idx": 20}, {"type": "text", "text": "Proof of Theorem C.3. Excess risk: Note that the assumption in the theorem ensures that $K_{i}\\leq n_{i}$ for all $i$ . By similar arguments to those used in [AL24, Proposition 3.7], we will show that with high probability $\\geq1-2/(\\bar{n}m)$ , for all $i\\in[l],t\\in[T_{i}],S_{i}^{t}=D_{i}^{\\bar{t}}$ and hence $g_{i}^{t}$ is an unbiased estimator of $\\nabla\\widehat{F}_{D_{i}^{t}}(x_{i}^{t})$ . To show this, first note that for any $\\gamma>0$ and any fixed $x$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\nabla\\widehat{F}(x,Z_{j})-\\nabla F(x)\\|\\leq\\frac{L\\log(n d/\\gamma)}{\\sqrt{m}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "with probability at least $1-\\gamma/K_{i}$ by Hoeffding\u2019s inequality (see [AL24, Lemma 4.3]). Next, we invoke the stability of differential privacy to show that for all $t\\,\\in\\,[T_{i}]$ , $(q_{t}(Z_{i,1}^{t}),\\dots,q_{t}(Z_{i,K_{i}}^{t}))$ is $\\tau$ -concentrated (i.e. there exists $q^{*}\\ \\in\\ \\mathbb{R}^{d}$ such that $\\lVert q_{t}(Z_{i,j}^{t}\\,-\\,q^{*}\\,\\rVert\\,\\,\\leq\\,\\tau)$ with probability at least $1\\,-\\,T_{i}(e^{2\\varepsilon}\\gamma\\,+\\,\\delta)$ (see [BS23, Theorem 4.3]). By a union bound and the choice of $\\gamma\\,=\\,1/[(n m)^{5/4}\\log(n d m)e^{2\\varepsilon}]$ , we have that $(q_{t}(Z_{i,1}^{t}),\\dots,q_{t}(Z_{i,K_{i}}^{t}))$ is $\\tau$ -concentrated for all $i\\in[l],t\\in[T_{i}]$ with probability at least $1-1/n m$ . Now, $\\tau$ -concentration of $(q_{t}(Z_{i,1}^{t}),\\dots,q_{t}(Z_{i,K_{i}}^{t}))$ implies $s_{i}^{t}(\\tau)=K_{i}$ . Further, $s_{i}^{t}(\\tau)=K_{i}$ implies $\\widehat{s}_{i}^{t}(\\tau)\\geq4K_{i}/5$ with probability at least $1-\\zeta$ if $K_{i}\\geq500\\log(n m/\\zeta)$ , by Laplace concentration a n d a union bound. Next, note that $\\tau$ -concentration of $(q_{t}(Z_{i,1}^{t}),\\dots,q_{t}(Z_{i,K_{i}}^{t}))$ implies $p_{i}^{t}(Z_{i,j}^{t})=1$ for all $j\\in[K_{i}]$ and $S_{i}^{t}=D_{i}^{t}$ . Thus, $S_{i}^{t}=D_{i}^{t}$ for all $i,t$ with probability at least $1-1/n m$ . Setting $\\zeta=1/n m$ and using a union bound shows that with probability at least $1-2/n m$ , we have $S_{i}^{t}=D_{i}^{t}$ and $g_{i}^{t}=\\nabla\\widehat{F}_{D_{i}^{t}}(x_{i}^{t})$ for all $i,t$ . ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "Now, Lemma C.4 implies that, if the outlier-removal procedure in Algorithm 2 leads to an unbiased gradient estimator $g_{i}^{t}$ (line 12) for all $t\\in[T_{i}=\\widetilde{\\Theta}(1+\\sqrt{\\beta/\\lambda_{i}})]$ , then ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\widehat{F}_{i}(x_{i}^{T_{i}})-\\operatorname*{min}_{x\\in\\mathcal{X}}\\widehat{F}_{i}(x)]\\lesssim\\frac{V_{i}^{2}}{\\lambda_{i}T_{i}},\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where V i2 = maxt\u2208[ti] E\u2225git \u2212\u2207F i(xit)\u22252 \u2272 d\u03c3i2 + log(nKdmm)L2 (unconditionally, after taking expectation over the random draw of $\\mathscr{D}\\sim P^{n m}$ , by Lemma 3.5). We have shown that the event $\\mathrm{GOOD}:=\\{g_{i}^{t}=\\nabla\\widehat{F}_{D_{i}^{t}}(x_{i}^{t})$ for all $i\\in[l],t\\in[T_{i}]\\}$ occurs with probability at least $1-2/n m$ . We will condition on GOOD for the rest of the proof: note that the Lipschitz assumption implies that the total (unconditional) excess risk wil\u221al only by larger than the conditional (on GOOD) excess risk by an additive factor of at most $2L R/\\sqrt{n m}$ . ", "page_idx": 21}, {"type": "text", "text": "By stability of regularized ERM (see [SSSSS09]), we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(x_{i}^{*})-F(y)]\\lesssim\\frac{L^{2}}{\\lambda_{i}n_{i}m}+\\lambda_{i}\\mathbb{E}[\\|x_{i-1}-y\\|^{2}]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for all $i$ , where $x_{i}^{*}:=\\mathrm{argmin}_{x}\\widehat{F}_{i}(x)$ . By strong convexity and (14), we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n(\\lambda_{i}/2)\\mathbb{E}\\|x_{i}-x_{i}^{*}\\|^{2}\\leq\\mathbb{E}\\widehat{F}_{i}(x_{i})-\\widehat{F}_{i}^{*}\\lesssim\\frac{d\\sigma_{i}^{2}}{\\lambda_{i}T_{i}}+\\frac{L^{2}\\log(n d m)}{\\lambda_{i}T_{i}K_{i}m}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|x_{i}-x_{i}^{*}\\|^{2}\\lesssim\\frac{d\\sigma_{i}^{2}}{\\lambda_{i}T_{i}}+\\frac{L^{2}\\log(n d m)}{\\lambda_{i}T_{i}K_{i}m}\\lesssim\\frac{d\\tau^{2}\\log(1/\\delta)}{\\lambda_{i}^{2}\\varepsilon^{2}n_{i}^{2}}+\\frac{L^{2}\\log(n d m)}{\\lambda_{i}^{2}T_{i}K_{i}m}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Now, letting $x_{0}^{*}:=x^{*}=\\mathrm{argmin}_{x\\in\\mathcal{X}}F(x)$ and hiding logarithmic factors, we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\mathbb{E}[F(x_{l})-F^{*}]=\\sum_{i=1}^{l}\\mathbb{E}[F(x_{i}^{*})-F(x_{i-1}^{*})]+\\mathbb{E}[F(x_{l})-F(x_{l}^{*})]}}\\\\ &{}&{\\lesssim\\frac{L^{2}}{\\lambda_{1}n_{1}m}+\\lambda_{1}R^{2}+\\sum_{i=2}^{l}\\mathbb{E}\\left[\\frac{L^{2}}{\\lambda_{i}n_{i}m}+\\lambda_{i}\\|x_{i-1}-x_{i-1}^{*}\\|^{2}\\right]+L\\mathbb{E}\\|x_{l}-x_{l}^{*}\\|}\\\\ &{}&{\\lesssim\\frac{L^{2}}{\\lambda n m}+\\lambda R^{2}+\\sum_{i=2}^{l}\\bigg[\\frac{L^{2}}{\\lambda_{i}n_{i}m}+\\lambda_{i}\\left(\\frac{d\\tau^{2}\\log(1/\\delta)}{\\lambda_{i-1}^{2}\\varepsilon^{2}n_{i-1}^{2}}+\\frac{L^{2}}{\\lambda_{i-1}^{2}T_{i-1}K_{i-1}m}\\right)\\bigg]}\\\\ &{}&{\\quad+L\\frac{\\sqrt{d}\\tau\\sqrt{T_{l}\\log(1/\\delta)}}{\\lambda_{l}\\varepsilon^{m_{l}}},\\ \\ \\ \\ \\ \\ \\ \\ }\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the first inequality used (15) and Lipschitz continuity, the second inequality used (17). ", "page_idx": 21}, {"type": "text", "text": "Note t\u221ahat $K_{i}T_{i}~\\geq~n_{i}$ . Further, our choice of sufficiently large $p$ makes $\\lambda_{l}$ large enough that $\\begin{array}{r}{L\\frac{\\sqrt{d}\\tau\\sqrt{T_{l}\\log(1/\\delta)}}{\\lambda_{l}\\varepsilon n_{l}}\\leq\\frac{L R\\sqrt{d}}{\\varepsilon n\\sqrt{m}}}\\end{array}$ . Therefore, upper bounding the sum by it\u2019s corresponding geometric series gives us ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}[F(x_{l})-F^{*}]\\lesssim\\frac{L R\\sqrt{d}}{\\varepsilon n\\sqrt{m}}+\\frac{L^{2}}{\\lambda}\\left(\\frac{1}{n m}+\\frac{d\\tau^{2}\\log(1/\\delta)}{\\varepsilon^{2}n^{2}}\\right)+\\lambda R^{2}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Plugging in $\\lambda$ completes the excess risk proof. ", "page_idx": 21}, {"type": "text", "text": "Gradient Complexity: The gradient complexity is $\\scriptstyle\\sum_{i=1}^{l}T_{i}K_{i}m$ . Plugging in the prescribed choices of $T_{i}$ and $K_{i}$ completes the proof. \u53e3 ", "page_idx": 21}, {"type": "text", "text": "D Details on the non-smooth algorithm and the proof of Theorem 4.1 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "For any loss function $f(\\cdot,z)$ , we define the convolution function $f_{r}(\\cdot,z)\\,:=\\,f(\\cdot,z)\\ast n_{r}$ where $n_{r}$ is the uniform density in the $\\ell_{2}$ ball of radius $r$ centered at the origin in $\\mathbb{R}^{d}$ . Specifically, $\\begin{array}{r}{n_{r}(y)=\\frac{\\Gamma(\\frac{d}{2}+1)}{\\pi^{\\frac{d}{2}}r^{d}}}\\end{array}$ for $\\|y\\|\\leq r$ , and $n_{r}(y)=0$ otherwise. For simplicity, we omit the dependence on $z$ in the following Lemma: ", "page_idx": 22}, {"type": "text", "text": "Lemma D.1 (Randomized Smoothing, [YNS12, DBW12]). For any $r>0$ , let $\\mathcal{X}_{r}:=\\mathcal{X}+\\{x\\in$ $\\mathbb{R}^{d}:\\|x\\|\\leq r\\}$ . If $f$ is convex and $L$ -Lipschitz over $\\scriptstyle{\\mathcal{X}}_{r}$ , then the convolution function $f_{r}$ has the following properties: ", "page_idx": 22}, {"type": "text", "text": "\u2022 $f_{r}(x)\\leq f(x)\\leq f_{r}(x)+L r,$ , for all $x\\in\\mathscr{X}$ .   \n\u2022 $f_{r}$ is $L$ -Lipschitz and convex.   \n\u2022 fr is L d- smooth.   \n\u2022 For random variables $y\\sim n_{r}$ , we have $\\mathbb{E}_{y}[\\nabla f(x+y)]=\\nabla f_{r}(x)$ . ", "page_idx": 22}, {"type": "text", "text": "The following lemma can be easily seen from the proofs of Theorems 3.1 and 3.2: ", "page_idx": 22}, {"type": "text", "text": "Lemma D.2 (Privacy and utility of Algorithm 3 for general $K_{i},T_{i})$ . Let $\\varepsilon\\leq10$ , $q>0$ such that $\\begin{array}{r}{n^{1-q}>\\frac{100\\log(20n m\\bar{d}e^{\\varepsilon}/\\delta)}{\\varepsilon(1-(1/2)^{q})}}\\end{array}$ . ", "page_idx": 22}, {"type": "text", "text": "\u2022 If $\\begin{array}{r}{^{\\ '}K_{i}\\gtrsim\\frac{n_{i}\\varepsilon}{\\sqrt{T_{i}}}+\\frac{\\log(n m d e^{\\varepsilon}/\\delta)}{\\varepsilon}}\\end{array}$ , then Algorithm 3 is $(\\varepsilon,\\delta)$ -user-level DP. \u2022 If $T_{i}K_{i}\\geq n_{i}$ and $T_{i}\\gtrsim(1+\\sqrt{\\beta/\\lambda_{i}})\\log(n d m)$ for all i, then Algorithm 3 achieves optimal excess risk. ", "page_idx": 22}, {"type": "text", "text": "Theorem D.3 (Formal statement of Theorem 4.1). Let $\\varepsilon\\leq10$ , $\\delta<1/(m n)$ , and $q>0$ such that 100 l\u03b5o(g1(\u22122(01n/m2)dqe)\u03b5/\u03b4). Suppose that for any z, f(, z) is convex and L-Lipschitz over Xr for $\\mathcal{X}_{r}:=\\mathcal{X}+\\{x\\in\\mathbb{R}^{d}:\\|x\\|\\leq r\\}$ where $\\begin{array}{r}{r=\\frac{\\sqrt{d}}{\\varepsilon n\\sqrt{m}}R}\\end{array}$ \u03b5n\u221admR. Then, running Algorithm 3 with functions $\\{f_{r}(x;z)\\}_{z\\in D}$ yields optimal excess risk: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}F(x_{l})-F^{*}\\leq L R\\cdot\\widetilde{O}\\left(\\frac{1}{\\sqrt{m n}}+\\frac{\\sqrt{d\\log(1/\\delta)}}{\\varepsilon n\\sqrt{m}}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The gradient complexity of this algorithm is upper bounded by ", "page_idx": 22}, {"type": "equation", "text": "$$\nm n\\left(1+n^{3/8}m^{1/4}\\varepsilon^{1/4}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. By Lemma D.1 and our choice of $r$ , we have $\\begin{array}{r}{|f_{r}(x,z)-f(x,z)|\\leq L r=O(L R\\frac{{\\sqrt{d}}}{\\varepsilon n\\sqrt{m}})}\\end{array}$ . Set $\\textstyle\\lambda={\\frac{1}{\\sqrt{m n}}}$ . Then we know that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}F(x_{l})-F^{*}\\le\\mathbb{E}\\left[F_{r}(x_{l})-F_{r}^{*}\\right]+O(L R\\frac{\\sqrt{d}}{\\varepsilon n\\sqrt{m}}).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Further, $F_{r}$ is $\\beta$ -smooth for $\\begin{array}{r l r}{\\beta}&{{}\\le}&{\\frac{L}{R}\\varepsilon n\\sqrt{m}}\\end{array}$ . Set $T_{i}\\ =\\ (1\\,+\\,\\sqrt{\\beta/\\lambda_{i}})\\log(n d m)\\ =\\ 1\\ +$ $n_{i}^{3/4}m^{1/2}\\varepsilon^{1/2}\\log(n d m)$ da nydi $\\begin{array}{r}{K_{i}=\\frac{n_{i}\\varepsilon}{\\sqrt{T_{i}}}+\\frac{\\log\\left(n m d e^{\\varepsilon}/\\delta\\right)}{\\varepsilon}}\\end{array}$ . Then Lemma D.2 implies that Algorithm 3 $(\\varepsilon,\\delta)$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{E}F_{r}(x_{l})-F_{r}^{*}\\leq L R\\cdot\\tilde{O}\\left(\\frac{1}{\\sqrt{m n}}+\\frac{\\sqrt{d\\log(1/\\delta)}}{\\varepsilon n\\sqrt{m}}\\right),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "as desired. The number of gradient evaluations is ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{l}T_{i}K_{i}m\\lesssim m n\\left(1+n^{3/8}m^{1/4}\\varepsilon^{1/4}\\right).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This completes the proof. ", "page_idx": 22}, {"type": "text", "text": "E Limitations ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Our work weakens the assumptions on the smoothness parameter and the number of users that are needed for user-level DP SCO. Nevertheless, our results still require certain assumptions that may not always hold in practice. For example, we assume convexity of the loss function. In deep learning scenarios, this assumption does not hold and our algorithms should not be used. Thus, user-level DP non-convex optimization is an important direction for future research [LUW24]. Furthermore, the assumption that the loss function is convex and uniformly Lipschitz continuous may not hold in certain applications, motivating the future study of user-level DP stochastic optimization with heavy tails [LR22, ALT24]. ", "page_idx": 23}, {"type": "text", "text": "Our algorithms are also faster than the previous state-of-the-art, including a linear-time Algorithm 1 with state-of-the-art excess risk. However, our error-optimal accelerated Algorithm 3 runs in superlinear time. Thus, in certain applications where a linear-time algorithm is needed due to strict computational constraints, Algorithm 1 should be used instead. ", "page_idx": 23}, {"type": "text", "text": "F Broader Impacts ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Our work on differentially private optimization for machine learning advances the field of privacypreserving ML by developing techniques that protect the privacy of individuals (users) who contribute data. The significance of privacy cannot be overstated, as it is a fundamental right enshrined in various legal systems worldwide. However, the implications of our work extend beyond its intended benefits, and it is essential to consider both potential positive and negative impacts. ", "page_idx": 23}, {"type": "text", "text": "Positive Impacts: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Enhanced Privacy Protections: By incorporating differential privacy into machine learning models, we can provide strong privacy guarantees for individuals, mitigating the risk of personal data being exposed or misused.   \n2. Ethical Data Utilization: DP ML enables organizations to leverage data while adhering to ethical standards and privacy regulations, fostering trust among users and stakeholders.   \n3. Broad Applications: The techniques we develop can be applied across diverse domains, including healthcare, finance, and social sciences, where sensitive data is prevalent. This broad applicability can drive innovations while maintaining privacy.   \n4. Educational Advancement: Our research contributes to the growing body of knowledge in privacy-preserving technologies, serving as a valuable resource for future studies and fostering an environment of continuous improvement in privacy practices. ", "page_idx": 23}, {"type": "text", "text": "Potential Negative Impacts: ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "1. Misuse by Corporations and Governments: There is a risk that our algorithms could be exploited by entities to justify the unauthorized collection of personal data under the guise of privacy compliance. Vigilant oversight and clear regulatory frameworks are necessary to prevent such abuses.   \n2. Decreased Model Accuracy: While DP ML provides privacy benefits, it can also lead to reduced model accuracy compared to non-private models. This trade-off might have adverse consequences, such as less accurate medical diagnoses or flawed economic forecasts. For example, an overly optimistic prediction of environmental impacts due to lower accuracy could be misused to weaken environmental protections. ", "page_idx": 23}, {"type": "text", "text": "While recognizing the potential for misuse and the trade-offs involved, we firmly believe that the advancement and dissemination of differentially private machine learning algorithms offer a net benefit to society. By addressing privacy concerns head-on and advocating for responsible use, we aim to contribute positively to the field of machine learning and uphold the fundamental right to privacy. Through ongoing research, collaboration, and education, we strive to enhance both the capabilities and ethical foundations of machine learning technologies. ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We state our results in Sections 2-4 and prove them in the Appendix. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: See Appendix E. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: All assumptions are provided in theorem statements and proofs are provided in the Appendix. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The research conforms to the Code of Ethics. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: See Appendix F. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 27}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: This is a theoretical paper without experiments. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]