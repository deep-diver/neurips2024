[{"figure_path": "C62d2nS3KO/figures/figures_0_1.jpg", "caption": "Figure 1: Selected 8-step samples from our distilled text-to-image model.", "description": "This figure showcases examples of images generated by the distilled text-to-image model using only 8 sampling steps.  The images demonstrate the model's capability to produce high-resolution and detailed images directly in image space without the need for autoencoders or upsamplers. The two example images depict a teddy bear playing a guitar next to a cactus and a frog wearing a sweater. These examples highlight the model's ability to generate creative and diverse outputs.", "section": "Introduction"}, {"figure_path": "C62d2nS3KO/figures/figures_4_1.jpg", "caption": "Figure 2: Visualization of Algorithm 3: Moment matching in parameter space starts with applying forward diffusion to data from our dataset, mapping this to clean samples using the distilled generator model, and then minimizes the gradient of the teacher loss on this generated data.", "description": "This figure illustrates the process of Algorithm 3, which performs moment matching in parameter space. It begins with forward diffusion applied to data from the dataset. The distilled generator model then maps this data to clean samples. Finally, the algorithm minimizes the gradient of the teacher's loss function on the generated samples, effectively matching moments in parameter space rather than directly in image space.", "section": "3.2 Parameter-space moment matching"}, {"figure_path": "C62d2nS3KO/figures/figures_7_1.jpg", "caption": "Figure 3: Multistep distillation results for a single Imagenet class obtained with two different methods of sampling from the generator during distillation: Conditional q(zs|x, zt), and unconditional q(zs|x). Our choice of sampling from the conditional yields much better sample diversity.", "description": "This figure compares the results of conditional and unconditional sampling methods during the multistep distillation process. The left panel shows samples generated using conditional sampling from q(zs|x, zt), while the right panel displays samples from unconditional sampling q(zs|x).  The comparison highlights the superior sample diversity achieved by the conditional sampling approach, showcasing a wider range of Alaskan Malamute poses and backgrounds.", "section": "5.2 Ablating conditional sampling"}, {"figure_path": "C62d2nS3KO/figures/figures_7_2.jpg", "caption": "Figure 1: Selected 8-step samples from our distilled text-to-image model.", "description": "This figure displays four example images generated by the authors' distilled text-to-image diffusion model using only 8 sampling steps.  The images showcase the model's ability to generate high-quality and diverse outputs, including a teddy bear playing a guitar, a frog wearing a sweater, windmills in a tulip field, an astronaut riding a horse in space, a panda surfing, a robot rock climber, a dragon breathing fire, and a lion ice skating.  These examples highlight the model's capacity for generating detailed, coherent, and creative imagery.", "section": "Introduction"}, {"figure_path": "C62d2nS3KO/figures/figures_8_1.jpg", "caption": "Figure 8: Implied weighting of x-predictions made during sampling in determining the final sample, for the DDPM and DDIM sampling algorithms.", "description": "This figure shows the implied weighting of the predictions made during sampling in determining the final sample for both the DDPM (Denoising Diffusion Probabilistic Models) and DDIM (Denoising Diffusion Implicit Models) sampling algorithms.  It demonstrates how different algorithms prioritize the predictions at various time steps (t) during the sampling process. The y-axis represents the weighting assigned to the x-predictions at each time step, while the x-axis represents the time steps themselves.  The graph illustrates that the DDPM algorithm assigns the highest weight to the predictions in the later stages of sampling, whereas the DDIM algorithm distributes the weight more evenly across time steps.", "section": "E How different sampling algorithms average over model predictions"}, {"figure_path": "C62d2nS3KO/figures/figures_13_1.jpg", "caption": "Figure 1: Selected 8-step samples from our distilled text-to-image model.", "description": "This figure shows four example images generated by the authors' new method for distilling text-to-image diffusion models.  The images demonstrate the quality and diversity achievable using a significantly reduced number of sampling steps (8 steps) compared to the many-step models that are typically required.  The images depict a diverse set of subjects and scenes, including a teddy bear playing a guitar, a frog wearing a sweater, windmills in a field of tulips, an astronaut on the moon with a horse, a panda surfing, a robot climbing a mountain, a dragon breathing fire and a lion skating on ice, highlighting the model's capacity for creative and high-resolution image generation.", "section": "1 Introduction"}, {"figure_path": "C62d2nS3KO/figures/figures_13_2.jpg", "caption": "Figure 3: Multistep distillation results for a single Imagenet class obtained with two different methods of sampling from the generator during distillation: Conditional q(zs|x, zt), and unconditional q(zs|x). Our choice of sampling from the conditional yields much better sample diversity.", "description": "This figure compares the results of two different sampling methods used during the multistep distillation process.  The left side shows samples generated using conditional sampling, where the next noisy data point (zs) is sampled from a distribution that conditions on both the previous noisy data point (zt) and the predicted clean data (x).  The right side shows samples from unconditional sampling, which generates noisy data independently from the predicted clean data. The results demonstrate that conditional sampling, as used in the paper's method, leads to significantly better sample diversity, showing a wider range of variations for the same object class.", "section": "5.2 Ablating conditional sampling"}, {"figure_path": "C62d2nS3KO/figures/figures_14_1.jpg", "caption": "Figure 1: Selected 8-step samples from our distilled text-to-image model.", "description": "This figure showcases four example images generated by the researchers' distilled text-to-image model using only 8 sampling steps.  The images demonstrate the model's ability to generate high-resolution, detailed images directly in image space, without needing autoencoders or upsamplers, as a teddy bear playing a guitar, a frog wearing a sweater, a cactus, and other detailed images. This highlights the efficiency and quality of the proposed method for diffusion model distillation.", "section": "Introduction"}, {"figure_path": "C62d2nS3KO/figures/figures_15_1.jpg", "caption": "Figure 1: Selected 8-step samples from our distilled text-to-image model.", "description": "This figure showcases four example images generated by the authors' distilled text-to-image model using only 8 sampling steps.  The images demonstrate the model's ability to generate diverse and high-quality images, including a teddy bear playing a guitar, a frog wearing a sweater, a field of tulips with windmills, and an astronaut riding a horse in space.  This highlights the efficiency and effectiveness of the proposed distillation method.", "section": "1 Introduction"}, {"figure_path": "C62d2nS3KO/figures/figures_17_1.jpg", "caption": "Figure 8: Implied weighting of x's predictions made during sampling in determining the final sample, for the DDPM and DDIM sampling algorithms.", "description": "This figure illustrates how the weights of the predictions made during sampling change over time for two different sampling algorithms: DDPM (Denoising Diffusion Probabilistic Models) and DDIM (Denoising Diffusion Implicit Models).  The x-axis represents the time step t, ranging from 0 to 1, and the y-axis represents the weight given to the prediction at each time step.  The plot shows that DDPM gives higher weight to predictions made earlier in the process, whereas DDIM distributes the weights more evenly.  This difference in weighting strategies reflects the different approaches these two algorithms take to generate samples from a diffusion model.", "section": "E How different sampling algorithms average over model predictions"}]