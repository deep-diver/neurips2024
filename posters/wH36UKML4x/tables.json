[{"figure_path": "wH36UKML4x/tables/tables_8_1.jpg", "caption": "Table 1: A comparison of the worst group accuracy across various methods, ours included, on five datasets. The Group Info column indicates if each method utilizes group labels of the training/validation data, with \u2713 denoting that group information is employed during both the training and validation stages. Bold numbers are the highest results overall, while underlined ones are the best among methods that may require group annotation only for model selection. CivilComments is class imbalanced, MultiNLI has imbalanced attributes, and the other three datasets have spurious correlations. The \u00d7 sign indicates that the dataset is out of the scope of the method. The mean and standard deviation are calculated over three runs with different seeds.", "description": "This table compares the worst-group accuracy of several methods (including the proposed EVaLS and its variant EVaLS-GL) across five datasets. It shows the performance of each method under different levels of group supervision (whether group labels were used during training and/or validation). The datasets include those with spurious correlations, class imbalance, and attribute imbalance, providing a comprehensive evaluation across various scenarios.  The table highlights the performance of the proposed methods against existing state-of-the-art approaches.", "section": "4.1 Results"}, {"figure_path": "wH36UKML4x/tables/tables_8_2.jpg", "caption": "Table 2: Worst test group accuracy of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF Dataset. The mean and standard deviation are calculated based on runs with three distinct seeds.", "description": "This table presents the worst-group accuracy for four different methods on the Dominoes-CMF dataset.  ERM is the baseline Empirical Risk Minimization approach. DFR is the Deep Feature Re-weighting method. EVaLS-GL is the proposed Environment-based Validation and Loss-based Sampling method, but uses group labels for model selection.  EVaLS is the proposed method without any group labels. The results show improved worst-group accuracy with the proposed methods, particularly EVaLS.", "section": "4 Experiments"}, {"figure_path": "wH36UKML4x/tables/tables_13_1.jpg", "caption": "Table 3: The average and variation percentage (%)(across 3 seeds) of group shift between the inferred environments using EIIL [12] for each class, which is the absolute difference between the proportion of a minority group in the two environments of a class. Higher group shift indicates better separation of environments. In most cases, a significant group shift is observed between the inferred environments.", "description": "This table shows the average and variation in the group shift between environments inferred by the EIIL method for each class in the Waterbirds, CelebA, and UrbanCars datasets.  A higher group shift value indicates a greater difference in the distribution of minority groups between the two inferred environments, suggesting a better separation of environments.  The table highlights that significant group shifts are generally observed across the datasets.", "section": "4.1 Results"}, {"figure_path": "wH36UKML4x/tables/tables_20_1.jpg", "caption": "Table 1: A comparison of the worst group accuracy across various methods, ours included, on five datasets. The Group Info column indicates if each method utilizes group labels of the training/validation data, with \u2713 denoting that group information is employed during both the training and validation stages. Bold numbers are the highest results overall, while underlined ones are the best among methods that may require group annotation only for model selection. CivilComments is class imbalanced, MultiNLI has imbalanced attributes, and the other three datasets have spurious correlations. The \u00d7 sign indicates that the dataset is out of the scope of the method. The mean and standard deviation are calculated over three runs with different seeds.", "description": "This table compares the worst-group accuracy of different methods (including the proposed EVaLS and its variant with group labels for model selection, EVaLS-GL) on five datasets.  It shows the performance of each method considering the level of group annotation needed for training and model selection, highlighting the best-performing methods overall and those that perform best while requiring minimal annotations. The datasets include those with spurious correlation, class imbalance, and attribute imbalance.", "section": "4.1 Results"}, {"figure_path": "wH36UKML4x/tables/tables_20_2.jpg", "caption": "Table 1: A comparison of the worst group accuracy across various methods, ours included, on five datasets. The Group Info column indicates if each method utilizes group labels of the training/validation data, with \u2713 denoting that group information is employed during both the training and validation stages. Bold numbers are the highest results overall, while underlined ones are the best among methods that may require group annotation only for model selection. CivilComments is class imbalanced, MultiNLI has imbalanced attributes, and the other three datasets have spurious correlations. The \u00d7 sign indicates that the dataset is out of the scope of the method. The mean and standard deviation are calculated over three runs with different seeds.", "description": "This table compares the worst-group accuracy of different methods (including the proposed EVaLS and EVaLS-GL) on five datasets. It shows whether each method uses group labels for training and/or model selection and indicates the best results overall and among methods requiring only model selection group labels. Datasets include those with spurious correlations, class imbalances, and attribute imbalances.", "section": "4.1 Results"}, {"figure_path": "wH36UKML4x/tables/tables_21_1.jpg", "caption": "Table 2: Worst test group accuracy of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF Dataset. The mean and standard deviation are calculated based on runs with three distinct seeds.", "description": "This table presents the worst-group accuracy results for four different methods: ERM (Empirical Risk Minimization), DFR (Deep Feature Re-weighting), EVaLS-GL (Environment-based Validation and Loss-based Sampling with Group Labels), and EVaLS (Environment-based Validation and Loss-based Sampling).  The Dominoes-CMF dataset is used, which features multiple spurious correlations, highlighting the robustness of the proposed methods to these challenging conditions.  The mean and standard deviation across three independent runs are provided for each method.", "section": "4.1 Results"}, {"figure_path": "wH36UKML4x/tables/tables_21_2.jpg", "caption": "Table 6: A Comparison of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF Dataset. Both the worst and average of test group accuracies are presented. The mean and standard deviation are calculated based on runs with three distinct seeds.", "description": "This table compares the performance of four different methods (ERM, DFR, EVaLS-GL, and EVaLS) on the Dominoes-CMF dataset.  For each method, it shows the worst-group accuracy and the average group accuracy.  The mean and standard deviation are also included to show the variability of the results across multiple runs.", "section": "4.1 Results"}, {"figure_path": "wH36UKML4x/tables/tables_21_3.jpg", "caption": "Table 6: A Comparison of ERM, DFR, EVaLS, and EVaLS-GL on the Dominoes-CMF Dataset. Both the worst and average of test group accuracies are presented. The mean and standard deviation are calculated based on runs with three distinct seeds.", "description": "This table compares the performance of four different methods (ERM, DFR, EVaLS-GL, and EVaLS) on the Dominoes-CMF dataset in terms of worst-group accuracy and average accuracy.  The results are averaged across three separate runs, each using a different random seed, with mean and standard deviation reported to show variability.", "section": "4.1 Results"}, {"figure_path": "wH36UKML4x/tables/tables_24_1.jpg", "caption": "Table 9: Results of DFR and AFR with EIIL-inferred environment for model selection.", "description": "This table shows the results of applying Deep Feature Rewighting (DFR) and Automatic Feature Reweighting (AFR) methods while using Environment Inference for Invariant Learning (EIIL) for model selection.  It compares the worst-group accuracy achieved on the Waterbirds and Celeba datasets using these combined methods.", "section": "E Ablation Study"}, {"figure_path": "wH36UKML4x/tables/tables_24_2.jpg", "caption": "Table 10: The performances of three environment inference methods, when combined with loss-based sample selection, are evaluated on spurious correlation benchmarks. The mean and standard deviation values are calculated over three separate runs, each initiated with a different seed.", "description": "This table compares the performance of three different environment inference methods (EVaLS-ES, EVaLS-RC, and EVaLS) when used in conjunction with loss-based sampling for handling spurious correlations in image classification.  The methods are evaluated on three benchmark datasets (Waterbirds, CelebA, UrbanCars), and the results show the worst-group accuracy and average accuracy across groups.  The table helps to understand the impact of different group inference techniques on model robustness.", "section": "E Ablation Study"}]