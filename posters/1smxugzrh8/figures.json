[{"figure_path": "1SmXUGzrH8/figures/figures_0_1.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control various fine-grained style aspects, such as color, object placement, background, and texture.  The left image in each pair shows the style reference image that the model was fine-tuned on.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_1_1.jpg", "caption": "Figure 2: StyleDrop [41] tends to leak contents of the style reference image into generated images, such as the spindle leaves in the background of \u201ca sneaker\u201d, even though it is not included in the text prompt. FineStyle learns by pinpointing desirable style attributes (e.g., flat cartoon vector art) and mitigates the leakage of unwanted content (e.g., spindle leaves) at generation.", "description": "This figure compares the results of StyleDrop and FineStyle models when generating images of sneakers.  StyleDrop, a state-of-the-art model, suffers from content leakage, generating images that include elements from the style reference image (spindle leaves) that are not specified in the text prompt. FineStyle, in contrast, mitigates this leakage by focusing on the desired style attributes, resulting in images that are more faithful to the prompt while maintaining the style.", "section": "1 Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_4_1.jpg", "caption": "Figure 3: An overview of FineStyle framework, including the concept-oriented data scaling workflow (arrows) and PEFT adapters (green box) applied to key and value kernels within transformer blocks. The workflow starts from the top-left with a single image-text pair containing user-specified concepts in colored texts. The image-text cross-attention map (top-right) is retrieved from the dot product between the query and key matrices. From an attention map, we aggregate attention values corresponding to the user-specified concepts (e.g., laptop, woman, or plant) to create extra training pairs, as in (a), (b), and (c), each of which focuses on different subjects, derived from a single style image.", "description": "This figure illustrates the FineStyle framework.  It shows how a single style image and its corresponding text prompt are decomposed into multiple concept-oriented sub-image-text pairs. This concept-oriented data scaling increases the amount of training data for fine-tuning.  The figure also highlights the use of parameter-efficient adapter tuning applied to the key and value kernels of cross-attention layers within the transformer blocks.  The overall process enhances controllability for style-personalized text-to-image generation.", "section": "Method"}, {"figure_path": "1SmXUGzrH8/figures/figures_6_1.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases FineStyle's ability to control style in text-to-image generation.  Nine pairs of images demonstrate how fine-tuning on a single style image allows for precise control over various aspects like color, objects, background, and texture. Each pair highlights a specific style attribute.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_6_2.jpg", "caption": "Figure 5: Generated images of \\\"melting golden 3d rendering\\\" style from text prompts of subjects whose semantic distance to the reference subject (\\\"flower\\\") is gradually changed from close to far. StyleDrop creates images that follow the text prompt when the subject is far from the reference subject. In contrast, FineStyle creates images of subjects even when they are semantically close (\\\"rose\\\" or \\\"mushroom\\\") to the reference subject.", "description": "This figure compares the performance of StyleDrop and FineStyle models in generating images with a specific style (\"melting golden 3d rendering\") when the subject's semantic similarity to the reference image (a flower) varies.  The x-axis represents the semantic distance from the reference image (flower), ranging from close (rose, mushroom) to far (house).  The results show that StyleDrop struggles to maintain style consistency when the subject is semantically close to the reference, whereas FineStyle better preserves the style across different subjects with varying semantic distances.", "section": "5.2 Qualitative Results"}, {"figure_path": "1SmXUGzrH8/figures/figures_7_1.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control various fine-grained style aspects, such as color, background, and texture, based on a single reference image.  The fine-grained control is showcased through textual descriptions overlaid on the images, highlighting the model's nuanced compositionality.", "section": "Method"}, {"figure_path": "1SmXUGzrH8/figures/figures_7_2.jpg", "caption": "Figure 7: An example reference image variation. The last image without \u201ctree, mountain, village\u201d is synthesized with the prompt \u201ca clear starry night sky close up in oil painting style on a blue background.\u201d", "description": "This figure demonstrates the controllable reference image variation of FineStyle.  It shows a series of images generated using different prompts, all based on a reference image similar to Van Gogh's \"The Starry Night\". The variations highlight FineStyle\u2019s ability to control the presence or absence of specific elements (trees, mountains, a village) within the generated image while maintaining the overall style.", "section": "5.2.2 Controllable Reference Image Variation"}, {"figure_path": "1SmXUGzrH8/figures/figures_9_1.jpg", "caption": "Figure 8: Effects of style (\u03bb\u2081) and semantic (\u03bb\u2082) guidance scales. The text prompt at training is \u201ca cliff bay with boats on calm water...", "description": "This figure demonstrates the impact of hyperparameters \u03bb\u2081 and \u03bb\u2082 on the generated image's fidelity to both style and semantic content.  \u03bb\u2081 controls the strength of the style, while \u03bb\u2082 controls the strength of the semantic content from the prompt.  As \u03bb\u2081 increases, the image increasingly reflects details from the style reference image, potentially leading to unwanted style leakage (like the boats). Increasing \u03bb\u2082 counteracts this leakage by better aligning the generated image with the specified semantic content of the prompt, resulting in a more balanced image.", "section": "5.4.2 Inference Hyperparameters"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_1.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control various fine-grained aspects of image style, such as color, background, and texture, based on a single reference image.  The differences between the image pairs highlight the level of style control offered by FineStyle.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_2.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control various fine-grained style aspects, such as color, object placement, background, and texture.  The left image in each pair shows the generated image, and the right image is a comparison, highlighting the controlled aspects of the generated image.  The style of each generated image is determined by a single reference image, which is shown in the corner of the left image in each pair.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_3.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases the fine-grained control over style offered by the FineStyle model.  Nine pairs of images demonstrate how the model, personalized with a single reference image, generates images with various controlled stylistic elements (color, objects, background, texture). Each pair highlights a specific stylistic concept.", "section": "Abstract"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_4.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control fine-grained style aspects, such as color, objects, background, and texture, based on a single reference image.  The reference image is shown in the corner of the left image in each pair.  The fine-grained style concepts are overlaid on the generated images for comparison.", "section": "Abstract"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_5.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model.  Each pair demonstrates the model's ability to control various fine-grained style aspects, such as color, background, object features and texture, based on a single reference image. The differences between the image pairs highlight the level of control offered by FineStyle.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_6.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases the fine-grained control offered by FineStyle over the style of images generated by personalized text-to-image models.  Nine pairs of images are shown; each pair demonstrates how a single style image influences the generated image, highlighting control over color, foreground object, background, and texture.", "section": "Abstract"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_7.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control various fine-grained style aspects such as color, object placement, background, and texture.  The left image of each pair shows the generated image, and the right image shows a similar image without the fine-grained style controls applied.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_8.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases the fine-grained style control offered by FineStyle. Nine pairs of images demonstrate how the model, fine-tuned on a single style image, generates images according to specific, nuanced prompts.  Each pair highlights the impact of factors such as color, foreground object, background, and texture.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_13_9.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases FineStyle's ability to control image generation styles with high granularity. Nine pairs of images demonstrate how fine-tuning on a single style reference image enables control over various aspects, including color, foreground objects, background, and texture. Each pair highlights a specific stylistic element, allowing for a nuanced comparison of FineStyle's capabilities.", "section": "Abstract"}, {"figure_path": "1SmXUGzrH8/figures/figures_14_1.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases the fine-grained style control offered by FineStyle.  Nine pairs of images are presented; each pair shows an image generated by a model fine-tuned on a specific style image (shown in the corner).  The image pairs highlight the model's ability to control various stylistic elements, such as color, the main object, background, and texture, demonstrating the nuanced control over style.", "section": "Abstract"}, {"figure_path": "1SmXUGzrH8/figures/figures_15_1.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases the fine-grained controllability of FineStyle in generating images.  Nine pairs of images are shown, each pair demonstrating the influence of fine-tuning on a single style reference image.  The fine-tuning allows for control over aspects like color, foreground objects, background, and texture, highlighting the model's ability to capture nuanced stylistic details.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_16_1.jpg", "caption": "Figure 4: Qualitative comparison between FineStyle and various baselines. Unwanted concepts list those appearing in training prompts but should not be in synthesis prompts.", "description": "This figure compares the image generation results of FineStyle against several baseline methods (StyleDrop, StyleAligned, and IP-Adapter) across five different styles.  Each row shows a prompt, the style reference image, and the outputs from each model.  The goal is to demonstrate FineStyle's superior performance in preventing \"content leakage.\" Content leakage refers to undesired elements from the style image appearing in generated images, even when those elements are not mentioned in the prompt.  The \"Unwanted concepts\" column lists elements present in the style image's training data but not included in the image generation prompt\u2014highlighting FineStyle's success in producing cleaner, more faithful results to the prompt alone.", "section": "5.2 Qualitative Results"}, {"figure_path": "1SmXUGzrH8/figures/figures_16_2.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated by FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control fine-grained style aspects like color, background, and texture. The left image of each pair shows the style reference image that was used for fine-tuning the model.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_16_3.jpg", "caption": "Figure 6: Extensive Style Control. (a) modifies a fine-grained style by omitting it or adding decoration to it. (b) controls multiple fine-grained styles at the same time.", "description": "This figure demonstrates FineStyle's ability to precisely control style attributes.  Panel (a) shows how omitting or adding words related to a specific style element (drips) leads to changes in the generated image's drips. The changes are subtle but noticeable, showcasing the fine-grained control. Panel (b) shows that FineStyle can control multiple style elements simultaneously, unlike other methods that struggle with such compositionality.  The images highlight FineStyle's ability to handle complex style combinations with accuracy.", "section": "5.2.1 Extensive Style Control"}, {"figure_path": "1SmXUGzrH8/figures/figures_16_4.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure shows nine pairs of images generated using FineStyle, a personalized text-to-image model. Each pair demonstrates the model's ability to control fine-grained style aspects like color, background, and texture.  The left image in each pair shows the style reference image used for fine-tuning.", "section": "Introduction"}, {"figure_path": "1SmXUGzrH8/figures/figures_16_5.jpg", "caption": "Figure 3: An overview of FineStyle framework, including the concept-oriented data scaling workflow (arrows) and PEFT adapters (green box) applied to key and value kernels within transformer blocks. The workflow starts from the top-left with a single image-text pair containing user-specified concepts in colored texts. The image-text cross-attention map (top-right) is retrieved from the dot product between the query and key matrices. From an attention map, we aggregate attention values corresponding to the user-specified concepts (e.g., laptop, woman, or plant) to create extra training pairs, as in (a), (b), and (c), each of which focuses on different subjects, derived from a single style image.", "description": "This figure illustrates the FineStyle framework's workflow. It starts with a single style image and its text description, decomposes it into multiple concept-oriented sub-image-text pairs, and uses a parameter-efficient adapter to fine-tune the key and value kernels of the transformer blocks.  The concept-oriented data scaling method amplifies training data by creating multiple sub-prompts focusing on individual concepts within the style reference image.  Cross-attention maps help identify the spatial locations of these concepts.", "section": "4 Method"}, {"figure_path": "1SmXUGzrH8/figures/figures_16_6.jpg", "caption": "Figure 6: Extensive Style Control. (a) modifies a fine-grained style by omitting it or adding decoration to it. (b) controls multiple fine-grained styles at the same time.", "description": "This figure demonstrates FineStyle's ability to control specific style attributes. In (a), the model modifies the style of melting drips by omitting or adding decorative elements. The results show that FineStyle can precisely control the style of these fine-grained elements, even with limited visual representation. (b) shows the model's capability to control multiple fine-grained styles simultaneously. This further highlights the model's enhanced control over styles due to its fine-grained concept alignment.", "section": "5.2.1 Extensive Style Control"}, {"figure_path": "1SmXUGzrH8/figures/figures_17_1.jpg", "caption": "Figure 1: Demonstration of fine-grained style controllability of FineStyle. Nine image pairs are generated by personalized text-to-image models, each of which is fine-tuned on a respective, single style reference image displayed at the corner of the left image of each pair. Fine-grained concepts are written on top of the images for comparisons, showing the nuanced compositionality encompassing color, foreground object, background, and textures. Full prompts are available in Appendix A.1. Visit https://github.com/SHI-Labs/FineStyle for code and more examples.", "description": "This figure showcases FineStyle's ability to control image generation styles with precision. Nine pairs of images are shown, each pair generated from the same text prompt but with different styles. The left image in each pair shows the style reference image used in training, highlighting FineStyle's fine-grained control over color, objects, background, and texture.", "section": "1 Introduction"}]