[{"figure_path": "1SmXUGzrH8/tables/tables_8_1.jpg", "caption": "Table 1: CLIP scores measuring image-text similarity (Text) and image-image similarity (Style). We test FineStyle alongside two variants: (a) with data scaling and a feature adapter after transformer layers, and (b) without data scaling, using an adapter at key and value kernels within transformer layers. FineStyle demonstrates the best balance between text and style scores.", "description": "This table presents the CLIP scores (a metric evaluating the quality of image generation) for four different models: Muse (baseline), StyleDrop (a state-of-the-art method), two variants of FineStyle (with and without data scaling), and FineStyle itself.  The scores are separated into Text score (measuring how well the generated image matches the given text prompt) and Style score (measuring how well the generated image matches the style of a reference image). The table aims to showcase FineStyle's superior performance by achieving a better balance between text and style fidelity.", "section": "5.1 Evaluation Setup"}, {"figure_path": "1SmXUGzrH8/tables/tables_8_2.jpg", "caption": "Table 1: CLIP scores measuring image-text similarity (Text) and image-image similarity (Style). We test FineStyle alongside two variants: (a) with data scaling and a feature adapter after transformer layers, and (b) without data scaling, using an adapter at key and value kernels within transformer layers. FineStyle demonstrates the best balance between text and style scores.", "description": "This table presents the CLIP scores for image-text similarity (Text) and image-image similarity (Style) for different methods: Muse, StyleDrop, and two variants of FineStyle (with and without data scaling and different adapter locations).  It shows the performance of FineStyle and its variants in balancing the trade-off between text and style scores in image generation, indicating that FineStyle provides the best overall performance.", "section": "5.1 Evaluation Setup"}, {"figure_path": "1SmXUGzrH8/tables/tables_14_1.jpg", "caption": "Table 3: Hyperparameters for optimizer, adapter architecture, and synthesis.", "description": "This table presents the hyperparameters used for the optimizer (Adam), adapter architecture, and image synthesis process in both FineStyle and StyleDrop.  It details the learning rate, batch size, number of training steps, projection dimension (d_prj), whether adapter parameters are shared, the total number of adapter parameters, the number of decoding steps, temperature, and the lambda values (\u03bb1, \u03bb2, \u03bbmuse) used for classifier-free guidance.  These settings are crucial in controlling the model's training and image generation behavior, highlighting the differences in approach between FineStyle and StyleDrop.", "section": "A.3 Implementation Details"}]