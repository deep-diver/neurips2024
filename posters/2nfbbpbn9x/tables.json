[{"figure_path": "2NfBBpbN9x/tables/tables_5_1.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the performance of various generative models on short time series data for unconditional generation tasks.  It uses two metrics: discriminative score (disc\u2193) and predictive score (pred\u2193). Lower scores indicate better performance.  The datasets used are Stocks, Energy, and MuJoCo, representing different characteristics of time-series data.  The 'Ours' row shows the performance of the proposed method in this paper, which consistently outperforms the existing methods.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_6_1.jpg", "caption": "Table 2: Long time series unconditional marginal, classification, and prediction tasks' results.", "description": "This table presents the results of the long-term unconditional generation experiments.  It compares the performance of the proposed method against several state-of-the-art baselines across three real-world datasets: FRED-MD, NN5 Daily, and Temperature Rain.  The evaluation metrics include marginal likelihood, classification accuracy, and prediction accuracy.  Each metric provides a quantitative assessment of how well each method captures the underlying data distribution and generates realistic time series samples.", "section": "5.2 Long-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_7_1.jpg", "caption": "Table 3: Ultra-long unconditional generation.", "description": "This table presents the results of ultra-long unconditional generation experiments on two datasets: Traffic and KDD-Cup.  The results are compared across three metrics: prediction (pred), classification (class), and marginal (marg). Lower values for prediction and marginal indicate better performance, while higher values for classification suggest that the generated samples are more difficult to distinguish from real samples. The table compares the performance of three methods: Latent-ODE, LS4, and the proposed 'Ours' method.", "section": "5.3 Ultra-long Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_8_1.jpg", "caption": "Table 4: Interpolation and extrapolation results on datasets of varying lengths. The asterisk (*) denotes non-converging runs, running for over seven days.", "description": "This table presents the results of interpolation and extrapolation experiments on various time-series datasets with varying lengths.  It compares the performance of several generative models, including ODE-RNN, Latent ODE, CRU, LS4, and the proposed 'Ours' method, in terms of mean squared error (MSE).  Lower MSE values indicate better performance.  The asterisk (*) indicates that the LS4 and CRU models did not converge for the Traffic and KDD-Cup datasets within seven days of runtime.", "section": "5.4 Conditional Generation of Time Series"}, {"figure_path": "2NfBBpbN9x/tables/tables_8_2.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the performance of various generative models on short time series data for unconditional generation tasks.  It compares the results on three datasets (Stocks, Energy, MuJoCo) across two metrics: discriminative score (disc\u2193) and predictive score (pred\u2193). Lower scores indicate better performance. The 'disc' metric uses a discriminator to assess how well the generated data resembles the real data, while 'pred' evaluates the predictability of the generated sequences using a separate prediction model.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_15_1.jpg", "caption": "Table 6: Short-term unconditional generation hyperparameters including short time Fourier transform (STFT), delay embedding (DE) hyperparameters and diffusion hyperparameters", "description": "This table lists the hyperparameters used for the short-term unconditional generation experiments. It breaks down the parameters into three categories: General (image size, learning rate, batch size), Delay Embedding (embedding (n), delay (m)), and Short Time Fourier Transform (n_fft, hop_length).  The final section covers Diffusion model parameters (U-net channels, in channels, sampling steps).  Specific values are provided for each hyperparameter for the Stocks, Energy, MuJoCo, and Sine datasets.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_16_1.jpg", "caption": "Table 7: Long-term unconditional generation hyperparameters including short time Fourier transform (STFT), delay embedding (DE) hyperparameters and diffusion hyperparameters", "description": "This table presents the hyperparameters used for long-term unconditional generation experiments. It details the settings for three datasets: FRED-MD, Temperature Rain, and NN5 Daily.  The hyperparameters are categorized into general settings (image size, learning rate, batch size), delay embedding parameters (embedding(n), delay(m)), short-time Fourier transform parameters (n_fft, hop_length), and diffusion model parameters (U-net channels, in channels, sampling steps). The table provides a comprehensive overview of the configuration used for each dataset in the long-term unconditional generation experiments. ", "section": "5.2 Long-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_17_1.jpg", "caption": "Table 8: Ultra-long unconditional generation hyperparameters including short time Fourier transform (STFT), delay embedding (DE) hyperparameters and diffusion hyperparameters", "description": "This table lists the hyperparameters used for ultra-long term unconditional generation experiments using the proposed framework.  It shows the settings for two datasets, Traffic and KDD-Cup.  The hyperparameters are categorized into General settings (image size, learning rate, batch size), Delay Embedding (DE) parameters (embedding size, delay), Short Time Fourier Transform (STFT) parameters (n_fft, hop_length), and Diffusion model parameters (U-net channels, input channels, sampling steps).  The table specifies the specific values used for each dataset and parameter type.", "section": "5.3 Ultra-long Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_18_1.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the quantitative results of the proposed method and several baseline methods on short time series unconditional generation tasks.  The metrics used for evaluation are discriminative and predictive scores. The discriminative score evaluates the similarity of generated data to real data using a proxy discriminator, while the predictive score assesses the utility of the generated data by training an independent prediction model. The table includes results for multiple datasets, namely Stocks, Energy, and MuJoCo, allowing for a comparison of performance across different data characteristics.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_19_1.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the performance comparison of different generative models on short time series data for unconditional generation tasks.  It shows the discriminative and predictive scores for various models across multiple datasets: Stocks, Energy, and MuJoCo.  Lower scores are better for both metrics, indicating better model performance in distinguishing between real and generated data (discriminative score) and making accurate predictions (predictive score). The table helps to understand the relative strengths and weaknesses of various generative models and highlights the performance improvement achieved by the proposed method.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_19_2.jpg", "caption": "Table 11: We calculate the Wasserstein distances between the original cluster, our generated samples cluster the other method cluster shown in Figs. 4, 5 and 6.", "description": "This table presents the Wasserstein distances, a measure of similarity between probability distributions, calculated for the t-SNE embeddings (2D representations) of real and generated time series data.  The comparison includes the authors' method and two other methods (GT-GAN and LS4) across several datasets: Stocks, Energy, MuJoCo, Temp Rain, NN5 Daily, Traffic, and KDD-Cup. Lower Wasserstein distances indicate higher similarity between the real and generated data distributions, suggesting better performance of the generative models.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_19_3.jpg", "caption": "Table 2: Long time series unconditional marginal, classification, and prediction tasks' results.", "description": "This table presents the quantitative results comparing the proposed method with state-of-the-art long-term time series generation methods across three real-world datasets: FRED-MD, NN5 Daily, and Temperature Rain.  The metrics used are Marginal, Classification, and Prediction, providing a comprehensive evaluation of the unconditional generation performance. Lower values for Marginal and Prediction indicate better performance, while higher values for Classification show improved realism of the generated data.", "section": "5.2 Long-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_20_1.jpg", "caption": "Table 3: Ultra-long unconditional generation.", "description": "This table presents the results of the ultra-long unconditional generation task.  It compares the performance of three different methods (Latent ODE, LS4, and the proposed method) on two datasets (Traffic and KDD-Cup). The metrics used to evaluate performance include prediction error (pred\u2193), classification accuracy (class\u2191), and marginal probability density difference (marg\u2193). Lower values for pred\u2193 and marg\u2193 indicate better performance, while higher values for class\u2191 indicate better performance. The results demonstrate that the proposed method achieves the best results across both datasets and all metrics.", "section": "5.3 Ultra-long Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_21_1.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the results of the short-term unconditional generation experiments.  It compares the performance of the proposed method against several state-of-the-art baselines across three datasets (Stocks, Energy, MuJoCo) and two metrics (discriminative and predictive scores). The discriminative score measures the similarity between generated and real data distributions, while the predictive score assesses the ability of the generated data to predict future values. Lower scores indicate better performance in both metrics.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_22_1.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the results of evaluating different generative models on three short-term time series datasets (Stocks, Energy, and MuJoCo).  Each dataset consists of short sequences (length 24). The models are evaluated using two metrics: the discriminative score (disc), which measures how well the generated data resembles the real data, and the predictive score (pred), which evaluates how well the generated data can be used to predict future values. Lower scores are better for both metrics.  The table allows comparison of the proposed method's performance against various existing state-of-the-art generative models for short time series.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_22_2.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the performance of various generative models on short time series data, specifically focusing on unconditional generation.  The models are evaluated using two metrics: discriminative score and predictive score. The discriminative score measures how well the generated data resembles real data, while the predictive score assesses the generated data's ability to be used for prediction.  Lower scores indicate better performance for both metrics. The table includes results across multiple datasets (Stocks, Energy, MuJoCo) to demonstrate the models' performance across different data characteristics.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_23_1.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the performance comparison of different generative models on three short time series datasets (Stocks, Energy, MuJoCo) for unconditional generation.  Two metrics are used for evaluation: discriminative score and predictive score. The discriminative score measures how well the generated data resembles the real data. The predictive score measures the quality of the generated data used for prediction tasks. Lower scores indicate better performance in both metrics.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_24_1.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the performance of various generative models on short time series data.  The models are evaluated using two metrics: discriminative and predictive.  The discriminative score measures the model's ability to generate realistic data indistinguishable from real data using a discriminator, while the predictive score reflects the ability of the generated time series to be accurately predicted by a separate prediction model. Lower scores are better for both metrics, indicating more realistic and predictable generated time series.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_24_2.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the results of evaluating several generative models on three short time-series datasets (Stocks, Energy, MuJoCo).  Each dataset's results are broken down into discriminative and predictive scores for each method.  Lower scores indicate better performance. The discriminative score measures how well the generated data resembles the real data, and the predictive score assesses the utility of the generated data in a prediction task. The table compares the performance of the proposed method against several strong baselines, showcasing its superior performance across all datasets and metrics.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_24_3.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the performance of various methods on short-term time series generation tasks using three datasets: Stocks, Energy, and MuJoCo.  The metrics used are 'disc' (discriminative score) and 'pred' (predictive score), both lower is better.  The table allows comparison of the proposed method to a range of existing generative models for time series data, showcasing its performance relative to state-of-the-art techniques on various metrics and datasets.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/tables/tables_25_1.jpg", "caption": "Table 21: DiffTime scaling laws, KDD Cup", "description": "This table presents the results of the DiffTime model's performance on the KDD Cup dataset at different model sizes, showing the marginal, classification, and prediction scores. It demonstrates how the model's performance changes as its size increases.  The table highlights that simply increasing model size doesn't necessarily improve the results, unlike the method proposed in the paper.", "section": "C.12 Other Image Generative Models"}, {"figure_path": "2NfBBpbN9x/tables/tables_25_2.jpg", "caption": "Table 1: Error measures for the short time series unconditional discriminative and prediction tasks.", "description": "This table presents the results of several generative models on short time series datasets, focusing on unconditional generation tasks.  The metrics used are: disc (discriminative score) which measures the model's ability to generate realistic-looking data indistinguishable from real data, and pred (predictive score) which measures the usefulness of generated data in prediction tasks. Lower disc and pred values indicate better performance. The table shows results for three distinct datasets: Stocks, Energy, and MuJoCo.  Each dataset has its own characteristics, such as dimensionality and the presence of noise or periodicity.", "section": "5.1 Short-Term Unconditional Generation"}]