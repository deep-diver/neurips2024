[{"figure_path": "2NfBBpbN9x/figures/figures_4_1.jpg", "caption": "Figure 1: Our training pipeline (top) involves transforming a time series signal to its e.g., delay embedding image, process the image with a diffusion model, and output its cleaned version. During inference (bottom), we sample from a standard normal distribution and obtain a clean image using the trained diffusion model. Finally, we transform the image back to the time series domain.", "description": "This figure illustrates the training and inference pipeline of the proposed ImagenTime framework.  During training, a time series is first transformed into an image representation using a chosen invertible transform (like delay embedding or STFT). Noise is added to this image, and a U-Net based diffusion model is trained to remove this noise and reconstruct a clean image.  The clean image is then inversely transformed back into a time series.  During inference, the process is reversed:  the diffusion model generates a clean image from random noise, and this image is then inversely transformed to produce a new, generated time series.", "section": "4 Method"}, {"figure_path": "2NfBBpbN9x/figures/figures_6_1.jpg", "caption": "Figure 3: We plot above a time series signal (A), and its image transformations via the Gramian angular field (B), STFT (C), and the delay embedding (D).", "description": "This figure shows four different image transformations applied to a sample time series signal.  Panel (A) displays the raw time series data. Panels (B), (C), and (D) illustrate how the Gramian Angular Field, the Short Time Fourier Transform (STFT), and the Delay Embedding method, respectively, transform the one-dimensional time series into a two-dimensional image representation.  Each transformation has different properties and advantages for processing time series data. The figure serves to illustrate the various image-based representations used to input the data into the proposed generative model.", "section": "Time series to image transforms"}, {"figure_path": "2NfBBpbN9x/figures/figures_14_1.jpg", "caption": "Figure 3: We plot above a time series signal (A), and its image transformations via the Gramian angular field (B), STFT (C), and the delay embedding (D).", "description": "This figure shows four different representations of the same time series data. The first panel (A) displays the original time series as a line graph. The following three panels illustrate three different image transformations of this time series data: Gramian Angular Field, Short Time Fourier Transform (STFT), and Delay Embedding.  Each image transformation provides a distinct visual representation of the time series, highlighting different aspects of its structure and characteristics. These transformations are crucial for applying computer vision techniques to time series data for tasks like generative modeling.", "section": "3 Background"}, {"figure_path": "2NfBBpbN9x/figures/figures_19_1.jpg", "caption": "Figure 2: We plot the 2D t-SNE embeddings of synthetic data generated with our method and SOTA tools vs. the real data (top). Then, we compare their probability density functions (bottom).", "description": "This figure presents a comparison of the results obtained using the proposed method against state-of-the-art (SOTA) techniques. The top row displays 2D t-SNE embeddings, visualizing how well the generated data (from both the proposed method and SOTA methods) aligns with the real data distribution. The bottom row shows the probability density functions of the generated and real data, offering a more detailed view of the similarity between the generated and real data distributions.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/figures/figures_20_1.jpg", "caption": "Figure 2: We plot the 2D t-SNE embeddings of synthetic data generated with our method and SOTA tools vs. the real data (top). Then, we compare their probability density functions (bottom).", "description": "This figure shows a comparison of the generated data from the proposed method and other state-of-the-art methods against real data. The top row presents 2D t-SNE embeddings to visualize the data distribution, where similar data points are grouped together.  The bottom row shows the probability density functions (PDFs) for each dataset, providing a detailed view of the data distribution characteristics. By visually comparing the embeddings and PDFs, one can assess how well the generated data resembles the real data and the differences between the proposed approach and other methods.", "section": "5.1 Short-Term Unconditional Generation"}, {"figure_path": "2NfBBpbN9x/figures/figures_21_1.jpg", "caption": "Figure 3: We plot above a time series signal (A), and its image transformations via the Gramian angular field (B), STFT (C), and the delay embedding (D).", "description": "This figure shows four different image representations of the same time series data.  Panel (A) displays the original time series as a line graph.  The remaining panels (B, C, and D) illustrate three different image transformations applied to the time series: the Gramian angular field, the short-time Fourier transform, and delay embedding, respectively. These image representations can be used as inputs for vision-based diffusion models.  Each method for converting a time series to an image captures different aspects of the time series' temporal structure and frequency characteristics. The visualization helps to understand how various transformations can be employed before processing the data with image-based models.", "section": "3 Background"}, {"figure_path": "2NfBBpbN9x/figures/figures_23_1.jpg", "caption": "Figure 7: Scaling analysis of different models on Stocks data. A lower discriminative score is better.", "description": "This figure presents a scaling law analysis for three different time series generative models: DiffTime, LS4, and the authors' proposed model, which leverages image transformations and diffusion models.  The x-axis represents the number of model parameters (in millions), and the y-axis represents the discriminative score, a measure of how well the generated data resembles real data (lower is better). Error bars indicate standard deviation. The figure demonstrates how the discriminative score changes as the model size increases for each method.  The goal is to assess whether increasing model complexity consistently leads to improved performance.", "section": "C.11 Scaling Laws Analysis"}]