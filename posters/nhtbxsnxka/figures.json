[{"figure_path": "NhtBXSNXKA/figures/figures_8_1.jpg", "caption": "Figure 1: Training Curves of PU Learning", "description": "This figure compares the training loss curves of different algorithms for Positive-Unlabeled (PU) learning on four datasets: Fashion-MNIST, MNIST, CIFAR10, and FER2013.  The algorithms compared include SMAG (the authors' proposed algorithm), SGD, SDCA, SSDC-SPG, SSDC-Adagrad, and SBCD.  The x-axis represents the training epoch, and the y-axis represents the training loss. The shaded regions represent the standard deviation across multiple runs for each method.  The figure shows SMAG achieving lower training loss than the baseline methods across all datasets.", "section": "5.1 Positive-Unlabeled Learning"}, {"figure_path": "NhtBXSNXKA/figures/figures_20_1.jpg", "caption": "Figure 2: Ablation Study of SMAG for PU Learning", "description": "This figure shows the ablation study of SMAG (Stochastic Moreau Envelope Approximate Gradient Method) on the PU learning task. It presents the training loss curves for different values of the hyperparameter gamma on two datasets: CIFAR10 and FER2013. Each curve represents the average training loss over multiple runs for a specific value of gamma. The shaded area around each curve indicates the standard deviation. The purpose is to illustrate how the choice of gamma affects the performance of SMAG in solving PU learning problems.", "section": "5.1 Positive-Unlabeled Learning"}]