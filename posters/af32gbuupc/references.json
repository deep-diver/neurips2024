{"references": [{"fullname_first_author": "Pierre Foret", "paper_title": "Sharpness-aware minimization for efficiently improving generalization", "publication_date": "2020-10-01", "reason": "This paper introduces Sharpness-Aware Minimization (SAM), a core technique that the current paper builds upon to improve the generalization of GNNs in few-shot node classification."}, {"fullname_first_author": "Chelsea Finn", "paper_title": "Model-agnostic meta-learning for fast adaptation of deep networks", "publication_date": "2017-00-00", "reason": "This paper introduces Model-Agnostic Meta-Learning (MAML), a foundational meta-learning algorithm used as a baseline and compared against in the current paper's experiments on few-shot node classification."}, {"fullname_first_author": "Thomas N. Kipf", "paper_title": "Semi-supervised classification with graph convolutional networks", "publication_date": "2016-09-01", "reason": "This is a highly influential paper that introduced Graph Convolutional Networks (GCNs), a fundamental architecture in graph neural networks which is used extensively as a baseline model throughout the current paper's experimental evaluation."}, {"fullname_first_author": "William L. Hamilton", "paper_title": "Inductive representation learning on large graphs", "publication_date": "2017-00-00", "reason": "This paper introduced a significant improvement to graph representation learning, which is highly relevant to the current paper's focus on enhancing GNN performance for node classification."}, {"fullname_first_author": "Petar Veli\u010dkovi\u0107", "paper_title": "Graph attention networks", "publication_date": "2017-10-01", "reason": "This paper introduced Graph Attention Networks (GATs), another important GNN architecture, used as a baseline model in the current paper's experimental comparison across different tasks."}]}