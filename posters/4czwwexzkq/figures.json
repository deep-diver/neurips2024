[{"figure_path": "4czwwExZKQ/figures/figures_0_1.jpg", "caption": "Figure 1: An active learning accelerated framework for rapid quality control of cell extraction results. Left. A typical processing of Ca2+ imaging movies involves identification of cell candidates by automated cell extraction algorithms. Middle. ActSort's preprocessing module jointly compresses the cell extraction results and the Ca2+ imaging movie to allow memory efficient cell sorting in large-scale Ca2+ imaging movies, and computes quality metrics for each cell candidate. The selection GUI allows human annotators to visually inspect the cell extraction results and annotate the true and false positive cell candidates. The active learning module, working in closed-loop feedback with the selection GUI, strategically selects next cell candidates to be annotated by the experimenter in order to optimally reduce the human effort. Right. The resulting outputs from ActSort are probabilities and binary labels (cell or not a cell) for each cell candidate.", "description": "This figure illustrates the ActSort framework, which consists of three modules: preprocessing, selection GUI, and active learning.  The preprocessing module compresses large datasets for efficient processing. The selection GUI allows human annotators to review and label cell candidates. The active learning module uses this feedback to intelligently select the most informative cells for annotation, thereby minimizing human effort and improving accuracy.", "section": "2 Results"}, {"figure_path": "4czwwExZKQ/figures/figures_2_1.jpg", "caption": "Figure 1: An active learning accelerated framework for rapid quality control of cell extraction results. Left. A typical processing of Ca2+ imaging movies involves identification of cell candidates by automated cell extraction algorithms. Middle. ActSort's preprocessing module jointly compresses the cell extraction results and the Ca2+ imaging movie to allow memory efficient cell sorting in large-scale Ca2+ imaging movies, and computes quality metrics for each cell candidate. The selection GUI allows human annotators to visually inspect the cell extraction results and annotate the true and false positive cell candidates. The active learning module, working in closed-loop feedback with the selection GUI, strategically selects next cell candidates to be annotated by the experimenter in order to optimally reduce the human effort. Right. The resulting outputs from ActSort are probabilities and binary labels (cell or not a cell) for each cell candidate.", "description": "This figure illustrates the workflow of ActSort, an active learning-based cell sorting algorithm.  The process begins with cell candidates identified from a calcium imaging movie.  ActSort's preprocessing module compresses the data to improve efficiency. A graphical user interface (GUI) allows human annotators to review and label candidates. The active learning module selects informative candidates for annotation, iteratively improving the algorithm's accuracy. The output shows probabilities and labels for each cell.", "section": "2 Results"}, {"figure_path": "4czwwExZKQ/figures/figures_3_1.jpg", "caption": "Figure 2: Feature engineering improves the accuracy of automated cell sorting with linear classifiers. A The newly engineered features increased classifiers' ability to reject false-positives and led to improved area under the receiver operating characteristic curve (Wilcoxon signed-rank tests (***p < 10-3)). B We computed the discriminability indices (d') that quantify how well each feature can separate out cells from false-positives. C Many features exhibited middle or strong effects (d' \u2265 0.5 or d' \u2265 0.8, respectively), whereas few features were not discriminative for this particular dataset. Boxes span the 25th to 75th percentiles, whiskers 1.5 times the inter-quartile range.", "description": "This figure demonstrates the impact of feature engineering on the accuracy of automated cell sorting using linear classifiers.  Panel A shows that incorporating newly engineered features significantly improved the classifier's ability to distinguish between true cells and false positives, as measured by the area under the ROC curve.  Panel B visualizes the discriminability (d') of individual features in separating cells from false positives, indicating the effectiveness of each feature.  Panel C summarizes the overall discriminative power of the different feature types (temporal, spatial, and spatiotemporal), illustrating that many features effectively separated cells from false positives.", "section": "2.2 Automated cell sorting with linear classifiers utilizing newly engineered features"}, {"figure_path": "4czwwExZKQ/figures/figures_5_1.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure shows the results of a comparison between four active learning query algorithms (random, CAL, DAL, and DCAL) in selecting samples for annotation.  Dimensionality reduction was used to visualize the selected samples in a 2D space.  The figure demonstrates that DCAL effectively selects outlier boundary samples which are diverse and near the decision boundary, leading to improved efficiency and accuracy in cell sorting compared to other methods.", "section": "Results"}, {"figure_path": "4czwwExZKQ/figures/figures_6_1.jpg", "caption": "Figure 4: ActSort converges rapidly (at 5\u201310% data) and outperforms human annotators (at 1\u20133%). We simulated online annotation scenarios using the hemisphere datasets from three distinct mice (Table S1 and Fig. 4B\u2013D). With as little as 5% annotations, DCAL achieved human level true negative rates (Fig. 4D), whereas all algorithms except DAL and random sampling had an above human level true positive rate of \u226595% with <1% annotated samples (Fig. 4C). As expected, DCAL\u2019s performance was mostly independent from the chosen weight due to the adaptive estimation process (Appendix B.3), but also distinct (and better) compared to either DAL or CAL. Notably, ActSort with DCAL reached human-level balanced accuracy with annotating roughly 3% of the full dataset and converged within <10% beyond these levels, even though the classifiers were trained on human outputs (Fig. 4B). In comparison, random sampling reached the same marks with roughly 10% and 50% annotated samples, respectively (Fig. 4B\u2013D). Next, we considered processing cell candidates from multiple animals in a single combined batch (Fig. 4E\u2013G). To test this scenario, we augmented 64 new annotators and corresponding evaluators by selecting one annotator from each dataset (Fig. S6B). Consequently, each combined dataset contained slightly more than 28,000 samples across three mice. In this experiment, with <1% annotated instances, DCAL reached human-level balanced accuracy, and had minimal improvements beyond roughly 3% annotated samples (Fig. 4E). Surprisingly, both DAL and CAL massively underperformed DCAL, offering little improvement over random sampling (Fig. 4E\u2013G). These results underscore the importance of broader coverage and better representation of the decision space, especially when the annotation dataset contains diverse cell candidates sampled from multiple imaging sessions.", "description": "This figure demonstrates the performance of ActSort, a cell-sorting algorithm, compared to human annotators. It shows that ActSort, particularly using the DCAL query algorithm, achieves high accuracy with a significantly smaller number of annotations than human annotators across different experimental settings and combined datasets. The efficiency of ActSort is highlighted by its ability to reach human-level performance with only 1-3% of annotations compared to random sampling which require a much larger percentage.", "section": "2.5 Performance evaluations of ActSort on the human annotated benchmarks"}, {"figure_path": "4czwwExZKQ/figures/figures_7_1.jpg", "caption": "Figure 4: ActSort converges rapidly (at 5\u201310% data) and outperforms human annotators (at 1\u20133%). We simulated online annotation scenarios using the hemisphere datasets from three distinct mice (Table S1 and Fig. 4B\u2013D). With as little as 5% annotations, DCAL achieved human-level true negative rates (Fig. 4D), whereas all algorithms except DAL and random sampling had an above human level true positive rate of \u226595% with <1% annotated samples (Fig. 4C). As expected, DCAL\u2019s performance was mostly independent from the chosen weight due to the adaptive estimation process (Appendix B.3), but also distinct (and better) compared to either DAL or CAL. Notably, ActSort with DCAL reached human-level balanced accuracy with annotating roughly 3% of the full dataset and converged within <10% beyond these levels, even though the classifiers were trained on human outputs (Fig. 4B). In comparison, random sampling reached the same marks with roughly 10% and 50% annotated samples, respectively (Fig. 4B\u2013D). Next, we considered processing cell candidates from multiple animals in a single combined batch (Fig. 4E\u2013G). To test this scenario, we augmented 64 new annotators and corresponding evaluators by selecting one annotator from each dataset (Fig. S6B). Consequently, each combined dataset contained slightly more than 28,000 samples across three mice. In this experiment, with <1% annotated instances, DCAL reached human-level balanced accuracy, and had minimal improvements beyond roughly 3% annotated samples (Fig. 4E). Surprisingly, both DAL and CAL massively underperformed DCAL, offering little improvement over random sampling (Fig. 4E\u2013G). These results underscore the importance of broader coverage and better representation of the decision space, especially when the annotation dataset contains diverse cell candidates sampled from multiple imaging sessions.", "description": "This figure demonstrates ActSort's performance in cell sorting, comparing it against other active learning methods and random sampling. It shows that ActSort, using the discriminative-confidence active learning (DCAL) algorithm, significantly outperforms other methods in terms of balanced accuracy, true positive rate, and true negative rate, even with a very small percentage of human-annotated data.  The experiment is performed on large-scale calcium imaging data and validates ActSort's efficiency and accuracy across different experimental conditions and datasets from multiple animals.", "section": "2.5 Performance evaluations of ActSort on the human annotated benchmarks"}, {"figure_path": "4czwwExZKQ/figures/figures_31_1.jpg", "caption": "Figure 1: An active learning accelerated framework for rapid quality control of cell extraction results. Left. A typical processing of Ca2+ imaging movies involves identification of cell candidates by automated cell extraction algorithms. Middle. ActSort's preprocessing module jointly compresses the cell extraction results and the Ca2+ imaging movie to allow memory efficient cell sorting in large-scale Ca2+ imaging movies, and computes quality metrics for each cell candidate. The selection GUI allows human annotators to visually inspect the cell extraction results and annotate the true and false positive cell candidates. The active learning module, working in closed-loop feedback with the selection GUI, strategically selects next cell candidates to be annotated by the experimenter in order to optimally reduce the human effort. Right. The resulting outputs from ActSort are probabilities and binary labels (cell or not a cell) for each cell candidate.", "description": "This figure illustrates the ActSort workflow. The left panel shows the input: a Ca2+ imaging movie and cell candidates identified by a cell extraction algorithm. The middle panel shows the core of ActSort, including the preprocessing module for memory efficiency, the selection GUI for human annotation, and the active learning module for strategic sample selection. The right panel shows the output: labeled cells with associated probabilities.", "section": "2 Results"}, {"figure_path": "4czwwExZKQ/figures/figures_31_2.jpg", "caption": "Figure 1: An active learning accelerated framework for rapid quality control of cell extraction results. Left. A typical processing of Ca2+ imaging movies involves identification of cell candidates by automated cell extraction algorithms. Middle. ActSort's preprocessing module jointly compresses the cell extraction results and the Ca2+ imaging movie to allow memory efficient cell sorting in large-scale Ca2+ imaging movies, and computes quality metrics for each cell candidate. The selection GUI allows human annotators to visually inspect the cell extraction results and annotate the true and false positive cell candidates. The active learning module, working in closed-loop feedback with the selection GUI, strategically selects next cell candidates to be annotated by the experimenter in order to optimally reduce the human effort. Right. The resulting outputs from ActSort are probabilities and binary labels (cell or not a cell) for each cell candidate.", "description": "This figure illustrates the ActSort workflow. The left side shows the input: a Ca2+ imaging movie and cell candidates from a cell extraction algorithm. The middle shows the core of ActSort: the preprocessing module (joint compression of movie and extraction results), the selection GUI (visual inspection and annotation), and the active learning module (strategic selection of candidates for annotation). The right side shows the output: labeled cells and their probabilities of being cells.  ActSort uses an active learning approach to minimize human effort in validating the cell extraction results.", "section": "2 Results"}, {"figure_path": "4czwwExZKQ/figures/figures_32_1.jpg", "caption": "Figure 1: An active learning accelerated framework for rapid quality control of cell extraction results. Left. A typical processing of Ca2+ imaging movies involves identification of cell candidates by automated cell extraction algorithms. Middle. ActSort's preprocessing module jointly compresses the cell extraction results and the Ca2+ imaging movie to allow memory efficient cell sorting in large-scale Ca2+ imaging movies, and computes quality metrics for each cell candidate. The selection GUI allows human annotators to visually inspect the cell extraction results and annotate the true and false positive cell candidates. The active learning module, working in closed-loop feedback with the selection GUI, strategically selects next cell candidates to be annotated by the experimenter in order to optimally reduce the human effort. Right. The resulting outputs from ActSort are probabilities and binary labels (cell or not a cell) for each cell candidate.", "description": "This figure illustrates the workflow of ActSort, an active learning algorithm for cell sorting in large-scale calcium imaging datasets.  The process begins with input Ca2+ imaging movies and cell candidates from a cell extraction algorithm. ActSort's preprocessing module efficiently compresses these data, computing quality metrics for each candidate. A user-friendly graphical user interface (GUI) allows human annotators to review candidates and label them as true positives or false positives. ActSort's active learning module strategically selects the most informative candidates for annotation, reducing human effort and improving accuracy. Finally, ActSort outputs probabilities and binary classifications (cell or not cell) for each cell candidate.", "section": "2 Results"}, {"figure_path": "4czwwExZKQ/figures/figures_32_2.jpg", "caption": "Figure 2: Feature engineering improves the accuracy of automated cell sorting with linear classifiers. A The newly engineered features increased classifiers' ability to reject false-positives and led to improved area under the receiver operating characteristic curve (Wilcoxon signed-rank tests (***p < 10-3)). B We computed the discriminability indices (d') that quantify how well each feature can separate out cells from false-positives. C Many features exhibited middle or strong effects (d' \u2265 0.5 or d' \u2265 0.8, respectively), whereas few features were not discriminative for this particular dataset. Boxes span the 25th to 75th percentiles, whiskers 1.5 times the inter-quartile range.", "description": "This figure demonstrates that using engineered features significantly improves the accuracy of automated cell sorting. Panel A shows the improvement in the area under the ROC curve when using all engineered features compared to only using traditional features. Panel B illustrates the discriminability index (d') for each feature, showing how well it separates cells from false positives. Panel C displays the distribution of d' values, indicating that many features are highly discriminative.", "section": "2 Results"}, {"figure_path": "4czwwExZKQ/figures/figures_33_1.jpg", "caption": "Figure 5: ActSort pre-trained with previously annotated datasets converges faster on new animals. A To test ActSort's generalization capacity, we trained cell classifiers on half of the cell candidates from one mouse (representing pre-annotated datasets) and fine-tuned on samples from another mouse (representing the new dataset that needs to be annotated) using the hemisphere dataset. The GUI displays the current dataset, whereas the active learning module trains the cell classifiers using both newly- and pre-annotated data in the background. The query algorithm then selects the next candidates for human annotation, facilitating fine-tuning to the dataset of interest (Method; Appendix D.5). B - D We created 6 pairs of mice, involving 16 augmented annotations per pair, totaling 56,020 cell candidates and 224,080 annotations. The first dataset is sorted up to 50% of cell candidates. Using the same query algorithm, the second dataset is sorted up to 20%. We evaluated various query strategies - random, CAL, DAL, and DCAL - by computing (B) balanced accuracies, (C) true positive rates, and (D) true negative rates by averaging over the 96 data-annotation pairs. Solid lines: means. Shaded areas: s.e.m. over 96 augmented annotations pairs. Dashed line and gray area: mean and s.e.m. from human annotations. See Table S8 and Fig. S13D for additional details.", "description": "This figure demonstrates ActSort's ability to generalize to new datasets using pre-trained classifiers.  It shows that using pre-training with a subset of annotated data from one mouse enables faster convergence when annotating data from a new mouse, compared to starting from scratch.  The results demonstrate the effectiveness of ActSort across different query algorithms (random, CAL, DAL, and DCAL) in terms of balanced accuracy, true positive rate, and true negative rate.", "section": "2. Results"}, {"figure_path": "4czwwExZKQ/figures/figures_33_2.jpg", "caption": "Figure 1: An active learning accelerated framework for rapid quality control of cell extraction results. Left. A typical processing of Ca2+ imaging movies involves identification of cell candidates by automated cell extraction algorithms. Middle. ActSort's preprocessing module jointly compresses the cell extraction results and the Ca2+ imaging movie to allow memory efficient cell sorting in large-scale Ca2+ imaging movies, and computes quality metrics for each cell candidate. The selection GUI allows human annotators to visually inspect the cell extraction results and annotate the true and false positive cell candidates. The active learning module, working in closed-loop feedback with the selection GUI, strategically selects next cell candidates to be annotated by the experimenter in order to optimally reduce the human effort. Right. The resulting outputs from ActSort are probabilities and binary labels (cell or not a cell) for each cell candidate.", "description": "This figure illustrates the ActSort workflow.  The left side shows the input: a calcium imaging movie and the cell candidates identified by an automated cell extraction algorithm. The middle section details ActSort's three main components: a preprocessing module (jointly compressing the movie and cell extraction results), a graphical user interface (GUI) for visual inspection and annotation, and an active learning module (strategically selecting cells for annotation). The right side shows the output: labeled cells with associated probabilities (cell or not cell).", "section": "2 Results"}, {"figure_path": "4czwwExZKQ/figures/figures_34_1.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure demonstrates that the discriminative-confidence active learning (DCAL) algorithm effectively selects outlier boundary samples for annotation, improving the efficiency of the cell sorting process.  It shows the distribution of selected samples in a reduced feature space for different query algorithms (random, CAL, DAL, and DCAL with various weights) and compares their performance in terms of boundary sample selection, diversity, and agreement with human annotators.  DCAL shows a superior balance of selecting boundary samples and achieving diverse coverage.", "section": "Results"}, {"figure_path": "4czwwExZKQ/figures/figures_34_2.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure compares four different active learning query algorithms (random, CAL, DAL, and DCAL) in terms of their ability to select boundary samples for annotation in a cell sorting task. DCAL, a novel algorithm combining aspects of CAL and DAL, demonstrates superior performance in selecting outlier boundary samples, leading to more effective and efficient annotation.", "section": "Results"}, {"figure_path": "4czwwExZKQ/figures/figures_35_1.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure shows the geometrical interpretation of different query algorithms (random, CAL, DAL, and DCAL) for active learning in cell sorting.  It uses dimension reduction to visualize how each algorithm selects samples for annotation, highlighting DCAL's ability to select outlier boundary samples that provide broad coverage and better representation of the boundary.", "section": "Results"}, {"figure_path": "4czwwExZKQ/figures/figures_36_1.jpg", "caption": "Figure S10: ActSort can process two-photon Ca2+ imaging movies with residual motion. With ActSort, we processed an example two-photon Ca2+ imaging movie recording layer 2/3 pyramidal cells in primary visual cortex (Method; Appendix C). The movie had uncorrected residual motion by design, which led to several false positives in the form of duplicates. B-I Same as Fig. S9.", "description": "This figure demonstrates the ActSort algorithm's ability to handle two-photon calcium imaging movies that contain residual motion artifacts.  The residual motion created duplicate cell candidates.  Despite this, ActSort accurately identifies and classifies cells, showing similar results (balanced accuracy, true positive rate, true negative rate, AUC, precision, F-score, and recall) compared to human annotators.  The results are presented in several subplots and highlight the algorithm's robustness even under challenging imaging conditions. ", "section": "Results"}, {"figure_path": "4czwwExZKQ/figures/figures_37_1.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure shows the geometrical interpretation of different active learning query algorithms (random, CAL, DAL, and DCAL) by visualizing their sample selection in a reduced feature space.  It demonstrates that DCAL effectively selects samples near the decision boundary while maintaining diversity, improving the efficiency and accuracy of cell sorting.", "section": "Results"}, {"figure_path": "4czwwExZKQ/figures/figures_38_1.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure demonstrates that the discriminative-confidence active learning (DCAL) algorithm effectively selects outlier boundary samples for annotation. It compares DCAL's performance to other query algorithms (random, CAL, DAL) by visualizing sample selections in a reduced feature space and quantifying the percentage of boundary samples, the distribution of candidate types, and the average cosine distance between selected samples.  The results show DCAL's superior ability to select diverse boundary samples, leading to improved efficiency in reducing annotation effort.", "section": "2.4 Geometrical interpretation of discriminative-confidence queries"}, {"figure_path": "4czwwExZKQ/figures/figures_39_1.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure demonstrates how different query algorithms in ActSort select samples for annotation.  Dimensionality reduction is used to visualize the samples in a 2D feature space. It shows that DCAL effectively selects samples near the decision boundary, balancing the selection of true and false positives, while also ensuring good coverage across the feature space.  The results demonstrate the advantages of DCAL over random, CAL, and DAL.", "section": "Results"}, {"figure_path": "4czwwExZKQ/figures/figures_40_1.jpg", "caption": "Figure 3: Discriminative-confidence active learning (DCAL) algorithm selects outlier boundary samples. A Dimension reduction via supervised partial least squares (PLS) was applied to the 9,983 cell candidates from a representative annotation of one hemisphere dataset. For each query algorithm, we sorted up to 3% cell candidates and visualized them in the PLS-reduced dimensions computed from the majority-voted held-out labels. Blue dots, cells (as annotated by one human); red dots, false positives; dashed black lines, (approximate) decision boundaries in the reduced feature space. The fraction next to DCAL indicates its user-defined initial weight. B The average percentage of the selected samples near the decision boundary (probabilities within [0.25, 0.75], Method; Appendix D.4) when sorting 3% of cell candidates with each algorithm. C The fraction of cell candidate types, based on annotators' votes (0:4/4:0 1:3/3:1 and 2:2), selected by each query algorithm normalized with respect to the total number in that particular confidence pool. D The average cosine distance between standardized features of boundary samples, the same samples that lie within the decision boundary in (B). In (B-D), each dot represents a single annotation instance. Error bars: s.e.m. over 12 annotations. All tests are two-sided Wilcoxon signed-rank tests with Bonferroni-Holm corrections (***p < 10-3, **p < 10\u22122, *p < 0.05).", "description": "This figure demonstrates how different active learning query algorithms select samples for annotation.  It shows that the discriminative-confidence active learning (DCAL) algorithm effectively selects samples near the decision boundary, while maintaining diversity and focusing on outlier samples.  The results are visualized using a dimensionality reduction technique and various metrics are provided to quantify the performance of each algorithm.", "section": "Results"}]