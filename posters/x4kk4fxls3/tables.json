[{"figure_path": "x4Kk4FxLs3/tables/tables_8_1.jpg", "caption": "Table 1: Generation quality on QM9 with explict hydrogens.", "description": "This table presents the performance of various models on the QM9 dataset, specifically focusing on the generation quality of molecules with explicit hydrogens.  The metrics used to evaluate the models are Validity, Uniqueness, Atom Stability, and Molecular Stability.  The results are compared against an optimal dataset, indicating how well each model achieves the desired properties.  The table highlights PARD's performance compared to other methods, including DiGress with various configurations and ConGress.", "section": "5.1 Molecular Graph Generation"}, {"figure_path": "x4Kk4FxLs3/tables/tables_8_2.jpg", "caption": "Table 2: Generation quality on ZINC250K.", "description": "This table presents the performance of various graph generation models on the ZINC250K dataset.  The metrics used to evaluate the models include Validity (the percentage of generated molecules that are valid chemical structures), Fr\u00e9chet ChemNet Distance (FCD, a lower score indicates better similarity to real molecules), Uniqueness (the percentage of unique molecules generated), and Model Size (the number of parameters in the model).  The table compares PARD's performance against several baseline models, highlighting PARD's superior performance in terms of Uniqueness and FCD, while also showing a relatively small model size compared to some competitors.", "section": "5.1 Molecular Graph Generation"}, {"figure_path": "x4Kk4FxLs3/tables/tables_8_3.jpg", "caption": "Table 3: Generation quality on MOSES. The top three methods use hard-coded rules (not highlight).", "description": "This table presents the performance of various graph generation models on the MOSES dataset.  The metrics used to evaluate the models include Validity (the percentage of generated graphs that are valid molecules), Uniqueness (the percentage of valid molecules that are unique), Novelty (the percentage of valid molecules that are novel and not present in the training set), Filters (a metric specific to the MOSES dataset measuring the fraction of generated molecules that pass standard filters used for the test set), Fr\u00e9chet ChemNet Distance (FCD) (a measure of similarity between generated and training molecules, lower is better), SNN (a measure of nearest neighbor similarity using Tanimoto Distance), and Scaffold (a measure of the frequency of Bemis-Murcko scaffolds in the generated molecules).  Note that the top three models, not highlighted in the table, employ hard-coded rules for generation, whereas the remaining models are general-purpose generative models. This allows for a comparison of PARD's performance against specialized and general-purpose models.", "section": "5.1 Molecular Graph Generation"}, {"figure_path": "x4Kk4FxLs3/tables/tables_8_4.jpg", "caption": "Table 4: Generation quality on generic graphs. All metrics are based on generated-to-test set MMD distances, the lower the better. Top performance is in bold, and Runner-up is underlined.", "description": "This table presents the performance of different graph generation models on five generic graph datasets: COMMUNITY-SMALL, CAVEMAN, CORA, BREAST, and GRID.  The models are evaluated using three metrics: Degree, Clustering, and Orbit, each calculated as the Maximum Mean Discrepancy (MMD) between the generated graphs and the test graphs. Lower MMD scores indicate better performance, with the best scores shown in bold and the second-best underlined.  The table shows that PARD generally outperforms the other methods across the datasets and metrics.", "section": "5.2 Generic Graph Generation"}, {"figure_path": "x4Kk4FxLs3/tables/tables_9_1.jpg", "caption": "Table 5: Ablation study on QM9 with varying maximum hops while keeping the total diffusion steps fixed (first two parts). The last part examines the effect of increasing steps for the no AR case.", "description": "This ablation study investigates the impact of autoregressive (AR) components on the performance of the diffusion model.  It compares three settings: no AR (pure diffusion), AR with varying maximum hops (controlling the number of blocks), and no AR with increased diffusion steps.  The results show the effect of AR on validity, uniqueness, molecular stability, and atom stability metrics on the QM9 dataset. The increase in performance with AR demonstrates its effectiveness in improving graph generation.", "section": "5.3 Ablation Study"}, {"figure_path": "x4Kk4FxLs3/tables/tables_9_2.jpg", "caption": "Table 6: Results for QM9 dataset with different model architectures with Kh = 3 and 140 total steps.", "description": "This table presents the ablation study results on the QM9 dataset using different model architectures: Transformer, PPGN, and PPGNTransformer.  Kh (maximum hops) is set to 3, and the total number of diffusion steps is 140.  The table compares the performance of these architectures across four metrics: Validity, Uniqueness, Molecular Stability, and Atomic Stability.  The results demonstrate the impact of architectural choices on the performance of the graph generation model.", "section": "4 Architecture Improvement"}, {"figure_path": "x4Kk4FxLs3/tables/tables_19_1.jpg", "caption": "Table 7: Dataset summary", "description": "This table summarizes the eight benchmark datasets used in the paper's experiments.  For each dataset, it provides the number of graphs, the average number of nodes (|V|avg), and the average number of edges (|E|avg). The datasets include both molecular datasets (QM9, ZINC250K, MOSES) and generic graph datasets (COMMUNITY-S, CAVEMAN, CORA, BREAST, GRID).", "section": "5.1 Molecular Graph Generation"}, {"figure_path": "x4Kk4FxLs3/tables/tables_20_1.jpg", "caption": "Table 8: Comparison of different models on QM9 dataset", "description": "This ablation study on the QM9 dataset investigates the impact of varying the number of diffusion steps per block and the total number of diffusion steps on the model's performance.  The results show that increasing the total number of diffusion steps generally improves performance, but only up to a certain point.  The best performance is achieved with a total of 140 diffusion steps, which is far less than the 500 steps used by DiGress. The table compares the performance of PARD across different configurations with DiGress's results.", "section": "5.3 Ablation Study"}, {"figure_path": "x4Kk4FxLs3/tables/tables_20_2.jpg", "caption": "Table 8: Comparison of different models on QM9 dataset", "description": "This table presents an ablation study on the QM9 dataset, comparing the performance of PARD with different numbers of diffusion steps per block and total diffusion steps.  It demonstrates the effect of varying the number of autoregressive steps on the overall model performance, highlighting the trade-off between autoregression and diffusion.  The results show that increasing the number of steps, up to a point, generally improves model performance across several metrics.", "section": "5.3 Ablation Study"}, {"figure_path": "x4Kk4FxLs3/tables/tables_21_1.jpg", "caption": "Table 10: Performance comparison of diffusion methods on GRID.", "description": "This table compares the performance of different diffusion models (EDP-GNN, GDSS, PARD, and PARD with EigenVec.) on the GRID dataset, in terms of three metrics: Degree, Clustering, and Orbit.  Lower values are better, indicating better model performance.", "section": "5.2 Generic Graph Generation"}]