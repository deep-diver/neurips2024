[{"figure_path": "uyqjpycMbU/tables/tables_6_1.jpg", "caption": "Table 1: DICE scores for ACDC, MS-CMR, and CHAOS", "description": "This table presents the DICE scores achieved by different active learning methods on three datasets: ACDC, MS-CMR, and CHAOS.  The results are broken down by the percentage of annotation used (2%, 3%, 4%, 5%, and 40%) and whether weak or full supervision was used.  The table allows comparison of the performance of the proposed method against several baselines across various annotation budgets and supervision levels.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_6_2.jpg", "caption": "Table 2: DICE scores for DAVIS", "description": "This table presents the DICE scores achieved by different active learning methods on the DAVIS dataset using fully supervised learning.  The methods are compared across various annotation percentages (10%, 20%, 30%, 40%), showing the average DICE score obtained for each method at each annotation level.  The table helps demonstrate the relative performance of each method in a fully-supervised setting with varying amounts of annotated data.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_6_3.jpg", "caption": "Table 3: Mean DICE scores over all annotation datapoints with pre-trained weights", "description": "This table presents the mean Dice Similarity Coefficient (DSC) scores achieved by different active learning methods on three datasets (ACDC, CHAOS, and DAVIS) when using pre-trained segmentation models.  The scores represent the average performance across all annotation levels, providing a comprehensive comparison of the methods' performance with pretrained models.  Higher DSC scores indicate better segmentation accuracy.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_8_1.jpg", "caption": "Table 4: Ablation study based on the mean DICE scores for the 2-5% weak annotation datapoint", "description": "This table presents the results of an ablation study conducted to evaluate the impact of different combinations of contrastive losses on the model's performance.  The study focuses on the mean DICE scores obtained for a weak annotation datapoint (2-5%).  The table shows how different combinations of NT-Xent loss (a contrastive learning method), patient group loss, volume group loss, and slice group loss affect the overall performance (mDICE). Each row represents a different model configuration indicated by checkmarks in the relevant columns.  The mDICE score is a measure of the model's segmentation accuracy.", "section": "4.6 Ablation study"}, {"figure_path": "uyqjpycMbU/tables/tables_19_1.jpg", "caption": "Table 1: DICE scores for ACDC, MS-CMR, and CHAOS", "description": "This table presents the DICE scores achieved by different active learning methods on three datasets: ACDC, MS-CMR, and CHAOS.  Results are shown for both weakly-supervised and fully-supervised settings, across various annotation percentages (2%, 3%, 4%, 5%, and 40%). The table allows for a comparison of the performance of different algorithms in low annotation budget scenarios and at higher annotation levels. ", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_20_1.jpg", "caption": "Table 1: DICE scores for ACDC, MS-CMR, and CHAOS", "description": "This table presents the Dice Similarity Coefficient (DSC) scores achieved by different active learning methods on three datasets: ACDC, MS-CMR, and CHAOS.  The scores are shown for both weakly-supervised and fully-supervised settings, across various annotation percentages (2%, 3%, 4%, 5%, and 40%).  The table allows for a comparison of the performance of different active learning strategies under different levels of annotation.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_20_2.jpg", "caption": "Table 1: DICE scores for ACDC, MS-CMR, and CHAOS", "description": "This table presents the DICE scores achieved by various active learning methods across three different datasets (ACDC, MS-CMR, and CHAOS) under both weakly and fully supervised settings.  The results are shown for different annotation percentages (2%, 3%, 4%, 5%, and 40%), allowing comparison of performance under varying annotation budgets.  This comparison helps assess the efficiency of each active learning technique in improving segmentation accuracy with limited annotations.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_20_3.jpg", "caption": "Table 2: DICE scores for DAVIS", "description": "This table presents the Dice Similarity Coefficient (DSC) scores achieved by different active learning methods on the DAVIS dataset.  The DSC is a common metric for evaluating the performance of segmentation models, representing the overlap between the predicted and ground truth segmentations.  The table shows the results for both weakly and fully supervised settings and for various annotation percentages (10%, 20%, 30%, 40%).  Higher DSC scores indicate better segmentation accuracy.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_21_1.jpg", "caption": "Table 9: DICE scores for ACDC (pretrained)", "description": "This table presents the DICE scores achieved by different active learning methods on the ACDC dataset when using pre-trained segmentation models.  The results are shown for various annotation percentages (1%, 2%, 3%, 4%, and 5%), comparing the performance of Random sampling, Stochastic Batches, Coreset, and the authors' proposed method.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_21_2.jpg", "caption": "Table 10: DICE scores for CHAOS (pretrained)", "description": "This table presents the performance of different active learning methods on the CHAOS dataset using pretrained segmentation models.  The DICE scores are shown for different annotation percentages (1%, 2%, 3%, 4%, and 5%), comparing the performance of Random sampling, Stochastic Batches, Coreset, and the proposed method.", "section": "4.3 Results"}, {"figure_path": "uyqjpycMbU/tables/tables_21_3.jpg", "caption": "Table 9: DICE scores for ACDC (pretrained)", "description": "This table presents the Dice Similarity Coefficient (DSC) scores achieved by different active learning methods on the ACDC dataset using pretrained segmentation models.  The results are broken down by the percentage of fully-supervised annotations used (1%, 2%, 3%, 4%, and 5%).  The methods compared include Random sampling, Stochastic Batches, Coreset, and the authors' proposed method.  Higher DSC scores indicate better segmentation performance.", "section": "4.3 Results"}]