[{"figure_path": "l0c1j4QvTq/tables/tables_7_1.jpg", "caption": "Table 1\nAverage final return. Computed as the mean of the highest return values observed in the final 10% of iteration steps per run, with an evaluation interval of 15,000 iterations. \u00b1 corresponds to standard deviation over five runs.", "description": "This table presents the average final return achieved by different reinforcement learning algorithms across various MuJoCo benchmark tasks.  The average is calculated from the highest return values observed during the final 10% of the training process, evaluated every 15,000 iterations.  The results represent the mean and standard deviation across five independent runs, providing a measure of algorithm performance and its stability.", "section": "5 Experiments"}, {"figure_path": "l0c1j4QvTq/tables/tables_14_1.jpg", "caption": "TABLE 2\nDETAILED HYPERPARAMETERS.", "description": "This table lists the hyperparameters used in the experiments.  It is divided into shared hyperparameters (common across all algorithms) and algorithm-specific hyperparameters. Shared hyperparameters include replay buffer capacity, batch size, initial alpha, action bounds, hidden layer structure of the actor and critic networks, activation functions, optimizer, learning rates, discount factor, reward scaling, and more. Algorithm-specific hyperparameters include those specific to the maximum-entropy framework, such as the expected entropy and the deterministic policy.", "section": "A.2 Training Details on MuJoCo tasks"}, {"figure_path": "l0c1j4QvTq/tables/tables_15_1.jpg", "caption": "TABLE 3\nALGORITHM HYPERPARAMETER", "description": "This table lists the hyperparameters used in the DACER algorithm.  It includes settings for replay buffer capacity, batch size, discount factor, learning rates for actor, critic, and alpha, and other parameters related to the diffusion model such as noise scale and the number of Gaussian distributions used for mixing.", "section": "5 Experiments"}]