[{"figure_path": "x9eFgahVBI/tables/tables_1_1.jpg", "caption": "Table 1: ICL on different single-relationship word analogy tasks, averaged over 10 repetitions, demonstrates stable, good performance across embedding dimensions (de), as Theorem 1 suggests. The corrupted setting also demonstrates excellent ICL ability under certain scenarios.", "description": "This table presents the average accuracy of In-context Learning (ICL) on single-relationship word analogy tasks.  The experiments are performed across different embedding dimensions (de) and averaged over 10 repetitions for both clean and corrupted data.  The results show consistent and good performance across the embedding dimensions, supporting Theorem 1.  Even in the corrupted setting, where some word pairs are replaced with other words, there is excellent ICL performance under certain scenarios.", "section": "2 In-context learning can arise by modeling co-occurrence via CBOW"}, {"figure_path": "x9eFgahVBI/tables/tables_3_1.jpg", "caption": "Table 1: ICL on different single-relationship word analogy tasks, averaged over 10 repetitions, demonstrates stable, good performance across embedding dimensions (dE), as Theorem 1 suggests. The corrupted setting also demonstrates excellent ICL ability under certain scenarios.", "description": "This table presents the average accuracy of In-context learning (ICL) on single-relationship word analogy tasks. The experiments were conducted with different embedding dimensions (dE = 10 and dE = 100) and different probabilities for the number of (ci, di) pairs in each sentence. Two scenarios are considered: a \"clean\" scenario, and a \"corrupted\" scenario.  The results show the ICL performance is consistent across different embedding dimensions in the clean and corrupted scenarios, supporting Theorem 1. ", "section": "2.1 In-context learning on single-relationship word analogy tasks"}, {"figure_path": "x9eFgahVBI/tables/tables_4_1.jpg", "caption": "Table 2: ICL on dual-connected-relationship tasks, averaged over 10 repetitions, achieves perfect accuracy when (po, P1,P2) \u2208 {(1/2, 0/1, 2), (0, 1/2, 1/2), (1/3, 1/3, 1/3)} regardless of architectures and embedding dimensions (de). When (po, P1, P2) = (1/2, 1/2, 0), ICL performs better under imbalanced or extreme scenarios and with larger de.", "description": "This table presents the results of in-context learning (ICL) experiments on dual-connected-relationship word analogy tasks.  It shows the accuracy of a CBOW model trained on sentences containing two distinct word relationships in different scenarios. The scenarios vary in the probability distribution of these relationships: balanced, imbalanced, and extreme. The results demonstrate that perfect ICL accuracy is achieved under certain probability distributions, regardless of model architecture and embedding dimensionality.  However, in other distributions, performance depends on factors like imbalance and embedding dimensionality.", "section": "2.2 In-context learning on dual-connected-relationship word analogy tasks"}, {"figure_path": "x9eFgahVBI/tables/tables_5_1.jpg", "caption": "Table 2: ICL on dual-connected-relationship tasks, averaged over 10 repetitions, achieves perfect accuracy when (po, P1, P2) \u2208 {(1/2, 0/1, 2), (0, 1/2, 1/2), (1/3, 1/3, 1/3)} regardless of architectures and embedding dimensions (dE). When (po, P1, P2) = (1/2, 1/2, 0), ICL already performs well under the balanced scenario.", "description": "This table shows the results of in-context learning (ICL) experiments on dual-connected-relationship word analogy tasks.  The experiments varied the probability of having zero, one, or two distinct word pairs in a sentence, along with the balance of those pairs in the data. The table shows that ICL performance is perfect under certain conditions (specific probabilities of word pair occurrences), and is robust to architectural choices and embedding dimensionality.  When only a single type of relationship is prevalent, ICL is still effective under balanced conditions. ", "section": "2.2 In-context learning on dual-connected-relationship word analogy tasks"}, {"figure_path": "x9eFgahVBI/tables/tables_6_1.jpg", "caption": "Table 4: Prediction accuracy with single/multi-layer models. For ICL to occur, the first tokens of training sentences should cover the entire vocabulary (Both). Also, positional embeddings are essential, especially in one-layer models.", "description": "This table presents the results of an experiment assessing the accuracy of single and multi-layer transformer models in predicting the last token of sequences following the pattern x1x2x3x1.  The experiment varied the number of layers (1 or 5), the type of positional embedding (learned, sinusoidal, or none), and whether each token in the vocabulary was used as the first token in both training and test sets (Both) or only one of them (Either). The results demonstrate that positional embeddings are crucial for achieving high accuracy, especially with only one layer, and that for the model to generalize well, each token should be present as the first token in both the training and test sets.", "section": "3 The essential role of positional information in enabling in-context learning"}, {"figure_path": "x9eFgahVBI/tables/tables_7_1.jpg", "caption": "Table 5: ICL on single-pattern tasks, averaged over 10 repetitions, achieves near-perfect accuracy in the clean data scenario regardless of architectures and embedding dimension (dE). The one-noisy scenario is the most challenging, with sinusoidal embeddings giving a higher accuracy. In the block-noisy scenario, learned positional embeddings result in significantly better ICL performance.", "description": "This table presents the results of in-context learning (ICL) experiments on single-pattern tasks.  It shows the accuracy of different models (with different positional embedding methods) under three scenarios: clean data, data with one randomly inserted noise token, and data with a block of noise tokens.  The results highlight the importance of positional information and the type of positional embedding used, especially in noisy scenarios. Learned positional embeddings are shown to significantly improve performance in noisy scenarios compared to sinusoidal or ROPE embeddings.", "section": "3.1 In-context learning on single-pattern tasks"}, {"figure_path": "x9eFgahVBI/tables/tables_8_1.jpg", "caption": "Table 5: ICL on single-pattern tasks, averaged over 10 repetitions, achieves near-perfect accuracy in the clean data scenario regardless of architectures and embedding dimension (dE). The one-noisy scenario is the most challenging, with sinusoidal embeddings giving a higher accuracy. In the block-noisy scenario, learned positional embeddings result in significantly better ICL performance.", "description": "This table presents the results of in-context learning (ICL) experiments on single-pattern tasks with different noise conditions. The accuracy of predicting the last token in a sequence (abacdc) is evaluated under three scenarios: clean (no noise), one-noisy (one random token inserted), and block-noisy (three consecutive random tokens inserted). The table shows that accuracy is high in the clean scenario but significantly lower in the noisy scenarios.  Learned positional embeddings improve performance in the block-noisy condition, whereas sinusoidal embeddings are better in the one-noisy condition.  This highlights the importance of positional information and data structure for ICL.", "section": "3.1 In-context learning on single-pattern tasks"}, {"figure_path": "x9eFgahVBI/tables/tables_9_1.jpg", "caption": "Table 7: ICL in failed scenarios, averaged over 10 repetitions, achieves zero accuracy for any architecture and embedding dimension (d<sub>E</sub>).", "description": "This table presents the results of in-context learning (ICL) experiments in two scenarios where ICL fails, regardless of the model architecture or embedding dimension.  The experiments are performed using both learned and sinusoidal positional embeddings with 1-layer and 5-layer models.  The results demonstrate that in both scenarios,  the accuracy of ICL is zero, indicating a complete failure of ICL to learn in these specific setups.", "section": "4 Scenarios where in-context learning fails"}, {"figure_path": "x9eFgahVBI/tables/tables_22_1.jpg", "caption": "Table 8: ICL performance in the clean scenario, evaluated with both squared and cross-entropy loss functions across different numbers of examples (0 to 8) with dE = 100, averaged over 10 repetitions.", "description": "This table shows the accuracy of In-context Learning (ICL) in a clean scenario (without noise) for single-relationship word analogy tasks using the Continuous Bag-of-Words (CBOW) model.  It compares the performance using two different loss functions (squared loss and cross-entropy loss) and various numbers of in-context examples (0 to 8). The embedding dimension (dE) is set to 100. The results are averaged over 10 repetitions.", "section": "2.1 In-context learning on single-relationship word analogy tasks"}, {"figure_path": "x9eFgahVBI/tables/tables_22_2.jpg", "caption": "Table 9: ICL performance in the corrupted scenario, evaluated with both squared and cross-entropy loss functions across different numbers of examples (0 to 8) with dE = 100, averaged over 10 repetitions.", "description": "This table presents the results of in-context learning (ICL) experiments using a continuous bag-of-words (CBOW) model on a single-relationship word analogy task.  The experiment is performed with a corrupted dataset where training sentences have a 25% chance of a word pair being replaced with a word and random token. The table shows average accuracy across 10 repetitions for both squared loss and cross-entropy loss functions. The 'accuracy' values represent the proportion of correct predictions for different numbers of in-context examples (0 to 8) and varying probabilities of having 0, 1, or 2 word pairs in a training sentence.", "section": "2.1 In-context learning on single-relationship word analogy tasks"}]