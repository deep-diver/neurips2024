[{"type": "text", "text": "The Implicit Bias of Gradient Descent toward Collaboration between Layers: A Dynamic Analysis of Multilayer Perceptions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zheng Wang. Geyong Min Department of Computer Science University of Exeter {zw360;G.Min}@exeter.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Wenjie Ruan\\* School of Computer Science USTC rwjie@ustc.edu.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The implicit bias of gradient descent has long been considered the primary mechanism explaining the superior generalization of over-parameterized neural networks without overfitting, even when the training error is zero. However, the implicit bias toward adversarial robustness has rarely been considered in the research community, although it is crucial for the trustworthiness of machine learning models. To fill this gap, in this paper, we explore whether layers in neural networks collaborate to strengthen adversarial robustness during gradient descent. By quantifying this collaboration between layers using our proposed concept, co-correlation, we demonstrate a monotonically increasing trend in co-correlation, which implies a decreasing trend in adversarial robustness during gradient descent. Additionally, we observe different behaviours between narrow and wide neural networks during gradient descent. We conducted extensive experiments that verified our proposed theorems. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "As Artificial Intelligence (AI) has been widely applied in many industrial sectors, understanding the theoretical properties behind modern machine learning models is important, especially for neural networks due to their black-box nature. One such property is implicit bias, stemming from the phenomenon where over-parameterized neural networks, trained in a gradient descent manner, often exhibit great generalization without over-fitting. This implicit bias of gradient descent is often explained as steering neural networks towards solutions characterized by max-margin [3, 23, 12]. ", "page_idx": 0}, {"type": "text", "text": "Another intriguing phenomenon is the existence of adversarial examples \u2014\u2014 imperceptible perturbations of inputs that alter classification results. Apart from existing work on attacks \u2014\u2014- algorithms for generating adversarial examples [5, 39, 37], defences against attacks, e.g., adversarial training [25, 36] and distillation [28], and verification [40, 34] to identify safe regions guaranteeing the absence of adversarial examples, recently some works are aiming at a theoretical understanding behind adversarial robustness. However, a principled way to comprehend the core contributors to the vulnerability of neural networks, especially a theoretical understanding of their relation to generalization capabilities, remains fragmented. This fragmentation is largely due to the intricate nature of neural networks, where robustness is interconnected with many factors spanning across input data distribution [33, 14], sampling complexity [1, 27], optimization techniques [25], weight initialization strategies [41], and model capacity and architectures [32, 2, 18, 35]. Not to mention that only very few works can address both generalization and adversarial robustness in a uniform framework. One such research by Frei et al. [13] investigates the implicit bias concerning both generalization and adversarial robustness, asserting that while implicit bias leads to solutions with improved generalization, it results in weaker adversarial robustness. However, this work ignores the architectural factor of neural networks and is hard to generalize to neural networks with more than two layers. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Inspired by this work and to investigate whether neural network layers collaborate against adversarial examples during training, this paper first adopts the novel concept of Dirichlet energy\u2014originating from Partial Differential Equations (PDEs) to assess the variability of a function [11]\u2014-to evaluate the adversarial robustness of neural networks. We then theoretically demonstrate that Dirichlet energy serves as an effective measure of adversarial risk. By decomposing the Dirichlet energy across the entire neural network into its constituent layers, we can quantify the interactions between adjacent layers concerning adversarial robustness. We term this interaction collaboration correlation (co-correlation) and find that this metric reflects 'alignments' in feature selection between neighbouring layers. Furthermore, we conduct a dynamic analysis of co-correlation in two-layer MLPs, demonstrating with high probability a monotonic increase under gradient descent, which indicates diminishing adversarial robustness. Additionally, our experiments show that two-layer MLPs with small widths tend to enhance their performance through strengthened co-correlation, a pattern not observed in wide two-layer MLPs. Our key contributions in this paper can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": ". To the best of our knowledge, this work is the first to study the implicit bias of interaction between layers. We have quantified the interactions between adjacent layers and theoretically demonstrated that co-correlation between layers strengthens during gradient descent in neural networks under mild assumptions, suggesting that it not only fails to collaborate against adversarial perturbations but may even hinder resistance to them during gradient descent. ", "page_idx": 1}, {"type": "text", "text": "2. We demonstrate how neural networks with a large width differ in behaviour from the neural network of a small width, showing that MLPs with larger widths exhibit more resistance to increased co-correlation and, therefore, are more adversarial robust, which is complementary for the work by Dohmatob and Bietti [8].   \n3. Extensive experiments have been conducted to validate our proposed framework. By controlling the weight initialization, a perspective also suggested by Zhu et al. [41], we challenge the argument, as proposed by Huang et al. [18], that a wide neural network does not necessarily lead to better adversarial robustness, through the lens of cross-layer collaboration. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "2.1  Implicit Bias of Gradient Descent ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "The mystery of over-parameterized neural network trained with gradient descent manner hardly over-fitting has long been studied. Chizat and Bach [3] study the two-layer neural network with infinite width and homogeneous activations, showing that gradient flow can be characterized as a max-margin classifier on exponentially tailed losses. Lyu et al. [24], Sarussi et al. [29] study the two-layer Leaky ReLU neural network on linearly separable data and claim that networks converge to a max-margin linear predictor by gradient descent manner. Frei et al. [12] confirms those claims on high-dimensional nearly orthogonal data. ", "page_idx": 1}, {"type": "text", "text": "Lyu and Li [23], Ji and Telgarsky [19] claims that the homogeneous neural networks with exponentially-tailed classification losses converge to a KKT point of a maximum-margin problem. Kunin et al. [21] extend these results to a more boarder family of quasi-homogeneous neural networks. A more recent research [13] considers both generalization and robustness for two-layer ReLU neural networks, arguing that gradient descent is biased towards solutions that generalise well but are more vulnerable against adversarial examples, even the neural network is highly over-parameterized. ", "page_idx": 1}, {"type": "text", "text": "2.2  Theoretical Investigation of Adversarial Robustness ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Since the phenomenon of adversarial examples has been discovered [15], various works have been proposed to understand the theoretical fundamentals behind it, especially for neural networks. Some researchers argue that the source of adversarial vulnerability comes from the input data [33, 8, 31, 26, 14, 7, 30, 1, 27]. The more recent researches investigate the fragility of neural networks from an architectural perspective. Simon-Gabriel et al. [32] study the vulnerability of feed-forward neural networksmeasured by $L_{p}$ norm of the loss function w.r.t. input data, suggesting that the vulnerability increases with input dimension independent of model structures. Daniely and Shacham [6] examined the ReLU neural network characterized by decreasing dimensions at each layer. They asserted that the manifestation of adversarial robustness is intrinsically tied to the network's architecture, which contrasts with the propositions put forth by Simon-Gabriel et al. [32]. Bubeck et al. [2] expanded the findings of Daniely and Shacham's work on two-layer neural networks from an \"under-complete case\" scenario to an \"over-complete\" one where the number of neurons surpasses the input dimension. They further broadened the conclusions drawn by Daniely and Shacham [6] and Bubeck et al. [2] to encompass Deep ReLU networks, hinting at a crucial role played by bottleneck layers in these networks. Zhu et al. [41], instead of merely considering random weights as the standard configuration, conducted a comprehensive analysis of the effects of weight initialization on adversarial robustness. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Unlike previous studies that focus solely on the overall assessment of neural networks while overlooking layer interactions, our research examines the synergistic involvement between layers within neural networks, taking into account both weight initialization and optimization. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1  General Setting ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We follow the binary classification setting where the input data is $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ , with the label ${\\boldsymbol{\\mathcal{V}}}\\subseteq\\{0,1\\}$ Given data set $D=\\{(x_{i},y_{i})\\}_{i=1}^{n}$ drawn from an unknown probability measure $P$ on $\\mathcal X\\times\\mathcal X$ and the neural network $f:\\mathcal{X}\\times\\Theta\\rightarrow\\mathbb{R}$ where $\\Theta$ denotes the set of parameters, our objective is to optimize $f$ by updating the weights with gradient descent method such that it can predict the label accurately. The prediction result is shown in Equation (1). ", "page_idx": 2}, {"type": "equation", "text": "$$\ny_{p r e d}=\\left\\{1,s i g(f_{W}(\\pmb x))>0.5\\right.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $s i g$ is the sigmoid function, i.e., $s i g(x)=1/(1+e^{-x})$ .We use Binary Cross-Entropy $(B C E)$ loss in Equation (2) as our loss function. For simplicity, we denote $u_{i}=f(\\pmb{x}_{i},W),i\\in[\\bar{n}]$ as the output of the neural network for input $\\pmb{x}_{i}$ , where $[\\bar{n}]=\\{k\\in\\mathbb{N}^{+}|k\\le n\\}$ ", "page_idx": 2}, {"type": "equation", "text": "$$\nL(f,y)=\\frac{1}{n}\\sum_{i=1}^{n}L(s i g(u_{i}),y_{i})=-\\frac{1}{n}\\sum_{i=1}^{n}\\bigg[y_{i}\\log(s i g(u_{i}))+(1-y_{i})\\log(1-s i g(u_{i}))\\bigg].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "3.2 Neural Networks and Adversarial Risk ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Our exploration starts from a basic linear model, then to Multilayer Perceptrons $(M L P)$ Weprovide the proof for both linear and 2-layer MLPs, which can be extended to MLPs with more layers. They aredefined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{c}{f_{l i n e a r}({\\pmb x},W)={\\pmb a}^{T}(W{\\pmb x})}\\\\ {f_{m l p}({\\pmb x},W)={\\pmb a}^{T}(\\sigma(W{\\pmb x})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\pmb{x}\\in\\mathcal{X}$ is the input data, $W\\in\\mathbb{R}^{m\\times d}$ denotes the linear transformation, $m$ is the width of the networks. $\\sigma$ denotes the element-wise activation functions. ", "page_idx": 2}, {"type": "text", "text": "We follow the initialization setting in [9], where $\\textbf{\\em a}$ is randomly initialized and fixed from a binary selection of $\\{-{\\frac{1}{\\sqrt{m}}},{\\frac{1}{\\sqrt{m}}}\\}^{m}$ .Additionally, we introduce a slightly different setting for the weights $W$ which are randomly initialized following the normal distribution $\\textstyle N(0,{\\frac{1}{m^{1+2q}}})$ with $q>0$ instead of $N(0,{\\frac{1}{m}})$ . However, in our experiment, different settings of $q$ are considered, including the scenario that $q\\leq0$ ", "page_idx": 2}, {"type": "text", "text": "Generalization ability is one of the most important concepts for machine learning models. Classifiers with better generalization power indicate lower natural risk for unseen data. Given data points $(\\pmb{x},y)\\sim P$ and classifier $f$ , the natural risk is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\nR(f)=\\underset{(\\pmb{x},y)\\sim P}{\\mathbb{E}}[L(f(\\pmb{x}),y))].\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "When it comes to O-1 loss, the natural risk becomes the probability of misclassification for unseen data points. ", "page_idx": 2}, {"type": "text", "text": "Similar to natural risk, the adversarial risk is defined as the probability of misclassification under adversarial perturbations as is shown in Definition 3.1. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.1 (Adversarial Risk). Given data points $(\\pmb{x},y)\\sim P$ , and a perturbation $\\varepsilon$ within a norm-ball, i.e., ", "page_idx": 3}, {"type": "equation", "text": "$$\nB_{r}=\\{\\|\\boldsymbol{\\epsilon}\\|_{2}\\leq r\\},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $r>0$ indicates the $L_{2}$ -norm budget for perturbations. The adversarial risk for neural network $f$ on loss function $L$ is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\nR^{r o b}(f,r)=\\underset{(\\pmb{x},y)\\sim P}{\\mathbb{E}}\\left[\\underset{\\pmb{\\varepsilon}\\in B_{r}}{\\operatorname*{sup}}L(f(\\pmb{x}+\\pmb{\\varepsilon}),y))\\right]\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Since adversarial perturbations are almost invisible to human eyes, we expect $r$ to be quite small. ", "page_idx": 3}, {"type": "text", "text": "3.3  Dirichlet Energy ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "The concept of Dirichlet energy, originating from Partial Differential Equations $(P D E s)$ ,servesas a tool to assess the variability of a function [11]. However, as argued by Dohmatob and Bietti [8], it serves as a more effective measure of adversarial robustness than the Lipschitz constant. We extend this concept to mappings to make it more suitable for multi-dimensional problems, which is formally defined in Definition 3.2. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.2 (Dirichlet Energy for Mappings). Let convex set $\\mathcal{Z}_{1}\\subseteq\\mathbb{R}^{m_{1}}$ and $\\mathcal{Z}_{2}\\subseteq\\mathbb{R}^{m_{2}}$ . Given a differentiable mapping $\\phi:{\\mathcal{Z}}_{1}\\to{\\mathcal{Z}}_{2}$ , the Dirichlet Energy w.r.t. $x\\sim P_{x}$ is defined as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathfrak{S}(\\phi)\\triangleq\\sqrt{\\|J_{\\phi}(\\pmb{x})\\|_{L^{2}(P_{\\alpha})}^{2}}=\\sqrt{\\mathbb{E}_{\\pmb{x}\\sim P_{\\alpha}}\\left[\\|J_{\\phi}(\\pmb{x})\\|_{2}^{2}\\right]},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\Vert\\cdot\\Vert_{2}$ refers to the operator norm and $J_{\\phi}(x)$ denotes the Jacobian matrix of $\\phi$ w.r.t. its input $\\textbf{\\em x}$ ", "page_idx": 3}, {"type": "text", "text": "To be clear, we use $\\|\\cdot\\|_{2}$ to denote the $L_{2}$ -norm for vectors and operator norm for matrices throughout our analysis. This concept can be extended to layers with ReLU activation by extending the derivative $R e L\\dot{U}^{\\prime}(x)=\\mathbf{1}_{\\{x\\geq0\\}}$ where ${\\mathbf{1}}_{\\{x\\geq0\\}}$ is the indicator function. With the concepts defined, we now establish the relationship between adversarial risk and Dirichlet energy. ", "page_idx": 3}, {"type": "text", "text": "4  Measure Adversarial Risk by Dirichlet Energy ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we establish the relationship between the adversarial risks and Dirichlet energy, showing that Dirichlet Energy is a proper measurement for adversarial risk. Dohmatob and Bietti [8] only compares the Dirichlet energy with the Lipschitz constant. We, instead, illustrate that Dirichlet energy is a proper representation of the gap between natural risk and adversarial risk. ", "page_idx": 3}, {"type": "text", "text": "Theorem 4.1. Given data points $(\\pmb{x},y)\\sim P$ and $\\pmb{x}\\sim P_{x}$ the relationship between adversarial risk and Dirichlet energy for classifier $f$ with differentiable loss function $L$ is shownas ", "page_idx": 3}, {"type": "equation", "text": "$$\nR^{r o b}(f,r)\\lesssim R(f)+r\\mathfrak{S}(L(f)),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $r\\,>\\,0$ is the largest perturbation budget and $\\mathfrak{S}(L(f))\\,=\\,\\sqrt{\\mathbb{E}_{{\\pmb{x}}\\sim P_{\\mathbf{x}}}\\left[\\Vert\\nabla_{f}L^{T}\\cdot J_{{\\pmb{f}}}({\\pmb{x}})\\Vert_{2}^{2}\\right]}$ indicating the Dirichlet energy of the classifier on loss $L$ ", "page_idx": 3}, {"type": "text", "text": "As is shown, the Dirichlet energy is a proper representation of the gap between generalization and adversarial risk which indicates the adversarial robustness. The proof relies on the linear approximationof $L(f)$ . The detailed proof is shown in Appendix A. ", "page_idx": 3}, {"type": "text", "text": "We also empirically show that the Dirichlet energy for classifier $f$ i.e., ${\\mathfrak{S}}(f)$ instead of $\\mathfrak{S}(L(f))$ is the part that infuences the adversarial robustness, as is shown in Figure 1 where we compare the level of Dirichlet energy for $f$ with the robust accuracy of the classifier attacked by Auto-attack [5]. ", "page_idx": 3}, {"type": "text", "text": "Since the Dirichlet energy defined in Equation (7) can be used to measure the variability of mappings, it follows that this metric could be employed to evaluate the adversarial robustness of individual layers or modules within neural networks. Consequently, this allows for an assessment of whether there is collaboration between these components in terms of adversarial robustness. ", "page_idx": 3}, {"type": "text", "text": "4.1 Measure Correlation between Layers ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "To evaluate the collective impact of neighbouring layers on the adversarial robustness, we regard the neural network as compounded separate mappings, i.e., $\\phi\\circ\\varphi$ . By calculating the Dirichlet energy for each mapping $(\\mathfrak{S}(\\phi)$ and ${\\mathfrak{S}}(\\varphi))$ and comparing it with the overall Dirichlet energy for the whole classifier $(\\mathfrak{S}(\\phi\\circ\\varphi))$ , we can quantify the collaboration between these two mappings, and we term this quantification co-correlation which is defined in 4.2. ", "page_idx": 4}, {"type": "text", "text": "Definition 4.2 (Co-correlation). Let $\\varphi:{\\mathcal{Z}}_{1}\\rightarrow{\\mathcal{Z}}_{2}$ and $\\phi:{\\mathcal{Z}}_{2}\\to{\\mathcal{Z}}_{3}$ be two successive mappings, where both ${\\mathcal{Z}}_{1}$ and ${\\mathcal{Z}}_{2}$ are convex. Given input $x\\sim P_{x}$ , the collaboration correlation (co-correlation) is defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\varrho_{\\phi,\\varphi}\\triangleq\\frac{\\left(\\mathbb{E}_{\\pmb{x}\\sim P_{\\pmb{x}}}\\|J_{\\phi\\circ\\varphi}(\\pmb{x})\\|_{2}^{2}\\right)^{\\frac{1}{2}}}{\\left(\\mathbb{E}_{\\pmb{x}\\sim P_{\\pmb{x}}}\\big[\\|J_{\\phi}(\\varphi)\\|_{2}^{2}\\cdot\\|J_{\\varphi}(\\pmb{x})\\|_{2}^{2}\\big]\\right)^{\\frac{1}{2}}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "To avoid any confusion, we use $\\varphi$ interchangeably to denote both the function $\\varphi:{\\mathcal{Z}}_{1}\\rightarrow{\\mathcal{Z}}_{2}$ and the output of the function $\\varphi=\\varphi({\\pmb x})$ for a given input $\\textbf{\\em x}$ . Consequently, $\\varphi$ in $J_{\\phi}(\\varphi)$ represents the outputs, while in $J_{\\varphi}(x)$ , it represents the mapping. Since for each $\\pmb{x}\\in P_{x}$ , we have ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|J_{\\phi\\circ\\varphi}(\\pmb{x})\\|_{2}=\\|J_{\\phi}(\\varphi)\\cdot J_{\\varphi}(\\pmb{x})\\|_{2}\\leq\\|J_{\\phi}(\\varphi)\\|_{2}\\cdot\\|J_{\\varphi}(\\pmb{x})\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Weexpect $0\\leq\\varrho_{\\phi,\\varphi}\\leq1$ The concept of c-corelation canbe xplainedby the feature alignmentf layers in neural networks. ", "page_idx": 4}, {"type": "text", "text": "Interpretation of co-correlation. Intuitively, co-correlation can be viewed as feature 'alignment' between layers. We illustrate this intuition with a 2-layer neural network with linear activation functions,i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\nf({\\pmb x})=\\phi(\\varphi({\\pmb x}))=W_{2}W_{1}{\\pmb x},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $W_{1}$ and $W_{2}$ are weight matrices, and ${\\pmb\\varphi}({\\pmb x})=W_{1}{\\pmb x}$ represents the feature selection in layer-1, while $\\phi(\\varphi)=W_{2}\\varphi$ represents it in layer-2. By Definition 4.2, the co-correlation between $\\phi$ and $\\varphi$ is ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\varrho_{\\phi,\\varphi}=\\frac{\\|W_{2}W_{1}\\|_{2}}{\\|W_{2}\\|_{2}\\|W_{1}\\|_{2}}.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\|\\cdot\\|_{2}$ denotes the operator norm. Let $S_{\\varphi}\\;=\\;\\arg\\operatorname*{max}_{\\|\\pmb{x}\\|_{2}=1}\\|W_{1}\\pmb{x}\\|_{2}$ , representing the set of input features that maximize the $L_{2}$ -norm of their corresponding outputs. Similarly, let $\\begin{array}{r}{S_{\\phi}=\\arg\\operatorname*{max}_{\\|z\\|_{2}=1}\\|W_{2}z\\|_{2}}\\end{array}$ Assume $\\varrho_{\\phi,\\varphi}=1$ , there exists $\\pmb{x}\\in S_{\\varphi}$ such that $\\begin{array}{r l r}{\\lefteqn{\\frac{\\varphi(\\pmb{x})}{\\|\\varphi(\\pmb{x})\\|_{2}}\\in S_{\\phi}}}\\end{array}$ This implies that the maximal output in terms of the $L_{2}$ -norm at the first layer can lead the output at the second layer to reach its maximum. In other words, in terms of maximizing outputs, layer 1 aligns with layer 2. We can thus regard co-correlation as the degree of alignment in feature selection between adjacent layers within the context of output maximization. In the non-linear case, the weight matrices are replaced by the Jacobians of the respective layers, which can be equivalently viewed as weight matrices that vary based on their inputs. ", "page_idx": 4}, {"type": "text", "text": "Definition 4.3 (Other Related Statistics). Given the same assumptions in Definition 4.2, we define the linear correlation between $\\|J_{\\phi}(\\varphi)\\|_{2}$ and $\\|J_{\\varphi}(\\pmb{x})\\|_{2}$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\rho_{\\phi,\\varphi}\\triangleq\\frac{\\mathbb{E}_{{\\mathbf{x}}\\sim{P}_{\\mathbf{x}}}\\big[\\|J_{\\phi}(\\varphi)\\|_{2}\\cdot\\|J_{\\varphi}({\\boldsymbol{x}})\\|_{2}\\big]}{\\left(\\mathbb{E}_{\\varphi\\sim\\varphi({\\boldsymbol{x}})}\\|J_{\\phi}(\\varphi)\\|_{2}^{2}\\right)^{\\frac{1}{2}}\\left(\\mathbb{E}_{{\\mathbf{x}}\\sim{P}_{\\mathbf{x}}}\\|J_{\\varphi}({\\boldsymbol{x}})\\|_{2}^{2}\\right)^{\\frac{1}{2}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\varphi\\,\\sim\\,\\varphi({\\pmb x})$ shows that $\\varphi$ follows the distribution of $\\varphi(\\mathbf{x}),\\mathbf{x}\\;\\sim\\;P_{x}$ . It is obvious that $0\\leq\\rho_{\\phi,\\varphi}\\leq1$ and when $\\rho_{\\phi,\\varphi}=1$ \uff0c $\\|J_{\\phi}(\\varphi)\\|_{2}$ and $\\|J_{\\varphi}({\\pmb x})\\|_{2}$ are linear correlated. ", "page_idx": 4}, {"type": "text", "text": "The mean and variance for $\\|J_{\\phi}(\\varphi)\\|_{2}\\cdot\\|J_{\\varphi}(\\mathbf{x})\\|_{2}$ are defined as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mu_{\\phi,\\varphi}\\triangleq\\mathbb{E}_{\\pmb{x}\\sim P_{\\mathbf{x}}}\\big[\\|J_{\\phi}(\\varphi)\\|_{2}\\cdot\\|J_{\\varphi}(\\pmb{x})\\|_{2}\\big],}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "and ", "page_idx": 4}, {"type": "equation", "text": "$$\nv a r_{\\phi,\\varphi}\\triangleq V a r_{\\mathbf{x}\\sim P_{\\mathbf{x}}}\\big[\\|J_{\\phi}(\\varphi)\\|_{2}\\cdot\\|J_{\\varphi}(\\mathbf{x})\\|_{2}\\big].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "image", "img_path": "jV6z08u7y0/tmp/93e2507840a35ce7637cba694ccac978644ff034f2b4492de731971797778eaf.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 1: For all MLPs considered, lower value of Dirichlet Energy (Figure 1b) corresponds to larger robust accuracy on test-set attacked by. $L_{2}$ -norm Auto-attack with $\\epsilon=0.5$ .The dynamics of the co-correlation $\\varrho$ for linear and MLPs is shown in Figure 1c and 1d. The architectures of neural networks are defined in Equation (3b). The parameters to control the weight initialization in Assumption 5.1 is set to $q=0.25$ ", "page_idx": 5}, {"type": "text", "text": "Remark 4.4 (Linear Correlation for $L_{2}$ -norm of the Jacobian). We have $\\rho_{\\phi,\\varphi}=1$ iff there exist $t\\in\\mathbb R$ such that ", "page_idx": 5}, {"type": "equation", "text": "$$\nP(t\\|J_{\\phi}(\\varphi)\\|_{2}=\\|J_{\\varphi}(\\pmb{x})\\|_{2})=1,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "implying that $\\rho_{\\phi,\\varphi}$ certainly can be used to assess the linear correlations. It reduces to Pearson correlation coefficient [4] when the mean of both random variables equals zero. ", "page_idx": 5}, {"type": "text", "text": "Now we give the theorem that binds them together. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4.5 (Robustness Decomposition). Given the same assumption in Definition 4.2, the measurementforoveralladversarialrobustnesscanbedecomposedas ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{S}(\\phi\\circ\\varphi)=\\left(\\mathbb{E}_{\\pmb{x}\\sim P}\\big[\\|J_{\\phi\\circ\\varphi}(\\pmb{x})\\|_{2}^{2}\\big]\\right)^{\\frac{1}{2}}}\\\\ &{\\qquad\\qquad=\\varrho_{\\phi,\\varphi}\\Big(1+\\frac{v a r_{\\phi,\\varphi}}{\\mu_{\\phi,\\varphi}^{2}}\\Big)^{\\frac{1}{2}}\\rho_{\\phi,\\varphi}\\mathfrak{S}(\\phi)\\mathfrak{S}(\\varphi)}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The proof is straightforward from the definition. Based on this theorem, we have conducted experiments with various linear models and 2-layer MLPs. These experiments demonstrate that, apart from the co-correlation, all other statistics are negligible, as shown in Figure 5 in the Appendix D. Consequently, our analysis primarily focuses on the co-correlation $\\varrho$ ", "page_idx": 5}, {"type": "text", "text": "5   On Dynamics of Co-Correlation ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "5.1  Dynamics for Linear Model ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Before delving into our analysis, we state our assumptions explicitly. ", "page_idx": 5}, {"type": "text", "text": "Assumption 5.1. We assume that each element $w_{i,j}$ in the weight matrix $W(0)\\,\\in\\,\\mathbb{R}^{m\\times d}$ at initilization follows the Gaussian distribution $\\textstyle N(0,{\\frac{1}{m^{1+2q}}})$ , with $q>0$ Additionally, each element $a_{r},r\\in[m]$ .n $\\textbf{\\em a}$ is randomly elected from the set $\\{-{\\frac{1}{\\sqrt{m}}},{\\frac{1}{\\sqrt{m}}}\\}$ and fxed during raining. ", "page_idx": 5}, {"type": "text", "text": "Assumption 5.2. We assume that for each $(\\pmb{x}_{i},y_{i})\\in D,i\\in[n]$ \uff0c $\\pmb{x}_{i}$ is $L_{2}$ norm bounded such that $\\|\\pmb{x}_{i}\\|_{2}\\bar{=}1$ for all $i\\in[n]$ ", "page_idx": 5}, {"type": "text", "text": "Since we only assume bounded inputs and a specific weight initialization method, compared to existing works [23, 19, 21, 12], our approach can be easily extended to MLPs with more than two layers. ", "page_idx": 5}, {"type": "text", "text": "Now let us focus on the co-correlation defined in Equation (9) and show the dynamics of $\\varrho_{\\phi,\\varphi}$ for each step of gradient descent. We start from the linear model described in Equation (3a). Given the binary classification problem and the linear model described. Our first theorem demonstrates that co-correlation $\\varrho_{\\phi,\\varphi}$ gradually accumulates throughout gradient descent optimization. Despite the simplicity of the linear model, it effectively exhibits most of the core properties under consideration. ", "page_idx": 5}, {"type": "text", "text": "Since the weights are updated by the gradient descent, the update of the weights at step $t\\in\\mathbb{N}$ is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Delta{\\pmb w}_{r}(t)=\\eta a_{r}\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_{i}-s i g(u_{i}(t))\\big){\\pmb x}_{i},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\eta$ denotes the learning rate. Therefore, the dynamics of the weights can be expressed as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\dot{W}(t)=\\pmb{a}\\otimes\\pmb{\\widetilde{x}}^{T}(t),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\otimes$ denotes the Kronecker product and $\\widetilde{\\pmb{x}}(t)$ is the error weighted input such that ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{x}}(t)=\\frac{1}{n}\\sum_{i=1}^{n}\\Big[y_{i}-s i g\\big(u_{i}(t)\\big)\\Big]\\pmb{x}_{i}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Given the weight updates, we demonstrate that the dynamics of the co-correlation for the linear model, denoted as $\\dot{\\varrho}_{a,W}(t)$ , exhibit an increasing trend, particularly during the initial steps of training when most predictions are still essentially random. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5.3 (Dynamics of the Co-correlation for Linear Model). Given the linear model defined in Equation (3a) and training dataset $D=\\{(\\pmb{x}_{i},y_{i})\\}_{i=1}^{n}$ Assume that assumptions 5.1 and 5.2 hold for $W$ and $\\textbf{\\em a}$ The gradient descent applied to the weights results in the dynamics of the co-correlation being expressed as: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\dot{\\varrho}_{\\pmb{a},W}(t)=\\eta C(t)\\varrho_{\\pmb{a},W},}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "and with high probability, ", "page_idx": 6}, {"type": "equation", "text": "$$\nC(t)\\geq\\frac{\\sum_{\\tau=1}^{t}\\widetilde{\\pmb{x}}(\\tau)^{T}\\widetilde{\\pmb{x}}(t)}{\\|W(t)\\|_{2}^{2}}\\cdot\\Big(1-\\big(\\pmb{v}(t)^{T}\\pmb{a}\\big)^{2}\\Big)+\\mathcal{O}\\Big(\\frac{1}{m^{q}}\\Big)\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where the $v(t)$ is the dominate eigenvector for $W(t)W(t)^{T}$ ", "page_idx": 6}, {"type": "text", "text": "When m is suffciently large, and during the initial steps of the optimization process, $\\widetilde{\\mathbfit{x}}(\\tau),\\tau\\in[t]$ are quite similar to each other in terms of cosine similarity,implying an acute angle to each other, whichleadsto $\\begin{array}{r}{\\sum_{\\tau=1}^{t}\\widetilde{\\pmb{x}}(\\tau)^{T}\\widetilde{\\pmb{x}}(t)\\geq0}\\end{array}$ As a result, we canconclude that $C(t)\\geq0$ ", "page_idx": 6}, {"type": "text", "text": "The detailed proof can be found in the Appendix B. This assertion is also corroborated by the results of our experiments as shown in Figure 1c. Even though Theorem 5.3 is based on a linear model, the essential properties are universally applicable and can be summarized as follows: ", "page_idx": 6}, {"type": "text", "text": "Property 1. The co-correlation $\\varrho_{\\pmb{a},W}$ develops during the initial stages of training and becomes saturated as training progresses to its later stages. ", "page_idx": 6}, {"type": "text", "text": "Property 2. The speed of the accumulation of co-correlation $\\varrho_{\\pmb{a},W}$ is inversely related to the operator norm of weights $\\|W(t)\\|_{2}$ ", "page_idx": 6}, {"type": "text", "text": "Under the same weight initialization conditions specified in Assumption 5.1, an increase in network width leads to a decrease in the $L_{2}$ -norm of the weight, consequently causing a substantial rise in co-correlation. ", "page_idx": 6}, {"type": "text", "text": "5.2 Dynamics for MLP Model ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "For the non-linear case, we make certain assumptions regarding activation functions. ", "page_idx": 6}, {"type": "text", "text": "Assumption 5.4. The derivative of the activation function $\\sigma^{\\prime}(x)$ in non-linear neural networks is boundedby $M$ . In other words, we have $|\\sigma^{\\prime}(x)|\\leq M$ ", "page_idx": 6}, {"type": "text", "text": "With Assumption 5.4, Theorem 5.3 can be extended to MLPs, and the two properties still hold. Different from the linear model, the update of weights for non-linear MLP defined in (3b) is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Delta{\\pmb w}_{r}=\\eta a_{r}\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_{i}-s i g(u_{i})\\big)\\sigma^{\\prime}\\big({\\pmb w}_{r}^{T}{\\pmb x}_{i}\\big){\\pmb x}_{i},\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $\\sigma^{\\prime}(w_{r}^{T}x_{i})$ is the derivative of activation function w.r.t. its input. Hence, ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\Delta W=\\eta\\left(\\!\\!\\begin{array}{c}{{a_{1}\\widetilde{\\mathbf{x}}_{1}^{T}}}\\\\ {{\\vdots}}\\\\ {{a_{m}\\widetilde{\\mathbf{x}}_{m}^{T}}}\\end{array}\\!\\!\\right),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "image", "img_path": "jV6z08u7y0/tmp/9e2a86c9c2a30c7f6f32a3e3760b36cdb4da571c2b3bc3e3178d9b7045ebdd60.jpg", "img_caption": ["Figure 2: The dynamics of co-correlation for ResNet50 and WRN50 under different way of partition. The way of partition is illustrated in Figure 2a. A1-A2 and B1-B2 represent the separations that distinguish the head and tail separately. "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "where for each $r\\in[m]$ \uff0c", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{x}}_{r}=\\frac{1}{n}\\sum_{i=1}^{n}\\sigma^{\\prime}(\\pmb{w}_{r}^{T}\\pmb{x}_{i})\\big(y_{i}-s i g(u_{i})\\big)\\pmb{x}_{i}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "As is shown in Equation (20), $\\textbf{\\em a}$ is not the dominant eigenvector for $\\Delta W\\Delta W^{T}$ due to the difference of $\\widetilde{\\mathbf{x}}_{r},r\\in[m]$ from $\\widetilde{\\mathbf{\\Omega}}$ . Thus to average out the difference, we define the weighted sum of inputs for the non-linear model as ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{x}}_{*}(t)\\triangleq\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i}(t,\\pmb{x})\\big(y_{i}-s i g(u_{i}(t))\\big)\\pmb{x}_{i},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $(x_{i},y_{i})\\in\\mathcal{D}$ are realized r.v., and $\\pmb{x}\\sim P_{x}$ . Given $\\begin{array}{r}{w_{i,j}\\overset{i.i.d.}{\\sim}N(0,\\frac{1}{m^{1+2q}})}\\end{array}$ for each element in $W(0)$ , we have $\\begin{array}{r}{\\pmb{w}(0)\\sim N(0,\\frac{1}{m^{1+2q}}\\mathbf{I}_{d})}\\end{array}$ . Furthermore, given that $W(t)$ is calculated from $W(0)$ ,it is evident that each row in $W({\\ddot{t}})$ , denoted as $w(t)$ , constitutes a random variable. As a result, both $\\sigma^{\\prime}(\\pmb{w}(t)^{T}\\pmb{x})$ and $\\sigma^{\\prime}(\\pmb{w}(t)^{T}\\pmb{x}_{i})$ are bounded random variables that are contingent upon $W(0)$ . Hence, we define $\\alpha_{i}(t,{\\pmb x})$ as ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\alpha_{i}(t,\\pmb{x})\\triangleq\\mathbb{E}_{W(0)}\\Big[\\sigma^{\\prime}(\\pmb{w}(t)^{T}\\pmb{x})\\sigma^{\\prime}(\\pmb{w}(t)^{T}\\pmb{x}_{i})\\Big].\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Since, $x\\sim P_{x}$ $\\alpha_{i}(t,{\\pmb x})$ is stillr.v. contingent to $\\textbf{\\em x}$ and so does the $\\widetilde{\\mathbf{x}}_{\\ast}(t)$ . Now we show the dynamics of co-correlation for two-layer MLP defined in Equation (3b). ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.5. (Dynamics of the $C o$ -correlation for MLP) Given the MLP defined in Equation (3) with training dataset $D=\\{(\\pmb{x}_{i},y_{i})\\}_{i=1}^{n}$ $x\\in\\mathcal{X}$ such that $x\\sim P_{x}$ . Assume that Assumption 5.1 and 5.2 hold for $W$ and $\\textbf{\\em a}$ ,and Assumption 5.4 holds for the activation function.we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\dot{\\varrho}_{a,\\sigma\\circ W}(t)=\\eta C(t)\\varrho_{a,\\sigma\\circ W}(t).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "With high probability, ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{C(t)\\geq\\frac{\\sum_{\\tau=1}^{t}\\big(1-a^{T}v(\\tau)a^{T}v(t)\\big)\\mathbb{E}_{x\\sim P_{\\alpha}}\\left[\\widetilde{x}_{*}^{T}(\\tau)\\widetilde{x}_{*}(t)\\right]}{\\mathbb{E}_{x\\sim P_{\\alpha}}\\left\\|D(t)W(t)\\right\\|_{2}^{2}}+\\operatorname*{max}\\bigg\\{\\mathcal{O}\\bigg(\\frac{1}{\\sqrt{m}}\\bigg),\\mathcal{O}\\bigg(\\frac{1}{m^{q}}\\bigg)\\bigg\\},}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where ", "page_idx": 7}, {"type": "equation", "text": "$$\nD(t)=d i a g(\\sigma^{\\prime}(\\pmb{w}_{1}(t)^{T}\\pmb{x}),\\cdot\\cdot\\cdot\\mathbf{\\sigma},\\sigma^{\\prime}(\\pmb{w}_{m}(t)^{T}\\pmb{x})),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "and ${\\pmb v}(t)$ denotes the dominant eigenvector for $W(t)W(t)^{T}$ with $\\widetilde{\\pmb{x}}_{*}^{T}$ is defined in Equation (21). Similartotheheorem5.3,whenmissuffcientlylarge,and dringtheinitial stepsof theoptimiatin where the error-weighted inputs $\\widetilde{\\pmb{x}}_{\\ast}^{T}(\\tau),\\bar{\\tau}\\in[t]$ do not significantly fuctuate, we have that $C(t)\\geq0$ ", "page_idx": 7}, {"type": "text", "text": "The detailed proof is in Appendix C. In Theorem 5.5, $\\widetilde{\\mathbf{x}}_{\\ast}$ serves a similar purpose as $\\widetilde{\\mathbf{\\Omega}}$ for the linear model. In addition, it considers the influence of the activation function. Property 1 still holds for the MLPs, and Property 2 extends to Ez\\~ PaIID(t)W(t)12 =IIJgow (\u03b1) (Pg) ", "page_idx": 7}, {"type": "image", "img_path": "jV6z08u7y0/tmp/a415ee21cd5915e2554c048d8ae79b091c731d59432133eb17da471fd9dad83b.jpg", "img_caption": ["Figure 3: The dynamic of co-correlation under different set-up of weight initialization. MLP network defined in Equation (3) with ReLU activation function for width 32, 512, 2048 and 8192 are included. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "To estimate the co-correlation more efficiently and in parallel, we employ the Power Iteration algorithm [10] in conjunction with Functorch [17]. The corresponding pseudo-code is presented in theAppendix E. ", "page_idx": 8}, {"type": "text", "text": "We verify our proposed theorem on linear and MLP models on the MNIST dataset [22]. The width of hidden layers varied from $2^{4}$ 10m $2^{13}$ with weightsinitialized via aGaussian distribution $\\textstyle N(0,{\\frac{1}{m^{1+2q}}})$ where $q$ was set to values ranging from 0.25 to $-0.15$ . We train both the linear and MLP for 50 epochs with a batch size of 512 using the SGD optimizer with a learning rate of 0.003. In addition, we also conduct the experiment on more complex ResNet50 [16] and WRN50 [38]. For both models, we opted for default random weight initialization and used the Adam optimizer with a learning rate of 0.0005 on CIFAR10 [20]. To calculate the co-correlation and other statistics, we cover the entire testset. We consider using $L_{2}$ Auto-attack [5] with $\\epsilon=0.5$ for all MLPs we trained. The experiments were executed on a Nvidia RTX3090 GPU, using Python 3.9.7 and PyTorch 1.9.1. The code for the experiment is available at https : //github . com/squarewang2077/co- correlation. ", "page_idx": 8}, {"type": "text", "text": "6.1  Empirical Evidence for Proposed Theorem ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Figure 1 presents a comparison between the robust accuracy and the Dirichlet energy ${\\mathfrak{S}}(f)$ acrossall trained MLPs. As observed in Figure 1a and 1b, models with lower levels of Dirichlet energy ${\\mathfrak{S}}(f)$ tend to exhibit higher robust accuracy, suggesting that Dirichlet energy is an effective representation of adversarial robustness. Another noteworthy finding is that wider neural networks, with the same level of weight initialization, demonstrate improved adversarial robustness. ", "page_idx": 8}, {"type": "text", "text": "Figure 1 also depicts the dynamic behaviour of shallow neural networks with a weight initialization parameter of $q=0.25$ . As is shown in Figure 1c and 1d, the co-correlation $\\varrho$ increases throughout training. Except for narrow widths like $2^{4}$ and $2^{5}$ , the majority of networks demonstrate an upward trend. This trend, however, flattens for non-linear models, suggesting potentially stronger adversarial robustness due to the non-linearity of the activation function introduced in MLPs. ", "page_idx": 8}, {"type": "text", "text": "Figure 2 shows the dynamics of the co-correlation on ResNet50 and Wide-ResNet50. Both networks are trained on CIFAR10 using the Adam optimizer. We divide them by the pattern of A1-A2 and B1- B2, as shown in Figure 2a. The co-correlation outcomes for these divisions are displayed in Figure 2b and Figure 2c, it shows that even with the Adam optimizer, without specific weight initialization considerations, there is a noticeable rise in co-correlation. ", "page_idx": 8}, {"type": "text", "text": "6.2The Impact of Width and Weight Initialization ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Figure 3 illustrates the co-correlation dynamics under varying $q$ for both linear and MLPs with widths of 32, 512, 2,048, and 8,192. The figure highlights that our proposed theorems\u2019 assumption of $q>0$ is quite tight, as all trajectories with $q<0$ remain flat throughout training. We can also observe that the speed of accumulation significantly increases with larger network widths. ", "page_idx": 8}, {"type": "text", "text": "Figure 4 displays the accuracy on testset and co-correlation for both linear and MLPs as heat-maps. Each cell in the heat-map represents a trained network. From Figure 4c and Figure 4d, we observe that the best performance and robustness are shown by the MLPs with the largest widths (width $=8192$ and the smallest weight initializations $g=-0.15)$ . And when we alter the weight initialization to control the co-correlation, making it increase from 0.25 to 0.83, the accuracy declines accordingly from 0.93 to 0.68. On the contrary, for another extreme case of models with a width of 16, enhanced performance is accompanied by increased co-correlation. Consequently, an interesting conclusion can be drawn about the diverse behaviour of neural networks with small and larger width. Gradient descent tends to enhance the training of neural networks with smaller width by fostering co-correlation among layers, which is intrinsically brittle. However, wide networks are trained with less reliance on interlayer correlation, resulting in inherently more robust models. ", "page_idx": 8}, {"type": "image", "img_path": "jV6z08u7y0/tmp/4b3df592a705ea92ab7f3eea209e67458ba9ea177bb914244f7bbe7b658baf0c.jpg", "img_caption": ["Figure 4: Accuracy and Co-correlation under different initialization and width. Figure 4a and 4b show the heat map for linear model, and Figure 4c and 4d is for MLP ReLU. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "7  Conclusion and Limitation ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our work investigates the implicit bias of gradient descent toward adversarial robustness from the perspective of collaboration between layers. By adapting Dirichlet energy to estimate the adversarial robustness of neural networks\u2019 individual components, we characterized the collaboration behaviour between consecutive layers and identified two fundamental properties for dynamics of the co-correlation. The first property shows that the co-correlation for MLPs will build up during gradient descent under mild assumptions for weight initialization. The second property shows that the speed of accumulation for co-correlation is inversely related to the operator norm of Jacobian for the corresponding sub-modules. In addition, we observed that networks with small widths tend to foster co-correlation among layers to improve performance, whereas wide networks\u2032 performance improvement does not heavily rely on establishing such co-correlation. Future research can expand upon this by examining the effects of increased network depth and more sophisticated structures on the observed phenomena. ", "page_idx": 9}, {"type": "text", "text": "Limitation  Our work can be easily extended to multi-layer neural networks since we only assume that the inputs are bounded by the $L_{2}$ -norm. However, like many theoretical studies, extending our approach to more complex models is challenging. It remains unknown whether complex models exhibit thesamebehaviors. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1]  R. Bhattacharjee, S. Jha, and K. Chaudhuri. Sample complexity of robust linear classification on separated data. In International Conference on Machine Learning, pages 884-893. PMLR, 2021.   \n[2] S. Bubeck, Y. Cherapanamjeri, G. Gidel, and R. Tachet des Combes. A single gradient step finds adversarial examples on random two-layers neural networks. Advances in Neural Information Processing Systems, 34:10081-10091, 2021.   \n[3]  L. Chizat and F. Bach. Implicit bias of gradient descent for wide two-layer neural networks trained with the logistic loss. In Conference on Learning Theory, pages 1305-1338. PMLR, 2020.   \n[4] I. Cohen, Y. Huang, J. Chen, J. Benesty, J. Benesty, J. Chen, Y. Huang, and I. Cohen. Pearson correlation coefficient. Noise reduction in speech processing, pages 1-4, 2009.   \n[5]  F. Croce and M. Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks. In International conference on machine learning, pages 2206-2216. PMLR, 2020.   \n[6]  A. Daniely and H. Shacham.  Most relu networks suffer from $l^{2}$ adversarial perturbations. Advances in Neural Information Processing Systems, 33:6629-6636, 2020.   \n[7] E. Dobriban, H. Hassani, D. Hong, and A. Robey. Provable tradeoffs in adversarially robust classification. arXiv preprint arXiv:2006.05161, 2020.   \n[8] E. Dohmatob and A. Bietti. On the (non-) robustness of two-layer neural networks in different learning regimes. arXiv preprint arXiv:2203.11864, 2022.   \n[9] S. S. Du, X. Zhai, B. Poczos, and A. Singh. Gradient descent provably optimizes overparameterized neural networks. arXiv preprint arXiv: 1810.02054, 2018.   \n[10] J. F. Epperson. An introduction to numerical methods and analysis. John Wiley & Sons, 2021.   \n[11] L. C. Evans. Partial differential equations, volume 19. American Mathematical Society, 2022.   \n[12] S. Frei, G. Vardi, P. L. Bartlett, N. Srebro, and W. Hu. Implicit bias in leaky relu networks trained on high-dimensional data. arXiv preprint arXiv:2210.07082, 2022.   \n[13] S. Frei, G. Vardi, P. L. Bartlett, and N. Srebro. The double-edged sword of implicit bias: Generalization vs. robustness in relu networks. arXiv preprint arXiv:2303.01456, 2023.   \n[14] J. Gilmer, L. Metz, F. Faghri, S. S. Schoenholz, M. Raghu, M. Wattenberg, and I. Goodfellow. Adversarial spheres. arXiv preprint arXiv:1801.02774, 2018.   \n[15] 1. J. Goodfellow, J. Shlens, and C. Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.   \n[16] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770- 778, 2016.   \n[17]  R. Z. Horace He. functorch: Jax-like composable function transforms for pytorch. https : //github.com/pytorch/functorch, 2021.   \n[18] H. Huang, Y. Wang, S. Erfani, Q. Gu, J. Bailey, and X. Ma. Exploring architectural ingredients of adversarially robust deep neural networks. Advances in Neural Information Processing Systems, 34:5545-5559, 2021.   \n[19]  Z. Ji and M. Telgarsky. Directional convergence and alignment in deep learning. Advances in Neural Information Processing Systems, 33:17176-17186, 2020.   \n[20]  A. Krizhevsky. Learning multiple layers of features from tiny images. Master's thesis, University of Tront, 2009.   \n[21] D. Kunin, A. Yamamura, C. Ma, and S. Ganguli. The asymmetric maximum margin bias of quasi-homogeneous neural networks. arXiv preprint arXiv:2210.03820, 2022.   \n[22]  Y. LeCun, C. Cortes, and C. Burges. Mnist handwritten digit database. ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist, 2, 2010.   \n[23]  K. Lyu and J. Li. Gradient descent maximizes the margin of homogeneous neural networks. arXiv preprint arXiv:1906.05890, 2019.   \n[24] K. Lyu, Z. Li, R. Wang, and S. Arora. Gradient descent on two-layer nets: Margin maximization and simplicity bias. Advances in Neural Information Processing Systems, 34:12978-12991, 2021.   \n[25]  A. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu. Towards deep learning models resistant to adversarial attacks. arXiv preprint arXiv: 1706.06083, 2017.   \n[26] S. Mahloujifar, D. I. Diochnos, and M. Mahmoody. The curse of concentration in robust learning: Evasion and poisoning attacks from concentration of measure. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 4536-4543. Association for the Advancement of Artificial Intelligence (AAAI), 2019.   \n[27]  Y. Min, L. Chen, and A. Karbasi. The curious case of adversarially robust models: More data can help, double descend, or hurt generalization. In Uncertainty in Artificial Intelligence, pages 129-139. PMLR, 2021.   \n[28] N. Papernot, P. McDaniel, X. Wu, S. Jha, and A. Swami. Distillation as a defense to adversarial perturbations against deep neural networks. In 2016 IEEE symposium on security and privacy (SP), pages 582-597. IEEE, 2016.   \n[29]  R. Sarussi, A. Brutzkus, and A. Globerson. Towards understanding learning in neural networks with linear teachers. In International Conference on Machine Learning, pages 9313-9322. PMLR, 2021.   \n[30] L. Schmidt, S. Santurkar, D. Tsipras, K. Talwar, and A. Madry. Adversarially robust generalization requires more data. Advances in neural information processing systems, 31, 2018.   \n[31] A. Shafahi, W. R. Huang, C. Studer, S. Feizi, and T. Goldstein. Are adversarial examples inevitable? arXiv preprint arXiv:1809.02104, 2018.   \n[32] C.-J. Simon-Gabriel, Y. Ollivier, L. Bottou, B. Scholkopf, and D. Lopez-Paz. First-order adversarial vulnerability of neural networks and input dimension. In International conference on machine learning, pages 5809-5817. PMLR, 2019.   \n[33] D. Tsipras, S. Santurkar, L. Engstrom, A. Turner, and A. Madry. Robustness may be at odds with accuracy. arXiv preprint arXiv: 1805.12152, 2018.   \n[34] F. Wang, P. Xu, W. Ruan, and X. Huang. Towards verifying the geometric robustness of large-scale neural networks. arXiv preprint arXiv:2301. 12456, 2023.   \n[35]  Z. Wang and W. Ruan. Understanding adversarial robustness of vision transformers via cauchy problem. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2022, Grenoble, France, September 19-23, 2022, Proceedings, Part Il, pages 562-577. Springer, 2023.   \n[36]  X. Yin and W. Ruan. Boosting adversarial training via fisher-rao norm-based regularization. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 24544-24553, 2024.   \n[37] X. Yin, W. Ruan, and J. Fieldsend. Dimba: discretely masked black-box attack in single object tracking. Machine Learning, 113(4):1705-1723, 2024.   \n[38] S. Zagoruyko and N. Komodakis. Wide residual networks. arXiv preprint arXiv:1605.07146, 2016.   \n[39] H. Zhang, Y. Yu, J. Jiao, E. Xing, L. El Ghaoui, and M. Jordan. Theoretically principled trade-off between robustness and accuracy. In International conference on machine learning, pages 7472-7482. PMLR, 2019.   \n[40]  T. Zhang, W. Ruan, and J. E. Fieldsend. Proa: A probabilistic robustness assessment against functional perturbations. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 154-170. Springer, 2022.   \n[41]  Z. Zhu, F. Liu, G. Chrysos, and V. Cevher. Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization). Advances in Neural Information Processing Systems, 35:36094-36107, 2022. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A The Proof for Theorem 4.1 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Suppose that the loss function $L$ is differentiable w.r.t. $f$ . Given data points $(\\pmb{x},y)\\sim P$ and $x\\sim P_{x}$ \uff0c we have ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R^{r o b}(f,r)=\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,\\underset{r\\in\\mathbb{B}_{r}}{\\operatorname*{sup}}\\,L(f(x+\\varepsilon),y))}\\\\ &{\\qquad\\qquad=\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,\\underset{\\varepsilon\\in B_{r}}{\\operatorname*{sup}}\\,L(f(x),y))+\\underset{\\varepsilon\\in B_{r}}{\\operatorname*{sup}}\\,L(f(x+\\varepsilon),y))-\\underset{\\varepsilon\\in B_{r}}{\\operatorname*{sup}}\\,L(f(x,y))\\Bigg]}\\\\ &{\\qquad\\le\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,[L(f(x),y)]]+\\sqrt{\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,\\underset{\\varepsilon\\in B_{r}}{\\operatorname*{sup}}\\,\\left(\\ L(f(x+\\varepsilon),y))-L(f(x,y))\\right)^{2}}\\Bigg]}\\\\ &{\\qquad\\approx\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,[L(f(x),y))]+\\sqrt{\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,\\underset{\\varepsilon\\in B_{r}}{\\operatorname*{sup}}\\,(\\nabla_{f}L^{T}\\cdot J_{f}(x)\\varepsilon)^{2}\\Bigg]}}\\\\ &{\\qquad=\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,[L(f(x),y))]+r\\sqrt{\\underset{(x,y)\\sim P}{\\mathbb{E}}\\,\\underset{\\varepsilon\\in B_{r}}{\\mathbb{E}}\\,\\underset{f(x,y)\\sim P}{\\mathbb{E}}\\,\\|\\nabla_{f}L^{T}\\cdot J_{f}(x)\\|_{2}^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\nabla_{f}L$ is the gradients of $L$ W.r.t. $f,\\nabla_{f}L^{T}$ indicates that it is a row vector. $J_{f}(x)$ is the Jacobian matrix for classifer $f$ ", "page_idx": 12}, {"type": "text", "text": "BThe Proof of Theorem 5.3 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Before formally proving the theorem, we provide some lemmas which are useful for our proof. ", "page_idx": 12}, {"type": "text", "text": "Lemma B.1 (Dynamic of Weights for Linear Model). Given gradient descent to optimize the weights, thedynamic of theweightsat step $t$ is ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\dot{W}(t)=\\pmb{a}\\otimes\\pmb{\\widetilde{x}}^{T}(t),\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Proof. Given the step size $\\eta$ , the update for $r_{t h}$ row of the weight matrix $W$ is ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\Delta{\\pmb w}_{r}=-\\frac{\\eta}{n}\\sum_{i=1}^{n}\\frac{\\partial l}{\\partial u_{i}}\\frac{\\partial f({\\pmb W},{\\pmb x}_{i})}{\\partial{\\pmb w}_{r}}}\\\\ {\\displaystyle=\\eta a_{r}\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_{i}-s i g(u_{i})\\big){\\pmb x}_{i},}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $s i g(\\cdot)$ denotes the sigmoid function. Hence, for weight matrix $W$ ,wehave ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta W=\\left(\\!\\!\\begin{array}{c}{\\Delta w_{1}^{T}}\\\\ {\\vdots}\\\\ {\\Delta w_{m}^{T}}\\end{array}\\!\\!\\right)}\\\\ &{\\qquad=\\eta\\left(\\!\\!\\begin{array}{c}{a_{1}\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-s i g(u_{i})\\right)x_{i}^{T}}\\\\ {\\vdots}\\\\ {a_{m}\\frac{1}{n}\\sum_{i=1}^{n}\\left(y_{i}-s i g(u_{i})\\right)x_{i}^{T}}\\end{array}\\!\\!\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "After replacing with ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\widetilde{\\pmb{x}}=\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_{i}-s i g(u_{i})\\big)\\pmb{x}_{i},\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Delta W=\\eta\\left(\\!\\!\\begin{array}{c}{a_{1}\\widetilde{\\pmb{x}}^{T}}\\\\ {\\vdots}\\\\ {a_{m}\\widetilde{\\pmb{x}}^{T}}\\end{array}\\!\\!\\right)}\\\\ {=\\eta\\pmb{a}\\otimes\\widetilde{\\pmb{x}}^{T}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Since $\\|\\pmb{x}_{i}\\|_{2}=1$ we alsohave $\\|\\widetilde{\\pmb{x}}\\|_{2}\\leq1$ . Therefore, we can say that the dynamics of weights, i.e. $\\dot{W}(t)$ ,is ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\dot{W}(t)=\\pmb{a}\\otimes\\pmb{\\widetilde{x}}^{T}(t).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Lemma B.2 (The Concentration for $L_{2}$ Norm of Gaussian r.v.). Let $I_{m}$ be identical matrix of size $m\\times m$ $z_{1},\\cdot\\cdot\\cdot\\,,z_{n}$ suchat $\\begin{array}{r}{z_{i}\\overset{i.i.d.}{\\sim}N(0,\\frac{1}{m^{1+2q}}\\mathbf{I}_{m}),q\\,>}\\end{array}$ $0,\\forall i\\in[n]$ .With probability at least $1-\\delta$ , we have several conclusions: ", "page_idx": 13}, {"type": "text", "text": "1. Average of the norm ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\|z_{i}\\|_{2}=\\frac{1}{m^{q}}+\\mathcal{O}\\bigg(\\sqrt{\\frac{8\\log(2n/\\delta)}{m^{1+2q}}}\\bigg).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "2. Average of the square norm ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\|z_{i}\\|_{2}^{2}=\\frac{1}{m^{2q}}+\\mathcal{O}\\bigg(\\operatorname*{max}\\bigg\\{\\frac{8\\log(2/\\delta)}{m^{1+2q}n},\\sqrt{\\frac{8\\log(2/\\delta)}{m^{1+4q}n}}\\bigg\\}\\bigg).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "3. Square root of the average of the square norm ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\|z_{i}\\|_{2}^{2}}=\\frac{1}{m^{q}}+\\mathcal{O}\\bigg(\\sqrt{\\frac{8\\log(2/\\delta)}{m^{1+2q}n}}\\bigg).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Proof. We first prove the concentration property for the average of the norm. Since $\\sqrt{m^{1+2q}}z_{i,r}\\stackrel{i.i.d}{\\sim}$ $N(0,1),i\\in[n],r\\in[m]$ we have that $m^{1+2q}z_{i,r}^{2}\\sim\\chi^{2}(1)$ entthxldi as $S E(\\nu^{2},\\alpha)$ , we have $m^{1+2q}z_{i,r}^{2}-1\\in S E(4,4)$ .Hence $\\forall i\\in[n]$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\Big|\\frac{1}{m}\\sum_{r=1}^{m}\\big(\\sqrt{m^{1+2q}}z_{i,r}\\big)^{2}-1\\Big|\\geq\\epsilon\\bigg)\\leq\\left\\{2\\exp\\Big(-\\frac{m\\epsilon^{2}}{8}\\Big)\\right.\\quad\\epsilon\\in(0,1)\\;.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore,wehave $\\forall\\epsilon>0$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\bigg(\\bigg|\\frac{1}{\\sqrt{m}}\\|\\sqrt{m^{1+2q}}z_{i}\\|_{2}-1\\bigg|\\geq\\epsilon\\bigg)\\leq\\mathbb{P}\\bigg(\\bigg|\\frac{1}{m}\\|\\sqrt{m^{1+2q}}z_{i}\\|_{2}^{2}-1\\bigg|\\geq\\operatorname*{max}\\{\\epsilon,\\epsilon^{2}\\}\\bigg)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq2\\exp\\Big(-\\frac{m\\epsilon^{2}}{8}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Equation (40) is because of the fact that given $c>0$ fixed, $\\forall x>0$ wehave ", "page_idx": 13}, {"type": "equation", "text": "$$\n|x-1|\\geq c\\Rightarrow|x^{2}-1|\\geq\\operatorname*{max}\\{c,c^{2}\\}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Hence, ", "text_level": 1, "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\bigg(\\bigg|\\displaystyle\\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\|m^{q}z_{i}\\|_{2}-1\\bigg|\\geq\\epsilon\\bigg)=\\mathbb{P}\\bigg(\\bigg|\\displaystyle\\frac{1}{n}\\displaystyle\\sum_{i=1}^{n}\\frac{1}{\\sqrt{m}}\\|\\sqrt{m^{1+2q}}z_{i}\\|_{2}-1\\bigg|\\geq\\epsilon\\bigg)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathbb{P}\\bigg(\\displaystyle\\sum_{i=1}^{n}\\bigg|\\displaystyle\\frac{1}{\\sqrt{m}}\\|\\sqrt{m^{1+2q}}z_{i}\\|_{2}-1\\bigg|\\geq n\\epsilon\\bigg)}\\\\ &{\\qquad\\qquad\\leq\\displaystyle\\sum_{i=1}^{n}\\mathbb{P}\\bigg(\\bigg|\\displaystyle\\frac{1}{\\sqrt{m}}\\|\\sqrt{m^{1+2q}}z_{i}\\|_{2}-1\\bigg|\\geq\\epsilon\\bigg)}\\\\ &{\\qquad\\qquad\\leq2n\\exp\\Big(-\\displaystyle\\frac{m\\epsilon^{2}}{8}\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Equivalently, with probability at least $1-\\delta$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{c}{{\\displaystyle\\left\\lvert\\frac{1}{n}\\sum_{i=1}^{n}m^{q}\\lVert z_{i}\\rVert_{2}-1\\right\\rvert\\le\\sqrt{\\displaystyle\\frac{8}{m}l o g\\frac{2n}{\\delta}}}}\\\\ {{\\Rightarrow\\displaystyle\\left\\lvert\\frac{1}{n}\\sum_{i=1}^{n}\\lVert z_{i}\\rVert_{2}-\\frac{1}{m^{q}}\\right\\rvert\\le\\displaystyle\\frac{1}{m^{q}}\\sqrt{\\frac{8}{m}l o g\\frac{2n}{\\delta}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To prove the second convergence, we starts from the fact that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\|z_{i}\\|_{2}^{2}=\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{r=1}^{m}z_{i,r}^{2}=\\frac{1}{m^{2q}}\\frac{1}{n m}\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\big(\\sqrt{m^{1+2q}}z_{i,r}\\big)^{2}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Since $\\left(\\sqrt{m^{1+2q}}z_{i,r}\\right)^{2}\\overset{i.i.d.}{\\sim}\\chi^{2}(1),\\forall i\\in[n],r\\in[m]$ similar to quation (39), we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\Big|\\frac{1}{n m}\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\big(\\sqrt{m^{1+2q}}z_{i,r}\\big)^{2}-1\\Big|\\geq\\epsilon\\bigg)\\leq\\left\\{\\begin{array}{l l}{2\\exp\\bigg(-\\frac{n m}{8}\\epsilon^{2}\\bigg)}&{\\epsilon\\in(0,1)}\\\\ {2\\exp\\bigg(-\\frac{n m}{8}\\epsilon\\bigg)}&{\\epsilon\\geq1}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Equivalently, with probability at least $1-\\delta$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\left|\\frac{1}{n}\\sum_{i=1}^{n}m^{2q}\\|z_{i}\\|_{2}^{2}-1\\right|\\leq\\left\\{\\sqrt{\\frac{8}{m n}l o g\\frac{2}{\\delta}}\\quad\\epsilon\\in(0,1)\\right.}\\\\ {\\displaystyle\\Rightarrow\\left|\\frac{1}{n}\\sum_{i=1}^{n}\\|z_{i}\\|_{2}^{2}-\\frac{1}{m^{2q}}\\right|\\leq\\frac{1}{m^{2q}}\\operatorname*{max}\\left\\{\\frac{8}{m n}l o g\\frac{2}{\\delta},\\sqrt{\\frac{8}{m n}l o g\\frac{2}{\\delta}}\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Now we prove the third concentration, with similar trick of the first concentration, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle>\\!\\left(\\left|\\sqrt{\\frac{1}{n m}\\displaystyle\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\left(\\sqrt{m^{1+2q}z_{i,r}}\\right)^{2}}-1\\right|\\geq\\epsilon\\right)\\leq\\mathbb{P}\\!\\left(\\left|\\frac{1}{n m}\\displaystyle\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\left(\\sqrt{m^{1+2q}z_{i,r}}\\right)^{2}-1\\right|\\geq\\operatorname*{max}\\{\\epsilon,\\epsilon^{2}\\}\\right.}\\\\ {\\displaystyle<3}\\\\ {\\displaystyle\\leq2\\exp\\left(-\\left.\\frac{n m}{8}\\epsilon^{2}\\right)}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\Big|\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}m^{2q}\\|z_{i}\\|_{2}^{2}}-1\\Big|\\ge\\epsilon\\bigg)\\le2\\exp\\bigg(-\\frac{n m}{8}\\epsilon^{2}\\bigg),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "with probability at least $1-\\delta$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\left|m^{q}\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\|z_{i}\\|_{2}^{2}}-1\\right|\\leq\\sqrt{\\frac{8}{m n}l o g\\frac{2}{\\delta}}}\\\\ {\\displaystyle\\Rightarrow\\left|\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\|z_{i}\\|_{2}^{2}}-\\frac{1}{m^{q}}\\right|\\leq\\frac{1}{m^{q}}\\sqrt{\\frac{8}{m n}l o g\\frac{2}{\\delta}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Now, we prove the theorem 5.3. Given the linear model and training dataset $D\\,=\\,\\{({\\pmb{x}}_{i},y_{i})\\}_{i=1}^{n}$ Assume that each wi,j .... $\\begin{array}{r}{w_{i,j}\\overset{i.i.d.}{\\sim}N(0,\\frac{1}{m^{1+2q}}),q>0}\\end{array}$ andi $\\textbf{\\em a}$ is randomly inilized subject to the constraint $\\|\\pmb{a}\\|_{2}=1$ and fixed during training. Hence, with high probability, we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\dot{\\varrho}_{a,W}\\geq\\eta\\varrho_{a,W}\\cdot\\left(\\frac{\\sum_{\\tau=1}^{t}\\widetilde{\\pmb{x}}(\\tau)^{T}\\widetilde{\\pmb{x}}(t)}{\\|W(t)\\|_{2}^{2}}\\cdot\\left(1-\\left(\\pmb{v}(t)^{T}\\pmb{a}\\right)^{2}\\right)+\\mathcal{O}\\!\\left(\\frac{1}{m^{q}}\\right)\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof. We first show that the derivative of co-correlation is ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\dot{\\varrho}_{a,W}(t)=\\frac{d}{d t}\\varrho_{a,W}(t)}\\\\ {=\\frac{d}{d t}\\frac{\\mathbb{E}_{x}[\\|\\alpha^{T}W(t)\\|_{2}^{2}]^{\\frac{1}{2}}}{\\mathbb{E}_{x}[\\|W(t)\\|_{2}^{2}]^{\\frac{1}{2}}}}\\\\ {=\\frac{d}{d t}\\frac{\\|a^{T}W(t)\\|_{2}}{\\|W(t)\\|_{2}}}\\\\ {=\\frac{\\varrho_{a,W}(t)}{2}\\bigg(\\frac{d\\|a^{T}W(t)\\|_{2}^{2}/d t}{\\|a^{T}W(t)\\|_{2}^{2}}-\\frac{d\\|W(t)\\|_{2}^{2}/d t}{\\|W(t)\\|_{2}^{2}}\\bigg)}\\\\ {\\geq\\frac{\\varrho_{a,W}(t)}{2\\|W(t)\\|_{2}^{2}}\\bigg(\\frac{d\\|a^{T}W(t)\\|_{2}^{2}}{d t}-\\frac{d\\|W(t)\\|_{2}^{2}}{d t}\\bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "by the law of derivatives for inner product of matrices and the eigenvalue of matrix $W(t)W(t)^{T}$ ,we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\|\\boldsymbol{a}^{T}\\boldsymbol{W}(t)\\|_{2}^{2}}{d t}=\\pmb{a}^{T}(\\dot{\\boldsymbol{W}}(t)\\boldsymbol{W}(t)^{T}+\\boldsymbol{W}(t)\\dot{\\boldsymbol{W}}(t)^{T})\\pmb{a}}\\\\ &{\\quad\\frac{d\\|\\boldsymbol{W}(t)\\|_{2}^{2}}{d t}=\\pmb{v}(t)^{T}(\\dot{\\boldsymbol{W}}(t)\\boldsymbol{W}(t)^{T}+\\boldsymbol{W}(t)\\dot{\\boldsymbol{W}}(t)^{T})\\pmb{v}(t),}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where ${\\pmb v}(t)$ is the dominant eigenvector for $W(t)W(t)^{T}$ . Equation (60) is because $J_{W}(x)=W$ and $\\|\\pmb{a}\\|_{2}=1$ by assumption. Since Equation (60) do not depend on $x$ , we can safely drop the Expectation $\\mathbb{E}_{x}$ as is shown in Equation (61). Equation (63) is because $\\|\\pmb{a}^{T}W\\|_{2}^{2}\\leq\\|\\pmb{a}\\|_{2}^{\\bar{2}}\\|W\\mathbf{\\hat{|}}_{2}^{2}=\\|\\dot{W}\\|_{2}^{2}$ .By Lemma B.1, the weight matrix $W(t)$ at training step $t$ can be approximated as ", "page_idx": 15}, {"type": "equation", "text": "$$\nW(t)=W(0)+\\sum_{\\tau=1}^{t}\\Delta W(\\tau).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "then ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\dot{W}(t)W(t)^{T}=a\\otimes\\hat{x}^{T}(t)\\left(W(0)^{T}+\\sum_{r=1}^{t}\\Delta W(\\tau)^{T}\\right)}}\\\\ {{\\displaystyle\\qquad\\qquad=a\\otimes\\hat{x}^{T}(t)\\left(W(0)^{T}+\\eta\\sum_{r=1}^{t}a^{T}\\otimes\\hat{x}(\\tau)\\right)}}\\\\ {{\\displaystyle\\qquad=a\\otimes\\hat{x}^{T}(t)\\left(W(0)^{T}+\\eta a^{T}\\otimes\\sum_{r=1}^{t}\\tilde{x}(\\tau)\\right)}}\\\\ {{\\displaystyle\\qquad=a\\otimes\\hat{x}^{T}(t)W(0)^{T}+\\eta\\left(a\\otimes\\hat{x}^{T}(t)\\right)\\left(a^{T}\\otimes\\sum_{r=1}^{t}\\tilde{x}(\\tau)\\right)}}\\\\ {{\\displaystyle\\qquad=a\\otimes\\hat{x}^{T}(t)W(0)^{T}+\\eta\\left(\\sum_{r=1}^{t}\\tilde{x}(\\tau)^{T}\\tilde{x}(t)\\right)a a^{T}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "similarity, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{W(t)\\dot{W}(t)^{T}=\\displaystyle\\left(W(0)+\\sum_{\\tau=1}^{t}\\Delta W(\\tau)\\right){a^{T}}\\otimes\\widetilde{x}(t)}}\\\\ {{\\displaystyle\\qquad\\qquad=\\left(W(0)+\\eta{a}\\otimes\\sum_{\\tau=1}^{t}\\widetilde{x}^{T}(\\tau)\\right){a^{T}}\\otimes\\widetilde{x}(t)}}\\\\ {{\\displaystyle\\qquad\\qquad=W(0)\\widetilde{x}(t){a^{T}}+\\eta\\biggl(\\sum_{\\tau=1}^{t}\\widetilde{x}(\\tau)^{T}\\widetilde{x}(t)\\biggr){a}{a^{T}}.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Hence ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{2}\\Big(\\displaystyle\\frac{d\\|a^{T}W(t)\\|_{2}^{2}}{d t}-\\frac{d\\|W(t)\\|_{2}^{2}}{d t}\\Big)}\\\\ &{=\\underbrace{\\eta\\Big(1-\\big(a^{T}v(t)\\big)^{2}\\Big)\\Big(\\displaystyle\\sum_{\\tau=1}^{t}\\widetilde{x}(\\tau)^{T}\\widetilde{x}(t)\\Big)}_{\\displaystyle(\\Omega)}+\\underbrace{a^{T}W(0)\\widetilde{x}(t)a^{T}a-v(t)^{T}W(0)\\widetilde{x}(t)a^{T}v(t)}_{\\displaystyle(\\Omega)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "$\\textcircled{1}$ is the main part of our theorem. And for $\\textcircled{2}$ , it can be bounded as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\mathcal{D}|=\\Big|\\big(a-a^{T}v(t)v(t)\\big)^{T}W(0)\\widetilde{x}(t)\\Big|}\\\\ &{\\quad\\le\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\Big|\\big(y_{i}-s i g(u_{i})\\big)\\big(a-a^{T}v(t)v(t)\\big)^{T}W(0)x_{i}\\,\\Big|}\\\\ &{\\quad\\le\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\underbrace{|y_{i}-s i g(u_{i})|\\sqrt{1-(a^{T}v(t))^{2}}}_{0\\le\\dots\\le1}\\|W(0)x_{i}\\|_{2}}\\\\ &{\\quad\\le\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\|W(0)x_{i}\\|_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Now since $\\begin{array}{r}{w_{i,j}\\,\\sim\\,N(0,\\frac{1}{m^{1+2q}}),q\\,>\\,0}\\end{array}$ and each $w_{i,j}$ is independent with each other, for given $\\mathbf{\\Delta}\\mathbf{x}_{i},i=1,...,n$ ,wehave ", "page_idx": 16}, {"type": "equation", "text": "$$\nW(0)\\pmb{x}_{i}=\\left(\\begin{array}{c}{\\pmb{w}_{1}(0)^{T}\\pmb{x}_{i}}\\\\ {\\vdots}\\\\ {\\pmb{w}_{m}(0)^{T}\\pmb{x}_{i}}\\end{array}\\right)\\sim N\\bigg(0,\\frac{\\|\\pmb{x}_{i}\\|_{2}^{2}}{m^{1+2q}}I_{m}\\bigg),\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\|\\pmb{x}_{i}\\|_{2}^{2}=1$ by assumption. By the lemma B.2, with high probability ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\sum_{i=1}^{n}\\|W(0)\\pmb{x}_{i}\\|_{2}=\\frac{1}{m^{q}}+\\mathcal{O}\\bigg(\\sqrt{\\frac{8\\log(2n/\\delta)}{m^{1+2q}}}\\bigg).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n|{\\mathcal{O}}|={\\mathcal{O}}{\\biggl(}{\\frac{1}{m^{q}}}{\\biggr)}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "with high probability, and it comes to our conclusion. ", "page_idx": 17}, {"type": "text", "text": "C The Proof of Theorem 5.5 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "To prove the Theorem 5.5, the following lemma is crucial. ", "page_idx": 17}, {"type": "text", "text": "Lemma C.1 (Dynamic of Weights for A Nonlinear Model for Initial Steps). Given gradient descent to optimize the weights, the dynamic of the weights at the initial step t for the non-linear model is ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\dot{W}(t)=\\left(\\!\\!\\begin{array}{c}{{a_{1}\\widetilde{\\mathbf{x}}_{1}^{T}(t)}}\\\\ {{\\vdots}}\\\\ {{a_{m}\\widetilde{\\mathbf{x}}_{m}^{T}(t)}}\\end{array}\\!\\!\\right),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\widetilde{\\mathbf{x}}_{r}(t)=a_{r}\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_{i}-s i g(u_{i}(t))\\big)\\sigma^{\\prime}(\\mathbf{w}_{r}^{T}(t)x_{i})x_{i},\\quad r\\in[m].\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. Similar to the linear case, the update for the $r_{t h}$ row for the weight matrix is ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\Delta{\\pmb w}_{r}=-\\frac{\\eta}{n}\\sum_{i=1}^{n}\\frac{\\partial l}{\\partial u_{i}}\\frac{\\partial f({\\boldsymbol W},{\\pmb x}_{i})}{\\partial{\\pmb w}_{r}}}\\\\ {\\displaystyle=\\eta a_{r}\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_{i}-s i g(u_{i})\\big)\\sigma^{\\prime}({\\pmb w}_{r}^{T}{\\pmb x}_{i}){\\pmb x}_{i}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence that the update of the weight matrix $W(t)$ is ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta W=\\left(\\underset{\\vdots}{\\Delta w_{m}^{T}}\\right)}\\\\ &{=\\eta\\left(\\underset{a_{m}\\lambda_{n}}{\\overset{\\sum}{\\sum}}\\right)}\\\\ &{\\qquad=\\eta\\left(\\underset{a_{m}\\frac{1}{n}\\sum_{i=1}^{n}}{\\overset{n}{\\sum}}\\left(y_{i}-s i g(u_{i})\\right)\\sigma^{\\prime}(w_{1}^{T}x_{i})x_{i}^{T}\\right)}\\\\ &{\\qquad=\\eta\\left(\\underset{a_{m}\\frac{1}{n}\\sum_{i=1}^{n}}{\\overset{n}{\\sum}}\\left(y_{i}-s i g(u_{i})\\right)\\sigma^{\\prime}(w_{m}^{T}x_{i})x_{i}^{T}\\right)}\\\\ &{\\qquad=\\eta\\left(\\underset{a_{m}\\frac{1}{\\lambda_{n}}}{\\overset{n}{\\sum}}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence our conclusion. ", "page_idx": 17}, {"type": "text", "text": "Lemma C.2 (Concentration for Weighted Sum and Square Root Scalar for Bounded Variables). Suppose $X_{r}-\\mu\\in[l,u],\\forall i\\in[m]$ isindependentidenticallydistributed $r\\nu.$ with mean $O$ .Given a vector $\\pmb{v}\\in\\mathbb{R}^{m},\\lVert\\pmb{v}\\rVert_{2}=1$ and $\\textbf{\\em a}$ such that $a_{r}\\in\\{-1,1\\},r\\in[m]$ wehaveconcentrationinequality ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\Big|\\frac{1}{\\sqrt{m}}\\sum_{r=1}^{m}a_{r}v_{r}X_{r}-\\frac{1}{\\sqrt{m}}a^{T}v\\mu\\Big|\\geq\\epsilon\\bigg)\\leq2\\exp\\bigg\\{-\\frac{m\\epsilon^{2}}{2(u-l)^{2}}\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. We first show the moment generation function of the r.v. we would like to estimate. ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathbb{E}\\bigg[\\exp\\bigg\\{t\\Big(\\frac{1}{\\sqrt{m}}\\sum_{r=1}^{m}a_{r}v_{r}X_{r}-\\frac{1}{\\sqrt{m}}a^{T}v\\mu\\Big)\\bigg\\}\\bigg]\\leq\\exp\\bigg\\{\\frac{t^{2}}{2m}(u-l)^{2}\\bigg\\}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Now, we prove this inequality. ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}\\bigg[\\exp\\bigg\\{t\\bigg(\\frac{1}{\\sqrt{m}}\\displaystyle\\sum_{r=1}^{m}a_{r}v_{r}X_{r}-\\frac{1}{\\sqrt{m}}a^{r}v_{\\theta}\\bigg)\\bigg\\}\\bigg]=\\mathbb{E}\\bigg[\\exp\\bigg\\{\\frac{t}{\\sqrt{m}}\\bigg(\\displaystyle\\sum_{r=1}^{m}a_{r}v_{r}X_{r}-\\displaystyle\\sum_{r=1}^{m}a_{r}v_{r}\\bigg)\\bigg\\}\\bigg]}&{}\\\\ {=\\displaystyle\\prod_{r=1}^{m}\\mathbb{E}\\bigg[\\exp\\bigg\\{\\frac{t_{a}v_{r}}{\\sqrt{m}}\\bigg(X_{r}-\\mu\\bigg)\\bigg\\}\\bigg]}&{\\quad(94)}\\\\ {\\leq\\displaystyle\\prod_{r=1}^{m}\\exp\\bigg\\{\\frac{v_{r}^{2}t^{2}}{2m}(u-l)^{2}\\bigg\\}}&{\\quad(95)}\\\\ {=\\exp\\bigg\\{\\frac{t^{2}}{2m}(u-l)^{2}\\displaystyle\\sum_{r=1}^{m}v_{r}^{2}\\bigg\\}}&{\\quad(96)}\\\\ {=\\exp\\bigg\\{\\frac{t^{2}}{2m}(u-l)^{2}\\bigg\\},}&{\\quad(97).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $t\\geq0$ . Hence by Chernoff's bound, we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{P}\\bigg(\\Big|\\displaystyle\\frac{1}{\\sqrt{m}}\\displaystyle\\sum_{r=1}^{m}a_{r}v_{r}X_{r}-\\frac{1}{\\sqrt{m}}a^{T}v\\mu\\Big|\\geq\\epsilon\\bigg)\\leq2\\operatorname*{inf}_{t\\geq0}\\frac{\\exp\\big\\{\\frac{t^{2}}{2m}(u-l)^{2}\\big\\}}{\\exp\\{t\\epsilon\\}}}&{}&\\\\ {=2\\exp\\bigg\\{-\\frac{m\\epsilon^{2}}{2(u-l)^{2}}\\bigg\\}}&{}&\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Here, we prove the theorem 5.5. Given a shallow neural network, with high probability we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\dot{\\varrho}_{a,\\sigma\\circ W}(t)=\\frac{\\eta\\varrho_{a,\\sigma\\circ W}(t)}{\\mathbb{E}_{x}\\|D(t)W(t)\\|_{2}^{2}}\\bigg[\\underset{\\tau=1}{\\overset{t}{\\sum}}(1-a^{T}v(\\tau)a^{T}v(t))\\mathbb{E}_{x}\\big[\\widetilde{\\pmb{x}}^{*}(\\tau)^{T}\\widetilde{\\pmb{x}}^{*}(t)\\big]}\\\\ &{\\quad\\quad\\quad+\\operatorname*{max}\\bigg\\{\\mathcal{O}\\bigg(\\frac{1}{\\sqrt{m}}\\bigg),\\mathcal{O}\\bigg(\\frac{1}{m^{q}}\\bigg)\\bigg\\}\\bigg]}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. Because of activation function depends on the input $\\textbf{\\em x}$ , we cannot drop the expectation $\\mathbb{E}_{x}$ Hence, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\dot{\\varrho}_{a,W}(t)=\\cfrac{d}{d t}\\varrho_{a,W}(t)}\\\\ &{\\qquad\\qquad=\\cfrac{d}{d t}\\frac{\\mathbb{E}_{x}[\\|a^{T}D(t)W(t)\\|_{2}^{2}]^{\\frac{1}{2}}}{\\mathbb{E}_{x}[\\|D(t)W(t)\\|_{2}^{2}]^{\\frac{1}{2}}}}\\\\ &{\\qquad\\qquad=\\cfrac{\\varrho_{a,W}(t)}{2}\\bigg(\\frac{\\mathbb{E}_{x}d\\|a^{T}D(t)W(t)\\|_{2}^{2}/d t}{\\mathbb{E}_{x}\\|a^{T}D(t)W(t)\\|_{2}^{2}}-\\cfrac{\\mathbb{E}_{x}d\\|D(t)W(t)\\|_{2}^{2}/d t}{\\mathbb{E}_{x}\\|D(t)W(t)\\|_{2}^{2}}\\bigg)}\\\\ &{\\qquad\\qquad\\geq\\cfrac{\\varrho_{a,W}(t)}{2\\mathbb{E}_{x}\\|D(t)W(t)\\|_{2}^{2}}\\mathbb{E}_{x}\\bigg(\\cfrac{d\\|a^{T}D(t)W(t)\\|_{2}^{2}}{d t}-\\cfrac{d\\|D(t)W(t)\\|_{2}^{2}}{d t}\\bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where $D(t)\\;=\\;d i a g(\\sigma^{\\prime}({\\pmb w}_{1}^{T}{\\pmb x}),...,\\sigma^{\\prime}({\\pmb w}_{m}^{T}{\\pmb x}))$ .And for ReLu activation function, $\\sigma^{\\prime}({\\pmb w}_{m}^{T}{\\pmb x})\\;=\\$ $\\mathbf{1}_{\\{w_{m}^{T}x\\geq0\\}}$ . We assume that the activation does not change at an infinitely small change of $t$ ,implying $\\dot{D}(t)=\\mathbf{0}$ .Hence, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\|a^{T}D(t)W(t)\\|_{2}^{2}}{d t}=a^{T}\\bigg(\\dot{D}(t)W(t)W(t)^{T}D(t)+D(t)W(t)W(t)^{T}\\dot{D}(t)}\\\\ &{\\qquad\\qquad\\qquad+D(t)\\dot{W}(t)W(t)^{T}D(t)+D(t)W(t)\\dot{W}(t)^{T}D(t)\\bigg)a}\\\\ &{\\qquad\\qquad\\quad=a^{T}\\bigg(D(t)\\dot{W}(t)W(t)^{T}D(t)+D(t)W(t)\\dot{W}(t)^{T}D(t)\\bigg)a}\\\\ &{\\qquad\\qquad\\quad=2a^{T}D(t)\\eta\\underset{\\tau=1}{\\overset{t}{\\longrightarrow}}\\left(\\underset{a_{m}\\dot{\\mathcal{X}}_{m}^{T}(\\tau)}{\\overset{a_{1}\\dot{\\mathcal{X}}_{1}^{T}(\\tau)}{\\vdots}}\\right)(a_{1}\\ddot{\\mathbf{x}}_{1}(t)\\quad\\cdots\\quad a_{m}\\ddot{\\mathcal{X}}_{m}(t))\\,D(t)a}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{+\\:2\\,{\\bf a}^{T}D(t)\\left(\\begin{array}{c}{a_{1}\\widetilde{{\\bf x}}_{1}^{T}(t)}\\\\ {\\vdots}\\\\ {a_{m}\\widetilde{{\\bf x}}_{m}^{T}(t)}\\end{array}\\right)W(0)^{T}D(t){\\bf a}\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "And similarly, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{d\\|D(t)W(t)\\|_{2}^{2}}{d t}=v^{T}(t)\\bigg(D(t)\\dot{W}(t)W(t)^{T}D(t)+D(t)W(t)\\dot{W}(t)^{T}D(t)\\bigg)v(t)}\\\\ &{\\qquad\\qquad=2\\underbrace{v^{T}(t)D(t)\\underbrace{t}_{\\mathrm{'~=~1}}^{t}\\left(\\underbrace{a_{n}\\widetilde{x}_{n}^{T}(t)}_{a_{n}\\widetilde{x}_{n}^{T}(t)}\\right)\\left(a_{1}\\widetilde{x}_{1}(t)\\quad\\cdots\\quad a_{m}\\widetilde{x}_{m}(t)\\right)D(t)v(t)}_{\\widetilde{(1)}^{2}}}\\\\ &{\\qquad\\qquad\\qquad=\\underbrace{\\left.\\partial\\mathbf{\\Omega}^{T}(t)\\right.\\partial(t)}_{a_{n}\\widetilde{x}_{1}^{T}(t)}}\\\\ &{\\qquad\\qquad\\qquad+\\underbrace{2\\,v^{T}(t)D(t)\\left(\\underbrace{a_{1}\\widetilde{x}_{n}^{T}(t)}_{a_{m}\\widetilde{x}_{m}^{T}(t)}\\right)W(0)^{T}D(t)v(t)}_{(\\widetilde{2})^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "$\\textcircled{1}$ can be ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\widehat{\\mathbb{\\mathbb{\\Omega}}}=\\eta\\sum_{\\tau=1}^{t}\\left(\\sum_{r=1}^{m}a_{r}^{2}\\sigma^{\\prime}(w_{r}(\\tau)^{T}x)\\widetilde{\\mathbf{x}}_{r}^{T}(\\tau)\\right)\\left(\\sum_{r=1}^{m}a_{r}^{2}\\sigma^{\\prime}(w_{r}(t)^{T}x)\\widetilde{\\mathbf{x}}_{r}(t)\\right)}\\\\ {\\displaystyle\\quad=\\eta\\sum_{\\tau=1}^{t}\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\left[a_{r}^{2}\\sigma^{\\prime}(w_{r}(\\tau)^{T}x)\\sigma^{\\prime}(w_{r}(\\tau)^{T}x_{i})\\right](y-s i g(u_{i}))x_{i}^{T}\\right]}\\\\ {\\displaystyle\\quad\\cdot\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\left[a_{r}^{2}\\sigma^{\\prime}(w_{r}(t)^{T}x)\\sigma^{\\prime}(w_{r}(t)^{T}x_{i})\\right](y-s i g(u_{i}))x_{i}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Since $a_{r}\\in\\{-{\\frac{1}{\\sqrt{m}}},{\\frac{1}{\\sqrt{m}}}\\}$ andthederivative ativationf $\\sigma^{\\prime}$ is bounded by $M$ by assumption, we have that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb P_{W(0)}\\bigg(\\bigg|\\displaystyle\\sum_{r=1}^{m}a_{r}^{2}\\sigma^{\\prime}(w_{r}(t)^{T}x)\\sigma^{\\prime}(w_{r}(t)^{T}x_{i})-\\alpha_{i}(t;x)\\bigg|\\ge\\epsilon\\bigg)}\\\\ &{\\,=\\mathbb P_{W(0)}\\bigg(\\bigg|\\displaystyle\\frac1m\\sum_{r=1}^{m}\\sigma^{\\prime}(w_{r}(t)^{T}x)\\sigma^{\\prime}(w_{r}(t)^{T}x_{i})-\\alpha_{i}(t;x)\\bigg|\\ge\\epsilon\\bigg)\\le2e^{-\\frac{m\\epsilon^{2}}{2M^{4}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\alpha_{i}(t,\\pmb{x})=\\mathbb{E}_{W(0)}\\Big[\\sigma^{\\prime}(\\pmb{w}(t)^{T}\\pmb{x})\\sigma^{\\prime}(\\pmb{w}(t)^{T}\\pmb{x}_{i})\\Big].\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Equivalently, with probability at least $1-\\delta$ ,wehave ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Big|\\sum_{r=1}^{m}a_{r}^{2}\\sigma^{\\prime}\\big(\\pmb{w}_{r}(t)^{T}\\pmb{x}\\big)\\sigma^{\\prime}\\big(\\pmb{w}_{r}(t)^{T}\\pmb{x}_{i}\\big)-\\alpha_{i}(t;\\pmb{x})\\Big|\\leq\\sqrt{\\frac{2M^{4}}{m}l o g\\frac{2}{\\delta}}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Let ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\widetilde{\\pmb{x}}^{*}(t)\\triangleq\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i}\\big(t,\\pmb{x}\\big)\\big(y_{i}-s i g\\big(u_{i}(t)\\big)\\big)\\pmb{x}_{i}}\\\\ &{\\displaystyle\\widetilde{\\pmb{x}}(t)\\triangleq\\frac{1}{n}\\sum_{i=1}^{n}\\big(y_{i}-s i g\\big(u_{i}(t)\\big)\\big)\\pmb{x}_{i}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Hence, with probability at least $1-\\delta$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\mathbb{\\bar{D}}=\\eta\\sum_{\\tau=1}^{t}\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i}(\\tau,x)(y_{i}-s i g(u_{i}(\\tau)))x_{i}^{T}+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(\\tau)^{T}\\right]}\\\\ &{\\displaystyle\\quad\\cdot\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\alpha_{i}(t,x)(y_{i}-s i g(u_{i}(t)))x_{i}+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(t)\\right]}\\\\ &{\\displaystyle\\quad=\\eta\\sum_{\\tau=1}^{t}\\bigg[\\tilde{x}^{*}(\\tau)^{T}+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(\\tau)^{T}\\bigg]\\cdot\\bigg[\\tilde{x}^{*}(t)+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(t)\\bigg]}\\\\ &{\\displaystyle\\quad=\\eta\\sum_{\\tau=1}^{t}\\tilde{x}^{*}(\\tau)^{T}\\tilde{x}^{*}(t)+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(\\tau)^{T}\\tilde{x}^{*}(t)}\\\\ &{\\displaystyle\\quad\\quad+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}^{*}(\\tau)^{T}\\tilde{x}(t)+\\mathcal{O}\\bigg(\\frac{1}{m}\\log\\frac{2}{\\delta}\\bigg)\\tilde{x}(t)^{T}\\tilde{x}(t).}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Since ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\widetilde{\\mathbf{x}}^{*}(t)\\|_{2}\\leq\\frac{1}{n}\\bigg\\|\\left(\\!\\begin{array}{c}{\\alpha_{1}\\big(\\tau,\\mathbf{x}\\big)\\big(y_{1}-s i g(u_{1}(t))\\big)}\\\\ {\\vdots}\\\\ {\\alpha_{n}\\big(\\tau,x\\big)\\big(y_{n}-s i g(u_{n}(t))\\big)}\\end{array}\\!\\bigg)\\bigg\\|_{2}\\bigg\\|\\left(\\!\\begin{array}{c}{x_{1}^{T}}\\\\ {\\vdots}\\\\ {x_{n}^{T}}\\end{array}\\!\\right)\\bigg\\|_{2}\\leq M^{2}}\\\\ &{\\|\\widetilde{\\mathbf{x}}(t)\\|_{2}\\leq\\frac{1}{n}\\bigg\\|\\left(\\!\\begin{array}{c}{y_{1}-s i g(u_{1}(t))}\\\\ {\\vdots}\\\\ {y_{n}-s i g(u_{n}(t))}\\end{array}\\!\\right)\\bigg\\|_{2}\\bigg\\|\\left(\\!\\begin{array}{c}{x_{1}^{T}}\\\\ {\\vdots}\\\\ {x_{n}^{T}}\\end{array}\\!\\right)\\bigg\\|_{2}\\leq1,}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "we have that for at least $1-\\delta$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\langle\\!\\!{\\mathfrak{D}}=\\eta\\sum_{\\tau=1}^{t}{\\widetilde{\\pmb{x}}}^{*}(\\tau)^{T}{\\widetilde{\\pmb{x}}}^{*}(t)+\\mathcal{O}\\!\\left({\\sqrt{\\frac{1}{m}\\log{\\frac{2}{\\delta}}}}\\right)\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Similarly, ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\mathbb{O}^{\\prime}=\\eta\\sum_{\\tau=1}^{t}\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\left[v_{r}(t)a_{r}\\sigma^{\\prime}({\\boldsymbol w}_{r}(\\tau)^{T}{\\boldsymbol x})\\sigma^{\\prime}({\\boldsymbol w}_{r}(\\tau)^{T}{\\boldsymbol x}_{i})\\right](y_{i}-s i g(u_{i})){\\boldsymbol x}_{i}^{T}\\right]}}\\\\ {{\\displaystyle~~~~~\\cdot\\left[\\frac{1}{n}\\sum_{i=1}^{n}\\sum_{r=1}^{m}\\left[v_{r}(t)a_{r}\\sigma^{\\prime}({\\boldsymbol w}_{r}(t)^{T}{\\boldsymbol x})\\sigma^{\\prime}({\\boldsymbol w}_{r}(t)^{T}{\\boldsymbol x}_{i})\\right](y_{i}-s i g(u_{i})){\\boldsymbol x}_{i}\\right]},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Let $\\pmb{a}^{*}=\\sqrt{m}\\pmb{a}\\in\\{-1,1\\}^{m}$ and by the conclusion of lemma C.2, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\mathbb{P}_{W(0)}\\displaystyle\\left(\\left|\\sum_{r=1}^{m}v_{r}(t)a_{r}\\sigma^{\\prime}(w_{r}(t)^{T}x)\\sigma^{\\prime}(w_{r}(t)^{T}x_{i})-\\sum_{r=1}^{m}v_{r}(t)a_{r}\\alpha_{i}(t,x)\\right|\\geq\\epsilon\\right)}\\\\ {=\\mathbb{P}_{W(0)}\\left(\\left|\\frac{1}{\\sqrt{m}}\\displaystyle\\sum_{r=1}^{m}a_{r}^{*}v_{r}(t)\\sigma^{\\prime}(w_{r}(t)^{T}x)\\sigma^{\\prime}(w_{r}(t)^{T}x_{i})-a^{T}v(t)\\alpha_{i}(t;x)\\right|\\geq\\epsilon\\right)}\\\\ {\\leq2\\exp\\left\\{-\\displaystyle\\frac{m\\epsilon^{2}}{2M^{4}}\\right\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Equivalently, with probability at least $1-\\delta$ \uff0c ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\left|\\frac{1}{\\sqrt{m}}\\sum_{r=1}^{m}a_{r}^{*}v_{r}(t)\\sigma^{\\prime}(w_{r}(t)^{T}x)\\sigma^{\\prime}(w_{r}(t)^{T}x_{i})-a^{T}v(t)\\alpha_{i}(t;x)\\right|\\leq\\sqrt{\\frac{2M^{4}}{m}\\log\\frac{2}{\\delta}}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Hence, ", "text_level": 1, "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{D}^{\\vec{\\tau}}=\\eta\\frac{t}{\\tau-1}\\left[\\frac{1}{n}\\sum_{i=1}^{n}a^{\\tau}\\mathbf{v}(\\tau)\\alpha_{i}(\\tau,x)\\big(y_{i}-s i g(u_{i}(\\tau))\\big)x_{i}^{T}+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(\\tau)^{T}\\right]\\qquad\\quad(125)}\\\\ &{\\quad\\cdot\\bigg[\\frac{1}{n}\\sum_{i=1}^{n}a^{\\tau}\\mathbf{v}(t)\\alpha_{i}(t,x)\\big(y_{i}-s i g(u_{i}(t))\\big)x_{i}+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(t)\\bigg]\\qquad\\qquad\\quad(137)}\\\\ &{\\quad=\\eta\\frac{t}{\\tau-1}\\bigg[a^{T}v(\\tau)\\tilde{x}^{*}(\\tau)^{T}+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(\\tau)^{T}\\bigg]\\cdot\\bigg[a^{T}v(t)\\tilde{x}^{*}(t)+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(t)\\bigg]}\\\\ &{\\quad\\quad=\\eta\\frac{t}{\\tau-1}a^{T}v(\\tau)a^{T}v(t)\\tilde{x}^{*}(\\tau)^{T}\\tilde{x}^{*}(t)}\\\\ &{\\quad\\quad\\quad+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}(\\tau)^{T}\\tilde{x}^{*}(t)+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\\tilde{x}^{*}(\\tau)^{T}\\tilde{x}(t)+\\mathcal{O}\\bigg(\\frac{1}{m}\\log\\frac{2}{\\delta}\\bigg)\\tilde{x}(t)^{T}\\tilde{x}(t).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "We have that for at least $1-\\delta$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widehat{\\mathbb{\\langle D}}^{\\prime}=\\eta\\sum_{\\tau=1}^{t}\\pmb{a}^{T}\\pmb{v}(\\tau)\\pmb{a}^{T}\\pmb{v}(t)\\widetilde{\\pmb{x}}^{*}(\\tau)^{T}\\widetilde{\\pmb{x}}^{*}(t)+\\mathcal{O}\\bigg(\\sqrt{\\frac{1}{m}\\log\\frac{2}{\\delta}}\\bigg)\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "For $\\textcircled{2}$ ,we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\langle\\overline{{\\Omega}}|=\\left|a^{T}D(t)\\left(\\begin{array}{l}{a_{1}\\overline{{x}}_{1}^{T}(t)}\\\\ {\\vdots}\\\\ {a_{m}\\widetilde{x}_{m}^{T}(t)}\\end{array}\\right)W(0)^{T}D(t)a\\right|}\\\\ &{\\quad\\leq\\|a^{T}D(t)\\|_{2}^{2}\\|\\left(a_{1}W(0)\\widetilde{x}_{1}(t)\\quad\\cdots\\quad a_{m}W(0)\\widetilde{x}_{m}(t)\\right)\\|_{2}}\\\\ &{\\quad\\leq M^{2}\\big\\|\\left(a_{1}W(0)\\widetilde{x}_{1}(t)\\quad\\cdots\\quad a_{m}W(0)\\widetilde{x}_{m}(t)\\right)\\big\\|_{F}}\\\\ &{\\quad\\leq M^{2}\\sqrt{\\displaystyle\\sum_{r=1}^{m}a_{r}^{2}\\|W(0)\\widetilde{x}_{r}\\|_{2}^{2}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where ", "text_level": 1, "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\|W(0)\\widetilde{\\mathbf x}_{r}\\|_{2}^{2}=\\left\\|\\frac1n\\sum_{i=1}^{n}\\sigma^{\\prime}(w_{r}(0)^{T}x_{i})(y_{i}-s i g(u_{i}))W(0)x_{i}\\right\\|_{2}^{2}}\\\\ {\\le\\displaystyle\\frac1{n^{2}}\\displaystyle\\Bigg\\|\\left(\\sigma^{\\prime}(w_{r}(0)^{T}x_{1})(y_{1}-s i g(u_{1}))\\right)\\left\\|_{2}^{2}\\left\\|(W(0)x_{1}\\quad\\cdots\\quad W(0)x_{n})\\right\\|_{2}^{2}}\\\\ {\\le\\displaystyle\\frac1{n^{2}}\\displaystyle\\sum_{i=1}^{n}\\frac{\\sigma^{\\prime}(w_{r}(0)^{T}x_{n})(y_{n}-s i g(u_{i}))^{2}}{\\vartheta\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Similar to the proof of the linear case, and accords to Lemma B.2, we have that with probability at least $1-\\delta$ ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}\\|W(0)\\pmb{x}_{i}\\|_{2}^{2}}=\\frac{1}{m^{q}}+\\mathcal{O}\\bigg(\\sqrt{\\frac{8\\log(2/\\delta)}{m^{1+2q}n}}\\bigg).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, with high probability, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\textcircled{2}|\\leq M^{4}\\sqrt{\\displaystyle\\sum_{r=1}^{m}a_{r}^{2}\\frac{1}{n}\\sum_{i=1}^{n}\\|W(0)\\pmb{x}_{i}\\|_{2}^{2}}}\\\\ &{\\ \\ \\ \\ =M^{4}\\sqrt{\\displaystyle\\frac{1}{n}\\sum_{i=1}^{n}\\|W(0)\\pmb{x}_{i}\\|_{2}^{2}}}\\\\ &{\\ \\ \\ \\ =\\mathcal{O}\\bigg(\\displaystyle\\frac{1}{m^{q}}\\bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Follow the exact same procedure. With high probability, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle|\\widehat{\\mathbb{Q}}^{\\prime}|=\\Big|v^{T}(t)D(t)\\left(\\begin{array}{l}{a_{1}\\widetilde{x}_{1}^{T}(t)}\\\\ {\\vdots}\\\\ {a_{m}\\widetilde{x}_{m}^{T}(t)}\\end{array}\\right)W(0)^{T}D(t)v(t)\\Big|}\\\\ {\\displaystyle\\quad\\leq\\|v(t)^{T}D(t)\\|_{2}^{2}\\Big\\|\\left(a_{1}W(0)\\widetilde{x}_{1}(t)\\quad\\cdots\\quad a_{m}W(0)\\widetilde{x}_{m}(t)\\right)\\big\\|_{2}}\\\\ {\\displaystyle\\quad\\leq M^{2}\\sqrt{\\sum_{r=1}^{m}a_{r}^{2}\\|W(0)\\widetilde{x}_{r}\\|_{2}^{2}}}\\\\ {\\displaystyle=\\mathcal{O}\\Big(\\frac{1}{m^{q}}\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "We put all the information together, with high probability, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\dot{\\varrho}_{a,\\sigma\\circ W}(t)\\geq\\frac{\\varrho_{a,\\sigma\\circ W}(t)}{\\mathbb{E}_{x}\\|D(t)W(t)\\|_{2}^{2}}\\mathbb{E}_{x}\\bigg(\\langle\\overline{{\\mathbb{D}}}-\\langle\\overline{{\\mathbb{D}}}^{\\prime}+\\langle\\overline{{\\mathbb{2}}}-\\langle\\overline{{\\mathbb{2}}}^{\\prime}\\rangle}\\\\ &{\\qquad\\qquad\\geq\\frac{\\varrho_{a,\\sigma\\circ W}(t)}{\\mathbb{E}_{x}\\|D(t)W(t)\\|_{2}^{2}}\\bigg[\\eta\\sum_{\\tau=1}^{t}(1-a^{T}v(\\tau)a^{T}v(t))\\mathbb{E}_{x}\\big[\\widetilde{x}^{*}(\\tau)^{T}\\widetilde{x}^{*}(t)\\big]}\\\\ &{\\qquad\\qquad+\\operatorname*{max}\\bigg\\{\\mathcal{O}\\bigg(\\frac{1}{m^{\\frac{1}{2}}}\\bigg),\\mathcal{O}\\bigg(\\frac{1}{m^{q}}\\bigg)\\bigg\\}\\bigg]}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "image", "img_path": "jV6z08u7y0/tmp/36cd69268ed59e63c937fb11a9393364cfebf9c727fae5181ea1eb9a0274819c.jpg", "img_caption": ["Figure 5: Linear Correlation $\\&$ Relative Std. The linear correlation and the standard deviation over the mean are given for all MLPs with the initialization parameter $q=0.25$ "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "jV6z08u7y0/tmp/4a34112d1599585668796b75ddf775c3f9dfcc9c5e282d4e3327340baf87a723.jpg", "img_caption": ["Figure 6: The accumulation of co-correlation under different width. X-axis denotes the width of the neural network, and the line in different color shows the result under different setting of weight initialization. The lower plot is the result for linear model and the result for shallow ReLU is at the top. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "D Extra Experiment Results ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Figure 5 summarizes the statistics of linear correlation and relative variability, illustrating that co-correlation is the dominant factor in the decomposition outlined in Theorem 4.5. ", "page_idx": 23}, {"type": "text", "text": "Figure 6 shows the accumulated change in co-correlation during training across varying network widths. Each line, represented by different colours, corresponds to a unique weight initialization settingof $q$ . A clear inference from the figure is the positive relationship between the accumulated co-correlation change and network width under the same. $q$ -the wider the network, the greater the accumulated co-correlation change. Moreover, as we shift the weight initialization setting from $q=-0.15$ to $q=0.25$ , the accumulation of co-correlation also increases. These observations align with our Theorem 5.3 and 5.5, indicating that the increase in co-correlation is inversely proportional to $\\|W(t)\\|_{2}$ ", "page_idx": 23}, {"type": "text", "text": "E Algorithm ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We use the Power Iteration algorithm [10] along with Functorch [17] to compute co-correlation and other relevant statistics. This combination assists in approximating the $L_{2}$ -norm of the Jacobian for the layers under consideration. The algorithm to estimate the related statistics including cocorrelation are outlined in Algorithm 1. The power iteration used to obtain the $L_{2}$ -normofthe Jacobian is summarized in Algorithm 2. ", "page_idx": 24}, {"type": "text", "text": "Algorithm 1 Estimation of Related Statistics ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Input: Input dataset and modules $\\phi,\\varphi$ for the given blocks in sequential $\\{\\pmb{x}_{i},i=1,..,N\\}$   \nOutput: Approximation of co-correlations $\\widehat{\\varrho}_{\\phi,\\varphi}$ linear correlation $\\widehat{\\rho}_{\\phi,\\varphi}$ , mean $\\widehat{\\mu}_{\\phi},\\widehat{\\mu}_{\\varphi}$ and variance   \n$\\sigma_{\\phi},\\sigma_{\\varphi}$ of the Jacobian of the module w.r.t. their inputs   \n1: Computation of Jacobin of $\\|J_{\\varphi}(\\mathbf{\\boldsymbol{x}}_{i})\\|_{2},\\|J_{\\phi}(\\varphi(\\mathbf{\\boldsymbol{x}}_{i}))\\|_{2}$ for $\\{\\pmb{x}_{i},i\\in[n]\\}$ w.r.t. their inputs   \n2: $\\begin{array}{r l r l}{\\ddots}&{{}}&{\\quad\\quad\\quad}&{{}\\frac{1}{N}\\sum_{i=1}^{N}\\|J_{\\phi}(\\varphi(\\pmb{x}_{i}))\\|_{2}\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}}\\end{array}$ $\\begin{array}{r}{\\widehat{\\rho}_{\\phi,\\varphi}\\leftarrow\\frac{\\frac{+}{N}\\sum_{i=1}^{...}\\|J_{\\phi}(\\varphi(\\pmb{x}_{i}))\\|_{2}\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}}{\\left(\\frac{1}{N}\\sum_{i=1}^{N}\\|J_{\\phi}(\\varphi(\\pmb{x}_{i}))\\|_{2}^{2}\\right)^{\\frac{1}{2}}\\left(\\frac{1}{N}\\sum_{i=1}^{N}\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}^{2}\\right)^{\\frac{1}{2}}}}\\end{array}$   \n4: $\\begin{array}{r}{\\widehat{\\mu}_{\\phi}\\leftarrow\\frac{1}{N}\\sum_{i=1}^{N}\\|J_{\\phi}(\\varphi(\\pmb{\\varphi}(\\pmb{x}_{i}))\\|_{2}\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}}\\end{array}$   \n5: $\\begin{array}{r}{\\widehat{\\sigma}_{\\phi}\\leftarrow\\left[\\frac{1}{N-1}\\sum_{i=1}^{N}(\\|J_{\\phi}(\\varphi(\\pmb{x}_{i}))\\|_{2}\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}-\\hat{\\mu}_{\\phi})^{2}\\right]^{\\frac{1}{2}}}\\end{array}$ ", "page_idx": 24}, {"type": "text", "text": "Algorithm 2 Power Iteration Based Computation ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Input: Input dataset and module for the given sequential blocks $\\{\\pmb{x}_{i},i=1,..,N\\},\\phi,\\varphi$ Output: Approximation of co-correlations $\\varrho_{\\phi,\\varphi}$ linear correlation $\\rho_{\\phi,\\varphi}$ ,mean $\\mu_{\\phi},\\mu_{\\varphi}$ and variance $\\sigma_{\\phi},\\sigma_{\\varphi}$ of the Jacobian of the module w.r.t. their inputs ", "page_idx": 24}, {"type": "text", "text": "1: COMPUTATION OF $\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}$ FOR $\\{\\pmb{x}_{i},i\\in[n]\\}$   \n2: while $i\\leq N_{b}$ do   \n3: sample randomly $\\pmb{u}\\sim U([0,1])$   \n4: $\\pmb{u}\\leftarrow\\pmb{u}/\\lVert\\pmb{u}\\rVert_{2}$   \n5: generate jacobian-vector product function $j v p(\\cdot;{\\bf x}_{i})$   \n6: generating vector-jacobian product function $v j p(\\cdot;\\mathbf{x}_{i})$   \n7: $\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}^{o l d}\\leftarrow N o n e$   \n8: while $e r r\\geq10^{-6}$ do   \n9: $\\begin{array}{r l}&{v\\leftarrow j v p(u;\\mathbf{x}_{i})}\\\\ &{u\\leftarrow v j p(v;\\mathbf{x}_{i})}\\\\ &{u\\leftarrow u/||\\mathbf{u}||_{2}}\\\\ &{v\\leftarrow v/||v||_{2}}\\\\ &{||J_{\\varphi}(x_{i})||_{2}^{n e w}\\leftarrow\\frac{u/||\\mathbf{u}||_{2}}{v/||\\mathbf{v}||_{2}}}\\\\ &{\\mathrm{if}\\ ||J_{\\varphi}(x_{i})||_{2}^{||\\mathcal{I}^{l}|}\\neq{N o n e\\ t h\\mathbf{en}}}\\\\ &{\\qquad e r r=\\left|\\frac{\\|J_{\\varphi}(\\mathbf{x}_{i})\\|_{2}^{n e w}-\\|J_{\\varphi}(\\mathbf{x}_{i})\\|_{2}^{o l d}}{\\|J_{\\varphi}(\\mathbf{x}_{i})\\|_{2}^{|\\mathcal{I}^{l}d|}}\\right|}\\end{array}$   \n10:   \n11:   \n12:   \n13:   \n14:   \n15:   \n16: end if   \n17: $\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}^{o l d}=\\|J_{\\varphi}(\\pmb{x}_{i})\\|_{2}^{n e w}$   \n18: end while   \n19: end while ", "page_idx": 24}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: The abstract and introduction have clearly stated the claims made, including the contributions made in the paper. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 25}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Justification: A separate section \"Discussion and Limitations\" has been designed and can be seen in the end of this paper. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should refect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should refect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 25}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The complete proofs are provided in the appendix. Theorems and Lemmas are properly referenced in this paper. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 26}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The algorithm and detailed experiment settings are provided ", "page_idx": 26}, {"type": "text", "text": "Guidelines: The code is provided in the supplemental material ", "page_idx": 26}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a)  If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 26}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: The code is uploaded in github, including detailed README file. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 27}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: All details can be checked in Experiment section. Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 27}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Justification: The detailed methods can be found in Experiment section. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The paper introduces the configuration of the computer in Experiment section. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 28}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: We have read the NeurIPs Code of Ethics and confirm that the research conforms in every respect. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 28}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: There is no societal impact of the work performed. This is a theoretical paper to understand existing ML methods. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: The paper poses no such risks. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 29}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Justification: We have cited the original paper that produced the code package or dataset properly. ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 29}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 30}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 30}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 30}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 30}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 30}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 30}]