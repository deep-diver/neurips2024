[{"figure_path": "f70e6YYFHF/figures/figures_1_1.jpg", "caption": "Figure 1: (Left) Reversal curse from training a model on sentences with Paris before France. (Right) Left-to-right objective does not learn how to predict early tokens from later ones even if the information content is the same. The model overfits to a specific factorization of the joint distribution over tokens, and is unable to answer questions that require reasoning about a different factorization.", "description": "This figure illustrates the concept of the reversal curse and how it relates to the factorization curse. On the left, it shows how training a model on sentences where \"Paris\" always precedes \"France\" leads to the model's inability to answer a question about France's capital when phrased differently.  On the right, a visual representation clarifies how the left-to-right training objective prevents the model from learning to predict earlier tokens based on later tokens, even if the semantic meaning remains the same.  This highlights how models become overly reliant on a particular sequence of tokens and fail to generalize to different factorizations of the information.", "section": "2 The Factorization Curse"}, {"figure_path": "f70e6YYFHF/figures/figures_6_1.jpg", "caption": "Figure 3: An example passage with a forward relation triple. The forward question queries the tail, backward queries the head. WikiReversal is a collection of passages and forward/backward QAs.", "description": "This figure illustrates the WikiReversal dataset used in the paper.  It shows an example of a Wikipedia passage containing information about Paris being the capital of France, represented as a knowledge graph with nodes for \"Paris\", \"France\", and the relation \"Capital Of\".  Two types of questions are shown: a \"forward\" question that follows the direction of the triple (e.g., \"Paris is the capital of which country?\"), and a \"backward\" question that reverses this direction (e.g., \"What is the capital of France?\").  The WikiReversal dataset consists of many such passages and corresponding question-answer pairs designed to test the model's ability to retrieve information regardless of the order it was presented during training.", "section": "3.2 Wikipedia Knowledge Graph Reversal"}, {"figure_path": "f70e6YYFHF/figures/figures_7_1.jpg", "caption": "Figure 4: In panel (a) we compare MLM with varying masking ratios to MLM-U. In panels (b) and (c) we visualize the two main principal components of representations learned via AR versus MLM-U.", "description": "This figure compares the performance of MLM with fixed masking rates (15%, 40%, 85%) against MLM-U, a variation that uses uniformly sampled masking rates.  Panel (a) shows that MLM with fixed masking rates is inconsistent, while MLM-U performs better. Panels (b) and (c) use PCA to visualize the representations learned by AR (autoregressive) and MLM-U models respectively. The visualizations reveal that MLM-U learns more structured entities than AR, suggesting improved knowledge representation.", "section": "3 Experiments"}, {"figure_path": "f70e6YYFHF/figures/figures_7_2.jpg", "caption": "Figure 5: Star Graph Task: Illustration and Performance Comparison. The illustration shows the \"Clever Hans\" failure mode with teacher-forced AR ((Bachmann & Nagarajan, 2024) adapted).", "description": "This figure illustrates a simple path-finding task used to evaluate planning capabilities of language models.  The task involves predicting a sequence of nodes (2,6,7) to reach a goal node (7) starting from a start node (4). The figure highlights the \"Clever Hans\" failure mode, where a model trained with autoregressive next-token prediction may simply predict each node based on the previously predicted node, without needing true planning abilities.", "section": "4 On the Importance of Future Predictions for Planning"}, {"figure_path": "f70e6YYFHF/figures/figures_13_1.jpg", "caption": "Figure 6: AR w/reverse cannot predict (left-to-right) entities that appeared on the left during training as it only learned to complete them from right to left. The two sequences in the bottom right indicate that backward retrieval is roughly equivalent to refactorizing the conditionals such that the entity of interest is predicted last conditioned on everything else. This is only approximate because answering a backward QA might require adding new tokens like \"The answer to the question is ...\" but we make a weak assumption that such differences are generally irrelevant compared to the entities and relations of interest.", "description": "This figure demonstrates why simply reversing the training sequences in autoregressive models (AR w/reverse) does not solve the reversal curse.  The left side shows that while the model can successfully predict tokens in a reversed sequence when the entity is already provided, it fails when asked a question that necessitates reasoning about the entity in the opposite direction. The right side illustrates that true backward reasoning requires the model to be able to predict the earlier tokens based on the later context which AR models are not trained to do.  It highlights a key limitation of solely relying on reversing the training order and the need for a fundamentally different approach to learn factorization-agnostic models.", "section": "A Why does AR w/reverse sequences fail?"}, {"figure_path": "f70e6YYFHF/figures/figures_14_1.jpg", "caption": "Figure 7: Performance of MLM-U versus AR in the two-token setting. We train both MLM-U and AR in a two-token variant of the retrieval task from from Section 3.1. We find MLM-U reaches 100% forward and backward whereas AR struggles to learn the backwards setting.", "description": "The figure shows the performance comparison of MLM-U and AR models on a simplified retrieval task with only two tokens.  MLM-U achieves perfect accuracy (100%) in both forward and backward directions, while the AR model struggles significantly with the backward direction. This highlights the advantage of the MLM-U objective in overcoming the reversal curse and shows that it can learn to retrieve information regardless of the order in which it was presented during training.", "section": "3.1 Controlled Experiments in Factorization-Agnostic Training"}, {"figure_path": "f70e6YYFHF/figures/figures_19_1.jpg", "caption": "Figure 8: Accuracy in Forward/Backward Questions on the Bios dataset (left) and the Wikireversal dataset (right)", "description": "This figure shows the accuracy curves for training with MLM-U for both Bios and WikiReversal datasets. The left panel shows that the model gradually learns both forward and backward questions throughout training. The backward accuracy shows an upward trend even after 20k optimization steps. The right panel shows a similar trend in the delayed generalization in WikiReversal for both forward and backward questions after 300k optimization steps.  These results demonstrate that the MLM-U objective is more challenging and exhibits delayed generalization relative to standard next-token prediction training.", "section": "F Delayed Generalization in Language Modeling"}, {"figure_path": "f70e6YYFHF/figures/figures_20_1.jpg", "caption": "Figure 7: Performance of MLM-U versus AR in the two-token setting. We train both MLM-U and AR in a two-token variant of the retrieval task from from Section 3.1. We find MLM-U reaches 100% forward and backward whereas AR struggles to learn the backwards setting.", "description": "This figure compares the performance of MLM-U and AR models on a simplified retrieval task with only two tokens.  It shows that MLM-U achieves perfect accuracy in both forward and backward retrieval scenarios, while AR struggles to learn the backward direction. This highlights the superior ability of MLM-U to handle different factorizations of the data, addressing the factorization curse.", "section": "3.1 Controlled Experiments in Factorization-Agnostic Training"}]