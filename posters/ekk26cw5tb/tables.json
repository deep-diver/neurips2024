[{"figure_path": "ekK26cW5TB/tables/tables_8_1.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents a comparison of the performance of different semantic segmentation methods on three benchmark datasets (Cityscapes, ADE20K, and COCO-Stuff 164K).  The results are presented in terms of mean Intersection over Union (mIoU), broken down by overall performance, and performance on head, middle, and tail classes. The best-performing method for each metric is highlighted in bold, and the second-best is underlined.  This allows for a direct comparison of the effectiveness of various methods in handling long-tailed distributions in semantic segmentation.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_8_2.jpg", "caption": "Table 2: Results of AUCSeg using different backbones in terms of mIoU (%).", "description": "This table presents the performance comparison of AUCSeg using four different backbones (DeepLabV3+, EMANet, OCRNet, and ISANet) on the semantic segmentation task.  For each backbone, the table shows the overall mean Intersection over Union (mIoU) and the mIoU specifically for the tail classes.  The \"X\" indicates that the backbone was used without AUCSeg, while the \"\u2713\" indicates that AUCSeg was applied.  This highlights the improvement achieved by integrating AUCSeg with various state-of-the-art backbones.", "section": "5.3 Backbone Extension"}, {"figure_path": "ekK26cW5TB/tables/tables_9_1.jpg", "caption": "Table 3: Ablation study on the effectiveness of AUC Optimization and T-Memory Bank (TMB) in terms of mIoU (%).", "description": "This table presents the results of an ablation study to evaluate the individual and combined effects of AUC optimization and the T-Memory Bank on the performance of the AUCSeg model.  The mIoU (mean Intersection over Union) metric is used to assess the overall and tail class performance.  The table shows that both AUC optimization and the T-Memory Bank contribute to improved performance, especially in the tail classes.", "section": "5.4 Ablation studies"}, {"figure_path": "ekK26cW5TB/tables/tables_17_1.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents the quantitative performance comparison of AUCSeg against 13 state-of-the-art semantic segmentation methods and 6 long-tail approaches on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K.  The evaluation metric used is mean Intersection over Union (mIoU). The results are broken down by overall performance, as well as performance on head, middle, and tail classes.  The best-performing method and the second-best method for each category are highlighted.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_27_1.jpg", "caption": "Table 5: The number of images containing pixels from each class in the Cityscapes. Class ID represents the class number in the original dataset.", "description": "This table shows the number of images in the Cityscapes dataset that contain at least one pixel belonging to each of the 19 classes.  It provides a visual representation of class imbalance, showing how many images have pixels from each class.  Classes with lower numbers indicate a higher frequency of occurrence in the dataset, while those with higher numbers are less frequent.", "section": "Additional Experimental Results"}, {"figure_path": "ekK26cW5TB/tables/tables_27_2.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents a comparison of the performance of different semantic segmentation methods on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K.  The metrics used is mean Intersection over Union (mIoU), which is broken down into overall performance, and performance on head, middle and tail classes. The best and second-best performing methods are highlighted for each dataset and class.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_27_3.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents the quantitative results of the proposed AUCSeg model and other state-of-the-art models on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K. The evaluation metric is mean Intersection over Union (mIoU), calculated for overall performance and broken down into head, middle, and tail classes.  The best and second-best performing models are highlighted.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_30_1.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents the quantitative results of the proposed AUCSeg method and other state-of-the-art semantic segmentation methods on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K. The evaluation metric used is the mean Intersection over Union (mIoU).  The results are broken down by overall performance, as well as performance on head, middle, and tail classes.  The best-performing method for each metric is highlighted in bold, with the second-best method underlined.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_30_2.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents the quantitative results of the proposed AUCSeg method and other state-of-the-art semantic segmentation methods on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K.  The results are shown in terms of mean Intersection over Union (mIoU), a common metric for evaluating semantic segmentation performance. The table breaks down the mIoU scores into overall performance, and performance on head, middle, and tail classes to highlight the impact of long-tailed distribution. The best-performing method for each metric is highlighted in bold, and the second-best is underlined.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_30_3.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents a comparison of the mean Intersection over Union (mIoU) scores achieved by various semantic segmentation methods on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K.  The results are broken down by overall performance, as well as performance on head, middle, and tail classes. The best-performing method and the second-best method in each category are highlighted.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_32_1.jpg", "caption": "Table 11: The comparison of imbalance ratio and tail classes performance improvements on ADE20K, Cityscapes, and COCO-Stuff 164K.", "description": "This table compares the imbalance ratio (rm) across three datasets (ADE20K, Cityscapes, and COCO-Stuff 164K) and shows the performance improvement of AUCSeg on tail classes compared to the second-best performing method.  The imbalance ratio (rm) is calculated using a formula shown in the paper and represents the degree of class imbalance. The table demonstrates a correlation between the imbalance ratio and the improvement achieved by AUCSeg, suggesting better performance gains on more imbalanced datasets.", "section": "G.2 Performance Differences Across Different Datasets"}, {"figure_path": "ekK26cW5TB/tables/tables_34_1.jpg", "caption": "Table 12: Results of AUCSeg on different model sizes of SegNeXt in terms of mIoU (%).", "description": "This table presents the results of the AUCSeg model using different sizes (Tiny, Small, Base, Large) of the SegNeXt backbone.  It shows the overall and tail class mIoU for each backbone size with and without AUCSeg, demonstrating the performance improvement of AUCSeg across all sizes.", "section": "G.4 Backbone Extension of Different Model Sizes"}, {"figure_path": "ekK26cW5TB/tables/tables_34_2.jpg", "caption": "Table 13: Experimental results of AUCSeg in the salient object detection.", "description": "This table shows the experimental results of AUCSeg on three benchmark datasets (ECSSD, HKU-IS, and PASCAL-S) for salient object detection.  The baseline method used is SI-SOD-EDN.  The metrics used for evaluation are MAE (Mean Absolute Error), F<sub>m</sub> (F-measure), and E<sub>m</sub> (E-measure). Lower MAE indicates better performance. Higher F<sub>m</sub> and E<sub>m</sub> values indicate better performance. The table demonstrates the improvement achieved by AUCSeg over the baseline SI-SOD-EDN on each dataset for each metric.", "section": "G.5 Backbone Extension of Different Pixel-level Long-tail Problems"}, {"figure_path": "ekK26cW5TB/tables/tables_35_1.jpg", "caption": "Table 14: Space resource consumption required for training properly. TMB is the abbreviation of T-Memory Bank.", "description": "This table shows the GPU memory usage during training with different configurations. The first row shows the baseline without AUC and TMB, which requires 13.29G of memory.  The second row demonstrates that using AUC alone drastically increases memory usage to 72.90G, due to the larger batch size required for convergence. Finally, the third row illustrates that by using both AUC and TMB, the memory consumption is reduced back down to 15.45G, showcasing the memory efficiency of the T-Memory Bank.", "section": "G.6 Spatial Resource Consumption"}, {"figure_path": "ekK26cW5TB/tables/tables_35_2.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents a quantitative comparison of the proposed AUCSeg method against 13 state-of-the-art semantic segmentation methods and 6 long-tail approaches across three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K.  The evaluation metric is mean Intersection over Union (mIoU). The results are broken down into overall performance, as well as performance on head, middle, and tail classes.  The best and second-best performing methods are highlighted.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_35_3.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents a comparison of the performance of the proposed AUCSeg method against other state-of-the-art semantic segmentation methods on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K.  The evaluation metric used is mean Intersection over Union (mIoU). The table shows the overall mIoU, as well as the mIoU for head, middle, and tail classes. The best-performing method for each metric is highlighted in bold, and the second-best is underlined.  This allows for a direct comparison of the effectiveness of different methods in handling long-tailed distributions in pixel-level semantic segmentation.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_36_1.jpg", "caption": "Table 17: The average number of pixels from head and tail classes per image.", "description": "This table presents a quantitative comparison of the average number of pixels belonging to head and tail classes per image across three different datasets: ADE20K, Cityscapes, and COCO-Stuff 164K.  The data highlights the class imbalance present in these datasets, showcasing a significantly larger number of head class pixels compared to tail class pixels.", "section": "G.8 Results of the Comparison Between PMB and TMB"}, {"figure_path": "ekK26cW5TB/tables/tables_36_2.jpg", "caption": "Table 18: The performance differences between PMB and TMB in terms of mIoU (%).", "description": "This table compares the performance of the proposed Tail-class Memory Bank (TMB) against a Pixel-level Memory Bank (PMB) in terms of mean Intersection over Union (mIoU) across three benchmark datasets (ADE20K, Cityscapes, and COCO-Stuff 164K).  The PMB stores all pixel classes, while the TMB focuses on storing only tail class pixels. The results demonstrate the effectiveness of TMB compared to PMB, highlighting its efficiency in terms of memory usage without significant performance loss.", "section": "G.8 Results of the Comparison Between PMB and TMB"}, {"figure_path": "ekK26cW5TB/tables/tables_37_1.jpg", "caption": "Table 19: Results of different memory bank update Strategies on ADE20K in terms of mIoU (%).", "description": "This table presents the ablation study on different memory bank update strategies. The strategies compared are random sampling, FIFO, LIFO, and PU. The results are evaluated in terms of mIoU across overall, head, middle, and tail classes on the ADE20K dataset. The random update strategy shows the best results overall but is surpassed by the FIFO strategy on tail classes.", "section": "G.9 Results of Different Memory Bank Update Strategies"}, {"figure_path": "ekK26cW5TB/tables/tables_37_2.jpg", "caption": "Table 21: Ablation study on Sample Ratio (Rs) in terms of mIoU (%).", "description": "This table presents the ablation study on the impact of the sample ratio (Rs) on the performance of the proposed AUCSeg method. The sample ratio is a hyperparameter that controls the number of tail classes selected from the T-Memory bank for augmentation.  The table shows the overall and tail mIoU achieved for different Rs values on the ADE20K dataset. The best performance is observed at Rs=0.05.", "section": "G.10 Detailed Results of the Ablation Study on Hyper-Parameters"}, {"figure_path": "ekK26cW5TB/tables/tables_37_3.jpg", "caption": "Table 20: Ablation study on Memory Size (SM) in terms of mIoU (%).", "description": "This table presents the ablation study results on the impact of the memory size (SM) on the performance of the proposed AUCSeg model. The mIoU (mean Intersection over Union) metric is used to evaluate the overall and tail class segmentation performance. The results are presented for different values of SM (1, 3, 5, 8, 10, and 20), showing how the memory size affects the model's ability to learn and generalize, especially for tail classes.", "section": "G.10 Detailed Results of the Ablation Study on Hyper-Parameters"}, {"figure_path": "ekK26cW5TB/tables/tables_37_4.jpg", "caption": "Table 12: Results of AUCSeg on different model sizes of SegNeXt in terms of mIoU (%).", "description": "This table presents the results of the AUCSeg method using different model sizes (tiny, small, base, and large) of the SegNeXt backbone network.  The mIoU (mean Intersection over Union) metric is used to evaluate the performance on overall semantic segmentation and specifically on tail classes.  It demonstrates the effectiveness of AUCSeg across various model sizes.", "section": "G.4 Backbone Extension of Different Model Sizes"}, {"figure_path": "ekK26cW5TB/tables/tables_37_5.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents a comparison of the performance of different semantic segmentation methods on three benchmark datasets: Cityscapes, ADE20K, and COCO-Stuff 164K.  The results are measured using mean Intersection over Union (mIoU) and are broken down into overall performance, as well as performance on head, middle, and tail classes. The best and second-best performing methods are highlighted for each category.", "section": "5.2 Overall Performance"}, {"figure_path": "ekK26cW5TB/tables/tables_38_1.jpg", "caption": "Table 1: Quantitative results on Cityscapes, ADE20K and COCO-Stuff 164K val set in terms of mIoU (%). The champion and the runner-up are highlighted in bold and underline.", "description": "This table presents a comparison of the model's performance (measured by mean Intersection over Union or mIoU) on three benchmark datasets (Cityscapes, ADE20K, and COCO-Stuff 164K)  across different categories (Overall, Head, Middle, and Tail).  The results show the mIoU for various semantic segmentation methods, highlighting the best-performing (champion) and second-best-performing (runner-up) models for each dataset and category.", "section": "5.2 Overall Performance"}]