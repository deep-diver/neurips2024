[{"figure_path": "iC869BBmc5/figures/figures_0_1.jpg", "caption": "Figure 1: By decomposing a difficult task into easy subtasks and then progressively performing them (upper part), our ProEdit achieves high-quality 3D editing results with bright colors and detailed textures along with introducing new controllability of the editing aggressivity (lower part). More results are provided on our project page.", "description": "This figure demonstrates the core idea of ProEdit: decomposing complex 3D scene editing tasks into smaller, easier subtasks that are processed sequentially. The top row shows an example of this process with three different tasks, each broken down into subtasks with increasing levels of editing 'aggressivity'. The bottom row shows the final results for each task at different levels of aggressivity. The overall result is high-quality 3D scene editing with bright colors and detailed textures, as well as increased control over the degree of editing applied.", "section": "Abstract"}, {"figure_path": "iC869BBmc5/figures/figures_3_1.jpg", "caption": "Figure 2: Our ProEdit framework features three major designs: an interpolation-based subtask formulation (Sec. 3.1), a difficulty-aware subtask scheduler for subtask decomposition (Sec. 3.2), and an adaptive 3DGS tailored for progressive scene editing through a dual-GPU pipeline (Sec. 3.3). For an editing task, we first decompose it into interpolation-based subtasks to schedule the editing process with the subtask scheduler, and then progressively perform the subtasks with adaptive 3DGS.", "description": "This figure illustrates the ProEdit framework's three main components: subtask formulation, subtask scheduling, and adaptive 3DGS for progressive scene editing.  It shows how a full editing task is decomposed into smaller subtasks, scheduled according to their difficulty, and processed using 3DGS on a dual-GPU system. The figure highlights the iterative nature of the process and how the intermediate results of each subtask contribute to the final edited scene.", "section": "3 ProEdit: Methodology"}, {"figure_path": "iC869BBmc5/figures/figures_6_1.jpg", "caption": "Figure 3: In the comparative experiments on the Fangzhou and Face scenes, our ProEdit achieves high-quality editing, with strong instruction fidelity, clear textures, and precise shapes across both levels of aggressivity controlled by subtask scheduling. The \"medium aggressivity\" editing results are obtained from an intermediate subtask. The editing results of the baselines are sourced from visualizations in their respective papers.", "description": "This figure compares the results of ProEdit with several other state-of-the-art methods on two scenes.  The top row shows the original images, and the following rows show the edited results produced by different methods for several different editing tasks.  ProEdit produces higher quality results across different levels of editing \"aggressiveness\", which is controlled by the number of subtasks.", "section": "4 Experiments"}, {"figure_path": "iC869BBmc5/figures/figures_7_1.jpg", "caption": "Figure 4: In the comparative experiments on the ScanNet++ scenes, our simple ProEdit also achieves high-quality editing that is comparable to, and in some cases even outperforms, the sophisticated baseline ConsistDreamer [9]. All visualizations are sourced from ConsistDreamer's paper.", "description": "This figure compares the results of ProEdit with ConsistDreamer and EN2N on three different indoor scenes from the ScanNet++ dataset.  Each scene is subjected to four different editing instructions, resulting in edits with varying levels of visual fidelity. The figure highlights ProEdit's ability to produce results comparable or superior to more complex baselines.", "section": "4 Experiments"}, {"figure_path": "iC869BBmc5/figures/figures_7_2.jpg", "caption": "Figure 5: In the comparative experiments across various outdoor scenes, our ProEdit not only achieves high-quality editing that surpasses the baselines, but also enables aggressivity controls for a range of scenes and tasks.", "description": "This figure compares the results of ProEdit with IN2N and ConsistDreamer on two outdoor scenes.  The top row shows the original scenes. The following rows show the results of different methods, including ProEdit at both medium and high levels of aggressivity, demonstrating improved results and the ability to control the level of editing. The caption highlights that ProEdit outperforms the baselines and provides control over editing aggressivity.", "section": "4.2 Experimental Results and Analysis"}, {"figure_path": "iC869BBmc5/figures/figures_8_1.jpg", "caption": "Figure 6: Ablation study of our \u201cno subtask decomposition\u201d variant shows that removing subtask decomposition results in unreasonable geometry, particularly near the cheek area (indicated by the bounding boxes). This validates the importance of subtask decomposition in achieving high-quality editing in our framework. \u201cModeled depth map\u201d is the depths modeled by the scene representation.", "description": "This figure shows an ablation study comparing the results of ProEdit with and without subtask decomposition.  The top row shows the original image and the results when using ProEdit with 8 subtasks (progressive editing). The bottom row displays the same editing task performed with only 1 subtask. The images showcase clear geometric issues such as unrealistic cheek shapes (highlighted with bounding boxes) when the subtask decomposition is removed, highlighting the importance of the method's progressive refinement strategy.", "section": "3 ProEdit: Methodology"}, {"figure_path": "iC869BBmc5/figures/figures_13_1.jpg", "caption": "Figure A: The visualization of per-view edited results (where each view is edited separately with IP2P [4]) shows that with the increment of the subtask ratio r, the multi-view inconsistency also increases, leading to greater editing difficulty.", "description": "This figure visualizes the results of editing each view of a scene separately using the IP2P model, for different values of the subtask ratio *r*. As *r* increases, the inconsistency between views increases, making the overall editing task more difficult. This demonstrates the challenge of achieving high-quality 3D scene editing when dealing with a large feasible output space.", "section": "A Editing Difficulty w.r.t. Subtask Ratio r"}, {"figure_path": "iC869BBmc5/figures/figures_14_1.jpg", "caption": "Figure B: The additional subtask r<sub>n</sub> does not significantly change the overall appearance, but it brings slight improvements on geometric structure.", "description": "This figure shows a comparison of the results before and after applying the additional subtask r<sub>n</sub>. The depth maps, modeled by 3DGS, are segmented to emphasize the foreground.  The before and after images are very similar in overall appearance, however, the refined version shows more precise geometry and detail near the ear. This demonstrates that while subtask r<sub>n</sub> does not significantly alter the overall look, it does provide minor improvements and refinements to the geometric structure of the edited results.", "section": "3.3 Adaptive 3DGS Tailored for Progression"}, {"figure_path": "iC869BBmc5/figures/figures_15_1.jpg", "caption": "Figure C: The edited 3D scene at each decomposed subtask aligns well with the corresponding interpolated tasks edited by IP2P [4] for the image.", "description": "This figure shows a comparison between the results of editing a 3D scene using the proposed ProEdit method and the results of editing a 2D image using the IP2P method. The 3D scene is decomposed into several subtasks, each corresponding to a different level of editing intensity. The results of editing the 3D scene using each subtask are shown in the bottom row, while the results of editing the 2D image using the IP2P method are shown in the top row. As can be seen, the results of editing the 3D scene using each subtask are very similar to the results of editing the 2D image using the IP2P method. This suggests that the proposed ProEdit method is able to effectively decompose the editing task into several subtasks and that the results of editing the 3D scene using each subtask are consistent with the results of editing the 2D image using the IP2P method. This demonstrates the effectiveness of the proposed subtask decomposition strategy for 3D scene editing.", "section": "F Semantic Meaning of Subtasks and Alignment with IP2P Editing"}]