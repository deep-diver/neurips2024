{"importance": "This paper challenges the prevailing wisdom in vision transformer (ViT) pre-training, demonstrating that **transferring only the attention patterns from a pre-trained model is surprisingly effective** for downstream tasks.  This opens exciting avenues for more efficient and potentially secure transfer learning strategies, reducing reliance on transferring all the heavy weights and potentially mitigating security risks.", "summary": "Vision Transformers achieve surprisingly high accuracy by transferring only pre-training attention maps, challenging the conventional belief that feature learning is crucial.", "takeaways": ["Transferring only attention patterns from pre-trained ViTs to student models is sufficient to achieve comparable downstream performance to full fine-tuning.", "Pre-trained attention maps effectively guide information flow, enabling student models to learn high-quality features from scratch.", "Attention transfer offers a more practical and potentially secure alternative to traditional fine-tuning in vision transformers, especially when faced with distribution shift or security considerations."], "tldr": "Pre-training large vision models is computationally expensive and resource-intensive, commonly believed to be essential for achieving high accuracy on downstream tasks. This paper investigates the actual necessity of pre-trained features in vision transformers (ViTs). It challenges the conventional understanding that the effectiveness of pre-training lies solely in learning useful feature representations. \nThe researchers propose a novel method called \"attention transfer.\" Instead of transferring all model weights during fine-tuning, they transfer only the attention patterns (information flow) from a pre-trained teacher ViT to a student ViT.  Their experiments show that even without feature transfer, this method allows the student model to achieve comparable performance to full fine-tuning.  This approach offers a potentially more efficient and secure way of using pre-trained ViTs. The study also analyzes the sufficiency of attention maps under various conditions, including distribution shift settings where attention transfer underperforms fine-tuning.", "affiliation": "Carnegie Mellon University", "categories": {"main_category": "Computer Vision", "sub_category": "Image Classification"}, "podcast_path": "5DwqmoCE1N/podcast.wav"}