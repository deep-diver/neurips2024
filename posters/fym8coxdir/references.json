{"references": [{"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-18", "reason": "This paper introduces CLIP, the core model that the current research builds upon and analyzes."}, {"fullname_first_author": "Joanna Materzynska", "paper_title": "Disentangling visual and written concepts in CLIP", "publication_date": "2022-06-20", "reason": "This paper is highly relevant as it directly addresses the problem of disentangling visual and textual features within CLIP, a key focus of the current research."}, {"fullname_first_author": "Gabriel Goh", "paper_title": "Multimodal neurons in artificial neural networks", "publication_date": "2021-07-18", "reason": "This paper is cited for its insightful analysis of CLIP's struggles with text-visual images, which is a central issue the current research aims to address."}, {"fullname_first_author": "Aditya Ramesh", "paper_title": "Hierarchical text-conditional image generation with CLIP latents", "publication_date": "2022-07-18", "reason": "This paper is important for its contribution to Stable Diffusion which is employed to generate images for validation of the disentanglement process."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-06-20", "reason": "This paper is critical as it introduces the Stable Diffusion model used to demonstrate the quality of the disentanglement visually."}]}