{"references": [{"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This paper is foundational for chain-of-thought prompting, a key concept behind the SKETCHPAD framework, demonstrating the ability of large language models to perform few-shot learning."}, {"fullname_first_author": "Jason Wei", "paper_title": "Chain-of-thought prompting elicits reasoning in large language models", "publication_date": "2022-12-01", "reason": "This paper introduces chain-of-thought prompting, a core technique used in SKETCHPAD to guide multimodal reasoning by generating intermediate steps in natural language."}, {"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment Anything", "publication_date": "2023-12-01", "reason": "This paper introduces a powerful segmentation model that is a key component of SKETCHPAD, facilitating the generation of visual sketches and visual reasoning by the LLM."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "Llama 2: Open foundation and fine-tuned chat models", "publication_date": "2023-07-18", "reason": "This paper introduces Llama 2, a strong multimodal language model that serves as the foundation of the SKETCHPAD framework, providing the basic capabilities for textual and visual processing."}, {"fullname_first_author": "Penghao Wu", "paper_title": "V*: Guided visual search as a core mechanism in multimodal LLMs", "publication_date": "2023-12-01", "reason": "This paper highlights the limitations of existing multimodal LLMs in visual search tasks, motivating the development of SKETCHPAD to enhance their visual reasoning capabilities."}]}