{"references": [{"fullname_first_author": "J. Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper introduces denoising diffusion probabilistic models (DDPMs), a class of generative models that are central to the research presented in the current paper."}, {"fullname_first_author": "A. Q. Nichol", "paper_title": "Diffusion models beat gans on image synthesis", "publication_date": "2021-12-01", "reason": "This paper demonstrates the superior performance of diffusion models over GANs on image synthesis tasks, which provided a basis for the current research."}, {"fullname_first_author": "Y. Song", "paper_title": "Score-based generative modeling through stochastic differential equations", "publication_date": "2020-11-18", "reason": "This paper provides a unified framework for score-based generative modeling using SDEs, which is relevant to the theoretical underpinnings of the current study."}, {"fullname_first_author": "Q. Bertrand", "paper_title": "On the stability of iterative retraining of generative models on their own data", "publication_date": "2023-10-26", "reason": "This paper investigates the stability of iterative retraining of generative models, addressing a related challenge in generative model training that is relevant to the current paper."}, {"fullname_first_author": "S. Alemohammad", "paper_title": "Self-consuming generative models go mad", "publication_date": "2023-07-05", "reason": "This paper explores another failure mode in generative models, which is relevant to the concept of model collapse and its relation to hallucination in diffusion models."}]}