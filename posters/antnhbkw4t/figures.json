[{"figure_path": "aNTnHBkw4T/figures/figures_1_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure shows the results of training a diffusion model on two datasets: a simple shapes dataset and a hand dataset. The top part shows that the model generates hallucinated images containing combinations of shapes that were not present in the training data.  The bottom part demonstrates that the model trained on hand images can produce images with extra or missing fingers. The red boxes highlight examples of hallucinations in both datasets.", "section": "1.1 Hallucination in Diffusion Models"}, {"figure_path": "aNTnHBkw4T/figures/figures_4_1.jpg", "caption": "Figure 2: Mode Interpolation in 1D GAUSSIAN. The red curve indicates the PDF of the true data distribution q(x), which is a mixture of 3 Gaussians (notice that the y-axis is in log-scale). In blue, we show a density histogram of the samples generated by a DDPM trained on varying number of samples from the true data distribution. For each histogram, we sampled 100 million examples from the diffusion model to observe the interpolated distribution. (a,b) show how the density of samples generated in the interpolated region reduces with an increase in the number of samples from the real distribution (used for training the DDPM). (c,d) show the impact of moving one of the modes (originally at \u03bc = 3) to \u03bc = 4. We see how the density of samples generated in the region between distant (but neighboring) modes is significantly lesser than that between nearby modes.", "description": "This figure shows the results of training a denoising diffusion probabilistic model (DDPM) on a 1D Gaussian mixture distribution.  It demonstrates the phenomenon of mode interpolation, where the model generates samples in regions between the modes of the true distribution, even though these regions have negligible probability mass. The plots show density histograms of samples generated by the DDPM for varying numbers of training samples and different mode separations. As expected, increased training samples reduce the number of samples in the interpolated regions. Similarly, moving modes further apart also decreases the number of interpolated samples.", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_5_1.jpg", "caption": "Figure 3: Mode Interpolation in 2D GAUSSIAN. The dataset consists of a mixture of 25 Gaussians arranged in a square grid, with a training set containing 100,000 samples. (a,b) The blue points represent samples generated by a DDPM, with visible density between the nearest modes of the original Gaussian mixture (in orange). These interpolated samples have near-zero probability in the original distribution. (c,d) We trained a DDPM on a rotated version of the dataset where the modes form a diamond shape. In this configuration, we see no interpolation along the x-axis, illustrating that diffusion models interpolate between nearest modes.", "description": "This figure shows the mode interpolation phenomenon in a 2D Gaussian mixture dataset.  Subfigures (a) and (b) demonstrate interpolation between nearby Gaussian modes in a square grid arrangement, where the model generates samples in regions with near-zero probability in the original data distribution. (c) and (d) show that this interpolation is localized and does not occur when the modes are rearranged into a diamond shape, indicating that the interpolation is between nearest neighbors.", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_5_2.jpg", "caption": "Figure 4: Explaining Mode Interpolation via Learned Score Function. The left panel shows the ground truth score function for a mixture of Gaussians across various timesteps, while the right panel illustrates the score function learned by the neural network. While the true score function exhibits sharp jumps that separate distinct modes (particularly in the initial time steps), the neural network approximates a smoother version.", "description": "This figure compares the ground truth score function and the learned score function of a diffusion model trained on a mixture of Gaussians. The ground truth score function has sharp jumps between different modes, while the learned score function is smoother. This difference explains why the diffusion model interpolates between modes, generating samples outside the support of the training distribution (hallucinations). The rightmost panel shows the trajectory of the predicted x0 (final sample) for different timesteps during the reverse diffusion process, highlighting the high variance for hallucinated samples.", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_6_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure shows a comparison of training samples and generated samples from diffusion models. The top part demonstrates mode interpolation on a simple shapes dataset: the model generates samples with combinations of shapes never seen in the training data.  The bottom part shows that the model trained on images of hands can hallucinate hands with extra fingers. This illustrates the phenomenon of mode interpolation, a central point of the paper.", "section": "1.1 Hallucination in Diffusion Models"}, {"figure_path": "aNTnHBkw4T/figures/figures_7_1.jpg", "caption": "Figure 6: Variance of  Trajectories. The trajectory of the predicted  for hallucinated (shades of red), and non-hallucinated samples (shades of blue). We see that non-hallucinated samples stabilize in their prediction in the last 20 time steps for both 1D GAUSSIAN and 2D GAUSSIAN setups, whereas the hallucinated samples have high variance in the predicted  across time steps.", "description": "This figure visualizes the variance in the predicted values of x0 (the final image) during the reverse diffusion process for both hallucinated and non-hallucinated samples in 1D and 2D Gaussian datasets.  The plots show the trajectories of x0 over time. Hallucinated samples exhibit high variance, particularly in the final time steps, while non-hallucinated samples stabilize their predictions. This difference in variance is used as a metric to distinguish between hallucinated and non-hallucinated samples.", "section": "5 Variance in the trajectory of prediction"}, {"figure_path": "aNTnHBkw4T/figures/figures_7_2.jpg", "caption": "Figure 7: Histogram of Hallucination Metric. We depict the hallucination metric values for (a) 1D GAUSSIAN, (b) 2D GAUSSIAN, and (c) SIMPLE SHAPES setups. The histograms show that trajectory variance can capture a separation between hallucinated (orange) and non-hallucinated (blue) samples.", "description": "This figure shows the distribution of the proposed hallucination metric for three different datasets: 1D Gaussian, 2D grid of Gaussians, and Simple Shapes.  The metric measures the variance in the trajectory of the predicted noise during the reverse diffusion process.  Hallucinated samples, which lie outside the support of the training distribution, exhibit higher variance than in-support samples. The histograms clearly show a separation between the two groups, indicating the effectiveness of the metric in detecting hallucinations.", "section": "5 Variance in the trajectory of prediction"}, {"figure_path": "aNTnHBkw4T/figures/figures_9_1.jpg", "caption": "Figure 8: Mitigating Hallucinations with Pre-emptive Detection. We filter out hallucinated samples using the metric from \u00a7 5 before training on samples from the previous generation of the diffusion model. In the case of (a) 2D GAUSSIAN, (b) SIMPLE SHAPES, where we have clear definitions of hallucination (mode interpolation, and new shape combinations) we see the effectiveness of our variance-based filtering method in minimizing hallucinations across generations compared to random filtering. In the case of (c) MNIST dataset, we measure the FID of subsequent generations and notice that pre-emptive filtering of hallucinated samples makes the recursive model collapse slower.", "description": "This figure shows the effectiveness of pre-emptive hallucination filtering in recursive model training.  Three datasets are used: a 2D grid of Gaussians, simple shapes, and MNIST.  The \"Trajectory Variance Filtering\" method significantly reduces the percentage of hallucinated samples in the first two datasets over multiple generations, compared to random filtering. For MNIST, the Fr\u00e9chet Inception Distance (FID) shows that pre-emptive filtering slows down model collapse.", "section": "6 Implications on Recursive Model Training"}, {"figure_path": "aNTnHBkw4T/figures/figures_14_1.jpg", "caption": "Figure 9: Recursive Training on 2D GAUSSIAN. We investigate the impact of recursively training a DDPM on its own generated data using a square grid of 2D Gaussians with T = 500 diffusion steps. In each generation, we sample 100k examples, and train the subsequent generation on these data points. As the training progresses through multiple generations, the hallucinated (interpolated) samples significantly influence the learning of the next generation's distribution.", "description": "This figure visualizes the effect of recursive training on a 2D Gaussian dataset.  Each subplot shows the generated data distribution for a different generation of the model. As the model is retrained on its own output, the initially well-defined modes start to blur and eventually collapse, indicating a loss of diversity and mode collapse.", "section": "6 Implications on Recursive Model Training"}, {"figure_path": "aNTnHBkw4T/figures/figures_15_1.jpg", "caption": "Figure 10: Interpolation in Representation Space. We analyze the bottleneck of the U-Net to demonstrate mode interpolation in the Shapes dataset. We clearly see that Region 2 (which consists of 2 squares) is interpolating between Region 1 (one square in the bottom half) and Region 3 (one square in the top half).", "description": "This figure visualizes the results of t-SNE dimensionality reduction applied to the bottleneck layer of a U-Net used in the SIMPLE SHAPES experiment.  Three distinct regions in the reduced feature space represent different image characteristics. Region 1 corresponds to images with a single square in the bottom half, Region 3 corresponds to images with a single square at the top, and Region 2, an interpolated region, contains images with two squares (one at the top and one at the bottom), demonstrating the hallucination phenomenon of mode interpolation.", "section": "4.4 SIMPLE SHAPES"}, {"figure_path": "aNTnHBkw4T/figures/figures_15_2.jpg", "caption": "Figure 11: Variational Diffusion Model. We train a Variational Diffusion Model (VDM) on the 2D Gaussian Data with 10k samples (first three columns). T denotes the timesteps during training and T\u2019 denotes the sampling timesteps. T = \u221e refers to the continuous time variant. The fourth column shows a DDPM trained on a 2D Gaussian with imbalanced modes. The boxes indicate the modes with less data. The last column shows result of sampling from the true score function.", "description": "This figure demonstrates the results of training Variational Diffusion Models (VDM) and Denoising Diffusion Probabilistic Models (DDPM) on a 2D Gaussian distribution with 10,000 samples.  The first three columns show the sample distributions generated by VDMs with varying training timesteps (T) and sampling timesteps (T'). The fourth column illustrates a DDPM trained on an imbalanced 2D Gaussian dataset, highlighting the effect of imbalanced data on the generated samples. Finally, the last column displays samples generated using the true score function for comparison. The figure showcases how different training parameters and data distributions influence the quality and characteristics of generated samples.", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_16_1.jpg", "caption": "Figure 2: Mode Interpolation in 1D GAUSSIAN. The red curve indicates the PDF of the true data distribution q(x), which is a mixture of 3 Gaussians (notice that the y-axis is in log-scale). In blue, we show a density histogram of the samples generated by a DDPM trained on varying number of samples from the true data distribution. For each histogram, we sampled 100 million examples from the diffusion model to observe the interpolated distribution. (a,b) show how the density of samples generated in the interpolated region reduces with an increase in the number of samples from the real distribution (used for training the DDPM). (c,d) show the impact of moving one of the modes (originally at \u03bc = 3) to \u03bc = 4. We see how the density of samples generated in the region between distant (but neighboring) modes is significantly lesser than that between nearby modes.", "description": "This figure shows the impact of the number of training samples and the distance between Gaussian modes on the mode interpolation phenomenon in diffusion models.  The plots demonstrate that increasing the number of training samples reduces the generation of samples in the regions between modes, and that greater distance between the modes also decreases this effect. This effect is consistent with the concept of mode interpolation, where the model generates samples between existing modes, even when such samples are not present in the training data.", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_16_2.jpg", "caption": "Figure 2: Mode Interpolation in 1D GAUSSIAN. The red curve indicates the PDF of the true data distribution q(x), which is a mixture of 3 Gaussians (notice that the y-axis is in log-scale). In blue, we show a density histogram of the samples generated by a DDPM trained on varying number of samples from the true data distribution. For each histogram, we sampled 100 million examples from the diffusion model to observe the interpolated distribution. (a,b) show how the density of samples generated in the interpolated region reduces with an increase in the number of samples from the real distribution (used for training the DDPM). (c,d) show the impact of moving one of the modes (originally at \u03bc = 3) to \u03bc = 4. We see how the density of samples generated in the region between distant (but neighboring) modes is significantly lesser than that between nearby modes.", "description": "This figure shows the results of training a denoising diffusion probabilistic model (DDPM) on a 1D Gaussian mixture distribution.  The top row demonstrates how increasing the number of training samples reduces the density of generated samples in the regions between the Gaussian modes (interpolation). The bottom row shows that increasing the distance between modes also reduces this interpolation effect.", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_16_3.jpg", "caption": "Figure 2: Mode Interpolation in 1D GAUSSIAN. The red curve indicates the PDF of the true data distribution q(x), which is a mixture of 3 Gaussians (notice that the y-axis is in log-scale). In blue, we show a density histogram of the samples generated by a DDPM trained on varying number of samples from the true data distribution. For each histogram, we sampled 100 million examples from the diffusion model to observe the interpolated distribution. (a,b) show how the density of samples generated in the interpolated region reduces with an increase in the number of samples from the real distribution (used for training the DDPM). (c,d) show the impact of moving one of the modes (originally at \u03bc = 3) to \u03bc = 4. We see how the density of samples generated in the region between distant (but neighboring) modes is significantly lesser than that between nearby modes.", "description": "This figure shows the results of an experiment to demonstrate mode interpolation in a 1D Gaussian mixture model.  The experiment varies the number of training samples and the positions of Gaussian modes, demonstrating how smoothly the diffusion model interpolates between modes, even generating samples in areas with zero probability density in the original distribution. The density of these interpolated samples decreases with the increase of training samples.  It also shows that distant modes have less interpolation than near modes.", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_16_4.jpg", "caption": "Figure 2: Mode Interpolation in 1D GAUSSIAN. The red curve indicates the PDF of the true data distribution q(x), which is a mixture of 3 Gaussians (notice that the y-axis is in log-scale). In blue, we show a density histogram of the samples generated by a DDPM trained on varying number of samples from the true data distribution. For each histogram, we sampled 100 million examples from the diffusion model to observe the interpolated distribution. (a,b) show how the density of samples generated in the interpolated region reduces with an increase in the number of samples from the real distribution (used for training the DDPM). (c,d) show the impact of moving one of the modes (originally at \u03bc = 3) to \u03bc = 4. We see how the density of samples generated in the region between distant (but neighboring) modes is significantly lesser than that between nearby modes.", "description": "This figure shows the results of experiments with a 1D Gaussian mixture model.  The top row shows the probability density function (PDF) of the true data distribution (red) and the density histogram of samples generated by a denoising diffusion probabilistic model (DDPM) trained on different numbers of samples from the true distribution (blue).  The results show that the DDPM tends to generate samples in the regions between the Gaussian modes (mode interpolation), even though these samples are not present in the training data.  The amount of mode interpolation decreases as the number of training samples increases. The bottom row shows that the amount of mode interpolation also depends on the distance between the modes: more distant modes lead to less interpolation. ", "section": "4 Understanding Mode Interpolation and Hallucination"}, {"figure_path": "aNTnHBkw4T/figures/figures_17_1.jpg", "caption": "Figure 8: Mitigating Hallucinations with Pre-emptive Detection. We filter out hallucinated samples using the metric from \u00a7 5 before training on samples from the previous generation of the diffusion model. In the case of (a) 2D GAUSSIAN, (b) SIMPLE SHAPES, where we have clear definitions of hallucination (mode interpolation, and new shape combinations) we see the effectiveness of our variance-based filtering method in minimizing hallucinations across generations compared to random filtering. In the case of (c) MNIST dataset, we measure the FID of subsequent generations and notice that pre-emptive filtering of hallucinated samples makes the recursive model collapse slower.", "description": "This figure demonstrates the effectiveness of preemptively filtering out hallucinated samples (using a variance-based metric) before training subsequent generations of diffusion models.  The experiment is performed on three datasets: 2D Gaussian, Simple Shapes, and MNIST. Results show that this method significantly reduces hallucinations across generations compared to random filtering, and in the case of MNIST, delays model collapse.", "section": "6 Implications on Recursive Model Training"}, {"figure_path": "aNTnHBkw4T/figures/figures_17_2.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure shows the comparison of an original dataset and a generated dataset using a diffusion model. The top part shows a dataset with simple shapes (triangle, square, and pentagon) where each shape appears at most once per image. The bottom part shows a dataset with high-quality images of hands. The generated datasets show that diffusion models can generate images with multiple occurrences of the same shape (hallucinations) or images of hands with additional fingers, indicating a failure mode of diffusion models.", "section": "1.1 Hallucination in Diffusion Models"}, {"figure_path": "aNTnHBkw4T/figures/figures_18_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure shows the results of training a diffusion model on two different datasets. The top half shows a dataset of simple shapes (triangles, squares, pentagons) where each image contains at most one of each shape. The generated samples, however, contain hallucinations: images with multiple instances of the same shape. The bottom half shows a similar experiment using images of hands. The original dataset contains images of hands with the correct number of fingers. The model generates images of hands with extra or missing fingers, demonstrating the problem of mode interpolation in diffusion models.", "section": "1.1 Hallucination in Diffusion Models"}, {"figure_path": "aNTnHBkw4T/figures/figures_19_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure shows the results of training a diffusion model on two different datasets. The top part shows a dataset of simple shapes (triangles, squares, pentagons) where each image contains at most one of each shape. The generated samples, however, contain multiple instances of the same shape, demonstrating the phenomenon of hallucination. The bottom part shows similar results on a dataset of hands, where the generated images frequently contain extra or missing fingers.", "section": "1.1 Hallucination in Diffusion Models"}, {"figure_path": "aNTnHBkw4T/figures/figures_20_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure shows examples of \"hallucinations\" in diffusion models.  The top row illustrates the difference between a dataset of simple shapes (triangles, squares, pentagons) and the output of a diffusion model trained on that dataset.  The model generates images with multiple instances of the same shape, something not present in the original data. The bottom row shows the same issue with a more realistic example of hand images.  A diffusion model trained on hands produces images of hands with extra fingers, which also shows hallucinations.", "section": "1.1 Hallucination in Diffusion Models"}, {"figure_path": "aNTnHBkw4T/figures/figures_21_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure demonstrates hallucinations in diffusion models. The top half shows a simple dataset of shapes (triangles, squares, pentagons) and the hallucinations that arise from training a diffusion model on this dataset, such as having multiple instances of the same shape in one image, a combination which is not present in the original training dataset. The bottom half shows a similar experiment, this time using high-quality images of hands, which results in hallucinations such as images of hands with extra fingers.", "section": "1.1 Hallucination in Diffusion Models"}, {"figure_path": "aNTnHBkw4T/figures/figures_22_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure demonstrates the concept of hallucination in diffusion models using two examples. The top part shows a dataset of simple shapes (triangles, squares, pentagons) and the corresponding generated images by a diffusion model. It highlights that the model hallucinates by generating images with combinations of shapes never seen in the training data. The bottom part uses a more realistic example of human hands, showing that the model can generate hands with extra fingers, another example of hallucination.", "section": "1 Introduction"}, {"figure_path": "aNTnHBkw4T/figures/figures_23_1.jpg", "caption": "Figure 1: Hallucinations in Diffusion Models: Original Dataset (Left) & Generated Dataset (Right). (Top) The original dataset consists of 64x64 images divided into three columns, each containing a triangle, square, or pentagon with a 0.5 probability of the shape being present. Each shape appears at most once per image. The generated dataset created using an unconditional DDPM includes some samples (hallucinations) with multiple occurrences of the same shape that is unseen in the original dataset. (Bottom) We also train a ADM [29] on a dataset of high-quality images of human hands and show that the diffusion model generates hallucinated images of hands with additional fingers.", "description": "This figure shows examples of hallucinations in diffusion models. The top part compares a dataset of simple shapes (triangles, squares, pentagons) with samples generated by a diffusion model trained on this dataset. The generated samples contain artifacts such as multiple instances of the same shape, which were not present in the training data. The bottom part shows the same phenomenon for images of human hands: the model generates images of hands with extra or missing fingers, which is a common failure mode of diffusion models.", "section": "1.1 Hallucination in Diffusion Models"}]