{"references": [{"fullname_first_author": "Tongzhou Wang", "paper_title": "Dataset distillation", "publication_date": "2018-11-10", "reason": "This paper is foundational to the field of dataset distillation, introducing the core concept of creating smaller, synthetic datasets that match the performance of larger ones."}, {"fullname_first_author": "Zeyuan Yin", "paper_title": "Squeeze, recover and relabel: Dataset condensation at imagenet scale from a new perspective", "publication_date": "2023-12-01", "reason": "This paper presents a novel three-stage framework for ImageNet-level dataset condensation that directly addresses the limitations of previous approaches in scaling to large datasets."}, {"fullname_first_author": "Zeyuan Yin", "paper_title": "Dataset distillation in large data era", "publication_date": "2023-11-18", "reason": "This paper significantly improves on the previous state-of-the-art for large-scale dataset distillation, and its techniques are closely compared and contrasted with the proposed approach."}, {"fullname_first_author": "Shitong Shao", "paper_title": "Generalized large-scale data condensation via various backbone and statistical matching", "publication_date": "2024-01-01", "reason": "This is a very recent paper that tackles similar challenges in dataset condensation and provides a strong baseline comparison for evaluating the proposed method's effectiveness."}, {"fullname_first_author": "Peng Sun", "paper_title": "On the diversity and realism of distilled dataset: An efficient dataset distillation paradigm", "publication_date": "2023-12-01", "reason": "This paper directly addresses the issue of image diversity within condensed datasets, which is a key factor in determining the effectiveness of dataset distillation and is explored in detail in the current work."}]}