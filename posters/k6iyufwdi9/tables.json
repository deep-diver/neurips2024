[{"figure_path": "k6iyUfwdI9/tables/tables_2_1.jpg", "caption": "Figure 4: PR-curve for the baseline and the proposed methods on various datasets. On the TriviaQA and AmbigQA datasets, M.I. and S.E. perform nearly identically, but they outperform the T0 and S.V. baselines. For the S.E. and M.I. methods, the responses for a large number of queries can be clustered into a single group, and therefore the semantic entropy and mutual information scores are zero. This is why the starting point of their curves is at a higher recall values. On the TriviaQA+WordNet and AmbigQA+WordNet datasets with a significant number of high entropy multi-label queries, M.I. outperforms the S.E. baseline. The methods perform nearly identical on the not shown recall area.", "description": "This figure compares several methods for detecting hallucination in LLMs.  It shows precision-recall curves for four different methods on four different datasets.  The datasets vary in the proportion of single-label vs. multi-label queries. The methods compared are: greedy response probability (T0), semantic entropy (S.E.), the proposed mutual information (M.I.), and self-verification (S.V.). The results show that M.I. and S.E. perform similarly on datasets with primarily single-label queries but that M.I. outperforms S.E. on datasets with a significant number of multi-label queries.", "section": "6 Experiments"}]