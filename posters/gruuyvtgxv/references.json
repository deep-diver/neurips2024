{"references": [{"fullname_first_author": "Leslie Pack Kaelbling", "paper_title": "Planning and acting in partially observable stochastic domains", "publication_date": "1998-00-00", "reason": "This paper is foundational to the field of partially observable Markov decision processes (POMDPs), providing a formal framework for understanding and addressing problems with partial observability, a core focus of the current paper."}, {"fullname_first_author": "Volodymyr Mnih", "paper_title": "Human-level control through deep reinforcement learning", "publication_date": "2015-00-00", "reason": "This paper introduced deep reinforcement learning (DRL), demonstrating the ability of DRL agents to achieve human-level performance on complex tasks, significantly advancing the field and inspiring much subsequent work, including the current paper."}, {"fullname_first_author": "David Silver", "paper_title": "Mastering the game of Go with deep neural networks and tree search", "publication_date": "2016-00-00", "reason": "This paper demonstrated the power of deep reinforcement learning combined with advanced search techniques to master the game of Go, exceeding human-level performance and showcasing the potential of DRL in tackling complex problems."}, {"fullname_first_author": "David Silver", "paper_title": "Mastering the game of Go without human knowledge", "publication_date": "2017-00-00", "reason": "This paper advanced the state-of-the-art in reinforcement learning by demonstrating that an agent could master Go entirely through self-play, without any human knowledge of the game or hand-engineered features, highlighting the power of self-learning and generalisation in DRL."}, {"fullname_first_author": "Andrea Baisero", "paper_title": "Unbiased asymmetric reinforcement learning under partial observability", "publication_date": "2022-00-00", "reason": "This paper directly addresses the core challenge of the current paper\u2014unbiased learning under partial observability\u2014by introducing an asymmetric actor-critic framework with a theoretically sound approach to reduce variance and improve sample efficiency."}]}