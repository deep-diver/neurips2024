[{"figure_path": "3ivnixHy16/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of VIDEORM. By incorporating temporal modeling modules, VIDEORM is capable of not only capturing the preference scores of individual frames but also modeling the temporal features of the video, thereby better evaluating the overall preference score of the video.", "description": "This figure illustrates the architecture of VIDEORM, a video preference reward model.  It shows how the model combines a text encoder (CLIP Text Encoder) with an image encoder that processes video frames (using ViT layers and Temporal Shift). A Temporal Transformer module is included to model temporal dynamics in videos. The model ultimately outputs a scalar value representing the overall preference score, integrating both individual frame quality and temporal coherence.", "section": "3.1 Architecture"}, {"figure_path": "3ivnixHy16/figures/figures_5_1.jpg", "caption": "Figure 2: Best-of-n experiments on the T2VQA-DB [18] test benchmark. We sample n generated videos and choose the one with the highest reward.", "description": "This figure shows the results of best-of-n experiments conducted on the T2VQA-DB benchmark dataset to evaluate the effectiveness of VIDEORM in selecting high-quality videos.  In these experiments, n videos were generated for each prompt, and the video with the highest reward score (as determined by VIDEORM) was selected as the 'best'. The graph plots the win rate (percentage of times the best video selected by VIDEORM was preferred by human evaluators) against the number of samples (n).  As n increases, the win rate also increases, indicating that VIDEORM is effective in identifying higher-quality videos.", "section": "4.1 Task 1: Reward Modeling"}, {"figure_path": "3ivnixHy16/figures/figures_5_2.jpg", "caption": "Figure 2: Best-of-n experiments on the T2VQA-DB [18] test benchmark. We sample n generated videos and choose the one with the highest reward.", "description": "This figure shows the results of best-of-n experiments conducted on the T2VQA-DB [18] test benchmark to evaluate the effectiveness of VIDEORM in identifying high-quality videos.  In these experiments, n videos were generated for each prompt, and VIDEORM's reward scores were used to select the best video. The x-axis represents the number of samples (n) considered, and the y-axis shows the win rate, indicating the percentage of times the top-ranked video selected by VIDEORM was indeed considered superior.  The results demonstrate a clear positive correlation between the number of samples considered and the win rate, suggesting that VIDEORM is effective at identifying higher-quality videos.", "section": "4.1 Task 1: Reward Modeling"}, {"figure_path": "3ivnixHy16/figures/figures_6_1.jpg", "caption": "Figure 5: Win rates of text-to-video models fine-tuned with DRaFT-V compared to other baselines. Here baseline denotes the base text-to-video model without any fine-tuning.", "description": "This figure presents the results of a human evaluation comparing the performance of three different fine-tuning methods for text-to-video models: DRaFT-V, InstructVideo, and a baseline model without fine-tuning. The evaluation metrics are win rate, tie rate, and loss rate across three benchmark datasets: TVGE [56], VBench [15], and T2VQA-DB [18]. Each bar in the chart represents the proportion of wins, ties, and losses for each comparison on a given dataset.  The results show that DRaFT-V consistently outperforms both InstructVideo and the baseline, demonstrating its effectiveness in aligning text-to-video generation with human preferences.", "section": "4.2 Task 2: Fine-tuning Text-to-Video Generative Models"}, {"figure_path": "3ivnixHy16/figures/figures_6_2.jpg", "caption": "Figure 6: (a) Visualization of reward model values change with the training steps for both DRaFT-V and DRaFT-H. (b) Evaluation result across three test benchmarks for the size of training data used in optimizing VIDEORM. (c) Ablation study for the number of input frames N in VIDEORM.", "description": "This figure presents three subplots that demonstrate the impact of different hyperparameters on the performance of reward models. Plot (a) compares the change in reward scores for DRaFT-V and DRaFT-H during training steps. Plot (b) shows the accuracy of VIDEORM on three benchmark datasets (TVGE, VBench, and T2VQA-DB) under different sizes of training data. Plot (c) examines the effect of varying the number of input frames (N) in VIDEORM on the accuracy of the model on TVGE benchmark dataset. ", "section": "4 Experiments"}, {"figure_path": "3ivnixHy16/figures/figures_6_3.jpg", "caption": "Figure 6: (a) Visualization of reward model values change with the training steps for both DRaFT-V and DRaFT-H. (b) Evaluation result across three test benchmarks for the size of training data used in optimizing VIDEORM. (c) Ablation study for the number of input frames N in VIDEORM.", "description": "This figure presents three subplots showing the results of experiments evaluating the VIDEORM model. (a) shows the reward model values changing over training steps for two different methods, DRaFT-V and DRaFT-H. (b) shows evaluation results across three benchmarks for varying training data sizes used to optimize VIDEORM. (c) shows an ablation study for the number of input video frames (N) used in VIDEORM, demonstrating its performance under different input frame numbers.", "section": "4. Experiments"}, {"figure_path": "3ivnixHy16/figures/figures_7_1.jpg", "caption": "Figure 7: Ablation over K adopted in DRaFT-V during fine-tuning text-to-video model.", "description": "This figure shows the ablation study on the impact of different K values adopted in the DRaFT-V algorithm during the fine-tuning process of text-to-video models.  The x-axis represents the training steps, and the y-axis represents the reward score. Different lines represent different values of K (1, 5, 10, 20, 40). The figure demonstrates how the performance of the algorithm changes with different K values during model training.", "section": "4.3 Ablation Study"}, {"figure_path": "3ivnixHy16/figures/figures_8_1.jpg", "caption": "Figure 8: The impact of different hyper-parameter choices on the annotation accuracy of GPT-4 V.", "description": "The figure shows the impact of two hyperparameters, the number of frames (N) and the temperature (\u03c4), on the accuracy of GPT-4 V annotations.  The x-axis represents the number of frames considered, while the y-axis represents the annotation accuracy. Two lines are plotted, one for different temperature values and another for different frame numbers, showing how accuracy changes.  The results suggest that annotation accuracy increases initially with the number of frames considered, but then plateaus or even decreases for higher frame counts.  Similarly, lower temperatures generally lead to higher accuracy, suggesting that less randomness in the GPT-4 V model improves annotation consistency.", "section": "4.3 Ablation Study"}, {"figure_path": "3ivnixHy16/figures/figures_13_1.jpg", "caption": "Figure 9: Score distribution across two annotation aspects in VIDEOPREFER.", "description": "This figure shows the distribution of scores across the two annotation aspects in the VIDEOPREFER dataset: Prompt-Following and Video-Quality.  The bar chart displays the percentage of annotations receiving each score (1-5) for each aspect.  The distribution for Prompt-Following is relatively normal, indicating a good spread of opinions, while the Video-Quality scores skew toward the lower end, suggesting that the generated videos often fall short of ideal quality.", "section": "B VIDEOPREFER"}, {"figure_path": "3ivnixHy16/figures/figures_14_1.jpg", "caption": "Figure 10: Visualization of example data item in VIDEOPREFER. Here we show one data item which contains a prompt and four corresponding generated videos. For each video, there are two annotations from different annotation aspects (Prompt-Following and Video-Quality) are provided by GPT-4 V", "description": "This figure shows an example data point from the VIDEOPREFER dataset.  It consists of a text prompt (e.g., a description of a scene) and four corresponding video clips generated by different models. Each video clip is accompanied by two scores provided by GPT-4 V, assessing how well the video follows the prompt and the overall video quality. The scores provide a fine-grained evaluation of the generated videos.", "section": "2 VIDEOPREFER"}, {"figure_path": "3ivnixHy16/figures/figures_14_2.jpg", "caption": "Figure 10: Visualization of example data item in VIDEOPREFER. Here we show one data item which contains a prompt and four corresponding generated videos. For each video, there are two annotations from different annotation aspects (Prompt-Following and Video-Quality) are provided by GPT-4 V", "description": "This figure shows an example data item from the VIDEOPREFER dataset.  It consists of a text prompt and four video clips generated from that prompt by different models.  Each video is accompanied by two scores from GPT-4 V: one evaluating how well the video follows the prompt, and one assessing its visual quality.", "section": "2 VIDEOPREFER"}, {"figure_path": "3ivnixHy16/figures/figures_14_3.jpg", "caption": "Figure 10: Visualization of example data item in VIDEOPREFER. Here we show one data item which contains a prompt and four corresponding generated videos. For each video, there are two annotations from different annotation aspects (Prompt-Following and Video-Quality) are provided by GPT-4 V", "description": "This figure shows an example data item from the VIDEOPREFER dataset.  Each data item includes a text prompt and four generated videos.  For each video, GPT-4V provides two scores: one for how well the video follows the prompt, and another for video quality.  The figure visually displays the prompt, the four video frames, and the two scores assigned by GPT-4V for each video.", "section": "2 VIDEOPREFER"}, {"figure_path": "3ivnixHy16/figures/figures_14_4.jpg", "caption": "Figure 10: Visualization of example data item in VIDEOPREFER. Here we show one data item which contains a prompt and four corresponding generated videos. For each video, there are two annotations from different annotation aspects (Prompt-Following and Video-Quality) are provided by GPT-4 V", "description": "This figure shows a sample data entry from the VIDEOPREFER dataset.  Each entry consists of a text prompt describing a scene (e.g., \"A man working in his room, typing on a portable computer, and a cat watching him\") and four corresponding videos generated by different models.  Each video receives two scores from GPT-4 V: one for \"Prompt-Following\" (how well the video matches the prompt) and one for \"Video-Quality\" (the overall aesthetic and technical quality of the video). The scores provide a fine-grained evaluation of the generated videos, demonstrating the dataset's capacity for detailed assessment.", "section": "2 VIDEOPREFER"}, {"figure_path": "3ivnixHy16/figures/figures_15_1.jpg", "caption": "Figure 11: Top-1 videos from 32 generated videos select by CLIP, ImageReward, PickScore, HPS v2 and VIDEORM. VIDEORM is capable of selecting higher-quality generated videos, e.g., those that better match the prompt descriptions and exhibit more dynamic content.", "description": "This figure shows the top-ranked videos selected by five different reward models (CLIP, ImageReward, PickScore, HPS v2, and VIDEORM) for three different prompts.  The goal is to demonstrate the ability of VIDEORM to select videos that better match the text prompt and exhibit more dynamic and engaging content compared to other reward models.", "section": "Visualization of Selection Results"}, {"figure_path": "3ivnixHy16/figures/figures_16_1.jpg", "caption": "Figure 12: Visualization Results for different fine-tuning methods. We find that compared to fine-tuning with an image domain reward model, fine-tuning with VIDEORM significantly enhances the performance of text-to-video models (DRaFT-V and InstructVideo-V).", "description": "This figure compares the results of fine-tuning text-to-video models using different reward models. The baseline model is compared to InstructVideo (using HPS v2), DRaFT-H (using HPS v2), InstructVideo-V (using VIDEORM), and DRaFT-V (using VIDEORM).  The results show that using VIDEORM for fine-tuning significantly improves the quality of the generated videos compared to using an image-based reward model like HPS v2.", "section": "4.2 Task 2: Fine-tuning Text-to-Video Generative Models"}, {"figure_path": "3ivnixHy16/figures/figures_17_1.jpg", "caption": "Figure 1: Overview of VIDEORM. By incorporating temporal modeling modules, VIDEORM is capable of not only capturing the preference scores of individual frames but also modeling the temporal features of the video, thereby better evaluating the overall preference score of the video.", "description": "The figure illustrates the architecture of VIDEORM, a video preference reward model.  It shows how the model uses a combination of image and text encoders, along with added temporal modeling modules (Temporal Shift and Temporal Transformer), to evaluate video preferences holistically, considering both individual frames and the overall temporal coherence and dynamics of the video. The text input is processed by a text encoder and compared against the video, which is processed by an image encoder that includes the temporal modules before finally outputting a preference score.", "section": "3 VIDEORM: A General-Purpose Video Preference Reward Model"}]