[{"figure_path": "uS9RZH6K65/figures/figures_1_1.jpg", "caption": "Figure 1: Left: For open-vocabulary action recognition (OVAR), existing researches neglect an essential aspect: the text descriptions provided by users may be noisy (e.g., misspelling and typos), resulting in potential classification errors and limiting the real-world practicality. Right: Rethinking the robustness for popular OVAR methods [49, 62]. On various datasets, they exhibit high sensitivity to text noises. Besides, as the noise level increases, the performance degrades significantly.", "description": "The figure highlights the impact of noisy text descriptions on Open-Vocabulary Action Recognition (OVAR). The left panel illustrates how noisy descriptions (misspellings, typos) can affect the performance of existing OVAR methods, while the right panel shows the significant drop in accuracy of popular OVAR methods as the level of noise in text descriptions increases across various datasets (UCF101, K700, HMDB51). This emphasizes the need for robust OVAR models that can handle noisy input.", "section": "1 Introduction"}, {"figure_path": "uS9RZH6K65/figures/figures_3_1.jpg", "caption": "Figure 2: Framework Overview. DENOISER is composed of one generative part Igene and one discriminative part disc. \u03a8gene views denoising text descriptions as a decoding process Ti\u22121 \u2192 Ti. We first propose text candidates Pprop for Ti\u22121 based on spelling similarity; then choose the best candidate by inter-modal weighting Pinter and intra-modal weighting Pintra. Pinter uses vision-text information, while intra relies solely on texts. disc assigns text semantics to visual samples, then only visual samples with the same semantics can vote for text candidates. We optimize alternatively between generative and discriminative steps to tackle noisy OVAR.", "description": "This figure illustrates the DENOISER framework, which consists of a generative step and a discriminative step. The generative step focuses on denoising noisy text descriptions by proposing candidate texts based on spelling similarity and using inter-modal and intra-modal weighting to select the best candidate.  The discriminative step leverages an existing OVAR model to assign visual samples to text descriptions. The two steps iterate alternatively to progressively refine the text descriptions and improve the accuracy of visual sample classification.  The figure shows the flow of information between the different components and highlights the interplay between visual and textual information in the denoising process.", "section": "3.2 DENOISER: One Robust OVAR Framework"}, {"figure_path": "uS9RZH6K65/figures/figures_6_1.jpg", "caption": "Figure 3: Statistics for Noises in Reality. Text noises may be classified into 4 types: inserting, substituting, swapping, and deleting characters.[2] In terms of edit distance, based on TOEFL-Spell dataset[10], most of the text noises have an edit distance = 1 compared to the clean version. Nevertheless, the distribution tends to be positively skewed towards larger noise.", "description": "This figure shows the statistical analysis of noise types and their edit distances in real-world text descriptions.  The left pie chart breaks down the percentage of each noise type (insertion, substitution, deletion, swap). The right pie chart shows the distribution of edit distances (difference in characters between noisy and clean text).  The data shows that substitution is the most frequent noise type, and that the majority of noise instances have an edit distance of 1.", "section": "4.1 Statistics on Noise Type/Rate for Text Descriptions"}, {"figure_path": "uS9RZH6K65/figures/figures_15_1.jpg", "caption": "Figure 5: Comparison to Adversarial Training. Adversarial training is not efficient, especially in low-noise scenarios, even leading to a lower performance compared to the original model. It also falls behind our method by a significant margin.", "description": "This figure compares the performance of adversarial training against the proposed DENOISER method on the UCF101 dataset.  Different levels of noise (0%, 5%, 10%, and 20%) were injected into the training data for adversarial training. The results show that adversarial training, while effective in some contexts, does not improve robustness to noisy text descriptions, especially at low noise levels. In fact, pre-training with noise even hinders performance at lower noise rates compared to the original (clean data) model. The DENOISER method consistently outperforms adversarial training at all noise levels, achieving significantly higher top-1 accuracy.", "section": "B.1 DENOISER vs. Adversarial Training"}, {"figure_path": "uS9RZH6K65/figures/figures_15_2.jpg", "caption": "Figure 6: Ablation Study on the Number of Visual Samples. When fewer visual samples are used in Pinter, our method shows a drop in performance. The bigger the noise rate, the larger the drop, showing that inter plays a role of increasing importance when the noise is larger.", "description": "This figure shows the ablation study on the number of visual samples used in the inter-modal weighting component (Pinter) of the DENOISER model.  The x-axis represents the percentage of visual samples used, while the y-axis shows the Top-1 accuracy.  Multiple lines represent different noise rates (5%, 10%, and 20%). The results demonstrate that using fewer visual samples leads to a decrease in performance, and this effect is more pronounced at higher noise rates. This suggests the importance of the inter-modal weighting component, especially in noisy scenarios.", "section": "B.2 Ablation Study on the Number of Visual Samples"}, {"figure_path": "uS9RZH6K65/figures/figures_16_1.jpg", "caption": "Figure 7: Denoising Visualization. Left: result with noisy text descriptions (crosses w black border). Middle: text candidates (crosses w/o black border), the visual samples (in dots) that are used to vote for candidates. Right: denoised class texts (crosses w black border) help for better classification.", "description": "This figure visualizes the effectiveness of the DENOISER model in denoising noisy text descriptions for open-vocabulary action recognition.  The left panel shows the results with noisy text descriptions, illustrating significant overlap and misclassification. The middle panel displays text candidates generated by the model, along with visual samples used to refine the selection process. The right panel demonstrates the results after denoising, showcasing improved separation and accuracy in classification.", "section": "B.3 Qualitative Results"}]