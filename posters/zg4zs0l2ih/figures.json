[{"figure_path": "Zg4zs0l2iH/figures/figures_0_1.jpg", "caption": "Figure 1: Multi-Object Relationship Modeling in Aerial videos analyzes a drone-captured video to detect and refine object relationships over time. The CYCLO model first identifies relationships between objects in individual frames and then incorporates temporal information about object positions and interactions to refine the understanding of those relationships across the video sequence. (Best viewed in colors)", "description": "The figure illustrates the process of multi-object relationship modeling in aerial videos using the CYCLO model.  The top part shows a sequence of drone-captured frames depicting several vehicles in motion.  The bottom part shows how the CYCLO model identifies and refines relationships between objects across those frames, incorporating temporal information about their positions and interactions to create a more comprehensive understanding of the scene's dynamics.", "section": "Abstract"}, {"figure_path": "Zg4zs0l2iH/figures/figures_3_1.jpg", "caption": "Figure 2: Comparisons of CYCLO and existing relationship modeling: (a) Progression [27, 63]: frame-wise fusion and classification; (b) Batch-progression [22, 55, 56]: temporal transformer; (c) Hierarchy [8]: spatiotemporal graph; (d) Our CYCLO approach: circular connectivity for capturing temporal dependencies.", "description": "This figure compares four different approaches to relationship modeling in videos: Progressive, Batch-Progressive, Hierarchical, and CYCLO.  The Progressive approach processes each frame independently, fusing pairwise features before classification. The Batch-Progressive approach uses a transformer to incorporate temporal information. The Hierarchical approach represents the video as a sequence of graphs with different levels of detail. CYCLO, the proposed method, establishes circular connectivity between frames to model temporal dependencies. The diagrams illustrate how each method processes video frames and combines spatial and temporal features to predict relationships.", "section": "Discussions"}, {"figure_path": "Zg4zs0l2iH/figures/figures_4_1.jpg", "caption": "Figure 3: Example annotation in our dataset. In Fig. 3b, straight arrows denote relationships between objects, while curved arrows indicate the positions of the objects. Nodes of the same color represent the same object, and the labels on the edges specify the predicate of each relationship. (Best viewed in colors)", "description": "This figure shows an example of the annotation process in the AeroEye dataset.  Figure 3a displays a basketball scene from the ERA dataset.  Figure 3b shows a graph representing the relationships between the objects in the scene.  Straight arrows in the graph indicate relationships (e.g., \"in front of,\" \"behind,\" \"next to\"), while curved arrows show the positions of the objects. Objects are represented by nodes of the same color, and the labels on the edges describe the relationship predicates.", "section": "3.2 Data Specification"}, {"figure_path": "Zg4zs0l2iH/figures/figures_4_2.jpg", "caption": "Figure 1: Multi-Object Relationship Modeling in Aerial videos analyzes a drone-captured video to detect and refine object relationships over time. The CYCLO model first identifies relationships between objects in individual frames and then incorporates temporal information about object positions and interactions to refine the understanding of those relationships across the video sequence. (Best viewed in colors)", "description": "The figure shows how the CYCLO model processes a drone video to detect and refine relationships between multiple objects over time. First, it identifies relationships within individual frames. Then, it incorporates temporal information about object positions and interactions to improve its understanding of relationships throughout the video sequence.", "section": "Abstract"}, {"figure_path": "Zg4zs0l2iH/figures/figures_4_3.jpg", "caption": "Figure 2: Comparisons of CYCLO and existing relationship modeling: (a) Progression [27, 63]: frame-wise fusion and classification; (b) Batch-progressive [22, 55, 56]: temporal transformer; (c) Hierarchy [8]: spatiotemporal graph; (d) Our CYCLO approach: circular connectivity for capturing temporal dependencies.", "description": "This figure compares four different approaches for modeling relationships in videos: Progressive, Batch-Progressive, Hierarchical, and CYCLO.  The Progressive approach processes each frame independently, fusing pairwise features and classifying predicate types. The Batch-Progressive approach uses a transformer to incorporate temporal information. The Hierarchical approach represents the video as a sequence of graphs with different levels of granularity.  CYCLO, the proposed method, uses circular connectivity among frames to capture both short-term and long-term dependencies, allowing for handling of cyclical patterns and periodic relationships.  The illustration highlights the key differences in design and information flow.", "section": "2.3 Discussions"}, {"figure_path": "Zg4zs0l2iH/figures/figures_6_1.jpg", "caption": "Figure 6: Illustration of cyclic interactions in the Cyclic Spatial-Temporal Graph Transformer. Each frame, represented by a colored block (where the first frame, t = 1 and the last frame, T = 4), undergoes spatial attention to obtain queries (Qt) and keys (Kt).", "description": "This figure illustrates the cyclic attention mechanism in the CYCLO model's Cyclic Temporal Graph Transformer. It shows how information from different frames is integrated in a cyclical manner to capture temporal dependencies.  Each frame is represented by a block, and the arrows show how queries (Qt) from each frame interact with keys (Kt) from other frames, creating a cyclical flow of information across the entire video sequence. This cyclical process helps the model better capture the temporal dynamics and long-range dependencies in video data.", "section": "4.3 Cyclic Temporal Graph Transformer"}, {"figure_path": "Zg4zs0l2iH/figures/figures_9_1.jpg", "caption": "Figure 7: Scene graphs generated by the CYCLO model on the AeroEye dataset, illustrating dynamic relationships between objects and agents across UAV-captured frames. (Best viewed in colors)", "description": "This figure shows the results of the CYCLO model on the AeroEye dataset.  The top part displays a sequence of frames from a drone-captured video, showing a police interaction with a driver.  Bounding boxes highlight detected objects. The bottom part shows the scene graphs generated by the CYCLO model. Each graph represents the relationships between objects (police officers, driver, car, and possibly bystanders) at a specific point in time. The edges and labels indicate the type of relationship (e.g., \"investigating\", \"approaching\"). The graphs demonstrate how CYCLO tracks and refines these relationships over the course of the video sequence.", "section": "Experimental Results"}, {"figure_path": "Zg4zs0l2iH/figures/figures_20_1.jpg", "caption": "Figure 2: Comparisons of CYCLO and existing relationship modeling: (a) Progression [27, 63]: frame-wise fusion and classification; (b) Batch-progressive [22, 55, 56]: temporal transformer; (c) Hierarchy [8]: spatiotemporal graph; (d) Our CYCLO approach: circular connectivity for capturing temporal dependencies.", "description": "This figure compares four different approaches for relationship modeling in videos: Progressive, Batch-Progressive, Hierarchical, and the authors' proposed CYCLO method.  The Progressive approach processes frames individually.  The Batch-Progressive approach uses a transformer to incorporate temporal information.  The Hierarchical approach models the video as a sequence of graphs at different levels of granularity.  The CYCLO approach uses cyclic connectivity to capture temporal dependencies, improving the handling of periodic and overlapping relationships.", "section": "Discussions"}, {"figure_path": "Zg4zs0l2iH/figures/figures_20_2.jpg", "caption": "Figure 1: Multi-Object Relationship Modeling in Aerial videos analyzes a drone-captured video to detect and refine object relationships over time. The CYCLO model first identifies relationships between objects in individual frames and then incorporates temporal information about object positions and interactions to refine the understanding of those relationships across the video sequence. (Best viewed in colors)", "description": "This figure illustrates the overall approach of the CYCLO model for multi-object relationship modeling in aerial videos.  It shows how the model processes a drone video sequence, first identifying relationships between objects within individual frames.  Then, it incorporates temporal information (object movement and interactions) to improve the understanding and refinement of those relationships over the entire video.", "section": "Abstract"}, {"figure_path": "Zg4zs0l2iH/figures/figures_21_1.jpg", "caption": "Figure 3: Example annotation in our dataset. In Fig. 3b, straight arrows denote relationships between objects, while curved arrows indicate the positions of the objects. Nodes of the same color represent the same object, and the labels on the edges specify the predicate of each relationship. (Best viewed in colors)", "description": "This figure shows an example of the annotation process used in the AeroEye dataset. Figure 3a shows a basketball scene from the ERA dataset, while Figure 3b provides a visual representation of the scene graph with annotations. Straight arrows indicate the relationships between objects, curved arrows show the positions of the objects, and node colors represent the same object across the graph.", "section": "3.2 Data Specification"}, {"figure_path": "Zg4zs0l2iH/figures/figures_21_2.jpg", "caption": "Figure 1: Multi-Object Relationship Modeling in Aerial videos analyzes a drone-captured video to detect and refine object relationships over time. The CYCLO model first identifies relationships between objects in individual frames and then incorporates temporal information about object positions and interactions to refine the understanding of those relationships across the video sequence. (Best viewed in colors)", "description": "This figure shows how the CYCLO model processes a drone video to understand multi-object relationships.  First, relationships between objects are identified in individual frames. Then, the model uses temporal information (object movement and interactions over time) to improve its understanding of these relationships across the entire video.", "section": "Abstract"}]