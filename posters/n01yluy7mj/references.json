{"references": [{"fullname_first_author": "Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "This paper introduces CLIP, the core model analyzed in the current work."}, {"fullname_first_author": "Koh", "paper_title": "Concept bottleneck models", "publication_date": "2020-07-01", "reason": "This paper introduces Concept Bottleneck Models, a baseline method compared against in the current work."}, {"fullname_first_author": "Chefer", "paper_title": "Transformer interpretability beyond attention visualization", "publication_date": "2021-06-01", "reason": "This paper provides a foundational approach for interpreting transformers, relevant to interpreting CLIP."}, {"fullname_first_author": "Krizhevsky", "paper_title": "Imagenet classification with deep convolutional neural networks", "publication_date": "2012-01-01", "reason": "This paper introduces the ImageNet dataset, a key dataset used for evaluating CLIP in the current work."}, {"fullname_first_author": "Zhou", "paper_title": "Learning to prompt for vision-language models", "publication_date": "2021-01-01", "reason": "This paper explores prompt engineering for vision-language models, a technique also used in the current work."}]}