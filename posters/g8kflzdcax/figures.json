[{"figure_path": "g8kFlZDcaX/figures/figures_1_1.jpg", "caption": "Figure 1: (Convergence under Misspecification). Excess regret normalized by optimal policy's performance under the misspecified setting of Section 4.1 (a = 1, m = 0). PGB is our proposed loss. ETO is a decision-blind approach that minimizes MSE. Other benchmarks include: DBB [26], FYL [1], and SPO+ [7]. Under misspecification, only the PG losses have vanishing excess regret. Error bars are 95% confidence intervals on the mean over 100 trials.", "description": "The figure shows the convergence of different methods for minimizing excess regret under misspecification.  The x-axis represents the training size (n), and the y-axis represents the normalized excess regret. The proposed Perturbation Gradient (PGB) loss significantly outperforms other methods (DBB, ETO, FYL, SPO+) by exhibiting vanishing excess regret as the training size increases.  The error bars indicate 95% confidence intervals based on 100 trials. The experiment uses a misspecified setting where a=1 and m=0, as described in Section 4.1 of the paper.", "section": "4 Numerical Experiments"}, {"figure_path": "g8kFlZDcaX/figures/figures_2_1.jpg", "caption": "Figure 2: (Comparing Surrogates under Misspecification). See Section 4.1 for setup (a = 1, m = 0). Benchmarks are decision-loss (DL) l, our PGB and PGC losses, Fenchel-Young Loss (FYL) [1], SPO+ [7], and the learning-to-rank list loss ([21]. Left-panel: (n = 200) Only our PG losses closely track the DL. Right Panels: As n increases, the DL and PG losses both become smoother.", "description": "This figure compares different surrogate losses under misspecified settings.  The left panel shows that for a small sample size (n=30), only the proposed Perturbation Gradient (PG) losses (PGB and PGC) track the decision loss (DL) closely. The right panel demonstrates that as the sample size increases (n=3000), the DL and PG losses become smoother, while other methods deviate significantly from the DL, indicating that the PG losses are more robust to misspecification as data increases.  The figure highlights the improved approximation of PG losses compared to existing approaches under misspecification.", "section": "4 Numerical Experiments"}, {"figure_path": "g8kFlZDcaX/figures/figures_7_1.jpg", "caption": "Figure 3: (SPO+ Comparisons) The left figure plots the excess regret normalized by the optimal policy's performance as we vary m for n = 80 and a = 1. The right figure plots the same value as we vary a for n = 200. When a = 0 the noise is centrally symmetric and when a = 1 the noise is the most asymmetric. Error bars are 95% confidence intervals on the mean over 100 trials.", "description": "This figure compares the performance of SPO+ with other methods (ETO, PGB, and PGC) under different misspecification levels (m) and noise asymmetry levels (a). The left panel shows that as misspecification increases, the excess regret for decision-aware methods increases more slowly than for decision-blind methods. The right panel shows that the performance of SPO+ is significantly impacted by noise asymmetry, whereas the PG losses remain relatively robust.", "section": "4 Numerical Experiments"}, {"figure_path": "g8kFlZDcaX/figures/figures_8_1.jpg", "caption": "Figure 4: Harder Shortest Path. a) One of the two planted paths will be optimal depending on value of X6. All other arcs strictly worse. b) Normalized Excess Regret as we vary the training samples. Error bars are 95% confidence intervals on the mean over 100 trials.", "description": "This figure shows the results of a shortest path experiment on a 5x5 grid graph with planted arcs, where one of two paths is optimal depending on the value of X6 (a random variable).  Subfigure (a) illustrates the graph structure with safe (red) and risky (blue) paths.  Subfigure (b) compares the normalized excess regret of various methods (2-State LR, PGB, PGC, SPO+, FYL) as the training sample size (n) increases for two noise distributions: Gaussian and uniform.  Error bars represent 95% confidence intervals over 100 trials. The experiment demonstrates that the performance of the proposed PG losses (PGB, PGC) are more robust against misspecification than other methods in scenarios with a more complex structure.", "section": "4.2 Shortest Path Experiments"}, {"figure_path": "g8kFlZDcaX/figures/figures_9_1.jpg", "caption": "Figure 5: (Portfolio Optimization) We plot the excess regret normalized by optimal policy's performance as we vary the number of training samples. Error bars are 95% confidence intervals on the mean over 100 trials.", "description": "The figure shows the normalized excess regret of different methods for portfolio optimization as the training sample size increases.  The normalized excess regret is calculated by dividing the excess regret by the optimal policy's performance.  The plot compares the performance of PGB and PGC losses against other decision-aware surrogates (2-State LR, FYL, SPO+) and the decision-blind approach (ETO). Error bars represent 95% confidence intervals based on 100 trials. This experiment utilizes real-world data (Fama French Industry Sector Portfolios) making the results especially relevant to practical applications.", "section": "4.3 Portfolio Experiment"}, {"figure_path": "g8kFlZDcaX/figures/figures_12_1.jpg", "caption": "Figure 6: (Comparing Zeroth Order Gradients). PGC, PGB, and PGF all approximate the decision loss (DL), but PGB is a pessimistic bound, while PGF is an optimistic bound. Here the optimism causes PGF to choose the wrong policy.", "description": "This figure compares three different zeroth-order gradient methods (PGF, PGB, PGC) for approximating the decision loss function (DL).  It demonstrates that the choice of approximation method significantly impacts the quality of the approximation.  PGB provides a pessimistic approximation, consistently underestimating the DL.  PGF offers an optimistic approximation, sometimes overestimating the DL to the point of selecting an entirely incorrect policy.  In contrast, PGC produces a more accurate approximation, closely tracking the DL function.", "section": "Comparing Zeroth Order Gradient Schemes"}, {"figure_path": "g8kFlZDcaX/figures/figures_13_1.jpg", "caption": "Figure 7: (Synthetic Data Generation from Section 4.1) Observations of (Xi, Yi) for m = \u22124 (left) and m = 0 (right). Red line is f*(X) for each setting.", "description": "This figure shows the synthetic data generated for the experiments in Section 4.1.  The left panel shows data generated under the well-specified setting (m = -4), where the underlying function f* is within the hypothesis class. The right panel shows data from the misspecified setting (m = 0), where f* lies outside of the hypothesis class.  The red line in each panel represents the true function f*(X).  The scatter plots show the observed data points (Xi, Yi). The difference in the scatter plots illustrates the impact of misspecification on the observed data.", "section": "4 Numerical Experiments"}]