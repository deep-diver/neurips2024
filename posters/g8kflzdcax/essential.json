{"importance": "This paper is crucial for researchers in decision-making under uncertainty because **it introduces a novel family of surrogate losses that overcome the limitations of existing methods, especially in misspecified settings.** This significantly improves the accuracy and efficiency of predict-then-optimize approaches, opening up new avenues for research and applications in various fields.", "summary": "New Perturbation Gradient losses connect expected decisions with directional derivatives, enabling Lipschitz continuous surrogates for predict-then-optimize, asymptotically yielding best-in-class policies even with misspecified models.", "takeaways": ["Perturbation Gradient (PG) losses are a novel family of surrogate losses for predict-then-optimize that are Lipschitz continuous and can be optimized using off-the-shelf gradient-based methods.", "Unlike existing surrogate losses, the approximation error of PG losses vanishes as the number of samples grows, guaranteeing a best-in-class policy even in misspecified settings.", "Numerical evidence shows that PG losses significantly outperform existing methods when the underlying model is misspecified."], "tldr": "Traditional predict-then-optimize methods struggle with the discontinuity of decision losses, hindering the use of gradient-based optimization.  Existing surrogates often have approximation errors that don't vanish, leading to suboptimal policies, particularly in real-world scenarios where models are often misspecified. This paper tackles these issues.\nThis research proposes Perturbation Gradient (PG) losses. PG losses connect the expected downstream decision loss to the directional derivative of a plug-in objective.  This allows for approximation via zeroth-order gradient techniques, resulting in Lipschitz continuous surrogates that can be optimized efficiently.  Crucially, the approximation error of PG losses vanishes as the number of samples increases, guaranteeing asymptotically optimal policies even when the underlying model is incorrect.  Experiments show PG losses outperform existing methods, particularly under model misspecification.", "affiliation": "UC Los Angeles", "categories": {"main_category": "AI Theory", "sub_category": "Optimization"}, "podcast_path": "g8kFlZDcaX/podcast.wav"}