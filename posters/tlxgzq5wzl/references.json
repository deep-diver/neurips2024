{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduced the concept of Neural Radiance Fields (NeRFs), a foundational technique for novel view synthesis that heavily influenced the development of the current method."}, {"fullname_first_author": "Ben Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduced Gaussian splatting, a crucial component of the proposed method, enabling efficient rendering of high-resolution 3D scenes."}, {"fullname_first_author": "Xuanchi Ren", "paper_title": "XCube: Large-scale 3D generative modeling using sparse voxel hierarchies", "publication_date": "2024-00-00", "reason": "This paper presented the XCube model, which serves as the foundation for the geometry reconstruction module in the proposed method, enabling the generation of high-resolution sparse voxel grids."}, {"fullname_first_author": "Julien Philip", "paper_title": "Lift, splat, shoot: Encoding images from arbitrary camera rigs by implicitly unprojecting to 3d", "publication_date": "2020-00-00", "reason": "This paper introduced the Lift, Splat, Shoot technique, which the authors adapted to create a sparse voxel representation from images."}, {"fullname_first_author": "Matthew Oquab", "paper_title": "DINOv2: Learning robust visual features without supervision", "publication_date": "2023-00-00", "reason": "This paper's DINOv2 model provides robust visual features which are used as input to condition the model in the proposed method for image-based geometry generation."}]}