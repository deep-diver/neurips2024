[{"figure_path": "5sm8YDnWvC/tables/tables_5_1.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of different attention mechanisms (iterative, sequential, and bi-directional) on two tasks: ImageNet classification and ModelNet40 point cloud shape classification.  It shows that the bi-directional approach achieves competitive accuracy using fewer FLOPs and parameters. The table also demonstrates the effect of adding modality-specific components to the BiXT architecture on the point cloud task. ", "section": "3.2 Attention \u2013 Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_6_1.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of BiXT against other models using different attention mechanisms (iterative, sequential, and bi-directional) on ImageNet1K and ModelNet40 datasets.  It shows that the BiXT model, which uses bi-directional cross-attention, achieves higher accuracy and efficiency. The table also demonstrates the impact of adding modality-specific components to the BiXT architecture.", "section": "3.2 Attention \u2013 Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_7_1.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of BiXT with different attention mechanisms (bi-directional vs. iterative) on ImageNet1K classification and ModelNet40 point cloud shape classification.  It shows top-1 accuracy, FLOPS, memory usage, and the number of parameters for various architectures.  The ImageNet results highlight the advantage of BiXT's bi-directional attention. The ModelNet40 results demonstrate BiXT's adaptability through the addition of modality-specific components.", "section": "3.2 Attention - Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_7_2.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of different attention mechanisms on ImageNet1K classification and ModelNet40 point cloud shape classification. It contrasts the performance of bi-directional cross-attention with iterative attention, highlighting the impact of different architectural choices on accuracy, FLOPs, memory usage, and the number of parameters.  The ImageNet results show BiXT's superiority in accuracy at a similar FLOP count compared to iterative methods. ModelNet40 results demonstrate BiXT's ability to be competitive even without modality-specific components, showing improvement when these are added.", "section": "3.2 Attention - Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_15_1.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of Bi-directional and Iterative attention mechanisms on two tasks: ImageNet1K classification and ModelNet40 point cloud shape classification.  It shows the top-1 and top-5 accuracy, FLOPs, memory usage, and number of parameters for various configurations of each attention type. The ImageNet1K results highlight the improvement achieved by Bi-directional attention over iterative methods, even when considering parameter sharing. The ModelNet40 results demonstrate the flexibility of BiXT by showing its performance with and without modality-specific components.", "section": "3.2 Attention \u2013 Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_18_1.jpg", "caption": "Table 2: Classification on ImageNet1K using \u2018few-FLOP\u2019 Transformers. Note that we focus here on efficient models in the low FLOP and/or parameter regime. Perceiver architectures are included as contrast to our bi-directional attention. All methods have been trained on input resolutions of 2242, and \u2191384 further fine-tuned on 3842. Note that different models may have received a different optimization effort. *result reproduced as not reported in original work. '(conv)' indicates the use of a convolutional tokenizer (see appendix for details).", "description": "This table compares BiXT's performance on ImageNet1K classification against other efficient transformer models, including Perceiver architectures.  It highlights BiXT's accuracy, FLOPs, and parameter counts, showcasing its efficiency compared to other models, especially at higher resolutions (384x384).  The table also differentiates between models with and without convolutional tokenizers.", "section": "3.3 Image Classification"}, {"figure_path": "5sm8YDnWvC/tables/tables_19_1.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of BiXT with different attention mechanisms (iterative, sequential, and bi-directional) on ImageNet1K classification and ModelNet40 point cloud shape classification.  It highlights the impact of bi-directional attention on accuracy and efficiency, showing that BiXT outperforms iterative approaches while being more memory-efficient and faster. The table also presents results with and without modality-specific components for BiXT on point cloud classification.", "section": "3.2 Attention \u2013 Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_19_2.jpg", "caption": "Table A1: Architectural variants using iterative attention & cross-attention parameter sharing. Classification accuracy on the ImageNet1K dataset for varying types of attention. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Cross-attention parameter sharing schemes: indicates sharing of all, of all but the 1st layer's cross-attention parameters. Architectural configurations noted in brackets. Three randomly seeded runs were performed for the 'best' architectures (judged by their performance on seed = 42), and mean and (unbiased) standard deviation are reported. One randomly seeded run reported for all other architectures.", "description": "This table compares different attention mechanisms for image classification on ImageNet. It shows the top-1 and top-5 accuracy, FLOPs, memory usage, and number of parameters for various architectures using iterative, sequential, and bi-directional cross-attention.  The results highlight the efficiency and performance gains of the bi-directional cross-attention approach.", "section": "A BiXT \u2013 General Aspects and Insights"}, {"figure_path": "5sm8YDnWvC/tables/tables_20_1.jpg", "caption": "Table A1: Architectural variants using iterative attention & cross-attention parameter sharing. Classification accuracy on the ImageNet1K dataset for varying types of attention. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Cross-attention parameter sharing schemes: indicates sharing of all, of all but the 1st layer's cross-attention parameters. Architectural configurations noted in brackets. Three randomly seeded runs were performed for the 'best' architectures (judged by their performance on seed = 42), and mean and (unbiased) standard deviation are reported. One randomly seeded run reported for all other architectures.", "description": "This table compares different attention mechanisms (iterative, sequential, and bi-directional) used in the ImageNet1K classification task.  It shows the top-1 and top-5 accuracy, FLOPs, memory usage, and the number of parameters for various architectural configurations.  The results highlight the trade-offs between accuracy, efficiency, and architectural choices.", "section": "A.4 Types of Attention \u2013 Additional Results, Visualizations and Further Explanations"}, {"figure_path": "5sm8YDnWvC/tables/tables_21_1.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of BiXT with iterative and sequential attention methods on ImageNet1k and ModelNet40 datasets.  Part (a) focuses on ImageNet1k classification accuracy, comparing different configurations of iterative attention against BiXT's bi-directional approach, highlighting the impact of FLOPs, memory usage and the number of parameters.  Part (b) shows the results on ModelNet40 point cloud shape classification, contrasting the performance of BiXT with and without additional modality-specific components.", "section": "3.2 Attention \u2013 Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_21_2.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the performance of different attention mechanisms (iterative, sequential, and bi-directional) on image classification (ImageNet) and point cloud shape classification (ModelNet40).  It shows that BiXT achieves competitive accuracy with fewer FLOPS and parameters, particularly when incorporating modality-specific components. The table highlights the trade-off between computational efficiency and performance, demonstrating BiXT's advantage in resource-constrained settings.", "section": "3.2 Attention \u2013 Iterative, Sequential or Bi-directional?"}, {"figure_path": "5sm8YDnWvC/tables/tables_23_1.jpg", "caption": "Table 1: Bi-directional vs. iterative attention. (a) Classification accuracy on ImageNet1K. All architectures use 64 latent vectors and have been trained for 120 epochs with hyperparameters individually optimized. Architectural configurations noted in brackets. \u2020indicates sharing of all, \u2021of all but the 1st layer's cross-attention parameters. Results reported as mean and (unbiased) std-dev over 3 randomly seeded training runs (see appendix for complete results). (b) Point cloud shape classification on ModelNet40. BiXT without (na\u00efve) and with modality-specific components.", "description": "This table compares the classification accuracy of different attention mechanisms on ImageNet1K and ModelNet40 datasets.  It contrasts the performance of bi-directional attention with iterative attention approaches, highlighting the efficiency and accuracy gains achieved by the proposed bi-directional cross-attention.  The table also shows the impact of adding modality-specific components to the BiXT architecture for point cloud data.", "section": "3.2 Attention \u2013 Iterative, Sequential or Bi-directional?"}]