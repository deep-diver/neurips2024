[{"figure_path": "kVr3L73pNH/tables/tables_6_1.jpg", "caption": "Table 1: Leave-K-out baseline comparisons. Given a synthesized image \\(\\hat{z}\\), we train leave-K-out models for each of the attribution methods and track \\(\\Delta L(\\hat{z}, \\theta)\\), the increase in loss change, and \\(\\Delta G_\\theta(\\epsilon, c)\\), deviation of generation. We report results over 110 samples, and gray shows the standard error. Bolded and underlined are the best and second best performing method, respectively.", "description": "This table presents a comparison of different data attribution methods using a leave-K-out evaluation strategy.  The methods are compared based on two metrics: the change in loss (\\(\\Delta L(\\hat{z}, \\theta)\\)) after removing K influential images and the deviation in generated images (\\(\\Delta G_\\theta(\\epsilon, c)\\)).  Higher \\(\\Delta L(\\hat{z}, \\theta)\\) indicates better identification of influential images, while higher deviation in generated images (measured using MSE and CLIP similarity) suggests less accurate predictions. The table shows results for different values of K, allowing analysis of method performance across varying levels of image removal.", "section": "5.1 Leave-K-out counterfactual evaluation"}, {"figure_path": "kVr3L73pNH/tables/tables_8_1.jpg", "caption": "Table 1: Leave-K-out baseline comparisons. Given a synthesized image \\textbf{z}, we train leave-K-out models for each of the attribution methods and track \\textbf{\\textDelta}L(\\textbf{z}, \\theta), the increase in loss change, and \\textbf{\\textDelta}G_{\\theta}(\\epsilon, c), deviation of generation. We report results over 110 samples, and gray shows the standard error. Bolded and underlined are the best and second best performing method, respectively.", "description": "This table compares different baselines for leave-K-out counterfactual evaluation of data attribution methods for text-to-image models.  For each of several methods (including the proposed method), the table shows the increase in loss and change in image generation quality (measured in MSE and CLIP similarity) after retraining the model without the top K most influential images identified by that method.  Higher loss and greater MSE indicate better performance of the method. The results are averaged across 110 synthesized image samples. ", "section": "5.1 Leave-K-out counterfactual evaluation"}, {"figure_path": "kVr3L73pNH/tables/tables_17_1.jpg", "caption": "Table 3: Effectiveness in Unlearning Synthesized Images. We compare different choices of unlearning algorithms and evaluate based on whether the method can forget the target images and retain other images. We measure the performance with regenerated images' deviations via mean square error (MSE) and CLIP similarity. SGD refers to the naive baseline without EWC regularization, and full weight refers to updating on all of the weights instead of cross-attention KV.", "description": "This table compares the effectiveness of different unlearning algorithms in forgetting target images while retaining other images.  The performance is measured using Mean Squared Error (MSE) and CLIP similarity on regenerated images. The results show that the proposed method (Ours) outperforms the naive baseline (SGD) and the full-weight update method, demonstrating its ability to selectively unlearn the target image without significantly affecting other images.", "section": "5 Experiments"}, {"figure_path": "kVr3L73pNH/tables/tables_18_1.jpg", "caption": "Table 4: Does leave-K-out models forget other images? We verify that leave-K-model forgets concepts specific to the target query. We report deviations (MSE, CLIP) from the target image, related images that are similar to the target, and other images of unrelated concepts. We find that target images deviate more than related and other images, while other images stay almost the same. Related images\u2019s errors increase with larger K, but they are much smaller than target images\u2019 deviations.", "description": "This table presents the results of an experiment designed to evaluate whether the leave-K-out models forget other images besides the target image. Three categories of images are evaluated: target images (the images the model is trained to forget), related images (images similar to the target), and other images (unrelated images).  The table shows that the MSE (mean squared error) for target images is significantly higher than for related and other images, and the CLIP (CLIP similarity) score is lower, indicating that the model successfully forgets the target images while retaining information about related and unrelated images.  The differences in MSE and CLIP scores between the target images and the other two image categories grow larger as the number of removed images (K) increases.", "section": "5.1 Leave-K-out counterfactual evaluation"}, {"figure_path": "kVr3L73pNH/tables/tables_19_1.jpg", "caption": "Table 1: Leave-K-out baseline comparisons. Given a synthesized image \\textbf{z}, we train leave-K-out models for each of the attribution methods and track \\textbf{\u2206L(z, \u03b8)}, the increase in loss change, and \\textbf{\u2206G(\u03b5, c)}, deviation of generation. We report results over 110 samples, and gray shows the standard error. Bolded and underlined are the best and second best performing method, respectively.", "description": "This table presents a comparison of different data attribution methods using a leave-K-out evaluation strategy.  For each of 110 synthesized images, several methods were used to identify influential training images, which were then removed to create a leave-K-out model. The table shows the increase in loss (\u2206L(z, \u03b8)) and deviation in image generation (\u2206G(\u03b5, c)) for each method, evaluated using both MSE and CLIP similarity.  The best and second-best performing methods are highlighted.", "section": "5.1 Leave-K-out counterfactual evaluation"}]