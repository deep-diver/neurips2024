{"references": [{"fullname_first_author": "Scott M Lundberg", "paper_title": "A unified approach to interpreting model predictions", "publication_date": "2017-00-00", "reason": "This paper provides a unified framework for interpreting model predictions, which is foundational to the current research on explainable AI."}, {"fullname_first_author": "Neil Jethani", "paper_title": "Have we learned to explain?: How interpretability methods can learn to encode predictions in their interpretations", "publication_date": "2021-00-00", "reason": "This paper introduces the concept of encoding explanations, which is a central focus of the current paper."}, {"fullname_first_author": "Marco Tulio Ribeiro", "paper_title": "\"why should i trust you?\" explaining the predictions of any classifier", "publication_date": "2016-00-00", "reason": "This paper introduces LIME, a popular method for explaining individual predictions, which is compared to the proposed method in this paper."}, {"fullname_first_author": "Ian Covert", "paper_title": "Explaining by removing: A unified framework for model explanation", "publication_date": "2021-00-00", "reason": "This paper proposes a unified framework for model explanation, which is used in this paper to compare different evaluation methods."}, {"fullname_first_author": "Neil Jethani", "paper_title": "Don't be fooled: label leakage in explanation methods and the importance of their quantitative evaluation", "publication_date": "2023-00-00", "reason": "This paper discusses label leakage, a problem closely related to encoding, and further motivates the need for careful evaluation of explanation methods."}]}