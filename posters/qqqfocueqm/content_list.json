[{"type": "text", "text": "Conjugated Semantic Pool Improves OOD Detection with Pre-trained Vision-Language Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Mengyuan Chen ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Junyu Gao\u2217 ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "MAIS, Institute of Automation, CAS School of Artificial Intelligence, UCAS chenmengyuan2021@ia.ac.cn ", "page_idx": 0}, {"type": "text", "text": "MAIS, Institute of Automation, CAS School of Artificial Intelligence, UCAS junyu.gao@nlpr.ia.ac.cn ", "page_idx": 0}, {"type": "text", "text": "Changsheng $\\mathbf{Xu}^{*}$   \nMAIS, Institute of Automation, CAS   \nSchool of Artificial Intelligence, UCAS Pengcheng Laboratory csxu@nlpr.ia.ac.cn ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "A straightforward pipeline for zero-shot out-of-distribution (OOD) detection involves selecting potential OOD labels from an extensive semantic pool and then leveraging a pre-trained vision-language model to perform classification on both in-distribution (ID) and OOD labels. In this paper, we theorize that enhancing performance requires expanding the semantic pool, while increasing the expected probability of selected OOD labels being activated by OOD samples, and ensuring low mutual dependence among the activations of these OOD labels. A natural expansion manner is to adopt a larger lexicon; however, the inevitable introduction of numerous synonyms and uncommon words fails to meet the above requirements, indicating that viable expansion manners move beyond merely selecting words from a lexicon. Since OOD detection aims to correctly classify input images into ID/OOD class groups, we can \"make up\" OOD label candidates which are not standard class names but beneficial for the process. Observing that the original semantic pool is comprised of unmodified specific class names, we correspondingly construct a conjugated semantic pool (CSP) consisting of modified superclass names, each serving as a cluster center for samples sharing similar properties across different categories. Consistent with our established theory, expanding OOD label candidates with the CSP satisfies the requirements and outperforms existing works by $7.89\\%$ in FPR95. Codes are available in https://github.com/MengyuanChen21/NeurIPS2024-CSP. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "The efficacy of machine learning models typically diminishes on out-of-distribution (OOD) data, thereby underscoring the significance of flagging OOD samples for caution. Traditional visual OOD detection methods are typically driven by a single image modality, leaving the rich information in textual labels untapped [21, 34, 63, 56, 11]. As pre-trained vision-language models (VLMs) develop, employing textual information in visual OOD detection has become a burgeoning paradigm [15, 12, 40, 58, 64, 43, 29]. A straightforward pipeline [29] is to select potential OOD labels from a semantic pool and leverages the text-image alignment ability of a pre-trained VLM. Specifically, potential OOD labels are selected from WordNet [39] based on their similarities to the In-distribution (ID) label space, and then CLIP [47] is employed to classify input images into ID/OOD class groups. ", "page_idx": 0}, {"type": "text", "text": "In this paper, we establish a mathematic model to describe the performance of the above pipeline. Specifically, the activation status of selected OOD labels, aka whether the similarities between OOD labels and an input image exceed an implicit threshold, can be modeled as a series of independent Bernoulli random variables [29]. Depending on the class group of the input image, we refer these as ID and OOD Bernoulli variables for short. As the proportion of selected OOD labels in the semantic pool increases, our theory indicates an inverted-V performance variation trend, which aligns with the actual observation. We further derive that the peak performance is positively correlated with two factors: the size of the semantic pool and the average expectation of the OOD Bernoulli variables. Considering the mutual influence between factors, a clear strategy for enhancing performance involves concurrently enlarging these two factors while maintaining low mutual dependence among the Bernoulli variables. As a result, with an existing semantic pool, what we need to do is to expand it with additional OOD labels which have higher and independent probabilities of being activated by OOD images. ", "page_idx": 1}, {"type": "text", "text": "A straightforward manner of semantic pool expansion is to adopt larger lexicons. However, simple lexicon expansion fails to yield consistent satisfactory outcomes, and we conclude that the inefficacy is attributed to the following reasons: On the one hand, larger lexicons bring numerous uncommon words, whose expected probabilities of being activated by OOD images are minimal, thus resulting in a reduction of the average expectation of the OOD Bernoulli variables. On the other hand, larger lexicons introduce plenty of (near-)synonyms for existing OOD label candidates, leading to a high degree of functional overlap and little benefit. The corresponding Bernoulli random variables for (near-)synonyms are highly mutual dependent, which severely violates the independence assumption required by Lyapunov central limit theorem [1], thus failing to achieve the expected enhancement. ", "page_idx": 1}, {"type": "text", "text": "The above analysis suggests that viable strategies for semantic pool expansion require moving beyond the paradigm of simply selecting labels from larger lexicons. Since the goal of OOD detection is to correctly classify input images into ID/OOD class groups, we can freely \"make up\" OOD label candidates which are not standard class names but beneficial for the process. Inspired by the fact that the original semantic pool is comprised of unmodified specific class names (e.g., \"cat\", \"wallet\", \"barbershop\"), each of which serves as a cluster center for samples from the same category but with varying properties, we correspondingly construct a conjugated semantic pool (CSP) consisting of specifically modified superclass names (e.g., \"white creature\", \"valuable item\", \"communal place\"), each of which serves as a cluster center for samples sharing similar properties across different categories. Expanding OOD label candidates with the CSP satisfies the requirements of our theoretical scheme. Specifically, since superclasses used in constructing the CSP include broad semantic objects, the property clusters encompass samples from numerous potential OOD categories. Therefore, these cluster centers, serving as OOD labels, have much higher expected probabilities of being activated by OOD samples, thus increasing the average expectation of the OOD Bernoulli variables. Furthermore, the distribution of these property cluster centers in the feature space is distinctly different from that of the original category cluster centers, resulting in a relatively low mutual dependence between the new and original labels. Consistent with the established theory, our method outperforms the SOTA method NegLabel [29] with an improvement of $7.89\\%$ in FPR95, which underscores the efficacy of our method. Our contributions include: ", "page_idx": 1}, {"type": "text", "text": "\u2022 A theoretical scheme for improving OOD detection with pre-trained VLMs (Section 3.1). We derive that an unequivocal strategy for performance enhancement requires concurrently increasing the semantic pool size and the expected activation probability of OOD labels and ensuring low mutual dependence among the activations of selected OOD labels. \u2022 An analysis of the inefficacy of simple lexicon expansion (Section 3.2). We attribute the inefficacy to the introduction of numerous uncommon words and (near-)synonyms, which respectively reduces the expected activation probabilities of OOD labels and brings severe mutual dependence, thereby failing to achieve theoretical enhancement. \u2022 An expansion manner beyond selecting labels from existing lexicons (Section 3.3). We construct an additional conjugated semantic pool (CSP), consisting of modified superclass names, each serving as a cluster center for samples with similar properties across different categories. Consistent with our established theory, expanding OOD label candidates with the CSP satisfies the requirements and achieves satisfactory performance improvements. \u2022 Extensive experiments and related analysis on multiple OOD detection benchmarks with state-of-the-art performances (Section 5), which demonstrate the effectiveness of our method. ", "page_idx": 1}, {"type": "text", "text": "Proof and derivations, visualizations, additional experiment results and details are given in Appendix. ", "page_idx": 1}, {"type": "text", "text": "Task setup. OOD detection leveraging pre-trained vision-language models (VLMs), also termed as zero-shot OOD detection [15, 12, 40, 58, 64, 43, 29], aims to identify OOD images from ID ones with only natural-language labels of ID classes available. Formally, given the testing image set ${\\mathcal X}={\\mathcal X}^{\\mathrm{in}}\\cup{\\mathcal X}^{\\mathrm{out}}$ , where $\\mathcal{X}^{\\mathrm{in}}\\cap\\mathcal{X}^{\\mathrm{out}}=\\emptyset$ , and ID label (class name) set $\\bar{\\mathcal{D}}^{\\mathrm{in}}=\\{y_{1},\\ldots,\\bar{y}_{K}\\}$ , where $K$ is the number of ID classes, our target is to obtain an OOD detector $G(x;\\mathcal{V}^{\\mathrm{in}}):\\mathcal{X}\\rightarrow\\{\\mathrm{in},\\mathrm{out}\\}$ , where $x\\in\\mathscr{X}$ denotes a test image. It is noteworthy that the zero-shot setting does not require that there be no overlap between the pre-training data of VLMs and the testing data $\\mathcal{X}$ , but only stipulates that no ID images are available for model fine-tuning. In other words, the split of ID and OOD data completely depends on how users manually preset the ID label set $\\mathcal{V}_{\\mathrm{in}}$ . ", "page_idx": 2}, {"type": "text", "text": "OOD detection with a pre-trained VLM and a semantic pool. A straightforward pipeline of this task is to select potential OOD labels from a semantic pool and leverages the text-image alignment ability of a pre-trained VLM to perform zero-shot OOD detection [29]. Specifically, there are three steps: (1) Fetching numerous words from a semantic pool like WordNet [39] as OOD label candidates; (2) Selecting a portion of OOD label candidates most dissimilar to the entire ID label space; (3) Employing a pre-trained VLM like CLIP [47] to obtain similarities between testing images and ID/OOD labels and then performing OOD detection with a designed OOD score. ", "page_idx": 2}, {"type": "text", "text": "The OOD detection performance of this pipeline can be modeled as follows [29]. Given the selected OOD label set $\\mathcal{V}^{\\mathrm{out}}=\\:\\{z_{1},\\ldots,z_{m}\\}$ , $0\\,<\\,m\\,\\leq\\,M$ , where $m$ is the number of selected OOD labels, and $M$ is the size of the semantic pool. By applying a threshold $\\psi$ , we can naturally define $p_{i}^{\\mathrm{in}}=P(s_{i}\\geq\\psi|f,z_{i},\\chi^{\\mathrm{in}})$ as the probability of classifying ID input images $x\\in\\chi^{\\mathrm{in}}$ as positive for the given label $z_{i}$ , where $s_{i}=\\bar{\\mathrm{sim}}(f(x),\\dot{f}(z_{i}))$ is the similarity score given by the pre-trained model $f$ . To derive an analytic form for the model\u2019s OOD detection performance, we employ a straightforward OOD score function $S(x)$ , aka the total positive count across categories for a sample $x$ . Specifically, $\\begin{array}{r}{S(x^{\\mathrm{in}})=\\sum_{i}s_{i}^{\\mathrm{in}}}\\end{array}$ , where $s_{i}^{\\mathrm{in}}$ is a Bernoulli random variable with parameter $p_{i}^{\\mathrm{in}}$ , i.e., the probability of $s_{i}^{\\mathrm{in}}=1$ is $p_{i}^{\\mathrm{in}}$ and the probability of $s_{i}^{\\mathrm{in}}=0$ is $1-p_{i}^{\\mathrm{in}}$ . Consequently, $S(x^{\\mathrm{in}})$ follows a Poisson binomial distribution with parameters $\\{p_{1}^{\\mathrm{in}},...,p_{m}^{\\mathrm{in}}\\}$ . $p_{i}^{\\mathrm{out}}$ and $S(x^{\\mathrm{out}})$ are defined similarly. Based on the Lyapunov central limit theorem (CLT) [1], we can obtain the following lemma: ", "page_idx": 2}, {"type": "text", "text": "Lemma 1. Given independent Bernoulli random variables $\\{s_{1},...,s_{m}\\}$ with parameters $\\{p_{1},...,p_{m}\\}$ , where $0<p_{i}<1$ , as m goes to infinity, the Poisson binomial random variable $C=\\textstyle\\sum_{i=1}^{m}s_{i}$ converges in distribution to a normal random variable with distribution $\\begin{array}{r}{\\mathcal{N}\\left(\\sum_{i=1}^{m}p_{i},\\sum_{i=1}^{m}p_{i}(\\bar{1}-p_{i})\\right)}\\end{array}$ . ", "page_idx": 2}, {"type": "text", "text": "According to Lemma 1, proved in Appendix A.1, the distribution of $C^{\\mathrm{in}}$ can be approximated as $\\begin{array}{r}{C^{\\mathrm{in}}\\sim\\mathcal{N}\\left(\\sum_{i=1}^{m}p_{i}^{\\mathrm{in}},\\sum_{i=1}^{m^{\\star}}p_{i}^{\\mathrm{in}}(1-p_{i}^{\\mathrm{in}})\\right)}\\end{array}$ , and the distribution of $C^{\\mathrm{out}}$ can be approximated similarly. By denoting $q_{1}=\\mathbb{E}_{i}[p_{i}^{\\mathrm{in}}]$ , $v_{1}=\\mathrm{Var}_{i}[p_{i}^{\\mathrm{in}}]$ , $q_{2}=\\mathbb{E}_{i}[p_{i}^{\\mathrm{out}}]$ , $v_{2}=\\mathrm{Var}_{i}[p_{i}^{\\mathrm{out}}]$ , we have ", "page_idx": 2}, {"type": "equation", "text": "$$\nC^{\\mathrm{in}}\\sim\\mathcal{N}\\left(m q_{1},m q_{1}(1-q_{1})-m v_{1}\\right),C^{\\mathrm{out}}\\sim\\mathcal{N}\\left(m q_{2},m q_{2}(1-q_{2})-m v_{2}\\right).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Thereafter, with the derivation provided in Appendix A.2, we can obtain the closed-form expression of one of the most commonly adopted OOD performance metric, aka the false positive rate (FPR) when the true positive rate (TPR) is $\\lambda\\in[0,1]$ , denoted by $\\mathrm{FPR}_{\\lambda}$ , as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathrm{FPR}_{\\lambda}=\\frac{1}{2}+\\frac{1}{2}\\cdot\\mathrm{erf}\\left(\\sqrt{\\frac{q_{1}(1-q_{1})-v_{1}}{q_{2}(1-q_{2})-v_{2}}}\\mathrm{erf}^{-1}\\left(2\\lambda-1\\right)+\\frac{\\sqrt{m}(q_{1}-q_{2})}{\\sqrt{2q_{2}(1-q_{2})-2v_{2}}}\\right),\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\begin{array}{r}{\\operatorname{erf}(x)=\\frac{2}{\\sqrt{\\pi}}\\int_{0}^{x}e^{-t^{2}}d t}\\end{array}$ . However, contrary to the monotonic trend suggested by Eqn. 2, the actual performances in experiments exhibit an inverted- $\\mathrm{v}$ trend as the ratio of selected OOD labels in the semantic pool increases. Therefore, we further optimize the mathematic model by incorporating finer-grained variable relationships, seeking theoretical guidance for performance enhancement. ", "page_idx": 2}, {"type": "text", "text": "3 Methodology ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 A Theoretical Scheme for Performance Enhancement ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Since selecting OOD labels is typically based on the reverse-order of similarities to the ID label space to minimize semantic overlap, i.e., the most dissimilar OOD label candidates are most likely to be selected, the expected probability, $q_{1}$ , of OOD labels being activated by ID images is not static. Specifically, as the ratio of selected OOD labels $r=m/M$ increases, the expected activation probability $q_{1}=\\dot{\\mathbb{E}}_{i}[p_{i}^{\\mathrm{in}}]$ of existing OOD labels for ID images will monotonically increase, since more OOD labels with higher affinities to ID labels are selected. When all labels in the semantic pool are finally selected, $q_{1}$ will achieve $q_{2}$ , which means the expected probabilities of OOD labels being activated by ID and OOD images are close. Meanwhile, $q_{2}$ is considered as a constant when the semantic pool is fixed and the ratio $r$ varies, since whether an element in the pool (excluding ID labels) corresponds to a potential OOD sample is independent of its similarity to the ID label space. Formally, defining $q_{0}$ as the lower bound of $q_{1}$ , we model the accumulated increase in $q_{1}$ as the ratio $r$ increases from zero with the function $u(r)$ , which exhibits following properties: ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nu(r)=q_{1}(r)-q_{0},\\;u(r=0|q_{0},q_{2})=0,\\;u(r=1|q_{0},q_{2})=q_{2}-q_{0}>0,\\;u^{\\prime}(r)\\geq0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Besides, we assume that the absolute value of the curvature of $u$ is constrained within a specific range, thereby preventing abrupt changes in the trend of $u$ , which facilitates subsequent analysis. With $u(r)$ , we set $\\lambda=0.5$ in Eqn. 2 for convenience and then explore the properties of ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{FPR}_{0.5}=\\frac{1}{2}+\\frac{1}{2}\\cdot\\mathrm{erf}\\left(\\sqrt{\\frac{m}{2}}\\cdot\\frac{q_{0}-q_{2}+u(r|q_{0},q_{2})}{\\sqrt{q_{2}(1-q_{2})-v_{2}}}\\right).\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Denote z =  2 \u00b7\u221aq20(1\u22122q2)\u2212v2 , from Eqn. 4, we can derive that the first-order derivative of $\\mathrm{FPR}_{0.5}$ , denoted as $G(r)$ , can be expressed as ", "page_idx": 3}, {"type": "equation", "text": "$$\nG(r|q_{0},q_{2},u,M)=\\frac{\\partial\\mathrm{FPR}_{0.5}}{\\partial r}=\\frac{M e^{-z^{2}}}{2\\sqrt{2\\pi}}\\cdot\\frac{q_{0}-q_{2}+u+2r u^{\\prime}}{\\sqrt{m}\\sqrt{q_{2}(1-q_{2})-v_{2}}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which can be further proved to monotonically increase over the interval $(0,1]$ with respect to $r$ with the above assumptions. Besides, according to Eqn. 5, we can obtain that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{r\\to0^{+}}G(r)=\\operatorname*{lim}_{r\\to0^{+}}\\frac{\\kappa(q_{0}-q_{2})}{2\\sqrt{r}}=-\\infty,\\quad\\operatorname*{lim}_{r\\to1}G(r)=\\kappa u^{\\prime}(r=1)\\geq0,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "equation", "text": "$\\kappa=(M/2\\pi)^{\\frac{1}{2}}(q_{2}(1-q_{2})-v_{2})^{-\\frac{1}{2}}e^{-z^{2}}>0.$ ", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Since $\\mathrm{FPR}_{0.5}(r)$ is a continuous function within our framework and satisfies Eqn. 6, it can be deduced that there exists a value $r_{0}\\in(0,1]$ where $\\mathrm{FPR}_{0.5}$ reaches its minimum. Furthermore, $\\mathrm{FPR_{0.5}}$ monotonically decreases over the interval $(0,r_{0}]$ and increases over the interval $[r_{0},1]$ . Since $\\mathrm{FPR}_{\\lambda}$ is a smooth continuous function with respect to $\\lambda$ , we deduce that $\\mathrm{FPR}_{\\lambda}$ and $\\mathrm{FPR_{0.5}}$ share similar trends as the parameter $r$ varies, which aligns with the actual results presented in Fig. 1. A more detailed calculation process from Eqn. 4 to Eqn. 6 is provided in Appendix A.3. ", "page_idx": 3}, {"type": "text", "text": "Subsequently, we delve deeper into the factors influencing the optimal value of the OOD detection performance evaluated by $\\mathrm{FPR}_{0.5}(r)$ . When $r$ reaches the critical point $r_{0}$ , the expected performance improvement resulting from \"OOD samples being correctly identified due to the addition of new OOD labels\" will be equal to the performance degradation caused by \"ID samples being misclassified due to the addition of new OOD labels\". As a result, the model performance achieves its peak. Specifically, from Eqn. 5, it can be inferred that $r_{0}$ satisfies ", "page_idx": 3}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/3fc0dcd79a8ada4a411fd6e829c7438307c2014f0ef93210d41095ddf6699db6.jpg", "img_caption": ["Figure 1: Model performances evaluated by FPR50 and FPR95 (lower is better) of our method and NegLabel against the ratio $r$ , which exhibit a trend of initial decline followed by an increase. Detailed results can be found in Table 8. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nq_{0}-q_{2}+u(r_{0}|q_{0},q_{2})+2r_{0}u^{\\prime}(r_{0}|q_{0},q_{2})=0.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Given the complex interdependencies among the variables in the above equation, it is challenging to derive any definitive conclusions with the undefined form of the function $u$ . Consequently, we simplify by assuming that the function $u(r)$ is linear. Under this assumption, by substituting Eqn. 7 into Eqn. 4, we obtain that the optimal value of $\\mathrm{FPR_{0.5}}$ can be expressed as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{FPR}_{0.5}(r_{0})=\\frac{1}{2}+\\frac{1}{2}\\cdot\\mathrm{erf}\\left(-\\frac{(2M)^{\\frac{1}{2}}r_{0}^{\\frac{3}{2}}(q_{2}-q_{0})}{\\sqrt{q_{2}(1-q_{2})-v_{2}}}\\right),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the variables $M$ and $q_{2}$ , aka the semantic pool size and the expected probability of OOD labels being activated by OOD samples, are the predominant factors influencing the right side of the equation. The other variables $q_{0},r_{0}$ , and $v_{2}$ remain nearly constant with a sufficiently large semantic pool (refer to Appendix A.4 for analysis), thus exerting marginal impact. ", "page_idx": 4}, {"type": "text", "text": "If we disregard the interdependencies among the variables, the impact of $M$ and $q_{2}$ on the optimal value of $\\mathrm{FPR}_{0.5}$ is straightforward: (1) With $q_{2}$ fixed, it can be easily observed that $\\mathrm{FPR}_{0.5}(r_{0})$ monotonically decreases with $M$ . (2) With $M$ fixed, and denoting the input to the erf $\\left(\\cdot\\right)$ function as $\\zeta$ , it can be derived from Eqn. 8 that, ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathrm{FPR}_{0.5}(r_{0})}{\\partial q_{2}}=\\frac{1}{2}\\cdot\\frac{\\partial\\mathrm{erf}(\\zeta)}{\\partial\\zeta}\\cdot\\frac{\\partial\\zeta}{\\partial q_{2}}=-\\sqrt{\\frac{M r_{0}^{3}}{2\\pi}}\\cdot\\frac{e^{-\\zeta^{2}}(q_{2}+q_{0}-2q_{0}q_{2}-2v_{2})}{(q_{2}(1-q_{2})-v_{2})^{\\frac{3}{2}}}\\leq0\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "holds in almost all practical cases (see Appendix A.5 for analysis), thus $\\mathrm{FPR}_{0.5}(r_{0})$ also monotonically decreases with respect to $q_{2}$ . However, in real-world scenarios, the complex interactions between $M$ and $q_{2}$ prevent either variable from being adjusted in isolation. For instance, utilizing a larger lexicon to expand the size $M$ of the semantic pool may cause a decline in $q_{2}$ (see Section 3.2). Conversely, discarding candidates with lower activation probabilities to elevate $q_{2}$ leads to a reduction of $M$ . The variable changes in both strategies exert opposing effects, ultimately leading to minimal improvements or even degradation in model performance. Besides, the Lyapunov central limit theorem (CLT) used in proof of Lemma 1 requires that the activations of selected OOD labels are independent. Although complete independence is impossible to achieve in real-world scenarios, it is essential to maintain a relatively low level of mutual dependence to reduce the errors in theoretical derivations. Therefore, an unequivocal strategy for performance enhancement is concurrently increasing the variables $M$ and $q_{2}$ and ensuring that there is no strong dependence among the activations of selected OOD labels. With an existing semantic pool, what we need to do is to expand it with additional OOD labels which have higher and independent probabilities of being activated by OOD images. ", "page_idx": 4}, {"type": "text", "text": "3.2 A Closer Look at the Inefficacy of Simple Lexicon Expansion ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Therefore, it is time to consider how to expand the original semantic pool, which already includes most common words, while ensuring the increase of $q_{2}$ and low mutual dependence. The most straightforward strategy for expansion, adopting larger existing lexicons, fails to consistently yield satisfactory outcomes, as shown in Fig. 2. Subsequently, we analyze that the inefficacy of simple lexicon expansion is attributed to the following reasons. ", "page_idx": 4}, {"type": "text", "text": "On the one hand, larger lexicons bring numerous uncommon words, whose expected probability of being activated by OOD images are minimal, thus resulting in a reduction of $\\mathbf{{q_{2}}}$ . As derived in Section 3.1, the decrease of $q_{2}$ attenuates the performance improvements yielded by enlarging $M$ . There are two potential reasons for the activation probability $p_{i}^{\\mathrm{out}}$ of an uncommon OOD label $z_{i}$ being minimal: (1) Pre-trained VLMs lack semantic matching capability for label $z_{i}$ . This issue is particularly pronounced when $z_{i}$ pertains to concepts such as highly abstract notions (e.g., \"idealism\", \"metaphysics\"), complex mathematical concepts (e.g., \"Lyapunov condition\", \"central limit theorem\"), or specific knowledge of individuals (e.g., personal names excluding celebrities). Pre-trained VLMs are unable to recognize the corresponding content of these text inputs, resulting in $p_{i}^{\\mathrm{out}}$ remaining close to zero. (2) The set ${\\mathcal{X}}^{\\mathrm{out}}$ lacks testing samples similar to label $z_{i}$ . For instance, when the test dataset primarily consists of images of everyday items, new labels constructed from astronomical terms are likely to maintain $p_{i}^{\\mathrm{out}}$ close to zero. 2 The above scenarios are much more prevalent in lexicons of uncommon terms than those of common words. Thereafter, a larger proportion of labels with minimal activation probability $p_{i}^{\\mathrm{out}}$ will diminish $q_{2}=\\mathbb{E}_{i}[p_{i}^{\\mathrm{{out}}}]$ , thus attenuating the performance improvement. ", "page_idx": 4}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/4f603b2c653416488eef8ff475d34b02cb66fea501ce79a0d9fb97cf4ff30c9d.jpg", "img_caption": ["Figure 2: Model performances evaluated by FPR95 (lower is better) with lexicons of different sizes. Detailed results can be found in Table 9. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "On the other hand, larger lexicons introduce plenty of synonyms and near-synonyms for existing OOD label candidates, leading to a high degree of functional overlap with little additional benefit. ", "page_idx": 4}, {"type": "text", "text": "For example, the common word \"smartphone\" can be expanded by adding synonyms such as \"mobile phone\" and \"cellphone\". However, the selection results for these words are consistent due to their similar meanings, and if they are selected, the activation of these labels still depends solely on the presence of a smartphone in the input image. This demonstrates a high level of mutual dependency and provides little additional benefti compared to only including \"smartphone\" in the semantic pool. Despite no reduction in $q_{2}$ , the corresponding Bernoulli random variables for synonyms, representing whether they are activated by an input OOD image, severely violate the independent assumption required by Lemma 1. Although the Lyapunov CLT used in proof of Lemma 1 relaxes the requirement for random variables to have strictly identical distributions as mandated by the traditional CLT, it still requires that the variables maintain mutual independence. Despite the random variables corresponding to semantically dissimilar labels are not strictly independent, the intensity of their mutual dependency is generally much lower than that observed in (near-)synonyms. Contrarily, synonyms and nearsynonyms lead to significant bias in the approximation of Eqn. 1 and the conclusions derived, thereby failing to achieve the theoretical enhancement. ", "page_idx": 5}, {"type": "text", "text": "3.3 Expanding Label Candidates with Conjugated Semantic Pool ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "The above analysis suggests that viable strategies for semantic pool expansion require moving beyond the paradigm of simply selecting labels from a lexicon. Since the goal of OOD detection is to correctly classify input images into ID/OOD class groups, we can freely \"make up\" OOD label candidates which are not standard class names but beneficial for the process. Inspired by the fact that the original semantic pool is comprised of unmodified specific class names, each of which serves as a cluster center for samples from the same category but with varying properties, we correspondingly construct a conjugated semantic pool (CSP) consisting of specifically modified superclass names, each of which serves as a cluster center for samples sharing similar properties across different categories. ", "page_idx": 5}, {"type": "text", "text": "We notice that a class name inherently encompasses a broad semantic range. As shown in the bottom right of Fig. 3, when an image is attached with the class label \"cat\", it actually depicts one of various more specific situations, such as a \"white cat\", \"tabby kitten\", \"gray cat\", \"yawning cat\", or \"cat on a mat\", etc. Considering all feature points that correspond to more specific descriptions of cats as a cluster within the feature space, the feature point of \"cat\" can be regarded as its cluster center. ", "page_idx": 5}, {"type": "text", "text": "In an ideal scenario, each input image in the feature space would be closest (most similar) to the cluster center that corresponds to its category, thereby achieving perfect OOD identification. However, the following issues impair the ideal case: (1) Due to the limited capabilities of pre-trained VLMs, some OOD images, such as \"white polar bear\" in Fig. 3, are closer to incorrect cluster centers than to the correct ones. (2) Owing to the limited scope of lexicons and the inaccuracy of label selection, the category name corresponding to an OOD image, such as \"white peacock\" in Fig. 3, may not exist in selected labels, resulting in the absence of an appropriate cluster center. To summarize briefly: not every input OOD image locates close to a correct OOD cluster center. ", "page_idx": 5}, {"type": "text", "text": "Thereafter, it naturally occurs to us that we should construct more suitable cluster centers to attract such \"homeless\" OOD images. This is why we expand the original semantic pool by constructing the CSP as follows: Instead of specifying concrete category names (e.g., \"cat\", \"wallet\", \"barbershop\"), we utilize superclass names to encompass a wider range of categories (e.g., \"creature\", \"item\", \"place\"); Instead of leaving category names undecorated, we using adjectives from a lexicon as modifiers to attract objects sharing similar properties. As a result, we obtain numerous label candidates of random combinations of adjectives and superclasses (e.g., \"white creature\", \"valuable item\", \"communal place\"). As Fig. 3 shows, in the feature space, \"white creature\" can be considered as the cluster center of all feature points corresponding to creatures modified by \"white\", such as \"white cat\", \"white butterfly\", \"white polar bear\", etc. Note that the semantic scopes of label candidates in the CSP may overlap with ID categories. For example, when $^{\\prime\\prime}C a t^{\\prime\\prime}$ or \"Butterfly\" in Fig. 3 are included in ID classes, the label candidate \"White Creature\" in the CSP may not be selected as an OOD label. ", "page_idx": 5}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/a5c51583f3eb47bd6ced5e192b8fab8d5cfe28f768344cbfc03d4d833096db04.jpg", "img_caption": ["Figure 3: An illustrative diagram of an element in the conjugated semantic pool (CSP). Category names can be regarded as the centers of category clusters. Similarly, elements in CSP can be considered as cluster centers of superclass objects with similar properties. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Consistent with our established theory, our proposed method achieves satisfactory performance improvements by concurrently enlarging the semantic pool size $M$ and the expected activation probability $q_{2}$ of OOD labels and ensuring that there is no severe mutual dependence among the activations of selected OOD labels. Firstly, when we expand the original semantic pool with the CSP, the enlargement of $M$ is obvious. Then, since the superclasses used in constructing the CSP typically include broad semantic objects, the property clusters encompass samples from numerous potential OOD categories. Therefore, their centers have much higher expected probabilities of being activated by OOD samples, which brings an increase in $q_{2}$ . Furthermore, the distribution of these property cluster centers in the feature space is distinctly different from that of the original category cluster centers. As a result, the mutual dependence between the new and original labels is relatively low, and the functions of labels from the CSP will not be overshadowed, enhancing the likelihood that an OOD image locates close to a correct OOD cluster center. Experiment results and analysis which support the above claims are provided in Appendix C.1. ", "page_idx": 6}, {"type": "text", "text": "4 Related works ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Traditional visual OOD detection. Traditional visual OOD detection methods, driven by the single image modality, can be broadly categorized into four distinct types: (1) Output-based methods, which aims to obtain improved OOD scores from network output, can be further classified into post-hoc methods [21, 34, 25, 54, 55, 44, 38] and training-based ones [10, 23, 57, 26, 71, 65, 30]. (2) Density-based methods [37, 49, 53, 67, 11] explicitly model the ID data with probabilistic models and identify test data located in regions of low density as OOD. (3) Distance-based methods [32, 51, 63, 56, 41, 7, 70, 59, 24, 18] originate from the core idea that OOD samples should be relatively far away from ID prototypes or centroids. (4) Reconstruction-based methods [76, 69, 28, 33], which employ an encoder-decoder framework trained on ID data, leverage the performance discrepancies between ID and OOD samples as indicators for anomaly detection. Furthermore, numerous studies [52, 72, 14, 42, 6] offer theoretical contributions. ", "page_idx": 6}, {"type": "text", "text": "OOD detection leveraging pre-trained VLMs. By adopting pre-trained VLMs, employing textual information in visual OOD detection has become a burgeoning paradigm with remarkable performance [15, 12, 40, 58, 64, 43, 29]. Fort et al.[15] propose to feed the names of potential outlier classes to image-text pre-trained transformers like CLIP [47] for OOD detection. ZOC [12] extends CLIP with a text-based image description generator to output OOD label candidates for testing. MCM [40] simply adopts maximum predicted softmax value as the OOD score, which is an effective and representative post-hoc OOD detection method based on vision-language pre-training. Based on MCM, NPOS [58] generates artificial OOD training data and facilitates learning a reliable decision boundary between ID and OOD data. CLIPN [64] trains a text encoder to teach CLIP to comprehend negative prompts, effectively discriminating OOD samples through the similarity discrepancies between two text encoders and the frozen image encoder. Also based on CLIP, LSN [43] constructs negative classifiers by learning negative prompts to identify images not belonging to a given category. NegLabel [29] proposes a straightforward pipeline, that is, selecting potential OOD labels from an extensive semantic pool like WordNet [39], and then leveraging a pre-trained VLM like CLIP to classify input images into ID/OOD class groups. In this study, we explore the theoretical requirements for performance enhancement in this pipeline, and thus construct a conjugated semantic pool to expand OOD label candidates, which achieves performances improvements as expected. ", "page_idx": 6}, {"type": "text", "text": "Further discussion about NegLabel. NegLabel [29] undertakes a rudimentary theoretical analysis of the correlation between OOD detection performance and the quantity of adopted potential labels, concluding that an increase in selected labels correlates with enhanced performance. However, this conclusion contradicts the observed actual trend. The contradiction arises from that [29] simply assume a constant higher similarity between OOD labels and OOD images compared to ID images, neglecting that this similarity discrepancy originates from the strategy of reverse-order selection of OOD labels based on their similarity to the ID label space. As the set of selected OOD labels transitions from \"a small subset of labels with the lowest similarity to the entire ID label space\" to \"the whole semantic pool, which is unrelated to the setting of ID and OOD labels\", the discrepancy in similarity of ID images to OOD labels versus OOD images to OOD labels will progressively diminish until it disappears. Incorporating the above dynamic to optimize the mathematic model, we focus on the correlation between OOD detection performance and the ratio of selected OOD labels in the semantic pool, seeking theoretical guidance for performance enhancement. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "5.1 Experiment Setup ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Benchmarks. We mainly evaluate our method on the widely-used ImageNet-1k OOD detection benchmark [26]. This benchmark utilizes the large-scale ImageNet-1k dataset as the ID data, and select samples from iNaturalist [60], SUN [66], Places [73], and Textures [8] as the OOD data. The categories of the OOD data have been manually selected to prevent overlap with ImageNet-1k. Furthermore, we conduct experiments on hard OOD detection tasks, or with various ID datasets. Besides, we access whether our method generalizes well to different VLM architectures, including ALIGN [27], GroupViT [68], EVA [13], etc. More details of datasets can be found in Appendix B. ", "page_idx": 7}, {"type": "text", "text": "Implementation details. Unless otherwise specified, we employ the CLIP ViT-B/16 model as the pre-trained VLM and WordNet as the lexicon. The superclass set for constructing the conjugated semantic pool is {area, creature, environment, item, landscape, object, pattern, place, scene, space, structure, thing, view, vista}, which nearly encompasses all real-world objects. The ablation in Appendix C.5 shows that numerous alternative selections can also yield significant performance improvements. All hyper-parameters are directly inherited from [29] without any modification, including the ratio $r$ which is set to $15\\%$ . Additionally, we adopt the same NegMining algorithm, OOD score calculation method, and grouping strategy as described in [29]. All experiments are conducted using GeForce RTX 3090 GPUs. ", "page_idx": 7}, {"type": "text", "text": "Prompt ensemble. We use the following prefixes to construct prompts for labels in the original semantic pool: the, the good (nice), a photo of (with) the nice, a good (close-up) photo of the nice. For labels in the conjugated semantic pool, we apply the prefixes: a nice (good, close-up) photo of. The baseline results reported in the ablation study (see Table 3) also utilize this technique. ", "page_idx": 7}, {"type": "text", "text": "Computational cost. The prompt ensemble is constructed over the embedding space to avoid any additional inference cost. Similar to NegLabel, our method is a post hoc OOD detector with negligible extra computational burden, which introduces $<1\\%$ network forward latency. ", "page_idx": 7}, {"type": "text", "text": "Evaluation metrics. Following previous works [40, 29, 64], we adopt the following metrics: the area under the receiver operating characteristic curve (AUROC), and the false positive rate of OOD data when the true positive rate of ID data is $95\\%$ (FPR95) [46]. ", "page_idx": 7}, {"type": "text", "text": "5.2 Evaluation on OOD detection benchmarks ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Evaluation on ImageNet-1k OOD detection benchmark. We compare our method with existing OOD detection methods on the ImageNet-1k benchmark organized by [26] in Table 1. The methods listed in the upper section of Table 1, ranging from MSP [21] to VOS [11], represent traditional visual OOD detection methods. Conversely, the methods in the lower section, extending from ZOC [12] to NegLabel [29], employ pre-trained VLMs like CLIP. It is evident that the integration of textual information through VLMs has increasingly become the predominant paradigm. Our method outperforms the baseline method NegLabel with a considerable improvement of $1.55\\%$ in AUROC and $7.89\\%$ in FPR95, which underscores the efficacy of our method. The reported results are averaged from runs of 10 different random seeds, whose results are provided in Appendix C.2. ", "page_idx": 7}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/222b82449c5ec0cc9eaccaea33ba61df6e9090928b2e08f5158d32bf333526cc.jpg", "table_caption": ["Table 1: Comparative performance of OOD detection across baseline methods utilizing CLIP ViTB/16 architecture with ImageNet-1k as ID data. Performance metrics are presented as percentages. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/1582b20380642bb578c9200c58056e295b75c7ff16d81eb895ea883f4fb9b4ae.jpg", "table_caption": ["Table 2: OOD detection performance comparison on hard OOD detection tasks "], "table_footnote": [], "page_idx": 8}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/13429bf55e2d22fa88125944809a71ccbbaaf7a32c635dbc3d018af3be2388d4.jpg", "table_caption": ["Table 3: Ablation study with CLIP (ViT-B/16) as the backbone on ImageNet-1k as ID. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Evaluation on hard OOD detection tasks. Following [40], we also evaluate our method on the hard OOD detection tasks in Table 2. The results of NegLabel [29] are reproduced with its released setting. Our method shows consistently high performances on various hard ID-OOD dataset pairs. ", "page_idx": 8}, {"type": "text", "text": "Evaluation with various ID datasets. We also experiment on various ID datasets, including StanfordCars [31], CUB-200 [61], Oxford-Pet [45], Food-101 [2], ImageNet-Sketch [62], ImageNet-A [22], ImageNet-R [20], ImageNetV2 [48], etc. Refer to Appendix C.3 for details. ", "page_idx": 8}, {"type": "text", "text": "5.3 Empirical evidence supporting our assertions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Performance trends related to the ratio $r$ . In Fig. 1 and Table 8 (Appendix C.4), we present the FPR performances of our method and NegLabel against a progressively increasing ratio $r$ , which represents the proportion of selected OOD labels in the whole semantic pool. The color gradations displayed in the table clearly illustrate an initial improvement in model performance followed by a subsequent decline as the ratio $r$ increases. This trend aligns with our derivation in Section 3.1. ", "page_idx": 8}, {"type": "text", "text": "Inefficacy of simple lexicon expansion. In Fig. 2 and Table 9 (Appendix C.4), we assess whether adopting larger lexicons enhances performances. Our findings indicate that it does not always hold. When the semantic pool covers the vast majority of common words, further expansion will introduce an excessive number of uncommon words and (near-)synonyms, thus failing to meet the derived requirements for theoretical performance enhancement. The inefficacy of simple lexicon expansion indicates that viable expansion manners move beyond merely selecting words from existing lexicons. ", "page_idx": 8}, {"type": "text", "text": "Validation of consistency between methodology and theory. Refer to Appendix C.1. ", "page_idx": 8}, {"type": "text", "text": "5.4 Ablation study ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Ablation of different semantic pool components. As shown in Table 3, we explore the effect of three semantic pool components: (1) the original semantic pool, which consists exclusively of specific class names; (2) simple adjective labels employed by NegLabel; and (3) our conjugated semantic pool (CSP). The results demonstrate that the CSP consistently outperforms the simple adjective labels. Furthermore, the highest average performance across the four OOD datasets is achieved when the CSP is employed to expand the original semantic pool. ", "page_idx": 8}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/0fd07f57f2fee2476811a52891ba16e4ca061d3fd4e85715730dbc2b42375b3a.jpg", "table_caption": ["Table 4: Performances of OOD detection with different CLIP architectures on ImageNet-1k as ID "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Analysis of different CLIP architectures. Table 4 shows that our proposed method consistently outperforms the baseline method NegLabel by a large margin with differernt CLIP architectures, which demonstrates our effectiveness. ", "page_idx": 9}, {"type": "text", "text": "Ablation of different superclass sets. Refer to Appendix C.5 for details. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Summary. In this paper, we propose that enhancing the performance of zero-shot OOD detection theoretically requires: (1) concurrently increasing the semantic pool size and the expected activation probability of selected OOD labels; (2) ensuring low mutual dependence among the label activations. Furthermore, we analyze that the inefficacy of simply adopting larger lexicons is attributed to the introduction of numerous uncommon words and (near-)synonyms, thus failing to meet the above requirements. Observing that the original semantic pool is comprised of unmodified specific class names, we correspondingly construct a conjugated semantic pool consisting of specifically modified superclass names, each serving as a cluster center for samples sharing similar properties across different categories. Consistent with the established theory, expanding OOD label candidates with the conjugated semantic pool satisfies the requirements and achieves considerable improvements. ", "page_idx": 9}, {"type": "text", "text": "Limitations and Future directions. Our method has following limitations worth further exploration: (1) The effectiveness of CSP depends on the implicit assumption that the OOD samples exhibit a variety of distinct visual properties. When this assumption does not hold, i.e., OOD samples most share similar visual properties, such as the plant images in iNaturalist, the addition of CSP results in a slight performance decline, since most newly added labels are not likely to be activated. Reducing dependency on this assumption is a valuable direction for future research. (2) In this work, we primarily focus on analyzing and optimizing the activation status of OOD labels while making no modification to the ID label set. However, there is a possibility that selecting additional labels from the semantic pool, including the CSP, to expand the ID label set could enhance the identification of difficult ID samples. We consider this a promising direction for future exploration. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported in part by the National Key Research and Development Plan of China under Grant 2021ZD0112200, in part by the National Natural Science Foundation of China under Grants 62036012, U21B2044, 62236008, 62102415, U2333215, 62072286, and 62106262, in part by Beijing Natural Science Foundation under Grant 4242051. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Patrick Billingsley. Probability and measure. John Wiley & Sons, 2017.   \n[2] Lukas Bossard, Matthieu Guillaumin, and Luc Van Gool. Food-101\u2013mining discriminative components with random forests. In Computer Vision\u2013ECCV 2014: 13th European Conference, Zurich, Switzerland, September 6-12, 2014, Proceedings, Part VI 13, pages 446\u2013461. Springer, 2014.   \n[3] Mengyuan Chen, Junyu Gao, and Changsheng Xu. Uncertainty-aware dual-evidential learning for weaklysupervised temporal action localization. IEEE transactions on pattern analysis and machine intelligence, 2023.   \n[4] Mengyuan Chen, Junyu Gao, and Changsheng Xu. R-edl: Relaxing nonessential settings of evidential deep learning. In The Twelfth International Conference on Learning Representations, 2024.   \n[5] Mengyuan Chen, Junyu Gao, and Changsheng Xu. Revisiting essential and nonessential settings of evidential deep learning. arXiv preprint arXiv:2410.00393, 2024.   \n[6] Ruoyu Chen, Hua Zhang, Siyuan Liang, Jingzhi Li, and Xiaochun Cao. Less is more: Fewer interpretable region via submodular subset selection. arXiv preprint arXiv:2402.09164, 2024.   \n[7] Xingyu Chen, Xuguang Lan, Fuchun Sun, and Nanning Zheng. A boundary based out-of-distribution classifier for generalized zero-shot learning. In European conference on computer vision, pages 572\u2013588. Springer, 2020.   \n[8] Mircea Cimpoi, Subhransu Maji, Iasonas Kokkinos, Sammy Mohamed, and Andrea Vedaldi. Describing textures in the wild. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 3606\u20133613, 2014.   \n[9] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009.   \n[10] Terrance DeVries and Graham W Taylor. Learning confidence for out-of-distribution detection in neural networks. arXiv preprint arXiv:1802.04865, 2018.   \n[11] Xuefeng Du, Zhaoning Wang, Mu Cai, and Yixuan Li. Vos: Learning what you don\u2019t know by virtual outlier synthesis. In International Conference on Learning Representations, 2021.   \n[12] Sepideh Esmaeilpour, Bing Liu, Eric Robertson, and Lei Shu. Zero-shot out-of-distribution detection based on the pre-trained model clip. In Proceedings of the AAAI conference on artificial intelligence, volume 36, pages 6568\u20136576, 2022.   \n[13] Yuxin Fang, Wen Wang, Binhui Xie, Quan Sun, Ledell Wu, Xinggang Wang, Tiejun Huang, Xinlong Wang, and Yue Cao. Eva: Exploring the limits of masked visual representation learning at scale. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 19358\u201319369, 2023.   \n[14] Zhen Fang, Yixuan Li, Jie Lu, Jiahua Dong, Bo Han, and Feng Liu. Is out-of-distribution detection learnable? Advances in Neural Information Processing Systems, 35:37199\u201337213, 2022.   \n[15] Stanislav Fort, Jie Ren, and Balaji Lakshminarayanan. Exploring the limits of out-of-distribution detection. Advances in Neural Information Processing Systems, 34:7068\u20137081, 2021.   \n[16] Junyu Gao, Mengyuan Chen, Liangyu Xiang, and Changsheng Xu. A comprehensive survey on evidential deep learning and its applications. arXiv preprint arXiv:2409.04720, 2024.   \n[17] Junyu Gao, Mengyuan Chen, and Changsheng Xu. Vectorized evidential learning for weakly-supervised temporal action localization. IEEE transactions on pattern analysis and machine intelligence, 2023.   \n[18] Eduardo Dadalto C\u00e2mara Gomes, Florence Alberge, Pierre Duhamel, and Pablo Piantanida. Igeood: An information geometry approach to out-of-distribution detection. In International Conference on Learning Representations, 2022.   \n[19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770\u2013778, 2016.   \n[20] Dan Hendrycks, Steven Basart, Norman Mu, Saurav Kadavath, Frank Wang, Evan Dorundo, Rahul Desai, Tyler Zhu, Samyak Parajuli, Mike Guo, et al. The many faces of robustness: A critical analysis of out-of-distribution generalization. In Proceedings of the IEEE/CVF international conference on computer vision, pages 8340\u20138349, 2021.   \n[21] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassified and out-of-distribution examples in neural networks. arXiv preprint arXiv:1610.02136, 2016.   \n[22] Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song. Natural adversarial examples. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 15262\u201315271, 2021.   \n[23] Yen-Chang Hsu, Yilin Shen, Hongxia Jin, and Zsolt Kira. Generalized odin: Detecting out-of-distribution image without learning from out-of-distribution data. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 10951\u201310960, 2020.   \n[24] Haiwen Huang, Zhihan Li, Lulu Wang, Sishuo Chen, Bin Dong, and Xinyu Zhou. Feature space singularity for out-of-distribution detection. arXiv preprint arXiv:2011.14654, 2020.   \n[25] Rui Huang, Andrew Geng, and Yixuan Li. On the importance of gradients for detecting distributional shifts in the wild. Advances in Neural Information Processing Systems, 34:677\u2013689, 2021.   \n[26] Rui Huang and Yixuan Li. Mos: Towards scaling out-of-distribution detection for large semantic space. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8710\u20138719, 2021.   \n[27] Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung, Zhen Li, and Tom Duerig. Scaling up visual and vision-language representation learning with noisy text supervision. In International conference on machine learning, pages 4904\u20134916. PMLR, 2021.   \n[28] Wenyu Jiang, Yuxin Ge, Hao Cheng, Mingcai Chen, Shuai Feng, and Chongjun Wang. Read: Aggregating reconstruction error into out-of-distribution detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 14910\u201314918, 2023.   \n[29] Xue Jiang, Feng Liu, Zhen Fang, Hong Chen, Tongliang Liu, Feng Zheng, and Bo Han. Negative label guided ood detection with pretrained vision-language models. In The Twelfth International Conference on Learning Representations, 2023.   \n[30] Jang-Hyun Kim, Sangdoo Yun, and Hyun Oh Song. Neural relation graph: A unified framework for identifying label noise and outlier data. Advances in Neural Information Processing Systems, 36, 2024.   \n[31] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3d object representations for fine-grained categorization. In Proceedings of the IEEE international conference on computer vision workshops, pages 554\u2013561, 2013.   \n[32] Kimin Lee, Kibok Lee, Honglak Lee, and Jinwoo Shin. A simple unified framework for detecting outof-distribution samples and adversarial attacks. Advances in neural information processing systems, 31, 2018.   \n[33] Jingyao Li, Pengguang Chen, Zexin He, Shaozuo Yu, Shu Liu, and Jiaya Jia. Rethinking out-of-distribution (ood) detection: Masked image modeling is all you need. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 11578\u201311589, 2023.   \n[34] Shiyu Liang, Yixuan Li, and Rayadurgam Srikant. Enhancing the reliability of out-of-distribution image detection in neural networks. arXiv preprint arXiv:1706.02690, 2017.   \n[35] Siyuan Liang, Wei Wang, Ruoyu Chen, Aishan Liu, Boxi Wu, Ee-Chien Chang, Xiaochun Cao, and Dacheng Tao. Object detectors in the open environment: Challenges, solutions, and outlook. arXiv preprint arXiv:2403.16271, 2024.   \n[36] Jeremiah Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax Weiss, and Balaji Lakshminarayanan. Simple and principled uncertainty estimation with deterministic deep learning via distance awareness. Advances in neural information processing systems, 33:7498\u20137512, 2020.   \n[37] Weitang Liu, Xiaoyun Wang, John Owens, and Yixuan Li. Energy-based out-of-distribution detection. Advances in neural information processing systems, 33:21464\u201321475, 2020.   \n[38] Xixi Liu, Yaroslava Lochman, and Christopher Zach. Gen: Pushing the limits of softmax-based out-ofdistribution detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 23946\u201323955, 2023.   \n[39] George A Miller. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39\u201341, 1995.   \n[40] Yifei Ming, Ziyang Cai, Jiuxiang Gu, Yiyou Sun, Wei Li, and Yixuan Li. Delving into out-of-distribution detection with vision-language representations. Advances in Neural Information Processing Systems, 35:35087\u201335102, 2022.   \n[41] Yifei Ming, Yiyou Sun, Ousmane Dia, and Yixuan Li. How to exploit hyperspherical embeddings for out-of-distribution detection? In The Eleventh International Conference on Learning Representations, 2022.   \n[42] Peyman Morteza and Yixuan Li. Provable guarantees for understanding out-of-distribution detection. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 7831\u20137840, 2022.   \n[43] Jun Nie, Yonggang Zhang, Zhen Fang, Tongliang Liu, Bo Han, and Xinmei Tian. Out-of-distribution detection with negative prompts. In The Twelfth International Conference on Learning Representations, 2023.   \n[44] Jaewoo Park, Yoon Gyo Jung, and Andrew Beng Jin Teoh. Nearest neighbor guidance for out-of-distribution detection. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1686\u2013 1695, 2023.   \n[45] Omkar M Parkhi, Andrea Vedaldi, Andrew Zisserman, and CV Jawahar. Cats and dogs. In 2012 IEEE conference on computer vision and pattern recognition, pages 3498\u20133505. IEEE, 2012.   \n[46] Foster J Provost, Tom Fawcett, Ron Kohavi, et al. The case against accuracy estimation for comparing induction algorithms. In ICML, volume 98, pages 445\u2013453, 1998.   \n[47] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models from natural language supervision. In International conference on machine learning, pages 8748\u20138763. PMLR, 2021.   \n[48] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do imagenet classifiers generalize to imagenet? In International conference on machine learning, pages 5389\u20135400. PMLR, 2019.   \n[49] Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo, Joshua Dillon, and Balaji Lakshminarayanan. Likelihood ratios for out-of-distribution detection. Advances in neural information processing systems, 32, 2019.   \n[50] Shiori Sagawa, Pang Wei Koh, Tatsunori B Hashimoto, and Percy Liang. Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization. arXiv preprint arXiv:1911.08731, 2019.   \n[51] Chandramouli Shama Sastry and Sageev Oore. Detecting out-of-distribution examples with gram matrices. In International Conference on Machine Learning, pages 8491\u20138501. PMLR, 2020.   \n[52] Walter J Scheirer, Anderson de Rezende Rocha, Archana Sapkota, and Terrance E Boult. Toward open set recognition. IEEE transactions on pattern analysis and machine intelligence, 35(7):1757\u20131772, 2012.   \n[53] Joan Serr\u00e0, David \u00c1lvarez, Vicen\u00e7 G\u00f3mez, Olga Slizovskaia, Jos\u00e9 F N\u00fa\u00f1ez, and Jordi Luque. Input complexity and out-of-distribution detection with likelihood-based generative models. In International Conference on Learning Representations, 2019.   \n[54] Yiyou Sun, Chuan Guo, and Yixuan Li. React: Out-of-distribution detection with rectified activations. Advances in Neural Information Processing Systems, 34:144\u2013157, 2021.   \n[55] Yiyou Sun and Yixuan Li. Dice: Leveraging sparsification for out-of-distribution detection. In European Conference on Computer Vision, pages 691\u2013708. Springer, 2022.   \n[56] Yiyou Sun, Yifei Ming, Xiaojin Zhu, and Yixuan Li. Out-of-distribution detection with deep nearest neighbors. In International Conference on Machine Learning, pages 20827\u201320840. PMLR, 2022.   \n[57] Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin. Csi: Novelty detection via contrastive learning on distributionally shifted instances. Advances in neural information processing systems, 33:11839\u2013 11852, 2020.   \n[58] Leitian Tao, Xuefeng Du, Jerry Zhu, and Yixuan Li. Non-parametric outlier synthesis. In The Eleventh International Conference on Learning Representations, 2022.   \n[59] Joost Van Amersfoort, Lewis Smith, Yee Whye Teh, and Yarin Gal. Uncertainty estimation using a single deep deterministic neural network. In International conference on machine learning, pages 9690\u20139700. PMLR, 2020.   \n[60] Grant Van Horn, Oisin Mac Aodha, Yang Song, Yin Cui, Chen Sun, Alex Shepard, Hartwig Adam, Pietro Perona, and Serge Belongie. The inaturalist species classification and detection dataset. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8769\u20138778, 2018.   \n[61] Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. The caltech-ucsd birds-200-2011 dataset. 2011.   \n[62] Haohan Wang, Songwei Ge, Zachary Lipton, and Eric P Xing. Learning robust global representations by penalizing local predictive power. Advances in Neural Information Processing Systems, 32, 2019.   \n[63] Haoqi Wang, Zhizhong Li, Litong Feng, and Wayne Zhang. Vim: Out-of-distribution with virtual-logit matching. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 4921\u20134930, 2022.   \n[64] Hualiang Wang, Yi Li, Huifeng Yao, and Xiaomeng Li. Clipn for zero-shot ood detection: Teaching clip to say no. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 1802\u20131812, 2023.   \n[65] Qizhou Wang, Zhen Fang, Yonggang Zhang, Feng Liu, Yixuan Li, and Bo Han. Learning to augment distributions for out-of-distribution detection. Advances in Neural Information Processing Systems, 36, 2024.   \n[66] Jianxiong Xiao, James Hays, Krista A Ehinger, Aude Oliva, and Antonio Torralba. Sun database: Largescale scene recognition from abbey to zoo. In 2010 IEEE computer society conference on computer vision and pattern recognition, pages 3485\u20133492. IEEE, 2010.   \n[67] Zhisheng Xiao, Qing Yan, and Yali Amit. Likelihood regret: An out-of-distribution detection score for variational auto-encoder. Advances in neural information processing systems, 33:20685\u201320696, 2020.   \n[68] Jiarui Xu, Shalini De Mello, Sifei Liu, Wonmin Byeon, Thomas Breuel, Jan Kautz, and Xiaolong Wang. Groupvit: Semantic segmentation emerges from text supervision. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 18134\u201318144, 2022.   \n[69] Yijun Yang, Ruiyuan Gao, and Qiang Xu. Out-of-distribution detection with semantic mismatch under masking. In European Conference on Computer Vision, pages 373\u2013390. Springer, 2022.   \n[70] Alireza Zaeemzadeh, Niccolo Bisagno, Zeno Sambugaro, Nicola Conci, Nazanin Rahnavard, and Mubarak Shah. Out-of-distribution detection using union of 1-dimensional subspaces. In Proceedings of the IEEE/CVF conference on Computer Vision and Pattern Recognition, pages 9452\u20139461, 2021.   \n[71] Jinsong Zhang, Qiang Fu, Xu Chen, Lun Du, Zelin Li, Gang Wang, Shi Han, Dongmei Zhang, et al. Out-of-distribution detection based on in-distribution data patterns memorization with modern hopfield energy. In The Eleventh International Conference on Learning Representations, 2022.   \n[72] Lily Zhang, Mark Goldstein, and Rajesh Ranganath. Understanding failures in out-of-distribution detection with deep generative models. In International Conference on Machine Learning, pages 12427\u201312436. PMLR, 2021.   \n[73] Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10 million image database for scene recognition. IEEE transactions on pattern analysis and machine intelligence, 40(6):1452\u20131464, 2017.   \n[74] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu. Conditional prompt learning for visionlanguage models. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition, pages 16816\u201316825, 2022.   \n[75] Kaiyang Zhou, Jingkang Yang, Chen Change Loy, and Ziwei Liu. Learning to prompt for vision-language models. International Journal of Computer Vision, 130(9):2337\u20132348, 2022.   \n[76] Yibo Zhou. Rethinking reconstruction autoencoder-based out-of-distribution detection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 7379\u20137387, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "A Proof and Derivation ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The proof is partially adapted from the appendix of [29]. ", "page_idx": 14}, {"type": "text", "text": "A.1 Proof of Lemma 1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Lyapunov Central Limit Theorem. Suppose $\\{s_{1},...,s_{m},...\\}$ is a sequence of independent random variables, each with finite expected value $\\mu_{i}$ and variance $\\sigma_{i}^{2}$ . Define $\\textstyle\\rho_{m}^{2}=\\sum_{i=1}^{m}{\\sigma_{i}^{2}}$ . If for some $\\delta>0$ , Lyapunov\u2019s condition ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{m\\to\\infty}\\frac{1}{\\rho_{m}^{2+\\delta}}\\sum_{i=1}^{m}\\mathbb{E}[|s_{i}-\\mu_{i}|^{2+\\delta}]=0\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "is satisfied, then a sum of $\\frac{s_{i}\\!-\\!\\mu_{i}}{\\rho_{m}}$ converges in distribution to a standard normal random variable, as $m$ goes to infinity: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{1}{\\rho_{m}}\\sum_{i=1}^{m}(s_{i}-\\mu_{i})\\overset{d}{\\to}\\mathcal{N}(0,1).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Lemma 1. Given a sequence of independent Bernoulli random variables $\\{s_{1},...,s_{m}\\}$ with parameters $\\{p_{1},...,p_{m}\\}.$ , where $0\\,<\\,p_{i}\\,<\\,1$ , as $m$ goes to infinity, the Poisson binomial random variable $\\textstyle C=\\sum_{i=1}^{m}s_{i}$ converges in distribution to the normal random variable: ", "page_idx": 14}, {"type": "equation", "text": "$$\nC\\stackrel{d}{\\to}\\mathcal{N}\\left(\\sum_{i=1}^{m}p_{i},\\sum_{i=1}^{m}p_{i}(1-p_{i})\\right).\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Proof. The proof process involves an application of the Lyapunov central limit theorem (CLT) [1], a particular form of CLT which relaxes the identical-distribution assumption. Since $s_{i}$ is a Bernoulli random variable with parameter $p_{i}$ , we know that $\\mu[s_{i}]\\,=\\,p_{i}$ , $\\sigma^{2}[s_{i}\\bar{]}=p_{i}(1-p_{i})$ . To keep the notation uncluttered, we use $\\mu_{i}$ and $\\sigma_{i}^{2}$ for substitution. Based on the above expectation and variance values, we try to verify the Lyapunov condition: Denote $\\textstyle\\rho_{m}^{2}=\\sum_{i=1}^{m}\\sigma_{i}^{2}$ , for some $\\delta>0$ , ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{m\\to\\infty}\\frac{1}{\\rho_{m}^{2+\\delta}}\\sum_{i=1}^{m}\\mathbb{E}\\left[|s_{i}-\\mu_{i}|^{2+\\delta}\\right]=0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Analyzing the term $\\mathbb{E}[|s_{i}-\\mu_{i}|^{2+\\delta}]$ based on $s_{i}$ and $\\mu_{i}$ , we know ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[|s_{i}-\\mu_{i}|^{2+\\delta}]=(1-\\mu_{i})^{2+\\delta}\\operatorname*{Pr}(s_{i}=1)+(0-\\mu_{i})^{2+\\delta}\\operatorname*{Pr}(s_{i}=0)}\\\\ &{\\phantom{=}=(1-p_{i})^{2+\\delta}p_{i}+(0-p_{i})^{2+\\delta}(1-p_{i})}\\\\ &{\\phantom{=}=(1-p_{i})p_{i}\\left((1-p_{i})^{1+\\delta}+p_{i}^{1+\\delta}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Thus, we know $0<\\mathbb{E}[|s_{i}-\\mathbb{E}[s_{i}]|^{2+\\delta}]<2$ . Then, we analyze ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\rho_{m}^{2+\\delta}=\\left(\\sum_{i=1}^{m}p_{i}(1-p_{i})\\right)^{1+\\delta/2}\\geq\\left(\\sum_{i=1}^{m}\\varepsilon\\right)^{1+\\delta/2}=\\varepsilon^{1+\\delta/2}m^{1+\\delta/2},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\varepsilon=\\operatorname*{min}(p_{i}-p_{i}^{2})>0$ . Based on Eqn. 14 and Eqn. 15, we have ", "page_idx": 14}, {"type": "equation", "text": "$$\n0<\\frac{1}{\\rho_{m}^{2+\\delta}}\\sum_{i=1}^{m}\\mathbb{E}[|s_{i}-\\mu_{i}|^{2+\\delta}]\\leq\\frac{2m}{\\varepsilon^{1+\\delta/2}m^{1+\\delta/2}}=\\frac{2}{\\varepsilon^{1+\\delta/2}m^{\\delta/2}}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Thus, as $m\\rightarrow\\infty$ , the squeeze theorem tells us that ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{m\\to\\infty}{\\frac{1}{\\rho_{m}^{2+\\delta}}}\\sum_{i=1}^{m}\\mathbb{E}[|s_{i}-\\mu_{i}|^{2+\\delta}]=0.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Hence, we verify the Lyapunov condition for $C$ and $s_{i}$ . Based on the Lyapunov CLT, we know that, as $m$ goes to infinity, ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\frac{1}{\\rho_{m}}\\sum_{i=1}^{m}(s_{i}-\\mu_{i})\\overset{d}{\\to}\\mathcal{N}(0,1),\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where $\\xrightarrow{d}$ means \u201cconverges in distribution\u201d. Thus, for a sufficiently large $m$ , the Poisson binomial random variable $\\textstyle C=\\sum_{i=1}^{\\bar{m}}s_{i}$ approximately follows ", "page_idx": 15}, {"type": "equation", "text": "$$\nC\\sim{\\cal N}\\left(\\sum_{i=1}^{m}\\mu_{i},\\rho_{m}^{2}\\right)={\\cal N}\\left(\\sum_{i=1}^{m}p_{i},\\sum_{i=1}^{m}p_{i}(1-p_{i})\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "A.2 Derivation of Eq. (3) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "First, we denote the cumulative distribution function (CDF) of a normal distribution with mean $\\mu$ and standard deviation $\\sigma$ as $\\Phi(x;\\mu,\\sigma^{2})$ , which can be expressed by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Phi(x;\\mu,\\sigma^{2})={\\frac{1}{2}}\\left[1+\\operatorname{erf}\\left({\\frac{x-\\mu}{{\\sqrt{2}}\\sigma}}\\right)\\right],\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and its inverse function can be expressed by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Phi^{-1}(x;\\mu,\\sigma^{2})=\\sqrt{2}\\sigma\\cdot\\mathrm{erf}^{-1}(2x-1)+\\mu,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\operatorname{erf}(x)$ denotes the integral of the standard normal distribution from 0 to $x$ , termed as error function, and can be given by ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname{erf}(x)={\\frac{2}{\\sqrt{\\pi}}}\\int_{0}^{x}e^{-t^{2}}d t.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Besides, with the distributions of $C^{\\mathrm{in}}$ and $C^{\\mathrm{out}}$ given by ", "page_idx": 15}, {"type": "equation", "text": "$$\nC^{\\mathrm{in}}\\sim\\mathcal{N}\\left(m q_{1},m q_{1}(1-q_{1})-m v_{1}\\right),C^{\\mathrm{out}}\\sim\\mathcal{N}\\left(m q_{2},m q_{2}(1-q_{2})-m v_{2}\\right),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "the false positive rate (FPR) when the true positive rate (TPR) is $\\lambda\\in[0,1]$ , denoted by $\\mathrm{FPR}_{\\lambda}$ , can be calculated as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{F P R}_{\\lambda}=F_{\\mathrm{out}}(F_{\\mathrm{in}}^{-1}(\\lambda))=\\Phi\\left[\\Phi^{-1}\\left(\\lambda;m q_{1},m q_{1}(1-q_{1})-m v_{1}\\right);m q_{2},m q_{2}(1-q_{2})-m v_{2}\\right]}\\\\ &{\\qquad=\\frac{1}{2}+\\frac{1}{2}\\cdot\\mathrm{erf}\\left(\\frac{\\Phi^{-1}\\left(\\lambda;m q_{1},m q_{1}(1-q_{1})-M v_{1}\\right)-m q_{2}}{\\sqrt{2m q_{2}(1-q_{2})}-2m v_{2}}\\right)}\\\\ &{\\qquad=\\frac{1}{2}+\\frac{1}{2}\\cdot\\mathrm{erf}\\left(\\frac{\\sqrt{2m q_{1}(1-q_{1})-2m v_{1}}\\mathrm{erf}^{-1}\\left(2\\lambda-1\\right)+m q_{1}-m q_{2}}{\\sqrt{2m q_{2}(1-q_{2})-2m v_{2}}}\\right)}\\\\ &{\\qquad=\\frac{1}{2}+\\frac{1}{2}\\cdot\\mathrm{erf}\\left(\\sqrt{\\frac{q_{1}(1-q_{1})-v_{1}}{q_{2}(1-q_{2})-v_{2}}}\\mathrm{erf}^{-1}\\left(2\\lambda-1\\right)+\\frac{\\sqrt{m}(q_{1}-q_{2})}{\\sqrt{2q_{2}(1-q_{2})-2v_{2}}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $F_{\\mathrm{in}}$ and $F_{\\mathrm{out}}$ denote the cumulative distribution functions which correspond to the scores obtained by ID and OOD samples. ", "page_idx": 15}, {"type": "text", "text": "A.3 Calculation process from Eq.(3) to Eq.(6) ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "First, from ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{FPR}_{\\lambda}=\\frac{1}{2}+\\frac{1}{2}\\cdot\\mathrm{erf}\\left(\\sqrt{\\frac{q_{1}(1-q_{1})-v_{1}}{q_{2}(1-q_{2})-v_{2}}}\\mathrm{erf}^{-1}\\left(2\\lambda-1\\right)+\\frac{\\sqrt{m}(q_{1}-q_{2})}{\\sqrt{2q_{2}(1-q_{2})-2v_{2}}}\\right),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "we know that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{FPR}_{\\mathrm{0.5}}=\\frac{1}{2}+\\frac{1}{2}\\mathrm{erf}\\left(\\sqrt{\\frac{m}{2}}\\cdot\\frac{q_{0}-q_{2}+u(r|q_{0},q_{2})}{\\sqrt{q_{2}(1-q_{2})-v_{2}}}\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Denote $\\begin{array}{r}{z=\\sqrt{\\frac{m}{2}}\\cdot\\frac{q_{0}-q_{2}+u(r|q_{0},q_{2})}{\\sqrt{q_{2}(1-q_{2})-v_{2}}}}\\end{array}$ m\u00b7 q0\u221a\u2212q2+u(r|q0,q2), then we can derive that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{G(r|q_{0},q_{2},u,M)=\\frac{\\partial\\mathrm{FPR}_{0.5}}{\\partial r}=\\frac{\\partial\\mathrm{FPR}_{0.5}}{\\partial z}\\frac{\\partial z}{\\partial m}\\frac{\\partial m}{\\partial r}=\\frac{1}{2}\\frac{\\partial\\mathrm{erf}(z)}{\\partial z}\\frac{\\partial z}{\\partial m}\\frac{\\partial m}{\\partial r}}\\\\ &{\\qquad\\qquad=\\frac{M}{2}\\cdot\\frac{2e^{-z^{2}}}{\\sqrt{\\pi}}\\cdot\\frac{\\frac{1}{2\\sqrt{m}}(q_{0}-q_{2}+u)+\\frac{\\sqrt{m}}{M}\\frac{\\partial u}{\\partial r}}{\\sqrt{2q_{2}(1-q_{2})-2v_{2}}}}\\\\ &{\\qquad\\qquad=\\frac{M e^{-z^{2}}}{2\\sqrt{2\\pi}}\\cdot\\frac{q_{0}-q_{2}+u+\\frac{2m}{M}\\frac{\\partial u}{\\partial r}}{\\sqrt{m}\\sqrt{q_{2}(1-q_{2})-v_{2}}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Denote $\\begin{array}{r}{w=\\frac{1}{\\sqrt{m}}\\left(q_{0}-q_{2}+u+\\frac{2m}{M}\\frac{\\partial u}{\\partial r}\\right)}\\end{array}$ , then we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{\\displaystyle\\frac{\\partial w}{\\partial r}=\\frac{M}{m}\\left(\\left(\\frac{1}{M}\\frac{\\partial u}{\\partial r}+\\frac{2}{M}\\frac{\\partial u}{\\partial r}+\\frac{2m}{M^{2}}\\frac{\\partial^{2}u}{\\partial r^{2}}\\right)\\sqrt{m}-\\frac{1}{2\\sqrt{m}}\\left(q_{0}-q_{2}+u+\\frac{2m}{M}\\frac{\\partial u}{\\partial r}\\right)\\right)}\\\\ {\\displaystyle}&{\\displaystyle\\qquad=\\frac{M}{2m^{\\frac{3}{2}}}\\left(\\frac{4m^{2}}{M^{2}}\\frac{\\partial^{2}u}{\\partial r^{2}}+\\frac{4m}{M}\\frac{\\partial u}{\\partial r}-q_{0}+q_{2}-u\\right)}\\\\ {\\displaystyle}&{\\displaystyle\\qquad\\geq\\frac{M}{2m^{\\frac{3}{2}}}\\left(-\\frac{4m^{2}}{M^{2}}\\frac{\\partial u}{\\partial r}+\\frac{4m}{M}\\frac{\\partial u}{\\partial r}-q_{0}+q_{2}-u\\right)}\\\\ {\\displaystyle}&{\\displaystyle\\qquad=\\frac{M}{2m^{\\frac{3}{2}}}\\left(4r(1-r)\\frac{\\partial u}{\\partial r}+(q_{2}-q_{0}-u)\\right)\\geq0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the derivation from the second to the third line utilizes an assumption on the limited range of the curvature of the function $u(r)$ , aka $|u^{\\prime\\prime}|\\leq u^{\\prime}$ . While recognizing the challenge of consistently maintaining this assumption in complex real-world scenarios, we consider it reasonable for use in intuitive quantitative analyses to simplify derivations. Therefore, we come to the conclusion that $\\begin{array}{r}{G^{\\prime}(r)=\\frac{\\bar{\\partial}^{2}\\mathrm{FPR}_{0.5}}{\\partial r^{2}}\\geq0}\\end{array}$ \u22022F\u2202PrR20.5 \u22650. Besides, according to Eqn. 27, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{r\\to0^{+}}G(r)=\\operatorname*{lim}_{r\\to0^{+}}\\frac{\\sqrt{M}e^{-z^{2}}}{2\\sqrt{2\\pi}}\\cdot\\frac{q_{0}-q_{2}}{\\sqrt{r}\\sqrt{q_{2}(1-q_{2})-v_{2}}}=\\operatorname*{lim}_{r\\to0^{+}}\\frac{\\kappa(q_{0}-q_{2})}{2\\sqrt{r}}=-\\infty,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{r\\rightarrow1}G(r)=\\frac{e^{-z^{2}}}{\\sqrt{2\\pi}}\\cdot\\frac{\\sqrt{M}u^{\\prime}(r=1|q_{0},q_{2})}{\\sqrt{q_{2}(1-q_{2})-v_{2}}}=\\kappa u^{\\prime}(r=1)\\geq0,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\kappa=(M/2\\pi)^{\\frac{1}{2}}(q_{2}(1-q_{2})-v_{2})^{-\\frac{1}{2}}e^{-z^{2}}>0.$ ", "page_idx": 16}, {"type": "text", "text": "A.4 Analysis of some variables in Eq.(8) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Defined as the lower bound of $q_{1},\\,q_{0}$ represents the expected probability of the OOD label, which is most dissimilar to the ID label space, being activated by ID images. When the semantic pool size is large enough, this OOD label has very different meaning from ID labels, thus its expected probability $q_{0}$ of being activated by ID images is close to zero. With the assumption that the function $u(r)$ is linear, from Eqn. 7 we can derive that $r_{0}=1/3$ , which is a constant unrelated to other factors. Empirical evidence also indicates that the change of $r_{0}$ is relatively slight. Besides, $v_{2}$ is defined as the variance of the probabilities of OOD labels being activated by OOD samples. When the semantic pool is large enough, this variance changes very slightly with further expansion. Therefore, we come to the conclusion that variables $q_{0},\\,r_{0}$ , and $v_{2}$ remain nearly constant with a sufficiently large semantic pool, thus exerting marginal impact to the right side of Eqn. 8. ", "page_idx": 16}, {"type": "text", "text": "A.5 Analysis of a condition in Eq.(9) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "By adjusting its shape parameters, $\\alpha$ and $\\beta$ , the Beta distribution can flexibly simulate a range of distinct probability distribution profiles. This flexibility is particularly useful in statistical modeling and analysis where the behavior of probabilities needs to be accurately described. Assuming that $p_{i}^{\\mathrm{out}}$ follows a Beta distribution, we know that ", "page_idx": 16}, {"type": "equation", "text": "$$\nq_{2}=\\mathbb{E}_{i}[p_{i}^{\\mathrm{out}}]={\\frac{\\alpha}{\\alpha+\\beta}},\\quad v_{2}=\\mathrm{Var}_{i}[p_{i}^{\\mathrm{out}}]={\\frac{\\alpha\\beta}{(\\alpha+\\beta)^{2}(\\alpha+\\beta+1)}}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "If $q_{2}-2v_{2}\\geq0$ does not hold, it means that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\frac{\\alpha}{\\alpha+\\beta}-\\frac{2\\alpha\\beta}{(\\alpha+\\beta)^{2}(\\alpha+\\beta+1)}<0,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "which is equivalent to ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\alpha^{2}+2\\alpha\\beta+\\beta^{2}+\\alpha-\\beta<0,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "and $\\alpha\\,<\\,\\mathrm{min}\\{0.5,\\beta\\}\\,<\\,1$ is a necessary condition for the above equation. In this situation, the Beta distribution exhibits a pronounced peak at 0 and a long, thin tail stretching towards 1. In our experiments, we observe that the similarity distribution between OOD input images and OOD text labels exhibits a distinct unimodal concentration, with probability densities near 0 and 1 approaching zero, which is entirely different from the distribution shape derived theoretically. Consequently, we can conclude that in the vast majority of practical cases, the following inequality holds, ", "page_idx": 17}, {"type": "equation", "text": "$$\nq_{2}+q_{0}-2q_{0}q_{2}-2v_{2}=q_{2}-2v_{2}+q_{0}(1-2q_{2})\\geq0.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "B Datasets and Lexicons ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "B.1 Main benchmark ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We mainly evaluate our method on the widely-used ImageNet-1k OOD detection benchmark [26]. This benchmark utilizes the large-scale ImageNet-1k dataset as the ID data, and select samples from iNaturalist [60], SUN [66], Places [73], and Textures [8] as the OOD data. The categories of the OOD data have been manually selected to prevent overlap with the classes of ImageNet-1k. ", "page_idx": 17}, {"type": "text", "text": "ImageNet-1k, also referred to as ILSVRC 2012, is a subset of the larger ImageNet dataset [9]. This dataset encompasses 1,000 object classes and includes 1,281,167 images for training, 50,000 images for validation, and 100,000 images for testing. In the widely used benchmark for OOD detection organized by [26], the validation set of ImageNet-1k is designated as the ID data. ", "page_idx": 17}, {"type": "text", "text": "iNaturalist [60] is a fine-grained dataset containing 859,000 images across more than 5,000 species of plants and animals. [26] randomly sample 10,000 images from 110 manually selected plant classes which are not present in ImageNet-1k as the OOD data. ", "page_idx": 17}, {"type": "text", "text": "SUN [66] is a scene database which includes 130,519 images from 397 categories. [26] sample 10,000 images from 50 nature-related classes that do not overlap with ImageNet-1k as OOD data. ", "page_idx": 17}, {"type": "text", "text": "Places [73] is another scene dataset containing more than 2.5 million images covering more than 205 scene categories with more than 5,000 images per category. [26] manually select 50 categories from this dataset and then randomly sample 10,000 images as OOD data. ", "page_idx": 17}, {"type": "text", "text": "Textures [8], also referred to as Describable Textures Dataset (DTD), consists of 5,640 images from 47 categories of textural patterns inspired from human perception. There are 120 images for each category. [26] use the entire dataset as OOD data. ", "page_idx": 17}, {"type": "text", "text": "B.2 Datesets of hard OOD detection ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "We also evaluate our method on the hard OOD detection tasks as shown in Table 2. Specifically, the ID-vs-OOD dataset pairs includes ImageNet-10 vs ImageNet-20, ImageNet-10 vs ImageNet-100, ImageNet-1k vs ImageNet-O [22], WaterBirds [50]-vs-Placebg, etc. ", "page_idx": 17}, {"type": "text", "text": "ImageNet-O [22] is a dataset of adversarially filtered examples for ImageNet OOD detectors. To create this dataset, the authors delete examples of ImageNet-1k from ImageNet-22k, and then select examples that a ResNet-50 [19] model misclassifies as belonging to an ImageNet-1k class with high confidence. This dataset contains 2,000 images across 200 classes. In a hard OOD detection task, we use ImageNet-1k as the ID data and use ImageNet-O as OOD data. ", "page_idx": 17}, {"type": "text", "text": "WaterBirds [50] is constructed by combining bird photographs from the CUB-200 dataset [61] with image backgrounds from the Places dataset [73]. Therefore, WaterBirds keeps the same size with CUB-200, i.e., it contains 11,788 images from 200 bird classes. To construct this dataset, the authors label each bird as waterbird or landbird and place it on one image of water background or land background. In a hard OOD detection task, we use WaterBirds as the ID data and use its background images as OOD data. ", "page_idx": 17}, {"type": "text", "text": "B.3 Datasets of various ID data ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As depicted in Table 7, our method is evaluated against baseline methods, including MCM [40] and NegLabel [29], across various ID datasets. These datasets encompass (1) specialized domain-focused datasets such as Stanford-Cars [31], CUB-200 [61], Oxford-Pet [45], and Food-101 [2]; (2) subsets of ImageNet, including ImageNet10, ImageNet20, and ImageNet100; (3) ImageNet domain shift datasets, namely ImageNet-Sketch [62], ImageNet-A [22], ImageNet-R [20], and ImageNetV2 [48]. ", "page_idx": 18}, {"type": "text", "text": "Stanford-Cars [31] contains 16,185 images of 196 classes of cars. Classes are typically at the level of Make, Model, Year, e.g., 2012 Tesla Model S or 2012 BMW M3 coupe. The data is split into 8,144 training images and 8,041 testing images. ", "page_idx": 18}, {"type": "text", "text": "CUB-200 [61], formally recognized as Caltech-UCSD Birds-200-2011, comprises 11,788 images across 200 bird subcategories, with 5,994 images for training and 5,794 for testing. ", "page_idx": 18}, {"type": "text", "text": "Oxford-Pet [45] is a 37 category pet dataset with roughly 200 images for each class created by the Visual Geometry Group at Oxford. The total image number is 7,390. ", "page_idx": 18}, {"type": "text", "text": "Food-101 [2] dataset consists of 101 food categories with 750 training and 250 test images per category, making a total of 101k images. ", "page_idx": 18}, {"type": "text", "text": "ImageNet-Sketch [62] dataset consists of 50,889 images, approximately 50 images for each of the 1,000 ImageNet classes. The dataset was created using Google Image searches for \"sketch of {Class Name}\", specifically limiting results to the \"black and white\" color scheme. ", "page_idx": 18}, {"type": "text", "text": "ImageNet-A [22] is a dataset of 7,500 real-world adversarially flitered images, which are misclassified by a ResNet-50 ImageNet classifier, from 200 classes. The user-tagged images are downloaded from websites including iNaturalist, Flicker, and DuckDuckGo. ", "page_idx": 18}, {"type": "text", "text": "ImageNet-R [20], formally recognized as ImageNet-Renditions, contains 30,000 images of ImageNet objects from 200 classes with different textures and styles. ", "page_idx": 18}, {"type": "text", "text": "ImageNetV2 [48] contains 10,000 new images across the 1,000 categories of ImageNet-1k. The new images are gathered from the same source of ImageNet to avoid bias. ", "page_idx": 18}, {"type": "text", "text": "B.4 Lexicons ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "As shown in Table 9, we conduct experiments with lexicons of different sizes, and observe that simply adopting larger lexicons does not yield consistent performance improvement. From each lexicon, we select all the nouns to construct the original semantic pool, and use all the adjectives to construct the additional conjugated semantic pool for expansion. ", "page_idx": 18}, {"type": "text", "text": "WordNet [39] is a large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms, each expressing a distinct concept. In our experiments, we use the 70K nouns and adjectives to construct a semantic pool. ", "page_idx": 18}, {"type": "text", "text": "Common- $.20\\mathbf{K}^{3}$ is a list of the 20,000 most common English words in order of frequency, as determined by n-gram frequency analysis of the Google\u2019s Trillion Word Corpus. In our experiments, we use the 17K nouns and adjectives to construct a semantic pool. ", "page_idx": 18}, {"type": "text", "text": "Part-of-Speech Tagging4 is a 370K English words corpus. In our experiments, we use the 319K nouns and adjectives to construct a semantic pool. ", "page_idx": 18}, {"type": "text", "text": "C More Results and Analysis ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Validation of consistency between methodology and theoretical framework ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Consistent with our established theory, expanding label candidates with the CSP satisfies the requirements derived in Section 3.1: (1) Concurrently enlarging the semantic pool size $M$ and the expected activation probability $q_{2}$ of OOD labels; (2) Ensuring that there is no severe mutual dependence among the activations of selected OOD labels. ", "page_idx": 18}, {"type": "text", "text": "(1) The enlargement of the semantic pool size $M$ is evident. Besides, since the superclasses used in constructing the CSP typically include broad semantic objects, the property clusters encompass samples from numerous potential OOD categories. Therefore, their centers have much higher expected probabilities of being activated by OOD samples, which brings an increase in $q_{2}$ . In Table 5, we present the expected softmax scores for a single OOD label from both the original semantic pool and the CSP. These scores, averaged across OOD samples, serve as an approximation of $q_{2}$ , which is defined as the expected probability of OOD labels being activated by OOD samples. Table 5 reveals that the average score of our CSP across four OOD datasets is distinctly higher than that of the original pool, indicating that this expansion leads to an increase in $q_{2}$ . ", "page_idx": 19}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/eaa2d90de60cb7a3046662c3106983aecf03d93ef3d0915adcc893177360365d.jpg", "table_caption": ["Table 5: The expected Softmax scores of a single OOD label, an approximation of $q_{2}$ , from the original semantic pool and the conjugated semantic pool, scaled up by a factor of 1000. "], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "The effectiveness of the CSP is based on the implicit assumption that OOD samples exhibit various visual properties. However, the degree of visual diversity varies across different OOD datasets, resulting in different expected probabilities of OOD labels in the CSP being activated, as reflected in the varying scores of conjugated labels shown in Table 5. For instance, plant images in iNaturalist have limited visual diversity, leading to low scores for conjugated labels, whereas the Texture dataset, with its higher visual diversity, exhibits the opposite phenomenon. We can observe that across different OOD datasets, there is a correlation between these scores and the performance improvements achieved by our method: the score is lower on iNaturalist compared to the original pool, relatively higher on SUN and Places, and significantly higher on Textures. Consequently, our method achieves only modest gains on iNaturalist, normal improvements on SUN and Places, and substantial enhancements on Textures. This correlation further corroborates the validity of our theory. ", "page_idx": 19}, {"type": "text", "text": "(2) Since the labels in CSP are centers of property clusters, while the labels in the original semantic pool are centers of category clusters, it is highly improbable that numerous synonym pairs would exist between these two semantic pools. Our statistical analysis supports this claim: we calculate the average maximum similarity between each label and other labels within the semantic pool, a metric which reflects the proportion of synonymous pairs within the pool and tends to increase monotonically as the semantic pool expands. Our findings indicate that only $3.94\\%$ of the original labels find more similar counterparts in the expanded CSP, resulting in a negligible increase in the aforementioned metric from 0.8721 to 0.8726. As a result, the mutual dependence between the new and original labels is relatively low, and the functions of labels from the CSP will not be overshadowed, enhancing the likelihood that an OOD image locates close to an OOD cluster center. ", "page_idx": 19}, {"type": "text", "text": "C.2 Random analysis ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Table 6 shows the results of our method under random seeds from 0 to 9, whose average is reported in the main text. It is evident that the performance of our method is minimally impacted by randomness, consistently exhibiting superior efficacy. ", "page_idx": 19}, {"type": "text", "text": "C.3 Various ID datasets ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "As depicted in Table 7, our method is evaluated against baseline methods, including MCM [40] and NegLabel [29], across various ID datasets. These datasets encompass (1) specialized domainfocused datasets such as Stanford-Cars [31], CUB-200 [61], Oxford-Pet [45], and Food-101 [2]; (2) subsets of ImageNet, including ImageNet10, ImageNet20, and ImageNet100; (3) ImageNet domain shift datasets, namely ImageNet-Sketch [62], ImageNet-A [22], ImageNet-R [20], and ImageNetV2 [48]. Our proposed method consistently achieves satisfactory results on all the above ID datasets. For example, our method outperforms NegLabel by $9.23\\%$ and $11.71\\%$ evaluated by FPR95 with ImageNet-A and ImageNet-R as the ID data, respectively. ", "page_idx": 19}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/ea68c754e9fa7402e6fc01279f6204b383cfec4ea4933a60fa18d28c550ed223.jpg", "table_caption": ["Table 6: Mean and standard deviation of OOD detection performance across various random seeds with CLIP-B/16 on ImageNet-1k as ID data. Performance metrics are presented as percentages. "], "table_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/9bb85b0d339106f4d23930e1b6216540e2610d6d07447727921d5757c64abfa3.jpg", "table_caption": ["Table 7: OOD detection performance comparison on various ID datasets. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "C.4 Empirical evidence supporting our assertions ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Performance trends related to the ratio $r$ . In Fig. 1 and Table 8, we present the FPR95 performances of our method and NegLabel against a progressively increasing ratio $r$ , which represents the proportion of selected OOD labels in the whole semantic pool. The color gradations displayed in the table clearly illustrate an initial improvement in model performance followed by a subsequent decline as the ratio $r$ increases. This trend aligns with our derivation in Section 3.1. ", "page_idx": 20}, {"type": "text", "text": "Effect of simple lexicon expansion. In Fig. 2 and Table 9, we assess whether adopting larger lexicons enhances performances. Our findings indicate that it does not always hold. When the semantic pool covers the vast majority of common words, further expansion will introduce an excessive number of uncommon words and (near-)synonyms, thus failing to meet the derived requirements for theoretical performance enhancement. The inefficacy of simple lexicon expansion indicates that viable expansion manners move beyond merely selecting words from existing lexicons. ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/cec80ba71ceaf51c82374933c50928323e50150b0c11c6c71318c8f70e981f3c.jpg", "table_caption": ["Table 8: OOD detection performance evaluated by the FPR95 metric with different candidate selection ratios $r$ . The results of our method and the baseline method NegLabel share similar trends. "], "table_footnote": [], "page_idx": 21}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/62c5d438dde18e45101ea0af37d2b7fd08f613b55cc8884cc7b26451680d8a04.jpg", "table_caption": ["Table 9: Evaluation with different corpus sources. \u201cSize\u201d refers to the size of semantic pools. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "C.5 Analysis of superclasses in conjugated semantic pool ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The indices 1 through 14 in Table 10 represent the following superclasses, listed in alphabetical order: area, creature, environment, item, landscape, object, pattern, place, scene, space, structure, thing, view, vista. Table 10 displays the outcomes of multiple runs with 4, 7, and 10 randomly selected superclasses. Although the selection of different superclasses results in some performance fluctuations, any selection significantly enhances performance compared to not employing CSP (as shown in the first row of the table), and achieves state-of-the-art results. ", "page_idx": 21}, {"type": "text", "text": "Acute readers may be concerned about performance fluctuations caused by different superclass sets. However, despite the specific OOD categories being unknown in real-world applications, it is likely that an approximate range of OOD superclasses can be estimated in advance based on the deployment scenario and empirical evidence. Generally, users can preset a suitable superclass set to achieve satisfactory performance enhancements provided by the conjugated semantic pool. ", "page_idx": 21}, {"type": "text", "text": "D Visualization ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this section, we present visualization results of images picked from the ImageNet-1k OOD detection benchmark. Each subfigure includes the original image, the ground-truth label (for ID images only), the image name in the dataset, and the top-5 softmax scores for ID labels (orange), OOD labels from the original semantic pool (green), and OOD labels from the conjugated semantic pool (blue). ", "page_idx": 21}, {"type": "text", "text": "D.1 In-distribution examples ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In Figs. 4 and 5, we present ID examples that have been correctly classified into the ground-truth ID class with high and low confidence, respectively. Fig. 6 presents ID examples that have been correctly classified into the ID class group but assigned the wrong specific classes. Figs. 7 and 8 display failure cases where the ID image is misclassified into labels of the original semantic pool or our conjugated semantic pool, respectively. ", "page_idx": 21}, {"type": "table", "img_path": "qqQFOcUEqM/tmp/5dec9790a2d33b88d41f0f443dc07e803bf728f7221f62f879c57bc75429b70e.jpg", "table_caption": ["Table 10: Analysis of the number of the superclasses constructing the conjugated Semantic Pool. "], "table_footnote": [], "page_idx": 22}, {"type": "text", "text": "We observe that, for ID samples, incorrect OOD detection results mainly stem from the following reasons: (1) Low image clarity or VLM limitations: Due to the low clarity of the images or the limited capabilities of the VLM, the VLM provides incorrect classification results. For instance, the category of image ImageNet_ILSVRC2012_val_00002364 in Fig. 7 is \"coho (silver salmon)\", but CLIP mistakenly classifies it as \"chum salmon\", thereby identifying it as an OOD sample. (2) Inaccurate ground truth labels: Some images have ground truth labels that are not precise enough. For example, the image ImageNet_ILSVRC2012_val_00004471 in Fig. 8 is labeled as \"coil or spiral\", which is not commonly used to refer to a spiral staircase. This leads the model to classify the image as a \"helter-skelter structure\", a more accurate OOD category. (3) Multiple elements in images: Certain images contain multiple elements that correspond to several appropriate labels. Although we selected OOD labels with low similarity to the ID label space, it does not ensure that OOD labels are entirely unrelated to the specific ID images. For instance, the image ImageNet_ILSVRC2012_val_00003031 in Fig. 8 is labeled as \"doormat\", but \"cursive view\" and \"frosty view\" are also suitable descriptions, resulting in incorrect OOD detection. ", "page_idx": 22}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/b06952c40b3b8fb5001a769a9c17709415f190878c5313127664402ffbfec4a5.jpg", "img_caption": ["Figure 4: ID Examples of correct OOD detection, correct classification, and high confidence. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "D.2 Out-of-distribution examples ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Figs. 9,11,13, and 15 show OOD images from the iNaturalist, Places, SUN, and Textures datasets, respectively, that have been correctly classified as OOD samples. Contrarily, Figs. 10,12,14, and 16 display the failure cases, where OOD images are misclassified as ID ones. ", "page_idx": 22}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/db9781feba0a0f2c93dd5ccf18e934116c3ad9aaa03b56b5f5b551e43d327104.jpg", "img_caption": ["Figure 5: ID Examples of correct OOD detection, correct classification, and low confidence. "], "img_footnote": [], "page_idx": 23}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/6f4763265aeaadb83a73b8c4233facce0eccb5275952d7f948142bd8a9b93ae3.jpg", "img_caption": ["Figure 6: ID Examples of correct OOD detection and incorrect classification. "], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "We observe that there are two primary reasons for OOD misdetection results in OOD datasets: (1) Absence of suitable OOD labels: In the process of selecting potential OOD labels, elements in the semantic pool that have a high similarity to ID labels are discarded. This may lead to the absence of corresponding labels for OOD images. For example, in Fig. 16, the image named waffled_0103 depicts a waffle. However, the OOD label candidates do not include the label \"waffle\", resulting in the image being incorrectly classified as the ID category \"waffle iron\". (2) Presence of ID category objects within some OOD images: For instance, in Fig. 12, the image s_ski_slope_00004560 from the Places dataset, whose label is \"ski slope\", depicts a man skiing on a ski slope. Actually, classifying it as the ID category $\"s k i\"$ is entirely correct, and this image should not be considered an OOD sample. Similarly, in Fig. 16, the label of the image striped_0032 from the Texture dataset, which shows part of a zebra, is \"striped\", but it is also reasonable that CLIP directly classifies it as the ID category \"zebra\". Thus, although the ImageNet-1k OOD detection benchmark established by [26] has been widely used, constructing more accurate and comprehensive OOD datasets remains crucial for further advancements in this field. We will pursue this as a future research direction. ", "page_idx": 23}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/927c1057551eee69162bdcfcab635c19ad764e3d95dc3a361986adf0b82db8c4.jpg", "img_caption": ["Figure 7: ID Examples of incorrect OOD detection classified into the original semantic pool. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/ed18c9301ec4d44e08e64047d3bca86e7cd1b98f0b11ef17eee600079666e8d1.jpg", "img_caption": ["Figure 8: ID Examples of incorrect OOD detection classified into the conjugated semantic pool. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/ee9a8ef36ea349a3d95a7dec8578e80e70c231c0ec057306fbf89d74dbf95085.jpg", "img_caption": ["Figure 9: OOD Examples of correct OOD detection from iNaturalist. "], "img_footnote": [], "page_idx": 24}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/4dc139ea2d57161fd915ad25e08f149a7581f6c91f0856cbfab7095a726e0a81.jpg", "img_caption": ["Figure 10: OOD Examples of incorrect OOD detection from iNaturalist. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/83165c7308379410c75689091e4c7ffec843dabd492cdca1db7b126b5a28d26c.jpg", "img_caption": ["Figure 11: OOD Examples of correct OOD detection from Places. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/27a79b45b4f9133cbfec98a52f7cf3ed0eab1b657e5dfc4b60b65c7e27010edc.jpg", "img_caption": ["Figure 12: OOD Examples of incorrect OOD detection from Places. "], "img_footnote": [], "page_idx": 25}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/220e325c7d927c4932e5b08994270dd43b96cca009647e905eda9c9f2f41bea4.jpg", "img_caption": ["Figure 13: OOD Examples of correct OOD detection from SUN. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/dae181ed1d5a31a97c59471efbf0a63d0097a2ecc924fa49863d719e2ab03087.jpg", "img_caption": ["Figure 14: OOD Examples of incorrect OOD detection from SUN. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/cc0edd5c6d64924a3d83f240d0dd4c220cfad827b160546e6c8971f88ea87779.jpg", "img_caption": ["Figure 15: OOD Examples of correct OOD detection from Textures. "], "img_footnote": [], "page_idx": 26}, {"type": "image", "img_path": "qqQFOcUEqM/tmp/9ca5bc79dc246ed2643c05a3e209e8c2d0dd636c585aa135fed6ed86e486c9aa.jpg", "img_caption": ["Figure 16: OOD Examples of incorrect OOD detection from Textures. "], "img_footnote": [], "page_idx": 27}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The abstract and introduction clearly state the paper\u2019s contributions and scope. Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 28}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: The limitations are discussed in Section 6. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 28}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: The full set of assumptions and proofs is provided in Appendix A. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 29}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "Justification: We have provided necessary information for reproduction in Section 5.1. Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 29}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: Our source codes are available in https://github.com/MengyuanChen21/ NeurIPS2024-CSP. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 30}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: Our method does not require training. All the test details necessary to understand the results have been provided in Section 5. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 30}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: We provide the standard deviations, which are commonly used as error bars, for the main experiment results under different random seeds in Appendix C.2. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 30}, {"type": "text", "text": "", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The computational cost is analyzed in Section 5.1. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 31}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The research conforms with the NeurIPS Code of Ethics in every respect. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 31}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 31}, {"type": "text", "text": "Justification: Given the focus on zero-shot OOD detection, the paper prioritizes discussing technical methodologies and results rather than societal impacts. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: The paper exploring zero-shot OOD detection poses no such risks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: We have properly credited the used assets. All the datasets and lexicons, introduced in Appendix B, are available for free to researchers for non-commercial use. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 32}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: New assets introduced in the paper are well documented and the documentation is provided alongside the assets. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 33}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 33}]