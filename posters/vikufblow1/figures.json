[{"figure_path": "VikufBLOW1/figures/figures_1_1.jpg", "caption": "Figure 1: Two failure cases of the visual entity recognition dataset of [7]. Our proposed method overcomes these limitations by prompting a multimodal LLM to correct candidate entities. The LLM has access to relevant context such as the candidate entity Wikipedia page and the input image-caption pair. We also enrich the dataset with rationales and question/answer pairs covering diverse entities.", "description": "This figure shows two examples where existing visual entity recognition datasets fail.  In (a), an image of a residential building is wrongly labeled as \"Negative equity\" due to an irrelevant caption. In (b), a fish image is incorrectly labeled as a moth due to an inaccurate caption-entity match. The authors propose a new method using a multimodal Large Language Model (LLM) to solve this, which includes verifying and correcting candidate entities, generating rationales explaining image-entity relationships, and creating diverse question-answer pairs to enhance the dataset.", "section": "1 Introduction"}, {"figure_path": "VikufBLOW1/figures/figures_2_1.jpg", "caption": "Figure 2: LLM-Refined Entity-WebLI\" (REW) dataset. We propose a method to refine the Entity-WebLI dataset of Caron et al. [7] by prompting a multimodal LLM to verify and correct Wikipedia entities. We also prompt the multimodal LLM to output visually grounded rationales and question-answer pairs about diverse attributes of the image. Complete prompts are in Appendix A.3.1.", "description": "This figure illustrates the proposed LLM-Refined Entity-WebLI (REW) dataset creation method.  It shows how a multimodal Large Language Model (LLM) is used to refine an existing dataset (Entity-WebLI) by verifying and correcting entity labels. The LLM accesses image captions, Wikipedia content, and prompts to reason about potential entity labels, resulting in more accurate annotations. The LLM also generates visually grounded rationales and question-answer pairs to further enrich the dataset.", "section": "3 Method"}, {"figure_path": "VikufBLOW1/figures/figures_7_1.jpg", "caption": "Figure 1: Two failure cases of the visual entity recognition dataset of [7]. Our proposed method overcomes these limitations by prompting a multimodal LLM to correct candidate entities. The LLM has access to relevant context such as the candidate entity Wikipedia page and the input image-caption pair. We also enrich the dataset with rationales and question/answer pairs covering diverse entities.", "description": "This figure shows two examples where the visual entity recognition dataset of Caron et al. [7] fails.  In (a), an image of a building is incorrectly labeled \"Negative equity\" due to an irrelevant caption. In (b), the caption is incorrectly matched with a different animal species. The authors propose a new method using a multimodal LLM to correct these errors by providing additional context and enriching the dataset with rationales and question-answer pairs.", "section": "1 Introduction"}, {"figure_path": "VikufBLOW1/figures/figures_7_2.jpg", "caption": "Figure 3: Qualitative analysis of the importance of the entity verification and correction step.", "description": "This figure shows examples where the multimodal LLM, with and without access to Wikipedia and original captions, makes incorrect corrections.  It highlights how access to additional context significantly improves the accuracy of entity correction. The examples illustrate cases of hallucination, overly generic outputs, and situations where the LLM corrects an already correct entity.  It also shows that only using the original caption as a target also leads to suboptimal performance.", "section": "Analysis and ablation study"}, {"figure_path": "VikufBLOW1/figures/figures_7_3.jpg", "caption": "Figure 1: Two failure cases of the visual entity recognition dataset of [7]. Our proposed method overcomes these limitations by prompting a multimodal LLM to correct candidate entities. The LLM has access to relevant context such as the candidate entity Wikipedia page and the input image-caption pair. We also enrich the dataset with rationales and question/answer pairs covering diverse entities.", "description": "This figure showcases two examples where the visual entity recognition dataset from Caron et al. [7] fails.  The first example shows an image of a building incorrectly linked to the entity \"Negative equity\" due to an irrelevant caption. The second shows an image of a fish incorrectly matched with a moth's entity name. The authors' proposed method addresses these issues by using a multimodal LLM to verify and correct candidate entities, while enriching the dataset with rationales and question-answer pairs.", "section": "1 Introduction"}, {"figure_path": "VikufBLOW1/figures/figures_13_1.jpg", "caption": "Figure 2: LLM-Refined Entity-WebLI\" (REW) dataset. We propose a method to refine the Entity-WebLI dataset of Caron et al. [7] by prompting a multimodal LLM to verify and correct Wikipedia entities. We also prompt the multimodal LLM to output visually grounded rationales and question-answer pairs about diverse attributes of the image. Complete prompts are in Appendix A.3.1.", "description": "This figure illustrates the proposed LLM-Refined Entity-WebLI (REW) dataset creation method.  It shows how a multimodal LLM is used to verify and correct entity labels from the Entity-WebLI dataset by accessing additional context (like Wikipedia pages). The LLM also generates rationales (explanations) and question-answer pairs to enrich the dataset, improving the accuracy and detail of the annotations.", "section": "3 Method"}, {"figure_path": "VikufBLOW1/figures/figures_14_1.jpg", "caption": "Figure 2: LLM-Refined Entity-WebLI\" (REW) dataset. We propose a method to refine the Entity-WebLI dataset of Caron et al. [7] by prompting a multimodal LLM to verify and correct Wikipedia entities. We also prompt the multimodal LLM to output visually grounded rationales and question-answer pairs about diverse attributes of the image. Complete prompts are in Appendix A.3.1.", "description": "This figure illustrates the LLM-Refined Entity-WebLI (REW) dataset creation process.  It shows how a multimodal LLM is used to refine the existing Entity-WebLI dataset by verifying and correcting Wikipedia entities associated with images.  The LLM also generates rationales (explanations) and question-answer pairs to enrich the dataset, improving the connection between images and their associated entities.", "section": "3 Method"}]