[{"figure_path": "0uGlKYS7a2/tables/tables_13_1.jpg", "caption": "Example 1. Consider the zero sum game where:", "description": "This table presents a zero-sum game example with specific utility matrices A and B for the optimizer and the learner, respectively.  It highlights how different min-max strategies for the optimizer can lead to varying numbers of best responses from the learner. The table showcases a specific game where one min-max strategy is particularly effective when the learner utilizes the Multiplicative Weights Update (MWU) algorithm.", "section": "B.1 Continuous games"}, {"figure_path": "0uGlKYS7a2/tables/tables_14_1.jpg", "caption": "Example 1. Consider the zero sum game where:", "description": "This table presents a zero-sum game example used to illustrate a point in the paper. The example highlights a situation where the optimizer can gain significantly more utility by leveraging the suboptimality of the learner's strategy (using MWU), as compared to the theoretical minimum utility guaranteed by minmax strategies.", "section": "B.1 Continuous games"}, {"figure_path": "0uGlKYS7a2/tables/tables_16_1.jpg", "caption": "Example 1. Consider the zero sum game where:", "description": "This table presents a zero-sum game matrix A, where the rows represent actions for player 1 (optimizer) and columns represent actions for player 2 (learner).  The entries show the utility for player 1.  The game demonstrates the concept of multiple min-max strategies for the optimizer, but some provide better rewards against the Multiplicative Weights Update (MWU) algorithm than others.  This is used to illustrate a point in the paper.", "section": "B.1 Continuous games"}, {"figure_path": "0uGlKYS7a2/tables/tables_17_1.jpg", "caption": "Example 1. Consider the zero sum game where:", "description": "This table shows a zero-sum game matrix A and its corresponding matrix B, where the optimizer's goal is to maximize its utility and the learner uses a learning algorithm. The table illustrates an example where multiple min-max strategies exist for the optimizer, but only one of them provides optimal rewards when used against a learner employing the Multiplicative Weights Update (MWU) algorithm. This highlights the complexity of optimizing against adaptive learners in zero-sum games. The example showcases how the discrete-time optimizer's performance can differ from that of the continuous-time optimizer against a learner using MWU.", "section": "B.2 Discrete Case"}, {"figure_path": "0uGlKYS7a2/tables/tables_23_1.jpg", "caption": "Table 1: Utility matrices A and B for the example in Section C.", "description": "This table shows the utility matrices A and B used in an example illustrating the reduction from the Hamiltonian cycle problem to the Optimal Control Discrete Pure (OCDP) problem.  Matrix A represents the optimizer's utilities, while matrix B represents the learner's utilities. The rows correspond to the optimizer's actions (edges in the graph), and the columns correspond to the learner's actions (vertices in the graph and their incoming edges).  The values indicate the utilities obtained by each player given a specific combination of actions. This example demonstrates how the construction of the matrices encodes the constraints of finding a Hamiltonian cycle in the graph to construct a YES/NO instance of the OCDP problem.", "section": "C Computational lower bound"}, {"figure_path": "0uGlKYS7a2/tables/tables_23_2.jpg", "caption": "Table 3: Matrix B", "description": "This table shows the utility matrix B for the learner.  Each cell (a\u1d62,b\u2c7c) represents the utility the learner receives when the optimizer plays action a\u1d62 and the learner plays action b\u2c7c.  Note the different values depending on whether the action is an incoming or outgoing edge in the graph used for the Hamiltonian Cycle problem reduction.  The values reflect the design to incentivize the learner to follow a Hamiltonian cycle.", "section": "C Computational lower bound"}, {"figure_path": "0uGlKYS7a2/tables/tables_23_3.jpg", "caption": "Table 1: The rewards history of the learner during this game", "description": "This table shows the evolution of the learner's rewards (h(t)) for each action across multiple rounds (t) of a game. Each row represents a round, and each column shows the cumulative rewards for a specific action.  The rewards are updated after each round, reflecting the influence of the optimizer's actions. This data is used in the proof to demonstrate that the optimal strategy for the optimizer leads to a specific sequence of learner actions and a final cumulative reward of n+1. This is part of the reduction from Hamiltonian Cycle problem to Optimal Control Discrete Pure problem.", "section": "C Computational lower bound"}]