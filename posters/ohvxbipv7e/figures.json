[{"figure_path": "ohvXBIPV7e/figures/figures_1_1.jpg", "caption": "Figure 1: An example dataset of vectors and its proximity graph.", "description": "The figure shows an example dataset of vectors represented as nodes and their proximity graph which visualizes the relationships between the vectors.  (a) shows the dataset in a 2D space, and (b) illustrates a Relative Neighborhood Graph (RNG) constructed from this data, demonstrating how vectors with closer proximity are connected by edges.", "section": "1 Introduction"}, {"figure_path": "ohvXBIPV7e/figures/figures_3_1.jpg", "caption": "Figure 2: An example of CSPG index, where the proximity graphs are built using relative neighborhood graph G\u2081 and G\u2082 (with very similar degree to Figure 1b).", "description": "This figure shows an example of a CSPG index.  It illustrates how the dataset is randomly partitioned into subsets (P1 and P2 in this case), and each subset has its own sparse proximity graph (G1 and G2, built using relative neighborhood graphs).  The key point is that the partitions share common vectors (routing vectors, highlighted in red), which allow the greedy search algorithm to traverse between different partitions during the search process, improving efficiency. The green graph represents G1 and the blue graph represents G2.", "section": "3.1 CSPG: Crossing Sparse Proximity Graphs"}, {"figure_path": "ohvXBIPV7e/figures/figures_7_1.jpg", "caption": "Figure 3: QPS v.s. recall curves for comparing query performance", "description": "This figure shows the query performance (Queries Per Second or QPS) against the recall@10 for different datasets (SIFT1M, GIST1M, DEEP1M, SIFT10M) and various approximate nearest neighbor search (ANNS) algorithms.  The algorithms include HNSW, Vamana, and HCNNG, both in their original forms and enhanced with the proposed CSPG framework.  The plot illustrates the speedup achieved by integrating CSPG into existing ANNS algorithms.  It shows that CSPG consistently improves the QPS across all datasets and algorithms at a fixed recall, suggesting a significant performance enhancement.", "section": "6.2 Evaluating query performance"}, {"figure_path": "ohvXBIPV7e/figures/figures_8_1.jpg", "caption": "Figure 4: Query performance when varying the dataset size n", "description": "This figure displays the Query Performance per Second (QPS) versus Recall@10 for different dataset sizes (n).  The datasets are variations of the SIFT dataset, ranging from 0.1 million to 5 million vectors.  Each line represents the performance of a specific algorithm, with solid lines indicating the CSPG-enhanced versions and dashed lines representing the original algorithms (HNSW, Vamana, and HCNNG).  The results show that CSPG consistently improves performance across all dataset sizes and algorithms, though the improvement is less dramatic as the dataset size grows.", "section": "6.4 Impact of factors and parameters"}, {"figure_path": "ohvXBIPV7e/figures/figures_8_2.jpg", "caption": "Figure 5: Query performance when varying the number of partitions m", "description": "This figure shows the impact of varying the number of partitions (m) on the query performance (QPS) of the CSPG method.  It presents QPS vs. Recall@10 curves for three different graph-based ANNS algorithms (HNSW, Vamana, and HCNNG) integrated with CSPG.  Each curve represents a different number of partitions, allowing for comparison of how the choice of m affects the speed and accuracy of the approximate nearest neighbor search.  The results indicate that a moderate number of partitions usually yields optimal performance, with extremes (too few or too many) degrading performance.", "section": "6.4 Impact of factors and parameters"}, {"figure_path": "ohvXBIPV7e/figures/figures_8_3.jpg", "caption": "Figure 12: Query performance when varying the sampling ratio \u03bb", "description": "This figure displays the impact of varying the sampling ratio (\u03bb) on the query performance of the CSPG method across different recall levels. The sampling ratio determines the proportion of vectors randomly selected as routing vectors before partitioning the dataset.  The figure shows that for each of the three graph-based ANNS algorithms (HNSW, Vamana, and HCNNG), the performance generally increases with a higher sampling ratio.  This suggests that having a greater number of routing vectors improves the effectiveness of navigating across the different partitions during the search.", "section": "6.4 Impact of factors and parameters"}, {"figure_path": "ohvXBIPV7e/figures/figures_9_1.jpg", "caption": "Figure 7: Query performance when varying the candidate set size ef\u2081 in the first stage", "description": "This figure shows how the query performance (QPS) of the CSPG method varies with different candidate set sizes (ef1) in the first stage of the two-stage search process. It compares three different graph-based ANNS algorithms (HNSW, Vamana, and HCNNG) enhanced with CSPG. The x-axis represents the recall@10, and the y-axis represents the QPS.  Each line represents a different ef1 value, illustrating the trade-off between speed and accuracy.  A smaller ef1 leads to faster query times but potentially lower accuracy, while a larger ef1 results in higher accuracy but slower queries.", "section": "6.4 Impact of factors and parameters"}, {"figure_path": "ohvXBIPV7e/figures/figures_9_2.jpg", "caption": "Figure 8: Detour factor when varying the dataset size n", "description": "This figure displays the detour factor (w) against Recall@10 for different dataset sizes (n) using three different graph-based ANNS algorithms integrated with CSPG. The detour factor represents the extent to which the search paths deviate from monotonicity. The figure illustrates how the detour factor changes with varying dataset sizes, providing insight into the impact of data size on search efficiency and monotonicity.", "section": "6.4 Impact of factors and parameters"}, {"figure_path": "ohvXBIPV7e/figures/figures_9_3.jpg", "caption": "Figure 3: QPS v.s. recall curves for comparing query performance", "description": "This figure shows the query performance (Queries Per Second or QPS) against the recall@10 for different approximate nearest neighbor search (ANNS) algorithms.  It compares the performance of several traditional ANNS algorithms (HNSW, Vamana, HCNNG, NSG, and two faiss implementations) against their enhanced versions that incorporate the Crossing Sparse Proximity Graphs (CSPG) framework proposed in the paper. The x-axis represents the recall@10 (the fraction of the top 10 nearest neighbors correctly retrieved), and the y-axis represents the QPS.  The plot demonstrates that the CSPG-enhanced algorithms consistently outperform their base counterparts across various recall levels, showcasing the effectiveness of the CSPG framework in improving query efficiency while maintaining a high recall rate.", "section": "6.2 Evaluating query performance"}, {"figure_path": "ohvXBIPV7e/figures/figures_16_1.jpg", "caption": "Figure 10: Number of distance computation v.s. recall curves for comparing query performance", "description": "This figure compares the number of distance computations required by the original graph-based ANNS algorithms (HNSW, Vamana, and HCNNG) and their CSPG enhanced versions across four benchmark datasets (SIFT1M, GIST1M, DEEP1M, and SIFT10M) at varying recall@10 values.  It illustrates the reduction in distance computations achieved by incorporating CSPG into each algorithm. The x-axis represents the recall@10, and the y-axis represents the number of distance computations. Each line represents a different algorithm, with solid lines representing the original algorithms and dashed lines representing their CSPG counterparts.  The figure visually demonstrates the efficiency gains obtained by using CSPG.", "section": "6.2 Evaluating query performance"}, {"figure_path": "ohvXBIPV7e/figures/figures_16_2.jpg", "caption": "Figure 11: Query performance when varying the number of partitions m", "description": "This figure shows the impact of varying the number of partitions (m) on the query performance of the CSPG method.  It displays QPS (Queries Per Second) versus Recall@10 for different values of m (1, 2, 4, 8, 16).  The results are shown for three datasets (SIFT1M, GIST1M, and DEEP1M) and three graph-based ANNS algorithms integrated with CSPG (HNSW, Vamana, and HCNNG).  The figure illustrates how the choice of m affects the balance between speed and accuracy for each algorithm and dataset.", "section": "6.4 Impact of factors and parameters"}, {"figure_path": "ohvXBIPV7e/figures/figures_16_3.jpg", "caption": "Figure 7: Query performance when varying the candidate set size ef\u2081 in the first stage", "description": "This figure shows the impact of varying the candidate set size (ef1) in the first stage of the CSPG search algorithm on the query performance.  It presents QPS (Queries Per Second) versus Recall@10 curves for three different graph-based ANNS algorithms (HNSW, Vamana, HCNNG) enhanced by CSPG.  Each curve within a subplot represents a different ef1 value, demonstrating how this parameter affects the trade-off between speed and accuracy across various datasets (SIFT1M, GIST1M, DEEP1M). The results illustrate how the choice of ef1 influences the algorithm's efficiency and effectiveness in quickly approaching the query vector.", "section": "4.2 The Second Stage: cross-partition expansion for precise search"}, {"figure_path": "ohvXBIPV7e/figures/figures_17_1.jpg", "caption": "Figure 12: Query performance when varying the sampling ratio \u03bb", "description": "This figure shows the impact of varying the sampling ratio \u03bb on the query performance of CSPG with different graph-based ANNS algorithms (HNSW, Vamana, and HCNNG) across various datasets (SIFT1M, GIST1M, and DEEP1M).  The x-axis represents Recall@10, and the y-axis represents QPS (Queries Per Second). Each line represents a different value of \u03bb, ranging from 0.1 to 0.5.  The results demonstrate that changes in \u03bb affect the trade-off between recall and query speed.  Higher values of \u03bb generally lead to better recall but lower QPS, suggesting a balance needs to be found between the number of routing vectors and the sparsity of individual graphs.", "section": "6.4 Impact of factors and parameters"}, {"figure_path": "ohvXBIPV7e/figures/figures_17_2.jpg", "caption": "Figure 3: QPS v.s. recall curves for comparing query performance", "description": "This figure compares the query performance of the CSPG method with the baseline methods (HNSW, Vamana, and HCNNG) across four benchmark datasets (SIFT1M, GIST1M, DEEP1M, and SIFT10M). It showcases the QPS (Queries Per Second) achieved at different recall levels (@10).  The results demonstrate that CSPG consistently outperforms the baseline algorithms in terms of query speed for various recall levels, highlighting the efficiency gains achieved by the proposed approach.", "section": "6.2 Evaluating query performance"}]