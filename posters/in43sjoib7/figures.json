[{"figure_path": "iN43sJoib7/figures/figures_1_1.jpg", "caption": "Figure 1: Experimental results illustrating the mean squared error (MSE) and the number of parameters with varying input sequence lengths on ETTm1. Each bubble represents a different model, with the bubble size indicating the number of parameters in millions\u2014larger bubbles denote models with more parameters. Our model consistently shows the lowest MSE (i.e., best performance) with fewer parameters even for longer input sequences. The detailed results can be found in Table 5.", "description": "This figure shows the mean squared error (MSE) and the number of parameters (in millions) for different models on the ETTm1 dataset with various input sequence lengths.  The size of each bubble corresponds to the number of parameters used.  The model proposed in the paper (labeled \"Ours\") consistently achieves the lowest MSE across all sequence lengths with the fewest number of parameters.", "section": "1 Introduction"}, {"figure_path": "iN43sJoib7/figures/figures_2_1.jpg", "caption": "Figure 2: Absolute values of weights in the final linear layer for different PatchTST variations. The distinct patterns reveal how each model captures temporal information.", "description": "This figure shows the absolute values of weights in the final linear layer for three variations of the PatchTST model: (a) original PatchTST with overlapping patches, (b) PatchTST with non-overlapping patches, and (c) PatchTST with self-attention replaced by a linear embedding layer.  The different patterns illustrate how effectively each model captures temporal information. The version with linear embedding shows the clearest capture, suggesting that self-attention is not necessary for this task.", "section": "3 Revisiting Self-Attention in Time Series Forecasting"}, {"figure_path": "iN43sJoib7/figures/figures_3_1.jpg", "caption": "Figure 3: Illustration of existing time series forecasting architectures and the proposed architecture.", "description": "This figure compares four different architectures for time series forecasting. (a) shows a standard Transformer architecture with both encoder and decoder, using self-attention and cross-attention mechanisms. (b) is a simplified encoder-only Transformer architecture, relying only on self-attention. (c) represents a linear model, which does not use any attention mechanism. (d) is the proposed CATS (Cross-Attention-only Time Series Transformer) architecture, which only uses cross-attention and eliminates self-attention.", "section": "Rethinking Transformer Design"}, {"figure_path": "iN43sJoib7/figures/figures_4_1.jpg", "caption": "Figure 4: Illustration on the proposed model architecture. Our model removes all self-attentions from the original Transformer structure and focuses on cross-attentions. To fully utilize the cross-attention, we conceptualize the future horizon as queries and use the input time series (i.e., past time series) as keys and values (Fig. A). This simplified structure enables us to enhance the parameter sharing across forecasting horizons (Fig. B) and make use of query-adaptive masking (Fig. C) for performance.", "description": "This figure illustrates the architecture of the proposed Cross-Attention-only Time Series Transformer (CATS) model.  It highlights three key components: (A) Cross-Attention with Future as Query, (B) Parameter Sharing across Horizons, and (C) Query-Adaptive Masking.  Panel A shows how future horizons are used as queries in the cross-attention mechanism, while past time series data serve as keys and values. Panel B demonstrates the parameter sharing strategy employed to enhance efficiency. Panel C details the query-adaptive masking technique used to improve performance by preventing access to irrelevant time series data for each horizon.", "section": "4 Proposed Methodology"}, {"figure_path": "iN43sJoib7/figures/figures_7_1.jpg", "caption": "Figure 5: Efficiency and performance analysis for time series forecasting models. We summarize the forecasting performance, number of parameters, GPU memory consumption, and running time with varying forecasting horizon lengths on Traffic. The running time is averaged from 300 iterations.", "description": "This figure presents a comparative analysis of various time series forecasting models, focusing on efficiency and performance across different forecasting horizons on the Traffic dataset. It shows four sub-figures: (a) Model Performance (MSE across different forecasting horizons), (b) Parameter Efficiency (number of parameters across horizons), (c) Memory Efficiency (GPU memory consumption across horizons), and (d) Running Time Efficiency (running time per iteration across horizons). The analysis reveals that the proposed CATS model demonstrates superior performance and efficiency compared to other models, especially for longer forecasting horizons.", "section": "5.2 Efficient and Robust Forecasting for Long Input Sequences"}, {"figure_path": "iN43sJoib7/figures/figures_9_1.jpg", "caption": "Figure 6: Score map of cross-attentions between input and output patches.", "description": "The figure shows the cross-attention score maps (12 \u00d7 18) for two attention heads in the CATS model.  Each map visualizes the attention weights between input and output patches, revealing how the model attends to different parts of the input sequence when making predictions.  The patterns in the maps illustrate the model's ability to capture both shock values and periodicities in the input time series data.  Specifically, the periodic patterns in the attention weights reflect the model's understanding of the temporal dependencies in the data, which is essential for accurate time series forecasting. The clear patterns in the attention weights show the model's capacity to discern temporal structures in the input data and use that information effectively for prediction. The higher the value in the map, the stronger the attention between the corresponding input and output patches.", "section": "5.5 Explaining Periodic Patterns through Cross-Attention"}, {"figure_path": "iN43sJoib7/figures/figures_9_2.jpg", "caption": "Figure 6: Score map of cross-attentions between input and output patches.", "description": "This figure visualizes the attention weights between input and output patches in the Cross-Attention-only Time Series Transformer (CATS) model.  It shows how the model attends to different parts of the input sequence when making predictions. The distinct patterns reveal how the model captures temporal information and periodic patterns in time series data.  Specifically, it highlights the model's ability to identify and utilize periodic information for accurate forecasting. The clarity of the patterns in this figure contrasts with previous models and showcases the advantages of CATS.", "section": "3 Revisiting Self-Attention in Time Series Forecasting"}, {"figure_path": "iN43sJoib7/figures/figures_19_1.jpg", "caption": "Figure 1: Experimental results illustrating the mean squared error (MSE) and the number of parameters with varying input sequence lengths on ETTm1. Each bubble represents a different model, with the bubble size indicating the number of parameters in millions\u2014larger bubbles denote models with more parameters. Our model consistently shows the lowest MSE (i.e., best performance) with fewer parameters even for longer input sequences. The detailed results can be found in Table 5.", "description": "This figure compares the performance of different time series forecasting models, including the proposed CATS model, on the ETTm1 dataset.  It visualizes the mean squared error (MSE) achieved by each model against the number of parameters used.  The size of each bubble corresponds to the number of parameters (in millions), allowing for a visual comparison of model complexity.  The figure demonstrates that the CATS model consistently achieves the lowest MSE with a significantly smaller number of parameters, highlighting its superior performance and efficiency.", "section": "1 Introduction"}, {"figure_path": "iN43sJoib7/figures/figures_20_1.jpg", "caption": "Figure 9: Visualization of input signals for toy experiment.", "description": "This figure visualizes the two synthetic input signals used in the toy experiment presented in Section 5.5 of the paper.  The first signal is a randomly generated time series, illustrating the complexity and unpredictability of real-world data.  The second signal is designed to incorporate a periodic shock component with a phase difference of 4, representing periodic patterns often found in real-world time-series such as electricity demand or weather data. The third subplot shows the combination of the two signals, designed to test the model\u2019s ability to distinguish between noise and periodic patterns.", "section": "5.5 Explaining Periodic Patterns through Cross-Attention"}, {"figure_path": "iN43sJoib7/figures/figures_20_2.jpg", "caption": "Figure 7: Illustration of (a) forecasting result, (b) averaged cross-attention score, and (c,d) patches with the highest score on ETTm1. The score map is averaged from all the heads across layers.", "description": "This figure shows the forecasting results of the proposed CATS model on the ETTm1 dataset.  It highlights the model's ability to capture temporal dependencies through cross-attention. Panel (a) presents the predicted and actual time series. Panel (b) displays a heatmap representing the average cross-attention scores across all attention heads and layers. The brighter the color, the higher the attention score, indicating stronger relationships between input and output patches. Panels (c) and (d) zoom into specific patches with the highest attention scores, demonstrating how CATS uses past data to predict future values, showcasing its understanding of temporal patterns.", "section": "5.5 Explaining Periodic Patterns through Cross-Attention"}, {"figure_path": "iN43sJoib7/figures/figures_21_1.jpg", "caption": "Figure 6: Score map of cross-attentions between input and output patches.", "description": "This figure visualizes the attention weights between input and output patches in the CATS model.  The heatmaps show the attention scores for two different attention heads.  The distinct patterns reveal how the model captures temporal information and periodic patterns within the time series data, highlighting the effectiveness of cross-attention in this architecture.", "section": "3 Revisiting Self-Attention in Time Series Forecasting"}, {"figure_path": "iN43sJoib7/figures/figures_21_2.jpg", "caption": "Figure 7: Illustration of (a) forecasting result, (b) averaged cross-attention score, and (c,d) patches with the highest score on ETTm1. The score map is averaged from all the heads across layers.", "description": "This figure visualizes the forecasting results of the CATS model on the ETTm1 dataset, along with the averaged cross-attention score map.  The score map highlights the attention weights assigned to different input patches during prediction. The figure also shows two example pairs of input and output patches with the highest attention weights. These visualizations illustrate how CATS leverages cross-attention to capture temporal dependencies and patterns in the time series data for accurate forecasting.", "section": "5.5 Explaining Periodic Patterns through Cross-Attention"}, {"figure_path": "iN43sJoib7/figures/figures_21_3.jpg", "caption": "Figure 7: Illustration of (a) forecasting result, (b) averaged cross-attention score, and (c,d) patches with the highest score on ETTm1. The score map is averaged from all the heads across layers.", "description": "This figure shows the forecasting results, cross-attention score map, and patches with the highest attention scores for the ETTm1 dataset.  The cross-attention score map visualizes the attention weights between input and output patches, highlighting the model's ability to capture temporal dependencies and periodic patterns in the time series data. The patches with the highest scores further illustrate how the model focuses on specific parts of the time series for accurate predictions. This figure provides visual support for the model's ability to effectively capture temporal patterns and improve prediction accuracy.", "section": "5.5 Explaining Periodic Patterns through Cross-Attention"}, {"figure_path": "iN43sJoib7/figures/figures_21_4.jpg", "caption": "Figure 6: Score map of cross-attentions between input and output patches.", "description": "This figure visualizes the attention weights between input and output patches in the CATS model.  The distinct patterns reveal how the model captures temporal information, particularly periodic patterns.  The heatmap shows the attention scores for each pair of input and output patches, illustrating which input patches are most relevant to predicting each output patch's value.  High attention scores indicate a strong relationship between the corresponding input and output patches.", "section": "5.5 Explaining Periodic Patterns through Cross-Attention"}, {"figure_path": "iN43sJoib7/figures/figures_22_1.jpg", "caption": "Figure 7: Illustration of (a) forecasting result, (b) averaged cross-attention score, and (c,d) patches with the highest score on ETTm1. The score map is averaged from all the heads across layers.", "description": "Figure 7 presents the forecasting results and cross-attention scores on the ETTm1 dataset, highlighting the model's ability to capture temporal patterns.  Subfigure (a) shows the forecasting results, comparing ground truth and model predictions. Subfigure (b) displays an averaged cross-attention score map, visualizing the attention weights between input and output patches.  Subfigures (c) and (d) illustrate specific patch pairs with the highest attention weights, further demonstrating the model's capacity to detect and utilize sequential patterns for forecasting.", "section": "5.5 Explaining Periodic Patterns through Cross-Attention"}]