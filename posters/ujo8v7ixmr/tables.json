[{"figure_path": "Ujo8V7iXmR/tables/tables_7_1.jpg", "caption": "Table 1: Experiment setup (left), and the corresponding auction outcomes (right). Note that all metrics are normalized by dividing them by their maximum possible value.", "description": "This table presents the setup of an experiment with four advertisers and their bids, along with the corresponding relevance and allocation probability for each.  The right side shows the results of four different auction mechanisms on metrics such as social welfare, revenue, relevance, and minimum social welfare. All metrics are normalized for easy comparison.", "section": "4.1 Results"}, {"figure_path": "Ujo8V7iXmR/tables/tables_8_1.jpg", "caption": "Table 2: The 2-4th columns represent the similarity of the individual segment to the original output, and the 5-7th columns represent the similarity of the first k segments to the original output.", "description": "This table presents the results of an experiment comparing different auction mechanisms for integrating ads into the output of large language models (LLMs).  The experiment measures the similarity between the original LLM output (without ads) and the modified output with ads inserted using different methods. The table shows the similarity scores for individual segments (sentences) and for the first k segments (multiple sentences) for different numbers of ads (k) and allocation strategies. Higher scores indicate greater similarity and therefore better output quality. The methods compared are:\n\n* **Seg w/ repl.:** Segment auction with replacement (same ads can be used multiple times).\n* **Seg w/o repl.:** Segment auction without replacement (each ad used only once).\n* **Naive I:**  Ads appended to the end of the output without using the LLM to integrate them.\n* **Naive II:** A naive approach where ads are selected without considering relevance scores.\n* **Multi-alloc:** Multi-allocation segment auction (multiple ads assigned to the entire document).", "section": "4.1 Results"}, {"figure_path": "Ujo8V7iXmR/tables/tables_21_1.jpg", "caption": "Table 1: Experiment setup (left), and the corresponding auction outcomes (right). Note that all metrics are normalized by dividing them by their maximum possible value.", "description": "The left part of the table shows the experimental setup, including the bids and relevance scores for four advertisers (Velora, Bookhaven, MassMart, EspressoEdge). The right part presents the results of four different auction mechanisms (Segment with replacement, Segment without replacement, Naive II, Multi-allocation) on the metrics of Social Welfare, Revenue, Relevance, and Minimum Social Welfare, all normalized.", "section": "4.1 Results"}, {"figure_path": "Ujo8V7iXmR/tables/tables_22_1.jpg", "caption": "Table 1: Experiment setup (left), and the corresponding auction outcomes (right). Note that all metrics are normalized by dividing them by their maximum possible value.", "description": "This table presents the configuration of the experiment setup and the results of four different auction mechanisms: Segment Auction with Replacement, Segment Auction without Replacement, Naive II, and Multi-allocation Auction.  The left side shows the bids and relevance scores for four advertisers: Velora, BookHaven, MassMart, and EspressoEdge. The right side shows the average results (with standard deviations) across 500 trials for each mechanism, measuring social welfare, revenue, relevance, and minimum social welfare. All metrics are normalized to a 0-1 scale by dividing by the maximum possible value, enabling easy comparison across mechanisms.", "section": "4 Results"}, {"figure_path": "Ujo8V7iXmR/tables/tables_22_2.jpg", "caption": "Table 5: Bids and relevance of the advertisers for Scenario 3.", "description": "This table shows the bids submitted by each advertiser and their corresponding relevance scores for Scenario 3 of the experiment.  Scenario 3 uses a larger number of advertisers (11) compared to the previous scenarios. The relevance score (qi) indicates how relevant each advertiser's ad is to the user query, and it influences the probability of the ad being selected in the auction.", "section": "4 Experiments"}, {"figure_path": "Ujo8V7iXmR/tables/tables_22_3.jpg", "caption": "Table 1: Experiment setup (left), and the corresponding auction outcomes (right). Note that all metrics are normalized by dividing them by their maximum possible value.", "description": "This table presents the setup of an experiment, showing the bids and relevance scores for four advertisers. It also shows the results of four different auction mechanisms applied to this setup: the segment auction with replacement, the segment auction without replacement, Naive II, and the multi-allocation auction.  The outcomes measured are social welfare, revenue, relevance, and minimum social welfare. All values are normalized for easy comparison.", "section": "4.1 Results"}, {"figure_path": "Ujo8V7iXmR/tables/tables_22_4.jpg", "caption": "Table 2: The 2-4th columns represent the similarity of the individual segment to the original output, and the 5-7th columns represent the similarity of the first k segments to the original output.", "description": "This table presents the results of an experiment comparing the output quality of different auction mechanisms for integrating ads into LLM outputs.  The quality is measured by cosine similarity between embeddings of the original output (without ads) and the modified outputs generated by different methods. The table shows similarity scores for individual segments and the first k segments (where k is the number of ads allocated) for different auction mechanisms (segment auction with replacement, segment auction without replacement, and multi-allocation segment auction).", "section": "4.1 Results"}]