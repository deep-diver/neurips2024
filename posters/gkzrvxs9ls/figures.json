[{"figure_path": "GkzrVxs9LS/figures/figures_2_1.jpg", "caption": "Figure 1: Eigen-projection (first row) and signal concentration ratio (second row) of Vit-Base on NiH-ChestXray-14, COVIDx, and CheXpert. To compute the eigen-projection, we first calculate the eigenvectors U of the kernel gram matrix K \u2208 Rnxn computed by a feature matrix F \u2208 Rnxd, then the projection value is computed by p =  \u2211=1 || UTY(\u00a9) ||2||Y(\u00a9)||2 \u2208 R, where C is the number of classes, and Y \u2208 {0,1}n\u00d7C is the one-hot labels of all the training data, Y(c) is the c-th column of Y. The eigen-projection p, for r \u2208 [min(n, d)] reflects the amount of the signal projected onto the r-th eigenvector of K, and the signal concentration ratio of a rank r reflects the proportion of signal projected onto the top r eigenvectors of K. The signal concentration ratio for rank r is computed by ||p(1:r) ||2, where p(1:r) contains the first r elements of p. For example, by the rank r = 38, the signal concentration ratio of Y on NIH ChestX-ray14, COVIDx, and CheXpert are 0.959, 0.964, and 0.962 respectively.", "description": "This figure shows the eigen-projection and signal concentration ratio for different ranks on three datasets (NIH ChestXray-14, COVIDx, and CheXpert).  It visually demonstrates the Low Frequency Property (LFP), which shows that a low-rank projection of the ground truth training class labels contains most of the information in the original labels. This supports the use of Low-Rank Feature Learning in the paper.", "section": "Our Contributions"}, {"figure_path": "GkzrVxs9LS/figures/figures_9_1.jpg", "caption": "Figure 2: Robust Grad-CAM [95] visualization results on NIH ChestX-ray 14. The figures in the first row are the visualization results of ViT-Base, and the figures in the second row are the visualization results of Low-Rank ViT-Base.", "description": "This figure shows Grad-CAM visualization results for both the ViT-Base and the Low-Rank ViT-Base models on the NIH ChestX-ray14 dataset. Grad-CAM highlights the image regions that are most important to the model's predictions.  The top row displays the ViT-Base model's attention, while the bottom row shows the Low-Rank ViT-Base's attention.  A comparison reveals that the Low-Rank model focuses more on the disease areas, while the original ViT-Base model also highlights irrelevant background regions.", "section": "4.5.3 Grad-CAM Visualization"}, {"figure_path": "GkzrVxs9LS/figures/figures_19_1.jpg", "caption": "Figure 1: Eigen-projection (first row) and signal concentration ratio (second row) of Vit-Base on NiH-ChestXray-14, COVIDx, and CheXpert. To compute the eigen-projection, we first calculate the eigenvectors U of the kernel gram matrix K \u2208 Rnxn computed by a feature matrix F \u2208 Rnxd, then the projection value is computed by p = \u2211c=1 ||UTY(c)||2/||Y(c)||2 \u2208 R, where C is the number of classes, and Y \u2208 {0,1}n\u00d7C is the one-hot labels of all the training data, Y(c) is the c-th column of Y. The eigen-projection p, for r \u2208 [min(n, d)] reflects the amount of the signal projected onto the r-th eigenvector of K, and the signal concentration ratio of a rank r reflects the proportion of signal projected onto the top r eigenvectors of K. The signal concentration ratio for rank r is computed by ||p(1:r)||2, where p(1:r) contains the first r elements of p. For example, by the rank r = 38, the signal concentration ratio of Y on NIH ChestX-ray14, COVIDx, and CheXpert are 0.959, 0.964, and 0.962 respectively.", "description": "This figure shows the eigen-projection and signal concentration ratio for different ranks (low-rank features) on three datasets: NIH ChestXray-14, COVIDx, and CheXpert.  The eigen-projection illustrates how much of the signal from the class labels is captured by the top eigenvectors of a kernel gram matrix (computed using feature vectors). The signal concentration ratio shows the proportion of signal captured by the top r eigenvectors for different ranks, indicating how much information is contained in low-rank features. The results show that a significant amount of information from the class labels is concentrated in low-rank projections.", "section": "3 Formulation"}, {"figure_path": "GkzrVxs9LS/figures/figures_21_1.jpg", "caption": "Figure 2: Robust Grad-CAM [95] visualization results on NIH ChestX-ray 14. The figures in the first row are the visualization results of ViT-Base, and the figures in the second row are the visualization results of Low-Rank ViT-Base.", "description": "This figure shows the Grad-CAM visualization results for both the baseline ViT-Base model and the proposed Low-Rank ViT-Base model on the NIH ChestX-ray14 dataset.  Grad-CAM highlights the regions of the input image that are most important for the model's predictions.  The comparison highlights how the Low-Rank model focuses more precisely on the relevant disease areas within the bounding box, whereas the baseline model shows activations in less relevant areas, suggesting improved robustness to noise and background.", "section": "4.5.3 Grad-CAM Visualization"}, {"figure_path": "GkzrVxs9LS/figures/figures_21_2.jpg", "caption": "Figure 2: Robust Grad-CAM [95] visualization results on NIH ChestX-ray 14. The figures in the first row are the visualization results of ViT-Base, and the figures in the second row are the visualization results of Low-Rank ViT-Base.", "description": "The figure shows Grad-CAM visualization results for both ViT-Base and Low-Rank ViT-Base models on the NIH ChestX-ray14 dataset.  Grad-CAM highlights the image regions most influential in the model's predictions. The comparison aims to illustrate how Low-Rank Feature Learning affects the model's attention to relevant image areas versus background or noise.", "section": "4.5.3 Grad-CAM Visualization"}, {"figure_path": "GkzrVxs9LS/figures/figures_23_1.jpg", "caption": "Figure 1: Eigen-projection (first row) and signal concentration ratio (second row) of Vit-Base on NiH-ChestXray-14, COVIDx, and CheXpert. To compute the eigen-projection, we first calculate the eigenvectors U of the kernel gram matrix K \u2208 Rnxn computed by a feature matrix F \u2208 Rnxd, then the projection value is computed by p =  \u2211c=1 || UTY(c) ||2||Y(c)||2 \u2208 R, where C is the number of classes, and Y \u2208 {0,1}n\u00d7C is the one-hot labels of all the training data, Y(c) is the c-th column of Y. The eigen-projection p, for r \u2208 [min(n, d)] reflects the amount of the signal projected onto the r-th eigenvector of K, and the signal concentration ratio of a rank r reflects the proportion of signal projected onto the top r eigenvectors of K. The signal concentration ratio for rank r is computed by ||p(1:r) ||2, where p(1:r) contains the first r elements of p. For example, by the rank r = 38, the signal concentration ratio of Y on NIH ChestX-ray14, COVIDx, and CheXpert are 0.959, 0.964, and 0.962 respectively.", "description": "The figure shows eigen-projections and signal concentration ratios for different ranks on three datasets (NIH ChestX-ray14, COVIDx, and CheXpert).  Eigen-projections illustrate how much signal from class labels is captured by different eigenvectors from the kernel gram matrix of features. Signal concentration ratios demonstrate the proportion of signal concentrated in the top-ranked eigenvectors. The results support the low-frequency property (LFP), indicating that low-rank features retain most of the class information.", "section": "Our Contributions"}, {"figure_path": "GkzrVxs9LS/figures/figures_23_2.jpg", "caption": "Figure 1: Eigen-projection (first row) and signal concentration ratio (second row) of Vit-Base on NiH-ChestXray-14, COVIDx, and CheXpert. To compute the eigen-projection, we first calculate the eigenvectors U of the kernel gram matrix K \u2208 Rnxn computed by a feature matrix F \u2208 Rnxd, then the projection value is computed by p = \u2211c=1 ||UTY(c)||2/||Y(c)||2 \u2208 R, where C is the number of classes, and Y \u2208 {0,1}n\u00d7C is the one-hot labels of all the training data, Y(c) is the c-th column of Y. The eigen-projection p, for r \u2208 [min(n, d)] reflects the amount of the signal projected onto the r-th eigenvector of K, and the signal concentration ratio of a rank r reflects the proportion of signal projected onto the top r eigenvectors of K. The signal concentration ratio for rank r is computed by ||p(1:r)||2, where p(1:r) contains the first r elements of p. For example, by the rank r = 38, the signal concentration ratio of Y on NIH ChestX-ray14, COVIDx, and CheXpert are 0.959, 0.964, and 0.962 respectively.", "description": "This figure shows the eigen-projection and signal concentration ratio for different ranks on three datasets (NIH ChestX-ray14, COVIDx, and CheXpert).  The eigen-projection illustrates how much of the signal (class label information) is captured by the top-ranked eigenvectors of the kernel gram matrix, calculated from the features extracted by a ViT-Base model.  The signal concentration ratio shows the cumulative proportion of the signal captured as the rank increases.  The results suggest that a low-rank representation of the features preserves a significant portion of the class label information, supporting the use of low-rank feature learning.", "section": "3 Formulation"}]