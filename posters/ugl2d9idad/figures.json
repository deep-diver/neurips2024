[{"figure_path": "ugL2D9idAD/figures/figures_1_1.jpg", "caption": "Figure 1: Performance of Mean Squared Error (MSE) on a simple synthetic multi-frequency signal. More details about the experimental settings can be found in Appendix C.4.", "description": "The figure shows the performance comparison of the iTransformer and FilterNet models on a synthetic dataset with low, middle, and high-frequency components. FilterNet significantly outperforms iTransformer, achieving a much lower MSE (Mean Squared Error). This highlights FilterNet's superior ability to handle multi-frequency signals, which is a key advantage over Transformer-based models that often struggle with high-frequency noise. Appendix C.4 provides additional details regarding experimental setup.", "section": "1 Introduction"}, {"figure_path": "ugL2D9idAD/figures/figures_3_1.jpg", "caption": "Figure 2: The overall architecture of FilterNet. (i) Instance normalization is employed to address the non-stationarity among time series data; (ii) The frequency filter block is applied to capture the temporal patterns, which has two different implementations, i.e., plain shaping filter and contextual shaping filter; (iii) Feed-forward network is adopted to project the temporal patterns extracted by frequency filter block back onto the time series data and make predictions.", "description": "This figure illustrates the architecture of FilterNet, a time series forecasting model.  The input time series data first undergoes instance normalization to handle non-stationarity. Then, a frequency filter block processes the data, choosing between a plain shaping filter (using a universal kernel) or a contextual shaping filter (with a data-dependent kernel) to extract key temporal features. Finally, a feed-forward network maps these features to produce the forecast.", "section": "4.1 Overview"}, {"figure_path": "ugL2D9idAD/figures/figures_4_1.jpg", "caption": "Figure 3: The structure of frequency filters. (a) Plain shaping filter: the plain shaping filter is initialized randomly with channel-shared (left) or channel-unique (right) parameters, and then performs circular convolution (i.e., the symbol ) with the input time series; (b) Contextual shaping filter: the contextual shaping filter firstly learns a data-dependent filter and then conducts multiplication (i.e., the symbol ) with the frequency representation of the input time series.", "description": "This figure shows the architecture of two types of learnable frequency filters used in the FilterNet model. The plain shaping filter uses a randomly initialized, universal frequency kernel for filtering and temporal modeling.  The kernel can be either shared across channels or unique per channel. The contextual shaping filter learns a data-dependent filter to perform frequency filtering and utilizes filtered frequencies for dependency learning, thus adapting to the input signals' characteristics. Both filter types perform a circular convolution or multiplication with the frequency representation of the input time series.", "section": "4.2 Plain Shaping Filter\n4.3 Contextual Shaping Filter"}, {"figure_path": "ugL2D9idAD/figures/figures_7_1.jpg", "caption": "Figure 1: Performance of Mean Squared Error (MSE) on a simple synthetic multi-frequency signal. More details about the experimental settings can be found in Appendix C.4.", "description": "The figure demonstrates the performance of the Mean Squared Error (MSE) metric on a synthetic multi-frequency signal. It compares the performance of the iTransformer model (state-of-the-art) and FilterNet (the proposed model). The input signal consists of low, middle, and high-frequency components.  FilterNet achieves significantly lower MSE (2.7e-05) compared to iTransformer (1.1e-01), indicating its superior performance in handling multi-frequency signals. This highlights FilterNet's ability to utilize the full frequency spectrum effectively, unlike the iTransformer which struggles with high-frequency components.  More detail on the experimental setup is provided in Appendix C.4 of the paper.", "section": "1 Introduction"}, {"figure_path": "ugL2D9idAD/figures/figures_7_2.jpg", "caption": "Figure 5: Visualization of prediction on the ETTh1 dataset with lookback and horizon length as 96.", "description": "This figure visualizes the prediction results of three different models (FilterNet, iTransformer, and PatchTST) on the ETTh1 dataset. Each plot shows the ground truth, input data, and predictions.  The x-axis represents the time, and the y-axis represents the values. The purpose is to provide a visual comparison of the forecasting performance of these three models. FilterNet seems to align better with the ground truth compared to iTransformer and PatchTST.", "section": "5 Experiments"}, {"figure_path": "ugL2D9idAD/figures/figures_8_1.jpg", "caption": "Figure 7: Spectrum visualizations of filters learned on the Weather, ETTh1, and Traffic datasets.", "description": "This figure visualizes the frequency response characteristics of the learned filters for three different datasets: Weather, ETTh1, and Traffic.  Each subfigure shows a spectrum plot, representing the amplitude of different frequency components present in the learned filter. The x-axis represents frequency, and the y-axis represents amplitude. The plots provide insights into which frequency components are emphasized or attenuated by the filters for each dataset, revealing the filters' selectivity in capturing relevant temporal patterns in the time series data.  Differences in the spectra across datasets highlight the data-adaptive nature of the filter learning process, adjusting its frequency response based on the unique characteristics of each dataset.", "section": "5.3 Model Analysis"}, {"figure_path": "ugL2D9idAD/figures/figures_8_2.jpg", "caption": "Figure 7: Spectrum visualizations of filters learned on the Weather, ETTh1, and Traffic datasets.", "description": "This figure visualizes the frequency response characteristics of the learned filters for three different datasets: Weather, ETTh1, and Traffic.  Each subfigure shows the spectrum of a filter, with the x-axis representing frequency and the y-axis representing amplitude.  The visualizations help to understand how the filters selectively pass or attenuate different frequency components of the input time series data for each dataset.  The variations in the spectrum across datasets illustrate that the learned filters adapt their frequency responses according to the characteristics of the respective time series data.", "section": "5.3 Model Analysis"}, {"figure_path": "ugL2D9idAD/figures/figures_8_3.jpg", "caption": "Figure 6: Model effectiveness and efficiency comparison on the Exchange and Electricity datasets.", "description": "This figure compares the effectiveness and efficiency of FilterNet against other state-of-the-art time series forecasting models (DLinear, iTransformer, Autoformer, Pyraformer, Transformer, PatchTST, and FreTS) across two datasets: Exchange (with 8 variables) and Electricity (with 321 variables).  It visualizes the memory footprint and training time (in seconds per epoch) for each model, showing FilterNet's superior performance in terms of both efficiency and accuracy in time series forecasting. The size of the circles represents the memory footprint, while the horizontal position represents the training time. The figure effectively demonstrates the advantage of FilterNet in terms of resource utilization and speed.", "section": "5 Experiments"}, {"figure_path": "ugL2D9idAD/figures/figures_16_1.jpg", "caption": "Figure 9: MSE and MAE of filters under different bandwidths on the Weather dataset.", "description": "This figure visualizes the impact of different filter bandwidths on the model's performance using the MSE (Mean Squared Error) and MAE (Mean Absolute Error) metrics for the Weather dataset. It shows three scenarios with varying lookback window lengths and prediction lengths. The results show a relationship between bandwidth and the effectiveness of the filters in making accurate predictions.", "section": "5.3 Model Analysis"}, {"figure_path": "ugL2D9idAD/figures/figures_16_2.jpg", "caption": "Figure 1: Performance of Mean Squared Error (MSE) on a simple synthetic multi-frequency signal. More details about the experimental settings can be found in Appendix C.4.", "description": "This figure shows the performance comparison between iTransformer and FilterNet on a simple synthetic multi-frequency signal. The input signal is composed of low-, middle-, and high-frequency components.  The figure demonstrates that FilterNet achieves significantly lower MSE (Mean Squared Error) compared to iTransformer, highlighting FilterNet's superior performance in handling multi-frequency signals.", "section": "1 Introduction"}, {"figure_path": "ugL2D9idAD/figures/figures_18_1.jpg", "caption": "Figure 11: Visualizations on the ETTh1 dataset.", "description": "The figure compares the forecasting results of the ETTh1 dataset using channel-shared and channel-unique filters. The visualization shows that the predictions from the channel-shared filters align more closely with the ground truth compared to the channel-unique filters. This observation supports the findings in Table 2, indicating that channel-shared filters provide better forecasting performance.", "section": "G.1 Visualization of Channel-shared vs Channel-unique Filters"}, {"figure_path": "ugL2D9idAD/figures/figures_18_2.jpg", "caption": "Figure 7: Spectrum visualizations of filters learned on the Weather, ETTh1, and Traffic datasets.", "description": "This figure visualizes the frequency response characteristics of the learned filters for three different datasets: Weather, ETTh1, and Traffic.  Each sub-figure shows the spectrum (amplitude vs. frequency) of a filter learned by the FilterNet model on a particular dataset. The visualizations provide insights into how the filters selectively attend to different frequency components in the input time series data.  The distinct patterns in each spectrum highlight the dataset-specific frequency characteristics captured by the filters, demonstrating the filter's ability to adapt to the unique properties of various time series.", "section": "5.3 Model Analysis"}, {"figure_path": "ugL2D9idAD/figures/figures_19_1.jpg", "caption": "Figure 5: Visualization of prediction on the ETTh1 dataset with lookback and horizon length as 96.", "description": "This figure visualizes the prediction results of FilterNet, iTransformer, and PatchTST on the ETTh1 dataset. The lookback and horizon lengths are both set to 96. The figure shows that FilterNet achieves better prediction accuracy compared to the other two models, indicating its superior performance in time series forecasting.", "section": "5 Experiments"}]