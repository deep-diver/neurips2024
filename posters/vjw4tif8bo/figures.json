[{"figure_path": "vjw4TIf8Bo/figures/figures_2_1.jpg", "caption": "Figure 1: PaDeLLM-NER training paradigm: texts within frames of the same color represents one training example, where texts inside the solid-line frame are the input, and those inside the dashed-line frame are the output. Italic texts are prompt templates. The \"entity type\" signifies the label being predicted. The \"<num>\" indicates count of mentions for that label, and \"<mention n>\" refers to the nth mention of a label in the input.", "description": "This figure illustrates the training process of PaDeLLM-NER.  A single unstructured text containing multiple entities (e.g., Person, Location, Organization) is broken down into multiple training examples. Each example focuses on a single entity type and contains the count of mentions for that type and each mention's text. This allows for the parallel generation of label-mention pairs during inference, which is the core innovation of the PaDeLLM-NER approach.", "section": "3 Method"}, {"figure_path": "vjw4TIf8Bo/figures/figures_3_1.jpg", "caption": "Figure 2: PaDeLLM-NER inference paradigm: texts enclosed in frames with identical colors indicate sequences of the same label. Specifically, the texts within solid-lined frames represent the added templates, while those within dashed-lined frames denote the prediction. In Step 1, the model predicts the number of mentions for all labels while in Step 2, it predicts the mentions. By aggregating mentions and labels from all sequences, the final NER results are obtained. Duplicate mentions appearing in different labels are resolved using prediction probabilities.", "description": "This figure illustrates the two-step inference process in PaDeLLM-NER.  First, the model predicts the number of mentions for each label (Step 1). Then, based on that count, it predicts each mention in parallel (Step 2). Finally, duplicate mentions (predicted for multiple labels) are resolved by choosing the one with the highest probability.", "section": "3.2 Inference of Label-Mention Pairs"}, {"figure_path": "vjw4TIf8Bo/figures/figures_6_1.jpg", "caption": "Figure 3: Speedup of PaDeLLM-NER compared to Autoregressive methods.", "description": "This figure shows the speedup of PaDeLLM-NER compared to autoregressive methods across different datasets.  The speedup is calculated by dividing the latency of the baseline autoregressive methods (AutoRegAug and AutoRegstruct) by the latency of PaDeLLM-NER.  The results show significant speed improvements for PaDeLLM-NER across all datasets, with speedup factors varying across different datasets. This highlights the efficiency gains of PaDeLLM-NER in reducing inference latency.", "section": "4.2 Main Results"}, {"figure_path": "vjw4TIf8Bo/figures/figures_17_1.jpg", "caption": "Figure 4: Percentage of different error types.", "description": "This figure shows a breakdown of the error types found in the ACE2005 dataset.  The majority (56.8%) of errors are due to incorrect mention counts. A significant portion (23.9%) results from index inaccuracies (incorrect mentions for a given index).  Finally, 19.3% of the errors are attributed to inaccuracies in the ground truth data itself.", "section": "F Error analysis"}]