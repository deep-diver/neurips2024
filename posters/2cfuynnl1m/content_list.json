[{"type": "text", "text": "Weight Diffusion for Future: Learn to Generalize in Non-Stationary Environments ", "text_level": 1, "page_idx": 0}, {"type": "image", "img_path": "2cFUYnNL1m/tmp/06797a41bdf29e273110d53b38a32acaa32efe0eeb25887b10bfcf8b832ff6dd.jpg", "img_caption": [], "img_footnote": [], "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Enabling deep models to generalize in non-stationary environments is vital for real-world machine learning, as data distributions are often found to continually change. Recently, evolving domain generalization (EDG) has emerged to tackle the domain generalization in a time-varying system, where the domain gradually evolves over time in an underlying continuous structure. Nevertheless, it typically assumes multiple source domains simultaneously ready. It still remains an open problem to address EDG in the domain-incremental setting, where source domains are non-static and arrive sequentially to mimic the evolution of training domains. To this end, we propose Weight Diffusion (W-Diff), a novel framework that utilizes the conditional diffusion model in the parameter space to learn the evolving pattern of classifiers during the domain-incremental training process. Specifically, the diffusion model is conditioned on the classifier weights of different historical domain (regarded as a reference point) and the prototypes of current domain, to learn the evolution from the reference point to the classifier weights of current domain (regarded as the anchor point). In addition, a domain-shared feature encoder is learned by enforcing prediction consistency among multiple classifiers, so as to mitigate the overfitting problem and restrict the evolving pattern to be reflected in the classifier as much as possible. During inference, we adopt the ensemble manner based on a great number of target domain-customized classifiers, which are cheaply obtained via the conditional diffusion model, for robust prediction. Comprehensive experiments on both synthetic and real-world datasets show the superior generalization performance of W-Diff on unseen domains in the future. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Domain generalization (DG) deals with a fundamental problem in modern machine learning [13, 46, 47], where performance degeneration often occurs when deep models encounter out-of-distribution (OOD) data [38, 56]. The goal of DG is to learn a model that can perform well on unseen target domains by leveraging labeled data from multiple related but different source domains [23, 19, 57, 22]. ", "page_idx": 0}, {"type": "text", "text": "Despite of abundant works on DG and promising progress so far, they typically embark upon the generalization among stationary and discrete environments [29], where the distribution shift among domains is obvious and remains static over time. In contrast, there have emerged several works on evolving domain generalization (EDG) [24, 29, 51, 2, 44, 50] in recent years, where the data distribution gradually shifts in an underlying continuous structure, e.g., the age-related structural changes in the optic nerve in ocular diseases [12]. But most of EDG methods still assume multiple source domains simultaneously ready, which may be impractical in real world. As the data distribution constantly evolves along time, training data from new data distributions will continue to emerge. Hence, equipping models with lifelong learning ability is crucial for their practical applications. ", "page_idx": 1}, {"type": "text", "text": "Despite of the fact that existing researches on continual learning [16, 32, 5] have studied the empowerment of lifelong learning, their focus is on maintaining the performance of seen tasks, instead of generalizing on unseen domains in the future. Therefore, it is still an open problem to achieve evolving domain generalization in the domain-incremental setting, where source domains sequentially arrive to mimic the dynamics of training domains. To this end, previous work EvoS [45] models the features from each domain as a Gaussian distribution and proposes to capture the evolving pattern at the feature level by leveraging self-attention mechanism to generate the feature mean and variance for future domain based on those of historical domains. However, the assumption that features adhere to a Gaussian distribution may not always be applicable. Different from EvoS, we propose to excavate evolving pattern at the parameter level and further achieve domain-customized parameter generation. ", "page_idx": 1}, {"type": "text", "text": "Inspired by neural network diffusion [42] that there exist specific parameter patterns in optimized model layers and these patterns can be modeled with diffusion model, we propose to capitalize on the strong modeling ability of diffusion models to capture the evolving pattern of optimized classifiers across domains. To achieve this, we propose a Weight Diffusion (W-Diff) approach, which is specialized for EDG in the domain-incremental setting. Specifically, to address the problem of inaccessible historical data, we maintain a first-in-first-out (FIFO) queue to store the optimized classifier weights of historical domains. The stored classifier weights of each historical domain serve as a reference point to calculate the change between the classifier weights of current domain (regarded as the anchor point) and that of corresponding historical domain. The changes of classifier weights between the anchor point and different reference points provide evolving patterns at different time intervals, which can be utilized to make the modeling of evolving patterns more robust. ", "page_idx": 1}, {"type": "text", "text": "In addition, for guidance on how to switch from a reference point to the anchor point, we condition the diffusion model on the class prototypes of current domain along with the reference point. Then, the conditional diffusion model is trained to model the distribution of residual classifier weights, i.e., the change of classifier weights between the anchor point and reference point. Meanwhile, to reduce the overfitting of the feature encoder and to restrict the evolutionary pattern to be reflected only in the classifier as much as possible, we learn a domain-shared feature space by enforcing the predictions from different classifiers to be consistent. Finally, during the inference stage, we adopt weights ensemble to give robust predictions based on a great number of generated classifier weights by the diffusion model that is conditioned on current class prototypes and different reference points. ", "page_idx": 1}, {"type": "text", "text": "Contributions: 1) We study the under-explored area of evolving domain generalization in the domain-incremental setting and explore the innovative usage of diffusion model for this problem. 2) We propose a novel weight diffusion (W-Diff) approach to capture the evolutionary pattern at the parameter level, orthogonal to previous feature level approaches. Capitalizing on the strong generative ability of diffusion model, W-Diff can generate customized parameters by controlling the condition and make robust predictions via weights ensemble. 3) Comprehensive experiments on both synthetic and real-world datasets verify the effectiveness and superiority of W-Diff on generalization. ", "page_idx": 1}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Evolving Domain Generalization (EDG) learns the evolving pattern underlying in multiple source domains to achieve generalization capability on the unseen future target domains over time [2, 50, 24, 52, 44, 29]. To name a few, SDE-EDG [50] introduces stochastic differential equations (SDEs) to model the evolving pattern through individual temporal trajectories. DRAIN [2] builds on the Bayesian framework and leverages LSTM to infer the future status of the whole network. However, most of these methods, except for DRAIN, require multiple source domains to be simultaneously available. Very recently, EvoS [45] focuses on EDG with sequentially arriving domains, considering the low efficiency of training the model from scratch once the accumulated domains are updated. It assumes that features for each domain follow a Gaussian distribution and then models the evolving pattern of the feature distribution, while this assumption is not always suitable. Besides, in the generalization process of multiple consecutive target domains, the statistics generated from previous timestamps are used as inputs to the attention mechanism to generate the statistics at next timestamp, which in turn serve as the input for next generation. This manner is likely to cause error accumulation if previous generation is not accurate. Orthogonal to EvoS [45], we proposes to mine the evolving pattern at the model parameter level and further implement domain-oriented parameter generation via controlling the condition of the diffusion model to avoid the potential error accumulation in EvoS. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Continual Learning (CL) focuses on the scenario where the model is trained on a sequence of tasks, and the model is required to adapt to current task and meanwhile maintain the performance on previous tasks [53, 16, 5, 39, 43, 32, 11]. The literature on this field is abundant. Most of the techniques can be categorized into architecture-based [34, 9], representation-based [4, 43, 10], regularization-based [16, 53, 32] and replay-based [5, 39, 11]. In this work, we also continually train models on sequential domains, but the goal is to generalize well on novel domains in the near future. ", "page_idx": 2}, {"type": "text", "text": "Parameter Generation has been gaining great interests with the rise of diffusion models [42, 8, 21, 54]. For example, p-diff [42] directly generates high-performing neural network parameters from random noises with a standard latent diffusion model, which verifies the feasibility of modeling the parameter distribution via diffusion models. Nevertheless, p-diff uses unconditional diffusion model and can only generate parameters for in-distribution data. G.pt [28] collects the loss, error or return of task model checkpoints during training as the condition for the diffusion model. However, it is designed for a single dataset to which the training data belongs, thus struggling with distribution shifts. D2NWG [36] uses CLIP [30] to extract features for each sample and leverages Set Transformer [18] to generate dataset encoding from these features. Then, the diffusion model is conditioned on the dataset encoding. But labeled training set samples of a new dataset are required to obtain the dataset encoding, which is infeasible in unlabeled target domains. In addition, ProtoDiff [8] and MetaDiff [54] generate prototype classifiers for the meta-test stage by conditioning the diffusion model on the information (e.g., the prototypes in [8] and the gradients in [54]) from the support set. Yet, they concentrate on few-shot learning and the support set requires labeled data, which is unavailable in the target domain of EDG. By contrast, we aims at capturing the evolving pattern among source domains and leveraging it to enable generalization on future target domains without any labeled target data. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "3.1 Problem Formulation ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We consider the evolving domain generalization (EDG) in the domain-incremental setting. Formally, during training phase, we are given $T$ sequentially arriving source (training) domains: $\\bar{\\cal S}\\,=\\,\\{{\\cal D}^{1},{\\bar{\\cal D}}^{2},...\\,,{\\bar{\\cal D}}^{\\bar{T}}\\}$ , which are collected at timestamps $t_{1}\\,<\\,t_{2}\\,<\\,.\\ldots\\,<\\,t_{T}$ , respectively. Each domain is defined as $\\mathbf{\\mathcal{D}^{t}}=\\{\\pmb{x}_{i}^{t},y_{i}^{t}\\}_{i=1}^{N^{t}}$ , $t=1,\\ldots,T$ , where $\\pmb{x}_{i}^{t}$ is the $i^{\\th}$ -th sample from the -th domain, $y_{i}^{t}\\in\\{0,1,\\ldots,C-\\dot{1}\\}$ is the category label of sample $\\pmb{x}_{i}^{t}$ , and $N^{t},C$ are the number of training samples in the $t$ -th domain and the number of categories, respectively. In the domainincremental setting, we can only access current domain $\\mathcal{D}^{t}$ at timestamp $t_{t}$ and historical domains $\\{D^{1},\\ldots,D^{t-1}\\}$ are unavailable. This takes into account the data storage burden, privacy concerns and the dynamic evolution of the source domain. Following previous EDG works [24, 29, 2], the label set is the same among domains, but the data distribution of domains is assumed to continuously evolve over time in some patterns. And our goal is to generalize the model, which is composed of a feature encoder $E_{\\psi}$ parameterized with $\\psi$ and a classifier $H_{\\mathbf{W}}$ parameterized with $\\mathbf{W}$ , on unseen $K$ target (testing) domains in the future: T = {DT +1, . $\\mathcal{T}=\\{\\mathcal{D}^{T+1},\\ldots,\\mathcal{D}^{T+K}\\}$ . To tackle this problem, we propose to model the evolving pattern at the parameter level via the conditional diffusion model and generate customized parameters for future domains by controlling the condition of the diffusion model. ", "page_idx": 2}, {"type": "text", "text": "3.2 Diffusion Model ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Diffusion models have achieved tremendous success in computer vision by modeling the probability transformation from a prior Gaussian distribution to the target distribution [14, 40]. They typically comprise a diffusion process to progressively add Gaussian noise to data in a multi-step Markov chain and a denoising process to recover data from the noise via reversing the diffusion process. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Diffusion process. Given a clean data point $\\pmb{x}_{0}$ sampled from a real data distribution $q(x)$ , i.e., ${\\pmb x}_{0}\\sim q({\\pmb x})$ , the diffusion process is characterized as a Markov chain which slowly adds random Gaussian noise to $\\pmb{x}_{0}$ in $S$ steps, obtaining a sequence of noisy samples: $\\pmb{x}_{1},\\dots,\\pmb{x}_{S}$ . Formally, this process is expressed as ", "page_idx": 3}, {"type": "equation", "text": "$$\nq(x_{1:S}|x_{0})=\\prod_{s=1}^{S}q(x_{s}|x_{s-1}),\\quad q(x_{s}|x_{s-1})=\\mathcal{N}(x_{s};\\sqrt{1-\\beta_{s}}x_{s-1},\\beta_{s}\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\{\\beta_{s}\\,\\in\\,(0,1)\\}_{s=1}^{S}$ is a variance schedule, $\\mathcal{N}$ represents Gaussian distribution, and $\\mathbf{I}$ is the identity matrix. And the forward diffused sample at step $s$ , denoted as $\\pmb{x}_{s}$ , can be directly obtained in a single step by Eq. (2) without iteratively adding noise: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pmb{x}_{s}=\\sqrt{\\bar{\\alpha}_{s}}\\pmb{x}_{0}+\\sqrt{1-\\bar{\\alpha}_{s}}\\pmb{\\epsilon},\\quad\\pmb{\\epsilon}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\begin{array}{r}{\\bar{\\alpha}_{s}=\\prod_{s^{\\prime}=1}^{s}(1-\\beta_{s^{\\prime}})}\\end{array}$ . When step size $S$ approaches infinity, $\\pmb{x}_{S}$ is equivalent to a data point from an isotropic Gaussian distribution, i.e., the prior Gaussian distribution $\\bar{\\mathcal{N}}(\\mathbf{0},\\mathbf{I})$ . ", "page_idx": 3}, {"type": "text", "text": "Denoising process. Given a start noise $\\pmb{x}_{S}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ , the denoising process moves backward on the multi-step Markov chain as $s$ decreases from $S$ to $1$ to remove the noise at each step $s$ , finally recovering the clean data. Concretely, the formulation of the denoising process at step $s$ is denoted as ", "page_idx": 3}, {"type": "equation", "text": "$$\nx_{s-1}=\\mu_{\\theta}(x_{s},s)+\\sigma_{s}\\epsilon=\\frac{1}{\\sqrt{1-\\beta_{s}}}\\left(x_{s}-\\frac{\\beta_{s}}{\\sqrt{1-\\bar{\\alpha}_{s}}}\\mathcal{E}_{\\theta}(x_{s},s)\\right)+\\sigma_{s}\\epsilon,\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "$\\begin{array}{r}{\\mu_{\\theta}(x_{s},s)=\\frac{1}{\\sqrt{1-\\beta_{s}}}\\left(x_{s}-\\frac{\\beta_{s}}{\\sqrt{1-\\bar{\\alpha}_{s}}}\\mathcal{E}_{\\theta}(x_{s},s)\\right)}\\end{array}$ and $\\mathcal{E}_{\\theta}(\\cdot,\\cdot)$ is a denoising model parameterized with $\\pmb{\\theta}$ to estimate the noise. $\\sigma_{s}$ is a variance hyperparameter that is theoretically set to $\\sigma_{s}^{2}=\\beta_{s}$ in most diffusion works [14, 26]. During the training stage, the denoising model $\\mathcal{E}_{\\theta}$ is trained by minimizing the following loss $\\mathcal{L}_{d i f f}$ to minimize the noise estimation error: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{L}_{d i f f}=\\mathbb{E}_{\\mathbf{x}_{0},s,\\epsilon}\\left[\\|\\epsilon-\\mathcal{E}_{\\theta}(\\sqrt{\\bar{\\alpha}_{s}}x_{0}+\\sqrt{1-\\bar{\\alpha}_{s}}\\epsilon,s)\\|^{2}\\right].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Conditional diffusion model. The way of conditional diffusion models to generate samples is analogous to the unconditional one, except for the added conditional information. Specifically, as in most conditional diffusion works [25, 17], the denoising model $\\mathcal{E}_{\\theta}(\\mathbf{\\Delta}\\pmb{x}_{s},s)$ is replaced with $\\mathcal{E}_{\\theta}(\\mathbf{\\boldsymbol{x}}_{s},s,\\mathbf{\\boldsymbol{c}})$ , where c denotes the condition, e.g., class labels, texts, images, etc. The matched condition c regulates the sample generation in a supervised manner to ensure the desired image content. And inspired by the generating of specific image contents via introducing conditional information to diffusion models, we propose to achieve domain-oriented parameter generation by controlling the diffusion condition. ", "page_idx": 3}, {"type": "text", "text": "4 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "With the preliminary knowledge of EDG in the domain-incremental setting and diffusion models, we will present the details of Weight Diffusion (W-Diff) in this section. We begin with how to obtain the data for diffusion model training in Section 4.1 and then model the evolving pattern of parameters via the conditional diffusion model in Section 4.2. Finally, the inference procedure of W-Diff to generate customized classifiers is presented in Section 4.3. The overview of W-Diff is illustrated in Fig. 1. ", "page_idx": 3}, {"type": "text", "text": "4.1 Per-domain Parameter Fitting in Domain-Incremental Setting ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In our approach, we try to capture the evolving pattern in optimized model parameters across domains and further generate customized parameters for target domain via leveraging the learned pattern. Considering the unaffordable training cost if modeling the whole parameters for relatively large models, we choose to excavate the evolutionary pattern in the task-specific head, e,g., the classifier for classification tasks. Nevertheless, the remaining parts of the task model would overfit to current domain and cause degraded generalization if without any processing. To avoid this, we learn a domain-shared feature encoder for all domains and a domain-specific classifier for each domain during the domain-incremental training. As $t$ increases from 1 to $T$ , once the training stage on domain $\\mathcal{D}^{t}$ ends, the classifier weights with the best validation performance on the validation set of $\\mathcal{D}^{t}$ , denoted as $\\ddot{\\mathbf{W}}^{t}\\in\\mathbb{R}^{C\\times d_{f}}$ , is stored in the reference point queue $Q_{r}$ , where $d_{f}$ the dimension of deep features output by the feature encoder $E_{\\psi}$ . $Q_{r}$ is a global FIFO queue with the maximum length $L$ and is used to calculate the change of classifier weights between current domain and a given historical domain in Section 4.2, which reflects the evolving pattern at the parameter level. ", "page_idx": 3}, {"type": "image", "img_path": "2cFUYnNL1m/tmp/aec9e611b73e6462b451e4d245b35abc68f4ca8a8ca92b652df45f1a21695e13.jpg", "img_caption": ["Figure 1: Overview of W-Diff. The reference point queue $Q_{r}$ stores classifier weights of recent $\\left|Q_{r}\\right|$ historical domains, and the anchor point queue $Q_{a}$ and prototype queue $Q_{p}$ store the updated classifier weights and prototype matrix at each iteration after the warm-up stage on current domain. $\\mathcal{L}_{c o n}^{t}$ is the prediction consistency loss to learn a domain-shared feature space and $\\mathcal{L}_{c e}^{t}$ is the cross-entropy loss. The conditional diffusion model E\u03b8 is trained with the noise estimation error loss Ltdiff to model the evolving pattern of classifiers, conditioned on historical reference point and current prototype matrix. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Learning Domain-Shared Feature Encoder. In the domain-incremental setting, we can only access the data from current domain, which prohibits us from utilizing conventional DG methods that require to access multiple domains simultaneously to learn domain-invariant feature representations. To tackle this problem, we resort to the stored different classifiers in $Q_{r}$ . Intuitively, if domain-shared feature representation is learned, classifiers from different domains should give similar predictions for a given data sample. Hence, at timestamp $t_{t}$ , we train the task model on the $t$ -th domain $\\mathcal{D}^{t}$ by minimizing the consistency loss $\\mathcal{L}_{c o n}^{t}$ to learn a domain-shared feature space: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}_{c o n}^{t}=\\displaystyle\\frac{1}{1+|Q_{r}|}\\cdot\\frac{1}{N^{t}}\\cdot\\frac{1}{C}\\sum_{t^{\\prime}=t-|Q_{r}|}^{t}\\sum_{i=1}^{N^{t}}K L(\\bar{p}_{i}^{t}||p_{i}^{t,t^{\\prime}}),}\\\\ &{\\bar{p}_{i}^{t}=\\displaystyle\\frac{1}{1+|Q_{r}|}\\sum_{t^{\\prime}=t-|Q_{r}|}^{t}p_{i}^{t,t^{\\prime}},\\quad p_{i}^{t,t^{\\prime}}=\\left\\{\\mathrm{softmax}(\\mathrm{sg}(\\mathbf{W}^{t})\\times f_{i}^{t}),\\quad t^{\\prime}=t\\right.,}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\pmb{f}_{i}^{t}=E_{\\psi}(\\pmb{x}_{i}^{t})\\in\\mathbb{R}^{d_{f}},\\mid\\cdot\\mid$ is the length of the object and $\\operatorname{sg}(\\cdot)$ denotes stopping gradients. $\\ddot{\\mathbf{W}}^{t^{\\prime}}$   \nis the stored classifier weights of historical domain $\\mathcal{D}^{t^{\\prime}}$ and $\\mathbf{W}^{t}$ is current classifier weights on $\\mathcal{D}^{t}$ . ", "page_idx": 4}, {"type": "text", "text": "Learning Domain-Specific Classifier. As $t$ increases from 1 to $T$ , domain-specific classifier is directly learned by incrementally training the task model via the supervision loss $\\overline{{\\mathcal{L}_{c e}^{t}}}$ on domain $\\mathcal{D}^{t}$ : ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}_{c e}^{t}=\\frac{1}{N^{t}}\\sum_{i=1}^{N^{t}}C r o s s E n t r o p y\\left(\\mathrm{softmax}(\\mathbf{W}^{t}\\times\\mathbf{f}_{i}^{t}),y_{i}^{t}\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "$\\mathcal{D}^{t}$ $\\mathcal{L}_{t o t a l}^{t}$ ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal{L}_{t o t a l}^{t}=\\mathcal{L}_{c e}^{t}+\\lambda\\mathcal{L}_{c o n}^{t},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\lambda$ is a tradeoff hyperparameter to balance the two losses. ", "page_idx": 4}, {"type": "text", "text": "Collecting Data for Diffusion Model Training. Considering that parameters at the early stage are unstable, we start to collect the training data for diffusion model after the warm-up stage of the task model is over on corresponding domain. Specifically, when training on the $t$ -th domain, the warm-up epochs of the task model account for $\\rho\\in(0,1)$ of the total training epochs on domain $\\mathcal{D}^{t}$ , where $\\rho$ is a hyperparameter. After the warm-up stage, the updated classifier weights $\\mathbf{W}^{t}\\in\\mathbb{R}^{C\\times d_{f}}$ via back-propagating the gradients of $\\mathcal{L}_{t o t a l}^{t}$ and the updated prototype matrix $\\bar{\\pmb{\\mu}^{t}}\\in\\mathbb{R}^{C\\times d_{f}}$ via Eq. (8) are respectively stored into the anchor point queue $Q_{a}$ and prototype queue $Q_{p}$ at each iteration. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\pmb{\\mu}^{t}[c]:=\\frac{n^{t}\\cdot\\pmb{\\mu}^{t}[c]+\\sum_{i=1}^{B}p_{i}^{t,t}[c]\\cdot\\pmb{f}_{i}^{t}}{n^{t}+B},c=0,1,\\dotsc,C-1,}\\\\ {\\displaystyle n^{t}:=n^{t}+B.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "$\\pmb{\\mu}^{t}[c]$ is the $c$ -th row of $\\pmb{\\mu}^{t}$ , i.e., the prototype of class $c$ on domain $\\mathcal{D}^{t}$ based on all data in the seen batches after the warm-up stage on $\\mathcal{D}^{t}$ . $B$ is the batch size of task model. $n^{t}$ counts the total number of samples in seen batches after the warm-up stage and is initialized to 0 at the start of training on each domain. $p_{i}^{t,t}[c]$ is the predicted probability of $\\pmb{x}_{i}^{t}$ belonging to class $c$ via current classifier of domain $\\mathcal{D}^{t}$ . Here, using predicted probability instead of ground-truth label to compute prototypes avoids the issue of missing categories in a batch and the inaccessibility of labels in testing domains. ", "page_idx": 5}, {"type": "text", "text": "In implementation, $Q_{a}$ and $Q_{p}$ are both FIFO queue with the maximum length $M$ , i.e., the training batch size of the diffusion model. When they are full, the training of the conditional diffusion model starts. Note that $Q_{a}$ and $Q_{p}$ are only used during the training phase and are locally used on each domain. That is, they are initialized to empty at the beginning of the training stage on each domain. ", "page_idx": 5}, {"type": "text", "text": "4.2 Modeling Parameter Evolution Pattern with Conditional Diffusion Model ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Having prepared the data for diffusion model training, we can utilize them to learn the evolving pattern of parameters during the domain-incremental training process of the task model. To be specific, we use the difference between the classifier weights of current domain and that of a given historical domain to represent the evolution of parameters: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\Delta\\mathbf{W}_{m}^{t,t^{\\prime}}=\\mathbf{W}_{m}^{t}-\\ddot{\\mathbf{W}}^{t^{\\prime}},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $\\mathbf{W}_{m}^{t}$ , $m=1,2,\\ldots,M$ , is the classifier weights of current domain $\\mathcal{D}^{t}$ , which is cached in the anchor point queue $Q_{a}$ when training the task model on $\\mathcal{D}^{t}$ . And $\\ddot{\\mathbf{W}}^{t^{\\prime}}$ is the classifier weights of the historical domain $\\mathcal{D}^{t^{\\prime}}$ from the reference point queue $Q_{r}$ , $t^{\\prime}\\in\\{t-|Q_{r}|,\\ldots,t-1\\}$ . Hence, the residual classifier weights $\\{\\Delta\\mathbf{W}_{m}^{t,t^{\\prime}}\\}_{m=1}^{M}$ tm,t \u2032}mM=1 represent how to evolve from a reference point to the anchor point. Moreover, to guide the evolution, we provide the paired condition for each residual classifier weight matrix $\\Delta\\mathbf{W}_{m}^{t,t^{\\prime}}$ , where the paired condition is formulated as $\\mathbf{c}_{m}^{t,t^{\\prime}}=\\ddot{\\mathbf{W}}^{t^{\\prime}}\\oplus\\pmb{\\mu}_{m}^{t}\\in\\mathbb{R}^{C\\times d_{f}\\times2}$ and $\\oplus$ denotes concatenating. The additional condition provides the information about the the starting point and knowledge about the distribution of data in the feature space, which is rightly the anchor point, i.e., the optimized classifier, needs to adapt to. Then, when the task model is incrementally trained on the $t$ -th domain, the conditional diffusion model is also incrementally trained to minimize the following noise estimation error loss $\\mathcal{L}_{d i f f}^{t}$ in Eq. (10), so as to learn how to generate the desired residual classifier weights when given the reference point and prototype matrix as the condition. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{L}_{d i f f}^{t}=\\mathbb{E}_{\\tilde{\\mathbf{W}}^{t^{\\prime}}\\in Q_{r},\\mathbf{W}_{m}^{t}\\in Q_{a},\\epsilon\\sim\\!N(\\mathbf{0},\\mathbf{I}),s}\\left[\\Vert\\epsilon-\\mathcal{E}_{\\theta}\\big(\\sqrt{\\bar{\\alpha}_{s}}\\cdot\\Delta\\mathbf{W}_{m}^{t,t^{\\prime}}+\\sqrt{1-\\bar{\\alpha}_{s}}\\epsilon,s,\\mathfrak{c}_{m}^{t,t^{\\prime}}\\big)\\Vert^{2}\\right].\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "In implementation, the conditional diffusion model adopts the similar U-Net structure as LDM [31] and uses a hybrid conditioning way, i.e., the condition is injected both in the cross-attention and input sides. In Eq. (10), different reference points could enrich the diversity of training data for the conditional diffusion model and provide the evolving pattern at different time intervals. ", "page_idx": 5}, {"type": "text", "text": "4.3 Generating Customized Classifiers in Inference Phase ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "After finishing the training on domain $\\mathcal{D}^{T}$ , we can use the conditional diffusion model to generate customized classifiers for a given testing domain $\\mathcal{D}^{t e s t}$ . Firstly, we calculate the prototype matrix $\\pmb{\\mu}^{t e s t}$ of domain $\\mathcal{D}^{t e s t}$ via $\\begin{array}{r}{\\pmb{\\mu}^{t e s t}[\\bar{c}]\\,=\\,\\frac{1}{N^{t e s t}}\\sum_{i=1}^{N^{t e s t}}\\bar{\\pmb{p}}_{i}^{t e s t}\\bar{[c]}\\,\\cdot\\pmb{f}_{i}^{t e s t}}\\end{array}$ , where $\\bar{\\pmb{p}}_{i}^{t e s t}=$ $\\begin{array}{r}{\\frac{1}{|Q_{r}|}\\sum_{\\ddot{\\mathbf{W}}^{t^{\\prime}}\\in Q_{r}}}\\end{array}$ softmax $(\\ddot{\\mathbf{W}}^{t^{\\prime}}\\times f_{i}^{t e s t})$ , $c=0,1,\\ldots,C-1$ . Here, we use the more robust average prediction of multiple classifiers to compute the prototype matrix in the inference phase. Then, given each reference point $\\ddot{\\mathbf{W}}^{t^{\\prime}}$ in $Q_{r}$ along with the prototype matrix $\\pmb{\\mu}^{t e s t}$ , we can generate $M_{g}$ residual classifier weights: {\u2206Wjtest,t\u2032}jM=g1 by substituting the denoising net in Eq. (3) with its conditional version and applying the denoising process with condition $\\mathbf{c}^{t e s t,t^{\\prime}}=\\ddot{\\mathbf{W}}^{t^{\\prime}}\\oplus\\pmb{\\mu}^{t e s t}$ . Ultimately, we use the following average weight ensemble $\\bar{\\mathbf{W}}^{t e s t}$ as the final classifier for label predicting on $\\dot{\\mathcal{D}}^{t e s t}$ : ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "equation", "text": "$$\n\\bar{\\mathbf{W}}^{t e s t}=\\frac{1}{|Q_{r}|}\\frac{1}{M_{g}}\\sum_{\\ddot{\\mathbf{w}}^{t^{\\prime}}\\in Q_{r}}\\sum_{j=1}^{M_{g}}(\\ddot{\\mathbf{W}}^{t^{\\prime}}+\\Delta\\mathbf{W}_{j}^{t e s t,t^{\\prime}}).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "In this way, we capitalize on the powerful modeling and generating ability of conditional diffusion model to cheaply produce a great number of target-customized classifiers, which offers more robust and accurate predictions. The pseudo codes of training and testing procedures are in Appendix $\\mathbf{C}$ . ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "5.1 Experimental Setup ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Benchmark Datasets. We evaluate W-Diff on both synthetic and real-world datasets [2, 48], including two text classification datasets (Huffpost, Arxiv), three image classification datasets (Yearbook, RMNIST, fMoW) and two multivariate classification datasets (2-Moons, ONP). Except for synthetic datasets 2-Moons and RMNIST that use the rotation angle as a proxy for time, all other datasets collect real-world data with the distribution shift over time. Following [45], the number of source and target domains is set as Yearbook: $T\\,=\\,16,K\\,=\\,5)$ , RMNIST: $\\mathit{T}\\,=\\,6,K\\,=\\,3)$ ), fMoW: $(T=13,K=3)$ , Huffpost: $(T=4,K=3)$ ), Arxiv: $(T=9,K=7)$ , 2-Moons: $(T=9,K=1)$ ), ONP: $(T=5,K=1)$ ). For each source domain, we randomly divide the data into training and validation sets in the ratio of $9:1$ . For more details on datasets, please refer to Appendix D.1. ", "page_idx": 6}, {"type": "text", "text": "Network Details. For the task model, we follow the usage in [48, 45]. For the conditional diffusion model, we implement it in a U-Net similar to LDM [31]. Please refer to Appendix D.2 for details. ", "page_idx": 6}, {"type": "text", "text": "Training Details. For all datasets, we set the batch size $B=64$ , the loss tradeoff $\\lambda=10$ and the maximum length $L=8$ for the reference point queue $Q_{r}$ . To optimize the task model, we adopt the Adam optimizer with momentum 0.9. As for the warm-up hyperparameter $\\rho$ , we $\\rho=0.6$ for Huffpost, fMoW and $\\rho=0.2$ for Arxiv, Yearbook, RMNIST, 2-Moons, ONP. For the conditional diffusion model, we set the maximum diffusion step $S=1000$ and use the AdamW optimizer with batch size $M=32$ , where $M$ is also the maximum length of queue $Q_{a}$ and $Q_{p}$ . And the number of generated residual classifier weights based on each reference point is set to ${M_{g}}=32$ in the inference stage. All experiments are conducted using the PyTorch packages and run on a single NVIDIA GeForce RTX 4090 GPU with 24GB memory. Three independent experiments with different random seeds are repeated for each task to report the mean and standard deviation (std) of accuracy, which is denoted in the format of \u201cmean $\\pm$ std\u201d in the table. Please refer to Appendix D.3 for more details. ", "page_idx": 6}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/8b150455551238f8ea2bf785613d7f0439da4f5feda0679d2959b5f4d793fe95.jpg", "table_caption": ["Table 1: Accuracy $(\\%)$ on Huffpost and Arxiv. The best and second best results in the incremental setup are bolded and underlined, respectively. (Huffpost: $K=3$ , Axriv: $K=7$ ) "], "table_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/4d2924697576f46e8a2198618901603b638b00cee0aa614e28ae4d592f39912d.jpg", "table_caption": ["Table 2: Accuracy $(\\%)$ on Yearbook, RMNIST and fMoW. The best and second best results in the incremental setup are bolded and underlined. (Yearbook: $K=5$ , RMNIST: $K=3$ , fMoW: $K=3$ ) "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/058a93159e4789505f075e8c749d702633b305d8ab5092d0d7309732bc0c5c9f.jpg", "table_caption": ["Table 3: (a): Error rate $(\\%)$ on 2-Moons and ONP $K=1$ ). (b): Ablation study on RMNIST. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Evaluation Metrics. We report the generalization performance on $K$ target domains in the future, including the average accuracy \u201cOOD avg.\u201d $\\begin{array}{r}{(\\frac{1}{K}\\sum_{k=1}^{K}\\mathrm{Accuracy}(\\mathcal{D}^{T+k}))}\\end{array}$ and the worst accuracy \u201cOOD worst\u201d $(\\operatorname*{min}_{k\\in\\{1,\\ldots,K\\}}$ Accuracy $\\scriptstyle({\\mathcal{D}}^{T+k})$ ) on $K$ target domains and the accuracy on $\\mathcal{D}^{T+1}$ . ", "page_idx": 7}, {"type": "text", "text": "5.2 Main Results ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We provide the quantitative results in Table 1, 2, 3(a), where the results of baselines in the nonincremental and incremental scenarios are reported from [45]. For ONP dataset, we notice that previous continuous domain adaptation methods (CDOT and CIDA) and EDG methods (GI and DRAIN) all perform worse than the Offline method that trains the task model on the cumulation of all source domains. In contrast, our W-Diff still obtains superior accuracy to previous state-of-the-art method (EvoS) on this challenging dataset, which validates the superiority of W-Diff. Besides, our W-Diff also achieves the best results on Huffpost, Arxiv, RMNIST and fMoW, in terms of the OOD worst accuracy. These results benefti from the modeling of parameter evolution pattern and the more robust predictions via the weight ensemble based on the conditional diffusion model. For Yearbook dataset, DRAIN, which models the evolution of whole model parameters via LSTM, is inferior to EvoS, which models the evolution of domain-level feature distribution. It suggests that modeling the evolving pattern at the feature level may be more appropriate for Yearbook, which also explains why W-Diff does not obtain the state-of-the-art performance on Yearbook. But our W-Diff still obviously outperforms DRAIN. Overall, we can observe that W-Diff surpasses the baselines in the incremental-training setup on six out of seven datasets, which shows the superiority of W-Diff. ", "page_idx": 7}, {"type": "text", "text": "5.3 Analytical Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Ablation Study. Firstly, the significant performance drop of variant A in Table 3(b) suggests that learning domain-invariant feature representations is necessary for EDG in the domain-incremental setting. Otherwise, the feature encoder could easily overfit to current domain, prohibiting the task model from generalization. Then, we try different ways to construct the average weight ensemble $\\bar{\\mathbf{W}}^{t e s t}$ , including variant $\\mathbf{C}$ which directly uses the historical classifier weights in $Q_{r}$ , i.e., $\\begin{array}{r}{\\bar{\\mathbf{W}}^{t e s t}=\\frac{1}{|Q_{r}|}\\sum_{\\ddot{\\mathbf{W}}^{t^{\\prime}}\\in Q_{r}}\\ddot{\\mathbf{W}}^{t^{\\prime}}}\\end{array}$ , and variant $\\mathrm{D}$ which augments classifier weights by adding small ", "page_idx": 7}, {"type": "image", "img_path": "2cFUYnNL1m/tmp/c81e6b3bde1a73ed55bfbeaf88366917e1d7939f9b7f7da3737cae84fb5a2210.jpg", "img_caption": ["Figure 2: (a): Decision boundary of EvoS [45] and W-Diff on 2-Moons, where we incrementally train the model until the $t$ -th domain and then visualize the decision boundary for future domain $\\overline{{\\mathcal{D}^{t+1}}}$ . (b): visualization of features from target domains, where different colors represent different domains. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "2cFUYnNL1m/tmp/f87b2677694a36c0d973f41aa84785730d84f4578e5d7441b8d8daff3a94581e.jpg", "img_caption": ["(a) Visualization of classifier weights. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "2cFUYnNL1m/tmp/c2be36eab172f9dab3f84a16ddb70c11a094ef0ffaa142922b43ba03bde2d5da.jpg", "img_caption": ["(b) Results when evaluating in batch-data stream. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 3: (a): Visualization of classifier weights for $\\mathcal{D}^{T+1},T=6$ , on RMNIST and their accuracy range. $\\ddot{\\mathbf{W}}^{t^{\\prime}},t^{\\prime}\\,=\\,1,\\dots,6$ , is the reference point from $Q_{r}$ , $\\hat{\\mathbf{W}}^{7|t^{\\prime}}$ is the generated $M_{g}$ classifier weights based on $\\ddot{\\mathbf{W}}^{t^{\\prime}}$ , and $\\mathbf{W}^{7}$ is the average weights of $\\mathcal{D}^{7}$ fine-tuned classifier weights in the last 200 iterations. (b): Accuracy of EvoS and W-Diff on RMNIST and Huffpost datastes, where $\\scriptstyle\\mathbf{W}-\\mathbf{D}\\dot{\\mathrm{iff}}_{s t r e a m}$ denotes W-Diff is evaluated with batch-data stream for each target domain. ", "page_idx": 8}, {"type": "text", "text": "noises to the weights in $Q_{r}$ , i.e., $\\begin{array}{r}{\\bar{\\mathbf{W}}^{t e s t}\\,=\\,\\frac{1}{|Q_{r}|}\\frac{1}{M_{g}}\\sum_{\\ddot{\\mathbf{W}}^{t^{\\prime}}\\in Q_{r}}\\sum_{j=1}^{M_{g}}(\\ddot{\\mathbf{W}}^{t^{\\prime}}+n o{\\dot{\\iota}}s e_{j}),n o{\\dot{\\iota}}s e_{j}\\,\\sim}\\end{array}$ $\\mathrm{Uniform}(-0.01,0.01)$ . The inferior results of variant B, C and D indicate that W-Diff beneftis from generating meaningful and customized classifier weights via controlling the condition of diffusion model. Finally, different conditioning ways for the diffusion model are explored, including variant E which injects the condition only in the cross-attention, and variant $\\boldsymbol{\\mathrm{F}}$ which injects the condition only in the input by concatenating the condition with diffused residual classifier weights. Results of variant E and F are both unsatisfactory. This is probably due to the large gap between the residual classifier weights in the input side and the full classifier weights in the condition side, which makes the information interaction hard. And injecting the condition only on the input side can lead to insufficient information interaction. Empirically, we find that the hybrid manner works best. ", "page_idx": 8}, {"type": "text", "text": "Decision Boundary Visualization on Future Domain. In Fig. 2(a), the model is incrementally trained until the training stage on the $t$ -th domain $\\mathcal{D}^{t}$ finishes. Then we visualize the decision boundary on the next future domain $\\mathcal{D}^{t+1}$ , $t=8,9$ . From the results, we can see that the decision boundary of W-Diff adapts to the evolution of domains better than that of EvoS, which shows the superiority of W-Diff in addressing evolving domain generalization in the domain-incremental setup. ", "page_idx": 8}, {"type": "text", "text": "t-SNE Visualization of Features. In this qualitative experiment, we visualize the features of future target domains for RMNIST dataset to show the effectiveness of $\\mathcal{L}_{c o n}^{t}$ . From Fig. 2(b), we can observe that features from different target domains align well. To some extent, it verifies the effectiveness of $\\mathcal{L}_{c o n}^{t}$ to learn a domain-shared feature space, which contributes to the mitigation of distribution shift. ", "page_idx": 8}, {"type": "text", "text": "Visualization of Generated Classifier Weights. In Fig. 3(a), we plot the generated classifier weights for domain $\\mathcal{D}^{T+1},T=6$ , on RMNIST, as well as the accuracy range on $\\breve{\\mathscr D}^{T+1}$ of generated classifier weights based on different reference points. In Fig. 3(a), some generated weights locate close to the average fine-tuned weights $\\mathbf{W}^{7}$ , showing that W-Diff generates domain-customized classifiers. ", "page_idx": 8}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/59118f7549c580b3e1eec7982e84d14e76cf5b020890ec268b5b411122c0e3d3.jpg", "table_caption": ["Table 4: Accuracy $(\\%)$ of W-Diff on RMNIST dataset using different conditions. $K=3$ ) "], "table_footnote": ["\u2021d idffeenroetnecse  tbheet rweefeerne tnhcee  rpefoeirnet nics es cpaoliendt  abnyd t haen cfhacotr opr $\\begin{array}{r}{\\eta=1.5-\\frac{1}{1+e^{-\\Delta t}}}\\end{array}$ , where $\\Delta t$ is the timestamp "], "page_idx": 9}, {"type": "text", "text": "Besides, $\\hat{\\mathbf{W}}^{7|1}$ , $\\hat{\\mathbf{W}}^{7|2}$ , $\\hat{\\mathbf{W}}^{7|3}$ are similar, while $\\hat{\\mathbf{W}}^{7|4},\\hat{\\mathbf{W}}^{7|5},\\hat{\\mathbf{W}}^{7|6}$ are different, due to the more pronounced differences among reference points $\\ddot{\\mathbf{W}}^{4}$ , $\\ddot{\\mathbf{W}}^{5}$ , and $\\ddot{\\mathbf{W}}^{6}$ . This implies that the evolution pattern may be different at different time intervals. And these diverse and high-performing generated weights based on different reference points could conduce to more robust predictions. ", "page_idx": 9}, {"type": "text", "text": "Evaluating in Batch-Data Stream. In addition to the inference way in Section 4.3, we also provide another version, where the data in target domain arrives batch by batch. Concretely, we use the iterative manner in Eq. (8) along with the average prediction in Section 4.3 to update the prototype matrix $\\pmb{\\mu}^{t e s t}$ , once a batch of data from $\\mathcal{D}^{t e s t}$ arrives. Then, we compute the average weight ensemble $\\bar{\\mathbf{W}}^{t e s t}$ via Eq. 11 for this data batch. Fig. 3(b) shows the results on RMNIST and Huffpost. The two manners present similar results and users can choose appropriate manner based on their scenarios. ", "page_idx": 9}, {"type": "text", "text": "Equipping Condition with Timestamp Difference. In this part, we try to explicitly incorporate the timestamp difference between the anchor point and reference point into the condition of diffusion model. Concretely, we scale the reference point $\\ddot{\\mathbf{W}}^{t^{\\prime}}$ in the condition ${\\mathfrak{c}}^{t,t^{\\prime}}$ by a factor $\\eta$ , where $\\begin{array}{r}{\\eta=1.5-\\frac{1}{1+e^{-\\Delta t}}}\\end{array}$ and $\\Delta t=t_{t}-t_{t^{\\prime}}$ is the timestamp difference between reference and anchor points. More distant reference points have larger $\\Delta t$ and are weakened. The results on RMNIST dataset are given in Table 4, where the average and worst accuracies of target domains improve slightly. The insignificant performance improvement may be due to the fact that our approach implicitly takes the timestamp difference into account via the domain-incremental training and residual classifier weights. ", "page_idx": 9}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/d7dd827637756c75e2821df3d64b9594df2b4f00531a301b7fb8f581b428a5d5.jpg", "table_caption": ["Results with Larger Backbones. We try larger backbones on the fMoW dataset by replacing the DenseNet-121 with DenseNet169/201/161 [15], respectively. The Table 5: Accuracy $(\\%)$ of W-Diff on fMoW dataset with differresults are provided in Table 5. ent backbones. $K=3)$ ) "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "When applying lagers backbones, our method still works well and further performance improvements are obtained. This benefits from the consideration of only modeling the evolution of classifier weights, instead of the whole network ", "page_idx": 9}, {"type": "text", "text": "parameters. Otherwise, the training difficulty and huge memory burden from the conditional diffusion model would be unbearable, despite of the greater feature extraction capability of larger backbones. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work delves into the under-explored problem of evolving domain generalization in the domainincremental setting, where the source domain is also non-stationary and dynamically evolves. To tackle this, we propose a Weight Diffusion (W-Diff) approach to capture the evolving pattern across domains at the parameter level and further generate customized classifiers for future domains. W-Diff innovatively leverages the conditional diffusion model to learn the evolution of classifiers from historical domain to current domain, conditioned on the historical classifier weights and current prototype matrix. Extensive results on synthetic and real-world datasets verify the efficacy of W-Diff. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This paper was supported by National Key R&D Program of China (No. 2021YFB3301503), the National Natural Science Foundation of China (No. 62376026), and also sponsored by Beijing Nova Program (No. 20230484296), CCF-Tencent Rhino-Bird Open Research Fund and KuaiShou. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] M. Arjovsky, L. Bottou, I. Gulrajani, and D. Lopez-Paz. Invariant risk minimization. arXiv:1907.02893, 2019. [2] G. Bai, C. Ling, and L. Zhao. Temporal domain generalization with drift-aware dynamic neural networks. In ICLR, 2023. [3] M. Caron, I. Misra, J. Mairal, P. Goyal, P. Bojanowski, and A. Joulin. Unsupervised learning of visual features by contrasting cluster assignments. In NeurIPS, 2020.   \n[4] H. Cha, J. Lee, and J. Shin. $C_{0}2_{1}$ : Contrastive continual learning. In ICCV, pages 9496\u20139505, 2021.   \n[5] A. Chaudhry, M. Ranzato, M. Rohrbach, and M. Elhoseiny. Efficient lifelong learning with A-GEM. In ICLR, 2019. [6] T. Chen, S. Kornblith, M. Norouzi, and G. E. Hinton. A simple framework for contrastive learning of visual representations. In ICML, pages 1597\u20131607, 2020. [7] L. Deng. The MNIST database of handwritten digit images for machine learning research [best of the web]. SPM, 29(6):141\u2013142, 2012.   \n[8] Y. Du, Z. Xiao, S. Liao, and C. Snoek. Protodiff: Learning to learn prototypical networks by task-guided diffusion. In NeurIPS, 2023.   \n[9] S. Ebrahimi, F. Meier, R. Calandra, T. Darrell, and M. Rohrbach. Adversarial continual learning. In ECCV, volume 12356, pages 386\u2013402, 2020.   \n[10] E. Fini, V. G. T. da Costa, X. Alameda-Pineda, E. Ricci, K. Alahari, and J. Mairal. Selfsupervised models are continual learners. In CVPR, pages 9611\u20139620, 2022.   \n[11] R. Gao and W. Liu. DDGR: continual learning with deep diffusion-based generative replay. In ICML, pages 10744\u201310763, 2023.   \n[12] H. E. Grossniklaus, J. M. Nickerson, H. F. Edelhauser, L. A. Bergman, and L. Berglin. Anatomic alterations in aging and age-related diseases of the eye. IOVS, 54(14):ORSF23\u2013ORSF27, 2013.   \n[13] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, pages 770\u2013778, 2016.   \n[14] J. Ho, A. Jain, and P. Abbeel. Denoising diffusion probabilistic models. In NeurIPS, 2020.   \n[15] G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In CVPR, pages 2261\u20132269, 2017.   \n[16] J. Kirkpatrick, R. Pascanu, N. C. Rabinowitz, J. Veness, G. Desjardins, A. A. Rusu, K. Milan, J. Quan, T. Ramalho, A. Grabska-Barwinska, D. Hassabis, C. Clopath, D. Kumaran, and R. Hadsell. Overcoming catastrophic forgetting in neural networks. arXiv:1612.00796, 2016.   \n[17] G. Kwon and J. C. Ye. Diffusion-based image translation using disentangled style and content representation. In ICLR, 2023.   \n[18] J. Lee, Y. Lee, J. Kim, A. R. Kosiorek, S. Choi, and Y. W. Teh. Set transformer: A framework for attention-based permutation-invariant neural networks. In ICML, volume 97, pages 3744\u20133753, 2019.   \n[19] H. Li, S. J. Pan, S. Wang, and A. C. Kot. Domain generalization with adversarial feature learning. In CVPR, pages 5400\u20135409, 2018.   \n[20] S. Li, C. H. Liu, Q. Lin, Q. Wen, L. Su, G. Huang, and Z. Ding. Deep residual correction network for partial domain adaptation. TPAMI, 43(7):2329\u20132344, 2021.   \n[21] S. Lutati and L. Wolf. Ocd: Learning to overfit with conditional diffusion models. In ICML, pages 23157\u201323169, 2023.   \n[22] F. Lv, J. Liang, S. Li, J. Zhang, and D. Liu. Improving generalization with domain convex game. In CVPR, pages 24315\u201324324, 2023.   \n[23] K. Muandet, D. Balduzzi, and B. Sch\u00f6lkopf. Domain generalization via invariant feature representation. In ICML, pages 10\u201318, 2013.   \n[24] A. Nasery, S. Thakur, V. Piratla, A. De, and S. Sarawagi. Training for the future: A simple gradient interpolation loss to generalize along time. In NeurIPS, pages 19198\u201319209, 2021.   \n[25] H. Ni, C. Shi, K. Li, S. X. Huang, and M. R. Min. Conditional image-to-video generation with latent flow diffusion models. In CVPR, pages 18444\u201318455, 2023.   \n[26] A. Q. Nichol and P. Dhariwal. Improved denoising diffusion probabilistic models. In ICML, pages 8162\u20138171, 2021.   \n[27] G. Ortiz-Jim\u00e9nez, M. E. Gheche, E. Simou, H. P. Maretic, and P. Frossard. CDOT: continuous domain adaptation using optimal transport. arXiv:1909.11448, 2019.   \n[28] W. S. Peebles, I. Radosavovic, T. Brooks, A. A. Efros, and J. Malik. Learning to learn with generative models of neural network checkpoints. arXiv:2209.12892, 2022.   \n[29] T. Qin, S. Wang, and H. Li. Generalizing to evolving domains with latent structure-aware sequential autoencoder. In ICML, pages 18062\u201318082, 2022.   \n[30] A. Radford, J. W. Kim, C. Hallacy, A. Ramesh, G. Goh, S. Agarwal, G. Sastry, A. Askell, P. Mishkin, J. Clark, G. Krueger, and I. Sutskever. Learning transferable visual models from natural language supervision. In ICML, volume 139, pages 8748\u20138763, 2021.   \n[31] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, pages 10674\u201310685, 2022.   \n[32] G. Saha and K. Roy. Continual learning with scaled gradient projection. In AAAI, pages 9677\u20139685, 2023.   \n[33] V. Sanh, L. Debut, J. Chaumond, and T. Wolf. Distilbert, a distilled version of BERT: smaller, faster, cheaper and lighter. arXiv:1910.01108, 2019.   \n[34] J. Serr\u00e0, D. Suris, M. Miron, and A. Karatzoglou. Overcoming catastrophic forgetting with hard attention to the task. In ICML, volume 80, pages 4555\u20134564, 2018.   \n[35] J. Song, C. Meng, and S. Ermon. Denoising diffusion implicit models. In ICLR, 2021.   \n[36] B. Soro, B. Andreis, H. Lee, S. Chong, F. Hutter, and S. J. Hwang. Diffusion-based neural network weights generation. arXiv:2402.18153, 2024.   \n[37] B. Sun and K. Saenko. Deep coral: Correlation alignment for deep domain adaptation. In ECCV Workshops, pages 443\u2013450, 2016.   \n[38] R. Taori, A. Dave, V. Shankar, N. Carlini, B. Recht, and L. Schmidt. Measuring robustness to natural distribution shifts in image classification. In NeurIPS, 2020.   \n[39] R. Tiwari, K. Killamsetty, R. K. Iyer, and P. Shenoy. GCR: gradient coreset based replay buffer selection for continual learning. In CVPR, pages 99\u2013108, 2022.   \n[40] A. Ulhaq, N. Akhtar, and G. Pogrebna. Efficient diffusion models for vision: A survey. arXiv:2210.09292, 2022.   \n[41] H. Wang, H. He, and D. Katabi. Continuously indexed domain adaptation. In ICML, volume 119, pages 9898\u20139907, 2020.   \n[42] K. Wang, Z. Xu, Y. Zhou, Z. Zang, T. Darrell, Z. Liu, and Y. You. Neural network diffusion. arXiv:2402.13144, 2024.   \n[43] Y. Wang, Z. Huang, and X. Hong. S-prompts learning with pre-trained transformers: An occam\u2019s razor for domain incremental learning. In NeurIPS, 2022.   \n[44] B. Xie, Y. Chen, J. Wang, K. Zhou, B. Han, W. Meng, and J. Cheng. Enhancing evolving domain generalization through dynamic latent representations. In AAAI, pages 16040\u201316048, 2024.   \n[45] M. Xie, S. Li, L. Yuan, C. H. Liu, and Z. Dai. Evolving standardization for continual domain generalization over temporal drift. In NeurIPS, 2023.   \n[46] L. Yang, Y. Han, X. Chen, S. Song, J. Dai, and G. Huang. Resolution adaptive networks for efficient inference. In CVPR, pages 2366\u20132375, 2020.   \n[47] L. Yang, H. Jiang, R. Cai, Y. Wang, S. Song, G. Huang, and Q. Tian. Condensenet V2: sparse feature reactivation for deep networks. In CVPR, pages 3569\u20133578, 2021.   \n[48] H. Yao, C. Choi, B. Cao, Y. Lee, P. W. Koh, and C. Finn. Wild-time: A benchmark of in-the-wild distribution shift over time. In NeurIPS, 2022.   \n[49] H. Yao, Y. Wang, S. Li, L. Zhang, W. Liang, J. Zou, and C. Finn. Improving out-of-distribution robustness via selective augmentation. In ICML, pages 25407\u201325437, 2022.   \n[50] Q. Zeng, C. Shui, L.-K. Huang, P. Liu, X. Chen, C. Ling, and B. Wang. Latent trajectory learning for limited timestamps under distribution shift over time. In ICLR, 2023.   \n[51] Q. Zeng, W. Wang, F. Zhou, C. Ling, and B. Wang. Foresee what you will learn: Data augmentation for domain generalization in non-stationary environments. arXiv:2301.07845, 2023.   \n[52] Q. Zeng, W. Wang, F. Zhou, G. Xu, R. Pu, C. Shui, C. Gagn\u00e9, S. Yang, C. X. Ling, and B. Wang. Generalizing across temporal domains with koopman operators. In AAAI, pages 16651\u201316659, 2024.   \n[53] F. Zenke, B. Poole, and S. Ganguli. Continual learning through synaptic intelligence. In ICML, pages 3987\u20133995, 2017.   \n[54] B. Zhang, C. Luo, D. Yu, X. Li, H. Lin, Y. Ye, and B. Zhang. Metadiff: Meta-learning with conditional diffusion for few-shot learning. In AAAI, pages 16687\u201316695, 2024.   \n[55] H. Zhang, M. Ciss\u00e9, Y. N. Dauphin, and D. Lopez-Paz. mixup: Beyond empirical risk minimization. In ICLR, 2018.   \n[56] K. Zhou, Z. Liu, Y. Qiao, T. Xiang, and C. C. Loy. Domain generalization: A survey. TPAMI, 45(4):4396\u20134415, 2023.   \n[57] K. Zhou, Y. Yang, Y. Qiao, and T. Xiang. Domain generalization with mixstyle. In ICLR, 2021. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix Contents ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A. Broader Impacts & Limitations   \nB. Notation Table   \nC. Algorithm of W-Diff   \nD. Experimental Setup Details   \nE. More Results ", "page_idx": 13}, {"type": "text", "text": "A Broader Impacts & Limitations ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Broader Impacts. In this work, we explore the evolving domain generalization in the domain incremental setting. The ability to continually learn from dynamic source domains and leverage the learned evolving pattern to generalize on unseen domains in the future may benefit relevant nonstationary scenarios, e.g., advertisement recommendation with continually emerging new training data and autonomous driving with distribution shift over time or geographical position, etc. It reduces the time and cost for labeling data of target domain and avoids the low efficiency of training the model from scratch with all saved domains once new training domain is available. Yet, for high-security demanding scenarios, the prediction from the model should be adopted with caution to avoid severe accidents, as failures can occur in our method when facing significant distribution shifts. ", "page_idx": 13}, {"type": "text", "text": "Limitations. Our work presents a way to capture the evolving pattern at the parameter level via capitalizing on the powerful modeling ability of conditional diffusion model. Yet, like any research, our work is not absolutely perfect. There are indeed some limitations that should be acknowledged. Firstly, the task considered in this paper limits to the classification. In the future, we may extend our method to more diverse tasks, e.g., regression tasks. Besides, considering the training cost, we only model the evolution of classifiers. Perhaps, it is feasible to consider more parameters by mapping them into a low-dimensional latent space, but achieving the accurate encoding and decoding is not easy. We leave this for a future work. ", "page_idx": 13}, {"type": "text", "text": "B Notation Table ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Given the large number of notations used throughout the paper, we provide an overall notation description in Table 6 to ease the burden on readers. ", "page_idx": 13}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/64a04a00e42bdf517c49fede2906655f087971fbf25f71bcc1cf3f882098221a.jpg", "table_caption": ["Table 6: Notation description "], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "W parameters of the classifier $Q_{r}$ the reference point queue $L$ the maximum length of $Q_{r}$ W\u00a8t\u2032 the saved classifier weights in $Q_{r}$ for the $t^{\\prime}$ -th domain $(\\ddot{\\mathbf{W}}^{t^{\\prime}}\\in\\mathbb{R}^{C\\times d_{f}})$ Wt the current classifier weights of the $t$ -th domain $(\\mathbf{W}^{t}\\in\\mathbb{R}^{C\\times d_{f}})$ ) $\\pmb{\\mu}^{t}$ the current prototype matrix of the $t$ -th domain $(\\pmb{\\mu}^{t}\\in\\mathbb{R}^{C\\times d_{f}}$ ) $\\pmb{\\mu}^{t}[c]$ the $c$ -th row of $\\pmb{\\mu}^{i}$ nt the total number of samples in seen batches after the warm-up stage on domain $\\mathcal{D}^{t}$ $p_{i}^{t,t^{\\prime}}$ the prediction for the $i$ -th sample in the $t$ -th domain by the classifier of domain $\\mathcal{D}^{t^{\\prime}}$ $p_{i}^{t,t^{\\prime}}[c]$ the c-th element of pit, $p_{i}^{t,t^{\\prime}}$ $\\bar{\\pmb{p}}_{i}^{t}$ the average prediction for the $i$ -th sample in the $t$ -th domain $Q_{a}$ the anchor point queue, which stores the classifier weights of current domain $Q_{p}$ the prototype queue, which stores the prototype matrices of current domain $M$ the maximum length of $Q_{a}$ and $Q_{p}$ $m$ the index of the object in $Q_{a}$ and $Q_{p}$ $\\mathbf{\\Phi}^{m}\\in\\{1,2,\\cdot\\cdot\\cdot,M\\})$ $\\pmb{\\mu}_{m}^{t}$ the $m$ -th prototype matrix in the prototype queue $Q_{p}$ of the $t$ -th domain Wt trhese $m$ -atlh  ccllaassssiiffieier r wweeiigghhttss e $Q_{a}$ of the $t$ -th domain \u2206Wt,t\u2032 $(\\Delta\\mathbf{W}_{m}^{t,t^{\\prime}}=\\mathbf{W}_{m}^{t}-\\ddot{\\mathbf{W}}^{t^{\\prime}})$ t,t\u2032 cm condition of the conditional diffusion model $(\\mathbf{c}_{m}^{t,t^{\\prime}}=\\ddot{\\mathbf{W}}^{t^{\\prime}}\\oplus\\pmb{\\mu}_{m}^{t}\\in\\mathbb{R}^{C\\times d_{f}\\times2})$ $\\rho$ warm-up hyperparameter $(\\rho\\in(0,1)$ ) $\\lambda$ tradeoff hyperparameter Ltcon the consistency loss on the $t$ -th domain $\\mathcal{L}_{c e}^{t}$ the cross-entropy loss on the $t$ -th domain $\\underline{{\\mathcal{L}_{t o t a l}^{t}}}$ the total loss on the $t^{\\th}$ -th domain $(\\mathcal{L}_{t o t a l}^{t}=\\mathcal{L}_{c e}^{t}+\\lambda\\mathcal{L}_{c o n}^{t})$ ", "page_idx": 14}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/2c89f0d2ce108a9f2ccc27303e6b121bd16c7ee862d2f9e5f7ddeb881df32040.jpg", "table_caption": ["Diffusion model-related "], "table_footnote": [], "page_idx": 14}, {"type": "text", "text": "C Algorithm of W-Diff ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The training and testing procedures of W-Diff are presented in Algorithm 1 and 2. ", "page_idx": 15}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/07f5829dc07774ff0606850644e5f1e664e0fe241adf75e1739dcee07df7354f.jpg", "table_caption": [], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "D Experimental Setup Details ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "D.1 Dataset Description ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Huffpost (license: CC0: Public Domain) from [48] comprises 63, 907 news headlines from the Huffington Post, with the time span from 2012 to 2018. These news headlines belong to 11 categories: \u201cBlack Voices\u201d, \u201cBusiness\u201d, \u201cComedy\u201d, \u201cCrime\u201d, \u201cEntertainment\u201d, \u201cImpact\u201d, \u201cQueer Voices\u201d, \u201cScience\u201d, \u201cSports\u201d, \u201cTech\u201d and \u201cTravel\u201d. This dataset reflects changes in news content and style over time. Follwoing [45], the first 4 years are used for training $T=4,$ ) and the last 3 years are used for testing $[K=3]$ ). For each training domain, we randomly divide the data into training set and validation set in the ratio of $9:1$ . ", "page_idx": 15}, {"type": "text", "text": "Arxiv (license: CC0: Public Domain) in [48] is a large-scale dataset, including 2, 057, 952 paper titles from 2007 to 2022. It reflects the change over time as research fields evolve. The task is to classify a research paper into one of 172 categories based solely on its title. For this dataset, we use data from the first 9 years as source domains $T=9$ ) and data from the last 7 years as target domains $[K=7]$ ). For each source domain, the data is randomly divided into training set and validation set in the ratio of $9:1$ . ", "page_idx": 15}, {"type": "text", "text": "Input: sequentially arriving target domains $\\mathcal{T}=\\{\\mathcal{D}^{T+1},\\mathcal{D}^{T+2},\\ldots,\\mathcal{D}^{T+K}\\}$ , feature encoder $E_{\\psi^{T}}$ , conditional diffusion model $\\mathcal{E}_{\\theta^{T}}$ , reference point queue $Q_{r}$ , number of categories $C$ , batch size $B$ , maximum diffusion step $S$ , number of generated residual weights $M_{g}$ based on each reference point. 1 for $k=1$ to $K$ do 2 Set $\\mathcal{D}^{t e s t}=\\mathcal{D}^{T+k}$ . 3 Calculate the prototype matrix $\\pmb{\\mu}^{t e s t}$ vai $\\begin{array}{r}{\\pmb{\\mu}^{t e s t}[c]=\\frac{1}{N^{t e s t}}\\sum_{i=1}^{N^{t e s t}}\\bar{p}_{i}^{t e s t}[c]\\cdot\\pmb{f}_{i}^{t e s t}}\\end{array}$ , where $\\begin{array}{r}{\\bar{p}_{i}^{t e s t}=\\frac{1}{|Q_{r}|}\\sum\\Ddot{\\mathbf{W}}^{t^{\\prime}}\\!\\in\\!Q_{r}}\\end{array}$ softmax $(\\ddot{\\mathbf{W}}^{t^{\\prime}}\\times f_{i}^{t e s t})$ , $\\pmb{f}_{i}^{t e s t}=E_{\\psi^{T}}(\\pmb{x}_{i}^{t e s t})$ , $c=0,\\ldots,C-1$ . 4 for $\\ddot{\\mathbf{W}}^{t^{\\prime}}\\in Q_{r}$ do 5 Generate Mg residual classifier weights: {\u2206Wjtest,t}jM=g1 by substituting the denoising net in Eq. (3) with $\\mathcal{E}_{\\theta^{T}}$ and applying the denoising process with condition $\\mathbf{c}^{t e s t,t^{\\prime}}=\\ddot{\\mathbf{W}}^{t^{\\prime}}\\oplus\\pmb{\\mu}^{t e s t}$ . 6 Obtain the average weight =|Q1r|M1g W\u00a8t\u2032\u2208Qr jM=g1( W\u00a8t\u2032 + \u2206Wjtest,t\u2032). 7 Get the final label predictions on domain $\\mathcal{D}^{t e s t}$ : $\\begin{array}{r}{\\{\\hat{y}_{i}^{t e s t}=\\mathrm{argmax}_{c}\\,{\\pmb p}_{i}^{t e s t}[c]\\}_{i=1}^{N^{t e s t}}}\\end{array}$ , where $\\pmb{p}_{i}^{t e s t}=\\operatorname{softmax}(\\bar{\\mathbf{W}}^{t e s t}\\times\\pmb{f}_{i}^{t e s t})$ . 8 return Label Predictions {{y\u02c6iT +k}iN=T1 +k} ", "page_idx": 16}, {"type": "text", "text": "Yearbook (MIT license) dataset comes from [48]. It collects 37, 189 grayscale yearbook photos from 128 American high schools, with the time span from 1930 to 2013. The resolution of photos is $32\\times32$ . Photos from different years reflect changes in fashion trends and social norms over the decades. The task is to classify the genders from a yearbook photo. It is worth mentioning that we only use this dataset to evaluate the generalization performance of different methods in classification tasks. Following [45], we group the data into domains at four-year intervals, resulting in 21 domains. And the first 16 domains are used as source domains ( $T=16$ ), with the last 5 domains as target domains $[K=5]$ ). For each source domain, we randomly select $90\\%$ of samples as the training split and $10\\%$ of samples as the validation split. And for each target domain, we evaluate on its all data. ", "page_idx": 16}, {"type": "text", "text": "RMNIST (license: CC BY-SA 3.0) is constructed from MNIST dataset [7] which contains grayscale images of digits from 0 to 9. The image resolution is $28\\times28$ . RMNIST first randomly divides all data in MNIST into 9 groups and then creates 9 domains by rotating the 9 groups by $0^{\\circ}$ , $10^{\\circ},\\ldots,80^{\\circ}$ , respectively. The rotation angle is used to simulate the evolving data distribution over time. Following [45], we use the first 6 domains $T=6$ ) as source domains and the last 3 domains as target domains $K=3$ ). Similarly, we split each source domain into training and validation sets in the ratio of $9:1$ . ", "page_idx": 16}, {"type": "text", "text": "fMoW (license: https://github.com/fMoW/dataset/blob/master/LICENSE) dataset is from [48], which consists of 141, 696 RGB satellite images from 2002 to 2017. The visual features in these satellite images change over time due to human and environmental activities. The image resolution is $224\\times224$ and the task is to classify the functional purpose of the buildings or land in a image into one of 62 categories. For this dataset, we consider each year as a separate domain. And the first 13 domains are used for training $T=13$ ), while the last 3 domains are used for testing $[K=3]$ ). The ratio of training data to validation data for each source domain is $9:1$ . ", "page_idx": 16}, {"type": "text", "text": "2-Moons (license: https://github.com/BaiTheBest/DRAIN/blob/main/LICENSE) from [2] is constructed from 2-entangled moons dataset, where the lower moon with label 0 and the upper moon with label 1 contain 100 data points, respectively. 2-Moons creates 10 domains by counterclockwise rotating the 200 data points at an interval of $18^{\\circ}$ . Similar to RMNIST, the rotation angle simulates the evolving of data distribution. Following [2], the first 9 ( $T=9$ ) domains are used as source domain and the last domain is used as target domain ( $K=1$ ). ", "page_idx": 16}, {"type": "text", "text": "Online News Popularity (ONP) (license: CC BY 4.0) in [2] summarizes a heterogeneous set of features related to the articles published by Mashable in a two-year period. This dataset is divided into 6 domains by time, and the goal is to predict whether an article is popular in social networks based on its features. Following [2], we use the first 5 domains for training $\\mathcal{T}=5,$ ) and the last domain for testing $[K=1]$ ). ", "page_idx": 16}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/94bcae0da67f4f6cb9b31ac953a3d7ac0b5d010bf05ad4b73e304b1f4bb1b9e0.jpg", "table_caption": ["Table 7: Configuration of the U-Net $\\mathcal{E}_{\\theta}$ on different datasets with hybrid conditioning way. "], "table_footnote": [], "page_idx": 17}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/54f91064ed9c83638ba6dc3ce4bd801ab6afb08f8971a0db023dd64423a4bfa4.jpg", "table_caption": ["Table 8: Training details on different datasets. "], "table_footnote": [], "page_idx": 17}, {"type": "text", "text": "D.2 Network Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For the backbone of the task model, Huffpost and Arxiv apply pretrained DistilBERT base model [33] along with a bottleneck layer [20] to reduce the feature dimensions into 128. The bottleneck layer is implemented as the combination of a linaer layer, BatchNorm and ReLU. Yearbook uses the 4-layer convolutional network in [48], RMNIST adopts the ConvNet in [29], and fMoW employs the ImageNet-pretrained DenseNet-121 [15] along with a bottleneck layer [20] to reduce the feature dimensions into 256. Meanwhile, 2-Moons uses a MLP with two hidden layers of hidden size 64 and 128, and ONP adopts a MLP with one hidden layer of hidden size 128. ", "page_idx": 17}, {"type": "text", "text": "For the conditional diffusion model, we implement it in a U-Net architecture similar to LDM [31] and make some modifications to better suit our method. Detailed modifications can be found in the code provided in the supplementary material. In Table 7, we provide detailed configurations for U-Net $\\mathcal{E}_{\\theta}$ on different datasets. Please refer to original paper [31] for the meaning of different hyperparameters. ", "page_idx": 17}, {"type": "text", "text": "D.3 Training Recipe ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Training details on different datasets are given in Table 8, where $B$ is the batch size for the task model, $I_{D M}$ is the inner iterations for updating $\\mathcal{E}_{\\theta}$ , $\\lambda$ is the loss tradeoff hyperparameter, $\\rho$ is the warm-up hyperparameter, $L$ is the maximum length of the reference point queue $Q_{r}$ , $M$ is the maximum length of the anchor point queue $Q_{a}$ and prototype queue $Q_{p}$ , and $M_{g}$ is the number of generated residual classifier weights based on each reference point. All experiments are conducted using the PyTorch packages and run on a single NVIDIA GeForce RTX 4090 GPU with 24GB memory. ", "page_idx": 17}, {"type": "text", "text": "E More Results ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "E.1 Hyperparameter Sensitivity ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In Fig. 4(a), we test the sensitivity of W-Diff to the loss tradeoff hyperparameter $\\lambda$ , the maximum length $L$ of the reference point queue $Q_{r}$ and the number $M_{g}$ of generated residual classifier weights based on each reference point, where $\\lambda\\in\\{0.1,0.5,1.0,5.0,10.0,50.0\\}.$ , $L\\in\\{1,2,4,8\\}$ , $M_{g}\\in\\{8,16,32,64,128\\}$ . We find that larger $M_{g}$ results in more weights for ensemble and seems to be better. W-Diff is a little bit sensitive to $\\lambda$ and $L$ . Empirically, $\\lambda=10.0$ and larger $L$ work well. ", "page_idx": 17}, {"type": "image", "img_path": "2cFUYnNL1m/tmp/46a7b73d2a4900a13370e12d87e7a77592d420d44e3cf1faee5acece1d56fc8a.jpg", "img_caption": ["Figure 4: (a): Sensitivity of W-Diff to hyperparameters $\\lambda,L,M_{g}$ on RMNIST. (b): The loss curve of $\\tilde{\\mathcal{L}_{d i f f}^{t}}$ on RMNIST and Huffpost when training conditional diffusion model on the second domain. ", "(a) Hyperparameter sensitivity. ", ""], "img_footnote": [], "page_idx": 18}, {"type": "table", "img_path": "2cFUYnNL1m/tmp/a96a9634559a0685e308d307744a113168c55fcf061a19dea0aed94dd01e6272.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "E.2 Convergence of Diffusion Model Training ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In Fig. 4(b), we plot the loss curve of $\\mathcal{L}_{d i f f}^{t}$ , when the conditional diffusion model is incrementally trained on the second source domain. Form the results, we see that the noise estimation error loss $\\mathcal{L}_{d i f f}^{t}$ steadily decreases and finally converges, demonstrating that using the FIFO queue to cache the recent $M$ classifier weights and prototype matrices after the warm-up stage is feasible for the diffusion model training. Storing all checkpoints after the warm-up stage provides lost of training data for diffusion model but requires more storage cost. By contrast, using a FIFO queue with a fixed length balances the storage cost and the diversity of training data. ", "page_idx": 18}, {"type": "text", "text": "E.3 Memory and Time Cost of Diffusion Model ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "In Table 9, we list the model size and inference time of the conditional diffusion model on different datasets. Since the diffusion model only models the evolving pattern of the classifier weights which are the parameters of a linear layer, the model size that is measured by the number of parameters is small on all datasets. Besides, the inference time when forwarding the diffusion model for 1000 times to generate a batch of residual classifier weights is moderate. Concretely, forwarding the condition diffusion model for one time requires $\\leq181$ ms. Certainly, acceleration techniques, e.g., DDIM [35] can be used to further reduce the inference time. ", "page_idx": 18}, {"type": "text", "text": "E.4 Significance test (t-test) of W-Diff. ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "To comprehensively evaluate the effectiveness of W-Diff, we conduct the significance test (ttest) on Huffpost, Arxiv, Yearbook, RMNIST and fMoW datasets. Concretely, a significance level of 0.05 is applied. If the p-value is less than 0.05, then the accuracy difference between EvoS [45] and W-Diff is statistically significant. For clearer explanation, the -log(p) of each pvalue is plotted. In Fig. 5, the majority of the -log(p) of the performance comparison between EvoS [45] and W-Diff are larger than -log(0.05), which means that W-Diff is statistically superior to EvoS [45] at most datasets. ", "page_idx": 18}, {"type": "image", "img_path": "2cFUYnNL1m/tmp/642afc2ef9294ce56950871880a4b10dbeb85ec07b4c7fee7fbdaebe259e0593.jpg", "img_caption": ["Figure 5: t-test for W-Diff vs EvoS [45], where a significance level of 0.05 is adopted. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We have stated the contribution of our work in the introduction section. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 19}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Justification: We have discussed the limitations of the work in Section A ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 19}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 19}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 19}, {"type": "text", "text": "Justification: Our work is a methodological level design and does not propose new theories. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 20}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We have provided the implementation details in Section D and provide the code in the supplementary material. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 20}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The datasets used in our paper are from previous work and are publicly available. We have provided the dataset details in Section D and the URL for downloading in the supplementary material. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 21}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We have described the problem setting in Section 3.1 and the experimental details in Section 5.1 and D. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 21}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We have reported the mean and standard deviation in the main experiments when independently running each task with three random seeds. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We have pointed out the used GPU in Section D and the number of parameters for the conditional diffusion model in Section E.3. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 22}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We have preserve anonymity in all submitted materials. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 22}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We have discussed the potential social impacts in Section A. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed. \u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. ", "page_idx": 22}, {"type": "text", "text": "\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 23}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 23}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 23}, {"type": "text", "text": "Justification: The datasets and models used in the paper are all public and from previous works. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 23}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: The datasets and models used in the paper are from previous works and are public. We have cited related papers in our work and provided the license in Section D.1. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: No new assets are released. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 24}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: Neither crowdsourcing nor research with human subjects is used. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 24}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 24}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 24}, {"type": "text", "text": "Justification: Our work does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}]