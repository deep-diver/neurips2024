[{"figure_path": "o8m4RM5mBk/tables/tables_3_1.jpg", "caption": "Table 1: Ablation of the attention network from ViT's last block.", "description": "This table presents the ablation study of removing the attention network from the last block of the Vision Transformer (ViT) model.  It shows the impact of different attention mechanisms (Self-Attention (SA), Identity SA, Cosine SA, Average SA) on the classification accuracy across five datasets (miniImageNet, CropDiseases, EuroSAT, ISIC2018, ChestX). The results demonstrate the impact of self-attention on both source and target domain performance.", "section": "2.3 Why do attention networks get ineffective on target domains?"}, {"figure_path": "o8m4RM5mBk/tables/tables_3_2.jpg", "caption": "Table 2: Domain similarity w.r.t. ablated attention modules.", "description": "This table presents the domain similarity results calculated using the Centered Kernel Alignment (CKA) method.  It compares the similarity between the source domain (miniImageNet) and the target domains (CropDiseases, EuroSAT, ISIC2018, ChestX) for different ablated attention modules in the Vision Transformer (ViT) network.  The modules ablated include the input tokens only, the input tokens with self-attention, input tokens with identity self-attention, input tokens with cosine self-attention, and input tokens with average self-attention. A higher CKA value indicates higher similarity between domains, showing lower domain transferability. The table helps in the analysis of how different attention mechanisms affect the transferability of ViT across different domains.", "section": "2 Delve into Attention in ViT-based Cross-Domain Few-Shot Learning"}, {"figure_path": "o8m4RM5mBk/tables/tables_6_1.jpg", "caption": "Table 3: Comparison with state-of-the-art works by the 5-way 1-shot classification.", "description": "This table compares the proposed AttnTemp method with other state-of-the-art methods on a 5-way 1-shot classification task across four benchmark datasets (CropDiseases, EuroSAT, ISIC2018, and ChestX).  It shows the average accuracy achieved by each method on each dataset, broken down by whether or not fine-tuning (FT) was used.  The table allows for a comparison of performance between different backbone networks (ResNet10 and ViT-S) and highlights the improvement achieved by the AttnTemp method.", "section": "4 Experiments"}, {"figure_path": "o8m4RM5mBk/tables/tables_7_1.jpg", "caption": "Table 3: Comparison with state-of-the-art works by the 5-way 1-shot classification.", "description": "This table compares the proposed AttnTemp method with other state-of-the-art methods on a 5-way 1-shot classification task.  It shows the backbone network used (ResNet10 or ViT-S), whether fine-tuning (FT) was employed, the conference and year of publication, and the accuracy achieved on four different target datasets (Crop, Euro, ISIC, Ches) and the average accuracy across all four datasets.  The table helps demonstrate the improved performance of AttnTemp compared to existing approaches.", "section": "4 Experiments"}, {"figure_path": "o8m4RM5mBk/tables/tables_7_2.jpg", "caption": "Table 5: Ablation study by the 5-way 5-shot accuracy.", "description": "This table presents the ablation study of the proposed method on the 5-way 5-shot accuracy task. It compares the performance of different variants of the method, specifically varying whether the attention adjustment and abandonment modules are used.  The results are presented in terms of accuracy for four target datasets (CropDisease, EuroSAT, ISIC2018, ChestX) and their average.", "section": "4.4 Ablation Study"}, {"figure_path": "o8m4RM5mBk/tables/tables_8_1.jpg", "caption": "Table 6: Verification of improved self-attention w.r.t. domain similarity and target-domain accuracy.", "description": "This table presents a comparison of the baseline (BL) and the proposed method's performance across different ViT blocks (1-12).  It shows the Centered Kernel Alignment (CKA) similarity scores, measuring the similarity between the feature representations learned by the baseline and the proposed method across various blocks.  The table also lists the accuracy (Acc.) for both methods on the target domain, illustrating the improvement in performance achieved by the proposed method, which enhances the transferability of the attention networks and improves the accuracy of target domain classification.", "section": "4.5 Verification of Improved Attention"}, {"figure_path": "o8m4RM5mBk/tables/tables_14_1.jpg", "caption": "Table 7: Our method with iBOT-pretrained ViT-S.", "description": "This table presents the ablation study results on four target datasets (ChestX, ISIC2018, EuroSAT, CropDiseases) using 1-shot and 5-shot settings.  It compares the performance of the baseline iBOT (Image BERT pre-training) method with the proposed AttnTemp method (Attention Temperature). The results show that the proposed method consistently improves the accuracy on all four datasets and in both shot settings, indicating the effectiveness of the attention temperature adjustment technique in enhancing cross-domain few-shot learning.", "section": "A.2 More experiments"}, {"figure_path": "o8m4RM5mBk/tables/tables_15_1.jpg", "caption": "Table 8: Our method with DINO-pretrained ViT-Base.", "description": "This table presents a comparison of the performance of the baseline method (DINO-B) and the proposed method (DINO-B+Ours) using a ViT-Base model pretrained with DINO.  The results are shown for both 1-shot and 5-shot settings across four target datasets (ChestX, ISIC2018, EuroSAT, CropDiseases).  The average accuracy across all four datasets is also provided for each setting and method.", "section": "4 Experiments"}]