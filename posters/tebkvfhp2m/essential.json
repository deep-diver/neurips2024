{"importance": "This paper is crucial for researchers working with large language models (LLMs). It provides **a novel framework for prompt compression**, addressing the high cost of LLM inference. The framework's theoretical analysis and proposed algorithm can significantly improve efficiency and reduce costs, making LLMs more accessible and practical for various applications.  It also opens **new avenues for research** in prompt compression techniques and its theoretical limits.", "summary": "This paper introduces a rate-distortion framework for prompt compression in LLMs, bridging the gap between existing methods and optimal performance. By formulating prompt compression as a linear program, researchers can efficiently compute theoretical limits.", "takeaways": ["A rate-distortion framework is proposed to unify token-level prompt compression methods for black-box LLMs.", "The optimal rate-distortion function is derived and an efficient algorithm is provided to compute it.", "Adaptive QuerySelect, a novel query-aware and variable-rate method, outperforms existing methods."], "tldr": "Large Language Models (LLMs) are powerful but expensive to use, especially with long prompts.  Existing prompt compression techniques aim to reduce costs but lack a unified theoretical framework and often underperform. This paper tackles this by presenting a novel framework that considers the rate-distortion trade-off for prompt compression in LLMs.\nThe paper formalizes prompt compression as a rate-distortion problem, deriving the optimal trade-off as a linear program.  It introduces a new efficient algorithm to compute this limit and evaluates existing methods against this optimal baseline.  A new algorithm, Adaptive QuerySelect, is proposed, and is shown to achieve significantly better performance by utilizing query information and variable-rate compression.", "affiliation": "University of Texas at Austin", "categories": {"main_category": "Natural Language Processing", "sub_category": "Large Language Models"}, "podcast_path": "TeBKVfhP2M/podcast.wav"}