[{"figure_path": "TeBKVfhP2M/tables/tables_20_1.jpg", "caption": "Table 1: The outputs produced by lines 7\u20139 of Algorithm 1 with (Ra, Da) and (R\u03b2, D\u03b2) as given in Fig. 6.", "description": "This table shows the output of lines 7-9 of Algorithm 1 which is used to compute the distortion-rate function via the dual linear program. The table is used as an example in the paper for demonstrating how the algorithm works.  The table shows the values of lambda (\u03bb), and the minimizers m(x)  for each x \u2208 X (where X is a set containing two elements, alpha and beta in this case), and  for each range of lambda values defined by lines 5-6 of Algorithm 1.", "section": "C.2 Proof and illustration of Algorithm 1"}, {"figure_path": "TeBKVfhP2M/tables/tables_23_1.jpg", "caption": "Table 2: One example of each query from the validation set of our synthetic dataset", "description": "This table shows example prompts and queries from the validation set of the synthetic dataset used in the paper's experiments.  The prompts are binary strings, and the queries are natural language questions designed to elicit specific information about those strings. The corresponding answers are also provided.", "section": "4.1 Experimental setup"}, {"figure_path": "TeBKVfhP2M/tables/tables_24_1.jpg", "caption": "Table 3: One example of each prompt from our natural language dataset.", "description": "This table provides four examples of prompts and their associated queries and answers from a small natural language dataset used in the paper's experiments. Each row represents a prompt (a short text passage), a query (a question related to the prompt), and the corresponding answer. The dataset is used to evaluate the performance of prompt compression methods on natural language data.", "section": "F.2.2 Choice of distortion metric"}, {"figure_path": "TeBKVfhP2M/tables/tables_25_1.jpg", "caption": "Table 4: Final set of hyperparameters used to train the LLM used in each prompt compression method.", "description": "This table lists the hyperparameters used for fine-tuning LLMs in each prompt compression method.  It includes tokenization type (standard or forced), number of epochs, batch size, learning rate, LoRA rank and LoRA alpha.  The hyperparameters were determined through a grid search process, choosing the best performing set on a test dataset.  The methods are: Selective Context, LLMLingua (with and without query), LLMLingua-2 (with and without query), QuerySelect, Adaptive QuerySelect, and the black-box target LLM.", "section": "4.2 Results"}, {"figure_path": "TeBKVfhP2M/tables/tables_26_1.jpg", "caption": "Table 4: Final set of hyperparameters used to train the LLM used in each prompt compression method.", "description": "This table shows the hyperparameters used for fine-tuning the language models used in each prompt compression method.  It lists the tokenization method (standard or forced), number of epochs, batch size, learning rate, LoRA rank, and LoRA alpha for each method: Selective Context, LLMLingua (standard and forced), LLMLingua Query (standard and forced), LLMLingua-2 (standard and forced), QuerySelect (standard and forced), Adaptive QuerySelect (standard and forced), and the black-box target LLM (standard and forced).", "section": "F.3 LLM fine-tuning"}, {"figure_path": "TeBKVfhP2M/tables/tables_32_1.jpg", "caption": "Table 6: Average time required to compress a single prompt (seconds).", "description": "This table presents the average time taken to compress a single prompt, in seconds, for different prompt compression methods.  The timings are broken down for two datasets: NarrativeQA and a smaller natural language processing (NLP) dataset. The table allows for a comparison of the computational efficiency of the various methods.", "section": "4.2 Results"}]