[{"figure_path": "eP9auEJqFg/figures/figures_1_1.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the core concept of Representation Noising (RepNoise). It shows how the method works by pushing the intermediate activations (representations) of harmful text inputs towards random directions. This process reduces the mutual information between harmful representations and harmful text sequences, making it difficult for attackers to recover harmful representations even if they have access to the model's weights. The visualization uses Principal Component Analysis (PCA) to show that the structure of harmful representations is destroyed after applying RepNoise.", "section": "Method"}, {"figure_path": "eP9auEJqFg/figures/figures_7_1.jpg", "caption": "Figure 2: L2 distance between weights of each layer between the base model, a successfully attacked model and two defences. RepNoise's differences spread through the layers compared to Adversarial loss where the weight differences are concentrated at the later layers indicative of superficial defence.", "description": "This figure shows the L2 distance between the weights of each layer in three different models: the base model, a successfully attacked model, and two defended models (using adversarial loss and RepNoise). The plot shows that the adversarial loss defence mainly affects the last few layers of the model, while RepNoise changes weights more uniformly across all layers. This suggests that the adversarial loss defense is a surface-level defense that does not affect the deep representations, while RepNoise affects the deep representations by spreading changes across the model's layers. Thus, RepNoise appears to provide a more robust and effective defense against harmful fine-tuning.", "section": "5 Mechanistic Analysis"}, {"figure_path": "eP9auEJqFg/figures/figures_8_1.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the core concept of Representation Noising (RepNoise). It shows how the method works by pushing intermediate activations (representations) of harmful text inputs toward random directions using Principal Component Analysis (PCA).  By doing this, RepNoise reduces the mutual information between harmful representations and the original harmful text sequences, making it harder for attackers to reconstruct harmful representations during harmful fine-tuning attacks. The visualization highlights the loss of structure in the 'Immunized Representations Z*' after applying RepNoise.", "section": "Method"}, {"figure_path": "eP9auEJqFg/figures/figures_8_2.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the core idea of Representation Noising (RepNoise).  It shows how RepNoise modifies the intermediate activations (representations) of harmful text inputs within a neural network. Instead of directly altering the weights, RepNoise pushes the harmful representations towards random noise vectors, thus reducing the mutual information between these representations and the original harmful text. This makes it harder for an attacker to recover the harmful information during fine-tuning, even if they have access to the model's weights.  The visualization uses Principal Component Analysis (PCA) to project high-dimensional representations into a 2D space, clearly showing that after RepNoise, the harmful representations lose their structure and become indistinguishable from random noise.", "section": "1 Introduction"}, {"figure_path": "eP9auEJqFg/figures/figures_8_3.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the core idea behind Representation Noising (RepNoise).  It shows how the method alters the intermediate activations (representations) of harmful text inputs within a neural network. Instead of directly modifying the weights, RepNoise pushes these harmful representations towards random noise, effectively reducing the information contained within them that could be used to perform harmful fine-tuning attacks (HFAs). The visualization uses principal component analysis (PCA) to show that the structure of the harmful representations is removed, making it difficult for attackers to recover them even if they have access to the model's weights. ", "section": "1 Introduction"}, {"figure_path": "eP9auEJqFg/figures/figures_28_1.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the core idea behind Representation Noising (RepNoise). Harmful representations (Zharmful) in the original representations (Z) are pushed towards random noise, effectively removing their information content.  This makes it harder for attackers to recover these harmful representations during harmful fine-tuning attacks. The figure uses Principal Component Analysis (PCA) to visualize the effect, showing that harmful representations become indistinguishable from noise after RepNoise is applied.", "section": "1 Introduction"}, {"figure_path": "eP9auEJqFg/figures/figures_29_1.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the mechanism of Representation Noising (RepNoise). It shows how RepNoise modifies the intermediate activations (representations) of harmful text inputs.  By pushing these harmful representations towards random directions, RepNoise reduces the mutual information between the harmful representations and the corresponding harmful text sequences. This makes it difficult for attackers to recover the harmful representations through harmful fine-tuning attacks (HFAs). The PCA visualization demonstrates that the structure of the harmful representations is effectively removed after applying RepNoise.", "section": "1 Introduction"}, {"figure_path": "eP9auEJqFg/figures/figures_29_2.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the core idea behind Representation Noising (RepNoise).  It shows how RepNoise modifies the intermediate layer activations (representations) of harmful text inputs. Instead of directly altering the input or output, RepNoise pushes the harmful representations towards random noise vectors. This makes it difficult for an attacker to recover the original harmful representations during harmful fine-tuning attacks (HFAs), even if they have access to the model weights. The visualization uses Principal Component Analysis (PCA) to demonstrate the lack of discernible structure in the modified (immunized) representations, emphasizing that harmful information is effectively removed.", "section": "1 Introduction"}, {"figure_path": "eP9auEJqFg/figures/figures_32_1.jpg", "caption": "Figure 1: Representation Noising pushes the intermediate activations of harmful text inputs (their representations) towards random directions, effectively reducing the mutual information between harmful representations and harmful text sequences and making it difficult to recover harmful representations through HFAs. We visualize this here as a projection (PCA) which isn't able to recover any structure.", "description": "This figure illustrates the RepNoise defense mechanism. It shows how the method pushes harmful representations (intermediate activations of harmful text inputs) towards random directions, thereby reducing the mutual information between these harmful representations and the harmful text sequences.  The result is that it becomes difficult to recover the harmful representations during harmful fine-tuning attacks (HFAs). The visualization uses Principal Component Analysis (PCA) to show that no structure remains after the RepNoise process, making it difficult for attackers to leverage this information during the HFAs.", "section": "Method"}]