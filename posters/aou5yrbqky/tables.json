[{"figure_path": "aou5yrBqKy/tables/tables_4_1.jpg", "caption": "Table 1: Summary of training data statistics in the fine-tuning stage.", "description": "This table summarizes the datasets used in the fine-tuning stage of the TabPedia model training.  It shows the dataset name, the subset used (if applicable), the tasks performed on that subset, and the number of samples in each subset. The datasets include PubTab1M (with subsets for detection, structure recognition/question answering, and querying), FinTabNet (structure recognition/question answering), PubTabNet (structure recognition), WikiTableQuestions (question answering), and TabFact (question answering).", "section": "3.1 Model Architecture"}, {"figure_path": "aou5yrBqKy/tables/tables_4_2.jpg", "caption": "Table 2: Different task types and their instruction examples.", "description": "This table shows four different visual table understanding (VTU) tasks and provides an example instruction for each.  The tasks are Table Detection (TD), Table Structure Recognition (TSR), Table Querying (TQ), and Table Question Answering (TQA). Each example shows how a user might instruct a model to perform that task. This demonstrates the diversity of tasks encompassed by VTU and highlights the variety of input/output modalities.", "section": "4 Dataset Construction"}, {"figure_path": "aou5yrBqKy/tables/tables_6_1.jpg", "caption": "Table 3: Comparison with the existing best table detection model TATR [9]. NMS denotes Non-Maximum Suppression.", "description": "This table compares the performance of TabPedia with the state-of-the-art table detection model, TATR [9], on the task of table detection.  It shows that TabPedia achieves comparable performance to TATR, especially when using the DETR backbone, but without using Non-Maximum Suppression (NMS), indicating a more efficient and potentially more robust approach.", "section": "5.2 Quantitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_6_2.jpg", "caption": "Table 5: Quantitative results on two subsets of PubTab1M [9], including PubTab1M-Str and PubTab1M-Syn.", "description": "This table presents a quantitative comparison of the TabPedia model's performance on two subsets of the PubTab1M dataset: PubTab1M-Str (table structure recognition) and PubTab1M-Syn (synthetic table querying).  It compares TabPedia against the task-specific model TATR [9] for the table structure recognition task, showcasing TabPedia's competitive performance despite being a general-purpose model for various visual table understanding (VTU) tasks.  The table also includes results on both table querying (TQ) and the combined table detection and querying (TD+TQ) tasks, highlighting TabPedia's ability to handle multiple tasks within a unified framework.", "section": "5.2 Quantitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_6_3.jpg", "caption": "Table 4: Comparison with end-to-end TSR methods on two datasets. \"*\" represents the results reported by [41].", "description": "This table compares the performance of TabPedia with three other end-to-end table structure recognition (TSR) methods on two datasets: PubTabNet and FinTabNet.  The metrics used are the S-TEDS scores (Structure Tree-EditDistance-based Similarity), which measure the similarity between the predicted and ground truth table structures.  The input size refers to the resolution of the images used for processing.  The results indicate TabPedia's superior performance compared to the other methods.", "section": "5.2 Quantitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_6_4.jpg", "caption": "Table 6: Comparison with existing LVLMs on TQA task. \"*\" denotes the results obtained through the open-source checkpoint or API of the closed-source model. ComTQA is our released new benchmark. The second best methods are underlined.", "description": "This table compares the performance of TabPedia against other Large Vision Language Models (LVLMs) on the Table Question Answering (TQA) task.  It shows accuracy scores on three datasets: WTQ, TabFact, and the newly introduced ComTQA benchmark.  ComTQA is highlighted as a more challenging, real-world benchmark.", "section": "5.2 Quantitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_8_1.jpg", "caption": "Table 7: Contributions of different tokens.", "description": "This table presents the averaged attention scores of different tokens (Meditative tokens, High-res visual tokens, Low-res visual tokens) across all layers and attention heads from the LLM, showing their contribution to the generation of satisfactory answers for different tasks (TD, TSR, TQ, TQA).", "section": "5.3 Qualitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_9_1.jpg", "caption": "Table 8: Impact of meditative tokens in TabPedia.", "description": "This table presents the impact of using meditative tokens in the TabPedia model.  It compares the performance metrics (Precision for PubTab1M-Det, S-TEDS for FinTabNet, and Accuracy for WTQ) with and without the meditative tokens. The results show a significant improvement in performance when using meditative tokens.", "section": "5.4 Ablation Studies"}, {"figure_path": "aou5yrBqKy/tables/tables_9_2.jpg", "caption": "Table 7: Contributions of different tokens.", "description": "This table presents the averaged attention scores of the TabPedia-generated answers with respect to meditative tokens, high-resolution visual tokens, and low-resolution visual tokens across all the attention maps from the LLM for different tasks (TD, TSR, TQ, and TQA). The results demonstrate the importance of the meditative tokens in generating satisfactory answers and the varying contributions of high- and low-resolution visual information for different tasks.", "section": "5.3 Qualitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_9_3.jpg", "caption": "Table 10: Impact of different training strategies on low-resolution vision encoder.", "description": "This table shows the impact of different training strategies (frozen vs. unfrozen) on the low-resolution vision encoder's performance across three datasets (PubTab1M-Det, FinTabNet, WTQ) using different metrics (Precision, S-TEDS, Acc). The results indicate that freezing the encoder leads to comparable performance with slightly improved accuracy and reduced training time.", "section": "5.2 Quantitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_9_4.jpg", "caption": "Table 11: Impact of dual vision encoders.", "description": "This table presents the results of experiments evaluating the impact of using both high-resolution and low-resolution vision encoders in the TabPedia model.  The results are shown for three different tasks (PubTab1M-Det, FinTabNet, WTQ), each using a different metric (Precision, S-TEDS, and Accuracy, respectively). The table compares the model's performance when only the high-resolution encoder is used, only the low-resolution encoder is used, and when both encoders are used together.", "section": "5.2 Quantitative Results"}, {"figure_path": "aou5yrBqKy/tables/tables_18_1.jpg", "caption": "Table B3: The illustration of an example table with dilated bounding box annotations for different object classes for modeling table structure recognition.", "description": "This table shows an example of how table structure is represented using dilated bounding boxes. Each box represents a different component of the table structure, such as rows, columns, column headers, projected row headers, and spanning cells.  The visual representation helps in modeling the table's structure for machine comprehension. This aids in tasks like Table Structure Recognition (TSR).", "section": "B Annotation in TSR task"}, {"figure_path": "aou5yrBqKy/tables/tables_20_1.jpg", "caption": "Table D2: Qualitative results of TabPedia's responses.", "description": "This table shows several examples of qualitative results comparing TabPedia's responses with and without meditative tokens.  It demonstrates how the inclusion of meditative tokens leads to more complete and accurate responses, particularly in longer-form answers and those requiring complex reasoning.", "section": "D More Qualitative Results"}]