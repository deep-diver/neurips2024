{"references": [{"fullname_first_author": "Brandon Smock", "paper_title": "PubTables-1M: Towards comprehensive table extraction from unstructured documents", "publication_date": "2022-06-01", "reason": "This paper introduces a large-scale dataset, PubTables-1M, crucial for training and evaluating visual table understanding models, significantly impacting the field's progress."}, {"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2020-01-01", "reason": "This foundational paper introduces the Vision Transformer (ViT), a highly influential architecture for image processing that forms the basis of many visual table understanding models."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-07-01", "reason": "The introduction of CLIP, a model that connects image and text embeddings, provides a crucial mechanism for visual-language tasks such as visual table understanding."}, {"fullname_first_author": "Nicolas Carion", "paper_title": "End-to-end object detection with transformers", "publication_date": "2020-01-01", "reason": "DETR's introduction of an end-to-end object detection approach based on transformers significantly advanced table structure recognition by simplifying the pipeline and improving accuracy."}, {"fullname_first_author": "Hao Feng", "paper_title": "Docpedia: Unleashing the power of large multimodal model in the frequency domain for versatile document understanding", "publication_date": "2023-01-01", "reason": "Docpedia, a large multimodal model, is a related work demonstrating the effectiveness of large language models for document understanding, informing the design choices in this paper's proposed method."}]}