[{"figure_path": "Cjnirz5pan/figures/figures_1_1.jpg", "caption": "Figure 1: Comparisons of (a) prevailing PTM-based CL methods [2, 23, 52] and our Slow And Fast parameter-Efficient tuning (SAFE). The right part (b) illustrates several parameter-efficient tuning (PET) blocks: Adapter [6], Scale & Shift (SSF) [21], and Visual Prompt Tuning (VPT) [16].", "description": "This figure compares existing continual learning methods that use pre-trained models with the proposed SAFE method.  Panel (a) shows that most previous methods use parameter-efficient tuning (PET) in the first session, but freeze parameters in later sessions.  This contrasts with SAFE, which uses slow and fast PET methods to balance stability and plasticity. Panel (b) illustrates common PET methods including adapters, scale and shift, and visual prompt tuning.", "section": "1 Introduction"}, {"figure_path": "Cjnirz5pan/figures/figures_3_1.jpg", "caption": "Figure 2: An overview of our SAFE framework. In the first session, PTM transfers knowledge to the slow learner for better generalization. In sessions t > 1, the fast learner is guided by the slow learner for enhanced plasticity. During inference, robust predictions are made by dynamic aggregation.", "description": "This figure illustrates the SAFE framework for continual learning.  The left side shows the training process.  In the first session (t=1), knowledge is transferred from the pre-trained model (PTM) to the slow learner (S-PET) which is then frozen. Subsequent sessions (t>1) involve a fast learner (F-PET) that is guided by the slow learner to learn new concepts while preventing catastrophic forgetting. The right side shows the inference process, where an entropy-based aggregation strategy combines the predictions of the slow and fast learners for robust results.", "section": "3.2 Overall Architecture"}, {"figure_path": "Cjnirz5pan/figures/figures_7_1.jpg", "caption": "Figure 3: Comparisons with T-SNE visualization.", "description": "This figure visualizes the embedding space of five unseen classes and five seen classes using t-SNE after the first session adaptation. It compares the baseline method with the proposed method (ours) showing that the embedding space of the slow learner in the proposed method exhibits distinct separation between seen and unseen classes, illustrating the successful integration of generalization capabilities from the PTM into the slow learner.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/figures/figures_8_1.jpg", "caption": "Figure 4: Validations on the necessity of the aggregation on IN-R. We provide detailed classification accuracy of test samples from different sessions. Results of the slow learner, the fast learner and SAFE are presented for comparison.", "description": "This figure validates the necessity of using an aggregation strategy that combines the predictions from both the slow and fast learners.  It shows the classification accuracy for different class ranges (00-19, 20-39, etc.) on the ImageNet-R (IN-R) dataset across different training sessions. The results demonstrate that the aggregation method outperforms using only the slow learner or the fast learner, highlighting the complementary strengths of both learners for robust performance.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/figures/figures_8_2.jpg", "caption": "Figure 5: Aggregation weights for the slow learner and fast learner on IN-R.", "description": "This figure visualizes how the entropy-based aggregation dynamically balances the contributions of the slow and fast learners during inference on the ImageNet-R dataset. The x-axis represents class indices grouped into ranges, while the y-axis shows the average aggregation weights assigned to each learner for those classes.  The plot reveals that the slow learner has higher weights for older classes (0-119), reflecting its superior performance on previously seen data, while the fast learner receives stronger weights for newer classes (120-199), indicating its better ability to adapt to recently introduced concepts. This dynamic allocation of weights highlights the complementary strengths of the two learners.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/figures/figures_9_1.jpg", "caption": "Figure 6: Memory usage comparison.", "description": "This figure compares the memory usage (parameter size) and final accuracy of different continual learning methods (ADAM, RanPAC, Ours (SAFE), SSIAT, CODAPrompt, EASE).  It demonstrates that SAFE achieves comparable or better performance than other methods while using a similar or even smaller parameter size.  This highlights SAFE's efficiency in terms of resource usage.", "section": "4.4 Memory Usage"}, {"figure_path": "Cjnirz5pan/figures/figures_16_1.jpg", "caption": "Figure 3: Comparisons with T-SNE visualization.", "description": "This figure visualizes the effectiveness of the slow learner by comparing the t-SNE embeddings of five unseen classes and five seen classes, after the first session adaptation. It shows a clear separation between seen and unseen classes in the slow learner's embedding space, demonstrating successful knowledge transfer from the PTM and improved generalization ability.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/figures/figures_17_1.jpg", "caption": "Figure 8: Visualization of seven benchmark datasets.", "description": "This figure shows a visualization of the seven benchmark datasets used in the paper: CIFAR100, CUB200, ImageNet-A, Omnibenchmark, ImageNet-R, DomainNet, and VTAB. Each dataset is represented by a grid of images, showcasing the variety of visual data included in each dataset. This visualization helps demonstrate the diversity and complexity of the datasets, highlighting the differences in image content, style, and quality.  The datasets cover a wide range of image types and visual characteristics, making them suitable for evaluating the continual learning capabilities of different models.", "section": "F Visualization of Datasets"}]