[{"figure_path": "Cjnirz5pan/tables/tables_6_1.jpg", "caption": "Table 1: Performance on DomainNet", "description": "This table presents the performance comparison of different methods on the DomainNet dataset in terms of final accuracy.  The results show that the proposed SAFE method achieves the highest accuracy (67.82%) compared to other state-of-the-art approaches, such as L2P, S-iPrompts, ADaM, and RanPAC.  It also demonstrates the contribution of both the slow and fast learners within the SAFE framework, showcasing their individual performances before aggregation.", "section": "4.2 Comparisons with State-of-The-Arts"}, {"figure_path": "Cjnirz5pan/tables/tables_7_1.jpg", "caption": "Table 2: Performance comparisons on six class-incremental learning datasets. The final accuracy (%) of each dataset is reported in the table, and the last column presents the averaged accuracy over all the datasets. Methods with/without data replay are noted using \u201cw/\u201d and \u201cw/o\u201d, respectively.", "description": "This table compares the performance of different continual learning methods on six benchmark datasets.  The \"Replay\" column indicates whether the method uses data replay or not. Each subsequent column shows the final accuracy achieved by each method on a specific dataset (CIFAR, IN-R, IN-A, CUB, OB, VTAB). The final column provides the average accuracy across all six datasets.  This allows for a comprehensive comparison of the methods, considering both their individual performance on different datasets and their overall average performance.  It highlights the relative strengths and weaknesses of each approach.", "section": "4.2 Comparisons with State-of-The-Arts"}, {"figure_path": "Cjnirz5pan/tables/tables_7_2.jpg", "caption": "Table 3: Overall ablation study on IN-A.", "description": "This table presents the ablation study results on the ImageNet-A dataset.  It shows the impact of including the slow learner, the fast learner, and both learners (SAFE) on the final and average accuracy. The baseline represents the result without any of these components. This helps to understand the contribution of each component to the overall performance improvement.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/tables/tables_7_3.jpg", "caption": "Table 4: Ablation study of aggregation.", "description": "This table presents the results of an ablation study on different aggregation strategies for combining the predictions of the slow and fast learners in the SAFE framework.  The methods compared are: simple feature concatenation, logits addition, logits maximization, and the proposed entropy-based aggregation. The table shows the final and average accuracy on the ImageNet-A dataset for each method. The results demonstrate that the entropy-based aggregation approach yields the best performance.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/tables/tables_8_1.jpg", "caption": "Table 5: Ablation study of the slow learner.", "description": "This table presents the ablation study results for the slow learner component of the SAFE framework.  It shows the impact on the final and average accuracy metrics when different variations of the slow learner are used.  The baseline represents the performance without the slow learner. The other rows show the results of adding Feature Alignment (FA), Logits Alignment (LA), Second-order Statistics Alignment (SSA), and the proposed Slow Learner method (Baseline + Lslow). The last row shows a significant improvement in accuracy, highlighting the effectiveness of the slow learner component.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/tables/tables_8_2.jpg", "caption": "Table 6: Ablation study of the fast learner.", "description": "This table presents the results of ablation experiments conducted on the fast learner component of the SAFE framework. It shows the impact of using different loss functions (Ls\u2194f, Lcos) on the model's performance (final and average accuracy) on a specific dataset, by comparing a baseline against different configurations.  The results highlight the importance of using both Ls\u2194f and Lcos for optimal performance.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/tables/tables_15_1.jpg", "caption": "Table 2: Performance comparisons on six class-incremental learning datasets. The final accuracy (%) of each dataset is reported in the table, and the last column presents the averaged accuracy over all the datasets. Methods with/without data replay are noted using \u201cw/\u201d and \u201cw/o\u201d, respectively.", "description": "This table presents a comparison of different continual learning methods across six datasets.  It shows the final accuracy achieved by each method on each dataset, as well as the average accuracy across all datasets.  The table also indicates whether each method used data replay or not.", "section": "4.2 Comparisons with State-of-The-Arts"}, {"figure_path": "Cjnirz5pan/tables/tables_16_1.jpg", "caption": "Table 8: Ablation of \u03bbcos on the fast learner.", "description": "This ablation study investigates the effect of the hyperparameter \u03bbcos on the performance of the fast learner.  The table shows that varying \u03bbcos impacts the final accuracy of the fast learner on the ImageNet-A dataset, with the optimal value appearing to be around 50.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/tables/tables_16_2.jpg", "caption": "Table 9: Ablation of \u03b3 on the aggregated model.", "description": "This table shows the ablation study of the hyperparameter \u03b3 used in the entropy-based aggregation of the slow and fast learners' predictions in the SAFE framework. The results demonstrate the impact of different values of \u03b3 on the final accuracy of the model on the ImageNet-A dataset.  The optimal value of \u03b3 = 1 yields the best overall performance, which is highlighted in bold.", "section": "4.3 Ablation Study"}, {"figure_path": "Cjnirz5pan/tables/tables_16_3.jpg", "caption": "Table 10: Ablation of the teacher model for the fast learner.", "description": "This table presents the ablation study of different teacher models used for guiding the fast learner in the SAFE framework.  It compares the final and average accuracy results achieved when using no teacher, the pre-trained model (PTM), the fast learner from the previous session (t-1), and the slow learner as the teacher.  The results demonstrate the superior performance of the slow learner as a teacher model.", "section": "4.3 Ablation Study"}]