[{"figure_path": "hiwHaqFXGi/tables/tables_6_1.jpg", "caption": "Table 1: Experiment results for node classification. Micro-F1 score is reported for PPI, and accuracy for other datasets. The best unsupervised method scores in each dataset are highlighted in bold.", "description": "This table presents the performance comparison of different node classification methods on four datasets: Cora, Citeseer, Pubmed, and PPI.  The methods are categorized into supervised, contrastive, and generative approaches.  The table shows the micro-F1 score (for PPI) and accuracy (for other datasets) for each method, highlighting the best-performing unsupervised method for each dataset in bold.  This allows for a direct comparison of DiGGR's performance against state-of-the-art techniques in unsupervised node classification.", "section": "4.1 Node Classification"}, {"figure_path": "hiwHaqFXGi/tables/tables_7_1.jpg", "caption": "Table 2: Experiment results in unsupervised representation learning for graph classification. We report accuracy (%) for all datasets. The optimal outcomes for methods, excluding supervised approaches (GIN and DiffPool), on each dataset are emphasized in bold.", "description": "This table presents the results of unsupervised representation learning for graph classification using various methods.  The accuracy of each method on seven different datasets is shown, with the best performing method (excluding supervised methods) highlighted in bold.  It demonstrates the performance of DiGGR in comparison to other techniques.", "section": "4 Experiments"}, {"figure_path": "hiwHaqFXGi/tables/tables_8_1.jpg", "caption": "Table 3: The NMI between the latent factors extracted by DiGGR and Non-probabilistic factor learning method across various datasets, and its performance improvement compared to GraphMAE, are examined. A lower NMI indicates a more pronounced disentanglement between factor-specific graphs, resulting in a greater performance enhancement.", "description": "This table presents the normalized mutual information (NMI) between the latent factors learned by DiGGR and a non-probabilistic factor learning method for several datasets.  It also shows the accuracy gain achieved by DiGGR compared to GraphMAE. Lower NMI values indicate better disentanglement of factors, leading to improved performance.  The results demonstrate that DiGGR's disentanglement strategy improves performance.", "section": "4.3 Exploratory Studies"}, {"figure_path": "hiwHaqFXGi/tables/tables_12_1.jpg", "caption": "Table 4: The average accuracy of datasets is calculated through 5 random initialization tests when using different representations.", "description": "This table presents the average accuracy results for node classification across four datasets (Cora, IMDB-MULTI, Citeseer, PROTEINS) using different combinations of node-level (Hd) and graph-level (Hg) representations.  The results are obtained by averaging across five random initialization runs. The best performance is achieved by using both Hd and Hg.  The variations in accuracy highlight the relative importance of node vs. graph-level features for the different datasets and the overall task.", "section": "A.1.2 Representation for downstream tasks"}, {"figure_path": "hiwHaqFXGi/tables/tables_13_1.jpg", "caption": "Table 5: Statistics for node classification datasets.", "description": "This table presents the statistics of four node-level classification datasets used in the paper's experiments.  For each dataset, it shows the number of nodes, features, edges, and classes. Additionally, it lists the hyperparameters used for the experiments on each dataset, including the mask rate, hidden size, maximum number of epochs, the mixing coefficients (\u03bbd; \u03bbg; \u03bbz), the learning rate, and the number of latent factors.", "section": "4.1 Node Classification"}, {"figure_path": "hiwHaqFXGi/tables/tables_14_1.jpg", "caption": "Table 6: Statistics for graph classification datasets.", "description": "This table provides a detailed overview of the characteristics of seven different datasets used for graph classification experiments. It includes the average number of nodes per graph, the number of features describing each node, the total number of graphs in the dataset, the number of classes in the dataset, and hyperparameters specific to the graph classification task, such as the mask rate, hidden layer size, number of epochs, learning rate, and other parameters relevant to the training process.  These hyperparameters were adjusted to optimize performance for each dataset.", "section": "4.2 Graph Classification"}]