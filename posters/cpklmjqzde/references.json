{"references": [{"fullname_first_author": "Mohsen Bayati", "paper_title": "The dynamics of message passing on dense graphs, with applications to compressed sensing", "publication_date": "2011-02-01", "reason": "This paper establishes the theoretical foundation of Approximate Message Passing (AMP) and its state evolution analysis, which are crucial for understanding the convergence and optimality guarantees of AMP-based algorithms and their unrolled neural network counterparts."}, {"fullname_first_author": "David L. Donoho", "paper_title": "Message-passing algorithms for compressed sensing", "publication_date": "2009-01-01", "reason": "This foundational paper introduces the AMP algorithm for compressed sensing, providing a computationally efficient alternative to traditional Bayesian inference methods and inspiring the unrolled AMP architecture examined in the current work."}, {"fullname_first_author": "Michael Celentano", "paper_title": "The estimation error of general first order methods", "publication_date": "2020-01-01", "reason": "This paper proves the optimality of AMP among general first-order methods for a wide range of inference tasks in the high-dimensional limit, providing strong theoretical justification for the focus on AMP in the current work."}, {"fullname_first_author": "Mark Borgerding", "paper_title": "AMP-inspired deep networks for sparse linear inverse problems", "publication_date": "2017-01-01", "reason": "This paper pioneers the approach of unrolling AMP algorithms into deep neural networks, which is the basis for the unrolled architecture analyzed in the current work.  It demonstrates empirically the effectiveness of this approach."}, {"fullname_first_author": "Andrea Montanari", "paper_title": "Estimation of low-rank matrices via approximate message passing", "publication_date": "2021-01-01", "reason": "This paper extends the theoretical analysis of AMP to the problem of low-rank matrix estimation, a problem closely related to compressed sensing that is also examined in the current paper. It provides crucial context and theoretical results."}]}