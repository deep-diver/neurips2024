[{"figure_path": "os14qXhy55/figures/figures_1_1.jpg", "caption": "Figure 1: Scale difference of various categories and octree representation. (a) compares the average space occupied by different object types, indicating varying granularities needed for different semantic regions. (b) demonstrates the advantage of octree representations, enabling specific granularities for different objects and even parts of objects, reducing computational overhead while retaining spatial information.", "description": "This figure illustrates the motivation behind using octrees for 3D occupancy prediction.  Subfigure (a) shows the varying sizes of objects in a typical scene, highlighting the inefficiency of using a uniform grid representation. Subfigure (b) demonstrates how an octree adapts its resolution to different object scales, thus capturing details effectively with less computation.", "section": "1 Introduction"}, {"figure_path": "os14qXhy55/figures/figures_3_1.jpg", "caption": "Figure 2: Overall framework of OctreeOcc. From multi-view images, we extract multi-scale features using an image backbone. The initial octree structure is derived from image segmentation priors, transforming dense queries into octree queries. The octree encoder refines these queries and rectifies the octree structure. Finally, we decode the octree queries to obtain occupancy predictions. The diagram of the Iterative Structure Rectification module shows the octree query and mask in 2D (quadtree) form for better visualization.", "description": "This figure illustrates the overall framework of the OctreeOcc model. It starts by extracting multi-scale features from multi-view images using a backbone network.  A semantic-guided octree initialization module leverages image segmentation to create an initial octree structure. This structure is then used to convert dense voxel queries into sparse octree queries. An octree encoder processes these queries using temporal self-attention and image cross-attention to refine the queries and iteratively rectify the octree structure via an iterative structure rectification module. Finally, an octree decoder generates the occupancy prediction from the refined octree queries. A simplified 2D representation (quadtree) is used to visualize the iterative structure rectification process.", "section": "3 Methodology"}, {"figure_path": "os14qXhy55/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of octree structure rectification. The left figure shows the initially predicted octree structure, while the right figure displays the structure after rectification. It's evident that the rectification module improves the consistency of the octree structure with the object's shape.", "description": "This figure demonstrates the improvement in octree structure prediction after applying the Iterative Structure Rectification module. The left side shows the initial, less accurate prediction, while the right side displays a refined structure that better aligns with the shapes of the objects in the scene. The rectification module enhances the accuracy and consistency of the octree representation.", "section": "3.5 Octree Encoder"}, {"figure_path": "os14qXhy55/figures/figures_9_1.jpg", "caption": "Figure 4: Qualitative results on Occ3D-nuScenes val set, where the resolution of the voxel predictions is 200\u00d7200\u00d716.", "description": "This figure shows a qualitative comparison of occupancy prediction results from different methods on the Occ3D-nuScenes validation set.  The predictions are visualized as 3D point clouds colored by semantic class, and are compared to the ground truth.  The resolution of the voxel predictions is 200x200x16.  The figure highlights the improvements in accuracy and detail provided by the proposed OctreeOcc method compared to existing methods like PanoOcc and FB-OCC.", "section": "4.4 Results"}, {"figure_path": "os14qXhy55/figures/figures_15_1.jpg", "caption": "Figure 5: More visualization on Occ3D-nuScenes validation set. The first row displays input multi-view images, while the second row showcases the occupancy prediction results of PanoOcc(8), FBOCC(3), our methods, and the ground truth.", "description": "This figure compares the occupancy prediction results of three different methods (PanoOcc, FB-OCC, and OctreeOcc) with the ground truth. The first row shows the input multi-view images used for prediction. The second row displays the occupancy predictions from each method, visually demonstrating the differences in their performance.  Each method's prediction is presented alongside the ground truth for direct comparison and evaluation. Circular highlights are used to point out the differences and highlight specific areas of interest for better visualization.", "section": "4.4 Results"}, {"figure_path": "os14qXhy55/figures/figures_16_1.jpg", "caption": "Figure 6: Visualization of octree structure. The first row displays input multi-view images, while the second and third rows showcase the occupancy prediction results and the corresponding octree structure prediction results.", "description": "This figure visualizes the OctreeOcc model's output.  The top row shows the input multi-view images used by the model. The second row displays the final occupancy prediction generated by the model in a 3D voxel grid.  The third row presents a visualization of the octree structure created during the prediction process.  Different colors in the occupancy prediction represent different semantic classes, while the different gray levels in the octree structure represent different levels of detail in the octree, showing the varying granularities used to represent different parts of the scene.", "section": "3. Methodology"}]