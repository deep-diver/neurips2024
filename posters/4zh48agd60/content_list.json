[{"type": "text", "text": "Active, anytime-valid risk controlling prediction sets ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Ziyu Xu\u2217 Department of Statistics and Data Science Carnegie Mellon University xzy@cmu.edu ", "page_idx": 0}, {"type": "text", "text": "Nikos Karampatziakis Microsoft ", "page_idx": 0}, {"type": "text", "text": "Paul Mineiro Microsoft pmineiro@microsoft.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Rigorously establishing the safety of black-box machine learning models concerning critical risk measures is important for providing guarantees about model behavior. Recently, Bates et. al. $(\\mathbf{J}\\mathbf{A}\\mathbf{C}\\mathbf{M}\\ ^{*}24)$ introduced the notion of a risk controlling prediction set (RCPS) for producing prediction sets that are statistically guaranteed low risk from machine learning models. Our method extends this notion to the sequential setting, where we provide guarantees even when the data is collected adaptively, and ensures that the risk guarantee is anytime-valid, i.e., simultaneously holds at all time steps. Further, we propose a framework for constructing RCPSes for active labeling, i.e., allowing one to use a labeling policy that chooses whether to query the true label for each received data point and ensures that the expected proportion of data points whose labels are queried are below a predetermined label budget. We also describe how to use predictors (i.e., the machine learning model for which we provide risk control guarantees) to further improve the utility of our RCPSes by estimating the expected risk conditioned on the covariates. We characterize the optimal choices of label policy and predictor under a fixed label budget and show a regret result that relates the estimation error of the optimal labeling policy and predictor to the wealth process that underlies our RCPSes. Lastly, we present practical ways of formulating label policies and empirically show that our label policies use fewer labels to reach higher utility than naive baseline labeling strategies on both simulations and real data. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "One of the core problems of modern deep learning systems is the lack of rigorous statistical guarantees one can ensure about the performance of a model in practice. In particular, we are interested in ensuring the safety of a deep learning system, that is, it does not incur undue risk while optimizing for some other objective of interest. This type of guarantee arises in many applications. For example, a deep learning based medical imaging segmentation system that detects lesions [37, 10, 30] should guarantee that it does not miss most of the lesion tissue while remaining precise and minimizing the total amount of tissue that is highlighted. Hence, it is crucial to provide a statistical guarantee about the \u201csafety\u201d of any machine learning system to be deployed. Bates et al. [4] introduced the notion of a risk controlling prediction set as a method to derive such guarantees on top of the outputs of a wide range of black-box models. They consider the setting where all the calibration data are available as a single dataset before deployment and the model only needs to be calibrated once, i.e., the batch setting. However, this is often unrealistic in a production setup when we have no data concerning the performance of a model before we deploy it, and we wish to update our calibration each time a new data point (or group of data points) arrives. Consequently, it is natural to calibrate the machine learning model in an online fashion while receiving new data sequentially. Unfortunately, methods for obtaining statistical guarantees in the batch setting of Bates et al. [4] do not ensure risk control guarantees in the sequential regime. Further, the consideration of using data from production also brings up the concern that this data is often unlabeled, and one must expend resources (either paying experts or utilizing a more powerful model) to label these data points. Hence, we also consider an active setting in which we see the covariate $X$ and choose whether to query the true label $Y$ . Consider the following scenarios where an active and sequential method is relevant. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "\u2022 Reduce query cost in medical imaging. As discussed prior, a medical imaging system that outputs scores for for each pixel of image that determines whether there is a lesion or not would want to utilize labels given by medical experts for unlabeled images from new patients. Since the cost of asking experts to label these images is quite high, one would want to query experts efficiently, and only on data that would be most helpful for reducing the number of highlighted pixels. ", "page_idx": 1}, {"type": "text", "text": "\u2022 Domain adaptation for behavior prediction. One reason we would want online calibration in a production setting is that we may have much different distribution of data that we do not have access to before deployment. For example, during a navigation task for a robot, we may want to predict the actions of other agents and avoid colliding into them when travelling between two points [20]. Since agents may behave differently in every environment, it makes sense to collect the behavior data in the test environment and update the behavior prediction in an online fashion to get accurate predictions calibrated for specifically the test environment.   \n\u2022 Safe outputs for large language models (LLMs). One of the goals with large language models is to ensure their responses are not harmful in some fashion (e.g., factually wrong, toxic, etc.). One can view this as outputting a prediction set for the binary label set of $Y\\in\\{{\\mathrm{harmful}}$ , not harmful}. Many pipelines for modern LLMs include some form of a safety classifier, which scores the risk level of an output, and determines whether it should be output to the user or not [22, 15], or a default backup response should be used instead. One would want to label production data acquired from user interaction with the LLM and used to calibrate cutoff for the scores that are considered low enough for the response to be allowed through. ", "page_idx": 1}, {"type": "text", "text": "Example: image classification Let us assume we wish to classify an image $X\\in\\mathcal{X}$ , and we have access to a probabilistic classifier $s:\\mathcal{X}\\to\\Delta^{\\mathcal{Y}}$ where $\\Delta^{y}$ is the probability simplex over distributions over all possible classes, $\\boldsymbol{\\wp}$ . Let $s^{y}(x)$ denote the probability of class $y$ in the distribution $s(x)$ . Based on the probabilities from $s(X)$ , we can define $C(X,{\\dot{\\beta}})$ to have the labels with the largest probabilities that sum to $\\beta\\in[0,1]$ in the following fashion: ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\gamma(X,\\beta):=\\operatorname*{max}\\left\\{\\gamma\\in[0,1]:\\displaystyle\\sum_{y\\in\\mathcal{Y}}\\mathbf{1}\\left\\{s^{y}(X)\\geq\\gamma\\right\\}\\cdot s^{y}(X)\\geq\\beta\\right\\},}\\\\ &{C(X,\\beta):=\\left\\{y\\in\\mathcal{Y}:s^{y}(X)\\geq\\gamma(X,\\beta)\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Now, we can define the miscoverage error of our label set $C(X,{\\boldsymbol{\\beta}})$ as follows: ", "page_idx": 1}, {"type": "equation", "text": "$$\nr(X,Y,\\beta):={\\bf1}\\left\\{Y\\not\\in C(X,\\beta)\\right\\}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "Now, assume that $(X,Y)\\sim\\mathcal{P}^{*}$ , i.e., the images and class are jointly drawn from a fixed distribution. We want to find a choice of $\\beta$ such that $\\rho(\\beta)\\,\\stackrel{\\cdot}{:}=\\mathbb{E}[r(X,Y,\\beta)]$ is guaranteed to be at most $\\theta\\in[0,1]$ , i.e., the expected miscoverage over the population of images and labels is at most $\\theta$ . ", "page_idx": 1}, {"type": "text", "text": "In the above image classification example, we do not simply wish to find any $\\beta$ that ensures $\\rho(\\beta)\\leq\\theta$ \u2014 setting $\\beta=1$ would trivially ensure this guarantee for any $\\theta\\in[0,1]$ . We also want to minimize the size of our uncertainty set $C(X,{\\boldsymbol{\\beta}})$ . To present this formulation in more general terms, we are interested in solving the following problem for a fixed level of risk control $\\theta\\in[0,1]$ : ", "page_idx": 1}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\beta}g(\\beta)\\qquad\\mathrm{subject}\\tan\\rho(\\beta)\\leq\\theta.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where $g$ is the utility of our choice. We make the following natural assumption about $r,\\,\\rho$ , and $g$ . Assumption 1. $g$ and $\\rho$ are monotonically decreasing w.r.t. $\\beta$ and we assume $\\rho(1)=0$ . In addition, $\\rho$ is right-continuous. ", "page_idx": 1}, {"type": "text", "text": "Our image classification example has an expected risk and utility that satisfy the respective monotonicity assumptions, and such risk measures arise in many applications such as natural language question answering [27], image segmentation [1], and behavior control for robotics [21, 16]. Assumption 1 implies that maximizing $g(\\beta)$ is equivalent to minimizing $\\beta$ , as $g$ is decreasing in $\\beta$ , and the right-continuity of $\\rho$ allows us to define the notion of an optimal calibration parameter that is the solution to (2): ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\beta^{*}:=\\operatorname*{min}\\,\\big\\{\\beta\\in[0,1]:\\rho(\\beta)\\leq\\theta\\big\\}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Our goal in this paper is to derive a sequence of upper bounds on $\\beta^{*}$ that quickly approach the true $\\beta^{*}$ but are \u201canytime safe\u201d in the sense that they are always greater the $\\beta^{*}$ and induce risk under $\\theta$ , i.e., $\\beta\\geq\\beta^{*}$ implies that $\\rho(\\beta)\\,\\leq\\,\\rho(\\beta^{*})\\,\\leq\\,\\theta$ . Since we are guaranteed by Assumption 1 that $\\rho(1)=0\\leq\\theta$ , we always have a safe option of $\\beta=1$ to start with as our upper bound. ", "page_idx": 2}, {"type": "text", "text": "Our contributions. The primary contributions of this paper are as follows. ", "page_idx": 2}, {"type": "text", "text": "1. Extensions of RCPS to anytime-valid and active settings. We extend the notion of RCPS in two ways: (1) to enable anytime-valid RCPS which allows one to refine the set as one receives more samples in a stream while maintaining risk control throughout the entire stream, and (2) to define an RCPS that is valid under active learning, i.e., enable us to decide whether to label each example based on the covariates. We also define a way for incorporating risk predictions from the machine learning model to decrease variance further and reduce the number of labels needed to estimate $\\beta^{*}$ . We formulate this betting framework in Section 2. ", "page_idx": 2}, {"type": "text", "text": "2. Deriving powerful labeling policies and predictors. We show in Section 3 that our active, anytimevalid RCPS methods are practically powerful and converge to $\\beta^{*}$ in a label efficient manner by also deriving formulations for the optimal labeling policy and predictors under the standard log-optimality criterion that is used for evaluating anytime-valid methods [13, 35, 19]. We derive explicit regret bounds w.r.t. a lower bound on the growth rate on the wealth processes that underlie our RCPS methods. These bounds characterize how the deviation of any labeling policy and predictor from the log-optimal policy and predictor affect the growth rate of our wealth processes (and hence the earliest time at which a candidate $\\beta$ is removed from consideration as $\\beta^{*}$ ). In Section 4 we also show that machine learning model based estimators of the optimal policy and predictors are label efficient in practice through experiments. ", "page_idx": 2}, {"type": "text", "text": "Related work. Most relevant to this paper is the recent work from Zrnic and Cand\\`es [38] that provides a rigorous framework for statistical inference with active labeling policies, and leverages machine learning predictions through prediction-powered inference [2]. However, their focus is on M-estimation and deriving asymptotic, martingale central-limit theorem based results for a parameter. On the other hand, we provide finite sample anytime-valid results that are also valid at adaptive stopping times that directly utilize e-process [29] construction of sequential tests. Further, our goal is to provide a time-uniform statistical guarantee in the RCPS framework rather than directly estimating a parameter with adaptively collected data. We discuss additional related work in depth in Section 5. ", "page_idx": 2}, {"type": "text", "text": "2 Anytime-valid risk control through betting ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We use $(X_{t})_{t\\in\\mathbb{I}}$ to denote a sequence that is indexed by $t$ with index set I. If the index set or indexing variable is apparent in context, we drop it for brevity. In our setup, we assume that our data points arrive in a stream $(X_{1},Y_{1}),(X_{2},Y_{2}),.\\,.\\,.$ . that proceeds indefinitely. Let $\\left(\\mathcal{F}_{t}\\right)$ be the canonical flitration on the data, i.e., $\\mathcal{F}_{t}:=\\sigma(\\{(X_{i},Y_{i})\\}_{i\\leq[t]})$ is the sigma-algebra over the first $t$ points. Recall that we assumed $(X_{t},Y_{t})\\sim\\mathcal{P}^{*}$ are i.i.d. draws for each $t\\in\\mathbb{N}:=\\{1,2,3,\\dots\\}$ , and want to control the risk $\\rho(\\beta)=\\mathbb{E}_{(X,Y)\\sim{\\mathcal{P}}^{*}}[r(X,Y,\\beta)]$ where the expectation is take only over $(X,Y)$ . We illustrate an overview of our methodology (which we describe in the sequel) in Figure 1. ", "page_idx": 2}, {"type": "text", "text": "We desire to output a sequence of calibration parameters, $(\\widehat{\\beta}_{t})$ , such that every $\\beta_{t}$ is \u201csafe\u201d, i.e., ensures that the resulting risk of the output is provably controlled under a fixed level. ", "page_idx": 2}, {"type": "text", "text": "Definition 1. A sequence of calibration parameters $(\\widehat{\\beta}_{t})$ is said to have $(\\theta,\\alpha)$ -anytime-valid risk control if it possesses the following property: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\rho({\\widehat{\\beta}}_{t})\\leq\\theta\\,{\\mathrm{for~all~}}t\\in\\mathbb{N})\\geq1-\\alpha.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "image", "img_path": "4ZH48aGD60/tmp/ea7c87f040e7a4b2fd1fe687d917c5aa3e17641c4c9f985b510386a856d89efc.jpg", "img_caption": ["Figure 1: Diagram of the active labeling setup for ensuring anytime-valid risk control. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "We name this as \u201canytime-valid\u201d since the risk control condition (i.e., $\\rho(\\widehat{\\beta}_{t})\\leq\\theta)$ is guaranteed to hold simultaneously at all $t\\in\\mathbb{N}$ . Hence, this allows for the user to process a continuous stream of data and control the probability that a $\\widehat{\\beta}_{t}$ is chosen at any time $t$ that is \u201cunsafe\u201d, i.e., $\\rho(\\widehat{\\beta}_{t})>\\theta$ . We build on recent work that develops a framework for hypothesis testing and parameter estimation with sequential data collection based on martingales and gambling with virtual wealth known as testing by betting [31]. In this framework, the goal is to design an $e$ -process, $\\left(E_{t}\\right)$ , w.r.t. a null hypothesis $H_{0}$ , which satisfies the following properties when true: ", "page_idx": 3}, {"type": "text", "text": "Definition 2. An e-process, $(E_{t})_{t\\in\\mathbb{N}_{0}}$ , w.r.t. a hypothesis $H_{0}$ , is a nonnegative process for which there exists another nonnegative process, $(M_{t})_{t\\in\\mathbb{N}_{0}}$ s.t. the following is true when $H_{0}$ is true: (1) $\\mathbb{E}[M_{0}]\\leq1$ , (2) $M_{t}\\geq E_{t}$ for all $t\\in\\mathbb{N}$ almost surely and (3) $\\mathbb{E}[M_{t}\\mid\\mathcal{F}_{t-1}]\\leq M_{t-1}$ for all $t\\in\\mathbb{N}.$ ,, i.e., $\\left(M_{t}\\right)$ is a supermartingale. ", "page_idx": 3}, {"type": "text", "text": "E-processes will be the main tool we use to construct $(\\widehat{\\beta}_{t})$ . We leverage the probabilistic bound on e-processes provided by Ville\u2019s inequality to prove our anytime-valid risk control guarantee. Fact 1 (Ville\u2019s inequality [34]). For any e-process, $\\left(E_{t}\\right)$ , with initial expectation bounded by 1, i.e., $\\mathbb{E}[E_{0}]\\leq1$ , we have that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left({\\mathrm{exists}}\\,t\\in\\mathbb{N}:M_{t}\\geq\\alpha^{-1}\\right)\\leq\\alpha\\,{\\mathrm{for}}\\,{\\mathrm{each}}\\,\\alpha\\in[0,1].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In this paper, all our e-processes will also be nonnegative supermartingales, so we denote them as $\\left(M_{t}\\right)$ . Now, we will specify the null hypotheses in our risk control setting. For each $\\beta\\in[0,1]$ , we test the null hypothesis $H_{0}^{\\beta}:\\rho(\\beta)\\geq\\theta$ for a fixed risk control level $\\theta\\in[0,1]$ . Note that we include equality to $\\theta$ in the null hypothesis since we do not wish to reject $H_{0}^{\\beta^{*}}$ . Let $\\{(M_{t}(\\beta))\\}_{\\beta\\in[0,1]}$ be a family of e-processes where $\\left(M_{t}(\\beta)\\right)$ is an e-process for $H_{0}^{\\beta}$ . Then, we can derive ${\\widehat{\\beta}}_{t}$ for each $t\\in\\mathbb{N}$ as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\widehat{\\beta}_{t}:=\\operatorname*{min}\\,\\{\\beta\\in[0,1]:M_{t}(\\beta^{\\prime})\\geq1/\\alpha\\;\\mathrm{for}\\;\\mathrm{all}\\;\\beta^{\\prime}>\\beta\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Theorem 1. The sequence of estimates $(\\widehat{\\beta}_{t})$ in (4) satisfies the anytime-valid risk control guarantee (3), i.e., $\\mathbb{P}(\\rho(\\widehat{\\beta}_{t})\\leq\\theta$ for all $t\\in\\mathbb{N})\\geq1-\\alpha.$ . ", "page_idx": 3}, {"type": "text", "text": "Proof. First, we note that ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\{\\exists t\\in\\mathbb{N}:\\rho(\\widehat{\\beta}_{t})>\\theta\\}\\Leftrightarrow\\{\\exists t\\in\\mathbb{N}:\\widehat{\\beta}_{t}<\\beta^{*}\\}\\Rightarrow\\{\\exists t\\in\\mathbb{N}:M_{t}(\\beta^{*})\\geq1/\\alpha\\}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Since $H_{0}^{\\beta^{*}}$ is always true by definition of $\\beta^{*}$ , we get that $(M_{t}(\\beta^{*}))$ is an e-process by Proposition 1. Thus, by applying Ville\u2019s inequality, we get that: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{P}(\\exists t\\in\\mathbb{N}:\\rho(\\widehat{\\beta}_{t})>\\theta)\\leq\\mathbb{P}\\left(\\exists t\\in\\mathbb{N}:M_{t}(\\beta^{*})\\geq1/\\alpha\\right)\\leq\\alpha.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Now, we will present a concrete example of an e-process. Denote $R_{t}(\\beta):=r(X_{t},Y_{t},\\beta)$ . We test $H_{0}^{\\beta}$ using the betting e-process from Waudby-Smith and Ramdas [35]: ", "page_idx": 4}, {"type": "equation", "text": "$$\nM_{t}(\\beta)=\\prod_{i=1}^{t}\\left(1+\\lambda_{i}\\left(\\theta-R_{i}(\\beta)\\right)\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\left(\\lambda_{t}\\right)$ is predictable w.r.t. $(\\mathcal{F}_{t})$ , i.e., $\\lambda_{t}$ can be determined by $\\mathcal{F}_{t-1}$ for each $t~\\in~\\mathbb{N}$ , and $\\lambda_{t}\\in[0,(1-\\theta\\bar{)}^{-1}]$ . ", "page_idx": 4}, {"type": "text", "text": "Proposition 1. $\\left[M_{t}(\\beta)\\right)$ in (5) is an e-process for all $\\beta$ where $H_{0}^{\\beta}$ is true, i.e., where $\\rho(\\beta)\\geq\\theta$ . ", "page_idx": 4}, {"type": "text", "text": "Proof. We note that $\\left(M_{t}(\\beta)\\right)$ is nonnegative by the support of $\\lambda_{t}$ being limited, i.e., ", "page_idx": 4}, {"type": "equation", "text": "$$\n1+\\lambda_{t}(\\theta-r(X_{t},Y_{t},\\beta))\\geq1+\\lambda_{t}(\\theta-1)\\geq0.\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Now, we will also show that $\\left(M_{t}(\\beta)\\right)$ is a supermartingale when $H_{0}^{\\beta}$ is true. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[M_{t}(\\beta)\\mid\\mathcal{F}_{t-1}]=\\mathbb{E}[1+\\lambda_{t}(\\theta-R_{t}(\\beta))\\mid\\mathcal{F}_{t-1}]\\cdot M_{t-1}(\\beta)}\\\\ &{\\qquad\\qquad\\qquad=(1+\\lambda_{t}(\\theta-\\mathbb{E}[R_{t}(\\beta)\\mid\\mathcal{F}_{t-1}]))\\cdot M_{t-1}(\\beta)\\le M_{t-1}(\\beta).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The second equality is because $\\lambda_{t}$ is measurable w.r.t. $\\mathcal{F}_{t-1}$ and the last inequality is by $R_{t}(\\beta)$ being independent of $\\mathcal{F}_{t-1}$ and $\\mathbb{E}[R_{t}(\\beta)]\\leq\\theta$ being true under $H_{0}^{\\beta}$ . Thus, we have our desired result. ", "page_idx": 4}, {"type": "text", "text": "Now, we have a concrete way to derive $(\\widehat{\\beta}_{t})$ that ensures the risk $\\rho(\\widehat{\\beta}_{t})$ , is controlled at every time step $t\\in\\mathbb{N}$ . However, this requires one to label every example that arrives, i.e., it requires access to entire stream of labels $\\left({{{Y}_{t}}}\\right)$ . We will now derive a more label efficient way for constructing $(\\widehat{\\beta}_{t})$ . Remark 1. Ramdas et al. [28] show that e-processes of the form in (5) characterize the set of admissible e-processes (and hence anytime-valid sequential tests) for testing the mean of bounded random variables. Hence, it is an optimal choice of e-process for our setting, and have been shown to perform better both theoretically and empirically than other sequential tests for bounded random variables (e.g., Hoeffding and empirical-Bernstein based tests [35]). ", "page_idx": 4}, {"type": "text", "text": "2.1 Active sampling for risk control ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Now, we describe active learning for risk control, where an algorithm sees $X_{t}$ decides whether a label, for the current point, $Y_{t}$ , should be queried or not. At each step $t\\in\\mathbb{N}$ , the algorithm produces a label policy $q_{t}:\\mathcal{X}\\to[q_{t}^{\\operatorname*{min}},1]$ based on the observed data (i.e., $\\mathcal{F}_{t-1})$ . It then queries the label, $Y_{t}$ , with probability $q_{t}(X_{t})$ that is lower bounded by a constant, $q_{t}^{\\operatorname*{min}}$ . Let $L_{t}$ be the indicator random variable for whether the tth label is queried, i.e., $L_{t}\\sim\\operatorname{Bern}(q_{t}(X_{t}))$ . ", "page_idx": 4}, {"type": "text", "text": "To produce a label efficient method, one would hope to label the most \u201cimpactful\u201d data points that result in the largest growth of $M_{t}(\\beta)$ for choices of $\\beta\\in(0,\\widehat{\\beta}_{t})$ , i.e. that are still in consideration for the next $\\widehat{\\beta}_{t+1}$ . For the labeling policies we consider in this paper, we let $q_{t}^{\\mathrm{min}}\\,\\in\\,[0,1]$ be a lower bound  on the labeling probability, i.e., $q_{t}(X_{t})\\geq q_{t}^{\\mathrm{min}}$ almost surely. Thus, we can derive the following e-process for any sequence of labeling policies $\\left(q_{t}\\right)$ . ", "page_idx": 4}, {"type": "equation", "text": "$$\nM_{t}(\\beta):=\\prod_{i=1}^{t}\\left(1+\\lambda_{i}\\left(\\theta-\\frac{L_{i}}{q_{i}(X_{i})}\\cdot R_{i}(\\beta)\\right)\\right).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Proposition 2. Let $\\left(q_{t}\\right)$ be a sequence of labeling policies, and $\\left(\\lambda_{t}\\right)$ be a sequence of betting parameters, and let both sequences be predictable w.r.t. $(\\mathcal{F}_{t})$ . Then, $\\left(M_{t}(\\beta)\\right)$ in (6) is an $e$ -process for all $\\beta$ where $H_{0}^{\\beta}$ is true, i.e., where $\\rho(\\beta)\\geq\\theta$ . ", "page_idx": 4}, {"type": "text", "text": "Proof. The proof of this is similar to that of inverse propensity-weighted e-processes derived in Waudby-Smith et al. [36]. We know that $\\left(M_{t}(\\beta)\\right)$ is nonnegative by the support of $\\lambda_{t}$ being limited: ", "page_idx": 5}, {"type": "equation", "text": "$$\n1+\\lambda_{t}\\left(\\theta-\\frac{L_{t}}{q_{t}(X_{t})}\\cdot R_{t}(\\beta)\\right)\\geq1+\\lambda_{t}\\left(\\theta-(q_{t}^{\\mathrm{min}})^{-1}\\right)\\geq0,\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the first inequality is by $R_{t}(\\beta)\\leq1$ and $q_{t}(X_{t})\\,\\geq\\,q_{t}^{\\mathrm{min}}$ , and the second inequality is by $\\lambda_{t}\\leq((q_{t}^{\\mathrm{min}})^{-1}-\\dot{\\theta})^{-1}$ . Now, we will also show that $\\left(M_{t}(\\beta)\\right)$ is a supermartingale. We first show the following upper bound: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\frac{L_{t}}{q_{t}(X_{t})}\\cdot R_{t}(\\beta)\\mid\\mathcal{F}_{t-1}\\right]=\\mathbb{E}\\left[\\frac{\\mathbb{E}[L_{t}\\mid X_{t},\\mathcal{F}_{t-1}]}{q_{t}(X_{t})}R_{t}(\\beta)\\mid\\mathcal{F}_{t-1}\\right]=\\mathbb{E}[R_{t}(\\beta)\\mid\\mathcal{F}_{t-1}]\\le\\theta.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The first equality is by further conditioning on $X_{t}$ , and the second equality is since $L_{t}$ is defined to be a Bernoulli random variable with parameter $q_{t}(X_{t})$ when conditioned on $X_{t}$ and $\\mathcal{F}_{t-1}$ . The last inequality is by $H_{0}^{\\beta}$ being true. Now, we have that ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathbb{E}[M_{t}(\\beta)\\mid\\mathcal{F}_{t-1}]=\\left(1+\\lambda_{t}\\left(\\theta-\\mathbb{E}\\left[\\frac{L_{t}}{q_{t}(X_{t})}R_{t}(\\beta)\\mid\\mathcal{F}_{t-1}\\right]\\right)\\right)M_{t-1}(\\beta)\\le M_{t-1}(\\beta),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the inequality is by (7). Hence, we have shown that $\\left(M_{t}(\\beta)\\right)$ is a nonnegative supermartingale, and hence also an e-process, under $H_{0}^{\\beta}$ . \u53e3 ", "page_idx": 5}, {"type": "text", "text": "Theorem 2. $(\\widehat{\\beta}_{t})$ defined w.r.t. (6) satisfies the anytime-valid risk control guarantee (3). ", "page_idx": 5}, {"type": "text", "text": "This is a result of Proposition 2 and Ville\u2019s inequality, similar to the proof of Theorem 1. Theorem 2 essentially shows that we can still design e-processes by allowing for a probabilistic label policy. ", "page_idx": 5}, {"type": "text", "text": "2.2 Variance reduction through prediction ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Often, we also have an estimate of the risk we incur, e.g., in the example given for classification, we have an estimated probability distribution over possible outcomes. As a result, we also have an empirical estimate of $\\mathbb{E}[r(X,Y,\\beta)\\mid X=x]$ for each $\\beta\\in[0,1]$ that we can use to reduce the variance of our estimate. This is similar to the usage of control variates for improving Monte Carlo estimation $[3,\\,\\S\\,\\,\\mathrm{V}.2]$ , and of predictors in the recently formulated prediction-powered inference framework [2]. Let $\\widehat{r}_{t}:\\mathcal{X}\\times[0,1]\\to[0,1]$ be an estimator of the risk incurred by parameter $\\beta$ conditional on $x\\in\\mathscr{X}$ for each time step $t\\in\\mathbb{N}$ . $\\left(\\widehat{r}_{t}\\right)$ is predictable w.r.t. $(\\mathcal{F}_{t})$ . ", "page_idx": 5}, {"type": "text", "text": "Where does $\\widehat{r}$ come from? We note that often machine learning models have some estimate ${\\hat{P}}(X)$ of the conditional distribution of $Y\\mid X$ (e.g, class probabilities, conditional diffusion models, LLMs, etc.). Thus, for any realized covariate $x$ , we can derive use $\\mathbb{E}_{Y\\sim\\hat{P}(x)}[r(X,Y,\\beta)\\mid X=x]$ from the machine learning model as our choice of $\\widehat{r}(\\boldsymbol{x},\\beta)$ . This expectation can either be calculated analytically (as we do in or classification examples in our experiments) or derived using Monte Carlo approximation (for generative models such as LLMs, one can sample from the conditional distribution). In essence, we can obtain a predictor from the very model we are calibrating. Further, we can have a sequence of $\\left(\\widehat{r}_{t}\\right)$ \u2014 we may update our predictor using new $(X_{t},Y_{t})$ pairs we receive for calibrating $(\\widehat{\\beta}_{t})$ as well. ", "page_idx": 5}, {"type": "text", "text": "Now, we define our e-process that utilizes our predictor as follows: ", "page_idx": 5}, {"type": "equation", "text": "$$\n{\\cal M}_{t}(\\beta):=\\prod_{i=1}^{t}\\left(1+\\lambda_{i}\\left(\\theta-\\widehat{r}_{i}(X_{i},\\beta)-\\frac{L_{i}}{q_{i}(X_{i})}\\cdot\\bar{R}_{i}(\\beta)\\right)\\right)\\mathrm{~where~}\\bar{R}_{t}(\\beta):=R_{t}(\\beta)-\\widehat{r}_{t}(X_{t},\\beta),\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "and we restrict $\\lambda_{t}\\in[0,((q_{t}^{\\mathrm{min}})^{-1}-\\theta)^{-1}]$ (or in other words, $q_{t}^{\\mathrm{min}}\\geq\\lambda_{t}/(1+\\lambda_{t}\\theta))$ . Note that this e-process recovers the active $\\mathbf{e}$ -process defined in (6) if we set $\\widehat{r}_{t}(\\cdot,\\beta)=0$ for all $t\\in\\mathbb{N}$ . ", "page_idx": 5}, {"type": "text", "text": "Proposition 3. $\\left(M_{t}(\\beta)\\right)$ as defined in (8) is an $e$ -process for $H_{0}^{\\beta}$ . ", "page_idx": 5}, {"type": "text", "text": "Proof. Since the restriction on $\\left(\\lambda_{t}\\right)$ ensures $M_{t}(\\beta)$ is nonnegative, to show that $\\left(M_{t}(\\beta)\\right)$ is an e-process, it is sufficient to show: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\lambda_{t}(\\theta-\\widehat{r}_{t}(X_{t},\\beta)-L_{t}\\cdot q_{t}(X_{t})^{-1}\\cdot\\bar{R}_{t}(\\beta)+)\\mid\\mathcal{F}_{t-1}]}\\\\ &{\\ =\\lambda_{t}(\\theta-\\mathbb{E}[\\widehat{r}_{t}(X_{t},\\beta)+L_{t}\\cdot q_{t}(X_{t})^{-1}\\cdot\\bar{R}_{t}(\\beta)\\mid\\mathcal{F}_{t-1}])}\\\\ &{\\ =\\lambda_{t}(\\theta-\\mathbb{E}[\\widehat{r}_{t}(X_{t},\\beta)+\\mathbb{E}[L_{t}\\cdot q_{t}(X_{t})^{-1}\\mid X_{t},\\mathcal{F}_{t-1}]\\cdot\\bar{R}_{t}(\\beta)\\mid\\mathcal{F}_{t-1}])}\\\\ &{\\ =\\lambda_{t}(\\theta-\\mathbb{E}[\\widehat{r}_{t}(X_{t},\\beta)+\\bar{R}_{t}(\\beta)\\mid\\mathcal{F}_{t-1}])=\\lambda_{t}(\\theta-\\mathbb{E}[R_{t}(\\beta)\\mid\\mathcal{F}_{t-1}])\\le0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The 3rd equality is by definition of $L_{t}$ , the last equality by the definition of $\\bar{R}_{t}$ , and the last inequality is due to $H_{0}^{\\beta}$ being true. \u53e3 ", "page_idx": 6}, {"type": "text", "text": "The role of $\\widehat{r_{t}}(X_{t},\\beta)$ is to accurately predict $R_{t}(\\beta)$ . Bad predictions can increase the variance of $\\bar{R}_{r}(\\beta)$ and  le ad to slower growth of $M_{t}(\\beta)$ , but do not compromise the risk control guarantee. On the other hand, accurate predictions, which come from pretrained models, decrease variance and improve the growth of $M_{t}(\\beta)$ . We characterize the optimal predictor (Proposition 4) and relate the accuracy of a predictor to its effect on the e-process (Theorem 3) in the next section. ", "page_idx": 6}, {"type": "text", "text": "3 Optimal labeling policies ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Since the goal of having an active labeling policy is to label fewer data points, one reasonable way of doing this is to maximize the growth rate of our e-process $\\left(M_{t}(\\beta)\\right)$ defined in (8). Define the following function, for some $\\beta\\in[0,1]$ , of a labeling policy $q$ , predictor $\\widehat{r}$ , and betting parameter $\\lambda$ where we let $L\\sim\\operatorname{Bern}(q(X))$ and $(\\bar{X overbar{,Y}})\\sim\\mathcal{P}^{*}$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{Z}^{\\beta}(q,\\widehat{r},\\lambda):=\\log\\left(1+\\lambda\\left(\\theta-\\widehat{r}(X,\\beta)-\\frac{L}{q(X)}\\bar{R}(\\beta)\\right)\\right)\\mathrm{~where~}\\bar{R}(\\beta):=r(X,Y,\\beta)-\\widehat{r}(X,\\beta).\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Define the growth rate at the tth step of $\\left(M_{t}(\\beta)\\right)$ as $\\mathbb{G}_{t}^{\\beta}:=\\mathbb{E}[G_{t}^{\\beta}(q_{t},\\widehat{r}_{t},\\lambda_{t})]$ , where we let $G_{t}^{\\beta}$ be identical to $G_{t}$ but with $X$ and $Y$ replaced with $X_{t}$ and $Y_{t}$ , respectively. It is a standard notion of power or sample efficiency for e-processes. Typically, our goal when designing an e-process based test is to maximize such a metric, i.e., we want our e-process to be log-optimal [13, 35, 19]. Log-optimality is also called the Kelly criterion in finance [18] and it is known that maximizing the growth rate of a process is equivalent to minimizing the expected time for the process to exceed a threshold, i.e., for our sequential test to reject a value of $\\beta$ , in the limit as the threshold approaches infinity [5]. Thus, in an asymptotic sense, maximizing the growth rate is equivalent to minimizing the expected time for rejection. Our goal is to maximize the growth rate while having a constraint on the number of labels we can produce. ", "page_idx": 6}, {"type": "text", "text": "Let $B\\in[0,1]$ be the constraint on our labeling budget, i.e., we label, in expectation, a $B$ fraction of all data points that we receive. To achieve both of these goals, we wish to choose $q_{t},\\widehat{r_{t}}$ , and $\\lambda_{t}$ that are the solutions to the following optimization problem: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{q,\\widehat{r},\\lambda}\\mathbb{E}_{L\\sim q(X)}[G^{\\beta}(q,\\widehat{r},\\lambda)]\\mathrm{~s.t.~}\\mathbb{E}[q(X)]\\leq B.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Since solving the above optimization problem is analytically difficult, one can instead maximize a lower bound on the expected growth [33, 26, 25]: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\widehat{G}^{\\beta}(q,\\widehat{r},\\lambda):=\\lambda\\left(\\theta-\\widehat{r}(X,\\beta)-\\frac{L}{q(X)}\\bar{R}(\\beta)\\right)-\\lambda^{2}\\left(\\theta-\\widehat{r}(X,\\beta)-\\frac{L}{q(X)}\\bar{R}(\\beta)\\right)^{2}}\\\\ {\\displaystyle\\leq G^{\\beta}(q,\\widehat{r},\\lambda),}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "which holds when $\\lambda\\in[0,(2(q^{\\mathrm{min}})^{-1}\\!-\\!2\\theta)^{-1}]$ , where $q^{\\mathrm{min}}:=\\operatorname*{inf}_{x\\in\\mathcal{X}}q(x)$ . We can further simplify We can use the lower bound in (9) to formulate the following optimization problem. ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{q,\\hat{r},\\lambda}\\mathbb{E}\\left[\\widehat{G}^{\\beta}(q,\\widehat{r},\\lambda)\\right]\\mathrm{~s.t.~}\\mathbb{E}[q(X)]\\leq B\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Let $(q^{*},r^{*},\\lambda^{*})$ be the tuple that is the solution to (10). We can analytically show what $r^{*}$ is. ", "page_idx": 6}, {"type": "text", "text": "Proposition 4. The optimal predictor $r^{*}$ in the solution to (10) is $r^{*}(x,\\beta)=\\mathbb{E}[r(X,Y,\\beta)\\mid X=x]$ for each $x\\in\\mathscr{X}$ . ", "page_idx": 6}, {"type": "text", "text": "We defer the proof to Appendix A.1. The optimal choice of $q^{*}$ has the following formulation. ", "page_idx": 7}, {"type": "text", "text": "Proposition 5. If we fix $\\widehat{r}$ and $\\lambda$ , the solution to the optimization problem in (10) is given by $q_{\\beta}^{*}$ where $q_{\\beta}^{*}(x)\\propto\\sqrt{\\mathbb{E}[\\bar{R}(\\beta)^{2}\\mid X=x]}.$ for each $x\\in\\mathscr{X}$ if such a $q_{\\beta}^{*}$ exists. ", "page_idx": 7}, {"type": "text", "text": "We defer the proof to Appendix A.2. Let $\\sigma_{\\beta}(x):=\\,\\sqrt{\\mathbb{V}[r(X,Y,\\beta)\\mid X=x]}$ be the conditional standard deviation of $r(X,Y,\\beta)$ . Now, we can argue that the solution to the optimization problem on the growth rate lower bound in (10) has the following characterization.   \nCorollary 1. The optimal choice of $q_{\\beta}^{*}$ and $\\lambda^{*}$ that solves (10) is ", "page_idx": 7}, {"type": "equation", "text": "$$\nq_{\\beta}^{*}(x):=\\frac{\\sigma_{\\beta}(x)}{\\mathbb{E}[\\sigma_{\\beta}(X)]}\\cdot B,\\qquad\\lambda^{*}:=\\frac{\\theta-\\rho(\\beta)}{2((\\theta-\\rho(\\beta))^{2}+\\mathbb{E}[\\sigma_{\\beta}(X)]^{2}\\cdot B^{-1}+\\mathbb{V}[r(X,Y,\\beta)])}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "if $q_{\\beta}^{*}(x)\\in[0,1]$ for all $x\\in\\mathscr{X}$ , and $\\lambda^{*}\\leq(2(\\operatorname*{inf}_{x\\in\\mathcal{X}}q_{\\beta}^{*}(x))^{-1}-2\\theta)^{-1}$ . The resulting growth rate has the following lower bound: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}[G_{t}^{\\beta}(q^{*},r^{*},\\lambda^{*})]\\geq\\mathbb{E}[\\widehat{G}_{t}^{\\beta}(q^{*},r^{*},\\lambda^{*})]=\\frac{(\\theta-\\rho(\\beta))^{2}}{4((\\theta-\\rho(\\beta))^{2}+\\mathbb{E}[\\sigma_{\\beta}(X)]^{2}\\cdot B^{-1}+\\mathbb{V}[r(X,Y,\\beta)])}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "We can show this is true as a consequence of Proposition 4, Proposition 5, and solving the quadratic equation that arises for the growth rate to derive the optimal choice of $\\lambda^{*}$ . Further, we note that we can define regret of a sequence $\\left(\\lambda_{t}\\right)$ compared to $\\lambda^{*}$ on $\\widehat{G}_{t}^{\\beta}$ as follows. ", "page_idx": 7}, {"type": "text", "text": "Definition 3. The ${\\widehat{G}}^{\\beta}$ -regret at the tth step of a sequence of betting parameters $\\left(\\lambda_{t}\\right)$ for a risk upper bound $\\theta\\in[0,1]$ ,  and a sequence of labeling policies $\\left(q_{t}\\right)$ and predictors $\\left(\\widehat{r}_{t}\\right)$ where $q_{t}(x)\\geq\\varepsilon>0$ for all $x\\in\\mathscr{X}$ and $t\\in\\mathbb{N}$ almost surely is defined as follows: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathsf{R e g}_{t}:=\\operatorname*{max}_{\\lambda\\in[0,(2\\varepsilon^{-1}-2\\theta)^{-1}]}\\sum_{i=1}^{t}\\mathbb{E}[\\widehat{G}_{t}^{\\beta}(q_{t},\\widehat{r}_{t},\\lambda)\\mid\\mathcal{F}_{t-1}]-\\mathbb{E}[\\widehat{G}_{t}^{\\beta}(q_{t},\\widehat{r}_{t},\\lambda_{t})\\mid\\mathcal{F}_{t-1}].\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Since $\\widehat{G}_{t}^{\\beta}(q,\\widehat{r},\\lambda)$ is exp-concave in $\\lambda$ , existing online learning algorithms such as Online Newton Step (ONS) [8] can get $o(T)$ regret guarantees, which means that the growth rate of $\\left(\\lambda_{t}\\right)$ averaged over time will approach (or exceed) the optimal growth rate under $\\lambda^{*}$ . For simplicity of analysis, we make the following assumption about the labeling probability of the optimal policy, $q_{\\beta}^{*}$ . ", "page_idx": 7}, {"type": "text", "text": "Assumption 2. Let $\\varepsilon>0$ be a positive constant. Assume that $q_{\\beta}^{*}(x)\\geq\\varepsilon$ for each $x\\in\\mathscr{X}$ . ", "page_idx": 7}, {"type": "text", "text": "The lower bound in the above assumption is an analog of the propensity score lower bound on optimal policies for adaptive experimentation which are needed for performing valid inference in that setting [17, 7]. Further, do not need this to hold on every $\\beta$ , since we are not necessarily interested in log-optimality w.r.t. fringe $\\beta$ that are quite far away from $\\beta^{*}$ \u2014 in practice having this assumption hold for values of $\\beta$ near $\\beta^{*}$ suffices to develop an estimator $\\widehat\\beta$ that shrinks toward $\\beta^{*}$ quickly. Now, we describe how much the growth rates deviates based on on how well $q^{*}$ and $r^{*}$ are estimated. ", "page_idx": 7}, {"type": "text", "text": "Theorem 3. Let $\\left(\\lambda_{t}\\right)$ be a sequence with $\\widehat{G}^{\\beta}$ -regret $(\\mathbf{Reg}_{t})$ and $\\left(q_{t}\\right)$ and $\\left(\\widehat{r}_{t}\\right)$ are sequences of labeling policies and predictors that are all  predictable w.r.t. $\\left(\\mathcal{F}_{t}\\right)$ . For a positiv e constant $\\varepsilon>0$ , let $q_{t}(x)\\geq\\varepsilon>0$ for each $t\\in\\mathbb N$ and $x\\in\\mathscr{X}$ almost surely. Under Assumption 2 for the same $\\varepsilon$ , the following bound holds: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\frac{t}{\\tau+1}\\mathbb{E}[\\widehat{G}_{t}^{\\beta}(q^{*},r^{*},\\lambda^{*})-\\widehat{G}_{t}^{\\beta}(q_{t},\\widehat{r}_{t},\\lambda_{t})]\\leq\\mathrm{Reg}_{t}+\\sum_{i=1}^{t}O(\\mathbb{E}[|q(X_{t})-q_{\\beta}^{*}(X_{t})|]+\\mathbb{E}[(\\widehat{r}_{t}(X_{t})-r^{*}(X_{t},\\beta))^{2}]).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "We defer the proof to Appendix A.3. The proof idea follows a similar idea that of the regret bound in Kato et al. [17] for deriving an estimator that is close to the optimal estimator for the average treatment effect in an adaptive experimentation setup. Theorem 3 relates the estimation error of $q_{\\beta}^{*}(x)$ and $r^{\\ast}(x,\\beta)$ to how quickly $\\beta$ will be deemed \u201csafe\u201d. Hence, if we have good estimates of those quantities, then we can produce an estimates $(\\widehat{\\beta}_{t})$ that are small and close to $\\beta^{*}$ while remaining safe. We will now describe some practical methods for calculating $q_{t}$ and $\\widehat{r}_{t}$ . ", "page_idx": 7}, {"type": "text", "text": "4 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We use PyTorch to model our $\\left(q_{t}\\right)$ and $\\left(\\widehat{r}_{t}\\right)$ , and we use the following methods to formulate them.2 ", "page_idx": 7}, {"type": "text", "text": "1. Baseline labeling policies. We have baseline labeling policies of labeling all data that arrives, and a policy that just randomly samples $B$ proportion of samples to label \u2014 these are denoted respectively as \u201call\u201d and \u201coblivious\u201d. ", "page_idx": 8}, {"type": "text", "text": "2. Pretrain: We derive an estimate of $r^{*}$ from a pretrained machine learning model, $\\widehat{r}^{\\mathrm{pretr}}$ , to be our choice of predictor for all time steps. We also derive an estimate of $\\sigma(\\boldsymbol{x},\\beta)$ , $\\widehat{\\sigma}^{\\mathrm{pretr}}(x,\\beta)$ , from the pretrained model. We also learn a sequence of normalizing constants $\\left(C_{t}\\right)$ s.t. the budget is satisfied. Our labeling policy in this case is $q_{t}(x)=\\widehat{\\sigma}(x,\\widehat{\\beta}_{t-1})/C_{t}$ , where we want to optimize our policy for the previous best bound on $\\beta^{*}$ , $\\widehat{\\beta}_{t-1}$ . We denote this method as \u201cpretrain\u201d. ", "page_idx": 8}, {"type": "text", "text": "3. Estimating $q_{\\beta}^{*}$ and $r^{*}$ : We learn sequences of models $(\\widehat{\\sigma}_{t}^{\\mathrm{plugin}})$ and $(\\widehat{r}_{t}^{\\mathrm{{plugin}}})$ using the labeled data points. We preprocess the outputs from $\\widehat{\\sigma}^{\\mathrm{pretr}}$ and $\\widehat{r}^{\\mathrm{pretr}}$ to use as the input features to these models, respectively. Each of these sequences o f  models  a re then updated at every step. We also similarly learn a sequence of normalization constants $\\left(C_{t}\\right)$ for deriving the final labeling policy $\\left(q_{t}\\right)$ . ", "page_idx": 8}, {"type": "text", "text": "We provide more details on how are methods are formulated in Appendix B. We run all our experiments on a 48-core CPU on the Azure platform, after using a GPU to precompute the predictions made by neural network models. We set $\\theta=0.1$ , $\\alpha=0.05$ , and $B=0.3$ for all our experiments. ", "page_idx": 8}, {"type": "text", "text": "4.1 Numerical simulations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We have a simple data generating process of sampling $P_{t}\\,\\sim\\,\\mathrm{Uniform}[0,1]$ and let $Y_{t}~\\mid~X_{t}~\\sim$ $\\mathtt{B e r n}(X_{t})$ . This simulates the setting we have with our real data where we have an accurate pretrained classifier that have a probability estimate of $Y_{t}$ of being 0 or 1. We let our covariates $X_{t}=P_{t}$ . As a result, our risk function is the false positive rate $r_{\\mathrm{FPR}}(X,Y,\\beta):={\\bf1}\\left\\{X\\geq\\beta,Y=0\\right\\}$ . We run 100 trials where each trial runs until 2500 labels are queried. We compare our methods based on their label efficiency, i.e., how close is ${\\widehat{\\beta}}_{t}$ to $\\beta^{*}=1-\\sqrt{2\\alpha}$ after a set number of queried labels. In Figure 2, we plot the average\u03b2 t reached after a given number of labels queried across trials. The shaded areas denotes pointwis e $95\\%$ confidence intervals on the uncertainty of the average estimate. We can see that the \u201cpretrain\u201d and \u201clearned\u201d methods outperform both the \u201call\u201d and \u201coblivious\u201d strategies uniformly numbers across labels queried. In Figure 2a, we show the average rate of safety violations, i.e., the average proportion of trials that ${\\widehat{\\beta}}_{t}$ was unsafe and $\\rho(\\widehat{\\beta}_{t})>\\theta$ at any time step. We can see that all methods control the desired safety violation rate at the predetermined level $\\alpha$ . ", "page_idx": 8}, {"type": "image", "img_path": "4ZH48aGD60/tmp/291a0e820a48871923086904841aae690e2aae0533d2fc958551f7fd944c74d4.jpg", "img_caption": [], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Figure 2: Experimental results for different methods for our numerical simulation setup. We can see that \u201cpretrain\u201d and \u201clearned\u201d perform better by getting lower average ${\\widehat{\\beta}}_{t}$ uniformly across number of labels queried \u2014 the dotted line in Figures 2b and $2c$ is $\\beta^{*}=0.5578$ . Each method also has low safety violation rate, i.e., is below the dotted line of $\\alpha=0.05$ in Figure 2a. ", "page_idx": 8}, {"type": "text", "text": "4.2 Imagenet ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We also evaluate our methods on the Imagenet dataset [9], and we used the pretrained neural network classifiers from Bates et al. [4] to provide estimates of the class probabilities. ", "page_idx": 8}, {"type": "text", "text": "Since Imagenet is a classification task with label support on $y=[1000]$ , our goal is to ensure that the miscoverage rate of the true class is controlled. We follow the same setup as descibed in the ", "page_idx": 8}, {"type": "text", "text": "introduction, i.e., with our risk measure $r$ specified according to (1). For Imagenet, we reshuffle our dataset for each trial, and run each method till we have queried 3000 labels. ", "page_idx": 9}, {"type": "image", "img_path": "4ZH48aGD60/tmp/dbd8cbfc849a95b92ef4598a689c51e3b25b4a58650ed8d306c8d8a316410054.jpg", "img_caption": ["Figure 3: Experimental results for different methods on Imagenet. Again, we see that \u201cpretrain\u201d and \u201clearned\u201d are the best performing, and they have very similar performance and hence overlap in Figure 3c. Here, $\\beta^{*}=0.8\\bar{3}49$ , and is delineated by the dotted line in Figures 3b and 3c. Again, each method also has low safety violation rate, i.e., is below the dotted line of $\\alpha=0.05$ in Figure 3a. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "In Figure 3, we plot the average $\\widehat{\\beta}_{t}$ across trials. Once again, we can see that the \u201cpretrain\u201d and \u201clearned\u201d methods outperform bot h the \u201call\u201d and \u201coblivious\u201d strategies here as well. On Imagenet the average safety violation rate is also controlled as well under the predetermined level of $\\alpha=0.05$ . ", "page_idx": 9}, {"type": "text", "text": "5 Additional related work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Casgrain et al. [6] provide anytime-valid sequential tests for identifiable functions, which result in similar hypotheses being tested as this paper albeit with equality instead of equality. They, in addition to other recent work [26, 25, 32], using regret bounds for betting-based e-processes to show either derivations for the growth rate of a betting strategy w.r.t. to the optimal growth rate. However, none of these settings incorporate the ability to perform adaptive sampling or inverse propensity weights. Prior work in anytime-valid inference have included inverse propensity weights have been for off policy evaluation [36], adaptive experimentation [7], or estimating the weighted mean of a finite population [33]. However, none of these works explicitly characterize deviation in the sampling policy away from the optimal sampling policy ultimately affects the growth rate as we do in Theorem 3. ", "page_idx": 9}, {"type": "text", "text": "Our analysis of power and regret for our algorithm is quite similar to methods in adaptive experimentation for average treatment effect estimation [14, 17] that attempt to derive a no regret treatment policy and outcome regressor that produces an estimator with a variance that approaches the variance of the optimal estimator. Unlike the adaptive experimentation setting, however, we have an additional label budget constraint on our formulation that results in a different optimal policy. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion, limitations, and future work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We have shown that we can extend the RCPS formulation to be anytime-valid, and retain validity and increase label efficiency in an active learning setting. We use the theory of betting and e-processes to develop this framework and show it is verifiably safe, and we verified this with our experimental results. We have primarily considered the i.i.d. setting here for anytime-valid calibration, and one key area in which one can extend this line of work is to account for distribution shift during test time. The empirical Bernstein supermartingales in Waudby-Smith et al. [36] can likely be used to extend our framework control risk in an average sense, but stronger guarantees could be made about the provided risk control if more realistic assumptions are made about the nature of the distribution (e.g., covariate shift, label shift, etc). It may also be possible extend a notion of adaptive conformal inference (ACI) [11, 12] to anytime-valid risk control. Another limitation of this work is the bounded label policy assumption (i.e., Assumption 2) and existence assumption in Proposition 5. We believe that more careful analysis can get rid of these assumptions in future work. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] A. N. Angelopoulos, A. P. Kohli, S. Bates, M. I. Jordan, J. Malik, T. Alshaabi, S. Upadhyayula, and Y. Romano. Image-to-Image Regression with Distribution-Free Uncertainty Quantification and Applications in Imaging. arXiv:2202.05265, 2022. [2] A. N. Angelopoulos, S. Bates, C. Fannjiang, M. I. Jordan, and T. Zrnic. Prediction-powered inference. Science, 382(6671):669\u2013674, 2023. [3] S. Asmussen and P. W. Glynn. Stochastic Simulation: Algorithms and Analysis. Stochastic Modelling and Applied Probability. Springer, New York, 1 edition, 2007.   \n[4] S. Bates, A. Angelopoulos, L. Lei, J. Malik, and M. Jordan. Distribution-free, Risk-controlling Prediction Sets. Journal of the ACM, 68(6):43:1\u201343:34, 2024. [5] L. Breiman. Optimal Gambling Systems for Favorable Games. Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Probability, Volume 1: Contributions to the Theory of Statistics, 4.1:65\u201379, 1961.   \n[6] P. Casgrain, M. Larsson, and J. Ziegel. Sequential testing for elicitable functionals via supermartingales. Bernoulli, 30(2):1347\u20131374, 2024.   \n[7] T. Cook, A. Mishler, and A. Ramdas. Semiparametric Efficient Inference in Adaptive Experiments. In Conference on Causal Learning and Reasoning, 2024.   \n[8] A. Cutkosky and F. Orabona. Black-Box Reductions for Parameter-free Online Learning in Banach Spaces. In Conference On Learning Theory, 2018.   \n[9] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition, pages 248\u2013255. Ieee, 2009.   \n[10] A. M. Flores, F. Demsas, N. J. Leeper, and E. G. Ross. Leveraging Machine Learning and Artificial Intelligence to Improve Peripheral Artery Disease Detection, Treatment, and Outcomes. Circulation Research, 128(12):1833\u20131850, 2021.   \n[11] I. Gibbs and E. Candes. Adaptive Conformal Inference Under Distribution Shift. In Neural Information Processing Systems, 2021.   \n[12] I. Gibbs and E. Cande\\`s. Conformal Inference for Online Prediction with Arbitrary Distribution Shifts. arXiv:2208.08401, 2023.   \n[13] P. Gru\u00a8nwald, R. de Heide, and W. Koolen. Safe Testing. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 2024.   \n[14] J. Hahn, K. Hirano, and D. Karlan. Adaptive Experimental Design Using the Propensity Score. Journal of Business & Economic Statistics, 29(1):96\u2013108, 2011.   \n[15] L. Hanu and Unitary team. Detoxify. Github. https://github.com/unitaryai/detoxify, 2020.   \n[16] H. Huang, S. Sharma, A. Loquercio, A. Angelopoulos, K. Goldberg, and J. Malik. Conformal Policy Learning for Sensorimotor Control Under Distribution Shifts. arXiv:2311.01457, 2023.   \n[17] M. Kato, T. Ishihara, J. Honda, and Y. Narita. Efficient Adaptive Experimental Design for Average Treatment Effect Estimation. arXiv:2002.05308, 2021.   \n[18] J. L. Kelly. A New Interpretation of Information Rate. The Bell System Technical Journal, page 10, 1956.   \n[19] M. Larsson, A. Ramdas, and J. Ruf. The numeraire e-variable and reverse information projection. arXiv:2402.18810, 2024.   \n[20] J. Lekeufack, A. N. Angelopoulos, A. Bajcsy, M. I. Jordan, and J. Malik. Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. arXiv:2310.05921, 2023.   \n[21] J. Lekeufack, A. N. Angelopoulos, A. Bajcsy, M. I. Jordan, and J. Malik. Conformal Decision Theory: Safe Autonomous Decisions from Imperfect Predictions. arXiv:2310.05921, 2024.   \n[22] T. Markov, C. Zhang, S. Agarwal, F. E. Nekoul, T. Lee, S. Adler, A. Jiang, and L. Weng. A Holistic Approach to Undesired Content Detection in the Real World. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12):15009\u201315018, 2023.   \n[23] F. Orabona and T. Tommasi. Training Deep Networks without Learning Rates Through Coin Betting. In Neural Information Processing Systems, volume 30, 2017.   \n[24] A. B. Owen. Monte Carlo theory, methods and examples. https://artowen.su.domains/ mc/, 2013.   \n[25] A. Podkopaev and A. Ramdas. Sequential Predictive Two-Sample and Independence Testing. In Neural Information Processing Systems, 2023.   \n[26] A. Podkopaev, P. Bl\u00a8obaum, S. Kasiviswanathan, and A. Ramdas. Sequential Kernelized Independence Testing. In International Conference on Machine Learning, 2023.   \n[27] V. Quach, A. Fisch, T. Schuster, A. Yala, J. H. Sohn, T. S. Jaakkola, and R. Barzilay. Conformal Language Modeling. arXiv:2306.10193, 2023.   \n[28] A. Ramdas, J. Ruf, M. Larsson, and W. Koolen. Admissible anytime-valid sequential inference must rely on nonnegative martingales. arXiv:2009.03167, 2022.   \n[29] A. Ramdas, P. Gru\u00a8nwald, V. Vovk, and G. Shafer. Game-Theoretic Statistics and Safe AnytimeValid Inference. Statistical Science, 38(4):576\u2013601, 2023.   \n[30] L. Saba, S. S. Sanagala, S. K. Gupta, V. K. Koppula, A. M. Johri, N. N. Khanna, S. Mavrogeni, J. R. Laird, G. Pareek, M. Miner, P. P. Sfikakis, A. Protogerou, D. P. Misra, V. Agarwal, A. M. Sharma, V. Viswanathan, V. S. Rathore, M. Turk, R. Kolluri, K. Viskovic, E. Cuadrado-Godia, G. D. Kitas, N. Sharma, A. Nicolaides, and J. S. Suri. Multimodality carotid plaque tissue characterization and classification in the artificial intelligence paradigm: A narrative review for stroke application. Annals of Translational Medicine, 9(14):1206, 2021.   \n[31] G. Shafer. Testing by betting: A strategy for statistical and scientific communication. Journal of the Royal Statistical Society: Series A (Statistics in Society), 184(2):407\u2013431, 2021.   \n[32] S. Shekhar and A. Ramdas. Nonparametric Two-Sample Testing by Betting. IEEE Transactions on Information Theory, 70(2):1178\u20131203, 2024.   \n[33] S. Shekhar, Z. Xu, Z. Lipton, P. Liang, and A. Ramdas. Risk-limiting financial audits via weighted sampling without replacement. In Conference on Uncertainty in Artificial Intelligence, 2023.   \n[34] J. Ville. E\u00b4tude Critique de la Notion de Collectif. PhD thesis, University of Paris, Paris, 1939.   \n[35] I. Waudby-Smith and A. Ramdas. Estimating means of bounded random variables by betting. Journal of the Royal Statistical Society Series B (Statistical Methodology), 2023.   \n[36] I. Waudby-Smith, L. Wu, A. Ramdas, N. Karampatziakis, and P. Mineiro. Anytime-valid off-policy inference for contextual bandits. ACM / IMS Journal of Data Science, 2024.   \n[37] J. Wu, J. Xin, X. Yang, J. Sun, D. Xu, N. Zheng, and C. Yuan. Deep morphology aided diagnosis network for segmentation of carotid artery vessel wall and diagnosis of carotid atherosclerosis on black-blood vessel wall MRI. Medical Physics, 46(12):5544\u20135561, 2019.   \n[38] T. Zrnic and E. J. Cande\\`s. Active Statistical Inference. In International Conference on Machine Learning, 2024. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Omitted proofs ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proofs that have been deferred from the main body of the paper are contained here. ", "page_idx": 12}, {"type": "text", "text": "A.1 Proof of Proposition 4 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We can rewrite the objective in the following way: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\widehat{G}(q,\\widehat{r},\\lambda)]=\\mathbb{E}\\left[\\lambda\\left(\\theta-\\widehat{r}(X,\\beta)-\\displaystyle\\frac{L}{q(X)}\\bar{R}(\\beta)\\right)-\\lambda^{2}\\left(\\theta-\\widehat{r}(X,\\beta)-\\displaystyle\\frac{L}{q(X)}\\bar{R}(\\beta)\\right)^{2}\\right]}\\\\ &{\\quad\\quad\\quad\\quad=\\lambda\\left(\\theta-\\rho(\\beta)\\right)-\\lambda^{2}\\left((\\theta-\\rho(\\beta))^{2}+\\mathbb{V}\\left[\\widehat{r}(X,\\beta)+\\displaystyle\\frac{L}{q(X)}\\bar{R}(\\beta)\\right]\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "Maximizing (11) is the same as minimizing the following equivalent expressions: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{~\\mathbb{V}\\left[\\hat{r}(X,\\beta)+\\frac{L}{q(X)}\\bar{R}(\\beta)\\right]}\\\\ &{=\\mathbb{E}\\left[\\mathbb{V}\\left[\\hat{r}(X,\\beta)+\\frac{L}{q(X)}\\bar{R}(\\beta)~|~X\\right]\\right]+\\mathbb{V}\\left[\\mathbb{E}\\left[\\hat{r}(X,\\beta)+\\frac{L}{q(X)}\\bar{R}(\\beta)~|~X\\right]\\right]}\\\\ &{=\\mathbb{E}\\left[\\mathbb{V}\\left[\\frac{L}{q(X)}\\bar{R}(\\beta)~|~X\\right]\\right]+\\mathbb{V}[R(\\beta)]}\\\\ &{=\\mathbb{E}\\left[\\mathbb{E}\\left[\\frac{\\bar{R}(\\beta)^{2}}{q(X)}~|~X\\right]-\\mathbb{E}[\\bar{R}(\\beta)~|~X]^{2}\\right]+\\mathbb{V}[R(\\beta)]}\\\\ &{=\\left(\\int\\left(\\frac{\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}~|~X=x\\right]}{q(X)}-\\mathbb{E}[\\bar{R}(\\beta)~|~X=x]^{2}\\right)p(x)~d x\\right)+\\mathbb{V}[R(\\beta)],}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where we derive the 1st equality from the law of total variance, and the 2nd equality from the fact that ${\\widehat{r}}(X,{\\beta})$ is fixed given $X$ . ", "page_idx": 12}, {"type": "text", "text": "Since the only term that $\\widehat{r}$ affects is the integral term in (12), we can choose each $\\widehat{r}(\\boldsymbol{x},\\beta)$ for each $x\\in\\mathscr{X}$ to minimize the f o llowing: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\mathbb{E}\\left[\\tilde{R}(\\beta)^{2}\\mid X=x\\right]}{q(x)}-\\mathbb{E}[\\bar{R}(\\beta)\\mid X=x]^{2}}\\\\ &{=\\!\\!\\frac{\\mathbb{E}[(r(X,Y,\\beta)-\\hat{r}(x,\\beta))^{2}\\mid X=x]}{q(x)}-(\\mathbb{E}[r(X,Y,\\beta)\\mid X=x]-\\hat{r}(x,\\beta))^{2}}\\\\ &{=\\!\\!\\frac{\\mathbb{E}[r(X,Y,\\beta)^{2}\\mid X=x]}{q(x)}-\\mathbb{E}[r(X,Y,\\beta)\\mid X=x]^{2}}\\\\ &{\\qquad\\quad-\\left(\\frac{1}{q(x)}-1\\right)(2\\mathbb{E}[r(X,Y,\\beta)\\mid X=x]\\hat{r}(x,\\beta)-\\hat{r}(x,\\beta)^{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "If we remove the constants (i.e., terms unaffected by $\\widehat{r}(\\boldsymbol{x},\\beta))$ ), and note that $q(x)^{-1}-1>0$ , we get that minimizing (13) is equivalent to minimizing ", "page_idx": 12}, {"type": "equation", "text": "$$\n2\\mathbb{E}[r(X,Y,\\beta)\\mid X=x]\\widehat{r}(x,\\beta)-\\widehat{r}(x,\\beta)^{2}.\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "This is equivalent to minimizng the squared error, i.e., $(\\mathbb{E}[r(X,Y,\\beta)\\mid X=x]-\\widehat{r}(x,\\beta))^{2}$ , which means that $r^{*}(x,\\beta)=\\mathbb{E}[r(X,\\bar{Y},\\beta)\\mid\\bar{X}=x]$ , which gets us our desired result. ", "page_idx": 12}, {"type": "text", "text": "A.2 Proof of Proposition 5 ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Since we have shown that maximizing (10) is equivalent to minimizing (12), we can isolate the terms that change wiht $q$ and see that we are looking for the solution to the following optimization problem: ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{q}{\\operatorname*{min}}\\int\\frac{p(x)}{q(x)}\\mathbb{E}[\\bar{R}(\\beta)^{2}\\mid X=x]\\;d x}\\\\ {\\mathrm{s.t.}\\;\\int p(x)q(x)\\;d x\\leq B.}\\end{array}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We can define $\\varphi(x):=p(x)q(x)$ rewrite this as ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\underset{\\varphi}{\\operatorname*{min}}\\int\\frac{p(x)^{2}}{\\varphi(x)}\\mathbb{E}[\\bar{R}(\\beta)^{2}\\mid X_{i}=x]\\;d x}\\\\ {\\mathrm{s.t.}\\;\\int\\varphi(x)\\;d x\\leq B.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Assume we can define a valid $q_{\\beta}^{*}$ where $q_{\\beta}^{*}(x)\\in[0,1]$ for each $x\\in\\mathscr{X}$ that satisfies the following conditions: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\varphi(x)\\propto p(x)\\sqrt{\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}\\mid X=x\\right]}}\\\\ {q_{\\beta}^{*}(x)\\propto\\sqrt{\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}\\mid X=x\\right]}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Explicitly, we define $q_{\\beta}^{*}$ as follows: ", "page_idx": 13}, {"type": "equation", "text": "$$\nq_{\\beta}^{*}(x)={\\frac{{\\sqrt{\\mathbb{E}\\left[{\\bar{R}}(\\beta)^{2}\\mid X=x\\right]}}}{\\mathbb{E}\\left[{\\sqrt{\\mathbb{E}\\left[{\\bar{R}}(\\beta)^{2}\\mid X=x\\right]}}\\right]}}\\cdot B.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "One can show its optimality by considering some other labeling policy $q^{\\prime}$ where $\\mathbb{E}[q^{\\prime}(X)]\\,=\\,B$ (we use a similar proof technique from importance sampling Owen [24, $\\S\\,9.1_{.}$ ]). Now, let $\\varphi^{*}(x):=$ $p(x)q_{\\beta}^{*}(x)$ and $\\varphi^{\\prime}(x)=p(x)q^{\\bar{\\prime}}(x)$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\displaystyle\\int\\frac{p(x)^{2}}{\\varphi^{*}(x)}\\mathbb{E}[\\bar{R}(\\beta)^{2}\\mid X_{i}=x]\\,d x}\\\\ &{=\\mathbb{E}\\left[\\sqrt{\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}\\mid X=x\\right]}\\right]\\int\\frac{p(x)}{B}\\cdot\\sqrt{\\mathbb{E}[\\bar{R}(\\beta)^{2}\\mid X_{i}=x]}\\,d x}\\\\ &{=\\mathbb{E}\\left[\\sqrt{\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}\\mid X=x\\right]}\\right]^{2}\\cdot B^{-1}}\\\\ &{=\\left(\\displaystyle\\int\\frac{p(x)}{\\varphi^{\\prime}(x)}\\cdot\\varphi^{\\prime}(x)\\cdot\\sqrt{\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}\\mid X=x\\right]}\\,d x\\right)^{2}\\cdot B^{-1}}\\\\ &{=B\\cdot\\left(\\displaystyle\\int\\frac{p(x)}{\\varphi^{\\prime}(x)}\\cdot\\frac{\\varphi^{\\prime}(x)}{B}\\cdot\\sqrt{\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}\\mid X=x\\right]}\\,d x\\right)^{2}}\\\\ &{\\leq\\displaystyle\\int\\frac{p(x)^{2}}{\\varphi^{\\prime}(x)}\\mathbb{E}\\left[\\bar{R}(\\beta)^{2}\\mid X=x\\right]\\,d x,}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where the last line is by Cauchy-Schwarz, since $\\varphi^{\\prime}(x)/B$ is a valid p.d.f. Hence, we have shown our desired result. ", "page_idx": 13}, {"type": "text", "text": "A.3 Proof of Theorem 3 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "By definition of $\\mathbf{Reg}_{t}$ , we know that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{t}\\mathbb{E}[\\widehat{G}^{\\beta}(q_{i},\\widehat{r}_{i},\\lambda^{*})]-\\mathbb{E}[\\widehat{G}^{\\beta}(q_{t},\\widehat{r}_{i},\\lambda_{i})]\\leq\\mathrm{Reg}_{t}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "by taking an expectation over $\\mathcal{F}_{i-1}$ for each term in the summation Hence, what remains to be shown is the following: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{i=1}^{t}\\mathbb{E}[\\widehat{G}^{\\beta}(q^{*},r^{*},\\lambda^{*})]-\\mathbb{E}[\\widehat{G}^{\\beta}(q_{t},\\widehat{r}_{t},\\lambda^{*})]}\\\\ &{\\displaystyle\\leq\\sum_{i=1}^{t}O(\\mathbb{E}[|q_{t}(X_{t})-q_{\\beta}^{*}(X_{t})|])+O(\\mathbb{E}[(\\widehat{r}_{t}(X_{t},\\beta)-r^{*}(X_{t},\\beta))^{2}])}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Let $\\bar{R}_{t}(\\beta):=r(X,Y,\\beta)\\!-\\!\\widehat{r}_{t}(X,\\beta)$ and $\\bar{R}^{*}(\\beta):=r(X,Y,\\beta)\\!-\\!r^{*}(X,\\beta)$ . We first note the following identity using (12): ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{E}[\\widehat{G}^{\\beta}(q^{*},r^{*},\\lambda^{*})]-\\mathbb{E}[\\widehat{G}^{\\beta}(q_{t},\\widehat{r}_{t},\\lambda^{*})]}\\\\ &{=\\!(\\lambda^{*})^{2}\\left(\\mathbb{E}\\left[\\mathbb{V}\\left[\\widehat{r}_{t}(X,\\beta)-\\frac{L}{q_{t}(X)}\\bar{R}_{t}(\\beta)\\mid\\mathcal{F}_{t-1}\\right]-\\mathbb{V}\\left[r^{*}(X,\\beta)-\\frac{L}{q_{\\beta}^{*}(X)}\\bar{R}^{*}(\\beta)\\right]\\right]\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Now, we make the following derivations for the difference between the variance $(\\mathbb{V})$ terms: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbb{V}\\left[\\widehat{r}_{t}(X,\\beta)-\\frac{L}{q_{t}(X)}\\bar{R}_{t}(\\beta)\\ |\\ \\mathcal{F}_{t-1}\\right]-\\mathbb{V}\\left[r^{*}(X,\\beta)-\\frac{L}{q_{\\beta}^{*}(X)}\\bar{R}^{*}(\\beta)\\right]}\\\\ &{=\\int\\left(\\frac{\\mathbb{E}[\\bar{R}_{t}(\\beta)^{2}\\mid X=x]}{q_{t}(x)}-\\frac{\\mathbb{E}[\\bar{R}^{*}(\\beta)^{2}\\mid X=x]}{q_{\\beta}^{*}(x)}-\\mathbb{E}[\\bar{R}_{t}(\\beta)\\ |X=x]^{2}\\right)\\cdot p(x)\\,d x}\\\\ &{=\\int\\left(\\frac{(q_{\\beta}^{*}(x)-q_{t}(x))\\mathbb{V}[r(X,Y,\\beta)\\mid X=x]+q_{\\beta}^{*}(x)(1-q_{t}(x))(\\widehat{r}_{t}(x)-r^{*}(x,\\beta))^{2}}{q_{t}(x)^{*}(x)}\\right)\\cdot p(x)\\,d x}\\\\ &{\\le\\int\\left((q_{\\beta}^{*}(x)-q_{t}(x))+(\\widehat{r}_{t}(x)-r^{*}(x,\\beta))^{2}\\right)\\cdot\\frac{p(x)}{\\varepsilon}\\,d x}\\\\ &{\\le\\ O(\\mathbb{E}[q_{\\beta}^{*}(X_{t})-q_{t}(X_{t})]\\mid\\mathcal{F}_{t-1}]+\\mathbb{E}[(\\widehat{r}_{t}(X_{t})-r^{*}(X_{t},\\beta))^{2}\\mid\\mathcal{F}_{t-1}]).}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The 1st equality is by substituting in the identity from (12). The 1st inequality is a result of $\\textstyle\\mathbb{V}[r(X,Y,{\\hat{\\beta}})\\mid{\\dot{X}}={\\dot{x}}]\\leq{\\frac{1}{4}}$ , since $\\bar{r}(X,Y,\\beta)\\in[0,1]$ , and $q_{\\beta}^{*}(x),q_{t}(x)\\in[\\varepsilon,\\bar{1}]$ almost surely. The 2nd inequality is by upper bounding $q_{\\beta}^{*}(x)-q_{t}(x)$ by its absolute value. ", "page_idx": 14}, {"type": "text", "text": "Now, if we plug (15) into (14), take the expectation over $\\mathcal{F}_{t-1}$ , and take the summation over $t$ , we get our desired result. ", "page_idx": 14}, {"type": "text", "text": "B Experiment details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this section, we discuss additional details about how we implement our methods described in Section 4. ", "page_idx": 14}, {"type": "text", "text": "B.1 Formulation of the labeling policy ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For the \u201cpretrain\u201d policy, we use an estimate of the conditional mean and variance derived from $s$ . ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{r}^{\\mathrm{pretr}}(x,\\beta):=\\displaystyle\\sum_{y\\notin C(x,\\beta)}s^{y}(x),}\\\\ &{\\widehat{\\sigma}^{\\mathrm{pretr}}(x,\\beta):=\\sqrt{\\widehat{r}^{\\mathrm{pretr}}(x,\\beta)\\cdot(1-\\widehat{r}^{\\mathrm{pretr}}(x,\\beta))}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "These estimates may not be accurate, but might still represent a reasonable partitioning of the feature space where $\\sigma(\\boldsymbol{x},\\beta)$ and $r^{\\ast}(x,\\beta)$ are similar. Hence, for $\\widehat{\\sigma}_{t}^{\\mathrm{plugin}}$ and rtplugin, we model them as linear regresssion models where inputs are a binning of $\\widehat{r}^{\\mathrm{pretr}}(x,\\bar{\\beta})$ and $\\widehat{\\sigma}^{\\mathrm{pretr}}(x,\\beta)$ , respectively. We then learn the regression model parameters on training data. ", "page_idx": 14}, {"type": "text", "text": "B.2 Optimization to maintain the budget constraint ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "For any predictor $\\widehat{\\sigma}$ , we optimize the Lagrangian corresponding to (10), which is defined as follows for a fixed $\\lambda_{t}$ . ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}(\\nu_{t},q_{t})}\\\\ &{=\\mathbb{E}[\\widehat{G}(q_{t},\\widehat{r}_{t},\\lambda_{t})]-\\nu_{t}(\\mathbb{E}[q_{t}(X_{t})]-B)}\\\\ &{=\\mathbb{E}\\left[\\lambda_{t}\\left(\\theta-\\frac{L_{t}}{q_{t}(X)}r(X,Y,\\beta)\\right)-\\psi(\\lambda_{t})\\left(\\theta-\\frac{L_{t}}{q_{t}(X)}r(X,Y,\\beta)\\right)^{2}\\right]-\\nu_{t}(\\mathbb{E}[q_{t}(X)]-B)}\\\\ &{=\\lambda_{t}(\\theta-\\rho(\\beta))-\\lambda_{t}^{2}\\mathbb{E}\\left[\\left(\\theta-\\widehat{r}_{t}(X,\\beta)-\\frac{L_{t}}{q_{t}(X)}\\bar{R}(\\beta)\\right)^{2}\\right]-\\nu_{t}(\\mathbb{E}[q_{t}(X)]-B)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Since we know the optimal form of $\\widehat{r}_{t}$ , we optimize it separately by taking an optimization step with the loss of squared error, $(r(X,Y,\\beta)-\\widehat{r}_{t}(\\bar{X},\\beta))^{2}$ , for each labeled example for a grid of $\\beta$ values. ", "page_idx": 15}, {"type": "text", "text": "To derive the solution, we simplify playing the minimax game with the above Lagrangian to the following objective: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{q_{t}}\\operatorname*{min}_{\\nu_{t}}\\ -\\operatorname{\\mathbb{E}}\\left[{\\frac{1}{q_{t}(X)}}\\cdot(r(X,Y,\\beta)-\\widehat{r}_{t}(X,\\beta))^{2}\\right]-\\nu_{t}(\\mathbb{E}[q_{t}(X)]-B)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "In the case of both \u201cpretrain\u201d and \u201clearned\u201d methods, we parameterize our $q_{t}$ in the following fashion: ", "page_idx": 15}, {"type": "equation", "text": "$$\nq_{t}(x)=\\frac{\\widehat{\\sigma}_{t}(x,\\widehat{\\beta}_{t-1})}{\\exp(c_{t})},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where our normalization constant $C_{t}=\\exp(c_{t})$ for some value $c_{t}\\in\\mathbb{R}$ to ensure it is nonnegative. ", "page_idx": 15}, {"type": "text", "text": "${\\widehat{\\sigma}}_{t}$ is updated separately. For \u201cpretrain\u201d, it is fixed from the beginning, and for \u201clearned\u201d, we take an optimization step to minimize the squared loss against the squared residual, i.e., we update to minimize $((r(X,\\hat{Y_{,}}\\hat{\\beta})-\\widehat{r}_{t}(X,\\beta))^{2}-\\hat{\\varpi}_{t}(X,\\beta)^{2})^{2}$ . ", "page_idx": 15}, {"type": "text", "text": "Hence, the only thing that remains to optimize $c_{t}$ , which now simply means we need to solve the following problem (where we treat $\\widehat{\\beta}_{t-1}$ as fixed): ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{c_{t}}\\operatorname*{min}_{\\nu_{t}}\\,-\\,c_{t}+\\nu_{t}\\left(\\frac{1}{\\exp(c_{t})}\\mathbb{E}[\\widehat{\\sigma}_{t}(X,\\widehat{\\beta}_{t-1})]-B\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The actual game payoff we play is the stochastic approximation of the Lagrangian in the following form: ", "page_idx": 15}, {"type": "equation", "text": "$$\nL(\\nu_{t},c_{t})=-c_{t}-\\nu_{t}\\left(\\frac{\\widehat{\\sigma}_{t}(X_{t},\\widehat{\\beta}_{t-1})}{\\exp(c_{t})}-B\\right).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "At each step, we take an optimization step on $c_{t}$ towards maximizing the above loss, and determine $\\nu_{t}$ by playing either best response or a windowed best response that takes an average of best responses over recent rounds. We use the COCOB optimizer [23] for all of learning and optimization which requires no hyperparameter or learning rate selection. ", "page_idx": 15}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 16}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 16}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 16}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 16}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \u201d[Yes] \u201d is generally preferable to \u201d[No] \u201d, it is perfectly acceptable to answer \u201d[No] \u201d provided a proper justification is given (e.g., \u201derror bars are not reported because it would be too computationally expensive\u201d or \u201dwe were unable to find the license for the dataset we used\u201d). In general, answering \u201d[No] \u201d or \u201d[NA] \u201d is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 16}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 16}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\u201d, \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 16}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Justification: We provide exactly what we describe in the abstract/introduction, i.e., a method for constructing active, anytime-valid risk controlling prediction sets along with theoretical guarantees and experiments demonstrating its efficacy. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 16}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 16}, {"type": "text", "text": "Justification: We elaborate on the limitations of the paper in Section 6 ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 17}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Justification: We provide proofs and assumptions for each result (clearly delineated) in the paper. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 17}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Justification: We provide the code for reproducing the experiments in a supplement. Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 18}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: We provide all code for reproducing the experiments in the paper in a supplement (see above). ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. ", "page_idx": 18}, {"type": "text", "text": "\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). \u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 19}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We provide experimental overview in Section 4, and we provide additional details in both the code and the appendix (Appendix B). ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 19}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We show error bars (from $95\\%$ normal CIs) for all our experiments. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 19}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 19}, {"type": "text", "text": "Justification: We specify our compute resources in Section 4. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: \u2022 The answer NA means that the paper does not include experiments. ", "page_idx": 19}, {"type": "text", "text": "\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: I have reviewed the ethics guidelines and this paper conforms with it. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 20}, {"type": "text", "text": "Justification: Our work is statistical methodology/theory for enabling active labeling for risk control \u2014 it may allow users of machine learning models more cost-effectively calibrate their models to control measures of harmful risk when using them in practice, but there are no direct societal impacts as far as we can discern. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 20}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 21}, {"type": "text", "text": "Justification: Our paper does not release new data/models. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: Yes, we properly cite the papers for which we use models, code, and data from (e.g, Imagenet, RCPS, etc.). ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 21}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: We provide our experimental code in the supplement and provide details about it in Appendix B. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 21}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: We don\u2019t perform human research for this paper. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 22}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: We don\u2019t perform human research in this paper. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 22}]