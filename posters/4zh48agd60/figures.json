[{"figure_path": "4ZH48aGD60/figures/figures_3_1.jpg", "caption": "Figure 1: Diagram of the active labeling setup for ensuring anytime-valid risk control.", "description": "This figure illustrates the active learning setup used for anytime-valid risk control.  Data points (X<sub>t</sub>, Y<sub>t</sub>) arrive sequentially. A labeling policy q(X<sub>t</sub>) determines whether to query the true label Y<sub>t</sub> for each data point.  If the label is queried (L<sub>t</sub> = 1), the incurred risk r(X<sub>t</sub>, Y<sub>t</sub>, \u03b2) is calculated for each candidate \u03b2; otherwise, the risk is treated as 0. A risk estimate \ud835\udc5f\u0303(X<sub>t</sub>, \u03b2) is optionally used to reduce risk variance.  The threshold \u03b2<sub>t-1</sub> is updated based on the incurred risk, aiming for a sequence of safe \u03b2 values such that p(\u03b2<sub>t</sub>) \u2264 \u03b8 (risk control guarantee). The final \u03b2<sub>t</sub> is deployed with risk control.", "section": "2 Anytime-valid risk control through betting"}, {"figure_path": "4ZH48aGD60/figures/figures_8_1.jpg", "caption": "Figure 2: Experimental results for different methods for our numerical simulation setup. We can see that \u201cpretrain\u201d and \u201clearned\u201d methods outperform both the \u201call\u201d and \u201coblivious\u201d strategies uniformly numbers across labels queried. In Figure 2a, we show the average rate of safety violations, i.e., the average proportion of trials that \u00dft was unsafe and p(\u03b2t) > 0 at any time step. We can see that all methods control the desired safety violation rate at the predetermined level a.", "description": "This figure presents the results of numerical simulations comparing four different methods for active learning in a risk-control setting. The methods are compared in terms of their label efficiency, measured by the average value of beta_t (\u03b2t) after a given number of labels are queried, and the average rate of safety violations. The results show that the \u2018pretrain\u2019 and \u2018learned\u2019 methods outperform the \u2018all\u2019 and \u2018oblivious\u2019 strategies, achieving similar levels of safety while using fewer labels. This highlights the effectiveness of using pretrained models to estimate the optimal labeling policies and predictors in this framework.", "section": "4.1 Numerical simulations"}, {"figure_path": "4ZH48aGD60/figures/figures_9_1.jpg", "caption": "Figure 2: Experimental results for different methods for our numerical simulation setup. We can see that \u201cpretrain\u201d and \u201clearned\u201d methods outperform both the \u201call\u201d and \u201coblivious\u201d strategies uniformly across numbers of labels queried. In Figure 2a, we show the average rate of safety violations, i.e., the average proportion of trials that \u00dft was unsafe and p(\u03b2t) > 0 at any time step. We can see that all methods control the desired safety violation rate at the predetermined level \u03b1.", "description": "The figure shows the results of numerical simulations comparing four methods for active, anytime-valid risk control.  The \"pretrain\" and \"learned\" methods outperform the baseline \"all\" and \"oblivious\" methods, achieving lower average values of \u03b2\u0302t (a measure of risk) over time. The figure demonstrates that all methods maintain the desired safety violation rate, indicating effective risk control.", "section": "4.1 Numerical simulations"}]