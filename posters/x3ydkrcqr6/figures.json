[{"figure_path": "X3ydKRcQr6/figures/figures_1_1.jpg", "caption": "Figure 1: MUVERA's two-step retrieval process, compared to PLAID's multi-stage retrieval process. Diagram on the right from Santhanam et. al. [43] with permission.", "description": "This figure compares the retrieval processes of MUVERA and PLAID. MUVERA uses a two-step process: First, it constructs fixed-dimensional encodings (FDEs) of queries and documents and performs a single-vector maximum inner product search (MIPS) using these FDEs.  Then, it reranks the top K candidates using Chamfer similarity. In contrast, PLAID uses a more complex four-stage process that involves multiple rounds of candidate generation, centroid interaction (with and without pruning), and final re-ranking with decompression.  The diagram highlights the relative simplicity and efficiency of MUVERA compared to PLAID.", "section": "1 Introduction"}, {"figure_path": "X3ydKRcQr6/figures/figures_4_1.jpg", "caption": "Figure 2: FDE Generation Process. Three SimHashes (ksim = 3) split space into six regions labelled A-F (in high-dimensions B = 2ksim, but B = 6 here since d = 2). Fq(Q), Fdoc(P) are shown as B \u00d7 d matrices, where the k-th row is q(k), p(k). The actual FDEs are flattened versions of these matrices. Not shown: inner projections, repetitions, and fill_empty_clusters.", "description": "This figure illustrates the process of generating Fixed Dimensional Encodings (FDEs) in MUVERA.  It uses SimHash to partition the data space into clusters.  The process shows how query and document multi-vector sets are transformed into single fixed-dimensional vectors (FDEs) by summarizing embeddings within each cluster. The figure simplifies the process to 2 dimensions and 3 SimHashes for clarity, while the actual implementation handles higher dimensions and multiple repetitions for improved accuracy. The final FDEs are obtained by concatenating the cluster summaries, but inner projections and a cluster filling step (not shown) are also performed to improve quality.", "section": "2 Fixed Dimensional Encodings"}, {"figure_path": "X3ydKRcQr6/figures/figures_6_1.jpg", "caption": "Figure 3: FDE recall vs dimension for varying FDE parameters on MS MARCO. Plots show FDE Recall@100,1k, 10k left to right. Recalls@N for exact Chamfer scoring is shown by dotted lines.", "description": "This figure shows the relationship between the dimensionality of the Fixed Dimensional Encoding (FDE) and its recall performance on the MS MARCO dataset.  Three different recall levels (@100, @1000, @10000) are plotted for different FDE parameters. The dotted lines represent the recall achieved using the exact Chamfer similarity calculation, providing a baseline for comparison.  The figure demonstrates how increasing the dimensionality of the FDEs improves recall, gradually approaching the performance of the exact Chamfer similarity.", "section": "3.1 Offline Evaluation of FDE Quality"}, {"figure_path": "X3ydKRcQr6/figures/figures_6_2.jpg", "caption": "Figure 10: FDE retrieval vs SV Heuristic, Recall@100-5000", "description": "This figure compares the recall performance of the proposed FDE (Fixed Dimensional Encoding) method against the Single-Vector heuristic method at different recall levels (Recall@100-5000) across six different datasets. The FDE method uses four different dimensionality settings for its embeddings, while the SV heuristic uses two approaches: one without deduplication and one with deduplication of document IDs. The graph shows the recall at different N values for each method, allowing for a clear comparison of the performance on different datasets and with different dimensionalities.", "section": "3.1 Offline Evaluation of FDE Quality"}, {"figure_path": "X3ydKRcQr6/figures/figures_7_1.jpg", "caption": "Figure 5: FDE retrieval vs SV Heuristic, both with and without document id deduplication.", "description": "This figure compares the performance of Fixed Dimensional Encoding (FDE) based retrieval against the Single-Vector (SV) heuristic, a method commonly used in multi-vector retrieval systems like PLAID. The SV heuristic involves querying a single-vector MIPS index for each query token to find initial candidate documents and then re-ranking them using the Chamfer similarity. The figure shows the Recall@N (the fraction of queries where the Chamfer 1-nearest neighbor is among the top-N most similar in either method) for both approaches, with and without deduplication (removing duplicate documents from the candidate list) of the SV heuristic results. The results demonstrate that FDEs significantly outperform the SV heuristic, especially in achieving high recall with fewer candidate documents.", "section": "3.1 Offline Evaluation of FDE Quality"}, {"figure_path": "X3ydKRcQr6/figures/figures_8_1.jpg", "caption": "Figure 6: Plots showing the trade-off between the threshold used for ball carving and the end-to-end recall.", "description": "This figure displays the relationship between the threshold used for ball carving and the resulting end-to-end recall at k=100 and k=1000 for three different datasets: MS MARCO, Quora, and NQ.  The x-axis represents the ball carving threshold, and the y-axis represents the Recall@k. Each line shows the Recall@k as the threshold changes.  The plots demonstrate that there is a trade-off between the recall and the threshold value. At lower thresholds, more query embeddings are used leading to higher recall, and at higher thresholds, fewer embeddings result in lower recall, however, with significant computational speed-up.", "section": "3.2 Online Implementation and End-to-End Evaluation"}, {"figure_path": "X3ydKRcQr6/figures/figures_8_2.jpg", "caption": "Figure 14: Plots showing the QPS vs. Recall@100 for MUVERA on the BEIR datasets we evaluate in this paper. The different curves are obtained by using different PQ methods on 10240-dimensional FDEs.", "description": "This figure shows the trade-off between the speed (queries per second, QPS) and the recall@100 of the MUVERA model for six different datasets from the BEIR benchmark.  Different curves represent the results obtained using various product quantization (PQ) methods to compress the 10240-dimensional fixed dimensional encodings (FDEs).  The plot helps to visualize how compression impacts both retrieval speed and accuracy.", "section": "3.2 Online Implementation and End-to-End Evaluation"}, {"figure_path": "X3ydKRcQr6/figures/figures_9_1.jpg", "caption": "Figure 8: Bar plots showing the latency and Recall@k of MUVERA vs PLAID on a subset of the BEIR datasets. The x-tick labels are formatted as dataset-k, i.e., optimizing for Recall@k on the given dataset.", "description": "This figure compares the performance of MUVERA and PLAID on several BEIR datasets for different recall@k values (k=100 and k=1000).  Two separate bar charts are shown, one for latency (lower is better) and one for recall (higher is better). Each bar represents a specific dataset and k value combination.  The chart shows MUVERA consistently outperforms PLAID in terms of latency while maintaining comparable recall, often exceeding PLAID's recall.", "section": "3 Evaluation"}, {"figure_path": "X3ydKRcQr6/figures/figures_20_1.jpg", "caption": "Figure 3: FDE recall vs dimension for varying FDE parameters on MS MARCO. Plots show FDE Recall@100,1k,10k left to right. Recalls@N for exact Chamfer scoring is shown by dotted lines.", "description": "This figure shows the relationship between the recall of the Fixed Dimensional Encoding (FDE) method and its dimensionality on the MS MARCO dataset.  It presents three plots representing Recall@100, Recall@1000, and Recall@10000 across different FDE dimensionalities.  Each plot includes multiple lines, representing different parameter settings used for generating FDEs, revealing how different parameters impact recall.  The dotted lines in each plot represent the recall achieved using the exact Chamfer similarity, providing a benchmark for comparing the accuracy of FDE approximations against the optimal score.", "section": "3.1 Offline Evaluation of FDE Quality"}, {"figure_path": "X3ydKRcQr6/figures/figures_20_2.jpg", "caption": "Figure 5: FDE retrieval vs SV Heuristic, both with and without document id deduplication.", "description": "This figure compares the recall performance of the proposed FDE (Fixed Dimensional Encoding) retrieval method against the single-vector (SV) heuristic retrieval method.  The SV heuristic is a common approach in multi-vector retrieval that uses single-vector MIPS (Maximum Inner Product Search) to find initial candidates, which are then re-ranked using Chamfer similarity. The figure shows that FDE retrieval consistently outperforms the SV heuristic, especially when document ID deduplication is considered. The FDE method achieves higher Recall@N (number of relevant documents retrieved among the top N) than the SV heuristic, even when the SV heuristic uses a larger number of candidates (as indicated by the larger Recall@N values on the x-axis for the SV heuristic). The results suggest that the FDE method is a more effective approach for multi-vector retrieval.", "section": "3.1 Offline Evaluation of FDE Quality"}, {"figure_path": "X3ydKRcQr6/figures/figures_21_1.jpg", "caption": "Figure 3: FDE recall vs dimension for varying FDE parameters on MS MARCO. Plots show FDE Recall@100,1k, 10k left to right. Recalls@N for exact Chamfer scoring is shown by dotted lines.", "description": "This figure displays the relationship between the dimensionality of Fixed Dimensional Encodings (FDEs) and their recall performance on the MS MARCO dataset.  It shows how recall@100, recall@1000, and recall@10000 change as the dimensionality of FDEs increases, and compares those results to the recalls achieved using exact Chamfer similarity scoring.  The dotted lines represent exact Chamfer results, while the solid lines represent results from different sets of FDE parameters.", "section": "3.1 Offline Evaluation of FDE Quality"}, {"figure_path": "X3ydKRcQr6/figures/figures_22_1.jpg", "caption": "Figure 13: Per-Core Re-ranking QPS versus Ball Carving Threshold, on MS MARCO dataset.", "description": "This figure shows the trade-off between the threshold used for ball carving and the end-to-end queries per second (QPS) on the MS MARCO dataset.  Two lines are plotted, one showing sequential re-ranking performance and another parallel. As the threshold increases (meaning fewer clusters are made), the QPS for sequential re-ranking increases, while the QPS for parallel re-ranking stays relatively flat and slightly lower than the sequential approach.", "section": "3.2 Online Implementation and End-to-End Evaluation"}, {"figure_path": "X3ydKRcQr6/figures/figures_22_2.jpg", "caption": "Figure 14: Plots showing the QPS vs. Recall@100 for MUVERA on the BEIR datasets we evaluate in this paper. The different curves are obtained by using different PQ methods on 10240-dimensional FDEs.", "description": "This figure shows the trade-off between the speed (queries per second, QPS) and the recall@100 of the MUVERA model on six different datasets from the BEIR benchmark. Different curves represent different product quantization (PQ) methods used to compress the 10240-dimensional fixed dimensional encodings (FDEs).  The plot demonstrates the impact of compression on both speed and retrieval accuracy.  Generally, higher compression leads to higher QPS but slightly lower recall.", "section": "3.2 Online Implementation and End-to-End Evaluation"}, {"figure_path": "X3ydKRcQr6/figures/figures_23_1.jpg", "caption": "Figure 1: MUVERA's two-step retrieval process, compared to PLAID's multi-stage retrieval process. Diagram on the right from Santhanam et. al. [43] with permission.", "description": "This figure compares the retrieval processes of MUVERA and PLAID.  MUVERA uses a two-stage process:  First, it constructs fixed dimensional encodings (FDEs) and performs a query maximum inner product search (MIPS). Second, it performs Chamfer reranking.  In contrast, PLAID uses a four-stage process involving initial candidate generation, centroid interaction with pruning, centroid interaction without pruning, and final ranking with decompression. The diagram illustrates the multiple steps in PLAID's process, highlighting its complexity compared to MUVERA's streamlined approach.", "section": "1 Introduction"}]