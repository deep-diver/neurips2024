[{"figure_path": "lpXDZKiAnt/tables/tables_5_1.jpg", "caption": "Table 1: Performance under different harmful ratio.", "description": "This table presents the performance of various methods (Non-Aligned, SFT, EWC, Vlguard, KL, and Vaccine) under different harmful ratios (0.01, 0.05, 0.1, 0.2).  For each method and harmful ratio, the harmful score (lower is better) and fine-tune accuracy (higher is better) are reported. The average performance across all harmful ratios is also provided.  This allows for comparison of the robustness of different alignment strategies to harmful data during fine-tuning.", "section": "5.2 Main Evaluation"}, {"figure_path": "lpXDZKiAnt/tables/tables_6_1.jpg", "caption": "Table 1: Performance under different harmful ratio.", "description": "This table presents the performance of different methods (Non-Aligned, SFT, EWC, Vlguard, KL, and Vaccine) under varying harmful ratios (0.01, 0.05, 0.1, and 0.2) in the fine-tuning stage.  The metrics used are Harmful Score (lower is better) and Fine-tune Accuracy (higher is better).  The table shows how each method's robustness to harmful data impacts both the safety (harmful score) and the effectiveness (fine-tune accuracy) of the fine-tuned model.", "section": "5.2 Main Evaluation"}, {"figure_path": "lpXDZKiAnt/tables/tables_6_2.jpg", "caption": "Table 2: Performance on different samples number under default setting.", "description": "This table presents the performance of different methods under various numbers of fine-tuning samples while keeping the harmful data ratio constant at 0.05.  It shows how the harmful score and fine-tune accuracy change as the number of samples increases, allowing for an analysis of the robustness of different approaches to varying amounts of training data.", "section": "5.2 Main Evaluation"}, {"figure_path": "lpXDZKiAnt/tables/tables_6_3.jpg", "caption": "Table 3: Performance on different models under default setting.", "description": "This table presents the results of the main evaluation comparing the performance of four different methods (Non-Aligned, SFT, EWC, and Vaccine) across three different large language models (LLMs): OPT-2.7B, Llama2-7B, and Vicuna-7B. The evaluation is performed on the SST2 dataset, measuring both the harmful score (HS) and fine-tune accuracy (FA). Lower HS indicates better safety performance, while higher FA represents better accuracy on the downstream task.  The table shows how Vaccine consistently outperforms other baselines in terms of harmful score reduction while maintaining high fine-tune accuracy.", "section": "5.2 Main Evaluation"}, {"figure_path": "lpXDZKiAnt/tables/tables_7_1.jpg", "caption": "Table 4: Performance on different datasets under default setting.", "description": "This table presents the results of the experiments conducted on four different datasets (SST2, AGNEWS, GSM8K, and AlpacaEval) using the Llama2-7B model.  The table shows the harmful score (HS) and fine-tune accuracy (FA) for each dataset, comparing the performance of four different methods: Non-Aligned, SFT, EWC, and Vaccine.  Lower HS values indicate better performance in mitigating harmful outputs, while higher FA values indicate better performance on the downstream task.", "section": "5.2 Main Evaluation"}, {"figure_path": "lpXDZKiAnt/tables/tables_7_2.jpg", "caption": "Table 5: Training time/GPU memory consumption of Vaccine. Training time is the clock time for each gradient step. Experiment is done with an A100 GPU.", "description": "This table presents a comparison of the training time and GPU memory consumption for the Vaccine method and the standard SFT method, using different language models (OPT-2.7B, Llama2-7B, and Vicuna-7B).  It shows that Vaccine takes approximately twice as long to train as SFT, but the increase in memory usage is minimal.", "section": "5.3 Statistical/System Analysis"}, {"figure_path": "lpXDZKiAnt/tables/tables_8_1.jpg", "caption": "Table 6: Performance on different perturbation intensity p. Alignment loss (FS) and Alignment loss (LS) respectively means alignment loss in the First Step and Last Step of fine-tuning.", "description": "This table presents the results of an ablation study on the effect of perturbation intensity (p) on the Vaccine model's performance.  It shows the harmful score (HS), fine-tune accuracy (FA), alignment loss at the first step (FS), and alignment loss at the last step (LS) for different values of p.  The results demonstrate the trade-off between reducing the harmful score and maintaining high accuracy as p increases.  Lower p values result in higher accuracy but potentially higher harmful scores, while higher p values lead to lower harmful scores but might reduce accuracy.", "section": "5.4 Ablation Study and Hyper-parameter Analysis"}, {"figure_path": "lpXDZKiAnt/tables/tables_8_2.jpg", "caption": "Table 7: Performance between random perturbation and gradient-based perturbation. p' is the variance of the Gaussian perturbation with mean equals to 0.", "description": "This table compares the performance of using random Gaussian perturbation versus gradient-based perturbation in the Vaccine model.  It shows the harmful score (HS) and fine-tune accuracy (FA) for different perturbation intensity levels (p' and p).  The results indicate that gradient-based perturbation generally outperforms random perturbation in achieving a lower harmful score while maintaining higher accuracy.", "section": "5.4 Ablation Study and Hyper-parameter Analysis"}, {"figure_path": "lpXDZKiAnt/tables/tables_8_3.jpg", "caption": "Table 8: Performance when applying Double-LoRA (DL) and Single-LoRA (SL).", "description": "This table compares the performance of using single and double LoRA adaptors in both SFT and Vaccine methods across three different datasets (SST2, AGNEWS, and GSM8K).  The metrics are harmful score (HS) and fine-tune accuracy (FA).  Double-LoRA uses separate adaptors for alignment and fine-tuning, while Single-LoRA uses a single adaptor for both stages. The results show that generally, both Vaccine and SFT perform better with Double-LoRA across datasets, although the performance differences vary depending on the dataset.", "section": "5.5 Alternative Design"}, {"figure_path": "lpXDZKiAnt/tables/tables_8_4.jpg", "caption": "Table 9: Performance combining EWC in user fine-tuning. \u03bb is the regularization intensity.", "description": "This table presents the results of an ablation study comparing the performance of Vaccine with and without Elastic Weight Consolidation (EWC) during the user fine-tuning stage.  The study evaluates the Harmful Score (HS) and Fine-tune Accuracy (FA) on three different datasets (SST2, AGNEWS, GSM8K) under various regularization intensities (\u03bb). The purpose is to analyze how incorporating EWC, a technique designed to mitigate catastrophic forgetting, affects the robustness and accuracy of Vaccine's alignment solution when dealing with potentially harmful user data.", "section": "5.5 Alternative Design"}, {"figure_path": "lpXDZKiAnt/tables/tables_16_1.jpg", "caption": "Table 10: Performance evaluation of Accelerated Vaccine. As shown, Accelerated Vaccine with proper perturbation periodicity can maintain defense performance, while significantly reducing the training step time.", "description": "This table presents the results of evaluating the Accelerated Vaccine algorithm.  It shows that by adjusting the frequency of perturbation updates (the parameter '\u03c4'), the algorithm can maintain its effectiveness in reducing harmful scores, while significantly decreasing training time.  The table compares the performance of the standard Vaccine, Accelerated Vaccine with different values of \u03c4, and SFT (Supervised Fine-Tuning) against the metrics of harmful score, fine-tune accuracy, and training time. This demonstrates the trade-off between computational efficiency and model robustness.", "section": "5.4 Ablation Study and Hyper-parameter Analysis"}, {"figure_path": "lpXDZKiAnt/tables/tables_22_1.jpg", "caption": "Table 11: System performance comparison between different methods. Evaluation is done with an H100 with 80GB memory.", "description": "This table compares the system performance (memory usage and step time) of three methods: SFT (Supervised Fine-Tuning), RepNoise, and Vaccine, across four different model sizes (OPT-1.3B, OPT-2.7B, OPT-6.7B, OPT-13B).  It highlights the additional resource requirements of the proposed Vaccine method relative to the baseline SFT and a comparable method, RepNoise, emphasizing its computational efficiency compared to RepNoise.", "section": "5.3 Statistical/System Analysis"}]