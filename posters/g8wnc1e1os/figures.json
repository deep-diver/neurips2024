[{"figure_path": "g8wnC1E1OS/figures/figures_1_1.jpg", "caption": "Figure 1: Motivation. Client parameter importance degree similarity (Left) shows difference between benign and malicious groups. The parameter important value distribution (Right) reveals that benign and malicious highlight different elements.", "description": "The figure demonstrates the difference in parameter importance between benign and malicious clients. The left panel shows a similarity matrix representing the pairwise similarity of parameter importance across clients, where benign and malicious clients show distinct patterns.  The right panel displays the distribution of parameter importance values, highlighting that benign and malicious clients emphasize different parameters, supporting the core idea of the proposed method (FDCR).", "section": "3.2 Fisher Discrepancy Cluster and Recale"}, {"figure_path": "g8wnC1E1OS/figures/figures_7_1.jpg", "caption": "Figure 2: Observation of gradient difference Vk Eq. (9b) (Left) and aggregation weight ak Eq. (11) (Right) on Cifar-10 and Fashion-MNIST scenarios (\u03b2=0.5,Y=30%). Backdoor attackers appear large Vk and thus are gradually removed via aggregation weight @k = 0. Please see details in Sec. 4.3.", "description": "This figure shows the gradient difference (Vk) and aggregation weight (ak) over communication rounds for both Cifar-10 and Fashion-MNIST datasets.  It illustrates how the proposed FDCR method identifies and mitigates backdoor attacks.  The left plots show that malicious clients (labeled as \"Evil\") exhibit significantly larger gradient differences (Vk) compared to benign clients (\"Benign\").  The right plots demonstrate how the aggregation weights (ak) for malicious clients are reduced to zero over time, effectively removing their influence on the global model update. This visualization supports the effectiveness of the FDCR method in identifying and excluding malicious clients from the federated learning process.", "section": "4.3 Diagnostic Experiments"}, {"figure_path": "g8wnC1E1OS/figures/figures_8_1.jpg", "caption": "Figure 2: Observation of gradient difference Vk Eq. (9b) (Left) and aggregation weight ak Eq. (11) (Right) on Cifar-10 and Fashion-MNIST scenarios (\u03b2=0.5,Y=30%). Backdoor attackers appear large Vk and thus are gradually removed via aggregation weight @k = 0. Please see details in Sec. 4.3.", "description": "This figure displays the gradient difference (Vk) and aggregation weight (ak) across communication rounds for Cifar-10 and Fashion-MNIST datasets.  It visually demonstrates how the proposed FDCR method identifies and mitigates backdoor attacks by showing that malicious clients exhibit a significantly larger gradient difference (Vk) compared to benign clients. Consequently, their aggregation weights (ak) are reduced to near zero, effectively removing their influence on the global model updates.", "section": "4.3 Diagnostic Experiments"}]