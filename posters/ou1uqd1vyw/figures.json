[{"figure_path": "OU1uqd1vyw/figures/figures_2_1.jpg", "caption": "Figure 1: Validation loss and training loss.", "description": "This figure shows the impact of low-quality data on the training and validation loss during collaborative fine-tuning of LLMs. The x-axis represents the number of training steps, and the y-axis represents the loss.  Different lines represent different proportions of low-quality data mixed with high-quality data.  As the proportion of low-quality data increases, both the training and validation loss increase, indicating that the presence of low-quality data negatively affects model performance.", "section": "Remarks 1 (Impact of Low Quality Data in Collaborative Private Domains)"}, {"figure_path": "OU1uqd1vyw/figures/figures_2_2.jpg", "caption": "Figure 2: Performance drop on the performance of collaborative fine-tuning of LLMs when we change the proportion of low-quality data from 0% to 60%. Higher scores indicate better performance.", "description": "This figure shows the performance drop when the proportion of low-quality data increases from 0% to 60% during collaborative fine-tuning of LLMs using two different base models (Mistral-7b and Llama2-7b).  The performance is measured using GPT-4 scoring and Knowledge Average.  The results illustrate a negative correlation between the percentage of low-quality data and model performance, highlighting the importance of high-quality data for effective LLM fine-tuning in collaborative settings.", "section": "2.2 Assumption and Objective: Collaborative High-quality Data Selection for LLMs"}, {"figure_path": "OU1uqd1vyw/figures/figures_3_1.jpg", "caption": "Figure 3: Overall workflow diagram consists of two phases: 1) Step One: client-side computes each sample's quality score with scoring functions using the public validation set and global model, then server-side calculates the score of a global threshold by anchor data 2) Step Two: clients filter data according to the global threshold and starts collaborative learning on selected high-quality data with adaptive weights on the model side.", "description": "This figure illustrates the two-phase workflow of the CLUES method.  In Step One, each client independently computes a quality score for each data sample using local training and a shared public validation set.  These scores are sent to a central server, which uses an \"anchor\" dataset to determine a global quality threshold. In Step Two, each client filters its data, keeping only the samples above the threshold. Then, collaborative fine-tuning is performed, using a model merging strategy to combine the updated models from each client. This collaborative approach ensures that only high-quality data are used in the training of the global model. Adaptive weights might be used on the server side during merging.", "section": "3 Methodology: CLUES"}, {"figure_path": "OU1uqd1vyw/figures/figures_8_1.jpg", "caption": "Figure 4: Experimental results for different levels of low-quality data", "description": "This figure shows the performance of GPT-4 scoring and the global threshold (score) at different proportions of low-quality data (20%, 50%, 80%).  The left graph displays the GPT-4 scoring performance with and without the data selection method applied. The right graph displays the selection accuracy and the global threshold, illustrating how these metrics change with varying levels of low-quality data. The results demonstrate the robustness of the proposed method in handling different proportions of low-quality data.", "section": "5 Analysis"}, {"figure_path": "OU1uqd1vyw/figures/figures_8_2.jpg", "caption": "Figure 4: Experimental results for different levels of low-quality data", "description": "This figure shows the experimental results obtained with varying proportions of low-quality data.  Panel (a) displays the GPT-4 scoring performance, illustrating how performance degrades as the percentage of low-quality data increases. Panel (b) shows the selection accuracy and the global threshold score, demonstrating the robustness of the data selection method even with a significant portion of low-quality data.  The global threshold score adjusts dynamically to account for varying levels of data quality.", "section": "4 Analysis"}, {"figure_path": "OU1uqd1vyw/figures/figures_8_3.jpg", "caption": "Figure 4: Experimental results for different levels of low-quality data", "description": "This figure presents the experimental results showing the impact of varying proportions of low-quality data on model performance.  It includes two subfigures: (a) illustrates the GPT-4 scoring performance across different proportions of low-quality data, highlighting the effect of low-quality data on the model's performance. (b) shows the data selection accuracy and the global threshold score (a unified standard of data quality) for different levels of low-quality data, demonstrating how the global threshold adapts to changing data quality. The results show that the proposed method effectively enhances data quality across all scenarios, even with high proportions of low-quality data.", "section": "5 Analysis"}, {"figure_path": "OU1uqd1vyw/figures/figures_15_1.jpg", "caption": "Figure 3: Overall workflow diagram consists of two phases: 1) Step One: client-side computes each sample's quality score with scoring functions using the public validation set and global model, then server-side calculates the score of a global threshold by anchor data 2) Step Two: clients filter data according to the global threshold and starts collaborative learning on selected high-quality data with adaptive weights on the model side.", "description": "This figure illustrates the two-phase workflow of CLUES.  In Phase 1 (Local Training for Data Quality Scoring), each client independently scores the quality of their data using a scoring function, leveraging a public validation dataset and a globally shared model. The server aggregates these scores and determines a global quality threshold based on an anchor dataset. In Phase 2 (Collaborative Training with High-Quality Data), clients filter their data based on this threshold, retaining only high-quality samples.  They then engage in collaborative training (e.g., via model merging or federated learning), using the selected high-quality data. Adaptive weights can be applied to the model side to further refine performance.", "section": "3 Methodology: CLUES"}]