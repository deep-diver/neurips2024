[{"figure_path": "BRW0MKJ7Rr/tables/tables_7_1.jpg", "caption": "Table 1: Hyperparameters", "description": "This table lists the hyperparameters used in the simulations for the tested algorithms.  It includes parameters common to all algorithms (replay buffer sampling, capacity, batch size, optimizer, learning rate, discount factor, target network update period) and algorithm-specific parameters (e-greedy exploration parameter, value network architecture, advantage network architecture, number of atoms, quantile Huber parameter K) for DAU, QR-DQN, DSUP and DAU+DSUP. Note that although the original DAU implementation scaled the learning rate with h, the authors use an alternative approach by updating every h\u207b\u00b9 environment steps.", "section": "5.2 High-Frequency Option Trading"}, {"figure_path": "BRW0MKJ7Rr/tables/tables_26_1.jpg", "caption": "Table 1: Hyperparameters", "description": "This table lists the hyperparameters used in the simulations for the algorithms tested in the paper.  It specifies the parameter, its value, and whether the value is uniform across all methods or specific to a particular algorithm (DAU, QR-DQN, DSUP, or DAU+DSUP). Parameters include those for replay buffer management, optimization, discounting, target network updates, exploration, network architectures, and quantile regression.", "section": "E.2 Hyperparameters"}]