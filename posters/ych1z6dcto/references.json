{"references": [{"fullname_first_author": "A. G. Baydin", "paper_title": "Gradients without backpropagation", "publication_date": "2022-02-14", "reason": "This paper introduces the concept of forward gradients, a core methodology of this paper, showing that gradients can be computed solely based on directional derivatives without backpropagation."}, {"fullname_first_author": "S. Malladi", "paper_title": "Fine-tuning language models with just forward passes", "publication_date": "2023-05-17", "reason": "This paper demonstrates the practical applicability of forward gradients on large language models, providing further support to the proposed method."}, {"fullname_first_author": "L. Fournier", "paper_title": "Can forward gradient match backpropagation?", "publication_date": "2023-06-12", "reason": "This paper investigates the capabilities of forward gradients in matching the performance of backpropagation, directly addressing a key concern of the proposed approach."}, {"fullname_first_author": "M. Ren", "paper_title": "Scaling forward gradient with local losses", "publication_date": "2022-10-12", "reason": "This paper addresses the challenges of forward gradients in high-dimensional spaces, offering solutions and insights relevant to practical implementation."}, {"fullname_first_author": "J. Lin", "paper_title": "On-device training under 256kb memory", "publication_date": "2022-06-07", "reason": "This paper tackles the challenges of on-device training with limited memory, providing a strong background and motivation for the proposed approach."}]}