[{"figure_path": "ypPzyflbYs/figures/figures_1_1.jpg", "caption": "Figure 1: Unsupervised learning of concepts for visual reasoning. (left) Models that learn concepts from unlabeled data require inspectable and revisable concept representations. (right) Concepts obtained from the Neural Concept Binder (NCB) can be utilized both in (interpretable) neural and symbolic computations.", "description": "This figure illustrates the unsupervised learning of concepts for visual reasoning. The left panel highlights the challenge of learning inspectable and revisable concepts from unlabeled data, emphasizing the need for human users to understand and correct the model's learned concepts.  The right panel introduces the Neural Concept Binder (NCB) as a solution. NCB generates both interpretable neural and symbolic concept representations, enabling intuitive inspection, straightforward integration of external knowledge, and seamless integration into both neural and symbolic modules for complex reasoning tasks. The figure visually depicts the NCB workflow, from input data to the generation of concept representations used for both neural and symbolic reasoning.", "section": "1 Introduction"}, {"figure_path": "ypPzyflbYs/figures/figures_2_1.jpg", "caption": "Figure 2: The Neural Concept Binder (NCB) combines continuous, block-slot encodings via slot-attention based image processing with discrete, concept-slot encodings via retrieval-based inference. The structured retrieval corpus (distilled from the block-slot encodings) allows for easy concept inspection and revision by human stakeholders. Moreover, the resulting concept-slot encodings can be easily integrated into complex downstream tasks.", "description": "This figure illustrates the Neural Concept Binder (NCB) framework.  It shows how NCB combines two types of binding: soft binding (using SysBinder for object-factor disentanglement) and hard binding (using hierarchical clustering and retrieval-based inference). The soft binding produces continuous block-slot encodings, which are then used to create a retrieval corpus of discrete concept-slot encodings.  This corpus allows for easy inspection and revision of concepts by human stakeholders.  Finally, the concept-slot encodings can be used in downstream tasks.", "section": "3 Neural Concept Binder (NCB): Extracting Hard from Soft Concepts"}, {"figure_path": "ypPzyflbYs/figures/figures_4_1.jpg", "caption": "Figure 3: NCB's concept space is inherently inspectable. A human stakeholder can easily inspect the concept space by asking a diverse set of questions. For example, NCB answers interventional questions (iii) via generating images with selectively modified concepts.", "description": "This figure demonstrates the inherent inspectability of the Neural Concept Binder (NCB)'s concept space.  It shows how a human user can interact with the model by asking different types of questions to understand its learned concepts.  Four types of inspection are shown: (i) Implicit, which asks for examples of a concept; (ii) Comparative, which compares two concepts; (iii) Interventional, which shows what happens when a concept is altered; and (iv) Similarity, which shows similar concepts.  This illustrates the NCB's ability to provide human-understandable feedback, improving model trust and allowing for easy revision of the learned concepts.", "section": "3.3 Inspecting and Revising NCB's Concepts"}, {"figure_path": "ypPzyflbYs/figures/figures_6_1.jpg", "caption": "Figure 4: Example from CLEVR-Sudoku. Each digit is represented by CLEVR objects with the same attribute combination. The objective is to solve the Sudoku only based on the initial grid of CLEVR images and the digit mapping of candidate examples.", "description": "This figure shows an example of a CLEVR-Sudoku puzzle.  A standard Sudoku grid is shown, but instead of numbers, each cell contains a small image of a 3D object from the CLEVR dataset.  To the right is a key that shows the mapping between the objects and the digits 1-9.  The goal is to solve the Sudoku puzzle by identifying the objects and using the key to translate them into digits.", "section": "4 Experimental Evaluations"}, {"figure_path": "ypPzyflbYs/figures/figures_8_1.jpg", "caption": "Figure 5: NCB\u2019s unsupervised concepts allow solving symbolic puzzles. Accuracy of solved Sudokus via different discrete concept encodings on Sudoku CLEVR-Easy and Sudoku CLEVR (left sides). Additional revision on NCB\u2019s concepts leads to improved performances (right sides).", "description": "This figure shows the results of using different methods for solving Sudoku puzzles with images as input.  The left side compares the performance of using ground truth concepts, supervised slot attention, unsupervised SysBinder, and unsupervised NCB.  The right side shows how performance improves when human feedback or GPT-4 is used to revise the NCB concepts.  The results are shown separately for easier and harder versions of the Sudoku puzzle (CLEVR-Easy and CLEVR).  The figure demonstrates that NCB performs well compared to other unsupervised methods and that concept revision can significantly improve performance.", "section": "4 Experimental Evaluations"}, {"figure_path": "ypPzyflbYs/figures/figures_9_1.jpg", "caption": "Figure 6: NCB's unsupervised concept representations facilitate shortcut mitigation. Test accuracy for classification via NN predictor when trained on confounded images.", "description": "This figure shows the results of a classification task on a dataset with confounding factors.  Three different methods are compared: using only the Neural Concept Binder (NCB) for feature extraction, using NCB and then performing explanatory interactive learning (XIL) on the neural network (NN) classifier, and performing XIL directly on the NCB concepts before classification. The graph plots the accuracy for each method. The results demonstrate that applying XIL directly on the NCB concepts achieves better mitigation of the confounding factors than performing XIL only on the NN classifier. This highlights how NCB's interpretable concepts facilitate a more transparent and effective method for addressing shortcut learning issues.", "section": "4 Experimental Evaluations"}, {"figure_path": "ypPzyflbYs/figures/figures_17_1.jpg", "caption": "Figure 7: Examples of Sudoku CLEVR for different K values.", "description": "This figure shows examples of Sudoku puzzles from the CLEVR-Sudoku dataset for different values of K.  K represents the number of empty cells in the 9x9 Sudoku grid. Each cell contains a CLEVR image representing a digit; different digits are represented by different image attributes (shape and color in CLEVR-Easy, shape, color, size, and material in CLEVR).  The examples illustrate how the difficulty of the puzzle changes with the number of empty cells (K).  A lower K value means more pre-filled cells, making the puzzle easier to solve.", "section": "B Details on CLEVR-Sudoku"}, {"figure_path": "ypPzyflbYs/figures/figures_22_1.jpg", "caption": "Figure 8: Average number of concepts (over all blocks) in NCB's retrieval corpus.", "description": "This figure shows the average number of concepts found across all blocks in the NCB's retrieval corpus for both CLEVR-Easy and CLEVR datasets.  The data suggests a significant difference in the number of concepts learned between the two datasets, indicating a potential relationship between dataset complexity and the number of concepts needed for representation.", "section": "F.3 Analysis of Learned Concept Space"}, {"figure_path": "ypPzyflbYs/figures/figures_23_1.jpg", "caption": "Figure 9: The distribution of number of obtained concepts per block both for CLEVR-Easy and CLEVR. These values are computed over all seeds.", "description": "This boxplot shows the distribution of the number of concepts per block in the Neural Concept Binder (NCB) model when trained on the CLEVR-Easy and CLEVR datasets.  The x-axis represents the dataset (CLEVR-Easy or CLEVR), and the y-axis represents the number of concepts found within each block.  Each boxplot displays the median, quartiles, and outliers of the distribution.  The figure shows a much wider range and greater variability in the number of concepts per block for the CLEVR dataset compared to the CLEVR-Easy dataset, indicating more complexity in the concept representations learned from the CLEVR data.", "section": "F Additional Quantitative Results"}, {"figure_path": "ypPzyflbYs/figures/figures_23_2.jpg", "caption": "Figure 5: NCB's unsupervised concepts allow solving symbolic puzzles. Accuracy of solved Sudokus via different discrete concept encodings on Sudoku CLEVR-Easy and Sudoku CLEVR (left sides). Additional revision on NCB's concepts leads to improved performances (right sides).", "description": "This figure shows the results of using different concept encodings to solve Sudoku puzzles where images are used in place of digits.  The left side compares the performance of using ground truth concepts, supervised slot attention encoder, unsupervised SysBinder, and unsupervised NCB. The right side shows how performance improves with human and GPT-4 revisions of the NCB concepts.", "section": "4 Experimental Evaluations"}, {"figure_path": "ypPzyflbYs/figures/figures_24_1.jpg", "caption": "Figure 5: NCB\u2019s unsupervised concepts allow solving symbolic puzzles. Accuracy of solved Sudokus via different discrete concept encodings on Sudoku CLEVR-Easy and Sudoku CLEVR (left sides). Additional revision on NCB\u2019s concepts leads to improved performances (right sides).", "description": "This figure shows the results of using different concept encodings to solve Sudoku puzzles.  The left side compares the performance of using ground truth concepts, supervised slot attention encodings, unsupervised SysBinder encodings, and unsupervised Neural Concept Binder (NCB) encodings.  The right side shows how revising the NCB concepts, either with GPT-4 or human feedback, impacts the results.  It demonstrates that NCB's unsupervised concepts perform well, particularly when human feedback is used for revision, highlighting the effectiveness of the NCB framework for symbolic reasoning tasks.", "section": "4 Experimental Evaluations"}, {"figure_path": "ypPzyflbYs/figures/figures_24_2.jpg", "caption": "Figure 5: NCB's unsupervised concepts allow solving symbolic puzzles. Accuracy of solved Sudokus via different discrete concept encodings on Sudoku CLEVR-Easy and Sudoku CLEVR (left sides). Additional revision on NCB's concepts leads to improved performances (right sides).", "description": "This figure shows the results of using different concept encodings to solve Sudoku puzzles using images from the CLEVR dataset. The left side compares the performance of ground truth concepts, NCB's unsupervised concepts, supervised concepts from a slot attention encoder, and unsupervised concepts from SysBinder.  The right side shows how human and GPT-4 revisions of NCB's concepts affect performance. The results demonstrate that NCB's unsupervised concepts achieve comparable performance to supervised methods and are easily improved through human revision.", "section": "4 Experimental Evaluations"}, {"figure_path": "ypPzyflbYs/figures/figures_25_1.jpg", "caption": "Figure 13: Test accuracy (%) for classifying objects as placed left or right in a scene.", "description": "This figure shows the test accuracy of a classifier trained to predict whether objects are located on the left or right side of a scene.  Four different NCB configurations are compared: a standard NCB, NCB with concepts merged to represent \"left\" and \"right\", and NCB with 5 and 20 exemplar images added for \"left\" and \"right\" concepts respectively.  The results demonstrate the ability to easily add new concepts and improve accuracy by adding more concept information to NCB.", "section": "F.6 Dynamically Discretising Continuous Factors via Symbolic Revision"}, {"figure_path": "ypPzyflbYs/figures/figures_25_2.jpg", "caption": "Figure 6: NCB\u2019s unsupervised concept representations facilitate shortcut mitigation. Test accuracy for classification via NN predictor when trained on confounded images.", "description": "This figure displays the results of an experiment evaluating the ability of NCB's unsupervised concept representations to mitigate shortcut learning.  Two models were tested: one using supervised concept representations (SA), and one using NCB's unsupervised representations.  The experiment involved training on images with a confounding factor (the color gray) and testing on images without that confounding factor. The results show that NCB\u2019s unsupervised approach was able to achieve comparable performance to the supervised method in mitigating the effects of the confounding factor, demonstrating the effectiveness of NCB in learning robust concept representations.", "section": "4 Experimental Evaluations"}, {"figure_path": "ypPzyflbYs/figures/figures_27_1.jpg", "caption": "Figure 16: Concepts of Block 2 for NCB with CLEVR-Easy. We here provide implicit inspection examples (i.e., via exemplars of each concept). We observe that block 2 appears to encode shape information (concept 1-3) and contains one ambiguous concept (concept 4).", "description": "This figure shows the concepts learned by the Neural Concept Binder (NCB) for Block 2 when trained on the CLEVR-Easy dataset.  It presents example images for each concept, allowing for visual inspection of what features each concept represents.  The caption highlights that Block 2 primarily encodes shape information, though one concept appears ambiguous, suggesting potential issues with the learned concept representation.", "section": "3.3 Inspecting and Revising NCB's Concepts"}, {"figure_path": "ypPzyflbYs/figures/figures_28_1.jpg", "caption": "Figure 17: Concepts of Block 8 for NCB with CLEVR-Easy. We here provide implicit inspection examples (i.e., via exemplars of each concept). We observe that block 8 appears to be encoding color information, contains one ambiguous concept (concept 8) and two concepts that appear to both encode the color purple (concept 9 and 10).", "description": "This figure shows the results of implicit inspection of concepts from block 8 of the Neural Concept Binder (NCB) model trained on the CLEVR-Easy dataset. Each concept is represented by a grid of example images. The figure shows ten concepts identified by the model, with each concept represented by a set of images sharing similar visual characteristics. Concept 8 seems ambiguous, while concepts 9 and 10 both appear to represent the color purple, indicating a potential redundancy in the model's representation.", "section": "3.3 Inspecting and Revising NCB's Concepts"}]