[{"type": "text", "text": "Promoting Fairness Among Dynamic Agents in Online-Matching Markets under Known Stationary Arrival Distributions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Will Ma ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Pan Xu ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Graduate School of Business Columbia University New York, NY 10027   \nwm2428@gsb.columbia.edu   \nDepartment of Computer Science   \nNew Jersey Institute of Technology Newark, NJ 07102 pxu@njit.edu ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Online (bipartite) matching under known stationary arrivals is a fundamental model that has been studied extensively with the objective of maximizing the total number of customers served. We instead study the objective of maximizing the minimum matching rate across all online types, which is referred to as long-run (individual) fairness. For Online Matching under long-run Fairness (OM-LF) with a single offilne agent, we show that the first-come-first-serve (FCFS) policy is 1-competitive, i.e., matching any optimal clairvoyant. For the general case of OM-LF: We present a sampling algorithm (SAMP) and show that (1) SAMP is of competitiveness of at least $1-1/e$ and (2) it is asymptotically optimal with competitiveness approaching one in different regimes when either all offline agents have a sufficiently large matching capacity, or all online types have a sufficiently large arrival rate, or highly imbalance between the total offline matching capacity and the number of online arrivals. To complement the competitive results, we show the following hardness results for OM-LF: (1) Any non-rejecting policy (matching every arriving online agent if possible) is no more than $1/2$ -competitive; (2) Any (randomized) policy is no more than $(\\sqrt{3}-1)$ -competitive; (3) SAMP can be no more than $(1-1/e)$ - competitive suggesting the tightness of competitive analysis for SAMP. We stress that all hardness results mentioned here are independent of any benchmarks. We also consider a few extensions of OM-LF by proposing a few variants of fairness metrics, including long-run group-level fairness and short-run fairness, and we devise related algorithms with provable competitive performance. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "In online (bipartite) matching problems, nodes on one side of a bipartite graph are given in advance, while nodes on the other side arrive one-by-one. We refer to the two sets of nodes as offline and online agents, respectively. The edges incident to an online agent, which indicate the offilne agents eligible to serve it, are revealed upon its arrival. An online matching algorithm must immediately serve each arriving agent using up to one eligible and unmatched offline agent; matches once made cannot be rearranged. The performance of an algorithm is typically evaluated as the total number of matches made, taking expectations as necessary if there is randomness in the arrivals or the algorithm. In this paper, we study online matching problems where performance is instead determined by the fairness in service provided to different online agent types. ", "page_idx": 0}, {"type": "text", "text": "Online Matching under Long-Run Fairness (OM-LF). Suppose there is a bipartite graph $G=$ $(I,J,E)$ , where $I$ and $J$ denote the sets of types for offilne and online agents, respectively. Here each online type is defined based on certain attributes, e.g., race and/or gender identity, which are observed upon arrival. For an offline agent (of type) $i\\in I$ , let ${\\mathcal{N}}_{i}\\subseteq J$ denote the \u201cneighboring\u201d online types that $i$ is eligible to serve. Similarly, for an online agent (of type) $j\\in J$ , let ${\\mathcal{N}}_{j}\\subseteq I$ denote the offilne agent types eligible to serve $j$ .1 Each offilne type $i\\in I$ has an integer capacity $b_{i}\\geq1$ indicating the maximum number of online agents (with types in ${\\mathcal N}_{i}$ ) that $i$ can serve.2 (Arriving Process). Agents of each online type $j\\in J$ arrive according to an independent Poisson process with homogeneous rate $\\lambda_{j}>0$ , over a time horizon scaled to be [0, 1].3 When an online agent arrives in the time horizon [0,1], its type $j$ is revealed, and an online algorithm (or policy) ALG must make an immediate and irreversible decision from two options: either reject $j$ or serve $j$ by assigning it to an offline agent $i\\in\\mathcal N_{j}$ that still has available capacity. For the latter choice, $i$ \u2019s matching capacity will be reduced by one. (Fairness Metric). For each online type $j\\in J$ , let $X_{j}$ be the number of agents $j$ served by ALG and $A_{j}$ the number of $j$ \u2019s arrivals by the end of the time horizon. For any $\\lambda>0$ , let $\\mathrm{Pois}(\\lambda)$ denote a Poisson random variable with mean $\\lambda$ . By our assumption, $A_{j}$ is distributionally identical to a $\\mathrm{Pois}(\\lambda_{j})$ for every $j\\in J$ . Let ${\\mathcal{A}}=(A_{j})_{j\\in J}$ , which is referred to as the (random) arrival vector with each $A_{j}\\sim\\mathrm{Pois}(\\lambda_{j})$ . We define a long-run fairness as follows. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "equation", "text": "$$\n\\mathrm{FAIR-L\\,\\,(Long-Run\\,Fairness)}=\\operatorname*{min}_{j\\in J}\\frac{\\mathbb{E}_{A,\\mathbb{A}\\sqcup\\left[X_{j}\\right]}}{\\mathbb{E}_{A}[A_{j}]}=\\operatorname*{min}_{j\\in J}\\frac{\\mathbb{E}_{A,\\mathbb{A}\\sqcup\\left[X_{j}\\right]}}{\\lambda_{j}}.\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "We aim to design an online algorithm ALG such that the achieved fairness is maximized. Note that all the information mentioned earlier, such as the graph $G=(I,J,E)$ , the capacities of offilne agents $\\{b_{i}|i\\in I\\}$ , and the arrival rates of online agents $\\{\\lambda_{j}|j\\in\\mathcal{I}\\}$ , are accessible to the algorithm ALG as part of the input. We refer to our problem as Online Matching under Long-Run Fairness (among online types) (OM-LF). ", "page_idx": 1}, {"type": "text", "text": "Remarks on FAIR-L. (1) Random variables $\\{X_{j}|j\\in J\\}$ are dependent on both the arrival vector $\\boldsymbol{\\mathcal{A}}$ and any random bits used in the algorithm $\\mathsf{A L G}$ itself. (2) For the long-run fairness FAIR-L, the time horizon typically represents one single day, and the algorithm is audited for fairness over a large number of days. In this case, the total number of agents (of type) $j$ served over all the days will be statistically close to $T$ times the numerator in (1), while the total number of arrivals of type $j$ over all the days will be statistically close to $T$ times the denominator. As a result, the audited performance is the minimum of this fraction over all types $j\\in J$ . ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries and Main Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Competitive Ratio. Consider a given instance, characterized as ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "$\\mathcal{Z}=\\bar{\\left(G=}(I,J,E),(b_{i})_{i\\in I},\\bar{(\\lambda_{j})_{j\\in J}})\\right)$ , an online algorithm ALG, and a given fairness metric. We overload notation and let $\\mathsf{A L G}(\\mathcal{T})$ denote the expected performance of ALG on $\\mathcal{T}$ . Similarly, we use ${\\mathsf{O P T}}({\\mathcal{T}})$ to denote an optimal clairvoyant algorithm and its corresponding performance when the context is clear. Note that $\\mathsf{O P T}$ can set the values of $(X_{j})_{j}$ with advance knowledge of $\\boldsymbol{\\mathcal{A}}$ . With a fixed objective in mind, an algorithm ALG is said to be at least $c$ -competitive if $\\mathsf{A L G}(\\mathcal{T})\\geq c\\cdot0\\mathsf{P T}(\\mathcal{T})$ for any possible instance $\\mathcal{T}$ . The maximum possible value over $c\\leq1$ for which the above holds is called the competitiveness of ALG. The maximum possible competitiveness within a class of online algorithms is called the competitive ratio for that class. ", "page_idx": 1}, {"type": "text", "text": "Holistic Nature of an Optimal Clairvoyant Algorithm. Consider the classical (edge-weighted) online bipartite matching under KIID where the goal is to maximize the total weight of all matches. In that case, an optimal clairvoyant algorithm OPT will aim to optimize the objective on every realized instance and it can always find a deterministic strategy to do so. However, this may not be true in our problem. To see this, consider a simple example under FAIR-L where there is one single offline agent with $b=1$ and two online types with $\\lambda_{1}\\,=\\,\\epsilon$ and $\\lambda_{2}=1$ . For any realized arrival vector ${\\mathcal{A}}=(A_{1},A_{2})$ with $A_{1}\\geq1$ and $A_{2}\\geq1$ , we can show that the strategy of OPT on $\\boldsymbol{\\mathcal{A}}$ can be characterized as follows: serve $j=1$ and $j=2$ with respective probabilities $p$ and $1-p$ , where $p\\geq(\\mathsf{e}-2)/(\\mathsf{e}-1)\\approx0.418$ . This suggests that OPT has to resort to a randomized strategy on $\\boldsymbol{\\mathcal{A}}$ , and it does not suffice to simply maximize the objective of $\\operatorname*{min}\\left(\\mathbb{E}[X_{1}]/\\epsilon,\\mathbb{E}[X_{2}]/1\\right)$ on every realization of $\\boldsymbol{\\mathcal{A}}$ . More detailed discussions and clarifications can be seen in Appendix $A$ . ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Benchmark Linear Program (LP). To guide the choice between offline agents, we write the following LP with variables $\\{x_{i j}|(i j)\\in E\\}$ and $s$ , where the variable $x_{i j}$ can be interpreted as the expected number of online type $j$ served by offilne agent $i$ in an optimal clairvoyant algorithm (OPT), while $s$ can be interpreted as the \u201cscale\u201d of demand that can be served. ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{j\\in\\mathcal{N}_{i}}x_{i j}\\le b_{i}}&{\\forall i\\in I}\\\\ &{\\displaystyle\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}\\ge s\\cdot\\lambda_{j}\\,\\,\\,\\forall j\\in J}\\\\ &{s,x_{i j}\\ge0}&{\\forall(i,j)\\in E}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Throughout this paper, we refer to the linear program described above as $L P$ (2). We utilize the notation OPT to denote both an optimal clairvoyant policy and its corresponding performance when the context is clear. ", "page_idx": 2}, {"type": "text", "text": "Lemma 1. LP (2) is a valid benchmark for OM-LF, i.e., the optimal value of LP (2), denoted by $s^{*}$ , is a valid upper bound for the performance of a clairvoyant algorithm. Therefore, OPT $\\leq$ $\\operatorname*{min}\\{s^{*},1\\}$ . ", "page_idx": 2}, {"type": "text", "text": "Note that it is important in Lemma 1 that we also upper bound OPT by 1; this will allow us to later establish asymptotic optimality in $s^{*}$ . ", "page_idx": 2}, {"type": "text", "text": "Proof. Consider any clairvoyant algorithm OPT. Let $X_{i j}$ be the random variable for the number of times it uses $i$ to serve $j$ , with $\\begin{array}{r}{X_{j}=\\sum_{i\\in\\mathcal{N}_{j}}X_{i j}}\\end{array}$ . Recall that $\\mathsf{O P T}=\\operatorname*{min}_{j\\in J}\\mathbb{E}[X_{j}]/\\lambda_{j}$ . It can be checked that setting $x_{i j}=\\mathbb{E}[X_{i j}]$ , $s=0\\mathsf{P T}$ constitutes a feasible LP solution with objective value OPT. Therefore, $\\mathrm{LP}\\geq\\mathsf{O P T}$ , and $1\\geq0\\mathsf{P T}$ holds by definition, completing the proof. \u53e3 ", "page_idx": 2}, {"type": "text", "text": "Remarks on LP (2). Among existing studies of online matching under known distributions, all benchmark LPs are designed solely for outputting an upper bound on the performance of an optimal clairvoyant (OPT), which is then used to establish a lower bound on the resulting competitiveness by comparing the performance of an online algorithm against it. In contrast, the benchmark LP (2) proposed here serves dual purposes. The optimal value $s^{*}$ of LP (2), not only offers an upper bound on OPT but also plays a crucial role in scaling online sampling distributions (e.g., in Algorithm SAMP of Theorem 1). This means that benchmark LP (2) actively participates in the online algorithm design, serving as a key component in shaping the online decision-making process of the algorithms. ", "page_idx": 2}, {"type": "text", "text": "2.1 Main Contributions ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this paper, we introduce a fairness metric among online types, defined in (1), and propose a model, called online matching under long-run fairness among online types (OM-LF). Our contributions are summarized as follows. ", "page_idx": 2}, {"type": "text", "text": "2.1.1 A Warm-Up for OM-LF with a Single Offline Agent. ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We observe that when there is a single offilne agent, the optimal online algorithm is First-Come-FirstServe (FCFS), which assigns all incoming agents to the offilne agent as long as capacity is available. We demonstrate that FCFS is 1-competitive. ", "page_idx": 2}, {"type": "text", "text": "Proposition 1. For OM-LF with one single offilne agent, FCFS is 1-competitive, making it optimal among all algorithms. ", "page_idx": 2}, {"type": "text", "text": "Proof. Suppose that $I$ consists of a single offline agent with capacity $b$ . Let $A$ be the random variable for the total number of online arrivals, in which case FCFS serves the first $\\operatorname*{min}\\{A,b\\}$ arrivals. Conditioned on any value $A\\,>\\,0$ , the distribution of online types served is proportional to the arrival rates $\\lambda_{j}$ . That is, for any online type $j\\in J$ , the expected number of type- $j$ agents served is $\\begin{array}{r}{\\mathbb{E}\\Big[\\operatorname*{min}\\{\\mathrm{Pois}\\big(\\sum_{j\\in J}\\lambda_{j}\\big),b\\}\\Big]\\cdot\\frac{\\lambda_{j}}{\\sum_{j\\in J}\\lambda_{j}}}\\end{array}$ \u00b7 j\u03bb\u2208jJ \u03bbj . All in all, FCFS achieves a fairness of $\\begin{array}{r}{\\mathbb{E}\\Big[\\operatorname*{min}\\{\\mathrm{Pois}(\\sum_{j\\in J}\\lambda_{j}),b\\}\\Big]/\\sum_{j\\in J}\\lambda_{j}}\\end{array}$ , which cannot be beaten even by a clairvoyant algorithm since the total number of agents served cannot exceed $\\begin{array}{r}{\\mathbb{E}\\Big[\\operatorname*{min}\\{\\operatorname*{Pois}(\\sum_{j\\in J}\\lambda_{j}),b\\}\\Big].}\\end{array}$ . This shows that FCFS is 1-competitive and is also the optimal clairvoyant algorithm. \u53e3 ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "2.1.2 General Cases of OM-LF. ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We consider OM-LF with multiple offline agents, where each offline agent may have a different capacity. ", "page_idx": 3}, {"type": "text", "text": "Theorem 1 (Section 4). There is an algorithm (SAMP) for OM-LF, whose competitiveness is lower-bounded by $\\kappa(b,s^{*})\\,\\doteq\\mathbb{E}[\\operatorname*{min}(\\mathrm{Pois}(b/s^{*}),b)]\\cdot\\operatorname*{max}(s^{*},1)/b\\,\\geq\\,\\kappa(1,1)\\,=\\,\\bar{1}-1/{\\mathsf{e}}$ , where $b=\\operatorname*{min}_{i\\in I}b_{i}$ and $s^{*}\\in(0,\\infty)$ is the optimal value to benchmark $L P$ (2) that measures the inverse of the overall demand saturation in the system. Meanwhile, the competitiveness of SAMP approaches 1 when either $b\\rightarrow\\infty$ or $s^{*}\\to0^{+}$ (demand dominates supply) or $s^{*}\\to\\infty$ (supply dominates demand). ", "page_idx": 3}, {"type": "text", "text": "Theorem 2 (Section 5). For OM-LF, the following hardness results hold: $(I)$ Any non-rejection algorithm (possibly randomized) that serves an incoming agent whenever possible is no more than $1/2$ -competitive. (2) Any algorithm (possibly randomized) is no more than $(\\sqrt{3}-1)$ -competitive. (3) The competitive analysis of SAMP is tight, as it cannot be more than $(1-1/\\mathsf{e})$ -competitive. All the hardness results mentioned in $(I)$ , (2), and (3) are independent of any benchmarks.4 ", "page_idx": 3}, {"type": "text", "text": "2.1.3 Extension of OM-LF to Group-Level Fairness. ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We consider an extension of OM-LF when each online type belongs to some pre-defined protected groups. Specifically, suppose there is a collection of protected groups $\\mathcal{G}$ , where each group $g\\in{\\mathcal{G}}$ is a subset of $J$ , indicating the online agent types that fall under group $g$ . We assume w.l.o.g. that every type $j\\in J$ is contained in at least one group (otherwise we could discard and never serve that type); note however that groups can overlap with each other. We generalize long-run fairness (FAIR-L), as defined in Equation (1), to a group-level version with respect to groups of $\\mathcal{G}$ as follows: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{FAIR-L}(\\mathcal G)=\\operatorname*{min}_{g\\in\\mathcal G}\\frac{\\mathbb{E}_{\\mathcal A,\\sf A L G}[X(g)]}{\\sum_{j\\in g}\\lambda_{j}},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\textstyle X(g)=\\sum_{j\\in g}X_{j}$ denotes the (random) number of types in $g$ served in an algorithm ALG. ", "page_idx": 3}, {"type": "text", "text": "Comparison between (Individual) Long-Run Fairness FAIR-L in (1) and Group-Level LongRun Fairness in (6). The original long-run fairness FAIR-L, as defined in (1), can be considered a special case of group-level long-run fairness in (6) with respect to $\\mathcal{G}=\\{g=\\{j\\}|j\\in J\\}$ , where each group consists of a single online type. Therefore, FAIR-L in (1) can be interpreted as individual long-run fairness with respect to every single type, as opposed to group-level fairness with respect to a pre-defined set of groups $\\mathcal{G}$ . We emphasize that overlaps among groups can potentially doom classical policies, such as first-come-first-serve (FCFS), even under very simple settings. Proposition 1 states that FCFS is 1-competitive (i.e., matching the performance of a clairvoyant optimal) for individual long-run fairness when there is a single offilne agent. In contrast, Example 1 (see below) demonstrates that FCFS is zero-competitive for group-level long-run fairness, as defined in (6), under the same setting of a single offline agent. ", "page_idx": 3}, {"type": "text", "text": "Example 1 (FCFS is zero-competitive for group-level fairness). Consider the following example: There is a single server with unit capacity. There are $n+1$ online types, indexed as $j=0,1,2,\\dots,n,$ each with an arrival rate of $^{\\,l}$ , and $n$ groups such that each group $k=1,2,\\hdots,n$ consists of two types $(0,j)$ with $j=k$ . We can verify the following: $(I)$ Any clairvoyant optimal (OPT) can achieve a group-level (long-run) fairness of at least $(1-1/e)/2$ . For any offline policy prioritizing serving arriving online types of $j=0$ , it achieves a group-level fairness of at least $(1-1/e)/2$ . (2) FCFS achieves a group-level fairness of $1/(n+1)$ : Note that each group has one agent served by FCFS only when the first arriving agent belongs to one of the two types in that group, which occurs with probability $2/(n+1)$ . Thus, we conclude that FCFS is zero-competitive for group-level fairness (when $n\\to\\infty$ ). ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Theorem 3 (Appendix G). For OM-LF with group-level long-run fairness: $(I)$ There exists an algorithm (SAMP-G) that achieves a competitive ratio of at least $1-\\mathsf{e}^{-b}b^{b}/b!$ with $b=\\operatorname*{min}_{i\\in I}b_{i}$ , which is increasing over $b\\in\\{1,2,\\ldots\\}$ and approaches $^{\\,l}$ as $b\\rightarrow\\infty$ ; (2) There exists an algorithm (RESERVE) that achieves a competitive ratio of at least $1-\\mathsf{e}^{-\\lambda}\\lambda^{\\lambda}/\\lambda!$ with $\\lambda=\\operatorname*{min}_{j\\in J}\\lambda_{j}$ , which approaches 1 as $\\lambda\\rightarrow\\infty$ . ", "page_idx": 4}, {"type": "text", "text": "Remarks on Results in Theorems 1, 2, and 3. (1) Ma et al. [28] considered both long-run individual and group-level fairness maximization, but their focus was on fairness among offline agents. This is in contrast to the emphasis on fairness among online types. Another difference is that the work of [28] assumed integral arrival rates among online types and utilized this assumption to propose a strengthened benchmark LP. Additionally, they claimed that each online type could be made to admit a unit arrival rate $(\\lambda_{j}\\,=\\,1)$ ) by creating multiple copies. In our paper, however, we do not make any assumptions regarding the arrival rates among online types: They can take any fractional or integer values, allowing for a more general analysis of fairness among online types. A more detailed discussion can be seen in Appendix B. (2) As noted before, our arrival setting is essentially equivalent to the Know Identical Independent Distributions (KIID), which is a discrete arrival setting commonly assumed in the study of online matching under known distributions. For Online Matching under KIID (OM-KIID), the most commonly studied objective is the maximization of the total weight of all matches under different weight settings, including unweighted, vertex-weighted (offline-side), and edge-weighted scenarios. To date, there have been only two known hardness results for OM-KIID with general arrival rates: one is 0.823 for unweighted and vertex-w\u221aeighted due to [31] and the other is 0.703 for edge-weighted due to [21]. Our hardness result of $\\bar{\\sqrt{3}}-1\\approx0.732$ contributes to this short list of hardness results for OM-KIID. Notably, our analysis focuses on the objective of maximizing long-run fairness among online types, which adds a new dimension to the study of OM-KIID and expands the understanding of the inherent challenges and limitations in achieving fairness in online matching scenarios. ", "page_idx": 4}, {"type": "text", "text": "2.1.4 Another Fairness Metric: Short-Run Fairness. ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We propose a second fairness metric, called Short-Run Fairness, which is defined as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{FAIR-S}=\\mathbb{E}_{A}\\left[\\operatorname*{min}_{\\substack{j\\in J:A_{j}>0}}\\frac{\\mathbb{E}_{\\mathsf{A L G}}[X_{j}|\\mathcal{A}]}{A_{j}}\\right],\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where ${\\mathcal{A}}=(A_{j})_{j\\in J}$ is the (random) arrival vector with $A_{j}\\sim\\mathrm{Pois}(\\lambda_{j})$ being the number of arrivals of type $j\\in J$ .5 ", "page_idx": 4}, {"type": "text", "text": "Remarks on FAIR-S. (a) In the numerator of FAIR-S, $\\mathbb{E}_{\\mathsf{A L G}}[X_{j}|\\mathcal{A}]$ is a conditional expectation taken over only the randomness in the algorithm ALG. (b) In FAIR-S, types $j$ with no realized arrivals (for which the denominator $A_{j}\\,=\\,0,$ ) are ignored. Also, we assume that FAIR- $\\mathrm{.S=1}$ in case all $A_{j}=0$ , i.e., no online agents arrive. (c) No inherent relation can be imposed on FAIR-L and FAIR-S. There are examples supporting both possibilities that FAIR- $\\mathrm{.L>}$ FAIR-S and FAIR-L $<$ FAIR-S; see details in Appendix C. (d) For the short-run fairness, the algorithm is audited for fairness based on the realized arrivals every single day. To avoid impossibility results, evaluation in the numerator of (7) is based on the expected service over any randomness in the algorithm.6 Interpreted another way, when evaluating Short-Run Fairness, we are allowing for fractional allocations to be made on a given day. The overall performance (7) then takes the expectation of the daily audit scores over a large number of days. (e) Note that the definitions of long-run and short-run fairness, as shown in equations (1) and (7) respectively, bear similarities to two other concepts known as ex-ante and ex-post fairness. These concepts have been extensively studied in the field of online resource allocation [2, 15, 30]. Specifically, our notion of long-run fairness aligns more closely with the idea of ex-ante fairness, which focuses on the minimum expectation, while the short-run fairness aligns more closely with the concept of ex-post fairness, which emphasizes the expectation of the minimum outcome. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Unlike FAIR-L, online matching under FAIR-S is quite technically challenging, even for upperbounding the performance of an optimal clairvoyant policy (OPT). So far, we have not found any appropriate linear program that can serve as a valid benchmark for OPT as we did for FAIR-L. That being said, we take an initial stab by focusing on a simple case when there is a single offline agent with a service capacity of $b$ . Even in this special case, characterizing the optimal online algorithm that maximizes FAIR-S is technically challenging. This contrasts with Proposition 1, which states that FCFS is 1-competitive under FAIR-L with a single offline agent. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4 (Appendix H). For online matching under FAIR-S with a single offilne agent of capacity b and a total online arrival rate of $\\textstyle\\lambda:=\\sum_{j\\in J}\\lambda_{j}$ : $(I)$ FCFS is 0.863-competitive when $\\lambda\\leq1$ ; (2) No algorithm can achieve a competitive ratio greater than 0.942 when $b=\\lambda=1$ ; (3) There exists an algorithm (Prob-Rej) that achieves a competitive ratio of at least $1-o(1)$ , where $o(1)$ is a vanishing term as $\\lambda\\rightarrow\\infty$ . ", "page_idx": 5}, {"type": "text", "text": "3 Other Related Work ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Online Bipartite Matching. Online bipartite matching was pioneered by Karp et al. [24] and its variants have gained interest during the past two decades in the CS community. Based on the arrival setting of online agents, there are three major categories: (1) Adversarial, the arrival sequence is fully unknown but fixed, see, e.g., [7, 33]; (2) Random arrival order, the full arrival sequence forms a random permutation over a set of unknown agents, see, e.g., [36, 29, 23, 17, 13]; (3) known/unknown distributions, the stochastic arrivals of online agents follow certain known/unknown distributions. A special case here is when online arrivals follow Known Independent and Identical Distributions (KIID), see, e.g., [14, 18, 31, 22]. Our arrival setting shares the spirit of KIID, though we consider a continuous version instead of discrete. Huang and Shu [19] considered the same arrival setting as ours and show that under mild assumptions,7the performance of an online algorithm is almost the same under the two arrival settings (i.e., KIID and independent Poisson process). ", "page_idx": 5}, {"type": "text", "text": "There is an interesting connection between our model under Long-Run fairness and the online-side vertex-weighted online matching under KIID. So far, studies about vertex-weighted online matching all focus on the setting of the offline side, i.e., all edges incident to any given offline agent share a weight. Examples include [19] and [6] under KIID, [20] under random arrival order, and [1] under adversarial arrival order. By contrast, we believe that our analysis and results can be applied to the online-side vertex-weighted online matching problem, which we leave as future work. ", "page_idx": 5}, {"type": "text", "text": "Fair Operations. Fairness in operations is a topic of increasing interest and we aim to provide a brief literature review. Classical works in this area include [4] and [5] which define the price of fairness and efficiency-fairness tradeoff, respectively, in an axiomatic fashion. Gig platforms have motivated many studies on balancing multiple objectives [26], including fair allocation on the rider side [34] and income equality on the driver side [38] in rideshare. Fair pricing to the customer side has been more generally studied in [12], while fair allocation has been studied in transportation problems [10, 9, 35] and COVID-19 vaccine distributions [37]. We note that in the application of [10], the authors justify prioritizing transportation for certain groups (e.g. seniors), instead of balancing fairness across all groups as we do. ", "page_idx": 5}, {"type": "text", "text": "More generally, online resource allocation frameworks that can capture fairness have been considered in [3, 25, 11]. These papers all derive regret bounds which are sublinear in the number of arrivals, while we derive competitive ratio bounds which hold universally and establish asymptotic optimality in regimes (involving the demand saturation) not previously captured. However, we should note that our techniques appear to be reliant on the max-min objective function, while these papers allow for more general functions. ", "page_idx": 5}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "4 Proof of Theorem 1: Online Matching Under Long-Run Fairness (OM-LF) ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "4.1 Algorithm SAMP and Intuitions ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we present an LP-based sampling algorithm, denoted by SAMP, which is $(1-1/\\mathsf{e})$ - competitive and asymptotically optimal in many parameter regimes. Let $\\{x_{i j}^{*},s^{*}\\}$ be an optimal solution to the benchmark LP (2). For all $j\\in J$ , WLOG assume that $\\begin{array}{r}{x_{j}^{*}\\doteq\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*}=s^{*}\\cdot\\lambda_{j}}\\end{array}$ .8 SAMP is formally stated in Algorithm 1. ", "page_idx": 6}, {"type": "table", "img_path": "0C3bLHwjsY/tmp/859efac67fab26a6331453c2209d82ab8670d569e7e0d3d97bc848876bb35a72.jpg", "table_caption": [], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "SAMP does not re-sample an offilne agent if the first one sampled is unavailable, so it does not share the property of FCFS that an incoming agent is served whenever possible. The property that SAMP sometimes \u201crejects\u201d an incoming agent is imperative for it to surpass the barrier of $\\bar{1}/2$ , as suggested by Theorem 2. ", "page_idx": 6}, {"type": "text", "text": "4.2 Proof of Theorem 1: Competitive Analysis of SAMP ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "First, we use two lemmas to analyze the number of times each online type is served by SAMP. ", "page_idx": 6}, {"type": "text", "text": "Lemma 2. For each $\\textit{i}\\in\\textit{I}$ and $t~\\in~[0,1]$ , let $\\mathsf{S F}_{i t}$ indicate if offline agent $i$ is safe at the instantaneous point in time $t$ in algorithm SAMP, i.e., $i$ still has remaining capacity at $t$ $\\mathbb{E}[\\mathsf{S F}_{i t}]\\ge\\mathrm{Pr}[\\mathrm{Pois}(b_{i}t/s^{*})<b_{i}],$ , for all $i\\in I$ and $t\\in[0,1]$ . ", "page_idx": 6}, {"type": "text", "text": "Proof. An offilne agent $i$ is safe at time $t$ if and only if there have been fewer than $b_{i}$ arrivals before $t$ which sampled $i$ . Such arrivals are Poisson with total rate $\\sum_{j\\in\\mathcal{N}_{i}}\\lambda_{j}\\cdot\\frac{x_{i j}^{*}}{s^{*}\\cdot\\lambda_{j}}$ , which is at most $b_{i}/s^{*}$ by LP constraints (3). Therefore, the number of such arrivals is Poisson with mean at most $b_{i}\\cdot t/s^{*}$ , completing the proof. $\\sqsupset$ ", "page_idx": 6}, {"type": "text", "text": "Lemma 3. Let $X_{j}^{S}$ be the random number of times type $j$ is serviced in SAMP. Then for all $j\\in J$ , ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{E}[X_{j}^{S}]}{\\lambda_{j}}\\ge s^{*}\\cdot\\operatorname*{min}_{i\\in I}\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b_{i}/s^{*}),b_{i}\\}]}{b_{i}}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Proof. Consider any $i,j$ for which an offline agent $i$ is eligible to serve online type $j$ . Let $X_{i j}^{S}$ be the random variable for the number of times SAMP uses $i$ to serve j. $X_{i j}^{S}$ is incremented whenever: (1) type $j$ arrives (occurring following Poisson process of rate $\\lambda_{j}$ ); (2) $i$ is sampled (occurring with probability $x_{i j}^{*}/(s^{*}\\cdot\\lambda_{j}))$ ; and (3) $i$ is safe (occurring with probability at least $\\mathrm{Pr}[\\mathrm{Pois}(b_{i}t/s^{*})^{\\top}<b_{i}]$ , by Lemma 2). Since these events are mutually independent, we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[X_{i j}^{S}]\\geq\\int_{0}^{1}\\lambda_{j}\\cdot\\frac{x_{i j}^{*}}{s^{*}\\cdot\\lambda_{j}}\\cdot\\operatorname*{Pr}[\\operatorname{Pois}(b_{i}\\cdot t/s^{*})<b_{i}]d t}\\\\ &{\\qquad=\\frac{x_{i j}^{*}}{b_{i}}\\int_{0}^{1}\\frac{b_{i}}{s^{*}}\\cdot\\operatorname*{Pr}[\\operatorname{Pois}(b_{i}\\cdot t/s^{*})<b_{i}]d t=\\frac{x_{i j}^{*}}{b_{i}}\\cdot\\mathbb{E}[\\operatorname*{min}\\{\\operatorname{Pois}(b_{i}/s^{*}),b_{i}\\}].}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "8This is because if $\\textstyle\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*}>s^{*}\\cdot\\lambda_{j}$ , then we can re-scale the values of $\\boldsymbol{x}_{i j}^{*}$ by $\\begin{array}{r}{(s^{*}\\cdot\\lambda_{j})/(\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*})}\\end{array}$ , without violating feasibility. ", "page_idx": 6}, {"type": "text", "text": "The final equality holds because the integral \u201ccounts\u201d an arrival from a Poisson process of rate $b_{i}/s^{*}$ whenever the number of arrivals thus far is less than $b_{i}$ ; this equals, in expectation, the number of arrivals from such a process truncated by $b_{i}$ . ", "page_idx": 7}, {"type": "text", "text": "Now, for any online type $j\\in J$ , let $\\begin{array}{r}{X_{j}^{S}=\\sum_{i\\in\\mathcal{N}_{j}}X_{i j}^{S}}\\end{array}$ be the random variable for the number of times SAMP serves $j$ . The previous derivation for $X_{i j}^{S}$ implies that ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbb{E}[X_{j}^{S}]\\geq\\sum_{i\\in{\\cal N}_{j}}x_{i j}^{*}\\cdot\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b_{i}/s^{*}),b_{i}\\}]}{b_{i}}\\geq s^{*}\\cdot\\lambda_{j}\\cdot\\operatorname*{min}_{i\\in{\\cal N}_{j}}\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b_{i}/s^{*}),b_{i}\\}]}{b_{i}},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where the second inequality uses LP constraint (4). This completes the proof. ", "page_idx": 7}, {"type": "text", "text": "Having derived the expression on the RHS of (8), we aim to lower bound it in terms of simpler expressions of $b_{i}$ and $s^{*}$ . Recall that $\\begin{array}{r}{\\kappa(b,s)\\doteq\\operatorname*{max}\\{s,1\\}\\cdot\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b/s),b\\}]}{b}}\\end{array}$ for any integer $b\\geq1$ and s > 0. For any \u03bb > 0 and s > 0, define \u03b7(\u03bb, s) = E[m\u03bbi\u00b7n mPioni(ss(,\u03bb1)),\u03bbs], a related function we will later use in our analysis. We can verify that $\\kappa(b,s)=\\eta(b/s,s)$ and $\\overset{\\cdot}{\\eta}(\\lambda,s)=\\kappa(\\lambda s,s)$ . Below are a few properties of $\\kappa(b,s)$ . ", "page_idx": 7}, {"type": "text", "text": "Lemma 4 (Appendix D). $(I)$ For any fixed $s\\,>\\,0$ , $\\kappa(b,s)$ is increasing over $b\\in\\{1,2,\\ldots\\}$ ; (2) For any fixed integer $b\\geq1$ , $\\kappa(b,s)$ is minimized at $s=1$ ; (3) For all integers $b\\geq1$ and $s\\,>\\,0$ , $\\kappa(b,s)\\geq\\kappa(1,1)=1-1/\\mathsf{e},$ ; (4) When $s>1$ , $\\kappa(b,s)\\geq1-\\exp\\big(-b\\ln{s}\\cdot(1-o(1))\\big)$ , where $o(1)$ vanishes when $s\\to\\infty$ ; (5) When $s=1$ , $\\begin{array}{r}{\\kappa(b,1)\\geq1-\\frac{1}{\\sqrt{2\\pi(b-1)}}}\\end{array}$ with $b>1$ ; (6) When $0<s<1$ , $\\begin{array}{r}{\\kappa(b,s)\\geq1-\\exp\\big(-\\frac{b}{2s}(1-s)^{2}\\big).}\\end{array}$ ", "page_idx": 7}, {"type": "text", "text": "Proof of Theorem 1. By Lemma 3, the fairness of SAMP under FAIR- $_\\mathrm{L}$ is at least ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{E}[X_{j}^{S}]}{\\lambda_{j}}\\geq s^{*}\\cdot\\operatorname*{min}_{i\\in I}\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b_{i}/s^{*}),b_{i}\\}]}{b_{i}}\\geq s^{*}\\cdot\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b/s^{*}),b\\}]}{b},\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $b~=~\\operatorname*{min}_{i}{b_{i}}$ , and the last inequality follows from Part (1) of Lemma 4. By Lemma 1, ${\\sf O P T}\\leq\\operatorname*{min}\\{s^{*},1\\}$ . Putting these statements together, we see that the competitive ratio is lower bounded by ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\frac{s^{*}}{\\operatorname*{min}\\{s^{*},1\\}}\\cdot\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b/s^{*}),b\\}]}{b}=\\kappa(b,s^{*}).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "All of the properties about $\\kappa(b,s^{*})$ follow directly from Lemma 4, with the asymptotic behavior when $b\\rightarrow\\infty$ , $s^{\\bar{*}}\\to0^{+}$ , or $s^{*}\\to\\infty$ following from the bounds given in parts (4)\u2013(6) of Lemma 4. ", "page_idx": 7}, {"type": "text", "text": "5 Proof of Theorem 2 ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Example 2 (Bad Example). $J$ consists of a large number of \u201crare types\u201d $t=1,\\dots,n$ each with $\\lambda_{t}=1/n$ and a single \u201ccommon type\u201d 0 with $\\lambda_{0}=n-1$ . I consists of $n$ unit-capacity servers such that each rare type $t=1,\\dots,n$ can only be served by a server $t_{\\perp}$ , but all servers can serve the common type. The graph structure is shown in Figure 1. ", "page_idx": 7}, {"type": "text", "text": "We can verify that the optimal clairvoyant algorithm gives priority to rare types, and uses each server $t\\in\\{1,2,\\ldots,n\\}$ for which type $t$ never arrived to serve the common type. The expected amount of each rare type $t$ served is $1-\\mathsf{e}^{-1/n}\\geq1/n-O(1/n^{2})$ , while the expected number of the common type served is at least $n-1-n(1-\\mathsf{e}^{-1/n})\\geq n-2$ . Thus, we claim any optimal clairvoyant (OPT) can achieve a long-run fairness of $1-O(1/n)$ under FAIR-L. ", "page_idx": 7}, {"type": "text", "text": "5.1 Proof of Part (1) of Theorem $2\\!\\colon1/2$ -Upper Bound for Non-Rejecting ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We first use Example 2 to show that non-rejecting algorithms cannot be better than 1/2-competitive. ", "page_idx": 7}, {"type": "text", "text": "Lemma 5. On Example 2, any non-rejecting online algorithm is no more than $1/2$ -competitive relative to the best clairvoyant algorithm. ", "page_idx": 7}, {"type": "image", "img_path": "0C3bLHwjsY/tmp/10d42cc79d307092495a7fa9e650122acfdd51c7b09e50b598576c89230010cc.jpg", "img_caption": ["Figure 1: A bad example used to show hardness results for any randomized and non-rejecting algorithms and the tightness of competitive analysis for SAMP. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "Proof. An online algorithm that serves incoming agents whenever possible must have a (randomized) order for available servers to use on the common type. The rare type which is in position $P\\in[n]$ in this order must have an arrival before the $P$ \u2019th arrival of the common type 0, to have any chance of being served. For a given rare type $t$ , let $P_{t}$ denote the (randomized) position of type $t$ in this order. For any position $\\bar{P}\\in[n]$ , let $\\mathrm{Arr}(P)\\in[0,1]$ denote the arrival time of the $P^{\\star}$ th arrival of the common type 0. By independence of the Poisson processes for the arrivals of different types, the probability of a rare type $t$ being served is at most ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{E}[1-\\exp(-\\operatorname{Arr}(P_{t})/n)]\\leq\\mathbb{E}[\\operatorname{Arr}(P_{t})/n],\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "which in turn is at most ${\\bigl(}{\\frac{\\mathbb{E}[P_{t}]+1}{n}}{\\bigr)}/n$ for sufficiently large $n$ .9 Recall that for each rare type $t=$ $1,2,\\ldots,n$ , $P_{t}\\in\\{1,2,\\ldots,n\\}$ denotes the position of type $t$ in a randomized order adopted by a non-rejecting policy. Thus, we claim that $\\begin{array}{r}{\\dot{\\sum_{t=1}^{n}}\\mathbb{E}[P_{t}]=\\dot{n}(n+1)/2}\\end{array}$ . This implies that at least one rare type $t$ must satisfy $\\mathbb{E}[P_{t}]\\le(n+1)/2$ . Therefore, the fairness of this online algorithm cannot exceed $1/2+O(1/n)$ . \u53e3 ", "page_idx": 8}, {"type": "text", "text": "Remarks. In Appendix $\\boldsymbol{\\mathrm E}$ , we present a proof of Lemma 6, which can be viewed as a stronger version of Lemma 5. The alternative proof, though more technically involved, provides a foundational framework for analyzing a much broader class of online policies and is more self-explanatory. Additionally, in Appendix F, we focus on the bad example (Example 2) to conduct a quantitative study on the tradeoff between competitiveness and the number of rejected agents. ", "page_idx": 8}, {"type": "text", "text": "5.2 Proof of Part (2) of Theorem 2: $(\\sqrt{3}-1)$ -Upper Bound for Any Randomized ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Proof. On Example 2, any online algorithm that is going to reject the common type is better off doing so sooner rather than later, since an earlier rejection allows more time to observe which rare types arrive, and give those types priority. For any $\\tau\\in[0,1]$ , suppose that the online algorithm, denoted by $\\mathsf{A L G}(\\tau)$ , starts accepting common types after time $\\tau$ . ", "page_idx": 8}, {"type": "text", "text": "The online algorithm must have some (possibly randomized) order of offline servers to use when it wants to serve the common type. The rare type whose corresponding offline server is in position $P\\in[n]$ in this order must have an arrival before the $P^{\\star}$ th arrival of the common type after time $\\tau$ , to have any hope of being served. Counting from time $\\tau$ , the $P^{*}$ \u2019th arrival of the common type will occur before $\\displaystyle{\\dot{\\tau}}+{\\frac{\\dot{P}{+}1}{n}}$ w.h.p. as $n\\to\\infty$ . As a result, the probability of this rare type being served is at most ", "page_idx": 8}, {"type": "equation", "text": "$$\n1-\\exp(-\\frac{\\operatorname*{min}\\{\\tau+\\frac{P+1}{n},1\\}}{n})\\leq\\frac{\\operatorname*{min}\\{\\tau+\\frac{P+1}{n},1\\}}{n}.\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "As $n\\to\\infty$ , the average value of the RHS expression over $P=1,\\ldots,n$ is ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\frac{1}{n}\\int_{0}^{1}\\operatorname*{min}\\{\\tau+z,1\\}d z=\\frac{1}{n}(\\tau+\\frac{1}{2}-\\frac{1}{2}\\tau^{2}).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Therefore, even using a randomized order, there must exist a rare type whose probability of being served is at most $\\begin{array}{r}{\\frac{1}{n}(\\overline{{\\tau}}+\\frac{1}{2}-\\frac{1}{2}\\tau^{2})}\\end{array}$ . Meanwhile, for any $\\tau$ , the expected number of common types served can be at most $(n-1)(1-\\tau)$ . Since the arrival rates for rare and common types are $\\scriptstyle{\\frac{1}{n}}$ and $n-1$ respectively, the fairness of the online algorithm cannot exceed $\\begin{array}{r}{\\operatorname*{min}\\{\\tau+\\frac{1}{2}-\\frac{1}{2}\\tau^{2},1-\\stackrel{\\cdot\\cdot}{\\tau}\\}}\\end{array}$ . We can \u221averify that the fairness of the online algorithm is maximized at $\\tau=2-{\\sqrt{3}}$ , in which case it equals ${\\sqrt{3}}-1$ . Meanwhile, for Example 2, a clairvoyant algorithm can achieve a fairness of 1. This completes the proof. \u53e3 ", "page_idx": 9}, {"type": "text", "text": "5.3 Proof of Part (3) of Theorem 2: Tightness of Competitive Analysis of SAMP ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Proof. For each $t\\in\\{1,2,\\ldots,n\\}$ and $\\tilde{t}\\in\\{0,1,2,\\ldots,n\\}$ , let $\\boldsymbol{x}_{t,\\tilde{t}}^{*}$ denote the value set by an optimal solution of LP (2) on the edge $(i_{t},j_{\\tilde{t}})$ in Example 2. We can verify that the optimal LP solution sets $x_{t,t}^{*}=1/n$ and $x_{t,0}^{*}=1-1/n$ for each $t=1,\\dots,n$ , and $s^{*}=1$ . As a result, each offline agent $t\\in[n]$ serves a demand with a total arrival rate of one. Thus, each offilne agent $t$ successfully serves a demand with probability $1-1/\\mathsf{e}$ since no demand arrives otherwise (which occurs with probability $1/\\mathfrak{e}]$ ). Conditioned on offline agent $t$ serving a demand, the probability of that demand being of rare type $t$ (instead of the common type 0) is $1/n$ . Therefore, for any rare type $t\\in[n]$ , we have $\\mathbb{E}[X_{t}]/\\lambda_{t}=1-1/{\\sf e}$ , where $X_{t}$ denotes the random number of times type $t$ is serviced. Thus, and under FAIR-L, SAMP achieves a fairness of at most $1-1/\\mathsf{e}$ . Meanwhile, in Example 2, we show that a clairvoyant algorithm can achieve a FAIR-L of $1-{\\dot{O}}(1/n)$ , completing the proof. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Reservations ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We propose algorithms for maintaining statistical parity in the service rates provided to different online types or groups when agents arrive dynamically. We believe this has the potential to make a positive impact on e.g., sharing economy platforms, where our algorithms will give priority to under-served groups when matching agents, thereby boosting their rates of service. However, we admit that our algorithms do not address any underlying discrimination issues of why those groups were less commonly served by hosts/drivers in the first place. Also, our algorithms are only \u201cfair\u201d with respect to the fairness metrics we defined: Our model does not necessarily guarantee fairness over all arriving individuals. Relatedly, our algorithms could have the negative consequence of causing \u201cunfairness\u201d by violating the first-come-first-serve principle, since sometimes earlier-arriving agents are rejected in order to preserve capacity for later-arriving agents who may belong to protected groups. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Pan Xu was partially supported by NSF CRII Award IIS-1948157. The authors gratefully acknowledge the valuable comments provided by the anonymous reviewers. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Gagan Aggarwal, Gagan Goel, Chinmay Karande, and Aranyak Mehta. Online vertex-weighted bipartite matching and single-bid budgeted allocations. In Proceedings of the twenty-second annual ACM-SIAM symposium on Discrete Algorithms, pages 1253\u20131264. SIAM, 2011. [2] Haris Aziz. Simultaneously achieving ex-ante and ex-post fairness. In International Conference on Web and Internet Economics, pages 341\u2013355. Springer, 2020.   \n[3] Santiago R. Balseiro, Haihao Lu, and Vahab S. Mirrokni. Regularized online allocation problems: Fairness and beyond. In Proceedings of the 38th International Conference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event, volume 139 of Proceedings of Machine Learning Research, pages 630\u2013639, 2021.   \n[4] Dimitris Bertsimas, Vivek F Farias, and Nikolaos Trichakis. The price of fairness. Operations research, 59(1):17\u201331, 2011.   \n[5] Dimitris Bertsimas, Vivek F Farias, and Nikolaos Trichakis. On the efficiency-fairness trade-off. Management Science, 58(12):2234\u20132250, 2012.   \n[6] Brian Brubach, Karthik Abinav Sankararaman, Aravind Srinivasan, and Pan Xu. Online stochastic matching: New algorithms and bounds. Algorithmica, pages 1\u201347, 2020.   \n[7] Niv Buchbinder, Kamal Jain, and Joseph Seff iNaor. Online primal-dual algorithms for maximizing ad-auctions revenue. In European Symposium on Algorithms, pages 253\u2013264. Springer, 2007.   \n[8] Cl\u00e9ment Canonne. A short note on poisson tail bounds. http://www.cs.columbia.edu/ \\~ccanonne/files/misc/2017-poissonconcentration.pdf, 2020. Accessed: 2020-02- 01.   \n[9] Xinwei Chen, Tong Wang, Barrett W Thomas, and Marlin W Ulmer. Same-day delivery with fairness. arXiv preprint arXiv:2007.09541, 2020.   \n[10] Yiwei Chen and Hai Wang. Why are fairness concerns so important? lessons from a shared last-mile transportation system. Lessons from a Shared Last-Mile Transportation System (April 25, 2018), 2018.   \n[11] Wang Chi Cheung, Guodong Lyu, Chung-Piaw Teo, and Hai Wang. Online planning with offline simulation. Available at SSRN 3709882, 2020.   \n[12] Maxime Cohen, Adam N Elmachtoub, and Xiao Lei. Price discrimination with fairness constraints. Available at SSRN 3459289, 2019.   \n[13] Nikhil R Devanur and Thomas P Hayes. The adwords problem: online keyword matching with budgeted bidders under random permutations. In Proceedings of the 10th ACM conference on Electronic commerce, pages 71\u201378. ACM, 2009.   \n[14] Jon Feldman, Aranyak Mehta, Vahab S. Mirrokni, and S. Muthukrishnan. Online stochastic matching: Beating 1-1/e. In 50th Annual IEEE Symposium on Foundations of Computer Science, FOCS \u201909, pages 117\u2013126, 2009.   \n[15] Rupert Freeman, Nisarg Shah, and Rohit Vaish. Best of both worlds: ex-ante and ex-post fairness in resource allocation. In Proceedings of the 21st ACM Conference on Economics and Computation, pages 21\u201322, 2020.   \n[16] Rajiv Gandhi, Samir Khuller, Srinivasan Parthasarathy, and Aravind Srinivasan. Dependent rounding and its applications to approximation algorithms. Journal of the ACM (JACM), 53(3): 324\u2013360, 2006.   \n[17] Gagan Goel and Aranyak Mehta. Online budgeted matching in random input models with applications to adwords. In Proceedings of the nineteenth annual ACM-SIAM symposium on Discrete algorithms, pages 982\u2013991. Society for Industrial and Applied Mathematics, 2008.   \n[18] Bernhard Haeupler, Vahab S. Mirrokni, and Morteza Zadimoghaddam. Online stochastic weighted matching: Improved approximation algorithms. In Internet and Network Economics - 7th International Workshop, WINE \u201911, pages 170\u2013181, 2011.   \n[19] Zhiyi Huang and Xinkai Shu. Online stochastic matching, poisson arrivals, and the natural linear program. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 682\u2013693, 2021.   \n[20] Zhiyi Huang, Zhihao Gavin Tang, Xiaowei Wu, and Yuhao Zhang. Online vertex-weighted bipartite matching: Beating 1-1/e with random arrivals. In 45th International Colloquium on Automata, Languages, and Programming (ICALP 2018). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2018.   \n[21] Zhiyi Huang, Xinkai Shu, and Shuyi Yan. The power of multiple choices in online stochastic matching. In Proceedings of the 54th Annual ACM SIGACT Symposium on Theory of Computing, pages 91\u2013103, 2022.   \n[22] Patrick Jaillet and Xin Lu. Online stochastic matching: New algorithms with better bounds. Mathematics of Operations Research, 39(3):624\u2013646, 2013.   \n[23] Chinmay Karande, Aranyak Mehta, and Pushkar Tripathi. Online bipartite matching with unknown distributions. In Proceedings of the forty-third annual ACM symposium on Theory of computing, pages 587\u2013596. ACM, 2011.   \n[24] Richard M. Karp, Umesh V. Vazirani, and Vijay V. Vazirani. An optimal algorithm for online bipartite matching. In Proceedings of the 22nd Annual ACM Symposium on Theory of Computing, STOC \u201990, pages 352\u2013358, 1990.   \n[25] Xin Liu, Bin Li, Pengyi Shi, and Lei Ying. Pond: Pessimistic-optimistic online dispatch. arXiv preprint arXiv:2010.09995, 2020.   \n[26] Guodong Lyu, Wang Chi Cheung, Chung-Piaw Teo, and Hai Wang. Multi-objective online ride-matching. Available at SSRN 3356823, 2019.   \n[27] Will Ma, David Simchi-Levi, and Jinglong Zhao. Dynamic pricing (and assortment) under a static calendar. Management Science, 2020.   \n[28] Will Ma, Pan Xu, and Yifan Xu. Fairness maximization among offilne agents in online-matching markets. ACM Transactions on Economics and Computation, 10(4):1\u201327, 2023.   \n[29] Mohammad Mahdian and Qiqi Yan. Online bipartite matching with random arrivals: an approach based on strongly factor-revealing lps. In Proceedings of the forty-third annual ACM symposium on Theory of computing, pages 597\u2013606. ACM, 2011.   \n[30] Vahideh Manshadi, Rad Niazadeh, and Scott Rodilitz. Fair dynamic rationing. In Proceedings of the 22nd ACM Conference on Economics and Computation, pages 694\u2013695, 2021.   \n[31] Vahideh H Manshadi, Shayan Oveis Gharan, and Amin Saberi. Online stochastic matching: Online actions based on offilne statistics. Mathematics of Operations Research, 37(4):559\u2013573, 2012.   \n[32] Enrico Masina. Useful review on the exponential-integral special function. arXiv preprint arXiv:1907.12373, 2019.   \n[33] Aranyak Mehta, Amin Saberi, Umesh Vazirani, and Vijay Vazirani. Adwords and generalized online matching. Journal of the ACM (JACM), 54(5):22, 2007.   \n[34] Vedant Nanda, Pan Xu, Karthik Abhinav Sankararaman, John Dickerson, and Aravind Srinivasan. Balancing the tradeoff between profit and fairness in rideshare platforms during highdemand hours. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 2210\u20132217, 2020.   \n[35] Anik Pramanik, Pan Xu, and Yifan Xu. Equity promotion in public transportation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 37, pages 11890\u201311898, 2023.   \n[36] GS Sankar, A Louis, M Nasre, and P Nimbhorkar. Matchings with group fairness constraints: Online and offilne algorithms. In IJCAI International Joint Conference on Artificial Intelligence, pages 377\u2013383. International Joint Conferences on Artificial Intelligence, 2021.   \n[37] Pan Xu and Yifan Xu. Equity promotion in online resource allocation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 9962\u20139970, 2022. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "[38] Yifan Xu and Pan Xu. Trade the system efficiency for the income equality of drivers in rideshare. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 4199\u20134205, 2020. ", "page_idx": 12}, {"type": "text", "text": "A Further Discussions on the Holistic Nature of an Optimal Clairvoyant ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "We emphasize that in our problem, any clairvoyant optimal policy (OPT) needs to consider the entire input instance as a whole when optimizing its decisions for each specific arrival sequence of online agents. (Recall that any clairvoyant optimal policy has the advantage of optimizing its decisions after observing the full arrival sequence.) This stands in contrast to clairvoyant optimal policies for existing, well-studied online matching problems when the objectives are to maximize the (expected) total weight of all matches. In these cases, any clairvoyant optimal policy only needs to optimize its decisions for each specific arrival sequence of online agents without considering any information or consequences of other possible arriving sequences. ", "page_idx": 13}, {"type": "text", "text": "Now, let us revisit the toy example of OM-LF, as mentioned before, where there is one single offline agent with $b=1$ and two online types with $\\lambda_{1}=\\epsilon$ and $\\lambda_{2}=1$ . According to the arrival setting, agents of $j=1$ and 2 each arrive following an independent Poisson process of rate 1 and $\\epsilon$ , respectively. OPT expects the following four possible scenarios. Let $A_{1}$ and $A_{2}$ denote the numbers of arrivals of $j=1,2$ , respectively. ", "page_idx": 13}, {"type": "text", "text": "\u2022 Case 1: $A_{1}=0,A_{2}\\ge1$ , which occurs with probability equal to $\\mathsf{e}^{-\\epsilon}(1-1/\\mathsf{e})$ ;   \n\u2022 Case 2: $A_{1}\\geq1,A_{2}=0$ , which occurs with probability equal to $(1-\\mathsf{e}^{-\\epsilon})(1/\\mathsf{e})$ ;   \n\u2022 Case 3: $A_{1}\\geq1,A_{2}\\geq1$ , which occurs with probability equal to $(1-\\mathsf{e}^{-\\epsilon})(1-1/\\mathsf{e})$ ;   \n\u2022 Case 4: $A_{1}=0,A_{2}=0$ , which occurs with probability equal to $\\mathsf{e}^{-\\epsilon-1}$ . ", "page_idx": 13}, {"type": "text", "text": "Observe that since we have one single offilne agent $i$ with a unit capacity, OPT has one single choice in Cases 1, 2, and 4. For example, in Case 1, OPT will match one arrival of $j=2$ with $i$ , and in Case 2, OPT will match any arrival of $j=1$ with $i$ , and in Case 4, OPT can do nothing since no arrivals. The only tricky issue arises in Case 3 since OPT can choose to match the only offilne agent with one arrival either from $j=1$ or $j=2$ . Consider the following two strategies. ", "page_idx": 13}, {"type": "text", "text": "The first policy, denoted by ALG-A, which aims to maximize $\\operatorname*{min}(\\mathbb{E}[X_{1}]/\\epsilon,\\mathbb{E}[X_{2}]/1)$ on every arrival instance. Thus, in Case 3, ALG-A should match the only offline agent with one arrival of $j=1$ and $j=2$ with respective probabilities of $\\epsilon/(1+\\epsilon)$ and $1/(1+\\epsilon)$ . Note that the expected number of matches of $j=1$ by ALG-A should be ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathfrak{L}[X_{1}]=\\operatorname*{Pr}[\\mathrm{Case~2}]\\cdot1+\\operatorname*{Pr}[\\mathrm{Case~3}]\\cdot\\frac{\\epsilon}{1+\\epsilon}=(1-\\mathfrak{e}^{-\\epsilon})\\cdot(1/\\mathfrak{e})\\cdot1+(1-\\mathfrak{e}^{-\\epsilon})(1-1/\\mathfrak{e})\\cdot\\frac{\\epsilon}{1+\\epsilon}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "This suggests that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{E}[X_{1}]}{\\lambda_{1}}=\\frac{\\mathbb{E}[X_{1}]}{\\epsilon}\\rightarrow\\frac{1}{\\mathsf{e}}\\;\\;(\\mathrm{when}\\;\\epsilon\\rightarrow0).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Similarly, the expected number of matches of $j=2$ by ALG-A should be ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{E}[X_{2}]}{\\lambda_{2}}=\\mathbb{E}[X_{2}]\\rightarrow1-1/{\\mathfrak{e}}\\;\\;(\\epsilon\\rightarrow0).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Thus, we claim that ALG-A above achieves a long-run fairness of $\\begin{array}{r}{\\operatorname*{min}\\left(\\frac{\\mathbb{E}[X_{1}]}{\\lambda_{1}},\\frac{\\mathbb{E}[X_{2}]}{\\lambda_{2}}\\right)=1/{\\mathsf e}.}\\end{array}$ ", "page_idx": 13}, {"type": "text", "text": "Now, we consider a second strategy, denoted by ALG-B, which in Case 3 matches the only offline agent with one arrival of $j=1$ and $j=2$ with respective probabilities of $p$ and $1-p$ , respectively, with $p\\in(0,1)$ being a constant independent of $\\epsilon$ . Note that the expected number of matches of $j=1$ by ALG-B should be ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\mathbb{E}[X_{1}]=\\operatorname*{Pr}[\\operatorname{Case~}2]\\cdot1+\\operatorname*{Pr}[\\operatorname{Case~}3]\\cdot p=(1-\\mathrm{e}^{-\\epsilon})\\cdot(1/\\mathrm{e})\\cdot1+(1-\\mathrm{e}^{-\\epsilon})(1-1/e)\\cdot p.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Thus, ", "page_idx": 13}, {"type": "equation", "text": "$$\n{\\frac{\\mathbb{E}[X_{1}]}{\\lambda_{1}}}={\\frac{\\mathbb{E}[X_{1}]}{\\epsilon}}\\to{\\frac{1}{\\mathsf{e}}}+(1-1/\\mathsf{e})\\cdot p\\;\\;(\\epsilon\\to0).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Similarly, we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{E}[X_{2}]}{\\lambda_{2}}=\\mathbb{E}[X_{2}]\\rightarrow1-1/{\\mathfrak{e}}\\;\\;(\\epsilon\\rightarrow0).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Thus, the long-run fairness achieved by ALG-B is equal to ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{min}{\\left(\\frac{\\mathbb{E}[X_{1}]}{\\lambda_{1}},\\frac{\\mathbb{E}[X_{2}]}{\\lambda_{2}}\\right)}=\\operatorname*{min}{\\left(1/\\mathsf{e}+(1-1/\\mathsf{e})\\cdot p,1-1/\\mathsf{e}\\right)},\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which is equal to $1-1/\\mathsf{e}$ when $p\\geq(1-2/\\mathsf{e})/(1-1/\\mathsf{e})\\approx0.418$ . That is strictly better than ALG-A.   \nWe can verify that ALG-B with $p\\geq(1-2/e)/(1-1/e)$ is a clairvoyant optimal policy. ", "page_idx": 14}, {"type": "text", "text": "B A Detailed Comparison of Our Work and Ma et al. [28] ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Let us detail the differences between the two studies in the following two aspects. ", "page_idx": 14}, {"type": "text", "text": "Model: As pointed out on lines 155 to 162, the model of [28] assumes integral arrival rates for all online types and then further assumes, without loss of generality, that each online type has a unit arrival rate. In contrast, we do not make that assumption. Importantly, the integral-arrival-rate assumption among online types allows them to propose a significantly stronger benchmark LP than ours. Specifically, the extra constraint $\\begin{array}{r}{\\sum_{j\\in S}x_{i j}\\,\\le\\,1-\\mathtt{e}^{-\\lambda(S)}\\,=\\,1-\\mathtt{e}^{-|S|}}\\end{array}$ in the LP [28] is crucial for overcoming the $1-1/\\mathsf{e}$ barrier for algorithms in [28], where $\\lambda(S)$ denotes the total arrival rates among all online types in $S$ . As acknowledged there, their algorithms cannot surpass $1-1/\\mathsf e$ without that constraint. In our case, while the constraint remains valid, it becomes ineffective compared to its role in [28], which is particularly evident when most online types are rare. For instance, when each online type in $S$ has an arrival rate as small as $1/n^{2}$ , this constraint reduces to $\\begin{array}{r}{\\sum_{j\\in S}x_{i j}\\le1-\\mathsf{e}^{-|S|/n^{2}}}\\end{array}$ , where the right-hand side approaches one as $n\\to\\infty$ regardless of the size of $S$ . ", "page_idx": 14}, {"type": "text", "text": "Techniques. Inspired by the insights above, we can no longer exploit any extra constraint to surpass the $1-1/\\mathsf{e}$ barrier. Instead, we conduct a parameter-dependent competitive analysis for our samplingbased policies and explore various scenarios where our algorithm can exceed $1-1/\\mathsf{e}$ or even approach one. Specifically, we incorporate two parameters\u2014the optimal LP value and the minimum offline serving capacity\u2014into the analysis and the final competitive ratio. In contrast, Ma et al. [28] conducted a traditional parameter-free analysis, neglecting the potential impact of different parameters in the input instance on the final competitiveness. ", "page_idx": 14}, {"type": "text", "text": "C Examples Showing the Possibilities of FAIR- $\\mathrm{.S>}$ FAIR-L and FAIR- $S<$ FAIR-L ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Below are examples showing it is possible that FAIR- $\\mathrm{.S>}$ FAIR-L and FAIR- $\\mathrm{~S~}<$ FAIR-L. ", "page_idx": 14}, {"type": "text", "text": "Example 3. Consider a simple example where we have one single offilne agent and one single online type with $b=\\lambda=1$ . Consider the algorithm FCFS: serve the online agent whenever it arrives. Let $A\\sim\\mathrm{Pois}(1)$ be the number of arrivals of online agents. Observe that FAIR- $\\cdot\\mathrm{L}\\,=\\,\\mathbb{E}[X]\\,=$ $\\operatorname*{Pr}[A\\geq1]=1-1/{\\epsilon}$ . Note that when $A=0$ , we have FAIR- $\\mathrm{S}=1$ . Thus, we can verify that ", "page_idx": 14}, {"type": "text", "text": "$\\begin{array}{l}{\\displaystyle\\mathrm{FAIR-S}=\\mathrm{Pr}[A=0]+\\sum_{k=1}^{\\infty}\\frac{\\mathrm{Pr}[A=k]}{k}>\\mathrm{e}^{-1}+\\sum_{k=1}^{\\infty}\\frac{\\mathrm{e}^{-1}}{k!}\\frac{1}{k+1}}\\\\ {\\displaystyle=\\mathrm{e}^{-1}\\Big(1+\\sum_{k=2}^{\\infty}\\frac{1}{k!}\\Big)=\\mathrm{e}^{-1}\\Big(1+\\mathrm{e}-2\\Big)=1-1/\\mathrm{e}=\\mathrm{FAIR-L}\\,.}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "Thus we claim that it is possible that FAIR- $.\\mathrm{~S~}{>}$ FAIR-L. ", "page_idx": 14}, {"type": "text", "text": "Example 4. Consider a simple example where we have one single offilne agent and one single online type with $b=1$ and an online arrival rate of $\\lambda.$ . Consider such an algorithm featured by a threshold $k$ as follows: serve the online agent only when it arrives for the kth time. In other words, ignore it for the first $k-1$ arrivals. Let $A\\sim\\mathrm{Pois}(\\lambda)$ denote the number of online arrivals. ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathrm{FAIR-S}=\\mathrm{Pr}[A=0]+\\sum_{\\ell=k}^{\\infty}\\mathrm{Pr}[A=\\ell]/\\ell<\\mathrm{e}^{-\\lambda}+\\mathrm{Pr}[A\\ge k]/k<\\mathrm{Pr}[A\\ge k]/\\lambda=\\mathrm{FAIR-L}\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Thus, we claim that it is possible that FAIR- $\\mathrm{~S~}<$ FAIR-L. ", "page_idx": 14}, {"type": "text", "text": "D Proof of Lemma ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof. Part (1) follows from the fact (see e.g., [27]) that $\\mathbb{E}\\big[\\operatorname*{min}\\{\\operatorname{Pois}(b/s),b\\}\\big]/b$ is increasing in $b$ . Part (2) is valid since: if $s\\leq1$ , then $\\kappa(b,s)=\\mathbb{E}\\big[\\operatorname*{min}\\{\\operatorname{Pois}(b/s),b\\}\\big]/b$ which is decreasing in $s$ ; if $s\\geq1$ , then $\\kappa(b,s)=s\\cdot(\\mathbb{E}\\big[\\operatorname*{min}\\{\\operatorname{Pois}(b/s),b\\}\\big]/b)$ , which is increasing in $s$ . Furthermore, we can derive that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b/s),b\\}]}{b}=1-\\frac{1}{b}\\mathbb{E}[\\operatorname*{max}\\{b-\\mathrm{Pois}(b/s),0\\}]=1-\\sum_{k=0}^{b-1}\\mathrm{e}^{-b/s}\\frac{b^{k-1}}{s^{k}k!}(b-k);\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "if $s=1$ then this equals ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b/s),b\\}]}{b}=1-\\sum_{k=0}^{b-1}\\mathrm{e}^{-b}\\frac{b^{k}}{k!}+\\sum_{k=1}^{b-1}\\mathrm{e}^{-b}\\frac{b^{k-1}}{(k-1)!}=1-\\mathrm{e}^{-b}\\frac{b^{b-1}}{(b-1)!}=\\kappa(b,1).\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "It can be verified that $\\kappa(b,1)$ gets minimized at $b=1$ with $\\kappa(1,1)=1-1/{\\mathrm{e}}$ . For $b>1$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathrm{s}(b,1)\\geq1-\\mathrm{e}^{-b}\\frac{b^{b-1}}{\\frac{(b-1)^{b-1}}{\\mathrm{e}^{b-1}}\\sqrt{2\\pi(b-1)}}=1-\\frac{1}{\\mathrm{e}}(1+\\frac{1}{b-1})^{b-1}\\frac{1}{\\sqrt{2\\pi(b-1)}}\\geq1-\\frac{1}{\\sqrt{2\\pi(b-1)}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where we use Stirling\u2019s approximation in the first inequality. This establishes Part (3) and Part (5). ", "page_idx": 15}, {"type": "text", "text": "Now, we show Parts (4) and (6). Recall that $\\begin{array}{r}{\\eta(\\lambda,s)\\,=\\,\\frac{\\mathbb{E}\\left[\\operatorname*{min}\\mathrm{Pois}(\\lambda),\\lambda s\\right]}{\\lambda\\cdot\\operatorname*{min}(s,1)}}\\end{array}$ and $\\kappa(b,s)\\,=\\,\\eta(b/s,s)$ Consider the first case when $s>1$ . We see that ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\eta(\\lambda,s)=\\displaystyle\\frac{\\mathbb{E}[\\operatorname*{min}(\\mathrm{Pois}(\\lambda),\\lambda s)]}{\\lambda}\\geq\\displaystyle\\frac{1}{\\lambda}\\sum_{k=1}^{\\lambda s}\\displaystyle\\frac{\\mathrm{e}^{-\\lambda}\\lambda^{k}k}{k!}=\\sum_{k=0}^{\\lambda s-1}\\displaystyle\\frac{\\mathrm{e}^{-\\lambda}\\lambda^{k}}{k!}=1-\\mathrm{Pr}[\\mathrm{Pois}(\\lambda)\\geq\\lambda s]}\\\\ &{\\qquad\\qquad\\geq1-\\exp\\Big(-\\lambda\\cdot\\displaystyle\\frac{\\ln s\\cdot(s-1)^{2}}{s}\\cdot(1-o(1))\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The last inequality is due to the upper tail bound of a Poisson random variable as shown by [8], where $o(1)\\ \\stackrel{!}{=}\\Theta(1/\\ln s)$ is vanishing when $s~\\rightarrow~\\infty$ . Thus, since $\\kappa(b,s)\\,=\\,\\eta(b/s,s)$ , we see $\\kappa(b,s)\\geq\\mathrm{i}-\\exp(-b\\cdot\\ln{s}\\cdot(1-1/s\\bar{)}^{2}(1-o(1)))$ , completing Part (4). ", "page_idx": 15}, {"type": "text", "text": "Similarly, for $s<1$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\eta(\\lambda,s)=\\displaystyle\\frac{\\mathbb{E}[\\operatorname*{min}(\\mathrm{Pois}(\\lambda),\\lambda s)]}{\\lambda s}\\geq\\displaystyle\\frac{\\lambda s}{\\lambda s}\\sum_{k=\\lambda s}^{\\infty}\\frac{\\mathrm{e}^{-\\lambda}\\lambda^{k}}{k!}=1-\\mathrm{Pr}[\\mathrm{Pois}(\\lambda)<\\lambda s]}\\\\ &{\\qquad\\qquad\\geq1-\\exp\\Big(-\\displaystyle\\frac{\\lambda(1-s)^{2}}{2}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The last inequality is due to [8]. Thus, by replacing $\\lambda$ with $b/s$ , we establish Part (6). ", "page_idx": 15}, {"type": "text", "text": "E An Alternative Proof for a Stronger Version of Lemma 5 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Consider Example 2. We present an alternative proof for a stronger version of Lemma 5 below. ", "page_idx": 15}, {"type": "text", "text": "Lemma 6. For Example $^{\\,l}$ , the optimal non-rejecting policy (Non-Rej) achieves a long-run fairness of $1/2+o(1)$ and $1-o(1)$ for the rare type and the common type, respectively, where $o(1)$ is $a$ vanishing term when $n\\to\\infty$ . ", "page_idx": 15}, {"type": "text", "text": "Since the clairvoyant optimal achieves a long-run fairness of $1-O(1/n)$ for both common and rare types, the above lemma immediately implies that Non-Rej achieves a competitiveness of $1/2+o(1)$ . ", "page_idx": 15}, {"type": "text", "text": "We claim that Non-Rej above is an optimal non-rejecting algorithm for the bad example. This can be justified as follows: When a common type arrives, the best strategy is to sample an available offline neighbor (server) uniformly at random since each rare type has an equal chance of arriving subsequently. ", "page_idx": 15}, {"type": "text", "text": "ALGORITHM 2: An Optimal Non-Rejecting Policy for Example 2 (Non-Rej) ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1 Let an online agent $j$ arrive at time $t$ .   \n2 if $j$ is of the common type then   \n3 Sample an available neighbor uniformly at random, if any, and assign $j$ to it;   \n4 else   \nAssign $j$ to its unique offline neighbor, if it is available then. ", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma 6. For each $k$ with $0\\leq k\\leq n$ and $t\\in[0,1]$ , let $\\pi_{k}(t)$ be the probability that there are $k$ available servers at time $t$ . By the nature of Non-Rej, the update on the number of available servers follows a pure death process: The system starts at state $k=n$ at time $t=0$ , i.e., $\\pi_{n}(0)=1$ ; given the system has $1\\leq k<n$ free servers at time $t$ , it leaves the state whenever either a common type arrives or any rare type uniquely served by any of the $k$ free servers arrives, with a total arrival rate of $n-1+k/n$ . Thus, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l l}{\\displaystyle\\frac{\\mathrm{d}\\pi_{k}(t)}{\\mathrm{d}t}=-\\pi_{k}(t)\\cdot n,\\pi_{k}(0)=1}&{k=n;}\\\\ {\\displaystyle\\frac{\\mathrm{d}\\pi_{k}(t)}{\\mathrm{d}t}=-\\pi_{k}(t)\\cdot\\Big(n-1+\\displaystyle\\frac{k}{n}\\Big)+\\pi_{k+1}(t)\\Big(n-1+\\displaystyle\\frac{k+1}{n}\\Big),\\pi_{k}(0)=0}&{\\quad1\\leq k<n;}\\\\ {\\displaystyle\\pi_{0}(t)=1-\\sum_{k=1}^{n}\\pi_{k}(t).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "From the above ordinary-differential-equation system, we can solve that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\pi_{k}(t)=\\left\\{\\!\\!\\operatorname*{Pr}[\\!{\\mathrm{Pois}}(t n)=n-k](1+o(1)),\\!\\!\\begin{array}{l l}{\\mathrm{if}\\;1\\leq k\\leq n;}\\\\ {\\mathrm{if}\\;k=0.}\\end{array}\\!\\!\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $X$ be the (random) numbers of rare type agents that arrive and get served in Non-Rej. Therefore, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathbb{E}[X]=\\int_{0}^{1}\\sum_{k=1}^{n}\\pi_{k}(t)\\cdot(k/n)\\mathrm{d}t=\\int_{0}^{1}\\sum_{k=1}^{n}\\Big(\\operatorname*{Pr}[\\operatorname{Pois}(t n)=n-k](1+o(1))\\Big)\\cdot(k/n)\\mathrm{d}t\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We can verify that $\\mathbb{E}[X]=1/2+o(1)$ , where $o(1)$ vanishes as $n\\to\\infty$ . By symmetry, the number of each rare type served equals $\\mathbb{E}[X]/n$ , leading to a long-run fairness of $(\\mathbb{E}[{\\bar{X}}]/n)/({\\bar{1}}/n)=\\mathbb{E}[X]=$ $1/2+o(1)$ . Similarly, let $Y$ be the number of common type agents that arrive and are served in Non-Rej. Thus, the long-run fairness achieved for the common type is ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\mathbb{E}[Y]}{n-1}=\\displaystyle\\frac{1}{n-1}\\int_{0}^{1}\\sum_{k=1}^{n}\\pi_{k}(t)\\cdot(n-1)\\mathsf{d}t=\\displaystyle\\int_{0}^{1}\\sum_{k=1}^{n}\\Big(\\mathrm{Pr}[\\mathrm{Pois}(t n)=n-k](1+o(1))\\Big)\\mathsf{d}t}\\\\ {\\displaystyle\\qquad=\\int_{0}^{1}\\mathrm{~Pr}[\\mathrm{Pois}(t n)\\leq n-1]\\mathsf{d}t+o(1)=\\displaystyle\\frac{1}{n}\\int_{0}^{1}\\mathrm{Pr}[\\mathrm{Pois}(t n)\\leq n-1]\\cdot n\\,\\mathsf{d}t+o(1)}\\\\ {\\displaystyle\\qquad=\\frac{1}{n}\\cdot\\mathbb{E}\\Big[\\operatorname*{min}\\Big(\\mathrm{Pois}(n),n\\Big)\\Big]-o(1)=1-o(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Thus, we establish the claim. ", "page_idx": 16}, {"type": "text", "text": "F A Quantitative Study on the Tradeoff between Competitiveness and the Number of Rejected Agents ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "We use the bad example (Example 2) to conduct a case study on the trade-off between competitiveness and the number of rejected arriving agents (when the serving capacity remains). We hope this case study can provide insights for a comprehensive study of this trade-off in general cases. The proof of Lemma 6 in Section $\\boldsymbol{\\mathrm E}$ offers a foundational framework for analyzing a general class of online policies. Consider an updated version of Non-Rej, denoted by ${\\mathsf{R e j}}(\\alpha)$ , where we reject each arriving common-type agent with a preset constant probability $\\alpha\\in[0,1]$ . We expect the parameter $\\alpha$ to serve as a useful moderator in balancing competitiveness and the number of rejected common-type agents. ", "page_idx": 16}, {"type": "text", "text": "ALGORITHM 3: An Updated Policy Parameterized by $\\alpha\\in[0,1]$ : ${\\mathsf{R e j}}(\\alpha)$ ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "1 Let an online agent $j$ arrive at time $t$ .   \n2 if $j$ is of the common type then   \n3 With probability $1-\\alpha$ , reject $j$ ; With probability $\\alpha$ , sample an available neighbor uniformly at random,   \nif any, and assign $j$ to it;   \n4 else   \n5 Assign $j$ to its unique offline neighbor, if it is available then. ", "page_idx": 17}, {"type": "text", "text": "Note that: (1) When $\\alpha\\,=\\,1$ , ${\\mathsf{R e j}}(\\alpha)$ reduces to Non-Rej; (2) The expected number of arriving common-type agents rejected in ${\\mathsf{R e j}}(\\alpha)$ is at least $(1-\\alpha)(n-1)$ . ", "page_idx": 17}, {"type": "text", "text": "Lemma 7. The policy ${\\mathsf{R e j}}(\\alpha)$ achieves a long-run fairness of $1-\\alpha/2+o(1)$ and $\\alpha-o(1)$ for the rare and common types, respectively, where $o(1)$ is a vanishing term as $n\\to\\infty$ . Additionally, $i t$ rejects at least $(1-\\alpha)(n-1)$ arriving common-type agents in expectation. ", "page_idx": 17}, {"type": "text", "text": "Proof. For each $k$ with $0\\leq k\\leq n$ and $t\\in[0,1]$ , let $\\pi_{k}(t)$ be the probability that there are $k$ available servers at time $t$ . Following the same analysis as in the proof of Lemma 6, we have ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\pi_{k}(t)={\\Bigl\\{}\\operatorname*{Pr}[\\operatorname*{Pois}(t n\\alpha)=n-k](1+o(1)),\\quad{\\mathrm{if~}}1\\leq k\\leq n;\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Let $X$ be the (random) numbers of rare type agents that arrive and get served in ${\\mathsf{R e j}}(\\alpha)$ . Therefore, ", "page_idx": 17}, {"type": "equation", "text": "$$\n{\\begin{array}{l}{\\displaystyle\\mathbb{E}[X]=\\int_{0}^{1}\\sum_{k=1}^{n}\\pi_{k}(t)\\cdot(k/n)\\mathsf{d}t=\\int_{0}^{1}\\sum_{k=1}^{n}\\left(\\operatorname{Pr}[\\operatorname{Pois}(t n\\alpha)=n-k](1+o(1))\\right)\\cdot(k/n)\\mathsf{d}t}\\\\ {\\displaystyle=\\int_{0}^{1}\\sum_{\\ell=0}^{n-1}\\operatorname{Pr}[\\operatorname{Pois}(t n\\alpha)=\\ell]\\cdot(1-\\ell/n)\\mathsf{d}t+o(1)}\\\\ {\\displaystyle=\\int_{0}^{1}\\sum_{\\ell=0}^{n-1}\\operatorname{Pr}[\\operatorname{Pois}(t n\\alpha)=\\ell]\\mathsf{d}t-{\\frac{\\ell}{n}}\\int_{0}^{1}\\sum_{\\ell=0}^{n-1}\\operatorname{Pr}[\\operatorname{Pois}(t n\\alpha)=\\ell]\\mathsf{d}t+o(1)}\\\\ {\\displaystyle=\\int_{0}^{1}\\operatorname{Pr}[\\operatorname{Pois}(t n\\alpha)\\leq n-1]\\mathsf{d}t-\\int_{0}^{1}(t\\alpha)\\cdot\\operatorname{Pr}[\\operatorname{Pois}(t n\\alpha)\\leq n-2]\\mathsf{d}t+o(1)}\\\\ {\\displaystyle=1-\\alpha/2+o(1).}\\end{array}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "By symmetry, the number of each rare type served is equal to $\\mathbb{E}[X]/n$ , leading to a long-run fairness of $({\\dot{\\mathbb{E}}}[X]/n{\\dot{)}}/(1/n)=\\mathbb{E}[X]=1-\\alpha{\\dot{/}}{\\bar{2}}+o(1)$ . Similarly, let $Y$ be the number of common type agents that arrive and are served in ${\\mathsf{R e j}}(\\alpha)$ . The long-run fairness achieved for the common type is ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\mathbb{E}[Y]}{\\imath-1}=\\frac{1}{n-1}\\int_{0}^{1}\\sum_{k=1}^{n}\\pi_{k}(t)\\cdot(n-1)\\cdot\\alpha\\,\\mathsf{d}t=\\alpha\\int_{0}^{1}\\sum_{k=1}^{n}\\mathrm{Pr}[\\mathrm{Pois}(t n\\alpha)=n-k]\\mathsf{d}t+o(1)}\\\\ {\\displaystyle\\qquad=\\alpha\\int_{0}^{1}\\mathrm{\\Pr}[\\mathrm{Pois}(t n\\alpha)\\leq n-1]\\mathsf{d}t+o(1)=\\alpha\\cdot\\frac{1}{n\\alpha}\\int_{0}^{1}\\mathrm{Pr}[\\mathrm{Pois}(t n\\alpha)\\leq n-1]\\cdot(n\\alpha)\\,\\mathsf{d}t+o(1)}\\\\ {\\displaystyle\\qquad=\\alpha\\cdot\\frac{1}{n\\alpha}\\cdot\\mathbb{E}\\Big[\\mathrm{min}\\left(\\mathrm{Pois}(n\\alpha),n\\right)\\Big]-o(1)=\\alpha-o(1).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Thus, we establish the claim. ", "page_idx": 17}, {"type": "text", "text": "G Proof of Theorem 3: Extension of OM-LF to Group-Level Fairness ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we consider the extension of OM-LF to group-level fairness. Recall that we have a collection of protected groups ${\\mathcal{G}}\\,=\\,\\{g|g\\,\\subseteq\\,J\\}$ , where each group $g\\,\\in\\,{\\mathcal{G}}$ is a subset of $J$ that indicates the online agent types in group $g$ . The updated long-run fairness with respect to $\\mathcal{G}$ is defined ", "page_idx": 17}, {"type": "text", "text": "as FAIR- $\\begin{array}{r}{\\cdot\\mathrm{L}(\\mathcal{G})=\\operatorname*{min}_{g\\in\\mathcal{G}}\\frac{\\mathbb{E}_{\\mathcal{A},\\mathsf{A}\\mathsf{L}\\mathsf{G}}[X(g)]}{\\sum_{j\\in g}\\lambda_{j}}}\\end{array}$ , as shown in (6). Below is an updated version of Benchmark LP for the long-run group-level fairness. ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\displaystyle\\sum_{j\\in{\\mathcal{N}}_{i}}x_{i j}\\leq b_{i}\\qquad}&{\\forall i\\in I}\\\\ &{\\displaystyle\\sum_{j\\in g}\\sum_{i\\in{\\mathcal{N}}_{j}}x_{i j}\\geq s\\cdot\\sum_{j\\in g}\\lambda_{j}\\ \\forall g\\in{\\mathcal{G}}}\\\\ &{\\displaystyle\\sum_{i\\in{\\mathcal{N}}_{j}}x_{i j}\\leq\\lambda_{j}\\qquad}&{\\forall j\\in J}\\\\ &{\\displaystyle s,x_{i j}\\geq0\\qquad}&{\\forall(i,j)\\in E}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Note that we add a new set of constraints (12), which are clearly valid for any clairvoyant algorithm since the constraints hold on every sample path based on the realized number of arrivals and services. Therefore, $\\mathsf{O P T}\\leq s^{*}$ , where $s^{*}$ represents the optimal value of LP (10), following the same argument as presented in the proof of Lemma 1. ", "page_idx": 18}, {"type": "text", "text": "G.1 Proof of Part (1) of Theorem 3: SAMP-G and Competitive Analysis ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The algorithm SAMP-G for OM-LF under long-run group-level fairness is formally stated in Algorithm 4. Note that SAMP-G will reject an online agent immediately with probability $\\textstyle1\\stackrel{-}{-}\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*}/\\lambda_{j}$ , and will also reject it if the first sampled offline agent has reached capacity. ", "page_idx": 18}, {"type": "table", "img_path": "0C3bLHwjsY/tmp/94a8ada23f17e2c11e61097b3f3aaa28e67821b352f2691b7c2ae23a4028e1d6.jpg", "table_caption": [], "table_footnote": [], "page_idx": 18}, {"type": "text", "text": "Proof of Part $(I)$ of Theorem 3. We provide a terse argument since detailed logic can be found in Lemmas 2\u20133. The incoming demand flow to an offilne agent i \u2208I is Poisson with rate j\u2208Ni \u03bbjx\u03bbijj , which is at most $b_{i}$ by LP feasibility. Therefore, the capacity of any offline agent $i$ has not been reached at time $t$ with probability at least $\\mathrm{Pr}[\\mathrm{Pois}(b_{i}t)<\\bar{b}_{i}]$ . Using this fact, the expected number of times offline agent $i$ serves online type $j$ is at least ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\int_{0}^{1}\\lambda_{j}\\frac{x_{i j}^{*}}{\\lambda_{j}}\\operatorname*{Pr}[\\mathrm{Pois}(b_{i}t)<b_{i}]d t=\\frac{x_{i j}^{*}}{b_{i}}\\cdot\\int_{0}^{1}b_{i}\\cdot\\operatorname*{Pr}\\big[\\mathrm{Pois}(b_{i}t)<b_{i}\\big]d t}}\\\\ &{}&{=x_{i j}^{*}\\cdot\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b_{i}),b_{i}\\}]}{b_{i}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Applying Lemma 4 twice, the expected total number of times a group $g\\in{\\mathcal{G}}$ is served is at least ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{j\\in g}\\displaystyle\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*}\\cdot\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b_{i}),b_{i}\\}]}{b_{i}}\\ge\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(b),b\\}]}{b}\\cdot\\displaystyle\\sum_{j\\in g}\\displaystyle\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*}}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=(1-\\mathrm{e}^{-b}\\frac{b^{b}}{b!})\\cdot\\displaystyle\\sum_{j\\in g}\\displaystyle\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The proof is completed by using the LP inequality that $\\begin{array}{r}{\\sum_{j\\in g}\\sum_{i\\in\\mathcal{N}_{j}}x_{i j}^{*}/\\sum_{j\\in g}\\lambda_{j}\\geq s^{*}}\\end{array}$ . ", "page_idx": 18}, {"type": "text", "text": "Remarks on the Missing Role Played by $s^{*}$ in the Final Competitiveness. Below are a few notes on why the competitiveness should no longer depend on $s^{*}$ . Recall that in Theorem 1, when the focus is the fairness among all possible online types, $s^{*}$ was interpreted as the \"scale\" of demand that can be served, and the competitiveness approached 1 if $s^{*}\\to\\infty$ or $s^{*}\\to0^{+}$ . However, in the context of group-level fairness, $s^{*}$ no longer has this interpretation, and the statements about asymptotic optimality no longer hold. To illustrate this, we provide two examples below. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "First, $s^{*}\\to\\infty$ is no longer possible, because $s^{*}\\leq1$ is implied by Constraints (11) and (12). On the other hand, if we do not add these constraints, then the LP has an unbounded gap, as demonstrated by the following example. There is a single group consisting of $n$ types with arrival rates 1. One type is connected to an offline agent with capacity $n$ ; the other types are connected to no offline agents. Without constraints (12), the LP would be able to \u201coverserve\u201d the first type and achieve a fairness of 1; any actual algorithm would have a fairness at most $1/n$ . All in all, in the generalized model, it is no longer possible to allow an $s$ which is greater than 1. ", "page_idx": 19}, {"type": "text", "text": "Second, if $s^{*}\\to0^{+}$ , it is no longer the case that online algorithms can achieve a fairness of $s^{*}$ , as demonstrated by the following example. There is a single group consisting of 2 types; one with arrival rate 1 and the other with arrival rate $\\lambda\\rightarrow\\infty$ . Each type is connected to its own offline agent with capacity 1. In this case $s^{*}=2/(1+\\lambda)$ , which approaches 0. However, an online algorithm makes in expectation only $1+(1-1/\\mathsf{e})$ services, achieving fairness $(2-1/\\mathsf{e})/(1+\\lambda)$ . ", "page_idx": 19}, {"type": "text", "text": "G.2 Algorithm RESERVE when All Online Types are Common ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "In this section we introduce another regime, in which algorithms are 1-competitive\u2014the regime where all online types are common, i.e., all have high arrival rates. However, this regime requires a different algorithm, which we now motivate using the following example. ", "page_idx": 19}, {"type": "text", "text": "Example 5. $J$ consists of a single type a with $\\lambda_{a}=n$ and $I$ consists of n separate servers each with unit capacity. Using SAMP-G, each server faces a separate demand according to a Poisson process of rate $^{\\,l}$ and successfully serves demand with probability $1-1/\\mathsf{e}$ . The total expected demand served is $n(1-1/\\mathsf{e})$ . However, an algorithm that adaptively chooses an available server and never rejects incoming demand as long as a server is available serves a total expected demand of $\\mathbb{E}[\\operatorname*{min}\\{\\operatorname{Pois}(n),n\\}]$ . As $n\\to\\infty$ , the FAIR-L of the adaptive algorithm approaches 1, while the FAIR-L of SAMP-G is stuck at $1-1/\\mathsf{e}$ . ", "page_idx": 19}, {"type": "text", "text": "SAMP-G did not improve on this example even when the arrival rate approached $\\infty$ because it did not \u201cpool\u201d the servers in order to reduce the variance in demand served. Motivated by this example, we now introduce an algorithm RESERVE, which pre-assigns the capacity that will be used to serve each online type. In general, offilne agents could be adjacent to many online types and may not be as straightforward to assign as in Example 5; however, we make use of the updated LP (10) along with the dependent rounding procedure [16] to generate a randomized assignment. We state RESERVE in Algorithm 5 and leave the proof of Part (2) of Theorem 3 to Appendix. ", "page_idx": 19}, {"type": "table", "img_path": "0C3bLHwjsY/tmp/6991d78c460f557f6d77153313038de6d7b8fb83a8c7a8555716de0aedf2e1ec.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "text", "text": "G.3 Proof of Part (2) of Theorem 3 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Proof. For all $j$ , let ${\\mathrm{Serve}}(j)$ denote the set $\\{i:X_{i j}^{R}=1\\}$ , which is generally randomized. By the work of [16], it is possible to do the rounding in Step 3 so that the sets $\\{{\\mathrm{Serve}}(j):j\\in J\\}$ are always mutually disjoint, and $|\\operatorname{Serve}(j)|\\in\\{\\lfloor x_{j}^{*}\\rfloor,\\lceil x_{j}^{*}\\rceil\\}$ for all $j$ with $\\mathbb{E}[\\vert$ $\\mathfrak{L}[|\\operatorname{Serve}(j)|]=x_{i}^{*}$ . ${\\mathrm{Serve}}(j)$ is fixed in advance, and hence independent of the number of arrivals of type $j$ , for any $j\\in J$ . Therefore, the expected number of an online type $j$ served is ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(\\lambda_{j}),|\\;\\mathrm{Serve}(j)|\\}]}\\\\ &{=\\mathbb{E}[\\mathrm{Pois}(\\lambda_{j})\\cdot\\mathbf{1}(\\mathrm{Pois}(\\lambda_{j})\\le\\lfloor x_{j}^{*}\\rfloor)+|\\;\\mathrm{Serve}(j)|\\cdot\\mathbf{1}(\\mathrm{Pois}(\\lambda_{j})>\\lfloor x_{j}^{*}\\rfloor)]}\\\\ &{=\\mathbb{E}[\\mathrm{Pois}(\\lambda_{j})\\cdot\\mathbf{1}(\\mathrm{Pois}(\\lambda_{j})\\le\\lfloor x_{j}^{*}\\rfloor)]+\\mathbb{E}[|\\mathrm{\\;Serve}(j)|]\\mathrm{\\;Pr}[\\mathrm{Pois}(\\lambda_{j})>\\lfloor x_{j}^{*}\\rfloor]}\\\\ &{=\\mathbb{E}[\\mathrm{Pois}(\\lambda_{j})\\cdot\\mathbf{1}(\\mathrm{Pois}(\\lambda_{j})\\le\\lfloor x_{j}^{*}\\rfloor)]+x_{j}^{*}\\,\\mathrm{Pr}[\\mathrm{Pois}(\\lambda_{j})>\\lfloor x_{j}^{*}\\rfloor]}\\\\ &{=\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(\\lambda_{j}),x_{j}^{*}\\}],}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the first equality uses the property that $|\\operatorname{Serve}(j)|\\in\\{\\lfloor x_{j}^{*}\\rfloor,\\lceil x_{j}^{*}\\rceil\\}$ , the second equality uses independence, and the third equality uses the property that $\\mathbb{E}[|\\operatorname{Serve}(j)|]=x_{j}^{*}$ . ", "page_idx": 20}, {"type": "text", "text": "For any group $g\\in{\\mathcal{G}}$ , the expected fraction served is ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\sum_{j\\in g}\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(\\lambda_{j}),x_{j}^{*}\\}]}{\\sum_{j\\in g}\\lambda_{j}}\\geq\\frac{\\sum_{j\\in g}\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(\\lambda_{j}),\\lambda_{j}\\}]}{\\lambda_{j}}\\cdot x_{j}^{*}}{\\sum_{j\\in g}\\lambda_{j}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\geq\\frac{\\mathbb{E}[\\operatorname*{min}\\{\\mathrm{Pois}(\\lambda),\\lambda\\}]}{\\lambda}\\cdot\\frac{\\sum_{j\\in g}x_{j}^{*}}{\\sum_{j\\in g}\\lambda_{j}}=(1-\\mathrm e^{-\\lambda}\\frac{\\lambda^{\\lambda}}{\\lambda!})\\cdot\\frac{\\sum_{j\\in g}x_{j}^{*}}{\\sum_{j\\in g}\\lambda_{j}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the first inequality holds because $\\begin{array}{r l r}{1}&{{}\\ge}&{\\frac{x_{j}^{*}}{\\lambda_{j}}}\\end{array}$ , and the second inequality holds because E[min{Pois(\u03bb),\u03bb}] is increasing in \u03bb. Finally, $\\frac{\\sum_{j\\in g}x_{j}^{*}}{\\sum_{j\\in g}{\\lambda_{j}}}\\geq s^{*}$ by LP feasibility, where $s^{*}$ is in turn an upper bound on OPT. Since this holds for all groups $g\\in{\\mathcal{G}}$ , the proof is complete. \u53e3 ", "page_idx": 20}, {"type": "text", "text": "H Proof of Theorem 4: Short-Run Fairness with a Single Offline Type ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "H.1 Proof of Part (1) of Theorem 4: Competitive Analysis for FCFS ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Proof. Let $b$ be the serving capacity of the single offline agent and $\\lambda$ be the total arrival rate of online types. Thus, the fairness of FCFS under FAIR-S should be at least $\\operatorname*{Pr}[\\operatorname*{Pois}(\\lambda)\\,\\le\\,b]$ . In contrast, the fairness of the offline optimal under FAIR-S should be ${\\mathsf{O P T}}\\,=\\,{\\mathrm{Pr}}[{\\mathrm{Pois}}(\\lambda)\\,\\leq$ $\\begin{array}{r}{b]+\\sum_{k>b}\\operatorname*{Pr}[\\operatorname{Pois}(\\lambda)=k]\\cdot(b/k)}\\end{array}$ . By definition, the competitive ratio of FCFS under FAIR-S is at le ast ", "page_idx": 20}, {"type": "equation", "text": "$$\nf(b,\\lambda)\\doteq\\frac{\\operatorname*{Pr}[\\operatorname*{Pois}(\\lambda)\\le b]}{\\operatorname*{Pr}[\\operatorname*{Pois}(\\lambda)\\le b]+\\sum_{k>b}\\operatorname*{Pr}[\\operatorname*{Pois}(\\lambda)=k]b/k}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We now show that the value of $f(b,\\lambda)$ , for all positive integers $b$ and $\\lambda\\leq1$ , is lower-bounded by $f(1,1)$ , which equals approximately 0.863. We first show that for any given $\\lambda\\leq1$ , $f(b,\\lambda)$ is an increasing function of $b$ when $b\\geq1$ . Fix a $\\lambda\\in[0,1]$ , Let $f_{1}(b)=\\mathrm{Pr}[\\mathrm{Pois}(\\lambda)\\le b]$ and $f_{2}(b)=$ $\\begin{array}{r}{\\operatorname*{Pr}[\\operatorname{Pois}(\\bar{\\lambda})\\leq b]\\!+\\!\\sum_{k>b}\\operatorname*{Pr}[\\operatorname{Pois}(\\lambda)=k]b/k}\\end{array}$ . Thus, we have $f(b,\\lambda)=f_{1}(b,)/f_{2}(b)$ . Observe that (1) $f_{1}(b)-f_{1}(b-1)=\\operatorname*{Pr}[\\operatorname*{Pois}(\\lambda)=b]=\\mathrm{e}^{-\\lambda}\\lambda^{b}/b!$ ; (2) $\\begin{array}{r}{f_{2}(b)-f_{2}(b-1)=\\sum_{k=b}^{\\infty}\\mathrm{e}^{-\\lambda}\\lambda^{k}/(k\\!\\cdot\\!k!)}\\end{array}$ . Thus, for $b\\geq2$ , ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\frac{f_{1}(b)-f_{1}(b-1)}{f_{2}(b)-f_{2}(b-1)}=\\frac{\\mathrm{e}^{-\\lambda}\\lambda^{b}/b!}{\\sum_{k=b}^{\\infty}\\mathrm{e}^{-\\lambda}\\lambda^{k}/(k\\cdot k!)}\\ge\\frac{1}{\\sum_{k=b}^{\\infty}b!/(k\\cdot k!)}\\ge\\frac{1}{\\sum_{k=2}^{\\infty}2!/(k\\cdot k!)}=1.573.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Note that $f_{1}(b)/f_{2}(b)\\leq1$ . Thus, we claim that $f(b,\\lambda)=f_{1}(b)/f_{2}(b)$ is an increasing function of $b\\geq1$ . So, $f(b,\\lambda)\\ge f(1,\\lambda)$ . ", "page_idx": 20}, {"type": "text", "text": "Now we show $f(1,\\lambda)$ is a decreasing function of $\\lambda\\in[0,1]$ . When $b=1$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\nf(1,\\lambda)={\\frac{\\mathsf{e}^{-\\lambda}(1+\\lambda)}{\\mathsf{e}^{-\\lambda}(1+\\lambda)+\\sum_{k=2}^{\\infty}{\\frac{\\mathsf{e}^{-\\lambda}\\lambda^{k}}{k!k}}}}={\\frac{1}{1+{\\frac{\\lambda^{k}}{1+\\lambda}}\\sum_{k=2}^{\\infty}{\\frac{1}{k!k}}}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Observe that $\\lambda^{k}/(1+\\lambda)$ increases over $\\lambda>0$ for all given integer $k\\geq1$ . Thus, we claim $f(1,\\lambda)$ is a decreasing function of $\\lambda$ over $\\lambda\\in[0,1]$ . Therefore, $f(1,\\lambda)\\ge f(1,1)\\approx0.863$ . ", "page_idx": 20}, {"type": "text", "text": "H.2 Proof of Part (2) of Theorem 4 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Proof. Let $b$ be the serving capacity of the single offilne agent and $\\lambda$ be the total arrival rate of online types. Consider an instance with $b=1$ , and assume all online types are rare. In other words, with probability one, every online type has at most one arrival. For each $t\\,\\in\\,[0,1]$ , let $\\sigma(\\lambda,t)$ be the fairness achieved by an optimal online algorithm under FAIR-S when the online process is restricted as Poisson process of rate $\\lambda t$ . Thus, we care about the value $\\sigma(\\lambda,1)$ , which is the fairness achieved by the online optimal. ", "page_idx": 21}, {"type": "text", "text": "Consider an infinitesimally small period $\\delta$ during which at most one arrival can occur. Now we try to upper bound $\\sigma(\\lambda,t+\\delta)$ . (Case 1) There is no arrival during $(t,t+\\delta]$ which occurs with probability $\\mathsf{e}^{-\\lambda\\delta}$ . In the case, we have $\\sigma(\\lambda,t+\\delta)=\\sigma(\\lambda,t)$ . (Case 2) There is one arrival during $(t,t+\\delta]$ which occurs with probability $1\\!-\\!\\ e^{-\\lambda\\delta}$ . In this case, we have $\\sigma(\\lambda,t\\!+\\!\\delta)\\leq\\operatorname*{min}(\\sigma(\\lambda,t),1\\!-\\!\\sigma(\\lambda,t)\\!+\\!\\mathfrak{e}^{-\\lambda t})$ , which is shown as below. ", "page_idx": 21}, {"type": "text", "text": "Let $\\alpha_{t,k}$ be the fairness achieved by an online optimal when there are $k$ arrivals during $[0,t]$ . Observe that $\\alpha_{t,0}=1$ for all $t\\in[0,1]$ . Therefore, by definition, $\\begin{array}{r}{\\sigma(\\lambda,t)=\\sum_{k=0}^{\\infty}\\alpha_{t,k}\\,\\mathrm{Pr}[\\dot{\\mathrm{Pois}}(\\lambda t)=k]}\\end{array}$ Assume there is one arrival during $(t,t+\\delta]$ . Note that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma(\\lambda,t+\\delta)=\\displaystyle\\sum_{k=0}^{\\infty}\\operatorname*{min}(\\alpha_{t,k},1-k\\cdot\\alpha_{t,k})\\operatorname*{Pr}[\\mathrm{Pois}(\\lambda t)=k]}\\\\ &{\\phantom{\\sigma(\\lambda,t+\\delta)}\\leq\\displaystyle\\sum_{k=0}^{\\infty}\\alpha_{t,k}\\operatorname*{Pr}[\\mathrm{Pois}(\\lambda t)=k]=\\sigma(\\lambda,t),}\\\\ &{\\sigma(\\lambda,t+\\delta)\\leq\\displaystyle\\sum_{k=0}^{\\infty}(1-k\\cdot\\alpha_{t,k})\\operatorname*{Pr}[\\mathrm{Pois}(\\lambda t)=k]}\\\\ &{\\phantom{\\sigma(\\lambda,t+\\delta)}\\leq1-\\displaystyle\\sum_{k=1}^{\\infty}\\alpha_{t,k}\\operatorname*{Pr}[\\mathrm{Pois}(\\lambda t)=k]=1-(\\sigma(\\lambda,t)-\\mathrm{e}^{-\\lambda t}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus, we claim that $\\sigma(\\lambda,t+\\delta)\\leq\\operatorname*{min}(\\sigma(\\lambda,t),1-\\sigma(\\lambda,t)+\\mathrm{{e}}^{-\\lambda t})$ . Wrapping up all the above analysis, we hav $z\\,\\sigma(\\lambda,t+\\delta)\\leq\\mathrm{e}^{-\\lambda\\delta}\\sigma(\\lambda,t)+(1-\\mathrm{e}^{-\\lambda\\delta})\\operatorname*{min}(\\sigma(\\lambda,t),1-\\sigma(\\lambda,t)+\\mathrm{e}^{-\\lambda t})$ . This suggests that $\\partial\\sigma(\\lambda,t)/\\partial t\\leq-\\lambda\\sigma(\\lambda,t)+\\lambda\\operatorname*{min}(\\sigma(\\lambda,t),1-\\sigma(\\lambda,t)+\\mathrm{e}^{-\\lambda t})$ . ", "page_idx": 21}, {"type": "text", "text": "For each given $\\lambda\\in[0,1]$ , let $R_{\\lambda}(t)$ be the unique function satisfying that $d R_{\\lambda}(t)/d t=-\\lambda R_{\\lambda}(t)+$ $\\lambda\\operatorname*{min}(R_{\\lambda}(t),1-R_{\\lambda}(t)+\\mathsf{e}^{-\\lambda t})$ with $R_{\\lambda}(0)=1$ . Thus, we claim that $\\sigma(\\lambda,1)\\leq R_{\\lambda}(1)$ . Recall that the offline optimal has a performance of e\u2212\u03bb(1 + \u03bb) + k\u221e=2e\u2212k\u03bb!k\u03bbk under FAIR-S. We can ically verify that $\\begin{array}{r}{R_{\\lambda}(1)/\\big(\\mathrm{e}^{-\\lambda}(1+\\lambda)+\\sum_{k=2}^{\\infty}\\frac{\\mathrm{e}^{-\\lambda}\\lambda^{k}}{k!k}\\big)}\\end{array}$ gets its minimum value of 0.942 when $\\lambda=1$ . Thus, we establish our result. ", "page_idx": 21}, {"type": "text", "text": "H.3 Proof of Part (3) of Theorem 4: Asymptomatically Optimal Algorithhm of Prob-Rej for FAIR-S with a Single Offline Agent ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Let $\\mathcal{T}(b,\\lambda)$ denote an instance of online matching under short-run fairness FAIR-S with a single offline agent of capacity $b$ and a total online arrival rate of $\\lambda\\gg1$ . ", "page_idx": 21}, {"type": "text", "text": "Lemma 8. Consider an instance $\\,\\mathcal{T}(b,\\lambda)\\,w i t h\\;b/\\lambda<1$ . We have ${\\sf O P T}\\le(b/\\lambda)\\cdot\\bigl(1+1/\\lambda+o(1/\\lambda)\\bigr)$ . ", "page_idx": 21}, {"type": "text", "text": "Proof. Let $\\textstyle A\\,=\\,\\sum_{j\\in J}A_{j}$ be the total number of online arrivals. Observe that the performance of an optimal clairvoyant under FAIR-S should satisfy (1) $\\mathsf{O P T}(A)\\,=\\,1$ when $A\\,\\leq\\,b$ and (2) ${\\mathsf{O P T}}({\\bar{A}})=b/k$ when $A=k>b$ . Therefore, ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{O P T}=\\mathbb{E}_{A}[\\mathsf{O P T}(A)]}\\\\ &{\\qquad=\\mathrm{Pr}[A\\leq b]\\cdot1+\\displaystyle\\sum_{k>b}^{\\infty}\\mathrm{Pr}[A=k]\\cdot\\frac{b}{k}}\\\\ &{\\qquad\\leq\\mathrm{Pr}[A\\leq\\lambda(1-(1-\\kappa))]+b\\cdot\\displaystyle\\sum_{k=1}^{\\infty}\\frac{\\mathrm{e}^{-\\lambda}\\lambda^{k}}{k!}\\frac{1}{k}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "equation", "text": "$$\n\\leq\\exp\\Big(-\\frac{\\lambda(1-\\kappa)^{2}}{2}\\Big)+b\\cdot\\Big(\\frac{1}{\\lambda}+\\frac{1}{\\lambda^{2}}+o\\big(\\frac{1}{\\lambda^{2}}\\big)\\Big)=\\kappa\\Big(1+\\frac{1}{\\lambda}+o\\big(\\frac{1}{\\lambda}\\big)\\Big).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that the inequality on the last line is due to the lower tail bound of a Poisson random variable as shown by [8]. Another trick involved is $\\begin{array}{r}{\\sum_{k=1}^{\\infty}\\frac{\\lambda^{k}}{k!}\\frac{1}{k}\\ =\\ \\mathrm{Ei}(\\lambda)\\,-\\,\\ln\\lambda\\,-\\,\\gamma}\\end{array}$ where $\\begin{array}{r}{\\gamma\\doteq\\operatorname*{lim}_{n\\to\\infty}\\left(\\sum_{k=1}^{n}1/k-\\ln n\\right)\\approx0.577}\\end{array}$ is a constant, and Ei is the Exponential integral function. As shown by [32], $\\operatorname{Ei}(\\lambda)=(\\mathsf{e}^{\\lambda}/\\lambda)(1+1/\\lambda+o(1/\\lambda))$ when $\\lambda\\gg1$ . Thus, we are done. \u53e3 ", "page_idx": 22}, {"type": "text", "text": "Now, we formally present the algorithm Prob-Rej in Algorithm 6, which shares the spirit as RESERVE as shown in Section G.2. Part (3) of Theorem 4 shows that Prob-Rej is 1-competitive as the total arrival rate $\\lambda\\rightarrow\\infty$ , even if the service capacity $b$ is increasing at the same time. Depending on whether $b/\\lambda$ is greater than 1, the probabilistic rejection probabilities have to be chosen differently. Also, note that due to dependent rounding, Prob-Rej is less likely to reject an agent if other agents have already been rejected, distributing equal opportunity among the first $K$ arrivals to be served. This dependent rounding makes it different from SAMP, SAMP-G, and similar algorithms in the literature. ", "page_idx": 22}, {"type": "text", "text": "ALGORITHM 6: Probabilistic-Rejection Algorithm for FAIR-S with a Single Offline Agent (Prob-Rej) ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "1 Set $\\epsilon=b/\\lambda-1$ if $b/\\lambda>1$ and $\\epsilon=\\sqrt{\\ln\\lambda/\\lambda}$ otherwise. let $K=\\lfloor\\lambda(1+\\epsilon)\\rfloor$ .   \n2 Apply dependent rounding [16] to the vector $\\mathbf{x}=\\left(b/K\\right)\\cdot\\mathbf{1}$ , which has $K$ identical entries each equal $b/K$ .   \nLet $(Y_{k})_{k}\\in\\{0,1\\}^{K}$ be the random vector output.   \n3 Suppose an online agent (of type) $j$ arrives, and let it be the $k$ th arrival among all online arrivals.   \n4 If $k\\leq K$ and $Y_{k}=1$ , then serve the incoming type- $j$ agent if it is possible; otherwise, reject agent $j$ . ", "page_idx": 22}, {"type": "text", "text": "Proof of Part (3) of Theorem 4. For notation convenience, we use $\\mathcal{T}$ to denote $\\mathcal{T}(b,\\lambda)$ , which represents an instance under FAIR-S with a single offline agent of capacity $b$ and a total online arrival rate of $\\lambda$ . Additionally, we use ALG to refer to the probabilistic-rejection algorithm Prob-Rej. By definition, we have $\\begin{array}{r}{\\mathsf{\\Lambda A L G}(\\mathbb{Z})=\\mathbb{E}_{A}\\Big[\\operatorname*{min}_{j:A_{j}>0}\\mathbb{E}_{\\mathsf{A L G}}[X_{j}]/A_{j}\\Big]\\doteq\\mathbb{E}_{A}[\\mathsf{A L G}(\\mathcal{A})]}\\end{array}$ . Consider a given arrival vector $\\boldsymbol{\\mathcal{A}}$ with $A$ being the total number of online arrivals. By definition, we have $\\mathsf{A L G}(\\mathcal{A})=1$ when $A=0$ . ", "page_idx": 22}, {"type": "text", "text": "Now, we show that $\\mathsf{A L G}(A)\\,=\\,b/K$ when (1) $0\\;<\\;A\\;\\leq\\;K$ and (2) $b/K\\,\\leq\\,1$ . Note that by dependent rounding, we have $(\\mathbf{P1})$ $\\mathrm{Pr}[Y_{j}=1]=b/K$ for all $j\\in[K]:=\\{1,2,\\dots,K\\}$ and $(\\mathbf{P}2)$ $\\begin{array}{r}{\\operatorname*{Pr}\\left[\\sum_{j=1}^{K}Y_{j}\\le\\sum_{j=1}^{K}b/K=b\\right]=1}\\end{array}$ . Focus on a given $j\\in J$ with $A_{j}>0$ . Consider a specific online arrival of type $j$ , which is counted as the $k$ th arrival among all online arrivals. When $A\\leq K$ , we see that $k\\leq K$ and the single offline agent will not reach the capacity upon arrival due to $(\\mathbf{P}2)$ . Thus, we claim that the type- $j$ agent will be served with probability equal to $\\mathrm{Pr}[Y_{k}=1]=b/K$ for each of its $A_{j}$ arrivals. Thus, $\\mathbb{E}[X_{j}]=A_{j}\\cdot b/K$ and $\\mathsf{A L G}(A)=\\operatorname*{min}_{j:A_{j}>0}$ EALG[Xj]/Aj = b/K. Consider the following three cases. ", "page_idx": 22}, {"type": "text", "text": "(Case 1) $b>\\lambda$ . In this case, $K=b$ . If $A=0$ , $\\mathsf{A L G}(\\mathcal{A})=1$ and if $0<A\\leq K$ , $\\mathsf{A L G}(A)=b/K=$ 1. Thus, we claim that $\\mathsf{A L G}(\\mathcal{A})=1$ when $A\\leq K$ . ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{i}\\mathrm{LG}(\\mathcal{Z})=\\mathbb{E}_{A}[\\mathsf{A L G}(A)]\\ge\\operatorname*{Pr}[A\\le K]=1-\\operatorname*{Pr}[\\operatorname*{Pois}(\\lambda)>b]\\ge1-\\exp\\big(-\\lambda(b/\\lambda-1)^{2}/(2b/\\lambda)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that $\\mathsf{O P T}(\\mathcal{Z})\\leq1$ . Thus, $\\mathsf{A L G}(\\mathcal{T})/\\mathsf{O P T}(\\mathcal{T})\\geq\\mathsf{A L G}(\\mathcal{T})$ and we are done. ", "page_idx": 22}, {"type": "text", "text": "(Case 2) $b=\\lambda$ . In this case, when $A\\leq K$ $\\zeta,\\mathsf{A L G}(A)\\geq b/K\\geq1/(1+\\epsilon)$ . Thus, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathrm{i}.\\mathsf{L G}(\\mathbb{Z})/\\mathsf{O P T}(\\mathbb{Z})\\geq\\mathsf{A L G}(\\mathbb{Z})=\\mathbb{E}_{A}[\\mathsf{A L G}(A)]\\geq\\frac{\\operatorname*{Pr}[A\\leq K]}{1+\\epsilon}\\geq\\left(1-\\exp\\left(-\\frac{\\lambda\\epsilon^{2}}{2(1+\\epsilon)}\\right)\\right)\\cdot\\frac{1}{1+\\epsilon}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Since $\\epsilon=\\sqrt{\\ln\\lambda/\\lambda}$ , we establish our claim. ", "page_idx": 22}, {"type": "text", "text": "(Case 3) $b<\\lambda$ . We have $\\mathsf{A L G}(A)\\geq b/K\\geq(b/\\lambda)/(1+\\epsilon)$ when $A\\leq K$ . Thus, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathsf{A L G}(\\mathbb{Z})=\\mathbb{E}_{A}[\\mathsf{A L G}(A)]\\geq\\operatorname*{Pr}[A\\leq K]\\cdot\\frac{b/\\lambda}{1+\\epsilon}\\geq\\left(1-\\exp\\Big(-\\frac{\\lambda\\epsilon^{2}}{2(1+\\epsilon)}\\Big)\\right)\\cdot\\frac{b/\\lambda}{1+\\epsilon}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By Lemma 8, we have that for any given instance $\\mathcal{T}(b,\\lambda)$ with $b<\\lambda$ , ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\frac{\\mathsf{A L G}(\\mathbb{Z})}{\\mathsf{O P T}(\\mathbb{Z})}\\geq\\left(1-\\exp\\Big(-\\frac{\\lambda\\epsilon^{2}}{2(1+\\epsilon)}\\Big)\\right)\\cdot\\frac{1}{1+\\epsilon}\\cdot\\frac{1}{1+1/\\lambda+o(1/\\lambda)}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Since $\\epsilon=\\sqrt{\\ln\\lambda/\\lambda}$ , we establish our claim. ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to ", "page_idx": 27}, {"type": "text", "text": "generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. ", "page_idx": 28}, {"type": "text", "text": "\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. \u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 28}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] Justification: ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]