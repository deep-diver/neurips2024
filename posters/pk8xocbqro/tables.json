[{"figure_path": "PK8xOCBQRO/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of different algorithms on simulated networks. Each cell reports \u00b12\u03c3 of the mean-squared error over 50 independent trials. Error numbers are all scaled by 1e2 for ease of reading. Bold: Best algorithm. Emphasis: Second-best algorithm.", "description": "The table compares the performance of three algorithms (Algorithm 1, Algorithm 2, and Oracle) on six simulated network datasets.  The algorithms are evaluated based on their mean squared error (MSE), with error bars representing \u00b12 standard deviations.  The MSE values are scaled by a factor of 100.  The \"Oracle\" represents an ideal scenario with full access to data, while Algorithms 1 and 2 leverage transfer learning.  The best performing algorithm for each dataset is highlighted in bold, with the second-best in italics.", "section": "4 Experiments"}, {"figure_path": "PK8xOCBQRO/tables/tables_7_2.jpg", "caption": "Table 1: Comparison of different algorithms on simulated networks. Each cell reports \\(\\hat{\\mu} \\pm 2\\sigma\\) of the mean-squared error over 50 independent trials. Error numbers are all scaled by 1e2 for ease of reading. Bold: Best algorithm. Emphasis: Second-best algorithm.", "description": "This table compares the performance of three algorithms (Algorithm 1, Algorithm 2, and Oracle) on six different simulated network datasets.  Each dataset is characterized by a source and target network type (Noisy-MMSB, 0.1-Smooth Graphon, 0.5-Smooth Graphon, Graphon R10, Latent(2.5), Latent(1.0)).  The results show the mean squared error (MSE), averaged over 50 independent trials, along with the standard error of the mean.  The table highlights the best-performing algorithm for each dataset.", "section": "4 Experiments"}]