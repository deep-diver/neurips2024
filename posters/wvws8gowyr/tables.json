[{"figure_path": "WvWS8goWyR/tables/tables_6_1.jpg", "caption": "Table 1: Numerical outcomes in terms of PCEE. The last row calculates the difference in PCEE between the two groups: the smaller, the better, and the best value is in bold.", "description": "This table presents the Proportion of Correctly Estimated Edges (PCEE) for standard and fair Gaussian graphical models (GLasso), Gaussian covariance graph models (CovGraph), and binary Ising models (BinNet).  It shows the PCEE for each model and for two separate groups, along with the difference in PCEE between the groups. A lower difference indicates better fairness.", "section": "4.2 Simulation Study of Fair GLasso and CovGraph"}, {"figure_path": "WvWS8goWyR/tables/tables_8_1.jpg", "caption": "Table 2: Outcomes in terms of the value of the objective function (F1), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. \u201c\u2193\u201d means the smaller, the better, and the best value is in bold. Note that both F\u2081 and A are deterministic.", "description": "This table presents the performance of the proposed Fair GM framework and the baseline GM method across six different datasets. The metrics include the objective function value (F1), the sum of pairwise graph disparity errors (\u25b3), and the computation time. Lower values of F1 and \u25b3 indicate better performance, while lower runtime is preferred. The results show that Fair GM generally achieves comparable performance to the baseline GM, while significantly reducing bias, indicated by lower values of \u25b3. The runtime is usually longer for Fair GM.", "section": "4 Experiment"}, {"figure_path": "WvWS8goWyR/tables/tables_16_1.jpg", "caption": "Table 2: Outcomes in terms of the value of the objective function (F1), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. \u201c\u2193\u201d means the smaller, the better, and the best value is in bold. Note that both F\u2081 and A are deterministic.", "description": "This table presents the results of experiments conducted on four different datasets (Simulation, TCGA, Credit, and LFM-1b) using both standard GMs and Fair GMs.  The table compares the standard and Fair versions of GLasso, CovGraph, and BinNet on the objective function value (F1), the sum of pairwise graph disparity error (\u25b3), and runtime.  Lower values for F1 and \u25b3 are better indicating improved performance and fairness, respectively.  It shows that the proposed Fair GMs achieve better fairness results without significant performance loss compared to the standard models.", "section": "4 Experiment"}, {"figure_path": "WvWS8goWyR/tables/tables_27_1.jpg", "caption": "Table 4: Outcomes in terms of the value of the objective function (F1), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. \u201c\u2193\u201d means the smaller, the better, and the best value is in bold. These experiments are conducted on an Apple M2 Pro processor. Note that both F\u2081 and A are deterministic.", "description": "This table presents the results of experiments conducted on two real-world datasets (AV45 and AV1451) using both standard GLasso and the proposed Fair GLasso method.  The table compares the objective function value (F1), the pairwise graph disparity error (\u25b3), and the runtime for each method across the datasets.  Lower values for F1 and \u25b3 are preferred, indicating better model performance and fairness.  The runtime provides a measure of the computational efficiency of each method.", "section": "4. Application of Fair GLasso to Amyloid / Tau Accumulation Network"}, {"figure_path": "WvWS8goWyR/tables/tables_28_1.jpg", "caption": "Table 2: Outcomes in terms of the value of the objective function (F1), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. \u201c\u2193\u201d means the smaller, the better, and the best value is in bold. Note that both F\u2081 and A are deterministic.", "description": "This table summarizes the performance of the proposed Fair GM framework and compares it against a standard GM on various datasets. The metrics used to evaluate the performance are the objective function value (F1), which measures the model's fit to the data, the summation of pairwise graph disparity error (\u25b3), which quantifies the fairness of the model, and the average computation time. The results show that Fair GM achieves a better balance between model accuracy and fairness.", "section": "4 Experiment"}, {"figure_path": "WvWS8goWyR/tables/tables_29_1.jpg", "caption": "Table 6: Numerical outcomes in terms of the value of the objective function (F\u2081), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. K = 2 and Nk = 1000 \u2200k \u2208 [K]. \u201c\u2193\u201d means the smaller, the better, and the best value is in bold. These experiments are conducted on an Apple M2 Pro processor. Note that both F\u2081 and \u0394 are deterministic.", "description": "This table presents the results of a sensitivity analysis on the feature size (P) in the GLasso algorithm.  For each feature size (from 50 to 400), it shows the objective function value (F1), the pairwise graph disparity error (\u0394), and the runtime for both standard GLasso and Fair GLasso.  The percentage change in F1 and \u0394 between the two methods are also included, highlighting the trade-off between fairness and model performance.", "section": "D.6 Sensitivity Analysis to Feature Size P"}, {"figure_path": "WvWS8goWyR/tables/tables_30_1.jpg", "caption": "Table 2: Outcomes in terms of the value of the objective function (F1), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. \u201c\u2193\u201d means the smaller, the better, and the best value is in bold. Note that both F\u2081 and A are deterministic.", "description": "This table presents the results of experiments evaluating the performance of the proposed Fair GM framework across various datasets. The metrics used are the objective function value (F1), the pairwise graph disparity error (\u25b3), and runtime. Lower values of F1 and \u25b3 indicate better performance. Each result is averaged across 10 repeated experiments.", "section": "4 Experiment"}, {"figure_path": "WvWS8goWyR/tables/tables_31_1.jpg", "caption": "Table 2: Outcomes in terms of the value of the objective function (F1), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. \u201c\u2193\u201d means the smaller, the better, and the best value is in bold. Note that both F\u2081 and A are deterministic.", "description": "This table presents the results of experiments on several datasets using both standard graphical models (GM) and the proposed Fair GMs.  It compares the objective function value (F1), the pairwise graph disparity error (\u25b3), and runtime for each method. Lower values for F1 and \u25b3 are better, indicating improved model performance and fairness.", "section": "4 Experiment"}, {"figure_path": "WvWS8goWyR/tables/tables_32_1.jpg", "caption": "Table 10: Outcomes of additional baseline with different optimization algorithms applied to GLasso and Multi-Objective Optimization (MOO), measured in terms of the value of the objective function (F1), the summation of the pairwise graph disparity error (\u25b3), and the average computation time in seconds (\u00b1 standard deviation) from 10 repeated experiments. \u201c\u2193\u201d indicates that smaller values are better. Our method applies ISTA to both GLasso and MOO (first row in each experiment). All experiments are conducted using the same runtime environment on Google Colab.", "description": "This table compares the performance of different optimization algorithms (ISTA, FISTA, PISTA, GISTA, OBN) for both GLasso and MOO in terms of the objective function (F1), pairwise graph disparity error (\u25b3), and runtime.  It demonstrates the impact of these optimization methods on mitigating bias (indicated by \u0394) and maintaining model performance (F1) while improving computational efficiency (runtime). The results are shown for three different synthetic datasets with varying numbers of subgroups, variables and observations.", "section": "D.10 Addendum to Subsection 4.8"}]