[{"figure_path": "gcpeEg88R3/tables/tables_8_1.jpg", "caption": "Table 1: Average log predictive score (lower is better) with error bars corresponding to two standard deviations over five runs for density estimation on datasets analysed by [35]. We note that as dimension increases, the QB-Vine outperforms all benchmarks.", "description": "This table presents the average log predictive scores for density estimation on five different datasets using various methods, including the proposed QB-Vine method and several state-of-the-art baselines.  The table highlights the QB-Vine's superior performance, particularly as dimensionality increases. Error bars represent two standard deviations from the mean over five runs, indicating the variability of each method's performance.", "section": "Experiments"}, {"figure_path": "gcpeEg88R3/tables/tables_9_1.jpg", "caption": "Table 2: Average LPS (lower is better) with error bars corresponding to two standard deviations over five runs for supervised tasks analysed by [35]. The QB-Vine performs favourably against benchmarks, with relative performance improving as samples per dimension decrease.", "description": "This table compares the performance of the QB-Vine model against other methods on several regression and classification tasks.  The results are presented as the average log predictive score (LPS), a lower score indicating better performance. Error bars represent two standard deviations, showing variability in the results across multiple runs. The table highlights QB-Vine's superior performance, particularly when the number of samples relative to the dimensions is low.", "section": "Experiments"}, {"figure_path": "gcpeEg88R3/tables/tables_27_1.jpg", "caption": "Table 3: Average LPS (in bpd, lower is better) over five runs with standard errors for the Digits dataset.", "description": "This table presents the average log predictive score (LPS) in bits per dimension (bpd) for the Digits dataset.  The LPS is a metric used to evaluate the performance of density estimation models, with lower values indicating better performance. The table shows the results for various models including MAF, RQ-NSF, R-BP, AR-BP, and the QB-Vine with different training sample sizes (30, 50, 100, 200, 300, 400, 500), as well as the QB-Vine trained on the full dataset. Error bars represent standard errors over five runs.", "section": "5 Experiments"}, {"figure_path": "gcpeEg88R3/tables/tables_28_1.jpg", "caption": "Table 1: Average log predictive score (lower is better) with error bars corresponding to two standard deviations over five runs for density estimation on datasets analysed by [35]. We note that as dimension increases, the QB-Vine outperforms all benchmarks.", "description": "This table shows the average log predictive score (LPS) for various density estimation methods on five different datasets.  Error bars represent two standard deviations over five runs. The QB-Vine method is compared against several other methods (KDE, DPMM, MAF, RQ-NSF, PRticle Filter, R-BP, AR-BP). The table highlights that the QB-Vine's performance improves significantly as the dimensionality of the data increases, outperforming other methods.", "section": "Experiments"}, {"figure_path": "gcpeEg88R3/tables/tables_28_2.jpg", "caption": "Table 5: Choice of p0 for different regression and classification experiments.", "description": "This table shows the initial predictive distribution, p0, used for different datasets in the regression and classification experiments.  The choice of p0, which is a hyperparameter, impacts the initialization of the Quasi-Bayesian Vine (QB-Vine) model.  The table lists five datasets: BOSTON (regression), CONCR (regression), DIAB (regression), IONO (classification), and PARKIN (classification), and specifies the initial distribution (Normal or Cauchy) selected for each.", "section": "Experiments"}, {"figure_path": "gcpeEg88R3/tables/tables_29_1.jpg", "caption": "Table 1: Average log predictive score (lower is better) with error bars corresponding to two standard deviations over five runs for density estimation on datasets analysed by [35]. We note that as dimension increases, the QB-Vine outperforms all benchmarks.", "description": "This table presents the average log predictive scores for density estimation on several datasets.  Lower scores indicate better performance.  Error bars represent two standard deviations calculated over five runs for each dataset and model.  The table compares the Quasi-Bayesian Vine (QB-Vine) model to several other methods, showing that QB-Vine's performance improves relative to other methods as the dimensionality of the data increases.", "section": "Experiments"}, {"figure_path": "gcpeEg88R3/tables/tables_30_1.jpg", "caption": "Table 7: Comparison of the MMD (lower is better) computed on samples from the QBVine and RQNSF models across different dimensions and GMMs. Each cell shows the QBVine value on top and the RQNSF value on the bottom, separated by a dotted line. The QB-Vine outperforms the RQNSF in all cases considered, demonstrating better sample quality via this metric.", "description": "This table compares the performance of the Quasi-Bayesian Vine (QB-Vine) and the Rank-ordered Normalizing Flows (RQ-NSF) models on Gaussian Mixture Models (GMMs) with varying dimensions (400, 500, 600) and five different GMMs.  The Maximum Mean Discrepancy (MMD) is used as the evaluation metric, where lower values indicate better model performance.  The table shows the QB-Vine consistently outperforms the RQ-NSF in all scenarios, suggesting that the QB-Vine generates samples of higher quality.", "section": "Experiments"}]