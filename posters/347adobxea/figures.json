[{"figure_path": "347aDObXEa/figures/figures_1_1.jpg", "caption": "Figure 1: Visualization of the embedding of the same graph in hyperbolic space (left) and Euclidean space (right), with different colors representing different class labels. Tree-like subgraphs maintain significant inter-class margins in hyperbolic space, leading to improved classification boundaries, while intra-class nodes with Euclidean properties may be overstretched due to the utilization of hyperbolic metrics, hence embedding in Euclidean space is preferred.", "description": "This figure shows a comparison of graph embeddings in hyperbolic and Euclidean spaces.  The left side illustrates how a graph is embedded in hyperbolic space, preserving tree-like structures and maximizing the distance between different classes. The right shows the embedding in Euclidean space, where some intra-class nodes are closer together, leading to potential classification issues.  This visual demonstrates the strengths and weaknesses of each geometric space for representing graph data.", "section": "Motivation"}, {"figure_path": "347aDObXEa/figures/figures_4_1.jpg", "caption": "Figure 2: Illustration of our proposed cross-geometry graph KD framework. Structure-Wise Knowledge Transfer (SWKT): Choosing embeddings in appropriate geometric spaces using \u03b4\u03c2; of nodes, conveying local subgraph topological knowledge to the student model: ZT Z(2), E denotes Euclidean teaching, and Z), denotes the hyperbolic teaching. GEO: Enhancing hint embeddings from the teacher models, reducing the negative effects of inconsistencies between different geometries.", "description": "This figure illustrates the proposed cross-geometry graph knowledge distillation (KD) framework. It shows how multiple teacher models (using Euclidean and hyperbolic geometries) generate hint embeddings that encapsulate distinct geometric properties.  A structure-wise knowledge transfer module leverages these embeddings to enhance student model training. A geometric optimization network bridges distributional disparities among embeddings. The framework uses local subgraph analysis to select the most appropriate geometry for each subgraph. This is visualized as selecting between Euclidean and hyperbolic embeddings.", "section": "4 Cross-Geometry Learning with KD"}, {"figure_path": "347aDObXEa/figures/figures_8_1.jpg", "caption": "Figure 2: Illustration of our proposed cross-geometry graph KD framework. Structure-Wise Knowledge Transfer (SWKT): Choosing embeddings in appropriate geometric spaces using \u03b4g; of nodes, conveying local subgraph topological knowledge to the student model: ZT(l),E denotes Euclidean teaching, and ZT(l),B denotes the hyperbolic teaching. GEO: Enhancing hint embeddings from the teacher models, reducing the negative effects of inconsistencies between different geometries.", "description": "This figure illustrates the proposed cross-geometry graph knowledge distillation (KD) framework. It highlights two key modules: Structure-Wise Knowledge Transfer (SWKT) and Geometric Embedding Optimization (GEO). SWKT selects the most appropriate geometric space (Euclidean or hyperbolic) for embedding each node based on its local subgraph's hyperbolicity. GEO optimizes the distribution of hint embeddings from multiple teacher models to mitigate inconsistencies between different geometries, thereby improving knowledge transfer to the student model.", "section": "4 Cross-Geometry Learning with KD"}, {"figure_path": "347aDObXEa/figures/figures_13_1.jpg", "caption": "Figure 4: Spaces with different curvatures. (a) Spherical space with curvature c = 1.0. (b) Euclidean space. (c) Hyperbolic space with curvature c = \u22120.5. (d) Hyperbolic space with curvature c = \u22121, which have a faster grow rate of volume.", "description": "This figure visualizes four different types of spaces with varying curvatures: spherical (positive curvature), Euclidean (zero curvature), and two hyperbolic spaces with different negative curvatures.  It illustrates how the curvature affects the geometry of the space, particularly the rate at which volume grows as one moves away from a central point. The image helps to understand the differences between these geometries in the context of graph representation, where different geometries might be more suitable for different types of graph structures.", "section": "Additional Theoretical Support"}, {"figure_path": "347aDObXEa/figures/figures_19_1.jpg", "caption": "Figure 5: t-SNE Visualization of embeddings obtained by student models.In contrast to baselines,our method achieves embeddings that fully utilize the entire space, ensuring substantial inter-class distances and thereby enhancing node classification performance.", "description": "This figure shows the t-SNE visualization of node embeddings generated by different knowledge distillation methods, including FitNet, AT, LSP, MSKD, VQG, and the proposed cross-geometry method. The visualization reveals that the proposed method produces embeddings that better utilize the embedding space, resulting in significantly larger inter-class distances compared to other methods. This improved separation of classes in the embedding space leads to better classification performance.", "section": "4 Cross-Geometry Learning with KD"}, {"figure_path": "347aDObXEa/figures/figures_20_1.jpg", "caption": "Figure 2: Illustration of our proposed cross-geometry graph KD framework. Structure-Wise Knowledge Transfer (SWKT): Choosing embeddings in appropriate geometric spaces using \u03b4\u03c2; of nodes, conveying local subgraph topological knowledge to the student model: ZT Z(2), E denotes Euclidean teaching, and Z), denotes the hyperbolic teaching. GEO: Enhancing hint embeddings from the teacher models, reducing the negative effects of inconsistencies between different geometries.", "description": "This figure illustrates the proposed cross-geometry graph knowledge distillation (KD) framework.  It shows how the framework uses multiple teacher models (Euclidean and Hyperbolic) to generate hint embeddings which encapsulate distinct geometric properties. A Structure-Wise Knowledge Transfer (SWKT) module selects appropriate embeddings based on local subgraph analysis. A Geometric Optimization (GEO) module refines the embeddings to reduce inconsistencies between different geometric spaces. Finally, the refined embeddings are transferred to the student model for improved performance.", "section": "4 Cross-Geometry Learning with KD"}]