[{"figure_path": "347aDObXEa/tables/tables_7_1.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. \u03b4 represents the global hyperbolicity.", "description": "This table presents the F1 scores and ROC AUC for node classification (NC) and link prediction (LP) tasks.  Different knowledge distillation (KD) methods are compared across Euclidean (E), hyperbolic (B), and spherical (S) geometries, both individually and in combinations. The results are shown for various datasets with different levels of hyperbolicity (\u03b4).  Higher scores indicate better performance.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_9_1.jpg", "caption": "Table 2: F1 scores(%)\u2191 of student model distilled by all KD methods for NC on Arxiv and Proteins.", "description": "This table presents the F1 scores achieved by different knowledge distillation (KD) methods on node classification (NC) tasks using the Arxiv and Proteins datasets.  It compares the performance of the student models trained using various KD techniques across different geometric spaces, highlighting the effectiveness of the proposed cross-geometry KD method in achieving superior performance compared to traditional KD approaches using single geometric spaces.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_9_2.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. \u03b4 represents the global hyperbolicity.", "description": "This table presents the results of node classification (NC) and link prediction (LP) tasks using different knowledge distillation (KD) methods.  It compares the performance of models trained using only Euclidean geometry (E), only hyperbolic geometry (B), only spherical geometry (S), and combinations of these geometries. The F1 score and ROC AUC are reported for each dataset and method, demonstrating the superiority of the cross-geometry approach.  The global hyperbolicity (\u03b4) of each dataset is also indicated.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_9_3.jpg", "caption": "Table 4: Ablation study results.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of individual components of the proposed cross-geometry graph knowledge distillation framework. It shows the performance (F1 scores and ROC AUC) of the model when using only a Euclidean teacher, only a hyperbolic teacher, without the Structure-Wise Knowledge Transfer (SWKT) module, without the Geometric Embedding Optimization (GEO) module, and with the comprehensive method (including both SWKT and GEO).  The results highlight the contribution of each component to the overall performance improvement.", "section": "5. Experiments"}, {"figure_path": "347aDObXEa/tables/tables_15_1.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. d represents the global hyperbolicity.", "description": "This table presents the F1 scores and ROC AUC values achieved by various knowledge distillation (KD) methods on node classification (NC) and link prediction (LP) tasks.  Different KD methods are compared, using either Euclidean (E), hyperbolic (B), or spherical (S) geometry, or combinations thereof. The results are shown for several datasets with varying levels of global hyperbolicity (\u03b4), demonstrating the performance of different geometric approaches for graph data.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_15_2.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space.  \u03b4 represents the global hyperbolicity.", "description": "This table presents the performance comparison of various knowledge distillation (KD) methods on node classification (NC) and link prediction (LP) tasks across different datasets.  It shows F1 scores and ROC AUC values for different KD methods using Euclidean, hyperbolic, and spherical geometries individually as well as combinations thereof.  The global hyperbolicity (\u03b4) of each dataset is also provided, offering context for interpreting the results. Higher F1 scores and ROC AUC indicate better performance.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_16_1.jpg", "caption": "Table 6: Parameter Settings in NC task.", "description": "This table presents the hyperparameters used in the node classification (NC) task for each dataset.  The hyperparameters include the number of layers in both the teacher and student models, the dimensions of the hidden layers, the learning rate, weight decay, dropout rate, and the lambda (\u03bb) and beta (\u03b2) parameters used in the cross-geometry knowledge distillation framework.  The values indicate the settings used to optimize the model's performance on each dataset.", "section": "5.1 Experimental Settings"}, {"figure_path": "347aDObXEa/tables/tables_16_2.jpg", "caption": "Table 6: Parameter Settings in NC task.", "description": "This table shows the hyperparameters used for the node classification (NC) task on five different datasets: Wiki-CS, Co-Physics, Pubmed, Citeseer, and Cora.  The parameters include the number of layers in the model, the dimensions of the hidden layers for both the teacher and student models, the learning rate, weight decay, dropout rate, and the hyperparameters \u03bb and \u03b2 specific to the proposed cross-geometry knowledge distillation method.", "section": "5.1 Experimental Settings"}, {"figure_path": "347aDObXEa/tables/tables_17_1.jpg", "caption": "Table 8: F1 scores (%)\u2191 of student models distilled from GAT teacher models on the NC Task.", "description": "This table presents the F1 scores achieved by student models trained using knowledge distillation (KD) with Graph Attention Networks (GATs) as teacher models.  The results are broken down by dataset (Wiki-CS, Co-Physics, Pubmed, Citeseer, Cora), geometry used for the teacher models (Euclidean (E), Hyperbolic (B), Spherical (S), and combinations thereof), and the overall best performing cross-geometry method. Higher F1 scores indicate better performance.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_17_2.jpg", "caption": "Table 9: F1 Scores (%)\u2191 of student models distilled from GTN teacher models on the NC Task.", "description": "This table presents the F1 scores achieved by student models trained using knowledge distillation (KD) with Graph Transformer Network (GTN) teacher models.  The results are broken down by the geometry used (Euclidean (E), Hyperbolic (B)) for both the teacher and student models, showing the performance improvement from cross-geometric training.  Inference times are included for both the GTN and GCN student models to highlight the efficiency of the GCN student.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_18_1.jpg", "caption": "Table 10: F1 scores (%)\u2191 of student models in different geometry on the NC Task.", "description": "This table presents the F1 scores achieved by student models trained using different KD methods and geometric spaces (Euclidean, Hyperbolic, Spherical).  The results showcase the performance of each method in each geometry, offering a comparison of their effectiveness in node classification tasks.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_18_2.jpg", "caption": "Table 11: F1 Scores (%)\u2191 of student models with the same architecture as the teacher models on the NC Task.", "description": "This table presents the F1 scores achieved by student models that have the same architecture as the teacher models for the node classification task. The results are compared across various knowledge distillation (KD) methods, including FitNet, AT, LSP, MSKD, VQG, and the proposed cross-geometry KD method.  The table highlights the performance differences when using Euclidean and Hyperbolic student models and the improvement achieved by the proposed method compared to baseline techniques.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_18_3.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. d represents the global hyperbolicity.", "description": "This table presents the performance of various Knowledge Distillation (KD) methods on node classification (NC) and link prediction (LP) tasks across different datasets.  Each method is tested using Euclidean (E), hyperbolic (B), and spherical (S) geometries, as well as combinations thereof. The F1 score and ROC AUC are reported, along with the global hyperbolicity (d) of each dataset, providing a comprehensive comparison of the methods across different geometric settings.", "section": "5.1 Experimental Settings"}, {"figure_path": "347aDObXEa/tables/tables_19_1.jpg", "caption": "Table 12: F1 scores (%)\u2191 of student models distilled from teacher models with different layers on the NC Task.", "description": "This table presents the F1 scores achieved by student models trained using knowledge distillation from teacher models with varying numbers of layers (1, 2, 3, and 4).  The results are shown for three different scenarios: using a single geometry (Euclidean, Hyperbolic, Spherical), combining two geometries, and combining all three geometries. The table highlights the performance of the proposed cross-geometry approach ('Our') against traditional single-geometry and combined-geometry knowledge distillation methods.  The results demonstrate the robustness and scalability of the proposed method across different teacher model layer configurations.", "section": "5. Experiments"}, {"figure_path": "347aDObXEa/tables/tables_20_1.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. d represents the global hyperbolicity.", "description": "This table presents the F1 scores and ROC AUC values achieved by various knowledge distillation (KD) methods on node classification (NC) and link prediction (LP) tasks.  It compares the performance of models trained using Euclidean geometry (E), hyperbolic geometry (B), spherical geometry (S), and combinations thereof. The global hyperbolicity (\u03b4) of each dataset is also provided, showing the effectiveness of different geometric approaches under varying dataset characteristics.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_20_2.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. \u03b4 represents the global hyperbolicity.", "description": "This table presents the performance comparison of different knowledge distillation (KD) methods on node classification (NC) and link prediction (LP) tasks using various graph datasets. The methods are categorized into Euclidean (E), hyperbolic (B), spherical (S) and cross-geometric approaches.  The table shows F1 scores and ROC AUC scores, along with the global hyperbolicity (\u03b4) for each dataset, indicating the effectiveness of each method across different geometric spaces and dataset characteristics.", "section": "5.2 Node Classification"}, {"figure_path": "347aDObXEa/tables/tables_21_1.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. d represents the global hyperbolicity.", "description": "This table presents the performance comparison of various knowledge distillation (KD) methods on node classification (NC) and link prediction (LP) tasks.  It shows F1 scores and ROC AUC values for different KD methods applied to datasets with varying global hyperbolicities. Each method is evaluated using Euclidean (E), hyperbolic (B), spherical (S) spaces, and combinations thereof, showcasing the impact of different geometric spaces on the performance of student models trained via KD.", "section": "5. Experiments"}, {"figure_path": "347aDObXEa/tables/tables_21_2.jpg", "caption": "Table 1: F1 scores(%)\u2191 and ROC AUC(%)\u2191 of student model distilled by all KD methods for NC and LP tasks. E, B, S respectively denote the method being in Euclidean, hyperbolic, and spherical spaces, with multiple symbols representing cross geometric space. \u03b4 represents the global hyperbolicity.", "description": "This table presents the performance comparison of various knowledge distillation (KD) methods on node classification (NC) and link prediction (LP) tasks.  It shows the F1 scores and ROC AUC values achieved by different KD methods across various graph datasets.  The methods are categorized by the geometric space they use (Euclidean, Hyperbolic, Spherical, and combinations thereof). The global hyperbolicity (\u03b4) of each dataset is also provided, offering context for performance variations across different geometries.", "section": "5.2 Node Classification"}]