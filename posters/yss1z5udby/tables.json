[{"figure_path": "YSs1z5udBY/tables/tables_1_1.jpg", "caption": "Table 1: Average online loss across epochs 2 to 5 for cyclic fine-tuning and random shuffled fine-tuning.", "description": "This table presents the average online loss across epochs 2 to 5 for two different training methods: cyclic fine-tuning and random shuffled fine-tuning.  The results are shown for four different model sizes (410M, 1B, 1.4B, and 2.8B parameters).  The table demonstrates the performance improvement achieved with cyclic fine-tuning compared to random shuffling, especially as the model size increases.", "section": "1 Introduction"}]