[{"type": "text", "text": "Deep Equilibrium Algorithmic Reasoning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Dobrik Georgiev University of Cambridge dgg30@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "JJ Wilson Independent Researcher josephjwilson74@gmail.com ", "page_idx": 0}, {"type": "text", "text": "Davide Buffelli MediaTek Research davide.buffelli@mtkresearch.com ", "page_idx": 0}, {"type": "text", "text": "Pietro Li\u00f2 University of Cambridge pl219@cam.ac.uk ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Neural Algorithmic Reasoning (NAR) research has demonstrated that graph neural networks (GNNs) could learn to execute classical algorithms. However, most previous approaches have always used a recurrent architecture, where each iteration of the GNN matches an iteration of the algorithm. In this paper we study neurally solving algorithms from a different perspective: since the algorithm\u2019s solution is often an equilibrium, it is possible to find the solution directly by solving an equilibrium equation. Our approach requires no information on the ground-truth number of steps of the algorithm, both during train and test time. Furthermore, the proposed method improves the performance of GNNs on executing algorithms and is a step towards speeding up existing NAR models. Our empirical evidence, leveraging algorithms from the CLRS-30 benchmark, validates that one can train a network to solve algorithmic problems by directly finding the equilibrium. We discuss the practical implementation of such models and propose regularisations to improve the performance of these equilibrium reasoners. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Algorithms, while straightforward in theory, become challenging to deploy in real-world scenarios. They operate in abstract domains with very specific conditions and types of inputs, which are represented with scalars. The main hurdle is the need to \u201ccollapse\u201d reality into a scalar every time an algorithm is used, something usually done based on intuition rather than principled science [25]. Neural Algorithmic Reasoning (NAR; 46) has been proposed to address this issue by utilising specialised neural network architectures to break this scalar bottleneck by executing algorithms in higher-dimensional space made out of arrays of numbers (vectors). The task of mapping reality into this vectorial space is delegated to automated gradient-based optimisation techniques rather than relying on human operators. ", "page_idx": 0}, {"type": "text", "text": "While NAR does not provide the correctness guarantees of its classical counterparts, robust performance can be achieved through alignment [55] \u2013 submodules of the model architecture correspond to easy-to-learn subparts of the algorithm (or class of). Graph Neural Networks (GNNs) have emerged as the most convenient architecture to execute all types of algorithms [29] and GNNs that align better to the target algorithm achieve better generalisation. This alignment game [50] has led to a sequence of exciting research \u2013 from aligning the architecture with iterative algorithms [42] to proving that \u201cgraph neural networks are dynamic programmers\u201d [13], especially if their message-passing function [21] takes into account 3-node interactions. ", "page_idx": 0}, {"type": "text", "text": "The aforementioned papers focus on aligning the computation of the GNN with an algorithm or a specific algorithm class (e.g. dynamic programming), but ignore the properties at the time of algorithm termination. For the algorithms in the CLRS-30 algorithmic reasoning benchmark [45] once the optimal solution is found, further algorithm iterations will not change it. For example, in dynamic programming shortest-paths algorithms making additional iterations would not alter the optimality of the shortest paths\u2019 distances found. Such a state is called an equilibrium \u2013 additional applications of a function (an algorithm\u2019s iteration) to the state leave it unchanged. ", "page_idx": 1}, {"type": "text", "text": "In this paper: ", "page_idx": 1}, {"type": "text", "text": "1. We explore the connection between execution of algorithms and equilibrium finding through the use of Denotational semantics and Domain theory. (section 3)   \n2. Inspired by the above, we implement a class of deep equilibrium algorithmic reasoners (DEARs) that learn algorithms by identifying the equilibrium point of the GNN equation and propose improvements to them. (section 4)   \n3. Our results suggest that the above reasoners can be successfully trained. Not only does equilibrium algorithmic reasoning achieve better overall performance with less expressive (and expensive) GNNs, but is also competitive to the more expressive (and expensive) NAR models. All this is done without providing any information on the number of algorithmic steps \u2013 neither at train nor at test time. (section 5)   \n4. DEARs also drastically improve the inference speed \u2013 an achievement made possible by the use of optimised root-finding algorithms and by decoupling the neural model from the sequential implementation of algorithms in standard benchmark datasets. (section 5) ", "page_idx": 1}, {"type": "text", "text": "Related work The main proposed application of NAR is settings where one wants to apply an algorithm, but it is impossible to represent reality with a single scalar, hence an \u201cexecutor\u201d operating in vector space and faithful to the algorithm is required [47, 50]. As NAR models are neural clones of algorithms, they need to provide correct output even for previously unobserved input sizes. Achieving robust out-of-distribution (OOD) generalisation is tricky. To this end a plethora of works have dedicated their attention to it \u2013 [8, 13, 14, 42] to name a few. Except for one concurrent work (a blog post;[53]), those works focus on improving the GNN step and many completely ignore the termination of algorithms or any properties of the last state, such as equilibrium. This work, similarly to Xhonneux et al. [53], studies neurally finding solutions to algorithms by relying on the equilibrium property. We, however, attempt to give the precise assumptions required for this approach to work. Further, we implement a more robust model than theirs, which achieves comparable or better performance to baselines. Finally, we propose modifications to improve equilibrium NARs. ", "page_idx": 1}, {"type": "text", "text": "2 Background ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Algorithmic Reasoning Let $A\\;:\\;\\mathbb{I}_{A}\\;\\rightarrow\\;\\mathbb{O}_{A}$ be an algorithm, acting on some input $\\textbf{\\em x}\\in\\mathbb{I}_{A}$ , producing an output $A(\\pmb{x})\\in\\mathbb{O}_{A}$ and let $\\mathbb{I}_{A}/\\mathbb{O}_{A}$ be the set of possible inputs/outputs $A$ can read/return. In algorithmic reasoning, we aim to learn a function $A:\\mathbb{I}_{A}\\to\\mathbb{O}_{A}$ , such that $A\\approx A$ . Importantly, we will not be learning simply an input-output mapping, but we will aim to align to the algorithm $A$ \u2019s trajectory. The alignment is often achieved through direct supervision1 on the intermediate states of the algorithm. To capture the execution of $A$ on an input $x$ we can represent it as ", "page_idx": 1}, {"type": "equation", "text": "$$\n{\\bar{h}}_{0}={\\mathrm{PREPROC}}({\\boldsymbol{x}})\\;\\;(1{\\mathrm{a}})\\qquad{\\bar{h}}_{\\boldsymbol{\\tau}}=\\underbrace{A_{t}(\\,\\dots{A_{t}}({\\bar{h}}_{0})\\,\\dots\\,)}_{\\tau{\\mathrm{~times}}}\\;\\;(1{\\mathrm{b}})\\qquad A({\\boldsymbol{x}})={\\mathrm{PosTPROC}}({\\bar{h}}_{\\boldsymbol{\\tau}})\\,\\qquad\n$$", "text_format": "latex", "page_idx": 1}, {"type": "text", "text": "where PREPROC and POSTPROC are some simple pre- and post-processing (e.g.initialising auxiliary variables or returning the correct variable), $\\bar{h}_{\\tau}\\overset{.}{\\in}\\mathbb{H}_{A}^{\\'}$ is $A$ \u2019s internal (hidden) state, $A_{t}$ is a subroutine (or a set of) that is executed at each step and the number of steps depends on a boolean property being satisfied (e.g. all nodes visited). It is therefore no surprise that the encode-process-decode architecture [24] is the de-facto choice when it comes to NAR. Thus, the architecture can be neatly represented as a composition of three learnable components: $\\mathcal{A}=g_{\\mathcal{A}}\\circ P\\circ f_{\\mathcal{A}}$ , where $g_{A}:\\mathbb{I}_{A}\\to\\mathbb{R}^{\\tilde{d}}$ and $f_{A}:\\mathbb{R}^{d}\\to\\mathbb{O}_{A}$ are the encoder and decoder function respectively (usually linear projections) and ${\\mathrm{\\boldmath~\\cal{P}~}}\\{{\\mathbb{R}}^{d}\\rightarrow{\\mathbb{R}}^{d}$ is a processor that mimics the rollout (Equation 1b) of $A$ . The processor often uses a message-passing GNN at its core. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "CLRS-30 The CLRS-30 benchmark [45] includes 30 iconic algorithms from the Introduction to Algorithms textbook [11]. Each data instance for an algorithm $A$ is a graph annotated with features from different algorithm stages (input, output, and hint), each associated with a location (node, edge, and graph). Hints contain time series data representing the algorithm rollout and include a temporal dimension often used to infer the number of steps $\\tau$ . Features in CLRS-30 have various datatypes with associated losses for training. The test split, designed for assessing out-of-distribution (OOD) generalisation, comprises graphs four times larger than the training size. ", "page_idx": 2}, {"type": "text", "text": "Deep Equilibrium Models Deep equilibrium models [DEQs 4] are a class of implicit neural networks [20]. The functions modelled with DEQs are of the form: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\pmb{z}^{*}=f_{\\boldsymbol{\\theta}}(\\pmb{z}^{*},\\pmb{x})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\textbf{\\em x}$ is input, $f_{\\theta}$ is a function parametrised by $\\theta$ (e.g. a neural network) and $z^{*}$ is the output. $z^{*}$ is an equilibrium point to the eventual output value of an infinite depth network where each layer\u2019s weights are shared, i.e. $f_{\\theta}^{[i]}=f_{\\theta}$ . By re-expressing (2) as $g_{\\theta}=f_{\\theta}(z^{*},x)-z^{*}$ DEQs allow us to find the fixed point $z^{*}$ via any black-box root-finding method [e.g. 2, 9], without the actual need to unroll the equation until convergence, allowing us to reduce steps. For backpropagation the gradient $\\partial{\\mathcal{L}}/\\partial\\theta$ could be calculated using the Implicit Function Theorem (cf. 4) and no intermediate state has to be stored, giving us a constant memory cost of gradient computation regardless of the number of iterations until convergence. ", "page_idx": 2}, {"type": "text", "text": "Expander graphs MPNNs operate by exchanging information between adjacent nodes [21]. It has been identified that the message passing process can be hindered by a phenomenon known as oversquashing [1], which occurs when a large volume of messages are compressed into fixed-sized vectors. The importance of overcoming the negative implication posed by this phenomenon is crucial for the overall expressivity of GNNs [22], particularly in the context of long-range node interactions. ", "page_idx": 2}, {"type": "text", "text": "To this end, several spectral methods have been proposed to mitigate oversquashing by increasing the Cheeger constant [3, 6, 30]. A higher Cheeger constant provides a measurement that a graph is globally lacking bottlenecks. The novel approaches include graph rewiring techniques [7, 44], as well as significant independent bodies of research recognising the efficacy of expander graphs [6, 12, 41], due to their desirable properties. ", "page_idx": 2}, {"type": "text", "text": "Expander graphs are proven to be highly connected sparse graphs $\\langle|E|\\,=\\,\\mathcal{O}(|V|)\\rangle$ with a low diameter [35], thus offering advantageous properties for information propagation. Consequently, this facilitates messages to be passed between any pair of nodes in a short number of hops, and as a result, alleviating oversquashing. Formally, a graph $G=(V,E)$ is defined as an expander if it satisfies certain expansion properties. One common definition involves the aforementioned Cheeger constant. In the work of Deac et al. [12], a high Cheeger constant is equivalent to a graph being bottleneck free [12, Definition 3], and that an expander has a high Cheeger constant [12, Theorem 5]. ", "page_idx": 2}, {"type": "text", "text": "There are various methods for constructing expander graphs. We opt for the deterministic algebraic approach as in Deac et al. [12], utilising Cayley graphs. Specifically, we leverage Definition 8 and Theorem 9 of [12] to construct the Cayley graph for the special linear group ${\\mathrm{SL}}(2,\\mathbb{Z}_{n})$ and its generating set $S_{n}-\\mathrm{see}\\,\\mathrm{p}.5$ of Deac et al. [12] for details. Note, that the order of a Cayley graph for $\\mathbb{Z}_{n}$ is $\\vert V\\vert=\\mathcal{O}(n^{3})$ . Hence, for many input graphs, a Cayley graph of the same size may not exist. ", "page_idx": 2}, {"type": "text", "text": "3 Denotational semantics: The denotation of a while loop statement ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "This aim of this section is to draw the parallel between finding equilibriums and executing an algorithm, in order to answer if and when an equilibrium NAR model can be successful. The following paragraphs introduce the mathematical tools for formalising fixed points \u2013 denotational semantics [39] and domain theory [38]. ", "page_idx": 2}, {"type": "text", "text": "Denotational semantics To every programming language expression2 $P$ denotational semantics provides an interpretation $\\mathbb{[}P\\mathbb{]}$ , which is a mathematical object (often a function), representing the behaviour of the expre s sio n to different inputs. These denotations must be: 1) abstract, i.e. independent of language and hardware, hence functions are natural choice; 2) compositional, i.e. $\\mathbb{[}P\\mathbb{]}$ can only be defined in terms of the denotations of $P$ \u2019s subexpressions, but not $P$ itself; 3) m o de l the computation $P$ performs. As an example, we will use the lightweight imperative programming language $\\mathbf{IMP}^{3}$ . It consists of numbers, locations, arithmetic expressions, boolean expressions and commands. Examples of IMP are given in Appendix A \u2013 we will use blue for IMP and encourage the reader to check how we use colour in the appendix. Albeit small, the language is Turing-complete and all algorithms we experiment with can be defined in it. ", "page_idx": 3}, {"type": "text", "text": "Denote the set of variable locations with $\\mathbb{L}-$ those are all variables/array elements we can ever define. A good analogy to think of is the addresses in the language C. The notation we can use to represent a program state is $[X\\mapsto1,B\\mapsto-48,\\cdot\\cdot\\cdot]$ and means that the value of $X$ is 1, the value of $B$ is $-48$ and so on. In other words, program states map locations to integers, s.t. a location can be mapped only once. Hence states are functions and the set of all program states State is the set of functions mapping locations to integers: given $s\\in S t a t e$ , $s(L)\\in\\mathbb{Z}$ is the value at the location $L$ for the state $s$ . The value for location $L$ in a different $s^{\\prime}\\in S t a t e$ , $s^{\\prime}(L)$ , may or may not differ. The denotation of arithmetic / boolean expressions / commands are the functions with domain State. These will be represented in the form of lambda abstractions, i.e. $\\lambda x\\,\\in\\,S.M$ rather than $f(x\\in S)=M$ , where $S$ is a set and $M$ is a function body. The codomain of the denotation depends on the type of expression: $\\mathbb{L}\\mathbf{\\Pi}\\colon S t a t e\\to\\mathbb{Z}$ for arithmetic expressions, $\\mathbb{[}b\\mathbb{]}:S t a t e\\rightarrow\\mathbb{B}$ , for boolean expressions and $\\mathbb{[}c\\mathbb{]}:S t a t e\\rightarrow S t a t e$ for commands. Since command  s t ransform state, they are also called state tran s fo rmers. Commands\u2019 denotations are partial functions, as expressions like while true do skip never terminate and have no denotation. ", "page_idx": 3}, {"type": "text", "text": "For a large portion of the above language, it is trivial and intuitive to define the denotations by structural recursion. For example: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\|\\downarrow\\mathrm{~}b\\mathrm{~then~}c_{0}\\mathrm{~else~}c_{1}\\right\\|=\\lambda s\\in S t a t e.\\mathrm{~}\\left\\{\\left\\|c_{0}\\right\\|(s)}&{\\mathrm{if~}\\|b\\|(s)\\mathrm{~is~true}}\\\\ {\\left\\|c_{1}\\right\\|(s)}&{\\mathrm{otherwise~}}\\\\ {\\left\\|(c_{0};c_{1})\\right\\|=\\lambda s\\in S t a t e.\\left\\|c_{1}\\right\\|(\\left\\|c_{0}\\right\\|(s))}&{\\left\\|s k i p\\right\\|=\\lambda s\\in S t a t e.\\mathrm{~}s}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "The only denotation that cannot be expressed recursively, is that of the while construct. Let $w=\\tt w h i l e\\;b\\;d o\\;c$ . By program equivalence, $w=\\mathrm{i}\\pounds\\ b$ then $(c;w)$ else skip. Therefore ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\left[w\\right]=\\left[\\mathrm{i}\\mathrm{.f.~}b\\mathrm{~then~}(c;w)\\mathrm{~e.se~}\\mathrm{~skip}\\right]=\\lambda s\\in S t a t e.\\ \\left\\{\\!\\!\\left[\\!\\!\\{w\\}\\!\\!\\right]\\left(\\left[\\!\\!\\!\\{c\\}\\!\\!\\right]\\!\\left(s\\right)\\!\\!\\!\\right)\\!\\!\\right.\\ \\mathrm{~if~}\\!\\!\\left[\\!\\!\\{b\\}\\!\\!\\right]\\!\\left(s\\right)\\mathrm{~is~true}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "but this is not a valid definition, since it reuses $[\\![w]\\!]$ (highlighted in red above). Denotational semantics solves this problem, by defining a function $\\bar{f}_{b,c}\\,\\mathrm{:}\\,(S t a t e\\,\\rightarrow\\,S t a t e)\\rightarrow(S t a t e\\,\\rightarrow\\,S t a t e)$ which takes one state transformer and returns another: ", "page_idx": 3}, {"type": "equation", "text": "$$\nf_{b,c}=\\lambda{\\hat{w}}\\in(S t a t e\\rightharpoonup S t a t e).\\lambda s\\in S t a t e.\\left\\{\\!\\!\\begin{array}{l l}{{\\hat{w}}\\left(c(s)\\right)}&{{\\mathrm{if}}\\;b(s)}\\\\ {s}&{{\\mathrm{otherwise}}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "$\\hat{w}$ is now a function variable. The denotation of $[\\![w]\\!]$ is the fixed point of $f_{[b],[c]}$ , i.e. $\\mathbb{[w]}\\,=$ $f_{[[b],[c]}([w])$ . In order to find the denotation, we nee d  to  solve the fixed point. To a id   th e read e r a  full w or k e d  exa mple of computing the denotation for a while loop construct is given in Appendix B. ", "page_idx": 3}, {"type": "text", "text": "Domain theory Scott [38] provides a framework with which we can both find and also characterise solutions for fixed point equations.4 Define $D$ as the domain of state transformers $^{\\prime}S t a t e\\rightarrow S t a t e)$ . A partial orde $^{.5}\\subseteq$ on $D$ is defined as follows: $w\\subseteq w^{\\prime}$ iff $\\forall s\\,\\in\\,S t a t e$ if $w(s)$ is defined then $w({\\bar{s}})\\,=\\,w^{\\prime}(s)$ . In other words $w^{\\prime}$ keeps old mappings and only defines new ones. The totally undefined partial function $\\bot$ is the least element in $D$ . This function contains no location to value mappings. A chain is a sequence of elements of $D$ , s.t. $d_{0}\\subseteq d_{1}\\subseteq d_{2}\\subseteq\\cdot\\cdot.$ . The supremum of the chain, called least upper bound $(l u b)$ , is denoted as $\\sqcup_{n\\geq0}d_{n}$ . There could exist different chains, but, by definition, all chains in a domain must have a lub. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "A function $f:D\\rightarrow D$ is monotonic iff $\\forall d,d^{\\prime}\\in D$ . $(d\\subseteq d^{\\prime}\\Rightarrow f(d)\\subseteq f(d^{\\prime}))$ . In other words, if the second state defined more mappings than the first and we apply one iteration step to both states, the state resulting from the second will still define more mappings. Monotonic functions for which $\\begin{array}{r}{\\bigcup_{n\\geq0}f(d_{n})=\\bar{f}(\\bigcup_{n\\geq0}d_{n})}\\end{array}$ are also called continuous. In plain language, if a function is continuous and we are provided with a chain, the lub of $f$ applied to every chain element is the same as $f$ applied to the lub of the chain. An element $d^{\\prime\\prime}\\in D$ is defined to be pre-fixed point if $f(d^{\\prime\\prime})\\subseteq d^{\\prime\\prime}-\\mathrm{apl}$ lying $f$ does not define anything new. The fixed point $f i x(f)$ of $f$ is the least pre-fixed point of $f$ . By utilising antisymmetry6 of $\\sqsubseteq$ and the two properties of $f i x(f)$ (pre-fixed point and least) we can obtain $\\mathbf{\\bar{\\alpha}}\\!\\!\\!f(f i x(f))=\\mathbf{\\bar{\\alpha}}\\!\\!\\!f i x(f)$ . By Tarski\u2019s theorem [43], any continuous $f:D\\to D$ has a least pre-fixed point. This fixed point can be found, by taking the lub of the chain of applications of f: $\\textstyle f i x(f)=\\bigcup_{n\\geq0}f^{n}(\\bot)$ . The helper function $f_{b,c}$ from Equation 3 is continuous [proof is given on p.120 of 23], therefore a direct result is that if the while $b$ do $c$ terminates then its denotation exists and is the least fixed point of sequence of iterations (compared to picking any fixed point). ", "page_idx": 4}, {"type": "text", "text": "Denotational semantics and NAR The above detour into denotational semantics has affirmed the existence of a connection between equilibrium models and algorithms (as conjectured by Xhonneux et al. [53]). Under the assumptions that: ", "page_idx": 4}, {"type": "text", "text": "\u2022 the algorithms always terminate \u2013 while not computable in the general case, this holds true for experiments, as we are dealing with offline algorithms with provable termination ", "page_idx": 4}, {"type": "text", "text": "\u2022 the algorithms we train on can be modelled as \u201cwhile b do c\u201d constructs within IMP the least fixed point exists and can be found by taking the first \u201cstate\u201d of the algorithm where future iterations on it have no effect. In Appendix C we have further annotated three algorithms from the official code of the CLRS benchmark: BFS, Floyd-Warshall, strongly connected components. Those annotations clearly show that algorithms can be rewritten in IMP regardless of their implementation size. While BFS is clearly a \u201cwhile $b$ do $c^{\\circ}$ -type of algorithm, annotating the other two reveals that either the network may need more input features to decide termination (Floyd-Warshall; Listing 2) or that the algorithm can be composed of several while loops where each $c$ is another while loop on its own (strongly connected components; Listing 3). Fortunately, our approach is not doomed to fail: a single DEQ layer can model any number of \u201cstacked\u201d DEQ layers [32, chapter 4]. ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "4 Deep equilibrium algorithmic reasoning ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Architecture We implement our processors/encoders/decoders following Ibarz et al. [29]. The most notable difference7 to their implementation is that ours uses a sparse graph representation. This requires us to assume a fully connected graph on tasks where no graph structure exists, in order to be able to give pointer predictions, and to reimplement the strongly connected components algorithm so that the output pointers are always in the edge set (this did not change the difficulty of the task). ", "page_idx": 4}, {"type": "text", "text": "The final node embeddings, from which the output is decoded, are the solution to the equation: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbf{H}^{(*)}=P_{\\mathbf{UE}}(\\mathbf{H}^{(*)})\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $P_{\\mathbf{UE}}(\\mathbf{H}^{(*)})=P(\\mathbf{H}^{(*)},\\mathbf{U},\\mathbf{E})$ , $\\mathbf{U}/\\mathbf{E}$ are the encoded node and edge feature matrices and $P$ is the processor function. $\\mathbf{H}^{(t)}$ are the stacked latent states of the nodes at timestep $t$ (with $\\mathbf{H}^{(0)}=\\mathbf{0}$ ). The above Equation 4 matches the signature of Equation 2, and can be solved via root-finding (we employ torchdeq [19]; MIT License), as if it is $f_{\\theta}$ of a DEQ. Any model using this technique will be called deep equilibrium algorithmic reasoner (DEAR) in our experiments. The default processor in the majority of our experiments is a PGN [48] with a gating mechanism as in Ibarz et al. [29], but we note that DEARs can use any kind of processor. ", "page_idx": 4}, {"type": "image", "img_path": "SuLxkxCENa/tmp/597d8ee908723723a4be3c6cd24bac42f85cd1391ce1d202178399af643732f7.jpg", "img_caption": [], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Figure 1: Proposed alignment rule: every state in the DEAR trajectory should \u201cgo forward\u201d. Alignments to a GNN state that has already been \u201cpassed\u201d are disallowed. First and last states must always align. We intentionally use arrows instead of $\\sqsubseteq$ for DEAR, as $\\sqsubseteq$ may not hold for DEAR\u2019s trajectory. ", "page_idx": 5}, {"type": "text", "text": "Finding the fixed point The torchdeq library provides several solvers. The most basic one is fixed-point iteration, equivalent to repeating Equation 4 until convergence. However, in our very first experiments the solver needed more iterations than the algorithm we train on. We therefore opted for the Anderson solver (implements Anderson acceleration [2]) and abandoned fixed-point iteration: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\hat{\\mathbf{H}}^{(t+1)}=P_{\\mathbf{UE}}(\\mathbf{H}^{(t)})\\qquad\\mathbf{H}^{(t+1)}=S o l v e r S t e p\\left(\\left[\\mathbf{H}^{(0)}\\cdot\\dots\\mathbf{H}^{(t)}\\right],\\hat{\\mathbf{H}}^{(t+1)}\\right)\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "The criteria for pre-fixed point check torchdeq implements is distance-based: for a state $\\mathbf{H}^{(t)}$ to be considered a pre-fixed point, the distance to the next state has to be under a pre-defined threshold $\\delta$ . We kept the criteria but modified the library to always return the least pre-fixed point (see Appendix E). This is in contrast to picking the pre-fixed point with the least distance to next state (the default option in torchdeq) and is a decision largely motivated from section 3. Due to a lack of a suitable definition for the domain of NAR trajectories, we define $\\forall t$ . $\\mathbf{H}^{(t)}\\subseteq\\mathbf{H}^{(t+1)}$ , i.e. we pick the first state that passes the pre-fixed point check. ", "page_idx": 5}, {"type": "text", "text": "Globally propagating information For problems defined on graphs it is in theory possible that the number of solver iterations needed to find equilibrium is less than the diameter of the graph. While, in practice, this is unlikely to happen we hypothesise that improving long-range interactions could improve the convergence of DEAR. For this reason, we adopt the implementation of Cayley Graph Propagation (CGP) [51]. Contrasted to Expander Graph Propagation (EGP) [12], which addresses the graph size misalignment (see section 2) by truncating the Cayley graph, CGP keeps the extra nodes as virtual nodes. The CGP model upholds the aforementioned advantageous properties of an expander graph in a more grounded manner by preserving the complete structure. ", "page_idx": 5}, {"type": "text", "text": "In GNNs, the benefits of augmenting a graph with virtual nodes and providing message-passing shortcuts have been observed to improve performance in various tasks [10, 26, 27]; further supported by the theoretical analysis [28]. Additionally, by retaining the complete Cayley graph structure we improve the structure-aware representations by varying the neighbourhood ranges [54]. ", "page_idx": 5}, {"type": "text", "text": "No hint by default We do not make any use of hints (supervising on intermediate algorithm state). First, although it may seem counterintuitive, it has been shown that a NAR model can successfully generalise, and even give better results when trained to only predict the correct output [8, 37]. Second, the fact that the solver uses the GNN exactly once per call does not imply that one step of the solver would correspond to one iteration of the algorithm, bringing uncertainty which DEAR states to match to which algorithm step. While we propose an alignment scheme (see next paragraph), which has the potential to integrate hints, we leave this for future work. ", "page_idx": 5}, {"type": "text", "text": "Alignment Our idea of alignment is visualised in Figure 1. We are given two trajectories of states, one obtained from unrolling GNN iterations as in classical NAR and another obtained from using DEAR. We would like to match DEAR to NAR, such that $\\forall i\\leq j,i^{\\prime}\\leq j^{\\prime}$ if we have committed to aligning DEAR state $\\mathbf{H}^{(i^{\\prime})}$ to NAR state $\\mathbf{H}_{\\mathcal{G}}^{\\left(j\\right)}$ , we cannot align any $\\mathbf{H}^{(j^{\\prime})}$ to $\\mathbf{H}_{\\mathcal{G}}^{(i)}$ and from the same start we would like to reach the same final state. In other words, skipping states is allowed, going back in time is not. This auxiliary supervision would also improve the monotonicity of DEARs, encouraging faster convergence. Enforcing this alignment is done by using an auxiliary loss. Choosing the $L_{2}$ norm as a distance metric, we use a dynamic programming algorithm (Appendix F) ", "page_idx": 5}, {"type": "image", "img_path": "SuLxkxCENa/tmp/616e2a8289ea90478851456e442a19903e3f2c1711428e136e90e67d165b6297.jpg", "img_caption": ["Figure 2: Despite converging to slightly higher train loss our models remain stable during optimisation "], "img_footnote": [], "page_idx": 6}, {"type": "text", "text": "to compute the most optimal alignment (normalised by the number of solver steps, in order not to penalise longer trajectories) and supervise on that value. ", "page_idx": 6}, {"type": "text", "text": "Even with normalisation, the alignment sometimes had the effect of making the optimisation stuck in local minima where the number of steps to hit equilibrium was as low as 2 and the gradients were uninformative. We combated this in two ways: 1) instead of using the default layer normalisation we switched to GRANOLA [15]; 2) since $f(f i x(f))=f$ , we performed a random number of additional iterations [33] and take the last state. The probability of doing $s$ extra steps is $0.5^{s}$ . ", "page_idx": 6}, {"type": "text", "text": "5 Evaluation ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Setup For each algorithm we generated $10^{5}/100/100\\$ -sized training/validation/test datasets. Training sample sizes vary between 8 and 16 elements (uniformly randomly chosen) validation samples are of size 16. As is standard in NAR literature, we measure the test performance out-of-distribution, so our test samples are of size 64. For algorithms on graphs we generate Erdo\u02dds\u2013R\u00e9nyi graphs [17] with edge probabilities $p$ uniformly sampled from the interval [0.1, 0.9], with increments of 0.1, which is the data distribution our baselines [8, 29] have used. We obtained the ground truth execution trajectories and targets using the CLRS-30 implementation [45]. ", "page_idx": 6}, {"type": "text", "text": "In our experiments the models have a latent dimensionality of 128, the batch size is 32, the learning rate is $3\\stackrel{-}{\\times}10^{-4}$ and we use the Adam optimizer [31]. We train our algorithmic reasoners for 100 epochs, choosing the model with the lowest task validation loss (discounting any regularisation; focusing on performance only) for testing. Each task is independently learned, minimising the output loss (losses depend on the algorithm, cf. CLRS-30) plus any regularisation losses. Unless otherwise specified, DEARs employ the Anderson root-finding method from the torchdeq library and include Jacobian regularization [5], the tolerance for fixed point criteria on the forward pass is $\\delta=0.1$ (and $\\frac{\\delta}{10}$ on the backwards) and is based on the relative $L^{2}$ norm between GNN states. Standard deviations are based on 3 seeds. If run on a single 4090 GPU one would need about 3 weeks of total compute. ", "page_idx": 6}, {"type": "text", "text": "The performance metric we measure is the out-of-distribution accuracy, hence the larger test instances. The definition of accuracy varies between algorithms and is based on the specification of the algorithm itself. We refer the reader to Velic\u02c7kovic\u00b4 et al. [45] and CLRS-30 for corresponding accuracy metrics definitions. The main baselines we compare against are the results reported by Xhonneux et al. [53], as no implementation is publicly available, and a NAR architecture with a PGN processor trained in the no-hint regime, as done by Bevilacqua et al. [8]. As, logically, models that are provided the ground-truth number of steps at test time will perform better, we also add as additional baselines a model that always uses 64 steps at test time and a model that has a dedicated network to decide termination [49]. In order to understand how we compare to other, architectural alignments, we also provide a comparison with a more expressive processor (Triplet-MPNN). ", "page_idx": 6}, {"type": "text", "text": "5.1 Results ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We present results for 10 key algorithms (most of the ones used in Bevilacqua et al. [8]) in Table 1. ", "page_idx": 6}, {"type": "text", "text": "DEARs are reasoners The first set of experiments aims to establish whether learning to execute algorithms by finding the least fixed point is possible. As Xhonneux et al. [53] report that their models were prone to optimisation issues, we first compared the training loss for a standard NAR model and a DEAR model with the same neural components. The plots are visualised in Figure 2. In line with the previous work, we observed that the DEAR tends to converge to a slightly higher training loss as no algorithm\u2019s mean training loss dropped below 0.01. However, as evident in Figure 2, we found the optimisation to be overall stable, and the final train loss difference between NAR and DEAR was never greater than 0.1 \u2013 see Appendix G. We are unaware if Xhonneux et al. [53] observed the same numerical differences, but we were overall satisfied with the convergence of DEARs. ", "page_idx": 6}, {"type": "table", "img_path": "SuLxkxCENa/tmp/c1df2fc83167a150511d745208c874995c11aca682a8d066c267f69e3f575511.jpg", "table_caption": ["Table 1: Test accuracy for different algorithms and models. Models with a diamond $\\langle\\rangle$ or $\\spadesuit$ ) iterate for the correct amount of steps during train time (may differ between datapoints). Filled diamond $(\\spadesuit)$ means the ground truth number of steps is also given at test time. LT stands for learnt termination \u2013 the model that uses a termination network. For DEM [53] we leave a \u2212when no results are reported and we report two results for shortest path and MST as it is unclear to us from the main text how they differentiated between the two. We do not run DEAR with CGP for array tasks as they operate on fully-connected graphs. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Equilibrium is a useful inductive bias DEAR outperforms both of the above baselines achieving a $4.5\\%$ overall score increase, suggesting that aligning to the equilibrium property is a useful inductive bias. Moreover, DEAR with a PGN processor is comparable to a NAR with the more expressive Triplet-MPNN, achieving only $2\\%$ lower overall accuracy. This commendable achievement required no information about the ground-truth number of steps neither at train time nor during inference. A more detailed performance analysis follows. ", "page_idx": 7}, {"type": "text", "text": "On weighted graph algorithms our model performed on par with the baseline NAR no-hint model for Bellman-Ford, it outperformed the baseline on Floyd-Warshall, and scored slightly behind on the other two. On unweighted ones, it retained fairly high BFS accuracy compared to DEM and it provided better scores for DFS and Strongly Connected Components (SCC). Unfortunately, even though for this kind of algorithms we used separate edge features for the CGP, in order to distinguish CGP edges from input ones, CGP had a detrimental effect. We hypothesise that algorithms like DFS and SCC need a more advanced architecture or require different task specifications (the algorithm for SCC has a parallel \u201ctwin\u201d; see [16]) in order to generalise OOD. On algorithms on arrays, we got a significant performance improvement in the sorting task and got almost equal scores for min finding. However, the model underperformed by a large margin on the binary search task (in red). This result was very concerning, so we investigated further \u2013 Appendix H showed that DEARs overftited a lot on the classic representation of binary search and that when the task is designed carefully, DEARs can reach overall performance of a Triplet-MPNN NAR architecture. ", "page_idx": 7}, {"type": "text", "text": "Effects of using CGP Despite the slightly lower accuracies, our experiments with CGP have not been futile. In Figure 3, we observe that for almost half of the algorithms CGP applies to, it had a positive effect on the loss convergence \u2013 3/7 algorithms converged to at least half an order of magnitude lower train loss. The rest did not experience any strong negative effects of CGP. Peralgorithm plots can be found in Appendix I. We believe that the reduced accuracies are due to the nearest Cayley graph for the training sizes being unique and a size of 24 nodes. Our deterministic approach of generating a fixed Cayley graph for CGP, whose size is still distinct from test-time size leads to overfitting; what we may observe here. Future avenues of work may want to investigate this by methodically removing the Cayley graph\u2019s edges, but still retaining the desirable expansion properties [6], or by exploring alternative novel graph wiring techniques [7]. However, the limitation of these proposed approaches in comparison to CGP is that they may require dedicated preprocessing to scale (one of the desirable criteria set by the EGP method), therefore providing an interesting line of future work. ", "page_idx": 7}, {"type": "image", "img_path": "SuLxkxCENa/tmp/def47d2b73437f637af25467e93cd5cbc83410ccfda2fa6daed73177f8e7b4fb.jpg", "img_caption": ["Figure 3: Cayely graph propagation can help with convergence "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "SuLxkxCENa/tmp/13c0a0e8fcbfdaab23e61033a24a830753616b5e31bb3983ba2b87e97774cb4c.jpg", "img_caption": ["Figure 4: Alignment (with GRANOLA and stochasticity; DEAR w/ GAS) gives better convergence "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Alignment can distill knowledge into DEARs For evaluating our alignment we focused on the nonCGP version of DEAR and decided to pick algorithms where: 1) The baseline performs reasonably well ${90}\\mathrm{+\\%}$ accuracy), so as to provide good support; 2) the DEAR underperforms substantially. The algorithms to fulfil those requirements are: DAG Shortest paths, MST Prim and Binary Search. ", "page_idx": 8}, {"type": "text", "text": "Results are presented in Table 2. At first glance, the only algorithm that substantially improved was binary search, giving an almost $20\\%$ increase. The final test accuracy, however, does not represent all reality: Figure 4 shows that the task train loss (loss excluding any regularisers) for the model with alignment decreases, compared to no alignment and reaches similar levels as the one observed ", "page_idx": 8}, {"type": "table", "img_path": "SuLxkxCENa/tmp/d002d05ec9a708b2d84fff1cd90c999bf44b999c1f6ee8c0d723354e176801f7.jpg", "table_caption": ["Table 2: Test accuracy with and without alignment. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "for the non-DEQ solution. So, is it overfitting again? We argue it is not. Figure 5 shows that the test $(O O D)$ accuracy per epoch increases when using alignment, reaching similar accuracies to NAR for the DAG shortest path problem and improving over plain DEAR for MST-Prim, suggesting that choosing the right model using validation seed is hard in NAR [34]. Lastly, we would like to note that: 1) although GRANOLA $^{+}$ stochasticity does bring benefits on its own, alignment is necessary to narrow the gap to the NAR training loss (Appendix J); 2) We never reached perfect (0) alignment loss, suggesting better alignment techniques may further boost performance. ", "page_idx": 8}, {"type": "text", "text": "DEARs are highly parallel DEAR is not bound to follow sequential trajectories and GNNs are more aligned to parallel algorithms than to sequential ones [16]. As the cost for one step of DEAR (GNN iteration $^+$ solver) is at least as high as one step of an NAR model (GNN iteration only), we ", "page_idx": 8}, {"type": "image", "img_path": "SuLxkxCENa/tmp/a9ce8a8173be28cf3a4eb1f9025e1998c6dd91d7ebc6a6421b47b511b63ad4c4.jpg", "img_caption": ["Figure 5: Alignment (DEAR w/ GAS) leads to improvements OOD "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "Table 3: Mean inference time in seconds per sample. Measured on an RTX 4090 GPU. Up/down arrows denote improvements/deteriorations. $\\approx$ is used when difference is negligible. A double symbol is used for substantial $(5\\!\\times\\!)$ differences. ", "page_idx": 9}, {"type": "table", "img_path": "SuLxkxCENa/tmp/4730207be48eaacaa126d705d5241515ef6324c62fbdafe76a9192fa2ef1cb39.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "SuLxkxCENa/tmp/ad4a39db86f20031d0cd89f96f952649b22a15f37ece0b4d39259c85e225996a.jpg", "table_caption": ["Table 4: DEAR is architecture invariant and can also run with a Triplet-MPNN processor. "], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "used the inference speed of a DEAR as a measure of how parallel the final learnt algorithm is. Results are presented in Table 3. An immediate observation is that DEAR improves inference times across almost all algorithms. The only ones that were executed slower are: 1) Bellman-Ford and BFS, which are highly parallelised in the CLRS-30 implementation, so an improvement on them was unlikely; 2) Floyd-Warshall where the difference, although present, is marginal and we account it to the added overhead from the solver; 3) Binary search, where performance was almost identical. These results suggest that although not always guaranteed (the case for searching), it is very likely that a DEAR will learn a parallel algorithm. The most substantial improvements, in line with our past observations in Engelmayer et al. [16], were on the tasks of sorting and strongly-connected components. ", "page_idx": 9}, {"type": "text", "text": "DEARs are foundational Up until this point, DEAR was run with a PGN processor, which is a lightweight, yet well-performant NAR processor architecture. The last set of experiments aims to show that equilibrium reasoning is not tied to only one type of processor/architecture. It is rather a class of models/foundational model as it can natively support different types of processors. To verify this claim, we present results with DEAR using the Triplet-MPNN architecture in Table 4. As Triplet-MPNN is computationally expensive, we tested algorithms for which NAR with TripletMPNN improves over NAR with PGN. Results indeed confirm that we are not limited to a single type of processor with DEAR, and, as expected, the best overall performance is achieved when using DEAR with the more expressive, Triplet-MPNN, processor. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our investigations with equilibrium models have shown that it is possible and even beneficial to merge NAR and DEQs. While our models attained very competitive performance, there are certain limitations that need to be addressed: 1) Better algorithms for alignment can help close the gap even further for Prim\u2019s algorithm and binary search; 2) Better model selection is needed in order to know which DEARs would perform well OOD; 3) Graph rewiring techniques may be needed to prevent overftiting with CGP; 4) Algorithmic-aligned criteria for fixed-point may boost OOD generalisation for sequential algorithms. The last point is motivated by the fact that for each step, these algorithms update only a few nodes in the graph, keeping the rest untouched. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Dobrik Georgiev would like to acknowledge the financial support from G-Research towards covering his travel costs. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Alon, U. and Yahav, E. (2020). On the bottleneck of graph neural networks and its practical implications. arXiv preprint arXiv:2006.05205.   \n[2] Anderson, D. G. (1965). Iterative procedures for nonlinear integral equations. Journal of the ACM ( JACM).   \n[3] Arnaiz-Rodr\u00edguez, A., Begga, A., Escolano, F., and Oliver, N. (2022). Diffwire: Inductive graph rewiring via the Lov\u00e0sz bound. arXiv preprint arXiv:2206.07369.   \n[4] Bai, S., Kolter, J. Z., and Koltun, V. (2019). Deep equilibrium models. Neural Information Processing Systems.   \n[5] Bai, S., Koltun, V., and Kolter, J. Z. (2021). Stabilizing equilibrium models by jacobian regularization. International Conference on Machine Learning.   \n[6] Banerjee, P. K., Karhadkar, K., Wang, Y. G., Alon, U., and Mont\u00fafar, G. (2022). Oversquashing in gnns through the lens of information contraction and graph expansion. In 2022 58th Annual Allerton Conference on Communication, Control, and Computing (Allerton), pages 1\u20138. IEEE.   \n[7] Barbero, F., Velingker, A., Saberi, A., Bronstein, M. M., and Giovanni, F. D. (2024). Localityaware graph rewiring in GNNs. In The Twelfth International Conference on Learning Representations.   \n[8] Bevilacqua, B., Nikiforou, K., Ibarz, B., Bica, I., Paganini, M., Blundell, C., Mitrovic, J., and Velickovic, P. (2023). Neural algorithmic reasoning with causal regularisation. International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA, 202:2272\u20132288.   \n[9] Broyden, C. G. (1965). A class of methods for solving nonlinear simultaneous equations. Mathematics of Computation, 19:577\u2013593.   \n[10] Cai, C., Hy, T. S., Yu, R., and Wang, Y. (2023). On the connection between mpnn and graph transformer. In International Conference on Machine Learning, pages 3408\u20133430. PMLR.   \n[11] Cormen, T. H., Leiserson, C. E., Rivest, R. L., and Stein, C. (2009). Introduction to Algorithms, 3rd Edition. MIT Press.   \n[12] Deac, A., Lackenby, M., and Velic\u02c7kovic\u00b4, P. (2022). Expander graph propagation. In Learning on Graphs Conference, pages 38\u20131. PMLR.   \n[13] Dudzik, A. J. and Veli\u02c7ckovi\u00b4c, P. (2022). Graph neural networks are dynamic programmers. Advances in Neural Information Processing Systems, 35:20635\u201320647.   \n[14] Dudzik, A. J., von Glehn, T., Pascanu, R., and Velic\u02c7kovic\u00b4, P. (2024). Asynchronous algorithmic alignment with cocycles. In Villar, S. and Chamberlain, B., editors, Proceedings of the Second Learning on Graphs Conference, volume 231 of Proceedings of Machine Learning Research, pages 3:1\u20133:17. PMLR.   \n[15] Eliasof, M., Bevilacqua, B., Sch\u00f6nlieb, C.-B., and Maron, H. (2024). Granola: Adaptive normalization for graph neural networks. arXiv preprint arXiv: 2404.13344.   \n[16] Engelmayer, V., Georgiev, D. G., and Veli\u02c7ckovi\u00b4c, P. (2023). Parallel algorithms align with neural execution. In The Second Learning on Graphs Conference.   \n[17] Erdo\u02dds, P., R\u00e9nyi, A., et al. (1960). On the evolution of random graphs. Publ. Math. Inst. Hung. Acad. Sci, 5(1):17\u201360.   \n[18] Fiore, M. (2023/24). Denotational Semantics. Lecture notes for Part II of the Computer Science Tripos. University of Cambridge.   \n[19] Geng, Z. and Kolter, J. Z. (2023). Torchdeq: A library for deep equilibrium models. https: //github.com/locuslab/torchdeq.   \n[20] Ghaoui, L., Gu, F., Travacca, B., Askari, A., and Tsai, A. Y. (2019). Implicit deep learning. SIAM Journal on Mathematics of Data Science.   \n[21] Gilmer, J., Schoenholz, S. S., Riley, P. F., Vinyals, O., and Dahl, G. E. (2017). Neural message passing for quantum chemistry. In International conference on machine learning, pages 1263\u20131272. PMLR.   \n[22] Giovanni, F. D., Rusch, T. K., Bronstein, M. M., Deac, A., Lackenby, M., Mishra, S., and Velic\u02c7kovic\u00b4, P. (2023). How does over-squashing affect the power of gnns? arXiv preprint arXiv: 2306.03589.   \n[23] Gunter, C. A. (1992). Semantics of programming languages: structures and techniques. MIT press.   \n[24] Hamrick, J. B., Allen, K. R., Bapst, V., Zhu, T., McKee, K. R., Tenenbaum, J. B., and Battaglia, P. W. (2018). Relational inductive bias for physical construction in humans and machines. arXiv preprint arXiv:1806.01203.   \n[25] Harris, T. and Ross, F. (1955). Fundamentals of a method for evaluating rail net capacities. Technical report.   \n[26] Hu, W., Fey, M., Ren, H., Nakata, M., Dong, Y., and Leskovec, J. (2021). Ogb-lsc: A large-scale challenge for machine learning on graphs. arXiv preprint arXiv:2103.09430.   \n[27] Hu, W., Fey, M., Zitnik, M., Dong, Y., Ren, H., Liu, B., Catasta, M., and Leskovec, J. (2020). Open graph benchmark: Datasets for machine learning on graphs. Advances in neural information processing systems, 33:22118\u201322133.   \n[28] Hwang, E., Thost, V., Dasgupta, S. S., and Ma, T. (2022). An analysis of virtual nodes in graph neural networks for link prediction. In The First Learning on Graphs Conference.   \n[29] Ibarz, B., Kurin, V., Papamakarios, G., Nikiforou, K., Bennani, M., Csord\u00e1s, R., Dudzik, A. J., Bosnjak, M., Vitvitskyi, A., Rubanova, Y., Deac, A., Bevilacqua, B., Ganin, Y., Blundell, C., and Velickovic, P. (2022). A generalist neural algorithmic learner. In Rieck, B. and Pascanu, R., editors, Learning on Graphs Conference, LoG 2022, 9-12 December 2022, Virtual Event, volume 198 of Proceedings of Machine Learning Research, page 2. PMLR.   \n[30] Karhadkar, K., Banerjee, P. K., and Mont\u00fafar, G. (2022). Fosr: First-order spectral rewiring for addressing oversquashing in gnns. arXiv preprint arXiv:2210.11790.   \n[31] Kingma, D. P. and Ba, J. (2015). Adam: A method for stochastic optimization. In Bengio, Y. and LeCun, Y., editors, 3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.   \n[32] Kolter, Z., Duvenaud, D., and Johnson, M. (2023). Deep equilibrium models (deq) tutorial. https://implicit-layers-tutorial.org/deep_equilibrium_models/. Accessed: 2024-08-27.   \n[33] Liu, J., Hooi, B., Kawaguchi, K., Wang, Y., Dong, C., and Xiao, X. (2024). Scalable and effective implicit graph neural networks on large graphs. In The Twelfth International Conference on Learning Representations.   \n[34] Mahdavi, S., Swersky, K., Kipf, T., Hashemi, M., Thrampoulidis, C., and Liao, R. (2023). Towards better out-of-distribution generalization of neural algorithmic reasoning tasks. Transactions on Machine Learning Research.   \n[35] Mohar, B. (1991). Eigenvalues, diameter, and mean distance in graphs. Graphs and combinatorics, 7(1):53\u201364.   \n[36] Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al. (2019). Pytorch: An imperative style, high-performance deep learning library. arXiv preprint arXiv:1912.01703.   \n[37] Rodionov, G. and Prokhorenkova, L. (2023). Neural algorithmic reasoning without intermediate supervision. arXiv preprint arXiv:2306.13411.   \n[38] Scott, D. S. (1982). Domains for denotational semantics. In Automata, Languages and Programming: Ninth Colloquium Aarhus, Denmark, July 12\u201316, 1982 9, pages 577\u2013610. Springer.   \n[39] Scott, D. S. and Strachey, C. (1971). Toward a mathematical semantics for computer languages, volume 1. Oxford University Computing Laboratory, Programming Research Group Oxford.   \n[40] Sharir, M. (1981). A strong-connectivity algorithm and its applications in data flow analysis. Computers & Mathematics with Applications, 7(1):67\u201372.   \n[41] Shirzad, H., Velingker, A., Venkatachalam, B., Sutherland, D. J., and Sinop, A. K. (2023). Exphormer: Sparse transformers for graphs. In International Conference on Machine Learning, pages 31613\u201331632. PMLR.   \n[42] Tang, H., Huang, Z., Gu, J., Lu, B.-L., and Su, H. (2020). Towards scale-invariant graph-related problem solving by iterative homogeneous gnns. Advances in Neural Information Processing Systems, 33.   \n[43] Tarski, A. (1955). A lattice-theoretical fixpoint theorem and its applications.   \n[44] Topping, J., Di Giovanni, F., Chamberlain, B. P., Dong, X., and Bronstein, M. M. (2021). Understanding over-squashing and bottlenecks on graphs via curvature. arXiv preprint arXiv:2111.14522.   \n[45] Velic\u02c7kovic\u00b4, P., Badia, A. P., Budden, D., Pascanu, R., Banino, A., Dashevskiy, M., Hadsell, R., and Blundell, C. (2022). The clrs algorithmic reasoning benchmark. In International Conference on Machine Learning, pages 22084\u201322102. PMLR.   \n[46] Velickovic, P. and Blundell, C. (2021a). Neural algorithmic reasoning. Patterns, 2(7):100273.   \n[47] Velickovic, P. and Blundell, C. (2021b). Neural algorithmic reasoning. Patterns, 2(7):100273.   \n[48] Veli\u02c7ckovi\u00b4c, P., Buesing, L., Overlan, M., Pascanu, R., Vinyals, O., and Blundell, C. (2020). Pointer graph networks. Advances in Neural Information Processing Systems, 33:2232\u20132244.   \n[49] Velic\u02c7kovic\u00b4, P., Ying, R., Padovano, M., Hadsell, R., and Blundell, C. (2020). Neural execution of graph algorithms. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.   \n[50] Velic\u02c7kovic\u00b4, P. (2023). Neural algorithmic reasoning. The Gradient.   \n[51] Wilson, J., Bechler-Speicher, M., and Velic\u02c7kovic\u00b4, P. (2024). Cayley graph propagation. arXiv preprint arXiv:2410.03424.   \n[52] Winskel, G. (1993). The formal semantics of programming languages: an introduction. MIT press.   \n[53] Xhonneux, S., He, Y., Deac, A., Tang, J., and Gidel, G. (2024). Deep equilibrium models for algorithmic reasoning. In ICLR Blogposts 2024. https://iclr-blogposts.github.io/2024/blog/deqalgreasoning/.   \n[54] Xu, K., Li, C., Tian, Y., Sonobe, T., Kawarabayashi, K.-i., and Jegelka, S. (2018). Representation learning on graphs with jumping knowledge networks. In International conference on machine learning, pages 5453\u20135462. PMLR.   \n[55] Xu, K., Li, J., Zhang, M., Du, S. S., ichi Kawarabayashi, K., and Jegelka, S. (2020). What can neural networks reason about? In International Conference on Learning Representations. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A IMP: Definitions and examples ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Anything highlighted in blue below, is part of the IMP language. Subexpressions, to avoid confusion, are not coloured. ", "page_idx": 13}, {"type": "text", "text": "IMP consists of: ", "page_idx": 13}, {"type": "text", "text": "\u2022 numbers \u2013 1, -20, 13930   \n\u2022 locations \u2013 AVariableName, AnotherVar, ArrayName[11]   \n\u2022 arithmetic expressions \u2013 $(5+4)*3$ , but also $\\mathtt{A}{*}55$ . Note how variables can be parts of arithmetic expressions.   \n\u2022 boolean expressions \u2013 true, false, but also $\\mathtt{X}{=}{=}0$ , $3{\\ast}\\mathbb{A}{<}\\mathbb{B}$ and ${\\mathtt{X}}{=}{=}0\\ \\wedge\\ 3{*}{\\mathtt{A}}{<}{\\mathtt{B}}$ . Note how boolean expressions can be made by using variables or using boolean logic on subexpressions.   \n\u2022 commands \u2013 Commands can be one of: \u2013 skip, which is a no-op \u2013 $X:=\\mathtt{a}$ , where $\\Chi$ is assigned the value of arithmetic expression $a$ . An example $a$ is $3*\\mathtt{B}+0$ \u2013 if $b$ then $c_{\\mathrm{0}}$ else $c_{1}$ where $b$ is a boolean expression and $c_{0},\\,c_{1}$ are commands. For example if $_{\\mathrm{~A~}}<\\mathrm{~B~}$ then $\\mathbf{C}:=0$ else ${\\mathsf{C}}:=\\mathtt{A}-\\mathtt{B}$ which sets C to the difference of A and B, if it is positive \u2013 $(c_{0}\\,;c_{1})$ \u2013 while $b$ do $c$ which is a while loop repeating command $c$ as long as boolean expression $b$ . A (classic) example is $\\mathrm{~\\bar{~}Y!=1~}$ ; while $\\texttt{X}>\\;0$ do $\\mathrm{Y}:=\\mathtt{X}*\\mathtt{Y}$ ; ${\\tt X}:=\\tt X_{-1})$ ), which finds the factorial of $\\mathtt{X}$ and saves it in Y. ", "page_idx": 13}, {"type": "text", "text": "B Fixed point of a while loop \u2013 example ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Below, we will denote the state as $[A\\mapsto a,B\\mapsto b,\\dots]$ . It means that the value of variable $A$ is $a$ and so on. ", "page_idx": 13}, {"type": "text", "text": "Consider the facorial example from above removing the explicit set of $\\mathtt{Y}$ to 1. To find the denotation $\\mathbb{[}w\\mathbb{]}=\\mathbb{I}$ while $\\texttt{X}>\\;0$ do ( $\\mathrm{Y}:=\\mathtt{X}*\\mathrm{Y}$ ; $X\\!:=\\!\\!X\\!-\\!1)]$ , we first define our $f_{b,c}$ ", "page_idx": 13}, {"type": "equation", "text": "$$\nf_{b,c}(w)([X\\mapsto x,Y\\mapsto y])=\\left\\{{\\begin{array}{l l}{w\\left([X\\mapsto x-1,Y\\mapsto y*x]\\right)}&{{\\mathrm{if~}}X>0}\\\\ {[X\\mapsto x,Y\\mapsto y]}&{{\\mathrm{otherwise}}}\\end{array}}\\right.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "The equivalent definition if we were to keep the lambdas from the original text is ", "page_idx": 13}, {"type": "equation", "text": "$$\nf_{b,c}=\\lambda w\\in(S t a t e\\rightharpoonup S t a t e).\\lambda s\\in S t a t e.\\left\\{w\\left([X\\mapsto x-1,Y\\mapsto y*x]\\right)\\right.\\mathrm{~if~}X>0}\\\\ {\\left.[X\\mapsto x,Y\\mapsto y]\\right.\\qquad\\qquad\\qquad\\mathrm{otherwise}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "but we will work with the first definition as it is more compact. ", "page_idx": 13}, {"type": "text", "text": "The approximations of $f_{b,c}^{n}$ starting from $f_{b,c}^{0}=\\perp$ are: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\hat{H}_{2}=-k_{\\mathrm{A}}(\\hat{H}_{3})(|X+x,Y+\\hat{y}|)}&{=\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+x|)}{2}}}\\\\ &{=\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+x|)}{2}}}\\\\ &{=\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+x|)}{2}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+y|)}{2}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+x|)}{2}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+y|)}{2}}\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+x|)}{2}}}\\\\ &{=\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+y|)}{2}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+y|)}{2}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+y|)}{2}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+y|)}{2}}\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+y|)}{2}}}\\\\ &{=\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+x|)}{2}}}\\\\ {\\hat{H}_{2}=k_{\\mathrm{A}}(\\hat{H}_{3})(|X+x,Y+y|)}&{=\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+y|)}{2}}}\\\\ &{=\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+x|)}{2}}}\\\\ &{=\\left\\lbrace\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+y|)}{2}}+\\frac{\\phantom{\\frac{(\\hat{H}_{2})^{2}(|X+y|)}{2}}}{\\frac{1}{\\alpha}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+y|)}{2}}\\phantom{\\frac{(\\hat{H}_{3})^{2}(|X+y|)}{2}}\\right\\rbrace}\\end{array}\\frac{\\mathrm{d}}{\\alpha}-1}\\\\ &{=\\left\\lbrace\\begin{array}{l l l}{\\frac{(\\hat{H}_{3})^{2}(|X+x \n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "which for $n$ is: ", "page_idx": 14}, {"type": "equation", "text": "$$\nf_{b,c}^{n}={\\left\\{\\!\\!\\!\\begin{array}{l l}{{\\mathrm{undefined}}}&{{\\mathrm{if~}}x\\geq n}\\\\ {[X\\mapsto0,Y\\mapsto y*(x!)]}&{{\\mathrm{if~}}0<x<n}\\\\ {[X\\mapsto x,Y\\mapsto y]}&{{\\mathrm{if~}}x\\leq0}\\end{array}\\!\\!\\right.}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The sequence obeys $f_{b,c}^{0}\\,\\subseteq\\,f_{b,c}^{1}\\,\\subseteq\\,f_{b,c}^{2}\\,\\subseteq\\,\\cdots\\,\\subseteq\\,f_{b,c}^{n}\\,\\subseteq\\,\\cdot\\,.\\,.$ (we can see that whenever $f_{b,c}^{n-1}$ is defined it agrees with $f_{b,c}^{n})$ and $f_{b,c}$ is monotonic $(f_{b,c}^{k}\\subseteq f_{b,c}^{l}\\implies f_{b,c}(f_{b,c}^{k})\\subseteq f_{b,c}(f_{b,c}^{l}))$ . ", "page_idx": 14}, {"type": "text", "text": "For a given X = x, f bx,c+1 $f_{b,c}^{x+1}\\,=\\,f_{b,c}^{x+2}\\,=\\,.\\,.\\,.$ . The fixed point is the lub of the whole sequence is therefore: ", "page_idx": 14}, {"type": "equation", "text": "$$\nf_{b,c}^{\\infty}=\\bigcup_{n\\geq0}f_{b,c}^{n}(\\perp)={\\biggl\\{}[X\\mapsto0,Y\\mapsto y*(x!)]{\\begin{array}{l}{{\\mathrm{if}}\\ x>0}\\\\ {\\ n\\geq0}\\end{array}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "By a similar analysis, it is not hard show that the denotation of while true do skip will be undefined.8 ", "page_idx": 14}, {"type": "text", "text": "C Can algorithms, as implemented in CLRS-30, have an equilibrium? ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In this appendix, we have copied over some algorithms implementations from CLRS- $\\cdot30^{9}$ . Additionally, we have annotated how and when they follow the while $b$ do $c$ construct. Algorithms, that are not necessarily solved via this construct (e.g. strongly connected components) were also included, so as to showcase if this would break. ", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "def bfs(A: _Array , s: int) -> _Out: chex. assert_rank(A, 2) probes $=$ probing.initialize(specs.SPECS[\u2019bfs \u2019]) A_pos $=$ np.arange(A.shape [0]) probing.push( probes , specs.Stage.INPUT , next_probe ={ \u2019pos \u2019: np.copy(A_pos) \\* 1.0 / A.shape [0], \u2019s\u2019: probing.mask_one(s, A.shape [0]) , \u2019A\u2019: np.copy(A), \u2019adj \u2019: probing.graph(np.copy(A)) }) reach $=$ np.zeros(A.shape [0]) $\\ p\\dot{1}=\\mathtt{\\ p n p}$ .arange(A.shape [0]) reach[s] = 1 # Initialisation code ends here # implemented as do -while , but do -whiles are essentially # c; while b do c while True: prev_reach $=$ np.copy(reach) probing.push( probes , specs.Stage.HINT , next_probe ={ \u2019reach_h \u2019: np.copy(prev_reach ), \u2019pi_h \u2019: np.copy(pi) }) # command c: update reachability . for i in range(A.shape [0]): for j in range(A.shape [0]): if A[i, j] > 0 and prev_reach[i] $\\circleddash\\ \\ 1$ : if pi[j] $==$ j and j $!=$ s: pi[j] $=$ i reach[j] $\\mathit{\\Theta}=\\mathit{\\Theta}\\-1$ if np.all(reach $==$ prev_reach): # boolean condition b: has reachability vector changed break probing.push(probes , specs.Stage.OUTPUT , next_probe $=$ {\u2019pi\u2019: np.copy(pi)}) ", "page_idx": 15}, {"type": "text", "text": "probing.finalize(probes) return pi , probes ", "page_idx": 15}, {"type": "text", "text": "Listing 1: BFS algorithm. Clearly implemented as while $b$ do c. ", "page_idx": 15}, {"type": "text", "text": "# The sampler   \nclass FloydWarshallSampler (Sampler): \"\"\" Sampler for all -pairs shortest paths.\"\"\" def _sample_data ( self , length: int , p: Tuple[float , $\\ \\ \\cdot\\ \\cdot\\ ]\\ \\ \\ =\\ \\ \\ (\\ 0\\cdot5\\ ,)$ , low: float $=$ 0. # never changed in the data generation high: float $=$ 1., # never changed in the data generation graph $=$ self. _random_er_graph ( # samples random ER graph with weights in [low;high) nb_nodes $=.$ length , p=self._rng.choice(p), directe $\\lambda\\!=\\!1$ alse , acycli $\\mathtt{c}=$ False , weighted $\\cdot^{=}$ True , $\\tt{1}o w\\tt{=}2o w$ , high=high) return [graph]   \n# The implementation   \ndef floyd_warshall (A: _Array) -> _Out: \"\"\" Floyd -Warshall \u2019s all -pairs shortest paths (Floyd , 1962).\"\"\" chex. assert_rank(A, 2) probes $=$ probing.initialize(specs.SPECS[\u2019floyd_warshall \u2019]) A_pos $=$ np.arange(A.shape [0])   \nprobing.push( probes , specs.Stage.INPUT , next_probe $=\\{$ \u2019pos \u2019: np.copy(A_pos) / A.shape [0], \u2019A\u2019: np.copy(A), \u2019adj \u2019: probing.graph(np.copy(A)) })   \nD = np.copy(A)   \n$\\mathrm{~\\mathsf~{~P~i~}~}=$ np.zeros ((A.shape [0], A.shape [0]))   \nmsk $=$ probing.graph(np.copy(A))   \nfor i in range(A.shape [0]): for j in range(A.shape [0]): Pi[i, $\\mathrm{~j~}\\textbf{\\em J}=\\textbf{\\em i}$   \n# Initialisation code ends here   \n# for loops are while loops   \n# \u2018\u2018for k in range(N)\u2019\u2019 is equivalent to $\\,:\\,\\overline{{\\,}}\\,\\mathbf{k}:=0$ ; while ( $\\dot{\\tt1}\\!<\\!\\mathrm{N}$ ) do (c; k: $=\\!\\log+1$ ) \u2019\u2019   \n# NOTE #1 The NN , however , has to learn to increase the k, solely   \n# based on the \u2018pos \u2018 input feature; having a \u2018pred \u2019 feature ,   \n# (as in string algorithms) might have been more appropriate   \n# NOTE #2 \\*Since the sampler (above) only samples positive edge weights $^*$   \n# no negative -weight cycles can exist. Hence any reruns of the inner two   \n# for loops , after k iteraitons have passed will not change matrix D.   \n# boolean condition b: k iterations have passed   \n# (a necessary , \\*but not sufficient\\* condition is that D remains unchanged)   \nfor k in range(A.shape [0]): prev_ $.\\textsc{d}=$ np.copy(D) prev_msk $=$ np.copy(msk) probing.push( probes , specs.Stage.HINT , next_probe ={ \u2019Pi_h \u2019: np.copy(Pi), \u2019D\u2019: np.copy(prev_D), \u2019msk\u2019: np.copy(prev_msk), \u2019k\u2019: probing.mask_one(k, A.shape [0]) }) # command c: update D for intermediate vertex k for i in range(A.shape [0]): for j in range(A.shape [0]): if prev_msk[i, k] > 0 and prev_msk[k, j] > 0: if msk[i, $j\\,]\\quad=\\quad0$ or prev_D[i, k] $^+$ prev_D[k, j] < D[i, j]: D[i, j] $=$ prev_D[i, k] $^+$ prev_D[k, j] Pi[i, $\\begin{array}{r l r}{\\dot{\\bf j}\\,\\mathtt{I}}&{{}=}&{{\\bf p}_{\\bot}\\,\\mathtt{L}{\\bf k}}\\end{array}$ , j] else: D[i, j] $=$ prev_D[i, j] msk[i, j] = 1   \nprobing.push(probes , specs.Stage.OUTPUT , next_probe $=$ {\u2019Pi\u2019: np.copy(Pi)})   \nprobing.finalize(probes) ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "return Pi , probes ", "page_idx": 16}, {"type": "text", "text": "Listing 2: Floyd-Warshall algorithm and its sampler (above). Can also be viewed as while b do c, in CLRS-30. ", "page_idx": 16}, {"type": "text", "text": "ef strongly_connected_components (A: _Array) -> _Out:   \n\"\"\" Kosaraju \u2019s strongly -connected components (Aho et al., 1974).\"\"\" chex. assert_rank(A, 2)   \nprobes $=$ probing.initialize( specs.SPECS[\u2019strongly_connected_components \u2019])   \nA_pos $=$ np.arange(A.shape [0])   \nprobing.push( probes , specs.Stage.INPUT , next_probe ={ # < omitted for brevity > })   \nscc_id $=$ np.arange(A.shape [0])   \ncolor $=$ np.zeros(A.shape [0], dtype $=$ np.int32)   \n$\\texttt{d}=$ np.zeros(A.shape [0])   \n$\\texttt{f}=$ np.zeros(A.shape [0])   \ns_prev $=$ np.arange(A.shape [0])   \ntime $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$   \n${\\tt A\\_t}={\\tt\\Delta\\ n p}$ .transpose(A)   \n# Initialisation code ends here   \n# boolean condition b: there are unvisited (color[s] $=0$ ) vertices   \nfor s in range(A.shape [0]): if color[s] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$ : s_last $=$ s $\\mathrm{~\\boldmath~u~}=$ s $\\v{v}=$ s probing.push( probes , specs.Stage.HINT , next_probe $=5$ # < omitted for brevity > }) # command c: grey them (color $^{\\dag}=1$ ) and recursively visit descendants # NOTE command c is another while b\u2019 do c\u2019 with a stack while True: # b \u2019: stack is not empty if color[u] $==$ 0 or d[u] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0\\quad.\\qquad\\qquad$ : time $+=\\ \\ 0\\ ,\\ 0\\,1$ d[u] $=$ time color[u] $\\mathit{\\Theta}=\\mathit{\\Theta}\\-1$ probing.push( probes , specs.Stage.HINT , next_probe $=\\{$ { # < omitted for brevity $>$ }) for v in range(A.shape [0]): # c \u2019: add lowest id unvisited descendant of top -stack node to the top of the stack if A[u, v] $!=~0$ : if color[v] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$ : color[v] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad1$ s_prev[v] $=$ s_last s_last $=\\_v$ probing.push( probes , specs.Stage.HINT , next_probe $=5$ # < omitted for brevity > }) break if s_last $\\mathbf{\\tau}=\\mathbf{\\tau}\\cdot\\mathbf{u}$ : # no descending color[u] $\\r=\\ r_{2}$ time $+=\\ \\ 0\\ ,\\ 0\\,1$ f[u] $=$ time probing.push( probes , specs.Stage.HINT , next_probe $=\\{$ { # < omitted for brevity > }) if s_prev[u] $\\mathbf{\\tau}=\\mathbf{\\tau}\\cdot\\mathbf{u}$ : # and we are on top of the recursion # although imaginary , in the implementation here , # if a stack was used , it\u2019d be empty in this if # statement assert s_prev[s_last] $==$ s_last break pr = s_prev[s_last] s_prev[s_last] $=$ s_last s_last $=$ pr u = s_last   \ncolor $=$ np.zeros(A.shape [0], dtype $=$ np.int32)   \ns_prev $=$ np.arange(A.shape [0]) ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "# boolean condition b \u2019\u2019: there are unvisited (color[s] $=0$ ) vertices # (order of visiting depends on finishing time; ", "page_idx": 17}, {"type": "text", "text": "96 # see Introduction to algorithms , 4th edition , Chapter 20)   \n97 for s in np.argsort(-f):   \n98 if color[s] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$ :   \n99 s_last $=$ s   \n00 $\\mathrm{~\\boldsymbol~{~u~}~}=\\mathrm{~\\boldsymbol~{~s~}~}$   \n01 $\\ensuremath{\\texttt{v}}=\\ensuremath{\\texttt{s}}$   \n02 probing.push(   \n03 probes ,   \n04 specs.Stage.HINT ,   \n05 next_probe $=5$   \n06 # $<$ omitted for brevity >   \n07 })   \n08 # NOTE command c is another while b\u2019\u2019\u2019 do c\u2019\u2019\u2019 with a stack   \n09 while True: # b \u2019\u2019\u2019: stack is not empty   \n0 scc_id[u] $=$ s   \n1 if color[u] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$ or d[u] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0\\quad.\\qquad\\qquad$ :   \n2 time $+=\\ \\ 0\\ ,\\ 0\\,1$   \n3 d[u] $=$ time   \n4 color[u] $\\mathit{\\Theta}=\\mathit{\\Theta}\\-1$   \n15 probing.push(   \n6 probes ,   \n17 specs.Stage.HINT ,   \n8 next_probe $=\\{$ {   \n19 # < omitted for brevity >   \n20 })   \n21 for v in range(A.shape [0]): # c \u2019\u2019\u2019: add lowest id unvisited descendant of top -   \nstack node to the top of the stack   \n22 if A_t[u, v] $\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!0=\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!0\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!=\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!0\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!.\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!$ :   \n23 if color[v] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$ :   \n24 color[v] $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad1$   \n25 s_prev[v] $=$ s_last   \n26 s_last $=\\_v$   \n27 probing.push(   \n28 probes ,   \n29 specs.Stage.HINT ,   \n30 next_probe $=5$   \n31 # < omitted for brevity >   \n2 })   \n33 break   \n4   \n5 if s_last $\\mathbf{\\tau}=\\mathbf{\\tau}\\cdot\\mathbf{u}$ :   \n6 color[u] $\\r=\\ r_{2}$   \n37 time $+=\\ \\ 0\\ ,\\ 0\\,1$   \n8 f[u] $=$ time   \n39   \n40 probing.push(   \n41 probes ,   \n2 specs.Stage.HINT ,   \n3 next_probe $=\\{$ {   \n4 # < omitted for brevity $>$   \n5 })   \n46   \n7 if s_prev[u] $\\mathbf{\\tau}=\\mathbf{\\tau}\\cdot\\mathbf{u}$ : # same as before   \n8 assert s_prev[s_last] $==$ s_last   \n49 break   \n150 pr s_prev[s_last]   \n51 s_prev[s_last] $=$ s_last   \n2 s_last $=$ pr   \n3   \n4 u = s_last   \n5   \n6 probing.push(   \n7 probes ,   \n8 specs.Stage.OUTPUT ,   \n9 next_probe ={\u2019scc_id \u2019: np.copy(scc_id)},   \n60 )   \n61 probing.finalize(probes)   \n2   \n3 return scc_id , probes ", "page_idx": 18}, {"type": "text", "text": "Listing 3: Kosaraju\u2019s strongly connected components [40] algorithm. It is composed of four (two nested ones, sequenced one after the other) while $b$ do $c$ constructs. ", "page_idx": 18}, {"type": "text", "text": "D Differences to Ibarz et al. [29] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Our differences are mostly required by software engineering rather than research, hence they live here. Differences are: ", "page_idx": 18}, {"type": "text", "text": "\u2022 Different DL framework (Pytorch [36]) ", "page_idx": 19}, {"type": "text", "text": "\u2022 Ibarz et al. [29] use an extra nonlinearity after the GNN step. We found this to be not necessary (there are plenty of nonlinearities at the message function) for the baseline and to be making the training of DEARs less stable so we removed it.   \n\u2022 Sorting-based algorithms use a Sinkhorn operator to force the output to be a permutation. However, this gave very negative logits for the predictions at initialisation, leading to runs starting from a very high loss and converging to poorer minima. We fixed this by adding an off-centred leaky ReLU activation with the kink point at (-6, -6) right after the Sinkhorn operator. After conversion of logits to outputs via softmax, our change is mathematically equivalent to saying that the probability for each other node to be predecessor should not drop below $10^{-\\overline{{6}}}$ ", "page_idx": 19}, {"type": "text", "text": "E Picking least fixed point ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "For a given batch fixed point finding continues until all instances in the batch converge and at each step the solver is stepped on all instances. For a given instance, when two $\\mathbf{H}^{(t)}$ and $\\bar{\\mathbf{H}}^{(t^{\\prime})}$ are under the threshold $\\delta$ , for some $t\\le t^{\\prime}$ , the torchdeq library prefers the state that has the lower distance to next state. Consequently, out the returned fixed points only one is guaranteed to be least \u2013 the one that require the most steps. This not only misaligns with domain theory, but also had the practical effect that the neural models require more iterations to converge the more we train them. Thus, we changed the library to choose the first $\\mathbf H(t)$ that passes the fixed point criteriaq. ", "page_idx": 19}, {"type": "text", "text": "F Alignment algorithm ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Assume we have computed pairwise distance matrices between the states and those are stored in a $T\\times T_{\\mathcal{G}}$ distance matrix $\\mathbf{D}$ with elements $d_{i,j}$ . Ignoring the required alignment of the last states, we focus on aligning the rest of the states. This is done via standard dynamic programming algorithm. The dynamic programming state we define is as follows: $d p_{i,j}$ is the most optimal alignment for the first $i$ DEAR states and first $j$ NAR states, with $d p_{0,j}=0$ (having leftover NAR states mean we skipped some, but we do not want to penalise that) and $d p_{i,0}=\\infty$ (we want to align all DEAR states). We consider two recursive formulas, first one we use, the other we use when $T\\leq T_{\\mathcal{G}}$ : ", "page_idx": 19}, {"type": "text", "text": "states to align to a same state: $d p_{i,j}=\\operatorname*{min}{\\left\\{\\begin{array}{l l}{d p_{i-1,j}+d_{i,j}}&{{\\mathrm{aligning~DEAR~state~}}i{\\mathrm{~and~NAR~state~}}j,{\\mathrm{but~allowing~for~}}i}\\\\ &{{\\mathrm{previous~states~to~align~to~it~as~well}}}\\\\ {d p_{i,j-1}}&{{\\mathrm{skipping~alignment~with~state~}}j}\\end{array}\\right.}$ \u2022 when the $T\\leq T_{\\mathcal{G}}$ we require that each DEAR state aligns to an unique NAR state: ", "page_idx": 19}, {"type": "text", "text": "", "page_idx": 19}, {"type": "equation", "text": "$$\nd p_{i,j}=\\operatorname*{min}{\\\\left\\{\\begin{array}{l l}{d p_{i-1,j-1}+d_{i,j}}&{{\\mathrm{aligning~DEAR~state~}}i{\\mathrm{~and~NAR~state~}}j}\\\\ {d p_{i,j-1}}&{{\\mathrm{skipping~alignment~with~state~}}j}\\end{array}\\right.}\\qquad{\\mathrm{(6)}}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We have highlighted the difference to the above in purple. ", "page_idx": 19}, {"type": "text", "text": "The optimal alignment for the whole two sequence is stored in $d p_{T,T_{\\mathcal{G}}}$ . As both $\\mathbf{H}^{(0)}$ and $\\mathbf{H}_{\\mathcal{G}}^{(0)}$ are concatenation of 0 vectors (due to how we initialise the latent state), their distance is always 0 and they will always align as required. To enforce alignment of the last state, we take the optimal value for the subsequences without last states $d p_{T-1,T_{\\mathcal{G}}-1}$ and always (even when subsampling, see below) add the distances between the last states to the loss function. ", "page_idx": 19}, {"type": "text", "text": "As the above will always penalise longer DEQ trajectories, we divide $d p_{T-1,T_{\\mathcal{G}}-1}$ by $T-1$ before including it in the loss function. Lastly, to allow for \u201cintermediate\u201d states (ones not necessarily matching a GNN state) to exist, we subsample randomly, without replacement, $\\begin{array}{r}{T^{\\prime}=\\operatorname*{max}(\\lfloor\\frac{T-1}{2}\\rfloor,\\dot{1})}\\end{array}$ DEAR states and apply the dynamic programming algorithm with the subsampled sequence. ", "page_idx": 19}, {"type": "image", "img_path": "SuLxkxCENa/tmp/a2de89dec090bdd34d268d3ddaa50d215336f324cac47b6a47944fc221002153.jpg", "img_caption": ["G Training loss: NAR vs DEAR ", "Figure 6: Side-by-side comparison of NAR vs DEAR. DEAR training loss is always within 1 order of magnitude of NAR. Note the log scale. "], "img_footnote": [], "page_idx": 20}, {"type": "table", "img_path": "SuLxkxCENa/tmp/0919910825262eadaab12a693e0f535df99149b4718aa26d2b35b5de6f2e588f.jpg", "table_caption": ["Table 5: Fixing anomalies with CLRS-30\u2019s binary search further increases our overall score making our approach very competitive to Triplet-MPNN. Notation taken from Table 1. "], "table_footnote": [], "page_idx": 21}, {"type": "text", "text": "H Binary search anomalies ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In the CLRS-30 implementation of binary search, we aim to find the place to insert the target value x in a sorted array A. Thus we need to point to the graph node that holds the smallest value in the array A, which is greater than x. However, if $\\mathtt{x}>\\mathtt{m a x}$ (A), the answer is a pointer to the last value of the array, which by the convention used by CLRS-30 means we would be inserting ${\\tt x}$ at the wrong place. In other words, the answer to $\\mathtt{A}\\mathrm{{=}}\\left[0.1\\right]$ , 0.2, 0.3] ${\\tt x}^{=}0.25$ and $\\mathtt{A}\\mathrm{{=}}\\left[0.1\\right]$ , 0.2, 0.3] $\\tt x{=}0.35$ is the same \u2013 insert ${\\tt x}$ to the left of 0.3. This contributed some noise, so we fixed the sampler to always give x within [0, max(A)). The other changes were to explicitly use graph $\\&$ pointer instead of node $\\&$ mask_one as the location & datatype of the pointer to the position in the array, also done by Engelmayer et al. [16]. Similarly to them, we also add an additional supervision signal, but at the output level rather than the hint level \u2013 teaching the models to predict which array elements are smaller than x (binary mask type). ", "page_idx": 21}, {"type": "text", "text": "We reran the new, parallel version of search, reporting results in Table 5. Our model still falls short of the baselines, but the $26\\%$ increase in accuracy is large enough to give a slight overall advantage to DEAR over the Triplet-MPNN model. We do note, however, that the task of searching is mostly numerical (comparison between floating point numbers), resulting in DEAR overftiting a lot \u2013 recall that train accuracy was $95\\%$ even for the original (binary) search. We verified that if the training data is increased $3\\times-5\\times$ , test accuracy becomes comparable to other models, regardless of which version is used. ", "page_idx": 21}, {"type": "image", "img_path": "SuLxkxCENa/tmp/ce6192e4de92881cbe32fa34358661732d8fc58931a46aa0a028abdad92fd033.jpg", "img_caption": ["I Training loss: DEAR vs DEAR w/ CGP ", "Figure 7: Effect of using Cayley Graph propagation on the train loss. "], "img_footnote": [], "page_idx": 22}, {"type": "text", "text": "J Alignment gives closer convergence ", "text_level": 1, "page_idx": 23}, {"type": "image", "img_path": "SuLxkxCENa/tmp/f8b49de5d965137794f8b9bc75072e351a963498ad75717f097e839b36e039fc.jpg", "img_caption": [], "img_footnote": [], "page_idx": 23}, {"type": "text", "text": "Figure 8: Alignment (orange) leads to lower task train loss compared to no aligment, but using stochasticity and GRANOLA (green). ", "page_idx": 23}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We have even included pointers to sections relevant to the claims ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 24}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Justification: Drawbacks are highlighted and discussed throughout the experimental section Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 24}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Although we do not prove any theorems we clearly state the assumptions of when our method should work. (Beginning of implementation section) ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 25}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Refer to implementation, beginning of evaluation and appendicies. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 25}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: Proprietary codebase, but we are planning open-sourcing in the future Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 26}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: See experimental sections ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 26}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 26}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 26}, {"type": "text", "text": "Justification: The only exception where we do not report deviations, is DEM [53] \u2013 we do not have their code and they do not report standard deviations in their work ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: Page 7, bottom; also ?? We did not take precise measures since the very beginning of the project, so we give an approximation. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 27}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 27}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 27}, {"type": "text", "text": "Justification: We conformed to the code of ethics ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 27}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 27}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 27}, {"type": "text", "text": "Justification: Our work focuses on the improving NAR reasoners on abstract algorithms, not their real-world applications. ", "page_idx": 27}, {"type": "text", "text": "Guidelines: ", "page_idx": 27}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 28}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 28}, {"type": "text", "text": "Justification: See above; we are not LLM research ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 28}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: Licenses for CLRS-30 and torchdeq are given. ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 28}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 29}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: We do not release new assets ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 29}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: No crowdsourcing experiments were performed ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 29}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 29}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 29}, {"type": "text", "text": "Justification: No crowdsourcing experiments were performed ", "page_idx": 29}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 29}]