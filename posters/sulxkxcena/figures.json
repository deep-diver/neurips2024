[{"figure_path": "SuLxkxCENa/figures/figures_5_1.jpg", "caption": "Figure 1: Proposed alignment rule: every state in the DEAR trajectory should \"go forward\". Alignments to a GNN state that has already been \"passed\" are disallowed. First and last states must always align. We intentionally use arrows instead of  for DEAR, as  may not hold for DEAR's trajectory.", "description": "This figure illustrates the proposed alignment rule for Deep Equilibrium Algorithmic Reasoners (DEARs).  The rule states that the sequence of states in the DEAR trajectory must always progress forward, never revisiting previously visited states (except for the start and end states which must align).  This constraint helps to ensure that the DEAR model's execution mirrors the forward progress of the algorithm it is emulating. The diagram uses arrows to represent the DEAR state transitions, as the direct equality between states may not always hold in the DEAR trajectory.  The allowed and disallowed alignments of states are visually demonstrated, clarifying acceptable and unacceptable state mappings between the DEAR and GNN (Graph Neural Network) rollouts.", "section": "4 Deep equilibrium algorithmic reasoning"}, {"figure_path": "SuLxkxCENa/figures/figures_6_1.jpg", "caption": "Figure 6: Side-by-side comparison of NAR vs DEAR. DEAR training loss is always within 1 order of magnitude of NAR. Note the log scale.", "description": "This figure shows a comparison of the training loss curves for NAR (Neural Algorithmic Reasoning) and DEAR (Deep Equilibrium Algorithmic Reasoners) models across ten different algorithms.  The y-axis represents the training loss on a logarithmic scale, ranging from 10\u207b\u2075 to 10\u2070. The x-axis represents the training epoch, from 0 to 100. For each algorithm, two lines are plotted, one for NAR and one for DEAR.  The results indicate that the DEAR training loss consistently remains within one order of magnitude of the NAR training loss across all algorithms. This suggests that DEAR achieves comparable performance to NAR while having a different architecture and training approach.", "section": "5.1 Results"}, {"figure_path": "SuLxkxCENa/figures/figures_8_1.jpg", "caption": "Figure 7: Effect of using Cayley Graph propagation on the train loss.", "description": "This figure shows a comparison of the training loss curves for DEAR models with and without Cayley Graph Propagation (CGP) across various algorithms.  The plots show that for some algorithms, CGP led to lower loss, indicating potential benefit for convergence. For others, however, the effect was less pronounced or even slightly negative.", "section": "5.1 Results"}, {"figure_path": "SuLxkxCENa/figures/figures_8_2.jpg", "caption": "Figure 8: Alignment (orange) leads to lower task train loss compared to no alignment, but using stochasticity and GRANOLA (green).", "description": "This figure shows a comparison of training loss curves for three different model variants across three algorithms: Binary Search, DAG Shortest Paths, and MST Prim.  The \"NAR\" line represents a standard Neural Algorithmic Reasoning (NAR) model.  The \"DEAR w/ GAS\" line represents a Deep Equilibrium Algorithmic Reasoner (DEAR) model with the addition of a Gating mechanism and stochasticity. The \"DEAR w/ GS\" line represents a DEAR model with only stochasticity.  The results suggest that using alignment (orange curves) leads to lower training loss compared to models without alignment (green), particularly for the DAG Shortest Paths and MST Prim algorithms. The use of stochasticity and GRANOLA (a type of layer normalization) further enhances the results, leading to closer convergence of the training loss.", "section": "5.1 Results"}, {"figure_path": "SuLxkxCENa/figures/figures_9_1.jpg", "caption": "Figure 5: Alignment (DEAR w/ GAS) leads to improvements OOD", "description": "This figure displays the test accuracy over epochs for two algorithms: DAG Shortest Paths and MST Prim.  Three model variations are compared: NAR (standard Neural Algorithmic Reasoning), DEAR (Deep Equilibrium Algorithmic Reasoner), and DEAR w/ GAS (DEAR with a Global Alignment Scheme).  The graph shows that the alignment scheme (GAS) generally improves the test accuracy of the DEAR models, particularly in later epochs, suggesting it enhances out-of-distribution generalization performance.", "section": "5 Evaluation"}, {"figure_path": "SuLxkxCENa/figures/figures_20_1.jpg", "caption": "Figure 6: Side-by-side comparison of NAR vs DEAR. DEAR training loss is always within 1 order of magnitude of NAR. Note the log scale.", "description": "This figure presents a detailed comparison of the training loss curves for both NAR (Neural Algorithmic Reasoning) and DEAR (Deep Equilibrium Algorithmic Reasoner) models across ten different algorithms.  The y-axis represents the training loss on a logarithmic scale, highlighting the relative differences. The x-axis shows the number of training epochs.  The key observation is that the training loss for DEAR consistently remains within one order of magnitude of the NAR loss across all algorithms, demonstrating comparable training performance. The log scale emphasizes the consistent proximity of the loss values between the two models, indicating that DEAR does not substantially deviate in terms of training loss compared to the more traditional NAR approach.", "section": "5 Evaluation"}, {"figure_path": "SuLxkxCENa/figures/figures_22_1.jpg", "caption": "Figure 7: Effect of using Cayley Graph propagation on the train loss.", "description": "This figure shows the training loss curves for DEAR models both with and without Cayley Graph Propagation (CGP) across various algorithms from the CLRS-30 benchmark. The plot reveals that for some algorithms, CGP aids in achieving a lower training loss, suggesting that it can be beneficial for model convergence and overall performance. Conversely, for others, there's no clear advantage or even a slight negative impact with CGP. This highlights that the effectiveness of CGP is algorithm-dependent and not universally beneficial for deep equilibrium algorithmic reasoning.", "section": "5.1 Results"}, {"figure_path": "SuLxkxCENa/figures/figures_23_1.jpg", "caption": "Figure 8: Alignment (orange) leads to lower task train loss compared to no alignment, but using stochasticity and GRANOLA (green).", "description": "The figure shows the training loss curves for three different algorithms (Binary Search, DAG Shortest Paths, and MST Prim) using three different training methods: NAR (baseline), DEAR w/ GAS (DEAR with alignment, GRANOLA, and stochasticity), and DEAR w/ GS (DEAR with GRANOLA and stochasticity, but without alignment).  The graphs clearly demonstrate that using alignment (DEAR w/ GAS) consistently results in lower training loss than using only GRANOLA and stochasticity without alignment (DEAR w/ GS), and often significantly lower training loss than the baseline NAR method.  The use of both GRANOLA and stochasticity seems to help with the convergence of training loss.", "section": "5.1 Results"}]