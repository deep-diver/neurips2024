[{"type": "text", "text": "Achieving Constant Regret in Linear Markov Decision Processes ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Weitong Zhang\\* ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zhiyuan Fan\\* ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "School of Data Science and Society University of North Carolina at Chapel Hill Chapel Hill, NC 27599 weitongz@unc.edu ", "page_idx": 0}, {"type": "text", "text": "EECS Massachusetts Institute of Technology Cambridge, MA 02139 fanzy@mit.edu ", "page_idx": 0}, {"type": "text", "text": "Jiafan He ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Quanquan Gu ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of Computer Science University of California, Los Angeles Los Angeles, CA 90095 jiafanhe19@ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Department of Computer Science University of California, Los Angeles Los Angeles, CA 90095 qgu@cs.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the constant regret guarantees in reinforcement learning (RL). Our objective is to design an algorithm that incurs only finite regret over infinite episodes with high probability. We introduce an algorithm, Cert -LsVI-UCB, for misspecified linear Markov decision processes (MDPs) where both the transition kernel and the reward function can be approximated by some linear function up to misspecification level $\\zeta$ .At the core of Cert-LsVI-UCB is an innovative certified estimator, which facilitates a fine-grained concentration analysis for multi-phase value-targeted regression, enabling us to establish an instance-dependent regret bound that is constant w.r.t. the number of episodes. Specifically, we demonstrate that for a linear MDP characterized by a minimal suboptimality gap $\\Delta$ Cert-LSVI-UCB has a cumulative regret of $\\widetilde{\\cal O}(d^{3}H^{5}/\\Delta)$ with high probability, provided that the misspecification level $\\zeta$ is below $\\tilde{\\mathcal{O}}(\\Delta/(\\sqrt{d}H^{2}))$ .Here $d$ is the dimension of the feature space and $H$ is the horizon. Remarkably, this regret bound is independent of the number of episodes $K$ . To the best of our knowledge, Cert -LsVI-UCB is the first algorithm to achieve a constant, instance-dependent, high-probability regret bound in RL with linear function approximation without relying on prior distribution assumptions. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Reinforcement learning (RL) has been a popular approach for teaching agents to make decisions based on feedback from the environment. RL has shown great success in a variety of applications, including robotics (Kober et al., 2013), gaming (Mnih et al., 2013), and autonomous driving. In most of these applications, there is a common expectation that RL agents will master tasks after making only a bounded number of mistakes, even over indefinite runs. However, theoretical support for this expectation is limited in RL literature: in the worst case, existing works such as Jin et al. (2020); Ayoub et al. (2020); Wang et al. (2019) only provided $\\widetilde{\\mathcal{O}}(\\sqrt{K})$ regret upper bounds with $K$ being the number of episodes; in the instance-dependent case, Simchowitz and Jamieson (2019); Yang et al. (2021); He et al. (2021a) achieved logarithmic high-probability regret upper bounds (e.g., $\\tilde{\\mathcal{O}}(\\Delta^{-1}\\log K))$ for both tabular MDPs and MDPs with linear function approximations, provided a minimal suboptimality gap $\\Delta$ . However, these findings suggest that an agent's regret increases with the number of episodes $K$ , contradicting to the expectation of finite mistakes in practice. To close this gap between theory and practice, there is a recent line of work proving constant regrets bound for RL and bandits, suggesting that an RL agent's regret may remain bounded even when it encounters an indefinite number of episodes. Papini et al. (2021a); Zhang et al. (2021) have provided instance-dependent constant regret bound under certain coverage assumptions on the data distribution. However, verifying these data distribution assumptions can be difficult or even infeasible. On the other hand, it is known that high-probability constant regret bound can be achieved unconditionally in multi-armed bandits (Abbasi- Yadkori et al., 2011) and contextual linear bandits if and only if the misspecification is sufficiently small with respect to the minimal sub-optimality gap (Zhang et al., 2023b). This raises a critical question: ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Is it possible to design a reinforcement learning algorithm that incurs only constant regret under minimalassumptions? ", "page_idx": 1}, {"type": "text", "text": "To answer this question, we introduce a novel algorithm, which we refer to as Cert -LsvI-UCB, for reinforcement learning with linear function approximation. To encompass a broader range of realworld scenarios characterized by large state-action spaces and the need for function approximation, we consider the misspecified linear MDP (Jin et al., 2020) setting, where both the transition kernel and reward function can be approximated by a linear function with approximation error $\\zeta$ .Weshow that, with our innovative design of certified estimator and novel analysis, Cert -LsVI-UCB achieves constant regret without relying on any prior assumption on data distributions. Our key contributions are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u00b7 We introduce a parameter-free algorithm, referred to as Cert-LsVI-UCB, featuring a novel certified estimator for testing when the confidence set fails. This certified estimator enables Cert -LSVI-UCB to achieve a constant, instance-dependent, high probability regret bound of $\\widetilde{\\cal O}(d^{3}H^{5}/\\Delta)$ for tasks with a suboptimality gap $\\Delta$ , under the condition that the misspecification level $\\zeta$ is bounded by $\\zeta<\\tilde{\\mathcal{O}}\\big(\\Delta/(\\sqrt{d}H^{2})\\big)$ . This bound is termed a high probability constant regret bound, indicating that it does not depend on the number of episodes $K$ .Wenote that this constant regret bound matches the logarithmic expected regret lower bound of $\\Omega(\\Delta^{-1}\\log K)$ suggesting that our result is valid and optimal in terms of the dependence on the suboptimality gap $\\Delta$ ", "page_idx": 1}, {"type": "text", "text": "\u00b7 When restricted to a well-specified linear MDP (i.e., $\\zeta\\;=\\;0$ ), the constant high probability regret bound improves the previous logarithmic result ${\\widetilde{\\mathcal{O}}}(d^{3}H^{5}\\Delta^{-1}\\log K)$ in He et al. (2021a) by a $\\log K$ factor. Our results suggest that the total suboptimality incurred by Cert -LSVI-UCB remains constantly bounded, regardless of the number of episodes $K$ . In contrast to the previous constant regret bound achieved by Papini et al. (2021a), our regret bound does not require any prior assumption on the feature mapping, such as the UniSOFT assumption made in Papini et al. (2021a). To the best of our knowledge, Cert -LsVI-UCB is the first algorithm to achieve a high probability constant regret bound for MDPs without prior assumptions on data distributions. We further show that this constant regret high-probability bound does not violate the logarithmic expected regret bound by letting $\\bar{\\delta}\\,\\bar{=}\\,1/K^{\\,\\overline{{{2}}}}$ ", "page_idx": 1}, {"type": "text", "text": "Notation. Vectors are denoted by lower case boldface letters such as $\\mathbf{x}$ , and matrices by upper case boldface letters such as A. We denote by $[k]$ the set $\\{1,2,\\cdots\\,,k\\}$ for positive integers $k$ We use $\\log x$ to denote the logarithm of $x$ to base 2. For two non-negative sequence $\\{a_{n}\\},\\{b_{n}\\},a_{n}\\leq\\mathcal{O}(b_{n})$ means that there exists a positive constant $C$ such that $a_{n}\\leq C b_{n}$ $a_{n}\\leq{\\widetilde{\\mathcal{O}}}(b_{n})$ means there exists a positive constant $k$ such that $a_{n}\\leq O(b_{n}\\log^{k}b_{n})$ $a_{n}\\geq\\Omega(b_{n})$ means that there exists a positive constant $C$ such that $a_{n}\\,\\geq\\,C b_{n}$ $a_{n}\\,\\geq\\,{\\widetilde{\\Omega}}(b_{n})$ means there exists a positive constant $k$ such that $a_{n}\\,\\geq\\,\\Omega(b_{n}\\log^{-k}b_{n})$ $a_{n}\\,\\geq\\,\\omega(b_{n})$ means that $\\begin{array}{r}{\\operatorname*{lim}_{n\\to\\infty}b_{n}/a_{n}=0}\\end{array}$ . For a vector $\\textbf{x}\\in\\mathbb{R}^{d}$ and a positive semi-definite matrix $\\mathbf{A}\\in\\dot{\\mathbb{R}}^{d\\times d}$ , we define $\\|\\mathbf{x}\\|_{\\mathbf{A}}^{2}=\\mathbf{x}^{\\top}\\mathbf{Ax}$ . For any set $\\mathcal{C}$ we use $|{\\mathcal{C}}|$ to denote its cardinality. We denote the identity matrix by $\\mathbf{I}$ and the empty set by $\\mathcal{Q}$ . The total variation distance of two distribution measures $\\mathbb{P}(\\cdot)$ and $\\mathbb{Q}(\\cdot)$ is denoted by $\\lVert\\bar{\\mathbb{P}}\\bar{(\\cdot)}-\\bar{\\mathbb{Q}}^{\\dot{(\\cdot)}\\lVert_{\\mathbb{T V}}}$ ", "page_idx": 1}, {"type": "table", "img_path": "02r24A8doi/tmp/776787e942a40294fff892ed193d12f49f6b6a0ff62b83b236e5fa0ac263e51b.jpg", "table_caption": [], "table_footnote": ["Table 1: Instance-dependent regret bounds for different algorithms under the linear MDP setting. Here $d$ is the dimension of the linear function $\\phi(s,a)$ \uff0c $H$ is the horizon length, $\\Delta$ is the minimal suboptimality gap. All results in the table represent high probability regret bounds. The regret bound depends the number of episodes $K$ in He et al. (2021a) and the minimum positive eigenvalue $\\lambda$ of features mapping in Papini et al. (2021b). Misspecified MDP? indicates if the algorithm can $(\\checkmark)$ handle the misspecified linear MDP or not $(\\times)$ "], "page_idx": 2}, {"type": "text", "text": "2 Related Work ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Instance-dependent regret bound in RL. Although most of the theoretical RL works focus on worst-case regret bounds, instance-dependent (a.k.a., problem-dependent, gap-dependent) regret bound is another important bound to understanding how the hardness of different instance can affect the sample complexity of the algorithm. For tabular MDPs, Jaksch et al. (2010) proved a ${\\widetilde{\\mathcal{O}}}(D^{2}S^{2}A\\bar{\\Delta^{-1}}\\log{\\bar{K}})$ instance-dependent regret bound for average-reward MDP where $D$ is the diameter of the MDP and $\\Delta$ is the policy suboptimal gap. Simchowitz and Jamieson (2019) provided a lower bound for episodic MDP which suggests that the any algorithm will suffer from $\\Omega(\\Delta^{-1})$ regret bound. Yang et al. (2021) analyzed the optimistic $Q$ -learning and proved a $\\mathcal{O}(S A\\dot{H}^{6}\\Delta^{-1}\\log\\dot{K})$ logarithmic instance-dependent regret bound. In the domain of linear function approximation, He et al. (2021a) provided instance-dependent regret bounds for both linear MDPs (i.e., $\\tilde{\\mathcal{O}}(d^{3}H^{5}\\Delta^{-1}\\log\\dot{K}))$ and linear mixture MDPs (i.e., $\\tilde{\\mathcal{O}}(\\tilde{d^{2}H^{5}}\\Delta^{-1}\\log K))$ . Furthermore, Dann et al. (2021) provided an improved analysis for this instance-dependent result with a redefined suboptimal gap. Zhang et al. (2023a) proved a similar logarithmic instance-dependent bound with He et al. (2021a) in misspecified linear MDPs, showing the relationship between misspecification level and suboptimality bound. Despite all these bounds are logarithmic depended on the number of episode $K$ , many recent works are trying to remove this logarithmic dependence. Papini et al. (2021a) showed that under the linear MDP assumption, when the distribution of contexts $\\phi(s,a)$ satisfies the \u201cdiversity assumption\u2019 (Hao et al., 2020) called \u201cUniSOFT', then LSVI-UCB algorithm may achieve an expected constant regret w.r.t. $K$ . Zhang et al. (2021) showed a similar result on bilinear MDP (Yang and Wang, 2020), and extended this result to ofline setting, indicating that the algorithm only need a finite offline dataset to learn the optimal policy. Table 1 summarizes the most relevant results mentioned above for the ease of comparison with our results. ", "page_idx": 2}, {"type": "text", "text": "RL with model misspecification.  All of the aforementioned works consider the well-specified setting and ignore the approximation error in the MDP model. To better understand this misspecification issue, Du et al. (2019) showed that having a good representation is insufficient for efficient RL unless the approximation error (i.e., misspecification level) by the representation is small enough. In particular, Du et al. (2019) showed that an $\\widetilde{\\Omega}(\\sqrt{H/d})$ misspecification will lead to $\\Omega(2^{H})$ sample complexity for RL to identify the optimal policy, even with a generative model. On the other hand, a series of work (Jin et al., 2020; Zanette et al., 2020b,a) provided $\\widetilde{\\mathcal{O}}(\\sqrt{K}+\\zeta K)$ -type regret bound for RL in various settings, where $\\zeta$ is the misspecification level3 and we ignore the dependence on the dimension of the feature mapping $d$ and the planing horizon $H$ for simplicity. These algorithms, however, require the knowledge of misspecification level $\\zeta$ , thus are not parameterfree. Another concern for these algorithms is that some of the algorithms (Jin et al., 2020) would possibly suffer from a trivial asymptotic regret, i.e., $\\operatorname{Regret}(k)>\\operatorname{\\bar{\\omega}}(k\\zeta\\cdot\\operatorname{poly}(d,H,\\log(1/\\delta)))$ , as suggested by Vial et al. (2022). This means the performance of the RL algorithm will possibly degenerate as the number of episodes $k$ grows. To tackle these two issues, Vial et al. (2022) propose the Sup-LSVI-UCB algorithm which requires a parameter $\\varepsilon_{\\mathrm{tol}}$ . When $\\varepsilon_{\\mathrm{{tol}}}\\,=\\,d/\\sqrt{K}$ , the proposed algorithm is parameter-free but will have a trivial asymptotic regret bound. When $\\varepsilon_{\\mathrm{{tol}}}\\;=\\;\\zeta$ ,the algorithm will have a non-trivial asymptotic regret bound but is not parameter-free since it requires knowledge of the misspecification level. Another series of works (He et al., 2022b; Lykouris et al., 2021; Wei et al., 2022) are working on the corruption robust setting. In particular, Lykouris et al. (2021); Wei et al. (2022) are using the model-selection technique to ensure the robustness of RL algorithms under adversarial MDPs. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We consider episodic Markov Decision Processes, which are denoted by $\\mathcal{M}(\\ensuremath{\\boldsymbol{\\mathcal{S}}},\\mathcal{A},\\ensuremath{\\boldsymbol{H}},\\left\\{\\ensuremath{\\boldsymbol{r}}_{h}\\right\\},\\left\\{\\ensuremath{\\mathbb{P}}_{h}\\right\\})$ Here, $\\boldsymbol{S}$ is the state space, $\\boldsymbol{\\mathcal{A}}$ is the finite action space, $H$ is the length of each episode, $r_{h}:S\\times A\\mapsto$ $[0,1]$ is the reward function at stage $h$ and $\\mathbb{P}_{h}(\\cdot|s,a)$ is the transition probability function at stage $h$ The policy $\\pi=\\{\\pi_{h}\\}_{h=1}^{H}$ dentes a set of policyfunctons $\\pi_{h}:S\\mapsto A$ for each stage $h$ For given policy $\\pi$ , we define the state-action value function $Q_{h}^{\\pi}(s,a)$ and the state value function $V_{h}^{\\pi}(s)$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{I}_{h}^{\\pi}(s,a)=r_{h}(s,a)+\\mathbb{E}\\left[\\sum_{h^{\\prime}=h+1}^{H}r_{h^{\\prime}}\\big(s_{h^{\\prime}},\\pi_{h^{\\prime}}(s_{h^{\\prime}})\\big)~\\middle|~s_{h}=s,a_{h}=a\\right],V_{h}^{\\pi}(s)=Q_{h}^{\\pi}\\big(s,\\pi_{h}(s)\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $s_{h^{\\prime}+1}\\,\\sim\\,\\mathbb{P}_{h}\\bigl(\\cdot\\vert s_{h^{\\prime}},a_{h^{\\prime}}\\bigr)$ . The optimal state-action value function $Q_{h}^{*}$ and the optimal state value function $V_{h}^{*}$ are defined by $\\begin{array}{r}{Q_{h}^{*}(s,a)=\\operatorname*{max}_{\\pi}Q_{h}^{\\pi}(s,a),V_{h}^{*}(s)=\\operatorname*{max}_{\\pi}V_{h}^{\\pi}(s)}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "By definition, both the state-action value function $Q_{h}^{\\pi}(s,a)$ and the state value function $V_{h}^{\\pi}(s)$ are bounded by $[0,H]$ for any state $s$ , action $a$ and stage $h$ . For any function $V:{\\mathcal{S}}\\mapsto\\mathbb{R}$ , we denote by $[\\mathbb{P}_{h}V](s,\\bar{a})=\\^{\\prime}\\mathbb{E}_{s^{\\prime}\\sim\\mathbb{P}_{h}(\\cdot|s,a)}V(s^{\\prime})$ the expected value of $V$ after transitioning from state $s$ given action $a$ at stage $h$ and $\\lbrack\\mathbb{B}_{h}{\\dot{V}}](s,a)=r_{h}(s,a)+[\\mathbb{P}_{h}V](s,a)$ where $\\mathbb{B}$ is referred to as the Bellman operator. For each stage $\\textit{h}\\in[H]$ and policy $\\pi$ , the Bellman equation, as well as the Bellman optimality equation, are presented as follows ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{Q_{h}^{\\pi}(s,a)=r_{h}(s,a)+[{\\mathbb P}_{h}V_{h+1}^{\\pi}](s,a):=[{\\mathbb B}_{h}V_{h+1}^{\\pi}](s,a),}\\\\ &{Q_{h}^{*}(s,a)=r_{h}(s,a)+[{\\mathbb P}_{h}V_{h+1}^{*}](s,a):=[{\\mathbb B}_{h}V_{h+1}^{*}](s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We use regret to measure the performance of $\\mathrm{RL}$ algorithms. It is defined as ${\\mathrm{Regret}}(K)\\;=$ $\\begin{array}{r}{\\sum_{k=1}^{K}\\left(V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi^{k}}(s_{1}^{k})\\right)}\\end{array}$ where $\\pi^{k}$ represents theaen's pleyat episode $k$ quantifies the cumulative difference between the expected rewards that could have been obtained by following the optimal policy and those achieved under the agent's policy across the first $K$ episodes, measuring the total loss in performance due to suboptimal decisions. ", "page_idx": 3}, {"type": "text", "text": "We consider linear function approximation in this work, where we adopt the misspecifed linear $M D P$ assumption, which is firstly proposed in Jin et al. (2020). ", "page_idx": 3}, {"type": "text", "text": "Assumption 3.1 $\\zeta$ -Approximate Linear MDP, Jin et al. 2020). For any $\\zeta\\,\\leq\\,1$ , we say a MDP $\\mathcal{M}(\\mathcal{S},\\bar{\\mathcal{A}},H,\\{r_{h}\\},\\{\\mathbb{P}_{h}\\})$ is a $\\zeta$ -approximate linear MDP with a feature map $\\phi:S\\times A\\mapsto\\mathbb{R}^{d}$ ,if for aly $h\\,\\in\\,[H]$ therexist $d$ umnknown siged measues $\\pmb{\\mu}_{h}\\,=\\,\\big(\\mu_{h}^{(1)},\\cdot\\cdot\\cdot\\,,\\mu_{h}^{(d)}\\big)$ over $\\boldsymbol{S}$ and an unknown vector $\\pmb{\\theta}_{h}\\in\\mathbb{R}^{d}$ such that for any $(s,a)\\in S\\times A$ , we have ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\left|\\mathbb{P}_{h}(\\cdot|s,a)-\\langle\\phi(s,a),\\mu_{h}(\\cdot)\\rangle\\right|\\right|_{\\mathrm{TV}}\\leq\\zeta,\\quad\\left|r_{h}(s,a)-\\langle\\phi(s,a),\\theta_{h}\\rangle\\right|\\leq\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "w.l.o.g. we assume $\\forall(s,a)\\in S\\times A:\\|\\phi(s,a)\\|\\leq1$ and $\\forall h\\in[H]:\\|\\pmb{\\mu}_{h}(S)\\|\\leq\\sqrt{d},\\|\\pmb{\\theta}_{h}\\|\\leq\\sqrt{d}.$ ", "page_idx": 3}, {"type": "text", "text": "The $\\zeta$ -approximate linear MDP suggests that for any policy $\\pi$ , the state-action value function $Q_{h}^{\\pi}$ can be approximated by a linear function of the given feature mapping $\\phi$ up to some misspecification level, which is summarized in the following proposition. ", "page_idx": 3}, {"type": "text", "text": "Proposition 3.2 (Lemma C.1, Jin et al. 2020). For a $\\zeta$ -approximate linear MDP, for any policy $\\pi$ \uff0c there exist corresponding weights $\\{\\mathbf{w}_{h}^{\\pi}\\}_{h\\in[H]}$ where $\\begin{array}{r}{\\dot{\\mathbf{w}_{h}^{\\pi^{*}}}=\\pmb{\\theta}_{h}+\\int V_{h+1}^{\\pi}(s^{\\prime})\\mathrm{d}\\pmb{\\mu}_{h}(s^{\\prime})}\\end{array}$ such that for any $(s,a,h)\\in S\\times A\\times[H]$ $\\left|Q_{h}^{\\pi}(s,a)-\\langle\\phi(s,a),\\mathbf{w}_{h}^{\\pi}\\rangle\\:\\right|\\leq2H\\zeta$ We have $\\|\\mathbf{w}_{h}^{\\pi}\\|_{2}\\leq2H\\sqrt{d}$ ", "page_idx": 3}, {"type": "text", "text": "Next, we introduce the definition of the suboptimal gap as follows. ", "page_idx": 3}, {"type": "text", "text": "Definition 3.3 (Minimal suboptimality gap). For each $s\\in{\\mathcal{S}},a\\in{\\mathcal{A}}$ and step $h\\in[H]$ , the suboptimality gap $\\displaystyle{\\tt g a p}_{h}(s,a)$ is defined by $\\Delta_{h}(s,a)=V_{h}^{*}(s)-Q_{h}^{*}(s,a)$ and the minimal suboptimality gap $\\Delta$ is defined by $\\begin{array}{r}{\\Delta=\\operatorname*{min}_{h,s,a}\\left\\{\\Delta_{h}(s,a):\\Delta_{h}(s,a)\\neq0\\right\\}}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "1: Set $V_{H+1}^{k}(s)=0$ for all $(s,k)\\in\\mathcal{S}\\times[K],\\mathcal{C}_{h,l}^{k}=\\emptyset$ for all $(h,l)\\in[H]\\times\\mathbb{N}^{+},\\lambda=16$   \n2: for episode $k=1,\\cdots\\,,K$ do   \n3: Set $L_{k}=\\operatorname*{max}\\{\\lceil\\log_{4}(k/d)\\rceil,0\\}$   \n4: for step $h=H,\\cdots\\,,1$ do   \n5: for phase $l=1,\\cdot\\cdot\\cdot\\,,L_{k}+1\\,\\mathbf{do}$   \n6: $\\begin{array}{r}{\\mathbf{U}_{h,l}^{k}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\boldsymbol{\\phi}_{h}^{\\tau}(\\boldsymbol{\\phi}_{h}^{\\tau})^{\\top}}\\end{array}$   \n7: $\\begin{array}{r}{\\mathbf{w}_{h,l}^{k}=(\\mathbf{U}_{h,l}^{k})^{-1}\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big(r_{h}^{\\tau}+\\widehat{V}_{h+1}^{k}\\big(s_{h+1}^{\\tau}\\big)\\big)}\\end{array}$   \n8: $\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}=\\kappa_{l}\\big[(\\mathbf{U}_{h,l}^{k})^{-1}/\\kappa_{l}\\big],\\widetilde{\\mathbf{w}}_{h,l}^{k}=\\kappa_{l}\\big[\\mathbf{w}_{h,l}^{k}/\\kappa_{l}\\big]$ where $\\kappa_{l}=0.01\\cdot2^{-4l}d^{-1}$   \n9: end for   \n10: $\\widetilde{V}_{h}^{k}\\binom{\\times^{\\infty}}{s_{h}},\\cdot,\\cdot,\\cdot=\\mathtt{C e r t-L i n U C B}\\binom{s_{h}^{\\tau}}{s_{h}}\\{\\widetilde{\\mathbf{w}}_{h,l}^{k}\\}_{l},\\{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}\\}_{l},L_{k}\\}\\mathrm{~for~}l$ or all $\\tau\\in[k-1]$   \n11: end for   \n12: Observe $s_{1}^{k}\\in\\mathcal{S}$   \n13: for step $h=1,\\cdots\\,,H$ do   \n45 $\\begin{array}{r l}&{\\cdot,\\pi_{h}^{\\star}(s_{h}^{k}),l_{h}^{k}(s_{h}^{k}),f_{h}^{k}(s_{h}^{k})=\\mathsf{C e r t-L i n U C B}(s_{h}^{k};\\{\\widetilde{\\mathbf{w}}_{h,l}^{k}\\}_{l},\\{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}\\}_{l},L_{k})}\\\\ &{\\mathcal{C}_{h,l_{h}^{k}(s_{h}^{k})}^{k}=\\mathcal{C}_{h,l_{h}^{k}(s_{h}^{k})}^{k-1}\\cup\\{k\\}\\;\\;\\mathrm{if}\\;\\;f_{h}^{k}(s_{h}^{k})=1\\;\\,\\mathsf{e l s e}\\;\\;\\mathcal{C}_{h,l_{h}^{k}(s_{h}^{k})}^{k-1}}\\end{array}$   \n16: $\\mathcal{C}_{h,l}^{k}=\\mathcal{C}_{h,l}^{k-1}$ for all $l\\neq l_{h}^{k}(s_{h}^{k})$   \n17: Play $\\pi_{h}^{k}(s_{h}^{k})$ , set $\\phi_{h}^{k}=\\phi\\big(s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k})\\big)$ receive $r_{h}^{k}$ and observe $s_{h+1}^{k}\\in\\mathcal{S}$   \n18: end for   \n19: end for ", "page_idx": 4}, {"type": "text", "text": "Notably, a task with a larger $\\Delta$ means it is easier to distinguish the optimal action $\\pi_{h}^{*}(s)$ from other actions $a\\in A$ , while a task with lower gap $\\Delta$ means it is more difficult to distinguish the optimal action. ", "page_idx": 4}, {"type": "text", "text": "4  Proposed Algorithms ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "4.1 Main algorithm: Cert-LSVI-UCB ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We begin by introducing our main algorithm Cert-LSVI-UCB, which is a modification of the Sup-LsVI-UCB (Vial et al., 2022). As presented in Algorithm 1, for each episode $k$ , our algorithm maintains a series of index sets $\\mathcal{C}_{k,h}^{l}$ for each stage $\\textit{h}\\in\\ [H]$ and phase $l$ The algorithm design ensures that for any episode $k$ , the maximum number of phases $l$ is bounded by $L_{k}\\,\\le\\,\\operatorname*{max}\\{\\lceil\\log_{4}(k/d)\\rceil,0\\}$ . During the exploitation step, for each phase $l$ associated with the index set $\\mathcal{C}_{k-1,h}^{l}$ , the algorithm constructs the estimator vector $\\mathbf{w}_{h,l}^{k}$ by solving the following ridge regression problem in Line 6 and Line 7: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{w}_{h,l}^{k}\\leftarrow\\operatorname{argmin}_{\\mathbf{w}\\in\\mathbb{R}^{d}}\\lambda\\|\\mathbf{w}\\|_{2}^{2}+\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\big(\\mathbf{w}^{\\top}\\phi_{h}^{\\tau}-r_{h}^{\\tau}-\\widehat{V}_{h+1}^{k}\\big(s_{h+1}^{\\tau}\\big)\\big)^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Afer calculating the estimator vector $\\mathbf{w}_{h,l}^{k}$ in Line 8, the algorithm quantilizes $\\mathbf{w}_{h,l}^{k}$ and $(\\mathbf{U}_{h,l}^{k})^{-1}$ to the preson of $\\kappa_{l}$ $\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}$ isthe guanized version of inverse covariance matrix $(\\mathbf{U}_{h,l}^{k})^{-1}$ rather than the inverse of quantized covariance matrix $(\\widetilde{\\mathbf{U}}_{h,l}^{k})^{-1}$ . The main difference between our implementation and that in Vial et al. (2022) is that we use a layer-dependent quantification precision $\\kappa_{l}$ instead of the global quantification precision $\\kappa=2^{-4L}/\\dot{d}$ , which enables our algorithm get rid of the dependence on ${\\mathcal{O}}(\\log K)$ in the maximum number of phases $L_{k}$ ", "page_idx": 4}, {"type": "text", "text": "After btaing $\\widetilde{\\mathbf{w}}_{h,l}^{k}$ and $\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}$ value function $\\widehat{V}_{h}^{k}(s_{h}^{\\tau})$ for all historical states $s_{h}^{\\tau}$ in Line 10. Then the algorithm transits to stage $h-1$ and iterativly computes $\\widetilde{\\mathbf{w}}_{h,l}^{k}$ and $\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}$ for all phase $l$ and stage $h\\in[H]$ ", "page_idx": 4}, {"type": "text", "text": "In the exploration step, the algorithm starts to do planning from the initial state $s_{1}^{k}$ . For each observed state $s_{h}^{k}$ , the same subroutine, Cert-LinUCB, will be called in Line 14 for the policy $\\pi_{h}^{k}(s_{h}^{k})$ ,the ", "page_idx": 4}, {"type": "text", "text": "1: input: $\\begin{array}{r}{s\\in\\mathcal{S},\\forall l:\\widetilde{\\mathbf{w}}_{h,l}^{k}\\in\\mathbb{R}^{d},\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}\\in\\mathbb{R}^{d\\times d},L\\in\\mathbb{N}^{+}}\\end{array}$   \n2: output: $\\hat{V}_{h}^{k}(s)\\in\\mathbb{R},\\pi_{h}^{k}(s)\\in\\mathcal{A},l_{h}^{k}(s)\\in\\mathbb{N}^{+},f_{h}^{k}(s)\\in\\{0,1\\}$   \n3: $\\mathcal{A}_{h,1}^{k}(s)=\\mathcal{A},\\check{V}_{h,0}^{k}(s)=0,\\widehat{V}_{h,0}^{k}(s)=H$   \n4: for phase $l=1,\\cdot\\cdot\\cdot\\,,L+1\\,\\mathbf{d}$   \n5: Set $Q_{h,l}^{k}(s,a)=\\left\\langle\\phi(s,a),\\widetilde{\\mathbf{w}}_{h,l}^{k}\\right\\rangle$   \n6: Set $\\pi_{h,l}^{k}(s)=\\mathrm{argmax}_{a\\in{\\cal A}_{h,l}^{k}}Q_{h,l}^{k}(s,a),V_{h,l}^{k}(s)=Q_{h,l}^{k}\\bigl(s,\\pi_{h,l}^{k}(s)\\bigr)$   \n7: if $l>L$ then   \n8: return $\\widetilde{(V_{h}^{k}(s),\\pi_{h}^{k}(s),l_{h}^{k}(s),f_{h}^{k}(s))}=\\big(\\widehat{V}_{h,l-1}^{k}(s),\\pi_{h,l-1}^{k}(s),l,1\\big)$   \n9: else if $\\begin{array}{r}{\\gamma_{l}\\cdot\\operatorname*{max}_{a\\in{A_{h,l}^{k}(s)}}\\Vert\\phi(s,a)\\Vert_{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}}\\geq2^{-l}}\\end{array}$ then   \n10: return $\\begin{array}{r}{\\big(\\widehat{V}_{h}^{k}(s),\\pi_{h}^{k}(s),l_{h}^{k}(s),f_{h}^{k}(s)\\big)=\\big(\\widehat{V}_{h,l-1}^{k}(s),\\mathrm{argmax}_{a\\in\\mathcal{A}_{h,l}^{k}(s)}\\,\\|\\phi(s,a)\\|_{\\widetilde{\\mathbf{U}}_{h}^{k,-1}},l,1\\big)}\\end{array}$   \n11: else if max $:\\left\\{V_{h,l}^{k}(s)-3\\cdot2^{-l},\\breve{V}_{h,l-1}^{k}(s)\\right\\}>\\operatorname*{min}\\left\\{V_{h,l}^{k}(s)+3\\cdot2^{-l},\\widehat{V}_{h,l-1}^{k}(s)\\right\\}\\mathbf{then}$   \n12: return $\\left(\\widehat{V}_{h}^{k}(s),\\pi_{h}^{k}(s),l_{h}^{k}(s),f_{h}^{k}(s)\\right)=\\left(\\widehat{V}_{h,l-1}^{k}(s),\\pi_{h,l-1}^{k}(s),l,0\\right)$   \n13: else   \n14: $\\begin{array}{r l}&{\\overset{\\circ}{\\hat{V}}_{h,l}^{k}(s)=\\operatorname*{min}\\big\\{V_{h,l}^{k}(s)+3\\cdot2^{-l},\\widehat{V}_{h,l-1}^{k}(s)\\big\\}}\\\\ &{\\overset{\\vee}{V}_{h,l}^{k}(s)=\\operatorname*{max}\\big\\{V_{h,l}^{k}(s)-3\\cdot2^{-l},\\check{V}_{h,l-1}^{k}(s)\\big\\}}\\\\ &{\\overset{\\mathcal{A}_{h,l+1}^{k}(s)}{\\sim}\\big\\{a\\in\\mathcal{A}_{h,l}^{k}(s):Q_{h,l}^{k}(s,a)\\geq V_{h,l}^{k}(s)-4\\cdot2^{-l}\\big\\}}\\end{array}$   \n15:   \n16:   \n17. end if ", "page_idx": 5}, {"type": "text", "text": "corresponding phase $l_{h}^{k}(s_{h}^{k})$ , and a flag $f_{h}^{k}(s_{h}^{k})$ . If the flag $f_{h}^{k}(s_{h}^{k})=1$ , the algorithm adds the index $k$ to the index set Ch,(\\* inLn 15.thewise, the algoritm ss thecurrent index  adll index sets remain unchanged. Finally,the algorithm executes policy $\\pi_{h}^{k}(s_{h}^{k})$ , receives reward $r_{h}^{k}$ and observes the next state $s_{h+1}^{k}$ in Line 17. ", "page_idx": 5}, {"type": "text", "text": "4.2  Subroutine: Cert-LinUCB ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Next we introduce subroutine Cert-LinUCB, improved from Sup-Lin-UCB-Var (Vial et al., 2022) that computes the optimistic value function $\\widehat V_{h}^{k}$ . The algorithm is described as follows. Starting from phase $l=1$ , the algorithm first calculates the estimated state-action function $Q_{h,l}^{k}(s,a)$ as a linear function over the quantified parameter $\\widetilde{\\mathbf{w}}_{h,l}^{k}$ and feature mapping $\\phi(s,a)$ , following Proposition 3.2. After calculating the estimated state-action value function $Q_{h,l}^{k}(s)$ , the algorithm computes the greedy policy $\\pi_{h,l}^{k}(s)$ and its corresponding value function $V_{h,l}^{k}(s)$ ", "page_idx": 5}, {"type": "text", "text": "Similar to Sup-Lin-UCB-Var (Vial et al., 2022), our algorithm has several conditions starting from Line 7 to determine whether to stop at the current phase or to eliminate the actions and proceed to thenextphase $l+1$ , which are listed in the following conditions. ", "page_idx": 5}, {"type": "text", "text": "\u00b7 Condition 1: In Line 7, if the current phase $l$ is greater than the maximum phase $L$ , we directly stop at that phase and take the greedy policy on previous phase $\\pi_{h}^{k}(s)=\\pi_{h,l-1}^{k}(s)$ \u00b7 Condition 2: In Line 9, if there exists an action whose uncertainty $\\|\\phi(s,a)\\|_{\\widetilde{\\mathbf{U}}_{h,l}^{k.-1}}$ is greater than the threshold $2^{-l}\\gamma_{l}^{-1}$ , our algorithm willperform explorationby selecting that action. \u00b7 Condition 3: In Line 11, we compare the value of the pessimistic value function $\\check{V}_{h,l}^{k}(s)$ and the optimistic value function $\\widehat{V}_{h,l}^{k}(s)$ which will be assigned in Line 14 and Line 15, if the pessimistic estimation will be greater than the optimistic estimation, we will stop at that phase and take the greedy policy on previous phase $\\pi_{h}^{k}(s)=\\pi_{h,l-1}^{k}(s)$ . Only in this case, the Algorithm 2 outputs flag $f_{h}^{k}(s)=0$ , which means this observation will not be used in Line 15 in Algorithm 1. \u00b7 Condition 4: In the default case in Line 16, the algorithm proceeds to the next phase after eliminating actions. ", "page_idx": 5}, {"type": "text", "text": "Notably, in Condition 4, since the expected estimation precision in the $l$ -thphase is about $\\widetilde{\\mathcal{O}}(2^{-l})$ our algorithm can eliminate the actions whose state-action value is significantly less than others, i.e., less than $\\widetilde{\\mathcal{O}}(2^{-l})$ , while retaining the remaining actions for the next phase. ", "page_idx": 6}, {"type": "text", "text": "Specially, our algorithm differs from that in Vial et al. (2022) in terms of Condition 3 to certify the performance of the estimation. In particular, a well-behaved estimation should always guarantee that the optimistic estimation is greater than the pessimistic estimation. According to Line 14 and Line 15, this is equivalent to the confidence region for $l$ -th phase has intersection of the previous confidenceregion $[\\check{V}_{h,l-1}^{k}(s),\\widehat{V}_{h,l-1}^{k}(s)]$ Otherwise, we hypotesis the etimation on $l$ thphaseis corrupted by either misspecification or bad concentration event, thus will stop the algorithm. We will revisit the detail of this design later. ", "page_idx": 6}, {"type": "text", "text": "It's important to highlight that our algorithms provide unique approaches when compared with previous works. In particular, He et al. (2021b) does not eliminate actions and combines estimations from all layers by considering the minimum estimated optimistic value function. This characteristic prevents their algorithm from achieving a uniform PAC guarantee in the presence of misspecification. For a more detailed comparison with He et al. (2021b), please refer to Appendix B.1. Additionally, Lykouris et al. (2021); Wei et al. (2022) focus on a model-selection regime where a set of base learners are employed in the algorithms, whereas we adopt a multi-phase approach similar with SupLinUCB rather than conducting model selection over base learners. ", "page_idx": 6}, {"type": "text", "text": "5  Constant Regret Guarantee ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Theorem 5.1. Under Assumption 3.1, let $\\gamma_{l}\\;=\\;5(l\\,+\\,20\\,+\\,\\lceil\\log(l d)\\rceil)d H\\sqrt{\\log(16l d H/\\delta)}$ for some fixed $0\\:<\\:\\delta\\:<\\:1/4$ .With probability at least $1-4\\delta$ , if misspecification level $\\zeta$ is below $\\widetilde{\\cal O}\\big(\\Delta/(\\sqrt{d}H^{2})\\big)$ where $\\Delta$ is the minimal suboptimality gap, then for all $K\\,\\in\\,\\mathbb{N}^{+}$ , the regret of Algorithm 1 is upper bounded by ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Regret}(K)\\le\\widetilde{\\mathcal{O}}\\big(d^{3}H^{5}\\Delta^{-1}\\log(1/\\delta)\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "This regret bound is constant w.r.t. the episode $K$ ", "page_idx": 6}, {"type": "text", "text": "Theorem 5.1 demonstrates a constant regret bound with respect to number of episodes $K$ .Compared with Papini et al. (2021a), our regret bound does not require any prior assumption on the feature mapping $\\phi$ , such as the UniSOFT assumption made in Papini et al. (2021a). In addition, compared with the previous logarithmic regret bound He et al. (2021a) in the well-specified setting, our constant regret bound removes the $\\log K$ factor, indicating the cumulative regret no longer grows w.r.t. the number of episode $K$ , with high probability. ", "page_idx": 6}, {"type": "text", "text": "Remark 5.2. As discussed in Zhang et al. (2023b) in the misspecified linear bandits, Our high probability constant regret bound does not violate the lower bound proved in Papini et al. (2021a), which says that certain diversity condition on the contexts is necessary to achieve an expected constant regret bound. When extending this high probability constant regret bound to the expected regret bound,wehave ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\mathrm{Regret}(K)]\\leq\\tilde{\\mathcal{O}}\\big(d^{3}H^{5}\\Delta^{-1}\\log(1/\\delta)\\big)\\cdot(1-\\delta)+\\delta K,}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "which depends on the number of episodes $k$ . To obtain a sub-linear expected regret, we can choose $\\delta=1/K$ , which yields a logarithmic expected regret ${\\widetilde{\\mathcal{O}}}(d^{3}H^{5}\\Delta^{-1}\\log{K})$ and does not violate the lower bound in Papini et al. (2021a). ", "page_idx": 6}, {"type": "text", "text": "Remark 5.3. Du et al. (2019) provide a lower bound showing the interplay between the misspecification level $\\zeta$ and suboptimality gap $\\Delta$ in a weaker setting, which we discuss in detail in Appendix B.2. Along with the result from Du et al. (2019), our results suggests that ignoring the dependence on $H$ $\\dot{\\zeta}=\\widetilde{\\mathcal{O}}(\\Delta/\\sqrt{d})$ plays an important seperation for if a misspeficied model can be efficiently learned. This result is also aligned with the positive result and negative result for linear bandits (Lattimore et al., 2020; Zhang et al., 2023b). ", "page_idx": 6}, {"type": "text", "text": "6 Technical Challenges and Highlight of Proof Techniques ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we highlight several major challenges in obtaining the constant regret under misspecifed linear MDP assumption and how our method, especially the certified estimator, tackles these challenges. ", "page_idx": 6}, {"type": "text", "text": "6.1  Challenge 1. Achieving layer-wise local estimation error. ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In the analysis of the value function under misspecified linear MDPs, we follow the multi-phase estimation strategy (Vial et al., 2022) to eliminate suboptimal actions and improve the robustness of the next phase estimation. Similar approaches have been observed in Zhang et al. (2023b); Chu et al. (2011) within the framework of (misspecified) linear bandits. However, unlike linear bandits, when constructing the empirical value function $\\widehat{V}_{h}$ forstage $h$ in linear MDPs, Jin et al. (2020) requires a covering statement on value functions to ensure the convergence of the regression, which is written by: (see Lemma D.4 in Jin et al. (2020) for details) ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Big\\|\\sum_{\\tau\\in\\mathcal{C}}\\phi_{h}^{\\tau}\\big[\\widehat{V}_{h+1}^{k}(s^{\\tau})-\\mathbb{E}[\\widehat{V}_{h+1}^{k}(s^{\\tau})]\\big]\\Big\\|_{\\mathbf{U}_{h}^{-1}}\\leq\\widetilde{\\mathcal{O}}_{H}\\Big(\\sqrt{d\\log(|\\mathcal{C}|)+\\log(|\\mathcal{V}_{h+1}^{k}|/\\delta)}+\\sqrt{d}\\kappa\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where we employ notation $\\widetilde{\\mathcal{O}}_{H}$ to obscure the dependence on $H$ to simplify the presentation. We use the notation $\\bar{\\mathcal{V}}_{h+1}^{k}$ to denote as an $\\kappa$ -covering, (or quantification in Takemura et al. (2021); Vial et al. (2022) for the value functions $\\widehat V_{h+1}^{k}$ . However, in the multi-phase algorithm, the empirical value function $\\widehat V_{h+1}^{k}$ from the subsequent stage $h+1$ whichsngalf $\\big\\{\\mathbf{w}_{h,\\ell}^{k},\\mathbf{U}_{h,\\ell}^{k}\\big\\}_{\\ell}$ $L$ \u5496 $\\log|\\mathcal{V}_{h+1}^{k}|$ $L={\\mathcal{O}}(\\log K)$ ", "page_idx": 7}, {"type": "text", "text": "Therefore, when analyzing any single phase $l$ . prior analysis cannot eliminate the $\\log K$ term from (6.1) to achieve a local estimation error independent that is independent of the logarithmic number of global episodes $\\log K$ . Furthermore, due to the algorithm design of previous methods (Vial et al., 2022), additional $\\log K$ terms may be introduced by global quantification (i.e., $\\varepsilon_{t o l}=d/\\sqrt{K})$ ", "page_idx": 7}, {"type": "text", "text": "Our approach: Cert -LinUCB. To tackle this challenge, we introduce the certified estimator into Algorithm 2 and use a \u201clocal quantification\u2019 to ensure the quantification error of each phase $l$ depend on the local phase $\\ \\widetilde O(l)$ instead of the global parameter $\\log K$ . The certified estimator works as follows: Considering the concentration term we need to control for each phase $l$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k}}\\phi_{h}^{\\tau}\\big[\\widehat{V}_{h+1}^{k}(s^{\\tau})-\\mathbb{E}[\\widehat{V}_{h+1}^{k}(s^{\\tau})]\\big]\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "as discussed in Challenge 1, the function class $\\widehat{\\nu}_{h+1}^{k}\\ni\\widehat{V}_{h+1}^{k}$ involves $L={\\mathcal{O}}(\\log K)$ parameters, leading to a $\\log K$ dependence in the results when using traditional routines. The idea of certified estimator is to get rid of this by not directly controlling $\\log|\\nu_{h+1}^{k}|$ . Instead, certified estimator estabishesa ovrng statemen forthe valefunton clas $\\mathcal{V}_{h+1,l_{+}}^{k}\\ni\\widehat{V}_{h+1,l_{+}}^{k}$ where $\\widehat{V}_{h+1,l_{+}}^{k}$ isthe valuefunction that only incorporates the frst $l_{+}$ phases of parameters $\\left\\{\\mathbf{w}_{h,\\ell}^{k},\\mathbf{U}_{h,\\ell}^{k}\\right\\}_{\\ell}$ . Under this framework, the covering statement becomes: ", "page_idx": 7}, {"type": "text", "text": "Lemma 6.1 Lemma C4 infomal, Let $\\widehat{V}_{h+1,l_{+}}^{k}$ be theoupu of Agorthm termiaedat phase $l_{+}\\in\\mathbb{N}^{+}$ , then with probability is at least $1-2\\delta$ \uff0c ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\sum_{\\tau\\in{\\cal C}_{h,l}^{k}}\\!\\phi_{h}^{\\tau}\\!\\left[\\widehat{V}_{h+1,l_{+}}^{k}(s^{\\tau})-{\\mathbb E}[\\widehat{V}_{h+1,l_{+}}^{k}(s^{\\tau})]\\right]\\right\\|_{({\\mathbf{U}}_{h,l}^{k})^{-1}}\\leq\\gamma_{l,l_{+}}=5l_{+}d H\\sqrt{\\log(16l d H/\\delta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Lemma 6.1 suggests a concentration inequality_ at any phase $l_{+}$ , and the following lemma suggests that this procedure will only introduce an $\\widetilde{\\mathcal{O}}(2^{-l+})$ error, under some faithful extension of the $\\widehat{V}_{h,l_{+}}^{k}(s)$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathbf{Lemma~6.2\\,(Lemma~C.2,\\,informal).}\\,\\,\\,\\mathrm{For}\\,\\,\\mathrm{any}\\,\\,l_{+}\\in\\mathbb{N}^{+},\\,|\\widehat{V}_{h}^{k}(s)-\\widehat{V}_{h,l_{+}}^{k}(s)|\\leq6\\cdot2^{-l_{+}}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Therefore, if a large enough $l_{+}$ can be reached in Algorithm 2, combining Lemma 6.1 and Lemma 6.2 allow us to bound (6.2) without introducing $\\log K$ factors. The next lemma shows that the Line 11 will only never be triggered in shallow layer $l$ ", "page_idx": 7}, {"type": "text", "text": "Lemma 6.3 (Lemma C.8, informal). With probability at least $1-2\\delta$ ,for any $(k,h)\\in[K]\\times[H].$ Line 11 in Algorithm 2 can only be triggered on phase $l\\ge\\widetilde\\Omega\\big(\\log(1/\\zeta)\\big)$ ", "page_idx": 7}, {"type": "text", "text": "Lemma 6.3 delivers a clear message: In the well-specified setting, Line 11 will never be triggered $(l\\,\\geq\\,\\infty)$ .When the misspecification level is large, then Line 11 will be more likely triggered, indicating it's harder for the algorithm to proceed to deeper layer. The contribution of the certified estimator yields the following important lemma regarding the \u201clocal estimation error': ", "page_idx": 8}, {"type": "text", "text": "Lemma 6.4 (Lemma C.12, Informal). With high probability, for any $\\varepsilon>\\widetilde\\Omega(\\sqrt{d}H^{2}\\zeta)$ and $h\\in[H]$ Cert-LSVI-UCB ensures $\\begin{array}{r}{\\sum_{k=1}^{\\infty}\\mathbb{1}\\left[V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\geq\\varepsilon\\right]\\leq\\widetilde{\\mathcal{O}}\\big(d^{3}H^{4}\\varepsilon^{-2}\\big)}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "Remark 6.5. He et al. (2021b) achieved a similar $O\\big(d^{3}H^{5}\\varepsilon^{-2}\\big)$ uniform- $P A C$ bound for (wellspecified) linear MDP. Comparing with Lemma 6.4 with $\\zeta=0$ , one can find that our result is better than He et al. (2021b). In addition, Lemma 6.4 ensures this uniform- $P A C$ result under all stage $h\\in[H]$ while He et al. (2021b) only ensure the $h=1$ . This improvement is achieved by a more efficient data selection strategy which we will discuss in detail in Appendix B.1. ", "page_idx": 8}, {"type": "text", "text": "6.2 Challenge 2. Achieving constant regret from local estimation error ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In misspecified linear bandits, Zhang et al. (2023b) concludes their proof by controlling $\\begin{array}{r}{\\sum_{k=1}^{\\infty}\\mathbb{1}\\dot{[}V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi}(s_{1}^{k})\\,\\geq\\,\\Delta]^{4}}\\end{array}$ . Although it is trivial showing that rounds with instantaneous regret $V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi}(s_{1}^{k})<\\Delta$ is optimal in bandits (i.e., $V_{1}^{*}(s_{1}^{k})=V_{1}^{\\pi}(s_{1}^{k}))$ , previous works fail to reach a similar result for RL settings. This difficulty arises from the randomness inherent in MDPs: Consider a policy $\\pi$ that is optimal at the initial stage $h=1$ . After the initial state and action, the MDP may transition to a state $s_{2}^{\\prime}$ with a small probability $p$ where the policy $\\pi$ is no longer optimal, or to another state $s_{2}$ where $\\pi$ remains optimal until the end. In this context, the gap between $V_{1}^{*}(s_{1})$ and $V_{1}^{\\pi}(s_{1})$ can be arbitrarily small, given a sufficiently small $p>0$ ", "page_idx": 8}, {"type": "text", "text": "$\\begin{array}{r}{\\gamma_{1}^{*}(s_{1})-V_{1}^{\\pi}(s_{1})=p\\big(V_{2}^{*}(s_{2}^{\\prime})-V_{2}^{\\pi}(s_{2}^{\\prime})\\big)+(1-p)\\big(V_{2}^{*}(s_{2})-V_{2}^{\\pi}(s_{2})\\big)=p\\big(V_{2}^{*}(s_{2}^{\\prime})-V_{2}^{\\pi}(s_{2}^{\\prime})\\big).}\\end{array}$ Therefore, one cannot easily draw a constant regret conclusion simply by controlling $\\begin{array}{r l}{\\sum_{k=1}^{\\infty}\\mathbb{1}[V_{1}^{*}(s_{1}^{k})\\,-\\,V_{1}^{\\pi}(s_{1}^{k})\\ \\stackrel{\\cdot}{\\geq}\\ \\Delta]}\\end{array}$ since the gap between $V_{1}^{*}(s_{1}^{k})\\,-\\,V_{1}^{\\pi}(s_{1}^{\\hbar})$ needs to be further fine-grained controlled. In short, the existence of $\\Delta$ describing the minimal gap between $V^{*}(s)-\\bar{Q}^{*}(s,a)$ cannot be easily applied to controlling regret $V^{*}(s)\\bar{-}\\,V^{\\pi}(s)$ ", "page_idx": 8}, {"type": "text", "text": "Our approach: A fine-grained concentration analysis  We address this challenge by providing a fine-grained concentration analysis in connecting the gap with the regret. Notice that the regret $V_{h}^{*}(s_{h})-V_{h}^{\\pi^{k}}(s_{h})$ in episode $k$ is the expectation of cumulative suboptimality gap $\\mathbb{E}[\\sum_{h=1}^{H}\\Delta_{h}^{k}]$ taking over trajectory $\\{s_{h}^{k}\\}_{h=1}^{H}$ In addition, thevariance of thrandmariable cane selfbd according to ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Var}\\left[\\sum_{h=1}^{H}\\Delta_{h}^{k}\\right]\\leq\\mathbb{E}\\left[\\left(\\sum_{h=1}^{H}\\Delta_{h}^{k}\\right)^{2}\\right]\\leq H^{2}\\,\\mathbb{E}\\left[\\sum_{h=1}^{H}\\Delta_{h}^{k}\\right]=H^{2}\\big(V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi^{k}}(s_{1}^{k})\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Denote $\\eta_{k}$ be the diference betwen $V_{h}^{*}(s_{h})-V_{h}^{\\pi^{k}}(s_{h})$ and the actual $\\sum_{h=1}^{H}\\Delta_{h}^{k}$ . Freedman inequality (Lemma H.5) implies that $\\begin{array}{r}{\\sum_{t=1}^{T}\\eta^{t}\\,\\geq\\,a C}\\end{array}$ and $\\begin{array}{r}{\\sum_{t=1}^{T}\\operatorname{Var}[\\eta^{t}]\\,\\leq\\,v\\dot{C}}\\end{array}$ happensat the same with a small probability for certain constant $a$ and $v$ . Using a fine-grained union bound statement over $C$ , we can reach the following statement indicates the cumulative regret can be upper bounded using the cumulative suboptimality gap: ", "page_idx": 8}, {"type": "text", "text": "Lemma 6.6 (Lemma C.14, Informal). The following statement holds with high probability: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sum_{k=1}^{K}\\bigl(V_{h}^{*}(s_{h})-V_{h}^{\\pi^{k}}(s_{h})\\bigr)\\leq\\tilde{\\mathcal{O}}\\Bigl(\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+H^{2}\\Bigr).}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Comparing with Lemma 6.1 in He et al. (2021a), Lemma 6.6 eliminates the $\\log K$ dependence, which is achieved by the aforementioned fine-grained union bound. As a result, together with Lemma 6.4, we reach the desired statement that Cert-LsVI-UCB achieves constant regret bound when the misspecification is sufficiently small against the minimal suboptimality gap. ", "page_idx": 8}, {"type": "text", "text": "7  Conclusions and Limitations ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this work, we proposed a new algorithm, called certified estimator, for reinforcement learning with a misspecified linear function approximation. Our algorithm is parameter-free and does not require prior knowledge of misspecification level $\\zeta$ or the suboptimality $\\Delta$ . Our algorithm is based on a novel certified estimator and provides the first constant regret guarantee for misspecified linear MDPs and (well-specified) linear MDPs. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Limitations. Despite these advancements, several aspects of our algorithm and analysis warrant further investigation. One significant open question is whether the dependency on the planning horizon and dimension $d,H$ can achieve optimal instance-dependent regret bounds. For the gapindependent regret bounds, the regret lower bound is $\\Omega(d{\\sqrt{H^{3}K}})$ as shown by Zhou et al. (2021a), and this benchmark has recently been met by works such as He et al. (2022a); Agarwal et al. (2022). Additionally, our analysis assumes uniform misspecification across all actions. Investigating other types of misspecifications could lead to more sophisticated results, enhancing the algorithm's robustness and applicability to diverse real-world scenarios. This exploration remains an important direction for future research. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We thank the anonymous reviewers for their helpful comments. This work was done while WZ was a PhD student at UCLA. WZ is partially supported by UCLA dissertation year fellowship and the research fund from UCLA-Amazon Science Hub. JH and QG are partially supported by the research fund from UCLA-Amazon Science Hub. The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "ABBASI-YADKORI, Y., PAL, D. and SZEPESVARI, C. (2011). Improved algorithms for linear stochastic bandits. Advances in neural information processing systems 24 2312-2320.   \nAGARWAL, A., JIN, Y. and ZHANG, T. (2022). Vo ql: Towards optimal regret in model-free rl with nonlinear function approximation. arXiv preprint arXiv:2212.06069 .   \nAYOUB, A., JIA, Z., SZEPESVARI, C., WANG, M. and YANG, L. (202O). Model-based reinforcement learning with value-targeted regression. In International Conference on Machine Learning. PMLR.   \nCESA-BIANCHI, N. and LUGOSI, G. (2006). Prediction, learning, and games. Cambridge university press.   \nCHU, W., LI1, L., REYZIN, L. and SCHAPIRE, R. (2011). Contextual bandits with linear payoff functions. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics. JMLR Workshop and Conference Proceedings.   \nDANN, C., MARINOV, T. V., MOHRI, M. and ZIMMERT, J. (2021). Beyond value-function gaps: Improved instance-dependent regret bounds for episodic reinforcement learning. Advances in Neural Information Processing Systems 34.   \nDU, S. S., KAKADE, S. M., WANG, R. and YANG, L. F. (2019). Is a good representation sufficient for sample efficient reinforcement learning? In International Conference on Learning Representations.   \nHAO, B., LATTIMORE, T. and SZEPESVARI, C. (2020). Adaptive exploration in linear contextual bandit. In International Conference on Artificial Intelligence and Statistics. PMLR.   \nHE, J., ZHAO, H., ZHOU, D. and GU, Q. (2022a). Nearly minimax optimal reinforcement learning for linear markov decision processes. arXiv preprint arXiv:2212.06132 .   \nHE, J., ZHOU, D. and GU, Q. (2021a). Logarithmic regret for reinforcement learning with linear function approximation. In International Conference on Machine Learning. PMLR.   \nHE, J., ZHOU, D. and GU, Q. (2021b). Uniform-PAC bounds for reinforcement learning with linear function approximation. In Advances in Neural Information Processing Systems. ", "page_idx": 9}, {"type": "text", "text": "HE, J., ZHOU, D., ZHANG, T. and GU, Q. (2022b). Nearly optimal algorithms for linear contextual bandits with adversarial corruptions. In Advances in Neural Information Processing Systems. ", "page_idx": 10}, {"type": "text", "text": "HOEFFDING, W. (1963). Probability inequalities for sum of bounded random variables. ", "page_idx": 10}, {"type": "text", "text": "ISHFAQ, H., CUI, Q., NGUYEN, V., AYOUB, A., YANG, Z., WANG, Z., PRECUP, D. and YANG, L. (2021). Randomized exploration in reinforcement learning with general value function approximation. In International Conference on Machine Learning. PMLR.   \nJAKSCH, T., ORTNER, R. and AUER, P. (2010). Near-optimal regret bounds for reinforcement learning. Journal of Machine Learning Research 11.   \nJIA, Z., YANG, L., SZEPEsVARI, C. and WANG, M. (2020). Model-based reinforcement learning with value-targeted regression. In Learning for Dynamics and Control. PMLR.   \nJIN, C., YANG, Z., WANG, Z. and JoRDAN, M. I. (2020). Provably effcient reinforcement learning with linear function approximation. In Conference on Learning Theory. PMLR.   \nKOBER, J., BAGNELL, J. A. and PETERs, J. (2013). Reinforcement learning in robotics: A survey. The International Journal of Robotics Research 32 1238-1274.   \nLATTIMORE, T., SZEPESVARI, C. and WEISZ, G. (2020). Learning with good feature representations in bandits and in rl with a generative model. In International Conference on Machine Learning. PMLR.   \nLYKOURIS, T., SIMCHOWITZ, M., SLIVKINS, A. and SUN, W. (2021). Corruption-robust exploration in episodic reinforcement learning. In Conference on Learning Theory. PMLR.   \nMNIH, V., KAvUkCUOGLu, K., SILVER, D., GRAVEs, A., ANTONOGLOU, I., WIERSTRA, D. and RIEDMILLER, M. (2013). Playing atari with deep reinforcement learning. arXiv preprint arXiv: 1312.5602 .   \nMODI, A., JIANG, N., TEWARI, A. and SINGH, S. (2020). Sample complexity of reinforcement learning using linearly combined model ensembles. In International Conference on Artificial Intelligence and Statistics.   \nPAPINI, M., TIRINZONI, A., PACCHIANO, A., RESTELLI, M., LAZARIC, A. and PIROTTA, M. (2021a). Reinforcement learning in linear mdps: Constant regret and representation selection. Advances in Neural Information Processing Systems 34 16371-16383.   \nPAPINI, M., TIRINZONI, A., RESTELLI, M., LAZARIC, A. and PIROTTA, M. (2021b). Leveraging good representations in linear contextual bandits. In International Conference on Machine Learning. PMLR.   \nSIMCHOWITZ, M. and JAMIESON, K. G. (2019). Non-asymptotic gap-dependent regret bounds for tabular mdps. Advances in Neural Information Processing Systems 32 1153-1162.   \nTAKEMURA, K., ITO, S., HATANO, D., SUMITA, H., FUKUNAGA, T., KAKIMURA, N. and KAWARABAYASHI, K.-1. (2021). A parameter-free algorithm for misspecified linear contextual bandits. In International Conference on Artificial Intelligence and Statistics. PMLR.   \nVIAL, D., PARULEKAR, A., SHAKKOTTA1, S. and SRIKANT, R. (2022). Improved algorithms for misspecified linear markov decision processes. In International Conference on Artificial Intelligence and Statistics. PMLR.   \nWANG, Y, WANG, R., DU, S. S. and KRISHNAMURTHY, A. (2019). Optimism in reinforcement learning with generalized linear function approximation. In International Conference on Learning Representations.   \nWEI, C.-Y., DANN, C. and ZIMMERT, J. (2022). A model selection approach for corruption robust reinforcement learning. In International Conference on Algorithmic Learning Theory. PMLR.   \nYANG, K., YANG, L. and DU, S. (2021). Q-learning with logarithmic regret. In International Conference on Artificial Intelligence and Statistics. PMLR. ", "page_idx": 10}, {"type": "text", "text": "YANG, L. and WANG, M. (2020). Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound. In International Conference on Machine Learning. PMLR. ", "page_idx": 11}, {"type": "text", "text": "ZANETTE, A.,BRANDFONBRENER, D., BRUNSKILL,E., PIROTTA, M. and LAZARIC, A. (2020a). Frequentist regret bounds for randomized least-squares value iteration. In International Conference on Artificial Intelligence and Statistics.   \nZANETTE, A., LAZARIC, A., KOCHENDERFER, M. and BRUNSKILL, E. (2020b). Learning near optimal policies with low inherent bellman error. In International Conference on Machine Learning.PMLR.   \nZHANG, W., HE, J., FAN, Z. and GU, Q. (2023a). On the interplay between misspecification and sub-optimality gap: From linear contextual bandits to linear MDPs.   \nZHANG, W., HE, J., FAN, Z. and GU, Q. (2023b). On the interplay between misspecification and sub-optimality gap in linear contextual bandits. arXiv preprint arXiv:2303.09390 .   \nZHANG, W., HE, J., ZHOU, D., ZHANG, A. and GU, Q. (2021). Provably efficient representation learning in low-rank markov decision processes. arXiv preprint arXiv:2106.11935 .   \nZHOU, D., GU, Q. and SZEPESVARI, C. (2021a). Nearly minimax optimal reinforcement learning for linear mixture markov decision processes. In Conference on Learning Theory. PMLR.   \nZHOU, D., HE, J. and GU, Q. (2021b). Provably efficient reinforcement learning for discounted mdps with feature mapping. In International Conference on Machine Learning. PMLR. ", "page_idx": 11}, {"type": "text", "text": "A Additional Related Work ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "RL with linear function approximation.  Recent years have witnessed a line of work focusing on RL with linear function approximation to tackle RL tasks in large state space. A widely studied MDP model is linear MDP (Jin et al., 2020), where both the transition kernel and the reward function are linear functions of a given feature mapping of the state-action pairs $\\phi(s,a)$ .Several works have developed RL algorithms with polynomial sample complexity or sublinear regret bound in this setting. For example, LSVI-UCB (Jin et al., 2020) has an $\\tilde{\\tilde{O}}(\\sqrt{d^{3}H^{4}K})$ regret bound, randomized LSVI (Zanette et al., 2020a) has an $\\widetilde{\\mathcal{O}}(\\sqrt{d^{4}H^{5}K})$ regret bound and Ishfaq et al. (2021) achieved an $\\widetilde{\\cal O}(\\sqrt{d^{3}H^{4}K})$ He et al. (2022a) then improves this regret bound to a nearly minimax-optimal result $\\widetilde{\\cal O}(d\\sqrt{H^{3}K})$ while Agarwal et al. (2022) provides a general function approximation extension given the above result. Linear mixture/kernel MDPs (Modi et al., 2020; Jia et al., 2020; Ayoub et al., 2020; Zhou et al., 2021b) have also emerged as another model that enables model-based RL with linear function approximation. In this setting, the transition kernel is a linear function of a feature mapping on the triplet of state, action, and next state $\\phi(s,a,s^{\\prime})$ . Nearly minimax optimal regrets can be achieved for both finite-horizon episodic MDPs (Ayoub et al., 2020; Zhou et al., 2021a) and infinite-horizon discounted MDPs (Zhou et al., 2021b) under this assumption. ", "page_idx": 11}, {"type": "text", "text": "B  Additional Discussions on Algorithm Design and Result ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "B.1 Comparison with He et al. (2021b) ", "text_level": 1, "page_idx": 11}, {"type": "text", "text": "It is worth comparing our algorithm with He et al. (2021b), which also provides a uniform PAC bound for linear MDPs. Both our algorithm and theirs utilize a multi-phase structure that maintains multiple regression-based value function estimators at different phases. Despite this similarity, there are several major differences between our algorithm and that in He et al. (2021b), which are highlighted as follows: ", "page_idx": 11}, {"type": "text", "text": "(1) In Line 7 of Algorithm 1, when calculating the regression-based estimator, for different phase $l$ we use the same regression target $\\widehat V_{h+1}^{k}$ while their algorithm uses diferent Vh+1,p for different phase $l$ ", "page_idx": 11}, {"type": "text", "text": "(2) When aggregating the regression estimators over all different $L_{k}$ phases, we follow the arm elimination method as in Chu et al. (2011), while He et al. (2021b) simply take the point-wise minimum of all estimated state-action functions, i.e., $\\begin{array}{r}{Q(s,a)=\\operatorname*{min}_{l\\in[L_{k}]}\\mathbf{\\dot{Q}}_{k,h}^{l}(s,a)}\\end{array}$ ", "page_idx": 11}, {"type": "text", "text": "(3) Whencalulaingthephase $l_{h}^{k}(s_{h}^{k})$ for rajetory $s_{1}^{k},s_{2}^{k},\\cdots,s_{H}^{k}$ He et al. (21b rquire that the phase $l_{h}^{k}(s_{h}^{k})$ to be monotonically decreasing with respect to the stage $h$ i.e., $l_{h}^{k}(s_{h}^{k})\\leq$ $l_{h-1}^{k}(s_{h-1}^{k})$ (see line 19 in Algorithm 2 in He et al. (2021b)). Such a requirement will lead to a poor estimation for later stages and thus increase the sample complexity. In contrast, we do not have this requirement or any other requirements related to $l_{h}^{k}(s_{h}^{k})$ and $l_{h-1}^{\\tilde{k}}(s_{h-1}^{k})$ ", "page_idx": 12}, {"type": "text", "text": "As a result, by (3), He et al. (2021b) have to sacrifice some sample complexity to make their algorithm work for different target value funetions $V_{h+1,l}^{k}$ As a comparison, since we use the same regression target for different phase $l$ , we do not have to make such a sacrifice in (3). Moreover, by (2), He et al. (2021b) cannot deal with linear MDPs with misspecification, while our algorithm can handle misspecification as in Vial et al. (2022). ", "page_idx": 12}, {"type": "text", "text": "B.2Discussion on Lower Bounds of Sample Complexity ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "We present a lower bound from Du et al. (2019) to better illustrate the interplay between the misspecification level $\\zeta$ and the suboptimality gap $\\Delta$ ", "page_idx": 12}, {"type": "text", "text": "Assumption B.1 (Assumption 4.3, Du et al. 2019, $\\zeta$ -Approximate Linear MDP). There exists $\\zeta>$ $),\\pmb{\\theta}_{h}\\in\\bar{\\mathbb{R}}^{d}$ and $\\mu_{h}:S\\stackrel{}{\\mapsto}\\mathbb{R}^{d}$ for each stage $h\\in[H]$ such that for any $(s,a,s^{\\prime})\\in\\mathcal S\\times\\mathcal A\\times\\mathcal S$ we have $\\left|\\mathbb{P}_{h}(s^{\\prime}|s,a)-\\langle\\phi(s,a),\\pmb{\\mu}_{h}(s^{\\prime})\\rangle\\right|\\leq\\zeta$ and $\\left|r(s,a)-\\langle\\phi(s,a),\\pmb\\theta_{h}\\rangle\\right|\\leq\\zeta$ ", "page_idx": 12}, {"type": "text", "text": "Theorem B.2 (Theorem 4.2, Du et al. 2019). There exists a family of hard-to-learn linear MDPs with action space $|{\\mathcal{A}}|\\;=\\;2$ and a feature mapping $\\phi(s,a)$ satisfying Assumption B.1, such that for any algorithm that returns a $1/2$ -optimal policy with probability 0.9 needs to sample at least $\\Omega(\\operatorname*{min}\\{|{\\check{S}}|,2^{H},\\exp(d\\zeta^{2}/16)\\})$ episodes. ", "page_idx": 12}, {"type": "text", "text": "Remark B.3. As claimed in Du et al. (2019), Theorem B.2 suggests that when misspecification in the $\\ell_{\\infty}$ norm satisfies $\\zeta=\\Omega(\\Delta\\sqrt{H/d})$ , the agent needs an exponential number of episodes to find a near-optimal policy, where $\\Delta=1/2$ in their setting. It is worth noting that Assumption B.1 is a $\\ell_{\\infty}$ approximation for the transition matrix. Such a $\\ell_{\\infty}$ guarantee ${\\left\\|\\cdot\\right\\|}\\infty\\leq\\zeta)$ is weaker than the $\\ell_{1}$ guarantee $(\\|\\cdot\\|_{1}\\leq\\zeta)$ provided in Assumption 3.1. So it's natural to observe a positive result when making a stronger assumption and a negative result when making a weaker assumption. In addition, despite of this difference, one could find that $\\zeta\\sim\\Delta/\\sqrt{d}$ plays a vital role in determining if the task can be efficiently learned. Similar positive and negative results are also provided in Lattimore et al. (2020); Zhang et al. (2023b) in the linear contextual bandit setting (a special case of linear MDP with $H=1$ ", "page_idx": 12}, {"type": "text", "text": "C Constant Regret Guarantees for Cert-LsVI-UCB ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "In this section, we present the proof of Theorem 5.1. To begin with, we recap the notations used in the algorithm and introduce several shorthand notations that would be employed for the simplicity of latter proof. The notation table is presented in Table 2.Any proofs not included in this section are deferred to Appendix D. ", "page_idx": 12}, {"type": "text", "text": "C.1Quantized State Value Function set $\\mathcal{V}_{h,l}^{k}$ ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "To begin our proof, we first extend the definition of $\\widehat{V}_{h,l}^{k}$ to arbtrary $l$ and give a formal definition of the state value function class $\\mathcal{V}_{h,l}^{k}$ as we skip the detail of this definition in Section 6. ", "page_idx": 12}, {"type": "text", "text": "Definition C.1. We extend the defnition of state value function $\\widehat{V}_{h,l}^{k}$ to any tuple $(k,h,l)\\in[K]\\times$ $[H]\\times\\mathbb{N}^{+}$ by ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\widehat{V}_{h,l}^{k},\\cdot,\\cdot,\\cdot=\\mathtt{C e r t-L i n U C B}\\big(s;\\{\\widetilde{\\mathbf{w}}_{h,\\ell}^{k}\\}_{\\ell=1}^{l},\\{\\widetilde{\\mathbf{U}}_{h,\\ell}^{k,-1}\\}_{\\ell=1}^{l},l\\big)\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "We also define the state value function family $\\mathcal{V}_{h,l}^{k}$ be the set of all possible $\\widehat{V}_{h,l}^{k}$ ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\mathcal{V}_{h,l}^{k}=\\left\\{\\widehat{V}_{h,l}^{k}\\;\\Big|\\;\\widehat{V}_{h,l}^{k},\\cdot,\\cdot,\\cdot=\\mathtt{C e r t-L i n U C B}\\big(s;\\{\\widetilde{\\mathbf{w}}_{\\cdot,\\ell}^{\\cdot}\\}_{\\ell=1}^{l},\\{\\widetilde{\\mathbf{U}}_{\\cdot,\\ell}^{\\cdot,-1}\\}_{\\ell=1}^{l},l\\big)\\right\\}\n$$", "text_format": "latex", "page_idx": 12}, {"type": "text", "text": "where $\\{\\widetilde{\\mathbf{w}}_{\\cdot,\\ell}\\}_{\\ell=1}^{l}$ and $\\{\\widetilde{\\mathbf{U}}_{\\cdot,\\ell}^{\\cdot,-1}\\}_{\\ell=1}^{l}$ are referring to any possible parameters generated by Line 8 in Algorithm 1. ", "page_idx": 12}, {"type": "table", "img_path": "02r24A8doi/tmp/40073e15bf20650fec54f4ce444e90998817d17c6696085c7bdb56fb52012e37.jpg", "table_caption": [], "table_footnote": ["Table 2: Notations used in algorithm and proof "], "page_idx": 13}, {"type": "text", "text": "It is worth noting that one can check the defnition of $\\widehat{V}_{h,l}^{k}$ here is consistent with those computed in Algorithm 2 with $l\\;<\\;l_{h}^{k}(s)$ . Therefore, we will not distinguish between the notations in the remainder of the proof. ", "page_idx": 13}, {"type": "text", "text": "The following lemma controls the distance between $\\widehat{V}_{h}^{k}(s)$ and $\\widehat{V}_{h,l}^{k}(s)$ for any phase $l$ ", "page_idx": 13}, {"type": "text", "text": "Lemma C.2. For any $(k,h,s)\\in[K]\\times[H]\\times{\\mathcal{S}},l\\in[l_{h}^{k}(s)-1]$ , it holds that ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\check{V}_{h,l}^{k}(s)\\leq\\widehat{V}_{h}^{k}(s)\\leq\\widehat{V}_{h,l}^{k}(s),\\quad|\\widehat{V}_{h}^{k}(s)-\\widehat{V}_{h,l}^{k}(s)|\\leq6\\cdot2^{-l}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Moreover, for any tuple $(k,h,s,l_{+})\\,\\in\\,[K]\\,\\times\\,[H]\\,\\times\\,\\mathcal{S}\\times\\mathbb{N}^{+}$ the difference $|\\widehat{V}_{h}^{k}(s)-\\widehat{V}_{h,l_{+}}^{k}(s)|$ is bounded by $6\\cdot2^{-l_{+}}$ , following the extension of the definition scope of Vk,l as outlined in Definition C.1. ", "page_idx": 13}, {"type": "text", "text": "Lemma C.2 suggests that given any phase $l_{+}$ \uff0c $\\widehat{V}_{h,l}^{k}$ is close to $\\widehat V_{h}^{k}$ .This enables us to construct covering on $\\widehat V_{h}^{k}$ using the covering on $\\widehat{V}_{h,l}^{k}$ ", "page_idx": 13}, {"type": "text", "text": "C.2 Concentration of State Value Function $\\widehat{V}_{h}^{k}(s)$ ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "In this subsection, we provide a new analysis for bounding the self-normalized concentration of $\\begin{array}{r l}&{\\Big|\\Big|\\sum_{\\tau}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}\\widehat{V}_{h}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat{V}_{h}^{k}(s_{h+1}^{\\tau})\\big)\\Big|\\Big|_{\\mathbf{U}^{-1}}}\\end{array}$ to getrid of the $\\log k$ factor in Vial et al. (2022). ", "page_idx": 13}, {"type": "text", "text": "$\\begin{array}{r}{\\mathcal{F}_{h}^{k}=\\Big\\{\\{s_{i}^{j},a_{i}^{j}\\}_{i=1,j=1}^{H,k-1},\\{s_{i}^{k},a_{i}^{k}\\}_{i=1}^{h}\\Big\\}.}\\end{array}$ Itis asy to verify that $s_{h}^{k},a_{h}^{k}$ are both $\\mathcal{F}_{h}^{k}$ -measurable. Also, for any function $V$ built on $\\mathcal{F}_{h}^{k}$ \uff0c $[\\mathbb{P}_{h}\\dot{V}](s_{h}^{k},a_{h}^{k})-$ $V(s_{h+1}^{k})$ $\\mathcal{F}_{h+1}^{k}$ measrabledsermaramaiabni $\\mathcal{F}_{h}^{k}$ ", "page_idx": 14}, {"type": "text", "text": "The first lemma we provide is similar with Vial et al. (2022), which shows the self-normalized concentration proprtyfreachphase $l$ andanyfunction $V\\in\\mathcal{V}_{h,l}^{k}$ ", "page_idx": 14}, {"type": "text", "text": "Definition C.3. For some fixed mapping $l\\mapsto l_{+}=l_{+}(l)$ that $l_{+}\\geq l$ , we define the bad event as ", "page_idx": 14}, {"type": "equation", "text": "$$\nB_{1}(k,h,l,V)=\\left\\{\\left\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}V](s_{h}^{\\tau},a_{h}^{\\tau})-V(s_{h+1}^{\\tau})\\big)\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}>\\gamma_{l,l_{+}}\\right\\}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "The good event is defined by $\\begin{array}{r}{\\mathcal{G}_{1}\\,=\\,\\bigcap_{k=1}^{K}\\bigcap_{h=1}^{H}\\bigcap_{l\\geq1}\\bigcap_{V\\in\\mathcal{V}_{h,l_{+}}^{k}}\\mathcal{B}_{1}^{\\complement}(k,h,l,V)}\\end{array}$ where we define $\\gamma_{l,l_{+}}=5l_{+}d H\\sqrt{\\log(16l d H/\\delta)}=\\widetilde{\\mathcal{O}}(l d H\\log(\\delta^{-1}))$ ", "page_idx": 14}, {"type": "text", "text": "Lemma C.4. The good event $\\mathcal{G}_{1}$ defined in Definition C.3 happens with probability at least $1-2\\delta$ ", "page_idx": 14}, {"type": "text", "text": "Lemma C.4 establishes the concentration bounds for any given phase $l$ . However, the total number of phases for the state value function $V_{h}^{k}(s)$ can be bounded only trivially $\\mathsf{b y}l=\\mathcal O(\\log K)$ , resulting in $\\log K$ dependence. To address this issue, the following lemma proposes a method to eliminate this logarithmic factor: ", "page_idx": 14}, {"type": "text", "text": "Lemma C.5. Under event $\\mathcal{G}_{1}$ , for any $(k,h,l)\\in[K]\\times[H]\\times\\mathbb{N}^{+},$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat{V}_{h+1}^{k}(s_{h+1}^{\\tau})\\big)\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq1.1\\gamma_{l}.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where we set $\\gamma_{l}=\\gamma_{l,l_{+}}$ with $l_{+}=l+20+\\lceil\\log(l d)\\rceil$ ", "page_idx": 14}, {"type": "text", "text": "Then Lemma C.5 immediately yields the following lemma regarding the estimation error of the state-actionvaluefunction $Q_{h,l}^{k^{\\star}}$ ", "page_idx": 14}, {"type": "text", "text": "Lemma C.6. Under event $\\mathcal{G}_{1}$ , for any $(k,h,s)\\in[K]\\times[H]\\times{\\cal{S}},l\\in[l_{h}^{k}(s)-f_{h}^{k}(s)],a_{l}\\in{\\cal{A}}_{h,l}^{k}(s),$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\bigl|Q_{h,l}^{k}(s,a)-\\bigl[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}\\bigr](s,a)\\bigr|\\leq2\\cdot2^{-l}+\\chi\\sqrt{l}\\zeta\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where we define $\\chi=12\\sqrt{d}H$ ", "page_idx": 14}, {"type": "text", "text": "Lemma C.6 build an estimation error for any $l\\in[l_{h}^{k}(s)-1]$ . As we mentioned in the algorithm design, a larger $l$ here will lead to more precise estimation (a smaller $2^{-l}$ term in (C.2)) but will suffer from a larger covering number (a larger $\\gamma_{l}$ term in (C.2)). Following a similar proof sketch from Vial et al. (2022), the next lemma shows that any action that is not eliminated has a low regret, ", "page_idx": 14}, {"type": "text", "text": "Lemma C.7. Fix some arbitrary $L_{0}\\ge1$ and let $\\chi=12\\sqrt{d}H$ Under event $\\mathcal{G}_{1}$ ,for any $(k,h,s)\\in$ $[K]\\times[H]\\times{\\mathcal{S}},l\\in[\\operatorname*{min}\\{L_{0},l_{h}^{k}(s)-f_{h}^{k}(s)\\}],a_{l+1}\\in{\\mathcal{A}}_{h,l+1}^{k}(s),$ ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\cal A}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})\\leq8\\cdot2^{-l}+2l\\cdot\\chi\\sqrt{L_{0}}\\zeta.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "C.3 The Impact of Misspecification Level $\\zeta$ ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Next, we are ready to show the criteria where Line 11 in Algorithm 2 will be triggered, which shows the impact of misspecification on this multi-phased estimation. ", "page_idx": 14}, {"type": "text", "text": "Lemma C.8. Under event $\\mathcal{G}_{1}$ , for any $(k,h)~\\in~[K]\\,\\times\\,[H]$ such that $f_{h}^{k}(s_{h}^{k})~=~0$ , we have $l_{h}^{k}(s_{h}^{k})\\,>\\,L_{\\zeta}$ where $L_{\\zeta}$ is the maximal integer satisfying $2^{-L_{\\zeta}}\\,\\geq\\,\\chi L_{\\zeta}^{1.5}\\zeta$ for $\\chi\\,=\\,12\\sqrt{d}H$ i.e., $L_{\\zeta}=\\Omega(\\log(1/\\zeta))$ ", "page_idx": 14}, {"type": "text", "text": "Equipped with Lemma C.8, the following lemma suggests that how much estimation precision $\\varepsilon$ can be achieved by accumulating the error $2^{-l_{h}^{k}(s_{h}^{k})}$ that ocurred in Lemma C.6. ", "page_idx": 14}, {"type": "text", "text": "Lemma C.9. Under event $\\mathcal{G}_{1}$ and for all $\\varepsilon\\ >\\ 0$ define $L_{\\varepsilon}$ to be the minimal integer satisfying $2^{-L_{\\varepsilon}}\\leq0.01\\varepsilon/H$ , i.e., $L_{\\varepsilon}=\\lceil-\\log(0.01\\varepsilon/H)\\rceil$ . When $L_{\\varepsilon}\\leq L_{\\zeta}$ , then for any $\\kappa\\subseteq[\\bar{K}],h\\in[\\bar{H}]$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{K}}2^{-l_{h}^{k}(s_{h}^{k})}\\leq0.01|\\mathcal{K}|\\cdot\\varepsilon/H+2^{12}L_{\\varepsilon}d H\\gamma_{L_{\\varepsilon}}^{2}\\cdot\\varepsilon^{-1}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The relationship between $L_{\\varepsilon}\\ \\leq\\ L_{\\zeta}$ can be translated to the relationship between $\\varepsilon$ and $\\zeta$ .We characterize this condition as follows: ", "page_idx": 15}, {"type": "text", "text": "Definition C.10. Condition $\\mathcal{G}_{\\varepsilon}$ is defined for a given $\\varepsilon$ , and is satisfied if $L_{\\zeta}\\,\\geq\\,L_{\\varepsilon}$ where $L_{\\varepsilon}$ is the minimal integer satisfying $2^{-L_{\\varepsilon}}\\,\\leq\\,0.01\\varepsilon/H$ and $L_{\\zeta}$ is the maximal integer satisfying $2^{-L_{\\zeta}}\\geq$ $\\chi L_{\\zeta}^{1.5}\\zeta$ ", "page_idx": 15}, {"type": "text", "text": "Lemma C.11. If $\\varepsilon\\geq\\Omega\\big(\\sqrt{d}H^{2}\\zeta\\log^{2}(1/\\zeta)\\big)$ , then $\\mathcal{G}_{\\varepsilon}$ is satisfied. ", "page_idx": 15}, {"type": "text", "text": "Proof. If $\\varepsilon\\geq\\Omega\\big(\\sqrt{d}H^{2}\\zeta\\log^{2}(1/\\zeta)\\big)$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n2^{-L_{\\varepsilon}}\\geq0.005\\varepsilon/H\\geq2\\chi L_{\\zeta}^{1.5}\\zeta\\geq2^{-L_{\\zeta}}.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where the first inequality is given by the definition of $L_{\\varepsilon}$ , the last inequality is given by the definition of $L_{\\zeta}$ , and the second inequality holds since $H\\chi L_{\\zeta}^{1.5}\\leq\\mathcal{O}\\big(\\sqrt{d}H^{2}\\log^{2}(1/\\zeta)\\big)$ , and the last inequality is given by the definition of $L_{\\varepsilon}$ and $L_{\\zeta}$ , respectively. Since $2^{-l}$ decreases as $l$ increases, we can conclude that $L_{\\varepsilon}\\leq L_{\\zeta}$ \u53e3 ", "page_idx": 15}, {"type": "text", "text": "The above analysis of the interplay between misspecification level $\\zeta$ and precision $\\varepsilon$ yieldsthe following important lemma in our proof, showing a local decision error across all $h\\in[H]$ ", "page_idx": 15}, {"type": "text", "text": "Lemma C.12. Under Assumption 3.1, let $\\gamma_{l}=5(l+20+\\lceil\\log(l d)\\rceil)d H\\sqrt{\\log(16l d H/\\delta)}.$ for some fixed $0<\\delta<1/3$ With probability at least $1\\!-\\!3\\delta$ , for any $\\varepsilon>\\Omega\\big(\\sqrt{d}H^{2}\\zeta\\log^{2}(1/\\zeta)\\big)$ and $h\\in[H]$ we have ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{\\infty}\\mathbb{1}\\left[V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\geq\\varepsilon\\right]\\leq\\mathcal{O}\\big(d^{3}H^{4}\\varepsilon^{-2}\\log^{4}(d H\\varepsilon^{-1})\\log(\\delta^{-1})\\iota\\big),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\iota$ refers to some polynomial of $\\log\\log(d{\\cal H}\\varepsilon^{-1}\\delta^{-1})$ . This can also be written as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[\\exists\\varepsilon>\\varepsilon_{0},h\\in[H],\\sum_{k=1}^{\\infty}\\mathbb{1}\\left[V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})>\\varepsilon\\right]>f(\\varepsilon,\\delta)\\right]\\le\\delta.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "with $\\varepsilon_{0}=\\widetilde\\Omega(\\sqrt{d}H^{2}\\zeta)$ and $f(\\varepsilon,\\delta)=\\widetilde{\\mathcal{O}}(d^{3}H^{4}\\varepsilon^{-2}\\log(\\delta^{-1}))$ ", "page_idx": 15}, {"type": "text", "text": "C.4 From Local Step-wise Decision Error to Constant Regret ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The next lemma shows that the total incurred suboptimality gap is constant if the minimal suboptimality gap $\\Delta$ satisfies $\\Delta>\\varepsilon_{0}$ ", "page_idx": 15}, {"type": "text", "text": "Lemma C.13. Suppose an RL algorithm ${\\tt A L g}$ . satisfies ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\left[\\exists\\varepsilon>\\varepsilon_{0},h\\in[H],\\sum_{k=1}^{\\infty}\\Im\\left[V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})>\\varepsilon\\right]>f(\\varepsilon,\\delta)\\right]\\le\\delta,\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "such that $f(\\varepsilon,\\delta)=\\widetilde{\\mathcal{O}}(C_{1}/\\varepsilon+C_{2}/\\varepsilon^{2})$ where $C_{1},C_{2}>0$ are constant in $\\varepsilon$ , but may depend on other quantities such as $d,H,\\log(\\delta^{-1})$ . If the minimal suboptimality gap $\\Delta$ satisfies $\\Delta>\\varepsilon_{0}$ , then ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}\\le\\widetilde{\\mathcal{O}}(C_{2}H/\\Delta+C_{1}H)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "where $\\Delta_{h}^{k}\\,=\\,\\Delta_{h}\\bigl(s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k})\\bigr)\\,=\\,V_{h}^{*}\\bigl(s_{h}^{k}\\bigr)\\,-\\,Q_{h}^{*}\\bigl(s_{h}^{k},\\pi_{h}^{k}\\bigl(s_{h}^{k}\\bigr)\\bigr)$ is the suboptimality gap suffed in stage $h$ of episode $k$ ", "page_idx": 15}, {"type": "text", "text": "The following Lemma is a refined version of Lemma 6.1 in He et al. (202la) that removes the dependence between regret and number of episodes $K$ ", "page_idx": 16}, {"type": "text", "text": "Lemma C.14. For each MDP $\\mathcal{M}(\\ensuremath{\\boldsymbol{\\mathcal{S}}},\\mathcal{A},\\ensuremath{\\boldsymbol{H}},\\left\\{\\ensuremath{\\boldsymbol{r}}_{h}\\right\\},\\left\\{\\ensuremath{\\mathbb{P}}_{h}\\right\\})$ and any $\\delta\\,>\\,0$ , with probability at least $1-\\delta$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n{\\mathrm{Regret}}(K)<\\widetilde{\\mathcal{O}}\\bigg(\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+H^{2}\\log(1/\\delta)\\bigg).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "We are now ready to prove Theorem 5.1: ", "page_idx": 16}, {"type": "text", "text": "Proof of Theorem 5.1. By plugging in Lemma C.12 and Lemma C.13 into Lemma C.14, we can reach the desired statement. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "D  Proof of Lemmas in Appendix C ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we prove lemmas outlined in Appendix C. Any proofs not included in this section are deferred to Appendix E. ", "page_idx": 16}, {"type": "text", "text": "D.1  Proof of Lemma C.2 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proof of Lemma C.2. According to the criteria for Line 11, we have $\\check{V}_{h,l}^{k}(s)\\ \\leq\\ \\widehat{V}_{h,l}^{k}(s)$ for any $l\\in[l_{h}^{k}(s)-1]$ From the definition of $\\check{V}_{h,l}^{k}(s)$ and $\\widehat{V}_{h,l}^{k}(s)$ , they are monotonic in $l$ that $\\widehat{V}_{h,l-1}^{k}(s)\\leq$ $\\widehat{V}_{h,l}^{k}(s)$ and $\\widehat{V}_{h,l}^{k}(s)\\leq\\widehat{V}_{h,l-1}^{k}(s)$ hold. Combining with $\\widehat V_{h+1}^{k}(s)=\\widehat V_{h,l_{h}^{k}(s)-1}^{k}$ Vh,l (s)-1, we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\forall l\\in[l_{h}^{k}(s)-1],\\widecheck V_{h,l}^{k}(s)\\leq\\widehat V_{h}^{k}(s)\\leq\\widehat V_{h,l}^{k}(s)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "From the definition of $\\widehat{V}_{h,l}^{k}(s)$ and $\\check{V}_{h,l}^{k}(s)$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n0\\le\\widehat{V}_{h,l}^{k}(s)-\\check{V}_{h,l}^{k}(s)\\le\\big(\\widehat{V}_{h,l}^{k}(s)-V_{h,l}^{k}(s)\\big)+\\big(V_{h,l}^{k}(s)-\\check{V}_{h,l}^{k}(s)\\big)\\le6\\cdot2^{-l}.\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Plugging (D.1) into (D.2), we conclude that for any phase $l\\in[l_{h}^{k}(s)-1]$ , it holds that $|\\widehat{V}_{h}^{k}(s)-$ $\\widehat V_{h,l}^{k}(s)|\\leq6\\cdot2^{-l}$ ", "page_idx": 16}, {"type": "text", "text": "Now considerthe extended state vale funtion $\\widehat{V}_{h,l_{+}}^{k}$ with an arbitrary $l_{+}\\in\\mathbb{N}^{+}$ . For every $s$ where $l_{+}\\leq\\,l_{h}^{k}(s)\\,-\\,1$ ,we have $|\\widehat{V}_{h}^{k}(s)-V_{h,l_{+}}^{k}(s)|\\,\\le\\,6\\cdot2^{-l_{+}}$ as reasoned above. For the other $s\\,\\in\\,S$ where $l_{+}\\geq l_{h}^{k}(s)$ , we have $\\widehat V_{h,l}^{k}(s)=\\widehat V_{h}^{k}(s)$ following the procedure of Algorithm 2. This suggest that $|\\widehat{V}_{h}^{k}(s)-\\widehat{V}_{h,l_{+}}^{k}(s)|\\leq6\\cdot2^{-l_{+}}$ always holds. \u53e3 ", "page_idx": 16}, {"type": "text", "text": "D.2 Proof of Lemma C.4 ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "The following Lemma shows the rounding only cast bounded effects on the recovered parameters. ", "page_idx": 16}, {"type": "text", "text": "Lemma D.1. For any $(k,h,s)\\in[K]\\times[H]\\times{\\cal{S}},l\\in[l_{h}^{k}(s)-f_{h}^{k}(s)],a\\in{\\cal{A}}_{h,l}^{k}(s)$ , it holds that ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\left\\langle\\phi(s,a),\\mathbf{w}_{h,l}^{k}\\right\\rangle-\\left\\langle\\phi(s,a),\\widetilde{\\mathbf{w}}_{h,l}^{k}\\right\\rangle\\right|\\leq0.01\\cdot2^{-4l},\\left|\\|\\phi(s,a)\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}-\\|\\phi(s,a)\\|_{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}}\\right|\\leq0.1\\cdot2^{-2l}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The following lemma shows the number of episodes that are taken into regression $|\\mathcal{C}_{h,l}^{k}|$ is bounded independently from the number of episodes $k$ ", "page_idx": 16}, {"type": "text", "text": "Lemma D.2. For any tuple $(k,h,l)\\in[K]\\times[H]\\times\\mathbb{N}^{+}$ wehave $|\\mathcal{C}_{h,l}^{k}|\\leq16l\\cdot4^{l}\\gamma_{l}^{2}d.$ ", "page_idx": 16}, {"type": "text", "text": "The following lemma shows the number of possible state value functions $|\\mathcal{V}_{h,l}^{k}|$ is bounded independently from the number of episodes $k$ ", "page_idx": 16}, {"type": "text", "text": "Lemma D.3. For any tuple $(k,h,l)\\in[K]\\times[H]\\times\\mathbb{N}^{+}$ , we have $|\\mathcal{V}_{h,l}^{k}|\\leq(2^{22}d^{6}H^{4})^{l^{2}d^{2}}$ ", "page_idx": 16}, {"type": "text", "text": "Now we are ready to prove Lemma C.4. ", "page_idx": 16}, {"type": "text", "text": "Proof of Lemma C.4. Recall in Definition C.3, the good event defined by the union of each single bad event: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{G}_{1}=\\bigcap_{k=1}^{K}\\bigcap_{h=1}^{H}\\bigcap_{l\\geq1}\\bigcap_{V\\in\\mathcal{V}_{h,l_{+}}^{k}}\\mathcal{B}_{1}^{\\complement}(k,h,l,V),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where each single bad event is given by ", "page_idx": 17}, {"type": "equation", "text": "$$\nB_{1}(k,h,l,V)=\\bigg\\{\\bigg\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}V](s_{h}^{\\tau},a_{h}^{\\tau})-V(s_{h+1}^{\\tau})\\big)\\bigg\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}>\\gamma_{l}\\bigg\\},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "in which $[\\mathbb{P}_{h}V](s,a)=\\mathbb{E}_{s^{\\prime}\\sim\\mathbb{P}_{h}(\\cdot|s,a)}\\,V(s)$ ", "page_idx": 17}, {"type": "text", "text": "Consider some fixed $(h,l)\\in[H]\\times\\mathbb{N}^{+}$ \uff0c $V\\in\\mathcal{V}_{h,l_{+}}^{K}$ Arrange lements of $\\mathcal{C}_{h,l}^{k}$ in ascending order as $\\{\\tau_{i}\\}_{i}$ .Since the environment sample $s_{h+1}^{\\tau_{i}}$ according to $\\mathbb{P}_{h}(\\cdot|s_{h}^{\\tau_{i}},a_{h}^{\\tau_{i}})$ , we have $[\\mathbb{P}_{h}V](s_{h}^{\\tau_{i}},a_{h}^{\\tau_{i}})\\mathrm{~-~}$ $V(s_{h+1}^{\\tau_{i}})$ .is $\\mathcal{F}_{h}^{\\tau_{i}}$ -measurable with $\\mathbb{E}\\left[[\\mathbb{P}_{h}V](s_{h}^{\\tau_{i}},a_{h}^{\\tau_{i}})-V(s_{h+1}^{\\tau_{i}})\\big\\vert\\mathcal{F}_{h}^{\\tau_{i}}\\right]=0$ Since $0\\leq V(s_{h+1}^{\\tau_{i}})\\leq$ $H$ , we have $|[\\Dot{\\mathbb{P}}_{h}V](s_{h}^{\\tau_{i}},a_{h}^{\\tau_{i}})-V(s_{h+1}^{\\tau_{i}})|\\leq\\Dot{H}$ . This further leads to ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigg\\|\\displaystyle\\sum_{\\tau\\in\\mathbb{C}_{h,t}^{\\tau}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}V]\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)-V\\big(s_{h+1}^{\\tau}\\big)\\big)\\bigg\\|_{(\\mathbb{U}_{h,t}^{k})^{-1}}}\\\\ &{=\\bigg\\|\\displaystyle\\sum_{i=1}^{|\\mathcal{C}_{h,t}^{\\lambda-1}|}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}V]\\big(s_{h}^{\\tau},a_{h}^{\\tau}\\big)-V\\big(s_{h+1}^{\\tau}\\big)\\big)\\bigg\\|_{(\\mathbf{U}_{h,t}^{k})^{-1}}}\\\\ &{\\le H\\sqrt{2d\\ln\\big(1+|\\mathcal{C}_{h,t}^{k}|/(d\\lambda)\\big)+2\\ln(l^{2}H|\\mathcal{V}_{h,l+1}^{K}|/\\delta)}}\\\\ &{\\le H\\sqrt{2d\\ln(1+l\\cdot4^{l}\\gamma_{l}^{2})+2\\ln(l^{2}H(2^{2}d^{6}H^{4})^{l_{+}^{2}\\ell^{2}}/\\delta)}}\\\\ &{\\le\\gamma_{l,l+1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the fist inequality holds following from the good event of probability $1-\\delta/(l^{2}H|\\mathcal{V}_{h,l_{+}}^{K}|)$ defined in Lemma H.2 over filtration $\\{\\mathcal{F}_{h}^{\\tau_{i}}\\}_{i}$ , the second inequality is derived from combining Lemma D.2 and Lemma D.3, and the last inequality is given by Lemma G.3. According to Lemma H.2, we have the bad event $\\bigcup_{k=1}^{K}{\\mathcal{B}}_{1}(k,h,l,V)$ happens with probability at most $\\delta/(l^{2}H|\\nu_{h,l_{+}}^{K}|)$ Taking unionbound over al $(h,l)\\in[H]\\times\\mathbb{N}^{+}$ \uff0c $V\\in\\mathcal{V}_{h,l_{+}}^{K}$ we have the bad event happens with probability at most ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Pr}[\\mathcal{G}_{1}^{\\complement}]\\leq\\sum_{h=1}^{H}\\sum_{l=1}^{\\infty}\\sum_{V\\in\\mathcal{V}_{h,l_{+}}^{K}}\\mathrm{Pr}\\left[\\bigcup_{k=1}^{K}\\mathcal{B}_{1}(k,h,l,V)\\right]\\leq\\sum_{h=1}^{H}\\sum_{l=1}^{\\infty}\\sum_{V\\in\\mathcal{V}_{h,l_{+}}^{K}}\\frac{\\delta}{l^{2}H|\\mathcal{V}_{h,l_{+}}^{K}|}\\leq2\\delta,\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last inquality holds to $\\begin{array}{r}{\\sum_{n\\geq1}n^{-2}=\\pi^{2}/6}\\end{array}$ This completes our proof. ", "page_idx": 17}, {"type": "text", "text": "D.3  Proof of Lemma C.5 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof of Lemma C.5. Denote the martingale difference between $\\widehat V_{h,l_{+}}^{k}-\\widehat V_{h}^{k}$ ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mu_{h,l}^{k}=[\\mathbb{P}_{h}(\\widehat{V}_{h,l_{+}}^{k}-\\widehat{V}_{h+1}^{k})](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))-\\big(\\widehat{V}_{h,l_{+}}^{k}(s_{h+1}^{k})-\\widehat{V}_{h+1}^{k}(s_{h+1}^{k})\\big).\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "By triangle inequality: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}\\widehat V_{h+1}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat V_{h+1}^{k}(s_{h+1}^{\\tau})\\big)\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}}\\\\ &{\\le\\displaystyle\\left\\|\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}V_{h,l_{+}}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat V_{h,l_{+}}^{k}(s_{h+1}^{\\tau})\\big)\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}+\\left\\|\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\mu_{h,l_{+}}^{\\tau}\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "According to the definition of event $\\mathcal{G}_{1}$ , we can upper bound the first term by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}V_{h,l_{+}}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat V_{h,l_{+}}^{k}(s_{h+1}^{\\tau})\\big)\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq\\gamma_{l,l_{+}}=\\gamma_{l}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "According to Lemma C.2, we have $|\\widehat{V}_{h,l_{+}}^{k}(s)-\\widehat{V}_{h+1}^{k}(s)|\\,\\leq\\,6\\cdot2^{-l_{+}}$ for any $s\\ \\in\\ S$ .Thus, the difference can be bounded by $|\\mu_{h,l_{+}}^{\\tau}|\\leq6\\cdot2^{-l_{+}}$ . Consequently, we can bound the second term by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\mu_{h,l+}^{\\tau}\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq6\\cdot2^{-l_{+}}\\sqrt{|\\mathcal{C}_{h,l}^{k}|}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq6\\cdot2^{-l_{+}}\\sqrt{16l\\cdot4^{l}\\gamma_{l}^{2}d}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=24\\cdot2^{l-l_{+}}\\gamma_{l}\\sqrt{l d},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the first inequality is provided by Lemma H.3, utilizing the condition $|\\mu_{h,l_{+}}^{\\tau}|\\leq6\\cdot2^{-l_{+}}$ ,the second inequality is from Lemma D.2. By plugging in the definition of $l_{+}$ , we can further bound the final term of (D.5) by ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\mu_{h,l_{+}}^{\\tau}\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq24\\cdot2^{l-l_{+}}\\gamma_{l}\\sqrt{l d}\\leq24\\cdot2^{-20}\\gamma_{l}\\leq0.1\\gamma_{l}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Plugging (D.4) and (D.6) into (D.3) yields the desired statement such that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\big([\\mathbb{P}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})-\\widehat{V}_{h+1}^{k}(s_{h+1}^{\\tau})\\big)\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq1.1\\gamma_{l},\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which concludes our proof. ", "page_idx": 18}, {"type": "text", "text": "D.4 Proof of Lemma C.6 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The following lemma shows the state-action value function $Q_{h,l}^{k}(s,a)$ is always well estimated. ", "page_idx": 18}, {"type": "text", "text": "Lemma D.4. Under event $\\mathcal{G}_{1}$ , for any $(k,h,l,s,a)\\in[K]\\times[H]\\times\\mathbb{N}^{+}\\times\\mathcal{S}\\times\\mathcal{A},$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\big|Q_{h,l}^{k}(s,a)-[\\mathbb{B}_{h}\\hat{V}_{h+1}^{k}](s,a)\\big|\\leq\\big(1.2+8\\sqrt{l d}H\\cdot2^{l}\\zeta\\big)\\gamma_{l}\\|\\phi(s,a)\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}+0.01\\cdot2^{-4l}+2H\\zeta.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Equipped with Lemma D.1 and Lemma D.4, we are ready to prove Lemma C.6. ", "page_idx": 18}, {"type": "text", "text": "Proof of Lemma C.6. In case that $l\\leq l_{h}^{k}(s)-f_{h}^{k}(s)$ , for any $a\\in A_{h,l}^{k}(s)$ , we have that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Vert\\phi(s,a)\\Vert_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq\\Vert\\phi(s,a)\\Vert_{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}}+\\Vert\\Vert\\phi(s,a)\\Vert_{(\\mathbf{U}_{h,l}^{k})^{-1}}-\\Vert\\phi(s,a)\\Vert_{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}}}\\\\ &{\\qquad\\qquad\\qquad\\leq2^{-l}\\gamma_{l}^{-1}+0.1\\cdot2^{-2l}\\leq1.1\\cdot2^{-l}\\gamma_{l}^{-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "where the first inequality holds due to triangle inequality, and in the second inequality, the first term is satisfied since state $s$ passes the criterion in Line 9 in phase $l$ and the second term follows from Lemma D.1, and the last inequality is given by Lemma G.2 which implies $2^{l}>\\gamma_{l}$ . Plugging (D.7) into Lemma D.4 gives ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|Q_{h,l}^{k}(s,a)-[\\mathbb{B}_{h}\\widehat V_{h+1}^{k}](s,a)\\right|\\le0.01\\cdot2^{-4l}+1.32\\cdot2^{-l}+8.8\\sqrt{l d}H\\zeta+2H\\zeta}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\le2\\cdot2^{-l}+12\\sqrt{l d}H\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "which proves the desired statement. ", "page_idx": 18}, {"type": "text", "text": "D.5 Proof of Lemma C.7 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Equipped with Lemma C.6, we are able to show several properties of the state value function $V_{h,l}^{k}$ throught the arm-elimination process. The first lemma suggests that for any action $a_{l}\\in\\mathcal{A}_{h,l}^{k}(s)$ there is at least one action $a_{l+1}~\\in~\\mathcal{A}_{h,l+1}^{k}(s)$ close to $a_{l}$ in terms of the Bellman operator $[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)$ after the elimination. ", "page_idx": 19}, {"type": "text", "text": "Lemma D.5. Under event $\\mathcal{G}_{1}$ , for any $(k,h,s)\\in[K]\\times[H]\\times\\mathcal{S},l\\in[\\operatorname*{min}\\{L_{0},l_{h}^{k}(s)-f_{h}^{k}(s)\\}],a_{l}\\in\\mathcal{S},$ $A_{h,l}^{k}(s)$ , there exists $a_{l+1}\\in\\mathcal{A}_{h,l+1}^{k}(s)$ that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})\\le2\\chi\\sqrt{L_{0}}\\zeta}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\chi=12\\sqrt{d}H$ for arbitrary $L_{0}\\ge1$ ", "page_idx": 19}, {"type": "text", "text": "Then the following lemma shows that by induction on stage $h\\in[H]$ , we can show the elimination process keep at least one near-optimal action $a_{l+1}\\in\\mathcal{A}_{h,l+1}^{k}(s)$ ", "page_idx": 19}, {"type": "text", "text": "Lemma D.6. Under event $\\mathcal{G}_{1}$ , for any $(k,h,s)\\in[K]\\times[H]\\times\\mathcal{S},l\\in[\\operatorname*{min}\\{L_{0},l_{h}^{k}(s)-f_{h}^{k}(s)\\}],$ there exists $a_{l+1}\\in\\mathcal{A}_{h,l+1}^{k}(s)$ that, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})\\leq2l\\cdot\\chi\\sqrt{L_{0}}\\zeta.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\chi=12\\sqrt{d}H$ for arbitrary $L_{0}\\ge1$ ", "page_idx": 19}, {"type": "text", "text": "The following two lemmas indicate that the state value function $V_{h,l}^{k}(s)$ on stage $h$ is a good estimation for the stae value funtion given byBellman operator $V(s)=\\operatorname*{max}_{a\\in A}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-V_{h,l}^{k}(s)\\leq2\\cdot2^{-l}+(2l-1)\\chi\\sqrt{L_{0}}\\zeta\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\chi=12\\sqrt{d}H$ for arbitrary $L_{0}\\ge1$ ", "page_idx": 19}, {"type": "text", "text": "Lemma D.8. Under ev ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{snt}\\mathcal{G}_{1},\\mathrm{for}\\;\\mathrm{any}\\;(k,h,s)\\in[K]\\times[H]\\times\\mathcal{S},l\\in[\\operatorname*{min}\\{L_{0},l_{h}^{k}(s)-f_{h}^{k}(s)\\}],}\\\\ &{V_{h,l}^{k}(s)-\\displaystyle\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\leq2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\chi=12\\sqrt{d}H$ for arbitrary $L_{0}\\ge1$ ", "page_idx": 19}, {"type": "text", "text": "Now we are ready to show any actions remaining in the elimination process are near-optimal. ", "page_idx": 19}, {"type": "text", "text": "Proof of Lemma C.7. First, according to Lemma D.7, we can write ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-V_{h,l}^{k}(s)\\leq2\\cdot2^{-l}+(2l-1)\\chi\\sqrt{L_{0}}\\zeta.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Any action $a_{l+1}\\in\\mathcal{A}_{h,l+1}^{k}(s)$ passes the elimination process will satisfy: ", "page_idx": 19}, {"type": "equation", "text": "$$\nQ_{h,l}^{k}(s,a_{l+1})\\geq V_{h,l}^{k}(s)-4\\cdot2^{-l}.\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "According to Lemma C.6 with the condition that $l\\,\\leq\\,L_{0}$ , we have that the empirical state-action value function $Q_{h,l}^{k}(s,\\cdot)$ is a good estimation for $[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\cdot)$ among every $a_{l+1}\\in\\mathcal{A}_{l}^{k}(s)$ under event $\\mathcal{G}_{1}$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\big|[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})-Q_{h,l}^{k}(s,a_{l+1})\\big|\\leq2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Combining (D.8), (D.9), and (D.10) gives ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\underset{a\\in A}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})}\\\\ &{=\\big(\\underset{a\\in A}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-V_{h,l}^{k}(s)\\big)+\\big(V_{h,l}^{k}(s)-Q_{h,l}^{k}(s,a_{l+1})\\big)+\\big(Q_{h,l}^{k}(s,a_{l+1})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})-\\mathbb{B}_{h}\\big)}\\\\ &{\\leq\\big(2\\cdot2^{-l}+(2l-1)\\chi\\sqrt{L_{0}}\\zeta\\big)+4\\cdot2^{-l}+\\big(2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta\\big)}\\\\ &{=8\\cdot2^{-l}+2l\\cdot\\chi\\sqrt{L_{0}}\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "which proves the desired statement. ", "page_idx": 19}, {"type": "text", "text": "D.6Proof of Lemma C.8 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "The following two lemmas demonstrate that, at stage $h$ , both the optimistic state value function, $\\widehat{V}_{h,l}^{k}(s)$ , and the pessimistic state value function, $\\check{V}_{h,l}^{\\overline{{k}}}(s)$ , exhibit a gap relative to the state value function determined by the Bellman operator, given as $V(s)=\\operatorname*{max}_{a\\in A}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)$ ", "page_idx": 20}, {"type": "text", "text": "Lemma D.9. Under event $\\mathcal{G}_{1}$ , for any $(k,h,s)\\in[K]\\times[H]\\times\\mathcal{S},l\\in[\\operatorname*{min}\\{L_{0},l_{h}^{k}(s)-f_{h}^{k}(s)\\}],$ $\\operatorname*{min}\\left\\{V_{h,l}^{k}(s)+3\\cdot2^{-l},\\widehat{V}_{h,l-1}^{k}(s)\\right\\}-\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\geq2^{-l}-(2l-1)\\chi\\sqrt{L_{0}}\\zeta,$ ", "page_idx": 20}, {"type": "text", "text": "where $\\chi=12\\sqrt{d}H$ for arbitrary $L_{0}\\ge1$ . In case that $l\\leq l_{h}^{k}(s)-1$ , the inequality is equivalent to ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\widehat{V}_{h,l}^{k}(s)-\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\geq2^{-l}-(2l-1)\\chi\\sqrt{L_{0}}\\zeta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.10. Under event $\\mathcal{G}_{1}$ , for any $\\mathbf{\\sigma}\\cdot(k,h,s)\\in[K]\\times[H]\\times{\\mathcal{S}},l\\in[\\operatorname*{min}\\{L_{0},l_{h}^{k}(s)-f_{h}^{k}(s)\\}],$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-\\operatorname*{max}\\left\\{V_{h,l}^{k}(s)-3\\cdot2^{-l},\\breve{V}_{h,l-1}^{k}(s)\\right\\}\\geq2^{-l}-\\chi\\sqrt{L_{0}}\\zeta,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\chi=12\\sqrt{d}H$ for arbitrary $L_{0}\\ge1$ . In case that $l\\leq l_{h}^{k}(s)-1$ , the inequality is equivalent to ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-\\check{V}_{h,l}^{k}(s)\\geq2^{-l}-\\chi\\sqrt{L_{0}}\\zeta.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof of Lemma C.8. Set $L_{0}=L_{\\zeta}$ be the maximal integer satisfying $2^{-L_{\\zeta}}-\\chi L_{\\zeta}^{1.5}\\zeta\\geq0.$ Combining Lemma D.10 and Lemma D.9, for any $l\\in[\\operatorname*{min}\\{L_{0},l_{h}^{k}(s)-f_{h}^{k}(s)\\}]$ , we have that ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\operatorname*{min}\\big\\{V_{h,l}^{k}(s)+3\\cdot2^{-l},\\widehat{V}_{h,l-1}^{k}(s)\\big\\}-\\operatorname*{max}\\big\\{V_{h,l}^{k}(s)-3\\cdot2^{-l},\\breve{V}_{h,l-1}^{k}(s)\\big\\}}\\\\ &{=\\big(\\widehat{V}_{h,l}^{k}(s)-\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big)+\\big(\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-\\breve{V}_{h,l}^{k}(s)\\big)}\\\\ &{\\ge\\big(2^{-l}-(2l-1)\\chi\\sqrt{L_{0}}\\zeta\\big)+\\big(2^{-l}-\\chi\\sqrt{L_{0}}\\zeta\\big)}\\\\ &{=2\\cdot2^{-l}-2l\\cdot\\chi\\sqrt{L_{0}}\\zeta}\\\\ &{\\ge2\\cdot2^{-L_{0}}-2\\chi L_{0}^{1.5}\\zeta\\ge0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where the second inequality holds since $2^{-l}$ decreases as $l$ increases and the last inequality holds according to the selection of $L_{0}$ ", "page_idx": 20}, {"type": "text", "text": "When $f_{h}^{k}(s)\\,=\\,0$ , consider $l\\,=\\,l_{h}^{k}(s)$ . The above reasoning indicates the criterion in Line 11 can never satisfied. Thus $f_{h}^{k}(s)=0$ can only happen if $l_{h}^{k}(s)>L_{0}=L_{\\zeta}$ \u53e3 ", "page_idx": 20}, {"type": "text", "text": "D.7 Proof of Lemma C.9 ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "By partitioning $[K]$ based on whether Algorithm 2 stops before phase $L_{\\varepsilon}$ , we can prove Lemma C.9. Specifically, Lemma D.2 bounds the number of episodes in which Algorithm 2 stops before phase $L_{\\varepsilon}$ . This allows us to establish an upper bound for the desired summation over these episodes. Fur$L_{\\varepsilon}$ the cotribuion of $2^{-l_{h}^{k}(s_{h}^{k})}\\gamma_{l_{h}^{k}(s_{h}^{k})}$ to the definition of $L_{\\varepsilon}$ ", "page_idx": 20}, {"type": "text", "text": "Proofof Lemma C.9. Denote $\\begin{array}{r}{\\mathcal{C}_{h,+}^{K}=[K]-\\bigcup_{l=1}^{L_{\\varepsilon}-1}\\mathcal{C}_{h,l}^{K}}\\end{array}$ In this sense, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\sum_{k\\in K}2^{-l_{h}^{k}(s_{h}^{k})}=\\sum_{k\\in K\\cap\\mathcal{C}_{h,+}^{K}}2^{-l_{h}^{k}(s_{h}^{k})}+\\sum_{l=1}^{L_{\\varepsilon}-1}\\sum_{k\\in K\\cap\\mathcal{C}_{h,l}^{K}}2^{-l_{h}^{k}(s_{h}^{k})}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "From the construction of $\\mathcal{C}_{h,l}^{K}$ we have $l_{h}^{k}(s_{h}^{k})\\;=\\;l$ for any $k\\,\\in\\,\\mathcal{C}_{h,l}^{K}$ Fix some $k\\ \\in\\ {\\mathcal{C}}_{h,+}^{K}$ If $f_{h}^{k}(s_{h}^{k})=0$ , we have $l_{h}^{k}(s_{h}^{k})\\geq L_{\\zeta}\\geq L_{\\varepsilon}$ where the first inequality is given by Lemma C.8 and the second inequality is given by the assignment of $L_{\\varepsilon}$ . Otherwise, we have $l_{h}^{k}(s_{h}^{k})\\geq L_{\\varepsilon}$ according to ", "page_idx": 20}, {"type": "text", "text": "the definition of $\\mathcal{C}_{h,l}^{K}$ This indicates $l_{h}^{k}(s_{h}^{k})\\geq L_{\\varepsilon}$ holds for any $k\\in\\mathcal{C}_{h,+}^{K}$ Thisallow isto bound the first term by ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{K}\\cap\\mathcal{C}_{h,+}^{K}}2^{-l_{h}^{k}(s_{h}^{k})}\\le\\sum_{k\\in\\mathcal{K}\\cap\\mathcal{C}_{h,+}^{K}}2^{-L_{\\varepsilon}}\\le0.01|\\mathcal{K}|\\cdot\\varepsilon/H,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the first inequality holds since $l_{h}^{k}(s_{h}^{k})>L_{\\varepsilon}$ and the second inequality holds from both $2^{-L_{\\varepsilon}}\\leq$ $0.01\\varepsilon/H$ and $|K\\cap\\mathcal{C}_{h,+}^{K}|\\le|K|$ ", "page_idx": 21}, {"type": "text", "text": "Furthermore, we can bound the second term by ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{l=1}^{L_{\\varepsilon}-1}\\sum_{k\\in K\\cap\\mathcal{C}_{h,l}^{K}}2^{-l_{h}^{k}(s_{h}^{k})}\\leq\\displaystyle\\sum_{l=1}^{L_{\\varepsilon}-1}|K\\cap\\mathcal{C}_{h,l}^{K}|\\cdot2^{-l}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{l=1}^{L_{\\varepsilon}-1}16l\\cdot4^{l}\\gamma_{l}^{2}d\\cdot2^{-l}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq16L_{\\varepsilon}d\\cdot2^{L_{\\varepsilon}}\\gamma_{L_{\\varepsilon}}^{2}\\leq2^{12}L_{\\varepsilon}d H\\gamma_{L_{\\varepsilon}}^{2}\\varepsilon^{-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second inequality is given by Lemma D.2, and the last inequality holds due to $0.005\\varepsilon/H\\leq2^{-L_{\\varepsilon}}$ which isbecause $L_{\\varepsilon}$ is a minimal integer such that $2^{-L_{\\varepsilon}}\\leq0.0\\dot{1}\\varepsilon/H$ ", "page_idx": 21}, {"type": "text", "text": "Finally, plugging D.12) and (D.13) into (D.11) gives ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{K}}2^{-l_{h}^{k}(s_{h}^{k})}\\leq0.01|\\mathcal{K}|\\cdot\\varepsilon/H+2^{12}L_{\\varepsilon}d H\\gamma_{L_{\\varepsilon}}^{2}\\varepsilon^{-1}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "D.8 Proof of Lemma C.12 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "The following lemma provides an upper bound for the underestimation error of the empirical state valuefunction $\\widehat V_{h}^{k}$ with respect to the optimal tate value function $V_{h}^{*}$ ", "page_idx": 21}, {"type": "text", "text": "Lemma D.11. Under event $\\mathcal{G}_{1}$ and for all $\\varepsilon>0$ that $\\mathcal{G}_{\\varepsilon}$ is satisfied, for any $(k,h,s)\\in[K]\\!\\times\\![H]\\!\\times\\!S$ ", "page_idx": 21}, {"type": "equation", "text": "$$\nV_{h}^{*}(s)-\\widehat{V}_{h}^{k}(s)\\leq0.07\\varepsilon.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "As $\\widehat V_{h}^{k}$ represents an empirical state value function with potentially optimal policy $\\pi_{h}^{k}(s)$ , the following lemma provides an upper bound for the overestimation error of $\\widehat V_{h}^{k}$ with respect to deploying the policy $\\pi_{h}^{k}(s)$ on the ground-truth transition kernel. ", "page_idx": 21}, {"type": "text", "text": "Lemma D.12. Under event $\\mathcal{G}_{1}$ and for all $\\varepsilon>0$ that $\\mathcal{G}_{\\varepsilon}$ is satisfied, for any $(k,h,s)\\in[K]\\!\\times\\![H]\\!\\times\\!S$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\widehat V_{h}^{k}(s)-[\\mathbb B_{h}\\widehat V_{h+1}^{k}](s,\\pi_{h}^{k}(s))\\le20\\cdot2^{-l_{h}^{k}(s)}+0.16\\varepsilon/H.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "To start with, we define a good event according to: ", "page_idx": 21}, {"type": "text", "text": "Definition D.13. For some $\\varepsilon>0$ , let $\\mathcal{K}_{h}^{\\varepsilon}=\\{k\\in[K]:V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\geq\\varepsilon\\}$ . We define the bad event as ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathcal{B}_{2}(h,\\varepsilon)=\\left\\{\\,\\sum_{k\\in\\mathcal{K}_{h}^{\\varepsilon}}\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{k}>4\\sqrt{H^{3}|K_{h}^{\\varepsilon}|\\log(4H|K_{h}^{\\varepsilon}|\\log(\\varepsilon^{-1})/\\delta)}\\right\\}\\!.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\eta_{h}^{k}=[\\mathbb{P}_{h}(\\widehat{V}_{h+1}^{k}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))-(\\widehat{V}_{h+1}^{k}(s_{h+1}^{k})-V_{h+1}^{\\pi^{k}}(s_{h+1}^{k}))$ . The good event is defined as $\\mathcal{G}_{2}=\\bigcap_{h=1}^{H}\\bigcap_{l\\ge1}{\\mathcal{B}}_{2}^{\\complement}(h,2^{-l})$ ", "page_idx": 21}, {"type": "text", "text": "The following lemma provides the concentration property such that the cumulative sample error is small with high probability. ", "page_idx": 21}, {"type": "text", "text": "Lemma D.14. Event $\\mathcal{G}_{2}$ happens with probability at least $1-\\delta$ ", "page_idx": 21}, {"type": "text", "text": "Using the above results, we can bound the instantaneous regret of any subsets once the misspecification level is appropriately controlled, ", "page_idx": 22}, {"type": "text", "text": "Lemma D.15. Under event $\\mathcal{G}_{1},\\mathcal{G}_{2}$ and for all $\\varepsilon\\ >\\ 0$ that $\\mathcal{G}_{\\varepsilon}$ is satisfied, for any $\\boldsymbol{\\kappa}\\,\\subseteq\\,[K]$ and $h\\in[H]$ , it satisfies that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{K}}\\left(V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\right)\\leq0.49|K|\\varepsilon+2^{17}L_{\\varepsilon}d H^{2}\\gamma_{L_{\\varepsilon}\\mathcal{E}}^{2}\\varepsilon^{-1}+4\\sqrt{H^{3}|K|\\log(4H|K|\\log(\\varepsilon^{-1})/\\delta)}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "With all lemmas stated above, we can show Cert-LsvI-UCBachieves constant step-wise decision error. The following lemma gives a sufficient condition that $\\mathcal{G}_{\\varepsilon}$ defined in Definition C.10 is satisfied. Now, we are ready to prove Lemma C.12. ", "page_idx": 22}, {"type": "text", "text": "Proof of Lemma C.12. We focus on the case where the good event $\\mathcal{G}_{1}\\cap\\mathcal{G}_{2}\\cap\\mathcal{G}_{\\varepsilon}$ Occurs.By the union bound statement over Lemma C.4 and Lemma D.14, and Lemma C.11, this good event happens with a probability of at least $1-3\\delta$ and requires $\\varepsilon\\geq\\Omega(\\zeta\\sqrt{d}H^{2}\\log^{2}(d H\\zeta^{-1}))$ . W.1.o.g, consider ${\\kappa}_{h}^{\\varepsilon}$ for some $h\\in[H]$ and $\\varepsilon=2^{-l}$ where $l>0$ is an integer. On the one hand, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{k\\in K_{h}^{\\varepsilon}}\\left(V_{h}^{*}(s_{h}^{k})-{V_{h}^{\\pi^{k}}(s_{h}^{k})}\\right)\\geq|\\mathcal{K}_{h}^{\\varepsilon}|\\varepsilon.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "On the other hand, Lemma D.15 gives ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{k\\in K_{h}^{\\varepsilon}}\\left(V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\right)\\leq0.49|K_{h}^{\\varepsilon}|\\varepsilon+2^{17}L_{\\varepsilon}d H^{2}\\gamma_{L_{\\varepsilon}}^{2}\\varepsilon^{-1}}}\\\\ &{}&\\\\ &{}&{\\qquad+\\,4\\sqrt{H^{3}|K_{h}^{\\varepsilon}|\\log(4H|K_{h}^{\\varepsilon}|\\log(\\varepsilon^{-1})/\\delta)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Combining (D.14) and (D.15) gives ", "page_idx": 22}, {"type": "equation", "text": "$$\n0.51|K_{h}^{\\varepsilon}|\\varepsilon\\leq2^{17}L_{\\varepsilon}d H^{2}\\gamma_{L_{\\varepsilon}}^{2}\\varepsilon^{-1}+4\\sqrt{H^{3}|K_{h}^{\\varepsilon}|\\log(4H|K_{h}^{\\varepsilon}|\\log(\\varepsilon^{-1})/\\delta)}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Plugging the value of $\\gamma_{L_{\\varepsilon}}$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0.51|K_{h}^{\\varepsilon}|\\varepsilon\\leq2^{22}L_{\\varepsilon}(L_{\\varepsilon}+\\log(2^{20}d H))^{2}d^{3}H^{4}\\varepsilon^{-1}\\log(16L_{\\varepsilon}d/\\delta)}\\\\ {+\\,4\\sqrt{H^{3}|K_{h}^{\\varepsilon}|\\log(4H|K_{h}^{\\varepsilon}|\\log(\\varepsilon^{-1})/\\delta)}.\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "According to Lemma G.4, (D.16) implies ", "page_idx": 22}, {"type": "equation", "text": "$$\n|K_{h}^{\\varepsilon}|\\leq\\mathcal{O}(L_{\\varepsilon}(L_{\\varepsilon}+\\log(d H))^{2}d^{3}H^{4}\\varepsilon^{-2}\\log(L_{\\varepsilon}d)\\log(\\delta^{-1})\\iota),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where $\\iota$ refers to a polynomial of $\\log\\log(d{\\cal H}\\varepsilon^{-1}\\delta^{-1})$ . With the definition of $L_{\\varepsilon}$ , we conclude that ", "page_idx": 22}, {"type": "equation", "text": "$$\n|K_{h}^{\\varepsilon}|\\leq\\mathcal{O}(d^{3}H^{4}\\varepsilon^{-2}\\log^{4}(d H\\varepsilon^{-1})\\log(\\delta^{-1})\\iota).\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "D.9 Proof of Lemma C.13 ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Proof of Lemma C.13. From the definition of suboptimality gap, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta_{h}^{k}=V_{h}^{*}(s_{h}^{k})-[\\mathbb{B}_{h}V_{h+1}^{*}](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))}\\\\ &{\\quad\\quad\\le V_{h}^{*}(s_{h}^{k})-[\\mathbb{B}_{h}V_{h+1}^{\\pi^{k}}](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))}\\\\ &{\\quad\\quad=V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "According to the assumption, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}\\mathbb{1}\\left[V_{h}^{*}(s_{1}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\geq\\varepsilon\\right]\\leq\\Big(\\frac{C_{1}}{\\varepsilon}+\\frac{C_{2}}{\\varepsilon^{2}}\\Big)\\log^{a}\\Big(\\frac{C_{1}}{\\varepsilon}+\\frac{C_{2}}{\\varepsilon^{2}}\\Big)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "holds for every $\\varepsilon>\\varepsilon_{0}$ with probability at least $1-\\delta$ replacing the $V_{h}^{*}(s_{1}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})$ with its lower bound $\\Delta_{h}^{k}$ yields for every $\\varepsilon>\\varepsilon_{0}$ \uff0c ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}\\mathbb{1}\\left[\\Delta_{h}^{k}\\geq\\varepsilon\\right]\\leq\\Big(\\frac{C_{1}}{\\varepsilon}+\\frac{C_{2}}{\\varepsilon^{2}}\\Big)\\log^{a}\\Big(\\frac{C_{1}}{\\varepsilon}+\\frac{C_{2}}{\\varepsilon^{2}}\\Big).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In addition, according to the definition of minimal suboptimality gap $\\Delta$ in Definition 3.3, we have $\\Delta_{h}^{k}$ is either O or no less than $\\Delta$ . Since for any $x\\,\\in\\,\\{{\\bar{0}}\\}\\cup[{\\bar{\\Delta_{,}}}\\,{\\bar{H}}]$ , it holds that $x\\leq\\Delta\\cdot\\mathbb{1}[x\\geq$ $\\begin{array}{r}{\\Delta\\bar{]}+\\int_{\\Delta}^{H}\\mathbb{1}[x\\geq\\varepsilon]\\,\\mathrm{d}\\varepsilon}\\end{array}$ we decompose the total suboptimality incurred in stage $h$ by ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\displaystyle\\sum_{k=1}^{K}\\Delta_{h}^{k}\\leq\\displaystyle\\sum_{k=1}^{K}\\left(\\Delta\\cdot\\mathbb{1}\\left[\\Delta_{h}^{k}\\geq\\Delta\\right]+\\displaystyle\\int_{\\Delta}^{H}\\mathbb{1}\\left[\\Delta_{h}^{k}\\geq\\varepsilon\\right]\\mathrm{d}\\varepsilon\\right)}\\\\ {=\\Delta\\displaystyle\\sum_{k=1}^{K}\\mathbb{1}\\left[\\Delta_{h}^{k}\\geq\\Delta\\right]+\\displaystyle\\int_{\\Delta}^{H}\\sum_{k=1}^{K}\\mathbb{1}\\left[\\Delta_{h}^{k}\\geq\\varepsilon\\right]\\mathrm{d}\\varepsilon.}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "In case that $\\varepsilon_{0}\\leq\\Delta$ , the first term in (D.18) can be bounded by ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\Delta\\sum_{k=1}^{K}\\mathbb{1}\\left[\\Delta_{h}^{k}\\geq\\Delta\\right]\\leq\\Delta\\Big(\\frac{C_{1}}{\\Delta}+\\frac{C_{2}}{\\Delta^{2}}\\Big)\\log^{a}\\Big(\\frac{C_{1}}{\\Delta}+\\frac{C_{2}}{\\Delta^{2}}\\Big).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We can further bound the second term by ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\int_{\\Delta}^{H}\\sum_{k=1}^{K}\\mathbb{1}\\left[V_{1}^{*}(s_{1}^{k})-V_{1}^{\\pi^{k}}(s_{1}^{k})\\geq\\varepsilon\\right]\\mathrm{d}\\varepsilon\\leq\\int_{\\Delta}^{H}\\Big(\\frac{C_{1}}{\\varepsilon}+\\frac{C_{2}}{\\varepsilon^{2}}\\Big)\\log^{a}\\Big(\\frac{C_{1}}{\\varepsilon}+\\frac{C_{2}}{\\varepsilon^{2}}\\Big)\\,\\mathrm{d}\\varepsilon}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\log^{a}\\Big(\\frac{C_{1}}{\\Delta}+\\frac{C_{2}}{\\Delta^{2}}\\Big)\\cdot\\Big(C_{1}\\ln\\frac{H}{\\Delta}+\\frac{C_{2}}{\\Delta}\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\big(C_{1}\\log H+C_{2}/\\Delta\\big)\\cdot\\mathrm{polylog}(C_{1},C_{2},\\Delta^{-1}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Plugging (D.19) and (D.20) into (D.18) with summation over $h\\,\\in\\,[H]$ , we conclude that the total suboptimality incurred in stage $h$ is bounded by ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}\\le H\\cdot(C_{1}+C_{2}/\\Delta+C_{1}\\log H+C_{2}/\\Delta)\\cdot\\mathrm{polylog}(C_{1},C_{2},\\Delta^{-1})}}\\\\ &{\\le\\widetilde{\\mathcal{O}}(C_{2}H/\\Delta+C_{1}H).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "D.10 Proof of Lemma C.14 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Proof of Lemma C.14. For a given policy $\\pi$ and any state $s_{h}\\in{\\mathcal{S}}$ ,wehave ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{h}^{*}(s_{h})-V_{h}^{\\pi}(s_{h})}\\\\ &{=\\big(V_{h}^{*}(s_{h})-[\\mathbb{B}_{h}V_{h+1}^{*}](s_{h},\\pi_{h}(s_{h}))\\big)+\\big([\\mathbb{B}_{h}V_{h+1}^{*}](s_{h},\\pi_{h}(s_{h}))-[\\mathbb{B}_{h}V_{h+1}^{\\pi}](s_{h},\\pi_{h}(s_{h}))\\big)}\\\\ &{=\\Delta_{h}(s_{h},\\pi_{h}(s_{h}))+[\\mathbb{P}_{h}(V_{h+1}^{*}-V_{h+1}^{\\pi})](s_{h},\\pi_{h}(s_{h})),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where the second equality is given by the definition of suboptimality gap $\\Delta_{h}(\\cdot,\\cdot)$ in Definition 3.3. Taking expectation on both sides with respect to the randomness of state-transition and taking telescoping sum over all $h\\in[H]$ gives ", "page_idx": 23}, {"type": "equation", "text": "$$\nV_{1}^{*}(s_{1})-V_{h}^{\\pi}(s_{1})=\\mathbb{E}\\Bigg[\\sum_{h=1}^{H}\\Delta_{h}\\big(s_{h},\\pi_{h}(s_{h})\\big)\\Bigg],\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Iwhere $s_{h+1}\\sim\\mathbb{P}_{h}\\big(\\cdot|s_{h},\\pi_{h}(s_{h})\\big)$ $\\mathcal{F}^{k}=\\left\\{\\left\\{s_{i}^{j},a_{i}^{j}\\right\\}_{i=1,j=1}^{H,k-1}\\right\\}$ we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\Big[\\sum_{h=1}^{H}\\Delta_{h}^{k}\\Big|\\mathcal{F}^{k}\\Big]=V_{1}^{*}(s_{1}^{k})-V_{h}^{\\pi^{k}}(s_{1}^{k}).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Denote random variable $\\begin{array}{r}{\\eta^{k}=\\left(V_{1}^{*}(s_{1}^{k})\\!-\\!V_{h}^{\\pi^{k}}(s_{1}^{k})\\right)\\!-\\!\\sum_{h=1}^{H}\\Delta_{h}^{k}}\\end{array}$ We can see $\\eta^{k}$ .s $\\mathcal{F}_{k+1}$ -measurable with $|\\mathbb{E}[\\eta^{k}|\\mathcal{F}^{k}]|=0$ . Furthermore, for the variance of $\\eta^{k}$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Var}[\\eta^{k}|\\mathcal{F}^{k}]\\le{\\mathbb E}\\left[\\Big(\\displaystyle\\sum_{h=1}^{H}\\Delta_{h}^{k}\\Big)^{2}\\Big|\\mathcal{F}^{k}\\right]}\\\\ &{\\qquad\\qquad\\le H^{2}{\\mathbb E}\\left[\\displaystyle\\sum_{h=1}^{H}\\Delta_{h}^{k}\\Big|\\mathcal{F}^{k}\\right]}\\\\ &{\\qquad\\qquad=H^{2}\\big(V_{1}^{*}(s_{1}^{k})-V_{h}^{\\pi^{k}}(s_{1}^{k})\\big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the first inequality holds due to $\\mathrm{Var}[X]\\leq\\mathbb{E}[(X-t)^{2}]$ for any fixed $t$ , the second inequality follows $0\\leq\\Delta_{h}^{k}\\leq H$ .As a result, the total variance of the random variables $\\{\\eta^{k}\\}$ can be bounded by ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}\\operatorname{Var}[\\eta^{k}|\\mathcal{F}^{k}]\\leq\\sum_{k=1}^{K}H^{2}\\bigl(V_{1}^{*}(s_{1}^{k})-V_{h}^{\\pi^{k}}(s_{1}^{k})\\bigr)=H^{2}\\mathrm{Regret}(K).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Let $F(x)={\\sqrt{2x H^{2}\\log(x/\\delta)}}+H^{2}\\log(x/\\delta)$ , using peeling technique, we can write ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{\\mathcal{P}}_{\\mathbf{T}}\\Big[\\Big(\\displaystyle\\sum_{k=1}^{K}\\eta^{k}\\Big)\\geq F(\\mathrm{Regret}(K)),1<\\mathrm{Regret}(K)\\Big]}\\\\ &{=\\operatorname*{Pr}\\Big[\\Big(\\displaystyle\\sum_{k=1}^{K}\\eta^{k}\\Big)\\geq F(\\mathrm{Regret}(K)),1<\\mathrm{Regret}(K),\\displaystyle\\sum_{k=1}^{K}\\mathrm{Var}[\\eta^{k}|\\mathcal{F}^{k}]\\leq H^{2}\\mathrm{Regret}(K)\\Big]}\\\\ &{\\leq\\displaystyle\\sum_{i=1}^{\\infty}\\operatorname*{Pr}\\Big[\\Big(\\displaystyle\\sum_{k=1}^{K}\\eta^{k}\\Big)\\geq F(\\mathrm{Regret}(K)),2^{i-1}<\\mathrm{Regret}(K)\\leq2\\sum_{k=1}^{K}\\mathrm{Var}[\\eta^{k}|\\mathcal{F}^{k}]\\leq H^{2}\\mathrm{Regret}(K)\\Big]}\\\\ &{\\leq\\displaystyle\\sum_{i=1}^{\\infty}\\operatorname*{Pr}\\Big[\\Big(\\displaystyle\\sum_{k=1}^{K}\\eta^{k}\\Big)\\geq F(2),\\displaystyle\\sum_{k=1}^{K}\\mathrm{Var}[\\eta^{k}|\\mathcal{F}^{k}]\\leq2^{i}H^{2}\\Big]}\\\\ &{\\leq\\displaystyle\\sum_{i=1}^{\\infty}\\exp\\Big(\\frac{-F(2^{i})^{2}}{2^{i+1}H^{2}}2F(2^{i})H^{2}/3\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the last inequality follows Lemma H.5. Plugging $F(x)=\\sqrt{2x H^{2}\\log(x/\\delta)}+H^{2}\\log(x/\\delta)$ back into (D.21) yields ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\Big[\\Big(\\displaystyle\\sum_{k=1}^{K}\\eta^{k}\\Big)\\geq\\sqrt{2\\mathrm{Regret}(K)H^{2}\\log(\\mathrm{Regret}(K)/\\delta)}+H^{2}\\log(\\mathrm{Regret}(K)/\\delta),1<\\mathrm{Regret}(K)\\Big]}\\\\ &{\\leq\\displaystyle\\sum_{i=1}^{\\infty}\\exp(-\\log(2^{i}/\\delta))=\\displaystyle\\sum_{i=1}^{\\infty}\\delta/2^{i}=\\delta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Therefore, whenever Regret $(K)>1$ , with probability at least $1-\\delta$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\sum_{k=1}^{K}\\eta^{k}<{\\sqrt{2\\mathrm{Regret}(K)H^{2}\\log(\\mathrm{Regret}(K)/\\delta)}}+H^{2}\\log(\\mathrm{Regret}(K)/\\delta).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Combining with the fact that Regre $\\begin{array}{r}{\\dot{\\boldsymbol{\\mathbf{\\rho}}}(K)=\\sum_{k=1}^{K}\\eta^{k}+\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}.}\\end{array}$ we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\operatorname{Regret}(K)<\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+{\\sqrt{2\\mathrm{Regret}(K)H^{2}\\log(\\operatorname{Regret}(K)/\\delta)}}+H^{2}\\log(\\operatorname{Regret}(K)/\\delta),\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "whenever Regret(K) > 1. Taking x = Regret(K),\u03b1 = k=1 > $\\begin{array}{r}{a=\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+H^{2}\\log(\\operatorname{Regret}(K)/\\delta).}\\end{array}$ and $b=2H^{2}\\log(\\mathrm{Regret}(K)/\\delta)$ , inequality (1) yields ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle\\mathrm{Regret}(K)\\leq2\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+2H^{2}\\log(\\mathrm{Regret}(K)/\\delta)+4H^{2}\\log(\\mathrm{Regret}(K)/\\delta)}}\\\\ {{\\displaystyle~~~~~~~~~~~=2\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+6H^{2}\\log(1/\\delta)+6H^{2}\\log(\\mathrm{Regret}(K))}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "According to the fact that $x\\leq a\\log x+b\\Rightarrow x\\leq4a\\log(2a)+2b\\,$ letting $x=\\mathop{\\mathrm{Regret}}(K),a=$ $\\begin{array}{r}{2\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+6H^{2}\\log(1/\\delta)}\\end{array}$ and $b=6H^{2}$ , (D.22) becomes ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname{\\sfzegret}(K)\\leq\\left(8\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+24H^{2}\\log(1/\\delta)\\right)\\log\\left(4\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+12H^{2}\\log(1/\\delta)\\right)+12H^{2}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Hiding the logarithmic factors within the $\\widetilde O$ notation yields ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\operatorname{Regret}(K)<\\tilde{\\mathcal{O}}\\Big(\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\Delta_{h}^{k}+H^{2}\\log(1/\\delta)\\Big).\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "E Proof of Lemmas in Appendix D ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "In this section, we prove lemmas outlined in Appendix D. Any proofs not included in this section are deferred to Appendix F. ", "page_idx": 25}, {"type": "text", "text": "E.1 Proof of Lemma D.1 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "We first introduce the claim from Vial et al. (2022) controlling the rounding error: ", "page_idx": 25}, {"type": "text", "text": "Lemma E.1 (Claim 1, Vial et al. 2022, restate). For any $(k,h,l,s,a)\\in[K]\\times[H]\\times\\mathbb{N}^{+}\\times S\\times\\mathcal{A},$ wehave ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\phi(s,a)^{\\top}(\\mathbf{w}_{h,l}^{k}-\\widetilde{\\mathbf{w}}_{h,l}^{k})\\leq\\sqrt{d}\\kappa_{l},\\,\\big|\\|\\phi(s,a)_{(\\mathbf{U}_{h,l}^{k})^{-1}}-\\|\\phi(s,a)\\|_{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}}\\big|\\leq\\sqrt{d\\kappa_{l}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $\\kappa_{l}$ is used to quantify the vector $\\mathbf{w}_{h,l}^{k}$ and inverse matrix $(\\mathbf{U}_{h,l}^{l})^{-1}$ ", "page_idx": 25}, {"type": "text", "text": "Proof of Lemma $D.I$ . From Lemma E.1 we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\left\\langle\\phi(s,a),\\mathbf{w}_{h,l}^{k}\\right\\rangle-\\left\\langle\\phi(s,a),\\widetilde{\\mathbf{w}}_{h,l}^{k}\\right\\rangle\\right|\\leq\\sqrt{d}\\kappa_{l}\\leq0.01\\cdot2^{-4l}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the first inequality is due to Lemma E.1, and the second inequality is valid due to $\\kappa_{l}\\;=$ $0.01\\cdot2^{-4l}$ .Similarly,wehave ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\|\\phi(s,a)\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}-\\|\\phi(s,a)\\|_{\\widetilde{\\mathbf{U}}_{h,l}^{k,-1}}|\\leq\\sqrt{d\\kappa_{l}}\\leq0.1\\cdot2^{-2l}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "E.2Proof of Lemma D.2 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Proof of Lemma $D.2$ . First, both $l_{h}^{\\tau}(s_{h}^{\\tau})\\,=\\,l$ and $f_{h}^{\\tau}(s_{h}^{\\tau})=1$ held for any $\\tau\\in{\\mathcal{C}}_{h,l}^{k}$ This implies that the criteria for either Line 7 or Line 9 holds as $l=l_{h}^{\\tau}(s_{h}^{\\tau})$ . For $\\tau$ that satisfies the first criterion, we have $l_{h}^{\\tau}(s_{h}^{\\tau})>L_{\\tau}$ . Note that $L_{\\tau}=\\operatorname*{max}\\{\\lceil\\log_{4}(\\tau/d)\\rceil,0\\}$ , so this only happens for $\\tau<4^{l}d$ For other $\\tau$ that satisfies the second criterion, we have that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi_{h}^{\\tau}\\|_{(\\mathbf{U}_{h,l}^{\\tau})^{-1}}\\geq\\|\\phi_{h}^{\\tau}\\|_{\\widetilde{\\mathbf{U}}_{h,l}^{\\tau,-1}}-\\left|\\|\\phi_{h}^{\\tau}\\|_{\\widetilde{\\mathbf{U}}_{h,l}^{\\tau,-1}}-\\|\\phi_{h}^{\\tau}\\|_{(\\mathbf{U}_{h,l}^{\\tau})^{-1}}\\right|\\geq2^{-l}\\gamma_{l}^{-1}-0.1\\cdot2^{-l}\\gamma_{l}^{-1}=0.9\\cdot2^{-l}\\gamma_{l}^{-1}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the first inequality holds due to the triangle inequality. In the second inequality, the first term $\\|\\phi_{h}^{\\tau}\\|_{\\widetilde{\\mathbf{U}}_{h,l}^{\\tau,-1}}$ is bounded by criterion in Line 9 while the second term $||\\phi_{h}^{\\tau}||_{\\widetilde{\\mathbf{U}}_{h,l}^{\\tau,-1}}-\\overline{{||\\phi_{h}^{\\tau}||_{(\\mathbf{U}_{h,l}^{\\tau})^{-1}}}}|$ follows from Lemma D.1. ", "page_idx": 26}, {"type": "text", "text": "Arrange elements of $\\mathcal{C}_{h,l}^{k}$ in ascending order as $\\{\\tau_{i}\\}_{i}$ . According to the above reasoning, the number of elements $\\tau\\in\\mathcal{C}_{h,l}^{k}$ that $\\|\\phi_{h}^{\\tau}\\|_{(\\mathbf{U}_{h,l}^{\\tau})^{-1}}\\geq0.9\\cdot2^{-l}\\gamma_{l}^{-1}$ is at least $|\\mathcal{C}_{h,l}^{k}|-4^{l}d$ This gives ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{|\\mathcal{C}_{h,l}^{k}|}\\operatorname*{min}\\{1,\\|\\phi_{h}^{\\tau}\\|_{(\\mathbf{U}_{h,l}^{\\tau})^{-1}}^{2}\\}\\ge(0.9\\cdot2^{-l}\\gamma_{l}^{-1})^{2}\\cdot(|\\mathcal{C}_{h,l}^{k}|-4^{l}d).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "On the other hand, Lemma H.1 upper bounds the LHS of (E.1) by ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{|\\mathcal{C}_{h,l}^{k}|}\\operatorname*{min}\\{1,\\|\\phi_{h}^{\\tau}\\|_{(\\mathbf{U}_{h,l}^{\\tau})^{-1}}^{2}\\}\\le2d\\ln\\big(1+|\\mathcal{C}_{h,l}^{k}|/(d\\lambda)\\big).\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Combining (E.1) and (E.2) gives ", "page_idx": 26}, {"type": "equation", "text": "$$\n0.81\\cdot4^{-l}\\gamma_{l}^{-2}(|\\mathcal{C}_{h,l}^{k}|-4^{l}d)\\leq2d\\ln\\left(1+|\\mathcal{C}_{h,l}^{k}|/(16d)\\right)\\!.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "From algebra analysis in Lemma G.1, a necessary condition for (E.3) is $|\\mathcal{C}_{h,l}^{k}|\\leq16l\\cdot4^{l}\\gamma_{l}^{2}d$ ", "page_idx": 26}, {"type": "text", "text": "E.3Proof of Lemma D.3 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "We first present a claim from Vial et al. (2022) controlling the infinite norm of coefficient w. ", "page_idx": 26}, {"type": "text", "text": "Lemma E.2 (Claim 10, Vial et al. 2022). For any $(k,h,l)\\in[K]\\times[H]\\times\\mathbb{N}^{+}$ ,we have $\\|\\mathbf{w}_{h,l}^{k}\\|_{\\infty}\\leq$ $\\|\\mathbf{w}_{h,l}^{k}\\|_{2}\\leq(2^{l}d H)^{4}$ ", "page_idx": 26}, {"type": "text", "text": "Proof of Lemma $D.3$ Denote $\\mathscr{X}_{\\ell}$ as the set of all $\\widetilde{\\mathbf{w}}_{h,\\ell}^{k}$ and $\\mathscr{y}_{\\ell}$ as the set of all $\\widetilde{\\mathbf{U}}_{h,\\ell}^{k,-1}$ . From the definition of $\\mathcal{V}_{h,l}^{k}$ we have that $\\begin{array}{r}{|\\nu_{h,l}^{k}|\\leq\\prod_{\\ell=1}^{l}\\left(|\\mathcal{X}_{\\ell}|\\cdot|\\mathcal{Y}_{\\ell}|\\right)}\\end{array}$ From Lemma E.2, we have $\\|\\mathbf{w}_{h,\\ell}^{k}\\|_{\\infty}\\leq$ $(2^{\\ell}d H)^{4}$ . Note that $\\mathbf{w}_{h,\\ell}^{k}\\in\\mathbb{R}^{d}$ wehave thenumerfdie $\\widetilde{\\mathbf{w}}_{h,\\ell}^{k}$ controlled by ", "page_idx": 26}, {"type": "equation", "text": "$$\n|\\mathcal{X}_{\\ell}|\\leq(1+2\\cdot(2^{\\ell}d H)^{4}/\\kappa_{\\ell})^{d}\\leq(2\\cdot(2^{\\ell}d H)^{4}\\cdot2^{6+4\\ell}d)^{d}\\leq2^{(7+8\\ell)d}d^{5d}H^{4d}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "In addition, we have $\\|(\\mathbf{U}_{h,l}^{k})^{-1}\\|_{\\infty}\\leq1/\\lambda=1/16$ So we can bound the number of $\\widetilde{\\mathbf{U}}_{h,\\ell}^{k,-1}$ by ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\mathcal{Y}_{\\ell}|\\leq(1+2\\cdot1/(16\\kappa_{\\ell}))^{d^{2}}\\leq(2\\cdot2^{2+4\\ell}d)^{d^{2}}\\leq2^{(3+4\\ell)d^{2}}d^{d^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "As a result, we can conclude that ", "page_idx": 26}, {"type": "equation", "text": "$$\n|\\mathcal{V}_{h,l}^{k}|\\leq\\prod_{\\ell=1}^{l}\\big(|\\mathcal{X}_{\\ell}|\\cdot|\\mathcal{V}_{\\ell}|\\big)\\leq\\prod_{\\ell=1}^{l}\\big(2^{(7+8\\ell)d}d^{5d}H^{4d}\\cdot2^{(3+4\\ell)d^{2}}d^{d^{2}}\\big)\\leq\\big(2^{22}d^{5}H^{4}\\big)^{l^{2}d^{2}}.\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "E.4Proof of Lemma D.4 ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Proof of Lemma $D.4.$ According to Proposition 3.2, there exists a parameter $\\mathbf{w}_{h}$ such that for any $(s,a)\\in S\\times A$ it holds that $\\big|\\langle\\phi(s,a),\\mathbf{w}_{h}\\rangle-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big|\\le2H\\zeta$ . Denoting $\\eta_{h}^{\\tau}=\\langle\\phi_{h}^{\\tau},\\mathbf{w}_{h}\\rangle-$ $[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})$ and $\\varepsilon_{h}^{\\tau}=\\big(\\widehat{V}_{h+1}^{k}(s_{h+1}^{\\tau})-[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})\\big)$ , we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathcal{V}_{h,l}^{k}(\\mathbf{w}_{h,l}^{k}-\\mathbf{w}_{h})=\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\Bigl(r_{h}^{\\tau}+\\hat{V}_{h+1}^{k}\\bigl(s_{h+1}^{\\tau}\\bigr)\\Bigr)-\\Bigl(\\lambda\\mathbf{I}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}(\\phi_{h}^{\\tau})^{\\top}\\Bigr)\\mathbf{w}_{h}}&{}\\\\ {=-\\lambda\\mathbf{w}_{h}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\Bigl(r_{h}^{\\tau}+\\hat{V}_{h+1}^{k}\\bigl(s_{h+1}^{\\tau}\\bigr)-\\bigl\\langle\\phi_{h}^{\\tau},\\mathbf{w}_{h}\\bigr\\rangle\\Bigr)}&{}\\\\ {=-\\lambda\\mathbf{w}_{h}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\Bigl(r_{h}^{\\tau}+\\hat{V}_{h+1}^{k}\\bigl(s_{h+1}^{\\tau}\\bigr)-\\bigl\\lbrack\\mathbb{B}_{h}\\hat{V}_{h+1}^{k}\\bigl(s_{h}^{\\tau},a_{h}^{\\tau}\\bigr)\\Bigr)+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}}&{}\\\\ {=-\\lambda\\mathbf{w}_{h}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\varepsilon_{h}^{\\tau}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau},}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "wherethqualldde $\\mathbf{U}_{h,l}^{k},\\mathbf{w}_{h,l}^{k}$ the second eqguality holds by rarranging the terms, the third equality holds according the definition of $\\eta_{h}^{\\tau}$ , and the last equality holds from the relationship that $\\[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})\\,=\\,r_{h}^{\\tau}+[\\mathbb{P}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{\\tau},a_{h}^{\\tau})$ . Therefore, for any vector $\\phi\\in\\mathbb{R}^{d}$ , it holds that ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\left<\\phi,\\mathbf{w}_{h,l}^{k}-\\mathbf{w}_{h}\\right>\\right|=\\left|\\phi^{\\top}\\!\\left(\\mathbf{U}_{h,l}^{k}\\right)^{-1}\\mathbf{U}_{h,l}^{k}(\\mathbf{w}_{h,l}^{k}-\\mathbf{w}_{h})\\right|}\\\\ &{\\qquad\\qquad=\\left|\\phi^{\\top}\\!\\left(\\mathbf{U}_{h,l}^{k}\\right)^{-1}\\cdot\\left(-\\lambda\\mathbf{w}_{h}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\varepsilon_{h}^{\\tau}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\right)\\right|}\\\\ &{\\qquad\\qquad\\leq\\|\\phi\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\right|-\\lambda\\mathbf{w}_{h}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\varepsilon_{h}^{\\tau}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\right|\\!\\Bigg|_{(\\mathbf{U}_{h,l}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the second equality follows (E.4) and the inequality holds from Cauchy-Schwarz inequality (i.e., $|\\mathbf{x}^{\\top}\\mathbf{U}\\mathbf{y}|\\leq\\|\\mathbf{x}\\|\\mathbf{u}\\|\\mathbf{\\dot{y}}\\|\\mathbf{u})$ . From the triangle inequality, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|-\\lambda\\mathbf{w}_{h}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\varepsilon_{h}^{\\tau}+\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}}\\\\ &{\\leq\\lambda\\|\\mathbf{w}_{h}\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}+\\left\\|\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\varepsilon_{h}^{\\tau}\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}+\\left\\|\\displaystyle\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "There are three terms which we will bound respectively. For the first term, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\lambda\\|\\mathbf{w}_{h}\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq2\\sqrt{d\\lambda}H\\leq0.1\\gamma_{l},\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the first inequality holds due to the fact that $\\|\\mathbf{w}_{h}\\|_{2}\\leq2H{\\sqrt{d}}$ as of Proposition 3.2 and the fact that $\\mathbf{U}_{h,l}^{k}\\succeq\\lambda\\mathbf{I}$ . Under the good event $\\mathcal{G}_{1}$ and Lemma C.5, the second term can be bounded by the following: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\varepsilon_{h}^{\\tau}\\right\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq1.1\\gamma_{l}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "And the last term can be bounded by: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\bigg\\|\\sum_{\\tau\\in\\mathcal{C}_{h,l}^{k-1}}\\phi_{h}^{\\tau}\\eta_{h}^{\\tau}\\bigg\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}\\leq2H\\zeta\\sqrt{|\\mathcal{C}_{h,l}^{k}|}\\leq2H\\zeta\\sqrt{16l\\cdot4^{l}\\gamma_{l}^{2}d}=8\\sqrt{l d}H\\cdot2^{l}\\gamma_{l}\\zeta,\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the first inequality is due to Lemma H.3, and the second inequality follows from Lemma D.2. Plugging (E.6), (E.7), (E.8), and (E.9) into (E.5) gives ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left|\\left\\langle\\phi,\\mathbf{w}_{h,l}^{k}-\\mathbf{w}_{h}\\right\\rangle\\right|\\leq\\left(1.2\\gamma_{l}+8\\sqrt{l d}H\\cdot2^{l}\\gamma_{l}\\zeta\\right)\\|\\phi\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "So for any $(s,a)\\in S\\times A$ , we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big|Q_{h,l}^{k}(s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big|=\\big|\\big\\langle\\phi(s,a),\\widetilde{\\mathbf{w}}_{h,l}^{k}\\big\\rangle-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big|}\\\\ &{\\leq\\big|\\big\\langle\\phi(s,a),\\widetilde{\\mathbf{w}}_{h,l}^{k}-\\mathbf{w}_{h,l}^{k}\\big\\rangle\\big|+\\big|\\big\\langle\\phi(s,a),\\mathbf{w}_{h,l}^{k}-\\mathbf{w}_{h}\\big\\rangle\\big|+\\big|\\big\\langle\\phi(s,a),\\mathbf{w}_{h}\\big\\rangle-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big|}\\\\ &{\\leq0.01\\cdot2^{-4l}+\\big(1.2+8\\sqrt{l d}H\\cdot2^{l}\\zeta\\big)\\gamma_{l}\\|\\phi(s,a)\\|_{(\\mathbf{U}_{h,l}^{k})^{-1}}+2H\\zeta.\\qquad\\qquad\\qquad\\qquad(\\mathrm{E}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the first inequality holds from the triangle inequality, and there are three terms in the second inequality which we will bound them respectively: the first term is given by Lemma D.1, the second term follows (E.10), and the third term holds from the definition of $\\mathbf{w}_{h}$ \u53e3 ", "page_idx": 27}, {"type": "text", "text": "E.5 Proof of Lemma D.5 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proof of Lemma D.5. We prove by doing case analysis. In case that action $a_{l}\\in\\mathcal{A}_{h,l+1}^{k}(s)$ ,we can assign $a_{l+1}=a_{l}\\in\\mathcal{A}_{h,l+1}^{k}(s)$ so that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "On the other hand, in the case that $a_{l}\\notin\\mathcal{A}_{h,l+1}^{k}(s)$ ,the action $a_{l}$ is eliminated with $Q_{h,l}^{k}(s,a_{l})\\,<$ $V_{h,l}^{k}(s)-4\\cdot2^{-l}$ Note in this case,there exists $a_{l+1}=\\pi_{h,l}^{k}(s)\\in\\mathcal{A}_{h,l+1}^{k}(s)$ suchthat ", "page_idx": 28}, {"type": "equation", "text": "$$\nQ_{h,l}^{k}(s,a_{l})+4\\cdot2^{-l}<V_{h,l}^{k}(s)=Q_{h,l}^{k}(s,a_{l+1}).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "According to Lemma C.6 and the condition that $l\\leq L_{0}$ , we have that empirical state-value function $Q_{h,l}^{k}(s,\\cdot)$ is a good estimation for $[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\cdot)$ on actions $a_{l},a_{l+1}\\in\\mathcal{A}_{l}^{k}(s)$ under event $\\mathcal{G}_{1}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{\\big|[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-Q_{h,l}^{k}(s,a_{l})\\big|\\leq2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta}\\\\ &{}&{\\big|[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})-Q_{h,l}^{k}(s,a_{l+1})\\big|\\leq2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Moreover, ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})}\\\\ &{=\\bigl([\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-Q_{h,l}^{k}(s,a_{l})\\bigr)}\\\\ &{\\quad+\\left(Q_{h,l}^{k}(s,a_{l})-Q_{h,l}^{k}(s,a_{l+1})\\right)+\\bigl(Q_{h,l}^{k}(s,a_{l+1})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})\\bigr)}\\\\ &{\\leq2\\cdot\\bigl(2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta\\bigr)-4\\cdot2^{-l}}\\\\ &{=2\\chi\\sqrt{L_{0}}\\zeta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the first inequality is derived from combining (E.13), (E.14), and (E.15). So from (E.12) and (E.16), we have that $\\lbrack\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](\\bar{s},a_{l+1})\\leq2\\chi\\sqrt{L_{0}}\\zeta$ holds in both cases. \u53e3 ", "page_idx": 28}, {"type": "text", "text": "E.6Proof of Lemma D.6 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proof of Lemma $D.6$ We prove by induction on $l$ . The induction basis holds at $l=0$ by selecting $a_{1}=\\operatorname{argmax}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\in\\mathcal{A}$ which ensures $\\begin{array}{r}{\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{1})=}\\end{array}$ 0. Additionally, if the induction hypothesis holds for $l-1$ , we have that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{a\\in A}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})}\\\\ &{=\\big(\\underset{a\\in A}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})\\big)+\\big([\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l+1})\\big)}\\\\ &{\\leq2(l-1)\\chi\\sqrt{L_{0}}\\zeta+2\\chi\\sqrt{L_{0}}\\zeta}\\\\ &{=2l\\cdot\\chi\\sqrt{L_{0}}\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the first inequality term is derived from combining induction hypothesis with Lemma D.5. We can then reach desired statement holds for all $l$ in the range by induction. \u53e3 ", "page_idx": 28}, {"type": "text", "text": "E.7Proof of Lemma D.7 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proof of Lemma D.7. According to Lemma D.6, there exists some action $a_{l}\\in A_{h,l}^{k}(s)$ that ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})\\leq2(l-1)\\chi\\sqrt{L_{0}}\\zeta.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Moreover, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-V_{h,l}^{k}(s)\\le[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a_{l})-Q_{h,l}^{k}(s,a_{l})\\le2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the first inequality comes from the definition $\\begin{array}{r}{V_{h,l}^{k}(s)=\\operatorname*{max}_{a\\in\\mathcal{A}_{h,l}^{k}}Q_{h,l}^{k}(s,a)}\\end{array}$ and the second inequality holds according to Lemma C.6 with $l\\leq L_{0}$ . Adding up (E.17) and (E.18) leads to ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-V_{h,l}^{k}\\leq2\\cdot2^{-l}+(2l-1)\\chi\\sqrt{L_{0}}\\zeta.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "This completes the proof. ", "page_idx": 28}, {"type": "text", "text": "E.8 Proof of Lemma D.8 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Proof of Lemma $D.8$ The statement holds by simply checking: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{h,l}^{k}(s)-\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\leq V_{h,l}^{k}(s)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h,l}^{k}(s))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=Q_{h,l}^{k}(s,\\pi_{h,l}^{k}(s))-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h,l}^{k}(s))}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the first inequality holds from $\\begin{array}{r}{\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\ge[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h,l}^{k}(s))}\\end{array}$ , the equality is from the definition $V_{h,l}^{k}(s)=Q_{h,l}^{k}\\bigl(s,\\pi_{h,l}^{k}(s)\\bigr)$ , and the last inequality holds according to Lemma C.6 with the condition $l\\leq L_{0}$ \u53e3 ", "page_idx": 29}, {"type": "text", "text": "E.9Proof of Lemma D.9 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Proof of Lemma $D.9.$ The statement holds by checking ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\operatorname*{min}\\left\\{V_{h,l}^{k}(s)+3\\cdot2^{-l},\\widehat{V}_{h,l-1}^{k}(s)\\right\\}-\\underset{a\\in A}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)}\\\\ &{=\\underset{\\ell=1}{\\operatorname*{min}}\\{V_{h,\\ell}^{k}(s)+3\\cdot2^{-\\ell}\\}-\\underset{a\\in A}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)}\\\\ &{\\geq\\underset{\\ell=1}{\\operatorname*{min}}\\{3\\cdot2^{-\\ell}-(2\\cdot2^{-l}+(2\\ell-1)\\chi\\sqrt{L_{0}}\\zeta)\\}}\\\\ &{=2^{-l}-(2l-1)\\chi\\sqrt{L_{0}}\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the frs eqgulitg holds due toe $\\widehat V_{h,l}^{k}(s)\\,=\\,\\operatorname*{min}_{\\ell=1}^{l}\\{V_{h,\\ell}^{k}(s)\\,+\\,3\\,\\cdot\\,2^{-\\ell}\\}$ , the ineqgulty holds according to Lemma D.7, and the last equality holds since $2^{-l}$ decreases as $l$ increases. \u53e3 ", "page_idx": 29}, {"type": "text", "text": "E.10 Proof of Lemma D.10 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Proof of Lemma $D.I O$ .The statement holds by checking ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{a\\in A}{\\mathrm{max}}[\\mathbb{B}_{h}\\hat{V}_{h+1}^{k}](s,a)-\\operatorname*{max}\\big\\{V_{h,l}^{k}(s)-3\\cdot2^{-l},\\breve{V}_{h,l-1}^{k}(s)\\big\\}}\\\\ &{=\\underset{a\\in A}{\\mathrm{max}}[\\mathbb{B}_{h}\\hat{V}_{h+1}^{k}](s,a)-\\underset{\\ell=1}{\\mathrm{max}}\\{V_{h,\\ell}^{k}(s)-3\\cdot2^{-\\ell}\\}}\\\\ &{=\\underset{\\ell=1}{\\mathrm{min}}\\big\\{\\underset{a\\in A}{\\mathrm{max}}[\\mathbb{B}_{h}\\hat{V}_{h+1}^{k}](s,a)-V_{h,\\ell}^{k}(s)+3\\cdot2^{-\\ell}\\big\\}}\\\\ &{\\geq\\underset{\\ell=1}{\\mathrm{min}}\\big\\{-(2\\cdot2^{-l}+\\chi\\sqrt{L_{0}}\\zeta)+3\\cdot2^{-\\ell}\\big\\}}\\\\ &{=2^{-l}-\\chi\\sqrt{L_{0}}\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the first equality holds due to the design of Algorithm 2 such that $\\begin{array}{r l}{\\check{V}_{h,l}^{k}(s)}&{{}=}\\end{array}$ $\\operatorname*{max}_{\\ell=1}^{l}\\{V_{h,\\ell}^{k}(s)\\,-\\,3\\,\\cdot\\,2^{-\\ell}\\}$ the inequalityl acorng tLa and thlastquality holds since $2^{-l}$ decreases as $l$ increases. \u53e3 ", "page_idx": 29}, {"type": "text", "text": "E.11 Proof of Lemma D.11 ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "We prove Lemma D.11 in this subsection. The first lemma which we introduce establishes an upper bound on the underestimation of the state value function $\\widehat V_{h}^{k}$ for every action and every state through a categorised discussion based on whether Algorithm 2 reaches phase $L_{\\varepsilon}$ for state $s$ .Specifically, if the process does not reach phase $L_{\\varepsilon}$ , we can substantiate the statement by applying Lemma D.9 to phase $l_{h}^{k}(s)-1$ : Conversely, if the process reaches phase $L_{\\varepsilon}$ , the statement can be proven by applying Lemma D.7 to phase $L_{\\varepsilon}$ ", "page_idx": 29}, {"type": "text", "text": "Lemma E.3. Under event $\\mathcal{G}_{1}$ and for all $\\varepsilon>0$ that $\\mathcal{G}_{\\varepsilon}$ is satisfied, for any $(k,h,s)\\in[K]\\times[H]\\times{\\cal{S}}.$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\cal A}[\\mathbb{B}_{h}\\widehat V_{h+1}^{k}](s,a)-\\widehat V_{h}^{k}(s)\\leq0.07\\varepsilon/H.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Now we are ready to prove Lemma D.11 by induction. ", "page_idx": 30}, {"type": "text", "text": "Proof of Lemma $D.I I$ We prove by induction on stage $\\textit{h}\\in[H]$ . It is suficient to show for any $h\\in[H],s\\in S$ ", "page_idx": 30}, {"type": "equation", "text": "$$\nV_{h}^{*}(s)-\\widehat{V}_{h}^{k}(s)\\leq0.07\\varepsilon\\cdot(H+1-h)/H.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "We use induction on $h$ from $H+1$ to 1 to prove the statement. The induction basis holds from the definition that $V_{H+1}^{*}(s)=\\widehat{V}_{H+1}^{k}(s)=0$ Assume the induction hypothesis (E.19) holds for $h+1$ wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}V_{h+1}^{*}](s,a)-\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\leq\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}(V_{h+1}^{*}-\\widehat{V}_{h+1}^{k})](s,a)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\underset{s^{\\prime}\\in\\mathcal{S}}{\\operatorname*{max}}\\left(V_{h+1}^{*}(s^{\\prime})-\\widehat{V}_{h+1}^{k}(s^{\\prime})\\right)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq0.07\\varepsilon\\cdot(H-h)/H.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "So for level $h$ , it holds that ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad V_{h}^{*}(s)-\\widehat{V}_{h}^{k}(s)}\\\\ &{=\\Big(\\displaystyle\\operatorname*{max}_{a\\in A}[\\mathbb{B}_{h}V_{h+1}^{*}](s,a)-\\displaystyle\\operatorname*{max}_{a\\in A}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big)+\\big(\\displaystyle\\operatorname*{max}_{a\\in A}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-\\widehat{V}_{h}^{k}(s)\\big)}\\\\ &{\\leq0.07\\varepsilon\\cdot(H-h)/H+0.07\\varepsilon/H\\leq0.07\\varepsilon\\cdot(H+1-h)/H,}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where the first inequality holds by combining (E.20) with Lemma E.3. This proves the induction statement (E.19) for $h$ , which leads to the desired statement. \u53e3 ", "page_idx": 30}, {"type": "text", "text": "E.12 Proof of Lemma D.12 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "We prove Lemma D.12 in this subsection, the first lemma we use establishes an upper bound on the overestimation of the state value function $\\widehat V_{h}^{k}$ for the executed policy $\\pi_{h}^{k}(s)$ across all states. ", "page_idx": 30}, {"type": "text", "text": "Lemma E.4. Under event $\\mathcal{G}_{1}$ and for all $\\varepsilon>0$ that $\\mathcal{G}_{\\varepsilon}$ is satisfied, for any $(k,h,s)\\in[K]\\times[H]\\times{\\cal{S}},$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h}^{k}(s))\\leq16\\cdot2^{-l_{h}^{k}(s)}+0.10\\varepsilon/H.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then the following lemma establishes an upper bound on the decision error induced by the armelimination process with respect to the state-action value function given by the ground-truth transform. ", "page_idx": 30}, {"type": "text", "text": "Lemma E.5. Under event $\\mathcal{G}_{1}$ and for all $\\varepsilon>0$ that $\\mathcal{G}_{\\varepsilon}$ is satisfied, for any $(k,h,s)\\in[K]\\times[H]\\times{\\cal{S}}.$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\widehat V_{h}^{k}(s)-\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb B_{h}\\widehat V_{h+1}^{k}](s,a)\\leq10\\cdot2^{-l_{h}^{k}(s)}+0.06\\varepsilon/H.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proofof Lemma $D.I2$ .We can directly reach the desired result by taking summation on Lemma E.4 and Lemma E.5: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{V}_{h}^{k}(s)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h}^{k}(s))}\\\\ &{\\ \\leq\\big(\\displaystyle\\operatorname*{max}_{a\\in A}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h}^{k}(s))\\big)+\\big(\\widehat{V}_{h}^{k}(s)-\\displaystyle\\operatorname*{max}_{a\\in A}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big)}\\\\ &{\\ \\leq\\big(16\\cdot2^{-l_{h}^{k}(s)}+0.10\\varepsilon/H\\big)+\\big(10\\cdot2^{-l_{h}^{k}(s)}+0.06\\varepsilon/H\\big)}\\\\ &{\\ =26\\cdot2^{-l_{h}^{k}(s)}+0.16\\varepsilon/H.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "E.13 Proof of Lemma D.14 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "We can prove the statement by applying a union bound to the concentration event, as given by the Azuma-Hoeffding inequality. ", "page_idx": 30}, {"type": "text", "text": "Proof of Lemma $D.I4.$ Consider some fixed $h\\in[H]$ and $\\varepsilon=2^{-l}>0$ . List the episodes index $k$ such that $V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})>\\varepsilon$ holds in ascending order as $\\{\\tau_{i}\\}_{i}$ . Recall that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\eta_{h}^{\\tau_{i}}=[\\mathbb{P}_{h}(\\widehat{V}_{h+1}^{\\tau_{i}}-V_{h+1}^{\\pi^{\\tau_{i}}})](s_{h}^{\\tau_{i}},\\pi_{h}^{\\tau_{i}}(s_{h}^{\\tau_{i}}))-(\\widehat{V}_{h+1}^{\\tau_{i}}(s_{h+1}^{\\tau_{i}})-V_{h+1}^{\\pi^{\\tau_{i}}}(s_{h+1}^{\\tau_{i}})).\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Since the environment sample $s_{h^{\\prime}+1}^{\\tau_{i}}$ according to $\\mathbb{P}_{h^{\\prime}}(\\cdot|s_{h^{\\prime}}^{\\tau_{i}},a_{h^{\\prime}}^{\\tau_{i}})$ we have $\\eta_{h^{\\prime}}^{\\tau_{i}}$ .s $\\mathcal{F}_{h^{\\prime}+1}^{\\tau_{i}}$ -measurable Wwith $\\mathbb{E}\\left[\\eta_{h^{\\prime}}^{\\tau_{i}}\\vert\\mathcal{F}_{h^{\\prime}}^{\\tau_{i}}\\right]=0$ Since both $0\\,\\leq\\,\\widehat{V}_{h^{\\prime}+1}^{\\tau_{i}}(s_{h^{\\prime}+1}^{\\tau_{i}})\\,\\leq\\,H$ and $0\\,\\leq\\,V_{h^{\\prime}+1}^{\\pi^{\\tau_{i}}}(s_{h^{\\prime}+1}^{\\tau_{i}})\\,\\leq\\,H$ hold, we have $|\\eta_{h^{\\prime}}^{\\tau_{i}}|\\leq2H$ . According to Lemma H.4 over fitration ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\mathcal{F}_{h}^{\\tau_{1}}\\subseteq\\mathcal{F}_{h+1}^{\\tau_{1}}\\subseteq\\dots\\subseteq\\mathcal{F}_{H}^{\\tau_{1}}\\subseteq\\mathcal{F}_{h}^{\\tau_{2}}\\subseteq\\mathcal{F}_{h+1}^{\\tau_{2}}\\subseteq\\dots\\subseteq\\mathcal{F}_{H}^{\\tau_{2}}\\subseteq\\dots\\subseteq\\mathcal{F}_{h^{\\prime}}^{\\tau_{i}}\\subseteq\\dots.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "for some fixed $S=|\\kappa_{h}^{\\varepsilon}|$ , the good event that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{|\\mathcal{K}_{h}^{\\varepsilon}|}\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{\\tau_{i}}\\leq2H\\sqrt{2H S\\log(4H S^{2}l^{2}/\\delta)}=4\\sqrt{H^{3}|\\mathcal{K}_{h}^{\\varepsilon}|\\log(4H|\\mathcal{K}_{h}^{\\varepsilon}|\\log(\\varepsilon^{-1})/\\delta)}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "happens with probability at least $1-\\delta/(4H S^{2}l^{2})$ . By the union bound statement over all $(h,S,l)\\in$ $[H]\\times[K]\\times\\mathbb{N}^{+}$ , we have the bad event happens with probability at most ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}[\\mathcal{G}_{2}^{\\sf E}]\\leq\\sum_{h=1}^{H}\\sum_{S=1}^{K}\\sum_{l=1}^{\\infty}\\operatorname*{Pr}[\\mathcal{B}_{2}(h,2^{-l})]\\leq\\sum_{h=1}^{H}\\sum_{S=1}^{K}\\sum_{l=1}^{\\infty}\\frac{\\delta}{4H S^{2}l^{2}}\\leq\\delta,\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the last inequality holds from $\\begin{array}{r}{\\sum_{n\\geq1}n^{-2}=\\pi^{2}/6}\\end{array}$ which reach the desired statement. ", "page_idx": 31}, {"type": "text", "text": "E.14 Proof of Lemma D.15 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "We first provide the following instantaneous regret upper bound by combining Lemma D.11 and Lemma D.12. ", "page_idx": 31}, {"type": "text", "text": "Lemma E.6. Under event $\\mathcal{G}_{1}$ and for all $\\varepsilon>0$ that $\\mathcal{G}_{\\varepsilon}$ is satisfied, for any $(k,h)\\in[K]\\times[H]$ ", "page_idx": 31}, {"type": "equation", "text": "$$\nV_{h}^{*}(s_{h}^{k})-{V_{h}^{\\pi^{k}}(s_{h}^{k})}\\le0.23\\varepsilon+26\\sum_{h^{\\prime}=h}^{H}2^{-l_{h^{\\prime}}^{k}(s_{h^{\\prime}}^{k})}+\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{k},\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where $\\eta_{h}^{k}=[\\mathbb{P}_{h}(\\widehat{V}_{h+1}^{k}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))-(\\widehat{V}_{h+1}^{k}(s_{h+1}^{k})-V_{h+1}^{\\pi^{k}}(s_{h+1}^{k}))$ isa $\\mathcal{F}_{h+1}^{k}$ measurable random variable that $\\mathbb{E}[\\eta_{h}^{k}|\\mathcal{F}_{h}^{k}]=0$ and $|\\eta_{h}^{k}|\\leq H$ ", "page_idx": 31}, {"type": "text", "text": "Together with Lemma C.9 and the definition of $\\mathcal{G}_{2}$ , we can provide an upper bound for arbitrary subsets. ", "page_idx": 31}, {"type": "text", "text": "Proof of Lemma D.15. Taking summation on result given by Lemma E.6 to all $k\\in\\mathcal{K}$ gives ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{k\\in K}\\left(V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\right)\\le0.23|K|\\varepsilon+26\\sum_{k\\in K}\\sum_{h^{\\prime}=h}^{H}2^{-l_{h^{\\prime}}^{k}(s_{h^{\\prime}}^{k})}+\\sum_{k\\in K}\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{k}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "We can bound the second term according to Lemma C.9 ", "page_idx": 31}, {"type": "equation", "text": "$$\n26\\sum_{k\\in K}\\sum_{h^{\\prime}=h}^{H}2^{-l_{h^{\\prime}}^{k}(s_{h^{\\prime}}^{k})}\\leq0.26|K|\\varepsilon+2^{17}L_{\\varepsilon}d H^{2}\\gamma_{L_{\\varepsilon}}^{2}\\varepsilon^{-1}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Under event $\\mathcal{G}_{2}$ , the third term satisfies that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{k\\in K}\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{k}\\leq4\\sqrt{H^{3}|K|\\log(4H|K|\\log(\\varepsilon^{-1})/\\delta)}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Plugging (E.22) and (E.23) into (E.21) gives ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\sum_{k\\in\\mathcal{K}}\\left(V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\right)\\leq0.49|K|\\varepsilon+2^{17}L_{\\varepsilon}d H^{2}\\gamma_{L_{\\varepsilon}\\varepsilon}^{2}\\varepsilon^{-1}+4\\sqrt{H^{3}|K|\\log(4H|K|\\log(\\varepsilon^{-1})/\\delta)}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "F Proof of Lemmas in Appendix E ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "F.1Proof of Lemma E.3 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Proof of Lemma $E.3$ We start the proof by discussing different cases. First, if $l_{h}^{k}(s)\\leq L_{\\varepsilon}$ ,wehave $l_{h}^{k}(s)-1\\leq\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ according to the definition of $\\widehat{V}_{h,l}^{k}(s)$ \uff0c ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-\\widehat{V}_{h}^{k}(s)=\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-\\widehat{V}_{h,l_{h}^{k}(s)-1}^{k}(s)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq-2^{-(l_{h}^{k}(s)-1)}+2(l_{h}^{k}(s)-1)\\chi\\sqrt{L_{\\varepsilon}}\\zeta}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq0+2\\chi L_{\\varepsilon}^{1.5}\\zeta}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq0.02\\varepsilon/H,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality holds from Lemma D.9, and the last inequality holds due to $\\chi L_{\\varepsilon}^{1.5}\\zeta\\leq$ $2^{-L_{\\varepsilon}}\\leq0.01\\varepsilon/H$ givenby $\\mathcal{G}_{\\varepsilon}$ ", "page_idx": 32}, {"type": "text", "text": "On the other hand, when $l_{h}^{k}(s)>L_{\\varepsilon}$ , we have $L_{\\varepsilon}\\leq\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ and thus ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\widehat{V}_{h}^{k}(s)\\geq\\breve{V}_{h,L_{\\varepsilon}}^{k}(s)\\geq V_{h,L_{\\varepsilon}}^{k}(s)-3\\cdot2^{-L_{\\varepsilon}}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality is due to Lemma C.2 and the second inequality holds due to the definition of $\\check{V}_{h,L_{\\varepsilon}}^{k}(s)$ .Therefore, $L_{\\varepsilon}\\leq\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ yields ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\operatorname*{max}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-\\widehat{V}_{h}^{k}(s)\\leq\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-V_{h,L_{\\varepsilon}}^{k}(s)+3\\cdot2^{-L_{\\varepsilon}}}}\\\\ &{\\leq5\\cdot2^{-L_{\\varepsilon}}+(2L_{\\varepsilon}-1)\\chi\\sqrt{L_{\\varepsilon}}\\zeta}\\\\ &{\\leq0.05\\varepsilon/H+0.02\\varepsilon/H=0.07\\varepsilon/H,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality is given by (F.2), the second inequality is given by Lemma D.7, and the last inequality holds from $\\chi\\bar{L}_{\\varepsilon}^{1.5}\\zeta\\leq2^{-L_{\\varepsilon}}\\leq0.01\\varepsilon/H$ givenby $\\mathcal{G}_{\\varepsilon}$ . So considering both (F.1) and (F.3), we have the first statement ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\cal A}[\\mathbb{B}_{h}\\widehat V_{h+1}^{k}](s,a)-\\widehat V_{h}^{k}(s)\\leq0.07\\varepsilon/H\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "always holds under event $\\mathcal{G}_{1}$ ", "page_idx": 32}, {"type": "text", "text": "F.2Proof of Lemma E.4 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We prove Lemma E.4 by applying Lemma C.7 on phase $\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ , in this subsection. ", "page_idx": 32}, {"type": "text", "text": "Prof f Lema E.4 Note we have $\\pi_{h,l_{h}^{k}(s)-1}^{k}(s)\\ \\in\\ A_{h,l_{h}^{k}(s)}^{k}(s)$ acording t the deiniton o $\\mathcal{A}_{h,l+1}^{k}(s)$ This implies $\\pi_{h}^{k}(s)\\in\\mathcal{A}_{h,l_{h}^{k}(s)}^{k}\\widetilde(s)$ during th elmiation proces. ", "page_idx": 32}, {"type": "text", "text": "f $l_{h}^{k}(s)\\leq L_{\\varepsilon}$ , we have $l_{h}^{k}(s)-1\\leq\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ . Thus, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h}^{k}(s))\\leq8\\cdot2^{-(l_{h}^{k}(s)-1)}+2l_{h}^{k}(s)\\cdot\\chi\\sqrt{L_{\\varepsilon}}\\zeta}&{{}}\\\\ {\\leq16\\cdot2^{-l_{h}^{k}(s)}+2\\chi L_{\\varepsilon}^{1.5}\\zeta}&{{}}\\\\ {\\leq16\\cdot2^{-l_{h}^{k}(s)}+0.02\\varepsilon/H,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where th frst inequality follws fromLmmaC.7 with $\\pi_{h}^{k}(s)\\in\\mathcal{A}_{h,l_{h}^{k}(s)}^{k}(s)$ and the last inequality holds due to $\\chi L_{\\varepsilon}^{1.5}\\zeta\\leq0.01\\varepsilon/H$ given by $\\mathcal{G}_{\\varepsilon}$ ", "page_idx": 32}, {"type": "text", "text": "Otherwise, we have $L_{\\varepsilon}\\leq\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ . In this case, we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h}^{k}(s))\\leq8\\cdot2^{-L_{\\varepsilon}}+2\\chi L_{\\varepsilon}^{1.5}\\zeta}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq0.08\\varepsilon/H+0.02\\varepsilon/H=0.10\\varepsilon/H,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the firs inequalityfollows from Lemma C.7 with $\\pi_{h}^{k}(s)\\in\\mathcal{A}_{h,l_{h}^{k}(s)}^{k}(s)\\subseteq\\mathcal{A}_{h,L_{\\varepsilon}}^{k}(s)$ according to the elimination routine and the final inequality holds due to $\\chi L_{\\varepsilon}^{1.5}\\zeta\\leq2^{-L_{\\varepsilon}}\\leq0.01\\varepsilon/H$ givenby $\\mathcal{G}_{\\varepsilon}$ . So by combining (F.4) and (F.5), we have the desired statement that ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,\\pi_{h}^{k}(s))\\leq16\\cdot2^{-l_{h}^{k}(s)}+0.10\\varepsilon/H.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "F.3Proof of Lemma E.5 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We prove Lemma E.5 in this section by applying Lemma D.8 on phase $\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ ", "page_idx": 33}, {"type": "text", "text": "Proof of Lemma E.5. If $l_{h}^{k}(s)\\leq L_{\\varepsilon}$ , we have $l_{h}^{k}(s)-1\\leq\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ . Firstly, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\widehat{V}_{h}^{k}(s)\\leq\\widehat{V}_{h,l_{h}^{k}(s)-1}^{k}(s)\\leq V_{h,l_{h}^{k}(s)-1}^{k}(s)+3\\cdot2^{-(l_{h}^{k}(s)-1)}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the first inequality is given by Lemma C.2 and the second inequality follows from the defini$\\widehat{V}_{h,l_{h}^{k}(s)-1}^{k}(s)$ ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\hat{\\gamma}_{h}^{k}(s)-\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\hat{V}_{h+1}^{k}](s,a)\\leq(\\widehat{V}_{h}^{k}(s)-V_{h,l_{h}^{k}(s)-1}^{k}(s))+\\big(V_{h,l_{h}^{k}(s)-1}^{k}(s)-\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big)}}\\\\ &{}&{\\leq3\\cdot2^{-(l_{h}^{k}(s)-1)}+2\\cdot2^{-(l_{h}^{k}(s)-1)}+\\chi\\sqrt{L_{\\varepsilon}}\\zeta}\\\\ &{}&{\\leq10\\cdot2^{-l_{h}^{k}(s)}+0.01\\varepsilon/H,\\qquad\\qquad\\qquad\\qquad\\qquad\\quad(\\mathrm{F}^{\\gamma})}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where in the second inequality, the first term is given by (F.6) and the second term holds according to Lemma D.8, and the third inequality holds from $\\chi\\sqrt{L_{\\varepsilon}}\\zeta\\leq0.01\\varepsilon/H$ givenby $\\mathcal{G}_{\\varepsilon}$ ", "page_idx": 33}, {"type": "text", "text": "Otherwise, we have $L_{\\varepsilon}\\leq\\operatorname*{min}\\{L_{\\varepsilon},l_{h}^{k}(s)-1\\}$ , this leads to ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widehat{V}_{h}^{k}(s)-\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\leq\\big(\\widehat{V}_{h}^{k}(s)-V_{h,L_{\\varepsilon}}^{k}(s)\\big)+\\big(V_{h,L_{\\varepsilon}}^{k}(s)-\\underset{a\\in\\mathcal{A}}{\\operatorname*{max}}[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s,a)\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq3\\cdot2^{-L_{\\varepsilon}}+2\\cdot2^{-L_{\\varepsilon}}+\\chi\\sqrt{L_{\\varepsilon}}\\zeta}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq0.03\\varepsilon/H+0.02\\varepsilon/H+0.01\\varepsilon/H=0.06\\varepsilon/H,\\qquad\\qquad\\mathrm{otherwise}}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where in the second inequality,the first term is given by the definition of $\\widehat{V}_{h}^{k}(s)$ and the second term holds according to Lemma D.8, and the third inequality holds from $\\chi L_{\\varepsilon}^{1.5}\\zeta\\,\\leq\\,2^{-L_{\\varepsilon}}\\,\\leq\\,0.01\\varepsilon/H$ givenby $\\mathcal{G}_{\\varepsilon}$ . Combining (F.7) and (F.8) gives the desired statement ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\widehat V_{h}^{k}(s)-\\operatorname*{max}_{a\\in\\mathcal{A}}[\\mathbb{B}_{h}\\widehat V_{h+1}^{k}](s,a)\\leq10\\cdot2^{-l_{h}^{k}(s)}+0.06\\varepsilon/H.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "F.4Proof of Lemma E.6 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Proof of Lemma $E.6.$ According to the defnition in which $V_{h}^{\\pi^{k}}(s_{h}^{k})\\,=\\,[\\mathbb{B}_{h}V_{h+1}^{\\pi^{k}}](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))$ and $\\eta_{h}^{k}+[\\mathbb{P}_{h}(\\widehat{V}_{h+1}^{k}-V_{h+1}^{\\pi^{k}})](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))-(\\widehat{V}_{h+1}^{k}(s_{h+1}^{k})-V_{h+1}^{\\pi^{k}}(s_{h+1}^{k}))$ We can write $\\widehat{V}_{h}^{k}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})=\\big(\\widehat{V}_{h}^{k}(s_{h}^{k})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))\\big)+\\eta_{h}^{k}+\\big(\\widehat{V}_{h+1}^{k}(s_{h+1}^{k})-V_{h+1}^{\\pi^{k}}(s_{h+1}^{k})\\big).$ Bya telescoping statement frm $h$ 0 $H$ with the final terminal value $\\widehat V_{H+1}^{k}(\\cdot)=V_{H+1}^{\\pi^{k}}(\\cdot)=0$ we reach $\\widehat{V}_{h}^{k}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})=\\sum_{h^{\\prime}=h}^{H}\\big(\\widehat{V}_{h}^{k}(s_{h}^{k})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))\\big)+\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{k}.$ (F.9) ", "page_idx": 33}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "As a result, we can bound the desired term by ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{h}^{*}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})\\le\\widehat{V}_{h}^{k}(s_{h}^{k})-V_{h}^{\\pi^{k}}(s_{h}^{k})+0.07\\varepsilon}\\\\ &{\\qquad\\qquad\\qquad\\qquad=\\displaystyle\\sum_{h^{\\prime}=h}^{H}\\big(\\widehat{V}_{h}^{k}(s_{h}^{k})-[\\mathbb{B}_{h}\\widehat{V}_{h+1}^{k}](s_{h}^{k},\\pi_{h}^{k}(s_{h}^{k}))\\big)+\\displaystyle{\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{k}}+0.07\\varepsilon}\\\\ &{\\qquad\\qquad\\qquad\\le\\displaystyle\\sum_{h^{\\prime}=h}^{H}\\big(26\\cdot2^{-l_{h^{\\prime}}^{k}(s_{h^{\\prime}}^{k})}+0.16\\varepsilon/H\\big)+\\displaystyle{\\sum_{h^{\\prime}=h}^{H}\\eta_{h^{\\prime}}^{k}}+0.07\\varepsilon}\\\\ &{\\qquad\\qquad\\qquad\\qquad=0.23\\varepsilon+26\\displaystyle\\sum_{h^{\\prime}=h}^{H}2^{-l_{h^{\\prime}}^{k}(s_{h^{\\prime}}^{k})}+\\displaystyle{\\sum_{h^{\\prime}=h}^{H}\\eta_{h}^{k}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the first inequality is given by Lemma D.11, the first equality is given by (F.9), and the final inequality is given by Lemma D.12. \u53e3 ", "page_idx": 34}, {"type": "text", "text": "GTechnical Numerical Lemmas ", "text_level": 1, "page_idx": 34}, {"type": "equation", "text": "$$\n|{\\mathcal{C}}_{h,l}^{k}|\\leq4^{l}d+2.5\\cdot4^{l}\\gamma_{l}^{2}d\\ln\\left(1+|{\\mathcal{C}}_{h,l}^{k}|/(16d)\\right),{\\sf t h e n}\\;|{\\mathcal{C}}_{h,l}^{k}|\\leq16l\\cdot4^{l}\\gamma_{l}^{2}d.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Proof. Denote $c=|\\mathcal{C}_{h,l}^{k}|/(l\\cdot4^{l}\\gamma_{l}^{2}d)$ . We have that ", "page_idx": 34}, {"type": "equation", "text": "$$\nc l\\cdot4^{l}\\gamma_{l}^{2}d\\leq4^{l}d+2.5\\cdot4^{l}\\gamma_{l}^{2}d\\ln(1+c l\\cdot4^{l}\\gamma_{l}^{2}/16).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Dividing both sides by $4^{l}\\gamma_{l}^{2}d$ we have that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{c l\\leq1/\\gamma_{l}^{2}+2.5\\ln(1+c l\\cdot4^{l}\\gamma_{l}^{2}/16)}\\\\ &{\\phantom{\\gamma_{l}^{2}}\\leq1/\\gamma_{l}^{2}+2.5\\ln(4c\\cdot5^{l}\\gamma_{l}^{2}/16)\\leq1/\\gamma_{l}^{2}+4.1l+2.5\\ln(c).}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Since $l\\geq1$ and $\\gamma_{l}\\geq1$ , we can further conclude that ", "page_idx": 34}, {"type": "equation", "text": "$$\nc\\leq5.1+2.5\\ln(c)\\leq5.1+2.5(1+c/6).\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "The necessary condition for the above inequality is $c\\leq16$ , which proves the desired statement. ", "page_idx": 34}, {"type": "text", "text": "Lemma G.2. For any $l\\geq1$ \uff0c $\\gamma_{l+1}/\\gamma_{l}\\leq1.4$ ", "page_idx": 34}, {"type": "text", "text": "Proof. Firstly, we have that ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\frac{l+22+\\log(l+1)}{l+20+\\log(l)}\\leq\\frac{l+22+0.2l+2}{l+20}=1.2,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the first inequality holds due to $\\log(x+1)\\leq0.2x+2$ . In addition, we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\frac{4+\\log(l+1)}{4+\\log(l)}\\leq\\frac{4+\\log(l)+1}{4+\\log(l)}\\leq1.25,\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the first inequality holds due to $\\log(x+1)\\leq\\log(x)+1$ . As a result, we can reach the desired statement according to ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\gamma_{l+1}}{\\gamma_{l}}=\\frac{5(l+1+\\lceil20+\\log((l+1)d)\\rceil)d H\\sqrt{\\log(16(l+1)d H/\\delta)}}{5(l+\\lceil20+\\log(l)\\rceil)d H\\sqrt{\\log(16l d H/\\delta)}}}\\\\ &{\\qquad\\le\\frac{l+22+\\log(l+1)+\\log(d)}{l+20+\\log(l)+\\log(d)}\\cdot\\sqrt{\\frac{\\log(l+1)+\\log(16d H/\\delta)}{\\log(l)+\\log(16d H/\\delta)}}}\\\\ &{\\qquad\\le\\frac{l+22+\\log(l+1)}{l+20+\\log(l)}\\cdot\\sqrt{\\frac{\\log(l+1)}{\\log(l)}}}\\\\ &{\\qquad\\le1.2\\sqrt{1.25}}\\\\ &{\\qquad\\le1.4.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the third inequality holds from plugging both (G.1) and (G.2) ", "page_idx": 34}, {"type": "text", "text": "Lemma G.3. ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sqrt{2d\\ln(1+l\\cdot4^{l}\\gamma_{l}^{2})+2\\ln(l^{2}H(2^{22}d^{6}H^{4})^{l_{+}^{2}d^{2}}/\\delta)}\\le\\gamma_{l,l_{+}}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Proof. By calculation, we have that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{H\\sqrt{2d\\ln(1+l\\cdot4l\\gamma_{l}^{2})+2\\ln(l^{2}H(2^{2}d^{6}H^{4})^{l_{+}^{2}d^{2}}/\\delta)}}\\\\ &{\\leq H\\sqrt{2d\\ln(1+l\\cdot4l\\cdot1.4^{2l}\\gamma_{1}^{2})}+H\\sqrt{12l_{+}^{2}d^{2}\\ln(2^{4}l d H/\\delta)}}\\\\ &{\\leq l_{+}d H\\sqrt{2\\ln(2^{4}l d H/\\delta)}+l_{+}d H\\sqrt{12\\ln(2^{4}l d H/\\delta)}}\\\\ &{\\leq5l_{+}d H\\sqrt{\\log(2^{4}\\gamma_{l_{+}}l d H/\\delta)}}\\\\ &{=\\gamma_{l,l_{+}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Lemma G.4. If some constant $c_{1},c_{2}>0$ that ", "page_idx": 35}, {"type": "equation", "text": "$$\n|K_{h}^{\\varepsilon}|<c_{1}L_{\\varepsilon}(L_{\\varepsilon}+\\log(d H))^{2}d^{3}H^{4}\\varepsilon^{-2}\\log(L_{\\varepsilon}d/\\delta)+\\varepsilon^{-1}\\sqrt{c_{2}H^{3}|K_{h}^{\\varepsilon}|\\log(H|K_{h}^{\\varepsilon}|\\log(\\varepsilon^{-1})/\\delta)}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Then, there exists $c_{3}>0$ such that ", "page_idx": 35}, {"type": "equation", "text": "$$\n|K_{h}^{\\varepsilon}|<c_{3}L_{\\varepsilon}(L_{\\varepsilon}+\\log(d H))^{2}d^{3}H^{4}\\varepsilon^{-2}\\log(L_{\\varepsilon}d)\\log(\\delta^{-1})\\iota,\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $\\iota$ is a polynomial of $\\log\\log(L_{\\varepsilon}d H\\delta^{-1})$ ", "page_idx": 35}, {"type": "equation", "text": "$$\nx<c_{1}L_{\\varepsilon}(L_{\\varepsilon}+\\log(d H))^{2}d^{3}H^{4}\\varepsilon^{-2}\\log(L_{\\varepsilon}d/\\delta)+\\varepsilon^{-1}\\sqrt{c_{2}H^{3}x\\log(H\\log(\\varepsilon^{-1})/\\delta)}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Since $x<a+{\\sqrt{b x}}$ implies $x<2a+2b$ , so the above inequality implies ", "page_idx": 35}, {"type": "equation", "text": "$$\nx<2c_{1}L_{\\varepsilon}(L_{\\varepsilon}+\\log(d H))^{2}d^{3}H^{4}\\varepsilon^{-2}\\log(L_{\\varepsilon}d/\\delta)+2c_{2}H^{3}\\varepsilon^{-2}\\log(H\\log(\\varepsilon^{-1})/\\delta).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Moreover, since $y/\\log(y)<a$ implies $y<2a\\log a$ we can conclude that there exists $c_{3}>0$ that ", "page_idx": 35}, {"type": "equation", "text": "$$\n|K_{h}^{\\varepsilon}|<c_{3}L_{\\varepsilon}(L_{\\varepsilon}+\\log(d H))^{2}d^{3}H^{4}\\varepsilon^{-2}\\log(L_{\\varepsilon}d)\\log(\\delta^{-1})\\iota,\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $\\iota$ is a polynomial of $\\log\\log(L_{\\varepsilon}d H\\varepsilon^{-1}\\delta^{-1})$ ", "page_idx": 35}, {"type": "text", "text": "H Auxiliary Lemmas ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "This section provides some auxiliary concentration lemmas frequently used in the proof. ", "page_idx": 35}, {"type": "text", "text": "Lemma H.1 (Lemma 11, Abbasi-Yadkori et al. (2011). Let $\\{\\phi^{k}\\}_{k=1}^{\\infty}$ be any bounded sequence such that $\\phi^{k}\\,\\in\\,\\mathbb{R}^{d}$ and $\\|\\phi^{k}\\|_{2}\\leq\\ B$ for some constant $B~>~0$ .For $k\\ \\geq\\ 1$ , let $\\mathbf{U}^{k}\\;=\\;\\lambda\\mathbf{I}\\;+$ $\\textstyle\\sum_{\\tau=1}^{k-1}\\phi^{\\tau}(\\phi^{\\tau})^{\\top}$ . Let $\\lambda>0$ , then for all $k\\in[K]$ , we have that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\sum_{\\tau=1}^{k}\\operatorname*{min}\\big\\{1,\\|\\phi^{\\tau}\\|_{({\\mathbf{U}}^{\\tau})^{-1}}^{2}\\big\\}\\leq2d\\ln\\big(1+k B^{2}/(d\\lambda)\\big).\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Lemma H.2 (Self-Normalized Martingale, Abbasi-Yadkori et al. (2011). Let $\\{\\mathcal{F}^{k}\\}_{k=1}^{\\infty}$ be a fltration, and $\\{\\phi^{k},\\eta^{k}\\}_{k=1}^{\\infty}$ be a stochastic process where $\\phi^{k}\\in\\mathbb{R}^{d}$ .is $\\mathcal{G}^{k}$ measurable and $\\eta^{k}$ .s $\\mathcal{F}^{k+1}$ measurable such that ", "page_idx": 35}, {"type": "equation", "text": "$$\n|\\mathbb{E}[\\eta^{k}|\\mathcal{F}^{k}]|=0,|\\eta^{k}|\\le R,\\|\\phi^{k}\\|_{2}\\le B\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "for some constant $B,R>0$ Let $\\lambda>0$ For $k\\geq1$ let $\\begin{array}{r}{\\mathbf{U}^{k}=\\lambda\\mathbf{I}+\\sum_{\\tau=1}^{k-1}\\phi^{\\tau}(\\phi^{\\tau})^{\\top}}\\end{array}$ . Then for any $\\delta\\in(0,1)$ , with probability at least $1-\\delta$ , for all $k\\geq1$ , we have that ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau=1}^{k-1}\\eta^{\\tau}\\phi^{\\tau}\\right\\|_{(\\mathbf{U}^{k})^{-1}}\\leq R\\sqrt{2d\\ln\\left(1+k B^{2}/(d\\lambda)\\right)+2\\ln\\delta^{-1}}.\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Lemma H.3 (Lemma 8, Zanette et al. (2020b)). Let $\\{\\phi^{k},\\eta^{k}\\}_{k=1}^{\\infty}$ be any bounded sequence satisfying $\\phi^{k}\\in\\mathbb{R}^{d}$ and $|\\eta^{k}|\\leq\\zeta$ for some constant $\\zeta>0$ For $k\\geq1$ let $\\begin{array}{r}{\\mathbf{U}^{k}=\\lambda\\mathbf{I}+\\sum_{\\tau=1}^{k-1}\\phi^{\\tau}(\\phi^{\\tau})^{\\top}}\\end{array}$ Then, for all $k\\geq1$ , we have that ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{\\tau=1}^{k-1}\\eta^{\\tau}\\phi^{\\tau}\\right\\|_{(\\mathbf{U}^{k})^{-1}}\\leq\\zeta\\sqrt{k}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Lemma H.4 (Azuma-Hoeffding inequality, Hoeffding (1963)). Let $\\{\\eta^{k}\\}_{k=1}^{K}$ be a martingale difference sequence with respect to a filtration $\\{\\mathcal{F}^{k}\\}_{k=1}^{K}$ satisfying $|\\eta^{k}|\\leq M$ for some constant $M>0$ and $\\eta^{k}$ .s $\\mathcal{F}^{k+1}$ -measurable with $|\\mathbb{E}[\\eta^{k}|\\mathcal{F}^{k}]|=0$ . Then for some fixed $k\\in[K]$ and any $\\delta\\in(0,1)$ \uff0c with probability at least $1-\\delta$ , we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\sum_{\\tau=1}^{k}\\eta^{\\tau}\\leq M\\sqrt{2k\\ln\\delta^{-1}}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Lemma H.5 (Freedman inequality, Cesa-Bianchi and Lugosi (2006). Let $\\{\\eta^{k}\\}_{k=1}^{K}$ be a martingale difeenqstan $\\{\\mathcal{F}^{k}\\}_{k=1}^{K}$ satsfying $|\\eta^{k}|\\leq M$ for some constant $M>0$ and $\\eta^{k}$ .s $\\mathcal{F}^{k+1}$ -measurable with $|\\mathbb{E}[\\eta^{k}|\\mathcal{F}^{k}]|=0$ Then for some fixed $k\\in[K]$ $a>0$ and $v>0$ , we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{Pr}\\Big(\\sum_{\\tau=1}^{k}\\eta^{\\tau}\\geq a,\\sum_{\\tau=1}^{k}\\mathrm{Var}[\\eta^{\\tau}|\\mathcal{F}^{\\tau}]\\leq v\\Big)\\leq\\exp\\Big(\\frac{-a^{2}}{2v+2a M/3}\\Big).\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "1 Numerical Simulation ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "We added experiments on synthetic datasets to verify the performance of the algorithm and the contribution of each component. Specifically, we consider a linear MDP with $S\\,=\\,4$ $A\\ =\\ 5$ $H=2$ , and $d=8$ . Each element in the feature vector $\\phi(s,a)$ and $\\pmb{\\mu}(s^{\\prime})$ is generated by a uniform distribution $U(0,1)$ . Subsequently, $\\phi$ is normalized to ensure that $\\mathbb{P}(\\boldsymbol{s}^{\\prime}|\\boldsymbol{s},\\boldsymbol{a})$ is a probability measure, i.e., $\\begin{array}{r}{\\phi(s,a)=\\phi(s,a)/\\sum_{s^{\\prime}}\\phi^{\\top}(s,a)\\pmb\\mu(s^{\\prime})}\\end{array}$ . The reward is defined by $r(s,a)=\\phi^{\\top}(s,a)\\theta$ , where $\\pmb{\\theta}\\sim N(0,I_{d})$ . The model misspecification is also added to the transition $\\mathbb{P}$ and reward function $r$ For a given misspecification $\\zeta$ , the ground truth reward function is defined by $r(s,a)=\\phi^{\\top}(s,a)\\theta+$ $Z(s,a)$ , where ${\\cal Z}(s,a)\\;\\sim\\;{\\cal U}(-\\zeta,\\zeta)$ . When adding the model misspecification to the transition kernel, we first random sample a subset $S_{+}\\subset S$ such that $|S_{+}|\\,=\\,|\\bar{S}|/2$ . Then the misspecified transition kernel is then generated by ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathbb{P}^{\\prime}(s^{\\prime}|s,a)=\\mathbb{P}(s^{\\prime}|s,a)+2\\frac{\\zeta}{S}\\,\\mathbb{1}[s^{\\prime}\\in S_{+}]-\\frac{\\zeta}{S},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "we can verify that $\\|\\mathbb{P}(\\cdot|s,a)-\\mathbb{P}^{\\prime}(\\cdot|s,a)\\|_{\\mathrm{TV}}=\\zeta$ . We investigated the misspecification level from $\\zeta\\,=\\,0,0.01,\\cdots\\,,0.3$ in 16 randomly generated environments over 2000 episodes. We report the cumulative regret and runtime with respect to different misspecification levels. Additionally, we performed an ablation study by 1) removing the certified estimation (Algorithm 2, Line 11) and 2) removing the quantization (Algorithm 1, Line 8). ", "page_idx": 36}, {"type": "text", "text": "The results of these configurations are presented in the following table. The detailed regret for all misspecification level is presented in Table 3 and Figure 1, we plot the cumulative regret for 2000 episodes with respect to the misspecification level $\\zeta$ The cumulative regret curve is plotted in Figure 2. ", "page_idx": 36}, {"type": "text", "text": "The experimental results suggest several key findings that support our theoretical analysis: ", "page_idx": 36}, {"type": "text", "text": "\u00b7 When the misspecification level is low, it is possible to achieve constant regret, where the instantaneous regret in the final rounds is approximately zero. \u00b7 The certified estimator and the quantization do not significantly affect the algorithm's runtime. In contrast, the certified estimator provides an \u2018early-stopping\u2019 condition in Algorithm 2, which slightly reduces the algorithm's runtime. In particular, our algorithm yields a computational complexityof $O(d^{2}A H K^{\\breve{2}}\\log K)$ which is the same as Vial et al. (2022) and only $\\log K$ greater than the vanilla LSVI-UCB (Jin et al., 2020) due to the multi-phased algorithm. ", "page_idx": 36}, {"type": "image", "img_path": "02r24A8doi/tmp/0b1ef3609e426f9726435c2a59c118ae34ffaa25cf1b1a9423c2fb7bdaaa63f6.jpg", "img_caption": ["(a) With quantization "], "img_footnote": [], "page_idx": 37}, {"type": "image", "img_path": "02r24A8doi/tmp/6c0171eff6ff577030acf767a9a13d71b13a5ed8f4fa72fa4e2d405113576531.jpg", "img_caption": ["Figure 1: Cumulative regret over 2000 episodes with respect to different misspecification level $\\zeta$ The result is averaged over 16 individual environments. ", "Average Cumulative Regret vs. Misspecification level 7 "], "img_footnote": [], "page_idx": 37}, {"type": "text", "text": "\u00b7 The certified estimator helps the algorithm by providing robust estimation in the presence of misspecification. As shown in the table, using the certified estimator does not make a significant difference when the misspecification level $\\zeta$ is low, but it becomes significant as the misspecification level increases. ", "page_idx": 37}, {"type": "text", "text": "\u00b7\u00b0 The quantization does not contribute significantly to the results, as the numerical results are intrinsically discrete and quantized. In Figure 2, the regret curve with quantization and the one without quantization are highly overlapped. ", "page_idx": 37}, {"type": "table", "img_path": "02r24A8doi/tmp/5d1a0f70ef76fd73f9cc6b67185aecd7be93270b120e5b174ee15511d742b6a7.jpg", "table_caption": [], "table_footnote": ["Table 3: Average cumulative regret ( $\\pm$ standard derivation) and execution time over 2000 episodes. The results are averaged over 16 individual runs. C indicates if Certified Estimator is used. Q indicates if Quantization is used. "], "page_idx": 37}, {"type": "image", "img_path": "02r24A8doi/tmp/81d4e9a30e29263545c1259d77c4208483d0d6cb0ecb67545556d21eae27a694.jpg", "img_caption": ["Figure 2: Cumulative regret with respect to the number of episodes. We reported the median cumulative regret with the shadow area as the region from $25\\%$ percentageto $75\\%$ percentage statistics over16runs. "], "img_footnote": [], "page_idx": 38}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: We study the constant regret analysis in reinforcement learning from a theoretical perceptive. The contribution, assumptions and scope are clearly claimed in the abstract and introduction. ", "page_idx": 38}, {"type": "text", "text": "Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 38}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: We discussed the limitations and future potential directions in Section 7. Guidelines: ", "page_idx": 38}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. \u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper. \u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. ", "page_idx": 38}, {"type": "text", "text": "\u00b7 The authors should refect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 39}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 39}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Justification: We provide a detailed proof for all theorems in the appendix, starting from AppendixC. ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 39}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 39}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 39}, {"type": "text", "text": "Justification: Our submission paper does not include experiments ", "page_idx": 39}, {"type": "text", "text": "Guidelines: ", "page_idx": 39}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with ", "page_idx": 39}, {"type": "text", "text": "the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. ", "page_idx": 40}, {"type": "text", "text": "\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example   \n(a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d)  We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 40}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: Our paper does not include experiments requiring code. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 40}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 40}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 40}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 40}, {"type": "text", "text": "Justification: Our paper does not include experiments. Guidelines: ", "page_idx": 40}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 41}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: The paper does not include experiments. Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 41}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 41}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 41}, {"type": "text", "text": "Justification: The paper does not include experiments. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 41}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 41}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 41}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 41}, {"type": "text", "text": "Answer: [Yes] Justification: We have reviewed the NeurIPS Code of Ethics. ", "page_idx": 41}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 42}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: Our work provides the theoretical understanding of reinforcement learning. Although there might be some potential social impacts on reinforcement learning applications, according to the guidelines, we believe our result does not have a direct connection with these issues. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 42}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 42}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 42}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 42}, {"type": "text", "text": "Justification: We place this paper on the theoretical understand of reinforcement learning thus the paper poses no such risks. ", "page_idx": 42}, {"type": "text", "text": "Guidelines: ", "page_idx": 42}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. ", "page_idx": 42}, {"type": "text", "text": "\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 43}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: We do not use existing assets in the paper. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 43}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 43}, {"type": "text", "text": "Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose assetisused.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 43}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 43}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 43}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 43}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects Guidelines: ", "page_idx": 43}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. ", "page_idx": 43}, {"type": "text", "text": "\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the datacollector. ", "page_idx": 44}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 44}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 44}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 44}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects Guidelines: ", "page_idx": 44}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 44}]