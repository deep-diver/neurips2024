[{"figure_path": "XdCJAYYiTP/figures/figures_1_1.jpg", "caption": "Figure 5: Qualitative comparison of 3D reconstruction results on the GSO dataset [12]. Era3D produces the most high-quality 3D meshes with more details than baseline methods.", "description": "This figure compares the 3D reconstruction results of Era3D with several baseline methods on the Google Scanned Objects (GSO) dataset.  It showcases input images alongside the 3D mesh reconstructions produced by each method.  The comparison highlights Era3D's ability to generate higher-quality meshes with finer details compared to the other methods, demonstrating its superior performance in reconstructing complex 3D shapes from single images.", "section": "4 Experiments"}, {"figure_path": "XdCJAYYiTP/figures/figures_1_2.jpg", "caption": "Figure 1: Given single-view image with arbitrary intrinsic and viewpoints, Era3D can generate high-quality multiview images with a resolution of 512 \u00d7 512 on the orthogonal camera setting, which can be used in mesh reconstruction by NeuS [68].", "description": "This figure shows the results of Era3D on various single-view images. Given a single image as input, Era3D generates multiple high-resolution (512x512) images from different viewpoints, as if viewed from an orthogonal camera. These generated images can then be used to reconstruct a 3D mesh model using the NeuS method.", "section": "1 Introduction"}, {"figure_path": "XdCJAYYiTP/figures/figures_2_1.jpg", "caption": "Figure 3: Different types of multiview attention layers. (a) In a dense multiview attention layer, all feature vectors of multiview images are fed into an attention block. For a general camera setting (b) with arbitrary viewpoints and intrinsics, utilizing epipolar constraint to construct an epipolar attention (c) needs to correlate the features on the epipolar line. This means that we need to sample K points along each epipolar line to compute such an attention layer. In our canonical camera setting (d) with orthogonal cameras and viewpoints on an elevation of 0\u00b0, epipolar lines align with the row of the images across different views (e), which eliminates the need to resample epipolar line to compute epipolar attention. We assume the latent feature map has a resolution of H \u00d7 W and H = W = S. In such a N-view camera system, row-wise attention reduces the computational complexity to O(N2S3).", "description": "This figure illustrates three different types of multiview attention mechanisms used in multiview image generation.  (a) shows a dense attention approach, where all features are processed together. (b) and (c) demonstrate the epipolar attention method, that leverages epipolar geometry to reduce computational cost. (d) and (e) show the canonical camera setting and the row-wise attention approach developed in this paper. Row-wise attention takes advantage of aligned epipolar lines and orthogonal cameras in the canonical setting to further optimize computational complexity.", "section": "3 Methods"}, {"figure_path": "XdCJAYYiTP/figures/figures_4_1.jpg", "caption": "Figure 4: Overview. Given a single-view image as input, Era3D applies multiview diffusion to generate multiview consistent images and normal maps in the canonical camera setting, which enables us to reconstruct 3D meshes using NeuS [68, 37].", "description": "This figure shows the overall pipeline of Era3D for 3D mesh reconstruction from a single-view image.  It begins with an input image that may have arbitrary intrinsic and viewpoint parameters.  The EFReg (Elevation and Focal Length Regression) module estimates the camera parameters (elevation and focal length) which are used to guide the multiview diffusion process (MVSD). The MVSD generates high-quality, multiview consistent images and normal maps (in a canonical orthogonal camera setting). Finally, these images are input to the NeuS (Neural Implicit Surface) module, which reconstructs a textured 3D mesh.", "section": "3 Methods"}, {"figure_path": "XdCJAYYiTP/figures/figures_6_1.jpg", "caption": "Figure 5: Qualitative comparison of 3D reconstruction results on the GSO dataset [12]. Era3D produces the most high-quality 3D meshes with more details than baseline methods.", "description": "This figure compares the 3D reconstruction results of different methods on the GSO dataset.  The input images are shown alongside the 3D meshes generated by Wonder3D, LGM, One-2-3-45, Shape-E, and Era3D.  The comparison highlights that Era3D produces significantly more detailed and higher-quality 3D meshes compared to the other methods. This demonstrates Era3D's superiority in reconstructing complex 3D shapes from a single image.", "section": "4 Experiments"}, {"figure_path": "XdCJAYYiTP/figures/figures_6_2.jpg", "caption": "Figure 6: Qualitative comparisons of novel view synthesis quality of reconstructed 3D meshes with single-view images generated by SDXL [45].", "description": "This figure compares the novel view synthesis quality achieved by different methods (LGM, Wonder3D, Magic123, and Era3D) on 3D meshes reconstructed from single-view images generated using the SDXL model.  It visually demonstrates the differences in the quality of generated novel views, showcasing the performance of Era3D in terms of detail, realism, and overall visual consistency.", "section": "4 Experiments"}, {"figure_path": "XdCJAYYiTP/figures/figures_7_1.jpg", "caption": "Figure 7: More comparisons w.r.t distortion problem.", "description": "This figure compares the 3D reconstruction results of Era3D, Wonder3D, and Unique3D on both the GSO dataset (synthetic objects) and in-the-wild images.  It visually demonstrates Era3D's superior performance in handling perspective distortion.  While other methods produce distorted reconstructions, Era3D generates accurate and visually appealing 3D models even when input images are taken from perspective cameras with varying viewpoints and focal lengths.", "section": "4.1 Experimental Results"}, {"figure_path": "XdCJAYYiTP/figures/figures_8_1.jpg", "caption": "Figure 8: Ablation study of EFReg.", "description": "This ablation study compares the results of the full model (with EFReg) against a model without the Elevation and Focal Length Regression module.  The figure shows that the absence of EFReg leads to distortions and inaccuracies in the generated novel views, whereas including EFReg results in significantly improved quality and detail in the generated images.", "section": "4.3 Ablations and Discussions"}, {"figure_path": "XdCJAYYiTP/figures/figures_15_1.jpg", "caption": "Figure 9: Equivalence between orthogonal and perspective camera models and our rendering samples in GSO dataset [12].", "description": "This figure illustrates the equivalence between orthogonal and perspective camera models used in the paper's experiments. It shows how renderings from both types of cameras can be made similar in size to reduce training bias.  The left panel (a) depicts the setup for an orthogonal camera, where the distance from the camera to the object is determined by the orthogonal scale 's' and focal length 'f'. The middle panel (b) shows the perspective camera setup, where the distance 'd' is calculated as f/s to create a similar image size. The right panel (c) displays renderings of the same object created with different focal lengths (\u221e, 105mm, 85mm, 50mm, 34mm, 24mm), highlighting the impact of focal length on perspective distortion. The figure is essential for understanding the camera canonicalization method employed in Era3D.", "section": "3.1 Camera Canonicalization"}, {"figure_path": "XdCJAYYiTP/figures/figures_15_2.jpg", "caption": "Figure 3: Different types of multiview attention layers. (a) In a dense multiview attention layer, all feature vectors of multiview images are fed into an attention block. For a general camera setting (b) with arbitrary viewpoints and intrinsics, utilizing epipolar constraint to construct an epipolar attention (c) needs to correlate the features on the epipolar line. This means that we need to sample K points along each epipolar line to compute such an attention layer. In our canonical camera setting (d) with orthogonal cameras and viewpoints on an elevation of 0\u00b0, epipolar lines align with the row of the images across different views (e), which eliminates the need to resample epipolar line to compute epipolar attention. We assume the latent feature map has a resolution of H \u00d7 W and H = W = S. In such a N-view camera system, row-wise attention reduces the computational complexity to O(N2S3).", "description": "This figure illustrates different types of multiview attention layers used in multiview image generation.  It compares dense attention, general camera setting with epipolar attention, canonical camera setting, and the proposed row-wise attention. The key difference highlighted is the computational complexity reduction achieved by the row-wise attention method in the canonical camera setting due to its alignment with image rows, leading to O(N2S3) complexity compared to higher complexities in other methods.", "section": "3 Methods"}, {"figure_path": "XdCJAYYiTP/figures/figures_17_1.jpg", "caption": "Figure 7: More comparisons w.r.t distortion problem.", "description": "This figure shows qualitative comparisons of 3D reconstruction results between Era3D and other state-of-the-art methods (Wonder3D and Unique3D).  The results are presented for both the GSO dataset (Google Scanned Objects) and in-the-wild images.  The comparison highlights Era3D's ability to mitigate the perspective distortion artifacts that affect other methods, especially when dealing with images captured under different camera settings (variable intrinsics and viewpoints).", "section": "4 Experiments"}, {"figure_path": "XdCJAYYiTP/figures/figures_17_2.jpg", "caption": "Figure 7: More comparisons w.r.t distortion problem.", "description": "This figure compares the results of Era3D and other state-of-the-art methods on the GSO and in-the-wild datasets. It demonstrates Era3D's ability to generate high-quality multiview images and 3D meshes even when the input images have severe perspective distortions, while other methods suffer from artifacts and inaccuracies. The figure showcases the robustness of Era3D to inconsistent camera intrinsics and demonstrates its ability to improve the quality of 3D reconstruction compared to existing methods.", "section": "4.1 Experimental Results"}, {"figure_path": "XdCJAYYiTP/figures/figures_19_1.jpg", "caption": "Figure 12: More results of images from the Internet.", "description": "This figure shows additional results of 3D reconstruction from single-view images obtained from the internet.  The left column displays the input images; the subsequent columns display the generated multiview images, normal maps, and final 3D mesh reconstructions.  A variety of objects are shown, demonstrating the model's ability to handle diverse input imagery and generate realistic 3D models.", "section": "4 Experiments"}]