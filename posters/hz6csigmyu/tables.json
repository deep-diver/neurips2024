[{"figure_path": "Hz6cSigMyU/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of generalization performance on eight unseen tasks, with episodic returns averaged over 100 episodes. In these tasks, we replace the pancake in the original Food Preparation task with other foods like cheese, hamburger, apple pie and pizza, or replace the (pancake, microwave) at the same time with (dishes, dishwasher) or (clothes, washing machine) for greater differences.", "description": "This table presents the generalization performance of different language agent training methods on eight unseen tasks.  The tasks are variations of the Food Preparation task from the Overcooked environment, modifying the food items and appliances. The performance is measured by the average episodic return over 100 episodes, showing how well the agents can adapt to new, similar tasks after training.", "section": "6.4 Open-Vocabulary Task Generalization"}, {"figure_path": "Hz6cSigMyU/tables/tables_9_1.jpg", "caption": "Table 2: Zero-shot performance on Language Model Evaluation Harness [56], with details in Appendix J.", "description": "This table presents the zero-shot performance of different language models (LLaMA2-7B, TWOSOME, NTPO, and POAD) on four common NLP benchmarks: ARC_C, HellaSwag, PIQA, and MMLU.  It demonstrates the impact of fine-tuning the language models using reinforcement learning techniques (POAD, TWOSOME, and NTPO) on their original capabilities, specifically focusing on whether the fine-tuning process negatively affected their performance on these standard NLP tasks. The results show little to no negative effect, suggesting the proposed methods successfully align language models with embodied environments without compromising their core linguistic abilities.", "section": "6.6 Impact on Original Language Ability"}, {"figure_path": "Hz6cSigMyU/tables/tables_17_1.jpg", "caption": "Table 5: Average wall-times for POAD training with each dataset with 1 * Nvidia A100.", "description": "This table shows the average training time of the Policy Optimization with Action Decomposition (POAD) model on different datasets using one Nvidia A100 GPU.  It provides the wall-clock time for training and the number of environmental steps taken for each dataset. The datasets are those used in the DataSciCoding task, which involves training language models to generate code for data science tasks.", "section": "6.4 Open-Vocabulary Task Generalization"}, {"figure_path": "Hz6cSigMyU/tables/tables_18_1.jpg", "caption": "Table 3: Details of task datasets in DataSciCoding, where [K] denotes Kaggle.", "description": "This table shows the details of six datasets used in the DataSciCoding experiments. Three datasets (Pharyngitis, Health Insurance, Spaceship Titanic) are from Kaggle, while the remaining three (Airlines, Balance Scale, Breast-w) are from OpenML.  For each dataset, the number of features, samples, and classes are listed.  The [K] designation indicates that the dataset originates from Kaggle.", "section": "E.1 Details of Dataset Used in DataSciCoding Tasks"}, {"figure_path": "Hz6cSigMyU/tables/tables_19_1.jpg", "caption": "Table 4: The performance of the best code discovered during POAD\u2019s training process with CodeLLaMA-7B, comparing with CAAFE with GPT-3.5 and GPT-4. [K] denotes that the dataset is collected from Kaggle, while others are collected from OpenML.", "description": "This table compares the performance of the best code generated by POAD using CodeLLaMA-7B against CAAFE (using GPT-3.5 and GPT-4) across six different datasets.  It highlights the relative performance of POAD against state-of-the-art AutoML methods, particularly on datasets with higher complexity.", "section": "6.3.2 Data Science Coding Tasks with Unrestricted Action Space"}, {"figure_path": "Hz6cSigMyU/tables/tables_20_1.jpg", "caption": "Table 5: Average wall-time for POAD training with each dataset with 1 * Nvidia A100.", "description": "This table presents the average training time and the number of environmental steps for the POAD model on six different datasets used in the DataSciCoding task.  The datasets vary in size and complexity, which impacts the training time. The table shows that training times generally range from approximately 1 hour and 43 minutes to 3 hours and 5 minutes, indicating a reasonable training time for this task and scale of model.", "section": "6.4 Open-Vocabulary Task Generalization"}, {"figure_path": "Hz6cSigMyU/tables/tables_20_2.jpg", "caption": "Table 1: Comparison of generalization performance on eight unseen tasks, with episodic returns averaged over 100 episodes (The fewer timesteps consumed, the higher the returns). In these tasks, we replace the pancake in the original Food Preparation task with other foods like cheese, hamburger, apple pie and pizza, or replace the (pancake, microwave) at the same time with (dishes, dishwasher) or (clothes, washing machine) for greater differences. In parentheses is the success rate of completing the task within 50 timesteps.", "description": "This table shows a comparison of generalization performance across eight unseen tasks using different methods (LLaMA2-7B, TWOSOME, NTPO, and POAD).  The tasks involve replacing the original pancake task with various food items or kitchen appliances to test the models' ability to generalize to similar but unseen tasks.  Results are reported as episodic returns averaged over 100 episodes, with success rates within 50 timesteps in parentheses.", "section": "6.4 Open-Vocabulary Task Generalization"}, {"figure_path": "Hz6cSigMyU/tables/tables_20_3.jpg", "caption": "Table 7: Zero-shot performance on Common Sense Reasoning tasks", "description": "This table presents the zero-shot performance of four different language models (LLaMA2-7B, TWOSOME, NTPO, and POAD) on three common sense reasoning benchmarks: ARC_C, HellaSwag, and PIQA.  Zero-shot performance indicates the models' performance without any fine-tuning or specific training on these particular benchmarks. The results show the scores achieved by each model on each benchmark, providing a comparison of their reasoning capabilities in a common sense context.", "section": "6.6 Impact on Original Language Ability"}, {"figure_path": "Hz6cSigMyU/tables/tables_21_1.jpg", "caption": "Table 8: Details of Zero-shot performance on Massive Multitask Language Understanding tasks", "description": "This table presents the zero-shot performance of three different language models (LLaMA2-7B, TWOSOME, NTPO, and POAD) on a variety of tasks from the Massive Multitask Language Understanding benchmark.  The results show the performance of each model on each individual task, providing a detailed comparison of their zero-shot capabilities across diverse domains.", "section": "6.6 Impact on Original Language Ability"}, {"figure_path": "Hz6cSigMyU/tables/tables_22_1.jpg", "caption": "Table 9: Hyper-Parameters candidates for grid search in Overcooked, VirtualHome, and DataSciCoding environments.", "description": "This table presents the hyperparameter candidates explored during the grid search in three different environments: Overcooked, VirtualHome, and DataSciCoding.  The hyperparameters considered include learning rates for both critic and actor networks, the number of PPO epochs, the mini-batch size used during training, the discount factor (gamma), the entropy coefficient, and the maximum gradient norm.", "section": "K Hyper-Parameters Settings of Experiments"}, {"figure_path": "Hz6cSigMyU/tables/tables_22_2.jpg", "caption": "Table 10: Hyper-parameters used for POAD in Overcooked tasks.", "description": "This table shows the hyperparameter settings used for the Policy Optimization with Action Decomposition (POAD) method on the Overcooked tasks.  It lists the values used for parameters such as critic learning rate, actor learning rate, batch size, number of mini-batches, PPO clipping value, entropy coefficient, value coefficient, maximum gradient norm, gamma (discount factor), and KL (Kullback-Leibler divergence) threshold. These parameters were tuned for optimal performance within the POAD framework on Overcooked.", "section": "6.3.1 Classical Sequential Decision-Making Tasks with Restricted Action Space"}, {"figure_path": "Hz6cSigMyU/tables/tables_22_3.jpg", "caption": "Table 10: Hyper-parameters used for POAD in Overcooked tasks.", "description": "This table shows the hyperparameter settings used for the Policy Optimization with Action Decomposition (POAD) method in the Overcooked environment.  The hyperparameters are values chosen through a grid search or experimentation that yielded optimal performance for POAD on this specific task.  The parameters listed control various aspects of the training process, including learning rates, batch size, and exploration parameters.", "section": "6.3.1 Classical Sequential Decision-Making Tasks with Restricted Action Space"}, {"figure_path": "Hz6cSigMyU/tables/tables_22_4.jpg", "caption": "Table 10: Hyper-parameters used for POAD in Overcooked tasks.", "description": "This table shows the hyperparameters used for the Policy Optimization with Action Decomposition (POAD) method in the Overcooked environment.  It lists the values used for various parameters including learning rates for the critic and actor networks, batch size, number of mini-batches, PPO clipping, entropy coefficient, value coefficient, gamma, max gradient norm, and KL threshold. These parameters were tuned to optimize the performance of the POAD algorithm in this specific environment.", "section": "6.3.1 Classical Sequential Decision-Making Tasks with Restricted Action Space"}, {"figure_path": "Hz6cSigMyU/tables/tables_23_1.jpg", "caption": "Table 5: Average wall-times for POAD training with each dataset with 1 * Nvidia A100.", "description": "This table presents the average training time in hours and minutes for the Policy Optimization with Action Decomposition (POAD) model across six different datasets. Each dataset was trained using a single Nvidia A100 GPU.  The number of environmental steps for each dataset is also provided.", "section": "6.4 Open-Vocabulary Task Generalization"}, {"figure_path": "Hz6cSigMyU/tables/tables_23_2.jpg", "caption": "Table 5: Average wall-times for POAD training with each dataset with 1 * Nvidia A100.", "description": "This table presents the average training time in hours and minutes for the Policy Optimization with Action Decomposition (POAD) method on different datasets using a single Nvidia A100 GPU.  The number of environmental steps for each task is also included.", "section": "6.4 Open-Vocabulary Task Generalization"}, {"figure_path": "Hz6cSigMyU/tables/tables_23_3.jpg", "caption": "Table 5: Average wall-time for POAD training with each dataset with 1 * Nvidia A100.", "description": "This table shows the average training time in hours and minutes for the Policy Optimization with Action Decomposition (POAD) method on different datasets using one Nvidia A100 GPU. The number of environmental steps is also provided.", "section": "6.4 Open-Vocabulary Task Generalization"}, {"figure_path": "Hz6cSigMyU/tables/tables_23_4.jpg", "caption": "Table 10: Hyper-parameters used for POAD in Overcooked tasks.", "description": "This table shows the hyperparameter settings used for the Policy Optimization with Action Decomposition (POAD) method in the Overcooked experimental environment.  It lists the values used for various parameters such as the critic learning rate, actor learning rate, number of PPO epochs, batch size, mini-batch size, gamma, entropy coefficient, value coefficient, maximum gradient norm, and KL threshold. These parameters were found to produce the best performance for POAD in the Overcooked tasks.", "section": "6.3.1 Classical Sequential Decision-Making Tasks with Restricted Action Space"}, {"figure_path": "Hz6cSigMyU/tables/tables_23_5.jpg", "caption": "Table 5: Average wall-time for POAD training with each dataset with 1 * Nvidia A100.", "description": "This table presents the average training time taken by the POAD algorithm for each dataset used in the experiments.  The training was performed using a single Nvidia A100 GPU. The table shows the wall-time (hours and minutes) and the number of environmental steps for each dataset.", "section": "6.4 Open-Vocabulary Task Generalization"}]