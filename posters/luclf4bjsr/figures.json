[{"figure_path": "LuCLf4BJsr/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of Chain-of-Agents, a training-free, task agnostic, and highly-interpretable framework that harnesses multi-agent collaboration for long-context tasks. Blue boxes indicate communication unit CU\u2081 between worker agents Wi and Wi+1. It consists of multiple worker agents who sequentially communicate to handle different segmented portions of the text, followed by a manager agent who synthesizes these contributions into a coherent final output.", "description": "This figure illustrates the Chain-of-Agents (CoA) framework, which consists of two stages.  In the first stage, multiple worker agents each process a segmented portion of a long input text.  Each agent communicates its findings to the next agent in a sequential chain. The final worker agent passes its information to the manager agent. In the second stage, the manager agent synthesizes the information from all worker agents to produce a coherent final output. The figure highlights the communication units (CUi) between consecutive worker agents. This framework is designed to be training-free, task-agnostic, and highly interpretable.", "section": "3 Method"}, {"figure_path": "LuCLf4BJsr/figures/figures_6_1.jpg", "caption": "Figure 2: Performance of Claude 3 on BookSum. Improvement is more obvious for longer inputs.", "description": "This figure shows the performance comparison between the full-context model (Full-200k) and the Chain-of-Agents model (CoA-8k) on the BookSum dataset.  The x-axis represents the number of tokens in the source input, grouped into bins (0-80k, 80-160k, etc.). The y-axis represents the average ROUGE score, a metric for evaluating summarization quality.  The figure demonstrates that CoA consistently outperforms the full-context approach across all input lengths, and that the performance difference between the two methods is more pronounced as the input length increases, indicating that CoA is particularly effective for handling very long inputs.", "section": "5 Analyses"}, {"figure_path": "LuCLf4BJsr/figures/figures_7_1.jpg", "caption": "Figure 3: Comparison on NarrativeQA. X-axis/Y-axis indicate RAG/CoA performance while each point represents a bin. The number indicates the chunk index of gold answer (ratio of number of samples in bracket), and the size of the point indicates the improvement of CoA over RAG.", "description": "This figure shows a comparison of the performance of RAG and CoA on the NarrativeQA dataset. The x-axis represents the F1 score achieved by RAG, while the y-axis represents the F1 score achieved by CoA. Each point on the graph represents a bin of samples, categorized by the position of the chunk containing the gold answer within the RAG input.  The number near each point indicates the bin's index and the percentage of samples in that bin.  The size of each point visually represents the performance improvement of CoA over RAG for that bin. The dashed line indicates the trend line, showing the general improvement of CoA over RAG.", "section": "5 Analyses"}, {"figure_path": "LuCLf4BJsr/figures/figures_7_2.jpg", "caption": "Figure 1: Overview of Chain-of-Agents, a training-free, task agnostic, and highly-interpretable framework that harnesses multi-agent collaboration for long-context tasks. Blue boxes indicate communication unit CU\u2081 between worker agents Wi and Wi+1. It consists of multiple worker agents who sequentially communicate to handle different segmented portions of the text, followed by a manager agent who synthesizes these contributions into a coherent final output.", "description": "This figure illustrates the Chain-of-Agents (CoA) framework.  CoA consists of two stages: 1) Worker agents that sequentially process segmented parts of a long input text and communicate their findings to the next agent in the chain, and 2) A manager agent that synthesizes information from all worker agents to produce a final output. Each communication between worker agents is a 'communication unit' (CU). The framework addresses the challenge of LLMs struggling with long contexts by breaking down the task into smaller, manageable segments.", "section": "3 Method"}, {"figure_path": "LuCLf4BJsr/figures/figures_21_1.jpg", "caption": "Figure 6: Performance of CoA on Claude 3 Haiku on the NarrativeQA dataset with various context window sizes of an agent. Results show the robustness of CoA towards different choices of context lengths.", "description": "This figure demonstrates the performance of the Chain-of-Agents (CoA) model using the Claude 3 Haiku model on the NarrativeQA dataset.  The x-axis shows different context window sizes used for each agent within the CoA framework, and the y-axis displays the corresponding performance. The graph shows that the CoA model achieves its best performance with a 16k context window size for the agents, demonstrating the model's robustness to variations in agent context window size.  The performance remains relatively stable even as the context window size increases beyond the optimal value. This suggests that CoA is relatively insensitive to the specific choice of context window size within a reasonable range.", "section": "F.2 Robustness against Context Window Size"}, {"figure_path": "LuCLf4BJsr/figures/figures_22_1.jpg", "caption": "Figure 7: NIAH PLUS test results of Vanilla model and CoA model. Greener/Redder cells indicate higher/lower performance. CoA with 8k improves the performance of the NIAH test greatly compared with the Vanilla baseline.", "description": "This figure compares the performance of the Vanilla model and the CoA model on the NIAH PLUS test.  The heatmap visualization shows that the CoA model (with an 8k context window) significantly outperforms the Vanilla model, achieving much higher accuracy scores across a range of input lengths.  The greener cells represent higher accuracy while redder cells represent lower accuracy, illustrating CoA's effectiveness in long context understanding tasks.", "section": "F.3 Evaluation on NIAH Test"}]