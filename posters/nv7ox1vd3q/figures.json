[{"figure_path": "nv7ox1vd3q/figures/figures_6_1.jpg", "caption": "Figure 3: Here, we fix n = 250, d = 2000, \u03c3 = 0.1, \u03b8* ~ Bernoulli(0.01) and select \u03bb to minimize the predicted asymptotic loss. Plus marks denote the median over 100 trials, and the shaded region indicates the interquartile range. Left: Predictions and simulations for weighting functions which are not uniformly bounded. Right: Predictions and simulations for the squared error ||u\u2299v\u2212\u03b8*||2.", "description": "This figure compares theoretical predictions and simulation results for the l1 test error and mean squared error in sparse linear regression for several choices of reweighting function (\u03c8).  The left panel shows results for reweighting functions that are not uniformly bounded, while the right panel shows results for the squared error. The figure demonstrates that the asymptotic analysis provides accurate predictions even for functions that violate the boundedness assumption, showcasing the robustness and generalizability of the theoretical findings.", "section": "Further simulations"}, {"figure_path": "nv7ox1vd3q/figures/figures_8_1.jpg", "caption": "Figure 2: Group-blind (\u03c8gb) vs. group-aware (\u03c8ga) reweighting when \u03b8* has group-sparse structure. We set n = 500, d = 4000, \u03c3 = 0.1, and \u03b8* ~ Bernoulli(0.01)1b. For each curve, \u03bb is set to minimize the asymptotic test error achieved. Simulation results are the median/IQR over 100 trials. Left: Comparison of the test error trajectory (log scale) for a fixed block size b = 8. Right: l\u2081 test error after T = 4 iterations, for varying group sizes.", "description": "This figure compares the performance of group-blind and group-aware reweighting schemes for learning linear diagonal networks when the underlying signal has a group-sparse structure.  The left panel shows the test error trajectory (log scale) over eight iterations for a fixed block size (b=8). The right panel shows the test error after four iterations for various group sizes (b). The results demonstrate that a group-aware reweighting scheme significantly outperforms a group-blind approach, particularly as the group size increases.", "section": "4 Grouped IRLS and the benefits of structured feature learning"}, {"figure_path": "nv7ox1vd3q/figures/figures_24_1.jpg", "caption": "Figure 3: Here, we fix n = 250, d = 2000, \u03c3 = 0.1, \u03b8* ~ Bernoulli(0.01) and select \u03bb to minimize the predicted asymptotic loss. Plus marks denote the median over 100 trials, and the shaded region indicates the interquartile range. Left: Predictions and simulations for weighting functions which are not uniformly bounded. Right: Predictions and simulations for the squared error ||u\u2299v\u2212\u03b8*||2.", "description": "This figure compares theoretical predictions and experimental simulations of the l1 test error and mean squared error for different reweighting functions.  It showcases the accuracy of the theoretical predictions, even when the reweighting functions don't meet the strict assumptions of the theoretical analysis (for example, the functions are not uniformly bounded).  The plots show the median error and interquartile range over 100 trials.", "section": "Further simulations"}, {"figure_path": "nv7ox1vd3q/figures/figures_24_2.jpg", "caption": "Figure 3: Here, we fix n = 250, d = 2000, \u03c3 = 0.1, \u03b8*  Bernoulli(0.01) and select \u03bb to minimize the predicted asymptotic loss. Plus marks denote the median over 100 trials, and the shaded region indicates the interquartile range. Left: Predictions and simulations for weighting functions which are not uniformly bounded. Right: Predictions and simulations for the squared error ||u\u2299v\u2212\u03b8*||2.", "description": "This figure compares theoretical predictions and simulation results for the mean squared error of different reweighting functions in high-dimensional sparse linear regression. The left panel focuses on reweighting functions that are not uniformly bounded, while the right panel shows results for the squared error.  The results show a close match between theoretical predictions and simulations across various reweighting schemes and demonstrate that even without uniformly bounded reweighting functions the model yields accurate results.  The test error is low after only a few iterations across all considered weightings.", "section": "Further simulations"}]