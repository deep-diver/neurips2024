[{"type": "text", "text": "Robust Neural Contextual Bandit against Adversarial Corruptions ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Yunzhe Qi, Yikun Ban, Arindam Banerjee, Jingrui He ", "page_idx": 0}, {"type": "text", "text": "University of Illinois at Urbana-Champaign Champaign, IL 61820 {yunzheq2,yikunb2,arindamb,jingrui}@illinois.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Contextual bandit algorithms aim to identify the optimal arm with the highest reward among a set of candidates, based on the accessible contextual information. Among these algorithms, neural contextual bandit methods have shown generally superior performances against linear and kernel ones, due to the representation power of neural networks. However, similar to other neural network applications, neural bandit algorithms can be vulnerable to adversarial attacks or corruptions on the received labels (i.e., arm rewards), which can lead to unexpected performance degradation without proper treatments. As a result, it is necessary to improve the robustness of neural bandit models against potential reward corruptions. In this work, we propose a novel neural contextual bandit algorithm named R-NeuralUCB, which utilizes a novel context-aware Gradient Descent (GD) training strategy to improve the robustness against adversarial reward corruptions. Under over-parameterized neural network settings, we provide regret analysis for R-NeuralUCB to quantify reward corruption impacts, without the commonly adopted arm separateness assumption in existing neural bandit works. We also conduct experiments against baselines on real data sets under different scenarios, in order to demonstrate the effectiveness of our proposed R-NeuralUCB. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Contextual bandits refer to one specific type of multi-armed bandit (MAB) problems, where the learner can access the arm context information during the decision-making process. Contextual bandit algorithms have been commonly applied in various real-world applications, including online content recommendation [59, 79, 8], and medical experiments [30, 73, 7]. While these algorithms have been proved effective for numerous online learning tasks, they can be susceptible to the malicious feedback from the environment, such as malicious user feedback in recommender systems [64], and corrupted labels under active learning settings [61]. This can potentially impair the model performance and interfere with the internal decision-making logic. One renowned research direction formulates this problem as contextual bandits with adversarial corruptions [57, 42, 16], where received arm rewards can be potentially ^corrupted\" by the unknown adversary. In this case, bandit algorithms need to be robust against such adversarial corruptions, otherwise they can lead to sub-optimal results. Existing works on contextual bandits with corruptions are mainly based on linear [17, 29, 57] and kernelized bandits [15, 16], where the unknown reward mapping function is assumed to be linear, or lies in a specified Reproducing Kernel Hilbert Space (RKHS). However, one key challenge is that these assumptions can evidently fail under real-world application scenarios [86], when we have little prior knowledge regarding this mapping function, or it becomes increasingly complex. ", "page_idx": 0}, {"type": "text", "text": "In the face of this challenge, neural bandit algorithms [86, 84, 11, 12] have been proposed to relax the assumptions on reward functions. By leveraging the representation power of neural networks, neural contextual bandit algorithms are able to deal with complex reward functions irrespective of whether they are linear or non-linear, along with suitable exploration strategies for tackling the exploitationexploration dilemma [5, 59]. While neural bandit algorithms have been proved effective [9, 68, 60], they can be sensitive to adversarial corruptions as well. From perspectives of trustworthiness, it is well known that neural models can be susceptible to \u201clabel attacks\" [71, 62, 65], which is akin to reward corruptions in bandit settings. Failure to comply with robustness requirements can impair the feasibility under real-world application scenarios like recommender systems [82, 27, 87, 78], and therefore it is necessary for neural bandit methods to be robust against potential adversarial corruptions. Furthermore, existing neural bandit works generally require arm separateness assumptions (e.g.. assuming a positive-definite Neural Tangent Kernel [NTK] Gram matrix [86, 84, 26], or positive arm Euclidean distances [11, 67]), which will require no duplicate arm contexts are observed (or chosen) by the learner. This can lead to additional vulnerabilities when arm contexts are intentionally chosen by the adversary (e.g., assigning duplicate arms in the candidate pool across different rounds), making the arm separateness assumption fail in such adversarial environments. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Motivated by aforementioned challenges, in this paper, we propose a novel neural contextual bandit algorithm named Robust Neural-UCB (R-NeuralUCB), which can model the discrepancy among candidate arms and adopt arm-specific context-aware Gradient Descent (GD) to enhance model robustness against reward corruptions. Instead of applying ordinary GD to update the network parameters, R-NeuralUCB utilizes a fine-grained GD strategy by modeling the importance level of training samples, to reduce the impact of potential adversarial reward corruptions. Meanwhile, to improve the model performance from both the theoretical and empirical perspectives, R-NeuralUCB simultaneously perceives the uncertainty levels of candidate arms, and adaptively customizes network parameters for each of these candidates. To deal with the exploitation-exploration dilemma, RNeuralUCB is equipped with an informative exploration mechanism based on Upper Confidence Bound (UCB) to achieve principled exploration. In addition, we present regret analysis without the commonly adopted arm separateness assumption, which reinforces R-NeuralUCB's theoretical robustness under adversarial scenarios. Our contributions can be summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u00b7 Problem Settings and Proposed algorithm: We study a novel neural bandit problem, where the received arm reward can be potentially corrupted by the unknown adversary. To deal with this problem, we propose a novel neural bandit algorithm called R-NeuralUCB, which leverages a refined context-aware Gradient Descent training strategy to improve the model robustness against potential arm reward corruptions. While we consider all the observed arms are governed by the same unknown reward mapping function as in (1) similar to existing neural bandit works, our R-NeuralUCB interestingly maintains separate model parameters specific to the different candidate arms, for a fine-grained way of improving the robustness. This casts lights on our contributions of novel algorithmic designs, compared to related existing methods without an arm-specific modeling (e.g., [42] and our base algorithm NeuralUCB-WGD in Appendix E). ", "page_idx": 1}, {"type": "text", "text": "\u00b7 Theoretical Analysis: With over-parameterized neural networks, we present the regret analysis for R-NeuralUCB. Given finite horizon $T$ , effective dimension of NTK Gram matrix d, and corruption level $C$ , R-NeuralUCB enjoys a data-dependent regret bound of $\\widetilde{\\mathcal{O}}(\\widetilde{d}\\sqrt{T}+C\\widetilde{d})$ . In addition, to ensure R-NeuralUCB is capable of handling contexts specified by the adversary (e.g., duplicate arms across different rounds), our analysis removes the arm separateness assumption dependency, a widely adopted assumption for neural bandit literature, which can be of independent interest. ", "page_idx": 1}, {"type": "text", "text": "\u00b7 Experiments: We conduct experiments on publicly available real-world data sets with various specifications. Under different types of reward corruptions, our R-NeuralUCB can achieve better performance, and is less vulnerable to reward corruptions than baselines. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Contextual Bandits with Adversarial Corruptions. To begin with, there have been numerous studies [76, 17, 29, 57, 63, 31, 22, 54] working on tackling adversarial reward corruptions under linear contextual bandit settings [59, 24]. A related topic is bandits with mis-specifications [36, 55, 33, 53, 83, 75], where the deviation of reward estimation comes from problem modeling instead of the adversary. On the other hand, kernelized bandits [15, 40, 16] extend the adversarial corruption problem to non-linear cases by assuming the reward mapping is a functional in the specified RKHS [72], while comparable ideas are also applicable for robust Bayesian Optimization [52]. Adversarial corruptions are also studied for other formulations, such as Lipschitz bandits [49, 89] and MAB without contexts [18, 80]. However, compared with neural bandit methods, these works generally require assumptions on the reward function prior, which may not be satisfied in real-world scenarios. ", "page_idx": 1}, {"type": "text", "text": "Neural Contextual Bandits. Neural contextual bandits algorithms are proposed to leverage the representation power of neural networks, and relax the assumptions on the reward mapping functions that can be linear or non-linear. Neural-UCB [86] applies a fully-connected (FC) neural network for reward estimation and utilizes corresponding network gradients for principled exploration. Comparable ideas have been leveraged by other neural bandit works [84, 50, 25, 10, 37, 46, 9, 60, 11], and adopted under various application scenarios such as active learning [74, 13, 6], and bandit-based graph learning [66, 67, 51] with graph neural networks [77, 34, 35]. Alternatively, [81] utilizes the neural network to embed original arm contexts for regression. [26] utilizes inverse reward gap for exploration, and [48] achieves exploration with the reward perturbation. However, as these methods are not designed to defend against reward corruptions and widely require arm separateness assumptions, they can fail to meet the robustness requirements in an adversarial environment. ", "page_idx": 2}, {"type": "text", "text": "3 Problem Definition ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Let $T$ be the finite horizon. In round $t\\in[T]$ , the learner receives $K$ candidate arms $\\scriptstyle{\\mathcal{X}}_{t}$ \uff0c $|\\mathcal{X}_{t}|=K$ and each arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ with arm index $i\\in[K]$ is described by a $d$ -dimensional vector $\\pmb{x}_{i,t}\\in\\mathbb{R}^{d}$ The learner will then choose one arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ and receive its reward $r_{t}$ . The index of $\\pmb{x}_{t}$ is denoted by $i_{t}\\in[K]$ , s.t. $\\pmb{x}_{t}=\\pmb{x}_{i_{t},t}$ . Here, similar to existing works (e.g., [42, 16, 15, 86, 84]), we define corruption-free arm reward $\\widetilde{r}_{i,t}$ for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , as well as corrupted arm reward $r_{t}$ for chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ , as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widetilde{r}_{i,t}=h(\\pmb{x}_{i,t})+\\epsilon_{i,t},\\qquad\\qquad r_{t}=\\widetilde{r}_{t}+c_{t}=h(\\pmb{x}_{t})+\\epsilon_{t}+c_{t},}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $h:\\,\\mathbb{R}^{d}\\,\\mapsto\\,\\mathbb{R}$ is an unknown reward mapping function that can be either linear or nonlinear. $\\epsilon_{i,t}\\in\\mathbb{R}$ stands for zero-mean $\\nu$ -sub-Gaussian random noise which is standard for stochastic contextual bandit works (e.g., [24, 72, 86]), and $c_{t}~\\in~\\mathbb{R}$ is the unknown adversarial corruption imposed by the adversary. While kernelized bandit works (e.g., [16, 72]) assume $h(\\cdot)$ belongs to the RKHS induced by specified kernels, we alternatively consider $h(\\cdot)$ as an arbitrary unknown function, and utilize the neural model to learn this mapping with flexibility. ", "page_idx": 2}, {"type": "text", "text": "Taking expectation w.r.t. zero-mean noise $\\epsilon$ , for the chosen arm $\\pmb{x}_{t}\\,\\in\\,\\mathcal{X}_{t}$ , we denote its expected perturbed reward $\\mathbb{E}[r_{t}]=h(\\pmb{x}_{t})+c_{t}$ ; meanwhile, for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , its expected corruption-free reward $\\mathbb{E}[\\widetilde{\\boldsymbol{r}}_{i,t}]=h(\\boldsymbol{x}_{i,t})$ . Here, we consider $\\mathbb{E}[r]$ and $\\mathbb{E}[\\widetilde{r}]$ both fall into value range $[0,1]$ , analogous to existing works (e.g., [86, 84, 11, 50]). This is intuitive as numerous real-world applications work with bounded rewards (e.g., online recommendation tasks with normalized rating [67] or binary feedback [24]); and the adversary also needs its attack to be stealthy, by ensuring perturbed rewards fall into the normal value range. With previously chosen arms $\\{\\overbar{\\mathbf{\\it{x}}}_{\\tau}\\}_{\\tau\\in[t]}$ up to round $t$ we denote received context-reward tuples with pertured rewards as ${\\mathcal{P}}_{t}:=\\{{\\pmb x}_{\\tau},r_{\\tau}\\}_{\\tau\\in[t]}=$ $\\{\\pmb{x}_{i_{\\tau},\\tau},r_{i_{\\tau},\\tau}\\}_{\\tau\\in[t]}$ , and the corresponding context-reward tuples with corruption-fre rewards as $\\widetilde{\\mathcal{P}}_{t}:=\\{\\pmb{x}_{\\tau},\\widetilde{r}_{\\tau}\\}_{\\tau\\in[t]}\\,=\\,\\{\\pmb{x}_{i_{\\tau},\\tau},\\widetilde{r}_{i_{\\tau},\\tau}\\}_{\\tau\\in[t]}$ where each corruption-free but imaginary unobserved reward is $\\widetilde{r}_{\\tau}=h(\\pmb{x}_{\\tau})+\\epsilon_{\\tau},\\tau\\in[t]$ based on (1). ", "page_idx": 2}, {"type": "text", "text": "Learning Objective. Our objective is to minimize cumulative pseudo-regret for $T$ rounds: ", "page_idx": 2}, {"type": "equation", "text": "$$\nR(T)=\\sum_{t=1}^{T}\\mathbb{E}[\\widetilde{r}_{t}^{*}-\\widetilde{r}_{t}],\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\mathbb{E}[\\widetilde{r}_{t}]\\;=\\;h({\\mathbf x}_{t})$ is the expected corruption-free reward of the chosen arm $\\mathbf{\\mathcal{x}}_{t}~\\in~\\mathcal{X}_{t}$ , and $\\mathbb{E}[\\widetilde{\\boldsymbol{r}}_{t}^{*}]=\\operatorname*{max}_{\\mathbf{x}_{i,t}\\in\\mathcal{X}_{t}}[h(\\mathbf{x}_{i,t})]$ stands for that of the optimal arm $\\mathbf{\\boldsymbol{x}}_{t}^{*}\\in\\mathcal{X}_{t}$ ", "page_idx": 2}, {"type": "text", "text": "Corruption Level. If the adversary determines the reward corruption $c_{i,t}$ for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ beforehand, without observing the learner's choice $\\pmb{x}_{t}$ , some works (e.g., [38]) formulate the corruption level measurement as $\\begin{array}{r}{\\bar{C^{\\prime}}\\overset{}{=}\\sum_{t\\in[T]}[\\operatorname*{max}_{i\\in[K]}|c_{i,t}|]}\\end{array}$ . In this work, similar to [42, 16], we alternatively consider reward corruptions are determined w.r.t. particular chosen arms $\\{\\boldsymbol{x}_{t}\\}_{t\\in[T]}$ and formulate the corruption level as $\\begin{array}{r}{C=\\sum_{t\\in[T]}|c_{t}|}\\end{array}$ This leads to $C\\le C^{\\prime}$ ", "page_idx": 2}, {"type": "text", "text": "4  Proposed Algorithm: Robust Neural-UCB (R-NeuralUCB) ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Recall that in (1), arm rewards under neural bandit settings are governed by the unknown reward mapping function $h(\\cdot)$ ,where $h(\\cdot)$ can be an arbitrary function. For our proposed R-NeuralUCB, we adopt a neural network $f(\\cdot)$ to approximate $h(\\cdot)$ for reward estimation. ", "page_idx": 2}, {"type": "text", "text": "Network Structure. We use $f(\\cdot;\\pmb\\theta)$ to denote an FC network with depth $L\\ge2$ and width $m\\in\\mathbb{N}^{+}$ ", "page_idx": 2}, {"type": "equation", "text": "$$\nf(\\pmb{x};\\pmb{\\theta}):=\\sqrt{m}\\pmb{\\theta}_{L}\\sigma(\\pmb{\\theta}_{L-1}\\sigma(\\pmb{\\theta}_{L-2}\\ldots\\sigma(\\pmb{\\theta}_{1}\\pmb{x})))\n$$", "text_format": "latex", "page_idx": 2}, {"type": "table", "img_path": "6U8iV9HVpS/tmp/952875e62aca759b6b737bb80487d3448bae5a2862c2156f8ede3406b23e4a16.jpg", "table_caption": ["Table 1: Comparison of $T$ -round regret bounds with adversarial corruption level $C$ "], "table_footnote": ["d: context dimension; $\\hat{d}$ NTK matrix effective dmensionor kernel information gain; $\\beta$ : data-dependent gradient deviation term. "], "page_idx": 3}, {"type": "text", "text": "Where $\\sigma(\\cdot)$ is element-wise ReLU activation, and we have trainable weight matrices $\\pmb{\\theta}_{1}\\in\\mathbb{R}^{m\\times d}$ $\\pmb{\\theta}_{l}\\in\\mathbb{R}^{m\\times m}$ $\\begin{array}{r}{m\\times m,2\\le l\\le L-1,\\pmb{\\theta}_{L}\\in\\mathbb{R}^{1\\times m}}\\end{array}$ For the ease of notation, we denote vectorized parameters ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\pmb{\\theta}:=[\\mathrm{vec}(\\pmb{\\theta}_{1})^{\\top},\\mathrm{vec}(\\pmb{\\theta}_{2})^{\\top},\\dots,\\pmb{\\theta}_{L}]^{\\top}\\in\\mathbb{R}^{p},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "with the dimensionality of $p$ , and randomly initialized parameters are denoted by $\\theta_{0}$ . Then, we let $g(\\pmb{x};\\pmb{\\theta})=\\mathrm{vec}(\\nabla_{\\pmb{\\theta}}f(\\pmb{x};\\pmb{\\theta}))\\overset{\\cdot}{\\in}\\mathbb{R}^{p}$ be vectorized network gradients w.r.t. input $\\textbf{\\em x}$ and parameters $\\pmb{\\theta}$ ", "page_idx": 3}, {"type": "text", "text": "We motivate our proposed R-NeuralUCB by first mentioning a base algorithm named NeuralUCB with Weighted GD (NeuralUCB-WGD), which is elaborated in Appendix E. To begin with, NeuralUCB-WGD measures the uncertainty level of training samples (i.e., previously received armreward pairs) through their UCB values, as the UCB essentially measures arm uncertainty levels in terms of reward estimation [24, 72, 86]. Then, different from conventional neural bandit methods that treat all training samples equally [86, 84], inspired by [42], NeuralUCB-WGD utilizes a weighted GD process to train neural model $f(\\cdot)$ for estimating arm rewards, where training samples with high uncertainty levels will be downplayed. The main idea is that although we do not know which training samples are corrupted, we instead aim to reduce potentially severe impacts caused by adversarial corruptions, by paying relatively more attention on the training samples (arm-reward pairs) with low uncertainty levels, for a stable GD training process. We also present corresponding regret analysis for NeuralUCB-WGD in Appendix E.2, as well as experiments in Section 6. ", "page_idx": 3}, {"type": "text", "text": "However, notice that the neural model will also perceive varying uncertainty levels for different candidate arms in terms of reward estimation. In this case, simply applying the same exploitationexploration strategy across all candidate arms can overlook this discrepancy, leading to insufficient granularity w.r.t. reward estimation. For instance, regarding candidate arms with low uncertainty levels, it can be more beneficial to adequately leverage existing training samples for estimating their rewards, instead of sharing an identical exploitation-exploration strategy with other high-uncertainty candidate arms. Meanwhile, analogous to existing works (e.g., [42, 16, 15]), NeuralUCB-WGD supposes a known corruption level $C$ for regret analysis (Theorem E.1), which can be difficult to satisfy if we have limited knowledge regarding the unknown adversary. With the above motivations, we propose R-NeuralUCB as a refined solution to further enhance neural model robustness against potential reward corruptions. For readers? reference, we also compare our proposed R-NeuralUCB and NeuralUCB-WGD with some regret results from existing works in Table 1. ", "page_idx": 3}, {"type": "text", "text": "4.1 R-NeuralUCB: Robust Neural-UCB ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Our R-NeuralUCB formulates a novel context-aware GD process, by taking the uncertainty information of both candidate arms and training samples into account, for neural network training and decision making. Here, R-NeuralUCB customizes individual sets of network parameters $\\theta_{i,t-1}$ for each candidate arm $\\mathbf{\\Deltax}_{i,t}\\in\\mathcal{X}_{t},i\\in[K]$ , before the actual arm recommendation. Afterwards, these arm-specific networks are applied for arm reward estimation, along with an informative arm-specific UCB-based exploration mechanism. The pseudo-code is presented in Algorithm 1. ", "page_idx": 3}, {"type": "text", "text": "Arm Weight Formulation. Inspired by NTK-based exploration mechanisms [86, 51, 66, 11, 84], we measure arm uncertainty levels with the weighted gradient norm of arms. With a_regularization_ parameter $\\lambda~>~0$ :we first define a weight-free gradient covariance matrix $\\bar{\\Sigma}_{t-1}=$ $\\begin{array}{r}{\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m}\\end{array}$ . Here, $\\theta_{\\tau-1}$ is the shorthand of $\\theta_{i_{\\tau},\\tau-1}$ , representing the network parameters of the previously chosen arm $\\pmb{x}_{\\tau}\\,=\\,\\pmb{x}_{i_{\\tau},\\tau},\\tau\\,\\in\\,[t\\,-\\,1]$ . Then, for each ", "page_idx": 3}, {"type": "text", "text": "1: Input: Time horizon $T$ . GD iterations $J$ . Learning rate $\\eta$ . Exploration coefficient $\\nu$ . Scaling   \nparameter $\\alpha$ . Norm parameter $S$ . Regularization parameter $\\lambda$   \n2: Initialization: Parameters $\\theta_{0}$ . Weight-free covariance matrix $\\bar{\\Sigma}_{0}=\\lambda\\mathbf{I}$ . Records $\\mathcal{P}_{0}=\\emptyset$   \n3: for each round $t\\in[T]$ do   \n4:Observe acollecionof $K$ candidate arms $\\mathcal{X}_{t}=\\{\\pmb{x}_{i,t}\\}_{i\\in[K]}$   \n5:  for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ do   \n6: if $t$ equals to 1 then   \n7: $\\pmb{\\theta}_{i,t-1}\\leftarrow\\pmb{\\theta}_{0}$   \n8: else   \n9: With arm weights $\\{w_{i,t}^{(\\tau)}\\}_{\\tau\\in[t-1]}$ in (4), rain prameters $\\theta_{i,t-1}$ with GD and the arm  \nspecific loss function in (5) based on received records $\\mathcal{P}_{t-1}$   \n10: end if   \n11: For candidate arm $\\pmb{x}_{i,t}$ , calculate its benefit score $U(\\pmb{x}_{i,t})$ based on (6).   \n12: end for   \n13: Choose arm $\\begin{array}{r}{\\pmb{x}_{t}=\\arg\\operatorname*{max}_{\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}}\\left[U(\\pmb{x}_{i,t})\\right]}\\end{array}$ with the highest benefit score.   \n14: Receive arm reward $r_{t}$ , and update the records, such that $\\mathcal{P}_{t}\\leftarrow\\mathcal{P}_{t-1}\\cup\\{(\\mathbf{x}_{t},r_{t})\\}$   \n15: Update the shorthand $\\pmb{\\theta}_{t-1}\\gets\\pmb{\\theta}_{i_{t},t-1}$ , and matrix $\\bar{\\Sigma}_{t}\\leftarrow\\bar{\\Sigma}_{t-1}\\!+\\!g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})^{\\top}/m.$   \n16: end for ", "page_idx": 4}, {"type": "text", "text": "candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , we formulate its weight w.r.t. previously chosen arm $\\mathbf{\\boldsymbol{x}}_{\\tau},\\tau\\in[t-1]$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\nw_{i,t}^{(\\tau)}=\\operatorname*{min}\\left\\{1,\\ \\frac{\\alpha\\cdot\\operatorname*{min}_{x\\in\\mathcal{X}_{t}}\\lVert g(\\pmb{x};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\rVert_{\\bar{\\Sigma}_{t-1}^{-1}}^{2}}{g_{\\tau}\\cdot\\lVert g(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\rVert_{(\\bar{\\Sigma}_{t-1}^{(\\kappa)})^{-1}}}\\right\\},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "with 2-scaled covariance matrix being \u2265() = I + k2 - Te(t-1 (; 0-1)g(a; 0,-1)T/m, for a constant  E (0, 1). Alternatively, we also denote w) $w_{i,t}^{(\\tau)}=\\operatorname*{min}\\left\\lbrace1,\\alpha\\cdot\\mathsf{f r a c}_{\\tau}(\\pmb{x}_{i,t};\\pmb{\\chi}_{t},\\pmb{\\bar{\\Sigma}}_{t-1})\\right\\rbrace$ with $\\mathtt{f r a c}_{\\tau}(\\cdot)$ being a shorthand that integrally represents the fraction term in (4). A tunable parameter $\\alpha>0$ andhqareddwimd $\\begin{array}{r l}&{\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{X}_{t}}\\|g(\\pmb{x};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{\\bar{\\pmb{\\Sigma}}_{t-1}^{-1}}^{2}}\\end{array}$ inthe numerator are applied for scaling purposes. We also include complementary discussions for arm weight scaling in Appendix B.5. Meanwhile, we have $g_{\\tau}=\\|g(\\pmb{x}_{\\tau};\\bar{\\pmb{\\theta_{\\tau-1}}})/\\sqrt{m}\\|_{(\\bar{\\pmb{\\Sigma}}_{\\tau-1}^{(\\kappa)})^{-1}},\\tau\\in[t\\!-\\!1]$ quantifying uncertainty levels of previously chosen arms (training samples) motivated by UCB-based exploration strategies (e.g., [86, 42]). Since previous $\\{g_{\\tau}\\}_{\\tau\\in[t-1]}$ values can be reused, we only need to compute and store $g_{t}$ for current round $t$ . As a result, if candidate arm $\\pmb{x}_{i,t}$ is of high uncertainty (i.e., large $\\lVert g(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\rVert_{\\bar{\\pmb{\\Sigma}}_{t-1}^{-1}}$ value), its arm weights $\\{w_{i,t}^{(\\tau)}\\}_{\\tau\\in[t-1]}$ will become small. ", "page_idx": 4}, {"type": "text", "text": "Model Training with Context-aware GD. According to line 9 in Algorithm 1, we perform model training before the actual arm recommendation in each round $t\\in\\{2,\\ldots,T\\}$ . For each candidate $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , we train its arm-specific parameters $\\theta_{i,t-1}$ with $J$ iterations of GD and received records $\\mathcal{P}_{t-1}\\,=\\,\\{(\\mathbf{x}_{\\tau},r_{\\tau})\\}_{\\tau\\in[t-1]}$ . Starting from initialization $\\pmb{\\theta}_{i,t-1}^{(0)}\\,=\\,\\pmb{\\theta}_{0}$ ,we have $j$ -th GD iteration $(j\\in[J])$ being $\\pmb{\\theta}_{i,t-1}^{(j)}=\\pmb{\\theta}_{i,t-1}^{(j-1)}-\\eta\\nabla_{\\pmb{\\theta}}\\mathcal{L}_{i,t}(\\mathcal{P}_{t-1};\\pmb{\\theta}_{i,t-1}^{(j-1)})$ where $\\eta>0$ refersto the earming rate. We formulate a loss function $\\mathcal{L}_{i,t}(\\cdot;\\cdot),i\\in[K]$ specified to candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathcal L_{i,t}(\\mathcal P_{t-1};\\pmb\\theta)=\\sum_{(\\boldsymbol x_{\\tau},\\boldsymbol r_{\\tau})\\in\\mathcal P_{t-1}}\\frac{w_{i,t}^{(\\tau)}}{2}\\cdot\\left|f(\\boldsymbol x_{\\tau};\\pmb\\theta)-\\boldsymbol r_{\\tau}\\right|^{2}+\\frac{m\\lambda}{2}\\cdot\\|\\pmb\\theta-\\pmb\\theta_{0}\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where the $L_{2}$ loss is scaled by arm weights $w_{i,t}^{(\\tau)},\\tau\\in[t-1]$ from (4). Intuitively,if arm weights $w_{i,t}^{(\\tau)}$ are large (i.e., low uncertainty level), we proceed to train a neural model that adequately fits the collected training data (i.e., previously received records) $\\mathcal{P}_{t-1}$ , instead of staying around the random initialization $\\theta_{0}$ given the $L_{2}$ regularization On the ther hand, if arm weighs $w_{i,t}^{(\\tau)}$ an are small, it means that the uncertainty level in terms of reward estimation is high. In this case, we prefer being relatively conservative to prevent potentially large impacts caused by adversarial corruptions. As a result, R-NeuralUCB will focus more on the training samples in $\\mathcal{P}_{t-1}$ with low uncertainty levels, and stay relatively close to the random initialization $\\pmb{\\theta}_{0}$ due to the regularization term in (5). ", "page_idx": 4}, {"type": "text", "text": "In practice, instead of starting from $\\pmb{\\theta}_{0}$ in each round $t\\in\\{2,\\ldots,T\\}$ , we can alternatively initiate the GD process from the existing trained parameters to reduce computational cost, inspired by the concept of warm-start GD [13]. Here, we can start from $\\pmb{\\theta}_{t-2}$ , the parameters of the previously chosen arm $x_{t-1}$ , and fine-tune arm-specific parameters $\\theta_{i,t-1}$ for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ \uff0c based on its loss function $\\mathcal{L}_{i,t}(\\cdot;\\cdot)$ and a small batch of samples from $\\mathcal{P}_{t-1}$ . Further details are elaborated in Appendix B.6, and this approach is also applied for the experiments in Section 6. ", "page_idx": 5}, {"type": "text", "text": "Arm Selection For candidate am $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ and arm weights $\\{w_{i,t}^{(\\tau)}\\}_{\\tau\\in[t-1]}$ , we formulae its armspecific gradient covariance matrix $\\begin{array}{r}{\\Sigma_{i,t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})\\^{\\top}/m}\\end{array}$ Here, if the variance proxy value $\\nu$ in (1) is unknown, similar to existing works (e.g., [86, 84]), we deem $\\nu\\geq0$ as a tunable parameter to control the exploration intensity. With our UCB-type exploration motivated by Appendix Lemma C.11, we formulate the benefit score for arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ as ", "page_idx": 5}, {"type": "equation", "text": "$$\nU(\\boldsymbol{x}_{i,t})=f(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})+\\gamma_{i,t-1}\\cdot\\sqrt{g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})\\tau\\Sigma_{i,t-1}^{-1}g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})/m},\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where the conidence coeficient /,-1 = (vlog det&(t) $\\begin{array}{r}{\\gamma_{i,t-1}=\\zeta\\cdot\\left(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}(\\Sigma_{i,t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\sqrt{\\lambda S}\\right)}\\end{array}$ constant $\\zeta>0$ from Lemma C.11. Afterwards, we choose $\\begin{array}{r}{\\pmb{x}_{t}=\\arg\\operatorname*{max}_{\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}}\\left[U(\\pmb{x}_{i,t})\\right]}\\end{array}$ (line 13, Algorithm 1), based on calculated arm benefit scores in (6). After receiving reward $r_{t}$ , the collected records will be updated by $\\mathcal{P}_{t}\\,\\leftarrow\\,\\mathcal{P}_{t-1}\\cup\\{(\\pmb{x}_{t},r_{t})\\}$ (line 14, Algorithm 1). We also update the shorthand for model parameters of the chosen arm as $\\pmb{\\theta}_{t-1}\\gets\\pmb{\\theta}_{i_{t},t-1}$ , and the weight-free covariance matrix $\\bar{\\Sigma}_{t}\\leftarrow\\bar{\\Sigma}_{t-1}+g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})^{\\top}/m$ for next round $t+1$ (line 15, Algorithm 1). ", "page_idx": 5}, {"type": "text", "text": "In summary, the primary goal of R-NeuralUCB is to customize individual learning objectives (i.e., loss functions) for different candidate arms by leveraging arm uncertainty information before pulling an arm. For candidate arms with high uncertainty levels, the neural model may lack confidence in estimating rewards based on current records, due to potential reward corruptions, which can lead to significant estimation errors. In this situation, by using the regularization term $\\frac{m\\lambda}{2}\\|\\pmb{\\theta}-\\pmb{\\theta}_{0}\\|_{2}^{2}$ we prefer to adopt a relatively conservative approach, training a model close to random initialization to mitigate the potentially large impacts of adversarial corruptions. This approach is inspired by existing work on enhancing model robustness through regularization techniques (e.g., [69, 23]). On the other hand, for candidate arms with low uncertainty, we aim to train neural models that fully utilize the received records for reward estimation. Since the model is confident in its estimation, the received samples can provide adequate reference. With larger arm weights, the loss function can focus more on the training samples, instead of staying closely around $\\theta_{0}$ ", "page_idx": 5}, {"type": "text", "text": "5  Theoretical Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To the best of our knowledge, we provide the first theoretical results under the neural bandit settings with adversarial reward corruptions, and our proof flow is distinct from those of linear and kernelized bandit works. In particular, as our ReLU activation in (3) is not Lipschitz smooth [3, 21], it leads to additional challenges for our theoretical analysis, since a small perturbation on rewards can lead to drastic changes of network gradients. As a result, even with a small corruption level $C$ thecorrupted model parameters trained by GD can significantly deviate from the imaginary network parameters trained with corresponding corruption-free rewards. Therefore, it is non-trivial to quantify corruption impacts from theoretical perspectives, which simultaneously makes our proof flow differ significantly from that of the vanilla Neural-UCB [86]. We include additional discussions on analysis distinctions and our contributions in Appendix B.3. To begin with, we first introduce some preliminaries. ", "page_idx": 5}, {"type": "text", "text": "Parameter Initialization. Analogous to existing works [86, 21, 3, 9, 84], for an $L$ -layernetworkof width $m$ in (3), we let its intermediate-layer matrices $\\pmb{\\theta}_{l}=\\(\\mathbf{\\Delta}_{\\mathbf{0}}^{\\mathbf{\\Delta}}\\mathbf{\\Delta}_{\\mathbf{\\Lambda}}^{\\mathbf{0}}),l\\in[\\bar{L}-1]$ ,where eachelement of matrix $\\Lambda$ is drawn from Gaussian distribution ${\\mathcal{N}}(0,4/m)$ . Similarly, let $\\pmb{\\theta}_{L}=(\\pmb{w}^{\\top},-\\pmb{w}^{\\top})$ , where each element ofvector $\\pmb{w}$ is drawn from $\\mathcal{N}(0,2/m)$ ", "page_idx": 5}, {"type": "text", "text": "Arm Context Normalization. To ensure arm contexts are of unit length (i.e., $\\|\\pmb{x}_{i,t}\\|\\,=\\,1,\\forall i\\,\\in$ $[K],t\\in[T])$ as in existing neural bandit works [86, 84, 11, 67, 50], we can apply the following transformation inspired by existing works [3, 86, 84] without loss of generality: with unprocessed context $\\widetilde{\\mathbf{\\boldsymbol{x}}}_{i,t}$ we formulatethecrresponding ormalized armn context $\\begin{array}{r}{\\mathbf{x}_{i,t}=[\\frac{\\widetilde{\\mathbf{x}}_{i,t}}{2\\cdot\\Vert\\widetilde{\\mathbf{x}}_{i,t}\\Vert_{2}}}\\end{array}$ $\\frac{\\widetilde{\\pmb{x}}_{i,t}}{2\\!\\cdot\\!\\parallel\\!\\widetilde{\\pmb{x}}_{i,t}\\parallel_{2}}$ can be verified that we have three properties: (i) $\\Vert{\\pmb x}_{i,t}\\Vert_{2}=1$ ; (i) no two normalized arm contexts will be in opposite directions; and (ii) $f(\\pmb{x}_{i,t};\\pmb{\\theta}_{0})=0$ with the randomly initialized $\\theta_{0}$ ", "page_idx": 5}, {"type": "text", "text": "Definitions of NTK Matrices. First, we denote imaginary corruption-free models as $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{t-1}),t\\in$ $[T]$ which are trained on corruption-free records $\\widetilde{\\mathcal{P}}_{t}\\ =\\ \\{\\pmb{x}_{\\tau},\\widetilde{r}_{\\tau}\\}_{\\tau\\in[t]},t\\ \\in\\ [T]$ , for the sake of theoretical analysis, and the learner does not need to own the imaginary model in practice. Let $\\{\\pmb{x}_{t}\\}_{t\\in[T]}~=~\\{\\pmb{x}_{i_{t},t}\\}_{t\\in[T]}$ be arms chosen by the corrupted model $f(\\cdot;\\pmb\\theta)$ , and $\\begin{array}{r l}{\\left\\{\\widetilde{\\pmb{x}}_{t}\\right\\}_{t\\in[T]}}&{=}\\end{array}$ $\\{\\boldsymbol{x}_{\\widetilde{\\iota}_{t},t}\\}_{t\\in[T]}$ be those chosen by the corruption-free model $f(\\cdot;\\widetilde{\\pmb\\theta})$ respectively. Then, define a union set $\\check{\\mathcal{A}}_{T}:=(\\{\\pmb{x}_{t}\\}_{t=1}^{T}\\cup\\{\\pmb{x}_{t}^{*}\\}_{t=1}^{T}\\cup\\{\\widetilde{\\pmb{x}}_{t}\\}_{t=1}^{T})$ , based on: (i) the chosen arms $\\{x_{t}\\}_{t=1}^{T}$ , (i) the optimal arms $\\{x_{t}^{*}\\}_{t=1}^{T}$ according to 2),and ii arms $\\{\\widetilde{\\mathbf{\\}}x_{t}\\}_{t=1}^{T}$ chosen by the imaginary corruption-fre models. Here, $\\breve{A}_{T}$ naturally contains unique arms from these three arm collections, with cardinality $|\\breve{A}_{T}|\\leq3T$ Meanwhile, we simply merge these three arm collections to form $A_{T}$ (with cardinality $\\left|\\mathcal{A}_{T}\\right|\\mathrm{~=~}3T)$ , which allows duplicate arms. Afterwards, we have the following two formulations of the NTK Gram matrix: (i) The NTK Gram matrix $\\mathbf{H}$ with possibly duplicate arms based on the collection $A_{T}$ ; (ii) the NTK matrix for non-duplicate arms $\\breve{\\textbf{H}}$ built upon the set $\\breve{A}_{T}$ ", "page_idx": 6}, {"type": "text", "text": "Definition 5.1 (NTK Gram Matrix with Possibly Duplicate Arms). Let $\\mathcal{N}$ be the Gaussian distribution. Withlayer index $l\\in[L]$ andsubscripts $i,j\\in\\{1,\\ldots,|A_{T}|\\}$ for enumerating across arms, comparable to [47, 86], define the following recursive process ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l r l}&{\\mathbf{H}_{i,j}^{0}=\\boldsymbol{\\Psi}_{i,j}^{0}=\\langle\\mathbf{x}_{i},\\mathbf{x}_{j}\\rangle,}&&{\\mathbf{N}_{i,j}^{l}=\\left(\\Psi_{i,i}^{l}\\quad\\Psi_{i,j}^{l}\\right),}\\\\ &{\\boldsymbol{\\Psi}_{i,j}^{l}=2\\mathbb{E}_{a,b\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{N}_{i,j}^{l-1})}[\\sigma(a)\\sigma(b)],}&{\\mathbf{H}_{i,j}^{l}=2\\mathbf{H}_{i,j}^{l-1}\\mathbb{E}_{a,b\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{N}_{i,j}^{l-1})}[\\sigma^{\\prime}(a)\\sigma^{\\prime}(b)]+\\boldsymbol{\\Psi}_{i,j}^{l}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "With $A_{T}$ containing possibly duplicate arms, we denote the NTK Gram matrix ${\\bf{H}}=({\\bf{H}}^{L}\\!+\\!\\Psi^{L})/2\\in$ $\\mathbb{R}^{3T\\times3\\bar{T}}$ ,and expected rewardvector ${\\textbf{\\textit{h}}}=\\,[h({\\textbf{\\em x}})]_{{\\textbf{\\em x}}\\in{\\mathcal{A}}_{T}}\\ \\in\\ \\mathbb{R}^{3T}$ . Existing works with the arm separateness assumption (e.g., [86, 84, 9, 25, 81]) generally assume $\\mathbf{H}\\succ\\mathbf{0}$ , while we do not. ", "page_idx": 6}, {"type": "text", "text": "Definition 5.2 (NTK Gram Matrix with Non-duplicate Arms). Follow the recursive process in (7). With set $\\breve{A}_{T}$ containing non-duplicate arms, we denote the corresponding NTK matrix $\\breve{\\mathbf{H}}=(\\breve{\\mathbf{H}}^{L}+$ $\\check{\\Psi}^{L})/2\\in\\mathbb{R}^{|\\check{A}_{T}|\\times|\\check{A}_{T}|}$ , and expected reward vector $\\breve{h}=[h(\\pmb{x})]_{\\pmb{x}\\in\\breve{\\mathcal{A}}_{T}}\\in\\mathbb{R}^{|\\breve{\\mathcal{A}}_{T}|}$ Wwith $|\\breve{A}_{T}|\\leq3T$ ", "page_idx": 6}, {"type": "text", "text": "Remark 5.3 (No Arm Separateness Assumption). Existing neural bandit works generally impose separateness assumptions regarding the arm contexts: NTK-based approaches (e.g., [86, 84, 9, 51, 50]) commonly assume $\\mathbf{H}\\succ\\mathbf{0}$ which requires no two arms are parallel among $\\{{\\pmb x}_{i,t}\\}_{i\\in[K],t\\in[T]}$ meanwhile, some other works (e.g., [11, 67]) assume the Euclidean separateness: $\\|\\pmb{x}_{i,t}-\\pmb{x}_{i^{\\prime},t^{\\prime}}\\|_{2}>0$ if $(i,t)\\,\\neq\\,(i^{\\prime},t^{\\prime}),\\forall i,i^{\\prime}\\,\\in\\,[K],t,t^{\\prime}\\,\\in\\,[T]$ . To avoid the arm separateness assumption, since $\\breve{A}_{T}$ contains all the unique arms from $A_{T}$ , we alternatively build the confidence ellipsoid upon the NTK matrix $\\breve{\\textbf{H}}$ , and the ellipsoid will also hold for all the arms in $A_{T}$ for regret analysis (Lemma C.1). This also leads to our tighter definition of NTK norm term $S$ (Theorem 5.6, Remark 5.8). ", "page_idx": 6}, {"type": "text", "text": "Fact 5.4. Let $\\breve{\\lambda}_{0}$ be the minimum eigenvalue of matrix $\\breve{\\textbf{H}}$ , and $\\lambda_{0}$ be that of NTK matrix $\\mathbf{H}$ We have (i) $\\Breve{\\lambda}_{0}=\\lambda_{\\operatorname*{min}}(\\Breve{\\mathbf{H}})>0$ and, (ii) $\\bar{\\tilde{\\lambda}}_{0}\\geq\\lambda_{0}\\geq0$ ", "page_idx": 6}, {"type": "text", "text": "For (i) in Fact 5.4, since $\\breve{A}_{T}$ contains no parallel arms, matrix H will be full-rank, leading to $\\breve{\\lambda}_{0}>0$ . For (ii),if $\\breve{A}_{T}\\ne A_{T}$ , then $A_{T}$ contains duplicate arms and matrix $\\mathbf{H}$ will be singular, s.t. $\\breve{\\lambda}_{0}>\\lambda_{0}=0$ . Otherwise, if $\\breve{A}_{T}=A_{T}$ , it will naturally lead to $\\breve{\\mathbf{H}}=\\mathbf{H}$ and $\\breve{\\lambda}_{0}=\\lambda_{0}$ . Next, similar to existing neural bandit works (e.g., [86, 84]), we define the NTK Gram matrix effective dimension $\\ {\\widetilde{d}},$ which essentially measures the vanishing speed of NTK Gram matrix eigenvalues. ", "page_idx": 6}, {"type": "text", "text": "Definition 5.5 (Effective Dimension of NTK Matrix [86, 84]). Given the NTK matrix $\\mathbf{H}$ With possibly duplicate arms EDef. 5.1), its effective dimension is defined as $\\begin{array}{r}{\\widetilde{d}=\\frac{\\log\\operatorname*{det}(\\mathbf{I}+\\mathbf{H}/\\lambda)}{\\log(1+T K/\\lambda)}}\\end{array}$ ", "page_idx": 6}, {"type": "text", "text": "5.1  Regret Analysis for R-NeuralUCB ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We follow the pseudo-regret $\\begin{array}{r}{R(T)=\\sum_{t=1}^{T}\\mathbb{E}[\\widetilde{r}_{t}^{*}-\\widetilde{r}_{t}]}\\end{array}$ in (2), which is defined based on the expected corruption-free reward of chosen arms and optimal arms across $T$ rounds. ", "page_idx": 6}, {"type": "text", "text": "Instance-dependent Gradient Deviation Term $\\beta$ . Recall that for a candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ in round $t\\in[T]$ its amwtu $\\mathbf{\\deltax}_{\\tau},\\tau\\in[t\\!-\\!1]$ in (4) can be represeted by $w_{i,t}^{(\\tau)}=$ $\\operatorname*{min}\\left\\{1,\\alpha\\cdot{\\sf f r a c}_{\\tau}({\\pmb x}_{i,t};\\mathcal{X}_{t},\\bar{\\pmb\\Sigma}_{t-1})\\right\\}$ , with the scaling parameter $\\alpha>0$ . Here, we define a minimum fraction value as $\\begin{array}{r}{\\beta=\\operatorname*{min}_{t\\in[T],\\tau\\in[t-1]}\\big[\\operatorname*{min}\\{\\mathsf{f r a c}_{\\tau}(\\pmb{x}_{t};\\mathcal{X}_{t},\\bar{\\Sigma}_{t-1})}\\end{array}$ \uff0c $\\mathsf{f r a c}_{\\tau}(\\widetilde{\\pmb{x}}_{t};\\mathcal{X}_{t},\\bar{\\pmb{\\Sigma}}_{t-1})\\}$ , which is formulated to quantify the gradient deviation among arms. Here, the learner is not required to know $\\beta$ , and we can adjust the scaling parameter $\\alpha$ in each round $t\\in[T]$ to constrain the round-wise minimum weight value $\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}$ (Subsection B.5), which leads to Theorem 5.6. ", "page_idx": 6}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Theorem 5.6. With finite horizon $T\\in\\mathbb{N}^{+}$ denote $S\\geq\\sqrt{2\\check{h}^{\\mathsf{T}}\\check{\\mathbf{H}}^{-1}\\check{h}},\\beta>0.$ Suppose $\\lambda\\geq S^{-2}$ $\\eta\\leq$ $\\mathcal{O}((T m L+m\\lambda)^{-1})$ \uff0c $J\\ge\\tilde{\\mathcal{O}}(T L/\\lambda)$ . Let $f(\\cdot)$ be an $L$ layerFCnetworkwithwidth $m$ , and adjust the scaling parameter $\\alpha$ s.t. $\\mathrm{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2}$ \uff0c $\\forall t\\in[T],$ for a tunable constant $\\kappa\\in(0,1)$ from (4). With $\\delta\\in(0,1)$ let network width $m\\ge\\Omega(p o l y(T,L,\\kappa^{-1},\\check{\\lambda}_{0}^{-1},\\lambda^{-1},S^{-1})\\log(\\delta^{-1}))$ .With probability at least $1-\\delta$ $R$ -NeuraluCBachievestheregretboundof ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\Im(T)\\le\\ \\mathcal{O}\\bigg(\\nu\\sqrt{\\tilde{d}\\log(\\frac{\\lambda+T K}{\\lambda})-2\\log(\\delta)}+S\\sqrt{\\lambda}\\bigg)\\tilde{\\mathcal{O}}\\bigg(\\sqrt{T\\tilde{d}/\\kappa^{2}}\\bigg)+\\mathcal{O}\\bigg(C\\tilde{d}\\beta^{-1}\\kappa^{2}\\log(\\frac{\\lambda+T K}{\\lambda})\\bigg)\\,.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "The proof of Theorem 5.6 is in Appendix C. The first term on the RHS refers to the corruptionindependent regret upper bound, which comparably matches the bound $\\tilde{\\mathcal{O}}(\\tilde{d}\\sqrt{T}\\!+\\!S\\sqrt{\\tilde{d}T})$ in existing corruption-free neural bandit works [86, 84]. Here, our corruption-dependent term is free of the NTK norm $S$ , which measures the complexity of reward mapping $h(\\cdot)$ (Appendix B.4). This is different from existing works (e.g., [15]) that include a parameter norm (similar to our NTK norm $S$ ) in their corruption-dependent terms, as the estimation error of confidence ellipsoids. In addition, inspired by [84], we can derive a $T$ -independent upper bound for the $\\beta^{-1}$ term, when the arm contexts are nearly spreading within some low-dimensional subspace of the NTK-induced RKHS (Appendix C.9), as it will lead to small effective dimension d and small eigenvalues of NTK matrix $\\mathbf{H}$ [84]. Meanwhile, compared with the regret bound of our base algorithm NeuralUCB-WGD (Theorem E.1), Theorem 5.6 removes the assumption of known corruption $C$ ; and, reduces the order of effective dimension d as well as the dependency of NTK norm $S$ for corruption-dependent terms. ", "page_idx": 7}, {"type": "text", "text": "Remark 5.7 (Unknown corruption level $C$ ). For Theorem 5.6, we do not assume $C$ is known to the learner in advance, as practitioners can have litle prior knowledge regarding the unknown adversary. This makes our regret analysis more challenging, compared with the existing works (e.g., [16]) where $C$ is assumed known for setting hyper-parameters to achieve tight regret bounds. ", "page_idx": 7}, {"type": "text", "text": "Remark 5.8 (Tighter definition for NTK norm $S$ ). For existing works (e.g., [86, 84]), the NTK Gram matrix is generally defined with llthe $T K$ observed candidate arms, i.e., $\\{\\pmb{x}_{i,t}\\}_{i\\in[K],t\\in[T]}$ , while our NTK matrices (Def. 5.1 and 5.2) only rely on arm collection $A_{T}$ and set $\\breve{A}_{T}$ , with cardinality $|\\check{A}_{T}|\\leq|A_{T}|=3T$ This results in our parameter norm $S$ that can be tighter compared to existing works (e.g., [84, 86]), because when constructing the confidence ellipsoid around the initialization $\\Theta_{\\mathrm{0}}$ in Lemma C.1, our ellipsoid is intuitively tighter, as it only needs to ensure Eq. C.1 holds for arms in $\\breve{A}_{T}$ (with cardinality $|\\check{A}_{T}|\\leq3T)$ , rather than for all $T K$ candidate arms. ", "page_idx": 7}, {"type": "text", "text": "Remark 5.9 (Reducing the order of $\\widetilde{d}$ and removing the dependency of $S$ for corruption-dependent terms). For corruption-dependent terms involving $C$ ,we have $\\widetilde{\\mathcal{O}}(\\breve{C}\\beta^{-1}\\widetilde{d})$ . Using NTK to align the information gain definition [16] with our effective dimension d, our result improves latest kernelized bandit works from $\\widetilde{\\mathcal{O}}(\\widetilde{d^{3/2}})$ to $\\widetilde{\\mathcal{O}}(\\widetilde{d})$ for corruption-dependent terms, given the NTK-induced RKHS and an indefinite arm space (Corollary 7 in [16]). Meanwhile, our corruption-dependent term is free of the NTK norm $S$ , while for some existing works with UCB-type exploration (e.g., [15]), they involve comparable parameter norms in their corruption-dependent regret terms, in order to quantify corruption impacts w.r.t. the reward mapping function complexity. ", "page_idx": 7}, {"type": "text", "text": "6 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We evaluate R-NeuralUCB and the base algorithm NeuralUCB-WGD (Appendix E) with experiments on three real data sets, under different adversarial corruption scenarios. Following definition in (2), we record the cumulative regret in terms of corruption-free rewards $\\begin{array}{r}{R(T)=\\sum_{t\\in[T]}\\left[\\widetilde{r}_{t}^{*}-\\widetilde{r}_{t}\\right]}\\end{array}$ Notethat the learner will still only have access to the potentially corrupted rewards $r_{t},t\\in[T]$ .Our baselines consist of linear algorithms: Lin-UCB [24], CW-OFUL [42]; and conventional neural algorithms: Neural-UCB [86], Neural-TS [84]. Complementary experiment details are in Appendix A. ", "page_idx": 7}, {"type": "text", "text": "MovieLens and Amazon Data Sets. From \u201cMovieLens 20M rating data set\" [41], we choose 5,000 movies and 10,oo0 users with most reviews to form the user-movie matrix, and the entries are user ratings. Then, we consider the arm (user-item pair) features as the concatenation of corresponding user features and item features, which are obtained by singular value decomposition (SVD) and extracting item genome-scores respectively, with $K=10$ and $d=41$ . The corruption-free arm rewards $\\bar{\\tilde{r_{i,t}}}$ are user ratings normalized into range [O, 1]. Here, we consider the \u201cexaggerated reward corruption\". If one pulled arm $\\pmb{x}_{t}$ is attacked and its corruption-free reward $\\tilde{r_{t}}\\geq0.5$ , we exaggerate its reward to $r_{t}=1$ . Otherwise, if one pulled arm $\\pmb{x}_{t}$ is attacked and $\\tilde{r}_{t}<0.5$ , we set its reward $r_{t}=0$ . Amazon Recommendation data set [43] consists of user reviews and corresponding ratings. With each piece of review (user-item pair) as an arm, we vectorize the review as the arm features using the \u201cSentire\u201d package [85, 58], with $K=10$ and $d=41$ . Similarly, the corruption-free arm rewards $\\widetilde{r_{i,t}}$ are normalized user ratings with the value range $[0,1]$ . Different from MovieLens data set, we here consider the \u201creverse exaggerated corruption\": if the pulled arm $\\pmb{x}_{t}$ is attacked and its corruption-free reward $\\tilde{r}_{t}\\geq0.5$ , we downplay its reward to $r_{t}=0$ ; or if the pulled arm $\\pmb{x}_{t}$ is attacked and $\\tilde{r}_{t}<0.5$ , we alternatively set the corrupted reward $r_{t}=1$ ", "page_idx": 7}, {"type": "image", "img_path": "6U8iV9HVpS/tmp/26e506f5da78b525d59079068e0e9c00cc927aa185dbdf31d05e9f88f6460547.jpg", "img_caption": ["Figure 1: Regret results on real data sets. (Left three figures: For MovieLens and Amazon, corrupt the chosen arm reward with $20\\%$ probability. ForMNIST,consider $C=2000$ and randomly sample 2000 rounds for atack); (Right three figures: For MovieLens and Amazon: we corrupt rewardwith $50\\%$ probability; For MNIST: $C=4000$ and randomly sample 4000 corrupted rounds). "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "MNIST Data Set. To perform online classification with bandit feedback experiment, we adopt the MNIST data set [56] which consists of 10 image classes. Similar to previous works (e.g., [86, 84]), given a sample $\\pmb{x}\\in\\mathbb{R}^{d^{\\prime}}$ in each round, we transform it into $K=10$ arms, denoted by $\\begin{array}{r}{{\\bf{\\boldsymbol{x}}}_{1}=({\\bf{\\boldsymbol{x}}},{\\bf{0}},\\ldots,{\\bf{0}}),{\\boldsymbol{\\boldsymbol{x}}}_{2}=({\\bf{0}},{\\boldsymbol{x}},\\ldots,{\\bf{0}}),\\ldots,{\\boldsymbol{x}}_{10}=({\\bf{0}},{\\bf{0}},\\ldots,{\\bf{x}})\\in\\mathbb{R}^{10\\times d^{\\prime}}}\\end{array}$ ,s.t. $d=10\\times d^{\\prime}$ .The arm index that the learner chooses will be its predicted class, and the reward is 1 if the sample $\\textbf{\\em x}$ belongs to this class; otherwise, the reward will be 0. Here, we consider the symmetric \u201clabel-flipping' attack [39]. For example, when a sample from digit class 2 is attacked, its corrupted label will be switched to digit class $9-2=7$ , and the corrupted arm rewards will also change accordingly. ", "page_idx": 8}, {"type": "text", "text": "Experiment Results. The experiment results are shown in Fig. 1, and we also include a parameter study in Appendix A.2. Due to the representation power of neural networks, neural algorithms generally perform better than linear ones. In particular, for the MNIST data set, since the reward mapping can be relatively more complex, neural algorithms manage to achieve more significant improvements over the linear algorithms. Here, compared with conventional neural methods, our proposed NeuralUCB- WGD and R-NeuralUCB are more robust against adversarial reward corruptions. In particular, we see that R-NeuralUCB outperforms NeuralUCB-WGD on these three data sets, which helps support our claim that it is beneficial to involve the uncertainty information in terms of both training samples and candidate arms. When we increase the corruption intensity (three figures on the right), the overall results tend to be consistent with previous findings. Notice that the performance gap among algorithms on the Amazon data set tends to be smaller, as this setting becomes significantly more difficult (i.e., with up to $\\sim8000$ regret) when we increase the corruption probabilityto $50\\%$ . Meanwhile, for MNIST, when we increase $C$ to 4000, the performance gap between our proposed algorithms and the conventional neural methods tends to increase, as the task becomes increasingly more complex. We also see that R-NeuralUCB still outperforms NeuralUCBWGD given the increased corruption intensity, showing the benefit of involving the candidate arm information and customizing arm-specific model parameters. ", "page_idx": 8}, {"type": "text", "text": "7  Conclusion and Future Direction ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we propose a novel neural bandit algorithm named R-NeuralUCB to address potential adversarial corruption issues on arm rewards. To enhance model robustness against reward corruptions, R-NeuralUCB applies a refined, context-aware Gradient Descent procedure that incorporates arm uncertainty information. To demonstrate its effectiveness, we present a regret analysis of R-NeuralUCB to quantify the impacts of adversarial corruption. Furthermore, to ensure that R-NeuralUCB can handle arm contexts deliberately chosen by an adversary (e.g., duplicate arms across different rounds), our analysis avoids the commonly adopted arm separateness assumption in neural bandit literature, which can be of independent interest. Empirical evaluations on real datasets with varied specifications show the effectiveness of our proposed solution over baseline methods. A challenging future direction is to derive the theoretical lower bound for neural bandits with corruption, and we provide complementary discussions in Appendix B.7. ", "page_idx": 8}, {"type": "text", "text": "Acknowledgments and Disclosure of Funding ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work is supported by National Science Foundation under Award No. IS-2117902, and Agriculture and Food Research Initiative (AFRI) grant no. 2020-67021-32799/project accession no.1024178 from the USDA National Institute of Food and Agriculture. The work is also supported in part by the National Science Foundation through awards IS 21-31335, OAC 21-30835, DBI 20-21898, as well as a C3.ai research award. The views and conclusions are those of the authors and should not be interpreted as representing the official policies of the funding agencies or the government. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1]  Yasin Abbasi-Yadkori, David Pal, and Csaba Szepesvari. Improved algorithms for linear stochastic bandits. Advances in neural information processing systems, 24:2312-2320, 2011.   \n[2]  Shipra Agrawal and Navin Goyal. Thompson sampling for contextual bandits with linear payoffs. In ICML, pages 127-135. PMLR, 2013.   \n[3]  Zeyuan Allen-Zhu, Yuanzhi Li, and Zhao Song. A convergence theory for deep learning via over-parameterization. In International Conference on Machine Learning, pages 242-252. PMLR, 2019.   \n[4]  Sanjeev Arora, Simon S Du, Wei Hu, Zhiyuan Li, Ruslan Salakhutdinov, and Ruosong Wang. On exact computation with an infinitely wide neural net. arXiv preprint arXiv: 1904.11955, 2019.   \n[5]  Peter Auer, Nicolo Cesa-Bianchi, and Paul Fischer. Finite-time analysis of the multiarmed bandit problem. Machine learning, 47(2-3):235-256, 2002.   \n[6]  Yikun Ban, Ishika Agarwal, Ziwei Wu, Yada Zhu, Kommy Weldemariam, Hanghang Tong, and Jingrui He. Neural active learning beyond bandits. arXiv preprint arXiv:2404.12522, 2024.   \n[7]  Yikun Ban and Jingrui He. Generic outlier detection in multi-armed bandit. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 913-923, 2020.   \n[8]  Yikun Ban and Jingrui He. Local clustering in contextual multi-armed bandits. In Proceedings of the Web Conference 2021, pages 2335-2346, 2021.   \n[9]  Yikun Ban, Jingrui He, and Curtiss B Cook. Multi-facet contextual bandits: A neural network perspective. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining, pages 35-45, 2021.   \n[10] Yikun Ban, Yunzhe Qi, Tianxin Wei, Lihui Liu, and Jingrui He. Meta clustering of neural bandits. In Proceedings of the 3Oth ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 95-106, 2024.   \n[11]  Yikun Ban, Yuchen Yan, Arindam Banerjee, and Jingrui He. Ee-net: Exploitation-exploration neural networks in contextual bandits. arXiv preprint arXiv:2110.03177, 2021.   \n[12]  Yikun Ban, Yuchen Yan, Arindam Banerjee, and Jingrui He. Neural exploitation and exploration of contextual bandits. arXiv preprint arXiv:2305.03784, 2023.   \n[13] Yikun Ban, Yuheng Zhang, Hanghang Tong, Arindam Banerjee, and Jingrui He. Improved algorithms for neural active learning. Advances in Neural Information Processing Systems, 35:27497-27509, 2022.   \n[14]  Alberto Bietti and Julien Mairal. On the inductive bias of neural tangent kernels. Advances in Neural Information Processing Systems, 32, 2019.   \n[15] lija Bogunovic, Andreas Krause, and Jonathan Scarlett. Corruption-tolerant gaussian process bandit optimization. In International Conference on Artijficial Intelligence and Statistics, pages 1071-1081. PMLR, 2020.   \n[16] lija Bogunovic, Zihan Li, Andreas Krause, and Jonathan Scarlett. A robust phased elimination algorithm for corruption-tolerant gaussian process bandits. Advances in Neural Information Processing Systems, 35:23951-23964, 2022.   \n[17] Iija Bogunovic, Arpan Losalka, Andreas Krause, and Jonathan Scarlett. Stochastic linear bandits robust to adversarial attacks. In International Conference on Artificial Intelligence and Statistics, pages 991-999. PMLR, 2021.   \n[18]  Sebastien Bubeck, Nicolo Cesa-Bianchi, et al. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends? in Machine Learning, 5(1):1-122, 2012.   \n[19] Xu Cai and Jonathan Scarlett. On lower bounds for standard and robust gaussian process bandit optimization. In International Conference on Machine Learning, pages 1216-1226. PMLR, 2021.   \n[20]  Yuan Cao, Zhiying Fang, Yue Wu, Ding-Xuan Zhou, and Quanquan Gu. Towards understanding the spectral bias of deep learning. arXiv preprint arXiv: 1912.01198, 2019.   \n[21]  Yuan Cao and Quanquan Gu. Generalization bounds of stochastic gradient descent for wide and deep neural networks. Advances in Neural Information Processing Systems, 32:10836-10846, 2019.   \n[22]  Vasileios Charisopoulos, Hossein Esfandiari, and Vahab Mirrokni. Robust and private stochastic linear bandits. In International Conference on Machine Learning, pages 4096-4115. PMLR, 2023.   \n[23]  Christopher A Choquette-Choo, Florian Tramer, Nicholas Carlini, and Nicolas Papernot. Labelonly membership inference attacks. In International conference on machine learning, pages 1964-1974. PMLR, 2021.   \n[24]  Wei Chu, Lihong Li, Lev Reyzin, and Robert Schapire. Contextual bandits with linear payoff functions. In AISTATS, pages 208-214, 2011.   \n[25] Zhongxiang Dai, Yao Shu, Arun Verma, Flint Xiaofeng Fan, Bryan Kian Hsiang Low, and Patrick Jaillet. Federated neural bandit. arXiv preprint arXiv:2205.14309, 2022.   \n[26]  Rohan Deb, Yikun Ban, Shiliang Zuo, Jingrui He, and Arindam Banerjee. Contextual bandits with online neural regression. arXiv preprint arXiv:2312.07145, 2023.   \n[27] Yashar Deldjoo, Tommaso Di Noia, and Felice Antonio Merra. A survey on adversarial recommender systems: from attack/defense strategies to generative adversarial networks. ACM Computing Surveys (CSUR), 54(2):1-38, 2021.   \n[28]  Aniket Anand Deshmukh, Urun Dogan, and Clay Scott. Multi-task learning for contextual bandits. In NeurIPS, pages 4848-4856, 2017.   \n[29]  Qin Ding, Cho-Jui Hsieh, and James Sharpnack. Robust stochastic linear contextual bandits under adversarial attacks. In International Conference on Artificial Intelligence and Statistics, pages 7111-7123. PMLR, 2022.   \n[30] Audrey Durand, Charis Achilleos, Demetris Iacovides, Katerina Strati, Georgios D Mitsis, and Joelle Pineau. Contextual bandits for adapting treatment in a mouse model of de novo carcinogenesis. In Machine learning for healthcare conference, pages 67-82. PMLR, 2018.   \n[31] Li Fan, Ruida Zhou, Chao Tian, and Cong Shen. Federated linear bandits with finite adversarial actions. Advances in Neural Information Processing Systems, 36, 2024.   \n[32]  Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. In International conference on machine learning, pages 1126-1135. PMLR, 2017.   \n[33] Dylan J Foster, Claudio Gentile, Mehryar Mohri, and Julian Zimmert. Adapting to misspecification in contextual bandits. Advances in Neural Information Processing Systems, 33:11478-11489, 2020.   \n[34] Dongqi Fu, Liri Fang, Ross Maciejewski, Vetle I. Torvik, and Jingrui He. Meta-learned metrics over multi-evolution temporal graphs. In KDD 2022, 2022.   \n[35] Dongqi Fu and Jingrui He. SDG: A simplified and dynamic graph neural network. In SIGIR 2021, 2021.   \n[36]  Avishek Ghosh, Sayak Ray Chowdhury, and Aditya Gopalan. Misspecified linear bandits. In Proceedings of the AAAl Conference on Artificial Intelligence, volume 31, 2017.   \n[37] Quanquan Gu, Amin Karbasi, Khashayar Khosravi, Vahab Mirrokni, and Dongruo Zhou. Batched neural bandits. ACM/IMS Journal of Data Science, 1(1): 1-18, 2024.   \n[38] Anupam Gupta, Tomer Koren, and Kunal Talwar. Better algorithms for stochastic bandits with adversarial corruptions. In Conference on Learning Theory, pages 1562-1578. PMLR, 2019.   \n[39] B Han, Q Yao, X Yu, G Niu, M Xu, W Hu, I Tsang, and M Sugiyama. Robust training of deep neural networks with extremely noisy labels. In Thirty-fourth Conference on Neural Information Processing Systems (NeurIPS), volume 2, page 4, 2020.   \n[40]  Eric Han and Jonathan Scarlett. Adversarial attacks on gaussian process bandits. In International Conference on Machine Learning, pages 8304-8329. PMLR, 2022.   \n[41] F Maxwell Harper and Joseph A Konstan. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tis), 5(4):1-19, 2015.   \n[42] Jiafan He, Dongruo Zhou, Tong Zhang, and Quanquan Gu. Nearly optimal algorithms for linear contextual bandits with adversarial corruptions. arXiv preprint arXiv:2205.06811, 2022.   \n[43] Ruining He and Julian McAuley. Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In proceedings of the 25th international conference on world wide web, pages 507-517, 2016.   \n[44] Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. Neural collaborative fltering. In WWW, pages 173-182, 2017.   \n[45]  Roger A Horn and Charles R Johnson. Matrix analysis. Cambridge university press, 2012.   \n[46]  Taehyun Hwang, Kyuwook Chai, and Min-hwan Oh. Combinatorial neural bandits. In International Conference on Machine Learning, pages 14203-14236. PMLR, 2023.   \n[47]  Arthur Jacot, Franck Gabriel, and Cl\u00e9ment Hongler. Neural tangent kernel: Convergence and generalization in neural networks. Advances in neural information processing systems, 31, 2018.   \n[48]  Yiling Jia, Weitong ZHANG, Dongruo Zhou, Quanquan Gu, and Hongning Wang. Learning neural contextual bandits through perturbed rewards. In International Conference on Learning Representations, 2021.   \n[49]  Yue Kang, Cho-Jui Hsieh, and Thomas Chun Man Lee. Robust lipschitz bandits to adversarial corruptions. Advances in Neural Information Processing Systems, 36, 2024.   \n[50]  Parnian Kassraie and Andreas Krause. Neural contextual bandits without regret. In International Conference on Artificial Intelligence and Statistics, pages 240-278. PMLR, 2022.   \n[51] Parnian Kassraie, Andreas Krause, and Iija Bogunovic. Graph neural network bandits. arXiv preprint arXiv:2207.06456, 2022.   \n[52]  Johannes Kirschner and Andreas Krause. Bias-robust bayesian optimization via dueling bandits. In International Conference on Machine Learning, pages 5595-5605. PMLR, 2021.   \n[53]  Sanath Kumar Krishnamurthy, Vitor Hadad, and Susan Athey. Adapting to misspecification in contextual bandits with offline regression oracles. In International Conference on Machine Learning, pages 5805-5814. PMLR, 2021.   \n[54] Yuko Kuroki, Alberto Rumi, Taira Tsuchiya, Fabio Vitale, and Nicolo Cesa-Bianchi. Best-ofboth-worlds algorithms for linear contextual bandits. In International Conference on Artificial Intelligence and Statistics, pages 1216-1224. PMLR, 2024.   \n[55]  Tor Lattimore, Csaba Szepesvari, and Gellert Weisz. Learning with good feature representations in bandits and inrl with a generative model. In International conference on machine learning, pages 5662-5670. PMLR, 2020.   \n[56] Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.   \n[57]  Chung-Wei Lee, Haipeng Luo, Chen- Yu Wei, Mengxiao Zhang, and Xiaojin Zhang. Achieving near instance-optimality and minimax-optimality in stochastic and adversarial linear bandits simultaneously. In International Conference on Machine Learning, pages 6142-6151. PMLR, 2021.   \n[58] Lei Li, Yongfeng Zhang, and Li Chen. Generate neural template explanations for recommendation. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management, pages 755-764, 2020.   \n[59] Lihong Li, Wei Chu, John Langford, and Robert E Schapire. A contextual-bandit approach to personalized news article recommendation. In WwW, pages 661-670, 2010.   \n[60] Xiaoqiang Lin, Zhaoxuan Wu, Zhongxiang Dai, Wenyang Hu, Yao Shu, See-Kiong Ng, Patrick Jaillet, and Bryan Kian Hsiang Low. Use your instinct: Instruction optimization using neural bandits coupled with transformers. arXiv preprint arXiv:2310.02905, 2023.   \n[61] Brad Miller, Alex Kantchelian, Sadia Afroz, Rekha Bachwani, Edwin Dauber, Ling Huang, Michael Carl Tschantz, Anthony D Joseph, and J Doug Tygar. Adversarial active learning. In Proceedings of the 2014 workshop on artificial inteligent and security workshop, pages 3-14, 2014.   \n[62] David J Miller, Zhen Xiang, and George Kesidis. Adversarial learning targeting deep neural network classification: Acomprehensive review of defenses against attacks. Proceedings of the IEEE, 108(3):402-433, 2020.   \n[63]  Aritra Mitra, Aman Adibi, George J Pappas, and Hamed Hassani. Collaborative linear bandits with adversarialagents: Near-optimal regret bounds. Advances in neural information processing systems, 35:22602-22616, 2022.   \n[64]  Bamshad Mobasher, Robin Burke, Runa Bhaumik, and Chad Williams. Toward trustworthy recommender systems: An analysis of attack models and algorithm robustness. ACM Transactions on Internet Technology (TOIT), 7(4):23-es, 2007.   \n[65] Rui Ning, Jiang Li, Chunsheng Xin, and Hongyi Wu. Invisible poison: A blackbox clean label backdoor attack to deep neural networks. In IEEE INFOCOM 2021-IEEE Conference on Computer Communications, pages 1-10. IEEE, 2021.   \n[66]  Yunzhe Qi Yikun Ban, and Jingrui He. Neural bandit with arm group graph. arXiv preprint arXiv:2206.03644, 2022.   \n[67]  Yunzhe Qi, Yikun Ban, and Jingrui He. Graph neural bandits. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD \\*23, page 1920-1931, New York, NY, USA, 2023. Association for Computing Machinery.   \n[68] Yunzhe Qi, Yikun Ban, Tianxin Wei, Jiaru Zou, Huaxiu Yao, and Jingrui He. Meta-learning with neural bandit scheduler. Advances in Neural Information Processing Systems, 36, 2024.   \n[69]  Elan Rosenfeld, Ezra Winston, Pradeep Ravikumar, and Zico Kolter. Certified robustness to label-flipping attacks via randomized smoothing. In International Conference on Machine Learning, pages 8230-8241. PMLR, 2020.   \n[70] Jonathan Scarlett, Ilija Bogunovic, and Volkan Cevher. Lower bounds on regret for noisy gaussian process bandit optimization. In Conference on Learning Theory, pages 1723-1742. PMLR, 2017.   \n[71] Ruixiang Tang, Mengnan Du, Ninghao Liu, Fan Yang, and Xia Hu. An embarrassingly simple approach for trojan attack in deep neural networks. In Proceedings of the 26th ACM SIGKDD international conference on knowledge discovery & data mining, pages 218-228, 2020.   \n[72] Michal Valko, Nathan Korda, Remi Munos, Ilias Flaounas, and Nello Cristianini. Finite-time analysis of kernelised contextual bandits. In Uncertainty in Artificial Intelligence, 2013.   \n[73]  Sofia S Villar, Jack Bowden, and James Wason. Multi-armed bandit models for the optimal design of clinical trials: benefits and challenges. Statistical science: a review journal of the Institute of Mathematical Statistics, 30(2):199, 2015.   \n[74] Zhilei Wang, Pranjal Awasthi, Christoph Dann, Ayush Sekhari, and Claudio Gentile. Neural active learning with performance guarantees. Advances in Neural Information Processing Systems, 34:7510-7521, 2021.   \n[75] Zhiyong Wang, Jize Xie, Xutong Liu, Shuai Li, and John Lui. Online clustering of bandits with misspecified user models. Advances in Neural Information Processing Systems, 36, 2024.   \n[76]  Chen-Yu Wei, Christoph Dann, and Julian Zimmert. A model selection approach for corruption robust reinforcement learning. In International Conference on Algorithmic Learning Theory, pages 1043-1096. PMLR, 2022.   \n[77] Max Welling and Thomas N Kipf. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations, 2017.   \n[78] Longfeng Wu, Yao Zhou, and Dawei Zhou. Towards high-order complementary recommendation via logical reasoning network. In Xingquan Zhu, Sanjay Ranka, My T. Thai, Takashi Washio, and Xindong Wu, editors, IEEE International Conference on Data Mining, ICDM 2022, Orlando, FL, USA, November 28 - Dec. 1, 2022, pages 1227-1232. IEEE, 2022.   \n[79] Qingyun Wu, Huazheng Wang, Quanquan Gu, and Hongning Wang. Contextual bandits in a collaborative environment. In SIGIR, pages 529-538, 2016.   \n[80]  Yulian Wu, Xingyu Zhou, Youming Tao, and Di Wang. On private and robust bandits. Advances in Neural Information Processing Systems, 36, 2024.   \n[81] Pan Xu, Zheng Wen, Handong Zhao, and Quanquan Gu. Neural contextual bandits with deep representation and shallow exploration. arXiv preprint arXiv:2012.01780, 2020.   \n[82] Fuzhi Zhang and Quanqiang Zhou. Ensemble detection model for profile injection attacks in collaborative recommender systems based on bp neural network. IET Information Security, 9(1):24-31, 2015.   \n[83]  Weitong Zhang, Jiafan He, Zhiyuan Fan, and Quanquan Gu. On the interplay between misspecification and sub-optimality gap in linear contextual bandits. In International Conference on Machine Learning, pages 41111-41132. PMLR, 2023.   \n[84]  Weitong Zhang, Dongruo Zhou, Lihong Li, and Quanquan Gu. Neural thompson sampling. In International Conference on Learning Representations, 2021.   \n[85] Yongfeng Zhang, Haochen Zhang, Min Zhang, Yiqun Liu, and Shaoping Ma. Do users rate or review? boost phrase-level sentiment labeling with review-level sentiment clasfication. In Proceedings of the 37th internationalACM SIGIR conference on Research & development in information retrieval, pages 1027-1030, 2014.   \n[86]  Dongruo Zhou, Lihong Li, and Quanquan Gu. Neural contextual bandits with ucb-based exploration. In International Conference on Machine Learning, pages 11492-11502. PMLR, 2020.   \n[87]  Yao Zhou, Haonan Wang, Jingrui He, and Haixun Wang. From intrinsic to counterfactual: On the explainability of contextualized recommender systems. CoRR, abs/2110.14844, 2021.   \n[88]  Yao Zhou, Jianpeng Xu, Jun Wu, Zeinab Taghavi, Evren Korpeoglu, Achan Kannan, and Jingrui He. Pure: Positive-unlabeled recommendation with generative adversarial network. In KDD, 2021. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "[89] Shiliang Zuo. Corruption-robust lipschitz contextual search. In International Conference on Algorithmic Learning Theory, pages 1234-1254. PMLR, 2024. ", "page_idx": 14}, {"type": "text", "text": "A  Experiment Settings and Additional Experiments ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A.1  Experiment settings ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "For all UCB-based baselines, we choose the exploration parameter through grid search over the range $\\{0.01,0.1,1\\}$ .We set $L=2$ for all deep learning models, including our proposed NeuralUCBWGD and R-NeuralUCB, and set the network width to $m=200$ . The learning rate for all neural algorithms is chosen by grid search from the range $\\{0.0001,0.001,0.01\\}$ . For all methods, we select the regularization parameter $\\lambda$ from the range $\\{0.{\\dot{0}}001,0.001,0.01\\}$ . The scaling parameter $\\alpha$ for NeuralUCB-WGD and R-NeuralUCB is chosen from $\\{0.2,0.5,1\\}$ . All experiments are conducted on a server with an Intel Xeon CPU and NVIDIA V100 GPUs. Additionally, we provide further details on our baseline methods, which include two linear algorithms and two conventional neural algorithms: ", "page_idx": 15}, {"type": "text", "text": "\u00b7 Lin-UCB [24, 59] uses linear regression as the reward estimation model and employs a UCB-based strategyfor exploration.   \n\u00b7 CW-OFUL [42] applies weighted linear ridge regression in instead of the standard one from Lin-UCB, with weights assigned to selected samples in proportion to reward estimation confidence.   \n\u00b7 Neural-UCB [86] employs a single neural network to estimate arm rewards and calculates the UCB based on network gradients for exploration.   \n\u00b7 Neural-TS [84] utilizes a fully connected network for arm reward estimation, along with the Thompson Sampling strategy [2] for exploration. ", "page_idx": 15}, {"type": "text", "text": "Additional Data Processing Details for Recommendation Data Sets. Here, we provide additional details about our data processing procedure. For the first data set, MovieLens 20M rating data set (https://grouplens.org/datasets/movielens/ $20\\mathtt{m}/\\$ ), we initially select 5,000 movies and 10,0o0 users with the most reviews to form a user-movie matrix, where the entries represent user ratings. The user features $\\pmb{x}_{u}\\in\\mathbb R^{d^{\\prime}}$ are derived via singular value decomposition (SVD) with a dimensionality of $d^{\\prime}=20$ . Using the genome scores provided for each movie, we select the 20 tags with the highest variance and used their corresponding scores as movie features $\\pmb{v}_{i}\\in\\mathbb{R}^{d^{\\prime}}$ . At each time step $t$ , given a user $u_{t}$ , we encode user information into the arm contexts following the Generalized Matrix Factorization (GMF) approach [44, 88] by concatenating the features $\\mathbf{\\boldsymbol{x}}_{i,t}=$ $[\\pmb{x}_{u_{t}};\\pmb{v}_{i}]\\in\\mathbb{R}^{2d^{\\prime}}$ , where $c\\in\\mathcal{C}_{t}$ and $i\\in[K]$ , with $K=10$ Finally, we concatenate a constant 0.01 to each $\\pmb{x}_{i,t}$ and normalize the entire vector to obtain $\\pmb{x}_{i,t}\\in\\mathbb{R}^{d}$ , where $d=41$ . The corruption-free arm rewards $\\widetilde{r}_{i,t}$ are user ratings normalized to the range $[0,1]$ . We consider the scenario of \"exaggerated reward corruption\": If a pulled arm $\\pmb{x}_{t}$ is attacked and its corruption-free reward $\\tilde{r}_{t}\\:\\geq\\:\\bar{0}.5$ we exaggerate its reward to $r_{t}=1$ . Conversely, if a pulled arm $\\pmb{x}_{t}$ is attacked and its corruption-free reward $\\tilde{r}_{t}<0.5$ , we downplay its reward to $r_{t}=0$ ", "page_idx": 15}, {"type": "text", "text": "For the Amazon Recommendation data set (https://jmcauley.ucsd.edu/data/amazon/ index_2014 .html), each user-item pair is associated with a review and the corresponding user rating. We transform the review text into vector representations to derive the arm contexts, following the text processing procedure in the \"Sentires\" package [85, 58]. We then set $d=41$ and apply $L_{2}$ normalization, with an arm pool size of $K=10$ Similarly, the corruption-free arm rewards $\\widetilde{r_{i,t}}$ are normalized user ratings in the range $[0,1]$ . Unlike the MovieLens data set, we apply a \"reverse exaggerated corruption\" approach here: If the pulled arm $\\pmb{x}_{t}$ is attacked and its corruption-free reward $\\tilde{r}_{t}\\ge0.5$ , we downplay its reward to $r_{t}=0$ . Conversely, if the pulled arm $\\pmb{x}_{t}$ is attacked and its corruption-free reward $\\tilde{r}_{t}<0.5$ , we set the corrupted reward to $r_{t}=1$ ", "page_idx": 15}, {"type": "text", "text": "A.2  Additional experiments: parameter study ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "We also include additional experiments with different regularization parameter values $\\lambda$ and exploration parameter values $\\nu$ . On the MNIST data set (corruption level $C\\,=\\,2000)$ 0, we conduct experiments for NeuralUCB-WGD and R-NeuralUCB. We present the parameter study results in Tables 2 and 3. For both of our proposed algorithms, setting $\\nu\\,\\in\\,(0.1,0.5]$ generally yields the best performance. However, with an overly small exploration coeficient (e.g., $\\nu=0.05$ ), optimal empirical performance may not be achievable. Meanwhile, setting $\\lambda$ to smaller values, such as 0.001 or 0.0001, tends to result in the best performance. Increasingly large regularization parameter values can cause the trained model parameters $\\theta$ to remain close to their random initialization $\\theta_{0}$ , which can overly constrain the neural network's capacity to fit the underlying reward mapping function. Thus, practitioners can adjust the $\\lambda$ value based on specific application needs, as is common in other neural bandit studies (e.g., [86]). In practice, starting with small values like $10^{-4}$ and performing a grid search to identify the optimal $\\lambda$ is a reasonable approach for R-NeuralUCB and NeuralUCB-WGD. ", "page_idx": 15}, {"type": "table", "img_path": "6U8iV9HVpS/tmp/b42ac3572752aa9cee43d21a45f18c6a864046d4e21a6b501d9e1ba0d6c07b41.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "table", "img_path": "6U8iV9HVpS/tmp/2242807e2b951b6026ab0c694e650fa2fe33f01162d9a7e2bb8a8101b87354e8.jpg", "table_caption": ["Table 2: Regret results for different exploration regularization parameter values $\\lambda$ (with std.) ", "Table 3: Regret results for different exploration parameter values $\\nu$ (with std.) "], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "B  Complementary Discussions on the Content of the Main Body ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "In this section, we provide additional discussion to complement the main body content. ", "page_idx": 16}, {"type": "text", "text": "B.1  Boarder impacts ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Since our objective is to deal with the potential adversarial attacks in machine learning applications, this work can contribute to the goal of achieving trustworthy machine learning for general practitioners. Therefore, we do not perceive significant negative societal impacts that can be generated by this work. ", "page_idx": 16}, {"type": "text", "text": "B.2 Limitations ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "One limitation of this work is the absence of a theoretical lower bound for neural bandits with adversarial corruptions. We would like to mention that this problem is significantly challenging and non-trivial. Given that we deal with an arbitrary reward function $h(\\cdot)$ , which is considerably different from linear [42] and kernelized bandits [16], deriving the lower bound itself can lead to substantial contributions, potentially leading to a separate line of research works (e.g., [70] under kernelized bandit settings). Therefore, we consider the derivation of such a lower bound for neural bandits with adversarial corruptions as an interesting and challenging future direction of this work. Additional discussions on the lower bound can be found in Subsec. B.7. ", "page_idx": 16}, {"type": "text", "text": "B.3  Theoretical contributions and comparisons with vanilla Neural-UCB ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Recall that we propose deriving the regret bound using NTK-based regression techniques. Unlike linear bandit approaches (e.g., [42]) and kernel bandit methods (e.g., [16]), our regression is conducted on the network gradients $g(\\cdot;\\pmb\\theta):=\\mathrm{vec}(\\nabla_{\\pmb\\theta}f(\\cdot;\\pmb\\theta))$ , which serve as the mapping for gradient-based NTK. In this framework, even for the same arm $\\textbf{\\em x}$ , the NTK-embedded arm contexts can differ due to the corrupted parameters $g(\\pmb{x};\\pmb{\\theta})$ and the corruption-free parameters $g(\\pmb{x};\\widetilde{\\pmb{\\theta}})$ . To address this challenge, we define two sets of regression parameters corresponding to the corrupted model and the corruption-free model respectively. Then, using the corruption-free model $f(\\cdot;\\widetilde{\\pmb{\\theta}})$ , we derive the confidence ellipsoid around its parameters $\\widetilde{\\pmb{\\theta}}$ . This serves as a proxy to quantify the parameter shift of the trained corrupted model parameters $\\pmb{\\theta}$ , enabling us to establish the regret upper bound. ", "page_idx": 16}, {"type": "text", "text": "For the theoretical analysis of R-NeuralUCB presented in Theorem 5.6, we considerably modify the regret analysis workflow due to the following reasons: (i) To achieve improved performance, R-NeuralUCB differs from conventional neural bandit approaches by tuning separate sets of network parameters for each candidate arm after perceiving arm context information; (i) To achieve a tighter regret bound and eliminate the assumption of a known corruption level $C$ , unlike in Theorem E.1, we cannot quantify the impact of $C$ using the confidence ellipsoid. To address this, let $\\boldsymbol{x}_{t}^{*}$ and $x_{t}$ represent the optimal arm and the chosen arm by the corrupted model, respectively. We decompose the single-round pseudo-regret $R_{t}=\\operatorname*{min}\\{h(x_{t}^{*})-h(x_{t}),1\\}$ into three components: (i) The prediction error of the corruption-free model; (ii) The reward estimation discrepancy between the corruption-free model and the corrupted model on the same arm; (i) The arm selection discrepancy of the corrupted model induced by adversarial corruptions. Next, we apply carefully designed arm weights in (4) to guide the gradient descent process and mitigate the impact of adversarial corruptions. As a result, R-NeuralUCB achieves non-trivial theoretical improvements: (i) removing the assumption of a known corruption level $C$ in regret analysis; (i) eliminating the dependency on the NTK norm term $S$ for corruption-dependent terms in the regret bound; (ii) reducing the order of corruption-dependent terms in the regret bound to the effective dimension $\\hat{d}$ from $\\bar{\\mathcal{O}}(\\widetilde{d}^{3/2})$ to $O(\\widetilde d)$ , compared with our base algorithm NeuralUCB-WGD and existing kernelized bandit algorithms (e.g., [16]). ", "page_idx": 16}, {"type": "text", "text": "", "page_idx": 17}, {"type": "text", "text": "In addition, as mentioned in Remark 5.3, existing neural bandit approaches typically impose separateness assumptions on observed arm contexts, whereas we do not. For example, Neural-UCB [86] assumes $\\mathbf{H}\\succ\\mathbf{0}$ , which requires that no two arms are parallel among $\\{{\\pmb x}_{i,t}\\}_{i\\in[K],t\\in[T]}$ . In contrast, by formulating our NTK Gram matrices (Definitions 5.1 and 5.2), we complete our proof without the separateness assumption, reinforcing the theoretical robustness of our approach against possible arm contexts selected by an adversary (e.g., duplicate arm contexts across time steps). As in Remark 5.8, existing methods, including Neural-UCB [86, 84], generally define their NTK Gram matrices over all $T K$ observed arms, i.e., $\\{\\pmb{x}_{i,t}\\}_{i\\in[K],t\\in[T]}$ . However, our NTK matrices (Definitions 5.1 and 5.2) are based on $A_{T}$ and $\\breve{A}_{T}$ , where $|\\check{A}_{T}|\\leq|A_{T}|=3T.$ This formulation can result in a tighter NTK norm $S$ compared with existing methods. ", "page_idx": 17}, {"type": "text", "text": "Upper bound for vanilla Neural-UCB. Meanwhile, to provide insights into the regret bound of Neural-UCB, one possible approach is to follow a similar analysis to the regret bound of NeuralUCBWGD. The key idea here is to quantify the impact of adversarial corruptions on the confidence ellipsoid around the trained parameters. Referring to the derivations in Lemma F.1, and denoting the corruption-free confidence radius in round $t$ as $\\tilde{\\gamma}_{t-1}$ , we obtain the corrupted confidence ellipsoid for Neural-UCB as $\\mathcal{C}_{t-1}=\\left\\{\\theta:\\|\\theta-\\theta_{t-1}\\|_{\\Gamma_{t-1}}\\leq\\gamma_{t-1}/\\sqrt{m}\\right\\}$ , where $\\gamma_{t-1}=\\tilde{\\gamma}_{t-1}+\\mathcal{O}(C L\\lambda^{-1/2})$ This result is derived by setting $w_{\\tau}=1$ for $\\tau\\in[t-1]$ and applying the fact that $\\begin{array}{r}{\\sum_{\\tau\\in[t]}c_{\\tau}\\leq C}\\end{array}$ along with Lemma G.2 and the initialization of the gradient covariance matrix $\\Gamma$ . Following the proof flow of Lemma 5.3 in [86], we obtain a regret upper bound of $\\tilde{\\mathcal{O}}(\\tilde{d}\\sqrt{T}+\\sqrt{S\\tilde{d}T}+C L\\sqrt{\\tilde{d}T/\\lambda})$ \uff0c which introduces an additional $\\tilde{\\mathcal{O}}(\\sqrt{T})$ to the corruption-dependent term. ", "page_idx": 17}, {"type": "text", "text": "Over-parameterization. For most neural bandit works with experiments (e.g., [84, 86, 25, 9, 11]), a gap exists between experiments and theoretical analysis. On one hand, as the number of layers $L$ and hidden dimension $m$ increase, neural networks become progressively harder to train, more timeconsuming in inference, and more resource-intensive. To make neural bandits feasible for practical applications, these works generally use a neural network of ordinary size for experiments. It has been shown that even with ordinary-sized neural networks, neural bandit algorithms achieve notable performance gains over linear and kernel-based methods [86, 84, 9, 11, 67]. On the other hand, from a theoretical standpoint, neural networks need to be over-parameterized, with $m\\geq\\mathcal{O}(\\mathrm{poly}(T))$ ,to approximate any arbitrary reward mapping function $h(\\cdot)$ . Additionally, with over-parameterization, the difference between NTK-based regression models and neural networks becomes sufficiently small for regret analysis, which is essential in neural bandit research. Therefore, we use a two-layer fully connected network for experiments while performing theoretical analysis under over-parameterized settings, as in most existing neural bandit works (e.g., [86, 84, 9, 11, 67]). ", "page_idx": 17}, {"type": "text", "text": "B.4  The definition and order of NTK norm parameter $S$ ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Recall that we have the NTK norm $S$ defined as the upper bound of the weighted norm $S\\geq\\|\\breve{\\mathbf{h}}\\|_{\\breve{\\mathbf{H}}^{-1}}$ \uff0c where $\\mathbf{h}$ refers to the vector of expected rewards and $\\breve{\\textbf{H}}$ refers to the NTK Gram matrix (Definition 5.2). We can follow existing neural bandit works [86, 50, 51, 84, 48] by considering that the reward mapping function $h(\\cdot)$ in (1) belongs to the Reproducing Kernel Hilbert Space (RKHS) $\\mathcal{H}$ induced by NTK. In this case, we can upper bound $S$ with the RKHS norm, such that $\\|h\\|_{\\mathcal{H}}\\geq S$ , and the RKHS norm $\\left\\|h\\right\\|_{\\mathcal{H}}$ will not grow along with the finite horizon $T$ (Remark 4.8 in [86]). ", "page_idx": 17}, {"type": "text", "text": "Meanwhile, we also would like to mention that this is a common formulation, and nearly all the neural bandit works (e.g., [86, 50, 51, 84, 9, 48]) will include a comparable NTK norm term in the regret bound. This is because the regret analysis of neural bandits is generally depending on the NTK regression approach. In this case, when constructing the confidence ellipsoid within the NTK-induced RKHS, we will need to involve the RKHS norm as the cost. Analogously, for the kernelized contextual bandits works (e.g., [72, 28, 16]), they inevitably involve the RKHS norm into the regret bound. For linear bandit works (e.g., [42]), they will also need to include an assumed upper bound of the true parameter $\\pmb{\\theta}^{*}$ norm in the Euclidean space, such that $\\lVert\\pmb{\\theta}^{*}\\rVert_{2}$ is bounded by a constant. Meanwhile, since the NTK norm term $S$ stays invariant across candidate arms $x_{i,t}\\in\\mathcal{X}_{t}$ \uff0c we can treat $S$ as a constant in practice (e.g., setting $S=1$ ), and control the exploration intensity by tuning the exploration parameter $\\nu$ ", "page_idx": 18}, {"type": "text", "text": "B.5  Details regarding the scaling of arm weights $w$ ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Recall that when defining the sample weights $w_{i,t}^{(\\tau)}$ in (4), we use the minimum gradient norm in the numerator to scale weights across the current candidate arms $\\scriptstyle{\\mathcal{X}}_{t}$ , while introducing the scaling parameter $\\alpha\\,>\\,0$ to provide additional control from the practitioner's perspective. Under the stochastic contextual bandit settings, the learner receives the candidate arm pool $\\mathbf{\\boldsymbol{\\mathcal{X}}}_{t}$ in each round $t$ from the environment, having little control over the minimum gradient norm, as $\\mathbf{\\mathcal{X}}_{t}$ is only revealed at round $t$ . To address this, we introduce a tunable parameter $\\alpha$ to control the minimum value of $w_{i,t}^{(\\tau)}$ , aiming for a more stable learning process. Additionally, when deriving the regret bound for R-NeuralUCB (Theorem 5.6), we scale the $\\alpha$ values to ensure that the minimum weight value is $\\kappa^{2}$ .Without this scaling, such as by setting $\\alpha=1$ , an extra corruption-independent term $\\mathcal{O}(\\sqrt{\\beta^{-1}T\\widetilde{d}\\log(1+T K/\\lambda)})$ would be added to the current regret bound, making the overall bound less tight. Therefore, the scaling parameter $\\alpha$ is essential for R-NeuralUCB. ", "page_idx": 18}, {"type": "text", "text": "Furthermore, the denominator of (4) consists of the product of two gradient norms: (i) the norm of the previously chosen arm $g_{\\tau}$ , and (ii) the norm of the candidate arm $\\lVert g(\\pmb{x}_{i,t};\\pmb{\\theta})/\\sqrt{m}\\rVert_{\\pmb{\\Sigma}^{-1}}$ . Here, we use the squared norm in the numerator to balance with the norm product in the denominator. This design is also critical for deriving the regret bound in Theorem 5.6. Without using the squared norm, our current derivation would yield a corruption-dependent term of $\\tilde{\\mathcal{O}}(\\tilde{d}\\sqrt{T}\\beta^{-1}\\dot{C})$ , rather than the current $\\widetilde{\\mathcal{O}}(\\widetilde{d}\\beta^{-1}C)$ ", "page_idx": 18}, {"type": "text", "text": "To be specific, for scaling the arm weight based on $\\kappa$ , we first recall that in round $t\\in[T]$ , we have arm weights $w_{i,t}^{(\\tau)},\\tau\\in[t-1],i\\in[K]$ We can also denote $w_{i,t}^{(\\tau)}=\\operatorname*{min}\\left\\lbrace1,\\alpha\\cdot{\\sf f r a c}_{\\tau}(x_{i,t};\\mathcal{X}_{t},\\bar{\\Sigma}_{t-1})\\right\\rbrace$ Here, instead of deeming $\\alpha$ as a fixed value across horizon $T$ , we can consider $\\alpha$ to be varying across different rounds, denoted by $\\alpha_{t},t\\,\\in\\,[T]$ . With a shorthand for minimum fraction value frac\"min $\\mathsf{f r a c}_{t}^{\\mathsf{m i n}}=\\operatorname*{min}_{i\\in[K],\\tau\\in[t-1]}\\left[\\mathsf{f r a c}_{\\tau}(x_{i,t};\\mathcal{X}_{t},\\bar{\\Sigma}_{t-1})\\right]$ . we can st each $\\alpha_{t}\\,=\\,\\kappa^{2}/\\mathsf{f r a c}_{t}^{\\mathsf{m i n}},\\kappa\\,\\in\\,(0,1)$ As a result, we can consequently have $\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2},\\;\\forall t\\in[T]$ ", "page_idx": 18}, {"type": "text", "text": "B.6 Warm-start training for candidate arms ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Recall that in each round $t\\in\\{2,\\ldots,T\\}$ , we need to train different sets of arm-specific parameters $\\pmb{\\theta}_{i,t-1},i\\in[K]$ according to Algorithm 1, for each of the candidate arms $\\mathbf{\\Deltax}_{i,t}\\,\\in\\,\\mathcal{X}_{t},i\\,\\in\\,[K]$ .As we have mentioned in the main body, we can adopt the idea of warm-start GD [13] in practice. Here, instead of training each set of parameters $\\theta_{i,t-1}$ from the randomly initialized $\\theta_{0}$ , we tune arm-specific parameters for each $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ with a small number of samples from current received records $\\mathcal{P}_{t-1}$ Wth thefolae amweis $w_{i,t}^{(\\tau)}$ in (4), we frst recllthe arm-speci os function associated with arm $\\pmb{x}_{i,t}$ as ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathcal L_{i,t}(\\mathcal P_{t-1};\\pmb\\theta)=\\sum_{(\\pmb x_{\\tau},r_{\\tau})\\in\\mathcal P_{t-1}}\\frac{w_{i,t}^{(\\tau)}}{2}\\cdot\\left|f(\\pmb x_{\\tau};\\pmb\\theta)-r_{\\tau}\\right|^{2}+\\frac{m\\lambda}{2}\\cdot\\|\\pmb\\theta-\\pmb\\theta_{0}\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The idea is that instead of starting from $\\pmb{\\theta}_{0}$ , we can initiate the GD process from the existing network parameters $\\pmb{\\theta}_{t-2}$ from the previous round $t-1$ , where $\\pmb{\\theta}_{t-2}=\\pmb{\\theta}_{i_{t-1},t-2}$ represents the parameters associated with the chosen arm $\\pmb{x}_{t-1}=\\pmb{x}_{i_{t-1},t-1}$ in round $t-1$ . The pseudo-code for this arm-specific warm-start GD process is provided in Algorithm 2. ", "page_idx": 18}, {"type": "text", "text": "1: Input: Candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ . Training steps $\\bar{J}$ . Learning rates $\\eta$ . Batch size $B$ . Regulariza  \ntion parameter $\\lambda$ Network parameters $\\pmb{\\theta}_{t-2}$ from round $t-1$ . Received records $\\mathcal{P}_{t-1}$   \n2: Output: Trained arm-specific network parameters $\\theta_{i,t-1}$ for arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$   \n3: Sample a batch of training samples from $\\mathcal{P}_{t-1}$ , denoted by $\\widehat{\\mathcal{P}}_{t-1}\\subseteq\\mathcal{P}_{t-1}$ , where $|\\widehat{\\mathcal{P}}_{t-1}|=B$   \nFollowing 4), caculae arm weights for samples in Pt-1.   \n4 $\\pmb{\\theta}_{i,t-1}^{(0)}\\leftarrow\\pmb{\\theta}_{t-2}$   \n5: for each training step $j\\in\\bar{J}$ do   \n6: ) $\\pmb{\\theta}_{i,t-1}^{(j)}=\\pmb{\\theta}_{i,t-1}^{(j-1)}-\\eta\\nabla_{\\pmb{\\theta}}\\mathcal{L}_{i,t}(\\widehat{\\mathcal{P}}_{t-1};\\pmb{\\theta}_{i,t-1}^{(j-1)})$   \n7: end for   \n8: 0i,t-1 \u2190   \n9: Return arm-specific network parameters $\\theta_{i,t-1}$ ", "page_idx": 19}, {"type": "image", "img_path": "6U8iV9HVpS/tmp/347f372e8cfbde59b08dd0859e9a05690c9167aad82d8d3071a72bc65b90424e.jpg", "img_caption": ["Figure 2: Number of parameters with hidden dimensions $m$ . Inference time with warm-start. "], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "As a result, in our experiments, to balance computational costs and model performance, we implement the following strategies: (1) Inspired by meta-learning approaches [32], we apply warm-start gradient descent (GD) by adapting previously trained network parameters $\\theta_{t-2}$ for each candidate arm, using a small number of training samples rather than starting from $\\theta_{0}$ with a large sample size; (2) Based on our formulation of the warm-start GD process, we sample a fixed number of mini-batch training samples (i.e., received arm-reward pairs) for each candidate arm to compute arm weights and perform GD. Using a fixed number of training samples helps keep round-wise inference time relatively stable, avoiding a drastic increase with $T$ . Figure 2 illustrates the parameter count and inference time across different hidden dimensions. As shown, inference time remains relatively stable due to the fixed number of adaptation samples used for warm-start GD. ", "page_idx": 19}, {"type": "text", "text": "B.7Additional discussions on the lower bound ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Under linear bandit settings, there is a model-agnostic lower bound of corruption-dependent term $\\Omega(C d)$ with probability at least $1/2$ [17], which will also hold for neural bandit works as our $h(\\cdot)$ can be an arbitrary function. Meanwhile, the lower bounds for kernelized bandits tend to vary depending on kernel characteristics, e.g., $\\Omega(C(\\log(T))^{d/2})$ for the SE kernel and $\\Omega(C^{\\frac{v}{d+v}}T^{\\frac{v}{d+v}})$ for the $v\\cdot$ -Mat\u00e9rn kernel [70, 16]. In this case, the order of term $C$ and whether the lower bound depends on non-logarithmic $T$ , will both depend on the kernel properties. Therefore, given close connections between NTK-based regression and over-parameterized networks, we hypothesize that such a lower bound for neural bandits with corruption can depend on NTK properties. However, it will require significant efforts and a well-established existing knowledge base (e.g., number of functions $M$ needed for the functional separateness condition [70, 19] regarding specified kernels) to obtain such a lower bound for non-linear cases, especially considering few restrictions are imposed for reward mapping $h(\\cdot)$ for neural bandits. Since there are no existing works from neural bandits or NTK perspectives, it can lead to a different line of research work by proving these results. Therefore, we consider providing such a corruption-dependent regret lower bound as a challenging future direction. ", "page_idx": 19}, {"type": "text", "text": "Meanwhile, when $C\\,=\\,0$ , we obtain a corruption-free regret of $\\tilde{\\mathcal{O}}(\\tilde{d}\\sqrt{T}+S\\sqrt{\\tilde{d}T})$ . By setting $C\\,=\\,\\Omega(R_{T}/d)$ , the regret bound becomes $\\tilde{\\mathcal{O}}\\left((\\tilde{d}^{2}\\sqrt{T}+S\\tilde{d}^{3/2}\\sqrt{T})\\cdot C\\beta^{-1}d^{-1}\\right)$ . We note that, following the proof flow of Theorem 4.12 in [42] and the learning problem defined in Assumption ", "page_idx": 19}, {"type": "text", "text": "2.1 of [42], our effective dimension term $\\tilde{d}^{2}$ may depend on the horizon $T$ and can grow with $T$ [26]. Consequently, although the regret bound contains only $\\sqrt{T}$ terms, the overall order of the regret bound could reach or exceed ${\\mathcal{O}}(T)$ due to the effective dimension $\\tilde{d}^{2}$ , as discussed in [26]. This behavior differs from that of linear bandits, where regret bounds generally depend on the horizon $T$ and other $T$ -independent terms, such as context dimension $d$ and a fixed $T$ -independent linear parameter norm $\\lVert\\theta^{*}\\rVert_{2}$ . Therefore, our Theorem 5.6 will not contradict Theorem 4.12 in [42]. ", "page_idx": 20}, {"type": "text", "text": "C Regret Analysis for R-NeuralUCB ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "To begin with, recall that we aim to minimize the pseudo-regret for $T$ rounds, denoted by ", "page_idx": 21}, {"type": "equation", "text": "$$\nR(T)=\\sum_{t=1}^{T}R_{t}=\\sum_{t=1}^{T}\\left[h(\\pmb{x}_{t}^{*})-h(\\pmb{x}_{t})\\right]\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the second equality is due to the definition of reward mapping $h$ in (1). We denote $f(\\cdot)$ as the bandit model we currently possess, which is trained with corrupted records $\\mathcal{P}_{t-1}$ up to round $t$ Similarly, we can also suppose a corresponding imaginary corruption-free bandit model, which is trained with corruption-free records $\\tilde{\\mathcal{P}}_{t-1}$ . Similarly, the model parameters of our possessed $f(\\cdot)$ are denoted as $\\pmb{\\theta}$ , while the parameters of the imaginary corruption-free model will be denoted as $\\widetilde{\\pmb{\\theta}}$ ", "page_idx": 21}, {"type": "text", "text": "Subsections outline and proof sketch. The content in this section is organized into the following sub-components: In Subsection C.1, we first present theoretical properties related to our definitions of the NTK Gram matrix (Definitions 5.1 and 5.2); In Subsection C.2, we decompose the single-round objective $R_{t},t\\,\\in\\,[T]$ into its sub-components: (i) the first component represents the prediction error of the corruption-free model; (ii) the second component measures the potential arm selection discrepancy of the corrupted model caused by adversarial corruptions; and (i) the third component captures the estimation discrepancy between the corruption-free model and the corrupted model. Next, in Subsection C.3, we bound the cumulative pseudo-regret $R(T)$ (proof of Theorem 5.6). Using the auxiliary sequence introduced in Subsection C.4, we bound the components of the single-round regret in Subsections C.5 through C.8. Finally, we discuss bounding the minimum fraction term $\\beta$ in Subsection C.9, particularly when the observed arm contexts lie nearly within a low-dimensional subspace of the RKHS induced by NTK. ", "page_idx": 21}, {"type": "text", "text": "C.1  Theoretical Results with NTK Gram Matrices ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "We will first introduce some results, in order to link the NTK matrices (Def. 5.1 and Def. 5.2) with the reward mapping function $h(\\cdot)$ and the gradient covariance matrix $\\Sigma$ (Algorithm 1). ", "page_idx": 21}, {"type": "text", "text": "Lemma C.1. With probability at least $1-\\delta$ ifnetworkwidth $m$ satisfies the condition in Theorem 5.6, for any $\\pmb{x}\\in A_{T}$ , there exists a set of parameters $\\pmb{\\theta}^{*}$ suchthat ", "page_idx": 21}, {"type": "equation", "text": "$$\nh(\\pmb{x})=\\langle g(\\pmb{x};\\pmb{\\theta}_{0}),\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rangle\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where parameters $\\pmb{\\theta}^{*}$ satisfy $\\lVert\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rVert\\leq S/\\sqrt{m}$ . along with the NTK norm $S\\geq\\sqrt{2\\check{h}^{\\top}\\check{\\mathbf{H}}^{-1}\\check{h}}.$ ", "page_idx": 21}, {"type": "text", "text": "Proof. The proof of this lemma is inspired by that of Lemma 5.1 in [86]. However, we build our proof upon the non-duplicate arms $\\bar{\\lambda_{T}}$ and the corresponding NTK Gram matrix $\\breve{\\textbf{H}}$ (Def. 5.2), instead of imposing the full-rank assumption on the conventional NTK matrix $\\mathbf{H}$ (Def. 5.1). Here, we recall that the matrix $\\breve{\\textbf{H}}$ is naturally positive definite $(\\Breve{\\lambda}_{0}=\\lambda_{\\operatorname*{min}}(\\Breve{\\mathbf{H}})>0)$ , as it is the NTK Gram matrix built upon a set of distinct arms that are not parallel (Fact 5.4). ", "page_idx": 21}, {"type": "text", "text": "Then, consider the gradient matrix with no-duplicate arms $\\breve{\\mathbf{G}}=[g(\\pmb{x};\\pmb{\\theta}_{0})]_{\\pmb{x}\\in\\breve{\\mathcal{A}}_{T}}/\\sqrt{m}\\in\\mathbb{R}^{p\\times|\\check{A}_{T}|}$ \uff0c where $p$ represents the total number of parameters in the neural network. As a result, by applying conclusion from Lemma C.3 and due to the fact that $|\\breve{A}_{T}|\\,\\le\\,3T$ with the network width $m\\ge$ $\\Omega(L^{6}\\log(T L/\\delta)/\\epsilon)$ \uff0c $\\forall\\epsilon>0$ and the probability at least $1-\\delta$ , we will have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\lVert\\breve{\\mathbf{G}}^{\\top}\\breve{\\mathbf{G}}-\\breve{\\mathbf{H}}\\rVert_{F}\\leq\\lvert\\breve{\\mathcal{A}}_{T}\\rvert\\cdot\\epsilon.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "By setting $\\begin{array}{r}{\\epsilon=\\frac{\\breve{\\lambda}_{0}}{2|\\breve{\\mathscr A}_{T}|}}\\end{array}$ 2|Ar, we will have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\check{\\mathbf{G}}^{\\top}\\check{\\mathbf{G}}\\succeq\\check{\\mathbf{H}}-\\|\\check{\\mathbf{G}}^{\\top}\\check{\\mathbf{G}}-\\check{\\mathbf{H}}\\|_{F}\\mathbf{I}\\succeq\\check{\\mathbf{H}}-\\check{\\lambda}_{0}/2\\mathbf{I}\\succeq\\check{\\mathbf{H}}/2\\succ\\mathbf{0}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where the last two inequalities are due to Fact 5.4 that $\\breve{\\mathbf{H}}\\succeq\\breve{\\lambda}_{0}\\mathbf{I}\\succ\\mathbf{0}$ . Analogous to Lemma 5.1 in [86], we consider the singular value decomposition of $\\breve{\\mathbf{G}}$ being $\\breve{\\mathbf{G}}=\\breve{\\mathbf{P}}\\breve{\\mathbf{A}}\\breve{\\mathbf{Q}}\\breve{\\tau}$ , where we naturally have $\\breve{\\mathbf{A}}\\succ0$ since $\\breve{\\textbf{H}}$ is positive definite. Then, with the expected reward vector $\\breve{h}$ (Def. 5.2), we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\check{h}=(\\check{\\mathbf{Q}}\\check{\\mathbf{A}}\\check{\\mathbf{P}}^{\\intercal})\\cdot(\\check{\\mathbf{P}}\\check{\\mathbf{A}}^{-1}\\check{\\mathbf{Q}}^{\\intercal})\\cdot\\check{h}=\\sqrt{m}\\cdot\\check{\\mathbf{G}}^{\\intercal}(\\theta^{*}-\\theta_{0}),\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "by considering there exists a set of parameters $\\pmb{\\theta}^{*}=\\pmb{\\theta}_{0}+(\\breve{\\mathbf{P}}\\breve{\\mathbf{A}}^{-1}\\breve{\\mathbf{Q}}^{\\top})\\cdot\\breve{\\pmb{h}}/\\sqrt{m}$ ", "page_idx": 22}, {"type": "text", "text": "Therefore, since $\\breve{h}=\\sqrt{m}\\cdot\\breve{\\mathbf{G}}^{\\intercal}\\big(\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\big)$ , we will have $\\forall\\pmb{x}\\in\\breve{A}_{T}$ ", "page_idx": 22}, {"type": "equation", "text": "$$\nh(\\pmb{x})=\\langle g(\\pmb{x};\\pmb{\\theta}_{0}),\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rangle.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Meanwhile, since $\\breve{\\mathbf{G}}^{\\top}\\breve{\\mathbf{G}}\\succeq\\breve{\\mathbf{H}}/2$ , by applying Lemma G.8, we will have the distance ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{m\\cdot\\|\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\|_{2}^{2}=h^{\\top}\\check{\\mathbf{Q}}\\check{\\mathbf{A}}^{-1}\\check{\\mathbf{P}}^{\\top}\\cdot\\check{\\mathbf{P}}\\check{\\mathbf{A}}^{-1}\\check{\\mathbf{Q}}^{\\top}h=h^{\\top}(\\check{\\mathbf{G}}^{\\top}\\check{\\mathbf{G}})^{-1}h\\leq2h^{\\top}\\check{\\mathbf{H}}^{-1}h.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Finally, since the above results holds $\\forall\\pmb{x}\\in\\breve{A}_{T}$ , due to the fact that $\\breve{A}_{T}$ contains all the unique arms of the collection $A_{T}$ , we will directly have the above results regarding parameters $\\pmb{\\theta}^{*}$ feasible $\\forall\\pmb{x}\\in A_{T}$ . This completes the proof. ", "page_idx": 22}, {"type": "text", "text": "Lemma C.2. Suppose m satisfies the conditions in Theorem 5.6. Suppose the gradient matrix with randomly initialized parametersis $\\begin{array}{r}{\\Sigma^{(0)}=\\lambda\\mathbf{I}+\\sum_{\\pmb{x}\\in\\mathcal{A}}g(\\pmb{x};\\pmb{\\theta}_{0})\\cdot g(\\bar{\\pmb{x}};\\pmb{\\theta}_{0})^{\\top}/m,}\\end{array}$ upon an arbirary subset ${\\mathcal{A}}\\subseteq A_{T}$ of arm collection $A_{T}$ .With probability at least $1-\\delta$ overtheinitialization,the result holds: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\log\\left(\\frac{\\operatorname*{det}\\Sigma^{(0)}}{\\operatorname*{det}\\lambda\\mathbf{I}}\\right)\\leq\\widetilde{d}\\log(1+T K/\\lambda)+1.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. First, recall that we have $A_{T}$ as the arm collection of: (i) the chosen arms $\\{x_{t}\\}_{t=1}^{T}$ ; (i) the optimal arms $\\{\\mathbf{\\boldsymbol{x}}_{t}^{*}\\}_{t=1}^{T}$ ; (i) and the imaginary ones $\\{\\widetilde{\\mathbf{\\it{x}}}_{t}\\}_{t=1}^{T}$ chosen by the corruption-free model. This makes its cardinality $\\left|\\mathcal{A}_{T}\\right|=3T$ . Thus, for the left hand side, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\log\\frac{\\operatorname*{det}(\\mathbf{\\Sigma}^{(0)})}{\\operatorname*{det}(\\lambda\\mathbf{I})}\\leq\\log\\operatorname*{det}(\\lambda\\mathbf{I}+\\sum_{x\\in\\mathcal{A}_{T}}g(x;\\theta_{0})g(x;\\theta_{0})^{\\mathsf{T}}/m)=\\operatorname*{det}(\\lambda\\mathbf{I}+\\mathbf{G}_{0}\\mathbf{G}_{0}^{\\mathsf{T}}),\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Wwherewe definegradient matrix $\\mathbf{G}_{0}=\\left[g(\\pmb{x};\\pmb{\\theta}_{0})/\\sqrt{m}\\right]_{\\pmb{x}\\in\\mathcal{A}_{T}}\\in\\mathbb{R}^{p\\times(3T)}$ based on arm olletion $A_{T}$ . Here, based on Lemma C.3, we can bound the distance between the Gradient matrix product $\\mathbf{G}_{\\mathrm{0}}^{\\mathsf{T}}\\mathbf{G}_{\\mathrm{0}}$ and the NTK matrix $\\mathbf{H}$ (Def. 5.1), as ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\|\\mathbf{G}_{0}^{\\mathsf{T}}\\mathbf{G}_{0}-\\mathbf{H}\\|\\leq3T\\cdot{\\frac{1}{3T\\cdot{\\mathcal{O}}({\\sqrt{T}}/\\lambda)}}={\\frac{1}{{\\mathcal{O}}({\\sqrt{T}}/\\lambda)}},\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "by seting $\\begin{array}{r}{\\epsilon\\,=\\,\\frac{1}{3T\\cdot\\mathcal{O}(\\sqrt{T}/\\lambda)}}\\end{array}$ . The aove rslts ill hold a long as we have the net work with $m\\geq\\Omega((T L)^{6}\\log(T L/\\delta)/\\lambda^{4})$ , matching the conditions in Theorem 5.6. As a result, we can have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\log\\operatorname*{det}({\\mathbf I}+{\\mathbf G}_{0}^{\\top}{\\mathbf G}_{0}/\\lambda)}\\\\ &{\\qquad\\qquad=\\log\\operatorname*{det}({\\mathbf I}+{\\mathbf H}/\\lambda+({\\mathbf G}_{0}^{\\top}{\\mathbf G}_{0}-{\\mathbf H})/\\lambda)}\\\\ &{\\qquad\\qquad\\le\\log\\operatorname*{det}({\\mathbf I}+{\\mathbf H}/\\lambda)+\\langle({\\mathbf I}+{\\mathbf H}/\\lambda)^{-1},({\\mathbf G}_{0}^{\\top}{\\mathbf G}_{0}-{\\mathbf H})/\\lambda\\rangle}\\\\ &{\\qquad\\le\\log\\operatorname*{det}({\\mathbf I}+{\\mathbf H}/\\lambda)+\\|({\\mathbf I}+{\\mathbf H}/\\lambda)^{-1}\\|_{F}\\|{\\mathbf G}_{0}^{\\top}{\\mathbf G}_{0}-{\\mathbf H}\\|_{F}/\\lambda}\\\\ &{\\qquad\\le\\log\\operatorname*{det}({\\mathbf I}+{\\mathbf H}/\\lambda)+{\\mathcal O}(\\sqrt{T}/\\lambda)\\cdot\\|{\\mathbf G}_{0}^{\\top}{\\mathbf G}_{0}-{\\mathbf H}\\|_{F}}\\\\ &{\\qquad\\le\\log\\operatorname*{det}({\\mathbf I}+{\\mathbf H}/\\lambda)+1}\\\\ &{\\qquad=\\tilde{d}\\log(1+T K/\\lambda)+1.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "The first inequality is because the concavity of $\\log\\operatorname*{det}(\\cdot)$ function; The third inequality is due to $\\|(\\mathbf{I}+\\mathbf{H}\\lambda)^{-1}\\|_{F}\\leq\\|\\mathbf{I}^{-1}\\|_{F}\\leq\\sqrt{T}$ ; The fourth inequality is by applying the above distance upper bound $\\begin{array}{r}{\\|\\mathbf{G}_{0}^{\\top}\\mathbf{G}_{0}-\\mathbf{H}\\|\\leq\\frac{1}{\\mathcal{O}(\\sqrt{T}/\\lambda)}}\\end{array}$ The las inqguaityis becaus ofthe hoicethe $m$ The last equality is because of the Definition of d. The proof is completed. ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "Lemma C.3. With the randomly initialized network parameters $\\pmb{\\theta}_{0}\\in\\mathbb{R}^{p}$ andacollectionofarms $\\mathcal{A}\\subset\\mathbb{R}^{d}$ define the gradientmatrix $\\mathbf{G}_{\\mathcal{A}}\\,=\\,\\bigl[g\\bigl(\\mathbf{x};\\bar{\\theta}_{0}\\bigr)\\bigr]_{\\pmb{x}\\in\\mathcal{A}}\\,\\in\\,\\mathbb{R}^{p\\times|\\mathcal{A}|}$ .Following the recursive procedure in Def. 5.1 (7), construct the NTK Gram matrix $\\mathbf{H}_{A}$ based on arms $\\boldsymbol{\\mathcal{A}}$ Then, with the probability at least $1-\\delta$ ,we will have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\|\\mathbf{G}_{\\mathcal{A}}^{\\mathsf{T}}\\mathbf{G}_{\\mathcal{A}}-\\mathbf{H}_{\\mathcal{A}}\\|_{F}\\leq|\\mathcal{A}|\\cdot\\epsilon,\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "with the network width $m\\geq\\Omega(L^{6}\\log(|A|L/\\delta)/\\epsilon^{4})$ ", "page_idx": 22}, {"type": "text", "text": "Proof. The proof of this lemma is analogous to the proof of Lemma B.1 in [86]. Based on Theorem 3.1 from [4], we have that for any two arms $\\pmb{x},\\pmb{x}^{\\prime}\\in\\mathcal{A}$ asthenetworkwidth $m\\bar{\\geq}\\Omega(L^{6}\\log(L/\\delta)/\\epsilon^{4})$ we will have $|\\langle g(\\pmb{x};\\pmb{\\theta}_{0}),g(\\pmb{x}^{\\prime};\\pmb{\\theta}_{0})\\rangle/m-\\mathbf{H}_{\\cal A}[\\pmb{x},\\pmb{x}^{\\prime}]|\\leq\\epsilon$ ,where $\\mathbf{H}_{\\mathcal{A}}[\\pmb{x},\\pmb{x}^{\\prime}]$ represents the element in NTK Gram matrix $\\mathbf{H}_{A}$ that corresponds to arms $\\textbf{\\em x}$ and $\\pmb{x}^{\\prime}$ ", "page_idx": 23}, {"type": "text", "text": "Next, taking the union bound over all the arms in $\\boldsymbol{\\mathcal{A}}$ , we will have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\|\\mathbf{G}_{A}^{\\sf T}\\mathbf{G}_{A}-\\mathbf{H}_{A}\\|_{F}=\\sqrt{\\sum_{x\\in A}\\sum_{x^{\\prime}\\in A}|\\langle g(x;\\theta_{0}),g(x^{\\prime};\\theta_{0})\\rangle/m-\\mathbf{H}_{A}[x,x^{\\prime}]|^{2}}\\le|A|\\cdot\\epsilon,\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "as long as the network width $m\\geq\\Omega(L^{6}\\log(|A|L/\\delta)/\\epsilon^{4})$ ", "page_idx": 23}, {"type": "text", "text": "C.2  Bounding single-round regret ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "With the above results linking the NTK to the neural model, we proceed to bound the single-round regret $R_{t}$ for $t\\in[T]$ . This single-round regret will then be aggregated to obtain the cumulative regret $\\begin{array}{r}{R(T)=\\sum_{t\\in[T]}\\dot{R}_{t}}\\end{array}$ ", "page_idx": 23}, {"type": "text", "text": "Based on Lemma C.1, we have the expected reward of an arm $\\mathbf{\\boldsymbol{x}}\\in\\mathcal{X}_{t}$ being ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[r|x]=h(x)=\\langle g(x;\\pmb{\\theta}_{0}),\\ \\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where there exist parameters $\\pmb{\\theta}^{*}$ such that $\\lVert\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rVert\\leq S/\\sqrt{m}$ . Meanwhile, apart from the trained parameters $\\pmb\\theta_{t-1}$ based on chosen arms as welas the corresponding received rewards $\\{\\pmb{x}_{\\tau},r_{\\tau}\\}_{\\tau\\in[t-1]}$ we also denote the imaginary corruption-free parameters $\\widetilde{\\pmb{\\theta}}_{t-1}$ , which is trained with the chosen arms along with their unknown corruption-free rewards $\\{\\mathbf{\\Delta}x_{\\tau},\\widetilde{r}_{\\tau}\\}_{\\tau\\in[t-1]}$ , for the sake of analysis. ", "page_idx": 23}, {"type": "text", "text": "C.2.1  Decomposing the single-round regret ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "To bound the single-round regret $R_{t}$ , we first decompose the objective into several individual terms, and then bound them individually. For reference, the parameters $\\pmb\\theta_{t-1}$ , covariance matrix $\\Sigma_{t-1}$ confidence ellipsoid $\\mathcal{C}_{t-1}$ , and weights $w_{t}$ pertain to the chosen arm $\\pmb{x}_{t}$ , with the arm index $i\\in[K]$ omitted for simplicity of notation. ", "page_idx": 23}, {"type": "text", "text": "Arm selection scores. First, recall that based on the arm pulling mechanism (line 13, Algorithm 1) and the benefit score (6) (Lemma C.11), the chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ isselected by ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{x_{t}=\\arg\\operatorname*{max}_{x_{i,t}\\in\\mathcal{X}_{t}}\\left[f(\\boldsymbol{x}_{i,t};\\theta_{i,t-1})+\\gamma_{i,t-1}\\cdot\\sqrt{g(\\boldsymbol{x}_{i,t};\\theta_{i,t-1})^{\\top}\\Sigma_{i,t-1}^{-1}g(\\boldsymbol{x}_{i,t};\\theta_{i,t-1})/m}\\right]}\\\\ &{\\quad=\\arg\\operatorname*{max}_{x_{i,t}\\in\\mathcal{X}_{t}}U(\\boldsymbol{x}_{i,t}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we denote the corresponding score shorthand as ", "page_idx": 23}, {"type": "equation", "text": "$$\nU(\\pmb{x}_{i,t})=f(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1})+\\gamma_{i,t-1}\\cdot\\sqrt{g(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1})\\pmb{\\top}\\Sigma_{i,t-1}^{-1}g(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1})}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Analogously, with $\\widetilde{\\pmb{\\theta}}_{i,t-1}$ being the parameters trained on same set of chosen arms and the corresponding corruption-free rewards, we denote ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\widetilde{U}(\\boldsymbol{x}_{i,t})=f(\\boldsymbol{x}_{i,t};\\widetilde{\\boldsymbol{\\theta}}_{i,t-1})+\\widetilde{\\gamma}_{i,t-1}\\cdot\\sqrt{g(\\boldsymbol{x}_{i,t};\\widetilde{\\boldsymbol{\\theta}}_{i,t-1})\\tau\\widetilde{\\Sigma}_{i,t-1}^{-1}g(\\boldsymbol{x}_{i,t};\\widetilde{\\boldsymbol{\\theta}}_{i,t-1})},\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "h corresponding covariance matrix $\\begin{array}{r}{\\widetilde\\Sigma_{i,t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})g(\\pmb{x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})^{\\top}/m,}\\end{array}$ and the coefficient $\\widetilde{\\gamma}_{i,t-1}$ based on $\\widetilde{\\Sigma}_{i,t-1}$ following the definition from (6). It is obvious that the arm selection depends on the trained network parameters, and thus if the corruption makes the makes the trained network parameters $\\theta_{i,t-1}$ deviate from the corruption-free ones $\\widetilde{\\pmb{\\theta}}_{i,t-1}$ , it will lead to discrepancy in terms of arm selection decisions. ", "page_idx": 23}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "Alternative forms of selection scores. On the other hand, to maintain the consistency with the form of (C.1) in Lemma C.1, we can consider an alternative form of arm selection being ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V(x_{i,t})=\\langle g(x_{i,t};\\theta_{0}),\\ \\theta_{i,t-1}-\\theta_{0}\\rangle+\\gamma_{i,t-1}\\cdot\\sqrt{g(x_{i,t};\\theta_{i,t-1})^{\\top}\\Sigma_{i,t-1}^{-1}g(x_{i,t};\\theta_{i,t-1})/m}}\\\\ &{\\qquad\\qquad=\\displaystyle\\operatorname*{max}_{\\theta\\in C_{i,t-1}}\\left\\langle g(x_{i,t};\\theta_{0}),\\ \\theta-\\theta_{0}\\right\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we have $\\mathcal{C}_{i,t-1}\\;:=\\;\\{\\pmb{\\theta}\\,:\\,\\|\\pmb{\\theta}-\\pmb{\\theta}_{i,t-1}\\|_{\\pmb{\\Sigma}_{i,t-1}}\\,\\leq\\,\\gamma_{i,t-1}/\\sqrt{m},\\gamma_{i,t-1}\\,>\\,0\\}$ being the confidence ellipsoid of for the actual trained parameters $\\theta_{i,t-1}$ , trained with possibly corrupted records. $\\gamma_{i,t-1}>0$ represents the radius of the confidence ellipsoid; and the last equality in (C.4) is due to $\\begin{array}{r}{\\operatorname*{max}_{\\mathbf{\\boldsymbol{x}}:\\|\\mathbf{\\boldsymbol{x}}-\\mathbf{\\boldsymbol{b}}\\|_{\\mathbf{A}}\\leq c}\\langle\\mathbf{\\boldsymbol{a}},\\mathbf{\\boldsymbol{x}}\\rangle\\,=\\,\\langle\\mathbf{\\boldsymbol{a}},\\mathbf{\\boldsymbol{b}}\\rangle\\,+c\\cdot\\sqrt{\\mathbf{\\boldsymbol{a}}^{\\intercal}\\mathbf{A}^{-1}\\mathbf{\\boldsymbol{a}}}}\\end{array}$ [86].  Analogously, for the corruption-free parameters $\\widetilde{\\pmb{\\theta}}_{i,t-1}$ , we also define its confidence ellipsoid $\\widetilde{\\mathcal{C}}_{i,t-1}:=\\left.\\left\\{\\pmb{\\theta}:\\|\\pmb{\\theta}-\\widetilde{\\pmb{\\theta}}_{i,t-1}\\|_{\\widetilde{\\pmb{\\Sigma}}_{i,t-1}}\\right.\\leq$ $\\widetilde{\\gamma}_{i,t-1}/\\sqrt{m},\\widetilde{\\gamma}_{i,t-1}>0\\}$ , with $\\widetilde\\gamma_{i,t-1}>0$ being the radius of the confidence ellipsoid, and by Lemma C.10, we will have $\\pmb{\\theta}^{*}\\in\\widetilde{\\mathcal{C}}_{i,t-1}$ . As a result, we can also formulate an alternative form for arm selection as ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{V}(x_{i,t})=\\langle g(x_{i,t};\\theta_{0}),\\ \\widetilde{\\theta}_{i,t-1}-\\theta_{0}\\rangle+\\widetilde{\\gamma}_{i,t-1}\\cdot\\sqrt{g(x_{i,t};\\widetilde{\\theta}_{i,t-1})^{\\top}\\widetilde{\\Sigma}_{i,t-1}^{-1}g(x_{i,t};\\widetilde{\\theta}_{i,t-1})/m}}\\\\ &{\\qquad\\qquad=\\underset{\\widetilde{\\theta}\\in\\widetilde{\\mathcal{C}}_{i,t-1}}{\\operatorname*{max}}\\langle g(x_{i,t};\\theta_{0}),\\ \\widetilde{\\theta}-\\theta_{0}\\rangle.}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Here, the radius of the confidence ellipsoid for the corruption-free parameters $\\widetilde{\\gamma}_{i,t-1}$ , is provided in Lemma C.10, ensuring that $\\theta^{*}\\in\\widetilde{\\mathcal{C}}_{i,t-1}$ . On the other hand, deriving the radius for the trained model, $\\gamma_{i,t-1}$ in face of potential corruptions, is considerably more challenging. With our carefully designed arm weights in (4), we manage to establish the updated confidence ellipsoid in Lemma C.12, along with the corresponding UCB for reward estimation (Lemma C.11). ", "page_idx": 24}, {"type": "text", "text": "Note that our UCB-based exploration score (6) is also motivated by Lemma C.11. For a specific arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , our UCB-type exploration score includes only terms related to $\\mathbf{\\boldsymbol{x}}_{i,t}$ , omitting constant and arm-invariant parts. This approach is intuitive, as arm-independent terms do not influence arm selection (line 13, Algorithm 1), and they will remain the same across candidate arms $\\scriptstyle{\\mathcal{X}}_{t}$ .Moreover, with a sufficiently large network width $m$ as in Theorem 5.6, a majority of these terms can be further reduced to $\\mathcal{O}(1)$ ", "page_idx": 24}, {"type": "text", "text": "Decomposing the single-round objective. Up to the time step $t\\in[T]$ denoting $\\pmb{x}_{t},\\pmb{x}_{t}^{*}\\in\\mathcal{X}_{t}$ being the chosen arm and the optimal arm in each round respectively, we will have the corresponding regret boundforstep $t$ as: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{t}=\\operatorname*{min}\\Bigg\\{h(\\pmb{x}_{t}^{*})-h(\\pmb{x}_{t}),\\:1\\Bigg\\}}\\\\ &{\\quad=\\operatorname*{min}\\Bigg\\{h(\\pmb{x}_{t}^{*})-\\widetilde{V}(\\pmb{x}_{t})+\\underbrace{\\widetilde{V}(\\pmb{x}_{t})-h(\\pmb{x}_{t})}_{\\widetilde{\\cup\\nabla\\pmb{\\Omega}_{t}}(\\pmb{x}_{t})},\\:1\\Bigg\\}}\\\\ &{\\quad=\\operatorname*{min}\\Bigg\\{\\widetilde{\\cup\\mathrm{CB}}_{t}(\\pmb{x}_{t})+\\underbrace{h(\\pmb{x}_{t}^{*})-V(\\pmb{x}_{t})}_{I_{R_{1}}}+\\underbrace{V(\\pmb{x}_{t})-\\widetilde{V}(\\pmb{x}_{t})}_{I_{R_{2}}},\\:1\\Bigg\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the first equality is because we have the expected rewards in bounded value range $[0,1]$ .Here, with the three terms after decomposing the single-round regret $R_{t}$ , we can bound the first term $\\widetilde{\\mathsf{U C B}}_{t}({\\pmb x}_{t})$ with Lemma C.9, while bounding the two error terms $I_{R_{1}}$ and $I_{R_{2}}$ with Lemma C.6 and Lemma C.4 respectively. ", "page_idx": 24}, {"type": "text", "text": "C.3  Bounding cumulative regret $R(T)$ (Proof of Theorem 5.6) ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "First, we would like to mention that since both the expected corrupted reward $\\mathbb{E}[r]$ and the expected corruption-free reward $\\mathbb{E}[\\widetilde{r}]$ fall within the range $[0,1]$ , as defined in (1), it follows that $C\\leq T$ . In this case, as long as the network width requirement $m\\bar{\\geq}\\Omega(\\mathrm{poly}(T))$ in Theorem 5.6 is adequately satisfied, this naturally implies $m\\geq\\Omega({\\mathrm{poiy}}(C,T))$ with a sufficiently large network width $m$ . This also indicates that knowledge of $C$ is not mandatory for setting $m$ before the online learning process begins. The above clarification will also be used to establish the final regret bound. ", "page_idx": 24}, {"type": "text", "text": "Then, with the derived results in terms of single-round regret $R_{t},t\\quad\\in\\ [T]$ ,we can then proceed to bound the cumulative regret over $T$ rounds. By definition in (C.6), we have $\\begin{array}{r}{\\stackrel{\\triangledown}{R}(T)=\\sum_{t=1}^{T}\\operatorname*{min}\\bigg\\{\\widetilde{\\mathrm{UCB}}_{t}(\\boldsymbol{x}_{t})+\\underbrace{h(\\pmb{x}_{t}^{*})-V(\\boldsymbol{x}_{t})}_{I_{R_{1}}}+\\underbrace{V(\\pmb{x}_{t})-\\widetilde{V}(\\pmb{x}_{t})}_{I_{R_{2}}},\\,1\\bigg\\}.}\\end{array}$ Recall that the fist term $\\widetilde{\\mathsf{U C B}}_{t}({\\pmb x}_{t})$ can be bounded with Lemma C.9, while we bound the other two error terms $I_{R_{1}}$ and $I_{R_{2}}$ with Lemma C.6 and Lemma C.4 respectively. Next, with the conclusions from above lemmas, we will have ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{R(T)}&{=\\displaystyle\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{\\Re(\\mathbf{z}(\\mathbf{z}_{h})(\\mathbf{z}_{t})+\\frac{\\mathbf{k}(\\mathbf{z}_{t})-\\mathbf{\\xi}_{V}(\\mathbf{z}_{t})}{I_{h}})+\\frac{\\mathbf{\\xi}_{V}(\\mathbf{z}_{t})-\\mathbf{\\xi}_{V}(\\mathbf{z}_{t})}{I_{h}}\\right\\}}\\\\ &{\\leq\\displaystyle\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{2\\widetilde{\\gamma}_{t-1}\\cdot\\mathbf{\\xi}_{[0]}(\\mathbf{z}_{t},\\widetilde{\\mathbf{z}}_{t-1})\\sqrt{\\gamma}\\mathfrak{m}\\right\\}\\rVert_{\\widetilde{\\mathbf{z}}_{t-1}}+\\eta\\langle\\mathbf{z}_{t},\\widetilde{\\mathbf{z}}_{t},\\widetilde{\\mathbf{z}}_{t}\\rangle}\\\\ &{\\quad+\\mathcal{O}(\\alpha{\\mathcal{C}})\\cdot\\left\\lVert\\mathfrak{p}(\\mathbf{z}_{t},\\widetilde{\\mathbf{z}}_{t-1})\\sqrt{\\gamma}\\mathfrak{m}\\right\\rVert_{\\mathfrak{z}_{t-1}\\to\\mathbf{\\xi}_{t}}^{2}+\\mathcal{O}(\\sqrt{\\Delta}{\\mathcal{S}})\\cdot\\left\\lVert\\mathfrak{p}(\\mathbf{z}_{t},\\widetilde{\\mathbf{z}}_{t-1})\\sqrt{\\gamma}\\mathfrak{m}\\right\\rVert_{\\mathfrak{z}_{t-1}\\to\\mathbf{\\xi}_{t}}}\\\\ &{\\quad+\\mathcal{O}(\\alpha{\\mathcal{C}})\\cdot\\left\\lVert\\mathfrak{p}(\\mathbf{z}_{t},\\widetilde{\\mathbf{z}}_{t-1})\\sqrt{\\gamma}\\mathfrak{m}\\right\\rVert_{\\mathfrak{z}_{t-1}\\to\\mathbf{\\xi}_{t}}^{2}+\\mathcal{O}(\\sqrt{\\Delta}{\\mathcal{S}})\\cdot\\left\\lVert\\mathfrak{g}(\\mathbf{z}_{t},\\widetilde{\\mathbf{z}}_{t-1})\\sqrt{\\gamma}\\mathfrak{m}\\right\\rVert_{\\mathfrak{z}_{t-1}\\to\\mathbf{\\xi}_{t}}}\\\\ &{\\quad+\\mathcal{O}((\\mathbf{z}^{-2/3})\\mathrm{L}_{\\mathfrak{z}_{t}}(\\mathbf{z}_{t})L^{2/3}L^{3}L^{3})+\\mathbb{V}\\mathfrak{f}(\\widetilde{\\mathbf{z}}_{t})}\\\\ &{\\quad+\\mathcal{O}(\\mathfrak{m}^{-1/8})\\sqrt{\\gamma}\\mathfrak{m}\\{(\\mathfrak{m})\\}L\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where \" weight-free\" covariance matrices are $\\begin{array}{r}{\\bar{\\Sigma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\tau}/m,}\\end{array}$ and $\\begin{array}{r}{\\Sigma_{t-1}^{\\prime}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\widetilde{\\pmb{x}}_{\\tau};\\pmb{\\theta}_{\\widetilde{i}_{\\tau},\\tau-1})g(\\widetilde{\\pmb{x}}_{\\tau};\\pmb{\\theta}_{\\widetilde{i}_{\\tau},\\tau-1})^{\\intercal}/m}\\end{array}$ . Afterwards, with suffcient network width $m$ that satisfies the conditions in Theorem 5.6, the majority of the terms on the RHS of (C.7), which contain $m$ to the negative order, can be reduced to $O(1)$ . Thus, we will then have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R(T)\\leq\\mathcal{O}(1)+\\frac{\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{\\mathcal{Z}_{T_{1}-1}^{T}-1\\:\\mathrm{lg}(\\alpha_{t},\\bar{\\theta}_{t-1}),\\sqrt{\\pi}\\mathfrak{M}_{\\theta-1}\\right\\}\\sqrt{m}\\frac{1}{|\\alpha_{T-1}^{-1}+\\gamma_{1}-1}\\mathrm{lg}(\\alpha_{t},\\theta_{t-1})|\\sqrt{m}\\mathfrak{M}_{\\theta-1}\\right\\}}\\\\ &{+\\mathcal{O}(\\alpha^{-1})\\left\\{\\theta(x,\\theta_{t-1})\\sqrt{\\pi}\\mathfrak{M}_{\\theta-1}^{-1},\\cdots\\right\\}\\quad+\\mathcal{O}(\\sqrt{\\lambda})\\Bigg\\lVert\\Phi(\\bar{\\theta}_{t},\\theta_{t-1})\\mathrm{,~}}\\\\ &{+\\mathcal{O}(\\alpha^{-1})\\Bigg\\rVert\\left\\{\\mathcal{O}(\\alpha_{t},\\theta_{t-1})\\sqrt{\\pi}\\right\\}\\Bigg\\rVert_{\\frac{1}{\\theta_{t-1}},\\cdots,1}^{\\theta_{t}}+\\mathcal{O}(\\sqrt{\\lambda})\\Bigg\\lVert\\Phi(\\alpha_{t},\\theta_{t-1})\\sqrt{\\pi}\\mathfrak{M}_{\\theta-1}\\Bigg\\}\\cdots}\\\\ &{\\leq\\mathcal{O}(1)+\\frac{\\sum_{t=1}^{T}\\operatorname*{min}\\Big\\{\\mathcal{Z}_{T_{1}-1}^{T}-1\\:\\mathrm{lg}(\\alpha_{t},\\bar{\\theta}_{t-1}),\\sqrt{\\pi}\\mathfrak{M}_{\\theta-1}^{-1}+\\gamma_{1}-1\\:\\mathrm{lg}(\\alpha_{t},\\theta_{t-1})\\sqrt{\\pi}\\mathfrak{M}_{\\theta-1}\\mathrm{,~}1\\right\\}}{t\\sum_{t=1}^{T}-1\\:\\mathrm{lg}(\\alpha_{t},\\theta_{t-1})\\sqrt{\\pi}\\mathfrak{M}_{\\theta-1}\\mathrm{,~}1\\Bigg\\}}}\\\\ &{\\quad+\\mathcal{O}(\\alpha^{-1})\\cdot\\sum_{t=1}^{T}\\left\\{\\left\\lvert\\Phi(\\alpha_{t},\\theta_{t-1})\\sqrt{\\pi}\\mathfrak{M}_{\\theta-1}^{-1},\\cdots\\right\\}\\right\\}}\\\\ &{\\quad+\\mathcal{O}(\\sqrt{\\lambda})\\Bigg\\lvert\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{\\left\\lVert\\Phi(\\alpha_{t},\\theta_{t-1})\\sqrt{\\pi}\\mathfrak \n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the second inequality is by applying the triangular inequality. Then, denote $w_{\\mathsf{m i n}}~=$ $\\operatorname*{min}[\\{w_{t}^{(\\tau)},w_{\\tilde{i}_{t},t}^{(\\tau)}\\}_{t\\in[T],\\tau\\in[t-1]}]$ . Aalogously we als ave theround-wis mnimum weight value being $w_{t}^{\\mathsf{m i n}}=\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2}<1$ \uff0c $\\forall t\\in[T]$ which wil eud tmn scaling parameter $\\alpha$ With our notation from Theorem 5.6, this intuitively leads to $\\begin{array}{r}{\\alpha\\le\\frac{\\kappa^{2}}{\\beta}}\\end{array}$ .As a ", "page_idx": 25}, {"type": "text", "text": "result, we can therefore have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R(T)\\leq\\mathcal{O}(1)+\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{\\mathcal{Z}_{7\\tilde{t}_{t-1}}\\cdot\\mathrm{lig}(x_{t};\\tilde{\\theta}_{t-1})\\sqrt{\\gamma\\mathfrak{m}}\\rVert_{\\tilde{\\Sigma}_{t-1}^{-1}}+\\gamma_{t-1}\\cdot\\mathrm{lig}(x_{t};\\theta_{t-1})\\sqrt{\\gamma\\mathfrak{m}}\\rVert_{\\mathbf{X}_{t-1}^{-1}}\\cdot1\\right\\}}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C\\beta^{-1}\\kappa^{2})\\cdot\\log\\frac{\\mathrm{dif}(\\tilde{X}_{T})}{\\mathrm{dif}(|\\tilde{X}|)}+\\mathcal{O}(\\sqrt{3}\\kappa)\\cdot\\sqrt{T}\\log\\frac{\\mathrm{dif}(\\tilde{\\Sigma}_{T})}{\\mathrm{dif}(|\\tilde{X}|)}+\\mathcal{O}(\\sqrt{\\lambda}S)\\cdot\\sqrt{T}\\log}\\\\ &{\\qquad\\leq\\mathcal{O}(1)+\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{2\\tilde{\\gamma}_{t-1}\\cdot\\mathrm{lig}(x_{t};\\tilde{\\theta}_{t-1})\\sqrt{\\gamma\\mathfrak{m}}\\rVert_{\\tilde{\\Sigma}_{t-1}^{-1}}+\\gamma_{t-1}\\cdot\\mathrm{lig}(x_{t};\\theta_{t-1})\\sqrt{\\gamma\\mathfrak{m}}\\rVert_{\\mathbf{X}_{t-1}^{-1}}\\cdot1\\right\\}}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C\\beta^{-1}\\kappa^{2})\\cdot\\mathrm{dig}(1+T K/\\lambda)+\\mathcal{O}(\\sqrt{3}S)\\cdot\\sqrt{T\\mathrm{dig}(1+T K/\\lambda)}}\\\\ &{\\qquad\\leq\\mathcal{O}(1)+\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{\\frac{\\gamma}{\\sqrt{\\mathfrak{m}}\\mathfrak{m}}\\cdot\\mathrm{lif}\\sqrt{\\mathfrak{m}}\\mathfrak{m}\\mathfrak{a}(x_{t};\\tilde{\\theta}_{t-1})\\sqrt{\\gamma\\mathfrak{m}}\\rVert_{\\tilde{\\Sigma}_{t-1}^{-1}}\\cdot1\\right\\}}\\\\ &{\\qquad\\qquad+\\sum_{t=1}^{T}\\operatorname*{min}\\left\\{\\frac{\\gamma}{\\sqrt{\\mathfrak{m}}m}\\rVert_{\\mathbf{Y}}\\mathrm{emp}(x_{t};\\theta_{t-1})/\\sqrt{\\mathfrak{m}}\\rVert_{\\mathbf{X}_{t-1}^{-1}}\\right\\}}\\\\ &{\\qquad \n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the first inequality is because the auxiliary matrices $\\bar{\\Sigma}_{t-1}^{(0)}$ and $\\Sigma_{t-1}^{\\prime}$ do not involve arm weights, thus we can directly applying the Lemma G.7 and Lemma G.6. The second inequality is by applying Lemma C.2. Meanwhile, since $\\Sigma_{t-1}^{\\prime}$ is not defined w.r.t. randomly initialized $\\theta_{0}$ , we additional apply the Lemma G.6 in terms of the matrix determinant difference to derive the results, where the extra term will also be reduced to $\\mathcal{O}(1)$ with sufficiently large $m$ . Afterwards, for the rest of the summation term ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{in~}\\Gamma(S),\\ \\mathrm{weabsre}}\\\\ &{\\ V=S(\\frac{\\gamma}{\\sqrt{\\pi}\\omega_{0}})\\Bigg\\{\\sqrt{\\displaystyle\\frac{\\gamma}{\\Gamma}\\sin\\left\\{\\sqrt{\\pi}\\cos\\left(\\alpha_{1}\\theta_{*}\\right)-1\\right\\}\\sqrt{\\sin\\left\\{\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\right\\}\\right\\}}}\\;+\\;}}\\\\ &{\\qquad\\quad+\\mathcal{O}(\\frac{\\gamma}{\\sqrt{\\pi}\\omega_{0}})\\sqrt{\\displaystyle\\frac{\\gamma}{\\Gamma}\\frac{\\gamma}{\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\right\\}}\\right\\}}}}\\;+\\;}}\\\\ &{\\qquad\\quad+\\mathcal{O}(\\epsilon^{-1}\\kappa^{-1})\\mathrm{~;~}\\mathrm{d}\\alpha_{1}\\big\\{\\cdot\\Gamma}(S)+\\mathcal{O}(\\sqrt{\\delta})\\bigg\\lvert\\sqrt{\\frac{\\gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\right\\}}{\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac}{\\Gamma}\\right\\}}\\right\\}}\\right\\rvert}}\\right)}}\\\\ &{\\therefore\\frac{\\gamma}{\\sqrt{\\cos\\left(\\alpha_{1}\\theta_{*}\\right)-1}}\\Bigg\\{\\sqrt{d}\\frac{\\gamma}{\\sin(1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\right\\})}-\\frac{\\gamma}{2}d\\phi(\\gamma)+\\mathcal{O}(\\kappa^{-1})\\sqrt{\\sin\\left\\{\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\sin\\left\\{1+\\frac{\\gamma}{\\Gamma}\\cos\\left\\{1+\\frac{\\gamma}{\\Gamma}\\right\\}}\\right\\}}\\;+\\;}}\\\\ &{\\qquad\\quad+\\mathcal{O}(\\sqrt{\\delta})\\Bigg\\}+\\mathcal{O}(\\sqrt{\\delta}),}\\\\ &{\\therefore\\frac{1}{\\sqrt\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the second inequality is by applying Lemma G.7 and Lemma C.2, as well as the definition of coefficients $\\gamma_{T},\\widetilde{\\gamma}_{T}$ , along with the fact that $\\gamma_{T}\\,\\geq\\,\\gamma_{t},\\widetilde{\\gamma}_{T}\\,\\geq\\,\\widetilde{\\gamma}_{t},t\\,\\in\\,[T]$ . The last inequality is by applying Lemma G.6. With sufficiently large network width $m$ as in Theorem 5.6, we can have $\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}T^{5/3}\\lambda^{-1/6})\\leq\\mathcal{O}(1)$ Then, due to he faethat $\\bar{\\Sigma}_{T}^{(0)}\\succeq\\widetilde{\\Sigma}_{T}^{(0)},\\Sigma_{T}^{(0)}$ >T\u201d,\u2265T\u2032, applying ", "page_idx": 26}, {"type": "text", "text": "the Lemma C.2, it will then lead to ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R(T)\\leq\\frac{1}{\\sqrt{w\\mathsf{m i n}}}\\mathcal{O}\\bigg(\\nu\\sqrt{\\widetilde{d}\\log(1+T K/\\lambda)-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)\\sqrt{T\\widetilde{d}\\log(1+T K/\\lambda)}}\\\\ &{\\qquad\\qquad+\\mathcal{O}\\big(C\\beta^{-1}\\kappa^{2}\\big)\\cdot\\widetilde{d}\\log(1+T K/\\lambda)+\\mathcal{O}(1)}\\\\ &{\\qquad\\leq\\mathcal{O}\\bigg(\\nu\\sqrt{\\widetilde{d}\\log(1+T K/\\lambda)-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)\\sqrt{T\\widetilde{d}\\log(1+T K/\\lambda)/\\kappa^{2}}}\\\\ &{\\qquad\\qquad+\\mathcal{O}\\big(C\\beta^{-1}\\widetilde{d}\\kappa^{2}\\log(1+T K/\\lambda)\\big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where the second inequality is by setting the tunable parameter $\\alpha$ in each round accordingly, in order to ensure $w_{\\mathrm{min}}\\ \\stackrel{\\cdot}{=}\\ \\dot{\\kappa^{2}}\\ <\\ \\dot{1}$ Here, we remind that our regret analysis does not require the learner to know the minimum fraction value $\\beta$ before the online learning process, where $\\beta\\,=\\,\\mathrm{min}_{t\\in[T],\\tau\\in[t-1]}\\,\\big[\\,\\mathrm{min}\\{\\mathsf{f r a c}_{\\tau}(x_{t};\\mathcal{X}_{t},\\bar{\\Sigma}_{t-1}),\\mathsf{f r a c}_{\\tau}(\\widetilde{\\boldsymbol{x}}_{t};\\mathcal{X}_{t},\\bar{\\boldsymbol{x}})\\,\\big]\\,,$ $\\mathsf{f r a c}_{\\tau}(\\widetilde{\\pmb{x}}_{t};\\mathcal{X}_{t},\\bar{\\pmb{\\Sigma}}_{t-1})\\}\\big]$ . As we have mentioned, in practice, the learner can scale the $\\alpha$ values in each round to make sure the round-wise minimum weight alue $w_{t}^{\\mathsf{m i n}}=\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2}<1$ $\\forall t\\in[T]$ (Subsec.B.5). ", "page_idx": 27}, {"type": "text", "text": "C.4  Auxiliary sequences: Regression parameters and gradient descent parameters ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "To bridge neural models with NTK regression, we have two different routes to decouple the effects of adversarial corruptions from the received arm rewards. First, we define the gradient-based ridge regression parameters specific to a candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ in round $t\\in[T]$ ,as ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{i,t-1}^{(0)}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}^{(\\tau)}w_{i,t}^{(\\tau)}g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})^{\\tau}/m,}\\\\ {\\displaystyle\\sum_{i,t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}^{(\\tau)}w_{i,t}^{(\\tau)}g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})^{\\tau}/m,}\\\\ {\\displaystyle\\widetilde{\\Sigma}_{i,t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}^{(\\tau)}w_{i,t}^{(\\tau)}g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\tilde{\\theta}}_{\\tau-1})\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\tilde{\\theta}}_{\\tau-1})^{\\tau}/m,}\\\\ {\\displaystyle b_{i,t-1}^{(0)}=\\sum_{\\tau\\in[t-1]}^{\\tau}w_{i,t}^{(\\tau)}g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot r_{\\tau}/\\sqrt{m},\\qquad\\ b_{i,t-1}=\\sum_{\\tau\\in[t-1]}^{\\tau}w_{i,t}^{(\\tau)}g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot r_{\\tau}/\\sqrt{m},}\\\\ {\\displaystyle\\widetilde{b}_{i,t-1}^{(0)}=\\sum_{\\tau\\in[t-1]}^{\\tau}w_{i}^{(\\tau)}g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot\\widetilde{r}_{\\tau}/\\sqrt{m},\\qquad\\widetilde{b}_{i,t-1}=\\sum_{\\tau\\in[t-1]}^{\\tau}w_{i,t}^{(\\tau)}g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot\\widetilde{r}_{\\tau}/\\sqrt{m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\{\\mathbf{\\boldsymbol{x}}_{\\tau},r_{\\tau}\\},\\tau\\ \\in\\ [t]$ respectively stand for the chosen arms as well as their rewards, while $\\{\\b{x}_{\\tau},\\b{\\widetilde{r}}_{\\tau}\\},\\tau\\in\\{t\\}$ refer to chosen arms and their imaginary corruption-free rewards. For notation simplicity, we use $w_{t}^{(\\tau)},\\tau\\in[t-1]$ to denote the arm weights for $\\pmb{x}_{t}$ ", "page_idx": 27}, {"type": "text", "text": "Meanwhie givenan andidate am $\\pmb{x}_{i,t}\\,\\in\\,\\mathcal{X}_{t}$ Wwith am weight $w_{i,t}^{(\\tau)}$ defned in (4),we can try to bound the term by decomposing the adversarial corruptions with a series auxiliary gradient sequences $\\{\\pmb\\theta_{0},\\pmb\\Theta^{(1)},\\dots,\\pmb\\Theta^{(J)}\\}$ as in Lemma D.1, such that for $j$ -th iteration ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta^{(j+1)}=\\Theta^{(j)}-\\eta\\cdot\\left[\\mathbf{J}^{(0)}\\cdot\\mathbf{W}\\cdot\\left([\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\theta_{0})-y\\right)+m\\lambda(\\Theta^{(j)}-\\theta_{0})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "as well as an analogous sequence for corruption-free parameters ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\widetilde{\\Theta}^{(j+1)}=\\widetilde{\\Theta}^{(j)}-\\eta\\cdot\\left[\\mathbf{J}^{(0)}\\cdot\\mathbf{W}\\cdot([\\mathbf{J}^{(0)}]^{\\top}(\\widetilde{\\Theta}^{(j)}-\\theta_{0})-\\widetilde{\\boldsymbol{y}})+m\\lambda(\\widetilde{\\Theta}^{(j)}-\\theta_{0})\\right]\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where $\\mathbf{J}^{(0)}:=\\left(g(\\pmb{x}_{1};\\pmb{\\theta}_{0}),g(\\pmb{x}_{2};\\pmb{\\theta}_{0}),\\dots,g(\\pmb{x}_{t-1};\\pmb{\\theta}_{0})\\right)\\in\\mathbb{R}^{p\\times(t-1)}$ and $\\mathbf{W}$ refers to the diagonal matrix of arm weights $\\{w_{i,t}^{(\\tau)}\\}_{\\tau\\in[t-1]}$ ,along with the reward vectors $\\pmb{y},\\widetilde{\\pmb{y}}\\in\\mathbb{R}^{t-1}$ separately being the vector of received rewards and corruption-free rewards. In particular, with $[\\mathbf{J}^{(0)}]_{\\tau}$ being the $\\tau$ -th column of matrix $\\mathbf{J}^{(0)}$ , the auxiliary sequence $\\Theta^{(j)}$ can be deemed as applying Gradient Descent to ", "page_idx": 27}, {"type": "text", "text": "solve the following optimization problem ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\Theta}\\mathcal{L}(\\Theta)=\\sum_{\\tau\\in[t-1]}\\frac{1}{2}\\cdot w_{i,t}^{(\\tau)}\\cdot\\left\\|[\\mathbf{J}^{(0)}]_{\\tau}^{\\top}(\\Theta-\\theta_{0})-y_{\\tau}\\right\\|_{2}^{2}+\\frac{1}{2}\\cdot m\\lambda\\cdot\\left\\|\\Theta-\\theta_{0}\\right\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Analogously, we can also derive the optimization problem for the sequence of corruption-free auxiliaryparameters $\\widetilde{\\Theta}^{(j)}$ , by applying the same definition of weight matrix W. Since the arm weights $w\\leq1$ by definition, we will also have the diagonal matrix norm $\\lVert\\mathbf{W}\\rVert_{2}\\leq1$ ", "page_idx": 28}, {"type": "text", "text": "Notation simplicity. For reference, we remind that the parameters $\\pmb\\theta_{t-1}$ , covariance matrix $\\Sigma_{t-1}$ \uff0c confidence ellipsoid $\\mathcal{C}_{t-1}$ , and weights $w_{t}$ pertain to the chosen arm $\\pmb{x}_{t}$ , with the arm index $i\\in[K]$ omitted for simplicity of notation. Meanwhile, the gradinet covariance matrix $\\Sigma_{i,t-1}$ , confidence ellipsoid $\\mathcal{C}_{i,t-1}$ , and weights $w_{i,t}$ are associated with each candidate arm $\\pmb{x}_{i,t}$ for $i\\in[K]$ ", "page_idx": 28}, {"type": "text", "text": "C.5  Bounding the error term $I_{R_{2}}$ in (C.6) ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Recall that to derive the upper bound for the single-round regret $R_{t}$ , we need to respectively bound the three error terms on the RHS of (C.6). Here, we first bound term $I_{R_{2}}$ with the following Lemma C.4. ", "page_idx": 28}, {"type": "text", "text": "Lemma C.4. Suppose the imaginary neural network $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{t-1})$ in round $t\\in[T]$ has been trained on corruption-free rewards $\\{\\pmb{x}_{\\tau},\\widetilde{r}_{\\tau}\\}_{\\tau\\in[t-1]}$ Meanwhile, $f(\\cdot)$ is an $L$ -layer $F C$ network withwidth $m$ Suppose we have $m,J,\\eta$ satisfying the conditions in Theorem 5.6. Then, for the chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ \uff0c with the probability at least $1-\\delta$ we will have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{R_{2}}=V(\\pmb{x}_{t})-\\widetilde{V}(\\pmb{x}_{t})}\\\\ &{\\quad\\le\\gamma_{t-1}\\cdot\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{\\pmb{\\Sigma}_{t-1}^{-1}}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{2/7})}\\\\ &{\\quad\\quad\\ +\\mathcal{O}(\\alpha C)\\cdot\\left\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\pmb{\\Sigma}_{t-1})^{-1}}^{2}+\\mathcal{O}(\\sqrt{\\lambda}S)\\left\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\pmb{\\Sigma}_{t-1})^{-1}}}\\\\ &{\\quad\\quad\\ +\\mathcal{O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{5})}\\\\ &{\\quad\\quad\\le\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4})}\\\\ &{\\quad\\quad\\quad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{7/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "By definition, we have Yt-1 = O(vlog dat<) $\\begin{array}{r}{\\gamma_{t-1}=\\mathcal{O}\\big(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}(\\Sigma_{t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\big)}\\end{array}$ dt< - 2log(8) + X1/2S), as well as the gradient covariance matrix $\\begin{array}{r}{\\bar{\\Sigma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\tau}/m.}\\end{array}$ The minimum round-wise arm weight $w_{t}^{m i n}=\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2}<1$ \uff0c $\\forall t\\in[T]$ by scalin paramneter $\\alpha$ ", "page_idx": 28}, {"type": "text", "text": "Proof. For the error term $I_{R_{2}}$ , we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{R_{2}}=V(x_{t})-\\tilde{V}(x_{t})}\\\\ &{\\qquad=\\underset{\\theta\\in\\mathbb{C}_{t-1}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{0}),\\ \\theta-\\theta_{0}\\rangle-\\underset{\\theta\\in\\mathcal{C}_{t-1}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{0}),\\ \\tilde{\\theta}-\\theta_{0}\\rangle}\\\\ &{\\qquad\\le\\underset{\\theta\\in\\mathbb{C}_{t-1}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{0}),\\ \\theta-\\theta_{0}\\rangle-\\langle g(x_{t};\\theta_{0}),\\ \\tilde{\\theta}_{t-1}-\\theta_{0}\\rangle}\\\\ &{\\qquad\\le\\underset{\\theta\\in\\mathbb{C}_{t-1}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{0}),\\ \\theta-\\theta_{0}\\rangle-\\langle g(x_{t};\\theta_{t-1}),\\ \\tilde{\\theta}_{t-1}-\\theta_{0}\\rangle+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{2}}\\\\ &{\\qquad=\\underset{\\theta\\in\\mathbb{C}_{t-1}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{0}),\\ \\theta-\\theta_{t-1}\\rangle-\\langle g(x_{t};\\theta_{t-1}),\\ \\tilde{\\theta}_{t-1}-\\theta_{t-1}\\rangle+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2}}\\\\ &{\\qquad=\\underset{\\theta\\in\\mathbb{C}_{t-1}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{0}),\\ \\theta-\\theta_{t-1}\\rangle+\\lvert\\underbrace{\\langle g(x_{t};\\theta_{t-1}),\\ \\tilde{\\theta}_{t-1}-\\theta_{t-1}\\rangle}_{I_{2}}\\rvert+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2}}\\\\ &{\\qquad\\le\\underset{\\mathrm{Pycion}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{0}),\\ \\theta\\rvert_{\\mathrm{Perese}}\\,}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the first inequality is because of the definition of confidence ellipsoids $\\widetilde{\\mathcal{C}}_{t-1}$ and $\\mathcal{C}_{t-1}$ .The second inequality is by applying Lemma G.3 and Lemma G.4. Here, we have the first term on the RHS is bounded by Corollary C.5, where this term is used to represent the gradient projection difference, between the confidence ellipsoid center parameters $\\pmb\\theta_{t-1}$ and the other parameters in this confidenceellipsoid $\\pmb{\\theta}\\in\\mathcal{C}_{t-1}$ .Meanwhile, term $I_{2}$ will be bounded by Corollary C.8. ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 29}, {"type": "text", "text": "Corollary C.5. Suppose the imaginary neural network $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{t-1})$ in round $t\\in[T]$ hasbeentrained on corruption-free rewards $\\{\\boldsymbol{x}_{\\tau},\\boldsymbol{\\widetilde{r}}_{\\tau}\\}_{\\tau\\in[t-1]}$ .Meanwhile, $f(\\cdot)$ is an $L$ -layer $F C$ networkwithwidth $m$ .Supposewehave $m,J,\\eta$ satisfying the conditions in Theorem 5.6. Then, for the chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ withtheprobability atleast $1-\\delta$ we will have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\varepsilon C_{t-1}}\\langle g(x_{t};\\theta_{0}),\\ \\theta-\\theta_{t-1}\\rangle\\leq\\gamma_{t-1}\\cdot\\|g(x_{t};\\theta_{t-1})/\\sqrt{m}\\|_{\\Sigma_{t-1}^{-1}}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{2/7}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "and the corresponding summationvalue being ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in[T]}\\operatorname*{min}\\big\\{\\operatorname*{max}_{\\theta\\in C_{t-1}}\\langle g(x_{t};\\theta_{0}),\\,\\theta-\\theta_{t-1}\\rangle,1\\big\\}}\\\\ &{\\displaystyle\\qquad\\leq\\frac{1}{\\sqrt{w_{t}^{m}\\!\\!\\!}^{\\rho}}\\mathcal{O}\\bigg(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}(\\Sigma_{T})}{\\operatorname*{det}(\\lambda\\mathrm{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)\\cdot\\sqrt{2T\\cdot\\log\\frac{\\operatorname*{det}(\\Sigma_{T})}{\\operatorname*{det}(\\lambda\\mathrm{I})}}\\cdot}\\\\ &{\\displaystyle\\qquad\\qquad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}T^{7/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}T^{7/6}\\lambda^{-7/6}L^{2/7}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Bydefnition, we have theradius ofCt being t1 =(v log $\\begin{array}{r}{\\gamma_{t-1}=\\mathcal{O}\\big(\\nu\\cdot\\sqrt{\\log\\frac{\\operatorname*{det}(\\Sigma_{t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\big)}\\end{array}$ and the gradient covariance matrix $\\begin{array}{r}{\\Sigma_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m.}\\end{array}$ ", "page_idx": 29}, {"type": "text", "text": "Proof. The proof of this corollary follows an analogous approach as Lemma C.9. By definition, we have the gradient inner product for the chosen arm $\\pmb{x}_{t}$ in round $t$ as ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{\\theta\\in C_{t-1}}{\\operatorname*{max}}\\left\\langle g(x_{t};\\theta_{0}),\\ \\theta-\\theta_{t-1}\\right\\rangle}\\\\ &{\\qquad\\leq\\underset{\\theta\\in C_{t-1}}{\\operatorname*{max}}\\Vert\\theta-\\theta_{t-1}\\Vert_{\\Sigma_{t-1}}\\cdot\\Vert g(x_{t};\\theta_{0})\\Vert_{\\Sigma_{t-1}^{-1}}}\\\\ &{\\qquad\\leq\\gamma_{t-1}\\cdot\\Vert g(x_{t};\\theta_{t-1})/\\sqrt{m}\\Vert_{\\Sigma_{t-1}^{-1}}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{2/7})}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the first inequality is due to Holder's inequality. The second inequality is by applying the definition of confidence ellipsoid $\\mathcal{C}_{t-1}$ , as well as Lemma G.4 and Lemma G.6. Then, similarly, we will also need to bound the summation over $T$ rounds. Following an analogous procedure as in Lemma C.9, we will have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sum_{t\\in[T]}\\operatorname*{min}\\{\\operatorname*{max}_{\\theta\\in C_{t-1}}\\langle g(x_{t};\\theta_{0}),\\,\\theta-\\theta_{t-1}\\rangle,\\,1\\}}}\\\\ &{}&{\\leq\\frac{1}{\\sqrt{w_{t}^{\\mathrm{min}}}}\\mathcal{O}\\bigg(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}\\bigl(\\sum_{T}\\bigr)}{\\operatorname*{det}\\bigl(\\lambda\\mathbf{I}\\bigr)}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)\\cdot\\sqrt{2T\\cdot\\log\\frac{\\operatorname*{det}\\bigl(\\sum_{T}\\right)}{\\operatorname*{det}\\bigl(\\lambda\\mathbf{I}\\bigr)}}\\cdot}\\\\ &{}&{\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}T^{7/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}T^{7/6}\\lambda^{-7/6}L^{2/7}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "By the definition $\\beta=\\operatorname*{min}_{t\\in[T],\\tau\\in[t-1]}[\\operatorname*{min}\\{\\{\\mathsf{r a c}_{\\tau}(\\pmb{x}_{t};\\mathcal{X}_{t},\\bar{\\Sigma}_{t-1})}$ \uff0c $\\mathsf{f r a c}_{\\tau}(\\widetilde{\\pmb{x}}_{t};\\mathcal{X}_{t},\\bar{\\pmb{\\Sigma}}_{t-1})\\}$ , we have the lower bound of arm weights being $w_{t}^{\\mathsf{m i n}}\\geq\\alpha\\cdot\\beta$ . Note that we also scale the $\\alpha$ parameter to ensure $w_{t}^{\\mathsf{m i n}}=\\kappa^{2}$ asindiatdwhqiw $\\beta$ ", "page_idx": 29}, {"type": "text", "text": "C.6 Bounding the error term $I_{R_{1}}$ in (C.6) ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In this subsection, we bound the error term $I_{R_{1}}$ in (C.6), with the following Lemma C.6. Meanwhile, we denote an extra weight-free gradient covariance matrix for the chosen arms $\\{\\widetilde{x}_{\\tau}\\}_{\\tau\\in[t]}$ of the corruption-free model. The corresponding arm index is denoted as $\\tilde{\\dot{i}}_{t},t\\in[T]$ ,such that $\\pmb{x}_{\\widetilde{i}_{t},t}=\\widetilde{\\pmb{x}}_{t}$ ", "page_idx": 29}, {"type": "text", "text": "Lemma C.6. Suppose the imaginary neural network $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{t-1})$ in round $t\\in[T]$ has been trained on corruption-free rewards $\\{\\mathbf{\\Delta}x_{\\tau},\\widetilde{r}_{\\tau}\\}_{\\tau\\in[t-1]}$ . Meanwhile, $f(\\cdot)$ is an $L$ -layer $F C$ network with width $m$ ", "page_idx": 29}, {"type": "text", "text": "Supposewehave $m,J,\\eta$ satisfying the conditions in Theorem 5.6. Then, for the chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ withtheprobabilityatleast $1-\\delta$ wewillhave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{R_{1}}=h({\\pmb x}_{t}^{*})-V({\\pmb x}_{t})}\\\\ &{\\quad\\leq{\\mathcal O}(\\alpha C)\\bigg\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\bigg\\|_{(\\overline{{\\pmb x}}_{t-1})^{-1}}^{2}+{\\mathcal O}(\\sqrt{\\lambda}S)\\cdot\\bigg\\|g(\\widetilde{{\\pmb x}}_{t};{\\pmb\\theta}_{i_{t-1}-1})/\\sqrt{m}\\bigg\\|_{({\\pmb x}_{t-1}^{\\prime})^{-1}}}\\\\ &{\\quad\\quad\\quad\\quad+{\\mathcal O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+{\\mathcal O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{?}}\\\\ &{\\quad\\quad\\quad\\quad+{\\mathcal O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4})}\\\\ &{\\quad\\quad\\quad\\quad+\\nu\\cdot\\sqrt{1+{\\mathcal O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot{\\mathcal O}(m^{-1/12}\\log^{1/4}(m)L^{3}t^{5/6}\\lambda^{-7/12})}\\\\ &{\\quad\\quad\\quad\\quad+{\\mathcal O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})+{\\mathcal O}(m^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\quad\\quad\\quad\\quad+\\,\\gamma_{i,t-1}\\cdot{\\mathcal O}(m^{-1/12}t^{7/12}\\lambda^{-1/3}/\\log^{1/4}(m)L^{t/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Bydefnition, we have the coefcient -1 = O(vlg t $\\begin{array}{r}{\\gamma_{\\tilde{i}_{t},t-1}=\\mathcal{O}\\big(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}(\\Sigma_{\\tilde{i}_{t},t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\big),}\\end{array}$ as well as the gradient covariance matrices $\\begin{array}{r}{\\Sigma_{t-1}^{\\prime}\\,=\\,\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\widetilde{i}_{\\tau},\\tau-1})g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\widetilde{i}_{\\tau},\\tau-1})^{\\tau}/m,}\\end{array}$ and $\\begin{array}{r}{\\bar{\\Sigma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\tau}/m}\\end{array}$ The minimum round-wise arm weight $w_{t}^{m i n}=\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2}<1$ $\\forall t\\in[T]$ byscalin parameter $\\alpha$ ", "page_idx": 30}, {"type": "text", "text": "Proof. By definition, we can have $I_{R_{1}}=h(\\pmb{x}_{t}^{*})-U(\\pmb{x}_{t})+U(\\pmb{x}_{t})-V(\\pmb{x}_{t})$ Here, in terms of the distance between $U(\\pmb{x}_{i,t})$ and $V(\\pmb{x}_{i,t})$ given a candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|U(\\pmb{x}_{i,t})-V(\\pmb{x}_{i,t})|=|f(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1})-\\left\\langle g(\\pmb{x}_{i,t};\\pmb{\\theta}_{0}),\\ \\pmb{\\theta}_{i,t-1}-\\pmb{\\theta}_{0}\\right\\rangle|}\\\\ &{\\qquad\\qquad\\leq|f(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1})-\\left\\langle g(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1}),\\ \\pmb{\\theta}_{i,t-1}-\\pmb{\\theta}_{0}\\right\\rangle|}\\\\ &{\\qquad\\qquad\\qquad+|\\left\\langle g(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1}),\\ \\pmb{\\theta}_{i,t-1}-\\pmb{\\theta}_{0}\\right\\rangle-\\left\\langle g(\\pmb{x}_{i,t};\\pmb{\\theta}_{0}),\\ \\pmb{\\theta}_{i,t-1}-\\pmb{\\theta}_{0}\\right\\rangle|}\\\\ &{\\qquad\\qquad\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where the first inequality is by triangular inequality, and the second inequality is by applying a similar approach as in (B.12) from [86] as well as Lemma G.4. Next, we proceed to bound term $I_{R_{1}}$ . Here, for a candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ and the associated corruption-free confidence ellipsoid $\\widetilde{C}_{i,t-1}$ , we have $\\pmb{\\theta}^{*}\\in\\widetilde{\\mathcal{C}}_{i,t-1}$ based on Lemma C.10. Thus, with $\\widetilde{\\pmb{x}}_{t}=\\arg\\operatorname*{max}_{\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}}\\widetilde{V}(\\pmb{x}_{i,t})$ being the arm chosen by the corruption-free neural model, with the highest score $\\widetilde{V}(\\widetilde{\\pmb{x}}_{t})$ , there will be ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{R_{1}}=h(\\pmb{x}_{t}^{*})-U(\\pmb{x}_{t})+U(\\pmb{x}_{t})-V(\\pmb{x}_{t})}\\\\ &{\\qquad=\\langle g(\\pmb{x}_{t}^{*};\\pmb{\\theta}_{0}),~\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rangle-U(\\pmb{x}_{t})+U(\\pmb{x}_{t})-V(\\pmb{x}_{t})}\\\\ &{\\qquad\\le\\underbrace{\\operatorname*{max}_{\\tilde{\\theta}\\in\\tilde{C}_{\\tilde{t}_{t},t-1}}\\langle g(\\pmb{x}_{t}^{*};\\pmb{\\theta}_{0}),~\\widetilde{\\pmb{\\theta}}-\\pmb{\\theta}_{0}\\rangle-U(\\pmb{x}_{t})+U(\\pmb{x}_{t})-V(\\pmb{x}_{t})}_{\\tilde{\\theta}\\in\\tilde{C}_{\\tilde{t}_{t},t-1}}}\\\\ &{\\qquad\\le\\underbrace{\\operatorname*{max}_{\\tilde{\\theta}\\in\\tilde{C}_{\\tilde{t}_{t},t-1}}\\langle g(\\widetilde{\\pmb{x}}_{t};\\pmb{\\theta}_{0}),~\\widetilde{\\pmb{\\theta}}-\\pmb{\\theta}_{0}\\rangle-U(\\pmb{x}_{t})+|U(\\pmb{x}_{t})-V(\\pmb{x}_{t})|,}_{\\tilde{\\theta}\\in\\tilde{C}_{\\tilde{t}_{t},t-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\widetilde{C}_{\\tilde{i}_{t},t-1}$ refers toth condencellipoidof corution-fr paraetr $\\widetilde{\\pmb{\\theta}}_{\\widetilde{i}_{t},t-1}$ , associated to arm $\\widetilde{\\mathbf{\\boldsymbol{x}}}_{t}\\in\\mathcal{X}_{t}$ . Afterwards, it further leads to ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{R_{1}}\\leq\\underset{\\Tilde{\\theta}\\in\\Tilde{\\mathcal{C}}_{\\Tilde{\\iota}_{\\tau,t-1}}}{\\operatorname*{max}}\\;\\langle g(\\widetilde{\\alpha}_{t};\\theta_{0}),\\Tilde{\\theta}-\\theta_{0}\\rangle-U(x_{t})}\\\\ &{\\qquad\\qquad\\qquad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\quad\\leq\\underset{\\Tilde{\\theta}\\in\\Tilde{\\mathcal{C}}_{\\Tilde{\\mathcal{C}}_{\\Tilde{\\iota}_{\\tau,t-1}}}}{\\operatorname*{max}}\\;\\langle g(\\widetilde{\\alpha}_{t};\\theta_{0}),\\Tilde{\\theta}-\\theta_{0}\\rangle-V(x_{t})}\\\\ &{\\qquad\\qquad\\quad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\quad\\leq\\underset{\\Tilde{\\theta}\\in\\Tilde{\\mathcal{C}}_{\\Tilde{\\mathcal{C}}_{\\Tilde{\\iota}_{\\tau,t-1}}}}{\\operatorname*{max}}\\;\\langle g(\\widetilde{\\alpha}_{t};\\theta_{0}),\\Tilde{\\theta}-\\theta_{0}\\rangle-V(\\widetilde{\\alpha}_{t})}\\\\ &{\\qquad\\qquad\\quad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\quad=\\widetilde{V}(\\widetilde{\\alpha}_{t})-V(\\widetilde{\\alpha}_{t})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "To bound the output difference between $V(\\pmb{x}_{i,t})$ and $\\widetilde{V}(\\mathbf{\\boldsymbol{x}}_{i,t})$ for an arm $\\pmb{x}_{i,t}$ , we can decompose them into separate terms. Recall the definition of $V(\\cdot)$ in (C.4), and we can also define the analogous $\\widetilde{V}(\\cdot)$ by applying the corruption-free parameters $\\widetilde{\\pmb{\\theta}}$ and covariance matrix $\\widetilde{\\Sigma}$ Therefore, for arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{^{\\prime}({x}_{i,t})-\\widetilde{V}({x}_{i,t})\\leq|{V}({x}_{i,t})-{V}^{(0)}({x}_{i,t})|+|{V}^{(0)}({x}_{i,t})-\\widetilde{V}^{(0)}({x}_{i,t})|+|\\widetilde{V}^{(0)}({x}_{i,t})-\\widetilde{V}({x}_{i,t})|,}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where for the sake of analysis, we define two variants with randomly initialized parameters $\\theta_{0}$ being: $\\begin{array}{r}{V^{(0)}(\\boldsymbol{x}_{i,t})=\\left\\langle g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0}),\\;\\boldsymbol{\\theta}_{t-1}-\\boldsymbol{\\theta}_{0}\\right\\rangle+\\gamma_{t-1}\\cdot\\sqrt{g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})\\tau(\\boldsymbol{\\Sigma}_{t-1}^{(0)})^{-1}g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})/m}}\\end{array}$ ,and $\\begin{array}{r}{\\widetilde{V}^{(0)}(\\boldsymbol{x}_{i,t})=\\left\\langle g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0}),\\;\\widetilde{\\boldsymbol{\\theta}}_{t-1}-\\boldsymbol{\\theta}_{0}\\right\\rangle+\\widetilde{\\gamma}_{t-1}\\cdot\\sqrt{g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})\\tau(\\boldsymbol{\\Sigma}_{t-1}^{(0)})^{-1}g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})/m}.}\\end{array}$ Withthis result, our objective then is to derive the upper bounds for the three terms on the RHS of (C.15). ", "page_idx": 31}, {"type": "text", "text": "Bounding the second term $|V^{(0)}(\\pmb{x}_{i,t})-\\widetilde{V}^{(0)}(\\pmb{x}_{i,t})|$ in (C.15). For the second term, we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V^{(0)}(\\mathbf{x}_{i,t})-\\widetilde{V}^{(0)}(\\mathbf{x}_{i,t})|}\\\\ &{\\le|\\big\\langle g(\\mathbf{x}_{i,t};\\theta_{0}),\\,\\theta_{i,t-1}-\\widetilde{\\theta}_{i,t-1}\\big\\rangle|}\\\\ &{\\quad+|\\gamma_{i,t-1}\\cdot\\sqrt{g(\\mathbf{x}_{i,t};\\theta_{0})\\tau(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}g(\\mathbf{x}_{i,t};\\theta_{0})/m}-\\widetilde{\\gamma}_{i,t-1}\\cdot\\sqrt{g(\\mathbf{x}_{i,t};\\theta_{0})\\tau(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}g(\\mathbf{x}_{i,t};\\theta_{0})}}\\\\ &{=|\\big\\langle g(\\mathbf{x}_{i,t};\\theta_{0}),\\,\\theta_{i,t-1}-\\widetilde{\\theta}_{i,t-1}\\big\\rangle|+|\\gamma_{i,t-1}-\\widetilde{\\gamma}_{i,t-1}|\\cdot\\sqrt{g(\\mathbf{x}_{i,t};\\theta_{0})\\tau(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}g(\\mathbf{x}_{i,t};\\theta_{0})/m}}\\\\ &{\\le|\\big\\langle g(\\mathbf{x}_{i,t};\\theta_{0}),\\,\\theta_{i,t-1}-\\widetilde{\\theta}_{i,t-1}\\big\\rangle|+|\\gamma_{i,t-1}-\\widetilde{\\gamma}_{i,t-1}|\\cdot\\mathcal{O}(L/\\sqrt{\\lambda}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Due to the fact that $|{\\sqrt{a}}-{\\sqrt{b}}|\\leq{\\sqrt{|a-b|}}$ , based on the definition of $\\gamma_{i,t-1}$ and $\\widetilde{\\gamma}_{i,t-1}$ , we will have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\gamma_{i,t-1}-\\widetilde\\gamma_{i,t-1}\\big|\\leq\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\cdot\\sqrt{\\left|\\log(\\frac{\\operatorname*{det}\\Sigma_{i,t-1}}{\\operatorname*{det}\\lambda\\mathbf{I}})-\\log(\\frac{\\operatorname*{det}\\Sigma_{0}}{\\operatorname*{det}\\lambda\\mathbf{I}})+\\log(\\frac{\\operatorname*{det}\\Sigma_{0}}{\\operatorname*{det}\\lambda\\mathbf{I}})-\\log(\\frac{\\operatorname*{det}\\widetilde\\Sigma_{i,t-1}}{\\operatorname*{det}\\lambda\\mathbf{I}})\\right|}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{2}t^{5/6}\\lambda^{-1/12})}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "based on Lemma G.6. Therefore, we will end up with ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|V^{(0)}(\\boldsymbol{x}_{i,t})-\\widetilde{V}^{(0)}(\\boldsymbol{x}_{i,t})|\\le|\\big\\langle g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0}),\\,\\boldsymbol{\\theta}_{i,t-1}-\\widetilde{\\boldsymbol{\\theta}}_{i,t-1}\\big\\rangle|}\\\\ &{\\qquad\\qquad+\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{3}t^{5/6}\\lambda^{-7/12}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Bounding Term $|V(\\pmb{x}_{i,t})-V^{(0)}(\\pmb{x}_{i,t})|$ and term $|\\widetilde V^{(0)}(\\mathbf{\\boldsymbol{x}}_{i,t})-\\widetilde V(\\mathbf{\\boldsymbol{x}}_{i,t})|$ in (C.15). On the other hand, for the first term on the RHS, $|V(\\pmb{x}_{i,t})-V^{(0)}(\\pmb{x}_{i,t})|$ , we can bound this difference term by ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\gamma(\\boldsymbol{x}_{i,t})-V^{(0)}(\\boldsymbol{x}_{i,t})}\\\\ &{=\\frac{\\gamma_{i,t-1}}{\\sqrt{m}}\\biggl(\\sqrt{g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})^{\\top}\\Sigma_{i,t-1}^{-1}g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})}-\\sqrt{g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})^{\\top}\\big(\\Sigma_{i,t-1}^{(0)}\\big)^{-1}g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})}\\biggr)}\\\\ &{=\\frac{\\gamma_{i,t-1}}{\\sqrt{m}}\\biggl(\\left\\|g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})\\right\\|_{\\Sigma_{i,t-1}^{-1}}-\\left\\|g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})\\right\\|_{(\\Sigma_{i,t-1}^{(0)})^{-1}}\\biggr)}\\\\ &{\\leq\\frac{\\gamma_{i,t-1}}{\\sqrt{m}}\\biggl(\\left\\|g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})\\right\\|_{\\Sigma_{i,t-1}^{-1}}-\\left\\|g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})\\right\\|_{(\\Sigma_{i,t-1}^{(0)})^{-1}}+\\left\\|g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{0})-g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})\\right\\|_{(\\Sigma_{i,t-1}^{(0)})^{-1}}}\\\\ &{\\leq\\mathcal{O}(m^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})+\\frac{\\gamma_{i,t-1}}{\\sqrt{m}}\\cdot\\biggl(\\left\\|g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})\\right\\|_{\\Sigma_{i,t-1}^{-1}}-\\left\\|g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})\\right\\|_{(\\Sigma_{i,t-1}^{(0)})^{-1}}\\biggr)}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\mathcal{O}(\\mathfrak{m}^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\qquad\\qquad+\\frac{\\gamma_{i,t-1}}{\\sqrt{m}}\\cdot\\left(\\sqrt{g(x_{i,t};\\theta_{i,t-1})\\tau\\Sigma_{i,t-1}^{-1}g(x_{i,t};\\theta_{i,t-1})-g(x_{i,t};\\theta_{i,t-1})\\tau(\\Sigma_{i,t-1}^{(0)})^{-1}g(x_{i,t};\\theta_{i,t-1})}\\right.}\\\\ &{\\leq\\mathcal{O}(\\mathfrak{m}^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})+\\frac{\\gamma_{i,t-1}}{\\sqrt{m}}\\cdot\\left(\\sqrt{\\langle g(x_{i,t};\\theta_{i,t-1}),\\ (\\Sigma_{i,t-1}^{-1}-(\\Sigma_{i,t-1}^{(0)})^{-1})g(x_{i,t};\\theta_{i,t-1})\\rangle}\\right.}\\\\ &{=\\mathcal{O}(\\mathfrak{m}^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\qquad\\qquad+\\left.\\frac{\\gamma_{i,t-1}}{\\sqrt{m}}\\cdot\\left(\\sqrt{\\left\\langle g(x_{i,t};\\theta_{i,t-1}),\\ \\left(\\Sigma_{i,t-1}^{-1}\\cdot(\\Sigma_{i,t-1}^{(0)}-\\Sigma_{i,t-1})\\cdot(\\Sigma_{i,t-1}^{(0)})^{-1}\\right)^{-1}\\right\\rangle}\\cdot g(x_{i,t};\\theta_{i,t-1})\\right.}\\\\ &{\\leq\\mathcal{O}(\\mathfrak{m}^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})+\\gamma_{i,t-1}\\cdot\\mathcal{O}(\\mathfrak{m}^{-1/12}t^{7/12}\\lambda^{-13/12}\\log^{1/4}(m)L^{t/2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first inequality is because of the triangular inequality. The second inequality is by applying Lemma G.4. The third inequality is again the application of triangular inequality, and the last inequality is the application of Lemma G.6. Since the similar procedure can also be applied to bound the third term $|\\widetilde{V}^{(0)}(\\mathbf{x}_{i,t})-\\widetilde{V}(\\mathbf{x}_{i,t})|$ , after summing up the results, we will have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|V(x_{i,t})-V^{(0)}(x_{i,t})|,\\,|\\tilde{V}^{(0)}(x_{i,t})-\\tilde{V}(x_{i,t})|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})+\\mathcal{O}(m^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\,\\gamma_{i,t-1}\\cdot\\mathcal{O}(m^{-1/12}t^{7/12}\\lambda^{-13/12}\\log^{1/4}(m)L^{t/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Summing up results. Combining the results, we finally have the upper bound for $I_{R_{1}}$ being ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{R_{1}}\\leq|\\langle g(\\widetilde{x}_{t};\\theta_{0}),\\theta_{i_{t},t-1}-\\widetilde{\\theta}_{i_{t},t-1}\\rangle|}\\\\ &{\\qquad+\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{3}t^{5/6}\\lambda^{-7/12})}\\\\ &{\\qquad\\quad+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})+\\mathcal{O}(m^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\qquad\\quad+\\gamma_{t,t-1}\\cdot\\mathcal{O}(m^{-1/12}t^{7/12}\\lambda^{-13/12}\\log^{1/4}(m)L^{t^{\\prime}/2})}\\\\ &{\\qquad\\quad\\leq|\\langle g(\\widetilde{x}_{t};\\theta_{i_{t},t-1}),\\theta_{i_{t},t-1}-\\widetilde{\\theta}_{i_{t},t-1}\\rangle|}\\\\ &{\\qquad\\quad+\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{3}t^{5/6}\\lambda^{-7/12})}\\\\ &{\\qquad\\quad+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\qquad\\quad+\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})+\\mathcal{O}(m^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\qquad\\quad+\\gamma_{t,t-1}\\cdot\\mathcal{O}(m^{-1/12}t^{7/12}\\lambda^{-13/12}\\log^{1/4}(m)L^{7/2}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "and therefore we can formulate our objective to bound as ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{R_{1}}\\leq|\\underbrace{\\langle g(\\widetilde{x}_{t};\\theta_{\\widetilde{t}_{t},t-1}),\\ \\theta_{\\widetilde{t}_{t},t-1}-\\widetilde{\\theta}_{\\widetilde{t}_{t},t-1}\\rangle}_{I_{1}}|}\\\\ &{\\qquad+\\,\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{3}t^{5/6}\\lambda^{-7/12})}\\\\ &{\\qquad+\\,\\mathcal{O}(m^{-1/6}t^{2/3}\\lambda^{-2/3}\\sqrt{\\log(m)}L^{7/2})+\\mathcal{O}(m^{-1/6}t^{1/6}\\lambda^{-7/6}\\sqrt{\\log(m)}L^{7/2})}\\\\ &{\\qquad+\\,\\gamma_{\\widetilde{t}_{t},t-1}\\cdot\\mathcal{O}(m^{-1/12}t^{7/12}\\lambda^{-13/12}\\log^{1/4}(m)L^{t/2}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "wherewe recall that $\\nu$ is the pre-defined exploration parameter that echoes the sub-Gaussian noise variance proxy. Finally, using the upper bound for term $I_{1}$ from Lemma C.7 will finish the proof. ", "page_idx": 32}, {"type": "text", "text": "C.7  Bounding the terms $I_{1},I_{2}$ ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Here, we see that there are still two terms in $R_{t},t\\in[T]$ that need to be bounded, which are ", "page_idx": 32}, {"type": "equation", "text": "$$\nI_{1}=\\big\\langle g(\\widetilde{\\pmb{x}}_{t};\\pmb{\\theta}_{\\widetilde{i}_{t},t-1}),\\ \\pmb{\\theta}_{\\widetilde{i}_{t},t-1}-\\widetilde{\\pmb{\\theta}}_{\\widetilde{i}_{t},t-1}\\big\\rangle,\\qquad I_{2}=\\langle g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1}),\\ \\widetilde{\\pmb{\\theta}}_{t-1}-\\pmb{\\theta}_{t-1}\\rangle,\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where we recall $\\mathbf{\\mathcal{x}}_{t}\\,\\in\\,\\mathcal{X}_{t}$ is the actual chosen arm that is selected by the corrupted model $\\pmb\\theta_{t-1}$ while we have $\\widetilde{\\mathbf{x}}_{t}\\in\\mathcal{X}_{t}$ being the imaginary arm chosen by the corruption-free model $\\widetilde{\\pmb{\\theta}}_{t-1}$ . In this subsection, the error term $I_{1}$ will be bounded by Lemma C.7, while term $I_{2}$ will be bounded by Corollary C.8. ", "page_idx": 33}, {"type": "text", "text": "Recap of auxiliary parameter definitions. With definitions in Subsection C.4, we can have two different alternatives to decouple the adversarial corruptions from arm rewards: (i) the gradient-based regression parameters; and, (i) the auxiliary sequence of gradient descent. For reference, recall that we denote the a series of gradient-based regression parameters, specified to candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ as ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{\\Sigma}_{i,t-1}^{(0)}=\\lambda\\mathbf{I}+\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})^{\\top}/m,}\\\\ &{\\boldsymbol{\\Sigma}_{i,t-1}=\\lambda\\mathbf{I}+\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})^{\\top}/m,}\\\\ &{\\displaystyle b_{i,t-1}^{(0)}=\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot\\boldsymbol{r}_{\\tau}/\\sqrt{m},\\ \\ \\ \\ \\ \\ \\ \\ \\ b_{i,t-1}=\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot\\boldsymbol{r}_{\\tau}/\\sqrt{m}}\\\\ &{\\displaystyle\\tilde{b}_{i,t-1}^{(0)}=\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot\\tilde{r}_{\\tau}/\\sqrt{m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $\\{\\pmb{x}_{\\tau},r_{\\tau}\\},\\tau\\in[t]$ respectively stands for the chosen arms as well as their received rewards, While $\\{\\mathbf{\\boldsymbol{x}}_{\\tau},\\widetilde{r}_{\\tau}\\},\\tau\\in[t]$ refer to the imaginary corruption-free rewards. ", "page_idx": 33}, {"type": "text", "text": "We also recal tha wit the hosen armn $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ in round $t$ With arm weights $w_{t}^{(\\tau)},\\tau\\in[t\\!-\\!1]$ defined in (4), we will have a series of auxiliary gradient sequences $\\{\\pmb{\\theta}_{0},\\pmb{\\Theta}^{(1)},\\dots,\\pmb{\\Theta}^{(J)}\\}$ as in Lemma D.1, such that for $j$ -th, $j\\in[J]$ , iteration ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta^{(j+1)}=\\Theta^{(j)}-\\eta\\cdot\\bigg[\\mathbf{J}^{(0)}\\cdot\\mathbf{W}\\big([\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\theta_{0})-y\\big)+m\\lambda(\\Theta^{(j)}-\\theta_{0})\\bigg]}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where the diagonal weight matrix is made up with the arm weights, as $\\mathbf{W}=\\mathrm{diag}\\bigl([w_{t}^{(\\tau)}]_{\\tau\\in[t-1]}\\bigr)\\in$ $\\mathbb{R}^{(t-1)\\times(t-1)}$ milalwilllaqoar $\\begin{array}{r l}&{\\widetilde{\\Theta}^{(j+1)}=\\widetilde{\\Theta}^{(j)}-\\eta\\cdot\\Bigg[\\!\\!\\!\\int^{(0)}\\cdot\\mathbf{W}\\big([\\mathbf{J}^{(0)}]^{\\top}(\\widetilde{\\Theta}^{(j)}-\\theta_{0})\\!-\\!\\widetilde{\\boldsymbol{y}}\\big)+m\\lambda(\\widetilde{\\Theta}^{(j)}-\\theta_{0})\\!\\!\\Bigg],}\\\\ &{\\operatorname{matrix}\\mathbf{J}^{(0)}:=\\left(g(x_{1};\\theta_{0}),g(x_{2};\\theta_{0}),\\dots,g(x_{t-1};\\theta_{0})\\right)\\in\\mathbb{R}^{p\\times(t-1)}.\\ \\mathrm{Here}}\\end{array}$ we have $\\pmb{y},\\widetilde{\\pmb{y}}\\in\\mathbb{R}^{t-1}$ separately being the vector of received rewards and that of the imaginary corruption-free rewards. In particular, with $[\\mathbf{J}^{(0)}]_{\\tau}$ being the $\\tau$ -th column of matrix $\\mathbf{J}^{(0)}$ , the auxiliary sequence $\\Theta^{(j)}$ can be deemed as applying Gradient Descent to solve the following optimization problem ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\Theta}\\mathcal{L}(\\Theta)=\\sum_{\\tau\\in[t-1]}\\frac{1}{2}\\cdot w_{i,t}^{(\\tau)}\\bigg\\|[\\mathbf{J}^{(0)}]_{\\tau}^{\\top}(\\Theta-\\theta_{0})-y_{\\tau}\\bigg\\|_{2}^{2}+\\frac{1}{2}\\cdot m\\lambda\\bigg\\|\\Theta-\\theta_{0}\\bigg\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Consequently, we can follow an analogous approach as in Lemma D.1 with the above optimization problem, to bound the difference between gradient-based parameters and the auxiliary sequence. ", "page_idx": 33}, {"type": "text", "text": "C.7.1 Bounding the error term $I_{1}$ ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We bound the error term using Lemma C.7. Following the notation in the main body, let $\\pmb\\theta_{t-1}$ denote the trained parameters associated with the chosen arm $\\pmb{x}_{t}$ , and let $\\theta_{\\widetilde{i}_{t},t-1}$ represent the trained parameters of the arm $\\widetilde{\\pmb{x}}_{t}=\\pmb{x}_{\\widetilde{i}_{t},t},t\\in[T].$ which corresponds to the chosen arm of the hypothetical corruption-free model $f(\\cdot;\\widetilde{\\pmb\\theta})$ . Additionally, we define a weight-free gradient covariance matrix for the arm collection $\\{\\widetilde{x}_{\\tau}\\}_{\\tau\\in[t]}$ containing arms selected by the corruption-fre model, which will be denoted by $\\begin{array}{r}{\\Sigma_{t-1}^{\\prime}=\\lambda\\mathbf{I}+\\dot{\\sum}_{\\tau\\in[t-1]}g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\widetilde{i}_{\\tau},\\tau-1})g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\widetilde{i}_{\\tau},\\tau-1})^{\\tau}/m.}\\end{array}$ ", "page_idx": 33}, {"type": "text", "text": "Lemma C.7. Suppose the imaginary corruption-free neural network $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{i,t-1})$ for arm $x_{i,t}~\\in$ $\\mathbf{\\mathcal{X}}_{t}$ hasbeentrained oncorruption-freerewards $\\{\\boldsymbol{x}_{\\tau},\\boldsymbol{\\widetilde{r}}_{\\tau}\\}_{\\tau\\in[t-1]}$ whiletheothertrainednetwork $f(\\cdot;\\pmb{\\theta}_{i,t-1})$ is trained on thereceivedrecords $\\{\\pmb{x}_{\\tau},r_{\\tau}\\}_{\\tau\\in[t-1]}$ :Suppose $f(\\cdot)$ is an $L$ -layer $F C$ network with width m that satisfies the conditions in Theorem 5.6. Then, for the arms $\\pmb{x}_{t},\\widetilde{\\pmb{x}}_{t}\\in\\mathcal{X}_{t}$ withtheprobabilityatleast $1-\\delta$ wewillhave ", "page_idx": 33}, {"type": "text", "text": "", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{1}=\\bigg|\\langle g(\\widetilde{\\mathbf x}_{t};\\theta_{\\widetilde{t}_{t},t-1}),\\ \\theta_{\\widetilde{t}_{t},t-1}-\\widetilde{\\theta}_{\\widetilde{t}_{t},t-1}\\rangle\\bigg|}\\\\ &{\\quad\\leq\\mathcal{O}(\\alpha C)\\cdot\\bigg\\|g({\\mathbf x}_{t};\\theta_{t-1})/\\sqrt{m}\\bigg\\|_{(\\overline{{\\Sigma}}_{t-1})^{-1}}^{2}+\\mathcal{O}(\\sqrt{\\lambda}S)\\cdot\\bigg\\|g(\\widetilde{\\mathbf x}_{t};\\theta_{\\widetilde{t}_{t},t-1})/\\sqrt{m}\\bigg\\|_{(\\mathbf{Sigma}_{t-1}^{\\prime})^{-1}}}\\\\ &{\\qquad+\\mathcal{O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{5})}\\\\ &{\\qquad\\quad\\quad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where $\\pmb\\theta_{t-1}$ are the parameters associated to chosen arm $\\pmb{x}_{t}$ and $\\theta_{\\widetilde{i}_{t},t-1}$ are those parameters of arm $\\widetilde{\\mathbf{x}}_{t}$ . The gradient matrx is defined as $\\begin{array}{r}{\\Sigma_{t-1}^{\\prime}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\widetilde{i}_{\\tau},\\tau-1})g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\widetilde{i}_{\\tau},\\tau-1})^{\\intercal}/m}\\end{array}$ \uff0c and we also have $\\begin{array}{r}{\\bar{\\Sigma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\tau}/m}\\end{array}$ ", "page_idx": 34}, {"type": "text", "text": "Proof. Since the only difference between term $I_{1}$ and term $I_{2}$ is the gradients w.r.t. different arms, we begin with term $I_{1}\\,=\\,\\langle g(\\widetilde{\\pmb{x}}_{t};\\pmb{\\theta}_{t-1})$ $\\widetilde{\\pmb{\\theta}}_{t-1}-\\pmb{\\theta}_{t-1}\\rangle$ , and the results can be readily generalized to term $I_{2}$ . Here, recall that we have $\\lVert\\pmb{\\theta}^{*}-\\widetilde{\\pmb{\\theta}}_{t}\\rVert_{\\widetilde{\\pmb{\\Sigma}}_{t-1}}\\leq\\widetilde{\\gamma}_{t}/\\sqrt{m}$ based on Lemma C.10, as well as $\\|\\pmb{\\theta}_{t}-\\pmb{\\theta}_{0}\\|_{2},\\|\\widetilde{\\pmb{\\theta}}_{t}-\\pmb{\\theta}_{0}\\|_{2}\\leq\\mathcal{O}(\\sqrt{t/m\\lambda})$ based on lemma G.3. ", "page_idx": 34}, {"type": "text", "text": "Simplifying the notation. For the following proof, for the sake of notation simplicity, we directly use (), @(J) to respectively represent it,t-1, @ $\\widetilde{\\Theta}_{\\widetilde{i}_{t},t-1}^{(J)},\\Theta_{\\widetilde{i}_{t},t-1}^{(J)}$ - which ae the gradient desent based parameters associated with the arm $\\widetilde{\\pmb{x}}_{t}$ On thatn $\\widetilde{\\pmb{x}}_{t}=\\pmb{x}_{\\widetilde{i}_{t},t}$ we use $\\theta_{\\widetilde{i}_{t}},\\Sigma_{\\widetilde{i}_{t}}$ and $b_{\\tilde{i}_{t}}$ to separately represent $\\theta_{\\widetilde{i}_{t},t-1},\\Sigma_{\\widetilde{i}_{t},t-1}$ and $b_{\\tilde{i}_{t},t-1}$ by omitted the subscript of time step $t-1$ to simplify the notation. ", "page_idx": 34}, {"type": "text", "text": "Afterwards, it can further lead to ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{1}=\\left|\\langle g(\\widetilde{\\mathbf x}_{t};\\theta_{\\widetilde{i}_{t}}),\\mathbf\\Delta\\theta_{\\widetilde{i}_{t}}-\\widetilde{\\theta}_{\\widetilde{i}_{t}}\\rangle\\right|}\\\\ &{\\quad\\le\\left|\\langle g(\\widetilde{\\mathbf x}_{t};\\theta_{\\widetilde{i}_{t}}),\\mathbf\\Delta\\theta_{\\widetilde{i}_{t}}-\\Theta^{(J)}\\rangle\\right|+\\left|\\langle g(\\widetilde{\\mathbf x}_{t};\\theta_{\\widetilde{i}_{t}}),\\widetilde{\\mathbf\\Theta}^{(J)}-\\widetilde{\\theta}_{\\widetilde{i}_{t}}\\rangle\\right|+\\underbrace{\\left|\\langle g(\\widetilde{\\mathbf x}_{t};\\theta_{\\widetilde{i}_{t}}),\\widetilde{\\mathbf\\Theta}^{(J)}-\\mathbf{\\Theta}^{(J)}\\rangle\\right|}_{I_{1,1}}}\\\\ &{\\quad\\le\\mathcal{O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+\\underbrace{\\left|\\langle g(\\widetilde{\\mathbf x}_{t};\\theta_{\\widetilde{i}_{t}}),\\mathbf\\Delta\\Theta^{(J)}-\\widetilde{\\Theta}^{(J)}\\rangle\\right|}_{I_{1,1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where the first inequality is due to triangular inequality, and the last inequality is by applying Lemma C.4 in [86], with the optimization problem being (C.12) which bounds the difference between gradient-based parameters and the auxiliary sequence. Here, term $I_{1.1}$ measures the distance between the auxiliary sequence trained with corrupted records, and that trained by imaginary corruption-free records. ", "page_idx": 34}, {"type": "text", "text": "Next, recall that with randomly initialized network parameters $\\pmb{\\theta}_{0}$ , we can formulate the least square parameters as $(\\Sigma_{\\tilde{i}_{t}}^{(0)})^{-1}b_{\\tilde{i}_{t}}^{(0)}/\\sqrt{m}$ Whil theleast sguare parameters rainedby corupton-free rewards are analogously denoted by $(\\Sigma_{\\tilde{i}_{t}}^{(0)})^{-1}\\widetilde{b}_{\\tilde{i}_{t}}^{(0)}/\\sqrt{m}$ In this case,the term $I_{1.1}$ can be alternatively transformed to ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{1,1}=\\left|\\left\\langle g(\\tilde{x}_{t};\\theta_{\\tilde{i}_{t}}),\\Theta^{(J)}-\\widetilde{\\Theta}^{(J)}\\right\\rangle\\right|}\\\\ &{\\quad\\quad\\leq\\left|\\left\\langle g(\\tilde{x}_{t};\\theta_{\\tilde{i}_{t}}),\\ (\\Theta^{(J)}-\\theta_{0}-(\\Sigma_{\\tilde{i}_{t}}^{(0)})^{-1}b_{\\tilde{i}_{t}}^{(0)}/\\sqrt{m})-(\\widetilde{\\Theta}^{(J)}-\\theta_{0}-(\\Sigma_{\\tilde{i}_{t}}^{(0)})^{-1}b_{\\tilde{i}_{t}}^{(0)}/\\sqrt{m})\\right\\rangle\\right|}\\\\ &{\\quad\\quad\\leq\\left|\\left\\langle g(\\tilde{x}_{t};\\theta_{\\tilde{i}_{t}}),\\ \\Theta^{(J)}-\\theta_{0}-(\\Sigma_{\\tilde{i}_{t}}^{(0)})^{-1}b_{\\tilde{i}_{t}}^{(0)}/\\sqrt{m}\\right\\rangle\\right|}\\\\ &{\\quad\\quad\\quad\\quad\\quad+\\left|\\left\\langle g(\\tilde{x}_{t};\\theta_{\\tilde{i}_{t}}),\\ \\widetilde{\\Theta}^{(J)}-\\theta_{0}-(\\Sigma_{\\tilde{i}_{t}}^{(0)})^{-1}b_{\\tilde{i}_{t}}^{(0)}/\\sqrt{m}\\right\\rangle\\right|}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "which further leads to ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{1.1}\\leq\\left|\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{i}_{t}}),\\mathbf{\\Delta}\\Theta^{(J)}-\\theta_{0}-(\\Sigma_{\\widetilde{i}_{t}}^{(0)})^{-1}b_{\\widetilde{i}_{t}}^{(0)}/\\sqrt{m}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad+\\left|\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{i}_{t}}),\\mathbf{\\Delta}\\widetilde{\\Theta}^{(J)}-\\theta_{0}-(\\Sigma_{\\widetilde{i}_{t}}^{(0)})^{-1}\\widetilde{b}_{\\widetilde{i}_{t}}^{(0)}/\\sqrt{m}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad+\\underbrace{\\left|\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{i}_{t}}),\\mathbf{\\Delta}(\\Sigma_{\\widetilde{i}_{t}}^{(0)})^{-1}(\\sum_{\\tau\\in[t-1]}w_{\\widetilde{i}_{t},t}^{(\\tau)}\\cdot g(\\mathbf{x}_{\\tau};\\theta_{0})\\cdot c_{\\tau})/m\\right\\rangle\\right|}_{I_{1.2}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the inequality is due to the definition of gradient-based regression parameters and triangular inequality. It is obvious that for the third term on the RHS, the only thing we have control on is $\\theta_{\\tilde{i}_{t}}$ . When trying to bound the first two terms on the RHS for the arm $\\widetilde{\\pmb{x}}_{t}$ , we can first apply Holder's inequality with $\\begin{array}{r}{\\Sigma_{t-1}^{\\prime}\\,=\\,\\lambda{\\bf I}+\\sum_{\\tau\\in[t-1]}g(\\widetilde{\\bf x}_{\\tau};\\pmb{\\theta}_{\\widetilde{i}_{\\tau},\\tau-1})g(\\widetilde{\\bf x}_{\\tau};\\pmb{\\theta}_{\\widetilde{i}_{\\tau},\\tau-1})^{\\top}/m}\\end{array}$ . Note that for the purpose of analysis and different from previous ones defined in (C.11), the new matrix $\\left(\\pmb{\\Sigma}_{t-1}^{\\prime}\\right)$ contains gradients of the sequence of arms $\\{\\widetilde{x}_{\\tau}\\}_{\\tau\\in[t-1]}$ chosen by the corruption-free model $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{\\tau-1}),\\tau\\in[t-1]$ , with the parameters $\\widetilde{\\pmb{\\theta}}_{\\tau-1},\\tau\\in[t-1]$ ", "page_idx": 35}, {"type": "text", "text": "In this case, we use the Holder's inequality to the first term on the RHS of (C.17) as ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\biggl\\langle g(\\Tilde{\\pi}_{i};\\theta_{i}),\\ \\Theta^{(J)}-\\theta_{0}-(\\Sigma_{i}^{(0)})^{-1}b_{i}^{(0)}/\\sqrt{m}\\biggr\\rangle}\\\\ &{\\qquad\\qquad\\leq\\left\\lVert g(\\Tilde{\\pi}_{i};\\theta_{i})/\\sqrt{m}\\right\\rVert_{(\\Sigma_{i-1}^{\\prime})^{-1}}\\cdot\\sqrt{m}\\cdot\\left\\lVert\\Theta^{(J)}-\\theta_{0}-(\\Sigma_{i}^{(0)})^{-1}b_{i}^{(0)}/\\sqrt{m}\\right\\rVert_{(\\Sigma_{i-1}^{\\prime})}}\\\\ &{\\qquad\\quad\\leq\\left\\lVert g(\\Tilde{\\pi}_{i};\\theta_{i})/\\sqrt{m}\\right\\rVert_{(\\Sigma_{i-1}^{\\prime})^{-1}}\\cdot\\sqrt{m}\\cdot\\left\\lVert\\Theta^{(J)}-\\theta_{0}-(\\Sigma_{i}^{(0)})^{-1}b_{i}^{(0)}/\\sqrt{m}\\right\\rVert_{2}\\cdot\\left\\lVert(\\Sigma_{i-1}^{\\prime})\\right\\rVert_{2}}\\\\ &{\\qquad\\quad\\leq\\left\\lVert g(\\Tilde{\\pi}_{i};\\theta_{i})/\\sqrt{m}\\right\\rVert_{(\\Sigma_{i-1}^{\\prime})^{-1}}\\cdot O(\\lambda+t L)\\cdot\\left\\lVert\\sqrt{m}(\\Theta^{(J)}-\\theta_{0})-(\\Sigma_{i}^{(0)})^{-1}b_{i}^{(0)}\\right\\rVert_{2}}\\\\ &{\\qquad\\quad\\leq\\left\\lVert g(\\Tilde{\\pi}_{i};\\theta_{i})/\\sqrt{m}\\right\\rVert_{(\\Sigma_{i-1}^{\\prime})^{-1}}\\cdot O(\\sqrt{\\lambda+t L})}\\\\ &{\\qquad\\qquad\\qquad\\cdot O\\biggl((1-\\eta m\\lambda)^{J/2}\\sqrt{t/\\lambda}+m^{-1/6}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda})\\biggr)}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left\\lVert g(\\Tilde{\\pi}_{i};\\theta_{i})/\\sqrt{m}\\right\\rVert_{(\\Sigma_{i-1}^{\\prime})^{-1}}\\cdot O(\\sqrt{\\lambda}S)}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where the first two inequalities are by the Holder's inequality and Cauchy-Schwartz inequality. The third inequality is by Lemma G.6. The fourth inequality is by applying Lemma D.1, with the optimization problem being (C.12) bounding the difference between gradient-based parameters and the auxiliary sequence. Finally, with $w_{t}\\leq1$ and the conditions in Theorem 5.6, applying the conclusion from Remark 4.7 in [86] will give the last inequality. Following a similar approach can also lead to the identical upper bound for the second term on the RHS of (C.17). ", "page_idx": 35}, {"type": "text", "text": "Bounding Term $I_{1.2}$ Based on Arm Weights. Next, we proceed to bound term $I_{1.2}$ . Recall that we need to derive the upper bound for the following term ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|I_{1,2}=\\left|\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{t}_{i}}),\\mathbf{\\Phi}(\\mathbf{\\Sigma}_{\\widetilde{t}_{i}}^{(0)})^{-1}(\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\mathbf{x}_{\\tau};\\theta_{0})\\cdot\\mathbf{c}_{\\tau})/m\\right\\rangle\\right|}\\\\ &{\\quad\\leq\\bigg|\\displaystyle\\sum_{\\tau\\in[t-1]}\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{t}_{i}}),\\mathbf{\\Phi}(\\mathbf{\\Sigma}_{\\widetilde{t}_{i}}^{(0)})^{-1}\\cdot w_{i,t}^{(\\tau)}\\cdot g(\\mathbf{x}_{\\tau};\\theta_{0})\\cdot\\mathbf{c}_{\\tau}/m\\right\\rangle\\bigg|}\\\\ &{\\quad\\leq\\bigg|\\displaystyle\\sum_{\\tau\\in[t-1]}\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{t}_{i}}),\\mathbf{\\Phi}_{w_{\\widetilde{t}_{i},t}^{(\\tau)}}^{(0)}\\cdot(\\mathbf{\\Sigma}_{\\widetilde{t}_{i}}^{(0)})^{-1}g(\\mathbf{x}_{\\tau};\\theta_{\\tau-1})c_{\\tau}/m\\right\\rangle\\bigg|}\\\\ &{\\qquad\\qquad+\\left|\\displaystyle\\sum_{\\tau\\in[t-1]}\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{t}_{i}}),\\mathbf{\\Phi}_{w_{\\widetilde{t}_{i},t}^{(\\tau)}}^{(0)}\\cdot(\\mathbf{\\Sigma}_{\\widetilde{t}_{i}}^{(0)})^{-1}(g(\\mathbf{x}_{\\tau};\\theta_{0})-g(\\mathbf{x}_{\\tau};\\theta_{\\tau-1}))c_{\\tau}/m\\right\\rangle\\right|}\\\\ &{\\quad\\leq\\left|\\displaystyle\\sum_{\\tau\\in[t-1]}\\left\\langle g(\\widetilde{\\mathbf{x}}_{t};\\theta_{\\widetilde{t}_{i}}),\\mathbf{\\Phi}_{w_{\\widetilde{t}_{i},t}^{(\\tau)}}^{(0)}\\cdot(\\mathbf{\\Sigma}_{\\widetilde{t}_{i}}^{(0)})^{-1}g(\\mathbf{x}_{\\tau};\\theta_{\\tau-1})\\cdot c_{\\tau}/m\\right\\rangle\\right|+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{ \n$$", "text_format": "latex", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\leq\\bigg|\\sum_{\\tau\\in[t-1]}\\bigg\\langle g(\\widetilde{x}_{t};\\theta_{\\widetilde{t}_{t}}),\\ w_{\\widetilde{t}_{t},t}^{(\\tau)}\\cdot(\\mathbf{{S}}_{\\widetilde{t}_{t}})^{-1}g(x_{\\tau};\\theta_{\\tau-1})\\cdot c_{\\tau}/m\\bigg\\rangle\\bigg|+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}I}\\\\ &{\\qquad+\\bigg|\\sum_{\\tau\\in[t-1]}\\bigg\\langle g(\\widetilde{x}_{t};\\theta_{\\widetilde{t}_{t}}),\\ w_{\\widetilde{t}_{t},t}^{(\\tau)}\\cdot((\\mathbf{{S}}_{\\widetilde{t}_{t}}^{(0)})^{-1}-(\\mathbf{{S}}_{\\widetilde{t}_{t}}^{-})^{-1})g(x_{\\tau};\\theta_{\\tau-1})\\cdot c_{\\tau}/m\\bigg\\rangle\\bigg|}\\\\ &{\\leq\\bigg|\\underbrace{\\sum_{\\tau\\in[t-1]}\\bigg\\langle g(\\widetilde{x}_{t};\\theta_{\\widetilde{t}_{t}}),\\ w_{\\widetilde{t}_{t},t}^{(\\tau)}\\cdot(\\mathbf{{S}}_{\\widetilde{t}_{t}})^{-1}g(x_{\\tau};\\theta_{\\tau-1})\\cdot c_{\\tau}/m\\bigg\\rangle}_{I_{1},3}\\bigg|+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-7/6}L^{4}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the second and fourth inequality is due to triangular inequality. The third inequality is by Lemma G.4, and the last inequality is due to Lemma G.6. ", "page_idx": 36}, {"type": "text", "text": "In particular, we aim to train separate neural models $f(\\cdot;\\pmb\\theta_{i,t})$ for each candidate arm $\\mathbf{\\boldsymbol{x}}_{i,t}\\ \\in$ $\\mathbf{\\mathcal{X}}_{t}$ , such that the term $I_{1.2}$ can be  minimized. Recall that  we  denote $\\begin{array}{r l r}{\\bar{\\Sigma}_{t-1}}&{{}=}&{\\lambda{\\bf I}\\;+}\\end{array}$ $\\begin{array}{r}{\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m}\\end{array}$ as the \"vanilla gradient covariance matrix without the arm weights, in terms of the potentially corrupted network parameters $\\theta_{\\tau-1}$ ", "page_idx": 36}, {"type": "text", "text": "In this case, with $w_{\\tilde{i}_{t},t}^{(\\tau)}$ referring to the weight of arm $\\widetilde{\\pmb{x}}_{t}$ , the above formulation of term $I_{1.3}$ canbe further transformed into ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{I_{13}\\leq\\bigg|\\sum_{\\varrho\\in[\\varrho-1]}\\frac{w_{\\varrho}^{(\\varrho)}(\\varrho-\\varrho_{\\star})}{n}\\cdot\\bigg\\langle\\varrho(\\widetilde{\\pi};\\theta_{i}),(\\nabla_{\\xi_{i}})\\cdot^{-1}\\boldsymbol{g}(\\boldsymbol{x};\\theta_{r-1})\\bigg\\rangle\\bigg|}&{}\\\\ {\\leq\\bigg|\\sum_{\\varrho\\in[\\varrho-1]}w_{\\varrho}^{(\\varrho)}\\cdot\\varrho_{\\star}\\cdot\\bigg\\|\\left(\\nabla(\\widetilde{\\pi};\\theta_{i})\\right)/\\sqrt{n}\\bigg|\\underbrace{\\ldots}_{\\mathcal{N}_{i_{1}}}\\cdot\\bigg\\|\\left(\\boldsymbol{\\Sigma}_{i_{\\xi}}\\right)^{-1}\\cdot\\boldsymbol{g}(\\boldsymbol{x}_{r};\\theta_{r-1})/\\sqrt{n}\\bigg|\\underbrace{\\biggr\\|_{\\mathcal{D}_{\\xi_{i}}}}_{\\leq_{r}}}\\\\ {\\leq\\bigg|\\sum_{\\varrho\\in[\\varrho-1]}w_{\\varrho}^{(\\varrho)}\\cdot\\varrho_{\\star}\\cdot\\bigg\\|\\left(\\overline{{\\pi}}(\\widetilde{\\pi};\\theta_{i})\\right)/\\sqrt{n}\\bigg|\\underbrace{\\ldots}_{\\mathcal{N}_{i_{1}}}\\cdot\\bigg\\|\\left(\\boldsymbol{\\mu}(\\boldsymbol{x};\\theta_{r-1})/\\sqrt{n}\\right)\\bigg|\\underbrace{\\biggr\\|_{\\mathcal{D}_{\\xi_{i}}}}_{\\leq_{r}}-\\bigg|\\left\\|\\left(\\boldsymbol{\\Sigma}_{i_{\\xi}}\\right)^{-1}\\cdot\\boldsymbol{g}(\\boldsymbol{x}_{r};\\theta_{r-1})/\\sqrt{n}\\right\\|\\underbrace{\\biggr\\|_{\\mathcal{D}_{\\xi_{i}}}}_{\\leq_{r}}-\\bigg|}\\\\ {\\leq\\bigg|\\sum_{\\varrho\\in[\\varrho-1]}w_{\\varrho}^{(\\varrho)}\\cdot\\varrho_{\\star}\\cdot\\bigg\\|\\left(\\overline{{\\pi}}(\\widetilde{\\pi};\\theta_{i})\\right)/\\sqrt{n}\\bigg|\\underbrace{\\ldots}_{\\mathcal{N}_{i_{1}}}\\cdot\\bigg|\\left\\|\\left(\\boldsymbol{\\mu}(\\boldsymbol{x}_{r};\\theta_{r-1})/\\sqrt{n}\\right)\\right\\|_{(\\Omega_{i}^{\\varrho},\\theta_{r-1})}\\cdot\\bigg|}\\\\ {\\leq\\alpha C\\cdot\\underbrace{\\log1}_{\\leq\\epsilon}\\bigg|\\left\\|\\left(\\boldsymbol{\\mu}(\\boldsymbol{x};\\theta_{r}-1)/\\sqrt{n}\\right)\\right\\|_{ \n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where the first inequality follows from applying Holder's inequality, and the second and third inegualitiesare obtainedby using LemaG.8 along withthe faethat $\\begin{array}{r}{\\Sigma_{\\tilde{i}_{t}}\\geq\\bar{\\Sigma}_{t-1}^{(\\kappa)}\\succeq\\bar{\\Sigma}_{\\tau-1}^{(\\kappa)}}\\end{array}$ by definition. The last two inequalities are derived from the definition of the arm weight $w_{\\tilde{i}_{t},t}^{(\\tau)}$ and the corruption level $\\begin{array}{r}{C=\\sum_{t\\in[T]}|c_{t}|}\\end{array}$ . Recall that for ach arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , we define its weight as $\\begin{array}{r}{w_{i,t}^{(\\tau)}=\\operatorname*{min}\\left\\{1,\\;\\frac{{\\alpha}\\cdot\\operatorname*{min}_{x\\in\\mathcal{X}_{t}}{\\|g(\\pmb{x};\\pmb{\\theta}_{t-1}^{\\star})/\\sqrt{m}\\|_{\\bar{\\Sigma}_{t-1}^{-1}}^{2}}}{{g_{\\tau}}\\cdot\\|g(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{(\\pmb{\\Sigma}_{t-1}^{(\\kappa)})^{-1}}}\\right\\}.}\\end{array}$ where $\\alpha>0$ is the tunable parameter. As a result, we will have the upper bound for $I_{1.2}$ , being ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{1.2}\\leq\\mathcal{O}(\\alpha C)\\cdot\\bigg\\|g({x_{t}};\\theta_{t-1})/\\sqrt{m}\\bigg\\|_{(\\bar{\\Sigma}_{t-1})^{-1}}^{2}+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{5})}\\\\ &{\\qquad\\qquad+\\ \\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4})}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "In this case, since the weights are lower bounded by $\\kappa^{2}$ , the only way to ensure this is by adjusting the tunable parameter $\\alpha>0$ accordingly. We remind that this does not require the learner to have a global view of the minimum fraction value $\\beta$ . In practice, the learner can adjust the $\\alpha$ values in each roundonsuretat theround-wsemnimweight vale $w_{t}^{\\mathsf{m i n}}=\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K]}=\\kappa^{2}<1$ for all $t\\in[T]$ and $\\tau\\in[t-1]$ , by tuning the parameter $\\alpha$ . By summing up all the results, we obtain the single-round bound for term $I_{1}$ , which leads to ", "page_idx": 36}, {"type": "text", "text": "", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{1}\\leq\\mathcal{O}(\\alpha C)\\cdot\\left\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\overline{{\\Sigma}}_{t-1})^{-1}}^{2}+\\mathcal{O}(\\sqrt{\\lambda}S)\\cdot\\left\\|g(\\widetilde{{\\pmb x}}_{t};{\\pmb\\theta}_{\\widetilde{i}_{t},t-1})/\\sqrt{m}\\right\\|_{(\\mathbf{\\Sigma}_{t-1}^{\\prime})^{-1}}}\\\\ &{\\qquad+\\mathcal{O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{5})}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "C.7.2  Bounding the error term $I_{2}$ ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Similarly, for the term $I_{2}$ related to the chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ , we can follow the below procedure to obtain a comparable bound as for term $I_{1}$ ", "page_idx": 37}, {"type": "text", "text": "Corollary C.8. Suppose the imaginary corruption-free neural network $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{i,t-1})$ for arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ has been trained on corruption-free rewards $\\{\\pmb{x}_{\\tau},\\widetilde{r}_{\\tau}\\}_{\\tau\\in[t-1]}.\\ f.$ $f(\\cdot)$ is an $L$ -layer $F C$ network with width m that satisfy the conditions in Theorem 5.6. Then, for the chosen arm $\\pmb{x}_{t}\\,\\in\\,\\mathcal{X}_{t}$ ,with the probabilityatleast $1-\\delta$ ,we will have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{2}\\le\\mathcal{O}(\\alpha C)\\cdot\\left\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\overline{{\\Sigma}}_{t-1})^{-1}}^{2}+\\mathcal{O}(\\sqrt{\\lambda}S)\\cdot\\left\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\overline{{\\Sigma}}_{t-1})^{-1}}}\\\\ &{\\qquad+\\mathcal{O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{5})}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where $\\pmb\\theta_{t-1}$ are the trained parameters associated to chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ in round $t$ and $\\theta_{\\widetilde{i}_{t},t-1}$ are the trained parameters of arm $\\widetilde{\\pmb{x}}_{t}$ , along with the corresponding weight-free gradient covariance matrix $\\begin{array}{r}{\\bar{\\Sigma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\bar{\\tau}}/m.}\\end{array}$ ", "page_idx": 37}, {"type": "text", "text": "Proof. The proof of this corollary follows an analogous procedure as in Lemma C.7. ", "page_idx": 37}, {"type": "text", "text": "Simplifying the notation. For notation simplicity, we apply  and $\\Theta^{(J)}$ to represent the gradient descent-based parameters associated with the arm $\\pmb{x}_{t}$ . For terms specific to the arm $\\pmb{x}_{t}=\\pmb{x}_{i_{t},t}$ ,we simplify notation by using $\\pmb\\theta_{t-1}$ \uff0c $\\Sigma_{t-1}$ , and $b_{t-1}$ to denote $\\theta_{i_{t},t-1},\\Sigma_{i_{t},t-1}.$ and $b_{i_{t},t-1}$ , respectively. Then, with the simplified notation, it leads to ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{2}=\\bigg\\vert\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\theta_{t-1}-\\widetilde{\\theta}_{t-1}\\rangle\\bigg\\vert}\\\\ &{\\quad\\le\\bigg\\vert\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\theta_{t-1}-\\Theta^{(J)}\\rangle\\bigg\\vert+\\bigg\\vert\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\widetilde{\\Theta}^{(J)}-\\widetilde{\\theta}_{t-1}\\rangle\\bigg\\vert+\\underbrace{\\Big\\vert\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\widetilde{\\Theta}^{(J)}-\\Theta^{(J)}\\rangle\\Big\\vert}_{I_{2,1}}}\\\\ &{\\quad\\le\\mathcal{O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+\\underbrace{\\Big\\vert\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\Theta^{(J)}-\\widetilde{\\Theta}^{(J)}\\rangle\\Big\\vert}_{I_{2,1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where the first inequality is due to triangular inequality, and the last inequality is by applying Lemma C.4 in [86], with the optimization problem being (C.12) bounding the difference between gradient-based parameters and the auxiliary sequence. ", "page_idx": 37}, {"type": "text", "text": "Next, recall that with randomly initialized network parameters $\\theta_{0}$ , we can formulate the least square parameters as $(\\Sigma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}$ , while the least square parameters trained by corruption-free ", "page_idx": 37}, {"type": "text", "text": "rewards are $(\\Sigma_{t-1}^{(0)})^{-1}\\widetilde{b}_{t-1}^{(0)}/\\sqrt{m}$ In this case, the term $I_{2,1}$ can be alternatively transformed to ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{2,1}=\\left|\\left\\langle g(x_{t};\\theta_{t-1}),~\\Theta^{(J)}-\\tilde{\\Theta}^{(J)}\\right\\rangle\\right|}\\\\ &{\\quad\\quad\\leq\\left|\\left\\langle g(x_{t};\\theta_{t-1}),~\\Theta^{(J)}-\\theta_{0}-(\\Sigma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\right\\rangle\\right|}\\\\ &{\\quad\\quad\\quad\\quad\\quad+\\left|\\left\\langle g(x_{t};\\theta_{t-1}),~\\widetilde{\\Theta}^{(J)}-\\theta_{0}-(\\Sigma_{t-1}^{(0)})^{-1}\\widehat{b}_{t-1}^{(0)}/\\sqrt{m}\\right\\rangle\\right|}\\\\ &{\\quad\\quad\\quad\\quad\\quad+\\left|\\left\\langle g(x_{t};\\theta_{t-1}),~(\\Sigma_{t-1}^{(0)})^{-1}(\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}g(x_{\\tau};\\theta_{0})\\cdot c_{\\tau})/m\\right\\rangle\\right|}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\tau\\in[t-1]}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the inequality is due to the definition of gradient-based regression parameters. ", "page_idx": 38}, {"type": "text", "text": "When trying to bound the first two terms on the RHS, we first apply Holder's inequality with $\\begin{array}{r}{\\bar{\\Sigma}_{t-1}=\\bar{\\lambda}\\mathbf{I}^{*}\\!+\\!\\sum_{\\tau\\in[t-1]}g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\tau-1})g(\\widetilde{\\pmb x}_{\\tau};\\pmb\\theta_{\\tau-1})^{\\intercal}/m}\\end{array}$ , and it further leadsto ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\langle g(\\pmb{x}_{t};\\theta_{t-1}),~\\Theta^{(J)}-\\theta_{0}-(\\pmb{\\Sigma}_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\right\\rangle}\\\\ &{\\qquad\\leq\\left\\|g(\\pmb{x}_{t};\\theta_{t-1})/\\sqrt{m}\\right\\|_{(\\Xi_{t-1})^{-1}}\\cdot\\sqrt{m}\\cdot\\left\\|\\Theta^{(J)}-\\theta_{0}-(\\pmb{\\Sigma}_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\right\\|_{(\\Xi_{t-1})}}\\\\ &{\\qquad\\leq\\left\\|g(\\pmb{x}_{t};\\theta_{t-1})/\\sqrt{m}\\right\\|_{(\\Xi_{t-1})^{-1}}\\cdot\\sqrt{m}\\cdot\\left\\|\\Theta^{(J)}-\\theta_{0}-(\\pmb{\\Sigma}_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\right\\|_{2}\\cdot\\left\\|(\\Xi_{t-1})\\right\\|_{2}}\\\\ &{\\qquad\\leq\\left\\|g(\\pmb{x}_{t};\\theta_{t-1})/\\sqrt{m}\\right\\|_{(\\Xi_{t-1})^{-1}}\\cdot O(\\lambda+t L)\\cdot\\left\\|\\sqrt{m}(\\Theta^{(J)}-\\theta_{0})-(\\pmb{\\Sigma}_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}\\right\\|_{2}}\\\\ &{\\qquad\\leq\\left\\|g(\\pmb{x}_{t};\\theta_{t-1})/\\sqrt{m}\\right\\|_{(\\Xi_{t-1})^{-1}}\\cdot O(\\sqrt{\\lambda+t L})}\\\\ &{\\qquad\\qquad\\qquad\\cdot O\\left((1-\\eta m\\lambda)^{J/2}\\sqrt{t/\\lambda}+m^{-1/6}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda})\\right)}\\\\ &{\\qquad\\qquad\\leq\\left\\|g(\\pmb{x}_{t};\\theta_{t-1})/\\sqrt{m}\\right\\|_{(\\Xi_{t-1})^{-1}}\\cdot O(\\sqrt{\\lambda}S)}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the first two inequalities is by Holder's inequality and Cauchy-Schwartz inequality. The third inequality is by Lemma G.6. The fourth inequality is by applying Lemma D.1, with the optimization problem being (C.12), in terms of the difference between gradient-based parameters and the auxiliary sequence. Finally, with $w_{t}\\leq1$ and the conditions in Theorem 5.6, applying the conclusion from Remark 4.7 in [86] will give the last inequality. Following a similar approach can also lead to the upper bound for the second term on the RHS of (C.19). ", "page_idx": 38}, {"type": "text", "text": "Bounding Term $I_{2,2}$ Based on Arm Weights. Next, we need to bound term $I_{2,2}$ . Recall that we want to have an upper bound for the following term ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{2,2}=\\left|\\left\\langle g(\\alpha;\\theta_{t},\\cdot),\\{\\Omega_{t-1}^{(0)}\\}^{-1}\\right\\rangle(\\sum_{\\ell=1}^{\\infty}g(\\alpha_{r};\\theta_{0})\\cdot c_{r})/m\\right\\rangle\\Bigg|}\\\\ &{\\quad\\leqslant\\bigg|\\sum_{r\\in[t-1]}\\left\\langle g(\\alpha;\\theta_{t-1}),\\ (\\Omega_{t-1}^{(0)})^{-1}g(\\alpha;\\theta_{r-1})\\cdot c_{r}/m\\right\\rangle\\bigg|+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/9}}\\\\ &{\\quad\\bigg|\\sum_{r\\in[t-1]}\\left\\langle g(\\alpha_{r};\\theta_{t-1}),\\ (\\Omega_{t-1})^{-1}g(\\alpha_{r};\\theta_{r-1})\\cdot c_{r}/m\\right\\rangle\\bigg|+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/9}}\\\\ &{\\qquad+\\bigg|\\sum_{r\\in[t-1]}\\left\\langle g(\\alpha;\\theta_{t-1}),\\ (\\Omega_{t-1}^{(0)})^{-1}-(\\Omega_{t-1})^{-1})g(\\alpha_{r};\\theta_{r-1})\\cdot c_{r}/m\\right\\rangle\\bigg|}\\\\ &{\\quad\\leqslant\\left|\\frac{\\mathcal{O}(\\alpha;\\theta_{t-1})}{r\\in[t-1]}\\left\\langle g(\\alpha_{r};\\theta_{t-1}),\\ (\\Omega_{t-1})^{-1}g(\\alpha_{r};\\theta_{r-1})\\cdot c_{r}/m\\right\\rangle\\right|+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6})}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the first inequality follows from applying the triangle inequality and Lemma G.4. The second inequality is also due to the triangle inequality, and the last inequality follows from Lemma G.6. In particular, we aim to train separate neural models $f(\\cdot;\\pmb\\theta_{i,t})$ for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ to minimize the term $I_{2,2}$ . Similarly,recall that $\\begin{array}{r}{\\bar{\\Sigma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\tau}/m}\\end{array}$ is the gradient covariance matrx without arm weights, and $w_{t}^{(\\tau)}$ is the weight of arm $\\pmb{x}_{t}$ , defined as $\\begin{array}{r}{w_{t}^{(\\tau)}=\\operatorname*{min}\\lbrace1,\\,\\,\\frac{\\alpha\\cdot\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{X}_{t}}\\,\\|g(\\pmb{x};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{\\bar{\\pmb{x}}_{t-1}^{-1}}^{2}}{g_{\\tau}\\cdot\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{(\\bar{\\pmb{x}}_{t-1}^{(\\kappa)})^{-1}}}\\rbrace}\\end{array}$ $\\alpha>0$ the derivation of term $I_{1.3}$ , it can further lead to ", "page_idx": 39}, {"type": "text", "text": "", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{2,3}\\leq\\bigg|\\displaystyle\\sum_{r\\in[t-1]}\\displaystyle\\sum_{n^{\\prime}\\in[t-1]}^{\\infty(r)^{+}\\cdot\\cdot\\cdot r_{\\sigma^{\\prime}}}\\cdot\\Big\\langle g(x_{t};\\theta_{t-1}),\\big(\\Sigma_{t-1}\\big)^{-1}\\cdot g(x_{t};\\theta_{\\tau-1})\\Big\\rangle\\bigg|}\\\\ &{\\qquad\\leq\\left|\\displaystyle\\sum_{r\\in[t-1]}w_{t}^{(r)}\\cdot c_{r^{\\prime}}\\cdot\\Big[g(x_{t};\\theta_{t-1})\\Big\\rangle\\sqrt{m}\\right|_{(\\Omega_{t-1})^{-1}}\\cdot\\left\\|\\Big(\\Sigma_{t-1}\\big)^{-1}\\cdot g(x_{\\tau};\\theta_{\\tau-1})/\\sqrt{m}\\right\\|_{\\Sigma_{t-1}}}\\\\ &{\\qquad\\leq\\bigg|\\displaystyle\\sum_{r\\in[t-1]}w_{t}^{(r)}\\cdot c_{r^{\\prime}}\\cdot\\Big[g(x_{t};\\theta_{t-1})\\Big\\rangle\\sqrt{m}\\Big|_{(\\Omega_{t-1})^{-1}}\\cdot\\left\\|g(x_{\\tau};\\theta_{\\tau-1})/\\sqrt{m}\\right\\|_{(\\Omega_{t-1})^{-1}}\\cdot\\bigg|}\\\\ &{\\qquad\\leq\\bigg|\\displaystyle\\sum_{r\\in[t-1]}w_{t}^{(r)}\\cdot c_{r^{\\prime}}\\cdot\\Big|g(x_{t};\\theta_{t-1})/\\sqrt{m}\\Big|_{(\\Omega_{t-1}^{(s)})^{-1}}\\cdot\\left\\|g(x_{\\tau};\\theta_{\\tau-1})/\\sqrt{m}\\right\\|_{(\\Omega_{t-1}^{(s)})^{-1}}\\bigg|}\\\\ &{\\qquad\\leq C\\cdot\\operatorname*{min}_{r\\in[t-1]}\\displaystyle\\Big|g(x;\\theta_{t-1})/\\sqrt{m}\\Big|\\displaystyle\\Big|_{(\\Omega_{t-1}^{(s)})^{-1}}^{2}}\\\\ &{\\qquad\\qquad\\leq C\\cdot\\left\\|g(x_{t};\\theta_{t-1})/\\sqrt{m}\\right\\|_{(\\Omega_{t-1})^{-1}}^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the first inequality is by applying the Holder's inequality, and the second and third inequalities arebyaplying LmaG8with te fct that $\\bar{\\Sigma}_{t-1}\\succeq\\bar{\\Sigma}_{t-1}^{\\left(\\kappa\\right)}\\succeq\\bar{\\Sigma}_{\\tau-1}^{\\left(\\kappa\\right)}$   \ninequalities are due to the defnition of arm weight $w_{t}^{(\\tau)}$ , as well as the definition of corruption level $\\begin{array}{r}{C=\\sum_{t\\in[T]}|c_{t}|}\\end{array}$ As aresult,by combining the upper bounds for the terms $I_{2,4}$ and $I_{2.5}$ , we obtain the following upper bound for $I_{2,2}$ ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r}{I_{2.2}\\leq\\mathcal{O}(\\alpha C)\\cdot\\bigg\\|g(x_{t};\\theta_{t-1})/\\sqrt{m}\\bigg\\|_{(\\bar{\\Sigma}_{t-1})^{-1}}^{2}+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{5})}\\\\ {+\\ \\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4}).\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "In this case, since we need to ensure that the minimum weight is $\\kappa^{2}$ , we scale the tunable parameter $\\alpha>0$ accordingly. Recall that this does not require the learner to have the prior knowledge of the minimum fraction value $\\beta$ , and the learner can adjust the $\\alpha$ values in each round to ensure that the round-wise minimum weight $w_{t}^{\\mathsf{m i n}}\\,=\\,\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K]}\\,<\\,1$ for all $t\\,\\in\\,[T]$ and $\\tau\\in[t-1]$ By summing up all the results, we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{2}\\le\\mathcal{O}(\\alpha C)\\cdot\\left\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\bar{\\Sigma}_{t-1})^{-1}}^{2}+\\mathcal{O}(\\sqrt{\\lambda}S)\\cdot\\left\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\bar{\\Sigma}_{t-1})^{-1}}}\\\\ &{\\qquad+\\mathcal{O}(m^{-2/3}\\log(m)L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/6}L^{5})}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{4}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "C.8 Deriving the UCB and confidence ellipsoid for corruption-free parameters and corrupted parameters ", "text_level": 1, "page_idx": 39}, {"type": "text", "text": "In this subsection, we provide upper bounds for $\\widetilde{\\mathsf{U C B}}_{t}({\\pmb x}_{t})$ in terms of the corruption-free parameters $\\widetilde{\\pmb{\\theta}}_{t-1}$ . Recall that without the arm index $i\\in[K]$ , the parameters $\\pmb{\\theta}$ , covariance matrix $\\Sigma_{t-1}$ \uff0c confidence ellipsoid $\\mathcal{C}_{t-1}$ , and weights $w_{t}$ pertain to the chosen arm $\\pmb{x}_{t}$ .For the hypothetical corruption-free parameters 0, trained with corruption-free rewards, Lemma C.9 provides the corresponding UCB result, and Lemma C.10 introduces the associated confidence ellipsoid. For the trained parameters $\\theta_{i,t-1}$ , based on the received records $\\mathcal{P}_{t-1}$ with potentially corrupted rewards, Lemma C.11 presents the corresponding UCB for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , while Lemma C.12 provides the corresponding confidence ellipsoid. Note that Lemmas C.11 and C.12 are used solely to motivate the design of our UCB-type exploration strategy and are not applied to derive the cumulative regret analysis result. ", "page_idx": 39}, {"type": "text", "text": "", "page_idx": 40}, {"type": "text", "text": "Lemma C.9. Suppose the imaginary neural network $f(\\cdot;\\widetilde{\\pmb{\\theta}}_{t-1})$ in round $t\\in[T]$ hasbeentrainedon corruption-free rewards $\\{\\mathbf{\\boldsymbol{x}}_{\\tau},\\widetilde{r}_{\\tau}\\}_{\\tau\\in[t-1]}$ and $f(\\cdot)$ is an $L$ -layer $F C$ network with width m. Suppose we have $m,J,\\eta$ satisfying the conditions in Theorem 5.6. Then, for the chosen arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ ,with the probabilityat least $1-\\delta$ wewill have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{J C B}_{t}(x_{t})=\\widetilde{V}(x_{t})-h(x_{t})\\leq2\\widetilde{\\gamma}_{t-1}\\cdot\\|g(x_{t};\\widetilde{\\theta}_{t-1})/\\sqrt{m}\\|_{\\widetilde{\\Sigma}_{t-1}^{-1}}+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{2/7}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "and the corresponding summation value across $T$ roundswill be ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\in[T]}\\operatorname*{min}\\left\\{\\widetilde{U C B}_{t}(x_{t}),1\\right\\}=\\displaystyle\\sum_{t\\in[T]}\\operatorname*{min}\\left\\{\\widetilde{V}(\\pmb{x}_{t})-h(\\pmb{x}_{t}),1\\right\\}}\\\\ &{\\qquad\\quad\\leq\\displaystyle\\frac{1}{\\sqrt{w_{t}^{m i n}}}\\mathcal{O}\\left(\\nu\\sqrt{\\log\\frac{\\mathrm{det}(\\widetilde{\\Sigma}_{T})}{\\mathrm{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\right)\\cdot\\sqrt{2T\\cdot\\log\\frac{\\mathrm{det}(\\widetilde{\\Sigma}_{T})}{\\mathrm{det}(\\lambda\\mathbf{I})}}}\\\\ &{\\qquad\\qquad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}T^{7/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}T^{7/6}\\lambda^{-7/6}L^{2/7}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "By definitions in Lemma C.10, we have the corresponding radius term for confidence ellipsoid $\\widetilde{\\mathcal{C}}_{t-1}$ $\\begin{array}{r l}&{\\colon_{S}\\widetilde{\\gamma}_{t-1}\\,=\\,\\mathcal{O}\\biggl(\\nu\\cdot\\sqrt{\\log\\frac{\\operatorname*{det}(\\widetilde{\\Sigma}_{t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\biggr),}\\\\ &{\\check{\\Sigma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}\\cdot g({\\boldsymbol x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})g({\\boldsymbol x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})^{\\intercal}/n}\\end{array}$ and the gradient covariance matrix as ", "page_idx": 40}, {"type": "text", "text": "Proof. With the confidence ellipsoid around the corruption-free parameters $\\widetilde{\\mathcal{C}}_{t-1}:=\\{\\pmb{\\theta}:\\|\\pmb{\\theta}-\\$ $\\widetilde{\\theta}_{t-1}\\Vert_{\\widetilde{\\Sigma}_{t-1}}\\leq\\widetilde{\\gamma}_{t-1}/\\sqrt{m},\\widetilde{\\gamma}_{t-1}>0\\}$ wehave $\\pmb{\\theta}^{*}\\in\\widetilde{\\mathcal{C}}_{t-1}$ according to Lemma C.10. In this case, Wwih te coeficient $\\begin{array}{r}{\\widetilde\\gamma_{t-1}=\\mathcal{O}\\big(\\nu\\cdot\\sqrt{\\log\\frac{\\operatorname*{det}(\\widetilde\\Sigma_{t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\big)}\\end{array}$ and the gradient covariance matrix $\\begin{array}{r}{\\widetilde\\Sigma_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})g(\\pmb{x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})^{\\top}/m,}\\end{array}$ we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{10\\mathrm{CB}_{t}(x_{t})=\\tilde{V}(x_{t})-h(x_{t})}}\\\\ &{=\\operatorname*{max}_{\\theta\\in\\tilde{C}_{t-1}}\\langle\\varphi(x_{t};\\theta_{0}),\\theta-\\theta_{0}\\rangle-\\langle g(x_{t};\\theta_{0}),\\theta^{*}-\\theta_{0}\\rangle}\\\\ &{\\leq\\operatorname*{max}_{\\theta\\in\\tilde{C}_{t-1}}\\langle g(x_{t};\\tilde{\\theta}_{0}),\\theta-\\tilde{\\theta}_{t-1}\\rangle-\\langle g(x_{t};\\tilde{\\theta}_{t-1}),\\ \\theta^{*}-\\tilde{\\theta}_{t-1}\\rangle}\\\\ &{\\quad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})}\\\\ &{\\leq\\operatorname*{max}_{\\theta\\in\\tilde{C}_{t-1}}\\|\\theta-\\tilde{\\theta}_{t-1}\\|\\frac{\\tilde{\\psi}(x_{t};\\tilde{\\theta}_{0})}{\\tilde{\\theta}_{t-1}}\\|\\frac{\\tilde{\\psi}(x_{t-1})}{\\tilde{\\theta}_{t-1}}+\\|g(x_{t};\\tilde{\\theta}_{t-1})\\|\\frac{\\tilde{\\psi}_{t-1}}{\\tilde{\\theta}_{t-1}}\\|\\theta^{*}-\\tilde{\\theta}_{t-1}\\|\\frac{\\tilde{\\psi}_{t-1}}{\\tilde{\\theta}_{t-1}}}\\\\ &{\\quad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})}\\\\ &{\\leq2\\tilde{\\gamma}_{t-1}\\cdot\\|g(x_{t};\\tilde{\\theta}_{t-1})/\\sqrt{m}\\|\\frac{\\tilde{\\psi}_{t-1}}{\\tilde{\\theta}_{t-1}}+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})}\\\\ &{\\quad\\quad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{2/7})}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where the first inequality is by Lemma G.4, second inequality is by Holder's inequality, and the last inequality is by applying the definition of confidence ellipsoid $\\widetilde{\\mathcal{C}}_{t-1}$ , Lemma G.4, and Lemma G.6. Next, recall that the above $\\widetilde{\\mathsf{U C B}}_{t}$ is one term composing the single-round regret $R_{t}$ ,and for the cumulative regret, it will be summed up across $T$ rounds. In this case, for the first term on the RHS ", "page_idx": 40}, {"type": "text", "text": "above, we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\in[T]}2\\cdot\\operatorname*{min}\\big\\{\\widetilde{\\gamma}_{t-1}\\cdot\\|g(\\mathbf{x}_{t};\\widetilde{\\theta}_{t-1})/\\sqrt{m}\\|_{\\widetilde{\\mathbf{S}}_{t-1}^{-1}},\\,1\\big\\}=\\displaystyle\\sum_{t\\in[T]}2\\cdot\\operatorname*{min}\\big\\{\\frac{\\widetilde{\\gamma}_{t-1}}{\\sqrt{w_{t}}}\\cdot\\|\\sqrt{w_{t}}g(\\mathbf{x}_{t};\\widetilde{\\theta}_{t-1})/\\sqrt{m}\\|_{\\widetilde{\\mathbf{S}}_{t-1}^{-1}}\\big\\}=}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\leq2(1+\\frac{\\widetilde{\\gamma}_{T}}{\\sqrt{w_{t}^{\\mathrm{min}}}})\\cdot\\sum_{t\\in[T]}\\operatorname*{min}\\big\\{\\|\\sqrt{w_{t}}g(\\mathbf{x}_{t};\\widetilde{\\theta}_{t-1})/\\sqrt{m}\\|_{\\widetilde{\\mathbf{S}}_{t-1}^{-1}},\\,1\\big\\}}\\\\ &{\\displaystyle\\qquad\\qquad\\leq2(1+\\frac{\\widetilde{\\gamma}_{T}}{\\sqrt{w_{t}^{\\mathrm{min}}}})\\cdot\\sqrt{T\\cdot\\sum_{t\\in[T]}\\operatorname*{min}\\big\\{\\|\\sqrt{w_{t}}g(\\mathbf{x}_{t};\\widetilde{\\theta}_{t-1})/\\sqrt{m}\\|_{\\widetilde{\\mathbf{S}}_{t-1}^{-1}}^{2},\\,1\\big\\}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where we have $w_{t}^{\\mathsf{m i n}}<1$ Then, applying LemmaG.7 and by the defnition of $\\gamma_{T}$ as well as supposing that $\\begin{array}{r}{\\frac{\\tilde{\\gamma}_{T}}{\\sqrt{w_{t}^{\\mathrm{min}}}}\\geq1}\\end{array}$ , we will have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in[T]}2\\operatorname*{min}\\big\\{\\widetilde{\\gamma}_{t-1}\\cdot\\|g(x_{t};\\widetilde{\\theta}_{t-1})/\\sqrt{m}\\|\\widetilde{\\Sigma}_{t-1}^{-1},\\,1\\big\\}}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad\\quad\\leq\\displaystyle\\frac{1}{\\sqrt{w_{t}^{\\mathrm{min}}}}\\mathcal{O}\\bigg(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}(\\widetilde{\\Sigma}_{T})}{\\operatorname*{det}(\\lambda\\mathrm{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)\\cdot\\sqrt{2T\\cdot\\log\\frac{\\operatorname*{det}(\\widetilde{\\Sigma}_{T})}{\\operatorname*{det}(\\lambda\\mathrm{I})}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Next, for the corrupted parameters $\\theta_{i,t-1}$ , we consider the confidence ellipsoid ${\\mathcal{C}}_{i,t-1}\\;:=\\;\\{\\theta\\;:\\;$ $\\lVert\\pmb{\\theta}-\\pmb{\\theta}_{i,t-1}\\rVert_{\\pmb{\\Sigma}_{i,t-1}}\\leq\\gamma_{i,t-1}/\\sqrt{m}\\}$ constructed around the corrupted parameters $\\theta_{i,t-1}$ , with the coefcient /,-1 = 0(v \u221alog dtc&(t-) $\\begin{array}{r}{\\gamma_{i,t-1}=\\mathcal{O}\\big(\\nu\\cdot\\sqrt{\\log\\frac{\\operatorname*{det}(\\Sigma_{i,t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\big)}\\end{array}$ gdt - 2log() + X1/2 ) andthe gradient covariance matrix $\\begin{array}{r}{\\Sigma_{i,t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m.}\\end{array}$ ", "page_idx": 41}, {"type": "text", "text": "LemmaC.10.Inround $t$ ,with the notation and conditions in Theorem 5.6, suppose the corruptionfree parameters $\\widetilde{\\pmb{\\theta}}_{i,t-1}$ associated with $a$ candidate arm $\\mathbf{\\mathcal{x}}_{i,t}~\\in~\\mathcal{X}_{t}$ are trained by ${\\mathcal{L}}(\\pmb{\\theta})\\ =$ >re[t-1]wi,t w2 I(e; 0)  T-12 + m2> 10 - Oo2. Then, we have the corresponding confdence ellipsoid ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\widetilde{\\mathcal{C}}_{i,t-1}:=\\{\\pmb{\\theta}:\\|\\pmb{\\theta}-\\widetilde{\\pmb{\\theta}}_{i,t-1}\\|_{\\widetilde{\\pmb{\\Sigma}}_{i,t-1}}\\leq\\widetilde{\\gamma}_{i,t-1}/\\sqrt{m}\\},\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "such that $\\pmb{\\theta}^{*}\\in\\widetilde{\\mathcal{C}}_{i,t-1}$ where $\\begin{array}{r}{\\widetilde{\\gamma}_{i,t-1}=\\mathcal{O}\\big(\\nu\\cdot\\sqrt{\\log\\frac{\\operatorname*{det}(\\widetilde{\\Sigma}_{i,t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\big)}\\end{array}$ dt(t - 2log(8)+\u51651/2 S), and the gradient covariance matrix $\\begin{array}{r}{\\widetilde\\Sigma_{i,t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})g(\\pmb{x}_{\\tau};\\widetilde{\\pmb{\\theta}}_{\\tau-1})^{\\top}/m.}\\end{array}$ ", "page_idx": 41}, {"type": "text", "text": "Proof. The proof of this lemma follows an analogous approach as in Lemma 5.2 in [86]. Recall that based on Lemma C.1, we have the expected reward of an arm $\\mathbf{\\boldsymbol{x}}\\in\\mathcal{X}_{t}$ being $\\mathbb{E}[r|{\\pmb x}]=h({\\pmb x})=$ $\\langle g(\\mathbf{x};\\pmb{\\theta}_{0}),~\\pmb{\\theta}^{*}\\:-\\:\\pmb{\\theta}_{0}\\rangle$ where there exist parameters $\\pmb{\\theta}^{*}$ such that $\\|\\pmb{\\theta}^{*}\\-\\pmb{\\theta}_{0}\\|\\ \\leq\\ S/\\sqrt{m},S\\ >\\ 0$ Intuitively, for each previously chosen arm $\\mathbf{\\boldsymbol{x}}_{\\tau},\\tau\\in[t-1]$ , we can consider an alternative form being ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\sqrt{w_{i,t}^{(\\tau)}}\\cdot r\\middle|\\;\\pmb{x}_{\\tau}\\right]=\\sqrt{w_{i,t}^{(\\tau)}}\\cdot h(\\pmb{x}_{\\tau})=\\left\\langle\\sqrt{w_{i,t}^{(\\tau)}}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{0})/\\sqrt{m},\\;\\sqrt{m}(\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0})\\right\\rangle\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Where $w>0$ refers to the weight associated with arm $\\textbf{\\em x}$ in our settings of R-NeuralUCB. Afterwards, with the weighted sequence of chosen arm gradients as well as their expected corruption-free rewards, wecanhave ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\|\\sqrt{m}(\\theta^{*}-\\theta_{0})-(\\widetilde{\\Sigma}_{i,t-1}^{(0)})^{-1}\\widetilde{b}_{i,t-1}^{(0)}\\|_{\\widetilde{\\Sigma}_{i,t-1}^{(0)}}\\le\\nu\\cdot\\sqrt{\\log\\frac{\\operatorname*{det}(\\widetilde{\\Sigma}_{i,t-1}^{(0)})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S,\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "by applying the conclusion of Theorem 2 from [1]. In this case, by triangular inequality, we also have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta^{*}-\\theta_{0}\\|_{\\widetilde{\\Sigma}_{i,t-1}}}\\\\ &{\\quad\\leq\\|\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{i,t-1}^{(0)})^{-1}\\widetilde{b}_{i,t-1}^{(0)}/\\sqrt{m}\\|_{\\widetilde{\\Sigma}_{i,t-1}}+\\|\\widetilde{\\theta}_{i,t-1}-\\theta_{0}-(\\widetilde{\\Sigma}_{i,t-1}^{(0)})^{-1}\\widetilde{b}_{i,t-1}^{(0)}/\\sqrt{m}\\|_{\\widetilde{\\Sigma}_{i,t-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Then, for the first term on the right hand side, we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m}|^{2}\\Bigg|_{\\widetilde{\\Sigma}_{\\Delta_{t-1},t}}^{2}}\\\\ &{=(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m})^{\\top}\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)}(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m})}\\\\ &{=(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m})\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)}(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m})}\\\\ &{\\quad+(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m})^{\\top}(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)}-\\widetilde{X}_{\\widetilde{A}_{1},t-1}^{(i)}):(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m})}\\\\ &{\\le(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)})^{-1}\\widetilde{b}_{i,t-1}^{(i)}/\\sqrt{m})\\widetilde{\\Sigma}_{\\widetilde{A}_{1},t-1}^{(i)}(\\theta^{*}-\\theta_{0}-(\\widetilde{\\Sigma}_{ \n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where the first inequality is because $x^{\\top}\\mathbf{A}x\\leq x^{\\top}\\mathbf{B}x\\cdot\\|\\mathbf{A}\\|_{2}/\\lambda_{\\operatorname*{min}}(\\mathbf{B})$ for some $0\\prec\\mathbf{B}$ and the fact that he mnimum eigeivale $\\lambda_{\\sf m i n}(\\widetilde{\\Sigma}_{i,t-1}^{(0)})\\geq\\lambda$ andhlasiqualtisbLGallas due to the fact $w_{i,t}^{(\\tau)}\\leq1$ Afterwards, for the second term, we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\iota_{t-1}-\\theta_{0}-(\\widetilde{\\Sigma}_{i,t-1}^{(0)})^{-1}\\widetilde{b}_{i,t-1}^{(0)}/\\sqrt{m}\\|_{\\widetilde{\\Sigma}_{i,t-1}}\\leq\\sqrt{\\|\\widetilde{\\Sigma}_{i,t-1}\\|_{2}}\\cdot\\|\\widetilde{\\theta}_{i,t-1}-\\theta_{0}-(\\widetilde{\\Sigma}_{i,t-1}^{(0)})^{-1}\\widetilde{b}_{i,t-1}^{(0)}/\\sqrt{m}\\|_{2}}\\\\ {\\leq\\mathcal{O}(\\sqrt{\\lambda+t L})\\cdot\\mathcal{O}\\bigg((1-\\eta m\\lambda)^{J/2}\\sqrt{t/m\\lambda}+m^{-2/3}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda})\\bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "The first inequality follows from applying Lemma G.6. For the second inequality, we apply a similar approach as in Lemma D.1, with the optimization problem given by (C.12). Since we scale the $\\alpha$ parametertoensure $\\underline{{1}}>w_{i,t}^{(\\tau)}\\geq\\kappa^{2}$ , we can follow the proof o Lemma B.2 in [86] to bound the difference between GD-based optimization and gradient-based regression. With the minimum weight value lower bounded by $\\kappa^{2}$ and under the conditions in Theorem 5.6, applying Remark 4.7 in [86] completes the proof. ", "page_idx": 42}, {"type": "text", "text": "Lemma C.11. For candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ ,suppose its associated neural network $f(\\cdot;\\pmb{\\theta}_{i,t-1})$ has been trained on received records $\\{\\pmb{x}_{\\tau},r_{\\tau}\\}_{\\tau\\in[t-1]}$ with $J$ iterations of $G D$ and learning rate $\\eta$ Let $f(\\cdot;\\pmb{\\theta}_{i,t-1})$ be an $L$ -layer $F C$ network with width m. Suppose conditions in Theorem 5.6 are satisfied. Then, given the candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , with a constant $\\zeta>0$ and probability at least $1-\\delta$ we will have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(x_{i,t};\\theta_{i,t-1})-h(x_{i,t})\\big|}\\\\ &{\\qquad\\qquad\\leq\\|g(x_{i,t};\\theta_{i,t-1})/\\sqrt{m}\\|_{\\Sigma_{t-1}^{-1}}\\cdot\\Big[\\zeta\\cdot\\Big(\\nu\\sqrt{\\log\\frac{\\mathrm{det}(\\Sigma_{i,t-1})}{\\mathrm{det}(\\lambda)}-2\\log(\\delta)}+\\lambda^{1/2}S\\Big)}\\\\ &{\\qquad\\qquad\\qquad+\\,(1-\\eta m\\lambda)^{J/2}\\sqrt{t/\\lambda}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\\\ &{\\qquad\\qquad\\qquad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{7/2})+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-13/6}L^{9/2})}\\\\ &{\\qquad\\qquad\\qquad+\\,\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{2}t^{5/6}\\lambda^{-1/12}}\\\\ &{\\qquad\\qquad+\\mathcal{O}(\\alpha C)\\cdot\\operatorname*{min}\\|g(x;\\theta_{i,t-1})/\\sqrt{m}\\|_{\\Sigma_{t-1}^{-1}}^{2}}\\\\ &{\\qquad\\qquad\\qquad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3}),}\\\\ &{\\qquad\\qquad\\qquad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/16}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-1/3}L^{3}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "with notation and definitions in Theorem 5.6. We also have the covariance matrix $\\pmb{\\Sigma}_{i,t-1}=\\lambda\\mathbf{I}+$ $\\begin{array}{r l}{\\sum_{\\tau\\in[t]}w_{i,t}^{(\\tau)}\\cdot g({\\pmb x}_{\\tau};{\\pmb\\theta}_{\\tau-1})g({\\pmb x}_{\\tau};{\\pmb\\theta}_{\\tau-1})^{\\tau}}\\end{array}$ with gradient vector $g(\\pmb{x}_{i,t};\\pmb{\\theta})=\\nu e c(\\nabla_{\\pmb{\\theta}}f(\\pmb{x}_{i,t};\\pmb{\\theta}))$ ", "page_idx": 43}, {"type": "text", "text": "Proof. Applying the Lemma C.1, we can transform the objective by substituting the reward mapping function $h(\\cdot)$ ,as ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|f({x}_{i,t};\\theta_{i,t-1})-h({x}_{i,t})\\right|=\\left|f({x}_{i,t};\\theta_{i,t-1})-\\left\\langle g({x}_{i,t};\\theta_{0}),\\theta^{*}-{\\theta}_{0}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad\\leq\\left|f({x}_{i,t};\\theta_{i,t-1})-\\left\\langle g({x}_{i,t};\\theta_{i,t-1}),\\theta^{*}-{\\theta}_{0}\\right\\rangle\\right|+{\\mathcal O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}{\\lambda}^{-1/6}L^{2/7})}\\\\ &{\\qquad\\qquad\\leq\\left|f({x}_{i,t};\\theta_{i,t-1})-\\left\\langle g({x}_{i,t};\\theta_{i,t-1}),\\theta_{i,t-1}-{\\theta}_{0}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad\\qquad+\\left|\\left\\langle g({x}_{i,t};\\theta_{i,t-1}),\\theta_{i,t-1}-\\theta_{0}\\right\\rangle-\\left\\langle g({x}_{i,t};\\theta_{i,t-1}),\\theta^{*}-\\theta_{0}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad\\qquad+{\\mathcal O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}{\\lambda}^{-1/6}{L}^{2/7})}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where the first equality is due to Lemma C.1, while the first inequality is due to Lemma G.4 and Lemma C.1, and the last inequality is because of the triangular inequality. Then, we proceed to separately bound the first and second term on the RHS. For the first term, we will have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|f(x_{i,t};\\theta_{i,t-1})-\\left\\langle g(x_{i,t};\\theta_{i,t-1}),\\theta_{i,t-1}-\\theta_{0}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad\\qquad=\\left|f(x_{i,t};\\theta_{i,t-1})-f(x_{i,t};\\theta_{0})-\\left\\langle g(x_{i,t};\\theta_{i,t-1}),\\theta_{i,t-1}-\\theta_{0}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where the first equality is due to the fact that $f(\\pmb{x}_{i,t};\\pmb{\\theta}_{0})=0$ based on our parameter initialization approach, and the inequality is by applying Lemma G.5 and Lemma G.3. Then, for the second term, wewillhave ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\left\\langle g(x_{i,t};\\theta_{i,t-1}),\\theta_{i,t-1}-\\theta_{0}\\right\\rangle-\\left\\langle g(x_{i,t};\\theta_{i,t-1}),\\theta^{*}-\\theta_{0}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad\\qquad=\\left|\\left\\langle g(x_{i,t};\\theta_{i,t-1}),\\theta^{*}-\\theta_{i,t-1}\\right\\rangle\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left\\Vert g(x_{i,t};\\theta_{i,t-1})/\\sqrt{m}\\right\\Vert_{\\Sigma_{i,t-1}^{-1}}\\cdot\\sqrt{m}\\cdot\\left\\Vert\\theta^{*}-\\theta_{i,t-1}\\right\\Vert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\gamma_{i,t-1}\\cdot\\left\\Vert g(x_{i,t};\\theta_{i,t-1})/\\sqrt{m}\\right\\Vert_{\\Sigma_{i,t-1}^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where the first inequality is by applying the Holder's inequality, and the last inequality is by applying Lemma 5.2 in [86], Lemma C.1 in terms of the confidence set $\\mathcal{C}_{i,t-1}$ and the fact that $\\pmb{\\theta}^{*}\\in\\bar{C}_{i,t-1}$ Then, with the confidence ellipsoid introduced and discussed in Lemma C.12, summing up the results above, we will then have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(x_{i},\\ t;\\theta_{i,t-1})-h(x_{i,t})\\bigg|}\\\\ &{\\leq\\|g(x_{i,t};\\theta_{i,t-1})/\\sqrt{m}\\|_{\\Sigma_{t,i-1}^{-1}}}\\\\ &{\\qquad\\cdot\\left[\\mathcal{O}\\bigg(\\nu\\sqrt{\\log\\frac{\\mathrm{det}(\\Sigma_{i,t-1})}{\\mathrm{det}(\\lambda)}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)+\\mathcal{O}(\\alpha C)\\cdot\\frac{\\operatorname*{min}_{i}\\|g(x;\\theta_{i,t-1})/\\sqrt{m}\\|_{\\Sigma_{t-1}^{-1}}^{2}}{\\|g(x_{i,t};\\theta_{i,t-1})/\\sqrt{m}\\|_{\\Sigma_{t-1}^{(\\theta)}}}}\\\\ &{\\qquad\\qquad+\\left(1-\\eta m\\lambda\\right)^{J/2}\\sqrt{t/\\lambda}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C m^{-2/3}\\sqrt{\\log(m)t^{1/6}\\lambda^{-7/6}L^{7/2}})+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)t^{7/6}\\lambda^{-13/6}}L^{9/2})}\\\\ &{\\qquad\\qquad+\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{2}t^{5/6}\\lambda^{-1/12})\\right]}\\\\ &{\\qquad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-1/6}L^{2/7}})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)t^{2/3}\\lambda^{-2/3}}L^{3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\|g(\\alpha_{i,i};\\theta_{i,t-1})/\\sqrt{m}\\|_{\\mathbf{z}_{i,t-1}^{-1}}}\\\\ &{\\qquad\\cdot\\left[\\mathcal{O}\\bigg(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}(\\mathbf{\\hat{S}}_{i,t-1})}{\\operatorname*{det}(\\mathbf{\\hat{A}})}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)\\right.}\\\\ &{\\qquad\\quad+\\left.(1-\\eta m\\lambda)^{J/2}\\sqrt{t/\\lambda}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{T/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))\\right.}\\\\ &{\\qquad\\quad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{7/2})+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/8}\\ell L^{9/2})}\\\\ &{\\qquad\\quad+\\left.\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{L/76}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{2}t^{5/6}\\lambda^{-1/12})\\right]}\\\\ &{\\qquad\\quad+\\|g(\\pm_{i,t};\\theta_{i,t-1})/\\sqrt{m}\\|_{\\mathbf{z}_{i,t-1}^{-1}}\\cdot\\mathcal{O}(\\alpha C)\\cdot\\frac{\\operatorname*{min}\\|g(\\pm_{i,t-1})/\\sqrt{m}\\|_{\\mathbf{\\hat{S}}_{i-1}^{-1}}^{2}}{\\|g(\\pm_{i,t};\\theta_{i,t-1})/\\sqrt{m}\\|_{\\mathbf{\\hat{S}}_{i-1}^{-1}}}}\\\\ &{\\qquad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where we naturally have Hermitian matrices $\\Sigma_{i,t-1}~\\succeq~\\bar{\\Sigma}_{t-1}^{(\\kappa)}$ by defnition, which leads to $(\\Sigma_{i,t-1})^{-1}\\,\\preceq\\,(\\bar{\\Sigma}_{t-1}^{(\\kappa)})^{-1}$ by applying the conclusion from Lemma G.8. Afterwards, due to the facthatwisa $w_{t}^{\\mathsf{m i n}}=\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2}<1,$ $\\forall t\\in[T]$ by scaling parameter $\\alpha$ , we can further have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{f(x_{i,i};\\theta_{i,i-1})-h(x_{i,i})\\Big|}\\\\ &{\\le\\|g(x_{i,i};\\theta_{i,i-1})\\rangle\\langle\\sqrt{m}\\|_{\\mathbf{X}_{i}^{-1-1}}}\\\\ &{\\quad\\cdot\\left[\\mathcal{O}\\Big(\\nu\\sqrt{\\log\\frac{\\mathrm{det}(\\mathbf{Z}_{i}(X))}{\\mathrm{det}(X)}}-2\\log(\\delta)+\\lambda^{1/2}S\\Big)\\right.}\\\\ &{\\qquad\\quad+(1-\\eta m\\Delta)^{/2}\\gamma\\overline{{f}}/\\lambda+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{7/2}\\epsilon^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\\\ &{\\qquad\\quad+\\mathcal{O}(C\\sigma^{-2/3}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{7/2})+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-1/8}\\ell^{9/2})}\\\\ &{\\qquad\\quad+\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4/7}\\theta_{+}-7\\ell^{9})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{2}t^{5/6}\\lambda^{-1/12})\\Bigg]}\\\\ &{\\quad+\\mathcal{O}(\\alpha C)\\cdot\\operatorname*{min}|g(x;\\theta_{i+1})\\sqrt{\\sqrt{m}}\\|_{\\mathbf{X}_{i}^{-1}}^{2}}\\\\ &{\\quad+\\mathcal{O}(S\\underline{{m}}^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "which completes the proof for this lemma. ", "page_idx": 44}, {"type": "text", "text": "Lemma C.12. In round $t\\in[T]$ with the notation and conditions from Theorem 5.6, suppose the corruptedparameters $\\pmb\\theta_{i,t-1}$ associated with a candidate arm $\\pmb{x}_{i,t}\\,\\in\\,\\mathcal{X}_{t}$ aretrainedby ${\\mathcal{L}}(\\pmb{\\theta})=$ $\\begin{array}{r}{\\frac{1}{2}\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot|f(\\pmb{x}_{\\tau};\\pmb{\\theta})-r_{\\tau}|^{2}+\\frac{m\\lambda}{2}\\cdot\\|\\pmb{\\theta}-\\pmb{\\theta}_{0}\\|_{2}^{2}}\\end{array}$ Then, we have the confidence ellipsoid ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\mathcal{C}_{i,t-1}=\\left\\{\\theta:\\|\\theta-\\theta_{i,t-1}\\|_{\\Sigma_{i,t-1}}\\leq\\gamma_{i,t-1}/\\sqrt{m}\\right\\}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where we have the unknown parameter $\\pmb{\\theta}^{*}\\in\\mathcal{C}_{i,t-1}$ ,andwedenote ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\iota_{i,t-1}=\\mathcal{O}\\bigg(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}(\\mathbf{\\Sigma}_{i,t-1})}{\\operatorname*{det}(\\lambda\\mathbf{I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)+\\mathcal{O}(\\alpha C)\\cdot\\frac{\\operatorname*{min}||g(\\mathbf{x};\\theta_{i,t-1})/\\sqrt{m}||_{\\bar{\\mathbf{S}}_{t-1}^{-1}}^{2}}{||g(\\alpha_{i,t};\\theta_{i,t-1})/\\sqrt{m}||_{(\\bar{\\mathbf{S}}_{t-1}^{(\\kappa)})^{-1}}}}\\\\ &{\\qquad\\qquad+\\left(1-\\eta m\\lambda\\right)^{J/2}\\sqrt{t/\\lambda}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\\\ &{\\qquad\\qquad+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{7/2})+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-13/6}L^{9/2})}\\\\ &{\\qquad\\qquad+\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-1/12}\\log^{1/4}(m)L^{2}t^{5/6}\\lambda^{-1/12}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Proof. Recall that for the imaginary corruption-free parameters $\\widetilde{\\pmb{\\theta}}_{i,t-1}$ , trained on corruption-free records $\\widetilde{\\mathcal{P}}_{t-1}$ we ca construct the confidence inteval $\\widetilde{\\mathcal{C}}_{i,t-1}\\;:=\\;\\{\\pmb{\\theta}\\,:\\,\\|\\pmb{\\theta}-\\widetilde{\\pmb{\\theta}}_{i,t-1}\\|_{\\widetilde{\\pmb{\\Sigma}}_{i,t-1}}\\,\\leq$ $\\widetilde{\\gamma}_{i,t-1}/\\sqrt{m},\\widetilde{\\gamma}_{i,t-1}>0\\}$ , ensuring that the unknown $\\pmb{\\theta}^{*}$ in Lemma C.1 satisfies $\\theta^{*}\\in\\widetilde{\\mathcal{C}}_{i,t-1}$ . The corresponding confidence ellipsoid is presented in Lemma C.10. ", "page_idx": 45}, {"type": "text", "text": "With the ellipsoid centered at $\\theta_{i,t-1}$ and the gradient covariance matrix defined as $\\pmb{\\Sigma}_{i,t-1}=\\lambda\\mathbf{I}+$ $\\begin{array}{r l}{\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m}\\end{array}$ , we proceed to derive the corresponding radius. Recall that $w_{i,t}^{(\\tau)}$ $\\pmb{x}_{\\tau}$ recall the preliminary bounds: $\\|\\Sigma_{i,t-1}-\\widetilde{\\Sigma}_{i,t-1}\\|_{F}\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-1/6})$ by Lemma G.6 and $\\|\\pmb{\\theta}_{i,t-1}-\\widetilde{\\pmb{\\theta}}_{i,t-1}\\|_{2}\\leq\\mathcal{O}(\\sqrt{t/(m\\lambda)})$ as shown in Lemma G.3. Next, as we already have $\\lVert\\pmb{\\theta}-\\widetilde{\\pmb{\\theta}}_{i,t-1}\\rVert_{\\widetilde{\\pmb{\\Sigma}}_{i,t-1}}\\leq\\widetilde{\\gamma}_{i,t-1}/\\sqrt{m}$ we then proceed to transform the objectiv to ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta^{*}-\\theta_{i,t-1}\\lVert\\mathbf{z}_{i,t-1}\\rVert_{\\dot{\\mathbf{z}}_{i,t-1}}\\leq\\lVert\\theta^{*}-\\widetilde{\\theta}_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}+\\lVert\\widetilde{\\theta}_{i,t-1}-\\theta_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\leq\\lVert\\theta^{*}-\\widetilde{\\theta}_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}+\\lVert\\widetilde{\\theta}_{i,t-1}-\\theta_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\leq\\lVert\\theta^{*}-\\widetilde{\\theta}_{i,t-1}\\rVert_{\\Sigma_{i,t-1}-\\widetilde{\\Sigma}_{i,t-1}+\\widetilde{\\Sigma}_{i,t-1}}+\\lVert\\widetilde{\\theta}_{i,t-1}-\\theta_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\leq\\lVert\\theta^{*}-\\widetilde{\\theta}_{i,t-1}\\rVert_{\\widetilde{\\Sigma}_{i,t-1}}+\\lVert\\theta^{*}-\\widetilde{\\theta}_{i,t-1}\\rVert_{\\Sigma_{i,t-1}-\\widetilde{\\Sigma}_{i,t-1}}+\\lVert\\widetilde{\\theta}_{i,t-1}-\\theta_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\leq\\widetilde{\\gamma}_{i,t-1}/\\sqrt{m}+\\lVert\\widetilde{\\theta}_{i,t-1}-\\theta_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}+\\mathcal{O}(\\sqrt{t/(m\\lambda)})\\cdot\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-1/6})}\\\\ &{\\qquad\\leq\\widetilde{\\gamma}_{i,t-1}/\\sqrt{m}+\\lVert\\widetilde{\\theta}_{i,t-1}-\\theta_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}+\\mathcal{O}(m^{-2/3}\\sqrt{\\log(m)}L^{4}t^{13/6}\\lambda^{-2/3}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "For the first term on the RHS, we can follow the proof flow in Lemma C.6, by applying Lemma G.4 to substitute $\\widetilde{\\Sigma}_{i,t-1}$ with corresponding $\\Sigma_{i,t-1}$ , which will consequently lead to $|\\gamma_{i,t-1}/\\sqrt{m}-$ $\\tilde{\\gamma_{i,t-1}}/\\sqrt{m}|\\leq\\nu\\cdot\\sqrt{1+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-7/6})}\\cdot\\mathcal{O}(m^{-7/12}\\log^{1/4}(m)L^{2}t^{5/6}\\lambda^{-1/12}).$ Meanwhile, for the second term on the RHS, we first define the gradient-based regression parameters as ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Sigma_{i,t-1}^{(0)}=\\lambda\\mathbf{I}+\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{0})\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{0})^{\\top}/m,}\\\\ &{b_{i,t-1}^{(0)}=\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{0})\\cdot r_{\\tau}/\\sqrt{m},}\\\\ &{\\widetilde{b}_{i,t-1}^{(0)}=\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{0})\\cdot\\widetilde{r}_{\\tau}/\\sqrt{m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Then, we can proceed to have ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\theta}_{i,t-1}-\\theta_{i,t-1}\\lVert\\mathbf{z}_{i,t-1}\\rVert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\leq\\lVert\\tilde{\\theta}_{i,t-1}-\\theta_{0}-(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}b_{i,t-1}^{(0)}/\\sqrt{m}+(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}b_{i,t-1}^{(0)}/\\sqrt{m}+\\theta_{0}-\\theta_{i,t-1}\\lVert\\mathbf{z}_{i,t-1}}\\\\ &{\\qquad\\leq\\lVert\\theta_{i,t-1}-\\theta_{0}-(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}b_{i,t-1}^{(0)}/\\sqrt{m}\\rVert_{\\Sigma_{i,t-1}}+\\lVert\\tilde{\\theta}_{i,t-1}-\\theta_{0}-(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}b_{i,t-1}^{(0)}/\\sqrt{m}\\rVert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\leq\\lVert\\theta_{i,t-1}-\\theta_{0}-(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}b_{i,t-1}^{(0)}/\\sqrt{m}\\rVert_{\\Sigma_{i,t-1}}+\\lVert\\tilde{\\theta}_{i,t-1}-\\theta_{0}-(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}\\tilde{b}_{i,t-1}^{(0)}/\\sqrt{m}\\rVert_{\\Sigma_{i,t-1}}}\\\\ &{\\qquad\\qquad+\\ m^{-1}\\lVert(\\mathbf{\\Sigma}_{i,t-1}^{(0)})^{-1}\\cdot(\\sum_{t\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\mathbf{x}_{\\tau};\\theta_{0})\\cdot c_{\\tau})\\rVert_{\\Sigma_{i,t-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "Bounding the first two term in Inequality C.22. Here, for the first term on the RHS, we can individually apply Lemma D.1, by considering the auxiliary sequence in $j$ -th iteration $(j\\in[J])$ With $\\pmb{\\Theta}^{(0)}=\\pmb{\\theta}_{0}$ ,.as ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta^{(j+1)}=\\Theta^{(j)}-\\eta\\cdot\\left[\\mathbf{J}^{(0)}\\cdot\\mathbf{W}\\cdot\\left([\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\theta_{0})-y\\right)+m\\lambda(\\Theta^{(j)}-\\theta_{0})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where the Jacobian matrix $\\mathbf{J}^{(0)}\\,:=\\,\\bigl(g(\\pmb{x}_{1};\\pmb{\\theta}_{0}),g(\\pmb{x}_{2};\\pmb{\\theta}_{0}),\\dots,g(\\pmb{x}_{i,t-1};\\pmb{\\theta}_{0})\\bigr)\\,\\in\\,\\mathbb{R}^{p\\times(t-1)}$ vector $\\pmb{y}\\in\\mathbb{R}^{t-1}$ contains the received arm rewards $r_{\\tau},\\tau\\in[t-1]$ , and matrix $\\mathbf{W}\\in\\mathbb{R}^{(t-1)\\times(t-1)}$ is the ", "page_idx": 45}, {"type": "text", "text": "diagonal matrix that contains sample weights $w_{i,t}^{(\\tau)},\\tau\\,\\in\\,[t-1]$ . In particular, we have is norm $\\lVert\\mathbf{W}\\rVert_{2}\\leq1$ by definition. Here, with $[\\mathbf{J}^{(0)}]_{\\tau}$ being the $\\tau$ -th column of matrix $\\mathbf{J}^{(0)}$ , the above sequence is expected to solve the following problem ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\underset{\\Theta}{\\operatorname*{min}}\\,\\mathcal{L}(\\Theta)=\\sum_{\\tau\\in[t-1]}\\frac{w_{i,t}^{(\\tau)}}{2}\\cdot\\bigg\\|[\\mathbf{J}^{(0)}]_{\\tau}^{\\top}(\\Theta-\\theta_{0})-r_{\\tau}\\bigg\\|_{2}^{2}+\\frac{1}{2}\\cdot m\\lambda\\cdot\\Big\\|\\Theta-\\theta_{0}\\bigg\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "As a result, following an analogous approach as in Lemma C.4 in [86], we can have $\\lVert\\Theta^{(j)}-\\pmb{\\theta}_{0}-\\$ $(\\Sigma_{i,t-1}^{(0)})^{-1}b_{i,t-1}^{(0)}/\\sqrt{m}\\|_{\\Sigma_{i,t-1}}\\leq(1-\\eta m\\lambda)^{j/2}\\sqrt{t/(m\\lambda)}.$ Furthemore by aplyingthe conelusion of Lemma D.i, we can have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\theta_{i,t-1}-\\theta_{0}-(\\Sigma_{i,t-1}^{(0)})^{-1}b_{i,t-1}^{(0)}/\\sqrt{m}\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq(1-\\eta m\\lambda)^{J/2}\\sqrt{t/(m\\lambda)}+\\mathcal{O}(m^{-2/3}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda})).}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Similarly, for the second term in Inequality C.22, we also can apply a comparable approach by solving the problem: ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\underset{\\Theta}{\\operatorname*{min}}\\,\\mathcal{L}(\\Theta)=\\sum_{\\tau\\in[t-1]}\\frac{w_{i,t}^{(\\tau)}}{2}\\bigg\\|[\\mathbf{J}^{(0)}]_{\\tau}^{\\top}(\\Theta-\\theta_{0})-\\widetilde{r}_{\\tau}\\bigg\\|_{2}^{2}+\\frac{1}{2}m\\lambda\\cdot\\bigg\\|\\Theta-\\theta_{0}\\bigg\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "and constructing the corresponding auxiliary sequence. This will lead to a similar bound for the secondtemo the RHIsofineguaityC.2suchthat $\\lVert\\widetilde{\\pmb{\\theta}}_{i,t-1}-\\pmb{\\theta}_{0}-(\\pmb{\\Sigma}_{i,t-1}^{(0)})^{-1}\\widetilde{\\pmb{b}}_{i,t-1}^{(0)}/\\sqrt{m}\\rVert_{2}\\leq$ $(1-\\eta m\\lambda)^{J/2}\\sqrt{t/(m\\lambda)}+\\mathcal{O}(m^{-2/3}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda})).$ ", "page_idx": 46}, {"type": "text", "text": "Bounding the third term in Inequality C.22. Then, for the third term on the RHS, we first have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(1)}-\\frac{1}{r}\\left(\\sum_{s=0}^{\\infty}\\eta_{s}^{(\\varepsilon)}-\\varepsilon\\left(x_{s}^{(\\varepsilon)}-\\theta\\right)\\right)\\rVert_{\\mathbf{S}_{t-1}},}\\\\ &{\\le m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(1)-1}-\\frac{1}{r}\\left(\\sum_{s=0}^{\\infty}\\eta_{s}^{(\\varepsilon)}-\\varepsilon\\left(x_{s}^{(\\varepsilon)}-\\theta\\right)\\right)\\rVert_{\\mathbf{S}_{t-1}},}\\\\ &{\\qquad+m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(1)-1}-(\\sum_{s=0}^{\\infty}\\eta_{s}^{(\\varepsilon)}-\\varepsilon\\left(x_{s}^{(\\varepsilon)}-\\theta\\right)\\rVert_{\\mathbf{S}_{t-1}},}\\\\ &{\\le m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(1)-1}-\\frac{1}{r}\\left(\\sum_{s=0}^{\\infty}\\eta_{s}^{(\\varepsilon)}-\\theta\\right)\\rVert_{\\mathbf{S}_{t-1}},}\\\\ &{\\qquad+m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(1)-1}\\rVert_{\\mathbf{S}_{t-1}},}\\\\ &{\\le m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(2)}-\\frac{1}{r}\\left(\\sum_{s=0}^{\\infty}\\eta_{s}^{(\\varepsilon)}-\\theta\\right)\\rVert_{\\mathbf{S}_{t-1}},}\\\\ &{\\qquad+m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(1)-1}\\rVert_{\\mathbf{S}_{t-1}},}\\\\ &{\\le m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(2)}-\\frac{1}{r}\\left(\\sum_{s=0}^{\\infty}\\eta_{s}^{(\\varepsilon)}-\\theta\\right)\\rVert_{\\mathbf{S}_{t-1}}+O(C^{-2/3}\\sqrt{\\log(m)^{2}\\pi^{2}\\lambda}-1)\\mathbb{G}_{t-1},}\\\\ &{\\le m^{-1}\\lVert\\widetilde{\\mathbf{G}}_{t,\\varepsilon-1}^{(1)-1}\\rVert_{\\mathbf{S}_{t-1}},}\\\\\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where the third inequality is due to Lemma G.6, and the last inequality is due to Lemma G.4. Then, recall that the weight $w_{i,t}^{(\\tau)}$ from (4) for each previously chosen arm $\\mathbf{\\nabla}x_{\\tau}$ In thiscase, we can further ", "page_idx": 46}, {"type": "text", "text": "have ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m^{-1/2}\\lVert(\\boldsymbol{\\Sigma}_{i,t-1})^{-1}(\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot\\boldsymbol{c}_{\\tau})/\\sqrt{m}\\rVert_{\\boldsymbol{\\Sigma}_{i,t-1}}}\\\\ &{\\qquad\\qquad\\qquad=m^{-1/2}\\lVert\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot\\boldsymbol{c}_{\\tau}/\\sqrt{m}\\rVert_{(\\boldsymbol{\\Sigma}_{i,t-1})^{-1}}}\\\\ &{\\qquad\\qquad\\leq m^{-1/2}\\displaystyle\\sum_{\\tau\\in[t-1]}w_{i,t}^{(\\tau)}\\boldsymbol{c}_{\\tau}\\cdot\\lVert g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})/\\sqrt{m}\\rVert_{(\\boldsymbol{\\Sigma}_{i,t-1})^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where the first inequality is by applying the triangular inequality. By definition, we naturally have $\\mathbf{\\Sigma}_{\\Sigma_{i,t-1}}\\succeq\\,\\bar{\\mathbf{\\Sigma}}_{\\tau-1}^{(\\bar{\\kappa})},\\breve{\\forall}\\tau\\ \\in\\ [t-\\bar{1}]$ . Next, we utlize Lemmas G.8 and the fact that $w_{t}^{\\mathsf{m i n}}\\,=$ $\\operatorname*{min}\\{w_{i,t}^{(\\tau)}\\}_{i\\in[K],\\tau\\in[t-1]}=\\kappa^{2}<1$ $\\forall t\\in[T]$ by scaling the parameter $\\alpha$ wWhich will lead to ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{m^{-1/2}\\lVert(\\boldsymbol{\\Sigma}_{i,t-1})^{-1}\\rVert\\sum_{\\tau\\in[t-1]}\\ w_{i,t}^{(\\tau)}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot c_{\\tau})/\\sqrt{m}\\lVert\\boldsymbol{\\Sigma}_{i,t-1}}&{}\\\\ &{\\qquad\\leq\\mathcal{O}(m^{-1/2})\\underset{\\tau\\in[t-1]}{\\sum}w_{i,t}^{(\\tau)}c_{\\tau}\\cdot\\lVert g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})/\\sqrt{m}\\rVert_{(\\mathbb{S}_{i,t-1})^{-1}}}\\\\ &{\\leq\\mathcal{O}(m^{-1/2})\\underset{\\tau\\in[t-1]}{\\sum}w_{i,t}^{(\\tau)}c_{\\tau}\\cdot\\lVert g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})/\\sqrt{m}\\rVert_{(\\mathbb{S}_{i-1}^{(s)})^{-1}}}\\\\ &{\\leq\\mathcal{O}(m^{-1/2})\\underset{\\tau\\in[t-1]}{\\sum}\\underset{\\tau\\in[t-1]}{\\sum}\\frac{\\alpha\\cdot\\operatorname*{min}\\lVert g(\\boldsymbol{x};\\boldsymbol{\\theta}_{i,t-1})/\\sqrt{m}\\rVert_{\\Sigma_{t-1}^{1}}}{\\lVert g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})/\\sqrt{m}\\rVert_{\\Sigma_{t-1}^{1}}}}\\\\ &{\\leq\\mathcal{O}(m^{-1/2})\\cdot\\mathcal{C}\\underset{\\tau\\in[t-1]}{\\sum}\\frac{\\alpha\\cdot\\operatorname*{min}\\lVert g(\\boldsymbol{x};\\boldsymbol{\\theta}_{i,t-1})/\\sqrt{m}\\rVert_{\\Sigma_{t-1}^{1}}}{\\lVert g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})/\\sqrt{m}\\rVert_{\\Sigma_{t-1}^{1}}}}\\\\ &{\\leq\\mathcal{O}(m^{-1/2})\\cdot C\\cdot\\frac{\\alpha\\cdot\\operatorname*{min}\\lVert g(\\boldsymbol{x})_{i}\\rVert_{L^{1}}}{\\lVert g(\\boldsymbol{x}_{i,t};\\boldsymbol{\\theta}_{i,t-1})/\\sqrt{m}\\rVert_{\\Sigma_{t-1}^{1}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where the third and the last inequalities are due to the definition of $w_{i,t}^{(\\tau)}$ and the definition of corruption level $C$ . Finally, summing up all the results will give the lemma. ", "page_idx": 47}, {"type": "text", "text": "C.9Discussion on the Minimum Fraction Value $\\beta$ ", "text_level": 1, "page_idx": 47}, {"type": "text", "text": "In this subsection, we provide an exemplary upper bound of $\\mathcal{O}(1/\\beta)$ . Inspired by [84], the following analysis is based on a scenario where the arm contexts nearly lie within a low-dimensional subspace of the RKHS, induced by the NTK defined in Definition 5.2. To begin, we recall that, as defined in (4), each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ is associated with the corresponding arm weight: ", "page_idx": 47}, {"type": "equation", "text": "$$\nw_{i,t}^{(\\tau)}=\\operatorname*{min}\\left\\{1,\\frac{\\alpha\\cdot\\operatorname*{min}_{x\\in\\mathcal{X}_{t}}\\Vert g(x;\\theta_{t-1})/\\sqrt{m}\\Vert_{\\bar{\\Sigma}_{t-1}^{-1}}^{2}}{g_{\\tau}\\cdot\\Vert g(x_{i,t};\\theta_{t-1})/\\sqrt{m}\\Vert_{(\\bar{\\Sigma}_{t-1}^{(\\kappa)})^{-1}}}\\right\\}=\\operatorname*{min}\\big\\{1,\\alpha\\cdot\\mathsf{f r a c}_{\\tau}(x_{i,t};\\mathcal{X}_{t},\\bar{\\Sigma}_{t-1})\\big\\},\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where $\\alpha\\,\\,>\\,0$ is a tunable scaling parameter to control the arm weight value range, and frac(-) is a shorthand for the fraction term. We denote the data-dependent minimum fraction value as $\\beta\\,=\\,\\mathrm{min}_{t\\in[T],\\tau\\in[t-1]}\\left[\\mathrm{min}\\left\\{\\mathsf{f r a c}_{\\tau}(x_{t};\\mathcal{X}_{t},\\bar{\\Sigma}_{t-1}),\\mathsf{f r a c}_{\\tau}(\\widetilde{x}_{t};\\dot{\\mathcal{X}}_{t},\\bar{\\Sigma}_{t-1})\\right\\}\\right]$ . In this case, the lower bound for fi $\\mathsf{a c}_{\\tau}(\\pmb{x}_{i,t};\\pmb{\\mathscr{X}}_{t},\\pmb{\\mathscr{\\bar{\\Sigma}}}_{t-1})$ , represented by $\\beta$ , can be expressed as ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}_{t}}\\|g(\\mathbf{x};\\theta_{t-1})/\\sqrt{m}\\|_{\\mathfrak{X}_{t-1}^{-1}}^{2}}{|g(\\boldsymbol{x}_{\\tau};\\theta_{\\tau-1})/\\sqrt{m}||_{(\\overline{{\\mathfrak{X}}}_{\\tau-1}^{(\\kappa)})^{-1}}\\cdot\\|g(\\boldsymbol{x}_{i,t};\\theta_{t-1})/\\sqrt{m}\\|_{(\\overline{{\\Sigma}}_{t-1}^{(\\kappa)})^{-1}}}\\geq\\frac{\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}_{t}}\\|g(\\mathbf{x};\\theta_{t-1})/\\sqrt{m}\\|_{\\mathfrak{X}_{t-1}^{-1}}^{2}}{\\mathcal{O}(L\\cdot\\lambda^{-1})}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\geq\\frac{\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}_{t}}\\|g(\\mathbf{x};\\theta_{t-1})/\\sqrt{m}\\|_{2}^{2}\\cdot\\lambda_{\\operatorname*{min}}(\\mathbf{x};\\theta_{t-1})/\\sqrt{m}\\|_{\\mathfrak{X}_{t-1}^{(\\kappa)}}}{\\mathcal{O}(L\\cdot\\lambda^{-1})}>0,}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "where the first inequality is because of Lemma G.2 and Lemma G.6. The second inequality is by applying Rayleigh-Ritz theorem. ", "page_idx": 47}, {"type": "text", "text": "Then, we let $\\breve{\\mathscr P}_{t-1}\\subseteq\\,\\mathscr P_{t-1}$ being the collection of received records that only consists of unique chosen arms from $\\mathcal{P}_{t-1}$ . With $\\breve{\\theta}_{t-1}$ be the parameters trained on $\\breve{\\mathscr P}_{t-1}$ , applying Lemma G.4 and Lemma G.3, we have $\\begin{array}{r}{\\|g(\\pmb{x}^{\\prime};\\pmb{\\theta}_{t-1})/\\sqrt{m}-g(\\pmb{x}^{\\prime};\\check{\\pmb{\\theta}}_{t-1})/\\sqrt{m}\\|_{2}\\leq\\mathcal{O}(m^{-1/6}\\lambda^{-1/6}t^{1/6}L^{7/2}\\log(m)).}\\end{array}$ where $\\begin{array}{r}{\\pmb{x}^{\\prime}=\\arg\\operatorname*{min}_{\\pmb{x}\\in\\mathcal{X}_{t}}||g(\\pmb{x};\\pmb{\\theta}_{t-1})/\\sqrt{m}||_{2}}\\end{array}$ Given the over-parameterization settings in Theorem 5.6 with sufficiently large $m$ , we can have $\\lVert g(\\pmb{x}^{\\prime};\\pmb{\\theta}_{t-1})/\\sqrt{m}-g(\\pmb{x}^{\\prime};\\breve{\\pmb{\\theta}}_{t-1})/\\sqrt{m}\\rVert_{2}\\ll\\mathcal{O}(1)$ . As a result, it leads to ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}_{t}}\\|g(\\mathbf{x};\\theta_{t-1})/\\sqrt{m}\\|_{\\mathfrak{I}_{t-1}^{-1}}^{2}}{|g(\\boldsymbol{x}_{\\tau};\\theta_{\\tau-1})/\\sqrt{m}||_{(\\mathfrak{I}_{t-1}^{(s)})^{-1}}\\cdot\\|g(\\boldsymbol{x}_{i,t};\\theta_{t-1})/\\sqrt{m}\\|_{(\\mathfrak{I}_{t-1}^{(s)})^{-1}}}\\geq\\frac{\\operatorname*{min}_{\\mathbf{x}\\in\\mathcal{X}_{t}}\\|g(\\mathbf{x};\\theta_{t-1})/\\sqrt{m}\\|_{2}^{2}\\cdot\\lambda_{\\operatorname*{min}}(\\overline{{\\Omega}}_{t-1}^{-1})}{\\mathcal{O}(L\\cdot\\lambda^{-1})}}\\\\ &{\\qquad\\qquad\\geq\\frac{\\left(\\|g(\\mathbf{x}^{\\prime};\\tilde{\\theta}_{t-1})/\\sqrt{m}\\|_{2}^{2}+\\|g(\\mathbf{x}^{\\prime};\\theta_{t-1})/\\sqrt{m}\\|_{2}^{2}-\\|g(\\mathbf{x}^{\\prime};\\tilde{\\theta}_{t-1})/\\sqrt{m}\\|_{2}^{2}\\right)\\cdot\\lambda_{\\operatorname*{min}}(\\overline{{\\Sigma}}_{t-1}^{-1})}{\\mathcal{O}(L\\cdot\\lambda^{-1})}}\\\\ &{\\qquad\\qquad\\geq\\frac{\\mathcal{O}(1)\\cdot\\lambda_{\\operatorname*{min}}(\\overline{{\\Sigma}}_{t-1}^{-1})}{\\mathcal{O}(L\\cdot\\lambda^{-1})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where the second inequality is derived based on $\\lVert g(\\pmb{x}^{\\prime};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\rVert_{2}^{2}\\,-\\,\\lVert g(\\pmb{x}^{\\prime};\\breve{\\pmb{\\theta}}_{t-1})/\\sqrt{m}\\rVert_{2}^{2}\\,\\geq$ $-1\\cdot(\\Vert g({\\pmb x}^{\\prime};{\\pmb\\theta}_{t-1})/\\sqrt{m}-g({\\pmb x}^{\\prime};\\check{{\\pmb\\theta}}_{t-1})/\\sqrt{m}\\Vert_{2}\\cdot\\Vert g({\\pmb x}^{\\prime};{\\pmb\\theta}_{t-1})/\\sqrt{m}+g({\\pmb x}^{\\prime};\\check{{\\pmb\\theta}}_{t-1})/\\sqrt{m}\\Vert_{2}),$ andwe bound the two multipliers separately with choice of $m$ The last inequality is by applying Theorem 3 of [3] with the fact that $f(\\cdot;\\mathbf{\\bar{\\theta}}_{t-1})=\\mathcal{O}(1)$ (Lemma B.2 in [21]). ", "page_idx": 48}, {"type": "text", "text": "Aferwardnwe $\\lambda_{\\mathsf{m i n}}(\\bar{\\Sigma}_{t-1}^{-1})$ Since $\\begin{array}{r}{\\lambda_{\\operatorname*{min}}(\\bar{\\Sigma}_{t-1}^{-1})=\\frac{1}{\\lambda_{\\operatorname*{max}}\\left(\\bar{\\Sigma}_{t-1}\\right)}}\\end{array}$ ,wened to find the upper bound for $\\|\\bar{\\Sigma}_{t-1}\\|_{2}$ . Denoting $\\mathbf{G}_{t-1}^{(0)}=[g(\\pmb{x}_{1};\\pmb{\\Theta}_{0}),g(\\pmb{x}_{2};\\pmb{\\Theta}_{0}),\\dots,g(\\pmb{x}_{t-1};\\pmb{\\Theta}_{0})]^{\\intercal}\\in$ $\\mathbb{R}^{(t-1)\\times p}$ as the gradient matrix, as well as $\\mathbf{H}_{t-1}\\in\\mathbb{R}^{(t-1)\\times(t-1)}$ as the NTK matrix constructed from the chosen arms $\\{x_{\\tau}\\}_{\\tau\\in[t-1]}$ , with sufficient network width $m$ (Theorem 5.6), we first have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\|\\mathbf{G}_{t-1}^{(0)}(\\mathbf{G}_{t-1}^{(0)})^{\\top}/m-\\mathbf{H}_{t-1}\\|_{2}\\leq\\mathcal{O}(1)\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "and this inequality is because of Lemma B.1 in [86] by setting $\\epsilon=t-1$ . In this case, we will have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\mathbf{\\Sigma}}_{t-1}\\|_{2}-\\lambda_{\\operatorname*{max}}(\\mathbf{H}_{t-1})\\leq\\|\\bar{\\mathbf{\\Sigma}}_{t-1}\\|_{2}-\\|(\\mathbf{G}_{t-1}^{(0)})^{\\top}\\mathbf{G}_{t-1}^{(0)}/m\\|_{2}+\\|\\mathbf{G}_{t-1}^{(0)}(\\mathbf{G}_{t-1}^{(0)})^{\\top}/m\\|_{2}-\\lambda_{\\operatorname*{max}}(\\mathbf{H}_{t-1})}\\\\ &{\\qquad\\qquad\\qquad\\leq\\|\\bar{\\mathbf{\\Sigma}}_{t-1}-(\\mathbf{G}_{t-1}^{(0)})^{\\top}\\mathbf{G}_{t-1}^{(0)}/m\\|_{2}+\\|\\mathbf{G}_{t-1}^{(0)}(\\mathbf{G}_{t-1}^{(0)})^{\\top}/m-\\mathbf{H}_{t-1}\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-1/6})+\\mathcal{O}(\\lambda)+\\mathcal{O}(1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where the last inequality is by applying Lemma G.6. This leads to the result that $\\|\\bar{\\Sigma}_{t-1}\\|_{2}\\leq$ $\\lambda_{\\operatorname*{max}}(\\mathbf{H}_{t-1})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-1/6})+\\mathcal{O}(\\lambda)+\\mathcal{O}(1)$ ", "page_idx": 48}, {"type": "text", "text": "Then, inspired by Section $\\mathrm{D}$ in [84], based on the formulation from [14] and [20], we can consider that each entry of $\\mathbf{H}_{t-1}$ is generated by ", "page_idx": 48}, {"type": "equation", "text": "$$\n[\\mathbf{H}_{t-1}]_{i,i^{\\prime}}=\\sum_{k=0}^{\\infty}\\mu_{k}\\sum_{j=1}^{N(d,k)}Y_{k,j}({\\pmb x}_{i})Y_{k,j}({\\pmb x}_{i^{\\prime}}),\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "where $Y_{k,j}$ are linearly independent spherical harmonics, w.r.t. degree $k$ and $d$ variables. $N(d,k)=$ $\\begin{array}{r}{\\frac{2k+d-2}{k}\\cdot\\overset{\\cdot}{C}_{k+d-3}^{d-2},\\mu_{k}=\\Theta(\\operatorname*{max}\\{k^{-d},(d-1)^{1-k}\\})}\\end{array}$ With the above feature mapping, if we have a subspace of the RKHS, such that the feature mapping in the RKHS is close enough to its projection onto this subspace, we can have $\\lambda_{\\operatorname*{max}}(\\mathbf{H}_{t-1})\\bar{=}\\,\\|\\bar{\\mathbf{H}}_{t-1}\\|_{2}\\leq\\mathcal{O}(1)$ . As a result, summing up the results and with suffciently large $m$ , we can have $\\begin{array}{r}{\\frac{1}{\\beta}\\leq\\mathcal{O}(L\\lambda^{-1})}\\end{array}$ ", "page_idx": 48}, {"type": "text", "text": "D  Bounding the Difference of Trained Parameters and Regression Parameters ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "In section, with weighted Gradient Descent, we provide the upper bound in terms of the distance betweenGDtrained pramters $\\pmb\\theta_{t-1}$ and theregresionprameters $(\\boldsymbol{\\Sigma}_{t-1}^{(0)})^{-1}\\boldsymbol{b}_{t-1}^{(0)}$ be applied to the proof flow of both NeuralUCB-WGD and R-NeuralUCB. First, with the definitions ", "page_idx": 48}, {"type": "text", "text": "in Subsec. C.2, we have the gradient-based regression parameters specified to arm $\\mathbf{\\boldsymbol{x}}_{t}\\in\\mathcal{X}_{t}$ as ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\Sigma_{t-1}^{(0)}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}g(x_{\\tau};\\theta_{0})g(x_{\\tau};\\theta_{0})^{\\top}/m,}\\\\ {\\displaystyle\\Sigma_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}g(x_{\\tau};\\theta_{\\tau-1})g(x_{\\tau};\\theta_{\\tau-1})^{\\top}/m,}\\\\ {\\displaystyle b_{t-1}^{(0)}=\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}g(x_{\\tau};\\theta_{0})\\cdot r_{\\tau}/\\sqrt{m},\\ ~~~~~~~~~~~~~~~~~~~b_{t-1}=\\sum_{\\tau\\in[t-1]}w_{t}^{(\\tau)}g(x_{\\tau};\\theta_{\\tau-1})\\cdot r_{\\tau}/\\sqrt{m}}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $\\{\\pmb{x}_{\\tau},r_{\\tau}\\},\\tau\\in[t]$ respectively stands for the chosen arms as well as their rewards. For notation simplicity, we also use $w_{t}^{(\\tau)},\\tau\\in[t-1]$ to denote the arm weights for the chosen arm $\\pmb{x}_{t}$ respectively. Analogously given an candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ with arm weight defined in (4), we have a eries auxiliary gradient sequences $\\{\\Theta^{(0)},\\Theta^{(1)},\\dots,\\Theta^{(J)}\\}$ as in G.3, such that for $j$ -th iteration ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta^{(j+1)}=\\Theta^{(j)}-\\eta\\cdot\\left[\\mathbf{J}^{(0)}\\cdot\\mathbf{W}\\cdot\\left([\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\theta_{0})-y\\right)+m\\lambda(\\Theta^{(j)}-\\theta_{0})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $\\mathbf{J}^{(0)}:=\\left(g(\\pmb{x}_{1};\\pmb{\\theta}_{0}),g(\\pmb{x}_{2};\\pmb{\\theta}_{0}),\\dots,g(\\pmb{x}_{t-1};\\pmb{\\theta}_{0})\\right)\\in\\mathbb{R}^{p\\times(t-1)}$ and W refers to the diagonal matrixof arm weights $\\{w_{i,t}^{(\\tau)}\\}_{\\tau\\in[t-1]}$ along with th reward vectors $\\pmb{y}\\in\\mathbb{R}^{t-1}$ separately eing the vector of received rewards and corruption-free rewards. In particular, the auxiliary sequence $\\Theta^{(j)}$ can be deemed as applying Gradient Descent to solve the following optimization problem ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\Theta}\\mathcal{L}(\\Theta)=\\sum_{\\tau\\in[t-1]}\\frac{1}{2}\\cdot w_{i,t}^{(\\tau)}\\cdot\\left\\|[\\mathbf{J}^{(0)}]_{\\tau}^{\\top}(\\Theta-\\theta_{0})-y_{\\tau}\\right\\|_{2}^{2}+\\frac{1}{2}\\cdot m\\lambda\\cdot\\left\\|\\Theta-\\theta_{0}\\right\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where $[\\mathbf{J}^{(0)}]_{\\tau}$ refers to the $\\tau$ -th column of the matrix $\\mathbf{J}^{(0)}$ . Analogously, we can also derive the optimization problem for the sequence of corruption-free auxiliary parameters $\\widetilde{\\Theta}^{(j)}$ , by applying the same definition of weight matrix $\\mathbf{W}$ . By the definition of arm weights, we will also have $\\bar{\\|\\mathbf{W}\\|}\\bar{\\|_{2}}\\bar{\\leq}1$ ", "page_idx": 49}, {"type": "text", "text": "Lemma D.1 (Lemma B.2 of [86]). With the notation and conditions in Theorem 5.6, consider $m\\geq\\Omega(p o l y(T,L,\\check{\\lambda}_{0}^{-1},\\lambda^{-1})$ $\\begin{array}{r}{\\eta\\le{\\mathcal O}(\\frac{1}{m\\lambda+t m L})}\\end{array}$ Foround $t\\in[T]$ wehave ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\theta_{t-1}-\\theta_{0}-(\\Sigma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\leq(1-\\eta m\\lambda)^{J/2}\\sqrt{t/(m\\lambda)}+\\mathcal{O}(m^{-2/3}t^{5/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "withthe $J$ iterations of Gradient Descent process ", "page_idx": 49}, {"type": "text", "text": "Proof. The proof of this lemma follows an analogous approach as in Lemma B.2 of [86]. Here, similar tothe previous sequence $\\{\\Theta^{(0)},\\Theta^{(1)},\\dots,\\Theta^{(\\bar{J})}\\}$ we denote another set of auxiliary sequences to simulatethe $J$ iterations of GD,by ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\pmb{\\theta}^{(j+1)}=\\pmb{\\theta}^{(j)}-\\eta\\cdot\\left[\\mathbf{J}^{(j)}\\cdot\\mathbf{W}\\cdot\\left(\\pmb{f}^{(j)}-\\pmb{y}\\right)+m\\lambda(\\pmb{\\theta}^{(j)}-\\pmb{\\theta}_{0})\\right]\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where we denote the corresponding gradient matrix at the $j$ -th  iteration  as $\\begin{array}{r l}{\\mathbf{J}^{(j)}}&{{}=}\\end{array}$ $\\left\\langle g(\\pmb{x}_{1};\\pmb{\\theta}^{(j)}),g(\\pmb{x}_{2};\\pmb{\\theta}^{(j)}),\\dots,g(\\bar{\\pmb{x}}_{t-1};\\pmb{\\theta}^{(j)})\\right\\rangle\\;\\in\\;\\mathbb{R}^{p\\times(t-1)}$ , as well as the vector of network outputs $\\pmb{f}^{(j)}\\,=\\,\\big(f(\\pmb{x}_{1};\\pmb{\\theta}^{(j)}),f(\\pmb{x}_{2};\\pmb{\\theta}^{(j)}),\\dots,f(\\pmb{x}_{t-1};\\pmb{\\theta}^{(j)})\\big)\\,\\in\\,\\mathbb{R}^{t-1}$ . In this case, we can have the difference between parameter sequences as ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta^{(j+1)}-\\Theta^{(j+1)}\\|}\\\\ &{=\\|(1-\\eta m\\lambda)\\cdot(\\theta^{(j)}-\\Theta^{(j)})-\\eta\\mathbf{W}(\\mathbf{J}^{(j)}-\\mathbf{J}^{(0)})(f^{(j)}-y)-\\eta\\mathbf{W}(f^{(j)}-[\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\theta_{0}))\\|}\\\\ &{\\leq\\|(1-\\eta m\\lambda)\\cdot(\\theta^{(j)}-\\Theta^{(j)})\\|+\\eta\\|\\mathbf{W}(\\mathbf{J}^{(j)}-\\mathbf{J}^{(0)})(f^{(j)}-y)\\|+\\eta\\|\\mathbf{J}^{(0)}\\mathbf{W}(f^{(j)}-[\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\mathbb{J}^{(0)})}\\\\ &{\\leq\\|(1-\\eta m\\lambda)(\\theta^{(j)}-\\Theta^{(j)})\\|+\\eta\\|\\mathbf{W}\\|\\|(\\mathbf{J}^{(j)}-\\mathbf{J}^{(0)})(f^{(j)}-y)\\|+\\eta\\|\\mathbf{J}^{(0)}\\mathbf{W}\\|\\|f^{(j)}-[\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\mathbb{J}^{(0)})}\\\\ &{\\leq\\underbrace{\\|(1-\\eta m\\lambda)\\cdot(\\theta^{(j)}-\\Theta^{(j)})\\|}_{I_{4}}+\\underbrace{\\eta\\cdot\\|(\\mathbf{J}^{(j)}-\\mathbf{J}^{(0)})(f^{(j)}-y)\\|}_{I_{5}}+\\underbrace{\\eta\\cdot\\|\\mathbf{J}^{(0)}\\|\\|f^{(j)}-[\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\mathbb{J}^{(0)})}_{I_{6}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where the frst inequality is by applying the triangular inequality. The second inequality is by using Cauchy-Schwartz inequality, and the third inequality is due to the fact that $\\lVert\\mathbf{W}\\rVert_{2}\\bar{\\leq}1$ .Here, the first term $I_{4}$ can be bounded recursively. For the second term $I_{5}$ on the RHS, we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\mathbf{\\dot{\\rho}}_{5}=\\eta\\|(\\mathbf{J}^{(j)}-\\mathbf{J}^{(0)})(f^{(j)}-y)\\|\\leq\\eta\\|(\\mathbf{J}^{(j)}-\\mathbf{J}^{(0)})\\|\\|(f^{(j)}-y)\\|\\leq\\mathcal{O}(\\eta t^{7/6}m^{1/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-1}).\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "by extending Lemma G.4 to the matrx $\\mathbf{J}$ Since we have the arm weights $w_{i,t}^{(\\tau)}\\le\\mathcal{O}(1)$ dueto the maximum cap as well as the choice of parameter $\\alpha$ , we can also directly apply the conclusion of Lemma C.3 in [86] for the second inequality. Meanwhile, for the third term $I_{6}$ , we will have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{6}=\\eta\\cdot\\Vert\\mathbf{J}^{(0)}\\Vert\\Vert f^{(j)}-[\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\theta_{0})\\Vert}\\\\ &{\\quad\\leq\\eta\\cdot\\Vert\\mathbf{J}^{(0)}\\Vert\\cdot\\underset{\\tau\\in[t-1]}{\\operatorname*{max}}\\sqrt{t}\\cdot|f(x_{\\tau};\\theta^{j})-f(x_{\\tau};\\theta_{0})-\\langle g(x_{\\tau};\\theta_{0}),\\theta^{j}-\\theta_{0}\\rangle|}\\\\ &{\\quad\\leq\\mathcal{O}(\\eta t^{5/3}m^{1/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-2/3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "by extending Lemma G.2 to the gradient matrix setting, as well as applying the Lemma G.5 on the absolute value. Afterwards, we can integrate these three terms, which will lead to ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta^{(j+1)}-\\Theta^{(j+1)}\\|\\leq\\|(1-\\eta m\\lambda)\\cdot(\\theta^{(j)}-\\Theta^{(j)})\\|}\\\\ &{\\qquad\\qquad\\qquad+\\mathcal{O}(\\eta t^{7/6}m^{1/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-1/6})+\\mathcal{O}(\\eta t^{5/3}m^{1/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-2/3})}\\\\ &{\\leq(1-\\eta m\\lambda)\\|\\theta^{(j)}-\\Theta^{(j)}\\|+\\mathcal{O}(\\eta t^{7/6}m^{1/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-1/6})+\\mathcal{O}(\\eta t^{5/3}m^{1/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-1/6})}\\\\ &{\\leq\\mathcal{O}(m^{-2/3}t^{5/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where for term $I_{4}$ , the last inequality is obtained by recursively applying the process to $\\lVert\\pmb{\\theta}^{(0)}-$ $\\Theta^{(0)}\\|=0$ and substituting the chosen upperbound for thelearning rate $\\eta$ . Then, with a sufficiently large network width $m$ as indicated in the lemma, we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\theta_{t-1}-\\theta_{0}-(\\Sigma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}\\|_{2}\\le\\|\\theta^{(j+1)}-\\Theta^{(j+1)}\\|+\\|\\Theta^{(j+1)}-\\theta_{0}-(\\Sigma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}\\|_{2}}\\\\ &{\\quad\\quad\\quad\\leq\\|\\Theta^{(j+1)}-\\theta_{0}-(\\Sigma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}\\|_{2}+{\\mathcal O}(m^{-2/3}t^{5/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\\\ &{\\quad\\quad\\quad\\leq(1-\\eta m\\lambda)^{j/2}\\sqrt{t/(m\\lambda)}+{\\mathcal O}(m^{-2/3}t^{5/3}\\sqrt{\\log(m)}L^{7/2}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where the frst inequality is by applying triangular inequality, and the second inequality is by applying $\\|\\pmb{\\theta}^{(j+1)}-\\pmb{\\Theta}^{(j+1)}\\|\\,\\le\\sqrt{t/(m\\lambda)}$ $w_{i,t}^{(\\tau)}\\leq1$ ", "page_idx": 50}, {"type": "text", "text": "E A Base Algorithm: NeuralUCB-WGD ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Recall that for each candidate arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ , its corruption-free expected reward is generated by an unknown reward mapping function $h(\\cdot)$ . Following existing neural bandit approaches, we use a neural network $f(\\cdot)$ to approximate $h(\\cdot)$ for estimating arm rewards. Consistent with the main text and R-NeuralUCB, we consider the network $f(\\cdot;\\pmb\\theta)$ to be a fully connected (FC) network with depth $L\\ge2$ and width $m\\in\\mathbb{N}^{+}$ ", "page_idx": 51}, {"type": "equation", "text": "$$\nf(\\pmb{x};\\pmb{\\theta}):=\\sqrt{m}\\pmb{\\theta}_{L}\\sigma(\\pmb{\\theta}_{L-1}\\sigma(\\pmb{\\theta}_{L-2}\\ldots\\sigma(\\pmb{\\theta}_{1}\\pmb{x}))),\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "where $\\sigma(\\cdot)$ denotes the ReLU activation function, and the trainable weight matrices are $\\pmb{\\theta}_{1}\\in\\mathbb{R}^{m\\times d}$ $\\pmb{\\theta}_{l}\\,\\in\\,\\mathbb{R}^{m\\times m}$ for $2\\leq l\\leq L-1$ , and $\\pmb{\\theta}_{L}\\,\\in\\,\\mathbb{R}^{1\\times m}$ . For simplicity, we also denote the vectorized parameters as ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\pmb{\\theta}:=[\\mathrm{vec}(\\pmb{\\theta}_{1})^{\\top},\\mathrm{vec}(\\pmb{\\theta}_{2})^{\\top},\\dots,\\mathrm{vec}(\\pmb{\\theta}_{L})]^{\\top}\\in\\mathbb{R}^{p},\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "with dimensionality $p$ and randomly initialized parameters $\\theta_{0}$ . Similar to R-NeuralUCB, we also define $g(\\pmb{x};\\pmb{\\theta})\\ =\\ \\mathrm{vec}(\\nabla_{\\pmb{\\theta}}f(\\pmb{x};\\pmb{\\theta}))\\ \\in\\ \\mathbb{R}^{p}$ as the vectorized network gradients, for input $\\textbf{\\em x}$ and parameters $\\pmb{\\theta}$ ", "page_idx": 51}, {"type": "text", "text": "E.1 NeuralUCB-WGD: Neural-UCB with Weighted GD ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Then, we introduce the workflow of our base algorithm NeuralUCB-WGD (Algorithm 3), which stands for Neural-UCB with Weighted GD. Here, NeuralUCB-WGD can be considered as a simplified version of R-NeuralUCB, where all the candidate arms $\\scriptstyle{\\mathcal{X}}_{t}$ inround $t$ will share the same neural network for decision making. The idea is that although we do not know which training samples are corrupted, we can reduce the effects caused by the potential corruption instead, by paying relatively more attention on the samples with low uncertainty for a stable training process. ", "page_idx": 51}, {"type": "text", "text": "Algorithm 3 Neural-UCB with Weighted GD (NeuralUCB-WGD) ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "1: Input: Time horizon $T$ . GD steps $J$ . Learning rate $\\eta$ . Exploration coefficient $\\nu\\geq0$ . Scaling coefficient $\\alpha>0$ Norm parameter $S$ , regularization parameter $\\lambda$   \n2: Initialization: Initialized parameters $\\theta_{0}$ . Covariance matrix $\\mathbf{\\Gamma}\\Gamma_{0}=\\lambda\\mathbf{I}$ . Received records $\\mathcal{P}_{0}=\\varnothing$   \n3: for each round $t\\in[T]$ do   \n4: Observe candidate arms $\\pmb{\\mathcal{X}}_{t}=\\{\\pmb{x}_{i,t}\\}_{i\\in[K]}$   \n5: for each arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ do   \n6: Calculate its benefit score $U(\\pmb{x}_{i,t})$ , based on reward estimation $f(\\pmb{x}_{i,t};\\pmb{\\theta}_{i,t-1})$ and the UCB-type exploration score for arm $\\pmb{x}_{i,t}$ (E.1).   \n7: end for   \n8: Recommend arm based on benefit scores $\\begin{array}{r}{\\pmb{x}_{t}=\\arg\\operatorname*{max}_{\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}}\\left[U(\\pmb{x}_{i,t})\\right]}\\end{array}$   \n9: Receive arm reward $r_{t}$ , and update the records, such that $\\mathcal{P}_{t}=\\mathcal{P}_{t-1}\\cup\\{(\\mathbf{x}_{t},r_{t})\\}$ Then, save the corresponding weight for chosen arm $\\pmb{x}_{t}$ , as $w_{t}=\\operatorname*{min}\\lbrace1,\\alpha/\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{\\Gamma_{t-1}^{-1}}\\rbrace$   \n10: Update the gradient covariance matrix $\\mathbf{\\Gamma}_{t}=\\mathbf{r}_{t-1}+w_{t}\\cdot g(\\mathbf{x}_{t};\\pmb{\\theta}_{t-1})\\cdot g(\\mathbf{x}_{t};\\pmb{\\theta}_{t-1})^{\\top}/m$   \n11: Starting from random initialization $\\theta_{0}$ , update the network parameters to $\\pmb{\\theta}_{t}$ , based on $J$ iterations of Gradient Descent and training data $\\mathcal{P}_{t}$ ", "page_idx": 51}, {"type": "text", "text": "12: end for ", "text_level": 1, "page_idx": 51}, {"type": "text", "text": "Arm Selection. In each round $t\\,\\in\\,[T]$ , after observing the candidate arms $\\mathbf{\\mathcal{X}}_{t}$ for selection, we calculate the reward estimation and the UCB score for arm selection (lines 5-7, Algorithm 3). Similar to R-NeuralUCB, in terms of the arm selection (line 8, Algorithm 3), we determine the chosen arm $\\mathbf{\\mathcal{x}}_{t}\\,\\in\\,\\mathcal{X}_{t}$ with the highest benefit score, by $\\pmb{x}_{t}\\,=\\,\\arg\\operatorname*{max}_{\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}}\\left[U(\\pmb{x}_{i,t})\\right]$ . Here, with the NTK norm parameter $S>0$ and the probability at least $1-\\delta$ given probability parameter $\\delta\\,\\in\\,(0,1)$ we formulate the benefit score $\\bar{U}({\\bf{\\boldsymbol{x}}}_{i,t})$ , along with a UCB-type exploration strategy (motivated by Lemma F.1), as ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\tau(x_{i,t})=f(x_{i,t};\\theta_{t-1})+\\mathcal{O}\\big(\\nu\\sqrt{\\log\\frac{\\operatorname*{det}({\\bf T}_{t-1})}{\\operatorname*{det}(\\lambda{\\bf I})}-2\\log(\\delta)}+\\lambda^{1/2}S\\big)\\cdot\\|g(x_{i,t};\\theta_{t-1})/\\sqrt{m}\\|_{\\Gamma_{t-1}^{-1}}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "where $\\pmb\\theta_{t-1}$ refer to network parameters in round $t$ before GD, which have been trained with received records $\\mathcal{P}_{t-1}$ ,and $\\lambda~>~0$ is regularization parameter.  Different from conventional neural bandit works, our gradient covariance matrix is defined as $\\begin{array}{r}{\\mathbf{\\boldsymbol{\\Gamma}}_{t-1}\\;=\\;\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{\\tau}\\mathrm{~.~}}\\end{array}$ $g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m$ . Here, to quantify the arm uncertainty level, inspired by [42], we define the sample weight as $w_{\\tau}=\\operatorname*{min}\\lbrace1,\\bar{\\alpha}/\\|g(\\pmb{\\mathscr{x}}_{\\tau};\\pmb{\\theta}_{\\tau-1})/\\sqrt{m}\\|_{\\Gamma_{\\tau-1}^{-1}}\\rbrace$ based on the gradient vector $g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})=\\mathrm{vec}\\big(\\nabla_{\\pmb{\\theta}}f(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})\\big)\\in\\mathbb{R}^{p}$ , and it is scaled by a tunable parameter $\\alpha>0$ . Notice that the arm weight $w_{\\tau}$ is inversely proportional to our UCB-type exploration score in (E.1). Since the UCB-based exploration score can be considered to quantify reward estimation uncertainty levels [24, 72, 86], we thus assign small weights to training samples with high uncertainty. Recall that in (1), we apply $\\nu$ to characterize the random noise $\\epsilon$ . Similar to R-NeuralUCB, when this value is unknown, we alternatively deem $\\nu\\geq0$ as a tunable exploration parameter to control the exploration intensity analogous to existing works (e.g., [86]). ", "page_idx": 51}, {"type": "text", "text": "", "page_idx": 52}, {"type": "text", "text": "After receiving the reward $r_{t}$ for the chosen arm $\\pmb{x}_{t}$ , we update the records to $\\mathcal{P}_{t}$ . The arm context $\\pmb{x}_{t}$ and its received reward $r_{t}$ are added to the collection $\\mathcal{P}_{t}$ , along with their weight $w_{t}=\\operatorname*{min}\\lbrace1,\\alpha/\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{\\Gamma_{t-1}^{-1}}\\rbrace$ (line 9, Algorithm 3). ", "page_idx": 52}, {"type": "text", "text": "Model Training.Afterwards, we perform $J$ iterations of GD to update the network parameters (line 11, Algorithm 3). With $\\mathcal{P}_{t}=\\bar{\\{\\pmb{x}_{\\tau},r_{\\tau}\\}}_{\\tau\\in[t]}$ up to round $t$ , we train the model parameters $\\pmb{\\theta}_{t}$ through $\\pmb{\\theta}_{t}^{(j)}=\\pmb{\\theta}_{t}^{(j-1)}-\\eta\\nabla_{\\pmb{\\theta}}\\mathcal{L}(\\mathcal{P}_{t};\\pmb{\\theta}_{t}^{(j-1)})$ .Here, $\\pmb{\\theta}_{t}^{(j)},j\\in[J]$ are the prameters afer the $j$ h GDiteratinstin ramltali $\\pmb{\\theta}_{t}^{(0)}=\\pmb{\\theta}_{0}$ and $\\eta>0$ refers to the learning rate. Different from existing neural bandit works (e.g., [86, 84]) which consider all received records to be equally important with the ordinary $L_{2}$ loss function, we alternatively define the weighted loss function as ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\mathcal{L}(\\mathcal{P};\\pmb{\\theta})=\\sum_{(\\pmb{x}_{\\tau},r_{\\tau})\\in\\mathcal{P}}\\frac{w_{\\tau}}{2}\\big|f(\\pmb{x}_{\\tau};\\pmb{\\theta})-r_{\\tau}\\big|^{2}+\\frac{m\\lambda}{2}\\|\\pmb{\\theta}-\\pmb{\\theta}_{0}\\|_{2}^{2}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where $\\lambda>0$ is the regularization parameter as in (E.1), and we have previously defined sample weights $w_{\\tau},\\tau\\in[t]$ associated with each chosen arm-reward pair $(\\mathbf{\\boldsymbol{x}}_{\\tau},r_{\\tau})\\in\\mathcal P_{t}$ . In summary, the intuition is that, when defining the loss function for the received records $\\mathcal{P}_{t}\\,=\\,\\{{\\pmb x}_{\\tau},r_{\\tau}\\}_{\\tau\\in[t]}$ up to round $t$ , we aim to give extra emphasis to samples with low estimation uncertainty. Intuitively, if samples with high uncertainty are indeed corrupted by the adversary, they are more likely to significantly disrupt the internal decision-making process, thereby impacting the stability of reward estimation. To mitigate this risk, even though we cannot identify which training samples are corrupted, we conservatively assign smaller weights to high-uncertainty samples, supporting a stable and robust GD training process. ", "page_idx": 52}, {"type": "text", "text": "E.2 Regret Analysis for NeuralUCB-WGD ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "For the theoretical analysis, different from that of R-NeuralUCB (Subsection 5.1), we focus on the case where the corruption level $C$ is known, a common setting in existing works [16, 42, 76, 17]. This assumption allows us to appropriately select the parameter $\\alpha$ in Algorithm 3 to achieve a tighter regret bound. Additionally, we briefy discuss potential outcomes if $C$ is unknown. Recall that our objective (2) is to minimize the overall pseudo-regret in terms of the corruption-free expected reward over a finite horizon of $T$ rounds: $\\begin{array}{r}{\\dot{R(T)}=\\sum_{t=1}^{\\bar{T}}\\mathbb{E}[\\widetilde{r}_{t}^{*}-\\widetilde{r}_{t}]}\\end{array}$ where $\\mathbb{E}[\\widetilde{r}_{t}]=h(\\pmb{x}_{t})$ denotes the expected corruption-free reward from the chosen arm $\\pmb{x}_{t}$ , and $\\mathbb{E}[\\widetilde{\\boldsymbol{r}}_{t}^{*}]\\,=\\,\\mathrm{max}_{{\\pmb{x}}_{i,t}\\in\\mathcal{X}_{t}}[h({\\pmb{x}}_{i,t})]$ represents the expected reward of the optimal arm. ", "page_idx": 52}, {"type": "text", "text": "To address challenges in regret analysis, we define two sets of regression parameters corresponding to the corrupted model and the corruption-free model. Using the corruption-free model $f(\\cdot;\\widetilde{\\pmb\\theta})$ ,we derive the confidence ellipsoid around its parameters $\\widetilde{\\pmb{\\theta}}$ , which serves as a proxy for updating the confidence ellipsoid around the trained corrupted model parameters $\\pmb{\\theta}$ .With the updated confidence ellipsoid and concentration results, we then finalize the regret upper bound. Here, without carefully designing the arm weights $w_{\\tau},\\tau\\in[t]$ (Algorithm 3) and structuring the regret analysis workflow, deriving the regret upper bound under adversarial corruption settings would be impractical. The following Theorem E.1 provides a bound on the cumulative pseudo-regret for NeuralUCB-WGD. ", "page_idx": 52}, {"type": "text", "text": "Theorem E.1.Given the finite horizon $T\\;\\in\\;\\mathbb{N}^{+}$ ,denote $S\\;\\geq\\;{\\sqrt{2{\\check{h}}^{\\mathsf{T}}{\\check{H}}^{-1}{\\check{h}}}}.$ Suppose probabilityparameter $\\delta~\\in~(0,1)$ networkwidth $m\\ \\geq\\ \\Omega(p o l y(T,L,C,\\check{\\lambda}_{0}^{-1},\\lambda^{-1},S^{-1})\\cdot\\log(1/\\delta))$ $\\eta\\leq\\mathcal{O}((T m L+m\\lambda)^{-1})$ \uff0c $J\\ge\\tilde{\\mathcal{O}}(T L/\\lambda)$ and $\\lambda\\geq S^{-2}$ . Let $f(\\cdot)$ be the $L$ layerFCnetworkwith ", "page_idx": 52}, {"type": "text", "text": "Width $m$ andset $\\alpha=1/C$ withoutthepriorknowledgeof $\\Hat{d}_{\\cdot}$ Then,withprobability at least $1-\\delta$ over random initialization, NeuralUCB-WGD achieves the regret upper bound: ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Im(T)\\le\\ \\widetilde{\\mathcal{O}}\\bigg(\\sqrt{\\widetilde{d}T}\\bigg)\\cdot\\widetilde{\\mathcal{O}}\\bigg(\\nu\\sqrt{\\widetilde{d}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)+\\mathcal{O}\\bigg(C\\widetilde{d}\\log(1+T K/\\lambda)\\bigg)+\\mathcal{O}\\big(C\\widetilde{d}\\cdot\\lambda^{1/2}S\\big)}\\\\ &{\\qquad\\qquad+\\mathcal{O}\\bigg(C\\widetilde{d}\\cdot\\big(\\nu\\sqrt{\\widetilde{d}\\log(1+T K/\\lambda)-2\\log(\\delta)}\\big)\\bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "The proof of Theorem E.1 is provided in Appendix F. The first term on the RHS represents the corruption-independent regret upper bound, which matches the bound $\\widetilde{\\mathcal{O}}(\\widetilde{d}\\sqrt{T})$ in corruptionfree neural bandit studies [86, 84]. For terms that depend on the corruption level $C$ , we obtain $\\tilde{\\mathcal{O}}(C\\tilde{d}\\lambda^{1/2}S+C\\tilde{d}^{3/2})$ by omitting logarithmic terms. When aligning the definition of information gain [16] with the effective dimension d, our results are consistent with the latest kernelized bandit research in terms of the horizon $T$ and effective dimension d, given the NTK-induced RKHS and an indefinite arm space (Corollary 7 in [16]). Additionally, we can bound the NTK norm term $S$ by a constant if $h(\\cdot)$ belongs to the RKHS norm induced by NTK (Subsection B.4). The regularization parameter $\\lambda$ can also be tuned to account for the NTK norm $S$ . Different from the vanilla NeuralUCB [86], we quantify the impact of corruption by deriving a new confidence ellipsoid around the corrupted parameters $\\pmb\\theta_{t-1}$ , ensuring that the corruption-related terms remain independent of the non-logarithmic $T$ term. ", "page_idx": 53}, {"type": "text", "text": "Inspired by [42], when $C$ is unknown to the learner, an estimated corruption level $\\bar{C}>0$ can be utilized based on prior knowledge of the adversary. In this case, we can set the scaling parameter $\\alpha=1/\\bar{C}$ . If the actual $C\\leq\\bar{C}$ , then the corresponding regret upper bound in Theorem 5.6 still holds. Conversely, if $C>\\bar{C}$ , the regret bound will no longer hold, leading to a trivial upper bound of $R(T)\\leq O(T)$ , similar to existing works (e.g., [42]). Here, practically, one approach is to set $\\bar{C}=\\sqrt{T}$ . For $C\\leq\\sqrt{T}$ the overall regret is then bounded by $\\widetilde{\\mathcal{O}}(\\widetilde{d}^{3/2}\\sqrt{T})$ , which matches [16] and improves upon $\\widetilde{\\mathcal{O}}(\\widetilde{d}T)$ from [15]. When $C\\,>\\,{\\sqrt{T}}$ . our trivial regret bound of ${\\mathcal{O}}(T)$ also aligns with the state-of-the-art kernelized method [15] with unknown $C$ , which has a bound of $\\widetilde{\\mathcal{O}}(\\widetilde{d}\\sqrt{T}+C\\widetilde{d}\\sqrt{T})\\implies\\widetilde{\\mathcal{O}}(\\widetilde{d}\\sqrt{T}+\\widetilde{d}T)$ . Thus, the regret bound for NeuralUCB-WGD comparably matches the latest theoretical results from the kernelized bandit research [16, 15] under the indefinite arm space setting. While the problem definition of neural contextual bandits (1) is more general and reduce restrictions from the reward mapping function aspect, it is also significantly distinct from the problem definitions of linear or kernelized bandits, which makes lots of techniques from existing works on tackling adversarial corruptions (e.g., [42, 16]) infeasible. ", "page_idx": 53}, {"type": "text", "text": "F Proof of Regret Bound for NeuralUCB-WGD (Proof of Theorem E.1) ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "By definition in (1), recall that we aim to minimize the pseudo-regret for $T$ rounds, denoted by ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle R(T)=\\sum_{t=1}^{T}\\left[h({\\pmb x}_{t}^{*})-h({\\pmb x}_{t})\\right]=\\sum_{t=1}^{T}R_{t}}}\\\\ {{\\displaystyle=\\sum_{t=1}^{T}\\left[\\langle g({\\pmb x}_{t}^{*};{\\pmb\\theta}_{0}),\\ {\\pmb\\theta}^{*}-{\\pmb\\theta}_{0}\\rangle-\\langle g({\\pmb x}_{t};{\\pmb\\theta}_{0}),\\ {\\pmb\\theta}^{*}-{\\pmb\\theta}_{0}\\rangle\\right]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where $\\pmb{x}_{t}$ is the chosen arm and $\\pmb{x}_{t}^{*}=\\arg\\operatorname*{max}_{\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}}[h(\\pmb{x}_{i,t})]$ being the optimal arm in round $t$ The third equality is due to Lemma C.1. Then, we denote $f(\\cdot)$ as the bandit model we currently possess, which is trained with corrupted records $\\mathcal{P}_{t-1}$ up to round $t$ , and also suppose an imaginary corruption-free bandit model accordingly, which is trained with corruption-free records $\\widetilde{\\mathcal{P}}_{t-1}}$ . The corresponding model parameters of $f(\\cdot)$ will be denoted as $\\pmb{\\theta}$ , while the parameters of the imaginary corruption-free model will be denoted as $\\widetilde{\\pmb{\\theta}}$ ", "page_idx": 53}, {"type": "text", "text": "Proof sketch. To begin with, we first analyze the single-round pseudo-regret $R_{t}$ for $t\\in[T]$ ,wherethe cumulativeregretisgivenby $\\begin{array}{r}{R(T)=\\sum_{t\\in[T]}R_{t}}\\end{array}$ Here, wedemonstrae that the single-round regret with corruption can be upper bounded by using the updated confidence ellipsoid (Lemma F.1) around the corrupted network parameters $\\theta_{t}$ . Since we cannot directly apply the self-regularized martingale concentration results from existing studies [1, 86], we instead derive updated concentration results that account for adversarial corruptions, as shown in Lemma F.2. These results are then combined to establish the cumulative regret over $T$ rounds. Additionally, we provide the optimal value for the scaling parameter $\\alpha$ based on the known corruption level $C$ , demonstrating why setting $\\alpha=1/C$ yields the desired regret bound. ", "page_idx": 53}, {"type": "text", "text": "", "page_idx": 54}, {"type": "text", "text": "F.1  Bounding the Single-round Regret ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "Following analogous approach as the proof of Lemma 5.3 in [86], we can transform the regret for a single round $t\\in[T]$ to ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{I}_{t}=\\langle g(\\pmb{x}_{t}^{*};\\theta_{0}),\\ \\theta^{*}-\\theta_{0}\\rangle-\\langle g(\\pmb{x}_{t};\\theta_{0}),\\ \\theta^{*}-\\theta_{0}\\rangle}\\\\ &{\\quad\\le\\langle g(\\pmb{x}_{t}^{*};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\rangle-\\langle g(\\pmb{x}_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\rangle+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})}\\\\ &{\\quad\\le\\underset{\\theta\\in\\mathcal{C}_{t-1}}{\\operatorname*{max}}\\langle g(\\pmb{x}_{t}^{*};\\theta_{t-1}),\\ \\theta-\\theta_{0}\\rangle-\\langle g(\\pmb{x}_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\rangle+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7}}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "where the first inequality is by the gradient difference in Lemma G.4, and the bound of $\\lVert\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rVert$ in Lemma C.1. Here, based on Lemma F.1, we have the unknown parameter $\\pmb{\\theta}^{*}\\in\\mathcal{C}_{t-1}$ with the confidence ellipsoid $\\mathcal{C}_{t-1}=\\{\\pmb{\\theta}:\\|\\pmb{\\theta}-\\pmb{\\theta}_{t-1}\\|_{\\mathbf{r}_{t-1}^{-1}}\\leq\\gamma_{t-1}/\\sqrt{m}\\}$ induced by our currently possessed parameters $\\pmb\\theta_{t-1}$ as well as the chosen arms $\\{x_{\\tau}\\}_{\\tau\\in[t-1]}$ . Here, with $\\widetilde\\gamma_{t-1}$ being the corresponding corruption-free radius term, we have ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma_{t-1}=\\widetilde\\gamma_{t-1}+\\alpha\\cdot C+(1-\\eta m\\lambda)^{J/2}\\sqrt{t/\\lambda}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\\\ {+\\mathcal{O}(C m^{-2/3}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{7/2})+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-13/6}L^{9/2}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "Then, based on the arm pulling mechanism, we denote the estimated arm benefit score as $U(\\pmb{x}_{i,t})=$ $f(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})+\\gamma_{t-1}\\cdot\\sqrt{g(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})\\pmb{\\top}\\Gamma_{t-1}^{-1}g(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})}$ and we also define its alternative based on the confidence ellipsoid as ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V(x_{i,t})=\\left\\langle g(x_{i,t};\\theta_{t-1}),\\ \\theta_{t-1}-\\theta_{0}\\right\\rangle+\\gamma_{t-1}\\cdot\\sqrt{g(x_{i,t};\\theta_{t-1})\\tau\\Gamma_{t-1}^{-1}g(x_{i,t};\\theta_{t-1})/m}}\\\\ &{\\quad\\quad\\quad=\\underset{\\theta\\in\\mathcal{C}_{t-1}}{\\operatorname*{max}}\\left\\langle g(x_{i,t};\\theta_{t-1}),\\ \\theta-\\theta_{0}\\right\\rangle}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "based on the confidence interval $\\mathcal{C}_{t-1}$ induced by the corrupted parameters $\\pmb\\theta_{t-1}$ . Regarding their distance, we can further derive $|U(\\pmb{x}_{i,t})-V(\\pmb{x}_{i,t})|\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})$ by applying Lemma G.5, as well as the fact that $f(\\pmb{x};\\pmb{\\theta}_{0})=0$ based on random initialization. It then leads to ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{R_{t}\\leq\\underset{\\theta\\in\\mathcal{C}_{t-1}}{\\operatorname*{max}}\\left\\lbrace g(\\mathbf{x}_{t}^{*};\\theta_{t-1}),\\ \\theta-\\theta_{0}\\right\\rbrace-\\left\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\right\\rangle+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-1/6}}I}\\\\ &{\\quad=V(\\mathbf{x}_{t}^{*})-\\left\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\right\\rangle+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-1/6}}I^{2/7})}\\\\ &{\\quad\\leq U(\\mathbf{x}_{t}^{*})-\\left\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\right\\rangle}\\\\ &{\\quad\\quad\\quad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-1/6}}I^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)t^{2/3}\\lambda^{-2/3}}I^{3})}\\\\ &{\\quad\\quad\\leq U(\\mathbf{x}_{t})-\\left\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\right\\rangle}\\\\ &{\\quad\\quad\\quad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-1/6}}I^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)t^{2/3}\\lambda^{-2/3}}I^{3})}\\\\ &{\\quad\\quad\\leq V(\\mathbf{x}_{t})-\\left\\langle g(\\mathbf{x}_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\right\\rangle}\\\\ &{\\quad\\quad\\quad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-1/6}}I^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)t^{2/3}\\lambda^{-2/3}}I^{3})}\\\\ &{\\quad\\quad\\quad\\quad\\quad\\quad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)t^{1/6}\\lambda^{-1/6}}I^{2/7} \n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "where the third inequality is due to the arm pulling mechanism. The second and the fourth inequality is due to the distance between $V(\\cdot)$ and $U(\\cdot)$ .Sincewehave $\\pmb{\\theta}^{*}\\in\\mathcal{C}_{t-1}$ , by Holder's inequality, it ", "page_idx": 54}, {"type": "text", "text": "will further lead to ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{X}_{t}\\le\\underset{\\theta\\in C_{t-1}}{\\operatorname*{max}}\\langle g(x_{t};\\theta_{t-1}),\\ \\theta-\\theta_{0}\\rangle-\\langle g(x_{t};\\theta_{t-1}),\\ \\theta^{*}-\\theta_{0}\\rangle+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7}}\\\\ &{\\qquad\\qquad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})}\\\\ &{\\quad\\le\\underset{\\theta\\in C_{t-1}}{\\operatorname*{max}}\\ \\Vert g(x_{t};\\theta_{t-1})\\Vert_{\\Gamma_{t-1}^{-1}}\\cdot\\Vert\\theta-\\theta_{0}\\Vert_{\\Gamma_{t-1}}+\\Vert g(x_{t};\\theta_{t-1})\\Vert_{\\Gamma_{t-1}^{-1}}\\cdot\\Vert\\theta^{*}-\\theta_{0}\\Vert_{\\Gamma_{t-1}}}\\\\ &{\\qquad\\qquad+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})}\\\\ &{\\quad\\le2\\gamma_{t-1}\\cdot\\Vert g(x_{t};\\theta_{t-1})/\\sqrt{m}\\Vert_{\\Gamma_{t-1}^{-1}}+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}\\sqrt{\\log(m)}t^{2/3})}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "where the last inequality is due to the definition of confidence ellipsoid $\\mathcal{C}_{t-1}$ . This gives the upper bound for our single-round regret. ", "page_idx": 55}, {"type": "text", "text": "F.2  Bounding the cumulative regret ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "On the other hand, based on the conclusion from Subsec. F.1, the cumulative regret upper bound can be transformed to ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle R(T)=\\sum_{t=1}^{T}\\left[h({\\pmb x}_{t}^{*})-h({\\pmb x}_{t})\\right]=\\sum_{t=1}^{T}R_{t}}\\\\ {\\displaystyle\\leq\\sum_{t=1}^{T}\\left[2\\cdot\\operatorname*{min}\\left\\{\\gamma_{t-1}\\cdot\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\|_{{\\pmb\\Gamma}_{t-1}^{-1}},\\,1\\right\\}+\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})\\right.}\\\\ {\\displaystyle\\left.\\qquad\\qquad+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}t^{2/3}\\lambda^{-2/3}L^{3})\\right]}\\\\ {\\displaystyle\\leq\\sum_{t=1}^{T}\\left[2\\cdot\\operatorname*{min}\\left\\{\\gamma_{t-1}\\cdot\\|g({\\pmb x}_{t};{\\pmb\\theta}_{t-1})/\\sqrt{m}\\|_{{\\pmb\\Gamma}_{t-1}^{-1}},\\,1\\right\\}\\right]+\\mathcal{O}(1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "where the last inequality is because of sufficiently large network width $m$ that satisfies conditions in Theorem E.1. Then, for the first term on the RHS, we can further have ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sum_{j=1}^{n}\\operatorname*{min}\\left\\{\\gamma_{j}\\cdots\\lVert\\tilde{\\mathbf{x}}(\\mathbf{r},\\theta_{j-1})_{j}\\rVert\\sqrt{n}\\rVert_{F_{p,\\theta}^{n}(\\cdot),1}\\right\\}}\\\\ &{\\le2\\:\\operatorname*{max}\\left\\{2\\:T\\mathrm{i}T\\mathrm{i}R(1+T K);\\theta+(1+\\frac{\\gamma}{\\theta_{j}})\\cdot\\tilde{\\mathbf{d}}_{j}\\mathrm{for}(1+T K/\\lambda)\\right\\}}\\\\ &{\\le2\\:\\operatorname*{min}\\{1+T K/\\lambda)+2\\gamma\\cdot\\left(\\sqrt{2\\pi}\\mathrm{Re}(1+T K/\\lambda)+\\frac{1}{\\theta_{j}}\\cdot\\tilde{\\mathbf{d}}_{j}\\mathrm{for}(1+T K/\\lambda)\\right)}\\\\ &{\\le\\tilde{\\lambda}\\mathrm{Re}{\\mu}_{1}+T K/\\lambda)+\\left(\\sqrt{2\\pi}\\mathrm{Re}(1+T K/\\lambda)+\\frac{1}{\\theta_{j}}\\cdot\\tilde{\\mathbf{d}}_{j}\\mathrm{for}(1+T K/\\lambda)\\right)}\\\\ &{\\quad\\cdot\\left(\\mathcal{R}_{j-1}+2\\:x<{\\pm}+2(1-\\phi_{0})^{1/2}\\right)\\sqrt{\\eta}\\sqrt{\\lambda}+\\mathcal{O}((1-^{n-1})^{n}\\sqrt{\\lambda}\\mathrm{Re}(1)Z^{n}\\lambda^{-3-3(1)}+(\\sqrt{\\lambda}))}\\\\ &{\\qquad+\\mathcal{O}({C}_{n}-{\\lambda})\\sqrt{8}\\mathrm{Re}(1)\\theta^{3}\\lambda^{-2(1)}\\sqrt{\\eta}\\sqrt{\\lambda}+\\mathcal{O}({C}_{n}-{\\lambda}^{-1/n-\\sqrt{\\lambda}}\\mathrm{Re}(1)\\theta^{2}\\lambda^{-3-3(1)}\\mathrm{Re}^{-3\\lambda(2)})}\\\\ &{\\le\\tilde{\\lambda}\\mathrm{Re}{\\mu}_{1}+T K/\\lambda)+\\left(\\sqrt{2\\pi}\\mathrm{Re}(1+T K/\\lambda)+\\frac{1}{\\theta_{j}}\\cdot\\tilde{\\mathbf{d}}_{j}\\mathrm{Re}(1+T K/\\lambda)\\right)}\\\\ &{\\qquad+\\left(\\sqrt{2}\\sqrt{\\eta}\\mathrm{Re}(1+T K/\\lambda)-2\\log(\\lambda)+\\lambda^{1/2}\\right)\\le2\\alpha\\cdot\\mathcal{O}(\\mathcal{Z})}\\\\ &{\\qquad+2(1-\\cos^{2})^{n}\\sqrt{(\\eta}\\sqrt{\\lambda}+\\\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "where the first inequality is due to Lemma F.2, and the second inequality is due to Lemma F.1. The third inequality can be derived following an analogous approach as Lemma 5.2 in [86], and the last inequality is due to the sufficiently large network width $m$ as mentioned in Theorem E.1, as well as the suficient number of GD iterations $J=\\widetilde{\\cal O}(T L/\\lambda)$ ", "page_idx": 56}, {"type": "text", "text": "Discussion on the value of $\\alpha$ . Here, notice that we have the tunable parameter $\\alpha>0$ nested in the regret bound. Taking some more steps, we can have ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t=1}^{T}2\\operatorname*{min}\\left\\{\\gamma_{t-1}\\cdot\\|g({\\boldsymbol x}_{t};{\\boldsymbol\\theta}_{t-1})/\\sqrt{m}\\|_{\\mathbf{r}_{t-1}^{-1}},\\,1\\right\\}}\\\\ &{\\qquad\\qquad\\leq\\left(\\sqrt{\\tilde{d}T\\log(1+T K/\\lambda)}+\\frac{1}{\\alpha}\\cdot\\tilde{d}\\log(1+T K/\\lambda)\\right)}\\\\ &{\\qquad\\qquad\\qquad\\cdot\\mathcal{O}\\bigg(\\nu\\sqrt{\\tilde{d}\\log(1+T K/\\lambda)-2\\log(\\delta)}+\\lambda^{1/2}S+2\\alpha\\cdot C\\bigg)}\\\\ &{\\qquad\\qquad\\leq\\tilde{O}\\bigg(\\sqrt{\\tilde{d}T}+\\frac{1}{\\alpha}\\cdot\\tilde{d}\\bigg)\\cdot\\bigg(\\nu\\sqrt{\\tilde{d}-2\\log(\\delta)}+\\lambda^{1/2}S+2\\alpha\\cdot C\\bigg)}\\\\ &{\\qquad\\qquad\\leq\\tilde{O}\\bigg(\\sqrt{\\tilde{d}T}+\\frac{1}{\\alpha}\\cdot\\tilde{d}\\bigg)\\cdot\\bigg(\\nu\\sqrt{\\tilde{d}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)+\\tilde{O}\\bigg(\\alpha C\\sqrt{\\tilde{d}T}+C\\tilde{d}\\bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Since we have no prior knowledge of effective dimension $\\hat{d}$ wecan set $\\begin{array}{r}{\\alpha=\\frac{1}{C}}\\end{array}$ . It will then lead to ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t=1}^{T}2\\operatorname*{min}\\bigg\\{\\gamma_{t-1}\\cdot\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{\\mathbf{F}_{t-1}^{-1}},\\,1\\bigg\\}}}\\\\ &{\\leq\\widetilde{\\mathcal{O}}\\bigg(\\sqrt{\\widetilde{d}T}+\\frac{1}{\\alpha}\\cdot\\widehat{d}\\bigg)\\cdot\\bigg(\\nu\\sqrt{\\widetilde{d}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)+\\widetilde{\\mathcal{O}}\\bigg(\\alpha C\\sqrt{\\widetilde{d}T}+C\\widehat{d}\\bigg)}\\\\ &{\\leq\\widetilde{\\mathcal{O}}\\bigg(\\sqrt{\\widetilde{d}T}\\bigg)\\cdot\\bigg(\\nu\\sqrt{\\widetilde{d}-2\\log(\\delta)}+\\lambda^{1/2}S\\bigg)+\\widetilde{\\mathcal{O}}\\bigg(C\\widetilde{d}+C\\widetilde{d}\\cdot\\big(\\nu\\sqrt{\\widetilde{d}-2\\log(\\delta)}+\\lambda^{1/2}S\\big)\\bigg).}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Finally, summing up all the results above will give the conclusion. ", "page_idx": 56}, {"type": "text", "text": "F.3 Confidence ellipsoid for corrupted parameters ", "text_level": 1, "page_idx": 56}, {"type": "text", "text": "Lemma F.1. With the notation and conditions in Theorem E.1, train the network parameters $\\pmb\\theta_{t-1}$ based onreceived records $\\mathcal{P}_{t-1}$ . The confidence ellipsoid around the corrupted network parameters $\\pmb\\theta_{t-1}$ canbedefinedas ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\mathcal{C}_{t-1}=\\left\\{\\theta:\\|\\theta-\\theta_{t-1}\\|_{\\Gamma_{t-1}}\\leq\\gamma_{t-1}/\\sqrt{m}\\right\\}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "where we have the unknown parameter $\\pmb{\\theta}^{*}\\in\\mathcal{C}_{t-1}$ ,andwedenote ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma_{t-1}=\\widetilde\\gamma_{t-1}+\\alpha\\cdot C+(1-\\eta m\\lambda)^{J/2}\\sqrt{t/\\lambda}+\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))}\\\\ {+\\mathcal{O}(C m^{-2/3}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-7/6}L^{7/2})+\\mathcal{O}(C m^{-1/6}\\sqrt{\\log(m)}t^{7/6}\\lambda^{-13/6}L^{9/2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Proof. The proof follows an analogous approach as in Lemma C.12. For the imaginary corruption-free parameters $\\ensuremath{\\widetilde{\\pmb{\\theta}}}_{t-1}$ , which are trained on corruption-free records $\\widetilde{\\mathcal{P}}_{t-1}$ , we can construct the confidence interval $\\widetilde{\\mathcal{C}}_{t-1}:=\\{\\pmb{\\theta}:\\|\\pmb{\\theta}-\\widetilde{\\pmb{\\theta}}_{t-1}\\|_{\\widetilde{\\Gamma}_{t-1}}\\leq\\widetilde{\\gamma}_{t-1}/\\sqrt{m},\\widetilde{\\gamma}_{t-1}>0\\}$ such that the unknown $\\pmb{\\theta}^{*}$ in Lemma C.1 satisfies $\\pmb{\\theta}^{*}\\in\\widetilde{\\mathcal{C}}_{t-1}$ . However, since we do not possess $\\widetilde{\\pmb{\\theta}}_{t-1}$ , we need to alternatively derive the confidence ellipsoid $\\mathcal{C}_{t-1}$ around the possessed corrupted parameters $\\pmb\\theta_{t-1}$ , such that $\\pmb{\\theta}^{*}\\in\\mathcal{C}_{t-1}$ ", "page_idx": 56}, {"type": "text", "text": "With the ellipsoid center $\\pmb\\theta_{t-1}$ as well as the weighted gradient covariance matrix $\\boldsymbol{\\Gamma}_{t-1}\\,=\\,\\lambda\\mathbf{I}+$ $\\begin{array}{r l}{\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m}\\end{array}$ , we need to derive the corresponding radius. Recall that $w_{\\tau}$ is the sample weight associated with chosen arm $\\mathbf{\\nabla}x_{\\tau}$ . Here, we first recall some preliminaries that $\\|\\Gamma_{t-1}-\\widetilde\\Gamma_{t-1}\\|_{F}\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-1/6})$ due to Lemma G.6, as well as $\\lVert\\pmb{\\theta}_{t-1}-$ $\\widetilde{\\pmb{\\theta}}_{t-1}\\|_{2}\\leq\\mathcal{O}(\\sqrt{t/(m\\lambda)})$ due to Lemma G.3. ", "page_idx": 56}, {"type": "text", "text": "Next as we already have $\\lVert\\theta-\\widetilde{\\theta}_{t-1}\\rVert_{\\widetilde{\\Gamma}_{t-1}}\\leq\\widetilde{\\gamma}_{t-1}/\\sqrt{m}$ we proced to tranfom the objtive t ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\theta^{*}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}\\leq\\|\\theta^{*}-\\tilde{\\theta}_{t-1}\\|_{\\mathbf{r}_{t-1}}+\\|\\tilde{\\theta}_{t-1}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}}\\\\ &{\\qquad\\leq\\|\\theta^{*}-\\tilde{\\theta}_{t-1}\\|_{\\mathbf{r}_{t-1}}+\\|\\tilde{\\theta}_{t-1}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}}\\\\ &{\\qquad\\leq\\|\\theta^{*}-\\tilde{\\theta}_{t-1}\\|_{\\mathbf{r}_{t-1}-\\tilde{\\mathbf{r}}_{t-1}+\\tilde{\\mathbf{r}}_{t-1}}+\\|\\tilde{\\theta}_{t-1}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}}\\\\ &{\\qquad\\leq\\|\\theta^{*}-\\tilde{\\theta}_{t-1}\\|_{\\tilde{\\mathbf{r}}_{t-1}}+\\|\\theta^{*}-\\tilde{\\theta}_{t-1}\\|_{\\mathbf{r}_{t-1}-\\tilde{\\mathbf{r}}_{t-1}}+\\|\\tilde{\\theta}_{t-1}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}}\\\\ &{\\qquad\\leq\\tilde{\\gamma}_{t-1}/\\sqrt{m}+\\|\\tilde{\\theta}_{t-1}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}+\\mathcal{O}(\\sqrt{t/(m\\lambda)})\\cdot\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-1/6})}\\\\ &{\\qquad\\leq\\tilde{\\gamma}_{t-1}/\\sqrt{m}+\\|\\tilde{\\theta}_{t-1}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}+\\mathcal{O}(m^{-2/3}\\sqrt{\\log(m)}L^{4}t^{13/6}\\lambda^{-2/3}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "For the second term on the RHS, we first define the gradient-based regression parameters as ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{\\Delta}\\Gamma_{t-1}^{(0)}=\\lambda\\mathbf{I}+\\displaystyle\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})^{\\top}/m,}\\\\ &{b_{t-1}^{(0)}=\\displaystyle\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot r_{\\tau}/\\sqrt{m},}\\\\ &{\\widetilde{b}_{t-1}^{(0)}=\\displaystyle\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{0})\\cdot\\widetilde{r}_{\\tau}/\\sqrt{m},}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Then, with the triangular inequality, we can proceed to have ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tilde{\\theta}_{t-1}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}\\leq\\|\\tilde{\\theta}_{t-1}-\\theta_{0}-(\\Gamma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}+(\\Gamma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}+\\theta_{0}-\\theta_{t-1}\\|_{\\mathbf{r}_{t-1}}}\\\\ &{\\qquad\\leq\\|\\theta_{t-1}-\\theta_{0}-(\\Gamma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\|_{\\mathbf{r}_{t-1}}+\\|\\tilde{\\theta}_{t-1}-\\theta_{0}-(\\Gamma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\|_{\\mathbf{r}_{t-1}}}\\\\ &{\\qquad\\leq\\|\\theta_{t-1}-\\theta_{0}-(\\Gamma_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\|_{\\mathbf{r}_{t-1}}+\\|\\tilde{\\theta}_{t-1}-\\theta_{0}-(\\Gamma_{t-1}^{(0)})^{-1}\\tilde{b}_{t-1}^{(0)}/\\sqrt{m}\\|_{\\mathbf{r}_{t-1}}}\\\\ &{\\qquad\\qquad+\\,m^{-1}\\|(\\Gamma_{t-1}^{(0)})^{-1}\\cdot\\big(\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(x_{\\tau};\\theta_{0})\\cdot c_{\\tau}\\big)\\|_{\\mathbf{r}_{t-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Bounding the first two term on the RHS of Inequality F.1. Here, for the first term on the RHS, we can individually apply Lemma D.1, by considering the auxiliary sequence in $j$ -th iteration $(j\\in[J])$ Wwith $\\pmb{\\Theta}^{(0)}=\\pmb{\\theta}_{0}$ .as ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Theta^{(j+1)}=\\Theta^{(j)}-\\eta\\cdot\\left[\\mathbf{J}^{(0)}\\cdot\\mathbf{W}\\cdot\\left([\\mathbf{J}^{(0)}]^{\\top}(\\Theta^{(j)}-\\theta_{0})-y\\right)+m\\lambda(\\Theta^{(j)}-\\theta_{0})\\right]}\\end{array}\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "where the Jacobian matrix $\\mathbf{J}^{(0)}:=\\left(g(\\pmb{x}_{1};\\pmb{\\theta}_{0}),g(\\pmb{x}_{2};\\pmb{\\theta}_{0}),\\dots,g(\\pmb{x}_{t-1};\\pmb{\\theta}_{0})\\right)\\in\\mathbb{R}^{p\\times(t-1)}$ , and vector $\\pmb{y}\\in\\mathbb{R}^{t-1}$ contains the received arm rewards $r_{\\tau},\\tau\\in[t-1]$ , while matrix $\\mathbf{W}\\in\\mathbb{R}^{(t-1)\\times(t-1)}$ is the diagonal matrix that contains sample weights $w_{\\tau},\\tau\\in[t-1]$ . We have its norm $\\lVert\\mathbf{W}\\rVert_{2}\\leq1$ by definition. Here, the above sequence is expected to solve the following problem with gradient descent ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\underset{\\Theta}{\\operatorname*{min}}\\,\\mathcal{L}(\\Theta)=\\sum_{\\tau\\in[t-1]}\\frac{w_{\\tau}}{2}\\cdot\\bigg\\|[\\mathbf{J}^{(0)}]_{\\tau}^{\\top}(\\Theta-\\theta_{0})-r_{\\tau}\\bigg\\|_{2}^{2}+\\frac{1}{2}\\cdot m\\lambda\\cdot\\bigg\\|\\Theta-\\theta_{0}\\bigg\\|_{2}^{2}.\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "As a result, following an analogous approach as in Lemma C.4 in [86], we can have $\\lVert\\Theta^{(j)}-\\pmb{\\theta}_{0}-\\$ $(\\mathbf{r}_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}\\|_{\\Gamma_{t-1}}\\leq(1-\\eta m\\lambda)^{j/2}\\sqrt{t/(m\\lambda)}$ Futhemoreby aplingtheconelesio oe ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\theta_{t-1}-\\theta_{0}-(\\mathbf{F}_{t-1}^{(0)})^{-1}b_{t-1}^{(0)}/\\sqrt{m}||_{2}\\leq(1-\\eta m\\lambda)^{J/2}\\sqrt{t/(m\\lambda)}+{\\mathcal{O}}(m^{-2/3}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1-\\eta m)^{2})\\,.\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "Similarly, for the second term in Inequality F.1, we also can apply a comparable approach by solving the problem: ", "page_idx": 57}, {"type": "equation", "text": "$$\n\\underset{\\Theta}{\\operatorname*{min}}\\,\\mathcal{L}(\\Theta)=\\sum_{\\tau\\in[t-1]}\\frac{w_{\\tau}}{2}\\bigg\\|[\\mathbf{J}^{(0)}]_{\\tau}^{\\top}(\\Theta-\\theta_{0})-\\widetilde{r}_{\\tau}\\bigg\\|_{2}^{2}+\\frac{1}{2}m\\lambda\\cdot\\bigg\\|\\Theta-\\theta_{0}\\bigg\\|_{2}^{2},\n$$", "text_format": "latex", "page_idx": 57}, {"type": "text", "text": "and constructing the corresponding auxiliary sequence. Following an analogous approach, it will lead to a similar bound for the econd term, such that $\\lVert\\widetilde{\\pmb{\\theta}}_{t-1}-\\widetilde{\\pmb{\\theta}}_{0}-(\\mathbf{I}_{t-1}^{(\\widetilde{0})})^{-1}\\widetilde{\\pmb{b}}_{t-1}^{(0)}/\\sqrt{m}\\rVert_{2}\\,\\leq$ $(1-\\eta m\\lambda)^{J/2}\\sqrt{t/(m\\lambda)}+\\mathcal{O}(m^{-2/3}\\sqrt{\\log(m)}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda}))$ ", "page_idx": 58}, {"type": "text", "text": "Bounding the third term on the RHS of Inequality F.1. Afterwards, for the third term on the RHS, wefirsthave ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m^{-1}:|\\{E_{j}^{m,\\frac{1}{2}-1}:\\quad(\\sum_{i=1}^{N},\\,m_{i}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j}\\rangle,\\,c_{j})|\\phi_{i-1}\\rangle}\\\\ &{\\leq m^{-1}:|\\{E_{j}\\}_{j-1}^{-1}:\\quad(\\sum_{i=1}^{N},\\,m_{i}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j}\\rangle,\\,c_{j})|\\phi_{i-1}\\rangle}\\\\ &{\\qquad\\qquad+m^{-1}:|\\{E_{j}\\}_{j}^{-1}:\\quad(\\sum_{i=1}^{N},\\,m_{i}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j}\\rangle,\\,c_{j})|\\phi_{i-1}\\rangle}\\\\ &{\\leq m^{-1}:|\\{E_{j}\\}_{j-1}^{-1}:\\quad(\\sum_{i=1}^{N},\\,m_{j}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j-1}\\rangle):\\quad(\\sum_{i=1}^{N},\\,m_{j}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j}\\rangle,\\,c_{j})|\\phi_{i-1}\\rangle}\\\\ &{\\qquad\\qquad+m^{-1}:|\\{E_{j}\\}_{j}^{-1}:\\quad(\\sum_{i=1}^{N},\\,m_{i}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j-1}\\rangle):\\quad(\\sum_{i=1}^{N},\\,m_{j}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j}\\rangle,\\,c_{j})|\\phi_{i-1}\\rangle}\\\\ &{\\leq m^{-1}:|\\{E_{j}\\}_{j}^{-1}:\\quad(\\sum_{i=1}^{N},\\,m_{j}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j-1}\\rangle):\\quad(\\sum_{i=1}^{N},\\,m_{j}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j}\\rangle,\\,c_{j})|\\phi_{i-1}\\rangle}\\\\ &{\\leq m^{-1}:|\\{E_{j}\\}_{j}^{-1}:\\quad(\\sum_{i=1}^{N},\\,m_{j}\\cdot\\nabla_{j}\\phi_{i},\\|\\phi_{j-1}\\rangle):\\quad(\\nabla_{j}\\phi_{i},\\|\\phi_{j}\\rangle):\\quad(\\sum\n$$where the third inequality is due to Lemma G.6, and the last inequality is due to Lemma G.4. Then, ", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "recallthat the weight $\\bar{w_{\\tau}}=\\{1,\\alpha/\\|g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})/\\sqrt{m}\\|_{\\Gamma_{\\tau-1}^{-1}}\\}$ for each chosen arm $\\mathbf{\\nabla}x_{\\tau}$ . In this case, wecanfurther have ", "page_idx": 58}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m^{-1/2}\\lVert(\\mathbf{r}_{t-1})^{-1}(\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\mathbf{x}_{\\tau};\\theta_{\\tau-1})\\cdot c_{\\tau})/\\sqrt{m}\\lVert\\mathbf{r}_{t-1}}\\\\ &{\\qquad\\quad=m^{-1/2}\\lVert\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\mathbf{x}_{\\tau};\\theta_{\\tau-1})\\cdot c_{\\tau}/\\sqrt{m}\\rVert_{(\\mathbf{r}_{t-1})^{-1}}}\\\\ &{\\qquad\\quad\\leq m^{-1/2}\\displaystyle\\sum_{\\tau\\in[t-1]}w_{\\tau}|c_{\\tau}|\\cdot\\lVert g(\\mathbf{x}_{\\tau};\\theta_{\\tau-1})/\\sqrt{m}\\rVert_{(\\Gamma_{t-1})^{-1}}}\\\\ &{\\qquad\\quad\\leq m^{-1/2}\\displaystyle\\sum_{\\tau\\in[t-1]}w_{\\tau}|c_{\\tau}|\\cdot\\lVert g(\\mathbf{x}_{\\tau};\\theta_{\\tau-1})/\\sqrt{m}\\rVert_{(\\Gamma_{\\tau-1})^{-1}}}\\\\ &{\\qquad\\quad\\leq\\alpha\\cdot C/\\sqrt{m}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 58}, {"type": "text", "text": "where the first inequality is by applying the Cauchy-Schwartz inequality, while the second inequality is due to $\\mathbf{T}_{\\tau-1}\\preceq\\mathbf{T}_{t-1}$ and Lemma G.8. The last inequality is by the definition of corruption level $C$ Finally, summing up all the results will give the desired lemma. ", "page_idx": 58}, {"type": "text", "text": "F.4  Self-regularized Martingale Sequence with Weighted Matrix ", "text_level": 1, "page_idx": 58}, {"type": "text", "text": "Recallthat we have the weighted gradient covariance matrix $\\begin{array}{r}{\\mathbf{\\Gamma}_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\mathbf{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})}\\end{array}$ $g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m$ ,where $g(\\mathbf{\\boldsymbol{x}}_{\\tau};\\mathbf{\\boldsymbol{\\theta}}_{\\tau-1})$ is the vectorized gradient vector, and $w_{\\tau}\\leq1$ refers to the sampled associated with chosen arm $\\pmb{x}_{\\tau}$ ", "page_idx": 58}, {"type": "text", "text": "By existing works [1, 86], we can have the self-normalized martingale such that ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\sum_{\\tau\\in[t]}\\operatorname*{min}\\left\\{\\left\\Vert g(\\mathbf{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})/\\sqrt{m}\\right\\Vert_{\\Gamma_{\\tau-1}^{-1}}^{2},\\ 1\\right\\}\\leq2\\log\\frac{\\operatorname*{det}(\\mathbf{r}_{t})}{\\operatorname*{det}(\\lambda\\mathbf{I})}.\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "if weights in $\\mathbf{\\boldsymbol{\\Gamma}}_{t}$ are all set to 1. However, since in our settings the gradient covariance matrix $\\mathbf{\\Gamma}\\mathbf{\\Gamma}_{t}$ involves sample weights, we will need to further discuss the upper bound for this sequence summation. ", "page_idx": 59}, {"type": "text", "text": "Lemma F.2. With the definition of $\\gamma_{t-1}$ from Lemma $F.I$ as well as the notation and conditions in Theorem $E.l$ ,we have the following inequality ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{\\epsilon\\mid T}\\operatorname*{min}\\left\\{\\gamma_{t-1}\\cdot\\left\\Vert g(\\boldsymbol{x}_{t};\\boldsymbol{\\theta}_{t-1})/\\sqrt{m}\\right\\Vert_{\\Gamma_{t-1}^{-1}},\\,1\\right\\}\\leq\\gamma_{T}\\sqrt{\\widetilde{d}T\\log(1+T K/\\lambda)}+(1+\\frac{\\gamma_{T}}{\\alpha})\\cdot\\widetilde{d}\\log(1+T K/\\lambda)\\,,}\\\\ &{\\displaystyle^{\\epsilon\\prod}\\epsilon\\gamma_{t-1}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t-1]}w_{\\tau}\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})\\cdot g(\\boldsymbol{x}_{\\tau};\\boldsymbol{\\theta}_{\\tau-1})^{\\tau}/m.}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "Proof. The proof of this lemma follows an analogous approach as Theorem 4.2 in [42]. Recall that sample weights $w_{\\tau}\\leq1,\\tau\\in[T]$ . In this case, we separately consider two scenarios when (i) $w_{\\tau}=1$ then $\\tau\\in T_{w=1}^{(T)}$ ; and (i) the scenario when $w_{\\tau}<1$ then $\\tau\\in T_{w<1}^{(T)}$ .In this case,theoriginal betive will become the following inequality ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{t\\in[T]}\\operatorname*{min}\\left\\{\\big\\|g(\\mathbf{x}_{t};\\theta_{t-1})/\\sqrt{m}\\big\\|_{\\mathbf{r}_{t-1}^{-1}},\\,1\\right\\}}\\quad}&{}\\\\ &{=\\sum_{t\\in{\\mathcal{T}}_{w=1}^{(T)}}\\operatorname*{min}\\left\\{\\big\\|g(\\mathbf{x}_{t};\\theta_{t-1})/\\sqrt{m}\\big\\|_{\\mathbf{r}_{t-1}^{-1}},\\,1\\right\\}+\\sum_{t\\in{\\mathcal{T}}_{w<1}^{(T)}}\\operatorname*{min}\\left\\{\\big\\|g(\\mathbf{x}_{t};\\theta_{t-1})/\\sqrt{m}\\big\\|_{\\mathbf{r}_{t-1}^{-1}},\\,1\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "First fr the scenario where $w_{\\tau}=1,\\tau\\in\\mathcal{T}_{w=1}^{(T)}$ we have ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{t\\in T_{w=1}^{(T)}}\\operatorname*{min}\\bigg\\{\\big\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\big\\|_{\\mathbf{r}_{t-1}^{-1}},1\\bigg\\}\\leq\\sqrt{\\displaystyle\\sum_{t\\in T_{w=1}^{(T)}}\\operatorname*{min}\\bigg\\{\\big\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\big\\|_{\\mathbf{r}_{t-1}^{-1}}^{2},1\\bigg\\}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\sqrt{\\displaystyle\\sum_{t\\in T_{w=1}^{(T)}}\\operatorname*{min}\\bigg\\{\\big\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\big\\|_{(\\Gamma_{t-1}^{w=1})^{-1}}^{2},1\\bigg\\}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "Here, we defne an extra auxiliary matrix T=1 = XI + \u2265reT $\\begin{array}{r l r}{\\ensuremath{\\mathbf{\\boldsymbol\\Gamma}}_{t-1}^{w=1}}&{=}&{\\lambda{\\bf I}\\;+\\;\\sum_{\\tau\\in{\\mathcal T}_{w=1}^{(t-1)}}w_{\\tau}\\;\\cdot\\;g({\\ensuremath{\\boldsymbol x}}_{\\tau};\\theta_{\\tau-1})}\\end{array}$ $g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m$ . Compared with the original gradient covariance matrix $\\mathbf{\\Gamma}\\mathbf{\\Gamma}_{t-1}$ , since we have $\\Gamma_{t-1}^{w=1}\\preceq\\Gamma_{t-1}$ and theyarebthmitamaricewecanderivetheastnequalitbad Lemma G.8. Then, by applying Lemma G.7 and Lemma C.2, it will lead to ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{\\epsilon\\mathcal{T}_{w=1}^{(T)}}\\operatorname*{min}\\left\\{\\|g({\\boldsymbol x}_{t};{\\boldsymbol\\theta}_{t-1})/\\sqrt{m}\\|_{\\Gamma_{t-1}^{-1}},\\,1\\right\\}\\leq\\sqrt{|\\mathcal{T}_{w=1}^{(T)}|\\cdot\\displaystyle\\sum_{t\\in\\mathcal{T}_{w=1}^{(T)}}\\operatorname*{min}\\left\\{\\|g({\\boldsymbol x}_{t};{\\boldsymbol\\theta}_{t-1})/\\sqrt{m}\\|_{(\\Gamma_{t-1}^{w=1})^{-1}}^{2},\\right.}\\\\ {\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\left.\\leq\\sqrt{|\\mathcal{T}_{w=1}^{(T)}|\\cdot\\tilde{d}\\log(1+T K/\\lambda)}\\\\ {\\qquad\\qquad\\qquad\\leq\\sqrt{\\tilde{d}T\\log(1+T K/\\lambda)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "Then, since we have $\\gamma_{t-1}\\leq\\gamma_{T}$ , plugging in the $\\gamma_{T}$ will complete the proof. ", "page_idx": 59}, {"type": "text", "text": "Afterwards, for the second scenario when $w_{\\tau}<1,\\tau\\in\\mathcal{T}_{w<1}^{(T)}$ w<1, we will have ", "page_idx": 59}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{\\in\\mathcal{T}_{w<1}^{(T)}}\\operatorname*{min}\\left\\lbrace\\gamma_{t-1}\\cdot\\left\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\right\\|_{\\Gamma_{t-1}^{-1}},\\ 1\\right\\rbrace=\\displaystyle\\sum_{t\\in\\mathcal{T}_{w<1}^{(T)}}\\left\\lbrace\\gamma_{t-1}\\cdot\\frac{w_{t}}{\\alpha}\\cdot\\left\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\right\\|_{\\Gamma_{t-1}^{-1}}^{2},\\ 1\\right\\rbrace}\\\\ {\\displaystyle\\leq(1+\\frac{\\gamma T}{\\alpha})\\cdot\\sum_{t\\in\\mathcal{T}_{w<1}^{(T)}}\\left\\lbrace w_{t}\\cdot\\left\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\right\\|_{\\Gamma_{t-1}^{-1}}^{2},\\ 1\\right\\rbrace}\\\\ {\\displaystyle}&{\\leq(1+\\frac{\\gamma T}{\\alpha})\\cdot\\sum_{t\\in\\mathcal{T}_{w<1}^{(T)}}\\left\\lbrace w_{t}\\cdot\\left\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\right\\|_{(\\mathbf{r}_{t-1}^{w<1})^{-1}}^{2},\\ 1\\right\\rbrace}\\end{array}\n$$", "text_format": "latex", "page_idx": 59}, {"type": "text", "text": "where the inequality is because we have $\\gamma_{t-1}\\leq\\gamma_{T},\\forall t\\in[T]$ ", "page_idx": 60}, {"type": "text", "text": "Followingthe revious aproach, ve definethe auxiliary matrixr $\\begin{array}{r}{\\Gamma_{t-1}^{w<1}\\,=\\,\\lambda{\\bf I}+\\sum_{\\tau\\in\\mathcal{T}_{w=1}^{(t-1)}}w_{\\tau}\\mathrm{~.~}}\\end{array}$ $g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})\\cdot g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m$ Here, since we al ave $\\Gamma_{t-1}^{w<1}\\preceq\\Gamma_{t-1}$ and they are both Hermitian matrices, we can derive the last inequality based on Lemma G.8. In addition, we consider an altemative fom of the riginal gradient vectorasg(; 0-1)= Vw g(\u00b1; 0-1),T E T(-). In this case, the auxiliary gradient covariance matrix can be alternatively represented as $\\mathbf{\\Gamma}_{t-1}^{w<1}=$ $\\begin{array}{r}{\\lambda\\mathbf{I}+\\sum_{\\tau\\in\\mathcal{T}_{w=1}^{(t-1)}}g^{\\prime}(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})\\cdot g^{\\prime}(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m}\\end{array}$ and the RHS will become ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{\\ell\\tau_{w<1}^{(T)}}\\operatorname*{min}\\left\\{\\gamma_{t-1}\\cdot\\big\\|g(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\big\\|_{\\Gamma_{t-1}^{-1}},\\,1\\right\\}\\leq(1+\\frac{\\gamma T}{\\alpha})\\cdot\\sum_{t\\in\\mathcal{T}_{w<1}^{(T)}}\\bigg\\{\\|g^{\\prime}(\\pmb{x}_{t};\\pmb{\\theta}_{t-1})/\\sqrt{m}\\|_{(\\mathbf{F}_{t-1}^{\\infty})}^{2}.}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad t\\in\\mathcal{T}_{w<1}^{(T)}}\\\\ &{\\leq(1+\\frac{\\gamma T}{\\alpha})\\cdot\\tilde{d}\\log(1+T K/\\lambda).}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where the last inequality is by applying Lemma G.7 and Lemma C.2. Summing up the results will finish the proof. ", "page_idx": 60}, {"type": "text", "text": "G  Lemmas for Over-parameterized FC Neural Networks ", "text_level": 1, "page_idx": 60}, {"type": "text", "text": "Given the input arm context vector $\\pmb{x}\\in\\mathbb{R}^{d}$ , we denote the $L$ -layer FC neural network with width $m$ as ", "page_idx": 60}, {"type": "equation", "text": "$$\nf(\\mathbf{x};\\pmb{\\theta})=\\pmb{\\theta}_{L}(\\prod_{l=1}^{L-1}\\mathbf{D}_{l}\\pmb{\\theta}_{l})\\cdot\\pmb{x},\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "wherewith $\\sigma$ being the ReLU activation, we define the intermediate hidden representations $h_{l},l\\in$ $\\{0,\\ldots,L-1\\}$ as ", "page_idx": 60}, {"type": "equation", "text": "$$\n{\\pmb h}_{0}={\\pmb x},\\quad{\\pmb h}_{l}=\\sigma(\\pmb\\theta_{l}{\\pmb h}_{l-1}),l\\in[L-1].\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "and we also have the binary diagonal matrix functioning as the ReLU activation being ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\mathbf{D}_{l}=\\mathrm{diag}(\\mathbb{I}\\{(\\theta_{l}h_{l-1})_{1}\\},\\dots,\\mathbb{I}\\{(\\theta_{l}h_{l-1})_{m}\\}),l\\in[L-1].\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where $\\mathbb{I}(\\cdot)$ is the indicator function. Afterwards, the corresponding gradients will become ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\nabla_{\\theta_{l}}f(x;\\theta)=\\left\\{\\!\\!\\left[h_{l-1}\\theta_{L}(\\prod_{\\tau=l+1}^{L-1}\\mathbf{D}_{\\tau}\\pmb{\\theta}_{\\tau})\\right]\\!\\!\\nabla,l\\in[L-1]\\!\\!\\right.}\\\\ {\\quad\\left.\\!\\!\\nabla_{\\theta_{l}}f(x;\\theta)=\\!\\!\\left\\{h_{L-1}^{\\top},l=L.\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "LemmaG.1.There existsapositiveconstant $C>0$ such that with probability at least $1-\\delta,\\,i f$ $m\\geq C T^{4}L^{6}\\log(T^{2}L/\\delta)/\\lambda^{4}$ for each arbitrary $\\begin{array}{r}{\\pmb{x}_{\\tau}\\in\\bigcup_{\\tau\\in[t]}\\mathcal{X}_{\\tau},}\\end{array}$ there exists a set of parameters $\\pmb{\\theta}^{*}$ such that with the neural network parameters $\\pmb\\theta_{t-1}$ trained on $\\{{\\pmb x}_{\\tau}\\}_{\\tau=1}^{t-1}$ wehave ", "page_idx": 60}, {"type": "equation", "text": "$$\n|\\langle g(x;\\pmb{\\theta}_{0}),\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rangle-\\langle g(x;\\pmb{\\theta}_{t-1}),\\pmb{\\theta}^{*}-\\pmb{\\theta}_{0}\\rangle|\\leq\\mathcal{O}(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7})\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where parameters $\\pmb{\\theta}^{*}$ satisfy $\\lVert\\theta^{*}-\\theta_{0}\\rVert\\leq S/\\sqrt{m},S>0$ as shown in Lemma C.1. ", "page_idx": 60}, {"type": "text", "text": "Proof. This lemma is based on Lemma C.1. Here, our objective can be reformed into ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\langle g({\\pmb x};\\theta_{0}),\\theta^{*}-\\theta_{0}\\rangle-\\langle g({\\pmb x};\\theta_{t-1}),\\theta^{*}-\\theta_{0}\\rangle|=\\|\\theta^{*}-\\theta_{0}\\|_{2}\\cdot\\big(g({\\pmb x};\\theta_{0})-g({\\pmb x};\\theta_{t-1})\\big)}\\\\ &{\\qquad\\qquad\\leq S/\\sqrt{m}\\cdot\\big(g({\\pmb x};\\theta_{0})-g({\\pmb x};\\theta_{t-1})\\big)}\\\\ &{\\qquad\\qquad\\leq\\mathcal O(S m^{-1/6}\\sqrt{\\log(m)}t^{1/6}\\lambda^{-1/6}L^{2/7}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "where the first inequality is due to Lemma C.1, and the second inequality is due to Lemmas G.2, G.3, and Lemma G.4. ", "page_idx": 60}, {"type": "text", "text": "Lemma G.2 (Lemma B.3 in [21] ). There exist constants $\\{C_{1},C_{2}\\}$ such that for any $\\delta>0$ ifwe have ", "page_idx": 60}, {"type": "equation", "text": "$$\n\\omega\\leq C_{1}L^{-6}(\\log m)^{-3/2},\n$$", "text_format": "latex", "page_idx": 60}, {"type": "text", "text": "then with probability at least $1\\!-\\!\\delta$ for any $\\begin{array}{r}{\\|\\pmb{\\theta}-\\pmb{\\theta}_{0}\\|\\leq\\omega}\\end{array}$ and for $\\pmb{x}\\in\\{\\mathcal{X}_{t}\\}_{t=1}^{T}$ we have $\\|g(\\pmb{x};\\pmb{\\theta})\\|_{2}\\leq$ $C_{2}\\sqrt{m L}$ ", "page_idx": 60}, {"type": "text", "text": "Proof. In terms of the gradient upper bound, directly applying Lemma B.3 in [21] will give the desired result that $\\|g(\\pmb{x};\\pmb{\\theta})\\|_{2}\\leq\\mathcal{O}(\\sqrt{m L})$ \u53e3 ", "page_idx": 61}, {"type": "text", "text": "Lemma G.3 (Lemma B.2 in [86]). For the $L$ -layerfull-connected network $f$ trained with $J$ iterations of $G D$ there exist constants $\\{{\\bar{C_{i}}}\\}_{i=1}^{5}\\geq0$ such that for $\\delta>0,$ if for all $t\\in[T],\\,\\eta,m$ satisfy ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{2\\sqrt{t/(m\\lambda)}\\geq C_{1}m^{-3/2}L^{-3/2}[\\log(T L^{2}/\\delta)]^{3/2},}\\\\ &{2\\sqrt{t/(m\\lambda)}\\leq C_{2}\\operatorname*{min}\\{L^{-6}[\\log m]^{-3/2},(m(\\lambda\\eta)^{2}L^{-6}t^{-1}(\\log m)^{-1})^{3/8}\\},}\\\\ &{\\eta\\leq C_{3}(m\\lambda+t m L)^{-1},}\\\\ &{m^{1/6}\\geq C_{4}\\sqrt{\\log m}L^{7/2}t^{7/6}\\lambda^{-7/6}(1+\\sqrt{t/\\lambda}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "then, with probability at least $1-\\delta$ ,wehave ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\theta_{t}-\\theta_{0}\\|\\le2\\sqrt{t/(m\\lambda)}}\\\\ &{\\theta_{t}-\\theta_{0}-\\bar{\\Sigma}_{t}^{-1}\\bar{b}_{t}/\\sqrt{m}\\|\\le(1-\\eta m\\lambda)^{J/2}\\sqrt{t/(m\\lambda)}+C_{5}m^{-2/3}\\sqrt{\\log m}L^{7/2}t^{5/3}\\lambda^{-5/3}(1+\\sqrt{t/\\lambda})}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "where the unweighted regression parameters are $\\begin{array}{r}{\\bar{\\Sigma}_{t}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})^{\\top}/m}\\end{array}$ and $\\begin{array}{r}{\\bar{\\pmb{b}}_{t}=\\sum_{\\tau\\in[t]}g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})\\pmb{r}_{\\tau}/\\sqrt{m}.}\\end{array}$ ", "page_idx": 61}, {"type": "text", "text": "Lemma G.4 (Theorem 5 in [3]). With probability at least $1-\\delta$ there exist constants $C_{1},C_{2}$ such that if $\\omega\\le C_{1}L^{-9/2}\\log^{-3}m,$ for $\\lVert\\pmb{\\theta}_{t}-\\pmb{\\theta}_{0}\\rVert_{2}\\leq\\omega_{t}$ wehave ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\|g(\\pmb{x};\\pmb{\\theta}_{t})-g(\\pmb{x};\\pmb{\\theta}_{0})\\|_{2}\\leq C_{2}\\sqrt{\\log m}\\omega^{1/3}L^{3}\\|g(\\pmb{x};\\pmb{\\theta}_{0})\\|_{2}.\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "Lemma G.5 (Lemma 4.1 in [21]). There exist constants $\\{\\bar{C}_{i=1}^{3}\\}\\geq0$ suchthat forany $\\delta\\geq0$ .i $\\tau$ satisfiesthat ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\tau\\leq\\bar{C}_{2}L^{-6}[\\log m]^{-3/2},\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "then with probability at least $1-\\delta_{i}$ for all $\\theta^{1},\\theta^{2}$ satisfying $\\begin{array}{r}{\\|\\theta^{1}-\\theta_{0}\\|\\leq\\tau,\\|\\theta^{2}-\\theta_{0}\\|\\leq\\tau}\\end{array}$ and for any $\\pmb{x}\\in\\{\\pmb{x}_{t}\\}_{t=1}^{T}$ we have ", "page_idx": 61}, {"type": "equation", "text": "$$\n|f(x;\\pmb\\theta^{1})-f(\\pmb x;\\pmb\\theta^{2})-\\langle(g(\\pmb x;\\pmb\\theta^{2}),\\pmb\\theta^{1}-\\pmb\\theta^{2})\\rangle|\\leq\\bar{C}_{3}\\tau^{4/3}L^{3}\\sqrt{m\\log m}.\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "Lemma G.6. Suppose m satisfies the conditions in Theorem 5.6. Suppose the gradient matrix can be represented by $\\begin{array}{r}{\\bar{\\Sigma}=\\lambda\\mathbf{I}+\\sum_{t\\in[T]}g(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})\\cdot g(\\pmb{x}_{i,t};\\pmb{\\theta}_{t-1})^{\\top}/m}\\end{array}$ with an arbitrary arm $\\pmb{x}_{i,t}\\in\\mathcal{X}_{t}$ from each time step $t$ \uff1aWith probability at least $1-\\delta$ over the initialization,the followingresults hold: ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{c}{\\displaystyle\\|\\Sigma\\|_{2}\\leq\\lambda+\\mathcal{O}(T L),}\\\\ {\\|\\Sigma-\\Sigma^{(0)}\\|_{F}\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{7/6}\\lambda^{-1/6})}\\\\ {\\|\\log\\frac{\\operatorname*{det}(\\Sigma)}{\\operatorname*{det}(\\lambda\\mathbf{I})}-\\log\\frac{\\operatorname*{det}(\\Sigma^{(0)})}{\\operatorname*{det}(\\lambda\\mathbf{I})}\\|_{F}\\leq\\mathcal{O}(m^{-1/6}\\sqrt{\\log(m)}L^{4}t^{5/6}\\lambda^{-1/6}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "where the gradient matrix defined based on randomly initialized parameters $\\pmb{\\theta}_{0}$ is $\\boldsymbol{\\Sigma}^{(0)}\\,=\\,\\lambda\\mathbf{I}+$ $\\begin{array}{r}{\\sum_{t\\in[T]}g(\\bar{\\mathbf{x}}_{i,t};\\pmb{\\theta}_{0})\\cdot g(\\mathbf{x}_{i,t};\\pmb{\\theta}_{0})^{\\top}/m.}\\end{array}$ ", "page_idx": 61}, {"type": "text", "text": "Proof. Based on the Lemma G.2, for any $t\\in[T],\\,\\|g(\\pmb{x}_{i,t};\\pmb{\\Theta}_{0})\\|_{2}\\leq\\mathcal{O}(\\sqrt{m L})$ Then, for the first inequality: ", "page_idx": 61}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\|\\Sigma^{(0)}\\|_{2}=\\|\\lambda\\mathbf{I}+\\sum_{t=1}^{T}g(\\pmb{x}_{i,t};\\pmb{\\Theta}_{0})g(\\pmb{x}_{i,t};\\pmb{\\Theta}_{0})^{\\top}/m\\|_{2}}}\\\\ &{}&{\\leq\\|\\lambda\\mathbf{I}\\|_{2}+\\|\\sum_{t=1}^{T}g(\\pmb{x}_{i,t};\\pmb{\\Theta}_{0})g(\\pmb{x}_{i,t};\\pmb{\\Theta}_{0})^{\\top}/m\\|_{2}}\\\\ &{}&{\\leq\\lambda+\\displaystyle\\sum_{t=1}^{T}\\|g(\\pmb{x}_{i,t};\\pmb{\\Theta}_{0})/\\sqrt{m}\\|_{2}^{2}\\leq\\lambda+\\mathcal{O}(T L).}\\end{array}\n$$", "text_format": "latex", "page_idx": 61}, {"type": "text", "text": "Then, the second and third inequalities in this lemma are the direct application of Lemma B.3 of [86]. ", "page_idx": 61}, {"type": "text", "text": "Lemma G.7 (Lemma 11 in [1], Lemma B.7 in [86]). Suppose a sequence of arms $\\{x_{\\tau}^{\\prime}\\}_{\\tau\\in[t]}$ with an arbitrary arm $\\mathbf{\\boldsymbol{x}}_{\\tau}^{\\prime}\\in\\mathcal{X}_{\\tau}$ from each time step $\\tau\\,\\in\\,[t]$ .The gradient matrix is denoted by $\\begin{array}{r}{\\pmb{\\Sigma}_{t}=\\lambda\\mathbf{I}+\\sum_{\\tau\\in[t]}g(\\pmb{x}_{\\tau}^{\\prime};\\pmb{\\theta}_{\\tau-1})\\cdot g(\\pmb{x}_{\\tau}^{\\prime};\\pmb{\\theta}_{\\tau-1})^{\\top}/m}\\end{array}$ where $\\theta_{\\tau-1}$ refer to network parameters in round $\\tau\\in[t]$ .We can have ", "page_idx": 62}, {"type": "equation", "text": "$$\n\\sum_{\\tau\\in[t]}\\operatorname*{min}\\big\\{\\lVert g(\\pmb{x}_{\\tau};\\pmb{\\theta}_{\\tau-1})/\\sqrt{m}\\rVert_{\\pmb{\\Sigma}_{\\tau-1}^{-1}}^{2},\\,1\\big\\}\\leq2\\log\\frac{\\operatorname*{det}(\\pmb{\\Sigma}_{t})}{\\operatorname*{det}(\\lambda\\mathbf{I})}.\n$$", "text_format": "latex", "page_idx": 62}, {"type": "text", "text": "G.1  Auxiliary Lemma ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "Lemma G.8 ((Corollary 7.7.4. (a) from [45]). Let A, B be Hermitian matrices of the same shape, and suppose they are positive semi-definite.Then, wehave $\\mathbf A\\succeq\\mathbf B$ if $\\mathbf{A}^{-1}\\preceq\\mathbf{B}^{-\\breve{1}}$ ", "page_idx": 62}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 63}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 63}, {"type": "text", "text": "Justification: We have included discussion for our contributions in the Abstract and Introduction. ", "page_idx": 63}, {"type": "text", "text": "Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 63}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 63}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Justification: Please see appendix for the discussion of the limitation. ", "page_idx": 63}, {"type": "text", "text": "Guidelines: ", "page_idx": 63}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should refect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should refect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 63}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 63}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 63}, {"type": "text", "text": "Justification: Please see theoretical analysis section and appendix for details. Guidelines: ", "page_idx": 64}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 64}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 64}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 64}, {"type": "text", "text": "Justification: Please see appendix and our submitted source code. ", "page_idx": 64}, {"type": "text", "text": "Guidelines: ", "page_idx": 64}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 64}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 64}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 64}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 65}, {"type": "text", "text": "Justification: We include the source code along with our submission. Guidelines: ", "page_idx": 65}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 65}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 65}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 65}, {"type": "text", "text": "Justification: We have shown our way of selecting the parameters and included the parameter study. ", "page_idx": 65}, {"type": "text", "text": "Guidelines: ", "page_idx": 65}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 65}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 65}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 65}, {"type": "text", "text": "Justification: Standard deviation is given for experiment results. ", "page_idx": 65}, {"type": "text", "text": "Guidelines: ", "page_idx": 65}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative errorrates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 65}, {"type": "text", "text": "", "page_idx": 66}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce theexperiments? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 66}, {"type": "text", "text": "Justification: Please see appendix where we mention our system specifications. ", "page_idx": 66}, {"type": "text", "text": "Guidelines: ", "page_idx": 66}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 66}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 66}, {"type": "text", "text": "Justification: We confirm this perform conform with the NeurIPS Code of Ethics. ", "page_idx": 66}, {"type": "text", "text": "Guidelines: ", "page_idx": 66}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 66}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Justification: We have included a subsection in appendix discussing this. ", "page_idx": 66}, {"type": "text", "text": "Guidelines: ", "page_idx": 66}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 66}, {"type": "text", "text": "", "page_idx": 67}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 67}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 67}, {"type": "text", "text": "Justification: This paper is mainly about defensing adversarial attacks under neural bandit settings with no new datasets. ", "page_idx": 67}, {"type": "text", "text": "Guidelines: ", "page_idx": 67}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 67}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 67}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 67}, {"type": "text", "text": "Justification: We include the URLs for the datasets used instead. ", "page_idx": 67}, {"type": "text", "text": "Guidelines: ", "page_idx": 67}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 67}, {"type": "text", "text": "\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 68}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 68}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 68}, {"type": "text", "text": "Justification: No new datasets are introduced. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 68}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 68}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 68}, {"type": "text", "text": "Justification: No human subjects are involved. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 68}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 68}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 68}, {"type": "text", "text": "Justification: No human subjects are involved. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 68}]