[{"figure_path": "9GhSOp1LYH/figures/figures_2_1.jpg", "caption": "Figure 2: An overview of ProMac: Masks created iteratively by the mask generator guide the prompt generator to jointly improve instance-specific prompts and visual masking in segmentation.", "description": "The figure illustrates the iterative process of ProMaC, a prompt-mask cycle generation method. It begins with an initial instance-specific prompt, which is used by a mask generator to produce an initial mask. This mask is then used by a prompt generator to refine the instance-specific prompt. This cycle repeats multiple times, improving both the prompt and the mask. The prompt generator uses a multi-scale chain of thought prompting, which involves exploring hallucinations to mine task-related information, and then reducing these hallucinations to formulate more precise prompts. The mask generator uses mask semantic alignment, which ensures that the generated masks are consistent with task semantics.", "section": "3 Methodology"}, {"figure_path": "9GhSOp1LYH/figures/figures_3_1.jpg", "caption": "Figure 3: ProMaC consists of a prompt generator and a mask generator for cyclical optimization. The prompt generator employs multi-scale chain-of-thought prompting. It initially use hallucinations for exploring task-related information within image patches. It identifies task-relevant objects and their backgrounds (Afore, Alback) along with their locations (Bk). Subsequently, it uses visual contrastive reasoning to refine and finalize instance-specific prompts (A, B) by eliminating hallucinations. The mask generator then processes these prompts into the segmentation model (\"Seg\"), producing a mask aligned with task semantics. This mask further guides the visual contrastive reasoning process, which leverages an inpainting model to eliminate masked regions, creating contrastive images. These images enable the prompt generator to further refine its prompts, enhancing segmentation accuracy.", "description": "This figure provides a detailed illustration of the ProMaC framework's architecture, highlighting the iterative interaction between the prompt and mask generators.  The prompt generator uses multi-scale chain of thought reasoning and visual contrastive reasoning (VCR) to refine instance-specific prompts. The mask generator utilizes these refined prompts, along with a segmentation model (Seg), to create masks that are aligned with the task semantics. These masks are then fed back to the prompt generator to further refine its prompts in an iterative process, leading to enhanced segmentation accuracy.", "section": "3.1 Prompt Generator"}, {"figure_path": "9GhSOp1LYH/figures/figures_8_1.jpg", "caption": "Figure 4: Visualization of various segmentation methods among various segmentation tasks.", "description": "This figure visualizes the results of different segmentation methods on three distinct tasks: Camouflaged Object Detection, Transparent Object Segmentation, and Medical Image Segmentation. For each task, it shows the original image, the ground truth segmentation, and the segmentation results produced by three different methods: Grounding SAM, GenSAM, and the proposed ProMaC method.  The contrastive sample is also shown for ProMaC, highlighting the use of contrastive reasoning to enhance the accuracy of the segmentations. The figure visually demonstrates the relative strengths and weaknesses of each method across different visual scenarios and complexities.", "section": "Results and Analysis"}, {"figure_path": "9GhSOp1LYH/figures/figures_9_1.jpg", "caption": "Figure 5: Visualization of the generated masks and contrastive samples over iterations.", "description": "This figure visualizes the iterative process of ProMaC.  It shows how the generated masks and contrastive samples evolve over four iterations. For each iteration, there are four rows representing four different samples. Each row shows the ground truth image (Image&GT), the predicted mask from the first iteration (iteration 1), the second iteration (iteration 2), the third iteration (iteration 3), the fourth iteration (iteration 4), and finally the prediction image (Prediction Image) and a contrastive image for each sample. The contrastive images are used to highlight task-relevant regions and reduce irrelevant hallucinations, demonstrating the cycle generation method.", "section": "3.3 Mask Prompt Cycle Generation"}, {"figure_path": "9GhSOp1LYH/figures/figures_15_1.jpg", "caption": "Figure 6: Left: In the bar chart, we analyze MLLM predictions with two versions of an image: the original (blue) and another with task-related objects removed via inpainting (orange). We then compare their predictions to the ground truth using CLIP similarity on the COD10K dataset. Despite missing key objects, the inpainted image's predictions still somewhat match the ground truth. When we select the higher similarity score from both images as the final score (green), it surpassed that of the original alone. It shows that prior knowledge from hallucinations can also provide useful information for generating prompts. Right: A example of using hallucinations to assist instance-specific prompt generation. Specifically, utilizing hallucination can leverage prior knowledge of image elements to better recognize and locate task-related objects. Directly inputting the image into LLaVA results in the hidden chameleon being incorrectly predicted. Splitting the image results in interested objects being incomplete or absent, prompting LLaVA to induce hallucinations and utilize prior knowledge to uncover potential task-related knowledge within the image. This knowledge assists in final accurately identifying and locating the chameleon.", "description": "The left part of the figure shows a bar chart comparing the cosine similarity between ground truth and predicted task-related objects using CLIP on the COD10K dataset.  The original image, an inpainted version (with task-related objects removed), and a combined version are compared.  The combined version shows improved similarity, suggesting that prior knowledge from hallucinations aids in prompt generation.  The right part illustrates how hallucinations assist in generating instance-specific prompts by showing an example image.  Directly inputting the original image leads to incorrect prediction, whereas splitting the image and using hallucinations leads to a more accurate prediction of the camouflaged chameleon.", "section": "A.2 More Experiments on the Motivation"}, {"figure_path": "9GhSOp1LYH/figures/figures_17_1.jpg", "caption": "Figure 4: Visualization of various segmentation methods among various segmentation tasks.", "description": "This figure visualizes the results of different segmentation methods on three diverse tasks: Camouflaged Object Detection, Transparent Object Segmentation, and Medical Image Segmentation.  It showcases how each method (including the proposed ProMaC) performs on various images, highlighting the differences in their ability to accurately segment objects in challenging scenarios. The visualization helps demonstrate ProMaC's effectiveness compared to other techniques across different visual challenges.", "section": "Results and Analysis"}, {"figure_path": "9GhSOp1LYH/figures/figures_18_1.jpg", "caption": "Figure 4: Visualization of various segmentation methods among various segmentation tasks.", "description": "This figure visualizes the results of various segmentation methods on three different tasks: Camouflaged Object Detection, Transparent Object Segmentation, and Medical Image Segmentation.  For each task, it shows the original image, the ground truth segmentation, the segmentation result using GenSAM, the segmentation result using GroundingSAM, and finally the segmentation result obtained by the proposed ProMaC method.  The visualization helps to compare the performance of different methods across diverse visual scenarios and demonstrates the effectiveness of ProMaC in handling challenging segmentation tasks.", "section": "Results and Analysis"}, {"figure_path": "9GhSOp1LYH/figures/figures_18_2.jpg", "caption": "Figure 4: Visualization of various segmentation methods among various segmentation tasks.", "description": "This figure visualizes the results of different segmentation methods (GenSAM, GroundingSAM, and ProMaC) on three different tasks: Camouflaged Object Detection, Transparent Object Segmentation, and Medical Image Segmentation.  It shows the original images, ground truth masks, and the masks generated by each method.  The visualization helps to compare the performance of the methods across various visual tasks and object types.", "section": "Results and Analysis"}, {"figure_path": "9GhSOp1LYH/figures/figures_19_1.jpg", "caption": "Figure 4: Visualization of various segmentation methods among various segmentation tasks.", "description": "This figure visualizes the results of different segmentation methods on three different tasks: Camouflaged Object Detection, Transparent Object Segmentation, and Medical Image Segmentation. It shows the original images, ground truth masks, and segmentation results obtained using ProMaC, as well as other compared methods.  This allows for a visual comparison of the performance of the various methods across diverse visual characteristics and challenges.", "section": "Results and Analysis"}]