{"references": [{"fullname_first_author": "Vardan Papyan", "paper_title": "Prevalence of neural collapse during the terminal phase of deep learning training", "publication_date": "2020-00-00", "reason": "This paper is foundational for the study of neural collapse, a phenomenon this paper builds upon and extends."}, {"fullname_first_author": "Dustin G Mixon", "paper_title": "Neural collapse with unconstrained features", "publication_date": "2020-00-00", "reason": "This paper introduces the unconstrained features model (UFM), a data-agnostic model that is frequently used to explain neural collapse, which is the theoretical basis used by this paper."}, {"fullname_first_author": "Adityanarayanan Radhakrishnan", "paper_title": "Mechanism for feature learning in neural networks and backpropagation-free machine learning models", "publication_date": "2024-00-00", "reason": "This paper introduces the Neural Feature Ansatz (NFA), a key concept for understanding feature learning in neural networks that this paper uses to explain the mechanism of Deep Neural Collapse."}, {"fullname_first_author": "Daniel Beaglehole", "paper_title": "Mechanism of feature learning in convolutional neural networks", "publication_date": "2023-00-00", "reason": "This paper introduces the Deep Recursive Feature Machine (Deep RFM), a method this paper uses to empirically and theoretically demonstrate the phenomenon of Deep Neural Collapse."}, {"fullname_first_author": "Ben Adlam", "paper_title": "The neural tangent kernel in high dimensions: Triple descent and a multi-scale theory of generalization", "publication_date": "2020-00-00", "reason": "This paper provides theoretical analysis for high-dimensional kernel methods and their generalization, which informs the theoretical analysis of Deep RFM in this paper."}]}