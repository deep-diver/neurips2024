[{"figure_path": "cw5mgd71jW/tables/tables_20_1.jpg", "caption": "Table 1: Questions in Malicious Use Cases dataset: The questions in the Malicious Use Cases dataset are generated using the helpful-only model. The table below contains a randomly sampled question belonging to each category.", "description": "This table presents example questions from each of the four categories of the Malicious Use Cases dataset. Each question is accompanied by a response generated by a language model, illustrating the model's potential to generate harmful content when prompted with unsafe queries.  The categories include Abusive or Fraudulent Content, Deceptive or Misleading Content, Illegal or Highly Regulated Goods or Services Content, and Discrimination.  The table highlights the diversity of harmful responses that can be elicited from language models.", "section": "C.1 Dataset Details"}, {"figure_path": "cw5mgd71jW/tables/tables_22_1.jpg", "caption": "Table 2: Question-answer pairs in the Opportunities to Insult dataset: The questions in the Opportunities to Insult dataset are sampled from a dataset originally gathered to train a helpfulness preference model. The insulting answer are model-generated. Below are three question-answer pairs.", "description": "This table shows three examples of questions and their corresponding model-generated responses from the Opportunities to Insult dataset.  The questions are benign, but the model has been prompted to provide insulting responses, illustrating the dataset's purpose in evaluating the model's ability to resist generating harmful outputs. The table highlights how seemingly innocuous questions can elicit negative responses when the model is manipulated.", "section": "C.1 Dataset Details"}, {"figure_path": "cw5mgd71jW/tables/tables_25_1.jpg", "caption": "Table 3: Effectiveness on Malicious Use Cases Dataset: We present some of the results plotted in Figure 1 in tabular form for additional clarity.", "description": "This table shows the effectiveness of many-shot jailbreaking attacks on different categories of malicious use cases.  The rows represent the number of shots (in-context demonstrations) used in the attack, and the columns represent the four categories: violent-hateful, deceptive, discrimination, and illegal-regulated. The values in the table represent the percentage of harmful responses elicited by the attack for each combination of shots and category.  The results show the increasing effectiveness of the attack as the number of shots increases.", "section": "D.5 Malicious Use Cases Results in Tabular Form"}]