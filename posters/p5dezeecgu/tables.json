[{"figure_path": "P5dEZeECGu/tables/tables_5_1.jpg", "caption": "Table 1: FlexCap's outputs are accurate and length compliant.", "description": "This table presents the results of evaluating FlexCap's performance on the MS-COCO region classification task and its compliance with generating captions of different lengths.  The MS-COCO results demonstrate the model's accuracy in generating captions for various regions. The compliance metrics show how well the generated captions match the target length.", "section": "4.1 Correctness and Compliance of Generated Captions"}, {"figure_path": "P5dEZeECGu/tables/tables_6_1.jpg", "caption": "Table 3: Zero-shot video question answering results reported on MSRVTT-QA and MSVD-QA on the test set. FlexCap-LLM is better than other zero-shot baselines for video VQA benchmarks.", "description": "This table presents the results of zero-shot video question answering experiments on two benchmark datasets: MSRVTT-QA and MSVD-QA.  The performance metric used is mean Average Precision (mAP) for both datasets. The table compares the performance of FlexCap-LLM to other state-of-the-art zero-shot methods. The results demonstrate that FlexCap-LLM outperforms other zero-shot baselines on both datasets.", "section": "4.2 Visual Question Answering"}, {"figure_path": "P5dEZeECGu/tables/tables_16_1.jpg", "caption": "Table 5: Ablations. We vary different aspects of model pre-training, dataset size, and model size and measure its effect on region captioning task on the Visual Genome dataset. In (a) and (b) the visual backbone is ViT-B/16 and in (b) and (c) all models start from contrastively pre-trained weights.", "description": "This ablation study investigates the impact of different factors on the region captioning task using the Visual Genome dataset.  It explores three key aspects:\n\n1. **Contrastive Pre-training:** Compares the performance when using a contrastively pre-trained vision encoder versus training from scratch. \n2. **Data Scaling:** Assesses the effect of varying dataset sizes (0.2B and 32B triplets) on performance.\n3. **Model Scaling:** Evaluates the impact of using different sized models (ViT-B/16 and SO-ViT/14). For all of the above,  the Visual Genome dataset is used for performance evaluation, measuring mean average precision (mAP).", "section": "4.3 Dense Captioning"}, {"figure_path": "P5dEZeECGu/tables/tables_17_1.jpg", "caption": "Table 6: Effect of caption lengths on FlexCap-LLM", "description": "This table shows the impact of using captions with different maximum lengths on the performance of the FlexCap-LLM model on two visual question answering datasets: VQAv2 and GQA.  The results demonstrate that increasing the maximum caption length generally improves the accuracy of the model on both datasets.", "section": "4.2 Visual Question Answering"}, {"figure_path": "P5dEZeECGu/tables/tables_19_1.jpg", "caption": "Table 1: FlexCap's outputs are accurate and length compliant.", "description": "This table presents the results of evaluating FlexCap's performance on the MS-COCO Region Classification task.  The table shows that FlexCap, using top-1 or top-20 caption choices, achieves high mean Average Precision (mAP) values across different caption lengths, indicating both accuracy and compliance with the desired caption length. The results are compared against existing baselines, showcasing FlexCap's superiority.", "section": "4.1 Correctness and Compliance of Generated Captions"}, {"figure_path": "P5dEZeECGu/tables/tables_19_2.jpg", "caption": "Table 1: FlexCap's outputs are accurate and length compliant.", "description": "This table presents the results of evaluating FlexCap's ability to generate accurate and length-compliant captions.  It shows that FlexCap achieves high mean Average Precision (mAP) scores for region classification on the MS-COCO dataset across different caption lengths, indicating the model's accuracy in describing image regions.  Additionally, it demonstrates the model's ability to produce captions of the desired length, highlighting its controllability and compliance.", "section": "4.1 Correctness and Compliance of Generated Captions"}, {"figure_path": "P5dEZeECGu/tables/tables_19_3.jpg", "caption": "Table 1: FlexCap's outputs are accurate and length compliant.", "description": "This table presents the results of evaluating FlexCap's ability to generate captions of varying lengths.  It shows that FlexCap achieves high accuracy (Mean Accuracy and Target Accuracy) across different lengths, demonstrating its ability to generate length-compliant captions.  The metrics used are Mean Length of Predicted Captions and Accuracy. Two separate versions of the experiment (a) MS-COCO Region Classification, and (b) Compliance metrics are presented.", "section": "4.1 Correctness and Compliance of Generated Captions"}, {"figure_path": "P5dEZeECGu/tables/tables_19_4.jpg", "caption": "Table 1: FlexCap's outputs are accurate and length compliant.", "description": "This table presents the results of evaluating FlexCap's performance on the MS-COCO region classification task. It demonstrates FlexCap's accuracy in generating captions of different lengths.  The table shows that FlexCap achieves high accuracy (mAP) and that the generated captions closely match the desired lengths.", "section": "4.1 Correctness and Compliance of Generated Captions"}, {"figure_path": "P5dEZeECGu/tables/tables_19_5.jpg", "caption": "Table 1: FlexCap's outputs are accurate and length compliant.", "description": "This table presents the results of evaluating FlexCap's accuracy and compliance with desired caption lengths in the MS-COCO Region Classification task.  It shows that FlexCap achieves high mean Average Precision (mAP) across different target caption lengths, demonstrating its ability to generate accurate and length-compliant captions.  The compliance metrics illustrate that the generated captions closely match the specified lengths.", "section": "4.1 Correctness and Compliance of Generated Captions"}, {"figure_path": "P5dEZeECGu/tables/tables_19_6.jpg", "caption": "Table 1: FlexCap's outputs are accurate and length compliant.", "description": "This table presents the results of the experiment evaluating the accuracy and length compliance of FlexCap's generated captions. The experiment used the MS-COCO Region Classification task, measuring mean Average Precision (mAP) for different caption lengths (1-8 words).  The results show FlexCap achieving high accuracy in producing captions with the specified number of words.", "section": "4.1 Correctness and Compliance of Generated Captions"}]