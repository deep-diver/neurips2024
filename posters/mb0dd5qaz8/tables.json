[{"figure_path": "MB0DD5qAz8/tables/tables_9_1.jpg", "caption": "Algorithm 5 Online learner", "description": "The algorithm takes as input a hypothesis class H, an offline learner B, and a time horizon T. For every integer b from 0 to T-1, it creates an instance of Algorithm 4 parameterized by b. Then, it runs the Deterministic Weighted Majority Algorithm (DWMA) using these instances of Algorithm 4 as experts on the input stream of examples (x1, y1), ..., (xT, yT).", "section": "3 Adaptive Rates in the Realizable Setting"}, {"figure_path": "MB0DD5qAz8/tables/tables_15_1.jpg", "caption": "Table 3.1 Adaptive Rates in the Realizable Setting", "description": "This table summarizes the main theoretical results of the paper, specifically in the realizable setting. It presents upper bounds on the number of mistakes made by online learners, given access to a predictor and an offline learner. These bounds depend on the quality of predictions, the offline learner's performance, and the Littlestone dimension of the hypothesis class. The table highlights how online learning can be easier when the example stream is easily predictable. ", "section": "3 Adaptive Rates in the Realizable Setting"}, {"figure_path": "MB0DD5qAz8/tables/tables_18_1.jpg", "caption": "Table 3.1: Adaptive Rates in the Realizable Setting", "description": "This table presents the main theoretical result of the paper, which provides upper bounds on the number of mistakes made by an online learner with access to predictions in the realizable setting. The upper bound gracefully adapts to the quality of predictions and the complexity of the hypothesis class. Specifically, it shows that the expected mistake bound interpolates between that of the best offline learner and the worst-case mistake bound.", "section": "3 Adaptive Rates in the Realizable Setting"}]