[{"figure_path": "QvqLdeSLWA/tables/tables_8_1.jpg", "caption": "Table 1: The results of semantic correspondence (left, PCK@0.1) and label-scarce semantic segmentation (right, mIoU\u2191). Red for the best result and blue for the runner-up.", "description": "This table presents the performance comparison of different methods on semantic correspondence and label-scarce semantic segmentation tasks.  The left side shows results for semantic correspondence, measured by PCK@0.1 (Percentage of Correct Keypoints within 0.1 of the image or bounding box size). The right side shows results for label-scarce semantic segmentation, using mIoU (mean Intersection over Union) as the metric.  Methods are categorized into Non-DF (non-diffusion feature), DF (diffusion feature), Baseline (using standard diffusion features without any enhancements), and GATE (the proposed method).  The best performing method for each task is highlighted in red, while the second-best is in blue.", "section": "6.2 Comparison with SOTA"}, {"figure_path": "QvqLdeSLWA/tables/tables_8_2.jpg", "caption": "Table 2: Results on the two standard semantic segmentation datasets, ADE20K and CityScapes. Red for the best result and blue for the runner-up.", "description": "This table presents the results of the proposed GATE method on two standard semantic segmentation datasets: ADE20K and CityScapes.  It compares the performance of GATE against other state-of-the-art (SOTA) methods. The metrics used are mean Intersection over Union (mIoU), overall accuracy (aAcc), and mean accuracy (mAcc). The best performing method for each metric is highlighted in red, and the second-best is in blue, indicating the relative improvements achieved by GATE.", "section": "6.2 Comparison with SOTA"}, {"figure_path": "QvqLdeSLWA/tables/tables_16_1.jpg", "caption": "Table 3: Experimental results comparing the influence on suppressing content shift of ControlNet and IP-Adapter.", "description": "This table presents the results of an experiment comparing the effectiveness of ControlNet and IP-Adapter in suppressing content shift.  The metric used is mIoU (mean Intersection over Union), a common evaluation metric for semantic segmentation.  The table shows that using only ControlNet within the GATE framework leads to a higher mIoU than using only IP-Adapter or no technique at all (DDPM baseline). The full GATE approach (combining both techniques) achieves the highest mIoU, indicating that combining multiple techniques is beneficial for suppressing content shift and improving the overall performance of diffusion features.", "section": "6.3 Qualitative Analysis"}, {"figure_path": "QvqLdeSLWA/tables/tables_18_1.jpg", "caption": "Table 4: Examining GATE on SDXL features. The best result is marked as red. For Baseline, three basic feature maps are used. For other settings, one or two basic feature maps are replaced with technique-enhanced ones, keeping the total number of features unchanged.", "description": "This table presents the results of applying the GATE method to SDXL features. It compares the performance of using only basic features (Baseline), using basic features along with a single technique (Individual), and using basic features along with multiple techniques (Combined). The mIoU metric is used to evaluate the performance, and the best result for each setting is highlighted in red. The table demonstrates that combining multiple techniques through GATE improves the quality of features.", "section": "6.3 Qualitative Analysis"}, {"figure_path": "QvqLdeSLWA/tables/tables_18_2.jpg", "caption": "Table 1: The results of semantic correspondence (left, PCK@0.1) and label-scarce semantic segmentation (right, mIoU\u2191). Red for the best result and blue for the runner-up.", "description": "This table presents the quantitative results of the proposed GATE method on semantic correspondence and label-scarce semantic segmentation tasks.  It compares the performance of GATE against various state-of-the-art (SOTA) methods.  The left side shows results for semantic correspondence (measured by PCK@0.1), while the right side displays results for label-scarce semantic segmentation (measured by mIoU).  The best performing method for each metric is highlighted in red, with the second-best in blue.  The table demonstrates the effectiveness of GATE in enhancing the performance of diffusion features on these tasks.", "section": "6 Experimental Validation"}, {"figure_path": "QvqLdeSLWA/tables/tables_19_1.jpg", "caption": "Table 5: Results on Horse-21 to study the effect of feature amalgamation, using the same setting as Figure 8. Each column corresponds to a group of features. Basic* is extracted at a different timestep with other settings remaining the same as Basic.", "description": "This table presents the results of an ablation study on the Horse-21 dataset, investigating the impact of feature amalgamation on model performance.  Different combinations of feature extraction methods (Basic, Basic* (different timestep), Fine-Grained Prompts, ControlNet, and LoRA) were evaluated and their mIoU scores are reported. The goal was to determine if combining multiple feature extraction techniques improved performance compared to using only one method or using different timesteps.", "section": "6.4 Ablation Study: Effect without Feature Amalgamation"}, {"figure_path": "QvqLdeSLWA/tables/tables_21_1.jpg", "caption": "Table 6: Results (mIoU\u2191) to reveal the impact of adjusting the number of weight assigners. The best result is marked as red.", "description": "This table presents the results of an ablation study on the number of weight assigners used in the feature amalgamation process.  The mIoU (mean Intersection over Union) metric, indicating the performance of semantic correspondence, is reported for different numbers of weight assigners (1 to 4). The results are shown for two different training durations: 1x and 2x the training steps.  The 'Gain' column shows the performance improvement compared to the 1x training steps. The best result for each number of weight assigners is highlighted in red. The table helps demonstrate that adding more weight assigners can enhance performance, but there's a trade-off with training time and computational cost.", "section": "6 Experimental Validation"}, {"figure_path": "QvqLdeSLWA/tables/tables_21_2.jpg", "caption": "Table 7: Experimental results on image classification in comparison to both ResNet and a diffusion feature baseline without GATE.", "description": "This table presents the accuracy results (%) for image classification on the CIFAR10 dataset.  Three methods are compared: ResNet-50 (a standard convolutional neural network), a baseline using diffusion features without the proposed GATE technique, and the proposed GATE method.  The results show that the GATE method outperforms both ResNet-50 and the diffusion feature baseline, indicating its effectiveness in improving the quality of diffusion features for image classification.", "section": "6.3 Qualitative Analysis"}]