{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper provides technical details about GPT-4, a large language model that serves as a foundation for the UniAudio 1.5 model"}, {"fullname_first_author": "Tom Brown", "paper_title": "Language models are few-shot learners", "publication_date": "2020-12-01", "reason": "This is a seminal paper introducing in-context learning, a key concept that UniAudio 1.5 relies upon for few-shot audio task learning."}, {"fullname_first_author": "Alexandre D\u00e9fossez", "paper_title": "High fidelity neural audio compression", "publication_date": "2022-10-13", "reason": "This paper introduces a high-fidelity neural audio codec, providing a relevant baseline and technical comparison for the LLM-Codec proposed in UniAudio 1.5."}, {"fullname_first_author": "Hugo Touvron", "paper_title": "LLaMA: Open and efficient foundation language models", "publication_date": "2023-02-23", "reason": "This paper introduces LLaMA, a large language model used as the foundation for UniAudio 1.5, providing the core capabilities for textual understanding and generation tasks."}, {"fullname_first_author": "Colin Raffel", "paper_title": "Exploring the limits of transfer learning with a unified text-to-text transformer", "publication_date": "2020-12-01", "reason": "This paper introduces T5, a text-to-text transformer model which is used in UniAudio 1.5 for semantic loss calculation, showcasing the effective integration of text and audio modalities"}]}