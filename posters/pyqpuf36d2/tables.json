[{"figure_path": "pyqPUf36D2/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of MI performance with PPA in high-resolution settings. Dprivate = CelebA or FaceScrub, GANs are pre-trained on Dpublic = FFHQ. The symbol \u2193 (or \u2191) indicates smaller (or larger) values are preferred, and the green numbers represent the attack performance improvement. The running time ratio (Ratio) between prior fine-tuning and MI reflects the overhead of fine-tuning.", "description": "This table compares the performance of the Pseudo-Private Data Guided Model Inversion (PPDG-MI) method against the state-of-the-art Plug & Play Attack (PPA) method in high-resolution settings for face recognition tasks.  It shows the improvements in attack accuracy (Acc@1 and Acc@5) and KNN distance achieved by PPDG-MI using different fine-tuning strategies (PPDG-PW, PPDG-CT, PPDG-MMD) across three different target models (ResNet-18, DenseNet-121, ResNeSt-50) and two private datasets (CelebA and FaceScrub). The ratio column indicates the relative computational overhead introduced by the fine-tuning process.  Green numbers highlight the performance gains of PPDG-MI.", "section": "4.2 Main Results"}, {"figure_path": "pyqPUf36D2/tables/tables_8_2.jpg", "caption": "Table 2: Comparison of MI performance with white-box MIAs in low-resolution settings. Target model M = VGG16 trained on Dprivate = CelebA. GANs are trained on Dpublic = CelebA or FFHQ.", "description": "This table presents the results of comparing the performance of the proposed PPDG-vanilla method with several state-of-the-art (SOTA) white-box model inversion attack methods in low-resolution settings. The target model used is VGG16, trained on a private CelebA dataset.  The GANs used in the attacks were trained on either a public CelebA dataset or a public FFHQ dataset. The table shows the accuracy (@1 and @5), KNN distance, and the ratio of the running time between fine-tuning and model inversion for each method.", "section": "4.2 Main Results"}, {"figure_path": "pyqPUf36D2/tables/tables_8_3.jpg", "caption": "Table 3: MI performance against SOTA defense methods in high-resolution settings. The target model M = ResNet-152 is trained on Dprivate = FaceScrub, GANs are pre-trained on Dpublic = FFHQ. Bold numbers indicate superior results.", "description": "This table presents the results of model inversion attacks (MIAs) against state-of-the-art (SOTA) defense methods.  The target model is ResNet-152, trained on a private FaceScrub dataset, with GANs pre-trained on a public FFHQ dataset.  The table compares the performance of the baseline PPA method against three variants of PPDG-MI (PPDG-PW, PPDG-CT, and PPDG-MMD) when facing two defenses: BiDO-HSIC and NegLS. The results are presented in terms of Acc@1 (top-1 attack accuracy) and KNN Dist (K-Nearest Neighbors Distance), indicating the improvement achieved by integrating the PPDG-MI strategy.", "section": "4.2 Main Results"}, {"figure_path": "pyqPUf36D2/tables/tables_16_1.jpg", "caption": "Table 4: A summary of experimental setups.", "description": "This table summarizes the experimental setups used in the paper. It specifies the type of model inversion attack (MIA) used, the private and public datasets used for training and evaluation, the target model used, and the evaluation model used to assess the performance of the attack.  Different rows represent different experimental configurations, categorized by the type of MIA (white-box, black-box, and label-only).", "section": "C Experimental Details"}, {"figure_path": "pyqPUf36D2/tables/tables_19_1.jpg", "caption": "Table 5: Enhance density of pseudo-private data under the prior distribution by distribution alignment.", "description": "This table presents the results of an experiment designed to evaluate the impact of distribution alignment on the performance of model inversion attacks. The experiment compares the performance of a baseline attack (PPA) with an attack that incorporates distribution alignment using PPDG-MI.  The results are presented in terms of attack accuracy (Acc@1\u2191) and KNN distance (KNN Dist\u2193). The goal is to demonstrate that enhancing the density of pseudo-private data under the prior distribution improves the accuracy of model inversion attacks.", "section": "3.4 Nuanced Approach of PPDG-MI for High-Dimensional Image Data"}, {"figure_path": "pyqPUf36D2/tables/tables_20_1.jpg", "caption": "Table 6: Comparison of MI performance with representative white-box MIAs in the low-resolution setting. The target model M is face.evoLVe trained on Dprivate = CelebA. GANs are trained on Dpublic = CelebA or FFHQ. The symbol \u2193 (or \u2191) indicates smaller (or larger) values are preferred, and the green numbers represent the attack performance improvement. The running time ratio (Ratio) between prior fine-tuning and MI reflects the relative overhead of fine-tuning.", "description": "This table compares the performance of several model inversion attack methods (GMI, LOM, KEDMI) with and without the proposed PPDG-vanilla method, on the face.evoLVe model trained with CelebA dataset.  It shows the attack accuracy (Acc@1, Acc@5), KNN distance, and the relative running time for each method, using both CelebA and FFHQ as public datasets for GAN training.  Green numbers highlight the performance improvements achieved by integrating PPDG-vanilla.", "section": "4.2 Main Results"}, {"figure_path": "pyqPUf36D2/tables/tables_20_2.jpg", "caption": "Table 7: Comparison of MI performance with PLG-MI in the low-resolution setting. Target model M = VGG16 or face.evoLVe trained on Dprivate = CelebA. GANs are trained on Dpublic = FaceScrub.", "description": "This table compares the performance of the proposed PPDG-vanilla method against the state-of-the-art PLG-MI method for model inversion attacks on low-resolution images.  The results show the attack accuracy (Acc@1, Acc@5), the KNN distance, and the ratio of running time for fine-tuning versus model inversion for both VGG16 and face.evoLVe target models.  It demonstrates improved MI performance with PPDG-vanilla.", "section": "Additional Experimental Results"}, {"figure_path": "pyqPUf36D2/tables/tables_21_1.jpg", "caption": "Table 8: Comparison of MI performance with RLB-MI and BREP-MI in the low-resolution setting. The target model M is VGG-16 trained on Dprivate = CelebA, GANs are trained on Dpublic = CelebA. The symbol \u2193 (or \u2191) indicates smaller (or larger) values are preferred, and the green numbers represent the attack performance improvement. The running time ratio (Ratio) between prior fine-tuning and MI reflects the relative overhead of fine-tuning.", "description": "This table compares the performance of model inversion attacks (MIAs) using two different methods: RLB-MI (a black-box attack) and BREP-MI (a label-only attack). It shows the results with and without using the proposed PPDG-vanilla method. The metrics used are attack accuracy at top-1 and top-5 (Acc@1\u2191, Acc@5\u2191), KNN distance (KNN Dist\u2193), and the ratio of running time between fine-tuning and the main MI attack (Ratio\u2193). Lower values for KNN Dist are better, while higher values are better for Acc@1\u2191 and Acc@5\u2191. The green numbers indicate the improvements achieved by using PPDG-vanilla.", "section": "Additional Experimental Results"}, {"figure_path": "pyqPUf36D2/tables/tables_21_2.jpg", "caption": "Table 9: Comparison of MI performance against state-of-the-art defense methods in the low-resolution setting. The target model M is VGG16 trained on Dprivate = CelebA, GANs are trained on Dpublic = CelebA. Bold numbers indicate superior results.", "description": "This table presents a comparison of the performance of three model inversion attack methods (LOM (GMI), KEDMI, and LOM (KEDMI)) against two state-of-the-art defense mechanisms (BiDO-HSIC and NegLS) in a low-resolution setting. The results show that incorporating PPDG-vanilla consistently improves attack performance across all three attack methods and both defense mechanisms, highlighting its effectiveness in enhancing the robustness of MIAs against existing defenses.", "section": "4.2 Main Results"}, {"figure_path": "pyqPUf36D2/tables/tables_23_1.jpg", "caption": "Table 10: Ablation study on the number K of high-quality samples selected for fine-tuning. \"Time\" (seconds per identity) denotes the time required for fine-tuning a single identity.", "description": "This table shows the ablation study on the impact of the number of high-quality pseudo-private samples selected for fine-tuning on the performance of PPDG-PW, PPDG-MMD, and PPDG-CT methods. The results indicate that increasing K initially improves performance but eventually leads to a decline due to overfitting and increased computational cost.", "section": "D.2.1 MIAs in the High-resolution setting"}, {"figure_path": "pyqPUf36D2/tables/tables_23_2.jpg", "caption": "Table 11: Ablation study on fine-tuning different layers of the StyleGAN synthesis network. \"Time\" (seconds per identity) denotes the time required for fine-tuning a single identity.", "description": "This ablation study investigates the impact of fine-tuning different layers of the StyleGAN generator on the performance of PPDG-MI. The results show that tuning layers with spatial resolutions from 4\n2\n\u2212128\n2\n achieves comparable results to tuning all layers (4\n2\n\u22121024\n2\n), suggesting that successful MIAs rely more on inferences about high-level features (e.g., face shape) rather than fine-grained details.", "section": "D.2 MIAs in the High-resolution setting"}, {"figure_path": "pyqPUf36D2/tables/tables_23_3.jpg", "caption": "Table 1: Comparison of MI performance with PPA in high-resolution settings. Dprivate = CelebA or FaceScrub, GANs are pre-trained on Dpublic = FFHQ. The symbol \u2193 (or \u2191) indicates smaller (or larger) values are preferred, and the green numbers represent the attack performance improvement. The running time ratio (Ratio) between prior fine-tuning and MI reflects the overhead of fine-tuning.", "description": "This table compares the performance of the state-of-the-art model inversion attack (PPA) with three variants of the proposed PPDG-MI method (PPDG-PW, PPDG-CT, and PPDG-MMD) on two high-resolution face recognition datasets (CelebA and FaceScrub).  The results show the improvement in attack accuracy (Acc@1 and Acc@5) and reduction in KNN distance, indicating better reconstruction of private data with the proposed methods.  The running time ratio shows the computational overhead of adding the PPDG-MI improvements.", "section": "4.2 Main Results"}, {"figure_path": "pyqPUf36D2/tables/tables_24_1.jpg", "caption": "Table 10: Ablation study on the number K of high-quality samples selected for fine-tuning. \"Time\" (seconds per identity) denotes the time required for fine-tuning a single identity.", "description": "This table presents the ablation study results on the impact of the number of high-quality pseudo-private samples (K) used for fine-tuning the generator. It shows the attack accuracy (Acc@1\u2191), K-Nearest Neighbors Distance (KNN Dist\u2193), and the time required for fine-tuning a single identity for different values of K, using three different fine-tuning methods (PPDG-PW, PPDG-CT, and PPDG-MMD).", "section": "D.2.1 MIAs in the High-resolution setting"}, {"figure_path": "pyqPUf36D2/tables/tables_24_2.jpg", "caption": "Table 1: Comparison of MI performance with PPA in high-resolution settings. Dprivate = CelebA or FaceScrub, GANs are pre-trained on Dpublic = FFHQ. The symbol \u2193 (or \u2191) indicates smaller (or larger) values are preferred, and the green numbers represent the attack performance improvement. The running time ratio (Ratio) between prior fine-tuning and MI reflects the overhead of fine-tuning.", "description": "This table compares the performance of the state-of-the-art model inversion attack (PPA) with the proposed PPDG-MI method in high-resolution settings. It shows the improvement in attack accuracy (Acc@1 and Acc@5), reduction in KNN distance, and the running time ratio for three different target models (ResNet-18, DenseNet-121, and ResNeSt-50).  The results are shown for two private datasets (CelebA and FaceScrub).", "section": "4.2 Main Results"}, {"figure_path": "pyqPUf36D2/tables/tables_24_3.jpg", "caption": "Table 15: Ablation study on identity-wise fine-tuning vs. multi-identity fine-tuning.", "description": "This table presents the ablation study comparing the performance of single-identity and multi-identity fine-tuning strategies. The results show that single-identity fine-tuning achieves better performance (higher attack accuracy and lower KNN distance), but multi-identity fine-tuning reduces computational costs.  The trade-off between performance and efficiency is highlighted.", "section": "D.2.2 MIAs in the Low-resolution Setting"}]