[{"figure_path": "bIRcf8i1kp/tables/tables_4_1.jpg", "caption": "Table 2: Key Components of GarmentLab Assets.", "description": "This table lists the key components of GarmentLab Assets, categorized by asset type (Garment and Cloth, Rigid and Articulated, Robot, Human Model, Materials).  For each category, it specifies the sources of the assets (e.g., ClothesNet, ShapeNet) and provides examples of the categories included (e.g., Hats, Ties, Masks for garments; Franka, UR5 for robots). This table gives a high-level overview of the diverse range of assets available in the GarmentLab environment for simulation and benchmarking.", "section": "3.2 GarmentLab Assets"}, {"figure_path": "bIRcf8i1kp/tables/tables_5_1.jpg", "caption": "Table 1: Comparisons with Other Deformable Object Environments.", "description": "This table compares GarmentLab with other deformable object environments across various features, including support for multi-camera scenes, different types of objects (garments, soft objects, rigid bodies, articulated objects, and fluids), sim-to-real capabilities, and the type of physics engine used.  It highlights GarmentLab's unique strengths in offering a comprehensive and realistic simulation environment for garment manipulation.", "section": "2 Related Work"}, {"figure_path": "bIRcf8i1kp/tables/tables_8_1.jpg", "caption": "Table 4: Benchmark Methods of GarmentLab.", "description": "This table provides a summary of the five different methods used in GarmentLab benchmark experiments. It lists the method name, its type (3D/2D visual correspondence, 3D representation, or reinforcement learning), its backbone (the underlying architecture or model), and the input type (point cloud, RGB image, or state-based ground truth).  The methods are compared based on their performance in handling various garment manipulation tasks within the GarmentLab environment.", "section": "7.1 Simulation Experiment Setup"}, {"figure_path": "bIRcf8i1kp/tables/tables_8_2.jpg", "caption": "Table 5: Simulation Results on Traditional Tasks. Numbers in the Large-piece column represent scores for Tops, Trousers and Skirts. Numbers in the Small-piece column represent scores for Hats and Gloves.", "description": "This table presents the quantitative results of five different algorithms (UGM, DIFT, Affordance, RL-State, RL-Vision) on five traditional garment manipulation tasks (Fold, Unfold, Hang, Place, Hang) categorized by Large-piece (Tops, Trousers, Skirts) and Small-piece (Hats, Gloves).  Each cell shows the average success rate across multiple trials for a given algorithm and task.  The results highlight the varying performance of different methods across different task types and garment sizes, offering insights into the strengths and weaknesses of each algorithm.", "section": "7.2 Simulation Result and Analysis"}, {"figure_path": "bIRcf8i1kp/tables/tables_9_1.jpg", "caption": "Table 6: Real-World Experiment and Ablation Results, w/o PA, w/o Noise, and w/o EA respectively represent UniGarmentManip without Pointcloud Alignment, Noise Augmentation, and KeyPoint Embedding Alignment.", "description": "This table presents the results of real-world experiments evaluating the performance of the UniGarmentManip algorithm on two garment manipulation tasks: T-shirt folding and hat hanging.  It also shows an ablation study demonstrating the impact of three key components of the UniGarmentManip sim-to-real approach: Pointcloud Alignment (PA), Noise Augmentation (Noise), and Keypoint Embedding Alignment (EA).  Each entry represents the number of successful trials out of 15 attempts for each task and algorithm configuration.", "section": "7.3 Real-World Experiments"}, {"figure_path": "bIRcf8i1kp/tables/tables_22_1.jpg", "caption": "Table 1: Comparisons with Other Deformable Object Environments.", "description": "This table compares GarmentLab with other deformable object environments across various features, including the types of objects supported (garments, soft objects, rigid bodies, fluids, articulated objects, and humans), simulation methods (FEM and PBD), sim-to-real capabilities, the availability of multi-camera setups, the presence of realistic scenes, and the types of tasks supported (dexterous manipulation, navigation, etc.). GarmentLab stands out due to its support for diverse object types and physics engines, comprehensive sim-to-real capabilities, the inclusion of real-world benchmarks, and its suitability for a wide range of manipulation tasks.", "section": "2 Related Work"}, {"figure_path": "bIRcf8i1kp/tables/tables_25_1.jpg", "caption": "Table 1: Comparisons with Other Deformable Object Environments.", "description": "This table compares GarmentLab with other deformable object environments across various features, including the support for multiple cameras, different types of objects (garments, rigid bodies, articulated objects, humans, fluids), physics engines, sim-to-real capabilities, and the type of tasks supported. It highlights GarmentLab's advantages in terms of its comprehensive features and realistic simulation capabilities.", "section": "2 Related Work"}, {"figure_path": "bIRcf8i1kp/tables/tables_26_1.jpg", "caption": "Table 1: Comparisons with Other Deformable Object Environments.", "description": "This table compares GarmentLab with other deformable object environments across various aspects such as the types of objects supported (garments, soft objects, rigid bodies, articulated objects, humans, fluids), simulation methods (FEM, PBD), sim-to-real capabilities, the presence of multi-camera setups, the availability of real-world benchmarks, and the type of tasks supported (dexterous manipulation, mobile manipulation, navigation tasks, etc.).  The table highlights GarmentLab's unique combination of features, particularly its support for multi-physics simulation, diverse garment types, a real-world benchmark, and robust sim-to-real techniques. ", "section": "2 Related Work"}]