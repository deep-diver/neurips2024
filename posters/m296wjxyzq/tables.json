[{"figure_path": "m296WJXyzQ/tables/tables_7_1.jpg", "caption": "Table 1: Scanning performance of TRODO compared with other methods, in terms of Accuracy on standard trained evaluation sets (ACC %) and adversarially trained ones (ACC* %). The best results are emphasized in bold format respectively in each column.", "description": "This table presents a comparison of the accuracy of the proposed TRODO method against several other state-of-the-art trojan detection methods.  The accuracy is measured on two types of datasets: standard trained models (ACC) and adversarially trained models (ACC*). The results are presented for different label mapping strategies (all-to-one and all-to-all) across multiple datasets (MNIST, CIFAR-10, GTSRB, CIFAR-100, and PubFig).  The table allows readers to assess the performance of TRODO against existing methods under various conditions.", "section": "6 Experiments"}, {"figure_path": "m296WJXyzQ/tables/tables_7_2.jpg", "caption": "Table 2: Comparison of TRODO and other methods on all released rounds of TrojAI benchmark on image classification task. For each method, we reported scanning Accuracy and the average scanning time for the classifiers.", "description": "This table compares the performance of TRODO against other state-of-the-art trojan detection methods on the TrojAI benchmark dataset.  It shows the accuracy and average scanning time for each method across multiple rounds of the benchmark, highlighting TRODO's competitive performance in terms of both accuracy and efficiency.", "section": "Experiments"}, {"figure_path": "m296WJXyzQ/tables/tables_8_1.jpg", "caption": "Table 1: Scanning performance of TRODO compared with other methods, in terms of Accuracy on standard trained evaluation sets (ACC %) and adversarially trained ones (ACC* %). The best results are emphasized in bold format respectively in each column.", "description": "This table presents a comparison of the proposed TRODO method with other state-of-the-art trojan detection methods.  The comparison is done across various datasets (MNIST, CIFAR10, GTSRB, CIFAR100, PubFig) and for two types of label mappings (All-to-One and All-to-All).  Accuracy is reported for both standard and adversarially trained models, allowing for a comprehensive evaluation of performance under different training regimes and attack scenarios.  The best accuracy for each scenario (standard and adversarial) is highlighted in bold.", "section": "Experiments"}, {"figure_path": "m296WJXyzQ/tables/tables_9_1.jpg", "caption": "Table 4: Accuracy of TRODO using various Validation (and OOD) datasets for different ID data. Each validation is used to find the hyperparameters (\u20ac and \u315c) and also as OOD datasets to find signatures. You can see the effect of choosing near-OOD dataset. For example, for CIFAR10, STL-10 and Tiny ImageNet are better choices than the other two datasets", "description": "This table presents the accuracy of the TRODO model when using different validation datasets.  It demonstrates how the choice of validation dataset (which is also used to create the OOD samples) impacts the accuracy of the model.  The Fr\u00e9chet Inception Distance (FID) is included to show how visually similar the validation dataset is to the training data (ID); lower FID values indicate higher visual similarity. The table suggests that using validation sets which are visually similar to the training data, but not drawn from the same distribution, leads to better performance of TRODO.", "section": "Ablation Study"}, {"figure_path": "m296WJXyzQ/tables/tables_9_2.jpg", "caption": "Table 5: Accuracy of our method with different boundary confidence level.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of varying the boundary confidence level (\u03b3) on the performance of TRODO.  The boundary confidence level is a hyperparameter in TRODO that influences the sensitivity of the method. The table shows the accuracy achieved by TRODO across five different datasets (MNIST, CIFAR10, GTSRB, CIFAR100, PubFig) for different values of \u03b3 (0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8).  By comparing the accuracy values across different \u03b3 values for each dataset, one can gain insights into the optimal value of \u03b3 for TRODO, as well as TRODO's sensitivity to this hyperparameter.", "section": "Ablation Study"}, {"figure_path": "m296WJXyzQ/tables/tables_17_1.jpg", "caption": "Table 6: OOD detection AUROC under attack with \\(\\epsilon = \\frac{8}{255}\\) for various methods trained with CIFAR-10 or CIFAR-100 as the training (closed) set. A clean evaluation indicates no attack on the data, whereas an attack evaluation means that out and in data is attacked. The best and second-best results are distinguished with bold and underlined text for each column.", "description": "This table presents the Area Under the Receiver Operating Characteristic Curve (AUROC) for Out-of-Distribution (OOD) detection using various methods.  It compares the performance of different OOD detection methods (ViT, AT, HAT, with variations in scoring methods like MSP, MD, RMD, and OpenMax) under both clean and attacked conditions. The table shows how the AUROC changes when the test data is perturbed with adversarial noise (Attack) compared to when it's not (Clean). The results are shown for two datasets, CIFAR-10 and CIFAR-100, demonstrating the robustness (or lack thereof) of these OOD detection methods against adversarial attacks.", "section": "C Robust OOD detection in Adversarially Trained Classifiers"}, {"figure_path": "m296WJXyzQ/tables/tables_28_1.jpg", "caption": "Table 7: Accuracy of our scanning method across various trojan attacks. For each attack, the trojaned models in the evaluation set are backdoored only with that attack. The number of clean and trojaned models is balanced. The architecture of all the models is resnet18", "description": "This table presents the accuracy of the proposed TRODO method in detecting various backdoor attacks on models with ResNet18 architecture. Each row represents a specific type of backdoor attack, and the columns show the accuracy on different datasets (CIFAR10, MNIST, GTSRB, CIFAR100, PubFig).  The key finding is that TRODO achieves high accuracy in detecting trojaned models across all datasets and different backdoor attacks.", "section": "O Extended Results"}, {"figure_path": "m296WJXyzQ/tables/tables_28_2.jpg", "caption": "Table 1: Scanning performance of TRODO compared with other methods, in terms of Accuracy on standard trained evaluation sets (ACC %) and adversarially trained ones (ACC* %). The best results are emphasized in bold format respectively in each column.", "description": "This table compares the performance of TRODO against several state-of-the-art trojan detection methods.  The accuracy is measured on standard and adversarially trained models, across several datasets (MNIST, CIFAR-10, GTSRB, CIFAR-100, PubFig) and two label mapping strategies (All-to-One, All-to-All).  The best results for each dataset and training type are highlighted in bold.", "section": "Experiments"}, {"figure_path": "m296WJXyzQ/tables/tables_28_3.jpg", "caption": "Table 1: Scanning performance of TRODO compared with other methods, in terms of Accuracy on standard trained evaluation sets (ACC %) and adversarially trained ones (ACC* %). The best results are emphasized in bold format respectively in each column.", "description": "This table presents a comparison of the proposed TRODO method against several state-of-the-art trojan detection methods.  The accuracy of each method is evaluated on two sets of data: standard trained (ACC) and adversarially trained (ACC*). The table shows the accuracy for each method across five different datasets (MNIST, CIFAR10, GTSRB, CIFAR100, PubFig), and the average accuracy across all datasets is also provided.  The best performing method for each dataset and attack type is highlighted in bold. This allows for a comprehensive comparison of the effectiveness of TRODO in various scenarios and datasets.", "section": "Experiments"}, {"figure_path": "m296WJXyzQ/tables/tables_29_1.jpg", "caption": "Table 10: Value of e and 7 for different validation sets and backbone architectures.", "description": "This table shows the values of two hyperparameters, epsilon (e) and tau (\u03c4), used in the TRODO algorithm.  Epsilon controls the size of adversarial perturbations, while tau is a threshold used to determine if a classifier is trojaned based on the ID-score difference.  The table presents these values for four different validation datasets (FMNIST, SVHN, STL-10, and TinyImageNet) and three different network architectures (ResNet-18, PreAct ResNet-18, and ViT-b-16).  These values were determined empirically using each validation set to tune the parameters for the corresponding architecture.", "section": "Ablation Study"}, {"figure_path": "m296WJXyzQ/tables/tables_29_2.jpg", "caption": "Table 1: Scanning performance of TRODO compared with other methods, in terms of Accuracy on standard trained evaluation sets (ACC %) and adversarially trained ones (ACC* %). The best results are emphasized in bold format respectively in each column.", "description": "This table presents a comparison of the proposed TRODO method against several state-of-the-art trojan detection methods.  The comparison is made across different datasets (MNIST, CIFAR10, GTSRB, CIFAR100, PubFig) and two scenarios: standard training and adversarial training. The accuracy of each method is reported for both scenarios, allowing for a comprehensive evaluation of their performance in various settings.  The table highlights the superior performance of TRODO in most cases, especially when the trojaned models are also adversarially trained.", "section": "Experiments"}, {"figure_path": "m296WJXyzQ/tables/tables_29_3.jpg", "caption": "Table 1: Scanning performance of TRODO compared with other methods, in terms of Accuracy on standard trained evaluation sets (ACC %) and adversarially trained ones (ACC* %). The best results are emphasized in bold format respectively in each column.", "description": "This table presents a comparison of the proposed TRODO method against existing state-of-the-art trojan detection methods across various datasets and label mappings.  It shows the accuracy of each method on both standard and adversarially trained models, highlighting TRODO's superior performance, especially when dealing with adversarially trained models.", "section": "Experiments"}, {"figure_path": "m296WJXyzQ/tables/tables_30_1.jpg", "caption": "Table 13: Performance comparison of TRODO-Zero under different OOD sample rates across datasets.", "description": "This table presents the performance of the TRODO-Zero model under varying OOD sample rates across different datasets. The performance is measured in terms of accuracy (ACC) and adversarially trained accuracy (ACC*) for each dataset (MNIST, CIFAR10, GTSRB, CIFAR100, PubFig). The average accuracy across all datasets is also reported for each OOD sample rate.  Different sample rates (0.1%, 0.2%, 0.3%, 0.5%, and 1%) are evaluated to analyze the impact of the amount of OOD data on the model's performance.  The table is part of an ablation study to understand how the size of OOD samples affects the model.", "section": "P Extra Ablation Studies"}]