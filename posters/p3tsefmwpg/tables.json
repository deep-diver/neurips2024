[{"figure_path": "p3tSEFMwpG/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a quantitative comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across a range of synthetic and real-world datasets.  For each dataset subset (synthetic and real-world), the table shows the performance of each model using metrics such as accuracy, F1-score, ROC AUC, and Expected Calibration Error (ECE), both for in-distribution (ID) and out-of-distribution (OOD) data.  The best-performing model for each metric within each dataset subset is highlighted in bold.  The results are averaged over three runs with 95% confidence intervals to reflect the statistical significance.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_18_1.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a comparison of the proposed Drift-Resilient TabPFN model against several baseline models on 18 datasets (8 synthetic, 10 real-world).  Performance metrics (Accuracy, F1-score, ROC AUC, and ECE) are reported for both in-distribution (ID) and out-of-distribution (OOD) data.  The results are averaged over three runs and include 95% confidence intervals.  The best-performing model for each metric is highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_18_2.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a comprehensive comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across a diverse set of 18 datasets (8 synthetic, 10 real-world).  The performance is evaluated using four key metrics: Accuracy, F1-score, ROC AUC, and ECE.  Results are shown for both in-distribution (ID) and out-of-distribution (OOD) data, reflecting the model's ability to generalize beyond the training data.  The table highlights the best-performing model for each metric in each dataset subset.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_21_1.jpg", "caption": "Table 4: Comparison of Drift-Resilient TabPFN against DRAIN and GI on the Rotated Two Moons dataset. The metric reported is the mean out-of-distribution (OOD) accuracy along with the standard deviation. Results for DRAIN and GI are taken from Bai et al. [12].", "description": "This table compares the out-of-distribution (OOD) accuracy of Drift-Resilient TabPFN against two state-of-the-art methods, DRAIN and GI, on the Rotated Two Moons dataset.  It shows the mean OOD accuracy and its standard deviation for each method. The results for DRAIN and GI are taken from the referenced paper by Bai et al. [12].", "section": "A.4.4 Quantitative Analysis"}, {"figure_path": "p3tSEFMwpG/tables/tables_21_2.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a comprehensive comparison of the proposed Drift-Resilient TabPFN model against various baseline methods across 18 datasets (8 synthetic and 10 real-world).  For each dataset subset (synthetic and real-world), it shows the performance of different models and variations using four evaluation metrics: Accuracy, F1-score, ROC AUC, and ECE.  The results are averaged over three different initializations and presented with 95% confidence intervals. The best-performing model for each metric in each dataset subset is highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_23_1.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a comprehensive comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across various datasets.  It shows the accuracy, F1 score, ROC AUC, and Expected Calibration Error (ECE) for both in-distribution (ID) and out-of-distribution (OOD) data.  The results are averaged over multiple runs to provide confidence intervals, and the best-performing methods are highlighted for each metric. The table helps to quantify the performance improvements of the proposed method, particularly in handling out-of-distribution data.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_24_1.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across a range of synthetic and real-world datasets.  It shows the performance of each model in terms of accuracy, F1 score, ROC AUC, and Expected Calibration Error (ECE) for both in-distribution (ID) and out-of-distribution (OOD) settings.  The results are averaged over three independent runs and include 95% confidence intervals. The best performing model for each metric in each dataset subset is highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_34_1.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a quantitative comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across a range of synthetic and real-world datasets.  The performance is evaluated using multiple metrics: accuracy, F1-score, ROC AUC, and Expected Calibration Error (ECE).  The results are shown for both in-distribution (ID) and out-of-distribution (OOD) data, which helps to assess the model's generalization ability to unseen data.  The best performing model for each metric in each dataset subset is highlighted in bold, and the overall trend of optimization for each metric (improvement or reduction) is indicated by arrows.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_35_1.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a detailed comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across various datasets.  It shows performance metrics (accuracy, F1-score, ROC AUC, and ECE) for both in-distribution (ID) and out-of-distribution (OOD) data, providing a comprehensive evaluation of the model's robustness to distribution shifts.  The best performing model for each metric in each dataset subset is highlighted in bold.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_36_1.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a comprehensive comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across 18 datasets (8 synthetic, 10 real-world).  It shows the performance of each model (including different configurations)  in terms of accuracy, F1-score, ROC AUC, and Expected Calibration Error (ECE), both for in-distribution (ID) and out-of-distribution (OOD) data. The best-performing model for each metric is highlighted in bold.  The table demonstrates the superior performance of Drift-Resilient TabPFN, especially for OOD data, and provides quantitative support for the claims made in the paper.", "section": "4 Experiments"}, {"figure_path": "p3tSEFMwpG/tables/tables_36_2.jpg", "caption": "Table 1: Comparison of Drift-Resilient TabPFN with various baselines and settings across the subsets of synthetic and real-world datasets. Metrics include accuracy, F1, ROC, and ECE for both in-distribution (ID) and out-of-distribution (OOD) data, averaged over three initializations and reported with 95% confidence intervals. The best mean of each metric within a dataset subset is marked in bold. Metric arrows indicate optimization direction.", "description": "This table presents a quantitative comparison of the proposed Drift-Resilient TabPFN model against several baseline methods across 18 datasets (8 synthetic and 10 real-world).  For each dataset, the table shows the performance of different model variants and baselines in terms of accuracy, F1-score, ROC AUC, and Expected Calibration Error (ECE) for both in-distribution (ID) and out-of-distribution (OOD) data.  The best performing model for each metric is highlighted in bold.  The results are averaged across three separate model initializations and include 95% confidence intervals.  The table also indicates the direction of optimization for each metric (improvement indicated by an upward-pointing arrow).", "section": "4 Experiments"}]