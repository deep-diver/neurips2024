[{"figure_path": "kK23oMGe9g/figures/figures_0_1.jpg", "caption": "Figure 1: Immiscible Diffusion can use a single line of code to efficiently achieve immiscibility by re-assigning a batch of noise to images. This process results in only a 2% reduction in distance post-assignment, leading to up to 3x increased training efficiency on top of the Consistency Model for CIFAR Dataset. Additionally, Immiscible Diffusion significantly enhances the image quality of Stable Diffusion for both unconditional and conditional generation tasks, and for both training from scratch and fine-tuning training tasks, on ImageNet Dataset within the same number of training steps.", "description": "This figure summarizes the key results of the Immiscible Diffusion method.  It shows that with a single line of code, the method achieves immiscibility (meaning the noise assigned to each image is distinct, not a random mixture), resulting in a minimal distance reduction (only 2%) yet a significant increase in training efficiency (up to 3x faster than the baseline on CIFAR-10 dataset). The improved efficiency translates to better image quality in Stable Diffusion on ImageNet, improving both unconditional and conditional generation and both training from scratch and fine-tuning tasks.", "section": "1 Introduction"}, {"figure_path": "kK23oMGe9g/figures/figures_2_1.jpg", "caption": "Figure 2: Physics illustration of Immiscible Diffusion. (a) depict the miscible and Immiscible Diffusion phenomenon in physics, while (b) demonstrate the image-noise pair relation in vanilla (miscible) and Immiscible Diffusion method.", "description": "The figure illustrates the concept of immiscible diffusion in both physics and image generation.  Panel (a) shows how miscible particles mix completely, while immiscible particles maintain distinct regions even after diffusion.  Panel (b) translates this to image generation, showing how vanilla diffusion methods produce a complete mix of image and noise data, making optimization difficult. In contrast, the Immiscible Diffusion method maintains distinct mappings between image and noise regions, making optimization easier.", "section": "3 Method"}, {"figure_path": "kK23oMGe9g/figures/figures_5_1.jpg", "caption": "Figure 3: Feature analysis of vanilla (miscible) and immiscible DDIM. Referring to [45], \u03c4 = S represents the layer denoising from the pure noise. We show that while the two sampled noises are similar, the denoised image of immiscible DDIM significantly outperforms that of the traditional one, generating an overall reasonable image. The reason behind this is traditional methods cannot successfully predict noises at noisy layers.", "description": "This figure compares the denoising process of vanilla DDIM and Immiscible DDIM. It shows that while both methods use similar sampled noise, Immiscible DDIM produces significantly better denoised images, particularly in the noisier layers. This is because traditional methods struggle to accurately predict noise in these layers, while Immiscible DDIM excels at this.", "section": "3.3 Mathematical Illustration"}, {"figure_path": "kK23oMGe9g/figures/figures_7_1.jpg", "caption": "Figure 4: Evaluation of baseline and immiscible Consistency Models on (a) CIFAR-10, (b) CelebA, and (c) tiny-ImageNet dataset. We illustrate the FID of two models with different training steps. Clearly, immiscible Consistency Models have much higher efficiency than the vanilla ones.", "description": "This figure compares the FID (Fr\u00e9chet Inception Distance) scores of baseline and immiscible Consistency Models trained on three different datasets (CIFAR-10, CelebA, and Tiny-ImageNet) with varying training steps.  The results show that the immiscible models achieve significantly lower FID scores with fewer training steps, demonstrating their higher training efficiency.  The 3x improvement highlighted in the CIFAR-10 plot emphasizes the substantial speedup.", "section": "4.2 Training Efficiency Improvement with Linear Assignment"}, {"figure_path": "kK23oMGe9g/figures/figures_7_2.jpg", "caption": "Figure 5: Evaluation of baseline and Immiscible DDIM on CIFAR-10 dataset with different inference steps S. We find that Immiscible DDIM outperforms the baseline more significantly when the number of inference steps S is smaller.", "description": "This figure shows the FID (Fr\u00e9chet Inception Distance) scores for baseline DDIM and Immiscible DDIM models trained on the CIFAR-10 dataset.  Three subplots are presented, each representing a different number of inference steps (S): 20, 50, and 100.  The results demonstrate that Immiscible DDIM consistently achieves lower FID scores than the baseline DDIM across all three inference step settings, indicating improved image generation quality. The improvement is particularly pronounced when fewer inference steps are used (S=20).", "section": "4.2 Training Efficiency Improvement with Linear Assignment"}, {"figure_path": "kK23oMGe9g/figures/figures_8_1.jpg", "caption": "Figure 4: Evaluation of baseline and immiscible Consistency Models on (a) CIFAR-10, (b) CelebA, and (c) tiny-ImageNet dataset. We illustrate the FID of two models with different training steps. Clearly, immiscible Consistency Models have much higher efficiency than the vanilla ones.", "description": "This figure shows the FID (Fr\u00e9chet Inception Distance) scores for baseline and immiscible Consistency Models trained on three different datasets: CIFAR-10, CelebA, and tiny-ImageNet.  The x-axis represents the number of training steps, and the y-axis represents the FID score. Lower FID scores indicate better image quality. The figure demonstrates that the immiscible Consistency Model converges to a lower FID score much faster than the baseline model for all three datasets, indicating significantly improved training efficiency.  The plots visually represent the faster convergence of the immiscible model to a lower FID, signifying its superior training efficiency compared to the traditional model.", "section": "4.2 Training Efficiency Improvement with Linear Assignment"}, {"figure_path": "kK23oMGe9g/figures/figures_9_1.jpg", "caption": "Figure 7: Ablation of OT in Immiscible Diffusion. FIDs of OT and non-OT Immiscible Diffusion indicates that it is the Immiscible Diffusion rather than OT that dominate the performance enhancement.", "description": "This figure shows the ablation study of Optimal Transport (OT) in the Immiscible Diffusion method. Three different FID curves are plotted: Vanilla DDIM, Non-OT Immiscible DDIM, and OT Immiscible DDIM. The FID values are plotted against the training steps. The results indicate that Immiscible Diffusion, rather than OT, is the primary factor contributing to performance improvement.", "section": "4.3 Discussion"}, {"figure_path": "kK23oMGe9g/figures/figures_14_1.jpg", "caption": "Figure 8: Effectiveness of Immiscible DDIM in a selected range of batch sizes.", "description": "The figure shows the FID scores for both vanilla and immiscible DDIM models trained on CIFAR-10 dataset with different batch sizes (128, 256, 512). The x-axis represents the number of training steps (in thousands), and the y-axis represents the FID score.  The plot demonstrates that Immiscible DDIM consistently outperforms vanilla DDIM across all batch sizes, achieving lower FID scores at various training steps.  This suggests that the Immiscible Diffusion technique improves training efficiency regardless of the batch size used.", "section": "4.2 Training Efficiency Improvement with Linear Assignment"}, {"figure_path": "kK23oMGe9g/figures/figures_14_2.jpg", "caption": "Figure 9: Qualitative comparison for Immiscible and baseline Consistency Model. We show images generated with the two models trained for 100k steps respectively. Compared to baseline method, immiscible models capture more details and more features of objects.", "description": "This figure shows a qualitative comparison of images generated by Immiscible and baseline Consistency Models.  The models were trained for 100,000 steps each. The top row displays images generated from CIFAR-10, showing significantly clearer and more detailed images from the Immiscible model.  The bottom row shows images generated from CelebA, again highlighting the superior detail and feature capture by the Immiscible model. This visual comparison directly supports the paper's claims of improved image quality with Immiscible Diffusion.", "section": "A.2 Qualitative Evaluations of Immiscible Diffusion"}, {"figure_path": "kK23oMGe9g/figures/figures_15_1.jpg", "caption": "Figure 1: Immiscible Diffusion can use a single line of code to efficiently achieve immiscibility by re-assigning a batch of noise to images. This process results in only a 2% reduction in distance post-assignment, leading to up to 3x increased training efficiency on top of the Consistency Model for CIFAR Dataset. Additionally, Immiscible Diffusion significantly enhances the image quality of Stable Diffusion for both unconditional and conditional generation tasks, and for both training from scratch and fine-tuning training tasks, on ImageNet Dataset within the same number of training steps.", "description": "This figure summarizes the core idea and results of Immiscible Diffusion. It shows that with a simple one-line code change, the method achieves immiscibility in noise assignment, resulting in a 2% reduction in image-noise distance and a 3x speedup in training for CIFAR-10 dataset.  The improved image quality of Stable Diffusion on ImageNet, across various generation tasks and training scenarios, is also highlighted.", "section": "1 Introduction"}, {"figure_path": "kK23oMGe9g/figures/figures_16_1.jpg", "caption": "Figure 1: Immiscible Diffusion can use a single line of code to efficiently achieve immiscibility by re-assigning a batch of noise to images. This process results in only a 2% reduction in distance post-assignment, leading to up to 3x increased training efficiency on top of the Consistency Model for CIFAR Dataset. Additionally, Immiscible Diffusion significantly enhances the image quality of Stable Diffusion for both unconditional and conditional generation tasks, and for both training from scratch and fine-tuning training tasks, on ImageNet Dataset within the same number of training steps.", "description": "This figure demonstrates the effectiveness of Immiscible Diffusion.  A single line of code reassigns noise to images, resulting in only a 2% reduction in image-noise distance but a 3x increase in training efficiency for the CIFAR dataset using the Consistency Model.  Immiscible Diffusion also improves image quality for Stable Diffusion on ImageNet, regardless of whether the model is trained from scratch or fine-tuned.", "section": "1 Introduction"}, {"figure_path": "kK23oMGe9g/figures/figures_17_1.jpg", "caption": "Figure 1: Immiscible Diffusion can use a single line of code to efficiently achieve immiscibility by re-assigning a batch of noise to images. This process results in only a 2% reduction in distance post-assignment, leading to up to 3x increased training efficiency on top of the Consistency Model for CIFAR Dataset. Additionally, Immiscible Diffusion significantly enhances the image quality of Stable Diffusion for both unconditional and conditional generation tasks, and for both training from scratch and fine-tuning training tasks, on ImageNet Dataset within the same number of training steps.", "description": "The figure shows a comparison of Immiscible Diffusion and other methods in terms of training efficiency and image quality.  Immiscible Diffusion achieves a 3x speedup in training and improved image quality with only a single line of code change.", "section": "1 Introduction"}, {"figure_path": "kK23oMGe9g/figures/figures_18_1.jpg", "caption": "Figure 1: Immiscible Diffusion can use a single line of code to efficiently achieve immiscibility by re-assigning a batch of noise to images. This process results in only a 2% reduction in distance post-assignment, leading to up to 3x increased training efficiency on top of the Consistency Model for CIFAR Dataset. Additionally, Immiscible Diffusion significantly enhances the image quality of Stable Diffusion for both unconditional and conditional generation tasks, and for both training from scratch and fine-tuning training tasks, on ImageNet Dataset within the same number of training steps.", "description": "This figure shows the effectiveness of Immiscible Diffusion.  A single line of code reassigns noise to images, resulting in a 2% distance reduction and a 3x training efficiency increase for CIFAR-10. Image quality is also improved for Stable Diffusion on ImageNet.", "section": "1 Introduction"}, {"figure_path": "kK23oMGe9g/figures/figures_19_1.jpg", "caption": "Figure 15: Generated images from immiscible and baseline stable diffusion models trained unconditionally on 10% ImageNet Dataset for 70k steps without cherry-picking", "description": "This figure shows a qualitative comparison of images generated by the immiscible and baseline Stable Diffusion models. Both models were trained unconditionally on 10% of the ImageNet dataset for 70,000 steps.  The images demonstrate that the immiscible Stable Diffusion model produces images with more details and better overall quality than the baseline model.", "section": "A.2.5 Generated images from immiscible and baseline stable diffusion models trained unconditionally on 10% ImageNet Dataset for 70k steps without cherry-picking"}, {"figure_path": "kK23oMGe9g/figures/figures_20_1.jpg", "caption": "Figure 14: Images generated by immiscible and baseline Stable Diffusion trained unconditionally on ImageNet for 70k steps. We see that the Immiscible Stable Diffusion presents more reasonable modal and catch more general features and details.", "description": "This figure shows a qualitative comparison of images generated by the immiscible and baseline Stable Diffusion models after 70k training steps on a subset of the ImageNet dataset.  The immiscible model produces images with more coherent and realistic details compared to the baseline.", "section": "A.2.4 Generated images from immiscible and baseline stable diffusion models trained unconditionally on 10% ImageNet for 70k steps."}, {"figure_path": "kK23oMGe9g/figures/figures_21_1.jpg", "caption": "Figure 1: Immiscible Diffusion can use a single line of code to efficiently achieve immiscibility by re-assigning a batch of noise to images. This process results in only a 2% reduction in distance post-assignment, leading to up to 3x increased training efficiency on top of the Consistency Model for CIFAR Dataset. Additionally, Immiscible Diffusion significantly enhances the image quality of Stable Diffusion for both unconditional and conditional generation tasks, and for both training from scratch and fine-tuning training tasks, on ImageNet Dataset within the same number of training steps.", "description": "This figure summarizes the key findings of the Immiscible Diffusion method.  It highlights that a simple one-line code change leads to a significant speedup in diffusion model training (up to 3x faster) and improved image quality, with minimal impact on the overall distance between image and noise data points. The effects are observed across different datasets (CIFAR and ImageNet) and training tasks (unconditional generation, conditional generation, and fine-tuning).", "section": "Figure 1"}, {"figure_path": "kK23oMGe9g/figures/figures_21_2.jpg", "caption": "Figure 6: Evaluation of baseline and immiscible class-conditional Stable Diffusion on ImageNet dataset, using 20 inference steps. (a) FID of two models trained from scratch (b) FID of two models fine-tuned on Stable Diffusion v1.4.", "description": "This figure shows the results of experiments comparing the baseline and immiscible class-conditional Stable Diffusion models on the ImageNet dataset.  Two versions of the model are evaluated: one trained from scratch and one fine-tuned from Stable Diffusion v1.4. The Fr\u00e9chet Inception Distance (FID) metric is used to evaluate the generated images, providing a quantitative measure of the quality of the generated samples. The results demonstrate the performance improvements achieved with the Immiscible Diffusion method across both training scenarios (from scratch and fine-tuning).", "section": "Experiments"}]