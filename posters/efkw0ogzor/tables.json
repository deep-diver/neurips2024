[{"figure_path": "EFkw0OgZOr/tables/tables_7_1.jpg", "caption": "Table 1: Open-vocabulary monocular 3D object detection results on KITTI and nuScenes. To compare with the baseline, we also present the OVM3D-Det results trained using ground-truth annotations for base classes and pseudo labels for novel classes, denoted by *. ", "description": "This table presents a comparison of open-vocabulary monocular 3D object detection results on the KITTI and nuScenes datasets.  It shows the performance of different methods, including an oracle model trained with full ground truth labels, a model using Grounding DINO for novel class prediction, and the proposed OVM3D-Det model with and without ground truth labels for base classes. The APB and APN columns represent the average precision for base classes and novel classes, respectively.  The numbers in parentheses indicate the improvement in APN achieved by OVM3D-Det compared to the baselines.", "section": "4.2 Main Results"}, {"figure_path": "EFkw0OgZOr/tables/tables_7_2.jpg", "caption": "Table 2: Open-vocabulary monocular 3D object detection results on SUN RGB-D and ARKitScenes. To compare with the baseline, we also present the OVM3D-Det results trained using ground-truth annotations for base classes and pseudo labels for novel classes, denoted by *.", "description": "This table presents the results of open-vocabulary monocular 3D object detection on SUN RGB-D and ARKitScenes datasets. It compares the performance of four different methods:\n\n1.  **Oracle Cube R-CNN:** Uses ground truth labels for both base and novel classes, serving as an upper bound on performance.\n2.  **Cube R-CNN + Grounding DINO:** Uses ground truth labels for base classes and leverages Grounding DINO for novel class prediction.\n3.  **OVM3D-Det*:**  Uses ground truth labels for base classes and pseudo labels for novel classes, serving as an intermediate comparison point for the proposed method.\n4.  **OVM3D-Det:** Uses only pseudo labels generated by the proposed method, reflecting its fully unsupervised nature.\n\nThe table shows Average Precision (AP) values for both base (B) and novel (N) classes on each dataset, highlighting the performance gain of OVM3D-Det compared to baselines, especially for novel categories.", "section": "4.2 Main Results"}, {"figure_path": "EFkw0OgZOr/tables/tables_7_3.jpg", "caption": "Table 3: Comparison with point cloud-based open-vocabulary 3D object detection methods on SUN RGB-D.", "description": "This table compares the performance of the proposed OVM3D-Det model against several existing point cloud-based open-vocabulary 3D object detection methods on the SUN RGB-D dataset.  The comparison focuses on the average precision (AP) metric, highlighting the significant improvement achieved by OVM3D-Det, which leverages only RGB images for training.", "section": "4.2 Main Results"}, {"figure_path": "EFkw0OgZOr/tables/tables_7_4.jpg", "caption": "Table 4: Comparison with point cloud-based open-vocabulary 3D object detection methods on KITTI.", "description": "This table compares the performance of the proposed OVM3D-Det model against existing point cloud-based open-vocabulary 3D object detection methods on the KITTI dataset.  It highlights the significant improvement achieved by OVM3D-Det in terms of average precision (AP), demonstrating its superiority in open-vocabulary 3D object detection without relying on LiDAR point cloud data.", "section": "4.2 Main Results"}, {"figure_path": "EFkw0OgZOr/tables/tables_8_1.jpg", "caption": "Table 5: Ablation studies. Default settings are marked in gray", "description": "This table presents the results of ablation studies conducted on the KITTI dataset to analyze the impact of different components of the OVM3D-Det framework.  It shows how the performance (measured by Average Precision, AP) changes when specific components are removed or modified. The components examined include the core framework, the adaptive pseudo-LiDAR erosion, orientation estimation method, dimension priors, box search loss function, and the thresholds used for the box search. The results highlight the importance of each component and the overall effectiveness of the proposed adaptive methods.", "section": "4.3 Ablation Studies"}, {"figure_path": "EFkw0OgZOr/tables/tables_9_1.jpg", "caption": "Table 6: Self-training can further improve the quality of the initially generated pseudo boxes.", "description": "This table shows the improvement of the model's performance after applying self-training. Self-training is a technique that uses the model's previous predictions as pseudo-labels to further train the model. The table shows that after self-training, the model's overall performance (AP) improves, and the performance on objects at various distances (AP-Near, AP-Middle, AP-Far) also improves.", "section": "4.4 Qualitative Results"}, {"figure_path": "EFkw0OgZOr/tables/tables_15_1.jpg", "caption": "Table 7: Category splits for open-vocabulary 3D detection.", "description": "This table shows how the datasets used in the paper (KITTI, nuScenes, SUN RGB-D, and ARKitScenes) are divided into base classes and novel classes. The base classes are those present in the training data, while the novel classes are those not seen during training and used to test the model's ability to generalize to unseen objects.", "section": "4.1 Experiment Setup"}, {"figure_path": "EFkw0OgZOr/tables/tables_15_2.jpg", "caption": "Table 8: LLM-generated priors and real priors of KITTI dataset.", "description": "This table compares the typical dimensions (length, width, height) of objects in the KITTI dataset as predicted by a large language model (LLM) and as calculated from the actual data statistics.  This comparison helps demonstrate the effectiveness of the LLM in providing reasonable estimations of object dimensions, which are used to evaluate the plausibility of automatically generated 3D bounding boxes.", "section": "4.3 Ablation Studies"}, {"figure_path": "EFkw0OgZOr/tables/tables_15_3.jpg", "caption": "Table 9: LLM-generated priors and real priors of nuScenes dataset.", "description": "This table compares the typical dimensions (length, width, height) of various object categories in the nuScenes dataset, as predicted by a large language model (LLM) and as derived from the dataset's statistical distribution.  The comparison helps assess the accuracy and reliability of using LLM-generated priors as a reasonable estimate for object dimensions in the absence of ground truth data. The slight discrepancies may arise from inherent ambiguities in natural language descriptions and variations in object sizes.", "section": "4.1 Experiment Setup"}, {"figure_path": "EFkw0OgZOr/tables/tables_16_1.jpg", "caption": "Table 1: Open-vocabulary monocular 3D object detection results on KITTI and nuScenes. To compare with the baseline, we also present the OVM3D-Det results trained using ground-truth annotations for base classes and pseudo labels for novel classes, denoted by *.", "description": "This table presents a comparison of open-vocabulary monocular 3D object detection results on the KITTI and nuScenes datasets.  It compares the performance of the proposed OVM3D-Det model against several baselines.  The results are broken down into average precision (AP) for both base classes and novel classes. A variant of the OVM3D-Det model is included (*), which uses ground truth labels for base classes and pseudo labels for novel classes, demonstrating the effectiveness of the method's pseudo-labeling technique.", "section": "4.2 Main Results"}, {"figure_path": "EFkw0OgZOr/tables/tables_16_2.jpg", "caption": "Table 1: Open-vocabulary monocular 3D object detection results on KITTI and nuScenes. To compare with the baseline, we also present the OVM3D-Det results trained using ground-truth annotations for base classes and pseudo labels for novel classes, denoted by *.", "description": "This table presents the results of open-vocabulary monocular 3D object detection experiments performed on the KITTI and nuScenes datasets.  The results are compared against several baselines, including an oracle model trained with ground truth labels,  a model using Grounding DINO for novel class labeling and the proposed OVM3D-Det method.  A variant of OVM3D-Det (*) is included which uses ground truth for base classes and pseudo labels for novel classes to help understand the effectiveness of the pseudo-labeling approach.", "section": "4.2 Main Results"}, {"figure_path": "EFkw0OgZOr/tables/tables_17_1.jpg", "caption": "Table 12: Depth Estimation and 3D Detection Performance on KITTI dataset.", "description": "This table shows the comparison result of depth estimation and 3D detection performance on KITTI dataset using two different depth estimation models: Metric3D and Unidepth.  It demonstrates the correlation between depth estimation accuracy and the performance of the 3D object detection model. A more accurate depth estimation model leads to better 3D detection performance. ", "section": "4.3 Ablation Studies"}, {"figure_path": "EFkw0OgZOr/tables/tables_18_1.jpg", "caption": "Table 13: Licenses of assets used.", "description": "This table lists the assets used in the paper and specifies their respective licenses.  The assets include various models for 3D object detection and depth estimation, as well as several publicly available datasets.  Knowing the licenses is important for understanding the usage rights and restrictions for each asset.", "section": "G Licenses"}]