[{"figure_path": "ZNqHm0a35E/figures/figures_1_1.jpg", "caption": "Figure 1: Incremental Vision-Language Object Detection (IVLOD) aims to enhance VLODMs' performance across specialized domains via incremental learning, while also preserving their zero-shot generalization capability, enabling them to handle both known and unknown objects simultaneously and effectively.", "description": "The figure shows a comparison of three different approaches for adapting Vision-Language Object Detection Models (VLODMs) to multiple downstream tasks.  The first approach is zero-shot learning (no adaptation), the second is conventional incremental learning using CL-DETR, and the third is zero-shot generalizable incremental learning (IVLOD) proposed in the paper. The figure demonstrates that IVLOD, unlike general incremental object detection, maintains the original zero-shot performance of the VLODM while also performing incremental learning.  It highlights the challenges of catastrophic forgetting (performance decline on previously learned tasks when introducing new tasks) and maintaining zero-shot generalizability in IVLOD.", "section": "1 Introduction"}, {"figure_path": "ZNqHm0a35E/figures/figures_4_1.jpg", "caption": "Figure 2: Our framework, features two Reparameterizable Dual Branch with Zero-interference Loss on both the vision and language sides.", "description": "This figure illustrates the architecture of the proposed method, Zero-interference Reparameterizable Adaptation (ZiRa), for Incremental Vision-Language Object Detection (IVLOD).  It shows how the model adapts to new tasks sequentially by adding reparameterizable dual branches to both the language and vision sides of a pre-trained Vision-Language Object Detection Model (VLODM). The dual branches, named Reparameterizable Dual Branch (RDB), consist of a high-learning-rate branch (HLRB) and a low-learning-rate branch (LLRB).  The Zero-interference Loss (ZiL) is applied to both RDBs to prevent forgetting previously learned knowledge and maintain zero-shot generalizability.  The figure highlights the interaction between image features, text prompts, the RDBs, and the final object detection output.", "section": "3.1 Overview"}, {"figure_path": "ZNqHm0a35E/figures/figures_4_2.jpg", "caption": "Figure 3: The structure of the Reparameterizable Dual Branch (RDB).", "description": "The figure illustrates the architecture of the Reparameterizable Dual Branch (RDB), a key component of the ZiRa approach.  It shows the dual-branch structure within the RDB, comprising the Low-learning rate Branch (LLRB) and the High-learning rate Branch (HLRB).  The LLRB is set at \u03b7 (0 < \u03b7 < 1) times the learning rate of the HLRB.  The different learning rates allow for a division of labor between the two branches, helping to maintain knowledge learned from previous tasks while adapting to new ones. The figure also depicts the reparameterization process, showing how the HLRB is merged into the LLRB after each new task. This effectively manages memory usage and helps to prevent catastrophic forgetting.", "section": "3.2 Reparameterizable Dual Branch"}, {"figure_path": "ZNqHm0a35E/figures/figures_6_1.jpg", "caption": "Figure 4: The performance of the pre-trained VLODM with different levels of Gaussian noise added to the input of VLODM's detector.", "description": "This figure shows how the performance of a pre-trained Vision-Language Object Detection Model (VLODM) changes when different levels of Gaussian noise are added to its input.  The x-axis represents the standard deviation of the added Gaussian noise, and the y-axis represents the average Average Precision (AP) on the COCO dataset. The graph demonstrates the robustness of the pre-trained VLODM to noise; even with significant amounts of noise, the performance does not decrease dramatically.", "section": "3.3 Zero-interference Loss"}, {"figure_path": "ZNqHm0a35E/figures/figures_6_2.jpg", "caption": "Figure 5: The average L\u2081 norm curve of the RDB's output overall sequentially learned downstream tasks, computing the output norm on both language and vision sides. The longitudinal axis is logarithmically scaled for better visualization.", "description": "This figure shows the change in the L1 norm of the RDB's output over multiple downstream tasks.  The L1 norm is a measure of the magnitude of the RDB's output. The plot displays the average L1 norm for both the language and vision sides of the model.  A lower L1 norm indicates that the model is less affected by the addition of new downstream tasks, which is a desired outcome for continual learning. The plot includes comparisons both with and without the Zero-interference Loss (ZiL) for both COCO and ODINW-13 datasets, showcasing the effect of ZiL on preventing catastrophic forgetting.", "section": "3.3 Zero-interference Loss"}, {"figure_path": "ZNqHm0a35E/figures/figures_15_1.jpg", "caption": "Figure 6: Visualization results of both seen categories and unseen categories with Grounding DINO-based ZiRa.", "description": "This figure visualizes the results of object detection on images containing both seen and unseen object categories.  Three methods are compared: Zero-shot detection using only a pre-trained model, incremental learning using iDETR, and incremental learning using the proposed ZiRa method. The images show that the Zero-shot approach misses some objects and the Incremental method using iDETR forgets some previously learned objects.  ZiRa, however, successfully identifies both seen and unseen objects, demonstrating its ability to incrementally learn new categories while preserving the ability to detect previously learned ones.", "section": "4 Experiments"}]