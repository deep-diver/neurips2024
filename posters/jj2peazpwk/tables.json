[{"figure_path": "Jj2PEAZPWk/tables/tables_7_1.jpg", "caption": "Table 1: Quantitative comparisons on S3DIS Area 5 under various weakly supervised settings. The bold denotes the best performance.", "description": "This table presents a quantitative comparison of various weakly supervised semantic segmentation methods on the S3DIS Area 5 dataset.  Different methods are evaluated at various label rates (100%, 0.1%, 0.03%, 0.02%, 0.01%), showing the mIoU (mean Intersection over Union) scores for each class (ceiling, floor, wall, beam, etc.). The table highlights the superior performance of DGNet, especially at lower label rates.", "section": "4. Experimental Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_7_2.jpg", "caption": "Table 2: Quantitative comparisons on ScanNet.", "description": "This table presents a quantitative comparison of different methods on the ScanNet dataset, showing the mean Intersection over Union (mIoU) achieved by each method under different supervision settings (100%, 1%, and 20 points).  The table highlights the performance of DGNet (using PointNeXt as the backbone) compared to state-of-the-art methods.  It shows the improvement in mIoU that DGNet achieves over baselines across different supervision levels.", "section": "4.2 Comparative Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_7_3.jpg", "caption": "Table 3: Quantitative comparisons on SemanticKITTI.", "description": "This table presents a comparison of the mean Intersection over Union (mIoU) scores achieved by different methods on the SemanticKITTI dataset.  The comparison is done under two weakly supervised settings: 0.1% and 0.01% label rates.  The table shows that DGNet (using RandLA-Net as the backbone network) outperforms other methods in both settings, demonstrating its effectiveness in weakly supervised semantic segmentation of outdoor point clouds.", "section": "4.2 Comparative Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_8_1.jpg", "caption": "Table 4: Comparisons on feature distribution description selection in distribution alignment branch.", "description": "This table presents the ablation study results on the selection of feature distribution description and distance metric in the distribution alignment branch of the proposed Distribution Guidance Network (DGNet). Four different combinations are compared: Category Prototype with Euclidean Norm, Category Prototype with Cosine Similarity, Gaussian Mixture Model (GMM) with Euclidean Norm, and Mixture of von Mises-Fisher distributions (moVMF) with Cosine Similarity. The results demonstrate that moVMF with Cosine Similarity achieves the best performance (mIoU of 62.4).", "section": "4.3 Ablations and Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_9_1.jpg", "caption": "Table 5: Ablation study for loss terms.", "description": "This table presents the results of an ablation study conducted to evaluate the impact of different loss terms on the performance of the proposed model. The study examines the contribution of partial cross-entropy loss (LPCE), truncated cross-entropy loss (LICE), hard von Mises-Fisher (vMF) loss, soft vMF loss, discriminative loss (LDIS), and consistency loss (LCON). The results are reported in terms of mean Intersection over Union (mIoU), a common metric for evaluating semantic segmentation models.", "section": "4.3 Ablations and Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_9_2.jpg", "caption": "Table 6: Ablation studies for Nested Expectation-Maximum Algorithm.", "description": "This table presents the ablation study for the Nested Expectation-Maximum Algorithm used in the paper. It shows the results of different configurations, including whether the E-step (expectation) was used for the soft-moVMF (mixture of von Mises-Fisher distributions) and/or whether the M-step (maximization) was used for the parameters \u03b1 (proportion of each von Mises-Fisher distribution) and \u03bc (mean vector of each distribution). The results demonstrate that the soft-moVMF algorithm with both E-step and M-step optimization provides the best performance, achieving a mIoU (mean Intersection over Union) of 62.4%.", "section": "4.3 Ablations and Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_9_3.jpg", "caption": "Table 5: Ablation study for loss terms.", "description": "This ablation study investigates the impact of each individual loss term (partial cross-entropy loss, vMF loss, discriminative loss, and consistency loss) and their combinations on the overall segmentation performance. It shows that the truncated cross-entropy loss and all three additional loss terms contribute to performance improvement in DGNet.", "section": "4.3 Ablations and Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_14_1.jpg", "caption": "Table 8: Performance comparison on various label rates.", "description": "This table presents a comparison of the mean Intersection over Union (mIoU) scores achieved by the PointNeXt baseline and the DGNet (PointNeXt) method across different label rates (10%, 1%, 0.1%, 0.01%, and 0.001%).  It demonstrates the performance of both methods under various levels of data sparsity, highlighting the impact of weakly supervised settings on the models' ability to accurately segment point cloud data.", "section": "4.2 Comparative Analysis"}, {"figure_path": "Jj2PEAZPWk/tables/tables_14_2.jpg", "caption": "Table 9: Sensitivity analysis of DGNet on S3DIS Area 5.", "description": "This table presents the results of a sensitivity analysis performed on the DGNet model using the S3DIS Area 5 dataset. The analysis focuses on evaluating the model's performance under varying numbers of labeled points, while maintaining the same label rate. The experiment was repeated five times for each setting (0.1% and 0.01% label rates), altering the locations of the labeled points. The table displays the model's performance (mIoU) for each trial, along with the mean and standard deviation across all trials, showcasing the model's robustness and consistency.", "section": "4.3 Ablations and Analysis"}]