[{"figure_path": "cRs4jvF4mO/figures/figures_6_1.jpg", "caption": "Figure 1: Simulation datasets, Classification error, Hellinger distance from true posteriors, mean max confidence or posterior for A. five two-dimensional and B. a high dimensional (Trunk) simulation experiments, visualized for the first two dimensions. The median performance is shown as a dark curve with shaded region as error bars.", "description": "This figure shows the results of simulation experiments on tabular data.  Panel A displays results from five two-dimensional simulations and one high-dimensional simulation ('Trunk'). For each simulation setup, it shows classification error, Hellinger distance (measuring the difference between the true and estimated posterior probabilities), and mean maximum confidence. The results show the performance of different methods (KDF, KDN, RF, and DN) across varying sample sizes and dimensions. Panel B focuses on the high-dimensional 'Trunk' simulation and visualizes how the performance of the different algorithms changes across a range of dimensions. The median performance is highlighted in each plot with shaded regions indicating error bars. ", "section": "5.1 Empirical Study on Tabular Data"}, {"figure_path": "cRs4jvF4mO/figures/figures_6_2.jpg", "caption": "Figure 2: Performance summary of KDF and KDN on OpenML-CC18 data suite. The dark curve in the middle shows the median of performance on 45 datasets with the shaded region as error bar. testing samples uniformly from hyperspheres where each hypersphere has increasing radius starting from 1 to 5. For each dataset, we measure improvement with respect to the parent algorithm: Ep\u2212Em/Ep", "description": "This figure summarizes the performance of Kernel Density Forest (KDF) and Kernel Density Network (KDN) on the OpenML-CC18 dataset. It shows the improvement of KDF and KDN over their respective parent algorithms (Random Forest and Deep Neural Network) in terms of classification, in-distribution (ID) calibration, and out-of-distribution (OOD) calibration. The improvement is measured as the difference between the performance metrics (classification error, maximum calibration error, mean max confidence) of the parent algorithm and the proposed algorithm, normalized by the performance of the parent algorithm. The x-axis represents either the number of training samples (in log scale) or the distance from the training data, depending on the subplot. The shaded regions indicate the range of improvement across different datasets. The figure demonstrates that KDF and KDN consistently improve OOD calibration and maintain comparable or better performance in ID calibration while mostly maintaining classification accuracy.", "section": "5.1 Empirical Study on Tabular Data"}, {"figure_path": "cRs4jvF4mO/figures/figures_7_1.jpg", "caption": "Figure 3: KDN filters out inference points with different kinds of semantic shifts from the training data. Simulated images: (A) circle with radius 10, (B) rectangle with sides (20, 50) and out-of-distribution test points: (C) ellipse with minor and major axis (10, 30). Mean max confidence of KDN are plotted for semantic shift of the inference points created by (D) changing the color intensity, (E) taking convex combination of circle and rectangle, (F) changing one of the axes of the ellipse.", "description": "This figure demonstrates the effectiveness of the proposed KDN method in handling out-of-distribution (OOD) data by showcasing its ability to assign lower confidence scores to samples with semantic shifts from the training distribution.  Three types of images (circle, rectangle, ellipse) are used as examples. The plots show how the mean maximum confidence changes as color intensity, convex combination of shapes, and axis length are varied, illustrating KDN's ability to maintain well-calibrated posteriors even when the input deviates significantly from the training data.", "section": "5.2 Empirical Study on Vision Data"}, {"figure_path": "cRs4jvF4mO/figures/figures_13_1.jpg", "caption": "Figure 1: Simulation datasets, Classification error, Hellinger distance from true posteriors, mean max confidence or posterior for A. five two-dimensional and B. a high dimensional (Trunk) simulation experiments, visualized for the first two dimensions. The median performance is shown as a dark curve with shaded region as error bars.", "description": "This figure visualizes the performance of different algorithms on six binary classification simulation datasets.  The top row shows the datasets themselves: Gaussian XOR, Spiral, Circle, Sinewave, Polynomial, and Trunk. The remaining rows show the performance metrics (classification error, Hellinger distance, mean max confidence) for Random Forests (RF), Kernel Density Forests (KDF) with Euclidean and Geodesic distance, Deep Neural Networks (DN), and Kernel Density Networks (KDN) with Euclidean and Geodesic distance, for both two-dimensional and higher-dimensional datasets.  The median performance is highlighted with error bars showing the variability.", "section": "5.1 Empirical Study on Tabular Data"}, {"figure_path": "cRs4jvF4mO/figures/figures_16_1.jpg", "caption": "Figure 1: Simulation datasets, Classification error, Hellinger distance from true posteriors, mean max confidence or posterior for A. five two-dimensional and B. a high dimensional (Trunk) simulation experiments, visualized for the first two dimensions. The median performance is shown as a dark curve with shaded region as error bars.", "description": "This figure shows the results of simulation experiments on tabular data.  The left panel (A) displays results from five 2D binary classification datasets with different underlying data distributions (Gaussian XOR, Spiral, Circle, Sinewave, Polynomial).  The right panel (B) shows results from the higher-dimensional Trunk simulation dataset. For each dataset, the figure presents plots of classification error, Hellinger distance from true posteriors, and mean max confidence. The results are shown for the proposed KDF and KDN methods, as well as their corresponding parent algorithms (RF and DN). The median performance across multiple simulations is displayed as a dark curve, with error bars illustrating the variability across simulations.", "section": "5.1 Empirical Study on Tabular Data"}, {"figure_path": "cRs4jvF4mO/figures/figures_17_1.jpg", "caption": "Figure 1: Simulation datasets, Classification error, Hellinger distance from true posteriors, mean max confidence or posterior for A. five two-dimensional and B. a high dimensional (Trunk) simulation experiments, visualized for the first two dimensions. The median performance is shown as a dark curve with shaded region as error bars.", "description": "This figure presents the results of simulations conducted to evaluate the performance of different algorithms on two types of datasets:  five two-dimensional and one high-dimensional (Trunk) dataset. The figure displays several metrics to assess the performance, including classification error, Hellinger distance from the true posterior distributions, and mean maximum confidence. The plots show median performance with error bars indicating variability. The visualization of the high dimensional dataset is limited to the first two dimensions for visual clarity.", "section": "5.1 Empirical Study on Tabular Data"}, {"figure_path": "cRs4jvF4mO/figures/figures_18_1.jpg", "caption": "Figure 1: Simulation datasets, Classification error, Hellinger distance from true posteriors, mean max confidence or posterior for A. five two-dimensional and B. a high dimensional (Trunk) simulation experiments, visualized for the first two dimensions. The median performance is shown as a dark curve with shaded region as error bars.", "description": "This figure visualizes the performance of different algorithms on six binary classification simulation datasets.  The datasets are visualized in two dimensions, with true and estimated class conditional posteriors shown for each. The algorithms being compared are KDF and KDN against their parent algorithms (RF and DN).  The performance metrics shown are classification error, Hellinger distance from the true posterior, and mean maximum confidence.  The figure highlights the better performance of KDF and KDN in estimating the in-distribution (ID) region and handling out-of-distribution (OOD) data compared to their parent algorithms. The results showcase how KDF and KDN obtain well-calibrated posteriors while largely preserving or improving classification accuracy in the ID region, and extrapolating appropriately to OOD inputs.", "section": "5.1 Empirical Study on Tabular Data"}, {"figure_path": "cRs4jvF4mO/figures/figures_19_1.jpg", "caption": "Figure 1: Simulation datasets, Classification error, Hellinger distance from true posteriors, mean max confidence or posterior for A. five two-dimensional and B. a high dimensional (Trunk) simulation experiments, visualized for the first two dimensions. The median performance is shown as a dark curve with shaded region as error bars.", "description": "This figure visualizes the performance of different algorithms on six different binary-class simulation datasets. The first two columns show the classification error, Hellinger distance (a measure of the difference between probability distributions), and mean maximum confidence for five two-dimensional datasets and a high-dimensional dataset. The remaining six columns provide visualizations of the true and estimated class-conditional posteriors for each algorithm on the datasets. The visualizations for the two-dimensional case are provided for the first two dimensions.  The median performance across multiple simulations is highlighted with a dark line, while error bars represent the range of performance.", "section": "5.1 Empirical Study on Tabular Data"}]