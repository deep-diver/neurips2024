[{"figure_path": "oe5ZEqTOaz/tables/tables_6_1.jpg", "caption": "Table 1: The difference between the four datasets we use.", "description": "This table summarizes the key differences among the four multimodal datasets used in the paper's experiments.  It shows the dataset name, the type of task (classification, regression, or segmentation), and the number of modalities involved for each dataset. This information is crucial for understanding the diversity and scope of the experimental evaluation.", "section": "4.1 Datasets and Evaluation Metrics"}, {"figure_path": "oe5ZEqTOaz/tables/tables_6_2.jpg", "caption": "Table 2: Quantitative results on the UPMC-Food 101 dataset. Bold: best results. Underline: second best results.", "description": "This table presents a quantitative comparison of different methods on the UPMC-Food 101 dataset, showing their accuracy and F1 score.  The best and second-best results are highlighted for easy comparison. The methods include using a single modality (text or image), a baseline multimodal approach, and several state-of-the-art multimodal learning methods.  The table helps illustrate the effectiveness of the proposed CGGM method.", "section": "4.1 Datasets and Evaluation Metrics"}, {"figure_path": "oe5ZEqTOaz/tables/tables_6_3.jpg", "caption": "Table 3: Results on BraTS 2021. WT, TC and ET denote the dice score of Whole Tumor, Tumor Core and Enhancing Tumor respectively.", "description": "This table presents the quantitative results of the BraTS 2021 dataset.  It compares various methods, including baselines and state-of-the-art approaches, in terms of their performance on three subregions of brain tumors: Whole Tumor (WT), Tumor Core (TC), and Enhancing Tumor (ET). The average Dice score across these three regions is also provided for each method.  The Dice score is a common metric for evaluating the accuracy of segmentation models.", "section": "4 Experiments"}, {"figure_path": "oe5ZEqTOaz/tables/tables_7_1.jpg", "caption": "Table 4: Quantitative results on the CMU-MOSI and IEMOCAP datasets. Bold: best results. Underline: second best results.", "description": "This table presents a comparison of the performance of several methods (including the proposed CGGM) on two benchmark multimodal datasets: CMU-MOSI and IEMOCAP.  For CMU-MOSI, which is a regression task, the metrics shown are accuracy (Acc-2 and Acc-7), F1 score, mean absolute error (MAE), and Pearson correlation (Corr). For IEMOCAP, a classification task, the metrics are accuracy (Acc) and F1 score.  The best result for each metric is bolded, and the second-best is underlined.  The results highlight the relative strengths of each method across different multimodal tasks.", "section": "4.3 Main Results"}, {"figure_path": "oe5ZEqTOaz/tables/tables_8_1.jpg", "caption": "Table 5: Accuracy on IEMOCAP. f1, f2 and f3 represent the audio, video and text classifier, respectively. We train three separate models in unimodal training.", "description": "This table presents the accuracy results of the IEMOCAP dataset for different training methods.  The first three columns show accuracy using individual modalities (unimodal training), the next three columns show accuracy when training with all modalities simultaneously (multimodal training), and the final three columns show accuracy when training with all modalities and using the proposed CGGM method.  f1, f2, and f3 represent the accuracy of the audio, video, and text classifiers, respectively.  It demonstrates the performance improvement achieved using CGGM over unimodal and multimodal training.", "section": "4.4 Classifier Performance and Gradient Direction"}, {"figure_path": "oe5ZEqTOaz/tables/tables_9_1.jpg", "caption": "Table 6: The benefits of modulating the magnitude of the gradients and the directions of the gradients.", "description": "This table presents the ablation study results on the IEMOCAP dataset to demonstrate the effectiveness of modulating gradient magnitude and direction in the proposed CGGM method. It compares the baseline model with three variants of CGGM: one modulating only the magnitude (p=1.0, \u03bb=0), one modulating only the direction (p=None, \u03bb=0.1), and one modulating both (p=1.0, \u03bb=0.1). The results show that modulating both gradient magnitude and direction yields the best performance, indicating the complementarity of these two strategies in balancing multimodal learning.", "section": "4.5 Ablation Study"}, {"figure_path": "oe5ZEqTOaz/tables/tables_12_1.jpg", "caption": "Table 7: Main hyperparameters of the four datasets.", "description": "This table lists the main hyperparameters used in the experiments performed on four different multimodal datasets: UPMC-Food 101, CMU-MOSI, IEMOCAP, and BraTS 2021.  These hyperparameters include the batch size, optimizer, base learning rate, classifier learning rate, weight decay, gradient clipping value, learning rate scheduler, \u03c1 (a scaling hyperparameter for gradient magnitude modulation), \u03bb (a trade-off parameter between task loss and balancing term), warm-up epochs, and total training epochs.  The specific values used for each parameter varied across the different datasets to optimize performance for each specific task.", "section": "4 Experiments"}, {"figure_path": "oe5ZEqTOaz/tables/tables_14_1.jpg", "caption": "Table 8: Additional gpu memory cost (MB) of classifiers.", "description": "This table shows the additional GPU memory cost in MB for using classifiers in the proposed CGGM method across four different datasets: UPMC-Food101, CMU-MOSI, IEMOCAP, and BraTS.  The memory overhead is relatively small, ranging from 8MB to 24MB, depending on the dataset.", "section": "4.4 Classifier Performance and Gradient Direction"}]