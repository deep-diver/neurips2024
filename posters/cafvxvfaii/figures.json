[{"figure_path": "cAFvxVFaii/figures/figures_2_1.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(nt, nt) and cross-covariance matrix Cov(nt\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure shows the contemporaneous and cross-covariance matrices of prediction residuals from a multivariate time series model.  The contemporaneous covariance matrix, Cov(nt, nt), displays the correlation between different time series at the same time step. The cross-covariance matrices, Cov(nt\u2212\u2206, \u03b7t) for \u2206=1,2,3, show the correlation between time series at different time steps (lags).  The data is from the m4_hourly dataset, and covariances are clipped for better visualization.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_4_1.jpg", "caption": "Figure 2: Graphic illustration of Eq. (8), where B is the number of time series in a batch, R is the rank of the covariance factor, D is the time window we consider cross-correlation, P and Q are the conditioning range and prediction range. Cross-correlation is modeled by introducing correlation in each row of matrix rt\u2212D+1:t.", "description": "This figure illustrates how the proposed method models cross-correlation in multivariate time series.  The input data is organized into a batch of time series with a specific temporal structure that spans a window of size D, encompassing both conditioning (P) and prediction (Q) ranges.  The figure shows how the input data (z_bat) is decomposed into the mean (\u03bc_bat), the low-rank covariance factor (L_bat), and a latent variable (r_bat) which models cross-covariance between different time steps and the diagonal matrix \u03b5_bat.  The key innovation shown is the use of matrix r_bat to introduce correlations across different time steps within the batch, allowing the model to learn cross-correlations.", "section": "4 Our Method"}, {"figure_path": "cAFvxVFaii/figures/figures_5_1.jpg", "caption": "Figure 2: Graphic illustration of Eq. (8), where B is the number of time series in a batch, R is the rank of the covariance factor, D is the time window we consider cross-correlation, P and Q are the conditioning range and prediction range. Cross-correlation is modeled by introducing correlation in each row of matrix rt\u2212D+1:t.", "description": "This figure illustrates how the proposed method models cross-correlation in multivariate time series.  It shows a batch of time series data organized into smaller slices to capture the temporal dependencies of errors (cross-correlation).  The figure highlights the components of Equation (8), showing how the cross-correlation is introduced into the latent variable vector *r* through a dynamic correlation matrix *C*.  Specifically, the figure demonstrates how the cross-correlation is modeled by introducing correlation within each row of the matrix *r<sub>t-D+1:t</sub>*. This matrix comprises smaller slices of time series, with a temporal length of P+1, sorted by prediction start time. ", "section": "4 Our Method"}, {"figure_path": "cAFvxVFaii/figures/figures_8_1.jpg", "caption": "Figure 4: (a) Component weights for generating Ct for a batch of time series (B = 8) from the m4_hourly dataset obtained by the GPVar model. Parameters wo, W1, W2 represent the component weights of the kernel matrices associated with lengthscales l = 0.5, 1.5, 2.5, and w3 is the component weight of the identity matrix. Shaded areas distinguish different days; (b) The autocorrelation function (ACF) indicated by the correlation matrix Ct at 17:00. Given the rapid decay of the ACF, we only plot 12 lags to enhance visualization; (c) The corresponding covariance matrix of the associated target variables \u03a3bat at 17:00. A zoom-in view of a 3B \u00d7 3B region is illustrated in the plot, where the diagonal blocks represent B \u00d7 B covariance matrices \u03a3t of zt, over three consecutive time steps. The off-diagonal blocks describe the cross-covariance Cov(zt\u2212\u2206, zt), \u2200\u2206 \u2260 0. For visualization clarity, covariance values are clipped to the range [0, 0.03].", "description": "This figure shows the component weights used to generate the dynamic correlation matrix (Ct) at different time points, the autocorrelation function (ACF) of Ct at a specific time (17:00), and the corresponding covariance matrix of the time series variables at that time. The figure highlights the dynamic nature of the correlation structure and its relationship to the model parameters.", "section": "Model Interpretation"}, {"figure_path": "cAFvxVFaii/figures/figures_22_1.jpg", "caption": "Figure 5: Training loss/validation loss vs training time of the GPVar model. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method.", "description": "This figure visualizes the training and validation loss curves for the GPVar model, comparing the performance with and without the proposed method that incorporates time-dependent errors. The x-axis represents the training steps (time), and the y-axis shows the loss. Separate curves are plotted for training and validation loss, with and without the proposed method.  This allows for a direct comparison of the impact of modeling temporal error correlations on the convergence and generalization performance of the model.", "section": "5 Experiments"}, {"figure_path": "cAFvxVFaii/figures/figures_22_2.jpg", "caption": "Figure 5: Training loss/validation loss vs training time of the GPVar model. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method.", "description": "This figure compares the training and validation loss curves for the GPVar model with and without the proposed method for incorporating time-dependent errors.  The x-axis represents the training steps, and the y-axis shows the loss values.  Separate curves are plotted for training loss and validation loss for each model (with and without time-dependent errors). The figure helps to visualize the convergence speed and generalization performance of the models with and without the method.", "section": "5 Experiments"}, {"figure_path": "cAFvxVFaii/figures/figures_23_1.jpg", "caption": "Figure 7: The influence of the number of time series in a batch on the performance of inference. \"w/o\" denotes methods without time-dependent errors, while \"w/\" indicates our method. We only show some datasets here because the remaining datasets have fewer than B = 20 time series in the testing set.", "description": "This figure shows how the number of time series used during prediction affects the performance of the proposed method and a baseline method (without time-dependent errors).  The results are presented for several different datasets.  The x-axis shows the number of time series in a batch during prediction, and the y-axis shows the CRPSsum, a metric to evaluate the accuracy of probabilistic forecasts. The lines represent the performance of the methods with and without the proposed method for modeling temporally correlated errors. It highlights that the benefit of including temporal error correlation diminishes when the number of time series is smaller than the batch size during training.", "section": "5.1 Evaluation of Predictive Performance"}, {"figure_path": "cAFvxVFaii/figures/figures_24_1.jpg", "caption": "Figure 8: ACF comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the solar dataset.", "description": "This figure compares the autocorrelation function (ACF) of one-step-ahead prediction residuals obtained using GPVar with and without the proposed method for four time series from the solar dataset. The ACF measures the correlation between a time series and its lagged values.  For each time series, two lines are shown: one for the model without the method (w/o), and one for the model with the proposed method (w/).  The plots show that the proposed method reduces the autocorrelation in the residuals, indicating that it better captures and accounts for the temporal dependence in the data.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_24_2.jpg", "caption": "Figure 8: ACF comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the solar dataset.", "description": "This figure compares the autocorrelation function (ACF) of the residuals from a one-step-ahead prediction model (GPVar) with and without the proposed method for four time series in the solar dataset.  The ACF plots show the correlation of the residuals at different lags.  Comparing the \"w/o\" (without the method) and \"w/\" (with the method) plots helps visualize how the proposed method affects the temporal correlation structure of the residuals, aiming for less autocorrelation.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_24_3.jpg", "caption": "Figure 8: ACF comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the solar dataset.", "description": "This figure compares the autocorrelation function (ACF) plots of the one-step-ahead prediction residuals generated by GPVar model with and without the proposed method that incorporates temporally correlated errors. Four time series from the solar dataset are shown to illustrate the effectiveness of the method. The blue dots represent the ACF of residuals from the base model (without correlated errors), while the orange dots represent the ACF of residuals from the improved model. This visual comparison helps to demonstrate the reduction in autocorrelation achieved by the method.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_25_1.jpg", "caption": "Figure 8: ACF comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the solar dataset.", "description": "This figure compares the autocorrelation function (ACF) plots of the one-step-ahead prediction residuals generated by the GPVar model, both with and without the proposed method for handling correlated errors. Four individual time series (A-D) are shown, each with two ACF plots (one for the model without and one for the model with the proposed method). The plots show how the proposed method effectively reduces the autocorrelation in prediction residuals across multiple time lags.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_25_2.jpg", "caption": "Figure 8: ACF comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the solar dataset.", "description": "This figure compares the autocorrelation function (ACF) plots of the one-step-ahead prediction residuals obtained from the GPVar model with and without the proposed method. The analysis is performed on four different time series from the solar dataset.  The plots show the autocorrelation of the residuals across multiple time lags. The comparison is designed to visually illustrate the impact of the proposed method in reducing the autocorrelation of the prediction residuals.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_25_3.jpg", "caption": "Figure 8: ACF comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the solar dataset.", "description": "This figure compares the autocorrelation function (ACF) plots of the one-step-ahead prediction residuals generated by the GPVar model, with and without the proposed method for handling correlated errors.  The results are shown for four different time series from the solar dataset. The ACF plots show the correlation of the residuals at different lags. A lag of 0 represents the correlation of the residuals with themselves, a lag of 1 represents the correlation between consecutive residuals, and so on.  The comparison helps to visually assess the effectiveness of the method in reducing autocorrelation in the prediction residuals.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_26_1.jpg", "caption": "Figure 8: ACF comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the solar dataset.", "description": "This figure compares the autocorrelation function (ACF) plots of prediction residuals for four different time series.  The blue points represent the ACF of the residuals from the model without the proposed method for handling correlated errors, while the orange points show the ACF of the residuals from the model *with* the proposed method. The x-axis represents the lags (time steps), and the y-axis represents the ACF value.  The plot illustrates how the proposed method reduces the autocorrelation in the prediction residuals across all four time series. ", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_26_2.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(\u03b7t, \u03b7t) and cross-covariance matrix Cov(\u03b7t\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure shows the contemporaneous and cross-covariance matrices of prediction residuals. The contemporaneous covariance shows the correlation between different time series at the same time step. The cross-covariance shows the correlation between different time series at different time steps (lag 1, 2, and 3). The data used is from the m4_hourly dataset, and the covariance values are clipped to the range [0, 0.6] for better visualization.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_26_3.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(\u03b7t, \u03b7t) and cross-covariance matrix Cov(\u03b7t\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure shows the empirical contemporaneous and cross-covariance matrices of prediction residuals from a probabilistic forecasting model (GPVar) applied to the m4_hourly dataset.  The contemporaneous covariance matrix, Cov(\u03b7t, \u03b7t), displays the correlation between different time series at the same time step. The cross-covariance matrices, Cov(\u03b7t\u2212\u2206, \u03b7t) for \u2206 = 1, 2, 3, illustrate the correlation between residuals at different time lags (\u2206). The visualizations are clipped to highlight correlations between 0 and 0.6 for better clarity.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_27_1.jpg", "caption": "Figure 15: Cross-correlation comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the electricity dataset.", "description": "This figure compares the cross-correlation matrices of one-step ahead prediction residuals obtained from the GPVar model, with and without the proposed method for handling correlated errors.  The matrices visualize the correlation between prediction residuals across different time lags and across different time series. Each subplot represents a specific time lag (1, 2, 3, and 4 steps). The color intensity represents the magnitude of cross-correlation; warmer colors indicate positive correlations, cooler colors indicate negative correlations, and lighter colors indicate near-zero correlation.  The comparison aims to demonstrate the effectiveness of the proposed method in reducing cross-correlation.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_27_2.jpg", "caption": "Figure 15: Cross-correlation comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the electricity dataset.", "description": "This figure compares the cross-correlation of residuals from a model trained with and without the proposed method for capturing cross-correlation in errors.  It shows the cross-covariance matrices Cov(\u03b7t\u2212\u2206, \u03b7t) for \u2206 = 1, 2, 3, 4, where \u03b7t represents the prediction residuals at time t.  The top row shows the results when the model does *not* account for cross-correlation (w/o), while the bottom row shows the results when the model *does* account for cross-correlation (w/). The color scale represents the correlation strength; warmer colors indicate stronger positive correlation, and cooler colors indicate stronger negative correlation.  The visual comparison aims to illustrate how the proposed method reduces cross-correlation among the residuals.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_27_3.jpg", "caption": "Figure 15: Cross-correlation comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the electricity dataset.", "description": "This figure compares the cross-correlation of one-step-ahead prediction residuals using GPVAR with and without the proposed method to model correlated errors.  Four different time series are shown (A, B, C, D). Each subplot shows the cross-covariance between residuals at time t and residuals at times t-1, t-2, t-3, and t-4. The color scale represents the correlation strength. The results indicate a reduction in cross-correlation after applying the proposed method.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_28_1.jpg", "caption": "Figure 15: Cross-correlation comparison of the one-step-ahead prediction residuals with and without our method. The results depict the prediction outcomes generated by GPVar for four time series in the electricity dataset.", "description": "This figure compares the cross-correlation of residuals from the GPVar model with and without the proposed method for four time series in the electricity dataset.  Specifically, it visualizes the cross-covariance matrices Cov(\u03b7t\u2212\u0394, \u03b7t), where \u0394 represents the lag (1, 2, 3, 4 steps) and \u03b7t represents the residuals at time step t.  The comparison shows that the proposed method effectively reduces cross-correlations in the residuals.", "section": "B.5.1 Comparison of Residual Correlation"}, {"figure_path": "cAFvxVFaii/figures/figures_28_2.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(\u03b7t, \u03b7t) and cross-covariance matrix Cov(\u03b7t\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure shows the empirical contemporaneous covariance matrix and cross-covariance matrices of prediction residuals from a multivariate time series model (GPVar) applied to the m4_hourly dataset.  The contemporaneous covariance (Cov(\u03b7t, \u03b7t)) shows the correlation between different time series at the same time step. The cross-covariance matrices (Cov(\u03b7t\u2212\u2206, \u03b7t) for \u2206 = 1,2,3) show the correlation between errors at different time lags. The covariance values are clipped to a range [0,0.6] for better visualization.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_29_1.jpg", "caption": "Figure 21: Step-wise CRPSsum accuracy of GPVar. \u201cw/o\u201d denotes methods without time-dependent errors, while \u201cw/\u201d indicates our method.", "description": "This figure compares the step-wise CRPSsum accuracy of the GPVar model with and without the proposed method for modeling correlated errors.  The x-axis represents the forecast steps, and the y-axis shows the CRPSsum.  Separate lines are shown for each dataset, comparing the model trained without considering temporal error correlations ('w/o') against the model trained with the proposed method ('w/').  The results demonstrate that modeling time-dependent errors generally leads to improved accuracy, especially in the earlier forecast steps. Note that the improvement varies across datasets and may decrease or increase at later steps, likely influenced by the dataset's characteristics such as seasonality and data variability.", "section": "5.2 Model Interpretation"}, {"figure_path": "cAFvxVFaii/figures/figures_31_1.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(\u03b7t, \u03b7t) and cross-covariance matrix Cov(\u03b7t\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure shows the contemporaneous and cross-covariance matrices of prediction residuals from a multivariate autoregressive model.  The contemporaneous covariance shows the correlation between errors at the same time step across different time series. The cross-covariance matrices (for lags 1, 2, and 3) depict the correlation between errors at different time steps. This visualization highlights the presence of both contemporaneous and temporal dependencies in the model's residuals, which are usually ignored by simpler models for scalability reasons. The data used is from the m4_hourly dataset.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_32_1.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(nt, nt) and cross-covariance matrix Cov(nt\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure shows the contemporaneous covariance matrix and cross-covariance matrices of prediction residuals from the GPVar model applied to the m4_hourly dataset.  It visually demonstrates the temporal dependence in the residuals, which violates the common assumption of temporal independence in many time series models. The covariance matrices show correlations between residuals at different time steps (cross-covariance), indicating the presence of autocorrelation and cross-lag correlation in the errors.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_32_2.jpg", "caption": "Figure 4: (a) Component weights for generating Ct for a batch of time series (B = 8) from the m4_hourly dataset obtained by the GPVar model. Parameters wo, W1, W2 represent the component weights of the kernel matrices associated with lengthscales l = 0.5, 1.5, 2.5, and w3 is the component weight of the identity matrix. Shaded areas distinguish different days; (b) The autocorrelation function (ACF) indicated by the correlation matrix Ct at 17:00. Given the rapid decay of the ACF, we only plot 12 lags to enhance visualization; (c) The corresponding covariance matrix of the associated target variables Et at 17:00. A zoom-in view of a 3B \u00d7 3B region is illustrated in the plot, where the diagonal blocks represent B \u00d7 B covariance matrices Et of z\u0142, over three consecutive time steps. The off-diagonal blocks describe the cross-covariance Cov(Zt\u2212\u2206, Zt), \u2200\u2206 \u2260 0. For visualization clarity, covariance values are clipped to the range [0, 0.03].", "description": "This figure shows an empirical example of the proposed method for learning cross-correlation in multivariate probabilistic forecasting models. It visualizes the component weights for generating the dynamic correlation matrix Ct (part a), the autocorrelation function (ACF) of Ct at a specific time (part b), and the corresponding covariance matrix of the time series variables at that time (part c). The figure demonstrates how the model captures dynamic correlation patterns and generates a time-varying covariance matrix for improving predictive accuracy.", "section": "5.2 Model Interpretation"}, {"figure_path": "cAFvxVFaii/figures/figures_33_1.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(nt, nt) and cross-covariance matrix Cov(nt\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [\u22120.6, 0.6].", "description": "This figure shows the contemporaneous and cross-covariance matrices of prediction residuals obtained from a GPVar model trained on the m4_hourly dataset.  The contemporaneous covariance matrix, Cov(nt, nt), displays the correlation between residuals at the same time step.  The cross-covariance matrices, Cov(nt\u2212\u2206, \u03b7t) for \u2206 = 1, 2, and 3, illustrate the correlation between residuals at different time steps (lags). The visualization uses a color scale to represent the covariance values, ranging from negative to positive correlation. The values are clipped for clarity.", "section": "2 Probabilistic Time Series Forecasting"}, {"figure_path": "cAFvxVFaii/figures/figures_33_2.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(\u03b7t, \u03b7t) and cross-covariance matrix Cov(\u03b7t\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [\u22120.6, 0.6].", "description": "This figure shows the contemporaneous and cross-covariance matrices of prediction residuals from a multivariate time series model (GP-Var) applied to the m4_hourly dataset.  The contemporaneous covariance (Cov(\u03b7t, \u03b7t)) represents the correlation between errors at the same time step, while the cross-covariance matrices (Cov(\u03b7t\u2212\u2206, \u03b7t) for \u2206 = 1, 2, 3) show correlations between errors at different time lags. The visualization helps to illustrate the presence of temporal dependencies in the residuals, which are not accounted for in many time series models.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_34_1.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(nt, nt) and cross-covariance matrix Cov(nt\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure shows the contemporaneous and cross-covariance matrices of prediction residuals.  The contemporaneous covariance matrix Cov(nt, nt) displays the correlation between errors at the same time step. The cross-covariance matrices Cov(nt\u2212\u2206, \u03b7t) show the correlation between errors at different time steps (lags \u2206 = 1, 2, 3). The data used is from the m4_hourly dataset, and the covariances are capped at 0.6 for better visualization.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_34_2.jpg", "caption": "Figure 1: Contemporaneous covariance matrix Cov(nt, nt) and cross-covariance matrix Cov(nt\u2212\u2206, \u03b7t), \u2206 = 1,2,3, calculated based on the one-step-ahead prediction residuals of GP-Var on a batch of time series from the m4_hourly dataset. For visualization clarity, covariance are clipped to the range [0, 0.6].", "description": "This figure displays the contemporaneous and cross-covariance matrices calculated from the prediction residuals of a GPVAR model trained on the m4_hourly dataset.  The contemporaneous covariance matrix shows the covariance between the errors at the same time step. The cross-covariance matrices show the covariance between the errors at different time steps (lags 1, 2, and 3).  The covariance values are clipped to the range [0, 0.6] for better visualization.", "section": "3 Related Work"}, {"figure_path": "cAFvxVFaii/figures/figures_35_1.jpg", "caption": "Figure 3: Illustration of the training process. Following [3], time series dimensions are randomly sampled, and the base model (e.g., RNNs) is unrolled for each dimension individually (e.g., 1, 2, 4, followed by 1, 3, 4 as depicted). The model parameters are shared across all time series dimensions. A batch of time series variables zhat contains time series vectors z\u0142 covering time steps from t \u2212 D+1 to t. In contrast to [3], our approach explicitly models dependencies over the extended temporal window from t \u2212 D + 1 to t during training.", "description": "This figure illustrates how the proposed method incorporates temporal dependencies in the latent variable within a batch to address cross-correlated errors in multivariate probabilistic forecasting. Unlike the traditional approach, which models the likelihood independently at each time step, the proposed method models dependencies over an extended temporal window, enhancing the capture of cross-correlation. This figure uses RNN as an example, but the concept applies to other autoregressive models as well. The model parameters are shared across all dimensions, making the method computationally efficient.", "section": "4 Our Method"}]