[{"figure_path": "JVtwC9RzlI/tables/tables_5_1.jpg", "caption": "Table 3: Performance of Text-to-Graph on WebNLG (2020). The Grapher-small* is obtained by running the officially released source code of Grapher with T5-small weights. The # Params of CycleGT is not disclosed [5].", "description": "This table presents the performance of different models on the text-to-graph generation task using the WebNLG 2020 dataset.  It compares the proposed TextGraphBART model against several baseline models, including CycleGT, BT5, and Grapher (with different configurations), reporting the F1 score (strict, exact, and partial match).  The table highlights the model parameters of each model to allow for a comparison based on model size.", "section": "4 Experiments and Results"}, {"figure_path": "JVtwC9RzlI/tables/tables_6_1.jpg", "caption": "Table 4: Performance of our model on each category of WebNLG (2020) test set comparing to Grapher-small. The * denotes the unseen categories.", "description": "This table compares the performance of the proposed TextGraphBART model against the Grapher-small model on the WebNLG 2020 dataset.  It breaks down the results by category, showing the F1 score (Strict, Exact, and Partial match) for each. The asterisk (*) indicates categories that were not seen during training, providing a useful measure of generalization ability.", "section": "4 Experiments and Results"}, {"figure_path": "JVtwC9RzlI/tables/tables_7_1.jpg", "caption": "Table 5: Ablation results of our structure embedding on WebNLG (2020) test set.", "description": "This table presents the ablation study results on the WebNLG 2020 test set.  It shows the impact of removing different components of the structure embedding (segment ID, type, head ID & tail ID, token ID & previous ID) on the model's performance, measured by the F1 score (Strict, Exact, and Partial).  The results demonstrate the contribution of each component to the overall performance.", "section": "4 Experiments and Results"}]