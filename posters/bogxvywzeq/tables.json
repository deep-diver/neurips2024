[{"figure_path": "boGxvYWZEq/tables/tables_8_1.jpg", "caption": "Table 1: Comparison of different CL methods on X-TAIL for each domain in terms of \"Transfer\", \"Average\", and \"Last\" scores (%). The best results are highlighted with bold style.", "description": "This table compares the performance of various Continual Learning (CL) methods on the Cross-domain Task-Agnostic Incremental Learning (X-TAIL) benchmark.  It shows the \"Transfer\", \"Average\", and \"Last\" accuracy scores for each of ten domains.  \"Transfer\" represents the zero-shot performance before any incremental learning; \"Average\" is the average performance across all domains and learning steps; and \"Last\" represents the final performance after all incremental learning has been completed.", "section": "5.1 Comparison results"}, {"figure_path": "boGxvYWZEq/tables/tables_9_1.jpg", "caption": "Table 1: Comparison of different CL methods on X-TAIL for each domain in terms of \"Transfer\", \"Average\", and \"Last\" scores (%). The best results are highlighted with bold style.", "description": "This table presents a comparison of various continual learning (CL) methods on the Cross-domain Task-Agnostic Incremental Learning (X-TAIL) benchmark.  It shows the performance of each method across ten different image domains, evaluating three key metrics: Transfer (zero-shot performance on unseen domains), Average (overall average performance), and Last (performance on seen domains after all learning).  The best results for each metric are highlighted in bold, allowing for easy comparison of the different methods.", "section": "5.1 Comparison results"}, {"figure_path": "boGxvYWZEq/tables/tables_18_1.jpg", "caption": "Table 1: Comparison of different CL methods on X-TAIL for each domain in terms of \"Transfer\", \"Average\", and \"Last\" scores (%). The best results are highlighted with bold style.", "description": "This table presents a comparison of different continual learning (CL) methods on the Cross-domain Task-Agnostic Incremental Learning (X-TAIL) benchmark.  It shows the performance of each method across ten different domains, evaluating three metrics: Transfer (zero-shot performance on unseen domains), Average (average accuracy across all domains and learning steps), and Last (final accuracy on seen domains after all learning steps). The bold values represent the best performance for each metric and domain.", "section": "5.1 Comparison results"}]