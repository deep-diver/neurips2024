[{"type": "text", "text": "A Compositional Atlas for Algebraic Circuits ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Benjie Wang University of California, Los Angeles benjiewang@ucla.edu ", "page_idx": 0}, {"type": "text", "text": "Denis Deratani Mau\u00e1 University of S\u00e3o Paulo ddm@ime.usp.br ", "page_idx": 0}, {"type": "text", "text": "Guy Van den Broeck University of California, Los Angeles guyvdb@cs.ucla.edu ", "page_idx": 0}, {"type": "text", "text": "YooJung Choi Arizona State University yj.choi@asu.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Circuits based on sum-product structure have become a ubiquitous representation to compactly encode knowledge, from Boolean functions to probability distributions. By imposing constraints on the structure of such circuits, certain inference queries become tractable, such as model counting and most probable configuration. Recent works have explored analyzing probabilistic and causal inference queries as compositions of basic operators to derive tractability conditions. In this paper, we take an algebraic perspective for compositional inference, and show that a large class of queries\u2014including marginal MAP, probabilistic answer set programming inference, and causal backdoor adjustment\u2014correspond to a combination of basic operators over semirings: aggregation, product, and elementwise mapping. Using this framework, we uncover simple and general sufficient conditions for tractable composition of these operators, in terms of circuit properties (e.g., marginal determinism, compatibility) and conditions on the elementwise mappings. Applying our analysis, we derive novel tractability conditions for many such compositional queries. Our results unify tractability conditions for existing problems on circuits, while providing a blueprint for analysing novel compositional inference queries. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Circuit-based representations, such as Boolean circuits, decision diagrams, and arithmetic circuits, are of central importance in many areas of AI and machine learning. For example, a primary means of performing inference in many models, from Bayesian networks [16, 9] to probabilistic programs [20, 24, 26, 43], is to convert them into equivalent circuits; this is commonly known as knowledge compilation. Inference via knowledge compilation has also been used for many applications in neuro-symbolic AI, such as constrained generation [2, 54] and neural logic programming [34, 28]. Circuits can also be learned as probabilistic generative models directly from data [25, 41, 40, 32], in which context they are known as probabilistic circuits [11]. Compared with neural generative models, probabilistic circuits enjoy tractable evaluation of inference queries such as marginal probabilities, which has been used for tasks such as fair machine learning [12] and causal reasoning [53, 50, 49]. ", "page_idx": 0}, {"type": "text", "text": "The key feature of circuits is that they enable one to precisely characterize tractability conditions under which a given inference query can be computed exactly and efficiently, in terms of structural properties of the circuit. One can then enforce these circuit properties when compiling or learning a model to enable tractable inference. For many basic inference queries, such as computing a marginal probability, tractability conditions are well understood [48, 8]. However, for more complex queries, the situation is less clear, and the exercise of deriving tractability conditions for a given query has usually been carried out in an instance-specific manner requiring significant effort. ", "page_idx": 0}, {"type": "image", "img_path": "mXlR1FLFDc/tmp/62ebe7f97a59c0924e1afeda50a7e693197544bf8b9224acc7fe333824e4f4bb.jpg", "img_caption": ["Figure 1: Example applications of our compositional inference framework for (Left) MMAP and (Right) Success Probability in Prob. Logic Programing under the Stable Model semantics (MaxEnt). "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "In Figure 1, we illustrate two such queries. The marginal MAP (MMAP) [13] query takes a probabilistic circuit $p$ and some evidence $^e$ and asks for the most likely assignment of a subset of variables. The success probability inference in probabilistic logic programming [6, 45] takes a circuit representation $\\phi$ of a logic program, a weight function $\\omega$ and some query $\\pmb q$ , and computes the probability of the query under the program\u2019s semantics (MaxEnt, in the example). At first glance, these seem like very different queries, involving different types of input circuits (logical and probabilistic), and different types of computations. However, they share similar algebraic structure: logical and probabilistic circuits can be interpreted as circuits defined over different semirings, while maximization and summation can be viewed as aggregation over different semirings. In this paper, inspired by the compositional atlas for probabilistic circuits [48], we take a compositional approach to algebraic inference problems, breaking them down into a series of basic operators: aggregation, product, and elementwise mapping. For example, the MMAP and probabilistic logic programming queries involve multiple interleaved aggregations and products, along with one elementwise mapping each. Given a circuit algorithm (and associated tractability condition) for each basic operator, we can reuse these algorithms to construct algorithms for arbitrary compositions. The key challenge is then to check if each intermediate circuit satisfies the requisite tractability conditions. ", "page_idx": 1}, {"type": "text", "text": "Our contributions can be summarized as follows. We introduce a compositional inference framework for algebraic circuits (Section 3) over arbitrary semirings, generalizing existing results on logical [18] and probabilistic [48] circuits. In particular, we provide a language for specifying inference queries involving different semirings as a composition of basic operators (Section 3.1). We then prove sufficient conditions for the tractability of each basic operator (Section 3.2) and novel conditions for composing such operators (Section 3.3). We apply our compositional framework to a number of inference problems (Section 4), showing how our compositional approach leads to more systematic derivation of tractability conditions and algorithms, and in some cases improved complexity analysis. In particular, we discover a tractability hierarchy for inference queries captured under the 2AMC framework [29], and reduce the complexity of causal backdoor/frontdoor adjustment on probabilistic circuits [38, 49] from quadratic/cubic to linear/quadratic respectively. ", "page_idx": 1}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Notation We use capital letters (e.g., $X,Y)$ to denote variables and lowercase for assignments (values) of those variables (e.g., $x,y)$ . We use boldface to denote sets of variables/assignments (e.g., $X,y)$ and write $\\mathrm{Assign}(V)$ for the set of all assignments to $V$ . Given a variable assignment $\\pmb{v}$ of $V$ , and a subset of variables $W\\subseteq V$ , we write $\\pmb{v}_{W}$ to denote the assignment of $W$ corresponding to $\\pmb{v}$ . ", "page_idx": 1}, {"type": "text", "text": "Semirings In this paper, we consider inference problems over commutative semirings. Semirings are sets closed w.r.t. operators of addition $\\left(\\oplus\\right)$ and multiplication $\\left(\\otimes\\right)$ that satisfy certain properties: ", "page_idx": 1}, {"type": "text", "text": "Definition 1 (Commutative Semiring). A commutative semiring $\\boldsymbol{S}$ is a tuple $(S,\\oplus,\\otimes,0s,1s)$ , where $\\bigoplus$ and $\\otimes$ are associative and commutative binary operators on a set $S$ (called the domain) such that $\\otimes$ distributes over $\\oplus$ (i.e., $a\\otimes(b\\oplus c)=(a\\otimes b)\\oplus(a\\otimes c)$ for all $a,b,c\\in S)$ ; $0s\\in S$ is the additive identity (i.e., $0_{\\cal S}\\oplus a=a$ for all $a\\in S$ ) and annihilates $S$ through multiplication (i.e., $0_{\\cal S}\\otimes a=0$ for all $a\\in S$ ); and $1s\\in S$ is the multiplicative identity (i.e., $1_{S}\\otimes a=a$ for all $a\\in S$ ). ", "page_idx": 1}, {"type": "text", "text": "For example, the probability semiring $\\mathcal{P}=(\\mathbb{R}_{\\geq0},+,\\cdot,0,1)$ employs standard addition and multiplication $\\oplus=+$ and $\\otimes=\\cdot)$ over the non-negative reals, the $\\mathrm{(max,\\cdot)}$ semiring $\\mathcal{M}=(\\mathbb{R}_{\\geq0},\\operatorname*{max},\\cdot,0,1)$ ", "page_idx": 1}, {"type": "text", "text": "replaces addition with maximization, while the Boolean semiring $\\beta=(\\{\\bot,\\top\\},\\lor,\\land,\\bot,\\top)$ employs disjunction and conjunction operators ( $\\oplus=\\lor$ and $\\otimes=\\wedge$ ) over truth values. ", "page_idx": 2}, {"type": "text", "text": "Algebraic Circuits We now define the concept of an algebraic circuit, which are computational graph-based representations of functions taking values in an arbitrary semiring. ", "page_idx": 2}, {"type": "text", "text": "Definition 2 (Algebraic Circuit). Given a semiring ${\\cal S}=({\\cal S},\\oplus,\\otimes,0_{\\cal S},1_{\\cal S}),$ , an algebraic circuit $C$ over variables $V$ is a rooted directed acyclic graph $(D A G)$ , whose nodes $\\alpha$ have the following syntax: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\alpha::=l\\mid+_{i=1}^{k}\\alpha_{i}\\mid\\times_{i=1}^{k}\\alpha_{i}\\,,\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\alpha_{i}\\in C$ are circuit nodes, $k\\in\\mathbb{N}^{>0}$ and $l:A s s i g n(W)\\to S$ is a function over a (possibly empty) subset $W\\subseteq V$ of variables, called its scope. That is, each circuit node may be an input $(l)$ , sum $(+),$ , or a product $(\\times)$ . The scope of any internal node is defined to be var $\\iota(\\alpha):=\\cup_{i=1}^{k}\\mathrm{vars}(\\alpha_{i})$ . Each node $\\alpha$ represents a function $p_{\\alpha}$ taking values in $S$ , defined recursively by: $p_{\\alpha}({\\pmb w}):=l({\\pmb w})\\;i f$ $\\alpha=l,$ , $p_{\\alpha}(\\pmb{w})::=\\oplus_{i=1}^{k}p_{\\alpha_{i}}(\\pmb{w})$ if $\\alpha=+_{i=1}^{k}\\alpha_{i}$ , and $p_{\\alpha}({\\pmb w})::=\\otimes_{i=1}^{k}p_{\\alpha_{i}}({\\pmb w})\\;i f\\times_{i=1}^{k}\\!\\!\\alpha_{i},$ , where $W$ is the scope of $\\alpha$ . The function $p{_C}$ represented by the circuit is defined to be the function of the root node. The size $|C|$ of a circuit is defined to be the number of edges in the $D A G$ . ", "page_idx": 2}, {"type": "text", "text": "For simplicity, we will restrict to circuits with binary products (i.e. $k=2$ for products); this can be enforced with at most a linear increase in size. Prominent examples of algebraic circuits include negation normal forms (NNF) and binary decision diagrams [4]\u2014which are over the Boolean semiring and represent Boolean functions\u2014and probabilistic circuits [11]\u2014which are over the probabilistic semiring and represent probability distributions.1 By imposing simple restrictions on the circuit, which we call circuit properties, various inference queries that are computationally hard in general become tractable. In particular, smoothness and decomposability ensure tractable marginal inference: ", "page_idx": 2}, {"type": "text", "text": "Definition 3 (Smoothness, Decomposability). A circuit is smooth if for every sum node $\\alpha=+_{i}\\alpha_{i}$ , its children have the same scope: $\\forall i,j$ , v $\\operatorname{ars}(\\alpha_{i})=\\operatorname{vars}(\\alpha_{j})$ . A circuit is decomposable if for every product node $\\alpha=\\alpha_{1}\\times\\alpha_{2}$ , its children have disjoint scopes: vars $(\\alpha_{1})\\cap\\operatorname{vars}(\\alpha_{2})=\\emptyset$ . ", "page_idx": 2}, {"type": "text", "text": "Aside from the scopes of circuit nodes, we can also specify properties relating to their supports [11]: ", "page_idx": 2}, {"type": "text", "text": "Definition 4 ( $\\mathbf{\\deltaX}$ -Support). Given a partition $(X,Y)$ of variables $V$ and a node $\\alpha$ in circuit $C$ , the $\\mathbf{\\deltaX}$ -support of $\\alpha$ is the projection of its support on $\\mathbf{\\deltaX}$ : ", "page_idx": 2}, {"type": "equation", "text": "$$\ns u p p_{X}(\\alpha)=\\{x\\in A s s i g n(X\\cap\\mathrm{vars}(\\alpha)):\\exists y\\in A s s i g n(\\mathrm{vars}(\\alpha)\\setminus X)\\;s.t\\;.\\;p_{\\alpha}(\\pmb{x},y)\\neq0_{S}\\}.\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Definition 5 ( $\\mathbf{\\deltaX}$ -Determinism). Given a circuit $C$ and a partition $(X,Y)$ of $V$ , we say that $C$ is $\\mathbf{\\deltaX}$ -deterministic if for all sum nodes $\\alpha\\,=\\,+_{i=1}^{k}\\alpha_{i}$ , either: $(i)$ var $\\operatorname{s}(\\alpha)\\cap X\\,=\\,\\emptyset$ ; or (ii) $s u p p_{X}(\\alpha_{i})\\cap s u p p_{X}(\\alpha_{j})=\\emptyset$ for all $i\\neq j$ . ", "page_idx": 2}, {"type": "text", "text": "$\\mathbf{\\deltaX}$ -determinism refers to a family of properties indexed by sets $\\mathbf{\\deltaX}$ . In particular $V$ -determinism is usually referred to simply as determinism. Note that, as defined, scope and support, and thus these circuit properties, apply to any semiring: the scope only depends on the variable decomposition of the circuit, while the support only refers to scope and the semiring additive identity $0_{S}$ . Figure 2a shows a simple example of a smooth, decomposable, and deterministic circuit that is not $X$ -deterministic, while Figure 2b shows a smooth, decomposable, and $\\{X_{1},X_{2}\\}$ -deterministic circuit. ", "page_idx": 2}, {"type": "text", "text": "3 Compositional Inference: A Unifying Approach ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Many inference problems can be written as compositions of basic operators, which take as input one or more functions and output another function. For example, the marginal MAP query on probability distributions $\\begin{array}{r}{\\operatorname*{max}_{\\pmb{x}}\\sum_{\\pmb{y}}p(\\pmb{x},\\pmb{y})}\\end{array}$ is a composition of the $\\displaystyle\\sum$ and max operators. Similarly, for Boolean functions $\\phi,\\psi$ , the query $\\begin{array}{r}{\\sum_{\\mathbf{x}}\\exists\\mathbf{y}.\\,\\phi(\\mathbf{x},\\mathbf{y})\\wedge\\psi(\\mathbf{x},\\mathbf{y})}\\end{array}$ composes the $\\displaystyle\\sum$ , \u2203and $\\wedge$ operators. Although these queries appear to involve four different operators, three of them $(\\Sigma,{\\mathrm{max}},\\exists)$ can viewed as an aggregation operation over different semirings. Thus, we begin this section by consolidating to a simple set of three operators applicable to functions taking values in some semiring: namely, aggregation, product, and elementwise mapping (Section 3.1). ", "page_idx": 2}, {"type": "image", "img_path": "mXlR1FLFDc/tmp/ddd40f6b11b6808121b8573763fc665e397eb6543b0dab67b4b14ec7418e52ff.jpg", "img_caption": ["(a) A Boolean circuit that is smooth, decompos- (b) A probabilistic circuit that is smooth, decomposable, and able, deterministic, but not $\\Chi$ -deterministic. X-deterministic. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Equipped with this language for specifiying compositional inference queries, we then move on to analyzing their tractability when the input functions are given as circuits. The thesis of this paper is that algebraic structure is often the right level of abstraction to derive useful sufficient (and sometimes necessary) conditions for tractability. We firstly show tractability conditions of each of the basic operators (Section 3.2), before deriving composability conditions that show how circuit properties are maintained through operators (Section 3.3). This enables us to systematically derive conditions for the input circuits that enable efficient computation of a compositional inference query. Algorithms and detailed proofs of all theorems can be found in Appendix A. ", "page_idx": 3}, {"type": "text", "text": "3.1 Basic Operators ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Aggregation Given a function $f:\\operatorname{Assign}(V)\\,\\to\\,S$ , aggregating $f$ over $W\\subseteq V$ returns the function $f^{\\prime}\\colon\\ensuremath{\\mathrm{Assign}}(Z)\\to S$ for $Z=V\\setminus W$ defined by $f^{\\prime}(z):=\\bigoplus_{w}f(z,w)$ . ", "page_idx": 3}, {"type": "text", "text": "For example, aggregation corresponds to forgetting variables $W$ in the Boolean semiring, marginalizing out $W$ in the probability semiring, and maximizing over assignments in the (max, \u00b7) semiring. Next, some queries, such as divergence measures between probability distributions, take two functions as inputs, and many others involve combining two or more intermediate results, as is the case in probabilistic answer set programming inference and causal backdoor/frontdoor queries. We define the product operator to encapsulate such \u201ccombination\u201d of functions in general. ", "page_idx": 3}, {"type": "text", "text": "Product Given two functions $f\\colon\\operatorname{Assign}(W)\\to S$ and $f^{\\prime}\\colon\\operatorname{Assign}(W^{\\prime})\\to S$ , the product of $f$ and $f^{\\prime}$ is a function $f^{\\prime\\prime}:\\operatorname{Assign}(V)\\to S$ , where $V\\!=\\!W\\!\\cup\\!W^{\\prime}$ , defined by $f^{\\prime\\prime}(\\boldsymbol{v}):=f(\\boldsymbol{v}_{W})\\otimes f^{\\prime}(\\boldsymbol{v}_{W^{\\prime}})$ . ", "page_idx": 3}, {"type": "text", "text": "For example, a product corresponds to the conjoin operator $\\wedge$ in the Boolean semiring, and standard multiplication $\\cdot$ in the probability semiring. Lastly, we introduce the elementwise mapping operator, defined by a mapping $\\tau$ from a semiring to a (possibly different) semiring. When applied to a function $f$ , it returns the function composition $\\tau\\circ f$ . This is the key piece that distinguishes our framework from prior analysis of sum-of-product queries over specific semirings, allowing us to express queries such as causal inference and probabilistic logic programming inference under the same framework. ", "page_idx": 3}, {"type": "text", "text": "Elementwise Mapping Given a function $f:\\operatorname{Assign}(V)\\to S$ and a mapping $\\tau:S\\rightarrow S^{\\prime}$ from semiring $\\boldsymbol{S}$ to $S^{\\prime}$ satisfying $\\tau(0_{S})=0_{S^{\\prime}}$ , an elementwise mapping of $f$ by $\\tau$ results in a function $f^{\\prime}:\\operatorname{Assign}(V)\\to S^{\\prime}$ defined by $f^{\\prime}(\\boldsymbol{v}):=\\tau(f(\\boldsymbol{v}))$ .2 ", "page_idx": 3}, {"type": "text", "text": "In practice, we use elementwise mappings as an abstraction predominantly for two purposes. The first is for switching between semirings, while the second is to map between elements of the same semiring. For the former, one of the most important elementwise mappings we will consider is the support mapping, which maps between any two semirings as follows. ", "page_idx": 3}, {"type": "text", "text": "Definition 6 (Support Mapping). Given a source semiring $\\boldsymbol{S}$ and a target semiring $S^{\\prime}$ , the support mapping $[\\![\\cdot]\\!]_{{\\cal S}\\to{\\cal S}^{\\prime}}$ is defined as: $[a]_{S\\rightarrow S^{\\prime}}=0_{S^{\\prime}}$ if $a=0_{S}$ ; $[a]_{S\\rightarrow S^{\\prime}}=1_{S^{\\prime}}$ otherwise. ", "page_idx": 3}, {"type": "text", "text": "In particular we will often use the source semiring ${\\cal S}={\\cal B}$ , in which case the support mapping maps $\\perp$ to the $0_{S^{\\prime}}$ and $\\intercal$ to the $1_{S^{\\prime}}$ in the target semiring. This is useful for encoding a logical function for inference in another semiring, e.g. probabilistic inference in the probabilistic semiring. ", "page_idx": 3}, {"type": "text", "text": "Example 1 (Marginal MAP). Suppose that we are given a Boolean formula $\\phi(X,Y)$ and a weight function $w:A s s i g n(X\\cup Y)\\rightarrow\\mathbb{R}_{\\geq0}$ . The marginal MAP query for variables $\\mathbf{\\deltaX}$ is defined by ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathrm{\\bfMMAP}(\\phi,\\omega)=\\operatorname*{max}_{x}\\sum_{y}\\phi({\\bf x},{\\bf y})\\cdot\\omega({\\bf x},{\\bf y})\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where we interpret $\\intercal$ as 1 and $\\bot$ as $\\boldsymbol{O}$ . We can break this down into a compositional query as follows: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bigoplus_{x}\\tau_{i d,\\mathcal{P}\\rightarrow\\mathcal{M}}\\left[\\bigoplus_{y}\\[\\phi(x,y)]_{\\mathcal{B}\\rightarrow\\mathcal{P}}\\otimes\\omega(\\pmb{x},\\pmb{y})\\right].\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The support mapping ensures $\\phi$ and $\\omega$ are both functions over the probabilistic semiring, so that we can apply the product operation. Notice also the inclusion of an identity mapping $\\tau_{i d,\\mathcal{P}\\rightarrow\\mathcal{M}}$ from the probability to the (max, \u00b7) semiring defined by $\\tau_{i d,\\mathcal{P}\\rightarrow\\mathcal{M}}(x)=x$ for all $x\\in\\mathbb{R}_{\\geq0}$ . While differentiating between semirings over the same domain may seem superfluous, the explicit identity operator will become important when we analyze the tractability of these compositions on circuits. ", "page_idx": 4}, {"type": "text", "text": "3.2 Tractability Conditions for Basic Operators ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We now consider the tractability of applying each basic operation to circuits: that is, computing a circuit whose function corresponds to the result of applying the operation to the functions given by the input circuit(s). First, it is well known that forgetting and marginalization of any subset of variables can be performed in polynomial time if the input circuits in the respective semirings (NNF and PC) are smooth and decomposable [18, 11]. This can be generalized to arbitrary semirings: ", "page_idx": 4}, {"type": "text", "text": "Theorem 1 (Tractable Aggregation). Let $C$ be a smooth and decomposable circuit representing a function $p:A s s i g n(V)\\to S$ . Then for any $W\\subseteq V$ , it is possible to compute the aggregate as a smooth and decomposable circuit $C^{\\prime}$ (i.e., $p_{C^{\\prime}}(Z)=\\bigoplus_{w}p_{C}(Z,w))$ in $O(|C|)$ time and space. ", "page_idx": 4}, {"type": "text", "text": "Next, let us consider the product operator. In the Boolean circuits literature, it is well known that the conjoin operator can be applied tractably if the circuits both follow a common structure known as a vtree [17]. In [48] a more general property known as compatibility was introduced that directly specifies conditions with respect to two (probabilistic) circuits, without reference to a vtree. We now define a generalization of this property ( $\\mathbf{\\deltaX}$ -compatibility) and also identify a new condition ( $\\mathbf{\\deltaX}$ -support-compatibility) that enables tractable products. ", "page_idx": 4}, {"type": "text", "text": "Definition 7 ( $\\mathbf{\\deltaX}$ -Compatibility). Given two smooth and decomposable circuits $C,C^{\\prime}$ over variables $V,V^{\\prime}$ respectively, and a variable set $X\\subseteq V\\cap V^{\\prime}$ , we say that $C,C^{\\prime}$ are $\\mathbf{\\deltaX}$ -compatible if for every product node $\\alpha=\\alpha_{1}\\times\\alpha_{2}\\in C$ and $\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\times\\alpha_{2}^{\\prime}\\in C^{\\prime}$ such that vars $(\\alpha)\\cap X=\\operatorname{vars}(\\alpha^{\\prime})\\cap X$ , the scope is partitioned in the same way, i.e. vars $(\\alpha_{1})\\cap X=\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap X$ and va $\\mathbf{\\hat{s}}(\\alpha_{2})\\cap\\mathbf{X}=$ $\\mathrm{vars}(\\alpha_{2}^{\\bar{\\prime}})\\cap\\bar{\\pmb X}$ . We say that $C,C^{\\prime}$ are compatible $i f$ they are $(V\\cap V^{\\prime})$ -compatible. ", "page_idx": 4}, {"type": "text", "text": "Intuitively, compatibility states that the scopes of the circuits decompose in the same way at product nodes. Compatibility of two circuits suffices to be able to tractably compute their product: ", "page_idx": 4}, {"type": "text", "text": "Theorem 2 (Tractable Product - Compatibility). Let $C,C^{\\prime}$ be compatible circuits over variables $V,V^{\\prime}$ , respectively, and the same semiring. Then it is possible to compute their product as a circuit $C$ compatible with them (i.e., $p_{C^{\\prime\\prime}}(V\\cup V^{\\prime})=p_{C}(V)\\otimes p_{C^{\\prime}}(V^{\\prime}))$ in $O(|C||C^{\\prime}|)$ time and space. ", "page_idx": 4}, {"type": "text", "text": "We remark that if we are given a fully factorized function $\\begin{array}{r}{f(V)\\,=\\,\\otimes_{V_{i}\\in V}f_{i}(V_{i})}\\end{array}$ , this can be arranged as a circuit (series of binary products) compatible with any other decomposable circuit; thus, we say this type of function is omni-compatible. We also say that a circuit is structured decomposable if it is compatible with itself. Now, our more general definition of $\\mathbf{\\deltaX}$ -compatibility states that the scopes of the circuits restricted to $\\mathbf{\\deltaX}$ decompose in the same way at product nodes. This will be important when we consider composing products with other operators, such as aggregation. The following result shows that compatibility w.r.t. a subset is a weaker condition: ", "page_idx": 4}, {"type": "text", "text": "Proposition 1 (Properties of $\\mathbf{\\deltaX}$ -Compatibility). If two circuits $C,C^{\\prime}$ are $\\mathbf{\\deltaX}$ -compatible, then they are $X^{\\prime}$ -compatible for any subset $X^{\\prime}\\subseteq X$ . ", "page_idx": 4}, {"type": "text", "text": "Compatibility is a sufficient but not necessary condition for tractable products; it is also known that some circuits can be multiplied with themselves in linear time, even when they are not structured decomposable [48, 27]. We formalize this idea with a new property which we call support-compatibility. ", "page_idx": 4}, {"type": "text", "text": "Definition 8 ( $\\mathbf{\\deltaX}$ -Support Compatibility). Given two smooth and decomposable circuits $C,C^{\\prime}$ over variables $V$ , $V^{\\prime}$ respectively, and a set of variables $X\\subseteq V\\cap V^{\\prime}$ , let $C[X]$ , $C^{\\prime}[X]$ be the $D A G s$ obtained by restricting to nodes with scope overlapping with $\\mathbf{\\deltaX}$ . We say that $C,C^{\\prime}$ are $\\mathbf{\\deltaX}$ -supportcompatible if there is an isomorphism \u03b9 between $C[X]$ , $C^{\\prime}[X]$ such that: $(i)$ for any node $\\alpha\\in C[X]$ , $\\operatorname{vars}(\\alpha)\\cap\\dot{\\mathbf{X}}=\\operatorname{vars}(\\iota(\\alpha))\\cap\\Bar{\\mathbf{X}},$ ; (ii) for any sum node $\\alpha\\in C[X],$ , sup $^{\\upsilon}_{X}(\\alpha_{i})\\cap s u p p_{X}(\\iota(\\alpha_{j}))\\stackrel{\\cdot}{=}\\bar{\\emptyset}$ whenever $i\\neq j$ . We say that $C,C^{\\prime}$ are support-compatible $i f$ they are $(V\\cap V^{\\prime})$ -support-compatible. ", "page_idx": 5}, {"type": "text", "text": "To unpack this definition, we note that any smooth, decomposable, and $\\mathbf{\\deltaX}$ -deterministic circuit is $\\mathbf{\\deltaX}$ -support-compatible with itself, with the obvious isomorphism. However, this property is more general in that it allows for circuits over different sets of variables and does not require that the nodes represent exactly the same function; merely that the sum nodes have \u201ccompatible\u201d support decompositions. As we will later see, the significance of this property is that it can be often maintained through applications of operators, making it useful for compositions. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3 (Tractable Product - Support Compatibility). Let $C,C^{\\prime}$ be support-compatible circuits over variables $V,V^{\\prime}$ , respectively, and the same semiring. Then, given the isomorphism $\\iota$ , it is possible to compute their product as a smooth and decomposable circuit $C^{\\prime\\prime}$ support-compatible with them (i.e., $p_{C^{\\prime\\prime}}\\bar{(}V\\cup V^{\\prime})\\stackrel{}{=}p_{C}(V)\\otimes p_{C^{\\prime}}(V^{\\prime}))$ in $O(\\operatorname*{max}(|C|,|C^{\\prime}|))$ time and space. ", "page_idx": 5}, {"type": "text", "text": "We now examine the tractability of general elementwise mappings $\\tau:S\\rightarrow S^{\\prime}$ on a circuit $C$ . It is tempting here to simply construct a new circuit $C^{\\prime}$ over the semiring $S^{\\prime}$ with the same structure as $C$ , and replace each input function $l$ in the circuit with $\\tau(l)$ . However, the resulting circuit $p_{C^{\\prime}}(V)$ is not guaranteed to correctly compute $\\tau(p_{C}(V))$ in general. For example, consider the support mapping $\\mathbb{\\bar{\\lVert}}\\mathbf{\\cdot}\\mathbb{J}_{B\\to S}$ \u2014which maps $\\perp$ to $0_{S}$ and $\\intercal$ to $1_{\\ensuremath{\\mathcal{S}}}$ \u2014for the probability semiring $S=(\\mathbb{R}_{\\geq0},+,\\cdot,0,1)$ . Then t h e transformation of the smooth and decomposable circuit $C=X\\vee X$ produces $C^{\\prime}=\\mathbb{1}_{X=1}\\!+\\!\\mathbb{1}_{X=1}$ , which evaluates to $p_{C^{\\prime}}(X=1)=2$ whereas $\\tau(p_{C}(X=1))=1$ . In order for this simple algorithm to be correct, we need to impose certain conditions on the elementwise mapping $\\tau$ and/or the circuit $C$ it is being applied to. ", "page_idx": 5}, {"type": "text", "text": "Theorem 4 (Tractable Mapping). Let $C$ be a smooth and decomposable circuit over semiring $\\boldsymbol{S}$ , and $\\tau:S\\rightarrow S^{\\prime}$ a mapping such that $\\tau(0_{\\cal S})=0_{\\cal S^{\\prime}}$ . Then it is possible to compute the mapping of $C$ by $\\tau$ as a smooth and decomposable circuit $C^{\\prime}$ (i.e., $p_{C^{\\prime}}(V)\\stackrel{!}{=}\\tau(p_{C}(V)))$ in $O(|C|)$ time and space if $\\tau$ distributes over sums and over products. ", "page_idx": 5}, {"type": "text", "text": "$\\tau$ distributes over sums $i f$ : either (Additive) $\\tau$ is an additive homomorphism, i.e. $\\tau(a\\oplus b)\\;=\\;$   \n$\\tau(a)\\oplus\\tau(b)$ ; or (Det) $C$ is deterministic. ", "page_idx": 5}, {"type": "text", "text": "$\\tau$ distributes over products $i f$ : either (Multiplicative) $\\tau$ is an multiplicative homomorphism, i.e. $\\tau(a\\otimes b)=\\tau(a)\\otimes\\tau(b);\\,o r\\,(P r o d\\,\\theta/I)\\,\\tau(1_{S})=1_{S^{\\prime}}$ , and for all product nodes $\\alpha=\\alpha_{1}\\times\\alpha_{2}\\in C$ , and for every value $\\pmb{v}\\in A s s i g n(\\operatorname{vars}(\\alpha))$ , either $p_{\\alpha_{1}}(\\pmb{v}_{\\mathrm{vars}(\\alpha_{1})})\\in\\{0_{S},1_{S}\\}$ or $p_{\\alpha_{2}}(\\pmb{v}_{\\mathrm{vars}(\\alpha_{2})})\\in\\{0_{S},1_{S}\\}$ . ", "page_idx": 5}, {"type": "text", "text": "We can apply Theorem 4 to immediately derive the following property of support mappings: ", "page_idx": 5}, {"type": "text", "text": "Corollary 1 (Support Mapping). Given a circuit $C$ over a semiring $\\boldsymbol{S}$ and any target semiring $S^{\\prime}$ , a circuit representing $\\mathbb{[}p_{C}\\mathbb{]}_{S\\rightarrow S^{\\prime}}$ can be computed tractably if $(i)\\,S$ satisfies $a\\oplus b=0_{\\cal S}\\implies a=$ $b=0_{S}$ and $S^{\\prime}$ is idem  pote nt (i.e., $1_{S^{\\prime}}\\oplus1_{S^{\\prime}}=1_{S^{\\prime}},$ ), or (ii) $C$ is deterministic. ", "page_idx": 5}, {"type": "text", "text": "Proof. First note that $[\\![\\cdot]\\!]_{{\\cal S}\\to{\\cal S}^{\\prime}}$ satisfies (Multiplicative), and thus distributes over products. If (i) holds, consider $[a\\oplus b]_{S\\rightarrow S^{\\prime}}$ .  If $a=b=0_{S}$ , then this is equal to ${\\mathbb{[}}0s{\\mathbb{J}}s\\to s^{\\prime}={\\mathbb{[}}a{\\mathbb{J}}s\\to s^{\\prime}+{\\mathbb{[}}b{\\mathbb{J}}s\\to s^{\\prime}=0_{S^{\\prime}}$ ; otherwis e $a,b,a\\oplus b\\neq0_{S}$ and ${\\displaystyle\\|a\\oplus b\\|_{\\mathcal{S}\\to\\mathcal{S}^{\\prime}}=\\|a\\|_{\\mathcal{S}\\to\\mathcal{S}^{\\prime}}\\oplus\\|b\\|_{\\mathcal{S}\\to\\mathcal{S}^{\\prime}}=\\bar{1}_{\\mathcal{S}^{\\prime}}}$ (by ide m p otence of $S^{\\prime}$ ). Thus $[\\![\\cdot]\\!]_{{\\cal S}\\to{\\cal S}^{\\prime}}$ satisfies (Additiv e ). Alte rnatively,   if ( ii) holds,  th en (Det) holds. In either case $\\[\\cdot]_{S\\to S^{\\prime}}$ distri b u tes over sums in the circuit. \u53e3 ", "page_idx": 5}, {"type": "text", "text": "The following examples illustrate the generality of elementwise mappings and Theorem 4: ", "page_idx": 5}, {"type": "text", "text": "Example 2 (Partition Function and MPE). Given a probability distribution $p(V)$ , consider the task of computing the partition function $\\sum_{v}p(v)$ and $M P E\\operatorname*{max}_{v}p(\\mathbf{v})$ . These can be viewed as aggregations over the probability and (max, \u00b7) semirings respectively. ", "page_idx": 5}, {"type": "text", "text": "$p$ is often either a probabilistic circuit $C_{p r o b}$ , or a combination of a Boolean circuit $C_{b o o l}$ and weights $w$ (in weighted model counting). In the former case, the partition function is tractable because the circuit is already over the probability semiring, while in the latter case, MPE is tractable because the $\\begin{array}{r}{S^{\\prime}=(\\operatorname*{max},\\cdot)}\\end{array}$ semiring is idempotent so $\\mathbb{\\left[}C_{b o o l}\\right]\\!\\!\\!\\slash_{B\\to S^{\\prime}}$ is tractable. On the other hand, the partition function for Boolean circuits and MPE for PCs require determinism for the conditions of Theorem 4 to hold; in fact, these problems are known to be NP-hard without determinism $[I8,39]$ . ", "page_idx": 5}, {"type": "table", "img_path": "mXlR1FLFDc/tmp/52482fdc2407360d748f2a8f8b561d2573e898b0f7a1af7813937eaa7b9c49ee.jpg", "table_caption": ["Table 1: Tractability Conditions for Operations on Algebraic Circuits. Sm: Smoothness, Dec: Decomposability; $\\mathbf{\\deltaX}$ -Det(erminism), $\\mathbf{\\deltaX}$ -Cmp: $\\mathbf{\\deltaX}$ -Compatibility, $\\mathbf{\\deltaX}$ -SCmp: $\\mathbf{\\deltaX}$ -Support-Compatibility. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "Example 3 (Power Function in Probability Semiring). For the probability semiring ${\\mathcal{S}}\\,=\\,{\\mathcal{S}}^{\\prime}\\,=$ $(\\mathbb{R}_{\\geq0},+,\\cdot,0,1)$ , consider the power function $\\tau_{\\beta}(a)\\;:=\\;\\left\\{{a}^{\\beta}\\quad i f\\,a\\neq0\\right.$ 0 if a = 0 for some \u03b2 \u2208 R. This mapping satisfies (Multiplicative), and is tractable if we enforce (Det) on the circuit. ", "page_idx": 6}, {"type": "text", "text": "It is worth noting that semiring homomorphisms (i.e. additive and multiplicative) are always tractable. In the case when $S=S^{\\prime}=\\mathcal{P}$ , it was shown in [48] that the only such mapping is the identity function. However this is not the case for other semirings: the power function $\\tau_{\\beta}$ is an example in the (max, \u00b7) semiring. To summarize, we have shown sufficient tractability conditions for aggeregation, products, and elementwise mappings. Notice that the conditions for aggregation and products only depend on variable scopes and supports, and as such apply to any semiring; in contrast, for elementwise mappings, we take advantage of specific properties of the semiring(s) in question. ", "page_idx": 6}, {"type": "text", "text": "3.3 Tractable Composition of Operators ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now analyze compositions of these basic operators. As such, we need to consider not only circuit properties that enable tractability, but how these properties are maintained through each operator, so that the output circuit can be used as input to another operator. We call these composability conditions. In all cases, the output circuit is smooth and decomposable. Thus, we focus on the properties of $\\mathbf{\\deltaX}$ -determinism, $\\mathbf{\\deltaX}$ -compatibility, and $\\mathbf{\\deltaX}$ -support-compatibility. We emphasize that these are not singular properties, but rather families of properties indexed by a variable set $\\mathbf{\\deltaX}$ . We present the intuitive ideas behind our results below, while deferring full proofs to the Appendix. ", "page_idx": 6}, {"type": "text", "text": "Theorem 5 (Composability Conditions). The results in Table 1 hold. ", "page_idx": 6}, {"type": "text", "text": "$\\mathbf{\\deltaX}$ -determinism Intuitively, $\\mathbf{\\deltaX}$ -determinism is maintained through products because the resulting sum nodes partition the $\\mathbf{\\deltaX}$ -support in a \"finer\" way to the original circuits, and through elementwise mappings since they do not expand the support of any node (since $\\tau(0_{\\cal S})=0_{{\\cal S}^{\\prime}})$ ). For aggregation, the $\\mathbf{\\deltaX}$ -support is maintained if aggregation does not occur over any of the variables in $\\mathbf{\\deltaX}$ . ", "page_idx": 6}, {"type": "text", "text": "$\\mathbf{\\deltaX}$ -compatibility Here, we are interested in the following question: if the input circuit(s) to some operator are $\\mathbf{\\deltaX}$ -compatible with some other circuit $C_{\\mathrm{other}}$ for any fixed $\\mathbf{\\deltaX}$ , is the same true of the output of the operator? $\\mathbf{\\deltaX}$ -compatibility with $C_{\\mathrm{other}}$ is maintained through aggregation because it weakens the condition (by Proposition 1) and through elementwise mapping as it does not change variable scopes. As for taking the product of circuits, the output circuit will maintain similar variable partitionings at products, such that it remains $\\mathbf{\\deltaX}$ -compatible with $C_{\\mathrm{other}}$ . Notably, this result does not hold for compatibility where the scope $\\mathbf{\\deltaX}$ may be different for each pair of circuits under consideration; we show a counterexample in Example 4 in the Appendix. ", "page_idx": 6}, {"type": "text", "text": "$\\mathbf{\\deltaX}$ -support-compatibility $\\mathbf{\\deltaX}$ -support-compatibility is maintained through elementwise mappings and aggregation (except on $\\mathbf{\\deltaX}$ ) for similar reasons to $\\mathbf{\\deltaX}$ -determinism. For products, the result retains a similar $\\mathbf{\\deltaX}$ -support structure, so $\\mathbf{\\deltaX}$ -support compatibility is maintained. ", "page_idx": 6}, {"type": "text", "text": "We conclude by remarking that, once we determine that a compositional query is tractable, then one immediately obtains a correct algorithm for computing the query by application of the generic algorithms for aggregation, product, and elementwise mapping (see Appendix A). An upper bound on the complexity (attained by the algorithm) is also given by considering the complexities of each individual operator; in particular, the algorithm is polytime for a bounded number of operators. ", "page_idx": 6}, {"type": "table", "img_path": "mXlR1FLFDc/tmp/04ee1355073b4eda70d3fba9e279d3fc1f7f13fab2a4f3d4a01ee8c9a7094519.jpg", "table_caption": ["Table 2: Tractability Conditions and Complexity for Compositional Inference Problems. We denote new results with an asterisk. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "4 Case Studies ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we apply our compositional framework to analyze the tractability of several different problems involving circuits found in the literature (Table 2). Some of the results are known, but can now be cast in a general framework (with often simpler proofs). We also present new results, deriving tractability conditions that are less restrictive than reported in existing literature. ", "page_idx": 7}, {"type": "text", "text": "Theorem 6 (Tractability of Compositional Queries). The results in Table 2 hold. ", "page_idx": 7}, {"type": "text", "text": "4.1 Algebraic Model Counting ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In algebraic model counting [30] (a generalization of weighted model counting), one is given a Boolean function $\\phi(V)$ , and a fully-factorized labeling function $\\omega(V)=\\otimes_{V_{i}\\in V}\\omega_{i}(V_{i})$ in some semiring $\\boldsymbol{S}$ , and the goal is to aggregate these labels for all satisfying assignments of $\\phi$ . This can be easily cast in our framework as $\\displaystyle\\oplus_{v}(\\mathbb{I}(\\phi(\\pmb{v}))\\mathbb{I}_{\\mathcal{B}\\to S}\\otimes\\omega(\\pmb{v}))$ . Here, the support mapping $\\mathbb{I}\\!\\cdot\\!\\mathbb{I}_{\\substack{B\\to S}}$ transfers the Boolean function to the semiring $\\boldsymbol{S}$ over which aggregation occurs. Assuming that $\\phi(V)$ is given as a smooth and decomposable Boolean circuit (DNNF), then by Corollary 1 AMC is tractable if $\\boldsymbol{S}$ is idempotent or if the circuit is additionally deterministic (note that $\\omega(V)$ is omni-compatible, so the product is tractable); this matches the results of [30]. ", "page_idx": 7}, {"type": "text", "text": "2AMC A recent generalization of algebraic model counting is the 2AMC (second-level algebraic model counting) problem [29], which encompasses a number of important bilevel inference problems such as marginal MAP and inference in probabilistic answer set programs. Given a partition of the variables $\\pmb{V}=(\\pmb{X},\\pmb{Y})$ , a Boolean function $\\phi(X,Y)$ , outer and inner semirings $S_{X},S_{Y}$ , labeling functions $\\omega_{Y}(Y)=\\bigotimes_{Y_{i}\\in Y}\\omega_{Y,i}(Y_{i})$ over $\\mathcal{S}_{Y}$ and $\\begin{array}{r}{\\omega_{X}(X)=\\bigotimes_{X_{i}\\in{\\pmb X}}\\omega_{{\\pmb X},i}(\\bar{X}_{i})}\\end{array}$ over $\\mathcal{S}_{\\mathbf{X}}$ , and an elementwise mappin g $\\tau_{S_{Y}\\rightarrow S_{X}}:S_{Y}\\rightarrow S_{X}$ , the 2AMC proble m is given by: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\bigoplus_{\\pmb{x}}\\left(\\tau_{S_{\\pmb{Y}}\\rightarrow S_{\\pmb{X}}}\\left(\\bigoplus_{\\pmb{y}}[\\phi(\\pmb{x},\\pmb{y})]_{\\pmb{B}\\rightarrow S_{\\pmb{Y}}}\\otimes\\omega(\\pmb{y})\\right)\\otimes\\omega^{\\prime}(\\pmb{x})\\right)\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "To tackle this type of bilevel inference problem, [29] identified a circuit property called $\\mathbf{\\deltaX}$ -firstness. ", "page_idx": 7}, {"type": "text", "text": "Definition 9 ( $\\mathbf{\\deltaX}$ -Firstness). Suppose $C$ is a circuit over variables $V$ and $(X,Y)$ a partition of $V$ . We say that a node $\\alpha\\in C$ is $\\mathbf{\\deltaX}$ -only $i f\\operatorname{vars}(\\alpha)\\subseteq X$ , $\\mathbf{\\deltaY}$ -only $i f\\operatorname{vars}(\\alpha)\\subseteq Y$ , and mixed otherwise. Then we say that $C$ is $\\mathbf{\\deltaX}$ -first if for all product nodes $\\alpha=\\alpha_{1}\\times\\alpha_{2}$ , we have that either: $(i)$ each $\\alpha_{i}$ is $\\mathbf{\\deltaX}$ -only or $\\mathbf{\\deltaY}$ -only; $(i i)$ or exactly one $\\alpha_{i}$ is mixed, and the other is $\\mathbf{\\deltaX}$ -only. ", "page_idx": 7}, {"type": "text", "text": "It was stated in [29] that smoothness, decomposability, determinism, and $\\mathbf{\\deltaX}$ -firstness suffice to ensure tractable computation of 2AMC problems, by simply evaluating the circuit in the given semirings (caching values if necessary). We now show that this is neither sufficient nor necessary in general. To build intuition, consider the simple NNF circuit $\\phi(X,Y)=(X\\wedge Y)\\vee(X\\wedge\\neg Y)$ Note that $\\phi$ trivially satisfies $X$ -firstness and is smooth, decomposable, and deterministic. Let $\\boldsymbol{S}$ be the probability semiring, $S^{\\prime}$ be the $(\\operatorname*{max},\\cdot)$ -semiring, labeling functions be $\\omega(y)=\\omega(\\neg y)=1$ , $\\omega^{\\prime}(x)\\,=\\,\\omega^{\\prime}(\\lnot x)\\,=\\,1$ , and the mapping function be the identity $\\tau(a)\\;=\\;a$ . Then, noting that the labels are the multiplicative identity 1, the 2AMC value is max $\\begin{array}{r l}{\\phantom{\\,\\,\\,x}x\\,\\tau(\\sum_{Y}[\\phi(X,Y)]\\mathbb{1}_{B\\to S})\\,=}&{{}}\\end{array}$ 1 $\\begin{array}{r}{\\operatorname*{max}\\bigl(\\tau([\\phi(x,y)]_{B\\to S}+[\\phi(x,\\neg y)]_{B\\to S}),\\tau([\\phi(\\neg x,y)]_{B\\to S}+[\\phi(\\neg x,\\neg y)]_{B\\to S})\\bigr)=\\operatorname*{max}\\bigl(\\tau(1+\\tau(x,\\neg y))\\bigr).}\\end{array}$ $1),\\tau(0))=2$ . On the other hand, the algorithm of [29] returns the value $2{\\mathrm{AMC}}=1$ , as shown in Figure 3. This is not just a flaw in the specific evaluation algorithm, but rather a provable intractability of the problem given these properties: ", "page_idx": 7}, {"type": "image", "img_path": "mXlR1FLFDc/tmp/155d2f8d8b1fd7bf11e2a5105f4f037af76b5878ed0390b28e596103c2559b7f.jpg", "img_caption": ["Figure 3: Failure case of 2AMC algorithm on smooth, decomposable, X-first circuit. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "", "page_idx": 8}, {"type": "text", "text": "Theorem 7 (Hardness of 2AMC with $\\mathbf{\\deltaX}$ -firstness). 2AMC is #P-hard, even for circuits that are smooth, decomposable, deterministic, and $\\mathbf{\\deltaX}$ -first, and a constant-time elementwise mapping. ", "page_idx": 8}, {"type": "text", "text": "Analyzing using our compositional framework, the issue is that the tractability conditions for $\\tau$ do not hold; whilst the Boolean circuit is deterministic, this is not true once $Y$ is aggregated. In fact, we show that also enforcing $\\mathbf{\\deltaX}$ -determinism suffices to tractably compute arbitrary 2AMC instances. ", "page_idx": 8}, {"type": "text", "text": "Theorem 8 (Tractability Conditions for 2AMC). Every 2AMC instance is tractable in $O(|C|)$ time for Boolean circuits that are smooth, decomposable, deterministic, $\\mathbf{\\deltaX}$ -first, and $\\mathbf{\\deltaX}$ -deterministic. ", "page_idx": 8}, {"type": "text", "text": "Proof sketch. The key point to notice is that the elementwise mapping relative to the transformation of inner to outer semiring operates over an aggregation of an $\\mathbf{\\deltaX}$ -first and $\\mathbf{\\deltaX}$ -deterministic circuit, obtained by the product of a Boolean function (mapped to the inner semiring by a support mapping) and a weight function of $\\mathbf{Y}$ . Hence, it satisfies (Det) and (Prod $0/1$ ): all of the $\\mathbf{\\deltaX}$ -only children of a product node are 0/1 valued (in the inner semiring). \u53e3 ", "page_idx": 8}, {"type": "text", "text": "For specific instances of 2AMC, depending on the semirings $S,S^{\\prime}$ and mapping function $\\tau$ , we also find that it is possible to remove the requirement of $\\mathbf{\\deltaX}$ -firstness or determinism, as we summarize in Table 2. One might thus wonder if there is a difference in terms of compactness between requiring $\\mathbf{\\deltaX}$ -determinism and $\\mathbf{\\deltaX}$ -firstness, as opposed to $\\mathbf{\\deltaX}$ -determinism alone. For example, for sentential decision diagrams (SDD) [17], a popular knowledge compilation target, these notions coincide: a SDD is $\\mathbf{\\deltaX}$ -deterministic iff it is $\\mathbf{\\deltaX}$ -first (in which context this property is known as $\\mathbf{\\deltaX}$ -constrainedness [37, 22]). However, as shown in Figure 2b, there exist $\\mathbf{\\deltaX}$ -deterministic but not $\\mathbf{\\deltaX}$ -first circuits. We now show that $\\mathbf{\\deltaX}$ -deterministic circuits can be exponentially more succinct than $\\mathbf{\\deltaX}$ -deterministic circuits that are additionally $\\mathbf{\\deltaX}$ -first, as the size of $\\mathbf{\\deltaX}$ grows.3 ", "page_idx": 8}, {"type": "text", "text": "Theorem 9 (Exponential Separation). Given sets of variables $\\pmb{X}=\\{X_{1},...,X_{n}\\},$ , $\\pmb{Y}=\\{Y_{1},...,Y_{n}\\}$ , there exists a smooth, decomposable and $\\mathbf{\\deltaX}$ -deterministic circuit $C$ of size poly $(n)$ such that the smallest smooth, decomposable, and $\\mathbf{\\deltaX}$ -first circuit $C^{\\prime}$ such that $p_{C}\\equiv p_{C^{\\prime}}$ has size $2^{\\Omega(n)}$ . ", "page_idx": 8}, {"type": "text", "text": "Thus, to summarize, some instances of 2AMC can be solved efficiently when $\\phi$ is smooth, decomposable and $\\mathbf{\\deltaX}$ -deterministic. A larger number of instances can be solved when additionally, $\\phi$ is deterministic; and all 2AMC problems are tractable if we also impose $\\mathbf{\\deltaX}$ -firstness. ", "page_idx": 8}, {"type": "text", "text": "4.2 Causal Inference ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In causal inference, one is often interested in computing interventional distributions, denoted using the $d o(\\cdot)$ operator, as a function of the observed distribution $p$ . This function depends on the causal graph linking the variables, and can be derived using the do-calculus [38]. For example, the well-known backdoor and frontdoor graphs induce the following formulae: ", "page_idx": 8}, {"type": "equation", "text": "$$\np(\\pmb{y}|d o(\\pmb{x}))=\\sum_{z}p(z)p(\\pmb{y}|\\pmb{x},z),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "equation", "text": "$$\np(\\pmb{y}|d o(\\pmb{x}))\\!=\\!\\sum_{\\pmb{z}}p(\\pmb{z}|\\pmb{x})\\sum_{\\pmb{x}^{\\prime}}p(\\pmb{x}^{\\prime})p(\\pmb{y}|\\pmb{x}^{\\prime},\\pmb{z}).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "Assuming that the observed joint distribution $p(X,Y,Z)$ is given as a probabilistic circuit $C$ , we consider the problem of obtaining a probabilistic circuit $C^{\\prime}$ over variables $X\\cup Y$ representing $p(\\boldsymbol{Y}|d o(\\boldsymbol{X}))$ . Tractability conditions for the backdoor/frontdoor cases were derived by [49], with quadratic/cubic complexity respectively. However, we observe that in some cases we can avoid the requirement of structured decomposability and/or obtain reduced complexity relative to their findings. ", "page_idx": 9}, {"type": "text", "text": "In the backdoor case, it is known that structured decomposability and $(X\\cup Z)$ -determinism suffices for a quadratic time algorithm. This can be seen by decomposing into a compositional query: ", "page_idx": 9}, {"type": "equation", "text": "$$\n\\bigoplus_{z}\\Big(\\big(\\bigoplus_{x,y}p(v)\\big)\\otimes p(v)\\otimes\\tau_{-1}\\Big(\\bigoplus_{y}p(v)\\Big)\\Big).\n$$", "text_format": "latex", "page_idx": 9}, {"type": "text", "text": "where $V\\,=\\,(X,Y,Z)$ , and $\\tau_{-1}(a)\\,=\\,{\\binom{a^{-1}}{0}}\\quad{\\mathrm{if~}}a\\neq0\\quad$ Assuming $(X\\cup Z)$ -determinism and structured decomposability, then $\\tau_{-1}(\\bigoplus_{y}p(V))$ is tractable by (Det) and (Multiplicative), the product $p(V)\\otimes\\tau_{-1}\\bigl(\\bigoplus_{y}p(V)\\bigr)$ by support-compatibility, and the final product by compatibility. However, if we additionally have $_{z}$ -determinism, then the final product becomes tractable by support compatibility. This has linear rather than quadratic complexity, and does not require the circuit to be structured decomposable. In the frontdoor case, [49] showed that $\\mathbf{\\deltaX}$ -determinism, $(X\\cup Z)$ - determinism, and structured decomposability suffices for cubic complexity. However, we note that under such conditions, the inner product $p({\\pmb X}^{\\prime})\\otimes p({\\pmb Y}|{\\pmb X}^{\\prime},{\\pmb Z})$ is tractable by support-compatibility. As such, the complexity of this query is actually quadratic rather than cubic as previously shown. We summarize our findings in Table 2 and refer the reader to the Appendix for full proofs. ", "page_idx": 9}, {"type": "text", "text": "5 Related Work ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Our work builds upon the observation that many inference problems can be characterized as a composition of basic operators. Prior works have considered compositional inference for circuits in the Boolean [18] and probabilistic semirings [48, 49], deriving tractability conditions for operators specific to these semirings. Aside from generalizing to arbitrary semirings, we also introduce extended composability conditions that enable interleaving of aggregation, products, and mappings. Meanwhile, algebraic model counting [30] deals (implicitly) with mappings from the Boolean semiring to an arbitrary semiring, but does not consider compositional queries. Closest to our work, [29] consider a generalization of algebraic model counting that allows for an additional semiring translation; however, this still assumes input Boolean circuits and has incomplete tractability characterizations. Our framework resolves these limitations, permitting arbitrary compositional queries over semirings. ", "page_idx": 9}, {"type": "text", "text": "Many works have considered (unbounded) sums-of-products queries on arbitrary semirings [21, 5, 1, 23], encompassing many important problems such as constraint satisfaction problems [7], graphical model inference [55], and database queries [52], which are often computationally hard in the worstcase. Algorithms for such queries often utilize compact intermediate representations and/or assume compact input representations, such as circuits [35, 17, 36, 3]. Our framework focuses on queries where the number of operators is bounded, and characterizes conditions under which inference is tractable in polynomial time. It also includes elementwise mappings as a key additional abstraction that can be used to express queries involving more than sums and products. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "In summary, we have introduced a framework for analysing compositional inference problems on circuits, based on algebraic structure. In doing so, we were able to derive new tractability conditions and simplified algorithms for a number of existing problems, including 2AMC and causal inference. Our framework focuses on simple and composable sufficient tractability conditions for aggregations, products and elementwise mappings operators; a limitation of this generality is these conditions may not be necessary for specific queries on specific semirings. Our work motivates the development of knowledge compilation and learning algorithms that target the requisite circuit properties, such as $\\mathbf{\\deltaX}$ -determinism. Finally, while we focus on exact inference, for many problems (e.g. marginal MAP) approximate algorithms exist and are of significant interest; an interesting direction for future work is to investigate if these can be also be generalized using the compositional approach. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "This work was done in part while the authors were visiting the Simons Institute for the Theory of Computing. This work was funded in part by the DARPA ANSR program under award FA8750-23-2- 0004, the DARPA PTG Program under award HR00112220005, and NSF grant #IIS-1943641. DM received generous support from the IBM Corporation, the Center for Artificial Intelligence at University of S\u00e3o Paulo (C4AI-USP), the S\u00e3o Paulo Research Foundation (FAPESP grants #2019/07665-4 and 2022/02937-9), the Brazilian National Research Council (CNPq grant no. 305136/2022-4) and CAPES (Finance Code 001). YC was partially supported by a gift from Cisco University Research Program. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Mahmoud Abo Khamis, Hung Q Ngo, and Atri Rudra. Faq: questions asked frequently. In Proceedings of the 35th ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems, pages 13\u201328, 2016.   \n[2] Kareem Ahmed, Stefano Teso, Kai-Wei Chang, Guy Van den Broeck, and Antonio Vergari. Semantic probabilistic layers for neuro-symbolic learning. In Advances in Neural Information Processing Systems 35 (NeurIPS), dec 2022.   \n[3] Antoine Amarilli and Florent Capelli. Tractable circuits in database theory. ACM SIGMOD Record, 53(2):6\u201320, 2024.   \n[4] Antoine Amarilli, Marcelo Arenas, YooJung Choi, Mika\u00ebl Monet, Guy Van den Broeck, and Benjie Wang. A circus of circuits: Connections between decision diagrams, circuits, and automata. arXiv preprint arXiv:2404.09674, 2024.   \n[5] Fahiem Bacchus, Shannon Dalmao, and Toniann Pitassi. Solving# sat and bayesian inference with backtracking search. Journal of Artificial Intelligence Research, 34:391\u2013442, 2009.   \n[6] Chitta Baral, Michael Gelfond, and J. Nelson Rushton. Probabilistic reasoning with answer sets. Theory and Practice of Logic Programming, 9(1):57\u2013144, 2009.   \n[7] Stefano Bistarelli, Ugo Montanari, and Francesca Rossi. Semiring-based constraint satisfaction and optimization. Journal of the ACM (JACM), 44(2):201\u2013236, 1997.   \n[8] Oliver Broadrick, Honghua Zhang, and Guy Van den Broeck. Polynomial semantics of tractable probabilistic circuits. In Proceedings of the 40th Conference on Uncertainty in Artificial Intelligence (UAI), july 2024.   \n[9] Mark Chavira and Adnan Darwiche. On probabilistic inference by weighted model counting. Artificial Intelligence, 172(6):772\u2013799, 2008.   \n[10] Arthur Choi, Yexiang Xue, and Adnan Darwiche. Same-decision probability: A confidence measure for threshold-based decisions. International Journal of Approximate Reasoning, 53 (9):1415\u20131428, 2012. ISSN 0888-613X. doi: https://doi.org/10.1016/j.ijar.2012.04.005. URL https://www.sciencedirect.com/science/article/pii/S0888613X12000485. Fifth European Workshop on Probabilistic Graphical Models (PGM-2010).   \n[11] YooJung Choi, Antonio Vergari, and Guy Van den Broeck. Probabilistic circuits: A unifying framework for tractable probabilistic models. arXiv preprint, 2020.   \n[12] YooJung Choi, Meihua Dang, and Guy Van den Broeck. Group fairness by probabilistic modeling with latent fair decisions. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 12051\u201312059, 2021.   \n[13] YooJung Choi, Tal Friedman, and Guy Van den Broeck. Solving marginal map exactly by probabilistic circuit transformations. In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics (AISTATS), 2022.   \n[14] Fabio Gagliardi Cozman and Denis Deratani Mau\u00e1. On the semantics and complexity of probabilistic logic programs. Journal of Artificial Intelligence Research, 60:221\u2013262, 2017.   \n[15] Adnan Darwiche. On the tractable counting of theory models and its application to truth maintenance and belief revision. Journal of Applied Non-Classical Logics, 11(1-2):11\u201334, 2001. doi: 10.3166/jancl.11.11-34.   \n[16] Adnan Darwiche. A differential approach to inference in bayesian networks. Journal of the ACM (JACM), 50(3):280\u2013305, 2003.   \n[17] Adnan Darwiche. Sdd: A new canonical representation of propositional knowledge bases. In Twenty-Second International Joint Conference on Artificial Intelligence, 2011.   \n[18] Adnan Darwiche and Pierre Marquis. A knowledge compilation map. Journal of Artificial Intelligence Research, 17:229\u2013264, 2002.   \n[19] Cassio P De Campos. New complexity results for map in bayesian networks. In IJCAI, volume 11, pages 2100\u20132106. Citeseer, 2011.   \n[20] Luc De Raedt, Angelika Kimmig, and Hannu Toivonen. Problog: A probabilistic prolog and its application in link discovery. In Proceedings of the International Joint Conference in Artificial Intelligence (IJCAI), volume 7, pages 2462\u20132467, 2007.   \n[21] Rina Dechter. Bucket elimination: A unifying framework for reasoning. Artificial Intelligence, 113(1-2):41\u201385, 1999.   \n[22] Vincent Derkinderen and Luc De Raedt. Algebraic circuits for decision theoretic inference and learning. In ECAI 2020, pages 2569\u20132576. IOS Press, 2020.   \n[23] Thomas Eiter and Rafael Kiesel. On the complexity of sum-of-products problems over semirings. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages 6304\u20136311, 2021.   \n[24] Daan Fierens, Guy Van den Broeck, Joris Renkens, Dimitar Shterionov, Bernd Gutmann, Ingo Thon, Gerda Janssens, and Luc De Raedt. Inference and learning in probabilistic logic programs using weighted boolean formulas. Theory and Practice of Logic Programming, 15(3):358\u2013401, 2015.   \n[25] Robert Gens and Domingos Pedro. Learning the structure of sum-product networks. In International conference on machine learning, pages 873\u2013880. PMLR, 2013.   \n[26] Steven Holtzen, Guy Van den Broeck, and Todd Millstein. Scaling exact inference for discrete probabilistic programs. Proceedings of the ACM on Programming Languages, 4(OOPSLA): 1\u201331, 2020.   \n[27] Haiying Huang and Adnan Darwiche. Causal unit selection using tractable arithmetic circuits. arXiv preprint arXiv:2404.06681, 2024.   \n[28] Jiani Huang, Ziyang Li, Binghong Chen, Karan Samel, Mayur Naik, Le Song, and Xujie Si. Scallop: From probabilistic deductive databases to scalable differentiable reasoning. Advances in Neural Information Processing Systems, 34:25134\u201325145, 2021.   \n[29] Rafael Kiesel, Pietro Totis, and Angelika Kimmig. Efficient knowledge compilation beyond weighted model counting. In Proceedings of the 38th International Conference on Logic Programming (ICLP 2022), 2022.   \n[30] Angelika Kimmig, Guy Van den Broeck, and Luc De Raedt. Algebraic model counting. Journal of Applied Logic, 22:42\u201362, 2017.   \n[31] Johan Kwisthout. Most frugal explanations in bayesian networks. Artificial Intelligence, 218: 56\u201373, 2015. ISSN 0004-3702. doi: https://doi.org/10.1016/j.artint.2014.10.001.   \n[32] Anji Liu, Honghua Zhang, and Guy Van den Broeck. Scaling up probabilistic circuits by latent variable distillation. In Proceedings of the International Conference on Learning Representations (ICLR), may 2023.   \n[33] T. Lukasiewicz. Probabilistic description logic programs. International Journal of Approximate Reasoning, 45(2):288\u2013307, 2007.   \n[34] Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, and Luc De Raedt. Deepproblog: Neural probabilistic logic programming. Advances in neural information processing systems, 31, 2018.   \n[35] Robert Mateescu, Rina Dechter, and Radu Marinescu. And/or multi-valued decision diagrams (aomdds) for graphical models. Journal of Artificial Intelligence Research, 33:465\u2013519, 2008.   \n[36] Dan Olteanu and Maximilian Schleich. Factorized databases. ACM SIGMOD Record, 45(2): 5\u201316, 2016.   \n[37] Umut Oztok, Arthur Choi, and Adnan Darwiche. Solving pp pp-complete problems using knowledge compilation. In Fifteenth International Conference on the Principles of Knowledge Representation and Reasoning, 2016.   \n[38] Judea Pearl. Causal diagrams for empirical research. Biometrika, 82(4):669\u2013688, 1995.   \n[39] Robert Peharz, Robert Gens, Franz Pernkopf, and Pedro Domingos. On the latent variable interpretation in sum-product networks. IEEE transactions on pattern analysis and machine intelligence, 39(10):2030\u20132044, 2016.   \n[40] Robert Peharz, Antonio Vergari, Karl Stelzner, Alejandro Molina, Xiaoting Shao, Martin Trapp, Kristian Kersting, and Zoubin Ghahramani. Random sum-product networks: A simple and effective approach to probabilistic deep learning. In Uncertainty in Artificial Intelligence, pages 334\u2013344. PMLR, 2020.   \n[41] Tahrima Rahman, Prasanna Kothalkar, and Vibhav Gogate. Cutset networks: A simple, tractable, and scalable approach for improving the accuracy of chow-liu trees. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2014, Nancy, France, September 15-19, 2014. Proceedings, Part II 14, pages 630\u2013645. Springer, 2014.   \n[42] Amirmohammad Rooshenas and Daniel Lowd. Learning sum-product networks with direct and indirect variable interactions. In International Conference on Machine Learning, pages 710\u2013718. PMLR, 2014.   \n[43] Feras A Saad, Martin C Rinard, and Vikash K Mansinghka. Sppl: probabilistic programming with fast exact symbolic inference. In Proceedings of the 42nd acm sigplan international conference on programming language design and implementation, pages 804\u2013819, 2021.   \n[44] Amir Shpilka, Amir Yehudayoff, et al. Arithmetic circuits: A survey of recent results and open questions. Foundations and Trends\u00ae in Theoretical Computer Science, 5(3\u20134):207\u2013388, 2010.   \n[45] Pietro Totis, Luc De Raedt, and Angelika Kimmig. smProbLog: Stable model semantics in problog for probabilistic argumentation. Theory And Practice Of Logic Programming, 23(6): 1198\u20131247, 2023.   \n[46] Leslie G Valiant. The complexity of enumeration and reliability problems. SIAM Journal on Computing, 8(3):410\u2013421, 1979.   \n[47] Guy Van den Broeck, Anton Lykov, Maximilian Schleich, and Dan Suciu. On the tractability of shap explanations. In Proceedings of the 35th AAAI International Conference on Artificial Intelligence and Statistics (AAAI 2021), 2021.   \n[48] Antonio Vergari, YooJung Choi, Anji Liu, Stefano Teso, and Guy den Broeck. A Compositional Atlas of Tractable Circuit Operations for Probabilistic Inference. In Advances in Neural Information Processing Systems, volume 34, pages 13189\u201313201, 2021.   \n[49] Benjie Wang and Marta Kwiatkowska. Compositional probabilistic and causal inference using tractable circuit models. In Proceedings of the 26th International Conference on Artificial Intelligence and Statistics (AISTATS), pages 9488\u20139498. PMLR, 2023.   \n[50] Benjie Wang, Matthew R Wicker, and Marta Kwiatkowska. Tractable uncertainty for structure learning. In International Conference on Machine Learning, pages 23131\u201323150. PMLR, 2022.   \n[51] Zhun Yang, Adam Ishay, and Joohyung Lee. NeurASP: Embracing neural networks into answer set programming. In Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI), pages 1755\u20131762, 2020.   \n[52] Mihalis Yannakakis. Algorithms for acyclic database schemes. In VLDB, volume 81, pages 82\u201394, 1981.   \n[53] Matej Zec\u02c7evic\u00b4, Devendra Dhami, Athresh Karanam, Sriraam Natarajan, and Kristian Kersting. Interventional sum-product networks: Causal inference with tractable probabilistic models. Advances in neural information processing systems, 34:15019\u201315031, 2021.   \n[54] Honghua Zhang, Meihua Dang, Nanyun Peng, and Guy Van den Broeck. Tractable control for autoregressive language generation. In Proceedings of the 40th International Conference on Machine Learning (ICML), jul 2023.   \n[55] Nevin L Zhang and David Poole. A simple approach to bayesian network computations. In Proc. of the Tenth Canadian Conference on Artificial Intelligence, 1994. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "Input: Smooth and decomposable algebraic circuit $C(V)$ ; node $\\alpha\\in C$ ; Subset of variables $W\\subseteq\\operatorname{vars}(\\alpha)$ Output: Node encoding $\\bigoplus_{W}p_{\\alpha}(V)$ 1 if $\\alpha$ is input node then 2 return AGG-INPUT $(\\alpha;W)$ 3 else if $\\alpha$ is product or sum node and va $\\mathbf{\\hat{s}}(\\alpha)=\\mathbf{W}$ then 4 return NEWNODE $\\left(\\bigotimes_{i=1}^{k}p_{\\mathtt{A G G}(\\alpha_{i};W\\cap\\mathrm{vars}(\\alpha_{i}))}\\right)$ if $\\alpha$ is product else NEWNODE $\\left(\\oplus_{i=1}^{k}p_{\\mathtt{A G G}(\\alpha_{i};\\pmb{W})}\\right)$ 5 else if $\\alpha$ is product or sum node and $W\\subset\\operatorname{vars}(\\alpha)$ then 6 return $\\mathsf{\\bar{\\mathbf{\\alpha}}}\\times_{i=1}^{k}\\mathsf{A G G}(\\alpha_{i};W\\cap\\mathrm{vars}(\\alpha_{i}))$ if $\\alpha$ is product else $+_{i=1}^{k}\\mathtt{A G G}(\\alpha_{i};\\pmb{W})$ ", "page_idx": 14}, {"type": "text", "text": "Algorithm 2: PROD-CMP Input: Compatible algebraic circuits $C(V),C^{\\prime}(V^{\\prime})$ ; nodes $\\alpha\\in C,\\alpha^{\\prime}\\in C^{\\prime}$ s.t. $\\iota\\mathbf{ars}(\\bar{\\alpha})\\cap(V\\cap V^{\\prime})=\\mathrm{vars}(\\alpha^{\\prime})\\cap(V\\cap V^{\\prime})$ Output: Node encoding $p_{C}(V)\\otimes p_{C^{\\prime}}(V^{\\prime})$ 1 if v $\\operatorname{ars}(\\alpha)\\cap\\operatorname{vars}(\\alpha^{\\prime})=\\varnothing$ then 2 return $\\alpha\\times\\alpha^{\\prime}$ 3 else if $\\alpha$ is a product or input node and $\\alpha^{\\prime}=+_{j=1}^{k^{\\prime}}$ +jk\u2032=1 is a sum node then 4 return $+_{j=1}^{k^{\\prime}}\\mathtt{P R O D-C M P}(\\alpha,\\alpha_{j}^{\\prime})$ 5 else if $\\alpha,\\alpha^{\\prime}$ are input nodes then 6 ret $\\scriptstyle\\mathbf{urn}\\,\\mathrm{PROD-INPUT}(\\alpha,\\alpha^{\\prime})$ 7 else if $\\alpha=\\alpha_{1}\\times\\alpha_{2},\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\times\\alpha_{2}^{\\prime}$ are product nodes then 8 return PROD $-\\mathtt{C M P}\\big(\\alpha_{1},\\alpha_{1}^{\\prime}\\big)\\times\\mathtt{P R O D-C M P}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)$ 9 else if $\\alpha=+_{i=1}^{k}\\alpha_{i},\\alpha^{\\prime}=+_{j=1}^{k^{\\prime}}\\alpha_{j}^{\\prime}$ are sum nodes then 10 $\\begin{array}{r}{\\mathbf{return}+_{i=1}^{k}+_{j=1}^{k^{\\prime}}\\mathtt{P R O D-C M P}(\\alpha_{i},\\alpha_{j}^{\\prime})}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "A Algorithms and Proofs ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "In Algorithms 1-4 we present algorithms for the aggregation, product (with compatibility), product (with support-compatiblity), and elementwise mapping operators respectively (the initial call is to the root of the circuit(s)). In the following, we present proofs that the algorithms soundly compute smooth and decomposable output circuits for the respective operators. ", "page_idx": 14}, {"type": "text", "text": "A.1 Tractable Aggregation ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Theorem 1 (Tractable Aggregation). Let $C$ be a smooth and decomposable circuit representing a function $p:A s s i g n(V)\\to S$ . Then for any $W\\subseteq V$ , it is possible to compute the aggregate as a smooth and decomposable circuit $C^{\\prime}$ (i.e., $\\begin{array}{r}{p_{C^{\\prime}}(Z)=\\bigoplus_{w}\\bar{p_{C}}(Z,w))}\\end{array}$ in $O(|C|)$ time and space. ", "page_idx": 14}, {"type": "text", "text": "Proof. We prove this inductively, starting from the input nodes of the circuit. Our claim is that for each node $\\alpha\\in C$ , $\\mathtt{A G G}(\\alpha;W)$ (Algorithm 1) returns a node $\\alpha^{\\prime}$ with scope vars $(\\alpha^{\\prime})=\\operatorname{vars}(\\alpha)\\setminus W$ such that $\\begin{array}{r}{p_{\\alpha^{\\prime}}(\\operatorname{vars}(\\alpha^{\\prime}))=\\bigoplus_{\\mathbf{\\omega}}p_{\\alpha}(\\operatorname{vars}(\\alpha))}\\end{array}$ , and is decomposable (if product) and smooth (if sum). ", "page_idx": 14}, {"type": "text", "text": "If $\\alpha$ is an input node (Lines 1-2), then this is possible by assumption; we denote this with AGG-INPUT in the algorithm. Note that if $\\operatorname{vars}(\\alpha)=W$ , then this is just a scalar/constant (i.e. input node with empty scope). ", "page_idx": 14}, {"type": "text", "text": "Input: Support-compatible algebraic circuits $C(V),C^{\\prime}(V^{\\prime})$ ; nodes $\\alpha\\in C,\\alpha^{\\prime}\\in C^{\\prime}$ s.t. $\\iota(\\stackrel{\\cdot}{\\alpha})^{\\sharp}=\\alpha^{\\prime}$ Output: Circuit encoding $p_{C}(V)\\otimes p_{C^{\\prime}}(V^{\\prime})$ 1 if $\\operatorname{vars}(\\alpha)\\cap\\operatorname{vars}(\\alpha^{\\prime})=\\emptyset$ then 2 return $\\alpha\\times\\alpha^{\\prime}$ 3 else if $\\alpha,\\alpha^{\\prime}$ are input nodes then 4 return PROD-INPUT $(\\alpha,\\alpha^{\\prime})$ 5 else if $\\alpha=\\alpha_{1}\\times\\alpha_{2}$ , $\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\times\\alpha_{2}^{\\prime}$ are product nodes then 6 retu $\\begin{array}{r}{\\mathbf{m}\\mathtt{P R O D-S C M P}\\big(\\alpha_{1},\\alpha_{1}^{\\prime}\\big)\\times\\mathtt{P R O D-S C M P}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)}\\end{array}$ 7 else if +ik=1\u03b1i, \u03b1\u2032 = +ik=1\u03b1\u2032i are sum nodes then 8 return $+_{i=1}^{k}\\mathtt{P R O D-S C M P}(\\alpha_{i},\\alpha_{i}^{\\prime})$ ", "page_idx": 15}, {"type": "text", "text": "Algorithm 4: MAPPING ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Input: Smooth and decomposable algebraic circuit $C(V)$ over semiring $\\boldsymbol{S}$ ; Node $\\alpha\\in C$ ; Mapping function $\\bar{\\tau}:S\\rightarrow S^{\\bar{\\prime}}$   \nOutput: Node encoding $\\tau(p_{C}(V))$   \nif $\\alpha$ is input node then return MAPPING-INPUT $(\\alpha;\\tau)$   \nelse if $\\alpha$ is product or sum node then   \nreturn $\\otimes_{i=1}^{k}\\tt M A P P I N G(\\alpha_{i};\\tau)$ if $\\alpha$ is product else $\\oplus_{i=1}^{k}\\tt M A P P I N G(\\alpha_{i};\\tau)$ ", "page_idx": 15}, {"type": "text", "text": "If $\\alpha$ is a product node $\\alpha_{1}\\times\\alpha_{2}$ , then by decomposability, $W\\cap\\operatorname{vars}(\\alpha_{1})$ and $W\\cap\\operatorname{vars}(\\alpha_{2})$ partition $W$ . Thus we have that: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigoplus_{w}p_{\\alpha}(\\mathrm{vars}(\\alpha))=\\bigoplus_{w}(p_{\\alpha_{1}}(\\mathrm{vars}(\\alpha_{1}))\\otimes p_{\\alpha_{2}}(\\mathrm{vars}(\\alpha_{2})))}\\\\ &{\\qquad\\qquad\\qquad=\\bigoplus_{w\\cap\\mathrm{vars}(\\alpha_{1})}\\bigoplus_{w\\cap\\mathrm{vars}(\\alpha_{2})}\\left(p_{\\alpha_{1}}(\\mathrm{vars}(\\alpha_{1}))\\otimes p_{\\alpha_{2}}(\\mathrm{vars}(\\alpha_{2}))\\right)}\\\\ &{\\qquad\\qquad=\\left(\\bigoplus_{w\\cap\\mathrm{vars}(\\alpha_{1})}p_{\\alpha_{1}}(\\mathrm{vars}(\\alpha_{1}))\\right)\\otimes\\left(\\bigoplus_{w\\cap\\mathrm{vars}(\\alpha_{2})}p_{\\alpha_{2}}(\\mathrm{vars}(\\alpha_{2}))\\right)}\\\\ &{\\qquad=p_{\\mathtt{A G G}(\\alpha_{1};W\\cap\\mathrm{vars}(\\alpha_{1}))}(\\mathrm{vars}(\\alpha_{1})\\mid W)\\otimes p_{\\mathtt{A G G}(\\alpha_{2};W\\cap\\mathrm{vars}(\\alpha_{2}))}(\\mathrm{vars}(\\alpha_{2})\\mid W)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The second equality follows by the partition (and associativity of the addition and multiplication), while the third follows by distributivity of multiplication over addition. In the case where vars $(\\alpha)=$ $W$ (Lines 3-4), then $p_{\\mathtt{A G G}}_{(\\alpha_{i};W\\cap\\mathrm{vars}(\\alpha_{i}))}\\big(\\mathrm{vars}(\\alpha_{i})\\big)$ is just a scalar for each $i$ , so we can directly perform this computation, returning a new scalar node $\\alpha^{\\prime}$ . Otherwise (Lines 5-6), we construct a new product node $\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\times\\alpha_{2}^{\\prime}=\\mathsf{A G G}(\\alpha_{1};W\\cap\\mathsf{v a r s}(\\alpha_{1}))\\times\\mathsf{A G G}(\\alpha_{2};W\\cap\\mathsf{v a r s}(\\alpha_{2})).$ . By the inductive hypothesis, $\\alpha_{i}^{\\prime}$ has scope var $:(\\alpha_{i}^{\\prime})=\\mathrm{vars}(\\alpha_{i})\\setminus W$ , so $\\alpha^{\\prime}$ is clearly decomposable and has scope $\\operatorname{vars}(\\alpha^{\\prime})=(\\operatorname{vars}(\\alpha_{1})\\setminus W)\\cup(\\operatorname{vars}(\\alpha_{2})\\setminus W)=\\operatorname{vars}(\\alpha)\\setminus W$ . ", "page_idx": 15}, {"type": "text", "text": "If $\\alpha=+_{i=1}^{k}\\alpha_{i}$ is a sum node, then we note that by smoothness, $\\operatorname{vars}(\\alpha_{i})=\\operatorname{vars}(\\alpha)$ for all $i$ . Thus we have that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\bigoplus_{w}p_{\\alpha}(\\mathrm{vars}(\\alpha))=\\bigoplus_{w}\\bigoplus_{i=1}^{k}p_{\\alpha_{i}}(\\mathrm{vars}(\\alpha))}\\\\ &{\\quad\\displaystyle=\\bigoplus_{i=1}^{k}\\bigoplus_{w}p_{\\alpha_{i}}(\\mathrm{vars}(\\alpha))}\\\\ &{\\quad\\displaystyle=\\bigoplus_{i=1}^{k}\\bigoplus_{w}p_{\\alpha_{i}}(\\mathrm{vars}(\\alpha_{i}))}\\\\ &{\\quad\\displaystyle=\\bigoplus_{i=1}^{k}p_{\\alpha_{i}}(\\mathrm{vars}(\\alpha_{i}))}\\\\ &{\\quad\\displaystyle=\\bigoplus_{i=1}^{k}p_{\\alpha\\cup(\\alpha_{i};W)}(\\mathrm{vars}(\\alpha_{i}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "In the case where $\\operatorname{vars}(\\alpha)\\,=\\,W$ (Lines 3-4), then $p_{\\mathtt{A G G}(\\alpha_{i};\\mathbf{W})}(\\operatorname{vars}(\\alpha_{i}))$ is just a scalar, so we can directly perform this computation, returning a new scalar node $\\alpha^{\\prime}$ . Otherwise (Lines 5-6), we construct a new sum node $\\alpha^{\\prime}\\,{\\overset{\\cdot}{=}}\\,+_{i=1}^{k}\\alpha_{i}^{\\prime}=+_{i=1}^{k}\\mathsf{\\tilde{A}G G}(\\alpha_{i};{\\pmb W})$ . By the inductive hypothesis, each $\\alpha_{i}^{\\prime}$ has scope vars $(\\alpha_{i})\\setminus W=\\operatorname{vars}(\\alpha)\\setminus W$ , so $\\alpha^{\\prime}$ is smooth and also has scope vars $(\\alpha)\\setminus W$ \uff1a\u53e3 ", "page_idx": 16}, {"type": "text", "text": "A.2 Tractable Product ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "A.2.1 Tractable Product with Compatibility ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Theorem 2 (Tractable Product - Compatibility). Let $C,C^{\\prime}$ be compatible circuits over variables $V,V^{\\prime}$ , respectively, and the same semiring. Then it is possible to compute their product as a circuit $C$ compatible with them (i.e., $p_{C^{\\prime\\prime}}(V\\cup V^{\\prime})=p_{C}(V)\\otimes p_{C^{\\prime}}(V^{\\prime}))$ in $O(|C||C^{\\prime}|)$ time and space. ", "page_idx": 16}, {"type": "text", "text": "Proof. We prove this inductively bottom up, for nodes $\\alpha\\in C,\\alpha^{\\prime}\\in C$ such that vars $\\mathbf{\\Psi}(\\alpha)\\cap(V\\cap V^{\\prime})=$ vars $\\bar{(\\alpha^{\\prime})}\\cap\\bar{(}V\\cap V^{\\prime})$ . Our claim is that $\\mathsf{P R O D-S C M P}(\\alpha,\\alpha^{\\prime})$ (Algorithm 2) returns a node $\\alpha^{\\prime\\prime}$ such that $p_{\\alpha^{\\prime\\prime}}=p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}$ , has scope vars $(\\alpha^{\\prime\\prime})=\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime})$ , and is decomposable (if product) and smooth (if sum). ", "page_idx": 16}, {"type": "text", "text": "If vars $;(\\alpha)\\cap\\operatorname{vars}(\\alpha^{\\prime})=\\emptyset$ (i.e. v $\\mathbf{ars}(\\alpha)\\cap(V\\cap V^{\\prime})=\\mathbf{vars}(\\alpha^{\\prime})\\cap(V\\cap V^{\\prime})$ is empty), then the algorithm (Lines 1-2) simply constructs a new product node $\\alpha^{\\prime\\prime}=\\alpha\\times\\alpha^{\\prime}$ . By definition, $p_{\\alpha^{\\prime\\prime}}=p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}$ , has scope vars $(\\alpha^{\\prime\\prime})^{-}{\\overset{\\cdot}{=}}\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime})$ , and $\\alpha^{\\prime\\prime}$ is decomposable. ", "page_idx": 16}, {"type": "text", "text": "If $\\alpha,\\alpha^{\\prime}$ are input nodes, then we can construct a new input node $\\alpha^{\\prime\\prime}$ satisfying the requisite properties (Lines 5-6). ", "page_idx": 16}, {"type": "text", "text": "If $\\alpha$ is an input or product node and $\\alpha^{\\prime}=+_{j=1}^{k^{\\prime}}\\alpha_{j}^{\\prime}$ is a sum node, then the algorithm constructs a new sum node $\\alpha^{\\prime\\prime}\\,=\\,+_{j\\,=\\,1}^{k^{\\prime}}\\tt P R O D-C M P(\\alpha,\\dot{\\alpha_{j}^{\\prime}})$ . This computes the correct function as $p_{\\alpha^{\\prime\\prime}}\\,=$ $\\oplus_{j=1}^{k^{\\prime}}\\left(p_{\\alpha}\\otimes p_{\\alpha_{j}^{\\prime}}\\right)=p_{\\alpha}\\otimes\\left(\\oplus_{j=1}^{k^{\\prime}}p_{\\alpha_{j}^{\\prime}}\\right)=p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}$ . Each child has scope vars $\\left(\\alpha\\right)\\cup$ vars $(\\alpha_{j}^{\\prime})=$ $\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime})$ , so smoothness is retained. ", "page_idx": 16}, {"type": "text", "text": "If $\\alpha=\\alpha_{1}\\!\\times\\!\\alpha_{2},\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\!\\times\\!\\alpha_{2}^{\\prime}$ are product nodes such that vars $(\\alpha)\\cap(V\\cap V^{\\prime})=\\operatorname{vars}(\\alpha^{\\prime})\\cap(V\\cap V^{\\prime})$ is non-empty, then writing $X:=V\\cap V^{\\prime}$ , by compatibility we also have v $\\mathrm{trs}(\\alpha_{1})\\cap X=\\mathrm{vars}(\\alpha_{1}^{\\prime})\\cap X$ and vars $(\\alpha_{2})\\cap X=\\operatorname{vars}(\\alpha_{2}^{\\prime})\\cap X$ , so we can apply the inductive hypothesis for PRO $\\mathsf{\\partial}\\mathsf{-}\\mathsf{C M P}\\big(\\alpha_{1},\\alpha_{1}^{\\prime}\\big)$ and PRO $\\mathsf{D{-}C M P}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)$ . Algorithm 2 constructs a new product node $\\alpha^{\\prime\\prime}={\\tt P R O D-C M P}(\\alpha_{1},\\alpha_{1}^{\\prime})\\stackrel{<}{\\times}$ PROD- ${\\mathrm{CMP}}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)$ . To show that this is decomposable, we need the following lemma: ", "page_idx": 16}, {"type": "text", "text": "Lemma 1 (Decomposability of Product). Suppose $\\alpha\\in C,\\alpha^{\\prime}\\in C^{\\prime}$ are decomposable product nodes which decompose in the same way over $\\mathbf{\\deltaX}$ , i.e. vars $(\\alpha_{1})\\cap X=\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap X$ and var $\\mathbf{\\dot{s}}(\\alpha_{2})\\cap\\mathbf{X}=$ $\\mathrm{vars}(\\alpha_{2}^{\\prime})\\cap\\bar{X}$ . Then ( $\\operatorname{vars}(\\alpha_{1})\\cup\\operatorname{vars}(\\alpha_{1}^{\\prime}))\\cap(\\operatorname{vars}(\\alpha_{2})\\cup\\operatorname{vars}(\\alpha_{2}^{\\prime}))={\\overline{{\\mathbb{\\left(\\right.}\\right.}}}$ . ", "page_idx": 16}, {"type": "text", "text": "Proof. We have that: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname{vars}(\\alpha_{1})\\cup\\operatorname{vars}(\\alpha_{1}^{\\prime}))\\cap(\\operatorname{vars}(\\alpha_{2})\\cup\\operatorname{vars}(\\alpha_{2}^{\\prime}))}\\\\ &{=(\\operatorname{vars}(\\alpha_{1})\\cap\\operatorname{vars}(\\alpha_{2}))\\cup(\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap\\operatorname{vars}(\\alpha_{2}^{\\prime}))\\cup(\\operatorname{vars}(\\alpha_{1})\\cap\\operatorname{vars}(\\alpha_{2}^{\\prime}))\\cup(\\operatorname{vars}(\\alpha_{2})\\cap\\operatorname{vars}(\\alpha_{1}^{\\prime}))}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Note that the first two intersections are empty due to decomposability of $\\alpha,\\alpha^{\\prime}$ . For the third intersection $\\left(\\mathrm{vars}(\\alpha_{1})\\cap\\mathrm{vars}(\\alpha_{2}^{\\prime})\\right)$ , any variable in this intersection must be in the common variables $\\mathbf{\\deltaX}$ . But we know that vars $(\\dot{\\alpha}_{2}^{\\prime})\\cap X\\,=\\,\\mathrm{vars}(\\alpha_{2})\\cap X$ in both cases above; by decomposability, $(\\operatorname{vars}(\\alpha_{2}^{\\prime})\\cap X)\\cap(\\operatorname{vars}(\\alpha_{1})\\cap\\mathbf{\\bar{X}})=\\emptyset$ . Thus the third intersection is also empty; a similar argument applies for the fourth. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Applying this Lemma, we see that $\\alpha^{\\prime\\prime}$ is decomposable as vars(PRO $\\mathbf{\\partial})\\mathbf{\\partial}-\\mathbf{CMP}\\big(\\alpha_{1},\\alpha_{1}^{\\prime}\\big)\\big)=\\left(\\mathbf{vars}(\\alpha_{1})\\cup\\mathbf{\\beta}\\right)$ vars $\\left(\\alpha_{1}^{\\prime}\\right)$ ) and vars $\\big(\\mathtt{P R O D-C M P}(\\alpha_{2},\\alpha_{2}^{\\prime})\\big)\\,=\\,\\big(\\mathtt{v a r s}(\\alpha_{2})\\cup\\mathtt{v a r s}(\\alpha_{2}^{\\prime})\\big)$ . We can also verify that $p_{\\alpha^{\\prime\\prime}}=$ $p_{\\mathtt{P R O D-C M P}(\\alpha_{1},\\alpha_{1}^{\\prime})}\\otimes p_{\\mathtt{P R O D-C M P}(\\alpha_{2},\\alpha_{2}^{\\prime})}=p_{\\alpha_{1}}\\otimes p_{\\alpha_{1}^{\\prime}}\\otimes p_{\\alpha_{2}}\\otimes p_{\\alpha_{2}^{\\prime}}=p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}$ by the inductive hypothesis, and associativity of $\\otimes$ . ", "page_idx": 17}, {"type": "text", "text": "If $\\alpha\\;=\\;+_{i=1}^{k}\\alpha_{i}$ , $\\alpha^{\\prime}\\;=\\;+_{i=1}^{k^{\\prime}}\\alpha_{i}^{\\prime}$ are sum nodes, then the algorithm produces a new sum node $\\alpha^{\\prime\\prime}\\,=\\,+_{i=1}^{k}\\,+_{j=1}^{k^{\\prime}}$ $\\mathsf{P R O D-C M P}\\big(\\alpha_{i},\\alpha_{j}^{\\prime}\\big)$ (Lines 7-8). This computes the correct function as $p_{\\alpha^{\\prime\\prime}}=$ $\\begin{array}{r}{\\bigoplus_{i=1}^{k}\\bigoplus_{j=1}^{k^{\\prime}}\\mathrm{PROD}-\\mathrm{CMP}(\\alpha_{i},\\alpha_{j}^{\\prime})=\\bigoplus_{i=1}^{k}\\bigoplus_{j=1}^{k^{\\prime}}p_{\\alpha_{i}}p_{\\alpha_{j}^{\\prime}}=\\left(\\bigoplus_{i=1}^{k}p_{\\alpha_{i}}\\right)\\otimes\\left(\\bigoplus_{j=1}^{k^{\\prime}}p_{\\alpha_{j}^{\\prime}}\\right)=p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}.}\\end{array}$ It also retains smoothness. ", "page_idx": 17}, {"type": "text", "text": "The complexity of this algorithm is $O(|C||C^{\\prime}|)$ because we perform recursive calls for pairs of nodes in $C$ and $C^{\\prime}$ . \u53e3 ", "page_idx": 17}, {"type": "text", "text": "A.2.2 Linear-time Product with Support Comptibility ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Theorem 3 (Tractable Product - Support Compatibility). Let $C,C^{\\prime}$ be support-compatible circuits over variables $V,V^{\\prime}$ , respectively, and the same semiring. Then, given the isomorphism $\\iota$ , it is possible to compute their product as a smooth and decomposable circuit $C^{\\prime\\prime}$ support-compatible with them (i.e., $p_{C^{\\prime\\prime}}\\bar{(}V\\cup V^{\\prime})\\stackrel{}{=}p_{C}(V)\\otimes p_{C^{\\prime}}(V^{\\prime}))$ in $O(\\operatorname*{max}(|C|,|C^{\\prime}|))$ time and space. ", "page_idx": 17}, {"type": "text", "text": "Proof. We prove this inductively bottom up, for nodes $\\alpha\\,\\in\\,C$ such that $\\alpha^{\\prime}\\in C$ either satisfies $\\alpha^{\\prime}=\\iota(\\alpha)$ or $\\operatorname{vars}(\\alpha)\\cap\\operatorname{vars}(\\alpha^{\\prime})\\stackrel{\\cdot}{=}\\varnothing$ . Our claim is that PROD-SCMP $(\\alpha,\\alpha^{\\prime})$ (Algorithm 3) returns a node $\\alpha^{\\prime\\prime}$ such that $p_{\\alpha^{\\prime\\prime}}=p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}$ , has scope $\\operatorname{vars}(\\alpha^{\\prime\\prime})=\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime})$ , and is decomposable (if product) and smooth (if sum). ", "page_idx": 17}, {"type": "text", "text": "If $\\operatorname{vars}(\\alpha)\\cap\\operatorname{vars}(\\alpha^{\\prime})\\,=\\,\\emptyset$ , then the algorithm (Lines 1-2) simply constructs a new product node $\\alpha^{\\prime\\prime}=\\dot{\\alpha}\\stackrel{\\cdot}{\\times}\\alpha^{\\prime}$ . By definition, $p_{\\alpha^{\\prime\\prime}}=p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}$ , has scope vars $(\\bar{\\alpha^{\\prime\\prime}})=\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\bar{\\alpha^{\\prime}})$ , and $\\alpha^{\\prime\\prime}$ is decomposable. ", "page_idx": 17}, {"type": "text", "text": "If the $\\alpha,\\alpha^{\\prime}$ are input nodes, then we can construct a new input node $\\alpha^{\\prime\\prime}$ satisfying the requisite properties (Lines 3-4). ", "page_idx": 17}, {"type": "text", "text": "If $\\alpha=\\alpha_{1}\\times\\alpha_{2},\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\times\\alpha_{2}^{\\prime}$ are product nodes and $\\iota(\\alpha)=\\alpha^{\\prime}$ , then the Algorithm (Lines 5-6) constructs a product node $\\alpha^{\\prime\\prime}\\overset{-}{=}{\\tt P R O D-S C M P}(\\alpha_{1},\\alpha_{1}^{\\prime})\\times{\\tt P R O D-S C M P}(\\alpha_{2},\\alpha_{2}^{\\prime})$ . Define $X=V\\cup V^{\\prime}$ . By support compatibility (i.e. $\\mathbf{\\deltaX}$ -support compatibility), $\\alpha,\\alpha^{\\prime}$ are part of the restricted circuits $\\dot{C}[X],\\dot{C}^{\\prime}[X]$ respectively and so $\\mathrm{vars}(\\alpha)\\cap\\bar{\\mathbf{X}}\\,\\neq\\,\\emptyset$ , $\\operatorname{vars}(\\alpha^{\\prime})\\cap{\\pmb X}\\,\\neq\\,\\emptyset$ . There are two cases to consider; we first show that in both of these cases, we can apply the inductive hypothesis to $\\mathsf{\\Delta A O D{-}S C M P}\\big(\\alpha_{1},\\alpha_{1}^{\\prime}\\big)$ and PRO $\\mathsf{\\Gamma}\\mathsf{1}\\!-\\!\\mathsf{S C M P}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)$ . ", "page_idx": 17}, {"type": "text", "text": "\u2022 Firstly, suppose that both $\\alpha_{1}$ and $\\alpha_{2}$ have scope overlapping with $\\mathbf{\\deltaX}$ . Then by the isomorphism, we have $\\alpha_{1}^{\\prime}=\\iota(\\alpha_{1})$ , $\\alpha_{2}^{\\prime}=\\iota(\\alpha_{2})$ . By the definition of support compatibility, this also means vars $(\\alpha_{1})\\cap X=\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap X$ and $\\operatorname{vars}(\\alpha_{2})\\cap X=\\operatorname{vars}(\\alpha_{2}^{\\prime})\\cap X$ and these are both non-empty; thus we can apply the inductive hypothesis for PROD- $-\\mathsf{S C M P}\\big(\\alpha_{1},\\alpha_{1}^{\\prime}\\big)$ and PROD- $\\mathbf{\\nabla}\\cdot\\mathbf{SCMP}(\\alpha_{2},\\alpha_{2}^{\\prime})$ . \u2022 Second, suppose instead that only $\\alpha_{1}$ has scope overlapping with $\\mathbf{\\deltaX}$ , and so va $\\operatorname{rs}(\\alpha_{2})\\cap X=$ $\\varnothing$ . Then $\\alpha_{1}^{\\prime}=\\iota(\\alpha_{1})$ and va $\\operatorname{rs}(\\alpha_{1})\\cap X=\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap X=\\operatorname{vars}(\\alpha)\\cap X=\\operatorname{vars}(\\alpha^{\\prime})\\cap X.$ . Since vars $(\\alpha_{2}^{\\prime})=\\operatorname{vars}(\\alpha^{\\prime})\\setminus\\operatorname{vars}(\\alpha_{1}^{\\prime})$ , it follows that vars $(\\alpha_{2})\\cap X=(\\operatorname{vars}(\\alpha^{\\prime})\\cap X)\\mid$ $\\left(\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap{\\bar{\\mathbf{X}}}\\right)=\\varnothing$ , i.e. $\\alpha_{2}^{\\prime}$ also does not have scope overlapping with $\\mathbf{\\deltaX}$ . Since $\\mathbf{\\deltaX}$ are the shared variables $V$ , $V^{\\prime}$ , it follows that var $;(\\alpha_{2})\\cap\\operatorname{vars}(\\alpha_{2}^{\\prime})=\\emptyset$ , and so we can apply the inductive hypothesis for $\\mathsf{P R O D-S C M P}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)$ (and for $\\mathsf{P R O D-S C M P}\\big(\\alpha_{1},\\alpha_{1}^{\\prime}\\big))$ . ", "page_idx": 17}, {"type": "text", "text": "By the inductive hypothesis, PROD- $\\mathrm{SCMP}(\\alpha_{1},\\alpha_{1}^{\\prime})$ has scope $\\mathrm{vars}(\\alpha_{1})\\ \\cup\\ \\mathrm{vars}(\\alpha_{1}^{\\prime})$ and $\\mathsf{P R O D-S C M P}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)$ has scope $\\operatorname{vars}(\\alpha_{2})\\cup\\operatorname{vars}(\\alpha_{2}^{\\prime}).$ We can thus apply Lemma 1. Thus $\\mathtt{P R O D-S C M P}(\\alpha_{1},\\alpha_{1}^{\\bar{\\prime}})$ and $\\mathsf{P R O D-S C M P}\\big(\\alpha_{2},\\alpha_{2}^{\\prime}\\big)$ have disjoint scopes and $\\alpha^{\\prime\\prime}$ is decomposable. We can also verify that p $\\begin{array}{r}{\\alpha^{\\prime\\prime}=\\!p_{\\mathtt{P R O D}-\\mathtt{S C M P}(\\alpha_{1},\\alpha_{1}^{\\prime}),\\bigotimes}\\mathcal{D}\\mathtt{p}_{\\mathtt{P R O D}-\\mathtt{S C M P}(\\alpha_{2},\\alpha_{2}^{\\prime})}=p_{\\alpha_{1}}\\otimes}\\end{array}$ p\u03b1\u20321 \u2297p\u03b12 \u2297p\u03b1\u20322 = p\u03b1 \u2297p\u03b1\u2032 by the inductive hypothesis, and associativity of $\\otimes$ . ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "text", "text": "If $\\alpha=+_{i=1}^{k}\\alpha_{i}$ , $\\alpha^{\\prime}=+_{i=1}^{k^{\\prime}}\\alpha_{i}^{\\prime}$ are sum nodes and $\\iota(\\alpha)=\\alpha^{\\prime}$ , then by smoothness, all of the children of $\\alpha$ have the same support and all the children of $\\alpha^{\\prime}$ have the same support; thus all the children are in $C[X],C^{\\prime}[X]$ respectively, $k=k^{\\prime}$ , and $\\iota(\\alpha_{i})=\\alpha_{i}^{\\prime}$ . By support compatibility, we also that (i) $\\mathrm{vars}(\\alpha_{i})\\cap\\mathbf{\\dot{X}}=\\mathrm{vars}(\\alpha_{j}^{\\prime})\\cap X$ for all $i,j$ ; and (ii) that $\\mathrm{supp}_{X}(\\alpha_{i})\\cap\\mathrm{supp}_{X}(\\alpha_{j}^{\\prime})$ for $i\\neq j$ . ", "page_idx": 18}, {"type": "text", "text": "We claim that $p_{\\alpha_{i}}\\otimes p_{\\alpha_{j}^{\\prime}}\\equiv0_{S}$ whenever $i\\neq j$ . To see this, recall the definition of $\\mathbf{\\deltaX}$ -support: we have that: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\operatorname*{supp}_{X}(\\alpha_{i})=\\{x\\in\\mathrm{Assign}(X\\cap\\mathrm{vars}(\\alpha_{i})):\\exists y\\in\\mathrm{Assign}(\\mathrm{vars}(\\alpha_{i})\\setminus X)\\;\\mathrm{s}}\\\\ {\\operatorname*{supp}_{X}(\\alpha_{j}^{\\prime})=\\{x\\in\\mathrm{Assign}(X\\cap\\mathrm{vars}(\\alpha_{j}^{\\prime})):\\exists y\\in\\mathrm{Assign}(\\mathrm{vars}(\\alpha_{j}^{\\prime})\\setminus X)\\;\\mathrm{s}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Since $X\\cap\\operatorname{vars}(\\alpha_{i})=X\\cap\\operatorname{vars}(\\alpha_{j}^{\\prime})$ and is nonempty, by (ii) we know that there is no assignment of ${\\cal X}\\cap\\operatorname{vars}(\\alpha_{i})$ such that $p_{\\alpha_{i}}$ and $p_{\\alpha_{j}^{\\prime}}$ can be simultaneously not equal to $0_{S}$ . Thus there is no assignment of $X\\cap\\operatorname{vars}(\\alpha_{i})$ such that $p_{\\alpha_{i}}\\otimes p_{\\alpha_{j}^{\\prime}}$ is not $0_{S}$ , since $0_{S}$ is the multiplicative annihilator. ", "page_idx": 18}, {"type": "text", "text": "Thus, the product function is given by: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{c l}{{p_{\\alpha}\\otimes p_{\\alpha^{\\prime}}=\\displaystyle\\bigoplus_{i=1}^{k}{\\displaystyle\\bigoplus_{j=1}^{k}(p_{\\alpha_{i}}\\otimes p_{\\alpha_{j}^{\\prime}})}}}\\\\ {{{}}}\\\\ {{{}=\\displaystyle\\bigoplus_{i=1}^{k}{(p_{\\alpha_{i}}\\otimes p_{\\alpha_{i}^{\\prime}})}}}\\\\ {{{}=\\displaystyle\\bigoplus_{i=1}^{k}{\\mathrm{PROD-SCMP}(\\alpha_{i},\\alpha_{i}^{\\prime})}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The second equality follows by the Lemma and the fact that $0_{S}$ is the additive identity, and the third equality by the inductive hypothesis. Thus $\\alpha^{\\prime\\prime}\\,=\\,+_{i=1}^{k}\\mathtt{P R O D-S C M P}(\\alpha_{i},\\alpha_{i}^{\\prime})$ computes the correct function (Lines 7-8). We conclude by noting that var $\\begin{array}{r}{\\mathrm{s}(\\alpha^{\\prime\\prime})=\\bigcup_{i=1}^{k}(\\mathrm{vars}(\\alpha_{i})\\cup\\mathrm{vars}(\\alpha_{i}))=}\\end{array}$ $\\textstyle\\bigcup_{i=1}^{k}\\operatorname{vars}(\\alpha_{i})\\cup\\bigcup_{i=1}^{k}\\operatorname{vars}(\\alpha_{i})=\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime}).$ ", "page_idx": 18}, {"type": "text", "text": "The complexity of this procedure applied to the root nodes is $O(\\operatorname*{max}(|C|,|C^{\\prime}|)$ , as we only perform recursive calls for (i) $\\alpha\\,\\in\\,C[X]$ and its corresponding node $\\alpha^{\\prime}=\\iota(\\alpha)$ and (ii) nodes with nonoverlapping scope, upon which the recursion ends; so the overall number of recursive calls is linear in the size of the circuits. ", "page_idx": 18}, {"type": "text", "text": "A.3 Tractable Elementwise Mapping ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Theorem 4 (Tractable Mapping). Let $C$ be a smooth and decomposable circuit over semiring $\\mathcal{S}$ , and $\\tau:S\\rightarrow S^{\\prime}$ a mapping such that $\\tau(0_{\\cal S})=0_{\\cal S^{\\prime}}$ . Then it is possible to compute the mapping of $C$ by $\\tau$ as a smooth and decomposable circuit $C^{\\prime}$ (i.e., $p_{C^{\\prime}}(V)\\stackrel{{}=}{=}\\tau(p_{C}(V)))$ in $O(|C|)$ time and space if $\\tau$ distributes over sums and over products. ", "page_idx": 18}, {"type": "text", "text": "$\\tau$ distributes over sums $i f$ : either (Additive) $\\tau$ is an additive homomorphism, i.e. $\\tau(a\\oplus b)\\;=\\;$   \n$\\tau(a)\\oplus\\tau(b)$ ; or (Det) $C$ is deterministic. ", "page_idx": 18}, {"type": "text", "text": "$\\tau$ distributes over products $i f$ : either (Multiplicative) $\\tau$ is an multiplicative homomorphism, i.e. $\\tau(a\\!\\otimes\\!b)=\\tau(a)\\otimes\\bar{\\tau}(b),$ ; or (Prod 0/1) $\\tau(1_{\\mathcal{S}})=1_{\\mathcal{S}^{\\prime}}$ , and for all product nodes $\\alpha=\\alpha_{1}\\times\\alpha_{2}\\in C$ , and for every value $\\pmb{v}\\in A s s i g n(\\operatorname{vars}(\\alpha))$ , either $p_{\\alpha_{1}}(\\pmb{v}_{\\mathrm{vars}(\\alpha_{1})})\\in\\{0_{S},1_{S}\\}$ or $p_{\\alpha_{2}}(\\pmb{v}_{\\mathrm{vars}(\\alpha_{2})})\\in\\{0_{S},1_{S}\\}$ . ", "page_idx": 18}, {"type": "text", "text": "Proof. First, let us consider sum nodes. Given any sum node $\\alpha\\,=\\,+_{i=1}^{k}\\alpha_{i}\\,\\in\\,C$ , we consider computing a circuit representing ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\tau{\\big(}p_{\\alpha}(\\operatorname{vars}(\\alpha)){\\big)}\\equiv\\tau{\\Big(}\\bigoplus_{i=1}^{k}p_{\\alpha_{i}}(\\operatorname{vars}(\\alpha)){\\Big)}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "If (Additive) holds, then we immediately have that $\\begin{array}{r}{\\tau\\big(\\bigoplus_{i=1}^{k}p_{\\alpha_{i}}(\\mathrm{vars}(\\alpha))\\big)\\equiv\\bigoplus_{i=1}^{k}\\tau\\big(p_{\\alpha_{i}}(\\mathrm{vars}(\\alpha))\\big)}\\end{array}$ by associativity of $\\oplus$ . Alternatively, if (Det) holds, then given any $\\pmb{v}\\in\\mathrm{Assign}((\\operatorname{vars}(\\alpha)))$ , there is at most one child, say $\\alpha_{j}$ , such that $p_{\\alpha_{j}}(\\pmb{v})\\neq0_{S}$ . Then we have that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{r(\\widetilde{\\alpha}_{i-1}^{k}p_{\\alpha_{i}}(v))=\\tau\\left(\\mathbb{R}_{p_{i}}(v)\\otimes\\Big(\\displaystyle\\frac{\\dot{\\mathbb{Q}}}{\\prod_{i=1}^{N}\\mathcal{M}_{p_{i}}}(v)\\Big)\\right)}&{}\\\\ {=\\tau\\left(p_{\\alpha_{i}}(v)\\otimes\\Big(\\displaystyle\\frac{\\dot{\\mathbb{Q}}}{\\prod_{i=1,\\ell}^{N}\\mathbb{I}_{p_{i}}}\\Big)\\otimes_{\\ell_{i}}\\right)}&{}\\\\ {=\\tau(p_{\\alpha_{i}}(v))}&{}\\\\ {=\\tau(p_{\\alpha_{i}}(v))\\otimes\\Big(\\displaystyle\\frac{\\dot{\\mathbb{Q}}}{\\prod_{i=1,\\ell}^{N}\\mathbb{I}_{p_{i}}}\\Big)}&{}\\\\ {=\\tau(p_{\\alpha_{i}}(v))\\otimes\\Big(\\displaystyle\\frac{\\dot{\\mathbb{Q}}}{\\prod_{i=1,\\ell}^{N}\\mathbb{I}_{p_{i}}}\\Big)}&{}\\\\ {=\\tau(p_{\\alpha_{i}}(v))\\otimes\\Big(\\displaystyle\\frac{\\dot{\\mathbb{Q}}}{\\prod_{i=1,\\ell}^{N}\\mathbb{I}_{p_{i}}}\\Big)}&{}\\\\ {=\\tau(p_{\\alpha_{i}}(v))\\otimes\\Big(\\displaystyle\\frac{\\dot{\\mathbb{Q}}}{\\prod_{i=1,\\ell}^{N}\\mathbb{I}_{p_{i}}}\\Big)}&{}\\\\ {=\\frac{\\dot{\\mathbb{Q}}}{\\bigoplus}\\tau(p_{\\alpha_{i}}(v))}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and so again $\\tau\\Big(\\bigoplus_{i=1}^{k}p_{\\alpha_{i}}(\\pmb{v})\\Big)\\equiv\\bigoplus_{i=1}^{k}\\tau(p_{\\alpha_{i}}(\\pmb{v})).$ ", "page_idx": 19}, {"type": "text", "text": "Second, let us consider product nodes. If (Multiplicative) holds, then we immediately have that $\\tau\\Big(\\bigotimes_{i=1}^{k}p_{\\alpha_{i}}(\\operatorname{vars}(\\alpha))\\Big)\\stackrel{-}{\\equiv}\\bigotimes_{i=1}^{k}\\tau\\big(p_{\\alpha_{i}}(\\operatorname{vars}(\\alpha))\\big)$ by associativity of $\\otimes$ . Otherwise, if $\\left(\\mathrm{Prod}\\;0/1\\right)$ ) holds, then given any $\\pmb{v}\\in\\mathrm{Assign}(\\mathrm{vars}(\\alpha))$ , there is at most one child, say $\\alpha_{j}$ , such that $p_{\\alpha_{j}}(\\pmb{v})\\not\\in$ $\\{0_{S},1_{S}\\}$ . Thus, we have that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\tau\\Big(\\displaystyle\\big(\\dot{\\bigotimes}p_{\\alpha_{i}}(v)\\big)=\\tau\\Big(p_{\\alpha_{j}}(v)\\otimes\\Big(\\displaystyle\\bigotimes\\bigotimes_{i=1,i\\neq j}^{k}p_{\\alpha_{i}}(v)\\Big)\\Big)}\\\\ &{=\\tau\\big(p_{\\alpha_{j}}(v)\\big)\\otimes\\tau\\Big(\\displaystyle\\bigotimes_{i=1,i\\neq j}^{k}p_{\\alpha_{i}}(v)\\Big)}\\\\ &{=\\tau\\big(p_{\\alpha_{j}}(v)\\big)\\otimes\\Big(\\displaystyle\\bigwedge_{i=1,i\\neq j}^{k}\\tau(p_{\\alpha_{i}}(v)\\Big)}\\\\ &{=\\displaystyle\\bigotimes_{i=1}^{k}\\tau(p_{\\alpha_{i}}(v))}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The second equality follows because $\\left(\\bigotimes_{i=1,i\\neq j}^{k}p_{\\alpha_{i}}(\\pmb{v})\\right)\\in\\{0_{S},1_{S}\\}$ , and we have that $\\tau(a\\!\\otimes\\!0_{\\cal S})=$ $0_{S^{\\prime}}=\\tau(a)\\otimes\\tau(0_{S})$ and $\\tau(a\\otimes1_{S})=1_{S^{\\prime}}=\\tau(a)\\otimes\\tau(1_{S})$ for any $a\\in S$ . The third equality follows as both $\\tau\\Big(\\bigotimes_{i=1,i\\neq j}^{k}p_{\\alpha_{i}}(\\pmb{v})\\Big)$ and $\\otimes_{i=1,i\\neq j}^{k}\\tau(p_{\\alpha_{i}}(\\pmb{v}))$ are equal to $1_{S^{\\prime}}$ iff no $p_{\\alpha_{i}}(\\pmb{v})$ is $0_{S}$ . Thus, we have that $\\tau\\Big(\\bigotimes_{i=1}^{k}p_{\\alpha_{i}}(\\pmb{v})\\Big)\\equiv\\bigotimes_{i=1}^{k}\\tau\\big(p_{\\alpha_{i}}(\\pmb{v})\\big).$ . ", "page_idx": 19}, {"type": "text", "text": "By applying these identities recursively to sum and product nodes, and assuming that $\\tau$ can be applied tractably to input nodes, we obtain a circuit $C^{\\prime}$ such that $p_{C^{\\prime}}(V)\\equiv\\tau(p_{C}(V))$ . \u53e3 ", "page_idx": 19}, {"type": "text", "text": "A.4 Tractable Composition of operators ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Theorem 5 (Composability Conditions). The results in Table 1 hold. ", "page_idx": 19}, {"type": "table", "img_path": "mXlR1FLFDc/tmp/f4d50dc866a5ec6fd85ab3bd0b240dcb8988092684a4614427356c57a25b5b02.jpg", "table_caption": [], "table_footnote": ["Table 3: Tractability Conditions for Operations on Algebraic Circuits. Sm: Smoothness, Dec: Decomposability; $\\mathbf{\\deltaX}$ -Det(erminism), $\\mathbf{\\deltaX}$ -Cmp: $\\mathbf{\\deltaX}$ -Compatibility, $\\mathbf{\\deltaX}$ -SCmp: $\\mathbf{\\deltaX}$ -Support-Compatibility. "], "page_idx": 20}, {"type": "text", "text": "Proof. We look at each property in turn, and show that they are maintained under the aggregation, product, and mapping operators as stated in the Table. For convenience, we reproduce the table in Table 3, with each result highlighted with a number that is referenced in the proof below. ", "page_idx": 20}, {"type": "text", "text": "X-determinism Suppose that circuit $C$ is $\\mathbf{\\deltaX}$ -deterministic; that is, for any sum node $\\alpha=+_{i=1}^{k}\\alpha_{i}\\in$ $C$ , either (i) $\\operatorname{vars}(\\alpha)\\,{\\overset{...}{\\cap}}\\,X=\\emptyset.$ , or else (ii) $\\operatorname{supp}_{X}(\\alpha_{i})\\cap\\operatorname{supp}_{X}(\\alpha_{j})=\\emptyset$ for all $i\\neq j$ . ", "page_idx": 20}, {"type": "text", "text": "(5.1) Consider aggregating with respect to a set of variables $W$ such that $W\\cap X=\\emptyset$ . According to Algorithm 1 and the proof of Theorem 1, this produces an output circuit where each node $\\alpha^{\\prime}$ corresponds to some node $\\alpha$ in the original circuit, such that $\\begin{array}{r}{p_{\\alpha^{\\prime}}=\\bigoplus_{w\\cap\\mathrm{vars}(\\alpha)}p_{\\alpha}}\\end{array}$ and with scope $\\operatorname{vars}(\\alpha)\\setminus W$ . In particular, for sum nodes $\\alpha=+_{i=1}^{k}\\alpha_{i}\\in C$ , either va $\\operatorname{rs}(\\alpha)\\subseteq W$ , in which case $\\alpha^{\\prime}$ is an input node (and $\\mathbf{\\deltaX}$ -determinism is not applicable), or else $\\alpha^{\\prime}=+_{i=1}^{k}\\alpha_{i}^{\\prime}$ is also a sum node, where each $\\alpha_{i}^{\\prime}$ corresponds to $\\alpha_{i}$ . If (i) $\\operatorname{vars}(\\alpha)\\cap\\mathbf{\\bar{X}}=\\varnothing$ , then vars $\\mathbf{\\partial};(\\alpha^{\\prime})\\cap\\mathbf{X}=\\emptyset$ also. ", "page_idx": 20}, {"type": "text", "text": "If (ii) $\\operatorname{supp}_{X}(\\alpha_{i})\\cap\\operatorname{supp}_{X}(\\alpha_{j})\\,=\\,\\emptyset$ for all $i\\ne j$ , we claim that $\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})\\;\\subseteq\\;\\mathrm{supp}_{X}(\\alpha_{i})$ for all $i$ . To see this, first note that by smoothness, $\\mathrm{vars}(\\alpha_{i}^{\\prime})\\,=\\,\\mathrm{vars}(\\alpha_{j}^{\\prime})\\,\\stackrel{\\_}{=}\\,\\mathrm{vars}(\\alpha^{\\prime})$ . Suppose that $\\pmb{x}_{i}\\in\\operatorname{Assign}(\\pmb{X}\\cap\\operatorname{vars}(\\alpha^{\\prime}))$ satisfies $\\pmb{x}\\in\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})$ . Then there exists $y_{i}\\in\\mathrm{Assign}(\\operatorname{vars}(\\alpha^{\\prime})\\setminus X)$ such that $p_{\\alpha_{i}^{\\prime}}(\\pmb{x}_{i},\\pmb{y}_{i})\\neq0_{S}$ . Since $\\alpha_{i}^{\\prime}$ corresponds to $\\alpha_{i}$ in the original circuit, we have: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\bigoplus_{\\pmb{w}\\in\\mathrm{Assign}(\\pmb{W})\\cap\\mathrm{vars}(\\alpha)}p_{\\alpha_{i}}(\\pmb{x}_{i},\\pmb{y}_{i},\\pmb{w}_{i})=p_{\\alpha_{i}^{\\prime}}(\\pmb{x},\\pmb{y})\\neq0_{S}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "This means that there must be some $\\pmb{w}_{i}\\,\\in\\,\\mathrm{Assign}(\\pmb{W})\\cap\\mathrm{vars}(\\alpha)$ such that $p_{\\alpha_{i}}(\\pmb{x},\\pmb{y}_{i},\\pmb{w}_{i})\\neq0_{S}$ (since $0_{S}$ is the additive identity); thus $\\pmb{x}\\in\\mathrm{supp}_{X}(\\alpha_{i})$ . To finish the proof, note that $\\operatorname{supp}_{X}(\\alpha_{i}^{\\prime})\\subseteq$ $\\operatorname{supp}_{X}(\\alpha_{i})$ and $\\mathrm{supp}_{X}(\\alpha_{l}^{\\prime})\\,\\subseteq\\,\\mathrm{supp}_{X}(\\alpha_{l})$ are disjoint unless $i=l$ (by $\\mathbf{\\deltaX}$ -determinism of $\\alpha$ , i.e. $\\operatorname{supp}_{X}(\\alpha_{i})\\cap\\operatorname{supp}_{X}(\\alpha_{l})=\\emptyset$ unless $i=l,$ ). Thus (ii) holds for $\\alpha^{\\prime}$ . In either case, we have shown that $\\alpha^{\\prime}$ is also $\\mathbf{\\deltaX}$ -deterministic. ", "page_idx": 20}, {"type": "text", "text": "(5.2) Consider taking the product of two compatible circuits $C,C^{\\prime}$ over variables $V,V^{\\prime}$ , outputting a circuit $C^{\\prime\\prime}$ . According to Algorithm 2 and the proof of Theorem 2, every sum node $\\alpha^{\\prime\\prime}\\bar{\\in}$ $C^{\\prime\\prime}$ corresponds to either the product of (a) an input or product node $\\alpha\\,\\in\\,C$ and a sum node $\\alpha^{\\prime}\\,=\\,+_{j=1}^{k^{\\prime}}\\alpha_{j}^{\\prime}\\,\\in\\,C^{\\prime}$ , such that $\\alpha^{\\prime\\prime}\\,=\\,+_{j=1}^{k^{\\prime}}\\alpha_{j}^{\\prime\\prime}$ or (b) two sum nodes $\\alpha\\;=\\;+_{i=1}^{k}\\alpha_{i}\\;\\in\\;C$ and $\\alpha^{\\prime}=+_{j=1}^{k^{\\prime}}\\alpha_{j}^{\\prime}\\in C^{\\prime}$ , such that $\\alpha^{\\prime\\prime}=+_{i=1}^{k}+_{j=1}^{k^{\\prime}}\\alpha_{i j}^{\\prime\\prime}$ . Further, $\\alpha$ and $\\alpha^{\\prime}$ have the same scope over the common variables $V\\cap V^{\\prime}$ , i.e. var $\\mathsf{s}(\\alpha)\\cap(\\bar{V}\\cap\\bar{V^{\\prime}})=\\mathrm{vars}(\\alpha^{\\prime})\\cap(V\\cap V^{\\prime})$ . ", "page_idx": 20}, {"type": "text", "text": "Assume that $C$ and $C^{\\prime}$ are both $\\mathbf{\\deltaX}$ -deterministic; then $X\\subseteq V\\cap V^{\\prime}$ . We note that since $\\alpha,\\alpha^{\\prime}$ have the same scope over the common variables, they also have the same scope over $\\mathbf{\\deltaX}$ , i.e. vars $(\\alpha)\\cap\\mathbf{X}=$ $\\operatorname{vars}(\\alpha^{\\prime})\\cap X$ . ", "page_idx": 20}, {"type": "text", "text": "In case (a), $\\mathbf{\\deltaX}$ -determinism of $\\alpha^{\\prime}$ means that either (i) $\\operatorname{vars}(\\alpha^{\\prime})\\cap X\\,=\\,\\emptyset$ or (ii) $\\operatorname{supp}_{X}(\\alpha_{i}^{\\prime})\\cap$ $\\operatorname{supp}_{X}(\\alpha_{j}^{\\prime})=\\emptyset$ for all $i\\neq j$ . If (i), then var $\\mathbf{s}(\\alpha^{\\prime\\prime})\\cap\\pmb{X}=(\\mathrm{vars}(\\alpha)\\cup\\mathrm{vars}(\\alpha^{\\prime}))\\cap\\pmb{X}=\\emptyset$ also. If (ii), note that $\\mathrm{supp}_{X}(\\alpha_{j}^{\\prime\\prime})\\subseteq\\mathrm{supp}_{X}(\\alpha_{j}^{\\prime})$ for all $j$ as $a\\otimes0_{\\cal S}=0_{\\cal S}$ for any semiring $\\boldsymbol{S}$ and $a\\in S$ . Thus $\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime\\prime})\\cap\\mathrm{supp}_{X}(\\alpha_{j}^{\\prime\\prime})=\\emptyset$ for all $i\\neq j$ . Thus $\\alpha^{\\prime\\prime}$ is $\\mathbf{\\deltaX}$ -deterministic. ", "page_idx": 20}, {"type": "text", "text": "In case (b), since $\\alpha,\\alpha^{\\prime}$ have the same scope over $\\mathbf{\\deltaX}$ , either (i) holds for both $\\alpha,\\alpha^{\\prime}$ , or (ii) holds for both. If (i), then $\\operatorname{vars}(\\alpha^{\\prime\\prime})\\cap X=(\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime}))\\cap X=\\emptyset$ also. If (ii), then for any $i,j$ , consider the restricted support $\\mathrm{supp}_{X}(\\alpha_{i j}^{\\prime\\prime})$ . Noting that var $;(\\alpha_{i})\\cap{\\pmb X}=\\operatorname{vars}(\\alpha_{j}^{\\prime})\\cap{\\pmb X}=\\operatorname{vars}(\\alpha_{i j}^{\\prime\\prime})\\cap$ $\\mathbf{\\deltaX}$ by smoothness, we claim that $\\mathsf{s u p p}_{X}(\\alpha_{i j}^{\\prime\\prime})\\;\\subseteq\\;\\mathsf{s u p p}_{X}(\\alpha_{i})\\cap\\mathsf{s u p p}_{X}(\\alpha_{j}^{\\prime})$ . Suppose that $_x\\in$ $\\mathrm{supp}_{X}(\\alpha_{i j}^{\\prime\\prime})$ . Then there exists some $y\\in\\mathrm{vars}(\\alpha_{i j}^{\\prime\\prime})\\backslash X$ such that $p_{\\alpha_{i j}^{\\prime\\prime}}({\\pmb x},{\\pmb y})=p_{\\alpha_{i}}({\\pmb x},{\\pmb y}_{\\mathrm{vars}(\\alpha_{i}))\\backslash{\\pmb X}})\\otimes$ $p_{\\alpha_{j}^{\\prime}}(\\pmb{x},\\pmb{y}_{\\mathrm{vars}(\\alpha_{j}^{\\prime})\\setminus\\pmb{X}})\\neq0_{S}$ . This means that both $p_{\\alpha_{i}}(\\pmb{x},\\pmb{y}_{\\mathrm{vars}(\\alpha_{i}))\\setminus\\pmb{X}}),p_{\\alpha_{j}^{\\prime}}(\\pmb{x},\\pmb{y}_{\\mathrm{vars}(\\alpha_{j}^{\\prime})\\setminus\\pmb{X}})$ cannot be $0_{S}$ , and so $\\pmb{x}\\in\\mathrm{supp}_{X}(\\alpha_{i})$ and $\\pmb{x}\\in\\mathrm{supp}_{X}(\\alpha_{j}^{\\prime})$ also. To finish the proof, we note that $\\mathrm{supp}_{X}(\\alpha_{i j}^{\\prime\\prime})\\subseteq$ $\\mathrm{supp}_{X}(\\alpha_{i})\\cap\\mathrm{supp}_{X}(\\alpha_{j}^{\\prime})$ and $\\mathrm{supp}_{x}(\\alpha_{l m}^{\\prime\\prime})\\subseteq\\mathrm{supp}_{X}(\\alpha_{l})\\cap\\mathrm{supp}_{X}(\\alpha_{m}^{\\prime})$ are disjoint unless $i=l,j=$ $m$ (by $\\mathbf{\\deltaX}$ -determinism of $\\alpha$ and $\\alpha^{\\prime}$ ). Thus $\\alpha^{\\prime\\prime}$ is $\\mathbf{\\deltaX}$ -deterministic by (ii). ", "page_idx": 20}, {"type": "text", "text": "", "page_idx": 21}, {"type": "text", "text": "(5.3) Consider taking the product of two support-compatible circuits $C,C^{\\prime}$ over variables $V,V^{\\prime}$ , outputting a circuit $C^{\\prime\\prime}$ . According to Algorithm 3 and the proof of Theorem 3, every sum node $\\alpha^{\\prime\\prime}\\,{^=}\\,+_{i=1}^{k}\\alpha_{i}^{\\prime\\prime}\\in C^{\\prime\\prime}$ corresponds to some sum nodes $\\alpha=\\dot{+}_{i=1}^{k}\\alpha_{i}\\in C$ and $\\alpha^{\\prime}=+_{i=1}^{\\tilde{k}}\\alpha_{i}^{\\prime}\\in C^{\\prime}$ such that $\\alpha^{\\prime}=\\iota(\\alpha)$ , $p_{\\alpha_{i}^{\\prime\\prime}}=p_{\\alpha_{i}}\\otimes p_{\\alpha_{i}^{\\prime}}$ , and has scope vars $(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime})$ . Further, $\\alpha$ and $\\alpha^{\\prime}$ have the same scope over the common variables $V\\cap V^{\\prime}$ , i.e. $\\operatorname{vars}(\\alpha)\\cap(V\\cap V^{\\prime})=\\operatorname{vars}(\\alpha^{\\prime})\\cap(V\\cap V^{\\prime})$ . ", "page_idx": 21}, {"type": "text", "text": "Assume that $C$ and $C^{\\prime}$ are both $\\mathbf{\\deltaX}$ -deterministic; then $X\\subseteq V\\cap V^{\\prime}$ . We note that since $\\alpha,\\alpha^{\\prime}$ have the same scope over the common variables, they also have the same scope over $\\mathbf{\\deltaX}$ , i.e. vars $(\\alpha)\\cap$ ${\\pmb X}~=~\\mathrm{vars}(\\bar{\\alpha^{\\prime}})\\cap{\\pmb X}$ . Thus, either (i) holds for both $\\alpha,\\alpha^{\\prime}$ , or (ii) holds for both. If (i), then $\\operatorname{vars}(\\alpha^{\\prime\\prime})\\cap X=(\\operatorname{vars}(\\alpha)\\cup\\operatorname{vars}(\\alpha^{\\prime}))\\cap X=\\emptyset$ also. If (ii), then for any $i$ , consider the restricted support $\\mathrm{supp}_{X}(\\alpha_{i j}^{\\prime\\prime})$ . Noting that var $\\mathsf{\\dot{\\rho}}(\\alpha_{i})\\cap{\\pmb X}=\\mathrm{vars}(\\alpha_{j}^{\\prime})\\cap{\\pmb X}=\\mathrm{vars}(\\dot{\\alpha_{i}^{\\prime\\prime}})\\cap{\\pmb X}$ by smoothness, we claim that $\\mathsf{s u p p}_{X}(\\alpha_{i}^{\\prime\\prime})\\subseteq\\mathsf{s u p p}_{X}(\\alpha_{i})\\cap\\mathsf{s u p p}_{X}(\\alpha_{i}^{\\prime})$ . Suppose that $x\\in\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime\\prime})$ . Then there exists some $y\\,\\in\\,\\mathrm{vars}(\\alpha_{i}^{\\prime\\prime})\\:\\backslash\\:X$ such that $p_{\\alpha_{i}^{\\prime\\prime}}(\\pmb{x},\\pmb{y})=p_{\\alpha_{i}}(\\pmb{x},\\pmb{y}_{\\mathrm{vars}(\\alpha_{i}))\\backslash\\pmb{X}})\\otimes p_{\\alpha_{i}^{\\prime}}(\\pmb{x},\\pmb{y}_{\\mathrm{vars}(\\alpha_{i}^{\\prime})\\backslash\\pmb{X}})\\neq0_{\\mathcal{S}}.$ This means that both $p_{\\alpha_{i}}(\\pmb{x},\\pmb{y}_{\\mathrm{vars}(\\alpha_{i}))\\setminus\\pmb{X}}),p_{\\alpha_{i}^{\\prime}}(\\pmb{x},\\pmb{y}_{\\mathrm{vars}(\\alpha_{i}^{\\prime})\\setminus\\pmb{X}})$ cannot be $0_{S}$ , and so $\\pmb{x}\\in\\mathrm{supp}_{X}(\\alpha_{i})$ and $\\pmb{x}\\in\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})$ also. To finish the proof, we note that $\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime\\prime})\\subseteq\\mathrm{supp}_{X}(\\alpha_{i})\\cap\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})$ and $\\mathsf{s u p p}_{\\mathbf{x}}(\\alpha_{l}^{\\prime\\prime})\\subseteq\\mathsf{s u p p}_{\\mathbf{X}}(\\alpha_{l})\\cap\\mathsf{s u p p}_{\\mathbf{X}}(\\alpha_{l}^{\\prime})$ are disjoint unless $i=l$ (by $\\mathbf{\\deltaX}$ -determinism of $\\alpha$ and $\\alpha^{\\prime}$ ). Thus $\\alpha^{\\prime\\prime}$ is $\\mathbf{\\deltaX}$ -deterministic by (ii). ", "page_idx": 21}, {"type": "text", "text": "(5.4) Consider applying an elementwise mapping $\\tau$ to a circuit $C$ , outputting a circuit $C^{\\prime}$ . According to Algorithm 4 and Theorem 4, every sum node $\\alpha^{\\prime}\\,=\\,+_{i=1}^{k}\\alpha_{i}^{\\prime}\\,\\in\\,\\stackrel{\\cdot}{C}^{\\prime}$ corresponds to some node $\\alpha=+_{i=1}^{k}\\alpha_{i}\\in C^{\\prime}$ , such that $p_{\\alpha^{\\prime}}=\\tau(p_{\\alpha})$ , and further $p_{\\alpha_{i}^{\\prime}}=\\tau(p_{\\alpha_{i}})$ and vars $(\\alpha_{i}^{\\prime})=\\mathrm{vars}(\\alpha_{i})$ for each $i$ . ", "page_idx": 21}, {"type": "text", "text": "Assume that $C$ is $\\mathbf{\\deltaX}$ -deterministic. If (i) $\\operatorname{vars}(\\alpha)\\cap X=\\varnothing$ , then vars $(\\alpha^{\\prime}){\\cal X}=\\emptyset$ also. Otherwise, (ii) $\\operatorname{supp}_{X}(\\alpha_{i})\\cap\\operatorname{supp}_{X}(\\alpha_{j})=\\emptyset$ for all $i\\neq j$ . We claim that $\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})\\subseteq\\mathrm{supp}_{X}(\\alpha_{i})$ for each $i$ . To see this, recall that elementwise mappings satisfy $\\tau(0_{\\cal S})=0_{\\cal S},$ . If $\\pmb{x}\\in\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})$ , then there exists $\\textit{\\textbf{y}}$ s.t. $p_{\\alpha_{i}^{\\prime}}({\\pmb x},{\\pmb y})\\neq0_{S^{\\prime}}$ . Since $p_{\\alpha_{i}^{\\prime}}({\\pmb x},{\\pmb y})=\\tau(p_{\\alpha_{i}}({\\pmb x},{\\pmb y}))$ , $p_{\\alpha_{i}}({\\pmb x},{\\pmb y})\\neq0_{S}$ . So $x\\in\\operatorname{supp}_{X}(\\alpha_{i})$ . To finish the proof, note that $\\mathrm{supp}_{x}(\\alpha_{i}^{\\prime})\\subseteq\\mathrm{supp}_{X}(\\alpha_{i})$ and $\\mathrm{supp}_{x}(\\alpha_{l}^{\\prime})\\subseteq\\mathrm{supp}_{X}(\\alpha_{l})$ are disjoint unless $i=l$ (by $\\mathbf{\\deltaX}$ -determinism of $\\alpha$ ). Thus $\\alpha^{\\prime}$ is $\\mathbf{\\deltaX}$ -deterministic by (ii). ", "page_idx": 21}, {"type": "text", "text": "$\\mathbf{X}$ -compatibility Recall that two smooth and decomposable circuits $C,C_{\\mathrm{other}}$ over variables $V,V_{\\mathrm{other}}$ are $\\mathbf{\\deltaX}$ -compatible for $X\\subseteq V\\cap V_{\\mathrm{other}}$ if for every product node $\\alpha\\,=\\,\\alpha_{1}\\,\\times\\,\\alpha_{2}\\,\\in\\,C$ and $\\alpha_{\\mathrm{other}}\\,=\\,\\alpha_{\\mathrm{other,1}}\\,\\times\\,\\alpha_{\\mathrm{other,2}}\\,\\in\\,C_{\\mathrm{other}}$ such that $\\cdot\\operatorname{vars}(\\alpha)\\cap\\overbar{X^{\\prime}}=\\operatorname{vars}(\\alpha_{\\mathrm{other}})\\cap X$ , it holds that va $\\mathrm{rs}(\\alpha_{1})\\cap X=\\mathrm{vars}(\\alpha_{\\mathrm{other},1})\\cap X$ and v $\\operatorname{ars}(\\alpha_{2})\\cap X=\\operatorname{vars}(\\alpha_{\\mathrm{other,2}})\\cap X$ . ", "page_idx": 21}, {"type": "text", "text": "(5.5) Suppose that $C,C_{\\mathrm{other}}$ are $\\mathbf{\\deltaX}$ -compatible. We wish to show that $C_{\\mathrm{other}},C^{\\prime}$ are $\\mathbf{\\deltaX}$ -compatible where $C^{\\prime}$ is the output circuit from Algorithm 1 that aggregates $C$ over $W$ , where $W\\cap X=\\emptyset$ . ", "page_idx": 21}, {"type": "text", "text": "Suppose $\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\times\\alpha_{2}^{\\prime}\\in C^{\\prime}$ and $\\alpha_{\\mathrm{other}}\\,=\\,\\alpha_{\\mathrm{other,1}}\\,\\times\\,\\alpha_{\\mathrm{other,2}}\\,\\in\\,C_{\\mathrm{other}}$ are product nodes such that $\\operatorname{vars}(\\alpha^{\\prime})\\cap X\\,=\\,\\operatorname{vars}(\\alpha_{\\mathrm{other}})\\cap X$ . Let $\\alpha\\,=\\,\\alpha_{1}\\,\\times\\,\\alpha_{2}$ be the corresponding node in $C$ such that $p_{\\alpha^{\\prime}}\\,=\\,\\oplus_{w}\\,p_{\\alpha}$ . The scope va $\\mathbf{rs(}\\alpha^{\\prime}\\mathbf{)\\;=\\;vars(}\\alpha\\mathbf{)\\;\\backslash\\;}W$ ; since $W\\cap X\\,=\\,\\emptyset$ , we have vars $(\\alpha)\\cap$ $X=\\operatorname{vars}(\\alpha_{\\mathrm{other}})\\cap X$ also. Thus, by $\\mathbf{\\deltaX}$ -compatibility of $C,C_{\\mathrm{other}}$ , we have that $\\operatorname{\\prime}\\!\\operatorname{ars}(\\alpha_{1})\\cap X=$ v $\\operatorname{ars}(\\alpha_{\\mathrm{other},1})\\cap X$ and $\\mathrm{vars}(\\alpha_{2})\\cap\\dot{\\cal X}=\\mathrm{vars}(\\stackrel{\\cdot}{\\alpha}_{\\mathrm{other,2}})\\bigcap X$ . Since vars $(\\alpha_{1}^{\\prime})=\\mathrm{vars}(\\dot{\\alpha_{1}})\\mathbin{\\backslash}W$ and $\\operatorname{vars}(\\alpha_{2}^{\\prime})=\\operatorname{vars}(\\alpha_{2})\\setminus W$ , this means that $\\imath\\mathrm{ars}(\\alpha_{1}^{\\prime})\\cap{\\pmb X}=\\mathrm{vars}(\\alpha_{\\mathrm{other},1})\\cap{\\pmb X}$ and var $\\mathsf{i}(\\alpha_{2}^{\\prime})\\cap{\\pmb X}=$ vars $\\left(\\alpha_{\\mathrm{other,2}}\\right)\\cap X$ . Thus $C^{\\prime},C_{\\mathrm{other}}$ are $\\mathbf{\\deltaX}$ -compatible. ", "page_idx": 21}, {"type": "text", "text": "(5.6) Suppose that $C$ over $V$ and $C^{\\prime}$ over $V^{\\prime}$ are both $\\mathbf{\\deltaX}$ -compatible with $C_{\\mathrm{other}}$ . We wish to show that $C_{\\mathrm{other}},C^{\\prime\\prime}$ are $\\mathbf{\\deltaX}$ -compatible where $C^{\\prime\\prime}$ is the output circuit from Algorithm 2 that computes the product of the two compatible (i.e. $(V\\cup V^{\\prime})$ -compatible) circuits $C,C^{\\prime}$ . ", "page_idx": 21}, {"type": "text", "text": "Suppose $\\alpha^{\\prime\\prime}\\,=\\,\\alpha_{1}^{\\prime\\prime}\\,\\times\\,\\alpha_{2}^{\\prime\\prime}\\,\\in\\,C^{\\prime\\prime}$ is a product node, and $\\alpha_{\\mathrm{other}}\\,=\\,\\alpha_{\\mathrm{other,1}}\\,\\times\\,\\alpha_{\\mathrm{other,2}}\\,\\in\\,C_{\\mathrm{other}}$ such that var $\\mathrm{s}(\\alpha^{\\prime\\prime})\\cap X\\,=\\,\\mathrm{vars}(\\alpha_{\\mathrm{other}})\\cap X$ ; we need to show that these decompose in the same way over $\\mathbf{\\deltaX}$ . By Algorithm 2 and the proof of Theorem 2, this was created as the product of nodes $\\alpha=\\alpha_{1}\\times\\alpha_{2}\\in C$ and $\\alpha^{\\prime}=\\alpha_{1}^{\\prime}\\times\\alpha_{2}^{\\bar{\\prime}}\\in C^{\\prime}$ such that vars $(\\alpha^{\\prime\\prime})\\cap(V\\cap V^{\\prime})=\\operatorname{vars}({\\bar{\\alpha}})\\cap(V\\cap V^{\\prime})=$ $\\operatorname{vars}(\\alpha^{\\prime})\\cap(V\\cap V^{\\prime})$ (and similarly for their children). Thus by $(V\\cup V^{\\prime})$ -compatibility of $C,C^{\\prime}$ , $\\alpha$ and $\\alpha^{\\prime}$ decompose the same way over $(V\\cup V^{\\prime})$ , i.e. $\\operatorname{vars}(\\alpha_{1})\\cap({\\dot{V}}\\cup V^{\\prime})=\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap(V\\cup V^{\\prime})$ and $\\mathrm{vars}(\\alpha_{2})\\cap(\\bar{V}\\cup V^{\\prime})=\\mathrm{vars}(\\bar{\\alpha}_{2}^{\\prime})\\cap(\\bar{V}\\cup V^{\\prime})$ . Since $X\\subseteq V\\cap V^{\\prime}$ (by definition of compatibility), this also holds over $\\mathbf{\\deltaX}$ , i.e. vars $(\\alpha_{1})\\cap X=\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap X$ and $\\mathrm{vars}(\\alpha_{2})\\cap X=\\mathrm{vars}(\\alpha_{2}^{\\prime})\\cap X$ . ", "page_idx": 21}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "Now, since vars $(\\alpha_{1}^{\\prime\\prime})=\\operatorname{vars}(\\alpha_{1})\\cup\\operatorname{vars}(\\alpha_{1}^{\\prime})$ and vars $(\\alpha_{2}^{\\prime\\prime})=\\operatorname{vars}(\\alpha_{2})\\cup\\operatorname{vars}(\\alpha_{2}^{\\prime})$ , we have that: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname{vars}(\\alpha^{\\prime\\prime})\\cap X=(\\operatorname{vars}(\\alpha)\\cap X)\\cup(\\operatorname{vars}(\\alpha^{\\prime})\\cap X)=\\operatorname{vars}(\\alpha)\\cap X}\\\\ &{\\operatorname{vars}(\\alpha_{1}^{\\prime\\prime})\\cap X=(\\operatorname{vars}(\\alpha_{1})\\cap X)\\cup(\\operatorname{vars}(\\alpha_{1}^{\\prime})\\cap X)=\\operatorname{vars}(\\alpha_{1})\\cap X}\\\\ &{\\operatorname{vars}(\\alpha_{2}^{\\prime\\prime})\\cap X=(\\operatorname{vars}(\\alpha_{2})\\cap X)\\cup(\\operatorname{vars}(\\alpha_{2}^{\\prime})\\cap X)=\\operatorname{vars}(\\alpha_{2})\\cap X}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By compatibility of $C,C_{\\mathrm{other}}$ , we have that vars $(\\alpha_{\\mathrm{other_{1}}})\\cap X=\\mathrm{vars}(\\alpha_{1})\\cap X$ and vars $(\\alpha_{\\mathrm{other_{2}}})\\cap X=$ $\\operatorname{vars}(\\alpha_{2})\\cap X$ . Thus var $\\mathsf{\\Gamma}_{3}\\big(\\alpha_{\\mathrm{other_{1}}}\\big)\\cap{\\pmb X}=\\mathrm{vars}(\\alpha_{1}^{\\prime\\prime})\\cap{\\pmb X}$ and $\\mathrm{vars}(\\alpha_{\\mathrm{other_{2}}})\\cap X\\,=\\,\\mathrm{vars}(\\alpha_{2}^{\\prime\\prime})\\cap X$ . This shows $\\mathbf{\\deltaX}$ -compatibility of $C^{\\prime\\prime},C_{\\mathrm{{other}}}$ . ", "page_idx": 22}, {"type": "text", "text": "Example 4 (Counterexample to (5.6) for Compatibility). While $\\mathbf{\\deltaX}$ -compatibility is maintained through multiplying compatible circuits, the same is not true for compatibility, due to the different variable overlaps between the circuits. For example, suppose that $C$ over variable sets $A,B,C$ has product nodes with scope decomposing as $\\alpha=\\alpha_{1}(\\pmb{A})\\times\\alpha_{2}(\\pmb{B}\\cup\\pmb{C}),$ , and $C^{\\prime}$ over variable sets $A,B,D$ has product nodes with scope decomposing as $\\alpha^{\\prime}=\\alpha_{1}^{\\prime}(A)\\times\\alpha_{2}^{\\prime}(B\\cup D)$ . Then these circuits are compatible (i.e. $A\\cup B$ -compatible), and their product is a circuit with product nodes with scope decomposing as $\\alpha^{\\prime\\prime}=\\alpha_{1}^{\\prime}(\\pmb{A})\\times\\alpha_{2}^{\\prime}(\\pmb{B}\\cup\\pmb{C}\\cup\\pmb{D})$ . Now consider $C_{o t h e r}$ with product nodes with scope decomposing as $\\alpha_{o t h e r}=\\alpha_{o t h e r}(C)\\times\\alpha_{o t h e r}(D)$ . This is compatible with $\\alpha$ and $\\alpha^{\\prime}$ , but not with $\\alpha^{\\prime\\prime}$ . ", "page_idx": 22}, {"type": "text", "text": "(5.7) This holds by the same argument as (5.6). ", "page_idx": 22}, {"type": "text", "text": "(5.8) The circuit $C^{\\prime}$ obtained by applying an elementwise mapping to $C$ does not change the scopes of any node. Thus, if $C$ is compatible with $C_{\\mathrm{other}}$ , then $C^{\\prime}$ is also compatible with $C_{\\mathrm{other}}$ . ", "page_idx": 22}, {"type": "text", "text": "$\\mathbf{X}$ -support-compatibility Recall that two smooth and decomposable circuits $C$ , $C_{\\mathrm{other}}$ over variables $V$ , $V_{\\mathrm{other}}$ are $\\mathbf{\\deltaX}$ -support-compatible for $X\\subseteq V\\cap V_{\\mathrm{other}}$ if there is an isomorphism $\\iota$ between the nodes $C[X]$ and $C_{\\mathrm{other}}[X]$ , such that: ", "page_idx": 22}, {"type": "text", "text": "\u2022 For any nod $\\in C[X],\\operatorname{vars}(\\alpha)\\cap X=\\operatorname{vars}(\\iota(\\alpha))\\cap X;$   \n\u2022 For all sum nodes $\\alpha=+_{i=1}^{k}\\alpha_{i}\\in C[X]$ , we have that $\\operatorname{supp}_{X}(\\alpha_{i})\\cap\\operatorname{supp}_{X}(\\iota(\\alpha_{j}))=\\emptyset$ whenever $i\\neq j$ . ", "page_idx": 22}, {"type": "text", "text": "(5.9) Suppose that $C,C_{\\mathrm{other}}$ are $\\mathbf{\\deltaX}$ -support-compatible; and let $\\iota_{C_{\\mathrm{other}},C}$ be the isomorphism from $C_{\\mathrm{other}}[X]$ to $C[X]$ . We wish to show that $C_{\\mathrm{other}}$ , $C^{\\prime}$ are $\\mathbf{\\deltaX}$ -support-compatible where $C^{\\prime}$ is the output circuit from Algorithm 1 that aggregates $C$ over $W$ , where $W\\cap X=\\emptyset$ . ", "page_idx": 22}, {"type": "text", "text": "We define the isomorphism as follows. Consider the set of nodes $C^{\\prime}[X]$ . Since $W\\cap X=\\emptyset$ , these nodes are not scalars and so are not propagated away by Lines 3-4. Moreover, since the algorithm retains the node types and connectivity of the circuit, there is an isomorphism $\\iota_{C,C^{\\prime}}$ between $C[X]$ and $C^{\\prime}[X]$ . There is thus an isomorphism $l C_{\\mathrm{other}},C^{\\prime}:=l C,C^{\\prime}\\;^{\\circ}\\;l C_{\\mathrm{other}},C$ between $C_{\\mathrm{other}}[X]$ and $C^{\\prime}[X]$ . It remains to show the two conditions. ", "page_idx": 22}, {"type": "text", "text": "Given a node $\\alpha_{\\mathrm{other}}~\\in~C_{\\mathrm{other}}$ , let us write $\\alpha~:=~\\iota_{C_{\\mathrm{other}},C}\\big(\\alpha_{\\mathrm{other}}\\big)$ and $\\alpha^{\\prime}\\;:=\\;\\iota_{C,C^{\\prime}}(\\alpha)$ . By $\\mathbf{\\deltaX}$ - support compatibility of $C_{\\mathrm{other}},C$ , we have that var $\\mathsf{s}(\\alpha_{\\mathrm{other}})\\cap X\\,=\\,\\mathrm{vars}(\\alpha)\\cap X$ . By the proof of Theorem 1, we know that $\\operatorname{vars}(\\alpha^{\\prime})\\;=\\;\\operatorname{vars}(\\alpha)\\:\\backslash\\:\\mathbf{\\operatorname{\\cal{W}}}$ . Since $W\\cap X\\,{\\overset{\\cdot}{=}}\\,\\emptyset$ , this implies that va $\\mathrm{rs}(\\alpha_{\\mathrm{other}})\\cap X=\\mathrm{vars}(\\alpha^{\\prime})\\cap X$ as required. For the second part, suppose that these are sum nodes, i.e. $\\alpha_{\\mathrm{other}}=+_{i=1}^{k}\\alpha_{\\mathrm{other},i}$ , $\\alpha=+_{i=1}^{k}\\alpha_{i}$ and $\\alpha^{\\prime}=+_{i=1}^{k}\\alpha_{i}^{\\prime}$ . We know by $\\mathbf{\\deltaX}$ -support-compatibility that $\\operatorname{supp}_{X}(\\alpha_{\\mathrm{other},i})\\cap\\operatorname{supp}_{X}(\\alpha_{j})=\\emptyset$ whenever $i\\neq j$ . By the same argument as in (5.1), we have that $\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})\\,\\subseteq\\,\\mathrm{supp}_{X}(\\alpha_{i})$ for all $i$ . Thus we can conclude that $\\mathrm{supp}_{X}(\\alpha_{\\mathrm{other},i})\\cap\\mathrm{supp}_{X}(\\alpha_{j}^{\\prime})=\\emptyset$ whenever $i\\neq j$ . So $C_{\\mathrm{other}},C^{\\prime}$ are $\\mathbf{\\deltaX}$ -support-compatible. ", "page_idx": 22}, {"type": "text", "text": "(5.10) Suppose that $C$ over $V$ and $C^{\\prime}$ over $V^{\\prime}$ are both $\\mathbf{\\deltaX}$ -support-compatible with $C_{\\mathrm{other}}$ ; write $\\iota_{C_{\\mathrm{other}},C}$ for the isomorphism from $C_{\\mathrm{other}}[X]$ to $C$ , and $\\iota_{C_{\\mathrm{other}},C^{\\prime}}$ for the isomorphism from $C_{\\mathrm{other}}[X]$ to $C^{\\prime}$ . We wish to show that $C_{\\mathrm{other}},C^{\\prime\\prime}$ are $\\mathbf{\\deltaX}$ -support-compatible where $C^{\\bar{\\prime}\\bar{\\prime}}$ is the output circuit from Algorithm 3 that computes the product of the two support-compatible (i.e. $(V\\cup V^{\\prime})$ -supportcompatible) circuits $C,C^{\\prime}$ . ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "We define the isomorphism as follows. Consider the set of nodes $C^{\\prime\\prime}[X]$ . The algorithm for multiplying $C,C^{\\prime}$ makes use of the isomorphism $^{l}C,C^{\\prime}$ between $C[V\\cap\\bar{V}^{\\prime}]$ and $C^{\\prime}[V\\,\\bar{\\cap}\\,V^{\\prime}]$ , with $C^{\\prime\\prime}[\\bar{V}\\cap\\bar{V}^{\\prime}]$ retaining the same connectivity and node types; thus there is an isomorphism $^{l}C,C^{\\prime\\prime}$ from $C[V\\cap V^{\\prime}]$ to $\\bar{C}^{\\prime\\prime}[V\\cap V^{\\prime}]$ , also. Since $X\\subseteq(V\\cap{\\dot{V}}^{\\prime})$ , this isomorphism also holds between the circuits restricted to $\\mathbf{\\deltaX}$ . Thus, we define the isomorphism $\\iota=\\iota_{C,C^{\\prime\\prime}}\\circ\\iota_{C_{\\mathrm{other}},C}$ between $C_{\\mathrm{other}}[X]$ and $C^{\\prime\\prime}[X]$ . It remains to show the two conditions. ", "page_idx": 23}, {"type": "text", "text": "Given a node $\\alpha_{\\mathrm{other}}\\in C_{\\mathrm{other}}$ , let us write $\\alpha:=\\iota_{C_{\\mathrm{other}},C}\\big(\\alpha_{\\mathrm{other}}\\big)$ , $\\alpha^{\\prime}=\\iota_{C,C^{\\prime}}(\\alpha)$ and $\\alpha^{\\prime\\prime}:=\\iota_{C,C^{\\prime\\prime}}(\\alpha)$ . By $\\mathbf{\\deltaX}$ -support-compatibility of $C_{\\mathrm{other}},C$ , we have that var $;(\\alpha_{\\mathrm{other}})\\cap X\\;=\\;\\operatorname{vars}(\\alpha)\\cap X$ . By support-compatibility of $C,C^{\\prime}$ , we have that $\\operatorname{vars}(\\alpha)\\cap(V\\cap V^{\\prime})=\\operatorname{vars}(\\alpha^{\\prime})\\cap(V\\cap V^{\\prime})$ and so $\\operatorname{vars}(\\alpha)\\cap X=\\operatorname{vars}(\\dot{\\alpha}^{\\prime})\\cap X$ , and both are equal to vars $4(\\alpha^{\\prime\\prime})\\cap X$ since v $\\operatorname{\\mathrm{urs}}(\\dot{\\alpha}^{\\prime\\prime})=\\operatorname{vars}(\\alpha)\\cup\\operatorname{\\mathrm{vars}}(\\alpha^{\\prime})$ (as in Theorem 3). Thus vars $(\\alpha_{\\mathrm{other}})\\cap X=\\operatorname{vars}(\\alpha^{\\prime\\prime})\\cap X$ as required. For the second part, suppose that these are sum nodes, i.e. $\\alpha_{\\mathrm{other}}=+_{i=1}^{k}\\alpha_{\\mathrm{other},i}$ , $\\alpha=+_{i=1}^{k}\\alpha_{i}$ , $\\alpha^{\\prime}=+_{i=1}^{k}\\alpha_{i}^{\\prime}$ and $\\alpha^{\\prime}=+_{i=1}^{k}\\alpha_{i}^{\\prime\\prime}$ We know by $\\mathbf{\\deltaX}$ -support-compatibility that $\\operatorname{supp}_{X}(\\alpha_{\\mathrm{other},i})\\cap\\operatorname{supp}_{X}(\\alpha_{j})=\\emptyset$ whenever $i\\neq j$ . By the same argument as in (5.3), we have that $\\begin{array}{r}{\\operatorname{supp}_{X}(\\alpha^{\\prime\\prime})\\subseteq\\operatorname{supp}_{X}(\\alpha)\\cap\\operatorname{supp}_{X}(\\alpha^{\\prime}).}\\end{array}$ . Thus we can conclude that $\\operatorname{supp}_{X}(\\alpha_{\\mathrm{other},i})\\cap\\operatorname{supp}_{X}(\\alpha^{\\prime\\prime})=\\emptyset$ . So $C_{\\mathrm{other}},C^{\\prime\\prime}$ are $\\mathbf{\\deltaX}$ -support-compatible. ", "page_idx": 23}, {"type": "text", "text": "(5.11) Suppose that $C,C_{\\mathrm{other}}$ are $\\mathbf{\\deltaX}$ -support-compatible; and let $\\iota_{C_{\\mathrm{other}},C}$ be the isomorphism from $C_{\\mathrm{other}}[X]$ to $C[X]$ . We wish to show that $C_{\\mathrm{other}},C^{\\prime}$ are $\\mathbf{\\deltaX}$ -support-compatible where $C^{\\prime}$ is the output circuit from Algorithm 4 that applies an elementwise mapping $\\tau$ to $C$ . Algorithm 4 maps each node $\\alpha\\in C$ to another node $\\alpha^{\\prime}\\in C$ , keeping the node type and connectivity; this defines an isomorphism $^{l}C,C^{\\prime}$ from $C[X]$ to $C^{\\prime}[X]$ . Thus we have an isomorphism $l C_{\\mathrm{other}},C^{\\prime}:=l C,C^{\\prime}\\circ l C_{\\mathrm{other}},C$ . It remains to show the two conditions. ", "page_idx": 23}, {"type": "text", "text": "Given a node $\\alpha_{\\mathrm{other}}~\\in~C_{\\mathrm{other}}$ , let us write $\\alpha~:=~\\iota_{C0,C}(\\alpha_{\\mathrm{other}})$ and $\\alpha^{\\prime}\\;:=\\;\\iota_{C,C^{\\prime}}(\\alpha)$ . By $\\mathbf{\\deltaX}$ - support-compatibility of $C_{\\mathrm{other}},C$ , we have that v $\\operatorname{ars}(\\alpha_{\\mathrm{other}})\\,\\cap\\,{\\cal X}\\ =\\ \\operatorname{vars}(\\alpha)\\,\\cap\\,{\\cal X}$ . The mapping algorithm does not change the scope of the nodes, i.e. vars $:\\!(\\alpha^{\\prime})\\,=\\,{\\mathrm{vars}}(\\dot{\\alpha})$ , so we have that $\\mathrm{vars}(\\alpha_{\\mathrm{other}})\\cap X=\\mathrm{vars}(\\alpha^{\\prime})\\cap X$ as required. For the second part, suppose that these are sum nodes, i.e. $\\alpha_{\\mathrm{other}}=+_{i=1}^{k}\\alpha_{\\mathrm{other},i}$ , $\\alpha=+_{i=1}^{k}\\alpha_{i}$ and $\\alpha^{\\prime}=+_{i=1}^{k}\\alpha_{i}^{\\prime}$ . We know by $\\mathbf{\\deltaX}$ -support-compatibility that $\\operatorname{supp}_{X}(\\alpha_{\\mathrm{other},i})\\cap\\operatorname{supp}_{X}(\\alpha_{j})=\\emptyset$ whenever $i\\neq j$ . We know by the same argument as in (5.4) that $\\mathrm{supp}_{X}(\\alpha_{i}^{\\prime})\\,\\subseteq\\,\\mathrm{supp}_{X}(\\alpha_{i})$ for all $i$ . Thus we can conclude that $\\operatorname{supp}_{X}(\\alpha_{\\mathrm{other},i})\\cap\\operatorname{supp}_{X}(\\alpha_{j}^{\\prime})=\\emptyset$ whenever $i\\neq j$ . So $C_{\\mathrm{other}},C^{\\prime}$ are $\\mathbf{\\deltaX}$ -support-compatible. \u53e3 ", "page_idx": 23}, {"type": "text", "text": "Theorem 7 (Hardness of 2AMC with $\\mathbf{\\deltaX}$ -firstness). 2AMC is #P-hard, even for circuits that are smooth, decomposable, deterministic, and $\\mathbf{\\deltaX}$ -first, and a constant-time elementwise mapping. ", "page_idx": 23}, {"type": "text", "text": "Proof. Take a ${\\mathrm{DNF}}\\;\\phi$ with terms $\\phi_{1},\\ldots,\\phi_{m}$ over variables $X_{1},\\ldots,X_{n}$ . Let $l=\\left\\lceil\\log m\\right\\rceil+1$ . Let us construct another DNF $\\phi^{\\prime}$ with terms $\\phi_{1}^{\\prime},\\ldots,\\phi_{m}^{\\prime}$ over variables $X_{1}\\ldots,X_{n}$ and $Y_{1},\\ldots,Y_{l+1}$ such that each $\\phi_{i}^{\\prime}$ is the conjunction of $\\phi_{i}$ , $Y_{l+1}$ and a term over $Y_{1},\\ldots,Y_{l}$ encoding a binary representation of $i$ . For example: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\phi_{5}^{\\prime}=\\phi_{5}\\wedge Y_{1}\\wedge\\neg Y_{2}\\wedge Y_{3}\\wedge\\neg Y_{4}\\wedge\\cdot\\cdot\\cdot\\wedge\\neg Y_{l}\\wedge Y_{l+1}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Now, efficiently manipulate $\\phi^{\\prime}$ to make it smooth [15]. The circuit $\\phi^{\\prime}$ is thus smooth, decomposable, deterministic and trivially satisfies $\\Chi$ -firstness (since the children to every $\\wedge$ -gate are literals). Take the probability semiring as $\\mathcal{S}_{\\mathbf{X}}$ , and $\\mathcal{S}_{Y}=(\\mathbb{N}^{2},+_{2},\\times_{2},(0,0),(1,1))$ and $\\tau((n1,n2))\\,=\\,n1/n2$ (define $0/0=0)$ . Also, define $\\omega(x)=1$ , and $\\omega^{\\prime}(Y_{l+1}=0)=(0,1)$ and $\\omega^{\\prime}(y)=1$ for all other literals. Then 2AMC counts the models of $\\phi$ , which is $\\#\\mathbf{P}$ -hard [46]: ", "page_idx": 23}, {"type": "equation", "text": "$$\n2A M C=\\sum_{x}\\frac{\\sum_{\\pmb{y}:y_{l+1}=1}\\phi^{\\prime}(\\pmb{x},\\pmb{y})}{\\sum_{\\pmb{y}}\\phi^{\\prime}(\\pmb{x},\\pmb{y})}=\\sum_{\\pmb{x}}\\phi(\\pmb{x}),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we assume $0/0\\,=\\,0$ . The last equality follows because the circuit is deterministic (hence $\\begin{array}{r}{\\sum_{\\pmb{y}}\\phi^{\\prime}(\\pmb{x},\\pmb{y})\\,=\\,\\operatorname*{max}_{\\pmb{y}}\\phi(\\pmb{x},\\pmb{y})\\,\\leq\\,1)}\\end{array}$ and logically equivalent to $\\phi$ (i.e., $\\forall\\pmb{x}\\,:\\,\\phi(\\pmb{x})\\,=\\,1\\,\\Leftrightarrow\\,\\exists\\pmb{y}\\,:$ $\\phi^{\\prime}({\\pmb x},{\\pmb y})=1)$ ). \u53e3 ", "page_idx": 23}, {"type": "text", "text": "Theorem 8 (Tractability Conditions for 2AMC). Every 2AMC instance is tractable in $O(|C|)$ time for Boolean circuits that are smooth, decomposable, deterministic, $\\mathbf{\\deltaX}$ -first, and $\\mathbf{\\deltaX}$ -deterministic. ", "page_idx": 23}, {"type": "image", "img_path": "mXlR1FLFDc/tmp/a34a5c68cd8ce3a912211f9be8dbd3acbb659c4bca1d59645a5c874d00967d1a.jpg", "img_caption": ["Figure 4: Illustration of PC computing hidden Markov model (HMM) "], "img_footnote": [], "page_idx": 24}, {"type": "text", "text": "Algorithm 5: 2AMC ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Input: Decomposable, smooth, deterministic, $\\mathbf{\\deltaX}$ -first and $\\mathbf{\\deltaX}$ -deterministic logic circuit $C$ over $\\boldsymbol{X}\\cup\\bar{\\boldsymbol{Y}}$ , weight circuits $\\omega_{X},\\omega_{Y}$ , semirings $S_{X},S_{Y}$ , mapping function $\\tau_{S\\mathbf{{\\gamma}}\\rightarrow S_{\\mathbf{{X}}}}$ Output: 2AMC value (scalar in semiring $\\mathcal{S}_{\\pmb{X}}$ )   \n1 $C_{S_{Y}}(X,Y)\\gets\\tt M A P P I N G(C(X,Y);\\mathbb{[}\\cdot\\mathbb{]}_{\\beta\\to S_{Y}})$   \n2 $C_{S_{Y},\\omega_{Y}}(X,Y)\\gets\\mathsf{P R O D-C M P}(C_{S_{Y}}(X,Y),\\omega_{Y})$   \n3 $C_{S_{Y},\\omega_{Y}}(X)\\gets\\tt A G G(C_{S_{Y},\\omega_{Y}}(X,Y);Y)$ $C_{S_{\\mathbf{X}},\\omega_{\\mathbf{Y}}}(X)\\gets\\mathbb{M}\\mathrm{APPING}(C_{S_{\\mathbf{Y}},\\omega_{\\mathbf{Y}}}(X);\\tau_{S_{\\mathbf{Y}}\\rightarrow S}$ X) $C_{S_{X},\\omega_{Y},\\omega_{X}}(X)\\gets\\mathsf{P R O D-C M P}(C_{S_{X}}(X),\\omega_{X})$ Result: $\\mathsf{A G G}\\big(C_{S_{X},\\omega_{Y},\\omega_{X}}(X);X\\big)$ ", "page_idx": 24}, {"type": "text", "text": "Proof. In Algorithm 5, we show the algorithm for 2AMC, which is simply a composition of aggregations, products, and elementwise mappings. To show tractability of 2AMC, we simply need to show that the input circuits to each of these operators satisfy the requisite tractability conditions. ", "page_idx": 24}, {"type": "text", "text": "We start with a smooth, decomposable, deterministic, $\\mathbf{\\deltaX}$ -deterministic, and $\\mathbf{\\deltaX}$ -first circuit $C(X,Y)$ . ", "page_idx": 24}, {"type": "text", "text": "\u2022 In line 1, we use the support mapping (Definition 6) from the Boolean to $\\mathcal{S}_{Y}$ semiring; this is tractable by Corollary 1 due to determinism, and the output $C_{S\\v{r}}(X,Y)$ retains all the properties by Table 3. \u2022 In line 2, we take the product of $C_{S_{Y}}(X,Y)$ and $\\omega_{X}(X)$ . $\\omega_{X}$ is omni-compatible, so we can apply PROD-CMP. This results in a circuit $C_{S_{Y},\\omega_{Y}}(X,Y)$ that is smooth, decomposable and $\\mathbf{\\deltaX}$ -first. $\\omega_{X}(X)$ is both deterministic and $\\mathbf{\\deltaX}$ -deterministic as it has no sum nodes, so this output circuit is also deterministic and $\\mathbf{\\deltaX}$ -deterministic by (5.2). \u2022 In line 3, we aggregate $C_{S_{Y},\\omega_{Y}}(X,Y)$ over $\\mathbf{Y}$ . The output circuit $C_{S_{Y},\\omega_{Y}}(X)$ is smooth and decomposable. It is also $\\mathbf{\\deltaX}$ -deterministic by (5.1), as $\\pmb{Y}\\cap\\pmb{X}=\\emptyset$ . ", "page_idx": 24}, {"type": "text", "text": "Since $C_{S_{Y},\\omega_{Y}}(X,Y)$ satisfied $\\mathbf{\\deltaX}$ -firstness, each product node $\\alpha=\\alpha_{1}\\times\\alpha_{2}$ in that circuit had at most one child (say $\\alpha_{1}$ ) with scope overlapping with $\\mathbf{\\deltaY}$ . Then, in the product in the previous step, $\\alpha_{2}$ must have been produced through Lines 1-2 (otherwise it would contain some variable in $\\mathbf{\\deltaY}$ ); thus it was produced by applying $\\lVert\\cdot\\rVert_{B\\to S_{Y}}$ to some node in $C$ . Thus, for any value $\\pmb{v}\\in\\mathrm{Assign}(\\alpha_{2})$ , $\\bar{p_{\\alpha_{2}}}\\in\\{0_{S_{Y}},\\bar{1_{S_{Y}}}\\}$ . So $\\left(\\mathrm{Prod}\\,0/1\\right)$ ) is satisfied. ", "page_idx": 25}, {"type": "text", "text": "\u2022 In line 4, we apply the mapping $\\tau_{S\\mathbf{Y}\\rightarrow S\\mathbf{X}}$ to $C_{S_{Y},\\omega_{Y}}(X)$ . This circuit is over $\\mathbf{\\deltaX}$ and is $\\mathbf{\\deltaX}$ -deterministic, i.e. deterministic and satisfies (Additive). As shown in the previous step, it also satisfies $({\\mathrm{Prod}}\\,0/1)$ ). Thus the mapping algorithm produces the correct result, producing a smooth, decomposable and determinsitic circuit $\\bar{C_{S x,\\omega_{Y}}}(X)$ as output. \u2022 In line 5, we take the product of $C_{S_{X},\\omega_{Y}}(X)$ with $\\omega_{X}(X)$ . $\\omega_{X}$ is omni-compatible so we can apply PROD-CMP, producing a circuit $C_{\\cal S_{\\bf X},\\omega_{\\bf Y},\\omega_{\\bf X}}$ that is smooth and decomposable (and also deterministic). \u2022 Finally, we aggregate $C_{S_{{\\pmb{x}}},\\omega_{{\\pmb{Y}}},\\omega_{{\\pmb{X}}}}({\\pmb{X}})$ over $\\mathbf{\\deltaX}$ , producing a scalar. ", "page_idx": 25}, {"type": "text", "text": "Theorem 9 (Exponential Separation). Given sets of variables ${\\pmb X}=\\{X_{1},...,X_{n}\\},{\\pmb Y}=\\{Y_{1},...,Y_{n}\\}$ , there exists a smooth, decomposable and $\\mathbf{\\deltaX}$ -deterministic circuit $C$ of size poly $(n)$ such that the smallest smooth, decomposable, and $\\mathbf{\\deltaX}$ -first circuit $C^{\\prime}$ such that $p_{C}\\equiv p_{C^{\\prime}}$ has size $2^{\\Omega(n)}$ . ", "page_idx": 25}, {"type": "text", "text": "Proof. Consider representing the distribution given by a hidden Markov model (HMM) over (hidden) variables $X_{\\leq n}=\\{X_{1},...,X_{n}\\}$ and (observed) variables $Y_{\\leq n}=\\{Y_{1},...,Y_{n}\\}$ , as depicted in Figure 4a. Figure $\\bar{4}\\mathbf{b}$ shows a structured decomposable circuit that computes the hidden Markov model distribution, where the components $C_{i}(\\bar{j})$ have scope $\\{X_{i},Y_{i}\\}$ . The corresponding vtree/scopedecomposition (with nodes notated using their scopes) is shown in Figure 4c. It can easily be checked that the circuit is $X{\\leq}n$ -deterministic, and that the circuit size is linear in $n$ . ", "page_idx": 25}, {"type": "text", "text": "It remains to show that the smallest $X{\\leq}n$ -first and $X{\\leq}n$ -deterministic circuit computing the HMM distribution is exponential in size. Explicitly, we will choose a HMM such that the emission distribution is given by $p(Y_{i}|{X}_{i})=\\mathbb{1}_{Y_{i}=X_{i}}$ . Then we have that $p_{C^{\\prime}}(x_{\\leq n},Y_{\\leq n})=p_{C^{\\prime}}(x_{\\leq n})p_{C^{\\prime}}(Y_{\\leq n}|x_{\\leq n})=$ $p_{C^{\\prime}}(x_{\\leq n})\\mathbb{1}_{Y_{\\leq n}=x_{\\leq n}}$ , for any circuit $C^{\\prime}$ that expresses the distribution of the HMM. ", "page_idx": 25}, {"type": "text", "text": "Consider any such circuit $C^{\\prime}$ . Then, let $\\pmb{\\alpha}=\\{\\alpha_{1},...,\\alpha_{K}\\}$ be the set of nodes with scope $Y_{\\leq n}$ in the circuit. We will need the following lemma: ", "page_idx": 25}, {"type": "text", "text": "Lemma 2. For any value $x_{\\leq n}$ of $X{\\leq}n$ , there exists constants $c_{1},..,c_{K}\\in\\mathbb{R}^{\\geq0}$ such that: ", "page_idx": 25}, {"type": "equation", "text": "$$\np_{C^{\\prime}}(x_{\\leq n},Y_{\\leq n})\\equiv\\sum_{k=1}^{K}c_{k}p_{\\alpha_{k}}(Y_{\\leq n})\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "In other words, the output of the circuit is a linear function of the nodes with scope $Y_{\\leq n}$ ", "page_idx": 25}, {"type": "text", "text": "Proof. We show this proof by bottom-up induction (child before parent), for the set of nodes whose scope contains $Y_{\\leq n}$ : ", "page_idx": 25}, {"type": "text", "text": "\u2022 Leaf node: If the scope is $Y_{\\leq n}$ , then it must be some node $\\alpha_{k}\\in\\alpha$ ; then we take $c_{k}=1$ and $c_{k^{\\prime}}=0$ for all $k^{\\prime}\\neq k$ . ", "page_idx": 25}, {"type": "text", "text": "\u2022 Sum node: By smoothness, all the children must have the same scope (containing $Y_{\\leq n.}$ ). The sum node is then just a linear combination of its children, so the result holds by the inductive hypothesis. ", "page_idx": 25}, {"type": "text", "text": "\u2022 Product node $P$ : Let $P_{1},P_{2}$ be the children of $P$ . By $X{\\leq}n$ -firstness, either both children are pure (have scope entirely contained in $X{\\leq}n$ or $Y_{\\leq n.}$ ), or one of them is pure, and the scope of the other one (say $P_{1}$ ) contains $Y_{\\leq n}$ . ", "page_idx": 25}, {"type": "text", "text": "In the first case, if there is exactly one node (say $P_{1}$ ), with scope contained in $Y_{\\leq n}$ , then it must have scope exactly $Y_{\\leq n}$ . Then we have that: ", "page_idx": 25}, {"type": "equation", "text": "$$\np_{P}(x\\underline{{\\leq}}n,Y_{\\leq n})=p_{P_{1}}(Y_{\\leq n})p_{P_{2}}(x\\underline{{\\leq}}n\\cap\\operatorname{vars}(P_{2}))\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "$p_{P_{2}}(x_{\\leq n}\\cap\\operatorname{vars}(P_{2}))$ here is a constant, so by the inductive hypothesis we are done. If both nodes have scope contained in $Y_{\\leq n}$ , then $P$ is in $_{\\alpha}$ , say $P=\\alpha_{k}$ . Then we set $c_{k}=1$ and $c_{k^{\\prime}}=0$ for $k^{\\prime}\\neq k$ . ", "page_idx": 26}, {"type": "text", "text": "In the second case, we have that: ", "page_idx": 26}, {"type": "equation", "text": "$$\np_{P}(x_{\\leq n},Y_{\\leq n})=p_{P_{1}}(x_{\\leq n}\\cap\\operatorname{vars}(P_{1}),Y_{\\leq n})p_{P_{2}}(x_{\\leq n}\\cap\\operatorname{vars}(P_{2}))\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Here $p_{P_{2}}(x_{\\leq n}\\cap\\operatorname{vars}(P_{2}))$ is a constant, so by the inductive hypothesis we are done. ", "page_idx": 26}, {"type": "text", "text": "Note that $X{\\leq}n$ -firstness was crucial to avoid the case where a product has two mixed nodes (containing variables in $X{\\leq}n$ and $Y_{\\leq n}$ ) as children. ", "page_idx": 26}, {"type": "text", "text": "For any $k=1,..,K$ , define $v_{k}\\in\\mathbb{R}_{\\geq0}^{2^{n}}$ to be the vector with entries $v_{k,i}=\\alpha_{k}(i)$ (where we interpret $i$ as a value of $Y_{\\leq n.}$ ). Then we have the following Corollary: ", "page_idx": 26}, {"type": "text", "text": "Corollary 2. The set of vectors $\\{v_{1},...,v_{K}\\}$ forms a spanning set for $\\mathbb{R}^{2^{n}}$ . ", "page_idx": 26}, {"type": "text", "text": "Proof. By the Lemma and the fact that $C^{\\prime}$ expresses the HMM distribution, we have that for any $x_{\\leq n}\\in\\{{\\dot{0}},1\\}^{n}$ , there exists $c_{1},..,c_{k}\\in\\mathbb{R}^{\\geq0}$ such that: ", "page_idx": 26}, {"type": "equation", "text": "$$\np_{C^{\\prime}}(x_{\\leq n})\\mathbb{1}_{Y_{\\leq n}=x_{\\leq n}}\\equiv\\sum_{k=1}^{K}c_{k}p_{\\alpha_{k}}(Y_{\\leq n})\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Rearranging, and writing in vector form, we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\ne_{x\\leq n}=\\sum_{k=1}^{K}{\\frac{c_{k}}{p_{C^{\\prime}}(x\\leq n)}}v_{k}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $e_{x\\leq n}\\in\\mathbb{R}_{\\geq0}^{2^{n}}$ is the standard basis vector corresponding to the value $x_{\\leq n}$ . Thus $\\{v_{1},...,v_{K}\\}$ is a spanning set. ", "page_idx": 26}, {"type": "text", "text": "Any spanning set for $\\mathbb{R}^{2^{n}}$ must contain at least $2^{n}$ elements. Thus, $K\\geq2^{n}$ , and the circuit $C^{\\prime}$ must be exponentially sized. \u53e3 ", "page_idx": 26}, {"type": "text", "text": "One might attempt to remedy the situation by replacing $\\Chi$ -firstness with $\\boldsymbol{\\mathrm{X}}$ -determinism. For the general case, that however is insufficient: ", "page_idx": 26}, {"type": "text", "text": "Theorem 10 (Hardness of 2AMC with $\\mathbf{\\deltaX}$ -determinism). 2AMC is #P-hard even for decomposable, smooth, deterministic and $\\mathbf{\\deltaX}$ -deterministic circuits, and a constant-time elementwise transformation function. ", "page_idx": 26}, {"type": "text", "text": "Proof. By reduction from the counting version of number partitioning: Given positive integers $k_{1},\\ldots,k_{n}$ , count the number of index sets $S\\,\\subseteq\\,\\{1,\\ldots,n\\}$ such that $\\begin{array}{r}{\\sum_{i\\in S}k_{i}\\,=\\,\\sum_{i\\notin S}k_{i}\\,=\\,c}\\end{array}$ . That problem is known to be #P-hard [47]. Define $\\textstyle\\phi=\\bigwedge_{i=1}^{n}(X_{i}\\Leftrightarrow Y_{i})$ . Then $\\phi$ is a deterministic, $\\mathbf{\\deltaX}$ -deterministic, decomposable and smooth circuit.4 Let the inner labeling function be $\\omega^{\\prime}(y_{i})=k_{i}/c$ and $\\omega^{\\prime}(\\lnot y_{i})=1$ . Then for a fixed configuration $x$ of the variables $\\boldsymbol{X}\\dot{=}\\left\\{X_{1},\\ldots,X_{n}\\right\\}$ , we have exactly one model for $\\phi$ , whose value is $\\otimes_{i:x_{i}=1}k_{i}/c$ . If we select the inner semiring so that $\\otimes$ is addition (e.g., the max tropical semiring or log semiring), then the inner AMC problem returns $\\textstyle\\sum_{i:x_{i}=1}k_{i}/c$ , which equals 1 iff ${\\bar{S}}=\\{i:{\\bar{x}}_{i}={\\bar{1}}\\}$ is a solution to the number partitioning instance. Now, define the outer labeling function to be $\\omega=1$ , and let the transformation function be $\\tau(s)=1$ if $s=1$ and $\\tau(s)=0$ otherwise. Then the 2AMC problem with the probability semiring as outer semiring counts the number of solutions of the number partitioning instance. \u53e3 ", "page_idx": 26}, {"type": "table", "img_path": "mXlR1FLFDc/tmp/e93e1ddcd84939fb50544ba0312e63eae6c64cdc04ce6cfef2520615066dcc4b.jpg", "table_caption": ["Table 4: Tractability Conditions and Complexity for Compositional Inference Problems. We denote new results with an asterisk. "], "table_footnote": [], "page_idx": 27}, {"type": "text", "text": "B Case Studies ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this section, we provide more details about the compositional inference problems in Table 2 (reproduced in Table 4) for convenience, and prove the tractability conditions for each (Theorem 6). For all of them, we assume that we are given a Boolean formula represented as a circuit. That would usually come from knowledge compilation from some source language such as Bayesian Networks [9] or probabilistic logic programs [24]; our results thus show what properties the compiled circuit must have in order a query of interest to be tractable. Note that the problems are generally computationally hard [19, 10] on the source language, which means there do not exist compact circuits satsifying the properties in the worst-case. ", "page_idx": 27}, {"type": "text", "text": "Theorem 6 (Tractability of Compositional Queries). The results in Table 2 hold. ", "page_idx": 27}, {"type": "text", "text": "B.1 2AMC Queries ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Firstly, we consider instances of 2AMC queries. Recall the general form of a 2AMC query. Given a partition of the variables $\\pmb{V}=(\\pmb{X},\\pmb{Y})$ , a Boolean function $\\phi(X,Y)$ , outer and inner semirings $S_{X},S_{Y}$ , labeling functions $\\omega_{Y}(Y)=\\otimes_{Y_{i}\\in Y}\\omega_{Y,i}(Y_{i})$ over $\\boldsymbol{S}$ and $\\begin{array}{r}{\\omega_{X}(X)=\\bigotimes_{X_{i}\\in{\\pmb X}}\\omega_{{\\pmb X},i}(\\bar{X_{i}})}\\end{array}$ over $\\mathcal{S}^{\\prime}$ , and an elementwise mapping $\\tau_{S\\mathbf{Y}\\rightarrow S\\mathbf{X}}:S_{\\mathbf{Y}}\\rightarrow S_{X}$ , the 2AMC problem is given by: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\bigoplus_{\\pmb{x}}\\left(\\tau_{S_{\\pmb{Y}}\\rightarrow S_{\\pmb{X}}}\\left(\\bigoplus_{\\pmb{y}}[\\phi(\\pmb{x},\\pmb{y})]_{\\pmb{B}\\rightarrow S_{\\pmb{Y}}}\\otimes\\omega(\\pmb{y})\\right)\\otimes\\omega^{\\prime}(\\pmb{x})\\right)\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "By Theorem 8, any 2AMC problem is tractable if $\\phi$ is given as a smooth, decomposable, deterministic, $\\mathbf{\\deltaX}$ -deterministic, and $\\mathbf{\\deltaX}$ -first circuit $C$ . However, in some instances, we can relax these conditions, as we show shortly. ", "page_idx": 27}, {"type": "text", "text": "B.1.1 Marginal MAP ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In the Marginal Maximum A Posteriori inference (MMAP), we are given a Boolean function $\\phi(V)$ , a (unnormalized) fully factorized distribution $\\textstyle p(V)\\,=\\,\\prod_{i}p_{i}(V_{i})$ , a partition $X\\cup Y=V$ and some evidence $^e$ on $E\\subset V$ . The goal is to compute the probability of the maximum probability assignment of $\\mathbf{\\deltaX}$ consistent with $^e$ : ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\boldsymbol{x}}p(\\boldsymbol{X}=\\boldsymbol{x},\\boldsymbol{E}=\\boldsymbol{e})=\\operatorname*{max}_{\\boldsymbol{x}}\\sum_{\\boldsymbol{y}\\left\\vert=\\phi(\\boldsymbol{x},\\boldsymbol{Y})\\wedge\\boldsymbol{e}}\\prod_{i}p_{i}(\\boldsymbol{v}_{i}).\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "To cast it as a 2AMC problem, take the inner semiring $\\mathcal{S}_{Y}$ to be the probability semiring and define the inner labelling function to assign $\\omega_{Y}(Y_{i})\\,=\\,0$ if $Y_{i}\\,\\in\\,E$ and $Y_{i}$ is inconsistent with $^e$ and $\\omega_{\\pmb Y}(Y_{i})\\,=\\,p_{i}(Y_{i})$ otherwise. The outer semiring is the $\\mathrm{(max,\\cdot)}$ semiring with labeling function $\\omega_{\\pmb{X}}({\\cal X}_{i})=1$ . The elementwise mapping function $\\tau_{S_{Y}\\rightarrow S_{X}}(a)=a$ is the identity function. ", "page_idx": 27}, {"type": "text", "text": "The proof of the tractability conditions follows Theorem 8, except that we note that the mapping function $\\tau_{S\\mathbf{Y}}\\!\\to\\!S_{\\mathbf{X}}$ from the outer to inner semiring satisifies (Multiplicative). As such, we do not need the (Prod $0/1$ ) circuit property, which was the reason we needed the $\\mathbf{\\deltaX}$ -firstness condition. ", "page_idx": 27}, {"type": "text", "text": "B.1.2 Probabilistic Answer Set Programming (PASP) ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "The Probabilistic Answer Set Programming Inference (PASP) query takes a Boolean formula $\\phi(V)$ , a partition $X\\cup Y=V$ , a (unnormalized) fully factorized distribution $\\begin{array}{r}{p(\\boldsymbol{X})=\\prod_{i}p(X_{i})}\\end{array}$ , and query variable and value $\\{Q=q\\}$ , for some $Q\\in V$ . The goal is to compute: ", "page_idx": 28}, {"type": "equation", "text": "$$\np(Q=q)=\\sum_{x}\\left(\\prod_{i}p(X_{i})\\right)\\sum_{y\\mid=\\phi(x,Y)\\land q}p^{*}(y|x).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "The function $p^{*}(\\mathbf{Y}|X)$ depends on the semantics adopted. Let $\\mathrm{mod}(Y|X):=\\{\\pmb{y}:\\phi(X,\\pmb{y})\\}$ be the set of assignments of $\\mathbf{Y}$ such that $\\phi(X,\\cdot)$ is true. In the Maximum Entropy Semantics (MaxEnt) [6, 51, 45], one distributes the probability mass $p(X)$ uniformly over the models of $\\phi$ consistent with $\\mathbf{\\deltaX}$ , i.e. $\\begin{array}{r}{p^{*}(\\pmb{y}|\\pmb{X})=\\frac{1}{|\\mathrm{mod}(\\pmb{Y}|\\pmb{X})|}}\\end{array}$ . On the other hand, in the Credal Semantics [33, 14] (Max-Credal), one places all probability mass $p(X)$ on some assignment $\\textit{\\textbf{y}}$ of $\\mathbf{Y}$ consistent with $\\mathbf{\\deltaX}$ and $q$ . To obtain an upper bound on the query probability regardless of which $\\textit{\\textbf{y}}$ is chosen, one sets $p^{*}(\\pmb{y}|\\pmb{X}):=1$ for all $\\textit{\\textbf{y}}$ if there exists an assignment $\\pmb{Y}\\in\\phi(\\pmb{X},\\pmb{Y})\\wedge q$ , and $p^{*}(\\pmb{Y}|\\pmb{X})=0$ otherwise. ", "page_idx": 28}, {"type": "text", "text": "The 2AMC formulation of the problem uses the probability semiring as outer semiring $\\mathcal{S}_{\\mathbf{X}}$ , with labeling function $\\omega_{\\mathbf{X}}(X_{i})=p(\\mathbf{\\bar{\\boldsymbol{X}}}_{i})$ for $X_{i}\\in X$ . ", "page_idx": 28}, {"type": "text", "text": "\u2022 In the (MaxEnt) semantics, for the inner semiring, we take as the semiring of pairs of naturals ${\\mathcal{S}}_{\\mathbf{Y}}\\,=\\,(\\mathbb{N}^{2},+,\\cdot,(0,0),(1,1))$ , with coordinatewise addition and multiplication. The inner labeling function sets $\\omega_{Y}(Q)\\,=\\,(\\mathbb{1}_{Q=q},1)$ , and sets $\\omega_{Y}(Y_{i})\\,=\\,(1,1)$ for all other variables $Y_{i}\\in Y$ . The mapping function is defined by $\\tau_{S_{\\mathbf{Y}}\\rightarrow S_{\\mathbf{X}}}((a,b))=a/b$ (with $0/0=0)$ ).   \n\u2022 In the (Max-Credal) semantics, we simply set the inner semiring to be the Boolean semiring $\\boldsymbol{S}_{\\boldsymbol{Y}}=\\boldsymbol{B}$ . The inner labeling function sets $\\omega_{Y}(Q)={\\binom{\\top}{\\bot}}$ \u22a4 if Q = q , and sets \u03c9Y (Yi) = $\\intercal$ for all other variables $Y_{i}~\\in~Y$ . The mapping function is defined by $\\tau_{S\\mathbf{\\gamma}\\rightarrow S_{\\mathbf{\\pmb{x}}}}(a)\\,=$ $[\\![a]\\!]_{S_{Y}\\rightarrow S_{X}}$ . ", "page_idx": 28}, {"type": "text", "text": "As with marginal MAP, we can see that in both cases, the mapping function $\\tau_{S\\mathbf{Y}}\\!\\to\\!S_{\\mathbf{X}}$ satisfies (Multiplicative), so $\\mathbf{\\deltaX}$ -firstness of the circuit is not required. In particular, for (MaxEnt) we have \u03c4 $\\begin{array}{r}{s_{Y}\\neg\\neg s_{X}\\left((a,b)\\otimes(c,d)\\right)=\\tau_{S Y}\\neg s_{X}\\left((a\\cdot c,b\\cdot d)\\right)=\\frac{a\\cdot c^{*}}{b\\cdot d}=\\frac{a}{b}\\cdot\\frac{c}{d}=\\tau_{S Y}\\neg s_{X}\\left(a,b\\right)\\cdot\\tau_{S_{Y}\\to S_{X}}\\left(c,d\\right)=\\tau_{S Y}\\wedge\\tau_{S_{Y}\\to S_{X}}\\left(d,b\\right).}\\end{array}$ $\\tau_{S_{\\mathbf{Y}}\\rightarrow S_{\\mathbf{X}}}(a,b)\\otimes\\tau_{S_{\\mathbf{Y}}\\rightarrow S_{\\mathbf{X}}}(c,d)$ (this holds also if $(a,\\tilde{b})=(0,\\tilde{0})$ and/or $(c,d)=(0,0))$ . Meanwhile, for (Max-Credal) we have $\\tau_{S_{Y}\\to S_{X}}(a\\otimes b)=\\tau_{S_{Y}\\to S_{X}}(a\\wedge b)=[a\\wedge b]_{S_{Y}\\to S_{X}}=[a]_{S_{Y}\\to S_{X}}$ \u00b7 $\\|b\\|_{S_{Y}\\rightarrow S_{X}}=\\tau_{S_{Y}\\rightarrow S_{X}}(a)\\cdot\\tau_{S_{Y}\\rightarrow S_{X}}(b)=\\tau_{S_{Y}\\rightarrow S_{X}}(a)\\otimes\\tau_{S_{Y}\\rightarrow S_{X}}(b)$ . ", "page_idx": 28}, {"type": "text", "text": "For the (Max-Credal) semantics, we note additionally since $\\mathcal{S}_{Y}$ is just the Boolean semiring, we do not need determinism in Line 1 of Algorithm 5. So the only conditions required are smoothness, decomposability, and $\\mathbf{\\deltaX}$ -determinism. ", "page_idx": 28}, {"type": "text", "text": "B.1.3 Same-Decision Probability ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "In the Same Decision Probability (SDP) query [37], we are given a Boolean formula $\\phi(V)$ , a fully factorized distribution $\\begin{array}{r}{p(V)=\\prod_{i}p(V_{i})}\\end{array}$ , a partition $\\mathbf{\\deltaX}$ , $\\{Y\\}$ of $V$ , a query $\\{Y=y\\}$ , some evidence $^e$ on a subset $E\\subseteq X$ of var iables and a threshold value $T\\,\\in\\,(0,1]$ . The goal is to compute a confidence measure on some threshold-based classification made with the underlying probabilistic model: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sum_{\\mathbf{x}}p(\\mathbf{\\boldsymbol{x}}|e)\\mathbb{1}_{p(Y=y|\\mathbf{\\boldsymbol{x}},e)\\geq T},\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "To cast this as a 2AMC instance, we use the inner semiring $S^{\\prime}\\ =\\ (\\mathbb{R}_{\\geq0}^{2},+,\\cdot,(0,0),(1,1))$ , with coordinate-wise addition and multiplication. The inner labeling function assigns $\\omega_{Y}(Y)=$ $(p(Y)\\mathbb{1}_{Y=y},p(Y))$ . The outer semiring is the probability semiring and the mapping $\\tau_{S\\mathbf{Y}}\\!\\to\\!S_{\\mathbf{X}}$ from inner to outer semirings is $\\tau_{S_{\\mathbf{Y}}\\rightarrow S_{\\mathbf{X}}}(({\\bar{a}},b))={\\mathbb{[}}a\\geq b T{\\mathbb{\\bar{]}}}$ . Last, the outer labeling function assigns $\\omega_{\\pmb{X}}(X_{i})=\\mathbb{1}_{X_{i}\\mid=e}$ if $X_{i}\\in E$ , and $\\omega_{\\pmb{X}}(X_{i})=p(X_{i})$ otherwise. ", "page_idx": 28}, {"type": "text", "text": "Unlike marginal MAP and PASP inference, there is no special structure in SDP that allows us to relax the general tractability conditions for 2AMC. However, it is still a 2AMC instance, and we have the tractability conditions from Theorem 8. In particular this justifies the use of $\\mathbf{\\deltaX}$ -constrained sentential decision diagrams for this problem. ", "page_idx": 28}, {"type": "text", "text": "B.2 Causal Inference ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "In Section 4.2, we discussed computing causal interventional distributions. In particular, in the backdoor and frontdoor cases, we had the following formulae: ", "page_idx": 29}, {"type": "equation", "text": "$$\np(\\pmb{y}|d o(\\pmb{x}))=\\sum_{z}p(z)p(\\pmb{y}|\\pmb{x},z),\n$$", "text_format": "latex", "page_idx": 29}, {"type": "equation", "text": "$$\np(\\pmb{y}|d o(\\pmb{x}))\\!=\\!\\sum_{\\pmb{z}}p(\\pmb{z}|\\pmb{x})\\sum_{\\pmb{x}^{\\prime}}p(\\pmb{x}^{\\prime})p(\\pmb{y}|\\pmb{x}^{\\prime},\\pmb{z}).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "B.2.1 Backdoor query ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "The backdoor query can be written as a compositional query as follows: ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathtt{B A C K D O D R}(p;x,y):=\\bigoplus_{z}\\Big(\\big(\\bigoplus_{x,y}p(v)\\big)\\otimes p(v)\\otimes\\tau_{-1}\\Big(\\bigoplus_{y}p(v)\\Big)\\Big).\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $V=(X,Y,Z)$ , and $\\tau_{-1}(a)={\\binom{a^{-1}}{0}}\\quad{\\mathrm{if~}}a\\neq0.$ . Note that $\\tau_{-1}$ satisfies (Multiplicative), and so for this mapping to be tractable we just need the circuit it is applied to to be deterministic. ", "page_idx": 29}, {"type": "text", "text": "Assume that $p(V)$ is given as a smooth, structured decomposable, and $(X\\cup Z)$ -deterministic circuit (over the probabilistic semiring). We now show that this query is tractable, by showing that each operator in the composition is tractable. For readability, we label each circuit constructed with the function that it represents $\\textstyle({\\overline{{\\lfloor\\log\\tt{d}}}})$ . ", "page_idx": 29}, {"type": "text", "text": "$\\boxed{p(X,Z)}\\,C_{1}(X,Z):=\\mathtt{A G G}(C,Y)$ is tractable by smoothness and decomposability. By (5.1) in Table 3, since $Y\\cap(X\\cup Z)=\\emptyset$ , $C_{1}$ is $(X\\cup Z)$ -deterministic (i.e. deterministic). $\\begin{array}{r}{\\bullet\\left\\lceil{\\frac{1}{p(X,Z)}}\\right\\rceil C_{2}(X,Z):=\\mathtt{M A P P I N G}(C_{1},\\tau_{-1})}\\end{array}$ is tractable since $C_{1}$ is deterministic.   \n$\\left[p(Y|X,Z)\\right]C_{3}(X,Y,Z)\\;:=\\;\\mathsf{P R O D-S C M P}(C(X,Y,Z),C_{2}(X,Z)).$ . $C$ is $(X\\cup Z)$ - support-compatible with itself as it is $(X\\cup Z)$ -deterministic $\\implies C$ is also $(X\\cup Z)$ - support-compatible with $C_{1}$ by $(5.9)\\implies C$ is also $(X\\cup Z)$ -support-compatible with $C_{2}$ by (5.11). As $C$ and $C_{2}$ share variables $(X\\cup Z)$ , this means they are support-compatible. Thus this product is tractable in linear time.   \n\u2022 $\\boxed{p(\\boldsymbol{Z})}\\boxed{C_{4}(\\boldsymbol{Z}):=\\mathtt{A G G}(\\boldsymbol{C},\\boldsymbol{X}\\cup\\boldsymbol{Y})}$ is tractable by smoothness and decomposability. $\\boxed{p(Z)p(Y|X,Z)}\\boxed{C_{5}(X,Y,Z):=\\mathtt{P R O D-C M P}(C_{4},C_{3})}$ . $C$ is $V$ -compatible with itself (structured decomposable) $\\implies C$ is $_{z}$ -compatible with itself by Proposition $1\\implies C$ is also $Z$ -compatible with $C_{4}$ by $(5.5)\\implies C_{4}$ is $_{z}$ -compatible with $C_{1}$ by $(5.5)\\implies$ $C_{4}$ is $Z$ -compatible with $C_{2}$ by $(5.8)\\implies C_{4}$ is $_{z}$ -compatible with $C_{3}$ by (5.6). Since $C_{4}$ and $C_{3}$ share variables $Z$ , this means they are compatible and so this product is tractable in quadratic time.   \n\u2022  z p(z)p(Y |X, z) $C_{6}(X,Y)=\\tt A G G(C_{5},Z)$ is tractable by smoothness and decomposability. ", "page_idx": 29}, {"type": "text", "text": "Thus, we have recovered the tractability conditions derived by [49], with the same complexity of $O(|C|^{2})$ (induced by the compatible product to construct $C_{5}$ ). However, we also have an alternative tractability condition. Suppose that $C$ were additionally $Z$ -deterministic, but not necessarily structured decomposable. Then we could replace the derivation of $C_{5}$ above with the following: ", "page_idx": 29}, {"type": "text", "text": "$\\boxed{p(\\pmb{Z})p(\\pmb{Y}|\\pmb{X},\\pmb{Z})}\\boxed{C_{5}(\\pmb{X},\\pmb{Y},\\pmb{Z})}\\::=\\:\\mathtt{P R O D-S C M P}(C_{4},C_{3}).$ . $C$ is $Z$ -support-compatible with itself as it is $\\vec{Z}$ -deterministic $\\implies C$ is also $Z$ -support-compatible with $C_{4}$ by (5.9) $\\implies C_{4}$ is $Z$ -support-compatible with $C_{1}$ by $(5.9)\\implies C_{4}$ is $Z$ -compatible with $C_{2}$ by $(5.11)\\implies C_{4}$ is $Z$ -compatible with $C_{3}$ by (5.10). Since $C_{4}$ and $C_{3}$ share variables $Z$ , this means they are compatible and so this product is tractable in linear time. ", "page_idx": 29}, {"type": "text", "text": "In this case, the overall complexity is also reduced to $O(|C|)$ . ", "page_idx": 29}, {"type": "text", "text": "B.2.2 Frontdoor query ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Now, consider the frontdoor case. In this case, we have the following compositional query: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname{FRONTDOOR}(p;x,y,z)=\\bigoplus_{z}\\Bigl(\\Bigl(\\bigoplus_{y}p(v)\\Bigr)\\otimes\\tau_{-1}\\Bigl(\\bigoplus_{y,z}p(v)\\Bigr)\\otimes\\operatorname{BACKDOOR}(p;z,y)\\Bigr)\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Assume that $p(V)$ is given as a smooth, structured decomposable, $\\mathbf{\\deltaX}$ -deterministic, and $(X\\cup Z)$ - deterministic circuit (over the probabilistic semiring). We continue the analysis from the backdoor case: ", "page_idx": 30}, {"type": "text", "text": "$\\boxed{p(\\boldsymbol{X})}\\,C_{7}(\\boldsymbol{X}):=\\mathtt{A G G}(C,Y\\cup Z)$ is tractable by smoothness and decomposability. By (5.1) in Table 3, since $(Y\\cup Z)\\cap X=\\varnothing$ , $C_{7}$ is $\\mathbf{\\deltaX}$ -deterministic (i.e. deterministic). p $\\begin{array}{r}{\\overline{{\\frac{1}{({\\boldsymbol X})}}}\\,\\Big|\\,C_{8}({\\boldsymbol X}):=\\mathtt{M A P P I N G}(C_{7},\\tau_{-1})}\\end{array}$ is tractable since $C_{7}$ is deterministic.   \n$\\boxed{p(\\boldsymbol{Z}|\\boldsymbol{X})}\\boxed{C_{9}(\\boldsymbol{X},\\boldsymbol{Z}):=\\mathtt{P R O D-S C M P}(C_{8},C_{1})}.$ . $C$ is $\\mathbf{\\deltaX}$ -support-compatible with itself as it is $\\overline{{X}}$ -deterministic $\\implies\\ C$ is $\\mathbf{\\deltaX}$ -support-compatible with $C_{1}$ by (5.9) $\\mathrm{~\\boldmath~\\Omega~}\\rightarrow\\mathrm{~\\boldmath~\\it~C_{1}~}$ is $\\mathbf{\\deltaX}$ -support-compatible with $C_{7}$ by $(5.9)\\implies C_{1}$ is $\\mathbf{\\deltaX}$ -support-compatible with $C_{8}$ by (5.11). Thus this product is tractable in linear time.   \n$\\begin{array}{r}{\\boxed{\\sum_{\\mathbfit{x}}p(\\mathbfit{x})p(\\mathbfcal{Y}|\\mathbfit{x},\\mathbf Z)}}\\end{array}$ $C_{10}(Y,Z)$ . This is just like $C_{6}$ , but with variables $\\mathbf{\\deltaX}$ and $_{z}$ swapped. Thus it is tractable for a smooth, $\\mathbf{\\deltaX}$ -deterministic and $(X\\cup Z)$ -deterministic circuit in linear time.   \n$\\begin{array}{r}{\\Big\\cdot\\Big[p(Z|X)\\sum_{x^{\\prime}}p(x^{\\prime})p(Y|x^{\\prime},Z)\\Big]C_{11}(X,Y,Z)\\,:=\\,\\mathtt{P R O D-C M P}(C_{9},C_{10}).}\\end{array}$ We can chain applications of (5.5), (5.7) and (5.8) in a similar way to the other steps to show that $C_{9},C_{10}$ are $_{z}$ -compatible (i.e. compatible), so this product is tractable in quadratic time.   \n\u2022  z p(z|X) x\u2032 p(x\u2032)p(Y |x\u2032, z) $C_{12}(X,Y)\\;:=\\;\\mathsf{A G G}(C_{11};Z)$ . This is tractable by smoothness and decomposability. ", "page_idx": 30}, {"type": "text", "text": "Thus, this algorithm has complexity $O(|C|^{2})$ , as opposed to the $O(|C|^{3})$ complexity algorithm in [49]. The key difference is that we exploit support compatibility for a linear time product when constructing $C_{10}$ . ", "page_idx": 30}, {"type": "text", "text": "B.3 Other Problems ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "B.3.1 Most Frugal Explanation ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "In [31], the most frugal explanation (MFE) query was introduced. Given a partition of variables $V$ into $(H,I^{+},I^{-},E)$ , some evidence $e\\in\\mathrm{Assign}(E)$ , and a probability distribution $p(V)$ , the MFE query asks for the following: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{h}\\sum_{i^{-}}\\mathbb{1}[h\\in\\arg\\operatorname*{max}_{h^{\\prime}}p(h^{\\prime},i^{-},e)]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "In words, we want the explanation (assignment to $\\pmb{H}$ ) that is the most probable for the most number of assignments to $I^{-}$ , when $I^{+}$ is marginalized out. We can rewrite as follows: ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{h}\\sum_{i^{-}}\\mathbb{1}\\left[\\frac{p(h,i^{-},e)}{\\operatorname*{max}_{h^{\\prime}}p(h^{\\prime},i^{-},e)}=1\\right]\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "This can be written as a compositional query as follows. ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\bigoplus_{h}\\tau_{S^{\\prime\\prime\\prime}\\to S^{\\prime}}\\bigoplus_{i^{-}}\\tau_{S^{\\prime\\prime}\\to S^{\\prime\\prime\\prime}}\\left(\\tau_{-1}\\left(\\tau_{S^{\\prime}\\to S^{\\prime\\prime}}\\left(\\bigoplus_{h^{\\prime}}\\tau_{S\\to S^{\\prime}}(p(h^{\\prime},i^{-},e))\\right)\\right)\\otimes p(h,i^{-},e)\\right)\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "where $\\boldsymbol{S}$ is the probability semiring, $S^{\\prime}$ is the $(\\operatorname*{max},\\cdot)$ -semiring, $S^{\\prime\\prime}$ is $([0,1],+,\\cdot,0,1)$ (i.e. the probability semiring with domain $[0,1];$ ), and $S^{\\prime\\prime\\prime}$ is the counting semiring $(\\mathbb{N},+,\\cdot,0,1)$ , and the mapping functions are defined as follows: ", "page_idx": 30}, {"type": "equation", "text": "$$\n{\\begin{array}{r l}&{{\\bullet}\\ \\tau_{S\\to S^{\\prime}}(a)=a}\\\\ &{=\\ \\tau_{S^{\\prime}\\to S^{\\prime\\prime}}(a)=a}\\\\ &{=\\ \\tau_{-1}(a)={\\left\\{\\begin{array}{l l}{a^{-1}}&{{\\mathrm{if~}}a\\neq0}\\\\ {0}&{{\\mathrm{if~}}a=0}\\end{array}\\right.}}\\\\ &{\\bullet\\ \\tau_{S^{\\prime\\prime}\\to S^{\\prime\\prime\\prime}}(a)=\\mathbb{1}_{a=1}}\\\\ &{=\\ \\tau_{S^{\\prime\\prime\\prime}\\to S^{\\prime}}(a)=a}\\end{array}}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Suppose we are given a probabilistic circuit representing $p(\\pmb{H},\\pmb{I}^{-},\\pmb{e})$ . While this query appears extremely intimidating at first glance, we note that the only operators we need to consider are the mappings and single product. Note that all of these mappings satisfy (Multiplicative) $(\\tau_{S^{\\prime\\prime}\\rightarrow S^{\\prime\\prime\\prime}}$ because the domain of $S^{\\prime\\prime}$ is $[0,1]$ so $\\tau_{S^{\\prime\\prime}\\rightarrow S^{\\prime\\prime\\prime}}(a\\cdot b)=1$ iff $a=b=1)$ ); thus the mappings are tractable if the input circuits are deterministic. By checking the scopes of the inputs to each mapping, we can see that $(H\\cup I^{-})$ -determinism, $I^{-}$ -determinism, and $\\pmb{H}$ -determinism suffices. This also enables tractability of the product in linear time by support compatibility. ", "page_idx": 31}, {"type": "text", "text": "No tractability conditions for exact inference for this query were previously known. While the motivation behind the MFE query is as a means of approximating marginal MAP, and so this exact algorithm is not practically useful in this case, this example illustrates the power of the compositional framework to tackle even very complex queries. ", "page_idx": 31}, {"type": "text", "text": "B.3.2 Reverse MAP ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Recently, in [27], the reverse-MAP query was introduced, defined by: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\boldsymbol{X}}p(\\boldsymbol{e}_{1}|\\boldsymbol{X},\\boldsymbol{e}_{2})\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where the variables are partitioned as $V=(E_{1},E_{2},X,H)$ . In our compositional framework, this can be written as: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\bigoplus_{x}\\tau_{\\mathcal{P}\\rightarrow\\mathcal{M}}\\Big(\\bigoplus_{h}p(e_{1},x,e_{2},h)\\otimes\\tau_{-1}\\big(\\bigoplus_{h,e_{1}^{\\prime}}p(e_{1}^{\\prime},x,e_{2},h)\\big)\\Big)\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Here, the mapping $\\tau_{-1}$ is tractable if the circuit for $p$ is $\\mathbf{\\deltaX}$ -deterministic. Since $p$ is $\\mathbf{\\deltaX}$ -deterministic, it is $\\mathbf{\\deltaX}$ -support-compatible with itself; chaining this with (5.9) and (5.11) in Table 3, the inputs to the product are $\\mathbf{\\deltaX}$ -compatible; since they have scope $\\mathbf{\\deltaX}$ , this means the product is tractable by support-compatibility. The resulting circuit remains $\\mathbf{\\deltaX}$ -deterministic (i.e. deterministic as the scope is $\\mathbf{\\deltaX}$ ), which means that the mapping $\\tau_{\\mathcal{P}\\rightarrow\\mathcal{M}}$ from the probability to $(\\operatorname*{max},\\cdot)$ semiring is tractable. Thus, this query is tractable for smooth, decomposable and $\\mathbf{\\deltaX}$ -deterministic circuits in linear time (same as derived by the authors). ", "page_idx": 31}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: The abstract and introduction reference the results in the rest of the paper. Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 32}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: Yes, in the conclusion we discuss the fact that while our results provide simple and general sufficient tractability conditions, these are not necessary conditions. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 32}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 32}, {"type": "text", "text": "Justification: Yes, assumptions are laid out in the statements of the results, and proofs are provided in the supplementary material. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 33}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: This paper does not include experiments. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 33}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not include experiments requiring code. Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 34}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not contain experiments. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 34}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: This paper does not contain experiments. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 34}, {"type": "text", "text": "", "page_idx": 35}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: This paper does not contain experiments. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 35}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: The paper does conform to the NeurIPS Code of Ethics. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 35}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 35}, {"type": "text", "text": "Answer: [No] ", "page_idx": 35}, {"type": "text", "text": "Justification: This paper presents foundational research that is not tied to any particular application/deployment; there are no particular societal impacts that we feel need to be highlighted. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 35}, {"type": "text", "text": "", "page_idx": 36}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper does not propose to release any data or models that would pose such a risk. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 36}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: This paper does not use existing assets. ", "page_idx": 36}, {"type": "text", "text": "Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. ", "page_idx": 36}, {"type": "text", "text": "\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 37}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 37}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 37}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 37}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 37}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 37}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 37}]