[{"figure_path": "tDvFa5OJyS/tables/tables_7_1.jpg", "caption": "Table 1: Generalization error (NLL, RMSE, and wall-clock time) on UCI benchmark datasets. The table shows the best results for all methods across learning rate sweeps, averaged across five random seeds. We report the epoch where each method obtained the lowest average test NLL, and all performance metrics (NLL, RMSE, and wall-clock runtime) are reported for this epoch. Highlighted in bold and color are the best approximate methods per metric (difference > 1 standard deviation).", "description": "This table presents a comparison of different Gaussian process approximation methods on six UCI regression datasets.  For each dataset and method, it reports the negative log-likelihood (NLL), root mean squared error (RMSE), and average runtime, all evaluated at the epoch with the best average test NLL across five random seeds and multiple learning rates.  The best performing methods for each metric are highlighted.", "section": "5 Experiments"}, {"figure_path": "tDvFa5OJyS/tables/tables_22_1.jpg", "caption": "Table 1: Generalization error (NLL, RMSE, and wall-clock time) on UCI benchmark datasets. The table shows the best results for all methods across learning rate sweeps, averaged across five random seeds. We report the epoch where each method obtained the lowest average test NLL, and all performance metrics (NLL, RMSE, and wall-clock runtime) are reported for this epoch. Highlighted in bold and color are the best approximate methods per metric (difference > 1 standard deviation).", "description": "This table presents a comparison of different Gaussian process approximation methods on several UCI benchmark datasets.  The metrics used are the negative log-likelihood (NLL), root mean squared error (RMSE), and wall-clock time.  Results are averaged over multiple random seeds and learning rates, showcasing the best performance of each method in terms of NLL. The best-performing methods for each metric, considering standard deviation, are highlighted.", "section": "5 Experiments"}, {"figure_path": "tDvFa5OJyS/tables/tables_22_2.jpg", "caption": "Table 1: Generalization error (NLL, RMSE, and wall-clock time) on UCI benchmark datasets. The table shows the best results for all methods across learning rate sweeps, averaged across five random seeds. We report the epoch where each method obtained the lowest average test NLL, and all performance metrics (NLL, RMSE, and wall-clock runtime) are reported for this epoch. Highlighted in bold and color are the best approximate methods per metric (difference > 1 standard deviation).", "description": "This table presents a comparison of different Gaussian process (GP) approximation methods on six UCI benchmark datasets for regression. The performance is evaluated using three metrics: negative log-likelihood (NLL), root mean squared error (RMSE), and wall-clock runtime.  The best results for each method are shown across various learning rates, averaged over five runs with different random seeds.  The table highlights the best performing approximate methods for each metric, indicating whether the difference from the best is statistically significant (more than one standard deviation).", "section": "5 Experiments"}, {"figure_path": "tDvFa5OJyS/tables/tables_24_1.jpg", "caption": "Table 1: Generalization error (NLL, RMSE, and wall-clock time) on UCI benchmark datasets. The table shows the best results for all methods across learning rate sweeps, averaged across five random seeds. We report the epoch where each method obtained the lowest average test NLL, and all performance metrics (NLL, RMSE, and wall-clock runtime) are reported for this epoch. Highlighted in bold and color are the best approximate methods per metric (difference > 1 standard deviation).", "description": "This table presents a comparison of the generalization performance of different Gaussian process models on six UCI benchmark datasets.  The metrics used are the negative log-likelihood (NLL), root mean squared error (RMSE), and wall-clock runtime.  The best performing model for each metric is highlighted.  Results are averaged across five random seeds and different learning rates.", "section": "5 Experiments"}]