{"references": [{"fullname_first_author": "Victor Garcia Satorras", "paper_title": "E(n) equivariant graph neural networks", "publication_date": "2021-02-22", "reason": "This paper introduces the Equivariant Graph Neural Networks (EGNNs) architecture, which is central to the methodology of the main paper."}, {"fullname_first_author": "John Schulman", "paper_title": "Proximal policy optimization algorithms", "publication_date": "2017-07-06", "reason": "This paper details the Proximal Policy Optimization (PPO) algorithm, the primary reinforcement learning algorithm used in the experiments of the main paper."}, {"fullname_first_author": "Ryan Lowe", "paper_title": "Multi-agent actor-critic for mixed cooperative-competitive environments", "publication_date": "2017-12-01", "reason": "This paper introduces the Multi-Agent Particle Environment (MPE), one of the primary benchmark environments used to evaluate the proposed method."}, {"fullname_first_author": "Benjamin Ellis", "paper_title": "SMACv2: An improved benchmark for cooperative multi-agent reinforcement learning", "publication_date": "2023-01-01", "reason": "This paper introduces StarCraft Multi-Agent Challenge v2 (SMACv2), another key benchmark environment used in the paper's experiments."}, {"fullname_first_author": "Elise van der Pol", "paper_title": "MDP homomorphic networks: Group symmetries in reinforcement learning", "publication_date": "2020-12-06", "reason": "This paper lays the theoretical groundwork for applying equivariance to Markov Decision Processes (MDPs), providing a foundation for the main paper's approach."}]}