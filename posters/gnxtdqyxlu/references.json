{"references": [{"fullname_first_author": "Mahmoud Assran", "paper_title": "Self-supervised learning from images with a joint-embedding predictive architecture", "publication_date": "2023", "reason": "This paper is foundational for the self-supervised learning techniques used in the PIVOT-R model, improving its efficiency and performance."}, {"fullname_first_author": "Anas Awadalla", "paper_title": "OpenFlamingo: An open-source framework for training large autoregressive vision-language models", "publication_date": "2023", "reason": "As the foundation model for PIVOT-R, OpenFlamingo's architecture and training techniques significantly impact the performance and generalizability of the overall system."}, {"fullname_first_author": "Anthony Brohan", "paper_title": "RT-1: Robotics Transformer for real-world control at scale", "publication_date": "2022", "reason": "RT-1 provides a strong baseline for comparison, showcasing the advancements made by PIVOT-R in terms of efficiency and performance on robotic manipulation tasks."}, {"fullname_first_author": "Pengzhen Ren", "paper_title": "Surfer: Progressive reasoning with world models for robotic manipulation", "publication_date": "2023", "reason": "Surfer, a state-of-the-art model, provides a key benchmark against which PIVOT-R's performance is measured, highlighting the improvements achieved."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021", "reason": "This paper's vision-language model is crucial for the primitive action parsing component of PIVOT-R, enabling the system to interpret and respond to high-level user instructions."}]}