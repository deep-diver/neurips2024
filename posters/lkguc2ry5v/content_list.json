[{"type": "text", "text": "Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Andrew Bennett\\* Morgan Stanley andrew.bennett@morganstanley.com ", "page_idx": 0}, {"type": "text", "text": "Nathan Kallus\\* Cornell University kallus@cornell.edu ", "page_idx": 0}, {"type": "text", "text": "Miruna Oprescu\\* Wen Sun\\* Kaiwen Wang\\* Cornell University Cornell University Cornell University amo78@cornell.edu ws455@cornell.edu kw437@cornell.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the evaluation of a policy under best- and worst-case perturbations to a Markov decision process (MDP), using transition observations from the original MDP, whether they are generated under the same or a different policy. This is an important problem when there is the possibility of a shift between historical and future environments, e.g. due to unmeasured confounding, distributional shift, or an adversarial environment. We propose a perturbation model that allows changes in the transition kernel densities up to a given multiplicative factor or its reciprocal, extending the classic marginal sensitivity model (MSM) for single timestep decision-making to infinite-horizon RL. We characterize the sharp bounds on policy value under this model - i.e., the tightest possible bounds based on transition observations from the original MDP - and we study the estimation of these bounds from such transition observations. We develop an estimator with several important guarantees: it is semiparametrically efficient, and remains so even when certain necessary nuisance functions, such as worst-case Q-functions, are estimated at slow, nonparametric rates. Our estimator is also asymptotically normal, enabling straightforward statistical inference using Wald confidence intervals. Moreover, when certain nuisances are estimated inconsistently, the estimator still provides valid, albeit possibly not sharp, bounds on the policy value. We validate these properties in numerical simulations. The combination of accounting for environment shifts from train to test (robustness), being insensitive to nuisancefunction estimation (orthogonality), and addressing the challenge of learning from finite samples (inference) together leads to credible and reliable policy evaluation. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Offline policy evaluation (OPE) from historical data is crucial in domains where active, on-policy experimentation is costly, risky, unethical, or otherwise operationally infeasible. Relevant domains range from medicine to finance and recommendation systems. However, whenever historical data is used to study future behavior, there is a concern of non-stationarity - shift between the environment generating the data (training environment) and the environment in which a policy will be deployed (test environment). This may occur, e.g., due to general distributional shifts in the environment over time, unobserved confounding in the observed historical data, or adversarial elements of the environment (such as other agents) that may react when the agent is deployed. While standard OPE in offline reinforcement learning (ORL) accounts for the change between the logging and evaluation policies, it may overlook the fact that the Markov decision process (MDP) too has changed. While this issue is particularly critical in high-stakes domains, it is broadly appealing to understand how value shifts across different environments in any application domain. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Robust MDPs [34, 56] model unknown environments by allowing an adversary to choose from any one environment in a set. Therefore, they offer a natural model for unknown environment shifts by simply considering all environments to which we could possibly shift. A variety of work addresses questions such as planning in a known robust MDP [30, 51, 80] as well as online learning [6, 79]. Here we focus on a purely statistical estimation question: given observations of transitions from some unknown transition kernel, we wish to estimate the worst-case (or best-case) value of a given evaluation policy in a robust MDP, defined by a set of MDPs whose transition functions are centered around the observed transition kernel. ", "page_idx": 1}, {"type": "text", "text": "This setting captures the previously studied unconfounded robust OPE problem [73], where the observed transition kernel corresponds to an MDP, and the observed transitions are the result of applying some logging policy within this MDP. In such cases, the goal is to estimate policy values that are robust to future changes in the MDP dynamics. However, our setting is more general in that it also captures problems where the observed transitions are confounded by some unobserved variables, in which case they do not correspond to observations from the transition kernel of an MDP. In this case, the robust MDP and the robust policy value estimates are designed to account for worst-case (or best-case) impact of this confounding bias. In either case, as in ORL, we emphasize that we do not know the observational MDP, and can only access it via a sample of transitions. Furthermore, even in the simple case with no unmeasured confounding, in a notable departure from standard ORL, the problem can be difficult even if the logging and evaluation policies are the same (the usually easy on-policy setting), since the policy can induce very different visitation distributions in the original and perturbedMDPs. ", "page_idx": 1}, {"type": "text", "text": "Such robust offline evaluation from transition data was considered in recent work [12, 59]. We build on this recent work by focusing the question of statistically efficient and robust estimation of the sharp bounds (i.e., the tightest possible given the data). Previous work focused on evaluation using only the Q-function under the worst-case environment (in some cases under a relaxation of the adversary, leading to loose bounds). Thus, any error in its estimation translates directly to error in evaluation. In other words, fexible nonparametric modeling of this function can mean slow rates for estimated bounds and a lack semiparametric efficiency. Moreover, without a clear understanding of the noise in the estimates, we cannot add confidence bands to the bounds, leading to bounds that are too tight. ", "page_idx": 1}, {"type": "text", "text": "We address these challenges by developing an orthogonalized estimation method that combines several nuisance functions: the worst-case $Q$ -function, the state-visitation frequency in the worst-case environment, and a threshold function characterizing the worst-case transition kernel. Our first key result is that, to first order, our estimator behaves as a sample average using the true values of these functions without having to estimate them at all, provided we just estimate them at certain slow nonparametric rates. This ensures we not only have a $\\sqrt{n}$ -rate of estimation even when nuisances are estimated more slowly, but also that our estimator is asymptotically normal. This allows for the construction of confidence bands on the bounds, providing assurance that the true bound is captured. We further show that our asymptotic variance is in fact the minimum variance among all regular and asymptotically linear (RAL) estimators, ensuring semiparametric efficiency. Our second key result is that even if we do not estimate some of the nuisance functions correctly, we are still consistent to sharp or valid bounds. That is, even when we are biased due to misestimation of nuisances, our bias (if any) only enlarges our bounds, so they remain valid. We illustrate these guarantees numerically. Collectively, these guarantees lend substantial credibility to the bounds generated by our method. ", "page_idx": 1}, {"type": "text", "text": "Our contributions are summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "1. We provide novel algorithms and analysis for learning robust $Q$ -functions (Section 3) and robust visitation density ratios (Section 4) under the function approximation setting.   \n2. We derive the sharp and efficient estimator for the robust policy value, which is optimal in the local-minimax sense and is the gold standard in semiparametric estimation (Section 5).   \n3. We empirically validate the efficiency and sharpness of our approach (Section 6). ", "page_idx": 1}, {"type": "text", "text": "1.1 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "Unobserved Confounding in Sequential Decision-Making. OPE in robust MDPs is related to OPE bounds in confounded MDPs, where the behavior policy and the transition kernel are influenced by unobserved confounders. The constraint Eq. (1) that defines our target robust MDP aligns with the Marginal Sensitivity Model (MSM) [66] employed in sensitivity analysis for causal inference. Yet, unlike the MSM, which limits the ratio of policy densities, our approach directly constrains the ratio of the transition kernels. Our formulation can be viewed as a generalization of the MSM from traditional two-action no-horizon causal effects (where the constrains coincide) to multi-action infinite-horizon discounted MDPs, where the next state is the \u201cpotential outcome\". In that sense, our model essentially serves as an outcome-based sensitivity model [10]. This distinction is crucial as it enables our model to subsume the policy-based MSM in cases where the policy is confounded. Nonetheless, the reverse does not hold, and the policy-based MSM does not imply a transition kernel-based MSM for $A>2$ This point is further coroborated by [12], who explore the policy-based MSM within confounded MDPs and obtain non-sharp identification bounds when $A>2$ . In contrast, our approach yields sharp identification in general, regardless of the number of actions and without placing assumptions on the behavior policy, which may or may not be confounded. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "[13] also considered an MSM-like model in the transition kernel but their formulation assumes $A=2$ . [40] operates under the setting of [12] and required tabular states. We note that all these works including ours considers i.i.d. confounders at each step, which translates to a robust MDP With $(s,a)$ -rectangularity and ensures that the worst-case problem is still an MDP rather than a POMDP. The importance of this assumption was verified by [55], who showed that without it, the non-memoryless confounder can create exponential-in-horizon changes in value. ", "page_idx": 2}, {"type": "text", "text": "Neyman Orthogonality and Semiparametric Efficient Estimation. We leverage a body of research focusing on learning with nuisances functions (e.g., Q-functions) that we need to estimate from data but are not the primary target (e.g., policy value). Much of this research [7, 16, 17, 29, 64, 70, among others] aims to identify Neyman-orthogonal estimators, which are first order orthogonal (insensitive) to nuisance errors. This literature is tightly linked to the semiparametric efficient estimation literature since Neyman-orthogonal scores can arise naturally from efficient influence functions [33, 62]. Going beyond the no-horizon causal inference setting, some explore such estimators in off-policy sequential-decisions contexts [19, 38, 42, 48, 50]. Notably, [39] derive efficient influence functions and orthogonal estimation in standard, non-robust OPE in infinite-horizon RL, which coincides with our unconfounded no-uncertainty case( $\\Lambda=1$ ", "page_idx": 2}, {"type": "text", "text": "Moving beyond point-identified settings, some works explore orthogonality and efficiency for partial identification and sensitivity analysis. In the causal inference literature, effcient/orthogonal estimation in the no-horizon setting has been studied extensively under several sensitivity models [10, 18, 24, 58]. Closest to our work is [24] who provide an orthogonal estimator and convergence rates under the MSM [66], which coincides with our setting under $\\gamma=1$ . In the sequential setting, [55] considers confounding at a single time step under the MSM, but their estimator is not orthogonal when the quantile function is unknown. [12] provide a fitted-Q-iteration learner with an orthogonalized loss function, but not orthogonal/efficient estimates of worst-case policy value. ", "page_idx": 2}, {"type": "text", "text": "2 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "We consider an MDP with state space $\\boldsymbol{S}$ , action space $\\boldsymbol{\\mathcal{A}}$ , transition kernel $P(s^{\\prime}\\ \\mid s,a)$ , reward function $r(s,a)\\,\\in\\,[0,1]$ and initial state distribution $d_{1}\\,\\in\\,\\Delta(S)$ . We do not require $\\boldsymbol{S}$ or $\\boldsymbol{\\mathcal{A}}$ to be finite. We assume $r$ and $d_{1}$ are known for simplicity, and it is standard to extend our analysis to when they are unknown. We are given a dataset $\\mathcal{D}$ of $n\\ i.i.d.$ tuples $(s_{i},a_{i},r_{i},s_{i}^{\\prime})$ such that $(s_{i},a_{i})\\sim\\nu$ \uff0c $s_{i}^{\\prime}\\sim P(\\cdot\\mid s,a)$ and $r_{i}=r(s_{i},a_{i})$ , where $\\nu$ is an arbitrary data-generating distribution. For discount factor $\\gamma\\in[0,1)$ , let the $Q$ function be the discounted cumulative rewards under a policy $\\pi:{\\mathcal{S}}\\rightarrow A$ $\\begin{array}{r}{Q_{\\pi,P}(s,a\\stackrel{.}{)}=\\mathbb{E}_{\\pi,P}[\\sum_{t=0}^{\\infty}\\gamma^{t}r_{t}(s_{t},a_{t})\\mid s_{1}=s,a_{1}=a]}\\end{array}$ . Similarly, define the value function as $V_{\\pi,P}(s)=Q_{\\pi,P}(s,\\pi)$ , where we use the notation $f(s,\\pi):=\\mathbb{E}_{a\\sim\\pi(s)}[f(s,a)]$ for any function $f:S\\times A\\rightarrow\\mathbb{R}$ ", "page_idx": 2}, {"type": "text", "text": "We are interested in estimating the value of a fixed target policy $\\pi_{\\mathfrak{t}}$ (a.k.a. evaluation policy) in an unobserved MDP with a feasible perturbed transition kernel $U$ .We say $U$ is a feasible perturbation of the observed, nominal kernel $P$ if for all $s,a,s^{\\prime}$ :we have ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Lambda^{-1}(s,a)\\leq\\frac{\\mathrm{d}U(s^{\\prime}|s,a)}{\\mathrm{d}P(s^{\\prime}|s,a)}\\leq\\Lambda(s,a)}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $\\Lambda(s,a)\\in[1,\\infty)$ is a sensitivity parameter chosen by the practitioner. On the extremes, $\\Lambda=1$ corresponds to no-confounding (i.e., classic OPE setting) and $\\Lambda\\,=\\,\\infty$ corresponds to maximalconfounding (i.e., worst or best outcome). We denote the set of all feasible perturbations of $P$ by ", "page_idx": 2}, {"type": "text", "text": "$\\mathcal{U}(P)$ , which is an $s,a_{}$ -rectangular set [51]. We define the best- and worst-case $Q$ functions of $\\pi_{\\updownarrow}$ as ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q^{+}(s,a):=\\operatorname*{sup}_{U\\in\\mathcal{U}(P)}Q_{\\pi_{\\mathrm{t}},U}(s,a);\\qquad Q^{-}(s,a):=\\operatorname*{inf}_{U\\in\\mathcal{U}(P)}Q_{\\pi_{\\mathrm{t}},U}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Thus, the goal of this paper is to estimate the best- and worst-case value of $\\pi_{\\mathrm{t}}$ at the initial state, ", "page_idx": 3}, {"type": "equation", "text": "$$\nV_{d_{1}}^{\\pm}:=(1-\\gamma)\\mathbb{E}_{s_{1}\\sim d_{1}}[V^{\\pm}(s_{1})].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $V^{\\pm}(s)=\\mathbb{E}_{a\\sim\\pi_{\\mathrm{t}}(s)}[Q^{\\pm}(s,a)]$ and the $\\pm$ symbol ignals that an equation should be read twice, once with $\\pm=+$ and once with $\\pm\\,=\\,-$ . For clarity, we focus the discussion in the main text on estimating the worst-case policy value, $V_{d_{1}}^{-}$ . We provide a similar analysis for policy values under best-case perturbations $(V_{d_{1}}^{+})$ in Appendix B. ", "page_idx": 3}, {"type": "text", "text": "Compared to standard OPE, robust OPE is more challenging since the best- and worst-case transition kernels $U^{\\pm}$ are unobserved as our dataset $\\mathcal{D}$ is generated under $P$ . For example, standard OPE is easy in the on-policy case i.e., if $\\mathcal{D}$ were generated by $\\pi_{\\mathrm{t}}$ , but our problem is still \u201coff-data\" and non-trivial. ", "page_idx": 3}, {"type": "text", "text": "Discounted Visitation Distributions. For any transition kernel $U$ , define the discounted visitation distribtion of $\\pi_{\\mathrm{t}}$ under $U$ as: $\\begin{array}{r}{d_{d_{1},U}^{\\pi_{\\mathrm{t}},\\infty}(s)\\,:=\\,(1-\\gamma)\\sum_{h=1}^{\\infty}\\gamma^{h-1}d_{d_{1},U}^{\\pi_{\\mathrm{t}},h}(s)}\\end{array}$ $d_{d_{1},U}^{\\pi_{\\mathrm{t}},h}(s)$ probability of reaching state $s$ in the Markov chain induced by $U$ and policy $\\pi_{\\updownarrow}$ starting from $d_{1}(\\cdot)$ Weuse $d^{-,\\infty}$ as shorthand for $d_{d_{1},U^{-}}^{\\pi_{\\mathrm{t}},\\infty}$ where $U^{-}$ denotes theworstcasekemelin $\\mathcal{U}(P)$ ", "page_idx": 3}, {"type": "text", "text": "Bellman-type Operators. For any function $f:S\\times A\\rightarrow\\mathbb{R}$ and transition kernel $U$ , recall the Bellman operator is defined as $\\bar{\\mathcal{T}}_{U}f(s,a)\\;:=\\;r(s,a)\\,+\\,\\gamma\\mathbb{E}_{U}[f(s^{\\prime},\\pi_{\\mathfrak{t}})\\ \\vert\\ \\,s,a]$ . For robust OPE, we define the following robust analog $\\begin{array}{r}{T_{\\mathrm{rob}}^{+}f(s,a)\\;:=\\;r(s,a)+\\gamma\\operatorname*{sup}_{U\\in\\mathcal{U}(P)}\\mathbb{E}_{U}[f(s^{\\prime},\\pi_{\\mathrm{t}})\\:\\:|\\:\\:s,a]}\\end{array}$ and $\\begin{array}{r}{T_{\\mathrm{rob}}^{-}f(s,a):=r(s,a)+\\gamma\\operatorname*{inf}_{U\\in\\mathcal{U}(P)}\\mathbb{E}_{U}[f(s^{\\prime},\\pi_{\\mathfrak{t}})\\ |\\ s,a]}\\end{array}$ . Moreover, we define $\\mathcal{I}_{U}f(s,a):=$ $\\gamma\\mathbb{E}_{U}[f(s^{\\prime},\\pi_{\\mathrm{t}})\\mid s,a]-f(s,a)$ . For any linear operator $\\tau$ , also let $\\mathcal{T}^{\\prime}$ denote its adjoint: that is, for all $f,g\\in L_{2}(\\nu)$ \uff0c $\\langle f,\\tau g\\rangle=\\langle T^{\\prime}f,g\\rangle$ , where $\\langle\\cdot,\\cdot\\rangle$ is the inner product in $L_{2}(\\nu)$ ", "page_idx": 3}, {"type": "text", "text": "Conditional Value-at Risk (CVaR). For a random variable $X$ , its upper/lower CVaRs at level $\\tau\\in[0,1]$ is defined as the average outcome of the upper/lower $\\tau$ -fraction of cases, and are formally defined as follows [61]: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{CVaR}_{\\tau}^{+}(X):=\\underset{b\\in\\mathbb{R}}{\\mathrm{min}}\\big\\lbrace b+\\tau^{-1}\\mathbb{E}[(X-b)_{+}]\\big\\rbrace,}\\\\ &{\\mathrm{CVaR}_{\\tau}^{-}(X):=\\underset{b\\in\\mathbb{R}}{\\mathrm{max}}\\big\\lbrace b+\\tau^{-1}\\mathbb{E}[(X-b)_{-}]\\big\\rbrace,}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $y_{+}:=\\operatorname*{max}(0,y)$ and $y_{-}:=\\operatorname*{min}(0,y)$ for $y\\in\\mathbb R$ The optima are attained at the upper/lower $\\tau$ -th quantile of $X$ which we denote as $\\beta_{\\tau}^{+}(X)/\\beta_{\\tau}^{-}(X)$ , i.e., ", "page_idx": 3}, {"type": "image", "img_path": "LKGuc2rY5v/tmp/a81c1ae08ed4df0e3802c0fe623dd3c13d9bc7224e5d7bcde5ce612d78e6aa91.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 1: Lower and upper CVaRs and quantiles $(\\beta)$ of $v(s^{\\prime})\\mid\\bar{s},a$ distribution. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\operatorname{VaR}_{\\tau}^{+}(X):=\\beta_{\\tau}^{+}(X)+\\tau^{-1}\\mathbb{E}[(X-\\beta_{\\tau}^{+}(X))_{+}],\\,\\,\\operatorname{CVaR}_{\\tau}^{-}(X):=\\beta_{\\tau}^{-}(X)+\\tau^{-1}\\mathbb{E}[(X-\\beta_{\\tau}^{-}(X))_{-}].\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "If $X$ has a cumulative distribution function (CDF) which is differentiable at $\\beta_{\\tau}^{\\pm}(X)$ , its CVaRs simplify to $\\operatorname{CVaR}_{\\tau}^{+}(X)=\\mathbb{E}[X\\mid X\\geq\\beta_{\\tau}^{+}(X)]$ and $\\operatorname{CVaR}_{\\tau}^{-}(X)=\\mathbb{E}[X\\mid X\\leq\\beta_{\\tau}^{-}(X)]$ . In the paper, $\\tau$ will often be set to $(\\bar{\\Lambda}+\\dot{1})^{-1}\\in[0,0.5$ ", "page_idx": 3}, {"type": "text", "text": "Notations. We use $x\\ \\lesssim\\ y$ to mean that $x\\,\\leq\\,C y$ holds for some universal constant $C$ The indicator function $\\mathbb{I}[p]$ takes value 1 if $p$ is true and O otherwise. For a measure $\\mu$ , we let $\\|f\\|_{\\mu}:=$ $(\\mathbb{E}_{\\mu}|f(X)|^{2})^{1/2}$ denote the $L_{2}$ norm of $f$ , provided it exists. When $\\mu$ is clear from context, we also use $\\|f\\|_{p}\\;:=\\;(\\mathbb{E}|f(X)|^{p})^{1/p}$ to denote the $L_{p}$ norm of $f$ and $\\|f\\|_{p,n}\\;:=\\;(\\mathbb{E}_{n}|f(X)|^{p})^{1/p}$ to denote the empirical analog. For a data sample of size $n$ , we define the empirical mean as $\\begin{array}{r}{\\mathbb{E}_{n}[f(X)]=\\frac{1}{n}\\sum_{i=1}^{n}f(x_{i})}\\end{array}$ . For a nuisance function $f$ , we reserve $f^{*}$ as its true value and $\\widehat{f}$ as the learned value from data. Moreover, we employ $^+$ and - to denote functions corresponding to bestand worst-case bounds, respectively. See Appendix A for a comprehensive notation table. ", "page_idx": 3}, {"type": "text", "text": "2.1  Background: Non-robust OPE ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "We provide a quick primer on the double RL (DRL) estimator for classic OPE in non-robust MDPs [38], which combines estimates of the $Q$ -function and density ratio $w$ to achieve orthogonality, double robustness and semiparametric efficiency. This sets the stage for our orthogonal estimator in Section 5, which generalizes DRL to robust MDPs by incorporating the robust $Q$ -function and density ratio in the worst-case MDP, as described in Section 3 and Section 4 respectively. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "The DRL estimator involves two nuisances: (1) $q$ , for which the oracle (true value) is the $Q$ -function of the target policy $Q^{\\pi_{\\mathtt{t}}}$ , and (2) $w$ , for which the oracle is the density ratio of the target policy's visitation distribution and the data distribution $w^{\\pi_{\\mathrm{t}}}=\\mathrm{d}d_{d_{1},P}^{\\pi_{\\mathrm{t}},\\infty}/\\mathrm{d}\\nu$ In this section, let $\\eta=(w,q)$ denote the DRL nuisances (outside this section, we use $\\eta$ to denote our robust estimator's nuisances) and let $\\eta^{\\star}=(w^{\\pi_{\\mathtt{t}}},Q^{\\pi_{\\mathtt{t}}})$ denot thirtrual ttterdfcit nt f $V_{d_{1}}^{\\pi_{\\mathrm{t}}}$ in non-robust MDPs is given by: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\psi^{\\tt D R L}(s,a,s^{\\prime};w,q)=V_{d_{1}}^{\\pi_{1}}+w(s,a)\\cdot(r(s,a)+\\gamma q(s^{\\prime},\\pi_{\\mathrm{t}})-q(s,a)).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "The DRL estimator uses cross-fitting to learn nuisances $\\widehat{\\eta}^{\\left[k\\right]}$ on all data excluding the $k$ -th fold $\\mathcal{D}^{k}$ for $k=1,2,\\ldots,K$ and estimates the OPE value via: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{V}_{d_{1}}^{\\mathtt{D R L}}=\\frac{1}{n}\\sum_{k=1}^{K}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}^{k}}\\psi^{\\mathsf{D R L}}(s,a,s^{\\prime};\\widehat{\\eta}^{\\mathtt{[k]}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "As we will see, this paves the way for the EIF of the robust value (Theorem 5.1) and our orthogonal estimator (Algorithm 3). There are two main guarantees for DRL: double robustness and semiparametric efficiency. Let $r_{n}^{w}$ and $r_{n}^{q}$ be rate functions depending on $n=|\\mathcal{D}|$ such that $\\lVert\\widehat{q}^{[k]}-Q^{\\pi_{\\mathrm{t}}}\\rVert_{2}\\\\stackrel{\\cdot}{\\leq}r_{n}^{q}$ and $\\lVert\\widehat{w}^{[k]}-w^{\\pi_{\\mathsf{t}}}\\rVert_{2}\\leq r_{n}^{w}$ $|\\widehat{V}_{d_{1}}^{\\mathsf{D R L}}-V_{d_{1}}^{\\pi_{\\mathsf{t}}}|\\leq O_{p}(n^{-1/2}+r_{n}^{w}r_{n}^{q})$ $\\Sigma^{\\mathsf{o p e}}$ achievable asymptotic variance among RAL estimators in nonparametric models for $(s,a,s^{\\prime}))$ , then $\\sqrt{n}(\\widehat{V}_{d_{1}}^{\\mathsf{D R L}}-V_{d_{1}}^{\\pi_{\\mathsf{t}}})\\mathbf{\\Sigma}\\overset{d}{\\to}\\mathcal{N}(0,\\Sigma^{\\mathsf{o p e}})$ . We sek similar guarantees for our othogonal robust estimator. ", "page_idx": 4}, {"type": "text", "text": "3 Robust $Q$ Function Estimation with Fitted. $Q$ Evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we identify the robust $Q$ -function using the robust Bellman equation and then derive convergence rates for iteratively minimizing the robust Bellman error. ", "page_idx": 4}, {"type": "text", "text": "3.1 Identification of the worst-case $Q$ function ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The robust worst-case $Q$ -function of $\\pi_{\\mathfrak{t}}$ , denoted as $Q^{-}$ , satisfies the robust Bellman equation $Q^{-}(s,a)=T_{\\mathrm{rob}}^{-}Q^{-}(s,a),\\forall s,a$ since the uncertainty set $\\mathcal{U}(P)$ factorizes over $s,a$ [34]. While these equations may seem intractable due to the inf in the definition of $\\mathcal{T}_{\\mathsf{r o b}}^{-}$ , [12] showed that $\\mathcal{T}_{\\mathtt{r o b}}^{-}$ has a closed form solution in terms of the CVaR under the observed kernel $P$ ", "page_idx": 4}, {"type": "text", "text": "Lemma 3.1. Set $\\tau(s,a)=\\left(\\Lambda(s,a)+1\\right)^{-1}$ . Then, for any $q:S\\times A\\to\\mathbb{R},$ $\\mathcal{T}_{\\mathrm{rob}}^{-}q(s,a)=r(s,a)+\\gamma\\Lambda^{-1}(s,a)\\mathbb{E}[v(s^{\\prime})\\mid s,a]+\\gamma(1-\\Lambda^{-1}(s,a))\\,\\mathrm{CVaR}_{\\tau(s,a)}^{-}[v(s^{\\prime})\\mid s,a],$ where $v(s^{\\prime})=\\mathbb{E}_{a^{\\prime}\\sim\\pi_{t}(s^{\\prime})}[q(s^{\\prime},a^{\\prime})]$ and E, $\\mathrm{CVaR}_{\\tau}$ are under the observed kernel $P(\\cdot\\mid s,a)$ ", "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Lemma 3.1 implies that $Q^{-}$ is identified via the following equation of observable distributions: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{2^{-}(s,a)=r(s,a)\\!+\\!\\gamma\\Lambda^{-1}(s,a)\\mathbb{E}[Q^{-}(s^{\\prime},\\pi_{\\mathsf{t}})\\mid s,a]\\!+\\!\\gamma(1\\!-\\!\\Lambda^{-1}(s,a))\\,\\mathrm{CVaR}_{\\tau(s,a)}^{-}[Q^{-}(s^{\\prime},\\pi_{\\mathsf{t}})\\mid s,a].}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Under no confounding $(\\Lambda(s,a)=1)$ ), this recovers the classic Bellman equation. ", "page_idx": 4}, {"type": "text", "text": "3.2  Estimating the Robust $Q$ -Function with Robust FQE ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we estimate $Q^{-}$ via an iterative fitting algorithm based on fitted Q-evaluation (FQE) [54]. Our algorithm RobustFQE (Algorithm 1) proceeds for $M$ iterations with two main steps in each iteration $i$ . First, in Line 5, we estimate the lower-quantile of ${\\widehat{v}}_{i-1}(s^{\\prime})\\mid s,a$ .Here, we assume access to an oracle QR for quantile regression, which is a well-established problem, allowing for the use of various existing algorithms. Second, in Line 6, we solve the tractable robust Bellman equation in Lemma 3.1 with the CVaR term estimated by its orthogonal estimating equation with the learned quantiles [57]. By orthogonally estimating CVaR, we achieve second-order dependence on the quantile estimation errors from the first step. Next, we minimize the mean squared error using a general function class, $\\mathcal{Q}\\subset\\mathcal{S}\\times\\mathcal{A}\\mapsto[0,(1-\\gamma)^{-1}]$ ", "page_idx": 4}, {"type": "text", "text": "To enable convergence guarantees, we make two assumptions. First, we assume that the quantile regression oracle has a specific convergence rate, which can be guaranteed under certain smoothness conditions [9, 14, 27, 28, 52, 60, 65]. Distributional RL may also be modified to learn quantiles of the next state value and have shown benefits in practice [21, 22] and in theory [5, 75, 76, 78]. ", "page_idx": 4}, {"type": "text", "text": "Algorithm 1 RobustFQE: Iterative fitting for estimating $Q^{-}$ and $\\beta_{\\tau}^{-}$ ", "page_idx": 5}, {"type": "text", "text": "1: Input: Number of iterations $M$ , Dataset $\\mathcal{D}$ of size $n$ \uff0c $Q$ -function class $\\mathcal{Q}$   \n2: Initialize $\\widehat{v}_{0}^{-}(s^{\\prime})=0$   \n3: for $i=1,2,\\dots,M$ do   \n4:Set $\\mathcal{D}_{i}=\\mathcal{D}[n i/M:n(i+1)/M]$   \n5: On the first half of $\\mathcal{D}_{i}$ , suae ue $\\tau(s,a)$ IUWer quaut vi $\\widehat{v}_{i-1}^{-}(s^{\\prime}),s^{\\prime}\\sim P(\\cdot\\mid s,a)$ ", "page_idx": 5}, {"type": "text", "text": "Let $\\widehat{\\beta}_{i}^{-}(s,a)$ denote the learned lower quantiles from the quantile regression oracle QR. 6: Using the second half of $\\mathcal{D}_{i}$ , solve the empirical robust Bellman equation by minimizing squared prediction error for the pseudo-outcome: $\\begin{array}{r l}&{\\widehat{q_{i}}\\gets\\arg\\operatorname*{min}_{q\\in\\mathcal{Q}}\\frac{1}{|D_{i}|/2}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}_{i}[|\\mathcal{D}_{i}|/2+1:]}[(y^{-}(s,a,s^{\\prime})-q(s,a))^{2}],}\\\\ &{\\quad y^{-}(s,a,s^{\\prime})=r(s,a)+\\gamma\\Lambda^{-1}(s,a)\\widehat{v_{i-1}}(s^{\\prime})+\\gamma(1-\\Lambda^{-1}(s,a))}\\\\ &{\\qquad\\quad\\times\\big(\\widehat{\\beta}_{i}^{-}(s,a)+\\tau^{-1}(s,a)(\\mathbb{E}_{a^{\\prime}\\sim\\pi_{1}(s^{\\prime})}[(\\widehat{q_{i}}\\left(s^{\\prime},a^{\\prime}\\right)-\\widehat{\\beta}_{i}^{-}(s,a))_{-}]\\big).}\\end{array}$ where ", "page_idx": 5}, {"type": "text", "text": "7: Output: $\\widetilde{q_{M}},\\widehat{\\beta}_{M}^{-}$ ", "page_idx": 5}, {"type": "text", "text": "Assumption 3.2 (QR Oracle). For any $v:S\\,\\mapsto\\,[0,(1-\\gamma)^{-1}]$ , let the true $\\tau(s,a)$ -quantile of $v(s^{\\prime}),s^{\\prime}\\sim P(s,a)$ be denoted by $\\beta_{\\tau}^{v}(s,a)$ . Given a dataset $\\mathcal{D}_{\\sf O R}$ , we assume QR outputs estimates $\\widehat{\\beta}_{v}$ with bounded $\\ell_{\\infty}$ error: for any $\\delta$ w.p. $1-\\delta$ $\\|\\widehat{\\beta}_{q}-\\beta_{\\tau}^{q}\\|_{\\infty}<\\mathsf{e r r}_{\\mathsf{Q R}}(|\\mathcal{D}_{\\mathsf{Q R}}|,\\delta).$ ", "page_idx": 5}, {"type": "text", "text": "The second assumption is completeness under the robust Bellman $\\mathcal{T}_{\\mathsf{r o b}}^{-}$ Completeness is a standard assumption in algorithms based on temporal-difference learning and without it, fitted-Q can diverge or converge to suboptimal fixed points [45, 68]. ", "page_idx": 5}, {"type": "text", "text": "Assumption 3.3 (Completeness). For all $q\\in\\mathcal{Q}$ ,we have $\\tau_{\\mathsf{r o b}}^{-}q\\in\\mathcal{Q}$ ", "page_idx": 5}, {"type": "text", "text": "We note that the current proofs of [12, 59] require a stronger completeness: $\\pi_{\\beta}q\\in\\mathcal{Q}$ for all $q\\in\\mathcal{Q}$ and feasible $\\beta$ . We circumvent the need for the stronger \u201call- $\\cdot\\beta^{\\bullet}$ completeness by bounding model misspecification of least squares regression with second order error in the quantile regression. ", "page_idx": 5}, {"type": "text", "text": "Finally, we express our bounds with the critical radius $\\varepsilon_{n}^{Q}$ , a standard tool for deriving fast rates in statistics; see Appendix D.2 for a summary. Also, we denote the standard concentrability coeffcient Wwith $C_{d_{1}}^{-}:=\\left\\|\\mathrm{d}\\dot{{d}}_{\\mu}^{\\widehat{-},\\infty}/\\mathrm{d}d_{1}\\right\\|_{\\infty}$ , a standard and necessary quantity for OPE. ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.4. Let $\\varepsilon_{n}^{Q}$ denote the critical radius of $\\mathcal{Q}$ .Under Assumptions 3.2 and 3.3, RobustFQE ensures that for any $\\overset{\\cdot}{\\delta}\\in(0,1),\\,w.p.\\,\\,1-\\delta$ ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\widetilde{q_{M}}-Q^{-}\\|_{d_{1}}\\lesssim(1-\\gamma)^{-2}(\\sqrt{C_{d_{1}}^{-}}\\cdot\\varepsilon_{n}^{Q}+\\mathsf{e r r}_{\\mathsf{O R}}^{2}(n/2M,\\delta/2M)),\\ \\ a n d}\\\\ &{\\big|(1-\\gamma)\\mathbb{E}_{d_{1}}[\\widehat{v_{M}}(s_{1})]-V_{d_{1}}^{-}\\big|\\lesssim\\gamma^{M}+(1-\\gamma)^{-1}(\\sqrt{C_{d_{1}}^{-}}\\cdot\\varepsilon_{n}^{Q}+\\mathsf{e r r}_{\\mathsf{O R}}^{2}(n/2M,\\delta/2M)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "For parametric classes (e.g., finite or linear), the critical radius converges at the standard $\\widetilde{\\mathcal{O}}(n^{-1/2})$ rate. Due to the orthogonal estimation of CVaR, we benefit from a favorable second-order dependence on erroR which allows for quantile regression to converge at slower $\\widetilde{\\mathcal{O}}(n^{-1/4})$ rates. The main disadvantage of this direct approach is that it converges at a slow sub- $\\sqrt{n}$ rate if $\\varepsilon_{n}^{Q}$ converges at a sub- $\\sqrt{n}$ e.g.,. $\\varepsilon_{n}^{Q}$ converges at a $\\widetilde{\\mathcal{O}}(n^{-1/4})$ rate if $\\mathcal{Q}$ is nonparametric with metric entropy at most $1/t^{2}$ [71]. In Section 5, we present an orthogonal estimator that is both robust to slower rates of $Q$ and achieves semiparametric efficiency. ", "page_idx": 5}, {"type": "text", "text": "4  Robust $w$ Function Estimation with Minimax Learning ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Before we present our orthogonal estimator, we study another essential nuisance function: the robust visitation density ratio, $i.e.$ , the robust $w$ -function [2, 39]. In this section, we first identify the worstcase transition kernel $U^{-}$ in our uncertainty set $\\mathcal{U}(P)$ . Then, we propose a minimax estimator [69] for the robust $w$ -function, an important nuisance function for our orthogonal estimator in Section 5. ", "page_idx": 5}, {"type": "text", "text": "Identification of $U^{-}$ . The robust transition kernel $U^{-}$ is defined as the feasible perturbed kernel that achieves the inf in the robust Bellman equation $Q^{-}(s,a)=T_{\\mathrm{rob}}^{-}Q^{-}(s,a)$ . Let $F^{-}(y\\mid s,a)=$ ", "page_idx": 5}, {"type": "text", "text": "1: Input: Dataset $\\mathcal{D}$ prior stage estimate $\\widetilde{\\zeta}$ , function classes $\\mathcal{W},\\mathcal{F}$ , stabilizer weight $\\lambda>0$   \n2: Define weights $\\xi^{-}(s,a,s^{\\prime}):=\\Lambda^{-1}(s,a)+(1-\\Lambda^{-1}(s,a))\\tau^{-1}(s,a)\\mathbb{I}[\\widetilde{\\zeta}(s,a,s^{\\prime})\\leq0]$   \n3: Output: ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\widehat{w}^{-}=\\underset{w\\in\\mathcal{W}}{\\arg\\operatorname*{min}}\\operatorname*{max}_{f\\in\\mathcal{F}}\\mathbb{E}_{n}\\big[w(s,a)(\\gamma\\xi^{-}(s,a,s^{\\prime})f(s^{\\prime},\\pi_{\\mathrm{t}})-f(s,a))+(1-\\gamma)\\mathbb{E}_{d_{1}}f(s_{1},\\pi_{\\mathrm{t}})\\big]}&{}&\\\\ {-\\lambda\\|\\gamma\\xi^{-}(s,a,s^{\\prime};\\widetilde{\\zeta})f(s^{\\prime},\\pi_{\\mathrm{t}})-f(s,a)\\|_{2,n}^{2}}&{}&{{}}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "$P(V^{-}(s^{\\prime})\\le y\\mid s,a)$ be the next-state pushforward measure of the robust value function $V^{-}$ .Then, $U^{-}$ is a convex combination of the nominal kernel $P$ and a reweighting of $P$ by an indicator function. ", "page_idx": 6}, {"type": "text", "text": "Lemma 4.1. Suppose $F^{-}(\\beta_{\\tau}^{-}(s,a)\\ \\mid\\ s,a)\\;=\\;\\tau_{.}$ where $\\beta_{\\tau}^{-}(s,a)$ is the lower $\\tau$ -th quantile of $F^{-}(\\cdot\\mid s,a)$ . Then, ", "page_idx": 6}, {"type": "equation", "text": "$$\nU^{-}(s^{\\prime}\\mid s,a)/P(s^{\\prime}\\mid s,a)=\\Lambda^{-1}(s,a)+(1-\\Lambda^{-1})\\tau(s,a)^{-1}\\mathbb{I}[(V^{-}(s^{\\prime})-\\beta_{\\tau}^{-}(s,a))\\leq0].\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The proof strategy decomposes $U^{-}$ into its nominal and perturbed components, leveraging the primal solution of $\\mathrm{CVaR}_{\\tau}$ [3]; we formalize this in Appendix E.2. ", "page_idx": 6}, {"type": "text", "text": "Identification of $w^{-}$ . Using the identification of $U^{-}$ in Lemma 4.1, we can now identify the robust $w$ -function based on the Bellman flow equations in the worst-case MDP. The Bellman flow in the robust MDP is given by $d^{-,\\infty}(s)=(1-\\gamma)d_{1}(s)+\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d^{-},\\infty,\\widetilde{a}\\sim\\pi_{\\mathrm{t}}(\\widetilde{s})}U^{-}(s\\mid\\widetilde{s},\\widetilde{a})$ where $d^{-,\\infty}(s)$ was defined in Section 2. Thus, the robust visitation density, defined as $w^{-}(s):=\\,\\mathrm{d}d^{-,\\infty}(s)\\big/\\mathrm{d}\\nu(s)$ satisfies the following moment condition for all $f:S\\mapsto\\mathbb{R}$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[w^{-}(s)f(s)]=(1-\\gamma)\\mathbb{E}_{d_{1}}[f(s_{1})]+\\gamma\\mathbb{E}[w^{-}(s,a)\\mathbb{E}_{s^{\\prime}\\sim U^{-}(s,a)}[f(s^{\\prime})]],}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where we relaxed notation and defined $w^{-}(s,a):=\\,w(s)\\cdot\\pi_{\\mathrm{t}}(a\\mid s)/\\nu(a\\mid s)$ . As before, in the unconfounded base ( $\\mathrm{\\Delta}\\Lambda=1\\$ 0, this result recovers the classic Bellman fow. ", "page_idx": 6}, {"type": "text", "text": "4.1 Estimating $w^{-}$ with Robust Minimax Indirect Learning ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We now propose a penalized minimax estimator for $w^{-}$ that generalizes the Minimax Indirect Learning (MIL) of [69] to our robust MDP setting. Our estimator, RobustMIL (Algorithm 2), leverages a general function class $\\mathcal{W}\\subset\\mathcal{S}\\times\\mathcal{A}\\mapsto\\mathbb{R}_{+}$ to approximately solve the moment equation in Eq. (5). It does so by minimizing the difference between the left- and right-hand sides of the equation across a sufficiently large set of adversaries $f$ in a discriminator class $\\mathcal{F}\\subset\\mathcal{S}\\times\\mathcal{A}\\mapsto\\mathbb{R}$ Since $U^{-}$ is unknown, we approximate it via Eq. (4) by plugging in a threshold $\\widetilde{\\zeta}(s,a,s^{\\prime})$ in the indicator function to approximate the true threshold $\\zeta^{-}(s,a,s^{\\prime}):=V^{-}(s^{\\prime})-\\beta_{\\tau(s,a)}^{-}(s,a)$ . This yields the minimax objective in Eq. (6), where we also allow for an optional regularization of the adversary's norm which can be useful for obtaining fast convergence rates. ", "page_idx": 6}, {"type": "text", "text": "We make the following assumptions for MIL [69]. The first is a regularity condition that (i) our function class has bounded outputs and (i) $\\zeta$ is continuously distributed around the threshold. ", "page_idx": 6}, {"type": "text", "text": "Assumption 4.2 (Regularity). () $\\mathrm{sup}_{w\\in\\mathcal{W}\\cup\\{w^{-}\\}}\\;\\|w\\|_{\\infty}<\\infty$ (i) the marginal CDF of $V^{-}(s^{\\prime})-$ $\\beta^{-}(s,a)$ , i.e., $F(y)=P(V^{-}(s^{\\prime})-\\beta_{\\tau(s,a)}^{-}(s,a)\\le y)$ , is boundedly differentiable around 0. ", "page_idx": 6}, {"type": "text", "text": "If next-value distribution is discrete, we can use the discrete form of CVaR and (i can be removed. ", "page_idx": 6}, {"type": "text", "text": "The second is that the adversary class is rich enough to capture all projected errors under the adjoint of theoperator $\\mathcal{T}_{U^{-}}f(s,a):=\\gamma\\mathbb{E}_{U^{-}}[f(s^{\\prime},\\pi_{\\mathfrak{t}})\\mid s,a]-f(s,a)$ ", "page_idx": 6}, {"type": "text", "text": "We note that Assumption 4.3 is monotone in the function class size and can be satisfied by making the function class more expressive, e.g., increasing size of the neural net. Our algorithms are also robust to violations in Assumption 4.3, which we show in Appendix G. ", "page_idx": 6}, {"type": "text", "text": "We are now ready to state the main estimation result for $w^{-}$ in terms of the critical radius (Appendix D.2) of the function class. ", "page_idx": 6}, {"type": "table", "img_path": "LKGuc2rY5v/tmp/d3d348001f8f47ec97ed14ecca233f30bae9551d1febbc6edb1fddd8d672d4e8.jpg", "table_caption": [], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Theorem 4.4. Let $\\varepsilon_{n}^{\\mathcal{W}}$ denote the maximum critical radi of the following classes: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{G}_{1}=\\{(s,a,s^{\\prime})\\mapsto(f(s,a)-\\gamma f(s^{\\prime},\\pi_{t})),f\\in\\mathscr{F}\\},}\\\\ &{\\mathcal{G}_{2}=\\big\\{(s,a,s^{\\prime})\\mapsto(w(s,a)-w^{-}(s,a))(\\gamma f(s^{\\prime},\\pi_{t})-f(s,a)),f\\in\\mathscr{F},w\\in\\mathcal{W}\\big\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Under Assumptions 4.2 and 4.3, RobustMIL ensures that for any $\\delta,\\,w.p.\\ 1-\\delta$ ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\mathcal{I}_{U^{-}}^{\\prime}(\\widehat{w}-w^{-})\\right\\|_{2}\\lesssim\\varepsilon_{n}^{\\mathcal{W}}+\\|\\widetilde{\\zeta}^{-}-\\zeta^{-}\\|_{\\infty}+\\sqrt{\\log(1/\\delta)/n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "As before, the critical radius $\\varepsilon_{n}^{\\mathcal{W}}$ converges at an $\\widetilde{\\mathcal{O}}(n^{-1/2})$ rate for parametric classes. Notably, our bounds degrade linearly w.r.t. the $\\ell_{\\infty}$ error in $\\widetilde{\\zeta}^{-}$ for estimating $\\zeta^{-}$ . For example, if $\\widetilde{\\zeta}(s,a,s^{\\prime})=$ $\\widehat{v}(s^{\\prime})\\mathrm{~-~}\\widehat{\\beta}(s,a)$ where $\\hat{v},\\hat{\\beta}$ are estimated with RobustFQE, then the $\\zeta$ -error can be bounded by $\\mathcal{O}(\\|\\widehat{\\boldsymbol{v}}-\\boldsymbol{v}^{-}\\|_{\\infty}\\!+\\!\\|\\widehat{\\boldsymbol{\\beta}}\\!-\\!\\boldsymbol{\\beta}^{-}\\|_{\\infty})$ . We present the full proof in Appendix G, where we also present a more general result that is robust to misspecifications to realizability and completeness (Assumption 4.3). ", "page_idx": 7}, {"type": "text", "text": "5  Orthogonal and Efficient Estimator for Robust Policy Value ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we propose an orthogonal estimator that is robust against errors in the nuisances (exhibiting only second-order sensitivity), achieves semiparametric efficiency, and enables inference. Our estimator is based on the efficient influence function (EIF) of $V_{d_{1}}^{-}$ , which is the canonical gradient of a statistical estimand [67]. The adoption of EIFs for developing efficient estimators is a broadly employed technique in causal inference [16, 43] and reinforcement learning [35, 39]. ", "page_idx": 7}, {"type": "text", "text": "We define the collection of nuisance parameters by $\\eta^{-}=(w^{-},q^{-},\\beta^{-})$ . The notation $\\widehat{\\eta}$ indicates that these functions are estimated from data, while the notation $\\eta$ denotes their true values. ", "page_idx": 7}, {"type": "text", "text": "Theorem 5.1 (Recentered) Efficient Influence Function). The $(R)E I F$ of $V_{d_{1}}^{-}$ is givenby: ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\psi(s,a,s^{\\prime};\\eta^{-})=V_{d_{1}}^{-}+w^{-}(s,a)\\big(r(s,a)+\\gamma\\rho^{-}(s,a,s^{\\prime};v^{-},\\beta^{-})-q^{-}(s,a)\\big),\\quad w h e r e^{-(s,a)}=0,\\quad\\forall\\d u(s,a)\\d u(s,a)\\d u(s,a)\\d u(s,a).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "equation", "text": "$$\n\\gamma^{-}(s,a,s^{\\prime};v^{-},\\beta^{-})=\\Lambda(s,a)^{-1}v^{-}(s^{\\prime})+(1-\\Lambda(s,a)^{-1})\\bigl(\\beta^{-}(s,a)+\\tau^{-1}(v^{-}(s^{\\prime})-\\beta^{-}(s,a))_{-}\\bigr).\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Remark5.2.When $\\Lambda=1$ , there is no shift in the target environment, and the weight on the CVaR term is zero. The (R)EIF then reduces to the (R)EIF in [39] for regular OPE with an infinite horizon. As $\\Lambda\\rightarrow\\infty$ , the CVaR term becomes predominant, with the quantile $\\beta^{-}(s,a)$ taking extreme values. This yields the (novel) (R)EIF for the problem in [25], where the expected value term is replaced solely by a CVaR component in the Bellman equation. ", "page_idx": 7}, {"type": "text", "text": "The (R)EIF forms the basis of our orthogonal estimator. First, we note that $\\mathbb{E}[\\psi(s,a,s^{\\prime};\\eta^{-})]$ is an unbiased estimator of $V_{d_{1}}^{-}$ . Furthermore, the expression for $\\psi(s,a,s^{\\prime};\\eta^{-})$ depends only on quantities $w^{-},q^{-},\\beta^{-}$ which can be estimated from data. Thus, we can cast the expression $\\mathbb{E}[\\psi(s,a,s^{\\prime};\\eta^{-})]$ as a statistical estimand to be learned from the observed sample. This suggests a natural two-stage estimator that we summarize in Algorithm 3. In the first stage, we estimate the nuisance parameters $\\widehat{\\eta}$ from the data with $K$ -fold cross-fitting; in the second stage, these estimates are incorporated into the (R)EIF expression and we calculate the empirical average using the observed data. We summarize our procedure in Algorithm 3. ", "page_idx": 7}, {"type": "text", "text": "The nuisance estimation is detailed in Sections 3.2 and 4.1. The reliance on the EIF confers our estimator desirable statistical properties including a second order bias due to the nuisances, meaning the bias has a product structure with respect to the nuisance errors. Thus, this special structure orthogonalizes away the dependency on $\\widehat{Q}^{-}$ errors which now only appear in second order. Furthermore, our estimator is semiparametrically efficient in the sense that under mild consistency assumptions, it achieves minimum variance among all regular and asymptotically linear (RAL) estimators. We provide theoretical justifications for these properties in the next section. ", "page_idx": 7}, {"type": "text", "text": "5.1  Theoretical Guarantees of the Orthogonal Estimator ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now characterize the theoretical properties of our orthogonal estimator. We consider the $K$ -fold cross-fitted estimator in Algorithm 3 given by ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widehat{V}_{d_{1}}^{-}=\\frac{1}{n}\\sum_{k=1}^{K}\\sum_{(s,a,s^{\\prime})\\in{\\mathscr{D}}^{k}}\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]}),}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "where nuisances $\\widehat{\\eta}^{[k]},k\\,\\in\\,[K]$ are trained on all data excluding the $k^{\\mathrm{th}}$ fold $\\mathcal{D}^{k}$ .The following theorem outlines the theoretical guarantees of this estimator: ", "page_idx": 8}, {"type": "text", "text": "Theorem 5.3 (Eficiency of $\\widehat{V}_{d_{1}}^{-}$ ). Let $r_{n,p}^{w},r_{n,p}^{q},r_{n,p}^{\\beta}$ be functions of the same size $n=|\\mathcal{D}|$ such thatr $\\begin{array}{r}{\\|\\mathcal{I}_{U^{-}}^{\\prime}(\\widehat{w}^{-,[k]}-w)\\|_{p}\\leq r_{n,p}^{w},\\,\\|\\widehat{q}^{-,[k]}-q\\|_{p}\\leq r_{n,p}^{q},}\\end{array}$ 11 $\\lVert\\beta^{-,[k]}-\\beta\\rVert_{p}\\leq r_{n,p}^{\\beta}$ for any $k\\in[K]$ ", "page_idx": 8}, {"type": "equation", "text": "$$\n|\\widehat{V}_{d_{1}}^{-}-V_{d_{1}}^{-}|\\lesssim O_{p}(n^{-1/2})+O_{p}(r_{n,2}^{w}r_{n,2}^{q}+(r_{n,\\infty}^{q})^{2}+(r_{n,\\infty}^{\\beta})^{2})\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Furthermore, if $\\,^{\\cdot}r_{n,2}^{w}\\,\\lor\\,r_{n,2}^{q}\\;=\\;o_{p}(1),\\;r_{n,2}^{w}r_{n,2}^{q}\\;=\\;o_{p}(n^{-1/2}),\\;r_{n,\\infty}^{q}\\;=$ $r_{n,\\infty}^{q}\\;=\\;o_{p}(n^{-1/4})$ and $r_{n,\\infty}^{\\beta}\\,=$ $o_{p}(n^{-1/4})$ then $\\widehat{V}_{d_{1}}^{-}$ satisies? ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\sqrt{n}(\\widehat{V}_{d_{1}}^{-}-V_{d_{1}}^{-})\\stackrel{d}{\\rightarrow}\\mathcal{N}(0,\\Sigma),\\quad\\Sigma=\\mathrm{Var}(\\psi(s,a,s^{\\prime};\\eta^{-})).\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Moreover, $\\Sigma$ is the minimum achievable asymptotic variance among RAL estimators in the nonparametricmodelfor $(s,a,s^{\\prime})$ (the efficiency bound). ", "page_idx": 8}, {"type": "text", "text": "We provide the intuition along with a detailed proof in Appendix H. The first part of Theorem 5.3 implies that as long as we estimate the nuisances at rates faster that $n^{-1/4}$ , then we can learn $\\widehat{V}_{d_{1}}^{-}$ at parametric rates. The second part of Theorem 5.3 states that under mild consistency assumptions, our estimator attains the efficiency bound and is asymptotically normal. That means, for example, we can construct asymptoticllyvalid lower $95\\%$ -confidence bound on $\\widehat{V}_{d_{1}}^{-}$ by simply subtracting 1.64 times $\\begin{array}{r}{\\small\\hat{\\mathrm{se}}=\\frac{1}{n}(\\sum_{k=1}^{K}\\sum_{(s,a,s^{\\prime})\\in\\mathcal{D}^{k}}(\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})-\\widehat{V}_{d_{1}}^{-})^{2})^{1/2}}\\end{array}$ Then, wecanbe sre tohav bound on the worst-case RL policy value, accounting both for potential environment shift and finite data. Finally, in Appendix J, we describe two settings when our orthogonal estimator remains valid even if some nuisances are inconsistent, which is a desirable guarantee for sensitivity analysis [23]. ", "page_idx": 8}, {"type": "text", "text": "Bringing it all together. We can instantiate Theorem 5.3 with the nuisance estimators from the previous sections. First, use RobustFQE to estimate $\\widehat{q}^{-}$ and ${\\widehat{\\beta}}^{-}$ , ensuring $\\lVert\\widehat{q}^{-}-Q^{-}\\rVert_{2}\\leq\\mathcal{O}(\\varepsilon_{n}^{\\mathcal{Q}}+$ $\\bar{\\mathrm{err}}_{\\mathsf{O R}}^{2})$ . Under smoothness conditions (Lemma D.2),the $L_{2}$ guarantee for $\\widehat{q}^{-}$ implies an $L_{\\infty}$ guarantee for $\\widehat{q}^{-}$ , which also ensures an $L_{\\infty}$ guarantee for ${\\widehat{\\beta}}^{-}$ . This ensures $\\operatorname*{max}(\\|\\widetilde{q}^{-}-Q^{-}\\|_{\\infty},\\|\\widehat{\\beta}^{-}-\\beta^{-}\\|_{\\infty})$ is well-controlled. Then, we can set $\\widetilde\\zeta^{-}(s,a,s^{\\prime})=\\widehat{q}^{-}(s^{\\prime},\\pi_{\\mathrm{t}})-\\widehat{\\beta}^{-}(s,a)$ and run RobustMIL for estimating $\\widehat{w}^{-}$ . By Theorem 4.4, its projected- $L_{2}$ error is $\\mathcal{O}(\\varepsilon_{n}^{w}+\\|\\widehat{q}^{-}-Q^{-}\\|_{\\infty}+\\|\\widehat{\\beta}^{-}-\\beta^{-}\\|_{\\infty})$ Therefore, the final rate via Theorem 5.3 is $\\mathcal{O}((\\varepsilon_{n}^{\\mathcal{Q}}+\\mathrm{err}_{\\mathsf{O R}}^{2})\\cdot\\varepsilon_{n}^{w}+\\|\\widehat{q^{-}}-Q^{-}\\|_{\\infty}^{2}+\\|\\widehat{\\beta}^{-}-\\beta^{-}\\|_{\\infty}^{2})$ ", "page_idx": 8}, {"type": "text", "text": "6  Empirical Evaluation ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We now provide a proof-of-concept empirical investigation to validate our theoretical findings. We experiment with our proposed methodology in a simple synthetic environment. First, we discuss our environment, followed by our approach for solving for the nuisances functions $\\eta^{-}$ . Then, we provide empirical results for our orthogonal estimator, and compare its performance to weighted or direct estimators using the $Q^{-}$ Or $w^{-}$ nuisances only. The code for our experiments is open-sourced and available at https: //github.com/CausalML/adversarial-ope/. ", "page_idx": 8}, {"type": "text", "text": "Experimental Setup We consider a synthetic MDP with a one-dimensional state and two actions, modeled after a simple control problem with non-deterministic dynamics. The task is to estimate the worst-casepolicyvalue $V_{d_{1}}^{-}$ of a fixed candidate policy $\\pi_{\\updownarrow}$ , across four different constant values of the sensitivity parameter: $\\Lambda(s,a)\\in\\{1,2,4,8\\}$ ", "page_idx": 8}, {"type": "image", "img_path": "LKGuc2rY5v/tmp/89113d4574e7a5494bcb4beacdcf07151fc40fac1738759677914f43f87f084b.jpg", "img_caption": ["Mean squared error (MSE) to true worst-case policy value "], "img_footnote": [], "page_idx": 9}, {"type": "table", "img_path": "LKGuc2rY5v/tmp/b5c259eb6f52507c198ffa48bcaf03570e63974cda300ef9c95fcfe8634088fd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 9}, {"type": "text", "text": "Figure 2: Results of our synthetic data experiments. We show results for our three estimators on all four $\\Lambda$ values, over our 10 experiment replications. Above: Box plot summarizing range of policy value estimates for each combination of estimator and $\\Lambda$ , with Horizontal red dashed lines showing the true worst-case policy values $V_{d_{1}}^{-}$ . Below: Table summarizing the corresponding MSE of these estimators for the true worst-case policy value, along with one standard deviation errors. ", "page_idx": 9}, {"type": "text", "text": "We considered three methods for estimating the robust alue $V_{d_{1}}^{-}$ ", "page_idx": 9}, {"type": "text", "text": "1. Q (RobustFQE): Direct method using the estimated robust quality function $\\widehat{Q}^{-}$ Only.   \n2. W (RobustMIL): Importance-sampling method using the estimated robust density ratio $\\widehat{w}^{-}$ Only.   \n3. Orth: Our orthogonal estimator which combines the former two, as described in Algorithm 3. ", "page_idx": 9}, {"type": "text", "text": "We performed 10 replications of our experimental procedure, where for each replication we: (1) sampled a dataset of 20,000 tuples using a different fixed logging policy $\\pi_{b}$ ; (2) fit the nuisance functions $Q^{-}$ $\\beta^{-}$ , and $w^{-}$ following the method outlined in Algorithms 1 and 2 for each $\\Lambda$ ; and (3) estimated the corresponding robust policy value $V_{d_{1}}^{-}$ for all estimators using the fitted nuisances. ", "page_idx": 9}, {"type": "text", "text": "Results  We summarize our results in Fig. 2. We note that all of our estimators are consistently valid for all values of $\\Lambda$ in our experiment. Notably, Orth consistently has the lowest mean squared error for the true worst-case policy value. In particular, incorporating the robust importance-sampling weights improves the RobustFQE estimator Q, even though these importance-sampling weights by themselves (as in $\\mathbf{W}$ ) are much noisier estimators. This is consistent with our theory that the orthogonal estimator is semiparametrically efficient and insensitive to errors in the nuisance functions. ", "page_idx": 9}, {"type": "text", "text": "Full experimental details, including our MDP, target/logging policies, methodology for computing the true robust policy values $V_{d_{1}}^{-}$ , and nuisance estimation, are provided in Appendix K. Finally, we also performed an empirical evaluation in the real-world medical problem of sepsis management using the MIMIC-III dataset [36]. We detail these results in Appendix L. ", "page_idx": 9}, {"type": "text", "text": "7 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We consider the problem of infinite-horizon OPE in RL settings when there can be unknown, but bounded, shifts in the transition distribution compared to the transition distribution generating the data. This can arise due to unobserved confounding, where observed transitions do not reflect the true causal ones, non-stationarity in the environment, or adversarial environments. We propose a sensitivity model for such transition kernel shifts analogous to the classic MSM for static decision making, and provide theoretical guarantees for identifying and estimating the sharp (i.e., tightest possible) bounds on the best/worst-case policy value, as well as the corresponding robust $Q$ -function and state density ratio functions. Our estimator for the best/worst-case policy value is orthogonal (insensitive to how the nuisance functions are estimated) and achieves semiparametric effciency (attaining the best possible asymptotic variance). Finally, our estimator also supports inference, ensuring we can derive reliable bounds for the robust policy value even with finite data. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We thank the anonymous reviewers for their valuable feedback and insightful suggestions. This material is based upon work supported by the National Science Foundation under Grant Numbers 1846210, IS-2154711, CAREER 2339395, and by the U.S. Department of Energy, Ofice of Science, Office of Advanced Scientific Computing Research, under Award Number DE-SC0023112. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Alekh Agarwal, Yuda Song, Wen Sun, Kaiwen Wang, Mengdi Wang, and Xuezhou Zhang. Provable benefits of representational transfer in reinforcement learning. In The Thirty Sixth Annual Conference on Learning Theory, pages 2114-2187. PMLR, 2023.   \n[2] Philip Amortila, Dylan J Foster, Nan Jiang, Ayush Sekhari, and Tengyang Xie. Harnessing density ratios for online reinforcement learning. arXiv preprint arXiv:2401.09681, 2024. [3]  Marcus Ang, Jie Sun, and Qiang Yao. On the dual representation of coherent risk measures. Annals of Operations Research, 262:29-46, 2018.   \n[4]  Jean-Yves Audibert and Alexandre B Tsybakov. Fast learning rates for plug-in classifiers under the margin condition. arXiv preprint math/0507180, 2005.   \n[5] Alex Ayoub, Kaiwen Wang, Vincent Liu, Samuel Robertson, James McInerney, Dawen Liang, Nathan Kallus, and Csaba Szepesvari. Switching the loss reduces the cost in batch reinforcement learning. International Conference of Machine Learning, 2024.   \n[6]  Kishan Panaganti Badrinath and Dileep Kalathil. Robust reinforcement learning using least squares policy iteration with provable performance guarantees. In International Conference on Machine Learning, pages 511-520. PMLR, 2021.   \n[7]  Alexandre Belloni, Victor Chernozhukov, Ivan Fernandez- Val, and Christian Hansen. Program evaluation and causal inference with high-dimensional data. Econometrica, 85(1):233-298, 2017.   \n[8]  Andrew Bennett, Nathan Kallus, and Miruna Oprescu. Low-rank mdps with continuous action spaces. arXiv preprint arXiv:2311.03564, 2023.   \n[9]  Pallab K Bhattacharya and Ashis K Gangopadhyay. Kernel and nearest-neighbor estimation of a conditional quantile. The Annals of Statistics, pages 1400-1415, 1990.   \n[10] Matteo Bonvini, Edward Kennedy, Valerie Ventura, and Larry Wasserman. Sensitivity analysis for marginal structural models. arXiv preprint arXiv:2210.04681, 2022.   \n[11]  Haim Brezis and Petru Mironescu. Where sobolev interacts with gagliardo-nirenberg. Journal of functional analysis, 277(8):2839-2864, 2019.   \n[12]  David Bruns-Smith and Angela Zhou. Robust fitted-q-evaluation and iteration under sequentially ex0genous unobserved confounders. arXiv preprint arXiv:2302.00662, 2023.   \n[13] David A Bruns-Smith. Model-free and model-based policy evaluation when causality is uncertain. In International Conference on Machine Learning, pages 1116-1126. PMLR, 2021.   \n[14] Domagoj Cevid, Loris Michel, Jeffrey Naf, Nicolai Meinshausen, and Peter Buhlmann. Distributional random forests: Heterogeneity adjustment and multivariate distributional regression. arXiv preprint arXiv:2005.14458, 2020.   \n[15] Jonathan Chang, Kaiwen Wang, Nathan Kallus, and Wen Sun. Learning bellman complete representations for offine policy evaluation. In International Conference on Machine Learning, pages 2938-2971. PMLR, 2022.   \n[16] Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Dufo, Christian Hansen, Whitney Newey, and James Robins. Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21(1):C1-C68, 2018. doi: 10.1111/ectj.12097.   \n[17] Victor Chernozhukov, Mert Demirer, Esther Duflo, and Ivan Fernandez- Val. Generic machine learning inference on heterogeneous treatment effects in randomized experiments, with an application to immunization in india. Technical report, National Bureau of Economic Research, 2018.   \n[18]  Victor Chernozhukov, Carlos Cinelli, Whitney Newey, Amit Sharma, and Vasilis Syrgkanis. Long story short: Omitted variable bias in causal machine learning. Technical report, National Bureau of Economic Research, 2022.   \n[19]  Victor Chernozhukov, Whitney Newey, Rahul Singh, and Vasilis Syrgkanis. Automatic debiased machine learning for dynamic treatment effects and general nested functionals. arXiv preprint arXiv:2203.13887, 2022.   \n[20] Yinlam Chow, Aviv Tamar, Shie Mannor, and Marco Pavone. Risk-sensitive and robust decisionmaking: a cvar optimization approach. Advances in neural information processing systems, 28, 2015.   \n[21]  Will Dabney, Georg Ostrovski, David Silver, and Remi Munos. Implicit quantile networks for distributional reinforcement learning. In International conference on machine learning, pages 1096-1105. PMLR, 2018.   \n[22] Will Dabney, Mark Rowland, Marc Bellemare, and Remi Munos. Distributional reinforcement learning with quantile regression. In Proceedings of the AAAI conference on arificial intelligence, volume 32, 2018.   \n[23] Jacob Dorn and Kevin Guo. Sharp sensitivity analysis for inverse propensity weighting via quantile balancing. Journal of the American Statistical Association, 118(544):2645-2657, 2023.   \n[24]  Jacob Dorn, Kevin Guo, and Nathan Kallus. Doubly-valid/doubly-sharp sensitivity analysis for causal inference with unmeasured confounding. arXiv preprint arXiv:2112.11449, 2021.   \n[25]  Yihan Du, Siwei Wang, and Longbo Huang. Provably efficient risk-sensitive reinforcement learning: Iterated cvar and worst path. In The Eleventh International Conference on Learning Representations, 2022.   \n[26]  Yaqi Duan, Chi Jin, and Zhiyuan Li. Risk bounds and rademacher complexity in batch reinforcement learning. In International Conference on Machine Learning, pages 2892-2902. PMLR, 2021.   \n[27]  Anouar El Ghouch and Marc G Genton. Local polynomial quantile regression with parametric features. Journal of the American Statistical Association, 104(488):1416-1429, 2009.   \n[28]  Kevin Elie-Dit-Cosaque and V\u00e9ronique Maume-Deschamps.  Random forest estimation of conditional distribution functions and conditional quantiles. Electronic Journal of Statistics, 16 (2):6553-6583, 2022.   \n[29] Dylan JFoster and Vasilis Syrgkanis. Orthogonal statistical learning. The Annals of Statistics, 51(3):879-908, 2023.   \n[30] Vineet Goyal and Julien Grand-Clement. Robust markov decision processes: Beyond rectangularity. Mathematics of Operations Research, 48(1):203-226, 2023.   \n[31] Oliver Hines, Oliver Dukes, Karla Diaz-Ordaz, and Stijn Vansteelandt. Demystifying statistical learning based on efficient influence functions. The American Statistician, 76(3):292-304, 2022.   \n[32]  Ronald A Howard and James E Matheson. Risk-sensitive markov decision processes. Management science, 18(7):356-369, 1972.   \n[33] Hidehiko Ichimura and Whitney K Newey. The infuence function of semiparametric estimators. Quantitative Economics, 13(1):29-61, 2022.   \n[34] Garud N Iyengar. Robust dynamic programming. Mathematics of Operations Research, 30(2): 257-280, 2005.   \n[35]  Nan Jiang and Lihong Li. Doubly robust off-policy value evaluation for reinforcement learning. In International Conference on Machine Learning, pages 652-661. PMLR, 2016.   \n[36] Alistair EW Johnson, Tom J Pollard, Lu Shen, Li-wei H Lehman, Mengling Feng, Mohammad Ghassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G Mark. Mimic-i, a freely accessible critical care database. Scientific data, 3(1):1-9, 2016.   \n[37] Nathan Kallus. What's the harm? sharp bounds on the fraction negatively affected by treatment. Advances in Neural Information Processing Systems, 35:15996-16009, 2022.   \n[38]  Nathan Kallus and Masatoshi Uehara. Double reinforcement learning for efficient off-policy evaluation in markov decision processes. The Journal of Machine Learning Research, 21(1): 6742-6804, 2020.   \n[39] Nathan Kallus and Masatoshi Uehara. Effciently breaking the curse of horizon in off-policy evaluation with double reinforcement learning. Operations Research, 70(6):3282-3302, 2022.   \n[40]  Nathan Kallus and Angela Zhou. Confounding-robust policy evaluation in infinite-horizon reinforcement learning. Advances in neural information processing systems, 33:22293-22304, 2020.   \n[41] Nathan Kallus, Xiaojie Mao, Kaiwen Wang, and Zhengyuan Zhou. Doubly robust distributionally robust off-policy evaluation and learning. In International Conference on Machine Learning, pages 10598-10632. PMLR, 2022.   \n[42] Edward H Kennedy. Nonparametric causal effects based on incremental propensity score interventions. Journal of the American Statistical Association, 114(526):645-656, 2019.   \n[43]  Edward H Kennedy. Towards optimal doubly robust estimation of heterogeneous causal effects. arXiv preprint arXiv:2004.14497, 2020.   \n[44]  Amirhossein Kiani, Chris Wang, and Angela Xu. Sepsis world model: A mimic-based openai gym\" world model simulator for sepsis treatment. arXiv preprint arXiv:1912.07127, 2019.   \n[45]  J Kolter. The fixed points of off-policy td. Advances in Neural Information Processing Systems, 24, 2011.   \n[46] Navdeep Kumar, Kfir Levy, Kaixin Wang, and Shie Mannor. Effcient policy iteration for robust markov decision processes via regularization. arXiv preprint arXiv:2205.14327, 2022.   \n[47] Navdeep Kumar, Esther Derman, Matthieu Geist, Kfr Yehuda Levy, and Shie Mannor. Policy gradient for rectangular robust markov decision processes. In Thirty-seventh Conference on Neural Information Processing Systems, 2023. URL https: //openreview.net/forum?id= NLpXRr jpa6.   \n[48]  Mark J Laan and James M Robins. Unified methods for censored longitudinal data and causality. Springer, 2003.   \n[49]  Giovanni Leoni. A first course in Sobolev spaces. American Mathematical Soc., 2017.   \n[50] Greg Lewis and Vasilis Syrgkanis. Double/debiased machine learning for dynamic treatment effects. In NeurIPS, pages 22695-22707, 2021.   \n[51]  Shie Mannor, Ofr Mebel, and Huan Xu. Robust mdps with k-rectangular uncertainty. Mathematics of Operations Research, 41(4):1484-1509, 2016.   \n[52] Nicolai Meinshausen and Greg Ridgeway. Quantile regression forests. Journal of machine learning research, 7(6), 2006.   \n[53] Volodymyr Mnih.0l Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602, 2013.   \n[54]  Remi Munos and Csaba Szepesvari. Finite-time bounds for ftted value iteration. Journal of Machine Learning Research, 9(5), 2008.   \n[55]  Hongseok Namkoong, Ramtin Keramati, Steve Yadlowsky, and Emma Brunskill. Off-policy policy evaluation for sequential decisions under unobserved confounding. Advances in Neural Information Processing Systems, 33:18819-18831, 2020.   \n[56]  Arnab Nilim and Laurent El Ghaoui. Robust controlof markov decision processes with uncertain transition matrices. Operations Research, 53(5):780-798, 2005.   \n[57]  Tomasz Olma. Nonparametric estimation of truncated conditional expectation functions. arXiv preprint arXiv:2109.06150, 2021.   \n[58] Miruna Oprescu, Jacob Dorn, Marah Ghoummaid, Andrew Jesson, Nathan Kallus, and Uri Shalit. B-learner: Quasi-oracle bounds on heterogeneus causal effects under hidden confounding. In International Conference on Machine Learning, pages 26599-26618. PMLR, 2023.   \n[59]  Kishan Panaganti, Zaiyan Xu, Dileep Kalathil, and Mohammad Ghavamzadeh. Robust reinforcement learning using offline data. Advances in neural information processing systems, 35: 32211-32224, 2022.   \n[60]  Jeffrey S Racine and Kevin Li. Nonparametric conditional quantile estimation: A locally weighted quantile kernel approach. Journal of Econometrics, 201(1):72-94, 2017.   \n[61]  R Tyrrell Rockafellar and Stanislav Uryasev. Conditional value-at-risk for general loss distributions. Journal of banking & finance, 26(7):1443-1471, 2002.   \n[62]  Anton Schick. On asymptotically effcient estimation in semiparametric models. The Annals of Statistics, pages 1139-1151, 1986.   \n[63] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv: 1707.06347, 2017.   \n[64]  Vira Semenova and Victor Chernozhukov. Debiased machine learning of conditional average treatment effects and other causal functions. The Econometrics Journal, 24(2):264-289, 2021.   \n[65] Ichiro Takeuchi, Quoc V Le, Timothy D Sears, Alexander J Smola, and Chris Williams. Nonparametric quantile estimation. Journal of machine learning research, 7, 2006.   \n[66]Zhiqiang Tan. A distributional approach for causal inference using propensity scores. Journal of the American Statistical Association, 101(476):1619-1637, 2006.   \n[67]  Anastasios A Tsiatis. Semiparametric theory and missing data, volume 4. Springer, 2006.   \n[68] John Tsitsiklis and Benjamin Van Roy. Analysis of temporal-difference learning with function approximation. Advances in neural information processing systems, 9, 1996.   \n[69] Masatoshi Uehara, Masaki Imaizumi, Nan Jiang, Nathan Kallus, Wen Sun, and Tengyang Xie. Finite sample analysis of minimax offine reinforcement learning: Completeness, fast rates and first-order efficiency. arXiv preprint arXiv:2102.02981, 2021.   \n[70] Mark J van der Laan, Sherri Rose, Wenjing Zheng, and Mark J van der Lan. Cross-validated targeted minimum-loss-based estimation. Targeted learning: causal inference for observational and experimental data, pages 459-474, 2011.   \n[71]  Aad W Van der Vaart. Asymptotic statistics, volume 3. Cambridge university press, 2000.   \n[72]  Martin J Wainwright. High-dimensional statistics: A non-asymptotic viewpoint, volume 48. Cambridge university pres 2019.   \n[73] Jie Wang, Rui Gao, and Hongyuan Zha. Reliable off-policy evaluation for reinforcement learning. Operations Research, 72(2):699-716, 2024.   \n[74] Kaiwen Wang, Nathan Kallus, and Wen Sun. Near-minimax-optimal risk-sensitive reinforcement learning with cvar. In International Conference on Machine Learning, pages 35864-35907. PMLR, 2023.   \n[75] Kaiwen Wang, Kevin Zhou, Runzhe Wu, Nathan Kallus, and Wen Sun. The benefits of being distributional: Small-loss bounds for reinforcement learning. Advances in Neural Information Processing Systems, 36,2023.   \n[76] Kaiwen Wang, Nathan Kallus, and Wen Sun. The central role of the loss function in reinforcement learning. arXiv preprint arXiv:2409.12799, 2024.   \n[77] Kaiwen Wang, Dawen Liang, Nathan Kallus, and Wen Sun. Risk-sensitive rl with optimized certainty equivalents via reduction to standard rl. arXiv preprint arXiv:2403.06323, 2024.   \n[78] Kaiwen Wang, Owen Oertell, Alekh Agarwal, Nathan Kallus, and Wen Sun. More benefits of being distributional: Second-order bounds for reinforcement learning. International Conference ofMachineLearning,2024.   \n[79] Yue Wang and Shaofeng Zou. Online robust reinforcement learning with model uncertainty. Advances in Neural Information Processing Systems, 34:7193-7206, 2021.   \n[80] Wolfram Wiesemann, Daniel Kuhn, and Berc Rustem. Robust markov decision processes. Mathematics of Operations Research, 38(1):153-183, 2013.   \n[81] Wenhao Xu, Xuefeng Gao, and Xuedong He. Regret bounds for Markov decision processes with recursive optimized certainty equivalents. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 38400-38427. PMLR, 23-29 Jul 2023. URL https: //proceedings.mlr.press/v202/xu23d.html. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "Appendices ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "A Notations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Table 1: List of Notations ", "page_idx": 15}, {"type": "text", "text": "$S,A$ State and action spaces.   \n$\\Delta(S)$ The set of distributions supported by set $S$   \n$d_{1}$ The initial state distribution.   \n$\\Lambda(s,a)$ Tolerance parameter for kernel shift at $(s,a)$ . Takes values $[1,\\infty]$   \n$\\tau(s,a)$ $\\begin{array}{r}{\\tau(s,a)=\\frac{1}{1+\\Lambda(s,a)}\\in[0,\\frac{1}{2}]}\\end{array}$   \n$V^{\\pm},Q^{\\pm}$ Robust value and quality functions of the target policy $\\pi_{\\mathfrak{t}}$   \n$f(s,\\pi)$ $f(s,\\pi):=\\mathbb{E}_{a\\sim\\pi(s)}[f(s,a)].$   \n$U^{\\pm}(s^{\\prime}\\mid s,a)$ Robust transition kernel which attains the best- or worst-case value.   \n$\\mathcal{T}_{U},\\mathcal{T}_{\\mathsf{r o b}}^{\\pm}$ Bellman operator under $U$ and the robust Bellman operators.   \n$\\mathcal{I}_{U}$ $\\mathcal{T}_{U}f(s,a):=\\gamma\\mathbb{E}_{U}[f(s^{\\prime},\\pi_{\\mathrm{t}})\\mid s,a]-f(s,a)$   \n$\\beta_{\\tau}^{\\pm}(s,a)$ The upper $\\tau$ -th quantile of $V^{+}(s^{\\prime})$ and lower $\\tau$ -th quantile of $V^{-}(s^{\\prime}),\\,s^{\\prime}\\sim P(s,a)$ $d_{d_{1},U}^{\\pi_{\\mathrm{t}},\\infty}$ The $\\gamma$ -discounted average visitation of $\\pi_{\\updownarrow}$ under MDP with transition $U$ starting from $d_{1}$ \uff1a $d^{\\pm,\\infty}$ $d^{\\pm,\\infty}=d_{d_{1},U^{\\pm}}^{\\pi_{\\mathfrak{t}},\\infty}$   \n$\\nu(s),\\nu(s,a)$ Data generating distribution. $\\nu(s)$ marginalizes over actions.   \n$w^{\\pm}$ $w^{\\pm}=\\mathrm{d}d^{\\pm,\\infty}/\\mathrm{d}\\nu$ . This is valid both as a function of $s$ or $(s,a)$   \n$\\omega(s,a)$ $\\begin{array}{r}{\\omega(s,a)=\\frac{\\pi_{\\mathrm{t}}(a|s)}{\\nu(a|s)}}\\end{array}$   \n$x_{+},x_{-}$ $\\operatorname*{max}(0,x)$ \uff0c $\\operatorname*{min}(0,x)$ respectively, for $x\\in\\mathbb R$   \n$x\\lesssim y$ $x\\leq C y$ for some constant $C$   \n$\\mathbb{E}_{n}$ Empirical average over $n$ samples.   \n$\\|f\\|_{p}$ $L^{p}$ norm, $(\\mathbb{E}|f(X)|^{p})^{1/p}$   \n$f^{\\star}$ True (oracle) value of a parameter or function $f$   \n$f,{\\bar{f}}$ Putative value of a parameter or function $f$   \n$\\widehat{f}$ Estimated value of a parameter or function $f$ ", "page_idx": 15}, {"type": "text", "text": "B  Results for Policy Evaluation Under Best-Case Perturbations ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "In this section, we present analogous results for the best-case perturbation under the uncertainty set, corresponding to the supremum case of Eq. (2). We derive a similar orthogonal estimator with the properties outlined in Theorem 5.3, following the same reasoning presented in the main text. ", "page_idx": 15}, {"type": "text", "text": "$Q^{+}$ Identification and Estimation.  We present the results of Lemma 3.1 for $\\mathcal{T}_{\\mathsf{r o b}}^{+}$ ", "page_idx": 15}, {"type": "equation", "text": "", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "$\\begin{array}{r}{T_{\\mathrm{rob}}^{+}q(s,a)=r(s,a)+\\gamma\\Lambda^{-1}(s,a)\\mathbb{E}[v(s^{\\prime})\\mid s,a]+\\gamma(1-\\Lambda^{-1}(s,a))\\,\\mathrm{CVaR}_{\\tau(s,a)}^{+}[v(s^{\\prime})\\mid s,a].}\\end{array}$ Next, applying Assumption 3.2 and Assumption 3.3 to $\\mathcal{T}_{\\mathsf{r o b}}^{+}$ , we derive from Theorem 3.4 for $Q^{-}$ that: $\\begin{array}{r l}&{\\|\\widehat{q}_{M}^{+}-Q^{+}\\|_{d_{1}}\\lesssim(1-\\gamma)^{-2}(\\sqrt{C_{d_{1}}^{+}}\\cdot\\varepsilon_{n}^{Q}+\\mathsf{e r r}_{\\mathsf{O R}}^{2}(n/2M,\\delta/2M)),\\ \\mathrm{~and~}}\\\\ &{\\big|(1-\\gamma)\\mathbb{E}_{d_{1}}[\\widehat{v}_{M}^{+}(s_{1})]-V_{d_{1}}^{+}\\big|\\lesssim\\gamma^{M}+(1-\\gamma)^{-1}(\\sqrt{C_{d_{1}}^{+}}\\cdot\\varepsilon_{n}^{Q}+\\mathsf{e r r}_{\\mathsf{O R}}^{2}(n/2M,\\delta/2M)).}\\end{array}$ $w^{+}$ Identification and Estimation. We first state the identification result for $U^{-}$ as in Lemma 4.1: ", "page_idx": 15}, {"type": "text", "text": "", "page_idx": 15}, {"type": "equation", "text": "$$\nU^{+}(s^{\\prime}\\mid s,a)/P(s^{\\prime}\\mid s,a)=\\Lambda^{-1}(s,a)+(1-\\Lambda^{-1})\\tau(s,a)^{-1}\\mathbb{I}[(V^{+}(s^{\\prime})-\\beta_{\\tau}^{+}(s,a))\\geq0].\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "1: Input: Dataset $\\mathcal{D}$ , number of splits $K$   \n2: for $k=1,2,\\ldots,K$ do   \n3: Use data $\\mathcal{D}\\setminus\\mathcal{D}_{k}$ to learn $(q^{+,[k]},\\beta^{+,[k]})$ with Algorithm 1 and $w^{+,[k]}$ with Algorithm 2   \n4: for $i=\\lfloor(k-1)n/K\\rfloor,\\ldots,\\lfloor k n/K\\rfloor-1$ do $\\psi_{i}^{+}=\\psi(s_{i},a_{i},s_{i}^{\\prime},\\widehat{\\eta}^{+})$   \n5: Output: $\\begin{array}{r}{\\widehat{V}_{d_{1}}^{+}=\\frac{1}{n}\\sum_{i=1}^{n}\\psi_{i}^{+}}\\end{array}$ ", "page_idx": 16}, {"type": "text", "text": "Then, under Assumption 4.2 and Assumption 4.3 formulated for $U^{+}$ , the minimax rates from Theorem 4.4 are given by: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathcal{I}_{U^{+}}^{\\prime}(\\widehat{w}-w^{+})\\|_{2}\\lesssim\\varepsilon_{n}^{\\mathcal{W}}+\\|\\widetilde{\\zeta}^{+}-\\zeta^{+}\\|_{\\infty}+\\sqrt{\\log(1/\\delta)/n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Orthogonal and Efficient Estimator for $V_{d_{1}}^{+}$ . Let the set of nuisance parameters be denoted by $\\eta^{+}=(w^{+},q^{+},\\beta^{+})$ . Then, the (recentered) effcient influence function (R)EIF (see Theorem 5.1) forin $V_{d_{1}}^{+}$ is formulaed as: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\nu(s,a,s^{\\prime};\\eta^{+})=V_{d_{1}}^{+}+w^{+}(s,a)\\big(r(s,a)+\\gamma\\rho^{+}(s,a,s^{\\prime};v^{+},\\beta^{+})-q^{+}(s,a)\\big),\\quad\\mathrm{where}}\\\\ &{+(s,a,s^{\\prime};v^{+},\\beta^{+})=\\Lambda(s,a)^{-1}v^{+}(s^{\\prime})+(1-\\Lambda(s,a)^{-1})\\big(\\beta^{+}(s,a)+\\tau^{-1}(v^{+}(s^{\\prime})-\\beta^{+}(s,a))_{+}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Using this (R)EIF, the orthogonal estimator for $V_{d_{1}}^{+}$ is presented in Algorithm 4. We now restate Theorem 5.3 for $\\widehat V_{d_{1}}^{+}$ ", "page_idx": 16}, {"type": "text", "text": "Theorem B.1 (Effcency of $\\widehat V_{d_{1}}^{+}$ 0. Let $r_{n,p}^{w},r_{n,p}^{q},r_{n,p}^{\\beta}$ be functions of $\\begin{array}{r l r}{n}&{{}=}&{|\\mathcal{D}|}\\end{array}$ such that $\\begin{array}{r}{\\|\\mathcal{I}_{U^{+}}^{\\prime}(\\widehat{w}^{+,[k]}-w^{*})\\|_{p}\\leq r_{n,p}^{w},\\,\\|\\widehat{q}^{+,[k]}-q^{*}\\|_{p}\\leq r_{n,p}^{q}}\\end{array}$ and $\\|\\beta^{+,[k]}-\\beta^{*}\\|_{p}\\leq r_{n,p}^{\\beta}$ forany $k\\in[K]$ Furthermore,assume that the regularity conditions in Assumption 4.2hold.Then: ", "page_idx": 16}, {"type": "equation", "text": "$$\n|\\widehat{V}_{d_{1}}^{+}-V_{d_{1}}|\\lesssim O_{p}(n^{-1/2})+O_{p}(r_{n,2}^{w}r_{n,2}^{q}+(r_{n,\\infty}^{q})^{2}+(r_{n,\\infty}^{\\beta})^{2})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Furthermore, if $r_{n,2}^{w}\\,\\vee\\,r_{n,2}^{q}\\;=\\;o_{p}(1),\\;r_{n,2}^{w}r_{n,2}^{q}\\;=\\;o_{p}(n^{-1/2}),\\;r_{n,\\infty}^{q}\\;=$ $r_{n,\\infty}^{q}\\;=\\;o_{p}(n^{-1/4}),$ and $r_{n,\\infty}^{\\beta}\\,=$ $o_{p}(n^{-1/4})$ then $\\widehat{V}_{d_{1}}^{+}$ satisfes ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\sqrt{n}(\\widehat{V}_{d_{1}}^{+}-V_{d_{1}})\\stackrel{d}{\\rightarrow}\\mathcal{N}(0,\\Sigma),\\quad\\Sigma=\\mathrm{Var}(\\psi(s,a,s^{\\prime};\\eta^{+})).\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Moreover, $\\Sigma$ is the minimum achievable asymptotic variance among RAL estimators in the nonparametricmodelfor $(s,a,s^{\\prime})$ (theefficiencybound). ", "page_idx": 16}, {"type": "text", "text": "C Additional Related Works ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Robust MDPs. There is a rich literature on Robust MDPs [30, 34, 51, 80] with $s$ \uff0c $a$ -rectangular uncertainty sets, but these foundational works assumed knowledge of the transition kernel. Recently, learning-based robust MDP algorithms have been proposed for uncertainty sets under the total variation [47, 59] and more generally $L_{p}$ balls [46]. These $L_{p}$ uncertainty sets are additive in nature, i.e., the adversary adds or subtracts a vector in the $\\ell_{p}$ ball to $P(\\cdot\\mid s,a)$ , whereas our uncertainty set is multiplicative in nature, i.e., the adversary can multiply or divide a bounded factor and is more commonly used in causal inference to model unobserved confounding. In the contextual bandit setting, [41] also derived efficiency bounds for robust OPE where both state distribution and reward distributions may shift - their work is however restricted to the one-step bandit setting while our full RL setting is more challenging. ", "page_idx": 16}, {"type": "text", "text": "Risk-Sensitive RL. Risk-sensitive RL is the problem of optimizing the risk measure of cumulative rewards [32] and is tightly related to robust MDPs [20]. For example, as we proved in Lemma 3.1, the MSM uncertainty set is indeed equivalent to risk-sensitive RL with the dynamic risk measure $\\Lambda\\mathbb{E}+\\left(1-\\Lambda\\right)\\mathrm{CVaR}_{\\tau}$ . We note that efficient online RL algorithms have been proposed for similar measures [25, 81]. Static risk-sensitive RL also modifies the Bellman equations in an augmented MDP [74, 77]. Our focus is on deriving the optimal off-policy evaluation estimators for the problem, which involves a different set of challenges such as deriving the efciency bound and ensuring sharpness guarantees even when nuisances are estimated slowly. ", "page_idx": 16}, {"type": "text", "text": "D Additional Technical Details ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "D.1 Higher Order Norms via Smoothness ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "For any $x~\\in~\\mathbb{R}^{+}$ , define $\\lfloor x\\rfloor$ as the greatest integer that is strictly less than $x$ , and let $x$ and $\\{x\\}={\\dot{x}}-\\lfloor x\\rfloor$ represent the fractional part. Thus, we obtain the distinct decomposition $x=\\lfloor x\\rfloor+\\{x\\}$ where $\\lfloor x\\rfloor\\in\\mathbb{N}$ and $\\{x\\}\\in(0,1]$ ", "page_idx": 17}, {"type": "text", "text": "Definition D.1 ( $\\alpha$ -smooth functions). Given $\\alpha\\in(0,\\infty)$ and $\\mathcal{X}\\subseteq\\mathbb{R}^{m}$ \uff0c $f:\\mathcal{X}\\to\\mathbb{R}$ is an $\\alpha$ -smooth function if (1) the mixed derivatives up to. $\\lfloor\\alpha\\rfloor$ -order exist and are bounded; and (2) all $\\lfloor\\alpha\\rfloor$ -order derivatives are $\\{\\alpha\\}$ -Holder continuous [49]. ", "page_idx": 17}, {"type": "text", "text": "Lemma D.2 ( $L^{\\infty}$ Bound for $\\alpha$ -Smooth Functions). Let $f:\\mathcal{X}\\to\\mathbb{R},\\mathcal{X}\\subseteq\\mathbb{R}^{m}$ be an $\\alpha$ smooth function as in Definition D.1. Then, if $\\mathcal{X}$ is $\\mathbb{R}^{m}$ , a half-space or a bounded Lipschitz domain in $\\mathbb{R}^{m}$ there exists a constant $C$ such the following inequality holds: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\|f\\|_{\\infty}\\leq C\\|f\\|_{p}^{\\frac{p\\alpha}{p\\alpha+m}}.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Proof. This lemma is a direct application of the fractional Gagliardo-Nirenberg interpolation inequality (Theorem 1 in [11]) from the functional analysis literature. For a more comprehensive exposition on this result, see Appendix A.1 in [8]. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "D.2  Localized Rademacher Complexity and Critical Radius ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Here, we recap the localized Rademacher complexity and critical radius which is a standard complexity measure for obtaining fast rates for squared loss [72]. Let $\\mathcal{G}$ be a class of functions $g:\\mathcal{Z}\\to\\mathbb{R}$ Given $n$ datapoints $z_{1},z_{2},\\dots,z_{n}$ , the empirical localized Rademacher complexity is: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{R}_{n}(\\varepsilon,\\mathcal{G}):=\\mathbb{E}_{\\sigma}\\left[\\operatorname*{sup}_{g\\in\\mathcal{G}:\\|g\\|_{n}\\leq\\varepsilon}\\frac{1}{n}\\sum_{i=1}^{n}\\epsilon_{i}g(z_{i})\\right],\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\mathbb{E}_{\\sigma}$ isexpectationover $n$ independent Rademacher random variables $\\sigma_{1},\\sigma_{2},\\ldots,\\sigma_{n}$ , i.e., $\\begin{array}{r}{\\mathbb{E}_{\\sigma}[\\cdot]=\\frac{1}{2^{n}}\\sum_{\\sigma\\in\\{-1,1\\}^{n}}[\\cdot]}\\end{array}$ . Note that when $\\varepsilon=\\infty$ , there is no localization and $\\mathcal{R}_{n}(\\infty,\\mathcal{G})$ reduces to the vanilla Rademacher complexity. Let $\\begin{array}{r}{C:=\\operatorname*{sup}_{g\\in\\mathcal{G}}\\|g\\|_{\\infty}}\\end{array}$ be the envelope of $\\mathcal{G}$ . Then, the critical radius of $\\mathcal{G}$ with $n$ , called $\\varepsilon_{n}$ , is the smallest $\\varepsilon$ that satisfies $\\mathcal{R}_{n}(\\varepsilon,\\mathcal{G})\\leq\\varepsilon^{2}/C$ ", "page_idx": 17}, {"type": "text", "text": "Unless otherwise stated, we will posit that $\\mathcal{G}$ is star-shaped: there exists $g_{0}\\in\\mathcal{G}$ such that for all $g\\in{\\mathcal{G}}$ and $\\alpha\\in[0,1]$ , we have $\\alpha g_{0}+(1-\\alpha)g\\in\\mathcal{G}$ .If not, we can replace $\\mathcal{G}$ by its star-hull, $i.e.$ , the smallest star-shaped set containing $\\mathcal{G}$ . We will also posit that $\\mathcal{G}$ is symmetric for simplicity. ", "page_idx": 17}, {"type": "text", "text": "The critical radius is a well-studied quantity in statistics [72] and also recently in RL [26, 69]. For example if $\\mathcal{G}$ has $d$ VC-subgraph dimension, then w.p. $1-\\delta$ $-\\;\\delta,\\,\\varepsilon_{n}\\,\\leq\\,{\\mathcal{O}}({\\sqrt{d\\log n/n}})$ .For nonparametric models with metric entropy at most $1/t^{\\beta}$ , the critical radius can also be bounded by $\\mathcal{O}(\\bar{n}^{-1/(\\operatorname*{max}(2+\\beta,2\\beta))})$ [69], e.g., is $O(n^{-1/4})$ $\\beta=2$ ", "page_idx": 17}, {"type": "text", "text": "E Proofs for Identification Results ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "E.1  Identification of robust $Q$ ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Lemma 3.1. Set $\\tau(s,a)=\\left(\\Lambda(s,a)+1\\right)^{-1}$ . Then, for any $q:S\\times A\\to\\mathbb{R}$ ", "page_idx": 17}, {"type": "text", "text": "$\\mathcal{T}_{\\mathrm{rob}}^{-}q(s,a)=r(s,a)+\\gamma\\Lambda^{-1}(s,a)\\mathbb{E}[v(s^{\\prime})\\mid s,a]+\\gamma(1-\\Lambda^{-1}(s,a))\\,\\mathrm{CVaR}_{\\tau(s,a)}^{-}[v(s^{\\prime})\\mid s,a],$ where $v(s^{\\prime})=\\mathbb{E}_{a^{\\prime}\\sim\\pi_{t}(s^{\\prime})}[q(s^{\\prime},a^{\\prime})]$ and $\\mathbb{E}$ \uff0c $\\mathrm{CVaR}_{\\tau}$ are under the observed kernel $P(\\cdot\\mid s,a)$ ", "page_idx": 17}, {"type": "text", "text": "Proof. Consider the uncertainty set in $\\mathcal{T}_{\\sf r o b}$ where the constraint on $U$ (Eq. (1) can be rewritten as: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{0\\le\\frac{U(s^{\\prime}|s,a)-\\Lambda^{-1}(s,a)P(s^{\\prime}|s,a)}{P(s^{\\prime}|s,a)}\\le\\Lambda(s,a)-\\Lambda^{-1}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, we can write $U(s^{\\prime}\\mid s,a)=\\Lambda^{-1}(s,a)P(s^{\\prime}\\mid s,a)+(1-\\Lambda^{-1})G(s^{\\prime}\\mid s,a)$ where we $\\begin{array}{r}{G(s^{\\prime}\\mid s,a):=\\frac{U(s^{\\prime}\\mid s,a)-\\Lambda^{-1}(s,a)P(s^{\\prime}\\mid s,a)}{1-\\Lambda^{-1}(s,a)}}\\end{array}$ .n\uff0c $G$ $G(\\cdot\\mid s,a)\\ll$   \n$P(\\cdot\\mid s,a)$ $\\|\\frac{\\mathrm{d}G(s^{\\prime}|s,a)}{\\mathrm{d}P(s^{\\prime}|s,a)}\\|\\,\\le\\,\\Lambda(s,a)+1$ $\\begin{array}{r}{\\tau(s,a)\\,=\\,\\frac{1}{\\Lambda(s,a)+1}}\\end{array}$   \nform of CVaR [3, 24] to obtain ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{inf}_{\\substack{G\\ll P:\\|\\frac{\\mathrm{d}G(\\cdot\\,|\\,s,a)}{\\mathrm{d}P(\\cdot\\,|\\,s,a)}\\|_{\\infty}\\leq\\tau^{-1}(s,a)}}\\mathbb{E}_{G}[f(s^{\\prime})]=\\mathrm{CVaR}_{\\tau(s,a)}^{-}[f(s^{\\prime})\\mid s,a].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Therefore, the supremum in $\\mathcal{T}_{\\sf r o b}$ can be expressed as $\\Lambda^{-1}(s,a)$ times the expectation under nominal $P$ and $\\left(1-\\Lambda^{-1}\\bar{(}s,a)\\right)$ times the above CVaR expression, which finishes the proof of the - case. ", "page_idx": 18}, {"type": "text", "text": "For the $^+$ case, we can simply use sup instead of inf and upper CVaR instead of lower CVaR. ", "page_idx": 18}, {"type": "text", "text": "E.2 Identification of robust kernel and visitation ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Lemma 4.1. Suppose $F^{-}(\\beta_{\\tau}^{-}(s,a)\\ \\mid\\ s,a)\\;=\\;\\tau$ where $\\beta_{\\tau}^{-}(s,a)$ is the lower $\\tau$ -th quantile of $F^{-}(\\cdot\\mid s,a)$ . Then, ", "page_idx": 18}, {"type": "equation", "text": "$$\nU^{-}(s^{\\prime}\\mid s,a)/P(s^{\\prime}\\mid s,a)=\\Lambda^{-1}(s,a)+(1-\\Lambda^{-1})\\tau(s,a)^{-1}\\mathbb{I}[(V^{-}(s^{\\prime})-\\beta_{\\tau}^{-}(s,a))\\leq0].\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Lemma E.1. Fix any $v:{\\mathcal{S}}\\rightarrow\\mathbb{R}$ and define the pushforward $F_{v}(y\\mid s,a)=P(v(s^{\\prime})\\leq y\\mid s,a)$ Suppose $F_{v}(\\beta_{\\tau,F_{v}(\\cdot\\vert s,a)}^{\\pm}(s,a)\\mid s,a)\\;=\\;\\textstyle{\\frac{1}{2}}\\pm(\\textstyle{\\frac{1}{2}}\\,-\\,\\tau)$ , where $\\beta_{\\tau,F_{v}}^{\\pm}$ is the upper/lower $\\tau$ quantile of $F_{v}$ . Then, $\\begin{array}{r}{\\operatorname*{sup}_{U\\in\\mathcal{U}(P)}\\mathbb{E}_{U}[v(s^{\\prime})\\mid s,a]=\\mathbb{E}_{s^{\\prime}\\sim U_{v}^{+}(s,a)}[v(s^{\\prime})]}\\end{array}$ and $\\operatorname*{inf}_{U\\in\\mathcal{U}(P)}\\mathbb{E}_{U}[v(s^{\\prime})\\mid s,a]=$ $\\mathbb{E}_{s^{\\prime}\\sim U_{v}^{-}(s,a)}[v(s^{\\prime})]$ where ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\gamma_{v}^{\\pm}(s^{\\prime}\\mid s,a)/P(s^{\\prime}\\mid s,a)=\\Lambda^{-1}(s,a)+(1-\\Lambda^{-1})\\tau(s,a)^{-1}\\mathbb{I}[\\pm(v(s^{\\prime})-\\beta_{\\tau,F_{v}(\\cdot\\mid s,a)}^{\\pm}(s,a))\\ge0].}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Proof. We start with some intuitions. First, if the CDF of $v(s^{\\prime})$ is differentiable $\\beta_{\\tau}^{+}(s,a)$ , then $\\mathrm{CVaR}_{\\tau}^{+}(v(s^{\\prime})\\mid s,a)=\\mathbb{E}[v(s^{\\prime})\\mid f(s^{\\prime})\\ge,\\beta_{\\tau}^{+}(s,a),s,a]$ and the result follows immediately from Lemma 3.1 by noticing that the form of $U^{+}$ exactly recovers the convex combination of expectation and CVaR. Alternatively, one can use the closed form solution of the primal CVaR as derived in [3] to obtain the result. ", "page_idx": 18}, {"type": "text", "text": "We now provide a formal proof. Fix any $s,a$ and let $\\tau\\,=\\,\\tau(s,a)$ . Fix any function $v(s^{\\prime})\\in\\mathbb R$ We want to show that the worst-case $U^{+}~=~\\arg\\operatorname*{max}_{U\\in{\\mathcal{U}}(P)}\\mathbb{E}_{U}[v(s^{\\prime}){\\mathrm{~\\boldmath~\\xi~}}|\\mathrm{~\\boldmath~\\xi~}{s},a]$ has a closed form expression as shown in line 725. By the proof of Lemma 3.1 above, we can rewrite $U^{+}(s^{\\prime}\\ \\ \\stackrel{\\scriptscriptstyle{\\top}}{|}\\ s,a)\\ =\\ \\Lambda^{-1}(s,a)P(s^{\\prime}\\ \\ |\\ s,a)\\stackrel{\\scriptscriptstyle{\\top}}{+}(1\\ \\stackrel{\\scriptscriptstyle{\\leftarrow}}{-}\\Lambda^{-1}(s,a))G^{+}(s^{\\prime}\\ \\ |\\ s,a),$ where $\\begin{array}{r l}{G^{+}}&{{}=}\\end{array}$ arg $\\begin{array}{r}{\\operatorname*{max}_{G\\ll P:|d G(\\cdot|s,a)/d P(\\cdot|s,a)|_{\\infty}\\leq\\tau^{-1}(s,a)}\\mathbb{E}_{G}|v(s^{\\prime})|}\\end{array}$ Thus, it sufices to simplify $G^{+}$ . To do so, we invoke the premise that the CDF of $\\boldsymbol{v}(\\boldsymbol{s}^{\\prime})$ is differentiable at $\\beta_{\\tau}^{+}$ , i.e. $F_{v}(\\beta_{\\tau,F_{v}}^{+}(s,a)\\mid s,a)=1-\\tau$ This implies that the CVaR is exactly the conditional expectation of the $1-\\tau(s,a)$ -fraction of best outcomes, i.e. $\\mathtt{C V a R}_{\\tau}^{+}(v(s^{\\prime})\\mid s,a)=\\mathbb{E}[v(s^{\\prime})\\mid v(s^{\\prime})\\ge\\beta_{\\tau}^{+}(s,a),s,a]$ , which in turn is equal to $\\tau^{-1}\\mathbb{E}[v(s^{\\prime})\\mathbb{I}[v(s^{\\prime})\\geq\\langle\\mathring{\\beta_{\\tau}^{+}}(s,\\dot{a})]\\mid s,a]$ . Thus, G- $^{-}(s^{\\prime}\\mid s,a)\\stackrel{.}{=}\\tau^{-1}P(s^{\\prime}\\mid s,a)\\mathbb{I}[v(s^{\\prime})\\stackrel{}{=}\\beta_{\\tau}^{+}(s,a)]$ This concludes the proof for the $^+$ case. The proof for the - case follows identical steps. \u53e3 ", "page_idx": 18}, {"type": "text", "text": "F Proofs for Robust FQE ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "We prove a more general result with approximate completeness, which shows that Theorem 3.4 is robust to approximate completeness. ", "page_idx": 18}, {"type": "text", "text": "Assumption F.1 (Approximate Completeness). $\\begin{array}{r}{\\operatorname*{max}_{q\\in\\mathcal{Q}}\\operatorname*{min}_{g\\in\\mathcal{Q}}\\|g-T_{\\mathrm{CVaR}}^{\\pm}q\\|_{\\nu}\\leq\\varepsilon_{\\mathsf{Q C o m p}}.}\\end{array}$ ", "page_idx": 18}, {"type": "text", "text": "Theorem F.2. Assume Assumption F.1. Under the same setup as Theorem 3.4, we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathopen{}\\mathclose\\bgroup\\left\\|\\hat{q}_{K}^{\\pm}-Q^{\\pm}\\aftergroup\\egroup\\right\\|_{\\mu}\\lesssim\\frac{1}{(1-\\gamma)^{2}}\\mathopen{}\\mathclose\\bgroup\\left(\\sqrt{C_{\\mu}^{\\pm}}\\cdot\\bigl(\\varepsilon_{n}^{\\underline{{Q}}}+\\varepsilon_{0}\\mathsf{c o c o m p}\\bigr)+\\mathsf{e r r}_{\\mathsf{O R}}^{2}\\mathopen{}\\mathclose\\bgroup\\left(n/2K,\\delta/2K\\aftergroup\\egroup\\right)\\aftergroup\\egroup\\right),\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "and ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\big|V_{d_{1}}^{\\pm}-(1-\\gamma)\\mathbb{E}_{d_{1}}[\\widehat{q}_{K}^{\\pm}(s_{1},\\pi_{t})]\\big|\\lesssim\\gamma^{K}+\\frac{1}{1-\\gamma}(\\sqrt{C_{\\mu}^{\\pm}}\\cdot\\big(\\varepsilon_{n}^{\\underline{{Q}}}+\\varepsilon_{\\mathsf{O C o m p}}\\big)+\\mathsf{e r r}_{\\mathsf{O R}}^{2}(n/2K,\\delta/2K)).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Proof. Let $U^{\\pm}$ denote the worst-case kernel that satisfes $V_{d_{1}}^{\\pm}=(1-\\gamma)\\mathbb{E}_{d_{1}}V_{U^{\\pm}}^{\\pi_{\\mathfrak{t}}}(s_{1})$ Then, ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V_{d_{1}}^{\\pm}-(1-\\gamma)\\mathbb{E}_{d_{1}}[\\widehat{q}_{K}^{\\pm}(s_{1},\\pi_{\\mathrm{t}})]=(1-\\gamma)\\mathbb{E}_{d_{1}}[V_{U^{\\pm}}^{\\pi_{\\mathrm{t}}}(s_{1})-\\widehat{q}_{K}(s_{1},\\pi_{\\mathrm{t}})]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad=\\mathbb{E}_{d_{U^{\\pm}}^{\\pi,\\infty}}[\\mathcal{T}_{U^{\\pm}}^{\\pi_{\\mathrm{t}}}\\widehat{q}_{K}(s,a)-\\widehat{q}_{K}(s,a)]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{4}{1-\\gamma}\\operatorname*{max}_{k=1,2,\\ldots}\\rVert\\widehat{q}_{k}-\\mathcal{T}_{U^{\\pm}}^{\\pi_{\\mathrm{t}}}\\widehat{q}_{k-1}\\rVert_{d_{U^{\\pm}}^{\\pi_{\\mathrm{t}},\\infty}}+\\gamma^{K/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Consider any $k=1,2,\\ldots$ By definition of $U^{\\pm}$ , we have ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\widehat{q}_{k}-\\mathcal{T}_{U^{\\pm}}^{\\pi_{\\mathtt{t}}}\\widehat{q}_{k-1}\\right\\rVert_{d_{U^{\\pm}}^{\\pi_{\\mathtt{t}},\\infty}}=\\left\\lVert\\widehat{q}_{k}-\\mathcal{T}_{\\beta_{k}^{\\star}}^{\\pm}\\widehat{q}_{k-1}\\right\\rVert_{d^{\\pm},\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where $\\beta_{k}^{\\star}(s,a)$ is the true quantile of $\\widehat{v}_{k-1}(s^{\\prime})$ Denote $q_{k}^{\\star}:=\\,\\mathcal{T}_{\\sf r o b}^{\\pm}\\widehat{q}_{k-1}$ and let $\\beta_{k}^{\\star}$ be the true upper/lower quantile of $\\widehat{q}_{k-1}$ . Recall the population loss function is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad L_{k}(q,\\beta):=\\mathbb{E}\\bigg[\\Big(y_{k}^{\\beta}(s,a,s^{\\prime})-q(s,a)\\Big)^{2}\\bigg]}\\\\ &{y_{k}^{\\beta}(s,a,s^{\\prime})=r(s,a)+\\gamma\\Lambda^{-1}(s,a)\\widehat{v}_{k-1}(s^{\\prime})}\\\\ &{\\quad\\quad\\quad\\ +\\gamma(1-\\Lambda^{-1}(s,a))\\big(\\beta(s,a)+\\tau^{-1}(s,a)(\\widehat{v}_{k-1}(s^{\\prime})-\\beta(s,a))_{\\pm}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "The empirical loss $\\widehat{L}_{k}(q,\\beta)$ is if $\\mathbb{E}$ is replaced by $\\mathbb{E}_{n}$ . Note that $\\widehat{q}_{k}=\\arg\\operatorname*{min}_{q\\in\\mathcal{Q}}\\widehat{L}_{k}(q,\\widehat{\\beta}_{k})$ ", "page_idx": 19}, {"type": "text", "text": "Nonparametric Least Squares with Model Misspecification. We will directly invoke [72, Theorem 13.13], which gives a fast rate for misspecified least squares with general nonparametric classes. We now bound the misspecification. Recall that at the $k$ -th iteration, our regression Bayes-optimal is $\\mathbb{E}[y_{k}^{\\widehat{\\beta}_{k}}(s,a,s^{\\prime})\\mid s,a]=\\mathcal{T}_{\\widehat{\\beta}_{k}}\\widehat{q}_{k-1}(s,a)$ . By Lemma H.3, we know this is close to $\\tau_{\\beta_{k}^{\\star}}\\widehat{q}_{k-1}(s,a)$ with second order errors in $\\beta$ : for any $\\mu$ ,wehave ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\lVert\\mathcal{T}_{\\widehat{\\beta}_{k}}^{\\pm}\\widehat{q}_{k-1}-\\mathcal{T}_{\\beta_{k}^{\\star}}^{\\pm}\\widehat{q}_{k-1}\\right\\rVert_{d_{\\mu}^{\\pm,\\infty}}\\lesssim\\lVert\\widehat{\\beta}_{k}-\\beta_{k}^{\\star}\\rVert_{\\infty}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Finally, by approximate completeness (Assumption F.1), there exists $\\begin{array}{r l r}{g}&{{}\\in}&{\\mathcal{Q}}\\end{array}$ such that $\\lVert\\angles{\\mathcal{T}_{\\beta_{k}^{\\star}}}{\\boldsymbol{\\hat{q}}_{k-1}}(\\!\\!s,a\\!)\\!-\\!\\!g\\rVert\\;\\leq\\;\\varepsilon_{\\mathsf{O C o m p}}$ . Putting this together: for any $k$ ,there exists a $\\textit{g}\\in\\textit{Q}$ such that ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|g-T_{\\widehat{\\beta}_{k}}\\widehat{q}_{k-1}(s,a)\\|_{d_{\\mu}^{\\pm,\\infty}}\\leq\\|g-T_{\\beta_{k}}\\widehat{q}_{k-1}(s,a)\\|_{d_{\\mu}^{\\pm,\\infty}}+\\|T_{\\beta_{k}}\\widehat{q}_{k-1}(s,a)-T_{\\widehat{\\beta}_{k}}\\widehat{q}_{k-1}(s,a)\\|_{d_{\\mu}^{\\pm,\\infty}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\leq\\sqrt{C_{\\mu}^{\\pm}}\\cdot\\varepsilon_{\\sf O C o m p}+\\|\\widehat{\\beta}_{k}-\\beta_{k}^{\\star}\\|_{\\infty}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, [72, Theorem 13.13] (and concentration of least squares) certifies that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\widehat{q}_{k}-\\mathcal{T}_{\\widehat{\\beta}_{k}}\\widehat{q}_{k-1}\\right\\|_{d^{\\pm},\\infty}\\lesssim\\sqrt{C_{\\mu}^{\\pm}}\\cdot\\left(\\varepsilon_{0\\mathsf{C o m p}}+\\varepsilon_{n}\\right)+\\|\\widehat{\\beta}_{k}-\\beta_{k}^{\\star}\\|_{\\infty}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Therefore, we have proven: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r l}&{\\left\\|\\widehat{q}_{k}-\\mathcal{T}_{\\beta_{k}^{\\star}}^{\\pm}\\widehat{q}_{k-1}\\right\\|_{d_{\\mu}^{\\pm,\\infty}}\\leq\\left\\|\\widehat{q}_{k}-\\mathcal{T}_{\\widehat{\\beta}_{k}}^{\\pm}\\widehat{q}_{k-1}\\right\\|_{d_{\\mu}^{\\pm,\\infty}}+\\left\\|\\mathcal{T}_{\\widehat{\\beta}_{k}}^{\\pm}\\widehat{q}_{k-1}-\\mathcal{T}_{\\beta_{k}^{\\star}}^{\\pm}\\widehat{q}_{k-1}\\right\\|_{d_{\\mu}^{\\pm,\\infty}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\lesssim\\sqrt{C_{\\mu}^{\\pm}}\\cdot\\left(\\varepsilon_{0}\\mathrm{comp}+\\varepsilon_{n}\\right)+\\|\\widehat{\\beta}_{k}-\\beta_{k}^{\\star}\\|_{\\infty}^{2}.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 19}, {"type": "text", "text": "Lemma F.3 (Performance Difference). For any $\\pi$ ,transitionkernel $P$ andfunction $f:S\\times A\\to\\mathbb{R},$ wehave ", "page_idx": 20}, {"type": "equation", "text": "$$\nV_{P}^{\\pi}-\\mathbb{E}_{s\\sim d_{1}}[f(s,\\pi)]=\\frac{1}{1-\\gamma}\\mathbb{E}_{d_{P}^{\\pi,\\infty}}[{T}_{P}^{\\pi}f(s,a)-f(s,a)].\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. See Lemma C.1 of [15]. ", "page_idx": 20}, {"type": "text", "text": "Lemma F.4 (Unrolling). For any $\\pi$ transitionkernel $P$ andfunctions $f_{0},f_{1},\\ldots,f_{K}:S\\times A\\to\\mathbb{R}$ satisfying fo(s,a) =0, we have Ifk - Tp frklla\u221e \u2264 1- 1 $\\begin{array}{r}{\\|f_{K}-\\mathcal{T}_{P}^{\\pi}f_{K}\\|_{d_{P}^{\\pi,\\infty}}\\,\\le\\,\\frac{4}{1-\\gamma}\\operatorname*{max}_{k=1,2,\\ldots}\\|f_{k}-\\mathcal{T}_{P}^{\\pi}f_{k-1}\\|_{d_{P}^{\\pi,\\infty}}\\,+}\\end{array}$ $\\gamma^{K/2}$ ", "page_idx": 20}, {"type": "text", "text": "Proof. See Lemma C.2 of [15]. ", "page_idx": 20}, {"type": "text", "text": "G Proofs for Robust Minimax Algorithm ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Assumption G.1 (Approximate $W$ -realizability and completeness). Assume the following hold for   \n$\\mathcal{W}$ and $\\mathcal{F}$   \n(A) Approximate realizability: $\\begin{array}{r}{\\operatorname*{min}_{w\\in\\mathcal{W}}\\lVert\\mathcal{J}_{U^{\\pm}}(w^{\\pm}-w)\\rVert_{2}\\leq\\varepsilon_{\\mathsf{W R e a l}};}\\end{array}$   \n(B) Approximate completeness: $\\begin{array}{r}{\\operatorname*{max}_{w\\in\\mathcal{W}}\\operatorname*{min}_{f\\in\\mathcal{F}}\\mathopen{}\\mathclose\\bgroup\\left\\|f-\\mathcal{I}_{U^{\\pm}}^{\\prime}(w-w^{\\pm})\\aftergroup\\egroup\\right\\|_{2}\\leq\\varepsilon_{\\mathsf{W C o m p}}.}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "We prove a more general result with approximate realizability and completeness, which implies Theorem 4.4 that is robust to misspecification in its assumptions. ", "page_idx": 20}, {"type": "text", "text": "Theorem G.2. Under Assumption G.1 and the same setup as Theorem 4.4, we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\big\\|\\mathcal I_{U^{\\pm}}^{\\prime}(\\widehat{w}-w^{\\pm})\\big\\|_{2}\\lesssim\\varepsilon_{n}^{w}+\\|\\widetilde{\\zeta}^{\\pm}-\\zeta^{\\pm}\\|_{\\infty}+\\sqrt{\\frac{\\log(1/\\delta)}{n}}+\\varepsilon_{\\mathsf{W R e a l}}+\\varepsilon_{\\mathsf{W C o m p}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Proof. For this proof, we focus on the worst-case kernel $P^{\\star}$ of the form $\\begin{array}{r l}{\\frac{P^{\\star}(s^{\\prime}|s,a)}{P(s^{\\prime}|s,a)}}&{{}=}\\end{array}$ $\\tau^{-1}(s,a)\\mathbb{I}[\\zeta^{\\star}(s,a,s^{\\prime})\\,\\leq\\,0]$ where $\\zeta^{\\star}(s,a,s^{\\prime})\\:=\\:V^{-}(s^{\\prime})\\:-\\:\\beta^{-}(s,a)$ . This corresponds to the pure CVaR case of $\\mathcal{T}_{\\mathsf{r o b}}^{-}$ ; the $\\mathbb{E}$ part is identical to standard non-robust RL so we omit it. The best-case kernel $U^{+}$ can be handled similarly. Let $\\widehat{\\cal P}(s^{\\prime}\\ |\\ s,a)$ denote our estimated robust kernel, which satisfies P(s/ls,a) $\\begin{array}{r}{\\frac{\\widehat{P}(s^{\\prime}|s,a)}{P(s^{\\prime}|s,a)}=\\tau^{-1}(s,a)\\mathbb{I}[\\widehat{\\zeta}(s,a,s^{\\prime})\\leq0]}\\end{array}$ , where $\\widehat{\\zeta}(s,a,s^{\\prime})$ is the given prior stage estimate of $\\zeta^{\\star}(s,a,s^{\\prime})=V^{-}(s^{\\prime})-\\beta^{-}(s,a)$ ", "page_idx": 20}, {"type": "text", "text": "The key and only difference between our Algorithm 2 and the MIL algorithm $\\widehat{(w_{\\mathrm{mil}})}$ of [69] is that our next-state samples are importance weighted with $\\xi^{\\pm}\\big(s,a,s^{\\prime}\\big)$ , which is the density ratio of the estimated robust kernel $\\widehat{\\cal P}(s^{\\prime}\\mid s,a)$ and the nominal kernel $P(s^{\\prime}\\mid s,a)$ . Note also that $\\xi^{\\pm}(s,a,s^{\\prime})\\le$ $\\tau^{-1}(s,a)\\,<\\,\\infty$ , and hence $\\begin{array}{r}{|\\mathbb{E}_{n}[\\zeta(s,a,s^{\\prime})f(s^{\\prime})]-\\mathbb{E}_{s,a\\sim\\nu,s^{\\prime}\\sim\\widehat{P}(s,a)}[f(s^{\\prime})]|\\,\\lesssim\\,\\sqrt{\\log(1/\\delta)/n}}\\end{array}$ w.p. $1-\\delta$ . Therefore, up to $\\mathcal{O}(\\sqrt{\\log(1/\\delta)/n})$ errors, our Algorithm 2 can be viewed as MIL applied to the MDP with kernel $\\widehat{P}$ ", "page_idx": 20}, {"type": "text", "text": "To invoke the result of [69, Theorem 6.1] (in MDP with kernel P), we need to show that its assumptions are met by bounding the model misspecification, i.e., Eq. (6) and Appendix $\\mathbf{C}$ of [69]. Note that these misspecifications are w.r.t. the MDP with kernel P, since this is the MDP in which we're applying Theorem 6.1 of [69]. Specifically, the two errors we need to bound are, (A) approximate realizability: $\\begin{array}{r}{\\varepsilon_{A}\\,=\\,\\operatorname*{min}_{w\\in{\\mathcal W}}\\|\\bar{\\mathcal J}_{\\widehat{P}}^{\\prime}(w_{\\widehat{P}}-{\\,\\overset{\\cdot}{w}})\\|_{2}}\\end{array}$ ; and (B) approximate completeness: $\\begin{array}{r}{{\\varepsilon}_{B}=\\operatorname*{max}_{w\\in{\\mathcal{W}}}\\operatorname*{min}_{f\\in{\\mathcal{F}}}\\|f-{\\mathcal{I}_{\\widehat{P}}}^{\\prime}(w-w_{\\widehat{P}})\\|_{2}}\\end{array}$ where recall that $\\mathcal{I}_{P}$ is the linear operator defined as $\\mathcal{I}_{P}f(s,a):=\\gamma\\mathbb{E}_{P}[f(s^{\\prime},\\pi_{\\mathrm{t}})\\mid s,a]-f(s,a)$ and $\\mathcal{I}_{P}^{\\prime}$ is the adjoint. ", "page_idx": 20}, {"type": "text", "text": "Bounding misspecifications by $\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}$ \u00b7Since $\\zeta^{\\star}(s,a,s^{\\prime})$ has a marginal CDF that's boundedly differentiable around 0 (i.e., (i) of Assumption 4.2), [37, Lemma 3] implies that $\\zeta^{\\star}(s,a,s^{\\prime})$ satisfies a 1-margin (Definition H.2). Hence, Lemma H.3 and the continuity of $\\zeta^{\\star}(s,a,s^{\\prime})$ implies that ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\operatorname*{Pr}\\Bigl(\\mathbb{I}[\\widehat{\\zeta}(s,a,s^{\\prime})\\leq0]\\neq\\mathbb{I}[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0]\\Bigr)}\\\\ &{=\\operatorname*{Pr}\\Bigl((\\mathbb{I}[\\widehat{\\zeta}(s,a,s^{\\prime})\\leq0]\\neq\\mathbb{I}[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0]),\\zeta^{\\star}(s,a,s^{\\prime})\\neq0\\Bigr)\\lesssim\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Thus, for any $v:S\\rightarrow\\mathbb{R}$ ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\big|(\\mathbb{E}_{\\widehat{P}}-\\mathbb{E}_{P^{\\star}})[v(s^{\\prime})\\mid s,a]\\big|\\leq\\mathbb{E}[\\tau^{-1}(s,a)(\\mathbb{I}[\\widehat{\\zeta}(s,a,s^{\\prime})\\leq0]\\neq\\mathbb{I}[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0])\\cdot|v(s^{\\prime})|]}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\lesssim\\|v\\|_{\\infty}\\cdot\\operatorname*{Pr}\\Big(\\mathbb{I}[\\widehat{\\zeta}(s,a,s^{\\prime})\\leq0]\\neq\\mathbb{I}[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0]\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\lesssim\\|v\\|_{\\infty}\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "or equivalently ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{E}\\|\\widehat{P}(\\cdot\\mid s,a)-P^{\\star}(\\cdot\\mid s,a)\\|\\uptau\\lesssim\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}.\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Equipped with Eq. (7), we can now bound the following two types of errors: (i) $\\langle f,(T_{P^{\\star}}-T_{\\widehat{P}})g\\rangle$ and (i) $\\langle w_{\\hat{P}}-w_{P^{\\star}},h\\rangle$ , where $f,g:S\\times A\\rightarrow\\mathbb{R}$ and $h:{\\mathcal{S}}\\rightarrow\\mathbb{R}$ , and $\\mathcal{T}_{P}$ and $w_{P}$ are the Beliman operator and visitation density of target policy $\\pi_{\\mathfrak{t}}$ in the MDP with kernel $P$ ", "page_idx": 21}, {"type": "text", "text": "For (i): ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\langle f,(\\mathcal{I}_{P^{\\star}}-\\mathcal{I}_{\\widehat{P}})g\\rangle\\right|=\\left|\\mathbb{E}[f(s,a)\\big(\\gamma(\\mathbb{E}_{P^{\\star}}-\\mathbb{E}_{\\widehat{P}})[g(s^{\\prime},\\pi_{\\sf t})\\mid s,a]\\big)]\\right|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\gamma\\|f\\|_{\\infty}\\mathbb{E}\\big|\\big(\\mathbb{E}_{P^{\\star}}-\\mathbb{E}_{\\widehat{P}})[g(s^{\\prime},\\pi_{\\sf t})\\mid s,a]\\big|}\\\\ &{\\qquad\\qquad\\qquad\\lesssim\\gamma\\|f\\|_{\\infty}\\|g(\\cdot,\\pi_{\\sf t})\\|_{\\infty}\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "For (i): ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\langle w_{\\hat{P}}-w_{P^{\\star}},h\\rangle=\\mathbb{E}[(w_{\\hat{P}}(s)-w_{P^{\\star}}(s))h(s)]}&{}\\\\ {\\quad\\le\\|h\\|_{\\infty}\\|d_{\\hat{P}}-d_{P^{\\star}}\\|_{\\Upsilon}}&{}\\\\ {\\quad\\le\\|h\\|_{\\infty}\\frac{\\gamma}{1-\\gamma}\\mathbb{E}_{d_{P^{\\star}}}\\|\\hat{P}(\\cdot\\ |\\ s,a)-P^{\\star}(\\cdot\\ |\\ s,a)\\|_{\\Upsilon}}&{}\\\\ {\\quad\\lesssim C\\|h\\|_{\\infty}\\frac{\\gamma}{1-\\gamma}\\mathbb{E}\\|\\hat{P}(\\cdot\\ |\\ s,a)-P^{\\star}(\\cdot\\ |\\ s,a)\\|_{\\Upsilon}}&{}\\\\ {\\quad\\lesssim C\\|h\\|_{\\infty}\\frac{\\gamma}{1-\\gamma}\\|\\hat{\\zeta}-\\zeta^{\\star}\\|_{\\infty},}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $C=\\|\\mathrm{d}\\boldsymbol{d}^{P^{\\star}}/\\mathrm{d}\\boldsymbol{\\nu}\\|_{\\infty}<\\infty$ ", "page_idx": 21}, {"type": "text", "text": "For approximate realizability $\\left(\\varepsilon_{A}\\right)$ : for any $w\\in\\mathcal{W}$ ,we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\mathcal{I}_{\\widehat{P}}^{\\prime}(w_{\\widehat{P}}-w)\\|_{2}}\\\\ &{\\le\\|(\\mathcal{T}_{\\widehat{P}}-\\mathcal{T}_{P^{\\star}})^{\\prime}(w_{\\widehat{P}}-w)\\|_{2}+\\|\\mathcal{I}_{P^{\\star}}^{\\prime}(w_{\\widehat{P}}-w_{P^{\\star}})\\|_{2}+\\|\\mathcal{I}_{P^{\\star}}^{\\prime}(w^{\\star}-w)\\|_{2}}\\\\ &{=\\langle w_{\\widehat{P}}-w,(\\mathcal{T}_{\\widehat{P}}-\\mathcal{T}_{P^{\\star}})g_{1}\\rangle+\\langle w_{\\widehat{P}}-w_{P^{\\star}},\\mathcal{T}_{P^{\\star}}g_{2}\\rangle+\\|\\mathcal{I}_{P^{\\star}}^{\\prime}(w^{\\star}-w)\\|_{2}}\\\\ &{\\lesssim\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}+\\|\\mathcal{I}_{P^{\\star}}^{\\prime}(w^{\\star}-w)\\|_{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\begin{array}{r}{\\begin{array}{r l}{g_{1}\\mathrm{\\boldmath~\\Pi~}_{:}=}&{{}((\\mathcal{I}_{P^{\\star}}\\mathrm{\\boldmath~-~}\\mathcal{I}_{\\widehat{P}})^{\\prime}(w_{\\widehat{P}}\\mathrm{\\boldmath~-~}w))/\\|(\\mathcal{I}_{P^{\\star}}\\mathrm{\\boldmath~-~}\\mathcal{I}_{\\widehat{P}})^{\\prime}(w_{\\widehat{P}}\\mathrm{\\boldmath~-~}w)\\|_{2},}\\end{array}}\\end{array}$ $\\begin{array}{r c l}{g_{2}}&{=}&{(\\mathcal{J}_{P^{\\star}}^{\\prime}(w_{\\widehat{P}}\\,\\mathrm{~-~}}\\end{array}$ $w_{P^{\\star}}))/\\|\\mathcal{T}_{P^{\\star}}^{\\prime}(w_{\\widehat{P}}-w_{P^{\\star}})\\|_{2}$ . The last inequality uses (i) and (i) with the fact that $\\|g_{1}\\|_{\\infty}<\\infty$ and $\\|g_{2}\\|_{\\infty}<\\infty$ as the $w$ terms are bounded by our premise. Therefore, taking min over $w$ and using Assumption G.1, we have $\\varepsilon_{A}\\lesssim\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}+\\varepsilon_{\\sf W R e a l}.$ ", "page_idx": 21}, {"type": "text", "text": "For approximate completeness $\\left(\\varepsilon_{B}\\right)$ : for any $w\\in\\mathcal{W}$ and $f\\in\\mathcal F$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|f-\\mathcal{T}_{\\hat{P}}^{\\prime}(w-w_{\\hat{P}})\\|_{2}}\\\\ &{\\leq\\|f-\\mathcal{T}_{P^{\\star}}^{\\prime}(w-w_{P^{\\star}})\\|_{2}+\\|(\\mathcal{T}_{P^{\\star}}-\\mathcal{T}_{\\hat{P}})^{\\prime}(w-w_{P^{\\star}})\\|_{2}+\\|\\mathcal{T}_{P^{\\star}}^{\\prime}(w_{\\hat{P}}-w_{P^{\\star}})\\|_{2}}\\\\ &{\\lesssim\\|f-\\mathcal{T}_{P^{\\star}}^{\\prime}(w-w_{P^{\\star}})\\|_{2}+\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty},}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "for the same reason as $\\varepsilon_{A}$ as the error terms are the same. Thus, $\\varepsilon_{B}\\lesssim\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}+\\varepsilon_{\\sf W C o m p}.$ ", "page_idx": 22}, {"type": "text", "text": "In sum, we have shown that the misspecification is at most $\\mathcal{O}(\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}+\\varepsilon_{\\sf W R e a l}+\\varepsilon_{\\sf W C o m p})$ Therefore, [69, Theorem 6.1 and Appendix C] ensures that w.p. $1-\\delta$ , our learned $\\widehat{w}$ satisfies, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\mathcal{I}_{\\widehat{P}}^{\\prime}(\\widehat{w}-w_{\\widehat{P}})\\right\\|_{2}\\lesssim\\varepsilon_{n}^{\\mathcal{W}}+\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}+\\varepsilon_{\\mathsf{W R e a l}}+\\varepsilon_{\\mathsf{W C o m p}}+\\sqrt{\\log(1/\\delta)/n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Concluding the proof. The final step is to translate the above guarantee to $\\|\\mathcal{T}_{P^{\\star}}^{\\prime}(\\widehat{w}-w_{P^{\\star}})\\|_{2}$ The following shows that the switching cost is $O(\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty})$ asbefore: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\mathcal{I}_{P^{\\star}}^{\\prime}(\\widehat{w}-w_{P^{\\star}})\\|_{2}}\\\\ &{\\leq\\|(\\mathcal{T}_{P^{\\star}}-\\mathcal{T}_{\\widehat{P}})^{\\prime}(\\widehat{w}-w_{P^{\\star}})\\|_{2}+\\|\\mathcal{I}_{\\widehat{P}}^{\\prime}(\\widehat{w}-w_{\\widehat{P}})\\|_{2}+\\|\\mathcal{I}_{\\widehat{P}}^{\\prime}(w_{\\widehat{P}}-w_{P^{\\star}})\\|_{2}}\\\\ &{\\lesssim\\varepsilon_{n}^{w}+\\|\\widehat{\\zeta}-\\zeta^{\\star}\\|_{\\infty}+\\varepsilon_{\\mathsf{W R e a l}}+\\varepsilon_{\\mathsf{W C o m p}}+\\sqrt{\\log(1/\\delta)/n}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 22}, {"type": "text", "text": "Lemma G.3 (Visitation performance-difference). Let $P,U:S\\rightarrow\\mathbb{R}_{+}$ benon-negativemeasures, which should be thought of as transitions in a discounted Markov chain.Assume $U$ satisfies $\\begin{array}{r}{\\sum_{s^{\\prime}}U(s^{\\prime}\\mid s)\\le1}\\end{array}$ Defne $\\begin{array}{r}{\\tilde{d}_{U}=(1-\\gamma)\\sum_{h=1}^{\\infty}\\gamma^{h-1}d_{U}^{h}}\\end{array}$ where $\\begin{array}{r}{d_{U}^{h}=\\int_{s_{1},s_{2},\\dots,s_{h-1}}d_{1}(s_{1})U(\\dot{s}_{2}\\mid}\\end{array}$ $s_{1})\\dotsm U(s\\mid s_{h-1})\\mathrm{d}s_{1:h-1}$ .Assume the same for $P$ ", "page_idx": 22}, {"type": "text", "text": "Let ${\\mathcal{F}}\\subset{\\mathcal{S}}\\rightarrow\\mathbb{R}$ be a function class that satisfies $f\\,\\in\\,{\\mathcal{F}}\\implies g(s)\\,=\\,\\mathbb{E}_{s^{\\prime}\\sim P(s)}[f(s^{\\prime})]\\,\\in\\,{\\mathcal{F}}$ i.e., closed under projection with $P$ .Then, define the integral (probability) metric $\\|P-U\\|_{\\mathcal{F}}:=$ $\\begin{array}{r}{\\operatorname*{sup}_{f\\in\\mathcal{F}}\\bigl|\\bigl(\\mathbb{E}_{P}-\\mathbb{E}_{U}\\bigr)\\bigl[f(s)\\bigr]\\bigr|}\\end{array}$ . Then we have, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\|d_{P}-d_{U}\\|_{\\mathcal{F}}\\leq\\frac{\\gamma}{1-\\gamma}\\mathbb{E}_{d_{U}}\\|P(\\cdot\\mid s)-U(\\cdot\\mid s)\\|_{\\mathcal{F}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. Recall Bellman's flow, which is $d_{P}(s)=(1-\\gamma)d_{1}(s)+\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d_{P}}P(s\\mid\\widetilde{s})$ .Fix any $f\\in\\mathcal F$ The initial state distributions cancel, so we have, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\big|\\big(\\mathbb{E}_{d P}-\\mathbb{E}_{d U}\\big)[f(s)]\\big|}\\\\ &{=\\big|\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d P}\\mathbb{E}_{s\\sim P(\\cdot|\\widetilde{s})}[f(s)]-\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d U}\\mathbb{E}_{s\\sim U(\\cdot|\\widetilde{s})}[f(s)]\\big|}\\\\ &{\\le\\big|\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d P}\\mathbb{E}_{s\\sim P(\\cdot|\\widetilde{s})}[f(s)]-\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d U}\\mathbb{E}_{s\\sim P(\\cdot|\\widetilde{s})}[f(s)]\\big|}\\\\ &{+\\left|\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d U}\\mathbb{E}_{s\\sim P(\\cdot|\\widetilde{s})}[f(s)]-\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d U}\\mathbb{E}_{s\\sim U(\\cdot|\\widetilde{s})}[f(s)]\\right|}\\\\ &{\\le\\gamma\\big|\\big(\\mathbb{E}_{\\widetilde{s}\\sim d P}-\\mathbb{E}_{\\widetilde{s}\\sim d U}\\big)[\\mathbb{E}_{s\\sim P(\\cdot|\\widetilde{s})}f(s)]\\big|+\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d U}\\left|\\big(\\mathbb{E}_{s\\sim P(\\cdot|\\widetilde{s})}-\\mathbb{E}_{s\\sim U(\\cdot|\\widetilde{s})}\\big)[f(s)]\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Thus, taking supremum over $\\mathcal{F}$ ,we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\lefteqn{\\|d_{P}-d_{U}\\|_{\\mathcal{F}}}}\\\\ &{\\leq\\gamma\\operatorname*{sup}_{f\\in\\mathcal{F}}\\bigl|(\\mathbb{E}_{\\widetilde{s}\\sim d_{P}}-\\mathbb{E}_{\\widetilde{s}\\sim d_{U}})[\\mathbb{E}_{s\\sim P(\\widetilde{s})}f(s)]\\bigr|+\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d_{U}}\\operatorname*{sup}_{f\\in\\mathcal{F}}\\bigl|\\bigl(\\mathbb{E}_{s\\sim P(\\cdot|\\widetilde{s})}-\\mathbb{E}_{s\\sim U(\\cdot|\\widetilde{s})}\\bigr)[f(s)]\\bigr|}\\\\ &{=\\gamma\\|d_{P}-d_{U}\\|_{\\mathcal{F}}+\\gamma\\mathbb{E}_{\\widetilde{s}\\sim d_{U}}\\|P(\\cdot|\\,\\widetilde{s})-U(\\cdot\\,|\\,\\widetilde{s})\\|_{\\mathcal{F}}.}&{(\\mathcal{F}\\,\\mathrm{closed~under~}P\\mathrm{-projection})}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Rearranging terms finishes the proof. ", "page_idx": 22}, {"type": "text", "text": "If $\\mathcal{F}$ is the class of functions with $\\|f\\|_{\\infty}\\leq1$ , then this recovers the TV distance, which gives, ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\lVert d_{P}-d_{U}\\rVert_{\\mathsf{T V}}\\le\\frac{\\gamma}{1-\\gamma}\\mathbb{E}_{d_{U}}\\lVert P(\\cdot\\mid s)-U(\\cdot\\mid s)\\rVert_{\\mathsf{T V}}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This generalizes Lemma E.3 of [1] to infinite horizon. ", "page_idx": 22}, {"type": "text", "text": "H  Proofs and Additional Details for the Orthogonal Estimator ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "H.1 Intuition for Theorem 5.3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "We provide some intuition for the results in Theorem 5.3. Consider the $V^{-}$ bound and let us decouple the indicator $\\mathbb{I}\\left[v(s^{\\prime})-\\beta(s,a)\\le0\\right]$ that appears implicitly in the $(v^{-}(s^{\\prime})\\mathrm{~-~}\\beta^{-}(s,a))_{-}$ notation of Theorem 5.1. We augment the set of nuisances with $\\zeta(s,a,s^{\\prime})=v^{-}(s^{\\prime})-\\beta^{-}(s,\\stackrel{..}{a})$ such that $(v^{-}(s^{\\prime})\\!-\\!\\beta^{-}(s,a))_{-}=\\overline{{(v^{-}(s^{\\prime})\\!-\\!\\beta^{-}(s,a))}}\\mathbb{I}\\left[\\zeta(s,a,s^{\\prime})\\leq0\\right]$ .We state the following lemma (which we elaborate upon in Lemmas H.4 and H.5 in the Appendix): ", "page_idx": 23}, {"type": "text", "text": "Lemma H.1 (Double sharpness with correct $\\zeta^{\\star}.$ 0.Let $\\mathbb{E}[\\psi(s,a,s^{\\prime};q,w,\\beta,\\zeta^{\\star})]$ be the expectation of the $(R)E I F$ with anarbitrary nuisance set $\\eta=(w,q,\\beta)$ ,but where the indicator $\\mathbb{I}[v^{-}(s^{\\prime})\\bar{\\leq}\\,\\beta^{-}(s,a)\\]$ has been replaced with the correct indicator $\\mathbb{I}[\\zeta^{\\star}(s,a,s^{\\prime})\\le0]$ . Then: ", "page_idx": 23}, {"type": "equation", "text": "$$\nV_{d_{1}}^{-}=\\mathbb{E}[\\psi(s,a,s^{\\prime};q,w^{\\star},\\beta^{\\star},\\zeta^{\\star})]=\\mathbb{E}[\\psi(s,a,s^{\\prime};q^{\\star},w,\\beta^{\\star},\\zeta^{\\star})]\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "This lemma implies that if $\\beta^{-}=(\\beta^{*})^{-}$ and $\\zeta=\\zeta^{*}$ , then the estimator $\\widehat{V}_{d_{1}}^{-}$ has a property known as \u201cdouble-robustness\" [43] or \u201cdouble-sharpness\" [24] in $q$ and $w$ , meaning the bias vanishes when either $q$ 0 $w$ is consistent. Moreover, the convergencerate would be $O_{p}(\\bar{r_{n,2}}r_{n,2}^{q})$ . This condition holds provided that $\\beta$ and $\\zeta$ are correctly specified. However, estimation errors in $\\beta$ introduce an additional $O_{p}\\left((r_{n,\\infty}^{\\beta})^{2}\\right)$ term, refecting that $\\beta$ is first-order optimal for the CVaR component. Additionally, discrepancies between $\\zeta$ and $\\zeta^{*}$ contribute an extra $O_{p}$ $_{p}\\left((r_{n,\\infty}^{q})^{2}\\right)$ to the error. While this discussion gives some insight into how we achieve the results in Theorem 5.3, we provide a a rigorous analysis in the next section. ", "page_idx": 23}, {"type": "text", "text": "H.2 Preliminaries ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "For this proof, our focus will be on $\\widehat{V}_{d_{1}}^{-}$ .The argument for $\\widehat V_{d_{1}}^{+}$ is analogous, following a symmetric approach. To improve the clarity of our exposition, we will omit the - and $\\tau$ indices, assuming their presence is clear from the context. ", "page_idx": 23}, {"type": "text", "text": "For simplicity, we assume that $n$ is a multiple of $K$ such that $n=K n_{K}$ , where $n_{K}$ is the size of a fold. We let $\\mathbb{E}_{n},\\mathbb{E}_{k}$ denote the empirical averages over the entire sample and the $k^{\\mathrm{th}}$ fold, respectively. Recall that we use $\\widehat{\\eta}=(\\widehat{w},\\widehat{q},\\widehat{\\beta})$ and $\\eta^{*}=(w^{*},q^{*},\\beta^{*})$ to denote the estimated and oracle nuisances, respectively. ", "page_idx": 23}, {"type": "text", "text": "We further suppress the dependency on $s,a$ in $\\Lambda$ and $\\tau$ and we write the $\\rho$ term in Theorem 5.1 as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\rho(s,a,s^{\\prime};v,\\beta)=(1-\\lambda)v(s^{\\prime})+\\lambda\\big(\\beta(s,a)+\\tau^{-1}(v(s^{\\prime})-\\beta(s,a))_{-}\\big).\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "We justify this by noting that the analysis holds regardless of whether $\\lambda$ and $\\tau$ depend on $s,a$ Sometimes, it will be useful to decouple the indicator $\\mathbb{I}\\left[v(s^{\\prime})-\\beta(s,a)\\le0\\right]$ implicit in the definition of $\\rho$ . In this case, we augment the set of nuisances with $\\zeta(s,a,s^{\\prime})=v(s^{\\prime})-\\beta(s,a)$ and write $\\rho$ as ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\rho(s,a,s^{\\prime};v,\\beta,\\zeta)=(1-\\lambda)v(s^{\\prime})+\\lambda\\big(\\beta(s,a)+\\tau^{-1}(v(s^{\\prime})-\\beta(s,a))\\mathbb{I}\\left[\\zeta(s,a,s^{\\prime})\\leq0\\right]\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Similarly define $\\psi(\\cdot;w,q,\\beta,\\zeta)$ with the $\\rho(\\cdot;v,\\beta,\\zeta)$ ", "page_idx": 23}, {"type": "text", "text": "H.3  Auxiliary Lemmas ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Definition H.2 (Margin Condition). A function $f:\\mathcal{X}\\to\\mathbb{R}$ of some random variable $X$ is said to satisfy the margin condition with sharpness $\\alpha\\in[0,\\infty]$ (or more succinctly, an $\\alpha$ -margin) if there exist a fixed constant $c>0$ such that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\forall t>0:P(0<|f(X)|\\leq t)\\leq c t^{\\alpha}.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "If $f(X)$ is either zero or bounded away from zero almost surely, then $f$ satisfies an infinite margin, i.e., $\\alpha=\\infty$ [37, Lemma 2]. If $f(X)$ is continuously distributed in a neighborhood around O, i.e., ", "page_idx": 23}, {"type": "text", "text": "its CDF is boundedly differentiable on $\\left(-\\varepsilon,0\\right)\\cup\\left(0,\\varepsilon\\right)$ for some $\\varepsilon>0$ , then $f$ has a 1-margin [37, Lemma 3]. ", "page_idx": 24}, {"type": "text", "text": "Lemma H.3 (Margin Guarantees). For any $f:\\,x\\,\\rightarrow\\,\\mathbb{R}$ satisfying $\\alpha$ -margin(Definition $H.2$ $p\\in[1,\\infty]$ ,andany $g:\\mathcal{X}\\to\\mathbb{R}$ thefollowing statements holdfor some constant $C>0$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{E}[(\\mathbb{I}[g(X)\\leq0]-\\mathbb{I}[f(X)\\leq0])f(X)]\\leq C\\|f-g\\|_{p}^{\\frac{p(1+\\alpha)}{p+\\alpha}},}&{}\\\\ {P[\\mathbb{I}[g(X)\\leq0]\\neq\\mathbb{I}[f(X)\\leq0],f(X)\\neq0]\\leq C\\|f-g\\|_{p}^{\\frac{p\\alpha}{p+\\alpha}},}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where $\\left\\|\\cdot\\right\\|_{p}$ is the $L^{p}$ norm and we set $\\infty t/\\infty=t$ in the exponents. ", "page_idx": 24}, {"type": "text", "text": "The proof of Eq. (12) for any $p\\in[1,\\infty]$ and of Eq. (13) for $p=\\infty$ is given in [4, Lemmas 5.1 and 5.2]. The proof of Eq. (13) for $p<\\infty$ is given in [37, Lemma 5]. ", "page_idx": 24}, {"type": "text", "text": "Lemma H.4 Sharpness with correct $q^{\\star}$ and $\\beta^{\\star}$ $\\begin{array}{r}{\\frac{1}{n}\\sum_{(s,a,s^{\\prime})\\sim\\mathcal{D}}\\psi(s,a,s^{\\prime};w,q,\\beta)}\\end{array}$ is an unbiased estimator of $V_{d_{1}}^{\\star}$ when $q=q^{\\star},\\beta=\\beta^{\\star}$ , i.e., ", "page_idx": 24}, {"type": "equation", "text": "$$\n(1-\\gamma)\\mathbb{E}_{d_{1}}v^{\\star}(s_{1})=\\mathbb{E}[\\psi(s,a,s^{\\prime};w,q^{\\star},\\beta{\\star})].\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof.Since $q^{\\star}$ and $\\beta^{\\star}$ are correct, the robust Bellman equation holds, and so for every $s,a$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbb{E}\\big[(1-\\lambda)v^{\\star}(s^{\\prime})+\\lambda(\\beta^{\\star}(s,a)+\\tau^{-1}(v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a))_{-})\\mid s,a\\big]=0.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus, multiplying by any $w$ does not change the fact that the debiasing term in $\\psi$ has expectation zero. Since we have $v^{\\star}$ , the first term in $\\psi$ is exactly the estimand, which concludes the proof. ", "page_idx": 24}, {"type": "text", "text": "Lemma H.5 (Sharpness with correct $w^{*}$ and $\\zeta^{*}$ $\\begin{array}{r}{\\frac{1}{n}\\sum_{(s,a,s^{\\prime})\\sim\\mathcal{D}}\\psi(s,a,s^{\\prime};w,q,\\beta,\\zeta)}\\end{array}$ is an unbiased estimator of $V_{d_{1}}^{\\star}$ when $w=w^{\\star},\\zeta=\\zeta^{\\star}$ , i.e., ", "page_idx": 24}, {"type": "equation", "text": "$$\n(1-\\gamma)\\mathbb{E}_{d_{1}}v^{\\star}(s_{1})=\\mathbb{E}[\\psi(s,a,s^{\\prime};q,w^{\\star},\\beta,\\zeta^{\\star})]\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Proof.Let $P^{\\star}$ denote the robust transition kernel and let $d^{\\star}$ denote the robust visitation measure under $\\pi$ , which satisfies: for all functions $f$ \uff0c ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}_{d^{\\star}}[f(s,a)]=(1-\\gamma)\\mathbb{E}_{d_{1}}f(s,\\pi)+\\gamma\\mathbb{E}_{\\widetilde{s},\\widetilde{a}\\sim d^{\\star},s\\sim P^{\\star}(s,a)}[f(s,\\pi)].}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Since $\\zeta^{\\star}$ is correct, for any $v,s,a$ , we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\mathbb{E}_{s^{\\prime}\\sim P(s,a)}\\left[(1-\\lambda)v(s^{\\prime})+\\lambda\\left(\\beta(s,a)+\\tau^{-1}(v(s^{\\prime})-\\beta(s,a))\\mathbb{I}\\left[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0\\right]\\right)\\right]}\\\\ &{\\ =\\mathbb{E}_{s^{\\prime}\\sim P(s,a)}\\left[(1-\\lambda)v(s^{\\prime})+\\lambda\\tau^{-1}v(s^{\\prime})\\mathbb{I}\\left[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0\\right]\\right]}\\\\ &{\\ =\\mathbb{E}_{s^{\\prime}\\sim P^{\\star}(s,a)}[v(s^{\\prime})],}&{\\mathrm{(Len~}~\\mathrm{~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where in $\\star$ weused $\\begin{array}{r l}&{\\mathbb{E}_{s_{\\cdot}^{\\prime}\\sim P(s,a)}\\big[\\beta(s,a)\\big(1-\\tau^{-1}\\mathbb{I}\\left[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0\\right]\\big)\\big]\\,=\\,\\beta(s,a)\\big(1-\\tau^{-1}\\tau\\big)\\,=\\,0.}\\end{array}$ That is, for all function $f$ wehave ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{(1-\\gamma){\\mathbb E}_{d_{1}}v(s_{1})+{\\mathbb E}[w^{\\star}(s,a)(r(s,a)+\\gamma\\rho(s,a,s^{\\prime};v,\\beta,\\zeta^{\\star})-q(s,a))]}&\\\\ &{=(1-\\gamma){\\mathbb E}_{d_{1}}v(s_{1})+{\\mathbb E}_{s,a\\sim d^{\\star}}[r(s,a)+\\gamma\\rho(s,a,s^{\\prime};v,\\beta,\\zeta^{\\star})-q(s,a)]}&\\\\ &{={\\mathbb E}_{s,a\\sim d^{\\star}}[r(s,a)]+(1-\\gamma){\\mathbb E}_{d_{1}}v(s_{1})+{\\mathbb E}_{s,a\\sim d^{\\star}}\\left[\\gamma{\\mathbb E}_{s^{\\prime}\\sim P^{\\star}(s,a)}[v(s^{\\prime})]-q(s,a)\\right]}&\\\\ &{={\\mathbb E}_{s,a\\sim d^{\\star}}[r(s,a)]}&{\\mathrm{(robust~Bellm~}}\\\\ &{=(1-\\gamma){\\mathbb E}_{d_{1}}v^{\\star}(s_{1}).}&\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 24}, {"type": "text", "text": "H.4 Proof of Rates ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "The estimation error is given by: ", "page_idx": 24}, {"type": "equation", "text": "$$\n|\\widehat{V}_{d_{1}}-V_{d_{1}}^{*}|=\\left|\\frac{1}{K}\\sum_{k=1}^{K}\\mathbb{E}_{k}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-V_{d_{1}}^{*}\\right|\\le\\frac{1}{K}\\sum_{k=1}^{K}\\left|\\mathbb{E}_{k}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-V_{d_{1}}^{*}\\right|\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "We wish need to bound $\\left|\\mathbb{E}_{k}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-V_{d_{1}}^{*}\\right|$ . We have that: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{E}_{k}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-V_{d_{1}}^{*}\\Big|\\le\\Big|\\mathbb{E}_{k}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-\\mathbb{E}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]\\Big|+\\Big|\\mathbb{E}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-V_{d_{1}}^{*}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "The first term is $O_{p}(n^{-1/2})$ by the CLT. We are now interested in bounding the second term: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\varepsilon(\\widehat{\\eta}):=\\left|\\mathbb{E}[\\psi(s,a,s^{\\prime};\\widehat{\\eta})]-V_{d_{1}}^{*}\\right|.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where we dropped the $[k]$ indicator without loss of generality. We further decompose $\\varepsilon(\\widehat{\\eta})$ intotwo error terms, $\\varepsilon_{A}$ and $\\varepsilon_{B}$ ,as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon(\\widehat{\\eta})=\\Big\\lvert\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},\\widehat{w},\\widehat{\\beta}\\big)\\Big]-\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},w^{\\star},\\widehat{\\beta},\\zeta^{\\star}\\big)\\Big]\\Big\\rvert}\\\\ &{\\qquad\\leq\\Big\\lvert\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},\\widehat{w},\\widehat{\\beta}\\big)\\Big]-\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},\\widehat{w},\\widehat{\\beta},\\zeta^{\\star}\\big)\\Big]\\Big\\rvert}\\\\ &{\\qquad+\\left\\lvert\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},\\widehat{w},\\widehat{\\beta},\\zeta^{\\star}\\big)\\Big]-\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},w^{\\star},\\widehat{\\beta},\\zeta^{\\star}\\big)\\Big]\\right\\rvert.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Bounding $\\varepsilon^{A}$ : Error from the incorrect indicator $\\zeta$ ", "text_level": 1, "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon_{A}=\\gamma\\lambda\\tau^{-1}\\mathbb{E}\\widehat{w}(s,a)\\Big(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\Big)\\Big(\\mathbb{I}\\left[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\right]-\\mathbb{I}\\left[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\right]\\Big)}\\\\ &{\\quad\\leq C\\gamma\\lambda\\tau^{-1}\\mathbb{E}\\Big(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\Big)\\Big(\\mathbb{I}\\left[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\right]-\\mathbb{I}\\left[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\right]\\Big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\mathrm{(Assumption~4)}}\\\\ &{\\quad\\lesssim\\mathbb{E}\\Big(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\Big)\\Big(\\mathbb{I}\\left[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\right]-\\mathbb{I}\\left[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\right]\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We break these terms down as follows: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Xi\\Big(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\Big)\\Big(\\mathbb{I}\\left[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\right]-\\mathbb{I}\\left[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\right]\\Big)}\\\\ &{=\\!\\mathbb{E}(v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a))\\Big(\\mathbb{I}\\left[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\right]-\\mathbb{I}\\left[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\right]\\Big)\\qquad\\qquad\\qquad\\qquad\\quad(\\varepsilon_{1}^{A})}\\\\ &{\\ \\ \\ +\\mathbb{E}\\Big(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)-v^{\\star}(s^{\\prime})+\\beta^{\\star}(s,a)\\Big)\\Big(\\mathbb{I}\\left[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\right]-\\mathbb{I}\\left[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\right]\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We first bound $\\varepsilon_{1}^{A}$ . Assumption 4.2 implies ", "page_idx": 25}, {"type": "equation", "text": "$$\nP(0<|v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)|\\leq t)\\leq c^{\\prime\\prime}t,\\;\\forall t\\in[0,c^{\\prime}),\\quad P(|v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)|=0)=0,\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $c^{\\prime}<1$ is the min of 1 and the given neighborhood of zero and $c^{\\prime\\prime}\\geq1$ is the max of 1 and the bound on the density in that neighborhood. This implies a margin condition with $\\alpha\\,=\\,1$ and $c=c^{\\prime\\prime}/c^{\\prime}$ ", "page_idx": 25}, {"type": "text", "text": "We can instantiate the first part of Lemma H.3 with $f(X)=v^{\\star}(s^{\\prime})\\!-\\!\\beta^{\\star}(s,a),g(X)=\\widehat{v}(s^{\\prime})\\!-\\!\\widehat{\\beta}(s,a)$ and obtain ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon_{1}^{A}\\lesssim\\left\\|v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)-\\widehat v(s^{\\prime})+\\widehat\\beta(s,a)\\right\\|_{p}^{\\frac{2p}{p+1}}}\\\\ &{\\quad\\leq\\|\\widehat v(s^{\\prime})-v^{\\star}(s^{\\prime})\\|_{p}^{\\frac{2p}{p+1}}+\\left\\|\\widehat\\beta(s,a)-\\beta^{\\star}(s,a)\\right\\|_{p}^{\\frac{2p}{p+1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "To bound $\\varepsilon_{2}^{A}$ , frst write ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{\\left|\\mathbb{E}\\Big(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)-v^{\\star}(s^{\\prime})+\\beta^{\\star}(s,a)\\Big)\\Big(\\mathbb{I}\\Big[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\Big]-\\mathbb{I}\\big[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\big]\\Big)\\right|}\\\\ &{\\leq\\Big\\|\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)-v^{\\star}(s^{\\prime})+\\beta^{\\star}(s,a)\\Big\\|_{p}}\\\\ &{\\quad}&{\\cdot\\mathbb{P}\\Big(\\mathbb{I}\\Big[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\Big]\\neq\\mathbb{I}\\big[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\big]\\Big)^{(p-1)/p}\\qquad\\qquad(\\mathrm{Holder}^{\\star}\\mathrm{sinequality})}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "We can bound $\\begin{array}{r}{\\mathbb{P}\\Big(\\mathbb{I}\\left[\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)\\leq0\\right]\\neq\\mathbb{I}\\left[v^{\\star}(s^{\\prime})-\\beta^{\\star}(s,a)\\leq0\\right]\\Big)}\\end{array}$ using the second part of Lemma H.3 such that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon_{2}^{A}\\lesssim\\Big\\|\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)-v^{\\star}(s^{\\prime})+\\beta^{\\star}(s,a)\\Big\\|_{p}\\Big\\|\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)-v^{\\star}(s^{\\prime})+\\beta^{\\star}(s,a)\\Big\\|^{\\frac{p-1}{p+1}}}\\\\ &{\\quad=\\Big\\|\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)-v^{\\star}(s^{\\prime})+\\beta^{\\star}(s,a)\\Big\\|_{p}^{\\frac{2p}{p+1}}}\\\\ &{\\quad\\leq\\|\\widehat{v}(s^{\\prime})-v^{\\star}(s^{\\prime})\\|_{p}^{\\frac{2p}{p+1}}+\\Big\\|\\widehat{\\beta}(s,a)-\\beta^{\\star}(s,a)\\Big\\|_{p}^{\\frac{2p}{p+1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Putting the $\\varepsilon_{1}^{A}$ and $\\varepsilon_{2}^{A}$ together, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon_{A}\\lesssim\\|\\widehat{v}(s^{\\prime})-v^{\\star}(s^{\\prime})\\|_{p}^{\\frac{2p}{p+1}}+\\Big\\|\\widehat{\\beta}(s,a)-\\beta^{\\star}(s,a)\\Big\\|_{p}^{\\frac{2p}{p+1}}}\\\\ &{\\quad\\lesssim\\|\\widehat{v}(s^{\\prime})-v^{\\star}(s^{\\prime})\\|_{\\infty}^{2}+\\Big\\|\\widehat{\\beta}(s,a)-\\beta^{\\star}(s,a)\\Big\\|_{\\infty}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Bounding $\\varepsilon^{B}$ : Error with correct indicator but wrong nuisances. Now we focus on bounding $\\varepsilon^{B}$ ", "text_level": 1, "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon_{B}=\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},\\widehat{w},\\widehat{\\beta},\\zeta^{\\star}\\big)\\Big]-\\mathbb{E}\\Big[\\psi\\big(s,a,s^{\\prime};\\widehat{q},w^{\\star},\\widehat{\\beta},\\zeta^{\\star}\\big)\\Big]}\\\\ &{=\\mathbb{E}\\big(\\widehat{w}(s,a)-w^{\\star}(s,a)\\big)\\Big(r(s,a)+\\gamma\\rho(s,a,s^{\\prime};\\widehat{v},\\widehat{\\beta},\\zeta^{\\star})-\\widehat{q}(s,a)\\Big)}\\\\ &{=\\mathbb{E}\\big(\\widehat{w}(s,a)-w^{\\star}(s,a)\\big)\\Big(r(s,a)+\\gamma\\rho(s,a,s^{\\prime};\\widehat{v},\\widehat{\\beta},\\zeta^{\\star})-\\widehat{q}(s,a)\\Big)}\\\\ &{-\\mathbb{E}\\big(\\widehat{w}(s,a)-w^{\\star}(s,a)\\big)(r(s,a)+\\gamma\\rho(s,a,s^{\\prime};v^{\\star},\\beta^{\\star})-q^{\\star}(s,a))}\\\\ &{=\\mathbb{E}\\big(\\widehat{w}(s,a)-w^{\\star}(s,a)\\big)\\Big(\\widehat{q}(s,a)-q^{\\star}(s,a)+\\gamma\\big(\\rho(s,a,s^{\\prime};\\widehat{v},\\widehat{\\beta},\\zeta^{\\star})-\\rho(s,a,s^{\\prime};v^{\\star},\\beta^{\\star})\\big)\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "In the Lemma H.4 step, we used ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathfrak{z}=(1-\\gamma)\\mathbb{E}_{d_{1}}v^{\\star}(s_{1})-\\mathbb{E}[\\psi(s,a,s^{\\prime};q^{\\star},\\widehat{w},\\beta^{\\star})]=(1-\\gamma)\\mathbb{E}_{d_{1}}v^{\\star}(s_{1})-\\mathbb{E}[\\psi(s,a,s^{\\prime};q^{\\star},w^{\\star},\\beta^{\\star})].}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Finally, note that ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\rho(s,a,s^{\\prime};\\widehat{v},\\widehat{\\beta},\\zeta^{\\star})-\\rho(s,a,s^{\\prime};v^{\\star},\\beta^{\\star})}\\\\ &{\\ =(1-\\lambda)(\\widehat{v}(s^{\\prime})-v^{\\star}(s^{\\prime}))+\\lambda\\tau^{-1}(\\widehat{v}(s^{\\prime})-v^{\\star}(s^{\\prime}))\\mathbb{I}\\left[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0\\right]}\\\\ &{\\ \\ \\ +\\lambda(\\widehat{\\beta}(s,a)-\\beta^{\\star}(s,a))\\big(1-\\tau^{-1}\\mathbb{I}\\left[\\zeta^{\\star}(s,a,s^{\\prime})\\leq0\\right]\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Due to continuity of the CDF of $v^{\\star}(s^{\\prime})$ at $\\beta^{\\star}(s,a)$ for all $s,a$ wehave $\\operatorname*{Pr}(\\zeta^{\\star}(s^{\\prime},s,a)\\leq0\\mid s,a)=\\tau$ and so the last term vanishes. Thus, we're left with a quantity that is at most $\\lesssim(\\widehat{v}(s^{\\prime})-v^{\\star}(s^{\\prime}))$ Therefore, ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\varepsilon_{B}\\lesssim\\mathbb{E}(\\widehat{w}(s,a)-w^{\\star}(s,a))(\\mathcal{I}_{U^{\\pm}}(\\widehat{q}(s,a)-q^{\\star}(s,a)))}\\\\ &{\\quad\\leq\\|\\mathcal{I}_{U^{\\pm}}^{\\prime}(\\widehat{w}-w^{\\star})\\|_{2}\\|\\widehat{q}-q^{\\star}\\|_{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "(Holder's inequality) ", "page_idx": 26}, {"type": "text", "text": "Putting everything together, we obtain the desired rates: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{|\\widehat{V}_{d_{1}}-V_{d_{1}}^{*}|\\lesssim O_{p}(n^{-1/2})+\\|\\mathcal{I}_{U^{\\pm}}^{\\prime}(\\widehat{w}-w^{\\star})\\|_{2}\\|\\widehat{q}-q^{\\star}\\|_{2}+\\|\\widehat{v}-v^{\\star}\\|_{p^{+1}}^{\\frac{2p}{p+1}}+\\left\\|\\widehat{\\beta}-\\beta^{\\star}\\right\\|_{p}^{\\frac{2p}{p+1}}}\\\\ &{\\qquad\\qquad=O_{p}(n^{-1/2})+O_{p}\\Big(r_{n}^{w}r_{n}^{q}+(r_{n,p}^{q})^{\\frac{2p}{p+1}}+(r_{n,p}^{\\beta})^{\\frac{2p}{p+1}}\\Big)\\qquad\\qquad(\\mathrm{when}\\,p\\in[1,\\infty))}\\\\ &{\\qquad\\qquad\\lesssim O_{p}(n^{-1/2})+\\|\\mathcal{I}_{U^{\\pm}}^{\\prime}(\\widehat{w}-w^{\\star})\\|_{2}\\|\\widehat{q}-q^{\\star}\\|_{2}+\\|\\widehat{v}-v^{\\star}\\|_{\\infty}^{2}+\\left\\|\\widehat{\\beta}-\\beta^{\\star}\\right\\|_{\\infty}^{2}}\\\\ &{\\qquad\\qquad=O_{p}(n^{-1/2})+O_{p}\\big(r_{n}^{w}r_{n}^{q}+(r_{n,\\infty}^{q})^{2}+(r_{n,\\infty}^{\\beta})^{2}\\big).\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "H.5Proof of Normality & Efficiency ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "In this part of the theorem, we let: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\widetilde{V}_{d_{1}}=\\frac{1}{K}\\sum_{k=1}^{K}\\mathbb{E}_{k}[\\psi(s,a,s^{\\prime};\\eta^{*})]\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then, we can write the following equality: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\sqrt{n}(\\widehat{V}_{d_{1}}-V_{d_{1}}^{*})=\\sqrt{n}(\\widehat{V}_{d_{1}}-\\widetilde{V}_{d_{1}})+\\underbrace{\\sqrt{n}(\\widetilde{V}_{d_{1}}-V_{d_{1}}^{*})}_{\\stackrel{d}{\\to}\\mathcal{N}(0,\\Sigma)}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "The second term converges in distribution to $\\mathcal{N}(0,\\Sigma)$ from the CLT and the fact that $\\psi$ is the efficient influence function. Thus, it remains to show that the first term is $o_{p}(1)$ . We decompose the first term asfollows: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\sqrt{n}(\\widehat{V}_{d_{1}}-\\widetilde{V}_{d_{1}})=\\sqrt{n}\\frac{1}{K}\\sum_{k=1}^{n}\\Big(\\mathbb{E}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-\\mathbb{E}[\\psi(s,a,s^{\\prime};\\eta^{*})]\\Big)}}\\\\ &{}&{\\qquad+\\,\\sqrt{n}\\frac{1}{K}\\sum_{k=1}^{n}\\!\\underbrace{(\\mathbb{E}_{k}-\\mathbb{E})[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})-\\psi(s,a,s^{\\prime};\\eta^{*})]}_{\\varepsilon_{k}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "In Eq. (15), we have that $|\\mathbb{E}[\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})]-\\mathbb{E}[\\psi(s,a,s^{\\prime};\\eta^{*})]|$ is bounded as in Eq. (Rates). Given the theorem's assumption about the nuisance rates, this term is $\\bar{o}_{p}(n^{-1/2})$ and Eq. (15) is $o_{p}(1)$ .We now seek to control the $\\varepsilon_{k}$ term in Eq. (16). Letting $\\mathcal{D}_{k}$ represent the samples in the $k^{\\mathrm{th}}$ fold, we leverage sample splitting to show that the mean of $\\varepsilon_{k}\\mid\\mathcal{D}_{k}$ is $0$ ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\varepsilon_{k}\\ |\\ \\mathcal{D}_{k}]=\\mathbb{E}[\\mathbb{E}_{k}[\\psi(s,a,s^{\\prime};\\hat{\\eta}^{[k]})-\\psi(s,a,s^{\\prime};\\eta^{*})]-\\mathbb{E}[\\psi(s,a,s^{\\prime};\\hat{\\eta}^{[k]})-\\psi(s,a,s^{\\prime};\\eta^{*})]\\ |\\ \\mathcal{D}_{k}]}\\\\ &{\\quad\\quad\\quad\\quad=0}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where we consider $\\widehat{\\eta}^{\\left[k\\right]}$ fixed with respect to the second expectation. The result follows from the fact that $\\widehat{\\eta}^{\\left[k\\right]}$ does not depend on $\\mathcal{D}_{k}$ . Then, we can invoke Chebyshev's inequality to obtain the following bound: ", "page_idx": 27}, {"type": "equation", "text": "$$\nP\\left(\\frac{\\varepsilon_{k}}{\\operatorname{Var}[\\varepsilon_{k}\\mid D_{k}]^{1/2}}\\geq\\epsilon\\bigg|\\mathcal{D}_{k}\\right)\\leq\\frac{1}{\\epsilon^{2}},\\,\\forall\\epsilon>0\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Thus, we have shown that $\\varepsilon_{k}\\ |\\ {\\mathcal D}_{k}\\;=\\;O_{p}(\\mathrm{Var}[\\varepsilon_{k}\\ |\\ \\mathcal D_{k}]^{1/2})\\;=\\;O_{p}(n^{-1/2}{\\mathbb E}[(\\psi(s,a,s^{\\prime};\\widehat\\eta^{[k]})\\ -$ $\\psi(s,a,s^{\\prime};\\eta^{*}))^{2}\\mid\\mathcal{D}_{k}]^{1/2})$ . Here, we used the fact that $n_{K}=n/K$ (the size of $\\mathcal{D}_{k}$ ) and that $K$ is a fixed integer that doesn't grow with $n$ . Moreover, $\\varepsilon_{k}$ has O conditional mean. ", "page_idx": 27}, {"type": "text", "text": "For the remainder of the analysis, we leave the conditioning on $\\mathcal{D}_{k}$ implicit for simplicity. To bound $\\mathbb{E}[(\\psi(s,a,s^{\\prime};\\hat{\\eta}^{[k]})-\\psi(s,a,s^{\\prime};\\eta^{*}))^{2}\\mid\\mathcal{D}_{k}]^{1/2}=\\|\\psi(s,a,\\Bar{s^{\\prime}};\\hat{\\eta}^{[k]})-\\psi(s,a,s^{\\prime};\\eta^{*})\\|_{2}^{1}$ , we use similar notation and techniques as in Appendix H.4: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\psi(s,a,s^{\\prime};\\widehat\\eta^{[k]})-\\psi(s,a,s^{\\prime};\\eta^{*})\\|_{2}\\le\\|\\psi(s,a,s^{\\prime};\\widehat\\ q,\\widehat w,\\widehat\\beta)-\\psi(s,a,s^{\\prime};\\widehat q,\\widehat w,\\widehat\\beta,\\zeta^{*})\\|_{2}\\qquad\\qquad(\\sigma_{1})}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\;\\|\\psi(s,a,s^{\\prime};\\widehat q,\\widehat w,\\widehat\\beta,\\zeta^{*})-\\psi(s,a,s^{\\prime};q^{*},w^{*},\\beta^{*},\\zeta^{*})\\|_{2}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\sigma_{\\infty})}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "where we invoked Cauchy-Schwarz for the $L_{2}$ norm. We bound $\\sigma_{2}$ as follows: ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{2}\\leq\\|\\psi(s,a,s^{\\prime};\\widehat{q},\\widehat{w},\\widehat{\\beta})-\\psi(s,a,s^{\\prime};q^{*},\\widehat{w},\\widehat{\\beta},\\zeta^{*})\\|_{2}}\\\\ &{\\qquad+\\|\\psi(s,a,s^{\\prime};q^{*},\\widehat{w},\\widehat{\\beta},\\zeta^{*})-\\psi(s,a,s^{\\prime};q^{*},\\widehat{w},\\beta^{*},\\zeta^{*})\\|_{2}}\\\\ &{\\qquad+\\|\\psi(s,a,s^{\\prime};q^{*},\\widehat{w},\\beta^{*},\\zeta^{*})-\\psi(s,a,s^{\\prime};q^{*},w^{*},\\beta^{*},\\zeta^{*})\\|_{2}}\\\\ &{\\qquad\\leq\\|\\widehat{v}-v^{*}\\|_{2}+\\gamma(1-\\lambda)\\|\\widehat{w}\\|_{2}\\|\\widehat{v}-v^{*}\\|_{2}+\\gamma\\lambda\\tau^{-1}\\|\\widehat{w}\\|_{2}\\|\\widehat{v}-v^{*}\\|_{2}+\\|\\widehat{w}\\|_{2}\\|\\widehat{q}-q^{*}\\|_{2}}\\\\ &{\\qquad+\\gamma\\lambda\\|\\widehat{w}\\|_{2}\\|\\widehat{\\beta}-\\beta^{*}\\|_{2}+\\gamma\\lambda\\tau^{-1}\\|\\widehat{w}\\|_{2}\\|\\widehat{\\beta}-\\beta^{*}\\|_{2}}&{(\\sigma_{2})}\\\\ &{\\qquad+\\|\\widehat{w}-w^{*}\\|_{2}\\left(\\|r\\|_{2}+\\gamma(1-\\lambda)\\|v^{*}\\|_{2}+\\gamma\\lambda\\|\\beta^{*}\\|_{2}+\\gamma\\lambda\\tau^{-1}\\|v^{*}-\\beta^{*}\\|_{2}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Given our rate assumptions, our boundedness assumptions for $\\widehat{w}$ , the implicit boundedness of $q^{*},v^{*},w^{*},\\beta^{*}$ , as well as the ordering of the $L_{2}$ and $L_{\\infty}$ norms, $\\sigma_{2}$ is $o_{p}(1)$ . We now bound the $\\sigma_{1}$ term: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\sigma_{2}=\\gamma\\lambda\\tau^{-1}\\left\\|\\widehat{w}(s,a)(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a))(\\mathbb{I}[\\widehat{v}(s^{\\prime})\\leq\\widehat{\\beta}(s,a)]-\\mathbb{I}[v^{*}(s^{\\prime})\\leq\\beta^{*}(s,a)])\\right\\|_{2}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "There are two cases in which the difference of indicators is non-zero: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{v^{*}(s^{\\prime})>\\beta^{*}(s,a)\\Rightarrow\\mathbb{I}[\\widehat{v}(s^{\\prime})\\leq\\widehat{\\beta}(s,a)]-\\mathbb{I}[v^{*}(s^{\\prime})\\leq\\beta^{*}(s,a)]=1}\\\\ &{v^{*}(s^{\\prime})\\leq\\beta^{*}(s,a)\\Rightarrow\\mathbb{I}[\\widehat{v}(s^{\\prime})\\leq\\widehat{\\beta}(s,a)]-\\mathbb{I}[v^{*}(s^{\\prime})\\leq\\beta^{*}(s,a)]=-1}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "In the first case, ${\\widehat{v}}(s^{\\prime})-{\\widehat{\\beta}}(s,a)\\leq0,\\beta^{*}(s,a)-v^{*}(s^{\\prime})<0$ and thus ", "page_idx": 28}, {"type": "equation", "text": "$$\n(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a))(\\mathbb{I}[\\widehat{v}(s^{\\prime})\\leq\\widehat{\\beta}(s,a)]-\\mathbb{I}[v^{*}(s^{\\prime})\\leq\\beta^{*}(s,a)])|\\leq|\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)+\\beta^{*}(s,a)-v^{*}(s^{\\prime})|.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "In the second case, $\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)>0,\\beta^{*}(s,a)-v^{*}(s^{\\prime})\\leq0$ and ", "page_idx": 28}, {"type": "equation", "text": "$$\n(\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a))(\\mathbb{I}[\\widehat{v}(s^{\\prime})\\leq\\widehat{\\beta}(s,a)]-\\mathbb{I}[v^{*}(s^{\\prime})\\leq\\beta^{*}(s,a)])|\\leq|\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)+\\beta^{*}(s,a)-v^{*}(s^{\\prime})|.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Going back to $\\sigma_{1}$ , we have: ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sigma_{2}\\leq\\gamma\\lambda\\tau^{-1}\\|\\widehat{w}\\|_{2}\\|\\widehat{v}(s^{\\prime})-\\widehat{\\beta}(s,a)+\\beta^{*}(s,a)-v^{*}(s^{\\prime}))\\|_{2}}\\\\ &{\\quad\\leq\\gamma\\lambda\\tau^{-1}\\|\\widehat{w}\\|_{2}(\\|\\widehat{v}-v^{*}\\|_{2}+\\|\\widehat{\\beta}-\\beta^{*}\\|_{2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "By out theorem's assumptions, this term is also $o_{p}(1)$ . Putting $\\sigma_{1}$ and $\\sigma_{2}$ together, we have that $\\|\\psi(s,a,s^{\\prime};\\widehat{\\eta}^{[k]})-\\psi(s,a,s^{\\prime};\\eta^{*})\\|_{2}$ .is $o_{p}(1)$ and $\\varepsilon_{k}\\mid\\mathcal{D}_{k}$ .s $o_{p}(n^{-1/2})$ . By the bounded convergence theorem,this implies that $\\varepsilon_{k}$ is also $o_{p}(n^{-1/2})$ . Then, the term in 16 is $o_{p}(1)$ , which further means that $\\sqrt{n}(\\widehat{V}_{d_{1}}-\\widetilde{V}_{d_{1}})=o_{p}(1)$ . Our proof is now complete. ", "page_idx": 28}, {"type": "text", "text": "1 Derivation of the Efficient Influence Function ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Weusethe $\\varepsilon$ -contamination approach of [31] to derive an influence function (IF) for our estimand $V_{d_{1}}^{-}$ .The proof for $V_{d_{1}}^{+}$ follows symmetrically. We note that since our tangent space is the whole space as it factorizes in the trivial way (as in [39, Page 54]), the IF we derive is actually the efficient influence function (EIF). ", "page_idx": 28}, {"type": "text", "text": "Let $P(s,a,s^{\\prime})$ denote the data distribution.  Consider the $\\varepsilon$ -contamination $P_{\\varepsilon}(s,a,s^{\\prime})\\;=\\;(1\\;-\\;$ $\\varepsilon)P(s,a,s^{\\prime})+\\varepsilon\\delta(\\bar{s},\\bar{a},\\bar{s}^{\\prime})$ , where $\\delta(\\bar{z})$ is the dirac delta at $\\bar{z}$ i.e., $\\delta(\\bar{z})$ has infinite mass at $\\bar{z}$ and 0 mass elsewhere. Let $V_{\\varepsilon}^{-}$ denote the robust value function under the transition kernel $P_{\\varepsilon}(s^{\\prime}\\mid s,a)$ Omitting the $\\varepsilon$ subscript means $\\varepsilon=0$ . The $\\mathrm{IF}$ of $V_{d_{1}}^{-}$ is then given by ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}(1-\\gamma)\\mathbb{E}_{d_{1}}V_{\\varepsilon}^{-}(s_{1})|_{\\varepsilon=0}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "We dedicate the rest of this section towards this goal, which will be obtained in Theorem I.5. ", "page_idx": 28}, {"type": "text", "text": "Lemma I.1. ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}P_{\\varepsilon}(s^{\\prime}\\mid s,a)|_{\\varepsilon=0}=\\frac{\\delta(\\bar{s},\\bar{a})}{P(s,a)}(\\delta(\\bar{s}^{\\prime})-P(s^{\\prime}\\mid s,a)).\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Proof. Use the fact $\\begin{array}{r}{P_{\\varepsilon}(s^{\\prime}\\mid s,a)=\\frac{P_{\\varepsilon}(s,a,s^{\\prime})}{P_{\\varepsilon}(s,a)}=\\frac{(1-\\varepsilon)P(s,a,s^{\\prime})+\\varepsilon\\delta(\\bar{s},\\bar{a},\\bar{s}^{\\prime})}{(1-\\varepsilon)P(s,a)+\\varepsilon\\delta(\\bar{s},\\bar{a})}}\\end{array}$ and take derivative. ", "page_idx": 28}, {"type": "text", "text": "Lemma I.2 (IF of conditional expectation). For any $s,a$ and $f_{\\varepsilon}$ ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}\\mathbb{E}_{P_{\\varepsilon}}[f_{\\varepsilon}(s^{\\prime})\\mid s,a]|_{\\varepsilon=0}=\\frac{\\delta(\\bar{s},\\bar{a})}{P(s,a)}(f(\\bar{s}^{\\prime})-\\mathbb{E}_{P}[f(s^{\\prime})\\mid s,a])+\\mathbb{E}_{P}\\left[\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}f_{\\varepsilon}(s^{\\prime})|_{\\varepsilon=0}\\mid s,a\\right],\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where $f=f_{0}$ ", "page_idx": 28}, {"type": "text", "text": "Proof. ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}\\mathbb{E}_{P_{\\varepsilon}}[f_{\\varepsilon}(s^{\\prime})\\mid s,a]|_{\\varepsilon=0}=\\sum_{s^{\\prime}}f(s^{\\prime})\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}P_{\\varepsilon}(s^{\\prime}\\mid s,a)|_{\\varepsilon=0}+\\sum_{s^{\\prime}}\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}f_{\\varepsilon}(s^{\\prime})|_{\\varepsilon=0}P(s^{\\prime}\\mid s,a)}\\\\ {=\\frac{\\delta(\\bar{s},\\bar{a})}{P(s,a)}(f_{0}(\\bar{s}^{\\prime})-\\mathbb{E}_{P}[f_{0}(s^{\\prime})\\mid s,a])+\\mathbb{E}_{P}\\left[\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}f_{\\varepsilon}(s^{\\prime})|_{\\varepsilon=0}\\mid s,a\\right],}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Lemma I.3 (IF of conditional CVaR). For any $\\tau,s,a$ and $f_{\\varepsilon}$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}\\,\\mathrm{CVaR}_{\\tau,P_{\\varepsilon}}[f_{\\varepsilon}(s^{\\prime})\\mid s,a]|_{\\varepsilon=0}=\\frac{\\delta(\\bar{s},\\bar{a})}{P(s,a)}\\big(\\beta_{\\tau}(s,a)+\\tau^{-1}(f(\\bar{s}^{\\prime})-\\beta_{\\tau}(s,a))_{-}-\\mathrm{CVaR}_{\\tau}(f(s^{\\prime})\\mid s,a)\\big)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+\\,\\mathbb{E}_{P}\\bigg[\\tau^{-1}\\mathbb{I}\\,[f(s^{\\prime})\\leq\\beta_{\\tau}(s,a)]\\,\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}f_{\\varepsilon}(s^{\\prime})|_{\\varepsilon=0}\\mid s,a\\bigg],}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where $f=f_{0}$ and $\\beta_{\\tau}(s,a)$ be the $(1-\\tau)$ -th quantile of $f(s^{\\prime}),s^{\\prime}\\sim P(s,a)$ ", "page_idx": 29}, {"type": "text", "text": "Proof. ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}\\,\\mathrm{CVaR}_{P_{\\varepsilon}}[f_{\\varepsilon}(s^{\\prime})\\mid s,a]|_{\\varepsilon=0}}\\\\ {\\displaystyle=\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}\\operatorname*{min}_{b}\\mathbb{E}_{P_{\\varepsilon}}\\big[b+\\tau^{-1}(f_{\\varepsilon}(s^{\\prime})-b)_{-}\\mid s,a\\big]|_{\\varepsilon=0}}\\\\ {\\displaystyle=\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}\\mathbb{E}_{P_{\\varepsilon}}\\big[\\beta_{\\tau}(s,a)+\\tau^{-1}(f_{\\varepsilon}(s^{\\prime})-\\beta_{\\tau}(s,a))_{-}\\mid s,a\\big]|_{\\varepsilon=0},}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the last equality is due to Danskin's theorem and the fact that $\\beta_{\\tau}(s,a)$ is the maximizer of the CVaR dual form at $\\varepsilon=0$ . Continuing, let $g_{\\varepsilon}(s^{\\prime};s,a):=\\beta_{\\tau}(s,a)+\\tau^{-1}(f_{\\varepsilon}(s^{\\prime})-\\beta_{\\tau}(s,a))_{-}$ ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{l}\\varepsilon}\\mathbb{E}_{P_{\\varepsilon}}\\big[g_{\\varepsilon}\\big(s^{\\prime};s,a\\big)\\bigm|s,a\\big]}\\\\ &{=\\displaystyle\\frac{\\delta\\big(\\bar{s},\\bar{a}\\big)}{P\\big(s,a\\big)}\\big(g\\big(\\bar{s}^{\\prime};s,a\\big)-\\mathbb{E}_{P}\\big[g\\big(s^{\\prime},s,a\\big)\\bigm|s,a\\big]\\big)+\\mathbb{E}_{P}\\bigg[\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}g_{\\varepsilon}\\big(s^{\\prime};s,a\\big)\\big|_{\\varepsilon=0}\\bigm|s,a\\bigg]\\qquad\\mathrm{(Lemma~I.2)}}\\\\ &{=\\displaystyle\\frac{\\delta\\big(\\bar{s},\\bar{a}\\big)}{P\\big(s,a\\big)}\\big(g\\big(\\bar{s}^{\\prime};s,a\\big)-\\mathrm{CVaR}_{\\tau}\\big(f\\big(s^{\\prime}\\big)\\bigm|s,a\\big)\\big)+\\mathbb{E}_{P}\\bigg[\\tau^{-1}\\mathbb{I}\\big[f\\big(s^{\\prime}\\big)\\leq\\beta_{\\tau}\\big(s,a\\big)\\big]\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}f_{\\varepsilon}\\big(s^{\\prime}\\big)\\big|_{\\varepsilon=0}\\bigm|s,a\\bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 29}, {"type": "text", "text": "We now prove the key \u201cone-step forward\" lemma. ", "page_idx": 29}, {"type": "text", "text": "Lemma I.4 (One-Step Forward). For any state distribution $\\nu(s)$ wehave ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{s\\sim\\nu}\\bigg[\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s)|_{\\varepsilon=0}\\bigg]}\\\\ &{=\\frac{\\nu(\\bar{s})\\pi(\\bar{a}\\mid\\bar{s})}{P(\\bar{s},\\bar{a})}\\big(r(\\bar{s},\\bar{a})+\\gamma\\big((1-\\lambda)V^{-}(\\bar{s}^{\\prime})+\\lambda\\big(\\beta_{\\tau}(\\bar{s},\\bar{a})+\\tau^{-1}(V^{-}(\\bar{s}^{\\prime})-\\beta_{\\tau}(\\bar{s},\\bar{a})\\big)_{-}\\big)\\big)}\\\\ &{\\phantom{=\\quad}\\quad-Q^{-}(\\bar{s},\\bar{a})\\big)}\\\\ &{\\phantom{=\\quad}+\\gamma\\mathbb{E}_{s\\sim\\nu}\\bigg[\\mathbb{E}_{\\pi,P}\\bigg[\\big((1-\\lambda)+\\lambda\\tau^{-1}\\mathbb{I}\\left[V^{-}(s^{\\prime})\\leq\\beta_{\\tau}(s,a)\\right]\\big)\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s^{\\prime})|_{\\varepsilon=0}\\mid s\\bigg]\\bigg].}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Proof. For any $s_{1}$ , we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{\\mathrm{d}}{\\mathrm{d}t}V_{\\varepsilon}^{-}(s_{1})}\\\\ &{=\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbb{E}_{0\\sim\\pi^{\\varepsilon}\\left(s_{1}\\right)}\\Big[r(s_{1},a_{1})+\\gamma((1-\\lambda)\\mathbb{E}_{P_{\\varepsilon}}\\big[V_{\\varepsilon}^{-}(s_{2})\\big|\\mathbf{\\Phi}_{1},a_{1}\\big]+\\lambda\\mathrm{CVaR}_{T,P_{\\varepsilon}}\\big[V_{\\varepsilon}^{-}(s_{2})\\big|\\mathbf{\\Phi}_{1},a_{1}\\big]\\Big]_{\\varepsilon=0}}\\\\ &{=\\gamma\\mathbb{E}_{0\\sim\\pi^{\\varepsilon}\\left(s_{1}\\right)}\\Big[(1-\\lambda)\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathbb{E}_{0\\sim P_{\\varepsilon}}\\big[V_{\\varepsilon}^{-}(s_{2})\\big|\\mathbf{\\Phi}_{1},a_{1}\\big]\\Big]_{\\varepsilon=0}+\\frac{\\mathrm{d}}{\\mathrm{d}t}\\mathrm{CVaR}_{T,P_{\\varepsilon}}\\big[V_{\\varepsilon}^{-}(s_{2})\\big|\\mathbf{\\Phi}_{1},a_{1}\\big]\\Big]_{\\varepsilon=0}\\Big]}\\\\ &{=\\gamma(1-\\lambda)\\mathbb{E}_{a_{1}\\sim\\pi^{\\varepsilon}\\left(s_{1}\\right)}\\Big[\\frac{\\delta}{P\\big(s_{1},a_{1}\\big)}\\Big(V^{-}(s^{\\prime})-\\mathbb{E}_{P}\\big[V^{-}(s_{2})\\big|\\mathbf{\\Phi}_{1},a_{1}\\big]\\Big)\\Big]}\\\\ &{+\\gamma(1-\\lambda)\\mathbb{E}_{0\\sim\\pi^{\\varepsilon}\\left(s_{1}\\right)}\\mathbb{E}_{P}\\Big[\\frac{\\mathrm{d}}{\\mathrm{d}t}V_{\\varepsilon}^{-}(s_{2})\\big|c_{1}\\circ\\mathbf{\\Phi}_{1}\\Big]}\\\\ &{+\\gamma\\lambda\\mathbb{E}_{0\\sim\\pi^{\\varepsilon}\\left(s_{1}\\right)}\\Big[\\frac{\\delta}{P\\big(s,a_{1}\\big)}\\Big(\\beta_{r}(s_{1},a_{1})+\\tau^{-1}\\big(V^{-}(\\delta^{\\prime})-\\beta_{r}(s_{1},a_{1})\\big)-\\mathrm{CVaR}_{r}(V^{-}(s_{2}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Taking expectation over $s_{1}\\sim\\nu$ , we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\Xi_{s\\sim\\nu}\\bigg[\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s)|_{\\varepsilon=0}\\bigg]=\\gamma\\displaystyle\\frac{\\nu(\\bar{s})\\pi(\\bar{a}\\mid\\bar{s})}{P(\\bar{s},\\bar{a})}\\bigg((1-\\lambda)V^{-}(\\bar{s}^{\\prime})+\\lambda\\big(\\beta_{\\tau}(\\bar{s},\\bar{a})+\\tau^{-1}(V^{-}(\\bar{s}^{\\prime})-\\beta_{\\tau}(\\bar{s},\\bar{a}))_{-}\\big)}}\\\\ {{\\phantom{=}\\displaystyle-\\left((1-\\lambda)\\mathbb{E}\\big[V^{-}(s^{\\prime})\\mid\\bar{s},\\bar{a}\\big]+\\lambda\\,\\mathrm{CVaR}_{\\tau}(V^{-}(s^{\\prime})\\mid\\bar{s},\\bar{a})\\right)\\bigg)}}\\\\ {{\\phantom{=}\\displaystyle+\\left.\\gamma\\mathbb{E}_{s\\sim\\nu}\\bigg[\\mathbb{E}_{\\pi,P}\\bigg[\\big((1-\\lambda)+\\lambda\\tau^{-1}\\mathbb{I}\\left[V^{-}(s^{\\prime})\\leq\\beta_{\\tau}(s,a)\\right]\\big)\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s^{\\prime})|_{\\varepsilon=0}\\mid s\\bigg]\\right]}}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Finally recall that $V^{-}$ satisfies the Bellman equation, so ", "page_idx": 30}, {"type": "equation", "text": "$$\n(1-\\lambda)\\mathbb{E}\\big[V^{-}(s^{\\prime})\\mid\\bar{s},\\bar{a}\\big]+\\lambda\\,\\mathrm{CVaR}_{\\tau}(V^{-}(s^{\\prime})\\mid\\bar{s},\\bar{a})=Q^{-}(\\bar{s},\\bar{a})-r(\\bar{s},\\bar{a}).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 30}, {"type": "text", "text": "Equipped with our main one-step lemma, we can now unroll it an infinite number of steps to derive the IF of our estimand. ", "page_idx": 30}, {"type": "text", "text": "Theorem I.5 (IF of Estimand). Let us denote ", "page_idx": 30}, {"type": "equation", "text": "$$\ng(\\bar{s},\\bar{a},\\bar{s}^{\\prime}):=r(\\bar{s},\\bar{a})+\\gamma\\bigl((1-\\lambda)V^{-}(\\bar{s}^{\\prime})+\\lambda\\bigl(\\beta_{\\tau}(\\bar{s},\\bar{a})+\\tau^{-1}(V^{-}(\\bar{s}^{\\prime})-\\beta_{\\tau}(\\bar{s},\\bar{a}))_{-}\\bigr)\\bigr).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Then, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}_{d_{1}}\\bigg[\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s_{1})|_{\\varepsilon=0}\\bigg]=\\frac{d_{r o b}^{\\pi,\\infty}(\\bar{s},\\bar{a})}{P(\\bar{s},\\bar{a})}g(\\bar{s},\\bar{a},\\bar{s}^{\\prime}).\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Proof. Let $d_{h}$ denote the $h$ -th step visitation in the robust MDP, with transition $P_{\\mathrm{rob}}$ satisfying P) = (1 ->)+>I[V-(s)\u2264\u03b2B(s,a)] Then notice that the fnalterm of Lmma I4 is exactly $\\begin{array}{r}{\\mathbb{E}_{s\\sim\\nu}\\left[\\mathbb{E}_{\\pi,P_{\\mathrm{rob}}}\\left[\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s^{\\prime})|_{\\varepsilon=0}\\mid s\\right]\\right]}\\end{array}$ . Therefore, ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}_{d_{1}}\\left[\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s_{1})|_{\\varepsilon=0}\\right]}\\\\ &{\\,=\\frac{d_{1}(\\bar{s})\\pi(\\bar{a}\\mid\\bar{s})}{P(\\bar{s},\\bar{a})}g(\\bar{s},\\bar{a},\\bar{s}^{\\prime})+\\gamma\\mathbb{E}_{s_{2}\\sim d_{2}}\\left[\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s_{2})|_{\\varepsilon=0}\\right]}\\\\ &{\\,=\\frac{d_{1}(\\bar{s})\\pi(\\bar{a}\\mid\\bar{s})}{P(\\bar{s},\\bar{a})}g(\\bar{s},\\bar{a},\\bar{s}^{\\prime})+\\gamma\\frac{d_{2}(\\bar{s})\\pi(\\bar{a}\\mid\\bar{s})}{P(\\bar{s},\\bar{a})}g(\\bar{s},\\bar{a},\\bar{s}^{\\prime})+\\gamma^{2}\\mathbb{E}_{s_{3}\\sim d_{3}}\\left[\\displaystyle\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s_{3})|_{\\varepsilon=0}\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Iterating the process, we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{E}_{d_{1}}\\bigg[\\frac{\\mathrm{d}}{\\mathrm{d}\\varepsilon}V_{\\varepsilon}^{-}(s_{1})|_{\\varepsilon=0}\\bigg]=\\sum_{h=1}^{\\infty}\\gamma^{h-1}\\frac{d_{h}(\\bar{s})\\pi(\\bar{a}\\mid\\bar{s})}{P(\\bar{s},\\bar{a})}g(\\bar{s},\\bar{a},\\bar{s}^{\\prime})=\\frac{d_{\\mathrm{rob}}^{\\pi,\\infty}(\\bar{s},\\bar{a})}{P(\\bar{s},\\bar{a})}g(\\bar{s},\\bar{a},\\bar{s}^{\\prime}),\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "as desired. ", "page_idx": 30}, {"type": "text", "text": "Finally, we can conclude that the IF in Theorem I.5 is in fact the efficient IF (EIF) because it is in the tangent space, as the tangent space is contains all functions [39]. ", "page_idx": 31}, {"type": "text", "text": "J  Additional Validity Guarantees for Orthogonal Estimator ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Our orthogonal estimator has additional desirable properties such as validity when some nuisances are misspecified. Specifically, the bounds returned by our orthogonal estimator will be asymptotically valid, though possibly loose, when some nuisances are inconsistent, i.e., do not converge to the their true values. Below, we detail conditions under which we achieve validity. To be concise, we focus on the-case asthe $^+$ case issymmetric. ", "page_idx": 31}, {"type": "text", "text": "Validity with correct $Q^{\\pm}$ .If $\\widehat{Q}=Q^{\\pm}$ , we obtain valid bounds even if $w,\\beta$ are inconsistent. Lemma J.1. For any $w,\\beta$ we have $\\mathbb{E}[\\psi(s,a,s^{\\prime};Q^{-},\\beta,w)]\\le V_{d_{1}}^{-}$ with equality when $\\beta=\\beta_{\\tau}^{-}$ ", "page_idx": 31}, {"type": "text", "text": "Validity with $Q\\,=\\,T_{\\beta}^{\\pm}Q$ .Even if $\\widehat{Q}$ is misspecified, we still have a valid bound if it solves a Bellman-type equation of the dual CVaR form. For a $\\beta:S\\times A\\rightarrow\\mathbb{R}$ ,define: ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{T}_{\\beta}^{\\pm}f(s,a):=r(s,a)+\\gamma\\Lambda^{-1}(s,a)\\mathbb{E}[f(s^{\\prime},\\pi_{\\mathfrak{t}})\\mid s,a]}\\\\ &{\\quad\\quad\\quad\\quad\\quad+\\gamma(1-\\Lambda^{-1}(s,a))\\mathbb{E}\\big[\\beta(s,a)+\\tau^{-1}(s,a)(f(s^{\\prime},\\pi_{\\mathfrak{t}})-\\beta(s,a))_{\\pm}\\mid s,a\\big].}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Lemma J.2. Fix any $w,\\beta$ f $Q_{\\beta}^{\\pm}=T_{\\beta}^{\\pm}Q_{\\beta}^{\\pm}$ ,then $\\mathbb{E}[\\psi(s,a,s^{\\prime};Q_{\\beta}^{-},\\beta,w)]\\le V_{d_{1}}^{-}.$ ", "page_idx": 31}, {"type": "text", "text": "Remark J.3. Lemmas J.1 and J.2 are dual to each other: in Lemma J.1, the plug-in is consistent while the debiasing correction errs in the valid direction $(i.e.,\\ge0$ for $^+$ and $\\leq0$ for $-$ ). In Lemma J.2, the plug-in is valid while the debiasing correction has expectation zero. ", "page_idx": 31}, {"type": "text", "text": "J.1  Proofs for validity ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Lemma J.1. For any $w,\\beta$ we have $\\mathbb{E}[\\psi(s,a,s^{\\prime};Q^{-},\\beta,w)]\\le V_{d_{1}}^{-}$ with equality when $\\beta=\\beta_{\\tau}^{-}$ ", "page_idx": 31}, {"type": "text", "text": "Proof. ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}[\\psi(s,a,s^{\\prime};Q^{-},\\beta,w)]\\leq(1-\\gamma)\\mathbb{E}_{d_{1}}[V_{\\beta}^{-}(s_{1})]+\\mathbb{E}[w(s,a)\\big(Q^{-}(s,a)-T_{\\mathrm{CVaR}}^{-}Q^{-}(s,a)\\big)]}\\\\ &{\\qquad\\qquad\\qquad\\qquad=V_{d_{1}}^{-}+0=V_{d_{1}}^{-},}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "where th inequalty cmes frm thfact tt $\\beta$ is sub-optimal for $\\mathbb{E}[\\beta(s,a)+\\tau^{-1}(V^{-}(s^{\\prime})\\,-$$\\beta(s,a))_{-}]$ . The same proof applies for $Q^{+}$ \u53e3", "page_idx": 31}, {"type": "text", "text": "We now prove Lemma J.2. First, we show that the $\\mathcal{T}_{\\beta}$ perspective gives rise to a dual definition of $Q^{\\pm}$ (duai to Eq. (2). ", "page_idx": 31}, {"type": "text", "text": "Lemma J.4. ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r}{Q^{+}(s,a)=\\arg\\operatorname*{min}_{\\beta:Q_{\\beta}=T_{\\beta}^{+}Q_{\\beta}}Q_{\\beta}(s,a),\\quad Q^{-}(s,a)=\\arg\\operatorname*{max}_{\\beta:Q_{\\beta}=T_{\\beta}^{-}Q_{\\beta}}Q_{\\beta}(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Proof. Unroll $Q^{-}(s,a)\\,=\\,r(s,a)\\,+\\,\\gamma\\operatorname*{inf}_{U\\in\\mathcal{U}(P)}\\mathbb{E}_{U}[r(s^{\\prime},a^{\\prime})+\\gamma\\operatorname*{inf}_{U\\in\\mathcal{U}(P)}\\mathbb{E}_{U}[\\cdot\\,.\\,.\\,]]$ , replacing each $\\operatorname{inf}_{U\\in\\mathcal{U}(P)}$ with the convex combination of $\\mathbb{E}$ and CVaR from Lemma 3.1. Then, write each CVaR using the dual form, i.e., $\\operatorname*{max}_{\\beta}\\{\\beta(s,a)+\\tau^{-1}(s,a)\\mathbb{E}[(\\cdot\\cdot\\cdot-\\beta(s,a))_{+}]\\}$ .By $s,a\\cdot$ rectangularity, the scalar $\\operatorname*{max}_{\\beta}$ separates per $s,a$ , so we can pull all the maxes out front as a max over $\\bar{\\beta(s,a)}$ functions. Note that not all $\\beta(s,a)$ functions have a well-defined infinite sum in this manner, as $\\mathcal{T}_{\\beta}$ is not always a contraction. The condition $Q_{\\beta}=\\tau_{\\beta}^{-}Q_{\\beta}$ exactly characterizes when this unrolling is well-defined. Thus, $Q^{-}$ is exactly the minimum $Q_{\\beta}$ whenever this procedure of unrolling with $\\beta$ is well-defined. This concludes the proof. \u53e3 ", "page_idx": 31}, {"type": "text", "text": "Proof. ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{E}[\\psi(s,a,s^{\\prime};Q_{\\beta}^{-},\\beta,w)]=(1-\\gamma)\\mathbb{E}_{d_{1}}[V_{\\beta}^{-}(s_{1})]+0\\le V_{d_{1}}^{-}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "The first equality is because the correction term is $\\tau_{\\beta}^{-}Q_{\\beta}^{-}-Q_{\\beta}^{-}$ , which is zero since $Q_{\\beta}^{-}$ is a fixed point. The inequality is due to Lemma J.4. \u53e3 ", "page_idx": 32}, {"type": "text", "text": "K   Additional Details for Main Experiment ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "K.1 Environment ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We consider a simple MDP with a one-dimensional state space $\\mathcal{S}=[0,5]$ , a binary action space $A=\\{0,1\\}$ , reward function ", "page_idx": 32}, {"type": "equation", "text": "$$\nr(s,a)=\\frac{26-s^{2}-\\mathbb{I}\\,[a=1]}{26}\\,,\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "which we note takes values in the range $[0,1]$ , and with transitions given by ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{P(\\cdot\\mid s,a=0)=\\mathrm{UnifClip}[s-0.2,~s+1]}\\\\ &{P(\\cdot\\mid s,a=1)=\\mathrm{UnifClip}[0.2s-0.02,~s+0.5]\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where ${\\mathrm{UnifClip}}[a,b]$ denotes a uniform distribution between $\\operatorname*{max}(a,0)$ and $\\operatorname*{min}(b,5)$ . In addition, the environment always starts in initial state $s_{0}=2$ . Essentially, this is a simple control environment, where high rewards are obtained by maintaining state as close to zero as possible, the action $a=1$ is a control action that (in expectation) moves the state closer to zero, and which occurs a small reward cost, and the action $a=0$ is a passive action that allows the state to freely drift (with an overall drift away from zero). ", "page_idx": 32}, {"type": "text", "text": "K.2  Target Policy ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We focus on estimating the worst-case policy value $V_{d_{1}}^{-}$ for the simple threshold-based target policy $\\pi_{\\mathfrak{t}}$ which takes action $a=1$ when $s\\geq2$ , and $a=0$ whenever $s<2$ ", "page_idx": 32}, {"type": "text", "text": "K.3 Logging Policy and Data Sampling Procedure ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "We sample data using an evaluation policy $\\pi_{b}$ which is an $\\epsilon$ -smoothed threshold policy similar to $\\pi_{t}$ Specifically, $\\pi_{b}$ takes action $a=1$ when $s\\geq1.5$ with probability 0.95, and takes action $a=0$ when $s<1.5$ with probability 0.95. We obtain a dataset $\\bar{\\{s_{i},a_{i},s_{i}^{\\prime},r_{i}\\}}$ by first rolling out with $\\pi_{b}$ for 1000 burn-in time steps, and then sampling the tuple $(s,a,s^{\\prime},r)$ every 10 time steps. For each replication of our experiment, we sample 10,000 tuples in total. ", "page_idx": 32}, {"type": "text", "text": "K.4Calculation of True Worst-Case Policy Values ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "A major challenge in studying robust policy value estimation is that, even with ground truth knowledge of the MDP and/or access to a simulator, it may be intractable to estimate the robust policy values $\\bar{V_{d_{1}}^{\\pm}}$ Fortunately, the above environment has the desirable property that we can analytically compute the best/worst-case transition distributions allowed by our sensitivity model, since no matter what policy $\\pi_{t}$ the agent is acting with, it always strictly prefers transitions to smaller states. In detail, suppose that for some state, action pair $(s,a)$ we have $P(\\cdot\\mid s,a)=\\operatorname{Unif}[x,y]$ , for some $0\\leq x\\leq y\\leq5]$ Then, letting $\\alpha=1/(1+\\bar{\\Lambda(s,a)})$ , it is easy to verify that the worst case transition kernel is given by ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r}{U^{-}(\\cdot\\mid s,a)=(1-\\Lambda^{-1}(s,a))\\mathrm{Unif}[y-\\alpha(y-x),y]+\\Lambda^{-1}(s,a)\\mathrm{Unif}[x,y]\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "That is, the worst case transition kernel is given by a mixture of two uniform distributions. Therefore, we can easily simulate rollouts with the best/worst case transition kernels, and accurately estimate the robust policy values. This allows us to validate our methodology in this synthetic environment. Specifically, for each $\\Lambda(s,a)$ we experiment with, we can compute the corresponding ground truth $V_{d_{1}}^{-}$ up to arbitrary precision via Monte Carlo sampling, by rolling out trajectories with $\\pi_{t}$ in the adversarial MDP according to the above worst-case transition kernel. ", "page_idx": 33}, {"type": "text", "text": "Note as well that if one wanted to estimate the best-case policy value, analogous reasoning would giveus ", "page_idx": 33}, {"type": "equation", "text": "$$\nU^{+}(\\cdot\\mid s,a)=(1-\\Lambda^{-1}(s,a))\\mathrm{Unif}[x,x+\\alpha(y-x)]+\\Lambda^{-1}(s,a)\\mathrm{Unif}[x,y]\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "However, in our experiments we only concern ourselves with worst-case policy value estimation. ", "page_idx": 33}, {"type": "text", "text": "K.5 Nuisance Estimation ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We instantiate slight variations of Algorithms 1 and 2 using neural nets for the classes $\\mathcal{Q},\\,\\mathcal{B}$ , and $\\mathcal{W}$ used for fitting $Q^{-}$ \uff0c $\\beta^{-}$ , and $w^{-}$ respectively, and linear sieves for the corresponding critic class $\\mathcal{Q}$ that we perform maximization over for the minimax estimation of $w^{-}$ . Specifically, we grow the linear sieve for the critic class in a data-driven way, as follows: at each step $k$ of the respective algorithm, we compute the best response $q_{k}\\in\\mathcal{Q}$ to the previous iterate solution $w_{k}\\in\\mathcal{W}$ by optimizing over a neural net class, and then we append this best-response function to the set of functions in our linear sieve for the corresponding critic class. Full exact nuisance estimation details necessary for reproducibility will be available in our code release. ", "page_idx": 33}, {"type": "text", "text": "K.6 Estimators ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "We estimate the worst-case policy value using three different estimators: ", "page_idx": 33}, {"type": "text", "text": "\u00b7 Q: Direct estimator given by: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\widehat V_{d_{1}}^{-}=\\widehat Q^{-}(s_{1},\\pi_{t}(s_{1}))\\,,\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where $s_{1}$ is the deterministic initial state. ", "page_idx": 33}, {"type": "text", "text": "\u00b7 W: Importance sampling-style estimator using $\\hat{w}^{-}$ , which is given by: ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\widehat V_{d_{1}}^{-}=\\frac{1}{n}\\sum_{i=1}^{n}\\widehat w^{-}(s_{i},a_{i})\\widehat\\xi_{i}r_{i}\\,,\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "where ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\widehat{\\xi_{i}}=\\Lambda^{-1}+(1-\\Lambda^{-1})(1+\\Lambda)\\mathbb{I}\\left[\\widehat{V}^{-}(s_{i}^{\\prime})\\leq\\widehat{\\beta}^{-}(s_{i},a_{i})\\right]\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "\u00b7 Orth: Our orthogonal estimator using EIF, given by ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\widehat{V}_{d_{1}}^{-}=\\frac{1}{n}\\sum_{i=1}^{n}\\psi(s_{i},a_{i},s_{i}^{\\prime};\\widehat{Q}^{-},\\widehat{\\beta}^{-},\\widehat{w}^{-})\\,.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Note as well that we used a simpler data splitting procedure rather than the cross-fitting procedure described in Algorithm 3. Specifically, we used the first 10,000 tuples for estimating nuisances, and the second 10,oo0 tuples for the final estimators. This was done for the sake of computational ease in running experiments with many replications, and was performed in the same way for all methods. ", "page_idx": 33}, {"type": "text", "text": "In addition, for extra robustness, in each experiment replication we ran the nuisance estimation pipeline 5 times (on the same fixed sampled dataset), and took the 8Oth percentile policy value estimates, since the estimators tend to under-estimate the true policy value by design, with greater under-estimation when the nuisance estimates are less well optimized. ", "page_idx": 33}, {"type": "text", "text": "L  Empirical Investigation on Medical Application ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Here, we describe an additional empirical investigation of our methodology on medical data. Specifically, we consider the problem of sepsis management using RL. For all parts of the investigation described below, fully complete details can be obtained from our code release. ", "page_idx": 34}, {"type": "text", "text": "L.1  Motivation of Investigation ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Training RL models in simulated environments derived from real-world data is an exciting avenue for leveraging AI towards critical medical use cases. However, doing this obviously has the downside that, unless one undergoes the very risky process of training an RL agent online via real medical interventions, one has to resort to training within simulators, and then has to account for the inevitable \"sim-to-real\u201d gap. Therefore, our robust OPE methodology provides an interesting approach for estimating worst-case performance of RL models under potential changes in dynamics when moving to real application. ", "page_idx": 34}, {"type": "text", "text": "L.2 RL Environment ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Our RL environment is based on the OpenAI Gym sepsis simulator environment of [44]. This RL environment allows for simulation of dynamic sepsis management, which was created by training a blackbox ML model to mimic observed transition dynamics from the real-world electronic health record-based MIMIC-II dataset [36]. This existing_sepsis simulator is an episodic environment that continues until the agent either recovers or dies. It has a 46-dimensional state space containing various vital measurements, a discrete action space containing 24 possible actions (where an action is essentially the Cartesian product of some independent base actions). The reward function in this original simulator gives zero reward whenever an episode has not terminated, a $+15$ reward at termination when if the patient survives, or a -15 reward at termination if the patient dies. Please see [44] and the code release linked therein for additional details. ", "page_idx": 34}, {"type": "text", "text": "We built an RL environment for our investigation by creating a simple wrapper around this existing sepsis simulator, in order to make it fit our setup. In particular, we made the following key changes: ", "page_idx": 34}, {"type": "text", "text": ". We made the environment infinite-horizon, by automatically looping to a new random starting state for a fresh patient whenever the episode in the base simulator terminates ", "page_idx": 34}, {"type": "text", "text": "2. We normalized the reward function so that it lies in range [o, 1], where: (a) $r(s,a)=0$ if patient dies (b) $r(s,a)=1$ if patient recovers and is discharged (C) $r(s,a)=0.5$ if treatment has not terminated for current patient ", "page_idx": 34}, {"type": "text", "text": "In addition, for this environment, we perform all experiments with $\\gamma=0.95$ ", "page_idx": 34}, {"type": "text", "text": "L.3  Policies for Investigation ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "We constructed RL policies for our empirical investigation by training some deep RL models using the sepsis simulator environment. ", "page_idx": 34}, {"type": "text", "text": "In the case of the behavioral policy $\\pi_{b}$ used to generate the observational offline data, we trained this policy by running Proximal Policy Optimization (PPO: [63]) over a relatively large (16,000) number timesteps, in order to emulate a reasonably good \u201ccurrent best practices\u201d model for creating observationaldata. ", "page_idx": 34}, {"type": "text", "text": "In the case of the target policy $\\pi_{\\mathrm{t}}$ to be evaluated, we trained this policy using Deep Q Learning (DQL: [53]), over a relatively small (1,600) number of timesteps, in order to emulate a potentially risky new candidate model. ", "page_idx": 34}, {"type": "table", "img_path": "LKGuc2rY5v/tmp/fadc5bb0a23bd1e4b921c19e816df5b893747752387baa8baf5f695524aeddbd.jpg", "table_caption": [], "table_footnote": [], "page_idx": 35}, {"type": "text", "text": "Table 2: Median policy value estimate for sepsis management investigation, for each estimator and valueof $\\Lambda$ over 5 runs of each estimator from random initial seeds. The $\\pm$ values are given by half the difference between 80th and 20th percentiles. ", "page_idx": 35}, {"type": "text", "text": "L.4   Creating an Offline Dataset ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Using our behavioral policy $\\pi_{b}$ which we created as above, we generated a fixed ofline dataset consisting of 20,000 observed tuples of state, action, reward, and next state. Unlike with our main empirical investigation in the main paper, we did not perform any \u201cthinning\u201d on these sampled tuples to make them more independent, so that the observed transitions are sequentially correlated as with real-world medical data. ", "page_idx": 35}, {"type": "text", "text": "L.5 Nuisance Estimation ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "We perform nuisance estimation almost identically as in our main empirical investigation, with the only change being a slight change to our neural network architectures to better handle the large discrete action space. Specifically, instead of training neural networks that take state as input and produce $|{\\mathcal{A}}|$ outputs (one per action), we train neural networks that take both state and action as inputs, using a learnt low-dimensional encoding of the actions, and produce a single output. Please see our codereleasefor details. ", "page_idx": 35}, {"type": "text", "text": "L.6 Estimators ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "We consider the same three estimators (Q, W, and $\\mathbf{Orth}_{.}$ ) as in our main empirical investigation. As in that investigation, we use these to estimate the worst-case policy value for the given $\\bar{\\Lambda}(s,a)$ . In addition, as in the main experiments, we consider these estimators for various fixed $\\Lambda(s,a)$ that do not depend on $s$ or $a$ . In this case, we consider $\\Lambda\\in\\{1,2,4\\}$ , as these reflect a reasonable range of possible confounding strength for real application. ", "page_idx": 35}, {"type": "text", "text": "L.7 Results ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Below, in Table 2 we show the estimated policy value for all three estimators for each fixed $\\Lambda\\in$ $\\{1,2,4\\}$ . Here, we present the median policy value estimate over 5 runs of our estimators from random starting seeds after removing outliers.2 In addition, we present a $\\pm$ spread given by half the difference between the 80th and 20th percentiles. ", "page_idx": 35}, {"type": "text", "text": "Although for this investigation we cannot analytically compute the ground truth \u201ctrue\u201d adversarial policy values to evaluate against when $\\Lambda>1$ , we can still analyze the trends of these estimators and compare them to those observed in our main synthetic experiment, and we can also compare their accuracywhen $\\Lambda=1$ ", "page_idx": 35}, {"type": "text", "text": "First, in the case of $\\Lambda=1$ , we computed the true policy value of $\\pi_{\\mathfrak{t}}$ to be within the range $0.532{\\scriptstyle\\pm0.002}$ with $95\\%$ confidence. This is almost exactly equal to the median Orth estimator, but far outside the spread of outputs of the $\\mathbf{Q}$ estimator. That is, although the $\\mathbf{Q}$ estimator has somewhat lower variance in outputs over multiple runs for $\\Lambda=1$ compared with Orth, it appears to be far more biased. ", "page_idx": 35}, {"type": "text", "text": "Next, looking more broadly across all values of $\\Lambda$ , as in our main experiment, the Q and Orth estimators generally result in similar estimates to each other, and the W estimators are very variable. ", "page_idx": 35}, {"type": "text", "text": "This may reflect the relative dificulty of estimating the $w^{-}$ nuisance function compared with $Q^{-}$ and $\\beta^{-}$ ; although both Orth and W are affected by this difficulty, the Orth estimator has a theoretical robustness to the errors of these nuisance functions that the W estimator does not, as outlined in our theory. ", "page_idx": 36}, {"type": "text", "text": "We also observe that when $\\Lambda=1$ the Q estimator is significantly more stable than Orth, but when $\\Lambda>1$ the stability of Orth is either comparable to or superior to Q. In order to understand this, we first note that unlike in our main experiments, here the repetitions are re-runs of the estimators with the same offline sepsis dataset, so these $\\pm$ spreads reflect potential computational errors rather than statistical errors. Given this, this pattern of errors could be explained by the fact that when $\\Lambda=1$ the Q estimation is extremely simple, reducing to standard FQI, whereas when $\\Lambda>1$ it requires a more complex robust FQI estimation with simultaneous estimation of $\\beta^{-}$ . That is, the difference in computational difficulty of estimating Orth versus Q may be smaller for $\\Lambda>1$ ", "page_idx": 36}, {"type": "text", "text": "Overall, although it is hard to definitively compare the accuracy of these estimators for $\\Lambda\\,>\\,1$ given a fundamental lack of ground truth, given both a similar pattern of results as in our synthetic experiments, as well as the far greater accuracy of Orth when $\\Lambda=1$ , it seems reasonably to believe based on these results that our proposed Orth estimator may be more reliable than the existing robust FQI approach of the Q estimator. ", "page_idx": 36}, {"type": "text", "text": "Finally, we consider the implication of our results for the problem of learning sepsis management policies from simulators. Our Orth estimator suggests that there is relatively little sensitivity of this environment to deviations allowed by $\\Lambda=2$ , but very significant deviation allowed by $\\Lambda=4$ Indeed, given the reward structure described above, the worst-case results under $\\Lambda=4$ imply an extremely high mortality rate. Whether worst-case deviations of this magnitude are reasonable or not is unclear, and this is something that requires further investigation for future work on RL for sepsis management. ", "page_idx": 36}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately refect the paper's contributions and scope? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 37}, {"type": "text", "text": "Justification: Yes, we provide complete proofs for our theorems and describe detailed empirical validation for our proposed algorithms. ", "page_idx": 37}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] . ", "page_idx": 37}, {"type": "text", "text": "Justification: Yes, we discussed where our assumptions may fail and settings not captured by the current paper, which we believe are directions for future research. ", "page_idx": 37}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: Yes, we provide full assumptions in the main paper and the complete proofs are written in the Appendix. ", "page_idx": 37}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 37}, {"type": "text", "text": "Justification: Yes, our experimental section includes all details needed to reproduce the main experimental results. ", "page_idx": 37}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 37}, {"type": "text", "text": "Justification: Yes, our code is open-sourced at https://github.com/CausalML/ adversarial-ope/. ", "page_idx": 37}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 37}, {"type": "text", "text": "Justification: Yes, please see our experimental section and appendices for all training and evaluation details. ", "page_idx": 37}, {"type": "text", "text": "Guidelines: ", "page_idx": 37}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 37}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 37}, {"type": "text", "text": "Justification: Yes, our experiments are replicated over multiple seeds and we report the confidence intervals. ", "page_idx": 37}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 38}, {"type": "text", "text": "Justification: Yes, this paper is mostly focused on theory and our experiment is a proof of concept and can be run on a standard GPU. ", "page_idx": 38}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 38}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 38}, {"type": "text", "text": "Justification: Yes, we have reviewed the code of ethics and believe our research conforms to it. ", "page_idx": 38}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: This paper is about foundational research not tied to particular applications so we do not feel the need to highlight any societal impacts. ", "page_idx": 38}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: This paper is about foundational research not tied to particular applications so we do not feel the need to highlight any risks for misuse here. ", "page_idx": 38}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not use any existing assets. ", "page_idx": 38}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not release new assets. ", "page_idx": 38}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 38}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 38}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 38}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)were obtained? ", "page_idx": 38}, {"type": "text", "text": "Answer: [NA] .   \nJustification: The paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 38}]