[{"figure_path": "HcifdQZFZV/tables/tables_4_1.jpg", "caption": "Table 2: The performance of Safe LoRA compared with LoRA, SafeInstr, and BEA methods under the Llama-2-7B-Chat/Llama-3-8B-Instruct models fine-tuned on the PureBad dataset.", "description": "This table presents the results of an experiment comparing SafeLoRA's performance against three other methods (LoRA, SafeInstr, and BEA) in mitigating safety risks during fine-tuning on a purely malicious dataset.  The table shows the harmfulness scores, utility scores (MT-Bench), and attack success rates for each method, allowing for a comparison of their effectiveness in balancing safety and utility.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_6_1.jpg", "caption": "Table 2: The performance of Safe LoRA compared with LoRA, SafeInstr, and BEA methods under the Llama-2-7B-Chat/Llama-3-8B-Instruct models fine-tuned on the PureBad dataset.", "description": "This table presents a comparison of the performance of Safe LoRA against three other methods (LoRA, SafeInstr, and BEA) on two different language models (Llama-2-7B-Chat and Llama-3-8B-Instruct) when fine-tuned using only malicious data (PureBad dataset).  The metrics used for comparison include Utility (measured by MT-Bench), Harmfulness Score (lower is better), and Attack Success Rate (ASR, lower is better). The table shows that Safe LoRA generally maintains high utility while significantly reducing the harmfulness score compared to the other methods.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_7_1.jpg", "caption": "Table 2: The performance of Safe LoRA compared with LoRA, SafeInstr, and BEA methods under the Llama-2-7B-Chat/Llama-3-8B-Instruct models fine-tuned on the PureBad dataset.", "description": "This table presents the results of experiments conducted on the PureBad dataset, which comprises purely malicious samples.  The table compares the performance of Safe LoRA with three other methods: the original LoRA, SafeInstr, and BEA.  Metrics used for comparison include utility (measured by MT-Bench), harmfulness (harmfulness score), and the attack success rate (ASR).  The table shows how these methods perform on both Llama-2-7B-Chat and Llama-3-8B-Instruct models.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_7_2.jpg", "caption": "Table 4: The performance of Safe LoRA compared with LoRA, SafeInstr, and BEA methods fine-tuned on the Alpaca dataset under the Llama-2-7B-Chat model.", "description": "This table presents the performance comparison of SafeLoRA against three other methods (LoRA, SafeInstr, and BEA) when fine-tuning on the Alpaca dataset using the Llama-2-7B-Chat model.  The metrics used for comparison are Utility (measured using MT-Bench scores, higher is better), Harmfulness Score (lower is better), and Attack Success Rate (ASR, lower is better).  The Alpaca dataset is a benign dataset, meaning it doesn't contain malicious data.  The results show SafeLoRA's ability to maintain high utility while significantly improving safety compared to the other methods.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_8_1.jpg", "caption": "Table 5: Comparison of performance of native full fine-tuning and Safe LoRA with the setting of full parameters fine-tuned on the PureBad dataset under the Llama-2-Chat model.", "description": "This table compares the performance of native full fine-tuning and Safe LoRA on the PureBad dataset using the Llama-2-Chat model.  It shows the harmfulness score, MT-Bench score (a measure of utility), and attack success rate (ASR) for both methods.  The results demonstrate the effectiveness of Safe LoRA in mitigating the negative impact of full fine-tuning on safety while preserving utility.", "section": "4.2 Ablation Study"}, {"figure_path": "HcifdQZFZV/tables/tables_13_1.jpg", "caption": "Table 2: The performance of Safe LoRA compared with LoRA, SafeInstr, and BEA methods under the Llama-2-7B-Chat/Llama-3-8B-Instruct models fine-tuned on the PureBad dataset.", "description": "This table presents a comparison of the performance of Safe LoRA against standard LoRA, SafeInstr, and BEA methods.  The models were fine-tuned on the PureBad dataset, which contains purely malicious examples.  The table shows the utility (measured by MT-Bench score), harmfulness (measured by harmfulness score), and attack success rate (ASR) for each method.  The results illustrate Safe LoRA's effectiveness in maintaining utility while mitigating safety risks compared to other approaches.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_14_1.jpg", "caption": "Table 6: Comparison of similarity of weights with models trained on different types of datasets.", "description": "This table compares the similarity scores (S(CAW, AW)) for models trained on different datasets: Alpaca (benign), Dialog Summary (mixed benign and malicious), and PureBad (purely malicious).  Lower scores indicate greater differences between the original and projected LoRA weights, suggesting a higher likelihood of safety degradation during fine-tuning.", "section": "A.4 Details of Computing Distance for LoRA Weights Trained on the PurBad Dataset"}, {"figure_path": "HcifdQZFZV/tables/tables_14_2.jpg", "caption": "Table 7: The performance of Safe LoRA compared with LoRA, SafeInstr, and BEA methods under the Gemma model fine-tuned on the Dialog Summary dataset.", "description": "This table presents the results of an experiment evaluating the performance of Safe LoRA and other methods (LoRA, SafeInstr, and BEA) on the Gemma model when fine-tuned on the Dialog Summary dataset.  The experiment included an adversarial attack (malicious data). The table shows the utility (Rouge-1 F1 score), harmfulness score, and attack success rate (ASR) for each method. The results highlight the effectiveness of Safe LoRA in maintaining utility while mitigating safety risks.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_15_1.jpg", "caption": "Table 8: The performance of Safe LoRA compared with Vaccine (single LoRA) under the Llama-2-chat model on PureBad and Dialog Summary datasets.", "description": "This table presents the performance comparison of Safe LoRA against the single LoRA version of the Vaccine method on two datasets: PureBad and Dialog Summary.  The evaluation metrics include utility (measured by MT-Bench and Rouge-1 F1 score), harmfulness score (rated by GPT-4), and attack success rate (ASR).  It demonstrates the effectiveness of Safe LoRA in maintaining utility while significantly reducing harmfulness and ASR compared to the Vaccine method.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_15_2.jpg", "caption": "Table 8: The performance of Safe LoRA compared with Vaccine (single LoRA) under the Llama-2-chat model on PureBad and Dialog Summary datasets.", "description": "This table presents the results of experiments comparing the performance of Safe LoRA against a single LoRA model and the Vaccine method on two datasets: PureBad (containing only harmful examples) and Dialog Summary (containing a mix of benign and harmful examples).  The metrics used for comparison are Utility (higher is better, measured by MT-Bench and Rouge scores), Harmfulness (lower is better, as scored by GPT-4), and Attack Success Rate (ASR, lower is better). The table shows that Safe LoRA outperforms both single LoRA and Vaccine in terms of Harmfulness and ASR while maintaining reasonably good utility, demonstrating its effectiveness in mitigating the negative effects of harmful training data.", "section": "4.1 Performance Evaluation"}, {"figure_path": "HcifdQZFZV/tables/tables_15_3.jpg", "caption": "Table 10: The performance of Safe LoRA compared with the Llama-2-Chat model (without defense) while varying the amount of harmful examples.", "description": "This table presents a comparison of the performance of Safe LoRA against a baseline Llama-2-Chat model (without any safety mechanisms) under different percentages of harmful examples in the fine-tuning dataset.  The metrics compared are Utility (MT-Bench score), Harmfulness Score (lower is better), and Attack Success Rate (ASR, lower is better).  The table shows how Safe LoRA maintains utility while significantly reducing harmfulness and ASR even as the proportion of malicious data increases.", "section": "4.2 Ablation Study"}]