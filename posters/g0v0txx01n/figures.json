[{"figure_path": "G0v0TxX01N/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of reasoning approaches. (a) Answer-only and (b) CoT generate left-to-right tokens by prompting autoregressive language model. (c) Implicit CoT replaces horizontal reasoning (CoT) with vertical reasoning from shallow layer to deep layer [7]. (d) DoT generates reasoning path along with the diffusion timesteps.", "description": "This figure illustrates four different reasoning approaches in language models. (a) shows the answer-only approach, where the model directly generates the answer without intermediate steps. (b) shows the chain-of-thought (CoT) approach, where the model generates a sequence of intermediate reasoning steps before producing the final answer. (c) shows the implicit CoT approach, where reasoning steps are implicitly learned within the layers of a neural network. (d) shows the Diffusion-of-Thought (DoT) approach proposed in the paper, which uses a diffusion model to generate reasoning steps over time.  DoT leverages the diffusion process to allow for parallel reasoning steps and greater flexibility in balancing computation and performance.", "section": "3 Diffusion-of-Thoughts"}, {"figure_path": "G0v0TxX01N/figures/figures_3_1.jpg", "caption": "Figure 2: Demonstration of DoT pipeline. DoT diffuses all possible thoughts across diffusion timestep t. Multi-pass DoT disentangles each rationale and introduces causal bias. The stacked circles stand for the marginalization over other potential reasoning paths, which is implicitly carried out during the training of diffusion models.", "description": "This figure illustrates the Diffusion-of-Thoughts (DoT) pipeline.  The single-pass DoT shows how reasoning steps diffuse over time through a diffusion model, updating a sequence of latent variables representing thoughts in parallel.  The multi-pass DoT (DoTMP) method focuses on generating one thought at a time to address potential causal bias, improving accuracy by introducing causal inductive bias.  The training process includes a \"scheduled sampling\" mechanism to improve self-correction by exposing and correcting errors, and \"coupled sampling\" to improve the robustness of multi-pass DoT. Finally, inference accelerates by utilizing a conditional ODE solver.", "section": "3.2 Modeling"}, {"figure_path": "G0v0TxX01N/figures/figures_6_1.jpg", "caption": "Figure 3: The effectiveness of ODE solver in speedup inference of Plaid DoT.", "description": "This figure shows how using an ODE solver improves the inference speed of the Plaid DoT model.  The x-axis represents the number of timesteps (T) used during the sampling process, and the y-axis shows the accuracy achieved.  Multiple lines are presented, comparing the performance of DoT and DoTMP models both with and without the ODE solver. The results demonstrate that incorporating the ODE solver significantly accelerates inference without sacrificing accuracy, highlighting its beneficial impact on the efficiency of the DoT approach.", "section": "3.4 Inference"}, {"figure_path": "G0v0TxX01N/figures/figures_7_1.jpg", "caption": "Figure 2: Demonstration of DoT pipeline. DoT diffuses all possible thoughts across diffusion timestep t. Multi-pass DoT disentangles each rationale and introduces causal bias. The stacked circles stand for the marginalization over other potential reasoning paths, which is implicitly carried out during the training of diffusion models.", "description": "This figure illustrates the pipeline of the proposed Diffusion of Thought (DoT) method.  It visually explains how DoT works by showing a sequence of latent variables representing thoughts, which diffuse over time in parallel, allowing reasoning steps to occur concurrently. The figure also contrasts DoT with its multi-pass variant (DoTMP), highlighting how DoTMP generates rationales one at a time to address causal bias, making it more suitable for complex reasoning.  The use of stacked circles represents the model\u2019s implicit marginalization over other potential reasoning paths during training.", "section": "3.2 Modeling"}]