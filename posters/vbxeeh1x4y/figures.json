[{"figure_path": "vBxeeH1X4y/figures/figures_5_1.jpg", "caption": "Figure 2: Cell-level outlier detection rate curves for 2D-OOB, 2D-KNN, and Random. The x-axis represents the percentage of inspected cells. The y-axis represents the detection rate, defined as the ratio of the number of detected outlier cells to the total number of outlier cells present in a dataset. The error bars show a 95% confidence interval based on 30 independent experiments. We examine the cells in ascending order, starting from those with the lowest values, and thus a curve closer to the left-top corner indicates better performance. 2D-OOB efficiently detects the majority of outlier cells by examining only a small fraction of the total cells, while 2D-KNN and Random require scanning nearly all the cells.", "description": "This figure compares the performance of three methods (2D-OOB, 2D-KNN, Random) in detecting cell-level outliers. The x-axis shows the percentage of cells inspected, and the y-axis shows the detection rate.  2D-OOB significantly outperforms the other two, achieving high detection rates while inspecting only a small fraction of the cells.  Error bars represent 95% confidence intervals.", "section": "4.1 Cell-level outlier detection"}, {"figure_path": "vBxeeH1X4y/figures/figures_6_1.jpg", "caption": "Figure 2: Cell-level outlier detection rate curves for 2D-OOB, 2D-KNN, and Random. The x-axis represents the percentage of inspected cells. The y-axis represents the detection rate, defined as the ratio of the number of detected outlier cells to the total number of outlier cells present in a dataset. The error bars show a 95% confidence interval based on 30 independent experiments. We examine the cells in ascending order, starting from those with the lowest values, and thus a curve closer to the left-top corner indicates better performance. 2D-OOB efficiently detects the majority of outlier cells by examining only a small fraction of the total cells, while 2D-KNN and Random require scanning nearly all the cells.", "description": "The figure shows the performance of three methods (2D-OOB, 2D-KNN, and Random) in detecting cell-level outliers.  The x-axis shows the percentage of cells examined, and the y-axis shows the percentage of outliers correctly identified.  2D-OOB significantly outperforms the other two methods, demonstrating its efficiency in identifying outliers.", "section": "4.1 Cell-level outlier detection"}, {"figure_path": "vBxeeH1X4y/figures/figures_6_2.jpg", "caption": "Figure 2: Cell-level outlier detection rate curves for 2D-OOB, 2D-KNN, and Random. The x-axis represents the percentage of inspected cells. The y-axis represents the detection rate, defined as the ratio of the number of detected outlier cells to the total number of outlier cells present in a dataset. The error bars show a 95% confidence interval based on 30 independent experiments. We examine the cells in ascending order, starting from those with the lowest values, and thus a curve closer to the left-top corner indicates better performance. 2D-OOB efficiently detects the majority of outlier cells by examining only a small fraction of the total cells, while 2D-KNN and Random require scanning nearly all the cells.", "description": "This figure compares the performance of 2D-OOB, 2D-KNN, and a random baseline in detecting cell-level outliers.  The detection rate (y-axis) is plotted against the inspection percentage (x-axis), showing how many outliers are found as a percentage of the total number of cells examined.  Error bars represent the 95% confidence interval across 30 experiments.  The results demonstrate that 2D-OOB significantly outperforms the other methods, achieving high detection rates with a much smaller proportion of cells inspected.", "section": "4.1 Cell-level outlier detection"}, {"figure_path": "vBxeeH1X4y/figures/figures_7_1.jpg", "caption": "Figure 5: Qualitative examples for 2D-00B in the backdoor trigger detection task. Each pair of images consists of a poisoned image and its corresponding cell valuation heatmap. The color of the heatmap indicates importance, with red cells representing higher importance and blue cells representing lower importance. In the first two pairs, the class \u201cbird\u201d is relabeled as \u201ccat\u201d, while in the latter two pairs, the class \u201cdeer\u201d is relabeled as \u201ccat\u201d. The heatmaps clearly show that higher cell valuations are predominantly concentrated in the regions containing triggers, while areas featuring actual objects receive lower valuations. This pattern suggests that 2D-00B effectively captures the triggers as the impactful features responsible for the misclassification of the poisoned samples.", "description": "This figure shows four examples of poisoned images and their corresponding cell valuation heatmaps generated by 2D-OOB.  The heatmaps visually represent the importance of each cell in the image, with red indicating higher importance and blue indicating lower importance. The examples demonstrate that 2D-OOB accurately highlights the backdoor triggers (the manipulated parts of the images) as the most important features driving misclassification, even when the actual object is present.  This is a key strength of 2D-OOB in its ability to localize the impact of data poisoning attacks at the cell level.", "section": "4.3 Backdoor trigger detection"}, {"figure_path": "vBxeeH1X4y/figures/figures_16_1.jpg", "caption": "Figure 2: Cell-level outlier detection rate curves for 2D-OOB, 2D-KNN, and Random. The x-axis represents the percentage of inspected cells. The y-axis represents the detection rate, defined as the ratio of the number of detected outlier cells to the total number of outlier cells present in a dataset. The error bars show a 95% confidence interval based on 30 independent experiments. We examine the cells in ascending order, starting from those with the lowest values, and thus a curve closer to the left-top corner indicates better performance. 2D-OOB efficiently detects the majority of outlier cells by examining only a small fraction of the total cells, while 2D-KNN and Random require scanning nearly all the cells.", "description": "This figure compares the performance of three methods (2D-OOB, 2D-KNN, and Random) in detecting cell-level outliers.  The x-axis shows the percentage of cells inspected, and the y-axis shows the detection rate.  2D-OOB significantly outperforms the other methods, demonstrating its efficiency in finding outliers.", "section": "4.1 Cell-level outlier detection"}, {"figure_path": "vBxeeH1X4y/figures/figures_16_2.jpg", "caption": "Figure 5: Qualitative examples for 2D-00B in the backdoor trigger detection task. Each pair of images consists of a poisoned image and its corresponding cell valuation heatmap. The color of the heatmap indicates importance, with red cells representing higher importance and blue cells representing lower importance. In the first two pairs, the class \u201cbird\u201d is relabeled as \u201ccat\u201d, while in the latter two pairs, the class \u201cdeer\u201d is relabeled as \u201ccat\u201d. The heatmaps clearly show that higher cell valuations are predominantly concentrated in the regions containing triggers, while areas featuring actual objects receive lower valuations. This pattern suggests that 2D-00B effectively captures the triggers as the impactful features responsible for the misclassification of the poisoned samples.", "description": "This figure shows four examples of poisoned images and their corresponding cell valuation heatmaps generated by 2D-00B.  Redder colors in the heatmaps indicate higher importance, and bluer colors indicate lower importance.  The heatmaps show that 2D-00B successfully highlights the backdoor trigger regions (the areas manipulated by the poisoning attack) as the most important features for the model's misclassification, rather than the actual content of the images.", "section": "4.3 Backdoor trigger detection"}, {"figure_path": "vBxeeH1X4y/figures/figures_20_1.jpg", "caption": "Figure 9: Point removal experiment results (test accuracy curves) of 7 data valuation methods-2D-00B-data, 2D-KNN-data, Data-00B, LAVA, DataBanzhaf, DataShapley, KNNShapley and a random baseline. We remove data points from the lowest valuation to the highest valuation. The results from 6 binary classification datasets are displayed. For each dataset, we conduct 30 independent trials and report the average results. A higher curve indicates better performance. 2D-00B-data demonstrates superior ability in finding a set of helpful data points.", "description": "The figure shows the test accuracy of different data valuation methods when data points are removed progressively, starting with the lowest-valued ones.  It compares 2D-00B-data against other methods like Data-00B, DataShapley, and KNNShapley across six binary classification datasets.  The goal is to illustrate how effectively each method identifies and removes unhelpful data points to improve model accuracy.  2D-00B-data generally shows the best performance, maintaining higher accuracy even after removing a significant portion of data points.", "section": "D.2 Point removal experiment"}]