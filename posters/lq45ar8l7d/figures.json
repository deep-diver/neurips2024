[{"figure_path": "lQ45aR8L7D/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of order dependency in Llama 2, 7B. Using the order provided by (Measuring Massive Multitask Language Understanding) (MMLU) (Hendrycks et al., 2020) Llama 2 gets the question correct as seen in a), but if the order is reversed for the questions Llama 2, 7B predictions the wrong answer. In c) we use Set-Based Prompting to remove the ordering of the answers and Llama 2, 7B once again gets the question correct.", "description": "This figure demonstrates the impact of input order on the performance of Llama 2 7B Language Model.  Panel (a) shows a correct prediction when the order of the options is the same as in the MMLU dataset.  Panel (b) shows an incorrect prediction when the options are reversed. Panel (c) shows that Set-Based Prompting, a technique introduced in the paper, removes the order dependency, resulting in a correct answer regardless of the options order. This illustrates the core problem the paper aims to solve and the proposed solution's effectiveness.", "section": "1 Introduction"}, {"figure_path": "lQ45aR8L7D/figures/figures_6_1.jpg", "caption": "Figure 3: Per model accuracy on two different datasets, blue bars (left three) indicate runs done without our method and green with Set-Based Prompting. The blue bars are constructed by running the test twice, once with the normal ordering and once with the reversed ordering. Worst of 2 and Best of 2 count when both orderings lead to an correct answer or only one ordering answered correctly, respectively. While Best of 1 indicates that the normal ordering led to correct answers. As Set-Based Prompting is invariant to reordering so we only show one bar for all orderings.", "description": "This figure displays the performance comparison of different LLMs on two datasets (CSQA and MMLU) with and without the proposed Set-Based Prompting technique.  It highlights the impact of input order on model accuracy, showcasing that Set-Based Prompting mitigates order dependency, leading to more consistent results across different input orderings.", "section": "4 Performance"}, {"figure_path": "lQ45aR8L7D/figures/figures_7_1.jpg", "caption": "Figure 3: Per model accuracy on two different datasets, blue bars (left three) indicate runs done without our method and green with Set-Based Prompting. The blue bars are constructed by running the test twice, once with the normal ordering and once with the reversed ordering. Worst of 2 and Best of 2 count when both orderings lead to an correct answer or only one ordering answered correctly, respectively. While Best of 1 indicates that the normal ordering led to correct answers. As Set-Based Prompting is invariant to reordering so we only show one bar for all orderings.", "description": "This figure shows the accuracy of different language models on two benchmark datasets (modified CSQA and modified MMLU) with and without using the proposed Set-Based Prompting method.  The blue bars represent the accuracy obtained using the original question order and its reverse, illustrating order dependency.  The green bars show accuracy with Set-Based Prompting applied, demonstrating order independence.  The results indicate that Set-Based Prompting maintains reasonable accuracy while eliminating order dependency.", "section": "4 Performance"}, {"figure_path": "lQ45aR8L7D/figures/figures_8_1.jpg", "caption": "Figure 3: Per model accuracy on two different datasets, blue bars (left three) indicate runs done without our method and green with Set-Based Prompting. The blue bars are constructed by running the test twice, once with the normal ordering and once with the reversed ordering. Worst of 2 and Best of 2 count when both orderings lead to an correct answer or only one ordering answered correctly, respectively. While Best of 1 indicates that the normal ordering led to correct answers. As Set-Based Prompting is invariant to reordering so we only show one bar for all orderings.", "description": "This figure shows the performance comparison of different LLMs on two datasets (Modified CSQA and Modified MMLU) with and without Set-Based Prompting.  The blue bars represent the accuracy when the input order is either normal or reversed, while the green bar represents the accuracy using Set-Based Prompting, which is order-invariant. The different shades of blue show the best and worst results obtained from normal and reversed ordering scenarios.  The results demonstrate the effect of Set-Based Prompting in reducing order dependence and achieving consistent performance across different input orders.", "section": "4 Performance"}, {"figure_path": "lQ45aR8L7D/figures/figures_16_1.jpg", "caption": "Figure 3: Per model accuracy on two different datasets, blue bars (left three) indicate runs done without our method and green with Set-Based Prompting. The blue bars are constructed by running the test twice, once with the normal ordering and once with the reversed ordering. Worst of 2 and Best of 2 count when both orderings lead to an correct answer or only one ordering answered correctly, respectively. While Best of 1 indicates that the normal ordering led to correct answers. As Set-Based Prompting is invariant to reordering so we only show one bar for all orderings.", "description": "This figure shows the accuracy of different language models on two benchmark datasets (modified CSQA and modified MMLU) with and without Set-Based Prompting.  The blue bars represent the accuracy using the default and reversed orderings of the options. The green bar represents the accuracy using Set-Based Prompting, which is order-invariant.  The different shades of blue bars show the best and worst case scenarios for the default ordering.", "section": "4 Performance"}, {"figure_path": "lQ45aR8L7D/figures/figures_16_2.jpg", "caption": "Figure 3: Per model accuracy on two different datasets, blue bars (left three) indicate runs done without our method and green with Set-Based Prompting. The blue bars are constructed by running the test twice, once with the normal ordering and once with the reversed ordering. Worst of 2 and Best of 2 count when both orderings lead to an correct answer or only one ordering answered correctly, respectively. While Best of 1 indicates that the normal ordering led to correct answers. As Set-Based Prompting is invariant to reordering so we only show one bar for all orderings.", "description": "This figure compares the accuracy of different LLMs on two datasets (Modified CSQA and Modified MMLU) with and without using Set-Based Prompting. For the models without Set-Based Prompting, two accuracy values are shown which represent the performance with default and reversed ordering of the input data. In contrast, the models with Set-Based Prompting show only one accuracy value because the technique makes the model order-independent.  The figure helps visualize the impact of Set-Based Prompting on mitigating order dependency and its effect on overall model accuracy.", "section": "4 Performance"}, {"figure_path": "lQ45aR8L7D/figures/figures_17_1.jpg", "caption": "Figure 9: MMLU accuracy for sub set of models with the normal ordering, reversed ordering, accuracy when only the positional encoding p(i, j) is modified, accuracy when only the positional encoding p(i, j) is modified reverse ordering, when only the attention mask Mf is modified, when only the attention mask Mf is modified reverse ordering and Set-Based Prompting applied to the options.", "description": "This figure shows the modified MMLU accuracy for a subset of models under various conditions.  It compares the accuracy with normal and reversed question orderings, and when only the positional encoding or attention mask is modified.  Finally, it displays the accuracy when using Set-Based Prompting. The purpose is to illustrate the impact of different modifications on the order dependency problem and how Set-Based Prompting improves accuracy.", "section": "4.3 Ablations"}, {"figure_path": "lQ45aR8L7D/figures/figures_17_2.jpg", "caption": "Figure 3: Per model accuracy on two different datasets, blue bars (left three) indicate runs done without our method and green with Set-Based Prompting. The blue bars are constructed by running the test twice, once with the normal ordering and once with the reversed ordering. Worst of 2 and Best of 2 count when both orderings lead to an correct answer or only one ordering answered correctly, respectively. While Best of 1 indicates that the normal ordering led to correct answers. As Set-Based Prompting is invariant to reordering so we only show one bar for all orderings.", "description": "This figure shows the accuracy results on two datasets (Modified CSQA and Modified MMLU) for several large language models (LLMs). Blue bars represent the performance without Set-Based Prompting, showing the variation between normal and reversed ordering (Worst of 2, Best of 2, and Best of 1). The green bar shows the accuracy achieved with Set-Based Prompting, demonstrating its consistency across different orderings.", "section": "4 Performance"}, {"figure_path": "lQ45aR8L7D/figures/figures_18_1.jpg", "caption": "Figure 3: Per model accuracy on two different datasets, blue bars (left three) indicate runs done without our method and green with Set-Based Prompting. The blue bars are constructed by running the test twice, once with the normal ordering and once with the reversed ordering. Worst of 2 and Best of 2 count when both orderings lead to an correct answer or only one ordering answered correctly, respectively. While Best of 1 indicates that the normal ordering led to correct answers. As Set-Based Prompting is invariant to reordering so we only show one bar for all orderings.", "description": "The figure shows the accuracy of different language models on two benchmark datasets (CSQA and MMLU) with and without the proposed Set-Based Prompting technique. The blue bars represent the accuracy with normal and reversed orderings of the options. The green bars show the accuracy with Set-Based Prompting, which is order-invariant. The results demonstrate the effectiveness of Set-Based Prompting in mitigating order dependency in LLMs.", "section": "4 Performance"}]