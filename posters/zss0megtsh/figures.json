[{"figure_path": "ZsS0megTsh/figures/figures_3_1.jpg", "caption": "Figure 1: Overview of the proposed method. During the stage of audio-visual speech representation learning, local speech representations and global information are learned by frame-wise feature alignment and the masked prediction task, respectively. In the stage of forgery detection, we separately feed the whole lip movement sequence and audio stream of a video into the learned model to get visual and audio speech representations. And we flag videos with low matching scores between visual and audio speech representations as fake videos.", "description": "This figure illustrates the SpeechForensics method proposed in the paper.  It's a two-stage process.  The first stage is audio-visual speech representation learning where a model learns representations from real videos using a combination of frame-wise audio-visual alignment and a masked prediction task to capture both local and global speech information.  The second stage is forgery detection; the trained model is then used to process both audio and visual streams of a video to obtain speech representations.  Videos with a low similarity score between the audio and visual speech representations are classified as fake.", "section": "3 Method"}, {"figure_path": "ZsS0megTsh/figures/figures_6_1.jpg", "caption": "Figure 2: Robustness to unseen perturbations. Video-level AUC scores (%) are reported under different perturbations. Each perturbation contains five intensity levels [34]. \u201cAverage\u201d denotes the mean of each perturbation under each intensity level.", "description": "This figure displays the robustness of different face forgery detection methods against various image perturbations.  Seven types of perturbations are tested (Saturation, Contrast, Block-wise, Gaussian Noise, Gaussian Blur, Pixelation, Compression), each at five different intensity levels. The AUC (Area Under the Receiver Operating Characteristic Curve) scores are plotted for each perturbation and intensity level.  The \"Average\" column shows the mean AUC across all intensity levels for each perturbation type. The figure demonstrates the relative performance of the different methods in dealing with these common image manipulations.", "section": "4.2 Quantitative Comparisons"}, {"figure_path": "ZsS0megTsh/figures/figures_7_1.jpg", "caption": "Figure 3: Visualized analysis. Cosine similarity distributions of audio and visual speech representations for real videos and fake videos generated by different manipulation methods.", "description": "This figure visualizes the cosine similarity distributions between the audio and visual speech representations extracted from real and fake videos.  Different manipulation methods are shown separately: Deepfakes, FaceSwap, Face2Face, NeuralTextures, FSGAN, and Wav2Lip. For each method, two histograms are presented: one for real videos and one for fake videos. The x-axis represents the cosine similarity, and the y-axis represents the count of videos. The purpose is to show how well the model can distinguish between real and fake videos using the learned audio-visual speech representations, demonstrating its ability to detect forgeries across various manipulation techniques.", "section": "4.3 Qualitative Results"}, {"figure_path": "ZsS0megTsh/figures/figures_7_2.jpg", "caption": "Figure 4: Interpretative analysis. The transcriptions are based on audio and visual speech representations of real and different types of fake videos. We show the transcriptions of each type of video containing the same audio.", "description": "This figure displays a qualitative analysis of the proposed method's ability to distinguish between real and manipulated videos by examining audio-visual speech representations. The top row presents a real video with its corresponding audio waveform and transcription generated from both audio and visual features. The subsequent rows show examples of videos manipulated using four different techniques (Deepfakes, FaceSwap, Face2Face, NeuralTextures), each with its transcription obtained similarly. This provides a visual comparison to demonstrate how the model utilizes audio and visual speech representations to understand the speech content and identify inconsistencies in manipulated videos.", "section": "4.3 Qualitative Results"}, {"figure_path": "ZsS0megTsh/figures/figures_8_1.jpg", "caption": "Figure 5: Influence of video length and sliding-window length. We evaluate the performance of our method conditioned on different input lengths and sliding-window lengths.", "description": "This figure shows the impact of video clip length and sliding window length on the performance of the proposed face forgery detection method.  The left panel displays how AUC (Area Under the ROC Curve) changes as the video length increases, showing improved performance with longer clips for FaceSwap, NeuralTextures, and an average across forgery methods.  The right panel illustrates the AUC as a function of the sliding window length used in the audio-visual alignment process. This panel demonstrates that increasing the window length to a certain degree improves the detection performance before leveling off.  Overall, the figure highlights the importance of considering both long-range temporal contexts (longer video clips) and appropriate time alignment (sliding window length) for optimal forgery detection.", "section": "4.4 Ablation study"}, {"figure_path": "ZsS0megTsh/figures/figures_13_1.jpg", "caption": "Figure 6: Perturbed examples. Visualization of all types of perturbations at different intensity levels. We present three representative (mild, moderate and severe) intensity levels.", "description": "This figure visualizes the effects of seven different types of image manipulations on a sample face image. Each manipulation is shown at three different intensity levels (mild, moderate, and severe). The manipulations include changes to saturation, contrast, addition of block artifacts, noise, blur, pixelation, and compression.  The figure demonstrates how various levels of noise and distortions can impact the visual quality of a face image, thereby affecting the performance of facial forgery detection methods.", "section": "4.3 Qualitative Results"}, {"figure_path": "ZsS0megTsh/figures/figures_14_1.jpg", "caption": "Figure 3: Visualized analysis. Cosine similarity distributions of audio and visual speech representations for real videos and fake videos generated by different manipulation methods.", "description": "This figure visualizes the cosine similarity distributions between audio and visual speech representations for both real and fake videos.  The fake videos were generated using different manipulation methods (Deepfakes, FaceSwap, Face2Face, NeuralTextures, FSGAN, and Wav2Lip). Each sub-figure shows a histogram of cosine similarity scores, with green representing real videos and orange representing fake videos. The distributions show that real videos tend to have higher cosine similarity scores compared to fake videos, reflecting the consistency between lip movements and audio in real videos, whereas inconsistencies are observed in fake videos due to manipulation techniques.", "section": "4.3 Qualitative Results"}]