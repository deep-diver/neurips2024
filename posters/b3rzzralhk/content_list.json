[{"type": "text", "text": "On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Tariq Berrada1,2 Pietro Astolfi1 Melissa Hall1 Reyhane Askari-Hemmat1 ", "page_idx": 0}, {"type": "text", "text": "Yohann Benchetrit1 Marton Havasi1 Matthew Muckley1 Karteek Alahari2 ", "page_idx": 0}, {"type": "text", "text": "Adriana Romero-Soriano1,3,4,5 Jakob Verbeek1 Michal Drozdzal1 ", "page_idx": 0}, {"type": "text", "text": "1FAIR at Meta 2Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LJK, France   \n3McGill University 4Mila, Quebec AI institute 5Canada CIFAR AI chair ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Large-scale training of latent diffusion models (LDMs) has enabled unprecedented quality in image generation. However, the key components of the best performing LDM training recipes are oftentimes not available to the research community, preventing apple-to-apple comparisons and hindering the validation of progress in the field. In this work, we perform an in-depth study of LDM training recipes focusing on the performance of models and their training efficiency. To ensure apple-to-apple comparisons, we re-implement five previously published models with their corresponding recipes. Through our study, we explore the effects of (i) the mechanisms used to condition the generative model on semantic information (e.g., text prompt) and control metadata (e.g., crop size, random flip flag, etc.) on the model performance, and (ii) the transfer of the representations learned on smaller and lower-resolution datasets to larger ones on the training efficiency and model performance. We then propose a novel conditioning mechanism that disentangles semantic and control metadata conditionings and sets a new state-of-the-art in classconditional generation on the ImageNet-1k dataset \u2013 with FID improvements of $7\\%$ on 256 and $8\\%$ on 512 resolutions \u2013 as well as text-to-image generation on the CC12M dataset \u2013 with FID improvements of $8\\%$ on 256 and $23\\%$ on 512 resolution. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Diffusion models have emerged as a powerful class of generative models and demonstrated unprecedented ability at generating high-quality and realistic images. Their superior performance is evident across a spectrum of applications, encompassing image [7, 14, 39, 41] and video synthesis [35], denoising [52], super-resolution [49] and layout-to-image synthesis [51]. The fundamental principle underpinning diffusion models is the iterative denoising of an initial sample from a trivial prior distribution, that progressively transforms it to a sample from the target distribution. The popularity of diffusion models can be attributed to several factors. First, they offer a simple yet effective approach for generative modeling, often outperforming traditional approaches such as Generative Adversarial Networks (GANs) [3, 16, 24, 25] and Variational Autoencoders (VAEs) [29, 48] in terms of visual fidelity and sample diversity. Second, diffusion models are generally more stable and less prone to mode collapse compared to GANs, which are notoriously difficult to stabilize without careful tuning of hyperparameters and training procedures [23, 30]. ", "page_idx": 0}, {"type": "image", "img_path": "B3rZZRALhk/tmp/c78bc157f2b71d4ec23e4737ee8f7f3f312679d2fa63ad8c11532e10d312efe8.jpg", "img_caption": ["Figure 1: Qualitative examples. Images generated using our model trained on CC12M at 512 resolution. "], "img_footnote": [], "page_idx": 1}, {"type": "text", "text": "Despite the success of diffusion models, training such models at scale remains computationally challenging, leading to a lack of insights on the most effective training strategies. Training recipes of large-scale models are often closed (e.g., DALL-E, Imagen, Midjourney), and only a few studies have analyzed training dynamics in detail [7, 14, 26, 27]. Moreover, evaluation often involves human studies which are easily biased and hard to replicate [17, 56]. Due to the high computational costs, the research community mostly focused on the finetuning of large text-to-image models for different downstream tasks [1, 4, 54] and efficient sampling techniques [34, 36, 45]. However, there has been less focus on ablating different mechanisms to condition on user inputs such as text prompts, and strategies to pre-train using datasets of smaller resolution and/or data size. The benefits of conditioning mechanisms are two-fold: allowing users to have better control over the content that is being generated, and unlocking training on augmented or lower quality data by for example conditioning on the original image size [39] and other metadata of the data augmentation. Improving pre-training strategies, on the other hand, can allow for big cuts in the training cost of diffusion models by significantly reducing the number of iterations necessary for convergence. ", "page_idx": 1}, {"type": "text", "text": "Our work aims to disambiguate some of these design choices, and provide a set of guidelines that enable the scaling of the training of diffusion models in an efficient and effective manner. Beyond the main architectural choices (e.g., Unet vs. ViT), we focus on two other important aspects for generative performance and efficiency of training. First, we enhance conditioning by decoupling different conditionings based on their type: control metadata conditioning (e.g., crop size, random flip, etc.), semantic-level conditioning based on class names or text-prompts. In this manner, we disentangle the contribution of each conditioning and avoid undesired interference among them. Second, we optimize the scaling strategy to larger dataset sizes and higher resolution by studying the influence of the initialization of the model with weights from models pre-trained on smaller datasets and resolutions. Here, we propose three improvements needed to seamlessly transition across resolutions: interpolation of the positional embeddings, scaling of the noise schedule, and using a more aggressive data augmentation strategy. ", "page_idx": 1}, {"type": "text", "text": "In our experiments we evaluate models at 256 and 512 resolution on ImageNet-1k and Conceptual Captions (CC12M), and also present results for ImageNet-22k at 256 resolution. We study the following five architectures: Unet/LDM-G4 [39], $D i T{\\cdot}X L2\\ w/L N$ [38], $m D T\\!\\cdot\\!\\nu2\\!-\\!X L/2\\;w/L N$ [15], PixArt- $\\cdot\\alpha$ -XL/2, and mmDiT-XL/2 (SD3) [14]. We find that among the studied base architectures, mmDiT-XL/2 (SD3) performs the best. Our improved conditioning approach further boosts the performance of the best model consistently across metrics, resolutions, and datasets. In particular, we improve the previous state-of-the-art DiT result of 3.04 FID on ImageNet-1k at 512 resolution to 2.76. For CC12M at 512 resolution, we improve FID of 11.24 to 8.64 when using our improved conditioning, while also obtaining a (small) improvement in CLIPscore from 26.01 to 26.17. See Fig. 1 for qualitative examples of our model trained on CC12M. ", "page_idx": 1}, {"type": "image", "img_path": "B3rZZRALhk/tmp/4742280e22af2c6396275c72699b79ab6377258bd64db57860ec01991598bc13.jpg", "img_caption": ["Figure 2: Influence of control conditions. Images generated using the same latent sample. Top: Model trained with constant weighting of the size conditioning as used in SDXL [39], introducing undesirable correlations between image content and size condition. Bottom: Model trained using our cosine weighting of lowlevel conditioning, disentangling the size condition from the image content. "], "img_footnote": [], "page_idx": 2}, {"type": "text", "text": "In summary, our contributions are the following: ", "page_idx": 2}, {"type": "text", "text": "\u2022 We present a systematic study of five different diffusion architectures, which we train from scratch using face-blurred ImageNet and CC12M datasets at 256 and 512 resolutions. \u2022 We introduce a conditioning mechanism that disentangles different control conditionings and semantic-level conditioning, improving generation and avoiding interference between conditions. \u2022 To transfer weights from pre-trained models we propose to interpolate positional embeddings, scale the noise schedule, and use stronger data augmentation, leading to improved performance. \u2022 We obtain state-of-the-art results at 256 and 512 resolution for class-conditional generation on ImageNet-1k and text-to-image generation and CC12M. ", "page_idx": 2}, {"type": "text", "text": "2 Conditioning and pre-training strategies for diffusion models ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we review and analyze the conditioning mechanisms and pre-training strategies used in prior work (see more detailed discussion of related work in App. A), and propose improved approaches based on the analysis. ", "page_idx": 2}, {"type": "text", "text": "2.1 Conditioning mechanisms ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "Background. To control the generated content, diffusion models are usually conditioned on class labels or text prompts. Adaptive layer norm is a lightweight solution to condition on class labels, used for both UNets [21, 39, 41] and DiT models [38]. Cross-attention is used to allow more fine-grained conditioning on textual prompts, where particular regions of the sampled image are affected only by part of the prompt, see e.g. [41]. More recently, another attention based conditioning was proposed in SD3 [14] within a transformer-based architecture that evolves both the visual and textual tokens across layers. It concatenates the image and text tokens across the sequence dimension, and then performs a self-attention operation on the combined sequence. Because of the difference between the two modalities, the keys and queries are normalized using RMSNorm [53], which stabilizes training. This enables complex interactions between the two modalities in one attention block instead of using both self-attention and cross-attention blocks. ", "page_idx": 2}, {"type": "text", "text": "Moreover, since generative models aim to learn the distribution of the training data, data quality is important when training generative models. Having low quality training samples, such as the ones that are poorly cropped or have unnatural aspect ratios, can result in low quality generations. Previous work tackles this problem by careful data curation and fine-tuning on high quality data, see e.g. [7, 9]. However, strictly filtering the training data may deprive the model from large portions of the available data [39], and collecting high-quality data is not trivial. Rather than treating them as nuisance factors, SDXL [39] proposes an alternative solution where a UNet-based model is conditioned on parameters corresponding to image size and crop parameters during training. In this manner, the model is aware of these parameters and can account for them during training, while also offering users control over these parameters during inference. These control conditions are transformed and additively combined with the timestep embedding before feeding them to the diffusion model. ", "page_idx": 2}, {"type": "text", "text": "Disentangled control conditions. Straightforward implementation of control conditions in DiT may cause interference between the time-step, class-level and control conditions if their corresponding embeddings are additively combined in the adaptive layer norm conditioning, e.g. causing changes in high-level content of the generated image when modifying its resolution, see Fig. 2. To disentangle the different conditions, we propose two modifications. First, we move the class embedding to be fed through the attention layers present in the DiT blocks. Second, to ensure that the control embedding does not overpower the timestep embedding when additively combined in the adaptive layer norm, we zero out the control embedding in early denoising steps, and gradually increase its strength. ", "page_idx": 2}, {"type": "text", "text": "", "page_idx": 3}, {"type": "text", "text": "Control conditions can be used for different types of data augmentations: (i) high-level augmentations $(\\phi_{h})$ that affect the image composition \u2013 e.g. flipping, cropping and aspect ratio \u2013, and (ii) low-level augmentations $(\\phi_{l})$ that affect low-level details \u2013 e.g. image resolution and color. Intuitively, high-level augmentations should impact the image formation process early on, while low-level augmentations should enter the process only once sufficient image details are present. We achieve this by scaling the contribution of the low-level augmentations, $\\phi_{l}$ , to the control embedding using a cosine schedule that downweights earlier contributions: ", "page_idx": 3}, {"type": "equation", "text": "$$\nc_{\\mathrm{emb}}(\\phi_{h},\\phi_{l},t)=E_{h}(\\phi_{h})+\\gamma_{c}(t)\\cdot E_{l}(\\phi_{l}),\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where the embedding functions $E_{h},E_{l}$ are made of sinusoidal embeddings followed by a 2-layer MLP with SiLU activation, and where $\\gamma_{c}$ is the cosine schedule illustrated in Fig. 3. ", "page_idx": 3}, {"type": "image", "img_path": "B3rZZRALhk/tmp/d353e51114ab493c4f18d2b3300a521cc8803e0bb9a315ffb538e3fad4c998b7.jpg", "img_caption": ["Figure 3: Weighting of low-level control conditions. The weight is zeroed out early on when image semantics are defined, and increased later when adding details. "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Improved text conditioning. Most commonly used text encoders, like CLIP [40], output a constant number of tokens $T$ that are fed to the denoising model (usually $T\\,=\\,77$ ). Consequently, when the prompt has less than $T$ tokens, the remaining positions are filled by zero-padding, but remain accessible via cross-attention to the denoising network. To make better use of the conditioning vector, we propose a noisy replicate padding mechanism where the padding tokens are replaced with copies of the text tokens, thereby pushing the subsequent cross-attention layers to attend to all the tokens in its inputs. As this might lead to redundant token embeddings, we improve the diversity of the feature representation across the sequence dimension, by perturbing the embeddings with additive Gaussian noise with a small variance $\\beta_{\\mathrm{txt}}$ . To ensure enough diversity in the token embeddings, we scale the additive noise by $\\sigma(\\phi_{\\mathrm{txt}})\\sqrt{m-1}$ , where $m$ is the number of token replications needed for padding, and $\\sigma(\\phi_{\\mathrm{txt}})$ is the per-channel standard deviation in the token embeddings. ", "page_idx": 3}, {"type": "text", "text": "Integrating classifier-free guidance. Classifier-free guidance (CFG) [20] allows for training conditional models by combining the output of the uncoditional generation with the output of the conditional generation. Formally, given a latent diffusion model trained to predict the noise $\\epsilon$ , CFG reads as: $\\epsilon^{\\lambda}\\stackrel{\\leftarrow}{=}\\lambda\\cdot\\epsilon_{s}+(1-\\lambda)\\stackrel{\\cdot}{\\cdot}\\epsilon_{\\emptyset}$ , where $\\epsilon_{\\emptyset}$ is the uncoditional noise prediction, $\\epsilon_{s}$ is the noise prediction conditioned on the semantic conditioning $s$ (e.g., text prompt), and $\\lambda$ is the hyper-parameter, known as guidance scale, which regulates the strength of the conditioning. Importantly, during training $\\lambda$ is set alternatively to 0 or 1, while at inference time it is arbitrarily changed in order to steer the generation to be more or less consistent with the conditioning. In our case, we propose the control conditioning to be an auxiliary guidance term, in order to separately regulate the strength of the conditioning on the control variables $c$ and semantic conditioning $s$ at inference time. In particular, we define the guided noise estimate as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\epsilon^{\\lambda,\\beta}=\\lambda\\left[\\beta\\cdot\\epsilon_{c,s}+(1-\\beta)\\cdot\\epsilon_{\\emptyset,s}\\right]+(1-\\lambda)\\cdot\\epsilon_{\\emptyset,\\emptyset},\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "where $\\beta$ sets the strength of the control guidance, and $\\lambda$ sets the strength of the semantic guidance. ", "page_idx": 3}, {"type": "text", "text": "2.2 On transferring models pre-trained on different datasets and resolutions ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Background. Transfer learning has been a pillar of the deep learning community, enabling generalization to different domains and the emergence of foundational models such as DINO [5, 10] and CLIP [40]. Large pre-trained text-to-image diffusion models have also been re-purposed for different tasks, including image compression [4] and spatially-guided image generation [1]. Here, we are interested in understanding to which extent pre-training on other datasets and resolutions can be leveraged to achieve a more efficient training of large text-to-image models. Indeed, training diffusion models directly to generate high resolution images is computationally demanding, therefore, it is common to either couple them with super-resolution models, see e.g. [44], or fine-tune them with high resolution data, see e.g. [7, 14, 39]. Although most models can directly operate at a higher resolution than the one used for training, fine-tuning is important to adjust the model to the different statistics of high-resolution images. In particular, we find that the different statistics influence the positional embedding of patches, the noise schedule, and the optimal guidance scale. Therefore, we focus on improving the transferability of these components. ", "page_idx": 3}, {"type": "text", "text": "Positional Embedding. Adapting to a higher resolution can be done in different ways. Interpolation scales the \u2013 most often learnable \u2013 embeddings according to the new resolution [2, 47]. Extrapolation simply replicates the embeddings of the original resolution to higher resolutions as illustrated in Fig. 4, resulting in a mismatch between the positional embeddings and the image features when switching to different resolutions. Most methods that use interpolation of learnable positional embeddings, e.g. [2, 47], adopt either bicubic or bilinear interpolation to avoid the norm reduction associated with the interpolation. In our case, we take advantage of the fact that our embeddings are sinusoidal and simply adjust the sampling grid to have constants limit under every resolution, see App. C. ", "page_idx": 4}, {"type": "text", "text": "Scaling the noise schedule. At higher resolution, the amount of noise necessary to mask objects at the same rate changes [14, 22]. If we observe a spatial patch at low resolution under a given uncertainty, upscaling the image by a factor $s$ creates s2 observations of this patch of the form yt(i $y_{t}^{(i)}=x_{t}+\\sigma_{t}\\epsilon^{(i)}-$ assuming the value of the patch is constant across the patch. This increase in the number of observations reduces the uncertainty around the value of that token, resulting in a higher signal-to-noise (SNR) ratio than expected. This issue gets further accentuated when the scheduler does not reach a terminal state with pure noise during training, i.e., a zero SNR [32], as the mismatch between the non-zero SNR seen during training and the purely Gaussian initial state of the sampling phase becomes significant. To resolve this, we scale the noise scheduler in order to recover the same uncertainty for the same timestep. ", "page_idx": 4}, {"type": "image", "img_path": "B3rZZRALhk/tmp/b4be5c39ef105d78c6b744094aea336534eea3ccdcd6bb1b2b932b3f9646042d.jpg", "img_caption": ["Figure 4: Interpolation and extrapolation of positional embeddings. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "Proposition 1. When going from a scale of s to a scale $s^{\\prime}$ , we update the $\\beta$ scheduler according to the following rule ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\bar{\\alpha}_{t^{\\prime}}=\\frac{s^{2}\\cdot\\bar{\\alpha}_{t}}{s^{\\prime2}+\\bar{\\alpha}_{t}\\cdot\\left(s^{2}-s^{\\prime2}\\right)}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "This increases the noise amplitude during intermediate denoising steps as illustrated in Fig. A1. The final equation obtained is similar to the one obtained in [14] with the accompanying change of variable $\\begin{array}{r}{t=\\frac{\\sigma^{2}}{1+\\sigma^{2}}}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Pre-training cropping strategies. When pre-training and finetuning at different resolutions, we can either first crop and then resize the crops according to the training resolution, or directly take differently sized crops from the training images. Using a different resizing during pre-training and finetuning may introduce some distribution shift, while using crops of different sizes may be detrimental to low-resolution training as the model will learn the distribution of smaller crops rather than full images, see Fig. 5. We experimentally investigate which strategy is more effective for low-resolution pretraining of high-resolution models. ", "page_idx": 4}, {"type": "image", "img_path": "B3rZZRALhk/tmp/d8e7b3a5198967c114854c14d745f8ac312b06ee05cef0aac9c8ff5c05359b34.jpg", "img_caption": ["Figure 5: Low-resolution pretraining. Crop size used for pretraining impacts finetuning. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Guidance scale. We discover that the optimal guidance scale for both FID and CLIPScore varies with the resolution of images. In App. D, we present a proof revealing that under certain conditions, the optimal guidance scale adheres to a scaling law with respect to the resolution, as ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\lambda^{\\prime}(s)=1+s\\cdot(\\lambda-1).\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "3 Experimental evaluation ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "3.1 Experimental setup ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "Datasets. In our study, we train models on three datasets. To train class-conditional models, we use ImageNet- $1k$ [11], which has 1.3M images spanning 1,000 classes, as well as ImageNet- $22k$ [43], which contains 14.2M images spanning 21,841 classes. Additionally, we train text-to-image models using Conceptual 12M (CC12M) [6], which contains 12M images with accompanying manually generated textual descriptions. We pre-process both datasets by blurring all faces. Differently from [7], we use the original captions for the CC12M dataset. ", "page_idx": 4}, {"type": "text", "text": "Evaluation. For image quality, we evaluate our models using the common FID [19] metric. We follow the standard evaluation protocol on ImageNet to have a fair comparison with the relevant literature [3, 15, 38, 41]. Specifically, we compute the FID between the full training set and $50\\mathrm{k}$ synthetic samples generated using 250 DDIM sampling steps. For image-text alignment, we compute the CLIP [40] score similarly to [7, 14]. We measure conditional diversity, either using class-level or text prompt conditioning, using LPIPS [55]. LPIPS is measured pairwise and averaged among ten generations obtained with the same random seed, prompt, and initial noise, but different size conditioning (we exclude sizes smaller than the target resolution); then we report the average over 10k prompts. In addition to ImageNet and CC12M evaluations, we provide FID and CLIPScore on the COCO [33] validation set, which contains approximately $40\\mathrm{k}$ images with associated captions. For COCO evaluation [33], we follow the same setting as [14] for computing the CLIP score, using 25 sampling steps and a guidance scale of 5.0. ", "page_idx": 4}, {"type": "table", "img_path": "B3rZZRALhk/tmp/af619226e38c5b0c05697868f777d1e8565b5b60a1d28138974681db830ebc5c.jpg", "table_caption": ["Table 1: Comparison between different model architectures. We compare results reported in the literature (top, reporting available numbers) with our reimplementations of existing architectures (middle), and to our best results obtained using architectural refinements and improved training. For 512 resolution, we trained models by fine-tuning models pre-trained at 256 resolution. In each column, we bold the best results among those in the first two blocks, and also those in the last row when they are equivalent or superior. \u2018\u2014\u2019 denotes that numbers are unavailable in the original papers, or architectures are incompatible with text-to-image generation in our experiments. $\\mathbf{\\nabla}x$ indicates diverged runs. \u2018\\*\u2019 is used for Esser et al. [14] pre-trained on CC12M to denote that FID is computed differently and some details about their evaluation are unclear. "], "table_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "text", "text": "Training. To train our models we use the Adam [28] optimizer, with a learning rate of $10^{-4}$ and $\\beta_{1},\\beta_{2}=0.9$ , 0.999. When training at $256\\!\\times\\!256$ resolution, we use a batch size of 2, 048 images, a constant learning rate of $\\mathrm{10\\times10^{-4}}$ , train our models on two machines with eight A100 GPUs each. In preliminary experiments with the DiT architecture we found that the FID metric on ImageNet-1k at 256 resolution consistently improved with larger batches and learning rate, but that increasing the learning rate by another factor of two led to diverging runs. We report these results in supplementary. When training models at $512\\!\\times\\!512$ resolution, we use the same approach but with a batch size of 384 distributed over 16 A100 GPUs. We train our ImageNet-1k models for $500\\mathrm{k}$ to 1M iterations and for $300\\mathrm{k}$ to $500\\mathrm{k}$ iterations for CC12M. ", "page_idx": 5}, {"type": "text", "text": "Model architectures. We train different diffusion architectures under the same setting to provide a fair comparison between model architectures. Specifically, we re-implement a UNet-based architecture following Stable Diffusion XL (SDXL) [39] 1 and several transformer-based architectures: vanilla DiT [38], masked DiT (mDiT-v2) [15], PixArt DiT (PixArt- $\\alpha$ ) [7], and multimodal DiT (mmDiT) as in Stable Diffusion 3 [14]. For vanilla DiT, which only supports class-conditional generation, we explore two variants one incorporating the class conditioning within LayerNorm and another one within the attention layer. Also, for text-conditioned models, we use the text encoder and tokenizer of CLIP (ViT-L/14) [40] having a maximum sequence length of $T=77$ . The final models share similar number parameters, e.g. for DiTs we inspect the XL/2 variant [38], for UNet (SDXL) we adopt similar size to the original LDM [41]. Similar to [14], we found the training of DiT with ", "page_idx": 5}, {"type": "text", "text": "Table 2: Control conditioning. We study different facets of control conditioning and their impact on the model performance. (a-b) We report $\\mathrm{FID}_{\\mathrm{train}}$ on ImageNet- $1\\mathrm{k}@256$ using 250 sampling steps. 120k training iterations. ", "page_idx": 6}, {"type": "table", "img_path": "B3rZZRALhk/tmp/cc7cd1c2222933a2718c12945208876a24cdf5bdabb6e50359e292f16b860f8e.jpg", "table_caption": ["(a) Influence of the parametrization. LPIPS computation considers all resolutions [64, 128, 256, 512, 1024] while LPIPS/HR exclude 64 and 128 "], "table_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "B3rZZRALhk/tmp/e1d39ea6ead6be6821d6df532ac4c7817ef2ee769056e91194e165035a95b7ee.jpg", "table_caption": ["(b) Size conditioning effect on FID at inference. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "cross-attention to be unstable and had to resort to using RMSNorm [53] to normalize the key and query in the attention layers. We detail the models sizes and computational footprints in Tab. A1. ", "page_idx": 6}, {"type": "text", "text": "3.2 Evaluation of model architectures and comparison with the state of the art ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In Tab. 1, we report results for models with different architectures trained at both 256 and 512 resolutions for ImageNet and CC12M, and compare our results (2nd block of rows) with those reported in the literature, where available (1st block of rows). Where direct comparison is possible, we notice that our re-implementation outperforms the one of existing references. Overall, we found the mmDiT [14] architecture to perform best or second best in all settings compared to other alternatives. For this reason, we apply our conditioning improvements on top of this architecture (last row of the table), boosting the results as measured with FID and CLIPScore in all settings. Below, we analyse the improvements due to our conditioning mechanisms and pre-training strategies. ", "page_idx": 6}, {"type": "text", "text": "3.3 Control conditioning ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "Scheduling rate of control conditioning. In Tab. 2a we consider the effect of controlling the conditioning on low-level augmentations via a cosine schedule for different decay rates $\\alpha$ . We compare to baselines (first two rows) with constant weighting (as in SDXL [39]) and without control conditioning. We find that our cosine weighting schedule significantly reduces the dependence between size control and image semantics as it drastically improves the instance specific LPIPS (0.33 vs. 0.04) in comparison to uniform weighting. In terms of FID, we observe a small gap with the baseline $(3.04\\,\\nu s.\\,3.08)$ , which increases (3.80 vs. 5.04) when computing FID by randomly sampling the size conditioning in the range [512,1024], see Tab. 2b. Finally, the improved disentangling between semantics and low-level conditioning is clearly visible in the qualitative samples in Fig. 2. ", "page_idx": 6}, {"type": "text", "text": "Crop and random-filp control conditioning. A potential issue of horizontal flip data augmentations is that it can create misalignment between the text prompt and corresponding image. For example the prompt $^{\\prime\\prime}A$ teddy bear holding a baseball bat in their right arm\" will no longer be accurate when an image is flipped \u2013 showing a teddy bear holding the bat in their left arm. Similarly, cropping images can remove details mentioned in the corresponding caption. In Tab. 2c we evaluate models trained on $\\mathrm{CC}12\\!\\mathrm{M@256}$ with and without horizontal flip conditioning, and find that adding this conditioning leads to slight improvements in both FID and CLIP as compared to using only crop conditioing. We depict qualitative comparison in Fig. 6, where we observe that flip conditioning improves prompt-layout consistency. ", "page_idx": 6}, {"type": "text", "text": "Inference-time control conditioning of image size. High-level augmentations $(\\phi_{h})$ may affect the image semantics. As a result they influence the learned distribution and modify the generation diversity. For example, aspect ratio conditioning can harm the quality of generated images, when images of a particular class or text prompt are unlikely to appear with a given aspect ratio. In Tab. 2b we compare of different image size conditionings for inference. We find that conditioning on the same size distribution as encountered during the training of the model yields a significant boost in FID as compared to generating all images with constant size conditioning or using uniformly randomly sampled sizes. Note that in all cases images are generated at 256 resolution. ", "page_idx": 6}, {"type": "image", "img_path": "B3rZZRALhk/tmp/98c3bb4e0ebb5bff350329178752204bcc31b75281e8cfd1302dec207bc08e10.jpg", "img_caption": ["Figure 7: Guidance scales. Left $^+$ center: The optimal guidance scale varies with the image resolution. Right: Decoupling the control guidance improves FID, the best reported performance is obtained with $\\beta=1.375$ . "], "img_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "Control conditioning and guidance. To understand how control condition impacts the generation process, we investigate the influence of control guidance $\\beta$ (introduced in Sec. 2.1 ) on FID and report the results in Fig. 7. We find that a higher control guidance scale results in improved FID scores. However, note that this improvement comes at the cost of compute due to the additional control term \u03f5c,s. ", "page_idx": 7}, {"type": "text", "text": "Replication text padding. We compare our noisy replication padding to the baseline zero-padding in Tab. 3. We observe that using a replication padding improves both FID and CLIP score, and that adding scaled perturbations further improves the results \u2013 0.35 point improvement in CLIP score and 0.4 point improvement in FID. ", "page_idx": 7}, {"type": "text", "text": "3.4 Transferring weights between datasets and resolutions ", "text_level": 1, "page_idx": 7}, {"type": "table", "img_path": "B3rZZRALhk/tmp/020fd8dcdc5461dcf9f012ba59b51f51b6fc84d75d06bf58a9a8814e2092dbdc.jpg", "table_caption": ["Table 3: Text padding. Our noisy replication embedding vs. baseline zero-padding. Models trained on $\\mathrm{CC}12\\mathrm{M@256}$ . "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Dataset shift. We evaluate the effect of pre-training on ImageNet-1k (at 256 resolution) when training the models on CC12M or ImageNet-22k (at 512 resolution) by the time needed to achieve the same performance as a model trained from scratch. In Tab. 4a, when comparing models trained from scratch to ImageNet-1k pre-trained models $\\mathrm{[600k}$ iterations) we observe two benefits: improved training convergence and performance boosts. For CC12M, we find that after only $100\\mathrm{k}$ iterations, both FID and CLIP scores improve over the baseline model trained with more than six times the ", "page_idx": 7}, {"type": "text", "text": "Table 4: Effect of pre-training across datasets and resolutions. Number of (pre-)training iterations given in thousands (k) per row. Relative improvements in FID and CLIP score given as percentage in parenthesis. ", "page_idx": 7}, {"type": "table", "img_path": "B3rZZRALhk/tmp/afbafd3585ec315bbe3729d427aa8f03022be1ea726e75132d03113317ac9a1d.jpg", "table_caption": ["(a) Pre-training models at 256 resolution on ImageNet-1k. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "B3rZZRALhk/tmp/9893864117c8a14d030c6462f7ff963ed1d0b00f71248ba27e4a069ac15a5782.jpg", "table_caption": ["(b) Pre-training 512 resolution models on ImageNet- $.22k$ before finetuning on CC12M. "], "table_footnote": [], "page_idx": 7}, {"type": "table", "img_path": "B3rZZRALhk/tmp/0b60c5c1db5b9ca28a09633ae8ba6037e51dbe86107e922e65f4b285d7609696.jpg", "table_caption": ["(c) Influence of pre-training at 256 resolution for 512 resolution models (ImageNet-1k). "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "Figure 8: Resolution shift. Experiments are conducted on ImageNet-1k at 512 resolution, FID is reported using 50 DDIM steps with respect to the ImageNet-1k validation set. ", "page_idx": 8}, {"type": "image", "img_path": "B3rZZRALhk/tmp/c1dbb02ef70e3be1baf49b3034623da5edb9576fb08293c374a7290f558a59a9.jpg", "img_caption": ["(a) Influence of positional embedding resampling on convergence. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "B3rZZRALhk/tmp/404d2760acca8284b348566a1ae494f719652bff98510584e5f2515a8f48e777.jpg", "img_caption": ["(b) Influence of noise schedule rescaling for training. "], "img_footnote": [], "page_idx": 8}, {"type": "image", "img_path": "B3rZZRALhk/tmp/5945ad8528faab2e85e1158be15fe547929ba250dcb06b0ec5f60d3b513b7eb5.jpg", "img_caption": ["(c) Influence of pretraining scale on convergence. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "amount of training iterations. For ImageNet-22k, which is closer in distribution to ImageNet-1k than CC12M, the gains are even more significant, the finetuned model achieves an FID lower by 0.5 point after only 80k training iterations. In Tab. 4b, we study the relative importance of pre-training vs finetuning when the datasets have dissimilar distributions but similar sample sizes. We fix a training budget in terms of number of training iterations $N$ , we first train our model on ImageNet- $.22\\mathbf{k}$ for $K$ iterations before continuing the training on CC12M for the remaining $N-K$ iterations. We see that the model pretrained for $200\\mathrm{k}$ iterations and finetuned for $150\\mathrm{k}$ performs better than the one spending the bulk of the training during pretraining phase. This validates the importance of domain specific training and demonstrates that the bulk of the gains from the pretrained checkpoint come from the representation learned during earlier stages. ", "page_idx": 8}, {"type": "text", "text": "Resolution change. We compare the performance boost obtained from training from scratch at 512 resolution vs. resuming from a 256-resolution trained model. According to our results in Tab. 4c, pretraining on low resolution significantly boosts the performance at higher resolutions, both for UNet and mmDiT, we find that higher resolution finetuning for short periods of time outperforms high resolution training from scratch by a large margin $(\\approx25\\%)$ ). These performance gains might in part be due to the increased batch size when pre-training the 256 resolution model, which allows the model to \u201csee\u201d more images as compared to training from-scratch at 512 resolution. ", "page_idx": 8}, {"type": "text", "text": "Positional Embedding. In Fig. 8a, we compare the influence of the adjustment mechanism for the positional embedding. We find that our grid resampling approach outperforms the default extrapolation approach, resulting in 0.2 point difference in FID after $130\\mathrm{k}$ training iterations. ", "page_idx": 8}, {"type": "text", "text": "Scaling the noise schedule. We conducted an evaluation to ascertain the influence of the noise schedule by refining our mmDiT model post its low resolution training and report the results in Fig. 8b. Remarkably, the application of the rectified schedule, for 40k iterations, resulted in an improvement of 0.7 FID points demonstrating its efficacy at higher resolutions. ", "page_idx": 8}, {"type": "text", "text": "Pre-training cropping strategies. During pretraining, the model sees objects that are smaller than what it sees during fine tuning, see Fig. 5. We aim to reduce this discrepancy by adopting more agressive cropping during the pretraining phase. We experiment with three cropping ratios for training: $0.9-1$ (global), $0.4-0.6\\$ (local), $0.4-1$ (mix). We report the results in Fig. 8c. On ImageNet1K $@256$ , the pretraining FID scores are 2.36, 245.55 and 2.21 for the local, global and mixed strategies respectively. During training at 512 resolution, we observe that the global and mix cropping strategies both outperform the local strategy. However, as reported in Fig. 8c, the local strategy provides benefits at higher resolutions. Overall, training with the global strategy performs the best at 256 resolution but lags behind for higher resolution adaptation. While local cropping underperforms at lower resolutions, because it does not see any images in their totality, it outperforms the other methods at higher resolutions \u2013 an improvement of almost $0.2\\,\\mathrm{FID}$ points is consistent after the first $50k$ training steps at higher resolution. ", "page_idx": 8}, {"type": "text", "text": "4 Conclusion ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we explored various approaches to enhance the conditional training of diffusion models. Our empirical findings revealed significant improvements in the quality and control over generated images when incorporating different coditioning mechanisms. Moreover, we conducted a comprehensive study on the transferability of these models across diverse datasets and resolutions. Our results demonstrated that leveraging pretrained representations is a powerful tool to improve the model performance while also cutting down the training costs. Furthermore, we provided valuable insights into efficiently scaling up the training process for these models without compromising performance. By adapting the schedulers and positional embeddings when scaling up the resolution, we achieved substantial reductions in training time while boosting the quality of the generated images. Additional experiments unveil the expected gains from different transfer strategies, making it easier for researchers to explore new ideas and applications in this domain. In Appendix B we discuss societal impact and limitations of our work. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1] Omri Avrahami, Thomas Hayes, Oran Gafni, Sonal Gupta, Yaniv Taigman, Devi Parikh, Dani Lischinski, Ohad Fried, and Xi Yin. Spatext: Spatio-textual representation for controllable image generation. In CVPR, 2023. [2] Lucas Beyer, Pavel Izmailov, Alexander Kolesnikov, Mathilde Caron, Simon Kornblith, Xiaohua Zhai, Matthias Minderer, Michael Tschannen, Ibrahim Alabdulmohsin, and Filip Pavetic. FlexiViT: One model for all patch sizes. In CVPR, 2023.   \n[3] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale GAN training for high fidelity natural image synthesis. In ICLR, 2019.   \n[4] Marl\u00e8ne Careil, Matthew J. Muckley, Jakob Verbeek, and St\u00e9phane Lathuili\u00e8re. Towards image compression with perfect realism at ultra-low bitrates. In ICLR, 2024.   \n[5] Mathilde Caron, Hugo Touvron, Ishan Misra, Herv\u00e9 J\u00e9gou, Julien Mairal, Piotr Bojanowski, and Armand Joulin. Emerging properties in self-supervised vision transformers. In ICCV, 2021. [6] Soravit Changpinyo, Piyush Sharma, Nan Ding, and Radu Soricut. Conceptual 12M: Pushing web-scale image-text pre-training to recognize long-tail visual concepts. In CVPR, 2021. [7] Junsong Chen, Jincheng Yu, Chongjian Ge, Lewei Yao, Enze Xie, Yue Wu, Zhongdao Wang, James Kwok, Ping Luo, Huchuan Lu, and Zhenguo Li. PixArt- $\\alpha$ : Fast training of diffusion transformer for photorealistic text-to-image synthesis. In ICLR, 2024. [8] Jaemin Cho, Abhay Zala, and Mohit Bansal. DALL-Eval: Probing the reasoning skills and social biases of text-to-image generation models. In ICCV, 2023.   \n[9] Xiaoliang Dai, Ji Hou, Chih-Yao Ma, Sam Tsai, Jialiang Wang, Rui Wang, Peizhao Zhang, Simon Vandenhende, Xiaofang Wang, Abhimanyu Dubey, Matthew Yu, Abhishek Kadian, Filip Radenovic, Dhruv Mahajan, Kunpeng Li, Yue Zhao, Vladan Petrovic, Mitesh Kumar Singh, Simran Motwani, Yi Wen, Yiwen Song, Roshan Sumbaly, Vignesh Ramanathan, Zijian He, Peter Vajda, and Devi Parikh. Emu: Enhancing image generation models using photogenic needles in a haystack. arXiv preprint, 2309.15807, 2023.   \n[10] Timoth\u00e9e Darcet, Maxime Oquab, Julien Mairal, and Piotr Bojanowski. Vision transformers need registers. In ICLR, 2024.   \n[11] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In ICCV, 2009.   \n[12] Prafulla Dhariwal and Alex Nichol. Diffusion models beat GANs on image synthesis. In NeurIPS, 2021.   \n[13] Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth $16\\!\\times\\!16$ words: Transformers for image recognition at scale. In ICLR, 2021.   \n[14] Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas M\u00fcller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek, and Robin Rombach. Scaling rectified flow transformers for high-resolution image synthesis. In ICML, 2024.   \n[15] Shanghua Gao, Pan Zhou, Ming-Ming Cheng, and Shuicheng Yan. Masked diffusion transformer is a strong image synthesizer. In ICCV, 2023.   \n[16] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In NeurIPS, 2014.   \n[17] Melissa Hall, Samuel J. Bell, Candace Ross, Adina Williams, Michal Drozdzal, and Adriana Romero Soriano. Towards geographic inclusion in the evaluation of text-to-image models. In FAccT, 2024.   \n[18] Melissa Hall, Candace Ross, Adina Williams, Nicolas Carion, Michal Drozdzal, and Adriana RomeroSoriano. DIG in: Evaluating disparities in image generations with indicators for geographic diversity. TMLR, 2024.   \n[19] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained by a two time-scale update rule converge to a local Nash equilibrium. In NeurIPS, 2017.   \n[20] Jonathan Ho and Tim Salimans. Classifier-free diffusion guidance. In NeurIPS Workshop on Deep Generative Models and Downstream Applications, 2021.   \n[21] Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In NeurIPS, 2020.   \n[22] Emiel Hoogeboom, Jonathan Heek, and Tim Salimans. Simple diffusion: End-to-end diffusion for high resolution images. In ICML, 2023.   \n[23] Minguk Kang, Jun-Yan Zhu, Richard Zhang, Jaesik Park, Eli Shechtman, Sylvain Paris, and Taesung Park. Scaling up GANs for text-to-image synthesis. In CVPR, 2023.   \n[24] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of StyleGAN. In CVPR, 2020.   \n[25] Tero Karras, Miika Aittala, Samuli Laine, Erik H\u00e4rk\u00f6nen, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Alias-free generative adversarial networks. In NeurIPS, 2021.   \n[26] Tero Karras, Miika Aittala, Timo Aila, and Samuli Laine. Elucidating the design space of diffusion-based generative models. In NeurIPS, 2022.   \n[27] Tero Karras, Janne Hellsten, Miika Aittala, Timo Aila, Jaakko Lehtinen, and Samuli Laine. Analyzing and improving the training dynamics of diffusion models. In CVPR, 2024.   \n[28] Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.   \n[29] Diederik P. Kingma and Max Welling. Auto-encoding variational Bayes. In ICLR, 2014.   \n[30] Kwonjoon Lee, Huiwen Chang, Lu Jiang, Han Zhang, Zhuowen Tu, and Ce Liu. ViTGAN: Training GANs with vision transformers. In ICLR, 2022.   \n[31] Mark Levy, Bruno Di Giorgi, Floris Weers, Angelos Katharopoulos, and Tom Nickson. Controllable music production with diffusion models and guidance gradients. arXiv preprint, 2311.00613, 2023.   \n[32] Shanchuan Lin, Bingchen Liu, Jiashi Li, and Xiao Yang. Common diffusion noise schedules and sample steps are flawed. In WACV, 2024.   \n[33] T.-Y. Lin, M. Maire, S. Belongie, L. Bourdev, R. Girshick, J. Hays, P. Perona, D. Ramanan, P. Doll\u00e1r, and C. Zitnick. Microsoft COCO: common objects in context. In ECCV, 2014.   \n[34] Yaron Lipman, Ricky T. Q. Chen, Heli Ben-Hamu, Maximilian Nickel, and Matthew Le. Flow matching for generative modeling. In ICLR, 2023.   \n[35] Yixin Liu, Kai Zhang, Yuan Li, Zhiling Yan, Chujie Gao, Ruoxi Chen, Zhengqing Yuan, Yue Huang, Hanchi Sun, Jianfeng Gao, Lifang He, and Lichao Sun. Sora: A review on background, technology, limitations, and opportunities of large vision models. arXiv preprint, 2402.17177, 2024.   \n[36] Cheng Lu, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, and Jun Zhu. DPM-Solver: A fast ODE solver for diffusion probabilistic model sampling in around 10 steps. In NeurIPS, 2022.   \n[37] Alexandra Sasha Luccioni, Christopher Akiki, Margaret Mitchell, and Yacine Jernite. Stable bias: Analyzing societal representations in diffusion models. In NeurIPS, 2023.   \n[38] William Peebles and Saining Xie. Scalable diffusion models with transformers. In ICCV, 2023.   \n[39] Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas M\u00fcller, Joe Penna, and Robin Rombach. SDXL: Improving latent diffusion models for high-resolution image synthesis. In ICLR, 2024.   \n[40] Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning transferable visual models from natural language supervision. In ICML, 2021.   \n[41] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image synthesis with latent diffusion models. In CVPR, 2022.   \n[42] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-Net: Convolutional networks for biomedical image segmentation. In Medical Image Computing and Computer-Assisted Intervention, 2015.   \n[43] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 115(3):211\u2013252, 2015.   \n[44] Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S. Sara Mahdavi, Rapha Gontijo Lopes, Tim Salimans, Jonathan Ho, David J Fleet, and Mohammad Norouzi. Photorealistic text-to-image diffusion models with deep language understanding. In NeurIPS, 2022.   \n[45] Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In ICLR, 2021.   \n[46] Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole. Score-based generative modeling through stochastic differential equations. In ICLR, 2021.   \n[47] Hugo Touvron, Matthieu Cord, Matthijs Douze, Francisco Massa, Alexandre Sablayrolles, and Herv\u00e9 J\u00e9gou. Training data-efficient image transformers & distillation through attention. In ICML, 2021.   \n[48] A. Vahdat and J. Kautz. NVAE: A deep hierarchical variational autoencoder. In NeurIPS, 2020.   \n[49] Chanyue Wu, Dong Wang, Yunpeng Bai, Hanyu Mao, Ying Li, and Qiang Shen. HSR-Diff: Hyperspectral image super-resolution via conditional diffusion models. In ICCV, 2023.   \n[50] Tong Wu, Zhihao Fan, Xiao Liu, Yeyun Gong, Yelong Shen, Jian Jiao, Hai-Tao Zheng, Juntao Li, Zhongyu Wei, Jian Guo, Nan Duan, and Weizhu Chen. AR-Diffusion: Auto-regressive diffusion model for text generation. In NeurIPS, 2023.   \n[51] Han Xue, Zhiwu Huang, Qianru Sun, Li Song, and Wenjun Zhang. Freestyle layout-to-image synthesis. In CVPR, 2023.   \n[52] Cheng Yang, Lijing Liang, and Zhixun Su. Real-world denoising via diffusion model. arXiv preprint, 2305.04457, 2023.   \n[53] Biao Zhang and Rico Sennrich. Root Mean Square Layer Normalization. In NeurIPS, 2019.   \n[54] Lvmin Zhang, Anyi Rao, and Maneesh Agrawala. Adding conditional control to text-to-image diffusion models. In ICCV, 2023.   \n[55] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual metric. In CVPR, 2018.   \n[56] Sharon Zhou, Mitchell L. Gordon, Ranjay Krishna, Austin Narcomey, Durim Morina, and Michael S. Bernstein. HYPE: a benchmark for Human eYe Perceptual Evaluation of generative models. In NeurIPS, 2019. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 13}, {"type": "image", "img_path": "B3rZZRALhk/tmp/18dbf18cc11b3bb0a43efc89c91993f021c30086892067c93d8ea372dc0c2892.jpg", "img_caption": [], "img_footnote": [], "page_idx": 13}, {"type": "text", "text": "A Related work ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Diffusion Models. Diffusion models have gained significant attention in recent years due to their ability to model complex stochastic processes and generate high-quality samples. These models have been successfully applied to a wide range of applications, including image generation [7, 21, 41], video generation [35], music generation [31], and text generation [50]. One of the earliest diffusion models was proposed in [21], which introduced denoising diffusion probabilistic models (DDPMs) for image generation. This work demonstrated that DDPMs can generate high-quality images that competitive with state-of-the-art generative models such as GANs [16]. Following this work, several variants of DDPMs were proposed, including score-based diffusion models [46], conditional diffusion models [12], and implicit diffusion models [45]. Overall, diffusion models have shown promising results in various applications due to their ability to model complex stochastic processes and generate high-quality samples [7, 14, 39, 41]. Despite their effectiveness, diffusion models also have some limitations, including the need for a large amount of training data and the required computational resources. Some works [26, 27] have studied and analysed the training dynamics of diffusion models, but most of this work considers the pixel-based models and small-scale settings with limited image resolution and dataset size. In our work we focus on the more scalable class of latent diffusion models [41], and consider image resolutions up to 512 pixels, and 14M training images. ", "page_idx": 13}, {"type": "text", "text": "Model architectures. Early work on diffusion models adopted the widely popular UNet arcchitecture [39, 41]. The UNet is an encoder-decoder architecture where the encoder is made of residual blocks that produce progressively smaller feature maps, and the decoder progressively upsamples the feature maps and refines them using skip connections with the encoder [42]. For diffusion, UNets are also equipped with cross attention blocks for cross-modality conditioning and adaptive layer normalization that conditions the outputs of the model on the timestep [41]. More recently, vision transformer architectures [13] were shown to scale more favourably than UNets for diffusion models with the DiT architecture [38]. Numerous improvements have been proposed to the DiT in order to have more efficient and stable training, see e.g. [7, 14, 15]. In order to reduce the computational complexity of the model and train at larger scales, windowed attention has been proposed [7]. Latent masking during training has been proposed to encourage better semantic understanding of inputs in [15]. Others improved the conditioning mechanism by evolving the text tokens through the layers of the transformer and replacing the usual cross-attention used for text conditioning with a variant that concatenates the tokens from both the image and text modalities [14]. ", "page_idx": 13}, {"type": "text", "text": "Large scale diffusion training. Latent diffusion models [41] unlocked training diffusion models at higher resolutions and from more data by learning the diffusion model in the reduced latent space of a (pre-trained) image autoencoder rather than directly in the image pixel space. Follow-up work has proposed improved scaling of the architecture and data [39]. More recently, attention-based architectures [7, 14, 15] have been adapted for large scale training, showing even more improvements by scaling the model size further and achieving state-of-the-art performance on datasets such as ImageNet-1k. Efficiency gains were also obtained by [7] by transferring ImageNet pre-trained models to larger datasets. ", "page_idx": 13}, {"type": "image", "img_path": "B3rZZRALhk/tmp/879875afac41b042a031e5f2aed5ed69cc232efe28a3d42fb89a5642da6dea62.jpg", "img_caption": ["Figure A1: Noise schedule scaling law. At higher resolutions, keeping the same uncertainty means spending more time at higher noise levels, thereby counteracting the uncertainty reduction from the increase in the observations for the same patch. "], "img_footnote": [], "page_idx": 14}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "B Societal impact and limitations ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Our research investigates the training of generative image models, which are widely employed to generate content for creative or education and accessibility purposes. However, together with these beneficial applications, these models are usually associated with privacy concerns (e.g., deepfake generation) and misinformation spread. In our paper, we deepen the understanding of the training dynamics of these modes, providing the community with additional knowledge that can be leveraged for safety mitigation. Moreover, we promote a safe and transparent/reproducible research by employing only publicly available data, which we further mitigate by blurring human faces. ", "page_idx": 14}, {"type": "text", "text": "Our work is mostly focused on training dynamics, and to facilitate reproducibility, we used publicly available datasets and benchmarks, without applying any data filtering. We chose datasets relying on the filtering/mitigation done by their respective original authors. In general, before releasing models like the ones described in our paper to the public, we recommend conducting proper evaluation of models trained using our method for bias, fairness and discrimination risks. For example, geographical disparities due to stereotypical generations could be revealed with methods described by Hall et al. [18], and social biases regarding gender and ethnicity could be captured with methods from Luccioni et al. [37] and Cho et al. [8]. ", "page_idx": 14}, {"type": "text", "text": "While our study provides valuable insights into control conditioning and the effectiveness of representation transfer in diffusion models, there are several limitations that should be acknowledged. (i) There are cases where these improvements can be less pronounced. For example, noisy replicates for the text embeddings can become less pertinent if the model is trained exclusively with long prompts. (ii) While low resolution pretraining with local crops on ImageNet resulted in better FID at 512 resolution (see Table 5c), it might not be necessary if pretraining on much larger datasets (e.g. ${>}100\\mathrm{M}$ samples, which we did not experiment in this work). Similarly, flip conditioning is only pertinent if the training dataset contains position sensitive information (left vs. right in captions, or rendered text in images), otherwise this condition will not provide any useful signal. (iii) We did not investigate the impact of data quality on training dynamics, which could have implications for the generalizability of our findings to datasets with varying levels of quality and diversity. (iv) As our analysis primarily focused on control conditioning, other forms of conditioning such as timestep and prompt conditioning were not explored in as much depth. Further research is needed to determine the extent to which these conditionings interact with control conditioning and how that impacts the quality of the models. (v) Our work did not include studies on other parts that are involved in the training and sampling of diffusion models, such as the different sampling mechanisms and training paradigms. This could potentially yield additional gains in performance and uncover new insights about the state-space of diffusion models. ", "page_idx": 14}, {"type": "text", "text": "C Implementation details ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Noise schedule scaling. In Fig. A1 we depict the rescaling of the noise for higher resolutions, following Eq. (3). ", "page_idx": 14}, {"type": "table", "img_path": "B3rZZRALhk/tmp/7650d648cc1116e30b31ebeb3af3a5b989cbacbb537618deb9a195d457fcdc94.jpg", "table_caption": ["Table A1: Computational comparison between different models. We compute FLOPs for different resolutions and the parameter count. FLOPS are computed with a batch size of 1. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "Positional embedding rescaling. As illustrated in App. C, rescaling the positional embedding can be integrated in two simple lines of code by changing the grid sampling to be based on reducing the stepsize in the grid instead of extending its limits. ", "page_idx": 15}, {"type": "image", "img_path": "B3rZZRALhk/tmp/73cc5acd6739ec4fd389ea61ef8e1e1395425e52f4994eae56c3eea6eccec919.jpg", "img_caption": ["Pseudocode 1: Rectified grid sampling for positional embeddings. "], "img_footnote": [], "page_idx": 15}, {"type": "text", "text": "Computational costs. In Tab. A1 we compare the model size and computational costs of the different architectures studied in the main paper. All model architectures are based on the original implemetations, but transposed to our codebase. Mainly, we use bfloat16 mixed precision and memory-efficient attention 2 from PyTorch. ", "page_idx": 15}, {"type": "text", "text": "Experimental details. To ensure efficient training of our models, we benchmark the most widely used hyperparameters and report the results of these experiments, which consist of the choice of the optimizer and its hyperparameters, the learning rate and the batch size. We then transpose the optimal settings to our other experiments. For FID evaluation, we use a guidance scale of 1.5 for 256 resolution and 2.0 for resolution 512. For evaluation on ImageNet-22k, we compute the FID score between $50\\mathrm{k}$ generated images and a subset of $200\\mathbf{k}$ images from the training set. ", "page_idx": 15}, {"type": "text", "text": "Training paradigm. We use the EDM [26] abstraction to train our models for epsilon prediction following DDPM paradigm. Differently from [15, 38], we do not use learned sigmas but follow a standard schedule. Specifically, we use a quadratic beta schedule with $\\beta_{\\mathrm{start}}\\,=\\,0.00085$ and $\\beta_{\\mathrm{end}}=0.012$ . In DDPM [21], a noising step is formulated as follows, with $x_{0}$ being the data sample and $t\\in[0,T]$ a timestep: ", "page_idx": 15}, {"type": "equation", "text": "$$\nx_{t}=\\sqrt{\\bar{\\alpha}_{t}}x_{0}+\\sqrt{1-\\bar{\\alpha}_{t}}\\epsilon,\\qquad\\epsilon\\sim\\mathcal{N}(0,I),\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "while in EDM, the cumulative alpha products are converted to corresponding signal-to-noise ratio (SNR) proportions, the noising process is then reformulated as: ", "page_idx": 15}, {"type": "equation", "text": "$$\nx_{t}=\\frac{x_{0}+\\sigma_{t}\\epsilon}{\\sqrt{1+\\sigma_{t}^{2}}},\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "and the loss is weighted by the inverse SNR $\\frac{1}{\\sigma_{t}^{2}}$ . ", "page_idx": 15}, {"type": "text", "text": "Scaling the training. A recurrent question when training deep networks is the coupling between the learning rate and the batch size. When multiplying the batch size by a factor $\\gamma$ , some works recommend scaling the learning rate by the square root of $\\gamma$ , while others scale the learning rate by the factor $\\gamma$ itself. In the following we experiment with training a class-conditional DiT model with different batch sizes and learning rates and report results after the same number of iterations. ", "page_idx": 15}, {"type": "table", "img_path": "B3rZZRALhk/tmp/726b033ed9f3415482ca9a0147c76fa8944771dd6ee24b4134edc84bd156d1dc.jpg", "table_caption": [], "table_footnote": [], "page_idx": 16}, {"type": "text", "text": "", "page_idx": 16}, {"type": "text", "text": "From Tab. A2 we observe an improved performance by increasing the batch size and the learning rate in every learning rate setting. If the learning rate is too high the training diverges. ", "page_idx": 16}, {"type": "text", "text": "Influence of momentum. We conduct a grid search over the momentum parameters of Adam optimizer, similar to previous sections, we train a UNet model fo 70k steps and compute FID with respect to the validation set of ImageNet1k using 50 DDIM steps. From Fig. A2, we can see that the default pytorch values ( $\\beta_{1}=0.9$ , $\\beta_{2}=0.999\\mathrm{~.~}$ ) are sub-optimal, resulting in an FID of 26.43 while the best performance is obtained when setting $\\dot{\\beta}_{1}\\,=\\,0.9,\\beta_{2}\\,=$ 0.95) improves FID by 4.78 points in our experimental setting. ", "page_idx": 16}, {"type": "text", "text": "Setting the optimal guidance scale. ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Proposition 2. The optimal guidance scale $\\lambda$ scales with the upsampling factor s according to the law $\\lambda^{\\prime}(s)\\;=\\;$ $1+s\\cdot(\\lambda-1)$ . ", "page_idx": 16}, {"type": "text", "text": "This is verified in Fig. 7 where the $\\lambda^{\\prime}(s=2)=1+2$ \u00b7 $(1.5-1.0)=2.0$ which is the optimal guidance scale at 512 resolution according to the figure. ", "page_idx": 16}, {"type": "text", "text": "Text padding mechanism. In order to train at a large scale, most commonly used text encoders output a constant number of tokens $T$ that are fed to the denoising model (usually $T=77$ ). Consequently, when the prompt has less than $T$ words, the remaining tokens are padding tokens that do not contain useful information, but can still contribute in the cross-attention, see Figure A3. This raises the question of whether better use can be made of padding text tokens to improve training performance and efficiency. One common mitigation involves using recaptioning methods that provide longer captions. However, this creates an inconsistency between training and sampling as users are more likely to provide shorter prompts. Thus, to make better use of the conditioning vector, we explore alternative padding mechanisms for the text encoder. We explore a \u2018replicate\u2019 padding mechanism where the padding tokens are replaced with copies of the text tokens, thereby pushing the subsequent cross-attention layers to attend to all the tokens in its inputs. To improve the diversity of the feature representation across the sequence dimension, we perturb the embeddings with additive Gaussian noise with a small variance $\\beta_{\\mathrm{txt}}$ . For shorter prompts with a high number of repeats $m$ , we scale the additive noise by $\\sqrt{m-1}$ to account for the reduction in posterior uncertainty induced by these repetitions: ", "page_idx": 16}, {"type": "image", "img_path": "B3rZZRALhk/tmp/d009d21272dd95f618b333f41dda27476200956df8b93fa0e8fba65a188c52d5.jpg", "img_caption": ["Table A2: Influence of learning rate and batch size on convergence. Training is performed on ImageNet- $1\\mathrm{k}@256$ . Results are reported on the model without EMA after 70k training steps. FID is computed using 250 sampling steps w.r.t. the training set of ImageNet- $1\\mathrm{k}@256$ . \u2717: diverged. For almost all learning rates, the optimal batch size is the highest possible. The best performance is obtained when using the highest learning rate that does not diverge with biggest batch size possible. ", "Figure A2: Influence of momentum on training dynamics of the UNet. We evaluate ImageNet1k $@256$ FID using 50 sampling steps after training the models for 70k steps. The FID is reported w.r.t. the validation set of ImageNet. "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "B3rZZRALhk/tmp/1c92642be69caa51b5c7b5999a918a4e0bb287c58756fa48ba4c4014e2827eb2.jpg", "img_caption": ["Figure A3: Contribution of Padding tokens. For short prompts, a large number of text tokens do not contain useful information, but may still contribute to the cross-attention, as illustrated by the non-zero gradients w.r.t. tokens after the ones coding the prompt (indicated by the dashed vertical line). "], "img_footnote": [], "page_idx": 16}, {"type": "image", "img_path": "B3rZZRALhk/tmp/5629a0cc281f332f9d183db1fd1f0d40a6b77dd55bc12ce99905e98540d04a23.jpg", "img_caption": ["Figure A4: Illustration of the attention matrix under different padding mechanisms. With the zero padding mechanism, a significant part of the attention can be used on \u201cdead\u201d padding tokens, potentially de-focusing from the relevant information. Using a replicate padding instead results in redundant information. Noisy replicate padding increases the diversity in the text token representations and therefore acts as a regularizer fostering the model to be robust to local variations in the latent space of the conditioning, e.g., akin to data augmentation. "], "img_footnote": [], "page_idx": 17}, {"type": "text", "text": "", "page_idx": 17}, {"type": "equation", "text": "$$\n\\phi_{\\mathrm{txt}}=\\phi_{\\mathrm{txt}}+\\sqrt{m-1}\\cdot\\sigma_{\\mathrm{ch}}(\\phi_{\\mathrm{txt}})\\cdot\\epsilon_{\\mathrm{txt}},\\qquad\\mathrm{with}\\;\\epsilon_{\\mathrm{txt}}\\sim\\mathcal{N}(0,I),\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $\\phi_{\\mathrm{ch}}$ is the standard deviation of the feature text embeddings over the feature dimension. See Figure A4 for an illustration comparing zero-padding, replication padding, and our noisy replication padding. ", "page_idx": 17}, {"type": "text", "text": "D Derivations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Derivation for Eq. (2) ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. The formula can be obtained by iteratively applying the guidance across the conditions. ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\epsilon^{\\lambda,\\beta}=\\lambda\\epsilon_{c}+(1-\\lambda)\\epsilon_{\\emptyset}}\\\\ &{\\epsilon^{\\lambda,\\beta}=\\lambda\\big(\\beta\\epsilon_{c,s}+(1-\\beta)\\epsilon_{c,\\emptyset}\\big)+(1-\\lambda)\\epsilon_{\\emptyset,\\emptyset}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Derivation for Eq. (4) ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Proof. Assuming that the unconditional prediction $\\epsilon_{\\emptyset}$ is distributed around the conditional distribution according to a normal law $\\epsilon_{\\emptyset}|\\epsilon_{c}\\sim\\mathcal{N}(\\epsilon_{c}^{\\bigstar},\\delta^{2}I)$ . ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\epsilon_{\\lambda}=\\lambda c+(1-\\lambda)(c+\\delta\\epsilon),\\quad\\epsilon\\sim\\mathcal{N}(0,I)}\\\\ &{\\epsilon_{\\lambda}=c+(1-\\lambda)\\delta\\epsilon}\\\\ &{\\operatorname*{Var}(\\epsilon_{\\lambda})=(1-\\lambda)^{2}\\delta^{2}}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "After upsampling by a scale factor of $s$ , the same low resolution patch has $s^{2}$ observations, hence the variance is decreased by $s^{2}$ . ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathrm{Var}(\\epsilon_{\\lambda})_{h r}=(1-\\lambda)^{2}\\delta^{2}/s^{2}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Hence by equalizing the discrepancy between the conditional and unconditional predictions at low and high resolutions we obtain: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Var}(\\epsilon_{\\lambda})_{s=1}=\\mathrm{Var}(\\epsilon_{\\lambda}^{\\prime})_{s}\\implies(1-\\lambda^{\\prime})^{2}\\delta^{2}/s^{2}=(1-\\lambda)^{2}\\delta^{2}}\\\\ {\\lambda^{\\prime}=1+s\\cdot(\\lambda-1)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "image", "img_path": "B3rZZRALhk/tmp/0d76b7738bed90c1a4e05785a05849dddb75ecf55d6cff992ba99f9502210c5c.jpg", "img_caption": ["Figure A5: Qualitative examples. Sample from mmDiT-XL/2 trained with our method on ImageNet1k at 512 resolution. Samples are generated with 50 DDIM steps and a guidance scale of 5. "], "img_footnote": [], "page_idx": 18}, {"type": "text", "text": "Derivation for Eq. (3) ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Proof. At timestep $t$ , the noisy observation is obtained as : ", "page_idx": 18}, {"type": "equation", "text": "$$\nx_{t}=\\frac{1}{\\sqrt{1+\\sigma_{t}^{2}}}\\big(x_{0}+\\sigma_{t}\\epsilon\\big),\\qquad\\epsilon\\sim\\mathcal{N}(0,I)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Hence $x_{0}$ can be estimated using the following formula: ", "page_idx": 18}, {"type": "equation", "text": "$$\nx_{0}=\\sqrt{1+\\sigma_{t}^{2}}x_{t}-\\sigma_{t}\\epsilon\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "The statistics of the estimate of $x_{0}$ are as follows. ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\left\\{\\begin{array}{l l}{\\mathbb{E}(x_{0})=\\sqrt{1+\\sigma_{t}^{2}}\\mathbb{E}(x_{t})}\\\\ {\\operatorname{Var}(x_{0})=(1+\\sigma_{t}^{2})\\operatorname{Var}(x_{t})+\\sigma_{t}^{2}}\\end{array}\\right.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Consequently, if we already have $x_{t}$ , we have an estimate of $x_{0}$ with an error bound given by: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname{Var}\\!\\left(x_{0}-{\\sqrt{1+\\sigma^{2}}}x_{t}\\right)=\\sigma_{t}^{2}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "At higher resolutions, we have $s^{2}$ corresponding observations for the same patch such that the error with respect to the estimate becomes: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\mathrm{Var}\\Big(x_{0}-\\frac{1}{s^{2}}\\sum_{i=1}^{s^{2}}\\sqrt{1+\\sigma_{t}^{2}}x_{t}^{(i)}\\Big)=\\sigma_{t}^{2}/s^{2}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Hence, if we want to keep the same uncertainty with respect to the low resolution patches, the following equality needs to be verified: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sigma(t,s)=\\sigma(t^{\\prime},s^{\\prime})\\implies\\sigma_{t}/s=\\sigma_{t}^{\\prime}/s^{\\prime}}\\\\ {\\displaystyle\\implies\\frac{1-\\bar{\\alpha}_{t}}{\\bar{\\alpha}_{t}}=(\\frac{s}{s^{\\prime}})^{2}\\cdot\\frac{1-\\bar{\\alpha}_{t^{\\prime}}}{\\bar{\\alpha_{t^{\\prime}}}}}\\\\ {\\displaystyle\\implies\\bar{\\alpha}_{t^{\\prime}}=\\frac{s^{2}\\cdot\\bar{\\alpha}_{t}}{s^{\\prime2}+\\bar{\\alpha}_{t}\\cdot(s^{2}-s^{\\prime2})}}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "E Additional results ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Qualitative results. We provide additional qualitative examples on ImageNet-1k in Fig. A5. ", "page_idx": 18}, {"type": "table", "img_path": "B3rZZRALhk/tmp/38d73d01957f1d2d91d6b4198eb5610a85a2dda0ff61269372e6bc1f044fdf2a.jpg", "table_caption": [], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "B3rZZRALhk/tmp/bb5155ddbb855f464cbc660f7718d66c7a936dc9641022e99b619c2ca52f5e47.jpg", "table_caption": ["Table A3: Effects of our changes. We summarize the improvements obtained by each change proposed in the paper. left: Changes relevant to conditioning mechanisms \u2013 right: Changes relevant to representation transfer across image resolutions. "], "table_footnote": ["Table A4: Comparison with previous paradigms. We provide a comparative table with previous works, notably SD-XL [39] and SD3 [14]. "], "page_idx": 19}, {"type": "text", "text": "Summary of findings. In Table A3 we summarize the improvements w.r.t. the DiT baseline obtained by the changes to the model architecture and training. In Table A4 we compare our model architecture and training recipe to that of SDXL and SD3. In Table A5, we provide a synopsis of the research questions addressed in our study alongside a respective recommendation based on our findings. ", "page_idx": 19}, {"type": "text", "text": "Effectiveness of the power cosine schedule We experiment with different function profiles for controlling the conditioning on low-level augmentations. Specifically, we compare the power-cosine profile with a linear and a piecewise constant profile. While the linear schedule manages an acceptable performance in terms of reducing LPIPS (although still higher than the power-cosine profile), it still achieves a higher FID than all the configurations with the cosine schedule. For the piecewise constant profiles, they achieve a higher LPIPS while also having a higher FID. In conclusion, the proposed power-cosine profile outperforms these simpler schedules in both FID and LPIPS, improving image quality while better removing the unwanted distribution shift induced from choosing different samples during training. ", "page_idx": 19}, {"type": "table", "img_path": "B3rZZRALhk/tmp/2afcc0e2e8dd25408f3c691aa6e9db28c39ec70be93c30c0968b974e642bb4b4.jpg", "table_caption": ["Table A5: Summary of the findings from our experiments in the form of a Q&A "], "table_footnote": [], "page_idx": 19}, {"type": "table", "img_path": "B3rZZRALhk/tmp/2d85ccea65fcb1d5b0608c84b78c603c43c88fe0401b37eb83089a6c87aa9606.jpg", "table_caption": ["Table A6: Comparison of the power cosine schedule with other schedules. We report results for a linear and step function schedules. "], "table_footnote": [], "page_idx": 20}, {"type": "text", "text": "", "page_idx": 20}, {"type": "text", "text": "F NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: The abstract and introduction clearly set the claims made in the paper and match theoretical and experimental results, which are addressed in Section 3. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 21}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Justification: We include discussion of limitations in Appendix B ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 21}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 21}, {"type": "text", "text": "Justification: Proofs are provided Appendix D and contain cross-references to the relevant parts in the main paper. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 22}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 22}, {"type": "text", "text": "Justification: We include details required for result reproducibility in Section 3.1. These include details about datasets used for training, evaluation metrics, training parameters, and model architectures. ", "page_idx": 22}, {"type": "text", "text": "Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 22}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 23}, {"type": "text", "text": "Answer: [No] ", "page_idx": 23}, {"type": "text", "text": "Justification: While we are not be able to include code, we do provide specific and thorough detailing of our training and evaluation methods in Section 3.1 to enable experimental reproduction. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 23}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 23}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 23}, {"type": "text", "text": "Justification: Details corresponding to training and testing are included in Section 3.1. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 23}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 23}, {"type": "text", "text": "Answer: [No] ", "page_idx": 23}, {"type": "text", "text": "Justification: Due to the computational cost of training and performing inference with generative models, we do not include error bars. ", "page_idx": 23}, {"type": "text", "text": "Guidelines: ", "page_idx": 23}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. ", "page_idx": 23}, {"type": "text", "text": "\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 24}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: Information about compute resources needed for experiment reproduction is included in Section 3.1. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 24}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: This research conforms to the Code of Ethics, including mitigation of potential harms caused by the research process, considerations of social impact, and taking steps for impact mitigation. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 24}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 24}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 24}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 24}, {"type": "text", "text": "Justification: We discuss societal impacts and steps taken to mitigate potential harms in Appendix B. ", "page_idx": 24}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 25}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 25}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 25}, {"type": "text", "text": "Justification: We do not release models nor data in this work. Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 25}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 25}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 25}, {"type": "text", "text": "Justification: Use of existing assets is discussed, including which version, and cited throughout the paper. No assets are released. ", "page_idx": 25}, {"type": "text", "text": "Guidelines: ", "page_idx": 25}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not release new assets. ", "page_idx": 26}, {"type": "text", "text": "Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 26}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not include crowdsourcing or research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 26}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 26}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 26}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 26}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 26}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. ", "page_idx": 26}, {"type": "text", "text": "\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 27}]