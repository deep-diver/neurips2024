[{"figure_path": "B3rZZRALhk/figures/figures_1_1.jpg", "caption": "Figure 1: Qualitative examples. Images generated using our model trained on CC12M at 512 resolution.", "description": "This figure displays eight example images generated by the model trained on the Conceptual Captions 12M dataset at a resolution of 512x512 pixels.  The images showcase the model's ability to generate diverse and realistic images across different styles and subject matters, demonstrating the capabilities of the improved conditioning and pre-training strategies presented in the paper.  Each image is accompanied by a short text description of its content.", "section": "1 Introduction"}, {"figure_path": "B3rZZRALhk/figures/figures_2_1.jpg", "caption": "Figure 2: Influence of control conditions. Images generated using the same latent sample. Top: Model trained with constant weighting of the size conditioning as used in SDXL [39], introducing undesirable correlations between image content and size condition. Bottom: Model trained using our cosine weighting of low-level conditioning, disentangling the size condition from the image content.", "description": "This figure demonstrates the impact of different control conditioning methods on image generation.  The top row shows images generated using a model trained with constant weighting of the size condition, leading to unwanted correlations between image content and size.  The bottom row shows images generated with a cosine weighting of low-level conditioning, effectively decoupling the size condition from the content, resulting in more controlled and natural-looking outputs.", "section": "2.1 Conditioning mechanisms"}, {"figure_path": "B3rZZRALhk/figures/figures_3_1.jpg", "caption": "Figure 3: Weighting of low-level control conditions. The weight is zeroed out early on when image semantics are defined, and increased later when adding details.", "description": "This figure shows the cosine weighting schedule used for low-level control conditions in the improved conditioning mechanism. The x-axis represents the timestep t, and the y-axis represents the weight applied to the low-level control embedding. Different curves are plotted for different values of the parameter \u03b1, which controls the steepness of the cosine curve.  The weight starts at 1.0 at the beginning of the generation process (t=0) and gradually decreases to 0.0 as the generation process continues. This ensures that low-level details are only added towards the end of the generation process, after high-level semantic information has already been established.  This helps disentangle control metadata from semantic-level conditioning to avoid undesired interference between them.", "section": "2.1 Conditioning mechanisms"}, {"figure_path": "B3rZZRALhk/figures/figures_4_1.jpg", "caption": "Figure 4: Interpolation and extrapolation of positional embeddings.", "description": "This figure compares three different methods for adapting positional embeddings to higher resolutions: (left) using the original low-resolution embeddings, (middle) extrapolating the low-resolution embeddings, and (right) interpolating the low-resolution embeddings. The figure shows that interpolation produces better results than extrapolation, because extrapolation leads to a mismatch between the positional embeddings and image features, whereas interpolation preserves a smooth transition between resolutions.", "section": "3 Experimental evaluation"}, {"figure_path": "B3rZZRALhk/figures/figures_4_2.jpg", "caption": "Figure 5: Low-resolution pre-training impacts finetuning.", "description": "This figure illustrates the impact of different pre-training strategies on the model's ability to finetune at higher resolutions.  The left image shows a low-resolution crop used during pre-training, representing the \"global context\" the model learns. The right image shows the higher-resolution image used during fine-tuning, representing the \"target resolution\". The arrow indicates that the model may struggle to adapt between these very different contexts during the finetuning phase.  This highlights a potential issue in training:  models that learn only from low-resolution, small crops may not generalize well to high-resolution, full images.", "section": "3 Experimental evaluation"}, {"figure_path": "B3rZZRALhk/figures/figures_7_1.jpg", "caption": "Figure 6: Illustration of the impact of flip conditioning. Without the flip conditioning, the model may confuse left-right specifications. Including flipping as a control condition enables the model to properly follow left-right instructions.", "description": "This figure demonstrates the effect of including \"flip\" as a control condition during image generation using diffusion models.  The top row shows images generated without flip conditioning, where the model struggles to consistently place objects correctly (a blue car on the left and a red car on the right). In contrast, the bottom row showcases images generated with flip conditioning enabled, demonstrating improved consistency in object placement and adherence to the prompt's specifications.", "section": "3.3 Control conditioning"}, {"figure_path": "B3rZZRALhk/figures/figures_8_1.jpg", "caption": "Figure 8: Resolution shift. Experiments are conducted on ImageNet-1k at 512 resolution, FID is reported using 50 DDIM steps with respect to the ImageNet-1k validation set.", "description": "This figure shows the impact of different strategies for handling resolution changes during the training process of diffusion models.  Specifically, it compares the training convergence and final FID score (Fr\u00e9chet Inception Distance, a measure of image quality) for three different approaches: default (no special handling of resolution change), positional embeddings resampling, and noise schedule rescaling. The x-axis represents training iterations, and the y-axis shows the FID score. The results suggest that scaling the noise schedule and resampling positional embeddings can lead to better performance.", "section": "3.4 Transferring weights between datasets and resolutions"}, {"figure_path": "B3rZZRALhk/figures/figures_8_2.jpg", "caption": "Figure 8: Resolution shift. Experiments are conducted on ImageNet-1k at 512 resolution, FID is reported using 50 DDIM steps with respect to the ImageNet-1k validation set.", "description": "This figure presents the results of experiments conducted to analyze the impact of resolution changes on the performance of the model. Three subplots show how different approaches to handling the transition from lower to higher resolutions affect the model's convergence. Specifically, it evaluates the impact of changes in the positional embedding resampling (left), noise schedule scaling (middle), and pre-training cropping strategies (right). The y-axis represents the FID score, and the x-axis represents the number of training iterations (k). The results demonstrate the significance of carefully managing the transition to higher resolutions to achieve optimal performance.", "section": "3.4 Transferring weights between datasets and resolutions"}, {"figure_path": "B3rZZRALhk/figures/figures_8_3.jpg", "caption": "Figure 8: Resolution shift. Experiments are conducted on ImageNet-1k at 512 resolution, FID is reported using 50 DDIM steps with respect to the ImageNet-1k validation set.", "description": "This figure demonstrates the impact of different pre-training strategies and resolution adaptations on model performance.  It shows how various methods for handling positional embeddings, noise schedules, and cropping strategies affect convergence speed and the final FID (Fr\u00e9chet Inception Distance) score on ImageNet-1k at 512x512 resolution. The results illustrate that careful consideration of these factors is crucial for efficient and effective training of high-resolution diffusion models.", "section": "3 Experimental evaluation"}, {"figure_path": "B3rZZRALhk/figures/figures_13_1.jpg", "caption": "Figure 1: Qualitative examples. Images generated using our model trained on CC12M at 512 resolution.", "description": "This figure displays several example images generated by the model trained on the Conceptual Captions dataset at 512x512 resolution.  It showcases the model's ability to generate various images based on different prompts, highlighting the diversity and quality of the generated images. The images demonstrate the model's capacity to produce realistic and varied outputs.", "section": "1 Introduction"}, {"figure_path": "B3rZZRALhk/figures/figures_14_1.jpg", "caption": "Figure A1: Noise schedule scaling law. At higher resolutions, keeping the same uncertainty means spending more time at higher noise levels, thereby counteracting the uncertainty reduction from the increase in the observations for the same patch.", "description": "This figure illustrates how the noise schedule needs to be adjusted when scaling the resolution of diffusion models.  At higher resolutions, with more observations of each image patch, the uncertainty is naturally reduced.  To maintain the same level of uncertainty across resolutions, the noise schedule needs to be modified.  The plot shows the noise schedule (\u03c3t(s)) for different scaling factors (s), demonstrating how the noise amplitude changes over time (timestep) to compensate for this resolution-dependent uncertainty.", "section": "C Implementation details"}, {"figure_path": "B3rZZRALhk/figures/figures_15_1.jpg", "caption": "Figure 4: Interpolation and extrapolation of positional embeddings.", "description": "This figure compares three different methods for adapting positional embeddings to higher resolutions: extrapolation, which simply replicates the original embeddings; bicubic interpolation; and the method proposed in the paper, which uses sinusoidal embeddings and adjusts the sampling grid.", "section": "2.2 On transferring models pre-trained on different datasets and resolutions"}, {"figure_path": "B3rZZRALhk/figures/figures_16_1.jpg", "caption": "Figure A2: Influence of momentum on training dynamics of the UNet. We evaluate ImageNet1k@256 FID using 50 sampling steps after training the models for 70k steps. The FID is reported w.r.t. the validation set of ImageNet.", "description": "This figure shows the results of a grid search over the momentum parameters (\u03b21 and \u03b22) of the Adam optimizer used in training a UNet model on ImageNet1k at 256x256 resolution.  The FID (Fr\u00e9chet Inception Distance) scores are shown as a heatmap, with lower FID values indicating better performance.  The heatmap reveals the optimal momentum parameter settings, demonstrating their impact on the model's training dynamics and FID score.", "section": "Additional results"}, {"figure_path": "B3rZZRALhk/figures/figures_16_2.jpg", "caption": "Figure A3: Contribution of Padding tokens. For short prompts, a large number of text tokens do not contain useful information, but may still contribute to the cross-attention, as illustrated by the non-zero gradients w.r.t. tokens after the ones coding the prompt (indicated by the dashed vertical line).", "description": "This figure shows the gradient magnitude of each token embedding in the text encoder.  For short prompts (less than the maximum number of tokens the model accepts), padding tokens are added.  Even though these tokens contain no semantic information, their embeddings still contribute to the attention mechanism in the transformer, as evidenced by non-zero gradients.", "section": "D Derivations"}, {"figure_path": "B3rZZRALhk/figures/figures_17_1.jpg", "caption": "Figure A4: Illustration of the attention matrix under different padding mechanisms. With the zero padding mechanism, a significant part of the attention can be used on \"dead\" padding tokens, potentially de-focusing from the relevant information. Using a replicate padding instead results in redundant information. Noisy replicate padding increases the diversity in the text token representations and therefore acts as a regularizer fostering the model to be robust to local variations in the latent space of the conditioning, e.g., akin to data augmentation.", "description": "This figure illustrates how different padding mechanisms affect the attention matrix in a diffusion model.  Zero padding wastes attention on irrelevant padding tokens, replicate padding leads to redundancy, while noisy replicate padding improves diversity and robustness by adding noise to the replicated tokens.", "section": "D Derivations"}, {"figure_path": "B3rZZRALhk/figures/figures_18_1.jpg", "caption": "Figure A5: Qualitative examples. Sample from mmDiT-XL/2 trained with our method on ImageNet1k at 512 resolution. Samples are generated with 50 DDIM steps and a guidance scale of 5.", "description": "This figure shows several example images generated by the improved mmDiT-XL/2 model trained on ImageNet-1k at a resolution of 512x512 pixels.  The images are generated using 50 DDIM sampling steps and a guidance scale of 5, highlighting the model's ability to generate high-quality and diverse images of various classes from the ImageNet-1k dataset. The improved conditioning mechanisms and pre-training strategies lead to these superior results.", "section": "E Additional results"}]