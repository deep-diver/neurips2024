[{"figure_path": "yDo1ynArjj/tables/tables_4_1.jpg", "caption": "Table 1: Diffusion Forcing for Planning. (top) During sampling, Diffusion Forcing allows each time step to be denoised on different noise schedules, enabling us to account for causal uncertainty during guided planning. Diffusion Forcing keeps the far future more uncertain than the near future while Diffuser [36] puts them at the same noise level during sampling. (bottom) Quantitatively, Diffusion Forcing achieves the highest average reward across runs. Diffuser fails dramatically when executing the actually generated actions, requiring a hand-crafted PD controller (indicated by the asterisk) and ignoring generated actions.", "description": "This table presents a comparison of Diffusion Forcing with several baselines on a set of 2D maze planning tasks.  The top section illustrates the difference in sampling strategies between Diffusion Forcing and Diffuser, highlighting Diffusion Forcing's ability to handle causal uncertainty by varying noise levels across time steps. The bottom section shows the quantitative results, demonstrating Diffusion Forcing's superior performance in terms of average reward compared to the baselines.  Note that Diffuser requires a hand-crafted controller to function effectively.", "section": "4.2 Diffusion Planning: MCG, Flexible Horizon Control"}, {"figure_path": "yDo1ynArjj/tables/tables_29_1.jpg", "caption": "Table 1: Diffusion Forcing for Planning. (top) During sampling, Diffusion Forcing allows each time step to be denoised on different noise schedules, enabling us to account for causal uncertainty during guided planning. Diffusion Forcing keeps the far future more uncertain than the near future while Diffuser [36] puts them at the same noise level during sampling. (bottom) Quantitatively, Diffusion Forcing achieves the highest average reward across runs. Diffuser fails dramatically when executing the actually generated actions, requiring a hand-crafted PD controller (indicated by the asterisk) and ignoring generated actions.", "description": "This table compares the performance of Diffusion Forcing with other planning methods on various 2D maze environments.  The top part describes the key differences in the sampling approach between Diffusion Forcing and Diffuser, highlighting Diffusion Forcing's ability to handle causal uncertainty more effectively. The bottom part presents a quantitative comparison of average rewards achieved by different methods, showcasing Diffusion Forcing's superior performance.  Note that Diffuser requires a hand-crafted PD controller to function properly.", "section": "4.2 Diffusion Planning: MCG, Flexible Horizon Control"}, {"figure_path": "yDo1ynArjj/tables/tables_36_1.jpg", "caption": "Table 1: Diffusion Forcing for Planning. (top) During sampling, Diffusion Forcing allows each time step to be denoised on different noise schedules, enabling us to account for causal uncertainty during guided planning. Diffusion Forcing keeps the far future more uncertain than the near future while Diffuser [36] puts them at the same noise level during sampling. (bottom) Quantitatively, Diffusion Forcing achieves the highest average reward across runs. Diffuser fails dramatically when executing the actually generated actions, requiring a hand-crafted PD controller (indicated by the asterisk) and ignoring generated actions.", "description": "This table presents a comparison of Diffusion Forcing with other planning methods on several maze environments.  The top part describes the different sampling approaches and how Diffusion Forcing handles causal uncertainty better than the Diffuser baseline. The bottom part shows the quantitative results, demonstrating Diffusion Forcing's superior performance in terms of average reward, highlighting its ability to effectively utilize generated actions.", "section": "4.2 Diffusion Planning: MCG, Flexible Horizon Control"}]