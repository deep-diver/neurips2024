[{"figure_path": "S8SEjerTTg/tables/tables_7_1.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the results of object detection experiments on two datasets, Foggy-Cityscapes and BDD100K, using the GDINO model.  It compares different object detection adaptation methods across four scenarios: unsupervised (U), source-free (SF), black-box (BB), and cloud (C).  The table shows the mean average precision (mAP) achieved by each method for various object categories (Truck, Car, Rider, Person, Train, Motorcycle, Bicycle, Bus).  The \"Oracle\" row indicates the performance achievable with perfect labels for the target domain.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_7_2.jpg", "caption": "Table 2: Results on Clipart under GDINO. Object detection adaptation settings: SF - Source-free, U - Unsupervised, C \u2013 Cloud. det: detector.", "description": "This table presents the results of object detection adaptation experiments conducted on the Clipart dataset using the GDINO model.  Different adaptation strategies are compared, including unsupervised (U), source-free (SF), and cloud-based (C) approaches.  The table shows the mean Average Precision (mAP) achieved by each method across various object categories.", "section": "Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_8_1.jpg", "caption": "Table 3: Quantitative results on KITTI under GDINO. U \u2013 Unsupervised, C \u2013 Cloud. det: detector.", "description": "This table presents a quantitative comparison of object detection performance on the KITTI dataset using different methods.  The results are broken down by the type of adaptation used (Unsupervised or Cloud-based), and specific methods are compared against each other.  The key metric presented is the Average Precision (AP) for the \"Car\" class.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_8_2.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents quantitative results for object detection on the Foggy-Cityscapes and BDD100K datasets using the GDINO model.  It compares various domain adaptation methods, including unsupervised (U), source-free (SF), black-box (BB), and cloud-based (C) approaches.  The results are broken down by object class (Truck, Car, Rider, Person, Train, Mcycle, Bcycle, Bus) and overall mean Average Precision (mAP).  The table helps illustrate the performance improvements achieved by the COIN method in the context of different adaptation techniques.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_9_1.jpg", "caption": "Table 5: Ablation study on Foggy-Cityscapes and Cityscapes under GDINO. det: detector.", "description": "This table presents the ablation study results for the proposed COIN method on two datasets, Foggy-Cityscapes and Cityscapes, using GDINO as the object detector. It shows the impact of different components of the COIN model (Lalign, Lcon, Linc, Lpri) on the mAP (mean Average Precision) performance.  The results demonstrate the effectiveness of each component and show the improvements in mAP achieved by including each part of the COIN method.  It provides a quantitative assessment of the importance of each loss function in the COIN framework for object detection.", "section": "4.2 Further Analysis"}, {"figure_path": "S8SEjerTTg/tables/tables_9_2.jpg", "caption": "Table 6: Ablation study for decision-level fusion of inconsistent detections on Foggy-Cityscapes under GDINO. Detections are filtered by \u03c0 = 0.7 for fair comparison. det: detector. probs: probabilities. avg: average. s-avg: score-weighted average.", "description": "This table presents the ablation study for decision-level fusion of inconsistent detections on the Foggy-Cityscapes dataset using the GDINO object detector.  Different methods for fusing inconsistent detections are compared: using only cloud detector probabilities, using only CLIP detector probabilities, simple averaging, score-weighted averaging, and the proposed Consistent Knowledge Generation (CKG) network.  The results are evaluated based on mAP and per-class AP scores for various object categories (Truck, Car, Rider, Person, Train, Mcycle, Bcycle, Bus).  The filtering threshold (\u03c0) is set to 0.7 for consistent comparison across methods.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_16_1.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the quantitative results of various object detection methods on two datasets, Foggy-Cityscapes and BDD100K, using the GDINO model.  The results are categorized by the type of domain adaptation used: Unsupervised (U), Source-free (SF), Black-box (BB), and Cloud (C).  The table shows the mean Average Precision (mAP) and precision for different object categories (Truck, Car, Rider, Person, Train, Motorcycle, Bicycle, Bus) for each method and adaptation setting.  It compares the performance of the proposed COIN method against existing unsupervised domain adaptation, source-free object detection, and black-box domain adaptive object detection methods, as well as a cloud detector and CLIP (Contrastive Language-Image Pre-training) baseline.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_18_1.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the quantitative results of various object detection methods on two datasets, Foggy-Cityscapes and BDD100K, using the GDINO model.  The results are categorized by the type of domain adaptation setting used: Unsupervised (U), Source-free (SF), Black-box (BB), and Cloud (C).  Each method's performance is evaluated across multiple object categories (Truck, Car, Rider, Person, Train, Motorcycle, Bicycle, Bus) using the mean Average Precision (mAP) metric.  The table allows for a comparison of different domain adaptation strategies and their impact on object detection accuracy.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_18_2.jpg", "caption": "Table 9: Quantitative results on Cityscapes, KITTI and Sim10K under GLIP. det: detector.", "description": "This table presents a quantitative comparison of object detection performance across three different datasets (Cityscapes, KITTI, and Sim10K) using the GLIP model.  The performance metrics include average precision (AP) for various object classes within each dataset.  The table allows for a comparison of the baseline cloud detector, the CLIP model, the CLIP detector, and the COIN method to assess the effectiveness of the proposed COIN approach in improving the accuracy of object detection on diverse datasets and diverse object categories.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_19_1.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the quantitative results of different object detection methods on two datasets: Foggy-Cityscapes and BDD100K.  The results are categorized by the type of domain adaptation setting used (Unsupervised, Source-free, Black-Box, Cloud) and the specific detector used.  The table shows the mean Average Precision (mAP) and per-class performance for various object categories.  The 'Cloud det' row represents the performance of a pre-trained cloud-based object detector used as a starting point for some adaptation techniques. The 'Oracle' row indicates the upper bound of performance achievable if true labels were available.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_19_2.jpg", "caption": "Table 11: Ablation study for different prompt templates of CLIP model (boxes are borrowed from cloud detector). A simple template represents \u201ca photo of a [CLS].\u201d; A simple template w/ style represents \u201ca [target domain name] style photo of a [CLS].\u201d; 81 templates w/o style represents 81 templates where \u201c[target domain name] style\u201d is not added.", "description": "This ablation study investigates the effectiveness of different prompt templates for CLIP model across six datasets.  It compares using a simple template, a simple template with added style information, 81 templates without style, and finally, all 81 templates. The results show the impact of incorporating style information and the number of prompts used on model performance across various datasets.", "section": "4.2 Further Analysis"}, {"figure_path": "S8SEjerTTg/tables/tables_20_1.jpg", "caption": "Table 12: Ablation study for dual prompt learning on Foggy-Cityscapes. Tempate w/ t\u00b2 represents \u201ca photo of a t1 t2 t3 t4 [CLS].\u201d. Tempate w/o t\u00b2 represents \u201ca photo of a [CLS].\u201d. Prototypes update represents the exponential moving average of them. COIN w/ CLIP det prototypes represents aligning to pre-trained CLIP detector prototypes, rather than collecting them with consistent detection. det: detector.", "description": "This ablation study investigates the impact of different prompt learning strategies on the performance of the proposed COIN method for object detection adaptation. It compares the effects of using simple prompts, more complex prompts with placeholders, and incorporating exponential moving averages to update prototypes. It also examines the impact of aligning to pre-trained CLIP detector prototypes versus collecting prototypes from consistent detections. The results show the effectiveness of the proposed dual prompt learning method. ", "section": "4.2 Further Analysis"}, {"figure_path": "S8SEjerTTg/tables/tables_21_1.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the performance comparison of different object detection methods on two datasets (Foggy-Cityscapes and BDD100K) using the GDINO model.  It shows the mean Average Precision (mAP) and per-class AP for various object categories under different adaptation settings: unsupervised, source-free, black-box, and cloud-based.  The results highlight the effectiveness of the proposed COIN method in adapting to the target domains.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_21_2.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the results of object detection experiments on two datasets, Foggy-Cityscapes and BDD100K, using the GDINO model.  The results are categorized by different domain adaptation settings: unsupervised (U), source-free (SF), black-box (BB), and cloud (C).  Each setting uses a different approach to adapt the detector for the respective target domain. The table shows the mean average precision (mAP) and performance metrics for several object classes (Truck, Car, Rider, Person, Train, Motorcycle, Bicycle, Bus) on each dataset and adaptation setting.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_22_1.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the performance comparison of different object detection methods on two datasets (Foggy-Cityscapes and BDD100K) using the GDINO model.  The methods are categorized by the type of domain adaptation they employ: Unsupervised (U), Source-Free (SF), Black-Box (BB), and Cloud (C).  The table shows the mean Average Precision (mAP) and per-class Average Precision (AP) for various object categories like Truck, Car, Rider, Person, Train, Motorcycle, Bicycle, and Bus.  The \"Cloud det\" row represents the results achieved by using a large pre-trained cloud-based object detector.  The \"COIN\" row shows the results obtained using the proposed COIN method in this paper. The \"Oracle\" row presents the upper bound results using ground truth labels.  The table helps to evaluate the effectiveness of COIN compared to existing unsupervised, source-free, and black-box object detection adaptation methods.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_22_2.jpg", "caption": "Table 16: Detection consistence of cloud detector GDINO and CLIP detector on BDD100K. The average results over 1000 iterations are reported. Cloud(P)/CLIP(N) means cloud detector is right while CLIP detector is wrong. So does Cloud(N)/CLIP(P).", "description": "This table shows the consistency between the cloud detector (GDINO) and the CLIP detector in identifying inconsistent object detections on the BDD100K dataset.  It indicates how often both detectors agree or disagree on whether a detection is correct or incorrect.  The numbers represent percentages across 1000 iterations.", "section": "4.2 Further Analysis"}, {"figure_path": "S8SEjerTTg/tables/tables_23_1.jpg", "caption": "Table 17: Model size and speed of target detector (ResNet50) and cloud detector on a 3090 GPU.", "description": "This table presents a comparison of the model size and inference speed of the target detector (using ResNet50) and the cloud detector (Swin-B) on a 3090 GPU.  The target detector's size and speed are shown for different numbers of proposals (1000, 500, 300, and 100), reflecting the tradeoff between accuracy and real-time performance in deployment scenarios.  The table highlights the significant reduction in model size and the increase in FPS of the target detector compared to the cloud detector, making it more suitable for deployment on resource-constrained devices.", "section": "A.2.3 Optimization and algorithm"}, {"figure_path": "S8SEjerTTg/tables/tables_24_1.jpg", "caption": "Table 1: Results on Foggy-Cityscapes and BDD100K under GDINO. Object detection adaptation settings: U - Unsupervised, SF \u2013 Source-free, BB - Black-Box, C \u2013 Cloud. det: detector.", "description": "This table presents the results of object detection experiments on two datasets, Foggy-Cityscapes and BDD100K, using the GDINO model.  It compares different object detection adaptation methods (Unsupervised, Source-free, Black-box, and Cloud) across various object categories.  The metrics include the mean Average Precision (mAP) and per-class precision values for each dataset and method. The table helps analyze how these methods perform in adapting to different levels of difficulty (Unsupervised vs. Source-free vs. Cloud) in object detection.", "section": "4 Experiments"}, {"figure_path": "S8SEjerTTg/tables/tables_24_2.jpg", "caption": "Table 19: Error bars on Foggy-Cityscapes. Five quantitative results from one default seed 2024 and other four randomly generated seeds are displayed. det: detector.", "description": "This table presents the mean and standard deviation of the mAP scores for five different random seeds on the Foggy-Cityscapes dataset.  The purpose is to show the stability and reproducibility of the COIN method.  The results are compared for the Cloud detector, CLIP, CLIP detector and COIN methods.", "section": "4 Experiments"}]