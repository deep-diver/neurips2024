{"references": [{"fullname_first_author": "Josh Achiam", "paper_title": "GPT-4 technical report", "publication_date": "2023-03-08", "reason": "This paper is a technical report on GPT-4, a large language model that is foundational to many of the models discussed in this paper."}, {"fullname_first_author": "Jean-Baptiste Alayrac", "paper_title": "Flamingo: a visual language model for few-shot learning", "publication_date": "2022-12-01", "reason": "This paper introduces Flamingo, a visual language model that serves as a basis for many large vision-language models (LVLMs) discussed in this paper."}, {"fullname_first_author": "Anas Awadalla", "paper_title": "Openflamingo: An open-source framework for training large autoregressive vision-language models", "publication_date": "2023-08-01", "reason": "This paper introduces OpenFlamingo, an open-source framework for training LVLMs, which is relevant to the methods and results of this paper."}, {"fullname_first_author": "Jinze Bai", "paper_title": "Qwen-vl: A versatile vision-language model for understanding, localization, text reading, and beyond", "publication_date": "2024-02-26", "reason": "This paper introduces Qwen-VL, a versatile vision-language model, which is directly relevant to the work in this paper on mitigating object hallucination in LVLMs."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2018-10-18", "reason": "This paper introduces BERT, a foundational language model, whose architecture and pre-training methods inform the architecture and training methods of many LVLMs discussed in this paper."}]}