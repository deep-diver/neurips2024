[{"figure_path": "JxOQeg1NkH/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of general reasoning abilities with previous MLLMs across several benchmarks. 'Res.' indicates the resolution of the input image. RoboVQA1 to RoboVQA4 represent the BLEU-1 to BLEU-4 scores, respectively. For TinyLLaVA and LLaMA-AdapterV2, we evaluate robotic reasoning abilities after fine-tuning the pre-trained MLLMs on the RoboVQA dataset.", "description": "This table compares the performance of RoboMamba against several state-of-the-art Multimodal Large Language Models (MLLMs) across various general reasoning benchmarks and a robotic-related reasoning benchmark (RoboVQA).  It highlights RoboMamba's competitive performance despite using a smaller language model (2.7B parameters). The table includes metrics like OKVQA, VQAv2, GQA, VizWiz, POPE, MME, MMB, MM-Vet, and RoboVQA BLEU scores (1-4).  The results for TinyLLaVA and LLaMA-AdapterV2 reflect performance after fine-tuning on RoboVQA, demonstrating RoboMamba's strong performance without extensive fine-tuning.", "section": "4.2 Reasoning quantitative results"}, {"figure_path": "JxOQeg1NkH/tables/tables_16_1.jpg", "caption": "Table 2: Comparison of the success rates between RoboMamba and baselines across various training (seen) and test (unseen) tasks. The representation for each task icon is shown in Table 3.", "description": "This table presents a comparison of the success rates achieved by RoboMamba and other baseline models on various robotic manipulation tasks.  The tasks are categorized into \"seen\" (those present in the training data) and \"unseen\" categories.  The success rate is a measure of how often the robot successfully completed each task.  Table 3 provides a visual key for understanding the icons used in this table to represent each task.", "section": "4.3 Manipulation quantitative results"}, {"figure_path": "JxOQeg1NkH/tables/tables_17_1.jpg", "caption": "Table 4: Ablation study of different image encoders on reasoning abilities.", "description": "This table presents the results of an ablation study comparing the performance of different vision encoders (CLIP, XCIT, SigLIP) and image resolutions (224x224, 336x336, 384x384) on several reasoning benchmarks (OKVQA, GQA, POPE, RoboVQA).  The results demonstrate the impact of the choice of encoder and resolution on the model's performance.  It aims to show the robustness of the proposed model's reasoning abilities and the contribution of the chosen encoder and resolution.", "section": "4.4 Ablation study"}, {"figure_path": "JxOQeg1NkH/tables/tables_18_1.jpg", "caption": "Table 5: Ablation study of training strategies on MLLM reasoning benchmarks.", "description": "This table presents the results of an ablation study evaluating the impact of different training strategies on the performance of Multimodal Large Language Models (MLLMs) across various reasoning benchmarks.  Each row represents a different experiment, indicated by \"Ex1\" through \"Ex6\". Each column represents a dataset included in the training: LLaVA 1.5, ShareGPT4V-SFT, LLaVA-Next, and Robo-300k. A checkmark (\u2713) indicates that the corresponding dataset was used in the experiment's training.  The remaining columns show the performance on the benchmarks GQA, POPE, and RoboVQA4. The results help determine which dataset combinations are most effective for training robust MLLMs.", "section": "4.4 Ablation study"}, {"figure_path": "JxOQeg1NkH/tables/tables_18_2.jpg", "caption": "Table 6: Ablation study of policy head design on manipulation dataset.", "description": "This table presents the results of an ablation study comparing different policy head designs for robot manipulation.  The study evaluates the accuracy ('Acc (Seen)') of the models on seen tasks using three different policy head architectures: MLP\u00d72 (two separate MLPs for position and direction prediction), MLP\u00d71 (a single MLP for both), and (SSM block+MLP)\u00d72 (two MLPs preceded by an SSM block).  The table also lists the number of parameters in each policy head and its percentage relative to the overall model size. The goal is to demonstrate that minimal fine-tuning parameters are needed to obtain good manipulation performance, suggesting that the reasoning capabilities of the model are more crucial than the complexity of the policy head.", "section": "4.4 Ablation study"}]