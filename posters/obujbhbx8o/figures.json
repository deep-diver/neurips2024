[{"figure_path": "ObUjBHBx8O/figures/figures_0_1.jpg", "caption": "Figure 1: An illustration of the cow/camel classification task. Red dotted boxes indicate samples where spurious correlations do not hold.", "description": "This figure shows examples of cow and camel images used in a classification task.  The images are categorized by their background (desert or pasture).  The red dotted boxes highlight examples where the typical spurious correlation (cow in pasture, camel in desert) does *not* hold, which is crucial for illustrating the concept of spurious correlations and the need for methods robust against them.", "section": "1 Introduction"}, {"figure_path": "ObUjBHBx8O/figures/figures_7_1.jpg", "caption": "Figure 2: Distributions of disagreement probabilities for each sample within bias-aligned and bias-conflicting groups.", "description": "This figure shows the distribution of disagreement probabilities for bias-aligned and bias-conflicting samples in the C-MNIST dataset with different bias-conflicting ratios (0.5%, 1%, and 5%).  The x-axis represents the disagreement probability, which is the probability that the prediction of a biased model disagrees with the true label. The y-axis represents the percentage of samples within each group that fall into each bin of disagreement probability.  It demonstrates that the disagreement probability can effectively distinguish between bias-aligned and bias-conflicting samples, with bias-aligned samples having lower disagreement probabilities and bias-conflicting samples having higher disagreement probabilities.  This supports the effectiveness of the proposed DPR method that leverages this disagreement probability to improve model robustness.", "section": "6 Experiments"}, {"figure_path": "ObUjBHBx8O/figures/figures_8_1.jpg", "caption": "Figure 3: Average loss of randomly initialized, pretrained, and biased models on bias-aligned and bias-conflicting groups. The error bars represent the standard deviations over three trials.", "description": "This figure shows the average loss of three different model types (randomly initialized, pretrained, and biased) on bias-aligned and bias-conflicting groups for two datasets (C-MNIST with 0.5% bias-conflicting samples and BFFHQ).  The results illustrate that randomly initialized and pretrained models have similar average losses across both groups.  In contrast, the biased model exhibits significantly higher average loss on the bias-conflicting group compared to the bias-aligned group, supporting the assumption made in the DPR method that biased models perform worse on bias-conflicting samples.", "section": "Ablation study"}, {"figure_path": "ObUjBHBx8O/figures/figures_14_1.jpg", "caption": "Figure 1: An illustration of the cow/camel classification task. Red dotted boxes indicate samples where spurious correlations do not hold.", "description": "This figure illustrates the challenge of spurious correlations in image classification.  The task is to classify images as either cows or camels.  However, a significant number of cow images have a pasture background, while most camel images show a desert setting.  This creates a spurious correlation, where the background becomes a strong predictor of the class label, rather than the actual animal characteristics.  The red dotted boxes highlight examples where this spurious correlation does *not* hold \u2013 a camel in a pasture or a cow in a desert.", "section": "1 Introduction"}]