[{"type": "text", "text": "Preference-based Pure Exploration ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Apurv Shukla\u2217 ", "page_idx": 0}, {"type": "text", "text": "Debabrota Basu ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Department of ECE, Texas A&M University E\u00b4quipe School, Univ. Lille, Inria, CNRS College Station, TX 77840 Centrale Lille, UMR-9189 - CRIStAL, France apurv.shukla@umich.edu debabrota.basu@inria.fr ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We study the preference-based pure exploration problem for bandits with vectorvalued rewards. The rewards are ordered using a (given) preference cone $\\mathcal{C}$ and our the goal is to identify the set of Pareto optimal arms. First, to quantify the impact of preferences, we derive a novel lower bound on the sample complexity for identifying the most preferred policy with confidence level $1-\\delta$ . Our lower bound elicits the role played by the geometry of the preference cone and punctuates the difference in hardness compared to existing best-arm identification variants of the problem. We further explicate this geometry when rewards follow Gaussian distributions. We then provide a convex relaxation of the lower bound. and leverage it to design Preference-based Track and Stop (PreTS) algorithm that identifies the most preferred policy. Finally, we show that sample complexity of PreTS is asymptotically tight by deriving a new concentration inequality for vector-valued rewards. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Following COVID-19, the importance of reliable clinical trials and corresponding data acquisition to design effective drugs has gained wider recognition. However, conducting large-scale clinical trials is cost and time intensive as it requires working with large number of patients and following-up their medical conditions over time. In the past two decades, this has led to doubling in the cost to bring a drug to the market, i.e., to $\\mathbb{S}2.6$ billion with a 12-year drug development horizon and $90\\%$ failure rate during the clinical trial (Mullard, 2014; Sun et al., 2022). However, due to the rise of systematic data acquisition about biological systems, pharmaceutical firms are interested in harvesting the collected data for drug discovery (Gaulton et al., 2012; Reker and Schneider, 2015). Thus, machine learning-based methods are increasingly studied and deployed as a promising avenue for identifying potentially successful drugs with less patient involvement, increasing the \u201chit rate\u201d, and speeding up the development process (Jayatunga et al., 2022; Smer-Barreto et al., 2023; Sadybekov and Katritch, 2023; Hasselgren and Oprea, 2024). But deciding whether a drug is successful depends on multiple and often conflicting objectives regarding safety, efficacy, and pharmacokinetic constraints (Lizotte and Laber, 2016). For example, COV-BOOST (Munro et al., 2021) demonstrates a phase II vaccine clinical trial conducted on 2883 participants to measure the immunogenicity indicators (e.g. cellular response, anti-spike IgG and $\\mathrm{{NT}_{50}}$ ) of different Covid19 vaccines as a booster (third dose). Experts decide how different indicators are preferred over one another, and above different thresholds (Jayatunga et al., 2022). This motivates us to study a sequential decision-making problem, where we aim to conduct minimum number of experiments to acquire informative data, and to reliably validate a hypothesis with multiple objectives by imposing preferences over them. ", "page_idx": 0}, {"type": "text", "text": "Problems of such nature can be modeled as a multi-armed bandit (in brief, bandits), which is an established framework for sequential decision-making under uncertainty (Lattimore and Szepesva\u00b4ri, 2020). In bandits, a learner has access to an instance of $K$ decisions (or arms). Each arm $k\\ \\in$ $\\{1,\\ldots,K\\}$ corresponds to a probability distribution $P_{k}$ of feedback (rewards) with unknown means $\\mu_{k}$ . At each step $t\\in\\mathbb{N}$ , the learner interacts with the instance by taking a decision $k_{t}$ (analogously pulling an arm), and observes a noisy reward $R_{t}$ from the corresponding distribution of rewards $P_{k_{t}}$ . The goal of the learner is to identify the arm with the highest expected reward over a certain confidence level through minimum number of interactions with the instance. This is popularly known as a fixed-confidence Best Arm Identification $(B A I)$ in bandit literature (Jamieson and Nowak, 2014; Garivier and Kaufmann, 2016; Soare et al., 2014), which is a special case of pure exploration problems (Even-Dar et al., 2006; Bubeck et al., 2009; Auer et al., 2016). ", "page_idx": 1}, {"type": "text", "text": "The bandit literature spanning over a century mostly focuses on a scalar reward, i.e., a single objective. In our problem, each reward $R_{t}$ is a real-valued vector of $L\\in\\mathbb N$ objectives, and thus, the unknown mean vector of each arm $\\mu_{k}\\in\\mathbb{R}^{L}$ . Since the objectives can be often conflicting, there might not exist a single best arm. Rather, there exists a Pareto Optimal Set of arms (Drugan and Nowe, 2013; Auer et al., 2016). Given a set of preferences over the objectives, the Pareto Optimal Set consists of arms whose mean vectors dominate the mean vectors of any other arm outside the set. Keeping generality, we assume that preferences are defined by a cone of vectors $\\mathcal{C}\\subseteq\\mathbb{R}^{L}$ . Every $\\mathcal{C}$ induces a set of partial or incomplete orders over the $L$ objectives (Jahn et al., 2009; L\u00a8ohne, 2011). Given the preference cone $\\mathcal{C}$ , we aim to exactly identify the complete Pareto Optimal Set with a confidence level $\\left(1-\\delta\\right)\\in\\left[0,1\\right)$ using as few interactions as possible. We refer to this problem Preference-based Pure Exploration $(P r e P E x)$ ). ", "page_idx": 1}, {"type": "text", "text": "Recently, Auer et al. (2016); Kone et al. (2023a,b); crepon et al. (2024) consider a special case of PrePEx, where the preference is known. To the best of our knowledge, Ararat and Tekin (2023) and Korkmaz et al. (2023) are the only studies of PrePEx from frequentist and Bayesian angles, respectively. Here, we consider a frequentist approach as in (Ararat and Tekin, 2023). However, their goal is to identify points that are in the Pareto Optimal Set or very close to it. In contrast, we focus on exactly identifying the Pareto Optimal Set. Additionally, (Ararat and Tekin, 2023) propose gap-based elimination algorithm to solve the problem generalising the algorithm of (Even-Dar et al., 2006). But in BAI, there is another paradigm of designing efficient algorithms that solves and tracks the exact lower bound on the expected time to identify the best arm $(\\bar{1}-\\delta)$ correctly (Garivier and Kaufmann, 2016; Degenne and Koolen, 2019). We explore this paradigm for PrePEx and ask two questions: ", "page_idx": 1}, {"type": "text", "text": "What is the exact lower bound of PrePEx for identifying the Pareto Optimal Set, and how to design a computationally tractable algorithm matching this bound? ", "page_idx": 1}, {"type": "text", "text": "We address them affirmatively in our contributions: ", "page_idx": 1}, {"type": "text", "text": "1. Lower Bound for PrePEx. In Theorem 3.1, we study hardness of PrePEx problems by deriving the novel lower bound on the expected sample complexity of any algorithm to yield the exact Pareto Optimal Set with confidence $(1-\\delta)$ . The challenge here is to extend the classical BAI lower bound (Garivier and Kaufmann, 2016) to a set of confusing instances given $\\mathcal{C}$ . We observe that unlike BAI, distinguishability of two arms in PrePEx depends on their projections on the cone polar to $\\mathcal{C}$ . We also show that our lower bound generalises the lower bound for pure exploration under known constraints (Carlsson et al., 2024). Additionally, we provide an exact characterization the lower bound further for Gaussian reward distributions in Theorem 3.2. It shows that the hardness depends on the bilinear projection of the mean matrix of arms onto the boundary of a normal cone of policies and the preferences. This is novel w.r.t. the existing gap-dependent lower bounds that hold either for a narrow range of $\\mu_{a}$ \u2019s (Ararat and Tekin, 2023), or fixed preference (Kone et al., 2023a). ", "page_idx": 1}, {"type": "text", "text": "2. Algorithm Design. First, we observe that the optimisation problem in our lower bound involves minimisation over a non-convex set. We provide a convex relaxation of the problem based on ideas from disjunctive programming (Theorem 4.1 and 4.2). We then leverage this lower bound to propose a novel Track-and-Stop (Garivier and Kaufmann, 2016) style algorithm, called PreTS (Preference-based Track-and-Stop). In Theorem 4.3, we devise a new stopping rule that can handle the preference-aligned suboptimality gaps between the arms. ", "page_idx": 1}, {"type": "text", "text": "3. Sample Complexity Analysis. Finally, we provide an upper bound on sample complexity of PreTS. This requires us to define a distance metric between two pareto sets of arms, and proving a concentration bound with respect to this metric (Theorem 5.1). In Theorem 5.2, we prove that sample complexity of PreTS matches the convexified lower bound up to constants. ", "page_idx": 1}, {"type": "text", "text": "1.1 Related Works ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In the past decade, works on multi-armed bandits also focuses on pure-exploration in addition to regret minimization. Regret minimization and pure-exploration differ in the sense when arms in pure-exploration are immediately discarded upon being deemed as sub-optimal, whereas, in the regret minimization setting, sub-optimal arms may still be played since they provide additional information about other arms. Pure-exploration problems have been considered in two settings: fixed-budget and fixed-confidence. The fixed-budget setting aims at bounding the probability of underestimating the best arm given a budget of samples. Audibert and Bubeck (2010) propose the first algorithm for the fixed budget setting. Here, the budget is divided into $K-1$ rounds and at the end of every round, the arms with the lowest empirical mean are discarded. On the other hand, best-arm identification is a version of the pure-exploration problem with scalar rewards (Even-Dar et al., 2006). In this setting, we are given a $\\delta\\in(0,1)$ and the goal is to identify the best-arm with probability at least $1-\\delta$ . Several strategies such as those based on elimination, adaptivity, racing, upper-confidence bounds have been proposed to minimize the number of expected pulls of an arm in the fixed confidence setting by (Kalyanakrishnan et al., 2012; Gabillon et al., 2012; Jamieson et al., 2014; Garivier and Kaufmann, 2016; Jedra and Proutiere, 2020). Arm rewards can be modeled as a vector with Gaussian Process (Zuluaga et al., 2016), linear rewards (Drugan and Nowe, 2013; Lu et al., 2019), and non-parametric rewards (Turgay et al., 2018), which can include contextual bandit formulations (Tekin and Turgay, 2017; Shukla, 2022). In recent past, the pure exploration techniques have been successfully applied in hyperparameter tuning (Li et al., 2018) and black-box optimization problems (Contal et al., 2013; Wang et al., 2021, 2022) demonstrating considerable performance gains. ", "page_idx": 2}, {"type": "text", "text": "In a marked deviation, given an instance of the bandit problem, the goal of this paper is to identify the entire Pareto front. A key observation in this regard is that there might be arms, which are sub-optimal for almost every objective but still lie on the Pareto front. Further, since sampling an arm returns a vector of rewards determining an arm-strategy that reduces the uncertainty in the estimate of every reward function is challenging. An immediate consequence of these differences is the fact that the complexity of identifying the Pareto front is different from that of best arm identification. Auer et al. (2016) consider the Pareto front identification problem in the multi-armed bandit model and establish sample complexity bounds for the problem in terms of relevant problem parameters in the fixed-confidence setting. The multi-armed bandit problem is further studied under cone-based preferences by Ararat and Tekin (2023). The main contribution of (Ararat and Tekin, 2023) are bounds on the sample complexity of the problem in terms of gap-based notions that depend on the cone. Karag\u00a8ozl\u00a8u et al. (2024) builds upon this work to introduce adaptive elimination based algorithms for learning the Pareto front under incomplete preferences. When the reward vectors are Gaussian processes Korkmaz et al. (2023) propose an elimination based algorithm based for identifying the Pareto front. The goal in these works is to identify the set of arms that are $\\epsilon$ close to the Pareto front as the sample complexity to identify the exact Pareto set can be very large. Kone et al. (2023a) consider the problem of identifying a relevant subset of the Pareto set using a single sampling strategy Adaptive Pareto Exploration, along with different stopping rules to consider variations of the Pareto Set Identification problem. crepon et al. (2024) consider the exact Pareto front identification problem in the multi-armed bandit setting but with fixed and known preference cone. They propose a lower bound and a computationally efficient gradient-based algorithm to implement a track-and-stop based strategy. To the best of our knowledge, ours is the first work to consider the exact Pareto front identification problem from a pure-exploration perspective. Therefore, our proposed framework can be used for identifying the Pareto front given a preference cone for several variants of the bandit problem including the standard multi-armed bandit problem, linear bandits, etc. ", "page_idx": 2}, {"type": "text", "text": "2 Preference-based Pure Exploration Problem ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we formalise the fixed-confidence setting of preference-based pure exploration and introduce the notations. ", "page_idx": 2}, {"type": "text", "text": "Notations. For $n\\in\\mathbb{N}$ , let $[n]$ denote the set $\\{1,2,\\ldots,n\\}$ . We use $\\|\\cdot\\|_{1},\\|\\cdot\\|_{2},\\|\\cdot\\|_{\\infty}$ to denote the $\\ell_{1}$ -norm, $\\ell_{2}$ -norm and $\\ell_{\\infty}$ -norm, respectively. For a vector $z$ , $_z^{(\\ell)}$ denotes its $\\ell^{t h}$ component. Let $e_{\\ell}$ denote the vector with 1 in the $\\ell^{t h}$ position and zero otherwise. $\\Delta_{K}$ denotes the simplex on $[K]$ . $d_{\\mathrm{KL}}\\left(P,Q\\right)$ measures the KL-divergence between distributions $P$ and $Q$ . $\\operatorname{vect}(A)$ is the vectorized version of matrix $A$ . 1 is the vector of all $\\mathrm{1\\,\\dot{s}}$ . Further details of notations are deferred to Appendix A. ", "page_idx": 2}, {"type": "text", "text": "Formulation. In PrePEx, a learner has access to a bandit instance with $K$ arms. Each arm $k\\in[K]$ corresponds to a reward distribution $\\nu_{k}$ over $\\mathbb{R}^{L}$ with unknown mean $\\mu_{k}\\in\\mathbb{R}^{L}$ . Here, $L$ denotes the number of objectives corresponding to each arm. Thus, a bandit instance can be specified with the vector of mean rewards $\\{\\mu_{k}\\}_{k=1}^{K}$ . For brevity, we represent them with a matrix $\\dot{M}\\in\\mathbb{R}^{L\\times K}$ such that its $k^{\\mathrm{th}}$ column is $\\mu_{k}$ . At each time $t\\in\\mathbb{N}$ , the learner pulls an arm $k_{t}\\in[K]$ and observes the corresponding reward vector $R_{t}$ sampled from $\\nu_{k_{t}}$ . In pure exploration, the learner typically focuses on finding the best arm, i.e. the arm with highest mean (Garivier and Kaufmann, 2016). In pure exploration, a more general setting of BAI, the learner aims to find a policy $\\pi\\in\\Delta_{K}$ that dictates the arm-proportion to choose in order to maximize the expected reward obtained from the instance. ", "page_idx": 3}, {"type": "text", "text": "Following the vector optimization literature (Jahn et al., 2009; Ararat and Tekin, 2023), we assume that the learner has additionally access to an ordering cone $\\mathcal{C}$ . ", "page_idx": 3}, {"type": "text", "text": "Definition 2.1 (Ordering Cone). A set $\\mathcal{C}\\subseteq\\mathbb{R}^{L}$ is called a cone if $v\\in\\mathcal{C}$ implies that $\\alpha v\\in{\\mathcal{C}}$ for all $\\alpha\\geq0$ . A solid cone has a non-empty interior, i.e., $\\operatorname{int}(\\mathcal{C})\\neq\\emptyset$ . A pointed cone contains the origin. A closed convex cone that is both pointed and solid is called an ordering cone. ", "page_idx": 3}, {"type": "text", "text": "An ordering cone can be both polyhedral and non-polyhedral. Following the literature (Ararat and Tekin, 2023; Karago\u00a8zlu\u00a8 et al., 2024), we consider access to a polyhedral ordering cone. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.2 (Polyhederal Cone). A cone $\\mathcal{C}$ is a polyhedral cone $i f{\\mathcal{C}}\\triangleq\\{x\\in\\mathbb{R}^{L}\\mid A x\\geq0\\}$ , where $A\\in\\mathbb{R}^{K\\times L}$ with rows $a_{i}^{\\top}$ . $A$ is called the half-space representation of $\\mathcal{C}$ . ", "page_idx": 3}, {"type": "text", "text": "Each polyhedral ordering cone induces a set of partial order on the reward vectors in $\\mathbb{R}^{L}$ . To ignore the redundancies and to focus on the bandit problem, we further assume that $A$ is full row-rank and $\\|A_{i}\\|_{2}=1$ (Ararat and Tekin, 2023). Hereafter, we call them preference cones, and the vectors in the cone as the preferences. We refer to (Jahn et al., 2009; Lo\u00a8hne, 2011) for further details on cones. ", "page_idx": 3}, {"type": "text", "text": "Example 2.1 (Preference cones). The positive orthant $\\mathbb{R}_{+}^{L}$ is a polyhedral cone. This is the one used in pareto-set identification literature (Auer et al., 2016; Kone et al., $2023b$ ; crepon et al., 2024). The cones with all non-negative entries are called solvency cones and used in finance (Kabanov, 2009). Another simple example is $\\mathcal{C}_{\\pi/3}\\triangleq\\{(r\\cos\\theta,r\\sin\\theta)\\in\\mathbb{R}^{2}\\ |\\ r\\geq0\\land\\theta\\in[0,\\pi/3]\\}$ , i.e. all the 2-dimensional vectors that makes an angle less than $\\pi/3$ with the $x$ -axis. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.3 (Partial Order). For every $\\mu,\\mu^{\\prime}\\,\\in\\,\\mathbb{R}^{L},\\mu\\,\\preceq c\\,\\,\\mu^{\\prime}\\,\\,i f\\,\\mu\\,\\in\\,\\mu^{\\prime}+\\mathcal{C}$ and $\\mu\\,\\prec_{\\mathcal{C}}\\ \\mu\\ i f$ $\\mu\\in\\mu^{\\prime}+i n t(\\mathcal{C})$ . Alternatively, $\\mu\\preceq c\\ \\mu^{\\prime}$ is equivalent to $z^{\\top}(\\mu-\\lambda-\\lambda)--\\lambda$ ", "page_idx": 3}, {"type": "text", "text": "The partial order induced by $\\mathcal{C}$ induces further order over the set of arms $[K]$ . ", "page_idx": 3}, {"type": "text", "text": "Definition 2.4 (Order over arms). Consider two arms $i,j\\in$ $[K]$ . (i) Arm $i$ weakly dominated by arm $j$ iff $\\mu_{j}\\mathrm{~}\\preceq\\!c\\mathrm{~}\\mu_{i}$ . $(i i)$ Arm i dominates arm $j$ iff $\\mu_{i}\\prec_{C\\backslash\\{0\\}}\\mu_{j}$ . (iii) Arm i strongly dominates arm j iff \u00b5i \u227aC \u00b5j. ", "page_idx": 3}, {"type": "text", "text": "Definition 2.5 (Pareto Optimal Set). An arm $i\\in[K]$ is Pareto Optimal if it is not dominated by any other arm w.r.t. the cone $\\mathcal{C}$ . The Pareto Optimal Set $\\mathcal{P}^{*}$ is defined as the set of all Pareto Optimal arms. Let $\\mathcal{Z}$ be the set of all Pareto Frontiers on $[\\dot{0},1]^{K}$ . ", "page_idx": 3}, {"type": "image", "img_path": "GvQU54uA7u/tmp/ef217381a9c4aef26123846b1eea9d1aeb30e6cb0d9295624434053182172d9b.jpg", "img_caption": ["Figure 1: Effect of cone selection on size of Pareto optimal set "], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Given a preference cone, a learner aims to exactly identify the Pareto Optimal Set from a finite set of arms $[K]$ whose mean rewards belong to the Pareto Optimal Set w.r.t. $\\mathcal{C}$ . Alternatively, this vector optimization problem can be represented in the policy space as finding a policy $\\pi\\in\\Delta_{K}$ supported on the Pareto optimal set of arms. This is given by the following vector optimization problem: ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 3}, {"type": "equation", "text": "$$\nV(M)=\\operatorname*{max}_{\\pi\\in\\Delta_{K}}\\;M\\pi\\;\\mathrm{over}\\,{\\mathcal C}.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "In this context, we denote the set of Pareto optimal policies as $\\Pi^{*}(M)\\triangleq\\arg\\operatorname*{max}_{\\pi\\in\\Delta_{K}}$ $M\\pi$ over $\\mathcal{C}$ .   \nWe assume that $\\Pi^{*}(M)$ is non-empty. ", "page_idx": 3}, {"type": "text", "text": "Example 2.2 (Pareto Optimal Sets for different cones). Figure 1 illustrates the Pareto Optimal Sets among 2-dimensional mean vectors of 200 randomly selected arms under preference cones $\\mathcal{C}_{\\pi/2}$ and $\\mathcal{C}_{\\pi/3}$ . We observe that the Pareto Optimal Sets for them (in pink and blue respectively), are completely different for same set of arms. Thus, we have to adapt to the available preferences to solve the aforementioned problem. As noted later, the geometry of this cone plays a crucial role in determining the Pareto front. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "text", "text": "In PrePEx, we consider the problem of Equation (1), when the mean matrix $M$ is unknown a priori but bounded, i.e., the entries of $M$ , $M_{i j}\\in[M_{\\operatorname*{min}},M_{\\operatorname*{max}}]$ , $M\\in\\mathcal{M}$ . Having identified the policy, will lead us to identify the true Pareto front $\\mathcal{P}^{*}$ . In the noisy feedback setting, the reward at time $t$ is $R_{t}\\,=\\,\\mu_{k_{t}}\\,+\\,\\eta_{t}$ , where $\\eta_{t}\\in\\mathbb{R}^{L}$ is the noise vector. We assume that the noise vectors $\\eta_{t}$ are independent of $\\mu_{k_{t}}$ and also across time. Further, they are sub-Gaussian with parameter $\\sigma$ and adapted to the filtration $\\mathcal{F}_{t}$ , which is a standard assumption in the literature. A policy $\\pi\\in\\Pi\\subset\\Delta^{K}$ is a randomized mapping from the history $\\mathcal{H}_{t}$ to the probability simplex over the set of arms $[K]$ . In Preference-based Pure EXploration (PrePEX) problem, the goal of the learner is to identify a Pareto optimal policy in $\\Pi^{*}$ (Equation (1)) given an instance $M$ and a preference cone $\\mathcal{C}$ while observing only noisy rewards from the arms, and also using as few observations as possible. ", "page_idx": 4}, {"type": "text", "text": "Definition 2.6 $(1-\\delta)$ -correct PrePEX). An algorithm for Preference-based Pure Exploration $(P r e P E x)$ is said to be $(1-\\delta)$ correct if with probability $1-\\delta$ , it recommends a Pareto optimal policy $\\pi\\in\\Pi^{*}$ . ", "page_idx": 4}, {"type": "text", "text": "For example, a pareto optimal policy for $\\mathcal{C}_{\\pi/2}$ would be a distribution in $\\Delta_{K}$ with support on the arms corresponding to the pink reward vectors (Figure 1). For $\\mathcal{C}_{\\pi/3}$ , it would be one with support on blue points. ", "page_idx": 4}, {"type": "text", "text": "3 Lower Bound on Sample Complexity ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "We begin by deriving a KL-divergence based lower bound for PrePEx using techniques from (Garivier and Kaufmann, 2016). Our lower bound is based on establishing a change-of-measure argument in the spirit of (Graves and Lai, 1997; Kaufmann et al., 2016). The lower bounds are derived first by defining a set of alternating instances $\\Lambda$ for a given bandit instance and then by trying to compute an optimal allocation policy $w\\in\\Delta_{K}$ that maximises the sum of minimum KL-divergence between any instance in $\\Lambda$ and the bandit instance under interaction. The key insight of our work is to formulate the identification of Pareto Set problem in the policy space rather than in the arm space as done in antecedent literature. This formulation helps us to derive the KL-based lower bound, which is more general than the existing suboptimality gap-based lower bounds (Auer et al., 2016; Ararat and Tekin, 2023; crepon et al., 2024). ", "page_idx": 4}, {"type": "text", "text": "The Alternating Instances with respect to Pareto Fronts. The learner needs to distinguish between all instance $\\tilde{M}\\;\\;\\in\\;\\mathcal{M}\\setminus\\{M\\}$ for which the Pareto front associated with $\\tilde{M}$ is different from the one associated with $M$ . At first, given an optimal policy of $M$ , say $\\pi^{*}$ , it would appear that the set of confusing instances is $\\Lambda_{\\pi^{*}}\\left(\\bar{M}\\right)^{\\mathrm{naive}}\\triangleq\\left\\{\\tilde{M}\\in\\bar{\\mathcal{M}}:\\tilde{M}\\pi^{*}\\preceq c\\mathrm{~max}_{\\pi\\in\\Pi}\\tilde{M}\\pi\\right\\}$ . However, this is fallacious since the instances whose rewards dominate $M$ can also confuse a policy $\\pi$ . Given a $\\pi^{\\star}$ , the correct alternating set is the set of instances in $\\mathcal{M}$ whose Pareto optimal set is not dominated by $\\pi^{\\star}$ corresponding to $M$ . ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Lambda_{\\pi^{*}}\\left(M\\right)\\triangleq\\bigg\\{\\tilde{M}\\in\\mathcal{M}\\setminus\\{M\\}:\\underset{\\pi\\in\\Pi}{\\operatorname*{max}}\\tilde{M}\\pi\\underset{\\pi\\in\\Pi}{\\not\\leq}\\tilde{M}\\pi^{*}\\bigg\\}}\\\\ &{\\qquad\\qquad=\\bigg\\{\\tilde{M}\\in\\mathcal{M}\\setminus\\{M\\}:\\exists\\boldsymbol{z}\\in\\mathcal{C}\\mathrm{~s.t.~}\\underset{\\pi\\in\\Pi}{\\operatorname*{max}}\\boldsymbol{z}^{\\top}\\tilde{M}\\pi>\\boldsymbol{z}^{\\top}\\tilde{M}\\pi^{*}\\bigg\\}\\mathrm{~.~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "With this new alternate set defined, we now establish lower bounds on the performance of any PrePEX algorithm. ", "page_idx": 4}, {"type": "text", "text": "Theorem 3.1 (Lower Bound). Given a bandit model $M\\in\\mathcal{M}$ , a preference cone $\\mathcal{C}$ , and a confidence level $\\delta\\in[0,1)$ , the expected stopping time of any $(1-\\delta)$ -correct PrePEx algorithm, to identify the Pareto Optimal Set is ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\mathbb{E}[\\tau]\\geq\\mathcal{T}_{M,\\mathcal{C}}\\log\\left(\\frac{1}{2.4\\delta}\\right),\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where, the expectation is taken over the stochasticity of both the algorithm and the bandit instance. Here, $\\mathcal{T}_{M,\\mathcal{C}}$ is called the characteristic time of the PrePEx instance $(\\mathcal{M},\\mathcal{C})$ and is expressed as ", "page_idx": 4}, {"type": "equation", "text": "$$\n(\\mathcal{T}_{M,\\mathcal{C}})^{-1}\\triangleq\\operatorname*{sup}_{w\\in\\Delta^{K}}\\operatorname*{inf}_{\\pi^{*}\\in\\Pi^{\\setminus}\\{\\pi^{*}\\}}\\operatorname*{inf}_{\\tilde{M}\\in\\partial\\Lambda_{\\pi^{*}}(M)}\\operatorname*{inf}_{z\\in\\mathcal{C}}\\sum_{k=1}^{K}w_{k}d_{K L}\\left(z^{\\top}M_{k},z^{\\top}\\tilde{M}_{k}\\right)\\,,\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Proof Intuition. First, we observe that an instance $\\tilde{M}$ is in alternating set if there exists a $\\pi\\in\\Pi\\backslash\\{\\pi^{*}\\}$ and $z\\in{\\mathcal{C}}$ , such that $z^{\\top}\\tilde{M}(\\pi-\\pi^{*})>0.$ . If $\\pi$ and $\\pi^{*}$ were pure strategies, it would have been exactly $\\operatorname*{inf}_{z\\in C\\setminus\\{0\\}}z^{\\top}(\\tilde{M}_{a}-\\tilde{M}_{a^{*}})>0$ . Let us denote the $z$ achieving the inf as $z_{\\mathrm{inf}}$ , i.e., the preference for which $\\tilde{M_{a}}$ and $\\tilde{M}_{a^{*}}$ are least distinguishable. Thus, we observe that $z_{\\mathrm{inf}}^{\\top}\\tilde{M}_{a}$ exactly functions as the mean of the arm $a$ in an instance $\\tilde{M}$ , whereas $z_{\\mathrm{inf}}^{\\top}(\\tilde{M}_{a^{*}}-M_{a})$ acts as the suboptimality gap. Now, we extend this idea in the classical lower bound scheme to get a nested optimization problem with inf over $z\\in{\\mathcal{C}}$ and $\\tilde{M}$ in the alternating set, and a sup over allocations $w\\in\\Delta_{K}$ . We further show that the inf for M\u02dc appears at the boundary of the alternating set defined as $\\partial\\Lambda(M)$ . ", "page_idx": 5}, {"type": "text", "text": "Discussions. (i) Novelty: In the best of our knowledge, this is the first lower bound for PrePEx with fixed confidence with an explicit KL-based dependence. All the existing lower bounds are gap dependent, and valid for a narrow range on mean vectors or known preference cone, i.e. the right orthant. Our proof does not need such assumptions. The gap-dependent bounds are special case of ours (cf. Theorem 3.2 for the case of Gaussian rewards). ", "page_idx": 5}, {"type": "text", "text": "(ii) Geometric Insights. Theorem 3.1 provides multiple geometric insights into the affect of the ordering cone $\\mathcal{C}$ on the characteristic time. First, the alternating set $\\Lambda_{\\pi^{*}}\\left(M\\right)$ is piece-wise polyhedral and non-convex. This is a concern that we address later in Section 4.1. Second, there is an additional minimization over the vectors lying in the cone $\\mathcal{C}$ . We interpret the minimization over vectors in the cone as a instance- and preference-dependent scalarization of the distance between the given instance $M$ and the corresponding most-confusing instance in $\\Lambda_{\\pi^{*}}$ $(M)$ . Third, in the proof, we show that the reward gap using the best policy $\\pi^{*}$ and a given policy $\\pi$ for the most confusing instance belongs to the polar cone ${\\mathcal{C}}^{\\circ}$ of the preference cone $\\mathcal{C}$ . The most confusing lies on the boundary of this polar cone and its projection the policy gaps $(\\pi^{*}-\\pi)$ . Further insights can be obtained by imagining the polar cone to be orthogonal to the cone $\\mathcal{C}$ . Then, the vector of reward-gaps for the most confusing instance for every objective is orthogonal to the generating rays of $\\mathcal{C}$ . These novel geometric insights are complementary to the existing algebraic and statistical insights available in the lower bound literature (Kone et al., $2023\\mathrm{a}$ ; Ararat and Tekin, 2023). ", "page_idx": 5}, {"type": "text", "text": "3.1 Characteraization of Lower Bounds for Gaussians ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "To understand our lower bound better and to compare it with the literature, we present a reduction for Gaussian bandits. In Gaussian Bandits, we assume that the reward vectors of arm $a\\in[K]$ are generated from a multivariate Gaussian distribution $\\mathcal{N}(\\mu_{a},\\Sigma)$ , where the covariance is a diagonal matrix: $\\Sigma\\triangleq\\operatorname{Diag}(\\sigma_{1}^{2},\\dots,\\sigma_{L}^{2})$ . ", "page_idx": 5}, {"type": "text", "text": "Theorem 3.2 (Lower Bound for Gaussian Bandits). 1. Given any $\\pi^{\\star}\\in\\Pi^{*}(M)$ and $N(\\pi^{*})$ being the set of neighbouring policies of $\\pi^{*}$ , the most confusing instance of $M$ belongs to the set ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\in\\mathcal{M}\\setminus\\{M\\}:\\tilde{M}=M+\\frac{1}{2}(\\alpha(z)\\mathbf{1}_{L}-\\mathrm{vect}(\\Sigma))(\\pi^{*}-\\pi)^{\\top}\\forall\\pi\\in N(\\pi^{*})\\land z\\in\\mathcal{C}\\setminus\\{0\\}\\Big\\}\\,,}\\\\ &{\\textit{e}\\alpha(z)\\triangleq\\frac{\\sum_{i,\\ell,k}\\lambda_{i}v_{i}^{(\\ell)}\\Delta_{k}\\mu_{k}^{(\\ell)}}{\\sum_{i,\\ell,k}\\frac{\\lambda_{i}v_{i}^{(\\ell)}\\Delta_{k}^{2}}{w_{k}\\pi\\frac{2}{k}}}=\\frac{z^{\\top}M(\\pi-\\pi^{*})}{(\\sum_{l}z^{l})\\sum_{k}\\frac{1}{w_{k}}\\left(1-\\frac{\\pi_{k}^{k}}{\\pi_{k}}\\right)^{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "2. The inverse of characteristic time, i.e. $(\\mathcal{T}_{M,\\mathcal{C}}^{\\mathrm{Gauss}})^{-1}$ , for an instance $(M,{\\mathcal{C}})$ is ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{w\\in\\Delta^{K}}\\ \\operatorname*{inf}_{\\pi\\in N(\\pi^{*})}\\ \\operatorname*{min}_{z\\in{\\mathcal{C}}\\backslash\\{0\\}}\\left(1-\\alpha(z)-\\frac{1}{4\\alpha(z)}\\right)z^{\\top}M(\\pi^{*}-\\pi)\\,.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Consequences. First, we observe an interesting phenomenon that a bilinear projection of mean matrix $M$ on the preferences and policy gaps operates as an extension of suboptimality gap in classical BAI. This is a reminiscent of the lower bound for pure exploration under known linear constraints as in Carlsson et al. (2024) who show that the hardness of the problem depends only on the projection of the mean vector on the policy gap. In addition to similar projection structure, preferences introduce a novel bilinearity here. Second, we show how the lower bound inflates with the covariance matrix for each objective. This shows the richness of our KL-divergence based lower bound as opposed to gap-based bounds which have diffiuclty accomodating variance related terms directly. ", "page_idx": 5}, {"type": "text", "text": "Connection to existing results. Our result generalizes several existing lower bounds for BAI. ", "page_idx": 6}, {"type": "text", "text": "1. BAI lower bound. Our lower bound is able to recover that of Kaufmann et al. (2016) for the standard BAI problem with fixed confidence. In the case of the standard BAI problem, the ordering cone is given by ${\\mathcal{C}}\\triangleq\\mathbb{R}_{+}$ and therefore the minimization over $\\mathcal{C}$ in (3) becomes redundant. The definition of the alternating set is then given by the set of instances which have a different optimal arm than $\\mu$ which is exactly the set considered in (Kaufmann et al., 2016). ", "page_idx": 6}, {"type": "text", "text": "2. Pure exploration under known constraints. Our lower bound is able to recover the lower bound of Carlsson et al. (2023) for the BAI problem with fixed confidence and linear constraints. This is the case with $L=1$ and the ordering cone being ${\\mathcal{C}}\\triangleq\\mathbb{R}_{+}$ making the minimization over $z\\in{\\mathcal{C}}$ in (3) redundant. $\\Lambda_{\\pi^{*}}$ $(M)$ becomes $\\bar{\\Lambda_{\\pi^{*}}}\\left(M\\right)=\\{\\bar{\\tilde{\\mu}}:\\operatorname*{max}_{\\pi\\in\\Pi}\\tilde{\\mu}^{\\top}\\pi\\stackrel{\\cdot}{\\geq}\\mu^{\\top}\\pi^{*}\\}$ . ", "page_idx": 6}, {"type": "text", "text": "4 Algorithm Design: PreTS ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "In this section, we propose an algorithm that tracks the lower bound. However, this is not straightforward since the alternating set is non-convex. We first propose a convex relaxation for this set and then, design a Track and Stop style algorithm, called PreTS. ", "page_idx": 6}, {"type": "text", "text": "4.1 Convex Relaxation of the Lower Bound ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "One of the major differences regarding the structure of lower bounds compared to a standard BAI problem is that $\\Lambda_{\\pi^{*}}\\left(M\\right)$ is a piece-wise polyhederon, i.e., a union of hyperplanes. Each hyperplance corresponds to a policy $\\bar{\\pi}\\in\\bar{\\Pi}\\setminus\\{\\pi^{*}\\}$ . In order to make the optimization problem tractable and obtain a convex program, we relax $\\Lambda_{\\pi^{*}}\\left(M\\right)$ using its convex closure, denoted by ch $(\\Lambda_{\\pi^{*}}\\left(M\\right))$ . We note that the construction of such a convex relaxation for the purpose of track-and-stop (when the lower bound problem is non-convex) has been done in the MDP setting Al Marjani and Proutiere (2021). We define ch $(\\Lambda_{\\pi^{*}}\\left(M\\right))$ in Theorem 4.1 by formulating it as a disjunctive program, which we can reformulate further as a linear program (Balas, 1985). ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.1. Let $\\mathcal{F}\\,\\triangleq\\,\\cup_{\\Pi\\backslash\\pi^{*}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\,\\exists\\,z\\in\\mathcal{C},\\,\\langle\\nu e c t\\left(z^{\\top}(\\pi-\\pi^{*})\\right),\\nu e c t\\big(\\tilde{M}\\big)\\rangle=0\\right\\}$ . Fix $z\\in{\\mathcal{C}}$ such that $z=\\sum_{i}\\alpha_{i}v_{i}$ . Then, we have c $h\\left(\\mathcal{F}\\right)=\\mathcal{T}$ , where $\\mathcal{T}$ is defined as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{Z}\\triangleq\\{\\tilde{M}\\in\\mathcal{M}:\\gamma^{\\top}\\nu e c t(\\tilde{M})\\geq\\gamma_{0},\\gamma=\\sum_{i}u_{i}\\alpha_{i}\\nu e c t(v_{i}^{\\top}(\\pi-\\pi^{*})),\\gamma_{0}\\leq u_{i}\\sum_{i}\\alpha_{i}v_{i}^{\\top}\\pi^{*}\\}.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Using the convex hull (Eq. (4)), we quantify the optimal value for a given allocation $w$ as ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\overline{{\\mathcal{V}}}_{\\mathcal{C}}(w,M)\\triangleq\\operatorname*{min}_{\\tilde{M}\\in\\mathrm{ch}(\\Lambda_{\\pi^{*}}(M))}\\operatorname*{inf}_{z\\in\\mathcal{C}}\\sum_{k=1}^{K}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}\\tilde{M}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "The corresponding optimal allocation is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\overline{{w}}^{*}(M)=\\arg\\operatorname*{max}_{w\\in\\Delta^{K}}\\operatorname*{inf}_{\\pi^{\\in}\\Pi\\backslash\\pi^{*}\\atop\\pi^{*}\\in\\Pi^{*}(M)}\\operatorname*{min}_{\\tilde{M}\\in\\operatorname{ch}(\\Lambda_{\\pi^{*}}(M))}\\operatorname*{inf}_{z\\in\\mathcal{C}}\\sum_{k=1}^{K}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}\\tilde{M}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Hereafter, we consider Equation (5) as the optimization problem to be tracked. To compute $\\overline{{\\mathcal{V}}}_{\\mathcal{C}}(w,M)$ , we need access to the true instance $M$ which is not available to us. Our Track-and-Stop strategy is based on repeatedly sampling an arm to construct an estimate of $M$ , i.e. $M_{t}$ , and exploiting continuity properties of $\\overline{{\\nu}}_{c}(\\dot{w},M)$ to show that $\\overline{{\\nu}}_{c}(w,M_{t})\\to\\overline{{\\nu}}_{c}(w,M)$ and the cumulative number of arm plays $N_{t,k}\\rightarrow w_{k}$ , $w_{k}\\in\\overline{{w}}^{*}(M)$ . These properties ensure that it makes sense to design a Track and Stop style algorithm for this problem. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.2 (Analytical Properties). For all $M\\in\\mathbb{R}^{L\\times K}$ and all preference cones $\\mathcal{C}$ , we get 1. The mapping $(w,M)\\overset{\\cdot}{\\to}\\overline{{{\\nu}}}_{c}(w,\\bar{M})$ is continuous. 2. The characteristic time mapping $M\\rightarrow\\overline{{\\mathcal{T}_{M,c}}}$ is continuous. 3. The set valued function $M\\to\\overline{{w}}^{*}(M)$ is upper-hemicontinuous. 4. The set $\\overline{{w}}^{*}(M)$ is convex. ", "page_idx": 6}, {"type": "text", "text": "Discussion: Cost of Convexification. For Gaussian bandits, as we can get the analytical form of the most confusing instance $\\tilde{M}$ (Theorem 3.2), we do not pay any extra cost of convexification. In the non-Gaussian settings, where we cannot find such analytical forms for the most confusing instances, the minimum value of the inner minimisation problem under convex hull (Equation (5)) can go lower ", "page_idx": 6}, {"type": "text", "text": "Algorithm 1 Preference-based Track-and-Stop (PreTS) ", "page_idx": 7}, {"type": "text", "text": "1: Input: Confidence parameter $\\delta$ , ", "page_idx": 7}, {"type": "text", "text": "2: if $\\bar{Z}(t)\\geq\\beta(t,\\delta)$ then   \n3: Compute $w_{t}\\gets\\arg\\operatorname*{max}_{w\\in\\Delta^{K}}\\overline{{\\mathcal{V}}}_{\\mathcal{C}}(w,\\hat{M}_{t})$   \n4: Play $\\begin{array}{r}{k_{t}\\gets\\arg\\operatorname*{min}_{k\\in[K]}\\left|N_{k,t}-\\sum_{s=1}^{t}w_{s}\\right|}\\end{array}$   \n5: Observe reward $r_{t}$   \n6: Construct estimator $\\hat{M}_{t}$ using Equation (6)   \n7: end if   \n8: Construct a Pareto Front $\\hat{\\mathcal{P}}_{\\tau}$ from empirical means $\\hat{M}_{\\tau}$   \n9: Return: $\\hat{\\mathcal{P}}_{\\tau}$ ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "than the minimum value found in the original non-convex set of instances (Equation (3)). Thus, the characteristic time attained by solving the convex relaxation might be higher than that of the original lower bound. Hence, an algorithm solving the convex relaxation has a higher stopping time. But convexification is essential for computational feasibility of a lower bound-tracking algorithm for PrePEx. This computational-statistical trade-off will be interesting to study in the future. ", "page_idx": 7}, {"type": "text", "text": "4.2 Algorithm: Preference-based Track-and-Stop (PreTS) ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We now construct a general recipe to design a PrePEx algorithm when we do not have access to the true instance $M$ . The fundamental element of any such recipe is constructing an estimate of $M$ . For a given set of observed rewards $\\{R_{t}\\}_{t=1}^{T}$ , we obtain a column-wise least-squares estimator of $M$ by solving the convex optimization problem in Equation (6). ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\hat{M}_{t}^{(k)}=\\arg\\operatorname*{min}_{M^{(k)}\\in\\mathbb{R}^{L}}\\|\\sum_{s=1}^{t^{\\star}}R_{s}^{(k)}-M^{(k)}\\|_{2}^{2}+\\lambda_{t}\\|M^{(k)}\\|_{2}.\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Now, we elaborate the three key components of our PrePEx algorithm Preference-based Track and Stop (PreTS, Algorithm 1). ", "page_idx": 7}, {"type": "text", "text": "1. Sampling Rule: For the sampling rule, we consider a Track-and-Stop strategy (Garivier and Kaufmann, 2016). It tracks the optimal proportion of arm sampling by plugging in the empirical estimates of means and empirical count $N_{k,t}$ in the convexified lower bound. This leads to an allocation policy with an improved information acquisition. ", "page_idx": 7}, {"type": "text", "text": "2. Stopping Rule: Our ultimate stopping goal is to identify arms that are on the Pareto front. Based on this, we define the confidence set as: ", "page_idx": 7}, {"type": "equation", "text": "$$\nc(t,\\delta)\\triangleq\\left\\{\\tilde{M}\\in\\mathcal{M}:\\operatorname*{min}_{z\\in\\mathcal{C}}\\sum_{k}N_{k,t}d_{\\mathrm{KL}}(z^{\\top}\\hat{M}_{t}^{(k)},z^{\\top}\\tilde{M}^{(k)})\\leq\\log\\frac{c_{1}t^{3}}{\\delta}\\right\\}\\,,\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $c_{1}$ is specified in the appendix. Our first claim is to show that the true instance belongs to the confidence ellipsoid with high-probability. ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.1 (Confidence Ball). There exists a constant $c_{1}~>~0$ such that for any $t~\\in~\\mathbb{N}$ and $\\begin{array}{r}{c(t,\\delta)\\triangleq\\log{\\frac{c_{1}t^{3}}{\\delta}}}\\end{array}$ , we have $\\mathbb{P}\\left(M\\notin c(t,\\delta)\\right)\\leq\\delta.$ . ", "page_idx": 7}, {"type": "text", "text": "Thus, we can now formalise the corresponding Chernoff stopping rule as ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\operatorname*{min}_{\\tilde{M}\\in\\operatorname{ch}\\left(\\Lambda_{\\pi^{*}}\\left(\\hat{M}_{t}\\right)\\right)}\\operatorname*{min}_{z\\in\\mathcal{C}}\\sum_{k}N_{k,t}d_{\\mathrm{KL}}\\left(z^{\\top}\\hat{M}_{t}^{(k)},z^{\\top}\\tilde{M}^{(k)}\\right)\\geq c(t,\\delta)\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "Given the estimates $\\hat{M}_{t}$ constructed using Equation (6), the problem in Equation (8) can be solved efficiently. Next, we show that upon stopping with Equation (8), PreTS returns the true Pareto Front $\\mathcal{P}^{*}$ with probability $1-\\delta$ . Let $\\hat{\\mathcal{P}}_{t}$ denote the estimated Pareto Front at time $t$ , which is constructed using estimates $\\hat{M}_{t}$ . Then at stopping time $\\tau$ , we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\mathbb{P}\\left(\\mathcal{P}^{*}\\neq\\hat{\\mathcal{P}}_{t}\\right)}&{\\leq}&{\\mathbb{P}\\left(\\exists\\,t\\in\\mathbb{N}:\\sum_{k,\\ell}N_{k,t}d_{\\mathrm{KL}}\\left(z^{\\top}\\hat{M}_{t}^{(k)},z^{\\top}M^{(k)}\\right)\\geq c(t.\\delta)\\right)}\\\\ &{\\leq}&{\\displaystyle\\sum_{t=1}^{\\infty}\\mathbb{P}\\left(\\sum_{k,\\ell}N_{k,t}d_{\\mathrm{KL}}\\left(z^{\\top}\\hat{M}_{t}^{(k)},z^{\\top}M^{(k)}\\right)\\geq c(t,\\delta)\\right)\\leq\\delta}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where, the last inequality is true due to Theorem 4.3, a concentration result on the KL-divergence with preference projected mean rewards. ", "page_idx": 8}, {"type": "text", "text": "Theorem 4.3. For all $\\gamma\\geq(K L+1)$ and $n\\in\\mathbb N$ , we have that: ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\sum_{k}N_{k,t}d_{K L}\\left(z^{\\top}\\hat{M}_{t}^{(k)},z^{\\top}M^{(k)}\\right)\\geq\\gamma\\right]\\leq\\exp\\left(-\\gamma\\right)\\left(\\frac{\\left[\\gamma\\log(\\gamma)\\right]}{K L}\\right)^{K L}\\exp\\left(K L+1\\right)\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "3. Recommendation Rule: At the end of stopping time $\\tau$ , the algorithm returns an estimate of the Pareto Front $\\hat{\\mathcal{P}}_{\\tau}$ . ", "page_idx": 8}, {"type": "text", "text": "5 Upper Bound on Sample Complexity ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Now, we prove upper bound on the expected sample complexity of PreTS. This requires us to the Track-an-Stop proof technique. But the challenge is to show concentration of the pareto fronts under a suitable metric. ", "page_idx": 8}, {"type": "text", "text": "Concentrating to the Pareto Front. To show that upon stopping the algorithm returns the true Pareto Frontier, we need to establish a valid metric to show such convergence. Usually, the distance between sets is measured using the Hausdorff metric (Costantini and Vitolo, 1995), i.e. $\\begin{array}{r}{d_{H}(\\hat{\\mathcal{P}}_{\\tau},\\mathcal{P})\\;\\triangleq\\;\\operatorname*{max}\\left\\{\\operatorname*{sup}_{k\\in\\hat{\\mathcal{P}}_{\\tau}}\\operatorname*{inf}_{k^{\\prime}\\in\\mathcal{P}}\\|\\mu_{k}-\\mu_{k^{\\prime}}\\|_{\\infty},\\,\\operatorname*{sup}_{k\\in\\mathcal{P}}\\operatorname*{inf}_{k^{\\prime}\\in\\hat{\\mathcal{P}}_{\\tau}}\\|\\mu_{k}-\\mu_{k^{\\prime}}\\|_{\\infty}\\right\\}.}\\end{array}$ But the Hausdorff distance only defines a pseudo-distance between sets and $\\mathcal{Z}$ may not be closed under this metric. To circumvent this issue, we build upon the notion of a gap-based metric considered in the antecedent literature (Auer et al., 2016) to measure the distance between the mean reward of an arm and a given Pareto Front. We extend it to a distance metric between elements in the space of Pareto Fronts $\\mathcal{Z}$ . ", "page_idx": 8}, {"type": "text", "text": "Definition 5.1 (Distance from Pareto Front). The distance of the mean of arm $k$ from the Pareto Front $\\mathcal{P}^{*}$ is $d(k,\\mathcal{P}^{*})\\triangleq\\operatorname*{inf}_{\\varepsilon\\geq0}\\varepsilon$ , such that $\\mu_{k}+\\varepsilon\\mathbf{1}\\notin_{\\mathcal{C}}\\mu_{k^{\\prime}}$ , $k^{\\prime}\\in\\mathcal{P}^{*}$ . Equivalently, ", "page_idx": 8}, {"type": "equation", "text": "$$\nd(k,\\mathcal{P}^{*})=\\operatorname*{inf}_{k^{\\prime}\\in\\mathcal{P}^{*}}\\operatorname*{max}\\left\\{0,\\operatorname*{sup}_{z\\in\\mathcal{C}\\cap\\mathbb{B}(1)}z^{\\top}\\left(\\mu_{k^{\\prime}}-\\mu_{k}\\right)\\right\\},\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Definition 5.2 (Distance between Pareto Fronts). We define the metric between Pareto Fronts $\\begin{array}{r}{d(\\cdot,\\cdot):\\mathcal{Z}\\times\\mathcal{Z}\\to\\mathbb{R}_{\\geq0}\\;a s\\;d_{\\mathrm{P}}\\left(\\hat{P},\\mathcal{P}^{*}\\right)\\triangleq\\operatorname*{max}\\Big\\{\\operatorname*{sup}_{k\\in\\hat{P}}d\\!\\left(k,\\mathcal{P}^{*}\\right),\\operatorname*{sup}_{k\\in\\mathcal{P}^{*}}d(k,\\hat{P})\\Big\\}.}\\end{array}$ ", "page_idx": 8}, {"type": "text", "text": "In the appendix, we establish that (i) $d(\\cdot,\\cdot)$ is a valid metric on $\\mathcal{Z}$ , and (ii) $\\mathcal{Z}$ is compact and complete under $d(\\cdot,\\cdot)$ . Now, we leverage this metric to show that the Pareto Front defined by the arm-wise constructed estimator $\\hat{M}_{t}$ concentrates towards the true Pareto Front. ", "page_idx": 8}, {"type": "text", "text": "Theorem 5.1 (Concentration of mean estimates). For any pair $(i,j)\\in[K]\\times[K]$ and $z\\in{\\mathcal{C}}$ , we have ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|z^{\\top}\\left(\\mu_{i}-\\mu_{j}\\right)-z^{\\top}\\left(\\hat{\\mu}_{i,t}-\\hat{\\mu}_{j,t}\\right)\\right\\|\\leq\\beta_{i j}(t)\\,.}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\left\\|z\\right\\|^{\\frac{3}{2}}4\\bigg(h\\left(\\frac{\\log(\\frac{K_{1}}{\\delta})}{2}\\right)+\\sum_{a\\in\\{i,j\\}}\\log\\left(4+\\log(N_{a}(t))\\right)\\bigg)\\left(\\sum_{a\\in\\{i,j\\}}\\frac{1}{N_{a}(t)}\\right)\\left(\\frac{1}{N_{i,t}}\\sum_{\\ell\\in[L]}z^{(\\ell)}\\right)}\\\\ &{m d\\,K_{1}\\triangleq\\frac{K(K-1)L}{2},\\ h(\\cdot)\\approx x+\\log(1+x).}\\end{array}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "Proof Sketch. This is a consequence of jointly applying a vectorial concentration result for multipleobjectives of each arm (Kaufmann and Koolen, 2021), and pairwise time-uniform concentration bounds (Kone et al., 2023a). A key observation here is that the confidence radii depends on the magnitude of the preference vector $z$ and scales with different objectives accordingly. ", "page_idx": 8}, {"type": "text", "text": "Sample Complexity of PreTS. Using this new concentration result for the Pareto Front and the stopping rule in Equation 8, we derive an upper bound on the expected stopping time of PreTS. ", "page_idx": 8}, {"type": "text", "text": "Theorem 5.2 (Upper Bound on Sample Complexity). For any $\\alpha>0$ and $c(t,\\delta)$ defined in (8), we have that the stopping time satisfies ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{\\delta\\to0}{\\frac{\\operatorname{\\mathbb{E}}[\\tau]}{\\log\\left({\\frac{1}{\\delta}}\\right)}}\\leq{\\overline{{T_{M,c}}}}\\vee M\\in\\mathbb{R}^{L\\times K}\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "The basic outline of the proof follows a general strategy to prove Track-and-Stop result. However, the new arguments lie in establishing that the Pareto fronts converge under a suitable metric sufficiently fast. Our proof implies that PreTS matches the convex relaxation of the lower bound asymptotically at the corresponding risk level $\\delta$ . Strictly, speaking this is not asymptotically optimal since, we do not track the exact lower-bound. ", "page_idx": 9}, {"type": "text", "text": "6 Conclusion and Future Works ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We study the fixed-confidence version of preference-based pure exploration problem under linear stochastic bandit feedback, where each arm corresponds to a reward vector ordered according to a preference cone. We derive a novel lower bound for this problem. We leverage the lower bound further to derive a track-and-stop based algorithm for PrePEx problem. As future work, it would be interesting to verify our results on a real-world datasets. ", "page_idx": 9}, {"type": "text", "text": "Additionally, it would be interesting and challenging to study how other asymptotically optimal pure exploration strategies, e.g. gamified explorers (Degenne and Koolen, 2019), top-two algorithms (), can be adapted to this setting. In general, improving the computational efficiency and studying the optimality gap with respect to the non-convex lower-bound problem would be of fundamental interest. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Al Marjani, A. and Proutiere, A. (2021). Adaptive sampling for best policy identification in markov decision processes. In International Conference on Machine Learning, pages 7459\u20137468. PMLR.   \nArarat, C. and Tekin, C. (2023). Vector optimization with stochastic bandit feedback. In International Conference on Artificial Intelligence and Statistics, pages 2165\u20132190. PMLR.   \nAudibert, J.-Y. and Bubeck, S. (2010). Best arm identification in multi-armed bandits.   \nAuer, P., Chiang, C.-K., Ortner, R., and Drugan, M. (2016). Pareto front identification from stochastic bandit feedback. In Artificial intelligence and statistics, pages 939\u2013947. PMLR.   \nBalas, E. (1985). Disjunctive programming and a hierarchy of relaxations for discrete optimization problems. SIAM Journal on Algebraic Discrete Methods, 6(3):466\u2013486.   \nBerge, C. (1877). Topological spaces: Including a treatment of multi-valued functions, vector spaces and convexity. Oliver & Boyd.   \nBubeck, S., Munos, R., and Stoltz, G. (2009). Pure exploration in multi-armed bandits problems. In Algorithmic Learning Theory: 20th International Conference, ALT 2009, Porto, Portugal, October 3-5, 2009. Proceedings 20, pages 23\u201337. Springer.   \nCarlsson, E., Basu, D., Johansson, F., and Dubhashi, D. (2024). Pure exploration in bandits with linear constraints. In International Conference on Artificial Intelligence and Statistics, pages 334\u2013342. PMLR.   \nCarlsson, E., Basu, D., Johansson, F. D., and Dubhashi, D. (2023). Pure exploration in bandits with linear constraints. arXiv preprint arXiv:2306.12774.   \nContal, E., Buffoni, D., Robicquet, A., and Vayatis, N. (2013). Parallel gaussian process optimization with upper confidence bound and pure exploration. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 225\u2013240. Springer.   \nCostantini, C. and Vitolo, P. (1995). On the infimum of the hausdorff metric topologies. Proceedings of the London Mathematical Society, 3(2):441\u2013480.   \ncrepon, e., Garivier, A., and M Koolen, W. (2024). Sequential learning of the Pareto front for multi-objective bandits. In Dasgupta, S., Mandt, S., and Li, Y., editors, Proceedings of The 27th International Conference on Artificial Intelligence and Statistics, volume 238 of Proceedings of Machine Learning Research, pages 3583\u20133591. PMLR.   \nDegenne, R. and Koolen, W. M. (2019). Pure exploration with multiple correct answers. In Neural Information Processing Systems.   \nDonsker, M. D. and Varadhan, S. S. (1975). Asymptotic evaluation of certain markov process expectations for large time, i. Communications on pure and applied mathematics, 28(1):1\u201347.   \nDrugan, M. M. and Nowe, A. (2013). Designing multi-objective multi-armed bandits algorithms: A study. In The 2013 international joint conference on neural networks (IJCNN), pages 1\u20138. IEEE.   \nEven-Dar, E., Mannor, S., and Mansour, Y. (2006). Action elimination and stopping conditions for the multi-armed bandit and reinforcement learning problems. Journal of machine learning research, 7(Jun):1079\u20131105.   \nGabillon, V., Ghavamzadeh, M., and Lazaric, A. (2012). Best arm identification: A unified approach to fixed budget and fixed confidence. In Advances in Neural Information Processing Systems, pages 3212\u20133220.   \nGarivier, A. and Kaufmann, E. (2016). Optimal best arm identification with fixed confidence. In Conference on Learning Theory, pages 998\u20131027.   \nGaulton, A., Bellis, L. J., Bento, A. P., Chambers, J., Davies, M., Hersey, A., Light, Y., McGlinchey, S., Michalovich, D., Al-Lazikani, B., et al. (2012). Chembl: a large-scale bioactivity database for drug discovery. Nucleic acids research, 40(D1):D1100\u2013D1107.   \nGraves, T. L. and Lai, T. L. (1997). Asymptotically efficient adaptive choice of control laws incontrolled markov chains. SIAM journal on control and optimization, 35(3):715\u2013743.   \nHasselgren, C. and Oprea, T. I. (2024). Artificial intelligence for drug discovery: Are we there yet? Annual Review of Pharmacology and Toxicology, 64:527\u2013550.   \nJahn, J. et al. (2009). Vector optimization. Springer.   \nJamieson, K., Malloy, M., Nowak, R., and Bubeck, S. (2014). lil\u2019ucb: An optimal exploration algorithm for multi-armed bandits. In Conference on Learning Theory, pages 423\u2013439.   \nJamieson, K. and Nowak, R. (2014). Best-arm identification algorithms for multi-armed bandits in the fixed confidence setting. In 2014 48th Annual Conference on Information Sciences and Systems (CISS), pages 1\u20136. IEEE.   \nJayatunga, M. K., Xie, W., Ruder, L., Schulze, U., and Meier, C. (2022). Ai in small-molecule drug discovery: a coming wave. Nat. Rev. Drug Discov, 21(3):175\u2013176.   \nJedra, Y. and Proutiere, A. (2020). Optimal best-arm identification in linear bandits. Advances in Neural Information Processing Systems, 33:10007\u201310017.   \nKabanov, Y. (2009). Markets with Transaction Costs Mathematical Theory. Springer.   \nKalyanakrishnan, S., Tewari, A., Auer, P., and Stone, P. (2012). Pac subset selection in stochastic multi-armed bandits. In ICML, volume 12, pages 655\u2013662.   \nKarag\u00a8ozl\u00a8u, E. M., Y\u0131ld\u0131r\u0131m, Y. C., Ararat, C., and Tekin, C. (2024). Learning the pareto set under incomplete preferences: Pure exploration in vector bandits. In International Conference on Artificial Intelligence and Statistics, pages 3070\u20133078. PMLR.   \nKaufmann, E., Capp\u00b4e, O., and Garivier, A. (2016). On the complexity of best arm identification in multi-armed bandit models. Journal of Machine Learning Research, 17:1\u201342.   \nKaufmann, E. and Koolen, W. M. (2021). Mixture martingales revisited with applications to sequential tests and confidence intervals. Journal of Machine Learning Research, 22(246):1\u201344.   \nKone, C., Kaufmann, E., and Richert, L. (2023a). Adaptive algorithms for relaxed pareto set identification. Advances in Neural Information Processing Systems, 36:35190\u201335201.   \nKone, C., Kaufmann, E., and Richert, L. (2023b). Bandit pareto set identification: the fixed budget setting. arXiv preprint arXiv:2311.03992.   \nKorkmaz, \u02d9I. O., Ararat, C., and Tekin, C. (2023). Bayesian vector optimization with gaussian processes.   \nLattimore, T. and Szepesva\u00b4ri, C. (2020). Bandit Algorithms. Cambridge University Press.   \nLi, L., Jamieson, K., DeSalvo, G., Rostamizadeh, A., and Talwalkar, A. (2018). Hyperband: A novel bandit-based approach to hyperparameter optimization. Journal of Machine Learning Research, 18(185):1\u201352.   \nLizotte, D. J. and Laber, E. B. (2016). Multi-objective markov decision processes for data-driven decision support. Journal of Machine Learning Research, 17(210):1\u201328.   \nL\u00a8ohne, A. (2011). Vector optimization with infimum and supremum. Springer Science & Business Media.   \nLu, S., Wang, G., Hu, Y., and Zhang, L. (2019). Multi-objective generalized linear bandits. arXiv preprint arXiv:1905.12879.   \nMullard, A. (2014). New drugs cost us $\\mathbb{S}2.6$ billion to develop. Nature reviews drug discovery, 13(12).   \nMunro, A. P., Janani, L., Cornelius, V., Aley, P. K., Babbage, G., Baxter, D., Bula, M., Cathie, K., Chatterjee, K., Dodd, K., et al. (2021). Safety and immunogenicity of seven covid-19 vaccines as a third dose (booster) following two doses of chadox1 ncov-19 or bnt162b2 in the uk (cov-boost): a blinded, multicentre, randomised, controlled, phase 2 trial. The Lancet, 398(10318):2258\u20132276.   \nPeskun, P. H. (1973). Optimum monte-carlo sampling using markov chains. Biometrika, 60(3):607\u2013 612.   \nReker, D. and Schneider, G. (2015). Active-learning strategies in computer-assisted drug discovery. Drug discovery today, 20(4):458\u2013465.   \nSadybekov, A. V. and Katritch, V. (2023). Computational approaches streamlining drug discovery. Nature, 616(7958):673\u2013685.   \nShukla, A. (2022). Optimization and Learning in Dynamic Environments: Models and Algorithms. Columbia University.   \nSmer-Barreto, V., Quintanilla, A., Elliott, R. J., Dawson, J. C., Sun, J., Campa, V. M., Lorente-Mac\u0131\u00b4as, A\u00b4., Unciti-Broceta, A., Carragher, N. O., Acosta, J. C., et al. (2023). Discovery of senolytics using machine learning. Nature communications, 14(1):3445.   \nSoare, M., Lazaric, A., and Munos, R. (2014). Best-arm identification in linear bandits. In Advances in Neural Information Processing Systems, pages 828\u2013836.   \nSun, D., Gao, W., Hu, H., and Zhou, S. (2022). Why 90Acta Pharmaceutica Sinica B, 12(7):3049\u2013 3062.   \nTekin, C. and Turgay, E. (2017). Multi-objective contextual bandits with a dominant objective. In 2017 IEEE 27th International Workshop on Machine Learning for Signal Processing (MLSP), pages 1\u20136. IEEE.   \nTurgay, E., Oner, D., and Tekin, C. (2018). Multi-objective contextual bandit problem with similarity information. In International Conference on Artificial Intelligence and Statistics, pages 1673\u20131681. PMLR.   \nWang, J., Basu, D., and Trummer, I. (2022). Procrastinated tree search: Black-box optimization with delayed, noisy, and multi-fidelity feedback. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 36, pages 10381\u201310390.   \nWang, J., Trummer, I., and Basu, D. (2021). Demonstrating udo: A unified approach for optimizing transaction code, physical design, and system parameters via reinforcement learning. In Proceedings of the 2021 International Conference on Management of Data, pages 2794\u20132797.   \nZuluaga, M., Krause, A., et al. (2016). e-pal: An active learning approach to the multi-objective optimization problem. Journal of Machine Learning Research, 17(104):1\u201332. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "Appendix ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Table of Contents ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "A Notations 14 ", "page_idx": 12}, {"type": "text", "text": "B Proofs of Lower Bounds 15 ", "page_idx": 12}, {"type": "text", "text": "B.1 Generic Lower Bound: Proof of Theorem 3.1 . 15   \nB.2 Lower Bound for Gaussians: Proof of Theorem 3.2 . 16   \nB.3 Proof of Theorem 4.1 18   \nB.4 Proof of Theorem 4.2 18   \nC.1 Proof of Lemma 4.1 20   \nC.2 Proof of Theorem 4.3 20 ", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "D Proofs for Sample Complexity Upper Bound 21 ", "page_idx": 12}, {"type": "text", "text": "D.1 Pairwise Concentration Bounds 21   \nD.2 Proof of Theorem 5.2 22 ", "page_idx": 12}, {"type": "text", "text": "E Reduction to Best-arm Identification 25 ", "page_idx": 12}, {"type": "text", "text": "F Technical Lemmas 26 ", "page_idx": 12}, {"type": "text", "text": "G Useful Existing Results 28 ", "page_idx": 12}, {"type": "text", "text": "A Notations ", "text_level": 1, "page_idx": 13}, {"type": "table", "img_path": "GvQU54uA7u/tmp/19d65bc8a0026b23265cca072c94dcdea2bf9fe3f2a02969abfda65d6937afc8.jpg", "table_caption": ["Table 1: Table of Notations "], "table_footnote": [], "page_idx": 13}, {"type": "text", "text": "B Proofs of Lower Bounds ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "B.1 Generic Lower Bound: Proof of Theorem 3.1 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Proof. The proof follows the basic structure of constructing a lower bound as in Kaufmann et al. (2016). Recall that their inverse of characteristic time is given by ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\mathcal{T}=\\operatorname*{sup}_{w\\in\\Pi}\\operatorname*{inf}_{\\tilde{M}\\in\\Lambda_{\\pi^{*}}(M)}\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(M_{k},\\tilde{M}_{k}\\right)\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Adopting the bound as is leads to incorrect definition as well as The main challenge for our setting is describing the alternating set $\\Lambda_{\\pi^{*}}\\left(M\\right)$ and scalarization of the given instance $M\\in\\mathcal{M}$ . Given a matrix of arm-objective mean-rewards $M$ , ordering cone $\\mathcal{C}$ and a family of policies $\\Pi$ , the Pareto front is the set of optimal values (ordered wrt $\\mathcal{C}$ ) of ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{\\pi\\in\\Pi}\\,M^{\\top}\\pi\\,.\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Let $\\pi^{*}\\in\\arg\\operatorname*{max}_{\\pi\\in\\Pi}\\boldsymbol{M}^{\\intercal}\\pi$ . Throughout we assume that the optimal solution to (11) is unique. ", "page_idx": 14}, {"type": "text", "text": "\u2022 Step 1: Constructing set of alternative instances ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "The set of confusing instances given $\\Pi$ and $\\mathcal{C}$ is the set of all matrices $\\tilde{M}$ which have a different Pareto front than $M$ when using the policy $\\pi^{*}$ . Therefore, the optimal values of (11) with instance $M$ are not-dominated by those of instance $\\tilde{M}$ . Hence, the set of alternative instances, $\\Lambda_{\\pi^{*}}\\left(M\\right)$ is given by: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\Lambda_{\\pi^{*}}\\left(M\\right):=\\left\\{\\tilde{M}\\in\\mathcal{M}:\\operatorname*{max}_{\\pi\\in\\Pi}\\tilde{M}^{\\top}\\pi\\not\\in\\mathcal{A}^{\\top}\\pi^{*}\\right\\}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Let $\\pi^{\\prime}\\in\\arg\\operatorname*{max}_{\\pi\\in\\Pi}\\tilde{M}^{\\top}\\pi$ over $\\mathcal{C}$ which implies $\\tilde{M}^{\\top}\\pi^{\\prime}\\not\\in\\tilde{M}^{\\top}\\pi^{*}$ or equivalently: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\exists\\;z\\in\\mathcal{C},\\;\\pi\\in\\Pi\\;\\backslash\\;\\{\\pi^{*}\\}\\;\\mathrm{s.t.}\\;z^{\\top}\\tilde{M}\\pi>z^{\\top}\\tilde{M}\\pi^{*}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "Therefore, the alternative set can be written as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Lambda_{\\pi^{*}}\\left(M\\right)\\triangleq\\cup_{\\pi\\in\\Pi\\backslash\\{\\pi^{*}\\}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\exists\\,z\\in\\mathcal{C},z^{\\top}\\tilde{M}\\pi>z^{\\top}\\tilde{M}\\pi^{*}\\right\\}}\\\\ &{\\qquad\\qquad\\quad=\\cup_{\\pi\\in\\Pi\\backslash\\{\\pi^{*}\\}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\exists\\,z\\in\\mathcal{C}:z^{\\top}\\tilde{M}\\cdot(\\pi-\\pi^{*})>0\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where, $\\cdot$ represents a bilinear product and, its complement is given by: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\overline{{\\Lambda_{\\pi^{*}}\\left(M\\right)}}\\triangleq\\cap_{\\pi\\in\\Pi\\backslash\\left\\{\\pi^{*}\\right\\}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\forall\\,z\\in\\mathcal{C}:z^{\\top}\\tilde{M}\\cdot\\left(\\pi-\\pi^{*}\\right)\\leq0\\right\\}}\\\\ &{\\qquad\\qquad=\\cap_{\\pi\\in\\Pi\\backslash\\left\\{\\pi^{*}\\right\\}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\tilde{M}\\cdot\\left(\\pi-\\pi^{*}\\right)\\in\\mathcal{C}^{\\circ}\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "where, ${\\dot{\\mathrm{ri}}}({\\mathcal{C}}^{\\circ})$ denotes the relative interior of the polar cone to $\\mathcal{C}$ . Since $\\mathcal{C}$ is a polyhederal cone, it is closed and convex and therefore, its polar cone is non-empty, closed and convex. Therefore, $\\overline{{{\\Lambda_{\\pi^{*}}\\left(M\\right)}}}$ is non-empty. We now show that given $\\pi^{*}$ , and $\\pi$ , the hardest instances $\\tilde{M}\\in\\mathcal{M}$ are such that: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\tilde{M}\\cdot(\\pi-\\pi^{*})\\in{\\mathsf{b d}}(C^{\\circ})\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "and the alternating set can be further characterized as: ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\overline{{\\Lambda_{\\pi^{*}}\\left(M\\right)}}:=\\cap_{\\pi\\in\\Pi\\backslash\\pi^{*}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\forall\\,z\\in C,\\,z^{\\top}\\tilde{M}\\cdot\\left(\\pi-\\pi^{*}\\right)=0\\right\\}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "\u2022 Step 2: Hardest instance lies on the boundary ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Fix $\\pi^{\\prime}\\quad\\in\\mathrm{~\\mathbb~{~I~}~}\\backslash\\ \\{\\pi^{*}\\}$ and let M \u2032 \u2208  M\u02dc \u2208M : M\u02dc \u00b7 (\u03c0\u2032 \u2212\u03c0\u2217) \u2208ri(C\u25e6) . Then, by convexity of $\\left\\{{\\tilde{M}}\\in{\\mathcal{M}}:\\exists\\,z\\in{\\mathcal{C}}:z^{\\top}{\\tilde{M}}\\cdot(\\pi-\\pi^{*})>0\\right\\}$ there exists M \u2032\u2032 \u2208 $\\left\\{\\tilde{M}\\in\\mathcal{M}:\\tilde{M}\\cdot(\\pi^{\\prime}-\\pi^{*})\\in{\\sf b d}(\\mathcal{C}^{\\circ})\\right\\}$ such that $\\begin{array}{r}{\\left|z^{\\top}M_{k}-z^{\\top}M_{k}^{\\prime}\\right|\\geq\\left|z^{\\top}M_{k}-z^{\\top}M_{k}^{\\prime\\prime}\\right|,\\forall\\,z\\in\\mathcal{C}.}\\end{array}$ Since $d_{\\mathrm{KL}}\\left(z^{\\top}M,\\cdot\\right)$ is decreasing, we have: $d_{\\mathrm{KL}}\\left(z^{\\top}M_{k},z^{\\top}M_{k}^{\\prime}\\right)\\geq d_{\\mathrm{KL}}\\left(z^{\\top}M_{k},z^{\\top}M_{k}^{\\prime\\prime}\\right)$ . ", "page_idx": 14}, {"type": "text", "text": "\u2022 Step 3: Concluding arguments ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Using the above arguments we see that the minimum argument of $\\begin{array}{r}{\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M^{\\prime},z^{\\top}M^{\\prime\\prime}\\right)}\\end{array}$ is such that $M^{\\prime\\prime}\\in\\left\\{\\tilde{M}\\in\\mathcal{M}:\\tilde{M}\\cdot(\\pi-\\pi^{*})\\in{\\sf b d}(\\mathcal{C}^{\\circ})\\right\\}$ . Hence, we can characterise $\\Lambda_{\\pi^{*}}\\left(M\\right)$ as: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\Lambda_{\\pi^{*}}\\left(M\\right)\\triangleq\\cup_{\\Pi\\backslash\\pi^{*}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\exists\\,z\\in\\mathcal{C},\\,\\,z^{\\top}\\tilde{M}\\cdot\\left(\\pi-\\pi^{*}\\right)=0\\right\\}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Linearising the bilinear terms leads us to: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Lambda_{\\pi^{*}}\\left(M\\right)\\triangleq\\cup_{\\Pi\\backslash\\pi^{*}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\,\\exists\\,z\\in\\mathcal{C},\\,\\,\\langle\\mathrm{vect}\\left(z^{\\top}(\\pi-\\pi^{*})\\right),\\mathrm{vect}(\\tilde{M})\\rangle=0\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "The optimization problem now becomes: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{w\\in\\Delta^{K}}\\operatorname*{inf}_{\\pi\\in\\Pi\\setminus\\pi^{*}}\\operatorname*{inf}_{z\\in{\\mathcal{C}}}\\sum_{k=1}^{K}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M_{k},z^{\\top}\\tilde{M}_{k}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Finally, we observe that if we have multiple candidates $\\pi^{*}\\in\\Pi^{*}$ , the inner minimisation problem add a new layer to yield ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{w\\in\\Delta^{K}}\\operatorname*{inf}_{\\pi\\in\\Pi\\setminus\\pi^{*}}\\operatorname*{inf}_{z\\in{\\mathcal{C}}}\\sum_{k=1}^{K}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M_{k},z^{\\top}\\tilde{M}_{k}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 15}, {"type": "text", "text": "B.2 Lower Bound for Gaussians: Proof of Theorem 3.2 ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Proof. ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "Step 1. Simplifying the KL-divergence for a Gaussian bandit instance with identical variance across all objectives yields ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\mathcal{V}_{\\mathcal{C}}(w,M)=\\operatorname*{min}_{\\tilde{M}\\in\\Lambda_{\\pi^{*}}(M)}\\operatorname*{min}_{z\\in C}\\sum_{k=1}^{K}w_{k}\\sum_{\\ell=1}^{L}z^{(\\ell)}\\frac{\\Big(\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}\\Big)^{2}}{\\sigma^{2}}\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Recalling that due to the projection lemma, the $\\tilde{M}$ achieving the minimum satisfies ", "page_idx": 15}, {"type": "equation", "text": "$$\nz^{\\top}\\sum_{k=1}^{K}\\tilde{M}_{k}^{\\top}\\left(\\pi_{k}^{*}-\\pi_{k}\\right)=0,\\,\\forall z\\in\\mathcal{C}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Additionally, for $z\\in C$ , we have ", "page_idx": 15}, {"type": "equation", "text": "$$\nz=\\sum_{i=1}^{N}\\lambda_{i}v_{i},\\;\\mathrm{for}\\;\\lambda_{i}\\ge0\\forall i\\in[N]\\,.\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Now, we formulate the Lagrangian of (13) with dual variables $\\beta$ for (14) and $\\gamma$ for (15) as ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathcal{L}\\left(\\boldsymbol{w},\\boldsymbol{M},\\tilde{\\boldsymbol{M}},\\gamma,\\beta\\right)}\\\\ &{=\\displaystyle\\sum_{k=1}^{K}\\pi_{k}^{2}w_{k}\\sum_{\\ell=1}^{L}z^{(\\ell)}\\left(\\frac{\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}}{\\sigma}\\right)^{2}+\\beta\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{\\top}\\tilde{M}\\left(\\pi^{*}-\\pi\\right)+\\gamma^{\\top}\\left(z-\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}\\right)}\\\\ &{=\\displaystyle\\sum_{k=1}^{K}\\pi_{k}^{2}w_{k}\\sum_{\\ell=1}^{L}\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\frac{\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}}{\\sigma}\\right)^{2}+\\beta\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{\\top}\\tilde{M}\\left(\\pi^{*}-\\pi\\right)+\\gamma^{\\top}\\left(z-\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Step 2. Taking derivative with respect to $\\gamma$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial\\gamma}=0\\quad\\implies\\quad z=\\sum_{i=1}^{N}\\lambda_{i}v_{i}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Thus, we get the Lagrangian as ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\boldsymbol{\\Sigma}(w,M,\\tilde{M},\\beta)=\\displaystyle\\sum_{k=1}^{K}\\pi_{k}^{2}w_{k}\\sum_{\\ell=1}^{L}\\left(\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\right)\\left(\\frac{\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}}{\\sigma}\\right)^{2}+\\beta\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{\\top}\\tilde{M}\\left(\\boldsymbol{\\pi}^{*}-\\boldsymbol{\\pi}\\right)}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{k=1}^{K}\\pi_{k}^{2}w_{k}\\displaystyle\\sum_{\\ell=1}^{L}\\left(\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\right)\\left(\\frac{\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}}{\\sigma}\\right)^{2}+\\beta\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}\\displaystyle\\sum_{\\ell=1}^{L}v_{i}^{(\\ell)}\\displaystyle\\sum_{k=1}^{K}\\tilde{M}_{k}^{(\\ell)}\\left(\\boldsymbol{\\pi}^{*}-\\boldsymbol{\\pi}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Step 3. Taking the derivative w.r.t. $\\tilde{M}$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial\\tilde{M}_{k}^{(\\ell)}}=\\pi_{k}^{2}w_{k}\\left(\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\right)\\left(\\frac{-2}{\\sigma^{2}}\\right)\\left(\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}\\right)+\\beta\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\pi^{*}-\\pi\\right)_{k}\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and setting it to zero, we get ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{c l c r}{{}}&{{}}&{{\\pi_{k}^{2}w_{k}\\,\\left(\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\right)\\left(\\frac{2}{\\sigma^{2}}\\right)\\left(\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}\\right)=\\beta\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\pi^{*}-\\pi\\right)_{k}\\,}}\\\\ {{}}&{{\\Longrightarrow\\tilde{M}_{k}^{(\\ell)}=\\mu_{k}^{(\\ell)}-\\displaystyle\\frac{\\sigma^{2}\\beta\\left(\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\pi-\\pi^{*}\\right)_{k}\\right)}{2\\pi_{k}^{2}w_{k}\\left(\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\right)}=\\mu_{k}^{(\\ell)}-\\displaystyle\\frac{\\sigma^{2}\\beta\\left(\\pi^{*}-\\pi\\right)_{k}}{2\\pi_{k}^{2}w_{k}}\\,.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "The last equality holds for any $\\textstyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\neq0$ . ", "page_idx": 16}, {"type": "text", "text": "Therefore, the Lagrangian now becomes ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\mathcal{L}(w,M,\\beta)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad=\\displaystyle\\sum_{k=1}^{K}\\pi_{k}^{2}w_{k}\\displaystyle\\sum_{\\ell=1}^{L}\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\frac{\\mu_{k}^{(\\ell)}-\\tilde{M}_{k}^{(\\ell)}}{\\sigma}\\right)^{2}+\\beta\\displaystyle\\sum_{i=1}^{N}\\lambda_{i}\\displaystyle\\sum_{\\ell=1}^{L}v_{i}^{(\\ell)}\\displaystyle\\sum_{k=1}^{K}\\tilde{M}_{k}^{(\\ell)}\\left(\\pi^{*}-\\pi\\right)_{k}}\\\\ &{\\quad=\\displaystyle\\sum_{k=1}^{K}\\pi_{k}^{2}w_{k}\\displaystyle\\sum_{\\ell=1}^{L}\\sum_{i=1}^{N}\\lambda_{i}v_{i}^{(\\ell)}\\frac{(\\pi^{*}-\\pi)_{k}^{2}}{\\pi_{k}^{4}w_{k}^{2}}\\frac{\\beta^{2}\\sigma^{2}}{4}+\\beta\\displaystyle\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\lambda_{i}v_{i}^{(\\ell)}\\displaystyle\\sum_{k=1}^{K}(\\pi^{*}-\\pi)_{k}\\left(\\mu_{k}^{(\\ell)}-\\frac{(\\pi^{*}-\\pi)_{k}}{\\pi_{k}^{2}w_{k}}\\left(\\frac{\\beta^{2}}{\\pi_{k}^{2}w_{k}}\\right)\\right)}\\\\ &{\\quad=\\displaystyle\\left(\\frac{\\beta^{2}\\sigma^{2}}{4}-\\frac{\\beta\\sigma^{2}}{2}\\right)\\displaystyle\\sum_{k=1}^{K}\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\frac{(\\pi^{*}-\\pi)_{k}^{2}}{w_{k}\\pi_{k}^{2}}\\lambda_{i}v_{i}^{(\\ell)}+\\beta\\displaystyle\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\sum_{k=1}^{K}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\pi^{*}-\\pi\\right)_{k}\\mu_{k}^{(\\ell)}}\\\\ &{\\quad=\\displaystyle\\beta\\left[\\frac{\\sigma^{2}}{2}\\left(\\frac{\\beta}{2}-1\\right)\\displaystyle\\sum_{k=1}^{K}\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\frac{(\\pi^{*}-\\pi)_ \n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Step 4. By taking the derivative with respect to $\\beta$ , we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial\\beta}=\\frac{\\sigma^{2}}{2}\\left(\\beta-1\\right)\\sum_{k=1}^{K}\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\frac{\\left(\\boldsymbol{\\pi}^{*}-\\boldsymbol{\\pi}\\right)_{k}^{2}}{w_{k}\\pi_{k}^{2}}\\lambda_{i}v_{i}^{(\\ell)}+\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\sum_{k=1}^{K}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\boldsymbol{\\pi}^{*}-\\boldsymbol{\\pi}\\right)_{k}\\mu_{k}^{(\\ell)}\\,,\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "and setting it to zero, leads to: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\beta=1-\\frac{2}{\\sigma^{2}}\\frac{\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\sum_{k=1}^{K}\\lambda_{i}v_{i}^{(\\ell)}\\left(\\pi^{*}-\\pi\\right)_{k}\\mu_{k}^{(\\ell)}}{\\sum_{k=1}^{K}\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\frac{\\lambda_{i}v_{i}^{(\\ell)}\\left(\\pi^{*}-\\pi\\right)_{k}^{2}}{w_{k}\\pi_{k}^{2}}}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "From (17), excluding for the origin lying within the cone, we get: ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\tilde{M}_{k}^{(\\ell)}=\\mu_{k}^{(\\ell)}-\\frac{\\beta\\sigma^{2}}{2}\\frac{(\\pi^{*}-\\pi)_{k}}{\\pi_{k}^{2}w_{k}}}}\\\\ {{=\\mu_{k}^{(\\ell)}-\\frac{\\sigma^{2}}{2}\\left(1-\\frac{2}{\\sigma^{2}}\\frac{\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\sum_{k=1}^{K}\\lambda_{i}v_{i}^{(\\ell)}\\,(\\pi^{*}-\\pi)_{k}\\,\\mu_{k}^{(\\ell)}}{\\sum_{k=1}^{K}\\sum_{i=1}^{N}\\sum_{\\ell=1}^{L}\\frac{\\lambda_{i}v_{i}^{(\\ell)}\\,(\\pi^{*}-\\pi)_{k}^{2}}{w_{k}\\pi_{k}^{2}}}\\right)\\left(\\frac{(\\pi^{*}-\\pi)_{k}}{\\pi_{k}^{2}w_{k}}\\right)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Let $\\Delta_{k}=\\left(\\pi^{*}-\\pi\\right)_{k}$ . Finally, the Lagrangian from (16) leads to ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathcal{L}(u,M)}\\\\ &{=\\left(1-\\frac{2}{\\sigma^{2}}\\frac{\\sum_{i,t\\neq\\lambda}\\lambda_{i}v_{i}^{(t)}(\\Delta_{\\lambda}u_{i}^{(t)})}{\\sum_{i,t\\neq\\lambda}\\frac{\\lambda_{i}v_{i}^{(t)}(\\Delta_{\\lambda}u_{i}^{(t)})}{\\sigma^{2}}}\\right)\\left[-\\left(\\frac{\\sigma^{2}}{4}+\\frac{\\sum_{i\\neq\\lambda}\\lambda_{i}v_{i}^{(t)}(\\Delta_{\\lambda}u_{i}^{(t)})}{2\\sum_{i,t\\neq\\lambda}\\frac{\\lambda_{i}^{2}u_{i}^{(t)}}{\\sigma^{2}}}\\right)\\right]\\sum_{i,k}\\frac{\\Delta_{\\lambda}^{2}}{\\sigma^{2}}\\lambda_{i}^{2}w_{k}^{(t)}+\\sum_{\\lambda,k}w_{i}^{(t)}}\\\\ &{=\\left(1-\\frac{2}{\\sigma^{2}}\\frac{\\sum_{i\\neq\\lambda}\\lambda_{i}v_{i}^{(t)}(\\Delta_{\\lambda}u_{i}^{(t)})}{\\sum_{i,t\\neq\\lambda}\\frac{\\lambda_{i}^{2}u_{i}^{(t)}}{\\sigma^{2}}}\\right)\\Bigg[\\frac{1}{2}\\sum_{i,k}\\lambda_{\\sigma^{()}}(\\Delta_{\\lambda}u_{i}^{(t)}-\\sigma^{2})\\frac{\\sum_{i,k}^{2}}{4\\sum_{i,t}\\frac{\\lambda_{i}^{2}u_{i}^{(t)}}{\\sigma^{2}}}\\Bigg]}\\\\ &{=\\left(1-\\frac{2}{\\sigma^{2}}\\frac{\\sum_{i,t\\neq\\lambda}\\lambda_{i}v_{i}^{(t)}(\\Delta_{\\lambda}u_{i}^{(t)})}{\\sum_{i,t\\neq\\lambda}\\frac{\\lambda_{i}^{2}u_{i}^{(t)}}{\\sigma^{2}}}\\right)\\frac{1}{2}\\sum_{i,k}\\lambda_{\\sigma^{()}}^{2}\\Delta_{i}u_{i}^{(t)}-\\frac{\\sigma^{2}}{4}\\sum_{i,k}\\frac{\\lambda_{i}^{2}}{\\sigma^{2}}w_{k}^{(t)}+\\frac{1}{2}\\sum_{i,k}w_{i}^{(t)}\\Delta_{\\lambda}u_{i}^{(t)}} \n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "$\\begin{array}{r}{\\alpha(z)\\triangleq\\frac{1}{\\sigma^{2}}\\frac{\\sum_{i,\\ell,k}\\lambda_{i}v_{i}^{(\\ell)}\\Delta_{k}\\mu_{k}^{(\\ell)}}{\\sum_{i,\\ell,k}\\frac{\\lambda_{i}v_{i}^{(\\ell)}\\Delta_{k}^{2}}{w_{k}\\pi_{k}^{2}}}=\\frac{z^{\\top}M(\\pi^{\\star}-\\pi)}{\\sigma^{2}(\\sum_{l}z^{l})\\sum_{k}\\frac{1}{w_{k}}\\left(\\frac{\\pi_{k}^{\\star}}{\\pi_{k}}-1\\right)^{2}}.}\\end{array}$ ", "page_idx": 17}, {"type": "text", "text": "B.3 Proof of Theorem 4.1 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "This proof follows directly from Theorem 3.1 in Balas (1985). Recall that the set $\\mathcal{F}$ is given by: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{F}\\triangleq\\cup_{\\Pi\\setminus\\{\\pi^{*}\\}}\\left\\{\\tilde{M}\\in\\mathcal{M}:\\left\\langle\\mathrm{vect}(z^{\\top}(\\pi-\\pi^{*})),\\mathrm{vect}(\\tilde{M})\\right\\rangle=0\\right\\}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Any $z\\ \\ \\in\\ \\ C$ , we have $\\begin{array}{r c l}{z}&{=}&{\\sum_{i}\\alpha_{i}v_{i}}\\end{array}$ . Rewriting, every hyperplane in $\\mathcal{F}$ as $\\begin{array}{r l}{P_{\\pi}}&{{}=}\\end{array}$ $\\begin{array}{r}{\\left\\{\\tilde{M}\\in\\mathcal{M}\\big\\vert\\langle\\mathrm{vect}\\left(\\sum_{i}\\alpha_{i}v_{i}^{\\top}\\pi\\right),\\mathrm{vect}(\\tilde{M})\\rangle=\\sum_{i}\\alpha_{i}v_{i}^{\\top}\\pi^{*}\\right\\}}\\end{array}$ . Then, by Theorem 3.1 in Balas (1985), $\\mathcal{C}(\\mathcal{F})$ is given by: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal C(\\mathcal F)=\\left\\{\\gamma^{\\top}\\mathbf{vect}(\\tilde{M})\\geq\\gamma_{0},\\;\\gamma=\\sum_{i}u_{i}\\alpha_{i}\\mathbf{vect}(v_{i}^{\\top}(\\pi-\\pi^{*}))\\right.\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "B.4 Proof of Theorem 4.2 ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Recall that: ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bar{\\mathcal{V}}_{\\mathcal{C}}(w,M)\\triangleq\\underset{\\tilde{M}\\in\\mathrm{ch}(\\Lambda_{\\pi^{*}}(M))}{\\operatorname*{min}}\\,\\underset{z\\in\\mathcal{C}}{\\operatorname*{inf}}\\sum_{k=1}^{K}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}\\tilde{M}\\right)}\\\\ &{\\quad\\bar{w}^{*}(M)\\triangleq\\underset{w\\in\\Delta^{K}}{\\operatorname*{max}}\\underset{\\pi^{*}\\in\\Pi\\backslash\\pi^{*}}{\\operatorname*{inf}}\\quad\\underset{\\tilde{M}\\in\\mathrm{ch}(\\Lambda_{\\pi^{*}}(M))}{\\operatorname*{min}}\\underset{z\\in\\mathcal{C}}{\\operatorname*{min}}\\sum_{k=1}^{K}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}\\tilde{M}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "\u2022 For (1) and (2) observe that $(z,M)\\,\\rightarrow\\,z^{\\top}M$ and $\\left(z,M,\\tilde{M}\\right)\\,\\to\\,d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}\\tilde{M}\\right)$ are continuous maps for all $(z,M)\\,\\in\\,\\mathcal{C}\\,\\times\\,\\mathcal{M}$ and $(z,M,\\tilde{M})\\,\\in\\,\\mathcal{C}\\,\\times\\,\\mathcal{M}\\,\\times\\,\\mathrm{ch}\\left(\\Lambda_{\\pi^{*}}\\left(M\\right)\\right)$ . Further, $\\begin{array}{r l}{\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}\\tilde{M}\\right)}\\end{array}$ is continuous in all its elements. Fix a sequence $(w_{t},\\boldsymbol{z}_{t},M_{t})\\ \\in$ $\\Pi\\times{\\mathcal{C}}\\times{\\mathcal{M}}$ such that $(\\dot{w}_{t},z_{t},M_{t})\\rightarrow(w,z,M)$ . For any $\\epsilon$ , $\\exists\\;t^{\\prime}\\geq1$ such that $\\|(w_{t},z_{t},M_{t})-$ $(w,z,M)\\|\\;\\leq\\;\\epsilon\\;\\forall\\;t\\;\\geq\\;t^{\\prime}$ . Further, $\\operatorname{ch}\\left(\\Lambda_{\\pi^{*}}\\left(M_{t}\\right)\\right)\\ \\to\\ \\operatorname{ch}\\left(\\Lambda_{\\pi^{*}}\\left(M\\right)\\right)$ . Therefore, for every $\\epsilon^{\\prime}$ , $\\exists\\,t^{\\prime\\prime}\\geq1$ such that $\\forall\\,t\\geq t^{\\prime\\prime}$ we ", "page_idx": 17}, {"type": "text", "text": "", "page_idx": 18}, {"type": "equation", "text": "$$\n\\Big|\\sum_{k}w_{k,t}d_{\\mathrm{KL}}\\left(z_{t}^{\\top}M_{t},z_{t}^{\\top}\\tilde{M}_{t}\\right)-\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z_{t}^{\\top}\\tilde{M}_{t}\\right)\\Big|\\le\\epsilon^{\\prime}\\,\\forall\\,\\tilde{M}_{t}\\in\\mathbb{R}^{K\\times L}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Taking $t\\geq\\operatorname*{max}\\{t^{\\prime},t^{\\prime\\prime}\\}$ , we have: ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigg|\\operatorname*{inf}_{\\tilde{M}\\in\\Lambda_{\\pi^{*}}(M)}\\operatorname*{inf}_{z\\in C}\\sum_{k}w_{k,t}d_{\\mathrm{KL}}\\left(z_{t}^{\\top}M_{t},z_{t}^{\\top}\\tilde{M}_{t}\\right)-\\underset{\\tilde{M}\\in\\Lambda_{\\pi^{*}}(M)}{\\operatorname*{inf}}\\operatorname*{inf}_{z\\in C}\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z_{t}^{\\top}\\tilde{M}_{t}\\right)\\bigg|}\\\\ &{\\leq\\bigg|\\operatorname*{inf}_{\\tilde{M}\\in\\Lambda_{\\pi^{*}}(M)}\\operatorname*{inf}_{z\\in C}\\sum_{k}w_{k,t}d_{\\mathrm{KL}}\\left(z_{t}^{\\top}M_{t},z_{t}^{\\top}\\tilde{M}_{t}\\right)-\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z_{t}^{\\top}\\tilde{M}_{t}\\right)\\bigg|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\quad}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "\u2022 For (3), we define $\\begin{array}{r}{f(w,M)=\\operatorname*{inf}_{\\tilde{M}\\in\\Lambda_{\\pi^{*}}(M)}\\operatorname*{inf}_{z\\in\\mathcal{C}}\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}\\tilde{M}\\right)}\\end{array}$ and $C(w)=\\Pi$ . Then, from Berge\u2019s Theorem (Theorem G.1 in Appendix), we get $w^{*}(M)$ is upper-hemicontinuous. \u2022 For (4), the convexity of $w^{*}(M)$ follows since the optimal solution ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{w\\in\\Pi}\\operatorname*{inf}_{{\\tilde{M}}\\in\\Lambda_{\\pi^{*}}(M)}\\operatorname*{inf}_{z\\in{\\mathcal{C}}}\\sum_{k}w_{k}d_{\\mathrm{KL}}\\left(z^{\\top}M,z^{\\top}{\\tilde{M}}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "is concave for any given $\\pi$ and $\\pi^{*}$ . ", "page_idx": 18}, {"type": "text", "text": "C Proof of the Stopping Time ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "C.1 Proof of Lemma 4.1 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The proof follows by showing that $\\begin{array}{r}{\\operatorname*{inf}_{z\\in\\mathcal{C}}\\sum_{k}N_{k,t}d_{\\mathrm{KL}}\\left(z^{\\top}\\hat{M}_{t},z^{\\top}M\\right)}\\end{array}$ is an appropriate stochastic process and using results from Kaufmann and Koolen (2021). To this end, it can be verified that for all $k\\in[K]$ : ", "page_idx": 19}, {"type": "text", "text": "1. There exists a martingale such that k,t such that ", "page_idx": 19}, {"type": "text", "text": "(a) $M_{k,\\ell}^{\\rho}(t)$ is non-negative and $M_{k,\\ell}^{\\rho}(0)=1$ (b) $M_{k,\\ell}^{\\rho}(t)$ is such that: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\forall\\,t\\in\\mathbb{N}:M_{k}^{\\rho}(t)\\geq\\exp\\left(\\rho d_{\\mathrm{KL}}\\left(z^{\\top}\\hat{M}_{t},z^{\\top}M\\right)-g(\\rho)\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "(c) For any subset $S\\subseteq[K]$ and $\\rho$ we have: $\\Pi_{k\\in S}M_{k}^{\\rho}(t)$ is a martingale. ", "page_idx": 19}, {"type": "text", "text": "2. From Lemma 4 in Kaufmann and Koolen (2021) and Theorem 4.3 on KL-concentration, we conclude the proof. ", "page_idx": 19}, {"type": "text", "text": "C.2 Proof of Theorem 4.3 ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Let $\\rho>K L+1$ and $\\eta$ . Define $\\begin{array}{r}{D=\\lceil\\frac{\\log(n)}{\\log(1+\\eta)}\\rceil}\\end{array}$ and set $\\mathcal{D}=\\{1,2,\\ldots,D\\}^{K}$ . Let: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{A_{t}=\\left\\{\\displaystyle\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}N_{k,t}\\cdot d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t}^{(\\ell)}\\right)\\geq\\rho\\right\\}}\\\\ &{}&{B_{d}=\\cap_{k=1}^{K}\\left\\{(1+\\xi)^{d-1}\\leq N_{k,t}\\leq(1+\\xi)^{d}\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "We have $A=\\cup_{d\\in\\mathcal{D}}A\\cap B_{d}$ , hence $\\begin{array}{r}{\\mathbb{P}(A)\\leq\\sum_{d\\in{\\mathcal{D}}}\\mathbb{P}(A\\cap B_{d})}\\end{array}$ . Using Lemma F.1 with $\\begin{array}{r}{\\eta=\\frac{1}{\\delta-1}}\\end{array}$ and $\\bar{t}_{k}=(1+\\eta)^{d_{k}-1}$ . Since $\\rho\\ge K+1$ , for $\\begin{array}{r}{\\eta=\\frac{1}{\\rho-1}}\\end{array}$ and $\\rho\\ge(1+\\eta)K$ , for all $d\\in\\mathcal{D}$ we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(A\\cap B_{d}\\right)\\leq\\left(\\frac{\\rho e}{K L}\\right)^{K L}\\exp\\left(\\frac{-\\rho}{\\left(1+\\eta\\right)}\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "By a union bound on $\\mathcal{D}$ , we have: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(A\\right)\\leq\\left(\\frac{D\\rho e}{K}\\right)^{K}\\exp\\left(\\frac{-\\rho}{1+\\eta}\\right)\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Noting that $\\begin{array}{r}{\\eta=\\frac{1}{\\rho-1}}\\end{array}$ , we get: ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(A\\right)\\leq\\exp\\left(-\\delta\\right)\\left(\\frac{\\delta\\lceil\\delta\\log(n)\\rceil}{K L}\\right)^{K L}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 19}, {"type": "text", "text": "D Proofs for Sample Complexity Upper Bound ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "D.1 Pairwise Concentration Bounds ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Lemma D.1 (Pairwise concentration). Consider the event: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\mathcal{E}_{t}\\triangleq\\cap_{k\\in[K]}\\cap_{i\\neq k}\\cap_{\\ell\\in[L]}\\left\\{L_{i,j}^{(\\ell)}(t)\\leq\\mu_{i}^{(\\ell)}-\\mu_{j}^{(\\ell)}\\leq U_{i,j}^{(\\ell)}(t)\\right\\}\\,,\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $L_{i j}(t)=z^{\\top}(\\mu_{i}-\\mu_{j})-\\beta_{i j}(t)$ and $U_{i j}(t)=z^{\\top}(\\mu_{i}-\\mu_{j})+\\beta_{i j}(t),$ , and $\\beta_{i j}(t)$ is defined in Theorem 5.1. Then, we get $\\mathbb{P}\\left(\\cap_{t=1}^{\\infty}\\mathcal{E}\\right)\\geq1-\\bar{\\delta}$ . ", "page_idx": 20}, {"type": "text", "text": "Proof. We have the following: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{\\mathcal{E}_{t}}&{=}&{\\cap_{(i,j)\\in\\mathcal{B}}\\cap_{\\ell=1}^{L}\\left\\{L_{i,j}^{(\\ell)}\\leq\\mu_{i}^{(\\ell)}-\\mu_{j}^{(\\ell)}\\leq U_{i,j}^{(\\ell)}\\right\\}}\\\\ &{=}&{\\cap_{(i,j)\\in\\mathcal{B}}\\cap_{\\ell=1}^{L}\\left\\{\\big|\\left(\\widehat{\\mu}_{i,t}^{(\\ell)}-\\widehat{\\mu}_{j,t}^{(\\ell)}\\right)-\\big(\\mu_{i}-\\mu_{j}\\big)\\big|\\leq\\beta_{i j}(t)\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where, $\\boldsymbol{\\mathrm{\\Delta}}\\boldsymbol{\\mathrm{\\Omega}}_{\\boldsymbol{B}}$ is the set of arm pairs. By a union bound we have the following: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{^>\\left(\\overline{{\\mathcal{E}}}_{t}\\right)}&{=}&{\\mathbb{P}\\left(\\exists\\,t\\geq1:\\overline{{\\mathcal{E}}}_{t}\\mathrm{~holds}\\,\\right)}\\\\ &{=}&{\\mathbb{P}\\left(\\exists\\,t\\geq1:(i,j)\\in\\mathcal{B},\\,\\ell\\in[L],(i,j)\\in\\mathcal{B}:\\left|\\,\\left(\\widehat{\\mu}_{i,t}^{(\\ell)}-\\widehat{\\mu}_{j,t}^{(\\ell)}\\right)-(\\mu_{i}-\\mu_{j})\\,\\right|\\geq\\beta_{i j}(t)\\right)}\\\\ &{\\leq}&{\\displaystyle\\sum_{(i,j)\\in\\mathcal{B}}\\sum_{\\ell\\in[L]}\\frac{\\delta}{K(K-1)}}\\\\ &{=}&{\\varepsilon}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We now show that the Pareto fronts under the metric $d_{p}$ . ", "page_idx": 20}, {"type": "text", "text": "Lemma D.2. $(\\mathcal{Z},d_{p})$ is a complete metric space. ", "page_idx": 20}, {"type": "text", "text": "Proof. From Definition 5.2, for two Pareto fronts $\\mathcal{P}_{1},\\mathcal{P}_{2}\\in\\mathcal{Z}$ , we have that: ", "page_idx": 20}, {"type": "equation", "text": "$$\nd_{p}(\\mathcal{P}_{1},\\mathcal{P}_{2})\\triangleq\\operatorname*{max}\\left\\{\\operatorname*{sup}_{k\\in\\mathcal{P}_{1}}d(k,\\mathcal{P}_{1}),\\operatorname*{sup}_{k\\in\\mathcal{P}_{2}}d(k,\\mathcal{P}_{1})\\right\\}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where, ", "page_idx": 20}, {"type": "equation", "text": "$$\nd(k,\\mathcal{P})=\\operatorname*{inf}_{k^{\\prime}\\in\\mathcal{P}}\\operatorname*{max}\\left\\{0,\\operatorname*{sup}_{z\\in\\mathcal{C}\\cap\\mathbb{B}(1)}z^{\\top}\\left(\\mu_{k^{\\prime}}-\\mu_{k}\\right)\\right\\}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "1. We first show that $d_{p}(\\mathcal{P}_{1},\\mathcal{P}_{2})$ is a metric. Let $\\mathcal{P}_{1},\\mathcal{P}_{2}\\in\\mathcal{Z}$ . To show that $d_{p}$ is a metric, we show that: ", "page_idx": 20}, {"type": "text", "text": "(a) Symmetry: $d_{p}(\\mathcal{P}_{1},\\mathcal{P}_{2})$ is symmetric by definition ", "page_idx": 20}, {"type": "text", "text": "(b) Triangle Inequality: We show that $d_{p}(\\mathscr{P}_{1},\\mathscr{P}_{3})\\leq d_{p}(\\mathscr{P}_{1},\\mathscr{P}_{2})+d_{p}(\\mathscr{P}_{2},\\mathscr{P}_{3}).$ ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l l}{d_{p}\\left(\\mathcal{P}_{1},\\mathcal{P}_{3}\\right)}&{=}&{\\operatorname*{max}\\left\\{\\underset{k\\in\\mathcal{P}_{1}}{\\operatorname*{max}}\\underset{k^{\\prime}\\in\\mathcal{P}_{3}}{\\operatorname*{min}}\\mu_{k^{\\prime}}(X_{3})-\\mu_{k}(X_{1}),\\underset{k\\in\\mathcal{P}_{3}}{\\operatorname*{max}}\\underset{k^{\\prime}\\in\\mathcal{P}_{1}}{\\operatorname*{min}}\\mu_{k^{\\prime}}(X_{1})-\\mu_{k}(X_{3})\\right\\}}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "We have that: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\underset{k\\in\\mathcal{P}_{1}}{\\operatorname*{max}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}_{3}}{\\operatorname*{min}}\\mu_{k^{\\prime}}(X_{3})-\\mu_{k}(X_{1})}\\\\ {\\le}&{\\underset{k\\in\\mathcal{P}_{1}}{\\operatorname*{max}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}_{3}}{\\operatorname*{min}}\\mu_{k^{\\prime}}(X_{3})+\\underset{k^{\\prime\\prime}\\in\\mathcal{P}_{2}}{\\operatorname*{min}}\\mu_{k^{\\prime\\prime}}(X_{2})-\\underset{k^{\\prime\\prime}\\in\\mathcal{P}_{2}}{\\operatorname*{max}}\\mu_{k^{\\prime\\prime}}(X_{2})-\\mu_{k}(X_{1})}\\\\ {\\le}&{\\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{max}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}_{3}}{\\operatorname*{min}}\\ \\mu_{k^{\\prime}}(X_{3})-\\mu_{k^{\\prime\\prime}}(X_{2})+\\underset{k\\in\\mathcal{P}_{1}}{\\operatorname*{max}}\\ \\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{min}}\\ \\mu_{k^{\\prime\\prime}}(X_{2})-\\mu_{k}(X_{1})}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Using a similar argument: ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{k\\in\\mathcal{P}_{3}}\\operatorname*{min}_{k^{\\prime}\\in\\mathcal{P}_{1}}\\mu_{k^{\\prime}}(X_{1})-\\mu_{k}(X_{2})\\leq\\operatorname*{max}_{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}\\operatorname*{min}_{k^{\\prime}\\in\\mathcal{P}_{1}}\\mu_{k^{\\prime}}(X_{1})-\\mu_{k^{\\prime\\prime}}(X_{2})+\\operatorname*{max}_{k\\in\\mathcal{P}_{3}}\\operatorname*{min}_{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}\\mu_{k^{\\prime\\prime}}(X_{2})-\\mu_{k}(X_{1})\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Noting that for any positive numbers $a,b,c,d$ $d,\\ \\operatorname*{max}\\{a+b,c+d\\}=\\operatorname*{max}\\{a+c,b+d\\}$ , we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{d_{p}(\\mathcal{P}_{1},\\mathcal{P}_{3})\\leq}&{}&{\\operatorname*{max}\\Big\\{\\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{max}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}_{3}}{\\operatorname*{min}}\\ \\mu_{k^{\\prime}}(X_{3})-\\mu_{k^{\\prime\\prime}}(X_{2})+\\underset{k\\in\\mathcal{P}_{1}}{\\operatorname*{max}}\\ \\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{min}}\\ \\mu_{k^{\\prime\\prime}}(X_{2})-\\mu_{k}(X_{1}),}\\\\ &{}&{\\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{max}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}_{1}}{\\operatorname*{min}}\\ \\mu_{k^{\\prime}}(X_{1})-\\mu_{k^{\\prime\\prime}}(X_{2})+\\underset{k\\in\\mathcal{P}_{3}}{\\operatorname*{max}}\\ \\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{min}}\\ \\mu_{k^{\\prime\\prime}}(X_{2})-\\mu_{k}(X_{3})\\Big\\}}\\\\ &{=}&{\\operatorname*{max}\\Big\\{\\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{max}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}_{1}}{\\operatorname*{min}}\\ \\mu_{k^{\\prime}}(X_{1})-\\mu_{k^{\\prime\\prime}}(X_{2})+\\underset{k^{\\prime}\\in\\mathcal{P}_{1}}{\\operatorname*{max}}\\ \\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{min}}\\ \\mu_{k^{\\prime\\prime}}(X_{2})-\\mu_{k^{\\prime}}(X_{1}),}\\\\ &{}&{\\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{max}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}_{3}}{\\operatorname*{min}}\\ \\mu_{k^{\\prime}}(X_{3})-\\mu_{k^{\\prime\\prime}}(X_{2})+\\underset{k\\in\\mathcal{P}_{3}}{\\operatorname*{max}}\\ \\underset{k^{\\prime\\prime}\\in\\mathcal{P}(X_{2})}{\\operatorname*{min}}\\ \\mu_{k^{ \n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "(c) We now show that $d_{p}(\\mathcal{P}_{1},\\mathcal{P}_{2})\\,=\\,0\\quad\\Longleftrightarrow\\ \\mathcal{P}_{1}\\,=\\,\\mathcal{P}_{2}$ . The implication $\\mathcal{P}_{1}\\,=\\,\\mathcal{P}_{2}\\quad\\Longrightarrow$ $d_{p}(\\mathcal{P}_{1},\\mathcal{P}_{2})=0$ is immediate. For the other side, note that by Definition 5.2, we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{d_{p}\\left(\\mathcal{P}_{1},\\mathcal{P}_{2}\\right)=0}\\\\ {\\implies}&{}&{\\displaystyle\\operatorname*{sup}_{k\\in\\mathcal{P}_{1}}\\Delta(k,\\mathcal{P}_{2})=0\\,\\mathrm{~and~}\\operatorname*{sup}_{k\\in\\mathcal{P}_{2}}\\Delta(k,\\mathcal{P}_{1})=0}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Further, $\\mathrm{sup}_{k\\in\\mathcal{P}_{1}}\\Delta(k,\\mathcal{P}_{2})=0$ implies: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\forall\\;k\\in\\mathcal{P}_{1},k\\;\\neq\\!c\\;k^{\\prime},\\;k^{\\prime}\\in\\mathcal{P}_{2}\\;\\Longleftrightarrow\\;\\forall\\;k\\in\\mathcal{P}_{1},\\;k\\in\\mathcal{P}_{2}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "A similar agrument using $\\operatorname*{sup}_{k\\in\\mathcal{P}_{1}}\\Delta(k,\\mathcal{P}_{1})=0$ implies that \u2200k \u2208P2, $k\\ \\not\\subset\\mathcal{E}c\\ k^{\\prime},k^{\\prime}\\in\\mathcal{P}_{1}$ ", "page_idx": 21}, {"type": "text", "text": "2. We now show that $\\mathcal{Z}$ is compact under the metric $d_{p}$ . Consider a sequence of Pareto fronts $\\mathcal{P}_{1},\\mathcal{P}_{2},\\ldots,\\mathcal{P}_{n}\\in\\mathcal{Z}$ and $\\mathcal{P}$ be the candidate for limiting Pareto front. ", "page_idx": 21}, {"type": "text", "text": "\u2022 Boundedness of $\\mathcal{P}$ is immediate.   \n\u2022 $\\mathcal{P}$ is convex since $\\mathcal{P}_{n},\\mathcal{P}_{n+1}$ are convex and $\\lambda\\mathcal{P}_{n}+(1-\\lambda)\\mathcal{P}_{n+1}$ is also convex for all $\\lambda\\in[0,1]$ .   \n\u2022 $\\mathcal{P}_{n}\\to\\mathcal{P}$ , therefore, $\\forall\\;\\epsilon\\,>\\,0,\\exists\\;N(\\epsilon)$ s.t. $\\forall\\:n\\>N(\\epsilon)$ and $d_{p}(P_{n},P)\\,<\\,\\epsilon$ . Let $\\mu_{k}$ be a limit point of $\\mathcal{P}$ , i.e., \u2203a sequence $\\mu_{k,n}\\in\\mathcal{P}$ such that $\\mu_{k,n}\\rightarrow\\mu_{k}$ . Since $d_{p}\\left(\\mathcal{P}_{n},\\mathcal{P}\\right)\\rightarrow0$ for each $\\mu_{k,n}\\in\\mathcal{P}$ there exists $\\mu_{k,n,m}\\in\\mathcal P_{n}$ s.t. $\\mu_{k,n,m}\\to\\mu_{k,n}$ . Using a diagonalization argument, we can obtain a subsequence $\\mu_{k,n,m}\\to\\mu_{k}$ . Since ${\\mathcal{P}}_{n}$ is compact, $\\mu_{k}$ must lie in $\\mathcal{P}$ and therefore, $\\mathcal{P}$ is closed. ", "page_idx": 21}, {"type": "text", "text": "D.2 Proof of Theorem 5.2 ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Lemma D.3. There exists constants $C_{1},C_{2}$ such that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\bar{\\mathcal{G}}_{T}\\right)\\le\\exp\\left(-C T^{1/8}\\right)\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Proof. We then have that: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l l}{\\mathbb{P}\\left(d_{p}\\left(\\hat{\\mathcal{P}}_{t},\\mathcal{P}^{*}\\right)\\geq\\epsilon\\right)}&{=}&{\\mathbb{P}\\left(\\operatorname*{max}\\left\\{d\\left(\\hat{\\mathcal{P}}_{t},\\mathcal{P}^{*}\\right),d\\left(\\mathcal{P}^{*},\\hat{\\mathcal{P}}_{t}\\right)\\right\\}\\geq\\epsilon\\right)}\\\\ &{\\leq}&{\\mathbb{P}\\left(d\\left(\\hat{\\mathcal{P}}_{t},\\mathcal{P}^{*}\\right)\\geq\\epsilon\\right)+\\mathbb{P}\\left(d\\left(\\mathcal{P}^{*},\\hat{\\mathcal{P}}_{t}\\right)\\geq\\epsilon\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Focusing on the first term we have: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d\\left(\\hat{\\mathcal{P}}_{t},\\mathcal{P}^{*}\\right)=\\underset{k\\in\\hat{\\mathcal{P}}_{t}}{\\operatorname*{inf}}\\ \\underset{k^{\\prime}\\in\\mathcal{P}^{*}}{\\operatorname*{sup}}\\,\\operatorname*{max}\\left\\lbrace0,\\underset{z\\in\\mathcal{C}\\cap\\mathbb{B}(1)}{\\operatorname*{max}}z^{(\\ell)}\\left(\\mu_{k^{\\prime}}^{(\\ell)}-\\hat{\\mu}_{k,t}^{(\\ell)}\\right)\\right\\rbrace\\geq\\underset{(k,k^{\\prime})}{\\sum}\\beta_{k k^{\\prime}}(t)}\\\\ &{\\overset{(a)}{=}\\underset{k\\in\\hat{\\mathcal{P}}_{t}}{\\operatorname*{min}}\\,\\underset{k^{\\prime}\\in\\mathcal{P}^{*}}{\\operatorname*{max}}\\,\\operatorname*{max}\\left\\lbrace0,\\underset{z\\in\\mathcal{C}\\cap\\mathbb{B}(1)}{\\operatorname*{max}}z^{(\\ell)}\\left(\\mu_{k^{\\prime}}^{(\\ell)}-\\hat{\\mu}_{k^{\\prime},t}^{(\\ell)}+\\hat{\\mu}_{k^{\\prime},t}^{(\\ell)}-\\hat{\\mu}_{k,t}^{(\\ell)}\\right)\\right\\rbrace}\\\\ &{\\overset{(b)}{\\leq}\\underset{k^{\\prime}\\in\\mathcal{P}^{*}}{\\operatorname*{max}}\\,\\operatorname*{max}\\left\\lbrace0,\\underset{z\\in\\mathcal{C}\\cap\\mathbb{B}(1)}{\\operatorname*{max}}z^{(\\ell)}\\left(\\mu_{k^{\\prime}}^{(\\ell)}-\\hat{\\mu}_{k^{\\prime},t}^{(\\ell)}\\right)\\right\\rbrace}\\\\ &{\\quad+\\underset{k^{\\prime}\\in\\mathcal{P}^{*}}{\\operatorname*{max}}\\,\\operatorname*{max}\\left\\lbrace0,\\underset{z\\in\\mathcal{C}\\cap\\mathbb{B}(1)}{\\operatorname*{max}}z^{(\\ell)}\\left(\\hat{\\mu}_{k^{\\prime}}^{(\\ell)}-\\hat{\\mu}_{k,t}^{(\\ell)}\\right)\\right\\rbrace}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "From Lemma D.1 with probability $1-\\delta$ we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\left|z^{\\top}\\left(\\mu_{k}^{\\left(\\ell\\right)}-\\mu_{k^{\\prime}}^{\\left(\\ell\\right)}\\right)-z^{\\top}\\left(\\widehat{\\mu}_{k,t}^{\\left(\\ell\\right)}-\\widehat{\\mu}_{k^{\\prime},t}^{\\left(\\ell\\right)}\\right)\\right|\\leq\\beta_{k k^{\\prime}}(t)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Therefore, with probability $1-\\delta$ , we have: ", "page_idx": 22}, {"type": "equation", "text": "$$\nd_{p}\\left(\\hat{\\mathcal{P}}_{t},\\mathcal{P}^{*}\\right)\\leq\\sum_{k\\in[K]}\\beta_{k}+\\sum_{(k,k^{\\prime})}\\beta_{k k^{\\prime}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "An identical argument shows that with probability $1-\\delta$ , ", "page_idx": 22}, {"type": "equation", "text": "$$\nd_{p}\\left(\\mathcal{P}^{*},\\hat{\\mathcal{P}}_{t}\\right)\\leq\\sum_{k\\in[K]}\\beta_{k}+\\sum_{(k,k^{\\prime})}\\beta_{k k^{\\prime}}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Now, we observe that $\\begin{array}{r}{\\beta_{k}(t)=O(\\sqrt{\\frac{\\log t}{t}})}\\end{array}$ . This allows us to hereafter follow the similar arguments as in Lemma 19 of (Garivier and Kaufmann, 2016), and prove that ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\bar{\\mathcal{G}}_{T}\\right)\\leq\\exp\\left(-C T^{1/8}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Theorem D.1 (Restating Theorem 5.2). For any $\\alpha>0$ and $c(t,\\delta)$ defined in (8), we have that the stopping time satisfies : ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{\\delta\\to0}{\\frac{\\mathbb{E}[\\tau]}{\\log\\left({\\frac{1}{\\delta}}\\right)}}\\leq\\alpha{\\bar{T}}_{\\mathcal{F}}(M)\\,\\forall\\,M\\in\\mathbb{R}^{K\\times L}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Proof. Step 1: Good Event Let $T\\in\\mathbb N$ , and $h(T)=\\sqrt{T}$ , define the good event: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathcal{G}_{T}=\\cap_{t=h(T)}^{T}\\left\\{d_{p}(\\hat{\\mathcal{P}}_{t},\\mathcal{P}^{*})\\leq f(\\epsilon)\\right\\}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "where, $f(\\epsilon)$ is such that: ", "page_idx": 22}, {"type": "equation", "text": "$$\nd_{p}(\\hat{\\mathcal{P}}_{t},\\mathcal{P}^{*})\\leq f(\\epsilon)\\implies\\operatorname*{sup}_{w^{\\prime}\\in w^{*}(\\hat{\\mathcal{P}}_{\\tau})}\\operatorname*{sup}_{w\\in w^{*}(\\mathcal{P}^{*})}\\|w^{\\prime}-w\\|\\leq\\epsilon\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Step 2: Concentration of Good Event In Lemma D.3, we show that: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left({\\bar{\\mathcal{G}}}_{T}\\right)\\leq\\exp\\left(-c T^{\\frac{1}{8}}\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Step 3: Tracking Lemma From (Garivier and Kaufmann, 2016), we have that: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{k}\\left|N_{k,t}-\\sum_{t}w_{k,t}\\right|\\leq K\\left(1+\\sqrt{t}\\right)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Step 4: Complexity of the good event ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Assume $t\\geq T_{\\epsilon}$ , and let: ", "page_idx": 22}, {"type": "equation", "text": "$$\nC_{\\epsilon}\\left(M\\right)\\triangleq\\operatorname*{inf}_{w^{\\prime},M^{\\prime}}\\overline{{\\mathcal{V}}}_{\\mathcal{C}}\\left(w,M\\right),\\,\\forall(w,M)\\mathrm{~s.t.~}\\left\\|w^{\\prime}-w\\right\\|\\leq3\\epsilon,\\;d_{\\mathrm{P}}\\left(\\hat{P}_{t},\\mathcal{P}^{*}\\right)\\leq f(\\epsilon)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Then, we have that: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\overline{{\\nu}}_{c}\\left(N_{t},\\hat{M}_{t}\\right)\\geq t C_{\\epsilon}(M)\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Step 5: Bounding the stopping time for good and bad events ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Let $\\tau_{\\delta}$ be the stopping time, then: ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\operatorname*{min}\\{\\tau_{\\delta},T\\}\\leq\\sqrt{T}+\\sum_{t=T_{\\epsilon}}^{T}\\mathbb{1}_{\\tau_{\\delta}\\geq t}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "From the stopping rule (Equation (8)), we get that: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{T_{\\epsilon}+\\displaystyle\\sum_{t=T_{\\epsilon}}^{T}\\mathbb{1}_{\\overline{{\\gamma}}_{c}\\left(N_{t},\\hat{M}_{t}\\right)\\leq c(t,\\delta)}}&{\\leq}&{\\sqrt{T}+\\displaystyle\\sum_{t=T_{\\epsilon}}^{T}\\mathbb{1}_{t C_{\\epsilon}(M)\\leq c(t,\\delta)}}\\\\ &{\\leq}&{\\sqrt{T}+\\displaystyle\\frac{c(t,\\delta)}{C_{\\epsilon}(M)}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Define $\\begin{array}{r}{T_{\\delta}=\\operatorname*{inf}\\left\\{T\\in\\mathbb{N}:\\sqrt{T}+\\frac{c(t,\\delta)}{C_{\\epsilon}(M)}\\leq T\\right\\}}\\end{array}$ . Hence, we have: ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\mathbb{E}\\left[\\tau_{\\delta}\\right]\\le T_{\\epsilon}+T_{\\epsilon}+\\sum_{T=1}^{\\infty}B T\\exp\\left(-C T^{-1/8}\\right)\\le T_{\\epsilon}+T_{\\delta}+T^{\\prime}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Let $\\begin{array}{r}{C(\\eta)=\\operatorname*{inf}\\{T:T-\\sqrt{T}\\geq\\frac{T}{(1+\\eta)}\\}}\\end{array}$ . Then: ", "page_idx": 23}, {"type": "equation", "text": "$$\nT_{\\delta}\\leq C(\\eta)+\\operatorname*{inf}\\left\\{T\\in\\mathbb{N}:\\frac{T C_{\\epsilon}(M)}{(1+\\eta)}\\geq c(t,\\delta)\\right\\}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Step 6: Obtaining the asymptotic bounds Taking limits: ", "text_level": 1, "page_idx": 23}, {"type": "equation", "text": "$$\n\\operatorname*{lim}_{\\delta\\to0}\\operatorname*{inf}{\\frac{\\operatorname{\\mathbb{E}}\\left[\\tau_{\\delta}\\right]}{\\log\\left({\\frac{1}{\\delta}}\\right)}}\\leq\\alpha T(M)\\,\\forall\\,\\alpha\\geq1\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "E Reduction to Best-arm Identification ", "text_level": 1, "page_idx": 24}, {"type": "text", "text": "We briefly discuss how the metric $d_{\\mathrm{P}}\\left(\\cdot,\\cdot\\right)$ extends existing notions of gap in best-arm and Pareto-front identification literature. Specifically, we proceed with the three following observations. ", "page_idx": 24}, {"type": "text", "text": "1. Observe that $d_{\\mathrm{P}}\\left(\\mathcal{P}^{*},\\mathcal{P}^{*}\\right)=0$ . ", "page_idx": 24}, {"type": "text", "text": "2. Further, iff $\\mathcal{C}$ represents the component-wise ordering as in Pareto-front identification (Auer et al., 2016; Kone et al., 2023a), then $\\bar{z}^{(\\ell)}=1,\\,\\forall\\,\\ell\\in[L]$ . ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\begin{array}{r l}&{d_{\\mathrm{P}}\\left(\\left|K\\right|\\right\\rangle\\left\\langle P^{*},P^{*}\\right\\rangle\\right)}\\\\ &{=\\phantom{\\frac{1}{\\ensuremath{\\mathrm{P}}}}\\left\\{\\phantom{\\frac{1}{b}}\\!\\!\\!\\!\\!\\!\\!-\\!\\!\\!\\!\\!}\\\\ &{=\\phantom{\\frac{1}{\\ensuremath{\\mathrm{P}}}}k\\!\\!\\!\\!\\!\\!\\!}\\\\ &{=\\phantom{\\frac{1}{\\ensuremath{\\mathrm{P}}}}k\\!\\!\\!\\!\\!\\!\\!}\\\\ &{=\\phantom{\\frac{1}{\\ensuremath{\\mathrm{P}}}}\\left\\{\\phantom{\\frac{1}{b}}\\!\\!\\!\\!\\!\\!\\!+\\!\\!\\!\\!\\!\\!}\\\\ &{\\phantom{\\frac{1}{b}}\\!\\!\\!\\!\\!\\!\\!\\!}\\\\ &{\\qquad\\qquad\\qquad\\mathrm{sing~}\\frac{\\mathrm{inf}}{k\\!\\!\\!\\!\\!\\!-\\!\\!\\!\\!r_{c}^{\\prime}\\!\\!\\!\\!\\!\\!+\\!\\!\\!\\!\\!\\frac{1}{c}\\!\\!\\!\\!\\!\\!+\\!\\!\\!\\!\\!\\frac{1}{n}\\!\\!\\!\\!\\!\\!\\!}\\operatorname*{max}\\left\\{0,\\operatorname*{min}\\left(h^{(i)}-h^{(i)}\\right)\\right\\}\\,}\\\\ &{=\\phantom{\\frac{1}{\\ensuremath{\\mathrm{P}}}}k\\!\\!\\!\\!\\!\\!\\!+\\!\\!\\!\\!\\!\\!\\!\\!\\!}\\\\ &{\\phantom{\\frac{1}{b}}k\\!\\!\\!\\!\\!\\!\\!+\\!\\!\\!\\!\\!\\!\\!\\!\\!}\\\\ &{=\\phantom{\\frac{1}{\\ensuremath{\\mathrm{P}}}}k\\!\\!\\!\\!\\!\\!\\!\\!+\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\! \n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "3. Finally, when there is only a single objective, i.e., $|L|=1$ and assuming an unique optimal arm (fairly common assumption in BAI literature), we have: ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{d_{\\mathrm{P}}\\left(\\left[K\\right]\\backslash\\mathcal{P}^{*},\\mathcal{P}^{*}\\right)\\right)=\\operatorname*{max}\\left\\{\\underset{k\\in\\left[K\\right]\\backslash\\mathcal{P}^{*}}{\\operatorname*{sup}}d\\left(k,\\mathcal{P}^{*}\\right),\\underset{k\\in\\mathcal{P}^{*}}{\\operatorname*{sup}}d\\left(\\left[K\\right]\\backslash\\mathcal{P}^{*},k\\right)\\right\\}}\\\\ &{\\qquad\\qquad=\\operatorname*{max}\\left\\{\\underset{k\\in\\left[K\\right]\\backslash\\mathcal{k}^{*}}{\\operatorname*{sup}}\\operatorname*{max}\\left\\{0,(\\mu_{k}-\\mu_{k^{*}})\\right\\},}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\underset{k^{\\prime}\\in\\left[K\\right]\\backslash\\mathcal{k}^{*}}{\\operatorname*{sup}}\\operatorname*{max}\\left\\{0,(\\mu_{k^{*}}-\\mu_{k^{\\prime}})\\right\\}\\Bigg\\}}\\\\ &{\\qquad\\qquad\\qquad=\\underset{k^{\\prime}\\neq k^{*}}{\\operatorname*{min}}\\Delta_{k^{\\prime}}\\,,}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "which is exactly the gap for one-dimensional bandit. ", "page_idx": 24}, {"type": "text", "text": "F Technical Lemmas ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Lemma F.1. For any $k=1,2,\\ldots,K$ , let $1\\leq t_{k}\\leq t.$ . Let $\\eta>0$ and define the event: ", "page_idx": 25}, {"type": "equation", "text": "$$\nC\\triangleq\\cap_{k\\in[K]}C_{k}\\triangleq\\cap_{k\\in[K]}\\{t_{k}\\leq N_{k,t}\\leq(1+\\eta)t_{k}\\}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "and let $\\mathbb{1}_{C_{k}}$ denote that the event holds. For $\\rho\\ge(1+\\eta)K$ , we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\mathbb{1}_{C_{k}}\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}N_{k,t}d_{K L}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t}^{(\\ell)}\\right)\\geq\\rho\\right]\\leq\\left(\\frac{\\rho e}{K L}\\right)^{K L}\\exp\\left(\\frac{-\\rho}{1+\\eta}\\right)\\,.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. Fi $\\mathfrak{c}\\ \\zeta\\in\\mathbb{R}_{+}^{K\\times L}$ and t \u22650. Define m(k\u2113,)t such that: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r c l}{{m_{k,t}^{(\\ell)}}}&{{=}}&{{\\displaystyle\\left\\{m,\\;\\mathrm{if}\\;\\exists\\;0\\leq m\\leq M_{k}^{(\\ell)},\\;\\mathrm{s.t.}\\;t D_{\\mathrm{KL}}(m,M_{k}^{(\\ell)})=\\zeta_{k}^{(\\ell)}\\right.}}\\\\ {{}}&{{}}&{{\\displaystyle\\left.0,\\;\\mathrm{otherwise}\\right.}}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By monotonicity of $t D_{\\mathrm{KL}},\\;t\\to m_{k,t}^{(\\ell)}$ is increasing. With $t=N_{k,t}$ , we have that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{V}_{k,t}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},m_{k,N_{k,t}}^{(\\ell)}\\right)=\\zeta_{k}^{(\\ell)}\\leq N_{k,t}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t}^{(\\ell)}\\right),\\implies\\hat{M}_{k,t}^{(\\ell)}\\overset{(a)}{\\leq}m_{k,N_{k,t}}^{(\\ell)}\\overset{(b)}{\\leq}m_{k,(1+\\eta)t_{k}}^{(\\ell)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $(a)$ follows from monotonicity of $D_{\\mathrm{KL}}(\\cdot,\\cdot)$ and $(b)$ follows from monotonicity of $m_{k,t}^{(\\ell)}$ . With $\\begin{array}{r}{t_{k}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t_{k}\\left(1+\\eta\\right)}^{(\\ell)}\\right)=\\frac{\\zeta_{k}^{(\\ell)}}{1+\\eta}}\\end{array}$ a nd non-negativity of $D_{\\mathrm{KL}}$ we have: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left(\\cap_{k\\in[K]}\\cap_{\\ell\\in[L]}\\left\\{\\mathbb{1}_{C_{k}}\\cdot N_{k,t}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t}^{(\\ell)}\\right)\\geq\\zeta_{k}^{(\\ell)}\\right\\}\\right)}\\\\ {\\leq}&{\\mathbb{P}\\left(\\cap_{k\\in[K]}\\cap_{\\ell\\in[L]}\\left\\{\\hat{M}_{k,t}^{(\\ell)}\\leq m_{k,\\ell}^{(\\ell)},C_{k}\\right\\}\\right)}\\\\ {\\leq}&{\\mathbb{P}\\left(\\cap_{k\\in[K]}\\cap_{\\ell\\in[L]}\\left\\{\\hat{M}_{k,t}^{(\\ell)}\\leq m_{k,(1+\\eta)t_{k}}^{(\\ell)},C_{k}\\right\\}\\right)}\\\\ {\\leq}&{\\mathbb{I}_{k\\in[K]}\\Pi_{\\ell\\in[L]}\\mathbb{P}\\left(\\left\\{\\hat{M}_{k,t}^{(\\ell)}\\leq m_{k,(1+\\eta)t_{k}}^{(\\ell)},C_{k}\\right\\}\\right)}\\\\ {\\overset{(e)}{\\leq}}&{\\Pi_{k\\in[K]}\\Pi_{\\ell\\in[L]}\\exp\\left(-(1+\\eta)t_{k}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},m_{k}^{(\\ell)}(t)\\right)\\right)}\\\\ {=}&{\\exp\\left(-\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}(1+\\eta)t_{k}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},m_{k}^{(\\ell)}(t)\\right)\\right)}\\\\ {=}&{\\kappa\\exp\\left(-\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}(1+\\eta)t_{k}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},m_{k}^{(\\ell)}(t)\\right)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where, the $(c)$ follows from Lemma F.2. Using Lemma F.3, with $Z_{k}=$ and $\\begin{array}{r}{a=\\frac{1}{(1+)}}\\end{array}$ (11+), we have that: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left[\\mathbb{1}_{C_{k}}\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}N_{k,t}d_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t}^{(\\ell)}\\right)\\geq\\rho\\right]\\leq\\left(\\frac{\\rho e}{K L}\\right)^{K L}\\exp\\left(\\frac{-\\rho}{1+\\eta}\\right)\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "This concludes the proof. ", "page_idx": 25}, {"type": "text", "text": "Lemma F.2. For any $k=1,2,\\ldots,K$ let $1\\leq t_{k}\\leq t.$ . Then for all $0\\leq C_{k}^{(\\ell)}\\leq M_{k}^{(\\ell)}$ we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\cap_{k\\in[K]}\\cap_{\\ell\\in[L]}\\left\\{\\hat{M}_{k,t}^{(\\ell)}\\leq C^{(\\ell)},\\;t_{k}\\leq N_{k,t}\\right\\}\\right)\\leq\\exp\\left(-\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}t_{k}d_{K L}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t}^{(\\ell)}\\right)\\right)\\,.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Proof. For all $k\\in[K]$ and $\\ell\\in[L]$ define the moment generating function as: ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\phi_{k}^{(\\ell)}(\\lambda)=\\ln\\mathbb{E}_{M_{k}^{(\\ell)}}\\left[\\exp(\\lambda X)\\right],\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where $X$ is sampled from a single-parameter exponential family with mean $M_{k}^{(\\ell)}$ . From DonskerVardhan Variational Formula, (Theorem G.2 in Appendix $\\mathrm{G}$ ), we have that: ", "page_idx": 26}, {"type": "equation", "text": "$$\nd_{\\mathrm{KL}}\\left(M_{k}^{(\\ell)},\\hat{M}_{k,t}^{(\\ell)}\\right)=\\operatorname*{sup}_{\\lambda\\leq0}\\mathbb{E}_{\\hat{M}_{k,t}^{(\\ell)}}\\left[\\lambda X\\right]-\\ln\\mathbb{E}_{M_{k}^{(\\ell)}}\\left[\\exp(\\lambda X)\\right]\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Define the events $\\mathcal{E}_{1}:=\\cap_{k\\in[K]}\\left\\{t_{k}\\leq N_{k,t}\\right\\}$ and $\\mathcal{E}_{2}:=\\cap_{k\\in[K]}\\cap_{\\ell\\in[L]}\\left\\{\\hat{M}_{k,t}^{(\\ell)}\\leq C_{k}^{(\\ell)}\\right\\}$ and $\\mathcal{E}=$ $\\mathcal{E}_{1}\\cap\\mathcal{E}_{2}$ . ", "page_idx": 26}, {"type": "text", "text": "Define the martingale $\\begin{array}{r}{G_{t}=\\exp\\left(\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}\\lambda_{k}^{(\\ell)}X_{k,t}-N_{k,t}\\phi_{k}^{(\\ell)}(\\lambda_{k}^{(\\ell)})\\right)}\\end{array}$ . For all $t^{\\prime}\\le t,\\,G_{t^{\\prime}}=$ $\\begin{array}{r l}&{G_{t^{\\prime}-1}\\exp\\left(\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}\\lambda_{k}^{(\\ell)}\\dot{X}_{k,t^{\\prime}}-N_{k,t^{\\prime}}\\phi_{k}^{(\\ell)}(\\lambda_{k}^{(\\ell)})\\right)}\\\\ &{\\mathbb{E}\\left[G_{t}\\right]=1.}\\end{array}$ We deduce $\\mathbb{E}\\left[G_{t^{\\prime}}|\\mathcal{F}_{t^{\\prime}-1}\\right]\\,=\\,G_{t^{\\prime}-1}$ and ", "page_idx": 26}, {"type": "text", "text": "We then define", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\bar{\\mathbb{P}}(\\xi)}&{=\\mathbb{P}\\left(\\cap_{k\\in[K]}\\cap_{\\mathbb{C}[\\mathcal{U}]}\\left\\{X_{k,\\xi}\\leq N_{k,\\xi}C_{k,k}^{(0)},\\hat{x}(k)\\right\\}\\right)}\\\\ &{\\leq\\mathbb{P}\\left(\\mathbf{1}_{\\ell,\\kappa}\\leq1\\left\\{\\sum_{k:\\{k:\\xi\\}\\in\\bar{\\mathcal{U}}}\\sum_{k_{k}\\in\\bar{\\mathcal{U}}}\\sum_{\\underline{{\\xi}}\\in\\bar{\\mathcal{U}}}\\sum_{k:\\mathcal{G}}\\sum_{k_{k}:\\mathcal{G}}\\sum_{k_{k}^{(0)}\\in\\bar{\\mathcal{G}}}^{\\mathcal{U}}\\right\\}\\right)}\\\\ &{\\leq\\mathbb{P}\\left(\\mathbf{1}_{\\ell,\\kappa}\\leq1\\left\\{\\exp{\\left(\\sum_{k:\\mathcal{G}}\\sum_{k=1}^{\\mathcal{A}}\\lambda_{\\xi}^{(0)}X_{k,\\xi}\\right)}\\geq\\exp{\\left(\\sum_{k:\\{k:\\xi\\}\\in\\bar{\\mathcal{U}}}\\sum_{k_{k}\\in\\bar{\\mathcal}}C_{k,k}^{(0)}X_{k,\\xi}C_{k}^{(0)}\\right)}\\right\\}\\right)}\\\\ &{\\leq\\mathbb{P}\\left(\\mathbf{1}_{\\ell}\\leq1\\right)\\left\\{G_{\\ell}\\geq\\exp{\\left(\\sum_{k:\\mathcal{G}}\\sum_{k=1}^{\\mathcal{A}}\\lambda_{\\xi}^{(0)}N_{k,\\xi}C_{k}^{(0)}-\\lambda_{\\xi}^{(0)}\\phi_{k}^{\\prime}\\right)}\\right\\}\\right)}\\\\ &{\\leq\\mathbb{P}\\left(\\mathbf{1}_{\\ell}\\leq1\\leq\\mathbb{C}\\exp{\\left(\\sum_{k:\\mathcal{G}}\\sum_{k=1}^{\\mathcal{A}}\\sum_{k_{k}\\in\\bar{\\mathcal{G}}}\\sum_{k_{k}^{(0)}}^{\\mathcal{A}}\\sum_{k_{k}^{(0)}}^{\\mathcal{A}}\\phi_{k}^{\\prime}\\right)}\\right)\\right\\}}\\\\ &{\\leq\\mathbb{P}\\left(\\mathbf{1}_{\\ell}\\leq1\\leq\\mathbb{C}\\exp{\\left(\\sum_{k:\\mathcal{G}}\\sum_{k=1}^{\\mathcal{B}}N_{k,\\xi}(\\lambda_{k}^{(0)}C_{k}^{(0)}-\\phi_{k}^{\\prime})\\right)}\\right)}\\\\ &{\\leq\\mathbb{P}\\left(\\mathbf{1}_\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Using Markov\u2019s inequality and $\\mathbb{E}\\left[G_{t}\\right]=1$ , we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\left[\\mathcal{E}\\right]=\\mathbb{E}\\left[\\mathbb{1}_{\\mathcal{E}_{1}}G_{t}\\right]\\exp\\left(-\\displaystyle\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}N_{k,t}d_{\\mathrm{KL}}\\left(M_{k}^{\\ell},m_{k}^{(\\ell)}\\right)\\right)}\\\\ &{\\qquad\\le\\exp\\left(-\\displaystyle\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}N_{k,t}d_{\\mathrm{KL}}\\left(M_{k}^{\\ell},m_{k}^{(\\ell)}\\right)\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Lemma F.3. Let $a>0$ and $K\\geq2$ and $Z\\in\\mathbb{R}^{K\\times L}$ such that for all $\\xi\\in\\mathbb{R}_{+}^{K\\times L}$ we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(Z\\geq\\zeta\\right)\\geq\\exp\\left(-a\\sum_{k\\in\\left[K\\right]}\\sum_{\\ell\\in\\left[L\\right]}\\zeta_{k}^{(\\ell)}\\right)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then, for all $\\rho\\geq\\frac{K}{a}\\in\\mathbb{R}_{+}$ , we have: ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\sum_{k\\in[K]}\\sum_{\\ell\\in[L]}Z_{k,\\ell}\\geq\\rho\\right)\\geq\\left(\\frac{a e\\rho}{K L}\\right)^{K L}\\exp(-a\\rho)\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "G Useful Existing Results ", "text_level": 1, "page_idx": 27}, {"type": "text", "text": "Theorem G.1 (Berge\u2019s Maximum Theorem (Berge, 1877)). Let $\\boldsymbol{\\mathcal{U}}$ and $\\mathcal{V}$ be topological spaces, $f:\\mathcal{U}\\times\\mathcal{V}\\to\\mathbb{R}$ and $C:\\mathcal{U}\\to\\mathcal{V}$ be non-empty compact set for all $u\\in\\mathcal{U}$ . Then, $i f C$ is continuous at u, $f^{*}(u)=\\operatorname*{max}_{v\\in C(u)}f(u,v)$ is continuous and $C^{*}(u)\\,=\\,\\{v\\,\\in\\,C(u)\\,:\\,f^{*}(u)\\,=\\,f(u,v)\\}$ is upper-hemicontinuous. ", "page_idx": 27}, {"type": "text", "text": "Theorem G.2 (Donsker-Vardhan Variational Formula (Donsker and Varadhan, 1975)). For mutual information $K L(P||Q)$ , we have that: ", "page_idx": 27}, {"type": "equation", "text": "$$\nd_{\\mathrm{KL}}(P\\|Q)=\\operatorname*{sup}_{f}\\mathbb{E}_{P}\\left[f\\right]-\\ln\\mathbb{E}_{Q}\\left[\\exp(f)\\right]\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Lemma G.1 (Peskun Ordering (Peskun, 1973)). For any two random variables $X,Y$ on $\\mathbb{R}^{K L}$ the following are equivalent: ", "page_idx": 27}, {"type": "text", "text": "1. $X\\le_{s}Y$   \n2. For all $x\\in\\mathbb{R}^{K L},\\;\\mathbb{P}\\left[X\\geq x\\right]\\leq\\mathbb{P}\\left[Y\\geq x\\right]$   \n3. For all non-negative functions $f_{1},f_{2},\\ldots,f_{k}$ , we have that: $\\Pi_{i=1}^{K}f_{i}\\le\\Pi_{i=1}^{K}f_{i}$ ", "page_idx": 27}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and precede the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 28}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 28}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 28}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 28}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \u201d[Yes] \u201d is generally preferable to \u201d[No] \u201d, it is perfectly acceptable to answer \u201d[No] provided a proper justification is given (e.g., \u201derror bars are not reported because it would be too computationally expensive\u201d or \u201dwe were unable to find the license for the dataset we used\u201d). In general, answering \u201d[No] \u201d or \u201d[NA] \u201d is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 28}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 28}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\u201d, \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 28}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 28}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Justification: ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 28}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 28}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 28}, {"type": "text", "text": "Justification: ", "page_idx": 28}, {"type": "text", "text": "Guidelines: ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \u201dLimitations\u201d section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 29}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 29}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 29}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 29}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 29}, {"type": "text", "text": "Answer: [Yes]   \nJustification:   \nGuidelines: \u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 29}, {"type": "text", "text": "", "page_idx": 30}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). ", "page_idx": 30}, {"type": "text", "text": "\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 31}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 31}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 31}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \u201dYes\u201d if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 31}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 31}, {"type": "text", "text": "Answer: [NA]   \nJustification:   \nGuidelines: \u2022 The answer NA means that the paper does not include experiments. \u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 31}, {"type": "text", "text": "", "page_idx": 32}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 32}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 32}, {"type": "text", "text": "Justification: Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 32}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 32}, {"type": "text", "text": "Answer: [NA]   \nJustification:   \nGuidelines: \u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 32}, {"type": "text", "text": "", "page_idx": 33}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] Justification: ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 33}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 33}, {"type": "text", "text": "Justification: ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 33}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 33}, {"type": "text", "text": "Answer: [NA] Justification: ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with humansubjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 34}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] Justification: Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 34}]