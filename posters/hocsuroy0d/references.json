{"references": [{"fullname_first_author": "Martin Abadi", "paper_title": "Deep learning with differential privacy", "publication_date": "2016", "reason": "This paper is foundational for the application of differential privacy to deep learning, providing the basis for many subsequent works, including the DP-SGD algorithm used in this paper."}, {"fullname_first_author": "Cynthia Dwork", "paper_title": "Calibrating noise to sensitivity in private data analysis", "publication_date": "2006", "reason": "This paper is a seminal work that introduced the concept of differential privacy and is frequently cited as the foundational paper for the field."}, {"fullname_first_author": "Cynthia Dwork", "paper_title": "The algorithmic foundations of differential privacy", "publication_date": "2014", "reason": "This work provides a comprehensive theoretical treatment of differential privacy, which is essential for understanding and applying the techniques discussed in the target paper."}, {"fullname_first_author": "Jinshuo Dong", "paper_title": "Gaussian differential privacy", "publication_date": "2022", "reason": "This paper introduces f-differential privacy, which is a key theoretical framework underpinning the main methodological contributions of the target paper."}, {"fullname_first_author": "Vadym Doroshenko", "paper_title": "Connect the dots: Tighter discrete approximations of privacy loss distributions", "publication_date": "2022", "reason": "This paper presents the tight privacy analysis method, a key algorithmic component that is extended in the target paper to enable direct calibration of noise to attack risk."}]}