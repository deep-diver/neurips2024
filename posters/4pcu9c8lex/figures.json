[{"figure_path": "4pCu9c8leX/figures/figures_1_1.jpg", "caption": "Figure 1: Examples of the keypoints detected by Key-Grid. The detected keypoints preserve semantic consistency under: (Top) large intra-category shape variations of rigid-body objects from the ShapeNetCoreV2 [2] dataset; (Bottom) dramatic deformations of soft-body objects from the ClothesNet [49] dataset.", "description": "This figure showcases the robustness of the Key-Grid model in detecting 3D keypoints across various object shapes and deformations.  The top row displays rigid objects with significant intra-class shape differences, while the bottom row demonstrates the model's ability to maintain keypoint consistency even under extreme deformations of soft objects like clothing.", "section": "1 Introduction"}, {"figure_path": "4pCu9c8leX/figures/figures_3_1.jpg", "caption": "Figure 2: Pipeline of Key-Grid. In the encoder section, given a point cloud, we detect the keypoints by utilizing the PointNet++. Then, we utilize the detected keypoints to form the grid heatmap. In the decoder section, we use each layer of the PointNet++ and the grid heatmap to reconstruct the input point cloud. \u201cMLP\u201d stands for multi-layer perceptron, which contains Batch-norm and ReLU. Additionally, following the practice in Skeleton Merger [26], the encoder outputs an additional head to predict the weights of CK = K(K \u2013 1)/2 skeleton segments, i.e., the edges between each pair of keypoints. Formally, (ki, kj) denotes the skeleton segment connecting the keypoints ki \u2208 R\u00b3 and kj \u2208 R\u00b3, and sij denotes the weight of the skeleton segment (ki, kj).", "description": "This figure illustrates the overall architecture of the Key-Grid model. The encoder uses PointNet++ to predict keypoints and their corresponding weights, while the decoder utilizes these keypoints and their associated features to reconstruct the 3D point cloud.  The key innovation is the use of a grid heatmap, which encodes the keypoint relationships in a dense 3D feature map that helps the decoder reconstruct the shape, especially when dealing with deformable objects.", "section": "3 Method"}, {"figure_path": "4pCu9c8leX/figures/figures_4_1.jpg", "caption": "Figure 3: Example of distance definition on the grid heatmap.", "description": "The figure illustrates the concept of using maximum distance instead of minimum distance to compute features in the grid heatmap. It highlights that using minimum distance may not effectively distinguish between points inside and outside an object, whereas maximum distance provides a clearer distinction.  Specifically, it shows that the minimum distance between a grid point (p1) inside the pants and the skeleton is the same as that between a grid point (p0) outside the pants and the skeleton. However, using maximum distance, the value for p1 is less than the value for p0, clearly differentiating their positions relative to the object.", "section": "3.2 Grid Heatmap: Dense 3D Feature Map"}, {"figure_path": "4pCu9c8leX/figures/figures_7_1.jpg", "caption": "Figure 4: Different methods on the Hat and Long Pant categories during the dropping and dragging processes. (a) and (b): Keypoint detection of Hat under the dropping and dragging deformation. (c) and (d): Keypoint detection of Long Pant under the dropping and dragging deformation. We use lines to connect keypoints of the same color, representing the positional changes of the same keypoints in the deformation process of the objects.", "description": "This figure compares the performance of four different keypoint detection methods (KD, SM, SC3K, and Key-Grid) on two clothing items (Hat and Long Pant) undergoing dropping and dragging deformations.  The images show the detected keypoints on the objects at various stages of deformation. Lines connect corresponding keypoints across different deformation stages to highlight their movement and preservation of semantic meaning.", "section": "4.2 Results"}, {"figure_path": "4pCu9c8leX/figures/figures_8_1.jpg", "caption": "Figure 5: Keypoints detected on the Fold Clothes, the Deep Fash3D V2 dataset and the SUN3D dataset. (a) and (b): Eight keypoints identified by different methods during the folding process of clothes. The lines connect the keypoints with the same color, which means the positions of these keypoints change in the deformation process. (c): Grid Heatmaps and Skeleton Structures on the fold clothes. In the skeleton structures, we use purple dots to connect the keypoints identified by SM to construct the skeleton. In the grid heatmap, we use colors to represent the values of D(p), with yellow indicating smaller values. The yellow dots capture the geometric structure of the folded clothes. (d): Keypoints detected by Key-Grid on the Deep Fash3D V2 and the SUN3D dataset.", "description": "This figure visualizes keypoint detection results on folded clothes using different methods, including Key-Grid, Skeleton Merger (SM), KeypointDeformer (KD), and SC3K.  Subfigures (a) and (b) compare the keypoint locations across methods during a folding deformation.  (c) shows a comparison of the grid heatmap and skeleton structure representations used by Key-Grid and SM, respectively. Finally, (d) displays keypoint detection on more complex datasets (DeepFashion3D V2 and SUN3D).", "section": "3.3 Decoder: Point Could Reconstruction"}, {"figure_path": "4pCu9c8leX/figures/figures_8_2.jpg", "caption": "Figure 6: Robustness Analysis of Key-Grid and Visualization Results of the SE(3)-Equivariant Keypoints. (a) and (b): DAS value under Gaussian noise and downsampling. (c): Visualization results of Key-Grid under these situations. The Gaussian noise scale is 0.06 and the downsample rate is 8x, respectively. (d): Keypoints on the folded pants undergoing SE(3) transformations. (e):Keypoint detection on the on occluded, side view, and outlier-laden point clouds.", "description": "This figure demonstrates the robustness of the Key-Grid model to various types of noise and data corruptions.  Subfigures (a) and (b) show the Dual Alignment Score (DAS) results under increasing levels of Gaussian noise and downsampling, respectively.  Subfigure (c) shows visualizations illustrating the keypoint detection performance under these conditions. Subfigure (d) shows the results of SE(3)-equivariant keypoints. Subfigure (e) visualizes the impact of occlusions, outliers, and different viewpoints.", "section": "4.3 Robustness Analysis"}, {"figure_path": "4pCu9c8leX/figures/figures_14_1.jpg", "caption": "Figure 7: Different number of detected keypoints on the folded pants. Key-Grid identifies different numbers (6, 8, 10, 12) of keypoints on the folded pants, respectively.", "description": "This figure shows the results of Key-Grid's keypoint detection on folded pants with varying numbers of keypoints (6, 8, 10, and 12). Each row displays the detected keypoints on multiple instances of folded pants, demonstrating that the keypoints consistently locate at semantically meaningful positions across different folding configurations.  The consistent keypoint positions, even with shape variations, showcase the method's robustness and ability to capture meaningful structural information about deformable objects.", "section": "Visualization Results"}, {"figure_path": "4pCu9c8leX/figures/figures_15_1.jpg", "caption": "Figure 8: Visualization results of the ablation study on the folded pants.", "description": "This figure visualizes the results of an ablation study conducted on a folded pants dataset.  The study investigated the impact of removing different components of the Key-Grid model, such as encoder information, grid heatmap, similarity loss, and farthest point keypoint loss. Each row shows the keypoint detection results when one component was removed, demonstrating the importance of each part in achieving accurate and consistent keypoint localization.", "section": "3.4 Training Objectives"}, {"figure_path": "4pCu9c8leX/figures/figures_15_2.jpg", "caption": "Figure 9: Performance of Key-Grid on the noisy point clouds. We indicate the level of Gaussian noise added underneath each noisy point cloud. \u201cNoise 0.00\u201d is the original point cloud.", "description": "This figure shows the robustness of Key-Grid to Gaussian noise. Four visualizations are presented, each showing the detected keypoints on a point cloud with increasing levels of added Gaussian noise (Noise 0.00, Noise 0.02, Noise 0.04, Noise 0.08).  Noise 0.00 represents the original point cloud without added noise. The keypoints maintain their positions despite the presence of increasing noise, illustrating the algorithm's robustness.", "section": "4.3 Robustness Analysis"}, {"figure_path": "4pCu9c8leX/figures/figures_16_1.jpg", "caption": "Figure 10: Performance of Key-Grid on the downsampled point clouds. The input point clouds are downsampled for different scales, as mentioned at the bottom of each point cloud. \u201c2048 sampled points\u201d is the input point cloud.", "description": "This figure demonstrates the robustness of Key-Grid to downsampling.  It shows the detected keypoints on a folded pant point cloud downsampled to 1024, 512, and 128 points.  The keypoints maintain reasonable accuracy and consistency even with significant reduction in the number of points.", "section": "4.3 Robustness Analysis"}, {"figure_path": "4pCu9c8leX/figures/figures_16_2.jpg", "caption": "Figure 1: Examples of the keypoints detected by Key-Grid. The detected keypoints preserve semantic consistency under: (Top) large intra-category shape variations of rigid-body objects from the ShapeNetCoreV2 [2] dataset; (Bottom) dramatic deformations of soft-body objects from the ClothesNet [49] dataset.", "description": "This figure showcases the robustness of the Key-Grid model in detecting 3D keypoints across various shape variations and deformations.  The top row shows examples of rigid-body objects from the ShapeNetCoreV2 dataset, demonstrating consistent keypoint detection despite significant shape differences within the same object category. The bottom row displays examples of deformable objects from the ClothesNet dataset, highlighting the model's ability to maintain semantic consistency even with significant deformations. The consistent keypoint locations across different poses illustrate the method's effectiveness.", "section": "1 Introduction"}, {"figure_path": "4pCu9c8leX/figures/figures_17_1.jpg", "caption": "Figure 12: Keypoint detection on the ShapeNetCoreV2 dataset. The keypoints are detected by SM and Key-Grid on the \u201cBed\u201d, \u201cGuitar\u201d, \u201cCar\u201d, and \u201cMotorcycle\u201d category of objects in the ShapeNetCoreV2 dataset. Each category shows four samples.", "description": "This figure compares the keypoint detection results of the Skeleton Merger (SM) method and the proposed Key-Grid method on four different categories of objects from the ShapeNetCoreV2 dataset: Bed, Guitar, Car, and Motorcycle.  Each category shows four different instances or viewpoints of the object, demonstrating the ability of each method to locate keypoints consistently across variations in shape and orientation. The colored spheres represent the detected keypoints. By comparing the keypoint locations across both methods for each object, one can visually assess the accuracy and consistency of each keypoint detection approach on rigid objects.", "section": "4 Experiments"}, {"figure_path": "4pCu9c8leX/figures/figures_17_2.jpg", "caption": "Figure 1: Examples of the keypoints detected by Key-Grid. The detected keypoints preserve semantic consistency under: (Top) large intra-category shape variations of rigid-body objects from the ShapeNetCoreV2 [2] dataset; (Bottom) dramatic deformations of soft-body objects from the ClothesNet [49] dataset.", "description": "This figure shows examples of 3D keypoint detection results obtained using the proposed Key-Grid method.  The top row demonstrates the method's ability to maintain consistent keypoint locations across various poses of rigid objects (ShapeNetCoreV2 dataset). The bottom row showcases the method's robustness in handling significant deformations of soft objects (ClothesNet dataset), highlighting the preservation of semantic keypoint consistency even under drastic shape changes.", "section": "1 Introduction"}, {"figure_path": "4pCu9c8leX/figures/figures_18_1.jpg", "caption": "Figure 13: Keypoint detection on the ClothesNet dataset. For the drop and drag deformation processes, we select the \u201cLong Dress\u201d, \u201cTie\u201d, and \u201cVest\u201d categories of objects to visualize the keypoints identified by SM and Key-Grid. We use lines to connect the keypoints at the same position during the deformation process.", "description": "This figure compares the keypoint detection results of Skeleton Merger (SM) and Key-Grid on deformable objects from the ClothesNet dataset.  The left column shows results using SM, and the right column shows results using Key-Grid.  Both methods are shown for 'Long Dress', 'Tie', and 'Vest' categories under 'drop' and 'drag' deformations.  Lines connect corresponding keypoints across different deformation stages to illustrate their consistency (or lack thereof). The figure highlights Key-Grid's superior performance in maintaining keypoint semantic consistency during significant shape changes.", "section": "4.2 Results"}]