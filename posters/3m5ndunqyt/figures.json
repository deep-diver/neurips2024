[{"figure_path": "3m5ndUNQYt/figures/figures_2_1.jpg", "caption": "Figure 1: Overview of proposed diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection. It includes multi-layer semantic feature extraction, Diffusion-based Feature Distortion and Reconstruction, and OOD detection head modules.", "description": "This figure illustrates the proposed framework's architecture for unsupervised out-of-distribution (OOD) detection. It consists of three main modules: 1. Multi-layer semantic feature extraction: Extracts features from different layers of the input image, providing both low-level and high-level semantic information.  2. Diffusion-based feature distortion and reconstruction: Uses a diffusion model to add Gaussian noise to the extracted features and then reconstructs them, aiming to differentiate ID and OOD samples based on reconstruction errors. 3. OOD detection head:  A module that uses the reconstruction errors from the previous stage to classify the input image as either in-distribution (ID) or OOD.  The overall process leverages the ability of diffusion models to reconstruct data and compact representation of ID data in feature space, improving OOD detection accuracy and speed.", "section": "3 Method"}, {"figure_path": "3m5ndUNQYt/figures/figures_3_1.jpg", "caption": "Figure 2: Residual Block Structure in LFDN.", "description": "This figure shows the architecture of a residual block (ResBlock) used in the Latent Feature Diffusion Network (LFDN).  The ResBlock consists of a main branch and a residual branch. The main branch includes Groupnorm, SiLU, and Linear layers. The residual branch consists of three linear layers and a SiLU activation function. The time embedding is also incorporated into the residual block. The outputs of the main and residual branches are then summed together to produce the final output of the ResBlock.", "section": "3.2 Diffusion-based Feature Distortion and Reconstruction"}, {"figure_path": "3m5ndUNQYt/figures/figures_7_1.jpg", "caption": "Figure 3: The MFsim score distributions of the first epoch (left) and the last epoch (right)", "description": "This figure shows the evolution of the MFsim score distributions for both in-distribution (ID) and out-of-distribution (OOD) samples across different datasets (CIFAR-10 as ID, others as OOD).  The left panel displays the distributions at the first epoch of training, while the right panel shows the distributions after the model has been trained. The comparison highlights the model's improved ability to distinguish between ID and OOD samples after training, as evidenced by the greater separation of distributions in the right panel. This visual representation demonstrates the effectiveness of the proposed diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection.", "section": "4.4 Ablation Study"}, {"figure_path": "3m5ndUNQYt/figures/figures_8_1.jpg", "caption": "Figure 4: CIFAR-10 dataset is the ID data, the six datasets listed in Table 3 are used as OOD data. The average AUROC and FPR95 for the three metrics are evaluated at different sampling time steps.", "description": "The figure shows the performance of the proposed method with different sampling time steps (t). The x-axis represents the sampling time step, while the y-axis shows AUROC and FPR@95TPR.  The results demonstrate how the performance changes with different noise levels added during the feature distortion process. It helps to find the optimal noise level for better OOD detection performance. ", "section": "4.4 Ablation Study"}, {"figure_path": "3m5ndUNQYt/figures/figures_8_2.jpg", "caption": "Figure 1: Overview of proposed diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection. It includes multi-layer semantic feature extraction, Diffusion-based Feature Distortion and Reconstruction, and OOD detection head modules.", "description": "This figure shows a schematic of the proposed diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection.  It consists of three main modules: a multi-layer semantic feature extraction module that processes the input image and extracts features at multiple levels, a diffusion-based feature distortion and reconstruction module that adds noise to the features and uses a diffusion network to reconstruct them, and an OOD detection head module that uses the reconstruction error to classify the input as either in-distribution (ID) or out-of-distribution (OOD).", "section": "3 Method"}, {"figure_path": "3m5ndUNQYt/figures/figures_15_1.jpg", "caption": "Figure 3: The MFsim score distributions of the first epoch (left) and the last epoch (right)", "description": "This figure shows the distribution of MFsim scores for both in-distribution (ID) and out-of-distribution (OOD) samples at the beginning and end of training.  The change in distribution demonstrates the model's improved ability to distinguish between ID and OOD samples over time.  The ID samples' MFsim scores become more tightly clustered around a lower value, while the OOD samples remain more dispersed and have higher scores. This visualization supports the effectiveness of the model's reconstruction process in separating ID and OOD data in the feature space.", "section": "4.4 Ablation Study"}, {"figure_path": "3m5ndUNQYt/figures/figures_15_2.jpg", "caption": "Figure 3: The MFsim score distributions of the first epoch (left) and the last epoch (right)", "description": "This figure shows the distribution of MFsim scores for both in-distribution (ID) and out-of-distribution (OOD) samples at the beginning and end of training.  The plots illustrate how the model's ability to distinguish between ID and OOD samples improves during training. The distribution of MFsim scores for ID samples becomes more concentrated near 0, while the distribution for OOD samples remains relatively flat.", "section": "4.4 Ablation Study"}, {"figure_path": "3m5ndUNQYt/figures/figures_18_1.jpg", "caption": "Figure 8: Reconstruction Error Distribution of ID and OOD Samples for Pixel-level", "description": "This figure shows the distribution of reconstruction errors (MSE) for both in-distribution (ID) and out-of-distribution (OOD) samples at the pixel level.  The different colored curves represent different datasets. The purpose is to illustrate that at the pixel level, it is difficult to distinguish ID and OOD samples based on reconstruction error alone, as the distributions overlap significantly.", "section": "D Qualitative results"}, {"figure_path": "3m5ndUNQYt/figures/figures_18_2.jpg", "caption": "Figure 3: The MFsim score distributions of the first epoch (left) and the last epoch (right)", "description": "This figure shows the distribution of MFsim scores for both in-distribution (ID) and out-of-distribution (OOD) samples at the beginning and end of training.  The change in distribution demonstrates the model's improved ability to distinguish ID from OOD data over time, as the reconstruction error for ID samples decreases while that of OOD samples remains relatively stable. This illustrates the efficacy of the proposed diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection.", "section": "4.4 Ablation Study"}, {"figure_path": "3m5ndUNQYt/figures/figures_18_3.jpg", "caption": "Figure 1: Overview of proposed diffusion-based layer-wise semantic reconstruction framework for unsupervised OOD detection. It includes multi-layer semantic feature extraction, Diffusion-based Feature Distortion and Reconstruction, and OOD detection head modules.", "description": "This figure illustrates the proposed framework for unsupervised out-of-distribution detection. The framework consists of three main modules: 1. Multi-layer semantic feature extraction which extracts features from multiple layers of a CNN; 2. Diffusion-based feature distortion and reconstruction that applies a diffusion model for feature reconstruction after adding Gaussian noise to multi-layer semantic features; and 3. OOD detection head module which evaluates the reconstruction error for OOD detection. ", "section": "3 Method"}]