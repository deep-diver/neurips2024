{"references": [{"fullname_first_author": "Holger Caesar", "paper_title": "nuScenes: A multimodal dataset for autonomous driving", "publication_date": "2020-06-01", "reason": "This paper introduces the nuScenes dataset, which is the primary dataset used for evaluating the proposed method in this research, making it fundamentally important to the study."}, {"fullname_first_author": "Yingwei Li", "paper_title": "Deepfusion: Lidar-camera deep fusion for multi-modal 3d object detection", "publication_date": "2022-06-01", "reason": "This paper presents a state-of-the-art multi-modal fusion method, which is directly compared against and improved upon by the approach detailed in the current research."}, {"fullname_first_author": "Zhiqi Li", "paper_title": "BEVFormer: Learning birds-eye-view representation from multi-camera images via spatiotemporal transformers", "publication_date": "2022-06-01", "reason": "The BEVFormer architecture is the basis for a core component in the proposed framework, making it a crucial foundational paper for this work."}, {"fullname_first_author": "Geoffrey Hinton", "paper_title": "Distilling the knowledge in a neural network", "publication_date": "2015-03-01", "reason": "This is a seminal paper on knowledge distillation, which is a central technique in the proposed framework, making it a highly important foundational reference."}, {"fullname_first_author": "Zhijian Liu", "paper_title": "BEVFusion: Multi-task multi-sensor fusion with unified bird's-eye view representation", "publication_date": "2023-05-01", "reason": "This paper presents BEVFusion, a highly influential multi-modal fusion method which serves as a strong baseline and direct comparison for the proposed approach in the current research."}]}