[{"figure_path": "sp8wHIsnu9/figures/figures_0_1.jpg", "caption": "Figure 1: A user is expecting two diverse templates from the foundation model.", "description": "This figure illustrates the problem of generating diverse responses from a foundation model. A user requests a personal website template. The model provides two different templates as responses, highlighting the diversity of the outputs.  This scenario motivates the need for methods that generate diverse and high-quality responses, without sacrificing accuracy.", "section": "1 Introduction"}, {"figure_path": "sp8wHIsnu9/figures/figures_2_1.jpg", "caption": "Figure 2: pass@1 on HumanEval after fine-tuning on some percentage of OSS-Instruct dataset (Wei et al., 2023) using LORA. The plot demonstrates the diminishing returns observed with increasing amounts of data used for parameter-efficient fine-tuning.", "description": "This figure shows the performance (pass@1 on the HumanEval benchmark) of a model fine-tuned using LORA on increasing amounts of the OSS-Instruct dataset.  The plot demonstrates the law of diminishing returns; while performance improves with more data, the rate of improvement slows significantly as the amount of training data increases. This highlights the potential benefit of SPA, which uses data partitioning to train multiple specialized models rather than training a single model on the entire dataset.", "section": "3 Problem Formulation"}, {"figure_path": "sp8wHIsnu9/figures/figures_3_1.jpg", "caption": "Figure 3: An illustration of the Synthesize, Partition, then Adapt (SPA) framework. SPA partitions synthetic dataset according to data attribution scores, which can be obtained using various methods such as influence function or lexical overlap. Multiple foundation model adaptations are then trained on each subset. Sampling from the collection of these model adaptations can present users with diverse responses. SPA is not limited to a specific attribution method.", "description": "This figure illustrates the SPA framework.  First, synthetic data is generated and then analyzed using data attribution methods (like influence functions or lexical overlap) to score each data point's importance.  These scores are used to partition the dataset into subsets. Finally, multiple model adaptations are trained on these subsets, allowing the model to generate diverse responses by sampling from the adapted models.", "section": "4 Partitioning Synthetic Data and Training Adaptations"}, {"figure_path": "sp8wHIsnu9/figures/figures_7_1.jpg", "caption": "Figure 4: How sampling temperature affects pass@1, pass@5, and Diversity Score for different methods on the HumanEval benchmark. The results are averaged over 4 checkpoints.", "description": "This figure shows the impact of different sampling temperatures on the performance of various methods (single adaptation, random partitioning, lexical overlap, and influence function) for the HumanEval benchmark.  The x-axis represents the temperature used for sampling, while the y-axes represent pass@1 (the percentage of problems where at least one of the generated samples passes all test cases), pass@5 (the percentage of problems where at least five of the generated samples pass all test cases), and the Diversity Score (a measure of the uniqueness of generated samples).  Error bars are included to show variability across different checkpoints. The results demonstrate a trade-off between diversity and accuracy, with higher temperatures leading to greater diversity but potentially lower accuracy. The influence function consistently outperforms other methods across all temperature values.", "section": "5.2 Code Generation Results"}, {"figure_path": "sp8wHIsnu9/figures/figures_8_1.jpg", "caption": "Figure 5: Average KL divergence and diversity score on various natural language understanding tasks. SPA with influence function consistently outperforms the lexical overlap and random adaptations, demonstrating its effectiveness in generating diverse samples across different NLU tasks.", "description": "This figure compares the performance of three different methods for generating diverse responses from language models on four natural language understanding tasks: BBH, GPQA, MMLU, and Winogrande.  The methods are SPA with influence function, SPA with lexical overlap, and random adaptation. The figure shows that SPA with influence function consistently achieves higher average KL divergence and diversity scores across all four tasks, indicating that it is the most effective method for generating diverse responses.", "section": "5.3 Natural Language Understanding Results"}, {"figure_path": "sp8wHIsnu9/figures/figures_14_1.jpg", "caption": "Figure 6: Diversity score as function of the number of adaptations on the HumanEval benchmark.", "description": "This figure shows the diversity score obtained using different data partitioning methods (influence, lexical, random) as the number of model adaptations is varied from 8 to 12.  The results indicate that increasing the number of adaptations beyond a certain point does not significantly improve diversity, regardless of the chosen partitioning method. The influence method consistently achieves higher diversity scores than the other two methods.", "section": "5.2 Code Generation Results"}]