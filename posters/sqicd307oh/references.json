{"references": [{"fullname_first_author": "Mohammad Gheshlaghi Azar", "paper_title": "Minimax regret bounds for reinforcement learning", "publication_date": "2017-00-00", "reason": "This paper provides foundational minimax regret bounds for reinforcement learning, which are crucial to the theoretical analysis of the proposed state-free RL algorithm."}, {"fullname_first_author": "Chi Jin", "paper_title": "Is Q-learning provably efficient?", "publication_date": "2018-00-00", "reason": "This paper addresses the fundamental question of Q-learning's efficiency, which is highly relevant to the paper's focus on designing efficient parameter-free RL algorithms."}, {"fullname_first_author": "Richard S Sutton", "paper_title": "Reinforcement learning: An introduction", "publication_date": "2018-00-00", "reason": "This is a foundational textbook in reinforcement learning, providing the basic concepts and terminology used throughout the paper."}, {"fullname_first_author": "Andrea Zanette", "paper_title": "Tighter problem-dependent regret bounds in reinforcement learning without domain knowledge using value function bounds", "publication_date": "2019-00-00", "reason": "This paper explores problem-dependent regret bounds, offering insights into designing RL algorithms that adapt to the intrinsic complexity of the environment, a key aspect of the state-free RL approach."}, {"fullname_first_author": "Max Simchowitz", "paper_title": "Non-asymptotic gap-dependent regret bounds for tabular mdps", "publication_date": "2019-00-00", "reason": "This paper provides gap-dependent regret bounds for tabular MDPs, relevant to the paper's exploration of instance-dependent learning and its relationship to parameter-free RL."}]}