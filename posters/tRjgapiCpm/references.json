{"references": [{"fullname_first_author": "M. Abadi", "paper_title": "Deep learning with differential privacy", "publication_date": "2016-00-00", "reason": "This paper is foundational for the application of differential privacy to deep learning, introducing the DP-SGD algorithm which is the focus of the current paper's analysis."}, {"fullname_first_author": "R. Bassily", "paper_title": "Private empirical risk minimization: Efficient algorithms and tight error bounds", "publication_date": "2014-00-00", "reason": "This paper provides fundamental theoretical results on differentially private empirical risk minimization, which are relevant to understanding the privacy guarantees of DP-SGD."}, {"fullname_first_author": "C. Dwork", "paper_title": "Calibrating noise to sensitivity in private data analysis", "publication_date": "2006-00-00", "reason": "This is a seminal paper in differential privacy, defining the core concepts and providing foundational results that underpin many later developments in the field, including the current work."}, {"fullname_first_author": "M. Nasr", "paper_title": "Adversary instantiation: Lower bounds for differentially private machine learning", "publication_date": "2021-00-00", "reason": "This paper introduces the concept of adversary instantiation and provides lower bounds for differentially private machine learning using this novel framework, which the current paper uses for comparison."}, {"fullname_first_author": "M. Nasr", "paper_title": "Tight Auditing of Differentially Private Machine Learning", "publication_date": "2023-00-00", "reason": "This paper presents state-of-the-art attacks for auditing differentially private machine learning, which are used as baselines and compared against the heuristic proposed in the current work."}]}