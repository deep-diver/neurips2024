{"references": [{"fullname_first_author": "Yasin Abbasi-Yadkori", "paper_title": "Improved algorithms for linear stochastic bandits", "publication_date": "2011-01-01", "reason": "This paper provides the foundational improved algorithms for linear stochastic bandits, which are directly relevant to the core topic of the current paper."}, {"fullname_first_author": "Shipra Agrawal", "paper_title": "Analysis of Thompson sampling for the multi-armed bandit problem", "publication_date": "2012-01-01", "reason": "This paper provides a crucial analysis of Thompson sampling for multi-armed bandits, a key algorithm in the linear bandit space that is compared against in the current paper."}, {"fullname_first_author": "Shipra Agrawal", "paper_title": "Thompson sampling for contextual bandits with linear payoffs", "publication_date": "2013-01-01", "reason": "This paper extends the analysis of Thompson sampling to contextual bandits with linear payoffs, a more general setting also relevant to the current paper's exploration of linear ensemble sampling."}, {"fullname_first_author": "Marc Abeille", "paper_title": "Linear Thompson Sampling Revisited", "publication_date": "2017-04-20", "reason": "This paper revisits and improves upon the analysis of Linear Thompson Sampling, offering refinements that are directly relevant to the current paper's theoretical advancements."}, {"fullname_first_author": "Branislav Kveton", "paper_title": "Perturbed-history exploration in stochastic linear bandits", "publication_date": "2020-01-01", "reason": "This paper introduces the Linear Perturbed-History Exploration (LinPHE) algorithm, a key algorithm closely related to linear ensemble sampling, which is a central focus of comparison and analysis in the current paper."}]}