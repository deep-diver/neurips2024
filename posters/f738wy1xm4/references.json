{"references": [{"fullname_first_author": "S. Arora", "paper_title": "On the optimization of deep networks: Implicit acceleration by overparameterization", "publication_date": "2018-07-10", "reason": "This paper provides foundational theoretical work on the optimization of deep networks, which is directly relevant to the current paper's focus on optimization dynamics."}, {"fullname_first_author": "L. Chizat", "paper_title": "On lazy training in differentiable programming", "publication_date": "2019-12-01", "reason": "This paper studies the phenomenon of lazy training in deep learning, which is closely related to the implicit regularization effects explored in the current paper."}, {"fullname_first_author": "Z. Ji", "paper_title": "Directional convergence and alignment in deep learning", "publication_date": "2020-12-01", "reason": "This paper provides a detailed analysis of convergence and alignment properties of deep learning models, offering insights into the optimization dynamics of deep linear networks."}, {"fullname_first_author": "N. S. Keskar", "paper_title": "On large-batch training for deep learning: Generalization gap and sharp minima", "publication_date": "2017-01-01", "reason": "This paper highlights the importance of flat minima for generalization in deep learning, providing a critical context for the current work's investigation of implicit regularization towards flat minima."}, {"fullname_first_author": "A. Lewkowycz", "paper_title": "The large learning rate phase of deep learning: the catapult mechanism", "publication_date": "2020-03-01", "reason": "This paper investigates the role of sharpness in relation to the learning rate, directly addressing a key question that motivates and informs the research presented in this paper."}]}