[{"figure_path": "WvoKwq12x5/tables/tables_2_1.jpg", "caption": "Table 1: Statistical information on the proposed dataset. PedCorpus is well extensible and adaptable by incorporating general domain data and as seed instructions to generate specialized corpora (i.e., PedCorpus-CPT and PedCorpus-DFPO). \u201cKG\u201d means the Knowledge Graphs.", "description": "This table presents a statistical overview of the PedCorpus dataset, including its size, sources, and task types. It also highlights the extensibility of the dataset through the incorporation of additional data sources.", "section": "3.1 PedCorpus: Multi-task Medical Instruction Dataset"}, {"figure_path": "WvoKwq12x5/tables/tables_5_1.jpg", "caption": "Table 2: Comparison results of different models on three pediatric medical benchmarks. In each benchmark, the best results are marked in bold, and the second-best results are marked underlined.", "description": "This table presents a quantitative comparison of various large language models (LLMs) on three benchmark tasks related to pediatric medicine: MedKQ&A (Medical Knowledge Question and Answering), EviDiag (Evidence-based Diagnosis), and TreRecom (Treatment Recommendation).  The performance of each model is evaluated using multiple metrics (ROUGE, BLEU, GLEU, Distinct-n), providing a comprehensive view of their capabilities in different aspects of language generation and medical knowledge reasoning.  The best and second-best performing models for each benchmark are highlighted for easy comparison.", "section": "4 Experiments"}, {"figure_path": "WvoKwq12x5/tables/tables_8_1.jpg", "caption": "Table 2: Comparison results of different models on three pediatric medical benchmarks. In each benchmark, the best results are marked in bold, and the second-best results are marked underlined.", "description": "This table presents a comparison of various large language models (LLMs) on three distinct pediatric medical benchmarks: MedKQ&A, EviDiag, and TreRecom.  The performance of each model is evaluated using multiple metrics, including ROUGE, BLEU, GLEU, and Distinct-n scores.  The table highlights the best-performing model for each benchmark and metric, offering a quantitative comparison of the models' abilities in pediatric medical applications.", "section": "4 Experiments"}]