[{"figure_path": "rI80PHlnFm/tables/tables_5_1.jpg", "caption": "Table 1: Assessment of various reward-based plasticity rules: R2 scores for weight and individual neural activity trajectories, and the percentage of deviance explained for behavior. Refer to Appendix Table 3 for a comprehensive list of simulated plasticity rules.", "description": "This table presents the performance of different reward-based plasticity rules in terms of R-squared values for weight and neural activity trajectories, and the percentage of deviance explained for behavior. It compares the results obtained using two different models: Multilayer Perceptron (MLP) and Taylor series approximation of the plasticity function. The table demonstrates that different plasticity rules yield varying levels of success in predicting both neural and behavioral data. Appendix Table 3 provides a more extensive list of the plasticity rules that were evaluated.", "section": "4 Inferring plasticity rules from behavior"}, {"figure_path": "rI80PHlnFm/tables/tables_6_1.jpg", "caption": "Table 2: Scalability analysis with respect to trajectory length (with a hidden layer size of 10) and hidden layer size (with a trajectory length of 240), assuming the ground-truth learning rule of \u2206wij = xjr = xj (R \u2013 E[R]) and using the Taylor series parameterization. Results are averaged over three runs with different random seeds.", "description": "This table shows the scalability of the proposed method for inferring plasticity rules from simulated behavioral data.  It demonstrates how the model's performance (measured by R-squared values for weights and activity, and percentage of deviance explained) changes with varying trajectory lengths and hidden layer sizes in the neural network model. The results suggest the model's robustness across different scales and parameters, highlighting its generalizability.", "section": "5 Application: inferring plasticity in the fruit fly"}, {"figure_path": "rI80PHlnFm/tables/tables_15_1.jpg", "caption": "Table 1: Assessment of various reward-based plasticity rules: R2 scores for weight and individual neural activity trajectories, and the percentage of deviance explained for behavior. Refer to Appendix Table 3 for a comprehensive list of simulated plasticity rules.", "description": "This table presents the performance of different reward-based plasticity rules in terms of their ability to explain simulated behavioral data.  The rules were evaluated using both MLP and Taylor series models, with R-squared values provided for weight and neural activity trajectories, alongside the percentage of deviance explained for behavior.  Appendix Table 3 provides additional detail on the plasticity rules.", "section": "4 Inferring plasticity rules from behavior"}, {"figure_path": "rI80PHlnFm/tables/tables_19_1.jpg", "caption": "Table 3: Evaluation of various different reward-based plasticity rules: R2 scores for weight and individual neural activity trajectories, and percentage of deviance explained for behavior.", "description": "This table presents the results of an experiment evaluating the performance of different reward-based plasticity rules using both MLP and Taylor series models. It shows the R-squared values for weights and neural activity trajectories, along with the percentage of deviance explained for behavior.  The purpose is to compare various plasticity functions to determine which model best fits the observed behavior and neural data, identifying the most effective way to incorporate reward information into synaptic plasticity models.", "section": "A.7 Additional plasticity rules"}]