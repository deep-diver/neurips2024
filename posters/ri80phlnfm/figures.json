[{"figure_path": "rI80PHlnFm/figures/figures_1_1.jpg", "caption": "Figure 1: Schematic overview of the proposed method. Animal-derived time-series data (yellow) and a plasticity-regulated in silico model (blue) generate trajectories o(t) and m(t). A loss function quantifies trajectory mismatch to produce a gradient, enabling the inference of the synaptic plasticity rule go.", "description": "This figure illustrates the model-based inference method for synaptic plasticity rules.  Animal-derived time-series data (neural activity or behavioral traces) are compared to the model's output. A loss function quantifies the difference between the model's prediction and the actual data, generating a gradient used to optimize the model's parameters (\u03b8) and infer the underlying synaptic plasticity rule (g\u03b8).  The model uses either a parameterized function (e.g., truncated Taylor series) or a neural network to approximate the plasticity rule.", "section": "2 Method overview"}, {"figure_path": "rI80PHlnFm/figures/figures_2_1.jpg", "caption": "Figure 2: Recovery of Oja's plasticity rule from simulated neural activity. (A) Schematic of the models used to simulate neural activity and infer plasticity. (B) Mean-squared difference between ground-truth and model synaptic weight trajectories over time (horizontal axis) over the course of training epochs (vertical axis). (C) The evolution of \u03b8 during training. Coefficients \u03b8110 and \u03b8021, corresponding to Oja's rule values (1, \u22121), are highlighted in orange. (D) R\u00b2 scores over weights, under varying noise and sparsity conditions in neural data. (E, F) Boxplots of distributions, across 50 seeds, corresponding to the first column (E) and row (F) in (D). (G) The evolution of learning rule coefficients over the course of training showing inaccurate \u03b8 recovery under high noise and sparsity conditions.", "description": "This figure demonstrates the recovery of Oja's plasticity rule from simulated neural activity using the proposed method. Panel A shows a schematic of the models. Panel B shows the mean-squared difference between ground truth and learned synaptic weights over time and training epochs. Panel C shows the evolution of the plasticity rule parameters during training, highlighting the recovery of Oja's rule values. Panel D shows the R-squared scores for different noise and sparsity levels. Panels E and F show boxplots of the R-squared scores for different noise and sparsity levels. Panel G shows the evolution of learning rule coefficients during training under high noise and sparsity conditions, demonstrating the robustness of the method.", "section": "3 Inferring a plasticity rule from neural activity"}, {"figure_path": "rI80PHlnFm/figures/figures_4_1.jpg", "caption": "Figure 3: Recovery of a reward-based plasticity rule from simulated behavior. (A) Schematic of the models used to stimulate behavior and infer plasticity rules. (B) The evolution of the weight of a single synapse, trained with  go and gMLP, compared against weight from a known reward-based update rule. (C) R\u00b2 distributions on the weights across 10 seeds, corresponding to varied weight initializations and stimulus encodings. (D) The evolution of \u03b8 during training, with \u03b8110, corresponding to ground truth rule (value = 1), highlighted in red. (E) Distribution of final inferred \u03b8 values across seeds, showing accurate identification of the relevant term from the ground truth learning rule. (F) The goodness of fit between ground truth behavior and model predictions plotted as the percent deviance explained.", "description": "This figure demonstrates the model's ability to infer reward-based plasticity rules from simulated behavioral data.  Panel A shows the model architecture. Panel B compares the evolution of synaptic weights in the ground truth model versus those learned using Taylor series and MLP approaches. Panel C shows the R-squared values indicating the goodness of fit across different simulations. Panel D and E demonstrate the learning dynamics of parameters in the inferred model, while Panel F displays the overall model fit to the ground truth behavioral data.", "section": "4 Inferring plasticity rules from behavior"}, {"figure_path": "rI80PHlnFm/figures/figures_7_1.jpg", "caption": "Figure 4: Inferring principles of plasticity in the fruit fly. (A) Schematic of the experimental setup used to study two-alternative choice behavior in flies. Left Design of arena showing odor entry ports and location of the reward zones. Right Description of the trial structure, showing two example trials. (B) The behavior of an example fly in the task. Top Schematics indicate the reward baiting probabilities for each odor in the three blocks. Bottom Individual odor choices are denoted by rasters, tall rasters - rewarded choices, short rasters unrewarded choices. Curves show 10-trial averaged choice (red) and reward (black) ratios, and horizontal lines the corresponding averages over the 80-trial blocks. (C) Final inferred \u03b8 value distribution across 18 flies, comparing models with and without a w<sub>ij</sub> term and the method from Rajagopalan et al. (2023). Plasticity rule terms are as follows: bias - (0000), w<sub>ij</sub> - (0001), x<sub>j</sub> - (0100), r - (0010), x<sub>j</sub>r - (0110) (D) Left Goodness of fit between fly behavior and model predictions plotted as the percent deviance explained (n = 18 flies). Right Change in the percent deviance explained calculated by subtracting percent deviance explained of model without a w<sub>ij</sub> (0001) term from that of a model with a w<sub>ij</sub> (0001) term. (E,F) Same as (C,D), except comparing models that do or don't incorporated reward expectation. Since these models include weight dependence, they cannot be fit using Rajagopalan et al. (2023)'s method.", "description": "This figure demonstrates the application of the proposed method to real behavioral data from Drosophila flies performing a two-alternative choice task. It shows the experimental setup, an example fly's behavior, the inferred plasticity rule parameters, and a comparison of model fits with and without a weight-dependent term and reward expectation.  The results highlight the importance of incorporating both weight-dependent decay and reward expectation to accurately model the learning process in flies.", "section": "Application: inferring plasticity in the fruit fly"}, {"figure_path": "rI80PHlnFm/figures/figures_15_1.jpg", "caption": "Figure 5: Effect of L1 regularization on R2 of weights for Taylor plasticity rule", "description": "This figure shows the effect of different L1 regularization strengths on the performance of the Taylor plasticity rule model.  The x-axis represents different L1 regularization values, and the y-axis shows the R-squared values for the model's weight predictions.  The box plot visualization shows the median, quartiles, and potential outliers in the R-squared values for each regularization strength.  It helps to determine the optimal level of L1 regularization for this model, balancing model performance and preventing overfitting.", "section": "A.5.1 L1 regularization"}, {"figure_path": "rI80PHlnFm/figures/figures_16_1.jpg", "caption": "Figure 6: Effect of moving average window (used for calculated expected reward) on the performance of learned plasticity rule", "description": "The box plot shows the effect of different moving average window sizes (5, 10, and 20 trials) on the R-squared values for the weights obtained from both Taylor series and MLP models. The results suggest that using smaller moving average windows generally leads to better performance, likely because shorter historical dependencies reduce the noisiness of the expected reward estimates.  However, the difference in performance across window sizes is relatively small, indicating that the method is robust to this hyperparameter.", "section": "4 Inferring plasticity rules from behavior"}, {"figure_path": "rI80PHlnFm/figures/figures_16_2.jpg", "caption": "Figure 7: Effect of input firing mean (used for odor representation) on the performance of learned plasticity rule", "description": "This figure shows the effect of varying the input firing mean (a parameter used to represent odor in the behavioral experiments) on the performance of the learned plasticity rule. The plot displays boxplots of R-squared values for weights, comparing the performance of two plasticity models (Taylor and MLP) under different input firing means (0.25, 0.5, 0.75, 1.0, and 1.25). It illustrates the robustness of the models across various input ranges.", "section": "A.5 Additional experimental parameters"}, {"figure_path": "rI80PHlnFm/figures/figures_17_1.jpg", "caption": "Figure 8: Percent deviance explained on the training and test data, training on x% of the fly data trajectory and testing on the remaining 100 \u2013 x%.", "description": "This figure shows the results of a validation experiment performed to evaluate the model's ability to generalize to unseen data.  The model was trained using a portion (x%) of each fly's behavioral trajectory data and then tested on the remaining (100-x%) portion.  The x-axis represents the percentage of data used for training, and the y-axis shows the percent deviance explained, a measure of how well the model fits the data.  The plot includes boxplots to show the distribution of results across different flies for both training and testing data.  The red line indicates zero percent deviance explained.  A positive percent deviance explained signifies a good fit to the data, while a negative value indicates a poor fit.", "section": "5 Application: inferring plasticity in the fruit fly"}, {"figure_path": "rI80PHlnFm/figures/figures_18_1.jpg", "caption": "Figure 9: Learned weight decay term in the Taylor series parametrized plasticity rule (Equation 6), from flies with positive (top) and negative (bottom) test set percent deviance explained.", "description": "This figure shows the weight decay coefficient (\u03b8\u2080\u2080\u2080\u2081) learned in the Taylor series parametrized plasticity rule (Equation 6) for flies with positive (top) and negative (bottom) test set percent deviance explained. It illustrates how the model's performance in predicting fly behavior relates to the learned weight decay term across various training set sizes (trajectory cutoffs).  Positive percent deviance explained signifies a good fit between model predictions and observations while negative indicates a poor fit.", "section": "A.6 Validation on held-out data"}]