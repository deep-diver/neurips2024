[{"figure_path": "ZfXRAqbBKX/figures/figures_2_1.jpg", "caption": "Figure 1: The diagram of IRCAN. When an LLM faces a knowledge conflict between the context and its inherent knowledge, IRCAN first calculates the attribution score for each neuron to measure its contribution to processing the context. It then identifies context-aware neurons by taking the intersection of neurons with the highest scores. Subsequently, the identified neurons are reweighted so that IRCAN could guide the model to be more aligned with the contextual knowledge, ensuring greater fidelity to the context.", "description": "This figure illustrates the IRCAN framework.  It shows how IRCAN addresses knowledge conflicts in LLMs by first identifying neurons most sensitive to contextual information (context-aware neurons).  This is done by calculating an attribution score for each neuron based on the impact of the context on the model's prediction.  Then, the weights of these identified neurons are increased, which steers the LLM to prioritize the contextual knowledge when generating output.", "section": "3 Methodology"}, {"figure_path": "ZfXRAqbBKX/figures/figures_6_1.jpg", "caption": "Figure 2: The results of ablation studies to illustrate the accuracy implications of different interventions. ErCAN denotes the variant where context-aware neurons are erased. ERN represents the enhancement of random neurons. ErRN indicates the erasure of random neurons.", "description": "This figure presents the results of ablation studies conducted to evaluate the impact of context-aware neurons on model accuracy.  Three variants are compared against the original IRCAN method: ErCAN (erasing context-aware neurons), ERN (enhancing random neurons), and ErRN (erasing random neurons). The bar charts show the accuracy achieved by each method on three different datasets (MemoTrap, COSE, and E-CARE) across several language models (Gemma-2B, Amber-7B, LLaMA-2-7B, LLaMA-3-8B, LLaMA-2-13B, and their chat/instruct versions). The results demonstrate the importance of context-aware neurons for improving model performance in handling knowledge conflicts.", "section": "4.5 Ablation Studies"}, {"figure_path": "ZfXRAqbBKX/figures/figures_7_1.jpg", "caption": "Figure 3: Model performance with different enhancement strengths \u03b2.", "description": "This figure shows the relationship between the enhancement strength (\u03b2) and the accuracy of the LLaMA-2-7B model on the MemoTrap dataset.  The number of enhanced neurons (h) is held constant at 14.  The graph illustrates that as \u03b2 increases, accuracy initially improves, reaches a peak, and then declines. This indicates an optimal enhancement strength exists, beyond which increasing \u03b2 negatively impacts performance.", "section": "5 Analysis"}, {"figure_path": "ZfXRAqbBKX/figures/figures_7_2.jpg", "caption": "Figure 12: Model performance with different numbers of enhanced neurons h.", "description": "This figure shows the relationship between the number of enhanced neurons and the model's accuracy.  The x-axis represents the number of enhanced neurons (h), and the y-axis represents the accuracy.  The plot shows that accuracy initially increases as the number of enhanced neurons increases, reaching a peak at around h=14. Beyond that point, accuracy starts to decrease slightly.", "section": "4.5 Ablation Studies"}, {"figure_path": "ZfXRAqbBKX/figures/figures_8_1.jpg", "caption": "Figure 5: The distribution of context-aware neurons across layers with various LLMs.", "description": "This figure shows the distribution of context-aware neurons across different layers for four different LLMs: Gemma-2B, LLaMA-2-7B, LLaMA-2-13B, and LLaMA-3-8B.  Each sub-figure represents a specific LLM and displays a histogram showing the percentage of context-aware neurons found in each layer of the model. The x-axis shows the layer number, and the y-axis shows the percentage of context-aware neurons. This visualization helps to understand where in the model these context-aware neurons are most concentrated.", "section": "5.2 Effect of the Number of Context-Aware Neurons"}, {"figure_path": "ZfXRAqbBKX/figures/figures_8_2.jpg", "caption": "Figure 5: The distribution of context-aware neurons across layers with various LLMs.", "description": "This figure shows the distribution of context-aware neurons across different layers of various LLMs (Gemma-2B, LLaMA-2-7B, LLaMA-2-13B, and LLaMA-3-8B).  The x-axis represents the layer number, and the y-axis shows the percentage of context-aware neurons in each layer.  The distribution varies across different models, indicating the diverse ways each model processes contextual information.", "section": "5.2 Effect of the Number of Context-Aware Neurons"}, {"figure_path": "ZfXRAqbBKX/figures/figures_16_1.jpg", "caption": "Figure 1: The diagram of IRCAN. When an LLM faces a knowledge conflict between the context and its inherent knowledge, IRCAN first calculates the attribution score for each neuron to measure its contribution to processing the context. It then identifies context-aware neurons by taking the intersection of neurons with the highest scores. Subsequently, the identified neurons are reweighted so that IRCAN could guide the model to be more aligned with the contextual knowledge, ensuring greater fidelity to the context.", "description": "This figure illustrates the IRCAN framework's three phases: context-aware attribution, neuron identification, and neuron reweighting. It shows how IRCAN addresses knowledge conflicts by identifying and strengthening neurons crucial for processing contextual information, thus aligning LLM outputs with the provided context.", "section": "3 Methodology"}, {"figure_path": "ZfXRAqbBKX/figures/figures_16_2.jpg", "caption": "Figure 1: The diagram of IRCAN. When an LLM faces a knowledge conflict between the context and its inherent knowledge, IRCAN first calculates the attribution score for each neuron to measure its contribution to processing the context. It then identifies context-aware neurons by taking the intersection of neurons with the highest scores. Subsequently, the identified neurons are reweighted so that IRCAN could guide the model to be more aligned with the contextual knowledge, ensuring greater fidelity to the context.", "description": "This figure illustrates the IRCAN framework.  It shows how IRCAN addresses knowledge conflicts in LLMs by first calculating an attribution score for each neuron to determine its contribution to context processing.  Neurons with high scores are identified as \"context-aware neurons.\" Finally, these context-aware neurons are reweighted to prioritize the contextual knowledge over the LLM's inherent knowledge, resulting in more contextually faithful generation.", "section": "3 Methodology"}, {"figure_path": "ZfXRAqbBKX/figures/figures_17_1.jpg", "caption": "Figure 1: The diagram of IRCAN. When an LLM faces a knowledge conflict between the context and its inherent knowledge, IRCAN first calculates the attribution score for each neuron to measure its contribution to processing the context. It then identifies context-aware neurons by taking the intersection of neurons with the highest scores. Subsequently, the identified neurons are reweighted so that IRCAN could guide the model to be more aligned with the contextual knowledge, ensuring greater fidelity to the context.", "description": "This figure illustrates the IRCAN framework.  It shows how IRCAN addresses knowledge conflicts in LLMs by first calculating attribution scores for each neuron to determine its contribution to processing contextual information.  Neurons with high scores (context-aware neurons) are then identified and reweighted, enabling the model to prioritize contextual knowledge during generation and improve its accuracy and faithfulness to the input context.", "section": "3 Methodology"}, {"figure_path": "ZfXRAqbBKX/figures/figures_17_2.jpg", "caption": "Figure 1: The diagram of IRCAN. When an LLM faces a knowledge conflict between the context and its inherent knowledge, IRCAN first calculates the attribution score for each neuron to measure its contribution to processing the context. It then identifies context-aware neurons by taking the intersection of neurons with the highest scores. Subsequently, the identified neurons are reweighted so that IRCAN could guide the model to be more aligned with the contextual knowledge, ensuring greater fidelity to the context.", "description": "This figure illustrates the IRCAN framework's three main steps: calculating the attribution score for each neuron to quantify its contribution to context processing; identifying context-aware neurons by selecting those with the highest scores; and reweighting the identified neurons to increase the model's reliance on contextual knowledge during generation.", "section": "3 Methodology"}, {"figure_path": "ZfXRAqbBKX/figures/figures_18_1.jpg", "caption": "Figure 11: Model performance with different enhancement strengths \u03b2.", "description": "This figure shows the relationship between the model's accuracy and the enhancement strength (\u03b2) when varying the number of enhanced neurons (h). Each subplot represents a different number of enhanced neurons (h), ranging from 10 to 15. The x-axis represents the enhancement strength (\u03b2), and the y-axis represents the accuracy. The figure demonstrates that accuracy generally improves with increasing \u03b2 until reaching a peak after which accuracy starts to decline, indicating that there is an optimal enhancement strength for each number of enhanced neurons.", "section": "4.5 Ablation Studies"}, {"figure_path": "ZfXRAqbBKX/figures/figures_18_2.jpg", "caption": "Figure 1: The diagram of IRCAN. When an LLM faces a knowledge conflict between the context and its inherent knowledge, IRCAN first calculates the attribution score for each neuron to measure its contribution to processing the context. It then identifies context-aware neurons by taking the intersection of neurons with the highest scores. Subsequently, the identified neurons are reweighted so that IRCAN could guide the model to be more aligned with the contextual knowledge, ensuring greater fidelity to the context.", "description": "This figure illustrates the IRCAN framework.  It shows how IRCAN addresses knowledge conflicts in LLMs by first calculating an attribution score for each neuron to determine its contribution to processing contextual information. Neurons with high scores (context-aware neurons) are then identified and reweighted to prioritize contextual knowledge during generation, thereby improving the model's accuracy and alignment with the provided context.", "section": "3 Methodology"}, {"figure_path": "ZfXRAqbBKX/figures/figures_19_1.jpg", "caption": "Figure 13: The intersection of neurons identified with different prompts was used for Gemma-2B-it and LlaMA-3-8B-Instruct.", "description": "This bar chart displays the percentage overlap of context-aware neurons identified by IRCAN using different prompts for two LLMs: Gemma-2B-it and LLaMA-3-8B-Instruct.  It demonstrates the robustness of IRCAN in identifying consistent context-aware neurons across various prompts, highlighting its reliability in identifying critical neurons regardless of the specific input.", "section": "5.2 Effect of the Number of Context-Aware Neurons"}]