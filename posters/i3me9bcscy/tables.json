[{"figure_path": "i3me9bCSCy/tables/tables_7_1.jpg", "caption": "Table 1: Predicting Frequencies of Implicit Neural Representations (INRs).", "description": "This table presents the results of predicting the frequencies of Implicit Neural Representations (INRs).  It compares the performance of several models (MLP, Deepsets, STATNN, NFNNP, NFNHNP, NFT, DWSNet, and the proposed SNE model) on this task by showing the number of parameters (#Params) and the Mean Squared Error (MSE) achieved by each model.  The MSE is a measure of how well the model predicts the frequency, with lower values indicating better performance. The table highlights that SNE significantly outperforms other baselines.", "section": "4.1 Encoding Implicit Neural Representations"}, {"figure_path": "i3me9bCSCy/tables/tables_7_2.jpg", "caption": "Table 2: Cross-Architecture Performance Prediction.", "description": "This table presents the results of the cross-architecture performance prediction task.  It demonstrates the generalization performance of the encoder trained on three homogeneous model zoos of the same architecture when tested on three different architectures unseen during training.  The rows represent the source architecture and target architecture used for training and testing, respectively.  The columns show the performance of different neural network encoding methods (DeepSets, NeuralGraph, and SNE).  The results show how well the performance predictors transfer to unseen architectures.  The model zoos are trained on MNIST, CIFAR10, and SVHN datasets.", "section": "4.2 Cross-Architecture Performance Prediction"}, {"figure_path": "i3me9bCSCy/tables/tables_8_1.jpg", "caption": "Table 3: Cross-Architecture Performance Prediction on Sch\u00fcrholt et al. [2022]'s model zoo.", "description": "This table presents the results of the cross-architecture performance prediction task on the model zoo of Sch\u00fcrholt et al. [2022]. It demonstrates how well the SNE model generalizes to unseen architectures.  The table compares the performance of SNE and HyperRep on three different cross-architecture transfer tasks, where models are trained on SVHN and tested on SVHN, MNIST, and CIFAR10, respectively. The results show that SNE significantly outperforms HyperRep in all three scenarios, indicating that SNE is more robust in handling unseen architectures compared to HyperRep.", "section": "4.2 Cross-Architecture Performance Prediction"}, {"figure_path": "i3me9bCSCy/tables/tables_8_2.jpg", "caption": "Table 4: Cross-Architecture Performance on Transformers. We report Kendall's \u03c4.", "description": "This table presents the results of cross-architecture performance prediction on transformers.  The experiment evaluates how well performance predictors trained on a specific architecture (Arch1) transfer to an unseen architecture (Transformer).  Three datasets (MNIST, CIFAR10, and SVHN) were used, and each dataset's model zoo was used to evaluate the transfer performance from its associated Arch1 models to a transformer architecture trained on MNIST.  The table shows the Kendall's \u03c4 correlation values for each dataset and the two compared methods (DeepSets and SNE).  SNE consistently outperforms DeepSets, demonstrating its better ability to generalize across unseen architectures.", "section": "4.2 Cross-Architecture Performance Prediction"}, {"figure_path": "i3me9bCSCy/tables/tables_8_3.jpg", "caption": "Table 5: Cross-Dataset Prediction. We report Kendall's \u03c4.", "description": "This table presents the results of the cross-dataset performance prediction task. Kendall's \u03c4, a rank correlation measure, is used to evaluate the performance of different models. Each row represents a different cross-dataset evaluation scenario (e.g., MNIST to FashionMNIST). The table shows how well models trained on one dataset generalize to other unseen datasets. The best performing model for each row is highlighted in red, and the second best in blue.", "section": "4.3 Cross-Dataset Performance Prediction"}, {"figure_path": "i3me9bCSCy/tables/tables_14_1.jpg", "caption": "Table 6: Ablation on SNE Components", "description": "This ablation study analyzes the impact of different components of the Set-based Neural Network Encoder (SNE) on its performance.  The results show the mean squared error (MSE) achieved by models missing various elements of the SNE, including the layer level encoder, layer type encoder, set functions, positional and hierarchical encoding, and the invariance regularization.  The table highlights the contribution of each component to the overall performance, demonstrating the effectiveness of SNE's design.", "section": "E Ablation"}, {"figure_path": "i3me9bCSCy/tables/tables_15_1.jpg", "caption": "Table 7: Effect of Chunksize.", "description": "This table presents an ablation study on the effect of different chunk sizes on the model's performance.  The chunk size is a hyperparameter that determines how the weights of each layer in the neural network are divided into smaller chunks for processing. The results show that the model's performance (measured by MSE) is relatively stable across a range of chunk sizes, suggesting that the choice of chunk size may not be highly critical.", "section": "E Ablation"}, {"figure_path": "i3me9bCSCy/tables/tables_16_1.jpg", "caption": "Table 8: Cross-Dataset Neural Network Performance Prediction. We benchmark how well each method transfers across multiple datasets. In the first column, A \u2192 B implies that a model trained on a homogeneous model zoo of dataset A is evaluated on a homogeneous model zoo of dataset B. In the last row, we report the averaged performance of all methods across the cross-dataset task. For each row, the best model is shown in red and the second best in blue. Models are evaluated in terms of Kendall's T, a rank correlation measure.", "description": "This table presents the results of a cross-dataset experiment, evaluating the performance of various methods in predicting neural network properties.  Each method was trained on a model zoo from a single dataset (e.g., MNIST) and then tested on model zoos from other datasets (MNIST, FashionMNIST, CIFAR10, SVHN). The table shows the Kendall's Tau correlation coefficient, measuring the rank correlation between predicted and actual properties. The best and second-best performing methods for each dataset combination are highlighted.", "section": "F.1 Cross-Dataset Evaluation"}, {"figure_path": "i3me9bCSCy/tables/tables_17_1.jpg", "caption": "Table 9: Cross-Architecture NN Performance Prediction. We show how SNE transfers across architectures and report Kendall\u2019s \u03c4.", "description": "This table presents the results of the cross-architecture experiment.  The experiment evaluates how well a neural network property predictor trained on a specific architecture generalizes to unseen architectures.  Each row shows the Kendall's \u03c4 (a rank correlation measure) for models trained on one architecture (Arch2) and tested on another (Arch1).  The datasets used are MNIST, CIFAR10, and SVHN.  The results demonstrate the ability of SNE to transfer across architectures.", "section": "F.2 Cross-Architecture Evaluation"}, {"figure_path": "i3me9bCSCy/tables/tables_17_2.jpg", "caption": "Table 10: Arch\u2081 for MNIST, FashionMNIST, CIFAR10 and SVHN.", "description": "This table details the architecture used for generating the model zoos of Arch\u2081.  Arch\u2081 is a specific architecture used in the cross-dataset and cross-architecture experiments described in the paper. The architecture consists of three convolutional layers, an adaptive average pooling layer, a flatten layer, and two linear layers, resulting in a 10-dimensional output.  The input image sizes and channel specifications vary based on the dataset (MNIST, FashionMNIST, CIFAR10, and SVHN).", "section": "G Architectures for Generating model zoos"}, {"figure_path": "i3me9bCSCy/tables/tables_18_1.jpg", "caption": "Table 11: Arch2 for MNIST.", "description": "This table details the architecture of model zoos for the cross-architecture task, specifically for the MNIST dataset.  It shows the layer-by-layer specifications including input size, number of channels, kernel size, activation function (ReLU), and max pooling. The final layers are linear layers leading to an output size of 10.", "section": "G Architectures for Generating model zoos"}, {"figure_path": "i3me9bCSCy/tables/tables_18_2.jpg", "caption": "Table 12: Arch2 for CIFAR10 and SVHN.", "description": "This table presents the architecture used for generating the model zoos of Arch2 for CIFAR10 and SVHN datasets in the cross-architecture experiments. It details the layers, their output sizes, and the operations involved for each layer in the architecture. The architecture consists of multiple convolutional layers, max-pooling layers, a flattening layer, and finally two linear layers to produce the output.", "section": "G Architectures for Generating model zoos"}, {"figure_path": "i3me9bCSCy/tables/tables_18_3.jpg", "caption": "Table 13: Dataset splits for model zoos of Arch1.", "description": "This table shows the number of neural networks in the training, validation, and testing sets for each of the four datasets used to create the model zoos of Arch1. The datasets include MNIST, FashionMNIST, CIFAR10, and SVHN.  Arch1 refers to a specific neural network architecture used in the paper's experiments.", "section": "H Dataset Details"}, {"figure_path": "i3me9bCSCy/tables/tables_18_4.jpg", "caption": "Table 6: Ablation on SNE Components", "description": "This table presents the ablation study of different components of the proposed Set-based Neural Network Encoder (SNE). It shows the impact of removing each component on the model's performance in terms of Mean Squared Error (MSE).  The components include the Layer Level Encoder, the Layer Type Encoder, Set Functions, Positional and Hierarchical Encoding, and the Invariance Regularization.", "section": "E Ablation"}, {"figure_path": "i3me9bCSCy/tables/tables_19_1.jpg", "caption": "Table 16: INR Architecture. Activations are Sinusoidal", "description": "This table shows the architecture of the Implicit Neural Representations (INRs) used in the experiments.  It specifies the number of layers, input and output sizes, and activation function (sinusoidal) used for each layer in the INR model.", "section": "J Implementation Details"}, {"figure_path": "i3me9bCSCy/tables/tables_19_2.jpg", "caption": "Table 16: INR Architecture. Activations are Sinusoidal", "description": "This table shows the architecture of the Implicit Neural Representations (INRs) used in the experiments.  The INR architecture consists of three linear layers. The first two layers have an output size of 32 and use a sinusoidal activation function. The final layer outputs a single value and uses no activation function.", "section": "J Implementation Details"}]