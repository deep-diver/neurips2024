[{"figure_path": "NDs9Ejz4Pe/tables/tables_2_1.jpg", "caption": "Table 1: Zero-shot class-agnostic object detection performance of Grounding DINO [33] on MS-COCO [32], with hand-crafted prompts from various sources. We report average recall (AR) and precision (AP) limited to a maximum of 100 detections per image. AAR quantifies the percentage decrease in AR comparing \u201cquery-merging\u201d to \u201cprediction-merging\u201d for forming multi-word queries.", "description": "This table presents the zero-shot class-agnostic object detection results on the MS-COCO dataset using Grounding DINO.  Three different prompt sources (ChatGPT, WordNet, and a combination of both) are used, and two merging strategies (query-merging and prediction-merging) are compared. The table reports average recall (AR), average recall at different object sizes (AR@S, AR@M, AR@L), average precision (AP), and the percentage decrease in AR when using query-merging instead of prediction-merging (AAR).  This allows for analysis of how different query approaches and merging methods affect the performance of class-agnostic object detection.", "section": "2 Pilot Study"}, {"figure_path": "NDs9Ejz4Pe/tables/tables_6_1.jpg", "caption": "Table 2: Class-agnostic object detection on the MS-COCO dataset. [] indicate the prompt word for Grounding DINO. The prompting methods indicated with '*' are adapted to the OD task.", "description": "This table presents the performance comparison of various class-agnostic object detection methods on the MS-COCO dataset.  It includes both traditional bottom-up methods and more recent self-training and prompting-based approaches using the Grounding DINO model. The table shows the Average Recall (AR) at different detection thresholds (AR@1, AR@10, AR@100), average recall by object size (AR@S, AR@M, AR@L), and Average Precision (AP).  The methods are categorized by their approach (e.g., self-training, zero-shot).  The table highlights the improvement achieved by the proposed DiPEx method.", "section": "4.2 Main Results on Class-agnostic OD and OOD-OD"}, {"figure_path": "NDs9Ejz4Pe/tables/tables_6_2.jpg", "caption": "Table 2: Class-agnostic object detection on the MS-COCO dataset. [] indicate the prompt word for Grounding DINO. The prompting methods indicated with '*' are adapted to the OD task.", "description": "This table presents the results of class-agnostic object detection experiments on the MS-COCO dataset.  It compares various methods, including several self-training approaches and zero-shot methods using Grounding DINO with different prompts.  The metrics used to evaluate performance are Average Recall (AR) at different detection thresholds (AR1, AR10, AR100) along with average precision (AP) and average recall based on object size (AR@S, AR@M, AR@L). The table highlights the superior performance of DiPEx compared to other methods.", "section": "4.2 Main Results on Class-agnostic OD and OOD-OD"}, {"figure_path": "NDs9Ejz4Pe/tables/tables_7_1.jpg", "caption": "Table 3: Class-agnostic object detection on the LVIS dataset. \u2020 indicate the model is fine-tuned on the LVIS training set by self-training without box annotations.", "description": "This table presents the results of class-agnostic object detection experiments conducted on the LVIS dataset.  It compares the performance of various methods, including several baselines and the proposed DiPEx approach.  The metrics reported include average recall (AR) at different detection thresholds (AR1, AR10, AR200), average recall for small, medium, and large objects (AR@S, AR@M, AR@L), and average precision (AP) and AP for small, medium, and large objects (AP@S, AP@M, AP@L).  The \u2020 symbol indicates that the model was fine-tuned on the LVIS training set using self-training without ground truth bounding box annotations.", "section": "4.2 Main Results on Class-agnostic OD and OOD-OD"}, {"figure_path": "NDs9Ejz4Pe/tables/tables_7_2.jpg", "caption": "Table 4: The downstream out-of-distribution object detection (OOD-OD) on the MS-COCO dataset, where the ground truth boxes contain both known and unknown classes.", "description": "This table presents the results of out-of-distribution object detection experiments on the MS-COCO dataset.  It compares different methods' performance on identifying both known and unknown classes within the ground truth bounding boxes.  The metrics used include Average Precision (AP), AP at IoU=0.5 (AP50), Average Recall at 100 detections (AR100), and Average Recall at different object scales (AR@S, AR@M, AR@L). The results are broken down to show performance on known classes and unknown classes separately, providing a comprehensive evaluation of the methods' ability to generalize to unseen objects.", "section": "4.2 Main Results on Class-agnostic OD and OOD-OD"}, {"figure_path": "NDs9Ejz4Pe/tables/tables_16_1.jpg", "caption": "Table 2: Class-agnostic object detection on the MS-COCO dataset. [ ] indicate the prompt word for Grounding DINO. The prompting methods indicated with \u2018*\u2019 are adapted to the OD task.", "description": "This table presents the performance comparison of various methods for class-agnostic object detection on the MS-COCO dataset.  It shows the average recall (AR) at different detection thresholds (AR@1, AR@10, AR@100) and average precision (AP) for different object sizes (small, medium, large).  Methods include several baselines (e.g., Selective Search, UP-DETR, etc.) and different prompting methods using Grounding DINO, with and without adaptation for object detection tasks. DiPEx achieves the best performance.", "section": "4.2 Main Results on Class-agnostic OD and OOD-OD"}]