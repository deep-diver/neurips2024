[{"figure_path": "2oZea6pKhl/figures/figures_4_1.jpg", "caption": "Figure 1: Overall pipeline of RadarOcc. The data volume reduction pre-processes the 4DRT into a lightweight sparse RT via Doppler bins encoding and sidelobe-aware spatial sparifying. We apply spherical-based feature encoding on the sparse RT and aggregate the spherical features using Cartesian voxel queries. The 3D occupancy volume is finally output via 3D occupancy decoding.", "description": "This figure shows the overall pipeline of the proposed RadarOcc model for 3D occupancy prediction using 4D imaging radar data.  The pipeline consists of four main stages: \n\n1. **Data Volume Reduction:** This stage reduces the size of the massive 4D radar tensor (4DRT) by encoding Doppler bins (frequency information) into descriptors and applying a sidelobe-aware spatial sparsification technique. This removes redundant and noisy information while preserving key spatial features.\n2. **Spherical-based Feature Encoding:** The sparsified data is then processed using a spherical-based feature encoding method. This avoids the loss of information often associated with converting spherical radar coordinates to Cartesian coordinates. This process employs sequential sparse convolutions and deformable self-attention to extract relevant features.\n3. **Spherical-to-Cartesian Feature Aggregation:** This stage seamlessly integrates the spherical features with Cartesian voxel queries through deformable cross-attention, enabling the model to predict occupancy in the desired 3D Cartesian grid.\n4. **3D Occupancy Decoding:** Finally, multi-scale 3D convolutions and upsampling are used to decode the aggregated features and generate the final 3D occupancy prediction.", "section": "4.2 Overview"}, {"figure_path": "2oZea6pKhl/figures/figures_5_1.jpg", "caption": "Figure 1: Overall pipeline of RadarOcc. The data volume reduction pre-processes the 4DRT into a lightweight sparse RT via Doppler bins encoding and sidelobe-aware spatial sparifying. We apply spherical-based feature encoding on the sparse RT and aggregate the spherical features using Cartesian voxel queries. The 3D occupancy volume is finally output via 3D occupancy decoding.", "description": "This figure shows the overall pipeline of the RadarOcc model for 3D occupancy prediction using 4D imaging radar data.  It illustrates the four main components: data volume reduction (using Doppler bins encoding and sidelobe-aware spatial sparsification), spherical-based feature encoding, spherical-to-Cartesian feature aggregation, and 3D occupancy decoding.  The process starts with a large 4DRT, reduces it to a smaller sparse representation, encodes features in spherical coordinates, aggregates them into Cartesian coordinates, and finally outputs the 3D occupancy grid.", "section": "4 Method"}, {"figure_path": "2oZea6pKhl/figures/figures_9_1.jpg", "caption": "Figure 1: Overall pipeline of RadarOcc. The data volume reduction pre-processes the 4DRT into a lightweight sparse RT via Doppler bins encoding and sidelobe-aware spatial sparifying. We apply spherical-based feature encoding on the sparse RT and aggregate the spherical features using Cartesian voxel queries. The 3D occupancy volume is finally output via 3D occupancy decoding.", "description": "This figure shows the overall pipeline of the proposed RadarOcc method. It starts with data volume reduction of the 4D radar tensor (4DRT) using Doppler bins encoding and sidelobe-aware spatial sparsifying.  Then, spherical-based feature encoding is performed on the sparse representation, followed by spherical-to-Cartesian feature aggregation using Cartesian voxel queries. Finally, 3D occupancy decoding produces the output 3D occupancy volume.", "section": "4.2 Overview"}, {"figure_path": "2oZea6pKhl/figures/figures_20_1.jpg", "caption": "Figure 3: Qualitative comparison between RadarOcc, LiDAR-based L-baseline [3] and camera-based SurroundOcc [25] in adverse weathers. Ground truth bounding boxes are shown in RGB images.", "description": "This figure compares the qualitative results of RadarOcc, a LiDAR-based method (L-baseline), and a camera-based method (SurroundOcc) under adverse weather conditions.  The top row shows the input data from each modality (4D Radar, LiDAR, and RGB camera). The bottom row shows the corresponding predictions of 3D occupancy, highlighting the superiority of RadarOcc in adverse weather.  The RGB images include ground truth bounding boxes for reference. ", "section": "5 Experiment"}, {"figure_path": "2oZea6pKhl/figures/figures_20_2.jpg", "caption": "Figure 1: Overall pipeline of RadarOcc. The data volume reduction pre-processes the 4DRT into a lightweight sparse RT via Doppler bins encoding and sidelobe-aware spatial sparifying. We apply spherical-based feature encoding on the sparse RT and aggregate the spherical features using Cartesian voxel queries. The 3D occupancy volume is finally output via 3D occupancy decoding.", "description": "This figure illustrates the complete pipeline of the RadarOcc model for 3D occupancy prediction using 4D imaging radar data. It begins with data volume reduction techniques to handle the large size of 4D radar tensors (4DRTs), followed by spherical-based feature encoding to process the spatial features directly on the spherical RTs without transforming them to Cartesian coordinates. Finally, a Cartesian occupancy prediction is generated using voxel queries.", "section": "4 Method"}]