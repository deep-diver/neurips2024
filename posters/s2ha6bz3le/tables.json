[{"figure_path": "s2hA6Bz3LE/tables/tables_8_1.jpg", "caption": "Table 1: OOD detection results with inlier Dirty-MNIST and outlier Fashion MNIST, over 5 runs. All models were trained on a LeNet, with HE-CKA and CKApw utilizing a cosine similarity feature kernel. One exception to predictive entropy (PE) report is DDU, which uses feature space density, indicated by a star, to calculate AUROC Mukhoti et al. (2023). More training details can be found in Appendix C.", "description": "This table presents the results of out-of-distribution (OOD) detection experiments using different methods on the Dirty-MNIST and Fashion-MNIST datasets.  It compares the performance of various methods, including those using the proposed HE-CKA and CKApw approaches, in terms of negative log-likelihood (NLL), accuracy, expected calibration error (ECE), and AUROC for FashionMNIST (as an OOD dataset).  The table highlights the superior performance of methods incorporating HE-CKA, particularly when combined with out-of-distribution (OOD) data and an entropy term.", "section": "5.2 OOD Detection on Real Datasets"}, {"figure_path": "s2hA6Bz3LE/tables/tables_8_2.jpg", "caption": "Table 2: OOD results on CIFAR10 vs SVHN. Methods used 10 particles of a modified ResNet32 were trained as described in D' Angelo & Fortuin (2021). Methods with (*) report values taken from D' Angelo & Fortuin (2021). One exception to predictive entropy (PE) report is DDU* which uses feature space density to calculate AUROC (Mukhoti et al., 2023).", "description": "This table presents the out-of-distribution (OOD) detection results on CIFAR-10 versus SVHN datasets.  Different methods are compared, including variations of Stein Variational Gradient Descent (SVGD) with different kernels (RBF, CKApw, HE-CKA), Deep Deterministic Uncertainty (DDU), and ensembles.  The table shows negative log-likelihood (NLL), accuracy, expected calibration error (ECE), area under the receiver operating characteristic curve (AUROC) for SVHN (as the OOD dataset), predictive entropy (PE), and mutual information (MI).  The results highlight the performance of the proposed HE-CKA method in improving OOD detection capabilities compared to other approaches.", "section": "5.2 OOD Detection on Real Datasets"}, {"figure_path": "s2hA6Bz3LE/tables/tables_8_3.jpg", "caption": "Table 3: OOD detection results with inlier Dirty-MNIST and outlier Fashion MNIST, over 5 runs. All models were trained on a LeNet, with HE-CKA and CKApw utilizing a cosine similarity feature kernel. One exception to predictive entropy (PE) report is DDU, which uses feature space density, indicated by a star, to calculate AUROC Mukhoti et al. (2023). More training details can be found in Appendix C.", "description": "This table presents the results of out-of-distribution (OOD) detection experiments using the Dirty-MNIST dataset as inliers and Fashion-MNIST as outliers.  Multiple models, including a deep ensemble, SVGD with various kernel choices (RBF, CKApw, HE-CKA), and a hypernetwork, were evaluated.  Performance is measured by negative log-likelihood (NLL), accuracy, expected calibration error (ECE), AUROC on Fashion-MNIST, predictive entropy (PE), and mutual information (MI).  The HE-CKA method shows better performance, especially when combined with out-of-distribution (OOD) examples, leading to near-perfect OOD detection.", "section": "5.2 OOD Detection on Real Datasets"}, {"figure_path": "s2hA6Bz3LE/tables/tables_9_1.jpg", "caption": "Table 4: Performance of a five member ResNet18 ensemble trained on TinyImageNet. All models utilized a pretrained deep ensemble with no repulsive term, then fine tuned for 30 epochs for each method (including deep ensemble). Methods utilizing CKApw and HE-CKA utilized a linear feature kernel.", "description": "This table presents the results of out-of-distribution (OOD) detection experiments using a five-member ResNet18 ensemble trained on the TinyImageNet dataset.  The models were initially pretrained without a repulsive term, then fine-tuned for 30 epochs using various methods.  These include a standard ensemble,  SVGD with RBF, CKApw, and HE-CKA kernels.  The table displays negative log-likelihood (NLL), in-distribution (ID) accuracy, expected calibration error (ECE), and area under the receiver operating characteristic curve (AUROC) for predictive entropy (PE) on SVHN, CIFAR-10/100, and Textures (DTD) datasets. The HE-CKA and CKApw methods used a linear feature kernel.", "section": "5 Experiments"}, {"figure_path": "s2hA6Bz3LE/tables/tables_16_1.jpg", "caption": "Table 5: OOD results on CIFAR-100 vs SVHN. Methods used a ResNet18 ensemble of size 5.", "description": "This table presents the out-of-distribution (OOD) detection results on the CIFAR-100 dataset using SVHN as the outlier dataset.  Three different model variations were tested: a standard ensemble, an ensemble with HE-CKA regularization, and an ensemble with HE-CKA regularization and synthetic OOD data.  The results show negative log-likelihood (NLL), accuracy on in-distribution data, expected calibration error (ECE), and area under the receiver operating characteristic curve (AUROC) for SVHN as an outlier. The metrics evaluate the performance of each model variation in distinguishing between in-distribution and out-of-distribution samples.", "section": "5.2 OOD Detection on Real Datasets"}, {"figure_path": "s2hA6Bz3LE/tables/tables_17_1.jpg", "caption": "Table 6: Ablation on number of training particles for ResNet18 + trained with HE-CKA TinyImageNet.", "description": "This table presents the results of an ablation study on the number of particles used in training a ResNet18 model with the HE-CKA method on the TinyImageNet dataset.  The table shows that increasing the number of particles generally improves performance, as measured by negative log-likelihood (NLL), ID accuracy, expected calibration error (ECE), and AUROC of the predictive entropy (PE) for outlier detection on SVHN, CIFAR-10/100, and Textures (DTD) datasets.  The best performance is observed when using 5 particles. ", "section": "5.2 OOD Detection on Real Datasets"}, {"figure_path": "s2hA6Bz3LE/tables/tables_18_1.jpg", "caption": "Table 7: Average pairwise unbiased CKA across all layers of an ensemble of 5 ResNet18 trained on CIFAR-10.", "description": "This table shows the average pairwise unbiased Centered Kernel Alignment (CKA) values across all layers for different methods used to train an ensemble of 5 ResNet18 models on the CIFAR-10 dataset.  The methods compared include a standard deep ensemble, SVGD with RBF kernel, SVGD with CKA regularization, SVGD with hyperspherical energy (HE) regularization, and HE alone. Lower CKA values indicate greater diversity among the models in the ensemble.", "section": "G Memory Footprint and Time Complexity"}, {"figure_path": "s2hA6Bz3LE/tables/tables_22_1.jpg", "caption": "Table 1: OOD detection results with inlier Dirty-MNIST and outlier Fashion MNIST, over 5 runs. All models were trained on a LeNet, with HE-CKA and CKApw utilizing a cosine similarity feature kernel. One exception to predictive entropy (PE) report is DDU, which uses feature space density, indicated by a star, to calculate AUROC Mukhoti et al. (2023). More training details can be found in Appendix C.", "description": "This table presents the out-of-distribution (OOD) detection performance of various methods on the Dirty-MNIST and Fashion-MNIST datasets.  It compares the Negative Log-Likelihood (NLL), Accuracy, Expected Calibration Error (ECE), Area Under the Receiver Operating Characteristic curve (AUROC) for Fashion-MNIST, predictive entropy (PE), and mutual information (MI).  The results are averaged over 5 runs and show that the proposed HE-CKA method outperforms other baselines, especially when combined with out-of-distribution (OOD) data and entropy terms.", "section": "5.2 OOD Detection on Real Datasets"}]