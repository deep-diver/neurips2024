{"references": [{"fullname_first_author": "Ben Mildenhall", "paper_title": "Nerf: Representing scenes as neural radiance fields for view synthesis", "publication_date": "2021-00-00", "reason": "This paper introduces Neural Radiance Fields (NeRF), a foundational work in neural rendering that heavily influences the 3D Gaussian Splatting method used in OpenGaussian."}, {"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment Anything", "publication_date": "2023-00-00", "reason": "This paper introduces the Segment Anything Model (SAM), a powerful zero-shot image segmentation model used in OpenGaussian for generating instance masks."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "This paper introduces CLIP, a model that connects image and text embeddings, which is leveraged by OpenGaussian for open-vocabulary understanding."}, {"fullname_first_author": "Bernhard Kerbl", "paper_title": "3D Gaussian splatting for real-time radiance field rendering", "publication_date": "2023-00-00", "reason": "This paper introduces 3D Gaussian Splatting (3DGS), a core component of the proposed OpenGaussian method for efficient 3D scene representation and rendering."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper introduces DINO, a self-supervised vision transformer model that provides an alternative to CLIP for learning visual features and is mentioned in the related work section as having been used in related approaches."}]}