[{"figure_path": "nge5deRsEH/tables/tables_3_1.jpg", "caption": "Table 1: Experiment Results on TinyStories: The results show that an auto-regressive tree can achieve better performance as the GPT-Neo architecture and exhibit competitive performance compared to both GPT-4 and TinyStories-33M.", "description": "This table presents a comparison of the performance of different language models, including Auto-Regressive Decision Trees (ARDTs), on the TinyStories dataset.  The models are evaluated based on four metrics: grammar, creativity, consistency, and plot. The table shows parameter counts for each model and highlights the ARDT's surprisingly strong performance relative to its size.", "section": "4.2 The Ability to Generate Coherent Stories"}, {"figure_path": "nge5deRsEH/tables/tables_4_1.jpg", "caption": "Table 1: Experiment Results on TinyStories: The results show that an auto-regressive tree can achieve better performance as the GPT-Neo architecture and exhibit competitive performance compared to both GPT-4 and TinyStories-33M.", "description": "This table compares the performance of different language models, including an autoregressive decision tree (ARDT), on the TinyStories dataset.  The models are evaluated on four metrics: grammar, creativity, consistency, and plot. The table shows that the ARDT achieves performance comparable to more complex models such as GPT-4 and TinyStories-33M, despite having significantly fewer parameters.", "section": "4.2 The Ability to Generate Coherent Stories"}, {"figure_path": "nge5deRsEH/tables/tables_8_1.jpg", "caption": "Table 1: Experiment Results on TinyStories: The results show that an auto-regressive tree can achieve better performance as the GPT-Neo architecture and exhibit competitive performance compared to both GPT-4 and TinyStories-33M.", "description": "This table presents the quantitative results of story generation experiments using various models, including the proposed ARDTs model and several baselines such as TinyStories-1M, TinyStories-33M, and GPT-4.  The models are evaluated using four metrics: Grammar, Creativity, Consistency, and Plot. Higher scores indicate better performance. The ARDTs model, despite having significantly fewer parameters than the GPT-4 and even the larger TinyStories-33M, achieves competitive performance, highlighting its efficiency.", "section": "4.2 The Ability to Generate Coherent Stories"}, {"figure_path": "nge5deRsEH/tables/tables_8_2.jpg", "caption": "Table 2: Experimental Results on BIG-Bench-Hard. Lin: Linear Embedding; GPT: GPT-2 Embedding. The results demonstrate that ARDTs possess good reasoning capabilities.", "description": "This table presents the performance of ARDTs (Auto-Regressive Decision Trees) on the BIG-Bench Hard dataset, a benchmark for challenging logical reasoning tasks.  It compares the ARDT's performance using both linear embeddings and GPT-2 embeddings against several strong baselines: Human raters, InstructGPT, Codex, and PaLM 540B.  The results show how ARDTs, despite their simpler architecture, achieve competitive performance on various tasks, indicating their potential for handling complex reasoning problems.", "section": "4.3 Evaluating ARDTs in Language Reasoning Tasks"}, {"figure_path": "nge5deRsEH/tables/tables_14_1.jpg", "caption": "Table 3: Basic Information about the Tinystories Dataset.", "description": "This table presents a summary of the TinyStories dataset, providing key statistics for both the training and validation sets.  Specifically, it shows the number of stories, the total number of tokens, the range of word counts per story, and the size of the vocabulary (unique words) in each set.  These statistics are useful for understanding the scale and characteristics of the dataset used to train and evaluate the autoregressive decision tree (ARDT) language model described in the paper.", "section": "4.1 Setting"}, {"figure_path": "nge5deRsEH/tables/tables_14_2.jpg", "caption": "Table 1: Experiment Results on TinyStories: The results show that an auto-regressive tree can achieve better performance as the GPT-Neo architecture and exhibit competitive performance compared to both GPT-4 and TinyStories-33M.", "description": "This table compares the performance of different language models on the TinyStories dataset, focusing on metrics such as grammar, creativity, consistency, and plot.  The models compared include two small Transformers (TinyStories-1M and TinyStories-33M), GPT-4, and the authors' proposed Auto-Regressive Decision Trees (ARDTs). The table highlights that the ARDTs, despite having fewer parameters than the small transformer models, achieve comparable or even better performance in several aspects.", "section": "4.2 The Ability to Generate Coherent Stories"}, {"figure_path": "nge5deRsEH/tables/tables_15_1.jpg", "caption": "Table 1: Experiment Results on TinyStories: The results show that an auto-regressive tree can achieve better performance as the GPT-Neo architecture and exhibit competitive performance compared to both GPT-4 and TinyStories-33M.", "description": "This table presents a comparison of the performance of different language models, including an Auto-Regressive Decision Tree (ARDT) model, on the TinyStories dataset.  The models are evaluated on four metrics: grammar, creativity, consistency, and plot.  The ARDT model achieves comparable performance to larger, more complex models like GPT-4 and TinyStories-33M, demonstrating the potential of ARDTs for language generation tasks.", "section": "4.2 The Ability to Generate Coherent Stories"}, {"figure_path": "nge5deRsEH/tables/tables_15_2.jpg", "caption": "Table 1: Experiment Results on TinyStories: The results show that an auto-regressive tree can achieve better performance as the GPT-Neo architecture and exhibit competitive performance compared to both GPT-4 and TinyStories-33M.", "description": "This table presents a comparison of the performance of various language models, including the proposed Auto-Regressive Decision Trees (ARDTs), on the TinyStories dataset.  The models are evaluated on four metrics: grammar, creativity, consistency, and plot.  The table shows parameter counts for each model to help assess the efficiency of the ARDT approach. Note that the ARDT model outperforms a smaller transformer model (TinyStories-1M) despite having fewer parameters.", "section": "4.2 The Ability to Generate Coherent Stories"}, {"figure_path": "nge5deRsEH/tables/tables_15_3.jpg", "caption": "Table 1: Experiment Results on TinyStories: The results show that an auto-regressive tree can achieve better performance as the GPT-Neo architecture and exhibit competitive performance compared to both GPT-4 and TinyStories-33M.", "description": "This table presents a comparison of the performance of different language models, including the proposed Auto-Regressive Decision Trees (ARDTs), on the TinyStories dataset.  The models are evaluated based on four metrics: grammar, creativity, consistency, and plot.  The table shows that the ARDTs achieve comparable performance to larger, more complex models like GPT-4 and TinyStories-33M, despite having significantly fewer parameters. This demonstrates the effectiveness of the ARDT approach for language generation tasks.", "section": "4.2 The Ability to Generate Coherent Stories"}]