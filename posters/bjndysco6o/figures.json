[{"figure_path": "BJndYScO6o/figures/figures_0_1.jpg", "caption": "Figure 1: MBD refines the trajectory by leveraging the dynamics model directly without relying on demonstration data.", "description": "This figure illustrates the Model-Based Diffusion (MBD) framework.  The left side shows the model information (dynamics) being used to compute a score function. The right side displays the diffusion process.  The diffusion process starts with noisy samples (Y(0)) and iteratively refines them using the computed score function to converge towards optimal and dynamically feasible trajectories (Y(N)).  Crucially, the method directly uses the model information rather than relying on demonstration data, making it more generalizable to new scenarios.", "section": "1 Introduction"}, {"figure_path": "BJndYScO6o/figures/figures_4_1.jpg", "caption": "Figure 2: Reverse SDE vs. Monte Carlo score ascent (MCSA) on a synthetic highly non-convex objective function. (a) Synthesized objective function with multiple local minima. (b) The intermediate stage density pi (\u00b7), where peaked po(\u00b7) is iteratively corrupted to a Gaussian pv (\u00b7). (c) Reverse SDE vs. MCSA: Background colors represent the density of pi() at different stages. MCSA converges faster due to larger step size and lower sampling noise while still capturing the multimodality.", "description": "This figure compares Reverse Stochastic Differential Equations (SDE) and Monte Carlo Score Ascent methods for optimization on a synthetic, highly non-convex objective function with multiple local minima.  Subfigure (a) shows the objective function. Subfigure (b) illustrates how the forward diffusion process iteratively corrupts the target distribution into a Gaussian distribution. Subfigure (c) visually compares the reverse SDE and MC Score Ascent processes in terms of convergence speed and the density of intermediate distributions, highlighting MC Score Ascent's faster convergence and ability to capture multimodality.", "section": "4.1 Model-based Diffusion as Multi-stage Optimization"}, {"figure_path": "BJndYScO6o/figures/figures_8_1.jpg", "caption": "Figure 4: MBD optimized trajectory with data augmentation on the (a) Humanoid Jogging and (b) Car UMaze Navigation tasks. With data augmentation, the trajectory is regularized and refined to achieve the desired objective.", "description": "This figure shows the results of applying Model-Based Diffusion (MBD) to two different tasks: humanoid jogging and car navigation in a U-maze.  The left panel (a) illustrates the humanoid jogging task. It shows that using data augmentation (MBD with data) leads to a more regularized and refined trajectory compared to using MBD without data. The right panel (b) demonstrates the car navigation task.  Again, the addition of data augmentation results in a trajectory that is better refined and achieves the objective more effectively.  In both examples, MBD benefits from incorporating external data to improve trajectory optimization.", "section": "5 Experimental Results"}, {"figure_path": "BJndYScO6o/figures/figures_9_1.jpg", "caption": "Figure 3: Optimization process of MBD on the (a) Humanoid Standup, (b) Push T, and (c) Humanoid Running tasks. The trajectory is iteratively refined to achieve the desired objective in the high-dimensional space with model information.", "description": "This figure shows the iterative refinement process of the Model-Based Diffusion (MBD) algorithm across three different tasks: Humanoid Standup, Push T, and Humanoid Running.  Each subfigure illustrates the evolution of the trajectory from an initial, noisy state (i=0) to a refined, optimized trajectory (i=N). The color gradient represents the refinement process, moving from light to dark shades as the optimization progresses.  The figure demonstrates MBD's ability to leverage model information to effectively navigate high-dimensional state spaces and achieve the desired objective.", "section": "5 Experimental Results"}, {"figure_path": "BJndYScO6o/figures/figures_17_1.jpg", "caption": "Figure 2: Reverse SDE vs. Monte Carlo score ascent (MCSA) on a synthetic highly non-convex objective function. (a) Synthesized objective function with multiple local minima. (b) The intermediate stage density pi (\u00b7), where peaked po(\u00b7) is iteratively corrupted to a Gaussian pv (\u00b7). (c) Reverse SDE vs. MCSA: Background colors represent the density of pi() at different stages. MCSA converges faster due to larger step size and lower sampling noise while still capturing the multimodality.", "description": "This figure compares the Reverse Stochastic Differential Equation (SDE) approach with the Monte Carlo Score Ascent (MCSA) method for solving a synthetic highly non-convex optimization problem.  Subfigure (a) shows the objective function with multiple local minima. Subfigure (b) illustrates the forward diffusion process, where the target distribution is iteratively corrupted into a Gaussian distribution. Subfigure (c) visually contrasts the reverse SDE and MCSA methods, highlighting MCSA's faster convergence due to its larger step size and reduced sampling noise. Despite the faster convergence, MCSA successfully captures the multimodality of the distribution.", "section": "4.1 Model-based Diffusion as Multi-stage Optimization"}, {"figure_path": "BJndYScO6o/figures/figures_19_1.jpg", "caption": "Figure 6: MBD with data vs. without data on a nonconvex function with constraints ||Y|| \u2013 0.4| > 0.3. We want MBD converge to the optimal point with the help of demonstration data. Although the demostration point is not optimal, MBD can still converge to the optimal point with the guidance of the demonstration data. Here data serves as a regularization term to guide the diffusion process to the negative optimal point while allowing to use model further to refine the solution.", "description": "This figure shows a comparison of Model-Based Diffusion (MBD) with and without demonstration data on a non-convex function with constraints.  The left panel displays the objective function and probability density of the target distribution, showing a non-convex landscape with an optimal solution, infeasible regions, and a demonstration data point that is not optimal. The right panel illustrates the backward diffusion process using Monte Carlo score ascent, demonstrating how the addition of demonstration data guides the diffusion process towards the optimal solution.  In the absence of demonstration data, the sampling process struggles to converge on the optimum.  The data acts as a form of regularization, drawing the process toward a good region, after which the model is able to refine the solution.", "section": "4.3 Model-based Diffusion with Demonstration"}, {"figure_path": "BJndYScO6o/figures/figures_22_1.jpg", "caption": "Figure 7: Comparison of the performance between RL, MBD and MBD receding horizon version with both perfect model and noisy model (with 5% control noise). Given perfect model, we find MBD's performance can be further augmented by 9.6% with naive receding horizon planning and leads RL by larger 74.2%. Given noisy model, MBD receding horizon version still outperforms RL by 65.3%.", "description": "This figure compares the performance of Reinforcement Learning (RL), Model-Based Diffusion (MBD), and a receding horizon version of MBD under both ideal and noisy conditions.  With a perfect model, the receding horizon MBD improves upon standard MBD, significantly outperforming RL. Even when 5% control noise is introduced, the receding horizon MBD maintains a substantial performance advantage over RL.", "section": "5.1 MBD for Planning in Contact-rich Tasks"}, {"figure_path": "BJndYScO6o/figures/figures_23_1.jpg", "caption": "Figure 2: Reverse SDE vs. Monte Carlo score ascent (MCSA) on a synthetic highly non-convex objective function. (a) Synthesized objective function with multiple local minima. (b) The intermediate stage density pi (\u00b7), where peaked po(\u00b7) is iteratively corrupted to a Gaussian pv (\u00b7). (c) Reverse SDE vs. MCSA: Background colors represent the density of pi() at different stages. MCSA converges faster due to larger step size and lower sampling noise while still capturing the multimodality.", "description": "This figure compares the performance of Reverse Stochastic Differential Equations (SDE) and Monte Carlo Score Ascent (MCSA) methods on a synthetic highly non-convex objective function with multiple local minima.  Panel (a) shows the objective function. Panel (b) illustrates the iterative corruption of the target distribution (peaked po(\u00b7)) into a Gaussian distribution (pv(\u00b7)) during the forward diffusion process. Panel (c) visually compares the reverse SDE and MCSA processes, highlighting the faster convergence of MCSA due to its larger step size and reduced sampling noise while maintaining the multimodality of the distribution.", "section": "4.1 Model-based Diffusion as Multi-stage Optimization"}, {"figure_path": "BJndYScO6o/figures/figures_24_1.jpg", "caption": "Figure 7: Comparison of the performance between RL, MBD and MBD receding horizon version with both perfect model and noisy model (with 5% control noise). Given perfect model, we find MBD's performance can be further augmented by 9.6% with naive receding horizon planning and leads RL by larger 74.2%. Given noisy model, MBD receding horizon version still outperforms RL by 65.3%.", "description": "This figure compares the performance of Reinforcement Learning (RL), Model-Based Diffusion (MBD), and a receding horizon version of MBD across various control tasks.  Both perfect and noisy (5% control noise) model scenarios are evaluated.  The results demonstrate the improved performance of MBD, especially when a receding horizon approach is used.", "section": "5.1 MBD for Planning in Contact-rich Tasks"}]