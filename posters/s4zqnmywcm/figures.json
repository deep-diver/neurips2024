[{"figure_path": "S4ZqnMywcM/figures/figures_1_1.jpg", "caption": "Figure 1: Different paradigms of spike-to-image reconstruction. (a) Prevailing step-by-step network architecture (e.g., Spk2ImgNet [55]). (b) Our proposed joint motion-intensity learning framework. A simple yet effective hybrid spike embedding representation (HSER) is also proposed as a link between the binary spikes and the deep model.", "description": "This figure compares two different approaches for spike-to-image reconstruction.  (a) shows the traditional step-by-step method, which consists of separate modules for spike embedding, temporal motion estimation, and spatial intensity reconstruction. (b) illustrates the proposed method, which uses a joint motion-intensity learning framework. The proposed method uses a novel hybrid spike embedding representation (HSER) to efficiently link the binary spikes from the camera to the deep learning model.", "section": "1 Introduction"}, {"figure_path": "S4ZqnMywcM/figures/figures_3_1.jpg", "caption": "Figure 3: Overview of our STIR framework (a) and details of the key components (b), (c), and (d). In our joint learning architecture, spatio-temporal features are refined progressively from coarse to fine, where warping-based inter-frame feature alignment (Orange line) and synthesis-based intra-frame feature filtering (Purple dashed line) are simultaneously performed in (b). Integrating (c) and (d) at the top and bottom pyramids, respectively, can boost the spatio-temporal interaction of the network.", "description": "This figure provides a detailed overview of the proposed Spatio-Temporal Interactive Reconstruction (STIR) network architecture.  It shows the overall framework, highlighting the key components: the hybrid spike embedding representation (HSER), the hierarchical feature encoder, the spatio-temporal interactive decoder with motion-intensity interactive blocks, the symmetric interactive attention block, and the multi-motion field estimation block. The figure illustrates how the network processes spike streams from a spiking camera to generate high-quality intermediate frames. The color-coded lines indicate feature flow and processing, showcasing the network's coarse-to-fine refinement strategy.", "section": "4 Methodology"}, {"figure_path": "S4ZqnMywcM/figures/figures_7_1.jpg", "caption": "Figure 4: Visual comparison on synthetic [57] (top) and real-captured [61] (bottom) data. Our method reconstructs precise boundaries of fast-moving objects with higher fidelity. Zoom in for more details.", "description": "This figure compares the image reconstruction results of different methods on synthetic and real datasets. The top row shows results for a synthetic dataset, while the bottom row shows results for a real-captured dataset. The results show that the proposed method outperforms the existing methods in terms of accurately reconstructing the boundaries of fast-moving objects.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/figures/figures_15_1.jpg", "caption": "Figure 4: Visual comparison on synthetic [57] (top) and real-captured [61] (bottom) data. Our method reconstructs precise boundaries of fast-moving objects with higher fidelity. Zoom in for more details.", "description": "This figure shows a qualitative comparison of different image reconstruction methods on both synthetic and real-captured datasets.  The top row presents results from a synthetic dataset, while the bottom row shows results from real-world data captured by a spiking camera.  The figure highlights the superior performance of the proposed STIR method (Ours) in accurately reconstructing the boundaries of fast-moving objects, demonstrating its ability to handle dynamic scenes effectively and with high precision. This contrasts with the results from other methods, which show more blurry or less defined edges, especially for rapidly moving objects.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/figures/figures_16_1.jpg", "caption": "Figure 4: Visual comparison on synthetic [57] (top) and real-captured [61] (bottom) data. Our method reconstructs precise boundaries of fast-moving objects with higher fidelity. Zoom in for more details.", "description": "This figure shows a visual comparison of image reconstruction results on synthetic and real datasets using different methods, including the proposed STIR method. The top row presents results from the synthetic dataset, and the bottom row shows results from the real-captured dataset. Each scene contains 24 consecutive frames, and a corresponding spike stream of N=20 is centered around each frame.  The figure highlights the superior performance of the STIR method in reconstructing precise boundaries and details of fast-moving objects compared to other methods.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/figures/figures_16_2.jpg", "caption": "Figure 7: Visualization of ablation results based on the \"recVidarReal2019\" dataset [66]. From left to right, we show the removal of symmetric interactive attention block, the removal of reconstruction loss Lrec, the removal of warping-based inter-frame feature alignment, and the estimation of single-motion field. Our full model reconstructs higher-fidelity images with fewer artifacts. Please zoom in for more details.", "description": "This figure visualizes the ablation study conducted on the recVidarReal2019 dataset.  It demonstrates the impact of removing key components of the proposed Spatio-Temporal Interactive Reconstruction (STIR) network on the quality of reconstructed images.  The results show that each component (symmetric interactive attention block, reconstruction loss Lrec, warping-based inter-frame feature alignment, and the use of multiple motion fields) contributes to the overall performance. Removing any of these components leads to a noticeable decrease in image quality, highlighting the effectiveness of the STIR model's full design.", "section": "5.3 Ablation Studies"}, {"figure_path": "S4ZqnMywcM/figures/figures_17_1.jpg", "caption": "Figure 4: Visual comparison on synthetic [57] (top) and real-captured [61] (bottom) data. Our method reconstructs precise boundaries of fast-moving objects with higher fidelity. Zoom in for more details.", "description": "This figure presents a visual comparison of image reconstruction results using different methods on both synthetic and real-world datasets.  The top row shows results for a synthetic dataset, while the bottom row displays results for real-captured data. Each image shows a scene with fast-moving objects. The figure highlights the superior performance of the proposed STIR method in accurately reconstructing the details and boundaries of these moving objects, emphasizing its improved fidelity compared to existing state-of-the-art methods.  The detailed captions under the images indicate the methods used for reconstruction.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/figures/figures_18_1.jpg", "caption": "Figure 4: Visual comparison on synthetic [57] (top) and real-captured [61] (bottom) data. Our method reconstructs precise boundaries of fast-moving objects with higher fidelity. Zoom in for more details.", "description": "This figure shows a visual comparison of image reconstruction results between the proposed method and several state-of-the-art methods using both synthetic and real datasets.  The top row displays results from synthetic data, while the bottom row showcases results obtained from real-world spiking camera data. Yellow boxes highlight the regions of interest, and the results show that the proposed method is superior in reconstructing precise boundaries of fast-moving objects, indicating higher fidelity compared to other methods.", "section": "5 Experiments"}, {"figure_path": "S4ZqnMywcM/figures/figures_19_1.jpg", "caption": "Figure 1: Different paradigms of spike-to-image reconstruction. (a) Prevailing step-by-step network architecture (e.g., Spk2ImgNet [55]). (b) Our proposed joint motion-intensity learning framework. A simple yet effective hybrid spike embedding representation (HSER) is also proposed as a link between the binary spikes and the deep model.", "description": "This figure compares two different approaches for spike-to-image reconstruction. (a) shows the traditional step-by-step method, which involves separate modules for spike embedding, motion estimation, and intensity recovery.  (b) illustrates the authors' proposed method, which integrates motion and intensity estimation within a unified framework, using a novel hybrid spike embedding representation (HSER) to bridge the gap between raw spike data and the deep learning model.  The new method aims for more efficiency and better performance.", "section": "1 Introduction"}]