[{"figure_path": "1zVinhehks/tables/tables_7_1.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for several graph classification methods across eight benchmark datasets.  The accuracy is expressed as a percentage and averaged across multiple runs.  The top three methods, as determined by the average accuracy across all datasets, are highlighted in bold.  The datasets encompass various domains and scales, providing a comprehensive evaluation of the different models.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_8_1.jpg", "caption": "Table 2: AUC-ROC scores of large imbalanced data classification. Bold text indicates the best.", "description": "This table presents the AUC-ROC (Area Under the Receiver Operating Characteristic Curve) scores achieved by four different graph neural network models on three large, imbalanced datasets: PC-3, MCF-7, and OGBG-MOLHIV.  The AUC-ROC is a common metric for evaluating the performance of binary classification models, particularly useful when dealing with imbalanced datasets. The models compared include GIN, Diffpool, Patchy-SAN, and the authors' proposed GRDL method. The best performing model for each dataset is highlighted in bold.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_8_2.jpg", "caption": "Table 3: Comparison of time cost (second) per epoch with Wit-TopoPool and MSGNN.", "description": "This table compares the training time per epoch of GRDL with two state-of-the-art pooling methods, Wit-TopoPool and MSGNN, across eight real-world datasets and three synthetic datasets (SYN-100, SYN-300, SYN-500).  The synthetic datasets vary in the number of nodes per graph (100, 300, and 500) to assess scalability.  Empty cells indicate training times exceeding 200 seconds, highlighting the efficiency of GRDL. The table demonstrates that GRDL consistently exhibits faster training times compared to both Wit-TopoPool and MSGNN.", "section": "5.2 Time Cost Comparison"}, {"figure_path": "1zVinhehks/tables/tables_16_1.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for various graph classification methods on eight benchmark datasets.  The accuracy is represented as a percentage, averaged over multiple runs. The top three methods are highlighted in bold for each dataset, allowing for easy comparison of model performance across different datasets.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_16_2.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for various graph classification methods across eight benchmark datasets.  The accuracy is expressed as a percentage, and the results are averaged across multiple runs, with standard deviations indicated. The top three methods with the highest average accuracy for each dataset are highlighted in bold. The datasets cover diverse domains such as bioinformatics and social networks, offering a comprehensive evaluation of the methods.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_19_1.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for various graph classification methods across eleven benchmark datasets.  Each dataset's accuracy is presented as a mean \u00b1 standard deviation, calculated across multiple trials.  The top three performing methods for each dataset are highlighted in bold to quickly identify the best-performing algorithms.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_19_2.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for various graph classification methods across eight benchmark datasets and three large-scale imbalanced datasets.  The accuracy is presented as an average with standard deviation across multiple runs of 10-fold cross validation.  The top three performing methods for each dataset are highlighted in bold.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_20_1.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for several graph classification methods across eight benchmark datasets.  The accuracy is reported as a percentage with standard deviation, and the top three performing methods are highlighted in bold for each dataset.  The average accuracy across all datasets is also provided for each method.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_20_2.jpg", "caption": "Table 9: Average prediction time per graph (10-3 seconds).", "description": "This table presents the average prediction time, measured in milliseconds, for different graph classification methods (GRDL, OT-GNN, and TFGW) across eight benchmark datasets.  It shows the speed of prediction for each model, indicating the computational efficiency.  The values reflect the average time taken to predict the class label of a single graph.", "section": "5.2 Time Cost Comparison"}, {"figure_path": "1zVinhehks/tables/tables_20_3.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for various graph classification methods across eight benchmark datasets.  The accuracy is reported as an average over multiple runs with standard deviation.  The top three methods in terms of average accuracy are highlighted in bold for each dataset, allowing for easy comparison between the different methods.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_21_1.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for various graph classification methods on eight benchmark datasets.  The accuracy is expressed as a percentage and represents the average performance across multiple trials, with standard deviation implied by the \u00b1 notation.  Bold text highlights the top three performing methods for each dataset, providing a clear comparison of the different approaches. The datasets encompass various domains, offering a robust evaluation of the models' generalization capabilities.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_21_2.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy results for several graph classification methods across eight benchmark datasets and three large-scale imbalanced datasets.  Each dataset's results are given as mean \u00b1 standard deviation of accuracy for each method. The top three methods are highlighted in boldface for each dataset, indicating their superior performance. The table provides a comprehensive comparison of various methods and allows for the assessment of the relative performance of each algorithm on different graph structures.", "section": "5 Numerical Experiments"}, {"figure_path": "1zVinhehks/tables/tables_22_1.jpg", "caption": "Table 1: Classification accuracy (%). Bold text indicates the top 3 mean accuracy.", "description": "This table presents the classification accuracy of various graph classification methods on eight benchmark datasets.  The accuracy is expressed as a percentage and represents the average performance across multiple trials.  The top three performing methods for each dataset are highlighted in bold to emphasize the relative performance of different approaches. The average accuracy across all datasets is also provided for each method.", "section": "5 Numerical Experiments"}]