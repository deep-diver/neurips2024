[{"type": "text", "text": "Randomized Exploration in Cooperative Multi-Agent Reinforcement Learning ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Hao-Lun Hsu\\* Weixin Wang\\* Miroslav Pajic, Pan Xu Duke University {hao-lun.hsu, weixin.wang,miroslav.pajic,pan.xu}@duke.edu ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "We present the first study on provably efficient randomized exploration in cooperative multi-agent reinforcement learning (MARL). We propose a unified algorithm framework for randomized exploration in parallel Markov Decision Processes (MDPs), and two Thompson Sampling (TS)-type algorithms, CoopTS-PHE and CoopTS-LMC, incorporating the perturbed-history exploration (PHE) strategy and the Langevin Monte Carlo exploration (LMC) strategy respectively, which are flexible in design and easy to implement in practice. For a special class of parallel MDPs where the transition is (approximately) linear, we theoretically prove that both CoopTS-PHE and CoopTS-LMC achieve a $\\widetilde{\\cal O}(d^{3/2}H^{2}\\sqrt{M K})$ regret bound with communication complexity $\\widetilde{\\cal O}(d H M^{2})$ , where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the number of agents, and $K$ is the number of episodes. This is the first theoretical result for randomized exploration in cooperative MARL. We evaluate our proposed method on multiple parallel RL environments, including a deep exploration problem (i.e., $N$ -chain), a video game, and a real-world problem in energy systems. Our experimental results support that our framework can achieve better performance, even under conditions of misspecified transition models. Additionally, we establish a connection between our unified framework and the practical application of federated learning. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Multi-Agent Reinforcement Learning (MARL) has emerged as a potent tool with wide-ranging applications in diverse fields including robotics [23, 54], gaming [74, 92, 84], and numerous realworld systems [10, 25, 85]. This is particularly evident in cooperative scenarios, where MARL's effectiveness is enhanced through both direct and indirect communication channels among agents. This requires MARL algorithms to adeptly and flexibly coordinate communications to optimize the benefits of cooperation. One of the classical challenges in MARL is balancing exploration and exploitation so that agents effectively utilize existing information while acquiring new knowledge. Recent literature highlights the intricacies of this balance, focusing on cooperative exploration strategies [27] and dynamic exploitation tactics [68]. Achieving this equilibrium is crucial for the practical deployment of MARL systems in real-world scenarios, where unpredictability and the need for rapid adaptation are prevalent [27, 14, 55]. ", "page_idx": 0}, {"type": "text", "text": "Optimism in the Face of Uncertainty (OFU) is a popular strategy to address the explorationexploitation problem [1]. OFU strategy leads to numerous upper confidence bound (UCB)-type algorithms in contextual bandits [18, 1, 50], single-agent reinforcement learning [36, 76], and more recently multi-agent reinforcement learning [24, 56]. These algorithms compute statistical confidence regions for the model or the value function, given the observed history, and perform the greedy policy with respect to these regions, or upper confidence bounds. Though UCB-based methods give out strong theoretical results, they often have poor performance in practice [61, 60]. For example, Wang et al. [76] demonstrates that computing the confidence bonus necessitates advanced sensitivity sampling and the expensive computation makes the practical applications inefficient. It is worth noting that UCB is mostly constructed based on a linear structure [18, 36]. NeuralUCB is a notable attempt at a nonlinear version while it is infeasible in terms of computational complexity [94, 82]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Inspired by Thompson Sampling (TS) [73], posterior sampling for reinforcement learning (RL) [7, 95] involves maintaining a posterior distribution over the parameters of the Markov Decision Processes (MDP) model parameters. Although conceptually simple, most existing TS methods require the exact posterior or a good Laplacian approximation [83]. Recently, there have been advancements in randomized exploration with approximate sampling. One important method is perturb-history exploration (PHE) strategy, which involves introducing random perturbations in the action history of the agent [45, 47, 32]. This randomized exploration approach diversifies the agent's experience, aiding in learning more robust strategies in environments with uncertainty and variability. Another effective method is Langevin Monte Carlo (LMC) method [83, 33, 31, 42, 58, 34]. Notably, Ishfaq et al. [33] maintains the simplicity and scalability of LMC, making it applicable in deep RL algorithms by approximating the posterior distribution of the $Q$ function. ", "page_idx": 1}, {"type": "text", "text": "Despite the aforementioned advancements of randomized exploration in bandits and single-agent RL, there remains a scarcity of research on randomized exploration within cooperative MARL, which motivates us to present the first investigation into provably efficient randomized exploration in cooperative MARL, with both theoretical and empirical evidence. We specifically focus on the applicability in parallel MDPs, aiming to facilitate faster learning and to improve policy optimization with the same state and action spaces, allowing for leveraging similarities across MDPs. We theoretically and empirically demonstrate that randomized exploration strategies can be extended to the multi-agent setting and the benefit of randomized exploration instead of UCB can be significant from single-agent to multi-agent setting. ", "page_idx": 1}, {"type": "text", "text": "In summary, our contributions are as follows: ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "\u00b7 We propose a unified algorithm framework for learning parallel MDPs, and apply two TS-related strategies PHE and LMC for exploration, which leads to the CoopTS-PHE and CoopTS-LMC algorithms. Unlike conventional TS, which suffers from sampling errors due to Laplace approximation and expensive posterior computation [66, 46], our proposed algorithms only require adding standard Gaussian noises to the dataset (CoopTS-PHE) or the gradient (CoopTS-LMC) when performing Least-Square Value Iteration, which is efficient in computation and avoids sampling bias due to the Laplace approximation. Notably, both algorithms are easily implementable which are more practical than UCB-based algorithms in deep MARL. \u00b7 When reduced to linear parallel MDPs, we theoretically prove that both CoopTS-PHE and CoopTSLMC with linear function approximation can achieve a regret bound $\\widetilde{\\cal O}\\left(d^{3/2}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\right.$ $\\sqrt{K})$ )with communication complexity $\\tilde{\\mathcal{O}}\\big((d+K/\\gamma)M H\\big)$ , where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the number of agents, $K$ is the number of episodes for each agent, and $\\gamma$ is a parameter controlling the communication frequency. When $\\gamma=\\bar{O}(K/d M)$ , our algorithms attain $\\widetilde{\\mathcal{O}}\\big(d^{3/2}H^{2}\\sqrt{M K}\\big)$ regret with $\\widetilde{\\cal O}(d H M^{2})$ communication complexity. This result matches the best communication complexity in cooperative MARL [56], and the best regret bounds for randomized RL in the single-agent setting ( $M=1$ ) [32, 33]. A comprehensive comparison with baseline algorithms on episodic, non-sationary, linear MDPs is presented in Table 1. \u00b7 We further extend our theoretical analysis to the misspecified setting where both the transition and reward are approximately linear up to an error $\\zeta$ and the MDPs could be heterogeneous across agents, which is a generalized notion of misspecification [36]. We theoretically prove when $\\zeta={\\mathcal{O}}{\\big(}{\\sqrt{d/M K}}{\\big)}$ , the cumulative regret for CoopTS-PHE matches the result in the linear homogeneous MDP setting. Simultaneously, when $\\zeta=\\mathcal{O}\\big(\\sqrt{1/M K}\\big)$ , the cumulative regret for CoopTS-LMC matches the result in the linear homogeneous MDP setting. This result indicates that CoopTS-PHE has a slightly higher tolerance on the model misspecification than CoopTS-LMC. \u00b7 We conduct extensive experiments on various benchmarks with comprehensive ablation studies, including $N$ -chain that requires deep exploration, Super Mario Bros task in a misspecified setting, and a real-world problem in thermal control of building energy systems. Our empirical evaluation demonstrates that our randomized exploration strategies outperform existing deep $Q$ -network (DQN)-based baselines. We also show that these strategies in cooperative MARL can be adapted to the existing federated RL framework when data transitions are not shared. ", "page_idx": 1}, {"type": "table", "img_path": "7Tir0u0ukg/tmp/df234e969b07ca4d0f8e374df32b21b5952d0c0cae95c0d6c71f53b71caa291a.jpg", "table_caption": ["Table 1: Comparison on episodic, non-stationary, linear MDPs. We define the average regret as the cumulative regret divided by the total number of samples (transition pairs) used by the algorithm. Here $d$ is the feature dimension, $H$ is the episode length, $K$ is the number of episodes, and $M$ is the number of agents in a multi-agent setting. "], "table_footnote": [], "page_idx": 2}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "2 Preliminary ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In parallel Markov Decision Processes (MDPs), $M$ agents interact independently with their respective discrete-time MDPs, sharing the same but independent state and action spaces. Each agent might have its unique reward functions and transition kernels. Specifically, for agent $m\\in\\mathcal{M}$ , the associated MDP is defined by the tuple $\\mathrm{MDP}(S,\\mathcal{A},H,\\mathbb{P}_{m},r_{m})$ . Here $\\boldsymbol{S}$ and $\\boldsymbol{\\mathcal{A}}$ are the state and action spaces respectively, $H$ is the horizon length, $\\mathbb{P}_{m}\\,=\\,\\{\\mathbb{P}_{m,h}\\}_{h\\in[H]}$ and $r_{m}\\,=\\,\\{r_{m,h}\\}_{h\\in[H]}$ are the sets of transition kernels and reward functions. For step $h\\in[H]$ $\\mathbf{\\dot{P}}_{m,h}^{\\prime}(\\cdot|s,a)$ is the probability measure over the next state given current state-action pair $(s,a)$ $a),r_{m,h}:S\\times A\\to[0,1]$ is the deterministic reward function. The policy $\\pi_{m}=\\{\\pi_{m,h}\\}_{h\\in[H]}$ is a sequences of decision rules where $\\pi_{m,h}:S\\to A$ is the deterministic policy at step $h$ ", "page_idx": 2}, {"type": "text", "text": "For agent $m\\in\\mathcal{M}$ , given any policy $\\pi$ and transition $\\mathbb{P}$ , to evaluate the policy effectiveness in the $m^{\\mathrm{th}}$ MDP, we define value function $\\begin{array}{r}{V_{m,h}^{\\pi}(s):=\\mathbb{E}_{\\pi}[\\sum_{h^{\\prime}=h}^{H}r_{m,h^{\\prime}}(s_{m,h^{\\prime}},a_{m,h^{\\prime}})|s_{m,h}=s]}\\end{array}$ and $Q$ function $\\begin{array}{r}{Q_{m,h}^{\\pi}(s,a):=\\mathbb{E}_{\\pi}[\\sum_{h^{\\prime}=h}^{H}r_{m,h^{\\prime}}(s_{m,h^{\\prime}},a_{m,h^{\\prime}})|s_{m,h}=s,a_{m,h}=a]}\\end{array}$ forany $(h,s,a)\\in[H]\\times S\\times A$ The optimal pliey i defined as $\\pi_{m}^{*}$ and we denote $V_{m,h}^{*}(s)=V_{m,h}^{\\pi_{m}^{*}}(s)$ For each $k\\in[K]$ athe beginning of episode $k$ , each agent $m\\in\\mathcal{M}$ receives the initial state $s_{m,1}^{k}$ chosen arbitrarly by the environment. For each step $h\\in[H]$ in this episode, each agent $m$ observes its current state $s_{m,h}^{k}$ \uff0c selects an action to the next state sm,h+1 b $a_{m,h}^{k}$ based on policy based $\\pi_{m,h}^{k}$ $r_{m,h}(s_{m,h}^{k},a_{m,h}^{k})$ $\\mathbb{P}_{m,h}(\\cdot|s_{m,h}^{k},a_{m,h}^{k})$ and then transitions defaults to O when the episode terminates at step .The goal of agents is to minimize the cumulative group regret after $K$ episodes, which is defined as ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathrm{Regret}(K)=\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\left[V_{m,1}^{*}\\big(s_{m,1}^{k}\\big)-V_{m,1}^{\\pi_{m}^{k}}\\big(s_{m,1}^{k}\\big)\\right].}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "3  Algorithm Design ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "In this section, we first present a unified algorithm framework for conducting randomized exploration in cooperative MARL. Then we introduce two practical randomized exploration strategies. ", "page_idx": 2}, {"type": "text", "text": "3.1  Unified Algorithm Framework ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "A unified algorithm framework is presented in Algorithm 1, where each agent executes Least-Square Value Iteration (LsVI) in parallel and makes decisions based on collective data obtained from communication between each agent and the server. Before we describe the details of our algorithm, we first define notations about the datasets stored on each agent's local machine and the server. ", "page_idx": 2}, {"type": "text", "text": "Algorithm 1 Unified Algorithm Framework for Randomized Exploration in Parallel MDPs ", "page_idx": 3}, {"type": "text", "text": "1: Initialization: set $U_{h}^{\\mathrm{ser}}(k),U_{m,h}^{\\mathrm{loc}}(k)=\\emptyset$   \n2: for episode $k=1,...,K$ do   \n3: for agent $m\\in\\mathcal{M}$ do   \n4: Receive initial state sm,1   \n5: Vm,H+1() \u2190 0.   \n6: $\\{Q_{m,h}^{k}(\\cdot,\\cdot)\\}_{h=1}^{H}\\gets$ Randomized Exploration < Algorithm 2 or Algorithm 3   \n7: for step $h=1,...,H$ do   \n8: $\\begin{array}{r}{a_{m,h}^{k}\\leftarrow\\operatorname*{argmax}_{a\\in\\mathcal{A}}Q_{m,h}^{k}(s_{m,h}^{k},a).}\\end{array}$   \n9: Receive $s_{m,h+1}^{k}$ and $r_{m,h}$ .k   \n10: $U_{m,h}^{\\mathrm{loc}}(k)\\gets U_{m,h}^{\\mathrm{loc}}(k)\\bigcup\\big(s_{m,h}^{k},a_{m,h}^{k},s_{m,h+1}^{k}\\big).$   \n11: if Condition then   \n12: SYNCHRONIZE $\\leftarrow$ True.   \n13: end if   \n14: end for   \n15: end for   \n16: if SYNCHRONIZE then   \n17: for step $h=H,...,1$ do   \n18: $\\forall\\,A G E N T$ Send $U_{m,h}^{\\mathrm{loc}}(k)$ to ERVER.   \n19: SERVER: $U_{h}^{\\mathrm{loc}}(k)\\gets\\bigcup_{m\\in\\mathcal{M}}U_{m,h}^{\\mathrm{loc}}(k)$ \uff0c   \n20: SERVER: $U_{h}^{\\mathrm{ser}}(k)\\gets U_{h}^{\\mathrm{ser}}(k)\\bigcup U_{h}^{\\mathrm{loc}}(k)$   \n21: SERVER: Send $U_{h}^{\\mathrm{ser}}(k)$ to each AGENT.   \n22: $\\forall\\,A G E N T$ Set $U_{m,h}^{\\mathrm{loc}}(k)\\gets\\emptyset$   \n23: end for   \n24: end if   \n25: end for ", "page_idx": 3}, {"type": "text", "text": "Index notation  We define $k_{s}(k)$ (denoted as $k_{s}$ when no ambiguity arises) as the last episode before episode $k$ where synchronization happens. For episode $k$ and step $h$ , we define three datasets: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{U_{h}^{\\mathrm{ser}}(k)=\\big\\{\\bigl(s_{n,h}^{\\tau},a_{n,h}^{\\tau},s_{n,h+1}^{\\tau}\\bigr)\\big\\}_{n\\in\\mathcal{M},\\tau\\in[k_{s}]},}\\\\ &{U_{m,h}^{\\mathrm{loc}}(k)=\\big\\{\\bigl(s_{m,h}^{\\tau},a_{m,h}^{\\tau},s_{m,h+1}^{\\tau}\\bigr)\\big\\}_{\\tau=k_{s}+1}^{k-1},}\\\\ &{U_{m,h}(k)=U_{h}^{\\mathrm{ser}}(k)\\bigcup U_{m,h}^{\\mathrm{loc}}(k).}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "By definition, $U_{h}^{\\mathrm{ser}}(k)$ is the dataset that is shared across all agents due to the latest synchronization at episode $k_{s}$ $U_{m,h}^{\\mathrm{loc}}(k)$ is the unique data collected by agent $m$ since episode $k_{s}$ . Then $U_{m,h}(k)$ is the total dataset available for agent $m$ at the current time. Let $\\kappa(k)=|U_{m,h}(k)|$ be the total number of data points. For the simplicity of notation, we also re-order the data points in $U_{m,h}(k)$ , and rename the tuple $(s_{m,h}^{\\tau},a_{m,h}^{\\tau},s_{m,h+1}^{\\tau})$ as $(s^{l},a^{l},s^{\\prime}{}^{l})$ such that we have $\\begin{array}{r}{U_{m,h}(k)=\\bigcup_{l=1}^{\\mathcal{K}(k)}(s^{l},a^{l},s^{\\prime}{}^{l})}\\end{array}$ . In fact, this can be done by the following one-to-one mapping ", "page_idx": 3}, {"type": "equation", "text": "$$\nl_{m,k}(n,\\tau)=\\left\\{\\!\\!\\begin{array}{l l}{{(\\tau-1)M+n}}&{{\\tau\\leq k_{s},}}\\\\ {{(M-1)k_{s}+\\tau}}&{{k_{s}<\\tau\\leq k-1.}}\\end{array}\\!\\!\\right.\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Therefore, we use indices $(s,a,s^{\\prime})\\in U_{m,h}(k)$ and $l\\in[K(k)]$ interchangeably for the summation over set $U_{m,h}(k)$ ", "page_idx": 3}, {"type": "text", "text": "Algorithm interpretation  At a high level, each episode $k$ in Algorithm 1 consists of two stages. The first stage (Lines 3-15) is parallelly executed by all agents and the second stage (Lines 16-24) involves the communication among agents and the server. ", "page_idx": 3}, {"type": "text", "text": "In the first stage (Lines 3-15) of Algorithm 1, each agent $m$ operates in two parts. The first part (Line 6) updates estimated $Q$ functions $\\{Q_{m,h}^{k}\\}_{h=1}^{H}$ through LSVI with a randomized exploration strategy (Algorithm 2 or Algorithm 3, which will be introduced in Section 3.2). In particular, given the estimated aluefunctions $V_{m,h+1}^{k}(\\cdot)=\\operatorname*{max}_{a\\in A}Q_{m,h}^{k}(\\cdot,a)$ atstep $h+1$ we perfom one step robust backward Bellman update to obtain $V_{m,h}^{k}(\\cdot)$ at step $h$ . And we initialize Vm,H+1(-) to be 0 (Line 5). In the second part (Lines 7-14), after obtaining the estimated $Q$ functions, in each step $h$ we execute the greedy policy with respect to $Q_{m,h}^{k}$ and collect new data points which are added to the local dataet $U_{m,h}^{\\mathrm{loc}}(k)$ (Lines 8-10). Then we erify the synchronization condition Lines 11-13). In this paper, we mainly use three types of synchronization rules. (1) We can synchronize every $c$ episode where $c$ is a user-defined constant, which is easy to implement in practice. (2) We can also synchronize at the episode of $b^{1},b^{2},...,b^{n}$ , with $b$ representing the base of the exponential function. This is guided by the intuition that agents require more transitions urgently at the early learning stages. (3) Additionally, if we have a feature mapping $\\phi(s,a):S\\times\\bar{A}\\to\\dot{\\mathbb{R}}^{d}$ , based on (3.1), we define the following empirical covariance matrices. ", "page_idx": 3}, {"type": "text", "text": "", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad^{\\mathrm{ser}}\\Lambda_{h}^{k}=\\sum_{(s^{l},a^{l},s^{\\prime}})\\{{U}_{h}^{\\mathrm{ser}}(k)\\,\\phi\\bigl(s^{l},a^{l}\\bigr)\\phi\\bigl(s^{l},a^{l}\\bigr)^{\\top},}\\\\ &{^{\\mathrm{loc}}\\Lambda_{m,h}^{k}=\\sum_{(s^{l},a^{l},s^{\\prime}})\\in U_{m,h}^{\\mathrm{loc}}(k)\\,\\phi\\bigl(s^{l},a^{l}\\bigr)\\phi\\bigl(s^{l},a^{l}\\bigr)^{\\top},}\\\\ &{\\quad\\Lambda_{m,h}^{k}=\\,^{\\mathrm{ser}}\\Lambda_{h}^{k}+\\,^{\\mathrm{loc}}\\Lambda_{m,h}^{k}+\\lambda\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "We synchronize as long as the following condition is met: ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\log\\frac{\\operatorname*{det}\\left(^{\\mathrm{ser}}\\Lambda_{h}^{k}+^{\\mathrm{loc}}\\Lambda_{m,h}^{k}+\\lambda\\mathbf{I}\\right)}{\\operatorname*{det}\\left(^{\\mathrm{ser}}\\Lambda_{h}^{k}+\\lambda\\mathbf{I}\\right)}\\geq\\frac{\\gamma}{(k-k_{s})},\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $\\gamma$ is a communication control factor. In our experiments, we try all three rules and compare their performance, which is discussed in detail in Appendix K.1. ", "page_idx": 4}, {"type": "text", "text": "The second stage (Lines 16-24) is executed only when the synchronization condition is satisfied. First althantsuload tharansi $U_{m,h}^{\\mathrm{loc}}(k)$ e,the newly colleced local datafter the last synchronization, to the server. Then, the server gathers all information together in $U_{h}^{\\mathrm{ser}}(k)$ and sends it back to each agent. Finally, each agent resets the local transition set $U_{m,h}^{\\mathrm{loc}}(k)\\gets\\emptyset$ Now agent $m$ can access the dataset $U_{m,h}(k)=\\,U_{h}^{\\mathrm{ser}}(k)\\bigcup U_{m,h}^{\\mathrm{loc}}(k)$ which contains the historical data of all agents up to last synchronization and its local dataset. ", "page_idx": 4}, {"type": "text", "text": "3.2  Randomized Exploration Strategies ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "When we update the model parameter and estimate $Q$ functions in Algorithm 1 (Line 6), we use $Q$ $\\{Q_{m,h}^{k}\\}_{h=1}^{H}$ Although UCB-based methods come with strong theoretical guarantees, they often perform poorly in practice [16, 61, 60]. Moreover, UCB requires precise computation of the confidence set, which is usually hard to be implemented beyond the linear structure. In contrast, randomized exploration strategies offer more robust performance, flexibility in design, ease of implementation, and do not require a linear structure. ", "page_idx": 4}, {"type": "text", "text": "We approximate the $Q$ functions with the following function class ${\\mathcal F}=\\{f_{\\mathbf{w}}:S\\times A\\rightarrow\\mathbb{R}|f_{\\mathbf{w}}(s,a)=$ $f(\\mathbf{w};\\boldsymbol{\\phi}(s,a))\\}$ ,where $\\mathbf{w}\\in\\mathbb{R}^{d}$ is the parameter and $\\phi\\in\\mathbb{R}^{d}$ is a feature mapping associated with state-action pairs. Now we define the loss function for estimating the $Q$ functions. ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{m,h}^{k}(\\mathbf{w})=\\sum_{l=1}^{K(k)}L\\big(r_{h}^{l}+V_{m,h+1}^{k}(s^{\\prime}),f\\big(\\mathbf{w};\\phi^{l}\\big)\\big)+\\lambda\\|\\mathbf{w}\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where $r_{h}^{l}=r_{h}\\big(s^{l},a^{l}\\big)$ \uff0c $\\phi^{l}=\\phi\\big(s^{l},a^{l}\\big)$ , and $L$ is a user-specified loss function. ", "page_idx": 4}, {"type": "text", "text": "Perturbed-History Exploration   The first strategy we use in Algorithm 1 is called the perturbedhistory exploration [45, 47, 32], displayed in Algorithm 2. We refer to the resulting algorithm as CoopTS-PHE. In particular, we optimize the following randomized loss function, where we add random Gaussian noises to the rewards and regularizer in (3.4). ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widetilde{L}_{m,h}^{k,n}(\\mathbf{w})=\\sum_{l=1}^{K(k)}L\\big(\\big(r_{h}^{l}+\\epsilon_{h}^{k,l,n}\\big)+V_{m,h+1}^{k}(s^{\\prime}^{l}),f\\big(\\mathbf{w};\\phi^{l}\\big)\\big)+\\lambda\\|\\mathbf{w}+\\xi_{h}^{k,n}\\|^{2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "where Eh, $\\epsilon_{h}^{k,l,n}\\overset{\\mathrm{i.i.d}}{\\sim}\\mathcal{N}(0,\\sigma^{2}),\\boldsymbol{\\xi}_{h}^{k,n}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$ and $n\\in[N]$ Then we obtain the following perturbd estimated parameter ", "page_idx": 4}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\widetilde{\\mathbf{w}}_{m,h}^{k,n}=\\mathop{\\mathrm{argmin}}_{\\mathbf{w}\\in\\mathbb{R}^{d}}\\widetilde{L}_{m,h}^{k,n}(\\mathbf{w}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 4}, {"type": "text", "text": "Note that we repeat the above steps for $n=1,\\ldots,N$ to obtain independent copies of parameters, which is referred to as the multi-sampling process [32, 33]. Then we obtain the estimated $Q$ function $Q_{m,h}^{k}$ basedon Line in Algorithm 2. Finaly by maximizing $Q_{m,h}^{k}$ over actionspace $\\boldsymbol{\\mathcal{A}}$ we obtain the estimated value function $V_{m,h}^{k}$ ", "page_idx": 5}, {"type": "text", "text": "Algorithm 2 Perturbed-History Exploration ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "1: Input: multi-sampling number $N\\in\\mathbb{N}^{+}$ , function class ${\\mathcal F}=\\{f_{\\mathbf{w}}:{\\mathcal S}\\times{\\mathcal A}\\rightarrow\\mathbb R|f_{\\mathbf{w}}(s,a)=$ $f(\\mathbf{w};\\boldsymbol{\\phi}(s,a))\\}$   \n2: for step $h=H,...,1$ do $n=1,...,N$ Sample fekl,y $\\{\\epsilon_{h}^{k,l,n}\\}_{l\\in[K(k)]}\\overset{\\mathrm{i.i.d}}{\\sim}\\mathcal{N}(0,\\sigma^{2})$ $\\xi_{h}^{k,n}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$   \n5: Solve $\\widetilde{\\mathbf{w}}_{m,h}^{k,n}$ according to (3.6).   \n6: end for   \n7: $\\begin{array}{r}{\\overbrace{Q_{m,h}^{k}}^{\\substack{\\frown}}\\leftarrow\\operatorname*{min}\\big\\{\\operatorname*{max}_{n\\in[N]}f\\big(\\widetilde{\\mathbf{w}}_{m,h}^{k,n};\\boldsymbol{\\phi}\\big),H-h+1\\big\\}^{+}.}\\end{array}$   \n8: $V_{m,h}^{k}(\\cdot)\\gets\\operatorname*{max}_{a\\in\\mathcal{A}}Q_{m,h}^{k}(\\cdot,a)$   \n9: end for   \n10: Output: $\\{Q_{m,h}^{k}(\\cdot,\\cdot),V_{m,h}^{k}(\\cdot,\\cdot)\\}_{h=1}^{H}$ ", "page_idx": 5}, {"type": "text", "text": "Langevin Monte Carlo Exploration Next we introduce the Langevin Monte Carlo exploration strategy [83, 33] in Algorithm 3, which stems from the Langevin dynamics [67, 8, 19, 81, 96]. Combining it with Algorithm 1 leads to our second proposed algorithm, CoopTS-LMC. Specifically, we update the model parameter iteratively. For iterate $j=1,\\ldots,J_{k}$ , the update is given by ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{w}_{m,h}^{k,j,n}=\\mathbf{w}_{m,h}^{k,j-1,n}-\\eta_{m,k}\\nabla L_{m,h}^{k}\\big(\\mathbf{w}_{m,h}^{k,j-1,n}\\big)+\\sqrt{2\\eta_{m,k}\\beta_{m,k}^{-1}}\\epsilon_{m,h}^{k,j,n},}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where $L_{m,h}^{k}$ is defned in 3.4), k,n E Rd is a standard Gaussian noise, Im, s the learning rate, and $\\beta_{m,k}$ is the inverse temperature parameter. We similarly use the multi-sampling trick to obtain $N$ independent estimators and estimate $Q$ function $Q_{m,h}^{k}$ by truncation based on Line 10 in Algorithm 3. ", "page_idx": 5}, {"type": "text", "text": "Algorithm 3 Langevin Monte Carlo Exploration ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "1: Input: multi-sampling number $\\begin{array}{r l r}{N}&{{}\\in}&{\\mathbb{N}^{+}}\\end{array}$ , function class $\\mathcal{F}~=~\\{f_{\\mathrm{w}}~:~\\mathcal{S}~\\times~\\mathcal{A}~\\rightarrow$   \n$\\mathbb{R}\\bar{|}f_{\\mathbf{w}}(s,a)\\,=\\,f(\\bar{\\mathbf{w}};\\bar{\\phi(s,a)})\\}$ , step sizes $\\{\\eta_{m,k}\\}_{m\\in\\mathcal{M},k\\in[K]}$ , inverse temperature parameters   \n[Bm,kmeM,ke[K].   \n2: for step $h=H,...,1$ do   \n3: for $n=1,...,N$ do   \n4: $\\mathbf{w}_{m,h}^{k,0,n}=\\mathbf{w}_{m,h}^{k-1,J_{k-1},n}$   \n5: for $j=1,...,J_{k}$ do   \n6: Sample ek,j,n id $\\epsilon_{m,h}^{k,j,n}\\overset{\\mathrm{i.i.d}}{\\sim}\\mathcal{N}(\\mathbf{0},\\mathbf{I})$   \n7: Update wm,h by (3.7).   \n8: end for   \n910 $\\begin{array}{r}{Q_{m,h}^{k}\\leftarrow\\operatorname*{min}\\big\\{\\operatorname*{max}_{n\\in[N]}f\\big(\\mathbf{w}_{m,h}^{k,J_{k},n};\\boldsymbol{\\phi}\\big),H-h+1\\big\\}^{+}.}\\end{array}$   \n11: $V_{m,h}^{k}(\\cdot)\\leftarrow\\operatorname*{max}_{a\\in A}Q_{m,h}^{k}(\\cdot,a)$   \n12: end for   \n13: Output: $\\{Q_{m,h}^{k}(\\cdot,\\cdot),V_{m,h}^{k}(\\cdot,\\cdot)\\}_{h=1}^{H}$ ", "page_idx": 5}, {"type": "text", "text": "4  Theoretical Analysis ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "4.1   Homogeneous Parallel Linear MDPs ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "We provide theoretical analyses of our algorithms in the linear structure under the assumption of linear function approximation and linear MDP setting. We first present the definition of linear MDPs. ", "page_idx": 5}, {"type": "text", "text": "Definition 4.1 (Linear MDP [36]). An $\\mathrm{MDP}(\\mathcal{S},\\mathcal{A},H,\\mathbb{P},r)$ is a linear MDP with feature map $\\phi:S\\times A\\rightarrow\\mathbb{R}^{d}$ , if for any $h\\in[H]$ , there exist $d$ unknown measures $\\pmb{\\mu}_{h}=(\\mu_{h}^{1},...,\\mu_{h}^{d})$ over $\\boldsymbol{S}$ and an unknown vector $\\pmb{\\theta}_{h}\\in\\mathbb{R}^{d}$ such that for any $(s,a)\\in S\\times A$ ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathbb{P}_{h}(\\cdot|s,a)=\\bigl\\langle\\phi(s,a),\\mu_{h}(\\cdot)\\bigr\\rangle,\\quad r_{h}(s,a)=\\bigl\\langle\\phi(s,a),\\pmb{\\theta}_{h}\\bigr\\rangle.\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Without loss of generality, we assume that for all $(s,a)\\;\\;\\in\\;\\;{\\cal S}\\;\\times\\;{\\cal A},$ $\\|\\phi(s,a)\\|~\\leq~1$ and $\\operatorname*{max}\\{\\|\\pmb{\\mu}_{h}(S)\\|,\\|\\pmb{\\theta}_{h}\\|\\}\\leq\\sqrt{d}.$ ", "page_idx": 6}, {"type": "text", "text": "Throughout the analyses in this section, we assume the homogeneous parallel MDPs setting where all agents share the same linear MDP defined in Definition 4.1. We also provide the results when the MDPs across agents are approximately linear and heterogeneous, which is deferred to Section 4.2 due to the space limit. Under the linear MDP assumption, it is known that the $Q$ -function admits a linear form [36, Proposition 2.3]. Consequently, we choose the loss function $L$ in (3.4) to be the $l_{2}$ loss and approximate the $Q$ function in the linear function class $f(\\mathbf{w};\\boldsymbol{\\phi}^{l})=\\mathbf{w}^{\\top}\\boldsymbol{\\phi}^{l}$ ", "page_idx": 6}, {"type": "text", "text": "Now we first present the regret bound for CoopTS-PHE ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.2. Under Definition 4.1, choose $L$ to be $l_{2}$ loss and linear function class $f(\\mathbf{w};\\boldsymbol{\\phi}^{l})=$ $\\mathbf{w}^{\\top}\\boldsymbol\\phi^{l}$ in (3.4). In CoopTS-PHE (Algorithm $1+$ Algorithm 2), let $N\\,=\\,\\widetilde{C}\\log(\\delta)/\\log(\\dot{c}_{0})$ where $\\widetilde{C}=\\widetilde{O}(d)$ and $c_{0}=\\Phi(1)$ \uff0c $\\Phi(\\cdot)$ is the cumulative distribution function (CDF) of the standard normal distribution. Let $\\lambda=1$ and $0<\\delta<1$ Under the determinant synchronization condition (3.3), we obtain the following cumulative regret ", "page_idx": 6}, {"type": "equation", "text": "$$\n{\\mathrm{Regret}}(K)=\\widetilde{\\mathcal{O}}\\big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)\\big),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with probability at least $1-\\delta$ ", "page_idx": 6}, {"type": "text", "text": "Remark 4.3. When we choose $\\gamma\\,=\\,\\mathcal{O}(K/d M)$ in the synchronization condition (3.3), the cumulative regret of CoopTS-PHE becomes $\\widetilde{\\cal O}(d^{3/2}H^{2}\\sqrt{M K})$ , which matches the result of UCB exploration [24]. When $M=1$ , the regret becomes $\\widetilde{\\cal O}(d^{3/2}H^{2}\\sqrt{K})$ , which matches the existing best randomized single-agent result [32, 33]. Note that if there is no communication at all and agents act independently, with the same number of learning rounds (or samples), the cumulative regret becomes $\\tilde{\\mathcal{O}}(\\dot{M}\\!\\cdot\\!d^{3/2}\\dot{H}^{2}\\sqrt{K})$ . By incorporating communication, our regret bound in Theorem 4.2 is lower than that of the independent seting by a factor $\\sqrt{M}$ . A similar strategy called rare-switching update with a determinant synchronization condition has also been adopted in parallel bandit problems [69, 15]. ", "page_idx": 6}, {"type": "text", "text": "Similarly, we have the following result for CoopTS-LMC. ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.4. Under Definition 4.1, choose $L$ to be $l_{2}$ loss and linear function class $f(\\mathbf{w};\\boldsymbol{\\phi}^{l})=$ $\\mathbf{w}^{\\top}\\boldsymbol\\phi^{l}$ in (3.4). In CoopTS-LMC (Algorithm $1+$ Algorithm 3), let $N=\\bar{C}\\log(\\delta)/\\log(\\bar{c}_{0}^{\\prime})$ where $c_{0}^{\\prime}=1\\,{-}\\,1/2\\sqrt{2e\\pi}$ and $\\bar{C}=\\widetilde{\\mathcal{O}}(d)$ . Let $1/\\sqrt{\\beta_{m,k}}=\\widetilde{\\mathcal{O}}\\big(H\\sqrt{d}\\big)$ for all $m\\in\\mathcal{M}$ \uff0c $\\lambda=1$ , and $0<\\delta<$ 1. For any episode $k\\in[K]$ and agent $m\\in\\mathcal{M}$ , let the learning rate $\\eta_{m,k}=1/\\bigl(4\\lambda_{\\operatorname*{max}}\\bigl(\\mathbf{A}_{m,h}^{k}\\bigr)\\bigr)$ , the update number $J_{k}=2\\kappa_{k}\\log(4H K M d)$ where $\\kappa_{k}=\\lambda_{\\mathrm{max}}\\big(\\mathbf{\\Lambda}_{m,h}^{k}\\big)/\\lambda_{\\mathrm{min}}\\big(\\mathbf{\\Lambda}_{m,h}^{k}\\big)$ is the condition number of ${\\pmb{\\Lambda}}_{m,h}^{k}$ . Under the determinant synchronization condition (3.3), we have ", "page_idx": 6}, {"type": "equation", "text": "$$\n{\\mathrm{Regret}}(K)=\\widetilde{\\mathcal{O}}\\big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)\\big),\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "with probability at least $1-\\delta$ ", "page_idx": 6}, {"type": "text", "text": "Remark 4.5. Note that CoopTS-PHE and CoopTS-LMC have the same order of regret. Hence the discussion in Remark 4.3 also applies to CoopTS-LMC. We would also like to highlight that our results are the first rigorous regret bounds for randomized MARL algorithms. ", "page_idx": 6}, {"type": "text", "text": "From the perspective of technical novelty, our analysis of randomized MARL algorithms is different from that of UCB-based algorithms [24] because the model prediction error here contains randomness, causing a more complex probability analysis and an additional approximation error. We would also like to point out that in proofs for both CoopTS-LMC and CoopTS-PHE we use a new $\\varepsilon$ -covering technique to prove that the optimism lemma holds for all $(s,a)\\in S\\!\\times\\!A$ instead of just the state-action pairs encountered by the algorithm, which is essential for the regret analysis. This was ignored by previous works [13] and its follow-up works [93, 33] that use the same regret decomposition technique. Furthermore, the multi-agent setting and the communications from synchronization in our algorithms also significantly increase the challenges in our analysis compared to randomized exploration in the single-agent setting [32, 33]. ", "page_idx": 6}, {"type": "text", "text": "Next we present the communication complexity of Algorithm 1 with synchronization condition (3.3). ", "page_idx": 7}, {"type": "text", "text": "Lemma 4.6. The total number of communication rounds between the agents and the server in Algorithm 1 is bounded by $\\mathrm{CPX}=\\widetilde{\\mathcal{O}}((d+K/\\gamma)M H)$ . Moreover, the total number of transferred random bits only has a logarithmic dependence on the number of episodes $K$ ", "page_idx": 7}, {"type": "text", "text": "Remark 4.7. We provide a refined analysis in Appendix C to get this improved result based on that of [24], which studied the same communication procedure as ours. When we choose $\\gamma=\\mathcal{O}(K/d M)$ the communication complexity reduces to $\\widetilde{\\cal O}(d H M^{2})$ , which only has a logarithmic dependence on the number of episodes $K$ . Additionally, we provide a rigorous analysis to show that the algorithm only needs to communicate logarithm number of random bits throughout the learning process. ", "page_idx": 7}, {"type": "text", "text": "Note that Min et al. [56] studied the asynchronous setting where only one agent is active in each episode, giving out the regret $\\widetilde{\\mathcal{O}}(d^{3/2}H^{\\dot{2}}\\sqrt{K})$ with the communication complexity $\\widetilde{\\cal O}(d H M^{2})$ .Itis interesting to see that our algorithm, though in the synchronous setting, has the same communication complexity as the asynchronous variant. This implies that the asynchronous algorithm can only circumvent current communication by delaying it to the future but does not decrease the communication complexity. In fact, the synchronous setting can learn the policy better in our work, which is indicated by comparison of the average regret (the cumulative regret divided by the total number of samples used by the algorithm) in Table 1. By achieving a matched communication complexity, we find that synchronous and asynchronous settings have their own advantages and cannot replace each other. This phenomenon can help us better understand the properties of these two communication schemes. ", "page_idx": 7}, {"type": "text", "text": "4.2  Misspecifed Setting ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this part, we extend our theoretical analysis to the misspecified setting. In this setting, the transition functions $\\mathbb{P}_{m,h}$ and the reward functions $r_{m,h}$ are heterogeneous across different MDPs, which is slightly more complicated than the homogeneous setting. Moreover, instead of assuming the transition and reward are linear, we only require each individual MDP is a $\\zeta$ -approximate linear MDP [36] where both the transition and reward are approximately linear up to an controlled error $\\zeta$ ", "page_idx": 7}, {"type": "text", "text": "Definition 4.8 (Misspecified Parallel MDPs). For any $0\\,<\\,\\zeta\\,\\leq\\,1$ , and for any agent $m\\,\\in\\,{\\mathcal{M}}$ the corresponding $\\mathrm{MDP}(S,\\mathcal{A},H,\\mathbb{P}_{m},r_{m})$ is a $\\zeta$ -approximate linear MDP with a feature map $\\phi:S\\times A\\rightarrow\\mathbb{R}^{d}$ for any $h\\in[H]$ $d$ unknow sigedmeasures $\\pmb{\\mu}_{h}=(\\mu_{h}^{(1)},\\dots,\\mu_{h}^{(d)})$ over $\\boldsymbol{S}$ and an unknown vector $\\pmb{\\theta}_{h}\\in\\mathbb{R}^{d}$ such that for any $(s,a)\\in S\\times A$ , we have ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\mathbb{P}_{m,h}(\\cdot\\mid s,a)-\\left\\langle\\phi(s,a),\\pmb{\\mu}_{h}(\\cdot)\\right\\rangle\\right\\|_{\\mathrm{TV}}\\leq\\zeta,}\\\\ {\\left|r_{m,h}(s,a)-\\left\\langle\\phi(s,a),\\pmb{\\theta}_{h}\\right\\rangle\\right|\\leq\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $\\Vert\\cdot\\Vert_{\\mathrm{TV}}$ is the total variation norm, for two distributions $P_{1}$ and $P_{2}$ , we define it as: $\\|P_{1}-$ $\\begin{array}{r}{P_{2}\\|_{\\mathrm{TV}}\\stackrel{!}{=}\\frac{1}{2}\\sum_{\\mathbf{x}\\in\\Omega}|P_{1}(\\mathbf{x})-P_{2}(\\mathbf{x})|}\\end{array}$ Without loss of generality, we assume that $\\|\\phi(s,a)\\|\\leq1$ for all $(s,a)\\in S\\times A$ , and max $\\big\\{\\|\\mu_{h}(S)\\|,\\|\\pmb{\\theta}_{h}\\|\\big\\}\\leq\\sqrt{d}$ for all $h\\in[H]$ and $m\\in\\mathcal{M}$ ", "page_idx": 7}, {"type": "text", "text": "Remark 4.9. Note that our misspecified setting defined in Definition 4.8 is a generalized notion of misspecification in [36]. Moreover, our misspecified setting is also more general and cover the small heterogeneous setting mentioned in [24]. The triangle inequality can easily be used to derive small heterogeneous setting from our misspecified setting, but not vice versa. ", "page_idx": 7}, {"type": "text", "text": "Next we state our regret bound for CoopTS-PHE in the misspecified setting. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.10 (Misspecified Regret Bound for CoopTS-PHE). In CoopTS-PHE (Algorithm $1+\\mathrm{Al}$ gorithm 2), under Definition 4.8 and determinant synchronization condition (3.3), with the same initialization with Theorem 4.2, we obtain the following cumulative regret ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathrm{Regret}(K)=\\tilde{\\mathcal{O}}\\Big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)+d H^{2}M\\sqrt{K}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)\\zeta\\Big),\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "with probability at least $1-\\delta$ ", "page_idx": 7}, {"type": "text", "text": "Remark 4.11. When  we_choose $\\begin{array}{r l r}{\\zeta}&{{}=}&{{\\mathcal O}\\big(\\sqrt{d/M K}\\big)}\\end{array}$ , the cumulative regret becomes $\\widetilde{\\mathcal{O}}\\big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)\\big)$ . This matches the result of Theorem 4.2 in the linear MDP setting. ", "page_idx": 7}, {"type": "text", "text": "Similarly, we can have the following result for CoopTS-LMC. ", "page_idx": 7}, {"type": "text", "text": "Theorem 4.12 (Misspecified Regret Bound for CoopTS-LMC). In CoopTS-LMC (Algorithm $1+\\mathrm{Al}$ gorithm 3), under Definition 4.8 and determinant synchronization condition (3.3), with the same initialization with Theorem 4.4 except that $1/\\sqrt{\\beta_{m,k}}=\\widetilde{\\mathcal{O}}\\big(H\\sqrt{d}+H\\sqrt{M K d}\\zeta\\big)$ ,weobtain the following cumulative regret ", "page_idx": 8}, {"type": "equation", "text": "$$\n\\mathrm{Regret}(K)=\\widetilde{\\mathcal{O}}\\Big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)+d^{\\frac{3}{2}}H^{2}M\\sqrt{K}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)\\zeta\\Big),\n$$", "text_format": "latex", "page_idx": 8}, {"type": "text", "text": "with probability at least $1-\\delta$ ", "page_idx": 8}, {"type": "text", "text": "Remark 4.13. When $\\zeta=\\mathcal{O}\\big(\\sqrt{1/M K}\\big)$ , the cumulative regret becomes $\\widetilde{\\cal O}\\big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+$ $\\sqrt{K})$ ). This matches the result of Theorem 4.4 in the linear MDP setting. By comparing Theorems 4.10 and 4.12, we find the result of CoopTS-LMC has an extra $\\sqrt{d}$ factor worse than that of CoopTS-PHE, causing the chosen $\\zeta$ in CoopTS-PHE has an extra $\\sqrt{d}$ order over that in CoopTS-LMC. This indicates that CoopTS-PHE has better performance tolerance for the misspecified seting. ", "page_idx": 8}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this section, we present an empirical evaluation of our proposed randomized exploration strategies (i.e., CoopTS-PHE and CoopTS-LMC) with deep $Q$ -networks (DQNs) [57] as the core algorithm on varying tasks under multi-agent settings compared with several baselines: vanilla DQN, Double DQN [28], Bootstrapped DQN [62], and Noisy-Net [26]). Given that all experiments are conducted under multi-agent settings unless explicitly specified as a single-agent or centralized scenario, we denote CoopTS-PHE as \"PHE\" and CoopTS-LMC as \"LMC\" in both experimental contexts and figures. Note that we run all our experiments on Nvidia RTX A5000 with 24GB RAM. The implementation of this work can be found at https://github.com/panxulab/MARL-CoopTS ", "page_idx": 8}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/6897ad85fc9879a6a59ca9f3f6b1d30d963dd26be75be2c5e69929226dc2af6e.jpg", "img_caption": ["Figure 1: Comparison among different exploration strategies in different environments. (a)-(b): $N$ -chainwith $N=25$ . (c)-(d): Super Mario Bros. All results are averaged over 10 runs and the shaded area represents the standard deviation. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.1 $N$ -chain ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "The $N$ -chain [62] comprises a sequence of $N$ states denoted as $\\{s_{l}\\}_{l=1}^{N}$ Assuming the existence of $m$ agents, all initiating their trajectories from $s_{2}$ , this study explores the dynamics of their movement within the chain. At each time step, agents face the decision to move either left or right. Notably, each agent incurs a nominal reward of $r=0.001$ upon reaching state $s_{1}$ , while a more substantial reward of $r=1$ is obtained upon reaching the terminal state $s_{N}$ . The illustration of $N$ -chain environment is shown in Appendix K.1. With a horizon length of $N+9$ the optimal return is 10. We consider $N=25$ with the communication among agents in Figure 1 following the synchronization approach in Algorithm 1. In Figure 1(a), we show that PHE and Bootstrapped DQN result in higher average episode return among all agents while LMC can also eventually converge to a similar reward. ", "page_idx": 8}, {"type": "text", "text": "Upon increasing the number of agents to $m\\,=\\,3$ , we show in Figure 1(b) that our randomized exploration methods outperform all other baselines. Notably, the fuctuation in PHE is observed to be less pronounced against LMC. This observation lends support to our theoretical framework regarding performance tolerance in the misspecified setting, as detailed in Section 4.2. The complete results for $N$ -chain and ablation studies can be found in Appendix K.1. ", "page_idx": 8}, {"type": "text", "text": "5.2 Super Mario Bros ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "Environmental heterogeneity, arising from various sources, is a prevalent challenge in practical scenarios. In Section 4.2, we illustrate the extension of homogeneous parallel MDP to the misspecified setting. In the Super Mario Bros task [74], we examine a scenario where four agents, denoted as $m=4$ , engage in learning within distinct environments. Despite these environments sharing the samestatespace $\\boldsymbol{S}$ ,actionspace $\\boldsymbol{\\mathcal{A}}$ , and reward function, their characteristics are different described in Appendix K.2. The primary objective of the Super Mario Bros task is to train an agent capable of advancing as far-right and rapidly as possible without collisions or falls. Utilizing preprocessed images as input states, agents aim to select optimal actions from a set of 7 discrete actions. ", "page_idx": 8}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Figure 1(c) visually depicts that both randomized exploration strategies outperform other baselines in cooperative parallel learning. Notably, We observe that the superiority of LMC gets significant against PHE unlike the results in $N$ -chain in Figures 1(a) and 1(b). In the case of PHE, Gaussian noise is introduced to the reward before applying the Bellman update, which can be viewed as a method empirically approximating the posterior distribution of the $Q$ function using a Gaussian distribution. However, it is crucial to note that in practical scenarios, unlike the $N$ -chain setting, Gaussian distributions may not always provide an accurate approximation of the true posterior of the $Q$ function [33]. Here, transitions are shared among the four agents whenever the synchronization condition in (3.3) is met. We also conducted extra experiments in this task extending our proposed method to federated learning shown in Figure 1(d) with details in Appendix K.2. ", "page_idx": 9}, {"type": "text", "text": "5.3  Thermal Control of Building Energy Systems ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "Finally, we assess the efficacy of our randomized exploration strategies through their application to a practical task within a sustainable energy system: BuildingEnv, as outlined in [85]. BuildingEnv is designed to manage the heating supply in a multi-zone building, which involves addressing realworld physical constraints and accounting for environmental shifts over time. The objective is to meet user-defined temperature specifications while simultaneously minimizing overall electricity consumption. We defer the environment details to Appendix K.3. ", "page_idx": 9}, {"type": "text", "text": "With the availability of different cities in varying weather types, we conduct experiments on multiple cities in parallel and share their data following Algorithm 1 for each exploration strategy. During the evaluation, we deploy those trained policies to the environment of each city/weather respectively. We include all methods as well as random action in Figure 2 for a fair comparison. Specifically, we sample action randomly from action space for random action. We display the distribution of the return with probability density in violin plots, indicating that our PHE and LMC can perform better with a higher mean. Additional results for other cities can be found in Appendix K.3. ", "page_idx": 9}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/14bb7bde528b22e53869baf8549ffe5ef9caeddd4cf363b228348b5229991dc3.jpg", "img_caption": ["Figure 2: Evaluation performance at Tampa (hot humid) in building energy systems. All results are averaged over 10 runs. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "6 Conclusion ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "We proposed a unified algorithm framework for provably efficient randomized exploration in parallel MDPs. By combining this unified algorithm framework with two TS-type randomized exploration strategies, PHE and LMC, we obtained two algorithms for parallel MDPs: CoopTS-PHE and CoopTSLMC. These two algorithms are both flexible in design and easy to implement in practice. Under the linear MDP setting, we derived the theoretical regret bounds and communication complexities of CoopTS-PHE and CoopTS-LMC. This is the first result for randomized exploration in cooperative MARL, matching the best existing regret bounds for single-agent RL [32, 33]. We also extended our theoretical analysis to the misspecified setting. Our experiments on diverse RL parallel environments verified that randomized exploration improves the balance between exploration and exploitation in both homogeneous and heterogeneous settings. Future research directions includes extending our randomized exploration algorithm to fully decentralized or federated learning settings. Additionally, developing a more communication-efficient algorithm to reduce the substantial communication costs in the general function class setting is another potential direction. ", "page_idx": 9}, {"type": "text", "text": "Acknowledgments ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "We would like to thank the anonymous reviewers for their helpful comments. HH and MP were supported in part by the ONR under agreement N00014-23-1-2206, AFOSR under the award number FA9550-19-1-0169, and by the NSF under NAIAD Award 2332744 as well as the National AI Institute for Edge Computing Leveraging Next Generation Wireless Networks, Grant CNS-2112562. WW and PX were supported in part by the National Science Foundation (DMS-2323112) and the Whitehead Scholars Program at the Duke University School of Medicine. The views and conclusions in this paper are those of the authors and should not be interpreted as representing any funding agency. ", "page_idx": 10}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "[1]  Y. Abbasi-Yadkori, D. Pal, and C. Szepesvari. Improved algorithms for linear stochastic bandits. Advances in neural information processing systems, 24, 2011. 1, 56, 57   \n[2]  M. Abeille and A. Lazaric. Linear thompson sampling revisited. In Artifcial Intelligence and Statistics, pages 176-184. PMLR, 2017. 18   \n[3]  M. Abramowitz and I. A. Stegun. Handbook of mathematical functions with formulas, graphs, and mathematical tables, volume 55. US Government printing office, 1968. 57   \n[4]  P. Agrawal, J. Chen, and N. Jiang. Improved worst-case regret bounds for randomized leastsquares value iteration. In Proceedings of the AAAl Conference on Artificial Intelligence, volume 35, pages 6566-6573, 2021. 17   \n[5]  S. Agrawal and N. Goyal. Thompson sampling for contextual bandits with linear payoffs. In International Conference on Machine Learning, pages 127-135, 2013. 60   \n[6]  S. Agrawal and N. Goyal. Thompson sampling for contextual bandits with linear payoffs. In International conference on machine learning, pages 127-135. PMLR, 2013. 18   \n[7]  S. Agrawal and R. Jia. Optimistic posterior sampling for reinforcement learning: worst-case regret bounds. In Advances in Neural Information Processing Systems, volume 30, pages 1184-1194, 2017. 2,17   \n[8]  D. Bakry, I. Gentil, M. Ledoux, et al. Analysis and geometry of Markov diffusion operators, volume 103. Springer, 2014. 6   \n[9] N. A. Bakshi, T. Gupta, R. Ghods, and J. Schneider. Guts: Generalized uncertainty-aware thompson sampling for multi-agent active search. In IEEE International Conference on Robotics and Automation (ICRA), pages 7735-7741. IEEE, 2023. 17   \n[10]  A. L. Bazzan. Opportunities for multiagent systems and multiagent reinforcement learning in traffic control. Autonomous Agents and Multi-Agent Systems, 18:342-375, 2009. 1   \n[11]  D. S. Bernstein, R. Givan, N. Immerman, and S. Zilberstein. The complexity of decentralized control of markov decision processes. Mathematics of Operations Research, 27(4):819-840, 2002.17   \n[12]  C. Boutilier. Planning, learning and coordination in multiagent decision processes. In Theoretical Aspects of Rationality and Knowledge, 1996. 17   \n[13] Q. Cai, Z. Yang, C. Jin, and Z. Wang. Provably efficient exploration in policy optimization. In International Conference on Machine Learning, pages 1283-1294. PMLR, 2020. 7, 22   \n[14] G. Chalkiadakis and C. Boutilier. Coordination in multiagent reinforcement learning: A bayesian approach. In Proceedings of the second international joint conference on Autonomous agents and multiagent systems, pages 709-716, 2003. 1   \n[15] J. Chan, A. Pacchiano, N. Tripuraneni, Y.S. Song, P Bartlet, and M. I. Jordan. Parallelizing contextual bandits. arXiv preprint arXiv:2105.10590, 2021. 7   \n[16]  O. Chapelle and L. Li. An empirical evaluation of thompson sampling. Advances in neural information processing systems, 24, 2011. 5, 18   \n[17] Y. Chen, P. Dong, Q. Bai, M. Dimakopoulou, W. Xu, and Z. Zhou. Society of agents: Regret bounds of concurrent thompson sampling. Advances in Neural Information Processing Systems, pages 7587-7598, 2022. 17   \n[18]  W. Chu, L. Li, L. Reyzin, and R. Schapire. Contextual bandits with linear payoff functions. In Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics, pages 208-214. JMLR Workshop and Conference Proceedings, 2011. 1, 2   \n[19]  A. S. Dalalyan. Theoretical guarantees for approximate sampling from smooth and log-concave densities. Journal of the Royal Statistical Society Series B: Statistical Methodology, 79(3): 651-676,2017.6   \n[20] C. Dann, M. Mohri, T. Zhang, and J. Zimmert. A provably efficient model-free posterior sampling method for episodic reinforcement learning. Advances in neural information processing systems, 34, 2021. 17   \n[21]  M. Dimakopoulou and B. V. Roy. Coordinated exploration in concurrent reinforcement learning. Proceedings of the 35th International Conference on Machine Learning, pages 1271-1279, 2018.17   \n[22]  M. Dimakopoulou, I. Osband, and B. V. Roy. Scalable coordinated exploration in concurrent reinforcement learning. Advances in Neural Information Processing Systems, pages 4219-4227, 2018. 17   \n[23] G. Ding, J. J. Koh, K. Merckaert, B. Vanderborght, M. M. Nicotra, C. Heckman, A. Roncone, and L. Chen. Distributed reinforcement learning for cooperative multi-robot object manipulation. In Proceedings of the 2020 International Conference on Autonomous Agents and Multiagent Systems, AAMAS, pages 1831-1833. ACM, 2020. 1   \n[24] A. Dubey and A. Pentland. Provably efficient cooperative multi-agent reinforcement learning with function approximation. arXiv preprint arXiv:2103.04972, 2021. 1, 3, 5, 7, 8, 17, 19, 22   \n[25]  Y. Fei and R. Xu. Cascaded gaps: Towards logarithmic regret for risk-sensitive reinforcement learning. In International Conference on Machine Learning, pages 6392-6417. PMLR, 2022. 1   \n[26] M. Fortunato, M. G. Azar, B. Piot, et al. Noisy networks for exploration. In International Conference on Learning Representations, 2018. 9, 17, 58   \n[27] J. Hao, T. Yang, H. Tang, C. Bai, J. Liu, Z. Meng, P. Liu, and Z. Wang. Exploration in deep reinforcement learning: From single-agent to multiagent domain. IEEE Transactions on Neural Networks and Learning Systems, 2023. 1   \n[28] H. V. Hasselt, A. Guez, and D. Silver. Deep reinforcement learning with double qlearning. In Annual AAAI Conference on Artificial Intelligence (AAAI), 2016. 9, 58   \n[29] E. Hillel, Z. S. Karnin, T. Koren, R. Lempel, and O. Somekh. Distributed exploration in multi-armed bandits. Advances in Neural Information Processing Systems, 26, 2013. 17   \n[30] R. A. Horn and C. R. Johnson. Matrix analysis. Cambridge university press, 2012. 56   \n[31]  T. Huix, M. Zhang, and A. Durmus. Tight regret and complexity bounds for thompson sampling via langevin monte carlo. In F. Ruiz, J. Dy, and J.-W. van de Meent, editors, Proceedings of The 26th International Conference on Artificial Intelligence and Statistics, volume 206 of Proceedings of Machine Learning Research, pages 8749-8770. PMLR, 25-27 Apr 2023. URL https://proceedings.mlr.press/v206/huix23a.html. 2   \n[32] H. Ishfaq, Q. Cui, V. Nguyen, A. Ayoub, Z. Yang, Z. Wang, D. Precup, and L. Yang. Randomized exploration in reinforcement learning with general value function approximation. In International Conference on Machine Learning, pages 4607-4616. PMLR, 2021. 2, 3, 5, 6, 7, 10, 17, 56, 57   \n[33] H. Ishfaq, Q. Lan, P. Xu, A. R. Mahmood, D. Precup, A. Anandkumar, and K. Azizzadenesheli. Provable and practical: Efficient exploration in reinforcement learning via langevin monte carlo. In The Twelfth International Conference on Learning Representations, 2024. URL https: //openreview.net/forum?id=nfIAEJFiBZ. 2,3, 6, 7, 10, 17,22,56, 59 [34] H. Ishfaq, Y. Tan, Y. Yang, Q. Lan, J. Lu, A. R. Mahmood, D. Precup, and P. Xu. More effcient randomized exploration for reinforcement learning via approximate sampling. Reinforcement Learning Journal, 3:1211-1235, 2024. 2, 3 [35] M. Jafarnia-Jahromi, R. Jain, and A. Nayyar. A bayesian learning algorithm for unknown zero-sum stochastic games with an arbitrary opponent. In International Conference on Artificial Intelligence and Statistics, pages 3880-3888. PMLR, 2024. 17 [36] C. Jin, Z. Yang, Z. Wang, and M. 1. Jordan. Provably effcient reinforcement learning with linear function approximation. In Conference on Learning Theory, pages 2137-2143. PMLR,   \n2020.1,2,3,7,8,17,56 [37] H. Jin, Y. Peng, W. Yang, S. Wang, and Z. Zhang. Federated reinforcement learning with environment hterogeneityInInternationalConferenceonArtifcialInteligence and Statistis, pages 18-37. PMLR, 2022. 64 [38] T. Jin, P. Xu, J. Shi, X. Xiao, and Q. Gu. Mots: Minimax optimal thompson sampling. In International Conference on Machine Learning, pages 5074-5083. PMLR, 2021. 17 [39]  T. Jin, P. Xu, X. Xiao, and A. Anandkumar. Finite-time regret of thompson sampling algorithms for exponential family multi-armed bandits. Advances in Neural Information Processing Systems, 35:38475-38487, 2022. [40] T. Jin, X. Yang, X. Xiao, and P. Xu. Thompson sampling with less exploration is fast and optimal. In International Conference on Machine Learning, pages 15239-15261. PMLR, 2023.   \n17 [41]  T. Jin, H.-L. Hsu, W. Chang, and P. Xu. Finite-time frequentist regret bounds of multi-agent thompson sampling on sparse hypergraphs. In Annual AAAI Conference on Artificial Inteligence (AAAI), 2024. 17 [42]  A. Karbasi, N. L. Kuang, Y. Ma, and S. Mitra. Langevin thompson sampling with logarithmic communication: Bandits and reinforcement learning. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, editors, Proceedings of the 4Oth International Conference on Machine Learning, volume 202 of Proceedings of Machine Learning Research, pages 15828-15860. PMLR, 23-29 Jul 2023. URL https : //proceedings .mlr .press/ v202/karbasi23a.html. 2, 17 [43]  R. M. Kretchmar. Parallel reinforcement learning. In The 6th World Conference on Systemics, Cybernetics, and Informatics, 2002. 17 [44] N. Kuang, M. Yin, et al. Posterior sampling with delayed feedback for reinforcement learning with linear function approximation. Advances in neural information processing systems, 2023.   \n17 [45]  B. Kveton, C. Szepesvari, M. Ghavamzadeh, and C. Boutilier. Perturbed-history exploration in stochastic multi-armed bandits, 2019. 2, 5 [46] B. Kveton, M. Zaheer, C. Szepesvari, L. Li, M. Ghavamzadeh, and C. Boutilier. Randomized exploration in generalized linear bandits. InInternational Conference on Artifcial Intelligence and Statistics, pages 2066-2076. PMLR, 2020. 2, 18 [47] B. Kveton, M. Zaheer, C. Szepesvari, L. Li, M. Ghavamzadeh, and C. Boutilier. Randomized exploration in generalized linear bandits. In S. Chiappa and R. Calandra, editors, Proceedings oftheTwentyThirdIntrnationalConferencenArtifcialIntelienceandStatisticsvolume   \n108 of Proceedings of Machine Learning Research, pages 2066-2076. PMLR, 26-28 Aug 2020. URL https://proceedings.mlr.press/v108/kveton20a.html. 2, 5 [48] P. Landgren, V. Srivastava, and N. E. Leonard. On distributed cooperative decision-making in multiarmed bandits. In 2016 European Control Conference (ECC), pages 243-248. IEEE, 2016.   \n17   \n[49] L. Li, W. Chu, J. Langford, and R. E. Schapire. A contextual-bandit approach to personalized news article recommendation. In Proceedings of the 19th international conference on World wide web, pages 661-670, 2010. 60   \n[50] L. Li, Y. Lu, and D. Zhou. Provably optimal algorithms for generalized linear contextual bandits. In International Conference on Machine Learning, pages 2071-2080. PMLR, 2017. 1   \n[51]  T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith. Federated optimization inheterogeneus networks. In Proceedings of Machine Learning and Systems, volume 2, pages 429-450, 2020. 17   \n[52] Z. Li, Y. Li, Y. Zhang, T. Zhang, and Z.-Q. Luo. Hyperdqn: A randomized exploration method for deep reinforcement learning. In International Conference on Learning Representations, 2022.17   \n[53] J. Lidard, U. Madhushani, and N. E. Leonard. Provably efficient multi-agent reinforcement learning with fully decentralized communication. In 2022 American Control Conference (ACC), pages 3311-3316. IEEE, 2022. 17   \n[54] B. Liu, L. Wang, and M. Liu. Lifelong federated reinforcement learning: a learning architecture for navigation in cloud robotic systems. IEEE Robotics and Automation Letters, 4(4):4555-4562, 2019. 1   \n[55] Z. Liu, J. Zhang, Z. Liu, H. Du, Z. Wang, D. Niyato, M. Guizani, and B. Ai. Cell-free xl-mimo meets multi-agent reinforcement learning: Architectures, challenges, and future directions. IEEE Wireless Communications, 31(4):155-162, 2024. 1   \n[56] Y. Min, J. He, T. Wang, and Q. Gu. Cooperative multi-agent reinforcement learning: asynchronous communication and linear function approximation. In International Conference on Machine Learning, pages 24785-24811. PMLR, 2023. 1, 2, 3, 5, 8, 17   \n[57]  V. Mnih, K. Kavukcuoglu, D. Silver, et al. Human-level control through deep reinforcement learning. Nature, 518:529-533, 2015. 9, 58, 65   \n[58]  A. Mousavi-Hosseini, T. Farghly, Y. He, K. Balasubramanian, and M. A. Erdogdu. Towards a complete analysis of langevin monte carlo: Beyond poincare inequality, 2023. 2   \n[59]  T. Nguyen-Tang and R. Arora. On sample-efficient offine reinforcement learning: Data diversity, posterior sampling and beyond. Advances in neural information processing systems, 2023. 17   \n[60] 1. Osband and B. Van Roy. Why is posterior sampling better than optimism for reinforcement learning? In International conference on machine learning, pages 2701-2710. PMLR, 2017. 2, 5,17   \n[61] 1. Osband, D. Russo, and B. Van Roy. (more) effcient reinforcement learning via posterior sampling. Advances in Neural Information Processing Systems, 26, 2013. 2, 5, 17   \n[62] I. Osband, C. Blundell, A. Pritzel, and B. V. Roy. Deep exploration via bootstrapped dqn. Advances in neural information processing systems, 29, 2016. 9, 17, 58   \n[63] I. Osband, B. Van Roy, and Z. Wen. Generalization and exploration via randomized value functions. In International Conference on Machine Learning, pages 2377-2386. PMLR, 2016. 17   \n[64] I. Osband, J. Aslanides, and A. Cassirer. Randomized prior functions for deep reinforcement learning. Advances in neural information processing systems, 31, 2018. 17   \n[65] S. Qiu, Z. Dai, H. Zhong, Z. Wang, Z. Yang, and T. Zhang. Posterior sampling for competitive rl: Function approximation and partial observation. Advances in neural information processing systems, 2023. 17   \n[66] C. Riquelme, G. Tucker, and J. Snoek. Deep bayesian bandits showdown: An empirical comparison of bayesian deep networks for thompson sampling. In International Conference on Learning Representations, 2018. 2, 18   \n[67]  G. O. Roberts and R. L. Tweedie. Exponential convergence of langevin distributions and their discrete approximations. Bernoulli, pages 341-363, 1996. 6   \n[68]  C. Rojas-Cordova, A. J. Williamson, J. A. Pertuze, and G. Calvo. Why one strategy does not fit all: a systematic review on exploration-exploitation in different organizational archetypes. Review of Managerial Science, 17(7):2251-2295, 2023. 1   \n[69]  Y. Ruan, J. Yang, and Y. Zhou. Linear bandits with limited adaptivity and learning distributional optimal design. In Proceedings of the 53rd Annual ACM SIGACT Symposium on Theory of Computing, pages 74-87, 2021. 7   \n[70]  D. Russo. Worst-case regret bounds for exploration via randomized value functions. Advances in neural information processing systems, 32:14410-14420, 2019. 17   \n[71]  M. Strens. A bayesian framework for reinforcement larning. In International Conference on Machine Learning, pages 943-950. PMLR, 2000. 17   \n[72] M. E. Taylor and P. Stone. Transfer learning for reinforcement learning domains: A survey. Journal of Machine Learning Research, 10(56):1633-1685, 2009. 17   \n[73]  W. R. Thompson. On the likelihood that one unknown probability exceeds another in view of the evidence of two samples. Biometrika, 25(3-4):285-294, 1933. 2, 17   \n[74] J.-J. Tsay, C.-C. Chen, and J.-J. Hsu. Evolving intelligent mario controller by reinforcement learning. In International Conference on Technologies and Applications of Artificial Intelligence, pages 266-272, 2011. 1, 10   \n[75]  R. Vershynin. High-dimensional probability: An introduction with applications in data science, volume 47. Cambridge university press, 2018. 56   \n[76]  R. Wang, R. R. Salakhutdinov, and L. Yang. Reinforcement learning with general value function approximation: Provably effcient approach via bounded eluder dimension. Advances in Neural Information Processing Systems, 33:6123-6135, 2020. 1, 2   \n[77] Y. Wang, J. Hu, X. Chen, and L. Wang. Distributed bandit learning: Near-optimal regret with efcient communication. In International Conference on Learning Representations, 2020. 17   \n[78]  Z. Wang and M. Zhou. Thompson sampling via local uncertainty. In International Conference on Machine Learning, pages 10115-10125. PMLR, 2020. 17   \n[79] Q. Xie, Y. Chen, Z. Wang, and Z. Yang. Learning zero-sum simultaneous-move markov games using function approximation and correlated equilibrium. In Proceedings of Thirty Third Conference on Learning Theory, volume 125, pages 3674-3682. PMLR, 2020. 17   \n[80] W. Xiong, H. Zhong, C. Shi, C. Shen, and T. Zhang. A self-play posterior sampling algorithm for zero-sum markov games. In International Conference on Machine Learning, pages 24496- 24523. PMLR, 2022.17   \n[81] P. Xu, J. Chen, D. Zou, and Q. Gu. Global convergence of langevin dynamics based algorithms for nonconvex optimization. Advances in Neural Information Processing Systems, 31, 2018. 6   \n[82]  P. Xu, Z. Wen, H. Zhao, and Q. Gu. Neural contextual bandits with deep representation and shallow exploration. In International Conference on Learning Representations, 2021. 2   \n[83] P. Xu, H. Zheng, E. V. Mazumdar, K. Azizzadenesheli, and A. Anandkumar. Langevin monte carlo for contextual bandits. In International Conference on Machine Learning, pages 24830- 24850. PMLR, 2022. 2, 6,17, 18   \n[84] D. Ye, G. Chen, W. Zhang, S. Chen, B. Yuan, B. Liu, J. Chen, Z. Liu, F. Qiu, H. Yu, et al. Towards playing full moba games with deep reinforcement learning. Advances in Neural Information Processing Systems, 33:621-632, 2020. 1   \n[85] C. Yeh, V. Li, R. Datta, J. Arroyo, N. Christianson, C. Zhang, Y. Chen, M. Hosseini, A. Golmohammadi, Y. Shi, Y. Yue, and A. Wierman. Sustaingym: A benchmark suite of reinforcement learning for sustainability applications. In Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track. PMLR, 2023. 1, 10, 65, 66   \n[86]  C. Yu, A. Velu, E. Vinitsky, J. Gao, Y. Wang, A. Bayen, and Y. Wu. The surprising effectiveness of PPO in cooperative multi-agent games. In Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track, 2022. 17   \n[87] C. Yu, X. Yang, J. Gao, J. Chen, Y. Li, J. Liu, Y. Xiang, R. Huang, H. Yang, Y. Wu, and Y. Wang. Asynchronous multi-agent reinforcement learning for efficient real-time multi-robot cooperative exploration. In Proceedings of the 2023 International Conference on Autonomous Agents and Multiagent Systems, AAMAS, pages 1107-1115. ACM, 2023. 17   \n[88] A. Zanette, D. Brandfonbrener, E. Brunskill, M. Pirotta, and A. Lazaric. Frequentist regret bounds for randomized least-squares value iteration. In International Conference on Artificial Intelligence and Statistics, pages 1954-1964. PMLR, 2020. 3, 17   \n[89]  K. Zhang, Z. Yang, H. Liu, T. Zhang, and T. Basar. Fully decentralized multi-agent reinforcement learning with networked agents. In International Conference on Machine Learning, volume 80, pages 5872-5881. PMLR, 2018. 17   \n[90]  W. Zhang, D. Zhou, L. Li, and Q. Gu. Neural thompson sampling. In International Conference on Learning Representations, 2021. 60   \n[91] Y. Zhang, G. Qu, P. Xu, Y. Lin, Z. Chen, and A. Wierman. Global convergence of localized policy iteration in networked multi-agent reinforcement learning. Proceedings of the ACM on Measurement and Analysis of Computing Systems, 7(1):1-51, 2023. 17   \n[92] Y. Zhao, I. Borovikov, J. Rupert, C. Somers, and A. Beirami. On multi-agent learning in team sports games. arXiv preprint arXiv:1906.10124, 2019. 1   \n[93]  H. Zhong and T. Zhang. A theoretical analysis of optimistic proximal policy optimization in linear markov decision processes. Advances in Neural Information Processing Systems, 36, 2023.7   \n[94]  D. Zhou, L. Li, and Q. Gu. Neural contextual bandits with ucb-based exploration. In International Conference on Machine Learning, pages 11492-11502, 2020. 2, 60   \n[95]  Y. Zhou, J. Li, and J. Zhu. Posterior sampling for multi-agent reinforcement learning: solving extensive games with imperfect information. In International Conference on Learning Representations, 2019. 2, 17   \n[96] D. Zou, P. Xu, and Q. Gu. Faster convergence of stochastic gradient langevin dynamics for non-log-concave sampling. In Uncertainty in Artificial Intelligence, pages 1152-1162. PMLR, 2021.6 ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "", "page_idx": 15}, {"type": "text", "text": "A Related Work ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Cooperative Multi-Agent Reinforcement LearningCooperative MARL is closely intertwined with the domain of multi-agent multi-armed bandits, exemplified by decentralized algorithms featuring communication across a network or hypergraphs [48, 91, 41] and distributed settings [29, 77]. Cooperative MARL manifests primarily in two categories: multi-agent MDPs [12, 89, 79, 24] and parallel MDPs [11, 24, 53, 11, 56]. In the realm of cooperative multi-agent robotics, the former is employed to formulate optimal multi-agent policies across the distributed system [86, 87]. On the other hand, homogeneous parallel MDPs leverage inter-agent communication to expedite learning processes [43]. Additionally, heterogeneous parallel MDPs establish connections to heterogeneous federated learning [51] and exhibit improved generalizability in transfer learning scenarios [72]. ", "page_idx": 16}, {"type": "text", "text": "We focus on parallel MDPs in this paper, where agents interact with the environment simultaneously to tackle shared challenges within extensive and distributed systems [43]. Recently, Dubey and Pentland [24] proposed the Coop-LSVI algorithm, extending the LSVI-UCB algorithm [36] in singleagent RL to MARL with linear MDPs. In a parallel RL setting with asynchronous communication, Min et al. [56] builds upon Coop-LSVI while relinquishing compatibility with heterogeneous MDPs. Meanwhile, Lidard et al. [53] focuses on fully decentralized multi-agent UCB $Q$ -learning in a tabular setting, maintaining polynomial space complexity even as the number of agents increases. However, it is worth noting that neither of the previous works [24, 56] in non-tabular cooperative MRAL provides experimental validation for the efficacy of their proposed communication strategies. The gap arises from their reliance on LsVI-UCB as the core algorithm, wherein optimism is instantiated through UCB. Empirical evidence suggests that UCB-based approaches tend to underperform in practical scenarios [61, 60, 33]. Moreover, the computational demands of LsVI-UCB become untenable due to the necessity of recurrently computing the feature covariance matrix for updating the UCB bonus function. On the other hand, distributed applications of parallel MDPs in TS-based concurrent RL algorithms have been explored [21, 22, 17]. Specifically, Dimakopoulou and Roy [21] proposed a tabular model learning method based on seed sampling for coordinated exploration. This approach was further generalized to address intractable state spaces in [22] and supported by a Bayesian regret bound in [17]. However, none of these studies consider the communication complexity associated with efficient cooperative strategies. Therefore, randomized exploration in this work is critical to make these algorithm designs practical. ", "page_idx": 16}, {"type": "text", "text": "Randomized Exploration  The roots of randomized exploration, particularly TS, can be traced back to its success in bandit problems [73]. Randomized exploration strategies can typically exhibit superior performance in practical applications due to avoidance of early convergence to suboptimal actions [38\u201440]. Furthermore, these strategies demonstrate robustness in the face of noise and uncertainty, particularly within non-stationary environments [78, 9]. This success has extended to Langevin Monte Carlo Thompson Sampling (LMCTS), which has been applied to various domains, including linear bandits, generalized linear bandits, and neural contextual bandits [83]. The exploration of posterior sampling techniques in RL has gained prominence, building upon the foundation laid by TS [71, 7]. Randomized Least-Square Value Iteration (RLSVI) is an approach that leverages random perturbations to approximate the posterior, with frequentist regret analysis applied under the tabular MDP seting [63], inspiring subsequent works focusing on theoretical analyses aimed at improving worst-case regret under tabular MDPs [70, 4], with extensions to the linear setting [88, 32, 20]. In addition to theoretical advancements, several practical algorithms have been proposed based on RLSVI to approximate posterior samples of $Q$ functions in deep RL. These approaches involve ensembles of randomly initialized neural networks [62, 64] and noise injection into the parameters of the neural network [26, 52]. With the success of LMCTS [83] in bandit domains, the exploration of randomized methods has expanded to alternative approaches like LMC in tabular RL [42] and linear MDPs with neural network approximation [33]. Further works delve into the realm of random exploration from the perspectives of delayed feedback [44] and offline RL [59]. ", "page_idx": 16}, {"type": "text", "text": "While posterior sampling demonstrates superiority in various contexts, its theoretical foundations in the multi-agent setting remain underexplored. Existing research predominantly focuses on two-player zero-sum games, considering both Bayesian [95, 35] and frequentist regrets [80, 65]. There is no existing work studying randomized exploration for cooperative multi-agent settings. ", "page_idx": 16}, {"type": "text", "text": "B  Instantiation of the Proposed Algorithms in the Linear Function Class ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "In this section, we specifically discuss our TS-related algorithms in the linear structure, which is under the assumption of linear function approximation and linear MDP setting. ", "page_idx": 17}, {"type": "text", "text": "Recall from the loss function in (3.4), here we choose $L$ tobe $l_{2}$ loss and linear function class $f(\\mathbf{w};\\boldsymbol{\\phi}^{l})\\,=\\,\\mathbf{w}^{\\top}\\boldsymbol{\\phi}^{l}$ . By solving this least-square regression problem, we obtain the unperturbed regression estimator $\\widehat{\\mathbf{w}}_{m,h}^{k}$ . In the linear setting, we have the closed-form solution ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\widehat{\\mathbf{w}}_{m,h}^{k}=(\\mathbf{A}_{m,h}^{k})^{-1}b_{m,h}^{k},\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Where ${\\pmb{\\Lambda}}_{m,h}^{k}$ and m,h are defined as follows ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\quad\\mathbf{A}_{m,h}^{k}=\\displaystyle\\sum_{l=1}^{\\kappa(k)}\\phi\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)^{\\top}+\\lambda\\mathbf{I},}\\\\ &{\\quad\\quad\\quad\\quad\\kappa(k)}\\\\ &{\\displaystyle b_{m,h}^{k}=\\sum_{l=1}^{\\kappa(k)}\\big[r_{h}\\big(s^{l},a^{l}\\big)+V_{m,h+1}^{k}\\big(s^{\\prime}\\big^{l}\\big)\\big]\\phi\\big(s^{l},a^{l}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "A natural way of doing randomized exploration is to add a noise $\\mathcal{N}(\\mathbf{0},\\sigma^{2}(\\mathbf{A}_{m,h}^{k})^{-1})$ to $\\widehat{\\mathbf{w}}_{m,h}^{k}$ and get the estimated parameter $\\bar{\\mathbf{w}}_{m,h}^{k}$ .Then we can construct estimated $Q$ function $Q_{m,h}^{k}(\\cdot,\\cdot)\\;=\\;$ $\\operatorname*{min}\\{\\phi(\\cdot,\\cdot)^{\\top}\\bar{\\mathbf{w}}_{m,h}^{k},H-h+1\\}^{+}$ : We call this method as CoopTS, which is aligned with other linear TS algorithms [6, 2]. In what follows, we theoretically show that our proposed algorithms are equivalent or approximately converge to the CoopTS algorithm in the linear function approximation setting. ", "page_idx": 17}, {"type": "text", "text": "For CoopTS-PHE (Algorithm $1+$ Algorithm 2), let the function approximation in (3.5) be linear and choose $L$ to be the squared loss. By solving this least-square regression problem, we obtain the perturbedregessionetimator $\\widetilde{\\mathbf{w}}_{m,h}^{k,n}$ in CoopTS-PHE. The following proposition conveys that CoopTS-PHE is actually equivalent to CoopTS. ", "page_idx": 17}, {"type": "text", "text": "Proposition B.1 (Equivalent to CoopTS). The output $\\widetilde{\\mathbf{w}}_{m,h}^{k,n}$ by CoopTS-PHE is equivalent to adding a Gaussian vector to the unperturbed regression estimator m,h, i.e., w $\\widetilde{\\mathbf{w}}_{m,h}^{k,n}=\\widehat{\\mathbf{w}}_{m,h}^{k}+\\boldsymbol{\\zeta}_{m,h}^{k,n}$ Sm,h, where $\\boldsymbol{\\zeta}_{m,h}^{k,n}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}(\\mathbf{A}_{m,h}^{k})^{-1}).$ ", "page_idx": 17}, {"type": "text", "text": "For CoopTS-LMC (Algorithm $1+$ Algorithm 3), let function approximation in (3.4) be linear and choose $L$ to be $l_{2}$ loss to get the loss function. Then after finishing the LMC update, we get the estimated parameter wm,h\\* and construct the model approximation of $Q$ function. The following propositionconveys thattedistributionofw converges to the posterior distribution of Thompson Sampling exploration. The proof of this proposition is given in [83]. ", "page_idx": 17}, {"type": "text", "text": "Proposition B.2 (Approximately equivalent to CoopTS [83]). If the epoch length $J_{k}$ in Algorithm 3 is suficiently large, the distribution of $\\mathbf{w}_{m,h}^{k,J_{k}}$ converges to Gaussian distribution $\\mathcal{N}(\\widehat{\\mathbf{w}}_{m,h}^{k},\\beta_{m,k}^{-1}(\\mathbf{A}_{m,h}^{k})^{-1})$ ", "page_idx": 17}, {"type": "text", "text": "Propositions B.1 and B.2 indicate that the results of our two randomized exploration strategies are closely related to CoopTS. As we have mentioned above, in CoopTS, the estimated parameter $\\bar{\\mathbf{w}}_{m,h}^{k}$ isamledfrmthnmalibuton $\\mathcal{N}(\\widehat{\\mathbf{w}}_{m,h}^{k},\\sigma^{2}(\\mathbf{\\Lambda}_{m,h}^{k})^{-1})$ However, i practice, this $\\beta\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ $\\bar{\\mathbf{w}}_{m,h}^{k}=$ $\\widehat{\\mathbf{w}}_{m,h}^{k}+\\sigma(\\mathbf{A}_{m,h}^{k})^{-\\frac{1}{2}}\\beta$ and obtain the estimated parameter. Nevertheless, computing $\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-\\frac{1}{2}}$ can be computationally expensive, often requiring at least $\\mathcal{O}(d^{3})$ operations with the Cholesky decomposition, making it impractical for high-dimensional machine learning challenges. Additionally, the Gaussian distribution used in Thompson Sampling may not effectively approximate the posterior distribution in more complex bandit models than the linear MDP due to their intricate structures. ", "page_idx": 17}, {"type": "text", "text": "Moreover, as pointed out by recent work [16, 66, 46, 83], the Laplace approximation-based Thompson Sampling exhibits a constant approximation error in the estimation of the posterior distribution. Therefore, it necessitates a careful redesign of the covariance matrix to ensure effective performance. ", "page_idx": 17}, {"type": "text", "text": "Advantagesof PHE and LMCAs mentioned above, computing $\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-\\frac{1}{2}}$ can becomputionally expensive. However, Perturbed-History exploration and Langevin Monte Carlo exploration can avoid this. For PHE, by only adding i.i.d random Gaussian noise to perturb reward and regularizer, its performance will be equivalent to TS. For LMC, by only performing noisy gradient descent, we can do the randomized exploration, resulting in similar performance compared with TS. Additionally, these two methods can easily be implemented to general function class while Thompson Sampling usually cannot be generalized except for the linear setting. In summary, these two methods are both flexible in design and easy to implement in practice. ", "page_idx": 18}, {"type": "text", "text": "Communication cost We emphasize that agents can just send compressed statistics to the server under the linear setting, which can largely reduce communication cost. In the linear function class, we can calculate the closed-form solution of the regression problem (B.1). In this case, when $^{\\mathrm{loc}}\\mathbf{A}_{m,h}^{k}$ ads $^{\\mathrm{loc}}b_{m,h}^{\\dot{k}}$ $\\pmb{\\Lambda}$ $d{\\times}d$ $^{b}$ $d\\!.$ $d$ in linear MDP assumption. This can also avoid privacy disclosure through communications. ", "page_idx": 18}, {"type": "text", "text": "Nevertheless, in the general function class setting, our proposed algorithms still require sharing all the collected datasets, which will cause relatively large communication cost. Additionally, in Appendix K.2, we also propose a federated setting algorithm Algorithm 4. In this setting, instead of sharing collected datasets, agents can just share the weight of the collected estimated $Q$ functions, which can largely reduce the communication cost. ", "page_idx": 18}, {"type": "text", "text": "C  Analysis of the Communication Complexity of Algorithm 1 ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "The proof of the communication complexity is largely inspired by that in [24]. However, we provide a refined analysis here, and thus obtain an improved communication complexity $\\widetilde{\\cal O}(d H\\bar{M}^{2})$ ,in contrast with the $\\widetilde{\\cal O}(d H M^{3})$ complexity in their paper. We also discussed this in Remark 4.7 and showed that our result matches that of a recently proposed asynchronous algorithm. Moreover, we do a careful calculation of the total number of transferred random bits and show it only has a dependence on the number of episodes $K$ ", "page_idx": 18}, {"type": "text", "text": "Proof of Lemma 4.6. We assume $\\sigma=\\{\\sigma_{1},\\ldots,\\sigma_{n}\\}$ as the synchronization episodes, where $\\sigma_{i}\\in[K]$ we also denote $\\sigma_{0}=0$ . To bound the number of synchronization $n$ , we separate $\\sigma$ into two parts with an undetermined term $\\alpha$ ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r}{I_{1}=\\{i\\in[n]|\\sigma_{i}-\\sigma_{i-1}\\leq\\alpha\\},}\\\\ {I_{2}=\\{i\\in[n]|\\sigma_{i}-\\sigma_{i-1}>\\alpha\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then we have $n=|I_{1}|+|I_{2}|$ . Note that ", "page_idx": 18}, {"type": "equation", "text": "$$\nK\\geq\\sigma_{n}=\\sum_{i=1}^{n}(\\sigma_{i}-\\sigma_{i-1})\\geq\\sum_{i\\in I_{2}}(\\sigma_{i}-\\sigma_{i-1})>|I_{2}|\\alpha.\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Then we have $|I_{2}|<K/\\alpha$ . Then note that ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{i=1}^{n}\\log\\left(\\frac{\\operatorname*{det}(\\boldsymbol{\\Lambda}_{m,h}^{\\sigma_{i}})}{\\operatorname*{det}(\\boldsymbol{\\Lambda}_{m,h}^{\\sigma_{i-1}})}\\right)\\geq\\displaystyle\\sum_{i\\in I_{1}}\\log\\left(\\frac{\\operatorname*{det}(\\boldsymbol{\\Lambda}_{m,h}^{\\sigma_{i}})}{\\operatorname*{det}(\\boldsymbol{\\Lambda}_{m,h}^{\\sigma_{i-1}})}\\right)}&{}\\\\ {\\displaystyle\\geq\\displaystyle\\sum_{i\\in I_{1}}\\frac{\\gamma}{\\sigma_{i}-\\sigma_{i-1}}}&{}\\\\ {\\displaystyle\\geq|I_{1}|\\frac{\\gamma}{\\alpha}.}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 18}, {"type": "text", "text": "Define $\\begin{array}{r}{\\mathbf{\\Lambda}_{\\mathbf{h}_{h}}^{\\mathbf{K}}=\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\phi\\bigl(z_{m,h}^{k}\\bigr)\\phi\\bigl(z_{m,h}^{k}\\bigr)^{\\top}+\\lambda\\mathbf{I}}\\end{array}$ where ${z_{m,h}^{k}}=\\left({s_{m,h}^{k}},{a_{m,h}^{k}}\\right)$ . On the other hand, we have ", "page_idx": 18}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{n}\\log\\left(\\frac{\\operatorname*{det}(\\mathbf{\\Lambda}_{m,h}^{\\sigma_{i}})}{\\operatorname*{det}(\\mathbf{\\Lambda}_{m,h}^{\\sigma_{i-1}})}\\right)=\\log\\left(\\frac{\\operatorname*{det}(\\mathbf{\\Lambda}_{m,h}^{\\sigma_{n}})}{\\operatorname*{det}(\\mathbf{\\Lambda}_{m,h}^{\\sigma_{0}})}\\right)\n$$", "text_format": "latex", "page_idx": 18}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\leq\\log\\left(\\frac{\\operatorname*{det}(\\Lambda_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathbf{I})}\\right)}\\\\ {\\displaystyle\\leq d\\log(1+M K/d),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "where the first inequality holds due to the trivial fact that $\\mathbf{A}\\prec\\mathbf{B}\\Rightarrow\\operatorname*{det}(\\mathbf{A})\\leq\\operatorname*{det}(\\mathbf{B})$ ,the second inequality follow from Lemma J.2 and the fact that $\\|\\phi(\\cdot)\\|_{2}\\leq1$ Combine (C.1) and (C.2), then we have $|I_{1}|\\le d\\alpha/\\gamma\\log(1+M K/d)$ .Finally, we choose $\\alpha=K/d$ , then we have ", "page_idx": 19}, {"type": "equation", "text": "$$\nn\\leq{\\frac{K}{\\alpha}}+{\\frac{d\\alpha}{\\gamma}}\\log\\left(1+{\\frac{M K}{d}}\\right)=\\left(d+{\\frac{K}{\\gamma}}\\right)\\log\\left(1+{\\frac{M K}{d}}\\right).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "When one synchronization occurs, communications between agents and the server will occur $M$ times because we have $M$ agents in total. Recall from Lines 16-24 in Algorithm 1, also note that in one synchronization episode, communications will happen $H$ times between every agent and the server. Finally, the upper bound of communication complexity is ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\mathrm{CPX}=\\tilde{\\mathcal{O}}\\big((d+K/\\gamma)M H\\big).\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Next we consider the total number of transferred random bits. We first calculate the communication bits per round. Under the linear setting, we can calculate the closed-form solution of the regression problem $\\hat{\\mathbf{w}}_{m,h}^{k}=(\\mathbf{\\Lambda}_{m,h}^{k})^{-1}b_{m,h}^{k}$ where ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{A}_{m,h}^{k}=\\sum_{l=1}^{K(k)}\\phi\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)^{\\top}+\\lambda\\mathbf{I},}\\\\ &{\\mathbf{\\phi}_{m,h}^{k}=\\sum_{l=1}^{K(k)}[r_{h}\\big(s^{l},a^{l}\\big)+V_{m,h+1}^{k}(s^{\\prime})]\\phi\\big(s^{l},a^{l}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "Note that $l\\in[K(k)]$ is equivalent to $(s,a,s^{\\prime})\\in U_{m,h}(k)$ , and the index set $U_{m,h}(k)$ consists of $U_{h}^{\\mathrm{ser}}(k)$ and $U_{m,h}^{\\mathrm{loc}}(k)$ Therefore,the empical covariancematrix ${\\pmb{\\Lambda}}_{m,h}^{k}$ and the vector $b_{m,h}^{k}$ can be decomposed into the summation of the local matrices and vectors on each agent. When the synchronization occurs, agents just need to send their local statistics $^{\\mathrm{loc}}{\\Lambda}_{m,h}^{k}$ Im,h and locgk bm,h to the server to help solve the regression problem on each agent. ", "page_idx": 19}, {"type": "text", "text": "For the local empirical covariance matrix $^{\\mathrm{loc}}{\\Lambda}_{m,h}^{k}$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{\\omega}^{\\mathrm{loc}}\\mathbf{A}_{m,h}^{k}=\\sum_{(s^{l},a^{l},s^{\\prime{l}})\\in U_{m,h}^{\\mathrm{loc}}(k)}\\phi\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)^{\\top},}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "this is the summation of up to $K\\ d\\times d$ matrices. Note that $\\|\\phi(s,a)\\|\\leq1$ , thus it is easy to see that the entries of each matrix, namely, $\\phi\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)^{\\top}$ , are bounded by 1. Therefore, the entries in $^{\\mathrm{loc}}{\\Lambda}_{m,h}^{k}$ are bounded by $K$ . For each entry in this matrix, it suffices to use ${\\mathcal{O}}(\\log K)$ bits to communicate between the server and the agent. Thus in each round, ${\\mathcal{O}}(d^{2}\\log K)$ bits are needed to send the matrix lo mn.ht ", "page_idx": 19}, {"type": "text", "text": "For the local vector $^{\\mathrm{loc}}b_{m,h}^{k}$ ", "page_idx": 19}, {"type": "equation", "text": "$$\n\\begin{array}{r}{^{\\mathrm{loc}}b_{m,h}^{k}=\\sum_{(s^{l},a^{l},s^{\\prime}^{l})\\in U_{m,h}^{\\mathrm{loc}}(k)}\\bigl[r_{h}\\bigl(s^{l},a^{l}\\bigr)+V_{m,h+1}^{k}(s^{\\prime}^{l})\\bigr]\\phi\\bigl(s^{l},a^{l}\\bigr),}\\end{array}\n$$", "text_format": "latex", "page_idx": 19}, {"type": "text", "text": "this is a $d$ -dimensional vector. Note that $r_{h}$ is bounded by 1, Vh,h+1 is bounded by H and is linear with $\\phi$ by definition, which indicates we only need to communicate a $d$ -dimensional vector $\\bar{\\mathbf{w}}_{m,h}^{k}$ to obtain Vk. Vm,h+ milar to the abve analysis, neach roud, (dlog(K(H+ 1)bits arened t send the vector $^{\\mathrm{loc}}b_{m,h}^{k}$ ", "page_idx": 19}, {"type": "text", "text": "Therefore, the total bits of communication still only has a logarithmic dependency on the number of episodes $K$ . This completes the proof. \u53e3 ", "page_idx": 19}, {"type": "text", "text": "DProof of the Regret Bound for CoopTS-LMC ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "The general framework for CoopTS-LMC and CoopTS-PHE is closely similar. To make the article more concise, we first prove CoopTS-LMC completely, which is a bit more complicated. Then we can simplify the following similar proof for CoopTS-PHE in Appendix G. ", "page_idx": 19}, {"type": "text", "text": "D.1 Supporting Lemmas ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Before deriving the regret bound for CoopTS-LMC, we first provide the necessary technical lemmas for our regret analysis. Note that the loop (Line 3-9) in Algorithm 3 is to do multi-sampling for $N$ times. To simplify the notations, we eliminate the index $n$ before Lemma D.7 because the previous lemmas have nothing to do with multi-sampling. ", "page_idx": 20}, {"type": "text", "text": "Definition D.1 (Model prediction error). For any $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ , we define the model error associated with the reward $r_{h}$ ", "page_idx": 20}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)=r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-Q_{m,h}^{k}(s,a).\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Definition D.2 (Filtration). For any $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ , we define the filtration ${\\mathcal{F}}_{m,k,h}$ as $\\begin{array}{r}{\\mathbf{r}_{m,k,h}=\\sigma\\Big(\\big\\{\\big(s_{n,i}^{\\tau},a_{n,i}^{\\tau}\\big)\\big\\}_{(n,\\tau,i)\\in M\\times[k-1]\\times[H]}\\bigcup\\big\\{\\big(s_{n,i}^{k},a_{n,i}^{k}\\big)\\big\\}_{(n,i)\\in[m-1]\\times[H]}\\bigcup\\big\\{\\big(s_{m,i}^{k},a_{m,i}^{k}\\big)\\big\\}_{i\\in[h]}\\Big).}\\end{array}$ ", "page_idx": 20}, {"type": "text", "text": "Proposition D.3. In Algorithm 3, the parameter $\\mathbf{w}_{m,h}^{k,J_{k}}$ satsfies the Gaussian distribution $\\mathcal{N}(\\mu_{m,h}^{k,J_{k}},\\Sigma_{m,h}^{k,J_{k}})$ wheee ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mu_{m,h}^{k,J_{k}}=\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{1}^{J_{1}}\\mathbf{w}_{m,h}^{1,0}+\\displaystyle\\sum_{i=1}^{k}{\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{I}-\\mathbf{A}_{i}^{J_{i}}\\big)\\widehat{\\mathbf{w}}_{m,h}^{i}},}\\\\ &{\\Sigma_{m,h}^{k,J_{k}}=\\displaystyle\\sum_{i=1}^{k}\\frac{1}{\\beta_{m,i}}\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}}\\big)(\\mathbf{A}_{m,h}^{i})^{-1}(\\mathbf{I}+\\mathbf{A}_{i})^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}...\\mathbf{A}_{k}^{J_{k}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $\\mathbf{A}_{i}=\\mathbf{I}-2\\eta_{m,i}\\mathbf{A}_{m,h}^{i}$ for $i\\in[k]$ ", "page_idx": 20}, {"type": "text", "text": "Lemma D.4. For any $(m,k,h)\\,\\in\\,\\mathcal{M}\\,\\times\\,[K]\\,\\times\\,[H]$ the unperturbed estimated parameter $\\widehat{\\mathbf{w}}_{m,h}^{k}$ satisfies ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\widehat{\\mathbf{w}}_{m,h}^{k}\\|\\leq2H\\sqrt{M k d/\\lambda}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.5. Let $\\lambda=1$ in Algorithm 3. For any fixed $0<\\delta<1$ , with probability at least $1-\\delta^{2}$ \uff0c for any $(m,k,h)\\in\\mathcal{M}\\times[K]\\stackrel{*}{\\times}[H]$ and for any $(s,a)\\in S\\times A$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\Bigl|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k}}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\Bigr|\\leq\\left(5\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\lVert\\phi(s,a)\\rVert_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.6. Let $\\lambda=1$ in Algorithm 3. For any fixed $0<\\delta<1$ , with probability at least $1-\\delta$ , for any $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\|\\mathbf{w}_{m,h}^{k,J_{k}}\\|\\leq\\frac{16}{3}H d\\sqrt{M K}+\\sqrt{\\frac{2K}{3\\beta_{K}\\delta}}d^{3/2}\\stackrel{\\mathrm{def}}{=}B_{\\delta},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.7. Let $\\lambda=1$ in Algorithm 3. For any fixed $0<\\delta<1$ with probability at least $1-\\delta$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ , we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\left[\\left(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\right)\\big(s^{l},a^{l}\\big)\\right]\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq3H\\sqrt{d}C_{\\delta},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "$\\begin{array}{r}{C_{\\delta}=\\Big[\\frac{1}{2}\\log(K+1)+\\log\\Big(\\frac{2\\sqrt{2}K B_{\\delta/2N M H K}}{H}\\Big)+\\log\\frac{3}{\\delta}\\Big]^{1/2}}\\end{array}$ and $B_{\\delta}$ is defined in Lemma D.6. ", "page_idx": 20}, {"type": "text", "text": "Lemma D.8. Let $\\lambda=1$ in Algorithm 3. Under Definition 4.1, for any fixed $0\\,<\\,\\delta\\,<\\,1$ , with probability at least $1-\\delta$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times A$ ,we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\right|\\leq5H\\sqrt{d}C_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "Lemma D.9 (Error bound). Let $\\lambda=1$ in Algorithm 3. Under Definition 4.1, for any fixed $0<\\delta<1$ with probability at least $1-\\delta-\\delta^{2}$ , for any $\\left(m,k,h\\right)\\in\\mathcal{M}\\times\\left[K\\right]\\times\\left[H\\right]$ and for any $(s,a)\\in S\\times A$ we have ", "page_idx": 20}, {"type": "equation", "text": "$$\n-l_{m,h}^{k}(s,a)\\leq\\left(5H\\sqrt{d}C_{\\delta}+5\\sqrt{\\frac{2d\\log\\left(\\sqrt{N}/\\delta\\right)}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\|\\phi(s,a)\\|_{\\left(\\mathbf{A}_{m,h}^{k}\\right)-1},\n$$", "text_format": "latex", "page_idx": 20}, {"type": "text", "text": "where $C_{\\delta}$ is defined in Lemma D.7. ", "page_idx": 20}, {"type": "text", "text": "Lemma D.10 (Optimism). Let $\\lambda=1$ in Algorithm 3 and $\\begin{array}{r}{c_{0}^{\\prime}=1-\\frac{1}{2\\sqrt{2e\\pi}}}\\end{array}$ Under Definition .1, for any fixed $0<\\delta<1$ , with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime}^{N}-2\\delta$ where $|{\\mathcal{C}}(\\varepsilon)|\\leq(3/\\varepsilon)^{d}$ , for all $(m,h;k)\\in\\mathcal{M}\\times[H]\\times[K]$ and for all $(s,a)\\in S\\times{\\dot{A}}$ , we have ", "page_idx": 21}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)\\leq\\alpha_{\\delta}\\varepsilon,\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "where $\\alpha_{\\delta}=\\sqrt{M K}\\big(2H\\sqrt{d}+B_{\\delta/N M H K}\\big)$ ", "page_idx": 21}, {"type": "text", "text": "Remark D.11. Here we point out that in our proofs for both CoopTS-LMC and CoopTS-PHE, we useanew $\\varepsilon$ -covering technique to prove that the optimism lemma holds for all $(s,a)\\,\\in\\,S\\times A$ instead of just the state-action pairs encountered by the algorithm, which is essential in applying this lemmatobound theterm $\\mathbb{E}_{\\pi^{*}}\\!\\left\\lbrack l_{m,h}^{k}(s_{m,h},a_{m,h})\\right\\rbrack\\!\\!\\stackrel{\\!\\cdot}{s}_{m,1}=\\!\\!\\!\\stackrel{\\!\\circ}{s}_{m,1}^{k}\\!\\!\\right\\rbrack$ in D.2)in the regret analysis. This was ignored by previous works [13, 33] that use the same regret decomposition technique in the single-agent setting. ", "page_idx": 21}, {"type": "text", "text": "The following lemma gives the upper bound of self-normalized term summation in the multi-agent setting, which is first introduced by Lemma 9 in [24]. To make our analysis complete, we give out the proof in the Appendix E.9 where we make some necessary modifications compared with Lemma 9 in [24]. ", "page_idx": 21}, {"type": "text", "text": "Lemma D.12. Let Algorithm 2 run for any $K>0$ $M\\geq1$ , and $\\gamma$ as the communication control factor. Define $\\begin{array}{r}{\\mathbf{A}_{h}^{K}=\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\phi\\bigl(s_{m,h}^{k},a_{m,h}^{k}\\bigr)\\phi\\bigl(s_{m,h}^{k},a_{m,h}^{k}\\bigr)^{\\top}+\\lambda\\mathbf{I}_{h}}\\end{array}$ then we have $\\sum_{\\substack{n\\in\\mathcal{M}\\,k=1}}\\big\\|\\phi(s_{m,h}^{k},a_{m,h}^{k})\\big\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq\\bigg(\\log\\bigg(\\frac{\\operatorname*{det}(\\Lambda_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathbf{I})}\\bigg)+1\\bigg)M\\sqrt{\\gamma}+2\\sqrt{M K\\log\\bigg(\\frac{\\operatorname*{det}(\\Lambda_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathbf{I})}\\bigg)}.$ ", "page_idx": 21}, {"type": "text", "text": "The following lemma shows that we can decompose the regret of Algorithm 2 into three different components. The proof of this lemma closely resembles Lemma 4.2 in [13] for the single-agent setting. When we fix the agent $m\\in\\mathcal{M}$ , it is totally same as Lemma 4.2 in [13]. ", "page_idx": 21}, {"type": "text", "text": "Lemma D.13. [13, Lemma 4.2] Define the operators and the following terms: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{(\\mathbb{J}_{m,h}f)(s)=\\langle f(s,\\cdot),\\pi_{m,h}^{*}(\\cdot|s)\\rangle,\\quad(\\mathbb{J}_{m,k,h}f)(s)=\\langle f(s,\\cdot),\\pi_{m,h}^{k}(\\cdot|s)\\rangle,}\\\\ &{\\quad D_{m,k,h,1}=\\big(\\mathbb{J}_{m,k,h}\\big(Q_{m,h}^{k}-Q_{m,h}^{\\pi_{m,k}}\\big)\\big)\\big(s_{m,h}^{k}\\big)-\\big(Q_{m,h}^{k}-Q_{m,h}^{\\pi_{m,k}}\\big)\\big(s_{m,h}^{k},a_{m,h}^{k}\\big),\\quad\\quad\\quad(\\mathbb{J}_{m,h}^{k})=\\mathbb{J}_{m,h}^{k},}\\\\ &{\\quad D_{m,k,h,2}=\\big(\\mathbb{P}_{m,h}\\big(V_{m,h+1}^{k}-V_{m,h+1}^{\\pi_{m,k}}\\big)\\big)\\big(s_{m,h}^{k},a_{m,h}^{k}\\big)-\\big(V_{m,h+1}^{k}-V_{m,h+1}^{\\pi_{m,k}}\\big)\\big(s_{m,h+1}^{k}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "Then we can decompose the regret into the following form: ", "page_idx": 21}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{Regret}(K)=\\displaystyle\\sum_{m\\in\\mathbb{A}}\\sum_{k=1}^{K}V_{m,1}^{*}(s_{m,1}^{k})-V_{m,1}^{*,k}(s_{m,1}^{k})}\\\\ &{=\\displaystyle\\sum_{\\underbrace{\\scriptstyle m\\in\\mathbb{A}^{k-1}\\displaystyle\\sum_{h=1}^{K}\\mathbb{I}_{n^{-1}}}}^{K}\\mathbb{E}_{\\pi^{*}}[\\langle Q_{m,h}^{k}(s_{m,h}),\\pi_{m,h}^{*}(\\cdot,|s_{m,h})-\\pi_{m,h}^{k}(\\cdot|s_{m,h})\\rangle|s_{m,1}=s_{m,1}^{k}]}\\\\ &{\\quad\\displaystyle+\\sum_{\\underbrace{\\scriptstyle m\\in\\mathbb{A}^{k-1}\\displaystyle\\sum_{h=1}^{K}(D_{m,k,h,1}+D_{m,k,h,2})}}^{K}}\\\\ &{\\quad\\displaystyle+\\sum_{\\underbrace{\\scriptstyle m\\in\\mathbb{A}^{k-1}\\displaystyle\\sum_{h=1}^{K}(\\mathbb{I}_{n^{-1}}\\left[i_{m,h}^{k}(s_{m,h},a_{m,h})\\right]s_{m,1}=s_{m,1}^{k}\\right]}}-l_{m,h}^{k}\\binom{k}{s_{m,h},a_{m,h}^{k}}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 21}, {"type": "text", "text": "D.2 Regret Analysis ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "In this part, we give out the proof of Theorem 4.4, the regret bound for CoopTS-LMC. ", "page_idx": 21}, {"type": "text", "text": "Proof of Theorem 4.4. Based on the result from Lemma D.13, we do the regret decomposition first ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{Regret}(K)=\\displaystyle\\sum_{m\\in\\mathbb{A}\\times1}\\sum_{i=1}^{K}V_{m,1}^{*}(s_{m,1}^{k})-V_{m,1}^{**}(s_{m,1}^{k})}\\\\ &{=\\displaystyle\\sum_{m\\in\\mathbb{A}\\times1}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}_{m^{*}}[\\langle Q_{m,h}^{k}(s_{m,h}),\\pi_{m,h}^{*}(\\cdot,|s_{m,h})-\\pi_{m,h}^{k}(\\cdot|s_{m,h})\\rangle|s_{m,1}=s_{m,1}^{k}]}\\\\ &{\\quad\\displaystyle\\cdot\\sum_{m\\in\\mathbb{A}\\times1}^{K}\\sum_{i=1}^{K}\\Big(D_{m,k}b_{m,1}+D_{m,k}b_{m,2}\\Big)}\\\\ &{\\quad\\quad\\displaystyle\\cdot\\sum_{m\\in\\mathbb{A}\\times1-1}^{K}\\sum_{i=1}^{H}(D_{m,k}b_{m,1}+D_{m,k}b_{m,2})}\\\\ &{\\quad\\quad+\\displaystyle\\sum_{m\\in\\mathbb{A}\\times1-1}^{K}\\sum_{i=1}^{H}(\\mathbb{E}_{m^{*}}[\\Tilde{l}_{m,h}^{k}(s_{m,h},a_{m,h})]s_{m,1}=s_{m,1}^{k}]-l_{m,h}^{k}(s_{m,h}^{k},a_{m,h}^{k})\\Big)\\,.}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Next, we will bound the above three terms respectively. ", "page_idx": 22}, {"type": "text", "text": "Bounding Term (i) in (D.2): for the policy $\\pi_{m,h}^{k}$ Tm.h, we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi^{*}}\\big[\\big\\langle Q_{m,h}^{k}(s_{m,h},\\cdot),\\pi_{m,h}^{*}(\\cdot,|s_{m,h})-\\pi_{m,h}^{k}(\\cdot|s_{m,h})\\big\\rangle|s_{m,1}=s_{m,1}^{k}\\big]\\le0.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "This is bcauseby efniton $\\pi_{m,h}^{k}$ is the gredy pole for $Q_{m,h}^{k}$ ", "page_idx": 22}, {"type": "text", "text": "Bounding Term (i) in (D.2): note that $0\\leq Q_{m,h}^{k}\\,\\leq\\,H-h+1\\leq H$ , based on (D.1), for any $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ we have $|D_{m,k,h,1}|\\leq2H$ and $|D_{m,k,h,2}|\\leq2H$ . Note that $D_{m,k,h,1}$ is a martingale difference sequence $\\mathbb{E}[D_{m,k,h,1}|\\mathcal{F}_{m,k,h}]=0$ . By applying Azuma-Hoeffding inequality, with probability at least $1-\\delta/3$ , we have ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,1}\\leq2\\sqrt{2M H^{3}K\\log(6/\\delta)}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Note that $D_{m,k,h,2}$ is also a martingale difference sequence. By applying Azuma-Hoeffding inequality. with probability at least $1-\\delta/3$ wehave ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,2}\\leq2\\sqrt{2M H^{3}K\\log(6/\\delta)}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "By taking union bound, with probability at least $1-2\\delta/3$ ,wehave ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,1}+\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,2}\\le4\\sqrt{2M H^{3}K\\log(6/\\delta)}.\n$$", "text_format": "latex", "page_idx": 22}, {"type": "text", "text": "Bounding Term (ii) in (D.2): based on Lemmas D.9 and D.10, by taking union bound, with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime\\,N}-2\\delta^{\\prime}-M H K(\\delta^{\\prime}+{\\delta^{\\prime}}^{2})$ ,wehave ", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{n\\in\\mathcal{M}}\\sum_{k=1}^{\\overset{N}{\\sum}}\\left(\\mathbb{E}_{\\pi^{*}}\\big[l_{m,h}^{k}(s_{m,h},a_{m,h})\\big|s_{m,1}=s_{m,1}^{k}\\big]-l_{m,h}^{k}\\big(s_{m,h}^{k},a_{m,h}^{k}\\big)\\right)}\\quad}&{}\\\\ &{\\leq\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\big(\\alpha_{\\delta^{\\prime}}\\varepsilon-l_{m,h}^{k}\\big(s_{m,h}^{k},a_{m,h}^{k}\\big)\\big)}\\\\ &{\\leq H M K\\alpha_{\\delta^{\\prime}}\\varepsilon+\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\left(5H\\sqrt{d}C_{\\delta^{\\prime}}+5\\sqrt{\\frac{2d\\log(\\sqrt{N}/\\delta^{\\prime})}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\|\\phi(s_{m,h}^{k},a_{m,h}^{k})\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 22}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{=H M K\\alpha_{\\delta^{\\prime}}\\varepsilon+\\left(5H\\sqrt{d}C_{\\delta^{\\prime}}+5\\sqrt{\\frac{2d\\log(\\sqrt{N}/\\delta^{\\prime})}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\underset{h=1}{\\overset{H}{\\sum}}\\sum_{n\\in\\mathcal{M}}^{-1}\\underset{k=1}{\\overset{K}{\\sum}}\\|\\phi(s_{m,h}^{k},a_{m,h}^{k})\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}}}\\\\ &{\\leq H M K\\alpha_{\\delta^{\\prime}}\\varepsilon+\\left(5H\\sqrt{d}C_{\\delta^{\\prime}}+5\\sqrt{\\frac{2d\\log(\\sqrt{N}/\\delta^{\\prime})}{3\\beta_{K}}}+\\frac{4}{3}\\right)}\\\\ &{\\quad\\times\\displaystyle\\sum_{h=1}^{H}\\left(\\log\\left(\\frac{\\operatorname*{det}(\\mathbf{A}_{h}^{K})}{\\operatorname*{det}(\\boldsymbol{M})}\\right)+1\\right)M\\sqrt{\\gamma}+2\\sqrt{M K\\log\\left(\\frac{\\operatorname*{det}(\\mathbf{A}_{h}^{K})}{\\operatorname*{det}(\\boldsymbol{M})}\\right)}}\\\\ &{\\leq H M K\\alpha_{\\delta^{\\prime}}\\varepsilon+\\left(5H\\sqrt{d}C_{\\delta^{\\prime}}+5\\sqrt{\\frac{2d\\log(\\sqrt{N}/\\delta^{\\prime})}{3\\beta_{K}}}+\\frac{4}{3}\\right)}\\\\ &{\\quad\\times H\\left(d(\\log(1+M K/d)+1)M\\sqrt{\\gamma}+2\\sqrt{M K\\operatorname*{det}(1+M K/d)}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "The first inequality follows from Lemma D.10, the second inequality follows from Lemma D.9, the third inequality follows from Lemma D.12, the last inequality holds due to Lemma J.2 and the fact that $\\lVert\\phi(\\cdot)\\rVert_{2}\\leq1$ ", "page_idx": 23}, {"type": "text", "text": "Here we choose $\\varepsilon=d H\\sqrt{d/M K}/\\alpha_{\\delta^{\\prime}}=\\widetilde{\\mathcal{O}}(\\sqrt{1/d H M^{3}K^{4}N})$ and choose $\\begin{array}{c}{{{\\frac{1}{\\sqrt{\\beta_{K}}}}=20H\\sqrt{d}C_{\\delta^{\\prime}}+}}\\end{array}$ $\\frac{16}{3}$ we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\sum_{\\substack{1\\in\\mathcal{M}\\,k=1}}\\sum_{h=1}^{K}\\big(\\mathbb{E}_{\\pi^{*}}\\big[l_{m,h}^{k}(s_{m,h},a_{m,h})\\big]|s_{m,1}=s_{m,1}^{k}\\big]-l_{m,h}^{k}\\big(s_{m,h}^{k},a_{m,h}^{k}\\big)\\big)\\leq\\widetilde{\\mathcal{O}}\\big(d H^{2}\\big(d M\\sqrt{\\gamma}+\\sqrt{d M K}\\big)\\big),\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "occurs with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime\\,N}-2\\delta^{\\prime}-M H K(\\delta^{\\prime}+\\delta^{\\prime}{}^{2}).$ ", "page_idx": 23}, {"type": "text", "text": "We set $\\delta^{\\prime}=\\delta/12(M H K+1)$ and choose $N=\\bar{C}\\log(\\delta)/\\log(c_{0}^{\\prime})$ where $\\bar{C}=\\widetilde{\\mathcal{O}}(d)$ , then we have ", "page_idx": 23}, {"type": "equation", "text": "$$\n1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime\\,N}-2\\delta^{\\prime}-M H K(\\delta^{\\prime}+{\\delta^{\\prime}}^{2})\\geq1-\\delta/3.\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "Combining Terms (i)(i)(ii) together: Based on (D.3), (D.4) and (D.5). By taking union bound, we get that the final regret bound for CoopTS-LMC is $\\widetilde{\\mathcal{O}}\\big(d H^{2}\\big(d M\\sqrt{\\gamma}+\\sqrt{d M K}\\big)\\big)$ with probability at least $1-\\delta$ \u53e3 ", "page_idx": 23}, {"type": "text", "text": "E Proof of Supporting Lemmas in Appendix D ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "E.1Proof of Proposition D.3 ", "text_level": 1, "page_idx": 23}, {"type": "text", "text": "Recall from Algorithm 3, the LMC update rule is ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbf{w}_{m,h}^{k,j}=\\mathbf{w}_{m,h}^{k,j-1}-\\eta_{m,k}\\nabla L_{m,h}^{k}\\big(\\mathbf{w}_{m,h}^{k,j-1}\\big)+\\sqrt{2\\eta_{m,k}\\beta_{m,k}^{-1}}\\epsilon_{m,h}^{k,j},}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "text", "text": "where we have VLkm,h(w) $\\nabla L_{m,h}^{k}\\big(\\mathbf{w}_{m,h}^{k,j-1}\\big)=2\\big(\\mathbf{\\Lambda}_{m,h}^{k}\\mathbf{w}_{m,h}^{k,j-1}-b_{m,h}^{k}\\big)$ Plug i theaove formula then we can calculate that ", "page_idx": 23}, {"type": "equation", "text": "$$\n\\begin{array}{l}{{\\displaystyle{\\mathbf{v}_{m,h}^{k,J_{k}}=\\mathbf{w}_{m,k}^{k,J_{k}-1}-2\\eta_{m,k}\\big(\\mathbf{A}_{m,h}^{k}\\mathbf{w}_{m,h}^{k,J_{k}-1}-b_{m,h}^{k}\\big)+\\sqrt{2\\eta_{m,k}\\beta_{m,k}^{-1}}\\epsilon_{m,h}^{k,J_{k}}}\\ ~}}\\\\ {{\\displaystyle{=\\big(\\mathbf{I}-2\\eta_{m,k}\\mathbf{A}_{m,h}^{k}\\big)\\mathbf{w}_{m,h}^{k,J_{k}-1}+2\\eta_{m,k}b_{m,h}^{k}+\\sqrt{2\\eta_{m,k}\\beta_{m,k}^{-1}}\\epsilon_{m,h}^{k,J_{k}}}\\ ~}}\\\\ {{\\displaystyle{=\\big(\\mathbf{I}-2\\eta_{m,k}\\mathbf{A}_{m,h}^{k}\\big)^{J_{k}}\\mathbf{w}_{m,h}^{k,0}+\\sum_{l=0}^{J_{k}-1}\\big(\\mathbf{I}-2\\eta_{m,k}\\mathbf{A}_{m,h}^{k}\\big)^{l}\\Big(2\\eta_{m,k}b_{m,h}^{k}+\\sqrt{2\\eta_{m,k}\\beta_{m,k}^{-1}}\\epsilon_{m,h}^{k,J_{k}-l}\\Big)}\\ ~}}\\\\ {{\\displaystyle{=\\big(\\mathbf{I}-2\\eta_{m,k}\\mathbf{A}_{m,h}^{k}\\big)^{J_{k}}\\mathbf{w}_{m,h}^{k,0}+2\\eta_{m,k}\\sum_{l=0}^{J_{k}-1}\\big(\\mathbf{I}-2\\eta_{m,k}\\mathbf{A}_{m,h}^{k}\\big)^{l}b_{m,h}^{k}}\\ ~}}\\end{array}\n$$", "text_format": "latex", "page_idx": 23}, {"type": "equation", "text": "$$\n+\\,\\sqrt{2\\eta_{m,k}\\beta_{m,k}^{-1}}\\sum_{l=0}^{J_{k}-1}\\big({\\mathbf{I}}-2\\eta_{m,k}{\\mathbf{A}}_{m,h}^{k}\\big)^{l}\\epsilon_{m,h}^{k,J_{k}-l},\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the third equality follows from iteration. Denote that $\\mathbf{A}_{i}=\\mathbf{I}-2\\eta_{m,i}\\mathbf{A}_{m,h}^{i}$ Moreover, we choose the step size such that $0<\\eta_{m,i}<1/\\left(2\\lambda_{\\operatorname*{max}}\\big(\\mathbf{A}_{m,h}^{i}\\big)\\right)$ . Thus we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbf{w}_{m,h}^{k,J_{k}}=\\mathbf{A}_{k}^{J_{k}}\\mathbf{w}_{m,h}^{k-1,J_{k-1}}+2\\eta_{m,k}\\sum_{l=0}^{J_{k-1}}\\mathbf{A}_{k}^{l}\\mathbf{A}_{m,h}^{k}\\hat{\\mathbf{w}}_{m,h}^{k}+\\sqrt{2\\eta_{m,k}\\delta_{m,k}^{-1}}\\sum_{l=0}^{J_{k-1}}\\mathbf{A}_{k}^{l}\\mathbf{\\epsilon}_{m,h}^{k,J_{k-1}}}&{}\\\\ {=\\mathbf{A}_{k}^{J_{k}}\\mathbf{w}_{m,h}^{k-1,J_{k-1}}+(\\mathbf{I}-\\mathbf{A}_{k})(\\mathbf{I}+\\mathbf{A}_{k}+\\ldots+\\mathbf{A}_{k}^{J_{k-1}})\\hat{\\mathbf{w}}_{m,h}^{k}+\\sqrt{2\\eta_{m,k}\\delta_{m,k}^{-1}}\\sum_{l=0}^{J_{k-1}}\\mathbf{A}_{k}^{l}\\mathbf{\\epsilon}_{m,h}^{k,l_{l}}}&{}\\\\ {=\\mathbf{A}_{k}^{J_{k}}\\mathbf{w}_{m,h}^{k-1,J_{k-1}}+(\\mathbf{I}-\\mathbf{A}_{k}^{J_{k}})\\hat{\\mathbf{w}}_{m,h}^{k}+\\sqrt{2\\eta_{m,k}\\delta_{m,k}^{-1}}\\sum_{l=0}^{J_{k-1}}\\mathbf{A}_{k}^{l}\\mathbf{\\epsilon}_{m,h}^{k,J_{l}-l}}&{}\\\\ {=\\mathbf{A}_{k}^{J_{k}}\\mathbf{\\cdotA}_{1}^{J_{1}}\\mathbf{w}_{m,h}^{1,0}+\\sum_{l=1}^{K}\\mathbf{A}_{k}^{J_{k}}\\mathbf{\\cdotA}_{1+1}^{J_{l+1}}(\\mathbf{I}-\\mathbf{A}_{l}^{J_{l}})\\hat{\\mathbf{w}}_{m,h}^{k}}&{}\\\\ {+\\sum_{l=1}^{K}\\sqrt{2\\eta_{m,i}\\delta_{m,l}^{-1}}\\mathbf{A}_{k}^{J_{k}}\\mathbf{\\cdotA}_{l+1}^{J_{l+1}}\\sum_{l=0}^{K}\\mathbf{A}_{l}^{l}\\mathbf{\\epsilon}_{m \n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "wherethefrstqualityldsa $\\pmb{b}_{m,h}^{k}=\\mathbf{A}_{m,h}^{k}\\widehat{\\mathbf{w}}_{m,h}^{k}$ and Wk1Je-Wwththirdequalty follows from the fact that $\\mathbf{I}+\\mathbf{A}+\\ldots+\\mathbf{A}^{n-1}=(\\mathbf{I}-\\mathbf{A}^{n})(\\mathbf{I}-\\mathbf{A})^{-1}$ and the fourth equality hols because of iteration. ", "page_idx": 24}, {"type": "text", "text": "Note that $\\pmb{\\epsilon}_{m,h}^{i,J_{i}-l}\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I})$ ba $\\mathbf{w}_{m,h}^{k,J_{k}}\\sim\\mathcal{N}\\big(\\pmb{\\mu}_{m,h}^{k,J_{k}},\\pmb{\\Sigma}_{m,h}^{k,J_{k}}\\big)$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\pmb{\\mu}_{m,h}^{k,J_{k}}=\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{1}^{J_{1}}\\mathbf{w}_{m,h}^{1,0}+\\sum_{i=1}^{k}\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{I}-\\mathbf{A}_{i}^{J_{i}}\\big)\\widehat{\\mathbf{w}}_{m,h}^{i}.\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Next we will calculate the covariance matrix $\\Sigma_{m,h}^{k,J_{k}}$ For simplicity, we define ${\\bf M}_{i}\\quad=\\quad$ $\\sqrt{2\\eta_{m,i}\\beta_{m,i}^{-1}}\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{i+1}^{J_{i+1}}$ thus we have ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\mathbf{M}_{i}\\sum_{l=0}^{J_{i}-1}\\mathbf{A}_{i}^{l}\\epsilon_{m,h}^{i,J_{i}-l}\\sim\\mathcal{N}\\Bigg(\\mathbf{0},\\sum_{l=0}^{J_{i}-1}\\mathbf{M}_{i}\\mathbf{A}_{i}^{l}\\big(\\mathbf{M}_{i}\\mathbf{A}_{i}^{l}\\big)^{\\top}\\Bigg)\\sim\\mathcal{N}\\Bigg(\\mathbf{0},\\mathbf{M}_{i}\\bigg(\\sum_{l=0}^{J_{i}-1}\\mathbf{A}_{i}^{2l}\\bigg)\\mathbf{M}_{i}^{\\top}\\Bigg).\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "Thus we get the covariance matrix $\\Sigma_{m,h}^{k,J_{k}}$ ", "page_idx": 24}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{m,h}^{k,J_{k}}=\\sum_{i=1}^{k}{\\mathbf{M}_{i}\\left(\\sum_{l=0}^{J_{i}-1}\\mathbf{A}_{i}^{2l}\\right)}\\mathbf{M}_{i}^{\\top}}\\\\ {\\displaystyle}\\\\ {\\displaystyle}&{\\displaystyle=\\sum_{i=1}^{k}2\\eta_{m,i}\\beta_{m,i}^{-1}\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\sum_{l=0}^{J_{i}-1}\\mathbf{A}_{i}^{2l}\\right)\\mathbf{A}_{i+1}^{J_{i+1}}\\cdots\\mathbf{A}_{k}^{J_{k}}}\\\\ &{\\displaystyle=\\sum_{i=1}^{k}2\\eta_{m,i}\\beta_{m,i}^{-1}\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}}\\right)(\\mathbf{I}-\\mathbf{A}_{i}^{2})^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\cdots\\mathbf{A}_{k}^{J_{k}}}\\\\ &{\\displaystyle=\\sum_{i=1}^{k}\\frac{1}{\\beta_{m,i}}\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}}\\right)\\left(\\boldsymbol{\\Lambda}_{m,h}^{i}\\right)^{-1}(\\mathbf{I}+\\boldsymbol{\\Lambda}_{i})^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\cdots\\mathbf{A}_{k}^{J_{k}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 24}, {"type": "text", "text": "where the third equality follows from the fact that $\\mathbf{I}+\\mathbf{A}+\\ldots+\\mathbf{A}^{n-1}=(\\mathbf{I}-\\mathbf{A}^{n})(\\mathbf{I}-\\mathbf{A})^{-1}$ Here we complete the proof. ", "page_idx": 24}, {"type": "text", "text": "E.2 Proof of Lemma D.4 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Proof. Note that m,h=(Am,k)-bm m,h, we can calculate that ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\left\\|\\widehat{\\mathbf{w}}_{m,h}^{k}\\right\\|=\\left\\|\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-1}\\mathbf{b}_{m,h}^{k}\\right\\|}}\\\\ &{=\\left\\|\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-1}\\sum_{\\{s^{\\prime},a^{\\prime},s^{\\prime}\\}\\in U_{m,h}(k)}^{-1}\\left[r_{n}(s^{\\prime},a^{\\prime})+V_{m,h+1}^{k}(s^{\\prime})^{l}\\right]\\phi(s^{\\prime},a^{\\prime})\\right\\|}\\\\ &{\\leq\\frac{1}{\\sqrt{\\lambda}}\\sqrt{K(k)}\\Bigg(\\underset{(s^{\\prime},a^{\\prime},s^{\\prime})\\in U_{m,h}(k)}{\\sum_{\\{s^{\\prime},a^{\\prime},s^{\\prime}\\}\\in U_{m,h}(k)}}\\left\\|\\left[r_{n}(s^{\\prime},a^{\\prime})+V_{m,h+1}^{k}(s^{\\prime})\\right]\\phi(s^{\\prime},a^{\\prime})\\right\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}^{2}\\Bigg)^{1/2}}\\\\ &{\\leq\\frac{2H}{\\sqrt{\\lambda}}\\sqrt{K(k)}\\Bigg(\\underset{(s^{\\prime},a^{\\prime},s^{\\prime})\\in U_{m,h}(k)}{\\sum_{\\{s^{\\prime},a^{\\prime},s^{\\prime}\\}\\in U_{m,h}(k)}}\\left\\|\\phi(s^{\\prime},a^{\\prime})\\right\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}^{2}\\Bigg)^{1/2}}\\\\ &{\\leq2H\\sqrt{K(k)}d/\\lambda}\\\\ &{\\leq2H\\sqrt{M k d/\\lambda},}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "where the first inequality follows from Lemma J.3, the second inequality is due to $0\\,\\leq\\,V_{m,h}^{k}\\,\\leq$ $H-h+1$ $0\\leq r_{h}\\leq1$ and $\\|\\phi(s,a)\\|\\leq1$ , the third inequality follows from Lemma J.4, and the last inequality holds because $\\dot{\\kappa}(k)=(M-1)k_{s}+k-1\\le M k$ \u53e3 ", "page_idx": 25}, {"type": "text", "text": "E.3Proof of Lemma D.5 ", "text_level": 1, "page_idx": 25}, {"type": "text", "text": "Proof. We separate the error into two terms and bound them respectively, ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\boldsymbol{\\phi}(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k}}-\\boldsymbol{\\phi}(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\Big|\\leq\\underbrace{\\left\\lvert\\phi(s,a)^{\\top}\\left(\\mathbf{w}_{m,h}^{k,J_{k}}-\\mu_{m,h}^{k,J_{k}}\\right)\\right\\rvert}_{I_{1}}+\\underbrace{\\left\\lvert\\phi(s,a)^{\\top}\\left(\\mu_{m,h}^{k,J_{k}}-\\widehat{\\mathbf{w}}_{m,h}^{k}\\right)\\right\\rvert}_{I_{2}}.\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Bounding Term $I_{1}$ in (E.1): by Cauchy-Schwarz inequality, we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\phi(s,a)^{\\top}\\middle(\\mathbf{w}_{m,h}^{k,J_{k}}-\\mu_{m,h}^{k,J_{k}}\\right)\\right|\\leq\\left\\|\\phi(s,a)\\right\\|_{\\Sigma_{m,h}^{k,J_{k}}}\\cdot\\left\\|\\mathbf{w}_{m,h}^{k,J_{k}}-\\mu_{m,h}^{k,J_{k}}\\right\\|_{(\\Sigma_{m,h}^{k,J_{k}})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "By choosing $\\eta_{m,k}\\leq1/\\bigl(4\\lambda_{\\operatorname*{max}}\\bigl(\\mathbf{A}_{m,h}^{k}\\bigr)\\bigr)$ for all $k$ and $m$ , then we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{1}{2}\\mathbf{I}\\prec\\mathbf{A}_{k}=\\mathbf{I}-2\\eta_{m,k}\\mathbf{A}_{m,h}^{k}\\prec(1-2\\eta_{m,k}\\lambda_{\\operatorname*{min}}(\\mathbf{A}_{m,h}^{k}))\\mathbf{I},}\\\\ &{\\frac{3}{2}\\mathbf{I}\\prec\\mathbf{I}+\\mathbf{A}_{k}=2\\mathbf{I}-2\\eta_{m,k}\\mathbf{A}_{m,h}^{k}\\prec2\\mathbf{I}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "text", "text": "Recall the definition of $\\Sigma_{m,h}^{k,J_{k}}$ in Proposition D.3. By choosing $\\beta_{m,i}\\,=\\,\\beta_{K}$ for all $i\\;\\in\\;[k]$ and $m\\in\\mathcal{M}$ , then we have ", "page_idx": 25}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\mathbf{X}_{m,h}^{k,J_{k}}\\phi(s,a)}\\\\ &{=\\displaystyle\\sum_{i=1}^{k}\\frac{1}{\\beta_{m,i}}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}}\\right)\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}(\\mathbf{I}+\\mathbf{A}_{i})^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{\\leq\\displaystyle\\frac{2}{3\\beta_{m,i}}\\sum_{i=1}^{k}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}-\\mathbf{A}_{i}^{J_{i}}\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}\\mathbf{A}_{i}^{J_{i}}\\right)\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{=\\displaystyle\\frac{2}{3\\beta_{K}}\\sum_{i=1}^{k-1}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}-\\left(\\mathbf{A}_{m,h}^{i+1}\\right)^{-1}\\right)\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{\\qquad-\\displaystyle\\frac{2}{3\\beta_{K}}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\mathbf{A}_{1}^{J_{i}}\\left(\\mathbf{A}_{m,h}^{1}\\right)^{-1}\\mathbf{A}_{1}^{J_{1}}\\cdot\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\end{array}\n$$", "text_format": "latex", "page_idx": 25}, {"type": "equation", "text": "$$\n+\\,\\frac{2}{3\\beta_{K}}\\phi(s,a)^{\\top}(\\mathbf{A}_{m,h}^{k})^{-1}\\phi(s,a),\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where the first inequality follows from (E.2). By the defnition of ${\\pmb{\\Lambda}}_{m,h}^{i}$ and Woodbury formula, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}-\\left(\\mathbf{A}_{m,h}^{i+1}\\right)^{-1}=\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}-\\left(\\mathbf{A}_{m,h}^{i}+\\displaystyle\\sum_{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}\\phi(s^{l},a^{l})\\phi(s^{l},a^{l})^{\\top}\\right)^{-1}}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{A}_{m,h}^{i})^{-1}\\varphi(\\mathbf{I}_{n}+\\varphi^{\\top}(\\mathbf{A}_{m,h}^{i})^{-1}\\varphi)^{-1}\\varphi^{\\top}(\\mathbf{A}_{m,h}^{i})^{-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\varphi$ is a matrix with the dimension of $d\\times n,n$ is the number difference of $\\phi(s^{l},a^{l})$ between $\\left(\\Lambda_{m,h}^{i}\\right)^{-1}$ and $\\left(\\mathbf{A}_{m,h}^{i+1}\\right)^{-1}$ (i.e. we concatenate all $\\phi(s^{l},a^{l})$ into the matrix $\\varphi$ ). Note that $n\\leq M$ then we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}\\Big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}-\\big(\\mathbf{A}_{m,h}^{i+1}\\big)^{-1}\\Big)\\mathbf{A}_{i+1}^{J_{i+1}}\\cdots\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{=\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}\\Big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi(\\mathbf{I}_{n}+\\varphi^{\\top}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi\\big)^{-1}\\varphi^{\\top}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\Big)\\mathbf{A}_{i+1}^{J_{i+1}}\\cdots\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{\\leq\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi\\varphi^{\\top}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\cdots\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{=\\lVert\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi\\rVert_{2}^{2}}\\\\ &{\\leq\\lVert\\mathbf{A}_{k}^{J_{k}}\\cdots\\mathbf{A}_{i+1}^{J_{i+1}}(\\mathbf{A}_{m,h}^{i})^{-1/2}\\phi(s,a)\\rVert_{2}^{2}\\cdot\\lVert\\big(\\mathbf{A}_{m,h}^{i})^{-1/2}\\varphi\\rVert_{F}^{2}}\\\\ &{\\leq\\displaystyle\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\mathbf{A}_{m,h}^{j}\\big)\\Big)^{2J_{j}}\\,\\mathrm{tr}\\,\\big(\\varphi^{\\top}\\big\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "where $\\left\\|\\cdot\\right\\|_{F}$ is Frobenius norm and the last inequality is due to $\\|\\mathbf{A}^{-\\frac{1}{2}}\\mathbf{X}\\|_{F}^{2}=\\operatorname{tr}(\\mathbf{X}^{\\top}\\mathbf{A}^{-1}\\mathbf{X})$ and (E.2). Thus we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\big\\|\\phi(s,a)\\big\\|_{\\mathbf{z}_{m,h}^{k,J_{k}}}^{2}\\leq\\frac{2}{3\\beta_{K}}\\displaystyle\\sum_{i=1}^{k}\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\mathbf{A}_{m,h}^{j}\\big)\\Big)^{2J_{j}}\\operatorname{tr}\\big(\\varphi^{\\top}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi\\big)\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{i})^{-1}}^{2}}}\\\\ &{}&{+\\ \\displaystyle\\frac{2}{3\\beta_{K}}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Using the inequality ${\\sqrt{a^{2}+b^{2}}}\\leq a+b$ for $a,b>0$ , we get ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\phi(s,a)\\right|\\right|_{\\mathbf{Z}_{m,h}^{k,J_{k}}}\\leq\\sqrt{\\displaystyle\\frac{2}{3\\beta_{K}}}\\Bigg(\\displaystyle\\sum_{i=1}^{k}\\prod_{j=i+1}^{k}\\left(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}(\\Lambda_{m,h}^{j})\\right)^{J_{j}}\\mathrm{tr}(\\varphi^{\\top}(\\Lambda_{m,h}^{i})^{-1}\\varphi)^{\\frac{1}{2}}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{i})^{-1}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad+\\left\\|\\phi(s,a)\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\Bigg)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\frac{\\mathrm{def}}{a}\\hat{a}_{-}^{k}\\,.(\\phi(s,a)).}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Note that $\\begin{array}{r}{\\Big(\\Sigma_{m,h}^{k,J_{k}}\\Big)^{-1/2}\\Big(\\mathbf{w}_{m,h}^{k,J_{k}}-\\mu_{m,h}^{k,J_{k}}\\Big)\\sim\\mathcal{N}(\\mathbf{0},\\mathbf{I}_{d})}\\end{array}$ By the Gaussian concentration property, we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathbb{P}\\bigg(\\|\\Big(\\mathbf{\\Sigma}_{m,h}^{k,J_{k}}\\Big)^{-1/2}\\Big(\\mathbf{w}_{m,h}^{k,J_{k}}-\\mu_{m,h}^{k,J_{k}}\\Big)\\Big\\|\\geq\\sqrt{4d\\log(1/\\delta)}\\bigg)\\leq\\delta^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "text", "text": "Then we have ", "page_idx": 26}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\Big(\\Big|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k}}-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\Big|\\geq2\\widehat{g}_{m,h}^{k}(\\phi(s,a))\\sqrt{d\\log(1/\\delta)}\\Big)}\\\\ &{\\leq\\mathbb{P}\\Big(\\Big|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k}}-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\Big|\\geq2\\sqrt{d\\log(1/\\delta)}\\|\\phi(s,a)\\|_{\\Sigma_{m,h}^{k,J_{k}}}\\Big)}\\\\ &{\\leq\\mathbb{P}\\Big(\\Big\\|\\phi(s,a)\\Big\\|_{\\Sigma_{m,h}^{k,J_{k}}}\\cdot\\Big\\|\\mathbf{w}_{m,h}^{k,J_{k}}-\\mu_{m,h}^{k,J_{k}}\\Big\\|_{(\\Sigma_{m,h}^{k,J_{k}})^{-1}}\\geq2\\sqrt{d\\log(1/\\delta)}\\|\\phi(s,a)\\|_{\\Sigma_{m,h}^{k,J_{k}}}\\Big)}\\\\ &{=\\mathbb{P}\\Big(\\Big\\|\\big(\\Sigma_{m,h}^{k,J_{k}})^{-1/2}\\big(\\mathbf{w}_{m,h}^{k,J_{k}}-\\mu_{m,h}^{k,J_{k}}\\big)\\Big\\|\\geq2\\sqrt{d\\log(1/\\delta)}\\Big)}\\end{array}\n$$", "text_format": "latex", "page_idx": 26}, {"type": "equation", "text": "$\\leq\\delta^{2}.$ ", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Bounding Term $I_{2}$ in (E.1): Recall from Proposition D.3, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mu_{m,h}^{k,J_{k}}=\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{1}^{J_{1}}\\mathbf{w}_{m,h}^{1,0}+\\displaystyle\\sum_{i=1}^{k}{\\mathbf{A}}_{k}^{J_{k}}...\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{I}-\\mathbf{A}_{i}^{J_{i}}\\big)\\widehat{\\mathbf{w}}_{m,h}^{i}}\\\\ &{\\qquad=\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{1}^{J_{1}}\\mathbf{w}_{m,h}^{1,0}+\\displaystyle\\sum_{i=1}^{k-1}{\\mathbf{A}}_{k}^{J_{k}}...\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\widehat{\\mathbf{w}}_{m,h}^{i}-\\widehat{\\mathbf{w}}_{m,h}^{i+1}\\big)-\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{1}^{J_{1}}\\widehat{\\mathbf{w}}_{m,h}^{1}+\\widehat{\\mathbf{w}}_{m,h}^{k}}\\\\ &{\\qquad=\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{1}^{J_{1}}(\\mathbf{w}_{m,h}^{1,0}-\\widehat{\\mathbf{w}}_{m,h}^{1})+\\displaystyle\\sum_{i=1}^{k-1}\\mathbf{A}_{k}^{J_{k}}...\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\widehat{\\mathbf{w}}_{m,h}^{i}-\\widehat{\\mathbf{w}}_{m,h}^{i+1}\\big)+\\widehat{\\mathbf{w}}_{m,h}^{k}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Then we can get ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}(\\mu_{m,h}^{k,J_{k}}-\\widehat{\\mathbf{w}}_{m,h}^{k})}\\\\ &{=\\underbrace{\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\ldots\\mathbf{A}_{1}^{J_{1}}(\\mathbf{w}_{m,h}^{1,0}-\\widehat{\\mathbf{w}}_{m,h}^{1})}_{I_{21}}+\\underbrace{\\phi(s,a)^{\\top}\\sum_{i=1}^{k-1}\\mathbf{A}_{k}^{J_{k}}\\ldots\\mathbf{A}_{i+1}^{J_{i+1}}(\\widehat{\\mathbf{w}}_{m,h}^{i}-\\widehat{\\mathbf{w}}_{m,h}^{i+1})}_{I_{22}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "In Algorithm 3, we choose $\\mathbf{w}_{m,h}^{1,0}=\\mathbf{0}$ and $\\widehat{\\mathbf{w}}_{m,h}^{1}=(\\mathbf{A}_{m,h}^{1})^{-1}b_{m,h}^{1}=\\mathbf{0}$ Thus we have $I_{21}=0$ To bound term $I_{22}$ , we use the inequalities in (E.2) and Lemma D.4, we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{I_{22}\\leq\\Big|\\displaystyle\\sum_{i=1}^{k-1}\\phi(s,a)^{\\top}\\mathbf A_{k}^{J_{k}}\\cdots\\mathbf A_{i+1}^{J_{i+1}}(\\widehat\\mathbf{w}_{m,h}^{i}-\\widehat\\mathbf{w}_{m,h}^{i+1})\\Big|}\\\\ &{\\quad\\leq\\displaystyle\\sum_{i=1}^{k-1}\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}(\\Lambda_{m,h}^{j})\\Big)^{J_{j}}\\Vert\\phi(s,a)\\Vert(\\Vert\\widehat\\mathbf{w}_{m,h}^{i}\\Vert+\\Vert\\widehat\\mathbf{w}_{m,h}^{i+1}\\Vert)}\\\\ &{\\quad\\overset{k-1}{\\leq}\\displaystyle\\sum_{i=1}^{k-1}\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}(\\Lambda_{m,h}^{j})\\Big)^{J_{j}}\\Vert\\phi(s,a)\\Vert\\big(2H\\sqrt{M i d/\\lambda}+2H\\sqrt{M(i+1)d/\\lambda}\\big)}\\\\ &{\\quad\\leq4H\\sqrt{M K d/\\lambda}\\displaystyle\\sum_{i=1}^{k-1}\\displaystyle\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}(\\Lambda_{m,h}^{j})\\Big)^{J_{j}}\\Vert\\phi(s,a)\\Vert.}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Thus we get ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\phi(s,a)^{\\top}\\big(\\mu_{m,h}^{k,J_{k}}-\\widehat\\mathbf{w}_{m,h}^{k}\\big)\\leq4H\\sqrt{M K d/\\lambda}\\sum_{i=1}^{k-1}\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\Lambda_{m,h}^{j}\\big)\\Big)^{J_{j}}\\|\\phi(s,a)\\|.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "Substituting (E.3) and (E.4) into (E.1), with probability at least $1-\\delta^{2}$ ,wehave ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k}}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\right|}\\\\ &{\\leq4H\\sqrt{M K d/\\lambda}\\displaystyle\\sum_{i=1}^{k-1}\\prod_{j=i+1}^{k}\\left(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}(\\Lambda_{m,h}^{j})\\right)^{J_{j}}\\|\\phi(s,a)\\|+2\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta_{K}}}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\qquad+\\,2\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta_{K}}}\\displaystyle\\sum_{i=1}^{k}\\prod_{j=i+1}^{k}\\left(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}(\\Lambda_{m,h}^{j})\\right)^{J_{j}}\\mathrm{tr}\\left(\\varphi^{\\top}\\left(\\Lambda_{m,h}^{i}\\right)^{-1}\\varphi\\right)^{\\frac{1}{2}}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{i})^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "def W. ", "page_idx": 27}, {"type": "text", "text": "Here we choose $\\eta_{m,j}=1/(4\\lambda_{\\operatorname*{max}}(\\mathbf{A}_{m,h}^{j}))$ and set $\\kappa_{j}=\\lambda_{\\mathrm{max}}\\big(\\mathbf{A}_{m,h}^{j}\\big)/\\lambda_{\\mathrm{min}}\\big(\\mathbf{A}_{m,h}^{j}\\big)$ then we have ", "page_idx": 27}, {"type": "equation", "text": "$$\n\\left(1-2\\eta_{m,j}\\lambda_{\\mathrm{min}}\\big(\\mathbf{\\Lambda}_{m,h}^{j}\\big)\\right)^{J_{j}}=(1-1/2\\kappa_{j})^{J_{j}}.\n$$", "text_format": "latex", "page_idx": 27}, {"type": "text", "text": "We want to have $(1-1/2\\kappa_{j})^{J_{j}}<\\epsilon$ , it suffices to choose $J_{j}$ such that ", "page_idx": 28}, {"type": "equation", "text": "$$\nJ_{j}\\ge\\frac{\\log(1/\\epsilon)}{\\log\\left(\\frac{1}{1-1/2\\kappa_{j}}\\right)}.\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Note that $1/2\\kappa_{j}\\leq1/2$ we have $\\mathrm{log}(1/(1-1/2\\kappa_{j}))\\ge1/2\\kappa_{j}$ because $e^{-x}>1-x$ for $0<x<1$ Therefore, we only need to pick $J_{j}\\ge2\\kappa_{j}\\log(1/\\epsilon)$ \uff1a ", "page_idx": 28}, {"type": "text", "text": "Also note that $1\\geq\\|\\phi(s,a)\\|\\geq\\sqrt{\\lambda}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{i})^{-1}}$ and $\\mathrm{tr}\\left(\\boldsymbol{\\varphi}^{\\top}\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}\\boldsymbol{\\varphi}\\right)\\,\\leq\\,M$ due to the fact that $n\\leq M$ . By setting $\\epsilon=1/(4H M K d)$ and $\\lambda=1$ we obtain ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{V\\underset{=}{\\leq}\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i}4H\\sqrt{M K d/\\lambda}|\\phi(s,a)|+2\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta k}}\\bigg(\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i}\\sqrt{M}|\\phi(s,a)|\\bigg)}\\\\ &{\\quad\\leq\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i}4H\\sqrt{M K d/\\lambda}\\sqrt{M K}|\\phi(s,a)|(\\alpha_{m,h}^{k})|(\\alpha_{m,h}^{k})^{-1}}\\\\ &{\\qquad\\quad\\quad+2\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta k}}\\bigg(\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i}M\\sqrt{K}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\bigg)}\\\\ &{\\quad\\leq\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i-1}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+2\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta k}}\\bigg(\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i-1}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\quad\\leq\\Big(5\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta k}}+\\frac{4}{3}\\Big)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "where the second inequality follows from $\\begin{array}{r l r}{\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\!}&{{}\\ge}&{\\!1/\\sqrt{{\\cal K}(k)+1}\\|\\phi(s,a)\\|\\;\\;\\ge}\\end{array}$ $1/\\sqrt{M K}\\|\\phi(s,a)\\|$ , the fourth inequalityfollows from $\\begin{array}{r}{\\sum_{i=1}^{k-1}\\epsilon^{k-i-1}=\\sum_{i=0}^{k-2}\\epsilon^{i}<1/(1\\!-\\!\\epsilon)\\le4/3}\\end{array}$ Finallywehave ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}\\bigg(\\Big|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k}}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\Big|\\leq\\bigg(5\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta_{K}}}+\\frac{4}{3}\\bigg)\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\bigg)}\\\\ &{\\geq\\mathbb{P}\\Big(\\Big|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k}}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\Big|\\leq W\\Big)}\\\\ &{\\geq1-\\delta^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "This completes the proof. ", "page_idx": 28}, {"type": "text", "text": "E.4Proof of Lemma D.6 ", "text_level": 1, "page_idx": 28}, {"type": "text", "text": "Proof. Recall that w,h $\\mathbf{w}_{m,h}^{k,J_{k}}\\sim\\mathcal{N}(\\pmb{\\mu}_{m,h}^{k,J_{k}},\\pmb{\\Sigma}_{m,h}^{k,J_{k}})$ . Let $\\pmb{\\xi}_{m,h}^{k,J_{k}}=\\mathbf{w}_{m,h}^{k,J_{k}}-\\pmb{\\mu}_{m,h}^{k,J_{k}}\\sim\\mathcal{N}(\\mathbf{0},\\pmb{\\Sigma}_{m,h}^{k,J_{k}})$ m,h ), thus we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathbf{w}_{m,h}^{k,J_{k}}\\|=\\|{\\mu}_{m,h}^{k,J_{k}}+{\\xi}_{m,h}^{k,J_{k}}\\|\\leq\\|{\\mu}_{m,h}^{k,J_{k}}\\|+\\|{\\xi}_{m,h}^{k,J_{k}}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "text", "text": "Bounding $\\|\\pmb{\\mu}_{m,h}^{k,J_{k}}\\|$ in (E.6): Based on Proposition D.3, we have ", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\left\\|{\\mu}_{m,h}^{k,J_{k}}\\right\\|=\\left\\|\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\cdot\\mathbf{A}_{1}^{J_{1}}\\mathbf{w}_{m,h}^{1,0}+\\displaystyle\\sum_{i=1}^{k}\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\mathbf{I}-\\mathbf{A}_{i}^{J_{i}}\\right)\\widehat{\\mathbf{w}}_{m,h}^{i}\\right\\|}&{}\\\\ {\\leq\\displaystyle\\sum_{i=1}^{k}\\left\\|\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\mathbf{I}-\\mathbf{A}_{i}^{J_{i}}\\right)\\right\\|_{F}\\cdot\\left\\|\\widehat{\\mathbf{w}}_{m,h}^{i}\\right\\|}&{}\\\\ {\\leq2H\\sqrt{M K d/\\lambda}\\displaystyle\\sum_{i=1}^{k}\\left\\|\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\mathbf{I}-\\mathbf{A}_{i}^{J_{i}}\\right)\\right\\|_{F}}&{}\\\\ {\\leq2H d\\sqrt{M K/\\lambda}\\displaystyle\\sum_{i=1}^{k}\\left\\|\\mathbf{A}_{k}\\right\\|_{2}^{J_{k}}\\cdot\\cdot\\cdot\\left\\|\\mathbf{A}_{i+1}\\right\\|_{2}^{J_{i+1}}\\left\\|\\left(\\mathbf{I}-\\mathbf{A}_{i}^{J_{i}}\\right)\\right\\|_{2}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 28}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\leq2H d\\sqrt{M K/\\lambda}\\sum_{i=1}^{k}\\prod_{j=i+1}^{k}\\left(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\Lambda_{m,h}^{j}\\big)\\right)^{J_{j}}\\left(\\|\\mathbf{I}\\|_{2}+\\left\\|\\mathbf{A}_{i}\\right\\|_{2}^{J_{i}}\\right)}\\\\ {\\displaystyle\\leq2H d\\sqrt{M K/\\lambda}\\sum_{i=1}^{k}\\prod_{j=i+1}^{k}\\left(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\Lambda_{m,h}^{j}\\big)\\right)^{J_{j}}\\left(1+\\big(1-2\\eta_{m,i}\\lambda_{\\operatorname*{min}}\\big(\\Lambda_{m,h}^{i}\\big)\\big)^{J_{j}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the second inequality holds from Lemma D.4, the third inequality follows from the fact that rank $\\left(\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\left(\\bar{\\mathbf{I}}-\\mathbf{A}_{i}^{J_{i}}\\right)\\right)\\,\\leq\\,d$ and $\\|\\mathbf{X}\\|_{2}\\,\\leq\\,\\|\\mathbf{X}\\|_{F}\\,\\leq\\,\\mathrm{rank}(\\mathbf{X})\\|\\mathbf{X}\\|_{2}$ Where $\\|\\mathbf{X}\\|_{2}=$ $\\sigma_{\\mathrm{max}}(\\mathbf X)$ ", "page_idx": 29}, {"type": "text", "text": "Recall that in Lemma D.5, we set $J_{j}\\;\\geq\\;2\\kappa_{j}\\log(1/\\epsilon)$ where $\\kappa_{j}\\;=\\;\\lambda_{\\mathrm{max}}\\big(\\mathbf{A}_{m,h}^{j}\\big)\\big/\\lambda_{\\mathrm{min}}\\big(\\mathbf{A}_{m,h}^{j}\\big)$ $\\epsilon=1/(4H M K d)$ and $\\lambda=1$ , thus we get ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|{\\mu}_{m,h}^{k,J_{k}}\\right\\|\\leq2H d\\sqrt{M K/\\lambda}\\displaystyle\\sum_{i=1}^{k}(\\epsilon^{k-i}+\\epsilon^{k-i+1})}\\\\ &{\\qquad\\qquad\\leq4H d\\sqrt{M K/\\lambda}\\displaystyle\\sum_{i=0}^{\\infty}\\epsilon^{i}}\\\\ &{\\qquad\\qquad\\leq\\frac{16}{3}H d\\sqrt{M K}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Bounding $\\|\\pmb{\\xi}_{m,h}^{k,J_{k}}\\|$ in (E.6): Note that $\\xi_{m,h}^{k,J_{k}}\\ \\sim\\ \\mathcal{N}(\\mathbf{0},\\boldsymbol{\\Sigma}_{m,h}^{k,J_{k}})$ using Gaussa concenraton Lemma J.5, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\vert\\vert\\pmb{\\xi}_{m,h}^{k,J_{k}}\\vert\\vert\\leq\\sqrt{\\frac{1}{\\delta}\\operatorname{tr}\\left(\\Sigma_{m,h}^{k,J_{k}}\\right)}\\Bigg)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Recall from Proposition D.3, we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{tr}\\left(\\mathbf{\\Sigma}_{m,h}^{k,J_{k}}\\right)=\\displaystyle\\sum_{i=1}^{k}\\frac{1}{\\beta_{m,i}}\\operatorname{tr}\\left(\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}}\\big)\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}(\\mathbf{I}+\\mathbf{A}_{i})^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\cdot\\cdot\\mathbf{A}_{k}^{J_{k}}\\right)}\\\\ &{\\quad\\quad\\quad\\leq\\displaystyle\\sum_{i=1}^{k}\\frac{1}{\\beta_{m,i}}\\operatorname{tr}\\left(\\mathbf{A}_{k}^{J_{k}}\\right)\\cdot\\cdot\\cdot\\operatorname{tr}\\left(\\mathbf{A}_{i+1}^{J_{i+1}}\\right)\\operatorname{tr}\\left(\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}}\\right)\\operatorname{tr}\\left(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\right)\\operatorname{tr}\\left(\\big(\\mathbf{I}+\\mathbf{A}_{i}\\big)^{-1}\\right)}\\\\ &{\\quad\\quad\\quad\\times\\operatorname{tr}\\left(\\mathbf{A}_{i+1}^{J_{i+1}}\\right)\\cdot\\cdot\\cdot\\operatorname{tr}\\left(\\mathbf{A}_{k}^{J_{k}}\\right),}\\end{array}\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "where the inequality holds due to Lemma J.6. Recallfrom (E.2) that, when $\\eta_{m,k}\\leq1/\\bigl(4\\lambda_{\\operatorname*{max}}\\bigl(\\mathbf{A}_{m,h}^{k}\\bigr)\\bigr)$ for all $k$ and $m$ , we have ${\\bf A}_{i}^{J_{i}}\\preccurlyeq(1-2\\eta_{m,k}\\lambda_{\\mathrm{min}}({\\bf A}_{m,h}^{k}))^{J_{j}}{\\bf I}$ set $\\lambda=1$ , then we obtain ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathrm{tr}(\\mathbf{A}_{i}^{J_{i}})\\leq\\mathrm{tr}\\left(\\left(1-2\\eta_{m,k}\\lambda_{\\mathrm{min}}\\!\\left(\\mathbf{A}_{m,h}^{k}\\right)\\right)^{J_{j}}\\mathbf{I}\\right)\\leq d\\big(1-2\\eta_{m,k}\\lambda_{\\mathrm{min}}\\!\\left(\\mathbf{A}_{m,h}^{k}\\right)\\big)^{J_{j}}\\leq d\\epsilon\\leq1.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Similarly, we have $\\begin{array}{r}{\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}}\\preccurlyeq\\big(1-\\frac{1}{2^{2J_{i}}}\\big)\\mathbf{I}}\\end{array}$ , then we get ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathrm{tr}(\\mathbf{I}-\\mathbf{A}_{i}^{2J_{i}})\\leq\\bigg(1-\\frac{1}{2^{2J_{i}}}\\bigg)d<d.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Also, based on $\\begin{array}{r}{({\\bf I}+{\\bf A}_{i})^{-1}\\preccurlyeq\\frac{2}{3}{\\bf I},}\\end{array}$ we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\operatorname{tr}\\left((\\mathbf{I}+\\mathbf{A}_{i})^{-1}\\right)\\leq{\\frac{2}{3}}d.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Note that $\\lambda_{\\operatorname*{max}}\\big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\big)\\leq1$ , we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\mathrm{tr}\\left(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\right)\\leq\\sum\\lambda\\big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\big)\\leq d.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Combine the above results together and choose $\\beta_{m,i}=\\beta_{K}$ for all $i\\in[K]$ and $m\\in\\mathcal{M}$ ,we have ", "page_idx": 29}, {"type": "equation", "text": "$$\n\\operatorname{tr}\\left(\\Sigma_{m,h}^{k,J_{k}}\\right)\\leq\\sum_{i=1}^{K}\\frac{1}{\\beta_{m,i}}\\cdot\\frac{2}{3}\\cdot d^{3}=\\frac{2}{3\\beta_{K}}K d^{3}.\n$$", "text_format": "latex", "page_idx": 29}, {"type": "text", "text": "Then we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\mathbb{P}\\bigg(\\|\\xi_{m,h}^{k,J_{k}}\\|\\leq\\sqrt{\\frac{1}{\\delta}\\cdot\\frac{2}{3\\beta_{K}}K d^{3}}\\bigg)\\geq\\mathbb{P}\\bigg(\\|\\xi_{m,h}^{k,J_{k}}\\|\\leq\\sqrt{\\frac{1}{\\delta}\\operatorname{tr}\\left(\\Sigma_{m,h}^{k,J_{k}}\\right)}\\bigg)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Combine above results together: with probability at least $1-\\delta$ wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\|\\mathbf{w}_{m,h}^{k,J_{k}}\\|\\leq\\frac{16}{3}H d\\sqrt{M K}+\\sqrt{\\frac{2K}{3\\beta_{K}\\delta}}d^{3/2}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "This completes the proof. ", "page_idx": 30}, {"type": "text", "text": "E.5Proof of Lemma D.7 ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Proof. Based on Lemma D.6, for any fixed $\\textit{n}\\in\\:[N]$ , with probability at least $1\\,-\\,\\delta$ ,for any $(m,\\dot{k},h)\\in\\mathcal{M}\\times[K]\\times[H]$ wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\left\\|\\mathbf{w}_{m,h}^{k,J_{k},n}\\right\\|\\leq\\frac{16}{3}H d\\sqrt{M K}+\\sqrt{\\frac{2K}{3\\beta_{K}\\delta}}d^{3/2}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By taking union over $n,m,k,h$ , we have for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for all $n\\in[N]$ with probability $1-\\delta/2$ , we have ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\big\\|\\mathbf{w}_{m,h}^{k,J_{k},n}\\big\\|\\leq\\frac{16}{3}H d\\sqrt{M K}+\\sqrt{\\frac{4N M H K^{2}}{3\\beta_{K}\\delta}}d^{3/2}=B_{\\delta/2N M H K}.\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Based on Lemma J.7 and Lemma J.9, we have that for any $\\varepsilon>0$ and $\\delta>0$ , with probability at least $1-\\delta/2$ ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\vert\\ \\sum_{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\left[\\left(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\right)\\big(s^{l},a^{l}\\big)\\right]\\right\\vert_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\leq\\bigg(4H^{2}\\bigg[\\frac{d}{2}\\log\\bigg(\\frac{k+\\lambda}{\\lambda}\\bigg)+d\\log\\bigg(\\frac{B_{\\delta/2N M H K}}{\\varepsilon}\\bigg)+\\log\\frac{3}{\\delta}\\bigg]+\\frac{8k^{2}\\varepsilon^{2}}{\\lambda}\\bigg)^{1/2}}\\\\ &{\\leq2H\\bigg[\\frac{d}{2}\\log\\bigg(\\frac{k+\\lambda}{\\lambda}\\bigg)+d\\log\\bigg(\\frac{B_{\\delta/2N M H K}}{\\varepsilon}\\bigg)+\\log\\frac{3}{\\delta}\\bigg]^{1/2}+\\frac{2\\sqrt{2}k\\varepsilon}{\\sqrt{\\lambda}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "Here we set $\\begin{array}{r}{\\lambda=1,\\varepsilon=\\frac{H}{2\\sqrt{2}k}}\\end{array}$ 2 with probabilty at east - 8/2, wehave ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\displaystyle\\sum_{(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\left[\\left(V_{m,h+1}^{k}-{\\mathbb P}_{h}V_{m,h+1}^{k}\\right)\\big(s^{l},a^{l}\\big)\\right]\\right\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}}\\\\ &{\\leq2H\\sqrt{d}\\bigg[\\displaystyle\\frac{1}{2}\\log(k+1)+\\log\\bigg(\\displaystyle\\frac{B_{\\delta/2N M H K}}{\\frac{H}{2\\sqrt{2}k}}\\bigg)+\\log\\displaystyle\\frac{3}{\\delta}\\bigg]^{1/2}+H}\\\\ &{\\leq3H\\sqrt{d}\\bigg[\\displaystyle\\frac{1}{2}\\log(K+1)+\\log\\bigg(\\displaystyle\\frac{2\\sqrt{2}K B_{\\delta/2N M H K}}{H}\\bigg)+\\log\\displaystyle\\frac{3}{\\delta}\\bigg]^{1/2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "By applying union bound between (E.7) and (E.8), and define that $\\begin{array}{r}{C_{\\delta}=\\Big[\\frac{1}{2}\\log(K+1)+\\log\\frac{3}{\\delta}+}\\end{array}$ (2VKBs/2Mx)/,fnally we obtain that forall(m,k,h) M x [K] \u00d7 [H], ", "page_idx": 30}, {"type": "equation", "text": "$$\n\\left\\|\\sum_{(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\left[\\left(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\right)\\big(s^{l},a^{l}\\big)\\right]\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq3H\\sqrt{d}C_{\\delta},\n$$", "text_format": "latex", "page_idx": 30}, {"type": "text", "text": "with probability at least $1-\\delta$ ", "page_idx": 30}, {"type": "text", "text": "E.6Proof of Lemma D.8 ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Proof. We denote the inner product over $\\boldsymbol{S}$ by $\\langle\\cdot,\\cdot\\rangle_{\\cal{S}}$ . Based on $\\mathbb{P}_{h}(\\cdot|s,a)=\\langle\\phi(s,a),\\mu_{h}(\\cdot)\\rangle_{S}$ in Definition 4.1, we have ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathfrak{s}_{h}V_{m,h+1}^{k}(s,a)=\\phi(s,a)^{\\top}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{s}}\\\\ &{\\qquad\\qquad=\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\bigl(\\Lambda_{m,h}^{k}\\bigr)\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{s}}\\\\ &{\\qquad\\qquad=\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\Biggl(\\underset{(s^{l},a^{l},s^{l^{\\prime}})\\in U_{m,h}(k)}{\\sum}\\phi\\bigl(s^{l},a^{l}\\bigr)\\phi\\bigl(s^{l},a^{l}\\bigr)^{\\top}+\\lambda\\mathbf{I}\\biggr)\\bigl\\langle\\mu_{h},V_{m,h+1}^{k}\\bigr\\rangle_{s}}\\\\ &{\\qquad\\qquad=\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\Biggl(\\underset{(s^{l},a^{l},s^{l^{\\prime}})\\in U_{m,h}(k)}{\\sum}\\phi\\bigl(s^{l},a^{l}\\bigr)\\bigl(\\mathbb{P}_{h}V_{m,h+1}^{k}\\bigr)\\bigl(s^{l},a^{l}\\bigr)+\\lambda\\mathbf{I}\\bigl\\langle\\mu_{h},V_{m,h+1}^{k}\\bigr\\rangle_{s}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Here the last equality uses $\\mathbb{P}_{h}\\mathopen{}\\mathclose\\bgroup\\left(\\cdot\\vert s,a\\aftergroup\\egroup\\right)=\\mathopen{}\\mathclose\\bgroup\\left\\langle\\phi(s,a),\\pmb{\\mu}_{h}(\\cdot)\\aftergroup\\egroup\\right\\rangle_{S}$ again. Then we can separate the following error into three parts, ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\\\ &{=\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\qquad\\qquad\\qquad\\qquad\\qquad\\big[r_{h}\\big(s^{l},a^{l}\\big)+V_{m,h+1}^{k}(s^{l})\\big]\\phi\\big(s^{l},a^{l}\\big)-r_{h}(s,a)}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad(s^{l},a^{l},s^{l})\\in U_{m,h}(k)}\\\\ &{\\qquad-\\;\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\sum_{(s^{l},a^{l},s^{l})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\big(\\mathbb{P}_{h}V_{m,h+1}^{k}\\big)\\big(s^{l},a^{l}\\big)+\\lambda\\mathbf{I}\\big\\langle\\mu_{h},V_{m,h+1}^{k}\\big\\rangle_{s}}\\\\ &{=\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\sum_{(s^{l},a^{l},s^{l})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\big[\\big(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\big)\\big(s^{l},a^{l}\\big)\\big]\\Bigg)}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n-\\underbrace{\\lambda\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{\\mathcal{S}}}_{\\mathrm{(iii)}}.\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Here the first equality holds due to (E.9). We now provide an upper bound for each of the terms in (E.10). ", "page_idx": 31}, {"type": "text", "text": "Bounding Term (i) in (E.10): using Cauchy-Schwarz inequality and Lemma D.7, with probability at least $1-\\delta$ ,for ali $(m,k,h)\\in\\mathcal{M}\\stackrel{\\cdot}{\\times}[K]\\times[H]$ and for any $(s,a)\\in S\\times A$ wehave ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\big(\\Lambda_{m,h}^{k}\\big)^{-1}\\Bigg(\\underset{(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}{\\sum}\\phi\\big(s^{l},a^{l}\\big)\\big[\\big(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\big)\\big(s^{l},a^{l}\\big)\\big]\\Bigg)}\\\\ &{\\leq\\Bigg\\|\\underset{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}{\\sum}\\phi\\big(s^{l},a^{l}\\big)\\big[\\big(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\big)\\big(s^{l},a^{l}\\big)\\big]\\Bigg\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\leq3H\\sqrt{d}C_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "text", "text": "Bounding Term (ii) in (E.10): we first note that ", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\left(\\sum_{(s^{l},a^{l},s^{\\prime}}\\!\\!\\sum_{\\ell_{m,h}(k)}\\!\\!r_{h}\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)\\right)-r_{h}(s,a)\\right.}\\\\ &{\\,\\,\\left.=\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\left(\\sum_{(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}r_{h}\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)\\right)-\\phi(s,a)^{\\top}\\theta_{h}}\\end{array}\n$$", "text_format": "latex", "page_idx": 31}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\underset{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}{\\sum}r_{h}\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)-\\Lambda_{m,h}^{k}\\theta_{h}\\Bigg)}\\\\ &{=\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\underset{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}{\\sum}r_{h}\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)-\\underset{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}{\\sum}\\phi\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)^{\\top}\\theta_{h}-}\\\\ &{=\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\underset{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}{\\sum}r_{h}\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)-\\underset{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}{\\sum}\\phi\\big(s^{l},a^{l}\\big)r_{h}\\big(s^{l},a^{l}\\big)-\\lambda\\theta_{h}}\\\\ &{=-\\lambda\\phi\\big(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\theta_{h},}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the first and fourth equality holds due to the definition $r_{h}(s,a)=\\langle\\phi(s,a),\\pmb{\\theta}_{h}\\rangle$ from Definition 1, th third equltyusesthe defnition of ${\\pmb{\\Lambda}}_{m,h}^{k}$ Next we can obtai that ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-\\lambda\\phi(s,a)^{\\top}\\big(\\mathbf{\\Lambda}_{\\Delta_{m,h}}^{k}\\big)^{-1}\\theta_{h}\\leq\\lambda\\|\\phi(s,a)\\|_{(\\mathbf{\\Lambda}_{\\Delta_{m,h}}^{k})^{-1}}\\|\\theta_{h}\\|_{(\\mathbf{\\Lambda}_{m,h}^{k})^{-1}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\sqrt{\\lambda}\\|\\phi(s,a)\\|_{(\\mathbf{\\Lambda}_{m,h}^{k})^{-1}}\\|\\theta_{h}\\|}\\\\ &{\\qquad\\qquad\\qquad\\leq\\sqrt{\\lambda d}\\|\\phi(s,a)\\|_{(\\mathbf{\\Lambda}_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where we use the fact that $\\lambda_{\\operatorname*{max}}\\big(\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\big)\\ \\leq\\ 1/\\lambda$ and $\\|\\pmb{\\theta}_{h}\\|\\leq\\sqrt{d}$ from Definition 4.1. By Combining (E.12) and (E.13), we obtain ", "page_idx": 32}, {"type": "equation", "text": "$$\nb(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\sum_{(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}r_{h}\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)\\Bigg)-r_{h}(s,a)\\leq\\sqrt{\\lambda d}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Bounding Term (i) in (E.10): we have ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\lambda\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\big\\langle\\mu_{h},V_{m,h+1}^{k}\\big\\rangle_{\\mathcal{S}}\\leq\\lambda\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\big\\|\\big\\langle\\mu_{h},V_{m,h+1}^{k}\\big\\rangle_{\\mathcal{S}}\\big\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}}}\\\\ &{}&{\\leq\\sqrt{\\lambda}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\big\\|\\big\\langle\\mu_{h},V_{m,h+1}^{k}\\big\\rangle_{\\mathcal{S}}\\big\\|}\\\\ &{}&{\\leq H\\sqrt{\\lambda}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\|\\mu_{h}\\|}\\\\ &{}&{\\leq H\\sqrt{\\lambda d}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "where the second inequality holds due to the fact that $\\lambda_{\\operatorname*{max}}\\big(\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\big)\\leq1/\\lambda$ the third inequality uses the fact that $V_{m,h+1}^{k}\\leq H$ and the last inequality follows from $\\|\\pmb{\\mu}_{h}\\|\\leq\\sqrt{d}$ in Definition 4.1. ", "page_idx": 32}, {"type": "text", "text": "Combine Terms (i)(ii)(iii) together: combine (E.11), (E.14) and (E.15), then set $\\lambda\\,=\\,1$ ,with probability at least $1-\\delta$ ,weget ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\right|\\leq\\left(3H C_{\\delta}+\\sqrt{\\lambda d}+H\\sqrt{\\lambda d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq5H\\sqrt{d}C_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "This completes the proof. ", "page_idx": 32}, {"type": "text", "text": "E.7 Proof of Lemma D.9 ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Proof. Recall from Definition D.1, ", "page_idx": 32}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-l_{m,h}^{k}(s,a)=Q_{m,h}^{k}(s,a)-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\\\ &{\\phantom{-\\operatorname*{max}{\\phi}}=\\operatorname*{min}\\left\\{\\begin{array}{l l}{\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n},H-h+1\\right\\}^{+}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\\\ &{\\phantom{-\\operatorname*{max}{\\phi}}\\leq\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\\\ &{\\phantom{-\\operatorname*{max}{\\phi}}=\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n}-\\phi(s,a)^{\\top}\\widehat{\\mathbf w}_{m,h}^{k}+\\phi(s,a)^{\\top}\\widehat{\\mathbf w}_{m,h}^{k}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\end{array}\n$$", "text_format": "latex", "page_idx": 32}, {"type": "text", "text": "Bounding Term $I_{1}$ : based on Lemma D.5, for any fixed $n\\in[N]$ , for any $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and for any $(s,a)\\in S\\times A$ , with probability at least $1-\\delta^{2}$ ,we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\bigl|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\bigr|\\leq\\biggl(5\\sqrt{\\frac{2d\\log(1/\\delta)}{3\\beta_{K}}}+\\frac{4}{3}\\biggr)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "By taking union bound over $n$ , we have for all $n\\in[N]$ , with probability $1-\\delta^{2}$ , we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\bigl|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\bigr|\\leq\\left(5\\sqrt{\\frac{2d\\log\\bigl(\\sqrt{N}/\\delta\\bigr)}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "This indicates, for any $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and $(s,a)\\in S\\times A$ with probability at least $1-\\delta^{2}$ , we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\textbf{n}I_{1}=\\operatorname*{max}_{n\\in[N]}\\left|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\right|\\leq\\left(5\\sqrt{\\frac{2d\\log\\left(\\sqrt{N}/\\delta\\right)}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\lVert\\phi(s,a)\\rVert_{(\\Lambda_{m,h}^{k})^{-1}}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Bounding Term $I_{2}$ : based on Lemma D.8, with probability at least $1-\\delta$ ,for any $(m,h,k)\\in$ $\\mathcal{M}\\times[H]\\times[K]$ and $(s,a)\\in S\\times A$ ,wehave ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\big|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}^{k}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\big|\\leq5H\\sqrt{d}C_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Combine the two result above, by taking union bound, with probability at least $1-\\delta-\\delta^{2}$ ,for any $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and $(s,a)\\in S\\times A$ ,wehave ", "page_idx": 33}, {"type": "equation", "text": "$$\n-l_{m,h}^{k}(s,a)\\leq\\left(5H\\sqrt{d}C_{\\delta}+5\\sqrt{\\frac{2d\\log\\left(\\sqrt{N}/\\delta\\right)}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "This completes the proof. ", "page_idx": 33}, {"type": "text", "text": "E.8Proof of Lemma D.10 ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Proof. Recall from Definition D.1, ", "page_idx": 33}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)=r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-Q_{m,h}^{k}(s,a).\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Note that ", "page_idx": 33}, {"type": "equation", "text": "$$\nQ_{m,h}^{k}(s,a)=\\operatorname*{min}\\Big\\{\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n},H-h+1\\Big\\}^{+}\\leq\\operatorname*{max}_{n\\in[N]}\\phi(x,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "Note that $\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\leq\\sqrt{1/\\lambda}\\|\\phi(s,a)\\|\\leq1$ for all $\\phi(s,a)$ . Define $\\mathcal C(\\varepsilon)$ to be a $\\varepsilon$ -cover of $\\left\\{\\phi\\mid\\|\\phi\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\leq1\\right\\}$ . Based on Lemma J.8, we have $|{\\mathcal{C}}(\\varepsilon)|\\leq(3/\\varepsilon)^{d}$ ", "page_idx": 33}, {"type": "text", "text": "$\\phi(s,a)~\\in~\\mathcal{C}(\\varepsilon)$ $\\phi(s,a)^{\\top}{\\mathbf w}_{m,h}^{k,J_{k},n}\\sim{\\mathcal N}\\Big(\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}},\\phi(s,a)^{\\top}{\\Sigma}_{m,h}^{k,J_{k}}\\phi(s,a)\\Big)$ $n\\,\\in\\,[N]$ define ", "page_idx": 33}, {"type": "equation", "text": "$$\nZ_{k}=\\frac{r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\pmb{\\mu}_{m,h}^{k,J_{k}}}{\\sqrt{\\phi(s,a)^{\\top}\\pmb{\\Sigma}_{m,h}^{k,J_{k}}\\phi(s,a)}}.\n$$", "text_format": "latex", "page_idx": 33}, {"type": "text", "text": "When $|Z_{k}|<1$ , by Gaussian concentration Lemma J.10, we have ", "page_idx": 33}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big(\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}\\geq r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\Big)\n$$", "text_format": "latex", "page_idx": 33}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{=\\mathbb{P}\\Bigg(\\frac{\\phi\\left(s,a\\right)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-\\phi\\left(s,a\\right)^{\\top}\\mu_{m,h}^{k,J_{k}}}{\\sqrt{\\phi\\left(s,a\\right)^{\\top}\\mathbf{D}_{m,h}^{k,J_{k}}\\phi\\left(s,a\\right)}}\\geq\\frac{r_{h}\\left(s,a\\right)+\\mathbb{P}_{h}V_{m,h+1}^{k}\\left(s,a\\right)-\\phi\\left(s,a\\right)^{\\top}\\mu_{m,h}^{k,J_{k}}}{\\sqrt{\\phi\\left(s,a\\right)^{\\top}\\mathbf{D}_{m,h}^{k,J_{k}}\\phi\\left(s,a\\right)}}\\Bigg)}\\\\ &{=\\mathbb{P}\\Bigg(\\frac{\\phi\\left(s,a\\right)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-\\phi\\left(s,a\\right)^{\\top}\\mu_{m,h}^{k,J_{k}}}{\\sqrt{\\phi\\left(s,a\\right)^{\\top}\\mathbf{D}_{m,h}^{k,J_{k}}\\phi\\left(s,a\\right)}}\\geq Z_{k}\\Bigg)}\\\\ &{\\geq\\frac{1}{2\\sqrt{2\\pi}}\\exp(-Z_{k}^{2}/2)}\\\\ &{\\geq\\frac{1}{2\\sqrt{2e\\pi}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Consider the numerator of $Z_{k}$ ", "text_level": 1, "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\right|}\\\\ &{\\leq\\left|r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\right|+\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\right|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Based on Lemma D.8, with probablity at least $1-\\delta$ ,wehave ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}|\\leq5H\\sqrt{d}C_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "From (E.4), we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\phi(s,a)^{\\top}\\big(\\mu_{m,h}^{k,J_{k}}-\\widehat\\mathbf{w}_{m,h}^{k}\\big)\\leq4H\\sqrt{M K d/\\lambda}\\sum_{i=1}^{k-1}\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\Lambda_{m,h}^{j}\\big)\\Big)^{J_{j}}\\|\\phi(s,a)\\|.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Recallthe proof of Lemma D.5, we set $\\eta_{m,j}=1/(4\\lambda_{\\operatorname*{max}}(\\Lambda_{m,h}^{j})),J_{j}\\geq2\\kappa_{j}\\log(1/\\epsilon)$ then we have for all $\\in[K],\\,(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}(\\mathbf{A}_{m,h}^{j}))^{J_{j}}\\leq\\epsilon$ set $\\epsilon=1/4H M K d$ and $\\lambda=1$ ,we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\bigl|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\bigr|\\leq4H\\sqrt{M K d}\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i}\\|\\phi(s,a)\\|}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\sum_{i=1}^{k-1}\\epsilon^{k-i-1}\\displaystyle\\frac{1}{4M H K d}4H\\sqrt{M K d}\\sqrt{M K}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq\\displaystyle\\frac{4}{3}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "So, with probablity at least $1-\\delta$ , we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\left|\\boldsymbol{r}_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\boldsymbol{\\mu}_{m,h}^{k,J_{k}}\\right|\\leq\\left(5H\\sqrt{d}C_{\\delta}+\\frac{4}{3}\\right)\\|\\phi(s,a)\\|_{(\\boldsymbol{\\Lambda}_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "Consider the denominator of $Z_{k}$ : recall from the defniion of $\\Sigma_{m,h}^{k,J_{k}}$ from Proposition D.3,then we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\phi(s,a)^{\\top}\\mathbf{\\Sigma}_{m,h}^{k,J_{k}}\\phi(s,a)}\\\\ &{\\displaystyle=\\sum_{i=1}^{k}\\frac{1}{\\beta_{m,i}}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{I}-\\mathbf{A}^{2J_{i}}\\big)\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}(\\mathbf{I}+\\mathbf{A}_{i})^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\cdot\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{\\displaystyle\\geq\\sum_{i=1}^{k}\\frac{1}{2\\beta_{m,i}}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{I}-\\mathbf{A}^{2J_{i}}\\big)\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\cdot\\cdot\\mathbf{A}_{k}^{J_{k}}\\phi(s,a),}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "text", "text": "where we used the fact that $\\begin{array}{r}{\\frac{1}{2}{\\bf I}\\preccurlyeq({\\bf I}+{\\bf A}_{k})^{-1}}\\end{array}$ . Then we have ", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\Sigma_{m,h}^{k,J_{k}}\\phi(s,a)}\\\\ &{\\quad\\geq\\displaystyle\\sum_{i=1}^{k}\\frac{1}{2\\beta_{m,i}}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\cdot\\cdot\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}-\\mathbf{A}_{i}^{J_{i}}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\mathbf{A}_{i}^{J_{i}}\\big)\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\cdot\\cdot\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\end{array}\n$$", "text_format": "latex", "page_idx": 34}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{=\\frac{1}{2\\beta_{K}}\\sum_{i=1}^{k-1}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\dots\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}-\\big(\\mathbf{A}_{m,h}^{i+1}\\big)^{-1}\\big)\\mathbf{A}_{i+1}^{J_{i+1}}\\cdot\\dots\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}}\\\\ &{\\quad-\\,\\frac{1}{2\\beta_{K}}\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\cdot\\dots\\mathbf{A}_{1}^{J_{1}}\\big(\\mathbf{A}_{m,h}^{1}\\big)^{-1}\\mathbf{A}_{1}^{J_{1}}\\cdot\\dots\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{\\quad+\\,\\frac{1}{2\\beta_{K}}\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\phi(s,a).}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "By the definition of ${\\bf A}_{m,h}^{i}$ and Woodbury formula, we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}-\\left(\\mathbf{A}_{m,h}^{i+1}\\right)^{-1}=\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}-\\left(\\mathbf{A}_{m,h}^{i}+\\displaystyle\\sum_{(s^{l},a^{l},s^{\\prime}^{l})\\in U_{m,h}(k)}\\phi(s^{l},a^{l})\\phi(s^{l},a^{l})^{\\top}\\right)^{-1}}\\\\ &{\\qquad\\qquad\\qquad=(\\mathbf{A}_{m,h}^{i})^{-1}\\varphi\\big(\\mathbf{I}_{n}+\\varphi^{\\top}(\\mathbf{A}_{m,h}^{i})^{-1}\\varphi\\big)^{-1}\\varphi^{\\top}(\\mathbf{A}_{m,h}^{i})^{-1},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $\\varphi$ is a matrix with the dimension of $d\\times n$ $n$ is the number difference of $\\phi(s^{l},a^{l})$ between $\\left(\\mathbf{A}_{m,h}^{i}\\right)^{-1}$ and $\\left(\\Lambda_{m,h}^{i+1}\\right)^{-1}$ (i. we concatenate all $\\phi(s^{l},a^{l})$ in to the matrix $\\varphi$ ). Note that $n\\leq M$ we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\!\\cdot\\!\\dots\\mathbf{A}_{i+1}^{J_{i+1}}\\Big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}-\\big(\\mathbf{A}_{m,h}^{i+1}\\big)^{-1}\\Big)\\mathbf{A}_{i+1}^{J_{i+1}}\\!\\cdot\\!\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{=\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\!\\cdot\\!\\dots\\mathbf{A}_{i+1}^{J_{i+1}}\\Big(\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi(\\mathbf{I}_{n}+\\varphi^{\\top}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi\\big)^{-1}\\varphi^{\\top}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\Big)\\mathbf{A}_{i+1}^{J_{i+1}}\\!\\cdot\\!\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{\\leq\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\!\\cdot\\!\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi\\varphi^{\\top}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\mathbf{A}_{i+1}^{J_{i+1}}\\!\\cdot\\!\\mathbf{A}_{k}^{J_{k}}\\phi(s,a)}\\\\ &{=\\|\\phi(s,a)^{\\top}\\mathbf{A}_{k}^{J_{k}}\\!\\cdot\\!\\mathbf{A}_{i+1}^{J_{i+1}}\\big(\\mathbf{A}_{m,h}^{i}\\big)^{-1}\\varphi\\|_{2}^{2}}\\\\ &{\\leq\\|\\mathbf{A}_{k}^{J_{k}}\\!\\cdot\\!\\mathbf{A}_{i+1}^{J_{i+1}}(\\mathbf{A}_{m,h}^{i})^{-1/2}\\phi(s,a)\\|_{2}^{2}\\cdot\\big\\|(\\mathbf{A}_{m,h}^{i})^{-1/2}\\varphi\\big\\|_{F}^{2}}\\\\ &{\\leq\\displaystyle\\prod_{j=i+1}^{k}\\Big(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\mathbf{A}_{m,h}^{j}\\big \n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where $\\left\\|\\cdot\\right\\|_{F}$ is Frobenius norm and the last inequality is due to $\\|\\mathbf{A}^{-\\frac{1}{2}}\\mathbf{X}\\|_{F}^{2}=\\operatorname{tr}(\\mathbf{X}^{\\top}\\mathbf{A}^{-1}\\mathbf{X})$ and (E.2). Therefore, we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\phi(s,a)^{\\top}\\Sigma_{m,h}^{k,J_{k}}\\phi(s,a)}\\\\ &{\\displaystyle\\geq\\frac{1}{2\\beta_{K}}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}^{2}-\\frac{1}{2\\beta_{K}}\\prod_{i=1}^{k}\\left(1-2\\eta_{m,i}\\lambda_{\\operatorname*{min}}\\big(\\Lambda_{m,h}^{i}\\big)\\right)^{2J_{i}}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{1})^{-1}}^{2}}\\\\ &{\\displaystyle\\qquad-\\,\\frac{1}{2\\beta_{K}}\\sum_{i=1}^{k-1}\\prod_{j=i+1}^{k}\\left(1-2\\eta_{m,j}\\lambda_{\\operatorname*{min}}\\big(\\Lambda_{m,h}^{j}\\big)\\right)^{2J_{j}}\\mathrm{tr}\\,\\big(\\varphi^{\\top}\\big(\\Lambda_{m,h}^{i}\\big)^{-1}\\varphi\\big)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{i})^{-1}}^{2}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "Similar to the proof of Lemma D.5, note that $\\mathrm{tr}\\left(\\varphi^{\\top}(\\mathbf{A}_{m,h}^{i})^{-1}\\varphi\\right)\\,\\leq\\,M$ , when we choose $J_{j}\\ \\geq$ $2\\kappa_{j}\\log(3k M)$ ,we have ", "page_idx": 35}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\Vert\\phi(s,a)\\Vert_{\\mathbf{\\Sigma}_{m,h}^{k,J_{k}}}\\geq\\frac{1}{2\\sqrt{\\beta_{K}}}\\bigg(\\Vert\\phi(s,a)\\Vert_{(\\Lambda_{m,h}^{k})^{-1}}-\\frac{\\Vert\\phi(s,a)\\Vert}{(3K M)^{k}}-\\sum_{i=1}^{k-1}\\frac{\\sqrt{M}}{(3k M)^{k-i}}\\Vert\\phi(s,a)\\Vert\\bigg)}}\\\\ &{}&{\\geq\\frac{1}{2\\sqrt{\\beta_{K}}}\\bigg(\\Vert\\phi(s,a)\\Vert_{(\\Lambda_{m,h}^{k})^{-1}}-\\frac{1}{3\\sqrt{k M}}\\Vert\\phi(s,a)\\Vert-\\frac{1}{6\\sqrt{k M}}\\Vert\\phi(s,a)\\Vert\\bigg)}\\\\ &{}&{\\geq\\frac{1}{4\\sqrt{\\beta_{K}}}\\Vert\\phi(s,a)\\Vert_{(\\Lambda_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 35}, {"type": "text", "text": "where we used th fct that $\\lambda_{\\operatorname*{min}}\\big(\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\big)\\geq1/k M$ and $\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\geq1/\\sqrt{k M}\\|\\phi(s,a)\\|$ Therefore, according to (E.17) and (E.18), with probablity at least $1-\\delta$ , it holds that ", "page_idx": 35}, {"type": "equation", "text": "$$\n|Z_{k}|=\\left|\\frac{r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}}{\\sqrt{\\phi(s,a)^{\\top}\\Sigma_{m,h}^{k,J_{k}}\\phi(s,a)}}\\right|\n$$", "text_format": "latex", "page_idx": 35}, {"type": "equation", "text": "$$\n\\leq\\frac{5H\\sqrt{d}C_{\\delta}+\\frac{4}{3}}{\\frac{1}{4\\sqrt{\\beta_{K}}}},\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Wwhich imples $|Z_{k}|<1$ when $\\begin{array}{r}{\\frac{1}{\\sqrt{\\beta_{K}}}=20H\\sqrt{d}C_{\\delta}+\\frac{16}{3}}\\end{array}$", "page_idx": 36}, {"type": "text", "text": "Till now we have proved that for any fixed $\\phi(s,a)\\in\\mathcal{C}(\\varepsilon)$ and for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ for any fixed $n\\in[N]$ , with probablity at least $1-\\delta$ ,wehave ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big(\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\geq0\\Big)\\geq\\frac{1}{2\\sqrt{2e\\pi}}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "By taking union bound over $n\\in[N]$ , with probablity at least $1-\\delta$ , we have ", "page_idx": 36}, {"type": "text", "text": "$\\gg\\Big(\\operatorname*{max}_{n\\in[N]}\\Big\\{\\phi(s,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n}-r_{h}(s,a)-\\mathbb P_{h}V_{m,h+1}^{k}(s,a)\\Big\\}\\geq0\\Big)\\geq1-\\Big(1-\\frac{1}{2\\sqrt{2e\\pi}}\\Big)^{N}=1-c_{0}^{\\prime}\\,^{N}$ where $\\begin{array}{r}{c_{0}^{\\prime}=1\\!-\\!\\frac{1}{2\\sqrt{2e\\pi}}}\\end{array}$ Threfore, fo any ixed $\\phi(s,a)\\in\\mathcal{C}(\\varepsilon)$ and oral $(m,h,k)\\in\\mathcal{M}\\!\\times\\![H]\\!\\times\\![K]$ with probabilityat least $(1-\\delta)\\big(1-{c_{0}^{\\prime}}^{N}\\big)>1-\\delta-{c_{0}^{\\prime}}^{N}$ , we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\{\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\right\\}\\geq0.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Next for any $\\phi\\,=\\,\\phi(s,a)$ , we can find $\\phi^{\\prime}\\in\\mathcal{C}(\\varepsilon)$ such that $\\|\\phi-\\phi^{\\prime}\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq\\,\\varepsilon$ We define $\\Delta\\phi=\\phi-\\phi^{\\prime}$ . Recall from Definition 4.1, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)=\\phi(s,a)^{\\top}\\theta_{h}+\\phi(s,a)^{\\top}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{\\mathcal{S}}\\stackrel{\\mathrm{def}}{=}\\phi(s,a)^{\\top}{\\mathbf w}_{m,h}^{k},}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "where $\\mathbf{w}_{m,h}^{k}\\,=\\,\\pmb{\\theta}_{h}\\,+\\,\\langle\\pmb{\\mu}_{h},V_{m,h+1}^{k}\\rangle_{S}$ Note that $\\operatorname*{max}\\{\\|\\mu_{h}(S)\\|,\\|\\pmb{\\theta}_{h}\\|\\}\\,\\le\\,\\sqrt{d}$ and $V_{m,h+1}^{k}\\leq$ $H-h\\leq{\\dot{H}}$ , thus we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\mathbf{w}_{m,h}^{k}\\|\\leq\\|\\pmb{\\theta}_{h}\\|+\\|\\langle\\pmb{\\mu}_{h},V_{m,h+1}^{k}\\rangle_{S}\\|\\leq\\sqrt{d}+H\\sqrt{d}\\leq2H\\sqrt{d}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Then we define the regression error $\\Delta\\mathbf{w}_{m,h}^{k}=\\mathbf{w}_{m,h}^{k}-\\mathbf{w}_{m,h}^{k,J_{k},n}$ k,J,n. Thus we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\big\\{\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\big\\}=\\operatorname*{max}_{n\\in[N]}\\big\\{-\\phi(s,a)^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\big\\}.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Then by Cauchy-Schwarz inequality, we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\phantom{\\omega^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}}=\\boldsymbol{\\phi^{\\prime}}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}+\\Delta\\boldsymbol{\\phi}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}}&{}\\\\ {\\phantom{\\omega^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}}\\geq\\boldsymbol{\\phi^{\\prime}}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}-\\|\\Delta\\boldsymbol{\\phi}\\|\\cdot\\|\\Delta\\mathbf{w}_{m,h}^{k}\\|}&{}\\\\ {\\phantom{\\omega^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}}\\geq\\boldsymbol{\\phi^{\\prime}}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}-\\sqrt{M K}\\varepsilon\\|\\Delta\\mathbf{w}_{m,h}^{k}\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "By triangle inequality, with probability at least $1-\\delta$ ,wehave ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\|\\Delta\\mathbf{w}_{m,h}^{k}\\|\\leq\\|\\mathbf{w}_{m,h}^{k}\\|+\\|\\mathbf{w}_{m,h}^{k,J_{k},n}\\|\\leq2H\\sqrt{d}+B_{\\delta/N M H K}}\\end{array}\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Denote $\\alpha_{\\delta}\\,=\\,\\sqrt{M K}\\big(2H\\sqrt{d}+B_{\\delta/N M H K}\\big)$ . Then, for all $(m,h,k)\\,\\in\\,\\mathcal{M}\\,\\times\\,[H]\\,\\times\\,[K]$ , with probability at least $1-\\delta$ , we have ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\{\\boldsymbol{\\phi}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\right\\}\\geq\\operatorname*{max}_{n\\in[N]}\\left\\{\\boldsymbol{\\phi}^{\\prime}{}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\right\\}-\\alpha_{\\delta}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Recallfrom (E.19), by taking union bound, with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime}^{N}-2\\delta$ , for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\stackrel{}{\\times}[K]$ and for all $(s,a)\\in S\\stackrel{}{\\times}{\\mathcal{A}}$ wehave ", "page_idx": 36}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\{\\boldsymbol{\\phi}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\right\\}\\geq-\\alpha_{\\delta}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "Finally, with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime}^{N}-2\\delta$ , for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and for all $(s,a)\\overset{\\cdot}{\\in}S\\times\\overset{\\cdot}{A}$ , we have ", "page_idx": 36}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)\\leq\\alpha_{\\delta}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 36}, {"type": "text", "text": "This completes the proof. ", "page_idx": 36}, {"type": "text", "text": "E.9Proof of Lemma D.12 ", "text_level": 1, "page_idx": 37}, {"type": "text", "text": "Prof. For simplicity, we denote $(s_{m,h}^{k},a_{m,h}^{k})$ $z_{m,h}^{k}$ Then we consider the follwing mappings $\\left(\\nu_{M},\\nu_{K}\\right):\\left[M K\\right]\\to\\left[M\\right]\\times\\left[K\\right]$ ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\nu_{M}(\\tau)=\\tau(\\mathrm{mod}M),\\qquad\\nu_{K}=\\Biggl\\lceil\\frac{\\tau}{M}\\Biggr\\rceil,\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where we set $\\nu_{M}(\\tau)=M$ if $M\\vert\\tau$ . Next, for any $\\tau\\geq0$ , we define ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\bar{\\mathbf{A}}_{h}^{\\tau}=\\lambda\\mathbf{I}+\\displaystyle\\sum_{u=1}^{\\tau M}\\phi\\Bigl(z_{\\nu_{M}(u),h}^{\\nu_{K}(u)}\\Bigr)\\phi\\Bigl(z_{\\nu_{M}(u),h}^{\\nu_{K}(u)}\\Bigr)^{\\top},\\quad\\mathrm{for}\\;\\tau>0,}\\\\ {\\bar{\\mathbf{A}}_{h}^{0}=\\lambda\\mathbf{I},\\quad\\mathrm{for}\\;\\tau=0.}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "We denote $\\sigma\\,=\\,\\{\\sigma_{1},\\ldots,\\sigma_{n}\\}$ as the synchronization episodes, where $\\sigma_{i}\\,\\in\\,[K]$ , we also denote $\\sigma_{0}\\,=\\,0$ . Then we separate the episodes $k\\,=\\,1,\\ldots,K$ into two groups based on the following condition, ", "page_idx": 37}, {"type": "equation", "text": "$$\n1\\leq\\frac{\\operatorname*{det}(\\bar{\\mathbf{Lambda}}_{h}^{\\sigma_{i}})}{\\operatorname*{det}(\\bar{\\mathbf{Lambda}}_{h}^{\\sigma_{i-1}})}\\leq3.\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "Note that the left inequality always holds due to $\\bar{\\mathbf{A}}_{h}^{\\sigma_{i-1}}\\preccurlyeq\\bar{\\mathbf{A}}_{h}^{\\sigma_{i}}$ and the trivial fact that $\\mathbf{A}\\preccurlyeq\\mathbf{B}\\Rightarrow$ $\\operatorname*{det}(\\mathbf{A})\\leq\\,\\operatorname*{det}(\\mathbf{B}).$ Then we define that $I_{1}\\,=\\,\\{k\\,\\in\\,\\mathbb{N}^{+},k\\,\\in\\,[\\sigma_{i-1},\\sigma_{i}),\\forall i\\,\\in\\,[n]|(\\mathrm{E}.20)$ is true} and $I_{2}^{'}=\\{k\\in\\mathbb{N}^{+},k\\in[\\sigma_{i-1},\\sigma_{i}),\\forall i\\in[n]|(\\mathbb{E}.\\dot{2}0)$ is false}, then $[K]=I_{1}\\cup I_{2}\\cup\\{K\\}$ . For any $k\\in[\\sigma_{i-1},\\sigma_{i})$ and $k\\in I_{1}$ , note that $\\bar{\\mathbf{Lambda}}_{h}^{\\sigma_{i-1}}\\preccurlyeq\\mathbf{\\Lambda}_{m,h}^{k}\\preccurlyeq\\bar{\\mathbf{\\Lambda}}_{h}^{k}\\preccurlyeq\\bar{\\mathbf{\\Lambda}}_{h}^{\\sigma_{i}}$ , thus for any $m\\in\\mathcal{M}$ ,we have ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\phi(z_{m,h}^{k})\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq\\left\\|\\phi\\big(z_{m,h}^{k}\\big)\\right\\|_{(\\bar{\\Lambda}_{h}^{k})^{-1}}\\!\\sqrt{\\frac{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{k})}{\\operatorname*{det}(\\Lambda_{m,h}^{k})}}}\\\\ &{\\qquad\\qquad\\qquad\\leq\\left\\|\\phi\\big(z_{m,h}^{k}\\big)\\right\\|_{(\\bar{\\Lambda}_{h}^{k})^{-1}}\\!\\sqrt{\\frac{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i}})}{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i-1}})}}}\\\\ &{\\qquad\\qquad\\qquad\\leq2\\!\\left\\|\\phi\\big(z_{m,h}^{k}\\big)\\right\\|_{(\\bar{\\Lambda}_{h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where the first inequality follows from Lemma J.12, the second inequality follows from the trivial fact that $\\mathbf{A}\\prec\\mathbf{B}\\Rightarrow\\operatorname*{det}(\\mathbf{A})\\leq\\operatorname*{det}(\\mathbf{B})$ , and the final inequality holds because $k\\in I_{1}$ . Then we will bound the summation for $k\\in I_{1}$ and $k\\in I_{2}$ respectively. ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{k\\in I_{1}\\cup\\{K\\}}\\displaystyle\\sum_{m\\in\\mathcal{M}}\\|\\phi(z_{m,h}^{k})\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq\\sqrt{M K\\displaystyle\\sum_{m\\in\\mathcal{M}}\\displaystyle\\sum_{k\\in I_{1}\\cup\\{K\\}}\\|\\phi(z_{m,h}^{k})\\|_{(\\Lambda_{m,h}^{k})^{-1}}^{2}}}\\\\ &{\\leq2\\sqrt{M K\\displaystyle\\sum_{m\\in\\mathcal{M}}\\displaystyle\\sum_{k\\in I_{1}\\cup\\{K\\}}\\|\\phi(z_{m,h}^{k})\\|_{(\\Lambda_{h}^{k})^{-1}}^{2}}}\\\\ &{\\leq2\\sqrt{M K\\displaystyle\\sum_{m\\in\\mathcal{M}}\\displaystyle\\sum_{k=1}^{K}\\|\\phi(z_{m,h}^{k})\\|_{(\\Lambda_{h}^{k})^{-1}}^{2}}}\\\\ &{\\leq2\\sqrt{M K\\log\\left(\\displaystyle\\frac{\\mathrm{det}(\\Lambda_{h}^{k})}{\\mathrm{det}(\\lambda\\mathrm{d})}\\right)},}\\end{array}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "text", "text": "where the first inequality follows from Cauchy-Schwarz inequality, the second inequality holds due to (E.21), the final equality follows from Lemma J.1 and $\\mathbf{\\Lambda}_{h}^{K}\\mathbf{\\Lambda}^{-}=$ $\\begin{array}{r}{\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\phi\\bigl(s_{m,h}^{k},a_{m,h}^{k}\\bigr)\\phi\\bigl(s_{m,h}^{k},a_{m,h}^{k}\\bigr)^{\\top}+\\lambda\\mathbf{I}.}\\end{array}$ ", "page_idx": 37}, {"type": "text", "text": "For any interval $[\\sigma_{i-1},\\sigma_{i})$ , define $\\Delta_{i}=\\sigma_{i}-\\sigma_{i-1}-1$ , we calculate that ", "page_idx": 37}, {"type": "equation", "text": "$$\n\\sum_{k=\\sigma_{i-1}}^{\\sigma_{i}-1}\\big\\|\\phi(z_{m,h}^{k})\\big\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq\\sqrt{\\Delta_{i}\\sum_{k=\\sigma_{i-1}}^{\\sigma_{i}-1}\\big\\|\\phi(z_{m,h}^{k})\\big\\|_{(\\Lambda_{m,h}^{k})^{-1}}^{2}}\n$$", "text_format": "latex", "page_idx": 37}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\le\\sqrt{\\Delta_{i}\\log\\left(\\frac{\\operatorname*{det}(\\boldsymbol{\\Lambda}_{m,h}^{\\sigma_{i}-1})}{\\operatorname*{det}(\\boldsymbol{\\Lambda}_{m,h}^{\\sigma_{i}-1})}\\right)}}\\\\ &{\\le\\sqrt{\\gamma},}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where the last inequality follows from the synchronization condition (3.3). ", "page_idx": 38}, {"type": "text", "text": "Defne $\\begin{array}{r}{R_{h}=\\left\\lceil\\log\\left(\\frac{\\operatorname*{det}(\\mathbf{A}_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathbf{I})}\\right)\\right\\rceil}\\end{array}$ , note that $\\sigma_{n}\\leq K$ , then we can find that ", "page_idx": 38}, {"type": "equation", "text": "$$\nR_{h}\\geq\\log\\bigg(\\frac{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{n}})}{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{0}})}\\bigg)=\\sum_{i=1}^{n}\\log\\bigg(\\frac{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i}})}{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i-1}})}\\bigg).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "We can claim that $I_{2}$ has at most $R_{h}$ synchronization episodes, otherwise ", "page_idx": 38}, {"type": "equation", "text": "$$\nR_{h}\\geq\\sum_{i=1}^{n}\\log\\left(\\frac{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i}})}{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i-1}})}\\right)\\geq\\sum_{i\\in\\{i|\\sigma_{i-1}\\in I_{2}\\}}\\log\\left(\\frac{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i}})}{\\operatorname*{det}(\\bar{\\Lambda}_{h}^{\\sigma_{i-1}})}\\right)\\geq R_{h}\\log3,\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "which causes the contradiction. Thus $I_{2}$ has at most $R_{h}$ intervals, then we get ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\sum_{k\\in I_{2}}\\sum_{m\\in\\mathcal{M}}\\big\\|\\phi(z_{m,h}^{k})\\big\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\leq R_{h}M\\sqrt{\\gamma}\\leq\\left(\\log\\left(\\frac{\\operatorname*{det}(\\mathbf{A}_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathbf{I})}\\right)+1\\right)M\\sqrt{\\gamma}.\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Finally, we can bound the total summation, ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\sum_{\\substack{n\\in\\mathcal{M}}}\\sum_{k=1}^{K}\\|\\phi(z_{m,h}^{k})\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\leq\\sum_{\\substack{m\\in\\mathcal{M}}}\\sum_{k\\in I_{2}}\\|\\phi(z_{m,h}^{k})\\|_{(\\Lambda_{m,h}^{k})^{-1}}+\\sum_{\\substack{m\\in\\mathcal{M}\\,k\\in I_{1}\\cup\\{K\\}}}\\|\\phi(z_{m,h}^{k})\\|_{(\\Lambda_{m,h}^{k})^{-1}}}}\\\\ &{\\leq\\bigg(\\log\\bigg(\\frac{\\operatorname*{det}(\\Lambda_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathrm{I})}\\bigg)+1\\bigg)M\\sqrt{\\gamma}+2\\sqrt{M K\\log\\bigg(\\frac{\\operatorname*{det}(\\Lambda_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathrm{I})}\\bigg)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "This completes the proof. ", "page_idx": 38}, {"type": "text", "text": "F  Proof of the Regret Bound for CoopTS-LMC in Misspecified Setting ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "In this section, we prove the regret bound for CoopTS-LMC in the misspecified setting. The regret analysis, the essential supporting lemmas and their corresponding proofs are almost same as what we have presented in Appendix D and Appendix E. Here we mainly point out the differences of proof between these two settings. ", "page_idx": 38}, {"type": "text", "text": "F.1 Supporting Lemmas ", "text_level": 1, "page_idx": 38}, {"type": "text", "text": "Definition F.1 (Model prediction error). For any $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ , we define the model error asociated with the reward $r_{m,h}$ ", "page_idx": 38}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)=r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-Q_{m,h}^{k}(s,a).\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "Lemma F.2. Let $\\lambda\\,=\\,1$ in Algorithm 3. Under Definition 4.8, for any fixed $0\\,<\\,\\delta\\,<\\,1$ , with probability at least $1-\\delta$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times A$ , we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{m,h}(s,a)-{\\mathbb P}_{m,h}V_{m,h+1}^{k}(s,a)\\right|}\\\\ &{\\leq(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d})\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+3H\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "text", "text": "where $C_{\\delta}$ is defined in Lemma D.7. ", "page_idx": 38}, {"type": "text", "text": "Proof of Lemma $F.2$ . Recall from Definition 4.8, we have ", "page_idx": 38}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{\\mathcal{S}}|\\le\\big\\|\\mathbb{P}_{m,h}(\\cdot\\mid s,a)-\\langle\\phi(s,a),\\mu_{h}(\\cdot)\\rangle\\big\\|_{1}\\|V_{m,h+1}^{k}\\|_{\\infty}}&{}\\\\ {\\le2H\\big\\|\\mathbb{P}_{m,h}(\\cdot\\mid s,a)-\\langle\\phi(s,a),\\mu_{h}(\\cdot)\\rangle\\big\\|_{\\mathrm{TV}}}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 38}, {"type": "equation", "text": "$$\n\\leq2H\\zeta,\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "where the first inequality follows from Cauchy-Schwarz inequality, the second inequality follows from the fact that $\\|V_{m,h+1}^{k}\\|_{\\infty}\\leq H$ and $P_{2}$ \uff0c $\\begin{array}{r}{\\|\\dot{P}_{1}-P_{2}\\|_{\\mathrm{TV}}=\\frac{1}{2}\\sum_{\\mathbf{x}\\in\\omega}|P_{1}(\\mathbf{x})-P_{2}(\\mathbf{\\dot{x}})|\\stackrel{\\cdot}{=}\\frac{1}{2}\\|P_{1}-}\\end{array}$ $P_{2}\\|_{1}$ for twodistributions $P_{1}$ and $P_{2}$ , note that here we regard distribution as infinite dimensional vector, the third inequality follows from Definition 4.8. Define $\\Delta_{m,1}\\,=\\,\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)\\,-$ $\\phi(s,a)^{\\top}\\langle\\pmb{\\mu}_{h},V_{m,h+1}^{k}\\rangle_{S}$ thus $|\\Delta_{m,1}|\\leq2H\\zeta$ Then we have ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{P}_{n},V_{n,h}^{k}\\mathbb{P}_{n+1}(s,\\alpha)}\\\\ &{=\\phi(s,\\alpha)^{\\top}\\{\\mathbf{A}_{n},\\mathbf{P}_{n,h}^{k,n}\\}_{\\beta}+\\Delta_{m,1}}\\\\ &{=\\phi(s,\\alpha)^{\\top}(\\Delta_{m,h})^{-1}\\Bigg(\\sum_{(s^{\\prime},a^{\\prime})\\in\\mathcal{V}_{n,h}(s,\\beta)}\\phi(s^{\\prime},a^{\\prime})\\phi(s^{\\prime},a^{\\prime})^{\\top}+\\Delta t\\Bigg)\\langle\\mu_{n},V_{n,h+1}^{k}\\rangle_{\\beta}+\\Delta_{m,1}}\\\\ &{=\\phi(s,\\alpha)^{\\top}(\\Delta_{m,h})^{-1}\\Bigg(\\sum_{(s^{\\prime},a^{\\prime})\\in\\mathcal{V}_{n,h}(s,\\beta)}\\phi(s^{\\prime},a^{\\prime})\\phi(s^{\\prime},a^{\\prime})^{\\top}\\langle\\mu_{n},V_{n,h+1}^{k}\\rangle_{\\beta}\\Bigg)}\\\\ &{\\quad\\quad+\\Delta\\phi(s,\\alpha)^{\\top}(\\Delta_{m,h})^{-1}\\Bigg(\\sum_{(s^{\\prime},a^{\\prime})\\in\\mathcal{V}_{n,h}(s,\\beta)}\\phi(s^{\\prime},a^{\\prime})\\phi(s^{\\prime},a^{\\prime})^{\\top}\\langle\\mu_{n},V_{n,h+1}^{k}\\rangle_{\\beta}\\Bigg)}\\\\ &{\\quad\\quad=\\phi(s,\\alpha)^{\\top}(\\Delta_{m,h})^{-1}\\Bigg(\\sum_{(s^{\\prime},a^{\\prime})\\in\\mathcal{V}_{n,h}(s,\\beta)}\\phi(s^{\\prime},a^{\\prime})\\left(\\nabla_{n},V_{n,h}^{k}\\right)(s^{\\prime},a^{\\prime})\\Bigg)}\\\\ &{\\quad\\quad\\quad-\\phi(s,\\alpha)^{\\top}(\\Delta_{m,h}^{k})^{-1}\\Bigg(\\sum_{(s^{\\prime},a^{\\prime})\\in\\mathcal{V}_{n,h}(s,\\beta)}\\phi(s^{\\prime},a^{\\prime})\\left(\\phi(s^{\\prime},a^{\\prime})\\right)}\\\\ &{\\qquad\\quad\\quad+\\Delta\\phi(s,\\alpha)^{\\top}(\\Delta_{m,h}^{k})^{-1}\\Bigg)\\Bigg\\{\\mu_{n},V_{n,h+1} \n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "Based on (F.1), we can separate the following error into four parts, ", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\widehat{\\Psi}_{m,h}^{\\prime}-r_{m,h}(s,a)-\\sum_{m,h}\\sum_{h=1}^{H}(s,a)}\\\\ &{=\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\displaystyle\\sum_{(s^{\\prime},a^{\\prime},s^{\\prime})\\in\\mathcal{V}_{m,h}(k)}\\left[\\Gamma_{m,h}\\bigl(s^{\\prime},a^{\\prime}\\bigr)+V_{m,h+1}^{k}(s^{\\prime})\\bigr]\\phi(s^{\\prime},a^{\\prime})-r_{m,h}(s,a)}\\\\ &{\\qquad-\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\Bigg(\\sum_{(s^{\\prime},a,a^{\\prime},s^{\\prime})\\in\\mathcal{V}_{m,h}(k)}\\phi\\bigl(s^{\\prime},a^{\\prime}\\bigr)\\bigl(\\mathbb{P}_{m,h}V_{m,h+1}^{k}\\bigr)\\bigl(s^{\\prime},a^{\\prime}\\bigr)\\Bigg)}\\\\ &{\\qquad+\\Delta_{m,1}\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\Bigg(\\sum_{(s^{\\prime},a^{\\prime},s^{\\prime})\\in\\mathcal{V}_{m,h}(k)}\\phi\\bigl(s^{\\prime},a^{\\prime}\\bigr)\\Bigg)}\\\\ &{\\qquad-\\lambda\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\cdot\\Bigl\\{\\mu_{h},V_{m,h+1}^{k}\\bigr)_{S}-\\Delta_{m,1}}\\\\ &{=\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\mathscr{N}\\Bigl(\\sum_{(s^{\\prime},a^{\\prime},s^{\\prime})\\in\\mathcal{V}_{m,h}(k)}\\phi\\bigl(s^{\\prime},a^{\\prime}\\bigr)\\bigl[\\bigl(V_{m,h+1}^{k}-\\mathbb{P}_{m,h}V_{m,h+1}^{k}\\bigr)\\bigl(s^{\\prime},a^{\\prime}\\bigr)\\bigr]\\Bigr)}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{+\\underbrace{\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\sum_{(s^{l},a^{l},s^{t^{l}})\\in U_{m,h}(k)}r_{m,h}(s^{l},a^{l})\\phi(s^{l},a^{l})\\Bigg)-r_{m,h}(s,a)}_{(\\mathrm{if})}}\\\\ &{-\\underbrace{\\lambda\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{S}}_{(\\mathrm{ii})}}\\\\ &{+\\underbrace{\\Delta_{m,1}\\phi(s,a)^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\sum_{(s^{l},a^{l},s^{t^{l}})\\in U_{m,h}(k)}\\phi(s^{l},a^{l})\\Bigg)-\\Delta_{m,1}}_{(\\mathrm{i})}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 39}, {"type": "text", "text": "We now provide an upper bound for each of the terms in (F.3). ", "page_idx": 40}, {"type": "text", "text": "Bounding Term (i) in (F.3): same as (E.11) in Appendix E.6, with probability at least $1-\\delta$ wehave ", "page_idx": 40}, {"type": "equation", "text": "$$\n|\\mathbf{Term}\\ (\\mathbf{i})|\\leq3H\\sqrt{d}C_{\\delta}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Bounding Term (i) $^{+}$ Term (iv) in (F.3): define $\\Delta_{m,2}=r_{m,h}(s,a)-\\phi(s,a)^{\\top}\\theta_{h}$ then we have $|\\Delta_{m,2}|\\leq\\zeta$ due to Definition 4.8. Next we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb{E}\\{a_{1},\\}^{T}\\big(\\mathbb{A}_{n}\\big)^{-1}\\Bigg)^{-1}\\Bigg(\\underset{(u,v,u)\\sim\\pi_{1}(\\nu,u)}{\\sum}\\sum_{\\substack{u\\in\\mathcal{A}_{n}\\setminus\\mathcal{H}(\\mathcal{H}(\\mathcal{H}(\\pi)))}}r_{u,v}(u^{\\prime},u^{\\prime})\\Big)-r_{u,v}\\mathbb{A}_{n}(u)}\\\\ &{=\\phi(u,v)^{T}\\big(\\mathbb{A}_{n}\\big)^{-1}\\Bigg(\\underset{(u,v)\\sim\\pi_{1}(\\nu,u)\\sim\\pi_{1}(\\nu,u)}{\\sum}r_{u,v}(u_{u,v}(u^{\\prime},u^{\\prime}))\\varphi(u^{\\prime},u^{\\prime})\\Big)-\\phi(u,v)^{T}\\theta_{n}-\\Delta_{n},}\\\\ &{=\\phi(u,v)^{T}\\big(\\mathbb{A}_{n}\\big)^{-1}\\Bigg(\\underset{(u,v)\\sim\\pi_{1}(\\nu,u)\\sim\\pi_{1}(\\nu,u)}{\\sum}r_{u,v}(u_{u,v}(u^{\\prime},u^{\\prime}))\\varphi(u^{\\prime},u^{\\prime})-\\mathbb{A}_{n}^{-1}\\mu_{1}\\Bigg)-\\Delta_{n}}\\\\ &{=\\phi(u,v)^{T}\\big(\\mathbb{A}_{n}\\big)^{-1}\\Bigg)^{-1}\\Bigg(\\underset{(u,v)\\sim\\pi_{1}(\\nu,u)\\sim\\pi_{1}(\\nu,u)}{\\sum}\\sum_{\\substack{u\\in\\mathcal{E}_{n}\\setminus\\mathcal{H}(\\mathcal{H}(\\pi))}}\\varphi\\big(x^{\\prime},u^{\\prime}\\big)r_{u,v}(u_{u,v}^{\\prime},u^{\\prime})}\\\\ &{\\qquad-\\underset{(u,v)\\sim\\pi_{1}(\\nu,u)\\sim\\pi_{1}(\\nu,u)\\sim\\pi_{1}(\\nu,u)}{\\sum}\\varphi\\big(x_{u,v}^{\\prime},u^{\\prime}\\big)\\varphi(u_{u,v}^{\\prime},u^{\\prime})\\big)-\\delta_{n},}\\\\ &{=\\phi(u,v)^{T}\\big(\\mathbb{A}_{n}\\big)^{-1}\\Bigg(\\underset{(u,v)\\sim\\pi_{1}(\\nu,u)\\sim\\pi_{1}(\\nu,u)}{\\sum}\\varphi\\big(x_{u^{\\prime},u}^{\\prime})\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where the third equality uses the definition of ${\\pmb{\\Lambda}}_{m,h}^{k}$ . By Combining (F.5) and (E.13) in Appendix E.6, we obtain ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\mathbf{Term}\\left(\\mathbf{ii}\\right)+\\mathbf{Term}\\left(\\mathbf{iv}\\right)|\\leq\\sqrt{\\lambda d}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+|\\mathbf{Term}\\left(\\mathbf{iv}\\right)+\\mathbf{Term}\\left(\\mathbf{v}\\right)|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Then we calculate that ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\bf~Term~(iv)+Term~(v)}}\\\\ &{=\\left|(\\Delta_{m,1}+\\Delta_{m,2})\\phi(s,a)^{\\top}(\\Delta_{m,h}^{k})^{-1}\\right|\\displaystyle\\sum_{(\\varepsilon^{\\prime},a^{\\prime},s^{\\prime\\prime})\\in U_{m,h}(k)}\\phi(s^{\\prime},a^{\\prime})\\right)-(\\Delta_{m,1}+\\Delta_{m,2})\\right|}\\\\ &{\\leq|\\Delta_{m,1}+\\Delta_{m,2}|\\cdot\\left|\\phi(s,a)^{\\top}(\\Delta_{m,h}^{k})^{-1}\\right|\\displaystyle\\sum_{(\\varepsilon^{\\prime},a^{\\prime},s^{\\prime\\prime})\\in U_{m,h}(k)}\\phi(s^{\\prime},a^{\\prime})\\right)\\right|+|\\Delta_{m,1}+\\Delta_{m,2}|}\\\\ &{\\leq3H\\zeta|\\phi(s,a)|\\|_{(\\Delta_{m,h}^{k})^{-1}}\\displaystyle\\sum_{(s^{\\prime},a^{\\prime},s^{\\prime\\prime})\\in U_{m,h}(k)}\\left\\|\\phi(s^{\\prime},a^{\\prime},a^{\\prime})\\right\\|_{(\\Delta_{m,h}^{k})^{-1}}+3H\\zeta}\\\\ &{\\leq3H\\zeta\\|\\phi(s,a)\\|_{(\\Delta_{m,h}^{k})^{-1}}\\displaystyle\\sum_{(s^{\\prime},a^{\\prime},s^{\\prime\\prime})\\in U_{m,h}(k)}\\left\\|\\phi(s^{\\prime},a^{\\prime})\\right\\|_{(\\Delta_{m,h}^{k})^{-1}}^{2}+3H\\zeta}\\\\ &{\\leq3H\\zeta\\sqrt{d\\phi(s,a)}\\|_{(\\Delta_{m,h}^{k})^{-1}}\\cdots\\displaystyle\\sum_{(s^{\\prime},a^{\\prime},s^{\\prime\\prime})\\in U_{m,h}(k)}\\left\\|\\phi(s^{\\prime},a^{\\prime})\\right\\|_{(\\Delta_{m,h}^{k})^{-1}}^{2}\\right)^{\\frac{1}{2}}+3H\\zeta}\\\\ &{\\leq3H\\zeta\\sqrt{d K M k}\\|\\phi(s,a)\\|_{(\\Delta_{m,h}^{k})^{-1}}+3H\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "where the second inequality follows from Cauchy-Schwarz inequality and the fact that $|\\Delta_{m,1}+$ $\\Delta_{m,2}|\\,\\leq\\,|\\Delta_{m,1}|+|\\bar{\\Delta}_{m,2}|^{\\,^{\\prime}}\\leq\\,2H\\zeta+\\zeta\\,\\leq\\,3H\\zeta$ , the third inequality holds because of CauchySchwarz inequality, and the last inequality holds because $\\kappa(k)\\leq M\\dot{K}$ and Lemma J.4. Substitute (F.7) into (F.6), we have ", "page_idx": 40}, {"type": "equation", "text": "$$\n\\left|\\mathbf{Term}\\left(\\mathbf{i}\\mathbf{i}\\right)+\\mathbf{Term}\\left(\\mathbf{i}\\mathbf{v}\\right)\\right|\\leq\\left(3H\\zeta\\sqrt{M K d}+\\sqrt{\\lambda d}\\right)\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}+3H\\zeta.\n$$", "text_format": "latex", "page_idx": 40}, {"type": "text", "text": "Bounding Term (i) in (F.3): same as (E.15) in Appendix E.6, we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\lvert\\mathrm{Term}\\ (\\ensuremath{\\mathrm{iii}})\\rvert\\leq H\\sqrt{\\lambda d}\\lVert\\phi(s,a)\\rVert_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Combine all the terms in (F.3) together: by using triangle inequality in (F.3), we combine (F.4), (F.8) and (F.9), then set $\\lambda=1$ , with probability at least $1-\\delta$ ,weget ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{m,h}(s,a)-{\\mathbb P}_{m,h}V_{m,h+1}^{k}(s,a)\\right|}\\\\ &{\\leq\\left(3H\\sqrt{d}C_{\\delta}+\\sqrt{d}+H\\sqrt{d}+3H\\zeta\\sqrt{M K d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+3H\\zeta}\\\\ &{\\leq\\left(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+3H\\zeta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "This completes the proof. ", "page_idx": 41}, {"type": "text", "text": "Lemma F.3 (Error bound). Let $\\lambda=1$ in Algorithm 3. Under Definition 4.8, for any fixed $0<\\delta<1$ with probability at least $1-\\delta-\\delta^{2}$ , for any $\\bar{(}m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times A$ we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n-l_{m,h}^{k}(s,a)\\leq\\left(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d}+5\\sqrt{\\frac{2d\\log\\left(\\sqrt{N}/\\delta\\right)}{3\\beta_{K}}+\\frac{4}{3}}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+3H\\zeta,\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where $C_{\\delta}$ is defined in Lemma D.7. ", "page_idx": 41}, {"type": "text", "text": "ProofofLemma $F.3$ .We do the same process as that in Appendix E.7, and we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-l_{m,h}^{k}(s,a)\\leq\\underset{\\underset{n\\in[N]}{\\underbrace{\\operatorname*{max}}}}{\\operatorname*{max}}\\left|\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\right|}\\\\ &{\\qquad\\qquad\\qquad+\\underbrace{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{m,h}(s,a)-\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)\\right|}_{(i i)}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Bounding Term (i): based on (E.16), for any $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and $(s,a)\\in S\\times A$ with probability at least $1-\\delta^{2}$ ,we have ", "page_idx": 41}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\vert\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\right\\vert\\leq\\left(5\\sqrt{\\frac{2d\\log\\left(\\sqrt{N}/\\delta\\right)}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\left\\Vert\\phi(s,a)\\right\\Vert_{(\\mathbf{A}_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "Bounding Term (i): based on Lemma F.2, for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and $(s,a)\\in S\\times A$ wehave ", "page_idx": 41}, {"type": "text", "text": "$\\begin{array}{r}{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}^{k}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\right|\\leq\\left(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+3H\\zeta.}\\end{array}$ Combine the two result above, by taking union bound, with probability at least $1-\\delta-\\delta^{2}$ wehave $-l_{m,h}^{k}(s,a)\\leq\\left(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d}+5\\sqrt{\\frac{2d\\log\\left(\\sqrt{N}/\\delta\\right)}{3\\beta_{K}}}+\\frac{4}{3}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+3H\\zeta.$ ", "page_idx": 41}, {"type": "text", "text": "This completes the proof. ", "page_idx": 41}, {"type": "text", "text": "Lemma E4 (Optimism). Let $\\lambda=1$ in Algorthm 3 and $\\begin{array}{r}{c_{0}^{\\prime}=1-\\frac{1}{2\\sqrt{2e\\pi}}}\\end{array}$ Under Defniton 4.8. for anyfixed $0\\textless\\delta\\textless1$ Wwith probability a least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime}^{N}-2\\delta$ where $|{\\mathcal{C}}(\\varepsilon)|\\leq(3/\\varepsilon)^{d}$ for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and for all $(s,a)\\in S\\times{\\dot{A}}$ , we have ", "page_idx": 41}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)\\leq\\alpha_{\\delta}\\varepsilon+3H\\zeta,\n$$", "text_format": "latex", "page_idx": 41}, {"type": "text", "text": "where $\\alpha_{\\delta}=\\sqrt{M K}\\big(2H\\sqrt{d}+B_{\\delta/N M H K}\\big)$ ", "page_idx": 41}, {"type": "text", "text": "Proofof Lemma $F.4$ This proof is similar to the proof in Appendix E.8, we just prove the part that for fixed $\\phi\\in{\\mathcal{C}}(\\varepsilon)$ . Recall from Definition F.1, ", "page_idx": 42}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)=r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-Q_{m,h}^{k}(s,a).\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Note that ", "page_idx": 42}, {"type": "equation", "text": "$$\nQ_{m,h}^{k}(s,a)=\\operatorname*{min}\\Big\\{\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n},H-h+1\\Big\\}^{+}\\leq\\operatorname*{max}_{n\\in[N]}\\phi(x,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n}.\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Here we define ", "page_idx": 42}, {"type": "equation", "text": "$$\nZ_{k}=\\frac{r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}-(\\Delta_{m,1}+\\Delta_{m,2})}{\\sqrt{\\phi(s,a)^{\\top}\\Sigma_{m,h}^{k,J_{k}}\\phi(s,a)}},\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "where $\\begin{array}{r l r}{\\Delta_{m,1}}&{{}=}&{\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)\\ -\\ \\phi(s,a)^{\\top}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{\\mathcal{S}},\\Delta_{m,2}\\quad=\\quad r_{m,h}(s,a)\\ -\\phi(s,a)\\,,}\\end{array}$ $\\phi(s,a)^{\\top}\\pmb{\\theta}_{h}$ Based on theresutsin Prpstion D we have that $\\begin{array}{r l}{\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}}&{\\sim}\\end{array}$ $\\mathcal{N}\\Big(\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}},\\phi(s,a)^{\\top}\\Sigma_{m,h}^{k,J_{k}}\\phi(s,a)\\Big)$ for any fixed $n\\in[N]$ When $|Z_{k}|<1$ by Gaussian concentration Lemma J.10, we have ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\sqrt{\\Big(r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k,n}}\\leq(\\Delta_{m,1}+\\Delta_{m,2})\\Big)}}\\\\ &{=\\mathbb{P}\\Big(\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k,n}}\\geq r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-(\\Delta_{m,1}+\\Delta_{m,2})\\Big)}\\\\ &{=\\mathbb{P}\\Bigg(\\frac{\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k,n}}-\\phi(s,a)^{\\top}\\mathbf{\\bar{\\mu}}_{m,h}^{k,J_{k,h}}}{\\sqrt{\\phi(s,a)^{\\top}\\mathbf{D}_{m,h}^{k,J_{k,h}}\\phi(s,a)}}\\geq\\frac{r_{m,h}V_{m,h+1}^{k}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-(\\Delta_{m,1}+\\Delta_{m,2})-\\phi(s,a)^{\\top}\\mathbf{\\bar{\\mu}}_{m,h}^{k,J_{k,h}}}{\\sqrt{\\phi(s,a)^{\\top}\\mathbf{D}_{m,h}^{k,J_{k,h}}\\phi(s,a)}}}\\\\ &{=\\mathbb{P}\\Bigg(\\frac{\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k,h}}-\\phi(s,a)^{\\top}\\mathbf{\\bar{\\mu}}_{m,h}^{k,J_{k}}}{\\sqrt{\\phi(s,a)^{\\top}\\mathbf{D}_{m,h}^{k,J_{k}}\\phi(s,a)}}\\geq Z_{k}\\Bigg)}\\\\ &{\\geq\\frac{1}{2\\sqrt{2\\pi}}\\exp(-Z_{k}^{2}/2)}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Consider the numerator of $Z_{k}$ ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}-(\\Delta_{m,1}+\\Delta_{m,2})\\right|}\\\\ &{\\leq\\underbrace{\\left|r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-(\\Delta_{m,1}+\\Delta_{m,2})\\right|}_{I_{1}}}\\\\ &{\\qquad+\\underbrace{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\right|}_{I_{2}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "text", "text": "Bounding Term $I_{1}$ in (F.10): recall the proof of Lemma F.2, we do the almost same error decomposition as (F.3) with the only difference of adding term $(\\Delta_{m,1}+\\Delta_{m,2})$ ", "page_idx": 42}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{m,h}(s,a)-\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)+(\\Delta_{m,1}+\\Delta_{m,2})}\\\\ &{=\\phi(s,a)^{\\top}\\bigl(\\Lambda_{m,h}^{k}\\bigr)^{-1}\\Biggl(\\sum_{(s^{l},a^{l},s^{\\prime\\prime})\\in{\\cal U}_{m,h}(k)}\\phi\\bigl(s^{l},a^{l}\\bigr)\\bigl[\\bigl(V_{m,h+1}^{k}-\\mathbb{P}_{m,h}V_{m,h+1}^{k}\\bigr)\\bigl(s^{l},a^{l}\\bigr)\\bigr]\\Biggr)}\\end{array}\n$$", "text_format": "latex", "page_idx": 42}, {"type": "equation", "text": "$$\n+\\;\\phi(s,a)^{\\top}\\!\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-1}\\!\\left(\\sum_{(s^{l},a^{l},s^{\\prime}^{l})\\in U_{m,h}(k)}r_{m,h}\\!\\left(s^{l},a^{l}\\right)\\!\\phi\\!\\left(s^{l},a^{l}\\right)\\right)-r_{m,h}\\!\\left(s,a\\right)\n$$", "text_format": "latex", "page_idx": 42}, {"type": "equation", "text": "$$\n+\\,\\Delta_{m,1}\\phi(s,a)^{\\top}\\!\\left(\\Lambda_{m,h}^{k}\\right)^{-1}\\!\\left(\\sum_{(s^{l},a^{l},s^{\\prime}^{l})\\in U_{m,h}(k)}\\phi\\!\\left(s^{l},a^{l}\\right)\\right)+\\Delta_{m,2}\\,.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "We now provide an upper bound for each of the terms in (F.11). ", "page_idx": 43}, {"type": "text", "text": "Bounding Term (i) in (F.11): almost same as (E.11) in Appendix E.6 with the only difference between $\\mathbb{P}_{h}$ and $\\mathbb{P}_{m,h}$ , with probability at least $1-\\delta$ wehave ", "page_idx": 43}, {"type": "equation", "text": "$$\n|\\mathbf{Term}\\left(\\mathbf{i}\\right)|\\leq3H\\sqrt{d}C_{\\delta}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Bounding Term (ii) $^+$ Term (iv) in (F.11): we do the same calculation as that in the proof of Lemma F.2, based on (F.5), we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathsf{R e r m}\\left(\\ddot{\\mathbf{u}}\\right)=\\phi(s,a)^{\\top}\\!\\left(\\Lambda_{m,h}^{k}\\right)^{-1}\\!\\left(\\displaystyle\\sum_{(s^{l},a^{l},s^{l^{\\prime}})\\in U_{m,h}(k)}r_{m,h}\\!\\left(s^{l},a^{l}\\right)\\!\\phi(s^{l},a^{l})\\right)-r_{m,h}(s,a)}\\\\ &{\\qquad=-\\lambda\\phi(s,a)^{\\top}\\!\\left(\\Lambda_{m,h}^{k}\\right)^{-1}\\!\\theta_{h}+\\Delta_{m,2}\\phi(s,a)^{\\top}\\!\\left(\\Lambda_{m,h}^{k}\\right)^{-1}\\!\\left(\\displaystyle\\sum_{(s^{l},a^{l},s^{l})\\in U_{m,h}(k)}\\phi\\!\\left(s^{l},a^{l}\\right)\\right)-\\Delta_{m,2}\\,,}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\quad.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "By Combining (F.13) and (E.13) in Appendix E.6, we obtain ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r}{|\\mathbf{Term}\\left(\\mathbf{i}\\mathbf{i}\\right)+\\mathbf{Term}\\left(\\mathbf{i}\\mathbf{v}\\right)|\\leq\\sqrt{\\lambda d}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+|\\mathbf{Term}\\left(\\mathbf{i}\\mathbf{v}\\right)+\\mathbf{Term}\\left(\\mathbf{v}\\right)|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Then we calculate that ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{\\normalfont~Ierm~(iv)+Term~(v)|=}\\left|\\Delta_{m,1}+\\Delta_{m,2}\\right|\\cdot\\Bigg|\\phi\\big(s,a\\big)^{\\top}\\!\\left(\\Lambda_{m,h}^{k}\\right)^{-1}\\!\\Bigg(\\!\\qquad\\underset{(s^{\\prime},a^{\\prime},s^{\\prime})\\in U_{m,h}(k)}{\\sum}\\phi\\big(s^{l},a^{l}\\big)\\!\\right)\\Bigg|}\\\\ &{\\qquad\\qquad\\qquad\\leq3H\\zeta\\!\\left\\|\\phi\\big(s,a\\big)\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\sum_{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\Vert\\phi\\big(s^{l},a^{l}\\big)}\\!\\!\\!\\!\\!\\!\\left\\|\\phi\\big(s^{l},a^{l}\\big)\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\leq3H\\zeta\\!\\left\\|\\phi\\big(s,a\\big)\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\sum_{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times}\\displaystyle\\sum_{(s^{\\prime},a^{l},s^{\\prime})\\in U_{m,h}(k)}\\left\\|\\phi\\big(s^{l},a^{l}\\big)\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}^{2}\\!\\!\\!\\!\\!\\!\\!\\!}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\times1H\\zeta\\!\\left\\|\\phi\\big(s,a\\big)\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\mathrm{\\normalfont~F.l}5)}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "where the first inequality follows from Cauchy-Schwarz inequality and the fact that $|\\Delta_{m,1}+\\Delta_{m,2}|\\leq$ $3H\\zeta$ , the second inequality holds because of Cauchy-Schwarz inequality, and the last inequality holdsbecause $K(k)\\leq M K$ and Lemma J.4. Substitute (F.15) into (F.14), we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n|\\mathbf{Ierm}\\left(\\mathbf{i}\\right)+\\mathbf{Term}\\left(\\mathbf{iv}\\right)|\\leq\\left(3H\\zeta\\sqrt{M K d}+\\sqrt{\\lambda d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Bounding Term (ii) in (F.11): same as (E.15) in Appendix E.6, we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\lvert\\mathrm{Term\\r{(iii)}}\\rvert\\le H\\sqrt{\\lambda d}\\lVert\\phi(s,a)\\rVert_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Combine all the terms in (F.11) together: by using triangle inequality in (F.11), we combine (F.12), (F.16) and (F.17), then set $\\lambda=1$ ,with probability at least $1-\\delta$ ,weget ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{m,h}(s,a)-{\\mathbb P}_{m,h}V_{m,h+1}^{k}(s,a)+(\\Delta_{m,1}+\\Delta_{m,2})\\right|}\\\\ &{\\leq(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d})\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "Bounding Term $I_{2}$ in (F.10): same as the proof in Appendix E.8, we have ", "page_idx": 43}, {"type": "equation", "text": "$$\n\\bigl|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\bigr|\\leq\\frac{4}{3}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 43}, {"type": "text", "text": "So, with probability at least $1-\\delta$ , we have ", "page_idx": 44}, {"type": "equation", "text": "$$\nr_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\mu_{m,h}^{k,J_{k}}\\Big|\\leq\\bigg(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d}+\\frac{4}{3}\\bigg)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Consider the denominator of $Z_{k}$ : same as the proof in Appendix E.8, with (E.18), we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\|\\phi(s,a)\\|_{\\Sigma_{m,h}^{k,J_{k}}}\\geq\\frac{1}{4\\sqrt{\\beta_{K}}}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}},\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where we used the fact that $\\lambda_{\\operatorname*{min}}\\big(\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\big)\\geq1/k$ and $\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\geq1/\\sqrt{k}\\|\\phi(s,a)\\|_{2}$ Therefore, according to (F.18) and (F.19), with probability at least $1-\\delta$ , it holds that ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|Z_{k}\\right|=\\left|\\frac{r_{m,h}\\left(s,a\\right)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}\\left(s,a\\right)-\\phi\\left(s,a\\right)^{\\top}\\mu_{m,h}^{k,J_{k}}}{\\sqrt{\\phi\\left(s,a\\right)^{\\top}\\Sigma_{m,h}^{k,J_{k}}\\phi\\left(s,a\\right)}}\\right|}\\\\ &{\\quad\\le\\frac{\\left(5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d}+\\frac{4}{3}\\right)\\left\\|\\phi\\left(s,a\\right)\\right\\|\\left(\\Lambda_{m,h}^{k}\\right)^{-1}}{\\frac{1}{4\\sqrt{\\beta_{K}}}\\left\\|\\phi\\left(s,a\\right)\\right\\|\\left(\\Lambda_{m,h}^{k}\\right)^{-1}}}\\\\ &{\\quad=\\frac{5H\\sqrt{d}C_{\\delta}+3H\\zeta\\sqrt{M K d}+\\frac{4}{3}}{\\frac{1}{4\\sqrt{\\beta_{K}}}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Which implies $|Z_{k}|<1$ when $\\begin{array}{r}{\\frac{1}{\\sqrt{\\beta_{K}}}=20H\\sqrt{d}C_{\\delta}+12H\\zeta\\sqrt{M K d}+\\frac{16}{3}.}\\end{array}$ ", "page_idx": 44}, {"type": "text", "text": "Now we have already proved that, for any fixed $n\\in[N]$ , with probability at least $1-\\delta$ ,wehave ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big(r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k,J_{k},n}\\leq(\\Delta_{m,1}+\\Delta_{m,2})\\Big)\\geq\\frac{1}{2\\sqrt{2e\\pi}}.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "By taking union bound over $n\\in[N]$ , with probablity at least $1-\\delta$ , we have ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbb P\\Big(\\displaystyle\\operatorname*{max}_{n\\in[N]}\\left\\{\\phi(s,a)^{\\top}\\mathbf w_{m,h}^{k,J_{k},n}-r_{m,h}(s,a)-\\mathbb P_{m,h}V_{m,h+1}^{k}(s,a)\\right\\}\\geq-(\\Delta_{m,1}+\\Delta_{m,2})\\Big)}\\\\ &{\\geq1-\\left(1-\\displaystyle\\frac1{2\\sqrt{2e\\pi}}\\right)^{N}}\\\\ &{=1-c_{0}^{\\prime\\,N},}\\end{array}\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "where $\\begin{array}{r}{c_{0}^{\\prime}=1-\\frac{1}{2\\sqrt{2e\\pi}}}\\end{array}$ .Finally, with probability at last $(1-\\delta)\\big(1-{c_{0}^{\\prime}}^{N}\\big)$ , for all $(s,a)\\in S\\times A$ we have ", "page_idx": 44}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)\\leq3H\\zeta.\n$$", "text_format": "latex", "page_idx": 44}, {"type": "text", "text": "Till now we have completed the proof of fixed $\\phi\\in{\\mathcal{C}}(\\varepsilon)$ . Follow the proof in Appendix E.8, we can get the final result. \u53e3 ", "page_idx": 44}, {"type": "text", "text": "F.2  Regret Analysis ", "text_level": 1, "page_idx": 44}, {"type": "text", "text": "In this part, we give out the proof of Theorem 4.12, the regret bound for CoopTS-LMC in the misspecified setting. ", "page_idx": 44}, {"type": "text", "text": "Proof of Theorem 4.12. This proof is almost same as the proof in Appendix D.2. We do the same regret decomposition (D.2) and obtain the same bound for Term(i) (D.3) and Term(ii) (D.4). Next we bound Term (ii) with new lemmas in the misspecified setting. ", "page_idx": 44}, {"type": "text", "text": "Bounding Term (ii) in (D.2): based on Lemma F.3 and Lemma F.4, by taking union bound, with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime\\,N}-2\\delta^{\\prime}-M H K(\\delta^{\\prime}+{\\delta^{\\prime}}^{2})$ wehave ", "page_idx": 44}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\left(\\mathbb{E}_{\\pi^{*}}\\left[l_{m,h}^{k}(s_{m,h},a_{m,h})\\middle|s_{m,1}=s_{m,1}^{k}\\right]-l_{m,h}^{k}\\left(s_{m,h}^{k},a_{m,h}^{k}\\right)\\right)\n$$", "text_format": "latex", "page_idx": 44}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\le\\displaystyle\\sum_{m\\in\\mathbb{R}_{+}\\atop m\\le t_{+}=1}^{\\sum_{k}\\sum_{i}}\\left(-I_{m,k}\\big(A_{m,k}^{*},a_{m,k}^{*}\\big)+\\alpha_{P}\\epsilon+3I t\\right)}\\\\ &{\\le\\displaystyle\\sum_{m\\le t_{+}=1}^{t_{+}}\\sum_{i=1}^{p}\\Bigg(\\left(5I^{*}\\widehat{A}^{*}\\widehat{A}^{*}+3I\\widehat{C}^{*}\\widehat{A}^{*}+5\\sqrt{\\frac{2\\log\\left(\\sqrt{N/\\ell}\\right)}{3K}}+\\frac{4}{3}\\right)\\|\\phi(a_{m,k}^{*},a_{m,k}^{*})\\|_{\\infty_{+}}\\Bigg)}\\\\ &{\\quad+\\alpha_{P}\\epsilon+\\mu I\\epsilon\\Bigg)}\\\\ &{=I I M K\\omega\\varphi+\\epsilon\\left(9I^{*}\\lambda I^{*}\\widehat{A}^{*}+\\left(5I^{*}\\widehat{A}^{*}\\widehat{C}^{*}+3I t\\right)\\sqrt{\\frac{4\\lambda I\\epsilon}{3K}}+5\\sqrt{\\frac{2\\log\\left(\\sqrt{N/\\ell}\\right)}{3K}}+\\frac{4}{3}\\right)}\\\\ &{\\quad\\displaystyle\\qquad\\times\\sum_{m\\le t_{+}=1}^{n}\\sum_{i=1}^{p}\\left\\|\\phi(a_{m,k}^{*},a_{m,k}^{*})\\right\\|_{\\infty_{+}>1},}\\\\ &{\\le H M K\\omega\\varepsilon+4\\eta I\\lambda\\varepsilon\\ll\\left(5I I^{*}\\widehat{A}^{*}+3I t\\sqrt{\\sqrt{3K}}+5\\sqrt{\\frac{2\\log\\left(\\sqrt{N/\\ell}\\right)}{3K}}+\\frac{4}{3}\\right)}\\\\ &{\\qquad\\times\\sum_{i=1}^{\\sum_{k}\\bigg(\\log\\left(\\frac{\\sinh\\left(\\lambda\\right)}{4K\\left(\\lambda\\right)}\\right)+1\\right)M\\gamma\\zeta^{-2}}+\\sqrt{\\lambda}\\mathrm{Re}\\operatorname*{lims}\\left(\\frac{\\sqrt{6K}\\lambda I}{4K\\left(K\\left(\\lambda\\right)\\right)}\\right)}\\\\ &{\\le H M K\\omega\\varepsilon+1\\eta I\\gamma^{2}I\\eta^{-1}\\lambda\\mathrm{Re}\\varepsilon+\\left(5I I^{*}\\widehat{A}^{*}+1\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "The first inequality follows from Lemma F.4, the second inequality follows from Lemma F.3, the third inequality follows from Lemma D.12, the last inequality holds due to Lemma J.2 and the fact that $\\|\\phi(\\cdot)\\|_{2}\\leq1$ , the last equality follows from $\\begin{array}{r}{\\frac{1}{\\sqrt{\\beta_{K}}}=20\\dot{H}\\sqrt{d}C_{\\delta^{\\prime}}+12H\\zeta\\sqrt{M K d}+\\frac{16}{3}}\\end{array}$ Which we define in Lemma F.4. ", "page_idx": 45}, {"type": "text", "text": "The probability calculation is same as that in Appendix D.2. By combining Terms (i)(i)(ii) together, we get that the final regret bound for CoopTS-LMC in misspecified setting is ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\widetilde{\\mathcal{O}}\\Big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)+d^{\\frac{3}{2}}H^{2}M\\sqrt{K}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)\\zeta\\Big),\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "with probability at least $1-\\delta$ . Here we finish the proof. ", "page_idx": 45}, {"type": "text", "text": "G Proof of the Regret Bound for CoopTS-PHE ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Before getting the regret bound for CoopTS-PHE, we first present some essential technical lemmas required for our analysis. ", "page_idx": 45}, {"type": "text", "text": "G.1  Supporting Lemmas ", "text_level": 1, "page_idx": 45}, {"type": "text", "text": "Proposition G.1. The difference between the perturbed estimated parameter $\\widetilde{\\mathbf{w}}_{m,h}^{k,n}$ and unperturbed estimated parameter $\\widehat{\\mathbf{w}}_{m,h}^{k}$ satisfies the Gaussian distribution, ", "page_idx": 45}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\boldsymbol{\\zeta}_{m,h}^{k,n}=\\widetilde{\\mathbf{w}}_{m,h}^{k,n}-\\widehat{\\mathbf{w}}_{m,h}^{k}\\sim{\\mathcal{N}}\\Big(\\mathbf{0},\\sigma^{2}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Big),}\\end{array}\n$$", "text_format": "latex", "page_idx": 45}, {"type": "text", "text": "where $\\begin{array}{r}{\\widehat{\\mathbf{w}}_{m,h}^{k}=\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Big(\\sum_{(s^{l},a^{l},s^{\\prime}})\\!\\in\\!U_{m,h}(k)\\big[r_{h}+V_{m,h+1}^{k}\\big(s^{\\prime}\\!^{l}\\big)\\big]\\phi\\big(s^{l},a^{l}\\big)\\Big)}\\end{array}$ is the unperturbed estimated parameter. ", "page_idx": 45}, {"type": "text", "text": "Next we will define some good events that hold with high probability to help prove the critical lemmas in this section. ", "page_idx": 45}, {"type": "text", "text": "Lemma G.2 (Good events). For any fixed $0\\,<\\,\\delta\\,<\\,1$ , with some constant $c>0$ , we define the following random events ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\ \\ \\ \\ \\mathcal{G}_{m,h}^{k}(\\zeta,\\delta)\\overset{\\mathrm{def}}{=}\\Big\\{\\underset{n\\in[N]}{\\operatorname*{max}}\\ \\big\\|\\zeta_{m,h}^{k,n}\\big\\|_{\\boldsymbol{\\Lambda}_{m,h}^{k}}\\leq c_{1}\\sigma\\sqrt{d}\\Big\\},}\\\\ &{\\mathcal{G}(M,K,H,\\delta)\\overset{\\mathrm{def}}{=}\\displaystyle\\bigcap_{m\\in\\mathcal{M}}\\bigcap_{k\\leq K}\\bigcap_{h\\leq H}\\mathcal{G}_{m,h}^{k}(\\zeta,\\delta),}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $c_{1}=c\\sqrt{\\log(d N M K H/\\delta)}$ . Then the event $\\mathcal{G}(M,K,H,\\delta)$ occurs with probability at least $1-\\delta$ ", "page_idx": 46}, {"type": "text", "text": "Lemma G.3. Let $\\lambda\\,=\\,1$ in Algorithm 2. For any fixed $0\\,<\\,\\delta\\,<\\,1$ , conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability $1-\\delta$ , for all $(m,\\dot{k_{,}}\\,h)\\in\\mathcal{M}\\times[K]\\times[H]$ ,we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\displaystyle\\sum_{(s^{l},a^{l},s^{l})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\left[\\left(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\right)\\big(s^{l},a^{l}\\big)\\right]\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\le3H\\sqrt{d}D_{\\delta},}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where we defne $\\begin{array}{r}{D_{\\delta}=\\Big[\\frac{1}{2}\\log(K+1)+\\log\\Big(\\frac{6\\sqrt{2}K(2H\\sqrt{M K d}+c_{1}\\sigma\\sqrt{d})}{H}\\Big)+\\log\\frac{1}{\\delta}\\Big]^{1/2}.}\\end{array}$ ", "page_idx": 46}, {"type": "text", "text": "Lemma G.4. Let $\\lambda=1$ in Algorithm 2. Under Definition 4.1, for any fixed $0<\\delta<1$ , conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability $1-\\delta$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times A$ , we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\Bigl|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\Bigr|\\leq5H\\sqrt{d}D_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "Lemma G.5 (Optimism). Let $\\lambda=1$ in Algorithm 2 and set $c_{0}\\,=\\,\\Phi(1)$ : Under Definition 4.1, conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta$ where $|{\\mathcal{C}}(\\varepsilon)|\\leq$ $(3/\\varepsilon)^{d}$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for all $(s,a)\\in S\\times A$ , we have ", "page_idx": 46}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)\\leq A_{\\delta}\\varepsilon,\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $A_{\\delta}=c_{1}\\sigma\\sqrt{d}+5H\\sqrt{d}D_{\\delta}=\\widetilde{\\mathcal{O}}(H d).$ ", "page_idx": 46}, {"type": "text", "text": "Lemma G.6 (Error bound). Let $\\lambda=1$ in Algorithm 2. Under Definition 4.1, for any fixed $0<\\delta<1$ conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability $1-\\delta$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times{\\mathcal{A}}$ , we have ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r}{-l_{m,h}^{k}(s,a)\\leq c_{2}H d\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "text", "text": "where $c_{2}=\\widetilde{\\mathcal{O}}(1)$ ", "page_idx": 46}, {"type": "text", "text": "G.2 Regret Analysis ", "text_level": 1, "page_idx": 46}, {"type": "text", "text": "In this part, we give out the proof of Theorem 4.2, the regret bound for CoopTS-PHE ", "page_idx": 46}, {"type": "text", "text": "Proof of Theorem 4.2. Based on the result from Lemma D.13, we do the regret decomposition first ", "page_idx": 46}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathrm{Regret}(K)=\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}V_{m,1}^{*}\\big(s_{m,1}^{k}\\big)-V_{m,1}^{\\pi_{m}^{k}}\\big(s_{m,1}^{k}\\big)}\\\\ &{\\qquad\\qquad=\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi^{*}}\\big[\\langle Q_{m,h}^{k}(s_{m,h},\\cdot),\\pi_{m,h}^{*}(\\cdot,|s_{m,h}\\rangle-\\pi_{m,h}^{k}(\\cdot|s_{m,h})\\rangle|s_{m,1}=s_{m,1}^{k}\\big]}\\\\ &{\\qquad\\qquad\\qquad+\\displaystyle\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}(D_{m,k,h,1}+D_{m,k,h,2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 46}, {"type": "equation", "text": "$$\n+\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\left(\\mathbb{E}_{\\pi^{*}}\\left[l_{m,h}^{k}\\big(s_{m,h},a_{m,h}\\big)\\middle|s_{m,1}=s_{m,1}^{k}\\right]-l_{m,h}^{k}\\big(s_{m,h}^{k},a_{m,h}^{k}\\big)\\right).\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Next, we will bound the above three terms respectively. ", "page_idx": 47}, {"type": "text", "text": "Bounding Term (i) in (G.2): for the policy $\\pi_{m,h}^{k}$ Tm.h, we have ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\mathbb{E}_{\\pi^{*}}\\big[\\langle Q_{m,h}^{k}(s_{m,h},\\cdot),\\pi_{m,h}^{*}(\\cdot,|s_{m,h})-\\pi_{m,h}^{k}(\\cdot|s_{m,h})\\rangle|s_{m,1}=s_{m,1}^{k}\\big]\\le0.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "This is bcauseby efniton $\\pi_{m,h}^{k}$ is the gredy pole for $Q_{m,h}^{k}$ ", "page_idx": 47}, {"type": "text", "text": "Bounding Term (i) in (G.2): note that $0\\leq Q_{m,h}^{k}\\,\\leq\\,H-h+1\\leq H$ , based on (D.1), for any $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ we have $|D_{m,k,h,1}|\\leq2H$ and $|D_{m,k,h,2}|\\leq2H$ . Note that $D_{m,k,h,1}$ is a martingale difference sequence $\\mathbb{E}[D_{m,k,h,1}|\\mathcal{F}_{m,k,h}]=0$ . By applying Azuma-Hoeffding inequality, with probability at least $1-\\delta/3$ , we have ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,1}\\leq2\\sqrt{2M H^{3}K\\log(6/\\delta)}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Note that $D_{m,k,h,2}$ is also a martingale difference sequence. By applying Azuma-Hoeffding inequality, with probability at least $1-\\delta/3$ ,wehave ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,2}\\leq2\\sqrt{2M H^{3}K\\log(6/\\delta)}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "By taking union bound, with probability at least $1-2\\delta/3$ ,wehave ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,1}+\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}D_{m,k,h,2}\\le4\\sqrt{2M H^{3}K\\log(6/\\delta)}.\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "Bounding Term (i) in (G.2): conditioned on the event $\\mathcal{G}(M,K,H,\\delta^{\\prime})$ , based on Lemma G.6 and Lemma G.5, by taking union bound, with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta^{\\prime}-M H K\\delta^{\\prime}$ wehave ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{m\\in\\mathbb{M}}\\displaystyle\\sum_{h=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\big(\\mathbb{E}_{x^{*}}\\big[l_{m,h}^{k}(s_{m,h},a_{m,h})\\big]s_{m,1}=s_{m,1}^{k}\\big]-l_{m,h}^{k}\\big(\\textstyle\\frac{s_{m,h}^{k}}{s_{m,h}^{k}},a_{m,h}^{k}\\big)\\big)}\\\\ &{\\le\\displaystyle\\sum_{m\\in\\mathbb{M}}\\displaystyle\\sum_{k=1}^{K}\\displaystyle\\sum_{h=1}^{H}\\big(A_{\\delta^{\\varepsilon}}\\varepsilon-l_{m,h}^{k}\\big(s_{m,h}^{k},a_{m,h}^{k}\\big)\\big)}\\\\ &{\\le H M K A_{\\delta^{\\varepsilon}}+\\displaystyle\\sum_{m\\in\\mathbb{M}}\\sum_{h=1}^{K}\\displaystyle\\sum_{h=1}^{H}c_{2}d H\\big\\|\\phi(s_{m,h}^{k},a_{m,h}^{k})\\big\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\le H M K A_{\\delta^{\\varepsilon}}+c_{2}d H\\displaystyle\\sum_{h=1}^{H}\\bigg(\\log\\bigg(\\frac{\\operatorname*{det}(\\Lambda_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathrm{M})}\\bigg)+1\\bigg)M\\sqrt{\\gamma+2\\sqrt{M K\\log\\bigg(\\frac{\\operatorname*{det}(\\Lambda_{h}^{K})}{\\operatorname*{det}(\\lambda\\mathrm{M})}\\bigg)}}}\\\\ &{\\le H M K A_{\\delta^{\\varepsilon}}+c_{2}d H\\cdot H\\big(d(\\log(1+M K/d)+1)M\\sqrt{\\gamma+2\\sqrt{M K d\\log(1+M K/d)}}\\big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "The first inequality follows from Lemma G.5, the second inequality holds due to Lemma G.6, the third inequality follows from Lemma D.12, the last inequality holds due to Lemma J.2 and the fact that $\\lVert\\phi(\\cdot)\\rVert_{2}\\leq1$ ", "page_idx": 47}, {"type": "text", "text": "Here we choose $\\varepsilon=d H\\sqrt{d/M K}/A_{\\delta^{\\prime}}=\\widetilde{\\mathcal{O}}(\\sqrt{d/M K})$ . Conditioned on the event $\\mathcal{G}(M,K,H,\\delta^{\\prime})$ we have ", "page_idx": 47}, {"type": "equation", "text": "$$\n\\sum_{m\\in\\mathcal{M}}\\sum_{k=1}^{K}\\sum_{h=1}^{H}\\big(\\mathbb{E}_{\\pi^{*}}\\big[l_{m,h}^{k}(s_{m,h},a_{m,h})\\big]s_{m,1}=s_{m,1}^{k}\\big]-l_{m,h}^{k}\\big(s_{m,h}^{k},a_{m,h}^{k}\\big)\\big)\\leq\\widetilde{\\mathcal{O}}\\big(d H^{2}\\big(d M\\sqrt{\\gamma}+\\sqrt{d M K}\\big)\n$$", "text_format": "latex", "page_idx": 47}, {"type": "text", "text": "with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta^{\\prime}\\!-\\!M H K\\delta^{\\prime}$ Based on Lemma G.2, the event $\\mathcal{G}(M,K,H,\\delta^{\\prime})$ occurs with probability at least $1-\\delta^{\\prime}$ . Therefore, (G.5) occurs with probability at least ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\big(1-\\delta^{\\prime}\\big)\\big(1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta^{\\prime}-M H K\\delta^{\\prime}\\big).\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "We set $\\delta^{\\prime}=\\delta/6(M H K+2)$ and choose $N={\\widetilde{C}}\\log(\\delta)/\\log(c_{0})$ where $\\widetilde{C}=\\widetilde{O}(d)$ , then we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left(1-\\delta^{\\prime}\\right)\\left(1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta^{\\prime}-M H K\\delta^{\\prime}\\right)\\geq1-\\delta/3.}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Combining Terms (i)(i)(i) together: Based on (G.3), (G.4) and (G.5). By taking union bound, we get that the final regret bound for CoopTS-PHE is $\\widetilde{\\mathcal{O}}\\big(d H^{2}\\big(d M\\sqrt{\\gamma}+\\sqrt{d M K}\\big)\\big)$ with probability at least $1-\\delta$ \u53e3 ", "page_idx": 48}, {"type": "text", "text": "H Proof of Supporting Lemmas in Appendix G ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "H.1  Proof of Proposition G.1 ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Proof. Based on (3.5), we can calculate that ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\widetilde{\\mathbf{w}}_{m,h}^{k,n}=\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-1}\\Bigg(\\sum_{\\scriptstyle(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}\\big[\\big(r_{h}\\big(s^{l},a^{l}\\big)+\\epsilon_{h}^{k,l,n}\\big)+V_{m,h+1}^{k}\\big(s^{\\prime}\\big)\\big]\\phi\\big(s^{l},a^{l}\\big)-\\lambda\\xi_{h}^{k,n}\\Bigg)}\\\\ &{\\qquad=\\widehat{\\mathbf{w}}_{m,h}^{k}+\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\sum_{\\scriptstyle(s^{l},a^{l},s^{\\prime})\\in U_{m,h}(k)}\\epsilon_{h}^{k,l,n}\\phi\\big(s^{l},a^{l}\\big)-\\lambda\\xi_{h}^{k,n}\\Bigg),\\qquad\\qquad\\qquad\\qquad(\\mathrm{H.1.})}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Where $\\begin{array}{r}{\\widehat{\\mathbf{w}}_{m,h}^{k}=\\big({\\mathbf{\\Lambda}}_{m,h}^{k}\\big)^{-1}\\Big(\\sum_{(s^{l},a^{l},s^{\\prime}})\\!\\in\\!U_{m,h}(k)\\,\\big[r_{h}+V_{m,h+1}^{k}\\big(s^{\\prime}\\!^{l}\\big)\\big]\\phi\\big(s^{l},a^{l}\\big)\\Big)}\\end{array}$ is the unperturbed estimated parameter. Since eh eh,n \\~N(0,\u00b2), forl E [K(k)], based on the property of Gaussian distribution, we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\epsilon_{h}^{k,l,n}\\phi\\big(s^{l},a^{l}\\big)\\sim\\mathcal{N}\\bigg(0,\\sigma^{2}\\phi\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)^{\\top}\\bigg),\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "Since $\\xi_{h}^{k,n}\\sim\\mathcal{N}(\\mathbf{0},\\sigma^{2}\\mathbf{I})$ , we can calculate the covariance matrix of the second term in (H.1), ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-1}\\mathrm{Cov}\\left(\\sum_{\\scriptstyle(s^{l},a^{l},s^{l})\\in{\\cal U}_{m,h}({\\cal k})}\\epsilon_{h}^{k,l,n}\\phi(s^{l},a^{l})-\\lambda\\xi_{h}^{k,n}\\right)\\left(\\mathbf{A}_{m,h}^{k}\\right)^{-1}}\\\\ &{=\\left(\\Lambda_{m,h}^{k}\\right)^{-1}\\sigma^{2}\\left(\\sum_{\\scriptstyle(s^{l},a^{l},s^{l})\\in{\\cal U}_{m,h}({\\cal k})}\\phi(s^{l},a^{l})\\phi(s^{l},a^{l})^{\\top}+\\lambda\\mathbf{I}\\right)\\left(\\Lambda_{m,h}^{k}\\right)^{-1}}\\\\ &{=\\sigma^{2}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\mathbf{A}_{m,h}^{k}\\left(\\Lambda_{m,h}^{k}\\right)^{-1}}\\\\ &{=\\sigma^{2}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "It is obvious that the mean of the second term in (H.1) is 0. Thus, we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\boldsymbol{\\zeta}_{m,h}^{k,n}=\\widetilde{\\mathbf{w}}_{m,h}^{k,n}-\\widehat{\\mathbf{w}}_{m,h}^{k}\\sim{\\mathcal{N}}\\Big(0,\\sigma^{2}\\big({\\mathbf{A}}_{m,h}^{k}\\big)^{-1}\\Big).}\\end{array}\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "This completes the proof. ", "page_idx": 48}, {"type": "text", "text": "H.2Proof of Lemma G.2 ", "text_level": 1, "page_idx": 48}, {"type": "text", "text": "Proof. Recall that in Proposition G.1, we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\bigl\\{\\mathsf{\\Sigma}_{m,h}^{k,n}\\bigr\\}\\sim\\mathcal{N}\\Bigl(\\mathbf{0},\\sigma^{2}\\bigl(\\mathbf{A}_{m,h}^{k}\\bigr)^{-1}\\Bigr).\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "By Lemma J.10, for fixed $n\\in[N]$ , with probability at least $1-\\delta$ , we have ", "page_idx": 48}, {"type": "equation", "text": "$$\n\\|\\zeta_{m,h}^{k,n}\\|_{\\mathbf{\\Lambda}_{\\Lambda_{m,h}^{k}}^{k}}\\leq c\\sqrt{d\\sigma^{2}\\log(d/\\delta)}.\n$$", "text_format": "latex", "page_idx": 48}, {"type": "text", "text": "By applying union bound over $N$ samples, we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big(\\operatorname*{max}_{n\\in[N]}\\left\\|{\\boldsymbol{\\zeta}}_{m,h}^{k,n}\\right\\|_{\\boldsymbol{\\Lambda}_{m,h}^{k}}\\leq c\\sqrt{d\\sigma^{2}\\log(d/\\delta)}\\Big)\\geq1-N\\delta.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Now we define $c_{1}=c\\sqrt{\\log(d N M K H/\\delta)}$ , and we define the event ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{G}_{m,h}^{k}(\\zeta,\\delta)\\stackrel{\\mathrm{def}}{=}\\Big\\{\\underset{n\\in[N]}{\\operatorname*{max}}\\;\\big\\|\\zeta_{m,h}^{k,n}\\big\\|_{\\mathbf{A}_{m,h}^{k}}\\leq c_{1}\\sigma\\sqrt{d}\\Big\\}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Thus for any fixed $m,h$ and $k$ , the event $\\mathcal{G}_{m,h}^{k}(\\zeta,\\delta)$ occurs with a probability of at least $1-\\delta/M K H$ By taking union bound over all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ ,we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\mathbb{P}\\big(\\mathcal{G}(M,K,H,\\delta)\\big)=\\mathbb{P}\\Bigg(\\bigcap_{m\\in\\mathcal{M}}\\bigcap_{k\\le K}\\bigcap_{h\\le H}\\mathcal{G}_{m,h}^{k}(\\zeta,\\delta)\\Bigg)\\ge1-\\delta.\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "This completes the proof. ", "page_idx": 49}, {"type": "text", "text": "H.3 Proof of Lemma G.3 ", "text_level": 1, "page_idx": 49}, {"type": "text", "text": "Proof. Based on the result in Lemma D.4, for any $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ ,wehave ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left\\|\\widehat{\\mathbf{w}}_{m,h}^{k}\\right\\|\\leq2H\\sqrt{M k d/\\lambda}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "By recalling the construction of ${\\pmb{\\Lambda}}_{m,h}^{k}$ , it is trivial to find that $\\lambda_{\\operatorname*{min}}\\left(\\mathbf{A}_{m,h}^{k}\\right)\\geq\\lambda$ . Conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , we have ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\sqrt{\\lambda}\\|\\zeta_{m,h}^{k,n}\\|\\leq\\|\\zeta_{m,h}^{k,n}\\|_{\\mathbf{A}_{m,h}^{k}}\\leq c_{1}\\sigma\\sqrt{d}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Then by triangle inequality, for all $n\\in[N]$ , we obtain the upper bound ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathopen{}\\mathclose\\bgroup\\left\\|\\widetilde{\\mathbf{w}}_{m,h}^{k,n}\\aftergroup\\egroup\\right\\|=\\mathopen{}\\mathclose\\bgroup\\left\\|\\widehat{\\mathbf{w}}_{m,h}^{k}+\\boldsymbol{\\zeta}_{m,h}^{k,n}\\aftergroup\\egroup\\right\\|\\leq2H\\sqrt{M k d/\\lambda}+c_{1}\\sigma\\sqrt{d/\\lambda}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Based on the result from Lemma J.7 and Lemma J.9, we have that, for any $\\varepsilon\\;>\\;0$ ,and for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ , with probability at least $1-\\delta$ wehave ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left\\|\\underset{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}{\\sum}\\phi\\big(s^{l},a^{l}\\big)\\big[\\big(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\big)\\big(s^{l},a^{l}\\big)\\big]\\right\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\leq\\Bigg(4H^{2}\\Bigg[\\frac{d}{2}\\log\\bigg(\\frac{k+\\lambda}{\\lambda}\\bigg)+d\\log\\Bigg(\\frac{3\\big(2H\\sqrt{M k d/\\lambda}+c_{1}\\sigma\\sqrt{d/\\lambda}\\big)}{\\varepsilon}\\Bigg)+\\log\\frac{1}{\\delta}\\Bigg]+\\frac{8k^{2}\\varepsilon^{2}}{\\lambda}\\Bigg)^{1/2}}\\\\ &{\\leq2H\\Bigg[\\frac{d}{2}\\log\\bigg(\\frac{k+\\lambda}{\\lambda}\\bigg)+d\\log\\Bigg(\\frac{3\\big(2H\\sqrt{M k d/\\lambda}+c_{1}\\sigma\\sqrt{d/\\lambda}\\big)}{\\varepsilon}\\Bigg)+\\log\\frac{1}{\\delta}\\Bigg]^{1/2}+\\frac{2\\sqrt{2}k\\varepsilon}{\\sqrt{\\lambda}}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "Here we set \u5165 = 1,\u03b5 = $\\begin{array}{r}{\\lambda=1,\\varepsilon=\\frac{H}{2\\sqrt{2}k}}\\end{array}$ 2 with probabilityat least , wehave ", "page_idx": 49}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\bigg\\|\\sum_{(s^{l},a^{l},s^{\\prime\\prime})\\in U_{m,h}(k)}\\phi\\big(s^{l},a^{l}\\big)\\big[\\big(V_{m,h+1}^{k}-\\mathbb{P}_{h}V_{m,h+1}^{k}\\big)\\big(s^{l},a^{l}\\big)\\big]\\bigg\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}}\\\\ &{\\leq2H\\sqrt{d}\\Bigg[\\displaystyle\\frac{1}{2}\\log(K+1)+\\log\\left(\\frac{6\\sqrt{2}K\\big(2H\\sqrt{M K d}+c_{1}\\sigma\\sqrt{d}\\big)}{H}\\right)+\\log\\displaystyle\\frac{1}{\\delta}\\Bigg]^{1/2}+H}\\\\ &{\\leq3H\\sqrt{d}D_{\\delta},}\\end{array}\n$$", "text_format": "latex", "page_idx": 49}, {"type": "text", "text": "where we define $\\begin{array}{r}{D_{\\delta}=\\Big[\\frac{1}{2}\\log(K+1)+\\log\\Big(\\frac{6\\sqrt{2}K\\left(2H\\sqrt{M K d}+c_{1}\\sigma\\sqrt{d}\\right)}{H}\\Big)+\\log\\frac{1}{\\delta}\\Big]^{1/2}}\\end{array}$the proof. \u53e3", "page_idx": 49}, {"type": "text", "text": "H.4 Proof of Lemma G.4 ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Proof. This proof is almost same as the proof of Lemma D.8 in Appendix E.6. The only difference is the Term (i) in (E.10). Here based on Lemma G.6, conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ ,with probability $1-\\delta$ ,wehave ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\mathbf{Term}\\ (\\mathbf{i})\\leq3H\\sqrt{d}D_{\\delta}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Finally, conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability $1-\\delta$ , for all $(m,k,h)\\in\\mathcal{M}\\times$ $[K]\\times[H]$ and for any $(s,a)\\in S\\times{\\dot{A}}$ , we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\begin{array}{r l}&{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\right|\\leq\\big(3H\\sqrt{d}D_{\\delta}+H\\sqrt{d}+\\sqrt{d}\\big)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\leq5H\\sqrt{d}D_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,k}^{k})^{-1}}.}\\end{array}}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Here we finish the proof. ", "page_idx": 50}, {"type": "text", "text": "H.5 Proof of Lemma G.5 ", "text_level": 1, "page_idx": 50}, {"type": "text", "text": "Proof. Recall from Definition 4.1, we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)=\\phi(s,a)^{\\top}\\theta_{h}+\\phi(s,a)^{\\top}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{\\mathcal{S}}\\stackrel{\\mathrm{def}}{=}\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k},}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where $\\mathbf{w}_{m,h}^{k}\\,=\\,\\pmb{\\theta}_{h}\\,+\\,\\langle\\pmb{\\mu}_{h},V_{m,h+1}^{k}\\rangle_{S}$ Note that $\\operatorname*{max}\\{\\|\\mu_{h}(S)\\|,\\|\\pmb{\\theta}_{h}\\|\\}\\,\\le\\,\\sqrt{d}$ and $V_{m,h+1}^{k}\\leq$ $H-h\\leq{\\dot{H}}$ , thus we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\|\\mathbf{w}_{m,h}^{k}\\|\\leq\\|\\pmb{\\theta}_{h}\\|+\\|\\langle\\pmb{\\mu}_{h},V_{m,h+1}^{k}\\rangle_{S}\\|}\\\\ &{\\qquad\\qquad\\leq\\sqrt{d}+H\\sqrt{d}}\\\\ &{\\qquad\\qquad\\leq2H\\sqrt{d}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Then we defne the regression errr wm,h = wm,h. Forany $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and any $(s,a)\\in S\\times A$ ,we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\frac{k}{m,h}(s,a)=r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-Q_{m,h}^{k}(s,a)}\\\\ &{\\qquad\\qquad=r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\operatorname*{min}\\Big\\{H-h+1,\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\Big(\\widehat{\\mathbf{w}}_{m,h}^{k}+\\xi_{m,h}^{k,n}\\Big)\\Big\\}^{+}}\\\\ &{\\qquad\\qquad\\leq\\operatorname*{max}\\Big\\{\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k}-(H-h+1),\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k}-\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\Big(\\widehat{\\mathbf{w}}_{m,h}^{k}+\\xi_{m,h}^{k,n}\\Big)\\Big\\}}\\\\ &{\\qquad\\qquad\\leq\\operatorname*{max}\\Big\\{0,\\phi(s,a)^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}-\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\xi_{m,h}^{k,n}\\Big\\},\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\mathrm{H.2})}\\end{array}\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "where the last inequality holds because $\\vert r_{h}\\vert\\le1$ and $V_{m,h+1}^{k}\\leq H-h$ this indcates $r_{h}(s,a)+$ $\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)=\\boldsymbol{\\phi}(s,a)^{\\top}\\mathbf{w}_{m,h}^{k}\\leq H-h+1$ Note that $\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\leq\\sqrt{1/\\lambda}\\|\\phi(s,a)\\|\\leq$ 1 for all $\\phi(s,a)$ . Define $\\mathcal C(\\varepsilon)$ to be a $\\varepsilon$ -cover of $\\left\\{\\phi\\mid\\|\\phi\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\leq1\\right\\}$ . Based on Lemma J.8, we have $|{\\mathcal{C}}(\\varepsilon)|\\leq(3/\\varepsilon)^{d}$ ", "page_idx": 50}, {"type": "text", "text": "First, for any fixed $\\phi(s,a)\\in\\mathcal{C}(\\varepsilon)$ , we have ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\bigl\\{\\phi^{\\top}\\zeta_{m,h}^{k,n}\\bigr\\}\\sim\\mathcal{N}\\Bigl(\\mathbf{0},\\sigma^{2}\\|\\phi\\|_{(\\Lambda_{m,h}^{k})^{-1}}^{2}\\Bigr).\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "Use the property of Gaussian distribution, we obtain ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big(\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\sigma\\|\\phi\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\geq0\\Big)=\\Phi(-1).\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "By taking union bound over $n\\in[N]$ , we obtain ", "page_idx": 50}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Big(\\operatorname*{max}_{n\\in[N]}\\big\\{\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\sigma\\|\\phi\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\big\\}\\geq0\\Big)\\geq1-\\big(1-\\Phi(-1)\\big)^{N}=1-\\Phi(1)^{N}=1-c_{0}^{N}.\n$$", "text_format": "latex", "page_idx": 50}, {"type": "text", "text": "By applying union bound over $\\mathcal C(\\varepsilon)$ , with probability $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}$ , for all $\\phi\\in{\\mathcal{C}}(\\varepsilon)$ , we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\{\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\sigma\\|\\phi\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\right\\}\\geq0.\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Then, for any $\\phi\\,=\\,\\phi(s,a)$ , we can find $\\phi^{\\prime}\\,\\in\\,\\mathcal{C}(\\varepsilon)$ such that $\\|\\phi-\\phi^{\\prime}\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\,\\le\\,\\varepsilon$ . Define $\\Delta\\phi=\\phi-\\phi^{\\prime}$ , we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\phi^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}=\\phi^{\\prime^{\\top}}\\zeta_{m,h}^{k,n}-\\phi^{\\prime^{\\top}}\\Delta\\mathbf{w}_{m,h}^{k}+\\Delta\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\Delta\\phi^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\phi^{\\prime^{\\top}}\\zeta_{m,h}^{k,n}-\\Vert\\phi^{\\prime}\\Vert_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\Vert\\Delta\\mathbf{w}_{m,h}^{k}\\Vert_{\\mathbf{A}_{m,h}^{k}}-\\Vert\\Delta\\phi\\Vert_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\Vert\\zeta_{m,h}^{k,n}\\Vert_{\\mathbf{A}_{m,h}^{k}}}\\\\ &{\\qquad\\qquad\\qquad-\\left\\Vert\\Delta\\phi\\right\\Vert_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\Vert\\Delta\\mathbf{w}_{m,h}^{k}\\Vert_{\\mathbf{A}_{m,h}^{k}}}\\\\ &{\\qquad\\qquad\\qquad\\geq\\phi^{\\prime^{\\top}}\\zeta_{m,h}^{k,n}-\\Vert\\phi^{\\prime}\\Vert_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\Vert\\Delta\\mathbf{w}_{m,h}^{k}\\Vert_{\\mathbf{A}_{m,h}^{k}}}\\\\ &{\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad(\\mathbf{H}.4)}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "Conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\|\\zeta_{m,h}^{k,n}\\|_{\\mathbf{A}_{m,h}^{k}}\\leq c_{1}\\sigma\\sqrt{d}.\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "For any vector $\\mathbf{x}\\in\\mathbb{R}^{d}$ , we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\mathbf{x}^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}=\\mathbf{x}^{\\top}\\big(\\mathbf{w}_{m,h}^{k}-\\widehat{\\mathbf{w}}_{m,h}^{k}\\big)}\\\\ &{\\phantom{\\ x x}=\\mathbf{x}^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\mathbf{A}_{m,h}^{k}\\mathbf{w}_{m,h}^{k}-\\bigg(\\sum_{(s^{\\prime},a^{\\prime},s^{\\prime})\\in U_{m,h}(k)}\\big[r_{h}+V_{m,h+1}^{k}\\big(s^{\\prime})\\big]\\phi\\big(s^{\\prime},a^{\\prime}\\big)\\bigg)\\Bigg)}\\\\ &{\\phantom{\\ x x}=\\mathbf{x}^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\sum_{l=1}^{K(k)}\\phi\\big(s^{l},a^{l}\\big)\\phi\\big(s^{l},a^{l}\\big)^{\\top}\\mathbf{w}_{m,h}^{k}+\\lambda\\mathbf{w}_{m,h}^{k}}\\\\ &{\\phantom{\\ x x}-\\bigg(\\sum_{l=1}^{K(k)}\\big[r_{h}+V_{m,h+1}^{k}\\big(s^{l}\\big)\\big]\\phi\\big(s^{l},a^{l}\\big)\\bigg)\\Bigg)}\\\\ &{\\phantom{\\ x x}=\\mathbf{x}^{\\top}\\big(\\mathbf{A}_{m,h}^{k}\\big)^{-1}\\Bigg(\\mathbf{w}_{m,h}^{k}+\\Bigg(\\sum_{l=1}^{K(k)}\\big[\\mathbb{B}_{h}V_{m,h+1}^{k}-V_{m,h+1}^{k}\\big(s^{l}\\big)\\big]\\phi\\big(s^{l},a^{l}\\big)\\Bigg)\\Bigg),}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "where the third equality holds due to the definition of Am,h. We set x = Akm. $\\mathbf{x}=\\mathbf{A}_{m,h}^{k}\\Delta\\mathbf{w}_{m,h}^{k}$ By using Cauchy-Schwarz inequality, we have ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\left\\lvert\\Delta\\mathbf{w}_{m,h}^{k}\\right\\rvert\\right\\rvert_{\\boldsymbol{\\Lambda}_{m,h}^{k}}^{2}=\\Delta\\mathbf{w}_{m,h}^{k}\\,\\mathrm{\\Delta}^{\\top}\\bigg(\\mathbf{w}_{m,h}^{k}+\\Bigg(\\displaystyle\\sum_{l=1}^{K(k)}\\left[\\mathbb{P}_{h}V_{m,h+1}^{k}-V_{m,h+1}^{k}\\big(s^{\\prime}\\big)\\right]\\phi\\big(s^{l},a^{l}\\big)\\Bigg)\\Bigg)}\\\\ &{\\displaystyle\\qquad\\qquad\\qquad\\leq\\left\\lVert\\Delta\\mathbf{w}_{m,h}^{k}\\right\\rVert_{\\boldsymbol{\\Lambda}_{m,h}^{k}}\\cdot\\left\\lVert\\mathbf{w}_{m,h}^{k}+\\Bigg(\\displaystyle\\sum_{l=1}^{K(k)}\\left[\\mathbb{P}_{h}V_{m,h+1}^{k}-V_{m,h+1}^{k}\\big(s^{\\prime}\\big)\\right]\\phi\\big(s^{l},a^{l}\\big)\\right)\\right\\rVert_{(\\Lambda_{m,h}^{k})^{-\\frac{1}{2}}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "This indicates that with probability at least $1-\\delta$ , for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ wehave ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\big\\|\\Delta\\mathbf{w}_{m,h}^{k}\\big\\|_{\\boldsymbol{\\Lambda}_{m,h}^{k}}\\leq\\big\\|\\mathbf{w}_{m,h}^{k}\\big\\|_{(\\Lambda_{m,h}^{k})^{-1}}+\\bigg\\|\\displaystyle\\sum_{l=1}^{K(k)}\\big[\\mathbb{P}_{h}V_{m,h+1}^{k}-V_{m,h+1}^{k}\\big(s^{\\prime}\\big)\\big]\\phi\\big(s^{l},a^{l}\\big)\\bigg\\|_{(\\Lambda_{m,h}^{k})^{-1}}}}\\\\ &{\\leq\\big\\|\\mathbf{w}_{m,h}^{k}\\big\\|+3H\\sqrt{d}D_{\\delta}}\\\\ &{\\leq5H\\sqrt{d}D_{\\delta},}\\end{array}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "text", "text": "where the second inequality holds because of Lemma G.3. Then for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ with probability at least $1-\\delta$ , (H.4) becomes ", "page_idx": 51}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\{\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\phi^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\right\\}\n$$", "text_format": "latex", "page_idx": 51}, {"type": "equation", "text": "$$\n\\geq\\operatorname*{max}_{n\\in[N]}\\big\\{\\phi^{\\prime^{\\top}}\\zeta_{m,h}^{k,n}-\\|\\phi^{\\prime}\\|_{(\\Lambda_{m,h}^{k})^{-1}}\\big\\|\\Delta\\mathbf{w}_{m,h}^{k}\\big\\|_{\\Lambda_{m,h}^{k}}\\big\\}-\\varepsilon\\big(c_{1}\\sigma\\sqrt{d}+5H\\sqrt{d}D_{\\delta}\\big).\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Now we choose $\\sigma\\;=\\;{\\widetilde{\\cal O}}(H{\\sqrt{d}})$ and guarantee that $\\sigma\\ >\\ 5H\\sqrt{d}D_{\\delta}\\ \\geq\\ \\|\\Delta\\mathbf{w}_{m,h}^{k}\\|_{\\mathbf{A}_{m,h}^{k}}$ , this is achievable through calculation. Define ${\\cal A}_{\\delta}\\ =\\ c_{1}\\sigma\\sqrt{d}\\,+\\,5H\\sqrt{d}{\\cal D}_{\\delta}\\ =\\ \\tilde{\\mathcal{O}}(H d)$ . Then, for all $(m,h,k)\\in\\mathcal{M}\\times\\bar{[H]}\\times[K]$ , with probability at least $1-\\delta$ , we have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\big\\{\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\phi^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\big\\}\\geq\\operatorname*{max}_{n\\in[N]}\\big\\{\\phi^{\\prime}^{\\top}\\zeta_{m,h}^{k,n}-\\sigma\\|\\phi^{\\prime}\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}\\big\\}-A_{\\delta}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Recall from (H.3), by taking union bound, with probability at least $1\\,-\\,|\\mathcal{C}(\\varepsilon)|c_{0}^{N}\\,-\\,\\delta$ , for all $(m,h,k)\\in\\mathcal{M}\\times[H]^{'}\\times[K]$ and for all $(s,a)\\in S\\times A$ wehave ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\{\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\phi^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\right\\}\\geq-A_{\\delta}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Finally, recall from (H.2), we have, with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta$ , for all $(m,h,k)\\in$ $\\mathcal{M}\\times\\dot{[H]}\\times[K]$ and for all $(s,a)\\in S\\times A$ wehave ", "page_idx": 52}, {"type": "equation", "text": "$$\nl_{m,h}^{k}(s,a)\\leq A_{\\delta}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "This completes the proof. ", "page_idx": 52}, {"type": "text", "text": "H.6 Proof of Lemma G.6 ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "Proof. Recall the definition of model prediction error in Definition D.1, we get ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-l_{m,h}^{k}(s,a)=Q_{m,h}^{k}(s,a)-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\\\ &{\\qquad\\qquad=\\operatorname*{min}\\Big\\{\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\Big(\\widehat{\\mathbf{w}}_{m,h}^{k}+\\xi_{m,h}^{k,n}\\Big),H-h+1\\Big\\}^{+}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\\\ &{\\qquad\\quad\\leq\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\Big(\\widehat{\\mathbf{w}}_{m,h}^{k}+\\xi_{m,h}^{k,n}\\Big)-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)}\\\\ &{\\qquad\\quad=\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\xi_{m,h}^{k,n}-\\Big(r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\Big)}\\\\ &{\\qquad\\qquad\\leq\\Big|r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\Big|+\\displaystyle\\operatorname*{max}_{n\\in[N]}\\Big|\\phi(s,a)^{\\top}\\xi_{m,h}^{k,n}\\Big|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Based on Lemma G.4, conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability $1\\,-\\,\\delta$ ,for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times A$ ,wehave ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}(s,a)-{\\mathbb P}_{h}V_{m,h+1}^{k}(s,a)\\right|\\leq5H\\sqrt{d}D_{\\delta}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and for any $(s,a)\\in$ ${\\mathcal{S}}\\times{\\mathcal{A}}$ , we have ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\big|\\phi(s,a)^{\\top}\\zeta_{m,h}^{k,n}\\big|\\leq c_{1}\\sigma\\sqrt{d}\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "Combine (H.5) and (H.6), then use $\\sigma$ defined in Lemma G.5. Conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ with probability $1-\\delta$ , for all $(m,h,k)\\in\\mathcal{M}\\times[H]\\times[K]$ and for any $(s,a)\\in S\\times{\\dot{A}}$ ,we get ", "page_idx": 52}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-l_{m,h}^{k}(s,a)\\leq\\big(5H\\sqrt{d}D_{\\delta}+c_{1}\\sigma\\sqrt{d}\\big)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}}\\\\ &{\\qquad\\qquad\\leq c_{2}H d\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}},}\\end{array}\n$$", "text_format": "latex", "page_idx": 52}, {"type": "text", "text": "where $c_{2}=\\widetilde{\\mathcal{O}}(1)$ . Here we completes the proof. ", "page_idx": 52}, {"type": "text", "text": "1  Proof of the Regret Bound for CoopTS-PHE in Misspecified Setting ", "text_level": 1, "page_idx": 52}, {"type": "text", "text": "In this section, we prove the regret bound for CoopTS-PHE in the misspecified setting. The regret analysis, the essential supporting lemmas and their corresponding proofs are very similar to what we have presented in Appendix G and Appendix H. Here we mainly point out the differences of proof between these two settings. ", "page_idx": 52}, {"type": "text", "text": "1.1  Supporting Lemmas ", "text_level": 1, "page_idx": 53}, {"type": "text", "text": "Lemma I.1. Let $\\lambda=1$ in Algorithm 2. Under Definition 4.8, for any fixed $0<\\delta<1$ 2, conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability $1-\\delta$ , for all $({\\dot{m}},k,h)\\ {\\dot{\\in}}\\ {\\mathcal{M}}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times{\\mathcal{A}}$ , we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\left|\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}-r_{h}(s,a)-\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)\\right|\\leq\\left(5H\\sqrt{d}D_{\\delta}+3H\\zeta\\sqrt{M K d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{m,h}^{k})^{-1}}+3H\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where $D_{\\delta}$ is defined in Lemma G.3. ", "page_idx": 53}, {"type": "text", "text": "Proof of Lemma I.1. This proof is almost same as the proof of Lemma F.2, with the only difference in bounding Term(i) in (F.3). Here (F.4) becomes ", "page_idx": 53}, {"type": "equation", "text": "$$\n|\\mathbf{Term(i)}|\\leq3H\\sqrt{d}D_{\\delta}\\|\\phi(s,a)\\|_{(\\mathbf{A}_{m,h}^{k})^{-1}}.\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Finally we can get the desired result ", "page_idx": 53}, {"type": "text", "text": "Lemma 1.2 (Optimism). Let $\\lambda\\,=\\,1$ in Algorithm 2 and set $c_{0}\\;=\\;\\Phi(1)$ : Under Definition 4.8, conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta$ where $|{\\mathcal{C}}(\\varepsilon)|\\leq$ $(3/\\varepsilon)^{d}$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for all $(s,a)\\in S\\times A$ , we have ", "page_idx": 53}, {"type": "equation", "text": "$$\nl_{m,h}^{k}\\le A_{\\delta}\\varepsilon+3H\\zeta,\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Wwhere $A_{\\delta}=c_{1}\\sigma\\sqrt{d}+5H\\sqrt{d}D_{\\delta}=\\widetilde{\\mathcal{O}}(H d).$", "page_idx": 53}, {"type": "text", "text": "Proof of Lemma I.2. This proof is similar to the proof in Appendix H.5. In the previous part, we havedefined ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\Delta_{m,1}=\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\langle\\mu_{h},V_{m,h+1}^{k}\\rangle_{s},}\\\\ &{\\Delta_{m,2}=r_{m,h}(s,a)-\\phi(s,a)^{\\top}\\theta_{h},}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where $|\\Delta_{m,1}|\\leq2H\\zeta$ and $|\\Delta_{m,2}|\\leq\\zeta$ . Thus we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r}{r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)=\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k}+\\Delta_{m,1}+\\Delta_{m,2},}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where $\\mathbf{w}_{m,h}^{k}=\\langle\\pmb{\\mu}_{h},V_{m,h+1}^{k}\\rangle_{S}+\\pmb{\\theta}_{h}$ Then we define $\\Delta\\mathbf{w}_{m,h}^{k}=\\mathbf{w}_{m,h}^{k}-\\widehat{\\mathbf{w}}_{m,h}^{k}$ m,h.Forany (m,h, k) E $\\mathcal{M}\\times[H]\\times[K]$ and any $(s,a)\\in S\\times A$ , we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}{\\lefteqn{\\frac{k}{m_{n}h}(s,a)=r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-Q_{m,h}^{k}(s,a)}}\\\\ &{}&{=r_{m,h}(s,a)+\\mathbb{P}_{m,h}V_{m,h+1}^{k}(s,a)-\\operatorname*{min}\\Big\\{H-h+1,\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\Big(\\widehat{\\mathbf{w}}_{m,h}^{k}+\\zeta_{m,h}^{k,n}\\Big)\\Big\\}^{+}}\\\\ &{}&{\\leq\\operatorname*{max}\\Big\\{\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k}-(H-h+1),\\phi(s,a)^{\\top}\\mathbf{w}_{m,h}^{k}-\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\Big(\\widehat{\\mathbf{w}}_{m,h}^{k}+\\zeta_{m,h}^{k,n}\\Big)\\Big\\}}\\\\ &{}&{\\quad+\\:\\Delta_{m,1}+\\Delta_{m,2}}\\\\ &{}&{\\leq\\operatorname*{max}\\Big\\{0,\\phi(s,a)^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}-\\displaystyle\\operatorname*{max}_{n\\in[N]}\\phi(s,a)^{\\top}\\zeta_{m,h}^{k,n}\\Big\\}+3H\\zeta.}\\end{array}\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "In Appendix H.5, we have proved that with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{N}-\\delta$ , for all $(m,h,k)\\in$ $\\mathcal{M}\\times\\bar{[H]}\\times[K]$ and for ali $(s,a)\\in S\\times A$ ,wehave ", "page_idx": 53}, {"type": "equation", "text": "$$\n\\operatorname*{max}_{n\\in[N]}\\left\\{\\phi^{\\top}\\zeta_{m,h}^{k,n}-\\phi^{\\top}\\Delta\\mathbf{w}_{m,h}^{k}\\right\\}\\geq-A_{\\delta}\\varepsilon.\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "Substitute it into (I.2), we can get the final result. ", "page_idx": 53}, {"type": "text", "text": "Lemma I.3 (Error bound). Let $\\lambda=1$ in Algorithm 2. Under Definition 4.8, for any fixed $0<\\delta<1$ conditioned on the event $\\mathcal{G}(M,K,H,\\delta)$ , with probability $1-\\delta$ , for all $(m,k,h)\\in\\mathcal{M}\\times[K]\\times[H]$ and for any $(s,a)\\in S\\times{\\dot{A}}$ , we have ", "page_idx": 53}, {"type": "equation", "text": "$$\n-l_{m,h}^{k}(s,a)\\leq\\left(c_{2}H d+3H\\zeta\\sqrt{M K d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{h}^{k})^{-1}}+3H\\zeta,\n$$", "text_format": "latex", "page_idx": 53}, {"type": "text", "text": "where $c_{2}=\\widetilde{\\mathcal{O}}(1)$ is same as that in Lemma G.6. ", "page_idx": 53}, {"type": "text", "text": "Proof of Lemma I.3. Similar to the proof in Appendix H.6, using (H.6) in Appendix H.6 and (1.1), wehave ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{-l_{m,h}^{k}(s,a)\\leq\\left|r_{h}(s,a)+\\mathbb{P}_{h}V_{m,h+1}^{k}(s,a)-\\phi(s,a)^{\\top}\\widehat{\\mathbf{w}}_{m,h}^{k}\\right|+\\operatorname*{max}_{n\\in[N]}\\left|\\phi(s,a)^{\\top}\\zeta_{m,h}^{k,n}\\right|}\\\\ &{\\qquad\\qquad\\leq\\left(5H\\sqrt{d}D_{\\delta}+3H\\zeta\\sqrt{M K d}+c_{1}\\sigma\\sqrt{d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{h}^{k})^{-1}}+3H\\zeta}\\\\ &{\\qquad\\qquad\\leq\\left(c_{2}H d+3H\\zeta\\sqrt{M K d}\\right)\\|\\phi(s,a)\\|_{(\\Lambda_{h}^{k})^{-1}}+3H\\zeta,}\\end{array}\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "where $c_{2}=\\widetilde{\\mathcal{O}}(1)$ is same as that in Lemma G.6. Here we completes the proof. ", "page_idx": 54}, {"type": "text", "text": "1.2  Regret Analysis ", "text_level": 1, "page_idx": 54}, {"type": "text", "text": "In this part, we give out the proof of Theorem 4.10, the regret bound for CoopTS-PHE in the misspecified setting. ", "page_idx": 54}, {"type": "text", "text": "Proof of Theorem 4.10. This proof is almost same as the proof in Appendix G.2. We do the same regret decomposition (G.2) and obtain the same bound for Term (i) (G.3) and Term (i) (G.4). Next we bound Term (i) with new lemmas in misspecified setting. ", "page_idx": 54}, {"type": "text", "text": "Bounding Term (ii) in (G.2): conditioned on the event $\\mathcal{G}(M,K,H,\\delta^{\\prime})$ , based on Lemma I.3 and Lemma I.2, by taking union bound, with probability at least $1-|\\mathcal{C}(\\varepsilon)|c_{0}^{\\prime\\,N}-\\delta^{\\prime}-M H K\\delta^{\\prime}$ wehave ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\displaystyle\\sum_{n\\in\\mathbb{N}_{D}}\\mathbb{E}_{\\mathbb{E}_{n}}^{\\mathbb{E}_{n}}\\left(\\mathbb{E}_{n}\\left[\\phi_{n,k}(\\mathbf{m}_{b,k}\\mathbf{\\upmu}_{m,k})\\right]\\omega_{1,n}=\\frac{\\mathbf{b}_{n,k}}{n}\\right)-\\frac{\\mathbf{\\mu}_{n,k}}{n}(\\delta_{m,k}^{\\star}\\mathbf{a}_{m,k}^{\\star}))}\\\\ &{\\displaystyle\\leq\\sum_{n\\in\\mathbb{N}_{D}}\\sum_{i=1}^{n}\\left(-\\ell_{n,k}^{\\star}\\binom{n}{m}\\binom{n}{m}\\sum_{i=1}^{n}A\\ell_{i}+3A\\ell_{i}+3B\\ell_{i}\\right)}\\\\ &{\\displaystyle\\leq\\sum_{n\\in\\mathbb{N}_{D}}\\sum_{i=1}^{n}\\left(\\ell_{n,i}^{\\star}\\prod_{j=1}^{n}\\left(\\phi_{n,k}^{\\star}\\mathbf{\\upmu}_{n,j}^{\\star}\\right)\\|\\phi_{n,i}^{\\star}\\sigma_{n}\\|_{\\infty}\\right)+4B\\ell+A\\ell_{i}+3I\\ell_{j}\\right)}\\\\ &{\\displaystyle=\\prod_{n\\in\\mathbb{N}_{D}}\\sum_{i=1}^{n}\\left(\\ell_{n,i}^{\\star}\\prod_{j=1}^{n}\\left(\\phi_{n,j}^{\\star}+I_{2}A\\ell_{j}+3I\\ell_{i}\\sqrt{3A\\ell_{j}}\\right)\\|\\phi_{n,i}^{\\star}\\sigma_{n}\\|_{\\infty}\\right)}\\\\ &{\\displaystyle=H M K k A\\ell_{i}+6I I^{2}M K\\zeta+(c_{2}I I I+3H\\zeta\\zeta\\zeta\\mathbb{M})\\sum_{i=1}^{n}\\sum_{n\\in\\mathbb{N}_{D}}\\sum_{i=1}^{n}\\left|\\phi_{n,n}^{\\star}\\mathbf{\\mu}_{n,n}^{\\star}\\sigma_{n,n}^{\\star}\\right|\\|_{(\\mathbf{a}_{n,i}^{\\star}),\\ldots,n}}\\\\ &{\\displaystyle\\leq B I W K\\ell+6I I^{2}M K\\zeta+(c_{2}I I I+3H\\zeta\\zeta\\mathbb{M})}\\\\ &{\\displaystyle\\qquad\\times\\sum_{i=1}^{n}\\left(\\mathrm{bya}\\left(\\frac{\\mathbf{b}_{n,i}^{\\star}\\mathbf{\\zeta}}{\\mathbf{\\upmu}_{n,j}^{\\star}}\\right)+1\\right)A\\zeta\\zeta^{-1 \n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "The first inequality follows from Lemma I.2, the second inequality holds due to Lemma I.3, the third inequality follows from Lemma D.12, the last inequality holds due to Lemma J.2 and the fact that $\\|\\phi(\\cdot)\\|_{2}\\leq1$ ,and againwechoose $\\varepsilon=d H\\sqrt{d/M{\\cal K}}/\\dot{A_{\\delta^{\\prime}}}=\\widetilde{\\mathcal{O}}(\\sqrt{d/M{\\cal K}})$ ", "page_idx": 54}, {"type": "text", "text": "The probability calculation is same as that in Appendix G.2. By combining Terms (i)(i)(i) together, we get that the final regret bound for CoopTS-PHE in misspecified setting is ", "page_idx": 54}, {"type": "equation", "text": "$$\n\\mathrm{Regret}(K)=\\tilde{\\mathcal{O}}\\Big(d^{\\frac{3}{2}}H^{2}\\sqrt{M}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)+d H^{2}M\\sqrt{K}\\big(\\sqrt{d M\\gamma}+\\sqrt{K}\\big)\\zeta\\Big),\n$$", "text_format": "latex", "page_idx": 54}, {"type": "text", "text": "with probability at least $1-\\delta$ . Here we finish the proof. ", "page_idx": 54}, {"type": "text", "text": "Auxiliary Lemmas ", "text_level": 1, "page_idx": 55}, {"type": "text", "text": "Lemma J.1. [1, Lemma 11] Let $\\{\\mathbf{X}_{t}\\}_{t=1}^{\\infty}$ be a sequence in $\\mathbb{R}^{d}$ \uff0c $\\mathbf{V}$ .s $d\\times d$ positive definite matrix and define $\\begin{array}{r}{{\\bar{\\mathbf{V}}}_{t}={\\mathbf{V}}+\\sum_{s=1}^{t}{\\mathbf{X}}_{s}{\\mathbf{X}}_{s}^{\\top}}\\end{array}$ . Then, we have that ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\log\\left(\\frac{\\operatorname*{det}(\\bar{\\mathbf{V}}_{n})}{\\operatorname*{det}(\\mathbf{V})}\\right)\\leq\\sum_{t=1}^{n}\\|\\mathbf{X}_{t}\\|_{\\bar{\\mathbf{V}}_{t-1}^{-1}}^{2}.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Further, if $\\|\\mathbf{X}_{t}\\|_{2}\\leq L$ for all $t$ , then ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{t=1}^{n}\\operatorname*{min}\\Big\\{1,\\|\\mathbf{X}_{t}\\|_{\\bar{\\mathbf{V}}_{t-1}^{-1}}^{2}\\Big\\}\\leq2\\big(\\log\\operatorname*{det}(\\bar{\\mathbf{V}}_{n})-\\log\\operatorname*{det}\\mathbf{V}\\big)}&{}\\\\ {\\displaystyle\\leq2\\big(d\\log\\big(\\big(\\mathrm{trace}(\\mathbf{V})+n L^{2}\\big)/d\\big)-\\log\\operatorname*{det}\\mathbf{V}\\big),}&{}\\end{array}\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "and finally, if $\\lambda_{\\operatorname*{min}}(\\mathbf{V})\\geq\\operatorname*{max}\\left(1,L^{2}\\right)$ then ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\sum_{t=1}^{n}\\|\\mathbf{X}_{t}\\|_{\\bar{\\mathbf{V}}_{t-1}^{-1}}^{2}\\leq2\\log\\frac{\\operatorname*{det}(\\bar{\\mathbf{V}}_{n})}{\\operatorname*{det}(\\mathbf{V})}.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma J.2. [1, Lemma 10] Suppose $\\mathbf{X}_{1},\\mathbf{X}_{2},\\ldots,\\mathbf{X}_{t}\\in\\mathbb{R}^{d}$ and for any $1\\leq s\\leq t,\\|\\mathbf{X}_{s}\\|_{2}\\leq L$ Let $\\begin{array}{r}{\\bar{\\mathbf{V}}_{t}=\\lambda\\mathbf{I}+\\sum_{s=1}^{t}\\mathbf{X}_{s}\\mathbf{X}_{s}^{\\top}}\\end{array}$ for some $\\lambda>0$ Then, ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\operatorname*{det}\\left(\\bar{\\mathbf{V}}_{t}\\right)\\leq\\big(\\lambda+t L^{2}/d\\big)^{d}.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma J3. [32, Lemma D.5] Let $\\textbf{A}\\in\\,\\mathbb{R}^{d\\times d}$ be a positive definite matrix where its largest eigenvalue $\\lambda_{\\operatorname*{max}}(\\mathbf{A})\\leq\\lambda$ . Let $\\mathbf{x}_{1},...,\\mathbf{x}_{k}$ be $k$ vectors in $\\bar{\\mathbb{R}}^{d}$ . Then it holds that ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\Big\\|\\mathbf{A}\\sum_{i=1}^{k}\\mathbf{x}_{i}\\Big\\|\\leq\\sqrt{\\lambda k}\\bigg(\\sum_{i=1}^{k}\\|\\mathbf{x}_{i}\\|_{\\mathbf{A}}^{2}\\bigg)^{1/2}.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma J.4. [36, Lemma D.1] Let $\\begin{array}{r}{\\mathbf{A}_{t}=\\lambda\\mathbf{I}+\\sum_{i=1}^{t}\\phi_{i}\\boldsymbol{\\phi}_{i}^{\\top}}\\end{array}$ ,where $\\phi_{i}\\in\\mathbb{R}^{d}$ and $\\lambda>0$ . Then it holds that ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\sum_{i=1}^{t}\\phi_{i}^{\\top}(\\mathbf{A}_{t})^{-1}\\phi_{i}\\leq d.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma J.5. [33, Lemma D.1] Given a multivariate normal distribution $\\mathbf{X}\\sim{\\mathcal{N}}\\left(\\mathbf{0},\\Sigma\\right)$ ,wehave, ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\mathbb{P}\\Bigg(\\lVert\\mathbf{X}\\rVert\\leq\\sqrt{\\frac{1}{\\delta}\\operatorname{tr}(\\Sigma)}\\Bigg)\\geq1-\\delta.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma J.6. [30] If $\\mathbf{A}$ and $\\mathbf{B}$ are positive semi-definite square matrices of the same size, then ", "page_idx": 55}, {"type": "equation", "text": "$$\n0\\leq[\\operatorname{tr}(\\mathbf{A}\\mathbf{B})]^{2}\\leq\\operatorname{tr}\\left(\\mathbf{A}^{2}\\right)\\operatorname{tr}\\left(\\mathbf{B}^{2}\\right)\\leq[\\operatorname{tr}(\\mathbf{A})]^{2}[\\operatorname{tr}(\\mathbf{B})]^{2}.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma J.7. [36, Lemma D.4] Let $\\{s_{i}\\}_{i=1}^{\\infty}$ be a stochastic process on state space $\\boldsymbol{S}$ with corresponding filtration $\\{\\mathcal{F}_{i}\\}_{i=1}^{\\infty}$ . Let $\\{\\phi_{i}\\}_{i=1}^{\\infty}$ be an $\\mathbb{R}^{d}$ -valued stochastic process where $\\phi_{i}\\in\\mathcal{F}_{i-1}$ , and $\\lVert\\phi_{i}\\rVert\\leq1$ Let $\\begin{array}{r}{\\mathbf{\\pmb{\\Lambda}}_{k}=\\lambda\\mathbf{I}+\\sum_{i=1}^{k}\\phi_{i}\\phi_{i}^{\\top}}\\end{array}$ . Then for any $\\delta>0$ , with probability at least $1-\\delta$ , for all $k\\geq0$ , and any $V\\in\\mathcal{V}$ with $\\operatorname{sup}_{s\\in S}|V(s)|\\leq H$ we have ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\Big\\|\\sum_{i=1}^{k}\\phi_{i}\\{V(s_{i})-\\mathbb{E}[V(s_{i})\\mid\\mathcal{F}_{i-1}]\\}\\Big\\|_{\\Lambda_{k}^{-1}}^{2}\\le4H^{2}\\Big[\\frac{d}{2}\\log\\Big(\\frac{k+\\lambda}{\\lambda}\\Big)+\\log\\frac{\\mathcal{N}_{\\varepsilon}}{\\delta}\\Big]+\\frac{8k^{2}\\varepsilon^{2}}{\\lambda},\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Where $\\mathcal{N}_{\\varepsilon}$ is the $\\varepsilon$ coveringnumber of $\\nu$ with respecto thedistance $\\operatorname{dist}(V,V^{\\prime})=\\operatorname{sup}_{s\\in S}|V(s)-$ $V^{\\prime}(s)|$ ", "page_idx": 55}, {"type": "text", "text": "Lemma J.8. [75, Covering number of Euclidean ball] For any $\\varepsilon>0,\\mathcal{N}_{\\varepsilon}$ ,the $\\varepsilon$ -covering number of the Euclidean ball of radius $B>0$ in $\\mathbb{R}^{d}$ satisfies ", "page_idx": 55}, {"type": "equation", "text": "$$\n\\displaystyle N_{\\varepsilon}\\leq\\left(1+\\frac{2B}{\\varepsilon}\\right)^{d}\\leq\\left(\\frac{3B}{\\varepsilon}\\right)^{d}.\n$$", "text_format": "latex", "page_idx": 55}, {"type": "text", "text": "Lemma J.9. Let $\\mathcal{V}$ denote a class of functions mapping from $\\boldsymbol{S}$ to $\\mathbb{R}$ with the following parametric form ", "page_idx": 56}, {"type": "equation", "text": "$$\nV(\\cdot)=\\operatorname*{max}_{a\\in A}\\Big\\{\\operatorname*{min}\\Big\\{\\operatorname*{max}_{n\\in[N]}\\phi(\\cdot,a)^{\\top}\\mathbf{w}^{n},H-h+1\\Big\\}^{+}\\Big\\},\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "where the parameter $\\mathbf{w}^{n}$ satisifies $\\|\\mathbf{w}^{n}\\|\\,\\leq\\,B$ for all $\\boldsymbol n\\,\\in\\,[N]$ and for all $(x,a)\\,\\in\\,S\\,\\times\\,A$ we have $\\|\\phi(x,a)\\|\\,\\leq\\,1$ . Let $N_{\\mathcal{V},\\varepsilon}$ be the $\\varepsilon$ -covering number of $\\mathcal{V}$ with respect to the distance dist $\\left(V,V^{\\prime}\\right)=\\operatorname*{sup}_{s\\in S}\\left|V(s)-V^{\\prime}(s)\\right|$ . Then ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\displaystyle{\\mathcal{N}}_{\\mathcal{V},\\varepsilon}\\leq\\bigg(\\frac{3B}{\\varepsilon}\\bigg)^{d}.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Proof. Consider any two functions $V_{1},V_{2}\\in\\mathcal{V}$ with parameters $\\{\\mathbf{w}_{1}^{n}\\}_{n\\in[N]}$ and $\\{\\mathbf{w}_{2}^{n}\\}_{n\\in[N]}$ respectively. Then we have ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\mathrm{dist}(V_{1},V_{2})\\leq\\underset{s,a}{\\operatorname*{sup}}\\left|\\ \\underset{n\\in[N]}{\\operatorname*{max}}\\phi(s,a)^{\\top}\\mathbf{w}_{1}^{n}-\\underset{n\\in[N]}{\\operatorname*{max}}\\phi(s,a)^{\\top}\\mathbf{w}_{2}^{n}\\right|}\\\\ &{\\leq\\underset{s,a}{\\operatorname*{sup}}\\left|\\ \\underset{n\\in[N]}{\\operatorname*{max}}\\left(\\phi(s,a)^{\\top}\\mathbf{w}_{1}^{n}-\\phi(s,a)^{\\top}\\mathbf{w}_{2}^{n}\\right)\\right|}\\\\ &{\\leq\\underset{\\|\\phi\\|\\leq1}{\\operatorname*{sup}}\\ \\underset{n\\in[N]}{\\operatorname*{max}}\\left|\\phi^{\\top}\\mathbf{w}_{1}^{n}-\\phi^{\\top}\\mathbf{w}_{2}^{n}\\right|}\\\\ &{=\\underset{n\\in[N]}{\\operatorname*{max}}\\ \\underset{\\|\\phi\\|\\leq1}{\\operatorname*{sup}}\\left|\\phi^{\\top}(\\mathbf{w}_{1}^{n}-\\mathbf{w}_{2}^{n})\\right|}\\\\ &{\\leq\\underset{n\\in[N]}{\\operatorname*{max}}\\ \\underset{\\|\\phi\\|\\leq1}{\\operatorname*{sup}}\\,\\|\\phi\\|\\|\\mathbf{w}_{1}^{n}-\\mathbf{w}_{2}^{n}\\|}\\\\ &{\\leq\\underset{n\\in[N]}{\\operatorname*{max}}\\ \\left\\|\\mathbf{w}_{1}^{n}-\\mathbf{w}_{2}^{n}\\right\\|.}\\end{array}\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Let $\\mathcal{N}_{\\mathbf{w},\\varepsilon}$ denote the $\\varepsilon$ -covering number of $\\{\\mathbf{w}\\in\\mathbb{R}^{d}\\mid\\|\\mathbf{w}\\|\\leq B\\}$ . Then, Lemma J.8 implies ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\mathcal{N}_{\\mathbf{w},\\varepsilon}\\leq\\bigg(1+\\frac{2B}{\\varepsilon}\\bigg)^{d}\\leq\\bigg(\\frac{3B}{\\varepsilon}\\bigg)^{d}.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "For any $V_{1}\\in\\mathcal{V}$ , we consider its corresponding parameters $\\{\\mathbf{w}_{1}^{n}\\}_{n\\in[N]}$ . For any $n\\in[N]$ , we can find $\\mathbf{w}_{2}^{n}$ such that $\\left\\|\\mathbf{w}_{1}^{n}-\\mathbf{w}_{2}^{n}\\right\\|\\leq\\varepsilon$ , then we can get $V_{2}\\in\\mathcal{V}$ with parameters $\\{\\mathbf{w}_{2}^{n}\\}_{n\\in[N]}$ . Then we have $\\begin{array}{r}{\\mathrm{dist}(V_{1},V_{2})\\leq\\operatorname*{max}_{n\\in[N]}\\|\\mathbf{w}_{1}^{n}-\\mathbf{w}_{2}^{n}\\|\\leq\\varepsilon}\\end{array}$ Thus, we have, ", "page_idx": 56}, {"type": "equation", "text": "$$\nN_{\\mathcal{V},\\varepsilon}\\leq\\mathcal{N}_{\\mathbf{w},\\varepsilon}\\leq\\left(1+\\frac{2B}{\\varepsilon}\\right)^{d}\\leq\\left(\\frac{3B}{\\varepsilon}\\right)^{d}.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "This completes the proof. ", "page_idx": 56}, {"type": "text", "text": "Lemma J.10. [3] Suppose $Z$ is a Gaussian random variable $Z\\sim{\\mathcal{N}}(\\mu,\\sigma^{2})$ , where $\\sigma\\,>\\,0$ . For $0\\leq z\\leq1$ , we have ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\mathbb{P}(Z>\\mu+z\\sigma)\\geq\\frac{1}{\\sqrt{8\\pi}}e^{\\frac{-z^{2}}{2}},\\quad\\mathbb{P}(Z<\\mu-z\\sigma)\\geq\\frac{1}{\\sqrt{8\\pi}}e^{\\frac{-z^{2}}{2}}.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "And for $z\\geq1$ , we have ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\frac{e^{-z^{2}/2}}{2z\\sqrt{\\pi}}\\leq\\mathbb{P}(|Z-\\mu|>z\\sigma)\\leq\\frac{e^{-z^{2}/2}}{z\\sqrt{\\pi}}.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "Lemma J.11. [32, Lemma D.2] Consider a $d$ -dimensional multivariate normal distribution $\\mathcal{N}\\big(\\mathbf{0},A\\mathbf{A}^{-1}\\big)$ where $A$ is a scalar. Let $\\eta_{1},\\eta_{2},\\dots,\\eta_{N}$ be $N$ independent samples from the distribution. Then for any $\\delta>0$ ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\mathbb{P}\\left(\\operatorname*{max}_{j\\in[M]}\\|\\eta_{j}\\|_{\\Lambda}\\leq c\\sqrt{d A\\log(d/\\delta)}\\right)\\geq1-M\\delta,\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "where $c$ is some absolute constant. ", "page_idx": 56}, {"type": "text", "text": "Lemma J.12. [1, Lemma 12] Let A, $\\mathbf{B}$ and $\\mathbf{C}$ be positive semi-definite matrices such that $\\mathbf{A}=$ $\\mathbf{B}+\\mathbf{C}$ .Then we have that ", "page_idx": 56}, {"type": "equation", "text": "$$\n\\operatorname*{sup}_{\\mathbf{x}\\neq0}\\frac{\\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}}{\\mathbf{x}^{\\top}\\mathbf{B}\\mathbf{x}}\\leq\\frac{\\operatorname*{det}(\\mathbf{A})}{\\operatorname*{det}(\\mathbf{B})}.\n$$", "text_format": "latex", "page_idx": 56}, {"type": "text", "text": "K   Additional Experimental Details ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "We conduct comprehensive experiments investigating the exploration strategies for DQN under a multi-agent setting. For all the $Q$ networks in our experiments, we use ReLU as our activation function. Given that all experiments are conducted under multi-agent settings unless explicitly specified as a single-agent or centralized scenario, we denote our methods: CoopTS-PHE as \"PHE\" and CoopTS-LMC as \"LMC\" in experimental contexts and figures. In addition to our methods, the baselines we selected are either commonly used (DQN [57], DDQN [28]) or with competitive empirical performance (Bootstrapped DQN [62], NoisyNet DQN [26]). Both Bootstrapped DQN and NoisyNet DQN are randomized exploration methods. Bootstrapped DQN uses finite ensembles to generate the randomized value functions and views them as approximate posterior samples of $Q$ -value functions. NoisyNet DQN injects noise into the parameters of neural networks to aid efficient exploration. For those figures which aim to compare among different $m$ agents within a single plot, we use Total Episodes to indicate the total number of training samples for a direct comparison. Note that the shaded areas on all figures represent the standard deviation. ", "page_idx": 57}, {"type": "table", "img_path": "7Tir0u0ukg/tmp/fc7a1fec85983dd56666e0c13a058a7c970a880127cc0f77912148cc5aa6e142.jpg", "table_caption": ["Table 2: The swept hyper-parameters in N-Chain for PHE "], "table_footnote": [], "page_idx": 57}, {"type": "table", "img_path": "7Tir0u0ukg/tmp/36f204e87db40174ae37f1fc949fc0e381b97e2606b92114054240e229423896.jpg", "table_caption": ["Table 3: The swept hyper-parameters in N-Chain for LMC "], "table_footnote": [], "page_idx": 57}, {"type": "text", "text": "K.1 $N$ -chain ", "text_level": 1, "page_idx": 57}, {"type": "text", "text": "We commence by presenting the comprehensive results for $N=25$ in Figure 4, illustrating that our randomized exploration methods exhibit greater suitability in realistic scenarios characterized by an increasing number of agents. This superiority is particularly evident under two potential circumstances: (1) where there are more limitations on computation or data access from each source in the real world, and (2) when parallel learning from multiple sources can significantly enhance runtime eficiency. ", "page_idx": 57}, {"type": "text", "text": "Subsequently, we provide a more comprehensive study to investigate the exploration capabilities facilitated by parallel training. Preliminary experiments are conducted with a reduced state space, specifically considering $N=10$ . The study aims to investigate exploration capabilities across varying agent counts, specifically within the set $\\dot{m}\\in\\{1,2,3,4\\}$ ", "page_idx": 57}, {"type": "text", "text": "We list the details of all swept hyper-parameters in $N$ -chain for PHE and LMC in Table 2 and Table 3 respectively. Specificall, PHE is trained with reward noise k,n = 10-2 and regularizer noise $\\xi_{h}^{k,n}=10^{-3}$ in (3.5) and LMC is trained with $\\beta_{m,k}\\,=\\,10^{2}$ and in (3.7) and optimized by Adam SGLD [33] with $\\alpha_{1}=0.9$ $\\alpha_{2}=0.999$ and bias factor $\\alpha=0.1$ . The final hyper-parameters used in $N$ -chain are presented in Table 4. ", "page_idx": 57}, {"type": "table", "img_path": "", "table_caption": ["Table 4: Hyper-parameters used in the N-chain "], "table_footnote": [], "page_idx": 58}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/2245d8d254acde3a382f191ee115353ef0d8ee1d85c63d7c89278d6480005227.jpg", "img_caption": [], "img_footnote": [], "page_idx": 58}, {"type": "image", "img_path": "", "img_caption": ["Figure 4: Comparison among different exploration strategies in $N$ -chain with $N=25$ .All results are averaged over 10 runs. "], "img_footnote": [], "page_idx": 58}, {"type": "text", "text": "", "page_idx": 58}, {"type": "text", "text": "Performance Consistency with Varying $m$ In the investigation detailed in Figure 5, we explore parallel learning without inter-agent communication. Note that the $x$ -axis implies the total training episodesfrom $m$ agents. Consequently, while multiple agents engage in simultaneous policy learning, each agent independently formulates its policies without the exchange of transition information. The discernible trend in this scenario is that an increase in the number of agents sharing the total episodes results in a slower rate of policy learning. Notably, despite this temporal discrepancy, all learning trajectories eventually approximate convergence towards the optimal dashed line. ", "page_idx": 58}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/671bfa0d6e9ecb88bf48a8d091162d8abdf9829d48bf62fb490cfa3a062f373a.jpg", "img_caption": ["Figure 5: Rewards with averaged over 10 independent runs for different numbers of agents among algorithms without communication. Note that when $m=1$ , one agent indicates a centralized setting. "], "img_footnote": [], "page_idx": 58}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/54745c4dbe6e200aa2f69a97145e8546f4001b957daf6ed86104f262df839fc8.jpg", "img_caption": ["Figure 6: Different number of agents $m$ with different synchronization strategies as well as the single-agent and no communication settings in $N=10$ . Top: PHE, Bottom: LMC "], "img_footnote": [], "page_idx": 59}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/d1e98132866965cca0943e4a8824c608c49a146615e54f59fa45c55b4ffe80fb.jpg", "img_caption": ["Figure 7: Performance with different number of agents $m$ compared with bandit-inspired exploration in $N=10$ "], "img_footnote": [], "page_idx": 59}, {"type": "text", "text": "Different Synchronization Conditions  To further demonstrate the efficiency of parallel learning with communication, we compare different synchronization conditions in Section 3.1. Specifically, we denote synchronization (1) in every constant step as constant, (2) following exponential function as exponential, and (3) based on (3.3) as linear. To have a fair comparison among different synchronization conditions, we firstly record the empirical number of synchronization via linear condition in average, and then we consider constant value for constant condition and select proper base $b$ for exponential condition with a similar number of synchronization. Figure 6 illustrates that any synchronization condition can improve learning efficiency but still with centralized learning as an upper bound. Note that the $x$ -axis implies the total training episodes from $m$ agents. ", "page_idx": 59}, {"type": "text", "text": "Performance Compared with Bandit-inspired Methods _ Since one of our proposed random exploration strategies, PHE is a variant of approximation TS, it is fair for us to investigate the performance of other exploration methods from bandit algorithms with the integration of DQN. We mainly compare both TS and UCB under neural network (i.e., NeuralTS [9O] and NeuralUCB [94]) and linear (i.e., LinTS [5] and LinUCB [49]) settings. We show that a performance gap exists between linear approaches and other neural-based methods even in a small-scale exploration problem with $N=10$ in Figure 7. Note that the $x$ -axis implies the total training episodes from $m$ agents. ", "page_idx": 59}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/65f51b557e025c4b2b46eb2fc60b83cd41a9054a2c526b3c20392a8dad8a74d1.jpg", "img_caption": ["Figure 8: Computation time with different exploration strategies. "], "img_footnote": [], "page_idx": 60}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/61818556eedb86801d078fae0198b5797e049c638bc35af47fb6162ae99609ce.jpg", "img_caption": ["Figure 9: Hyper-parameter tuning of inverse temperature (inv temp) $\\beta_{m,k}$ for LMC with $N=25$ :(a) centralized setting $m=1$ (b) 2 agents without communication $m=2$ "], "img_footnote": [], "page_idx": 60}, {"type": "text", "text": "Computational Time We have demonstrated that both NeuralTS and NeuralUCB exhibit convergence to performance levels comparable to our proposed randomized exploration strategies (i.e., PHE and LMC)whenconsidering thecaseof $N=10$ with $m=4$ under the synchronization condition (linear), as outlined in (3.3). However, we argue that the scalability of both methods is limited due to their associated computational costs. To substantiate this assertion, we conduct experiments across all methods including DQN baselines with $N=10$ and $m=4$ over $10^{4}$ steps with varying neural network sizes, such as [32, 32, 32], which signifies three layers with 32 neurons in each layer. Importantly, the length of the chain $N$ has no bearing on the running time. ", "page_idx": 60}, {"type": "text", "text": "In Figure 8, we show the computational time of all methods under different neural network sizes. The solid lines represent the average computational time over 10 random seeds and the shaded area represents the standard deviation. We observe that NeuralTS and NeuralUCB have heavy running time consistently with varying network sizes. Although the computation time of LMC is still higher than other remaining approaches, we observe that it maintains a similar computation time with different neural network sizes, which can still be scaled up to more complex problems with larger neuralnetworks. ", "page_idx": 60}, {"type": "text", "text": "Hyper-parameter Tuning of Inverse Temperature $\\beta_{m,k}$ Subsequently, we scale the problem to $N=25$ . Given the extended horizon, the demand for exploration intensifies, leading us to conduct hyper-parameter tuning for the inverse temperature parameter $\\beta_{m,k}$ in LMC, as illustrated in Figure 9. It is crucial to note that the efficacy of learning is significantly influenced by the exploration capacity in both centralized learning and parallel learning without communication. Our observations reveal a discernible gap between centralized and parallel learning, a departure from the pattern observed in Figure 5. We posit that the disparity may stem from issues associated with the replay buffer size in off-policy RL algorithms. Specifically, when the replay buffer exhausts its capacity for new transitions, the incoming transition replaces the oldest one. ", "page_idx": 60}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/047acd7ff1cb5c04630b076a1c2b9ea06ba652941d32a2d78a470712f0c7f0d6.jpg", "img_caption": ["Figure 10: Different buffer size with $N=25$ between single agent (centralized) and 2 agents (no communication). Note that the full buffer indicates the size of the total episodes. Each agent in no communication setting only occupies half of the total episodes. Therefore, two curves (full buffer, half buffer) in no communication are consistent. "], "img_footnote": [], "page_idx": 61}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/a7b8729b078594f2579f2915c49c1740f62a530d87accab19c361e98ee47d850.jpg", "img_caption": ["Figure 11: Different synchronization strategies as well as the single-agent and no communication settings in $N=25$ "], "img_footnote": [], "page_idx": 61}, {"type": "text", "text": "", "page_idx": 61}, {"type": "text", "text": "Hyper-parameter Tuning of Buffer Size  Therefore, we present a performance comparison between a solitary agent ( $(m=1)$ ) and a scenario involving two agents $\\ m\\mathrm{~=~}2)$ in Figure 10 with different buffer sizes. Full buffer and half buffer indicate the replay buffer's capacity to store the complete set and half of the transitions during training, respectively. We observe that the learning process is more effcient with less buffer size in a centralized setting because having an excessively large replay buffer may potentially impede the efficiency of the learning process. Furthermore, the gap between centralized setting and paralleling learning still exists among different buffer sizes. Therefore, we focus on the setting of less buffer size with different synchronization conditions in Figure 11. We conclude that linear condition results in competitive performance in both PHE and LMC in the $N$ -chain problem and we report all exploration strategies with linear condition in ", "page_idx": 61}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/dbba8813be73b603fb614a911bd6f24bc0587101a3041797a27da51e667af7b8.jpg", "img_caption": ["Figure 12: Gap reduction improvement with prioritized experience replay for parallel learning without communication. Note that the same settings with standard and prioritized experience replay are in the same-ishcolor. "], "img_footnote": [], "page_idx": 62}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/5a2dcbcf57b8ff0c47ac6794fe85b07fc2155de7853b47917f80135021a3faf8.jpg", "img_caption": ["Figure 13: Ilustrations of 4 different environments in Super Mario Bros task. "], "img_footnote": [], "page_idx": 62}, {"type": "text", "text": "Section 5.1. Note that the $x$ -axis in Figure 10 and Figure 11 represent the total training episodes from $m$ agents. ", "page_idx": 62}, {"type": "text", "text": "Ablation Study of Sampling Mechanism  To reduce the reward gap, we adopt a better sampling mechanism in the replay buffer with prioritized experience replay (PER). In Figure 12, parallel learning without inter-agent communication can increase reward with PER, where the $x$ axisrepresents the total training episodes from $m$ agents. However, centralized learning with PER improves faster convergence with similar performance and the trends for linear condition curves are similar. Therefore, the gap between centralized and parallel learning without communication is reduced with PER. Note that the main experimental results in Figure 1 are based on standard experience replay because standard sampling in linear condition has similar performance against PER with faster training time. ", "page_idx": 62}, {"type": "text", "text": "K.2  Super Mario Bros ", "text_level": 1, "page_idx": 62}, {"type": "text", "text": "While cooperative parallel learning enhances training efficiency through data sharing, challenges emerge when handling data from devices capturing images or audio due to privacy concerns in realworld applications. In response, our approach extends randomized exploration strategies to a federated reinforcement learning framework as shown in Algorithm 4, from Algorithm 1, which incorporates parameter synchronization among $Q$ neural networks rather than relying on the conventional practice of sharing agents\u2019 transitions in Line 14 in Algorithm 4. Note that the synchronization follows the format as in Algorithm 1 to update Q functions with horizon $h\\in H$ . However, in practice, we can directly update the weight of the neural network to reduce the communication cost. ", "page_idx": 62}, {"type": "table", "img_path": "7Tir0u0ukg/tmp/ba3c7261d2d49447857d1fc01c2c7fecedbd0b4a637265c83c9ba160553d3c34.jpg", "table_caption": ["Table 5: Hyper-parameters used in the Super Mario Bros "], "table_footnote": [], "page_idx": 63}, {"type": "text", "text": "The training process unfolds within a federated reinforcement learning framework, wherein local updates and global aggregations are iteratively executed [37]. Specifically, each agent iterates through multiple local updates of its value function, followed by server-mediated averaging of these functions across all agents, constituting a form of parameter sharing. Note that the transitions are not accessible among agents, leading us to directly synchronize all agents with parameter sharing every constant local iteration instead of synchronization condition in (3.3). We use the same architecture for all the experiments in the Super Mario Bros task with the preprocessed images as the input states and 7 discrete actions in action space. ", "page_idx": 63}, {"type": "text", "text": "Particularly, we construct 3 convolutional neural network layers with width [32, 64, 32], followed by 2 fully connected layers with the output of action space in the $Q$ network. The detailed hyper-parameters for Super Mario Bros task are presented in Table 5. ", "page_idx": 63}, {"type": "table", "img_path": "7Tir0u0ukg/tmp/06f38463bf3b9f3124b7365d2ef51357750dfacba1db69156e657bd40c891f81.jpg", "table_caption": [], "table_footnote": [], "page_idx": 63}, {"type": "text", "text": "K.3Thermal Control of Building Energy Systems ", "text_level": 1, "page_idx": 63}, {"type": "text", "text": "BuildingEnv encompasses the regulation of heat flow in a multi-zone building to sustain a desired temperature setpoint. We focus on one pre-defined building called \"office small\" in different cities with varying weather types, i.e., Tampa (Hot Humid), Tucson (Hot Dry), Rochester (Cold Humid), and Great Falls (Cold Dry). Each episode is designed to span a single day, comprising 5-minute time intervals $\\mathrm{H}=288$ $\\tau=5/60$ hours). ", "page_idx": 63}, {"type": "table", "img_path": "7Tir0u0ukg/tmp/85ff523cbbb3fc3d6b2b11d44fad5b9b907250cb829d1b63863a563ccdc88069.jpg", "table_caption": ["Table 6: Hyper-parameters used in the building energy systems "], "table_footnote": [], "page_idx": 64}, {"type": "image", "img_path": "7Tir0u0ukg/tmp/1b88360260da08edcb8cf8ad88245e9418255fabb23a307e19b963fb09ff97db.jpg", "img_caption": ["Figure 14: Evaluation performance at different cities in building energy systems "], "img_footnote": [], "page_idx": 64}, {"type": "text", "text": "Observation Space  The state at time step $t$ , denoted as $s(t)\\in\\mathbb{R}^{M+4}$ , encompasses the temperatures $T_{i}(t)$ of each zone, where $i\\in M$ , along with four additional properties: $Q^{G H I}(t)$ $\\bar{Q}^{p}(t)$ \uff0c $T_{G}(t)$ , and $T_{E}(t)$ . Specifically, $Q^{G H I}(t)$ represents the heat gain from solar irradiance, $\\bar{Q}^{p}(t)$ denotes the heat acquired from occupant activities, while $T_{G}(t)$ and $T_{E}(t)$ signify the ground and outdoor environment temperatures, respectively. ", "page_idx": 64}, {"type": "text", "text": "Action Space The continuous version of the action $a(t)\\in[-1,1]^{M}$ controls the heating of $M$ zones. However, since our randomized exploration strategies use DQN [57] as the backbone, we adopt the multi-discrete action space defined in [85], which is a vector of action spaces. Then we convert the multi-discrete action space to a single discrete action space with action mapping. ", "page_idx": 64}, {"type": "text", "text": "Reward Function  The primary objective is to minimize energy consumption while ensuring the maintenance of temperature within a specified comfort range. Therefore, the reward is penalized with both temperature deviations and HVAC energy consumption as follows: ", "page_idx": 64}, {"type": "equation", "text": "$$\nr(t)=-(1-\\beta)\\|a(t)\\|_{2}-\\beta\\|T^{\\mathrm{target}}(t)-T(t)\\|_{2},\n$$", "text_format": "latex", "page_idx": 64}, {"type": "text", "text": "Where $T^{\\mathrm{target}}(t)\\ =\\ [T_{1}^{\\mathrm{target}}(t),T_{2}^{\\mathrm{target}}(t),...,T_{M}^{\\mathrm{target}}(t)]$ are the trge temperatures and $\\begin{array}{r l}{T^{(}t)}&{{}=}\\end{array}$ $[T_{1}(t),T_{2}(t),...,T_{M}(t)]$ are the actual zonal temperatures. The parameter $\\beta$ is the trade-off between the energy consumption and temperature deviation penalties. ", "page_idx": 64}, {"type": "text", "text": "We execute experiments following the united framework in Algorithm 1, synchronizing every constant number of steps across diverse weather conditions in varying cities. The hyper-parameters we used are in Table 6. Subsequently, we evaluate the performance of all methods in distinct cities respectively, as illustrated in Figure 14. Notably, our proposed random exploration strategies demonstrate a consistently higher mean return across all cities. However, it is worth highlighting that DQN in Figure 14(c) and Noisy-Net in Figure 14(d) exhibit lower returns compared to random actions. This outcome can be attributed to the discrete action space configuration [85]. In addition, we observe that maintaining thermal control of buildings is more challenging in cold weather conditions compared to hot weather conditions. ", "page_idx": 65}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 66}, {"type": "text", "text": "Justification: We propose our algorithm in Section 3 with main theoretical analysis in Section 4. We also support our proposed method with empirical results in Section 5. ", "page_idx": 66}, {"type": "text", "text": "Guidelines: ", "page_idx": 66}, {"type": "text", "text": "\u00b7 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u00b7 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u00b7 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u00b7 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 66}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Justification: We discuss that the limitation of theory is hard to generalize to deep RL setting and the communication cost will also be higher in Section 6. ", "page_idx": 66}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "\u00b7 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u00b7 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u00b7 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u00b7 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u00b7 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u00b7 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u00b7 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u00b7 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 66}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 66}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 66}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 67}, {"type": "text", "text": "Justification: We present theoretical analyses of our algorithms in the linear structure under the assumption of linear function approximation and linear MDP setting in Section 3. We provide comprehensive proof from Appendix B to Appendix J, including the analysis of the communication complexity, proof of the regret bound for two proposed methods, misspecified setting, and all supporting lemmas. ", "page_idx": 67}, {"type": "text", "text": "Guidelines: ", "page_idx": 67}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include theoretical results.   \n\u00b7 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u00b7 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u00b7 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u00b7 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u00b7 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 67}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 67}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 67}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 67}, {"type": "text", "text": "Justification: We describe experiment settings and environments with the main experiment results in Section 5 and mention the hardware we run on. In addition, the used architectures and hyper-parameters are provided in Appendix K. We also release our code in supplementary materials. ", "page_idx": 67}, {"type": "text", "text": "Guidelines: ", "page_idx": 67}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u00b7 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u00b7 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u00b7 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a)  If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. () If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). ", "page_idx": 67}, {"type": "text", "text": "(d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 68}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 68}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Justification: We provide our code in supplementary materials and in the link in Section 5.   \nSpecifically, we provide scripts and access to the datasets/environments we use. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that paper does not include experiments requiring code.   \n\u00b7 Please see the NeurIPS code and data submission guidelines (https: //nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\" is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u00b7 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https : / /nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u00b7 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u00b7 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u00b7 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u00b7 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 68}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 68}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Justification: We present the goals, main settings, and the datasets/environments in Section 5.   \nDue to the space limit, the full training details are provided in Appendix K. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 68}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments. \u00b7 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u00b7 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 68}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 68}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 68}, {"type": "text", "text": "Justification: We present our learning curves in the figures with shaded areas, representing the standard deviation over varying random seeds. In addition, violin plots can display the distribution of the return with probability density. ", "page_idx": 68}, {"type": "text", "text": "Guidelines: ", "page_idx": 69}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u00b7 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u00b7 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u00b7 The assumptions made should be given (e.g., Normally distributed errors).   \n\u00b7 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u00b7 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u00b7 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u00b7 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 69}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 69}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 69}, {"type": "text", "text": "Justification: We indicate the related description in Section 5. ", "page_idx": 69}, {"type": "text", "text": "Guidelines: ", "page_idx": 69}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not include experiments.   \n\u00b7 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u00b7 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u00b7 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). ", "page_idx": 69}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https: //neurips.cc/public/EthicsGuidelines? ", "page_idx": 69}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 69}, {"type": "text", "text": "Justification: We do review and follow the NeurIPS Code of Ethics. ", "page_idx": 69}, {"type": "text", "text": "Guidelines: ", "page_idx": 69}, {"type": "text", "text": "\u00b7 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u00b7 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u00b7 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 69}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 69}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 69}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 69}, {"type": "text", "text": "Justification: This paper presents work whose goal is to advance the field of Reinforcement Learning. This work does not have any potential negative social impacts. ", "page_idx": 70}, {"type": "text", "text": "Guidelines: ", "page_idx": 70}, {"type": "text", "text": "\u00b7 The answer NA means that there is no societal impact of the work performed.   \n\u00b7 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u00b7 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u00b7 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u00b7 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u00b7 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 70}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 70}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 70}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 70}, {"type": "text", "text": "Justification: Our work does not include and release new data, so the paper poses no such risks. ", "page_idx": 70}, {"type": "text", "text": "Guidelines: ", "page_idx": 70}, {"type": "text", "text": "\u00b7 The answer NA means that the paper poses no such risks.   \n\u00b7 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safetyfilters.   \n\u00b7 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u00b7 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 70}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 70}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properlyrespected? ", "page_idx": 70}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 70}, {"type": "text", "text": "Justification: We have cited and the original paper that produced the code package and dataset. In addition, we also provide the URL in the README.md. ", "page_idx": 70}, {"type": "text", "text": "Guidelines: ", "page_idx": 70}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not use existing assets.   \n\u00b7 The authors should cite the original paper that produced the code package or dataset.   \n\u00b7 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u00b7 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u00b7 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u00b7 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode . com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u00b7 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u00b7 If this information is not available online, the authors are encouraged to reach out to the asset's creators. ", "page_idx": 70}, {"type": "text", "text": "", "page_idx": 71}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 71}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 71}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 71}, {"type": "text", "text": "Justification: We do not release new assets. ", "page_idx": 71}, {"type": "text", "text": "Guidelines: ", "page_idx": 71}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not release new assets.   \n\u00b7 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u00b7 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u00b7 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 71}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 71}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 71}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 71}, {"type": "text", "text": "Justification: This paper is mainly for proposing provable and practical algorithms without any human subjects. ", "page_idx": 71}, {"type": "text", "text": "Guidelines: ", "page_idx": 71}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u00b7 According to the NeurIPs Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 71}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "page_idx": 71}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution)wereobtained? ", "page_idx": 71}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 71}, {"type": "text", "text": "Justification: This paper is mainly for proposing provable and practical algorithms without any human subjects. ", "page_idx": 71}, {"type": "text", "text": "Guidelines: ", "page_idx": 72}, {"type": "text", "text": "\u00b7 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u00b7 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u00b7 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPs Code of Ethics and the guidelines for their institution.   \n\u00b7 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 72}]