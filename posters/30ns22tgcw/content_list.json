[{"type": "text", "text": "Optimal Scalarizations for Sublinear Hypervolume Regret ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Qiuyi (Richard) Zhang Google Deepmind qiuyiz@google.com ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Scalarization is a general, parallizable technique that can be deployed in any multiobjective setting to reduce multiple objectives into one, yet some have dismissed this versatile approach because linear scalarizations cannot explore concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that provably explore a diverse set of $k$ objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights achieves an optimal sublinear hypervolume regret bound of $O(\\dot{T}^{-1/k})$ , with matching lower bounds that preclude any algorithm from doing better asymptotically. For the setting of multiobjective stochastic linear bandits, we utilize properties of hypervolume scalarizations to derive a novel non-Euclidean analysis to get regret bounds of $\\widetilde{O}(d T^{-1/2}+T^{-1/k})$ , removing unnecessary poly $(k)$ dependencies. We support our theory with strong empirical performance of using non-linear scalarizations that outperforms both their linear counterparts and other standard multiobjective algorithms in a variety of natural settings. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Optimization objectives in modern AI systems are becoming more complex with many different components that must be combined to perform precise tradeoffs in machine learning models. Starting from standard $\\ell_{p}$ regularization objectives in regression problems [Kutner et al., 2005] to increasingly multi-component losses used in reinforcement learning [Sutton et al., 1998] and deep learning [LeCun et al., 2015], many of these single-objective problems are phrased as a scalarized form of an inherently $k$ -objective problem. ", "page_idx": 0}, {"type": "text", "text": "Scalarization Method. Practitioners often vary the weights of the scalarization method, with the main goal of exploring the entire Pareto frontier, which is the set of optimal objectives that cannot be simultaneously improved. First, one chooses some weights $\\lambda\\in\\mathbb{R}^{\\hat{k}}$ and scalarization functions $s_{\\lambda}(y):\\mathbb{R}^{k}\\to\\mathbb{R}$ that convert $k$ multiple objectives $F(a):=(f_{1}(a),...,f_{k}(a))$ over some parameter space $a\\in\\mathcal{A}\\subseteq\\mathbb{R}^{d}$ into a single-objective scalar. Optimization is then applied to this family of single-objective functions $s_{\\lambda}(\\bar{F}(x))$ for various $\\lambda$ and since we often choose $s_{\\lambda}$ to be monotonically increasing in all coordinates, $\\scriptstyle x_{\\lambda}\\;=\\;\\arg\\operatorname*{max}_{a\\in\\mathcal{A}}\\,s_{\\lambda}(F(a))$ is on the Pareto frontier and the various choices of $\\lambda$ recovers an approximation to the Pareto frontier [Paria et al., 2018]. ", "page_idx": 0}, {"type": "text", "text": "Due to its simplicity of use, many have turned to a heuristic-based scalarization strategy to pick the family of scalarizer and weights, which efficiently splits the multi-objective optimization into numerous single \"scalarized\" optimizations [Roijers et al., 2013]. Linear scalarizations with varying weights are often used in multi-objective optimization problems, such as in multi-objective reinforcement learning to combine task reward with the negative action norm [Abdolmaleki et al., 2021] or in RLHF to align responses with human preferences Ouyang et al. [2022]. However, the appeal of using scalarizations in multiobjective optimization declined as linear scalarizations are shown to be provably incapable of exploring the full Pareto frontier [Boyd and Vandenberghe, 2004]. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Beyond Linear Scalarization. To address this, some works have proposed piecewise linear scalarizations inspired by economics [Busa-Fekete et al., 2017], while for multi-armed bandits, scalarized knowledge gradient methods empirically perform better with non-linear scalarizations [Yahyaa et al., 2014]. The classical Chebyshev scalarization has been shown to be effective in many settings, such as evolutionary strategies Qi et al. [2014], Li et al. [2016], general blackbox optimization [Kasimbeyli et al., 2019] or reinforcement learning Van Moffaert et al. [2013]. Other works have come up with novel scalarizations that perform better empirically in some settings [Aliano Filho et al., 2019, Schmidt et al., 2019]. There also have been specific multi-objective algorithms tailored to specific settings such as ParEgo [Knowles, 2006] and MOEAD [Zhang and Li, 2007] for black-box optimization or multivariate iteration for reinforcement learning [Yang et al., 2019]. Furthermore, many adaptive reweighting strategies have been proposed in order to target or explore the full Pareto frontier, which have connections to gradient-based multi-objective optimization [Lin et al., 2019, Abdolmaleki et al., 2021]. However these adaptive strategies are heuristic-driven and hard to compare, while understanding simple oblivious scalarizations remain very important especially in batched settings where optimizations are done heavily in parallel Gergel and Kozinov [2019]. ", "page_idx": 1}, {"type": "text", "text": "Hypervolume Regret. To determine optimality, a natural and widely used metric to measure progress of an optimizer is the hypervolume indicator, which is the volume of the dominated portion of the Pareto set [Zitzler and Thiele, 1999]. The hypervolume metric has become a gold standard because it has strict Pareto compliance meaning that if set $A$ is a subset of $B$ and $B$ has at least one Pareto point not in $A$ , then the hypervolume of $B$ is greater than that of $A$ . Unsurprisingly, multiobjective optimizers often use hypervolume related metrics for progress tracking or acquisition function, such as the Expected Hypervolume Improvement (EHVI) or its differentiable counterpart [Daulton et al., 2020, Hupkens et al., 2015]. Only recently has some works provide sub-linear hypervolume regret bounds which guarantees convergence to the full Pareto frontier; however, they are exponential in $k$ and its analysis only applies to a specially tailored algorithm that requires an unrealistic classification step [Zuluaga et al., 2013]. We draw inspiration on work by [Golovin and Zhang, 2020] that introduces random hypervolume scalarizations but their work does not consider the finite-sample regime and their regret bounds are in the blackbox setting, where the convergence rate quantifies the statistical convergence of the Pareto frontier estimation. ", "page_idx": 1}, {"type": "text", "text": "1.1 Our Contributions ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "We show, perhaps surprisingly, that a simple ensemble of nonlinear scalarizations, known as Hypervolume scalarizations, are theoretically optimal to minimize hypervolume regret and are empirically competitive for general multiobjective optimization. Intuitively, we quantify how fast scalarizations can approximate the Pareto frontier under finite samples even with perfect knowledge of the Pareto frontier, which is the white-box setting. Specifically, as the hypervolume scalarization has sharp level curves, they naturally allow for the targeting of a specific part of the Pareto frontier, without any assumptions on the Pareto set or the need for adaptively changing weights. Additionally, we can oblivously explore the Pareto frontier by choosing $T$ maximizers of randomly weighted Hypervolume scalarizations and achieve a sublinear hypervolume regret rate of $O(T^{-1/k})$ , where $T$ is the number of points sampled. ", "page_idx": 1}, {"type": "text", "text": "Sublinear Hypervolume Regret. Given any set of objectives $\\mathbf{Y}$ that are explicitly provided, our goal is to choose points on the Pareto frontier in a way to maximize the hypervolume. In this white-box setting, we introduce the notion of the hypervolume regret convergence rate, which is both a function of both the scalarization and the weight distribution, and show that the maxima of Hypervolume scalarization with uniform i.i.d. weights enjoy $O(T^{-1/k})$ hypervolume regret (see Theorem 7). In fact, our derived regret rate of the Hypervolume scalarization holds for all frontiers, regardless of the inherent multiobjective function $F$ or the underlying optimizer. Therefore, we emphasize that analyzing these model-agnostic rates can be a general theoretical tool to compare and analyze the effectiveness of proposed multiobjective algorithms. Although many scalarizers will search the entire Pareto frontier as $T\\to\\infty$ , the rate at which this convergence occurs can differ significantly, implying that this framework paves the road for a theoretical standard by which to judge the effectiveness of advanced strategies, such as adaptively weighted scalarizations. ", "page_idx": 1}, {"type": "text", "text": "Lower bounds. On the other hand, we show surprisingly that no multiobjective algorithm, whether oblivious or adaptive, can beat the optimal hypervolume regret rates of applying single-objective optimization with the hypervolume scalarization. To accomplish this, we prove novel lower bounds showing one cannot hope for a better convergence rate due to the exponential nature of our regret, for any set of $T$ points. Specifically, we show that the hypervolume regret of any algorithm after $T$ actions is at least $\\Omega(T^{-1/k})$ , demonstrating the necessity of the $O(T^{-1/\\bar{k}})$ term up to small constants in the denominator. As a corollary, we leverage the sublinear regret properties of hypervolume scalarization to transfer our lower bounds to the more general setting of scalarized Bayes regret. Together, we demonstrate that for general multiobjective optimzation, finding maximas of the hypervolume scalarizations with a uniform weight distribution optimally finds the Pareto frontier asymptotically. ", "page_idx": 2}, {"type": "text", "text": "Theorem 1 (Informal Restatement of Theorem 7 and Theorem 8). Let $\\mathbf{Y}_{T}=\\{y_{1},...,y_{T}\\}$ be a set of $T$ points in $\\mathbb{R}^{k}$ such that $y_{i}\\in\\arg\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda_{i}}^{\\mathrm{HV}}(y)$ with $\\lambda_{i}\\sim S_{+}$ randomly drawn i.i.d. from an uniform distribution and $s^{\\mathrm{HV}}$ are hypervolume scalarizations. Then, the hypervolume regret satisfies ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{H}\\mathcal{V}(\\mathcal{V}^{\\star})-\\mathcal{H}\\mathcal{V}(\\mathbf{Y}_{T})=O(T^{-\\frac{1}{k}})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "where $y^{\\star}$ is the Pareto frontier and $\\mathcal{H V}$ is the hypervolume function. Furthermore, any algorithm for choosing these $T$ points must suffer hypervolume regret of at least $\\Omega(T^{-{\\frac{1}{k}}})$ . ", "page_idx": 2}, {"type": "text", "text": "Scalarized Algorithm for Linear Bandit. Next, we use a novel non-Euclidean analysis to prove improved hypervolume regret bounds for our theoretical toy model: the classic stochastic linear bandit setting. For any scalarization and weight distribution, we propose a new scalarized algorithm (Algorithm 1) for multiobjective stochastic linear bandit that combines uniform exploration and exploitation via an UCB approach to provably obtain scalarized Bayes regret bounds, which we then combine with the hypervolume scalarization to derive optimal hypervolume regret bounds. Specifically, for any scalarization $s_{\\lambda}$ , we show that our algorithm in the linear bandit setting has a scalarized Bayes regret bound of $\\widetilde{\\cal O}(L_{p}k^{1/p}d T^{-1/2}+T^{-1/k})$ , where $L_{p}$ is the Lipschitz constant of the $s_{\\lambda}(\\cdot)$ in the $\\ell_{p}$ norm. Final ly, by using hypervolume scalarizations and exploiting their $\\ell_{\\infty}$ - smoothness, we completely remove the dependence on the number of objectives, $k$ , which had a polynomial dependence in previous regret bound given by Golovin and Zhang [2020]. ", "page_idx": 2}, {"type": "text", "text": "Theorem 2 (Informal Restatement of Theorem 11). For the multiobjective linear bandit problem, let $\\mathbf{A}_{T}\\subseteq A$ be the actions generated by $T$ rounds of Algorithm $^{\\,l}$ , then our hypervolume regret is bounded by: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\mathcal{H V}_{z}(\\Theta^{\\star}A)-\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathbf{A}_{T})\\leq O(d T^{-\\frac{1}{2}}+T^{-\\frac{1}{k}})\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Experiments. Guided by our theoretical analysis, we empirically evaluate a diverse combination of scalarizations and weight distributions in multiple natural settings. First, we consider a synthetic optimization that is inspired by our theoretical derivation of hypervolume regret when the entire Pareto front is known and analytically given. Thus we can explicitly calculate hypervolume regret as a function of the number of Pareto points chosen and compare the regret convergence rates of multiple scalarizations with the uniform $S_{+}$ distribution with $k=3$ objectives, for easy visualization. This is important since when $k=2$ , we show that the Chebyshev and Hypervolume scalarizations are in fact equivalent. ", "page_idx": 2}, {"type": "text", "text": "In our setup, we consider synthetic combinations of concave, convex, and concave/convex Pareto frontiers in each dimension. As expected, non-linear Hypervolume and Chebyshev scalarizations enjoy fast sublinear convergence, while the performance of the Linear scalarization consistently lacks behind, surprisingly even for convex Pareto frontiers. We observe that generally the Hypervolume scalarization does better on concave Pareto frontiers and on some convex-concave frontiers, while the Chebyshev distribution have faster hypervolume convergence in certain convex regimes. ", "page_idx": 2}, {"type": "text", "text": "For multiobjective linear bandits, our experiments show that for many settings, despite having a convex Pareto frontier, applying linear or Chebyshev scalarizations naively with various weight distributions leads to suboptimal hypervolume progress, especially when the number of objective increase to exceed $k\\geq5$ . This is because the non-uniform curvature of the Pareto frontier, exaggerated by the curse of dimensionality and combined with a stationary weight distribution, hinders uniform progress in exploring the frontier. Although one can possibly adapt the weight distribution to the varying curvature of the Pareto frontier when it is convex, the use of simple non-linear scalarizations allow for fast parallelization and are theoretically sound. ", "page_idx": 2}, {"type": "text", "text": "For general multiobjective optimization, we perform empirical comparisons on BBOB benchmarks for bi-ojective functions in a bayesian optimization setting, using classical Gaussian Process models [Williams and Rasmussen, 2006]. When comparing EHVI with hypervolume scalarization approaches, we find that EHVI tends to limit its hypervolume gain by over-focusing on the central portion of the Pareto frontier, whereas the hypervolume scalarization encourages a diverse exploration of the extreme ends. ", "page_idx": 3}, {"type": "text", "text": "We summarize our contributions as follows: ", "page_idx": 3}, {"type": "text", "text": "\u2022 Show that hypervolume scalarizations optimizes for the full Pareto frontier and enjoys sublinear hypervolume regret bounds of $\\bar{O}(T^{-1/k})$ , a theoretical measure of characterizing scalarization effectiveness in the white-box setting.   \n\u2022 Establish a tight lower bound on the hypervolume regret for any algorithm and Bayes regret of $\\Omega(T^{-1/k})$ by a packing argument on the Pareto set.   \n\u2022 Introduce optimization algorithm for multiobjective linear bandits that achieves improved $\\widetilde{O}(d T^{-1/2}+T^{-1/k})$ hypervolume regret via a novel non-Euclidean regret analysis and metric entropy bounds.   \n\u2022 Empirically justify the adoption of hypervolume scalarizations for finding a diverse Pareto frontier in general multiobjective optimization via synthetic, linear bandit, and blackbox optimization benchmarks. ", "page_idx": 3}, {"type": "text", "text": "2 Problem Setting and Notation ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "For a scalarization function $s_{\\lambda}(x)$ , $s_{\\lambda}$ is $L_{p}$ -Lipschitz with respect to $x$ in the $\\ell_{p}$ norm on $\\mathcal{X}\\subseteq\\mathbb{R}^{d}$ if for $x_{1},x_{2}\\in\\mathcal{X}$ , $|s_{\\lambda}(x_{1})-s_{\\lambda}(x_{2})|\\leq L_{p}\\dot{\\|}x_{1}-x_{2}\\|_{p}$ , and $L_{\\lambda}$ analogously for $\\lambda$ in the Euclidean norm. We let $S_{+}^{k-1}=\\{y\\in\\mathbb{R}^{k}\\,|\\,\\|y\\|=1,y>0\\}$ be the sphere in the positive orthant and by abuse of notation, we also let $y\\sim S_{+}^{k-1}$ denote that $y$ is drawn uniformly on $S_{+}^{k-1}$ . Our usual settings of the weight distribution $\\mathcal{D}=\\mathcal{S}_{+}^{k-1}$ will be uniform, unless otherwise stated. ", "page_idx": 3}, {"type": "text", "text": "For two outputs $y,z\\,\\in\\,\\mathcal{V}\\,\\subseteq\\,\\mathbb{R}^{k}$ , we say that $y$ is Pareto-dominated by $z$ if $y\\ \\leq\\ z$ and there exists $j$ such that $y_{j}\\ <\\ z_{j}$ , where $y\\leq z$ is defined for vectors element-wise. A point is Paretooptimal if no point in the output space $\\boldsymbol{\\wp}$ can dominates it. Let $y^{\\star}$ denote the set of Pareto-optimal points (objectives) in $\\boldsymbol{\\wp}$ , which is also known as the Pareto frontier. Our main progress metrics for multiobjective optimization is given by the standard hypervolume indicator. For $\\dot{S}\\subseteq\\mathbb{R}^{k}$ compact, let $\\mathrm{vol}(S)$ be the regular hypervolume of $S$ with respect to the standard Lebesgue measure. ", "page_idx": 3}, {"type": "text", "text": "Definition 3. For a set $\\boldsymbol{\\wp}$ of points in $\\mathbb{R}^{k}$ , we define the (dominated) hypervolume indicator of $\\boldsymbol{\\wp}$ with respect to reference point $z$ as: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathcal{H V}_{z}(\\mathcal{Y})=\\mathrm{vol}(\\{x\\,|\\,x\\geq z,x\\;i s\\;d o m i n a t e d\\;b y\\;s o m e\\;y\\in\\mathcal{Y}\\})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "We can formally phrase our optimization objective as trying to rapidly minimize the hypervolume (psuedo-)regret. Let $\\boldsymbol{\\mathcal{A}}$ be our action space and for some general multi-objective function $F$ , let $\\boldsymbol{\\wp}$ be the image of $\\boldsymbol{\\mathcal{A}}$ under $F$ . Let $\\mathbf{A}_{T}\\in\\mathbb{R}^{\\dot{T}\\times d}$ be any matrix of $T$ actions and let $\\mathbf{Y}_{T}=F(\\mathbf{A}_{T})\\in\\mathbb{R}^{T\\times k}$ be the $k$ objectives corresponding. Then, the hypervolume regret of actions ${\\bf A}_{T}$ , with respect to the reference point $z$ , is given by: ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\mathrm{Hypervolume-Regret}(\\mathbf A_{T})=\\mathcal H V_{z}(\\mathcal V^{\\star})-\\mathcal H\\mathcal V_{z}(\\mathbf Y_{T})\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "which is 0 for all $z$ if and only if ${\\bf Y}_{T}$ contains all unique points in $y^{\\star}$ . ", "page_idx": 3}, {"type": "text", "text": "For various scalarizations and weight distributions, an related measure of progress that attempts to capture the requirement of diversity in the Pareto front is scalarized Bayes regret for some scalarization function $s_{\\lambda}$ . For some fixed scalarization with weights $\\lambda$ , $s_{\\lambda}:\\mathbb{R}^{k^{\\prime}}\\!\\!\\to\\mathbb{R}$ , we can define the instantaneous scalarized (psuedo-)regret as $\\begin{array}{r}{r(s_{\\lambda},a_{t})\\,=\\,\\operatorname*{max}_{a\\in\\cal A}{s_{\\lambda}(F(a))}\\,-\\,s_{\\lambda}(F(a_{t}))}\\end{array}$ . To capture diversity and progress, we will vary $\\lambda\\sim{\\mathcal{D}}$ according to some distribution of non-negative weight vectors and define regret with respect with respect to all past actions ${\\bf A}_{t}$ . Specifically, we define the (scalarized) Bayes regret with respect to a set of actions ${\\bf A}_{t}$ to be: $B R(s_{\\lambda},\\mathbf{A}_{t})\\stackrel{!}{=}$ $\\mathbf{E}_{\\lambda\\sim\\mathcal{D}}[\\operatorname*{max}_{a\\in A}s_{\\lambda}(F(a))-\\operatorname*{inax}_{a\\in\\mathbf{A}_{t}}s_{\\lambda}(F(a))]=\\mathbf{E}_{\\lambda\\sim\\mathcal{D}}[\\operatorname*{min}_{a\\in\\mathbf{A}_{t}}r(s_{\\lambda},a)]$ ", "page_idx": 3}, {"type": "text", "text": "Unlike previous notions of Bayes regret in literature, we are actually calculating the Bayes regret of a reward function that is maximized with respect to an entire set of actions ${\\bf A}_{t}$ . Specifically, by maximizing over all previous actions, this captures the notion that during multi-objective optimization our Pareto set is always expanding. We will see later that this novel definition is the right one, as it generalizes to the multi-objective setting in the form of hypervolume regret. ", "page_idx": 4}, {"type": "text", "text": "2.1 Scalarizations for Multiobjective Optimization ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "For multiobjective optimization, we generally only consider monotone scalarizers that have the property that if $y>z$ , then $s_{\\lambda}(y)>s_{\\lambda}(z)$ for all $\\lambda$ . Note this guarantees that an optimal solution to the scalarized optimization is on the Pareto frontier. A common scalarization used widely in practice is the linear scalarization: $s_{\\lambda}^{\\mathrm{LIN}}(y)=\\lambda^{\\top}y$ for some chosen positive weights $\\lambda\\in\\mathbb{R}^{k}$ . By Lagrange duality and hyperplane separation of convex sets, one can show that any convex Pareto frontier can be characterized fully by an optimal solution for some weight settings. ", "page_idx": 4}, {"type": "text", "text": "However, linear scalarizations cannot recover the non-convex regions of Pareto fronts since the linear level curves can only be tangent to the Pareto front in the protruding convex regions (see Figure 1). To overcome this drawback, another scalarization that is proposed is the Chebyshev scalarization: $s_{\\lambda}^{\\mathrm{CS}}(y)=\\operatorname*{min}_{i}\\lambda_{i}y_{i}$ . Indeed, one can show that the sharpness of the scalarization, due to its minimum operator, can discover non-convex Pareto frontiers. ", "page_idx": 4}, {"type": "text", "text": "Proposition 4 (Emmerich and Deutz [2018]). For a point $y^{\\star}\\in\\mathcal{V}^{\\star}$ for convex $\\boldsymbol{\\wp}$ , there exists $\\lambda>0$ such that $y^{\\star}=\\arg\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda}^{\\mathrm{LIN}}(y)$ . For a point $y^{\\star}\\in\\mathcal{V}^{\\star}$ for any possibly non-convex set $\\boldsymbol{\\wp}$ that lies in the positive orthant, there exists $\\lambda>0$ such that $y^{\\star}=\\arg\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda}^{\\mathrm{CS}}(y).$ . ", "page_idx": 4}, {"type": "image", "img_path": "30NS22tgCW/tmp/69dcb75515eda8a1536f034798a87f0b4aee46a6eb8f0c717c5cdc7f36520c4e.jpg", "img_caption": [], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "Figure 1: Left: Comparisons of the scalarized minimization solutions with various weights with convex and non-convex Pareto fronts. The colors represent different weights; the dots are scalarized optima and the dotted lines represent level curves. Linear scalarization does not have an optima in the concave region of the Pareto front for any set of weights, but the non-linear scalarization, with its sharper level curves, can discover the whole Pareto front (Figure from [Emmerich and Deutz, 2018]). Right: The dotted red lines represent the level curves of the hypervolume scalarization with $\\lambda=v$ , discovering $b$ , whereas the linear scalarization would prefer $a$ or $c$ . Furthermore, the optima is exactly the Pareto point that is in the direction of $v$ . ", "page_idx": 4}, {"type": "text", "text": "3 Hypervolume Scalarizations ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "In this section, we show the utility and optimality of a related scalarization known as the Hypervolume scalarization, $s_{\\lambda}^{\\mathrm{HV}}(y)\\,=\\,\\dot{\\mathrm{min}}(y_{i}/\\dot{\\lambda}_{i})^{k}$ that was introduced in Golovin and Zhang [2020]. To gain intuition, we visualize the non-linear level curves of the scalarization, which shows that our scalarization targets the portion of the Pareto frontier in the direction of $\\lambda$ for any $\\lambda>0$ (see Figure 1), since the tangent point of the level curves of the scalarization is always on the vector in the direction of $\\lambda$ . This implies that with an uniform distribution on $\\lambda$ , we are guaranteed to have a uniform spread of Pareto points in terms of its angular direction. ", "page_idx": 4}, {"type": "image", "img_path": "30NS22tgCW/tmp/88703220a45bc633ff64ecafde3a56077993fa651a0e1c7f28cc902a1a5b3d66.jpg", "img_caption": ["Figure 2: The hypervolume scalarization taken with respect to a direction $\\lambda=w$ corresponds to a differential area element within dominated hypervolume and averaging over random directions is analogous to integrating over the dominated hypervolume in polar coordinates. We exploit this fact to show that by choosing the maximizers of $T$ random hypervolume scalarizers, we quickly converge to the hypervolume of the Pareto frontier at an optimal rate of $O(T^{-1/k})$ . Figure from [Song et al., 2024] "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "Lemma 5. For any point $y^{\\star}$ on the Pareto frontier of any set $\\boldsymbol{\\wp}$ that lies in the positive orthant, there exists $\\lambda>0$ such that $y^{\\star}=\\arg\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda}^{\\mathrm{HV}}(y)$ . Furthermore, for any $\\alpha,\\lambda>0$ such that $\\alpha\\lambda$ is on the Pareto frontier, then $\\alpha\\lambda\\in\\arg\\operatorname*{max}_{y\\in\\mathcal{P}}s_{\\lambda}^{\\mathrm{HV}}(y).$ . ", "page_idx": 5}, {"type": "text", "text": "This scalarization additionally has the special property that the expected maximized scalarized value under a uniform weight distribution on $S_{+}^{k-1}$ gives the dominated hypervolume, up to a constant scaling factor. Thus, the optima of the hypervolume scalarization over some static uniform distribution will be provably sufficiently diverse for any Pareto set in expectation. ", "page_idx": 5}, {"type": "text", "text": "Lemma 6 (Hypervolume in Expectation [Golovin and Zhang, 2020]). Let $\\mathbf{Y}_{T}=\\{y_{1},...,y_{T}\\}$ be $a$ set of $T$ points in $\\mathbb{R}^{k}$ . Then, the hypervolume with respect to a reference point $z$ is given by: ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\mathcal{H}\\mathcal{V}_{z}(\\mathbf{Y}_{T})=c_{k}\\underset{\\lambda\\sim\\mathcal{S}_{+}^{k-1}}{\\mathbf{E}}\\left[\\underset{y\\in\\mathbf{Y}_{T}}{\\mathrm{max}}~s_{\\lambda}^{\\mathrm{HV}}(y-z)\\right]\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "where ck =2k \u0393(k/2+1) \u03c0k/2 is a constant depending only on $k$ . ", "page_idx": 5}, {"type": "text", "text": "While this lemma is useful in the infinite limit, we supplement it by showing that finite-sample bounds on the strongly sublinear hypervolume convergence rate. In fact, many scalarizations will eventually explore the whole Pareto frontier in the infinite limit, but the rate at which the exploration improves the hypervolume is not known, and may be exponentially slow. We show that the optimizing hypervolume scalarizations with a uniform weight distribution enjoys sublinear hypervolume regret, specifically $O(T^{-1/k})$ hypervolume regret convergence rates for any Pareto set $\\boldsymbol{\\wp}$ . Note that this rate is agnostic of the underlying optimization algorithm or Pareto set, meaning this is a general property of the scalarization. ", "page_idx": 5}, {"type": "text", "text": "Our novel proof of convergence uses a generalization argument to connect hypervolume-scalarized Bayes regret and its finite sample form, exploiting the Lipschitz properties of $s_{\\lambda}^{\\mathrm{HV}}$ to derive metric entropy bounds. Proving smoothness properties of our hypervolume scalarizations for any $\\lambda>0$ with $\\lambda$ normalized on the unit sphere is non-obvious as $s_{\\lambda}^{\\mathrm{HV}}(\\bar{y})$ depends inversely on $\\lambda_{i}$ so when $\\lambda_{i}$ is small, $s_{\\lambda}^{\\mathrm{HV}}$ might change wildly. ", "page_idx": 5}, {"type": "text", "text": "Theorem 7 (Sublinear Hypervolume Regret). Let $\\mathbf{Y}_{T}=\\{y_{1},...,y_{T}\\}$ be a set of $T$ points in $\\mathbb{R}^{k}$ such that $y_{i}\\,\\in\\,\\arg\\operatorname*{max}_{y\\in\\mathcal{P}}{s_{\\lambda_{i}}^{\\mathrm{HV}}(\\bar{y}-z)}$ with respect to a reference point $z$ and $B_{l}\\,\\leq\\,y_{i}\\,-\\,z\\,\\leq\\,B_{u}$ . Then, with probability at least $1-\\delta$ over $\\lambda_{i}\\sim S_{+}$ i.i.d., the hypervolume of ${\\bf Y}_{T}$ with respect to $z$ satisfies ", "page_idx": 5}, {"type": "text", "text": "sublinear hypervolume regret in $T$ : ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\begin{array}{r}{\\mathcal{H}\\mathcal{V}_{z}(\\mathcal{V}^{\\star})-\\mathcal{H}\\mathcal{V}_{z}(\\mathbf{Y}_{T})=O(T^{-\\frac{1}{k+1}}+\\sqrt{\\ln(1/\\delta)}T^{-\\frac{1}{2}})}\\end{array}\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "where $O$ hides constant factors in $k,B_{u},B_{l}$ . ", "page_idx": 6}, {"type": "text", "text": "For $k=2$ , this also holds when Chebyshev scalarization is used: $y_{i}\\in\\arg\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda_{i}}^{\\mathrm{CS}}(y-z)$ . ", "page_idx": 6}, {"type": "text", "text": "We note that the distribution of Pareto points selected by the Chebyshev scalarizer is quite similar to the Hypervolume scalarizer as the formulas are almost identical, except for the inverse weights of the latter. In fact, we show that when $k=2$ , both scalarizers behave the same and enjoy strong convergence rates; however for $k>2$ , the Pareto distributions are in fact different under $\\lambda\\sim S_{+}$ and we can empirically observe the suboptimality of the Chebyshev scalarizer. By definition, using the inverse weight distribution with the Chebyshev scalarizer will be equivalent to applying the Hypervolume scalarizer. ", "page_idx": 6}, {"type": "text", "text": "3.1 Lower Bounds and Optimality ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "The dominating factor in our derived convergence rate is the $O(T^{-1/(k+1)})$ term and we show that this cannot be improved. Over all subsets ${\\bf Y}_{T}\\subseteq\\mathcal{Y}$ of size $T$ , note that our optimal convergence rate is given by the the subset that maximizes the dominated hypervolume of ${\\bf Y}_{T}$ , although finding this is in fact a NP-hard problem due to reduction to set cover. By constructing a lower bound via a novel packing argument, we show that even this optimal set would incur at least $\\Omega(T^{-1/k})$ regret, implying that our convergence rates, derived from generalization rates when empirically approximating the hypervolume, are optimal. ", "page_idx": 6}, {"type": "text", "text": "Specifically, we show that for hypervolume regret, any algorithm cannot achieve better than $\\bar{O}(T^{-1/(k-1)})$ regret even when using linear objectives, and this matches the dominating factor in our algorithm up to a small constant in the denominator. By using hypervolume scalarizations and its connection to hypervolume regret, we conclude that this also implies a $\\Omega(T^{-1/(k-1)})$ lower bound on the scalarized Bayes regret. ", "page_idx": 6}, {"type": "text", "text": "Theorem 8 (Hypervolume Regret Lower Bound). There exists a setting of linear objective parameters $\\Theta^{\\star}$ and $\\mathcal{A}=\\{\\bar{a}:\\|a\\|=1\\}$ such that for any actions ${\\bf A}_{T}$ , the hypervolume regret at $z=0$ after $T$ rounds is ", "page_idx": 6}, {"type": "equation", "text": "$$\n\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathcal{A})-\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathbf{A}_{T})=\\Omega(T^{-\\frac{1}{k-1}})\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "Corollary 9. There is a setting of objectives $\\Theta^{\\star}$ and ${\\mathcal{A}}=\\{a:\\|a\\|=1\\}$ such that for any actions ${\\bf A}_{T}$ , the scalarized Bayes regret after $T$ rounds is ", "page_idx": 6}, {"type": "equation", "text": "$$\nB R(s_{\\lambda}^{\\mathrm{HV}},{\\bf A}_{T})=\\Omega(T^{-\\frac{1}{k-1}})\n$$", "text_format": "latex", "page_idx": 6}, {"type": "text", "text": "4 Multiobjective Stochastic Linear Bandits ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "We propose a simple scalarized algorithm for linear bandits and provide a novel $\\ell_{p}$ analysis of the hypervolume regret that removes the polynomial dependence on $k$ in the scalarized regret bounds. When combin\u221aed with the $\\ell_{\\infty}$ sharpness of the hypervolume scalarization, this analysis gives an optimal $O(d/\\sqrt{T})$ bound on the scalarized regret, up to $\\log(k)$ factors. This log dependence on $k$ is perhaps surprising but is justified information theoretically since each objective is observed separately. Note that our scalarized algorithm works despite of noise in the observations, which makes it difficult to even statistically infer measures of hypervolume progress. Our setup and algorithm is given in the Appendix (see Section A). ", "page_idx": 6}, {"type": "text", "text": "By using the confidence ellipsoids given by the UCB algorithm, we can determine each objective parameter $\\Theta_{i}^{\\star}$ , up to a small error. To bound the scalarized regret, we utilize the $\\ell_{p}$ smoothness of $s_{\\lambda}$ , $L_{p}$ , to reduce the dependence on $k$ to be $O(k^{1/p})$ , which effectively removes the polynomial dependence on $k$ when $p\\rightarrow\\infty$ . This is perhaps not surprising, since each objective is observed independently and fully, so the information gain scales with the number of objectives. ", "page_idx": 6}, {"type": "text", "text": "Lemma 10. Consider running EXPLOREUCB (Algorithm 1) for $T>\\operatorname*{max}(k,d)$ iterations and for $T$ even, let $a_{T}$ be the action that maximizes the scalarized UCB in iteration $T/2$ . Then, with probability at least $1-\\delta$ , the instantaneous scalarized regret can be bounded by ", "page_idx": 7}, {"type": "equation", "text": "$$\nr(s_{\\lambda},a_{T})\\leq10k^{\\frac{1}{p}}L_{p}d\\sqrt{\\frac{\\log(k/\\delta)+\\log(T)}{T}}\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "where $L_{p}$ is the $\\ell_{p}$ -Lipschitz constant for $s_{\\lambda}(\\cdot)$ . ", "page_idx": 7}, {"type": "text", "text": "uFinnifaolrlym,  cwoen vceorngneenccte  tphreo epxerptieecst eodf  aBlla yfuens crteiogrnes t ofw itthhe  tfhoer me $\\bar{f}(\\lambda)=\\operatorname*{max}_{a\\in\\mathbf{A}}\\bar{s_{\\lambda}}(\\Theta^{\\star}a)$ .a lBayr iuzseidn gr $\\bar{s}_{\\lambda}^{\\mathrm{HV}}$ avnida setting $p=\\infty$ , we derive our final fast hypervolume regret rates for stochastic linear bandits, which is the combination of the scalarized regret rates and the hypervolume regret rates. ", "page_idx": 7}, {"type": "text", "text": "Theorem 11 (HyperVolume Regret of EXPLOREUCB). Let $z\\in\\mathbb{R}^{k}$ be a reference point such that over all $a\\in A$ , $B_{l}\\leq\\Theta^{\\star}a-z\\leq B_{u}$ . Then, with constant probability, running Algorithm $^{\\,l}$ with $s_{\\lambda}^{\\mathrm{HV}}(y)$ and $\\mathcal{D}=\\mathcal{S}_{+}$ gives hypervolume regret bound, for $k$ constant, ", "page_idx": 7}, {"type": "equation", "text": "$$\n\\mathcal{H}\\mathcal{V}_{z}(\\Theta^{\\star}A)-\\mathcal{H}\\mathcal{V}_{z}(\\Theta^{\\star}\\mathbf{A}_{T})\\leq O\\left(d\\sqrt{\\frac{\\log(T)}{T}}+\\frac{1}{T^{\\frac{1}{k+1}}}\\right)\n$$", "text_format": "latex", "page_idx": 7}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "In this section, we empirically justify our theoretical results by comparing hypervolume convergence curves for multiobjective optimization in synthetic, linear bandit and blackbox optimization environments with multiple scalarizations and weight distributions. Our empirical results highlight the advantage of the hypervolume scalarization with uniform weights in maximizing the diversity and hypervolume of the resulting Pareto front when compared with other scalarizations and weight distributions, especially when there are a mild number of output objectives $k$ . Our experiments are not meant to show that scalarizations is the best way to solve multiobjective optimization; rather, it is a simple yet competitive baseline that is easily parallelized in a variety of settings. Also, we use slightly altered form of our hypervolume scalarization as $s_{\\lambda}(y)=\\operatorname*{min}_{i}\\dot{y}_{i}/\\lambda_{i}$ , which is a simply a monotone transform and does not inherently affect the optimization. All error bars are given between the 30 to 70 percentile over independent repeats. ", "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5.1 Synthetic Optimization ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "Our synthetic optimization benchmarks assume the knowledge of $\\boldsymbol{\\wp}$ and the Pareto frontier and thus we can compute the total hypervolume and compare the hypervolume regret of multiple scalarizations with the uniform $S_{+}$ distribution. For our experiments, we fix our weight distribution and compare the three widely types of scalarizations that were previously mentioned: the Linear, Chebyshev, and the Hypervolume scalarization. We focus on the $k=3$ setting and apply optimization for a diverse set of Pareto frontiers in the region $x,y\\in[0,1],z>0$ . We discretize our region into 30 points per dimension to form a discrete Pareto frontier and set our reference point to be at $z=[-\\epsilon,-\\epsilon,-\\epsilon]$ for $\\epsilon=1\\mathrm{e}{-4}$ and run for 10 repeats. ", "page_idx": 7}, {"type": "text", "text": "The synthetic Pareto frontiers that we are consider are a product of 1-dimensional frontiers and specifically, $z\\,=\\,g(x)\\cdot g(y)$ , where $g(x)\\,=\\,\\exp(-x),3^{'}-\\,\\exp(x),\\cos(\\pi x)+1$ , which form a concave, convex, and concave/convex Pareto frontiers respectively. Now that since the derivatives of these functions are all negative in our feasible region, $z$ is a valid Pareto front. From our combination of functions, we observe that both Hypervolume and Chebyshev scalarizations enjoy fast convergence, while the performance of the Linear scalarization consistently lacks behind, surprisingly even for convex Pareto frontiers (see full plots in C.1). Interestingly, we observe that generally the Hypervolume scalarization does better on concave Pareto frontiers and on some convex-concave frontiers; however since these are static algorithms, it is not surprising that the Chebyshev distribution can perform better in certain convex regimes. However, we still advocate the usage of the hypervolume indicator as it is guaranteed to have a uniform spread especially when the number of objectives is increased, as shown by our later experiments. ", "page_idx": 7}, {"type": "image", "img_path": "30NS22tgCW/tmp/ba851f71641e1a337a0a5afd2c5d4c6f60556443675d7f5540289639ef9cfe39.jpg", "img_caption": ["Figure 3: Comparisons of multiple scalarizations for the synthetic concave Pareto frontier given by $z=\\exp(-x-y)$ . The hypervolume regret for Linear is constant, and the Hypervolume enjoys a faster regret convergence rate than the Chebyshev. "], "img_footnote": [], "page_idx": 8}, {"type": "text", "text": "5.2 Stochastic Linear Bandits ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We run Algorithm 1 and compare scalarization effects for the multiobjective linear bandit setting. We set our reference point to be $\\mathbf{z}=-2$ in $k$ dimension space, since our action set of ${\\mathcal{A}}=\\{a:\\|a\\|{\\overset{\\cdot}{=}}1\\}$ and our norm bound on $\\Theta^{\\star}$ ensures that our rewards are in $[-1,1]$ . ", "page_idx": 8}, {"type": "text", "text": "In conjunction with the scalarizer, we use our weight distribution $\\mathcal{D}=\\mathcal{S}_{+}$ , which samples vectors uniformly across the unit sphere. In addition, we also compare this with the bounding box distribution methods that were suggested by [Paria et al., 2018], which samples from the uniform distribution from the min to the max each objective and requires some prior knowledge of the range of each objective [Hakanen and Knowles, 2017]. Given our reward bounds, we use the bounding box of $[-1,1]$ for each of the $k$ objectives. Following their prescription for weight sampling, we draw our weights for the linear and hypervolume scalarization uniformly in [1, 3] and take an inverse for the Chebyshev scalarization. We name this the boxed distribution for each scalarization, respectively. ", "page_idx": 8}, {"type": "text", "text": "To highlight the differences between the multiple scalarizations, we configure our linear bandits parameters to be anti-correlated, which creates a convex Pareto front with non-uniform curvature. Note that a perfect anti-correlated Pareto front would be linear, which would cause linear scalarizations to always optimize at the end points. We start with simple $k=2$ case and let $\\theta_{0}$ be random and $\\theta_{1}=-\\theta_{0}+\\eta$ , where $\\eta$ is some small random Gaussian perturbation (we set the standard deviation to be about 0.1 times the norm of $\\theta_{i}$ ). We renormalize after the anti-correlation to ensure $\\|\\Theta^{\\star}\\|=1$ . We run our algorithm with inherent dimension $d=4$ for $T=100$ , 200 rounds with $k=2,6,10$ . ", "page_idx": 8}, {"type": "text", "text": "As expected, we find the hypervolume scalarization consistently outperforms the Chebyshev and linear scalarizations, with linear scalarization as the worst performing (see Figure 4). Note that when we increase the output dimension of the problem by setting $k=10$ , the hypervolume scalarization shows a more distinct advantage. The boxed distribution approach of [Paria et al., 2018] does not seem to fare well and consistently performs worse than its uniform counterpart. While linear scalarization provides relatively good performance when the number of objective $k\\leq5$ , it appears that as the number of objectives increase in multi-objective optimization, more care needs to be put into the design of scalarization and their weights due to the curse of dimensionality, since the regions of non-uniformity will exponentially increase. We suggest that as more and more objectives are being added to modern machine learning systems, using smart scalarizations is critical to an uniform exploration of the Pareto frontier. ", "page_idx": 8}, {"type": "text", "text": "5.3 BBOB Functions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "We empirically demonstrate the competitiveness of hypervolume scalarizations for Bayesian Optimization by comparing them to the popular BO method of EHVI [Hupkens et al., 2015]. Running our proposed multiobjective algorithms on the Black-Box Optimization Benchmark (BBOB) functions, which can be paired up into multiple bi-objective optimization problems [Tu\u0161ar et al., 2016]. Our goal is to use a wide set of non-convex benchmarks to supplement our experiments on our simple toy example of linear bandits. For scalarized approaches, we use hypervolume scalarizations with the scalarized UCB algorithm with a constant standard deviation multiplier of 1.8 and all algorithms with use a Gaussian Process as the underlying model with a standard Mat\u00e9rn kernel that is tuned via ARD Williams and Rasmussen [2006]. ", "page_idx": 8}, {"type": "image", "img_path": "30NS22tgCW/tmp/747a688dd8437e32c710e5808a088a3332fa2cb33ee679737b0988239413aa53.jpg", "img_caption": ["Figure 4: Comparisons of the cumulative hypervolume plots with some anti-correlated $\\theta$ . When the output dimension increase, there is a clearer advantage to using the hypervolume scalarization over the linear and Chebyshev scalarization. We find that the boxed weight distribution does consistently worse than the uniform distribution. "], "img_footnote": [], "page_idx": 9}, {"type": "text", "text": "", "page_idx": 9}, {"type": "text", "text": "Our objectives are given by BBOB functions, which are usually non-negative and are minimized. The input space is always a compact hypercube $[-5,5]^{n}$ and the global minima is often at the origin. For bi-objective optimization, given two different BBOB functions $f_{1},f_{2}$ , we attempt to maximize the hypervolume spanned by $({\\bar{-}}f_{1}(x_{i}),-f_{2}(x_{i}))$ over choices of inputs $x_{i}$ with respect to the reference point $(-5,-5)$ . We normalize each function due to the drastically different ranges and add random observation noise. We also apply vectorized shifts of the input space of 2, \u22122 on the two functions respectively, so that the optima of each function do not co-locate at the origin. ", "page_idx": 9}, {"type": "text", "text": "We run each of our algorithms in dimensions $d=8,16,24$ and optimize for 160 iterations with 5 repeats. From our results, we see that both EHVI and UCB with hypervolume scalarizations are competitive on the BBOB problems but the scalarized UCB algorithm seems to be able to explore the extreme ends of the Pareto frontier, whereas EHVI tends to favor points in the middle (see Appendix and Figure 5). From our experiments, this trend appears to be consistent across different functions and is more prominent as the input dimensions $d$ increase. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 10}, {"type": "text", "text": "Michael H Kutner, Christopher J Nachtsheim, John Neter, William Li, et al. Applied linear statistical models, volume 5. McGraw-Hill Irwin Boston, 2005. ", "page_idx": 10}, {"type": "text", "text": "Richard S Sutton, Andrew G Barto, et al. Introduction to reinforcement learning, volume 2. MIT press Cambridge, 1998.   \nYann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436\u2013444, 2015.   \nBiswajit Paria, Kirthevasan Kandasamy, and Barnab\u00e1s P\u00f3czos. A flexible framework for multiobjective bayesian optimization using random scalarizations. arXiv preprint arXiv:1805.12168, 2018.   \nDiederik M Roijers, Peter Vamplew, Shimon Whiteson, and Richard Dazeley. A survey of multiobjective sequential decision-making. Journal of Artificial Intelligence Research, 48:67\u2013113, 2013.   \nAbbas Abdolmaleki, Sandy H Huang, Giulia Vezzani, Bobak Shahriari, Jost Tobias Springenberg, Shruti Mishra, Dhruva TB, Arunkumar Byravan, Konstantinos Bousmalis, Andras Gyorgy, et al. On multi-objective policy optimization as a tool for reinforcement learning. arXiv preprint arXiv:2106.08199, 2021.   \nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35: 27730\u201327744, 2022.   \nStephen Poythress Boyd and Lieven Vandenberghe. Convex optimization. Cambridge University Press, Cambridge, 2004. ISBN 0-521-83378-7.   \nR\u00f3bert Busa-Fekete, Bal\u00e1zs Sz\u00f6r\u00e9nyi, Paul Weng, and Shie Mannor. Multi-objective bandits: Optimizing the generalized gini index. In International Conference on Machine Learning, pages 625\u2013634. PMLR, 2017.   \nSaba Q Yahyaa, Madalina M Drugan, and Bernard Manderick. The scalarized multi-objective multiarmed bandit problem: An empirical study of its exploration vs. exploitation tradeoff. In 2014 International Joint Conference on Neural Networks (IJCNN), pages 2290\u20132297. IEEE, 2014.   \nYutao Qi, Xiaoliang Ma, Fang Liu, Licheng Jiao, Jianyong Sun, and Jianshe Wu. Moea/d with adaptive weight adjustment. Evolutionary computation, 22(2):231\u2013264, 2014.   \nHui Li, Qingfu Zhang, and Jingda Deng. Biased multiobjective optimization and decomposition algorithm. IEEE transactions on cybernetics, 47(1):52\u201366, 2016.   \nRefail Kasimbeyli, Zehra Kamisli Ozturk, Nergiz Kasimbeyli, Gulcin Dinc Yalcin, and Banu Icmen Erdem. Comparison of some scalarization methods in multiobjective optimization. Bulletin of the Malaysian Mathematical Sciences Society, 42(5):1875\u20131905, 2019.   \nKristof Van Moffaert, Madalina M Drugan, and Ann Now\u00e9. Scalarized multi-objective reinforcement learning: Novel design techniques. In 2013 IEEE symposium on adaptive dynamic programming and reinforcement learning (ADPRL), pages 191\u2013199. IEEE, 2013.   \nAngelo Aliano Filho, Antonio Carlos Moretti, Margarida Vaz Pato, and Washington Alves de Oliveira. An exact scalarization method with multiple reference points for bi-objective integer linear optimization problems. Annals of Operations Research, pages 1\u201335, 2019.   \nMarie Schmidt, Anita Sch\u00f6bel, and Lisa Thom. Min-ordering and max-ordering scalarization methods for multi-objective robust optimization. European Journal of Operational Research, 275 (2):446\u2013459, 2019.   \nJoshua Knowles. Parego: a hybrid algorithm with on-line landscape approximation for expensive multiobjective optimization problems. IEEE Transactions on Evolutionary Computation, 10(1): 50\u201366, 2006.   \nQingfu Zhang and Hui Li. Moea/d: A multiobjective evolutionary algorithm based on decomposition. IEEE Transactions on evolutionary computation, 11(6):712\u2013731, 2007.   \nRunzhe Yang, Xingyuan Sun, and Karthik Narasimhan. A generalized algorithm for multi-objective reinforcement learning and policy adaptation. Advances in Neural Information Processing Systems, 32, 2019.   \nXi Lin, Hui-Ling Zhen, Zhenhua Li, Qing-Fu Zhang, and Sam Kwong. Pareto multitask learning. In Advances in Neural Information Processing Systems 32, pages 12037\u2013 12047. Curran Associates, Inc., 2019. URL http://papers.nips.cc/paper/ 9374-pareto-multi-task-learning.pdf.   \nVictor Gergel and Evgeny Kozinov. Parallel computations for various scalarization schemes in multicriteria optimization problems. In International Conference on Parallel Processing and Applied Mathematics, pages 174\u2013184. Springer, 2019.   \nEckart Zitzler and Lothar Thiele. Multiobjective evolutionary algorithms: a comparative case study and the strength pareto approach. IEEE transactions on Evolutionary Computation, 3(4):257\u2013271, 1999.   \nSamuel Daulton, Maximilian Balandat, and Eytan Bakshy. Differentiable expected hypervolume improvement for parallel multi-objective bayesian optimization. Advances in Neural Information Processing Systems, 33:9851\u20139864, 2020.   \nIris Hupkens, Andr\u00e9 Deutz, Kaifeng Yang, and Michael Emmerich. Faster exact algorithms for computing expected hypervolume improvement. In international conference on evolutionary multi-criterion optimization, pages 65\u201379. Springer, 2015.   \nMarcela Zuluaga, Guillaume Sergent, Andreas Krause, and Markus P\u00fcschel. Active learning for multi-objective optimization. In International Conference on Machine Learning, pages 462\u2013470, 2013.   \nDaniel Golovin and Qiuyi Zhang. Random hypervolume scalarizations for provable multi-objective black box optimization. arXiv preprint arXiv:2006.04655, 2020.   \nChristopher KI Williams and Carl Edward Rasmussen. Gaussian processes for machine learning, volume 2. MIT press Cambridge, MA, 2006.   \nMichael TM Emmerich and Andr\u00e9 H Deutz. A tutorial on multiobjective optimization: fundamentals and evolutionary methods. Natural computing, 17(3):585\u2013609, 2018.   \nXingyou Song, Qiuyi Zhang, Chansoo Lee, Emily Fertig, Tzu-Kuo Huang, Lior Belenki, Greg Kochanski, Setareh Ariafar, Srinivas Vasudevan, Sagi Perel, et al. The vizier gaussian process bandit algorithm. arXiv preprint arXiv:2408.11527, 2024.   \nJussi Hakanen and Joshua D Knowles. On using decision maker preferences with parego. In International Conference on Evolutionary Multi-Criterion Optimization, pages 282\u2013297. Springer, 2017.   \nTea Tu\u0161ar, Dimo Brockhoff, Nikolaus Hansen, and Anne Auger. Coco: the bi-objective black box optimization benchmarking (bbob-biobj) test suite. ArXiv e-prints, 2016.   \nTor Lattimore and Csaba Szepesv\u00e1ri. Bandit algorithms. Cambridge University Press, 2020.   \nJack Kiefer and Jacob Wolfowitz. The equivalence of two extremum problems. Canadian Journal of Mathematics, 12:363\u2013366, 1960.   \nPeter L Bartlett and Shahar Mendelson. Rademacher and gaussian complexities: Risk bounds and structural results. Journal of Machine Learning Research, 3(Nov):463\u2013482, 2002.   \nLee-Ad Gottlieb, Aryeh Kontorovich, and Robert Krauthgamer. Adaptive metric dimensionality reduction. Theoretical Computer Science, 620:105\u2013118, 2016.   \nYasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, and Csaba Szepesv\u00e1ri. Improved algorithms for linear stochastic bandits. Advances in neural information processing systems, 24:2312\u20132320, 2011. ", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "A Linear Bandit Setup and Algorithm ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "For theory, we use the classic stochastic linear bandit setting. For the single-objective setting, in round $t=1,2,...,T$ , the and receives a reward $y_{t}=\\langle\\theta^{\\star},a_{t}\\rangle+\\xi_{t}$ where $\\xi_{t}$ is i.i.d. 1-sub-Gaussian noise and $\\theta^{\\star}\\in\\mathbb{R}^{d}$ is the unknown true parameter vector. In the multi-objective stochastic linear bandit setting, the learner chooses an action $a_{t}\\in\\mathbb{R}^{d}$ from the action set $\\boldsymbol{\\mathcal{A}}$ and receives a vectorized reward $y_{t}\\,=\\,\\Theta^{\\star}a_{t}+\\xi_{t}$ , where $\\Theta^{\\star}\\,\\in\\,\\mathbb{R}^{k\\times d}$ is now a matrix of $k$ unknown true parameters and $\\xi_{t}\\in\\mathbb{R}^{k}$ is a vector of independent 1-sub-Gaussian noise. We assume, for sake of normalization, that $\\|\\Theta_{i}^{\\star}\\|\\leq1$ and that $\\|a_{t}\\|\\leq1$ , where $\\|\\cdot\\|$ denotes the $\\ell_{2}$ norm unless otherwise stated. Other norms that are used include the classical $\\ell_{p}$ norms $\\|\\cdot\\|_{p}$ and matrix norms $\\|x\\|_{\\mathbf{M}}=x^{\\top}\\mathbf{M}x$ for a positive semi-definite matrix $\\mathbf{M}$ . ", "page_idx": 12}, {"type": "text", "text": "We also denote $\\mathbf{A}_{t}\\,\\in\\,\\mathbb{R}^{d\\times t}$ to be the history action matrix, whose $i$ -th column is $a_{i}$ , the action taken in round $i$ . Similarly, $\\mathbf{y}_{t}$ is defined analogously. Finally, for sake of analysis, we assume that $\\boldsymbol{\\mathcal{A}}$ contains an isotropic set of actions and specifically, there is $\\mathcal{E}\\subset\\mathcal{A}$ with size $|{\\mathcal{E}}|=O(d)$ such that $\\begin{array}{r}{\\sum_{i}e_{i}e_{i}^{\\top}\\succeq\\frac{1}{2}\\mathbf{I}.}\\end{array}$ , where $\\succeq$ denotes the PSD ordering on symmetric matrices. This assumption is not  restrictive, as it can be relaxed by using optimal design for least squares estimators [Lattimore and Szepesv\u00e1ri, 2020] and the Kiefer-Wolfrowitz Theorem [Kiefer and Wolfowitz, 1960], which guarantees the existence and construction of an uniform exploration basis of size $O(\\mathsf{p o l y}(d))$ . ", "page_idx": 12}, {"type": "text", "text": "$\\mathbf{Algorithm\\1!\\EXPLOREUCB}(T,\\mathcal{D},s_{\\lambda})$ ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Input :number of maximum actions $T$ , weight distribution $\\mathcal{D}$ , scalarization $s_{\\lambda}$ repeat ", "page_idx": 12}, {"type": "text", "text": "2 Play action $e_{n}\\in\\mathcal{E}$ for $n\\equiv i\\ \\bmod d$   \n3 Let $C_{t i}$ be the confidence ellipsoid for $\\Theta_{i}$ and let $U C B_{i}(a)=\\operatorname*{max}_{\\theta\\in C_{i}}\\theta^{\\top}a$   \n4 Draw $\\lambda\\sim{\\mathcal{D}}$ , play $a^{*}=\\operatorname{argmax}_{a\\in\\mathcal{A}}s_{\\lambda}(U C B_{i}(a))$   \n5 until number of rounds i exceed $T/2$ ", "page_idx": 12}, {"type": "text", "text": "B Missing Proofs ", "text_level": 1, "page_idx": 12}, {"type": "text", "text": "Proof of Lemma 5. Let $\\lambda=y^{\\star}/\\|y^{\\star}\\|$ . Note that $\\lambda>0$ since $y^{\\star}$ is in the positive orthant and for the sake of contradiction, assume there exists $z$ such that $s_{\\lambda}(z)>s_{\\lambda}(y^{\\star})$ . However, note that for any $i$ , $\\begin{array}{r}{\\frac{z_{i}}{\\lambda_{i}}\\geq\\operatorname*{min}_{i}\\frac{z_{i}}{\\lambda_{i}}>\\operatorname*{min}_{i}\\frac{y_{i}^{\\star}}{\\lambda_{i}}=\\frac{y_{i}^{\\star}}{\\lambda_{i}}}\\end{array}$ , where the last line follows since $y_{i}^{\\star}/\\lambda_{i}=\\|y^{\\star}\\|$ for all $i$ by construction. Therefore, we conclude that , contradicting that is Pareto optimal. ", "page_idx": 12}, {"type": "text", "text": "Finally, note that if $\\alpha\\lambda$ is on the Pareto frontier, then we see that $\\mathrm{min}_{i}\\,\\alpha\\lambda_{i}/\\lambda_{i}=\\alpha$ and furthermore, this min value is achieved for all $i$ . Therefore, since $\\alpha\\lambda$ is on the Pareto frontier, any other point $y\\in\\mathcal{V}$ has some coordinate $j$ such that $y_{j}<\\alpha\\lambda_{j}$ , which implies that $\\operatorname*{min}_{i}y_{i}/\\lambda_{i}<\\alpha$ . \u53e3 ", "page_idx": 12}, {"type": "text", "text": "Proof of Theorem 7. Let us denote $s_{\\lambda}=s_{\\lambda}^{H V}$ is the hypervolume scalarization and WLOG let $z=0$ . Note that we can first decompose our regret as ", "page_idx": 12}, {"type": "text", "text": "$\\begin{array}{r l}&{\\mathcal{H}\\mathcal{V}_{z}(\\mathcal{V}^{\\star})-\\mathcal{H}\\mathcal{V}_{z}(\\mathcal{V}_{T})\\,\\le\\,|\\mathcal{H}\\mathcal{V}_{z}(\\mathcal{V}^{\\star})-\\frac{c_{k}}{T}\\sum_{i=1}^{T}\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda_{i}}(y)|+|\\frac{c_{k}}{T}\\sum_{i=1}^{T}\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda_{i}}(y)-s_{\\lambda_{i}}^{2}|^{2}\\,,}\\\\ &{\\mathcal{H}\\mathcal{V}_{z}(\\mathcal{V}_{T})|}\\end{array}$ \u2212 $\\begin{array}{r l}&{\\leq|\\mathcal{H}\\mathcal{V}_{z}(\\mathcal{Y})-\\frac{c_{k}}{T}\\sum_{i=1}^{T}s_{\\lambda_{i}}(y)|+|\\frac{c_{k}}{T}\\sum_{i=1}^{T}\\operatorname*{max}_{y\\in\\mathcal{Y}_{T}}s_{\\lambda_{i}}(y)-\\mathcal{H}\\mathcal{V}_{z}(\\mathcal{Y}_{T})|}\\end{array}$ where the second inequality uses the fact that $y_{i}\\in\\arg\\operatorname*{max}_{y\\in\\mathcal{Y}}s_{\\lambda_{i}}(y)$ . We proceed to bound both parts separately and we note that it suffices to prove uniform concentration of the empirical sum to the expectation, as by our choice of scalarization is the hypervolume by Lemma 6. ", "page_idx": 12}, {"type": "text", "text": "Let $f_{\\mathbf{Y}}(\\lambda_{i})\\,=\\,\\operatorname*{max}_{y\\in\\mathbf{Y}}s_{\\lambda_{i}}(y)$ . We let ${\\mathcal F}=\\{f_{\\mathbf{Y}}:\\mathbf{Y}\\subseteq{A}\\}$ be our class of functions over all possible output sets $\\mathbf{Y}$ . We will first demonstrate uniform convergence by bounding the complexity of $\\mathcal{F}$ . Specifically, by generalization bounds from Rademacher complexities Bartlett and Mendelson [2002], over choices of $\\lambda_{i}\\sim{\\mathcal{D}}$ , we know that with probability $1-\\delta$ , for all $\\mathbf{Y}$ , we have the bound ", "page_idx": 12}, {"type": "equation", "text": "$$\n\\left|\\sum_{\\lambda\\sim\\mathcal{D}}[f_{\\mathbf{Y}}]-\\frac{1}{m}\\sum_{i=1}^{m}f_{\\mathbf{Y}}(\\lambda_{i})\\right|\\leq R_{m}(\\mathcal{F})+\\sqrt{\\frac{8\\ln(2/\\delta)}{m}}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "$\\begin{array}{r}{R_{m}(\\mathcal{F})={\\mathbf E}_{\\lambda_{i}\\sim\\mathcal{D},\\sigma_{i}}\\,\\biggl[\\underset{f\\in\\mathcal{F}}{\\operatorname*{sup}}\\frac{2}{m}\\sum_{i}\\sigma_{i}f(\\lambda_{i})\\biggr];}\\end{array}$ where $\\sigma_{i}$ are i.i.d. $\\pm1$ Rademacher variables. ", "page_idx": 13}, {"type": "text", "text": "To bound $R_{m}({\\mathcal{F}})$ , we appeal to Dudley\u2019s integral formulation that allows us to use the metric entropy of $\\mathcal{F}$ to bound ", "page_idx": 13}, {"type": "equation", "text": "$$\nR_{m}(\\mathcal{F})\\leq\\operatorname*{inf}_{\\alpha>0}\\left(4\\alpha+12\\int_{\\alpha}^{\\infty}\\sqrt{\\frac{\\log(\\mathcal{N}(\\epsilon,\\mathcal{F},\\|\\cdot\\|_{2}))}{m}}\\,d\\epsilon\\right)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $\\mathcal{N}$ denotes the standard covering number for $\\mathcal{F}$ under the $\\ell_{2}$ function norm metric over $\\lambda\\in{\\mathcal{D}}$ . Since $\\mathcal{D}$ is the uniform distribution over $S_{+}$ , this induces a natural $\\ell_{\\infty}$ function norm metric on $\\mathcal{F}$ that is $\\|f\\|_{\\infty}=\\operatorname*{sup}_{\\lambda\\in S_{+}}|f(\\lambda)|$ . By Lemma 15, since $y_{i}-z$ is bounded below and above by $B_{u},B_{l}$ respectively, $s_{\\lambda}(y)$ is $L_{\\lambda}$ Lipschitz with respect to the Euclidean norm in $\\lambda$ . Note that since the maximal operator preserves Lipschitzness, $f_{\\mathbf{Y}}(\\lambda)$ is also $L_{\\lambda}$ -Lipschitz with respect to $\\lambda\\in\\mathbb{R}^{k}$ for any $\\mathbf{Y}$ . Since $\\mathcal{F}$ contains $L_{\\lambda}$ -Lipschitz functions in $\\mathbb{R}^{k}$ , we can bound the metric entropy via a covering of $\\lambda$ via a Lipschitz covering argument (see Lemma 4.2 of Gottlieb et al. [2016]), so we have ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\log(\\mathcal{N}(\\epsilon,\\mathcal{F},\\|\\cdot\\|_{2}))\\leq\\log(\\mathcal{N}(\\epsilon,\\mathcal{F},\\|\\cdot\\|_{\\infty}))\\leq(4L_{\\lambda}/\\epsilon)^{k}\\log(8/k)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Finally, we follow the same Dudley integral computation of Theorem 4.3 of Gottlieb et al. [2016] to get that ", "page_idx": 13}, {"type": "equation", "text": "$$\nR_{m}(\\mathcal{F})\\leq\\operatorname*{inf}_{\\alpha>0}\\left(4\\alpha+12\\int_{\\alpha}^{2}\\sqrt{\\frac{(4L_{\\lambda}/\\epsilon)^{k}\\log(8/k)}{T}}\\,d\\epsilon\\right)\n$$", "text_format": "latex", "page_idx": 13}, {"type": "equation", "text": "$$\n=O(L_{\\lambda}/m^{1/(k+1)})\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Therefore, we conclude that with probability at least $1-\\delta$ over the independent choices of $\\lambda_{i}\\sim{\\mathcal{D}}$ , for all $\\mathbf{Y}$ and setting $m=T$ ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\lefteqn{\\operatorname{\\sum}_{\\lambda\\sim\\mathcal{D}}\\left[\\operatorname*{max}_{a\\in\\mathbf{Y}}s_{\\lambda}(\\Theta^{\\star}a)\\right]-\\frac{1}{T}\\sum_{i=1}^{T}\\operatorname*{max}_{a\\in\\mathbf{Y}}s_{\\lambda_{i}}(\\Theta^{\\star}a)}\\Bigg|}\\\\ &{\\quad\\quad\\quad\\leq O\\left(\\frac{L_{\\lambda}}{T^{1/(k+1)}}\\right)+\\sqrt{\\frac{8\\ln(2/\\delta)}{T}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "where $B$ is some $\\ell_{\\infty}$ upper bound on the output set $\\mathbf{Y}$ . Finally, we conclude by using Lemma 6 to replace the expectation by the hypervolume and by setting $\\mathbf{Y}=\\mathcal{Y},\\mathcal{Y}_{T}$ respectively. ", "page_idx": 13}, {"type": "text", "text": "Now consider the case when $k=2$ and we are using the Chebyshev scalarizer $s_{\\lambda}^{C S}$ . We claim that over the choice of the distribution $\\mathbf{Y}_{T}=\\{y_{1},...,y_{T}\\}$ $\\lambda\\sim S_{+}$ that corresponds to is the same and specifically let $y\\in\\operatorname{arg\\,max}_{y\\in\\mathcal{Y}}s_{\\lambda}^{\\mathrm{CS}}(y)$ $Y$ denote that random variable . Then, note that a standard way to draw a random weight on $S_{+}$ is to draw random absolute Gaussians and then renormalize, so if $\\begin{array}{r}{R^{2}=\\sum_{i}|X_{i}|^{2}}\\end{array}$ , where $X_{i}$ are i.i.d. Gaussian, then $Y=\\arg\\operatorname*{max}_{y\\in\\mathcal{Y}}\\,\\operatorname*{min}(\\frac{|X_{1}|}{R}y_{1},\\frac{|X_{2}|}{R}y_{2})$ . Note that the optimization of the arg-max is unaffected by positive scalar multiples of the objective, so multiplying by $R^{2}/(|X_{1}||X_{2}|)$ gives $\\begin{array}{r}{Y\\,=\\,\\arg\\underset{y\\in\\mathcal{Y}}{\\operatorname*{max}}\\overset{\\bullet}{\\operatorname*{min}}(\\frac{R}{|X_{2}|}y_{1},\\frac{R}{|X_{1}|}y_{2})}\\end{array}$ . Note since $X_{1},X_{2}$ are i.i.d., we conclude that $Y$ is the same distribution as the random variable that is given by $y\\in\\arg\\operatorname*{max}_{y\\in\\mathcal{D}}\\sqrt{s_{\\lambda}^{\\mathrm{HV}}(y)}$ distribution, we conclude. ", "page_idx": 13}, {"type": "text", "text": "", "page_idx": 14}, {"type": "text", "text": "B.1 Proofs of Lipschitz Properties ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Again, recall that for a scalarization function $s_{\\lambda}(x)$ , $s_{\\lambda}$ is $L_{p}$ -Lipschitz with respect to $x$ in the $\\ell_{p}$ norm on $\\mathcal{X}$ if for $x_{1},x_{2}\\in\\mathcal{X}$ , $|s_{\\lambda}(x_{1})-s_{\\lambda}(x_{2})|\\leq L_{p}\\|x_{1}\\stackrel{{}}{-}x_{2}\\|_{p}$ , and analogously for define $L_{\\lambda}$ for $p\\,=\\,2$ so $|s_{\\lambda_{1}}(x)-s_{\\lambda_{2}}(x)|\\,\\le\\,L_{\\lambda}\\|\\lambda_{1}-\\lambda_{2}\\|_{2}$ . We utilize the fact that if $s_{\\lambda}$ is differentiable everywhere except for a finite set, bounding Lipschitz constants is equivalent to bounding the dual norm $\\|\\nabla s_{\\lambda}\\|_{q}$ , where $1/p+1/q=1$ , which follows from mean value theorem, which we state as Proposition 12. ", "page_idx": 14}, {"type": "text", "text": "Proposition 12. Let $f:\\mathcal{X}\\to\\mathbb{R}$ be a continuous function that is differentiable everywhere except on a finite set, then if $\\|\\nabla f(x)\\|_{q}\\leq L_{p}$ for all $x\\in\\mathscr{X}$ , $f(x)$ is $L_{p}$ -Lipshitz with respect to the $\\ell_{p}$ norm. ", "page_idx": 14}, {"type": "text", "text": "Lemma 13. Let $s_{\\lambda}(y)=\\lambda^{\\top}y$ be the linear sca\u221alarization with $\\|\\lambda\\|\\leq1$ and $\\|y\\|_{\\infty}\\leq1$ . Then, we may bound $L_{p}\\le\\operatorname*{max}(1,k^{1/2-1/p})$ and $L_{\\lambda}\\leq\\sqrt{k}$ and $|s_{\\lambda}|\\leq{\\sqrt{k}}$ . ", "page_idx": 14}, {"type": "text", "text": "Proof of Lemma 13. Since $\\nabla_{\\lambda}s_{\\lambda}(x)\\,=\\,y$ , we use Proposition 12 to bound $L_{\\lambda}\\,\\leq\\,\\operatorname*{max}_{y}\\,\\|y\\|\\,\\leq$ ${\\sqrt{k}}\\|y\\|_{\\infty}={\\sqrt{k}}$ . Similarly, since $\\nabla_{y}s_{\\lambda}(y)=\\lambda$ , we may bound for $p\\leq2$ , $L_{p}\\leq\\|\\lambda\\|_{q}\\leq\\|\\lambda\\|\\leq1$ for $1/p+1/q\\;=\\;1$ and for $p~\\geq~2$ , we may use Holder\u2019s inequality to bound $L_{p}\\;\\leq\\;\\|\\lambda\\|_{q}\\;\\leq$ $k^{1/q-1/2}\\|\\lambda\\|\\leq k^{1/2-1/p}$ . ", "page_idx": 14}, {"type": "text", "text": "T\u221ao bound the absolute value of $s_{\\lambda}$ , note $s_{\\lambda}(y)\\,=\\,\\lambda^{\\top}y\\,\\leq\\,\\sqrt{k}$ for all since $\\|y\\|_{2}\\,\\leq\\,\\sqrt{k}\\|y\\|_{\\infty}\\,\\leq$ $\\sqrt{k}$ . ", "page_idx": 14}, {"type": "text", "text": "Lemma 14. Let $s_{\\lambda}(y)=\\mathrm{min}_{i}\\,\\lambda_{i}y_{i}$ be the Chebyshev s\u221acalarization with $\\|\\lambda\\|\\leq1$ and $\\|y\\|_{\\infty}\\leq1$ .   \nThen, we may bound $L_{p}\\leq1$ and $L_{\\lambda}\\leq1$ and $|s_{\\lambda}|\\leq1/\\sqrt{k}$ . ", "page_idx": 14}, {"type": "text", "text": "Proof of Lemma $I4.$ . For a specific $\\lambda,y$ , let $i^{\\star}$ be the optimal index of the minimization. Then, the gradient $\\nabla_{\\lambda}s_{\\lambda}(x)$ is simply zero in every coordinate except at $i^{\\star}$ , where it is $y_{i}\\star$ . Therefore, since we can only have a finite number of discontinuities due to monotonicity, we use Proposition 12 to bound $L_{\\lambda}\\leq y_{i^{\\star}}\\leq1$ . Similarly, since $\\nabla_{y}s_{\\lambda}(y)$ has only one non-zero coordinate except at $i^{\\star}$ , which is $\\lambda_{i^{\\star}}$ , we may bound for $L_{q}\\leq\\lambda_{i^{\\star}}\\leq1$ . ", "page_idx": 14}, {"type": "text", "text": "To bound the ab\u221asolute value of $s_{\\lambda}$ , note that there must exists $\\lambda_{i}\\,<\\,1/\\sqrt{k}$ as $\\|\\lambda\\|\\,\\leq\\,1$ . Thus, $\\operatorname*{min}_{i}\\lambda_{i}y_{i}<1/\\sqrt{k}$ for $\\|y\\|_{\\infty}\\leq1$ . \u53e3 ", "page_idx": 14}, {"type": "text", "text": "Lemma 15. Let $s_{\\lambda}(y)\\;=\\;\\mathrm{min}_{i}(y_{i}/\\lambda_{i})^{k}$ be the hypervolume scalarization with $\\|\\lambda\\|\\;=\\;1$ and $0<B_{l}\\leq y_{i}\\leq B_{u}$ . Then, we may bound $\\begin{array}{r}{L_{p}\\leq\\frac{B_{u}^{k}}{B_{l}k^{k/2-1}}}\\end{array}$ \u2264Blkk/u2\u22121 and L\u03bb \u2264 $\\begin{array}{r}{L_{\\lambda}\\leq\\frac{B_{u}^{k+1}}{B_{l}k^{(k-1)/2}}}\\end{array}$ and $\\begin{array}{r}{|s_{\\lambda}|\\le\\frac{B_{u}^{k}}{k^{k/2}}}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Proof of Lemma 15. For a specific $\\lambda,y$ , let $i^{\\star}$ be the optimal index of the minimization. Then, the gradient $\\nabla_{\\lambda}s_{\\lambda}(x)$ is simply zero in every coordinate except at $i^{\\star}$ , which in absolute value is $k(y_{i^{\\star}}/\\lambda_{i^{\\star}})^{k}(1/\\lambda_{i^{\\star}})$ . ", "page_idx": 14}, {"type": "text", "text": "Let $j$ be the index such that $\\lambda_{j}$ is maximize\u221ad and since $\\|\\lambda\\|=1$ , we know that $\\lambda_{j}\\geq1/\\sqrt{k}$ . Therefore, we see that since $y_{i^{\\star}}/\\lambda_{i^{\\star}}\\leq\\dot{y}_{j}/\\lambda_{j}\\leq y_{j}/\\sqrt{k}$ , we conclude that $1/\\lambda_{i^{\\star}}\\le(B_{u}/B_{l})/\\sqrt{k}$ . ", "page_idx": 14}, {"type": "text", "text": "Therefore, using Proposition 12, we have $\\begin{array}{r}{L_{\\lambda}\\,\\le\\,k(y_{i^{\\star}}/\\lambda_{i^{\\star}})^{k}(1/\\lambda_{i^{\\star}})\\,\\le\\,k(B_{u}/\\sqrt{k})^{k}\\frac{(B_{u}/B_{l})}{\\sqrt{k}}\\,=\\,}\\end{array}$ $\\frac{B_{u}^{k+1}}{B_{l}k^{(k-1)/2}}$ ", "page_idx": 14}, {"type": "text", "text": "And similarly, since $\\nabla_{y}s_{\\lambda}(y)$ has only one non-zero coordinate except at $i^{\\star}$ , which is $k(y_{i^{\\star}}/\\lambda_{i^{\\star}})^{k-1}(1/\\lambda_{i^{\\star}})$ , we may bound for ", "page_idx": 14}, {"type": "equation", "text": "$$\n\\begin{array}{r}{L_{q}\\leq k(y_{i^{\\star}}/\\lambda_{i^{\\star}})^{k-1}(1/\\lambda_{i^{\\star}})\\leq k(B_{u}/\\sqrt{k})^{k-1}\\frac{(B_{u}/B_{l})}{\\sqrt{k}}\\leq\\frac{B_{u}^{k}}{B_{l}k^{k/2-1}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 14}, {"type": "text", "text": "To bound the absolute value of $s_{\\lambda}$ , note that $\\begin{array}{r}{s_{\\lambda}(y)\\le(\\frac{y_{j}}{\\lambda_{j}})^{k}\\le\\frac{B_{u}^{k}}{k^{k/2}}}\\end{array}$ ", "page_idx": 14}, {"type": "text", "text": "B.2 Proofs for Linear Bandits ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "The following lemma about the UCB ellipsoid is borrowed from the original analysis of linear bandits. Lemma 16 (Abbasi-Yadkori et al. [2011]). Consider the least squares estimator $\\widehat{\\theta_{t}}=(\\mathbf{M}_{t})^{-1}\\mathbf{A}_{t}^{\\top}\\mathbf{y}_{t}$ , where the covariance matrix of the action matrix is $\\mathbf{M}_{t}=\\mathbf{A}_{t}^{\\top}\\mathbf{A}_{t}+\\lambda\\mathbf{I}_{t}$ , then with probability $1-\\delta$ , ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\widehat{\\theta_{t}}-\\theta^{*}\\|_{\\mathbf{M}_{t}}\\leq\\sqrt{\\lambda}\\|\\theta^{*}\\|+\\sqrt{2\\log(\\frac{1}{\\delta})+d\\log(T/\\lambda)}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof of Lemma $I O$ . Let $\\widehat{\\Theta}_{T}$ be the least squares estimate of the true parameters after observing $(\\mathbf{A}_{T},\\mathbf{y}_{T})$ . Since the noise $\\xi_{t}$ in each objective is independent and 1-sub-Gaussian, by Lemma 16, if we let $\\mathbf{M}_{T}=\\mathbf{A}_{T}^{\\top}\\mathbf{A}_{T}+\\lambda\\mathbf{I}$ , then with regularization $\\lambda=1$ ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\|\\widehat{\\Theta}_{T i}-\\Theta_{i}^{\\star}\\|_{\\mathbf{M}_{T}}\\leq1+\\sqrt{2\\log(k/\\delta)+d\\log(T)}:=D_{T}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "holds with probability at least $1-\\delta/k$ . Note that this describes the confidence ellipsoid, $C_{T i}=\\{\\theta\\in$ $\\mathbb{R}^{d}:\\|\\widehat{\\Theta}_{T i}-\\theta_{i}\\|_{\\mathbf{M}_{T}}\\leq D_{T}\\}$ for $\\Theta_{T i}$ . ", "page_idx": 15}, {"type": "text", "text": "By the definition of the UCB maximization of $a_{t}$ , we see $a_{t},\\widetilde{\\Theta}_{t}=\\operatorname*{argmax}_{a\\in A}\\operatorname*{max}_{\\theta_{i}\\in C_{T i}}s_{\\lambda}\\big(\\Theta_{i}^{\\top}a\\big)$ . Note that since $\\Theta^{\\star}\\in\\mathbf{C}_{T}$ , we can bound the instantaneous  scalarized regret as: ", "page_idx": 15}, {"type": "equation", "text": "$$\nr(s_{\\lambda},a_{t})=\\operatorname*{max}_{a\\in A}s_{\\lambda}(\\Theta^{\\star}a)-s_{\\lambda}(\\Theta^{\\star}a_{t})\\leq s_{\\lambda}(\\widetilde\\Theta_{t}a_{t})-s_{\\lambda}(\\Theta^{\\star}a_{t})\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "By the Lipschitz smoothness condition, we conclude that $r(s_{\\lambda},a_{t})\\leq L_{p}\\|(\\widetilde{\\Theta_{t}}-\\Theta^{\\star})a_{t}\\|_{p}.$ ", "page_idx": 15}, {"type": "text", "text": "To bound the desired $\\ell_{p}$ norm, first note that by triangle inequality, $\\|\\widetilde{\\Theta_{t}}-\\Theta^{\\star}\\|_{\\mathbf{M}_{T}}\\leq2D_{T}$ . Since we apply uniform exploration every other step and $\\begin{array}{r l}{\\sum_{i}e_{i}e_{i}^{\\top}\\succeq\\frac{1}{2}\\mathbf{I}}\\end{array}$ for $e_{i}\\in\\mathcal{E}$ with size $|{\\mathcal{E}}|=d$ , we conclude that $\\begin{array}{r}{{\\bf M}_{T}\\,\\succeq\\,\\frac{T}{5d}{\\bf I}}\\end{array}$ . Therefore, we conclude that $\\lVert\\widehat{\\Theta}_{T i}-\\Theta_{i}^{\\star}\\rVert\\,\\leq\\,5\\sqrt{d/T}D_{T}:=\\,E_{T}$ with probability at least $1\\!-\\!\\delta/k$ . Since $\\|a_{t}\\|\\leq1$ , we conclude by Cauchy-Schwarz, that $|(\\widehat{\\Theta}_{T i}-\\Theta_{i}^{\\star})a_{t}|\\leq$ $E_{T}$ . Together with our Lipschitz condition, we conclude that ", "page_idx": 15}, {"type": "equation", "text": "$$\nr(s_{\\lambda},a_{t})\\le k^{1/p}L_{p}E_{T}\\le10k^{1/p}L_{p}d\\sqrt{(\\log(k/\\delta)+\\log(T))/T}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Theorem 17. Assume that for any $a\\in{\\mathcal{A}}$ , $|s_{\\lambda}(\\Theta^{\\star}a)|\\leq B$ for some $B$ and $s_{\\lambda}$ is $L_{\\lambda}$ -Lipschitz with respect to the $\\ell_{2}$ norm in $\\lambda.$ . With constant probability, the Bayes regret of running Algorithm $^{\\,l}$ at round $T$ can be bounded by ", "page_idx": 15}, {"type": "equation", "text": "$$\nB R(s_{\\lambda},\\mathbf{A}_{T})\\leq O\\left(k^{\\frac{1}{p}}L_{p}d\\sqrt{\\frac{\\log(k T)}{T}}+\\frac{B L_{\\lambda}}{T^{\\frac{1}{k+1}}}\\right)\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Proof of Theorem 17. For any set of actions $\\mathbf{A}\\subseteq A$ , we define $f_{\\mathbf{A}}(\\lambda)=\\operatorname*{max}_{a\\in\\mathbf{A}}s_{\\lambda}(\\Theta^{\\star}a)$ . We let $\\mathcal{F}=\\{f_{\\mathbf{A}}:\\mathbf{A}\\subseteq\\mathcal{A}\\}$ be our class of functions over all possible action sets and for any Bayes regret bounds, we will first demonstrate uniform convergence by bounding the complexity of $\\mathcal{F}$ . Specifically, by generalization bounds from Rademacher complexities Bartlett and Mendelson [2002], over choices of $\\lambda_{i}\\sim{\\mathcal{D}}$ , we know that with probability $1-\\delta$ , for all $\\mathbf{A}$ , we have the bound ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\left|\\sum_{\\lambda\\sim\\mathcal{D}}[f_{\\mathbf{A}}]-\\frac{1}{m}\\sum_{i=1}^{m}f_{\\mathbf{A}}(\\lambda_{i})\\right|\\leq R_{m}(\\mathcal{F})+\\sqrt{\\frac{8\\ln(2/\\delta)}{m}}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "$\\begin{array}{r}{R_{m}(\\mathcal{F})={\\mathbf E}_{\\lambda_{i}\\sim\\mathcal{D},\\sigma_{i}}\\left[\\operatorname*{sup}_{f\\in\\mathcal{F}}\\frac{2}{m}\\sum_{i}\\sigma_{i}f(\\lambda_{i})\\right]}\\end{array}$ , where $\\sigma_{i}$ are i.i.d. $\\pm1$ Rademacher variables. ", "page_idx": 15}, {"type": "text", "text": "To bound $R_{m}({\\mathcal{F}})$ , we appeal to Dudley\u2019s integral formulation that allows us to use the metric entropy of $\\mathcal{F}$ to bound ", "page_idx": 16}, {"type": "equation", "text": "$$\nR_{m}(\\mathcal{F})\\leq\\operatorname*{inf}_{\\alpha>0}\\left(4\\alpha+12\\int_{\\alpha}^{\\infty}\\sqrt{\\frac{\\log(\\mathcal{N}(\\epsilon,\\mathcal{F},\\|\\cdot\\|_{2}))}{m}}\\,d\\epsilon\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where $\\mathcal{N}$ denotes the standard covering number for $\\mathcal{F}$ under the $\\ell_{2}$ function norm metric over $\\lambda\\in{\\mathcal{D}}$ . Since $\\mathcal{D}$ is the uniform distribution over $S_{+}$ , this induces a natural $\\ell_{\\infty}$ function norm metric on $\\mathcal{F}$ that is $\\|f\\|_{\\infty}=\\operatorname*{sup}_{\\lambda\\in S_{+}}|f(\\lambda)|$ . Since $s_{\\lambda}(\\Theta^{\\star}a)$ is $L_{\\lambda}$ Lipschitz with respect to the Euclidean norm in $\\lambda$ . Note that since the maximal operator preserves Lipschitzness, $f_{\\mathbf{A}}(\\lambda)$ is also $L_{\\lambda}$ -Lipschitz with respect to $\\lambda\\in\\mathbb{R}^{k}$ . Since $\\mathcal{F}$ contains $L_{\\lambda}$ -Lipschitz functions in $\\mathbb{R}^{k}$ , we can bound the metric entropy via a covering of $\\lambda$ via a Lipschitz covering argument (see Lemma 4.2 of Gottlieb et al. [2016]), so we have ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\log(\\mathcal{N}(\\epsilon,\\mathcal{F},\\|\\cdot\\|_{2}))\\leq\\log(\\mathcal{N}(\\epsilon,\\mathcal{F},\\|\\cdot\\|_{\\infty}))\\leq(4L_{\\lambda}/\\epsilon)^{k}\\log(8/k)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Finally, we follow the same Dudley integral computation of Theorem 4.3 of Gottlieb et al. [2016] to get that ", "page_idx": 16}, {"type": "equation", "text": "$$\nR_{m}(\\mathcal{F})\\leq\\operatorname*{inf}_{\\alpha>0}\\left(4\\alpha+12\\int_{\\alpha}^{2}\\sqrt{\\frac{(4L_{\\lambda}/\\epsilon)^{k}\\log(8/k)}{m}}\\,d\\epsilon\\right)\n$$", "text_format": "latex", "page_idx": 16}, {"type": "equation", "text": "$$\n=O(L_{\\lambda}/m^{1/(k+1)})\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Therefore, we conclude that with probability at least $1-\\delta$ over the independent choices of $\\lambda_{i}\\sim{\\mathcal{D}}$ , for all $\\mathbf{A}$ , ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{\\left|\\underset{\\lambda\\sim\\mathcal{D}}{\\mathbf{E}}\\left[\\underset{\\boldsymbol{a}\\in\\mathbf{A}}{\\operatorname*{max}}\\,s_{\\lambda}(\\Theta^{\\star}\\boldsymbol{a})\\right]-\\frac{1}{m}\\sum_{i=1}^{m}\\underset{\\boldsymbol{a}\\in\\mathbf{A}}{\\operatorname*{max}}\\,s_{\\lambda_{i}}(\\Theta^{\\star}\\boldsymbol{a})\\right|}\\\\ &{\\qquad\\qquad\\leq O\\left(\\frac{B L_{\\lambda}}{m^{1/(k+1)}}\\right)+\\sqrt{\\frac{8\\ln(2/\\delta)}{m}}}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "Finally, note that for $T$ even, with constant probability, ", "page_idx": 16}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\beta H(\\omega_{\\infty},\\lambda_{\\infty})=}&{\\sum_{k\\geq1}^{\\infty}\\left[r(\\frac{\\sin{\\alpha}}{r})(s,k,\\omega_{\\infty})\\right]}\\\\ &{=\\frac{k}{2}\\cos{r}\\left[\\Theta_{\\infty}s,\\cos^{\\prime}(\\Theta^{-\\alpha})-\\frac{\\cos{s}_{0}(\\Theta^{-\\alpha})}{\\cos{r}s}\\right]}\\\\ &{\\leq\\frac{1}{2}\\frac{\\sqrt{2}}{\\int_{0}^{\\pi}\\left[\\frac{\\sin{\\alpha}}{r}\\right]\\left[\\Theta^{\\alpha}\\right]-\\sin{(\\Theta^{\\alpha})}}-\\frac{\\sin{s}_{0}(\\Theta^{-\\alpha})}{\\sin{r}s},}\\\\ &{\\phantom{=}+O\\left(\\frac{\\beta|U_{\\infty}\\lambda_{\\infty}}{2}\\right)}\\\\ &{\\leq\\frac{1}{2}\\frac{r(\\frac{\\sin{\\alpha}}{r})}{\\int_{0}^{\\pi}\\left[\\frac{\\sin{\\alpha}}{r}\\right]\\left[\\Theta^{\\alpha}\\right]-1}\\cos_{\\pi}(\\Theta^{-\\alpha}),}\\\\ &{\\phantom{=}+O\\left(\\frac{B_{\\infty}\\lambda_{\\infty}}{T^{2}/2}\\right)}\\\\ &{\\leq\\frac{1}{2}\\frac{\\sqrt{2}}{\\int_{0}^{\\pi}\\left[\\frac{\\sin{\\alpha}}{r}\\right]\\left[\\Theta^{\\alpha}\\right]+O\\left(\\frac{B_{\\infty}\\lambda_{\\infty}}{T^{2}/2}\\right)}}\\\\ &{\\leq O\\left(\\frac{k^{1/2}}{r^{1/2}}\\right)}\\end{array}\n$$", "text_format": "latex", "page_idx": 16}, {"type": "text", "text": "where the last line used Lemma 10 with $\\delta~=~1/T^{2}$ and applied a union bound over all ${\\cal O}(T)$ iterations. \u5382 ", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem $_{l l}$ . Note that by Lemma 6, we connect the Bayes regret to the hypervolume regret for $\\mathcal{D}$ : ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathcal{A})-\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathbf{A}_{t})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "equation", "text": "$$\n=c_{k}\\operatorname{\\bf\\bf~E}_{\\lambda\\sim\\mathcal{D}}[\\operatorname*{max}_{a\\in\\mathcal{A}}s_{\\lambda}(\\Theta^{\\star}a)-\\operatorname*{max}_{a\\in{\\bf A}_{T}}s_{\\lambda}(\\Theta^{\\star}a)]\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where $s_{\\lambda}(y)=\\mathrm{min}_{i}(y_{i}-z_{i}/\\lambda_{i})^{k}$ . ", "page_idx": 17}, {"type": "text", "text": "Note that since $\\|\\Theta^{\\star}a\\|_{\\infty}\\leq1$ for all $a\\in A$ and $B$ is maximal, we have $B\\leq\\Theta^{\\star}a-z\\leq B+2$ . Therefore, we conclude by Lemma 15 that $s_{\\lambda}$ is Lipschitz with ", "page_idx": 17}, {"type": "equation", "text": "$$\nL_{p}\\leq{\\frac{(B+2)^{k}}{B k^{k/2-1}}},L_{\\lambda}\\leq{\\frac{(B+2)^{k+1}}{B k^{(k-1)/2}}},|s_{\\lambda}|\\leq{\\frac{(B+2)^{k}}{k^{k/2}}}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "Finally, we combine this with Theorem 17 with $p=\\infty$ as the optimal choice of $p$ (since $L_{p}$ does not depend on $p$ ) to get our desired bound on hypervolume regret. \u53e3 ", "page_idx": 17}, {"type": "text", "text": "Proof of Theorem 8. We let $A=\\{a:\\|a\\|\\leq1\\}$ be the unit sphere and $\\Theta_{i}^{\\star}=e_{i}$ be the unit vector directions. Note that in this case the Pareto frontier is exactly $S_{+}^{k-1}$ . ", "page_idx": 17}, {"type": "text", "text": "Consider a uniform discretization of the Pareto front by taking an $\\epsilon$ grid with respect to each angular component with respect to the polar coordinates. Let $p_{1},...,p_{m}$ be the center (in terms of each of the $k-1$ angular dimensions) in the $m\\,=\\,\\Theta((1/\\epsilon)^{k-1})$ grid elements. We consider the output ${\\bf y}_{T}=\\Theta^{\\star}{\\bf A}_{T}$ and assume that for some grid element $i$ , it contains none of the $T$ outputs $\\mathbf{y}_{T}$ . Since our radial component $r=1$ , by construction of our grid in the angular component, we deduce that $\\mathrm{min}_{t}\\left\\|y_{t}-p_{i}\\right\\|_{\\infty}>\\epsilon/10$ by translating polar to axis-aligned coordinates. ", "page_idx": 17}, {"type": "text", "text": "Let $\\epsilon^{\\prime}\\,=\\,\\epsilon/10$ . Assume also that $\\begin{array}{r}{\\frac{1}{k}\\;<\\;p_{i}\\;<\\;1\\,-\\,\\frac{1}{k}}\\end{array}$ . Next, we claim that the hypercube from $p_{i}-\\epsilon^{\\prime}/k^{2}$ to $p_{i}$ is not dominated by any points in ${\\bf Y}_{T}$ . Assume otherwise that there exists $y_{t}$ such that $y_{t}\\geq p_{i}-\\epsilon^{\\prime}/k^{2}$ . Now, this combined with the fact that since $\\mathrm{min}_{t}\\,\\|y_{t}-p_{i}\\|_{\\infty}>\\epsilon^{\\prime}$ implies that there must exist a coordinate such that $y_{t j}\\ge p_{j}+\\epsilon^{\\prime}$ . ", "page_idx": 17}, {"type": "text", "text": "However, this implies that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\sum_{i=1}^{k}y_{t i}^{2}\\geq\\displaystyle\\sum_{i\\neq j}(p_{i}-\\epsilon^{\\prime}/k^{2})^{2}+(p_{j}+\\epsilon^{\\prime})^{2}}\\\\ {\\geq\\displaystyle\\sum_{i}p_{i}^{2}-2(\\epsilon^{\\prime}/k^{2})\\sum_{i\\neq j}p_{i}+2\\epsilon^{\\prime}p_{j}>1}\\end{array}\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "where the last inequality follows since $\\textstyle\\sum_{i}p_{i}<1/{\\sqrt{k}}$ and $\\begin{array}{r}{p_{j}>\\frac{1}{k}}\\end{array}$ by assumption. However, this contradicts that $\\|y_{t}\\|\\leq1$ , so it follows that $p_{i}-\\epsilon^{\\prime}$ is not dominated. ", "page_idx": 17}, {"type": "text", "text": "Therefore, for any grid element such that $p_{i}>1/k$ , if there is no $y_{t}$ in the grid, we must have a hypervolume regret of at least $\\Omega(\\epsilon^{\\prime k})=\\Omega(\\epsilon^{k})$ be simply consider the undominated hypervolume from $p_{i}$ to $p_{i}-\\epsilon^{\\prime}$ , which lies entirely within the grid element. In fact, since there are $\\Theta((1/\\epsilon)^{k-1})$ such grid elements satisfying $p_{i}>1/k$ , we see that if $T<O((1/\\epsilon)^{k-1})$ , by pigeonhole, there must be a hypervolume regret of at least $\\dot{\\Omega}((1/\\epsilon)^{k-1}\\epsilon^{k})=\\Omega(\\epsilon)$ ", "page_idx": 17}, {"type": "text", "text": "Therefore, for any $/2>\\epsilon>0,\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathcal{A})-\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathbf{A}_{T})<\\epsilon$ implies that $T=\\Omega((1/\\epsilon)^{k-1})$ . Rearranging shows that ", "page_idx": 17}, {"type": "equation", "text": "$$\n\\mathcal{H V}_{z}(\\Theta^{\\star}A)-\\mathcal{H V}_{z}(\\Theta^{\\star}\\mathbf{A}_{T})=\\Omega(T^{-1/(k-1)})\n$$", "text_format": "latex", "page_idx": 17}, {"type": "text", "text": "C Figures ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "C.1 Synthetic Figures ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Here are the relevant full plots from synthetic optimization of Pareto frontiers. Note that the title of each plots explicitly mention the optimized function. Generally, we observe that the hypervolume scalarizer has better performance on more concave curves. We also include a plot of a concave function multiplied by a linear combination of a convex and concave function, given by $z=$ $\\exp(-x)(x\\exp(-y)+(1-x)(3-\\exp(y)))$ , which demonstrates that hypervolume scalarization performs competitively even with convex frontier regions. ", "page_idx": 18}, {"type": "image", "img_path": "30NS22tgCW/tmp/340a813facec0e86895accf3c0cc176ad369db9be0856dd2f5f2906b66a54351.jpg", "img_caption": [], "img_footnote": [], "page_idx": 18}, {"type": "image", "img_path": "30NS22tgCW/tmp/3be4d0affef38c43ac599ea03893406e44b3d1f1887452f7181feb6d51717c6c.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "C.2 BBOB Figures ", "text_level": 1, "page_idx": 19}, {"type": "image", "img_path": "30NS22tgCW/tmp/f5fe6cde5b88bda1202c68593de18a9a5f2a611040e113e2c8f422326b95f4fd.jpg", "img_caption": [], "img_footnote": [], "page_idx": 19}, {"type": "text", "text": "Figure 5: Comparisons of the hypervolume indicator and the optimization fronts with BBOB functions. The left plot tracks the dominated hypervolume as a function of trials that were evaluated. The blue/orange dots represent the frontier points of the UCB-HV/EHVI algorithms respectively, over 5 repeats. Especially in high dimensions, EHVI tends overly concentrate on points in the middle of the frontier, limiting its hypervolume gain, while hypervolume scalarizations produce more diverse points. ", "page_idx": 19}, {"type": "image", "img_path": "30NS22tgCW/tmp/5c51e52b588526d188410962f79cf6f78f9918c91cc700f90cf92e9e169dc44a.jpg", "img_caption": [], "img_footnote": [], "page_idx": 20}, {"type": "image", "img_path": "30NS22tgCW/tmp/2921ce70692214cc5292d2ece6333799f04bd74c393bb7d7c027b09db6f3fece.jpg", "img_caption": [], "img_footnote": [], "page_idx": 21}, {"type": "text", "text": "D Code ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "# -\\*- coding: utf-8 -\\*- \"\"\"3D Hypervolume Experiments ", "page_idx": 22}, {"type": "text", "text": "Automatically generated by Colab. ", "page_idx": 22}, {"type": "text", "text": "Original file is located at https://colab.corp.google.com/drive/1XbxabRf_aqgE0nRY-cX6McieUc3XnHSG ", "page_idx": 22}, {"type": "text", "text": "### Imports \"\"\" ", "page_idx": 22}, {"type": "text", "text": "import numpy as np   \nimport matplotlib.pyplot as plt   \nfrom vizier.pyvizier import multimetric   \nfrom vizier.pyvizier.multimetric import xla_pareto   \n$\\mathsf{e p s}~=~1\\mathsf{e}\\!-\\!4$   \norigin $=$ np.zeros(shape $:=3$ ) - eps   \nfront $=$ multimetric.ParetoFrontier( points $;=$ np.zeros(shape $=$ (2,3)) - eps, origin $=$ origin, num_vector ${\\tt s}\\!=\\!1\\,0\\,0\\,0\\,0$ , cum_hypervolume_base $=$ xla_pareto.jax_cum_hypervolume_origin, ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "hv_curve $=$ front.hypervolume(is_cumulative $=$ True) ", "page_idx": 22}, {"type": "text", "text": "import numpy as np import matplotlib.pyplot as plt ", "page_idx": 22}, {"type": "text", "text": "$\\mathrm{{pi}~=~\\mathrm{{np}\\cdot\\mathrm{{p}\\dot{1}}~+~\\Omega1\\mathrm{{e}-4}}}$   \n# Define the function to plot   \nthreshold $=~0\\cdot1$   \ndef g(x): if x $<=$ threshold: return np.cos( $\\mathrm{{x}\\star\\mathrm{{p}\\bot/}}$ ( $^{2\\,\\star}$ threshold)) + 1 else: return np.exp( $^{-3\\star}$ (x-threshold))   \n$\\mathrm{~\\mathsf~{~g~}~}=\\mathrm{~\\mathsf~{~1~}~}$ ambda x : np.cos(x\\*pi) + 1 ", "page_idx": 22}, {"type": "text", "text": "# Generate some data $\\mathrm{~\\textit~{~x~}~}=$ np.linspace(0, 1, 500) $\\mathrm{~y~}=$ np.vectorize(g)(x) ", "page_idx": 22}, {"type": "text", "text": "# Plot the data   \nplt.plot(x, y, \u2019bo\u2019)   \nplt.xlabel $({\\bf\\Xi}^{\\prime}\\times{\\bf\\Xi}^{\\prime})$   \nplt.ylabel $({\\bf\\Xi}^{\\prime}\\ Y^{\\prime}\\ )$   \nplt.title(\u20191D Function Plot\u2019)   \nplt.show()   \ndef f(x, y): # return np.vectorize(g)(x) \\* np.vectorize(g)(y)   \n# return (3 - np.exp(x)) $\\star$ (x \\* np.exp(-y) + (1-x)\\*(3-np.exp(y)))   \n# return (3 - np.exp(x)) $\\star$ (3- np.exp(y))   \n# return np.exp(-x) $\\star$ (3-np.exp(y))   \nreturn (3-np.exp(x)) $\\star$ (np.cos(y \\* pi) + 1)   \nreturn np.exp(-x) $\\star$ (x \\* np.exp(-y) + (1-x) \\* (3 - np.exp(y))) # return np.exp $(-{\\tt x}\\,\\mathrm{~\\boldmath~-~}\\,\\mathrm{~\\boldmath~y~})$ ) ", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 22}, {"type": "text", "text": "", "page_idx": 23}, {"type": "text", "text": "$\\mathrm{~\\textit~{~x~}~}=$ np.linspace(0, 1, 30) $\\mathrm{~y~}=$ np.linspace(0, 1, 30) ", "page_idx": 23}, {"type": "text", "text": "X, $\\mathrm{~\\textit~{~Y~}~}=$ np.meshgrid(x, y)   \n$\\mathrm{~\\boldmath~\\sf~Z~}=\\mathrm{~\\boldmath~\\mathcal~{~f~}~}(\\mathrm{\\boldmath~X~},\\mathrm{~\\boldmath~\\Y~})$   \nfig $=$ plt.figure(figsize $=$ (4, 4))   \nax $=$ plt.axes(projecti $\\mathsf{o n}\\!=\\!^{\\prime}\\,3\\,\\mathsf{d}^{\\prime}$ )   \nax.contour3D(X, Y, Z, 500)   \nax.set_xlabel $({\\bf\\Xi}^{\\prime}\\times{\\bf\\Xi}^{\\prime})$   \nax.set_ylabel $({\\bf\\Xi}^{\\prime}\\boldsymbol{\\mathrm{\\Lambda}}_{\\boldsymbol{Y}}\\prime{\\bf\\Xi})$   \nax.set_zlabel $\\left({\\bf\\Xi}^{\\prime}\\subset{\\bf\\Xi}^{\\prime}\\right)$   \nax.set_title(\u2019z = (3-exp(x))(3 - exp(y)) ", "page_idx": 23}, {"type": "text", "text": "$\\smash{\\mathrm{~x~}=\\mathrm{~X~}}$ .flatten() y $=$ Y.flatten() z $=$ Z.flatten() ", "page_idx": 23}, {"type": "text", "text": "xla_pareto.is_frontier(np.array([x, y, z]).T) ", "page_idx": 23}, {"type": "text", "text": "total_hypervolume $=$ front.hypervolume(additional_point $\\leq=$ np.array([x, y, z]).T) ", "page_idx": 23}, {"type": "text", "text": "total_hypervolume ", "page_idx": 23}, {"type": "text", "text": "#@title Hypervolume code   \ndef get_points(scalarizer_generator, num_points $=~50$ ): index_maxes $=$ [] for _ in range(num_points): outputs $=$ scalarizer_generator(np.array([x, y, z])) index_max $=$ np.argmax(outputs) index_maxes.append(index_max) return index_maxes ", "page_idx": 23}, {"type": "text", "text": "def linear_gaussian_generator(array): weights $=$ abs(np.random.normal(size $=$ (array.shape[0], 1))) return np.sum(weights $\\star$ array, axi $\\scriptstyle\\mathtt{S}\\,=\\,0$ ) ", "page_idx": 23}, {"type": "text", "text": "def cheby_gaussian_generator(array): weights $=$ abs(np.random.normal(size $=$ (array.shape[0], 1))) return np.min(weights $\\star$ array, axi $\\scriptstyle\\mathtt{S}\\,=\\,0$ ) ", "page_idx": 23}, {"type": "text", "text": "def hv_gaussian_generator(array): weights $=$ abs(np.random.normal(size $=$ (array.shape[0], 1))) return np.min((1/weights) $\\star$ array, axis $=0$ )   \ngenerators $=$ { \u2019linear\u2019: linear_gaussian_generator, \u2019cheby\u2019: cheby_gaussian_generator, \u2019hv\u2019: hv_gaussian_generator,   \n} ", "page_idx": 23}, {"type": "text", "text": "index_maxes $=$ get_points(hv_gaussian_generator) ", "page_idx": 23}, {"type": "text", "text": "from vizier.benchmarks.analyzers import plot_median_convergence ", "page_idx": 23}, {"type": "text", "text": "num_repeats $\\r=\\ r_{1}0$   \ngenerator_curves $\\begin{array}{r l}{{}={}}&{{}\\left\\{\\begin{array}{l}{\\begin{array}{r l}\\end{array}}\\end{array}\\right\\}}\\end{array}$   \nfor _ in range(num_repeats): for key, generator in generators.items(): index_maxes $=$ get_points(generator, num_point $S\\!=\\!500$ ) new_points $=$ np.vstack([x[index_maxes], y[index_maxes], z[index_maxes]]).T hv_curve $=$ front.hypervolume(is_cumulative $=$ True, additional_points $=$ new_points) regret_curve $=$ total_hypervolume - hv_curve if key in generator_curves: generator_curves[key] $=$ np.vstack([generator_curves[key], regret_curve]) else: generator_curves[key] $=$ regret_curve   \nfig, ax $=$ plt.subplots(1, 1, figsize $=$ (4,4))   \nax.set_xlabel(\u2019# of Pareto Points\u2019)   \nax.set_ylabel(\u2019Hypervolume Regret\u2019)   \nax.set_title(\u2019z = (3- exp(x)) $\\star$ (cos(pi \\* y) + 1)\u2019)   \nax.set_yscale( $'\\,\\exists\\,\\mathrm{O}\\,\\mathrm{g}^{\\prime}$ )   \nfor key, curves in generator_curves.items(): print(curves.shape) plot_median_convergence(ax, curves, label $=$ key, percentiles $=$ ((25, 75),))   \nplt.legend()   \n# -\\*- coding: utf-8 -\\*-   \n\"\"\"Multiobjective Linear Bandits ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "Automatically generated by Colab. ", "page_idx": 24}, {"type": "text", "text": "Original file is located at https://colab.corp.google.com/drive/1CD7ek1DV4f3FNzoO7H1rmb0kOkMvx80Z   \n\"\"\"   \nimport dataclasses   \nimport itertools   \nimport math   \nimport os   \nimport re   \nfrom absl import flags   \nimport matplotlib.pyplot as plt   \nimport numpy as np   \n# @title Simple LinUCB implementation { display-mode: \"form\" }   \nimport numpy as np   \nimport pandas as pd   \nimport seaborn as sns ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 24}, {"type": "text", "text": "from google3.file.recordio.python import recordio from google3.learning.vizier import benchmark_v2 from google3.learning.vizier.benchmark_v2 import analysis from google3.learning.vizier.benchmark_v2 import config_pb2 import google3.pyglib.gfile as gfile ", "page_idx": 24}, {"type": "text", "text": "class LinUCB: \"\"\"Simple LinUCB implementation.\"\"\" ", "page_idx": 24}, {"type": "text", "text": "def __init self, dimension: int, max_inst_regret: float $=~2\\cdot0$ , regularizer: float $=~1,0$ , var_noise: float $=~1,0$ , max_parameter_norm: float $\\mathbf{\\Sigma}=\\mathbf{\\Sigma}\\,\\mathbb{1}\\,.\\,0\\,.$ , failure_probabilty: float $=~0\\cdot1$ , assert regularizer $>=~0~.~0$ ", "page_idx": 24}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "", "page_idx": 25}, {"type": "text", "text": "self.dimension $=$ dimension   \nself._regularizer $=$ regularizer   \nself._var_noise $=$ var_noise   \nself._max_parameter_norm $=$ max_parameter_norm   \nself._max_inst_regret $=$ max_inst_regret   \nself._failure_probability $=$ failure_probabilty ", "page_idx": 25}, {"type": "text", "text": "self.reset() ", "page_idx": 25}, {"type": "text", "text": "def reset(self): self._covariance_inv $=$ np.eye(self.dimension) $\\star$ self._regularizer self._reward_scaled_features $=$ np.zeros(self.dimension) self._parameter_estimate $=$ np.zeros(self.dimension) self._num_observations $\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad=\\quad0$ self._last_conf_radius $=$ None $=$ ", "page_idx": 25}, {"type": "text", "text": "self._conf_ellipsoid_width_raw self._conf_ellipsoid_rhs() ", "page_idx": 25}, {"type": "text", "text": "def add_observation(self, action, reward: float, context $=$ None): \"\"\"add an observation (action, reward) to the learner. ", "page_idx": 25}, {"type": "text", "text": "This function updates the covariance matrix and parameter estimate. ", "page_idx": 25}, {"type": "text", "text": "Args: action: action that was taken reward: achieved reward context: context for this observation blamed: whether this algorithm is to be blamed for this observation.   \n\"\"\" ", "page_idx": 25}, {"type": "text", "text": "self._num_observations $_{+=}\\ 1$ ", "page_idx": 25}, {"type": "text", "text": "# Sherman Morrison update of covariance matrix   \ny $=$ np.dot(self._covariance_inv, action)   \nself._covariance_inv $-=$ np.outer(y, y) / (1 + np.inner(action, y))   \n# regression target   \nself._reward_scaled_features $+\\!=$ reward $\\star$ action   \n# parameter estimate   \nself._parameter_estimate $=$ np.dot( self._covariance_inv, self._reward_scaled_features ", "page_idx": 25}, {"type": "text", "text": "self._conf_ellipsoid_width_raw $=$ self._conf_ellipsoid_rhs() ", "page_idx": 25}, {"type": "text", "text": "def ucb(self, actions, confidence_scale $=\\!\\!1\\cdot0$ ): \"\"\"computes the upper-confidence bound for a batch of actions. ", "page_idx": 25}, {"type": "text", "text": "Args: actions: A x d matrix confidence_scale: scaling factor in front of the bonus prescribed by theory ", "page_idx": 25}, {"type": "text", "text": "Returns: upper-confidence bound for each A action, A vector ", "page_idx": 25}, {"type": "text", "text": "\"\"\" ", "page_idx": 26}, {"type": "text", "text": "rewards $=$ np.dot(actions, self._parameter_estimate)   \nvar $=$ np.sum(actions $\\star$ np.dot(actions, self._covariance_inv), axis $_{;=1}$ )   \nbeta $=$ self._conf_ellipsoid_width_raw $\\star$ confidence_scale   \nreturn rewards, beta $\\star$ np.sqrt(var) ", "page_idx": 26}, {"type": "text", "text": "def choose_action(self, actions, confidence_scale $^{=1}$ .0): \"\"\"chooses the action that maximizes the upper confidence bound. ", "page_idx": 26}, {"type": "text", "text": "Args: actions: A x d matrix, possible actions to choose from confidence_scale: scaling factor in front of the bonus prescribed by theory ", "page_idx": 26}, {"type": "text", "text": "Returns: chosen action (d vector) ", "page_idx": 26}, {"type": "text", "text": "\"\"\" ", "page_idx": 26}, {"type": "text", "text": "rewards, conf_b $=$ self.ucb(actions, confidence_scale) action_index $=$ randargmax(rewards $^+$ conf_b) return actions[action_index, :] ", "page_idx": 26}, {"type": "text", "text": "def _conf_ellipsoid_rhs(self): # from Abbassi-Yadkori et al. 2011 beta_t $=$ np.sqrt(self._regularizer) $\\star$ self._max_parameter_norm log_dets $=$ -np.log(self._failure_probability) log_dets $-=$ self.dimension / 2 $\\star$ np.log(self._regularizer) log_dets $-=$ np.linalg.slogdet(self._covariance_inv)[1] / 2 beta_t $+\\!=$ np.sqrt(2 $\\star$ self._var_noise $\\star$ log_dets) ", "page_idx": 26}, {"type": "text", "text": "return beta_t ", "page_idx": 26}, {"type": "text", "text": "def randargmax(b): \"\"\"takes the argmax but randomly picks from the set of maximizers.\"\"\" return np.random.choice(np.flatnonzero( $\\mathrm{~b~}==\\mathrm{~b~}$ .max())) ", "page_idx": 26}, {"type": "text", "text": "def linear_scalarizer(acquisitions, weights): sum $=\\ \\ 0\\ .\\ 0$ for acquisition, weight in zip(acquisitions, weights): sum $+\\!=$ weight $\\star$ acquisition return sum ", "page_idx": 26}, {"type": "text", "text": "", "page_idx": 26}, {"type": "text", "text": "def chebyshev_scalarizer(acquisitions, weights): min $=$ np.inf for acquisition, weight in zip(acquisitions, weights): min $=$ np.minimum((acquisition - reference) $\\star$ weight, min ) return min ", "page_idx": 26}, {"type": "text", "text": "def hypervolume_scalarizer(acquisitions, weights): ", "page_idx": 26}, {"type": "text", "text": "min $=$ np.inf   \nfor acquisition, weight in zip(acquisitions, weights): min $=$ np.minimum((acquisition - reference)/ weight, min )   \nreturn min ", "page_idx": 26}, {"type": "text", "text": "def uniform_weights(): weights $=$ np.random.normal(size $=$ num_metrics) return abs(weights)/np.linalg.norm(weights) ", "page_idx": 26}, {"type": "text", "text": "def boxed_linear_weights(): # Use bounding box. u $=$ np.random.uniform(low $^{=1}$ .0, high $^{=3}$ .0, size $=$ num_metrics) return u / np.linalg.norm(u, ord $\\boldsymbol{\\cdot}$ , keepdims $=$ True) ", "page_idx": 27}, {"type": "text", "text": "def boxed_chebyshev_weights(): lmda $=$ boxed_linear_weights() lmda_prime $=$ 1.0/lmda return lmda_prime/np.linalg.norm(lmda_prime, ord $\\boldsymbol{\\mathbf{\\rho}}=1$ , keepdims $=$ True) ", "page_idx": 27}, {"type": "text", "text": "dim $=~5$   \nnum_metrics $\\r=\\_16$   \nthetas $=$ np.random.normal(size $=$ (num_metrics, dim))   \n# Anti-correlate thetas.   \nthetas[0, : $\\begin{array}{r l}{]}&{{}=}\\end{array}$ -thetas[1, :] $^+$ np.random.normal( siz $\\ominus=$ thetas[1, :].shape, scal $\\Rsh\\infty$ .01   \n)   \nfor i in range(int(num_metrics / 2)): index $=$ int( $\\langle2\\mathrm{~\\boldmath~\\star~}\\dot{\\mathrm{~\\boldmath~\\lambda~}}$ ) thetas[index, : $\\mathrm{~\\rightmoon~}=$ -thetas[index $+\\_1$ , :] $^+$ np.random.normal( size $=$ thetas[index $+\\ \\ 1$ , :].shape, scale $=0$ .01 )   \n# Renormalize to make sure |theta| $\\mathbf{\\Sigma}=\\mathbf{\\Sigma}\\cdot\\mathbb{1}$   \nthetas $=$ thetas / np.linalg.norm(thetas, axi $_{3}\\{=1$ , keepdims $=$ True)   \nreference $\\begin{array}{r l}{=}&{{}-2}\\end{array}$ ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "def run_linear_bandit(thetas, scalarizer, weight_generator, num_rounds $=\\!\\!\\perp0\\,0$ ): algs $=$ [LinUCB(dimension $\\cdot=$ dim) for theta in thetas] ", "page_idx": 27}, {"type": "text", "text": "expected_rewards $=$ np.empty(shape $=$ (num_rounds, num_metrics))   \nactions $=$ np.random.normal(size $=$ (1000, dim))   \nactions $=$ actions / np.linalg.norm(actions, axi ${_{S}}\\!=\\!1$ )[..., np.newaxis]   \nfor t in range(num_rounds):   \nindex $=$ np.random.choice(len(actions))   \naction $=$ actions[index]   \nexpected_reward $=$ np.inner(thetas, action)   \nrewards $=$ expected_reward $^+$ np.random.normal(size $=$ expected_reward.shape)   \nfor alg, reward in zip(algs, rewards): alg.add_observation(action, reward)   \nweights $=$ weight_generator()   \nacquisitions $=$ scalarizer([sum(alg.ucb(actions)) for alg in algs], weights)   \nassert len(acquisitions) $==$ len(actions)   \nindex $=$ randargmax(acquisitions)   \naction $=$ actions[index]   \nexpected_reward $=$ np.inner(thetas, action)   \nrewards $=$ expected_reward $^+$ np.random.normal(size $=$ expected_reward.shape)   \nfor alg, reward in zip(algs, rewards): alg.add_observation(action, reward) ", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "", "page_idx": 27}, {"type": "text", "text": "expected_rewards[t] $=$ expected_reward return actions, expected_rewards ", "page_idx": 27}, {"type": "text", "text": "scalarizations $=$ { \u2019linear-uniform\u2019: (linear_scalarizer, uniform_weights), \u2019linear-boxed\u2019: (linear_scalarizer, boxed_linear_weights), ", "page_idx": 27}, {"type": "text", "text": "\u2019chebyshev-uniform\u2019: (chebyshev_scalarizer, uniform_weights), \u2019chebyshev-boxed\u2019: (chebyshev_scalarizer, boxed_chebyshev_weights), \u2019hypervolume-uniform\u2019: (hypervolume_scalarizer, uniform_weights), \u2019hypervolume-boxed\u2019: (hypervolume_scalarizer, boxed_linear_weights), } ", "page_idx": 28}, {"type": "text", "text": "from vizier.pyvizier import multimetric from vizier.pyvizier.multimetric import xla_pareto pareto_algo $=$ xla_pareto.JaxParetoOptimalAlgorithm() ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "import matplotlib.pyplot as plt ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "num_rounds $=~100$   \nactions, linear_rewards $=$ run_linear_bandit( thetas, scalarizer $=$ hypervolume_scalarizer, weight_generator $=$ uniform_weights   \n)   \nall_values $=$ np.inner(actions, thetas)   \nall_frontier $=$ all_values[pareto_algo.is_pareto_optimal(all_values)]   \nfrontier $=$ linear_rewards[pareto_algo.is_pareto_optimal(linear_rewards)]   \nplt.scatter(all_values[:, 0], all_values[:, 1], color ${\\mathit{\\omega}}={\\mathit{\\check{\\Psi}}}$ grey\u2019)   \nplt.scatter( all_frontier[:, 0], all_frontier[:, 1], color ${\\mathit{\\Phi}}={\\mathcal{I}}$ red\u2019, label $=^{\\prime}$ \u2019Pareto-optimal points\u2019, ${\\it S}\\,{=}\\,3\\,0$ ,   \n)   \nplt.scatter( frontier[:, 0], frontier[:, 1], color ${\\mathit{\\Phi}}={\\mathcal{I}}$ green\u2019, label ${\\mathit{\\Phi}}={\\mathcal{I}}$ Discovered Frontier\u2019, ${\\it S}\\,{=}\\,3\\,0$ ,   \n)   \nplt.xlabel(\u2019y_1\u2019, fontsiz $_{\\ominus=13}$ )   \nplt.ylabel( $'y_{-}2'$ , fontsiz $_{\\ominus=13}$ )   \nplt.title( f\u2019Hypervolume scalarizer optimization at $\\mathrm{T}{=}\\;\\cdot$ {num_rounds} \u2019, fontsiz $_{\\Theta=18}$   \n) ", "page_idx": 28}, {"type": "text", "text": "", "page_idx": 28}, {"type": "text", "text": "plt.legend() ", "page_idx": 28}, {"type": "text", "text": "origin $\\begin{array}{r l}{=}&{{}-2}\\end{array}$ \\* np.ones(shape $=$ num_metrics) ", "page_idx": 28}, {"type": "text", "text": "num_repeats $=~5$ ", "page_idx": 28}, {"type": "text", "text": "fig, ax $=$ plt.subplots(1, 1, figsize $=$ (12, 8)) ", "page_idx": 28}, {"type": "text", "text": "for key, (scalarizer, weight_generator) in scalarizations.items(): hvs $=$ [] for _ in range(num_repeats): , linear_rewards $=$ run_linear_bandit( thetas, scalarizer, weight_generator, num_rounds $=\\!2\\,0\\,0$ ) front $=$ multimetric.ParetoFrontier( points $=$ linear_rewards, origin $=$ origin, cum_hypervolume_base $=$ xla_pareto.jax_cum_hypervolume_origin, ) hvs.append(front.hypervolume(is_cumulative $=$ True)) y $=$ np.array(hvs) ", "page_idx": 28}, {"type": "text", "text": "analysis.plot_median_convergence( ", "page_idx": 29}, {"type": "text", "text": "ax, y, xs $=$ np.array(range(y.shape[1])), label $=$ key, percentiles $\\xi=(\\ ($ (30, 70),) ", "page_idx": 29}, {"type": "text", "text": "ax.legend()   \nax.set_title(f\u2019Cumulative HV from {origin}\u2019, fontsize $_{:=15}$ )   \nax.set_ylabel(\u2019hypervolume (HV)\u2019)   \nax.set_xlabel(\u2019# of Trials\u2019) ", "page_idx": 29}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "The checklist is designed to encourage best practices for responsible machine learning research, addressing issues of reproducibility, transparency, research ethics, and societal impact. Do not remove the checklist: The papers not including the checklist will be desk rejected. The checklist should follow the references and follow the (optional) supplemental material. The checklist does NOT count towards the page limit. ", "page_idx": 30}, {"type": "text", "text": "Please read the checklist guidelines carefully for information on how to answer these questions. For each question in the checklist: ", "page_idx": 30}, {"type": "text", "text": "\u2022 You should answer [Yes] , [No] , or [NA] .   \n\u2022 [NA] means either that the question is Not Applicable for that particular paper or the relevant information is Not Available.   \n\u2022 Please provide a short (1\u20132 sentence) justification right after your answer (even for NA). ", "page_idx": 30}, {"type": "text", "text": "The checklist answers are an integral part of your paper submission. They are visible to the reviewers, area chairs, senior area chairs, and ethics reviewers. You will be asked to also include it (after eventual revisions) with the final version of your paper, and its final version will be published with the paper. ", "page_idx": 30}, {"type": "text", "text": "The reviewers of your paper will be asked to use the checklist as one of the factors in their evaluation. While \"[Yes] \" is generally preferable to \"[No] \", it is perfectly acceptable to answer \"[No] \" provided a proper justification is given (e.g., \"error bars are not reported because it would be too computationally expensive\" or \"we were unable to find the license for the dataset we used\"). In general, answering \"[No] \" or \"[NA] \" is not grounds for rejection. While the questions are phrased in a binary way, we acknowledge that the true answer is often more nuanced, so please just use your best judgment and write a justification to elaborate. All supporting evidence can appear either in the main paper or the supplemental material, provided in appendix. If you answer [Yes] to a question, in the justification please point to the section(s) where related material for the question can be found. ", "page_idx": 30}, {"type": "text", "text": "IMPORTANT, please: ", "page_idx": 30}, {"type": "text", "text": "\u2022 Delete this instruction block, but keep the section heading \u201cNeurIPS paper checklist\", \u2022 Keep the checklist subsection headings, questions/answers and guidelines below. \u2022 Do not modify the questions and only use the provided macros for your answers. ", "page_idx": 30}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 30}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Justification: Abstract clearly state claims and introduction has a list of main contributions, both theoretical and experimental. ", "page_idx": 30}, {"type": "text", "text": "Guidelines: ", "page_idx": 30}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper.   \n\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers.   \n\u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings.   \n\u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 30}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 30}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [Yes] ", "page_idx": 30}, {"type": "text", "text": "Justification: In our introduction, we provide limitations of works given in the beyond linear scalarization and hypervolume regret subsections. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 31}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: All the theorems, formulas, and proofs are given in the paper or appendix and are numbered and cross-referenced. All informal proofs have a formal complement and all assumptions are clearly stated. ", "page_idx": 31}, {"type": "text", "text": "Guidelines: ", "page_idx": 31}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material.   \n\u2022 Theorems and Lemmas that the proof relies upon should be properly referenced. ", "page_idx": 31}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 31}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 31}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 31}, {"type": "text", "text": "Justification: The hypervolume scalarization is easy to code up and try on a wide variety of benchmarks. All the code is released and all data is generated synthetic or via open-sourced benchmarks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 32}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 32}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "Justification: All the code is released and all data is generated synthetic or via open-sourced benchmarks. ", "page_idx": 32}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 32}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code. \u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. \u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). \u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. \u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. ", "page_idx": 32}, {"type": "text", "text": "\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 33}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: Yes, all experimental details are provided in the core of the paper or in the appendix/code. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 33}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 33}, {"type": "text", "text": "Justification: Yes error bars are provided and we assume the standard reporting of 30-70 percentile for error bars over independent repeats, as stated. ", "page_idx": 33}, {"type": "text", "text": "Guidelines: ", "page_idx": 33}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 33}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 33}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 33}, {"type": "text", "text": "Answer: [No] ", "page_idx": 33}, {"type": "text", "text": "Justification: Our paper do not compare resource usage, rather it improves in Trial efficiency.   \nFurthermore, the use of different scalarizations does not affect resource usage. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 34}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 34}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 34}, {"type": "text", "text": "Justification: Research is mainly theoretical and conforms with code of ethics. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 34}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 34}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 34}, {"type": "text", "text": "Justification: Our research is mainly theoretical and improves optimization pipelines on synthetic data. ", "page_idx": 34}, {"type": "text", "text": "Guidelines: ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology.   \n\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 34}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 34}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our research is mainly theoretical and improves optimization pipelines on synthetic data. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 35}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 35}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 35}, {"type": "text", "text": "Justification: Our research is mainly theoretical and all previous usages are cited. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 35}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 35}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 35}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 35}, {"type": "text", "text": "Justification: No new assets are released. ", "page_idx": 35}, {"type": "text", "text": "Guidelines: ", "page_idx": 35}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets.   \n\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used. ", "page_idx": 35}, {"type": "text", "text": "\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 36}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 36}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 36}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 36}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 36}, {"type": "text", "text": "Justification: The paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 36}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 36}]