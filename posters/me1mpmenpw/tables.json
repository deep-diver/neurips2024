[{"figure_path": "me1MpmENpw/tables/tables_8_1.jpg", "caption": "Table 1: Empirical results on Shapes, averaged over five randomly initialized training runs.", "description": "This table presents the empirical results obtained from experiments conducted on the Shapes dataset.  Five different training runs were initialized randomly, and the results are averaged across these runs.  The table shows the number of unique messages generated, the discrimination accuracy achieved (higher is better), the topographic similarity (TopSim) score (higher indicates more compositionality), and the message variance (lower is better, indicating more semantic consistency).  The results are compared for both the reconstruction and discrimination tasks.  A random baseline is also included (Rand) for comparison, showing the message variance for randomly generated messages to the same number of unique messages as the trained models.", "section": "7 Experiments"}, {"figure_path": "me1MpmENpw/tables/tables_8_2.jpg", "caption": "Table 2: Empirical results on MNIST, averaged over three randomly initialized training runs.", "description": "This table presents the empirical results on the MNIST dataset.  It shows the performance of three different emergent communication setups (Reconstruction, Discrimination, and Supervised Discrimination) across multiple metrics.  These metrics include the number of unique messages used, discrimination accuracy, topographic similarity (TopSim), and message variance. The results are averaged over three separate training runs, each initialized randomly, and error bars (standard deviation) are provided to indicate variability.  The \"Trained\" column shows the results for models trained on the full dataset, whereas the \"Rand\" column represents a baseline established by randomizing message assignment while keeping the number of inputs per message constant.", "section": "7 Experiments"}, {"figure_path": "me1MpmENpw/tables/tables_29_1.jpg", "caption": "Table 1: Empirical results on Shapes, averaged over five randomly initialized training runs.", "description": "This table presents the empirical results obtained from experiments conducted on the Shapes dataset.  Five different training runs were initialized randomly, and the results were averaged.  The table shows the number of unique messages generated, the discrimination accuracy (higher is better), the TopSim score (a measure of compositionality, higher is better), and the message variance (lower is better, indicating more semantic consistency).  Results are shown for both the reconstruction and discrimination tasks, providing a comparison between the two common objective functions used in emergent communication research.", "section": "7 Experiments"}, {"figure_path": "me1MpmENpw/tables/tables_30_1.jpg", "caption": "Table 3: Empirical results with compositionality measures from literature.", "description": "This table presents the empirical results obtained using various compositionality measures (TopSim, BosDis, PosDis, and S-PosDis) alongside discrimination accuracy and message variance for both reconstruction and discrimination game settings.  The results are averaged over five (Shapes) or three (MNIST) independent training runs. The standard deviations are included.  It aims to show the relationship between different compositionality measures, performance on the discrimination task, and the semantic consistency captured by message variance.", "section": "E.1 Full results: Compositionality, semantic consistency and game performance"}, {"figure_path": "me1MpmENpw/tables/tables_31_1.jpg", "caption": "Table 4: Correlation Matrices for All Data, Reconstruction, and Discrimination Groups", "description": "This table presents the correlation matrices for six different metrics: TopSim, BosDis, PosDis, S-PosDis, Accuracy, and Msg Variance.  The correlations are calculated for three different groups of data: all data, reconstruction data only, and discrimination data only. This allows for an analysis of how the relationships between these metrics change depending on the experimental setup (reconstruction vs. discrimination).  High positive correlations suggest that two metrics tend to move together, whereas high negative correlations indicate an inverse relationship.", "section": "E.1 Full results: Compositionality, semantic consistency and game performance"}, {"figure_path": "me1MpmENpw/tables/tables_31_2.jpg", "caption": "Table 4: Correlation Matrices for All Data, Reconstruction, and Discrimination Groups", "description": "This table presents the correlation matrices for the compositionality and semantic consistency measures against accuracy and message variance.  The correlations are shown for three different sets of results: all data, reconstruction results only, and discrimination results only. The purpose is to investigate the relationships between these metrics and understand how these relationships differ across the two primary experimental setups.", "section": "E.1 Full results: Compositionality, semantic consistency and game performance"}, {"figure_path": "me1MpmENpw/tables/tables_31_3.jpg", "caption": "Table 4: Correlation Matrices for All Data, Reconstruction, and Discrimination Groups", "description": "This table presents correlation matrices for different metrics calculated from experimental results.  The correlations are shown for the entire dataset, and also separately for reconstruction and discrimination game results.  Metrics include TopSim (topographic similarity), BosDis (bag-of-symbols disentanglement), PosDis (positional disentanglement), S-PosDis (speaker-centered topographic similarity), accuracy, and message variance.  The table helps to understand the relationships between these different measures and how they relate to the different experimental conditions.", "section": "E.1 Full results: Compositionality, semantic consistency and game performance"}, {"figure_path": "me1MpmENpw/tables/tables_31_4.jpg", "caption": "Table 5: Purity measures compared with random baselines.", "description": "The table presents the purity results for three different purity measures (Purity-Max, Purity-Color, and Purity-Shape) for both reconstruction and discrimination game settings, along with their corresponding random baselines. Purity measures how well the messages convey information about specific attributes (color and shape). Higher purity values indicate that the messages contain more semantic information for the corresponding attribute.", "section": "7.1 Semantic consistency, compositionality and task performance"}, {"figure_path": "me1MpmENpw/tables/tables_32_1.jpg", "caption": "Table 6: Empirical results on Shapes, averaged over five randomly initialized training runs.", "description": "This table presents empirical results obtained from experiments conducted on the Shapes dataset.  Five different training runs were initialized randomly, and the results are averaged across those runs.  The table shows the number of unique messages used, the discrimination accuracy (a measure of performance in the discrimination task), the topographic similarity (TopSim, a measure of compositionality), and the message variance (a measure of semantic consistency).  Reconstruction and discrimination EC setups are compared, showing the performance metrics for each.", "section": "7 Experiments"}, {"figure_path": "me1MpmENpw/tables/tables_32_2.jpg", "caption": "Table 7: Cluster Variance on MNIST.", "description": "This table presents the results of the cluster variance experiment on the MNIST dataset.  It shows the trained cluster variance, random cluster variance, and the improvement achieved by the trained models over the random baseline for three different experimental setups: Reconstruction, Discrimination, and Supervised discrimination.  The lower the cluster variance, the more spatially meaningful the resulting messages.  The improvement percentage indicates how much better the trained model performs compared to a random assignment of messages.", "section": "7 Experiments"}]