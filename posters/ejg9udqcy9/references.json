{"references": [{"fullname_first_author": "L. Breiman", "paper_title": "Bagging predictors", "publication_date": "1996-01-01", "reason": "This paper introduces bagging, a foundational ensemble method widely used in machine learning, which is directly related to the concept of majority voting explored in the current paper."}, {"fullname_first_author": "Y. Freund and R. E. Schapire", "paper_title": "A short introduction to boosting", "publication_date": "1999-01-01", "reason": "This paper introduces boosting, another crucial ensemble method that improves model performance by combining multiple weak learners, a concept directly relevant to the paper's exploration of diverse experts."}, {"fullname_first_author": "S. M. Kakade and J. Langford", "paper_title": "Approximately optimal approximate reinforcement learning", "publication_date": "2002-01-01", "reason": "This paper provides theoretical foundations for approximate reinforcement learning, relevant to the study of transcendence as the paper explores the possibility of surpassing expert performance in a simplified setting."}, {"fullname_first_author": "V. Mnih et al.", "paper_title": "Human-level control through deep reinforcement learning", "publication_date": "2015-02-26", "reason": "This highly influential paper demonstrates human-level performance in complex games using deep reinforcement learning, providing a benchmark for evaluating the capabilities of AI models and directly inspiring the chess-playing model in the current paper."}, {"fullname_first_author": "D. Silver et al.", "paper_title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm", "publication_date": "2017-12-01", "reason": "This paper showcases the power of self-play reinforcement learning in achieving superhuman performance in complex games like chess and shogi, directly relevant to the current paper's investigation of transcendence through self-play training."}]}