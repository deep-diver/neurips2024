[{"type": "text", "text": "LM-HT SNN: Enhancing the Performance of SNN to ANN Counterpart through Learnable Multi-hierarchical Threshold Model ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Zecheng Hao1, Xinyu $\\mathbf{S}\\mathbf{h}\\mathbf{i}^{1,2}$ , Yujia $\\mathbf{Liu}^{1}$ , Zhaofei $\\mathbf{Y}\\mathbf{u}^{1,2*}\\pmb{\\&}$ Tiejun Huang1,2 1 School of Computer Science, Peking University 2 Institute for Artificial Intelligence, Peking University ", "page_idx": 0}, {"type": "text", "text": "Abstract ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Compared to traditional Artificial Neural Network (ANN), Spiking Neural Network (SNN) has garnered widespread academic interest for its intrinsic ability to transmit information in a more energy-efficient manner. However, despite previous efforts to optimize the learning algorithm of SNNs through various methods, SNNs still lag behind ANNs in terms of performance. The recently proposed multithreshold model provides more possibilities for further enhancing the learning capability of SNNs. In this paper, we rigorously analyze the relationship among the multi-threshold model, vanilla spiking model and quantized ANNs from a mathematical perspective, then propose a novel LM-HT model, which is an equidistant multi-threshold model that can dynamically regulate the global input current and membrane potential leakage on the time dimension. The LM-HT model can also be transformed into a vanilla single threshold model through reparameterization, thereby achieving more flexible hardware deployment. In addition, we note that the LM-HT model can seamlessly integrate with ANN-SNN Conversion framework under special initialization. This novel hybrid learning framework can effectively improve the relatively poor performance of converted SNNs under low time latency. Extensive experimental results have demonstrated that our model can outperform previous state-of-the-art works on various types of datasets, which promote SNNs to achieve a brand-new level of performance comparable to quantized ANNs. Code is available at https://github.com/hzc1208/LMHT_SNN. ", "page_idx": 0}, {"type": "text", "text": "1 Introduction ", "text_level": 1, "page_idx": 0}, {"type": "text", "text": "Recognized as the third generation of artificial neural networks [33], Spiking Neural Network (SNN) is increasingly receiving significant academic attention due to its enormous potential in biological plausibility and high energy efficiency. As the information transmission between the pre-synaptic and post-synaptic layers relies on the discrete spike signal, which will be only emitted when the membrane potential of the corresponding neuron exceeds the firing threshold, SNNs have a unique event-driven property compared to conventional Artificial Neural Network (ANN). By utilizing this property, researchers have pointed out that SNNs can achieve significant advantages in terms of energy consumption on neuromorphic hardware [35, 5, 37]. Currently, SNNs have further fulfliled a role in multiple application scenarios including object detection [22], natural language processing [32], and 3D recognition [24]. ", "page_idx": 0}, {"type": "text", "text": "Spatial-Temporal back-propagation (STBP) with surrogate gradients is currently the most mainstream supervised learning algorithm suitable for SNNs. Although previous works have attempted to further enhance the learning ability of SNNs by delving into various optimization strategies, including gradient adjustment [29, 8, 14] and structural improvement [54, 51, 44, 50], there is still a certain performance gap between ANNs and SNNs. ", "page_idx": 0}, {"type": "text", "text": "", "page_idx": 1}, {"type": "text", "text": "Recently, the STBP learning algorithm based on multi-threshold models [41, 42] is considered as another potential way to improve the performance of SNNs. In this scenario, multiple levels of the firing threshold enable SNNs to transmit richer information at each time-step. Unfortunately, we think that current related works have not accurately recognized the mathematical essence of multi-threshold models as well as their relationship with ANNs and SNNs. In this paper, we innovatively propose a learnable multi-hierarchical and equidistant threshold model based on global input information, which is called LM-HT model. On the one hand, we note that our LM-HT model can equivalently represent the information of the vanilla model over multiple consecutive time-steps within a single step. Furthermore, we can convert the LM-HT model into a vanilla single threshold model through a layer-by-layer reparameterization scheme. On the other hand, the STBP method based on the LM-HT model can be transformed into the training modes of the vanilla STBP and quantized ANNs under different parameter initialization conditions, respectively. The main contribution of this work has been summarized as follows: ", "page_idx": 1}, {"type": "text", "text": "\u2022 We point out that the essence of the equidistant multi-threshold model is to simulate the spike firing situation of the vanilla spiking model within specific time windows. Specially, when the input current follows a completely uniform distribution on the time dimension, its spike firing rate is mathematically equivalent to the activation output of quantized ANNs. \u2022 We propose an advanced LM-HT model, which can enhance the performance of SNNs to the level of ANNs and be transformed into a vanilla single threshold model losslessly during the inference stage. By adopting different parameter initialization schemes, the LM-HT model can further establish a bridge between the vanilla STBP and quantized ANNs training. \u2022 We further design a brand-new hybrid training framework based on the LM-HT model, which is enable to effectively improve the performance degradation problem of traditional ANN-SNN Conversion methods regardless of the time latency degree involved. \u2022 Experimental results have indicated that our model can fulfill state-of-the-art learning performance for various types of datasets. For instance, we achieve the top-1 accuracy of $81.76\\%$ for CIFAR-100, ResNet-19 within merely 2 time-steps. ", "page_idx": 1}, {"type": "text", "text": "2 Related Works ", "text_level": 1, "page_idx": 1}, {"type": "text", "text": "STBP supervised training. STBP is the most prevailing recurrent-mode learning algorithm in the field of SNN direct training. Wu et al. [47] tackled the non-differentiable problem existed in the spike firing process by utilizing surrogate gradients and achieved gradient smoothing calculation between layers. Deng et al. [8] and Guo et al. [14] respectively proposed brand-new target loss functions by analyzing the temporal distribution of the spike sequence and membrane potential. Furthermore, various temporal-dependent batch normalization layers [54, 10, 15] and advanced spiking neuron models [51, 44] have been pointed out, which enhances the capability and stability of SNN learning. The researchers also designed a variety of residual blocks [11, 20] and Transformer structures [55, 49] suitable for SNNs, promoting the development of STBP training towards the domains of deep and large-scale models. In addition, some variant and extended learning methods based on STBP have also received widespread attention. Temporal Coding [36] and Time-to-First-Spike (TTFS) [21] algorithm conduct one-time back-propagation based on the specific firing moment. Meng et al. [34] introduced the idea of online learning into vanilla STBP algorithm, which significantly saves training memory overhead by eliminating the gradient chains between different time-steps. Fang et al. [12] proposed a spiking neuron model that supports parallel computing in forward propagation, which also provides inspiration for this work. ", "page_idx": 1}, {"type": "text", "text": "ANN-SNN Conversion. ANN-SNN Conversion is another widely used method for obtaining highperformance SNNs with limited computational resources, which establishes a mathematical mapping relationship between activation layers and the Integrate-and-Fire (IF) models. Cao et al. [3] first proposed a two-step conversion learning framework, which replaces the activation functions of pre-trained ANNs with the IF models layer by layer. On this basis, Han et al. [16] and Li et al. [28] classified and summarized the relevant errors existed in the conversion process. Deng et al. [7] and Bu et al. [2] further reduced the conversion errors through deriving the optimal values for the bias term and initial membrane potential. For the critical conversion error caused by uneven spike firing sequences, multiple optimization strategies have been proposed successively, including memorizing the residual membrane potential [17], firing negative spikes [43, 25], calibrating offset spikes [18] and hybrid finetuning training [45]. Currently, ANN-SNN Conversion has been further applied to the training of large-scale visual and language models [46, 32]. ", "page_idx": 1}, {"type": "text", "text": "", "page_idx": 2}, {"type": "text", "text": "Spiking neural models with multi-threshold. The current proposed multi-threshold models can be generally divided into two categories: one emits signed spikes [22, 52, 43], while the other emits multi-bit spikes [27, 41, 42, 24]. However, these works generally consider using multi-threshold models to reduce ANN-SNN Conversion errors and lack further theoretical analysis. In this paper, we have the foresight to recognize the mathematical equivalence relationship between equidistant multi-threshold models and quantized ANNs under the conditions of using the soft-reset mechanism and uniform input current, achieving the current optimal performance in the domain of STBP learning. ", "page_idx": 2}, {"type": "text", "text": "3 Preliminaries ", "text_level": 1, "page_idx": 2}, {"type": "text", "text": "The spiking neuron models for SNNs. The Leaky-Integrate-and-Fire (LIF) model is one of the most commonly used models in the current SNN community. The following equations have depicted the dynamic procedure of the LIF model in a discrete form: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m_{L I F}^{l}(t)=\\lambda_{L I F}^{l}v_{L I F}^{l}(t-1)+I^{l}(t),~I^{l}(t)=W^{l}s_{L I F}^{l-1}(t)\\theta^{l-1}.}\\\\ &{v_{L I F}^{l}(t)=m_{L I F}^{l}(t)-s_{L I F}^{l}(t)\\theta^{l},~s_{L I F}^{l}(t)=\\left\\{1,~\\begin{array}{l l}{m_{L I F}^{l}(t)\\geq\\theta^{l}}\\\\ {0,}&{\\mathrm{otherwise}}\\end{array}\\right..}\\end{array}\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Eq.(1) describes the charging process: $\\forall t\\in[1,T]$ , $m_{L I F}^{l}(t)$ and ${\\pmb v}_{L I F}^{l}(t-1)$ respectively represent the membrane potential before and after the charging at the $t$ -th time-step. ${\\pmb I}^{l}(t)$ denotes the input current and $\\lambda_{L I F}^{l}$ characterizes the leakage degree of the membrane potential. When $\\lambda_{L I F}^{l}=1$ , the LIF model will degenerate into a more specialized model called the IF model. Eq.(2) depicts the reset and firing process: $s_{L I F}^{l}(t)$ indicates the spike emitting situation and $\\theta^{l}$ is the firing threshold. Here we adopt the soft-reset mechanism, which means that the reset amplitude of the membrane potential is equal to the value of $\\theta^{l}$ . ", "page_idx": 2}, {"type": "text", "text": "STBP learning algorithm for SNNs. The gradient calculation mode of STBP is inspired by the back-propagation Through Time (BPTT) algorithm in Recurrent Neural Network (RNN), which will propagate along the spatial and temporal dimensions of SNNs simultaneously. Following equations have described the specific propagation process: ", "page_idx": 2}, {"type": "equation", "text": "$$\n\\frac{\\partial\\mathcal{L}}{\\partial m_{L L F}^{l}(t-1)}=\\frac{\\partial\\mathcal{L}}{\\partial s_{L L F}^{l}(t-1)}\\frac{\\partial s_{L L F}^{l}(t-1)}{\\partial m_{L L F}^{l}(t-1)}+\\frac{\\partial\\mathcal{L}}{\\partial m_{L L F}^{l}(t)}\\frac{\\partial m_{L L F}^{l}(t)}{\\partial v_{L L F}^{l}(t-1)}\\frac{\\partial v_{L L F}^{l}(t-1)}{\\partial m_{L I F}^{l}(t-1)},\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Here $\\mathcal{L}$ denotes the target loss function. From Eq.(2) one can note that the mathematical relationship between $s_{L I F}^{l}(t)$ and $\\bar{m}_{L I F}^{l}(t)$ is equivalent to $\\begin{array}{r}{\\dot{\\pmb{s}}_{L I F}^{l}(t)\\,=\\,H(\\pmb{m}_{L I F}^{l}(t)\\,-\\,\\theta^{l})}\\end{array}$ , where $H(\\cdot)$ denotes Heaviside step function. As Heaviside function is non-differentiable, researchers consider using a surrogate function, which is approximate to Heaviside function but differentiable, to handle the term $\\frac{\\bar{\\partial^{\\mathbf{\\bar{s}}}}_{L I F}^{l}(t)}{\\partial\\pmb{m}_{L I F}^{l}(t)}$ in the back-propagation chain. For example,\u2202\u2202smLlLIIFF((tt)) $\\begin{array}{r}{\\frac{\\partial s_{L I F}^{l}(t)}{\\partial\\pmb{m}_{L I F}^{l}(t)}=\\mathrm{sign}\\left(\\left|\\pmb{m}_{L I F}^{l}(t)-\\theta^{l}\\right|\\leq\\frac{\\theta^{l}}{2}\\right)}\\end{array}$ describes the well-known rectangular surrogate function. ", "page_idx": 2}, {"type": "text", "text": "Quantized ANNs. The quantized ANN model is a widely used structure in the field of ANN-SNN Conversion. Compared to traditional ANNs, quantized ANNs usually use the following QuantizationClip-Floor-Shift (QCFS) function [28, 2] as their activation function: ", "page_idx": 2}, {"type": "equation", "text": "$$\n{\\pmb a}^{l}=\\frac{\\vartheta^{l}}{T_{q}}\\mathrm{clip}\\left(\\left\\lfloor\\frac{W^{l}{\\pmb a}^{l-1}T_{q}+\\varphi^{l}}{\\vartheta^{l}}\\right\\rfloor,0,T_{q}\\right).\n$$", "text_format": "latex", "page_idx": 2}, {"type": "text", "text": "Here $\\pmb{a}^{l}$ and $\\varphi^{l}$ represent the activation output and shift factor, while $T_{q}$ and $\\vartheta^{l}$ denote the quantization level and learnable scaling factor. If we set $\\begin{array}{r}{T_{q}=T,\\vartheta^{l}=\\theta^{l},\\pmb{a}^{l}=\\sum_{t=1}^{T}s_{I F}^{l}(t)\\theta^{l}/T,\\pmb{v}_{I F}^{l}(0)=\\varphi^{l},}\\end{array}$ one can find that the so-called QCFS function actually simulate the a verage spike firing rate of the IF smooftd-rele s(ewt em seect $\\begin{array}{r}{\\pmb{r}_{I F}^{l}(T_{q})=\\sum_{t=1}^{T_{q}}\\pmb{s}_{I F}^{l}(t)\\theta^{l}/T_{q})}\\end{array}$ sutsn dthera tt hSeN cNosn dhiativoe nt hoef  pthoet euntniiaflo trom  minaipnutta icnu rtrheen st aamnde level of performance as ANNs under specific conditions. ", "page_idx": 2}, {"type": "image", "img_path": "IlIDNMvwmX/tmp/95fcf96331584e4adfcd688ac304c709dc9e3d6034b23d69a66247cad9fd0e64.jpg", "img_caption": [], "img_footnote": [], "page_idx": 3}, {"type": "text", "text": "Figure 1: Forward and backward propagation of the M-HT model. (a)-(c): mathematical relationship between the M-HT model and vanilla IF model. (d)-(e): surrogate gradient calculation for the M-HT model. ", "page_idx": 3}, {"type": "text", "text": "4 Methodology ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "4.1 The Multi-hierarchical Threshold (M-HT) Model ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "In this section, we first introduce the M-HT model, which has equidistant multi-level thresholds and will select the threshold closest to its current membrane potential at each time-step to achieve the process of firing spikes and resetting potential. Eqs. (5)-(6) describe the dynamic equations of the M-HT model. ", "page_idx": 3}, {"type": "equation", "text": "$$\n\\begin{array}{r l}&{m^{l}(t)=\\lambda^{l}v^{l}(t-1)+I^{l}(t),\\;I^{l}(t)=W^{l}s^{l-1}(t)\\theta^{l-1}.}\\\\ &{v^{l}(t)=m^{l}(t)-s^{l}(t)\\theta^{l},\\;s^{l}(t)=\\left\\{\\begin{array}{l r}{L,}&{m^{l}(t)\\geq L\\theta^{l}}\\\\ {k,}&{k\\theta^{l}\\leq m^{l}(t)<(k+1)\\theta^{l},k=1,...,L-1\\;.}\\\\ {0,}&{\\mathrm{otherwise}}\\end{array}\\right.}\\end{array}\n$$", "text_format": "latex", "page_idx": 3}, {"type": "text", "text": "Here $L$ denotes the number of level for the firing threshold. Regarding the surrogate gradient calculation of the M-HT model, similar to the vanilla spiking models, we propose sml((tt)) sign $\\begin{array}{r}{(\\frac{1}{2}\\theta^{l}\\leq m^{l}(t)\\leq(L+\\frac{1}{2})\\theta^{l})}\\end{array}$ , which covers a wider range of the membrane potential, as shown in Fig.1(d)-(e). As the M-HT model has $L$ different firing options at each time-step, we can consider the information transmitted by the M-HT model within one time-step as an information integration of the vanilla model for $L$ time-steps. Therefore, we attempt to bridge a mathematical equivalent relationship between the M-HT and IF model: ", "page_idx": 3}, {"type": "text", "text": "Lemma 4.1. $\\forall t\\ \\in\\ [1,T]$ , if $\\pmb{v}^{l}(t\\mathrm{~-~}1)\\mathrm{~\\pmb~\\in~}\\left[0,\\theta^{l}\\right)$ , the effect of inputting current ${\\pmb I}^{l}(t)$ into a M-HT model with $L$ -level threshold at the $t$ -th time-step, is equivalent to continuously inputting uniform current $I^{l}(t)/L$ for $L$ time-steps into a $I F$ model with ${\\pmb v}_{I F}^{l}(0)\\,=\\,{\\pmb v}^{l}(t\\,-\\,1)$ , i.e. $\\begin{array}{r}{s^{l}(t)=c l i p\\left(\\left\\lfloor\\frac{v^{l}(t-1)+I^{l}(t)}{\\theta^{l}}\\right\\rfloor,0,L\\right)=\\sum_{j=1}^{L}s_{I F}^{l}(j).}\\end{array}$ ", "page_idx": 3}, {"type": "text", "text": "Lemma 4.1 indicates that the M-HT model under a single time-step can be used to simulate the total number of spikes emitted by the IF model under uniform input current within $L$ consecutive time-steps. In addition, note that $s^{l}(t)$ in Lemma 4.1 can also be calculated through clip $(\\lfloor\\cdot\\rfloor,\\cdot,\\cdot)$ , which is equivalent to the QCFS function mentioned before in quantized ANNs. The above conclusion preliminarily demonstrates that the M-HT model can achieve the same-level performance as pretrained ANNs with $L$ -level quantization under single-step condition. ", "page_idx": 3}, {"type": "text", "text": "4.2 The Representation Ability of the M-HT Model on Multiple Time-steps ", "text_level": 1, "page_idx": 3}, {"type": "text", "text": "Based on Lemma 4.1, we further consider the information representation of the M-HT model on multiple time-steps: ", "page_idx": 3}, {"type": "text", "text": "Theorem 4.2. When $\\lambda^{l}\\,=\\,1,{\\pmb v}^{l}(0)\\,\\in\\,[0,\\theta^{l}),$ , for a M-HT model with L-level threshold, after $T$ time-steps, we will derive the following conclusions: ", "page_idx": 3}, {"type": "image", "img_path": "IlIDNMvwmX/tmp/223dfb9de6050a57e266ae590c57cbe68cf3df8419101afe5b60f3c5646c1ec8.jpg", "img_caption": ["Figure 2: The STBP learning framework based on the LM-HT model. (a): vanilla STBP training. (b): STBP training with the LM-HT model. (c): direct training of quantized ANNs. (d): hybrid training with the LM-HT model, here R-I Curve denotes Rate-Input Curve. "], "img_footnote": [], "page_idx": 4}, {"type": "text", "text": "(i) If we further assume $\\forall t\\ \\in\\ [1,T],{\\cal I}^{l}(t)\\ \\in\\ [0,L\\theta^{l}),$ , we will have: $\\forall t\\;\\in\\;[1,T],s^{l}(t)\\;=$ $\\begin{array}{r}{\\sum_{j=L(t-1)+1}^{L t}s_{I F}^{l}(j),v^{l}(t)=v_{I F}^{l}(L t),\\sum_{t=1}^{T}s^{l}(t)=\\sum_{j=1}^{L T}s_{I F}^{l}(j).}\\end{array}$ .   \n(ii) If we further assume $\\begin{array}{r l}{\\pmb{I}^{l}(1)}&{{}=}\\end{array}$ ... $\\begin{array}{r l r}{.}&{{}=}&{I^{l}(T)}\\end{array}$ , we will have: $\\begin{array}{r l}{\\sum_{t=1}^{T}s^{l}(t)}&{{}=}\\end{array}$ $\\begin{array}{r}{c l i p\\left(\\left\\lfloor\\frac{\\boldsymbol{v}^{l}(0)+\\sum_{t=1}^{T}\\boldsymbol{I}^{l}(t)}{\\theta^{l}}\\right\\rfloor,0,L T\\right)}\\end{array}$ . ", "page_idx": 4}, {"type": "text", "text": "Here the $I F$ model has uniform input currents $\\pmb{I}^{l}(1)/L,...,\\pmb{I}^{l}(T)/L$ respectively within every $L$ steps and satisfies $\\pmb{v}_{I F}^{l}(0)=\\pmb{v}^{l}(0)$ . ", "page_idx": 4}, {"type": "text", "text": "The proofs of Lemma 4.1 and Theorem 4.2 have been provided in the Appendix. From Theorem 4.2(i) and Fig.1(a)-(c), one can find that the M-HT model is actually equivalent to dividing the spike firing sequence of the IF model on consecutive $L T$ steps into $T\\,L\\cdot$ -step time windows. Combining with the soft-reset mechanism, the M-HT model actually focuses on a specific time window of the vanilla IF model at each time-step and maintains an equal membrane potential with the IF model at the end of each time window $\\hat{(i.e.~}\\forall t\\in[1,T],v^{l}(t)\\dot{=}v_{I F}^{l}(L t))$ . The M-HT model follows the assumption of uniform input current within each window, while maintaining the basic calculation properties of spiking neurons between different windows. When the input current follows a complete uniform distribution, according to Theorem 4.2(ii), the M-HT model can further simulate the output of an ANN with $L T$ -level quantization. ", "page_idx": 4}, {"type": "text", "text": "4.3 The Learnable Multi-hierarchical Threshold (LM-HT) Model ", "text_level": 1, "page_idx": 4}, {"type": "text", "text": "The uniform and uneven firing regions in the M-HT model. For a specific spike firing rate, the M-HT model can often provide multiple spike firing sequences. For example, [1, 1], [0, 2], [2, 0] can all represent the situation where 2 spikes are emitted within 2 time-steps, while only [1, 1] can be viewed as a case of uniform firing situation. However, even when the input current is uniformly distributed, as the sum of spikes that cannot be divided by $L$ in $[0,L T]$ is unable to be represented by a uniform spike output sequence, there are still uneven firing situations: ", "page_idx": 4}, {"type": "text", "text": "Corollary 4.3. If $\\lambda^{l}\\,=\\,1,{\\pmb v}^{l}(0)\\,=\\,0$ and $\\pmb{I}^{l}(1)\\,=\\,...\\,=\\,\\pmb{I}^{l}(T),$ , for a M-HT model with $L$ -level threshold, $\\pmb{s}^{l}(1)=...=\\pmb{s}^{l}(T)$ is only satisfied when $\\pmb{I}^{l}(1)\\in[k\\theta^{l},k\\theta^{l}+\\theta^{l}/T),\\forall k=0,...,L-1$ or $\\pmb{I}^{l}(1)\\in(-\\infty,0)\\cup[L\\theta^{l},+\\infty)$ . ", "page_idx": 4}, {"type": "text", "text": "The proof is provided in the Appendix. From Corollary 4.3, we can divide the input current into uniform and uneven firing regions according to the corresponding intervals, as shown in Fig.1(a)-(b). Note that the uneven spike sequences emitted by the $l_{\\cdot}$ -th layer may further cause the input current of the $l+1$ -th layer to no longer follow the uniform distribution. That is to say, as the number of layers increases, the uneven firing cases will tend to increase gradually without introducing extra regulation. ", "page_idx": 4}, {"type": "text", "text": "Learnable Temporal-Global Information Matrix and leaky parameters. Enhancing the uniform firing pattern can promote SNNs to achieve superior performance similar to quantized ANNs, while uneven spike sequences retain more temporal and biological characteristics. Therefore, how to comprehensively utilize these two spike firing patterns becomes a critical problem. To address this issue, we first introduce the concept of Temporal-Global Information Matrix (T-GIM): ", "page_idx": 4}, {"type": "image", "img_path": "IlIDNMvwmX/tmp/378527cbe19aa8fd804cbb2c5b81aa6830613b098444fe5b6e1469cea889901b.jpg", "img_caption": ["Figure 3: Reparameterization procedure of the LM-HT model. "], "img_footnote": [], "page_idx": 5}, {"type": "text", "text": "", "page_idx": 5}, {"type": "equation", "text": "$$\n\\forall t\\in[1,T],I^{l}(t)=\\sum_{j=1}^{T}\\omega_{t j}^{l}W^{l}s^{l-1}(j)\\theta^{l-1}.\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "Here $\\omega_{t j}^{l}$ is the element at row $t$ and column $j$ of the T-GIM $\\Omega^{l}$ , $\\Omega^{l}\\in\\mathbb{R}^{T\\times T}$ . As shown in Eq.(7) and Fig.2(b), this brand-new input current adopts a multi-step current weighting form, allowing the model to simultaneously focus on the global information along the time dimension. Note that the new input current will follow a uniform distribution when $\\forall i,j\\in[1,T],\\omega_{i j}^{l}=\\frac{1}{T}$ and degrade to the vanilla input current when $\\boldsymbol{\\Omega}^{l}=\\mathrm{diag}(1,...,1)$ . For the first case mentioned above, if we further add the condition $\\lambda^{l}=1$ , according to Theorem 4.2(ii), one can find that the output of the model will be consistent with the activation output of a $L T$ -level quantized ANN layer by layer, as shown in Fig.2(b)-(c). For the second case, when $L=1$ , the model will degenerate into vanilla LIF model, as shown in Fig.2(a)-(b). ", "page_idx": 5}, {"type": "text", "text": "To enable the model to dynamically adjust the above calculation process, we set both $\\Omega^{l}$ and $\\lambda^{l}$ as learnable parameters. The initial values of $\\Omega^{l}$ and $\\lambda^{l}$ are set to $1/T$ and 1, respectively. During the training process, we choose the Sigmoid function $\\sigma(\\cdot)$ to control the parameters for fulfilling smooth gradient updates within a bounded learning range. We call this novel model as Learnable Multi-hierarchical Threshold (LM-HT) Model, which combines T-GIM and learnable attributes. We think the LM-HT model can regulate its spike firing pattern more flexibly and reasonably. ", "page_idx": 5}, {"type": "text", "text": "Since we can regulate the computational relationships between different time-steps through learnable $\\Omega^{l}$ and $\\lambda^{l}$ in the LM-HT model, during the back-propagation process, unlike Eq.(3), we detach the term\u2202ml(t)\u2202vl(t\u22121)\u2202ml(t\u22121) from the gradient calculation graph, thereby reducing redundant calculations and completely leaving the gradient propagation between different time-steps to $\\Omega^{l}$ and $\\lambda^{l}$ for control. The back-propagation calculation chains for the LM-HT model have been described as follow. Here $\\odot$ denotes the Hadamard product. ", "page_idx": 5}, {"type": "equation", "text": "$$\n\\begin{array}{l}{\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial\\boldsymbol{m}^{l}(t)}=\\frac{\\partial\\mathcal{L}}{\\partial s^{l}(t)}\\frac{\\partial s^{l}(t)}{\\partial\\boldsymbol{m}^{l}(t)},\\,\\,\\frac{\\partial s^{l}(t)}{\\partial\\boldsymbol{m}^{l}(t)}=\\mathrm{sign}\\left(\\frac{1}{2}\\theta^{l}\\leq\\boldsymbol{m}^{l}(t)\\leq\\left(L+\\frac{1}{2}\\right)\\theta^{l}\\right).}\\\\ {\\displaystyle\\frac{\\partial\\mathcal{L}}{\\partial\\lambda^{l}}=\\sum_{t=1}^{T}\\frac{\\partial\\mathcal{L}}{\\partial\\boldsymbol{m}^{l}(t)}\\odot\\boldsymbol{v}^{l}(t-1),\\,\\,\\frac{\\partial\\mathcal{L}}{\\partial\\omega_{i j}^{l}}=\\frac{\\partial\\mathcal{L}}{\\partial\\boldsymbol{m}^{l}(i)}\\odot\\left(\\boldsymbol{W}^{l}s^{l-1}(j)\\theta^{l-1}\\right).}\\end{array}\n$$", "text_format": "latex", "page_idx": 5}, {"type": "text", "text": "4.4 Hybrid Training based on the LM-HT Model ", "text_level": 1, "page_idx": 5}, {"type": "text", "text": "Although the traditional ANN-SNN Conversion frameworks have much lower computational overhead than STBP training algorithm, a serious performance degradation phenomenon often exists on the converted SNNs under low time latency [17]. To address this problem, previous researchers [39] considered adopting STBP training for a few epochs on the pre-trained ANN models to enhance the performance of the converted SNNs under fewer time-steps, which is called as hybrid training. In this work, we propose a brand-new hybrid training framework based on the LM-HT model. ", "page_idx": 5}, {"type": "table", "img_path": "IlIDNMvwmX/tmp/554b133c2c0a245633e6291cecc7a990007e94ca5c89929b514638fc5d3d68a6.jpg", "table_caption": ["Table 1: Ablation study for the LM-HT model on a subset of ImageNet-1k. "], "table_footnote": [], "page_idx": 6}, {"type": "table", "img_path": "IlIDNMvwmX/tmp/f0eb03fc34ad8466bb7a0a83978c68248aa1ab6dde4d8af794367f4325ae4e57.jpg", "table_caption": ["Table 2: Validation for the reparameterization procedure. "], "table_footnote": [], "page_idx": 6}, {"type": "text", "text": "", "page_idx": 6}, {"type": "text", "text": "We firstly choose QCFS function to train the quantized ANN models and then replace the QCFS function modules layer by layer with the LM-HT models under specific initialization $(\\forall i,j\\in$ $\\begin{array}{r}{[1,T],\\omega_{i j}^{l}=\\frac{1}{T};\\lambda^{l}=1,\\theta^{l}=\\vartheta^{l},\\pmb{v}^{l}(0)=\\frac{\\theta^{l}}{2})}\\end{array}$ , as shown in Fig.2(d). Combining with the conclusion pointed out by [2], one can note that the initialized LM-HT model and the QCFS function before substitution have an equivalence in terms of mathematical expectation, which has been described as the following theorem: ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.4. When $\\begin{array}{r}{\\sum_{t=1}^{T}\\pmb{I}^{l}(t)/L T\\,=\\,\\pmb{W}^{l}\\pmb{r}_{I F}^{l-1}(T_{q})}\\end{array}$ and $\\begin{array}{r}{\\sum_{t=1}^{T}\\pmb{I}^{l}(t)\\ \\in\\ [0,L T\\theta^{l}],\\ \\dot{\\pmb{y}}\\,\\forall\\dot{\\imath},\\,\\dot{\\jmath}\\ \\in}\\end{array}$ $\\begin{array}{r}{[1,T],\\omega_{i j}^{l}\\;=\\;\\frac{1}{T}}\\end{array}$ and $\\begin{array}{r}{\\lambda^{l}\\,=\\,1,\\theta^{l}\\,=\\,\\vartheta^{l},\\pmb{v}^{l}(0)\\,=\\,\\frac{\\theta^{l}}{2}}\\end{array}$ , for $L,T,T_{q}$ with arbitrary values, we have: $\\begin{array}{r}{\\mathbb{E}\\left(\\frac{\\sum_{t=1}^{T}s^{l}(t)\\theta^{l}}{L T}-\\frac{\\vartheta^{l}}{T_{q}}c l i p\\left(\\left\\lfloor\\frac{W^{l}r_{I F}^{l-1}(T_{q})T_{q}}{\\vartheta^{l}}+\\frac{1}{2}\\right\\rfloor,0,T_{q}\\right)\\right)=0.}\\end{array}$ . ", "page_idx": 6}, {"type": "text", "text": "Theorem 4.4 indicates that regardless of whether the time-steps we choose during the STBP training phase is equal to the inference steps simulated in ANN-SNN Conversion, the average spike firing rate of the LM-HT models under the initial state of STBP training maintains a mathematical equivalence with that simulated by the QCFS function modules in the previous stage. Therefore, under this new training framework, we can adopt STBP algorithm to optimize the inference performance of SNN under any degree of time latency. The detailed pseudo-code has been provided in the Appendix. ", "page_idx": 6}, {"type": "text", "text": "4.5 Reparameterize the LM-HT model to vanilla LIF model ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "As discussed in Section 4.2, the mathematical essence of the LM-HT model is to simulate the spike firing situation of vanilla LIF neurons within each time window. Considering that the current neuromorphic hardware mainly supports single threshold models, we propose a reparameterization scheme that can transform the LM-HT model obtained during the training stage into a vanilla LIF model, which can further be deployed on hardware for inference. ", "page_idx": 6}, {"type": "text", "text": "As shown in Fig.3, for a $L$ -level LM-HT model within $T$ steps, we expand it into a vanilla LIF model within $L T$ steps, where the membrane leakage factor between different time windows is set to $\\lambda^{l}$ . In addition, T-GIM will be extended from $\\mathbb{R}^{T\\times T}$ to $\\mathbb{R}^{L T\\times L T}$ and the parameters are averaged within each $L\\times L$ sub-region, ensuring that the input current meets the precondition in Theorem 4.2. We also rectify the bias terms in synaptic layers, which involve addition operations at each time-step. By performing layer-by-layer reparameterization in the above manner, we will obtain a single threshold SNN model with theoretically lossless accuracy. ", "page_idx": 6}, {"type": "text", "text": "5 Experiments ", "text_level": 1, "page_idx": 6}, {"type": "text", "text": "To validate the effectiveness of our proposed STBP and hybrid training frameworks based on the LM-HT model, we consider multiple static and neuromorphic datasets with different data scale, including CIFAR-10(100) [23], ImageNet-200(1k) [6] and CIFAR10-DVS [26]. Consistent with the previous works, we also choose VGG [40] and ResNet [19] as the basic network architecture . We evaluate the computational overhead of SNNs based on the number of synaptic operations (SOPs) and the calculation standard for related energy consumption refers to [55]. In addition, as the information transmitted by our $L$ -level LM-HT model within $T$ time-steps remains at the same level as that of the vanilla LIF model within $L T$ time-steps, to make a fair evaluation, we will compare the performance of the $L$ -level LM-HT model within $T$ steps with that of the previous works within $L T$ steps. ", "page_idx": 6}, {"type": "table", "img_path": "IlIDNMvwmX/tmp/170de0e95dbb8bde531e4e0e2af256fe42879e9a2c8062319200380c674a3683.jpg", "table_caption": ["Table 3: Comparison with previous state-of-the-art works. "], "table_footnote": [], "page_idx": 7}, {"type": "text", "text": "", "page_idx": 7}, {"type": "text", "text": "5.1 Ablation & Validation Studies for the LM-HT Model ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "As shown in Tab.1, we investigate the impact of threshold levels and T-GIM for our proposed model. One can note that vanilla IF neuron $(L=1,T=4)$ ) is not well suited for deep networks (e.g. ResNet34) and causes relatively high energy consumption, while the M-HT series models $(L=2,T=2)$ can effectively overcome the performance degradation problem on deep networks. When we further utilize T-GIM to regulate global information on the time dimension, the learning ability of our model is enhanced and the computational overhead in synaptic layers is significantly reduced. ", "page_idx": 7}, {"type": "text", "text": "We also validate the feasibility about the reparameterization procedure mentioned above. As shown in Tab.2 and Fig.3, by copying and reparameterizing the parameters of synapses, T-GIM and LMHT neurons layer by layer, we obtain a single threshold model that maintained almost the same performance and power consumption as the original LM-HT model. This convertible property enables the LM-HT model to be more flexibly deployed on neuromorphic hardware. ", "page_idx": 7}, {"type": "text", "text": "5.2 Comparison with Previous SoTA Works ", "text_level": 1, "page_idx": 7}, {"type": "text", "text": "We first investigate the competitiveness of our proposed model in the domain of STBP learning. As shown in Tab.3, our comparative works incorporate previous state-of-the-art (SoTA) methods in various sub-domains of STBP training, including batchnorm layer optimization [54, 15], improved surrogate gradients [29], learning function design [8, 14], energy-efficient training [13, 48, 34] and advanced neuron models [51, 44]. ", "page_idx": 7}, {"type": "table", "img_path": "IlIDNMvwmX/tmp/f18efdafd76ae569b8a4b23ea769fa6ccdf202839e1d5da823d2d906c9740123.jpg", "table_caption": ["Table 4: The performance of hybrid training based on the LM-HT model for CIFAR-100 dataset. "], "table_footnote": [], "page_idx": 8}, {"type": "text", "text": "CIFAR-10 & CIFAR-100. For conventional static datasets, one can find that our solution demonstrates significant performance advantages. For ResNet-18 structure, we achieve the top-1 accuracies of $96.25\\%$ and $79.33\\%$ with merely 2 time-steps on CIFAR-10 and CIFAR-100 datasets, respectively. For ResNet-19 network with a larger parameter scale, our method fulfills the precisions of $96.89\\%$ and $81.76\\%$ within 2 time-steps, which at least outperforms other corresponding works with $2.04\\%$ and $3.48\\%$ under the same time latency. In addition, it is worth noting that our above results have even exceeded the performance of other works with more time-steps (e.g. 6 steps). ", "page_idx": 8}, {"type": "text", "text": "ImageNet-200 & ImageNet-1k. For large-scale datasets, we also confirm the superiority of the LM-HT model. For the two-level LM-HT model, we respectively reach the top-1 accuracies of $61.09\\%$ and $70.90\\%$ within 2 time-steps on ImageNet-200 and ImageNet-1k datasets, which is $4.52\\%$ higher than ASGL (4 steps) and $3.38\\%$ higher than GLIF (4 steps) under the same-level time overhead. For a larger training time-step, one can note that our method will also demonstrate a significant advantage. For example, the two-level LM-HT model reaches the precision of $61.75\\%$ with 4 time-steps, which has surpassed ASGL (8 steps) with $4.94\\%$ . ", "page_idx": 8}, {"type": "text", "text": "CIFAR10-DVS. We also evaluate the effectiveness of our approach on neuromorphic datasets. Compared to other previous methods, our proposed model can achieve better results on shallower networks with fewer time-steps. For instance, the two-level LM-HT model can achieve the accuracy of $80.70\\%$ after merely 2 time-steps. ", "page_idx": 8}, {"type": "text", "text": "5.3 Performance Analysis of Hybrid Training ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In our hybrid training framework, we first choose [2] as the backbone for our ANN-SNN Conversion stage. Subsequently, we replace the QCFS function layer by layer with the initialized LM-HT model and conduct STBP training for merely 30 epochs. Furthermore, we also consider other advanced conversion methods [16, 43] and multi-stage error correction method [17] as our comparative works. ", "page_idx": 8}, {"type": "text", "text": "As shown in Tab.4, after conducting the STBP fine-tuning optimization with relatively low computational overhead, we note that the performance of the converted SNNs under different quantization levels has been significantly improved and surpass other previous methods, especially under low time latency. For instance, compared to the ResNet-20 network after eight-level quantization (i.e. $T_{q}{=}8)$ ), the two-level LM-HT model has achieved a performance improvement of $32.91\\%$ and $13.50\\%$ with 2 and 4 time-steps, respectively. ", "page_idx": 8}, {"type": "text", "text": "6 Conclusions ", "text_level": 1, "page_idx": 8}, {"type": "text", "text": "In this paper, we first investigate the mathematical equivalence among the multi-threshold model, vanilla spiking model and quantized ANNs, then propose an advanced STBP training method based on the LM-HT model, which has been proven to cover the representation range of vanilla STBP and quantized ANNs training frameworks, thereby promoting SNNs to achieve superior performance at the same level as quantized ANNs. Furthermore, the LM-HT model can achieve lossless transformation towards single threshold models or quantized ANNs under specific parameter configuration. Numerous experimental results have verified the effectiveness of our method. We believe that our work will further promote in-depth research on advanced spiking neural model. ", "page_idx": 8}, {"type": "text", "text": "Acknowledgements ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "This work was supported by STI 2030-Major Projects 2021ZD0200300, the National Natural Science Foundation of China under Grant No. 62176003 and No. 62088102, and by Beijing Nova Program under Grant No. 20230484362. ", "page_idx": 9}, {"type": "text", "text": "References ", "text_level": 1, "page_idx": 9}, {"type": "text", "text": "[1] L\u00e9on Bottou. Stochastic gradient descent tricks. In Neural networks: Tricks of the trade, pages 421\u2013436. Springer, 2012.   \n[2] Tong Bu, Wei Fang, Jianhao Ding, PengLin Dai, Zhaofei Yu, and Tiejun Huang. Optimal ANN-SNN conversion for high-accuracy and ultra-low-latency spiking neural networks. In International Conference on Learning Representations, 2022.   \n[3] Yongqiang Cao, Yang Chen, and Deepak Khosla. Spiking deep convolutional neural networks for energy-efficient object recognition. International Journal of Computer Vision, 113(1):54\u201366, 2015.   \n[4] Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learning augmentation strategies from data. In IEEE Conference on Computer Vision and Pattern Recognition, pages 113\u2013123, 2019.   \n[5] Mike Davies, Narayan Srinivasa, Tsung-Han Lin, Gautham Chinya, Yongqiang Cao, Sri Harsha Choday, Georgios Dimou, Prasad Joshi, Nabil Imam, Shweta Jain, et al. Loihi: A neuromorphic manycore processor with on-chip learning. IEEE Micro, 38(1):82\u201399, 2018.   \n[6] Jia Deng, Richard Socher, Lijia Li, Kai Li, and Feifei Li. Imagenet: A large-scale hierarchical image database. In IEEE Conference on Computer Vision and Pattern Recognition, 2009.   \n[7] Shikuang Deng and Shi Gu. Optimal conversion of conventional artificial neural networks to spiking neural networks. In International Conference on Learning Representations, 2021.   \n[8] Shikuang Deng, Yuhang Li, Shanghang Zhang, and Shi Gu. Temporal efficient training of spiking neural network via gradient re-weighting. International Conference on Learning Representations, 2022.   \n[9] Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017.   \n[10] Chaoteng Duan, Jianhao Ding, Shiyan Chen, Zhaofei Yu, and Tiejun Huang. Temporal effective batch normalization in spiking neural networks. In Advances in Neural Information Processing Systems, 2022.   \n[11] Wei Fang, Zhaofei Yu, Yanqi Chen, Tiejun Huang, Timoth\u00e9e Masquelier, and Yonghong Tian. Deep residual learning in spiking neural networks. In Advances in Neural Information Processing Systems, 2021.   \n[12] Wei Fang, Zhaofei Yu, Zhaokun Zhou, Ding Chen, Yanqi Chen, Zhengyu Ma, Timoth\u00e9e Masquelier, and Yonghong Tian. Parallel spiking neurons with high efficiency and ability to learn long-term dependencies. In Advances in Neural Information Processing Systems, 2023.   \n[13] Isha Garg, Sayeed Shafayet Chowdhury, and Kaushik Roy. DCT-SNN: Using dct to distribute spatial information over time for learning low-latency spiking neural networks. arXiv preprint arXiv:2010.01795, 2020.   \n[14] Yufei Guo, Xiaode Liu, Yuanpei Chen, Liwen Zhang, Weihang Peng, Yuhan Zhang, Xuhui Huang, and Zhe Ma. RMP-Loss: Regularizing membrane potential distribution for spiking neural networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023.   \n[15] Yufei Guo, Yuhan Zhang, Yuanpei Chen, Weihang Peng, Xiaode Liu, Liwen Zhang, Xuhui Huang, and Zhe Ma. Membrane potential batch normalization for spiking neural networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023.   \n[16] Bing Han, Gopalakrishnan Srinivasan, and Kaushik Roy. RMP-SNN: Residual membrane potential neuron for enabling deeper high-accuracy and low-latency spiking neural network. In IEEE Conference on Computer Vision and Pattern Recognition, pages 13558\u201313567, 2020.   \n[17] Zecheng Hao, Tong Bu, Jianhao Ding, Tiejun Huang, and Zhaofei Yu. Reducing ann-snn conversion error through residual membrane potential. In AAAI Conference on Artificial Intelligence, 2023.   \n[18] Zecheng Hao, Jianhao Ding, Tong Bu, Tiejun Huang, and Zhaofei Yu. Bridging the gap between anns and snns by calibrating offset spikes. In International Conference on Learning Representations, 2023.   \n[19] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition, pages 770\u2013778, 2016.   \n[20] Yifan Hu, Lei Deng, Yujie Wu, Man Yao, and Guoqi Li. Advancing spiking neural networks towards deep residual learning. IEEE Transactions on Neural Networks and Learning Systems, 2024.   \n[21] Saeed Reza Kheradpisheh and Timoth\u00e9e Masquelier. Temporal backpropagation for spiking neural networks with one spike per neuron. International Journal of Neural Systems, 30(06):2050027, 2020.   \n[22] Seijoon Kim, Seongsik Park, Byunggook Na, and Sungroh Yoon. Spiking-yolo: Spiking neural network for energy-efficient object detection. In AAAI Conference on Artificial Intelligence, 2020.   \n[23] Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.   \n[24] Yuxiang Lan, Yachao Zhang, Xu Ma, Yanyun Qu, and Yun Fu. Efficient converted spiking neural network for 3d and 2d classification. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023.   \n[25] Chen Li, Lei Ma, and Steve Furber. Quantization framework for fast spiking neural networks. Frontiers in Neuroscience, 16, 2022.   \n[26] Hongmin Li, Hanchao Liu, Xiangyang Ji, Guoqi Li, and Luping Shi. Cifar10-dvs: an eventstream dataset for object classification. Frontiers in Neuroscience, 2017.   \n[27] Yang Li and Yi Zeng. Efficient and accurate conversion of spiking neural network with burst spikes. In International Joint Conference on Artificial Intelligence, 2022.   \n[28] Yuhang Li, Shikuang Deng, Xin Dong, Ruihao Gong, and Shi Gu. A free lunch from ANN: Towards efficient, accurate spiking neural networks calibration. In International Conference on Machine Learning, pages 6316\u20136325, 2021.   \n[29] Yuhang Li, Yufei Guo, Shanghang Zhang, Shikuang Deng, Yongqing Hai, and Shi Gu. Differentiable spike: Rethinking gradient-descent for training spiking neural networks. In Advances in Neural Information Processing Systems, pages 23426\u201323439, 2021.   \n[30] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017.   \n[31] Ilya Loshchilov and Frank Hutter. SGDR: stochastic gradient descent with warm restarts. In International Conference on Learning Representations, 2017.   \n[32] Changze Lv, Jianhan Xu, and Xiaoqing Zheng. Spiking convolutional neural networks for text classification. In International Conference on Learning Representations, 2023.   \n[33] Wolfgang Maass. Networks of spiking neurons: the third generation of neural network models. Neural Networks, 10(9):1659\u20131671, 1997.   \n[34] Qingyan Meng, Mingqing Xiao, Shen Yan, Yisen Wang, Zhouchen Lin, and Zhiquan Luo. Towards memory and time-efficient backpropagation for training spiking neural networks. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023.   \n[35] Paul A Merolla, John V Arthur, Rodrigo Alvarez-Icaza, Andrew S Cassidy, Jun Sawada, Filipp Akopyan, Bryan L Jackson, Nabil Imam, Chen Guo, Yutaka Nakamura, et al. A million spiking-neuron integrated circuit with a scalable communication network and interface. Science, 345(6197):668\u2013673, 2014.   \n[36] Hesham Mostafa. Supervised learning based on temporal coding in spiking neural networks. IEEE Transactions on Neural Networks and Learning Systems, 29(7):3227\u20133235, 2017.   \n[37] Jing Pei, Lei Deng, Sen Song, Mingguo Zhao, Youhui Zhang, Shuang Wu, Guanrui Wang, Zhe Zou, Zhenzhi Wu, Wei He, et al. Towards artificial general intelligence with hybrid tianjic chip architecture. Nature, 572(7767):106\u2013111, 2019.   \n[38] Xuerui Qiu, Rui-Jie Zhu, Yuhong Chou, Zhaorui Wang, Liang-jian Deng, and Guoqi Li. Gated attention coding for training high-performance and efficient spiking neural networks. In AAAI Conference on Artificial Intelligence, 2024.   \n[39] Nitin Rathi and Kaushik Roy. DIET-SNN: A low-latency spiking neural network with direct input encoding and leakage and threshold optimization. IEEE Transactions on Neural Networks and Learning Systems, pages 1\u20139, 2021.   \n[40] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.   \n[41] Congyi Sun, Qinyu Chen, Yuxiang Fu, and Li Li. Deep spiking neural network with ternary spikes. In IEEE Biomedical Circuits and Systems Conference (BioCAS), 2022.   \n[42] Xiaoting Wang, Yanxiang Zhang, and Yongzhe Zhang. MT-SNN: Enhance spiking neural network with multiple thresholds. arXiv preprint arXiv:2303:11127, 2023.   \n[43] Yuchen Wang, Malu Zhang, Yi Chen, and Hong Qu. Signed neuron with memory: Towards simple, accurate and high-efficient ANN-SNN conversion. In International Joint Conference on Artificial Intelligence, 2022.   \n[44] Ziming Wang, Runhao Jiang, Shuang Lian, Rui Yan, and Huajin Tang. Adaptive smoothing gradient learning for spiking neural networks. In International Conference on Machine Learning, 2023.   \n[45] Ziming Wang, Shuang Lian, Yuhao Zhang, Xiaoxin Cui, Rui Yan, and Huajin Tang. Towards lossless ANN-SNN conversion under ultra-low latency with dual-phase optimization. arXiv preprint arXiv:2205.07473, 2022.   \n[46] Ziqing Wang, Yuetong Fang, Jiahang Cao, Qiang Zhang, Zhongrui Wang, and Renjing Xu. Masked spiking transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023.   \n[47] Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu, and Luping Shi. Spatio-temporal backpropagation for training high-performance spiking neural networks. Frontiers in Neuroscience, 12:331, 2018.   \n[48] Qu Yang, Jibin Wu, Malu Zhang, Yansong Chua, Xinchao Wang, and Haizhou Li. Training spiking neural networks with local tandem learning. In Advances in Neural Information Processing Systems, 2022.   \n[49] Man Yao, Jiakui Hu, Zhaokun Zhou, Yuan Li, Yonghong Tian, Bo Xu, and Guoqi Li. Spikedriven transformer. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2023.   \n[50] Man Yao, Guangshe Zhao, Hengyu Zhang, Yifan Hu, Lei Deng, Yonghong Tian, Bo Xu, and Guoqi Li. Attention spiking neural networks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 45(8):9393\u20139410, 2023.   \n[51] Xingting Yao, Fanrong Li, Zitao Mo, and Jian Cheng. GLIF: A unified gated leaky integrateand-fire neuron for spiking neural networks. In Advances in Neural Information Processing Systems, 2022.   \n[52] Qiang Yu, Chenxiang Ma, Shiming Song, Gaoyan Zhang, Jianwu Dang, and Kay Chen Tan. Constructing accurate and efficient deep spiking neural networks with double-threshold and augmented schemes. IEEE Transactions on Neural Networks and Learning Systems, pages 1714\u20131726, 2022.   \n[53] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.   \n[54] Hanle Zheng, Yujie Wu, Lei Deng, Yifan Hu, and Guoqi Li. Going deeper with directlytrained larger spiking neural networks. In AAAI Conference on Artificial Intelligence, pages 11062\u201311070, 2021.   \n[55] Zhaokun Zhou, Yuesheng Zhu, Chao He, Yaowei Wang, Shuicheng Yan, Yonghong Tian, and Yuan Li. Spikformer: When spiking neural network meets transformer. In International Conference on Learning Representations, 2023. ", "page_idx": 9}, {"type": "text", "text": "", "page_idx": 10}, {"type": "text", "text": "", "page_idx": 11}, {"type": "text", "text": "", "page_idx": 12}, {"type": "text", "text": "A Appendix ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1 Proof of Theorem ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "A.1.1 Proof of Lemma 4.1 & Theorem 4.2 ", "text_level": 1, "page_idx": 13}, {"type": "text", "text": "Before the proof of Theorem 4.2, we first need to introduce Lemma A.1: ", "page_idx": 13}, {"type": "text", "text": "Lemma A.1. Assume a continuous $T$ -step input current $\\pmb{I}^{l}(1),...,\\pmb{I}^{l}(T)$ , for a LM-HT model with $L$ -level threshold, when $\\forall t\\,\\in\\,[1,T],{\\cal I}^{l}(t)\\,\\in\\,[0,L\\theta^{l})$ and ${\\pmb v}^{l}(0)\\,\\in\\,[0,\\theta^{l}),\\lambda^{l}\\,=\\,1$ , we will have $\\pmb{v}^{l}(T)\\in[0,\\theta^{l})$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. $\\forall t\\ \\in\\ [0,T)$ , if $\\pmb{v}^{l}(t)\\;\\in\\;[0,\\theta^{l})$ , as $\\pmb{m}^{l}(t+1)\\;=\\;\\pmb{v}^{l}(t)\\,+\\pmb{I}^{l}(t)$ , we have $m^{l}(t+1)\\;\\in$ $[0,(L+1)\\theta^{l})$ . Therefore, after the firing process $\\pmb{v}^{l}(t+1)=\\pmb{m}^{l}(t+1)-\\pmb{s}^{l}(t)\\pmb{\\theta}^{l}$ , one can note that $\\pmb{v}^{l}(t+1)\\in[0,\\theta^{l})$ . According to the idea of mathematical induction, if we directly set ${\\pmb v}^{l}(0)\\in[0,\\theta^{l})$ , we can have $\\pmb{v}^{l}(\\dot{T})\\in[0,\\theta^{l})$ . \u53e3 ", "page_idx": 13}, {"type": "text", "text": "Theorem 4.2. When $\\lambda^{l}\\,=\\,1,{\\pmb v}^{l}(0)\\,\\in\\,[0,\\theta^{l}),$ , for a M-HT model with $L$ -level threshold, after $T$ time-steps, we will derive the following conclusions:   \n(i) If we further assume $\\forall t\\ \\in\\ [1,\\breve{T}],{\\cal I}^{l}(t)\\ \\in\\ [0,L\\theta^{l}),$ , we will have: $\\forall t\\;\\in\\;[1,T],s^{l}(t)\\;=$ $\\begin{array}{r}{\\sum_{j=L(t-1)+1}^{L t}s_{I F}^{l}(j),v^{l}(t)=v_{I F}^{l}(L t),\\sum_{t=1}^{T}s^{l}(t)=\\sum_{j=1}^{L T}s_{I F}^{l}(j).}\\end{array}$   \n$(i i)$ $\\begin{array}{r l}{\\pmb{I}^{l}(1)}&{{}=}\\end{array}$ .. $\\begin{array}{r l r}{.}&{{}=}&{I^{l}(T)}\\end{array}$ , we will have: $\\begin{array}{r l}{\\sum_{t=1}^{T}s^{l}(t)}&{{}=}\\end{array}$ $\\begin{array}{r}{c l i p\\left(\\left\\lfloor\\frac{\\boldsymbol{v}^{l}(0)+\\sum_{t=1}^{T}\\boldsymbol{I}^{l}(t)}{\\theta^{l}}\\right\\rfloor,0,L T\\right)}\\end{array}$ ", "page_idx": 13}, {"type": "text", "text": "Here the $I F$ model has uniform input currents $\\pmb{I}^{l}(1)/L,...,\\pmb{I}^{l}(T)/L$ respectively within every $L$ steps and satisfies $\\pmb{v}_{I F}^{l}(0)=\\pmb{v}^{l}(0)$ . ", "page_idx": 13}, {"type": "text", "text": "Proof. (i) If we consider the pre-condition in Theorem 4.2 and combine Eq.(1) with Eq.(2), $\\forall t\\in$ $[1,L T]$ , we will have: ", "page_idx": 13}, {"type": "equation", "text": "$$\nv_{I F}^{l}(t)-v_{I F}^{l}(t-1)=I^{l}\\left(\\left\\lceil\\frac{t}{L}\\right\\rceil\\right)/L-s_{I F}^{l}(t)\\theta^{l}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Similarly, if we set $\\lambda^{l}=1$ and incorporate Eq.(5), $\\forall t\\in[1,T]$ , we will have: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\begin{array}{r}{{\\pmb v}^{l}(t)-{\\pmb v}^{l}(t-1)={\\pmb I}^{l}(t)-{\\pmb s}^{l}(t){\\pmb\\theta}^{l}.}\\end{array}\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "Then we accumulate Eq.(S1) along the time dimension and obtain the following equation: ", "page_idx": 13}, {"type": "equation", "text": "$$\n{v_{I F}^{l}}(L t)-{v_{I F}^{l}}\\left(L(t-1)\\right)={I^{l}}(t)-\\sum_{j=L(t-1)+1}^{L t}s_{I F}^{l}(j)\\theta^{l}.\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "As $\\pmb{I}^{l}(t)\\in[0,L\\theta^{l})$ , according to Lemma A.1, when $\\pmb{v}^{l}(t-1)=\\pmb{v}_{I F}^{l}\\left(L(t-1)\\right)\\wedge\\pmb{v}^{l}(t-1)\\in[0,\\theta^{l})$ , we will have $\\pmb{v}^{l}(t)\\,\\in\\,[0,\\theta^{l})$ and ${\\pmb v}_{I F}^{l}(L t)\\,\\in\\,[0,\\theta^{l})$ . Considering $\\begin{array}{r}{\\pmb{s}^{l}(t),\\sum_{j=L(t-1)+1}^{L t}\\pmb{s}_{I F}^{l}(j)\\,\\in\\,\\mathbb{N}}\\end{array}$ , if $\\begin{array}{r}{\\pmb{s}^{l}(t)\\neq\\sum_{j=L(t-1)+1}^{L t}\\pmb{s}_{I F}^{l}(j)}\\end{array}$ , one can note that $\\begin{array}{r}{|\\sum_{j=L(t-1)+1}^{L t}s_{I F}^{l}(j)\\theta^{l}-s^{l}(t)\\theta^{l}|=|(v^{l}(t)-}\\end{array}$ $v^{l}(t-1))-(\\overline{{v_{I F}^{l}(L t)}}-\\overline{{v_{I F}^{l}\\left(L(t-1)\\right)}})|=|v^{l}(t)-v_{I F}^{l}(L t)|\\geq\\theta^{l}$ , which will violate the conclusion in Lemma A.1. Therefore, we can finally deduce that $\\begin{array}{r}{\\pmb{s}^{l}(t)=\\sum_{j=L(t-1)+1}^{L t}\\pmb{s}_{I F}^{l}(j)}\\end{array}$ . Then we can further have $\\pmb{v}^{l}(t)=\\pmb{v}_{I F}^{l}(L t)$ and $\\begin{array}{r}{\\sum_{t=1}^{T}\\pmb{s}^{l}(t)=\\sum_{j=1}^{L T}\\pmb{s}_{I F}^{l}(j)}\\end{array}$ . ", "page_idx": 13}, {"type": "text", "text": "(ii) If we accumulate Eq.(S2) along the time dimension and divide $\\theta^{l}$ on both sides, we will have the following equation: ", "page_idx": 13}, {"type": "equation", "text": "$$\n\\frac{{\\pmb v}^{l}(T)-{\\pmb v}^{l}(0)}{\\theta^{l}}=\\frac{\\sum_{t=1}^{T}{\\pmb I}^{l}(t)}{\\theta^{l}}-\\sum_{t=1}^{T}{\\pmb s}^{l}(t).\n$$", "text_format": "latex", "page_idx": 13}, {"type": "text", "text": "$\\begin{array}{r l r}{{\\cal I}^{l}(1)}&{{}<}&{0}\\end{array}$ $\\begin{array}{r l r}{I^{l}(1)}&{{}\\ge}&{L\\theta^{l}}\\end{array}$ o,r $\\begin{array}{r l}{\\sum_{t=1}^{T}s^{l}(t)}&{{}=}\\end{array}$ $\\begin{array}{r}{\\mathrm{clip}\\left(\\left\\lfloor\\frac{\\boldsymbol{v}^{l}(0)+\\sum_{t=1}^{T}\\boldsymbol{I}^{l}(t)}{\\boldsymbol{\\theta}^{l}}\\right\\rfloor,0,L T\\right)\\;=\\;0}\\end{array}$ $\\begin{array}{r}{\\sum_{t=1}^{T}s^{l}(t)\\;=\\;\\mathrm{clip}\\left(\\left\\lfloor\\frac{v^{l}(0)+\\sum_{t=1}^{T}I^{l}(t)}{\\theta^{l}}\\right\\rfloor,0,\\bar{L}T\\right)\\;=\\;L}\\end{array}$ ", "page_idx": 13}, {"type": "text", "text": "If $I^{l}(1)\\,\\in\\,[0,L\\theta^{l})$ , according to Lemma A.1, we will have $\\pmb{v}^{l}(T)\\,\\in\\,[0,\\theta^{l})$ . As $\\textstyle\\sum_{t=1}^{T}\\pmb{s}^{l}(t)\\ \\in$ N, based on Eq.(S4), we can finally deduce that  tT=1 sl(t) = vl(0)+ \u03b8ltT=1 Il( t) \u2212 v $\\begin{array}{r}{\\left\\lfloor\\frac{v^{l}(0)+\\sum_{t=1}^{T}I^{l}(t)}{\\theta^{l}}\\right\\rfloor=\\mathrm{clip}\\left(\\left\\lfloor\\frac{v^{l}(0)+\\sum_{t=1}^{T}I^{l}(t)}{\\theta^{l}}\\right\\rfloor,0,L T\\right)}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "One can note that Lemma 4.1 is actually a special case of Theorem 4.2 under the condition of $T=1$ , therefore Lemma 4.1 is also proven. \u53e3 ", "page_idx": 14}, {"type": "text", "text": "A.1.2 Proof of Corollary 4.3 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Corollary 4.3. If $\\lambda^{l}\\,=\\,1,{\\pmb v}^{l}(0)\\,=\\,0$ and $\\pmb{I}^{l}(1)\\,=\\,...\\,=\\,\\pmb{I}^{l}(T)$ , for a M-HT model with $L$ -level threshold, $\\pmb{s}^{l}(1)=...=\\pmb{s}^{l}(T)$ is only satisfied when $\\pmb{I}^{l}(1)\\in[k\\theta^{l},k\\theta^{l}+\\theta^{l}/T),\\forall k=0,...,L-1$ or $\\pmb{I}^{l}(1)\\in(-\\infty,0)\\cup[L\\theta^{l},+\\infty)$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. If $\\textbf{\\emph{I}}^{l}(1)~~<~~0$ or $\\pmb{I}^{l}(1)\\;\\;\\geq\\;\\;L\\theta^{l}$ , it is obvious that we will have $s^{l}(1)\\ \\,=\\ \\,\\ldots\\ =$ $\\pmb{\\mathscr{s}}^{l}(T)\\:=\\:0$ or $\\pmb{s}^{l}(1)\\:=\\:...\\:=\\:\\pmb{s}^{l}(T)\\:=\\:L$ . Otherwise, based on the conclusion $\\textstyle\\sum_{t=1}^{T}\\pmb{s}^{l}(t)\\;=$ $\\begin{array}{r}{\\mathrm{clip}\\left(\\left\\lfloor\\frac{\\boldsymbol{v}^{l}(0)+\\sum_{t=1}^{T}\\boldsymbol{I}^{l}(t)}{\\theta^{l}}\\right\\rfloor,0,L T\\right)}\\end{array}$ in Theorem 4.2(ii), when $\\begin{array}{r l r}{{\\cal I}^{l}(1)\\!}&{{}\\!\\in\\!}&{[k\\theta^{l},k\\theta^{l}+\\theta^{l}/T),\\forall k\\!}\\end{array}=$ $0,...,L\\mathrm{~-~}1$ , we will have $\\begin{array}{r}{\\sum_{t=1}^{T}s^{l}(t)\\;=\\;k T,\\forall k\\;=\\;0,...,L\\;-\\;1}\\end{array}$ . Note that $\\forall T^{\\prime}\\:\\in\\:[1,T]$ , we can further have $\\begin{array}{r}{\\sum_{t=1}^{T^{\\prime}}s^{l}(t)\\ =\\ k T^{\\prime},\\forall k\\ =\\ 0,...,L\\ -\\ 1}\\end{array}$ . Therefore, it can be concluded that $\\pmb{s}^{l}(1)=\\ldots=\\pmb{s}^{l}(\\overline{{T)}}=\\dot{k}$ . Instead, if $\\pmb{I}^{l}(1)\\in[0,L\\theta^{l})\\wedge\\pmb{I}^{l}(1)\\notin[k\\theta^{l},k\\theta^{l}+\\theta^{l}/T),\\forall k=0,...,L-1$ , we will have $\\begin{array}{r}{\\sum_{t=1}^{T}s^{l}(t)\\neq k T,\\forall k=0,...,L-1}\\end{array}$ . Therefore, $\\pmb{s}^{l}(1)=\\dots=\\pmb{s}^{l}(T)$ does not hold true. ", "page_idx": 14}, {"type": "text", "text": "A.1.3 Proof of Theorem 4.4 ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Theorem 4.4. When $\\begin{array}{r}{\\sum_{t=1}^{T}\\pmb{I}^{l}(t)/L T\\,=\\,\\pmb{W}^{l}\\pmb{r}_{I F}^{l-1}(T_{q})}\\end{array}$ and $\\begin{array}{r}{\\sum_{t=1}^{T}\\pmb{I}^{l}(t)\\;\\in\\;[0,L T\\pmb{\\theta}^{l}],\\;i\\pmb{f}\\,\\forall i,j}\\end{array}$ $\\begin{array}{r}{[1,T],\\omega_{i j}^{l}\\;=\\;\\frac{1}{T}}\\end{array}$ and $\\begin{array}{r}{\\lambda^{l}\\,=\\,1,\\theta^{l}\\,=\\,\\vartheta^{l},\\pmb{v}^{l}(0)\\,=\\,\\frac{\\theta^{l}}{2}}\\end{array}$ , for $L,T,T_{q}$ with arbitrary values, we have: $\\begin{array}{r}{\\mathbb{E}\\left(\\frac{\\sum_{t=1}^{T}s^{l}(t)\\theta^{l}}{L T}-\\frac{\\vartheta^{l}}{T_{q}}c l i p\\left(\\left\\lfloor\\frac{W^{l}r_{I F}^{l-1}(T_{q})T_{q}}{\\vartheta^{l}}+\\frac{1}{2}\\right\\rfloor,0,T_{q}\\right)\\right)=0.}\\end{array}$ . ", "page_idx": 14}, {"type": "text", "text": "Proof. If $\\begin{array}{r l r}{\\forall i,j}&{{}\\in}&{[1,T],\\omega_{i j}^{l}}&{=\\quad\\frac{1}{T}}\\end{array}$ , $\\begin{array}{r l r l r}{\\lambda^{l}}&{{}=}&{1,\\theta^{l}}&{{}=}&{\\vartheta^{l}}\\end{array}$ and $\\begin{array}{r l r}{{\\pmb v}^{l}(0)}&{{}=}&{\\frac{{\\pmb\\theta}^{l}}{2}}\\end{array}$ , combining with the conclusion mentioned in Theorem 4.2(ii), we will have $\\begin{array}{r l}{\\underbrace{\\sum_{t=1}^{T}\\pmb{s}^{l}(t)\\pmb{\\theta}^{l}}_{L T}}&{{}=}\\end{array}$ $\\begin{array}{r}{\\frac{\\theta^{l}}{L T}\\mathrm{clip}\\left(\\left\\lfloor\\frac{\\sum_{t=1}^{T}{I^{l}(t)}}{\\theta^{l}}+\\frac{1}{2}\\right\\rfloor,0,L T\\right)}\\end{array}$ . According to the conclusion pointed out in [2], we have known that $\\begin{array}{r l r}{{\\mathbb E}\\left(\\frac{\\stackrel{\\cdot}{\\theta}^{l}}{L T}\\mathrm{clip}\\left(\\left\\lfloor\\frac{x^{l}L T}{\\theta^{l}}+\\frac{1}{2}\\right\\rfloor,0,\\stackrel{\\cdot}{L T}\\right)-\\frac{\\vartheta^{l}}{T_{q}}\\mathrm{clip}\\left(\\left\\lfloor\\frac{x^{l}T_{q}}{\\vartheta^{l}}+\\frac{1}{2}\\right\\rfloor,0,T_{q}\\right)\\right)}&{=}&{0,}\\end{array}$ here $\\pmb{x}^{l}~\\in~[0,\\theta^{l}]$ . Therefore, we directly set $\\begin{array}{r}{\\pmb{x}^{l}\\,=\\,\\sum_{t=1}^{T}\\pmb{I}^{l}(t)/L T\\,=\\,\\pmb{W}^{l}\\pmb{r}_{I F}^{l-1}(T_{q})}\\end{array}$ and then we will draw the final conclusion. ", "page_idx": 14}, {"type": "text", "text": "A.1.4 Computational Equivalence about the Reparameterization Process ", "text_level": 1, "page_idx": 14}, {"type": "text", "text": "Theorem A.2. $\\forall t,i\\in[1,T],\\forall j\\in[L(t-1)+1,L t],\\forall k\\in[L(i-1)+1,L i]$ , when ${\\pmb s}^{l-1}(t)=$ $\\begin{array}{r}{\\sum_{j=L(t-1)+1}^{L t}\\pmb{s}_{I F}^{l-1}(j),}\\end{array}$ , if $\\hat{b_{j}^{l}}\\,=\\,b_{t}^{l}/L,\\omega_{j k}^{\\hat{l}}\\,=\\,\\omega_{t i}^{l}/L$ , we will have $\\begin{array}{r}{\\pmb{I}^{l}(t)\\,=\\,\\sum_{j=L(t-1)+1}^{L t}{\\pmb I}_{I F}^{l}(j)}\\end{array}$ Here $\\hat{b^{l}},\\hat{\\omega^{l}}$ denote the rectified bias term and T-GIM layer after the reparameterization process. ", "page_idx": 14}, {"type": "text", "text": "Proof. Firstly, it is obvious that ${\\pmb I}^{l}(t),{\\pmb I}_{I F}^{l}(j)$ can be rewritten as $\\begin{array}{r}{\\pmb{I}^{l}(t)=\\sum_{i=1}^{T}\\omega_{t i}^{l}({\\pmb W}^{l}{\\pmb s}^{l-1}(i)\\!+\\!b_{i}^{l})}\\end{array}$ and $\\begin{array}{r}{\\pmb{I}_{I F}^{l}(j)=\\sum_{i=1}^{L T}\\hat{\\omega_{j i}^{l}}(\\pmb{W}^{l}\\pmb{s}_{I F}^{l-1}(i)+\\hat{b_{i}^{l}})}\\end{array}$ . Considering the precondition $\\hat{b_{j}^{l}}={b_{t}^{l}}/{L},\\hat{\\omega_{j k}^{l}}=\\omega_{t i}^{l}/L$ , ", "page_idx": 14}, {"type": "text", "text": "we will have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l r}&{}&{I_{I F}^{l}(j)=\\displaystyle\\sum_{i=1}^{T}\\sum_{k=L(i-1)+1}^{L i}\\omega_{j k}^{\\hat{l}}(W^{l}s_{I F}^{l-1}(k)+\\hat{b_{k}^{l}})}\\\\ &{}&{\\qquad=\\displaystyle\\sum_{i=1}^{T}\\frac{\\omega_{t i}^{l}}{L}\\sum_{k=L(i-1)+1}^{L i}(W^{l}s_{I F}^{l-1}(k)+\\frac{b_{i}^{l}}{L}).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Then we can further have: ", "page_idx": 15}, {"type": "equation", "text": "$$\n\\begin{array}{r l}{\\displaystyle\\sum_{j=L(t-1)+1}^{L t}I_{I F}^{l}(j)=\\displaystyle\\sum_{j=L(t-1)+1\\;\\operatorname{i}=1}^{L t}\\displaystyle\\sum_{k=L(i-1)+1}^{L t}\\displaystyle\\sum_{k=L(i-1)+1}^{L i}\\displaystyle(W^{l}s_{I F}^{l-1}(k)+\\frac{b_{i}^{l}}{L})}\\\\ {\\displaystyle}&{=\\displaystyle\\sum_{i=1}^{T}\\displaystyle\\frac{w_{i}^{l}}{L}_{j=L(t-1)+1}^{l t}\\displaystyle(W^{l}\\sum_{k=L(i-1)+1}^{L i}s_{I F}^{l-1}(k)+b_{i}^{l})}\\\\ &{=\\displaystyle\\sum_{i=1}^{T}\\displaystyle\\frac{w_{i}^{l}}{L}_{j=L(t-1)+1}^{L t}\\displaystyle(W^{l}s^{l-1}(i)+b_{i}^{l})}\\\\ &{=\\displaystyle\\sum_{i=1}^{T}\\displaystyle\\sum_{i=1}^{\\alpha_{l}}(W^{l}s^{l-1}(i)+b_{i}^{l})}\\\\ &{=\\displaystyle\\sum_{i=1}^{L t}w_{i}^{l}(W^{l}s^{l-1}(i)+b_{i}^{l})}\\\\ &{=\\displaystyle I^{l}(t).}\\end{array}\n$$", "text_format": "latex", "page_idx": 15}, {"type": "text", "text": "Due to the fact that the calculation process of the spike sequences passing through Conv & BN and T-GIM layers can be abstractly described by Theorem A.2, we can conclude that the sum of the input currents within the corresponding time windows before and after reparameterization remains unchanged. The spike sequences obtained by passing the input currents through the spiking neuron layer will also satisfy the precondition of Theorem A.2 $\\begin{array}{r}{(\\pmb{s}^{l}(t)=\\sum_{j=L(t-1)+1}^{L t}\\pmb{s}_{I F}^{l}(\\bar{j}))}\\end{array}$ . Therefore, we can prove the computational equivalence before and after the reparameterization process. \u53e3 ", "page_idx": 15}, {"type": "text", "text": "A.2 Comparison with Other Advanced Network Backbones ", "text_level": 1, "page_idx": 15}, {"type": "text", "text": "As shown in Tab.S1, we have made comparison with related advanced works [20, 55, 49, 38] on CIFAR datasets. One can find that our LM-HT model has superior scalability and can demonstrate its effectiveness on multiple different backbones. For example, for CIFAR-100 dataset, compared to GAC-SNN [38], we achieve an accuracy improvement of $1.35\\%$ on MS-ResNet-18. For Transformer4-384 architecture, our method also outperforms Spikformer [55] and Spike-driven Transformer [49] in terms of performance. ", "page_idx": 15}, {"type": "table", "img_path": "IlIDNMvwmX/tmp/db2e10a36491a525e8768e37a2c3fe75fe23d908459d1d9f0efd425c8bed2406.jpg", "table_caption": ["Table S1: Comparison with previous methods based on advanced backbones and attention mechanism. "], "table_footnote": [], "page_idx": 15}, {"type": "text", "text": "A.3 Experimental Configuration ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "For static datasets, we attempt to suppress the possible overfitting phenomenon by utilizing data augmentation techniques including AutoAugment [4] and Cutout [9]. For CIFAR10-DVS dataset, we resize each image to $48\\times48$ pixels and split it into 10 frames. For ImageNet-1k dataset, we further consider MS-ResNet architecture [20] and Mixup technique [53] to strengthen the generalization ability of our network. We respectively try to use SGD [1] and AdamW [30] as our optimizers. The corresponding initial learning rate and weight decay are set to 0.025, $5\\times10^{-4}$ for SGD on CIFAR$\\mathrm{l}0(10\\dot{0}),0.01\\dot{2}5,5\\times10^{-4}$ for SGD on ImageNet-200 and 0.02, 0.01 for AdamW on CIFAR10-DVS. For ImageNet-1k dataset, we use SGD as our optimizer and set the corresponding weight decay as 0. Furthermore, in the hybrid training framework, our initial learning rate and weight decay are both set to $5\\times10^{-4}$ . For all experimental cases, we choose the Cosine Annealing scheduler [31] to dynamically regulate the learning rate. Our experiments are implemented on NVIDIA RTX A5000 and 4090. ", "page_idx": 16}, {"type": "text", "text": "A.4 The Pseudo-Code of Hybrid Training Algorithm ", "text_level": 1, "page_idx": 16}, {"type": "image", "img_path": "IlIDNMvwmX/tmp/b428f48558d754d5c479ef70e74a776f90492ac1f9b675118bcba1d511e2a9eb.jpg", "img_caption": [], "img_footnote": [], "page_idx": 16}, {"type": "text", "text": "NeurIPS Paper Checklist ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "1. Claims ", "text_level": 1, "page_idx": 16}, {"type": "text", "text": "Question: Do the main claims made in the abstract and introduction accurately reflect the paper\u2019s contributions and scope? ", "page_idx": 16}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 16}, {"type": "text", "text": "Justification: We clearly point out the contributions and scope of this work in the abstract and introduction sections. ", "page_idx": 16}, {"type": "text", "text": "Guidelines: ", "page_idx": 16}, {"type": "text", "text": "\u2022 The answer NA means that the abstract and introduction do not include the claims made in the paper. ", "page_idx": 16}, {"type": "text", "text": "\u2022 The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. \u2022 The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. \u2022 It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ", "page_idx": 17}, {"type": "text", "text": "2. Limitations ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: Does the paper discuss the limitations of the work performed by the authors? Answer: [NA] . ", "page_idx": 17}, {"type": "text", "text": "Justification: We find no limitation which needs to be emphasized here. ", "page_idx": 17}, {"type": "text", "text": "Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper.   \n\u2022 The authors are encouraged to create a separate \"Limitations\" section in their paper.   \n\u2022 The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be.   \n\u2022 The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated.   \n\u2022 The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon.   \n\u2022 The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size.   \n\u2022 If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness.   \n\u2022 While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren\u2019t acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ", "page_idx": 17}, {"type": "text", "text": "3. Theory Assumptions and Proofs ", "text_level": 1, "page_idx": 17}, {"type": "text", "text": "Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof? ", "page_idx": 17}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 17}, {"type": "text", "text": "Justification: We provide the corresponding assumptions and proofs in the Appendix section. Guidelines: ", "page_idx": 17}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include theoretical results.   \n\u2022 All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced.   \n\u2022 All assumptions should be clearly stated or referenced in the statement of any theorems.   \n\u2022 The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition.   \n\u2022 Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. ", "page_idx": 17}, {"type": "text", "text": "4. Experimental Result Reproducibility ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 18}, {"type": "text", "text": "Justification: We provide the detailed experimental configuration in the Appendix section. Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not.   \n\u2022 If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable.   \n\u2022 Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed.   \n\u2022 While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. ", "page_idx": 18}, {"type": "text", "text": "5. Open access to data and code ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material? ", "page_idx": 18}, {"type": "text", "text": "Answer: [Yes] ", "text_level": 1, "page_idx": 18}, {"type": "text", "text": "Justification: We provide the data and code with sufficient instructions in the supplemental materials. ", "page_idx": 18}, {"type": "text", "text": "Guidelines: ", "page_idx": 18}, {"type": "text", "text": "\u2022 The answer NA means that paper does not include experiments requiring code.   \n\u2022 Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 While we encourage the release of code and data, we understand that this might not be possible, so \u201cNo\u201d is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark).   \n\u2022 The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details.   \n\u2022 The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc.   \n\u2022 The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why.   \n\u2022 At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable).   \n\u2022 Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ", "page_idx": 18}, {"type": "text", "text": "", "page_idx": 19}, {"type": "text", "text": "6. Experimental Setting/Details ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results? ", "page_idx": 19}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 19}, {"type": "text", "text": "Justification: We specify the training and test details in the Appendix section and supplementary materials. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments. \u2022 The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. \u2022 The full details can be provided either with the code, in appendix, or as supplemental material. ", "page_idx": 19}, {"type": "text", "text": "7. Experiment Statistical Significance ", "text_level": 1, "page_idx": 19}, {"type": "text", "text": "Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments? ", "page_idx": 19}, {"type": "text", "text": "Answer: [No] ", "page_idx": 19}, {"type": "text", "text": "Justification: The experiments choose a shared random seed to ensure fairness and reproducibility. ", "page_idx": 19}, {"type": "text", "text": "Guidelines: ", "page_idx": 19}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The authors should answer \"Yes\" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper.   \n\u2022 The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions).   \n\u2022 The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.)   \n\u2022 The assumptions made should be given (e.g., Normally distributed errors).   \n\u2022 It should be clear whether the error bar is the standard deviation or the standard error of the mean.   \n\u2022 It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a $96\\%$ CI, if the hypothesis of Normality of errors is not verified.   \n\u2022 For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates).   \n\u2022 If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ", "page_idx": 19}, {"type": "text", "text": "8. Experiments Compute Resources ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] ", "page_idx": 20}, {"type": "text", "text": "Justification: We make description about the computation resources in the Appendix section. Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not include experiments.   \n\u2022 The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage.   \n\u2022 The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute.   \n\u2022 The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn\u2019t make it into the paper). ", "page_idx": 20}, {"type": "text", "text": "9. Code Of Ethics ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines? ", "page_idx": 20}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 20}, {"type": "text", "text": "Justification: The research conforms with the NeurIPS Code of Ethics. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics.   \n\u2022 If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics.   \n\u2022 The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ", "page_idx": 20}, {"type": "text", "text": "10. Broader Impacts ", "text_level": 1, "page_idx": 20}, {"type": "text", "text": "Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed? ", "page_idx": 20}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 20}, {"type": "text", "text": "Justification: We find no societal impact which needs to be emphasized here. ", "page_idx": 20}, {"type": "text", "text": "Guidelines: ", "page_idx": 20}, {"type": "text", "text": "\u2022 The answer NA means that there is no societal impact of the work performed.   \n\u2022 If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact.   \n\u2022 Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations.   \n\u2022 The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster.   \n\u2022 The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. ", "page_idx": 20}, {"type": "text", "text": "\u2022 If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ", "page_idx": 21}, {"type": "text", "text": "11. Safeguards ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 21}, {"type": "text", "text": "Justification: We think that this paper poses no such risks. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper poses no such risks.   \n\u2022 Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters.   \n\u2022 Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images.   \n\u2022 We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. ", "page_idx": 21}, {"type": "text", "text": "12. Licenses for existing assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected? ", "page_idx": 21}, {"type": "text", "text": "Answer: [Yes] . ", "page_idx": 21}, {"type": "text", "text": "Justification: We make proper statements and citations for relevant existing assets. ", "page_idx": 21}, {"type": "text", "text": "Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not use existing assets.   \n\u2022 The authors should cite the original paper that produced the code package or dataset.   \n\u2022 The authors should state which version of the asset is used and, if possible, include a URL.   \n\u2022 The name of the license (e.g., CC-BY 4.0) should be included for each asset.   \n\u2022 For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided.   \n\u2022 If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset.   \n\u2022 For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided.   \n\u2022 If this information is not available online, the authors are encouraged to reach out to the asset\u2019s creators. ", "page_idx": 21}, {"type": "text", "text": "13. New Assets ", "text_level": 1, "page_idx": 21}, {"type": "text", "text": "Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets? ", "page_idx": 21}, {"type": "text", "text": "Answer: [NA] . ", "page_idx": 21}, {"type": "text", "text": "Justification: We choose public datasets and models in this work. Guidelines: ", "page_idx": 21}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not release new assets. ", "page_idx": 21}, {"type": "text", "text": "\u2022 Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc.   \n\u2022 The paper should discuss whether and how consent was obtained from people whose asset is used.   \n\u2022 At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ", "page_idx": 22}, {"type": "text", "text": "14. Crowdsourcing and Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "page_idx": 22}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper.   \n\u2022 According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ", "page_idx": 22}, {"type": "text", "text": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with Human Subjects ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Question: Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained? ", "page_idx": 22}, {"type": "text", "text": "Answer: [NA] ", "text_level": 1, "page_idx": 22}, {"type": "text", "text": "Justification: This paper does not involve crowdsourcing nor research with human subjects. Guidelines: ", "page_idx": 22}, {"type": "text", "text": "\u2022 The answer NA means that the paper does not involve crowdsourcing nor research with human subjects.   \n\u2022 Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper.   \n\u2022 We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution.   \n\u2022 For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review. ", "page_idx": 22}]