{"references": [{"fullname_first_author": "Angela Dai", "paper_title": "ScanNet: Richly-annotated 3D reconstructions of indoor scenes", "publication_date": "2017-00-00", "reason": "This paper introduces ScanNet, a widely used benchmark dataset for 3D scene understanding research, providing the foundation for the evaluation of many 3D scene understanding methods."}, {"fullname_first_author": "Alexander Kirillov", "paper_title": "Segment Anything", "publication_date": "2023-00-00", "reason": "This paper presents the Segment Anything Model (SAM), a highly influential foundation model for image segmentation that inspired the design and capabilities of the UniSeg3D model."}, {"fullname_first_author": "Jitesh Jain", "paper_title": "Oneformer: One transformer to rule universal image segmentation", "publication_date": "2023-00-00", "reason": "This paper introduces OneFormer, a unified framework for 2D image segmentation tasks, which served as an inspiration for the UniSeg3D's unified architecture in 3D scene understanding."}, {"fullname_first_author": "Alec Radford", "paper_title": "Learning transferable visual models from natural language supervision", "publication_date": "2021-00-00", "reason": "CLIP, introduced in this paper, is a crucial component for UniSeg3D, enabling the model to effectively process and leverage textual information for tasks such as referring segmentation."}, {"fullname_first_author": "Charles Ruizhongtai Qi", "paper_title": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "publication_date": "2017-00-00", "reason": "PointNet++, a seminal work in processing point cloud data, is adopted by UniSeg3D as a backbone for extracting effective point-wise features from the input point cloud data."}]}