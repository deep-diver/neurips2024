[{"figure_path": "T9GbbWbNQG/tables/tables_5_1.jpg", "caption": "Table 1: Average pruning ratio and accuracy loss for all tasks. Values in parentheses are evaluated by excluding non-compressible cases.", "description": "This table presents the average pruning ratio and accuracy loss for 10 tasks and 2 models (S4D and S5).  The results are broken down by three pruning methods: Uniform, Global, and LAST.  The numbers in parentheses show the average for only the datasets that were compressible (meaning the pruning had a reasonable effect). The table highlights that the LAST method achieves significantly lower accuracy loss compared to the other two methods at comparable pruning ratios.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_6_1.jpg", "caption": "Table 2: Accuracy of pruned models on LRA tasks. LAST is evaluated at the maximum tested pruning ratio with less than 1% accuracy loss, and other methods were evaluated for the same pruning ratios.", "description": "This table compares the performance of three different pruning methods (Uniform H\u221e, Global H\u221e, and LAST) on six long-range sequence tasks from the LRA benchmark.  The table shows the accuracy of pruned models at different pruning ratios.  The results demonstrate that LAST outperforms the other methods, maintaining high accuracy even with significant state pruning.  The results highlight the effectiveness of LAST's layer-adaptive pruning strategy and energy normalization in identifying and removing less important states.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_19_1.jpg", "caption": "Table 3: Training configurations of S4D models for all tested tasks. ns: state dimension of each SISO system. LN: layer normalization, BN: batch normalization, Pre: pre-normalization. D: dropout. LR: learning rate. B: batch size. E: epochs. WD: weight decay. \u2020: The value is changed from the original release [Gu et al., 2022a] for training feasibility.", "description": "This table details the hyperparameters used for training the S4D (multi-SISO) models across various tasks.  It shows the number of layers (L), input channels (h), state dimension of each SISO system (ns), normalization type (LN or BN), whether pre-normalization was used, dropout rate (D), learning rate (LR), batch size (B), number of epochs (E), weight decay (WD), and the range of timescales used (Amin, Amax).  Note that the learning rate for the Path-X task was adjusted from the original setting for improved training.", "section": "C Experimental details"}, {"figure_path": "T9GbbWbNQG/tables/tables_19_2.jpg", "caption": "Table 4: Training configurations of S5 models for all tested tasks. All models used batch normalization, pre-normalization, and Amax = 0.1. nm: state dimension of a MIMO system. J: number of blocks for block initialization of A. D: dropout. LR: learning rate. SSM LR: learning rate for SSM parameters, B: batch size. E: epochs. WD: weight decay.", "description": "This table presents the training configurations used for the S5 models across all ten tasks in the experiments.  It details hyperparameters like the number of layers (L), input channels (h), state dimension (nm), number of blocks for initialization (J), dropout rate (D), learning rates (LR and SSM LR), batch size (B), number of epochs (E), weight decay (WD), and the minimum value of A (Amin).  These hyperparameters were carefully tuned to achieve optimal performance for each task.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_20_1.jpg", "caption": "Table 5: Average pruning ratio and accuracy loss for all tasks. Values in parentheses are evaluated by excluding non-compressible cases.", "description": "This table presents the average pruning ratio and accuracy loss for different pruning methods across various tasks. The results are divided into two categories: all tasks and only compressible tasks. The table highlights the performance of unstructured random pruning and structured random pruning, showcasing the impact of structured pruning on maintaining accuracy.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_21_1.jpg", "caption": "Table 6: Average pruning ratio and accuracy loss in S5 models for all tasks. Values in parentheses are evaluated by excluding non-compressible cases.", "description": "This table compares different pruning methods (random, uniform magnitude, global magnitude, LAMP, uniform H\u221e, global H\u221e, and LAST) on S5 models across various tasks.  For each method, it shows the average pruning ratio achieved and the resulting average accuracy loss. The \"State Importance\" column shows the criteria used for pruning by each method.  The values in parentheses represent results when non-compressible cases are excluded.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_22_1.jpg", "caption": "Table 7: Accuracy of pruned models on pixel-level image classification tasks. LAST is evaluated at the maximum tested pruning ratio with less than 1% accuracy loss, and other methods were evaluated for the same pruning ratios.", "description": "This table compares the accuracy of different pruning methods (Uniform H\u221e, Global H\u221e, and LAST) on three pixel-level image classification tasks (sMNIST, psMNIST, and sCIFAR).  The results are shown for both S4D (multi-SISO) and S5 (MIMO) models.  For each model and task, the accuracy is reported for the full model (no pruning) and for a pruned model at a specific pruning ratio that achieves less than 1% accuracy loss for LAST. The table highlights the superior performance of the LAST method in maintaining high accuracy after pruning compared to the other methods.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_22_2.jpg", "caption": "Table 8: Efficiency improvement in computational and memory costs in S5 models.", "description": "This table presents the average inference speed and peak GPU memory usage of pruned S5 models on six different tasks from the LRA benchmark.  The results demonstrate the efficiency gains achieved through state pruning, showing improvements in both speed and reduced memory consumption. The degree of improvement varies depending on the specific task and the level of pruning applied.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_24_1.jpg", "caption": "Table 2: Accuracy of pruned models on LRA tasks. LAST is evaluated at the maximum tested pruning ratio with less than 1% accuracy loss, and other methods were evaluated for the same pruning ratios.", "description": "This table compares the performance of LAST against three other pruning methods (Uniform H\u221e, Global H\u221e, and Random) across six tasks from the Long Range Arena (LRA) benchmark.  The table shows the accuracy of models after applying different pruning ratios.  LAST consistently demonstrates superior performance, maintaining high accuracy even with significant state pruning (up to 80% in some cases).  Uniform and Global H\u221e methods serve as ablations of LAST, highlighting the importance of energy normalization in LAST's effectiveness.  The Random pruning method provides a baseline showing the effectiveness of the proposed pruning strategy over a completely random approach.", "section": "5 Experiments"}, {"figure_path": "T9GbbWbNQG/tables/tables_25_1.jpg", "caption": "Table 10: Accuracy of pruned models on Speech Command task. LAST is evaluated at the maximum tested pruning ratio with less than 1% accuracy loss, and other methods were evaluated for the same pruning ratios.", "description": "This table presents the accuracy of different pruning methods (Uniform H\u221e, Global H\u221e, and LAST) on the Speech Command task, comparing their performance at various pruning ratios.  The table highlights the effectiveness of LAST in maintaining high accuracy even with significant state pruning.  Results are shown for both 16kHz and 8kHz sampling rates.", "section": "E.3 Speech command"}]