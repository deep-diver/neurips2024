{"references": [{"fullname_first_author": "Arthur Jacot", "paper_title": "Neural tangent kernel: Convergence and generalization in neural networks", "publication_date": "2018-12-01", "reason": "This paper introduced the Neural Tangent Kernel (NTK) theory, which is a widely used framework for analyzing overparametrized neural networks and is frequently compared to feature learning regimes in the current paper."}, {"fullname_first_author": "Lenaic Chizat", "paper_title": "On lazy training in differentiable programming", "publication_date": "2019-12-01", "reason": "This paper provides theoretical evidence for the lazy training dynamics of overparametrized neural networks, which is central to understanding the limitations of the NTK regime and motivates the exploration of feature learning mechanisms in the current work."}, {"fullname_first_author": "Zeyuan Allen-Zhu", "paper_title": "Learning and generalization in overparameterized neural networks, going beyond two layers", "publication_date": "2019-12-01", "reason": "This paper extends the analysis of overparametrized neural networks beyond the two-layer setting, offering insights into the feature learning capabilities of deeper architectures and providing a broader context for the current paper's findings."}, {"fullname_first_author": "Alexandru Damian", "paper_title": "Neural networks can learn representations with gradient descent", "publication_date": "2022-06-01", "reason": "This paper provides theoretical evidence of feature learning capabilities in the early stages of gradient-based training for 2-layer neural networks, which is directly relevant to the analysis of early stage feature learning presented in this paper."}, {"fullname_first_author": "Mo Zhou", "paper_title": "A local convergence theory for mildly over-parameterized two-layer neural networks", "publication_date": "2021-06-01", "reason": "This paper presents a local convergence analysis for regularized two-layer neural networks, which forms the theoretical basis for the local convergence analysis presented in the current paper."}]}