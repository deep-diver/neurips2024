[{"figure_path": "yXpfrLMIr2/figures/figures_1_1.jpg", "caption": "Figure 1: Visual comparison (\u00d74) of binarization methods. Some methods (e.g., BNN [19]) cannot work on diffusion models. Several methods (e.g., BBCU [66]) suffer from blurring and artifacts. In contrast, our proposed BI-DiffSR outperforms other methods with accurate results.", "description": "This figure compares the super-resolution results of different binarization methods on the image Urban100: img_074.  It shows that while some methods fail to produce usable results for diffusion models, or produce blurry/artifact-filled results, the authors' proposed method (BI-DiffSR) achieves superior performance.", "section": "1 Introduction"}, {"figure_path": "yXpfrLMIr2/figures/figures_3_1.jpg", "caption": "Figure 2: The overall structure of the noise estimation network. (a) UNet: The model consists of ResBlock, CP-Down, CP-Up, and CS-Fusion. It predicts noise et with the upscaled LR image y, noise image xt, and timestep t. (b) ResBlock: Residual block, utilizes the binarized convolution (BI-Conv) block. The input and output dimensions of the block remain consistent, making it suitable for binarization. (c) TE: Time encoding, encoders timestep t to produce the timestep embedding tem.", "description": "This figure shows the architecture of the noise estimation network used in the BI-DiffSR model.  It details the UNet structure (a), which consists of residual blocks (ResBlocks), consistent-pixel downsampling (CP-Down), consistent-pixel upsampling (CP-Up), and channel-shuffle fusion (CS-Fusion) modules.  The ResBlock (b) is highlighted, showcasing its use of binarized convolutions (BI-Conv) to maintain consistent input/output dimensions suitable for binarization. Finally, the timestep encoding (TE) process (c) is shown, which converts the timestep into a timestep embedding used in the network.", "section": "3.1 Model Structure"}, {"figure_path": "yXpfrLMIr2/figures/figures_4_1.jpg", "caption": "Figure 3: (a) CP-Down: Consistent-pixel-downsample. (b) CP-Up: Consistent-pixel-upsample. (c) CS-Fusion: Channel-shuffle fusion. (d) In the skip connection, the value ranges of two features (x1, x2) may be significant differences, which impedes effective fusion. (e) The illustration of channel shuffle. the shuffled features (x\u2081h, x3h) have closely matched value ranges.", "description": "This figure details the architecture of the proposed BI-DiffSR model's components for efficient binarization.  (a), (b), and (c) show the consistent-pixel downsample (CP-Down), consistent-pixel upsample (CP-Up), and channel-shuffle fusion (CS-Fusion) modules respectively. These modules maintain dimensional consistency during feature scaling and facilitate effective fusion in skip connections, crucial for handling the information loss inherent in binarization.  (d) illustrates the challenge of typical fusion methods (e.g., concatenation) in the presence of significantly different value ranges in skip connections. (e) demonstrates how the channel shuffle operation in CS-Fusion mitigates this issue by balancing activation ranges before fusion, improving the effectiveness of binarization.", "section": "3.1 Model Structure"}, {"figure_path": "yXpfrLMIr2/figures/figures_5_1.jpg", "caption": "Figure 4: Visualization of the changes in activation distribution across 50 timesteps.", "description": "This figure visualizes how activation distributions change across 50 timesteps in two different modules (ups.8.res_block.block2.block.3 and ups.13.res_block.block2.block.3) of a neural network.  Each subplot shows a box plot representing the distribution of activation values at a given timestep.  The figure demonstrates that the activation distributions change significantly across the 50 timesteps, shifting in both shape and range. This visualization is used to illustrate the challenge of maintaining consistency in the activation distributions throughout the diffusion model's iterative process, especially for binarized modules.", "section": "3.2 Activation Distribution"}, {"figure_path": "yXpfrLMIr2/figures/figures_5_2.jpg", "caption": "Figure 5: (a) The basic binarized convolutional (BI-Conv) block. The learnable bias b and the activation function RPReLU adjust the activations. (b) In timestep-aware redistribution (TaR) and activation function (TaA), multiple pairs of b and RPReLU are applied to adapt to the multi-step in DM. At each step t, only one pair of b and RPReLU is used (the darker modules with solid lines).", "description": "This figure illustrates the architecture of the basic binarized convolutional block and the timestep-aware version.  The basic block (a) uses a learnable bias and RPReLU activation function to adjust the activations before and after a 1-bit convolution. The timestep-aware version (b) extends this by using multiple pairs of bias and RPReLU, where only one pair is active at each timestep, adapting to the changing activation distributions throughout the diffusion process.", "section": "3.2 Activation Distribution"}, {"figure_path": "yXpfrLMIr2/figures/figures_7_1.jpg", "caption": "Figure 6: Activation distribution in the skip connection. Input 1(2): x1, x2. Sum: x1+x2. Fusion 1(2): x\u2081h, x2h.", "description": "This figure compares the activation distributions before and after fusion in a skip connection within the UNet architecture of the BI-DiffSR model. It visually demonstrates the limitations of using simple addition for feature fusion in a binarized network.  The left panel shows that direct addition of features (x1 and x2) leads to a skewed distribution where one input dominates, while the right panel illustrates how the proposed Channel-Shuffle Fusion (CS-Fusion) balances these distributions, resulting in more effective feature integration before being fed into the subsequent binarized convolutional layers.", "section": "3.1 Model Structure"}, {"figure_path": "yXpfrLMIr2/figures/figures_7_2.jpg", "caption": "Figure 7: Weights of biases b<sup>(i)</sup> (i\u2208{1, ..., 5}) in TaR.", "description": "This box plot visualizes the distribution of weights for the five learnable biases (b<sup>(i)</sup>) used in the Timestep-aware Redistribution (TaR) module. Each bias corresponds to one of the five groups of timesteps, showing how the bias values vary across different timesteps. The distribution of bias weights suggests how TaR adapts its functionality to effectively handle variations in activation distributions over the course of the diffusion process.", "section": "3.2 Activation Distribution"}, {"figure_path": "yXpfrLMIr2/figures/figures_8_1.jpg", "caption": "Figure 1: Visual comparison (\u00d74) of binarization methods. Some methods (e.g., BNN [19]) cannot work on diffusion models. Several methods (e.g., BBCU [66]) suffer from blurring and artifacts. In contrast, our proposed BI-DiffSR outperforms other methods with accurate results.", "description": "This figure presents a visual comparison of different image super-resolution methods using binarization techniques.  It shows that many existing binarization methods struggle to generate high-quality results when applied to diffusion models, producing blurry images or artifacts. In contrast, the proposed BI-DiffSR method produces significantly sharper and more accurate results compared to the other techniques.", "section": "1 Introduction"}]