[{"figure_path": "TIhiFqGOYC/figures/figures_1_1.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure compares how humans and large language models (LLMs) respond to two simple questions that share a common underlying generic fact: \"Acid is corrosive\".  The first question is about adding rock to hydrochloric acid, and the second is about acid touching human skin.  Humans correctly answer both questions, demonstrating an understanding of the generic fact and its application to different scenarios. LLMs, however, struggle to consistently apply this generic fact, highlighting a potential weakness in their ability to abstract and reason.", "section": "1 Introduction"}, {"figure_path": "TIhiFqGOYC/figures/figures_2_1.jpg", "caption": "Figure 2: Computation of abstract reasoning metric.", "description": "This figure illustrates the calculation of the abstract reasoning accuracy (AbsAcc) metric.  It shows three generic facts (r1, r2, r3), each supporting multiple examples (s1, s2, s3,...).  For each example, the 'Label' indicates the correct answer, and 'Prediction' shows the model's prediction. A green checkmark signifies a correct prediction, and a red cross indicates an incorrect prediction. The 'Vanilla' accuracy is the overall accuracy calculated considering all examples, while 'AbsAcc' focuses only on whether the model correctly predicts all examples for a given generic fact.  It highlights that AbsAcc offers a more nuanced assessment of abstract reasoning ability than vanilla accuracy.", "section": "2.1 Abstract reasoning metric"}, {"figure_path": "TIhiFqGOYC/figures/figures_3_1.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure shows a comparison of how humans and LLMs respond to questions that rely on a shared generic fact.  Panel (a) demonstrates human reasoning, illustrating the consistent application of the generic fact ('acid is corrosive') to different scenarios (adding rock to acid, acid touching skin). In contrast, panel (b) highlights the inconsistent responses of LLMs, suggesting a deficit in abstract reasoning abilities.  The figure visually represents the core problem addressed in the paper: LLMs struggle to abstract and apply generic facts consistently, unlike humans.", "section": "1 Introduction"}, {"figure_path": "TIhiFqGOYC/figures/figures_7_1.jpg", "caption": "Figure 4: Visualization of reasoning capabilities on MMLU, which is categorized by task domains.", "description": "This radar chart visualizes the performance of different LLMs (LLaMA-2, Orca-2, and MeanLearn) across various sub-domains of the MMLU benchmark.  The chart is split into two main sections: Vanilla Accuracy and Abstract Reasoning Accuracy (AbsAcc). Each section contains two charts, one for 7B parameter models and another for 13B parameter models.  Each chart shows the performance of each LLM in various domains (Physics & Astronomy, Law, Medical, Finance & Management, Society, Politics, Logic & Philosophy, Mathematics, Biology, Computer Science, Engineering, History, Geography, Psychology, and Chemistry). The chart allows for comparison of both general reasoning ability and abstract reasoning skills of LLMs across different model sizes and domains.", "section": "6.1 Performance on different domains"}, {"figure_path": "TIhiFqGOYC/figures/figures_14_1.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure compares how humans and large language models (LLMs) respond to two questions that rely on the same underlying generic fact.  Panel (a) shows that humans consistently and correctly use the generic fact to answer both questions.  Panel (b) shows that LLMs fail to do this consistently, highlighting a shortcoming in their abstract reasoning abilities.", "section": "1 Introduction"}, {"figure_path": "TIhiFqGOYC/figures/figures_15_1.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure shows a comparison of how humans and LLMs respond to two questions that rely on the same generic fact.  Panel (a) illustrates human reasoning, showing consistent and accurate deductions based on understanding the underlying principle. Panel (b) shows LLM responses, highlighting inconsistencies and a lack of flexible application of the generic fact, suggesting a deficit in abstract reasoning ability.", "section": "1 Introduction"}, {"figure_path": "TIhiFqGOYC/figures/figures_15_2.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure uses two subfigures to compare how humans and large language models (LLMs) respond to questions that are based on the same generic fact. Subfigure (a) shows the human responses, demonstrating their ability to apply the generic fact consistently and accurately to different questions.  In contrast, subfigure (b) shows the LLM's responses, highlighting their inconsistent and less accurate application of the generic fact.  This visual comparison demonstrates the gap between human abstract reasoning capabilities and those of current LLMs.", "section": "1 Introduction"}, {"figure_path": "TIhiFqGOYC/figures/figures_17_1.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure compares how humans and LLMs respond to two questions based on a shared generic fact.  Panel (a) shows the human responses, correctly identifying that both adding rock to acid and acid touching skin cause a corrosive effect due to the generic fact that 'acid is corrosive'. Panel (b) illustrates LLM responses which reveal inconsistencies in their ability to apply this generic fact across different scenarios, highlighting a deficiency in abstract reasoning.", "section": "1 Introduction"}, {"figure_path": "TIhiFqGOYC/figures/figures_17_2.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure shows a comparison of how humans and LLMs respond to two questions that share a common underlying generic fact.  Panel (a) illustrates the human responses, demonstrating consistent and accurate answers based on understanding the general principle. Panel (b) depicts the LLM responses, showcasing a lack of consistent application of the generic fact and revealing a gap in abstract reasoning abilities. The difference highlights the key challenge that the paper addresses: teaching LLMs to effectively utilize generic facts for abstract reasoning.", "section": "1 Introduction"}, {"figure_path": "TIhiFqGOYC/figures/figures_17_3.jpg", "caption": "Figure 1: The responses of (a) Humans and (b) LLMs when facing two questions which are supported by the same generic fact.", "description": "This figure compares how humans and large language models (LLMs) respond to two questions that rely on the same generic fact (\"acid is corrosive\").  Panel (a) shows the human responses, demonstrating accurate and consistent application of the generic fact to both scenarios (rock in acid, acid on skin). Panel (b) illustrates that LLMs often fail to consistently apply the generic fact, showcasing a deficiency in abstract reasoning abilities. The responses show that while LLMs can sometimes answer correctly, they struggle to generalize and apply the underlying principle across different situations.", "section": "1 Introduction"}]