[{"figure_path": "ZbjJE6Nq5k/tables/tables_3_1.jpg", "caption": "Table 1: Left: Top-1 prediction accuracy on the test sets of CIFAR-10 and ImageNet-1k. Right: per-token accuracy of a 400M transformer model pretrained on the C4 dataset, evaluated on a variety of language benchmarks. See Appendix C.5 for more results with variation measures.", "description": "This table presents the performance of the proposed method (NaP) on various image classification and language modeling benchmarks.  The left side shows the top-1 accuracy on CIFAR-10 and ImageNet-1k, demonstrating that NaP does not hinder performance on standard image classification tasks. The right side displays the per-token accuracy of a large language model (LLM) evaluated on several downstream language tasks. This part showcases that NaP does not negatively impact the performance of LLMs either.  Appendix C.5 provides additional results.", "section": "Stationary supervised benchmarks"}, {"figure_path": "ZbjJE6Nq5k/tables/tables_8_1.jpg", "caption": "Table 1: Left: Top-1 prediction accuracy on the test sets of CIFAR-10 and ImageNet-1k. Right: per-token accuracy of a 400M transformer model pretrained on the C4 dataset, evaluated on a variety of language benchmarks. See Appendix C.5 for more results with variation measures.", "description": "This table presents the results of experiments evaluating the proposed method (NaP) on image classification and language modeling benchmarks.  The left side shows the top-1 accuracy on CIFAR-10 and ImageNet-1k image classification tasks. The right side displays the per-token accuracy on various language modeling benchmarks (C4 Pile, WikiText, Lambada, SIQA, PIQA) using a large transformer model pre-trained on the C4 dataset.  The baseline and a version using only normalization are included for comparison. Appendix C.5 contains additional results and variation measures for a more complete comparison.", "section": "Stationary supervised benchmarks"}, {"figure_path": "ZbjJE6Nq5k/tables/tables_24_1.jpg", "caption": "Table 1: Left: Top-1 prediction accuracy on the test sets of CIFAR-10 and ImageNet-1k. Right: per-token accuracy of a 400M transformer model pretrained on the C4 dataset, evaluated on a variety of language benchmarks. See Appendix C.5 for more results with variation measures.", "description": "This table presents the results of experiments conducted on image classification and language modeling tasks to evaluate the performance of the proposed Normalize-and-Project (NaP) method. The left side shows the top-1 prediction accuracy on the CIFAR-10 and ImageNet-1k datasets, comparing NaP against a baseline and a model using only normalization. The right side presents the per-token accuracy of a large language model on various benchmarks, also comparing NaP against a baseline.  Appendix C.5 provides additional results and variations.", "section": "Stationary supervised benchmarks"}, {"figure_path": "ZbjJE6Nq5k/tables/tables_25_1.jpg", "caption": "Table 1: Left: Top-1 prediction accuracy on the test sets of CIFAR-10 and ImageNet-1k. Right: per-token accuracy of a 400M transformer model pretrained on the C4 dataset, evaluated on a variety of language benchmarks. See Appendix C.5 for more results with variation measures.", "description": "This table presents the results of applying the Normalize-and-Project (NaP) method to image classification and natural language processing tasks.  The left side shows the top-1 prediction accuracy on the CIFAR-10 and ImageNet-1k datasets, comparing NaP's performance to a baseline and a version using only normalization. The right side displays the per-token accuracy of a large language model (400M parameters) trained on the C4 dataset and evaluated on various language benchmarks (Pile, WikiText, Lambada, SIQA, PIQA).  The results demonstrate that NaP does not negatively impact performance on these standard tasks.", "section": "Stationary supervised benchmarks"}]