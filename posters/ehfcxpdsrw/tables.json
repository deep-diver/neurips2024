[{"figure_path": "ehfCxpDsrw/tables/tables_6_1.jpg", "caption": "Table 1: Indoor sem. seg. on S3DIS Area 5.", "description": "This table presents the results of indoor semantic segmentation on the S3DIS Area 5 dataset. It compares the performance of various methods (PointNet, PointCNN, PointWeb, PointNet++, KPConv, RandLA-Net, PTv1, CBL, PointMeta, ASSANet, Str. Trans., Fast PT, PTv2+, PTv3+, ConDaFormer, PointVector, PointNeXt, and LinNet) in terms of mIoU (mean Intersection over Union), OA (Overall Accuracy), and Acc (Accuracy).  The \"Input\" column specifies the type of input used by each method (point cloud). LinNet and LinNet+ (with test time augmentation) achieve the best results.", "section": "4 Experiments"}, {"figure_path": "ehfCxpDsrw/tables/tables_6_2.jpg", "caption": "Table 2: Outdoor sem. seg. on NuScenes.", "description": "This table presents the performance comparison of different semantic segmentation methods on the NuScenes dataset.  The table shows the input type (point cloud, voxel, or hybrid), validation mIoU, and test mIoU for each method. The methods are a mix of point-based, voxel-based, and hybrid approaches.  LinNet is compared to state-of-the-art methods, showing competitive or superior performance.", "section": "4 Experiments"}, {"figure_path": "ehfCxpDsrw/tables/tables_7_1.jpg", "caption": "Table 3: 3D object classification in ScanObjectNN and ModelNet40. Averaged results in three random runs using 1024 points as input without normals and without voting are reported.", "description": "This table presents a comparison of different 3D object classification methods on two benchmark datasets: ScanObjectNN and ModelNet40.  The results, averaged over three runs, show the overall accuracy (OA) and mean accuracy (mAcc) for each method.  The table also includes model parameters (in millions), FLOPs (in billions), and throughput (in instances per second).  The absence of normals and voting in the experiments is noted.", "section": "4.2 Object classification"}, {"figure_path": "ehfCxpDsrw/tables/tables_8_1.jpg", "caption": "Table 5: Ablation on the DSA design.", "description": "This table presents the ablation study on the Disassembled Set Abstraction (DSA) module. It compares the performance (mIoU) and latency of different variations of the DSA module against a vanilla set abstraction (SA) baseline.  The variations include depthwise separable set abstraction (DSSA), anisotropic separable set abstraction (ASSA), positional pooling (PosPool), average pooling, and the final DSA module.  The results show the impact of each component on both accuracy and efficiency.", "section": "4.4 Ablation Study"}, {"figure_path": "ehfCxpDsrw/tables/tables_9_1.jpg", "caption": "Table 6: Model scalability. Latency and FLOPs are measured with 24k points.", "description": "This table shows the impact of model size on the performance of LinNet.  Three different model sizes (Small, Base, Large) are evaluated, each with varying numbers of channels and depths.  The table presents the model parameters (Param(M)), floating-point operations (FLOPs (G)), inference latency (Latency (ms)), and mean Intersection over Union (mIoU(%)) achieved on a 24k point dataset.  It demonstrates the scalability of LinNet in terms of both efficiency and accuracy.", "section": "4.3 Model Efficiency"}, {"figure_path": "ehfCxpDsrw/tables/tables_9_2.jpg", "caption": "Table 7: Memory footprint during training and inference on the NuScenes dataset.", "description": "This table presents a comparison of the memory usage (both training and inference) for different models on the NuScenes dataset.  It shows that PointNeXt runs out of memory, while LinNet and LinNet-Small have considerably lower memory footprints, highlighting the efficiency of the proposed method.  MinkUNet is included as a baseline for comparison.", "section": "4.3 Model Efficiency"}, {"figure_path": "ehfCxpDsrw/tables/tables_13_1.jpg", "caption": "Table 9: Training setting.", "description": "This table details the hyperparameters used during the training phase for different datasets.  It includes the number of epochs, learning rate, weight decay, scheduler type (Cosine Annealing), optimizer (AdamW), and batch size used for each dataset (ScanObjectNN, ModelNet40, S3DIS, NuScenes, and SemanticKITTI).", "section": "A Experimental Details"}, {"figure_path": "ehfCxpDsrw/tables/tables_14_1.jpg", "caption": "Table 2: Outdoor sem. seg. on NuScenes.", "description": "This table presents the results of outdoor semantic segmentation on the NuScenes dataset.  It compares various methods (listed in the first column) based on their input data type (point cloud, voxel, or hybrid), validation mIoU, and test mIoU.  The results demonstrate the performance of LinNet in comparison to other state-of-the-art approaches for this task.", "section": "4.1 Semantic Segmentation"}, {"figure_path": "ehfCxpDsrw/tables/tables_14_2.jpg", "caption": "Table 1: Indoor sem. seg. on S3DIS Area 5.", "description": "This table presents the results of indoor semantic segmentation on the S3DIS Area 5 dataset.  It compares various methods (PointNet, PointCNN, PointNet++, etc.) in terms of their performance metrics: mIoU (mean Intersection over Union), OA (Overall Accuracy), and Acc (Accuracy).  The 'Input' column indicates whether the method uses point clouds or other representations.  The table highlights the performance of LinNet compared to state-of-the-art methods.", "section": "4.1 Semantic Segmentation"}, {"figure_path": "ehfCxpDsrw/tables/tables_14_3.jpg", "caption": "Table 12: Sem. seg. on Sem. KITTI.", "description": "This table shows the performance of different semantic segmentation methods on the SemanticKITTI dataset.  The table presents the validation and test mIoU scores for each method.  The SemanticKITTI dataset is a challenging benchmark for evaluating the performance of 3D semantic segmentation models, particularly in outdoor environments.", "section": "4.1 Semantic Segmentation"}, {"figure_path": "ehfCxpDsrw/tables/tables_14_4.jpg", "caption": "Table 14: Normalization layer.", "description": "This table presents the ablation study result on the normalization layer used in LinNet. Three different types of normalization layers were tested, including None (no normalization), Batch Normalization (BN), and Layer Normalization (LN). The results are presented in terms of mIoU (mean Intersection over Union), mAcc (mean Accuracy), and OA (Overall Accuracy).  The table shows that BN achieves slightly better performance than both LN and no normalization.", "section": "4.4 Ablation Study"}]