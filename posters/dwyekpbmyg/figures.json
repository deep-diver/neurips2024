[{"figure_path": "dwYekpbmYG/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Illustration of the key idea of concept-guided information bottleneck to enhance the task-relevant information and discard the task-irrelevant information. (b) Task-specific model adaptation with CATE to enhance the generalization across different data sources.", "description": "The figure illustrates the core idea of the Concept Anchor-guided Task-specific Feature Enhancement (CATE) method. (a) shows how CATE uses task-specific concepts to filter out task-irrelevant information from generic image features, focusing on the task-relevant aspects.  (b) demonstrates how CATE improves the generalizability of models across different datasets (data sources) by enhancing task-relevant features while suppressing irrelevant information, leading to better performance and robustness.", "section": "1 Introduction"}, {"figure_path": "dwYekpbmYG/figures/figures_3_1.jpg", "caption": "Figure 2: (a) Overview of CATE: the outputs of the CIB and CFI modules are concatenated to form the enhanced feature for downstream MIL models. (b) Task-relevant concept generation. (c) Concept-guided Information Bottleneck (CIB) module. (c) Concept-Feature Interference (CFI) module.", "description": "This figure illustrates the overall architecture of the Concept Anchor-guided Task-specific Feature Enhancement (CATE) framework.  Panel (a) shows the flow of the process: original WSI patches are passed through an image encoder, then the CIB and CFI modules process the features before being fed into a MIL model. Panel (b) shows the generation of task-relevant concepts using a text encoder. Panels (c) and (d) detail the inner workings of the CIB and CFI modules, respectively, showing how they process features and concept anchors to generate enhanced, task-specific features.", "section": "3 Method"}, {"figure_path": "dwYekpbmYG/figures/figures_8_1.jpg", "caption": "Figure 3: (a) Attention heatmap of CATE-MIL. (b) Attention heatmap of the original ABMIL. (c) similarity between the calibrated features and the corresponding class concept feature. (d) similarity between the original features and the corresponding class concept feature. (e) Original WSI. (f) UMAP visualization of class concept features, original features, and enhanced features.", "description": "This figure presents a comparative analysis of CATE-MIL and ABMIL using attention heatmaps and UMAP visualizations.  It highlights how CATE-MIL improves the focus on cancerous regions (as seen in the heatmaps (a) and (b)). The similarity plots (c) and (d) demonstrate that CATE-MIL aligns features more effectively with concept anchors, particularly for cancerous areas, leading to a clearer separation of cancerous and non-cancerous regions in the UMAP visualization (f).", "section": "4.2 Experimental Results"}, {"figure_path": "dwYekpbmYG/figures/figures_15_1.jpg", "caption": "Figure 3: (a) Attention heatmap of CATE-MIL. (b) Attention heatmap of the original ABMIL. (c) similarity between the calibrated features and the corresponding class concept feature. (d) similarity between the original features and the corresponding class concept feature. (e) Original WSI. (f) UMAP visualization.", "description": "This figure shows a comparison of attention heatmaps and UMAP visualizations for CATE-MIL and ABMIL models applied to breast cancer WSIs. The heatmaps highlight the attention given to different regions of the image by each model, while the UMAP visualization shows how the models cluster features in a lower-dimensional space.  Specifically, the figure illustrates how CATE-MIL enhances focus on cancerous regions and generates more discriminative features. Comparing (c) and (d) shows that CATE-MIL improves similarity between calibrated features and class-specific concept anchors, indicating better task-relevant feature extraction.", "section": "4.2 Experimental Results"}, {"figure_path": "dwYekpbmYG/figures/figures_16_1.jpg", "caption": "Figure 3: (a) Attention heatmap of CATE-MIL. (b) Attention heatmap of the original ABMIL. (c) similarity between the calibrated features and the corresponding class concept feature. (d) similarity between the original features and the corresponding class concept feature. (e) Original WSI. (f) UMAP visualization.", "description": "This figure shows a comparison of attention heatmaps and UMAP visualizations for CATE-MIL and the original ABMIL model.  It highlights how CATE-MIL focuses attention on cancerous regions more effectively than ABMIL. The similarity plots (c, d) demonstrate that CATE-MIL aligns calibrated features more closely with the corresponding class concept features. The UMAP visualization shows that CATE-MIL produces feature embeddings that are more discriminative and closer to the respective class concept features than those produced by ABMIL.", "section": "4.2 Experimental Results"}, {"figure_path": "dwYekpbmYG/figures/figures_20_1.jpg", "caption": "Figure 2: (a) Overview of CATE: the outputs of the CIB and CFI modules are concatenated to form the enhanced feature for downstream MIL models. (b) Task-relevant concept generation. (c) Concept-guided Information Bottleneck (CIB) module. (c) Concept-Feature Interference (CFI) module.", "description": "This figure illustrates the CATE framework, showing the two main modules: CIB and CFI.  The CIB module calibrates the original image features using concept anchors, while the CFI module generates discriminative task-specific features by leveraging similarities between calibrated features and concept anchors.  The final enhanced features are then fed into a downstream MIL model.", "section": "3 Method"}, {"figure_path": "dwYekpbmYG/figures/figures_24_1.jpg", "caption": "Figure 3: (a) Attention heatmap of CATE-MIL. (b) Attention heatmap of the original ABMIL. (c) similarity between the calibrated features and the corresponding class concept feature. (d) similarity between the original features and the corresponding class concept feature. (e) Original WSI. (f) UMAP visualization.", "description": "This figure shows a comparison of heatmaps and UMAP visualizations for CATE-MIL and ABMIL models applied to IDC and ILC cancer subtypes.  The heatmaps illustrate the attention mechanisms in each model, highlighting areas of interest for classification. The UMAP visualizations show the clustering of feature representations from both models, helping to understand how well they distinguish between the subtypes.  The similarity plots quantify the relationship between image features and concept anchors before and after calibration using CATE.", "section": "4.2 Experimental Results"}, {"figure_path": "dwYekpbmYG/figures/figures_25_1.jpg", "caption": "Figure 3: (a) Attention heatmap of CATE-MIL. (b) Attention heatmap of the original ABMIL. (c) similarity between the calibrated features and the corresponding class concept feature. (d) similarity between the original features and the corresponding class concept feature. (e) Original WSI. (f) UMAP visualization of class concept features, original features, and enhanced features.", "description": "This figure provides a visual comparison of the attention heatmaps generated by CATE-MIL and ABMIL, highlighting the differences in focus on relevant image regions.  It also shows the similarity scores (cosine similarity) between image features and class concept features, both before and after the CATE calibration process. Finally, it includes a UMAP visualization that shows how CATE enhances the clustering of features in the feature space, improving the separation of different classes. ", "section": "4.2 Experimental Results"}]