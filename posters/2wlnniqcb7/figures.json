[{"figure_path": "2wlNnIqCb7/figures/figures_1_1.jpg", "caption": "Figure 1: An example of an image from the ManyNames dataset illustrating both semantic and pragmatic communication. Top (semantic setting): A speaker communicates a target object xt (red box) by naming it regardless of the context induced by the image. The ManyNames dataset includes such responses from native English speakers (in this example, 10 speakers produced 'man', 10 'batter', 5 'baseball player', 4 'player', and 3 'person'). Bottom (pragmatic setting): A speaker and a listener observe two objects in an image (red and blue boxes). Only the speaker knows which one is the target xt and which one is the distractor xd. The speaker's goal is to communicate xt given this shared context, and the listener's goal is to discriminate the target from the distractor.", "description": "This figure shows an example from the ManyNames dataset to illustrate the difference between semantic and pragmatic communication.  In the semantic setting (top), a speaker names a target object without considering context.  The image shows a baseball player batting, and several names are given that people provided, such as 'man', 'batter', etc. showing the variability. In the pragmatic setting (bottom), the speaker and listener share the context of seeing two objects.  Only the speaker knows which is the target; the goal is for the speaker to communicate the target object to the listener.", "section": "1 Introduction"}, {"figure_path": "2wlNnIqCb7/figures/figures_3_1.jpg", "caption": "Figure 2: Communication model for the co-evolution of semantics and pragmatics (see Section 3). Agents are trained in a pragmatic setting, where both observe inputs x0, x1 as shared context; one input is randomly selected as target xt for the speaker. After training, the agent's emergent communication systems are evaluated in a lexical semantics setting, without shared context; the speaker observes only xt while xd is masked, and both inputs are masked for the listener.", "description": "This figure shows the architecture of the communication model used in the paper.  The model is trained in a pragmatic setting, where both speaker and listener share contextual information (x0, x1), but only the speaker knows the target object (xt). The speaker uses a Variational Autoencoder (VAE) to generate a representation of both the target (mt) and a distractor (md), then encodes the target representation into a communication signal (w).  The listener also uses a VAE to decode the signal into a representation (mt) and uses this representation to identify the target. The model is then evaluated in a semantic setting, where only the target is shown to the speaker. This evaluates the emergent lexicon (the communication signals) by testing the capacity of the communication signals to convey the meaning of the object to the listener without context.", "section": "3 A unifying model for the co-evolution of semantics and pragmatics"}, {"figure_path": "2wlNnIqCb7/figures/figures_6_1.jpg", "caption": "Figure 3: The information-theoretic landscape of emergent communication. Each simplex shows a test-time evaluation metric using either pragmatic (a) or semantic (b-e) settings, for the range of models spanned by the values of \u03bb = (\u03bb\u03c5, \u03bb\u2081, \u03bbc). Overall, none of the extremes yield human-like communication, and the best alignment with English is achieved for \u03bb > 0 near the top of the simplex. (a) Utility, reflecting the agents' pragmatic competence in solving the discrimination task. (b) Reconstruction loss, measured by the negative MSE between the speaker's and listener's target representations; values closer to 0 correspond to more informative communication (for ease of visualization, the model trained with \u03bb\u03c5 = 1, with negative MSE -20, is ignored in this plot). (c) Complexity, measured by the mutual information between the speaker's inputs and communication signals. The red arrow indicates the complexity of English as estimated from the ManyNames dataset. (d) The effective lexicon size of the emergent systems (i.e., the number of signals that are used with non-zero probabilities). The red arrow indicates the number of unique English terms in the ManyNames dataset. (e) Semantic (mis)alignment between the emergent systems and English, measured by Normalized Information Distance (NID). Lower values correspond to better alignment. (d-e) Insets show the top of the simplex with higher resolution, revealing the importance of \u03bbc > 0 in attaining human-like lexicon sizes and better alignment with English.", "description": "This figure displays the results of the experiment using a simplex to show the tradeoff between utility, informativeness, and complexity, and their effects on the emergent lexicon.  It shows how different weighting of these factors leads to different properties in the resulting communication system,  with a combination of all three factors being required to create a system that best aligns with human language properties. The figure shows that human-like properties emerge from an optimal trade-off between these three factors.", "section": "5 Results"}, {"figure_path": "2wlNnIqCb7/figures/figures_8_1.jpg", "caption": "Figure 3: The information-theoretic landscape of emergent communication. Each simplex shows a test-time evaluation metric using either pragmatic (a) or semantic (b-e) settings, for the range of models spanned by the values of \u03bb = (\u03bb\u03c5, \u03bb\u03b9, \u03bbc). Overall, none of the extremes yield human-like communication, and the best alignment with English is achieved for \u03bb > 0 near the top of the simplex. (a) Utility, reflecting the agents' pragmatic competence in solving the discrimination task. (b) Reconstruction loss, measured by the negative MSE between the speaker's and listener's target representations; values closer to 0 correspond to more informative communication (for ease of visualization, the model trained with \u03bb\u03c5 = 1, with negative MSE -20, is ignored in this plot). (c) Complexity, measured by the mutual information between the speaker's inputs and communication signals. The red arrow indicates the complexity of English as estimated from the ManyNames dataset. (d) The effective lexicon size of the emergent systems (i.e., the number of signals that are used with non-zero probabilities). The red arrow indicates the number of unique English terms in the ManyNames dataset. (e) Semantic (mis)alignment between the emergent systems and English, measure by Normalized Information Distance (NID). Lower values correspond to better alignment. (d-e) Insets show the top of the simplex with higher resolution, revealing the importance of \u03bbc > 0 in attaining human-like lexicon sizes and better alignment with English.", "description": "This figure visualizes the performance of the model across a range of hyperparameter settings, showing how different balances of utility, informativeness, and complexity lead to different outcomes.  The plots illustrate the trade-offs between these factors, and how a balance near the top of the simplex leads to the most human-like results.", "section": "5 Results"}]