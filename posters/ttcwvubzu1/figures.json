[{"figure_path": "TtcwVuBZu1/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of scan strategies for transforming 2D visual data into 1D sequences. (a) naive raster scan [80, 41, 66] ignores the 2D locality; (b) fixed window scan [26] lacks the flexibility to handle visual signals of varying granularities; (c) our learnable window partition and scan strategy adaptively preserves the 2D locality with a focus on the more informative window quadrant; (d) the effective receptive field of our QuadMamba demonstrates more locality than the plain Vision Mamba.", "description": "This figure illustrates different strategies for transforming 2D visual data into 1D sequences suitable for processing by the Mamba model.  (a) shows a naive raster scan which loses spatial information. (b) demonstrates a fixed window scan which lacks flexibility for varying granularity in the image. (c) presents the authors' proposed approach \u2013 learnable window partitioning and scanning \u2013 which adaptively preserves 2D locality by focusing on informative regions. (d) compares the effective receptive field, showing QuadMamba's improved locality compared to Vision Mamba.", "section": "Introduction"}, {"figure_path": "TtcwVuBZu1/figures/figures_3_1.jpg", "caption": "Figure 2: The pipeline of the proposed QuadMamba (a) and its building block: QuadVSS block (b). Similar to the hierarchical vision Transformer, QuadMamba builds stages with multiple blocks, making it flexible to serve as the backbone for vision tasks.", "description": "This figure illustrates the overall architecture of QuadMamba and a detailed breakdown of its core building block, the QuadVSS block.  QuadMamba follows a hierarchical structure similar to vision transformers, with multiple stages each containing several QuadVSS blocks. Each stage progressively reduces the spatial resolution while increasing the channel dimension of the feature maps. The QuadVSS block incorporates a learnable quadtree-based scanning mechanism for efficient feature extraction and modeling of local dependencies.", "section": "4 Method"}, {"figure_path": "TtcwVuBZu1/figures/figures_4_1.jpg", "caption": "Figure 3: Quadtree-based selective scan with prediction modules. Image tokens are partitioned into bi-level window quadrants from coarse to fine. A fully differentiable partition mask is then applied to generate the 1D sequence with negligible computational overhead.", "description": "This figure illustrates the Quadtree-based selective scan method used in QuadMamba.  It shows how image tokens are divided into quadrants, initially at a coarse level (larger quadrants) and then recursively at a finer level (smaller quadrants) based on a learned prediction of their importance.  A differentiable mask is created to select tokens from these quadrants, and these selected tokens are then flattened into a 1D sequence to be processed by the state space model. This approach allows for capturing both local (within quadrants) and global (across quadrants) dependencies efficiently and in a differentiable manner.", "section": "4.2 Quadtree-based Visual State Space Block"}, {"figure_path": "TtcwVuBZu1/figures/figures_5_1.jpg", "caption": "Figure 4: Omnidirectional window shifting scheme.", "description": "This figure illustrates the omnidirectional window shifting scheme used in QuadMamba.  The scheme addresses the issue of informative tokens spanning across adjacent window quadrants.  By shifting the window in two directions (horizontal and vertical), the model can capture more complete and informative features across different local regions, improving the flexibility and accuracy of the quadtree-based partitioning.", "section": "4.2 Quadtree-based Visual State Space Block"}, {"figure_path": "TtcwVuBZu1/figures/figures_9_1.jpg", "caption": "Figure 6: Visualization of partition maps that focus on different regions from shallow to deep blocks.", "description": "This figure visualizes the partition maps generated by the QuadMamba model across different layers (from shallow to deep). It demonstrates how the model focuses on different regions of the input image at various levels of the network. This adaptive focus on different regions is a key aspect of QuadMamba's ability to capture both local and global context in images.", "section": "4.2 Quadtree-based Visual State Space Block"}, {"figure_path": "TtcwVuBZu1/figures/figures_14_1.jpg", "caption": "Figure 2: The pipeline of the proposed QuadMamba (a) and its building block: QuadVSS block (b). Similar to the hierarchical vision Transformer, QuadMamba builds stages with multiple blocks, making it flexible to serve as the backbone for vision tasks.", "description": "The figure shows the overall architecture of QuadMamba and a detailed illustration of its building block, the QuadVSS block.  QuadMamba's architecture is hierarchical, similar to vision transformers, consisting of multiple stages with QuadVSS blocks. Each stage reduces spatial size and increases channel dimensions. The QuadVSS block is composed of several components: a token operator, a feed-forward network (FFN), and two residual connections. The token operator includes a learnable quadtree-based scan to capture local dependencies at different granularities and a Mamba layer for sequence modeling.", "section": "4 Method"}, {"figure_path": "TtcwVuBZu1/figures/figures_16_1.jpg", "caption": "Figure 4: Omnidirectional window shifting scheme.", "description": "The figure illustrates the omnidirectional window shifting scheme used in QuadMamba.  It shows how the model handles informative tokens that might cross the boundaries of adjacent quadrants during the quadtree-based partitioning. By shifting the windows in two directions, the model ensures that it captures more intact and informative features, improving the flexibility and accuracy of the model's understanding of local contexts within the image.", "section": "4.2 Quadtree-based Visual State Space Block"}, {"figure_path": "TtcwVuBZu1/figures/figures_17_1.jpg", "caption": "Figure 9: Details of the three different local window partition resolution configurations.", "description": "This figure illustrates the different window partition resolution configurations used in the QuadMamba model.  It shows three scenarios at both coarse and fine levels. In each scenario, the image is partitioned into quadrants (or windows) of varying sizes to capture local dependencies at different granularities.  The sizes of the quadrants are shown in the figure, with (H, W) representing the original image height and width. The red arrows represent the scanning direction for each level.", "section": "4.2 Quadtree-based Visual State Space Block"}, {"figure_path": "TtcwVuBZu1/figures/figures_19_1.jpg", "caption": "Figure 10: Visualization of partition maps that focus on different regions from shallow to deep blocks. The second column shows the partition score maps in the 1st block.", "description": "This figure visualizes how the quadtree-based partition strategy focuses on different image regions at various depths (layers) of the QuadMamba model. The first column displays example images.  Each row shows the evolution of partition maps (black representing masked-out regions, white/beige representing the selected regions) across eight layers. The second column displays the initial partition score maps in the first layer, guiding the partitioning process. This illustrates the model's ability to progressively refine attention to increasingly fine-grained relevant portions of the image as the network gets deeper.", "section": "4.2 Quadtree-based Visual State Space Block"}, {"figure_path": "TtcwVuBZu1/figures/figures_19_2.jpg", "caption": "Figure 1: Illustration of scan strategies for transforming 2D visual data into 1D sequences. (a) naive raster scan [80, 41, 66] ignores the 2D locality; (b) fixed window scan [26] lacks the flexibility to handle visual signals of varying granularities; (c) our learnable window partition and scan strategy adaptively preserves the 2D locality with a focus on the more informative window quadrant; (d) the effective receptive field of our QuadMamba demonstrates more locality than the plain Vision Mamba.", "description": "This figure illustrates different strategies for converting 2D image data into 1D sequences for processing by a State Space Model.  (a) shows a naive flattening approach that ignores spatial relationships. (b) uses fixed-size windows, limiting adaptability to varying image granularity. (c) presents the authors' proposed method, which uses a learnable quadtree to partition the image and adaptively select informative regions. (d) compares the receptive fields of the authors' model (QuadMamba) and a standard vision Mamba model, highlighting the improved locality preservation in QuadMamba.", "section": "1 Introduction"}]