[{"figure_path": "TtcwVuBZu1/tables/tables_7_1.jpg", "caption": "Table 1: Image classification results on ImageNet-1k. Throughput (images / s) is measured on a single V100 GPU. All models are trained and evaluated on 224x224 resolution.", "description": "This table compares the performance of QuadMamba with other state-of-the-art models on the ImageNet-1k image classification benchmark.  The metrics presented include the number of parameters, floating point operations (FLOPs), top-1 accuracy, and top-5 accuracy.  Throughput, measured in images per second on a single V100 GPU, is also included.  All models were trained and evaluated using 224x224 resolution images.", "section": "5.1 Image Classification on ImageNet-1k"}, {"figure_path": "TtcwVuBZu1/tables/tables_8_1.jpg", "caption": "Table 2: Object detection and instance segmentation results on the COCO val2017 split using the Mask RCNN [19] framework.", "description": "This table presents the performance comparison of various vision backbones on object detection and instance segmentation tasks using the COCO val2017 dataset and the Mask RCNN framework.  Metrics include APbox (average precision for bounding boxes) and Apmask (average precision for masks) at different IoU thresholds (50 and 75).  The table highlights the performance of QuadMamba models compared to other state-of-the-art methods.", "section": "5.2 Object Detection and Instance Segmentation on COCO"}, {"figure_path": "TtcwVuBZu1/tables/tables_8_2.jpg", "caption": "Table 3: Semantic segmentation results on ADE20K using UperNet [62]. mIoUs are measured with single-scale (SS) and multi-scale (MS) testings on the val set. FLOPs are measured with an input size of 512 \u00d7 2048.", "description": "This table presents the results of semantic segmentation experiments on the ADE20K dataset using the UperNet model.  It compares the performance of QuadMamba against various other backbones, including ResNet, DeiT, Swin Transformer, EfficientVMamba, LocalViM, and PlainMamba.  The metrics used are mean Intersection over Union (mIoU) for both single-scale (SS) and multi-scale (MS) testing. FLOPs (floating point operations) and model parameters are also reported, providing insight into computational efficiency.", "section": "5.3 Semantic Segmentation on ADE20K"}, {"figure_path": "TtcwVuBZu1/tables/tables_15_1.jpg", "caption": "Table 7: Our detailed model variants for ImageNet-1k. Here, The definitions are as follows: \"Conv-k_c_s\" denotes convolution layers with kernel size k, output channel c and stride s. \u201cMLP_c\" is the MLP structure with hidden channel 4c and output channel c. And \")(Quad)VSS_n_r\" is the VSS operation with the dimension expansion ratio n and the channel dimension r. \"C\" is 48 for QuadMamba-Li and 64 for QuadMamba-S, and 96 for QuadMamba-B and QuadMamba-L.", "description": "This table details the model variations used for ImageNet-1k experiments in the paper.  It provides a breakdown of the architecture for four different QuadMamba variants: Lite, Small, Base, and Large.  The table shows the structure (convolution layers, QuadVSS/VSS blocks, MLP layers), the number of times each block is repeated (x2, x5, x6, x15), and the channel dimension used at each stage.  Finally, it summarizes the GFLOPs and number of parameters for each model variant.", "section": "A.3 Model Variants"}, {"figure_path": "TtcwVuBZu1/tables/tables_15_2.jpg", "caption": "Table 8: Increased model costs when QuadVSS blocks are applied in the first two stages. The blocks in four stages are (2, 2, 2, 2).", "description": "This table shows the increase in model parameters and FLOPs when QuadVSS blocks are added to the first two stages of the model.  It demonstrates the computational overhead introduced by the Quadtree-based Visual State Space blocks. The baseline configuration uses (2,2,2,2) blocks across the four stages. The table highlights the tradeoff between added complexity and potential performance gains from applying the QuadVSS blocks in earlier stages.", "section": "A.3 Model Variants"}, {"figure_path": "TtcwVuBZu1/tables/tables_16_1.jpg", "caption": "Table 9: Throughputs of QuadMamba variants. Measurements are taken with an A800 GPU.", "description": "This table presents the throughput (images/s) of four different variants of the QuadMamba model (Lite, Tiny, Small, Base) measured using an A800 GPU.  Each variant has a different number of parameters and FLOPs (floating point operations), resulting in varying levels of computational efficiency and speed.", "section": "5 Experiment"}]