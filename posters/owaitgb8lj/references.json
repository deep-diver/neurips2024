{"references": [{"fullname_first_author": "Jonathan Ho", "paper_title": "Denoising diffusion probabilistic models", "publication_date": "2020-12-01", "reason": "This paper is foundational to the field of diffusion models, introducing the core concept and framework that this research builds upon."}, {"fullname_first_author": "Robin Rombach", "paper_title": "High-resolution image synthesis with latent diffusion models", "publication_date": "2021-12-01", "reason": "This paper significantly advanced the capabilities of diffusion models, enabling the generation of high-resolution images and setting a new state-of-the-art."}, {"fullname_first_author": "Itay Hubara", "paper_title": "Binarized neural networks", "publication_date": "2016-12-01", "reason": "This paper introduced binarized neural networks, a crucial technique for model compression that this research extends to the domain of diffusion models."}, {"fullname_first_author": "Mohammad Rastegari", "paper_title": "Xnor-net: Imagenet classification using binary convolutional neural networks", "publication_date": "2016-10-01", "reason": "This paper introduced XNOR-Net, a pioneering work on binary neural networks that provided a foundation for the binarization techniques used in the current paper."}, {"fullname_first_author": "Tim Salimans", "paper_title": "Progressive distillation for fast sampling of diffusion models", "publication_date": "2022-02-01", "reason": "This paper introduced progressive distillation, a key method for efficient training and sampling of diffusion models that is relevant to the proposed techniques."}]}