[{"figure_path": "BpJ6OTfWw3/tables/tables_2_1.jpg", "caption": "Table 2: Link prediction results on FB15k-237, WN18RR, CoDEx-L, and YAGO 3-10. % denotes the Hits @ 10 ratio regard to the anchor-based KGE baseline, i.e., NodePiece + RotatE.", "description": "This table presents the results of link prediction experiments on four benchmark datasets (FB15k-237, WN18RR, CoDEx-L, and YAGO3-10) using the RotatE model with and without the RecPiece anchor selection strategy.  The table shows the MRR (Mean Reciprocal Rank) and Hits@10 scores for each dataset and model, along with the relative improvement in Hits@10 compared to a baseline model using NodePiece.  Parameter counts (#Parameter) and efficiency (Effi.) are also provided.", "section": "4.2 Main Performance (RQ1)"}, {"figure_path": "BpJ6OTfWw3/tables/tables_5_1.jpg", "caption": "Table 2: Link prediction results on FB15k-237, WN18RR, CoDEx-L, and YAGO 3-10. % denotes the Hits @ 10 ratio regard to the anchor-based KGE baseline, i.e., NodePiece + RotatE.", "description": "This table presents the link prediction results of four different datasets (FB15k-237, WN18RR, CoDEx-L, and YAGO 3-10) using three different methods: RotatE, NodePiece + RotatE, and RecPiece + RotatE.  The results are compared in terms of MRR (Mean Reciprocal Rank) and Hits@10, showing the percentage improvement of RecPiece + RotatE over NodePiece + RotatE.  The number of parameters for each model is also listed, and the efficiency (Effi.) is calculated as MRR/#parameters.", "section": "4.2 Main Performance (RQ1)"}, {"figure_path": "BpJ6OTfWw3/tables/tables_5_2.jpg", "caption": "Table 3: Entity classification results on two subsets in WD50k.", "description": "This table presents the results of entity classification experiments conducted on two subsets of the WD50k dataset.  The results compare the performance of several models, including MLP, COMPGCN, NodePiece+COMPGCN, and RecPiece+COMPGCN, across three metrics: ROC-AUC, PRC-AUC, and Hard Accuracy.  The table highlights the improvements achieved by using RecPiece, demonstrating its effectiveness in enhancing entity classification performance.", "section": "4.2 Main Performance (RQ1)"}, {"figure_path": "BpJ6OTfWw3/tables/tables_5_3.jpg", "caption": "Table 9: Dataset Statistic. \"LP\" and \"EC\" denote link prediction and entity classification. \"#\" represents the number.", "description": "This table presents the statistics of six benchmark datasets used in the paper's experiments.  For each dataset, it shows the number of entities (#Ent.), the number of relations (#Rel.), and the total number of facts (#Fact).  The tasks performed on each dataset are also specified: LP for link prediction and EC for entity classification.", "section": "4.1 Experiment Setting"}, {"figure_path": "BpJ6OTfWw3/tables/tables_6_1.jpg", "caption": "Table 5: Ablation study for different anchor selection strategies. \"EP\" and \"RP\" represent entity prediction and relation prediction. \"NDC\" and \"PPR\" are short for Node Degree Centrality and Personalized PageRank.", "description": "This table presents the ablation study on different anchor selection strategies. It compares the performance of RecPiece against other strategies like Random Selection, Node Degree Centrality (NDC), and Personalized PageRank (PPR). The results are shown for both entity prediction (EP) and relation prediction (RP) tasks using metrics like MRR and Hits@10.  The comparison highlights the effectiveness of RecPiece's relational clustering-based anchor selection strategy in improving performance.", "section": "4.3.1 Anchor Selection Strategies"}, {"figure_path": "BpJ6OTfWw3/tables/tables_6_2.jpg", "caption": "Table 6: Ablation study for whether pretrained based on language models. \"KG-self\" and \"PLM\" represent that the pretrained features are generated on structure information and extra-textual information, respectively.", "description": "This ablation study investigates the impact of using pretrained language models for feature preparation in RecPiece.  It compares the performance of RecPiece when using features pretrained using only knowledge graph structural information (\"KG-self\") versus using features pretrained with external textual information (\"PLM\"). The results are shown in terms of MRR and Hits@10 metrics, demonstrating the relative effectiveness of each pretraining approach on the link prediction task.", "section": "4.3 Ablation Studies (RQ2)"}, {"figure_path": "BpJ6OTfWw3/tables/tables_6_3.jpg", "caption": "Table 7: Ablation study for different clustering features. \"triplet\" and \"entity\" represent clustering over the features of relational triplets and entities, respectively. All the results are for link prediction results on FB15k-237", "description": "This table presents the results of an ablation study comparing two different clustering feature methods (triplet and entity features) used in the RecPiece model for link prediction on the FB15k-237 dataset.  It shows the MRR and Hits@10 scores for the RotatE model alone, the NodePiece + RotatE baseline, and RecPiece using each of the two clustering feature types.", "section": "4.3 Ablation Studies (RQ2)"}, {"figure_path": "BpJ6OTfWw3/tables/tables_8_1.jpg", "caption": "Table 8: Link prediction results on OGB WikiKG 2. The best results are marked in Bold.", "description": "This table presents the results of link prediction experiments on the OGB WikiKG-2 dataset.  It compares the performance of RecPiece + AutoSF against several other state-of-the-art knowledge graph embedding (KGE) models. The models are evaluated based on the MRR metric and the number of parameters used. The table highlights that RecPiece + AutoSF achieves a higher MRR with significantly fewer parameters than the other models, demonstrating its efficiency and scalability.", "section": "4.5 Scalability Analysis (RQ4)"}, {"figure_path": "BpJ6OTfWw3/tables/tables_17_1.jpg", "caption": "Table 9: Dataset Statistic. \"LP\" and \"EC\" denote link prediction and entity classification. \"#\" represents the number.", "description": "This table presents the statistics of six benchmark datasets used in the paper's experiments.  It shows the number of entities, relationships, edges, and the split of the data into training, validation, and test sets for each dataset. The tasks performed on each dataset (link prediction or entity classification) are also indicated.", "section": "4.1 Experiment Setting"}]