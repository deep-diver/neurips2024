[{"figure_path": "HGNTcy4eEp/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of our latent space group action model.", "description": "This figure illustrates the architecture of the proposed latent space group action model. The model consists of an encoder, an attention module, a group action module, and a decoder. The encoder takes an input image and encodes it into a latent representation. The attention module processes the latent representation and generates query, key and value vectors. The group action module applies a group action to the latent representation. Finally, the decoder takes the modified latent representation and generates the output image.", "section": "3 Group actions on latent representations"}, {"figure_path": "HGNTcy4eEp/figures/figures_5_1.jpg", "caption": "Figure 3: Data samples used in the experiments. Each column represents a pair related by a group action, i.e., x\u2081 = g.x\u2082.", "description": "This figure shows example pairs of images from the five datasets used in the paper's experiments. Each column represents a dataset, and each row shows a pair of images related by a group action (e.g., rotation, contrast change).  The pairs demonstrate the various types of group actions that the proposed model handles. For instance, the 'Rotated MNIST' shows rotated images of the digit '7', while 'Rotated and blocked MNIST' shows the same digit with an added block, demonstrating that the group action is on the digit itself, and not just the visual appearance of the image.", "section": "6 Experiments"}, {"figure_path": "HGNTcy4eEp/figures/figures_7_1.jpg", "caption": "Figure 4: Sample reconstructions on MNIST derived datasets and brain MRI dataset", "description": "This figure shows the qualitative results of the proposed latent space group action model and two baselines (Hwang et al. and Winter et al.) on three datasets: Rotated MNIST, Rotated and blocked MNIST, and Brain MRI.  For each dataset, the \"Inputs\" row shows example input images. Subsequent rows show the reconstructions generated by each model. The \"Ground truth\" row shows the corresponding target images. The figure demonstrates the superior performance of the proposed method in generating visually accurate reconstructions, particularly in capturing finer details and dealing with occlusion (as in Rotated and blocked MNIST).", "section": "6 Experiments"}, {"figure_path": "HGNTcy4eEp/figures/figures_7_2.jpg", "caption": "Figure 5: Sample reconstructions on NMR dataset and plane in the sky dataset", "description": "This figure shows the reconstruction results of two 3D object datasets: NMR dataset and Plane in the sky dataset.  For each dataset, the input images are shown in the top row, followed by reconstruction results from three different models: Dupont et al., Sajjadi et al., and the proposed model. The ground truth images are displayed in the bottom row. The NMR dataset contains rendered 3D objects from various viewpoints, whereas the Plane in the sky dataset shows images of airplanes against a sky backdrop, under different rotations. The figure visually demonstrates the relative performance of each model on reconstructing images based on group actions in the latent space. The proposed model showcases better performance overall in terms of detail and visual fidelity.", "section": "Experiments"}, {"figure_path": "HGNTcy4eEp/figures/figures_9_1.jpg", "caption": "Figure 6: Samples from ablation models and our full model.", "description": "This figure visually compares the results of different ablation studies on the 3D object rendering dataset.  Each row represents a different object (gun, car, chair, airplane). The \"Inputs\" column shows the original input image. The subsequent columns show the reconstructions generated by different model variations:\n\n* **Ablation 1:**  Model without skip connections and LPIPS loss.\n* **Ablation 2:** Model without skip connections.\n* **Ablation 3:** Model without LPIPS loss.\n* **Full:** The complete model with skip connections and LPIPS loss.\n* **Ground truth:** The original, correctly rendered image.\n\nThe figure demonstrates the impact of skip connections and LPIPS loss on reconstruction quality. The \"Full\" model generally produces the best reconstructions, highlighting the importance of these components in achieving high-quality results.", "section": "6.3 Ablation study"}, {"figure_path": "HGNTcy4eEp/figures/figures_9_2.jpg", "caption": "Figure 7: Samples generated by swapping invariant and varying parts of latent representations.", "description": "This figure demonstrates the model's ability to disentangle invariant and varying factors in latent representations. By swapping the invariant and varying components of latent representations between two input images and decoding the results, the model generates new combinations of features. This showcases the model's capacity to generalize to unseen combinations of factors, indicating a successful disentanglement of the latent space.", "section": "6.3 Ablation study"}]