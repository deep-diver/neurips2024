[{"figure_path": "vI1WqFn15v/tables/tables_7_1.jpg", "caption": "Table 1: Performance evaluation of combining Self-Reminder and Gradient Cuff.  and mean the largest and the second largest TPR, respectively.", "description": "This table presents the results of combining the Self-Reminder and Gradient Cuff defense methods. It shows the False Positive Rate (FPR) and True Positive Rate (TPR) for both methods on two different language models, LLaMA2-7B-Chat and Vicuna-7B-V1.5. The results demonstrate the complementary nature of the two methods, where combining them leads to improved performance compared to using each individually.  The table also highlights that Gradient Cuff achieves superior performance over Self-Reminder when used alone.", "section": "4 Experiments"}, {"figure_path": "vI1WqFn15v/tables/tables_7_2.jpg", "caption": "Table 2: Performance comparison with supervised methods.", "description": "This table compares the performance of Gradient Cuff against two supervised methods, LLaMA-Guard and Safe-Decoding, in terms of both True Positive Rate (TPR) and False Positive Rate (FPR).  It shows the effectiveness of Gradient Cuff in relation to other approaches that require training additional models.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/tables/tables_8_1.jpg", "caption": "Table 3: Performance evaluation of Gradient Cuff and Gradient Cuff (w/o 2nd stage). We remove the second stage or adjust the detection threshold of the 2nd stage to show its significance.", "description": "This table presents the results of an ablation study on the Gradient Cuff method.  It compares the performance of the full Gradient Cuff method with a version that excludes the second stage (Gradient Norm Rejection) and versions with different thresholds (\u03c3) for the second stage.  The results show the impact of the second stage and different thresholds on the False Positive Rate (FPR) and True Positive Rate (TPR).", "section": "4.3 Effectiveness of Gradient Norm Rejection"}, {"figure_path": "vI1WqFn15v/tables/tables_8_2.jpg", "caption": "Table 4: Performance evaluation under adaptive attacks. The reported value is Gradient Cuff's refusal rate against the corresponding jailbreak attack.", "description": "This table presents the results of evaluating Gradient Cuff's performance against adaptive attacks.  Adaptive attacks are versions of existing attacks (PAIR, TAP, GCG) that are modified to try and circumvent the defense mechanism. The \"w/o\" column shows the refusal rate (percentage of malicious queries successfully rejected) before the adaptive attack is applied, while the \"w/\" column shows the refusal rate after the adaptive attack.  A lower refusal rate after the adaptive attack indicates that the adaptive attack was successful at bypassing the defense.", "section": "4.4 Adaptive Attack"}, {"figure_path": "vI1WqFn15v/tables/tables_8_3.jpg", "caption": "Table 2: Performance comparison with supervised methods.", "description": "This table compares the performance of Gradient Cuff against two supervised methods, LLaMA-Guard and Safe-Decoding, in terms of True Positive Rate (TPR) and False Positive Rate (FPR) on two language models: LLaMA-2-7B-Chat and Vicuna-7B-V1.5.  It shows the effectiveness of Gradient Cuff even when compared to supervised methods.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/tables/tables_15_1.jpg", "caption": "Table A1: Attack Success Rate computed by GPT-4 and LLaMA-Guard.", "description": "This table presents the attack success rates (ASR) computed using two different methods: GPT-4 and LLaMA-Guard.  The results show the ASR for Gradient Cuff, SmoothLLM, PPL, and the baseline (without defense) on two language models: LLaMA-2-7B-Chat and Vicuna-7B-V1.5.  The GPT-4 ASR uses GPT-4 to judge whether the model's response is jailbroken, while the LLaMA-Guard ASR uses the LLaMA-Guard model for the same purpose. Lower ASR values indicate better performance.", "section": "A.6 Attack Success Rate for Aligned LLMs"}, {"figure_path": "vI1WqFn15v/tables/tables_17_1.jpg", "caption": "Table 2: Performance comparison with supervised methods.", "description": "This table compares the performance of Gradient Cuff with two supervised methods (LLaMA-Guard and Safe-Decoding) in terms of True Positive Rate (TPR) and False Positive Rate (FPR).  The TPR represents the model's ability to correctly identify malicious queries, while the FPR represents the rate of incorrectly identifying benign queries as malicious.  Lower FPR and higher TPR are desired. The results are shown for both LLaMA2-7B-Chat and Vicuna-7B-V1.5 language models.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/tables/tables_17_2.jpg", "caption": "Table 1: Performance evaluation of combining Self-Reminder and Gradient Cuff.  and mean the largest and the second largest TPR, respectively.", "description": "This table presents the results of combining the Self-Reminder and Gradient Cuff methods. It shows the false positive rate (FPR) and true positive rate (TPR) for both methods on two language models (LLaMA2-7B-Chat and Vicuna-7B-V1.5). The table demonstrates that Gradient Cuff significantly improves the performance of Self-Reminder, especially in terms of TPR.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/tables/tables_17_3.jpg", "caption": "Table 2: Performance comparison with supervised methods.", "description": "This table compares the performance of Gradient Cuff with two supervised methods, LLaMA-Guard and Safe-Decoding, in terms of True Positive Rate (TPR) and False Positive Rate (FPR) for malicious and benign user queries on LLaMA2-7B-Chat and Vicuna-7B-V1.5.  It demonstrates the effectiveness of Gradient Cuff against other methods. ", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/tables/tables_18_1.jpg", "caption": "Table A5: Gradient Norm distribution of GCG prompts and Adaptive GCG prompts.", "description": "This table shows the gradient norm distribution of GCG prompts and adaptive GCG prompts for two LLMs: LLaMA-2-7B-Chat and Vicuna-7B-V1.5.  The gradient norm is a measure used in the Gradient Cuff method to detect jailbreak attempts.  The table presents the 25th, 50th, and 75th percentiles of the gradient norm for both standard GCG attacks and adaptive GCG attacks, along with the detection threshold used by Gradient Cuff for each LLM. The data highlights the differences in gradient norm between benign and malicious queries which is exploited by Gradient Cuff for improved jailbreak detection.", "section": "A.12 Proof of Theorem 1"}, {"figure_path": "vI1WqFn15v/tables/tables_19_1.jpg", "caption": "Table A6: (N,P) combinations when increasing query times", "description": "This table shows different combinations of N (LLM Response Sampling numbers) and P (Gaussian vector numbers) used in the Gradient Cuff algorithm when the total query times (q = N \u00d7 (P + 1)) are increased from 10 to 40. It illustrates two strategies for increasing q: 'fixed-N' keeps N constant while increasing P and 'fixed-P' keeps P constant while increasing N.  Each strategy's total query times and the corresponding (N, P) values are provided.", "section": "A.13 Ablation study on P and N in Gradient Cuff"}, {"figure_path": "vI1WqFn15v/tables/tables_21_1.jpg", "caption": "Table 2: Performance comparison with supervised methods.", "description": "This table compares the performance of Gradient Cuff against two supervised methods, namely LLaMA-Guard and Safe-Decoding.  The comparison is done in terms of False Positive Rate (FPR) and True Positive Rate (TPR), which represent the rate of rejecting benign queries and the rate of detecting malicious queries, respectively. The results are shown separately for LLaMA2-7B-Chat and Vicuna-7B-V1.5 models.  The table demonstrates Gradient Cuff's performance against these supervised baselines.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/tables/tables_23_1.jpg", "caption": "Table A8: Performance evaluation on non-LLaMA-based language models.", "description": "This table presents the performance comparison of Gradient Cuff, PPL, and SmoothLLM on two non-LLaMA-based language models, gemma-7b-it and Qwen2-7B-Instruct, against two types of attacks: GCG (transferred from Vicuna-7b-v1.5) and Base64. The results are shown in terms of refusal rates (higher is better), including the average refusal rate across both attacks for each model and defense method.", "section": "A.17 Defending Jailbreaks for non LLaMA-based Inaguage models"}]