[{"figure_path": "vI1WqFn15v/figures/figures_1_1.jpg", "caption": "Figure 1: Overview of Gradient Cuff. (a) introduces an example of jailbreak prompts by presenting a conversation between malicious actors and the Vicuna chatbot. (b) visualizes the refusal loss landscape for malicious queries and benign queries by plotting the interpolation of two random directions in the query embedding with coefficients \u03b1 and \u03b2 following [15]. The refusal loss evaluates the probability that the LLM would not directly reject the input query, and the loss value is computed using Equation 3. See details of how to plot (b) in Appendix A.4. (c) shows the running flow of Gradient Cuff (at top), practical computing examples for refusal loss (at bottom left), and the distributional difference of the gradient norm of refusal loss on benign and malicious queries (bottom right). (d) shows the performance of Gradient Cuff against 6 jailbreak attacks for Vicuna-7B-V1.5. See Appendix A.6 for full results.", "description": "This figure provides a comprehensive overview of the Gradient Cuff method. Panel (a) illustrates a jailbreak attack example using a conversation between a malicious user and the Vicuna chatbot. Panel (b) visualizes the refusal loss landscape for both malicious and benign queries, revealing distinct properties. Panel (c) presents the Gradient Cuff's two-step detection process, showing refusal loss calculation and gradient norm analysis. Panel (d) shows the effectiveness of Gradient Cuff against six different jailbreak attacks on the Vicuna-7B-V1.5 model.", "section": "Methodology and Algorithms"}, {"figure_path": "vI1WqFn15v/figures/figures_6_1.jpg", "caption": "Figure 2: Performance evaluation on LLaMA2-7B-Chat (a) and Vicuna-7B-V1.5 (b). The horizon axis represents the refusal rate of benign user queries (FPR), and the vertical axis shows the average refusal rate across 6 malicious user query datasets (TPR). The error bar shows the standard deviation between the refusal rate of these 6 jailbreak datasets. We also report the MMLU accuracy of Low-FPR methods to show their utility. Complete results can be found in Appendix A.9.", "description": "This figure shows the performance of Gradient Cuff and other defense methods against 6 different types of jailbreak attacks on two language models: LLaMA2-7B-Chat and Vicuna-7B-V1.5.  The x-axis represents the false positive rate (FPR), indicating how often benign queries were incorrectly flagged as malicious. The y-axis represents the true positive rate (TPR), showing how often malicious queries were correctly identified. The graph illustrates that Gradient Cuff achieves a high TPR while maintaining a low FPR, outperforming other methods.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/figures/figures_9_1.jpg", "caption": "Figure 1: Overview of Gradient Cuff. (a) introduces an example of jailbreak prompts by presenting a conversation between malicious actors and the Vicuna chatbot. (b) visualizes the refusal loss landscape for malicious queries and benign queries by plotting the interpolation of two random directions in the query embedding with coefficients \u03b1 and \u03b2 following [15]. The refusal loss evaluates the probability that the LLM would not directly reject the input query, and the loss value is computed using Equation 3. See details of how to plot (b) in Appendix A.4. (c) shows the running flow of Gradient Cuff (at top), practical computing examples for refusal loss (at bottom left), and the distributional difference of the gradient norm of refusal loss on benign and malicious queries (bottom right). (d) shows the performance of Gradient Cuff against 6 jailbreak attacks for Vicuna-7B-V1.5. See Appendix A.6 for full results.", "description": "This figure provides a comprehensive overview of the Gradient Cuff method. Panel (a) illustrates a jailbreak attack scenario, while panel (b) visualizes the refusal loss landscape for both benign and malicious queries. Panel (c) details the Gradient Cuff workflow, and panel (d) presents the method's performance against various jailbreak attacks on the Vicuna-7B-V1.5 model.  The figure demonstrates the key aspects of Gradient Cuff, from its conceptual basis to its empirical performance.", "section": "Methodology and Algorithms"}, {"figure_path": "vI1WqFn15v/figures/figures_9_2.jpg", "caption": "Figure 2: Performance evaluation on LLaMA2-7B-Chat (a) and Vicuna-7B-V1.5 (b). The horizon axis represents the refusal rate of benign user queries (FPR), and the vertical axis shows the average refusal rate across 6 malicious user query datasets (TPR). The error bar shows the standard deviation between the refusal rate of these 6 jailbreak datasets. We also report the MMLU accuracy of Low-FPR methods to show their utility. Complete results can be found in Appendix A.9.", "description": "The figure shows the performance of Gradient Cuff and baseline methods on two LLMs (LLaMA2-7B-Chat and Vicuna-7B-V1.5) against six types of jailbreak attacks.  The x-axis represents the false positive rate (FPR, benign query rejection rate), and the y-axis represents the true positive rate (TPR, malicious query rejection rate).  The plot helps to visually compare the effectiveness of different methods in terms of their ability to detect jailbreaks while minimizing false positives.  The MMLU accuracy is also provided to illustrate the tradeoff between security and model performance.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/figures/figures_15_1.jpg", "caption": "Figure 1: Overview of Gradient Cuff. (a) introduces an example of jailbreak prompts by presenting a conversation between malicious actors and the Vicuna chatbot. (b) visualizes the refusal loss landscape for malicious queries and benign queries by plotting the interpolation of two random directions in the query embedding with coefficients \u03b1 and \u03b2 following [15]. The refusal loss evaluates the probability that the LLM would not directly reject the input query, and the loss value is computed using Equation 3. See details of how to plot (b) in Appendix A.4. (c) shows the running flow of Gradient Cuff (at top), practical computing examples for refusal loss (at bottom left), and the distributional difference of the gradient norm of refusal loss on benign and malicious queries (bottom right). (d) shows the performance of Gradient Cuff against 6 jailbreak attacks for Vicuna-7B-V1.5. See Appendix A.6 for full results.", "description": "This figure provides a comprehensive overview of the Gradient Cuff method. Panel (a) illustrates a jailbreak attack scenario. Panel (b) visualizes the refusal loss landscape for both benign and malicious queries. Panel (c) shows the workflow of Gradient Cuff and examples of refusal loss calculation. Finally, panel (d) presents the performance evaluation of Gradient Cuff against various jailbreak attacks.", "section": "Methodology and Algorithms"}, {"figure_path": "vI1WqFn15v/figures/figures_19_1.jpg", "caption": "Figure 1: Overview of Gradient Cuff. (a) introduces an example of jailbreak prompts by presenting a conversation between malicious actors and the Vicuna chatbot. (b) visualizes the refusal loss landscape for malicious queries and benign queries by plotting the interpolation of two random directions in the query embedding with coefficients \u03b1 and \u03b2 following [15]. The refusal loss evaluates the probability that the LLM would not directly reject the input query, and the loss value is computed using Equation 3. See details of how to plot (b) in Appendix A.4. (c) shows the running flow of Gradient Cuff (at top), practical computing examples for refusal loss (at bottom left), and the distributional difference of the gradient norm of refusal loss on benign and malicious queries (bottom right). (d) shows the performance of Gradient Cuff against 6 jailbreak attacks for Vicuna-7B-V1.5. See Appendix A.6 for full results.", "description": "This figure provides a comprehensive overview of the Gradient Cuff method. Panel (a) illustrates a jailbreak attack example using a conversation between malicious actors and the Vicuna chatbot. Panel (b) visualizes the refusal loss landscape for both benign and malicious queries, highlighting the differences in their values and smoothness.  Panel (c) outlines the Gradient Cuff's two-step detection process, showing how refusal loss and its gradient norm are calculated. Finally, panel (d) presents a bar chart showing the effectiveness of Gradient Cuff against 6 different jailbreak attacks on the Vicuna-7B-V1.5 model.", "section": "Methodology and Algorithms"}, {"figure_path": "vI1WqFn15v/figures/figures_20_1.jpg", "caption": "Figure 2: Performance evaluation on LLaMA2-7B-Chat (a) and Vicuna-7B-V1.5 (b). The horizon axis represents the refusal rate of benign user queries (FPR), and the vertical axis shows the average refusal rate across 6 malicious user query datasets (TPR). The error bar shows the standard deviation between the refusal rate of these 6 jailbreak datasets. We also report the MMLU accuracy of Low-FPR methods to show their utility. Complete results can be found in Appendix A.9.", "description": "This figure shows the performance of Gradient Cuff and other baseline methods on two different language models, LLaMA2-7B-Chat and Vicuna-7B-V1.5.  It compares the true positive rate (TPR, correctly identifying malicious queries) against the false positive rate (FPR, incorrectly rejecting benign queries).  The plots illustrate the trade-off between effectively detecting malicious queries and maintaining good performance on benign queries.  Error bars represent the standard deviation across six different types of jailbreak attacks.  The MMLU accuracy is also included to show the impact of each method on the model's overall performance.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}, {"figure_path": "vI1WqFn15v/figures/figures_20_2.jpg", "caption": "Figure 1: Overview of Gradient Cuff. (a) introduces an example of jailbreak prompts by presenting a conversation between malicious actors and the Vicuna chatbot. (b) visualizes the refusal loss landscape for malicious queries and benign queries by plotting the interpolation of two random directions in the query embedding with coefficients \u03b1 and \u03b2 following [15]. The refusal loss evaluates the probability that the LLM would not directly reject the input query, and the loss value is computed using Equation 3. See details of how to plot (b) in Appendix A.4. (c) shows the running flow of Gradient Cuff (at top), practical computing examples for refusal loss (at bottom left), and the distributional difference of the gradient norm of refusal loss on benign and malicious queries (bottom right). (d) shows the performance of Gradient Cuff against 6 jailbreak attacks for Vicuna-7B-V1.5. See Appendix A.6 for full results.", "description": "This figure provides a comprehensive overview of the Gradient Cuff method. Panel (a) illustrates a jailbreak attack scenario. Panel (b) visualizes the refusal loss landscape for both benign and malicious queries, highlighting key differences. Panel (c) details the workflow of Gradient Cuff, including the two-step rejection process based on refusal loss and gradient norm. Finally, panel (d) presents experimental results demonstrating the effectiveness of Gradient Cuff against six different jailbreak attacks on Vicuna-7B-V1.5.", "section": "Methodology and Algorithms"}, {"figure_path": "vI1WqFn15v/figures/figures_23_1.jpg", "caption": "Figure 2: Performance evaluation on LLaMA2-7B-Chat (a) and Vicuna-7B-V1.5 (b). The horizon axis represents the refusal rate of benign user queries (FPR), and the vertical axis shows the average refusal rate across 6 malicious user query datasets (TPR). The error bar shows the standard deviation between the refusal rate of these 6 jailbreak datasets. We also report the MMLU accuracy of Low-FPR methods to show their utility. Complete results can be found in Appendix A.9.", "description": "This figure shows the performance of Gradient Cuff and other defense methods on two different LLMs (LLaMA2-7B-Chat and Vicuna-7B-V1.5) against six types of jailbreak attacks.  The x-axis represents the false positive rate (FPR), or the rate at which benign queries are incorrectly rejected. The y-axis represents the true positive rate (TPR), or the rate at which malicious queries are correctly rejected.  The chart visually compares the effectiveness of different methods at balancing high accuracy in detecting malicious queries with a low rate of false positives.  MMLU accuracy scores are also provided for methods with low FPR, demonstrating that maintaining model utility isn't sacrificed.", "section": "4.2 Performance Evaluation and Comparison with Existing Methods"}]