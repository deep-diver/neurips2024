[{"figure_path": "FDfrPugkGU/figures/figures_1_1.jpg", "caption": "Figure 1: (a) Conventional FIT (with LoRA): directly expands from intra-domain to inter-domain settings. (b) DoFIT-base (with catastrophic forgetting): aggregates overlapping modules among the top-k important modules from different domains on the inter-domain server side and completes the personalized initialization of the updating weight matrix on the intra-domain server side by assigning values to corresponding modules while keeping the rest unchanged. (c) DoFIT (with alleviated catastrophic forgetting): further integrates a proximal perturbation initialization strategy into the DoFIT-base for alleviating catastrophic forgetting in terms of domain information.", "description": "This figure illustrates the difference between conventional FIT and the proposed DoFIT method in handling domain-aware data heterogeneity. (a) shows conventional FIT, which directly expands from intra-domain to inter-domain settings without considering the domain differences. (b) shows DoFIT-base, which aggregates overlapping modules from different domains on the inter-domain server side and initializes updating weights on the intra-domain side. (c) shows the complete DoFIT method, which incorporates a proximal perturbation initialization strategy to alleviate catastrophic forgetting by better preserving domain information.  The figure highlights the key differences in aggregation and initialization strategies between conventional FIT and the proposed DoFIT.", "section": "3. Methodology"}, {"figure_path": "FDfrPugkGU/figures/figures_1_2.jpg", "caption": "Figure 2: Performance effect of conventional FIT trained on Specific domain (i.e., Finance) and Finance&General domain. FinGPT [36] and Alpaca-GPT4 [23] are the training datasets on Finance domain and General domain, respectively. FPB [19], FiQA-SA [18], TFNS [17], and NWGI [33] are all the evaluation datasets on Finance domain. Avg:3 and Avg:4 denote the average result on the first three evaluation datasets (i.e., FPB, FiQA-SA, and TFNS) and all the evaluation datasets, respectively.", "description": "This figure compares the performance of conventional federated instruction tuning (FIT) when trained on a single domain (Finance) versus multiple domains (Finance and General).  It shows accuracy and F1 scores on various evaluation datasets (FPB, FiQA-SA, TFNS, NWGI) for models trained on different datasets (FinGPT for Finance, Alpaca-GPT4 for General).  The average scores across three datasets (Avg:3) and all four datasets (Avg:4) are also presented.", "section": "1 Introduction"}, {"figure_path": "FDfrPugkGU/figures/figures_6_1.jpg", "caption": "Figure 3: Loss curves for different methods, i.e., FIT, DoFIT-base, and DoFIT, in F&G (left) and M&G (right) domains, respectively.", "description": "This figure shows the loss curves for three different federated instruction tuning methods: FIT (conventional FIT), DoFIT-base, and DoFIT.  The left panel displays the loss curves for the Finance & General (F&G) domain, while the right panel shows the loss curves for the Medical & General (M&G) domain. The curves illustrate how the loss decreases over training rounds for each method, providing a visual comparison of their performance in reducing loss during cross-domain collaborative training. DoFIT consistently demonstrates faster convergence and lower final loss compared to the other two methods, highlighting its effectiveness in mitigating catastrophic forgetting.", "section": "4 Experiments"}, {"figure_path": "FDfrPugkGU/figures/figures_8_1.jpg", "caption": "Figure 4: Loss curves for values of Top-k on F&G (left) and M&G (right) domains, respectively.", "description": "This figure displays the loss curves for different values of the top-k parameter in the DoFIT model.  The left panel shows the results for the Finance & General (F&G) domains, while the right panel shows the results for the Medical & General (M&G) domains. The x-axis represents the number of training rounds, and the y-axis represents the loss value. Different colored lines represent different values of the top-k parameter. This figure helps to illustrate how the choice of the top-k parameter affects the model's performance during training.", "section": "4.1 Experimental Settings"}, {"figure_path": "FDfrPugkGU/figures/figures_8_2.jpg", "caption": "Figure 3: Loss curves for different methods, i.e., FIT, DoFIT-base, and DoFIT, in F&G (left) and M&G (right) domains, respectively.", "description": "This figure shows the training loss curves for three different methods: conventional Federated Instruction Tuning (FIT), the DoFIT-base, and the proposed DoFIT method. The curves are plotted for two different domain settings: Finance & General (F&G) and Medical & General (M&G).  The plots visualize the training loss over a number of rounds, demonstrating the convergence speed and stability of each method in different domain settings.", "section": "4 Experiments"}, {"figure_path": "FDfrPugkGU/figures/figures_13_1.jpg", "caption": "Figure 3: Loss curves for different methods, i.e., FIT, DoFIT-base, and DoFIT, in F&G (left) and M&G (right) domains, respectively.", "description": "This figure shows the training loss curves for three different methods: FIT (conventional Federated Instruction Tuning), DoFIT-base (a baseline domain-aware method), and DoFIT (the proposed method).  The left panel shows the loss curves for the Finance & General domain combination (F&G), while the right panel displays the loss curves for the Medical & General domain combination (M&G).  The plots illustrate the convergence speed and final loss achieved by each method, demonstrating DoFIT's superior performance in reducing training loss.", "section": "4 Experiments"}, {"figure_path": "FDfrPugkGU/figures/figures_14_1.jpg", "caption": "Figure 7: Modules important scores (left) and singular value spectrum (right) on F and G domains", "description": "This figure visualizes the importance scores of modules and their singular value spectrum across different rounds for two domains (F and G). The left panel shows a heatmap representing the importance scores of modules across rounds, while the right panel displays bar charts comparing the singular value spectrum for selected clients in both domains.  These visualizations aim to illustrate the differences in module importance and singular value distribution between the two domains, providing insights into the model's learning behavior and the impact of DoFIT's domain-aware strategies.", "section": "A.5 Domain Heterogeneity"}]