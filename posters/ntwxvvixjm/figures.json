[{"figure_path": "NTWXVvIXJM/figures/figures_2_1.jpg", "caption": "Figure 1: Comparison between S2S-Diffusion model (i.e., DiffuSeq [21]) and the proposed Meta-DiffuB. The shades of color represent different amounts of noise being imposed. Different from prior works that use a fixed noise, we introduce a novel scheduler-exploiter framework, Meta-DiffuB, which achieves trainable noise scheduling inspired by Meta Exploration. Our scheduler model schedules contextualized noise, enhancing the training and generation of the S2S-Diffusion model, resulting in state-of-the-art (SOTA) performance compared to previous S2S-Diffusion models, as detailed in Section 4.", "description": "This figure compares the traditional S2S-Diffusion model (DiffuSeq) with the proposed Meta-DiffuB model.  The left side shows DiffuSeq, using a fixed noise schedule, represented by consistent shading. The right side depicts Meta-DiffuB, which introduces a scheduler model to dynamically determine the noise schedule based on the context of the input sentence, resulting in variable shading to represent the contextualized noise.", "section": "3 Methodology"}, {"figure_path": "NTWXVvIXJM/figures/figures_7_1.jpg", "caption": "Figure 2: Increase in BLEU score with varying candidate sizes |S| on the QQP and WA datasets.", "description": "This figure displays two line graphs, one for the QQP dataset (a) and another for the WA dataset (b). Both graphs show the BLEU scores achieved by three different models (DiffuSeq, GPT2-large, and Meta-DiffuB) as the candidate size |S| increases from 1 to 20.  The x-axis represents the candidate size |S|, and the y-axis represents the BLEU score. The graphs illustrate the performance improvement in BLEU score as the candidate size increases for all three models, with Meta-DiffuB consistently outperforming the other two models.", "section": "6 Experiments of Minimum Bayes Risk Decoding"}, {"figure_path": "NTWXVvIXJM/figures/figures_9_1.jpg", "caption": "Figure 1: Comparison between S2S-Diffusion model (i.e., DiffuSeq [21]) and the proposed Meta-DiffuB. The shades of color represent different amounts of noise being imposed. Different from prior works that use a fixed noise, we introduce a novel scheduler-exploiter framework, Meta-DiffuB, which achieves trainable noise scheduling inspired by Meta Exploration. Our scheduler model schedules contextualized noise, enhancing the training and generation of the S2S-Diffusion model, resulting in state-of-the-art (SOTA) performance compared to previous S2S-Diffusion models, as detailed in Section 4.", "description": "This figure compares the standard S2S-Diffusion model with the proposed Meta-DiffuB model.  It highlights the key difference: Meta-DiffuB uses a scheduler model to determine the amount of noise at each step, resulting in contextualized noise scheduling, whereas the standard model uses a fixed noise schedule.  The color intensity visually represents the amount of noise, showing that Meta-DiffuB adapts noise levels dynamically, unlike the fixed approach of the standard S2S-Diffusion model.", "section": "Methodology"}, {"figure_path": "NTWXVvIXJM/figures/figures_16_1.jpg", "caption": "Figure 3: Visualization of noise scheduling for each S2S-Diffusion model on the QQP and WA datasets. \u03b2t represents the average noise imposed on sentences at diffusion step t. Unlike other models, which impose the same noise on all sentences, our Meta-DiffuB (De = DiffuSeq) varies the noise levels.", "description": "This figure visualizes how different S2S diffusion models schedule noise during the diffusion process.  It compares Meta-DiffuB with three other models (DiffuSeq, Dinoiser, SeqDiffuSeq) across two datasets (QQP and WA).  The key takeaway is that Meta-DiffuB dynamically adjusts the noise level for each sentence, unlike the other methods that apply a fixed or predetermined noise schedule.  The graphs show the average noise (\u03b2t) applied at each diffusion step (t) over training epochs.", "section": "6.2 Contextualized Noise Scheduling of Meta-DiffuB"}]