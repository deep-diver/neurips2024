[{"figure_path": "URkFX1jmOd/tables/tables_6_1.jpg", "caption": "Table 1: The quantitative results on Alderley and BDD100k. \u2193 means lower result is better. \u2191 means higher is better.", "description": "This table presents a quantitative comparison of the proposed N2D3 model and several state-of-the-art methods on two benchmark datasets, Alderley and BDD100K.  The metrics used for evaluation include the Fr\u00e9chet Inception Distance (FID), Learned Perceptual Image Patch Similarity (LPIPS), Scale-Invariant Feature Transform (SIFT) keypoint matches, and mean Intersection over Union (mIoU) for semantic segmentation.  Lower FID and LPIPS scores indicate better image quality, while higher SIFT and mIoU scores signify improved semantic consistency and object detection, respectively.  The table allows readers to assess the relative strengths and weaknesses of different models for night-to-day image translation.", "section": "4.1 Experimental Settings"}, {"figure_path": "URkFX1jmOd/tables/tables_8_1.jpg", "caption": "Table 1: The quantitative results on Alderley and BDD100k. \u2193 means lower result is better. \u2191 means higher is better.", "description": "This table presents a quantitative comparison of the proposed N2D3 method against other state-of-the-art Night-to-Day translation methods on two benchmark datasets: Alderley and BDD100K.  It shows the Fr\u00e9chet Inception Distance (FID), Learned Perceptual Image Patch Similarity (LPIPS), and Scale-Invariant Feature Transform (SIFT) scores for each method on each dataset. Lower FID and LPIPS scores indicate better performance (closer to real daytime images), while a higher SIFT score reflects better preservation of semantic structure.  The table also includes mIoU (mean Intersection over Union) scores for BDD100K to evaluate performance on a downstream semantic segmentation task.", "section": "4.1 Experimental Settings"}]