[{"figure_path": "aCcHVnwNlf/figures/figures_7_1.jpg", "caption": "Figure 1: From Left to Right: (1) The normalized rows of the fingerprinting codebook X are well-spread on the do-dimensional unit sphere. (2) Applying the padding-and-permuting (PAP) technique makes the normalized points very close to each other on the d-dimensional unit sphere (d > do). (3) We create hard instances for DP subspace estimation using k-independent (normalized) PAP-FPC codebooks B\u2081, ..., Bk, where PAP(X) is planted in one of the Bi's (in this example, in B2). Reducing a (i.e., increasing the padding length) makes the points in each group Bi closer to each other, which in particular, increases the closeness to a k-dimensional subspace.", "description": "This figure illustrates the process of generating hard instances for DP subspace estimation using the padding-and-permuting (PAP) technique. Starting with well-spread points on a low-dimensional sphere, the PAP technique adds padding and permutes the columns, resulting in points clustered close together on a higher-dimensional sphere. This process is repeated k times, creating k groups of points with one group containing the original data embedded in it. Reducing the parameter 'a' further increases the point clustering, thus making them closer to a k-dimensional subspace, representing \"easy\" instances for the algorithm.", "section": "DP Subspace Estimation"}, {"figure_path": "aCcHVnwNlf/figures/figures_9_1.jpg", "caption": "Figure 2: From Left to Right: (1) The case k = 4 and \u03c4 = 10d, varying d (the X-axis is \u221ad). (2) The case d = 104 and \u03c4 = 10d, varying k. (3) The case d = 104 and k = 4, varying \u03c4 (the X-axis is \u03c4/d). In all the experiments, we use n = 250 \u00b7 k data points.", "description": "This figure shows the empirical evaluation results comparing three different methods for privately estimating the average of high-dimensional points that approximately lie in a low-dimensional subspace. The three methods compared are the Gaussian mechanism, the algorithm proposed by Dwork et al. (2014), and the proposed EstSubspace algorithm.  The plots illustrate the effect of varying the dimensionality (d), the subspace dimension (k), and the 'easiness' parameter (\u03c4) on the L2 error of the average estimation. The EstSubspace algorithm consistently outperforms the other two in high-dimensional regimes when the points are close to a low-dimensional subspace.", "section": "Empirical Evaluation"}]