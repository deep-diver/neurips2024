{"references": [{"fullname_first_author": "Stefan Ainetter", "paper_title": "End-to-end trainable deep neural network for robotic grasp detection and semantic segmentation from RGB", "publication_date": "2021-00-00", "reason": "This paper is foundational for the learning-based grasp detection methods that the current paper builds on."}, {"fullname_first_author": "Haoshu Fang", "paper_title": "Graspnet-1billion: A large-scale benchmark for general object grasping", "publication_date": "2020-00-00", "reason": "This paper provides the large-scale benchmark dataset used for training and evaluating the proposed method."}, {"fullname_first_author": "Michel Breyer", "paper_title": "Volumetric grasping network: Real-time 6 DOF grasp detection in clutter", "publication_date": "2020-00-00", "reason": "This paper proposes a method for multi-view grasp detection using volumetric representations, addressing the same challenge as the current paper."}, {"fullname_first_author": "Chenxi Wang", "paper_title": "Graspness discovery in clutters for fast and accurate grasp detection", "publication_date": "2021-00-00", "reason": "This paper introduces the concept of graspness, which is central to the current paper's approach."}, {"fullname_first_author": "Roy Or-El", "paper_title": "Stylesdf: High-resolution 3d-consistent image and geometry generation", "publication_date": "2022-00-00", "reason": "This paper provides the foundation for the neural graspness field approach by introducing a method for high-resolution 3D scene representation."}]}