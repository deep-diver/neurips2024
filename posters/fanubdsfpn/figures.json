[{"figure_path": "fAnubdSFpn/figures/figures_2_1.jpg", "caption": "Figure 1: The gradient magnitude of different gradient decay \u03b2 with increasing probability pc.", "description": "This figure shows curves illustrating how the gradient magnitude changes with increasing prediction probability (pc) for different values of the gradient decay hyperparameter (\u03b2).  Each curve represents a different \u03b2 value. The x-axis represents the prediction probability, and the y-axis represents the gradient magnitude.  The figure demonstrates that as the prediction probability increases, the gradient magnitude decreases, and this decrease is more pronounced for larger values of \u03b2. This illustrates the effect of the probability-dependent gradient decay mechanism used in the proposed method, where the gradient is reduced more strongly for higher confidence predictions.", "section": "2.2 Parametric Softmax"}, {"figure_path": "fAnubdSFpn/figures/figures_3_1.jpg", "caption": "Figure 6: Confidence histograms and reliability diagrams for gradient decay with ResNet18 on CIFAR-10. (bins = 10)", "description": "This figure visualizes the performance of ResNet18 on CIFAR-10 dataset under different gradient decay rates (\u03b2). Each subplot presents two plots: a confidence histogram showing the distribution of confidence scores and a reliability diagram illustrating the relationship between the average confidence and accuracy across different confidence intervals. The reliability diagram helps to assess the calibration of the model, while the confidence histogram shows the distribution of confidence levels.  The figure demonstrates how varying the gradient decay rate impacts model calibration; the impact of the gradient decay rate on calibration is evident in the reliability diagrams.", "section": "A.2 Experiments for fixed gradient decay rate"}, {"figure_path": "fAnubdSFpn/figures/figures_4_1.jpg", "caption": "Figure 3: The framework of PID controller-based adaptive probability-dependent gradient decay.", "description": "This figure illustrates the framework of the proposed PID controller-based adaptive probability-dependent gradient decay method. The control system uses the relative calibration error (RCE) calculated from a validation set as feedback. The RCE is compared to the desired value (0), and the difference (error) is used by a PID controller to adjust the gradient decay rate (\u03b2). This adjusted \u03b2 is then used to update the model's softmax mapping during the model optimization process.  Simultaneously, a learning rate compensation mechanism is used to counterbalance the impact of fluctuating gradient decay rates on the gradient magnitude, ensuring stable and consistent model calibration and accuracy. The entire system aims to achieve a balance between optimizing model accuracy and its calibration.", "section": "3 Methodology"}, {"figure_path": "fAnubdSFpn/figures/figures_6_1.jpg", "caption": "Figure 4: Confidence histograms and reliability diagrams for different calibration methods with ResNet35 on CIFAR-100. In each subplot, the left plot illustrates the sample distribution in individual bins, while the right plot displays the average confidence and accuracy in each bin. Our training calibration can improve performance on confidence estimate.", "description": "This figure compares the performance of different calibration methods (including the proposed PID controller approach) on the CIFAR-100 dataset using the ResNet35 model. Each subplot shows two plots: a histogram of the sample distribution across confidence bins and a reliability diagram showing the relationship between average confidence and accuracy within each bin. The ideal scenario is for the accuracy and confidence to match closely in each bin, indicating a well-calibrated model. The figure aims to visually demonstrate the effectiveness of the proposed method in improving model calibration, as indicated by better alignment between average confidence and accuracy compared to other methods.", "section": "4 Empirical experiments"}, {"figure_path": "fAnubdSFpn/figures/figures_8_1.jpg", "caption": "Figure 5: Accuracy and ECE of different PID settings with ResNet35 on CIFAR-100. The preceding figures illustrate the testing accuracy and ECE outcomes in the model optimization. Notably, the accuracy appears insensitive to the PID controller configuration. Nonetheless, excessive settings of P, I, and D may compromise the stability of ECE during the model optimization.", "description": "This figure shows the accuracy and expected calibration error (ECE) for different PID controller settings (proportional, integral, derivative gains) when training a ResNet35 model on the CIFAR-100 dataset.  The results indicate that accuracy is relatively unaffected by the choice of PID settings, but that excessive settings can negatively impact the stability of the ECE. This highlights the importance of carefully tuning PID parameters to balance model accuracy and calibration.", "section": "4.3 Ablation experiments and analysis for PID controller"}, {"figure_path": "fAnubdSFpn/figures/figures_12_1.jpg", "caption": "Figure 2: Confidence and reliability diagrams with ResNet18 on CIFAR-100. (bins = 10) In each subplot, the left plot illustrates the sample distribution in individual bins, while the right plot displays the average confidence and accuracy in each bin. Ideally, calibration aims for consistency between accuracy and average confidence in each bin. It indicates that a smaller gradient decay rate \u03b2 is associated with more pronounced miscalibration of the model, while a larger gradient decay rate mitigates this issue.", "description": "This figure shows the relationship between gradient decay rate (\u03b2) and model calibration performance using ResNet18 on the CIFAR-100 dataset.  Each subplot displays both a histogram showing the distribution of samples across confidence bins and a reliability diagram comparing average confidence and accuracy within each bin. The results indicate that a smaller \u03b2 leads to poorer calibration (overconfidence or underconfidence), while a larger \u03b2 improves calibration.", "section": "2.3 Probability-dependent gradient decay"}, {"figure_path": "fAnubdSFpn/figures/figures_13_1.jpg", "caption": "Figure 2: Confidence and reliability diagrams with ResNet18 on CIFAR-100. (bins = 10) In each subplot, the left plot illustrates the sample distribution in individual bins, while the right plot displays the average confidence and accuracy in each bin. Ideally, calibration aims for consistency between accuracy and average confidence in each bin. It indicates that a smaller gradient decay rate \u03b2 is associated with more pronounced miscalibration of the model, while a larger gradient decay rate mitigates this issue.", "description": "This figure shows the confidence and reliability diagrams for different gradient decay rates (\u03b2) using ResNet18 on the CIFAR-100 dataset. Each subplot contains two plots: a histogram showing the distribution of samples across confidence bins and a reliability diagram plotting the average confidence against the accuracy for each bin.  The reliability diagrams illustrate the relationship between the model's confidence and its actual accuracy. A perfectly calibrated model would show a diagonal line, indicating that the model's confidence accurately reflects its predictive accuracy. Deviations from this diagonal line indicate miscalibration (overconfidence or underconfidence).  The figure demonstrates that smaller values of \u03b2 result in more miscalibration (larger deviation from the diagonal), while larger values lead to better calibration (closer to the diagonal).", "section": "2.3 Probability-dependent gradient decay"}, {"figure_path": "fAnubdSFpn/figures/figures_13_2.jpg", "caption": "Figure 1: The gradient magnitude of different gradient decay \u03b2 with increasing probability pc.", "description": "This figure shows how the gradient magnitude changes with different gradient decay rates (\u03b2) as the probability (pc) increases.  It illustrates the effect of the hyperparameter \u03b2 on controlling the gradient decay rate within the Softmax function. A smaller \u03b2 leads to a slower decay rate, while a larger \u03b2 causes a faster decay, impacting the optimization process. The graph visually demonstrates the relationship between the hyperparameter, gradient magnitude, and the probability. This relationship is fundamental to the paper's approach of adapting the gradient decay rate based on model confidence.", "section": "2.3 Probability-dependent gradient decay"}, {"figure_path": "fAnubdSFpn/figures/figures_13_3.jpg", "caption": "Figure 2: Confidence and reliability diagrams with ResNet18 on CIFAR-100. (bins = 10) In each subplot, the left plot illustrates the sample distribution in individual bins, while the right plot displays the average confidence and accuracy in each bin. Ideally, calibration aims for consistency between accuracy and average confidence in each bin. It indicates that a smaller gradient decay rate \u03b2 is associated with more pronounced miscalibration of the model, while a larger gradient decay rate mitigates this issue.", "description": "This figure shows the confidence and reliability diagrams for ResNet18 model trained on CIFAR-100 dataset.  It visually represents the calibration performance of the model with different gradient decay rates (\u03b2). Each subplot presents a histogram showing the distribution of samples across confidence bins and a line plot illustrating average confidence versus accuracy for each bin.  The ideal scenario shows perfect agreement between accuracy and average confidence, indicating perfect calibration. The figure demonstrates how smaller \u03b2 values lead to worse miscalibration (larger discrepancy between accuracy and confidence), while larger values improve calibration.", "section": "2.3 Probability-dependent gradient decay"}]