[{"figure_path": "KkYZmepjHn/tables/tables_1_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and inference times for different models on three machine translation datasets (IWSLT14, WMT14, and WMT16).  It compares the performance of the proposed DNDM-Multi and DNDM-k-Multi models against RDM-Multi and RDM-k-Multi baselines.  The table shows results for different numbers of sampling steps (25, 50, 1000, and \u221e), allowing comparison of speed and accuracy tradeoffs.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_4_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table compares the performance of different diffusion models on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO) using the BLEU score as a metric.  It shows the performance for different numbers of steps (25, 50, 1000, and \u221e for continuous sampling) and whether top-k selection was used.  The blue highlighting indicates the authors' methods (DNDM), and bold numbers represent the best performance within each row.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_5_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and the average sampling time in seconds for different models (RDM-Multi, DNDM-Multi, RDM-k-Multi, DNDM-k-Multi) on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, WMT16 EN-RO) with different numbers of sampling steps (25, 50, 1000, \u221e). The results are broken down by whether top-k selection was used during token generation.  The table shows the performance of different models and the effect of using top-k selection on BLEU score and sampling speed across different datasets and number of steps.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_7_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and computation times for different diffusion models on three machine translation tasks (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO).  It compares the performance of RDM and RDM-k (baselines from Zheng et al., 2023) against DNDM and DNDM-k (the proposed methods). Results are shown for 25, 50, and 1000 sampling steps, as well as the continuous-time limit (\u221e). The table highlights the superior performance of the DNDM-based models in terms of both speed and sample quality.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_8_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and the corresponding sampling time for different models (RDM-Multi, DNDM-Multi, RDM-k-Multi, and DNDM-k-Multi) on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO) with different numbers of sampling steps (25, 50, 1000, and \u221e). The table highlights the superior performance of the proposed DNDM models in terms of both speed and BLEU score.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_9_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the results of experiments evaluating the performance of different diffusion models on machine translation tasks.  It compares the BLEU scores and computation times for various models (RDM-Multi, DNDM-Multi, RDM-k-Multi, DNDM-k-Multi) across three different datasets (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO) and different numbers of sampling steps (25, 50, 1000). The table highlights the superior performance of the proposed DNDM models in terms of both speed and quality, especially when using a larger number of sampling steps.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_20_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the results of the BLEU score and sampling time for different models (RDM-Multi, DNDM-Multi, RDM-k-Multi, DNDM-k-Multi) on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, WMT16 EN-RO) with different numbers of steps (25, 50, 1000, \u221e).  The results show the performance of both multinomial diffusion and the proposed methods (DNDM) across various settings, including with and without top-k selection.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_21_1.jpg", "caption": "Table 6: Comparison of left-to-right and right-to-left transition approaches across different datasets and step counts.", "description": "This table presents the BLEU scores achieved using two different transition approaches (left-to-right and right-to-left) for machine translation tasks on three different datasets (IWSLT14, WMT14, and WMT16) with varying numbers of sampling steps (25, 50, and 1000). The left-to-right approach shows better results.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_22_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and the average time in seconds for different sampling steps (25, 50, 1000, and \u221e) using multinomial diffusion on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO).  It compares the performance of four different methods: RDM-Multi, DNDM-Multi, RDM-k-Multi, and DNDM-k-Multi.  The results show the impact of the number of sampling steps and the use of top-k selection on BLEU score and sampling speed.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_23_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and average sampling times for different diffusion models on three machine translation tasks (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO).  It compares the performance of RDM and RDM-k (from Zheng et al., 2023) with DNDM and DNDM-k for different numbers of sampling steps (25, 50, 1000) and in the continuous-time limit.  The results show the impact of the proposed DNDM method on both sampling speed and the quality of the generated translations.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_24_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and sampling times for different models (RDM-Multi, DNDM-Multi, RDM-k-Multi, DNDM-k-Multi) on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, WMT16 EN-RO) with varying numbers of sampling steps (25, 50, 1000).  The best BLEU score for each row is bolded, highlighting the effectiveness of the proposed DNDM approach in improving both the speed and the quality of machine translation.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_25_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and inference times for different models on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO) using multinomial diffusion.  It compares the performance of RDM (baseline) and DNDM models with different numbers of sampling steps (25, 50, 1000, and \u221e).  The table highlights the superior performance of DNDM in terms of both speed and BLEU scores.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_25_2.jpg", "caption": "Table 3: BLEU score comparison of absorbing diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and the average number of function evaluations (NFE) for different models (RDM-Absorb, DNDM-Absorb, RDM-k-Absorb, DNDM-k-Absorb) on three machine translation datasets (IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO). The results are shown for 25, 50, and 1000 steps, and the best results for each setting are highlighted in bold. The table shows that DNDM-based methods generally outperform RDM-based methods, particularly for a large number of steps (1000). The table also presents results for continuous-time sampling (\u221e steps).", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_26_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and inference times for different models on three machine translation tasks using multinomial diffusion.  The models compared are RDM-Multi, RDM-k-Multi, DNDM-Multi, and DNDM-k-Multi, with varying numbers of steps (25, 50, 1000, and \u221e). The table shows that DNDM models generally achieve higher BLEU scores and significantly faster inference times than RDM models, particularly with a larger number of steps.", "section": "4.1 Conditional Text Generation"}, {"figure_path": "KkYZmepjHn/tables/tables_27_1.jpg", "caption": "Table 2: BLEU score comparison of multinomial diffusion on machine translation benchmarks IWSLT14 DE-EN, WMT14 EN-DE, and WMT16 EN-RO. Below the dataset, we present the amount of data used to run the evaluation (sentences). The blue background highlights our algorithms, and the bold number indicates the best performance within each row and each setting (i.e., with or without top-k).", "description": "This table presents the BLEU scores and inference times for different models on three machine translation tasks using multinomial diffusion.  It compares the performance of RDM (a baseline) and DNDM (the proposed method) with and without top-k selection for various numbers of sampling steps (25, 50, 1000).  The results highlight the speed improvement and comparable quality of DNDM, especially at higher sampling steps.", "section": "4.1 Conditional Text Generation"}]