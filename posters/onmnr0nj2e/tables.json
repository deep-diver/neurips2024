[{"figure_path": "oNMnR0NJ2e/tables/tables_3_1.jpg", "caption": "Table 1: Benchmark SOTA methods against CutMix baseline and soft label baseline on ImageNet-1K. SRe2L is the only method that can scale to ImageNet-1K. Both soft label-based baselines with random training images can already achieve comparable performances.", "description": "This table benchmarks several state-of-the-art (SOTA) dataset distillation methods against two baselines: a CutMix augmented soft labels baseline and a simpler soft label baseline.  The SOTA methods and the baselines are evaluated on the ImageNet-1K dataset using different numbers of images per class (IPC).  The results demonstrate that the soft label baselines, which use randomly selected training images and soft labels generated by a pre-trained model, can achieve comparable performance to the more complex SOTA methods, especially as the IPC increases.  This challenges the conventional wisdom that sophisticated synthetic data generation is crucial for dataset distillation.", "section": "3.2 Benchmarking distillation methods against the soft label baseline"}, {"figure_path": "oNMnR0NJ2e/tables/tables_4_1.jpg", "caption": "Table 1: Benchmark SOTA methods against CutMix baseline and soft label baseline on ImageNet-1K. SRe2L is the only method that can scale to ImageNet-1K. Both soft label-based baselines with random training images can already achieve comparable performances.", "description": "This table compares the performance of state-of-the-art (SOTA) data distillation methods with a simple baseline using randomly sampled training images and soft labels.  It shows that the baseline, despite its simplicity, achieves comparable performance to the SOTA methods, especially on larger datasets, highlighting the importance of soft labels in dataset distillation.", "section": "3.2 Benchmarking distillation methods against the soft label baseline"}, {"figure_path": "oNMnR0NJ2e/tables/tables_8_1.jpg", "caption": "Table 3: Comparison of label generation strategies on TinyImageNet. Ensemble provides consistent performance improvement. Distillation method (BPTT) can be adopted to learn labels.", "description": "This table compares different label generation strategies on the TinyImageNet dataset.  It shows student test accuracy results using hard labels derived directly from the data, soft labels generated by a single expert model, soft labels generated by an ensemble of expert models, soft labels learned using the Back-Propagation Through Time (BPTT) distillation method, and soft labels obtained via the Matching Training Trajectories (MTT) distillation method.  The table highlights the improvement in performance achieved by using ensemble soft labels and the effectiveness of using the BPTT method to learn labels.", "section": "5 Learning soft labels through data distillation methods"}, {"figure_path": "oNMnR0NJ2e/tables/tables_13_1.jpg", "caption": "Table 4: Benchmark SOTA methods against the soft label baseline (\u201cSI Baseline\u201d) on (downsized) ImageNet-1K. Other distillation methods can only scale to downsized (64 \u00d7 64) ImageNet-1K and they do not significantly outperform the baseline.", "description": "This table compares the performance of several state-of-the-art (SOTA) dataset distillation methods against a simple baseline that uses randomly sampled images and soft labels (the \"SI Baseline\"). The comparison is done on a downsized version of the ImageNet-1K dataset, with the number of images per class (IPC) limited to 1 or 2. The results show that even a simple baseline using soft labels achieves comparable performance to the SOTA methods, especially when scaling to larger datasets is considered.", "section": "3.2 Benchmarking distillation methods against the soft label baseline"}, {"figure_path": "oNMnR0NJ2e/tables/tables_13_2.jpg", "caption": "Table 5: Image selection with different random seeds on TinyImageNet. Our soft label baseline is not sensitive to random image selections.", "description": "This table presents the results of an experiment designed to assess the sensitivity of the soft label baseline to random image selection.  The soft label baseline, a method for dataset distillation, involves selecting images randomly from a training dataset and using them with soft labels. The experiment used six different random seeds to select images for the TinyImageNet dataset at three different images-per-class (IPC) values: 1, 10, and 50. The table shows that the student test accuracy remains relatively stable across the different random seeds, indicating that the soft label baseline is robust to random image selection, a key finding in the paper.", "section": "3.2 Benchmarking distillation methods against the soft label baseline"}, {"figure_path": "oNMnR0NJ2e/tables/tables_13_3.jpg", "caption": "Table 6: Image selection with different expert training seeds on TinyImageNet. Our soft label baseline is not sensitive to experts with different training seeds", "description": "This table presents the results of an experiment designed to assess the robustness of the soft label baseline to variations in expert training.  Six different expert models were trained, each with a unique random seed.  For each expert model, the student model's performance was evaluated at various image-per-class (IPC) values (1, 10, and 50). The table shows that the student test accuracy remains relatively stable across different expert models, indicating that the soft label baseline is not highly sensitive to variations in the expert training process.", "section": "3.2 Benchmarking distillation methods against the soft label baseline"}, {"figure_path": "oNMnR0NJ2e/tables/tables_14_1.jpg", "caption": "Table 1: Benchmark SOTA methods against CutMix baseline and soft label baseline on ImageNet-1K. SRe2L is the only method that can scale to ImageNet-1K. Both soft label-based baselines with random training images can already achieve comparable performances.", "description": "This table benchmarks several state-of-the-art (SOTA) dataset distillation methods against two baselines: a CutMix augmented soft labels baseline and a soft label baseline.  The SOTA methods are evaluated on the ImageNet-1K dataset using various image/class (IPC) ratios. The table highlights that the soft label baseline, which uses randomly sampled training images paired with soft labels, achieves performance comparable to more complex SOTA methods. Notably, only SRe2L, among the SOTA methods, scales well to ImageNet-1K.", "section": "3.2 Benchmarking distillation methods against the soft label baseline"}]