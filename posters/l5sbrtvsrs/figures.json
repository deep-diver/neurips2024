[{"figure_path": "l5SbrtvSRS/figures/figures_1_1.jpg", "caption": "Figure 1: Parameter competition within individual task models. Intra-balancing enhances performance beyond finetuning.", "description": "This figure shows how intra-balancing, a technique used in PCB-MERGING, improves the performance of individual task models by addressing parameter competition.  The x-axis represents the scale factor applied to parameters, while the y-axis shows the accuracy on the 'Cars' task. Different lines represent different parameter selection strategies: using the top 20%, 30%, and 50% of parameters with the highest magnitude, and using all parameters (Entire Segment). The figure demonstrates that selectively keeping a subset of parameters (intra-balancing) often yields better results than using all parameters, implying that some parameters are more important than others in contributing to the final accuracy.  The dashed red line shows the accuracy achieved by simply fine-tuning the model.", "section": "5.1 Cross Task Merging"}, {"figure_path": "l5SbrtvSRS/figures/figures_1_2.jpg", "caption": "Figure 2: Parameter competition within task model populations. Inter-balancing improves cross-task generalization.", "description": "This figure shows the impact of inter-balancing on cross-task generalization performance.  The x-axis represents the scaling factor applied to the task vectors during model merging. The y-axis shows the average accuracy across multiple tasks (AVE. Acc), the accuracy on the \"Cars\" task (Acc Cars), and the accuracy on the \"SUN397\" task (Acc SUN397). The red dashed line indicates the optimal scaling factor, where the inter-balancing technique achieves the best balanced performance across all three metrics.  The results illustrate that carefully balancing parameter competition between tasks improves cross-task generalization and overall performance.  The optimal scaling factor is determined by the point at which the lines representing the individual task accuracies intersect.", "section": "1 Introduction"}, {"figure_path": "l5SbrtvSRS/figures/figures_3_1.jpg", "caption": "Figure 3: An illustration of the steps in PCB-MERGING. Different colored blocks represent parameters with varying values. We start with multiple fine-tuned models and a pretrained model, establishing a PCB matrix through intra-balancing and inter-balancing. Low-scoring parameters are dropped, and the remaining ones are rescaled. Finally, we merge the modulated task vectors into the pretrained model to create the final merged model.", "description": "This figure illustrates the process of PCB-MERGING. It starts with multiple fine-tuned models and a pre-trained model. Intra-balancing and inter-balancing are used to create a PCB matrix, which weights the importance of parameters within and across tasks. Low-scoring parameters are dropped, and remaining ones are rescaled. Finally, modulated task vectors are merged into the pre-trained model to create the final merged model.", "section": "3 Method"}, {"figure_path": "l5SbrtvSRS/figures/figures_7_1.jpg", "caption": "Figure 4: Comparison of average performance on 7 in-domain and 6 held-out datasets after cross-task merging.", "description": "This figure compares the average out-of-domain (OOD) performance against the average in-domain performance for different model merging methods on 7 in-domain and 6 held-out datasets.  It shows that PCB-Merging (the authors' method) generally outperforms other methods, especially as in-domain performance increases, particularly for the T5-large model.", "section": "5.1 Cross Task Merging"}, {"figure_path": "l5SbrtvSRS/figures/figures_7_2.jpg", "caption": "Figure 5: Comparison of average performance on 5 in-domain and 5 distribution shift datasets after cross-domain merging.", "description": "This figure compares the average out-of-domain (OOD) performance against the average in-domain performance of different model merging methods (Simple Averaging, Fisher Merging, RegMean, TIES-Merging, and PCB-Merging) using two base models, Roberta-base and T5-base, across five in-domain and five distribution shift datasets for emotion classification. The x-axis represents the average in-domain performance, and the y-axis represents the average OOD performance.  The results show that PCB-Merging consistently outperforms other methods in both in-domain and OOD settings, demonstrating its effectiveness in cross-domain generalization.", "section": "5.2 Cross Domain Merging"}, {"figure_path": "l5SbrtvSRS/figures/figures_8_1.jpg", "caption": "Figure 6: Performance with various hyperparameters \u03bb and r.", "description": "This figure shows the performance of different models across various values of lambda (\u03bb) while keeping r constant at 0.1, and for various values of r with optimal lambda.  It compares the performance of the proposed PCB-Merging method against the TIES-Merging baseline, showing that PCB-Merging achieves higher performance within a suitable range of parameters.", "section": "6.2 Effect of Hyper-Parameters on the Performance"}, {"figure_path": "l5SbrtvSRS/figures/figures_18_1.jpg", "caption": "Figure 6: Performance with various hyperparameters \u03bb and r.", "description": "This figure shows the impact of hyperparameters \u03bb (lambda) and r on the performance of merging multiple NLP tasks.  The left and center plots show how performance varies with different values of \u03bb for T5-base and T5-large models, respectively, while keeping r constant at 0.2. The right plot displays how performance changes with different values of r for the T5-large model, with the optimal \u03bb determined for each r value. The results indicate that performance is highly sensitive to these hyperparameters and there exists an optimal range where the performance is maximized.", "section": "6.2 Effect of Hyper-Parameters on the Performance"}, {"figure_path": "l5SbrtvSRS/figures/figures_18_2.jpg", "caption": "Figure 8: Average normalized performance when merging a different number of tasks.", "description": "This figure shows the average normalized performance of different model merging methods (Weight Averaging, TIES-Merging, and PCB-Merging) across varying numbers of tasks (from 2 to 7).  The performance is normalized to the individual fine-tuned model's performance for each task.  The results indicate that as the number of merged tasks increases, performance decreases for all methods. This is likely due to increased parameter competition among tasks. Importantly, PCB-Merging shows a slower performance decline compared to the other methods, highlighting its effectiveness in managing parameter competition during model merging.", "section": "C.1 Merging Different Number of Tasks"}, {"figure_path": "l5SbrtvSRS/figures/figures_21_1.jpg", "caption": "Figure 9: Test set performance when merging ViT-B/32 and ViT-L/14 models on eight image classification tasks.", "description": "This figure shows radar charts visualizing the performance of different model merging methods on eight image classification tasks using two versions of the CLIP model (ViT-B/32 and ViT-L/14) as visual encoders. Each axis represents a specific task (SUN397, Cars, RESISC45, EuroSAT, SVHN, GTSRB, MNIST, and DTD), and the radial distance from the center indicates the performance of each merging method on that task. The figure helps compare the performance of the different merging methods (Averaging, RegMean, Task Arithmetic, TIES-Merging, Fisher Merging, and PCB-Merging) across multiple image classification tasks.", "section": "5 Results"}]