{"references": [{"fullname_first_author": "Alexey Dosovitskiy", "paper_title": "An image is worth 16x16 words: Transformers for image recognition at scale", "publication_date": "2021-00-00", "reason": "This paper introduces the Vision Transformer (ViT), a foundational model for the work presented, and is frequently cited."}, {"fullname_first_author": "Jacob Devlin", "paper_title": "Bert: Pre-training of deep bidirectional transformers for language understanding", "publication_date": "2019-00-00", "reason": "This paper introduces BERT, a highly influential model in natural language processing that inspired the use of transformers in other domains such as computer vision, which is relevant to this paper\u2019s focus on Vision Transformers."}, {"fullname_first_author": "Oriol Vinyals", "paper_title": "Matching networks for one shot learning", "publication_date": "2016-00-00", "reason": "This paper introduces Matching Networks, a fundamental few-shot learning method that forms a basis for the cross-domain few-shot learning explored in this work."}, {"fullname_first_author": "Jia Deng", "paper_title": "Imagenet: A large-scale hierarchical image database", "publication_date": "2009-00-00", "reason": "This paper introduces ImageNet, a large-scale dataset commonly used for training and benchmarking computer vision models, and its use is directly relevant to this paper's approach to cross-domain few-shot learning."}, {"fullname_first_author": "Mathilde Caron", "paper_title": "Emerging properties in self-supervised vision transformers", "publication_date": "2021-00-00", "reason": "This paper explores self-supervised learning in Vision Transformers, which is a relevant technique to this paper's focus on efficient transfer learning methods."}]}