[{"figure_path": "vYmvgxpgwH/figures/figures_1_1.jpg", "caption": "Figure 1: The inference computation scaling laws exhibited in error rate on the MATH500 test set based on weighted majority voting, where the left figure shows sampling vs. MCTS, and the right figure shows our proposed REBASE. Clearly, the error rate decreases steadily when the computation increases, and REBASE exhibits a Pareto-optimal tradeoff during inference.", "description": "This figure shows how the error rate on the MATH500 test set changes with increasing computational cost (measured in FLOPs) for different inference strategies. The left panel compares sampling and Monte Carlo Tree Search (MCTS) for 7B and 34B parameter models.  The right panel shows the performance of the proposed REBASE (Reward Balanced Search) method, also for 7B and 34B parameter models.  The results demonstrate that as computational cost increases, the error rate decreases; however, the REBASE method demonstrates a more efficient Pareto-optimal trade-off between accuracy and computational cost.", "section": "4 Experiments"}, {"figure_path": "vYmvgxpgwH/figures/figures_2_1.jpg", "caption": "Figure 2: Illustration of compute-optimal scaling laws in training and inference. The Chinchilla scaling law shows how to choose a model size and number of training tokens under a training-compute budget, while ours shows how to choose a model size and an inference strategy under a inference-compute budget.", "description": "This figure illustrates the concept of compute-optimal scaling laws in both training and inference.  The left side represents the Chinchilla scaling law, which focuses on finding the optimal model size and training token count given a fixed training compute budget. The right side shows the approach presented in the paper, which aims to determine the optimal model size and inference strategy for a given inference compute budget. The figure highlights that both training and inference optimization consider model size as a key parameter, but differ in their focus (training tokens vs. inference strategy).", "section": "3 An Empirical Analysis of Compute-Optimal Inference for Problem-Solving"}, {"figure_path": "vYmvgxpgwH/figures/figures_4_1.jpg", "caption": "Figure 3: Illustration of one iteration of REward Balanced SEarch (REBASE).", "description": "The figure illustrates one iteration of the REBASE algorithm.  It shows how the algorithm manages exploration and pruning of the search tree based on rewards from a reward model.  The algorithm starts with a set number of initial solutions (N), and in each iteration, it evaluates the 'completed' status of partial solutions.  Based on the reward scores, the algorithm dynamically allocates exploration budget to expand promising paths, balancing exploration and exploitation.  The sum of expanding widths determines the number of nodes in the next iteration, ensuring that the total number of explored nodes (N) is maintained within the computational budget.", "section": "3.1.3 Reward Balanced Search (REBASE)"}, {"figure_path": "vYmvgxpgwH/figures/figures_5_1.jpg", "caption": "Figure 4: The inference computation scaling comparisons across different model sizes. The left/right panel shows the GSM8K problem-solving error rate on GSM8K based on Weighted Mjority/Best-of-N.", "description": "This figure shows how the performance (test error rate) of different inference methods scales with increasing computational cost (inference FLOPs) on the GSM8K dataset.  It compares two different model sizes (7B and 34B parameters) using two strategies: Weighted Majority Voting and Best-of-N.  The plots illustrate the trade-off between accuracy and computational resources during inference.", "section": "4 Experiments"}, {"figure_path": "vYmvgxpgwH/figures/figures_6_1.jpg", "caption": "Figure 5: The inference computation scaling laws of different models for the problem-solving error rate on MATH500 test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B (right). In the legend, W.M. and BoN refer to Weighted Majority and Best-of-N, respectively.", "description": "This figure compares three different language models (Llemma-7B, Llemma-34B, and Mistral-7B) across two inference strategies (Weighted Majority voting and Best-of-N) on the MATH500 dataset.  The x-axis represents inference FLOPs (floating point operations), a measure of computational cost, while the y-axis shows the test error rate. The figure demonstrates the scaling laws of inference computation on model performance, showcasing how increasing compute budget affects the accuracy of problem-solving.  Each curve shows the error rate decrease as compute increases until saturation.", "section": "4.2 Main Results of Compute-Optimal Inference"}, {"figure_path": "vYmvgxpgwH/figures/figures_7_1.jpg", "caption": "Figure 10: The inference computation scaling laws of different models for the problem-solving error rate on GSM8K test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B (right). In the legend, M.V. and W.M. refer to Majority Voting and Weighted Majority, respectively.", "description": "This figure shows how the error rate changes with increased computation (measured in FLOPs) for three different language models (Llemma-7B, Llemma-34B, and Mistral-7B) on the GSM8K dataset.  It compares two inference strategies: Weighted Majority Voting (W.M.) and Best-of-N (BoN). The plot illustrates the trade-off between computational cost and accuracy for various model sizes and inference strategies.", "section": "4.2 Main Results of Compute-Optimal Inference"}, {"figure_path": "vYmvgxpgwH/figures/figures_13_1.jpg", "caption": "Figure 5: The inference computation scaling laws of different models for the problem-solving error rate on MATH500 test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B (right). In the legend, W.M. and BoN refer to Weighted Majority and Best-of-N, respectively.", "description": "This figure displays the relationship between inference computation (FLOPs) and test error rate on the MATH500 dataset for three different language models (Llemma-7B, Llemma-34B, and Mistral-7B).  It shows how the error rate decreases as computation increases, demonstrating the scaling laws of inference.  The figure compares two inference strategies (Weighted Majority Voting and Best-of-N), illustrating the trade-off between accuracy and computational cost.", "section": "4.2 Main Results of Compute-Optimal Inference"}, {"figure_path": "vYmvgxpgwH/figures/figures_14_1.jpg", "caption": "Figure 4: The inference computation scaling comparisons across different model sizes. The left/right panel shows the GSM8K problem-solving error rate on GSM8K based on Weighted Mjority/Best-of-N.", "description": "This figure displays the relationship between inference computation (in FLOPs) and test error rate on the GSM8K dataset for different LLMs (Llemma-7B and Llemma-34B).  Two inference strategies are compared: Weighted Majority Voting and Best-of-N.  The graphs show how increasing computation generally leads to lower error rates, illustrating the scaling laws of inference computation for different model sizes and approaches.", "section": "4 Experiments"}, {"figure_path": "vYmvgxpgwH/figures/figures_14_2.jpg", "caption": "Figure 5: The inference computation scaling laws of different models for the problem-solving error rate on MATH500 test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B (right). In the legend, W.M. and BoN refer to Weighted Majority and Best-of-N, respectively.", "description": "This figure shows how the error rate changes with increasing inference FLOPs (floating-point operations) for three different language models (Llemma-7B, Llemma-34B, and Mistral-7B) on the MATH500 dataset.  The results are shown for different inference strategies: Weighted Majority voting and Best-of-N. It demonstrates the trade-off between computational cost and accuracy during inference.", "section": "4.2 Main Results of Compute-Optimal Inference"}, {"figure_path": "vYmvgxpgwH/figures/figures_14_3.jpg", "caption": "Figure 10: The inference computation scaling laws of different models for the problem-solving error rate on GSM8K test set. The tested models are Llemma-7B (left), Llemma-34B (middle), & Mistral-7B (right). In the legend, M.V. and W.M. refer to Majority Voting and Weighted Majority, respectively.", "description": "This figure displays the relationship between inference computation (FLOPs) and test error rate for three different language models (Llemma-7B, Llemma-34B, and Mistral-7B) on the GSM8K dataset.  Two inference strategies, Majority Voting (M.V.) and Weighted Majority Voting (W.M.), are compared for each model. The plots show how the error rate changes as more computational resources are allocated to the inference process.  The shaded regions represent the confidence intervals around the mean error rates.", "section": "4.2 Main Results of Compute-Optimal Inference"}]