[{"figure_path": "0EfUYVMrLv/figures/figures_4_1.jpg", "caption": "Figure 1: An illustration of our problem and the Ada-ReAlign algorithm. The test data accumulate over time with changing distributions, and only a limited number of unlabeled data are available at each step. Initially, an offline model and the statistics of the offline data are provided, followed by continuous adaptation to the new distributions. Ada-ReAlign is composed of a group of base learners and a meta learner. Each base learner operates with a different window size by restarting, learning representations for its respective period by minimizing the discrepancy from the source representation. The outputs from the base learners are then combined by the meta learner to produce the final representation.", "description": "This figure illustrates the Ada-ReAlign algorithm, which addresses the challenge of continual test-time adaptation in non-stationary environments.  The algorithm uses multiple base learners, each with a different window size, to process incoming unlabeled data.  Each base learner updates its representation to align with the initial source domain representation. A meta-learner combines the outputs of these base learners to produce a final, adapted representation. The figure shows how the data distribution changes over time and the mechanism of restarting the base learners to adapt to these shifts.", "section": "3.3 Adaptive Representation Alignment"}, {"figure_path": "0EfUYVMrLv/figures/figures_8_1.jpg", "caption": "Figure 2: Weight (%) heatmap of base learners in (a) Sequential shift with different intervals. (b) Bernoulli sequential shift with different intervals, where the length of interval is an expected value.", "description": "This figure shows the weights assigned to each base learner in Ada-ReAlign across different time intervals (M) under sequential and Bernoulli shifts.  Each heatmap visualizes the weight distribution across K base learners, where each learner has a different window size (2^i, i=0,...,K-1).  The sequential shift shows a clear pattern:  weights are concentrated on learners with window sizes matching the length of distribution stability (M).  The Bernoulli shift shows a more diffuse weight distribution. The x-axis represents window size, while the y-axis represents time interval (M) length.", "section": "3.3 Adaptive Representation Alignment"}, {"figure_path": "0EfUYVMrLv/figures/figures_9_1.jpg", "caption": "Figure 4: Average Classification Error (%) Comparison with Various Components.", "description": "This figure compares the average classification error rates of different variants of the Ada-ReAlign algorithm across various corruption types in the CIFAR-10C dataset. The variants include Ada-ReAlign without distribution alignment (w/o DA), Ada-ReAlign with only representation alignment (RE), Ada-ReAlign with only entropy minimization (EM), Ada-ReAlign using the TENT algorithm's restart mechanism (CT), and Ada-ReAlign using a threshold-based restart mechanism (TS). The results highlight the importance of both representation alignment and entropy minimization in achieving high performance.  The standard error bars are also shown for each result.", "section": "4.3 Ablation Study"}]