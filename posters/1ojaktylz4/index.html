<!doctype html><html lang=en dir=ltr class=scroll-smooth data-default-appearance=light data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="en"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>ANT: Adaptive Noise Schedule for Time Series Diffusion Models &#183; NeurIPS 2024</title>
<meta name=title content="ANT: Adaptive Noise Schedule for Time Series Diffusion Models &#183; NeurIPS 2024"><meta name=description content="ANT: An adaptive noise schedule automatically determines optimal noise schedules for time series diffusion models, significantly boosting performance across diverse tasks."><meta name=keywords content="Machine Learning,Deep Learning,üè¢ Yonsei University,"><link rel=canonical href=https://deep-diver.github.io/neurips2024/posters/1ojaktylz4/><link type=text/css rel=stylesheet href=/neurips2024/css/main.bundle.min.595affd4445a931ea6d6e3a5a3c709930fa52a60be10b21c6f81fdb8fecaacea33aacedf80cdc88be45f189be14ed4ce53ea74a1e1406fad9cbf90c5ed409173.css integrity="sha512-WVr/1ERakx6m1uOlo8cJkw+lKmC+ELIcb4H9uP7KrOozqs7fgM3Ii+RfGJvhTtTOU+p0oeFAb62cv5DF7UCRcw=="><script type=text/javascript src=/neurips2024/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/neurips2024/js/main.bundle.min.efbf3b6b987689fffaf2d7b73173d2690c0279a04d444b0537a77d7f4ff6e6d493445400cb0cf56bc0f0f123e19f15394e63cae34e67f069bd013dd5c73df56e.js integrity="sha512-7787a5h2if/68te3MXPSaQwCeaBNREsFN6d9f0/25tSTRFQAywz1a8Dw8SPhnxU5TmPK405n8Gm9AT3Vxz31bg==" data-copy data-copied></script><script src=/neurips2024/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/neurips2024/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/neurips2024/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/neurips2024/favicon-16x16.png><link rel=manifest href=/neurips2024/site.webmanifest><meta property="og:url" content="https://deep-diver.github.io/neurips2024/posters/1ojaktylz4/"><meta property="og:site_name" content="NeurIPS 2024"><meta property="og:title" content="ANT: Adaptive Noise Schedule for Time Series Diffusion Models"><meta property="og:description" content="ANT: An adaptive noise schedule automatically determines optimal noise schedules for time series diffusion models, significantly boosting performance across diverse tasks."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posters"><meta property="article:published_time" content="2024-09-26T00:00:00+00:00"><meta property="article:modified_time" content="2024-09-26T00:00:00+00:00"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Deep Learning"><meta property="article:tag" content="üè¢ Yonsei University"><meta property="og:image" content="https://deep-diver.github.io/neurips2024/posters/1ojaktylz4/cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://deep-diver.github.io/neurips2024/posters/1ojaktylz4/cover.png"><meta name=twitter:title content="ANT: Adaptive Noise Schedule for Time Series Diffusion Models"><meta name=twitter:description content="ANT: An adaptive noise schedule automatically determines optimal noise schedules for time series diffusion models, significantly boosting performance across diverse tasks."><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"Posters","name":"ANT: Adaptive Noise Schedule for Time Series Diffusion Models","headline":"ANT: Adaptive Noise Schedule for Time Series Diffusion Models","abstract":"ANT: An adaptive noise schedule automatically determines optimal noise schedules for time series diffusion models, significantly boosting performance across diverse tasks.","inLanguage":"en","url":"https:\/\/deep-diver.github.io\/neurips2024\/posters\/1ojaktylz4\/","author":{"@type":"Person","name":"AI Paper Reviewer"},"copyrightYear":"2024","dateCreated":"2024-09-26T00:00:00\u002b00:00","datePublished":"2024-09-26T00:00:00\u002b00:00","dateModified":"2024-09-26T00:00:00\u002b00:00","keywords":["Machine Learning","Deep Learning","üè¢ Yonsei University"],"mainEntityOfPage":"true","wordCount":"4333"}]</script><meta name=author content="AI Paper Reviewer"><link href=https://neurips.cc/ rel=me><link href=https://x.com/NeurIPSConf rel=me><link href rel=me><link href=https://github.com/deep-diver/paper-reviewer/ rel=me><link href=https://x.com/algo_diver/ rel=me><script src=/neurips2024/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><script defer src=/neurips2024/lib/typeit/typeit.umd.1b3200cb448f5cd1f548f2781452643d3511a43584b377b82c03a58055da4fdb7bc8f6c6c2ce846480c7677ff25bfd0d75f15823c09443ab18e0fd2cad792587.js integrity="sha512-GzIAy0SPXNH1SPJ4FFJkPTURpDWEs3e4LAOlgFXaT9t7yPbGws6EZIDHZ3/yW/0NdfFYI8CUQ6sY4P0srXklhw=="></script><script defer src=/neurips2024/lib/packery/packery.pkgd.min.js integrity></script><script type=text/javascript src=/neurips2024/js/shortcodes/gallery.min.9b4cb28f931ed922c26fb9b2510c2debb370f6a63305050c2af81740b2919883715e24efbbdf3a081496718ec751df3a72729d4d0bc71d6071297563a97ce1ee.js integrity="sha512-m0yyj5Me2SLCb7myUQwt67Nw9qYzBQUMKvgXQLKRmINxXiTvu986CBSWcY7HUd86cnKdTQvHHWBxKXVjqXzh7g=="></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KX0S6Q55Y7"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-KX0S6Q55Y7")</script><meta name=theme-color><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js></script><script src=https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js></script><script>const firebaseConfig={apiKey:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",authDomain:"AIzaSyCv6pUES05bxrampKbfhhmW3y-1pmX3XgE",projectId:"neurips2024-f3065",storageBucket:"neurips2024-f3065.firebasestorage.app",messagingSenderId:"982475958898",appId:"1:982475958898:web:2147e5d7753d6ac091f0eb",measurementId:"G-YQ46HXQ9JS"};var app=firebase.initializeApp(firebaseConfig),db=firebase.firestore(),auth=firebase.auth()</script></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a></div><div class=min-h-[148px]></div><div class="fixed inset-x-0 pl-[24px] pr-[24px]" style=z-index:100><div id=menu-blur class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div><div class="relative max-w-[64rem] ml-auto mr-auto"><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/neurips2024/ class="text-base font-medium text-gray-500 hover:text-gray-900">NeurIPS 2024</a></nav><nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12"><a href=/neurips2024/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>About</p></a><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Oral
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/neurips2024/oral-ai-applications/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) AI Applications</p></a><a href=/neurips2024/oral-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) AI Theory</p></a><a href=/neurips2024/oral-image-generation/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Image Generation</p></a><a href=/neurips2024/oral-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Large Language Models</p></a><a href=/neurips2024/oral-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Others</p></a><a href=/neurips2024/oral-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(o) Reinforcement Learning</p></a></div></div></div></div><div><div class="cursor-pointer flex items-center nested-menu"><a class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title>Spotlight
</a><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></div><div class="absolute menuhide"><div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl"><div class="flex flex-col space-y-3"><a href=/neurips2024/spotlight-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) AI Theory</p></a><a href=/neurips2024/spotlight-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Large Language Models</p></a><a href=/neurips2024/spotlight-optimization/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Optimization</p></a><a href=/neurips2024/spotlight-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Others</p></a><a href=/neurips2024/spotlight-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-sm" title>(s) Reinforcement Learning</p></a></div></div></div></div><a href=/neurips2024/posters/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Posters</p></a><a href=/neurips2024/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>Tags</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="ltr:mr-14 rtl:ml-14 flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center space-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400" style=margin-right:5px><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 -mr-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/neurips2024/about/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>About</p></a></li><li class=mt-1><a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Oral</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/neurips2024/oral-ai-applications/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) AI Applications</p></a></li><li class=mt-1><a href=/neurips2024/oral-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) AI Theory</p></a></li><li class=mt-1><a href=/neurips2024/oral-image-generation/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Image Generation</p></a></li><li class=mt-1><a href=/neurips2024/oral-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Large Language Models</p></a></li><li class=mt-1><a href=/neurips2024/oral-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Others</p></a></li><li class=mt-1><a href=/neurips2024/oral-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(o) Reinforcement Learning</p></a></li><li class=mb-2></li><li class=mt-1><a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Spotlight</p><span><span class="relative block icon"><svg viewBox="0 0 20 20" fill="currentcolor" aria-hidden="true"><path fill-rule="evenodd" d="M5.23 7.21a.75.75.0 011.06.02L10 11.168l3.71-3.938a.75.75.0 111.08 1.04l-4.25 4.5a.75.75.0 01-1.08.0l-4.25-4.5a.75.75.0 01.02-1.06z" clip-rule="evenodd"/></svg></span></span></a></li><li class=mt-1><a href=/neurips2024/spotlight-ai-theory/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) AI Theory</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-large-language-models/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Large Language Models</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-optimization/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Optimization</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-others/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Others</p></a></li><li class=mt-1><a href=/neurips2024/spotlight-reinforcement-learning/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-sm font-small" title>(s) Reinforcement Learning</p></a></li><li class=mb-2></li><li class=mt-1><a href=/neurips2024/posters/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Posters</p></a></li><li class=mt-1><a href=/neurips2024/tags/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>Tags</p></a></li></ul></div></label></div></div></div></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("menu-blur");n.style.opacity=t/300})</script><div class="relative flex flex-col grow"><main id=main-content class=grow><article><div id=hero class="h-[150px] md:h-[200px]"></div><div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom" style=background-image:url(/neurips2024/posters/1ojaktylz4/cover_hu14680234469473730174.png)><div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal"></div><div class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal"></div></div><div id=background-blur class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div><script>window.addEventListener("scroll",function(){var t=window.pageYOffset||document.documentElement.scrollTop||document.body.scrollTop||0,n=document.getElementById("background-blur");n.style.opacity=t/300})</script><header id=single_header class="mt-5 max-w-prose"><ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden"><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/>NeurIPS 2024</a><span class="px-1 text-primary-500">/</span></li><li class=inline><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/posters/>Posters</a><span class="px-1 text-primary-500">/</span></li><li class="inline hidden"><a class="hover:underline decoration-neutral-300 dark:underline-neutral-600" href=/neurips2024/posters/1ojaktylz4/>ANT: Adaptive Noise Schedule for Time Series Diffusion Models</a><span class="px-1 text-primary-500">/</span></li></ol><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">ANT: Adaptive Noise Schedule for Time Series Diffusion Models</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time><span class="px-2 text-primary-500">&#183;</span><span>4333 words</span><span class="px-2 text-primary-500">&#183;</span><span title="Reading time">21 mins</span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=views_posters/1ojAkTylz4/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=views>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 576 512"><path fill="currentcolor" d="M288 32c-80.8.0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7.0 24.6C17.3 304 48.6 356 95.4 399.4 142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1 3.3-7.9 3.3-16.7.0-24.6-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144 64.5-144 144-144 144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64-11.5.0-22.3-3-31.6-8.4-.2 2.8-.4 5.5-.4 8.4.0 53 43 96 96 96s96-43 96-96-43-96-96-96c-2.8.0-5.6.1-8.4.4 5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<span id=likes_posters/1ojAkTylz4/index.md class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title=likes>loading</span>
<span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span></span><span class="px-2 text-primary-500">&#183;</span><span>
<button id=button_likes class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400" onclick=process_article()>
<span id=button_likes_heart style=display:none class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
</span></span><span id=button_likes_emtpty_heart class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M244 84l11.1 12 12-11.98C300.6 51.37 347 36.51 392.6 44.1 461.5 55.58 512 115.2 512 185.1V190.9c0 41.5-17.2 81.2-47.6 109.5L283.7 469.1c-7.5 7-17.4 10.9-27.7 10.9S235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1.0 232.4.0 190.9V185.1c0-69.9 50.52-129.52 119.4-141 44.7-7.59 92 7.27 124.6 39.9C243.1 84 244 84.01 244 84zm11.1 79.9-45-46.8c-21.7-20.82-52.5-30.7-82.8-25.66C81.55 99.07 48 138.7 48 185.1V190.9c0 28.2 11.71 55.2 32.34 74.4L256 429.3l175.7-164c20.6-19.2 32.3-46.2 32.3-74.4V185.1c0-46.4-33.6-86.03-79.3-93.66C354.4 86.4 323.6 96.28 301.9 117.1l-46.8 46.8z"/></svg>
</span></span><span id=button_likes_text>&nbsp;Like</span></button></span></div><div class="flex flex-row flex-wrap items-center"><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/machine-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Machine Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/deep-learning/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">Deep Learning
</span></span></span><span style=margin-top:.5rem class=mr-2 onclick='window.open("/neurips2024/tags/-yonsei-university/","_self")'><span class=flex style=cursor:pointer><span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">üè¢ Yonsei University</span></span></span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt="AI Paper Reviewer" src=/neurips2024/img/avatar_hu1344562329374673026.png><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">Author</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">AI Paper Reviewer</div><div class="text-sm text-neutral-700 dark:text-neutral-400">As an AI, I specialize in crafting insightful blog content about cutting-edge research in the field of artificial intelligence</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://neurips.cc/ target=_blank aria-label=Homepage rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg fill="currentcolor" height="800" width="800" id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 491.398 491.398"><g><g id="Icons_19_"><path d="M481.765 220.422 276.474 15.123c-16.967-16.918-44.557-16.942-61.559.023L9.626 220.422c-12.835 12.833-12.835 33.65.0 46.483 12.843 12.842 33.646 12.842 46.487.0l27.828-27.832v214.872c0 19.343 15.682 35.024 35.027 35.024h74.826v-97.62c0-7.584 6.146-13.741 13.743-13.741h76.352c7.59.0 13.739 6.157 13.739 13.741v97.621h74.813c19.346.0 35.027-15.681 35.027-35.024V239.091l27.812 27.815c6.425 6.421 14.833 9.63 23.243 9.63 8.408.0 16.819-3.209 23.242-9.63 12.844-12.834 12.844-33.65.0-46.484z"/></g></g></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/NeurIPSConf target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href target=_blank aria-label=Line rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg id="Capa_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 14.707 14.707"><g><rect x="6.275" y="0" style="fill:currentColor" width="2.158" height="14.707"/></g></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/deep-diver/paper-reviewer/ target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://x.com/algo_diver/ target=_blank aria-label=X-Twitter rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8"><div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]"><details open id=TOCView class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block"><summary class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#ant-adaptive-noise>ANT: Adaptive Noise</a></li><li><a href=#non-stationary-ts>Non-stationary TS</a></li><li><a href=#linear-schedule-use>Linear Schedule Use</a></li><li><a href=#ant-score-robustness>ANT Score Robustness</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden"><summary class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">Table of Contents</summary><div class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600"><nav id=TableOfContents><ul><li><ul><li><a href=#tldr>TL;DR</a><ul><li><a href=#key-takeaways>Key Takeaways</a></li><li><a href=#why-does-it-matter>Why does it matter?</a></li><li><a href=#visual-insights>Visual Insights</a></li></ul></li><li><a href=#in-depth-insights>In-depth insights</a><ul><li><a href=#ant-adaptive-noise>ANT: Adaptive Noise</a></li><li><a href=#non-stationary-ts>Non-stationary TS</a></li><li><a href=#linear-schedule-use>Linear Schedule Use</a></li><li><a href=#ant-score-robustness>ANT Score Robustness</a></li><li><a href=#future-research>Future Research</a></li></ul></li><li><a href=#more-visual-insights>More visual insights</a></li><li><a href=#full-paper>Full paper</a></li></ul></li></ul></nav></div></details><script>var margin=200,marginError=50;(function(){var t=$(window),e=$("#TOCView"),s=e.height();function n(){var n=t.height()-margin;s>=n?(e.css("overflow-y","scroll"),e.css("max-height",n+marginError+"px")):(e.css("overflow-y","hidden"),e.css("max-height","9999999px"))}t.on("resize",n),$(document).ready(n)})()</script></div></div><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><br><div class="flex flex-row flex-wrap items-center space-x-2"><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 48 48" fill="none"><rect width="48" height="48" fill="#fff" fill-opacity=".01"/><path d="M18 43V22c0-3.3137 2.6863-6 6-6s6 2.6863 6 6V43" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M12 40V22c0-6.6274 5.3726-12 12-12s12 5.3726 12 12V40" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M6 35V22C6 12.0589 14.0589 4 24 4s18 8.0589 18 18V35" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 44V31" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/><path d="M24 24.625v-2.75" stroke="#000" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"/></svg>
</span></span><span>1ojAkTylz4</span></span></span></div><div class="flex mt-2"><span class="rounded-full bg-primary-500 dark:bg-primary-400 text-neutral-50 dark:text-neutral-800 px-1.5 py-[1px] text-sm font-normal"><span class="flex flex-row items-center"><span class=mr-1><span class="relative block icon"><svg fill="#000" height="800" width="800" id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 511.999 511.999"><g><g><path d="M421.578 190.264l-99.847-99.847c-2.439-2.439-6.391-2.439-8.829.0L82.824 320.495c-2.439 2.439-2.439 6.392.0 8.829l99.847 99.847c2.439 2.439 6.391 2.439 8.829.0l230.078-230.078C424.017 196.655 424.017 192.703 421.578 190.264z"/></g></g><g><g><path d="M506.511 87.672 424.323 5.484c-7.308-7.31-19.175-7.315-26.488.0L348.219 55.1c-2.439 2.439-2.439 6.391.0 8.829l99.847 99.847c2.439 2.437 6.391 2.437 8.829.0l49.616-49.616C513.826 106.847 513.826 94.987 506.511 87.672z"/></g></g><g><g><path d="M508.133 491.11c-1.054-9.556-9.489-16.599-19.104-16.599H111.633l36.058-15.163c4.088-1.719 5.131-7.034 1.994-10.17l-86.854-86.854c-3.137-3.135-8.451-2.094-10.17 1.994C52.224 365.359 2.052 484.66 1.627 485.707c-5.815 13.208 4.855 27.01 18.107 26.263H489.52C500.566 511.97 509.379 502.408 508.133 491.11z"/></g></g></svg>
</span></span><span>Seunghan Lee et el.</span></span></span></div></div><p><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href="https://openreview.net/forum?id=1ojAkTylz4" target=_blank role=button>‚Üó OpenReview
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href=https://neurips.cc/virtual/2024/poster/96850 target=_blank role=button>‚Üó NeurIPS Homepage
</a><a class="!rounded-md bg-primary-600 px-4 py-2 !text-neutral !no-underline hover:!bg-primary-500 dark:bg-primary-800 dark:hover:!bg-primary-700" href="https://huggingface.co/spaces/huggingface/paper-central?tab=tab-chat-with-paper&amp;paper_id=1ojAkTylz4&amp;paper_from=neurips" target=_blank role=button>‚Üó Chat</a></p><audio controls><source src=https://ai-paper-reviewer.com/1ojAkTylz4/podcast.wav type=audio/wav>Your browser does not support the audio element.</audio><h3 class="relative group">TL;DR<div id=tldr class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#tldr aria-label=Anchor>#</a></span></h3><div class="lead text-neutral-500 dark:text-neutral-400 !mb-9 text-xl"><p>Time series (TS) data presents unique challenges for diffusion models, and existing methods often struggle with suboptimal performance due to the inherent non-stationarity of TS and improper noise schedules. Choosing the right noise schedule is crucial as it dictates the model&rsquo;s ability to learn effectively and generate high-quality results. Poorly chosen noise schedules can lead to wasted computation and subpar outcomes.</p><p>ANT addresses this by automatically generating noise schedules tailored to the specific characteristics of each TS dataset. This is achieved by using statistics to quantify the non-stationarity of a TS dataset. ANT then selects a noise schedule that gradually reduces this non-stationarity across diffusion steps, improving learning, and ultimately leading to enhanced performance. The researchers demonstrate the effectiveness of ANT through extensive experiments, showcasing significant gains across various TS tasks.</p></div><h4 class="relative group">Key Takeaways<div id=key-takeaways class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#key-takeaways aria-label=Anchor>#</a></span></h4><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-1e289d67c44249ab6cbc43c50434dfb6></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-1e289d67c44249ab6cbc43c50434dfb6",{strings:[" ANT automatically determines optimal noise schedules based on time series data statistics. "],speed:10,lifeLike:!0,startDelay:0,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-b1f49439a9c7ab7716e94c36c6bfd8b8></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-b1f49439a9c7ab7716e94c36c6bfd8b8",{strings:[" The proposed method improves performance on time series forecasting, refinement, and generation tasks. "],speed:10,lifeLike:!0,startDelay:1e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><div class="flex px-4 py-3 rounded-md bg-primary-100 dark:bg-primary-900"><span class="text-primary-400 ltr:pr-3 rtl:pl-3 flex items-center"><span class="relative block icon"><svg width="800" height="800" viewBox="0 0 24 24" fill="none"><path d="M9.15316 5.40838C10.4198 3.13613 11.0531 2 12 2s1.5802 1.13612 2.8468 3.40837l.3277.58786C15.5345 6.64193 15.7144 6.96479 15.9951 7.17781c.2806.21302.629999999999999.29209 1.329.45024L17.9605 7.77203C20.4201 8.32856 21.65 8.60682 21.9426 9.54773c.2926.94087-.5458 1.92137-2.2227 3.88217L19.2861 13.9372C18.8096 14.4944 18.5713 14.773 18.4641 15.1177 18.357 15.4624 18.393 15.8341 18.465 16.5776L18.5306 17.2544C18.7841 19.8706 18.9109 21.1787 18.1449 21.7602 17.3788 22.3417 16.2273 21.8115 13.9243 20.7512L13.3285 20.4768C12.6741 20.1755 12.3469 20.0248 12 20.0248S11.3259 20.1755 10.6715 20.4768L10.0757 20.7512c-2.30302 1.0603-3.45452 1.5905-4.22055 1.009C5.08912 21.1787 5.21588 19.8706 5.4694 17.2544L5.53498 16.5776C5.60703 15.8341 5.64305 15.4624 5.53586 15.1177 5.42868 14.773 5.19043 14.4944 4.71392 13.9372L4.2801 13.4299c-1.67685-1.9608-2.51528-2.9413-2.22268-3.88217C2.35002 8.60682 3.57986 8.32856 6.03954 7.77203l.63635-.14398C7.37485 7.4699 7.72433 7.39083 8.00494 7.17781 8.28555 6.96479 8.46553 6.64194 8.82547 5.99623L9.15316 5.40838z" fill="#1c274c"/></svg>
</span></span><span class=dark:text-neutral-300><div id=typeit-93adeabbd0365f1d484b9ad68b9fd160></div><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt("#typeit-93adeabbd0365f1d484b9ad68b9fd160",{strings:[" ANT is model-agnostic and efficient, requiring minimal computational overhead. "],speed:10,lifeLike:!0,startDelay:2e3,breakLines:!0,waitUntilVisible:!0,loop:!1}).go()})</script></span></div><h4 class="relative group">Why does it matter?<div id=why-does-it-matter class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#why-does-it-matter aria-label=Anchor>#</a></span></h4><p>This paper is important because it tackles a critical issue in time series diffusion models: suboptimal performance due to improper noise schedules. By introducing ANT, a method for automatically determining optimal noise schedules, the researchers provide a practical solution that significantly improves performance across various tasks. This work opens up new avenues for research in automated hyperparameter optimization within diffusion models, potentially impacting various fields that rely on time series analysis.</p><hr><h4 class="relative group">Visual Insights<div id=visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#visual-insights aria-label=Anchor>#</a></span></h4><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_0_1.jpg alt></figure></p><blockquote><p>The figure shows the forecasting performance (in terms of CRPS) of various time series diffusion models on the M4 dataset. ANT (Adaptive Noise Schedule for Time Series diffusion models) achieves a significant improvement (27.8% gain) over the baseline TSDiff model by automatically selecting an appropriate noise schedule based on the dataset&rsquo;s characteristics. Other models shown include DeepState, Transformer, CSDI, and TFT.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_5_1.jpg alt></figure></p><blockquote><p>This table presents the results of time series forecasting experiments using various methods, including DeepAR, DeepState, Transformer, TFT, CSDI, TSDiff, and TSDiff+ANT (the proposed method). The results are shown for different datasets (Solar, Electricity, Traffic, Exchange, M4, UberTLC, KDDCup, and Wikipedia) and are expressed in terms of Continuous Ranked Probability Score (CRPS), a metric for evaluating probabilistic forecasts. The &lsquo;+ Gain (%)&rsquo; column indicates the percentage improvement in CRPS achieved by TSDiff+ANT compared to the baseline TSDiff method. The table shows that TSDiff+ANT significantly outperforms TSDiff on most datasets, demonstrating the effectiveness of the proposed adaptive noise schedule.</p></blockquote><h3 class="relative group">In-depth insights<div id=in-depth-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#in-depth-insights aria-label=Anchor>#</a></span></h3><h4 class="relative group">ANT: Adaptive Noise<div id=ant-adaptive-noise class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ant-adaptive-noise aria-label=Anchor>#</a></span></h4><p>The heading &ldquo;ANT: Adaptive Noise&rdquo; suggests a method for adjusting noise levels in a system, likely a machine learning model, in an adaptive manner. <strong>Adaptive</strong> implies the noise adjustment isn&rsquo;t static but changes dynamically based on some criteria. The &ldquo;ANT&rdquo; acronym, while not explained here, likely represents a specific methodology or algorithm developed by the authors. The adaptive nature points towards a system that <strong>learns and optimizes</strong> noise settings during training or operation. This approach could be beneficial in scenarios where a constant noise level is suboptimal. For instance, the model might start with higher noise levels initially to explore a wider solution space, then gradually reduce noise as it learns to focus on a more refined solution. <strong>The key advantage</strong> would be improved performance and potentially faster convergence compared to methods using fixed noise schedules. We can infer that the paper details the implementation and evaluation of this adaptive noise technique, possibly showing performance gains on various tasks.</p><h4 class="relative group">Non-stationary TS<div id=non-stationary-ts class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#non-stationary-ts aria-label=Anchor>#</a></span></h4><p>The concept of &lsquo;Non-stationary TS&rsquo; (Time Series) is crucial to understanding the paper&rsquo;s core contribution. <strong>Non-stationarity</strong> refers to the inherent characteristic of many real-world time series, where statistical properties like mean, variance, or autocorrelation change over time. The authors cleverly leverage this characteristic by recognizing that standard noise scheduling techniques often fail to account for the evolving nature of non-stationary data. They propose an <strong>adaptive noise scheduling method</strong> that implicitly understands the time series&rsquo; non-stationarity, making the diffusion process more effective and enabling better performance. <strong>Quantifying non-stationarity</strong> is a key part of their approach, using statistics like integrated autocorrelation time (IAT) and its absolute version (IAAT) to characterize the data and guide the selection of appropriate noise schedules. This thoughtful consideration of the intrinsic data properties distinguishes their method, demonstrating that addressing non-stationarity directly leads to superior diffusion model training and, consequently, superior results in time series forecasting, refinement, and generation.</p><h4 class="relative group">Linear Schedule Use<div id=linear-schedule-use class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#linear-schedule-use aria-label=Anchor>#</a></span></h4><p>The concept of &lsquo;Linear Schedule Use&rsquo; within the context of time series diffusion models is crucial for understanding the paper&rsquo;s core contribution. A linear schedule, in this context, refers to how noise is gradually added (forward diffusion) or removed (reverse diffusion) during the process of training the diffusion model. <strong>The key advantage of a linear schedule is its simplicity and efficiency</strong>. It systematically reduces non-stationarity in time series data, ensuring all diffusion steps contribute equally to the training process, unlike abrupt noise introduction seen in other schedules. This linear reduction enables the model to better learn the underlying temporal dependencies. <strong>The paper highlights that employing a linear schedule makes diffusion step embedding unnecessary</strong>, simplifying model architecture and improving efficiency. <strong>While a linear schedule offers these advantages, the paper also explores the robustness of non-linear alternatives</strong>. The superior performance and robustness of non-linear schedules, particularly regarding the number of diffusion steps, is a key finding. Therefore, the choice between a linear and non-linear schedule depends on a tradeoff between simplicity and robustness to the specific characteristics of a given time series dataset.</p><h4 class="relative group">ANT Score Robustness<div id=ant-score-robustness class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#ant-score-robustness aria-label=Anchor>#</a></span></h4><p>The robustness of the ANT score is crucial for its reliability and practical applicability. <strong>Robustness to various non-stationarity statistics</strong> ensures the method&rsquo;s effectiveness across different datasets and their specific characteristics. The authors demonstrate this by testing the score with multiple statistics, indicating consistent performance despite variations in how non-stationarity is measured. <strong>Robustness to the choice of discrepancy metric</strong> between the ideal and actual non-stationarity curves further strengthens the ANT score‚Äôs reliability. The study&rsquo;s exploration of multiple discrepancy metrics highlights the score&rsquo;s resilience to different mathematical representations of curve similarity. <strong>Insensitivity to the total number of diffusion steps (T)</strong> is a significant advantage, allowing flexible application across various computational constraints. This characteristic is demonstrated by consistent results across different T values, ensuring practicality regardless of resource limitations. In essence, <strong>the multifaceted robustness checks</strong> detailed in the paper significantly enhance the ANT score&rsquo;s credibility and establish its value as a reliable tool for adaptive noise schedule selection in time series diffusion models. Further investigation into the sensitivity to other hyperparameters would provide additional insights into its overall robustness.</p><h4 class="relative group">Future Research<div id=future-research class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#future-research aria-label=Anchor>#</a></span></h4><p>The paper&rsquo;s &lsquo;Future Research&rsquo; section could explore several promising avenues. <strong>Extending ANT to other generative models</strong> beyond diffusion models is crucial. Investigating the applicability of ANT to different data modalities (images, text) would broaden its impact. <strong>Developing more sophisticated non-stationarity metrics</strong> is important to capture nuanced temporal dynamics. Currently, ANT relies on a single metric; a multi-faceted approach would improve robustness and accuracy. <strong>A deeper theoretical analysis</strong> of the relationship between noise schedule, non-stationarity, and model performance is needed. The current work provides empirical evidence, but rigorous theoretical understanding would strengthen its foundations. <strong>Investigating the impact of different noise schedule types</strong> is another avenue. While the paper explores several types, a more exhaustive study could reveal further insights. Finally, <strong>exploring different optimization strategies</strong> for finding the optimal schedule could enhance efficiency. The current method may not scale well for extremely large datasets; optimized search algorithms could address this limitation.</p><h3 class="relative group">More visual insights<div id=more-visual-insights class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#more-visual-insights aria-label=Anchor>#</a></span></h3><details><summary>More on figures</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_2_1.jpg alt></figure></p><blockquote><p>This figure demonstrates the adaptive noise schedule (ANT) proposed in the paper. Panel (a) compares the forward diffusion process of a standard noise schedule with ANT&rsquo;s adaptive schedule. It highlights how ANT gradually corrupts the time series (TS) data into noise, unlike the abrupt corruption seen in standard schedules. Panel (b) shows non-stationarity curves for both schedules, plotting non-stationarity against the percentage of diffusion steps. ANT&rsquo;s schedule exhibits a more linear decrease in non-stationarity, implying a smoother and more effective diffusion process. Finally, panel (c) shows a correlation between the linearity of the non-stationarity curve and the forecasting performance, indicating that schedules with a more linear non-stationarity reduction achieve better results.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_3_1.jpg alt></figure></p><blockquote><p>This figure illustrates the ANT framework. It demonstrates how the proposed adaptive noise schedule (ANT) gradually corrupts the time series (TS) data into random noise, unlike the abrupt corruption of a baseline schedule. The figure also shows how ANT reduces non-stationarity and improves model performance by making the non-stationarity curves closer to a linear line.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_4_1.jpg alt></figure></p><blockquote><p>This figure demonstrates the robustness of non-linear noise schedules (cosine and sigmoid) compared to linear schedules in terms of continuous ranked probability score (CRPS) and non-stationarity curves, across different numbers of diffusion steps (T). The left panel (a) shows that the coefficient of variation of CRPS remains relatively constant for non-linear schedules as T increases, indicating stability of performance regardless of the number of diffusion steps. In contrast, linear schedules show more variability. The right panel (b) visually confirms this by showing that the shapes of the non-stationarity curves for non-linear schedules remain consistent across different T values, whereas linear schedules show a more significant change in curve shape as T varies. This suggests that non-linear schedules are less sensitive to the hyperparameter T, leading to more reliable performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_4_2.jpg alt></figure></p><blockquote><p>This figure demonstrates the robustness of non-linear noise schedules to changes in the total number of diffusion steps (T). Panel (a) shows that the continuous ranked probability score (CRPS), a measure of forecasting accuracy, remains relatively stable for non-linear schedules across different values of T. In contrast, linear schedules exhibit more variability in CRPS as T changes. Panel (b) visually supports this finding by showing that the non-stationarity curves for non-linear schedules remain consistent across various T values, indicating their robustness to the choice of T.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_7_1.jpg alt></figure></p><blockquote><p>This figure presents an ablation study on the Adaptive Noise Schedule (ANT) method. Panel (a) shows a scatter plot illustrating the relationship between ANT score and the Continuous Ranked Probability Score (CRPS), a measure of forecasting performance. A lower ANT score indicates a better-performing schedule. Panel (b) shows a bar chart visualizing the correlation between the ANT score and CRPS when using different combinations of ANT&rsquo;s components (linear reduction of non-stationarity, noise collapse, and sufficient number of steps). The results demonstrate that using all three components yields the strongest correlation, highlighting the effectiveness of ANT&rsquo;s comprehensive approach.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_8_1.jpg alt></figure></p><blockquote><p>This figure visualizes the performance of ANT in selecting optimal noise schedules compared to an oracle. For each dataset (Solar, Electricity, Traffic, Exchange, M4, UberTLC, KDDCup, Wikipedia), it shows the relative ratio of the ANT score to the oracle score for different numbers of diffusion steps (T = 10, 20, 50, 75, 100). A lower relative ratio indicates better performance. The size of the circles represents the value of the CRPS (Continuous Ranked Probability Score), with larger circles representing worse performance. The red circles represent the schedules selected by ANT, while the orange circles represent the baseline schedule.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_8_2.jpg alt></figure></p><blockquote><p>This figure illustrates the ANT framework. Panel (a) compares the forward diffusion process using a standard schedule and ANT&rsquo;s adaptive schedule, highlighting how ANT gradually corrupts the time series (TS) data into noise, unlike the abrupt corruption of the standard schedule. Panel (b) shows the non-stationarity curves for both schedules and their deviation from a perfect linear decrease. The adaptive schedule from ANT exhibits a lower discrepancy. Panel (c) demonstrates that improved performance is directly related to how close the non-stationarity curve is to a linear decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_8_3.jpg alt></figure></p><blockquote><p>This figure shows the Œ≤t (variance of the noise) across different steps for a cosine schedule with different temperature parameters (œÑ). The x-axis represents the diffusion steps, and the y-axis represents the Œ≤t values. The different colored lines show the Œ≤t values for œÑ = 0.5, œÑ = 1.0, and œÑ = 2.0. The figure demonstrates the impact of the temperature parameter on the shape of the noise schedule, with higher temperatures leading to a more abrupt increase in noise towards the end of the diffusion process.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_20_1.jpg alt></figure></p><blockquote><p>This figure demonstrates the ANT&rsquo;s adaptive noise schedule. The leftmost panel (a) compares the forward diffusion process of TSDiff with and without ANT. While the base schedule (without ANT) abruptly corrupts the time series, ANT gradually reduces non-stationarity until it reaches random noise. The middle panel (b) visualizes this by plotting non-stationarity against the diffusion process. ANT&rsquo;s approach aims to create a linear non-stationarity decrease. The rightmost panel (c) shows that better performance is related to non-stationarity curves more closely approximating a linear decrease.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_20_2.jpg alt></figure></p><blockquote><p>This figure visualizes the non-stationarity curves for all variables of the Solar dataset using both the base schedule and the schedule proposed by ANT. The shaded area represents the 5th and 95th percentiles. It shows that ANT&rsquo;s proposed schedule more closely resembles the ideal linear line (black), indicating that ANT effectively reduces non-stationarity.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_22_1.jpg alt></figure></p><blockquote><p>This figure demonstrates the ANT (Adaptive Noise Schedule for Time Series Diffusion Models) framework. Panel (a) compares the noise level at each step for a baseline schedule and ANT&rsquo;s proposed schedule, illustrating how ANT gradually corrupts time series data into noise. Panel (b) visualizes non-stationarity through the diffusion process for both the baseline and ANT; the less deviation from a linear decrease of the non-stationarity curve the better. Panel (c) displays the correlation between the performance and discrepancy from a linear line, suggesting that smaller discrepancies mean better performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_22_2.jpg alt></figure></p><blockquote><p>This figure visualizes the distribution of the Integrated Absolute Autocorrelation Time (IAAT) for real and generated time series data using different methods (Real, TSDiff, and TSDiff+ANT). Subfigure (a) shows histograms, (b) displays kernel density estimations, and (c) illustrates Gaussian mixture model fits. The figure helps to compare the similarity of the generated time series data distribution to that of the real data, demonstrating the effectiveness of ANT in improving the quality of generated time series data.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_23_1.jpg alt></figure></p><blockquote><p>This figure illustrates the ANT framework. It compares the base schedule (without ANT) with the proposed ANT schedule. Panel (a) shows how the non-stationarity changes over diffusion steps for both methods, highlighting the gradual corruption in ANT versus abrupt corruption in the base schedule. Panel (b) plots non-stationarity curves against diffusion step percentage, demonstrating that ANT leads to a curve closer to linear decrease. Finally, panel (c) shows that better performance correlates with a more linear non-stationarity curve.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/figures_24_1.jpg alt></figure></p><blockquote><p>This figure demonstrates the forecasting performance improvement achieved by ANT (Adaptive Noise Schedule for Time Series diffusion models) on the M4 dataset, compared to several other time series forecasting methods. It highlights ANT&rsquo;s ability to choose an appropriate noise schedule based on the dataset&rsquo;s statistics, achieving a 27.8% gain in forecasting accuracy over a linear schedule using TSDiff.</p></blockquote></details><details><summary>More on tables</summary><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_5_2.jpg alt></figure></p><blockquote><p>This table presents the results of time series forecasting experiments on eight different datasets using various methods. It compares the performance of the proposed ANT method (applied to TSDiff) with other state-of-the-art time series forecasting approaches, including DeepAR, DeepState, TFT, CSDI, and TSDiff without ANT. The table shows the Continuous Ranked Probability Score (CRPS) for each method on each dataset, allowing for a direct comparison of forecasting accuracy across different models and datasets.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_5_3.jpg alt></figure></p><blockquote><p>This table presents the results of time series refinement experiments conducted using various methods (LMC-MS, LMC-Q, ML-MS, ML-Q) with and without the proposed ANT method. The results are shown for eight different datasets (Solar, Electricity, Traffic, Exchange, M4, UberTLC, KDDCup, Wikipedia). The table compares the performance of the refinement methods in terms of CRPS (Continuous Ranked Probability Score) and also shows the percentage gain achieved by using ANT. Lower CRPS values indicate better refinement performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_5_4.jpg alt></figure></p><blockquote><p>This table lists the candidate noise schedules explored in the ANT experiments. It shows three different noise functions (Linear, Cosine, Sigmoid), each evaluated with varying temperature parameters (œÑ) and numbers of diffusion steps (T). The combinations of these parameters form the pool of candidate schedules from which ANT selects the optimal schedule for each dataset.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_6_1.jpg alt></figure></p><blockquote><p>This table presents the results of time series forecasting experiments using various methods, including DeepAR, DeepState, TFT, CSDI, and TSDiff, with and without ANT. The results are shown for various datasets and prediction horizons. The &lsquo;+ Gain (%)&rsquo; column shows the percentage improvement in performance achieved by using ANT.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_6_2.jpg alt></figure></p><blockquote><p>This table presents the results of time series forecasting experiments conducted on eight datasets using various methods, including DeepAR, DeepState, TFT, CSDI, and TSDiff. The table compares the Continuous Ranked Probability Score (CRPS) achieved by each method across the different datasets. It highlights the performance improvement obtained by using ANT (Adaptive Noise Schedule for Time series diffusion models) with TSDiff compared to TSDiff without ANT and other baseline methods.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_6_3.jpg alt></figure></p><blockquote><p>This table presents the results of time series refinement experiments. It compares the performance of TSDiff with and without ANT (Adaptive Noise Schedule) across eight different datasets and using different refinement methods (ML-MS, ML-Q, LMC-MS, LMC-Q). The &lsquo;Gain (%) column shows the percentage improvement achieved by using ANT.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_7_1.jpg alt></figure></p><blockquote><p>This table presents the results of an ablation study conducted to evaluate the contribution of each component of the ANT (Adaptive Noise Schedule) score in selecting an appropriate noise schedule for time series diffusion models. The ANT score comprises three components: Alinear (linear reduction of non-stationarity), Anoise (noise collapse), and Astep (sufficient number of steps). The table shows the schedules selected by ANT when using different combinations of these components, including when all three components are used or when only some are utilized. The &lsquo;Oracle&rsquo; row indicates the best-performing schedule for each dataset, providing a benchmark for comparison.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_7_2.jpg alt></figure></p><blockquote><p>This table demonstrates the robustness of ANT to the choice of statistics for measuring non-stationarity. It shows the average CRPS across eight datasets for forecasting tasks using ANT with various statistics (VarAC, Lag1AC, IAAT). The results indicate that ANT outperforms the model without ANT across all statistics, with IAAT showing the best performance. This is likely because IAAT considers AC at all lags, while Lag1AC and VarAC focus on single lags and variance of AC, respectively.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_8_1.jpg alt></figure></p><blockquote><p>This table presents the Continuous Ranked Probability Score (CRPS) for various time series forecasting methods applied to eight different datasets. The methods compared include DeepAR, DeepState, TFT, CSDI, TSDiff, and TSDiff+ANT (the proposed method). The table shows the CRPS values for each method on each dataset, allowing for a comparison of performance across different models and datasets. Lower CRPS values indicate better forecasting accuracy. The &lsquo;Gain (%) column shows the percentage improvement of TSDiff+ANT over the baseline TSDiff model for each dataset.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_8_2.jpg alt></figure></p><blockquote><p>This table compares the training and inference times of TSDiff with and without ANT across eight datasets. The training time is reduced for datasets where linear schedules are selected by ANT because diffusion step embedding is eliminated. Inference time efficiency improves due to the reduced number of diffusion steps (T) used with ANT.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_8_3.jpg alt></figure></p><blockquote><p>This table displays the inference time of the TSDiff model with different numbers of diffusion steps (T). The results show that a smaller T leads to faster inference time, with the best forecasting performance achieved at T=75. Notably, even though the base schedule uses a larger T (100), its inference time is slower and its performance worse.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_8_4.jpg alt></figure></p><blockquote><p>This table presents the Continuous Ranked Probability Score (CRPS) results for time series forecasting tasks, comparing models with and without the ANT method. A constraint is applied on the maximum number of diffusion steps (T). The results demonstrate that ANT, even with fewer diffusion steps, can still achieve better performance than the baseline model without ANT.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_8_5.jpg alt></figure></p><blockquote><p>This table compares the average CRPS (Continuous Ranked Probability Score) across eight datasets for time series forecasting using three different noise schedules: Linear, Cosine [24], and Zero [21]. The results demonstrate the superior performance of the ANT method compared to existing approaches.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_12_1.jpg alt></figure></p><blockquote><p>This table presents the statistics of eight datasets used in the paper&rsquo;s experiments. For each dataset, it shows the number of training and testing samples (Ntrain, Ntest), the domain the data comes from, the frequency of the data (daily or hourly), the median length of the time series, and the length of the input and target windows (L, H) used in the forecasting tasks.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_13_1.jpg alt></figure></p><blockquote><p>This table lists the hyperparameters used in the experiments of the paper, including the learning rate, optimizer, batch size, epochs, gradient clipping threshold, number of residual layers and channels, dimension of diffusion step embedding, normalization method, and the self-guidance scale parameter. The table also specifies the values used for each hyperparameter and provides a separate listing of the scale parameter values for each dataset used in the experiments.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_16_1.jpg alt></figure></p><blockquote><p>This table demonstrates the robustness of the ANT method across various statistics used to quantify non-stationarity in time series. It shows the CRPS (Continuous Ranked Probability Score) for time series forecasting across eight datasets (Solar, Electricity, Traffic, Exchange, M4, UberTLC, KDDCup, Wikipedia) using the TSDiff model without ANT and with ANT using three different non-stationarity statistics (VarAC, LagAC, IAAT). The &lsquo;Oracle&rsquo; row indicates the best possible CRPS achievable for each dataset. The table&rsquo;s purpose is to show that ANT&rsquo;s performance is consistent regardless of which non-stationarity metric is used.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_17_1.jpg alt></figure></p><blockquote><p>This table presents an ablation study on the ANT (Adaptive Noise Schedule) method. It shows the schedules selected by ANT when using different combinations of its three components: linear reduction of non-stationarity (Alinear), noise collapse (Anoise), and sufficient steps (Astep). By comparing the schedules obtained using different combinations of components with the oracle (best-performing schedule), we can understand the contribution of each component to ANT&rsquo;s performance and identify the most important factor for schedule selection.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_17_2.jpg alt></figure></p><blockquote><p>This table presents the CRPS (Continuous Ranked Probability Score) for forecasting tasks across eight datasets. The results are shown for three different statistics representing non-stationarity: VarAC (Variance of Autocorrelation), LagAC (Lag-one Autocorrelation), and IAAT (Integrated Absolute Autocorrelation Time). The table compares the performance of the baseline TSDiff model and the proposed TSDiff+ANT method. The &lsquo;Oracle&rsquo; row indicates the lowest CRPS achieved among all candidate schedules for each dataset. The results demonstrate the robustness of the ANT method across various statistics of non-stationarity, as it consistently outperforms the baseline model, regardless of the chosen statistic. The IAAT statistic appears to provide the best performance in most cases.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_18_1.jpg alt></figure></p><blockquote><p>This table presents the noise schedules proposed by the ANT algorithm under various constraints on the total number of diffusion steps (T). The schedules are shown for different datasets (Solar, Electricity, Traffic, Exchange, M4, UberTLC, KDDCup, Wikipedia) and for different values of T (10, 20, 50, 75, 100). The schedules proposed without any constraints on T are highlighted in red. This demonstrates how ANT adapts the schedule based on the dataset and resource limitations.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_18_2.jpg alt></figure></p><blockquote><p>This table presents the results of time series forecasting experiments using various methods. The methods compared are DeepAR, DeepState, TFT, CSDI, TSDiff, and TSDiff+ANT (the proposed method). The table shows the Continuous Ranked Probability Score (CRPS) for each method on eight different datasets (Solar, Electricity, Traffic, Exchange, M4, UberTLC, KDDCup, and Wikipedia). A lower CRPS indicates better forecasting performance. The &lsquo;Gain (%) &rsquo; column shows the percentage improvement of TSDiff+ANT over TSDiff. The table is organized to showcase the performance improvements achieved using the ANT (Adaptive Noise Schedule) method across multiple datasets.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_18_3.jpg alt></figure></p><blockquote><p>This table compares the performance of ANT&rsquo;s adaptive noise schedule selection method against two other noise schedules commonly used in computer vision: a cosine schedule and a zero-signal-to-noise-ratio schedule. The results show ANT outperforms both on average CRPS across eight time series forecasting datasets.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_20_1.jpg alt></figure></p><blockquote><p>This table shows the number of variables (D), the length of the input window (L), and the length of the target window (H) for the three datasets used in the multivariate time series forecasting experiments: Solar, Electricity, and M4. The values provided are used to set up the forecasting experiments.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_20_2.jpg alt></figure></p><blockquote><p>This table presents the results of time series forecasting experiments using the CSDI model with and without the ANT method. The ANT method is applied using two different strategies: one with a single noise schedule for all variables (mIAAT), and one with a variable-specific noise schedule (IAAT). The table shows the CRPS (Continuous Ranked Probability Score) achieved on three datasets (Solar, M4, and Electricity). The &lsquo;Oracle&rsquo; row indicates the best performance achieved by any schedule on each dataset. The results demonstrate that using ANT with mIAAT improves performance.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_21_1.jpg alt></figure></p><blockquote><p>This table displays the inference time of the TSDiff model with different numbers of diffusion steps (T). The inference time is measured in seconds, and the CRPS (Continuous Ranked Probability Score) is also provided to show how the model performance changes with the number of steps. The table highlights that a smaller number of steps can achieve better performance (lower CRPS) than a larger number of steps, demonstrating the potential efficiency gains of the proposed method (ANT).</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_21_2.jpg alt></figure></p><blockquote><p>This table compares the training and inference times of TSDiff with and without the application of ANT across eight datasets. It shows that training time is reduced for datasets where linear schedules are selected from ANT because diffusion step embedding is eliminated. The inference time efficiency gains are also shown, highlighting significant improvements in some cases due to the reduced number of diffusion steps (T).</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_22_1.jpg alt></figure></p><blockquote><p>This table presents the results of fitting Gaussian distributions to the IAATs of real and generated time series data using the TSDiff model with and without the ANT method. It displays modality, parameters (mean and variance) and the ratio of the data points assigned to each modality for both real TS and TS generated by TSDiff. The results show that real TS exhibits a multimodal distribution, whereas TSDiff without ANT captures only one modality. TSDiff with ANT captures both modalities.</p></blockquote><p><figure><img class="my-0 rounded-md" loading=lazy src=https://ai-paper-reviewer.com/1ojAkTylz4/tables_22_2.jpg alt></figure></p><blockquote><p>This table presents the Continuous Ranked Probability Score (CRPS) and Jensen-Shannon divergence (JSD) values for the real electricity dataset and the time series generated using TSDiff with and without ANT, evaluated using three different downstream forecasters: Linear, DeepAR, and Transformer. The CRPS measures the accuracy of probabilistic forecasts, while the JSD quantifies the similarity between the probability distributions of real and generated time series in terms of their IAAT (Integrated Absolute Autocorrelation Time). Lower CRPS and JSD values indicate better performance.</p></blockquote></details><h3 class="relative group">Full paper<div id=full-paper class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#full-paper aria-label=Anchor>#</a></span></h3><div id=gallery-74bbed78db68d834df0c9670d94f6f6e class=gallery><img src=https://ai-paper-reviewer.com/1ojAkTylz4/1.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/2.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/3.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/4.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/5.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/6.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/7.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/8.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/9.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/10.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/11.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/12.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/13.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/14.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/15.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/16.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/17.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/18.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/19.png class="grid-w50 md:grid-w33 xl:grid-w25">
<img src=https://ai-paper-reviewer.com/1ojAkTylz4/20.png class="grid-w50 md:grid-w33 xl:grid-w25"></div></div><section class="flex flex-row flex-wrap justify-center pt-4 text-xl"><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://deep-diver.github.io/neurips2024/posters/1ojaktylz4/&amp;title=ANT:%20Adaptive%20Noise%20Schedule%20for%20Time%20Series%20Diffusion%20Models" title="Share on LinkedIn" aria-label="Share on LinkedIn"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M416 32H31.9C14.3 32 0 46.5.0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6.0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3.0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2.0 38.5 17.3 38.5 38.5.0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6.0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2.0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="https://twitter.com/intent/tweet/?url=https://deep-diver.github.io/neurips2024/posters/1ojaktylz4/&amp;text=ANT:%20Adaptive%20Noise%20Schedule%20for%20Time%20Series%20Diffusion%20Models" title="Tweet on Twitter" aria-label="Tweet on Twitter"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a><a target=_blank class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800" href="mailto:?body=https://deep-diver.github.io/neurips2024/posters/1ojaktylz4/&amp;subject=ANT:%20Adaptive%20Noise%20Schedule%20for%20Time%20Series%20Diffusion%20Models" title="Send via email" aria-label="Send via email"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg></span></a></section></div><script>var oid="views_posters/1ojAkTylz4/index.md",oid_likes="likes_posters/1ojAkTylz4/index.md"</script><script type=text/javascript src=/neurips2024/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span><a class="flex group mr-3" href=/neurips2024/posters/46v9axmouu/><span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&larr;</span>
<span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">AP-Adapter: Improving Generalization of Automatic Prompts on Unseen Text-to-Image Diffusion Models</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time>
</span></span></a></span><span><a class="flex text-right group ml-3" href=/neurips2024/posters/wes4wmzndy/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">Annealed Multiple Choice Learning: Overcoming limitations of Winner-takes-all with annealing</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-09-26T00:00:00+00:00>26 September 2024</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div><div class=pt-3><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class=pt-3><script src=https://utteranc.es/client.js repo=pmnxis/pmnxis.github.io issue-term=pathname label=Comment theme=dark-blue crossorigin=anonymous async></script></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label="Scroll to top" title="Scroll to top">&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2024
AI Paper Reviewer</p><p class="text-xs text-neutral-500 dark:text-neutral-400">Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a></p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/neurips2024/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://deep-diver.github.io/neurips2024/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=Search tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="Close (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body><script data-name=BMC-Widget data-cfasync=false src=https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js data-id=chansung data-description="Support me on Buy me a coffee!" data-message data-color=#FFDD00 data-position=Left data-x_margin=18 data-y_margin=18></script></html>