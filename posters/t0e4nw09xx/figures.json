[{"figure_path": "T0e4Nw09XX/figures/figures_15_1.jpg", "caption": "Figure 1: Arbitrarily Fast Rates Algorithm (Hanneke et al., 2022)", "description": "This algorithm achieves arbitrarily fast learning rates in the active learning setting.  It takes as input a label budget N and a rate function R(n). The algorithm proceeds by creating sets of labeled and unlabeled data, splitting the labeled data into batches, training ordinal SOA (Sequential Optimal Algorithm) on prefixes of batches, evaluating classifiers on unlabeled data, and forming equivalence classes based on classifier behavior. The algorithm iteratively queries labels of points that cause disagreement among classifiers, aiming to efficiently identify a classifier correctly classifying all queried points. If such a classifier is found, it's returned; otherwise, an arbitrary classifier from the equivalence classes is selected.", "section": "Arbitrarily Fast Rates"}, {"figure_path": "T0e4Nw09XX/figures/figures_26_1.jpg", "caption": "Figure 6: The VCL Game (Bousquet et al., 2021).", "description": "The figure shows the VCL game subroutine. It takes as input a labeled sequence and returns a pattern avoidance function.  The game is played between two players: the learner and the adversary. In each round, the adversary chooses a tuple of points and labels, and the learner tries to guess the labels. If the learner guesses correctly, the game continues to the next round; otherwise, the game stops. The output of the game is the pattern avoidance function, which maps each tuple of points to a vector of labels that the learner could not have guessed correctly. This function is then used to estimate the VC dimension of the partial concept class. The VC dimension is used to determine the optimal learning rates that are achievable by algorithms that have to specify the number of unlabeled examples they use ahead of time. This is a key component in the characterization of the optimal learning rates.", "section": "Combinatorial Measures"}]