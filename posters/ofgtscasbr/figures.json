[{"figure_path": "oFgTScAsBr/figures/figures_0_1.jpg", "caption": "Figure 1: (a) Ours surpasses current zero-shot methods with reduced inference time (on CSet with Gaussian \u03c3=25, see Sec. 3.2). (b) It shows better generalization across different noise types than current zero-shot & supervised/unsupervised methods (Sec. 3.3). (c) And can remove spatial correlated real-world noise, results are from SIDD benchmark [1] and FMD [2] (Sec. 3.4, Sec. 3.5).", "description": "This figure demonstrates the superior performance of the proposed method (Ours) compared to existing state-of-the-art zero-shot and supervised/unsupervised image denoising methods.  Panel (a) showcases a significant reduction in inference time while maintaining competitive performance with respect to Peak Signal-to-Noise Ratio (PSNR). Panel (b) highlights improved generalization across diverse noise types. Lastly, panel (c) visually presents the effectiveness of the method in removing real-world and medical image noise, demonstrating its superior performance compared to existing methods.", "section": "Abstract"}, {"figure_path": "oFgTScAsBr/figures/figures_2_1.jpg", "caption": "Figure 2: Example of model trained on ImageNet with 70% pixel-wise masking, denoised image is obtained by directly ensemble of predictions from fixed pre-trained weights (\"Directly ensemble\"), its performance can be further improved with iterative filling (\"+Zero-shot Optim.\").", "description": "The figure shows the results of applying a model trained on ImageNet with 70% pixel-wise masking to a noisy image.  The \"Directly ensemble\" column shows the result of simply averaging predictions from the pre-trained model, demonstrating a basic level of denoising. The \"+Zero-shot Optim.\" column, on the other hand, shows the result of applying iterative filling which further improves upon the quality of the denoised image.  This illustrates the effectiveness of the proposed iterative filling optimization step for zero-shot denoising.", "section": "2 Methods"}, {"figure_path": "oFgTScAsBr/figures/figures_2_2.jpg", "caption": "Figure 2: Example of model trained on ImageNet with 70% pixel-wise masking, denoised image is obtained by directly ensemble of predictions from fixed pre-trained weights (\"Directly ensemble\"), its performance can be further improved with iterative filling (\"+Zero-shot Optim.\").", "description": "The figure shows the PSNR and SSIM values for a noisy image, a denoised image obtained by directly averaging the predictions from a pre-trained model, and a denoised image obtained by further optimizing the pre-trained model using an iterative filling method.  The iterative filling method significantly improves the PSNR and SSIM values, demonstrating its effectiveness in enhancing denoising performance.", "section": "2.1 Motivation"}, {"figure_path": "oFgTScAsBr/figures/figures_3_1.jpg", "caption": "Figure 4: An overview of the proposed MPI paradigm consisting Masked Pre-training and Iterative filling. During pre-training D\u03b8(\u00b7) learns to reconstruct masked natural images. And the pre-trained weights \u03b8 are saved for zero-shot denoise, i.e., Iterative filling, to denoise a specific noisy image x. During zero-shot inference, network is initialized with pre-trained weights \u03b8, then the weights are further optimized on x for T steps, results from t-th (t=1, 2, ..., T-1) optimizing steps are gathered to obtain final denoised prediction y. Compared to current zero-shot methods, just adding one more step to load a pre-trained model enables faster and high-quality zero-shot denoising.", "description": "This figure illustrates the Masked Pre-train then Iterative fill (MPI) paradigm.  It shows the two main stages: 1) Masked Pre-training where a model learns to reconstruct masked natural images, extracting general knowledge about image distributions. 2) Iterative Filling, a zero-shot inference process where the pre-trained model is fine-tuned on a single noisy image to iteratively refine its denoising capabilities. The iterative process involves masked predictions, where only predictions for masked regions are retained to avoid overfitting and achieve efficient denoising in a limited number of iterations. The final denoised image is created by combining predictions across all the iterations.", "section": "2 Methods"}, {"figure_path": "oFgTScAsBr/figures/figures_4_1.jpg", "caption": "Figure 1: (a) Ours surpasses current zero-shot methods with reduced inference time (on CSet with Gaussian \u03c3=25, see Sec. 3.2). (b) It shows better generalization across different noise types than current zero-shot & supervised/unsupervised methods (Sec. 3.3). (c) And can remove spatial correlated real-world noise, results are from SIDD benchmark [1] and FMD [2] (Sec. 3.4, Sec. 3.5).", "description": "This figure demonstrates the superiority of the proposed method (Ours) over existing zero-shot and supervised/unsupervised image denoising methods.  Panel (a) shows a comparison of computational cost and performance, highlighting the faster inference time of the proposed method. Panel (b) showcases its better generalization across various noise types. Finally, panel (c) illustrates its ability to effectively denoise real-world and medical images.", "section": "Abstract"}, {"figure_path": "oFgTScAsBr/figures/figures_5_1.jpg", "caption": "Figure 6: Qualitative results on unseen noise types. Restormer is trained with Gaussian \u03c3=25. Noisy patches are from kodim07 and kodim12.", "description": "This figure shows qualitative comparisons of denoising results on unseen noise types (salt & pepper and speckle noise).  The results of the proposed method (MPI) are compared against several other methods including DIP, ZS-N2N, and Restormer. Restormer, a model trained on Gaussian noise, serves as a baseline for comparison. The figure highlights the superiority of the proposed MPI method in handling these different unseen noise types, producing images with noticeably improved visual quality and fewer artifacts.", "section": "3.3 Generalization on Unseen Noise"}, {"figure_path": "oFgTScAsBr/figures/figures_6_1.jpg", "caption": "Figure 7: Qualitative results on real noise removal from SIDD and PolyU. Noisy patches are from SIDDval31_1 and Canon80D_8_8_3200_ball_16.", "description": "This figure shows the qualitative results of the proposed method on real-world noisy images from two datasets: SIDD and PolyU.  The results are compared against several other state-of-the-art denoising methods (DIP, N2V*, N2S*, ZS-N2N, FasterDIP). The figure showcases the visual improvements achieved by the proposed method, particularly in terms of detail preservation and noise reduction.  The PSNR/SSIM values are provided below each image, which quantifies the performance gains.", "section": "3.4 Real Noisy Datasets"}, {"figure_path": "oFgTScAsBr/figures/figures_7_1.jpg", "caption": "Figure 8: Validation of pre-trained representations on image content differs from natural images. Comparing between \u201cBaseline", "description": "This figure shows that the pre-trained model generalizes better to unseen noise types compared to a model trained from scratch. The results show that the pre-trained model is able to denoise images with unseen noise better than a model trained from scratch, even when the content of the image is different from the images used in pre-training. This suggests that the pre-trained model has learned a more general representation of images that is able to handle unseen noise better than a model trained only on seen noise. The result indicates the model trained on ImageNet with 70% pixel-wise masking,  The denoised images are obtained by directly ensemble of predictions from fixed pre-trained weights. Its performance can be further improved with iterative filling. ", "section": "3 Experiments"}, {"figure_path": "oFgTScAsBr/figures/figures_7_2.jpg", "caption": "Figure 9: Effect of pre-trained model. Examples using Gauss \u03c3=25 removal on F_16 with \u03b2=0.99. Pre-trained results are labeled in orange, while default initialized results are labeled in blue.", "description": "This figure shows the effect of using a pre-trained model for denoising.  It presents a comparison of denoising results on an image with Gaussian noise (\u03c3=25) at different iterations (t=10, 100, 500, 1000, 1500) using both pre-trained weights (orange) and weights initialized from scratch (blue). The results visually demonstrate that the pre-trained model leads to better denoising performance, even at earlier iterations.", "section": "3.3 Generalization on Unseen Noise"}, {"figure_path": "oFgTScAsBr/figures/figures_8_1.jpg", "caption": "Figure 10: CKA (above) [47] and PCA (below) visualization of features extracted from the final timestep of model. Distribution of pre-trained model (\"Pretrained\") and from scratch (\"Baseline\") during inference is significantly different in last layers. Pre-trained model tends to restore the complete image, while the baseline model primarily focusing on restoring masked regions only.", "description": "This figure shows the visualization of features extracted from different layers of the model during inference. The top row shows the CKA and PCA analysis of the features, which reveals that the pre-trained model and the model trained from scratch have significantly different feature distributions in the last layers. The bottom row shows the feature maps from selected layers of the pre-trained model and the model trained from scratch. This comparison shows that the pre-trained model tends to restore the complete image, while the model trained from scratch focuses primarily on restoring the masked regions.", "section": "4 Ablation Study & Discussion"}, {"figure_path": "oFgTScAsBr/figures/figures_8_2.jpg", "caption": "Figure 11: Effect of masking ratios. 30% balances noise removal and prevents over-smoothing for synthetic noise.", "description": "This figure shows the impact of different masking ratios on the denoising performance using synthetic noise. The x-axis represents the masking ratio (percentage of pixels masked), and the y-axis shows the peak signal-to-noise ratio (PSNR) in dB.  The plot shows that a masking ratio of around 30% provides the best balance between noise removal and detail preservation.  Lower masking ratios result in insufficient noise reduction, while higher ratios lead to over-smoothing and loss of detail. The optimal ratio of 30% is specific to synthetic noise.", "section": "4 Ablation Study & Discussion"}, {"figure_path": "oFgTScAsBr/figures/figures_15_1.jpg", "caption": "Figure 12: Details of EMA process in Iterative filling. Masked regions of predictions from each optimization step t is assembled to a ensemble \u1ef9.", "description": "This figure illustrates the Exponential Moving Average (EMA) process used in the Iterative Filling step of the Masked Pre-train then Iterative fill (MPI) method.  In each iteration (t), the model generates predictions (yt). Only the predictions for the masked regions (Mt\u2299yt) are considered reliable and are used to update the ensemble (\u1ef9t). The contribution of each step's reliable predictions is weighted by \u03b2, an exponential weight. Unreliable pixels are kept unchanged. This process continues across multiple iterations (T) to refine the denoised output.", "section": "2.3 Iterative Filling"}, {"figure_path": "oFgTScAsBr/figures/figures_16_1.jpg", "caption": "Figure 13: An overview of the zero-shot denoising stage with adaptation to real-world noise. We adapt downsample \u201cDown(\u00b7)\u201d and upsample \u201cUp(\u00b7)\u201d to achieve noisy subsamples with less spatial correlation in noise, labeled in green arrows, and larger masking ratio is used to further deal with remaining spatial correlations. Actually, not all real noisy images needed to be sub-sampled, we only adapt \u201cDown(.)\u201d and \u201cUp(\u00b7)\u201d to SIDD dataset.", "description": "This figure illustrates the zero-shot denoising process with adaptations for real-world noise.  A downsampling step reduces spatial correlations in the noisy image before processing.  The model processes the downsampled image using masked pre-training and iterative filling, with the resulting prediction combined using EMA (Exponential Moving Average). Finally, an upsampling step restores the denoised image to its original resolution.  The green arrows highlight the downsampling and upsampling operations, which are only applied to the SIDD dataset.", "section": "2.4 Adaptation to Real-world Noise Removal"}, {"figure_path": "oFgTScAsBr/figures/figures_16_2.jpg", "caption": "Figure 11: Effect of masking ratios. 30% balances noise removal and prevents over-smoothing for synthetic noise.", "description": "This figure shows the impact of different masking ratios on the performance of the denoising model. The x-axis represents the masking ratio (percentage of pixels masked), while the y-axis represents the PSNR (Peak Signal-to-Noise Ratio), a metric that measures image quality.  The plot shows an optimal masking ratio of around 30% for synthetic noise. A lower ratio doesn't remove enough noise, while a higher ratio leads to over-smoothing, reducing detail. This finding is crucial for balancing noise reduction and detail preservation in the denoising process.", "section": "4 Ablation Study & Discussion"}, {"figure_path": "oFgTScAsBr/figures/figures_17_1.jpg", "caption": "Figure 4: An overview of the proposed MPI paradigm consisting Masked Pre-training and Iterative filling. During pre-training D\u03b8(\u00b7) learns to reconstruct masked natural images. And the pre-trained weights \u03b8 are saved for zero-shot denoise, i.e., Iterative filling, to denoise a specific noisy image x. During zero-shot inference, network is initialized with pre-trained weights \u03b8, then the weights are further optimized on x for T steps, results from t-th (t=1, 2, ..., T-1) optimizing steps are gathered to obtain final denoised prediction y. Compared to current zero-shot methods, just adding one more step to load a pre-trained model enables faster and high-quality zero-shot denoising.", "description": "This figure illustrates the two-stage process of the Masked Pre-train then Iterative fill (MPI) method.  The first stage, Masked Pre-training, involves training a model (D\u03b8) to reconstruct natural images from which random patches have been masked. The learned weights (\u03b8) from this stage are then used in the second stage, Iterative Filling.  In this stage, the model, initialized with the pre-trained weights, iteratively refines its prediction of a single noisy image (x) by focusing on reconstructing masked portions of the image. The process repeats for 'T' steps, ultimately producing a final denoised prediction (y). The inclusion of the pre-trained model improves both speed and quality compared to training a model from scratch for each image.", "section": "2 Methods"}, {"figure_path": "oFgTScAsBr/figures/figures_17_2.jpg", "caption": "Figure 16: Influence of different regularization strategies during iterations, including Total Variation (\"+TV\"), random image augmentation (\"+Aug\"), and early stopping (\"+ES\"). \"Ours\" and \"Faster\" are the methods evaluated in mainpaper. Example is tested on F16_512rgb with Gaussian \u03c3=25.", "description": "The figure shows the impact of different regularization techniques on the performance of the zero-shot denoising method. Total Variation (TV) regularization, data augmentation, and early stopping are compared to the original method. The results show that early stopping provides the best balance between performance and computational cost.", "section": "D.2 Over-fitting & Regularization"}, {"figure_path": "oFgTScAsBr/figures/figures_18_1.jpg", "caption": "Figure 13: An overview of the zero-shot denoising stage with adaptation to real-world noise. We adapt downsample \u201cDown(\u00b7)\u201d and upsample \u201cUp(\u00b7)\u201d to achieve noisy subsamples with less spatial correlation in noise, labeled in green arrows, and larger masking ratio is used to further deal with remaining spatial correlations. Actually, not all real noisy images needed to be sub-sampled, we only adapt \u201cDown(.)\u201d and \u201cUp(\u00b7)\u201d to SIDD dataset.", "description": "This figure illustrates the process of adapting the zero-shot denoising method to handle real-world noise.  Real-world noise often exhibits strong spatial correlations, which standard masking techniques struggle with. To address this, the model incorporates downsampling and upsampling steps.  The downsampling reduces spatial correlation before denoising, and the upsampling restores the image to its original resolution after processing. The figure also highlights the use of a larger masking ratio (80%-95%) to further mitigate the impact of remaining spatial correlations. Notably, this adaptation is specifically applied to the SIDD dataset; not all images undergo downsampling and upsampling.", "section": "2.4 Adaptation to Real-world Noise Removal"}, {"figure_path": "oFgTScAsBr/figures/figures_19_1.jpg", "caption": "Figure 18: Effect of pre-training on different noise levels from Gaussian (left) and Poisson (right) on CSet. Pre-training is beneficial for all 6 noise levels, especially in cases of intense noise.", "description": "This figure shows the impact of pre-training on the performance of a denoising model at various noise levels. The left panel shows results for Gaussian noise, while the right panel presents results for Poisson noise. Both panels display the PSNR (peak signal-to-noise ratio) against different noise levels (\u03c3 for Gaussian and \u03bb for Poisson).  Two lines are plotted in each panel, one for the baseline model (trained without pre-training), and one for the model trained using the paper's proposed masked pre-training approach. The plots illustrate that pre-training significantly improves denoising performance, particularly at higher noise levels, showcasing the effectiveness of the proposed method.", "section": "E.1 Noise Intensity"}, {"figure_path": "oFgTScAsBr/figures/figures_19_2.jpg", "caption": "Figure 18: Effect of pre-training on different noise levels from Gaussian (left) and Poisson (right) on CSet. Pre-training is beneficial for all 6 noise levels, especially in cases of intense noise.", "description": "This figure shows the results of an experiment comparing the performance of a denoising model with and without pre-training on different noise levels. The results show that pre-training significantly improves performance on all noise levels, particularly with stronger noise. This is because pre-training provides the model with a better foundation for understanding and removing noise patterns, which helps to reduce overfitting to specific noise characteristics and improve generalization across various noise levels. The left plot shows results for Gaussian noise, while the right plot shows results for Poisson noise.", "section": "E Additional Analysis on Pre-training"}, {"figure_path": "oFgTScAsBr/figures/figures_21_1.jpg", "caption": "Figure 20: Comparison of different methods under SIDD validation (SIDDval_34_22).", "description": "This figure shows a visual comparison of the denoising results from various methods on a specific noisy image patch (SIDDval_34_22) from the SIDD validation dataset. It allows for a qualitative assessment of the performance of each method in terms of noise reduction and detail preservation.  The methods compared include the proposed 'Ours' method, along with several baselines and state-of-the-art zero-shot and other denoising techniques, such as DIP-SURE, DDNM, DDPG, MM-BSN and PUCA.  The Ground Truth (GT) is also provided for reference.", "section": "G Additional Qualitative Results"}, {"figure_path": "oFgTScAsBr/figures/figures_23_1.jpg", "caption": "Figure 1: (a) Ours surpasses current zero-shot methods with reduced inference time (on CSet with Gaussian \u03c3=25, see Sec. 3.2). (b) It shows better generalization across different noise types than current zero-shot & supervised/unsupervised methods (Sec. 3.3). (c) And can remove spatial correlated real-world noise, results are from SIDD benchmark [1] and FMD [2] (Sec. 3.4, Sec. 3.5).", "description": "This figure demonstrates the effectiveness of the proposed MPI method for image denoising.  Subfigure (a) compares the computational cost and performance of MPI against other zero-shot denoising methods, highlighting its speed advantage. Subfigure (b) showcases MPI's superior generalization ability across various noise types compared to both zero-shot and supervised/unsupervised approaches.  Finally, subfigure (c) illustrates MPI's capability to effectively denoise real-world images with spatial noise correlation, using images from the SIDD and FMD benchmark datasets.", "section": "Abstract"}, {"figure_path": "oFgTScAsBr/figures/figures_23_2.jpg", "caption": "Figure 4: An overview of the proposed MPI paradigm consisting Masked Pre-training and Iterative filling. During pre-training D\u03b8(\u00b7) learns to reconstruct masked natural images. And the pre-trained weights \u03b8 are saved for zero-shot denoise, i.e., Iterative filling, to denoise a specific noisy image x. During zero-shot inference, network is initialized with pre-trained weights \u03b8, then the weights are further optimized on x for T steps, results from t-th (t=1,2,...,T-1) optimizing steps are gathered to obtain final denoised prediction y. Compared to current zero-shot methods, just adding one more step to load a pre-trained model enables faster and high-quality zero-shot denoising.", "description": "This figure provides a visual overview of the Masked Pre-train then Iterative fill (MPI) paradigm.  It shows the two main stages: 1) Masked Pre-training, where a model learns to reconstruct masked natural images, and 2) Iterative filling, which uses the pre-trained weights to iteratively refine a noisy image. The iterative process involves masking parts of the image, making predictions, and updating the model weights to better reconstruct the masked regions. This process is repeated multiple times, leading to improved denoising. The figure highlights how the pre-trained knowledge enables faster and better zero-shot denoising compared to traditional methods.", "section": "2 Methods"}, {"figure_path": "oFgTScAsBr/figures/figures_24_1.jpg", "caption": "Figure 23: Qualitative comparison of results on CBSD [34] with Gaussian \u03c3=10. Noisy patch is from CBSD-11.", "description": "This figure compares the denoising performance of various methods on a noisy patch from the CBSD dataset using Gaussian noise with a standard deviation of 10.  The methods compared include DIP, N2V*, N2S*, ZS-N2N, FasterDIP, and the proposed method (Ours). The reference image is provided for comparison.  The results are presented in terms of PSNR and SSIM values, which are quantitative metrics of image quality.", "section": "I Additional Qualitative Results"}, {"figure_path": "oFgTScAsBr/figures/figures_25_1.jpg", "caption": "Figure 1: (a) Ours surpasses current zero-shot methods with reduced inference time (on CSet with Gaussian \u03c3=25, see Sec. 3.2). (b) It shows better generalization across different noise types than current zero-shot & supervised/unsupervised methods (Sec. 3.3). (c) And can remove spatial correlated real-world noise, results are from SIDD benchmark [1] and FMD [2] (Sec. 3.4, Sec. 3.5).", "description": "This figure demonstrates the superiority of the proposed method (Ours) compared to existing zero-shot and supervised/unsupervised image denoising methods across three key aspects: computational cost, generalization ability, and real-world noise removal.  (a) shows the reduced inference time of the proposed method. (b) highlights the improved generalization across different noise types. (c) showcases the effectiveness on real-world noisy images from SIDD and FMD benchmark datasets.", "section": "Abstract"}, {"figure_path": "oFgTScAsBr/figures/figures_26_1.jpg", "caption": "Figure 5: Qualitative denoising results on Gaussian and Poisson noise. The quantitative PSNR/SSIM results are provided underneath. Noisy patches are from CBSD-44 and McMaster-14, respectively. Best viewed in color (zoom-in for better comparison).", "description": "This figure shows the qualitative and quantitative results of the proposed MPI method on Gaussian and Poisson noise. The results are compared against several state-of-the-art denoising methods.  The qualitative comparison shows the visual results of denoising on noisy patches from the CBSD-44 and McMaster-14 datasets. The quantitative comparison shows the PSNR and SSIM values for each method.", "section": "3 Experiments"}, {"figure_path": "oFgTScAsBr/figures/figures_27_1.jpg", "caption": "Figure 26: Qualitative comparison of results on CBSD [34] with Poisson \u03bb=10. Noisy patch is from CBSD-33.", "description": "This figure shows a qualitative comparison of different image denoising methods on a noisy patch from the CBSD dataset with Poisson noise (\u03bb=10).  The comparison includes the original noisy image, the ground truth (reference) image, and results from DIP, N2V*, N2S*, ZS-N2N, FasterDIP, the faster version of the proposed MPI method, and the proposed MPI method.  The visual results demonstrate the relative performance of each method in terms of noise reduction and detail preservation.", "section": "Additional Qualitative Results"}, {"figure_path": "oFgTScAsBr/figures/figures_28_1.jpg", "caption": "Figure 27: Qualitative comparison of results on CBSD [34] with Poisson \u03bb=25. Noisy patch is from CBSD-56.", "description": "This figure compares the denoising results of different methods on a CBSD dataset patch with Poisson noise (\u03bb=25).  The methods compared include DIP, N2V*, N2S*, ZS-N2N, FasterDIP, the proposed \"Ours (faster)\" method, and the full \"Ours\" method. The figure visually demonstrates the performance differences of each method in terms of noise reduction and detail preservation.", "section": "Additional Qualitative Results"}, {"figure_path": "oFgTScAsBr/figures/figures_29_1.jpg", "caption": "Figure 28: Qualitative comparison of results on CBSD [34] with Poisson \u03bb=50. Noisy patch is from CBSD-05.", "description": "The figure shows a qualitative comparison of denoising results on a noisy patch from the CBSD dataset with Poisson noise (\u03bb=50). It compares the performance of different methods including DIP, N2V*, N2S*, ZS-N2N, FasterDIP, and the proposed method (MPI).  The results demonstrate the superior performance of the MPI method in terms of noise removal and detail preservation compared to the other methods.", "section": "Additional Qualitative Results"}, {"figure_path": "oFgTScAsBr/figures/figures_29_2.jpg", "caption": "Figure 29: Qualitative comparison of generalization on Kodak [46] with S&P d=0.045. Noisy patch is from kodim11.", "description": "This figure compares the results of different denoising methods on a noisy patch from the Kodak dataset, where the noise is Salt and Pepper noise with density d=0.045.  The methods compared include SwinIR, Restormer, Neighbor2Neighbor, Blind2Unblind, DIP, ZS-N2N, and the proposed MPI method (both faster and full versions). The figure shows the visual quality of the denoised images produced by each method, highlighting the performance differences.", "section": "3 Experiments"}, {"figure_path": "oFgTScAsBr/figures/figures_30_1.jpg", "caption": "Figure 10: CKA (above) [47] and PCA (below) visualization of features extracted from the final timestep of model. Distribution of pre-trained model (\"Pretrained\") and from scratch (\"Baseline\") during inference is significantly different in last layers. Pre-trained model tends to restore the complete image, while the baseline model primarily focusing on restoring masked regions only.", "description": "This figure compares the feature distributions obtained from a model with and without pre-training using Kernel Canonical Correlation Analysis (CKA) and Principal Component Analysis (PCA). The results show that pre-trained weights significantly impact the feature distributions and improve the performance in image restoration. The pre-trained model focuses on restoring the complete image, while the untrained model focuses only on the masked areas.", "section": "4 Ablation Study & Discussion"}, {"figure_path": "oFgTScAsBr/figures/figures_31_1.jpg", "caption": "Figure 31: Qualitative comparison of generalization on Kodak [46] with Poisson \u03bb=40. Noisy patch is from kodim04.", "description": "This figure compares the denoising performance of different methods on a noisy patch from the Kodak dataset with Poisson noise (\u03bb=40). The comparison includes several supervised and unsupervised methods, along with the proposed MPI method.  The results show that MPI achieves superior denoising quality and better detail preservation compared to the other methods. This demonstrates the generalization capability of the proposed method to various unseen noise types.", "section": "3.3 Generalization on Unseen Noise"}, {"figure_path": "oFgTScAsBr/figures/figures_32_1.jpg", "caption": "Figure 32: Qualitative comparison of realnoise on PolyU [45]. Noisy patch is from Sony_3-5_200_1600_classroom_14.", "description": "This figure shows a qualitative comparison of denoising results on a real-world noisy image patch from the PolyU dataset.  The comparison includes the noisy image, the ground truth, and denoising results from several methods (DIP, N2V*, N2S*, ZS-N2N, FasterDIP, MPI (faster version), and MPI). The goal is to visually demonstrate the performance of MPI in removing real-world noise while preserving image details. Each method's PSNR and SSIM scores are also displayed.", "section": "3.4 Real Noisy Datasets"}, {"figure_path": "oFgTScAsBr/figures/figures_33_1.jpg", "caption": "Figure 7: Qualitative results on real noise removal from SIDD and PolyU. Noisy patches are from SIDDval31_1 and Canon80D_8_8_3200_ball_16.", "description": "This figure shows the qualitative comparison of denoising results on real noisy images from SIDD and PolyU datasets.  The results demonstrate the effectiveness of the proposed method (Ours) in removing real-world noise compared to other existing methods (DIP, N2V*, N2S*, ZS-N2N, FasterDIP).  It highlights the method's ability to preserve image details while effectively removing noise.", "section": "3.4 Real Noisy Datasets"}, {"figure_path": "oFgTScAsBr/figures/figures_33_2.jpg", "caption": "Figure 34: Qualitative comparison of realnoise on SIDD [1]. Noisy patch is from SIDDval_20_8.", "description": "This figure shows a qualitative comparison of denoising results on a real noisy image patch from the SIDD dataset. The comparison includes the noisy image, the ground truth (reference), and the denoised images generated by various methods including DIP, N2V*, N2S*, ZS-N2N, FasterDIP, and the proposed method (MPI).  The results illustrate the effectiveness of the authors' proposed method in achieving high quality results with preserved details compared to the other methods.", "section": "3 Experiments"}, {"figure_path": "oFgTScAsBr/figures/figures_34_1.jpg", "caption": "Figure 20: Comparison of different methods under SIDD validation (SIDDval_34_22).", "description": "This figure shows a qualitative comparison of different denoising methods on a specific noisy patch from the SIDD validation dataset (SIDDval_34_22).  It visually compares the results of DIP, N2V*, N2S*, ZS-N2N, FasterDIP, and the proposed \"Ours (faster)\" and \"Ours\" methods against the ground truth image. The comparison allows a visual assessment of the relative performance of each method in terms of noise reduction and detail preservation.", "section": "G.3 Details of Unseen Noise"}]