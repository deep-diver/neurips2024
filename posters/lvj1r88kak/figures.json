[{"figure_path": "LvJ1R88KAk/figures/figures_1_1.jpg", "caption": "Figure 1: Illustration of selective SSM in Mamba (eq. (11)) and single head linear attention (eq. (12)). It can be seen that selective SSM resembles single-head linear attention with additional input gate Ai, forget gate A\u2081 and shortcut Dx, while omitting normalization QiZi.", "description": "This figure illustrates the core similarities and differences between the selective state space model (SSM) in Mamba and the single-head linear attention mechanism.  Panel (a) shows the SSM equations and architecture, highlighting the input gate (Ai), forget gate (A\u2081), and shortcut (Dx).  Panel (b) shows the corresponding linear attention equations and architecture. The caption points out that the SSM closely resembles the linear attention but with the added gates and shortcut. The key difference is the absence of normalization (QiZi) in the SSM.", "section": "4 Connecting Mamba and Linear Attention Transformer"}, {"figure_path": "LvJ1R88KAk/figures/figures_3_1.jpg", "caption": "Figure 2: Illustration of selective state space model (eq. (8)) and its equivalent form (eq. (9)).", "description": "This figure illustrates the selective state space model used in Mamba and its equivalent reformulation.  The left side shows the selective SSM model with input-dependent parameters Ai, Bi, and Ci. The right side shows an equivalent form, making the formulas easier to analyze and compare with the linear attention formulation.  It highlights the key components of how the hidden state (hi) is updated based on the previous hidden state (hi-1) and current input (xi). The output (yi) is then calculated from the updated hidden state and input. The figure's purpose is to simplify the understanding of the Mamba model's core operations before connecting them to linear attention.", "section": "3.2 Selective State Space Model"}, {"figure_path": "LvJ1R88KAk/figures/figures_5_1.jpg", "caption": "Figure 3: Illustration of the macro designs of linear attention Transformer, Mamba and our MILA.", "description": "This figure compares the macro architecture designs of three different model types: Linear Attention Transformer, Mamba, and MILA (the proposed model). It visually represents the arrangement of blocks and layers within each architecture, highlighting their similarities and differences.  Each model's architecture is displayed as a sequence of blocks, including linear attention, multi-layer perceptrons (MLPs), normalization layers, and convolutional layers. The figure effectively illustrates the modifications and additions introduced in MILA to improve upon both the Linear Attention Transformer and Mamba architectures.", "section": "4.3 Analysis of Macro Architecture Design"}, {"figure_path": "LvJ1R88KAk/figures/figures_6_1.jpg", "caption": "Figure 4: (a) Visualizations of the distributions of input gate values. (b) The average of forget gate values in different layers. (c) The attenuation effect of different forget gate values.", "description": "This figure shows visualizations and analyses of the input and forget gate values in the Mamba model.  (a) shows examples of input gate value distributions across different image regions. (b) illustrates how the average forget gate value changes across different model layers. (c) demonstrates the effect of different forget gate values on the model's output, showing how higher values lead to more attenuation of previous hidden states.", "section": "5 Empirical Study"}, {"figure_path": "LvJ1R88KAk/figures/figures_7_1.jpg", "caption": "Figure 5: The standard deviation of token lengths.", "description": "This figure shows the standard deviation of token lengths in different layers of a model with and without attention normalization. The standard deviation of token lengths in the model without normalization is significantly larger, especially in the last two layers, indicating that longer tokens tend to dominate the whole feature map, while shorter tokens may fail to represent their corresponding semantics. The normalization helps to alleviate this issue.", "section": "5.2 Empirical Analysis of the Differences"}, {"figure_path": "LvJ1R88KAk/figures/figures_8_1.jpg", "caption": "Figure 6: Speed tests on a RTX3090 GPU.", "description": "This figure shows the trade-off between accuracy and inference speed for different vision Mamba models and the proposed MILA model on a RTX3090 GPU.  The x-axis represents inference time in milliseconds, and the y-axis represents the top-1 accuracy on ImageNet. MILA significantly outperforms other models in terms of both accuracy and speed, demonstrating the effectiveness of the proposed improvements.", "section": "5.3 Comparison with Mamba in Vision"}, {"figure_path": "LvJ1R88KAk/figures/figures_15_1.jpg", "caption": "Figure 3: Illustration of the macro designs of linear attention Transformer, Mamba and our MILA.", "description": "This figure compares the macro architecture designs of three different models: Linear Attention Transformer, Mamba, and MILA (the authors' proposed model).  Each model is represented visually with blocks that indicate different operations (linear layers, MLPs, normalization, etc.).  The figure illustrates how MILA incorporates design elements from both linear attention Transformers and Mamba to create its architecture, highlighting the differences in the overall design and the ways in which the blocks are arranged and connected.  The goal of the figure is to visually demonstrate the relationships and differences between the models at a high level.", "section": "4.3 Analysis of Macro Architecture Design"}]