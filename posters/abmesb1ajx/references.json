{"references": [{"fullname_first_author": "Jonathan Frankle", "paper_title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks", "publication_date": "2018-09-01", "reason": "This paper introduced the Lottery Ticket Hypothesis (LTH), the foundational concept upon which the Strong Lottery Ticket Hypothesis (SLTH), the focus of the current paper, is built."}, {"fullname_first_author": "Eran Malach", "paper_title": "Proving the Lottery Ticket Hypothesis: Pruning Is All You Need", "publication_date": "2020-07-01", "reason": "This paper provided the first rigorous proof of the SLTH for dense neural networks, establishing a framework and technical tools that have influenced much of the subsequent work in this area."}, {"fullname_first_author": "Ankit Pensia", "paper_title": "Optimal lottery tickets via SUBSETSUM: logarithmic over-parameterization is sufficient", "publication_date": "2020-12-01", "reason": "This paper improved upon previous SLTH results by showing that logarithmic overparameterization is sufficient, reducing the size of the random network needed compared to earlier work."}, {"fullname_first_author": "Arthur da Cunha", "paper_title": "Proving the Strong Lottery Ticket Hypothesis for Convolutional Neural Networks", "publication_date": "2022-04-01", "reason": "This paper extended the SLTH to convolutional neural networks (CNNs), a significant architecture in deep learning, demonstrating the broader applicability of the hypothesis."}, {"fullname_first_author": "Damien Ferbach", "paper_title": "A General Framework For Proving The Equivariant Strong Lottery Ticket Hypothesis", "publication_date": "2022-09-01", "reason": "This paper generalized the SLTH to equivariant networks, a class of networks that includes CNNs as a special case, providing a more abstract and general framework for understanding the SLTH."}]}