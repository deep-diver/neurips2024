[{"figure_path": "H6C4p8Dir7/tables/tables_4_1.jpg", "caption": "Table 1: Reconstruction FID on ImageNet validation split, CelebA-HQ, and FFHQ. * denotes models trained with Gumbel-Softmax reparameterization [39]. For our method, the results that are jointly trained with UCF-101 are reported.", "description": "This table presents the reconstruction FID (Fr\u00e9chet Inception Distance) scores for different models on three image datasets: ImageNet, CelebA-HQ, and FFHQ.  The FID score measures the similarity between the generated images and real images; lower scores indicate better reconstruction quality. The table compares the performance of the proposed OmniTokenizer-VQVAE and OmniTokenizer-VAE models against several state-of-the-art methods.  The results show that OmniTokenizer achieves significantly lower FID scores, demonstrating superior reconstruction performance.", "section": "4 Experiments"}, {"figure_path": "H6C4p8Dir7/tables/tables_5_1.jpg", "caption": "Table 3: Comparions of class-conditional results on ImageNet 256\u00d7256 using language models. \u201c\u2193\u201d (\u201c\u2191\u201d) indicates lower (higher) is better. Metrics include Fr\u00e9chet inception distance (FID) and inception score (IS). NAR and AR: non-autoregressive and autoregressive. *: taken from MaskGIT [7].", "description": "This table compares different autoregressive (AR) and non-autoregressive (NAR) language models for class-conditional image generation on the ImageNet dataset (256x256 resolution).  The metrics used are Fr\u00e9chet Inception Distance (FID) and Inception Score (IS), lower FID and higher IS indicating better performance. The table shows the number of parameters for each model.", "section": "4 Experiments"}, {"figure_path": "H6C4p8Dir7/tables/tables_6_1.jpg", "caption": "Table 5: Class-conditional results on ImageNet 256x256 using GAN and diffusion models.", "description": "This table compares the performance of various GAN and diffusion models on the ImageNet dataset for class-conditional image generation.  The metrics used are FID (Fr\u00e9chet Inception Distance), IS (Inception Score), Precision, and Recall. Lower FID indicates better image quality.  Higher IS, Precision, and Recall are desirable.", "section": "4.3 Visual Generation with Diffusion Models"}, {"figure_path": "H6C4p8Dir7/tables/tables_6_2.jpg", "caption": "Table 6: Comparisons of unconditional results on UCF-101 256x256 using GAN and diffusion models.", "description": "This table compares the unconditional video generation results on the UCF-101 dataset using various GAN and diffusion models.  The metrics used for comparison are Fr\u00e9chet Video Distance (FVD), a lower score indicating better performance. The table also shows the latent compression of each method.  The \"Ours-Latte\" row presents the results obtained when using the OmniTokenizer with the Latte model. ", "section": "4.3 Visual Generation with Diffusion Models"}, {"figure_path": "H6C4p8Dir7/tables/tables_7_1.jpg", "caption": "Table 7: Comparison of rFID on ImageNet and rFVD on various video datasets.", "description": "This table presents a comparison of reconstruction FID (Fr\u00e9chet Inception Distance) scores on the ImageNet dataset and reconstruction FVD (Fr\u00e9chet Video Distance) scores on various video datasets.  The table compares different training strategies for the OmniTokenizer model: training only on images with fixed or multiple resolutions, training only on videos with fixed or multiple resolutions, and joint training on images and videos with multiple resolutions. The results show the impact of different training strategies on the model's performance for both image and video reconstruction tasks.", "section": "4.4 Ablation Study"}]