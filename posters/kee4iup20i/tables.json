[{"figure_path": "KEe4IUp20I/tables/tables_5_1.jpg", "caption": "Table 1: Best bits-per-byte. Lowest bits-per-byte\u00b3 for each model architecture when trained using 10<sup>19</sup> FLOPs on different text modalities. The lowest bits-per-byte for each dataset are underlined; and the lowest within 2.5% are bolded. The largest statistical error (due to a finite number of evaluation samples) is 0.4%. SpaceByte significantly outperforms other byte-level architectures and performs on par with the SentencePiece subword Transformer.", "description": "This table presents the best bits-per-byte achieved by different language models across three datasets (PG-19, arXiv, and Github) when trained using a compute budget of 10<sup>19</sup> FLOPs. The models include both subword and byte-level transformer architectures, with various modifications (Window Attention, MegaByte, SpaceByte with fixed patch size, and SpaceByte). The lowest bits-per-byte for each dataset is underlined, and values within 2.5% of the lowest are bolded. The table highlights SpaceByte's superior performance compared to other byte-level models and its comparable performance to the SentencePiece subword transformer, indicating its effectiveness in closing the performance gap between byte-level and tokenized models.", "section": "4.1 Models"}, {"figure_path": "KEe4IUp20I/tables/tables_7_1.jpg", "caption": "Table 2: Comparison with other works. We compare SpaceByte to byte-level models trained in other works, along with a subword transformer that we train. All models are trained using roughly the same inference FLOPs-per-byte (\u2248 728M). The bits-per-byte for the Transformer, PerceiverAR, and MegaByte models are taken from Yu et al. [7], while MambaByte results are taken from Wang et al. [6]. The best bits-per-byte for each dataset are underlined; and the lowest within 3% are bolded. The largest 1-sigma statistical error (due to a finite number of evaluation samples) for the models we train is less than 0.001. SpaceByte is the overall best performing byte-level model and consistently performs within a few percent of the subword Transformer. \n+ These models used slightly different datasets for training and/or testing. For MambaByte-353M, we estimate that this difference very roughly amounts to an extra 3% statistical error.", "description": "This table compares the performance of SpaceByte against other byte-level models from related works and a subword transformer.  The comparison is made using a similar inference compute cost (FLOPs-per-byte), and the best performance (lowest bits-per-byte) is highlighted.  It shows that SpaceByte outperforms other byte-level models and achieves performance comparable to the subword transformer.", "section": "Comparison with Other Works"}, {"figure_path": "KEe4IUp20I/tables/tables_13_1.jpg", "caption": "Table 1: Best bits-per-byte. Lowest bits-per-byte for each model architecture when trained using 10<sup>19</sup> FLOPs on different text modalities. The lowest bits-per-byte for each dataset are underlined; and the lowest within 2.5% are bolded. The largest statistical error (due to a finite number of evaluation samples) is 0.4%. SpaceByte significantly outperforms other byte-level architectures and performs on par with the SentencePiece subword Transformer.", "description": "This table presents the best bits-per-byte achieved by different language models on three different datasets (PG-19, arXiv, and Github) when trained with a compute budget of 10<sup>19</sup> FLOPs.  It compares the performance of SpaceByte against several baselines, including byte-level and subword-level Transformer models, MegaByte, and variations of SpaceByte. The lowest bits-per-byte for each dataset is highlighted, along with those within 2.5% of the lowest.  The table demonstrates SpaceByte's superior performance compared to other byte-level models and its competitive performance with the SentencePiece subword Transformer.", "section": "4.1 Models"}, {"figure_path": "KEe4IUp20I/tables/tables_13_2.jpg", "caption": "Table 2: Comparison with other works. We compare SpaceByte to byte-level models trained in other works, along with a subword transformer that we train. All models are trained using roughly the same inference FLOPs-per-byte (\u2248 728M). The bits-per-byte for the Transformer, PerceiverAR, and MegaByte models are taken from Yu et al. [7], while MambaByte results are taken from Wang et al. [6]. The best bits-per-byte for each dataset are underlined; and the lowest within 3% are bolded. The largest 1-sigma statistical error (due to a finite number of evaluation samples) for the models we train is less than 0.001. SpaceByte is the overall best performing byte-level model and consistently performs within a few percent of the subword Transformer. + These models used slightly different datasets for training and/or testing. For MambaByte-353M, we estimate that this difference very roughly amounts to an extra 3% statistical error.", "description": "This table compares SpaceByte's performance with other byte-level models from existing works and a subword transformer. All models are trained with approximately the same inference FLOPs-per-byte, allowing for a fair comparison of their bits-per-byte performance across different datasets. The table highlights SpaceByte's superior performance compared to other byte-level models and its competitive performance against the subword transformer.", "section": "Comparison with Other Works"}, {"figure_path": "KEe4IUp20I/tables/tables_14_1.jpg", "caption": "Table 1: Best bits-per-byte. Lowest bits-per-byte for each model architecture when trained using 10<sup>19</sup> FLOPs on different text modalities. The lowest bits-per-byte for each dataset are underlined; and the lowest within 2.5% are bolded. The largest statistical error (due to a finite number of evaluation samples) is 0.4%. SpaceByte significantly outperforms other byte-level architectures and performs on par with the SentencePiece subword Transformer.", "description": "This table shows the best bits-per-byte achieved by different language models on three different datasets (PG-19, arXiv, and Github).  The models are categorized into byte-level and subword-level architectures.  The lowest bits-per-byte for each dataset is highlighted, along with those within 2.5% of the lowest.  SpaceByte demonstrates superior performance compared to other byte-level models and comparable performance to the top-performing subword model.", "section": "4.1 Models"}, {"figure_path": "KEe4IUp20I/tables/tables_14_2.jpg", "caption": "Table 1: Best bits-per-byte. Lowest bits-per-byte for each model architecture when trained using 10<sup>19</sup> FLOPs on different text modalities. The lowest bits-per-byte for each dataset are underlined; and the lowest within 2.5% are bolded. The largest statistical error (due to a finite number of evaluation samples) is 0.4%. SpaceByte significantly outperforms other byte-level architectures and performs on par with the SentencePiece subword Transformer.", "description": "This table presents the best bits-per-byte achieved by different language models on three datasets (PG-19, arXiv, and Github) when trained with a compute budget of 10<sup>19</sup> FLOPs.  The models compared include various byte-level and subword-level Transformer architectures.  The lowest bits-per-byte for each dataset is highlighted, and those within 2.5% of the lowest are bolded. The table demonstrates SpaceByte's superior performance compared to other byte-level models and its comparable performance to the SentencePiece subword Transformer.", "section": "4.1 Models"}]