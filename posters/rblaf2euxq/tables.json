[{"figure_path": "rblaF2euXQ/tables/tables_2_1.jpg", "caption": "Table 1: Comparisons of Greedy Linear Contextual Bandit Studies", "description": "This table compares several studies on greedy linear contextual bandit algorithms.  It lists the context distribution used in each study (mostly Gaussian), the achieved regret bound (ranging from O(\u221aT) to O(poly log T)), and the problem setting (single parameter or multiple parameters). The table highlights the expansion of applicable distributions from mostly Gaussian and uniform in previous works to a significantly wider class including Gaussian, exponential, uniform, Cauchy, Student's t, and their truncated variants in the current work.  The poly-logarithmic regret bound represents a significant improvement in efficiency.", "section": "1 Introduction"}, {"figure_path": "rblaF2euXQ/tables/tables_4_1.jpg", "caption": "Table 1: Comparisons of Greedy Linear Contextual Bandit Studies", "description": "This table compares several existing studies on greedy linear contextual bandit algorithms.  It contrasts the different context distributions assumed (mostly Gaussian), the resulting regret bounds achieved (ranging from O(\u221aT) to O(poly log T)), and the problem setting (single or multiple parameters). The table highlights the novelty of the current work by showing that it significantly expands the class of distributions for which a greedy algorithm can achieve a polylogarithmic regret bound.", "section": "1.2 Related Work"}]