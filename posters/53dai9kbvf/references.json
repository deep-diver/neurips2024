{"references": [{"fullname_first_author": "Haoxin Chen", "paper_title": "VideoCrafter2: Overcoming data limitations for high-quality video diffusion models", "publication_date": "2024-01-09", "reason": "This paper introduces VideoCrafter2, a crucial model for high-quality video generation that serves as a teacher model for T2V-Turbo in the experiments."}, {"fullname_first_author": "Xiang Wang", "paper_title": "VideoLCM: Video Latent Consistency Model", "publication_date": "2023-12-09", "reason": "This paper proposes VideoLCM, a foundational consistency model for fast video generation, whose quality bottleneck T2V-Turbo aims to overcome."}, {"fullname_first_author": "Ziqi Huang", "paper_title": "VBench: Comprehensive benchmark suite for video generative models", "publication_date": "2024-00-00", "reason": "This paper introduces VBench, the benchmark used for the quantitative evaluation of T2V-Turbo, providing crucial metrics for comparison with existing models."}, {"fullname_first_author": "Yang Song", "paper_title": "Consistency models", "publication_date": "2023-00-00", "reason": "This paper introduces consistency distillation, a core technique used by T2V-Turbo to improve efficiency while maintaining quality in video generation."}, {"fullname_first_author": "Hangjie Yuan", "paper_title": "InstructVideo: Instructing video diffusion models with human feedback", "publication_date": "2023-12-12", "reason": "This paper explores using reward feedback in video generation, a concept that T2V-Turbo builds upon by incorporating mixed reward feedback to achieve better results."}]}