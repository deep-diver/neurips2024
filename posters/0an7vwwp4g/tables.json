[{"figure_path": "0aN7VWwp4g/tables/tables_7_1.jpg", "caption": "Table 1: Comparison of the quantitative performance of different losses for models trained on the Stochastic Moving-MNIST. The better score between MSE and FACL is highlighted in bold.", "description": "This table compares the performance of different loss functions (MSE and FACL) on various models (ConvLSTM, PredRNN, SimVP, Earthformer) trained using the Stochastic Moving-MNIST dataset.  It shows quantitative results across different metrics categorized into pixel-wise/structural (MAE, SSIM), perceptual (LPIPS, FVD), skill (FSS, RHD), and a proposed metric (RHD).  The best performing loss function for each model and metric is bolded, allowing for easy comparison of the effectiveness of FACL against the traditional MSE loss.", "section": "4.2 A Stochastic Modification of Moving-MNIST"}, {"figure_path": "0aN7VWwp4g/tables/tables_8_1.jpg", "caption": "Table 2: Comparison of the quantitative performance of different losses for models trained on SEVIR, MeteoNet and HKO-7. MAE metrics is in the scale of 10<sup>-3</sup>. The better score between MSE and FACL is highlighted in bold.", "description": "This table presents a comparison of different loss functions (MSE and FACL) on three different radar-based datasets (SEVIR, MeteoNet, and HKO-7) using various models.  The metrics used to evaluate performance include pixel-wise metrics (MAE, SSIM), perceptual metrics (LPIPS, FVD), and meteorological skill scores (CSI, FSS, RHD). The table helps in understanding the impact of FACL on improving the quality and skillfulness of precipitation nowcasting.", "section": "4.3 Performance on Radar-based Datasets"}, {"figure_path": "0aN7VWwp4g/tables/tables_16_1.jpg", "caption": "Table 3: Quantitative performance of different losses for ConvLSTM on Stochastic Moving-MNIST.", "description": "This table presents the quantitative results of the ablation study performed on the ConvLSTM model trained on the Stochastic Moving-MNIST dataset.  It compares the performance of three different loss functions: using only the Fourier Amplitude Loss (FAL), using only the Fourier Correlation Loss (FCL), and using the combined Fourier Amplitude and Correlation Loss (FACL). The metrics used to evaluate the performance include MAE, MSE, SSIM, LPIPS, FVD, FSS, and RHD.  Lower values for MAE, MSE, LPIPS, FVD, and RHD indicate better performance, while higher values for SSIM and FSS indicate better performance.", "section": "F Ablation Study on FAL and FCL"}, {"figure_path": "0aN7VWwp4g/tables/tables_17_1.jpg", "caption": "Table 4: Effect of different \u03b1 on the performance of PredRNN trained with FACL on Stochastic Moving-MNIST.", "description": "This table presents the ablation study of the hyperparameter \u03b1 in the proposed FACL loss function.  It shows the impact of varying \u03b1 on multiple evaluation metrics (MAE, MSE, SSIM, LPIPS, FVD, FSS, RHD) for the PredRNN model trained on the Stochastic Moving-MNIST dataset.  The results demonstrate how the random selection between FAL and FCL, controlled by \u03b1, affects the model's performance in terms of pixel-wise accuracy, perceptual similarity, and meteorological skill scores. The optimal value of \u03b1 balances sharpness and accuracy.", "section": "F Ablation Study on FAL and FCL"}, {"figure_path": "0aN7VWwp4g/tables/tables_17_2.jpg", "caption": "Table 5: Effect of different \u03b1 on the performance of ConvLSTM trained with FACL on SEVIR, where MAE is in the scale of 10\u207b\u00b3.", "description": "This table presents the quantitative performance results of the ConvLSTM model trained with the Fourier Amplitude and Correlation Loss (FACL) on the SEVIR dataset.  It shows how different values of the hyperparameter \u03b1 affect various metrics, including Mean Absolute Error (MAE), Structural Similarity Index (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), Fr\u00e9chet Video Distance (FVD), Critical Success Index (CSI) with different pooling sizes (CSI-m, CSI4-m, CSI16-m), Fractional Skill Score (FSS), and Regional Histogram Divergence (RHD).  The results illustrate the trade-off between sharpness and other aspects of prediction quality as \u03b1 is varied.", "section": "4.3 Performance on Radar-based Datasets"}, {"figure_path": "0aN7VWwp4g/tables/tables_18_1.jpg", "caption": "Table 6: Comparison of the quantitative performance of different losses for models trained on Stochastic Moving-MNIST datasets. We report the average time (in seconds) of 5 training epochs and 100 inference steps on a single Nvidia GeForce RTX3090.", "description": "This table compares the training and inference time of different models (ConvLSTM, PredRNN, SimVP, Earthformer, LDCast, and MCVD) trained with either MSE or FACL loss. The experiments were conducted on a single Nvidia GeForce RTX 3090 GPU, and the results represent the average time taken for 5 training epochs and 100 inference steps.", "section": "G Running Time of FACL"}, {"figure_path": "0aN7VWwp4g/tables/tables_18_2.jpg", "caption": "Table 7: Comparison of the quantitative performance of different losses for models trained on the Stochastic Moving-MNIST. The better score between MSE and FACL is highlighted in bold.", "description": "This table compares the performance of different loss functions (MSE and FACL) on various models (ConvLSTM, SimVP, Earthformer) trained on the Stochastic Moving-MNIST dataset.  It evaluates pixel-wise metrics (MAE, SSIM), perceptual metrics (LPIPS, FVD), meteorological skill scores (FSS), and the proposed RHD metric. The bold values indicate the better performance between MSE and FACL for each model and metric.", "section": "I Evaluation on N-Body-MNIST"}, {"figure_path": "0aN7VWwp4g/tables/tables_19_1.jpg", "caption": "Table 2: Comparison of the quantitative performance of different losses for models trained on SEVIR, MeteoNet and HKO-7. MAE metrics is in the scale of 10-3. The better score between MSE and FACL is highlighted in bold.", "description": "This table compares the performance of models trained with Mean Squared Error (MSE) loss and Fourier Amplitude and Correlation Loss (FACL) across three different radar-based datasets: SEVIR, MeteoNet, and HKO-7.  It evaluates pixel-wise metrics (MAE, SSIM), perceptual metrics (LPIPS, FVD), meteorological skill scores (CSI with varying pooling sizes, FSS), and the proposed Regional Histogram Divergence (RHD).  The best-performing loss (MSE or FACL) for each metric is indicated in bold.  This allows for a comparison of the effectiveness of the proposed FACL loss against the standard MSE loss in various contexts.", "section": "4.3 Performance on Radar-based Datasets"}, {"figure_path": "0aN7VWwp4g/tables/tables_20_1.jpg", "caption": "Table 9: Comparison of the quantitative performance of different losses for ConvLSTM trained on Stochastic Moving-MNIST.", "description": "This table compares the performance of different loss functions (MSE, SSL, MSE+SSIM, and FACL) when training a ConvLSTM model on the Stochastic Moving-MNIST dataset.  The metrics evaluated include MAE, SSIM, LPIPS, FVD, FSS, and RHD, providing a comprehensive assessment of the model's performance in terms of pixel-wise accuracy, structural similarity, perceptual quality, and skillfulness.  The results help determine which loss function best balances various aspects of performance for this specific model and dataset.", "section": "J Comparison with Other Loss Alternatives"}, {"figure_path": "0aN7VWwp4g/tables/tables_20_2.jpg", "caption": "Table 2: Comparison of the quantitative performance of different losses for models trained on SEVIR, MeteoNet and HKO-7. MAE metrics is in the scale of 10<sup>-3</sup>. The better score between MSE and FACL is highlighted in bold.", "description": "This table compares the performance of different loss functions (MSE and FACL) on three different radar-based datasets (SEVIR, MeteoNet, and HKO-7) across multiple models.  The metrics used to evaluate performance include pixel-wise metrics (MAE, SSIM), perceptual metrics (LPIPS, FVD), and meteorological skill scores (CSI with different pooling sizes, FSS, RHD).  The table highlights the better-performing loss function (MSE or FACL) for each metric and dataset combination.", "section": "4.3 Performance on Radar-based Datasets"}, {"figure_path": "0aN7VWwp4g/tables/tables_21_1.jpg", "caption": "Table 11: Quantitative performance of SVGLP, STRPM and MCVD with different loss, trained on the Stochastic Moving-MNIST.", "description": "This table presents the quantitative results of three different generative models (SVGLP, STRPM, and MCVD) trained on the Stochastic Moving-MNIST dataset using two different loss functions: the original loss function of each model and the proposed Fourier Amplitude and Correlation Loss (FACL).  The metrics used for comparison include Mean Absolute Error (MAE), Structural Similarity Index (SSIM), Learned Perceptual Image Patch Similarity (LPIPS), Fr\u00e9chet Video Distance (FVD), Fractional Skill Score (FSS), and Regional Histogram Divergence (RHD). The table shows the impact of replacing the original loss functions with FACL on the performance of the generative models.", "section": "K Applying FACL to Generative Models"}, {"figure_path": "0aN7VWwp4g/tables/tables_22_1.jpg", "caption": "Table 12: The values of different metrics on different transformations, where MAE and MSE are in the scale of 10-3. The worst score for each metric under the tested distortions is underlined and the best score is in bold.", "description": "This table compares the performance of different metrics (MAE, MSE, SSIM, LPIPS, CSI-m, CSI4-m, CSI16-m, FSS, and RHD) across various image transformations (blurring, translation, rotation, brightening, and darkening).  It highlights how each metric responds to different types of image alterations, showcasing their strengths and weaknesses. The best performing metric for each transformation is shown in bold, while the worst performing metric is underlined.  This allows for a comparative analysis of the suitability of various metrics for evaluating the quality of nowcasting predictions under different error conditions.", "section": "L Analysis and Discussion of RHD"}, {"figure_path": "0aN7VWwp4g/tables/tables_24_1.jpg", "caption": "Table 1: Comparison of the quantitative performance of different losses for models trained on the Stochastic Moving-MNIST. The better score between MSE and FACL is highlighted in bold.", "description": "This table compares the performance of models trained using Mean Squared Error (MSE) loss and the proposed Fourier Amplitude and Correlation Loss (FACL) on the Stochastic Moving-MNIST dataset.  It evaluates pixel-wise metrics (MAE, SSIM), perceptual metrics (LPIPS, FVD), and skill scores (FSS, RHD). The bold values indicate which loss function (MSE or FACL) performed better for each metric.", "section": "4.2 A Stochastic Modification of Moving-MNIST"}]