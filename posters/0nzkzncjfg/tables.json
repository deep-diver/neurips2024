[{"figure_path": "0nzKznCjFG/tables/tables_3_1.jpg", "caption": "Figure 1: Performance before finetuning: We compare the test NLL loss before local personalization (finetuning) for baselines FedAvg, MAML, IFCA with our approach. NLL is uniformly averaged over users and each value is averaged over 50 random runs (error bars indicate 95% confidence intervals).", "description": "This figure compares the test negative log-likelihood (NLL) loss before local personalization (finetuning) for several algorithms on three different datasets: Reddit, StackOverflow, and Amazon Reviews.  The algorithms compared are FedAvg, MAML, IFCA, and the authors' approach.  The NLL is uniformly averaged across users for each dataset and experiment, with error bars representing 95% confidence intervals based on 50 runs.", "section": "5 Empirical evaluation"}, {"figure_path": "0nzKznCjFG/tables/tables_4_1.jpg", "caption": "Figure 3: Algorithmic design choices: We evaluate test NLL for Alg. 3 as we: (a) vary the number of clusters K; (b) use PrivateInit or randomly initialize cluster centers; and (c) use average of Good-Turing or empirical average to estimate cluster centers. In (d) we evaluate different finetuning methods applied to the FedAvg model.", "description": "This figure analyzes the impact of algorithmic choices on the test negative log-likelihood (NLL) using Algorithm 3.  Subfigures (a) to (c) explore the effects of varying the number of clusters, using PrivateInit for initialization versus random initialization, and employing Good-Turing averaging versus empirical averaging. Subfigure (d) compares different fine-tuning methods when applied to the FedAvg model.", "section": "Algorithmic design choices"}]